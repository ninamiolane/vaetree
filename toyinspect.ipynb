{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import importlib\n",
    "import toylosses\n",
    "importlib.reload(toylosses)\n",
    "import toynn\n",
    "importlib.reload(toynn)\n",
    "import toyvis\n",
    "importlib.reload(toyvis)\n",
    "\n",
    "import torch\n",
    "sns.set()\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "OUTPUT = '/scratch/users/nmiolane/toyoutput'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect generation of synthetic data from decoder_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_true = 2\n",
    "color_true = 'green'\n",
    "def generate_synthetic_1d(w=w_true, n=10):\n",
    "    z = np.random.normal(loc=0, scale=1, size=(n, 1))\n",
    "    eps = np.random.normal(loc=0, scale=1, size=(n, 1))\n",
    "\n",
    "    x = w * z + eps\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight tensor([[2.]], device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "assert decoder_true.layers[0].weight[0, 0] == w_true\n",
    "\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix from decoder:\n",
      "5.174616839917996\n",
      "Covariance matrix from synthetic:\n",
      "4.905543167070465\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "\n",
    "synthetic_x = generate_synthetic_1d(w=w_true, n=n_samples)\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = toyvis.plot_data(generated_true_x, color='green', label='from decoder true', ax=ax)\n",
    "ax = toyvis.plot_data(synthetic_x, color='green', label='from synthetic true', ax=ax)\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "print('Covariance matrix from decoder:')\n",
    "cov = np.cov(generated_true_x.T)\n",
    "print(cov)\n",
    "\n",
    "print('Covariance matrix from synthetic:')\n",
    "cov = np.cov(synthetic_x.T)\n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results from standard VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[2.]], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[1.0987]], device='cuda:0') \n",
      "\n",
      "Last losses:\n",
      "[0.04121307018399239, 0.04090024897456169, 0.04072944913804531, 0.04138818988204002, 0.04098958967626095]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "decoder_path = glob.glob(f'{OUTPUT}/train_vae/models/decoder.pth')[0]\n",
    "decoder = torch.load(decoder_path, map_location=DEVICE)\n",
    "\n",
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "losses_vae_path = glob.glob(f'{OUTPUT}/train_vae/train_losses.pkl')[0]\n",
    "train_losses_all_epochs = pickle.load(open(losses_vae_path, 'rb'))\n",
    "\n",
    "plt.figure()\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "plt.plot(range(n_epochs), train_losses_total)\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb4016e6d8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "\n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results from VEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[2.]], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[0.0350]], device='cuda:0') \n",
      "\n",
      "Last losses:\n",
      "[0.0851159046292305, 0.08510567712783813, 0.08511399310827256, 0.08511706686019897, 0.08512264275550842]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "decoder_path = glob.glob(f'{OUTPUT}/train_vem/models/decoder.pth')[0]\n",
    "decoder = torch.load(decoder_path, map_location=DEVICE)\n",
    "\n",
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "losses_vae_path = glob.glob(f'{OUTPUT}/train_vem/train_losses.pkl')[0]\n",
    "train_losses_all_epochs = pickle.load(open(losses_vae_path, 'rb'))\n",
    "\n",
    "plt.figure()\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "plt.plot(range(n_epochs), train_losses_total)\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb40cdef60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "\n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='orange', ax=ax)\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "toyvis.plot_data(generated_x, color='orange', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print pipeline logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Log file: logs2019-04-09 20:43:29.033664.txt\n",
      "\n",
      "2019-04-09 20:43:29,033 root         INFO     start\n",
      "2019-04-09 20:43:29,048 luigi        INFO     logging configured by default settings\n",
      "2019-04-09 20:43:29,071 luigi-interface DEBUG    Checking if RunAll() is complete\n",
      "2019-04-09 20:43:29,072 luigi-interface DEBUG    Checking if TrainVAE() is complete\n",
      "2019-04-09 20:43:29,072 luigi-interface DEBUG    Checking if TrainVEM() is complete\n",
      "2019-04-09 20:43:29,073 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   PENDING\n",
      "2019-04-09 20:43:29,073 luigi-interface DEBUG    Checking if MakeDataSet() is complete\n",
      "2019-04-09 20:43:29,074 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   PENDING\n",
      "2019-04-09 20:43:29,074 luigi-interface INFO     Informed scheduler that task   MakeDataSet__99914b932b   has status   PENDING\n",
      "2019-04-09 20:43:29,074 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   PENDING\n",
      "2019-04-09 20:43:29,074 luigi-interface INFO     Done scheduling tasks\n",
      "2019-04-09 20:43:29,074 luigi-interface INFO     Running Worker with 1 processes\n",
      "2019-04-09 20:43:29,074 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 20:43:29,075 luigi-interface DEBUG    Pending tasks: 4\n",
      "2019-04-09 20:43:29,075 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) running   MakeDataSet()\n",
      "2019-04-09 20:43:29,075 root         INFO     Configuration:\n",
      "2019-04-09 20:43:29,075 root         INFO     DATA_DIM = 1\n",
      "2019-04-09 20:43:29,075 root         INFO     LATENT_DIM = 1\n",
      "2019-04-09 20:43:29,075 root         INFO     N_DECODER_LAYERS = 1\n",
      "2019-04-09 20:43:29,075 root         INFO     NONLINEARITY=False\n",
      "2019-04-09 20:43:29,075 root         INFO     WITH_BIASX=False\n",
      "2019-04-09 20:43:29,075 root         INFO     WITH_LOGVARX=False\n",
      "2019-04-09 20:43:29,075 root         INFO     WITH_BIASZ=False\n",
      "2019-04-09 20:43:29,075 root         INFO     WITH_LOGVARZ=False\n",
      "2019-04-09 20:43:29,075 root         INFO     N_SAMPLES=10000\n",
      "2019-04-09 20:43:29,075 root         INFO     W_TRUE:\n",
      "2019-04-09 20:43:29,076 root         INFO     {0: [[2.0]]}\n",
      "2019-04-09 20:43:29,076 root         INFO     B_TRUE:\n",
      "2019-04-09 20:43:29,076 root         INFO     {}\n",
      "2019-04-09 20:43:32,927 root         INFO     Values of true 'decoder' parameters:\n",
      "2019-04-09 20:43:32,927 root         INFO     layers.0.weight\n",
      "2019-04-09 20:43:32,927 root         INFO     tensor([[2.]], device='cuda:0')\n",
      "2019-04-09 20:43:33,003 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) done      MakeDataSet()\n",
      "2019-04-09 20:43:33,003 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 20:43:33,004 luigi-interface INFO     Informed scheduler that task   MakeDataSet__99914b932b   has status   DONE\n",
      "2019-04-09 20:43:33,004 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 20:43:33,004 luigi-interface DEBUG    Pending tasks: 3\n",
      "2019-04-09 20:43:33,004 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) running   TrainVAE()\n",
      "2019-04-09 20:43:33,006 root         INFO     --Dataset tensor: (10000, 1)\n",
      "2019-04-09 20:43:33,006 root         INFO     -- Train tensor: (8000, 1)\n",
      "2019-04-09 20:43:33,007 root         INFO     Values of VAE's decoder parameters before training:\n",
      "2019-04-09 20:43:33,007 root         INFO     layers.0.weight\n",
      "2019-04-09 20:43:33,007 root         INFO     tensor([[0.9843]], device='cuda:0')\n",
      "2019-04-09 20:43:33,064 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 0.143113\n",
      "Reconstruction: 0.111874, Regularization: 0.031239\n",
      "2019-04-09 20:43:33,090 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 0.086073\n",
      "Reconstruction: 0.068759, Regularization: 0.017313\n",
      "2019-04-09 20:43:33,116 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 0.119782\n",
      "Reconstruction: 0.093426, Regularization: 0.026356\n",
      "2019-04-09 20:43:33,143 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 0.104063\n",
      "Reconstruction: 0.082816, Regularization: 0.021247\n",
      "2019-04-09 20:43:33,169 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 0.122470\n",
      "Reconstruction: 0.095654, Regularization: 0.026816\n",
      "2019-04-09 20:43:33,195 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 0.107716\n",
      "Reconstruction: 0.085178, Regularization: 0.022538\n",
      "2019-04-09 20:43:33,221 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 0.124466\n",
      "Reconstruction: 0.097871, Regularization: 0.026595\n",
      "2019-04-09 20:43:33,246 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 0.112226\n",
      "Reconstruction: 0.088852, Regularization: 0.023374\n",
      "2019-04-09 20:43:33,284 root         INFO     ====> Epoch: 0 Average loss: 0.1192\n",
      "2019-04-09 20:43:33,306 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 0.121119\n",
      "Reconstruction: 0.095526, Regularization: 0.025594\n",
      "2019-04-09 20:43:33,333 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 0.128738\n",
      "Reconstruction: 0.100717, Regularization: 0.028022\n",
      "2019-04-09 20:43:33,360 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 0.129123\n",
      "Reconstruction: 0.102360, Regularization: 0.026763\n",
      "2019-04-09 20:43:33,387 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 0.129338\n",
      "Reconstruction: 0.101829, Regularization: 0.027508\n",
      "2019-04-09 20:43:33,414 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 0.115296\n",
      "Reconstruction: 0.089340, Regularization: 0.025956\n",
      "2019-04-09 20:43:33,442 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 0.103050\n",
      "Reconstruction: 0.079963, Regularization: 0.023088\n",
      "2019-04-09 20:43:33,468 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 0.117097\n",
      "Reconstruction: 0.090895, Regularization: 0.026202\n",
      "2019-04-09 20:43:33,495 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 0.134582\n",
      "Reconstruction: 0.105552, Regularization: 0.029030\n",
      "2019-04-09 20:43:33,533 root         INFO     ====> Epoch: 1 Average loss: 0.1157\n",
      "2019-04-09 20:43:33,555 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 0.091388\n",
      "Reconstruction: 0.073079, Regularization: 0.018309\n",
      "2019-04-09 20:43:33,582 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 0.131784\n",
      "Reconstruction: 0.101614, Regularization: 0.030170\n",
      "2019-04-09 20:43:33,610 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 0.133483\n",
      "Reconstruction: 0.104337, Regularization: 0.029146\n",
      "2019-04-09 20:43:33,640 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 0.116499\n",
      "Reconstruction: 0.091024, Regularization: 0.025475\n",
      "2019-04-09 20:43:33,669 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 0.136757\n",
      "Reconstruction: 0.106304, Regularization: 0.030453\n",
      "2019-04-09 20:43:33,698 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 0.104426\n",
      "Reconstruction: 0.081701, Regularization: 0.022725\n",
      "2019-04-09 20:43:33,727 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 0.114189\n",
      "Reconstruction: 0.090864, Regularization: 0.023325\n",
      "2019-04-09 20:43:33,757 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 0.092408\n",
      "Reconstruction: 0.073768, Regularization: 0.018640\n",
      "2019-04-09 20:43:33,797 root         INFO     ====> Epoch: 2 Average loss: 0.1138\n",
      "2019-04-09 20:43:33,818 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 0.094357\n",
      "Reconstruction: 0.073235, Regularization: 0.021122\n",
      "2019-04-09 20:43:33,846 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 0.102295\n",
      "Reconstruction: 0.081409, Regularization: 0.020886\n",
      "2019-04-09 20:43:33,873 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 0.104147\n",
      "Reconstruction: 0.082682, Regularization: 0.021465\n",
      "2019-04-09 20:43:33,900 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 0.099068\n",
      "Reconstruction: 0.078090, Regularization: 0.020978\n",
      "2019-04-09 20:43:33,927 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 0.124678\n",
      "Reconstruction: 0.096491, Regularization: 0.028187\n",
      "2019-04-09 20:43:33,955 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 0.123925\n",
      "Reconstruction: 0.098221, Regularization: 0.025704\n",
      "2019-04-09 20:43:33,982 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 0.093572\n",
      "Reconstruction: 0.073734, Regularization: 0.019838\n",
      "2019-04-09 20:43:34,009 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 0.102098\n",
      "Reconstruction: 0.082144, Regularization: 0.019954\n",
      "2019-04-09 20:43:34,046 root         INFO     ====> Epoch: 3 Average loss: 0.1118\n",
      "2019-04-09 20:43:34,067 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 0.108173\n",
      "Reconstruction: 0.085282, Regularization: 0.022891\n",
      "2019-04-09 20:43:34,094 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 0.116430\n",
      "Reconstruction: 0.092072, Regularization: 0.024358\n",
      "2019-04-09 20:43:34,121 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 0.101917\n",
      "Reconstruction: 0.081432, Regularization: 0.020485\n",
      "2019-04-09 20:43:34,148 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 0.087024\n",
      "Reconstruction: 0.068988, Regularization: 0.018036\n",
      "2019-04-09 20:43:34,175 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 0.123969\n",
      "Reconstruction: 0.098118, Regularization: 0.025851\n",
      "2019-04-09 20:43:34,202 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 0.111509\n",
      "Reconstruction: 0.086611, Regularization: 0.024898\n",
      "2019-04-09 20:43:34,229 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 0.102699\n",
      "Reconstruction: 0.082108, Regularization: 0.020591\n",
      "2019-04-09 20:43:34,257 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 0.089395\n",
      "Reconstruction: 0.071534, Regularization: 0.017861\n",
      "2019-04-09 20:43:34,295 root         INFO     ====> Epoch: 4 Average loss: 0.1093\n",
      "2019-04-09 20:43:34,317 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 0.121246\n",
      "Reconstruction: 0.096093, Regularization: 0.025153\n",
      "2019-04-09 20:43:34,344 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 0.090817\n",
      "Reconstruction: 0.072246, Regularization: 0.018571\n",
      "2019-04-09 20:43:34,371 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 0.107512\n",
      "Reconstruction: 0.085399, Regularization: 0.022113\n",
      "2019-04-09 20:43:34,399 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 0.116574\n",
      "Reconstruction: 0.092925, Regularization: 0.023649\n",
      "2019-04-09 20:43:34,426 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 0.087916\n",
      "Reconstruction: 0.070981, Regularization: 0.016935\n",
      "2019-04-09 20:43:34,454 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 0.118471\n",
      "Reconstruction: 0.094306, Regularization: 0.024165\n",
      "2019-04-09 20:43:34,481 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 0.078050\n",
      "Reconstruction: 0.063052, Regularization: 0.014998\n",
      "2019-04-09 20:43:34,507 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 0.105228\n",
      "Reconstruction: 0.084380, Regularization: 0.020848\n",
      "2019-04-09 20:43:34,545 root         INFO     ====> Epoch: 5 Average loss: 0.1065\n",
      "2019-04-09 20:43:34,566 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 0.087810\n",
      "Reconstruction: 0.069627, Regularization: 0.018183\n",
      "2019-04-09 20:43:34,593 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 0.117592\n",
      "Reconstruction: 0.093556, Regularization: 0.024036\n",
      "2019-04-09 20:43:34,620 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 0.077602\n",
      "Reconstruction: 0.061684, Regularization: 0.015918\n",
      "2019-04-09 20:43:34,648 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 0.077849\n",
      "Reconstruction: 0.062272, Regularization: 0.015577\n",
      "2019-04-09 20:43:34,675 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 0.106479\n",
      "Reconstruction: 0.084898, Regularization: 0.021581\n",
      "2019-04-09 20:43:34,702 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 0.093098\n",
      "Reconstruction: 0.074561, Regularization: 0.018537\n",
      "2019-04-09 20:43:34,728 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 0.104046\n",
      "Reconstruction: 0.082784, Regularization: 0.021261\n",
      "2019-04-09 20:43:34,754 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 0.084027\n",
      "Reconstruction: 0.067921, Regularization: 0.016106\n",
      "2019-04-09 20:43:34,791 root         INFO     ====> Epoch: 6 Average loss: 0.1050\n",
      "2019-04-09 20:43:34,812 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 0.084186\n",
      "Reconstruction: 0.067248, Regularization: 0.016937\n",
      "2019-04-09 20:43:34,838 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 0.111053\n",
      "Reconstruction: 0.087495, Regularization: 0.023558\n",
      "2019-04-09 20:43:34,866 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 0.101025\n",
      "Reconstruction: 0.080713, Regularization: 0.020312\n",
      "2019-04-09 20:43:34,893 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 0.137743\n",
      "Reconstruction: 0.109308, Regularization: 0.028435\n",
      "2019-04-09 20:43:34,921 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 0.104566\n",
      "Reconstruction: 0.083250, Regularization: 0.021316\n",
      "2019-04-09 20:43:34,948 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 0.124386\n",
      "Reconstruction: 0.100268, Regularization: 0.024118\n",
      "2019-04-09 20:43:34,975 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 0.082989\n",
      "Reconstruction: 0.066022, Regularization: 0.016968\n",
      "2019-04-09 20:43:35,003 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 0.077630\n",
      "Reconstruction: 0.063224, Regularization: 0.014406\n",
      "2019-04-09 20:43:35,041 root         INFO     ====> Epoch: 7 Average loss: 0.1029\n",
      "2019-04-09 20:43:35,062 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 0.091930\n",
      "Reconstruction: 0.074055, Regularization: 0.017875\n",
      "2019-04-09 20:43:35,090 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 0.091458\n",
      "Reconstruction: 0.074267, Regularization: 0.017190\n",
      "2019-04-09 20:43:35,117 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 0.138804\n",
      "Reconstruction: 0.109707, Regularization: 0.029097\n",
      "2019-04-09 20:43:35,144 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 0.130547\n",
      "Reconstruction: 0.103344, Regularization: 0.027203\n",
      "2019-04-09 20:43:35,170 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 0.084247\n",
      "Reconstruction: 0.068224, Regularization: 0.016023\n",
      "2019-04-09 20:43:35,197 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 0.114507\n",
      "Reconstruction: 0.091597, Regularization: 0.022911\n",
      "2019-04-09 20:43:35,224 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 0.107422\n",
      "Reconstruction: 0.085236, Regularization: 0.022186\n",
      "2019-04-09 20:43:35,252 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 0.101115\n",
      "Reconstruction: 0.081371, Regularization: 0.019744\n",
      "2019-04-09 20:43:35,290 root         INFO     ====> Epoch: 8 Average loss: 0.1008\n",
      "2019-04-09 20:43:35,311 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 0.104324\n",
      "Reconstruction: 0.083577, Regularization: 0.020747\n",
      "2019-04-09 20:43:35,336 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 0.096223\n",
      "Reconstruction: 0.077114, Regularization: 0.019109\n",
      "2019-04-09 20:43:35,361 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 0.087821\n",
      "Reconstruction: 0.070621, Regularization: 0.017199\n",
      "2019-04-09 20:43:35,386 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 0.088269\n",
      "Reconstruction: 0.071339, Regularization: 0.016931\n",
      "2019-04-09 20:43:35,411 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 0.086726\n",
      "Reconstruction: 0.069221, Regularization: 0.017506\n",
      "2019-04-09 20:43:35,436 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 0.113033\n",
      "Reconstruction: 0.090742, Regularization: 0.022291\n",
      "2019-04-09 20:43:35,461 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 0.112149\n",
      "Reconstruction: 0.090107, Regularization: 0.022042\n",
      "2019-04-09 20:43:35,486 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 0.084682\n",
      "Reconstruction: 0.069031, Regularization: 0.015652\n",
      "2019-04-09 20:43:35,523 root         INFO     ====> Epoch: 9 Average loss: 0.0988\n",
      "2019-04-09 20:43:35,544 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 0.087294\n",
      "Reconstruction: 0.070752, Regularization: 0.016542\n",
      "2019-04-09 20:43:35,571 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 0.086872\n",
      "Reconstruction: 0.070351, Regularization: 0.016520\n",
      "2019-04-09 20:43:35,598 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 0.086476\n",
      "Reconstruction: 0.070368, Regularization: 0.016107\n",
      "2019-04-09 20:43:35,626 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 0.102736\n",
      "Reconstruction: 0.081979, Regularization: 0.020757\n",
      "2019-04-09 20:43:35,653 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 0.091722\n",
      "Reconstruction: 0.074691, Regularization: 0.017031\n",
      "2019-04-09 20:43:35,680 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 0.085702\n",
      "Reconstruction: 0.069538, Regularization: 0.016165\n",
      "2019-04-09 20:43:35,707 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 0.079470\n",
      "Reconstruction: 0.064884, Regularization: 0.014587\n",
      "2019-04-09 20:43:35,734 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 0.078421\n",
      "Reconstruction: 0.063657, Regularization: 0.014764\n",
      "2019-04-09 20:43:35,772 root         INFO     ====> Epoch: 10 Average loss: 0.0969\n",
      "2019-04-09 20:43:35,793 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.090095\n",
      "Reconstruction: 0.072507, Regularization: 0.017588\n",
      "2019-04-09 20:43:35,820 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 0.087805\n",
      "Reconstruction: 0.070823, Regularization: 0.016982\n",
      "2019-04-09 20:43:35,848 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.102506\n",
      "Reconstruction: 0.082202, Regularization: 0.020303\n",
      "2019-04-09 20:43:35,875 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 0.146445\n",
      "Reconstruction: 0.116475, Regularization: 0.029970\n",
      "2019-04-09 20:43:35,902 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 0.089261\n",
      "Reconstruction: 0.071845, Regularization: 0.017416\n",
      "2019-04-09 20:43:35,930 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 0.099277\n",
      "Reconstruction: 0.079760, Regularization: 0.019517\n",
      "2019-04-09 20:43:35,957 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.084531\n",
      "Reconstruction: 0.068625, Regularization: 0.015906\n",
      "2019-04-09 20:43:35,984 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 0.084892\n",
      "Reconstruction: 0.069328, Regularization: 0.015564\n",
      "2019-04-09 20:43:36,022 root         INFO     ====> Epoch: 11 Average loss: 0.0952\n",
      "2019-04-09 20:43:36,043 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 0.088853\n",
      "Reconstruction: 0.072176, Regularization: 0.016678\n",
      "2019-04-09 20:43:36,070 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 0.114926\n",
      "Reconstruction: 0.092408, Regularization: 0.022517\n",
      "2019-04-09 20:43:36,096 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 0.100323\n",
      "Reconstruction: 0.081616, Regularization: 0.018708\n",
      "2019-04-09 20:43:36,122 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 0.083775\n",
      "Reconstruction: 0.068622, Regularization: 0.015153\n",
      "2019-04-09 20:43:36,148 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 0.114519\n",
      "Reconstruction: 0.091961, Regularization: 0.022557\n",
      "2019-04-09 20:43:36,174 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.090872\n",
      "Reconstruction: 0.073714, Regularization: 0.017158\n",
      "2019-04-09 20:43:36,200 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.073561\n",
      "Reconstruction: 0.061296, Regularization: 0.012265\n",
      "2019-04-09 20:43:36,225 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 0.099856\n",
      "Reconstruction: 0.081273, Regularization: 0.018584\n",
      "2019-04-09 20:43:36,263 root         INFO     ====> Epoch: 12 Average loss: 0.0933\n",
      "2019-04-09 20:43:36,284 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 0.076596\n",
      "Reconstruction: 0.063413, Regularization: 0.013184\n",
      "2019-04-09 20:43:36,312 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 0.084473\n",
      "Reconstruction: 0.069197, Regularization: 0.015276\n",
      "2019-04-09 20:43:36,339 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 0.113973\n",
      "Reconstruction: 0.091801, Regularization: 0.022171\n",
      "2019-04-09 20:43:36,367 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 0.097616\n",
      "Reconstruction: 0.078827, Regularization: 0.018789\n",
      "2019-04-09 20:43:36,394 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 0.114320\n",
      "Reconstruction: 0.092423, Regularization: 0.021897\n",
      "2019-04-09 20:43:36,421 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 0.106722\n",
      "Reconstruction: 0.085788, Regularization: 0.020934\n",
      "2019-04-09 20:43:36,448 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 0.088348\n",
      "Reconstruction: 0.071363, Regularization: 0.016984\n",
      "2019-04-09 20:43:36,475 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 0.082466\n",
      "Reconstruction: 0.067096, Regularization: 0.015370\n",
      "2019-04-09 20:43:36,513 root         INFO     ====> Epoch: 13 Average loss: 0.0913\n",
      "2019-04-09 20:43:36,534 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.074063\n",
      "Reconstruction: 0.061542, Regularization: 0.012521\n",
      "2019-04-09 20:43:36,561 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.085444\n",
      "Reconstruction: 0.070799, Regularization: 0.014645\n",
      "2019-04-09 20:43:36,588 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 0.104169\n",
      "Reconstruction: 0.084607, Regularization: 0.019561\n",
      "2019-04-09 20:43:36,615 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.072497\n",
      "Reconstruction: 0.059965, Regularization: 0.012532\n",
      "2019-04-09 20:43:36,642 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.084897\n",
      "Reconstruction: 0.069490, Regularization: 0.015407\n",
      "2019-04-09 20:43:36,668 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 0.102656\n",
      "Reconstruction: 0.083405, Regularization: 0.019251\n",
      "2019-04-09 20:43:36,694 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.090474\n",
      "Reconstruction: 0.073891, Regularization: 0.016582\n",
      "2019-04-09 20:43:36,719 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.117014\n",
      "Reconstruction: 0.094383, Regularization: 0.022630\n",
      "2019-04-09 20:43:36,757 root         INFO     ====> Epoch: 14 Average loss: 0.0901\n",
      "2019-04-09 20:43:36,778 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 0.103261\n",
      "Reconstruction: 0.083932, Regularization: 0.019329\n",
      "2019-04-09 20:43:36,805 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 0.102733\n",
      "Reconstruction: 0.083671, Regularization: 0.019062\n",
      "2019-04-09 20:43:36,832 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.092465\n",
      "Reconstruction: 0.075777, Regularization: 0.016688\n",
      "2019-04-09 20:43:36,857 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.101808\n",
      "Reconstruction: 0.083017, Regularization: 0.018791\n",
      "2019-04-09 20:43:36,884 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.078647\n",
      "Reconstruction: 0.064993, Regularization: 0.013654\n",
      "2019-04-09 20:43:36,910 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.090887\n",
      "Reconstruction: 0.074479, Regularization: 0.016408\n",
      "2019-04-09 20:43:36,937 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.080443\n",
      "Reconstruction: 0.065503, Regularization: 0.014940\n",
      "2019-04-09 20:43:36,964 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 0.054522\n",
      "Reconstruction: 0.045737, Regularization: 0.008785\n",
      "2019-04-09 20:43:37,002 root         INFO     ====> Epoch: 15 Average loss: 0.0882\n",
      "2019-04-09 20:43:37,023 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 0.070046\n",
      "Reconstruction: 0.058126, Regularization: 0.011921\n",
      "2019-04-09 20:43:37,049 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 0.072569\n",
      "Reconstruction: 0.059962, Regularization: 0.012607\n",
      "2019-04-09 20:43:37,075 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.076244\n",
      "Reconstruction: 0.062893, Regularization: 0.013351\n",
      "2019-04-09 20:43:37,101 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 0.068663\n",
      "Reconstruction: 0.057019, Regularization: 0.011644\n",
      "2019-04-09 20:43:37,128 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 0.073743\n",
      "Reconstruction: 0.060790, Regularization: 0.012954\n",
      "2019-04-09 20:43:37,156 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 0.057911\n",
      "Reconstruction: 0.048428, Regularization: 0.009484\n",
      "2019-04-09 20:43:37,182 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 0.069919\n",
      "Reconstruction: 0.057406, Regularization: 0.012513\n",
      "2019-04-09 20:43:37,208 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.087642\n",
      "Reconstruction: 0.072011, Regularization: 0.015632\n",
      "2019-04-09 20:43:37,245 root         INFO     ====> Epoch: 16 Average loss: 0.0867\n",
      "2019-04-09 20:43:37,266 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.092886\n",
      "Reconstruction: 0.075983, Regularization: 0.016903\n",
      "2019-04-09 20:43:37,292 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 0.070512\n",
      "Reconstruction: 0.058203, Regularization: 0.012309\n",
      "2019-04-09 20:43:37,317 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.094380\n",
      "Reconstruction: 0.077890, Regularization: 0.016490\n",
      "2019-04-09 20:43:37,343 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 0.082515\n",
      "Reconstruction: 0.068470, Regularization: 0.014046\n",
      "2019-04-09 20:43:37,370 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.071002\n",
      "Reconstruction: 0.059440, Regularization: 0.011562\n",
      "2019-04-09 20:43:37,396 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 0.101649\n",
      "Reconstruction: 0.084338, Regularization: 0.017310\n",
      "2019-04-09 20:43:37,421 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 0.091980\n",
      "Reconstruction: 0.076105, Regularization: 0.015874\n",
      "2019-04-09 20:43:37,447 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 0.075350\n",
      "Reconstruction: 0.062296, Regularization: 0.013054\n",
      "2019-04-09 20:43:37,484 root         INFO     ====> Epoch: 17 Average loss: 0.0854\n",
      "2019-04-09 20:43:37,505 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 0.061680\n",
      "Reconstruction: 0.052227, Regularization: 0.009453\n",
      "2019-04-09 20:43:37,532 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.095234\n",
      "Reconstruction: 0.078458, Regularization: 0.016776\n",
      "2019-04-09 20:43:37,559 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 0.093446\n",
      "Reconstruction: 0.077172, Regularization: 0.016274\n",
      "2019-04-09 20:43:37,586 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.094657\n",
      "Reconstruction: 0.079060, Regularization: 0.015597\n",
      "2019-04-09 20:43:37,613 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 0.101334\n",
      "Reconstruction: 0.082657, Regularization: 0.018677\n",
      "2019-04-09 20:43:37,639 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.081240\n",
      "Reconstruction: 0.066804, Regularization: 0.014436\n",
      "2019-04-09 20:43:37,666 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 0.080795\n",
      "Reconstruction: 0.066572, Regularization: 0.014223\n",
      "2019-04-09 20:43:37,693 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 0.088018\n",
      "Reconstruction: 0.072165, Regularization: 0.015853\n",
      "2019-04-09 20:43:37,731 root         INFO     ====> Epoch: 18 Average loss: 0.0839\n",
      "2019-04-09 20:43:37,753 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 0.075797\n",
      "Reconstruction: 0.063262, Regularization: 0.012535\n",
      "2019-04-09 20:43:37,780 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 0.071749\n",
      "Reconstruction: 0.060298, Regularization: 0.011451\n",
      "2019-04-09 20:43:37,806 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 0.078067\n",
      "Reconstruction: 0.064933, Regularization: 0.013134\n",
      "2019-04-09 20:43:37,833 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 0.087170\n",
      "Reconstruction: 0.072094, Regularization: 0.015076\n",
      "2019-04-09 20:43:37,860 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 0.085230\n",
      "Reconstruction: 0.070839, Regularization: 0.014391\n",
      "2019-04-09 20:43:37,887 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 0.086966\n",
      "Reconstruction: 0.072285, Regularization: 0.014681\n",
      "2019-04-09 20:43:37,914 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 0.081238\n",
      "Reconstruction: 0.067166, Regularization: 0.014072\n",
      "2019-04-09 20:43:37,940 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.098832\n",
      "Reconstruction: 0.081317, Regularization: 0.017515\n",
      "2019-04-09 20:43:37,978 root         INFO     ====> Epoch: 19 Average loss: 0.0827\n",
      "2019-04-09 20:43:37,999 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 0.075317\n",
      "Reconstruction: 0.063001, Regularization: 0.012316\n",
      "2019-04-09 20:43:38,026 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 0.086279\n",
      "Reconstruction: 0.071863, Regularization: 0.014416\n",
      "2019-04-09 20:43:38,053 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 0.070771\n",
      "Reconstruction: 0.059860, Regularization: 0.010911\n",
      "2019-04-09 20:43:38,080 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 0.088181\n",
      "Reconstruction: 0.073115, Regularization: 0.015067\n",
      "2019-04-09 20:43:38,107 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 0.081508\n",
      "Reconstruction: 0.068158, Regularization: 0.013350\n",
      "2019-04-09 20:43:38,134 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 0.081416\n",
      "Reconstruction: 0.067427, Regularization: 0.013989\n",
      "2019-04-09 20:43:38,160 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 0.086913\n",
      "Reconstruction: 0.072281, Regularization: 0.014633\n",
      "2019-04-09 20:43:38,187 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 0.069705\n",
      "Reconstruction: 0.058505, Regularization: 0.011199\n",
      "2019-04-09 20:43:38,225 root         INFO     ====> Epoch: 20 Average loss: 0.0813\n",
      "2019-04-09 20:43:38,246 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.066612\n",
      "Reconstruction: 0.056279, Regularization: 0.010333\n",
      "2019-04-09 20:43:38,272 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 0.112903\n",
      "Reconstruction: 0.093163, Regularization: 0.019740\n",
      "2019-04-09 20:43:38,298 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 0.078872\n",
      "Reconstruction: 0.066133, Regularization: 0.012739\n",
      "2019-04-09 20:43:38,325 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 0.114042\n",
      "Reconstruction: 0.093947, Regularization: 0.020095\n",
      "2019-04-09 20:43:38,352 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.083688\n",
      "Reconstruction: 0.070097, Regularization: 0.013591\n",
      "2019-04-09 20:43:38,380 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 0.093261\n",
      "Reconstruction: 0.077363, Regularization: 0.015898\n",
      "2019-04-09 20:43:38,407 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 0.098732\n",
      "Reconstruction: 0.081870, Regularization: 0.016863\n",
      "2019-04-09 20:43:38,435 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.085565\n",
      "Reconstruction: 0.071360, Regularization: 0.014205\n",
      "2019-04-09 20:43:38,473 root         INFO     ====> Epoch: 21 Average loss: 0.0797\n",
      "2019-04-09 20:43:38,494 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 0.078047\n",
      "Reconstruction: 0.066166, Regularization: 0.011881\n",
      "2019-04-09 20:43:38,522 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 0.081577\n",
      "Reconstruction: 0.068189, Regularization: 0.013387\n",
      "2019-04-09 20:43:38,549 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 0.082650\n",
      "Reconstruction: 0.069633, Regularization: 0.013016\n",
      "2019-04-09 20:43:38,576 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 0.085678\n",
      "Reconstruction: 0.071259, Regularization: 0.014419\n",
      "2019-04-09 20:43:38,603 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.071681\n",
      "Reconstruction: 0.060336, Regularization: 0.011345\n",
      "2019-04-09 20:43:38,630 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 0.066190\n",
      "Reconstruction: 0.056000, Regularization: 0.010190\n",
      "2019-04-09 20:43:38,658 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 0.071060\n",
      "Reconstruction: 0.059682, Regularization: 0.011378\n",
      "2019-04-09 20:43:38,685 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 0.069309\n",
      "Reconstruction: 0.058892, Regularization: 0.010417\n",
      "2019-04-09 20:43:38,723 root         INFO     ====> Epoch: 22 Average loss: 0.0788\n",
      "2019-04-09 20:43:38,744 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 0.068900\n",
      "Reconstruction: 0.058262, Regularization: 0.010639\n",
      "2019-04-09 20:43:38,770 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 0.049807\n",
      "Reconstruction: 0.042996, Regularization: 0.006810\n",
      "2019-04-09 20:43:38,798 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 0.085919\n",
      "Reconstruction: 0.071283, Regularization: 0.014636\n",
      "2019-04-09 20:43:38,825 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 0.068543\n",
      "Reconstruction: 0.058435, Regularization: 0.010108\n",
      "2019-04-09 20:43:38,852 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 0.079541\n",
      "Reconstruction: 0.066690, Regularization: 0.012851\n",
      "2019-04-09 20:43:38,880 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 0.081710\n",
      "Reconstruction: 0.069070, Regularization: 0.012641\n",
      "2019-04-09 20:43:38,907 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 0.080158\n",
      "Reconstruction: 0.067526, Regularization: 0.012632\n",
      "2019-04-09 20:43:38,934 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 0.069336\n",
      "Reconstruction: 0.058948, Regularization: 0.010388\n",
      "2019-04-09 20:43:38,972 root         INFO     ====> Epoch: 23 Average loss: 0.0771\n",
      "2019-04-09 20:43:38,993 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.064238\n",
      "Reconstruction: 0.054679, Regularization: 0.009559\n",
      "2019-04-09 20:43:39,021 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 0.065220\n",
      "Reconstruction: 0.055234, Regularization: 0.009986\n",
      "2019-04-09 20:43:39,049 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 0.067647\n",
      "Reconstruction: 0.057425, Regularization: 0.010222\n",
      "2019-04-09 20:43:39,076 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 0.076995\n",
      "Reconstruction: 0.064799, Regularization: 0.012196\n",
      "2019-04-09 20:43:39,103 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 0.067878\n",
      "Reconstruction: 0.057417, Regularization: 0.010462\n",
      "2019-04-09 20:43:39,131 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 0.081014\n",
      "Reconstruction: 0.068582, Regularization: 0.012432\n",
      "2019-04-09 20:43:39,158 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 0.068459\n",
      "Reconstruction: 0.058428, Regularization: 0.010031\n",
      "2019-04-09 20:43:39,184 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 0.074672\n",
      "Reconstruction: 0.063328, Regularization: 0.011344\n",
      "2019-04-09 20:43:39,222 root         INFO     ====> Epoch: 24 Average loss: 0.0760\n",
      "2019-04-09 20:43:39,243 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 0.072635\n",
      "Reconstruction: 0.061639, Regularization: 0.010996\n",
      "2019-04-09 20:43:39,271 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 0.079124\n",
      "Reconstruction: 0.067225, Regularization: 0.011899\n",
      "2019-04-09 20:43:39,297 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 0.071802\n",
      "Reconstruction: 0.060991, Regularization: 0.010811\n",
      "2019-04-09 20:43:39,323 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 0.085594\n",
      "Reconstruction: 0.072222, Regularization: 0.013372\n",
      "2019-04-09 20:43:39,349 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 0.063830\n",
      "Reconstruction: 0.054806, Regularization: 0.009024\n",
      "2019-04-09 20:43:39,376 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 0.073275\n",
      "Reconstruction: 0.062397, Regularization: 0.010878\n",
      "2019-04-09 20:43:39,402 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.071487\n",
      "Reconstruction: 0.061110, Regularization: 0.010377\n",
      "2019-04-09 20:43:39,428 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 0.063799\n",
      "Reconstruction: 0.054879, Regularization: 0.008920\n",
      "2019-04-09 20:43:39,465 root         INFO     ====> Epoch: 25 Average loss: 0.0750\n",
      "2019-04-09 20:43:39,486 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 0.084621\n",
      "Reconstruction: 0.071613, Regularization: 0.013008\n",
      "2019-04-09 20:43:39,513 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 0.066701\n",
      "Reconstruction: 0.057082, Regularization: 0.009618\n",
      "2019-04-09 20:43:39,540 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 0.082649\n",
      "Reconstruction: 0.070110, Regularization: 0.012538\n",
      "2019-04-09 20:43:39,567 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 0.084155\n",
      "Reconstruction: 0.071403, Regularization: 0.012752\n",
      "2019-04-09 20:43:39,594 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.068733\n",
      "Reconstruction: 0.058840, Regularization: 0.009893\n",
      "2019-04-09 20:43:39,621 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 0.066031\n",
      "Reconstruction: 0.056590, Regularization: 0.009441\n",
      "2019-04-09 20:43:39,648 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 0.063497\n",
      "Reconstruction: 0.054433, Regularization: 0.009063\n",
      "2019-04-09 20:43:39,675 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 0.057039\n",
      "Reconstruction: 0.049005, Regularization: 0.008034\n",
      "2019-04-09 20:43:39,713 root         INFO     ====> Epoch: 26 Average loss: 0.0739\n",
      "2019-04-09 20:43:39,735 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 0.079334\n",
      "Reconstruction: 0.067595, Regularization: 0.011740\n",
      "2019-04-09 20:43:39,762 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.074280\n",
      "Reconstruction: 0.063705, Regularization: 0.010575\n",
      "2019-04-09 20:43:39,788 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 0.080647\n",
      "Reconstruction: 0.068835, Regularization: 0.011812\n",
      "2019-04-09 20:43:39,816 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.075224\n",
      "Reconstruction: 0.064372, Regularization: 0.010852\n",
      "2019-04-09 20:43:39,842 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 0.082353\n",
      "Reconstruction: 0.070289, Regularization: 0.012064\n",
      "2019-04-09 20:43:39,869 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.053894\n",
      "Reconstruction: 0.046602, Regularization: 0.007292\n",
      "2019-04-09 20:43:39,896 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.089844\n",
      "Reconstruction: 0.076355, Regularization: 0.013489\n",
      "2019-04-09 20:43:39,923 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 0.091804\n",
      "Reconstruction: 0.077396, Regularization: 0.014408\n",
      "2019-04-09 20:43:39,961 root         INFO     ====> Epoch: 27 Average loss: 0.0727\n",
      "2019-04-09 20:43:39,982 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.058917\n",
      "Reconstruction: 0.050973, Regularization: 0.007944\n",
      "2019-04-09 20:43:40,009 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.080638\n",
      "Reconstruction: 0.068719, Regularization: 0.011919\n",
      "2019-04-09 20:43:40,035 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 0.081879\n",
      "Reconstruction: 0.069808, Regularization: 0.012071\n",
      "2019-04-09 20:43:40,062 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.066482\n",
      "Reconstruction: 0.057311, Regularization: 0.009170\n",
      "2019-04-09 20:43:40,089 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.055385\n",
      "Reconstruction: 0.048185, Regularization: 0.007200\n",
      "2019-04-09 20:43:40,116 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.071395\n",
      "Reconstruction: 0.061331, Regularization: 0.010064\n",
      "2019-04-09 20:43:40,142 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.071969\n",
      "Reconstruction: 0.061777, Regularization: 0.010192\n",
      "2019-04-09 20:43:40,167 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.063867\n",
      "Reconstruction: 0.055113, Regularization: 0.008754\n",
      "2019-04-09 20:43:40,204 root         INFO     ====> Epoch: 28 Average loss: 0.0718\n",
      "2019-04-09 20:43:40,225 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 0.071794\n",
      "Reconstruction: 0.061488, Regularization: 0.010307\n",
      "2019-04-09 20:43:40,252 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 0.065204\n",
      "Reconstruction: 0.056413, Regularization: 0.008790\n",
      "2019-04-09 20:43:40,279 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 0.063980\n",
      "Reconstruction: 0.055508, Regularization: 0.008472\n",
      "2019-04-09 20:43:40,305 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 0.078192\n",
      "Reconstruction: 0.067342, Regularization: 0.010850\n",
      "2019-04-09 20:43:40,332 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.068613\n",
      "Reconstruction: 0.059224, Regularization: 0.009389\n",
      "2019-04-09 20:43:40,359 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 0.068598\n",
      "Reconstruction: 0.059171, Regularization: 0.009426\n",
      "2019-04-09 20:43:40,386 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 0.057373\n",
      "Reconstruction: 0.049958, Regularization: 0.007415\n",
      "2019-04-09 20:43:40,412 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.075203\n",
      "Reconstruction: 0.064657, Regularization: 0.010546\n",
      "2019-04-09 20:43:40,450 root         INFO     ====> Epoch: 29 Average loss: 0.0705\n",
      "2019-04-09 20:43:40,471 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.060234\n",
      "Reconstruction: 0.052478, Regularization: 0.007756\n",
      "2019-04-09 20:43:40,498 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.080096\n",
      "Reconstruction: 0.068927, Regularization: 0.011169\n",
      "2019-04-09 20:43:40,525 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.068557\n",
      "Reconstruction: 0.059059, Regularization: 0.009498\n",
      "2019-04-09 20:43:40,552 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.068209\n",
      "Reconstruction: 0.059145, Regularization: 0.009064\n",
      "2019-04-09 20:43:40,578 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.072987\n",
      "Reconstruction: 0.062996, Regularization: 0.009990\n",
      "2019-04-09 20:43:40,603 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.054521\n",
      "Reconstruction: 0.047597, Regularization: 0.006924\n",
      "2019-04-09 20:43:40,628 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.072696\n",
      "Reconstruction: 0.063221, Regularization: 0.009474\n",
      "2019-04-09 20:43:40,654 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 0.057621\n",
      "Reconstruction: 0.050192, Regularization: 0.007428\n",
      "2019-04-09 20:43:40,692 root         INFO     ====> Epoch: 30 Average loss: 0.0696\n",
      "2019-04-09 20:43:40,713 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.073049\n",
      "Reconstruction: 0.063172, Regularization: 0.009877\n",
      "2019-04-09 20:43:40,739 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.071313\n",
      "Reconstruction: 0.061955, Regularization: 0.009358\n",
      "2019-04-09 20:43:40,765 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 0.075825\n",
      "Reconstruction: 0.065729, Regularization: 0.010096\n",
      "2019-04-09 20:43:40,791 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.063698\n",
      "Reconstruction: 0.055397, Regularization: 0.008301\n",
      "2019-04-09 20:43:40,816 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.062717\n",
      "Reconstruction: 0.054745, Regularization: 0.007972\n",
      "2019-04-09 20:43:40,842 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.081076\n",
      "Reconstruction: 0.070083, Regularization: 0.010993\n",
      "2019-04-09 20:43:40,868 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 0.067297\n",
      "Reconstruction: 0.058739, Regularization: 0.008559\n",
      "2019-04-09 20:43:40,894 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 0.056071\n",
      "Reconstruction: 0.049212, Regularization: 0.006859\n",
      "2019-04-09 20:43:40,931 root         INFO     ====> Epoch: 31 Average loss: 0.0688\n",
      "2019-04-09 20:43:40,952 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.077322\n",
      "Reconstruction: 0.067110, Regularization: 0.010212\n",
      "2019-04-09 20:43:40,978 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.062801\n",
      "Reconstruction: 0.055003, Regularization: 0.007798\n",
      "2019-04-09 20:43:41,005 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.069763\n",
      "Reconstruction: 0.060834, Regularization: 0.008929\n",
      "2019-04-09 20:43:41,032 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.063801\n",
      "Reconstruction: 0.055742, Regularization: 0.008059\n",
      "2019-04-09 20:43:41,059 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.074912\n",
      "Reconstruction: 0.065119, Regularization: 0.009793\n",
      "2019-04-09 20:43:41,086 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 0.055881\n",
      "Reconstruction: 0.049186, Regularization: 0.006695\n",
      "2019-04-09 20:43:41,112 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.061226\n",
      "Reconstruction: 0.053876, Regularization: 0.007349\n",
      "2019-04-09 20:43:41,139 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.067866\n",
      "Reconstruction: 0.059143, Regularization: 0.008723\n",
      "2019-04-09 20:43:41,176 root         INFO     ====> Epoch: 32 Average loss: 0.0680\n",
      "2019-04-09 20:43:41,197 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.072690\n",
      "Reconstruction: 0.063409, Regularization: 0.009281\n",
      "2019-04-09 20:43:41,224 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.061879\n",
      "Reconstruction: 0.054378, Regularization: 0.007501\n",
      "2019-04-09 20:43:41,251 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.070509\n",
      "Reconstruction: 0.061657, Regularization: 0.008853\n",
      "2019-04-09 20:43:41,277 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.064355\n",
      "Reconstruction: 0.056333, Regularization: 0.008022\n",
      "2019-04-09 20:43:41,303 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 0.085023\n",
      "Reconstruction: 0.074206, Regularization: 0.010817\n",
      "2019-04-09 20:43:41,328 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.058561\n",
      "Reconstruction: 0.051766, Regularization: 0.006795\n",
      "2019-04-09 20:43:41,353 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 0.059689\n",
      "Reconstruction: 0.052583, Regularization: 0.007107\n",
      "2019-04-09 20:43:41,378 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.056491\n",
      "Reconstruction: 0.050088, Regularization: 0.006403\n",
      "2019-04-09 20:43:41,415 root         INFO     ====> Epoch: 33 Average loss: 0.0671\n",
      "2019-04-09 20:43:41,436 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.069377\n",
      "Reconstruction: 0.060671, Regularization: 0.008706\n",
      "2019-04-09 20:43:41,463 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.070567\n",
      "Reconstruction: 0.061809, Regularization: 0.008758\n",
      "2019-04-09 20:43:41,489 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.071972\n",
      "Reconstruction: 0.063024, Regularization: 0.008948\n",
      "2019-04-09 20:43:41,515 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.055206\n",
      "Reconstruction: 0.048964, Regularization: 0.006242\n",
      "2019-04-09 20:43:41,541 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.060902\n",
      "Reconstruction: 0.053791, Regularization: 0.007112\n",
      "2019-04-09 20:43:41,567 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.083648\n",
      "Reconstruction: 0.072792, Regularization: 0.010856\n",
      "2019-04-09 20:43:41,593 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.072025\n",
      "Reconstruction: 0.063364, Regularization: 0.008662\n",
      "2019-04-09 20:43:41,619 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 0.053616\n",
      "Reconstruction: 0.047664, Regularization: 0.005952\n",
      "2019-04-09 20:43:41,656 root         INFO     ====> Epoch: 34 Average loss: 0.0662\n",
      "2019-04-09 20:43:41,678 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.048494\n",
      "Reconstruction: 0.043235, Regularization: 0.005259\n",
      "2019-04-09 20:43:41,703 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.068727\n",
      "Reconstruction: 0.060382, Regularization: 0.008345\n",
      "2019-04-09 20:43:41,729 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.072756\n",
      "Reconstruction: 0.063919, Regularization: 0.008837\n",
      "2019-04-09 20:43:41,755 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.064751\n",
      "Reconstruction: 0.057271, Regularization: 0.007480\n",
      "2019-04-09 20:43:41,781 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.061942\n",
      "Reconstruction: 0.054844, Regularization: 0.007098\n",
      "2019-04-09 20:43:41,806 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.056294\n",
      "Reconstruction: 0.049868, Regularization: 0.006427\n",
      "2019-04-09 20:43:41,832 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.052961\n",
      "Reconstruction: 0.047135, Regularization: 0.005826\n",
      "2019-04-09 20:43:41,857 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.058542\n",
      "Reconstruction: 0.051900, Regularization: 0.006642\n",
      "2019-04-09 20:43:41,894 root         INFO     ====> Epoch: 35 Average loss: 0.0655\n",
      "2019-04-09 20:43:41,915 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 0.066353\n",
      "Reconstruction: 0.058684, Regularization: 0.007669\n",
      "2019-04-09 20:43:41,941 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.069297\n",
      "Reconstruction: 0.061162, Regularization: 0.008135\n",
      "2019-04-09 20:43:41,968 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.060746\n",
      "Reconstruction: 0.054017, Regularization: 0.006730\n",
      "2019-04-09 20:43:41,993 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.067819\n",
      "Reconstruction: 0.059983, Regularization: 0.007836\n",
      "2019-04-09 20:43:42,018 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.071285\n",
      "Reconstruction: 0.062965, Regularization: 0.008319\n",
      "2019-04-09 20:43:42,044 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.056232\n",
      "Reconstruction: 0.050158, Regularization: 0.006074\n",
      "2019-04-09 20:43:42,069 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 0.080474\n",
      "Reconstruction: 0.070954, Regularization: 0.009520\n",
      "2019-04-09 20:43:42,095 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.068006\n",
      "Reconstruction: 0.060163, Regularization: 0.007843\n",
      "2019-04-09 20:43:42,132 root         INFO     ====> Epoch: 36 Average loss: 0.0646\n",
      "2019-04-09 20:43:42,153 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.054346\n",
      "Reconstruction: 0.048527, Regularization: 0.005820\n",
      "2019-04-09 20:43:42,181 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.064852\n",
      "Reconstruction: 0.057690, Regularization: 0.007162\n",
      "2019-04-09 20:43:42,207 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.062529\n",
      "Reconstruction: 0.055703, Regularization: 0.006827\n",
      "2019-04-09 20:43:42,234 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 0.073943\n",
      "Reconstruction: 0.065486, Regularization: 0.008458\n",
      "2019-04-09 20:43:42,261 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.054787\n",
      "Reconstruction: 0.049085, Regularization: 0.005702\n",
      "2019-04-09 20:43:42,287 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.071641\n",
      "Reconstruction: 0.063521, Regularization: 0.008120\n",
      "2019-04-09 20:43:42,313 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.045466\n",
      "Reconstruction: 0.041137, Regularization: 0.004329\n",
      "2019-04-09 20:43:42,338 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.068670\n",
      "Reconstruction: 0.060959, Regularization: 0.007711\n",
      "2019-04-09 20:43:42,376 root         INFO     ====> Epoch: 37 Average loss: 0.0640\n",
      "2019-04-09 20:43:42,397 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.051011\n",
      "Reconstruction: 0.045944, Regularization: 0.005067\n",
      "2019-04-09 20:43:42,423 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.063762\n",
      "Reconstruction: 0.056818, Regularization: 0.006944\n",
      "2019-04-09 20:43:42,449 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.063897\n",
      "Reconstruction: 0.056896, Regularization: 0.007000\n",
      "2019-04-09 20:43:42,475 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 0.070673\n",
      "Reconstruction: 0.062928, Regularization: 0.007744\n",
      "2019-04-09 20:43:42,500 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.059932\n",
      "Reconstruction: 0.053633, Regularization: 0.006300\n",
      "2019-04-09 20:43:42,527 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.067339\n",
      "Reconstruction: 0.060006, Regularization: 0.007333\n",
      "2019-04-09 20:43:42,552 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.065198\n",
      "Reconstruction: 0.058232, Regularization: 0.006967\n",
      "2019-04-09 20:43:42,578 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.070051\n",
      "Reconstruction: 0.062498, Regularization: 0.007553\n",
      "2019-04-09 20:43:42,615 root         INFO     ====> Epoch: 38 Average loss: 0.0632\n",
      "2019-04-09 20:43:42,636 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 0.090452\n",
      "Reconstruction: 0.080105, Regularization: 0.010346\n",
      "2019-04-09 20:43:42,662 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.058973\n",
      "Reconstruction: 0.052927, Regularization: 0.006046\n",
      "2019-04-09 20:43:42,688 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.065589\n",
      "Reconstruction: 0.058735, Regularization: 0.006854\n",
      "2019-04-09 20:43:42,713 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.057128\n",
      "Reconstruction: 0.051332, Regularization: 0.005796\n",
      "2019-04-09 20:43:42,739 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.063295\n",
      "Reconstruction: 0.056741, Regularization: 0.006555\n",
      "2019-04-09 20:43:42,764 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.079683\n",
      "Reconstruction: 0.070751, Regularization: 0.008932\n",
      "2019-04-09 20:43:42,790 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.060244\n",
      "Reconstruction: 0.054092, Regularization: 0.006152\n",
      "2019-04-09 20:43:42,816 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.065968\n",
      "Reconstruction: 0.059082, Regularization: 0.006887\n",
      "2019-04-09 20:43:42,853 root         INFO     ====> Epoch: 39 Average loss: 0.0624\n",
      "2019-04-09 20:43:42,874 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.059678\n",
      "Reconstruction: 0.053709, Regularization: 0.005969\n",
      "2019-04-09 20:43:42,900 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.071823\n",
      "Reconstruction: 0.064337, Regularization: 0.007486\n",
      "2019-04-09 20:43:42,927 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.064177\n",
      "Reconstruction: 0.057710, Regularization: 0.006467\n",
      "2019-04-09 20:43:42,953 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.066140\n",
      "Reconstruction: 0.059295, Regularization: 0.006845\n",
      "2019-04-09 20:43:42,979 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.061348\n",
      "Reconstruction: 0.055147, Regularization: 0.006201\n",
      "2019-04-09 20:43:43,004 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 0.061322\n",
      "Reconstruction: 0.055279, Regularization: 0.006043\n",
      "2019-04-09 20:43:43,029 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.069433\n",
      "Reconstruction: 0.062284, Regularization: 0.007149\n",
      "2019-04-09 20:43:43,055 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.059969\n",
      "Reconstruction: 0.054143, Regularization: 0.005826\n",
      "2019-04-09 20:43:43,091 root         INFO     ====> Epoch: 40 Average loss: 0.0618\n",
      "2019-04-09 20:43:43,112 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 0.047497\n",
      "Reconstruction: 0.043262, Regularization: 0.004235\n",
      "2019-04-09 20:43:43,139 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.058776\n",
      "Reconstruction: 0.053119, Regularization: 0.005657\n",
      "2019-04-09 20:43:43,166 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 0.064783\n",
      "Reconstruction: 0.058232, Regularization: 0.006551\n",
      "2019-04-09 20:43:43,192 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.061309\n",
      "Reconstruction: 0.055412, Regularization: 0.005897\n",
      "2019-04-09 20:43:43,219 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.065847\n",
      "Reconstruction: 0.059309, Regularization: 0.006538\n",
      "2019-04-09 20:43:43,246 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 0.063735\n",
      "Reconstruction: 0.057548, Regularization: 0.006187\n",
      "2019-04-09 20:43:43,272 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.064547\n",
      "Reconstruction: 0.058266, Regularization: 0.006281\n",
      "2019-04-09 20:43:43,299 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.052329\n",
      "Reconstruction: 0.047571, Regularization: 0.004757\n",
      "2019-04-09 20:43:43,337 root         INFO     ====> Epoch: 41 Average loss: 0.0612\n",
      "2019-04-09 20:43:43,358 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.045960\n",
      "Reconstruction: 0.041991, Regularization: 0.003969\n",
      "2019-04-09 20:43:43,384 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.061534\n",
      "Reconstruction: 0.055727, Regularization: 0.005808\n",
      "2019-04-09 20:43:43,409 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.065140\n",
      "Reconstruction: 0.058867, Regularization: 0.006273\n",
      "2019-04-09 20:43:43,435 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 0.063920\n",
      "Reconstruction: 0.057837, Regularization: 0.006082\n",
      "2019-04-09 20:43:43,461 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.054961\n",
      "Reconstruction: 0.050072, Regularization: 0.004889\n",
      "2019-04-09 20:43:43,486 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.058104\n",
      "Reconstruction: 0.052753, Regularization: 0.005351\n",
      "2019-04-09 20:43:43,512 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.072500\n",
      "Reconstruction: 0.065451, Regularization: 0.007049\n",
      "2019-04-09 20:43:43,537 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.053045\n",
      "Reconstruction: 0.048386, Regularization: 0.004660\n",
      "2019-04-09 20:43:43,574 root         INFO     ====> Epoch: 42 Average loss: 0.0605\n",
      "2019-04-09 20:43:43,595 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.058221\n",
      "Reconstruction: 0.052922, Regularization: 0.005299\n",
      "2019-04-09 20:43:43,621 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.055681\n",
      "Reconstruction: 0.050761, Regularization: 0.004920\n",
      "2019-04-09 20:43:43,647 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.045420\n",
      "Reconstruction: 0.041728, Regularization: 0.003692\n",
      "2019-04-09 20:43:43,672 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.049860\n",
      "Reconstruction: 0.045660, Regularization: 0.004200\n",
      "2019-04-09 20:43:43,698 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.058389\n",
      "Reconstruction: 0.053179, Regularization: 0.005210\n",
      "2019-04-09 20:43:43,724 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.074865\n",
      "Reconstruction: 0.067758, Regularization: 0.007107\n",
      "2019-04-09 20:43:43,749 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.067882\n",
      "Reconstruction: 0.061602, Regularization: 0.006280\n",
      "2019-04-09 20:43:43,775 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.054528\n",
      "Reconstruction: 0.049824, Regularization: 0.004705\n",
      "2019-04-09 20:43:43,812 root         INFO     ====> Epoch: 43 Average loss: 0.0599\n",
      "2019-04-09 20:43:43,832 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.054426\n",
      "Reconstruction: 0.049784, Regularization: 0.004642\n",
      "2019-04-09 20:43:43,860 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.054018\n",
      "Reconstruction: 0.049470, Regularization: 0.004548\n",
      "2019-04-09 20:43:43,886 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.056417\n",
      "Reconstruction: 0.051582, Regularization: 0.004835\n",
      "2019-04-09 20:43:43,912 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.053614\n",
      "Reconstruction: 0.049151, Regularization: 0.004462\n",
      "2019-04-09 20:43:43,939 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.057950\n",
      "Reconstruction: 0.053024, Regularization: 0.004926\n",
      "2019-04-09 20:43:43,965 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.063119\n",
      "Reconstruction: 0.057595, Regularization: 0.005524\n",
      "2019-04-09 20:43:43,991 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.047027\n",
      "Reconstruction: 0.043364, Regularization: 0.003663\n",
      "2019-04-09 20:43:44,018 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.064757\n",
      "Reconstruction: 0.059040, Regularization: 0.005716\n",
      "2019-04-09 20:43:44,055 root         INFO     ====> Epoch: 44 Average loss: 0.0594\n",
      "2019-04-09 20:43:44,076 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.060616\n",
      "Reconstruction: 0.055475, Regularization: 0.005141\n",
      "2019-04-09 20:43:44,101 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 0.064123\n",
      "Reconstruction: 0.058580, Regularization: 0.005543\n",
      "2019-04-09 20:43:44,127 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.053456\n",
      "Reconstruction: 0.049108, Regularization: 0.004348\n",
      "2019-04-09 20:43:44,152 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.061925\n",
      "Reconstruction: 0.056703, Regularization: 0.005222\n",
      "2019-04-09 20:43:44,177 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.055988\n",
      "Reconstruction: 0.051420, Regularization: 0.004568\n",
      "2019-04-09 20:43:44,202 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.068401\n",
      "Reconstruction: 0.062514, Regularization: 0.005886\n",
      "2019-04-09 20:43:44,228 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.053559\n",
      "Reconstruction: 0.049279, Regularization: 0.004279\n",
      "2019-04-09 20:43:44,253 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.053427\n",
      "Reconstruction: 0.049194, Regularization: 0.004233\n",
      "2019-04-09 20:43:44,289 root         INFO     ====> Epoch: 45 Average loss: 0.0589\n",
      "2019-04-09 20:43:44,311 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.059880\n",
      "Reconstruction: 0.054916, Regularization: 0.004964\n",
      "2019-04-09 20:43:44,338 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.056919\n",
      "Reconstruction: 0.052352, Regularization: 0.004567\n",
      "2019-04-09 20:43:44,364 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.072458\n",
      "Reconstruction: 0.066235, Regularization: 0.006223\n",
      "2019-04-09 20:43:44,390 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.047709\n",
      "Reconstruction: 0.044167, Regularization: 0.003542\n",
      "2019-04-09 20:43:44,415 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.066003\n",
      "Reconstruction: 0.060533, Regularization: 0.005469\n",
      "2019-04-09 20:43:44,440 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.066694\n",
      "Reconstruction: 0.061149, Regularization: 0.005545\n",
      "2019-04-09 20:43:44,465 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.058899\n",
      "Reconstruction: 0.054217, Regularization: 0.004682\n",
      "2019-04-09 20:43:44,490 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.058710\n",
      "Reconstruction: 0.054059, Regularization: 0.004650\n",
      "2019-04-09 20:43:44,529 root         INFO     ====> Epoch: 46 Average loss: 0.0583\n",
      "2019-04-09 20:43:44,550 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.055349\n",
      "Reconstruction: 0.051087, Regularization: 0.004262\n",
      "2019-04-09 20:43:44,576 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.066683\n",
      "Reconstruction: 0.061253, Regularization: 0.005431\n",
      "2019-04-09 20:43:44,602 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.058080\n",
      "Reconstruction: 0.053559, Regularization: 0.004520\n",
      "2019-04-09 20:43:44,627 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.056644\n",
      "Reconstruction: 0.052305, Regularization: 0.004338\n",
      "2019-04-09 20:43:44,652 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.046933\n",
      "Reconstruction: 0.043614, Regularization: 0.003319\n",
      "2019-04-09 20:43:44,677 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.047859\n",
      "Reconstruction: 0.044443, Regularization: 0.003416\n",
      "2019-04-09 20:43:44,702 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.068787\n",
      "Reconstruction: 0.063293, Regularization: 0.005494\n",
      "2019-04-09 20:43:44,727 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.079344\n",
      "Reconstruction: 0.072788, Regularization: 0.006556\n",
      "2019-04-09 20:43:44,764 root         INFO     ====> Epoch: 47 Average loss: 0.0578\n",
      "2019-04-09 20:43:44,785 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.056035\n",
      "Reconstruction: 0.051855, Regularization: 0.004180\n",
      "2019-04-09 20:43:44,811 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.056302\n",
      "Reconstruction: 0.052113, Regularization: 0.004190\n",
      "2019-04-09 20:43:44,837 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.046374\n",
      "Reconstruction: 0.043180, Regularization: 0.003194\n",
      "2019-04-09 20:43:44,863 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.056586\n",
      "Reconstruction: 0.052427, Regularization: 0.004159\n",
      "2019-04-09 20:43:44,889 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.062084\n",
      "Reconstruction: 0.057394, Regularization: 0.004690\n",
      "2019-04-09 20:43:44,916 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.059610\n",
      "Reconstruction: 0.055176, Regularization: 0.004434\n",
      "2019-04-09 20:43:44,942 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.051389\n",
      "Reconstruction: 0.047771, Regularization: 0.003617\n",
      "2019-04-09 20:43:44,968 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.053138\n",
      "Reconstruction: 0.049385, Regularization: 0.003753\n",
      "2019-04-09 20:43:45,006 root         INFO     ====> Epoch: 48 Average loss: 0.0574\n",
      "2019-04-09 20:43:45,027 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.067138\n",
      "Reconstruction: 0.062039, Regularization: 0.005099\n",
      "2019-04-09 20:43:45,053 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.055498\n",
      "Reconstruction: 0.051548, Regularization: 0.003951\n",
      "2019-04-09 20:43:45,080 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.056766\n",
      "Reconstruction: 0.052710, Regularization: 0.004056\n",
      "2019-04-09 20:43:45,106 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.055617\n",
      "Reconstruction: 0.051690, Regularization: 0.003928\n",
      "2019-04-09 20:43:45,132 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.054334\n",
      "Reconstruction: 0.050554, Regularization: 0.003780\n",
      "2019-04-09 20:43:45,158 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.063206\n",
      "Reconstruction: 0.058607, Regularization: 0.004599\n",
      "2019-04-09 20:43:45,185 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.075141\n",
      "Reconstruction: 0.069453, Regularization: 0.005688\n",
      "2019-04-09 20:43:45,211 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.070191\n",
      "Reconstruction: 0.064984, Regularization: 0.005207\n",
      "2019-04-09 20:43:45,249 root         INFO     ====> Epoch: 49 Average loss: 0.0569\n",
      "2019-04-09 20:43:45,270 root         INFO     Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 0.050372\n",
      "Reconstruction: 0.047031, Regularization: 0.003341\n",
      "2019-04-09 20:43:45,296 root         INFO     Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 0.063141\n",
      "Reconstruction: 0.058640, Regularization: 0.004500\n",
      "2019-04-09 20:43:45,322 root         INFO     Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 0.049053\n",
      "Reconstruction: 0.045870, Regularization: 0.003183\n",
      "2019-04-09 20:43:45,349 root         INFO     Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 0.058644\n",
      "Reconstruction: 0.054600, Regularization: 0.004044\n",
      "2019-04-09 20:43:45,375 root         INFO     Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 0.051528\n",
      "Reconstruction: 0.048151, Regularization: 0.003377\n",
      "2019-04-09 20:43:45,401 root         INFO     Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 0.061450\n",
      "Reconstruction: 0.057194, Regularization: 0.004257\n",
      "2019-04-09 20:43:45,427 root         INFO     Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 0.048747\n",
      "Reconstruction: 0.045653, Regularization: 0.003093\n",
      "2019-04-09 20:43:45,453 root         INFO     Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 0.056794\n",
      "Reconstruction: 0.053000, Regularization: 0.003794\n",
      "2019-04-09 20:43:45,491 root         INFO     ====> Epoch: 50 Average loss: 0.0565\n",
      "2019-04-09 20:43:45,512 root         INFO     Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 0.048808\n",
      "Reconstruction: 0.045740, Regularization: 0.003067\n",
      "2019-04-09 20:43:45,538 root         INFO     Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 0.059365\n",
      "Reconstruction: 0.055374, Regularization: 0.003991\n",
      "2019-04-09 20:43:45,565 root         INFO     Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 0.055258\n",
      "Reconstruction: 0.051650, Regularization: 0.003608\n",
      "2019-04-09 20:43:45,590 root         INFO     Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 0.059693\n",
      "Reconstruction: 0.055709, Regularization: 0.003984\n",
      "2019-04-09 20:43:45,615 root         INFO     Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 0.053374\n",
      "Reconstruction: 0.049972, Regularization: 0.003402\n",
      "2019-04-09 20:43:45,640 root         INFO     Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 0.044619\n",
      "Reconstruction: 0.041995, Regularization: 0.002624\n",
      "2019-04-09 20:43:45,665 root         INFO     Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 0.054023\n",
      "Reconstruction: 0.050602, Regularization: 0.003421\n",
      "2019-04-09 20:43:45,691 root         INFO     Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 0.051018\n",
      "Reconstruction: 0.047868, Regularization: 0.003150\n",
      "2019-04-09 20:43:45,727 root         INFO     ====> Epoch: 51 Average loss: 0.0561\n",
      "2019-04-09 20:43:45,748 root         INFO     Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 0.049482\n",
      "Reconstruction: 0.046480, Regularization: 0.003002\n",
      "2019-04-09 20:43:45,775 root         INFO     Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 0.054399\n",
      "Reconstruction: 0.050997, Regularization: 0.003402\n",
      "2019-04-09 20:43:45,802 root         INFO     Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 0.052775\n",
      "Reconstruction: 0.049535, Regularization: 0.003240\n",
      "2019-04-09 20:43:45,829 root         INFO     Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 0.051920\n",
      "Reconstruction: 0.048759, Regularization: 0.003161\n",
      "2019-04-09 20:43:45,855 root         INFO     Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 0.057379\n",
      "Reconstruction: 0.053786, Regularization: 0.003593\n",
      "2019-04-09 20:43:45,882 root         INFO     Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 0.050311\n",
      "Reconstruction: 0.047316, Regularization: 0.002995\n",
      "2019-04-09 20:43:45,908 root         INFO     Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 0.061824\n",
      "Reconstruction: 0.057891, Regularization: 0.003932\n",
      "2019-04-09 20:43:45,935 root         INFO     Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 0.060706\n",
      "Reconstruction: 0.056891, Regularization: 0.003814\n",
      "2019-04-09 20:43:45,972 root         INFO     ====> Epoch: 52 Average loss: 0.0557\n",
      "2019-04-09 20:43:45,994 root         INFO     Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 0.049598\n",
      "Reconstruction: 0.046717, Regularization: 0.002880\n",
      "2019-04-09 20:43:46,020 root         INFO     Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 0.052218\n",
      "Reconstruction: 0.049139, Regularization: 0.003079\n",
      "2019-04-09 20:43:46,047 root         INFO     Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 0.071717\n",
      "Reconstruction: 0.067064, Regularization: 0.004653\n",
      "2019-04-09 20:43:46,074 root         INFO     Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 0.041941\n",
      "Reconstruction: 0.039723, Regularization: 0.002218\n",
      "2019-04-09 20:43:46,101 root         INFO     Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 0.072621\n",
      "Reconstruction: 0.067939, Regularization: 0.004682\n",
      "2019-04-09 20:43:46,128 root         INFO     Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 0.055380\n",
      "Reconstruction: 0.052123, Regularization: 0.003257\n",
      "2019-04-09 20:43:46,155 root         INFO     Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 0.055609\n",
      "Reconstruction: 0.052324, Regularization: 0.003285\n",
      "2019-04-09 20:43:46,181 root         INFO     Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 0.065454\n",
      "Reconstruction: 0.061427, Regularization: 0.004027\n",
      "2019-04-09 20:43:46,219 root         INFO     ====> Epoch: 53 Average loss: 0.0554\n",
      "2019-04-09 20:43:46,240 root         INFO     Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 0.055431\n",
      "Reconstruction: 0.052214, Regularization: 0.003217\n",
      "2019-04-09 20:43:46,266 root         INFO     Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 0.068052\n",
      "Reconstruction: 0.063869, Regularization: 0.004183\n",
      "2019-04-09 20:43:46,293 root         INFO     Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 0.061263\n",
      "Reconstruction: 0.057603, Regularization: 0.003660\n",
      "2019-04-09 20:43:46,320 root         INFO     Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 0.052028\n",
      "Reconstruction: 0.049131, Regularization: 0.002897\n",
      "2019-04-09 20:43:46,347 root         INFO     Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 0.052316\n",
      "Reconstruction: 0.049392, Regularization: 0.002925\n",
      "2019-04-09 20:43:46,373 root         INFO     Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 0.061854\n",
      "Reconstruction: 0.058234, Regularization: 0.003620\n",
      "2019-04-09 20:43:46,400 root         INFO     Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 0.051099\n",
      "Reconstruction: 0.048304, Regularization: 0.002795\n",
      "2019-04-09 20:43:46,427 root         INFO     Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 0.037729\n",
      "Reconstruction: 0.035963, Regularization: 0.001767\n",
      "2019-04-09 20:43:46,465 root         INFO     ====> Epoch: 54 Average loss: 0.0551\n",
      "2019-04-09 20:43:46,486 root         INFO     Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 0.051048\n",
      "Reconstruction: 0.048277, Regularization: 0.002771\n",
      "2019-04-09 20:43:46,513 root         INFO     Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 0.050785\n",
      "Reconstruction: 0.048059, Regularization: 0.002726\n",
      "2019-04-09 20:43:46,539 root         INFO     Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 0.051605\n",
      "Reconstruction: 0.048847, Regularization: 0.002758\n",
      "2019-04-09 20:43:46,566 root         INFO     Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 0.052298\n",
      "Reconstruction: 0.049462, Regularization: 0.002835\n",
      "2019-04-09 20:43:46,593 root         INFO     Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 0.051684\n",
      "Reconstruction: 0.048948, Regularization: 0.002736\n",
      "2019-04-09 20:43:46,620 root         INFO     Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 0.056778\n",
      "Reconstruction: 0.053666, Regularization: 0.003112\n",
      "2019-04-09 20:43:46,646 root         INFO     Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 0.046659\n",
      "Reconstruction: 0.044320, Regularization: 0.002339\n",
      "2019-04-09 20:43:46,671 root         INFO     Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 0.053732\n",
      "Reconstruction: 0.050887, Regularization: 0.002844\n",
      "2019-04-09 20:43:46,707 root         INFO     ====> Epoch: 55 Average loss: 0.0547\n",
      "2019-04-09 20:43:46,728 root         INFO     Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 0.054211\n",
      "Reconstruction: 0.051328, Regularization: 0.002883\n",
      "2019-04-09 20:43:46,756 root         INFO     Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 0.052805\n",
      "Reconstruction: 0.050053, Regularization: 0.002752\n",
      "2019-04-09 20:43:46,783 root         INFO     Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 0.050231\n",
      "Reconstruction: 0.047663, Regularization: 0.002568\n",
      "2019-04-09 20:43:46,809 root         INFO     Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 0.047105\n",
      "Reconstruction: 0.044805, Regularization: 0.002300\n",
      "2019-04-09 20:43:46,834 root         INFO     Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 0.062646\n",
      "Reconstruction: 0.059247, Regularization: 0.003399\n",
      "2019-04-09 20:43:46,860 root         INFO     Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 0.056431\n",
      "Reconstruction: 0.053482, Regularization: 0.002949\n",
      "2019-04-09 20:43:46,887 root         INFO     Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 0.051430\n",
      "Reconstruction: 0.048849, Regularization: 0.002581\n",
      "2019-04-09 20:43:46,913 root         INFO     Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 0.057904\n",
      "Reconstruction: 0.054912, Regularization: 0.002991\n",
      "2019-04-09 20:43:46,950 root         INFO     ====> Epoch: 56 Average loss: 0.0544\n",
      "2019-04-09 20:43:46,971 root         INFO     Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 0.046366\n",
      "Reconstruction: 0.044138, Regularization: 0.002228\n",
      "2019-04-09 20:43:46,999 root         INFO     Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 0.062828\n",
      "Reconstruction: 0.059507, Regularization: 0.003321\n",
      "2019-04-09 20:43:47,026 root         INFO     Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 0.058531\n",
      "Reconstruction: 0.055512, Regularization: 0.003019\n",
      "2019-04-09 20:43:47,053 root         INFO     Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 0.046734\n",
      "Reconstruction: 0.044547, Regularization: 0.002186\n",
      "2019-04-09 20:43:47,080 root         INFO     Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 0.045510\n",
      "Reconstruction: 0.043414, Regularization: 0.002095\n",
      "2019-04-09 20:43:47,106 root         INFO     Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 0.056996\n",
      "Reconstruction: 0.054125, Regularization: 0.002870\n",
      "2019-04-09 20:43:47,132 root         INFO     Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 0.052582\n",
      "Reconstruction: 0.050048, Regularization: 0.002534\n",
      "2019-04-09 20:43:47,158 root         INFO     Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 0.056697\n",
      "Reconstruction: 0.053889, Regularization: 0.002808\n",
      "2019-04-09 20:43:47,196 root         INFO     ====> Epoch: 57 Average loss: 0.0542\n",
      "2019-04-09 20:43:47,217 root         INFO     Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 0.054029\n",
      "Reconstruction: 0.051430, Regularization: 0.002599\n",
      "2019-04-09 20:43:47,243 root         INFO     Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 0.062129\n",
      "Reconstruction: 0.059033, Regularization: 0.003096\n",
      "2019-04-09 20:43:47,270 root         INFO     Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 0.056254\n",
      "Reconstruction: 0.053548, Regularization: 0.002706\n",
      "2019-04-09 20:43:47,296 root         INFO     Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 0.044978\n",
      "Reconstruction: 0.042982, Regularization: 0.001996\n",
      "2019-04-09 20:43:47,322 root         INFO     Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 0.048597\n",
      "Reconstruction: 0.046384, Regularization: 0.002213\n",
      "2019-04-09 20:43:47,348 root         INFO     Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 0.048673\n",
      "Reconstruction: 0.046483, Regularization: 0.002191\n",
      "2019-04-09 20:43:47,375 root         INFO     Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 0.069919\n",
      "Reconstruction: 0.066397, Regularization: 0.003522\n",
      "2019-04-09 20:43:47,402 root         INFO     Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 0.046433\n",
      "Reconstruction: 0.044417, Regularization: 0.002016\n",
      "2019-04-09 20:43:47,441 root         INFO     ====> Epoch: 58 Average loss: 0.0539\n",
      "2019-04-09 20:43:47,462 root         INFO     Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 0.063904\n",
      "Reconstruction: 0.060828, Regularization: 0.003076\n",
      "2019-04-09 20:43:47,489 root         INFO     Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 0.052466\n",
      "Reconstruction: 0.050101, Regularization: 0.002365\n",
      "2019-04-09 20:43:47,515 root         INFO     Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 0.046753\n",
      "Reconstruction: 0.044713, Regularization: 0.002040\n",
      "2019-04-09 20:43:47,542 root         INFO     Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 0.047720\n",
      "Reconstruction: 0.045646, Regularization: 0.002073\n",
      "2019-04-09 20:43:47,568 root         INFO     Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 0.049590\n",
      "Reconstruction: 0.047437, Regularization: 0.002153\n",
      "2019-04-09 20:43:47,594 root         INFO     Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 0.058887\n",
      "Reconstruction: 0.056146, Regularization: 0.002741\n",
      "2019-04-09 20:43:47,621 root         INFO     Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 0.062763\n",
      "Reconstruction: 0.059822, Regularization: 0.002942\n",
      "2019-04-09 20:43:47,647 root         INFO     Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 0.065065\n",
      "Reconstruction: 0.062020, Regularization: 0.003045\n",
      "2019-04-09 20:43:47,684 root         INFO     ====> Epoch: 59 Average loss: 0.0537\n",
      "2019-04-09 20:43:47,706 root         INFO     Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 0.048226\n",
      "Reconstruction: 0.046181, Regularization: 0.002044\n",
      "2019-04-09 20:43:47,733 root         INFO     Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 0.056016\n",
      "Reconstruction: 0.053485, Regularization: 0.002531\n",
      "2019-04-09 20:43:47,760 root         INFO     Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 0.053546\n",
      "Reconstruction: 0.051237, Regularization: 0.002309\n",
      "2019-04-09 20:43:47,787 root         INFO     Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 0.051969\n",
      "Reconstruction: 0.049722, Regularization: 0.002247\n",
      "2019-04-09 20:43:47,814 root         INFO     Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 0.054142\n",
      "Reconstruction: 0.051799, Regularization: 0.002343\n",
      "2019-04-09 20:43:47,840 root         INFO     Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 0.053508\n",
      "Reconstruction: 0.051230, Regularization: 0.002277\n",
      "2019-04-09 20:43:47,867 root         INFO     Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 0.052886\n",
      "Reconstruction: 0.050637, Regularization: 0.002248\n",
      "2019-04-09 20:43:47,894 root         INFO     Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 0.065839\n",
      "Reconstruction: 0.062872, Regularization: 0.002968\n",
      "2019-04-09 20:43:47,932 root         INFO     ====> Epoch: 60 Average loss: 0.0535\n",
      "2019-04-09 20:43:47,953 root         INFO     Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 0.056912\n",
      "Reconstruction: 0.054470, Regularization: 0.002441\n",
      "2019-04-09 20:43:47,980 root         INFO     Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 0.047319\n",
      "Reconstruction: 0.045399, Regularization: 0.001920\n",
      "2019-04-09 20:43:48,006 root         INFO     Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 0.047183\n",
      "Reconstruction: 0.045322, Regularization: 0.001861\n",
      "2019-04-09 20:43:48,032 root         INFO     Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 0.044753\n",
      "Reconstruction: 0.043029, Regularization: 0.001724\n",
      "2019-04-09 20:43:48,059 root         INFO     Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 0.048798\n",
      "Reconstruction: 0.046882, Regularization: 0.001915\n",
      "2019-04-09 20:43:48,086 root         INFO     Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 0.055763\n",
      "Reconstruction: 0.053434, Regularization: 0.002328\n",
      "2019-04-09 20:43:48,112 root         INFO     Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 0.048462\n",
      "Reconstruction: 0.046553, Regularization: 0.001909\n",
      "2019-04-09 20:43:48,139 root         INFO     Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 0.048263\n",
      "Reconstruction: 0.046383, Regularization: 0.001880\n",
      "2019-04-09 20:43:48,177 root         INFO     ====> Epoch: 61 Average loss: 0.0532\n",
      "2019-04-09 20:43:48,198 root         INFO     Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 0.055181\n",
      "Reconstruction: 0.052864, Regularization: 0.002316\n",
      "2019-04-09 20:43:48,225 root         INFO     Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 0.057458\n",
      "Reconstruction: 0.055150, Regularization: 0.002308\n",
      "2019-04-09 20:43:48,252 root         INFO     Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 0.059065\n",
      "Reconstruction: 0.056618, Regularization: 0.002447\n",
      "2019-04-09 20:43:48,279 root         INFO     Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 0.050519\n",
      "Reconstruction: 0.048565, Regularization: 0.001955\n",
      "2019-04-09 20:43:48,306 root         INFO     Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 0.057260\n",
      "Reconstruction: 0.054907, Regularization: 0.002353\n",
      "2019-04-09 20:43:48,333 root         INFO     Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 0.057065\n",
      "Reconstruction: 0.054727, Regularization: 0.002337\n",
      "2019-04-09 20:43:48,360 root         INFO     Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 0.056989\n",
      "Reconstruction: 0.054739, Regularization: 0.002250\n",
      "2019-04-09 20:43:48,387 root         INFO     Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 0.045803\n",
      "Reconstruction: 0.044101, Regularization: 0.001702\n",
      "2019-04-09 20:43:48,425 root         INFO     ====> Epoch: 62 Average loss: 0.0530\n",
      "2019-04-09 20:43:48,447 root         INFO     Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 0.043740\n",
      "Reconstruction: 0.042168, Regularization: 0.001573\n",
      "2019-04-09 20:43:48,473 root         INFO     Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 0.048997\n",
      "Reconstruction: 0.047157, Regularization: 0.001841\n",
      "2019-04-09 20:43:48,499 root         INFO     Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 0.052885\n",
      "Reconstruction: 0.050857, Regularization: 0.002028\n",
      "2019-04-09 20:43:48,526 root         INFO     Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 0.043053\n",
      "Reconstruction: 0.041543, Regularization: 0.001510\n",
      "2019-04-09 20:43:48,552 root         INFO     Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 0.049975\n",
      "Reconstruction: 0.048133, Regularization: 0.001842\n",
      "2019-04-09 20:43:48,578 root         INFO     Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 0.059731\n",
      "Reconstruction: 0.057410, Regularization: 0.002320\n",
      "2019-04-09 20:43:48,603 root         INFO     Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 0.042904\n",
      "Reconstruction: 0.041418, Regularization: 0.001486\n",
      "2019-04-09 20:43:48,629 root         INFO     Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 0.054529\n",
      "Reconstruction: 0.052490, Regularization: 0.002039\n",
      "2019-04-09 20:43:48,666 root         INFO     ====> Epoch: 63 Average loss: 0.0528\n",
      "2019-04-09 20:43:48,687 root         INFO     Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 0.047319\n",
      "Reconstruction: 0.045657, Regularization: 0.001662\n",
      "2019-04-09 20:43:48,713 root         INFO     Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 0.045828\n",
      "Reconstruction: 0.044263, Regularization: 0.001565\n",
      "2019-04-09 20:43:48,739 root         INFO     Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 0.046637\n",
      "Reconstruction: 0.044999, Regularization: 0.001639\n",
      "2019-04-09 20:43:48,765 root         INFO     Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 0.049720\n",
      "Reconstruction: 0.047962, Regularization: 0.001758\n",
      "2019-04-09 20:43:48,791 root         INFO     Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 0.058515\n",
      "Reconstruction: 0.056372, Regularization: 0.002143\n",
      "2019-04-09 20:43:48,817 root         INFO     Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 0.057418\n",
      "Reconstruction: 0.055277, Regularization: 0.002141\n",
      "2019-04-09 20:43:48,843 root         INFO     Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 0.043719\n",
      "Reconstruction: 0.042278, Regularization: 0.001441\n",
      "2019-04-09 20:43:48,869 root         INFO     Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 0.052562\n",
      "Reconstruction: 0.050711, Regularization: 0.001851\n",
      "2019-04-09 20:43:48,906 root         INFO     ====> Epoch: 64 Average loss: 0.0527\n",
      "2019-04-09 20:43:48,927 root         INFO     Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 0.051717\n",
      "Reconstruction: 0.049928, Regularization: 0.001789\n",
      "2019-04-09 20:43:48,953 root         INFO     Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 0.040297\n",
      "Reconstruction: 0.039023, Regularization: 0.001275\n",
      "2019-04-09 20:43:48,979 root         INFO     Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 0.047233\n",
      "Reconstruction: 0.045578, Regularization: 0.001655\n",
      "2019-04-09 20:43:49,007 root         INFO     Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 0.050118\n",
      "Reconstruction: 0.048356, Regularization: 0.001762\n",
      "2019-04-09 20:43:49,035 root         INFO     Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 0.045248\n",
      "Reconstruction: 0.043771, Regularization: 0.001477\n",
      "2019-04-09 20:43:49,062 root         INFO     Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 0.055999\n",
      "Reconstruction: 0.054079, Regularization: 0.001920\n",
      "2019-04-09 20:43:49,090 root         INFO     Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 0.051064\n",
      "Reconstruction: 0.049334, Regularization: 0.001731\n",
      "2019-04-09 20:43:49,118 root         INFO     Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 0.048251\n",
      "Reconstruction: 0.046634, Regularization: 0.001617\n",
      "2019-04-09 20:43:49,158 root         INFO     ====> Epoch: 65 Average loss: 0.0525\n",
      "2019-04-09 20:43:49,179 root         INFO     Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 0.041640\n",
      "Reconstruction: 0.040349, Regularization: 0.001291\n",
      "2019-04-09 20:43:49,207 root         INFO     Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 0.049019\n",
      "Reconstruction: 0.047369, Regularization: 0.001649\n",
      "2019-04-09 20:43:49,234 root         INFO     Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 0.051055\n",
      "Reconstruction: 0.049380, Regularization: 0.001676\n",
      "2019-04-09 20:43:49,262 root         INFO     Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 0.049837\n",
      "Reconstruction: 0.048222, Regularization: 0.001616\n",
      "2019-04-09 20:43:49,289 root         INFO     Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 0.049056\n",
      "Reconstruction: 0.047420, Regularization: 0.001636\n",
      "2019-04-09 20:43:49,316 root         INFO     Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 0.058221\n",
      "Reconstruction: 0.056234, Regularization: 0.001987\n",
      "2019-04-09 20:43:49,343 root         INFO     Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 0.052917\n",
      "Reconstruction: 0.051177, Regularization: 0.001740\n",
      "2019-04-09 20:43:49,370 root         INFO     Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 0.055097\n",
      "Reconstruction: 0.053199, Regularization: 0.001898\n",
      "2019-04-09 20:43:49,408 root         INFO     ====> Epoch: 66 Average loss: 0.0523\n",
      "2019-04-09 20:43:49,429 root         INFO     Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 0.046257\n",
      "Reconstruction: 0.044801, Regularization: 0.001456\n",
      "2019-04-09 20:43:49,457 root         INFO     Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 0.045589\n",
      "Reconstruction: 0.044191, Regularization: 0.001398\n",
      "2019-04-09 20:43:49,482 root         INFO     Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 0.040865\n",
      "Reconstruction: 0.039679, Regularization: 0.001186\n",
      "2019-04-09 20:43:49,509 root         INFO     Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 0.042005\n",
      "Reconstruction: 0.040790, Regularization: 0.001215\n",
      "2019-04-09 20:43:49,536 root         INFO     Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 0.057186\n",
      "Reconstruction: 0.055280, Regularization: 0.001906\n",
      "2019-04-09 20:43:49,563 root         INFO     Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 0.068225\n",
      "Reconstruction: 0.065869, Regularization: 0.002356\n",
      "2019-04-09 20:43:49,590 root         INFO     Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 0.056139\n",
      "Reconstruction: 0.054320, Regularization: 0.001819\n",
      "2019-04-09 20:43:49,617 root         INFO     Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 0.053658\n",
      "Reconstruction: 0.051963, Regularization: 0.001695\n",
      "2019-04-09 20:43:49,654 root         INFO     ====> Epoch: 67 Average loss: 0.0522\n",
      "2019-04-09 20:43:49,676 root         INFO     Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 0.056913\n",
      "Reconstruction: 0.055042, Regularization: 0.001871\n",
      "2019-04-09 20:43:49,703 root         INFO     Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 0.055225\n",
      "Reconstruction: 0.053478, Regularization: 0.001747\n",
      "2019-04-09 20:43:49,730 root         INFO     Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 0.046614\n",
      "Reconstruction: 0.045206, Regularization: 0.001408\n",
      "2019-04-09 20:43:49,757 root         INFO     Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 0.052850\n",
      "Reconstruction: 0.051120, Regularization: 0.001731\n",
      "2019-04-09 20:43:49,783 root         INFO     Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 0.052155\n",
      "Reconstruction: 0.050572, Regularization: 0.001583\n",
      "2019-04-09 20:43:49,810 root         INFO     Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 0.050291\n",
      "Reconstruction: 0.048735, Regularization: 0.001557\n",
      "2019-04-09 20:43:49,837 root         INFO     Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 0.053294\n",
      "Reconstruction: 0.051664, Regularization: 0.001630\n",
      "2019-04-09 20:43:49,864 root         INFO     Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 0.047607\n",
      "Reconstruction: 0.046171, Regularization: 0.001436\n",
      "2019-04-09 20:43:49,902 root         INFO     ====> Epoch: 68 Average loss: 0.0521\n",
      "2019-04-09 20:43:49,923 root         INFO     Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 0.046911\n",
      "Reconstruction: 0.045559, Regularization: 0.001352\n",
      "2019-04-09 20:43:49,950 root         INFO     Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 0.047134\n",
      "Reconstruction: 0.045741, Regularization: 0.001392\n",
      "2019-04-09 20:43:49,977 root         INFO     Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 0.048375\n",
      "Reconstruction: 0.046960, Regularization: 0.001415\n",
      "2019-04-09 20:43:50,005 root         INFO     Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 0.080016\n",
      "Reconstruction: 0.077318, Regularization: 0.002698\n",
      "2019-04-09 20:43:50,031 root         INFO     Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 0.054878\n",
      "Reconstruction: 0.053188, Regularization: 0.001690\n",
      "2019-04-09 20:43:50,058 root         INFO     Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 0.063727\n",
      "Reconstruction: 0.061693, Regularization: 0.002034\n",
      "2019-04-09 20:43:50,085 root         INFO     Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 0.051949\n",
      "Reconstruction: 0.050359, Regularization: 0.001590\n",
      "2019-04-09 20:43:50,112 root         INFO     Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 0.044288\n",
      "Reconstruction: 0.043088, Regularization: 0.001200\n",
      "2019-04-09 20:43:50,150 root         INFO     ====> Epoch: 69 Average loss: 0.0520\n",
      "2019-04-09 20:43:50,171 root         INFO     Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 0.041481\n",
      "Reconstruction: 0.040372, Regularization: 0.001108\n",
      "2019-04-09 20:43:50,198 root         INFO     Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 0.036645\n",
      "Reconstruction: 0.035683, Regularization: 0.000962\n",
      "2019-04-09 20:43:50,225 root         INFO     Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 0.052169\n",
      "Reconstruction: 0.050659, Regularization: 0.001510\n",
      "2019-04-09 20:43:50,252 root         INFO     Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 0.052174\n",
      "Reconstruction: 0.050615, Regularization: 0.001559\n",
      "2019-04-09 20:43:50,279 root         INFO     Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 0.048514\n",
      "Reconstruction: 0.047113, Regularization: 0.001400\n",
      "2019-04-09 20:43:50,306 root         INFO     Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 0.050829\n",
      "Reconstruction: 0.049292, Regularization: 0.001537\n",
      "2019-04-09 20:43:50,333 root         INFO     Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 0.051695\n",
      "Reconstruction: 0.050127, Regularization: 0.001568\n",
      "2019-04-09 20:43:50,361 root         INFO     Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 0.051118\n",
      "Reconstruction: 0.049652, Regularization: 0.001466\n",
      "2019-04-09 20:43:50,399 root         INFO     ====> Epoch: 70 Average loss: 0.0518\n",
      "2019-04-09 20:43:50,420 root         INFO     Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 0.049964\n",
      "Reconstruction: 0.048520, Regularization: 0.001444\n",
      "2019-04-09 20:43:50,447 root         INFO     Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 0.060135\n",
      "Reconstruction: 0.058279, Regularization: 0.001855\n",
      "2019-04-09 20:43:50,476 root         INFO     Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 0.041197\n",
      "Reconstruction: 0.040080, Regularization: 0.001117\n",
      "2019-04-09 20:43:50,504 root         INFO     Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 0.053195\n",
      "Reconstruction: 0.051659, Regularization: 0.001536\n",
      "2019-04-09 20:43:50,532 root         INFO     Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 0.049847\n",
      "Reconstruction: 0.048442, Regularization: 0.001405\n",
      "2019-04-09 20:43:50,561 root         INFO     Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 0.049055\n",
      "Reconstruction: 0.047628, Regularization: 0.001427\n",
      "2019-04-09 20:43:50,589 root         INFO     Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 0.051759\n",
      "Reconstruction: 0.050274, Regularization: 0.001485\n",
      "2019-04-09 20:43:50,618 root         INFO     Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 0.063184\n",
      "Reconstruction: 0.061221, Regularization: 0.001963\n",
      "2019-04-09 20:43:50,657 root         INFO     ====> Epoch: 71 Average loss: 0.0517\n",
      "2019-04-09 20:43:50,678 root         INFO     Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 0.051057\n",
      "Reconstruction: 0.049551, Regularization: 0.001506\n",
      "2019-04-09 20:43:50,706 root         INFO     Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 0.056067\n",
      "Reconstruction: 0.054383, Regularization: 0.001684\n",
      "2019-04-09 20:43:50,733 root         INFO     Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 0.054756\n",
      "Reconstruction: 0.053126, Regularization: 0.001631\n",
      "2019-04-09 20:43:50,760 root         INFO     Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 0.043100\n",
      "Reconstruction: 0.041950, Regularization: 0.001150\n",
      "2019-04-09 20:43:50,787 root         INFO     Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 0.055557\n",
      "Reconstruction: 0.053898, Regularization: 0.001660\n",
      "2019-04-09 20:43:50,813 root         INFO     Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 0.048518\n",
      "Reconstruction: 0.047149, Regularization: 0.001369\n",
      "2019-04-09 20:43:50,841 root         INFO     Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 0.047379\n",
      "Reconstruction: 0.046022, Regularization: 0.001357\n",
      "2019-04-09 20:43:50,867 root         INFO     Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 0.050984\n",
      "Reconstruction: 0.049531, Regularization: 0.001454\n",
      "2019-04-09 20:43:50,906 root         INFO     ====> Epoch: 72 Average loss: 0.0516\n",
      "2019-04-09 20:43:50,927 root         INFO     Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 0.046828\n",
      "Reconstruction: 0.045567, Regularization: 0.001261\n",
      "2019-04-09 20:43:50,954 root         INFO     Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 0.053907\n",
      "Reconstruction: 0.052345, Regularization: 0.001562\n",
      "2019-04-09 20:43:50,981 root         INFO     Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 0.048728\n",
      "Reconstruction: 0.047396, Regularization: 0.001332\n",
      "2019-04-09 20:43:51,008 root         INFO     Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 0.044381\n",
      "Reconstruction: 0.043188, Regularization: 0.001194\n",
      "2019-04-09 20:43:51,035 root         INFO     Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 0.056263\n",
      "Reconstruction: 0.054561, Regularization: 0.001701\n",
      "2019-04-09 20:43:51,063 root         INFO     Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 0.055982\n",
      "Reconstruction: 0.054327, Regularization: 0.001655\n",
      "2019-04-09 20:43:51,090 root         INFO     Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 0.048671\n",
      "Reconstruction: 0.047283, Regularization: 0.001388\n",
      "2019-04-09 20:43:51,116 root         INFO     Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 0.050509\n",
      "Reconstruction: 0.049093, Regularization: 0.001416\n",
      "2019-04-09 20:43:51,154 root         INFO     ====> Epoch: 73 Average loss: 0.0515\n",
      "2019-04-09 20:43:51,175 root         INFO     Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 0.050735\n",
      "Reconstruction: 0.049279, Regularization: 0.001456\n",
      "2019-04-09 20:43:51,202 root         INFO     Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 0.043165\n",
      "Reconstruction: 0.041958, Regularization: 0.001207\n",
      "2019-04-09 20:43:51,228 root         INFO     Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 0.050503\n",
      "Reconstruction: 0.049059, Regularization: 0.001443\n",
      "2019-04-09 20:43:51,254 root         INFO     Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 0.058147\n",
      "Reconstruction: 0.056401, Regularization: 0.001746\n",
      "2019-04-09 20:43:51,280 root         INFO     Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 0.046205\n",
      "Reconstruction: 0.044980, Regularization: 0.001225\n",
      "2019-04-09 20:43:51,307 root         INFO     Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 0.057906\n",
      "Reconstruction: 0.056196, Regularization: 0.001710\n",
      "2019-04-09 20:43:51,333 root         INFO     Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 0.049101\n",
      "Reconstruction: 0.047747, Regularization: 0.001354\n",
      "2019-04-09 20:43:51,359 root         INFO     Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 0.052734\n",
      "Reconstruction: 0.051187, Regularization: 0.001547\n",
      "2019-04-09 20:43:51,396 root         INFO     ====> Epoch: 74 Average loss: 0.0515\n",
      "2019-04-09 20:43:51,418 root         INFO     Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 0.041483\n",
      "Reconstruction: 0.040388, Regularization: 0.001095\n",
      "2019-04-09 20:43:51,444 root         INFO     Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 0.050850\n",
      "Reconstruction: 0.049349, Regularization: 0.001501\n",
      "2019-04-09 20:43:51,470 root         INFO     Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 0.054324\n",
      "Reconstruction: 0.052757, Regularization: 0.001567\n",
      "2019-04-09 20:43:51,497 root         INFO     Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 0.046361\n",
      "Reconstruction: 0.045090, Regularization: 0.001270\n",
      "2019-04-09 20:43:51,523 root         INFO     Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 0.058871\n",
      "Reconstruction: 0.057100, Regularization: 0.001771\n",
      "2019-04-09 20:43:51,549 root         INFO     Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 0.054656\n",
      "Reconstruction: 0.052991, Regularization: 0.001665\n",
      "2019-04-09 20:43:51,576 root         INFO     Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 0.056348\n",
      "Reconstruction: 0.054709, Regularization: 0.001639\n",
      "2019-04-09 20:43:51,604 root         INFO     Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 0.049378\n",
      "Reconstruction: 0.047992, Regularization: 0.001386\n",
      "2019-04-09 20:43:51,643 root         INFO     ====> Epoch: 75 Average loss: 0.0514\n",
      "2019-04-09 20:43:51,665 root         INFO     Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 0.047826\n",
      "Reconstruction: 0.046496, Regularization: 0.001330\n",
      "2019-04-09 20:43:51,692 root         INFO     Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 0.038376\n",
      "Reconstruction: 0.037418, Regularization: 0.000958\n",
      "2019-04-09 20:43:51,719 root         INFO     Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 0.043535\n",
      "Reconstruction: 0.042357, Regularization: 0.001177\n",
      "2019-04-09 20:43:51,746 root         INFO     Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 0.045646\n",
      "Reconstruction: 0.044382, Regularization: 0.001264\n",
      "2019-04-09 20:43:51,773 root         INFO     Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 0.046578\n",
      "Reconstruction: 0.045221, Regularization: 0.001358\n",
      "2019-04-09 20:43:51,799 root         INFO     Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 0.052596\n",
      "Reconstruction: 0.050993, Regularization: 0.001603\n",
      "2019-04-09 20:43:51,826 root         INFO     Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 0.052091\n",
      "Reconstruction: 0.050616, Regularization: 0.001475\n",
      "2019-04-09 20:43:51,853 root         INFO     Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 0.069482\n",
      "Reconstruction: 0.067179, Regularization: 0.002303\n",
      "2019-04-09 20:43:51,892 root         INFO     ====> Epoch: 76 Average loss: 0.0514\n",
      "2019-04-09 20:43:51,913 root         INFO     Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 0.057532\n",
      "Reconstruction: 0.055784, Regularization: 0.001747\n",
      "2019-04-09 20:43:51,940 root         INFO     Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 0.051642\n",
      "Reconstruction: 0.050228, Regularization: 0.001414\n",
      "2019-04-09 20:43:51,966 root         INFO     Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 0.043949\n",
      "Reconstruction: 0.042701, Regularization: 0.001248\n",
      "2019-04-09 20:43:51,993 root         INFO     Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 0.048253\n",
      "Reconstruction: 0.046826, Regularization: 0.001427\n",
      "2019-04-09 20:43:52,020 root         INFO     Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 0.062114\n",
      "Reconstruction: 0.060118, Regularization: 0.001996\n",
      "2019-04-09 20:43:52,046 root         INFO     Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 0.058986\n",
      "Reconstruction: 0.057065, Regularization: 0.001921\n",
      "2019-04-09 20:43:52,073 root         INFO     Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 0.041922\n",
      "Reconstruction: 0.040738, Regularization: 0.001183\n",
      "2019-04-09 20:43:52,099 root         INFO     Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 0.050468\n",
      "Reconstruction: 0.049017, Regularization: 0.001451\n",
      "2019-04-09 20:43:52,138 root         INFO     ====> Epoch: 77 Average loss: 0.0512\n",
      "2019-04-09 20:43:52,159 root         INFO     Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 0.053918\n",
      "Reconstruction: 0.052229, Regularization: 0.001689\n",
      "2019-04-09 20:43:52,186 root         INFO     Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 0.058143\n",
      "Reconstruction: 0.056304, Regularization: 0.001839\n",
      "2019-04-09 20:43:52,212 root         INFO     Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 0.059459\n",
      "Reconstruction: 0.057589, Regularization: 0.001870\n",
      "2019-04-09 20:43:52,239 root         INFO     Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 0.060323\n",
      "Reconstruction: 0.058393, Regularization: 0.001929\n",
      "2019-04-09 20:43:52,264 root         INFO     Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 0.033339\n",
      "Reconstruction: 0.032487, Regularization: 0.000851\n",
      "2019-04-09 20:43:52,288 root         INFO     Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 0.047883\n",
      "Reconstruction: 0.046456, Regularization: 0.001428\n",
      "2019-04-09 20:43:52,313 root         INFO     Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 0.050351\n",
      "Reconstruction: 0.048824, Regularization: 0.001527\n",
      "2019-04-09 20:43:52,337 root         INFO     Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 0.051774\n",
      "Reconstruction: 0.050226, Regularization: 0.001548\n",
      "2019-04-09 20:43:52,373 root         INFO     ====> Epoch: 78 Average loss: 0.0511\n",
      "2019-04-09 20:43:52,395 root         INFO     Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 0.057724\n",
      "Reconstruction: 0.055894, Regularization: 0.001830\n",
      "2019-04-09 20:43:52,423 root         INFO     Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 0.042929\n",
      "Reconstruction: 0.041760, Regularization: 0.001169\n",
      "2019-04-09 20:43:52,450 root         INFO     Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 0.066847\n",
      "Reconstruction: 0.064620, Regularization: 0.002227\n",
      "2019-04-09 20:43:52,475 root         INFO     Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 0.052103\n",
      "Reconstruction: 0.050425, Regularization: 0.001678\n",
      "2019-04-09 20:43:52,501 root         INFO     Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 0.041022\n",
      "Reconstruction: 0.039785, Regularization: 0.001236\n",
      "2019-04-09 20:43:52,527 root         INFO     Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 0.043441\n",
      "Reconstruction: 0.042198, Regularization: 0.001243\n",
      "2019-04-09 20:43:52,552 root         INFO     Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 0.055715\n",
      "Reconstruction: 0.053861, Regularization: 0.001853\n",
      "2019-04-09 20:43:52,578 root         INFO     Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 0.046689\n",
      "Reconstruction: 0.045219, Regularization: 0.001470\n",
      "2019-04-09 20:43:52,615 root         INFO     ====> Epoch: 79 Average loss: 0.0511\n",
      "2019-04-09 20:43:52,635 root         INFO     Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 0.051123\n",
      "Reconstruction: 0.049506, Regularization: 0.001617\n",
      "2019-04-09 20:43:52,662 root         INFO     Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 0.038828\n",
      "Reconstruction: 0.037731, Regularization: 0.001097\n",
      "2019-04-09 20:43:52,689 root         INFO     Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 0.046451\n",
      "Reconstruction: 0.045002, Regularization: 0.001449\n",
      "2019-04-09 20:43:52,715 root         INFO     Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 0.048157\n",
      "Reconstruction: 0.046619, Regularization: 0.001538\n",
      "2019-04-09 20:43:52,742 root         INFO     Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 0.054118\n",
      "Reconstruction: 0.052353, Regularization: 0.001765\n",
      "2019-04-09 20:43:52,767 root         INFO     Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 0.045862\n",
      "Reconstruction: 0.044513, Regularization: 0.001349\n",
      "2019-04-09 20:43:52,792 root         INFO     Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 0.047035\n",
      "Reconstruction: 0.045540, Regularization: 0.001495\n",
      "2019-04-09 20:43:52,818 root         INFO     Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 0.060872\n",
      "Reconstruction: 0.058702, Regularization: 0.002170\n",
      "2019-04-09 20:43:52,854 root         INFO     ====> Epoch: 80 Average loss: 0.0510\n",
      "2019-04-09 20:43:52,875 root         INFO     Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 0.051941\n",
      "Reconstruction: 0.050240, Regularization: 0.001700\n",
      "2019-04-09 20:43:52,903 root         INFO     Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 0.044136\n",
      "Reconstruction: 0.042705, Regularization: 0.001431\n",
      "2019-04-09 20:43:52,929 root         INFO     Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 0.045734\n",
      "Reconstruction: 0.044192, Regularization: 0.001542\n",
      "2019-04-09 20:43:52,956 root         INFO     Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 0.040449\n",
      "Reconstruction: 0.039230, Regularization: 0.001219\n",
      "2019-04-09 20:43:52,983 root         INFO     Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 0.058544\n",
      "Reconstruction: 0.056402, Regularization: 0.002143\n",
      "2019-04-09 20:43:53,009 root         INFO     Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 0.058180\n",
      "Reconstruction: 0.056103, Regularization: 0.002077\n",
      "2019-04-09 20:43:53,036 root         INFO     Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 0.051953\n",
      "Reconstruction: 0.050147, Regularization: 0.001806\n",
      "2019-04-09 20:43:53,063 root         INFO     Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 0.071947\n",
      "Reconstruction: 0.069166, Regularization: 0.002781\n",
      "2019-04-09 20:43:53,101 root         INFO     ====> Epoch: 81 Average loss: 0.0507\n",
      "2019-04-09 20:43:53,122 root         INFO     Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 0.051604\n",
      "Reconstruction: 0.049851, Regularization: 0.001753\n",
      "2019-04-09 20:43:53,148 root         INFO     Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 0.048663\n",
      "Reconstruction: 0.046995, Regularization: 0.001668\n",
      "2019-04-09 20:43:53,174 root         INFO     Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 0.037676\n",
      "Reconstruction: 0.036532, Regularization: 0.001144\n",
      "2019-04-09 20:43:53,201 root         INFO     Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 0.056446\n",
      "Reconstruction: 0.054271, Regularization: 0.002174\n",
      "2019-04-09 20:43:53,226 root         INFO     Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 0.051927\n",
      "Reconstruction: 0.049993, Regularization: 0.001934\n",
      "2019-04-09 20:43:53,252 root         INFO     Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 0.049488\n",
      "Reconstruction: 0.047577, Regularization: 0.001911\n",
      "2019-04-09 20:43:53,278 root         INFO     Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 0.052726\n",
      "Reconstruction: 0.050778, Regularization: 0.001947\n",
      "2019-04-09 20:43:53,304 root         INFO     Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 0.067424\n",
      "Reconstruction: 0.064705, Regularization: 0.002719\n",
      "2019-04-09 20:43:53,341 root         INFO     ====> Epoch: 82 Average loss: 0.0505\n",
      "2019-04-09 20:43:53,362 root         INFO     Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 0.042575\n",
      "Reconstruction: 0.041121, Regularization: 0.001453\n",
      "2019-04-09 20:43:53,389 root         INFO     Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 0.059511\n",
      "Reconstruction: 0.057106, Regularization: 0.002405\n",
      "2019-04-09 20:43:53,415 root         INFO     Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 0.060358\n",
      "Reconstruction: 0.057964, Regularization: 0.002394\n",
      "2019-04-09 20:43:53,440 root         INFO     Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 0.055139\n",
      "Reconstruction: 0.052997, Regularization: 0.002142\n",
      "2019-04-09 20:43:53,467 root         INFO     Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 0.054269\n",
      "Reconstruction: 0.052173, Regularization: 0.002096\n",
      "2019-04-09 20:43:53,493 root         INFO     Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 0.071122\n",
      "Reconstruction: 0.068035, Regularization: 0.003087\n",
      "2019-04-09 20:43:53,520 root         INFO     Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 0.050633\n",
      "Reconstruction: 0.048649, Regularization: 0.001984\n",
      "2019-04-09 20:43:53,547 root         INFO     Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 0.053157\n",
      "Reconstruction: 0.051028, Regularization: 0.002130\n",
      "2019-04-09 20:43:53,585 root         INFO     ====> Epoch: 83 Average loss: 0.0504\n",
      "2019-04-09 20:43:53,606 root         INFO     Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 0.046835\n",
      "Reconstruction: 0.045110, Regularization: 0.001725\n",
      "2019-04-09 20:43:53,633 root         INFO     Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 0.052668\n",
      "Reconstruction: 0.050601, Regularization: 0.002068\n",
      "2019-04-09 20:43:53,660 root         INFO     Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 0.051319\n",
      "Reconstruction: 0.049413, Regularization: 0.001906\n",
      "2019-04-09 20:43:53,686 root         INFO     Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 0.045870\n",
      "Reconstruction: 0.044105, Regularization: 0.001765\n",
      "2019-04-09 20:43:53,713 root         INFO     Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 0.041348\n",
      "Reconstruction: 0.039921, Regularization: 0.001426\n",
      "2019-04-09 20:43:53,740 root         INFO     Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 0.050880\n",
      "Reconstruction: 0.048803, Regularization: 0.002076\n",
      "2019-04-09 20:43:53,766 root         INFO     Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 0.042652\n",
      "Reconstruction: 0.041110, Regularization: 0.001542\n",
      "2019-04-09 20:43:53,793 root         INFO     Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 0.044313\n",
      "Reconstruction: 0.042624, Regularization: 0.001690\n",
      "2019-04-09 20:43:53,831 root         INFO     ====> Epoch: 84 Average loss: 0.0504\n",
      "2019-04-09 20:43:53,852 root         INFO     Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 0.049760\n",
      "Reconstruction: 0.047801, Regularization: 0.001958\n",
      "2019-04-09 20:43:53,879 root         INFO     Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 0.043956\n",
      "Reconstruction: 0.042178, Regularization: 0.001779\n",
      "2019-04-09 20:43:53,906 root         INFO     Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 0.039827\n",
      "Reconstruction: 0.038386, Regularization: 0.001441\n",
      "2019-04-09 20:43:53,933 root         INFO     Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 0.053261\n",
      "Reconstruction: 0.050910, Regularization: 0.002352\n",
      "2019-04-09 20:43:53,960 root         INFO     Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 0.047387\n",
      "Reconstruction: 0.045350, Regularization: 0.002037\n",
      "2019-04-09 20:43:53,987 root         INFO     Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 0.044005\n",
      "Reconstruction: 0.042200, Regularization: 0.001805\n",
      "2019-04-09 20:43:54,014 root         INFO     Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 0.044415\n",
      "Reconstruction: 0.042581, Regularization: 0.001834\n",
      "2019-04-09 20:43:54,040 root         INFO     Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 0.046441\n",
      "Reconstruction: 0.044450, Regularization: 0.001990\n",
      "2019-04-09 20:43:54,079 root         INFO     ====> Epoch: 85 Average loss: 0.0500\n",
      "2019-04-09 20:43:54,100 root         INFO     Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 0.056648\n",
      "Reconstruction: 0.054082, Regularization: 0.002566\n",
      "2019-04-09 20:43:54,128 root         INFO     Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 0.054514\n",
      "Reconstruction: 0.051984, Regularization: 0.002530\n",
      "2019-04-09 20:43:54,156 root         INFO     Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 0.065677\n",
      "Reconstruction: 0.062240, Regularization: 0.003436\n",
      "2019-04-09 20:43:54,184 root         INFO     Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 0.052476\n",
      "Reconstruction: 0.050221, Regularization: 0.002254\n",
      "2019-04-09 20:43:54,212 root         INFO     Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 0.060535\n",
      "Reconstruction: 0.057451, Regularization: 0.003083\n",
      "2019-04-09 20:43:54,240 root         INFO     Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 0.046624\n",
      "Reconstruction: 0.044454, Regularization: 0.002170\n",
      "2019-04-09 20:43:54,268 root         INFO     Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 0.047123\n",
      "Reconstruction: 0.044995, Regularization: 0.002128\n",
      "2019-04-09 20:43:54,296 root         INFO     Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 0.041866\n",
      "Reconstruction: 0.040117, Regularization: 0.001748\n",
      "2019-04-09 20:43:54,334 root         INFO     ====> Epoch: 86 Average loss: 0.0498\n",
      "2019-04-09 20:43:54,355 root         INFO     Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 0.038264\n",
      "Reconstruction: 0.036619, Regularization: 0.001645\n",
      "2019-04-09 20:43:54,382 root         INFO     Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 0.048210\n",
      "Reconstruction: 0.045927, Regularization: 0.002284\n",
      "2019-04-09 20:43:54,409 root         INFO     Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 0.044376\n",
      "Reconstruction: 0.042215, Regularization: 0.002161\n",
      "2019-04-09 20:43:54,436 root         INFO     Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 0.040520\n",
      "Reconstruction: 0.038748, Regularization: 0.001772\n",
      "2019-04-09 20:43:54,463 root         INFO     Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 0.049402\n",
      "Reconstruction: 0.046830, Regularization: 0.002572\n",
      "2019-04-09 20:43:54,490 root         INFO     Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 0.055822\n",
      "Reconstruction: 0.052809, Regularization: 0.003013\n",
      "2019-04-09 20:43:54,517 root         INFO     Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 0.040573\n",
      "Reconstruction: 0.038661, Regularization: 0.001911\n",
      "2019-04-09 20:43:54,544 root         INFO     Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 0.057472\n",
      "Reconstruction: 0.054499, Regularization: 0.002973\n",
      "2019-04-09 20:43:54,582 root         INFO     ====> Epoch: 87 Average loss: 0.0497\n",
      "2019-04-09 20:43:54,603 root         INFO     Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 0.047846\n",
      "Reconstruction: 0.045317, Regularization: 0.002528\n",
      "2019-04-09 20:43:54,630 root         INFO     Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 0.045275\n",
      "Reconstruction: 0.042971, Regularization: 0.002305\n",
      "2019-04-09 20:43:54,657 root         INFO     Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 0.041884\n",
      "Reconstruction: 0.039857, Regularization: 0.002027\n",
      "2019-04-09 20:43:54,684 root         INFO     Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 0.051139\n",
      "Reconstruction: 0.048430, Regularization: 0.002708\n",
      "2019-04-09 20:43:54,711 root         INFO     Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 0.049207\n",
      "Reconstruction: 0.046544, Regularization: 0.002662\n",
      "2019-04-09 20:43:54,738 root         INFO     Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 0.054706\n",
      "Reconstruction: 0.051835, Regularization: 0.002871\n",
      "2019-04-09 20:43:54,766 root         INFO     Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 0.049800\n",
      "Reconstruction: 0.047114, Regularization: 0.002686\n",
      "2019-04-09 20:43:54,793 root         INFO     Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 0.049736\n",
      "Reconstruction: 0.046895, Regularization: 0.002841\n",
      "2019-04-09 20:43:54,831 root         INFO     ====> Epoch: 88 Average loss: 0.0498\n",
      "2019-04-09 20:43:54,852 root         INFO     Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 0.062811\n",
      "Reconstruction: 0.058965, Regularization: 0.003846\n",
      "2019-04-09 20:43:54,879 root         INFO     Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 0.050579\n",
      "Reconstruction: 0.047869, Regularization: 0.002710\n",
      "2019-04-09 20:43:54,906 root         INFO     Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 0.055604\n",
      "Reconstruction: 0.052307, Regularization: 0.003296\n",
      "2019-04-09 20:43:54,933 root         INFO     Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 0.052449\n",
      "Reconstruction: 0.049327, Regularization: 0.003122\n",
      "2019-04-09 20:43:54,960 root         INFO     Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 0.041063\n",
      "Reconstruction: 0.038821, Regularization: 0.002242\n",
      "2019-04-09 20:43:54,987 root         INFO     Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 0.052376\n",
      "Reconstruction: 0.049153, Regularization: 0.003223\n",
      "2019-04-09 20:43:55,014 root         INFO     Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 0.045152\n",
      "Reconstruction: 0.042597, Regularization: 0.002555\n",
      "2019-04-09 20:43:55,040 root         INFO     Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 0.049894\n",
      "Reconstruction: 0.046998, Regularization: 0.002896\n",
      "2019-04-09 20:43:55,077 root         INFO     ====> Epoch: 89 Average loss: 0.0495\n",
      "2019-04-09 20:43:55,099 root         INFO     Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 0.060820\n",
      "Reconstruction: 0.056964, Regularization: 0.003856\n",
      "2019-04-09 20:43:55,125 root         INFO     Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 0.050421\n",
      "Reconstruction: 0.047217, Regularization: 0.003204\n",
      "2019-04-09 20:43:55,151 root         INFO     Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 0.044894\n",
      "Reconstruction: 0.042409, Regularization: 0.002485\n",
      "2019-04-09 20:43:55,177 root         INFO     Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 0.049791\n",
      "Reconstruction: 0.046711, Regularization: 0.003080\n",
      "2019-04-09 20:43:55,202 root         INFO     Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 0.048702\n",
      "Reconstruction: 0.045866, Regularization: 0.002836\n",
      "2019-04-09 20:43:55,228 root         INFO     Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 0.053091\n",
      "Reconstruction: 0.049696, Regularization: 0.003395\n",
      "2019-04-09 20:43:55,254 root         INFO     Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 0.045960\n",
      "Reconstruction: 0.043261, Regularization: 0.002700\n",
      "2019-04-09 20:43:55,281 root         INFO     Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 0.047681\n",
      "Reconstruction: 0.044757, Regularization: 0.002923\n",
      "2019-04-09 20:43:55,320 root         INFO     ====> Epoch: 90 Average loss: 0.0492\n",
      "2019-04-09 20:43:55,341 root         INFO     Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 0.061752\n",
      "Reconstruction: 0.057576, Regularization: 0.004176\n",
      "2019-04-09 20:43:55,368 root         INFO     Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 0.061362\n",
      "Reconstruction: 0.056964, Regularization: 0.004398\n",
      "2019-04-09 20:43:55,395 root         INFO     Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 0.056333\n",
      "Reconstruction: 0.052501, Regularization: 0.003831\n",
      "2019-04-09 20:43:55,422 root         INFO     Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 0.055414\n",
      "Reconstruction: 0.051705, Regularization: 0.003709\n",
      "2019-04-09 20:43:55,447 root         INFO     Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 0.055021\n",
      "Reconstruction: 0.051233, Regularization: 0.003789\n",
      "2019-04-09 20:43:55,472 root         INFO     Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 0.050755\n",
      "Reconstruction: 0.047383, Regularization: 0.003372\n",
      "2019-04-09 20:43:55,498 root         INFO     Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 0.050550\n",
      "Reconstruction: 0.046911, Regularization: 0.003639\n",
      "2019-04-09 20:43:55,524 root         INFO     Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 0.046020\n",
      "Reconstruction: 0.042743, Regularization: 0.003277\n",
      "2019-04-09 20:43:55,561 root         INFO     ====> Epoch: 91 Average loss: 0.0488\n",
      "2019-04-09 20:43:55,582 root         INFO     Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 0.043415\n",
      "Reconstruction: 0.040544, Regularization: 0.002871\n",
      "2019-04-09 20:43:55,609 root         INFO     Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 0.050659\n",
      "Reconstruction: 0.047274, Regularization: 0.003386\n",
      "2019-04-09 20:43:55,637 root         INFO     Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 0.037095\n",
      "Reconstruction: 0.034755, Regularization: 0.002339\n",
      "2019-04-09 20:43:55,664 root         INFO     Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 0.049691\n",
      "Reconstruction: 0.045980, Regularization: 0.003710\n",
      "2019-04-09 20:43:55,691 root         INFO     Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 0.044847\n",
      "Reconstruction: 0.041778, Regularization: 0.003069\n",
      "2019-04-09 20:43:55,718 root         INFO     Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 0.039119\n",
      "Reconstruction: 0.036627, Regularization: 0.002491\n",
      "2019-04-09 20:43:55,746 root         INFO     Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 0.048566\n",
      "Reconstruction: 0.045193, Regularization: 0.003374\n",
      "2019-04-09 20:43:55,773 root         INFO     Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 0.054167\n",
      "Reconstruction: 0.050257, Regularization: 0.003910\n",
      "2019-04-09 20:43:55,811 root         INFO     ====> Epoch: 92 Average loss: 0.0488\n",
      "2019-04-09 20:43:55,832 root         INFO     Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 0.056753\n",
      "Reconstruction: 0.052342, Regularization: 0.004412\n",
      "2019-04-09 20:43:55,859 root         INFO     Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 0.055313\n",
      "Reconstruction: 0.051259, Regularization: 0.004054\n",
      "2019-04-09 20:43:55,886 root         INFO     Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 0.044740\n",
      "Reconstruction: 0.041556, Regularization: 0.003184\n",
      "2019-04-09 20:43:55,913 root         INFO     Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 0.041185\n",
      "Reconstruction: 0.038418, Regularization: 0.002767\n",
      "2019-04-09 20:43:55,940 root         INFO     Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 0.046900\n",
      "Reconstruction: 0.043378, Regularization: 0.003522\n",
      "2019-04-09 20:43:55,966 root         INFO     Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 0.042365\n",
      "Reconstruction: 0.039325, Regularization: 0.003040\n",
      "2019-04-09 20:43:55,992 root         INFO     Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 0.054886\n",
      "Reconstruction: 0.050701, Regularization: 0.004185\n",
      "2019-04-09 20:43:56,019 root         INFO     Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 0.054817\n",
      "Reconstruction: 0.050207, Regularization: 0.004610\n",
      "2019-04-09 20:43:56,057 root         INFO     ====> Epoch: 93 Average loss: 0.0486\n",
      "2019-04-09 20:43:56,078 root         INFO     Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 0.049466\n",
      "Reconstruction: 0.045493, Regularization: 0.003973\n",
      "2019-04-09 20:43:56,105 root         INFO     Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 0.036971\n",
      "Reconstruction: 0.034168, Regularization: 0.002802\n",
      "2019-04-09 20:43:56,132 root         INFO     Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 0.046420\n",
      "Reconstruction: 0.042922, Regularization: 0.003498\n",
      "2019-04-09 20:43:56,159 root         INFO     Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 0.051300\n",
      "Reconstruction: 0.047080, Regularization: 0.004219\n",
      "2019-04-09 20:43:56,186 root         INFO     Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 0.051763\n",
      "Reconstruction: 0.047720, Regularization: 0.004043\n",
      "2019-04-09 20:43:56,213 root         INFO     Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 0.048745\n",
      "Reconstruction: 0.044871, Regularization: 0.003874\n",
      "2019-04-09 20:43:56,240 root         INFO     Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 0.041715\n",
      "Reconstruction: 0.038864, Regularization: 0.002851\n",
      "2019-04-09 20:43:56,267 root         INFO     Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 0.044533\n",
      "Reconstruction: 0.041566, Regularization: 0.002967\n",
      "2019-04-09 20:43:56,305 root         INFO     ====> Epoch: 94 Average loss: 0.0483\n",
      "2019-04-09 20:43:56,327 root         INFO     Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 0.047573\n",
      "Reconstruction: 0.043908, Regularization: 0.003665\n",
      "2019-04-09 20:43:56,353 root         INFO     Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 0.042368\n",
      "Reconstruction: 0.038998, Regularization: 0.003371\n",
      "2019-04-09 20:43:56,379 root         INFO     Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 0.038403\n",
      "Reconstruction: 0.035644, Regularization: 0.002760\n",
      "2019-04-09 20:43:56,405 root         INFO     Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 0.044600\n",
      "Reconstruction: 0.040732, Regularization: 0.003868\n",
      "2019-04-09 20:43:56,431 root         INFO     Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 0.054267\n",
      "Reconstruction: 0.049388, Regularization: 0.004878\n",
      "2019-04-09 20:43:56,458 root         INFO     Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 0.052398\n",
      "Reconstruction: 0.048141, Regularization: 0.004257\n",
      "2019-04-09 20:43:56,484 root         INFO     Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 0.043428\n",
      "Reconstruction: 0.039885, Regularization: 0.003544\n",
      "2019-04-09 20:43:56,510 root         INFO     Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 0.045467\n",
      "Reconstruction: 0.041339, Regularization: 0.004129\n",
      "2019-04-09 20:43:56,547 root         INFO     ====> Epoch: 95 Average loss: 0.0483\n",
      "2019-04-09 20:43:56,569 root         INFO     Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 0.047480\n",
      "Reconstruction: 0.043255, Regularization: 0.004225\n",
      "2019-04-09 20:43:56,595 root         INFO     Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 0.053312\n",
      "Reconstruction: 0.048284, Regularization: 0.005029\n",
      "2019-04-09 20:43:56,621 root         INFO     Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 0.051922\n",
      "Reconstruction: 0.047022, Regularization: 0.004900\n",
      "2019-04-09 20:43:56,647 root         INFO     Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 0.052727\n",
      "Reconstruction: 0.047461, Regularization: 0.005265\n",
      "2019-04-09 20:43:56,673 root         INFO     Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 0.053674\n",
      "Reconstruction: 0.048775, Regularization: 0.004900\n",
      "2019-04-09 20:43:56,698 root         INFO     Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 0.051245\n",
      "Reconstruction: 0.046570, Regularization: 0.004676\n",
      "2019-04-09 20:43:56,725 root         INFO     Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 0.046413\n",
      "Reconstruction: 0.041938, Regularization: 0.004475\n",
      "2019-04-09 20:43:56,751 root         INFO     Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 0.043610\n",
      "Reconstruction: 0.039595, Regularization: 0.004015\n",
      "2019-04-09 20:43:56,789 root         INFO     ====> Epoch: 96 Average loss: 0.0477\n",
      "2019-04-09 20:43:56,810 root         INFO     Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 0.045848\n",
      "Reconstruction: 0.041644, Regularization: 0.004204\n",
      "2019-04-09 20:43:56,837 root         INFO     Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 0.041260\n",
      "Reconstruction: 0.037595, Regularization: 0.003665\n",
      "2019-04-09 20:43:56,863 root         INFO     Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 0.058063\n",
      "Reconstruction: 0.052691, Regularization: 0.005372\n",
      "2019-04-09 20:43:56,889 root         INFO     Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 0.052465\n",
      "Reconstruction: 0.047236, Regularization: 0.005229\n",
      "2019-04-09 20:43:56,915 root         INFO     Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 0.043883\n",
      "Reconstruction: 0.040185, Regularization: 0.003698\n",
      "2019-04-09 20:43:56,940 root         INFO     Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 0.044058\n",
      "Reconstruction: 0.039787, Regularization: 0.004271\n",
      "2019-04-09 20:43:56,966 root         INFO     Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 0.052344\n",
      "Reconstruction: 0.047193, Regularization: 0.005151\n",
      "2019-04-09 20:43:56,992 root         INFO     Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 0.042830\n",
      "Reconstruction: 0.038990, Regularization: 0.003840\n",
      "2019-04-09 20:43:57,029 root         INFO     ====> Epoch: 97 Average loss: 0.0477\n",
      "2019-04-09 20:43:57,050 root         INFO     Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 0.050526\n",
      "Reconstruction: 0.045534, Regularization: 0.004992\n",
      "2019-04-09 20:43:57,077 root         INFO     Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 0.049311\n",
      "Reconstruction: 0.044331, Regularization: 0.004980\n",
      "2019-04-09 20:43:57,104 root         INFO     Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 0.044749\n",
      "Reconstruction: 0.040733, Regularization: 0.004016\n",
      "2019-04-09 20:43:57,131 root         INFO     Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 0.037827\n",
      "Reconstruction: 0.034262, Regularization: 0.003564\n",
      "2019-04-09 20:43:57,158 root         INFO     Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 0.051734\n",
      "Reconstruction: 0.045888, Regularization: 0.005846\n",
      "2019-04-09 20:43:57,185 root         INFO     Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 0.044642\n",
      "Reconstruction: 0.040035, Regularization: 0.004607\n",
      "2019-04-09 20:43:57,211 root         INFO     Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 0.054829\n",
      "Reconstruction: 0.048207, Regularization: 0.006622\n",
      "2019-04-09 20:43:57,238 root         INFO     Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 0.064829\n",
      "Reconstruction: 0.057452, Regularization: 0.007377\n",
      "2019-04-09 20:43:57,276 root         INFO     ====> Epoch: 98 Average loss: 0.0472\n",
      "2019-04-09 20:43:57,297 root         INFO     Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 0.036456\n",
      "Reconstruction: 0.032771, Regularization: 0.003685\n",
      "2019-04-09 20:43:57,324 root         INFO     Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 0.049526\n",
      "Reconstruction: 0.044768, Regularization: 0.004758\n",
      "2019-04-09 20:43:57,351 root         INFO     Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 0.046180\n",
      "Reconstruction: 0.041478, Regularization: 0.004702\n",
      "2019-04-09 20:43:57,378 root         INFO     Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 0.041743\n",
      "Reconstruction: 0.037517, Regularization: 0.004226\n",
      "2019-04-09 20:43:57,405 root         INFO     Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 0.044646\n",
      "Reconstruction: 0.040464, Regularization: 0.004181\n",
      "2019-04-09 20:43:57,432 root         INFO     Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 0.055597\n",
      "Reconstruction: 0.049585, Regularization: 0.006012\n",
      "2019-04-09 20:43:57,459 root         INFO     Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 0.047544\n",
      "Reconstruction: 0.042197, Regularization: 0.005346\n",
      "2019-04-09 20:43:57,485 root         INFO     Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 0.039124\n",
      "Reconstruction: 0.034972, Regularization: 0.004151\n",
      "2019-04-09 20:43:57,524 root         INFO     ====> Epoch: 99 Average loss: 0.0472\n",
      "2019-04-09 20:43:57,545 root         INFO     Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 0.050951\n",
      "Reconstruction: 0.044501, Regularization: 0.006450\n",
      "2019-04-09 20:43:57,573 root         INFO     Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 0.042151\n",
      "Reconstruction: 0.037612, Regularization: 0.004539\n",
      "2019-04-09 20:43:57,600 root         INFO     Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 0.051020\n",
      "Reconstruction: 0.045213, Regularization: 0.005807\n",
      "2019-04-09 20:43:57,626 root         INFO     Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 0.043174\n",
      "Reconstruction: 0.038296, Regularization: 0.004878\n",
      "2019-04-09 20:43:57,652 root         INFO     Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 0.048735\n",
      "Reconstruction: 0.043111, Regularization: 0.005624\n",
      "2019-04-09 20:43:57,677 root         INFO     Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 0.044490\n",
      "Reconstruction: 0.039449, Regularization: 0.005041\n",
      "2019-04-09 20:43:57,702 root         INFO     Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 0.041581\n",
      "Reconstruction: 0.037244, Regularization: 0.004337\n",
      "2019-04-09 20:43:57,727 root         INFO     Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 0.040279\n",
      "Reconstruction: 0.035698, Regularization: 0.004581\n",
      "2019-04-09 20:43:57,763 root         INFO     ====> Epoch: 100 Average loss: 0.0469\n",
      "2019-04-09 20:43:57,784 root         INFO     Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 0.042521\n",
      "Reconstruction: 0.037706, Regularization: 0.004815\n",
      "2019-04-09 20:43:57,812 root         INFO     Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 0.046824\n",
      "Reconstruction: 0.041413, Regularization: 0.005411\n",
      "2019-04-09 20:43:57,838 root         INFO     Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 0.054156\n",
      "Reconstruction: 0.047883, Regularization: 0.006273\n",
      "2019-04-09 20:43:57,865 root         INFO     Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 0.046953\n",
      "Reconstruction: 0.041543, Regularization: 0.005410\n",
      "2019-04-09 20:43:57,892 root         INFO     Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 0.047867\n",
      "Reconstruction: 0.042509, Regularization: 0.005358\n",
      "2019-04-09 20:43:57,919 root         INFO     Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 0.053072\n",
      "Reconstruction: 0.046890, Regularization: 0.006182\n",
      "2019-04-09 20:43:57,946 root         INFO     Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 0.048667\n",
      "Reconstruction: 0.042678, Regularization: 0.005989\n",
      "2019-04-09 20:43:57,973 root         INFO     Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 0.039571\n",
      "Reconstruction: 0.035172, Regularization: 0.004399\n",
      "2019-04-09 20:43:58,013 root         INFO     ====> Epoch: 101 Average loss: 0.0470\n",
      "2019-04-09 20:43:58,034 root         INFO     Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 0.053743\n",
      "Reconstruction: 0.047311, Regularization: 0.006432\n",
      "2019-04-09 20:43:58,062 root         INFO     Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 0.037574\n",
      "Reconstruction: 0.033156, Regularization: 0.004418\n",
      "2019-04-09 20:43:58,089 root         INFO     Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 0.040984\n",
      "Reconstruction: 0.036880, Regularization: 0.004104\n",
      "2019-04-09 20:43:58,114 root         INFO     Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 0.044060\n",
      "Reconstruction: 0.038843, Regularization: 0.005217\n",
      "2019-04-09 20:43:58,140 root         INFO     Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 0.049670\n",
      "Reconstruction: 0.042647, Regularization: 0.007022\n",
      "2019-04-09 20:43:58,165 root         INFO     Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 0.038046\n",
      "Reconstruction: 0.034157, Regularization: 0.003888\n",
      "2019-04-09 20:43:58,190 root         INFO     Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 0.039648\n",
      "Reconstruction: 0.034909, Regularization: 0.004739\n",
      "2019-04-09 20:43:58,216 root         INFO     Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 0.044542\n",
      "Reconstruction: 0.038792, Regularization: 0.005749\n",
      "2019-04-09 20:43:58,253 root         INFO     ====> Epoch: 102 Average loss: 0.0467\n",
      "2019-04-09 20:43:58,274 root         INFO     Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 0.044214\n",
      "Reconstruction: 0.038672, Regularization: 0.005541\n",
      "2019-04-09 20:43:58,301 root         INFO     Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 0.053243\n",
      "Reconstruction: 0.046420, Regularization: 0.006823\n",
      "2019-04-09 20:43:58,327 root         INFO     Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 0.052849\n",
      "Reconstruction: 0.046129, Regularization: 0.006719\n",
      "2019-04-09 20:43:58,354 root         INFO     Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 0.040585\n",
      "Reconstruction: 0.035500, Regularization: 0.005085\n",
      "2019-04-09 20:43:58,380 root         INFO     Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 0.051999\n",
      "Reconstruction: 0.044869, Regularization: 0.007130\n",
      "2019-04-09 20:43:58,406 root         INFO     Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 0.042460\n",
      "Reconstruction: 0.037565, Regularization: 0.004895\n",
      "2019-04-09 20:43:58,433 root         INFO     Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 0.045872\n",
      "Reconstruction: 0.039804, Regularization: 0.006068\n",
      "2019-04-09 20:43:58,459 root         INFO     Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 0.039114\n",
      "Reconstruction: 0.034409, Regularization: 0.004705\n",
      "2019-04-09 20:43:58,497 root         INFO     ====> Epoch: 103 Average loss: 0.0462\n",
      "2019-04-09 20:43:58,518 root         INFO     Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 0.033598\n",
      "Reconstruction: 0.029900, Regularization: 0.003698\n",
      "2019-04-09 20:43:58,546 root         INFO     Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 0.038730\n",
      "Reconstruction: 0.033188, Regularization: 0.005542\n",
      "2019-04-09 20:43:58,572 root         INFO     Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 0.049822\n",
      "Reconstruction: 0.043576, Regularization: 0.006246\n",
      "2019-04-09 20:43:58,598 root         INFO     Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 0.047429\n",
      "Reconstruction: 0.041269, Regularization: 0.006159\n",
      "2019-04-09 20:43:58,624 root         INFO     Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 0.038831\n",
      "Reconstruction: 0.033784, Regularization: 0.005047\n",
      "2019-04-09 20:43:58,650 root         INFO     Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 0.046254\n",
      "Reconstruction: 0.039808, Regularization: 0.006447\n",
      "2019-04-09 20:43:58,676 root         INFO     Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 0.045733\n",
      "Reconstruction: 0.039618, Regularization: 0.006115\n",
      "2019-04-09 20:43:58,702 root         INFO     Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 0.048216\n",
      "Reconstruction: 0.041943, Regularization: 0.006273\n",
      "2019-04-09 20:43:58,740 root         INFO     ====> Epoch: 104 Average loss: 0.0462\n",
      "2019-04-09 20:43:58,761 root         INFO     Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 0.044822\n",
      "Reconstruction: 0.039236, Regularization: 0.005586\n",
      "2019-04-09 20:43:58,787 root         INFO     Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 0.045415\n",
      "Reconstruction: 0.039078, Regularization: 0.006337\n",
      "2019-04-09 20:43:58,813 root         INFO     Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 0.040176\n",
      "Reconstruction: 0.034815, Regularization: 0.005361\n",
      "2019-04-09 20:43:58,838 root         INFO     Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 0.052901\n",
      "Reconstruction: 0.045083, Regularization: 0.007818\n",
      "2019-04-09 20:43:58,863 root         INFO     Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 0.038649\n",
      "Reconstruction: 0.033395, Regularization: 0.005255\n",
      "2019-04-09 20:43:58,888 root         INFO     Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 0.046873\n",
      "Reconstruction: 0.040544, Regularization: 0.006328\n",
      "2019-04-09 20:43:58,913 root         INFO     Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 0.050445\n",
      "Reconstruction: 0.042881, Regularization: 0.007563\n",
      "2019-04-09 20:43:58,938 root         INFO     Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 0.046049\n",
      "Reconstruction: 0.040072, Regularization: 0.005977\n",
      "2019-04-09 20:43:58,975 root         INFO     ====> Epoch: 105 Average loss: 0.0460\n",
      "2019-04-09 20:43:58,996 root         INFO     Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 0.050441\n",
      "Reconstruction: 0.042612, Regularization: 0.007830\n",
      "2019-04-09 20:43:59,023 root         INFO     Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 0.040107\n",
      "Reconstruction: 0.034716, Regularization: 0.005391\n",
      "2019-04-09 20:43:59,050 root         INFO     Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 0.046488\n",
      "Reconstruction: 0.039713, Regularization: 0.006775\n",
      "2019-04-09 20:43:59,077 root         INFO     Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 0.044770\n",
      "Reconstruction: 0.038320, Regularization: 0.006450\n",
      "2019-04-09 20:43:59,103 root         INFO     Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 0.045127\n",
      "Reconstruction: 0.038735, Regularization: 0.006392\n",
      "2019-04-09 20:43:59,130 root         INFO     Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 0.046862\n",
      "Reconstruction: 0.039923, Regularization: 0.006939\n",
      "2019-04-09 20:43:59,157 root         INFO     Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 0.044492\n",
      "Reconstruction: 0.038996, Regularization: 0.005496\n",
      "2019-04-09 20:43:59,184 root         INFO     Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 0.045784\n",
      "Reconstruction: 0.039068, Regularization: 0.006716\n",
      "2019-04-09 20:43:59,223 root         INFO     ====> Epoch: 106 Average loss: 0.0456\n",
      "2019-04-09 20:43:59,244 root         INFO     Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 0.036971\n",
      "Reconstruction: 0.031425, Regularization: 0.005547\n",
      "2019-04-09 20:43:59,271 root         INFO     Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 0.054018\n",
      "Reconstruction: 0.045655, Regularization: 0.008363\n",
      "2019-04-09 20:43:59,297 root         INFO     Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 0.040981\n",
      "Reconstruction: 0.035521, Regularization: 0.005461\n",
      "2019-04-09 20:43:59,324 root         INFO     Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 0.061441\n",
      "Reconstruction: 0.050676, Regularization: 0.010765\n",
      "2019-04-09 20:43:59,351 root         INFO     Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 0.053761\n",
      "Reconstruction: 0.044940, Regularization: 0.008821\n",
      "2019-04-09 20:43:59,378 root         INFO     Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 0.049123\n",
      "Reconstruction: 0.042151, Regularization: 0.006972\n",
      "2019-04-09 20:43:59,405 root         INFO     Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 0.051188\n",
      "Reconstruction: 0.043450, Regularization: 0.007737\n",
      "2019-04-09 20:43:59,431 root         INFO     Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 0.042553\n",
      "Reconstruction: 0.035911, Regularization: 0.006642\n",
      "2019-04-09 20:43:59,470 root         INFO     ====> Epoch: 107 Average loss: 0.0457\n",
      "2019-04-09 20:43:59,491 root         INFO     Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 0.047875\n",
      "Reconstruction: 0.040227, Regularization: 0.007648\n",
      "2019-04-09 20:43:59,517 root         INFO     Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 0.043881\n",
      "Reconstruction: 0.036750, Regularization: 0.007132\n",
      "2019-04-09 20:43:59,543 root         INFO     Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 0.044808\n",
      "Reconstruction: 0.038464, Regularization: 0.006344\n",
      "2019-04-09 20:43:59,569 root         INFO     Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 0.037192\n",
      "Reconstruction: 0.032519, Regularization: 0.004673\n",
      "2019-04-09 20:43:59,593 root         INFO     Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 0.043418\n",
      "Reconstruction: 0.036928, Regularization: 0.006490\n",
      "2019-04-09 20:43:59,618 root         INFO     Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 0.042692\n",
      "Reconstruction: 0.035352, Regularization: 0.007340\n",
      "2019-04-09 20:43:59,643 root         INFO     Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 0.057234\n",
      "Reconstruction: 0.047125, Regularization: 0.010109\n",
      "2019-04-09 20:43:59,669 root         INFO     Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 0.043431\n",
      "Reconstruction: 0.036407, Regularization: 0.007024\n",
      "2019-04-09 20:43:59,705 root         INFO     ====> Epoch: 108 Average loss: 0.0450\n",
      "2019-04-09 20:43:59,726 root         INFO     Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 0.040733\n",
      "Reconstruction: 0.034892, Regularization: 0.005840\n",
      "2019-04-09 20:43:59,754 root         INFO     Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 0.046976\n",
      "Reconstruction: 0.039327, Regularization: 0.007649\n",
      "2019-04-09 20:43:59,781 root         INFO     Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 0.041079\n",
      "Reconstruction: 0.035309, Regularization: 0.005770\n",
      "2019-04-09 20:43:59,807 root         INFO     Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 0.042366\n",
      "Reconstruction: 0.036123, Regularization: 0.006243\n",
      "2019-04-09 20:43:59,834 root         INFO     Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 0.043220\n",
      "Reconstruction: 0.035664, Regularization: 0.007556\n",
      "2019-04-09 20:43:59,861 root         INFO     Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 0.050901\n",
      "Reconstruction: 0.042163, Regularization: 0.008738\n",
      "2019-04-09 20:43:59,889 root         INFO     Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 0.040078\n",
      "Reconstruction: 0.034309, Regularization: 0.005769\n",
      "2019-04-09 20:43:59,916 root         INFO     Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 0.056532\n",
      "Reconstruction: 0.045471, Regularization: 0.011061\n",
      "2019-04-09 20:43:59,954 root         INFO     ====> Epoch: 109 Average loss: 0.0451\n",
      "2019-04-09 20:43:59,975 root         INFO     Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 0.044543\n",
      "Reconstruction: 0.037996, Regularization: 0.006547\n",
      "2019-04-09 20:44:00,003 root         INFO     Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 0.040855\n",
      "Reconstruction: 0.034286, Regularization: 0.006568\n",
      "2019-04-09 20:44:00,030 root         INFO     Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 0.040880\n",
      "Reconstruction: 0.034771, Regularization: 0.006110\n",
      "2019-04-09 20:44:00,056 root         INFO     Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 0.050213\n",
      "Reconstruction: 0.042489, Regularization: 0.007724\n",
      "2019-04-09 20:44:00,083 root         INFO     Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 0.050280\n",
      "Reconstruction: 0.042039, Regularization: 0.008241\n",
      "2019-04-09 20:44:00,109 root         INFO     Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 0.043727\n",
      "Reconstruction: 0.035982, Regularization: 0.007745\n",
      "2019-04-09 20:44:00,135 root         INFO     Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 0.053495\n",
      "Reconstruction: 0.043037, Regularization: 0.010458\n",
      "2019-04-09 20:44:00,162 root         INFO     Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 0.046376\n",
      "Reconstruction: 0.038632, Regularization: 0.007744\n",
      "2019-04-09 20:44:00,201 root         INFO     ====> Epoch: 110 Average loss: 0.0452\n",
      "2019-04-09 20:44:00,222 root         INFO     Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 0.042098\n",
      "Reconstruction: 0.036187, Regularization: 0.005910\n",
      "2019-04-09 20:44:00,249 root         INFO     Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 0.038247\n",
      "Reconstruction: 0.032904, Regularization: 0.005344\n",
      "2019-04-09 20:44:00,277 root         INFO     Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 0.045383\n",
      "Reconstruction: 0.037853, Regularization: 0.007529\n",
      "2019-04-09 20:44:00,303 root         INFO     Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 0.048658\n",
      "Reconstruction: 0.041423, Regularization: 0.007235\n",
      "2019-04-09 20:44:00,330 root         INFO     Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 0.041039\n",
      "Reconstruction: 0.034523, Regularization: 0.006516\n",
      "2019-04-09 20:44:00,356 root         INFO     Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 0.047692\n",
      "Reconstruction: 0.040215, Regularization: 0.007478\n",
      "2019-04-09 20:44:00,383 root         INFO     Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 0.048807\n",
      "Reconstruction: 0.040753, Regularization: 0.008055\n",
      "2019-04-09 20:44:00,409 root         INFO     Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 0.038709\n",
      "Reconstruction: 0.032859, Regularization: 0.005850\n",
      "2019-04-09 20:44:00,447 root         INFO     ====> Epoch: 111 Average loss: 0.0449\n",
      "2019-04-09 20:44:00,468 root         INFO     Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 0.050170\n",
      "Reconstruction: 0.041527, Regularization: 0.008643\n",
      "2019-04-09 20:44:00,495 root         INFO     Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 0.046458\n",
      "Reconstruction: 0.038404, Regularization: 0.008054\n",
      "2019-04-09 20:44:00,523 root         INFO     Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 0.050830\n",
      "Reconstruction: 0.041255, Regularization: 0.009575\n",
      "2019-04-09 20:44:00,552 root         INFO     Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 0.046483\n",
      "Reconstruction: 0.038494, Regularization: 0.007988\n",
      "2019-04-09 20:44:00,581 root         INFO     Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 0.044210\n",
      "Reconstruction: 0.036726, Regularization: 0.007484\n",
      "2019-04-09 20:44:00,610 root         INFO     Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 0.048660\n",
      "Reconstruction: 0.040210, Regularization: 0.008450\n",
      "2019-04-09 20:44:00,638 root         INFO     Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 0.043910\n",
      "Reconstruction: 0.036732, Regularization: 0.007178\n",
      "2019-04-09 20:44:00,667 root         INFO     Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 0.046792\n",
      "Reconstruction: 0.039039, Regularization: 0.007753\n",
      "2019-04-09 20:44:00,706 root         INFO     ====> Epoch: 112 Average loss: 0.0449\n",
      "2019-04-09 20:44:00,727 root         INFO     Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 0.053030\n",
      "Reconstruction: 0.043122, Regularization: 0.009909\n",
      "2019-04-09 20:44:00,754 root         INFO     Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 0.046174\n",
      "Reconstruction: 0.037316, Regularization: 0.008858\n",
      "2019-04-09 20:44:00,781 root         INFO     Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 0.048427\n",
      "Reconstruction: 0.041014, Regularization: 0.007413\n",
      "2019-04-09 20:44:00,808 root         INFO     Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 0.046501\n",
      "Reconstruction: 0.037821, Regularization: 0.008680\n",
      "2019-04-09 20:44:00,834 root         INFO     Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 0.039678\n",
      "Reconstruction: 0.033664, Regularization: 0.006013\n",
      "2019-04-09 20:44:00,861 root         INFO     Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 0.040055\n",
      "Reconstruction: 0.033809, Regularization: 0.006245\n",
      "2019-04-09 20:44:00,888 root         INFO     Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 0.048881\n",
      "Reconstruction: 0.038838, Regularization: 0.010043\n",
      "2019-04-09 20:44:00,914 root         INFO     Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 0.055662\n",
      "Reconstruction: 0.045801, Regularization: 0.009860\n",
      "2019-04-09 20:44:00,952 root         INFO     ====> Epoch: 113 Average loss: 0.0445\n",
      "2019-04-09 20:44:00,974 root         INFO     Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 0.057151\n",
      "Reconstruction: 0.045621, Regularization: 0.011530\n",
      "2019-04-09 20:44:01,000 root         INFO     Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 0.039242\n",
      "Reconstruction: 0.033303, Regularization: 0.005939\n",
      "2019-04-09 20:44:01,027 root         INFO     Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 0.044058\n",
      "Reconstruction: 0.036290, Regularization: 0.007768\n",
      "2019-04-09 20:44:01,054 root         INFO     Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 0.038255\n",
      "Reconstruction: 0.032497, Regularization: 0.005758\n",
      "2019-04-09 20:44:01,081 root         INFO     Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 0.048288\n",
      "Reconstruction: 0.039868, Regularization: 0.008420\n",
      "2019-04-09 20:44:01,107 root         INFO     Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 0.057731\n",
      "Reconstruction: 0.046653, Regularization: 0.011079\n",
      "2019-04-09 20:44:01,134 root         INFO     Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 0.051638\n",
      "Reconstruction: 0.042665, Regularization: 0.008973\n",
      "2019-04-09 20:44:01,160 root         INFO     Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 0.043973\n",
      "Reconstruction: 0.036313, Regularization: 0.007660\n",
      "2019-04-09 20:44:01,198 root         INFO     ====> Epoch: 114 Average loss: 0.0444\n",
      "2019-04-09 20:44:01,219 root         INFO     Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 0.039497\n",
      "Reconstruction: 0.032526, Regularization: 0.006971\n",
      "2019-04-09 20:44:01,246 root         INFO     Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 0.035525\n",
      "Reconstruction: 0.029097, Regularization: 0.006428\n",
      "2019-04-09 20:44:01,273 root         INFO     Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 0.044422\n",
      "Reconstruction: 0.036573, Regularization: 0.007848\n",
      "2019-04-09 20:44:01,300 root         INFO     Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 0.049066\n",
      "Reconstruction: 0.040381, Regularization: 0.008685\n",
      "2019-04-09 20:44:01,326 root         INFO     Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 0.045518\n",
      "Reconstruction: 0.036676, Regularization: 0.008842\n",
      "2019-04-09 20:44:01,352 root         INFO     Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 0.042946\n",
      "Reconstruction: 0.034735, Regularization: 0.008211\n",
      "2019-04-09 20:44:01,379 root         INFO     Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 0.040517\n",
      "Reconstruction: 0.033323, Regularization: 0.007194\n",
      "2019-04-09 20:44:01,405 root         INFO     Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 0.040808\n",
      "Reconstruction: 0.033910, Regularization: 0.006898\n",
      "2019-04-09 20:44:01,443 root         INFO     ====> Epoch: 115 Average loss: 0.0442\n",
      "2019-04-09 20:44:01,464 root         INFO     Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 0.042824\n",
      "Reconstruction: 0.035302, Regularization: 0.007522\n",
      "2019-04-09 20:44:01,492 root         INFO     Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 0.045123\n",
      "Reconstruction: 0.036650, Regularization: 0.008473\n",
      "2019-04-09 20:44:01,519 root         INFO     Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 0.049030\n",
      "Reconstruction: 0.040767, Regularization: 0.008263\n",
      "2019-04-09 20:44:01,547 root         INFO     Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 0.043439\n",
      "Reconstruction: 0.035467, Regularization: 0.007971\n",
      "2019-04-09 20:44:01,574 root         INFO     Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 0.050986\n",
      "Reconstruction: 0.042727, Regularization: 0.008259\n",
      "2019-04-09 20:44:01,601 root         INFO     Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 0.043162\n",
      "Reconstruction: 0.035640, Regularization: 0.007522\n",
      "2019-04-09 20:44:01,627 root         INFO     Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 0.057866\n",
      "Reconstruction: 0.046670, Regularization: 0.011196\n",
      "2019-04-09 20:44:01,654 root         INFO     Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 0.041678\n",
      "Reconstruction: 0.034695, Regularization: 0.006984\n",
      "2019-04-09 20:44:01,692 root         INFO     ====> Epoch: 116 Average loss: 0.0441\n",
      "2019-04-09 20:44:01,714 root         INFO     Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 0.034360\n",
      "Reconstruction: 0.028941, Regularization: 0.005419\n",
      "2019-04-09 20:44:01,740 root         INFO     Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 0.047492\n",
      "Reconstruction: 0.037875, Regularization: 0.009617\n",
      "2019-04-09 20:44:01,765 root         INFO     Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 0.048311\n",
      "Reconstruction: 0.037782, Regularization: 0.010530\n",
      "2019-04-09 20:44:01,792 root         INFO     Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 0.050365\n",
      "Reconstruction: 0.040718, Regularization: 0.009648\n",
      "2019-04-09 20:44:01,820 root         INFO     Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 0.038621\n",
      "Reconstruction: 0.031734, Regularization: 0.006887\n",
      "2019-04-09 20:44:01,847 root         INFO     Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 0.041157\n",
      "Reconstruction: 0.033551, Regularization: 0.007606\n",
      "2019-04-09 20:44:01,875 root         INFO     Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 0.037951\n",
      "Reconstruction: 0.031906, Regularization: 0.006045\n",
      "2019-04-09 20:44:01,901 root         INFO     Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 0.044812\n",
      "Reconstruction: 0.035837, Regularization: 0.008975\n",
      "2019-04-09 20:44:01,938 root         INFO     ====> Epoch: 117 Average loss: 0.0438\n",
      "2019-04-09 20:44:01,959 root         INFO     Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 0.042857\n",
      "Reconstruction: 0.034921, Regularization: 0.007937\n",
      "2019-04-09 20:44:01,986 root         INFO     Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 0.041714\n",
      "Reconstruction: 0.034049, Regularization: 0.007665\n",
      "2019-04-09 20:44:02,013 root         INFO     Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 0.045333\n",
      "Reconstruction: 0.035394, Regularization: 0.009940\n",
      "2019-04-09 20:44:02,040 root         INFO     Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 0.048220\n",
      "Reconstruction: 0.039605, Regularization: 0.008615\n",
      "2019-04-09 20:44:02,067 root         INFO     Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 0.045365\n",
      "Reconstruction: 0.035469, Regularization: 0.009896\n",
      "2019-04-09 20:44:02,094 root         INFO     Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 0.043659\n",
      "Reconstruction: 0.035942, Regularization: 0.007717\n",
      "2019-04-09 20:44:02,121 root         INFO     Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 0.036799\n",
      "Reconstruction: 0.030017, Regularization: 0.006782\n",
      "2019-04-09 20:44:02,148 root         INFO     Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 0.048982\n",
      "Reconstruction: 0.040365, Regularization: 0.008617\n",
      "2019-04-09 20:44:02,186 root         INFO     ====> Epoch: 118 Average loss: 0.0440\n",
      "2019-04-09 20:44:02,208 root         INFO     Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 0.045777\n",
      "Reconstruction: 0.036271, Regularization: 0.009506\n",
      "2019-04-09 20:44:02,236 root         INFO     Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 0.052032\n",
      "Reconstruction: 0.042505, Regularization: 0.009527\n",
      "2019-04-09 20:44:02,264 root         INFO     Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 0.052914\n",
      "Reconstruction: 0.041856, Regularization: 0.011058\n",
      "2019-04-09 20:44:02,292 root         INFO     Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 0.050998\n",
      "Reconstruction: 0.040606, Regularization: 0.010392\n",
      "2019-04-09 20:44:02,318 root         INFO     Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 0.045055\n",
      "Reconstruction: 0.037249, Regularization: 0.007806\n",
      "2019-04-09 20:44:02,344 root         INFO     Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 0.052415\n",
      "Reconstruction: 0.042485, Regularization: 0.009930\n",
      "2019-04-09 20:44:02,370 root         INFO     Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 0.039621\n",
      "Reconstruction: 0.031603, Regularization: 0.008018\n",
      "2019-04-09 20:44:02,396 root         INFO     Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 0.044931\n",
      "Reconstruction: 0.036094, Regularization: 0.008837\n",
      "2019-04-09 20:44:02,434 root         INFO     ====> Epoch: 119 Average loss: 0.0438\n",
      "2019-04-09 20:44:02,455 root         INFO     Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 0.046730\n",
      "Reconstruction: 0.038081, Regularization: 0.008649\n",
      "2019-04-09 20:44:02,483 root         INFO     Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 0.041779\n",
      "Reconstruction: 0.033525, Regularization: 0.008253\n",
      "2019-04-09 20:44:02,510 root         INFO     Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 0.043020\n",
      "Reconstruction: 0.034346, Regularization: 0.008674\n",
      "2019-04-09 20:44:02,537 root         INFO     Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 0.036468\n",
      "Reconstruction: 0.029693, Regularization: 0.006775\n",
      "2019-04-09 20:44:02,564 root         INFO     Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 0.049114\n",
      "Reconstruction: 0.039374, Regularization: 0.009739\n",
      "2019-04-09 20:44:02,591 root         INFO     Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 0.036046\n",
      "Reconstruction: 0.029446, Regularization: 0.006600\n",
      "2019-04-09 20:44:02,618 root         INFO     Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 0.043000\n",
      "Reconstruction: 0.035911, Regularization: 0.007089\n",
      "2019-04-09 20:44:02,645 root         INFO     Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 0.035859\n",
      "Reconstruction: 0.030296, Regularization: 0.005563\n",
      "2019-04-09 20:44:02,683 root         INFO     ====> Epoch: 120 Average loss: 0.0438\n",
      "2019-04-09 20:44:02,704 root         INFO     Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 0.041658\n",
      "Reconstruction: 0.034110, Regularization: 0.007549\n",
      "2019-04-09 20:44:02,732 root         INFO     Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 0.036202\n",
      "Reconstruction: 0.029264, Regularization: 0.006938\n",
      "2019-04-09 20:44:02,759 root         INFO     Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 0.038610\n",
      "Reconstruction: 0.030681, Regularization: 0.007929\n",
      "2019-04-09 20:44:02,787 root         INFO     Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 0.039218\n",
      "Reconstruction: 0.031412, Regularization: 0.007806\n",
      "2019-04-09 20:44:02,814 root         INFO     Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 0.044282\n",
      "Reconstruction: 0.034630, Regularization: 0.009652\n",
      "2019-04-09 20:44:02,841 root         INFO     Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 0.046314\n",
      "Reconstruction: 0.036974, Regularization: 0.009340\n",
      "2019-04-09 20:44:02,869 root         INFO     Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 0.043735\n",
      "Reconstruction: 0.035843, Regularization: 0.007893\n",
      "2019-04-09 20:44:02,896 root         INFO     Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 0.043566\n",
      "Reconstruction: 0.035218, Regularization: 0.008349\n",
      "2019-04-09 20:44:02,934 root         INFO     ====> Epoch: 121 Average loss: 0.0431\n",
      "2019-04-09 20:44:02,956 root         INFO     Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 0.048599\n",
      "Reconstruction: 0.039482, Regularization: 0.009117\n",
      "2019-04-09 20:44:02,981 root         INFO     Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 0.041383\n",
      "Reconstruction: 0.033072, Regularization: 0.008310\n",
      "2019-04-09 20:44:03,008 root         INFO     Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 0.043638\n",
      "Reconstruction: 0.034148, Regularization: 0.009490\n",
      "2019-04-09 20:44:03,035 root         INFO     Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 0.043956\n",
      "Reconstruction: 0.035984, Regularization: 0.007972\n",
      "2019-04-09 20:44:03,062 root         INFO     Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 0.046223\n",
      "Reconstruction: 0.036776, Regularization: 0.009447\n",
      "2019-04-09 20:44:03,090 root         INFO     Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 0.042082\n",
      "Reconstruction: 0.034705, Regularization: 0.007377\n",
      "2019-04-09 20:44:03,118 root         INFO     Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 0.040650\n",
      "Reconstruction: 0.032631, Regularization: 0.008018\n",
      "2019-04-09 20:44:03,147 root         INFO     Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 0.043408\n",
      "Reconstruction: 0.034615, Regularization: 0.008792\n",
      "2019-04-09 20:44:03,185 root         INFO     ====> Epoch: 122 Average loss: 0.0436\n",
      "2019-04-09 20:44:03,206 root         INFO     Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 0.037702\n",
      "Reconstruction: 0.030230, Regularization: 0.007473\n",
      "2019-04-09 20:44:03,233 root         INFO     Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 0.044225\n",
      "Reconstruction: 0.035468, Regularization: 0.008757\n",
      "2019-04-09 20:44:03,260 root         INFO     Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 0.049153\n",
      "Reconstruction: 0.037932, Regularization: 0.011220\n",
      "2019-04-09 20:44:03,286 root         INFO     Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 0.045962\n",
      "Reconstruction: 0.037134, Regularization: 0.008829\n",
      "2019-04-09 20:44:03,312 root         INFO     Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 0.041362\n",
      "Reconstruction: 0.032431, Regularization: 0.008930\n",
      "2019-04-09 20:44:03,338 root         INFO     Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 0.046502\n",
      "Reconstruction: 0.036746, Regularization: 0.009755\n",
      "2019-04-09 20:44:03,363 root         INFO     Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 0.035455\n",
      "Reconstruction: 0.029121, Regularization: 0.006334\n",
      "2019-04-09 20:44:03,389 root         INFO     Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 0.045714\n",
      "Reconstruction: 0.036048, Regularization: 0.009665\n",
      "2019-04-09 20:44:03,426 root         INFO     ====> Epoch: 123 Average loss: 0.0432\n",
      "2019-04-09 20:44:03,447 root         INFO     Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 0.047981\n",
      "Reconstruction: 0.038225, Regularization: 0.009756\n",
      "2019-04-09 20:44:03,474 root         INFO     Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 0.044281\n",
      "Reconstruction: 0.034403, Regularization: 0.009877\n",
      "2019-04-09 20:44:03,500 root         INFO     Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 0.048928\n",
      "Reconstruction: 0.037544, Regularization: 0.011384\n",
      "2019-04-09 20:44:03,526 root         INFO     Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 0.042606\n",
      "Reconstruction: 0.033032, Regularization: 0.009574\n",
      "2019-04-09 20:44:03,553 root         INFO     Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 0.041166\n",
      "Reconstruction: 0.032763, Regularization: 0.008403\n",
      "2019-04-09 20:44:03,580 root         INFO     Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 0.035931\n",
      "Reconstruction: 0.028765, Regularization: 0.007166\n",
      "2019-04-09 20:44:03,605 root         INFO     Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 0.036410\n",
      "Reconstruction: 0.028181, Regularization: 0.008229\n",
      "2019-04-09 20:44:03,631 root         INFO     Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 0.040337\n",
      "Reconstruction: 0.031998, Regularization: 0.008339\n",
      "2019-04-09 20:44:03,668 root         INFO     ====> Epoch: 124 Average loss: 0.0428\n",
      "2019-04-09 20:44:03,689 root         INFO     Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 0.046647\n",
      "Reconstruction: 0.036637, Regularization: 0.010010\n",
      "2019-04-09 20:44:03,716 root         INFO     Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 0.048789\n",
      "Reconstruction: 0.039018, Regularization: 0.009771\n",
      "2019-04-09 20:44:03,743 root         INFO     Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 0.036541\n",
      "Reconstruction: 0.030952, Regularization: 0.005589\n",
      "2019-04-09 20:44:03,770 root         INFO     Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 0.043407\n",
      "Reconstruction: 0.035215, Regularization: 0.008192\n",
      "2019-04-09 20:44:03,797 root         INFO     Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 0.043379\n",
      "Reconstruction: 0.035431, Regularization: 0.007948\n",
      "2019-04-09 20:44:03,824 root         INFO     Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 0.044702\n",
      "Reconstruction: 0.035503, Regularization: 0.009199\n",
      "2019-04-09 20:44:03,849 root         INFO     Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 0.043207\n",
      "Reconstruction: 0.033896, Regularization: 0.009311\n",
      "2019-04-09 20:44:03,875 root         INFO     Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 0.031301\n",
      "Reconstruction: 0.025074, Regularization: 0.006227\n",
      "2019-04-09 20:44:03,911 root         INFO     ====> Epoch: 125 Average loss: 0.0430\n",
      "2019-04-09 20:44:03,932 root         INFO     Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 0.039713\n",
      "Reconstruction: 0.032385, Regularization: 0.007328\n",
      "2019-04-09 20:44:03,959 root         INFO     Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 0.041930\n",
      "Reconstruction: 0.031526, Regularization: 0.010404\n",
      "2019-04-09 20:44:03,986 root         INFO     Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 0.047031\n",
      "Reconstruction: 0.036059, Regularization: 0.010973\n",
      "2019-04-09 20:44:04,013 root         INFO     Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 0.048620\n",
      "Reconstruction: 0.037624, Regularization: 0.010996\n",
      "2019-04-09 20:44:04,040 root         INFO     Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 0.046775\n",
      "Reconstruction: 0.037593, Regularization: 0.009182\n",
      "2019-04-09 20:44:04,067 root         INFO     Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 0.041676\n",
      "Reconstruction: 0.033820, Regularization: 0.007856\n",
      "2019-04-09 20:44:04,093 root         INFO     Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 0.039952\n",
      "Reconstruction: 0.031734, Regularization: 0.008218\n",
      "2019-04-09 20:44:04,121 root         INFO     Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 0.047715\n",
      "Reconstruction: 0.037038, Regularization: 0.010677\n",
      "2019-04-09 20:44:04,159 root         INFO     ====> Epoch: 126 Average loss: 0.0430\n",
      "2019-04-09 20:44:04,180 root         INFO     Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 0.040014\n",
      "Reconstruction: 0.031484, Regularization: 0.008530\n",
      "2019-04-09 20:44:04,207 root         INFO     Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 0.038471\n",
      "Reconstruction: 0.031516, Regularization: 0.006954\n",
      "2019-04-09 20:44:04,234 root         INFO     Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 0.039810\n",
      "Reconstruction: 0.030527, Regularization: 0.009283\n",
      "2019-04-09 20:44:04,259 root         INFO     Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 0.045150\n",
      "Reconstruction: 0.034246, Regularization: 0.010904\n",
      "2019-04-09 20:44:04,285 root         INFO     Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 0.049750\n",
      "Reconstruction: 0.038546, Regularization: 0.011204\n",
      "2019-04-09 20:44:04,310 root         INFO     Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 0.047057\n",
      "Reconstruction: 0.036592, Regularization: 0.010465\n",
      "2019-04-09 20:44:04,334 root         INFO     Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 0.040585\n",
      "Reconstruction: 0.033238, Regularization: 0.007347\n",
      "2019-04-09 20:44:04,359 root         INFO     Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 0.042326\n",
      "Reconstruction: 0.032279, Regularization: 0.010047\n",
      "2019-04-09 20:44:04,396 root         INFO     ====> Epoch: 127 Average loss: 0.0425\n",
      "2019-04-09 20:44:04,417 root         INFO     Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 0.042567\n",
      "Reconstruction: 0.033423, Regularization: 0.009144\n",
      "2019-04-09 20:44:04,444 root         INFO     Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 0.034905\n",
      "Reconstruction: 0.028563, Regularization: 0.006342\n",
      "2019-04-09 20:44:04,471 root         INFO     Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 0.046333\n",
      "Reconstruction: 0.035768, Regularization: 0.010565\n",
      "2019-04-09 20:44:04,498 root         INFO     Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 0.038143\n",
      "Reconstruction: 0.030737, Regularization: 0.007406\n",
      "2019-04-09 20:44:04,524 root         INFO     Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 0.036732\n",
      "Reconstruction: 0.028436, Regularization: 0.008296\n",
      "2019-04-09 20:44:04,551 root         INFO     Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 0.042819\n",
      "Reconstruction: 0.034044, Regularization: 0.008775\n",
      "2019-04-09 20:44:04,578 root         INFO     Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 0.044142\n",
      "Reconstruction: 0.033526, Regularization: 0.010617\n",
      "2019-04-09 20:44:04,605 root         INFO     Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 0.035029\n",
      "Reconstruction: 0.028535, Regularization: 0.006494\n",
      "2019-04-09 20:44:04,643 root         INFO     ====> Epoch: 128 Average loss: 0.0426\n",
      "2019-04-09 20:44:04,664 root         INFO     Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 0.042886\n",
      "Reconstruction: 0.033104, Regularization: 0.009783\n",
      "2019-04-09 20:44:04,691 root         INFO     Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 0.048345\n",
      "Reconstruction: 0.038657, Regularization: 0.009687\n",
      "2019-04-09 20:44:04,718 root         INFO     Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 0.036137\n",
      "Reconstruction: 0.028918, Regularization: 0.007219\n",
      "2019-04-09 20:44:04,744 root         INFO     Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 0.039977\n",
      "Reconstruction: 0.032300, Regularization: 0.007677\n",
      "2019-04-09 20:44:04,771 root         INFO     Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 0.037042\n",
      "Reconstruction: 0.028450, Regularization: 0.008592\n",
      "2019-04-09 20:44:04,798 root         INFO     Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 0.039709\n",
      "Reconstruction: 0.031024, Regularization: 0.008685\n",
      "2019-04-09 20:44:04,824 root         INFO     Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 0.041935\n",
      "Reconstruction: 0.031097, Regularization: 0.010838\n",
      "2019-04-09 20:44:04,851 root         INFO     Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 0.040046\n",
      "Reconstruction: 0.032173, Regularization: 0.007873\n",
      "2019-04-09 20:44:04,889 root         INFO     ====> Epoch: 129 Average loss: 0.0423\n",
      "2019-04-09 20:44:04,911 root         INFO     Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 0.042805\n",
      "Reconstruction: 0.033105, Regularization: 0.009700\n",
      "2019-04-09 20:44:04,937 root         INFO     Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 0.039330\n",
      "Reconstruction: 0.032206, Regularization: 0.007124\n",
      "2019-04-09 20:44:04,964 root         INFO     Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 0.042112\n",
      "Reconstruction: 0.033624, Regularization: 0.008488\n",
      "2019-04-09 20:44:04,989 root         INFO     Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 0.046686\n",
      "Reconstruction: 0.036399, Regularization: 0.010287\n",
      "2019-04-09 20:44:05,015 root         INFO     Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 0.041788\n",
      "Reconstruction: 0.032430, Regularization: 0.009358\n",
      "2019-04-09 20:44:05,041 root         INFO     Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 0.039854\n",
      "Reconstruction: 0.030577, Regularization: 0.009278\n",
      "2019-04-09 20:44:05,066 root         INFO     Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 0.043545\n",
      "Reconstruction: 0.034720, Regularization: 0.008825\n",
      "2019-04-09 20:44:05,092 root         INFO     Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 0.038475\n",
      "Reconstruction: 0.030738, Regularization: 0.007737\n",
      "2019-04-09 20:44:05,129 root         INFO     ====> Epoch: 130 Average loss: 0.0426\n",
      "2019-04-09 20:44:05,150 root         INFO     Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 0.040683\n",
      "Reconstruction: 0.032862, Regularization: 0.007821\n",
      "2019-04-09 20:44:05,176 root         INFO     Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 0.047157\n",
      "Reconstruction: 0.035695, Regularization: 0.011462\n",
      "2019-04-09 20:44:05,203 root         INFO     Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 0.044422\n",
      "Reconstruction: 0.034453, Regularization: 0.009969\n",
      "2019-04-09 20:44:05,229 root         INFO     Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 0.041419\n",
      "Reconstruction: 0.033122, Regularization: 0.008298\n",
      "2019-04-09 20:44:05,255 root         INFO     Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 0.035688\n",
      "Reconstruction: 0.028635, Regularization: 0.007053\n",
      "2019-04-09 20:44:05,281 root         INFO     Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 0.043687\n",
      "Reconstruction: 0.033943, Regularization: 0.009744\n",
      "2019-04-09 20:44:05,307 root         INFO     Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 0.046930\n",
      "Reconstruction: 0.036865, Regularization: 0.010065\n",
      "2019-04-09 20:44:05,333 root         INFO     Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 0.046706\n",
      "Reconstruction: 0.036562, Regularization: 0.010144\n",
      "2019-04-09 20:44:05,370 root         INFO     ====> Epoch: 131 Average loss: 0.0422\n",
      "2019-04-09 20:44:05,391 root         INFO     Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 0.040669\n",
      "Reconstruction: 0.032180, Regularization: 0.008488\n",
      "2019-04-09 20:44:05,418 root         INFO     Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 0.048257\n",
      "Reconstruction: 0.036926, Regularization: 0.011331\n",
      "2019-04-09 20:44:05,445 root         INFO     Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 0.035479\n",
      "Reconstruction: 0.027898, Regularization: 0.007581\n",
      "2019-04-09 20:44:05,472 root         INFO     Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 0.041690\n",
      "Reconstruction: 0.032332, Regularization: 0.009359\n",
      "2019-04-09 20:44:05,499 root         INFO     Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 0.038227\n",
      "Reconstruction: 0.029781, Regularization: 0.008446\n",
      "2019-04-09 20:44:05,526 root         INFO     Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 0.042397\n",
      "Reconstruction: 0.033665, Regularization: 0.008733\n",
      "2019-04-09 20:44:05,553 root         INFO     Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 0.039014\n",
      "Reconstruction: 0.030109, Regularization: 0.008905\n",
      "2019-04-09 20:44:05,580 root         INFO     Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 0.043131\n",
      "Reconstruction: 0.035507, Regularization: 0.007624\n",
      "2019-04-09 20:44:05,618 root         INFO     ====> Epoch: 132 Average loss: 0.0422\n",
      "2019-04-09 20:44:05,640 root         INFO     Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 0.057073\n",
      "Reconstruction: 0.044580, Regularization: 0.012493\n",
      "2019-04-09 20:44:05,667 root         INFO     Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 0.046164\n",
      "Reconstruction: 0.035249, Regularization: 0.010916\n",
      "2019-04-09 20:44:05,693 root         INFO     Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 0.046748\n",
      "Reconstruction: 0.035687, Regularization: 0.011061\n",
      "2019-04-09 20:44:05,720 root         INFO     Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 0.038246\n",
      "Reconstruction: 0.029733, Regularization: 0.008513\n",
      "2019-04-09 20:44:05,747 root         INFO     Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 0.039397\n",
      "Reconstruction: 0.031875, Regularization: 0.007522\n",
      "2019-04-09 20:44:05,774 root         INFO     Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 0.045448\n",
      "Reconstruction: 0.034360, Regularization: 0.011088\n",
      "2019-04-09 20:44:05,801 root         INFO     Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 0.044141\n",
      "Reconstruction: 0.034629, Regularization: 0.009512\n",
      "2019-04-09 20:44:05,828 root         INFO     Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 0.043408\n",
      "Reconstruction: 0.031516, Regularization: 0.011892\n",
      "2019-04-09 20:44:05,866 root         INFO     ====> Epoch: 133 Average loss: 0.0420\n",
      "2019-04-09 20:44:05,887 root         INFO     Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 0.043136\n",
      "Reconstruction: 0.033095, Regularization: 0.010041\n",
      "2019-04-09 20:44:05,914 root         INFO     Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 0.040774\n",
      "Reconstruction: 0.032569, Regularization: 0.008206\n",
      "2019-04-09 20:44:05,941 root         INFO     Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 0.038640\n",
      "Reconstruction: 0.030495, Regularization: 0.008145\n",
      "2019-04-09 20:44:05,967 root         INFO     Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 0.042214\n",
      "Reconstruction: 0.032822, Regularization: 0.009392\n",
      "2019-04-09 20:44:05,993 root         INFO     Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 0.048843\n",
      "Reconstruction: 0.037868, Regularization: 0.010975\n",
      "2019-04-09 20:44:06,019 root         INFO     Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 0.047802\n",
      "Reconstruction: 0.037758, Regularization: 0.010044\n",
      "2019-04-09 20:44:06,045 root         INFO     Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 0.041568\n",
      "Reconstruction: 0.031450, Regularization: 0.010119\n",
      "2019-04-09 20:44:06,072 root         INFO     Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 0.042095\n",
      "Reconstruction: 0.031395, Regularization: 0.010700\n",
      "2019-04-09 20:44:06,109 root         INFO     ====> Epoch: 134 Average loss: 0.0422\n",
      "2019-04-09 20:44:06,131 root         INFO     Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 0.035429\n",
      "Reconstruction: 0.028269, Regularization: 0.007160\n",
      "2019-04-09 20:44:06,158 root         INFO     Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 0.045310\n",
      "Reconstruction: 0.034840, Regularization: 0.010470\n",
      "2019-04-09 20:44:06,185 root         INFO     Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 0.050408\n",
      "Reconstruction: 0.040601, Regularization: 0.009808\n",
      "2019-04-09 20:44:06,212 root         INFO     Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 0.039081\n",
      "Reconstruction: 0.028016, Regularization: 0.011065\n",
      "2019-04-09 20:44:06,239 root         INFO     Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 0.044647\n",
      "Reconstruction: 0.034405, Regularization: 0.010242\n",
      "2019-04-09 20:44:06,266 root         INFO     Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 0.040719\n",
      "Reconstruction: 0.031921, Regularization: 0.008798\n",
      "2019-04-09 20:44:06,293 root         INFO     Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 0.042745\n",
      "Reconstruction: 0.032935, Regularization: 0.009809\n",
      "2019-04-09 20:44:06,320 root         INFO     Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 0.038176\n",
      "Reconstruction: 0.030165, Regularization: 0.008011\n",
      "2019-04-09 20:44:06,358 root         INFO     ====> Epoch: 135 Average loss: 0.0419\n",
      "2019-04-09 20:44:06,380 root         INFO     Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 0.040544\n",
      "Reconstruction: 0.031020, Regularization: 0.009524\n",
      "2019-04-09 20:44:06,406 root         INFO     Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 0.049440\n",
      "Reconstruction: 0.037314, Regularization: 0.012126\n",
      "2019-04-09 20:44:06,433 root         INFO     Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 0.039346\n",
      "Reconstruction: 0.030826, Regularization: 0.008520\n",
      "2019-04-09 20:44:06,460 root         INFO     Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 0.046301\n",
      "Reconstruction: 0.035940, Regularization: 0.010361\n",
      "2019-04-09 20:44:06,487 root         INFO     Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 0.044151\n",
      "Reconstruction: 0.031986, Regularization: 0.012166\n",
      "2019-04-09 20:44:06,514 root         INFO     Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 0.043592\n",
      "Reconstruction: 0.032160, Regularization: 0.011433\n",
      "2019-04-09 20:44:06,540 root         INFO     Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 0.042164\n",
      "Reconstruction: 0.034008, Regularization: 0.008156\n",
      "2019-04-09 20:44:06,565 root         INFO     Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 0.041868\n",
      "Reconstruction: 0.032365, Regularization: 0.009502\n",
      "2019-04-09 20:44:06,602 root         INFO     ====> Epoch: 136 Average loss: 0.0421\n",
      "2019-04-09 20:44:06,623 root         INFO     Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 0.047429\n",
      "Reconstruction: 0.037363, Regularization: 0.010066\n",
      "2019-04-09 20:44:06,650 root         INFO     Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 0.040102\n",
      "Reconstruction: 0.033444, Regularization: 0.006657\n",
      "2019-04-09 20:44:06,677 root         INFO     Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 0.039499\n",
      "Reconstruction: 0.031399, Regularization: 0.008101\n",
      "2019-04-09 20:44:06,704 root         INFO     Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 0.040124\n",
      "Reconstruction: 0.031419, Regularization: 0.008705\n",
      "2019-04-09 20:44:06,731 root         INFO     Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 0.035338\n",
      "Reconstruction: 0.029690, Regularization: 0.005648\n",
      "2019-04-09 20:44:06,758 root         INFO     Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 0.046265\n",
      "Reconstruction: 0.034877, Regularization: 0.011389\n",
      "2019-04-09 20:44:06,785 root         INFO     Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 0.046290\n",
      "Reconstruction: 0.033974, Regularization: 0.012316\n",
      "2019-04-09 20:44:06,812 root         INFO     Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 0.047996\n",
      "Reconstruction: 0.037813, Regularization: 0.010183\n",
      "2019-04-09 20:44:06,850 root         INFO     ====> Epoch: 137 Average loss: 0.0422\n",
      "2019-04-09 20:44:06,872 root         INFO     Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 0.039903\n",
      "Reconstruction: 0.030091, Regularization: 0.009812\n",
      "2019-04-09 20:44:06,899 root         INFO     Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 0.028842\n",
      "Reconstruction: 0.023985, Regularization: 0.004857\n",
      "2019-04-09 20:44:06,926 root         INFO     Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 0.042364\n",
      "Reconstruction: 0.032197, Regularization: 0.010167\n",
      "2019-04-09 20:44:06,952 root         INFO     Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 0.043163\n",
      "Reconstruction: 0.033891, Regularization: 0.009272\n",
      "2019-04-09 20:44:06,979 root         INFO     Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 0.042306\n",
      "Reconstruction: 0.031715, Regularization: 0.010591\n",
      "2019-04-09 20:44:07,006 root         INFO     Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 0.041631\n",
      "Reconstruction: 0.032746, Regularization: 0.008886\n",
      "2019-04-09 20:44:07,033 root         INFO     Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 0.037631\n",
      "Reconstruction: 0.029084, Regularization: 0.008547\n",
      "2019-04-09 20:44:07,059 root         INFO     Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 0.041397\n",
      "Reconstruction: 0.032616, Regularization: 0.008781\n",
      "2019-04-09 20:44:07,097 root         INFO     ====> Epoch: 138 Average loss: 0.0418\n",
      "2019-04-09 20:44:07,119 root         INFO     Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 0.050458\n",
      "Reconstruction: 0.038865, Regularization: 0.011594\n",
      "2019-04-09 20:44:07,144 root         INFO     Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 0.041942\n",
      "Reconstruction: 0.032819, Regularization: 0.009124\n",
      "2019-04-09 20:44:07,171 root         INFO     Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 0.034441\n",
      "Reconstruction: 0.027096, Regularization: 0.007345\n",
      "2019-04-09 20:44:07,197 root         INFO     Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 0.041106\n",
      "Reconstruction: 0.031519, Regularization: 0.009587\n",
      "2019-04-09 20:44:07,224 root         INFO     Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 0.039025\n",
      "Reconstruction: 0.031819, Regularization: 0.007206\n",
      "2019-04-09 20:44:07,251 root         INFO     Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 0.037202\n",
      "Reconstruction: 0.030076, Regularization: 0.007126\n",
      "2019-04-09 20:44:07,277 root         INFO     Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 0.049100\n",
      "Reconstruction: 0.038085, Regularization: 0.011015\n",
      "2019-04-09 20:44:07,304 root         INFO     Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 0.048229\n",
      "Reconstruction: 0.037128, Regularization: 0.011101\n",
      "2019-04-09 20:44:07,341 root         INFO     ====> Epoch: 139 Average loss: 0.0417\n",
      "2019-04-09 20:44:07,363 root         INFO     Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 0.044652\n",
      "Reconstruction: 0.033986, Regularization: 0.010666\n",
      "2019-04-09 20:44:07,389 root         INFO     Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 0.038308\n",
      "Reconstruction: 0.029880, Regularization: 0.008429\n",
      "2019-04-09 20:44:07,415 root         INFO     Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 0.048770\n",
      "Reconstruction: 0.035213, Regularization: 0.013557\n",
      "2019-04-09 20:44:07,442 root         INFO     Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 0.038527\n",
      "Reconstruction: 0.030826, Regularization: 0.007701\n",
      "2019-04-09 20:44:07,468 root         INFO     Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 0.036832\n",
      "Reconstruction: 0.028806, Regularization: 0.008026\n",
      "2019-04-09 20:44:07,495 root         INFO     Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 0.047096\n",
      "Reconstruction: 0.036069, Regularization: 0.011027\n",
      "2019-04-09 20:44:07,522 root         INFO     Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 0.041184\n",
      "Reconstruction: 0.033185, Regularization: 0.007999\n",
      "2019-04-09 20:44:07,549 root         INFO     Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 0.042807\n",
      "Reconstruction: 0.030729, Regularization: 0.012078\n",
      "2019-04-09 20:44:07,586 root         INFO     ====> Epoch: 140 Average loss: 0.0417\n",
      "2019-04-09 20:44:07,607 root         INFO     Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 0.036662\n",
      "Reconstruction: 0.030024, Regularization: 0.006638\n",
      "2019-04-09 20:44:07,635 root         INFO     Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 0.044323\n",
      "Reconstruction: 0.033394, Regularization: 0.010930\n",
      "2019-04-09 20:44:07,661 root         INFO     Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 0.040043\n",
      "Reconstruction: 0.031208, Regularization: 0.008836\n",
      "2019-04-09 20:44:07,686 root         INFO     Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 0.037390\n",
      "Reconstruction: 0.029160, Regularization: 0.008230\n",
      "2019-04-09 20:44:07,712 root         INFO     Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 0.042764\n",
      "Reconstruction: 0.031030, Regularization: 0.011733\n",
      "2019-04-09 20:44:07,738 root         INFO     Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 0.050182\n",
      "Reconstruction: 0.037840, Regularization: 0.012341\n",
      "2019-04-09 20:44:07,764 root         INFO     Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 0.044653\n",
      "Reconstruction: 0.032052, Regularization: 0.012601\n",
      "2019-04-09 20:44:07,790 root         INFO     Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 0.054186\n",
      "Reconstruction: 0.041837, Regularization: 0.012349\n",
      "2019-04-09 20:44:07,827 root         INFO     ====> Epoch: 141 Average loss: 0.0420\n",
      "2019-04-09 20:44:07,848 root         INFO     Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 0.034432\n",
      "Reconstruction: 0.027588, Regularization: 0.006843\n",
      "2019-04-09 20:44:07,874 root         INFO     Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 0.046410\n",
      "Reconstruction: 0.035118, Regularization: 0.011292\n",
      "2019-04-09 20:44:07,899 root         INFO     Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 0.037906\n",
      "Reconstruction: 0.031252, Regularization: 0.006654\n",
      "2019-04-09 20:44:07,924 root         INFO     Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 0.046528\n",
      "Reconstruction: 0.035485, Regularization: 0.011044\n",
      "2019-04-09 20:44:07,949 root         INFO     Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 0.037439\n",
      "Reconstruction: 0.030852, Regularization: 0.006587\n",
      "2019-04-09 20:44:07,974 root         INFO     Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 0.041994\n",
      "Reconstruction: 0.032479, Regularization: 0.009515\n",
      "2019-04-09 20:44:08,000 root         INFO     Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 0.049269\n",
      "Reconstruction: 0.037851, Regularization: 0.011418\n",
      "2019-04-09 20:44:08,025 root         INFO     Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 0.036071\n",
      "Reconstruction: 0.027078, Regularization: 0.008993\n",
      "2019-04-09 20:44:08,063 root         INFO     ====> Epoch: 142 Average loss: 0.0419\n",
      "2019-04-09 20:44:08,084 root         INFO     Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 0.039022\n",
      "Reconstruction: 0.031275, Regularization: 0.007747\n",
      "2019-04-09 20:44:08,110 root         INFO     Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 0.039937\n",
      "Reconstruction: 0.032087, Regularization: 0.007850\n",
      "2019-04-09 20:44:08,136 root         INFO     Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 0.034358\n",
      "Reconstruction: 0.026960, Regularization: 0.007398\n",
      "2019-04-09 20:44:08,163 root         INFO     Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 0.035560\n",
      "Reconstruction: 0.027810, Regularization: 0.007750\n",
      "2019-04-09 20:44:08,190 root         INFO     Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 0.041259\n",
      "Reconstruction: 0.032479, Regularization: 0.008780\n",
      "2019-04-09 20:44:08,217 root         INFO     Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 0.039171\n",
      "Reconstruction: 0.029747, Regularization: 0.009424\n",
      "2019-04-09 20:44:08,245 root         INFO     Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 0.047095\n",
      "Reconstruction: 0.035101, Regularization: 0.011994\n",
      "2019-04-09 20:44:08,271 root         INFO     Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 0.047019\n",
      "Reconstruction: 0.035052, Regularization: 0.011967\n",
      "2019-04-09 20:44:08,309 root         INFO     ====> Epoch: 143 Average loss: 0.0418\n",
      "2019-04-09 20:44:08,330 root         INFO     Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 0.037110\n",
      "Reconstruction: 0.027920, Regularization: 0.009190\n",
      "2019-04-09 20:44:08,357 root         INFO     Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 0.040329\n",
      "Reconstruction: 0.031091, Regularization: 0.009238\n",
      "2019-04-09 20:44:08,384 root         INFO     Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 0.039691\n",
      "Reconstruction: 0.031485, Regularization: 0.008206\n",
      "2019-04-09 20:44:08,411 root         INFO     Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 0.035159\n",
      "Reconstruction: 0.028543, Regularization: 0.006616\n",
      "2019-04-09 20:44:08,437 root         INFO     Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 0.042889\n",
      "Reconstruction: 0.033074, Regularization: 0.009815\n",
      "2019-04-09 20:44:08,464 root         INFO     Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 0.044909\n",
      "Reconstruction: 0.034150, Regularization: 0.010759\n",
      "2019-04-09 20:44:08,490 root         INFO     Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 0.035137\n",
      "Reconstruction: 0.028641, Regularization: 0.006497\n",
      "2019-04-09 20:44:08,517 root         INFO     Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 0.040894\n",
      "Reconstruction: 0.030698, Regularization: 0.010197\n",
      "2019-04-09 20:44:08,554 root         INFO     ====> Epoch: 144 Average loss: 0.0415\n",
      "2019-04-09 20:44:08,576 root         INFO     Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 0.041907\n",
      "Reconstruction: 0.030192, Regularization: 0.011715\n",
      "2019-04-09 20:44:08,603 root         INFO     Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 0.037623\n",
      "Reconstruction: 0.029736, Regularization: 0.007887\n",
      "2019-04-09 20:44:08,629 root         INFO     Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 0.044902\n",
      "Reconstruction: 0.033145, Regularization: 0.011758\n",
      "2019-04-09 20:44:08,656 root         INFO     Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 0.039906\n",
      "Reconstruction: 0.030741, Regularization: 0.009165\n",
      "2019-04-09 20:44:08,683 root         INFO     Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 0.040100\n",
      "Reconstruction: 0.031389, Regularization: 0.008711\n",
      "2019-04-09 20:44:08,710 root         INFO     Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 0.051822\n",
      "Reconstruction: 0.039952, Regularization: 0.011870\n",
      "2019-04-09 20:44:08,736 root         INFO     Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 0.035107\n",
      "Reconstruction: 0.027871, Regularization: 0.007237\n",
      "2019-04-09 20:44:08,763 root         INFO     Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 0.040762\n",
      "Reconstruction: 0.031584, Regularization: 0.009178\n",
      "2019-04-09 20:44:08,801 root         INFO     ====> Epoch: 145 Average loss: 0.0416\n",
      "2019-04-09 20:44:08,822 root         INFO     Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 0.048697\n",
      "Reconstruction: 0.036763, Regularization: 0.011934\n",
      "2019-04-09 20:44:08,849 root         INFO     Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 0.036445\n",
      "Reconstruction: 0.029067, Regularization: 0.007378\n",
      "2019-04-09 20:44:08,876 root         INFO     Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 0.040891\n",
      "Reconstruction: 0.032875, Regularization: 0.008016\n",
      "2019-04-09 20:44:08,903 root         INFO     Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 0.038922\n",
      "Reconstruction: 0.028827, Regularization: 0.010095\n",
      "2019-04-09 20:44:08,930 root         INFO     Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 0.048212\n",
      "Reconstruction: 0.035673, Regularization: 0.012539\n",
      "2019-04-09 20:44:08,956 root         INFO     Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 0.036605\n",
      "Reconstruction: 0.029710, Regularization: 0.006895\n",
      "2019-04-09 20:44:08,983 root         INFO     Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 0.047040\n",
      "Reconstruction: 0.035324, Regularization: 0.011717\n",
      "2019-04-09 20:44:09,009 root         INFO     Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 0.042919\n",
      "Reconstruction: 0.032304, Regularization: 0.010615\n",
      "2019-04-09 20:44:09,047 root         INFO     ====> Epoch: 146 Average loss: 0.0417\n",
      "2019-04-09 20:44:09,068 root         INFO     Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 0.045649\n",
      "Reconstruction: 0.035457, Regularization: 0.010192\n",
      "2019-04-09 20:44:09,096 root         INFO     Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 0.047870\n",
      "Reconstruction: 0.036286, Regularization: 0.011584\n",
      "2019-04-09 20:44:09,123 root         INFO     Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 0.046166\n",
      "Reconstruction: 0.036831, Regularization: 0.009335\n",
      "2019-04-09 20:44:09,149 root         INFO     Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 0.039384\n",
      "Reconstruction: 0.031464, Regularization: 0.007920\n",
      "2019-04-09 20:44:09,174 root         INFO     Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 0.044216\n",
      "Reconstruction: 0.032953, Regularization: 0.011263\n",
      "2019-04-09 20:44:09,200 root         INFO     Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 0.036251\n",
      "Reconstruction: 0.029052, Regularization: 0.007199\n",
      "2019-04-09 20:44:09,226 root         INFO     Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 0.041553\n",
      "Reconstruction: 0.031497, Regularization: 0.010056\n",
      "2019-04-09 20:44:09,253 root         INFO     Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 0.041175\n",
      "Reconstruction: 0.030458, Regularization: 0.010717\n",
      "2019-04-09 20:44:09,289 root         INFO     ====> Epoch: 147 Average loss: 0.0420\n",
      "2019-04-09 20:44:09,311 root         INFO     Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 0.040653\n",
      "Reconstruction: 0.030073, Regularization: 0.010579\n",
      "2019-04-09 20:44:09,338 root         INFO     Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 0.043591\n",
      "Reconstruction: 0.034186, Regularization: 0.009404\n",
      "2019-04-09 20:44:09,366 root         INFO     Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 0.033426\n",
      "Reconstruction: 0.027216, Regularization: 0.006210\n",
      "2019-04-09 20:44:09,393 root         INFO     Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 0.039310\n",
      "Reconstruction: 0.031700, Regularization: 0.007611\n",
      "2019-04-09 20:44:09,420 root         INFO     Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 0.035368\n",
      "Reconstruction: 0.027971, Regularization: 0.007398\n",
      "2019-04-09 20:44:09,448 root         INFO     Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 0.046029\n",
      "Reconstruction: 0.033955, Regularization: 0.012073\n",
      "2019-04-09 20:44:09,475 root         INFO     Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 0.043827\n",
      "Reconstruction: 0.033425, Regularization: 0.010401\n",
      "2019-04-09 20:44:09,503 root         INFO     Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 0.037898\n",
      "Reconstruction: 0.029054, Regularization: 0.008844\n",
      "2019-04-09 20:44:09,540 root         INFO     ====> Epoch: 148 Average loss: 0.0414\n",
      "2019-04-09 20:44:09,562 root         INFO     Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 0.038223\n",
      "Reconstruction: 0.028960, Regularization: 0.009263\n",
      "2019-04-09 20:44:09,589 root         INFO     Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 0.037218\n",
      "Reconstruction: 0.028855, Regularization: 0.008363\n",
      "2019-04-09 20:44:09,615 root         INFO     Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 0.039326\n",
      "Reconstruction: 0.029901, Regularization: 0.009425\n",
      "2019-04-09 20:44:09,642 root         INFO     Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 0.048040\n",
      "Reconstruction: 0.037091, Regularization: 0.010949\n",
      "2019-04-09 20:44:09,669 root         INFO     Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 0.038806\n",
      "Reconstruction: 0.028482, Regularization: 0.010324\n",
      "2019-04-09 20:44:09,696 root         INFO     Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 0.043039\n",
      "Reconstruction: 0.034416, Regularization: 0.008623\n",
      "2019-04-09 20:44:09,724 root         INFO     Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 0.046650\n",
      "Reconstruction: 0.033361, Regularization: 0.013289\n",
      "2019-04-09 20:44:09,751 root         INFO     Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 0.038134\n",
      "Reconstruction: 0.028985, Regularization: 0.009149\n",
      "2019-04-09 20:44:09,789 root         INFO     ====> Epoch: 149 Average loss: 0.0415\n",
      "2019-04-09 20:44:09,811 root         INFO     Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 0.038988\n",
      "Reconstruction: 0.030571, Regularization: 0.008417\n",
      "2019-04-09 20:44:09,839 root         INFO     Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 0.041438\n",
      "Reconstruction: 0.031484, Regularization: 0.009954\n",
      "2019-04-09 20:44:09,866 root         INFO     Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 0.043230\n",
      "Reconstruction: 0.031822, Regularization: 0.011408\n",
      "2019-04-09 20:44:09,894 root         INFO     Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 0.042989\n",
      "Reconstruction: 0.032893, Regularization: 0.010097\n",
      "2019-04-09 20:44:09,921 root         INFO     Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 0.035729\n",
      "Reconstruction: 0.027874, Regularization: 0.007855\n",
      "2019-04-09 20:44:09,949 root         INFO     Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 0.050521\n",
      "Reconstruction: 0.037985, Regularization: 0.012537\n",
      "2019-04-09 20:44:09,976 root         INFO     Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 0.036805\n",
      "Reconstruction: 0.028844, Regularization: 0.007961\n",
      "2019-04-09 20:44:10,003 root         INFO     Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 0.039327\n",
      "Reconstruction: 0.029628, Regularization: 0.009699\n",
      "2019-04-09 20:44:10,043 root         INFO     ====> Epoch: 150 Average loss: 0.0416\n",
      "2019-04-09 20:44:10,064 root         INFO     Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 0.037986\n",
      "Reconstruction: 0.029416, Regularization: 0.008570\n",
      "2019-04-09 20:44:10,091 root         INFO     Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 0.045360\n",
      "Reconstruction: 0.034467, Regularization: 0.010893\n",
      "2019-04-09 20:44:10,117 root         INFO     Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 0.042792\n",
      "Reconstruction: 0.032429, Regularization: 0.010362\n",
      "2019-04-09 20:44:10,144 root         INFO     Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 0.047880\n",
      "Reconstruction: 0.038105, Regularization: 0.009775\n",
      "2019-04-09 20:44:10,171 root         INFO     Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 0.045370\n",
      "Reconstruction: 0.035707, Regularization: 0.009662\n",
      "2019-04-09 20:44:10,197 root         INFO     Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 0.033033\n",
      "Reconstruction: 0.026587, Regularization: 0.006446\n",
      "2019-04-09 20:44:10,224 root         INFO     Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 0.042824\n",
      "Reconstruction: 0.032194, Regularization: 0.010630\n",
      "2019-04-09 20:44:10,250 root         INFO     Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 0.036330\n",
      "Reconstruction: 0.029808, Regularization: 0.006522\n",
      "2019-04-09 20:44:10,288 root         INFO     ====> Epoch: 151 Average loss: 0.0417\n",
      "2019-04-09 20:44:10,310 root         INFO     Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 0.048562\n",
      "Reconstruction: 0.037516, Regularization: 0.011046\n",
      "2019-04-09 20:44:10,336 root         INFO     Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 0.045234\n",
      "Reconstruction: 0.035391, Regularization: 0.009843\n",
      "2019-04-09 20:44:10,362 root         INFO     Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 0.044593\n",
      "Reconstruction: 0.033786, Regularization: 0.010808\n",
      "2019-04-09 20:44:10,388 root         INFO     Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 0.049749\n",
      "Reconstruction: 0.037578, Regularization: 0.012171\n",
      "2019-04-09 20:44:10,414 root         INFO     Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 0.036079\n",
      "Reconstruction: 0.026161, Regularization: 0.009919\n",
      "2019-04-09 20:44:10,440 root         INFO     Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 0.042463\n",
      "Reconstruction: 0.031984, Regularization: 0.010479\n",
      "2019-04-09 20:44:10,465 root         INFO     Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 0.038718\n",
      "Reconstruction: 0.030068, Regularization: 0.008650\n",
      "2019-04-09 20:44:10,491 root         INFO     Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 0.035818\n",
      "Reconstruction: 0.028202, Regularization: 0.007616\n",
      "2019-04-09 20:44:10,528 root         INFO     ====> Epoch: 152 Average loss: 0.0414\n",
      "2019-04-09 20:44:10,549 root         INFO     Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 0.044039\n",
      "Reconstruction: 0.033743, Regularization: 0.010295\n",
      "2019-04-09 20:44:10,577 root         INFO     Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 0.046014\n",
      "Reconstruction: 0.034605, Regularization: 0.011410\n",
      "2019-04-09 20:44:10,604 root         INFO     Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 0.053767\n",
      "Reconstruction: 0.041051, Regularization: 0.012716\n",
      "2019-04-09 20:44:10,631 root         INFO     Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 0.047258\n",
      "Reconstruction: 0.037267, Regularization: 0.009990\n",
      "2019-04-09 20:44:10,659 root         INFO     Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 0.033947\n",
      "Reconstruction: 0.026866, Regularization: 0.007081\n",
      "2019-04-09 20:44:10,686 root         INFO     Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 0.042640\n",
      "Reconstruction: 0.032529, Regularization: 0.010111\n",
      "2019-04-09 20:44:10,713 root         INFO     Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 0.041699\n",
      "Reconstruction: 0.031730, Regularization: 0.009968\n",
      "2019-04-09 20:44:10,740 root         INFO     Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 0.046464\n",
      "Reconstruction: 0.035349, Regularization: 0.011115\n",
      "2019-04-09 20:44:10,778 root         INFO     ====> Epoch: 153 Average loss: 0.0415\n",
      "2019-04-09 20:44:10,799 root         INFO     Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 0.039245\n",
      "Reconstruction: 0.030408, Regularization: 0.008837\n",
      "2019-04-09 20:44:10,827 root         INFO     Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 0.048873\n",
      "Reconstruction: 0.038174, Regularization: 0.010699\n",
      "2019-04-09 20:44:10,854 root         INFO     Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 0.047012\n",
      "Reconstruction: 0.036847, Regularization: 0.010165\n",
      "2019-04-09 20:44:10,879 root         INFO     Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 0.037955\n",
      "Reconstruction: 0.029544, Regularization: 0.008412\n",
      "2019-04-09 20:44:10,904 root         INFO     Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 0.043697\n",
      "Reconstruction: 0.033369, Regularization: 0.010328\n",
      "2019-04-09 20:44:10,930 root         INFO     Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 0.048103\n",
      "Reconstruction: 0.036954, Regularization: 0.011149\n",
      "2019-04-09 20:44:10,957 root         INFO     Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 0.035433\n",
      "Reconstruction: 0.028239, Regularization: 0.007194\n",
      "2019-04-09 20:44:10,983 root         INFO     Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 0.049005\n",
      "Reconstruction: 0.035853, Regularization: 0.013152\n",
      "2019-04-09 20:44:11,020 root         INFO     ====> Epoch: 154 Average loss: 0.0411\n",
      "2019-04-09 20:44:11,041 root         INFO     Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 0.040419\n",
      "Reconstruction: 0.030108, Regularization: 0.010312\n",
      "2019-04-09 20:44:11,068 root         INFO     Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 0.044470\n",
      "Reconstruction: 0.034237, Regularization: 0.010233\n",
      "2019-04-09 20:44:11,094 root         INFO     Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 0.040342\n",
      "Reconstruction: 0.031346, Regularization: 0.008997\n",
      "2019-04-09 20:44:11,119 root         INFO     Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 0.040637\n",
      "Reconstruction: 0.031611, Regularization: 0.009026\n",
      "2019-04-09 20:44:11,145 root         INFO     Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 0.046110\n",
      "Reconstruction: 0.033784, Regularization: 0.012326\n",
      "2019-04-09 20:44:11,172 root         INFO     Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 0.041782\n",
      "Reconstruction: 0.031804, Regularization: 0.009977\n",
      "2019-04-09 20:44:11,198 root         INFO     Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 0.037378\n",
      "Reconstruction: 0.028554, Regularization: 0.008824\n",
      "2019-04-09 20:44:11,225 root         INFO     Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 0.043675\n",
      "Reconstruction: 0.031955, Regularization: 0.011720\n",
      "2019-04-09 20:44:11,264 root         INFO     ====> Epoch: 155 Average loss: 0.0408\n",
      "2019-04-09 20:44:11,285 root         INFO     Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 0.040185\n",
      "Reconstruction: 0.031796, Regularization: 0.008389\n",
      "2019-04-09 20:44:11,312 root         INFO     Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 0.047699\n",
      "Reconstruction: 0.035173, Regularization: 0.012526\n",
      "2019-04-09 20:44:11,340 root         INFO     Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 0.040198\n",
      "Reconstruction: 0.031442, Regularization: 0.008756\n",
      "2019-04-09 20:44:11,367 root         INFO     Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 0.050562\n",
      "Reconstruction: 0.039245, Regularization: 0.011317\n",
      "2019-04-09 20:44:11,395 root         INFO     Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 0.043097\n",
      "Reconstruction: 0.034305, Regularization: 0.008792\n",
      "2019-04-09 20:44:11,421 root         INFO     Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 0.038869\n",
      "Reconstruction: 0.030135, Regularization: 0.008734\n",
      "2019-04-09 20:44:11,447 root         INFO     Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 0.042234\n",
      "Reconstruction: 0.031571, Regularization: 0.010664\n",
      "2019-04-09 20:44:11,473 root         INFO     Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 0.036302\n",
      "Reconstruction: 0.029418, Regularization: 0.006884\n",
      "2019-04-09 20:44:11,511 root         INFO     ====> Epoch: 156 Average loss: 0.0411\n",
      "2019-04-09 20:44:11,532 root         INFO     Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 0.041740\n",
      "Reconstruction: 0.034491, Regularization: 0.007249\n",
      "2019-04-09 20:44:11,558 root         INFO     Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 0.035778\n",
      "Reconstruction: 0.026993, Regularization: 0.008785\n",
      "2019-04-09 20:44:11,586 root         INFO     Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 0.038439\n",
      "Reconstruction: 0.029041, Regularization: 0.009398\n",
      "2019-04-09 20:44:11,614 root         INFO     Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 0.035651\n",
      "Reconstruction: 0.028224, Regularization: 0.007426\n",
      "2019-04-09 20:44:11,643 root         INFO     Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 0.045403\n",
      "Reconstruction: 0.034012, Regularization: 0.011391\n",
      "2019-04-09 20:44:11,671 root         INFO     Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 0.039025\n",
      "Reconstruction: 0.031242, Regularization: 0.007783\n",
      "2019-04-09 20:44:11,700 root         INFO     Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 0.027861\n",
      "Reconstruction: 0.023498, Regularization: 0.004363\n",
      "2019-04-09 20:44:11,727 root         INFO     Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 0.041791\n",
      "Reconstruction: 0.032298, Regularization: 0.009494\n",
      "2019-04-09 20:44:11,766 root         INFO     ====> Epoch: 157 Average loss: 0.0411\n",
      "2019-04-09 20:44:11,787 root         INFO     Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 0.045049\n",
      "Reconstruction: 0.034797, Regularization: 0.010253\n",
      "2019-04-09 20:44:11,815 root         INFO     Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 0.041893\n",
      "Reconstruction: 0.033664, Regularization: 0.008229\n",
      "2019-04-09 20:44:11,842 root         INFO     Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 0.040785\n",
      "Reconstruction: 0.031489, Regularization: 0.009295\n",
      "2019-04-09 20:44:11,870 root         INFO     Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 0.041371\n",
      "Reconstruction: 0.032915, Regularization: 0.008456\n",
      "2019-04-09 20:44:11,897 root         INFO     Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 0.038408\n",
      "Reconstruction: 0.028521, Regularization: 0.009888\n",
      "2019-04-09 20:44:11,924 root         INFO     Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 0.037321\n",
      "Reconstruction: 0.029726, Regularization: 0.007595\n",
      "2019-04-09 20:44:11,951 root         INFO     Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 0.040589\n",
      "Reconstruction: 0.030485, Regularization: 0.010104\n",
      "2019-04-09 20:44:11,979 root         INFO     Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 0.044128\n",
      "Reconstruction: 0.034530, Regularization: 0.009598\n",
      "2019-04-09 20:44:12,017 root         INFO     ====> Epoch: 158 Average loss: 0.0413\n",
      "2019-04-09 20:44:12,038 root         INFO     Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 0.042081\n",
      "Reconstruction: 0.032051, Regularization: 0.010030\n",
      "2019-04-09 20:44:12,066 root         INFO     Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 0.040803\n",
      "Reconstruction: 0.029837, Regularization: 0.010966\n",
      "2019-04-09 20:44:12,094 root         INFO     Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 0.037065\n",
      "Reconstruction: 0.029694, Regularization: 0.007371\n",
      "2019-04-09 20:44:12,121 root         INFO     Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 0.039717\n",
      "Reconstruction: 0.031093, Regularization: 0.008624\n",
      "2019-04-09 20:44:12,148 root         INFO     Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 0.038866\n",
      "Reconstruction: 0.030215, Regularization: 0.008652\n",
      "2019-04-09 20:44:12,175 root         INFO     Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 0.042288\n",
      "Reconstruction: 0.030847, Regularization: 0.011440\n",
      "2019-04-09 20:44:12,203 root         INFO     Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 0.044323\n",
      "Reconstruction: 0.034748, Regularization: 0.009575\n",
      "2019-04-09 20:44:12,231 root         INFO     Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 0.044004\n",
      "Reconstruction: 0.034669, Regularization: 0.009335\n",
      "2019-04-09 20:44:12,269 root         INFO     ====> Epoch: 159 Average loss: 0.0412\n",
      "2019-04-09 20:44:12,290 root         INFO     Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 0.038013\n",
      "Reconstruction: 0.031259, Regularization: 0.006754\n",
      "2019-04-09 20:44:12,318 root         INFO     Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 0.041107\n",
      "Reconstruction: 0.030321, Regularization: 0.010786\n",
      "2019-04-09 20:44:12,345 root         INFO     Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 0.038510\n",
      "Reconstruction: 0.029394, Regularization: 0.009116\n",
      "2019-04-09 20:44:12,372 root         INFO     Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 0.037726\n",
      "Reconstruction: 0.030076, Regularization: 0.007650\n",
      "2019-04-09 20:44:12,400 root         INFO     Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 0.038973\n",
      "Reconstruction: 0.030742, Regularization: 0.008231\n",
      "2019-04-09 20:44:12,426 root         INFO     Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 0.039013\n",
      "Reconstruction: 0.030120, Regularization: 0.008893\n",
      "2019-04-09 20:44:12,452 root         INFO     Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 0.039395\n",
      "Reconstruction: 0.029848, Regularization: 0.009547\n",
      "2019-04-09 20:44:12,477 root         INFO     Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 0.034898\n",
      "Reconstruction: 0.027441, Regularization: 0.007456\n",
      "2019-04-09 20:44:12,514 root         INFO     ====> Epoch: 160 Average loss: 0.0413\n",
      "2019-04-09 20:44:12,535 root         INFO     Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 0.040181\n",
      "Reconstruction: 0.032019, Regularization: 0.008162\n",
      "2019-04-09 20:44:12,562 root         INFO     Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 0.046044\n",
      "Reconstruction: 0.035003, Regularization: 0.011041\n",
      "2019-04-09 20:44:12,589 root         INFO     Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 0.041127\n",
      "Reconstruction: 0.033116, Regularization: 0.008011\n",
      "2019-04-09 20:44:12,616 root         INFO     Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 0.047873\n",
      "Reconstruction: 0.036496, Regularization: 0.011377\n",
      "2019-04-09 20:44:12,642 root         INFO     Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 0.043680\n",
      "Reconstruction: 0.033377, Regularization: 0.010304\n",
      "2019-04-09 20:44:12,669 root         INFO     Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 0.040226\n",
      "Reconstruction: 0.031427, Regularization: 0.008799\n",
      "2019-04-09 20:44:12,696 root         INFO     Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 0.037453\n",
      "Reconstruction: 0.029389, Regularization: 0.008065\n",
      "2019-04-09 20:44:12,723 root         INFO     Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 0.037687\n",
      "Reconstruction: 0.028964, Regularization: 0.008723\n",
      "2019-04-09 20:44:12,761 root         INFO     ====> Epoch: 161 Average loss: 0.0412\n",
      "2019-04-09 20:44:12,782 root         INFO     Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 0.044171\n",
      "Reconstruction: 0.035841, Regularization: 0.008330\n",
      "2019-04-09 20:44:12,808 root         INFO     Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 0.038853\n",
      "Reconstruction: 0.030203, Regularization: 0.008650\n",
      "2019-04-09 20:44:12,835 root         INFO     Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 0.040021\n",
      "Reconstruction: 0.030973, Regularization: 0.009047\n",
      "2019-04-09 20:44:12,861 root         INFO     Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 0.042077\n",
      "Reconstruction: 0.031723, Regularization: 0.010354\n",
      "2019-04-09 20:44:12,887 root         INFO     Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 0.044731\n",
      "Reconstruction: 0.030871, Regularization: 0.013860\n",
      "2019-04-09 20:44:12,914 root         INFO     Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 0.045703\n",
      "Reconstruction: 0.034831, Regularization: 0.010872\n",
      "2019-04-09 20:44:12,940 root         INFO     Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 0.043755\n",
      "Reconstruction: 0.033978, Regularization: 0.009776\n",
      "2019-04-09 20:44:12,967 root         INFO     Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 0.040560\n",
      "Reconstruction: 0.030762, Regularization: 0.009798\n",
      "2019-04-09 20:44:13,004 root         INFO     ====> Epoch: 162 Average loss: 0.0413\n",
      "2019-04-09 20:44:13,025 root         INFO     Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 0.041464\n",
      "Reconstruction: 0.031278, Regularization: 0.010186\n",
      "2019-04-09 20:44:13,052 root         INFO     Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 0.043721\n",
      "Reconstruction: 0.032414, Regularization: 0.011307\n",
      "2019-04-09 20:44:13,080 root         INFO     Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 0.042425\n",
      "Reconstruction: 0.031491, Regularization: 0.010934\n",
      "2019-04-09 20:44:13,107 root         INFO     Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 0.037051\n",
      "Reconstruction: 0.029824, Regularization: 0.007227\n",
      "2019-04-09 20:44:13,133 root         INFO     Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 0.042176\n",
      "Reconstruction: 0.032479, Regularization: 0.009697\n",
      "2019-04-09 20:44:13,159 root         INFO     Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 0.040468\n",
      "Reconstruction: 0.029691, Regularization: 0.010777\n",
      "2019-04-09 20:44:13,184 root         INFO     Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 0.036849\n",
      "Reconstruction: 0.027166, Regularization: 0.009683\n",
      "2019-04-09 20:44:13,210 root         INFO     Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 0.054506\n",
      "Reconstruction: 0.041452, Regularization: 0.013054\n",
      "2019-04-09 20:44:13,247 root         INFO     ====> Epoch: 163 Average loss: 0.0418\n",
      "2019-04-09 20:44:13,268 root         INFO     Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 0.048400\n",
      "Reconstruction: 0.037453, Regularization: 0.010947\n",
      "2019-04-09 20:44:13,295 root         INFO     Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 0.049547\n",
      "Reconstruction: 0.037866, Regularization: 0.011681\n",
      "2019-04-09 20:44:13,321 root         INFO     Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 0.041864\n",
      "Reconstruction: 0.032076, Regularization: 0.009788\n",
      "2019-04-09 20:44:13,347 root         INFO     Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 0.043545\n",
      "Reconstruction: 0.033551, Regularization: 0.009995\n",
      "2019-04-09 20:44:13,372 root         INFO     Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 0.037728\n",
      "Reconstruction: 0.028498, Regularization: 0.009230\n",
      "2019-04-09 20:44:13,398 root         INFO     Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 0.036860\n",
      "Reconstruction: 0.028564, Regularization: 0.008295\n",
      "2019-04-09 20:44:13,423 root         INFO     Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 0.034648\n",
      "Reconstruction: 0.028240, Regularization: 0.006408\n",
      "2019-04-09 20:44:13,449 root         INFO     Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 0.035265\n",
      "Reconstruction: 0.025862, Regularization: 0.009403\n",
      "2019-04-09 20:44:13,486 root         INFO     ====> Epoch: 164 Average loss: 0.0411\n",
      "2019-04-09 20:44:13,507 root         INFO     Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 0.033545\n",
      "Reconstruction: 0.026696, Regularization: 0.006848\n",
      "2019-04-09 20:44:13,534 root         INFO     Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 0.043728\n",
      "Reconstruction: 0.033178, Regularization: 0.010550\n",
      "2019-04-09 20:44:13,561 root         INFO     Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 0.036654\n",
      "Reconstruction: 0.029819, Regularization: 0.006835\n",
      "2019-04-09 20:44:13,588 root         INFO     Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 0.043669\n",
      "Reconstruction: 0.032711, Regularization: 0.010958\n",
      "2019-04-09 20:44:13,615 root         INFO     Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 0.038295\n",
      "Reconstruction: 0.029985, Regularization: 0.008310\n",
      "2019-04-09 20:44:13,642 root         INFO     Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 0.041090\n",
      "Reconstruction: 0.032154, Regularization: 0.008936\n",
      "2019-04-09 20:44:13,669 root         INFO     Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 0.040612\n",
      "Reconstruction: 0.031076, Regularization: 0.009537\n",
      "2019-04-09 20:44:13,696 root         INFO     Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 0.042232\n",
      "Reconstruction: 0.031525, Regularization: 0.010707\n",
      "2019-04-09 20:44:13,733 root         INFO     ====> Epoch: 165 Average loss: 0.0415\n",
      "2019-04-09 20:44:13,755 root         INFO     Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 0.042176\n",
      "Reconstruction: 0.030719, Regularization: 0.011457\n",
      "2019-04-09 20:44:13,781 root         INFO     Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 0.036744\n",
      "Reconstruction: 0.026988, Regularization: 0.009756\n",
      "2019-04-09 20:44:13,806 root         INFO     Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 0.038996\n",
      "Reconstruction: 0.028813, Regularization: 0.010183\n",
      "2019-04-09 20:44:13,831 root         INFO     Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 0.042047\n",
      "Reconstruction: 0.031335, Regularization: 0.010712\n",
      "2019-04-09 20:44:13,857 root         INFO     Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 0.037270\n",
      "Reconstruction: 0.028976, Regularization: 0.008295\n",
      "2019-04-09 20:44:13,883 root         INFO     Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 0.035434\n",
      "Reconstruction: 0.027416, Regularization: 0.008017\n",
      "2019-04-09 20:44:13,910 root         INFO     Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 0.040107\n",
      "Reconstruction: 0.030614, Regularization: 0.009494\n",
      "2019-04-09 20:44:13,936 root         INFO     Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 0.044404\n",
      "Reconstruction: 0.034733, Regularization: 0.009671\n",
      "2019-04-09 20:44:13,975 root         INFO     ====> Epoch: 166 Average loss: 0.0411\n",
      "2019-04-09 20:44:13,996 root         INFO     Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 0.038625\n",
      "Reconstruction: 0.028775, Regularization: 0.009851\n",
      "2019-04-09 20:44:14,023 root         INFO     Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 0.039452\n",
      "Reconstruction: 0.031195, Regularization: 0.008257\n",
      "2019-04-09 20:44:14,050 root         INFO     Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 0.044365\n",
      "Reconstruction: 0.034443, Regularization: 0.009922\n",
      "2019-04-09 20:44:14,076 root         INFO     Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 0.040669\n",
      "Reconstruction: 0.030989, Regularization: 0.009680\n",
      "2019-04-09 20:44:14,102 root         INFO     Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 0.043795\n",
      "Reconstruction: 0.031279, Regularization: 0.012516\n",
      "2019-04-09 20:44:14,128 root         INFO     Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 0.040343\n",
      "Reconstruction: 0.029939, Regularization: 0.010404\n",
      "2019-04-09 20:44:14,154 root         INFO     Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 0.044074\n",
      "Reconstruction: 0.034126, Regularization: 0.009947\n",
      "2019-04-09 20:44:14,180 root         INFO     Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 0.037168\n",
      "Reconstruction: 0.028408, Regularization: 0.008761\n",
      "2019-04-09 20:44:14,218 root         INFO     ====> Epoch: 167 Average loss: 0.0410\n",
      "2019-04-09 20:44:14,239 root         INFO     Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 0.039233\n",
      "Reconstruction: 0.030722, Regularization: 0.008511\n",
      "2019-04-09 20:44:14,265 root         INFO     Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 0.050548\n",
      "Reconstruction: 0.037063, Regularization: 0.013485\n",
      "2019-04-09 20:44:14,291 root         INFO     Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 0.038403\n",
      "Reconstruction: 0.030566, Regularization: 0.007837\n",
      "2019-04-09 20:44:14,317 root         INFO     Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 0.043673\n",
      "Reconstruction: 0.031994, Regularization: 0.011680\n",
      "2019-04-09 20:44:14,343 root         INFO     Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 0.046795\n",
      "Reconstruction: 0.037097, Regularization: 0.009698\n",
      "2019-04-09 20:44:14,369 root         INFO     Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 0.050076\n",
      "Reconstruction: 0.036357, Regularization: 0.013719\n",
      "2019-04-09 20:44:14,394 root         INFO     Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 0.036374\n",
      "Reconstruction: 0.027341, Regularization: 0.009034\n",
      "2019-04-09 20:44:14,420 root         INFO     Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 0.042638\n",
      "Reconstruction: 0.031586, Regularization: 0.011051\n",
      "2019-04-09 20:44:14,457 root         INFO     ====> Epoch: 168 Average loss: 0.0415\n",
      "2019-04-09 20:44:14,478 root         INFO     Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 0.047832\n",
      "Reconstruction: 0.037254, Regularization: 0.010578\n",
      "2019-04-09 20:44:14,506 root         INFO     Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 0.045435\n",
      "Reconstruction: 0.032918, Regularization: 0.012517\n",
      "2019-04-09 20:44:14,533 root         INFO     Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 0.043712\n",
      "Reconstruction: 0.032039, Regularization: 0.011674\n",
      "2019-04-09 20:44:14,560 root         INFO     Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 0.041664\n",
      "Reconstruction: 0.032603, Regularization: 0.009062\n",
      "2019-04-09 20:44:14,586 root         INFO     Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 0.037175\n",
      "Reconstruction: 0.027568, Regularization: 0.009607\n",
      "2019-04-09 20:44:14,613 root         INFO     Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 0.043489\n",
      "Reconstruction: 0.031033, Regularization: 0.012457\n",
      "2019-04-09 20:44:14,641 root         INFO     Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 0.034855\n",
      "Reconstruction: 0.029657, Regularization: 0.005198\n",
      "2019-04-09 20:44:14,668 root         INFO     Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 0.045528\n",
      "Reconstruction: 0.034945, Regularization: 0.010583\n",
      "2019-04-09 20:44:14,706 root         INFO     ====> Epoch: 169 Average loss: 0.0411\n",
      "2019-04-09 20:44:14,728 root         INFO     Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 0.042493\n",
      "Reconstruction: 0.032373, Regularization: 0.010120\n",
      "2019-04-09 20:44:14,754 root         INFO     Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 0.035361\n",
      "Reconstruction: 0.028597, Regularization: 0.006764\n",
      "2019-04-09 20:44:14,781 root         INFO     Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 0.040650\n",
      "Reconstruction: 0.030409, Regularization: 0.010241\n",
      "2019-04-09 20:44:14,807 root         INFO     Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 0.045827\n",
      "Reconstruction: 0.033470, Regularization: 0.012357\n",
      "2019-04-09 20:44:14,834 root         INFO     Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 0.036532\n",
      "Reconstruction: 0.028509, Regularization: 0.008023\n",
      "2019-04-09 20:44:14,861 root         INFO     Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 0.041133\n",
      "Reconstruction: 0.032756, Regularization: 0.008377\n",
      "2019-04-09 20:44:14,887 root         INFO     Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 0.040854\n",
      "Reconstruction: 0.032706, Regularization: 0.008148\n",
      "2019-04-09 20:44:14,914 root         INFO     Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 0.043752\n",
      "Reconstruction: 0.031560, Regularization: 0.012192\n",
      "2019-04-09 20:44:14,951 root         INFO     ====> Epoch: 170 Average loss: 0.0412\n",
      "2019-04-09 20:44:14,973 root         INFO     Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 0.047353\n",
      "Reconstruction: 0.036047, Regularization: 0.011306\n",
      "2019-04-09 20:44:15,000 root         INFO     Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 0.038600\n",
      "Reconstruction: 0.029486, Regularization: 0.009114\n",
      "2019-04-09 20:44:15,026 root         INFO     Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 0.050949\n",
      "Reconstruction: 0.038952, Regularization: 0.011998\n",
      "2019-04-09 20:44:15,052 root         INFO     Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 0.041686\n",
      "Reconstruction: 0.030079, Regularization: 0.011606\n",
      "2019-04-09 20:44:15,077 root         INFO     Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 0.035078\n",
      "Reconstruction: 0.027357, Regularization: 0.007721\n",
      "2019-04-09 20:44:15,103 root         INFO     Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 0.041778\n",
      "Reconstruction: 0.033309, Regularization: 0.008469\n",
      "2019-04-09 20:44:15,129 root         INFO     Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 0.037690\n",
      "Reconstruction: 0.029128, Regularization: 0.008562\n",
      "2019-04-09 20:44:15,155 root         INFO     Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 0.043333\n",
      "Reconstruction: 0.030505, Regularization: 0.012828\n",
      "2019-04-09 20:44:15,192 root         INFO     ====> Epoch: 171 Average loss: 0.0416\n",
      "2019-04-09 20:44:15,213 root         INFO     Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 0.045878\n",
      "Reconstruction: 0.035851, Regularization: 0.010027\n",
      "2019-04-09 20:44:15,241 root         INFO     Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 0.036968\n",
      "Reconstruction: 0.028979, Regularization: 0.007989\n",
      "2019-04-09 20:44:15,268 root         INFO     Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 0.040990\n",
      "Reconstruction: 0.031140, Regularization: 0.009850\n",
      "2019-04-09 20:44:15,294 root         INFO     Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 0.046920\n",
      "Reconstruction: 0.035507, Regularization: 0.011413\n",
      "2019-04-09 20:44:15,321 root         INFO     Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 0.037451\n",
      "Reconstruction: 0.028749, Regularization: 0.008702\n",
      "2019-04-09 20:44:15,348 root         INFO     Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 0.042095\n",
      "Reconstruction: 0.032902, Regularization: 0.009193\n",
      "2019-04-09 20:44:15,375 root         INFO     Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 0.050428\n",
      "Reconstruction: 0.038269, Regularization: 0.012158\n",
      "2019-04-09 20:44:15,402 root         INFO     Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 0.038106\n",
      "Reconstruction: 0.029476, Regularization: 0.008630\n",
      "2019-04-09 20:44:15,440 root         INFO     ====> Epoch: 172 Average loss: 0.0413\n",
      "2019-04-09 20:44:15,461 root         INFO     Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 0.036769\n",
      "Reconstruction: 0.028638, Regularization: 0.008131\n",
      "2019-04-09 20:44:15,488 root         INFO     Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 0.037926\n",
      "Reconstruction: 0.028482, Regularization: 0.009444\n",
      "2019-04-09 20:44:15,513 root         INFO     Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 0.037017\n",
      "Reconstruction: 0.028075, Regularization: 0.008942\n",
      "2019-04-09 20:44:15,539 root         INFO     Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 0.040640\n",
      "Reconstruction: 0.030608, Regularization: 0.010033\n",
      "2019-04-09 20:44:15,565 root         INFO     Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 0.033086\n",
      "Reconstruction: 0.025777, Regularization: 0.007309\n",
      "2019-04-09 20:44:15,590 root         INFO     Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 0.049584\n",
      "Reconstruction: 0.036937, Regularization: 0.012647\n",
      "2019-04-09 20:44:15,616 root         INFO     Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 0.038394\n",
      "Reconstruction: 0.030463, Regularization: 0.007931\n",
      "2019-04-09 20:44:15,642 root         INFO     Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 0.042665\n",
      "Reconstruction: 0.035015, Regularization: 0.007650\n",
      "2019-04-09 20:44:15,680 root         INFO     ====> Epoch: 173 Average loss: 0.0407\n",
      "2019-04-09 20:44:15,702 root         INFO     Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 0.036298\n",
      "Reconstruction: 0.027631, Regularization: 0.008666\n",
      "2019-04-09 20:44:15,729 root         INFO     Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 0.040382\n",
      "Reconstruction: 0.031247, Regularization: 0.009135\n",
      "2019-04-09 20:44:15,756 root         INFO     Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 0.048227\n",
      "Reconstruction: 0.036213, Regularization: 0.012013\n",
      "2019-04-09 20:44:15,782 root         INFO     Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 0.046149\n",
      "Reconstruction: 0.034913, Regularization: 0.011237\n",
      "2019-04-09 20:44:15,809 root         INFO     Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 0.038566\n",
      "Reconstruction: 0.030843, Regularization: 0.007724\n",
      "2019-04-09 20:44:15,835 root         INFO     Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 0.037296\n",
      "Reconstruction: 0.029155, Regularization: 0.008140\n",
      "2019-04-09 20:44:15,862 root         INFO     Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 0.042670\n",
      "Reconstruction: 0.032724, Regularization: 0.009947\n",
      "2019-04-09 20:44:15,889 root         INFO     Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 0.033384\n",
      "Reconstruction: 0.026814, Regularization: 0.006569\n",
      "2019-04-09 20:44:15,927 root         INFO     ====> Epoch: 174 Average loss: 0.0415\n",
      "2019-04-09 20:44:15,949 root         INFO     Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 0.043606\n",
      "Reconstruction: 0.033273, Regularization: 0.010333\n",
      "2019-04-09 20:44:15,977 root         INFO     Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 0.044772\n",
      "Reconstruction: 0.034223, Regularization: 0.010549\n",
      "2019-04-09 20:44:16,003 root         INFO     Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 0.040412\n",
      "Reconstruction: 0.032550, Regularization: 0.007862\n",
      "2019-04-09 20:44:16,030 root         INFO     Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 0.041533\n",
      "Reconstruction: 0.032104, Regularization: 0.009429\n",
      "2019-04-09 20:44:16,056 root         INFO     Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 0.040009\n",
      "Reconstruction: 0.030044, Regularization: 0.009965\n",
      "2019-04-09 20:44:16,082 root         INFO     Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 0.045481\n",
      "Reconstruction: 0.033369, Regularization: 0.012112\n",
      "2019-04-09 20:44:16,108 root         INFO     Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 0.037452\n",
      "Reconstruction: 0.029138, Regularization: 0.008314\n",
      "2019-04-09 20:44:16,134 root         INFO     Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 0.038428\n",
      "Reconstruction: 0.030419, Regularization: 0.008009\n",
      "2019-04-09 20:44:16,171 root         INFO     ====> Epoch: 175 Average loss: 0.0412\n",
      "2019-04-09 20:44:16,192 root         INFO     Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 0.040519\n",
      "Reconstruction: 0.032244, Regularization: 0.008276\n",
      "2019-04-09 20:44:16,220 root         INFO     Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 0.042155\n",
      "Reconstruction: 0.035005, Regularization: 0.007150\n",
      "2019-04-09 20:44:16,248 root         INFO     Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 0.044539\n",
      "Reconstruction: 0.034358, Regularization: 0.010181\n",
      "2019-04-09 20:44:16,276 root         INFO     Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 0.045002\n",
      "Reconstruction: 0.034633, Regularization: 0.010369\n",
      "2019-04-09 20:44:16,301 root         INFO     Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 0.041464\n",
      "Reconstruction: 0.033084, Regularization: 0.008380\n",
      "2019-04-09 20:44:16,326 root         INFO     Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 0.038894\n",
      "Reconstruction: 0.028682, Regularization: 0.010212\n",
      "2019-04-09 20:44:16,352 root         INFO     Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 0.040869\n",
      "Reconstruction: 0.030757, Regularization: 0.010112\n",
      "2019-04-09 20:44:16,377 root         INFO     Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 0.040435\n",
      "Reconstruction: 0.030330, Regularization: 0.010105\n",
      "2019-04-09 20:44:16,414 root         INFO     ====> Epoch: 176 Average loss: 0.0412\n",
      "2019-04-09 20:44:16,435 root         INFO     Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 0.041760\n",
      "Reconstruction: 0.032096, Regularization: 0.009664\n",
      "2019-04-09 20:44:16,462 root         INFO     Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 0.032439\n",
      "Reconstruction: 0.025274, Regularization: 0.007165\n",
      "2019-04-09 20:44:16,489 root         INFO     Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 0.034979\n",
      "Reconstruction: 0.026532, Regularization: 0.008447\n",
      "2019-04-09 20:44:16,516 root         INFO     Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 0.041516\n",
      "Reconstruction: 0.031445, Regularization: 0.010071\n",
      "2019-04-09 20:44:16,543 root         INFO     Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 0.037574\n",
      "Reconstruction: 0.028797, Regularization: 0.008776\n",
      "2019-04-09 20:44:16,569 root         INFO     Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 0.039692\n",
      "Reconstruction: 0.030641, Regularization: 0.009051\n",
      "2019-04-09 20:44:16,596 root         INFO     Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 0.036943\n",
      "Reconstruction: 0.025694, Regularization: 0.011249\n",
      "2019-04-09 20:44:16,622 root         INFO     Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 0.049137\n",
      "Reconstruction: 0.036727, Regularization: 0.012410\n",
      "2019-04-09 20:44:16,660 root         INFO     ====> Epoch: 177 Average loss: 0.0408\n",
      "2019-04-09 20:44:16,682 root         INFO     Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 0.039459\n",
      "Reconstruction: 0.030571, Regularization: 0.008888\n",
      "2019-04-09 20:44:16,709 root         INFO     Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 0.045550\n",
      "Reconstruction: 0.036521, Regularization: 0.009028\n",
      "2019-04-09 20:44:16,735 root         INFO     Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 0.044304\n",
      "Reconstruction: 0.032912, Regularization: 0.011392\n",
      "2019-04-09 20:44:16,761 root         INFO     Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 0.035460\n",
      "Reconstruction: 0.025685, Regularization: 0.009775\n",
      "2019-04-09 20:44:16,787 root         INFO     Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 0.041433\n",
      "Reconstruction: 0.032557, Regularization: 0.008876\n",
      "2019-04-09 20:44:16,813 root         INFO     Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 0.042151\n",
      "Reconstruction: 0.031739, Regularization: 0.010412\n",
      "2019-04-09 20:44:16,839 root         INFO     Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 0.040670\n",
      "Reconstruction: 0.030555, Regularization: 0.010114\n",
      "2019-04-09 20:44:16,865 root         INFO     Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 0.042401\n",
      "Reconstruction: 0.033965, Regularization: 0.008436\n",
      "2019-04-09 20:44:16,902 root         INFO     ====> Epoch: 178 Average loss: 0.0411\n",
      "2019-04-09 20:44:16,924 root         INFO     Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 0.042879\n",
      "Reconstruction: 0.031235, Regularization: 0.011644\n",
      "2019-04-09 20:44:16,950 root         INFO     Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 0.040002\n",
      "Reconstruction: 0.032446, Regularization: 0.007556\n",
      "2019-04-09 20:44:16,976 root         INFO     Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 0.035947\n",
      "Reconstruction: 0.029692, Regularization: 0.006254\n",
      "2019-04-09 20:44:17,002 root         INFO     Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 0.034266\n",
      "Reconstruction: 0.027223, Regularization: 0.007043\n",
      "2019-04-09 20:44:17,028 root         INFO     Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 0.038001\n",
      "Reconstruction: 0.030232, Regularization: 0.007769\n",
      "2019-04-09 20:44:17,055 root         INFO     Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 0.043235\n",
      "Reconstruction: 0.033136, Regularization: 0.010099\n",
      "2019-04-09 20:44:17,081 root         INFO     Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 0.034809\n",
      "Reconstruction: 0.026024, Regularization: 0.008785\n",
      "2019-04-09 20:44:17,108 root         INFO     Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 0.035928\n",
      "Reconstruction: 0.027259, Regularization: 0.008669\n",
      "2019-04-09 20:44:17,145 root         INFO     ====> Epoch: 179 Average loss: 0.0411\n",
      "2019-04-09 20:44:17,166 root         INFO     Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 0.044057\n",
      "Reconstruction: 0.032748, Regularization: 0.011309\n",
      "2019-04-09 20:44:17,193 root         INFO     Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 0.048418\n",
      "Reconstruction: 0.038445, Regularization: 0.009973\n",
      "2019-04-09 20:44:17,219 root         INFO     Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 0.042674\n",
      "Reconstruction: 0.035103, Regularization: 0.007571\n",
      "2019-04-09 20:44:17,246 root         INFO     Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 0.042652\n",
      "Reconstruction: 0.032620, Regularization: 0.010032\n",
      "2019-04-09 20:44:17,272 root         INFO     Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 0.036709\n",
      "Reconstruction: 0.028270, Regularization: 0.008439\n",
      "2019-04-09 20:44:17,298 root         INFO     Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 0.046132\n",
      "Reconstruction: 0.035428, Regularization: 0.010704\n",
      "2019-04-09 20:44:17,324 root         INFO     Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 0.047967\n",
      "Reconstruction: 0.036764, Regularization: 0.011203\n",
      "2019-04-09 20:44:17,350 root         INFO     Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 0.045808\n",
      "Reconstruction: 0.034242, Regularization: 0.011567\n",
      "2019-04-09 20:44:17,388 root         INFO     ====> Epoch: 180 Average loss: 0.0411\n",
      "2019-04-09 20:44:17,409 root         INFO     Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 0.033652\n",
      "Reconstruction: 0.026871, Regularization: 0.006781\n",
      "2019-04-09 20:44:17,436 root         INFO     Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 0.033827\n",
      "Reconstruction: 0.026289, Regularization: 0.007538\n",
      "2019-04-09 20:44:17,462 root         INFO     Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 0.040603\n",
      "Reconstruction: 0.031541, Regularization: 0.009062\n",
      "2019-04-09 20:44:17,489 root         INFO     Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 0.041509\n",
      "Reconstruction: 0.032130, Regularization: 0.009379\n",
      "2019-04-09 20:44:17,515 root         INFO     Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 0.047250\n",
      "Reconstruction: 0.035794, Regularization: 0.011456\n",
      "2019-04-09 20:44:17,542 root         INFO     Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 0.039664\n",
      "Reconstruction: 0.031908, Regularization: 0.007756\n",
      "2019-04-09 20:44:17,568 root         INFO     Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 0.039290\n",
      "Reconstruction: 0.030284, Regularization: 0.009006\n",
      "2019-04-09 20:44:17,594 root         INFO     Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 0.041582\n",
      "Reconstruction: 0.032301, Regularization: 0.009281\n",
      "2019-04-09 20:44:17,633 root         INFO     ====> Epoch: 181 Average loss: 0.0410\n",
      "2019-04-09 20:44:17,654 root         INFO     Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 0.047105\n",
      "Reconstruction: 0.037187, Regularization: 0.009918\n",
      "2019-04-09 20:44:17,681 root         INFO     Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 0.042867\n",
      "Reconstruction: 0.032822, Regularization: 0.010045\n",
      "2019-04-09 20:44:17,707 root         INFO     Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 0.036076\n",
      "Reconstruction: 0.028099, Regularization: 0.007977\n",
      "2019-04-09 20:44:17,733 root         INFO     Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 0.039943\n",
      "Reconstruction: 0.031540, Regularization: 0.008403\n",
      "2019-04-09 20:44:17,759 root         INFO     Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 0.038038\n",
      "Reconstruction: 0.028204, Regularization: 0.009834\n",
      "2019-04-09 20:44:17,785 root         INFO     Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 0.038748\n",
      "Reconstruction: 0.030420, Regularization: 0.008329\n",
      "2019-04-09 20:44:17,810 root         INFO     Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 0.038035\n",
      "Reconstruction: 0.030913, Regularization: 0.007121\n",
      "2019-04-09 20:44:17,836 root         INFO     Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 0.046590\n",
      "Reconstruction: 0.033189, Regularization: 0.013401\n",
      "2019-04-09 20:44:17,873 root         INFO     ====> Epoch: 182 Average loss: 0.0415\n",
      "2019-04-09 20:44:17,894 root         INFO     Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 0.044835\n",
      "Reconstruction: 0.034622, Regularization: 0.010213\n",
      "2019-04-09 20:44:17,920 root         INFO     Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 0.040480\n",
      "Reconstruction: 0.029148, Regularization: 0.011331\n",
      "2019-04-09 20:44:17,947 root         INFO     Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 0.032862\n",
      "Reconstruction: 0.024324, Regularization: 0.008538\n",
      "2019-04-09 20:44:17,973 root         INFO     Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 0.037205\n",
      "Reconstruction: 0.030643, Regularization: 0.006562\n",
      "2019-04-09 20:44:17,999 root         INFO     Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 0.042089\n",
      "Reconstruction: 0.034550, Regularization: 0.007539\n",
      "2019-04-09 20:44:18,024 root         INFO     Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 0.046987\n",
      "Reconstruction: 0.033078, Regularization: 0.013908\n",
      "2019-04-09 20:44:18,050 root         INFO     Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 0.045282\n",
      "Reconstruction: 0.034536, Regularization: 0.010747\n",
      "2019-04-09 20:44:18,075 root         INFO     Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 0.039928\n",
      "Reconstruction: 0.028772, Regularization: 0.011156\n",
      "2019-04-09 20:44:18,111 root         INFO     ====> Epoch: 183 Average loss: 0.0412\n",
      "2019-04-09 20:44:18,132 root         INFO     Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 0.039198\n",
      "Reconstruction: 0.030963, Regularization: 0.008236\n",
      "2019-04-09 20:44:18,159 root         INFO     Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 0.038726\n",
      "Reconstruction: 0.030935, Regularization: 0.007792\n",
      "2019-04-09 20:44:18,185 root         INFO     Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 0.041595\n",
      "Reconstruction: 0.032042, Regularization: 0.009553\n",
      "2019-04-09 20:44:18,211 root         INFO     Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 0.038495\n",
      "Reconstruction: 0.031989, Regularization: 0.006506\n",
      "2019-04-09 20:44:18,238 root         INFO     Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 0.047617\n",
      "Reconstruction: 0.037773, Regularization: 0.009843\n",
      "2019-04-09 20:44:18,264 root         INFO     Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 0.043300\n",
      "Reconstruction: 0.032246, Regularization: 0.011054\n",
      "2019-04-09 20:44:18,290 root         INFO     Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 0.048008\n",
      "Reconstruction: 0.035079, Regularization: 0.012929\n",
      "2019-04-09 20:44:18,316 root         INFO     Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 0.041367\n",
      "Reconstruction: 0.030875, Regularization: 0.010492\n",
      "2019-04-09 20:44:18,353 root         INFO     ====> Epoch: 184 Average loss: 0.0409\n",
      "2019-04-09 20:44:18,375 root         INFO     Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 0.049797\n",
      "Reconstruction: 0.036974, Regularization: 0.012823\n",
      "2019-04-09 20:44:18,401 root         INFO     Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 0.043469\n",
      "Reconstruction: 0.031269, Regularization: 0.012200\n",
      "2019-04-09 20:44:18,426 root         INFO     Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 0.038350\n",
      "Reconstruction: 0.030014, Regularization: 0.008336\n",
      "2019-04-09 20:44:18,452 root         INFO     Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 0.040505\n",
      "Reconstruction: 0.031694, Regularization: 0.008811\n",
      "2019-04-09 20:44:18,478 root         INFO     Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 0.041325\n",
      "Reconstruction: 0.032351, Regularization: 0.008974\n",
      "2019-04-09 20:44:18,503 root         INFO     Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 0.036269\n",
      "Reconstruction: 0.029232, Regularization: 0.007037\n",
      "2019-04-09 20:44:18,530 root         INFO     Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 0.043724\n",
      "Reconstruction: 0.034886, Regularization: 0.008838\n",
      "2019-04-09 20:44:18,556 root         INFO     Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 0.036795\n",
      "Reconstruction: 0.026760, Regularization: 0.010035\n",
      "2019-04-09 20:44:18,592 root         INFO     ====> Epoch: 185 Average loss: 0.0411\n",
      "2019-04-09 20:44:18,614 root         INFO     Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 0.046314\n",
      "Reconstruction: 0.034369, Regularization: 0.011945\n",
      "2019-04-09 20:44:18,640 root         INFO     Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 0.040903\n",
      "Reconstruction: 0.031548, Regularization: 0.009355\n",
      "2019-04-09 20:44:18,666 root         INFO     Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 0.048857\n",
      "Reconstruction: 0.038784, Regularization: 0.010074\n",
      "2019-04-09 20:44:18,692 root         INFO     Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 0.039019\n",
      "Reconstruction: 0.030595, Regularization: 0.008424\n",
      "2019-04-09 20:44:18,717 root         INFO     Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 0.033960\n",
      "Reconstruction: 0.027978, Regularization: 0.005982\n",
      "2019-04-09 20:44:18,743 root         INFO     Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 0.037956\n",
      "Reconstruction: 0.029016, Regularization: 0.008940\n",
      "2019-04-09 20:44:18,769 root         INFO     Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 0.042506\n",
      "Reconstruction: 0.032682, Regularization: 0.009824\n",
      "2019-04-09 20:44:18,794 root         INFO     Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 0.043804\n",
      "Reconstruction: 0.033013, Regularization: 0.010790\n",
      "2019-04-09 20:44:18,831 root         INFO     ====> Epoch: 186 Average loss: 0.0410\n",
      "2019-04-09 20:44:18,852 root         INFO     Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 0.034184\n",
      "Reconstruction: 0.025723, Regularization: 0.008461\n",
      "2019-04-09 20:44:18,879 root         INFO     Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 0.038937\n",
      "Reconstruction: 0.031350, Regularization: 0.007587\n",
      "2019-04-09 20:44:18,906 root         INFO     Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 0.048783\n",
      "Reconstruction: 0.035265, Regularization: 0.013518\n",
      "2019-04-09 20:44:18,932 root         INFO     Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 0.042768\n",
      "Reconstruction: 0.032817, Regularization: 0.009951\n",
      "2019-04-09 20:44:18,959 root         INFO     Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 0.053655\n",
      "Reconstruction: 0.040967, Regularization: 0.012688\n",
      "2019-04-09 20:44:18,985 root         INFO     Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 0.040852\n",
      "Reconstruction: 0.030484, Regularization: 0.010368\n",
      "2019-04-09 20:44:19,012 root         INFO     Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 0.039651\n",
      "Reconstruction: 0.031815, Regularization: 0.007836\n",
      "2019-04-09 20:44:19,039 root         INFO     Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 0.035343\n",
      "Reconstruction: 0.029138, Regularization: 0.006205\n",
      "2019-04-09 20:44:19,076 root         INFO     ====> Epoch: 187 Average loss: 0.0412\n",
      "2019-04-09 20:44:19,097 root         INFO     Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 0.039126\n",
      "Reconstruction: 0.029975, Regularization: 0.009152\n",
      "2019-04-09 20:44:19,124 root         INFO     Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 0.034223\n",
      "Reconstruction: 0.027151, Regularization: 0.007072\n",
      "2019-04-09 20:44:19,151 root         INFO     Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 0.041778\n",
      "Reconstruction: 0.033147, Regularization: 0.008631\n",
      "2019-04-09 20:44:19,178 root         INFO     Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 0.038108\n",
      "Reconstruction: 0.029704, Regularization: 0.008403\n",
      "2019-04-09 20:44:19,205 root         INFO     Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 0.044186\n",
      "Reconstruction: 0.033412, Regularization: 0.010775\n",
      "2019-04-09 20:44:19,232 root         INFO     Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 0.049317\n",
      "Reconstruction: 0.037905, Regularization: 0.011411\n",
      "2019-04-09 20:44:19,259 root         INFO     Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 0.043867\n",
      "Reconstruction: 0.033535, Regularization: 0.010333\n",
      "2019-04-09 20:44:19,285 root         INFO     Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 0.037959\n",
      "Reconstruction: 0.028499, Regularization: 0.009460\n",
      "2019-04-09 20:44:19,323 root         INFO     ====> Epoch: 188 Average loss: 0.0411\n",
      "2019-04-09 20:44:19,345 root         INFO     Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 0.043819\n",
      "Reconstruction: 0.031338, Regularization: 0.012481\n",
      "2019-04-09 20:44:19,372 root         INFO     Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 0.039974\n",
      "Reconstruction: 0.031431, Regularization: 0.008544\n",
      "2019-04-09 20:44:19,399 root         INFO     Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 0.035594\n",
      "Reconstruction: 0.027056, Regularization: 0.008538\n",
      "2019-04-09 20:44:19,425 root         INFO     Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 0.042597\n",
      "Reconstruction: 0.032206, Regularization: 0.010391\n",
      "2019-04-09 20:44:19,452 root         INFO     Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 0.034428\n",
      "Reconstruction: 0.028699, Regularization: 0.005729\n",
      "2019-04-09 20:44:19,478 root         INFO     Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 0.041649\n",
      "Reconstruction: 0.030331, Regularization: 0.011318\n",
      "2019-04-09 20:44:19,505 root         INFO     Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 0.036125\n",
      "Reconstruction: 0.027993, Regularization: 0.008132\n",
      "2019-04-09 20:44:19,531 root         INFO     Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 0.039200\n",
      "Reconstruction: 0.029035, Regularization: 0.010165\n",
      "2019-04-09 20:44:19,569 root         INFO     ====> Epoch: 189 Average loss: 0.0412\n",
      "2019-04-09 20:44:19,591 root         INFO     Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 0.034444\n",
      "Reconstruction: 0.027319, Regularization: 0.007126\n",
      "2019-04-09 20:44:19,617 root         INFO     Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 0.041417\n",
      "Reconstruction: 0.030592, Regularization: 0.010825\n",
      "2019-04-09 20:44:19,644 root         INFO     Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 0.041378\n",
      "Reconstruction: 0.032078, Regularization: 0.009300\n",
      "2019-04-09 20:44:19,671 root         INFO     Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 0.041293\n",
      "Reconstruction: 0.032310, Regularization: 0.008983\n",
      "2019-04-09 20:44:19,698 root         INFO     Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 0.046021\n",
      "Reconstruction: 0.034903, Regularization: 0.011117\n",
      "2019-04-09 20:44:19,725 root         INFO     Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 0.039702\n",
      "Reconstruction: 0.029184, Regularization: 0.010518\n",
      "2019-04-09 20:44:19,752 root         INFO     Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 0.038402\n",
      "Reconstruction: 0.029204, Regularization: 0.009198\n",
      "2019-04-09 20:44:19,779 root         INFO     Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 0.045637\n",
      "Reconstruction: 0.034234, Regularization: 0.011403\n",
      "2019-04-09 20:44:19,817 root         INFO     ====> Epoch: 190 Average loss: 0.0415\n",
      "2019-04-09 20:44:19,838 root         INFO     Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 0.037785\n",
      "Reconstruction: 0.027588, Regularization: 0.010197\n",
      "2019-04-09 20:44:19,864 root         INFO     Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 0.037496\n",
      "Reconstruction: 0.029850, Regularization: 0.007646\n",
      "2019-04-09 20:44:19,890 root         INFO     Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 0.040818\n",
      "Reconstruction: 0.031544, Regularization: 0.009275\n",
      "2019-04-09 20:44:19,915 root         INFO     Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 0.045786\n",
      "Reconstruction: 0.036311, Regularization: 0.009475\n",
      "2019-04-09 20:44:19,940 root         INFO     Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 0.040047\n",
      "Reconstruction: 0.030910, Regularization: 0.009137\n",
      "2019-04-09 20:44:19,966 root         INFO     Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 0.036770\n",
      "Reconstruction: 0.028701, Regularization: 0.008069\n",
      "2019-04-09 20:44:19,991 root         INFO     Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 0.049892\n",
      "Reconstruction: 0.038508, Regularization: 0.011384\n",
      "2019-04-09 20:44:20,017 root         INFO     Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 0.041172\n",
      "Reconstruction: 0.032917, Regularization: 0.008255\n",
      "2019-04-09 20:44:20,054 root         INFO     ====> Epoch: 191 Average loss: 0.0411\n",
      "2019-04-09 20:44:20,075 root         INFO     Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 0.040057\n",
      "Reconstruction: 0.029189, Regularization: 0.010868\n",
      "2019-04-09 20:44:20,102 root         INFO     Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 0.039231\n",
      "Reconstruction: 0.030447, Regularization: 0.008785\n",
      "2019-04-09 20:44:20,129 root         INFO     Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.034436\n",
      "Reconstruction: 0.026395, Regularization: 0.008041\n",
      "2019-04-09 20:44:20,156 root         INFO     Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 0.037029\n",
      "Reconstruction: 0.028424, Regularization: 0.008605\n",
      "2019-04-09 20:44:20,183 root         INFO     Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 0.038802\n",
      "Reconstruction: 0.029996, Regularization: 0.008806\n",
      "2019-04-09 20:44:20,210 root         INFO     Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 0.039305\n",
      "Reconstruction: 0.030660, Regularization: 0.008645\n",
      "2019-04-09 20:44:20,237 root         INFO     Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 0.036662\n",
      "Reconstruction: 0.029839, Regularization: 0.006822\n",
      "2019-04-09 20:44:20,263 root         INFO     Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 0.040553\n",
      "Reconstruction: 0.031091, Regularization: 0.009462\n",
      "2019-04-09 20:44:20,301 root         INFO     ====> Epoch: 192 Average loss: 0.0408\n",
      "2019-04-09 20:44:20,322 root         INFO     Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 0.037667\n",
      "Reconstruction: 0.030486, Regularization: 0.007180\n",
      "2019-04-09 20:44:20,349 root         INFO     Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 0.048525\n",
      "Reconstruction: 0.036146, Regularization: 0.012378\n",
      "2019-04-09 20:44:20,376 root         INFO     Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 0.041719\n",
      "Reconstruction: 0.033572, Regularization: 0.008147\n",
      "2019-04-09 20:44:20,404 root         INFO     Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 0.048098\n",
      "Reconstruction: 0.036508, Regularization: 0.011591\n",
      "2019-04-09 20:44:20,431 root         INFO     Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 0.039273\n",
      "Reconstruction: 0.031134, Regularization: 0.008139\n",
      "2019-04-09 20:44:20,458 root         INFO     Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 0.043047\n",
      "Reconstruction: 0.030485, Regularization: 0.012562\n",
      "2019-04-09 20:44:20,485 root         INFO     Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 0.040583\n",
      "Reconstruction: 0.029943, Regularization: 0.010640\n",
      "2019-04-09 20:44:20,512 root         INFO     Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 0.042477\n",
      "Reconstruction: 0.031648, Regularization: 0.010829\n",
      "2019-04-09 20:44:20,550 root         INFO     ====> Epoch: 193 Average loss: 0.0411\n",
      "2019-04-09 20:44:20,571 root         INFO     Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 0.035780\n",
      "Reconstruction: 0.028594, Regularization: 0.007186\n",
      "2019-04-09 20:44:20,598 root         INFO     Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 0.037953\n",
      "Reconstruction: 0.029410, Regularization: 0.008543\n",
      "2019-04-09 20:44:20,626 root         INFO     Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 0.045134\n",
      "Reconstruction: 0.036382, Regularization: 0.008752\n",
      "2019-04-09 20:44:20,652 root         INFO     Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 0.044606\n",
      "Reconstruction: 0.035445, Regularization: 0.009161\n",
      "2019-04-09 20:44:20,679 root         INFO     Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 0.044796\n",
      "Reconstruction: 0.031632, Regularization: 0.013164\n",
      "2019-04-09 20:44:20,707 root         INFO     Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 0.040452\n",
      "Reconstruction: 0.030929, Regularization: 0.009523\n",
      "2019-04-09 20:44:20,734 root         INFO     Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 0.050442\n",
      "Reconstruction: 0.038700, Regularization: 0.011742\n",
      "2019-04-09 20:44:20,761 root         INFO     Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 0.043151\n",
      "Reconstruction: 0.033294, Regularization: 0.009857\n",
      "2019-04-09 20:44:20,799 root         INFO     ====> Epoch: 194 Average loss: 0.0414\n",
      "2019-04-09 20:44:20,821 root         INFO     Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 0.042526\n",
      "Reconstruction: 0.032720, Regularization: 0.009805\n",
      "2019-04-09 20:44:20,848 root         INFO     Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 0.038337\n",
      "Reconstruction: 0.031571, Regularization: 0.006766\n",
      "2019-04-09 20:44:20,875 root         INFO     Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 0.037726\n",
      "Reconstruction: 0.030122, Regularization: 0.007605\n",
      "2019-04-09 20:44:20,901 root         INFO     Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 0.044918\n",
      "Reconstruction: 0.034098, Regularization: 0.010820\n",
      "2019-04-09 20:44:20,928 root         INFO     Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 0.041665\n",
      "Reconstruction: 0.031691, Regularization: 0.009975\n",
      "2019-04-09 20:44:20,955 root         INFO     Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 0.038171\n",
      "Reconstruction: 0.028464, Regularization: 0.009707\n",
      "2019-04-09 20:44:20,980 root         INFO     Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 0.037570\n",
      "Reconstruction: 0.029384, Regularization: 0.008186\n",
      "2019-04-09 20:44:21,006 root         INFO     Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 0.041284\n",
      "Reconstruction: 0.031782, Regularization: 0.009502\n",
      "2019-04-09 20:44:21,043 root         INFO     ====> Epoch: 195 Average loss: 0.0412\n",
      "2019-04-09 20:44:21,064 root         INFO     Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 0.034541\n",
      "Reconstruction: 0.025913, Regularization: 0.008628\n",
      "2019-04-09 20:44:21,091 root         INFO     Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 0.040918\n",
      "Reconstruction: 0.031511, Regularization: 0.009407\n",
      "2019-04-09 20:44:21,118 root         INFO     Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 0.040256\n",
      "Reconstruction: 0.031698, Regularization: 0.008558\n",
      "2019-04-09 20:44:21,146 root         INFO     Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 0.050096\n",
      "Reconstruction: 0.039677, Regularization: 0.010419\n",
      "2019-04-09 20:44:21,172 root         INFO     Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 0.041943\n",
      "Reconstruction: 0.033626, Regularization: 0.008317\n",
      "2019-04-09 20:44:21,199 root         INFO     Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 0.043124\n",
      "Reconstruction: 0.032965, Regularization: 0.010159\n",
      "2019-04-09 20:44:21,226 root         INFO     Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 0.035212\n",
      "Reconstruction: 0.026886, Regularization: 0.008325\n",
      "2019-04-09 20:44:21,253 root         INFO     Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 0.038551\n",
      "Reconstruction: 0.029362, Regularization: 0.009189\n",
      "2019-04-09 20:44:21,291 root         INFO     ====> Epoch: 196 Average loss: 0.0409\n",
      "2019-04-09 20:44:21,312 root         INFO     Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 0.037681\n",
      "Reconstruction: 0.029341, Regularization: 0.008340\n",
      "2019-04-09 20:44:21,339 root         INFO     Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 0.039381\n",
      "Reconstruction: 0.030710, Regularization: 0.008671\n",
      "2019-04-09 20:44:21,366 root         INFO     Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 0.041266\n",
      "Reconstruction: 0.032119, Regularization: 0.009147\n",
      "2019-04-09 20:44:21,393 root         INFO     Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 0.038516\n",
      "Reconstruction: 0.029190, Regularization: 0.009326\n",
      "2019-04-09 20:44:21,420 root         INFO     Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 0.037614\n",
      "Reconstruction: 0.028361, Regularization: 0.009253\n",
      "2019-04-09 20:44:21,448 root         INFO     Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 0.034846\n",
      "Reconstruction: 0.026970, Regularization: 0.007876\n",
      "2019-04-09 20:44:21,475 root         INFO     Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 0.034493\n",
      "Reconstruction: 0.027182, Regularization: 0.007311\n",
      "2019-04-09 20:44:21,503 root         INFO     Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 0.048578\n",
      "Reconstruction: 0.036771, Regularization: 0.011808\n",
      "2019-04-09 20:44:21,541 root         INFO     ====> Epoch: 197 Average loss: 0.0407\n",
      "2019-04-09 20:44:21,562 root         INFO     Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 0.046532\n",
      "Reconstruction: 0.035371, Regularization: 0.011161\n",
      "2019-04-09 20:44:21,589 root         INFO     Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.047631\n",
      "Reconstruction: 0.036405, Regularization: 0.011226\n",
      "2019-04-09 20:44:21,616 root         INFO     Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 0.044468\n",
      "Reconstruction: 0.032932, Regularization: 0.011536\n",
      "2019-04-09 20:44:21,643 root         INFO     Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 0.044762\n",
      "Reconstruction: 0.033137, Regularization: 0.011624\n",
      "2019-04-09 20:44:21,670 root         INFO     Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 0.040169\n",
      "Reconstruction: 0.030231, Regularization: 0.009938\n",
      "2019-04-09 20:44:21,697 root         INFO     Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 0.041736\n",
      "Reconstruction: 0.031540, Regularization: 0.010196\n",
      "2019-04-09 20:44:21,724 root         INFO     Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 0.041803\n",
      "Reconstruction: 0.034050, Regularization: 0.007754\n",
      "2019-04-09 20:44:21,750 root         INFO     Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 0.042530\n",
      "Reconstruction: 0.031247, Regularization: 0.011282\n",
      "2019-04-09 20:44:21,788 root         INFO     ====> Epoch: 198 Average loss: 0.0414\n",
      "2019-04-09 20:44:21,809 root         INFO     Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 0.044414\n",
      "Reconstruction: 0.033555, Regularization: 0.010858\n",
      "2019-04-09 20:44:21,837 root         INFO     Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 0.045664\n",
      "Reconstruction: 0.035276, Regularization: 0.010388\n",
      "2019-04-09 20:44:21,865 root         INFO     Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 0.039033\n",
      "Reconstruction: 0.031489, Regularization: 0.007544\n",
      "2019-04-09 20:44:21,892 root         INFO     Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 0.045498\n",
      "Reconstruction: 0.033685, Regularization: 0.011813\n",
      "2019-04-09 20:44:21,919 root         INFO     Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 0.038879\n",
      "Reconstruction: 0.029591, Regularization: 0.009288\n",
      "2019-04-09 20:44:21,946 root         INFO     Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 0.040728\n",
      "Reconstruction: 0.031150, Regularization: 0.009579\n",
      "2019-04-09 20:44:21,974 root         INFO     Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.042535\n",
      "Reconstruction: 0.032587, Regularization: 0.009948\n",
      "2019-04-09 20:44:22,001 root         INFO     Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 0.034320\n",
      "Reconstruction: 0.027919, Regularization: 0.006401\n",
      "2019-04-09 20:44:22,040 root         INFO     ====> Epoch: 199 Average loss: 0.0410\n",
      "2019-04-09 20:44:22,047 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) done      TrainVAE()\n",
      "2019-04-09 20:44:22,048 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 20:44:22,048 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   DONE\n",
      "2019-04-09 20:44:22,048 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 20:44:22,048 luigi-interface DEBUG    Pending tasks: 2\n",
      "2019-04-09 20:44:22,048 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) running   TrainVEM()\n",
      "2019-04-09 20:44:22,049 root         INFO     --Dataset tensor: (10000, 1)\n",
      "2019-04-09 20:44:22,049 root         INFO     -- Train tensor: (8000, 1)\n",
      "2019-04-09 20:44:22,050 root         INFO     Values of VEM's decoder parameters before training:\n",
      "2019-04-09 20:44:22,050 root         INFO     layers.0.weight\n",
      "2019-04-09 20:44:22,050 root         INFO     tensor([[0.5859]], device='cuda:0')\n",
      "2019-04-09 20:44:22,078 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 0.076626\n",
      "Reconstruction: 0.045808, Regularization: 0.000150, Discriminator: 0.022030; Generator: 0.008637,\n",
      "D(x): 0.575, D(G(z)): 0.575\n",
      "2019-04-09 20:44:22,144 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 0.082309\n",
      "Reconstruction: 0.051471, Regularization: 0.000168, Discriminator: 0.022018; Generator: 0.008652,\n",
      "D(x): 0.575, D(G(z)): 0.575\n",
      "2019-04-09 20:44:22,210 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 0.089495\n",
      "Reconstruction: 0.058692, Regularization: 0.000191, Discriminator: 0.021946; Generator: 0.008666,\n",
      "D(x): 0.577, D(G(z)): 0.574\n",
      "2019-04-09 20:44:22,276 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 0.093957\n",
      "Reconstruction: 0.063027, Regularization: 0.000203, Discriminator: 0.022048; Generator: 0.008680,\n",
      "D(x): 0.572, D(G(z)): 0.574\n",
      "2019-04-09 20:44:22,342 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 0.076134\n",
      "Reconstruction: 0.045266, Regularization: 0.000123, Discriminator: 0.022052; Generator: 0.008693,\n",
      "D(x): 0.571, D(G(z)): 0.573\n",
      "2019-04-09 20:44:22,408 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 0.081444\n",
      "Reconstruction: 0.050608, Regularization: 0.000141, Discriminator: 0.021987; Generator: 0.008708,\n",
      "D(x): 0.573, D(G(z)): 0.573\n",
      "2019-04-09 20:44:22,474 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 0.096468\n",
      "Reconstruction: 0.065506, Regularization: 0.000193, Discriminator: 0.022045; Generator: 0.008724,\n",
      "D(x): 0.570, D(G(z)): 0.572\n",
      "2019-04-09 20:44:22,539 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 0.076140\n",
      "Reconstruction: 0.045303, Regularization: 0.000112, Discriminator: 0.021987; Generator: 0.008738,\n",
      "D(x): 0.572, D(G(z)): 0.572\n",
      "2019-04-09 20:44:22,607 root         INFO     ====> Epoch: 0 Average loss: 0.0832\n",
      "2019-04-09 20:44:22,631 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 0.082681\n",
      "Reconstruction: 0.051779, Regularization: 0.000133, Discriminator: 0.022020; Generator: 0.008749,\n",
      "D(x): 0.570, D(G(z)): 0.571\n",
      "2019-04-09 20:44:22,698 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 0.082896\n",
      "Reconstruction: 0.051974, Regularization: 0.000130, Discriminator: 0.022028; Generator: 0.008764,\n",
      "D(x): 0.569, D(G(z)): 0.571\n",
      "2019-04-09 20:44:22,764 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 0.085940\n",
      "Reconstruction: 0.055002, Regularization: 0.000136, Discriminator: 0.022022; Generator: 0.008779,\n",
      "D(x): 0.568, D(G(z)): 0.570\n",
      "2019-04-09 20:44:22,830 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 0.086426\n",
      "Reconstruction: 0.055561, Regularization: 0.000137, Discriminator: 0.021935; Generator: 0.008793,\n",
      "D(x): 0.571, D(G(z)): 0.570\n",
      "2019-04-09 20:44:22,897 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 0.079359\n",
      "Reconstruction: 0.048508, Regularization: 0.000113, Discriminator: 0.021928; Generator: 0.008811,\n",
      "D(x): 0.570, D(G(z)): 0.569\n",
      "2019-04-09 20:44:22,963 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 0.078771\n",
      "Reconstruction: 0.047874, Regularization: 0.000108, Discriminator: 0.021965; Generator: 0.008824,\n",
      "D(x): 0.568, D(G(z)): 0.569\n",
      "2019-04-09 20:44:23,030 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 0.084035\n",
      "Reconstruction: 0.053046, Regularization: 0.000125, Discriminator: 0.022025; Generator: 0.008839,\n",
      "D(x): 0.565, D(G(z)): 0.568\n",
      "2019-04-09 20:44:23,096 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 0.079373\n",
      "Reconstruction: 0.048411, Regularization: 0.000107, Discriminator: 0.021999; Generator: 0.008856,\n",
      "D(x): 0.566, D(G(z)): 0.567\n",
      "2019-04-09 20:44:23,164 root         INFO     ====> Epoch: 1 Average loss: 0.0833\n",
      "2019-04-09 20:44:23,188 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 0.082304\n",
      "Reconstruction: 0.051435, Regularization: 0.000117, Discriminator: 0.021885; Generator: 0.008868,\n",
      "D(x): 0.569, D(G(z)): 0.567\n",
      "2019-04-09 20:44:23,252 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 0.075045\n",
      "Reconstruction: 0.044101, Regularization: 0.000092, Discriminator: 0.021968; Generator: 0.008884,\n",
      "D(x): 0.565, D(G(z)): 0.566\n",
      "2019-04-09 20:44:23,316 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 0.083584\n",
      "Reconstruction: 0.052597, Regularization: 0.000116, Discriminator: 0.021972; Generator: 0.008899,\n",
      "D(x): 0.565, D(G(z)): 0.566\n",
      "2019-04-09 20:44:23,380 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 0.081539\n",
      "Reconstruction: 0.050483, Regularization: 0.000110, Discriminator: 0.022029; Generator: 0.008918,\n",
      "D(x): 0.562, D(G(z)): 0.565\n",
      "2019-04-09 20:44:23,444 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 0.084066\n",
      "Reconstruction: 0.053144, Regularization: 0.000117, Discriminator: 0.021874; Generator: 0.008931,\n",
      "D(x): 0.567, D(G(z)): 0.565\n",
      "2019-04-09 20:44:23,508 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 0.084614\n",
      "Reconstruction: 0.053668, Regularization: 0.000117, Discriminator: 0.021883; Generator: 0.008946,\n",
      "D(x): 0.566, D(G(z)): 0.564\n",
      "2019-04-09 20:44:23,572 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 0.083321\n",
      "Reconstruction: 0.052280, Regularization: 0.000113, Discriminator: 0.021965; Generator: 0.008963,\n",
      "D(x): 0.562, D(G(z)): 0.563\n",
      "2019-04-09 20:44:23,636 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 0.079242\n",
      "Reconstruction: 0.048299, Regularization: 0.000099, Discriminator: 0.021869; Generator: 0.008974,\n",
      "D(x): 0.565, D(G(z)): 0.563\n",
      "2019-04-09 20:44:23,701 root         INFO     ====> Epoch: 2 Average loss: 0.0834\n",
      "2019-04-09 20:44:23,726 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 0.093606\n",
      "Reconstruction: 0.062522, Regularization: 0.000142, Discriminator: 0.021954; Generator: 0.008988,\n",
      "D(x): 0.561, D(G(z)): 0.563\n",
      "2019-04-09 20:44:23,789 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 0.082521\n",
      "Reconstruction: 0.051543, Regularization: 0.000111, Discriminator: 0.021860; Generator: 0.009007,\n",
      "D(x): 0.564, D(G(z)): 0.562\n",
      "2019-04-09 20:44:23,852 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 0.075356\n",
      "Reconstruction: 0.044352, Regularization: 0.000091, Discriminator: 0.021888; Generator: 0.009025,\n",
      "D(x): 0.562, D(G(z)): 0.561\n",
      "2019-04-09 20:44:23,916 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 0.094912\n",
      "Reconstruction: 0.063845, Regularization: 0.000150, Discriminator: 0.021877; Generator: 0.009040,\n",
      "D(x): 0.562, D(G(z)): 0.561\n",
      "2019-04-09 20:44:23,985 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 0.072805\n",
      "Reconstruction: 0.041649, Regularization: 0.000084, Discriminator: 0.022018; Generator: 0.009054,\n",
      "D(x): 0.556, D(G(z)): 0.560\n",
      "2019-04-09 20:44:24,053 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 0.088094\n",
      "Reconstruction: 0.057038, Regularization: 0.000131, Discriminator: 0.021851; Generator: 0.009073,\n",
      "D(x): 0.561, D(G(z)): 0.560\n",
      "2019-04-09 20:44:24,122 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 0.082469\n",
      "Reconstruction: 0.051435, Regularization: 0.000114, Discriminator: 0.021833; Generator: 0.009087,\n",
      "D(x): 0.561, D(G(z)): 0.559\n",
      "2019-04-09 20:44:24,191 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 0.089553\n",
      "Reconstruction: 0.058429, Regularization: 0.000135, Discriminator: 0.021887; Generator: 0.009101,\n",
      "D(x): 0.558, D(G(z)): 0.559\n",
      "2019-04-09 20:44:24,261 root         INFO     ====> Epoch: 3 Average loss: 0.0835\n",
      "2019-04-09 20:44:24,285 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 0.074027\n",
      "Reconstruction: 0.042926, Regularization: 0.000088, Discriminator: 0.021899; Generator: 0.009113,\n",
      "D(x): 0.557, D(G(z)): 0.558\n",
      "2019-04-09 20:44:24,353 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 0.081634\n",
      "Reconstruction: 0.050523, Regularization: 0.000111, Discriminator: 0.021874; Generator: 0.009127,\n",
      "D(x): 0.558, D(G(z)): 0.558\n",
      "2019-04-09 20:44:24,420 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 0.092651\n",
      "Reconstruction: 0.061588, Regularization: 0.000144, Discriminator: 0.021777; Generator: 0.009143,\n",
      "D(x): 0.561, D(G(z)): 0.557\n",
      "2019-04-09 20:44:24,487 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 0.082290\n",
      "Reconstruction: 0.051231, Regularization: 0.000112, Discriminator: 0.021789; Generator: 0.009158,\n",
      "D(x): 0.559, D(G(z)): 0.556\n",
      "2019-04-09 20:44:24,554 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 0.077156\n",
      "Reconstruction: 0.045957, Regularization: 0.000094, Discriminator: 0.021924; Generator: 0.009182,\n",
      "D(x): 0.554, D(G(z)): 0.556\n",
      "2019-04-09 20:44:24,621 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 0.096094\n",
      "Reconstruction: 0.065086, Regularization: 0.000147, Discriminator: 0.021669; Generator: 0.009192,\n",
      "D(x): 0.562, D(G(z)): 0.555\n",
      "2019-04-09 20:44:24,688 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 0.078629\n",
      "Reconstruction: 0.047577, Regularization: 0.000096, Discriminator: 0.021747; Generator: 0.009209,\n",
      "D(x): 0.559, D(G(z)): 0.555\n",
      "2019-04-09 20:44:24,756 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 0.085593\n",
      "Reconstruction: 0.054398, Regularization: 0.000114, Discriminator: 0.021854; Generator: 0.009226,\n",
      "D(x): 0.554, D(G(z)): 0.554\n",
      "2019-04-09 20:44:24,824 root         INFO     ====> Epoch: 4 Average loss: 0.0836\n",
      "2019-04-09 20:44:24,849 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 0.088211\n",
      "Reconstruction: 0.057094, Regularization: 0.000122, Discriminator: 0.021756; Generator: 0.009240,\n",
      "D(x): 0.557, D(G(z)): 0.554\n",
      "2019-04-09 20:44:24,916 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 0.076023\n",
      "Reconstruction: 0.044706, Regularization: 0.000085, Discriminator: 0.021973; Generator: 0.009259,\n",
      "D(x): 0.548, D(G(z)): 0.553\n",
      "2019-04-09 20:44:24,984 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 0.076183\n",
      "Reconstruction: 0.044988, Regularization: 0.000087, Discriminator: 0.021836; Generator: 0.009272,\n",
      "D(x): 0.553, D(G(z)): 0.552\n",
      "2019-04-09 20:44:25,050 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 0.093942\n",
      "Reconstruction: 0.062668, Regularization: 0.000138, Discriminator: 0.021844; Generator: 0.009292,\n",
      "D(x): 0.552, D(G(z)): 0.552\n",
      "2019-04-09 20:44:25,113 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 0.090520\n",
      "Reconstruction: 0.059211, Regularization: 0.000127, Discriminator: 0.021877; Generator: 0.009304,\n",
      "D(x): 0.550, D(G(z)): 0.551\n",
      "2019-04-09 20:44:25,178 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 0.083025\n",
      "Reconstruction: 0.051794, Regularization: 0.000107, Discriminator: 0.021801; Generator: 0.009323,\n",
      "D(x): 0.552, D(G(z)): 0.551\n",
      "2019-04-09 20:44:25,242 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 0.081607\n",
      "Reconstruction: 0.050353, Regularization: 0.000102, Discriminator: 0.021813; Generator: 0.009339,\n",
      "D(x): 0.551, D(G(z)): 0.550\n",
      "2019-04-09 20:44:25,306 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 0.082885\n",
      "Reconstruction: 0.051640, Regularization: 0.000106, Discriminator: 0.021784; Generator: 0.009356,\n",
      "D(x): 0.551, D(G(z)): 0.549\n",
      "2019-04-09 20:44:25,371 root         INFO     ====> Epoch: 5 Average loss: 0.0837\n",
      "2019-04-09 20:44:25,395 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 0.090661\n",
      "Reconstruction: 0.059413, Regularization: 0.000129, Discriminator: 0.021749; Generator: 0.009370,\n",
      "D(x): 0.552, D(G(z)): 0.549\n",
      "2019-04-09 20:44:25,464 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 0.082088\n",
      "Reconstruction: 0.050776, Regularization: 0.000104, Discriminator: 0.021822; Generator: 0.009385,\n",
      "D(x): 0.548, D(G(z)): 0.548\n",
      "2019-04-09 20:44:25,531 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 0.086798\n",
      "Reconstruction: 0.055469, Regularization: 0.000119, Discriminator: 0.021806; Generator: 0.009404,\n",
      "D(x): 0.548, D(G(z)): 0.548\n",
      "2019-04-09 20:44:25,599 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 0.084316\n",
      "Reconstruction: 0.053094, Regularization: 0.000111, Discriminator: 0.021690; Generator: 0.009420,\n",
      "D(x): 0.552, D(G(z)): 0.547\n",
      "2019-04-09 20:44:25,667 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 0.069299\n",
      "Reconstruction: 0.037899, Regularization: 0.000066, Discriminator: 0.021896; Generator: 0.009438,\n",
      "D(x): 0.543, D(G(z)): 0.547\n",
      "2019-04-09 20:44:25,735 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 0.077581\n",
      "Reconstruction: 0.046272, Regularization: 0.000090, Discriminator: 0.021770; Generator: 0.009449,\n",
      "D(x): 0.548, D(G(z)): 0.546\n",
      "2019-04-09 20:44:25,803 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 0.082623\n",
      "Reconstruction: 0.051150, Regularization: 0.000104, Discriminator: 0.021898; Generator: 0.009471,\n",
      "D(x): 0.542, D(G(z)): 0.545\n",
      "2019-04-09 20:44:25,871 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 0.092883\n",
      "Reconstruction: 0.061650, Regularization: 0.000130, Discriminator: 0.021620; Generator: 0.009483,\n",
      "D(x): 0.552, D(G(z)): 0.545\n",
      "2019-04-09 20:44:25,939 root         INFO     ====> Epoch: 6 Average loss: 0.0838\n",
      "2019-04-09 20:44:25,964 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 0.074933\n",
      "Reconstruction: 0.043507, Regularization: 0.000080, Discriminator: 0.021849; Generator: 0.009497,\n",
      "D(x): 0.543, D(G(z)): 0.545\n",
      "2019-04-09 20:44:26,032 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 0.087238\n",
      "Reconstruction: 0.055878, Regularization: 0.000114, Discriminator: 0.021736; Generator: 0.009511,\n",
      "D(x): 0.546, D(G(z)): 0.544\n",
      "2019-04-09 20:44:26,101 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 0.090159\n",
      "Reconstruction: 0.058862, Regularization: 0.000124, Discriminator: 0.021649; Generator: 0.009525,\n",
      "D(x): 0.549, D(G(z)): 0.544\n",
      "2019-04-09 20:44:26,169 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 0.076246\n",
      "Reconstruction: 0.044848, Regularization: 0.000083, Discriminator: 0.021771; Generator: 0.009544,\n",
      "D(x): 0.544, D(G(z)): 0.543\n",
      "2019-04-09 20:44:26,238 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 0.076058\n",
      "Reconstruction: 0.044651, Regularization: 0.000082, Discriminator: 0.021764; Generator: 0.009561,\n",
      "D(x): 0.543, D(G(z)): 0.542\n",
      "2019-04-09 20:44:26,306 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 0.088270\n",
      "Reconstruction: 0.056685, Regularization: 0.000116, Discriminator: 0.021893; Generator: 0.009576,\n",
      "D(x): 0.538, D(G(z)): 0.542\n",
      "2019-04-09 20:44:26,375 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 0.087700\n",
      "Reconstruction: 0.056180, Regularization: 0.000115, Discriminator: 0.021807; Generator: 0.009597,\n",
      "D(x): 0.540, D(G(z)): 0.541\n",
      "2019-04-09 20:44:26,443 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 0.074373\n",
      "Reconstruction: 0.042818, Regularization: 0.000079, Discriminator: 0.021868; Generator: 0.009609,\n",
      "D(x): 0.538, D(G(z)): 0.541\n",
      "2019-04-09 20:44:26,512 root         INFO     ====> Epoch: 7 Average loss: 0.0839\n",
      "2019-04-09 20:44:26,536 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 0.093544\n",
      "Reconstruction: 0.062034, Regularization: 0.000135, Discriminator: 0.021751; Generator: 0.009623,\n",
      "D(x): 0.541, D(G(z)): 0.540\n",
      "2019-04-09 20:44:26,604 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 0.080121\n",
      "Reconstruction: 0.048752, Regularization: 0.000098, Discriminator: 0.021635; Generator: 0.009635,\n",
      "D(x): 0.545, D(G(z)): 0.540\n",
      "2019-04-09 20:44:26,671 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 0.078516\n",
      "Reconstruction: 0.047077, Regularization: 0.000095, Discriminator: 0.021694; Generator: 0.009651,\n",
      "D(x): 0.542, D(G(z)): 0.539\n",
      "2019-04-09 20:44:26,738 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 0.078433\n",
      "Reconstruction: 0.047002, Regularization: 0.000094, Discriminator: 0.021672; Generator: 0.009664,\n",
      "D(x): 0.542, D(G(z)): 0.539\n",
      "2019-04-09 20:44:26,804 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 0.094054\n",
      "Reconstruction: 0.062557, Regularization: 0.000141, Discriminator: 0.021672; Generator: 0.009684,\n",
      "D(x): 0.542, D(G(z)): 0.538\n",
      "2019-04-09 20:44:26,871 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 0.086285\n",
      "Reconstruction: 0.054898, Regularization: 0.000120, Discriminator: 0.021564; Generator: 0.009702,\n",
      "D(x): 0.545, D(G(z)): 0.537\n",
      "2019-04-09 20:44:26,938 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 0.089475\n",
      "Reconstruction: 0.057789, Regularization: 0.000128, Discriminator: 0.021844; Generator: 0.009715,\n",
      "D(x): 0.535, D(G(z)): 0.537\n",
      "2019-04-09 20:44:27,006 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 0.091221\n",
      "Reconstruction: 0.059631, Regularization: 0.000133, Discriminator: 0.021731; Generator: 0.009727,\n",
      "D(x): 0.538, D(G(z)): 0.537\n",
      "2019-04-09 20:44:27,074 root         INFO     ====> Epoch: 8 Average loss: 0.0840\n",
      "2019-04-09 20:44:27,098 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 0.076289\n",
      "Reconstruction: 0.044733, Regularization: 0.000091, Discriminator: 0.021721; Generator: 0.009744,\n",
      "D(x): 0.537, D(G(z)): 0.536\n",
      "2019-04-09 20:44:27,166 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 0.089687\n",
      "Reconstruction: 0.057872, Regularization: 0.000129, Discriminator: 0.021929; Generator: 0.009758,\n",
      "D(x): 0.530, D(G(z)): 0.536\n",
      "2019-04-09 20:44:27,233 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 0.084529\n",
      "Reconstruction: 0.052881, Regularization: 0.000114, Discriminator: 0.021761; Generator: 0.009773,\n",
      "D(x): 0.535, D(G(z)): 0.535\n",
      "2019-04-09 20:44:27,301 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 0.077234\n",
      "Reconstruction: 0.045647, Regularization: 0.000092, Discriminator: 0.021711; Generator: 0.009784,\n",
      "D(x): 0.536, D(G(z)): 0.535\n",
      "2019-04-09 20:44:27,368 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 0.086649\n",
      "Reconstruction: 0.054846, Regularization: 0.000118, Discriminator: 0.021881; Generator: 0.009804,\n",
      "D(x): 0.530, D(G(z)): 0.534\n",
      "2019-04-09 20:44:27,435 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 0.078339\n",
      "Reconstruction: 0.046607, Regularization: 0.000093, Discriminator: 0.021827; Generator: 0.009812,\n",
      "D(x): 0.531, D(G(z)): 0.534\n",
      "2019-04-09 20:44:27,502 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 0.070463\n",
      "Reconstruction: 0.038850, Regularization: 0.000071, Discriminator: 0.021707; Generator: 0.009835,\n",
      "D(x): 0.534, D(G(z)): 0.533\n",
      "2019-04-09 20:44:27,568 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 0.080456\n",
      "Reconstruction: 0.048769, Regularization: 0.000099, Discriminator: 0.021740; Generator: 0.009847,\n",
      "D(x): 0.533, D(G(z)): 0.532\n",
      "2019-04-09 20:44:27,636 root         INFO     ====> Epoch: 9 Average loss: 0.0841\n",
      "2019-04-09 20:44:27,661 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 0.089358\n",
      "Reconstruction: 0.057747, Regularization: 0.000125, Discriminator: 0.021624; Generator: 0.009862,\n",
      "D(x): 0.536, D(G(z)): 0.532\n",
      "2019-04-09 20:44:27,733 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 0.088550\n",
      "Reconstruction: 0.056991, Regularization: 0.000122, Discriminator: 0.021560; Generator: 0.009877,\n",
      "D(x): 0.538, D(G(z)): 0.531\n",
      "2019-04-09 20:44:27,798 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 0.089209\n",
      "Reconstruction: 0.057176, Regularization: 0.000123, Discriminator: 0.022017; Generator: 0.009892,\n",
      "D(x): 0.522, D(G(z)): 0.531\n",
      "2019-04-09 20:44:27,864 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 0.080845\n",
      "Reconstruction: 0.049196, Regularization: 0.000100, Discriminator: 0.021645; Generator: 0.009904,\n",
      "D(x): 0.534, D(G(z)): 0.531\n",
      "2019-04-09 20:44:27,930 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 0.081240\n",
      "Reconstruction: 0.049457, Regularization: 0.000100, Discriminator: 0.021764; Generator: 0.009919,\n",
      "D(x): 0.529, D(G(z)): 0.530\n",
      "2019-04-09 20:44:27,996 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 0.094788\n",
      "Reconstruction: 0.062879, Regularization: 0.000138, Discriminator: 0.021829; Generator: 0.009942,\n",
      "D(x): 0.526, D(G(z)): 0.529\n",
      "2019-04-09 20:44:28,062 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 0.085419\n",
      "Reconstruction: 0.053592, Regularization: 0.000112, Discriminator: 0.021764; Generator: 0.009951,\n",
      "D(x): 0.528, D(G(z)): 0.529\n",
      "2019-04-09 20:44:28,128 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 0.089646\n",
      "Reconstruction: 0.057930, Regularization: 0.000125, Discriminator: 0.021626; Generator: 0.009966,\n",
      "D(x): 0.532, D(G(z)): 0.528\n",
      "2019-04-09 20:44:28,196 root         INFO     ====> Epoch: 10 Average loss: 0.0843\n",
      "2019-04-09 20:44:28,220 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.083179\n",
      "Reconstruction: 0.051467, Regularization: 0.000107, Discriminator: 0.021632; Generator: 0.009972,\n",
      "D(x): 0.532, D(G(z)): 0.528\n",
      "2019-04-09 20:44:28,286 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 0.097543\n",
      "Reconstruction: 0.065569, Regularization: 0.000147, Discriminator: 0.021838; Generator: 0.009989,\n",
      "D(x): 0.524, D(G(z)): 0.528\n",
      "2019-04-09 20:44:28,352 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.095241\n",
      "Reconstruction: 0.063485, Regularization: 0.000141, Discriminator: 0.021613; Generator: 0.010003,\n",
      "D(x): 0.531, D(G(z)): 0.527\n",
      "2019-04-09 20:44:28,418 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 0.076023\n",
      "Reconstruction: 0.044260, Regularization: 0.000086, Discriminator: 0.021659; Generator: 0.010019,\n",
      "D(x): 0.529, D(G(z)): 0.527\n",
      "2019-04-09 20:44:28,484 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 0.074659\n",
      "Reconstruction: 0.042699, Regularization: 0.000079, Discriminator: 0.021853; Generator: 0.010029,\n",
      "D(x): 0.522, D(G(z)): 0.526\n",
      "2019-04-09 20:44:28,549 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 0.089603\n",
      "Reconstruction: 0.057877, Regularization: 0.000122, Discriminator: 0.021563; Generator: 0.010041,\n",
      "D(x): 0.532, D(G(z)): 0.526\n",
      "2019-04-09 20:44:28,615 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.074310\n",
      "Reconstruction: 0.042638, Regularization: 0.000078, Discriminator: 0.021539; Generator: 0.010056,\n",
      "D(x): 0.532, D(G(z)): 0.525\n",
      "2019-04-09 20:44:28,680 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 0.073152\n",
      "Reconstruction: 0.041324, Regularization: 0.000072, Discriminator: 0.021692; Generator: 0.010063,\n",
      "D(x): 0.526, D(G(z)): 0.525\n",
      "2019-04-09 20:44:28,747 root         INFO     ====> Epoch: 11 Average loss: 0.0843\n",
      "2019-04-09 20:44:28,771 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 0.085357\n",
      "Reconstruction: 0.053443, Regularization: 0.000103, Discriminator: 0.021733; Generator: 0.010078,\n",
      "D(x): 0.524, D(G(z)): 0.525\n",
      "2019-04-09 20:44:28,834 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 0.078449\n",
      "Reconstruction: 0.046706, Regularization: 0.000086, Discriminator: 0.021568; Generator: 0.010090,\n",
      "D(x): 0.529, D(G(z)): 0.524\n",
      "2019-04-09 20:44:28,897 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 0.084860\n",
      "Reconstruction: 0.052994, Regularization: 0.000103, Discriminator: 0.021660; Generator: 0.010103,\n",
      "D(x): 0.526, D(G(z)): 0.524\n",
      "2019-04-09 20:44:28,960 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 0.093978\n",
      "Reconstruction: 0.062064, Regularization: 0.000130, Discriminator: 0.021668; Generator: 0.010116,\n",
      "D(x): 0.525, D(G(z)): 0.523\n",
      "2019-04-09 20:44:29,023 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 0.095831\n",
      "Reconstruction: 0.063719, Regularization: 0.000139, Discriminator: 0.021845; Generator: 0.010128,\n",
      "D(x): 0.519, D(G(z)): 0.523\n",
      "2019-04-09 20:44:29,086 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.080777\n",
      "Reconstruction: 0.048801, Regularization: 0.000097, Discriminator: 0.021727; Generator: 0.010153,\n",
      "D(x): 0.522, D(G(z)): 0.522\n",
      "2019-04-09 20:44:29,149 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.089762\n",
      "Reconstruction: 0.057663, Regularization: 0.000122, Discriminator: 0.021823; Generator: 0.010154,\n",
      "D(x): 0.519, D(G(z)): 0.522\n",
      "2019-04-09 20:44:29,212 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 0.079490\n",
      "Reconstruction: 0.047442, Regularization: 0.000092, Discriminator: 0.021797; Generator: 0.010159,\n",
      "D(x): 0.519, D(G(z)): 0.522\n",
      "2019-04-09 20:44:29,278 root         INFO     ====> Epoch: 12 Average loss: 0.0844\n",
      "2019-04-09 20:44:29,302 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 0.093303\n",
      "Reconstruction: 0.061342, Regularization: 0.000133, Discriminator: 0.021655; Generator: 0.010173,\n",
      "D(x): 0.524, D(G(z)): 0.521\n",
      "2019-04-09 20:44:29,369 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 0.082664\n",
      "Reconstruction: 0.050514, Regularization: 0.000104, Discriminator: 0.021869; Generator: 0.010177,\n",
      "D(x): 0.516, D(G(z)): 0.521\n",
      "2019-04-09 20:44:29,439 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 0.080112\n",
      "Reconstruction: 0.047889, Regularization: 0.000094, Discriminator: 0.021940; Generator: 0.010189,\n",
      "D(x): 0.513, D(G(z)): 0.521\n",
      "2019-04-09 20:44:29,508 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 0.086061\n",
      "Reconstruction: 0.054131, Regularization: 0.000109, Discriminator: 0.021622; Generator: 0.010200,\n",
      "D(x): 0.524, D(G(z)): 0.521\n",
      "2019-04-09 20:44:29,577 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 0.077004\n",
      "Reconstruction: 0.045032, Regularization: 0.000082, Discriminator: 0.021677; Generator: 0.010213,\n",
      "D(x): 0.521, D(G(z)): 0.520\n",
      "2019-04-09 20:44:29,647 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 0.076910\n",
      "Reconstruction: 0.044794, Regularization: 0.000081, Discriminator: 0.021818; Generator: 0.010218,\n",
      "D(x): 0.516, D(G(z)): 0.520\n",
      "2019-04-09 20:44:29,716 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 0.088464\n",
      "Reconstruction: 0.056459, Regularization: 0.000112, Discriminator: 0.021655; Generator: 0.010238,\n",
      "D(x): 0.521, D(G(z)): 0.519\n",
      "2019-04-09 20:44:29,786 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 0.069020\n",
      "Reconstruction: 0.037046, Regularization: 0.000060, Discriminator: 0.021661; Generator: 0.010252,\n",
      "D(x): 0.520, D(G(z)): 0.519\n",
      "2019-04-09 20:44:29,857 root         INFO     ====> Epoch: 13 Average loss: 0.0845\n",
      "2019-04-09 20:44:29,881 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.089351\n",
      "Reconstruction: 0.057412, Regularization: 0.000112, Discriminator: 0.021570; Generator: 0.010258,\n",
      "D(x): 0.523, D(G(z)): 0.519\n",
      "2019-04-09 20:44:29,948 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.081675\n",
      "Reconstruction: 0.049651, Regularization: 0.000089, Discriminator: 0.021664; Generator: 0.010270,\n",
      "D(x): 0.520, D(G(z)): 0.518\n",
      "2019-04-09 20:44:30,016 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 0.084994\n",
      "Reconstruction: 0.052854, Regularization: 0.000094, Discriminator: 0.021767; Generator: 0.010279,\n",
      "D(x): 0.516, D(G(z)): 0.518\n",
      "2019-04-09 20:44:30,083 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.091698\n",
      "Reconstruction: 0.059547, Regularization: 0.000112, Discriminator: 0.021753; Generator: 0.010286,\n",
      "D(x): 0.516, D(G(z)): 0.518\n",
      "2019-04-09 20:44:30,151 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.078872\n",
      "Reconstruction: 0.046865, Regularization: 0.000080, Discriminator: 0.021623; Generator: 0.010304,\n",
      "D(x): 0.520, D(G(z)): 0.517\n",
      "2019-04-09 20:44:30,218 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 0.084395\n",
      "Reconstruction: 0.052240, Regularization: 0.000093, Discriminator: 0.021757; Generator: 0.010305,\n",
      "D(x): 0.515, D(G(z)): 0.517\n",
      "2019-04-09 20:44:30,283 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.076046\n",
      "Reconstruction: 0.043743, Regularization: 0.000074, Discriminator: 0.021911; Generator: 0.010318,\n",
      "D(x): 0.510, D(G(z)): 0.517\n",
      "2019-04-09 20:44:30,348 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.078690\n",
      "Reconstruction: 0.046571, Regularization: 0.000081, Discriminator: 0.021714; Generator: 0.010325,\n",
      "D(x): 0.516, D(G(z)): 0.516\n",
      "2019-04-09 20:44:30,414 root         INFO     ====> Epoch: 14 Average loss: 0.0846\n",
      "2019-04-09 20:44:30,438 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 0.093106\n",
      "Reconstruction: 0.060801, Regularization: 0.000117, Discriminator: 0.021853; Generator: 0.010336,\n",
      "D(x): 0.511, D(G(z)): 0.516\n",
      "2019-04-09 20:44:30,507 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 0.092950\n",
      "Reconstruction: 0.060936, Regularization: 0.000116, Discriminator: 0.021551; Generator: 0.010347,\n",
      "D(x): 0.521, D(G(z)): 0.516\n",
      "2019-04-09 20:44:30,575 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.101549\n",
      "Reconstruction: 0.069177, Regularization: 0.000133, Discriminator: 0.021887; Generator: 0.010352,\n",
      "D(x): 0.510, D(G(z)): 0.516\n",
      "2019-04-09 20:44:30,643 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.079753\n",
      "Reconstruction: 0.047730, Regularization: 0.000081, Discriminator: 0.021585; Generator: 0.010357,\n",
      "D(x): 0.519, D(G(z)): 0.515\n",
      "2019-04-09 20:44:30,711 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.092237\n",
      "Reconstruction: 0.060179, Regularization: 0.000110, Discriminator: 0.021575; Generator: 0.010374,\n",
      "D(x): 0.519, D(G(z)): 0.515\n",
      "2019-04-09 20:44:30,778 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.096155\n",
      "Reconstruction: 0.063993, Regularization: 0.000118, Discriminator: 0.021659; Generator: 0.010385,\n",
      "D(x): 0.516, D(G(z)): 0.514\n",
      "2019-04-09 20:44:30,845 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.073681\n",
      "Reconstruction: 0.041533, Regularization: 0.000064, Discriminator: 0.021691; Generator: 0.010393,\n",
      "D(x): 0.514, D(G(z)): 0.514\n",
      "2019-04-09 20:44:30,912 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 0.090416\n",
      "Reconstruction: 0.058198, Regularization: 0.000104, Discriminator: 0.021715; Generator: 0.010399,\n",
      "D(x): 0.514, D(G(z)): 0.514\n",
      "2019-04-09 20:44:30,980 root         INFO     ====> Epoch: 15 Average loss: 0.0846\n",
      "2019-04-09 20:44:31,004 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 0.101962\n",
      "Reconstruction: 0.069588, Regularization: 0.000130, Discriminator: 0.021837; Generator: 0.010407,\n",
      "D(x): 0.510, D(G(z)): 0.514\n",
      "2019-04-09 20:44:31,071 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 0.073311\n",
      "Reconstruction: 0.041167, Regularization: 0.000063, Discriminator: 0.021672; Generator: 0.010409,\n",
      "D(x): 0.514, D(G(z)): 0.514\n",
      "2019-04-09 20:44:31,138 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.099511\n",
      "Reconstruction: 0.067108, Regularization: 0.000123, Discriminator: 0.021860; Generator: 0.010420,\n",
      "D(x): 0.508, D(G(z)): 0.513\n",
      "2019-04-09 20:44:31,206 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 0.088963\n",
      "Reconstruction: 0.056659, Regularization: 0.000099, Discriminator: 0.021773; Generator: 0.010432,\n",
      "D(x): 0.511, D(G(z)): 0.513\n",
      "2019-04-09 20:44:31,273 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 0.085943\n",
      "Reconstruction: 0.053817, Regularization: 0.000093, Discriminator: 0.021594; Generator: 0.010439,\n",
      "D(x): 0.516, D(G(z)): 0.513\n",
      "2019-04-09 20:44:31,341 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 0.076957\n",
      "Reconstruction: 0.044753, Regularization: 0.000071, Discriminator: 0.021683; Generator: 0.010449,\n",
      "D(x): 0.513, D(G(z)): 0.512\n",
      "2019-04-09 20:44:31,409 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 0.085184\n",
      "Reconstruction: 0.052892, Regularization: 0.000090, Discriminator: 0.021750; Generator: 0.010451,\n",
      "D(x): 0.511, D(G(z)): 0.512\n",
      "2019-04-09 20:44:31,476 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.097236\n",
      "Reconstruction: 0.065153, Regularization: 0.000120, Discriminator: 0.021506; Generator: 0.010457,\n",
      "D(x): 0.519, D(G(z)): 0.512\n",
      "2019-04-09 20:44:31,545 root         INFO     ====> Epoch: 16 Average loss: 0.0847\n",
      "2019-04-09 20:44:31,569 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.085334\n",
      "Reconstruction: 0.052994, Regularization: 0.000094, Discriminator: 0.021780; Generator: 0.010467,\n",
      "D(x): 0.509, D(G(z)): 0.512\n",
      "2019-04-09 20:44:31,635 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 0.090089\n",
      "Reconstruction: 0.057867, Regularization: 0.000105, Discriminator: 0.021646; Generator: 0.010471,\n",
      "D(x): 0.513, D(G(z)): 0.512\n",
      "2019-04-09 20:44:31,703 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.083657\n",
      "Reconstruction: 0.051538, Regularization: 0.000088, Discriminator: 0.021555; Generator: 0.010476,\n",
      "D(x): 0.516, D(G(z)): 0.511\n",
      "2019-04-09 20:44:31,770 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 0.083990\n",
      "Reconstruction: 0.051838, Regularization: 0.000089, Discriminator: 0.021586; Generator: 0.010477,\n",
      "D(x): 0.515, D(G(z)): 0.511\n",
      "2019-04-09 20:44:31,838 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.089660\n",
      "Reconstruction: 0.057101, Regularization: 0.000101, Discriminator: 0.021961; Generator: 0.010497,\n",
      "D(x): 0.502, D(G(z)): 0.511\n",
      "2019-04-09 20:44:31,905 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 0.084121\n",
      "Reconstruction: 0.051876, Regularization: 0.000088, Discriminator: 0.021655; Generator: 0.010501,\n",
      "D(x): 0.512, D(G(z)): 0.511\n",
      "2019-04-09 20:44:31,972 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 0.081799\n",
      "Reconstruction: 0.049711, Regularization: 0.000082, Discriminator: 0.021494; Generator: 0.010512,\n",
      "D(x): 0.517, D(G(z)): 0.510\n",
      "2019-04-09 20:44:32,040 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 0.088334\n",
      "Reconstruction: 0.055989, Regularization: 0.000096, Discriminator: 0.021734; Generator: 0.010515,\n",
      "D(x): 0.509, D(G(z)): 0.510\n",
      "2019-04-09 20:44:32,108 root         INFO     ====> Epoch: 17 Average loss: 0.0847\n",
      "2019-04-09 20:44:32,133 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 0.081978\n",
      "Reconstruction: 0.049542, Regularization: 0.000081, Discriminator: 0.021836; Generator: 0.010518,\n",
      "D(x): 0.505, D(G(z)): 0.510\n",
      "2019-04-09 20:44:32,201 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.096843\n",
      "Reconstruction: 0.064581, Regularization: 0.000117, Discriminator: 0.021621; Generator: 0.010523,\n",
      "D(x): 0.513, D(G(z)): 0.510\n",
      "2019-04-09 20:44:32,269 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 0.088635\n",
      "Reconstruction: 0.056181, Regularization: 0.000096, Discriminator: 0.021823; Generator: 0.010535,\n",
      "D(x): 0.505, D(G(z)): 0.510\n",
      "2019-04-09 20:44:32,337 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.086590\n",
      "Reconstruction: 0.054213, Regularization: 0.000092, Discriminator: 0.021744; Generator: 0.010541,\n",
      "D(x): 0.508, D(G(z)): 0.509\n",
      "2019-04-09 20:44:32,404 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 0.088364\n",
      "Reconstruction: 0.055899, Regularization: 0.000098, Discriminator: 0.021823; Generator: 0.010544,\n",
      "D(x): 0.505, D(G(z)): 0.509\n",
      "2019-04-09 20:44:32,472 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.091348\n",
      "Reconstruction: 0.059100, Regularization: 0.000107, Discriminator: 0.021591; Generator: 0.010550,\n",
      "D(x): 0.513, D(G(z)): 0.509\n",
      "2019-04-09 20:44:32,539 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 0.074225\n",
      "Reconstruction: 0.041756, Regularization: 0.000066, Discriminator: 0.021848; Generator: 0.010554,\n",
      "D(x): 0.504, D(G(z)): 0.509\n",
      "2019-04-09 20:44:32,607 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 0.078550\n",
      "Reconstruction: 0.046346, Regularization: 0.000078, Discriminator: 0.021568; Generator: 0.010558,\n",
      "D(x): 0.513, D(G(z)): 0.509\n",
      "2019-04-09 20:44:32,675 root         INFO     ====> Epoch: 18 Average loss: 0.0848\n",
      "2019-04-09 20:44:32,699 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 0.083825\n",
      "Reconstruction: 0.051361, Regularization: 0.000091, Discriminator: 0.021814; Generator: 0.010559,\n",
      "D(x): 0.505, D(G(z)): 0.509\n",
      "2019-04-09 20:44:32,766 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 0.079961\n",
      "Reconstruction: 0.047566, Regularization: 0.000081, Discriminator: 0.021749; Generator: 0.010565,\n",
      "D(x): 0.507, D(G(z)): 0.509\n",
      "2019-04-09 20:44:32,833 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 0.085083\n",
      "Reconstruction: 0.052917, Regularization: 0.000095, Discriminator: 0.021503; Generator: 0.010568,\n",
      "D(x): 0.515, D(G(z)): 0.508\n",
      "2019-04-09 20:44:32,899 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 0.080359\n",
      "Reconstruction: 0.048081, Regularization: 0.000083, Discriminator: 0.021618; Generator: 0.010577,\n",
      "D(x): 0.510, D(G(z)): 0.508\n",
      "2019-04-09 20:44:32,964 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 0.073275\n",
      "Reconstruction: 0.040936, Regularization: 0.000066, Discriminator: 0.021688; Generator: 0.010584,\n",
      "D(x): 0.508, D(G(z)): 0.508\n",
      "2019-04-09 20:44:33,030 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 0.085384\n",
      "Reconstruction: 0.053120, Regularization: 0.000093, Discriminator: 0.021584; Generator: 0.010586,\n",
      "D(x): 0.511, D(G(z)): 0.508\n",
      "2019-04-09 20:44:33,096 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 0.097880\n",
      "Reconstruction: 0.065335, Regularization: 0.000122, Discriminator: 0.021830; Generator: 0.010593,\n",
      "D(x): 0.503, D(G(z)): 0.508\n",
      "2019-04-09 20:44:33,162 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.093702\n",
      "Reconstruction: 0.061531, Regularization: 0.000111, Discriminator: 0.021463; Generator: 0.010596,\n",
      "D(x): 0.515, D(G(z)): 0.508\n",
      "2019-04-09 20:44:33,230 root         INFO     ====> Epoch: 19 Average loss: 0.0849\n",
      "2019-04-09 20:44:33,254 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 0.089499\n",
      "Reconstruction: 0.056854, Regularization: 0.000103, Discriminator: 0.021941; Generator: 0.010601,\n",
      "D(x): 0.499, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,318 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 0.090881\n",
      "Reconstruction: 0.058494, Regularization: 0.000106, Discriminator: 0.021679; Generator: 0.010600,\n",
      "D(x): 0.508, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,384 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 0.081347\n",
      "Reconstruction: 0.049173, Regularization: 0.000082, Discriminator: 0.021487; Generator: 0.010605,\n",
      "D(x): 0.514, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,450 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 0.094342\n",
      "Reconstruction: 0.061802, Regularization: 0.000112, Discriminator: 0.021811; Generator: 0.010617,\n",
      "D(x): 0.503, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,516 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 0.093774\n",
      "Reconstruction: 0.061428, Regularization: 0.000112, Discriminator: 0.021615; Generator: 0.010618,\n",
      "D(x): 0.509, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,582 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 0.093324\n",
      "Reconstruction: 0.061101, Regularization: 0.000113, Discriminator: 0.021487; Generator: 0.010624,\n",
      "D(x): 0.513, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,648 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 0.091283\n",
      "Reconstruction: 0.058724, Regularization: 0.000106, Discriminator: 0.021827; Generator: 0.010626,\n",
      "D(x): 0.502, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,714 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 0.077966\n",
      "Reconstruction: 0.045583, Regularization: 0.000074, Discriminator: 0.021681; Generator: 0.010629,\n",
      "D(x): 0.507, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,781 root         INFO     ====> Epoch: 20 Average loss: 0.0849\n",
      "2019-04-09 20:44:33,805 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.087743\n",
      "Reconstruction: 0.055340, Regularization: 0.000096, Discriminator: 0.021672; Generator: 0.010635,\n",
      "D(x): 0.507, D(G(z)): 0.506\n",
      "2019-04-09 20:44:33,871 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 0.071542\n",
      "Reconstruction: 0.039202, Regularization: 0.000058, Discriminator: 0.021646; Generator: 0.010636,\n",
      "D(x): 0.507, D(G(z)): 0.506\n",
      "2019-04-09 20:44:33,936 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 0.089217\n",
      "Reconstruction: 0.057042, Regularization: 0.000100, Discriminator: 0.021436; Generator: 0.010639,\n",
      "D(x): 0.514, D(G(z)): 0.506\n",
      "2019-04-09 20:44:34,002 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 0.079035\n",
      "Reconstruction: 0.046591, Regularization: 0.000075, Discriminator: 0.021723; Generator: 0.010646,\n",
      "D(x): 0.505, D(G(z)): 0.506\n",
      "2019-04-09 20:44:34,066 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.085205\n",
      "Reconstruction: 0.052964, Regularization: 0.000090, Discriminator: 0.021510; Generator: 0.010641,\n",
      "D(x): 0.512, D(G(z)): 0.506\n",
      "2019-04-09 20:44:34,132 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 0.081236\n",
      "Reconstruction: 0.048878, Regularization: 0.000079, Discriminator: 0.021632; Generator: 0.010647,\n",
      "D(x): 0.508, D(G(z)): 0.506\n",
      "2019-04-09 20:44:34,197 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 0.089798\n",
      "Reconstruction: 0.057229, Regularization: 0.000099, Discriminator: 0.021816; Generator: 0.010654,\n",
      "D(x): 0.502, D(G(z)): 0.506\n",
      "2019-04-09 20:44:34,260 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.082014\n",
      "Reconstruction: 0.049472, Regularization: 0.000081, Discriminator: 0.021808; Generator: 0.010653,\n",
      "D(x): 0.502, D(G(z)): 0.506\n",
      "2019-04-09 20:44:34,327 root         INFO     ====> Epoch: 21 Average loss: 0.0849\n",
      "2019-04-09 20:44:34,351 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 0.089645\n",
      "Reconstruction: 0.057140, Regularization: 0.000098, Discriminator: 0.021742; Generator: 0.010664,\n",
      "D(x): 0.504, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,418 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 0.087188\n",
      "Reconstruction: 0.054938, Regularization: 0.000092, Discriminator: 0.021489; Generator: 0.010670,\n",
      "D(x): 0.512, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,484 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 0.087721\n",
      "Reconstruction: 0.055163, Regularization: 0.000092, Discriminator: 0.021803; Generator: 0.010663,\n",
      "D(x): 0.502, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,550 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 0.088696\n",
      "Reconstruction: 0.056379, Regularization: 0.000095, Discriminator: 0.021554; Generator: 0.010668,\n",
      "D(x): 0.510, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,616 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.076161\n",
      "Reconstruction: 0.043834, Regularization: 0.000066, Discriminator: 0.021587; Generator: 0.010674,\n",
      "D(x): 0.508, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,680 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 0.083493\n",
      "Reconstruction: 0.051276, Regularization: 0.000082, Discriminator: 0.021462; Generator: 0.010674,\n",
      "D(x): 0.512, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,742 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 0.094870\n",
      "Reconstruction: 0.062367, Regularization: 0.000104, Discriminator: 0.021713; Generator: 0.010686,\n",
      "D(x): 0.504, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,805 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 0.093025\n",
      "Reconstruction: 0.060383, Regularization: 0.000099, Discriminator: 0.021856; Generator: 0.010687,\n",
      "D(x): 0.499, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,872 root         INFO     ====> Epoch: 22 Average loss: 0.0849\n",
      "2019-04-09 20:44:34,897 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 0.080576\n",
      "Reconstruction: 0.048252, Regularization: 0.000071, Discriminator: 0.021567; Generator: 0.010685,\n",
      "D(x): 0.508, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,963 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 0.076241\n",
      "Reconstruction: 0.043818, Regularization: 0.000063, Discriminator: 0.021671; Generator: 0.010689,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-09 20:44:35,029 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 0.095493\n",
      "Reconstruction: 0.062932, Regularization: 0.000103, Discriminator: 0.021760; Generator: 0.010698,\n",
      "D(x): 0.502, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,095 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 0.075033\n",
      "Reconstruction: 0.042704, Regularization: 0.000059, Discriminator: 0.021577; Generator: 0.010694,\n",
      "D(x): 0.508, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,161 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 0.088039\n",
      "Reconstruction: 0.055591, Regularization: 0.000085, Discriminator: 0.021665; Generator: 0.010698,\n",
      "D(x): 0.505, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,227 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 0.085437\n",
      "Reconstruction: 0.053112, Regularization: 0.000078, Discriminator: 0.021545; Generator: 0.010702,\n",
      "D(x): 0.509, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,293 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 0.092201\n",
      "Reconstruction: 0.059868, Regularization: 0.000090, Discriminator: 0.021541; Generator: 0.010702,\n",
      "D(x): 0.509, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,359 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 0.088205\n",
      "Reconstruction: 0.055588, Regularization: 0.000083, Discriminator: 0.021827; Generator: 0.010706,\n",
      "D(x): 0.499, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,427 root         INFO     ====> Epoch: 23 Average loss: 0.0850\n",
      "2019-04-09 20:44:35,451 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.082664\n",
      "Reconstruction: 0.050397, Regularization: 0.000075, Discriminator: 0.021487; Generator: 0.010705,\n",
      "D(x): 0.510, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,517 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 0.076918\n",
      "Reconstruction: 0.044360, Regularization: 0.000064, Discriminator: 0.021788; Generator: 0.010707,\n",
      "D(x): 0.500, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,584 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 0.102761\n",
      "Reconstruction: 0.070107, Regularization: 0.000120, Discriminator: 0.021821; Generator: 0.010712,\n",
      "D(x): 0.500, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,650 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 0.095542\n",
      "Reconstruction: 0.063206, Regularization: 0.000105, Discriminator: 0.021523; Generator: 0.010708,\n",
      "D(x): 0.509, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,716 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 0.087092\n",
      "Reconstruction: 0.054553, Regularization: 0.000086, Discriminator: 0.021737; Generator: 0.010716,\n",
      "D(x): 0.502, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,783 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 0.078982\n",
      "Reconstruction: 0.046548, Regularization: 0.000069, Discriminator: 0.021648; Generator: 0.010718,\n",
      "D(x): 0.505, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,848 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 0.080518\n",
      "Reconstruction: 0.048065, Regularization: 0.000071, Discriminator: 0.021661; Generator: 0.010720,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,913 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 0.082593\n",
      "Reconstruction: 0.050119, Regularization: 0.000075, Discriminator: 0.021675; Generator: 0.010725,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-09 20:44:35,980 root         INFO     ====> Epoch: 24 Average loss: 0.0850\n",
      "2019-04-09 20:44:36,004 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 0.088048\n",
      "Reconstruction: 0.055703, Regularization: 0.000087, Discriminator: 0.021533; Generator: 0.010725,\n",
      "D(x): 0.508, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,071 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 0.081564\n",
      "Reconstruction: 0.049009, Regularization: 0.000072, Discriminator: 0.021756; Generator: 0.010727,\n",
      "D(x): 0.501, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,137 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 0.081150\n",
      "Reconstruction: 0.048780, Regularization: 0.000071, Discriminator: 0.021575; Generator: 0.010724,\n",
      "D(x): 0.507, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,204 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 0.091249\n",
      "Reconstruction: 0.058693, Regularization: 0.000094, Discriminator: 0.021734; Generator: 0.010728,\n",
      "D(x): 0.502, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,270 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 0.088705\n",
      "Reconstruction: 0.056258, Regularization: 0.000086, Discriminator: 0.021628; Generator: 0.010733,\n",
      "D(x): 0.505, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,336 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 0.085529\n",
      "Reconstruction: 0.052977, Regularization: 0.000079, Discriminator: 0.021741; Generator: 0.010732,\n",
      "D(x): 0.501, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,402 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.072055\n",
      "Reconstruction: 0.039762, Regularization: 0.000050, Discriminator: 0.021511; Generator: 0.010732,\n",
      "D(x): 0.508, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,467 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 0.078220\n",
      "Reconstruction: 0.045862, Regularization: 0.000062, Discriminator: 0.021558; Generator: 0.010737,\n",
      "D(x): 0.507, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,533 root         INFO     ====> Epoch: 25 Average loss: 0.0850\n",
      "2019-04-09 20:44:36,557 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 0.089467\n",
      "Reconstruction: 0.056854, Regularization: 0.000086, Discriminator: 0.021789; Generator: 0.010739,\n",
      "D(x): 0.500, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,625 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 0.076597\n",
      "Reconstruction: 0.044201, Regularization: 0.000061, Discriminator: 0.021593; Generator: 0.010742,\n",
      "D(x): 0.506, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,692 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 0.087765\n",
      "Reconstruction: 0.055257, Regularization: 0.000084, Discriminator: 0.021681; Generator: 0.010743,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,759 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 0.093981\n",
      "Reconstruction: 0.061363, Regularization: 0.000096, Discriminator: 0.021775; Generator: 0.010747,\n",
      "D(x): 0.500, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,826 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.075146\n",
      "Reconstruction: 0.042566, Regularization: 0.000057, Discriminator: 0.021788; Generator: 0.010735,\n",
      "D(x): 0.499, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,893 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 0.089873\n",
      "Reconstruction: 0.057123, Regularization: 0.000085, Discriminator: 0.021926; Generator: 0.010740,\n",
      "D(x): 0.495, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,960 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 0.085150\n",
      "Reconstruction: 0.052701, Regularization: 0.000078, Discriminator: 0.021628; Generator: 0.010743,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-09 20:44:37,028 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 0.075688\n",
      "Reconstruction: 0.043201, Regularization: 0.000060, Discriminator: 0.021683; Generator: 0.010744,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-09 20:44:37,098 root         INFO     ====> Epoch: 26 Average loss: 0.0850\n",
      "2019-04-09 20:44:37,122 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 0.083360\n",
      "Reconstruction: 0.050890, Regularization: 0.000077, Discriminator: 0.021646; Generator: 0.010747,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-09 20:44:37,190 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.076182\n",
      "Reconstruction: 0.043663, Regularization: 0.000061, Discriminator: 0.021695; Generator: 0.010762,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,257 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 0.094527\n",
      "Reconstruction: 0.061810, Regularization: 0.000098, Discriminator: 0.021861; Generator: 0.010758,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,324 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.075028\n",
      "Reconstruction: 0.042498, Regularization: 0.000058, Discriminator: 0.021714; Generator: 0.010758,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,392 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 0.082405\n",
      "Reconstruction: 0.050095, Regularization: 0.000074, Discriminator: 0.021477; Generator: 0.010759,\n",
      "D(x): 0.509, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,457 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.078118\n",
      "Reconstruction: 0.045472, Regularization: 0.000065, Discriminator: 0.021816; Generator: 0.010765,\n",
      "D(x): 0.498, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,524 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.083613\n",
      "Reconstruction: 0.051091, Regularization: 0.000078, Discriminator: 0.021680; Generator: 0.010764,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,590 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 0.094066\n",
      "Reconstruction: 0.061638, Regularization: 0.000100, Discriminator: 0.021572; Generator: 0.010757,\n",
      "D(x): 0.506, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,658 root         INFO     ====> Epoch: 27 Average loss: 0.0850\n",
      "2019-04-09 20:44:37,682 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.082951\n",
      "Reconstruction: 0.050335, Regularization: 0.000075, Discriminator: 0.021782; Generator: 0.010758,\n",
      "D(x): 0.499, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,749 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.088770\n",
      "Reconstruction: 0.056064, Regularization: 0.000091, Discriminator: 0.021859; Generator: 0.010757,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,817 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 0.080446\n",
      "Reconstruction: 0.047927, Regularization: 0.000074, Discriminator: 0.021687; Generator: 0.010758,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,886 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.072479\n",
      "Reconstruction: 0.039919, Regularization: 0.000055, Discriminator: 0.021748; Generator: 0.010757,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,956 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.090068\n",
      "Reconstruction: 0.057366, Regularization: 0.000092, Discriminator: 0.021853; Generator: 0.010757,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,024 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.088279\n",
      "Reconstruction: 0.055684, Regularization: 0.000087, Discriminator: 0.021749; Generator: 0.010759,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,094 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.072977\n",
      "Reconstruction: 0.040368, Regularization: 0.000055, Discriminator: 0.021795; Generator: 0.010759,\n",
      "D(x): 0.498, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,163 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.092626\n",
      "Reconstruction: 0.060258, Regularization: 0.000097, Discriminator: 0.021511; Generator: 0.010761,\n",
      "D(x): 0.508, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,233 root         INFO     ====> Epoch: 28 Average loss: 0.0850\n",
      "2019-04-09 20:44:38,257 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 0.090939\n",
      "Reconstruction: 0.058433, Regularization: 0.000091, Discriminator: 0.021648; Generator: 0.010766,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,325 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 0.088645\n",
      "Reconstruction: 0.056119, Regularization: 0.000089, Discriminator: 0.021673; Generator: 0.010764,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,392 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 0.083245\n",
      "Reconstruction: 0.050796, Regularization: 0.000079, Discriminator: 0.021606; Generator: 0.010764,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,459 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 0.075001\n",
      "Reconstruction: 0.042558, Regularization: 0.000060, Discriminator: 0.021614; Generator: 0.010768,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,526 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.085939\n",
      "Reconstruction: 0.053249, Regularization: 0.000083, Discriminator: 0.021838; Generator: 0.010769,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,593 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 0.085457\n",
      "Reconstruction: 0.052858, Regularization: 0.000082, Discriminator: 0.021750; Generator: 0.010768,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,660 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 0.096107\n",
      "Reconstruction: 0.063626, Regularization: 0.000105, Discriminator: 0.021610; Generator: 0.010766,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,727 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.096086\n",
      "Reconstruction: 0.063567, Regularization: 0.000104, Discriminator: 0.021643; Generator: 0.010772,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,796 root         INFO     ====> Epoch: 29 Average loss: 0.0850\n",
      "2019-04-09 20:44:38,820 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.085444\n",
      "Reconstruction: 0.052969, Regularization: 0.000080, Discriminator: 0.021621; Generator: 0.010773,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,887 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.082730\n",
      "Reconstruction: 0.050215, Regularization: 0.000076, Discriminator: 0.021664; Generator: 0.010775,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,954 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.078044\n",
      "Reconstruction: 0.045472, Regularization: 0.000064, Discriminator: 0.021725; Generator: 0.010782,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,021 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.095493\n",
      "Reconstruction: 0.062942, Regularization: 0.000101, Discriminator: 0.021670; Generator: 0.010781,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,087 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.072612\n",
      "Reconstruction: 0.040055, Regularization: 0.000053, Discriminator: 0.021720; Generator: 0.010783,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,153 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.087372\n",
      "Reconstruction: 0.054791, Regularization: 0.000084, Discriminator: 0.021714; Generator: 0.010783,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,219 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.090142\n",
      "Reconstruction: 0.057640, Regularization: 0.000089, Discriminator: 0.021638; Generator: 0.010775,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,285 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 0.083845\n",
      "Reconstruction: 0.051308, Regularization: 0.000075, Discriminator: 0.021683; Generator: 0.010780,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,354 root         INFO     ====> Epoch: 30 Average loss: 0.0850\n",
      "2019-04-09 20:44:39,378 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.078607\n",
      "Reconstruction: 0.046171, Regularization: 0.000064, Discriminator: 0.021591; Generator: 0.010781,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,442 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.078166\n",
      "Reconstruction: 0.045789, Regularization: 0.000062, Discriminator: 0.021539; Generator: 0.010776,\n",
      "D(x): 0.506, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,508 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 0.092307\n",
      "Reconstruction: 0.059678, Regularization: 0.000091, Discriminator: 0.021762; Generator: 0.010776,\n",
      "D(x): 0.499, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,574 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.103323\n",
      "Reconstruction: 0.070705, Regularization: 0.000113, Discriminator: 0.021727; Generator: 0.010777,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,641 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.074243\n",
      "Reconstruction: 0.041824, Regularization: 0.000055, Discriminator: 0.021587; Generator: 0.010777,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,707 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.088031\n",
      "Reconstruction: 0.055580, Regularization: 0.000084, Discriminator: 0.021588; Generator: 0.010779,\n",
      "D(x): 0.505, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,773 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 0.074768\n",
      "Reconstruction: 0.042107, Regularization: 0.000056, Discriminator: 0.021827; Generator: 0.010777,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,839 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 0.084670\n",
      "Reconstruction: 0.052042, Regularization: 0.000077, Discriminator: 0.021770; Generator: 0.010781,\n",
      "D(x): 0.499, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,907 root         INFO     ====> Epoch: 31 Average loss: 0.0850\n",
      "2019-04-09 20:44:39,931 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.079269\n",
      "Reconstruction: 0.046673, Regularization: 0.000066, Discriminator: 0.021746; Generator: 0.010784,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:39,999 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.083252\n",
      "Reconstruction: 0.050633, Regularization: 0.000075, Discriminator: 0.021759; Generator: 0.010785,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,066 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.086036\n",
      "Reconstruction: 0.053535, Regularization: 0.000081, Discriminator: 0.021625; Generator: 0.010795,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,133 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.086214\n",
      "Reconstruction: 0.053683, Regularization: 0.000082, Discriminator: 0.021661; Generator: 0.010789,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,200 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.083363\n",
      "Reconstruction: 0.050880, Regularization: 0.000076, Discriminator: 0.021624; Generator: 0.010783,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-09 20:44:40,267 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 0.083105\n",
      "Reconstruction: 0.050632, Regularization: 0.000075, Discriminator: 0.021603; Generator: 0.010795,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,335 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.074416\n",
      "Reconstruction: 0.042074, Regularization: 0.000057, Discriminator: 0.021488; Generator: 0.010797,\n",
      "D(x): 0.507, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,403 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.089959\n",
      "Reconstruction: 0.057355, Regularization: 0.000089, Discriminator: 0.021721; Generator: 0.010794,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,471 root         INFO     ====> Epoch: 32 Average loss: 0.0850\n",
      "2019-04-09 20:44:40,495 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.091977\n",
      "Reconstruction: 0.059402, Regularization: 0.000091, Discriminator: 0.021692; Generator: 0.010793,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,563 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.087832\n",
      "Reconstruction: 0.055292, Regularization: 0.000082, Discriminator: 0.021667; Generator: 0.010790,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,630 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.083306\n",
      "Reconstruction: 0.050757, Regularization: 0.000072, Discriminator: 0.021685; Generator: 0.010792,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,698 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.075443\n",
      "Reconstruction: 0.042842, Regularization: 0.000058, Discriminator: 0.021751; Generator: 0.010792,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,765 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 0.084883\n",
      "Reconstruction: 0.052469, Regularization: 0.000077, Discriminator: 0.021554; Generator: 0.010783,\n",
      "D(x): 0.505, D(G(z)): 0.502\n",
      "2019-04-09 20:44:40,832 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.077169\n",
      "Reconstruction: 0.044700, Regularization: 0.000063, Discriminator: 0.021615; Generator: 0.010791,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,900 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 0.080678\n",
      "Reconstruction: 0.048200, Regularization: 0.000071, Discriminator: 0.021611; Generator: 0.010796,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,967 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.089491\n",
      "Reconstruction: 0.056784, Regularization: 0.000089, Discriminator: 0.021819; Generator: 0.010799,\n",
      "D(x): 0.496, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,034 root         INFO     ====> Epoch: 33 Average loss: 0.0850\n",
      "2019-04-09 20:44:41,059 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.079958\n",
      "Reconstruction: 0.047514, Regularization: 0.000068, Discriminator: 0.021582; Generator: 0.010794,\n",
      "D(x): 0.504, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,127 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.093208\n",
      "Reconstruction: 0.060577, Regularization: 0.000096, Discriminator: 0.021738; Generator: 0.010796,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,194 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.078486\n",
      "Reconstruction: 0.046028, Regularization: 0.000067, Discriminator: 0.021601; Generator: 0.010790,\n",
      "D(x): 0.504, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,261 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.080281\n",
      "Reconstruction: 0.047645, Regularization: 0.000068, Discriminator: 0.021772; Generator: 0.010796,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,329 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.084743\n",
      "Reconstruction: 0.052335, Regularization: 0.000080, Discriminator: 0.021532; Generator: 0.010796,\n",
      "D(x): 0.506, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,393 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.077630\n",
      "Reconstruction: 0.045098, Regularization: 0.000065, Discriminator: 0.021670; Generator: 0.010797,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,457 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.085131\n",
      "Reconstruction: 0.052571, Regularization: 0.000080, Discriminator: 0.021682; Generator: 0.010797,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,520 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 0.073488\n",
      "Reconstruction: 0.041062, Regularization: 0.000055, Discriminator: 0.021574; Generator: 0.010797,\n",
      "D(x): 0.504, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,586 root         INFO     ====> Epoch: 34 Average loss: 0.0851\n",
      "2019-04-09 20:44:41,610 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.084463\n",
      "Reconstruction: 0.051859, Regularization: 0.000078, Discriminator: 0.021730; Generator: 0.010796,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,677 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.093815\n",
      "Reconstruction: 0.061261, Regularization: 0.000098, Discriminator: 0.021658; Generator: 0.010799,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,744 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.083497\n",
      "Reconstruction: 0.051097, Regularization: 0.000076, Discriminator: 0.021522; Generator: 0.010801,\n",
      "D(x): 0.506, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,811 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.092841\n",
      "Reconstruction: 0.060202, Regularization: 0.000097, Discriminator: 0.021738; Generator: 0.010803,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,878 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.091658\n",
      "Reconstruction: 0.059029, Regularization: 0.000095, Discriminator: 0.021730; Generator: 0.010804,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,944 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.080402\n",
      "Reconstruction: 0.047789, Regularization: 0.000072, Discriminator: 0.021739; Generator: 0.010802,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,011 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.072960\n",
      "Reconstruction: 0.040415, Regularization: 0.000057, Discriminator: 0.021685; Generator: 0.010804,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,078 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.085715\n",
      "Reconstruction: 0.053230, Regularization: 0.000088, Discriminator: 0.021591; Generator: 0.010805,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,146 root         INFO     ====> Epoch: 35 Average loss: 0.0851\n",
      "2019-04-09 20:44:42,170 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 0.087398\n",
      "Reconstruction: 0.054904, Regularization: 0.000091, Discriminator: 0.021603; Generator: 0.010800,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,234 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.089576\n",
      "Reconstruction: 0.057026, Regularization: 0.000093, Discriminator: 0.021651; Generator: 0.010805,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,298 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.082868\n",
      "Reconstruction: 0.050270, Regularization: 0.000078, Discriminator: 0.021722; Generator: 0.010798,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,362 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.088380\n",
      "Reconstruction: 0.056088, Regularization: 0.000091, Discriminator: 0.021398; Generator: 0.010803,\n",
      "D(x): 0.510, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,425 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.083707\n",
      "Reconstruction: 0.051311, Regularization: 0.000078, Discriminator: 0.021516; Generator: 0.010802,\n",
      "D(x): 0.506, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,489 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.079141\n",
      "Reconstruction: 0.046610, Regularization: 0.000069, Discriminator: 0.021658; Generator: 0.010805,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,555 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 0.083702\n",
      "Reconstruction: 0.051033, Regularization: 0.000077, Discriminator: 0.021786; Generator: 0.010806,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,621 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.090585\n",
      "Reconstruction: 0.058013, Regularization: 0.000092, Discriminator: 0.021676; Generator: 0.010804,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,690 root         INFO     ====> Epoch: 36 Average loss: 0.0851\n",
      "2019-04-09 20:44:42,714 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.078976\n",
      "Reconstruction: 0.046457, Regularization: 0.000067, Discriminator: 0.021648; Generator: 0.010804,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,782 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.101304\n",
      "Reconstruction: 0.068614, Regularization: 0.000116, Discriminator: 0.021770; Generator: 0.010804,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,849 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.078165\n",
      "Reconstruction: 0.045798, Regularization: 0.000068, Discriminator: 0.021500; Generator: 0.010798,\n",
      "D(x): 0.506, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,916 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 0.091352\n",
      "Reconstruction: 0.058901, Regularization: 0.000097, Discriminator: 0.021552; Generator: 0.010802,\n",
      "D(x): 0.505, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,984 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.080902\n",
      "Reconstruction: 0.048217, Regularization: 0.000074, Discriminator: 0.021802; Generator: 0.010809,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,051 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.094846\n",
      "Reconstruction: 0.062171, Regularization: 0.000104, Discriminator: 0.021766; Generator: 0.010805,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,119 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.080374\n",
      "Reconstruction: 0.047842, Regularization: 0.000073, Discriminator: 0.021659; Generator: 0.010800,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,187 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.082691\n",
      "Reconstruction: 0.050290, Regularization: 0.000078, Discriminator: 0.021517; Generator: 0.010806,\n",
      "D(x): 0.506, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,255 root         INFO     ====> Epoch: 37 Average loss: 0.0851\n",
      "2019-04-09 20:44:43,279 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.092829\n",
      "Reconstruction: 0.060273, Regularization: 0.000100, Discriminator: 0.021646; Generator: 0.010810,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,348 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.081838\n",
      "Reconstruction: 0.049349, Regularization: 0.000077, Discriminator: 0.021606; Generator: 0.010806,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,415 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.074598\n",
      "Reconstruction: 0.042070, Regularization: 0.000061, Discriminator: 0.021661; Generator: 0.010806,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,483 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 0.093069\n",
      "Reconstruction: 0.060553, Regularization: 0.000102, Discriminator: 0.021610; Generator: 0.010803,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,550 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.082683\n",
      "Reconstruction: 0.050076, Regularization: 0.000078, Discriminator: 0.021723; Generator: 0.010805,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,618 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.088520\n",
      "Reconstruction: 0.055925, Regularization: 0.000092, Discriminator: 0.021696; Generator: 0.010807,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,684 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.086186\n",
      "Reconstruction: 0.053505, Regularization: 0.000087, Discriminator: 0.021790; Generator: 0.010805,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,752 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.083131\n",
      "Reconstruction: 0.050735, Regularization: 0.000080, Discriminator: 0.021508; Generator: 0.010808,\n",
      "D(x): 0.506, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,820 root         INFO     ====> Epoch: 38 Average loss: 0.0851\n",
      "2019-04-09 20:44:43,845 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 0.084875\n",
      "Reconstruction: 0.052198, Regularization: 0.000083, Discriminator: 0.021780; Generator: 0.010813,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,913 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.078089\n",
      "Reconstruction: 0.045559, Regularization: 0.000068, Discriminator: 0.021653; Generator: 0.010810,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,980 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.076929\n",
      "Reconstruction: 0.044351, Regularization: 0.000066, Discriminator: 0.021707; Generator: 0.010805,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 20:44:44,048 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.077774\n",
      "Reconstruction: 0.045255, Regularization: 0.000067, Discriminator: 0.021650; Generator: 0.010803,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:44,116 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.081327\n",
      "Reconstruction: 0.048809, Regularization: 0.000073, Discriminator: 0.021636; Generator: 0.010808,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:44,183 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.094427\n",
      "Reconstruction: 0.061910, Regularization: 0.000104, Discriminator: 0.021603; Generator: 0.010809,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:44,251 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.074415\n",
      "Reconstruction: 0.041844, Regularization: 0.000060, Discriminator: 0.021694; Generator: 0.010817,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,316 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.081287\n",
      "Reconstruction: 0.048813, Regularization: 0.000075, Discriminator: 0.021579; Generator: 0.010819,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,380 root         INFO     ====> Epoch: 39 Average loss: 0.0851\n",
      "2019-04-09 20:44:44,405 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.098537\n",
      "Reconstruction: 0.065987, Regularization: 0.000112, Discriminator: 0.021622; Generator: 0.010817,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,469 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.086183\n",
      "Reconstruction: 0.053663, Regularization: 0.000084, Discriminator: 0.021618; Generator: 0.010819,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,533 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.096879\n",
      "Reconstruction: 0.064397, Regularization: 0.000106, Discriminator: 0.021554; Generator: 0.010821,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,596 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.094810\n",
      "Reconstruction: 0.062270, Regularization: 0.000102, Discriminator: 0.021617; Generator: 0.010821,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,660 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.082545\n",
      "Reconstruction: 0.050005, Regularization: 0.000075, Discriminator: 0.021648; Generator: 0.010817,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,724 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 0.077122\n",
      "Reconstruction: 0.044618, Regularization: 0.000064, Discriminator: 0.021620; Generator: 0.010819,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,787 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.090303\n",
      "Reconstruction: 0.057803, Regularization: 0.000092, Discriminator: 0.021589; Generator: 0.010818,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,851 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.094798\n",
      "Reconstruction: 0.062200, Regularization: 0.000100, Discriminator: 0.021680; Generator: 0.010818,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,917 root         INFO     ====> Epoch: 40 Average loss: 0.0851\n",
      "2019-04-09 20:44:44,941 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 0.077658\n",
      "Reconstruction: 0.045178, Regularization: 0.000064, Discriminator: 0.021604; Generator: 0.010812,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,006 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.089071\n",
      "Reconstruction: 0.056471, Regularization: 0.000090, Discriminator: 0.021695; Generator: 0.010814,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,074 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 0.078564\n",
      "Reconstruction: 0.046122, Regularization: 0.000069, Discriminator: 0.021568; Generator: 0.010805,\n",
      "D(x): 0.504, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,143 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.091347\n",
      "Reconstruction: 0.058782, Regularization: 0.000098, Discriminator: 0.021652; Generator: 0.010815,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:45,211 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.091635\n",
      "Reconstruction: 0.059101, Regularization: 0.000101, Discriminator: 0.021610; Generator: 0.010823,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:45,279 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 0.087173\n",
      "Reconstruction: 0.054601, Regularization: 0.000090, Discriminator: 0.021665; Generator: 0.010818,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:45,347 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.088568\n",
      "Reconstruction: 0.055990, Regularization: 0.000093, Discriminator: 0.021672; Generator: 0.010812,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,416 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.080656\n",
      "Reconstruction: 0.048151, Regularization: 0.000076, Discriminator: 0.021617; Generator: 0.010811,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,485 root         INFO     ====> Epoch: 41 Average loss: 0.0851\n",
      "2019-04-09 20:44:45,509 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.075535\n",
      "Reconstruction: 0.043028, Regularization: 0.000066, Discriminator: 0.021625; Generator: 0.010817,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:45,575 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.079396\n",
      "Reconstruction: 0.046848, Regularization: 0.000075, Discriminator: 0.021655; Generator: 0.010817,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:45,640 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.078081\n",
      "Reconstruction: 0.045483, Regularization: 0.000073, Discriminator: 0.021714; Generator: 0.010811,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,704 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 0.101341\n",
      "Reconstruction: 0.068775, Regularization: 0.000127, Discriminator: 0.021630; Generator: 0.010808,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,768 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.083420\n",
      "Reconstruction: 0.050847, Regularization: 0.000085, Discriminator: 0.021677; Generator: 0.010811,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,831 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.092946\n",
      "Reconstruction: 0.060362, Regularization: 0.000107, Discriminator: 0.021670; Generator: 0.010807,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,895 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.083438\n",
      "Reconstruction: 0.050929, Regularization: 0.000086, Discriminator: 0.021613; Generator: 0.010810,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,958 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.074080\n",
      "Reconstruction: 0.041542, Regularization: 0.000064, Discriminator: 0.021658; Generator: 0.010817,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,025 root         INFO     ====> Epoch: 42 Average loss: 0.0851\n",
      "2019-04-09 20:44:46,049 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.079072\n",
      "Reconstruction: 0.046431, Regularization: 0.000075, Discriminator: 0.021746; Generator: 0.010821,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,115 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.094308\n",
      "Reconstruction: 0.061739, Regularization: 0.000107, Discriminator: 0.021644; Generator: 0.010817,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,179 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.071428\n",
      "Reconstruction: 0.038996, Regularization: 0.000057, Discriminator: 0.021559; Generator: 0.010817,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,243 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.082133\n",
      "Reconstruction: 0.049532, Regularization: 0.000080, Discriminator: 0.021704; Generator: 0.010818,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,307 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.076085\n",
      "Reconstruction: 0.043551, Regularization: 0.000065, Discriminator: 0.021654; Generator: 0.010816,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,371 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.078315\n",
      "Reconstruction: 0.045784, Regularization: 0.000071, Discriminator: 0.021642; Generator: 0.010818,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,435 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.084569\n",
      "Reconstruction: 0.052125, Regularization: 0.000084, Discriminator: 0.021545; Generator: 0.010816,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,498 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.097807\n",
      "Reconstruction: 0.065191, Regularization: 0.000113, Discriminator: 0.021680; Generator: 0.010823,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,564 root         INFO     ====> Epoch: 43 Average loss: 0.0851\n",
      "2019-04-09 20:44:46,588 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.092365\n",
      "Reconstruction: 0.059743, Regularization: 0.000100, Discriminator: 0.021701; Generator: 0.010821,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,655 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.080367\n",
      "Reconstruction: 0.047776, Regularization: 0.000076, Discriminator: 0.021688; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,720 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.078805\n",
      "Reconstruction: 0.046172, Regularization: 0.000072, Discriminator: 0.021738; Generator: 0.010822,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,786 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.075200\n",
      "Reconstruction: 0.042757, Regularization: 0.000064, Discriminator: 0.021562; Generator: 0.010817,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,852 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.088285\n",
      "Reconstruction: 0.055844, Regularization: 0.000091, Discriminator: 0.021532; Generator: 0.010818,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,918 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.079931\n",
      "Reconstruction: 0.047290, Regularization: 0.000070, Discriminator: 0.021751; Generator: 0.010820,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,984 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.095198\n",
      "Reconstruction: 0.062618, Regularization: 0.000103, Discriminator: 0.021659; Generator: 0.010818,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,049 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.073552\n",
      "Reconstruction: 0.040944, Regularization: 0.000058, Discriminator: 0.021728; Generator: 0.010822,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,117 root         INFO     ====> Epoch: 44 Average loss: 0.0851\n",
      "2019-04-09 20:44:47,140 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.076510\n",
      "Reconstruction: 0.043952, Regularization: 0.000065, Discriminator: 0.021668; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,207 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 0.081709\n",
      "Reconstruction: 0.049254, Regularization: 0.000076, Discriminator: 0.021551; Generator: 0.010828,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,274 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.083096\n",
      "Reconstruction: 0.050468, Regularization: 0.000079, Discriminator: 0.021716; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,341 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.090917\n",
      "Reconstruction: 0.058347, Regularization: 0.000095, Discriminator: 0.021651; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,407 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.101323\n",
      "Reconstruction: 0.068630, Regularization: 0.000115, Discriminator: 0.021753; Generator: 0.010826,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,473 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.077909\n",
      "Reconstruction: 0.045320, Regularization: 0.000066, Discriminator: 0.021702; Generator: 0.010820,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,540 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.081915\n",
      "Reconstruction: 0.049305, Regularization: 0.000075, Discriminator: 0.021714; Generator: 0.010821,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,607 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.086369\n",
      "Reconstruction: 0.053809, Regularization: 0.000084, Discriminator: 0.021653; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,675 root         INFO     ====> Epoch: 45 Average loss: 0.0851\n",
      "2019-04-09 20:44:47,699 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.084480\n",
      "Reconstruction: 0.051900, Regularization: 0.000079, Discriminator: 0.021679; Generator: 0.010822,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,767 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.093146\n",
      "Reconstruction: 0.060520, Regularization: 0.000095, Discriminator: 0.021713; Generator: 0.010819,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,832 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.087605\n",
      "Reconstruction: 0.055085, Regularization: 0.000084, Discriminator: 0.021617; Generator: 0.010818,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,894 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.078416\n",
      "Reconstruction: 0.045812, Regularization: 0.000064, Discriminator: 0.021721; Generator: 0.010819,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,956 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.088121\n",
      "Reconstruction: 0.055557, Regularization: 0.000083, Discriminator: 0.021665; Generator: 0.010817,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,020 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.088947\n",
      "Reconstruction: 0.056469, Regularization: 0.000083, Discriminator: 0.021579; Generator: 0.010816,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,085 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.085386\n",
      "Reconstruction: 0.052873, Regularization: 0.000076, Discriminator: 0.021620; Generator: 0.010817,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,150 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.078527\n",
      "Reconstruction: 0.046047, Regularization: 0.000064, Discriminator: 0.021600; Generator: 0.010816,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,216 root         INFO     ====> Epoch: 46 Average loss: 0.0851\n",
      "2019-04-09 20:44:48,241 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.080582\n",
      "Reconstruction: 0.048055, Regularization: 0.000067, Discriminator: 0.021634; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,307 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.086784\n",
      "Reconstruction: 0.054197, Regularization: 0.000082, Discriminator: 0.021681; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,376 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.093296\n",
      "Reconstruction: 0.060640, Regularization: 0.000097, Discriminator: 0.021736; Generator: 0.010823,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,445 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.086715\n",
      "Reconstruction: 0.054156, Regularization: 0.000083, Discriminator: 0.021651; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,514 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.089929\n",
      "Reconstruction: 0.057406, Regularization: 0.000088, Discriminator: 0.021613; Generator: 0.010821,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,583 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.090733\n",
      "Reconstruction: 0.058138, Regularization: 0.000088, Discriminator: 0.021683; Generator: 0.010823,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,653 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.093549\n",
      "Reconstruction: 0.061037, Regularization: 0.000093, Discriminator: 0.021592; Generator: 0.010827,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,722 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.087699\n",
      "Reconstruction: 0.055153, Regularization: 0.000081, Discriminator: 0.021635; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,792 root         INFO     ====> Epoch: 47 Average loss: 0.0851\n",
      "2019-04-09 20:44:48,817 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.091553\n",
      "Reconstruction: 0.058807, Regularization: 0.000088, Discriminator: 0.021833; Generator: 0.010824,\n",
      "D(x): 0.495, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,884 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.093638\n",
      "Reconstruction: 0.061197, Regularization: 0.000096, Discriminator: 0.021515; Generator: 0.010830,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,949 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.098920\n",
      "Reconstruction: 0.066317, Regularization: 0.000105, Discriminator: 0.021668; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,015 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.102148\n",
      "Reconstruction: 0.069576, Regularization: 0.000111, Discriminator: 0.021635; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,081 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.081643\n",
      "Reconstruction: 0.049039, Regularization: 0.000070, Discriminator: 0.021708; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,146 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.079501\n",
      "Reconstruction: 0.046997, Regularization: 0.000066, Discriminator: 0.021615; Generator: 0.010822,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,211 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.105338\n",
      "Reconstruction: 0.072752, Regularization: 0.000119, Discriminator: 0.021642; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,278 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.077126\n",
      "Reconstruction: 0.044534, Regularization: 0.000061, Discriminator: 0.021705; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,345 root         INFO     ====> Epoch: 48 Average loss: 0.0851\n",
      "2019-04-09 20:44:49,370 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.086595\n",
      "Reconstruction: 0.054096, Regularization: 0.000083, Discriminator: 0.021591; Generator: 0.010826,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,437 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.081257\n",
      "Reconstruction: 0.048718, Regularization: 0.000072, Discriminator: 0.021638; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,503 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.087248\n",
      "Reconstruction: 0.054646, Regularization: 0.000084, Discriminator: 0.021687; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,570 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.082405\n",
      "Reconstruction: 0.049916, Regularization: 0.000074, Discriminator: 0.021591; Generator: 0.010825,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,637 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.087066\n",
      "Reconstruction: 0.054439, Regularization: 0.000082, Discriminator: 0.021717; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,703 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.082468\n",
      "Reconstruction: 0.049867, Regularization: 0.000071, Discriminator: 0.021702; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,769 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.087183\n",
      "Reconstruction: 0.054512, Regularization: 0.000083, Discriminator: 0.021766; Generator: 0.010821,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,835 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.097398\n",
      "Reconstruction: 0.064883, Regularization: 0.000104, Discriminator: 0.021589; Generator: 0.010823,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,904 root         INFO     ====> Epoch: 49 Average loss: 0.0851\n",
      "2019-04-09 20:44:49,928 root         INFO     Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 0.094375\n",
      "Reconstruction: 0.061781, Regularization: 0.000100, Discriminator: 0.021670; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,996 root         INFO     Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 0.087888\n",
      "Reconstruction: 0.055349, Regularization: 0.000086, Discriminator: 0.021628; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,063 root         INFO     Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 0.079974\n",
      "Reconstruction: 0.047445, Regularization: 0.000069, Discriminator: 0.021633; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,130 root         INFO     Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 0.086012\n",
      "Reconstruction: 0.053501, Regularization: 0.000081, Discriminator: 0.021597; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,197 root         INFO     Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 0.080609\n",
      "Reconstruction: 0.048068, Regularization: 0.000071, Discriminator: 0.021643; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,263 root         INFO     Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 0.082422\n",
      "Reconstruction: 0.049922, Regularization: 0.000075, Discriminator: 0.021597; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,329 root         INFO     Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 0.090275\n",
      "Reconstruction: 0.057602, Regularization: 0.000092, Discriminator: 0.021753; Generator: 0.010828,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,395 root         INFO     Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 0.089500\n",
      "Reconstruction: 0.056954, Regularization: 0.000090, Discriminator: 0.021630; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,462 root         INFO     ====> Epoch: 50 Average loss: 0.0851\n",
      "2019-04-09 20:44:50,486 root         INFO     Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 0.087531\n",
      "Reconstruction: 0.054898, Regularization: 0.000085, Discriminator: 0.021723; Generator: 0.010824,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,553 root         INFO     Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 0.079471\n",
      "Reconstruction: 0.046910, Regularization: 0.000069, Discriminator: 0.021668; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,619 root         INFO     Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 0.076209\n",
      "Reconstruction: 0.043738, Regularization: 0.000062, Discriminator: 0.021590; Generator: 0.010820,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,685 root         INFO     Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 0.094056\n",
      "Reconstruction: 0.061479, Regularization: 0.000100, Discriminator: 0.021663; Generator: 0.010815,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,748 root         INFO     Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 0.087902\n",
      "Reconstruction: 0.055291, Regularization: 0.000086, Discriminator: 0.021710; Generator: 0.010816,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,811 root         INFO     Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 0.087052\n",
      "Reconstruction: 0.054531, Regularization: 0.000086, Discriminator: 0.021613; Generator: 0.010822,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,874 root         INFO     Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 0.090125\n",
      "Reconstruction: 0.057635, Regularization: 0.000094, Discriminator: 0.021568; Generator: 0.010828,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,937 root         INFO     Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 0.088851\n",
      "Reconstruction: 0.056314, Regularization: 0.000089, Discriminator: 0.021619; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,002 root         INFO     ====> Epoch: 51 Average loss: 0.0851\n",
      "2019-04-09 20:44:51,026 root         INFO     Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 0.088832\n",
      "Reconstruction: 0.056250, Regularization: 0.000090, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,089 root         INFO     Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 0.079785\n",
      "Reconstruction: 0.047210, Regularization: 0.000070, Discriminator: 0.021676; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,153 root         INFO     Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 0.083941\n",
      "Reconstruction: 0.051349, Regularization: 0.000077, Discriminator: 0.021692; Generator: 0.010823,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,216 root         INFO     Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 0.088577\n",
      "Reconstruction: 0.056134, Regularization: 0.000088, Discriminator: 0.021535; Generator: 0.010820,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,279 root         INFO     Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 0.081220\n",
      "Reconstruction: 0.048719, Regularization: 0.000074, Discriminator: 0.021595; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,342 root         INFO     Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 0.075087\n",
      "Reconstruction: 0.042532, Regularization: 0.000061, Discriminator: 0.021661; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,405 root         INFO     Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 0.076552\n",
      "Reconstruction: 0.044044, Regularization: 0.000066, Discriminator: 0.021610; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,467 root         INFO     Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 0.084850\n",
      "Reconstruction: 0.052275, Regularization: 0.000084, Discriminator: 0.021657; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,532 root         INFO     ====> Epoch: 52 Average loss: 0.0850\n",
      "2019-04-09 20:44:51,556 root         INFO     Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 0.079624\n",
      "Reconstruction: 0.047111, Regularization: 0.000072, Discriminator: 0.021608; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,623 root         INFO     Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 0.084809\n",
      "Reconstruction: 0.052296, Regularization: 0.000081, Discriminator: 0.021603; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,689 root         INFO     Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 0.085149\n",
      "Reconstruction: 0.052745, Regularization: 0.000081, Discriminator: 0.021499; Generator: 0.010824,\n",
      "D(x): 0.506, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,755 root         INFO     Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 0.086245\n",
      "Reconstruction: 0.053687, Regularization: 0.000086, Discriminator: 0.021647; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,821 root         INFO     Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 0.089020\n",
      "Reconstruction: 0.056481, Regularization: 0.000090, Discriminator: 0.021625; Generator: 0.010824,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,887 root         INFO     Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 0.083813\n",
      "Reconstruction: 0.051207, Regularization: 0.000082, Discriminator: 0.021693; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,953 root         INFO     Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 0.096731\n",
      "Reconstruction: 0.064042, Regularization: 0.000111, Discriminator: 0.021748; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,019 root         INFO     Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 0.081592\n",
      "Reconstruction: 0.049140, Regularization: 0.000079, Discriminator: 0.021553; Generator: 0.010820,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,088 root         INFO     ====> Epoch: 53 Average loss: 0.0851\n",
      "2019-04-09 20:44:52,112 root         INFO     Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 0.083482\n",
      "Reconstruction: 0.050941, Regularization: 0.000084, Discriminator: 0.021627; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,178 root         INFO     Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 0.082819\n",
      "Reconstruction: 0.050223, Regularization: 0.000084, Discriminator: 0.021689; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,245 root         INFO     Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 0.085654\n",
      "Reconstruction: 0.052996, Regularization: 0.000092, Discriminator: 0.021742; Generator: 0.010825,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,311 root         INFO     Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 0.090892\n",
      "Reconstruction: 0.058326, Regularization: 0.000105, Discriminator: 0.021634; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,377 root         INFO     Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 0.098967\n",
      "Reconstruction: 0.066532, Regularization: 0.000121, Discriminator: 0.021486; Generator: 0.010828,\n",
      "D(x): 0.506, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,444 root         INFO     Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 0.081576\n",
      "Reconstruction: 0.049011, Regularization: 0.000080, Discriminator: 0.021651; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,510 root         INFO     Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 0.080130\n",
      "Reconstruction: 0.047661, Regularization: 0.000076, Discriminator: 0.021561; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,576 root         INFO     Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 0.088367\n",
      "Reconstruction: 0.055648, Regularization: 0.000093, Discriminator: 0.021791; Generator: 0.010836,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,644 root         INFO     ====> Epoch: 54 Average loss: 0.0851\n",
      "2019-04-09 20:44:52,668 root         INFO     Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 0.078894\n",
      "Reconstruction: 0.046366, Regularization: 0.000071, Discriminator: 0.021624; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,732 root         INFO     Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 0.091368\n",
      "Reconstruction: 0.058839, Regularization: 0.000102, Discriminator: 0.021597; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,795 root         INFO     Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 0.078886\n",
      "Reconstruction: 0.046299, Regularization: 0.000072, Discriminator: 0.021682; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,857 root         INFO     Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 0.094425\n",
      "Reconstruction: 0.061858, Regularization: 0.000109, Discriminator: 0.021625; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,920 root         INFO     Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 0.078410\n",
      "Reconstruction: 0.045844, Regularization: 0.000071, Discriminator: 0.021664; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,984 root         INFO     Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 0.076713\n",
      "Reconstruction: 0.044106, Regularization: 0.000066, Discriminator: 0.021719; Generator: 0.010822,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,047 root         INFO     Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 0.101709\n",
      "Reconstruction: 0.069203, Regularization: 0.000123, Discriminator: 0.021553; Generator: 0.010830,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,109 root         INFO     Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 0.076724\n",
      "Reconstruction: 0.044182, Regularization: 0.000069, Discriminator: 0.021644; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,174 root         INFO     ====> Epoch: 55 Average loss: 0.0851\n",
      "2019-04-09 20:44:53,198 root         INFO     Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 0.083391\n",
      "Reconstruction: 0.050735, Regularization: 0.000084, Discriminator: 0.021742; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,261 root         INFO     Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 0.086705\n",
      "Reconstruction: 0.054042, Regularization: 0.000091, Discriminator: 0.021741; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,325 root         INFO     Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 0.085849\n",
      "Reconstruction: 0.053399, Regularization: 0.000089, Discriminator: 0.021528; Generator: 0.010832,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,388 root         INFO     Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 0.085192\n",
      "Reconstruction: 0.052602, Regularization: 0.000090, Discriminator: 0.021669; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,452 root         INFO     Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 0.084304\n",
      "Reconstruction: 0.051737, Regularization: 0.000086, Discriminator: 0.021653; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,516 root         INFO     Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 0.069596\n",
      "Reconstruction: 0.037035, Regularization: 0.000053, Discriminator: 0.021679; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,583 root         INFO     Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 0.075565\n",
      "Reconstruction: 0.043050, Regularization: 0.000066, Discriminator: 0.021620; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,650 root         INFO     Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 0.082459\n",
      "Reconstruction: 0.049796, Regularization: 0.000083, Discriminator: 0.021747; Generator: 0.010832,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,720 root         INFO     ====> Epoch: 56 Average loss: 0.0851\n",
      "2019-04-09 20:44:53,744 root         INFO     Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 0.089983\n",
      "Reconstruction: 0.057419, Regularization: 0.000103, Discriminator: 0.021631; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,810 root         INFO     Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 0.087687\n",
      "Reconstruction: 0.055100, Regularization: 0.000099, Discriminator: 0.021656; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,875 root         INFO     Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 0.076434\n",
      "Reconstruction: 0.043902, Regularization: 0.000072, Discriminator: 0.021632; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,940 root         INFO     Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 0.088595\n",
      "Reconstruction: 0.055979, Regularization: 0.000103, Discriminator: 0.021686; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,006 root         INFO     Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 0.085490\n",
      "Reconstruction: 0.052822, Regularization: 0.000093, Discriminator: 0.021743; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,070 root         INFO     Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 0.076770\n",
      "Reconstruction: 0.044226, Regularization: 0.000074, Discriminator: 0.021642; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,134 root         INFO     Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 0.083576\n",
      "Reconstruction: 0.050992, Regularization: 0.000093, Discriminator: 0.021664; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,198 root         INFO     Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 0.086435\n",
      "Reconstruction: 0.053864, Regularization: 0.000100, Discriminator: 0.021636; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,264 root         INFO     ====> Epoch: 57 Average loss: 0.0851\n",
      "2019-04-09 20:44:54,289 root         INFO     Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 0.089044\n",
      "Reconstruction: 0.056370, Regularization: 0.000108, Discriminator: 0.021736; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,356 root         INFO     Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 0.096228\n",
      "Reconstruction: 0.063569, Regularization: 0.000125, Discriminator: 0.021709; Generator: 0.010825,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,422 root         INFO     Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 0.073205\n",
      "Reconstruction: 0.040677, Regularization: 0.000067, Discriminator: 0.021635; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,488 root         INFO     Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 0.085731\n",
      "Reconstruction: 0.053250, Regularization: 0.000100, Discriminator: 0.021552; Generator: 0.010829,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,557 root         INFO     Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 0.084102\n",
      "Reconstruction: 0.051496, Regularization: 0.000092, Discriminator: 0.021678; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,626 root         INFO     Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 0.085964\n",
      "Reconstruction: 0.053320, Regularization: 0.000097, Discriminator: 0.021714; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,694 root         INFO     Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 0.083086\n",
      "Reconstruction: 0.050549, Regularization: 0.000092, Discriminator: 0.021618; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,763 root         INFO     Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 0.077611\n",
      "Reconstruction: 0.045068, Regularization: 0.000077, Discriminator: 0.021633; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,832 root         INFO     ====> Epoch: 58 Average loss: 0.0851\n",
      "2019-04-09 20:44:54,856 root         INFO     Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 0.081379\n",
      "Reconstruction: 0.048743, Regularization: 0.000083, Discriminator: 0.021720; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,921 root         INFO     Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 0.075567\n",
      "Reconstruction: 0.043062, Regularization: 0.000067, Discriminator: 0.021607; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,987 root         INFO     Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 0.084746\n",
      "Reconstruction: 0.052149, Regularization: 0.000088, Discriminator: 0.021670; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,052 root         INFO     Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 0.093259\n",
      "Reconstruction: 0.060706, Regularization: 0.000106, Discriminator: 0.021612; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,118 root         INFO     Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 0.076649\n",
      "Reconstruction: 0.044048, Regularization: 0.000068, Discriminator: 0.021702; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,184 root         INFO     Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 0.078385\n",
      "Reconstruction: 0.045754, Regularization: 0.000072, Discriminator: 0.021726; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,250 root         INFO     Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 0.097032\n",
      "Reconstruction: 0.064515, Regularization: 0.000113, Discriminator: 0.021577; Generator: 0.010827,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,316 root         INFO     Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 0.083699\n",
      "Reconstruction: 0.051272, Regularization: 0.000084, Discriminator: 0.021515; Generator: 0.010827,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,384 root         INFO     ====> Epoch: 59 Average loss: 0.0851\n",
      "2019-04-09 20:44:55,408 root         INFO     Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 0.082326\n",
      "Reconstruction: 0.049808, Regularization: 0.000081, Discriminator: 0.021604; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,474 root         INFO     Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 0.076254\n",
      "Reconstruction: 0.043675, Regularization: 0.000066, Discriminator: 0.021676; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,540 root         INFO     Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 0.082408\n",
      "Reconstruction: 0.049754, Regularization: 0.000080, Discriminator: 0.021747; Generator: 0.010827,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,605 root         INFO     Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 0.076643\n",
      "Reconstruction: 0.044103, Regularization: 0.000067, Discriminator: 0.021645; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,671 root         INFO     Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 0.077541\n",
      "Reconstruction: 0.044971, Regularization: 0.000068, Discriminator: 0.021675; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,739 root         INFO     Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 0.077700\n",
      "Reconstruction: 0.045187, Regularization: 0.000068, Discriminator: 0.021615; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,806 root         INFO     Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 0.074482\n",
      "Reconstruction: 0.041915, Regularization: 0.000062, Discriminator: 0.021669; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,874 root         INFO     Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 0.082687\n",
      "Reconstruction: 0.050129, Regularization: 0.000080, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,942 root         INFO     ====> Epoch: 60 Average loss: 0.0851\n",
      "2019-04-09 20:44:55,967 root         INFO     Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 0.094110\n",
      "Reconstruction: 0.061429, Regularization: 0.000106, Discriminator: 0.021745; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,033 root         INFO     Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 0.083699\n",
      "Reconstruction: 0.051064, Regularization: 0.000086, Discriminator: 0.021724; Generator: 0.010824,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,096 root         INFO     Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 0.092863\n",
      "Reconstruction: 0.060254, Regularization: 0.000109, Discriminator: 0.021678; Generator: 0.010823,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,159 root         INFO     Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 0.088988\n",
      "Reconstruction: 0.056489, Regularization: 0.000102, Discriminator: 0.021573; Generator: 0.010825,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,222 root         INFO     Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 0.078641\n",
      "Reconstruction: 0.046095, Regularization: 0.000077, Discriminator: 0.021645; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,288 root         INFO     Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 0.085763\n",
      "Reconstruction: 0.053184, Regularization: 0.000094, Discriminator: 0.021651; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,353 root         INFO     Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 0.084636\n",
      "Reconstruction: 0.052051, Regularization: 0.000092, Discriminator: 0.021666; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,418 root         INFO     Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 0.087768\n",
      "Reconstruction: 0.055175, Regularization: 0.000099, Discriminator: 0.021661; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,487 root         INFO     ====> Epoch: 61 Average loss: 0.0850\n",
      "2019-04-09 20:44:56,511 root         INFO     Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 0.094398\n",
      "Reconstruction: 0.061733, Regularization: 0.000116, Discriminator: 0.021711; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,576 root         INFO     Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 0.077789\n",
      "Reconstruction: 0.045206, Regularization: 0.000076, Discriminator: 0.021673; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,640 root         INFO     Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 0.083372\n",
      "Reconstruction: 0.050820, Regularization: 0.000086, Discriminator: 0.021634; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,707 root         INFO     Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 0.087713\n",
      "Reconstruction: 0.055127, Regularization: 0.000097, Discriminator: 0.021661; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,774 root         INFO     Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 0.093241\n",
      "Reconstruction: 0.060650, Regularization: 0.000111, Discriminator: 0.021656; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,840 root         INFO     Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 0.085097\n",
      "Reconstruction: 0.052459, Regularization: 0.000087, Discriminator: 0.021714; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,907 root         INFO     Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 0.079974\n",
      "Reconstruction: 0.047400, Regularization: 0.000075, Discriminator: 0.021664; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,974 root         INFO     Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 0.073024\n",
      "Reconstruction: 0.040443, Regularization: 0.000060, Discriminator: 0.021682; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,042 root         INFO     ====> Epoch: 62 Average loss: 0.0851\n",
      "2019-04-09 20:44:57,066 root         INFO     Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 0.081909\n",
      "Reconstruction: 0.049255, Regularization: 0.000080, Discriminator: 0.021737; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,131 root         INFO     Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 0.086778\n",
      "Reconstruction: 0.054270, Regularization: 0.000091, Discriminator: 0.021582; Generator: 0.010834,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,198 root         INFO     Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 0.091260\n",
      "Reconstruction: 0.058701, Regularization: 0.000101, Discriminator: 0.021624; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,265 root         INFO     Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 0.083821\n",
      "Reconstruction: 0.051236, Regularization: 0.000085, Discriminator: 0.021667; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,330 root         INFO     Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 0.071355\n",
      "Reconstruction: 0.038814, Regularization: 0.000056, Discriminator: 0.021654; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,395 root         INFO     Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 0.078985\n",
      "Reconstruction: 0.046433, Regularization: 0.000072, Discriminator: 0.021651; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,461 root         INFO     Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 0.094852\n",
      "Reconstruction: 0.062302, Regularization: 0.000106, Discriminator: 0.021612; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,527 root         INFO     Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 0.079499\n",
      "Reconstruction: 0.046982, Regularization: 0.000073, Discriminator: 0.021609; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,595 root         INFO     ====> Epoch: 63 Average loss: 0.0851\n",
      "2019-04-09 20:44:57,620 root         INFO     Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 0.086859\n",
      "Reconstruction: 0.054334, Regularization: 0.000089, Discriminator: 0.021602; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,689 root         INFO     Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 0.087245\n",
      "Reconstruction: 0.054692, Regularization: 0.000090, Discriminator: 0.021629; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,756 root         INFO     Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 0.086587\n",
      "Reconstruction: 0.053926, Regularization: 0.000088, Discriminator: 0.021745; Generator: 0.010827,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,824 root         INFO     Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 0.080352\n",
      "Reconstruction: 0.047733, Regularization: 0.000072, Discriminator: 0.021706; Generator: 0.010840,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,891 root         INFO     Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 0.097805\n",
      "Reconstruction: 0.065181, Regularization: 0.000113, Discriminator: 0.021668; Generator: 0.010843,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,956 root         INFO     Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 0.082401\n",
      "Reconstruction: 0.049800, Regularization: 0.000079, Discriminator: 0.021680; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,026 root         INFO     Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 0.078526\n",
      "Reconstruction: 0.045902, Regularization: 0.000071, Discriminator: 0.021709; Generator: 0.010844,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,096 root         INFO     Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 0.084280\n",
      "Reconstruction: 0.051594, Regularization: 0.000084, Discriminator: 0.021771; Generator: 0.010831,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,163 root         INFO     ====> Epoch: 64 Average loss: 0.0851\n",
      "2019-04-09 20:44:58,187 root         INFO     Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 0.089589\n",
      "Reconstruction: 0.056994, Regularization: 0.000096, Discriminator: 0.021672; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,255 root         INFO     Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 0.077304\n",
      "Reconstruction: 0.044715, Regularization: 0.000068, Discriminator: 0.021696; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,320 root         INFO     Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 0.081951\n",
      "Reconstruction: 0.049390, Regularization: 0.000077, Discriminator: 0.021658; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,383 root         INFO     Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 0.080684\n",
      "Reconstruction: 0.048097, Regularization: 0.000076, Discriminator: 0.021677; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,447 root         INFO     Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 0.095082\n",
      "Reconstruction: 0.062428, Regularization: 0.000107, Discriminator: 0.021715; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,512 root         INFO     Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 0.082539\n",
      "Reconstruction: 0.050038, Regularization: 0.000081, Discriminator: 0.021596; Generator: 0.010824,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,576 root         INFO     Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 0.083699\n",
      "Reconstruction: 0.051110, Regularization: 0.000082, Discriminator: 0.021679; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,640 root         INFO     Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 0.088358\n",
      "Reconstruction: 0.055843, Regularization: 0.000093, Discriminator: 0.021595; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,707 root         INFO     ====> Epoch: 65 Average loss: 0.0851\n",
      "2019-04-09 20:44:58,730 root         INFO     Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 0.084916\n",
      "Reconstruction: 0.052323, Regularization: 0.000084, Discriminator: 0.021675; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,796 root         INFO     Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 0.081444\n",
      "Reconstruction: 0.048880, Regularization: 0.000078, Discriminator: 0.021645; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,862 root         INFO     Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 0.083435\n",
      "Reconstruction: 0.050905, Regularization: 0.000083, Discriminator: 0.021614; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,927 root         INFO     Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 0.079584\n",
      "Reconstruction: 0.047061, Regularization: 0.000072, Discriminator: 0.021624; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,992 root         INFO     Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 0.096913\n",
      "Reconstruction: 0.064332, Regularization: 0.000111, Discriminator: 0.021647; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,057 root         INFO     Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 0.084164\n",
      "Reconstruction: 0.051594, Regularization: 0.000084, Discriminator: 0.021658; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,121 root         INFO     Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 0.080306\n",
      "Reconstruction: 0.047721, Regularization: 0.000075, Discriminator: 0.021677; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,186 root         INFO     Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 0.074733\n",
      "Reconstruction: 0.042163, Regularization: 0.000062, Discriminator: 0.021674; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,252 root         INFO     ====> Epoch: 66 Average loss: 0.0851\n",
      "2019-04-09 20:44:59,277 root         INFO     Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 0.071398\n",
      "Reconstruction: 0.038818, Regularization: 0.000055, Discriminator: 0.021688; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,343 root         INFO     Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 0.080938\n",
      "Reconstruction: 0.048400, Regularization: 0.000076, Discriminator: 0.021626; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,409 root         INFO     Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 0.083706\n",
      "Reconstruction: 0.051120, Regularization: 0.000083, Discriminator: 0.021657; Generator: 0.010847,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 20:44:59,475 root         INFO     Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 0.091205\n",
      "Reconstruction: 0.058606, Regularization: 0.000101, Discriminator: 0.021656; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,540 root         INFO     Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 0.091587\n",
      "Reconstruction: 0.058920, Regularization: 0.000102, Discriminator: 0.021723; Generator: 0.010842,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,602 root         INFO     Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 0.098882\n",
      "Reconstruction: 0.066339, Regularization: 0.000120, Discriminator: 0.021589; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,664 root         INFO     Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 0.086496\n",
      "Reconstruction: 0.053799, Regularization: 0.000091, Discriminator: 0.021769; Generator: 0.010837,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,726 root         INFO     Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 0.082954\n",
      "Reconstruction: 0.050437, Regularization: 0.000083, Discriminator: 0.021605; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,790 root         INFO     ====> Epoch: 67 Average loss: 0.0851\n",
      "2019-04-09 20:44:59,814 root         INFO     Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 0.090109\n",
      "Reconstruction: 0.057523, Regularization: 0.000099, Discriminator: 0.021662; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,879 root         INFO     Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 0.083517\n",
      "Reconstruction: 0.050974, Regularization: 0.000085, Discriminator: 0.021630; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,944 root         INFO     Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 0.075806\n",
      "Reconstruction: 0.043290, Regularization: 0.000069, Discriminator: 0.021621; Generator: 0.010826,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,009 root         INFO     Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 0.079538\n",
      "Reconstruction: 0.046965, Regularization: 0.000077, Discriminator: 0.021666; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,071 root         INFO     Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 0.090414\n",
      "Reconstruction: 0.057791, Regularization: 0.000105, Discriminator: 0.021690; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,134 root         INFO     Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 0.073727\n",
      "Reconstruction: 0.041192, Regularization: 0.000065, Discriminator: 0.021640; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,197 root         INFO     Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 0.079746\n",
      "Reconstruction: 0.047192, Regularization: 0.000080, Discriminator: 0.021639; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,261 root         INFO     Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 0.086349\n",
      "Reconstruction: 0.053703, Regularization: 0.000094, Discriminator: 0.021712; Generator: 0.010841,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,326 root         INFO     ====> Epoch: 68 Average loss: 0.0851\n",
      "2019-04-09 20:45:00,350 root         INFO     Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 0.091284\n",
      "Reconstruction: 0.058705, Regularization: 0.000109, Discriminator: 0.021638; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,413 root         INFO     Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 0.089293\n",
      "Reconstruction: 0.056664, Regularization: 0.000103, Discriminator: 0.021689; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,476 root         INFO     Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 0.072544\n",
      "Reconstruction: 0.040037, Regularization: 0.000063, Discriminator: 0.021613; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,539 root         INFO     Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 0.080203\n",
      "Reconstruction: 0.047662, Regularization: 0.000081, Discriminator: 0.021623; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,602 root         INFO     Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 0.092076\n",
      "Reconstruction: 0.059461, Regularization: 0.000111, Discriminator: 0.021664; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,664 root         INFO     Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 0.090477\n",
      "Reconstruction: 0.057865, Regularization: 0.000108, Discriminator: 0.021671; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,727 root         INFO     Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 0.091354\n",
      "Reconstruction: 0.058795, Regularization: 0.000109, Discriminator: 0.021620; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,790 root         INFO     Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 0.083359\n",
      "Reconstruction: 0.050756, Regularization: 0.000089, Discriminator: 0.021680; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,855 root         INFO     ====> Epoch: 69 Average loss: 0.0851\n",
      "2019-04-09 20:45:00,879 root         INFO     Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 0.083026\n",
      "Reconstruction: 0.050464, Regularization: 0.000088, Discriminator: 0.021646; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,945 root         INFO     Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 0.077118\n",
      "Reconstruction: 0.044576, Regularization: 0.000074, Discriminator: 0.021633; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,011 root         INFO     Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 0.093119\n",
      "Reconstruction: 0.060528, Regularization: 0.000112, Discriminator: 0.021643; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,078 root         INFO     Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 0.085102\n",
      "Reconstruction: 0.052605, Regularization: 0.000092, Discriminator: 0.021572; Generator: 0.010834,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,145 root         INFO     Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 0.072405\n",
      "Reconstruction: 0.039883, Regularization: 0.000062, Discriminator: 0.021629; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,213 root         INFO     Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 0.091391\n",
      "Reconstruction: 0.058741, Regularization: 0.000110, Discriminator: 0.021706; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,280 root         INFO     Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 0.096680\n",
      "Reconstruction: 0.064031, Regularization: 0.000121, Discriminator: 0.021698; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,346 root         INFO     Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 0.090271\n",
      "Reconstruction: 0.057774, Regularization: 0.000104, Discriminator: 0.021565; Generator: 0.010828,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,416 root         INFO     ====> Epoch: 70 Average loss: 0.0851\n",
      "2019-04-09 20:45:01,440 root         INFO     Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 0.082213\n",
      "Reconstruction: 0.049613, Regularization: 0.000084, Discriminator: 0.021688; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,506 root         INFO     Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 0.086336\n",
      "Reconstruction: 0.053774, Regularization: 0.000094, Discriminator: 0.021635; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,572 root         INFO     Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 0.094186\n",
      "Reconstruction: 0.061551, Regularization: 0.000114, Discriminator: 0.021690; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,638 root         INFO     Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 0.105443\n",
      "Reconstruction: 0.072890, Regularization: 0.000138, Discriminator: 0.021586; Generator: 0.010829,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,703 root         INFO     Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 0.094359\n",
      "Reconstruction: 0.061692, Regularization: 0.000111, Discriminator: 0.021722; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,769 root         INFO     Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 0.077272\n",
      "Reconstruction: 0.044773, Regularization: 0.000072, Discriminator: 0.021592; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,835 root         INFO     Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 0.084184\n",
      "Reconstruction: 0.051678, Regularization: 0.000089, Discriminator: 0.021582; Generator: 0.010834,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,901 root         INFO     Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 0.083219\n",
      "Reconstruction: 0.050639, Regularization: 0.000086, Discriminator: 0.021660; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,968 root         INFO     ====> Epoch: 71 Average loss: 0.0851\n",
      "2019-04-09 20:45:01,992 root         INFO     Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 0.069784\n",
      "Reconstruction: 0.037218, Regularization: 0.000054, Discriminator: 0.021682; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,056 root         INFO     Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 0.087726\n",
      "Reconstruction: 0.055126, Regularization: 0.000096, Discriminator: 0.021672; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,122 root         INFO     Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 0.084833\n",
      "Reconstruction: 0.052291, Regularization: 0.000091, Discriminator: 0.021620; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,188 root         INFO     Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 0.082719\n",
      "Reconstruction: 0.050131, Regularization: 0.000086, Discriminator: 0.021673; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,254 root         INFO     Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 0.090640\n",
      "Reconstruction: 0.058121, Regularization: 0.000107, Discriminator: 0.021587; Generator: 0.010826,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,320 root         INFO     Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 0.081094\n",
      "Reconstruction: 0.048548, Regularization: 0.000085, Discriminator: 0.021629; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,385 root         INFO     Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 0.083829\n",
      "Reconstruction: 0.051188, Regularization: 0.000091, Discriminator: 0.021719; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,450 root         INFO     Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 0.071899\n",
      "Reconstruction: 0.039383, Regularization: 0.000063, Discriminator: 0.021624; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,518 root         INFO     ====> Epoch: 72 Average loss: 0.0851\n",
      "2019-04-09 20:45:02,542 root         INFO     Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 0.082772\n",
      "Reconstruction: 0.050188, Regularization: 0.000088, Discriminator: 0.021658; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,606 root         INFO     Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 0.075698\n",
      "Reconstruction: 0.043078, Regularization: 0.000070, Discriminator: 0.021714; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,672 root         INFO     Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 0.087464\n",
      "Reconstruction: 0.054970, Regularization: 0.000099, Discriminator: 0.021562; Generator: 0.010833,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,741 root         INFO     Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 0.073151\n",
      "Reconstruction: 0.040585, Regularization: 0.000064, Discriminator: 0.021663; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,809 root         INFO     Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 0.081974\n",
      "Reconstruction: 0.049375, Regularization: 0.000087, Discriminator: 0.021677; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,878 root         INFO     Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 0.082887\n",
      "Reconstruction: 0.050351, Regularization: 0.000088, Discriminator: 0.021612; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,947 root         INFO     Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 0.077703\n",
      "Reconstruction: 0.045154, Regularization: 0.000076, Discriminator: 0.021643; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,015 root         INFO     Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 0.083710\n",
      "Reconstruction: 0.051094, Regularization: 0.000089, Discriminator: 0.021697; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,088 root         INFO     ====> Epoch: 73 Average loss: 0.0851\n",
      "2019-04-09 20:45:03,112 root         INFO     Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 0.074831\n",
      "Reconstruction: 0.042254, Regularization: 0.000068, Discriminator: 0.021676; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,179 root         INFO     Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 0.093641\n",
      "Reconstruction: 0.061091, Regularization: 0.000111, Discriminator: 0.021609; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,242 root         INFO     Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 0.093002\n",
      "Reconstruction: 0.060285, Regularization: 0.000110, Discriminator: 0.021779; Generator: 0.010827,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,308 root         INFO     Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 0.075896\n",
      "Reconstruction: 0.043363, Regularization: 0.000068, Discriminator: 0.021635; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,377 root         INFO     Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 0.073954\n",
      "Reconstruction: 0.041411, Regularization: 0.000064, Discriminator: 0.021644; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,446 root         INFO     Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 0.088534\n",
      "Reconstruction: 0.056002, Regularization: 0.000100, Discriminator: 0.021601; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,516 root         INFO     Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 0.084461\n",
      "Reconstruction: 0.051868, Regularization: 0.000090, Discriminator: 0.021668; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,584 root         INFO     Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 0.074997\n",
      "Reconstruction: 0.042477, Regularization: 0.000067, Discriminator: 0.021614; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,653 root         INFO     ====> Epoch: 74 Average loss: 0.0851\n",
      "2019-04-09 20:45:03,677 root         INFO     Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 0.090097\n",
      "Reconstruction: 0.057423, Regularization: 0.000103, Discriminator: 0.021734; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,750 root         INFO     Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 0.081407\n",
      "Reconstruction: 0.048907, Regularization: 0.000081, Discriminator: 0.021586; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,819 root         INFO     Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 0.080234\n",
      "Reconstruction: 0.047646, Regularization: 0.000080, Discriminator: 0.021678; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,887 root         INFO     Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 0.077616\n",
      "Reconstruction: 0.045117, Regularization: 0.000073, Discriminator: 0.021607; Generator: 0.010819,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,955 root         INFO     Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 0.083790\n",
      "Reconstruction: 0.051184, Regularization: 0.000086, Discriminator: 0.021689; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,021 root         INFO     Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 0.082258\n",
      "Reconstruction: 0.049694, Regularization: 0.000082, Discriminator: 0.021652; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,089 root         INFO     Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 0.075081\n",
      "Reconstruction: 0.042449, Regularization: 0.000064, Discriminator: 0.021733; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,157 root         INFO     Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 0.087768\n",
      "Reconstruction: 0.055056, Regularization: 0.000091, Discriminator: 0.021781; Generator: 0.010841,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,227 root         INFO     ====> Epoch: 75 Average loss: 0.0851\n",
      "2019-04-09 20:45:04,251 root         INFO     Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 0.079874\n",
      "Reconstruction: 0.047350, Regularization: 0.000075, Discriminator: 0.021609; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,319 root         INFO     Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 0.080699\n",
      "Reconstruction: 0.048124, Regularization: 0.000074, Discriminator: 0.021665; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,385 root         INFO     Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 0.092884\n",
      "Reconstruction: 0.060281, Regularization: 0.000101, Discriminator: 0.021664; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,453 root         INFO     Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 0.088858\n",
      "Reconstruction: 0.056310, Regularization: 0.000093, Discriminator: 0.021623; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,520 root         INFO     Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 0.088523\n",
      "Reconstruction: 0.055939, Regularization: 0.000091, Discriminator: 0.021661; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,588 root         INFO     Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 0.096125\n",
      "Reconstruction: 0.063573, Regularization: 0.000107, Discriminator: 0.021606; Generator: 0.010839,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,656 root         INFO     Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 0.093567\n",
      "Reconstruction: 0.060943, Regularization: 0.000104, Discriminator: 0.021681; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,733 root         INFO     Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 0.095115\n",
      "Reconstruction: 0.062576, Regularization: 0.000103, Discriminator: 0.021604; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,802 root         INFO     ====> Epoch: 76 Average loss: 0.0851\n",
      "2019-04-09 20:45:04,826 root         INFO     Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 0.085494\n",
      "Reconstruction: 0.052878, Regularization: 0.000080, Discriminator: 0.021705; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,892 root         INFO     Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 0.092564\n",
      "Reconstruction: 0.060007, Regularization: 0.000098, Discriminator: 0.021622; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,959 root         INFO     Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 0.087078\n",
      "Reconstruction: 0.054477, Regularization: 0.000086, Discriminator: 0.021685; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,024 root         INFO     Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 0.081598\n",
      "Reconstruction: 0.049074, Regularization: 0.000075, Discriminator: 0.021619; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,116 root         INFO     Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 0.089139\n",
      "Reconstruction: 0.056500, Regularization: 0.000095, Discriminator: 0.021712; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,218 root         INFO     Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 0.094494\n",
      "Reconstruction: 0.061918, Regularization: 0.000109, Discriminator: 0.021638; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,287 root         INFO     Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 0.091463\n",
      "Reconstruction: 0.058857, Regularization: 0.000103, Discriminator: 0.021665; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,354 root         INFO     Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 0.083545\n",
      "Reconstruction: 0.050895, Regularization: 0.000087, Discriminator: 0.021724; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,423 root         INFO     ====> Epoch: 77 Average loss: 0.0851\n",
      "2019-04-09 20:45:05,447 root         INFO     Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 0.090489\n",
      "Reconstruction: 0.057884, Regularization: 0.000102, Discriminator: 0.021667; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,513 root         INFO     Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 0.078655\n",
      "Reconstruction: 0.046099, Regularization: 0.000074, Discriminator: 0.021650; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,579 root         INFO     Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 0.088697\n",
      "Reconstruction: 0.056145, Regularization: 0.000098, Discriminator: 0.021620; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,644 root         INFO     Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 0.085193\n",
      "Reconstruction: 0.052643, Regularization: 0.000090, Discriminator: 0.021627; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,708 root         INFO     Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 0.088186\n",
      "Reconstruction: 0.055579, Regularization: 0.000098, Discriminator: 0.021673; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,774 root         INFO     Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 0.081478\n",
      "Reconstruction: 0.048785, Regularization: 0.000083, Discriminator: 0.021771; Generator: 0.010840,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,839 root         INFO     Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 0.084930\n",
      "Reconstruction: 0.052384, Regularization: 0.000092, Discriminator: 0.021626; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,903 root         INFO     Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 0.070665\n",
      "Reconstruction: 0.038133, Regularization: 0.000058, Discriminator: 0.021641; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,970 root         INFO     ====> Epoch: 78 Average loss: 0.0851\n",
      "2019-04-09 20:45:05,994 root         INFO     Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 0.075751\n",
      "Reconstruction: 0.043176, Regularization: 0.000070, Discriminator: 0.021668; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,061 root         INFO     Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 0.083818\n",
      "Reconstruction: 0.051259, Regularization: 0.000093, Discriminator: 0.021630; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,127 root         INFO     Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 0.076566\n",
      "Reconstruction: 0.043941, Regularization: 0.000073, Discriminator: 0.021705; Generator: 0.010847,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 20:45:06,192 root         INFO     Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 0.104468\n",
      "Reconstruction: 0.071771, Regularization: 0.000141, Discriminator: 0.021719; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,257 root         INFO     Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 0.097007\n",
      "Reconstruction: 0.064306, Regularization: 0.000129, Discriminator: 0.021735; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,320 root         INFO     Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 0.099788\n",
      "Reconstruction: 0.067162, Regularization: 0.000137, Discriminator: 0.021651; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,382 root         INFO     Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 0.094634\n",
      "Reconstruction: 0.062010, Regularization: 0.000124, Discriminator: 0.021665; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,445 root         INFO     Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 0.087887\n",
      "Reconstruction: 0.055252, Regularization: 0.000106, Discriminator: 0.021701; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,509 root         INFO     ====> Epoch: 79 Average loss: 0.0851\n",
      "2019-04-09 20:45:06,533 root         INFO     Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 0.089227\n",
      "Reconstruction: 0.056649, Regularization: 0.000108, Discriminator: 0.021640; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,597 root         INFO     Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 0.087806\n",
      "Reconstruction: 0.055219, Regularization: 0.000105, Discriminator: 0.021635; Generator: 0.010847,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 20:45:06,660 root         INFO     Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 0.088946\n",
      "Reconstruction: 0.056348, Regularization: 0.000104, Discriminator: 0.021659; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,724 root         INFO     Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 0.084281\n",
      "Reconstruction: 0.051775, Regularization: 0.000093, Discriminator: 0.021582; Generator: 0.010830,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,788 root         INFO     Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 0.078925\n",
      "Reconstruction: 0.046314, Regularization: 0.000078, Discriminator: 0.021695; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,852 root         INFO     Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 0.086849\n",
      "Reconstruction: 0.054263, Regularization: 0.000097, Discriminator: 0.021659; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,915 root         INFO     Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 0.080587\n",
      "Reconstruction: 0.047923, Regularization: 0.000086, Discriminator: 0.021750; Generator: 0.010827,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,979 root         INFO     Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 0.079181\n",
      "Reconstruction: 0.046626, Regularization: 0.000082, Discriminator: 0.021647; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,044 root         INFO     ====> Epoch: 80 Average loss: 0.0851\n",
      "2019-04-09 20:45:07,068 root         INFO     Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 0.087824\n",
      "Reconstruction: 0.055198, Regularization: 0.000104, Discriminator: 0.021688; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,134 root         INFO     Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 0.083843\n",
      "Reconstruction: 0.051303, Regularization: 0.000095, Discriminator: 0.021599; Generator: 0.010846,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 20:45:07,199 root         INFO     Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 0.079386\n",
      "Reconstruction: 0.046734, Regularization: 0.000084, Discriminator: 0.021720; Generator: 0.010848,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 20:45:07,266 root         INFO     Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 0.082997\n",
      "Reconstruction: 0.050383, Regularization: 0.000094, Discriminator: 0.021684; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,332 root         INFO     Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 0.083269\n",
      "Reconstruction: 0.050725, Regularization: 0.000095, Discriminator: 0.021616; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,398 root         INFO     Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 0.089884\n",
      "Reconstruction: 0.057256, Regularization: 0.000110, Discriminator: 0.021685; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,464 root         INFO     Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 0.081957\n",
      "Reconstruction: 0.049417, Regularization: 0.000090, Discriminator: 0.021622; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,529 root         INFO     Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 0.095069\n",
      "Reconstruction: 0.062455, Regularization: 0.000121, Discriminator: 0.021671; Generator: 0.010823,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,596 root         INFO     ====> Epoch: 81 Average loss: 0.0851\n",
      "2019-04-09 20:45:07,620 root         INFO     Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 0.096308\n",
      "Reconstruction: 0.063681, Regularization: 0.000128, Discriminator: 0.021670; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,684 root         INFO     Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 0.096914\n",
      "Reconstruction: 0.064335, Regularization: 0.000127, Discriminator: 0.021626; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,747 root         INFO     Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 0.080535\n",
      "Reconstruction: 0.047963, Regularization: 0.000088, Discriminator: 0.021652; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,810 root         INFO     Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 0.071145\n",
      "Reconstruction: 0.038653, Regularization: 0.000064, Discriminator: 0.021595; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,873 root         INFO     Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 0.082984\n",
      "Reconstruction: 0.050455, Regularization: 0.000096, Discriminator: 0.021607; Generator: 0.010826,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,936 root         INFO     Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 0.081302\n",
      "Reconstruction: 0.048725, Regularization: 0.000091, Discriminator: 0.021651; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,999 root         INFO     Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 0.079293\n",
      "Reconstruction: 0.046692, Regularization: 0.000086, Discriminator: 0.021678; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,062 root         INFO     Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 0.082137\n",
      "Reconstruction: 0.049586, Regularization: 0.000093, Discriminator: 0.021619; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,126 root         INFO     ====> Epoch: 82 Average loss: 0.0851\n",
      "2019-04-09 20:45:08,150 root         INFO     Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 0.081844\n",
      "Reconstruction: 0.049185, Regularization: 0.000092, Discriminator: 0.021730; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,213 root         INFO     Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 0.080854\n",
      "Reconstruction: 0.048273, Regularization: 0.000086, Discriminator: 0.021654; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,276 root         INFO     Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 0.070362\n",
      "Reconstruction: 0.037862, Regularization: 0.000060, Discriminator: 0.021597; Generator: 0.010843,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,342 root         INFO     Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 0.088073\n",
      "Reconstruction: 0.055531, Regularization: 0.000103, Discriminator: 0.021602; Generator: 0.010838,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,408 root         INFO     Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 0.094365\n",
      "Reconstruction: 0.061757, Regularization: 0.000122, Discriminator: 0.021642; Generator: 0.010844,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,474 root         INFO     Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 0.092472\n",
      "Reconstruction: 0.059781, Regularization: 0.000115, Discriminator: 0.021743; Generator: 0.010833,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,539 root         INFO     Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 0.087942\n",
      "Reconstruction: 0.055403, Regularization: 0.000103, Discriminator: 0.021605; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,605 root         INFO     Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 0.087486\n",
      "Reconstruction: 0.054874, Regularization: 0.000099, Discriminator: 0.021685; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,672 root         INFO     ====> Epoch: 83 Average loss: 0.0851\n",
      "2019-04-09 20:45:08,696 root         INFO     Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 0.089284\n",
      "Reconstruction: 0.056617, Regularization: 0.000104, Discriminator: 0.021737; Generator: 0.010825,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,759 root         INFO     Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 0.090990\n",
      "Reconstruction: 0.058423, Regularization: 0.000107, Discriminator: 0.021628; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,822 root         INFO     Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 0.087418\n",
      "Reconstruction: 0.054887, Regularization: 0.000099, Discriminator: 0.021603; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,886 root         INFO     Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 0.087611\n",
      "Reconstruction: 0.054959, Regularization: 0.000100, Discriminator: 0.021727; Generator: 0.010825,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,952 root         INFO     Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 0.088487\n",
      "Reconstruction: 0.055898, Regularization: 0.000103, Discriminator: 0.021661; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,018 root         INFO     Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 0.074982\n",
      "Reconstruction: 0.042470, Regularization: 0.000067, Discriminator: 0.021617; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,084 root         INFO     Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 0.087752\n",
      "Reconstruction: 0.055168, Regularization: 0.000100, Discriminator: 0.021643; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,150 root         INFO     Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 0.078791\n",
      "Reconstruction: 0.046292, Regularization: 0.000078, Discriminator: 0.021579; Generator: 0.010841,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,218 root         INFO     ====> Epoch: 84 Average loss: 0.0851\n",
      "2019-04-09 20:45:09,242 root         INFO     Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 0.087452\n",
      "Reconstruction: 0.054807, Regularization: 0.000101, Discriminator: 0.021707; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,307 root         INFO     Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 0.083943\n",
      "Reconstruction: 0.051291, Regularization: 0.000094, Discriminator: 0.021720; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,374 root         INFO     Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 0.091961\n",
      "Reconstruction: 0.059425, Regularization: 0.000113, Discriminator: 0.021587; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,439 root         INFO     Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 0.088122\n",
      "Reconstruction: 0.055458, Regularization: 0.000103, Discriminator: 0.021729; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,505 root         INFO     Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 0.081171\n",
      "Reconstruction: 0.048651, Regularization: 0.000088, Discriminator: 0.021602; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,572 root         INFO     Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 0.072544\n",
      "Reconstruction: 0.039901, Regularization: 0.000067, Discriminator: 0.021747; Generator: 0.010828,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,638 root         INFO     Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 0.081129\n",
      "Reconstruction: 0.048581, Regularization: 0.000089, Discriminator: 0.021628; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,705 root         INFO     Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 0.076682\n",
      "Reconstruction: 0.044065, Regularization: 0.000076, Discriminator: 0.021702; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,773 root         INFO     ====> Epoch: 85 Average loss: 0.0851\n",
      "2019-04-09 20:45:09,797 root         INFO     Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 0.081599\n",
      "Reconstruction: 0.049024, Regularization: 0.000089, Discriminator: 0.021654; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,864 root         INFO     Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 0.080174\n",
      "Reconstruction: 0.047678, Regularization: 0.000086, Discriminator: 0.021581; Generator: 0.010829,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,933 root         INFO     Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 0.083448\n",
      "Reconstruction: 0.050888, Regularization: 0.000095, Discriminator: 0.021636; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,001 root         INFO     Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 0.084674\n",
      "Reconstruction: 0.052047, Regularization: 0.000097, Discriminator: 0.021704; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,070 root         INFO     Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 0.079932\n",
      "Reconstruction: 0.047363, Regularization: 0.000083, Discriminator: 0.021654; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,139 root         INFO     Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 0.080889\n",
      "Reconstruction: 0.048287, Regularization: 0.000085, Discriminator: 0.021681; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,207 root         INFO     Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 0.081553\n",
      "Reconstruction: 0.049114, Regularization: 0.000086, Discriminator: 0.021522; Generator: 0.010831,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,276 root         INFO     Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 0.089489\n",
      "Reconstruction: 0.056920, Regularization: 0.000104, Discriminator: 0.021624; Generator: 0.010841,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,347 root         INFO     ====> Epoch: 86 Average loss: 0.0850\n",
      "2019-04-09 20:45:10,371 root         INFO     Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 0.086457\n",
      "Reconstruction: 0.053896, Regularization: 0.000096, Discriminator: 0.021627; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,438 root         INFO     Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 0.092219\n",
      "Reconstruction: 0.059620, Regularization: 0.000109, Discriminator: 0.021648; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,506 root         INFO     Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 0.078877\n",
      "Reconstruction: 0.046311, Regularization: 0.000077, Discriminator: 0.021656; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,572 root         INFO     Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 0.092819\n",
      "Reconstruction: 0.060229, Regularization: 0.000110, Discriminator: 0.021650; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,639 root         INFO     Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 0.091433\n",
      "Reconstruction: 0.058894, Regularization: 0.000107, Discriminator: 0.021604; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,707 root         INFO     Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 0.080352\n",
      "Reconstruction: 0.047769, Regularization: 0.000080, Discriminator: 0.021671; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,774 root         INFO     Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 0.081945\n",
      "Reconstruction: 0.049416, Regularization: 0.000084, Discriminator: 0.021611; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,842 root         INFO     Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 0.085812\n",
      "Reconstruction: 0.053308, Regularization: 0.000094, Discriminator: 0.021574; Generator: 0.010836,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,913 root         INFO     ====> Epoch: 87 Average loss: 0.0851\n",
      "2019-04-09 20:45:10,937 root         INFO     Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 0.087193\n",
      "Reconstruction: 0.054580, Regularization: 0.000095, Discriminator: 0.021683; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,006 root         INFO     Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 0.099324\n",
      "Reconstruction: 0.066818, Regularization: 0.000123, Discriminator: 0.021560; Generator: 0.010823,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,073 root         INFO     Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 0.090495\n",
      "Reconstruction: 0.057922, Regularization: 0.000103, Discriminator: 0.021646; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,141 root         INFO     Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 0.091619\n",
      "Reconstruction: 0.059018, Regularization: 0.000106, Discriminator: 0.021657; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,208 root         INFO     Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 0.073311\n",
      "Reconstruction: 0.040770, Regularization: 0.000063, Discriminator: 0.021636; Generator: 0.010842,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,276 root         INFO     Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 0.082795\n",
      "Reconstruction: 0.050231, Regularization: 0.000084, Discriminator: 0.021636; Generator: 0.010844,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,344 root         INFO     Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 0.082464\n",
      "Reconstruction: 0.049981, Regularization: 0.000085, Discriminator: 0.021560; Generator: 0.010837,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,411 root         INFO     Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 0.085196\n",
      "Reconstruction: 0.052631, Regularization: 0.000094, Discriminator: 0.021636; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,478 root         INFO     ====> Epoch: 88 Average loss: 0.0851\n",
      "2019-04-09 20:45:11,502 root         INFO     Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 0.078509\n",
      "Reconstruction: 0.045918, Regularization: 0.000077, Discriminator: 0.021683; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,570 root         INFO     Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 0.091653\n",
      "Reconstruction: 0.059132, Regularization: 0.000110, Discriminator: 0.021585; Generator: 0.010825,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,638 root         INFO     Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 0.087629\n",
      "Reconstruction: 0.055032, Regularization: 0.000099, Discriminator: 0.021665; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,705 root         INFO     Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 0.085720\n",
      "Reconstruction: 0.053110, Regularization: 0.000096, Discriminator: 0.021682; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,772 root         INFO     Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 0.086248\n",
      "Reconstruction: 0.053715, Regularization: 0.000097, Discriminator: 0.021611; Generator: 0.010825,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,840 root         INFO     Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 0.088313\n",
      "Reconstruction: 0.055650, Regularization: 0.000102, Discriminator: 0.021728; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,907 root         INFO     Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 0.085393\n",
      "Reconstruction: 0.052769, Regularization: 0.000094, Discriminator: 0.021696; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,975 root         INFO     Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 0.074568\n",
      "Reconstruction: 0.042007, Regularization: 0.000066, Discriminator: 0.021661; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,044 root         INFO     ====> Epoch: 89 Average loss: 0.0851\n",
      "2019-04-09 20:45:12,068 root         INFO     Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 0.086291\n",
      "Reconstruction: 0.053710, Regularization: 0.000095, Discriminator: 0.021646; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,135 root         INFO     Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 0.088142\n",
      "Reconstruction: 0.055570, Regularization: 0.000099, Discriminator: 0.021640; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,201 root         INFO     Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 0.088903\n",
      "Reconstruction: 0.056312, Regularization: 0.000098, Discriminator: 0.021658; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,268 root         INFO     Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 0.087067\n",
      "Reconstruction: 0.054439, Regularization: 0.000094, Discriminator: 0.021692; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,334 root         INFO     Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 0.086959\n",
      "Reconstruction: 0.054363, Regularization: 0.000093, Discriminator: 0.021667; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,401 root         INFO     Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 0.087634\n",
      "Reconstruction: 0.055107, Regularization: 0.000094, Discriminator: 0.021598; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,468 root         INFO     Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 0.089703\n",
      "Reconstruction: 0.057003, Regularization: 0.000098, Discriminator: 0.021761; Generator: 0.010841,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,535 root         INFO     Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 0.081396\n",
      "Reconstruction: 0.048805, Regularization: 0.000081, Discriminator: 0.021677; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,603 root         INFO     ====> Epoch: 90 Average loss: 0.0851\n",
      "2019-04-09 20:45:12,627 root         INFO     Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 0.089854\n",
      "Reconstruction: 0.057313, Regularization: 0.000102, Discriminator: 0.021610; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,694 root         INFO     Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 0.097007\n",
      "Reconstruction: 0.064405, Regularization: 0.000120, Discriminator: 0.021650; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,761 root         INFO     Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 0.070423\n",
      "Reconstruction: 0.037871, Regularization: 0.000056, Discriminator: 0.021662; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,830 root         INFO     Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 0.086859\n",
      "Reconstruction: 0.054132, Regularization: 0.000096, Discriminator: 0.021790; Generator: 0.010840,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,895 root         INFO     Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 0.076250\n",
      "Reconstruction: 0.043640, Regularization: 0.000071, Discriminator: 0.021704; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,960 root         INFO     Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 0.070943\n",
      "Reconstruction: 0.038411, Regularization: 0.000057, Discriminator: 0.021641; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,024 root         INFO     Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 0.099817\n",
      "Reconstruction: 0.067256, Regularization: 0.000124, Discriminator: 0.021605; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,086 root         INFO     Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 0.087505\n",
      "Reconstruction: 0.054916, Regularization: 0.000094, Discriminator: 0.021668; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,150 root         INFO     ====> Epoch: 91 Average loss: 0.0850\n",
      "2019-04-09 20:45:13,174 root         INFO     Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 0.081752\n",
      "Reconstruction: 0.049199, Regularization: 0.000082, Discriminator: 0.021639; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,238 root         INFO     Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 0.099963\n",
      "Reconstruction: 0.067292, Regularization: 0.000125, Discriminator: 0.021718; Generator: 0.010829,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,305 root         INFO     Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 0.096183\n",
      "Reconstruction: 0.063556, Regularization: 0.000117, Discriminator: 0.021681; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,371 root         INFO     Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 0.073829\n",
      "Reconstruction: 0.041289, Regularization: 0.000062, Discriminator: 0.021643; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,437 root         INFO     Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 0.082075\n",
      "Reconstruction: 0.049531, Regularization: 0.000081, Discriminator: 0.021624; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,503 root         INFO     Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 0.089599\n",
      "Reconstruction: 0.057024, Regularization: 0.000098, Discriminator: 0.021642; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,569 root         INFO     Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 0.085800\n",
      "Reconstruction: 0.053229, Regularization: 0.000090, Discriminator: 0.021652; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,636 root         INFO     Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 0.080524\n",
      "Reconstruction: 0.047935, Regularization: 0.000077, Discriminator: 0.021680; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,703 root         INFO     ====> Epoch: 92 Average loss: 0.0851\n",
      "2019-04-09 20:45:13,728 root         INFO     Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 0.089016\n",
      "Reconstruction: 0.056408, Regularization: 0.000097, Discriminator: 0.021671; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,795 root         INFO     Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 0.082454\n",
      "Reconstruction: 0.049890, Regularization: 0.000079, Discriminator: 0.021650; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,862 root         INFO     Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 0.084324\n",
      "Reconstruction: 0.051693, Regularization: 0.000085, Discriminator: 0.021716; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,927 root         INFO     Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 0.096079\n",
      "Reconstruction: 0.063455, Regularization: 0.000113, Discriminator: 0.021682; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,993 root         INFO     Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 0.083901\n",
      "Reconstruction: 0.051314, Regularization: 0.000084, Discriminator: 0.021677; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,058 root         INFO     Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 0.071868\n",
      "Reconstruction: 0.039402, Regularization: 0.000058, Discriminator: 0.021581; Generator: 0.010827,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,125 root         INFO     Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 0.076974\n",
      "Reconstruction: 0.044401, Regularization: 0.000069, Discriminator: 0.021678; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,191 root         INFO     Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 0.080026\n",
      "Reconstruction: 0.047475, Regularization: 0.000078, Discriminator: 0.021633; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,258 root         INFO     ====> Epoch: 93 Average loss: 0.0851\n",
      "2019-04-09 20:45:14,282 root         INFO     Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 0.082840\n",
      "Reconstruction: 0.050210, Regularization: 0.000082, Discriminator: 0.021701; Generator: 0.010847,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 20:45:14,349 root         INFO     Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 0.082858\n",
      "Reconstruction: 0.050360, Regularization: 0.000081, Discriminator: 0.021583; Generator: 0.010834,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,416 root         INFO     Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 0.088889\n",
      "Reconstruction: 0.056283, Regularization: 0.000094, Discriminator: 0.021675; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,483 root         INFO     Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 0.084385\n",
      "Reconstruction: 0.051744, Regularization: 0.000083, Discriminator: 0.021718; Generator: 0.010841,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,550 root         INFO     Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 0.086667\n",
      "Reconstruction: 0.054101, Regularization: 0.000087, Discriminator: 0.021646; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,616 root         INFO     Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 0.078159\n",
      "Reconstruction: 0.045601, Regularization: 0.000069, Discriminator: 0.021665; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,683 root         INFO     Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 0.094859\n",
      "Reconstruction: 0.062287, Regularization: 0.000106, Discriminator: 0.021643; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,748 root         INFO     Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 0.086398\n",
      "Reconstruction: 0.053767, Regularization: 0.000088, Discriminator: 0.021706; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,814 root         INFO     ====> Epoch: 94 Average loss: 0.0851\n",
      "2019-04-09 20:45:14,837 root         INFO     Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 0.087174\n",
      "Reconstruction: 0.054571, Regularization: 0.000090, Discriminator: 0.021670; Generator: 0.010843,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,906 root         INFO     Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 0.080850\n",
      "Reconstruction: 0.048258, Regularization: 0.000078, Discriminator: 0.021678; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,973 root         INFO     Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 0.085940\n",
      "Reconstruction: 0.053447, Regularization: 0.000090, Discriminator: 0.021568; Generator: 0.010835,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,040 root         INFO     Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 0.087874\n",
      "Reconstruction: 0.055297, Regularization: 0.000092, Discriminator: 0.021642; Generator: 0.010843,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,108 root         INFO     Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 0.082951\n",
      "Reconstruction: 0.050318, Regularization: 0.000082, Discriminator: 0.021708; Generator: 0.010843,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,175 root         INFO     Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 0.087796\n",
      "Reconstruction: 0.055213, Regularization: 0.000094, Discriminator: 0.021661; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,242 root         INFO     Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 0.085797\n",
      "Reconstruction: 0.053200, Regularization: 0.000091, Discriminator: 0.021674; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,311 root         INFO     Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 0.084791\n",
      "Reconstruction: 0.052137, Regularization: 0.000086, Discriminator: 0.021727; Generator: 0.010842,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,380 root         INFO     ====> Epoch: 95 Average loss: 0.0851\n",
      "2019-04-09 20:45:15,404 root         INFO     Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 0.086797\n",
      "Reconstruction: 0.054219, Regularization: 0.000093, Discriminator: 0.021655; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,471 root         INFO     Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 0.076934\n",
      "Reconstruction: 0.044359, Regularization: 0.000069, Discriminator: 0.021676; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,539 root         INFO     Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 0.072369\n",
      "Reconstruction: 0.039852, Regularization: 0.000058, Discriminator: 0.021627; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,607 root         INFO     Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 0.086519\n",
      "Reconstruction: 0.053921, Regularization: 0.000091, Discriminator: 0.021673; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,675 root         INFO     Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 0.082377\n",
      "Reconstruction: 0.049862, Regularization: 0.000084, Discriminator: 0.021604; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,741 root         INFO     Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 0.092025\n",
      "Reconstruction: 0.059519, Regularization: 0.000106, Discriminator: 0.021566; Generator: 0.010833,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,806 root         INFO     Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 0.092384\n",
      "Reconstruction: 0.059859, Regularization: 0.000106, Discriminator: 0.021581; Generator: 0.010838,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,871 root         INFO     Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 0.086302\n",
      "Reconstruction: 0.053764, Regularization: 0.000092, Discriminator: 0.021618; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,938 root         INFO     ====> Epoch: 96 Average loss: 0.0850\n",
      "2019-04-09 20:45:15,962 root         INFO     Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 0.078903\n",
      "Reconstruction: 0.046414, Regularization: 0.000075, Discriminator: 0.021578; Generator: 0.010836,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,029 root         INFO     Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 0.079089\n",
      "Reconstruction: 0.046485, Regularization: 0.000074, Discriminator: 0.021697; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,096 root         INFO     Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 0.084244\n",
      "Reconstruction: 0.051650, Regularization: 0.000085, Discriminator: 0.021676; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,163 root         INFO     Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 0.089045\n",
      "Reconstruction: 0.056369, Regularization: 0.000097, Discriminator: 0.021749; Generator: 0.010830,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,230 root         INFO     Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 0.084362\n",
      "Reconstruction: 0.051790, Regularization: 0.000088, Discriminator: 0.021657; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,297 root         INFO     Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 0.093603\n",
      "Reconstruction: 0.060982, Regularization: 0.000108, Discriminator: 0.021679; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,364 root         INFO     Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 0.082530\n",
      "Reconstruction: 0.049949, Regularization: 0.000080, Discriminator: 0.021657; Generator: 0.010845,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,431 root         INFO     Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 0.081147\n",
      "Reconstruction: 0.048548, Regularization: 0.000078, Discriminator: 0.021683; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,499 root         INFO     ====> Epoch: 97 Average loss: 0.0851\n",
      "2019-04-09 20:45:16,523 root         INFO     Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 0.082102\n",
      "Reconstruction: 0.049528, Regularization: 0.000079, Discriminator: 0.021655; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,590 root         INFO     Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 0.086069\n",
      "Reconstruction: 0.053448, Regularization: 0.000090, Discriminator: 0.021700; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,657 root         INFO     Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 0.078528\n",
      "Reconstruction: 0.046014, Regularization: 0.000072, Discriminator: 0.021616; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,724 root         INFO     Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 0.083585\n",
      "Reconstruction: 0.050970, Regularization: 0.000084, Discriminator: 0.021688; Generator: 0.010843,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,789 root         INFO     Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 0.083934\n",
      "Reconstruction: 0.051363, Regularization: 0.000083, Discriminator: 0.021644; Generator: 0.010845,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,854 root         INFO     Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 0.111452\n",
      "Reconstruction: 0.078978, Regularization: 0.000145, Discriminator: 0.021501; Generator: 0.010830,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,918 root         INFO     Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 0.091424\n",
      "Reconstruction: 0.058781, Regularization: 0.000101, Discriminator: 0.021707; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,982 root         INFO     Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 0.093671\n",
      "Reconstruction: 0.061157, Regularization: 0.000104, Discriminator: 0.021584; Generator: 0.010827,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,049 root         INFO     ====> Epoch: 98 Average loss: 0.0851\n",
      "2019-04-09 20:45:17,074 root         INFO     Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 0.087839\n",
      "Reconstruction: 0.055278, Regularization: 0.000089, Discriminator: 0.021637; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,140 root         INFO     Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 0.080910\n",
      "Reconstruction: 0.048301, Regularization: 0.000075, Discriminator: 0.021700; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,206 root         INFO     Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 0.082875\n",
      "Reconstruction: 0.050294, Regularization: 0.000082, Discriminator: 0.021669; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,272 root         INFO     Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 0.087913\n",
      "Reconstruction: 0.055289, Regularization: 0.000093, Discriminator: 0.021697; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,338 root         INFO     Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 0.088070\n",
      "Reconstruction: 0.055541, Regularization: 0.000092, Discriminator: 0.021608; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,404 root         INFO     Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 0.079786\n",
      "Reconstruction: 0.047195, Regularization: 0.000075, Discriminator: 0.021678; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,470 root         INFO     Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 0.083386\n",
      "Reconstruction: 0.050870, Regularization: 0.000083, Discriminator: 0.021601; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,536 root         INFO     Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 0.092528\n",
      "Reconstruction: 0.059956, Regularization: 0.000103, Discriminator: 0.021634; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,603 root         INFO     ====> Epoch: 99 Average loss: 0.0851\n",
      "2019-04-09 20:45:17,627 root         INFO     Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 0.086372\n",
      "Reconstruction: 0.053842, Regularization: 0.000090, Discriminator: 0.021605; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,692 root         INFO     Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 0.085913\n",
      "Reconstruction: 0.053345, Regularization: 0.000087, Discriminator: 0.021645; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,758 root         INFO     Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 0.086177\n",
      "Reconstruction: 0.053660, Regularization: 0.000088, Discriminator: 0.021602; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,824 root         INFO     Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 0.085697\n",
      "Reconstruction: 0.053165, Regularization: 0.000088, Discriminator: 0.021609; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,890 root         INFO     Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 0.083756\n",
      "Reconstruction: 0.051232, Regularization: 0.000086, Discriminator: 0.021607; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,955 root         INFO     Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 0.076963\n",
      "Reconstruction: 0.044373, Regularization: 0.000071, Discriminator: 0.021685; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,022 root         INFO     Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 0.081526\n",
      "Reconstruction: 0.049003, Regularization: 0.000082, Discriminator: 0.021612; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,087 root         INFO     Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 0.081164\n",
      "Reconstruction: 0.048561, Regularization: 0.000082, Discriminator: 0.021684; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,155 root         INFO     ====> Epoch: 100 Average loss: 0.0851\n",
      "2019-04-09 20:45:18,179 root         INFO     Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 0.088510\n",
      "Reconstruction: 0.055822, Regularization: 0.000100, Discriminator: 0.021752; Generator: 0.010836,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,246 root         INFO     Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 0.082842\n",
      "Reconstruction: 0.050159, Regularization: 0.000088, Discriminator: 0.021768; Generator: 0.010827,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,312 root         INFO     Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 0.079274\n",
      "Reconstruction: 0.046710, Regularization: 0.000077, Discriminator: 0.021662; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,379 root         INFO     Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 0.080977\n",
      "Reconstruction: 0.048425, Regularization: 0.000082, Discriminator: 0.021638; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,445 root         INFO     Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 0.083363\n",
      "Reconstruction: 0.050751, Regularization: 0.000090, Discriminator: 0.021687; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,512 root         INFO     Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 0.092114\n",
      "Reconstruction: 0.059597, Regularization: 0.000111, Discriminator: 0.021573; Generator: 0.010833,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,579 root         INFO     Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 0.079502\n",
      "Reconstruction: 0.046926, Regularization: 0.000079, Discriminator: 0.021663; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,646 root         INFO     Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 0.087532\n",
      "Reconstruction: 0.054980, Regularization: 0.000098, Discriminator: 0.021619; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,715 root         INFO     ====> Epoch: 101 Average loss: 0.0851\n",
      "2019-04-09 20:45:18,739 root         INFO     Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 0.095487\n",
      "Reconstruction: 0.062784, Regularization: 0.000117, Discriminator: 0.021745; Generator: 0.010841,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,807 root         INFO     Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 0.085317\n",
      "Reconstruction: 0.052700, Regularization: 0.000092, Discriminator: 0.021684; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,874 root         INFO     Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 0.087903\n",
      "Reconstruction: 0.055307, Regularization: 0.000099, Discriminator: 0.021669; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,940 root         INFO     Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 0.085173\n",
      "Reconstruction: 0.052634, Regularization: 0.000092, Discriminator: 0.021619; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,009 root         INFO     Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 0.083150\n",
      "Reconstruction: 0.050575, Regularization: 0.000087, Discriminator: 0.021654; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,076 root         INFO     Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 0.077226\n",
      "Reconstruction: 0.044660, Regularization: 0.000073, Discriminator: 0.021648; Generator: 0.010845,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,143 root         INFO     Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 0.088038\n",
      "Reconstruction: 0.055476, Regularization: 0.000101, Discriminator: 0.021619; Generator: 0.010842,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,209 root         INFO     Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 0.078873\n",
      "Reconstruction: 0.046274, Regularization: 0.000079, Discriminator: 0.021678; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,277 root         INFO     ====> Epoch: 102 Average loss: 0.0851\n",
      "2019-04-09 20:45:19,301 root         INFO     Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 0.081095\n",
      "Reconstruction: 0.048473, Regularization: 0.000084, Discriminator: 0.021705; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,369 root         INFO     Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 0.074831\n",
      "Reconstruction: 0.042274, Regularization: 0.000068, Discriminator: 0.021654; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,435 root         INFO     Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 0.085753\n",
      "Reconstruction: 0.053223, Regularization: 0.000095, Discriminator: 0.021594; Generator: 0.010841,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,501 root         INFO     Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 0.089931\n",
      "Reconstruction: 0.057307, Regularization: 0.000105, Discriminator: 0.021677; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,564 root         INFO     Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 0.079663\n",
      "Reconstruction: 0.047043, Regularization: 0.000079, Discriminator: 0.021702; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,628 root         INFO     Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 0.078900\n",
      "Reconstruction: 0.046346, Regularization: 0.000075, Discriminator: 0.021655; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,690 root         INFO     Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 0.078663\n",
      "Reconstruction: 0.046152, Regularization: 0.000075, Discriminator: 0.021614; Generator: 0.010823,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,754 root         INFO     Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 0.074072\n",
      "Reconstruction: 0.041528, Regularization: 0.000065, Discriminator: 0.021652; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,821 root         INFO     ====> Epoch: 103 Average loss: 0.0851\n",
      "2019-04-09 20:45:19,845 root         INFO     Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 0.095978\n",
      "Reconstruction: 0.063286, Regularization: 0.000116, Discriminator: 0.021738; Generator: 0.010837,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,912 root         INFO     Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 0.069134\n",
      "Reconstruction: 0.036648, Regularization: 0.000053, Discriminator: 0.021603; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,979 root         INFO     Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 0.094028\n",
      "Reconstruction: 0.061385, Regularization: 0.000110, Discriminator: 0.021703; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,045 root         INFO     Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 0.099713\n",
      "Reconstruction: 0.067091, Regularization: 0.000121, Discriminator: 0.021667; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,111 root         INFO     Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 0.090626\n",
      "Reconstruction: 0.058054, Regularization: 0.000101, Discriminator: 0.021630; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,178 root         INFO     Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 0.086210\n",
      "Reconstruction: 0.053650, Regularization: 0.000092, Discriminator: 0.021633; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,243 root         INFO     Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 0.086104\n",
      "Reconstruction: 0.053455, Regularization: 0.000090, Discriminator: 0.021720; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,309 root         INFO     Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 0.077228\n",
      "Reconstruction: 0.044706, Regularization: 0.000069, Discriminator: 0.021619; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,377 root         INFO     ====> Epoch: 104 Average loss: 0.0851\n",
      "2019-04-09 20:45:20,401 root         INFO     Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 0.100302\n",
      "Reconstruction: 0.067810, Regularization: 0.000121, Discriminator: 0.021539; Generator: 0.010833,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,469 root         INFO     Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 0.098546\n",
      "Reconstruction: 0.065934, Regularization: 0.000118, Discriminator: 0.021652; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,537 root         INFO     Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 0.081253\n",
      "Reconstruction: 0.048675, Regularization: 0.000079, Discriminator: 0.021666; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,602 root         INFO     Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 0.097659\n",
      "Reconstruction: 0.064998, Regularization: 0.000117, Discriminator: 0.021705; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,667 root         INFO     Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 0.085005\n",
      "Reconstruction: 0.052383, Regularization: 0.000089, Discriminator: 0.021703; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,733 root         INFO     Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 0.081107\n",
      "Reconstruction: 0.048604, Regularization: 0.000081, Discriminator: 0.021593; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,800 root         INFO     Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 0.075033\n",
      "Reconstruction: 0.042504, Regularization: 0.000067, Discriminator: 0.021624; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,866 root         INFO     Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 0.082625\n",
      "Reconstruction: 0.050021, Regularization: 0.000086, Discriminator: 0.021678; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,934 root         INFO     ====> Epoch: 105 Average loss: 0.0851\n",
      "2019-04-09 20:45:20,958 root         INFO     Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 0.080008\n",
      "Reconstruction: 0.047443, Regularization: 0.000078, Discriminator: 0.021653; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,026 root         INFO     Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 0.079161\n",
      "Reconstruction: 0.046574, Regularization: 0.000074, Discriminator: 0.021684; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,094 root         INFO     Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 0.072540\n",
      "Reconstruction: 0.040057, Regularization: 0.000060, Discriminator: 0.021594; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,162 root         INFO     Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 0.094740\n",
      "Reconstruction: 0.062143, Regularization: 0.000111, Discriminator: 0.021651; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,230 root         INFO     Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 0.086203\n",
      "Reconstruction: 0.053588, Regularization: 0.000093, Discriminator: 0.021692; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,297 root         INFO     Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 0.081431\n",
      "Reconstruction: 0.048898, Regularization: 0.000079, Discriminator: 0.021622; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,364 root         INFO     Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 0.077588\n",
      "Reconstruction: 0.045014, Regularization: 0.000070, Discriminator: 0.021664; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,431 root         INFO     Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 0.082461\n",
      "Reconstruction: 0.049813, Regularization: 0.000084, Discriminator: 0.021728; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,500 root         INFO     ====> Epoch: 106 Average loss: 0.0850\n",
      "2019-04-09 20:45:21,524 root         INFO     Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 0.102117\n",
      "Reconstruction: 0.069550, Regularization: 0.000132, Discriminator: 0.021599; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,591 root         INFO     Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 0.085021\n",
      "Reconstruction: 0.052434, Regularization: 0.000090, Discriminator: 0.021655; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,659 root         INFO     Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 0.092662\n",
      "Reconstruction: 0.060048, Regularization: 0.000106, Discriminator: 0.021669; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,726 root         INFO     Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 0.083131\n",
      "Reconstruction: 0.050576, Regularization: 0.000084, Discriminator: 0.021641; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,794 root         INFO     Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 0.082903\n",
      "Reconstruction: 0.050370, Regularization: 0.000081, Discriminator: 0.021615; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,861 root         INFO     Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 0.091002\n",
      "Reconstruction: 0.058335, Regularization: 0.000098, Discriminator: 0.021727; Generator: 0.010841,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,928 root         INFO     Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 0.076079\n",
      "Reconstruction: 0.043595, Regularization: 0.000065, Discriminator: 0.021587; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,995 root         INFO     Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 0.088954\n",
      "Reconstruction: 0.056295, Regularization: 0.000092, Discriminator: 0.021732; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,064 root         INFO     ====> Epoch: 107 Average loss: 0.0850\n",
      "2019-04-09 20:45:22,088 root         INFO     Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 0.089514\n",
      "Reconstruction: 0.056908, Regularization: 0.000093, Discriminator: 0.021684; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,155 root         INFO     Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 0.089215\n",
      "Reconstruction: 0.056584, Regularization: 0.000093, Discriminator: 0.021703; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,222 root         INFO     Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 0.092759\n",
      "Reconstruction: 0.060173, Regularization: 0.000102, Discriminator: 0.021651; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,288 root         INFO     Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 0.085531\n",
      "Reconstruction: 0.052929, Regularization: 0.000087, Discriminator: 0.021672; Generator: 0.010843,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,354 root         INFO     Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 0.085883\n",
      "Reconstruction: 0.053317, Regularization: 0.000090, Discriminator: 0.021642; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,420 root         INFO     Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 0.094505\n",
      "Reconstruction: 0.061955, Regularization: 0.000107, Discriminator: 0.021618; Generator: 0.010825,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,486 root         INFO     Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 0.075919\n",
      "Reconstruction: 0.043355, Regularization: 0.000065, Discriminator: 0.021668; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,551 root         INFO     Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 0.082911\n",
      "Reconstruction: 0.050411, Regularization: 0.000080, Discriminator: 0.021590; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,618 root         INFO     ====> Epoch: 108 Average loss: 0.0851\n",
      "2019-04-09 20:45:22,642 root         INFO     Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 0.082855\n",
      "Reconstruction: 0.050299, Regularization: 0.000079, Discriminator: 0.021644; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,710 root         INFO     Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 0.082654\n",
      "Reconstruction: 0.050161, Regularization: 0.000078, Discriminator: 0.021590; Generator: 0.010826,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,778 root         INFO     Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 0.090873\n",
      "Reconstruction: 0.058273, Regularization: 0.000094, Discriminator: 0.021674; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,846 root         INFO     Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 0.080787\n",
      "Reconstruction: 0.048184, Regularization: 0.000072, Discriminator: 0.021690; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,913 root         INFO     Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 0.081249\n",
      "Reconstruction: 0.048759, Regularization: 0.000075, Discriminator: 0.021584; Generator: 0.010830,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,980 root         INFO     Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 0.087717\n",
      "Reconstruction: 0.055065, Regularization: 0.000088, Discriminator: 0.021731; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,047 root         INFO     Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 0.090385\n",
      "Reconstruction: 0.057786, Regularization: 0.000094, Discriminator: 0.021672; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,115 root         INFO     Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 0.075868\n",
      "Reconstruction: 0.043294, Regularization: 0.000062, Discriminator: 0.021678; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,183 root         INFO     ====> Epoch: 109 Average loss: 0.0851\n",
      "2019-04-09 20:45:23,207 root         INFO     Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 0.080178\n",
      "Reconstruction: 0.047658, Regularization: 0.000072, Discriminator: 0.021614; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,275 root         INFO     Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 0.093085\n",
      "Reconstruction: 0.060546, Regularization: 0.000098, Discriminator: 0.021613; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,342 root         INFO     Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 0.097787\n",
      "Reconstruction: 0.065187, Regularization: 0.000109, Discriminator: 0.021666; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,410 root         INFO     Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 0.077228\n",
      "Reconstruction: 0.044633, Regularization: 0.000064, Discriminator: 0.021704; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,477 root         INFO     Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 0.076555\n",
      "Reconstruction: 0.044053, Regularization: 0.000063, Discriminator: 0.021605; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,544 root         INFO     Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 0.082795\n",
      "Reconstruction: 0.050265, Regularization: 0.000076, Discriminator: 0.021615; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,611 root         INFO     Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 0.074443\n",
      "Reconstruction: 0.041872, Regularization: 0.000057, Discriminator: 0.021667; Generator: 0.010847,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 20:45:23,679 root         INFO     Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 0.080476\n",
      "Reconstruction: 0.047932, Regularization: 0.000071, Discriminator: 0.021645; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,747 root         INFO     ====> Epoch: 110 Average loss: 0.0851\n",
      "2019-04-09 20:45:23,771 root         INFO     Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 0.086454\n",
      "Reconstruction: 0.053827, Regularization: 0.000084, Discriminator: 0.021705; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,836 root         INFO     Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 0.074254\n",
      "Reconstruction: 0.041698, Regularization: 0.000058, Discriminator: 0.021662; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,903 root         INFO     Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 0.097822\n",
      "Reconstruction: 0.065206, Regularization: 0.000106, Discriminator: 0.021673; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,972 root         INFO     Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 0.076932\n",
      "Reconstruction: 0.044401, Regularization: 0.000063, Discriminator: 0.021638; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,042 root         INFO     Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 0.076744\n",
      "Reconstruction: 0.044157, Regularization: 0.000061, Discriminator: 0.021690; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,110 root         INFO     Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 0.096091\n",
      "Reconstruction: 0.063559, Regularization: 0.000100, Discriminator: 0.021601; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,179 root         INFO     Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 0.090498\n",
      "Reconstruction: 0.057971, Regularization: 0.000090, Discriminator: 0.021602; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,248 root         INFO     Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 0.083044\n",
      "Reconstruction: 0.050475, Regularization: 0.000074, Discriminator: 0.021658; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,317 root         INFO     ====> Epoch: 111 Average loss: 0.0851\n",
      "2019-04-09 20:45:24,341 root         INFO     Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 0.073913\n",
      "Reconstruction: 0.041379, Regularization: 0.000056, Discriminator: 0.021639; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,410 root         INFO     Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 0.074738\n",
      "Reconstruction: 0.042192, Regularization: 0.000057, Discriminator: 0.021656; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,477 root         INFO     Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 0.084236\n",
      "Reconstruction: 0.051609, Regularization: 0.000077, Discriminator: 0.021716; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,544 root         INFO     Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 0.082808\n",
      "Reconstruction: 0.050245, Regularization: 0.000077, Discriminator: 0.021648; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,612 root         INFO     Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 0.086438\n",
      "Reconstruction: 0.053953, Regularization: 0.000082, Discriminator: 0.021574; Generator: 0.010828,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,679 root         INFO     Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 0.086997\n",
      "Reconstruction: 0.054436, Regularization: 0.000085, Discriminator: 0.021647; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,747 root         INFO     Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 0.078640\n",
      "Reconstruction: 0.046140, Regularization: 0.000068, Discriminator: 0.021599; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,814 root         INFO     Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 0.093897\n",
      "Reconstruction: 0.061251, Regularization: 0.000099, Discriminator: 0.021714; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,882 root         INFO     ====> Epoch: 112 Average loss: 0.0851\n",
      "2019-04-09 20:45:24,906 root         INFO     Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 0.088386\n",
      "Reconstruction: 0.055833, Regularization: 0.000087, Discriminator: 0.021629; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,973 root         INFO     Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 0.092648\n",
      "Reconstruction: 0.060061, Regularization: 0.000095, Discriminator: 0.021648; Generator: 0.010845,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,039 root         INFO     Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 0.094068\n",
      "Reconstruction: 0.061458, Regularization: 0.000101, Discriminator: 0.021663; Generator: 0.010847,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 20:45:25,103 root         INFO     Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 0.088837\n",
      "Reconstruction: 0.056183, Regularization: 0.000091, Discriminator: 0.021721; Generator: 0.010842,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,167 root         INFO     Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 0.083475\n",
      "Reconstruction: 0.050933, Regularization: 0.000079, Discriminator: 0.021629; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,231 root         INFO     Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 0.085300\n",
      "Reconstruction: 0.052791, Regularization: 0.000084, Discriminator: 0.021599; Generator: 0.010826,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,296 root         INFO     Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 0.079659\n",
      "Reconstruction: 0.047014, Regularization: 0.000071, Discriminator: 0.021743; Generator: 0.010831,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,363 root         INFO     Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 0.081897\n",
      "Reconstruction: 0.049325, Regularization: 0.000077, Discriminator: 0.021669; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,432 root         INFO     ====> Epoch: 113 Average loss: 0.0851\n",
      "2019-04-09 20:45:25,456 root         INFO     Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 0.081474\n",
      "Reconstruction: 0.048983, Regularization: 0.000076, Discriminator: 0.021586; Generator: 0.010829,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,525 root         INFO     Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 0.079564\n",
      "Reconstruction: 0.047055, Regularization: 0.000072, Discriminator: 0.021613; Generator: 0.010824,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,592 root         INFO     Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 0.093336\n",
      "Reconstruction: 0.060756, Regularization: 0.000104, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,660 root         INFO     Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 0.104657\n",
      "Reconstruction: 0.072043, Regularization: 0.000129, Discriminator: 0.021660; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,727 root         INFO     Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 0.090203\n",
      "Reconstruction: 0.057650, Regularization: 0.000096, Discriminator: 0.021632; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,793 root         INFO     Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 0.089419\n",
      "Reconstruction: 0.056882, Regularization: 0.000091, Discriminator: 0.021615; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,859 root         INFO     Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 0.089577\n",
      "Reconstruction: 0.057074, Regularization: 0.000093, Discriminator: 0.021575; Generator: 0.010835,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,924 root         INFO     Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 0.084971\n",
      "Reconstruction: 0.052400, Regularization: 0.000082, Discriminator: 0.021648; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,992 root         INFO     ====> Epoch: 114 Average loss: 0.0851\n",
      "2019-04-09 20:45:26,016 root         INFO     Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 0.095851\n",
      "Reconstruction: 0.063252, Regularization: 0.000108, Discriminator: 0.021652; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,083 root         INFO     Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 0.073683\n",
      "Reconstruction: 0.041134, Regularization: 0.000061, Discriminator: 0.021645; Generator: 0.010843,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,150 root         INFO     Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 0.091761\n",
      "Reconstruction: 0.059105, Regularization: 0.000097, Discriminator: 0.021720; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,216 root         INFO     Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 0.074420\n",
      "Reconstruction: 0.041830, Regularization: 0.000060, Discriminator: 0.021699; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,282 root         INFO     Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 0.089032\n",
      "Reconstruction: 0.056428, Regularization: 0.000090, Discriminator: 0.021688; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,348 root         INFO     Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 0.093184\n",
      "Reconstruction: 0.060615, Regularization: 0.000102, Discriminator: 0.021635; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,414 root         INFO     Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 0.086328\n",
      "Reconstruction: 0.053767, Regularization: 0.000084, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,480 root         INFO     Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 0.086285\n",
      "Reconstruction: 0.053698, Regularization: 0.000087, Discriminator: 0.021667; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,547 root         INFO     ====> Epoch: 115 Average loss: 0.0851\n",
      "2019-04-09 20:45:26,571 root         INFO     Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 0.084705\n",
      "Reconstruction: 0.052130, Regularization: 0.000084, Discriminator: 0.021654; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,637 root         INFO     Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 0.083999\n",
      "Reconstruction: 0.051447, Regularization: 0.000080, Discriminator: 0.021634; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,703 root         INFO     Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 0.084696\n",
      "Reconstruction: 0.052081, Regularization: 0.000081, Discriminator: 0.021700; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,769 root         INFO     Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 0.104161\n",
      "Reconstruction: 0.071453, Regularization: 0.000122, Discriminator: 0.021753; Generator: 0.010833,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,835 root         INFO     Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 0.082548\n",
      "Reconstruction: 0.049976, Regularization: 0.000074, Discriminator: 0.021678; Generator: 0.010820,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,901 root         INFO     Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 0.089526\n",
      "Reconstruction: 0.056969, Regularization: 0.000091, Discriminator: 0.021639; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,967 root         INFO     Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 0.081131\n",
      "Reconstruction: 0.048535, Regularization: 0.000073, Discriminator: 0.021687; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,033 root         INFO     Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 0.075035\n",
      "Reconstruction: 0.042459, Regularization: 0.000062, Discriminator: 0.021677; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,101 root         INFO     ====> Epoch: 116 Average loss: 0.0851\n",
      "2019-04-09 20:45:27,125 root         INFO     Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 0.085593\n",
      "Reconstruction: 0.053015, Regularization: 0.000085, Discriminator: 0.021651; Generator: 0.010843,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,189 root         INFO     Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 0.082401\n",
      "Reconstruction: 0.049796, Regularization: 0.000080, Discriminator: 0.021690; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,253 root         INFO     Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 0.086636\n",
      "Reconstruction: 0.054103, Regularization: 0.000088, Discriminator: 0.021610; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,316 root         INFO     Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 0.087764\n",
      "Reconstruction: 0.055212, Regularization: 0.000092, Discriminator: 0.021621; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,379 root         INFO     Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 0.101278\n",
      "Reconstruction: 0.068712, Regularization: 0.000120, Discriminator: 0.021606; Generator: 0.010841,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,444 root         INFO     Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 0.075344\n",
      "Reconstruction: 0.042819, Regularization: 0.000063, Discriminator: 0.021633; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,510 root         INFO     Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 0.087499\n",
      "Reconstruction: 0.054993, Regularization: 0.000091, Discriminator: 0.021584; Generator: 0.010830,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,576 root         INFO     Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 0.088304\n",
      "Reconstruction: 0.055778, Regularization: 0.000094, Discriminator: 0.021603; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,644 root         INFO     ====> Epoch: 117 Average loss: 0.0851\n",
      "2019-04-09 20:45:27,668 root         INFO     Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 0.076508\n",
      "Reconstruction: 0.043917, Regularization: 0.000065, Discriminator: 0.021690; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,735 root         INFO     Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 0.082556\n",
      "Reconstruction: 0.049989, Regularization: 0.000079, Discriminator: 0.021656; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,801 root         INFO     Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 0.080194\n",
      "Reconstruction: 0.047580, Regularization: 0.000073, Discriminator: 0.021705; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,868 root         INFO     Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 0.079842\n",
      "Reconstruction: 0.047325, Regularization: 0.000072, Discriminator: 0.021615; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,935 root         INFO     Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 0.095633\n",
      "Reconstruction: 0.062990, Regularization: 0.000107, Discriminator: 0.021713; Generator: 0.010824,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,003 root         INFO     Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 0.080691\n",
      "Reconstruction: 0.048135, Regularization: 0.000073, Discriminator: 0.021645; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,071 root         INFO     Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 0.080429\n",
      "Reconstruction: 0.047892, Regularization: 0.000074, Discriminator: 0.021627; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,136 root         INFO     Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 0.093963\n",
      "Reconstruction: 0.061417, Regularization: 0.000103, Discriminator: 0.021609; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,204 root         INFO     ====> Epoch: 118 Average loss: 0.0851\n",
      "2019-04-09 20:45:28,228 root         INFO     Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 0.073633\n",
      "Reconstruction: 0.041098, Regularization: 0.000058, Discriminator: 0.021636; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,295 root         INFO     Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 0.092397\n",
      "Reconstruction: 0.059781, Regularization: 0.000099, Discriminator: 0.021688; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,362 root         INFO     Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 0.081177\n",
      "Reconstruction: 0.048583, Regularization: 0.000076, Discriminator: 0.021685; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,429 root         INFO     Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 0.092522\n",
      "Reconstruction: 0.059914, Regularization: 0.000104, Discriminator: 0.021671; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,496 root         INFO     Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 0.083574\n",
      "Reconstruction: 0.050989, Regularization: 0.000085, Discriminator: 0.021668; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,563 root         INFO     Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 0.084156\n",
      "Reconstruction: 0.051458, Regularization: 0.000085, Discriminator: 0.021771; Generator: 0.010842,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,630 root         INFO     Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 0.076971\n",
      "Reconstruction: 0.044455, Regularization: 0.000067, Discriminator: 0.021617; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,695 root         INFO     Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 0.080169\n",
      "Reconstruction: 0.047656, Regularization: 0.000077, Discriminator: 0.021606; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,763 root         INFO     ====> Epoch: 119 Average loss: 0.0851\n",
      "2019-04-09 20:45:28,787 root         INFO     Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 0.085101\n",
      "Reconstruction: 0.052462, Regularization: 0.000088, Discriminator: 0.021710; Generator: 0.010841,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,855 root         INFO     Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 0.086335\n",
      "Reconstruction: 0.053732, Regularization: 0.000092, Discriminator: 0.021670; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,922 root         INFO     Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 0.093781\n",
      "Reconstruction: 0.061180, Regularization: 0.000109, Discriminator: 0.021646; Generator: 0.010845,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,988 root         INFO     Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 0.098536\n",
      "Reconstruction: 0.065824, Regularization: 0.000119, Discriminator: 0.021758; Generator: 0.010834,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,055 root         INFO     Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 0.105741\n",
      "Reconstruction: 0.073069, Regularization: 0.000137, Discriminator: 0.021703; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,123 root         INFO     Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 0.085542\n",
      "Reconstruction: 0.052951, Regularization: 0.000091, Discriminator: 0.021669; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,189 root         INFO     Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 0.079086\n",
      "Reconstruction: 0.046574, Regularization: 0.000076, Discriminator: 0.021610; Generator: 0.010825,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,252 root         INFO     Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 0.087194\n",
      "Reconstruction: 0.054611, Regularization: 0.000093, Discriminator: 0.021652; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,317 root         INFO     ====> Epoch: 120 Average loss: 0.0851\n",
      "2019-04-09 20:45:29,341 root         INFO     Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 0.079950\n",
      "Reconstruction: 0.047325, Regularization: 0.000076, Discriminator: 0.021715; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,407 root         INFO     Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 0.077707\n",
      "Reconstruction: 0.045185, Regularization: 0.000071, Discriminator: 0.021622; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,472 root         INFO     Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 0.077219\n",
      "Reconstruction: 0.044660, Regularization: 0.000069, Discriminator: 0.021652; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,537 root         INFO     Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 0.076212\n",
      "Reconstruction: 0.043637, Regularization: 0.000066, Discriminator: 0.021674; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,601 root         INFO     Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 0.082052\n",
      "Reconstruction: 0.049479, Regularization: 0.000081, Discriminator: 0.021662; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,665 root         INFO     Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 0.090452\n",
      "Reconstruction: 0.057856, Regularization: 0.000100, Discriminator: 0.021675; Generator: 0.010820,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,728 root         INFO     Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 0.086473\n",
      "Reconstruction: 0.053854, Regularization: 0.000091, Discriminator: 0.021687; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,792 root         INFO     Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 0.074593\n",
      "Reconstruction: 0.041961, Regularization: 0.000062, Discriminator: 0.021735; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,858 root         INFO     ====> Epoch: 121 Average loss: 0.0851\n",
      "2019-04-09 20:45:29,882 root         INFO     Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 0.077991\n",
      "Reconstruction: 0.045411, Regularization: 0.000070, Discriminator: 0.021668; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,948 root         INFO     Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 0.083540\n",
      "Reconstruction: 0.051027, Regularization: 0.000082, Discriminator: 0.021596; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,015 root         INFO     Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 0.085470\n",
      "Reconstruction: 0.052898, Regularization: 0.000085, Discriminator: 0.021645; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,082 root         INFO     Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 0.089385\n",
      "Reconstruction: 0.056871, Regularization: 0.000092, Discriminator: 0.021590; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,148 root         INFO     Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 0.070504\n",
      "Reconstruction: 0.037909, Regularization: 0.000051, Discriminator: 0.021702; Generator: 0.010842,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,215 root         INFO     Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 0.084566\n",
      "Reconstruction: 0.052054, Regularization: 0.000085, Discriminator: 0.021581; Generator: 0.010847,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 20:45:30,282 root         INFO     Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 0.086298\n",
      "Reconstruction: 0.053695, Regularization: 0.000088, Discriminator: 0.021682; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,349 root         INFO     Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 0.077893\n",
      "Reconstruction: 0.045289, Regularization: 0.000067, Discriminator: 0.021711; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,414 root         INFO     ====> Epoch: 122 Average loss: 0.0851\n",
      "2019-04-09 20:45:30,438 root         INFO     Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 0.069855\n",
      "Reconstruction: 0.037364, Regularization: 0.000050, Discriminator: 0.021617; Generator: 0.010825,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,506 root         INFO     Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 0.094588\n",
      "Reconstruction: 0.061997, Regularization: 0.000103, Discriminator: 0.021652; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,572 root         INFO     Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 0.096038\n",
      "Reconstruction: 0.063368, Regularization: 0.000105, Discriminator: 0.021735; Generator: 0.010829,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,639 root         INFO     Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 0.092427\n",
      "Reconstruction: 0.059874, Regularization: 0.000098, Discriminator: 0.021621; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,705 root         INFO     Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 0.077753\n",
      "Reconstruction: 0.045096, Regularization: 0.000068, Discriminator: 0.021742; Generator: 0.010848,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 20:45:30,772 root         INFO     Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 0.081433\n",
      "Reconstruction: 0.048896, Regularization: 0.000075, Discriminator: 0.021628; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,839 root         INFO     Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 0.075769\n",
      "Reconstruction: 0.043229, Regularization: 0.000063, Discriminator: 0.021649; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,905 root         INFO     Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 0.075875\n",
      "Reconstruction: 0.043277, Regularization: 0.000064, Discriminator: 0.021702; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,972 root         INFO     ====> Epoch: 123 Average loss: 0.0851\n",
      "2019-04-09 20:45:30,996 root         INFO     Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 0.091336\n",
      "Reconstruction: 0.058684, Regularization: 0.000098, Discriminator: 0.021726; Generator: 0.010828,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,061 root         INFO     Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 0.081767\n",
      "Reconstruction: 0.049187, Regularization: 0.000077, Discriminator: 0.021662; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,125 root         INFO     Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 0.106019\n",
      "Reconstruction: 0.073441, Regularization: 0.000129, Discriminator: 0.021615; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,188 root         INFO     Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 0.085717\n",
      "Reconstruction: 0.053117, Regularization: 0.000085, Discriminator: 0.021682; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,251 root         INFO     Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 0.098606\n",
      "Reconstruction: 0.066000, Regularization: 0.000114, Discriminator: 0.021667; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,315 root         INFO     Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 0.094963\n",
      "Reconstruction: 0.062369, Regularization: 0.000106, Discriminator: 0.021656; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,378 root         INFO     Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 0.078847\n",
      "Reconstruction: 0.046273, Regularization: 0.000071, Discriminator: 0.021665; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,443 root         INFO     Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 0.095151\n",
      "Reconstruction: 0.062558, Regularization: 0.000106, Discriminator: 0.021650; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,510 root         INFO     ====> Epoch: 124 Average loss: 0.0851\n",
      "2019-04-09 20:45:31,534 root         INFO     Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 0.084577\n",
      "Reconstruction: 0.052083, Regularization: 0.000081, Discriminator: 0.021575; Generator: 0.010837,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,602 root         INFO     Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 0.086856\n",
      "Reconstruction: 0.054314, Regularization: 0.000087, Discriminator: 0.021627; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,669 root         INFO     Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 0.098319\n",
      "Reconstruction: 0.065702, Regularization: 0.000110, Discriminator: 0.021672; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,736 root         INFO     Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 0.094921\n",
      "Reconstruction: 0.062346, Regularization: 0.000103, Discriminator: 0.021627; Generator: 0.010845,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,804 root         INFO     Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 0.101759\n",
      "Reconstruction: 0.069231, Regularization: 0.000120, Discriminator: 0.021567; Generator: 0.010841,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,871 root         INFO     Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 0.073297\n",
      "Reconstruction: 0.040740, Regularization: 0.000057, Discriminator: 0.021663; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,939 root         INFO     Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 0.101854\n",
      "Reconstruction: 0.069185, Regularization: 0.000116, Discriminator: 0.021722; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,004 root         INFO     Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 0.073807\n",
      "Reconstruction: 0.041285, Regularization: 0.000058, Discriminator: 0.021634; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,071 root         INFO     ====> Epoch: 125 Average loss: 0.0851\n",
      "2019-04-09 20:45:32,095 root         INFO     Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 0.082297\n",
      "Reconstruction: 0.049751, Regularization: 0.000076, Discriminator: 0.021644; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,162 root         INFO     Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 0.088459\n",
      "Reconstruction: 0.055949, Regularization: 0.000088, Discriminator: 0.021587; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,228 root         INFO     Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 0.087263\n",
      "Reconstruction: 0.054670, Regularization: 0.000086, Discriminator: 0.021661; Generator: 0.010847,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 20:45:32,295 root         INFO     Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 0.095133\n",
      "Reconstruction: 0.062531, Regularization: 0.000101, Discriminator: 0.021655; Generator: 0.010846,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 20:45:32,363 root         INFO     Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 0.077142\n",
      "Reconstruction: 0.044491, Regularization: 0.000062, Discriminator: 0.021752; Generator: 0.010837,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,431 root         INFO     Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 0.077453\n",
      "Reconstruction: 0.044850, Regularization: 0.000065, Discriminator: 0.021710; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,500 root         INFO     Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 0.089166\n",
      "Reconstruction: 0.056628, Regularization: 0.000090, Discriminator: 0.021628; Generator: 0.010819,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,569 root         INFO     Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 0.081687\n",
      "Reconstruction: 0.049150, Regularization: 0.000076, Discriminator: 0.021639; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,638 root         INFO     ====> Epoch: 126 Average loss: 0.0850\n",
      "2019-04-09 20:45:32,662 root         INFO     Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 0.082782\n",
      "Reconstruction: 0.050212, Regularization: 0.000077, Discriminator: 0.021658; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,730 root         INFO     Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 0.078655\n",
      "Reconstruction: 0.046062, Regularization: 0.000066, Discriminator: 0.021691; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,797 root         INFO     Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 0.086058\n",
      "Reconstruction: 0.053472, Regularization: 0.000080, Discriminator: 0.021670; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,863 root         INFO     Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 0.092481\n",
      "Reconstruction: 0.059877, Regularization: 0.000092, Discriminator: 0.021681; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,927 root         INFO     Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 0.074828\n",
      "Reconstruction: 0.042314, Regularization: 0.000057, Discriminator: 0.021628; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,994 root         INFO     Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 0.072543\n",
      "Reconstruction: 0.039947, Regularization: 0.000051, Discriminator: 0.021710; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,061 root         INFO     Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 0.084393\n",
      "Reconstruction: 0.051813, Regularization: 0.000076, Discriminator: 0.021670; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,126 root         INFO     Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 0.097719\n",
      "Reconstruction: 0.065156, Regularization: 0.000104, Discriminator: 0.021626; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,193 root         INFO     ====> Epoch: 127 Average loss: 0.0851\n",
      "2019-04-09 20:45:33,218 root         INFO     Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 0.085411\n",
      "Reconstruction: 0.052873, Regularization: 0.000081, Discriminator: 0.021625; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,285 root         INFO     Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 0.098766\n",
      "Reconstruction: 0.066137, Regularization: 0.000106, Discriminator: 0.021685; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,351 root         INFO     Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 0.079742\n",
      "Reconstruction: 0.047219, Regularization: 0.000068, Discriminator: 0.021627; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,416 root         INFO     Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 0.076771\n",
      "Reconstruction: 0.044289, Regularization: 0.000061, Discriminator: 0.021587; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,483 root         INFO     Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 0.082289\n",
      "Reconstruction: 0.049727, Regularization: 0.000070, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,548 root         INFO     Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 0.083444\n",
      "Reconstruction: 0.050907, Regularization: 0.000074, Discriminator: 0.021635; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,614 root         INFO     Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 0.090057\n",
      "Reconstruction: 0.057529, Regularization: 0.000086, Discriminator: 0.021607; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,681 root         INFO     Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 0.073669\n",
      "Reconstruction: 0.041066, Regularization: 0.000053, Discriminator: 0.021713; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,749 root         INFO     ====> Epoch: 128 Average loss: 0.0851\n",
      "2019-04-09 20:45:33,773 root         INFO     Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 0.084000\n",
      "Reconstruction: 0.051442, Regularization: 0.000073, Discriminator: 0.021650; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,841 root         INFO     Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 0.082122\n",
      "Reconstruction: 0.049511, Regularization: 0.000068, Discriminator: 0.021714; Generator: 0.010829,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,908 root         INFO     Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 0.081771\n",
      "Reconstruction: 0.049232, Regularization: 0.000071, Discriminator: 0.021635; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,975 root         INFO     Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 0.080350\n",
      "Reconstruction: 0.047825, Regularization: 0.000068, Discriminator: 0.021620; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,041 root         INFO     Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 0.074696\n",
      "Reconstruction: 0.042149, Regularization: 0.000056, Discriminator: 0.021660; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,108 root         INFO     Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 0.093945\n",
      "Reconstruction: 0.061406, Regularization: 0.000098, Discriminator: 0.021617; Generator: 0.010824,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,175 root         INFO     Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 0.086316\n",
      "Reconstruction: 0.053766, Regularization: 0.000080, Discriminator: 0.021633; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,242 root         INFO     Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 0.084218\n",
      "Reconstruction: 0.051684, Regularization: 0.000074, Discriminator: 0.021611; Generator: 0.010849,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 20:45:34,310 root         INFO     ====> Epoch: 129 Average loss: 0.0851\n",
      "2019-04-09 20:45:34,333 root         INFO     Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 0.083186\n",
      "Reconstruction: 0.050620, Regularization: 0.000072, Discriminator: 0.021659; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,400 root         INFO     Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 0.085193\n",
      "Reconstruction: 0.052613, Regularization: 0.000074, Discriminator: 0.021678; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,466 root         INFO     Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 0.095453\n",
      "Reconstruction: 0.062895, Regularization: 0.000093, Discriminator: 0.021625; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,532 root         INFO     Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 0.086832\n",
      "Reconstruction: 0.054238, Regularization: 0.000077, Discriminator: 0.021679; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,598 root         INFO     Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 0.092979\n",
      "Reconstruction: 0.060440, Regularization: 0.000091, Discriminator: 0.021617; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,664 root         INFO     Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 0.093424\n",
      "Reconstruction: 0.060806, Regularization: 0.000090, Discriminator: 0.021695; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,730 root         INFO     Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 0.081397\n",
      "Reconstruction: 0.048854, Regularization: 0.000068, Discriminator: 0.021645; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,796 root         INFO     Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 0.090584\n",
      "Reconstruction: 0.058019, Regularization: 0.000084, Discriminator: 0.021642; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,863 root         INFO     ====> Epoch: 130 Average loss: 0.0851\n",
      "2019-04-09 20:45:34,887 root         INFO     Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 0.086498\n",
      "Reconstruction: 0.053882, Regularization: 0.000076, Discriminator: 0.021705; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,950 root         INFO     Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 0.085597\n",
      "Reconstruction: 0.053031, Regularization: 0.000076, Discriminator: 0.021658; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,013 root         INFO     Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 0.085637\n",
      "Reconstruction: 0.053111, Regularization: 0.000075, Discriminator: 0.021621; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,076 root         INFO     Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 0.075163\n",
      "Reconstruction: 0.042623, Regularization: 0.000055, Discriminator: 0.021640; Generator: 0.010844,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,139 root         INFO     Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 0.078670\n",
      "Reconstruction: 0.046203, Regularization: 0.000061, Discriminator: 0.021569; Generator: 0.010837,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,202 root         INFO     Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 0.090987\n",
      "Reconstruction: 0.058391, Regularization: 0.000088, Discriminator: 0.021680; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,265 root         INFO     Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 0.080301\n",
      "Reconstruction: 0.047715, Regularization: 0.000067, Discriminator: 0.021688; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,328 root         INFO     Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 0.091659\n",
      "Reconstruction: 0.059068, Regularization: 0.000089, Discriminator: 0.021665; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,393 root         INFO     ====> Epoch: 131 Average loss: 0.0851\n",
      "2019-04-09 20:45:35,417 root         INFO     Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 0.089607\n",
      "Reconstruction: 0.057044, Regularization: 0.000085, Discriminator: 0.021645; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,483 root         INFO     Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 0.084208\n",
      "Reconstruction: 0.051581, Regularization: 0.000073, Discriminator: 0.021716; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,549 root         INFO     Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 0.080508\n",
      "Reconstruction: 0.047972, Regularization: 0.000066, Discriminator: 0.021637; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,615 root         INFO     Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 0.076197\n",
      "Reconstruction: 0.043629, Regularization: 0.000057, Discriminator: 0.021681; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,681 root         INFO     Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 0.081815\n",
      "Reconstruction: 0.049262, Regularization: 0.000070, Discriminator: 0.021658; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,748 root         INFO     Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 0.079610\n",
      "Reconstruction: 0.047088, Regularization: 0.000066, Discriminator: 0.021632; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,815 root         INFO     Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 0.092103\n",
      "Reconstruction: 0.059400, Regularization: 0.000091, Discriminator: 0.021775; Generator: 0.010837,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,880 root         INFO     Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 0.090378\n",
      "Reconstruction: 0.057781, Regularization: 0.000090, Discriminator: 0.021672; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,947 root         INFO     ====> Epoch: 132 Average loss: 0.0851\n",
      "2019-04-09 20:45:35,971 root         INFO     Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 0.078635\n",
      "Reconstruction: 0.046023, Regularization: 0.000065, Discriminator: 0.021707; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,035 root         INFO     Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 0.075107\n",
      "Reconstruction: 0.042587, Regularization: 0.000058, Discriminator: 0.021630; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,098 root         INFO     Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 0.095960\n",
      "Reconstruction: 0.063384, Regularization: 0.000102, Discriminator: 0.021641; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,161 root         INFO     Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 0.088319\n",
      "Reconstruction: 0.055717, Regularization: 0.000084, Discriminator: 0.021685; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,224 root         INFO     Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 0.076738\n",
      "Reconstruction: 0.044201, Regularization: 0.000061, Discriminator: 0.021638; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,286 root         INFO     Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 0.082278\n",
      "Reconstruction: 0.049806, Regularization: 0.000071, Discriminator: 0.021571; Generator: 0.010830,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,349 root         INFO     Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 0.090979\n",
      "Reconstruction: 0.058498, Regularization: 0.000090, Discriminator: 0.021563; Generator: 0.010827,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,412 root         INFO     Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 0.081215\n",
      "Reconstruction: 0.048601, Regularization: 0.000071, Discriminator: 0.021701; Generator: 0.010842,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,478 root         INFO     ====> Epoch: 133 Average loss: 0.0851\n",
      "2019-04-09 20:45:36,502 root         INFO     Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 0.078019\n",
      "Reconstruction: 0.045453, Regularization: 0.000062, Discriminator: 0.021667; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,565 root         INFO     Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 0.090460\n",
      "Reconstruction: 0.057837, Regularization: 0.000089, Discriminator: 0.021694; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,628 root         INFO     Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 0.084862\n",
      "Reconstruction: 0.052281, Regularization: 0.000078, Discriminator: 0.021669; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,691 root         INFO     Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 0.087005\n",
      "Reconstruction: 0.054484, Regularization: 0.000082, Discriminator: 0.021601; Generator: 0.010838,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,753 root         INFO     Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 0.090878\n",
      "Reconstruction: 0.058303, Regularization: 0.000087, Discriminator: 0.021658; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,816 root         INFO     Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 0.090921\n",
      "Reconstruction: 0.058337, Regularization: 0.000087, Discriminator: 0.021663; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,879 root         INFO     Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 0.081256\n",
      "Reconstruction: 0.048629, Regularization: 0.000068, Discriminator: 0.021725; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,942 root         INFO     Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 0.086964\n",
      "Reconstruction: 0.054468, Regularization: 0.000077, Discriminator: 0.021587; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,007 root         INFO     ====> Epoch: 134 Average loss: 0.0851\n",
      "2019-04-09 20:45:37,031 root         INFO     Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 0.084676\n",
      "Reconstruction: 0.052080, Regularization: 0.000071, Discriminator: 0.021686; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,097 root         INFO     Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 0.091805\n",
      "Reconstruction: 0.059183, Regularization: 0.000088, Discriminator: 0.021706; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,163 root         INFO     Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 0.091840\n",
      "Reconstruction: 0.059214, Regularization: 0.000085, Discriminator: 0.021702; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,226 root         INFO     Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 0.083093\n",
      "Reconstruction: 0.050451, Regularization: 0.000068, Discriminator: 0.021739; Generator: 0.010834,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,288 root         INFO     Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 0.080511\n",
      "Reconstruction: 0.047931, Regularization: 0.000061, Discriminator: 0.021687; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,351 root         INFO     Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 0.087687\n",
      "Reconstruction: 0.055185, Regularization: 0.000073, Discriminator: 0.021598; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,414 root         INFO     Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 0.083614\n",
      "Reconstruction: 0.050983, Regularization: 0.000067, Discriminator: 0.021718; Generator: 0.010847,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 20:45:37,477 root         INFO     Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 0.086037\n",
      "Reconstruction: 0.053530, Regularization: 0.000074, Discriminator: 0.021599; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,541 root         INFO     ====> Epoch: 135 Average loss: 0.0851\n",
      "2019-04-09 20:45:37,565 root         INFO     Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 0.084930\n",
      "Reconstruction: 0.052398, Regularization: 0.000071, Discriminator: 0.021626; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,629 root         INFO     Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 0.083961\n",
      "Reconstruction: 0.051438, Regularization: 0.000067, Discriminator: 0.021617; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,692 root         INFO     Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 0.082394\n",
      "Reconstruction: 0.049893, Regularization: 0.000063, Discriminator: 0.021605; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,756 root         INFO     Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 0.093949\n",
      "Reconstruction: 0.061341, Regularization: 0.000086, Discriminator: 0.021683; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,820 root         INFO     Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 0.092111\n",
      "Reconstruction: 0.059622, Regularization: 0.000084, Discriminator: 0.021572; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,883 root         INFO     Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 0.081860\n",
      "Reconstruction: 0.049336, Regularization: 0.000065, Discriminator: 0.021627; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,947 root         INFO     Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 0.084752\n",
      "Reconstruction: 0.052210, Regularization: 0.000070, Discriminator: 0.021639; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,011 root         INFO     Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 0.088378\n",
      "Reconstruction: 0.055785, Regularization: 0.000078, Discriminator: 0.021688; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,077 root         INFO     ====> Epoch: 136 Average loss: 0.0851\n",
      "2019-04-09 20:45:38,100 root         INFO     Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 0.089271\n",
      "Reconstruction: 0.056665, Regularization: 0.000078, Discriminator: 0.021697; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,167 root         INFO     Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 0.091188\n",
      "Reconstruction: 0.058604, Regularization: 0.000082, Discriminator: 0.021667; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,234 root         INFO     Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 0.086015\n",
      "Reconstruction: 0.053523, Regularization: 0.000072, Discriminator: 0.021576; Generator: 0.010844,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,300 root         INFO     Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 0.075211\n",
      "Reconstruction: 0.042712, Regularization: 0.000052, Discriminator: 0.021609; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,366 root         INFO     Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 0.088593\n",
      "Reconstruction: 0.056021, Regularization: 0.000076, Discriminator: 0.021662; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,432 root         INFO     Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 0.085937\n",
      "Reconstruction: 0.053404, Regularization: 0.000072, Discriminator: 0.021626; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,498 root         INFO     Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 0.091498\n",
      "Reconstruction: 0.058997, Regularization: 0.000082, Discriminator: 0.021582; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,564 root         INFO     Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 0.071646\n",
      "Reconstruction: 0.039085, Regularization: 0.000047, Discriminator: 0.021686; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,630 root         INFO     ====> Epoch: 137 Average loss: 0.0851\n",
      "2019-04-09 20:45:38,654 root         INFO     Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 0.086916\n",
      "Reconstruction: 0.054351, Regularization: 0.000074, Discriminator: 0.021667; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,720 root         INFO     Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 0.089448\n",
      "Reconstruction: 0.056934, Regularization: 0.000079, Discriminator: 0.021603; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,786 root         INFO     Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 0.090838\n",
      "Reconstruction: 0.058299, Regularization: 0.000082, Discriminator: 0.021622; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,852 root         INFO     Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 0.077320\n",
      "Reconstruction: 0.044786, Regularization: 0.000055, Discriminator: 0.021645; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,917 root         INFO     Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 0.088510\n",
      "Reconstruction: 0.055884, Regularization: 0.000074, Discriminator: 0.021721; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,982 root         INFO     Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 0.089837\n",
      "Reconstruction: 0.057233, Regularization: 0.000077, Discriminator: 0.021694; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,048 root         INFO     Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 0.096140\n",
      "Reconstruction: 0.063614, Regularization: 0.000087, Discriminator: 0.021606; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,113 root         INFO     Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 0.086006\n",
      "Reconstruction: 0.053502, Regularization: 0.000069, Discriminator: 0.021607; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,181 root         INFO     ====> Epoch: 138 Average loss: 0.0851\n",
      "2019-04-09 20:45:39,205 root         INFO     Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 0.088465\n",
      "Reconstruction: 0.055901, Regularization: 0.000072, Discriminator: 0.021656; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,271 root         INFO     Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 0.087874\n",
      "Reconstruction: 0.055288, Regularization: 0.000072, Discriminator: 0.021674; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,337 root         INFO     Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 0.081369\n",
      "Reconstruction: 0.048773, Regularization: 0.000060, Discriminator: 0.021693; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,403 root         INFO     Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 0.087824\n",
      "Reconstruction: 0.055311, Regularization: 0.000072, Discriminator: 0.021615; Generator: 0.010826,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,469 root         INFO     Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 0.080921\n",
      "Reconstruction: 0.048368, Regularization: 0.000060, Discriminator: 0.021651; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,535 root         INFO     Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 0.082827\n",
      "Reconstruction: 0.050327, Regularization: 0.000063, Discriminator: 0.021598; Generator: 0.010839,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,601 root         INFO     Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 0.088900\n",
      "Reconstruction: 0.056330, Regularization: 0.000076, Discriminator: 0.021665; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,667 root         INFO     Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 0.089702\n",
      "Reconstruction: 0.057039, Regularization: 0.000076, Discriminator: 0.021749; Generator: 0.010837,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,734 root         INFO     ====> Epoch: 139 Average loss: 0.0851\n",
      "2019-04-09 20:45:39,758 root         INFO     Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 0.081338\n",
      "Reconstruction: 0.048776, Regularization: 0.000060, Discriminator: 0.021680; Generator: 0.010823,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,824 root         INFO     Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 0.083556\n",
      "Reconstruction: 0.051030, Regularization: 0.000063, Discriminator: 0.021636; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,890 root         INFO     Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 0.082323\n",
      "Reconstruction: 0.049825, Regularization: 0.000061, Discriminator: 0.021604; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,956 root         INFO     Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 0.073824\n",
      "Reconstruction: 0.041230, Regularization: 0.000046, Discriminator: 0.021712; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,020 root         INFO     Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 0.083775\n",
      "Reconstruction: 0.051255, Regularization: 0.000063, Discriminator: 0.021631; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,084 root         INFO     Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 0.093313\n",
      "Reconstruction: 0.060731, Regularization: 0.000081, Discriminator: 0.021673; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,148 root         INFO     Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 0.084462\n",
      "Reconstruction: 0.051890, Regularization: 0.000064, Discriminator: 0.021681; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,212 root         INFO     Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 0.085756\n",
      "Reconstruction: 0.053218, Regularization: 0.000067, Discriminator: 0.021632; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,277 root         INFO     ====> Epoch: 140 Average loss: 0.0851\n",
      "2019-04-09 20:45:40,301 root         INFO     Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 0.088794\n",
      "Reconstruction: 0.056261, Regularization: 0.000072, Discriminator: 0.021622; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,368 root         INFO     Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 0.089567\n",
      "Reconstruction: 0.057023, Regularization: 0.000076, Discriminator: 0.021629; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,434 root         INFO     Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 0.081022\n",
      "Reconstruction: 0.048440, Regularization: 0.000063, Discriminator: 0.021688; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,500 root         INFO     Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 0.078848\n",
      "Reconstruction: 0.046271, Regularization: 0.000059, Discriminator: 0.021688; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,566 root         INFO     Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 0.084716\n",
      "Reconstruction: 0.052225, Regularization: 0.000070, Discriminator: 0.021591; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,632 root         INFO     Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 0.086632\n",
      "Reconstruction: 0.054067, Regularization: 0.000076, Discriminator: 0.021652; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,697 root         INFO     Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 0.084886\n",
      "Reconstruction: 0.052353, Regularization: 0.000073, Discriminator: 0.021622; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,763 root         INFO     Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 0.092137\n",
      "Reconstruction: 0.059527, Regularization: 0.000088, Discriminator: 0.021676; Generator: 0.010846,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,831 root         INFO     ====> Epoch: 141 Average loss: 0.0851\n",
      "2019-04-09 20:45:40,855 root         INFO     Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 0.089693\n",
      "Reconstruction: 0.057206, Regularization: 0.000084, Discriminator: 0.021571; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,925 root         INFO     Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 0.091422\n",
      "Reconstruction: 0.058854, Regularization: 0.000086, Discriminator: 0.021655; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,994 root         INFO     Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 0.086730\n",
      "Reconstruction: 0.054155, Regularization: 0.000078, Discriminator: 0.021664; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,063 root         INFO     Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 0.089171\n",
      "Reconstruction: 0.056565, Regularization: 0.000079, Discriminator: 0.021686; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,131 root         INFO     Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 0.086195\n",
      "Reconstruction: 0.053668, Regularization: 0.000072, Discriminator: 0.021615; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,200 root         INFO     Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 0.094986\n",
      "Reconstruction: 0.062417, Regularization: 0.000087, Discriminator: 0.021644; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,268 root         INFO     Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 0.107449\n",
      "Reconstruction: 0.074806, Regularization: 0.000106, Discriminator: 0.021706; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,336 root         INFO     Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 0.086526\n",
      "Reconstruction: 0.053960, Regularization: 0.000069, Discriminator: 0.021667; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,405 root         INFO     ====> Epoch: 142 Average loss: 0.0851\n",
      "2019-04-09 20:45:41,429 root         INFO     Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 0.093319\n",
      "Reconstruction: 0.060699, Regularization: 0.000084, Discriminator: 0.021704; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,497 root         INFO     Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 0.084797\n",
      "Reconstruction: 0.052166, Regularization: 0.000065, Discriminator: 0.021728; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,563 root         INFO     Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 0.091083\n",
      "Reconstruction: 0.058552, Regularization: 0.000076, Discriminator: 0.021629; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,629 root         INFO     Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 0.099203\n",
      "Reconstruction: 0.066727, Regularization: 0.000090, Discriminator: 0.021559; Generator: 0.010827,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,695 root         INFO     Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 0.081298\n",
      "Reconstruction: 0.048761, Regularization: 0.000060, Discriminator: 0.021639; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,762 root         INFO     Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 0.100148\n",
      "Reconstruction: 0.067587, Regularization: 0.000091, Discriminator: 0.021633; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,828 root         INFO     Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 0.079490\n",
      "Reconstruction: 0.046917, Regularization: 0.000054, Discriminator: 0.021676; Generator: 0.010843,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,894 root         INFO     Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 0.099575\n",
      "Reconstruction: 0.066945, Regularization: 0.000086, Discriminator: 0.021709; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,962 root         INFO     ====> Epoch: 143 Average loss: 0.0851\n",
      "2019-04-09 20:45:41,986 root         INFO     Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 0.102805\n",
      "Reconstruction: 0.070157, Regularization: 0.000092, Discriminator: 0.021726; Generator: 0.010829,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,054 root         INFO     Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 0.091351\n",
      "Reconstruction: 0.058725, Regularization: 0.000073, Discriminator: 0.021727; Generator: 0.010826,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,121 root         INFO     Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 0.098432\n",
      "Reconstruction: 0.065869, Regularization: 0.000087, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,187 root         INFO     Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 0.081161\n",
      "Reconstruction: 0.048637, Regularization: 0.000059, Discriminator: 0.021636; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,253 root         INFO     Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 0.083978\n",
      "Reconstruction: 0.051457, Regularization: 0.000066, Discriminator: 0.021637; Generator: 0.010819,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,318 root         INFO     Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 0.086992\n",
      "Reconstruction: 0.054466, Regularization: 0.000071, Discriminator: 0.021623; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,383 root         INFO     Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 0.077517\n",
      "Reconstruction: 0.044910, Regularization: 0.000054, Discriminator: 0.021714; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,449 root         INFO     Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 0.078171\n",
      "Reconstruction: 0.045657, Regularization: 0.000057, Discriminator: 0.021622; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,516 root         INFO     ====> Epoch: 144 Average loss: 0.0851\n",
      "2019-04-09 20:45:42,540 root         INFO     Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 0.078332\n",
      "Reconstruction: 0.045863, Regularization: 0.000056, Discriminator: 0.021571; Generator: 0.010842,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,609 root         INFO     Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 0.095756\n",
      "Reconstruction: 0.063256, Regularization: 0.000087, Discriminator: 0.021573; Generator: 0.010841,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,677 root         INFO     Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 0.082271\n",
      "Reconstruction: 0.049636, Regularization: 0.000060, Discriminator: 0.021733; Generator: 0.010843,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,746 root         INFO     Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 0.083599\n",
      "Reconstruction: 0.051130, Regularization: 0.000062, Discriminator: 0.021585; Generator: 0.010822,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,815 root         INFO     Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 0.080787\n",
      "Reconstruction: 0.048260, Regularization: 0.000056, Discriminator: 0.021640; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,884 root         INFO     Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 0.082378\n",
      "Reconstruction: 0.049832, Regularization: 0.000058, Discriminator: 0.021649; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,953 root         INFO     Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 0.077569\n",
      "Reconstruction: 0.044956, Regularization: 0.000050, Discriminator: 0.021719; Generator: 0.010844,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,022 root         INFO     Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 0.084742\n",
      "Reconstruction: 0.052181, Regularization: 0.000060, Discriminator: 0.021668; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,093 root         INFO     ====> Epoch: 145 Average loss: 0.0851\n",
      "2019-04-09 20:45:43,117 root         INFO     Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 0.079638\n",
      "Reconstruction: 0.047150, Regularization: 0.000052, Discriminator: 0.021610; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,183 root         INFO     Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 0.087664\n",
      "Reconstruction: 0.055122, Regularization: 0.000066, Discriminator: 0.021645; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,248 root         INFO     Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 0.083175\n",
      "Reconstruction: 0.050665, Regularization: 0.000061, Discriminator: 0.021626; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,312 root         INFO     Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 0.096120\n",
      "Reconstruction: 0.063596, Regularization: 0.000079, Discriminator: 0.021619; Generator: 0.010826,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,376 root         INFO     Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 0.084488\n",
      "Reconstruction: 0.051980, Regularization: 0.000062, Discriminator: 0.021618; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,440 root         INFO     Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 0.089985\n",
      "Reconstruction: 0.057497, Regularization: 0.000071, Discriminator: 0.021577; Generator: 0.010840,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,506 root         INFO     Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 0.081336\n",
      "Reconstruction: 0.048743, Regularization: 0.000057, Discriminator: 0.021698; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,570 root         INFO     Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 0.083799\n",
      "Reconstruction: 0.051212, Regularization: 0.000062, Discriminator: 0.021691; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,636 root         INFO     ====> Epoch: 146 Average loss: 0.0851\n",
      "2019-04-09 20:45:43,660 root         INFO     Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 0.080441\n",
      "Reconstruction: 0.047885, Regularization: 0.000056, Discriminator: 0.021663; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,727 root         INFO     Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 0.083600\n",
      "Reconstruction: 0.051090, Regularization: 0.000062, Discriminator: 0.021611; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,795 root         INFO     Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 0.090637\n",
      "Reconstruction: 0.058030, Regularization: 0.000076, Discriminator: 0.021693; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,862 root         INFO     Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 0.084506\n",
      "Reconstruction: 0.051987, Regularization: 0.000067, Discriminator: 0.021620; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,928 root         INFO     Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 0.089587\n",
      "Reconstruction: 0.057047, Regularization: 0.000075, Discriminator: 0.021637; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,995 root         INFO     Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 0.085419\n",
      "Reconstruction: 0.052809, Regularization: 0.000067, Discriminator: 0.021705; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,060 root         INFO     Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 0.085463\n",
      "Reconstruction: 0.052939, Regularization: 0.000066, Discriminator: 0.021620; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,124 root         INFO     Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 0.080671\n",
      "Reconstruction: 0.048157, Regularization: 0.000058, Discriminator: 0.021623; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,190 root         INFO     ====> Epoch: 147 Average loss: 0.0851\n",
      "2019-04-09 20:45:44,214 root         INFO     Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 0.082174\n",
      "Reconstruction: 0.049589, Regularization: 0.000062, Discriminator: 0.021686; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,280 root         INFO     Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 0.086347\n",
      "Reconstruction: 0.053795, Regularization: 0.000071, Discriminator: 0.021647; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,346 root         INFO     Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 0.080921\n",
      "Reconstruction: 0.048431, Regularization: 0.000060, Discriminator: 0.021586; Generator: 0.010844,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,412 root         INFO     Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 0.083506\n",
      "Reconstruction: 0.050984, Regularization: 0.000063, Discriminator: 0.021618; Generator: 0.010842,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,478 root         INFO     Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 0.092887\n",
      "Reconstruction: 0.060394, Regularization: 0.000080, Discriminator: 0.021581; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,543 root         INFO     Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 0.082787\n",
      "Reconstruction: 0.050218, Regularization: 0.000060, Discriminator: 0.021690; Generator: 0.010819,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,609 root         INFO     Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 0.083204\n",
      "Reconstruction: 0.050678, Regularization: 0.000059, Discriminator: 0.021641; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,674 root         INFO     Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 0.077842\n",
      "Reconstruction: 0.045269, Regularization: 0.000049, Discriminator: 0.021684; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,741 root         INFO     ====> Epoch: 148 Average loss: 0.0851\n",
      "2019-04-09 20:45:44,765 root         INFO     Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 0.083607\n",
      "Reconstruction: 0.051102, Regularization: 0.000060, Discriminator: 0.021604; Generator: 0.010841,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,832 root         INFO     Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 0.080099\n",
      "Reconstruction: 0.047536, Regularization: 0.000056, Discriminator: 0.021667; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,899 root         INFO     Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 0.088959\n",
      "Reconstruction: 0.056313, Regularization: 0.000069, Discriminator: 0.021735; Generator: 0.010842,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,966 root         INFO     Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 0.084656\n",
      "Reconstruction: 0.052072, Regularization: 0.000063, Discriminator: 0.021680; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,033 root         INFO     Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 0.089372\n",
      "Reconstruction: 0.056891, Regularization: 0.000071, Discriminator: 0.021571; Generator: 0.010838,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,100 root         INFO     Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 0.083990\n",
      "Reconstruction: 0.051472, Regularization: 0.000061, Discriminator: 0.021618; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,167 root         INFO     Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 0.075353\n",
      "Reconstruction: 0.042840, Regularization: 0.000047, Discriminator: 0.021629; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,234 root         INFO     Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 0.087149\n",
      "Reconstruction: 0.054581, Regularization: 0.000063, Discriminator: 0.021674; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,302 root         INFO     ====> Epoch: 149 Average loss: 0.0851\n",
      "2019-04-09 20:45:45,326 root         INFO     Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 0.082459\n",
      "Reconstruction: 0.049915, Regularization: 0.000055, Discriminator: 0.021670; Generator: 0.010819,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,392 root         INFO     Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 0.088249\n",
      "Reconstruction: 0.055736, Regularization: 0.000062, Discriminator: 0.021625; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,459 root         INFO     Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 0.087579\n",
      "Reconstruction: 0.055028, Regularization: 0.000060, Discriminator: 0.021650; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,525 root         INFO     Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 0.082958\n",
      "Reconstruction: 0.050408, Regularization: 0.000052, Discriminator: 0.021669; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,590 root         INFO     Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 0.088293\n",
      "Reconstruction: 0.055763, Regularization: 0.000061, Discriminator: 0.021631; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,655 root         INFO     Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 0.089823\n",
      "Reconstruction: 0.057304, Regularization: 0.000062, Discriminator: 0.021623; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,719 root         INFO     Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 0.086680\n",
      "Reconstruction: 0.054148, Regularization: 0.000056, Discriminator: 0.021638; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,783 root         INFO     Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 0.081719\n",
      "Reconstruction: 0.049164, Regularization: 0.000050, Discriminator: 0.021678; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,849 root         INFO     ====> Epoch: 150 Average loss: 0.0851\n",
      "2019-04-09 20:45:45,873 root         INFO     Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 0.088640\n",
      "Reconstruction: 0.056102, Regularization: 0.000061, Discriminator: 0.021651; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,939 root         INFO     Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 0.096122\n",
      "Reconstruction: 0.063492, Regularization: 0.000073, Discriminator: 0.021724; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,005 root         INFO     Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 0.082953\n",
      "Reconstruction: 0.050412, Regularization: 0.000054, Discriminator: 0.021659; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,071 root         INFO     Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 0.083469\n",
      "Reconstruction: 0.050945, Regularization: 0.000055, Discriminator: 0.021634; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,137 root         INFO     Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 0.085885\n",
      "Reconstruction: 0.053350, Regularization: 0.000060, Discriminator: 0.021640; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,204 root         INFO     Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 0.084439\n",
      "Reconstruction: 0.051983, Regularization: 0.000058, Discriminator: 0.021566; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,270 root         INFO     Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 0.083044\n",
      "Reconstruction: 0.050401, Regularization: 0.000059, Discriminator: 0.021750; Generator: 0.010834,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,337 root         INFO     Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 0.076797\n",
      "Reconstruction: 0.044332, Regularization: 0.000049, Discriminator: 0.021584; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,404 root         INFO     ====> Epoch: 151 Average loss: 0.0851\n",
      "2019-04-09 20:45:46,428 root         INFO     Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 0.076262\n",
      "Reconstruction: 0.043671, Regularization: 0.000047, Discriminator: 0.021712; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,495 root         INFO     Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 0.092892\n",
      "Reconstruction: 0.060421, Regularization: 0.000074, Discriminator: 0.021569; Generator: 0.010827,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,560 root         INFO     Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 0.088083\n",
      "Reconstruction: 0.055496, Regularization: 0.000068, Discriminator: 0.021684; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,626 root         INFO     Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 0.082945\n",
      "Reconstruction: 0.050415, Regularization: 0.000060, Discriminator: 0.021629; Generator: 0.010842,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,692 root         INFO     Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 0.084231\n",
      "Reconstruction: 0.051675, Regularization: 0.000062, Discriminator: 0.021651; Generator: 0.010843,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,758 root         INFO     Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 0.075474\n",
      "Reconstruction: 0.042936, Regularization: 0.000048, Discriminator: 0.021655; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,823 root         INFO     Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 0.081494\n",
      "Reconstruction: 0.048956, Regularization: 0.000056, Discriminator: 0.021647; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,889 root         INFO     Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 0.074254\n",
      "Reconstruction: 0.041727, Regularization: 0.000043, Discriminator: 0.021653; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,957 root         INFO     ====> Epoch: 152 Average loss: 0.0851\n",
      "2019-04-09 20:45:46,981 root         INFO     Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 0.095333\n",
      "Reconstruction: 0.062801, Regularization: 0.000078, Discriminator: 0.021625; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,047 root         INFO     Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 0.091917\n",
      "Reconstruction: 0.059395, Regularization: 0.000073, Discriminator: 0.021616; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,114 root         INFO     Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 0.091285\n",
      "Reconstruction: 0.058763, Regularization: 0.000074, Discriminator: 0.021613; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,180 root         INFO     Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 0.084970\n",
      "Reconstruction: 0.052436, Regularization: 0.000063, Discriminator: 0.021632; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,247 root         INFO     Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 0.088299\n",
      "Reconstruction: 0.055751, Regularization: 0.000067, Discriminator: 0.021649; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,313 root         INFO     Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 0.069324\n",
      "Reconstruction: 0.036771, Regularization: 0.000035, Discriminator: 0.021686; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,379 root         INFO     Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 0.089146\n",
      "Reconstruction: 0.056570, Regularization: 0.000069, Discriminator: 0.021683; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,445 root         INFO     Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 0.095810\n",
      "Reconstruction: 0.063251, Regularization: 0.000079, Discriminator: 0.021653; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,514 root         INFO     ====> Epoch: 153 Average loss: 0.0851\n",
      "2019-04-09 20:45:47,538 root         INFO     Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 0.071877\n",
      "Reconstruction: 0.039361, Regularization: 0.000041, Discriminator: 0.021636; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,601 root         INFO     Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 0.087920\n",
      "Reconstruction: 0.055298, Regularization: 0.000070, Discriminator: 0.021707; Generator: 0.010845,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,664 root         INFO     Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 0.089195\n",
      "Reconstruction: 0.056645, Regularization: 0.000072, Discriminator: 0.021633; Generator: 0.010845,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,728 root         INFO     Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 0.087173\n",
      "Reconstruction: 0.054592, Regularization: 0.000067, Discriminator: 0.021676; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,791 root         INFO     Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 0.076969\n",
      "Reconstruction: 0.044466, Regularization: 0.000050, Discriminator: 0.021617; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,855 root         INFO     Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 0.089914\n",
      "Reconstruction: 0.057319, Regularization: 0.000071, Discriminator: 0.021692; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,918 root         INFO     Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 0.079746\n",
      "Reconstruction: 0.047215, Regularization: 0.000053, Discriminator: 0.021653; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,982 root         INFO     Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 0.084945\n",
      "Reconstruction: 0.052443, Regularization: 0.000061, Discriminator: 0.021610; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,048 root         INFO     ====> Epoch: 154 Average loss: 0.0851\n",
      "2019-04-09 20:45:48,072 root         INFO     Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 0.088005\n",
      "Reconstruction: 0.055411, Regularization: 0.000069, Discriminator: 0.021697; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,136 root         INFO     Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 0.099973\n",
      "Reconstruction: 0.067282, Regularization: 0.000087, Discriminator: 0.021763; Generator: 0.010841,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,200 root         INFO     Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 0.087986\n",
      "Reconstruction: 0.055413, Regularization: 0.000069, Discriminator: 0.021675; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,264 root         INFO     Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 0.084906\n",
      "Reconstruction: 0.052358, Regularization: 0.000063, Discriminator: 0.021648; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,328 root         INFO     Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 0.086246\n",
      "Reconstruction: 0.053736, Regularization: 0.000065, Discriminator: 0.021609; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,392 root         INFO     Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 0.075109\n",
      "Reconstruction: 0.042551, Regularization: 0.000047, Discriminator: 0.021674; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,456 root         INFO     Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 0.070483\n",
      "Reconstruction: 0.037965, Regularization: 0.000041, Discriminator: 0.021649; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,520 root         INFO     Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 0.078870\n",
      "Reconstruction: 0.046288, Regularization: 0.000055, Discriminator: 0.021693; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,587 root         INFO     ====> Epoch: 155 Average loss: 0.0851\n",
      "2019-04-09 20:45:48,611 root         INFO     Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 0.078958\n",
      "Reconstruction: 0.046453, Regularization: 0.000056, Discriminator: 0.021618; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,675 root         INFO     Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 0.083820\n",
      "Reconstruction: 0.051214, Regularization: 0.000064, Discriminator: 0.021703; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,742 root         INFO     Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 0.079393\n",
      "Reconstruction: 0.046807, Regularization: 0.000056, Discriminator: 0.021704; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,809 root         INFO     Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 0.081571\n",
      "Reconstruction: 0.048997, Regularization: 0.000061, Discriminator: 0.021680; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,877 root         INFO     Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 0.079536\n",
      "Reconstruction: 0.046986, Regularization: 0.000057, Discriminator: 0.021658; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,945 root         INFO     Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 0.076385\n",
      "Reconstruction: 0.043916, Regularization: 0.000050, Discriminator: 0.021587; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,011 root         INFO     Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 0.087033\n",
      "Reconstruction: 0.054490, Regularization: 0.000067, Discriminator: 0.021640; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,077 root         INFO     Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 0.080683\n",
      "Reconstruction: 0.048129, Regularization: 0.000058, Discriminator: 0.021661; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,144 root         INFO     ====> Epoch: 156 Average loss: 0.0851\n",
      "2019-04-09 20:45:49,168 root         INFO     Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 0.090352\n",
      "Reconstruction: 0.057808, Regularization: 0.000074, Discriminator: 0.021634; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,235 root         INFO     Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 0.083557\n",
      "Reconstruction: 0.051114, Regularization: 0.000063, Discriminator: 0.021544; Generator: 0.010835,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,302 root         INFO     Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 0.083467\n",
      "Reconstruction: 0.050965, Regularization: 0.000060, Discriminator: 0.021616; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,368 root         INFO     Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 0.087466\n",
      "Reconstruction: 0.054947, Regularization: 0.000066, Discriminator: 0.021627; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,433 root         INFO     Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 0.081591\n",
      "Reconstruction: 0.049109, Regularization: 0.000057, Discriminator: 0.021589; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,499 root         INFO     Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 0.083281\n",
      "Reconstruction: 0.050671, Regularization: 0.000061, Discriminator: 0.021717; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,564 root         INFO     Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 0.084838\n",
      "Reconstruction: 0.052287, Regularization: 0.000065, Discriminator: 0.021651; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,630 root         INFO     Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 0.074358\n",
      "Reconstruction: 0.041764, Regularization: 0.000049, Discriminator: 0.021708; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,697 root         INFO     ====> Epoch: 157 Average loss: 0.0851\n",
      "2019-04-09 20:45:49,721 root         INFO     Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 0.082207\n",
      "Reconstruction: 0.049648, Regularization: 0.000063, Discriminator: 0.021654; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,785 root         INFO     Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 0.087039\n",
      "Reconstruction: 0.054427, Regularization: 0.000070, Discriminator: 0.021707; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,849 root         INFO     Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 0.080153\n",
      "Reconstruction: 0.047595, Regularization: 0.000060, Discriminator: 0.021669; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,912 root         INFO     Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 0.080204\n",
      "Reconstruction: 0.047676, Regularization: 0.000060, Discriminator: 0.021635; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,975 root         INFO     Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 0.086516\n",
      "Reconstruction: 0.054035, Regularization: 0.000073, Discriminator: 0.021573; Generator: 0.010836,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,041 root         INFO     Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 0.072188\n",
      "Reconstruction: 0.039679, Regularization: 0.000047, Discriminator: 0.021622; Generator: 0.010841,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,107 root         INFO     Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 0.082943\n",
      "Reconstruction: 0.050405, Regularization: 0.000067, Discriminator: 0.021636; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,174 root         INFO     Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 0.077318\n",
      "Reconstruction: 0.044763, Regularization: 0.000057, Discriminator: 0.021659; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,242 root         INFO     ====> Epoch: 158 Average loss: 0.0851\n",
      "2019-04-09 20:45:50,266 root         INFO     Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 0.092414\n",
      "Reconstruction: 0.059818, Regularization: 0.000083, Discriminator: 0.021680; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,331 root         INFO     Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 0.076329\n",
      "Reconstruction: 0.043787, Regularization: 0.000056, Discriminator: 0.021659; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,397 root         INFO     Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 0.083082\n",
      "Reconstruction: 0.050453, Regularization: 0.000068, Discriminator: 0.021733; Generator: 0.010828,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,463 root         INFO     Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 0.096098\n",
      "Reconstruction: 0.063465, Regularization: 0.000092, Discriminator: 0.021711; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,529 root         INFO     Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 0.081198\n",
      "Reconstruction: 0.048700, Regularization: 0.000065, Discriminator: 0.021600; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,595 root         INFO     Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 0.080628\n",
      "Reconstruction: 0.048049, Regularization: 0.000063, Discriminator: 0.021676; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,661 root         INFO     Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 0.087025\n",
      "Reconstruction: 0.054517, Regularization: 0.000077, Discriminator: 0.021593; Generator: 0.010839,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,727 root         INFO     Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 0.086244\n",
      "Reconstruction: 0.053748, Regularization: 0.000076, Discriminator: 0.021577; Generator: 0.010842,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,794 root         INFO     ====> Epoch: 159 Average loss: 0.0851\n",
      "2019-04-09 20:45:50,819 root         INFO     Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 0.080455\n",
      "Reconstruction: 0.047828, Regularization: 0.000066, Discriminator: 0.021721; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,886 root         INFO     Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 0.081763\n",
      "Reconstruction: 0.049186, Regularization: 0.000069, Discriminator: 0.021668; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,952 root         INFO     Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 0.079089\n",
      "Reconstruction: 0.046546, Regularization: 0.000064, Discriminator: 0.021640; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,018 root         INFO     Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 0.089679\n",
      "Reconstruction: 0.057108, Regularization: 0.000085, Discriminator: 0.021650; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,084 root         INFO     Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 0.083227\n",
      "Reconstruction: 0.050672, Regularization: 0.000073, Discriminator: 0.021647; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,149 root         INFO     Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 0.085221\n",
      "Reconstruction: 0.052745, Regularization: 0.000077, Discriminator: 0.021563; Generator: 0.010836,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,211 root         INFO     Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 0.081079\n",
      "Reconstruction: 0.048454, Regularization: 0.000068, Discriminator: 0.021721; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,273 root         INFO     Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 0.083725\n",
      "Reconstruction: 0.051180, Regularization: 0.000071, Discriminator: 0.021637; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,339 root         INFO     ====> Epoch: 160 Average loss: 0.0851\n",
      "2019-04-09 20:45:51,362 root         INFO     Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 0.086353\n",
      "Reconstruction: 0.053819, Regularization: 0.000074, Discriminator: 0.021634; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,428 root         INFO     Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 0.075763\n",
      "Reconstruction: 0.043185, Regularization: 0.000054, Discriminator: 0.021695; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,494 root         INFO     Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 0.077484\n",
      "Reconstruction: 0.044964, Regularization: 0.000059, Discriminator: 0.021636; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,560 root         INFO     Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 0.081748\n",
      "Reconstruction: 0.049140, Regularization: 0.000067, Discriminator: 0.021712; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,626 root         INFO     Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 0.089200\n",
      "Reconstruction: 0.056668, Regularization: 0.000080, Discriminator: 0.021628; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,691 root         INFO     Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 0.081049\n",
      "Reconstruction: 0.048522, Regularization: 0.000065, Discriminator: 0.021630; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,757 root         INFO     Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 0.089072\n",
      "Reconstruction: 0.056424, Regularization: 0.000080, Discriminator: 0.021729; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,823 root         INFO     Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 0.080962\n",
      "Reconstruction: 0.048368, Regularization: 0.000063, Discriminator: 0.021693; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,890 root         INFO     ====> Epoch: 161 Average loss: 0.0851\n",
      "2019-04-09 20:45:51,914 root         INFO     Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 0.089107\n",
      "Reconstruction: 0.056510, Regularization: 0.000078, Discriminator: 0.021683; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,980 root         INFO     Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 0.086339\n",
      "Reconstruction: 0.053823, Regularization: 0.000071, Discriminator: 0.021611; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,046 root         INFO     Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 0.092407\n",
      "Reconstruction: 0.059754, Regularization: 0.000081, Discriminator: 0.021736; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,112 root         INFO     Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 0.091019\n",
      "Reconstruction: 0.058380, Regularization: 0.000080, Discriminator: 0.021726; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,177 root         INFO     Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 0.100902\n",
      "Reconstruction: 0.068287, Regularization: 0.000098, Discriminator: 0.021684; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,242 root         INFO     Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 0.079476\n",
      "Reconstruction: 0.046855, Regularization: 0.000059, Discriminator: 0.021732; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,306 root         INFO     Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 0.084675\n",
      "Reconstruction: 0.052133, Regularization: 0.000069, Discriminator: 0.021634; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,371 root         INFO     Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 0.086931\n",
      "Reconstruction: 0.054351, Regularization: 0.000074, Discriminator: 0.021676; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,437 root         INFO     ====> Epoch: 162 Average loss: 0.0851\n",
      "2019-04-09 20:45:52,461 root         INFO     Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 0.085996\n",
      "Reconstruction: 0.053446, Regularization: 0.000075, Discriminator: 0.021632; Generator: 0.010843,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,525 root         INFO     Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 0.084396\n",
      "Reconstruction: 0.051766, Regularization: 0.000074, Discriminator: 0.021714; Generator: 0.010842,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,588 root         INFO     Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 0.080938\n",
      "Reconstruction: 0.048360, Regularization: 0.000066, Discriminator: 0.021678; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,652 root         INFO     Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 0.092092\n",
      "Reconstruction: 0.059535, Regularization: 0.000087, Discriminator: 0.021635; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,715 root         INFO     Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 0.079816\n",
      "Reconstruction: 0.047307, Regularization: 0.000065, Discriminator: 0.021614; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,777 root         INFO     Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 0.088209\n",
      "Reconstruction: 0.055664, Regularization: 0.000081, Discriminator: 0.021631; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,840 root         INFO     Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 0.095731\n",
      "Reconstruction: 0.063218, Regularization: 0.000095, Discriminator: 0.021581; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,904 root         INFO     Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 0.087850\n",
      "Reconstruction: 0.055218, Regularization: 0.000079, Discriminator: 0.021716; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,971 root         INFO     ====> Epoch: 163 Average loss: 0.0851\n",
      "2019-04-09 20:45:52,995 root         INFO     Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 0.085273\n",
      "Reconstruction: 0.052738, Regularization: 0.000071, Discriminator: 0.021630; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,058 root         INFO     Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 0.088052\n",
      "Reconstruction: 0.055481, Regularization: 0.000079, Discriminator: 0.021654; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,122 root         INFO     Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 0.088950\n",
      "Reconstruction: 0.056385, Regularization: 0.000080, Discriminator: 0.021651; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,185 root         INFO     Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 0.087891\n",
      "Reconstruction: 0.055345, Regularization: 0.000078, Discriminator: 0.021639; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,248 root         INFO     Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 0.074128\n",
      "Reconstruction: 0.041612, Regularization: 0.000053, Discriminator: 0.021639; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,312 root         INFO     Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 0.073283\n",
      "Reconstruction: 0.040729, Regularization: 0.000052, Discriminator: 0.021665; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,376 root         INFO     Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 0.091161\n",
      "Reconstruction: 0.058591, Regularization: 0.000086, Discriminator: 0.021646; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,440 root         INFO     Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 0.079992\n",
      "Reconstruction: 0.047402, Regularization: 0.000061, Discriminator: 0.021697; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,506 root         INFO     ====> Epoch: 164 Average loss: 0.0851\n",
      "2019-04-09 20:45:53,530 root         INFO     Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 0.082511\n",
      "Reconstruction: 0.049927, Regularization: 0.000067, Discriminator: 0.021684; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,594 root         INFO     Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 0.085230\n",
      "Reconstruction: 0.052649, Regularization: 0.000072, Discriminator: 0.021676; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,660 root         INFO     Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 0.082776\n",
      "Reconstruction: 0.050200, Regularization: 0.000069, Discriminator: 0.021673; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,725 root         INFO     Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 0.089029\n",
      "Reconstruction: 0.056441, Regularization: 0.000077, Discriminator: 0.021679; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,788 root         INFO     Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 0.087156\n",
      "Reconstruction: 0.054519, Regularization: 0.000076, Discriminator: 0.021727; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,851 root         INFO     Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 0.081462\n",
      "Reconstruction: 0.048895, Regularization: 0.000065, Discriminator: 0.021669; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,915 root         INFO     Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 0.080654\n",
      "Reconstruction: 0.048057, Regularization: 0.000065, Discriminator: 0.021691; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,979 root         INFO     Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 0.084218\n",
      "Reconstruction: 0.051620, Regularization: 0.000072, Discriminator: 0.021689; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,045 root         INFO     ====> Epoch: 165 Average loss: 0.0851\n",
      "2019-04-09 20:45:54,069 root         INFO     Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 0.075131\n",
      "Reconstruction: 0.042562, Regularization: 0.000056, Discriminator: 0.021680; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,135 root         INFO     Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 0.083676\n",
      "Reconstruction: 0.051142, Regularization: 0.000073, Discriminator: 0.021630; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,201 root         INFO     Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 0.073877\n",
      "Reconstruction: 0.041323, Regularization: 0.000052, Discriminator: 0.021669; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,268 root         INFO     Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 0.081175\n",
      "Reconstruction: 0.048595, Regularization: 0.000067, Discriminator: 0.021671; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,334 root         INFO     Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 0.082052\n",
      "Reconstruction: 0.049496, Regularization: 0.000068, Discriminator: 0.021652; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,400 root         INFO     Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 0.081371\n",
      "Reconstruction: 0.048801, Regularization: 0.000065, Discriminator: 0.021670; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,466 root         INFO     Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 0.099432\n",
      "Reconstruction: 0.066853, Regularization: 0.000099, Discriminator: 0.021652; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,531 root         INFO     Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 0.078869\n",
      "Reconstruction: 0.046266, Regularization: 0.000061, Discriminator: 0.021714; Generator: 0.010829,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,599 root         INFO     ====> Epoch: 166 Average loss: 0.0851\n",
      "2019-04-09 20:45:54,623 root         INFO     Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 0.090441\n",
      "Reconstruction: 0.057812, Regularization: 0.000083, Discriminator: 0.021708; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,687 root         INFO     Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 0.077786\n",
      "Reconstruction: 0.045208, Regularization: 0.000060, Discriminator: 0.021681; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,753 root         INFO     Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 0.081225\n",
      "Reconstruction: 0.048679, Regularization: 0.000067, Discriminator: 0.021632; Generator: 0.010846,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 20:45:54,819 root         INFO     Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 0.091933\n",
      "Reconstruction: 0.059327, Regularization: 0.000085, Discriminator: 0.021686; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,886 root         INFO     Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 0.086880\n",
      "Reconstruction: 0.054300, Regularization: 0.000075, Discriminator: 0.021669; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,952 root         INFO     Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 0.079999\n",
      "Reconstruction: 0.047485, Regularization: 0.000061, Discriminator: 0.021619; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,018 root         INFO     Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 0.087024\n",
      "Reconstruction: 0.054437, Regularization: 0.000073, Discriminator: 0.021682; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,084 root         INFO     Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 0.090390\n",
      "Reconstruction: 0.057784, Regularization: 0.000079, Discriminator: 0.021694; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,151 root         INFO     ====> Epoch: 167 Average loss: 0.0851\n",
      "2019-04-09 20:45:55,175 root         INFO     Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 0.091929\n",
      "Reconstruction: 0.059433, Regularization: 0.000083, Discriminator: 0.021585; Generator: 0.010827,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,242 root         INFO     Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 0.082110\n",
      "Reconstruction: 0.049521, Regularization: 0.000066, Discriminator: 0.021691; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,308 root         INFO     Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 0.077814\n",
      "Reconstruction: 0.045303, Regularization: 0.000058, Discriminator: 0.021628; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,374 root         INFO     Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 0.090418\n",
      "Reconstruction: 0.057824, Regularization: 0.000081, Discriminator: 0.021687; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,439 root         INFO     Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 0.086656\n",
      "Reconstruction: 0.054048, Regularization: 0.000075, Discriminator: 0.021696; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,506 root         INFO     Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 0.080060\n",
      "Reconstruction: 0.047505, Regularization: 0.000065, Discriminator: 0.021666; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,571 root         INFO     Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 0.078614\n",
      "Reconstruction: 0.046047, Regularization: 0.000062, Discriminator: 0.021674; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,638 root         INFO     Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 0.079882\n",
      "Reconstruction: 0.047371, Regularization: 0.000065, Discriminator: 0.021606; Generator: 0.010841,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,706 root         INFO     ====> Epoch: 168 Average loss: 0.0851\n",
      "2019-04-09 20:45:55,730 root         INFO     Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 0.080426\n",
      "Reconstruction: 0.047937, Regularization: 0.000064, Discriminator: 0.021583; Generator: 0.010842,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,796 root         INFO     Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 0.084658\n",
      "Reconstruction: 0.052069, Regularization: 0.000073, Discriminator: 0.021679; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,862 root         INFO     Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 0.081164\n",
      "Reconstruction: 0.048588, Regularization: 0.000067, Discriminator: 0.021673; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,927 root         INFO     Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 0.090386\n",
      "Reconstruction: 0.057803, Regularization: 0.000084, Discriminator: 0.021671; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,992 root         INFO     Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 0.084815\n",
      "Reconstruction: 0.052244, Regularization: 0.000072, Discriminator: 0.021671; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,058 root         INFO     Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 0.079871\n",
      "Reconstruction: 0.047363, Regularization: 0.000061, Discriminator: 0.021614; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,122 root         INFO     Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 0.091284\n",
      "Reconstruction: 0.058654, Regularization: 0.000081, Discriminator: 0.021710; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,187 root         INFO     Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 0.080773\n",
      "Reconstruction: 0.048225, Regularization: 0.000062, Discriminator: 0.021646; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,254 root         INFO     ====> Epoch: 169 Average loss: 0.0851\n",
      "2019-04-09 20:45:56,277 root         INFO     Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 0.080945\n",
      "Reconstruction: 0.048439, Regularization: 0.000062, Discriminator: 0.021604; Generator: 0.010840,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,344 root         INFO     Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 0.084319\n",
      "Reconstruction: 0.051817, Regularization: 0.000068, Discriminator: 0.021592; Generator: 0.010842,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,409 root         INFO     Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 0.072248\n",
      "Reconstruction: 0.039748, Regularization: 0.000044, Discriminator: 0.021616; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,475 root         INFO     Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 0.075201\n",
      "Reconstruction: 0.042605, Regularization: 0.000051, Discriminator: 0.021709; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,542 root         INFO     Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 0.083102\n",
      "Reconstruction: 0.050568, Regularization: 0.000066, Discriminator: 0.021632; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,610 root         INFO     Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 0.097082\n",
      "Reconstruction: 0.064479, Regularization: 0.000093, Discriminator: 0.021674; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,679 root         INFO     Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 0.085595\n",
      "Reconstruction: 0.053072, Regularization: 0.000072, Discriminator: 0.021620; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,746 root         INFO     Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 0.098077\n",
      "Reconstruction: 0.065455, Regularization: 0.000093, Discriminator: 0.021697; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,816 root         INFO     ====> Epoch: 170 Average loss: 0.0851\n",
      "2019-04-09 20:45:56,840 root         INFO     Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 0.084911\n",
      "Reconstruction: 0.052382, Regularization: 0.000069, Discriminator: 0.021626; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,909 root         INFO     Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 0.077192\n",
      "Reconstruction: 0.044642, Regularization: 0.000055, Discriminator: 0.021659; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,978 root         INFO     Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 0.074617\n",
      "Reconstruction: 0.042106, Regularization: 0.000050, Discriminator: 0.021623; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,046 root         INFO     Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 0.087810\n",
      "Reconstruction: 0.055179, Regularization: 0.000074, Discriminator: 0.021722; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,115 root         INFO     Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 0.081709\n",
      "Reconstruction: 0.049162, Regularization: 0.000064, Discriminator: 0.021657; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,182 root         INFO     Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 0.081651\n",
      "Reconstruction: 0.049107, Regularization: 0.000063, Discriminator: 0.021648; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,248 root         INFO     Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 0.081903\n",
      "Reconstruction: 0.049371, Regularization: 0.000062, Discriminator: 0.021647; Generator: 0.010822,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,314 root         INFO     Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 0.081060\n",
      "Reconstruction: 0.048513, Regularization: 0.000061, Discriminator: 0.021651; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,382 root         INFO     ====> Epoch: 171 Average loss: 0.0851\n",
      "2019-04-09 20:45:57,406 root         INFO     Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 0.084300\n",
      "Reconstruction: 0.051758, Regularization: 0.000067, Discriminator: 0.021639; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,473 root         INFO     Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 0.094272\n",
      "Reconstruction: 0.061718, Regularization: 0.000087, Discriminator: 0.021637; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,540 root         INFO     Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 0.076683\n",
      "Reconstruction: 0.044126, Regularization: 0.000054, Discriminator: 0.021670; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,607 root         INFO     Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 0.094701\n",
      "Reconstruction: 0.062081, Regularization: 0.000087, Discriminator: 0.021697; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,673 root         INFO     Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 0.089804\n",
      "Reconstruction: 0.057260, Regularization: 0.000080, Discriminator: 0.021630; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,738 root         INFO     Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 0.075097\n",
      "Reconstruction: 0.042662, Regularization: 0.000052, Discriminator: 0.021556; Generator: 0.010827,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,805 root         INFO     Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 0.086833\n",
      "Reconstruction: 0.054284, Regularization: 0.000074, Discriminator: 0.021638; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,873 root         INFO     Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 0.088053\n",
      "Reconstruction: 0.055471, Regularization: 0.000075, Discriminator: 0.021670; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,942 root         INFO     ====> Epoch: 172 Average loss: 0.0851\n",
      "2019-04-09 20:45:57,966 root         INFO     Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 0.072927\n",
      "Reconstruction: 0.040411, Regularization: 0.000047, Discriminator: 0.021631; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,031 root         INFO     Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 0.081045\n",
      "Reconstruction: 0.048445, Regularization: 0.000063, Discriminator: 0.021702; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,095 root         INFO     Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 0.075753\n",
      "Reconstruction: 0.043224, Regularization: 0.000053, Discriminator: 0.021639; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,159 root         INFO     Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 0.069943\n",
      "Reconstruction: 0.037373, Regularization: 0.000042, Discriminator: 0.021693; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,223 root         INFO     Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 0.082854\n",
      "Reconstruction: 0.050286, Regularization: 0.000064, Discriminator: 0.021676; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,287 root         INFO     Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 0.079159\n",
      "Reconstruction: 0.046573, Regularization: 0.000056, Discriminator: 0.021699; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,352 root         INFO     Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 0.080635\n",
      "Reconstruction: 0.048036, Regularization: 0.000063, Discriminator: 0.021704; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,418 root         INFO     Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 0.083951\n",
      "Reconstruction: 0.051420, Regularization: 0.000068, Discriminator: 0.021631; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,485 root         INFO     ====> Epoch: 173 Average loss: 0.0851\n",
      "2019-04-09 20:45:58,509 root         INFO     Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 0.095217\n",
      "Reconstruction: 0.062680, Regularization: 0.000087, Discriminator: 0.021611; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,576 root         INFO     Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 0.097177\n",
      "Reconstruction: 0.064599, Regularization: 0.000090, Discriminator: 0.021647; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,643 root         INFO     Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 0.084196\n",
      "Reconstruction: 0.051639, Regularization: 0.000065, Discriminator: 0.021653; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,710 root         INFO     Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 0.082149\n",
      "Reconstruction: 0.049602, Regularization: 0.000062, Discriminator: 0.021652; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,777 root         INFO     Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 0.089575\n",
      "Reconstruction: 0.056931, Regularization: 0.000074, Discriminator: 0.021740; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,844 root         INFO     Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 0.083725\n",
      "Reconstruction: 0.051205, Regularization: 0.000061, Discriminator: 0.021626; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,911 root         INFO     Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 0.083652\n",
      "Reconstruction: 0.051132, Regularization: 0.000061, Discriminator: 0.021632; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,976 root         INFO     Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 0.095792\n",
      "Reconstruction: 0.063212, Regularization: 0.000081, Discriminator: 0.021660; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,042 root         INFO     ====> Epoch: 174 Average loss: 0.0851\n",
      "2019-04-09 20:45:59,066 root         INFO     Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 0.095340\n",
      "Reconstruction: 0.062781, Regularization: 0.000079, Discriminator: 0.021647; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,134 root         INFO     Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 0.085892\n",
      "Reconstruction: 0.053350, Regularization: 0.000065, Discriminator: 0.021645; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,202 root         INFO     Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 0.074768\n",
      "Reconstruction: 0.042265, Regularization: 0.000047, Discriminator: 0.021633; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,269 root         INFO     Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 0.086377\n",
      "Reconstruction: 0.053847, Regularization: 0.000065, Discriminator: 0.021636; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,337 root         INFO     Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 0.075736\n",
      "Reconstruction: 0.043187, Regularization: 0.000047, Discriminator: 0.021662; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,404 root         INFO     Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 0.070794\n",
      "Reconstruction: 0.038266, Regularization: 0.000039, Discriminator: 0.021659; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,471 root         INFO     Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 0.080934\n",
      "Reconstruction: 0.048318, Regularization: 0.000053, Discriminator: 0.021727; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,539 root         INFO     Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 0.087681\n",
      "Reconstruction: 0.055130, Regularization: 0.000063, Discriminator: 0.021650; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,606 root         INFO     ====> Epoch: 175 Average loss: 0.0851\n",
      "2019-04-09 20:45:59,630 root         INFO     Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 0.085071\n",
      "Reconstruction: 0.052442, Regularization: 0.000060, Discriminator: 0.021731; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,698 root         INFO     Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 0.086628\n",
      "Reconstruction: 0.054024, Regularization: 0.000063, Discriminator: 0.021701; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,765 root         INFO     Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 0.082178\n",
      "Reconstruction: 0.049656, Regularization: 0.000057, Discriminator: 0.021627; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,833 root         INFO     Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 0.095577\n",
      "Reconstruction: 0.063020, Regularization: 0.000078, Discriminator: 0.021641; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,900 root         INFO     Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 0.085675\n",
      "Reconstruction: 0.053156, Regularization: 0.000062, Discriminator: 0.021630; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,967 root         INFO     Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 0.081269\n",
      "Reconstruction: 0.048755, Regularization: 0.000056, Discriminator: 0.021626; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,033 root         INFO     Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 0.087981\n",
      "Reconstruction: 0.055351, Regularization: 0.000066, Discriminator: 0.021735; Generator: 0.010829,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,099 root         INFO     Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 0.080954\n",
      "Reconstruction: 0.048375, Regularization: 0.000054, Discriminator: 0.021695; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,167 root         INFO     ====> Epoch: 176 Average loss: 0.0851\n",
      "2019-04-09 20:46:00,191 root         INFO     Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 0.077577\n",
      "Reconstruction: 0.045021, Regularization: 0.000048, Discriminator: 0.021671; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,260 root         INFO     Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 0.088028\n",
      "Reconstruction: 0.055441, Regularization: 0.000065, Discriminator: 0.021688; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,327 root         INFO     Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 0.088332\n",
      "Reconstruction: 0.055782, Regularization: 0.000065, Discriminator: 0.021653; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,395 root         INFO     Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 0.079877\n",
      "Reconstruction: 0.047286, Regularization: 0.000052, Discriminator: 0.021700; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,460 root         INFO     Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 0.080568\n",
      "Reconstruction: 0.048030, Regularization: 0.000052, Discriminator: 0.021648; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,525 root         INFO     Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 0.098247\n",
      "Reconstruction: 0.065649, Regularization: 0.000080, Discriminator: 0.021678; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,592 root         INFO     Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 0.085421\n",
      "Reconstruction: 0.052920, Regularization: 0.000060, Discriminator: 0.021609; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,659 root         INFO     Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 0.090806\n",
      "Reconstruction: 0.058230, Regularization: 0.000071, Discriminator: 0.021669; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,730 root         INFO     ====> Epoch: 177 Average loss: 0.0851\n",
      "2019-04-09 20:46:00,754 root         INFO     Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 0.078287\n",
      "Reconstruction: 0.045762, Regularization: 0.000049, Discriminator: 0.021646; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,819 root         INFO     Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 0.078629\n",
      "Reconstruction: 0.046105, Regularization: 0.000050, Discriminator: 0.021647; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,883 root         INFO     Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 0.081026\n",
      "Reconstruction: 0.048493, Regularization: 0.000052, Discriminator: 0.021649; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,950 root         INFO     Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 0.073760\n",
      "Reconstruction: 0.041216, Regularization: 0.000041, Discriminator: 0.021669; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,015 root         INFO     Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 0.079907\n",
      "Reconstruction: 0.047339, Regularization: 0.000050, Discriminator: 0.021683; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,080 root         INFO     Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 0.086452\n",
      "Reconstruction: 0.053918, Regularization: 0.000060, Discriminator: 0.021631; Generator: 0.010843,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,146 root         INFO     Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 0.090627\n",
      "Reconstruction: 0.058083, Regularization: 0.000068, Discriminator: 0.021638; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,211 root         INFO     Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 0.079474\n",
      "Reconstruction: 0.046903, Regularization: 0.000050, Discriminator: 0.021687; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,279 root         INFO     ====> Epoch: 178 Average loss: 0.0851\n",
      "2019-04-09 20:46:01,303 root         INFO     Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 0.085713\n",
      "Reconstruction: 0.053170, Regularization: 0.000061, Discriminator: 0.021652; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,371 root         INFO     Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 0.083126\n",
      "Reconstruction: 0.050633, Regularization: 0.000057, Discriminator: 0.021603; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,438 root         INFO     Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 0.088131\n",
      "Reconstruction: 0.055572, Regularization: 0.000065, Discriminator: 0.021659; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,505 root         INFO     Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 0.080029\n",
      "Reconstruction: 0.047458, Regularization: 0.000052, Discriminator: 0.021684; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,572 root         INFO     Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 0.100710\n",
      "Reconstruction: 0.068123, Regularization: 0.000082, Discriminator: 0.021670; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,639 root         INFO     Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 0.083250\n",
      "Reconstruction: 0.050650, Regularization: 0.000054, Discriminator: 0.021710; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,706 root         INFO     Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 0.076738\n",
      "Reconstruction: 0.044216, Regularization: 0.000045, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,773 root         INFO     Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 0.078159\n",
      "Reconstruction: 0.045547, Regularization: 0.000047, Discriminator: 0.021722; Generator: 0.010844,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,840 root         INFO     ====> Epoch: 179 Average loss: 0.0851\n",
      "2019-04-09 20:46:01,864 root         INFO     Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 0.085865\n",
      "Reconstruction: 0.053318, Regularization: 0.000059, Discriminator: 0.021663; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,933 root         INFO     Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 0.081142\n",
      "Reconstruction: 0.048590, Regularization: 0.000053, Discriminator: 0.021669; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,000 root         INFO     Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 0.097027\n",
      "Reconstruction: 0.064513, Regularization: 0.000079, Discriminator: 0.021602; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,067 root         INFO     Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 0.093454\n",
      "Reconstruction: 0.060875, Regularization: 0.000071, Discriminator: 0.021671; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,135 root         INFO     Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 0.079606\n",
      "Reconstruction: 0.047042, Regularization: 0.000050, Discriminator: 0.021682; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,202 root         INFO     Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 0.074823\n",
      "Reconstruction: 0.042183, Regularization: 0.000044, Discriminator: 0.021759; Generator: 0.010837,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,269 root         INFO     Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 0.088715\n",
      "Reconstruction: 0.056100, Regularization: 0.000066, Discriminator: 0.021711; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,335 root         INFO     Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 0.080575\n",
      "Reconstruction: 0.048098, Regularization: 0.000053, Discriminator: 0.021598; Generator: 0.010825,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,401 root         INFO     ====> Epoch: 180 Average loss: 0.0851\n",
      "2019-04-09 20:46:02,425 root         INFO     Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 0.078131\n",
      "Reconstruction: 0.045604, Regularization: 0.000051, Discriminator: 0.021644; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,493 root         INFO     Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 0.088564\n",
      "Reconstruction: 0.055970, Regularization: 0.000066, Discriminator: 0.021696; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,561 root         INFO     Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 0.081899\n",
      "Reconstruction: 0.049303, Regularization: 0.000056, Discriminator: 0.021713; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,628 root         INFO     Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 0.079004\n",
      "Reconstruction: 0.046492, Regularization: 0.000052, Discriminator: 0.021636; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,696 root         INFO     Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 0.088585\n",
      "Reconstruction: 0.056078, Regularization: 0.000067, Discriminator: 0.021606; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,763 root         INFO     Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 0.092753\n",
      "Reconstruction: 0.060229, Regularization: 0.000073, Discriminator: 0.021613; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,831 root         INFO     Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 0.087431\n",
      "Reconstruction: 0.054859, Regularization: 0.000063, Discriminator: 0.021672; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,898 root         INFO     Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 0.079216\n",
      "Reconstruction: 0.046638, Regularization: 0.000052, Discriminator: 0.021688; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,966 root         INFO     ====> Epoch: 181 Average loss: 0.0851\n",
      "2019-04-09 20:46:02,991 root         INFO     Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 0.082565\n",
      "Reconstruction: 0.050027, Regularization: 0.000058, Discriminator: 0.021644; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,059 root         INFO     Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 0.077900\n",
      "Reconstruction: 0.045290, Regularization: 0.000048, Discriminator: 0.021721; Generator: 0.010841,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,124 root         INFO     Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 0.094184\n",
      "Reconstruction: 0.061673, Regularization: 0.000076, Discriminator: 0.021608; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,188 root         INFO     Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 0.081600\n",
      "Reconstruction: 0.049032, Regularization: 0.000055, Discriminator: 0.021678; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,252 root         INFO     Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 0.093167\n",
      "Reconstruction: 0.060565, Regularization: 0.000074, Discriminator: 0.021689; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,317 root         INFO     Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 0.077990\n",
      "Reconstruction: 0.045467, Regularization: 0.000050, Discriminator: 0.021636; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,381 root         INFO     Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 0.094027\n",
      "Reconstruction: 0.061507, Regularization: 0.000078, Discriminator: 0.021611; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,445 root         INFO     Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 0.073205\n",
      "Reconstruction: 0.040687, Regularization: 0.000043, Discriminator: 0.021645; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,510 root         INFO     ====> Epoch: 182 Average loss: 0.0851\n",
      "2019-04-09 20:46:03,534 root         INFO     Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 0.084742\n",
      "Reconstruction: 0.052130, Regularization: 0.000061, Discriminator: 0.021720; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,602 root         INFO     Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 0.078878\n",
      "Reconstruction: 0.046326, Regularization: 0.000051, Discriminator: 0.021674; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,669 root         INFO     Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 0.080602\n",
      "Reconstruction: 0.048057, Regularization: 0.000054, Discriminator: 0.021662; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,735 root         INFO     Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 0.080963\n",
      "Reconstruction: 0.048428, Regularization: 0.000053, Discriminator: 0.021648; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,801 root         INFO     Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 0.082413\n",
      "Reconstruction: 0.049875, Regularization: 0.000056, Discriminator: 0.021647; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,867 root         INFO     Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 0.092150\n",
      "Reconstruction: 0.059604, Regularization: 0.000070, Discriminator: 0.021650; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,933 root         INFO     Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 0.072579\n",
      "Reconstruction: 0.040037, Regularization: 0.000040, Discriminator: 0.021668; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,000 root         INFO     Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 0.086424\n",
      "Reconstruction: 0.053827, Regularization: 0.000062, Discriminator: 0.021704; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,067 root         INFO     ====> Epoch: 183 Average loss: 0.0851\n",
      "2019-04-09 20:46:04,092 root         INFO     Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 0.084998\n",
      "Reconstruction: 0.052434, Regularization: 0.000060, Discriminator: 0.021659; Generator: 0.010845,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,158 root         INFO     Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 0.080358\n",
      "Reconstruction: 0.047827, Regularization: 0.000052, Discriminator: 0.021636; Generator: 0.010842,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,223 root         INFO     Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 0.082009\n",
      "Reconstruction: 0.049436, Regularization: 0.000053, Discriminator: 0.021679; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,290 root         INFO     Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 0.101144\n",
      "Reconstruction: 0.068578, Regularization: 0.000084, Discriminator: 0.021653; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,357 root         INFO     Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 0.077751\n",
      "Reconstruction: 0.045184, Regularization: 0.000048, Discriminator: 0.021680; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,423 root         INFO     Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 0.079594\n",
      "Reconstruction: 0.046991, Regularization: 0.000052, Discriminator: 0.021718; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,489 root         INFO     Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 0.091879\n",
      "Reconstruction: 0.059269, Regularization: 0.000069, Discriminator: 0.021706; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,556 root         INFO     Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 0.094020\n",
      "Reconstruction: 0.061416, Regularization: 0.000072, Discriminator: 0.021693; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,624 root         INFO     ====> Epoch: 184 Average loss: 0.0851\n",
      "2019-04-09 20:46:04,648 root         INFO     Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 0.082755\n",
      "Reconstruction: 0.050279, Regularization: 0.000054, Discriminator: 0.021590; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,716 root         INFO     Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 0.081065\n",
      "Reconstruction: 0.048513, Regularization: 0.000050, Discriminator: 0.021675; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,782 root         INFO     Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 0.085290\n",
      "Reconstruction: 0.052693, Regularization: 0.000056, Discriminator: 0.021707; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,848 root         INFO     Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 0.098897\n",
      "Reconstruction: 0.066313, Regularization: 0.000076, Discriminator: 0.021673; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,913 root         INFO     Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 0.081864\n",
      "Reconstruction: 0.049278, Regularization: 0.000052, Discriminator: 0.021700; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,979 root         INFO     Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 0.079978\n",
      "Reconstruction: 0.047418, Regularization: 0.000047, Discriminator: 0.021688; Generator: 0.010825,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,045 root         INFO     Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 0.087572\n",
      "Reconstruction: 0.055033, Regularization: 0.000058, Discriminator: 0.021657; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,112 root         INFO     Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 0.078212\n",
      "Reconstruction: 0.045655, Regularization: 0.000044, Discriminator: 0.021671; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,179 root         INFO     ====> Epoch: 185 Average loss: 0.0851\n",
      "2019-04-09 20:46:05,203 root         INFO     Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 0.071113\n",
      "Reconstruction: 0.038557, Regularization: 0.000034, Discriminator: 0.021676; Generator: 0.010845,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,266 root         INFO     Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 0.084339\n",
      "Reconstruction: 0.051761, Regularization: 0.000054, Discriminator: 0.021686; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,329 root         INFO     Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 0.077138\n",
      "Reconstruction: 0.044675, Regularization: 0.000042, Discriminator: 0.021591; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,392 root         INFO     Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 0.080135\n",
      "Reconstruction: 0.047601, Regularization: 0.000047, Discriminator: 0.021659; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,455 root         INFO     Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 0.077459\n",
      "Reconstruction: 0.044972, Regularization: 0.000043, Discriminator: 0.021615; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,518 root         INFO     Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 0.086715\n",
      "Reconstruction: 0.054158, Regularization: 0.000058, Discriminator: 0.021666; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,582 root         INFO     Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 0.078719\n",
      "Reconstruction: 0.046291, Regularization: 0.000045, Discriminator: 0.021553; Generator: 0.010829,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,645 root         INFO     Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 0.096361\n",
      "Reconstruction: 0.063857, Regularization: 0.000068, Discriminator: 0.021598; Generator: 0.010838,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,710 root         INFO     ====> Epoch: 186 Average loss: 0.0851\n",
      "2019-04-09 20:46:05,734 root         INFO     Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 0.084075\n",
      "Reconstruction: 0.051414, Regularization: 0.000051, Discriminator: 0.021770; Generator: 0.010841,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,799 root         INFO     Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 0.093969\n",
      "Reconstruction: 0.061392, Regularization: 0.000064, Discriminator: 0.021685; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,864 root         INFO     Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 0.099127\n",
      "Reconstruction: 0.066574, Regularization: 0.000071, Discriminator: 0.021646; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,928 root         INFO     Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 0.090884\n",
      "Reconstruction: 0.058342, Regularization: 0.000058, Discriminator: 0.021650; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,992 root         INFO     Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 0.089349\n",
      "Reconstruction: 0.056867, Regularization: 0.000056, Discriminator: 0.021589; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,058 root         INFO     Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 0.080417\n",
      "Reconstruction: 0.047768, Regularization: 0.000044, Discriminator: 0.021767; Generator: 0.010838,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,125 root         INFO     Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 0.094597\n",
      "Reconstruction: 0.062080, Regularization: 0.000063, Discriminator: 0.021621; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,191 root         INFO     Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 0.083968\n",
      "Reconstruction: 0.051492, Regularization: 0.000049, Discriminator: 0.021587; Generator: 0.010840,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,260 root         INFO     ====> Epoch: 187 Average loss: 0.0851\n",
      "2019-04-09 20:46:06,284 root         INFO     Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 0.085796\n",
      "Reconstruction: 0.053286, Regularization: 0.000052, Discriminator: 0.021622; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,350 root         INFO     Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 0.084169\n",
      "Reconstruction: 0.051617, Regularization: 0.000052, Discriminator: 0.021662; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,417 root         INFO     Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 0.086906\n",
      "Reconstruction: 0.054396, Regularization: 0.000053, Discriminator: 0.021625; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,483 root         INFO     Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 0.081925\n",
      "Reconstruction: 0.049378, Regularization: 0.000046, Discriminator: 0.021668; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,550 root         INFO     Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 0.091835\n",
      "Reconstruction: 0.059287, Regularization: 0.000056, Discriminator: 0.021657; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,616 root         INFO     Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 0.084980\n",
      "Reconstruction: 0.052463, Regularization: 0.000050, Discriminator: 0.021636; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,682 root         INFO     Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 0.094280\n",
      "Reconstruction: 0.061843, Regularization: 0.000061, Discriminator: 0.021548; Generator: 0.010829,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,748 root         INFO     Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 0.084521\n",
      "Reconstruction: 0.051993, Regularization: 0.000049, Discriminator: 0.021639; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,815 root         INFO     ====> Epoch: 188 Average loss: 0.0851\n",
      "2019-04-09 20:46:06,839 root         INFO     Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 0.087158\n",
      "Reconstruction: 0.054601, Regularization: 0.000050, Discriminator: 0.021672; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,906 root         INFO     Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 0.079385\n",
      "Reconstruction: 0.046838, Regularization: 0.000042, Discriminator: 0.021666; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,973 root         INFO     Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 0.084583\n",
      "Reconstruction: 0.052051, Regularization: 0.000048, Discriminator: 0.021645; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,039 root         INFO     Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 0.091257\n",
      "Reconstruction: 0.058680, Regularization: 0.000056, Discriminator: 0.021685; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,106 root         INFO     Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 0.087951\n",
      "Reconstruction: 0.055490, Regularization: 0.000050, Discriminator: 0.021571; Generator: 0.010841,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,172 root         INFO     Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 0.083964\n",
      "Reconstruction: 0.051458, Regularization: 0.000044, Discriminator: 0.021629; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,239 root         INFO     Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 0.092380\n",
      "Reconstruction: 0.059807, Regularization: 0.000054, Discriminator: 0.021688; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,305 root         INFO     Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 0.086248\n",
      "Reconstruction: 0.053729, Regularization: 0.000049, Discriminator: 0.021640; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,374 root         INFO     ====> Epoch: 189 Average loss: 0.0851\n",
      "2019-04-09 20:46:07,398 root         INFO     Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 0.082013\n",
      "Reconstruction: 0.049449, Regularization: 0.000042, Discriminator: 0.021692; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,465 root         INFO     Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 0.082158\n",
      "Reconstruction: 0.049621, Regularization: 0.000043, Discriminator: 0.021666; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,532 root         INFO     Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 0.077779\n",
      "Reconstruction: 0.045300, Regularization: 0.000037, Discriminator: 0.021605; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,598 root         INFO     Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 0.079979\n",
      "Reconstruction: 0.047402, Regularization: 0.000040, Discriminator: 0.021701; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,665 root         INFO     Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 0.087164\n",
      "Reconstruction: 0.054646, Regularization: 0.000051, Discriminator: 0.021642; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,731 root         INFO     Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 0.094117\n",
      "Reconstruction: 0.061609, Regularization: 0.000059, Discriminator: 0.021602; Generator: 0.010847,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 20:46:07,797 root         INFO     Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 0.105313\n",
      "Reconstruction: 0.072769, Regularization: 0.000071, Discriminator: 0.021638; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,864 root         INFO     Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 0.083051\n",
      "Reconstruction: 0.050456, Regularization: 0.000045, Discriminator: 0.021714; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,932 root         INFO     ====> Epoch: 190 Average loss: 0.0851\n",
      "2019-04-09 20:46:07,956 root         INFO     Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 0.090551\n",
      "Reconstruction: 0.058024, Regularization: 0.000054, Discriminator: 0.021642; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,023 root         INFO     Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 0.088653\n",
      "Reconstruction: 0.055976, Regularization: 0.000053, Discriminator: 0.021792; Generator: 0.010832,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,090 root         INFO     Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 0.076520\n",
      "Reconstruction: 0.043977, Regularization: 0.000038, Discriminator: 0.021686; Generator: 0.010818,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,157 root         INFO     Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 0.092403\n",
      "Reconstruction: 0.059905, Regularization: 0.000058, Discriminator: 0.021613; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,223 root         INFO     Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 0.098188\n",
      "Reconstruction: 0.065629, Regularization: 0.000064, Discriminator: 0.021662; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,291 root         INFO     Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 0.099067\n",
      "Reconstruction: 0.066488, Regularization: 0.000063, Discriminator: 0.021674; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,359 root         INFO     Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 0.080836\n",
      "Reconstruction: 0.048314, Regularization: 0.000041, Discriminator: 0.021643; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,427 root         INFO     Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 0.082957\n",
      "Reconstruction: 0.050426, Regularization: 0.000045, Discriminator: 0.021649; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,496 root         INFO     ====> Epoch: 191 Average loss: 0.0851\n",
      "2019-04-09 20:46:08,520 root         INFO     Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 0.080228\n",
      "Reconstruction: 0.047677, Regularization: 0.000042, Discriminator: 0.021671; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,588 root         INFO     Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 0.083430\n",
      "Reconstruction: 0.050908, Regularization: 0.000047, Discriminator: 0.021646; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,655 root         INFO     Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.092959\n",
      "Reconstruction: 0.060359, Regularization: 0.000057, Discriminator: 0.021711; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,721 root         INFO     Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 0.091347\n",
      "Reconstruction: 0.058851, Regularization: 0.000056, Discriminator: 0.021598; Generator: 0.010842,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,788 root         INFO     Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 0.079507\n",
      "Reconstruction: 0.046926, Regularization: 0.000040, Discriminator: 0.021700; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,855 root         INFO     Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 0.085982\n",
      "Reconstruction: 0.053474, Regularization: 0.000050, Discriminator: 0.021623; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,919 root         INFO     Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 0.084727\n",
      "Reconstruction: 0.052219, Regularization: 0.000047, Discriminator: 0.021619; Generator: 0.010843,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,983 root         INFO     Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 0.076747\n",
      "Reconstruction: 0.044191, Regularization: 0.000037, Discriminator: 0.021688; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,049 root         INFO     ====> Epoch: 192 Average loss: 0.0851\n",
      "2019-04-09 20:46:09,072 root         INFO     Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 0.091213\n",
      "Reconstruction: 0.058594, Regularization: 0.000055, Discriminator: 0.021737; Generator: 0.010827,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,139 root         INFO     Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 0.080673\n",
      "Reconstruction: 0.048101, Regularization: 0.000042, Discriminator: 0.021699; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,206 root         INFO     Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 0.077518\n",
      "Reconstruction: 0.045026, Regularization: 0.000037, Discriminator: 0.021626; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,272 root         INFO     Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 0.082535\n",
      "Reconstruction: 0.050009, Regularization: 0.000042, Discriminator: 0.021650; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,339 root         INFO     Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 0.076568\n",
      "Reconstruction: 0.044069, Regularization: 0.000035, Discriminator: 0.021637; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,406 root         INFO     Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 0.090691\n",
      "Reconstruction: 0.058138, Regularization: 0.000052, Discriminator: 0.021670; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,473 root         INFO     Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 0.087585\n",
      "Reconstruction: 0.055051, Regularization: 0.000048, Discriminator: 0.021647; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,539 root         INFO     Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 0.077403\n",
      "Reconstruction: 0.044828, Regularization: 0.000037, Discriminator: 0.021695; Generator: 0.010843,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,607 root         INFO     ====> Epoch: 193 Average loss: 0.0851\n",
      "2019-04-09 20:46:09,631 root         INFO     Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 0.085436\n",
      "Reconstruction: 0.052846, Regularization: 0.000047, Discriminator: 0.021710; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,699 root         INFO     Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 0.076557\n",
      "Reconstruction: 0.044088, Regularization: 0.000035, Discriminator: 0.021602; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,765 root         INFO     Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 0.094281\n",
      "Reconstruction: 0.061711, Regularization: 0.000055, Discriminator: 0.021672; Generator: 0.010843,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,832 root         INFO     Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 0.084972\n",
      "Reconstruction: 0.052505, Regularization: 0.000043, Discriminator: 0.021587; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,899 root         INFO     Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 0.085208\n",
      "Reconstruction: 0.052598, Regularization: 0.000042, Discriminator: 0.021728; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,965 root         INFO     Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 0.074716\n",
      "Reconstruction: 0.042132, Regularization: 0.000031, Discriminator: 0.021724; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,031 root         INFO     Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 0.106857\n",
      "Reconstruction: 0.074325, Regularization: 0.000068, Discriminator: 0.021640; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,097 root         INFO     Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 0.078308\n",
      "Reconstruction: 0.045763, Regularization: 0.000037, Discriminator: 0.021674; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,166 root         INFO     ====> Epoch: 194 Average loss: 0.0851\n",
      "2019-04-09 20:46:10,190 root         INFO     Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 0.096499\n",
      "Reconstruction: 0.063950, Regularization: 0.000058, Discriminator: 0.021658; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,256 root         INFO     Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 0.087113\n",
      "Reconstruction: 0.054540, Regularization: 0.000048, Discriminator: 0.021694; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,321 root         INFO     Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 0.079589\n",
      "Reconstruction: 0.047071, Regularization: 0.000038, Discriminator: 0.021656; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,388 root         INFO     Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 0.083695\n",
      "Reconstruction: 0.051230, Regularization: 0.000042, Discriminator: 0.021588; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,452 root         INFO     Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 0.079723\n",
      "Reconstruction: 0.047184, Regularization: 0.000037, Discriminator: 0.021662; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,515 root         INFO     Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 0.089952\n",
      "Reconstruction: 0.057362, Regularization: 0.000048, Discriminator: 0.021715; Generator: 0.010827,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,579 root         INFO     Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 0.093241\n",
      "Reconstruction: 0.060755, Regularization: 0.000052, Discriminator: 0.021597; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,642 root         INFO     Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 0.071966\n",
      "Reconstruction: 0.039404, Regularization: 0.000028, Discriminator: 0.021697; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,708 root         INFO     ====> Epoch: 195 Average loss: 0.0851\n",
      "2019-04-09 20:46:10,732 root         INFO     Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 0.087331\n",
      "Reconstruction: 0.054805, Regularization: 0.000046, Discriminator: 0.021645; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,799 root         INFO     Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 0.098495\n",
      "Reconstruction: 0.065839, Regularization: 0.000058, Discriminator: 0.021765; Generator: 0.010833,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,866 root         INFO     Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 0.096588\n",
      "Reconstruction: 0.064048, Regularization: 0.000055, Discriminator: 0.021657; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,933 root         INFO     Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 0.075133\n",
      "Reconstruction: 0.042618, Regularization: 0.000033, Discriminator: 0.021652; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,000 root         INFO     Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 0.092012\n",
      "Reconstruction: 0.059428, Regularization: 0.000054, Discriminator: 0.021690; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,067 root         INFO     Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 0.079682\n",
      "Reconstruction: 0.047129, Regularization: 0.000038, Discriminator: 0.021681; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,134 root         INFO     Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 0.081183\n",
      "Reconstruction: 0.048638, Regularization: 0.000039, Discriminator: 0.021676; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,204 root         INFO     Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 0.083140\n",
      "Reconstruction: 0.050651, Regularization: 0.000042, Discriminator: 0.021615; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,273 root         INFO     ====> Epoch: 196 Average loss: 0.0851\n",
      "2019-04-09 20:46:11,298 root         INFO     Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 0.073744\n",
      "Reconstruction: 0.041217, Regularization: 0.000029, Discriminator: 0.021657; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,364 root         INFO     Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 0.084057\n",
      "Reconstruction: 0.051506, Regularization: 0.000041, Discriminator: 0.021675; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,432 root         INFO     Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 0.095684\n",
      "Reconstruction: 0.063112, Regularization: 0.000055, Discriminator: 0.021684; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,499 root         INFO     Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 0.079876\n",
      "Reconstruction: 0.047337, Regularization: 0.000037, Discriminator: 0.021668; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,566 root         INFO     Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 0.097306\n",
      "Reconstruction: 0.064744, Regularization: 0.000056, Discriminator: 0.021670; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,634 root         INFO     Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 0.087011\n",
      "Reconstruction: 0.054345, Regularization: 0.000045, Discriminator: 0.021794; Generator: 0.010826,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,703 root         INFO     Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 0.081399\n",
      "Reconstruction: 0.048862, Regularization: 0.000041, Discriminator: 0.021664; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,771 root         INFO     Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 0.085223\n",
      "Reconstruction: 0.052605, Regularization: 0.000045, Discriminator: 0.021738; Generator: 0.010835,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,839 root         INFO     ====> Epoch: 197 Average loss: 0.0851\n",
      "2019-04-09 20:46:11,863 root         INFO     Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 0.100256\n",
      "Reconstruction: 0.067656, Regularization: 0.000061, Discriminator: 0.021700; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,931 root         INFO     Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.080639\n",
      "Reconstruction: 0.048200, Regularization: 0.000040, Discriminator: 0.021568; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,999 root         INFO     Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 0.089857\n",
      "Reconstruction: 0.057323, Regularization: 0.000050, Discriminator: 0.021649; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,062 root         INFO     Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 0.082129\n",
      "Reconstruction: 0.049546, Regularization: 0.000040, Discriminator: 0.021711; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,125 root         INFO     Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 0.088849\n",
      "Reconstruction: 0.056331, Regularization: 0.000050, Discriminator: 0.021638; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,192 root         INFO     Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 0.086933\n",
      "Reconstruction: 0.054424, Regularization: 0.000046, Discriminator: 0.021625; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,259 root         INFO     Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 0.091223\n",
      "Reconstruction: 0.058711, Regularization: 0.000053, Discriminator: 0.021622; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,326 root         INFO     Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 0.078295\n",
      "Reconstruction: 0.045749, Regularization: 0.000037, Discriminator: 0.021674; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,394 root         INFO     ====> Epoch: 198 Average loss: 0.0851\n",
      "2019-04-09 20:46:12,418 root         INFO     Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 0.084813\n",
      "Reconstruction: 0.052270, Regularization: 0.000045, Discriminator: 0.021663; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,485 root         INFO     Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 0.076462\n",
      "Reconstruction: 0.043859, Regularization: 0.000033, Discriminator: 0.021735; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,552 root         INFO     Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 0.094921\n",
      "Reconstruction: 0.062379, Regularization: 0.000056, Discriminator: 0.021655; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,619 root         INFO     Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 0.084170\n",
      "Reconstruction: 0.051614, Regularization: 0.000044, Discriminator: 0.021663; Generator: 0.010849,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 20:46:12,686 root         INFO     Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 0.078080\n",
      "Reconstruction: 0.045505, Regularization: 0.000037, Discriminator: 0.021702; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,751 root         INFO     Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 0.080512\n",
      "Reconstruction: 0.048049, Regularization: 0.000040, Discriminator: 0.021592; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,817 root         INFO     Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.083568\n",
      "Reconstruction: 0.051006, Regularization: 0.000044, Discriminator: 0.021691; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,883 root         INFO     Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 0.077778\n",
      "Reconstruction: 0.045282, Regularization: 0.000038, Discriminator: 0.021629; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,951 root         INFO     ====> Epoch: 199 Average loss: 0.0851\n",
      "2019-04-09 20:46:12,964 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) done      TrainVEM()\n",
      "2019-04-09 20:46:12,964 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 20:46:12,964 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   DONE\n",
      "2019-04-09 20:46:12,965 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 20:46:12,965 luigi-interface DEBUG    Pending tasks: 1\n",
      "2019-04-09 20:46:12,965 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) running   RunAll()\n",
      "2019-04-09 20:46:12,965 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) done      RunAll()\n",
      "2019-04-09 20:46:12,966 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 20:46:12,966 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   DONE\n",
      "2019-04-09 20:46:12,966 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 20:46:12,966 luigi-interface DEBUG    Done\n",
      "2019-04-09 20:46:12,966 luigi-interface DEBUG    There are no more tasks to run at this time\n",
      "2019-04-09 20:46:12,966 luigi-interface INFO     Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) was stopped. Shutting down Keep-Alive thread\n",
      "2019-04-09 20:46:12,967 luigi-interface INFO     \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 4 tasks of which:\n",
      "* 4 ran successfully:\n",
      "    - 1 MakeDataSet()\n",
      "    - 1 RunAll()\n",
      "    - 1 TrainVAE()\n",
      "    - 1 TrainVEM()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pattern = 'logs'\n",
    "logs = []\n",
    "for filename in os.listdir(OUTPUT):\n",
    "    if re.search(pattern, filename):\n",
    "        logs.append(filename)\n",
    "\n",
    "for filename in logs:\n",
    "    path = os.path.join(OUTPUT, filename)\n",
    "    print('\\n-- Log file: %s\\n' % filename)\n",
    "    with open(path, 'r') as f:\n",
    "        message = f.read()\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
