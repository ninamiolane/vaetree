{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import importlib\n",
    "import toylosses\n",
    "importlib.reload(toylosses)\n",
    "import toynn\n",
    "importlib.reload(toynn)\n",
    "import toyvis\n",
    "importlib.reload(toyvis)\n",
    "\n",
    "import torch\n",
    "sns.set()\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "OUTPUT = '/scratch/users/nmiolane/toyoutput'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide on experiment's configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight tensor([[ 0.3000],\n",
      "        [-0.1000]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0.0000, -0.1000], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.3.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.3.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.4.weight tensor([[ 0.2000, -0.2000],\n",
      "        [-0.2000,  0.2000]], device='cuda:0') \n",
      "\n",
      "layers.4.bias tensor([0.1000, 0.4000], device='cuda:0') \n",
      "\n",
      "layers.5.weight tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0') \n",
      "\n",
      "layers.5.bias tensor([0., 0.], device='cuda:0') \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-3.6250390297148876,\n",
       " 3.986330004722148,\n",
       " -3.9641172291304816,\n",
       " 4.599786822648022)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_DIM = 2\n",
    "LATENT_DIM = 1\n",
    "N_DECODER_LAYERS = 5\n",
    "NONLINEARITY = False\n",
    "N_SAMPLES = 10000\n",
    "WITH_BIASX = True\n",
    "WITH_LOGVARX = True\n",
    "\n",
    "W_TRUE = {}\n",
    "B_TRUE = {}\n",
    "\n",
    "W_TRUE[0] = [[0.3], [-0.1]]\n",
    "B_TRUE[0] = [0., -0.1]\n",
    "\n",
    "W_TRUE[1] = [[0.1, -0.1], [-0.1, .1]]\n",
    "B_TRUE[1] = [0.1, 0.]\n",
    "\n",
    "W_TRUE[2] = [[0.1, -0.1], [-0.1, .1]]\n",
    "B_TRUE[2] = [0.1, 0.]\n",
    "\n",
    "W_TRUE[3] = [[0.1, -0.1], [-0.1, .1]]\n",
    "B_TRUE[3] = [0.1, 0.]\n",
    "\n",
    "# For the reconstruction\n",
    "W_TRUE[4] = [[0.2, -0.2], [-0.2, .2]]\n",
    "B_TRUE[4] = [0.1, 0.4]\n",
    "\n",
    "# For the logvarx\n",
    "W_TRUE[5] = [[0., 0.], [0., 0.]]\n",
    "B_TRUE[5] = [0., 0.]\n",
    "\n",
    "if WITH_LOGVARX:\n",
    "    assert len(W_TRUE) == N_DECODER_LAYERS + 1, len(W_TRUE)\n",
    "else:\n",
    "    assert len(W_TRUE) == N_DECODER_LAYERS\n",
    "\n",
    "WITH_BIASZ = True\n",
    "WITH_LOGVARZ = True\n",
    "\n",
    "decoder_true = toynn.make_decoder_true(\n",
    "    w_true=W_TRUE, b_true=B_TRUE, latent_dim=LATENT_DIM, \n",
    "    data_dim=DATA_DIM, n_layers=N_DECODER_LAYERS,\n",
    "    nonlinearity=NONLINEARITY, with_biasx=WITH_BIASX, with_logvarx=WITH_LOGVARX)\n",
    "\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, N_SAMPLES)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = toyvis.plot_data(generated_true_x, color='green', label='from decoder true', ax=ax)\n",
    "ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect generation of synthetic data from decoder_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight tensor([[ 0.3000],\n",
      "        [-0.1000]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0.0000, -0.1000], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.3.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.3.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.4.weight tensor([[ 0.2000, -0.2000],\n",
      "        [-0.2000,  0.2000]], device='cuda:0') \n",
      "\n",
      "layers.4.bias tensor([0.1000, 0.4000], device='cuda:0') \n",
      "\n",
      "layers.5.weight tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0') \n",
      "\n",
      "layers.5.bias tensor([0., 0.], device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(nina): Add a comparison to a FA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results from standard VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[ 0.3000],\n",
      "        [-0.1000]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0.0000, -0.1000], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.3.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.3.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.4.weight tensor([[ 0.2000, -0.2000],\n",
      "        [-0.2000,  0.2000]], device='cuda:0') \n",
      "\n",
      "layers.4.bias tensor([0.1000, 0.4000], device='cuda:0') \n",
      "\n",
      "layers.5.weight tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0') \n",
      "\n",
      "layers.5.bias tensor([0., 0.], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[1.0605],\n",
      "        [0.2283]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([-0.9162, -0.0896], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 0.3157, -0.1862],\n",
      "        [ 0.1614,  0.1583]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([-0.3153,  0.2394], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[-0.3542,  0.4921],\n",
      "        [ 0.8422, -1.1447]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([-0.7002,  0.0099], device='cuda:0') \n",
      "\n",
      "layers.3.weight tensor([[1.5803, 0.7515],\n",
      "        [0.5318, 1.1653]], device='cuda:0') \n",
      "\n",
      "layers.3.bias tensor([-0.3550,  0.0500], device='cuda:0') \n",
      "\n",
      "layers.4.weight tensor([[-0.2555, -1.0835],\n",
      "        [-0.2567, -0.9278]], device='cuda:0') \n",
      "\n",
      "layers.4.bias tensor([-0.6214, -0.2757], device='cuda:0') \n",
      "\n",
      "layers.5.weight tensor([[ 0.3583,  0.9550],\n",
      "        [-0.7191,  0.1592]], device='cuda:0') \n",
      "\n",
      "layers.5.bias tensor([ 0.6998, -0.2296], device='cuda:0') \n",
      "\n",
      "Last losses:\n",
      "[0.08868470603227616, 0.08868665686249733, 0.08868894803524018, 0.08868673780560493, 0.08868110790848732]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "decoder_path = glob.glob(f'{OUTPUT}/train_vae/models/decoder.pth')[0]\n",
    "decoder = torch.load(decoder_path, map_location=DEVICE)\n",
    "\n",
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "losses_vae_path = glob.glob(f'{OUTPUT}/train_vae/train_losses.pkl')[0]\n",
    "train_losses_all_epochs = pickle.load(open(losses_vae_path, 'rb'))\n",
    "\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 4))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(range(n_epochs), train_losses_total)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(range(90, n_epochs), train_losses_total[90:])\n",
    "\n",
    "ax = axes[2]\n",
    "ax.plot(range(160, n_epochs), train_losses_total[160:])\n",
    "\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.6695665396928163, 4.643676752052625, -3.590941607208933, 5.337935022420529)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "\n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)\n",
    "ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results from VEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[ 0.3000],\n",
      "        [-0.1000]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0.0000, -0.1000], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.3.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.3.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.4.weight tensor([[ 0.2000, -0.2000],\n",
      "        [-0.2000,  0.2000]], device='cuda:0') \n",
      "\n",
      "layers.4.bias tensor([0.1000, 0.4000], device='cuda:0') \n",
      "\n",
      "layers.5.weight tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0') \n",
      "\n",
      "layers.5.bias tensor([0., 0.], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[ 1.0349],\n",
      "        [-1.3401]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0.5298, -0.6703], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 0.1810, -0.3287],\n",
      "        [ 1.5811, -0.4596]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([ 0.5552, -0.3759], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 0.0598,  0.3507],\n",
      "        [-1.1746, -0.5854]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([-0.1213,  0.0591], device='cuda:0') \n",
      "\n",
      "layers.3.weight tensor([[ 0.0873,  0.1124],\n",
      "        [-1.0479,  0.6055]], device='cuda:0') \n",
      "\n",
      "layers.3.bias tensor([0.5281, 0.0176], device='cuda:0') \n",
      "\n",
      "layers.4.weight tensor([[-0.3407, -0.1931],\n",
      "        [ 0.8468, -0.1793]], device='cuda:0') \n",
      "\n",
      "layers.4.bias tensor([-0.1494, -0.1237], device='cuda:0') \n",
      "\n",
      "layers.5.weight tensor([[ 0.5350,  0.3326],\n",
      "        [-0.4927, -0.3244]], device='cuda:0') \n",
      "\n",
      "layers.5.bias tensor([0.2400, 0.1101], device='cuda:0') \n",
      "\n",
      "Last losses:\n",
      "[230.70661661177874, 12.3575643055439, 15.677582047820092, 133636.68332380033, 542.4535223715901]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "decoder_path = glob.glob(f'{OUTPUT}/train_vem/models/decoder.pth')[0]\n",
    "decoder = torch.load(decoder_path, map_location=DEVICE)\n",
    "\n",
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "losses_vae_path = glob.glob(f'{OUTPUT}/train_vem/train_losses.pkl')[0]\n",
    "train_losses_all_epochs = pickle.load(open(losses_vae_path, 'rb'))\n",
    "\n",
    "plt.figure()\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "plt.plot(range(n_epochs), train_losses_total)\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.7290472744437118,\n",
       " 4.341764167573562,\n",
       " -4.528576802917074,\n",
       " 6.0650575732260945)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "\n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='orange', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "toyvis.plot_data(generated_x, color='orange', ax=ax)\n",
    "ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print pipeline logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 log files.\n",
      "\n",
      "-- Log file: logs2019-04-09 23:31:33.629344.txt\n",
      "\n",
      "2019-04-09 23:31:33,629 root         INFO     start\n",
      "2019-04-09 23:31:33,644 luigi        INFO     logging configured by default settings\n",
      "2019-04-09 23:31:33,662 luigi-interface DEBUG    Checking if RunAll() is complete\n",
      "2019-04-09 23:31:33,663 luigi-interface DEBUG    Checking if TrainVAE() is complete\n",
      "2019-04-09 23:31:33,663 luigi-interface DEBUG    Checking if TrainVEM() is complete\n",
      "2019-04-09 23:31:33,664 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   PENDING\n",
      "2019-04-09 23:31:33,664 luigi-interface DEBUG    Checking if MakeDataSet() is complete\n",
      "2019-04-09 23:31:33,664 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   PENDING\n",
      "2019-04-09 23:31:33,665 luigi-interface INFO     Informed scheduler that task   MakeDataSet__99914b932b   has status   PENDING\n",
      "2019-04-09 23:31:33,665 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   PENDING\n",
      "2019-04-09 23:31:33,665 luigi-interface INFO     Done scheduling tasks\n",
      "2019-04-09 23:31:33,665 luigi-interface INFO     Running Worker with 1 processes\n",
      "2019-04-09 23:31:33,665 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 23:31:33,665 luigi-interface DEBUG    Pending tasks: 4\n",
      "2019-04-09 23:31:33,665 luigi-interface INFO     [pid 19881] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=19881) running   MakeDataSet()\n",
      "2019-04-09 23:31:33,666 root         INFO     Configuration:\n",
      "2019-04-09 23:31:33,666 root         INFO     DATA_DIM = 2\n",
      "2019-04-09 23:31:33,666 root         INFO     LATENT_DIM = 1\n",
      "2019-04-09 23:31:33,666 root         INFO     N_DECODER_LAYERS = 5\n",
      "2019-04-09 23:31:33,666 root         INFO     NONLINEARITY=False\n",
      "2019-04-09 23:31:33,666 root         INFO     WITH_BIASX=True\n",
      "2019-04-09 23:31:33,666 root         INFO     WITH_LOGVARX=True\n",
      "2019-04-09 23:31:33,666 root         INFO     WITH_BIASZ=True\n",
      "2019-04-09 23:31:33,666 root         INFO     WITH_LOGVARZ=True\n",
      "2019-04-09 23:31:33,666 root         INFO     N_SAMPLES=10000\n",
      "2019-04-09 23:31:33,666 root         INFO     W_TRUE:\n",
      "2019-04-09 23:31:33,666 root         INFO     {0: [[0.3], [-0.1]], 1: [[0.1, -0.1], [-0.1, 0.1]], 2: [[0.1, -0.1], [-0.1, 0.1]], 3: [[0.1, -0.1], [-0.1, 0.1]], 4: [[0.2, -0.2], [-0.2, 0.2]], 5: [[0.0, 0.0], [0.0, 0.0]]}\n",
      "2019-04-09 23:31:33,666 root         INFO     B_TRUE:\n",
      "2019-04-09 23:31:33,666 root         INFO     {0: [0.0, -0.1], 1: [0.1, 0.0], 2: [0.1, 0.0], 3: [0.1, 0.0], 4: [0.1, 0.4], 5: [0.0, 0.0]}\n",
      "2019-04-09 23:31:37,468 root         INFO     Values of true 'decoder' parameters:\n",
      "2019-04-09 23:31:37,468 root         INFO     layers.0.weight\n",
      "2019-04-09 23:31:37,468 root         INFO     tensor([[ 0.3000],\n",
      "        [-0.1000]], device='cuda:0')\n",
      "2019-04-09 23:31:37,488 root         INFO     layers.0.bias\n",
      "2019-04-09 23:31:37,488 root         INFO     tensor([ 0.0000, -0.1000], device='cuda:0')\n",
      "2019-04-09 23:31:37,489 root         INFO     layers.1.weight\n",
      "2019-04-09 23:31:37,489 root         INFO     tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0')\n",
      "2019-04-09 23:31:37,490 root         INFO     layers.1.bias\n",
      "2019-04-09 23:31:37,490 root         INFO     tensor([0.1000, 0.0000], device='cuda:0')\n",
      "2019-04-09 23:31:37,491 root         INFO     layers.2.weight\n",
      "2019-04-09 23:31:37,491 root         INFO     tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0')\n",
      "2019-04-09 23:31:37,493 root         INFO     layers.2.bias\n",
      "2019-04-09 23:31:37,493 root         INFO     tensor([0.1000, 0.0000], device='cuda:0')\n",
      "2019-04-09 23:31:37,494 root         INFO     layers.3.weight\n",
      "2019-04-09 23:31:37,494 root         INFO     tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0')\n",
      "2019-04-09 23:31:37,495 root         INFO     layers.3.bias\n",
      "2019-04-09 23:31:37,495 root         INFO     tensor([0.1000, 0.0000], device='cuda:0')\n",
      "2019-04-09 23:31:37,496 root         INFO     layers.4.weight\n",
      "2019-04-09 23:31:37,496 root         INFO     tensor([[ 0.2000, -0.2000],\n",
      "        [-0.2000,  0.2000]], device='cuda:0')\n",
      "2019-04-09 23:31:37,497 root         INFO     layers.4.bias\n",
      "2019-04-09 23:31:37,497 root         INFO     tensor([0.1000, 0.4000], device='cuda:0')\n",
      "2019-04-09 23:31:37,498 root         INFO     layers.5.weight\n",
      "2019-04-09 23:31:37,498 root         INFO     tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "2019-04-09 23:31:37,499 root         INFO     layers.5.bias\n",
      "2019-04-09 23:31:37,499 root         INFO     tensor([0., 0.], device='cuda:0')\n",
      "2019-04-09 23:31:37,602 luigi-interface INFO     [pid 19881] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=19881) done      MakeDataSet()\n",
      "2019-04-09 23:31:37,602 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 23:31:37,603 luigi-interface INFO     Informed scheduler that task   MakeDataSet__99914b932b   has status   DONE\n",
      "2019-04-09 23:31:37,603 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 23:31:37,603 luigi-interface DEBUG    Pending tasks: 3\n",
      "2019-04-09 23:31:37,603 luigi-interface INFO     [pid 19881] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=19881) running   TrainVEM()\n",
      "2019-04-09 23:31:37,605 root         INFO     --Dataset tensor: (10000, 2)\n",
      "2019-04-09 23:31:37,605 root         INFO     -- Train tensor: (8000, 2)\n",
      "2019-04-09 23:31:37,607 root         INFO     Values of VEM's decoder parameters before training:\n",
      "2019-04-09 23:31:37,607 root         INFO     layers.0.weight\n",
      "2019-04-09 23:31:37,607 root         INFO     tensor([[-0.0526],\n",
      "        [-0.2078]], device='cuda:0')\n",
      "2019-04-09 23:31:37,608 root         INFO     layers.0.bias\n",
      "2019-04-09 23:31:37,608 root         INFO     tensor([ 0.3363, -0.4224], device='cuda:0')\n",
      "2019-04-09 23:31:37,609 root         INFO     layers.1.weight\n",
      "2019-04-09 23:31:37,609 root         INFO     tensor([[ 0.2904, -0.4362],\n",
      "        [-0.2126,  0.5412]], device='cuda:0')\n",
      "2019-04-09 23:31:37,610 root         INFO     layers.1.bias\n",
      "2019-04-09 23:31:37,610 root         INFO     tensor([ 0.0693, -0.5593], device='cuda:0')\n",
      "2019-04-09 23:31:37,612 root         INFO     layers.2.weight\n",
      "2019-04-09 23:31:37,612 root         INFO     tensor([[ 0.4248, -0.4699],\n",
      "        [-0.0456, -0.0020]], device='cuda:0')\n",
      "2019-04-09 23:31:37,613 root         INFO     layers.2.bias\n",
      "2019-04-09 23:31:37,613 root         INFO     tensor([-0.3116,  0.3165], device='cuda:0')\n",
      "2019-04-09 23:31:37,614 root         INFO     layers.3.weight\n",
      "2019-04-09 23:31:37,614 root         INFO     tensor([[-0.0699,  0.3861],\n",
      "        [ 0.3593, -0.5530]], device='cuda:0')\n",
      "2019-04-09 23:31:37,615 root         INFO     layers.3.bias\n",
      "2019-04-09 23:31:37,615 root         INFO     tensor([0.5281, 0.0176], device='cuda:0')\n",
      "2019-04-09 23:31:37,616 root         INFO     layers.4.weight\n",
      "2019-04-09 23:31:37,616 root         INFO     tensor([[ 0.5583,  0.4401],\n",
      "        [-0.2079, -0.1400]], device='cuda:0')\n",
      "2019-04-09 23:31:37,617 root         INFO     layers.4.bias\n",
      "2019-04-09 23:31:37,617 root         INFO     tensor([-0.2586, -0.3348], device='cuda:0')\n",
      "2019-04-09 23:31:37,618 root         INFO     layers.5.weight\n",
      "2019-04-09 23:31:37,618 root         INFO     tensor([[0.5477, 0.6593],\n",
      "        [0.3130, 0.6352]], device='cuda:0')\n",
      "2019-04-09 23:31:37,619 root         INFO     layers.5.bias\n",
      "2019-04-09 23:31:37,620 root         INFO     tensor([0.2400, 0.1101], device='cuda:0')\n",
      "2019-04-09 23:31:37,687 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 0.452545\n",
      "Reconstruction: 0.268352, Regularization: 0.079998, Discriminator: 0.042484; Generator: 0.061711,\n",
      "D(x): 0.378, D(G(z)): 0.197\n",
      "2019-04-09 23:31:37,798 root         INFO     Train Epoch: 0 [512/8000 (6%)]\tTotal Loss: 0.518051\n",
      "Reconstruction: 0.341114, Regularization: 0.084019, Discriminator: 0.048759; Generator: 0.044159,\n",
      "D(x): 0.388, D(G(z)): 0.336\n",
      "2019-04-09 23:31:37,908 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 0.368837\n",
      "Reconstruction: 0.190420, Regularization: 0.070716, Discriminator: 0.050508; Generator: 0.057194,\n",
      "D(x): 0.326, D(G(z)): 0.276\n",
      "2019-04-09 23:31:38,020 root         INFO     Train Epoch: 0 [1536/8000 (19%)]\tTotal Loss: 0.505424\n",
      "Reconstruction: 0.322757, Regularization: 0.075845, Discriminator: 0.051826; Generator: 0.054996,\n",
      "D(x): 0.323, D(G(z)): 0.270\n",
      "2019-04-09 23:31:38,130 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 0.339095\n",
      "Reconstruction: 0.179969, Regularization: 0.062744, Discriminator: 0.046903; Generator: 0.049478,\n",
      "D(x): 0.378, D(G(z)): 0.296\n",
      "2019-04-09 23:31:38,241 root         INFO     Train Epoch: 0 [2560/8000 (32%)]\tTotal Loss: 0.344618\n",
      "Reconstruction: 0.187591, Regularization: 0.057360, Discriminator: 0.049196; Generator: 0.050471,\n",
      "D(x): 0.346, D(G(z)): 0.296\n",
      "2019-04-09 23:31:38,351 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 0.405780\n",
      "Reconstruction: 0.256994, Regularization: 0.043863, Discriminator: 0.046572; Generator: 0.058352,\n",
      "D(x): 0.348, D(G(z)): 0.248\n",
      "2019-04-09 23:31:38,462 root         INFO     Train Epoch: 0 [3584/8000 (45%)]\tTotal Loss: 0.842882\n",
      "Reconstruction: 0.643841, Regularization: 0.093926, Discriminator: 0.047416; Generator: 0.057699,\n",
      "D(x): 0.355, D(G(z)): 0.250\n",
      "2019-04-09 23:31:38,573 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 0.633238\n",
      "Reconstruction: 0.389042, Regularization: 0.142898, Discriminator: 0.047402; Generator: 0.053897,\n",
      "D(x): 0.332, D(G(z)): 0.230\n",
      "2019-04-09 23:31:38,684 root         INFO     Train Epoch: 0 [4608/8000 (58%)]\tTotal Loss: 0.684921\n",
      "Reconstruction: 0.509671, Regularization: 0.074167, Discriminator: 0.052732; Generator: 0.048351,\n",
      "D(x): 0.330, D(G(z)): 0.308\n",
      "2019-04-09 23:31:38,795 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 0.638380\n",
      "Reconstruction: 0.412211, Regularization: 0.129961, Discriminator: 0.050803; Generator: 0.045405,\n",
      "D(x): 0.329, D(G(z)): 0.301\n",
      "2019-04-09 23:31:38,905 root         INFO     Train Epoch: 0 [5632/8000 (70%)]\tTotal Loss: 0.327732\n",
      "Reconstruction: 0.181540, Regularization: 0.049992, Discriminator: 0.047220; Generator: 0.048980,\n",
      "D(x): 0.370, D(G(z)): 0.299\n",
      "2019-04-09 23:31:39,016 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 0.259026\n",
      "Reconstruction: 0.122314, Regularization: 0.042025, Discriminator: 0.050495; Generator: 0.044192,\n",
      "D(x): 0.348, D(G(z)): 0.326\n",
      "2019-04-09 23:31:39,126 root         INFO     Train Epoch: 0 [6656/8000 (83%)]\tTotal Loss: 1.108407\n",
      "Reconstruction: 0.786095, Regularization: 0.232334, Discriminator: 0.048461; Generator: 0.041517,\n",
      "D(x): 0.385, D(G(z)): 0.345\n",
      "2019-04-09 23:31:39,235 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 1.628769\n",
      "Reconstruction: 1.394343, Regularization: 0.134368, Discriminator: 0.053246; Generator: 0.046812,\n",
      "D(x): 0.306, D(G(z)): 0.308\n",
      "2019-04-09 23:31:39,344 root         INFO     Train Epoch: 0 [7680/8000 (96%)]\tTotal Loss: 0.357447\n",
      "Reconstruction: 0.161389, Regularization: 0.099438, Discriminator: 0.048060; Generator: 0.048562,\n",
      "D(x): 0.373, D(G(z)): 0.324\n",
      "2019-04-09 23:31:39,424 root         INFO     ====> Epoch: 0 Average loss: 1.2491\n",
      "2019-04-09 23:31:39,450 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 0.385891\n",
      "Reconstruction: 0.245420, Regularization: 0.050140, Discriminator: 0.047176; Generator: 0.043155,\n",
      "D(x): 0.361, D(G(z)): 0.312\n",
      "2019-04-09 23:31:39,564 root         INFO     Train Epoch: 1 [512/8000 (6%)]\tTotal Loss: 2.243748\n",
      "Reconstruction: 2.062491, Regularization: 0.087347, Discriminator: 0.047954; Generator: 0.045956,\n",
      "D(x): 0.363, D(G(z)): 0.294\n",
      "2019-04-09 23:31:39,675 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 0.455281\n",
      "Reconstruction: 0.303046, Regularization: 0.061928, Discriminator: 0.046724; Generator: 0.043584,\n",
      "D(x): 0.358, D(G(z)): 0.304\n",
      "2019-04-09 23:31:39,787 root         INFO     Train Epoch: 1 [1536/8000 (19%)]\tTotal Loss: 0.266431\n",
      "Reconstruction: 0.136982, Regularization: 0.038117, Discriminator: 0.041103; Generator: 0.050230,\n",
      "D(x): 0.392, D(G(z)): 0.251\n",
      "2019-04-09 23:31:39,899 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 0.448416\n",
      "Reconstruction: 0.273423, Regularization: 0.083125, Discriminator: 0.045500; Generator: 0.046367,\n",
      "D(x): 0.386, D(G(z)): 0.303\n",
      "2019-04-09 23:31:40,011 root         INFO     Train Epoch: 1 [2560/8000 (32%)]\tTotal Loss: 0.517135\n",
      "Reconstruction: 0.388003, Regularization: 0.041659, Discriminator: 0.044660; Generator: 0.042813,\n",
      "D(x): 0.400, D(G(z)): 0.321\n",
      "2019-04-09 23:31:40,123 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 0.383232\n",
      "Reconstruction: 0.239654, Regularization: 0.056140, Discriminator: 0.047813; Generator: 0.039625,\n",
      "D(x): 0.393, D(G(z)): 0.362\n",
      "2019-04-09 23:31:40,235 root         INFO     Train Epoch: 1 [3584/8000 (45%)]\tTotal Loss: 0.501073\n",
      "Reconstruction: 0.365790, Regularization: 0.046776, Discriminator: 0.049086; Generator: 0.039421,\n",
      "D(x): 0.355, D(G(z)): 0.342\n",
      "2019-04-09 23:31:40,347 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 0.591017\n",
      "Reconstruction: 0.289730, Regularization: 0.210976, Discriminator: 0.049018; Generator: 0.041293,\n",
      "D(x): 0.355, D(G(z)): 0.318\n",
      "2019-04-09 23:31:40,458 root         INFO     Train Epoch: 1 [4608/8000 (58%)]\tTotal Loss: 0.509709\n",
      "Reconstruction: 0.328154, Regularization: 0.087068, Discriminator: 0.045065; Generator: 0.049422,\n",
      "D(x): 0.372, D(G(z)): 0.286\n",
      "2019-04-09 23:31:40,568 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 0.476462\n",
      "Reconstruction: 0.320361, Regularization: 0.070865, Discriminator: 0.052708; Generator: 0.032528,\n",
      "D(x): 0.365, D(G(z)): 0.413\n",
      "2019-04-09 23:31:40,679 root         INFO     Train Epoch: 1 [5632/8000 (70%)]\tTotal Loss: 0.291895\n",
      "Reconstruction: 0.147606, Regularization: 0.057462, Discriminator: 0.047082; Generator: 0.039745,\n",
      "D(x): 0.395, D(G(z)): 0.354\n",
      "2019-04-09 23:31:40,790 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 0.646239\n",
      "Reconstruction: 0.444920, Regularization: 0.115172, Discriminator: 0.045484; Generator: 0.040663,\n",
      "D(x): 0.369, D(G(z)): 0.309\n",
      "2019-04-09 23:31:40,901 root         INFO     Train Epoch: 1 [6656/8000 (83%)]\tTotal Loss: 0.286385\n",
      "Reconstruction: 0.123466, Regularization: 0.076027, Discriminator: 0.049733; Generator: 0.037159,\n",
      "D(x): 0.389, D(G(z)): 0.394\n",
      "2019-04-09 23:31:41,012 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 1.221420\n",
      "Reconstruction: 1.048649, Regularization: 0.082343, Discriminator: 0.045951; Generator: 0.044476,\n",
      "D(x): 0.351, D(G(z)): 0.286\n",
      "2019-04-09 23:31:41,122 root         INFO     Train Epoch: 1 [7680/8000 (96%)]\tTotal Loss: 0.435863\n",
      "Reconstruction: 0.271538, Regularization: 0.076351, Discriminator: 0.046777; Generator: 0.041197,\n",
      "D(x): 0.401, D(G(z)): 0.351\n",
      "2019-04-09 23:31:41,203 root         INFO     ====> Epoch: 1 Average loss: 0.8827\n",
      "2019-04-09 23:31:41,230 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 0.225762\n",
      "Reconstruction: 0.110314, Regularization: 0.034997, Discriminator: 0.041319; Generator: 0.039132,\n",
      "D(x): 0.446, D(G(z)): 0.342\n",
      "2019-04-09 23:31:41,342 root         INFO     Train Epoch: 2 [512/8000 (6%)]\tTotal Loss: 0.616968\n",
      "Reconstruction: 0.217157, Regularization: 0.311821, Discriminator: 0.040233; Generator: 0.047756,\n",
      "D(x): 0.411, D(G(z)): 0.259\n",
      "2019-04-09 23:31:41,454 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 0.612196\n",
      "Reconstruction: 0.385633, Regularization: 0.139589, Discriminator: 0.044260; Generator: 0.042714,\n",
      "D(x): 0.408, D(G(z)): 0.312\n",
      "2019-04-09 23:31:41,565 root         INFO     Train Epoch: 2 [1536/8000 (19%)]\tTotal Loss: 0.243025\n",
      "Reconstruction: 0.114251, Regularization: 0.044955, Discriminator: 0.037933; Generator: 0.045886,\n",
      "D(x): 0.450, D(G(z)): 0.284\n",
      "2019-04-09 23:31:41,675 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 0.328979\n",
      "Reconstruction: 0.197142, Regularization: 0.046271, Discriminator: 0.046320; Generator: 0.039247,\n",
      "D(x): 0.379, D(G(z)): 0.341\n",
      "2019-04-09 23:31:41,785 root         INFO     Train Epoch: 2 [2560/8000 (32%)]\tTotal Loss: 1.084909\n",
      "Reconstruction: 0.825785, Regularization: 0.177789, Discriminator: 0.049159; Generator: 0.032175,\n",
      "D(x): 0.410, D(G(z)): 0.411\n",
      "2019-04-09 23:31:41,895 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 0.339260\n",
      "Reconstruction: 0.196437, Regularization: 0.062618, Discriminator: 0.045321; Generator: 0.034884,\n",
      "D(x): 0.439, D(G(z)): 0.394\n",
      "2019-04-09 23:31:42,005 root         INFO     Train Epoch: 2 [3584/8000 (45%)]\tTotal Loss: 0.487043\n",
      "Reconstruction: 0.341075, Regularization: 0.064086, Discriminator: 0.038146; Generator: 0.043735,\n",
      "D(x): 0.446, D(G(z)): 0.292\n",
      "2019-04-09 23:31:42,117 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 0.258790\n",
      "Reconstruction: 0.113494, Regularization: 0.066657, Discriminator: 0.041280; Generator: 0.037358,\n",
      "D(x): 0.445, D(G(z)): 0.350\n",
      "2019-04-09 23:31:42,230 root         INFO     Train Epoch: 2 [4608/8000 (58%)]\tTotal Loss: 1.591895\n",
      "Reconstruction: 1.402690, Regularization: 0.108088, Discriminator: 0.043198; Generator: 0.037920,\n",
      "D(x): 0.443, D(G(z)): 0.347\n",
      "2019-04-09 23:31:42,341 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 0.290222\n",
      "Reconstruction: 0.145917, Regularization: 0.067676, Discriminator: 0.043242; Generator: 0.033388,\n",
      "D(x): 0.444, D(G(z)): 0.383\n",
      "2019-04-09 23:31:42,449 root         INFO     Train Epoch: 2 [5632/8000 (70%)]\tTotal Loss: 0.304729\n",
      "Reconstruction: 0.156525, Regularization: 0.064082, Discriminator: 0.041681; Generator: 0.042441,\n",
      "D(x): 0.415, D(G(z)): 0.310\n",
      "2019-04-09 23:31:42,562 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 3.812392\n",
      "Reconstruction: 3.633723, Regularization: 0.099927, Discriminator: 0.045252; Generator: 0.033490,\n",
      "D(x): 0.432, D(G(z)): 0.382\n",
      "2019-04-09 23:31:42,675 root         INFO     Train Epoch: 2 [6656/8000 (83%)]\tTotal Loss: 0.277499\n",
      "Reconstruction: 0.145847, Regularization: 0.050536, Discriminator: 0.042481; Generator: 0.038634,\n",
      "D(x): 0.434, D(G(z)): 0.349\n",
      "2019-04-09 23:31:42,786 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 0.757288\n",
      "Reconstruction: 0.629082, Regularization: 0.052109, Discriminator: 0.042728; Generator: 0.033369,\n",
      "D(x): 0.446, D(G(z)): 0.377\n",
      "2019-04-09 23:31:42,894 root         INFO     Train Epoch: 2 [7680/8000 (96%)]\tTotal Loss: 0.428318\n",
      "Reconstruction: 0.238729, Regularization: 0.111204, Discriminator: 0.046556; Generator: 0.031830,\n",
      "D(x): 0.424, D(G(z)): 0.397\n",
      "2019-04-09 23:31:42,973 root         INFO     ====> Epoch: 2 Average loss: 0.8244\n",
      "2019-04-09 23:31:42,999 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 0.250070\n",
      "Reconstruction: 0.149618, Regularization: 0.025091, Discriminator: 0.036933; Generator: 0.038428,\n",
      "D(x): 0.470, D(G(z)): 0.318\n",
      "2019-04-09 23:31:43,113 root         INFO     Train Epoch: 3 [512/8000 (6%)]\tTotal Loss: 0.303730\n",
      "Reconstruction: 0.187961, Regularization: 0.034988, Discriminator: 0.042107; Generator: 0.038674,\n",
      "D(x): 0.429, D(G(z)): 0.346\n",
      "2019-04-09 23:31:43,225 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 0.290378\n",
      "Reconstruction: 0.160028, Regularization: 0.053114, Discriminator: 0.041101; Generator: 0.036136,\n",
      "D(x): 0.450, D(G(z)): 0.352\n",
      "2019-04-09 23:31:43,337 root         INFO     Train Epoch: 3 [1536/8000 (19%)]\tTotal Loss: 0.859661\n",
      "Reconstruction: 0.690769, Regularization: 0.085161, Discriminator: 0.045173; Generator: 0.038558,\n",
      "D(x): 0.395, D(G(z)): 0.339\n",
      "2019-04-09 23:31:43,450 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 0.288836\n",
      "Reconstruction: 0.153642, Regularization: 0.056008, Discriminator: 0.038651; Generator: 0.040535,\n",
      "D(x): 0.456, D(G(z)): 0.307\n",
      "2019-04-09 23:31:43,562 root         INFO     Train Epoch: 3 [2560/8000 (32%)]\tTotal Loss: 0.283048\n",
      "Reconstruction: 0.153969, Regularization: 0.051933, Discriminator: 0.041977; Generator: 0.035169,\n",
      "D(x): 0.437, D(G(z)): 0.361\n",
      "2019-04-09 23:31:43,675 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 0.278330\n",
      "Reconstruction: 0.151997, Regularization: 0.049215, Discriminator: 0.043930; Generator: 0.033189,\n",
      "D(x): 0.449, D(G(z)): 0.394\n",
      "2019-04-09 23:31:43,786 root         INFO     Train Epoch: 3 [3584/8000 (45%)]\tTotal Loss: 0.340036\n",
      "Reconstruction: 0.212322, Regularization: 0.049669, Discriminator: 0.040332; Generator: 0.037714,\n",
      "D(x): 0.467, D(G(z)): 0.351\n",
      "2019-04-09 23:31:43,896 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 0.357346\n",
      "Reconstruction: 0.196519, Regularization: 0.083549, Discriminator: 0.043245; Generator: 0.034034,\n",
      "D(x): 0.458, D(G(z)): 0.387\n",
      "2019-04-09 23:31:44,007 root         INFO     Train Epoch: 3 [4608/8000 (58%)]\tTotal Loss: 0.446231\n",
      "Reconstruction: 0.312008, Regularization: 0.058201, Discriminator: 0.041679; Generator: 0.034343,\n",
      "D(x): 0.455, D(G(z)): 0.372\n",
      "2019-04-09 23:31:44,117 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 0.471774\n",
      "Reconstruction: 0.271978, Regularization: 0.122356, Discriminator: 0.046290; Generator: 0.031151,\n",
      "D(x): 0.424, D(G(z)): 0.408\n",
      "2019-04-09 23:31:44,227 root         INFO     Train Epoch: 3 [5632/8000 (70%)]\tTotal Loss: 0.400068\n",
      "Reconstruction: 0.238187, Regularization: 0.085546, Discriminator: 0.046801; Generator: 0.029533,\n",
      "D(x): 0.424, D(G(z)): 0.420\n",
      "2019-04-09 23:31:44,339 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 0.278504\n",
      "Reconstruction: 0.153042, Regularization: 0.050548, Discriminator: 0.041148; Generator: 0.033766,\n",
      "D(x): 0.475, D(G(z)): 0.383\n",
      "2019-04-09 23:31:44,451 root         INFO     Train Epoch: 3 [6656/8000 (83%)]\tTotal Loss: 0.355941\n",
      "Reconstruction: 0.217941, Regularization: 0.062150, Discriminator: 0.040801; Generator: 0.035049,\n",
      "D(x): 0.463, D(G(z)): 0.365\n",
      "2019-04-09 23:31:44,564 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 0.277833\n",
      "Reconstruction: 0.154795, Regularization: 0.044353, Discriminator: 0.043117; Generator: 0.035568,\n",
      "D(x): 0.439, D(G(z)): 0.372\n",
      "2019-04-09 23:31:44,676 root         INFO     Train Epoch: 3 [7680/8000 (96%)]\tTotal Loss: 2.054355\n",
      "Reconstruction: 1.780962, Regularization: 0.197980, Discriminator: 0.044039; Generator: 0.031373,\n",
      "D(x): 0.449, D(G(z)): 0.401\n",
      "2019-04-09 23:31:44,757 root         INFO     ====> Epoch: 3 Average loss: 0.4235\n",
      "2019-04-09 23:31:44,784 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 0.248904\n",
      "Reconstruction: 0.137213, Regularization: 0.039336, Discriminator: 0.037880; Generator: 0.034474,\n",
      "D(x): 0.490, D(G(z)): 0.356\n",
      "2019-04-09 23:31:44,898 root         INFO     Train Epoch: 4 [512/8000 (6%)]\tTotal Loss: 0.345359\n",
      "Reconstruction: 0.233904, Regularization: 0.040657, Discriminator: 0.040992; Generator: 0.029806,\n",
      "D(x): 0.492, D(G(z)): 0.412\n",
      "2019-04-09 23:31:45,010 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 0.256387\n",
      "Reconstruction: 0.129011, Regularization: 0.054932, Discriminator: 0.040552; Generator: 0.031893,\n",
      "D(x): 0.474, D(G(z)): 0.386\n",
      "2019-04-09 23:31:45,122 root         INFO     Train Epoch: 4 [1536/8000 (19%)]\tTotal Loss: 0.952585\n",
      "Reconstruction: 0.753787, Regularization: 0.125971, Discriminator: 0.043115; Generator: 0.029712,\n",
      "D(x): 0.467, D(G(z)): 0.417\n",
      "2019-04-09 23:31:45,234 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 0.265226\n",
      "Reconstruction: 0.115750, Regularization: 0.078970, Discriminator: 0.038315; Generator: 0.032192,\n",
      "D(x): 0.503, D(G(z)): 0.379\n",
      "2019-04-09 23:31:45,346 root         INFO     Train Epoch: 4 [2560/8000 (32%)]\tTotal Loss: 0.248672\n",
      "Reconstruction: 0.133918, Regularization: 0.041509, Discriminator: 0.044093; Generator: 0.029152,\n",
      "D(x): 0.480, D(G(z)): 0.441\n",
      "2019-04-09 23:31:45,456 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 0.450979\n",
      "Reconstruction: 0.248045, Regularization: 0.126250, Discriminator: 0.047932; Generator: 0.028753,\n",
      "D(x): 0.430, D(G(z)): 0.438\n",
      "2019-04-09 23:31:45,567 root         INFO     Train Epoch: 4 [3584/8000 (45%)]\tTotal Loss: 0.676161\n",
      "Reconstruction: 0.496211, Regularization: 0.106989, Discriminator: 0.040942; Generator: 0.032019,\n",
      "D(x): 0.479, D(G(z)): 0.399\n",
      "2019-04-09 23:31:45,676 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 0.251183\n",
      "Reconstruction: 0.124330, Regularization: 0.054682, Discriminator: 0.043582; Generator: 0.028589,\n",
      "D(x): 0.470, D(G(z)): 0.430\n",
      "2019-04-09 23:31:45,787 root         INFO     Train Epoch: 4 [4608/8000 (58%)]\tTotal Loss: 0.264760\n",
      "Reconstruction: 0.150298, Regularization: 0.041830, Discriminator: 0.040550; Generator: 0.032081,\n",
      "D(x): 0.464, D(G(z)): 0.381\n",
      "2019-04-09 23:31:45,897 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 0.256899\n",
      "Reconstruction: 0.158250, Regularization: 0.028249, Discriminator: 0.043406; Generator: 0.026995,\n",
      "D(x): 0.489, D(G(z)): 0.453\n",
      "2019-04-09 23:31:46,007 root         INFO     Train Epoch: 4 [5632/8000 (70%)]\tTotal Loss: 0.342656\n",
      "Reconstruction: 0.178346, Regularization: 0.091709, Discriminator: 0.039773; Generator: 0.032827,\n",
      "D(x): 0.478, D(G(z)): 0.374\n",
      "2019-04-09 23:31:46,117 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 0.237405\n",
      "Reconstruction: 0.120742, Regularization: 0.044863, Discriminator: 0.042180; Generator: 0.029620,\n",
      "D(x): 0.489, D(G(z)): 0.424\n",
      "2019-04-09 23:31:46,227 root         INFO     Train Epoch: 4 [6656/8000 (83%)]\tTotal Loss: 0.250599\n",
      "Reconstruction: 0.144305, Regularization: 0.033604, Discriminator: 0.042007; Generator: 0.030682,\n",
      "D(x): 0.465, D(G(z)): 0.402\n",
      "2019-04-09 23:31:46,338 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 0.270872\n",
      "Reconstruction: 0.139456, Regularization: 0.060710, Discriminator: 0.042739; Generator: 0.027967,\n",
      "D(x): 0.489, D(G(z)): 0.438\n",
      "2019-04-09 23:31:46,449 root         INFO     Train Epoch: 4 [7680/8000 (96%)]\tTotal Loss: 0.334377\n",
      "Reconstruction: 0.208007, Regularization: 0.055150, Discriminator: 0.039748; Generator: 0.031472,\n",
      "D(x): 0.494, D(G(z)): 0.395\n",
      "2019-04-09 23:31:46,530 root         INFO     ====> Epoch: 4 Average loss: 0.5079\n",
      "2019-04-09 23:31:46,557 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 0.282218\n",
      "Reconstruction: 0.151337, Regularization: 0.061208, Discriminator: 0.043018; Generator: 0.026655,\n",
      "D(x): 0.497, D(G(z)): 0.452\n",
      "2019-04-09 23:31:46,670 root         INFO     Train Epoch: 5 [512/8000 (6%)]\tTotal Loss: 0.336053\n",
      "Reconstruction: 0.213574, Regularization: 0.050646, Discriminator: 0.042497; Generator: 0.029336,\n",
      "D(x): 0.477, D(G(z)): 0.423\n",
      "2019-04-09 23:31:46,783 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 0.242219\n",
      "Reconstruction: 0.121797, Regularization: 0.049937, Discriminator: 0.041922; Generator: 0.028564,\n",
      "D(x): 0.487, D(G(z)): 0.428\n",
      "2019-04-09 23:31:46,895 root         INFO     Train Epoch: 5 [1536/8000 (19%)]\tTotal Loss: 0.464787\n",
      "Reconstruction: 0.286635, Regularization: 0.105385, Discriminator: 0.043232; Generator: 0.029535,\n",
      "D(x): 0.466, D(G(z)): 0.419\n",
      "2019-04-09 23:31:47,006 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 0.242160\n",
      "Reconstruction: 0.140886, Regularization: 0.034274, Discriminator: 0.040992; Generator: 0.026009,\n",
      "D(x): 0.536, D(G(z)): 0.464\n",
      "2019-04-09 23:31:47,117 root         INFO     Train Epoch: 5 [2560/8000 (32%)]\tTotal Loss: 0.284596\n",
      "Reconstruction: 0.152647, Regularization: 0.062123, Discriminator: 0.041505; Generator: 0.028321,\n",
      "D(x): 0.504, D(G(z)): 0.438\n",
      "2019-04-09 23:31:47,230 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 0.229692\n",
      "Reconstruction: 0.120169, Regularization: 0.040179, Discriminator: 0.037508; Generator: 0.031836,\n",
      "D(x): 0.512, D(G(z)): 0.382\n",
      "2019-04-09 23:31:47,342 root         INFO     Train Epoch: 5 [3584/8000 (45%)]\tTotal Loss: 0.212778\n",
      "Reconstruction: 0.111069, Regularization: 0.035556, Discriminator: 0.040268; Generator: 0.025885,\n",
      "D(x): 0.544, D(G(z)): 0.464\n",
      "2019-04-09 23:31:47,453 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 0.219126\n",
      "Reconstruction: 0.125249, Regularization: 0.025987, Discriminator: 0.040721; Generator: 0.027168,\n",
      "D(x): 0.525, D(G(z)): 0.449\n",
      "2019-04-09 23:31:47,565 root         INFO     Train Epoch: 5 [4608/8000 (58%)]\tTotal Loss: 0.298660\n",
      "Reconstruction: 0.154665, Regularization: 0.076508, Discriminator: 0.041821; Generator: 0.025665,\n",
      "D(x): 0.505, D(G(z)): 0.452\n",
      "2019-04-09 23:31:47,673 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 0.249749\n",
      "Reconstruction: 0.140776, Regularization: 0.040446, Discriminator: 0.043748; Generator: 0.024779,\n",
      "D(x): 0.499, D(G(z)): 0.475\n",
      "2019-04-09 23:31:47,782 root         INFO     Train Epoch: 5 [5632/8000 (70%)]\tTotal Loss: 0.273890\n",
      "Reconstruction: 0.175792, Regularization: 0.032302, Discriminator: 0.038431; Generator: 0.027365,\n",
      "D(x): 0.556, D(G(z)): 0.438\n",
      "2019-04-09 23:31:47,891 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 0.318946\n",
      "Reconstruction: 0.138089, Regularization: 0.110328, Discriminator: 0.042421; Generator: 0.028109,\n",
      "D(x): 0.482, D(G(z)): 0.428\n",
      "2019-04-09 23:31:48,000 root         INFO     Train Epoch: 5 [6656/8000 (83%)]\tTotal Loss: 0.253582\n",
      "Reconstruction: 0.118106, Regularization: 0.070033, Discriminator: 0.037701; Generator: 0.027743,\n",
      "D(x): 0.551, D(G(z)): 0.430\n",
      "2019-04-09 23:31:48,109 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 0.445471\n",
      "Reconstruction: 0.207032, Regularization: 0.170851, Discriminator: 0.043886; Generator: 0.023701,\n",
      "D(x): 0.516, D(G(z)): 0.488\n",
      "2019-04-09 23:31:48,218 root         INFO     Train Epoch: 5 [7680/8000 (96%)]\tTotal Loss: 0.264363\n",
      "Reconstruction: 0.147515, Regularization: 0.050875, Discriminator: 0.036687; Generator: 0.029287,\n",
      "D(x): 0.545, D(G(z)): 0.406\n",
      "2019-04-09 23:31:48,297 root         INFO     ====> Epoch: 5 Average loss: 0.4256\n",
      "2019-04-09 23:31:48,324 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 0.306437\n",
      "Reconstruction: 0.180917, Regularization: 0.057409, Discriminator: 0.042922; Generator: 0.025189,\n",
      "D(x): 0.498, D(G(z)): 0.462\n",
      "2019-04-09 23:31:48,436 root         INFO     Train Epoch: 6 [512/8000 (6%)]\tTotal Loss: 0.438778\n",
      "Reconstruction: 0.243194, Regularization: 0.125422, Discriminator: 0.044979; Generator: 0.025183,\n",
      "D(x): 0.498, D(G(z)): 0.479\n",
      "2019-04-09 23:31:48,547 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 0.487242\n",
      "Reconstruction: 0.262636, Regularization: 0.153716, Discriminator: 0.044971; Generator: 0.025919,\n",
      "D(x): 0.476, D(G(z)): 0.464\n",
      "2019-04-09 23:31:48,657 root         INFO     Train Epoch: 6 [1536/8000 (19%)]\tTotal Loss: 0.365548\n",
      "Reconstruction: 0.207729, Regularization: 0.088378, Discriminator: 0.044753; Generator: 0.024688,\n",
      "D(x): 0.484, D(G(z)): 0.472\n",
      "2019-04-09 23:31:48,768 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 0.331988\n",
      "Reconstruction: 0.173929, Regularization: 0.089941, Discriminator: 0.041045; Generator: 0.027073,\n",
      "D(x): 0.498, D(G(z)): 0.435\n",
      "2019-04-09 23:31:48,879 root         INFO     Train Epoch: 6 [2560/8000 (32%)]\tTotal Loss: 0.402246\n",
      "Reconstruction: 0.236647, Regularization: 0.095127, Discriminator: 0.044411; Generator: 0.026062,\n",
      "D(x): 0.483, D(G(z)): 0.460\n",
      "2019-04-09 23:31:48,989 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 0.329919\n",
      "Reconstruction: 0.192322, Regularization: 0.072107, Discriminator: 0.042092; Generator: 0.023399,\n",
      "D(x): 0.530, D(G(z)): 0.486\n",
      "2019-04-09 23:31:49,101 root         INFO     Train Epoch: 6 [3584/8000 (45%)]\tTotal Loss: 0.318148\n",
      "Reconstruction: 0.214531, Regularization: 0.035702, Discriminator: 0.042972; Generator: 0.024943,\n",
      "D(x): 0.492, D(G(z)): 0.465\n",
      "2019-04-09 23:31:49,212 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 0.189213\n",
      "Reconstruction: 0.089701, Regularization: 0.033830, Discriminator: 0.041531; Generator: 0.024152,\n",
      "D(x): 0.533, D(G(z)): 0.480\n",
      "2019-04-09 23:31:49,323 root         INFO     Train Epoch: 6 [4608/8000 (58%)]\tTotal Loss: 0.363115\n",
      "Reconstruction: 0.222936, Regularization: 0.073167, Discriminator: 0.041956; Generator: 0.025056,\n",
      "D(x): 0.520, D(G(z)): 0.466\n",
      "2019-04-09 23:31:49,434 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 0.522534\n",
      "Reconstruction: 0.383603, Regularization: 0.071849, Discriminator: 0.042555; Generator: 0.024528,\n",
      "D(x): 0.509, D(G(z)): 0.471\n",
      "2019-04-09 23:31:49,546 root         INFO     Train Epoch: 6 [5632/8000 (70%)]\tTotal Loss: 0.293570\n",
      "Reconstruction: 0.170624, Regularization: 0.056639, Discriminator: 0.039826; Generator: 0.026480,\n",
      "D(x): 0.536, D(G(z)): 0.449\n",
      "2019-04-09 23:31:49,657 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 0.461096\n",
      "Reconstruction: 0.276688, Regularization: 0.117605, Discriminator: 0.040485; Generator: 0.026317,\n",
      "D(x): 0.517, D(G(z)): 0.444\n",
      "2019-04-09 23:31:49,767 root         INFO     Train Epoch: 6 [6656/8000 (83%)]\tTotal Loss: 0.535753\n",
      "Reconstruction: 0.261989, Regularization: 0.205503, Discriminator: 0.041970; Generator: 0.026291,\n",
      "D(x): 0.504, D(G(z)): 0.451\n",
      "2019-04-09 23:31:49,879 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 0.242927\n",
      "Reconstruction: 0.124515, Regularization: 0.049753, Discriminator: 0.044324; Generator: 0.024336,\n",
      "D(x): 0.493, D(G(z)): 0.479\n",
      "2019-04-09 23:31:49,989 root         INFO     Train Epoch: 6 [7680/8000 (96%)]\tTotal Loss: 0.268103\n",
      "Reconstruction: 0.154681, Regularization: 0.046415, Discriminator: 0.038907; Generator: 0.028101,\n",
      "D(x): 0.525, D(G(z)): 0.427\n",
      "2019-04-09 23:31:50,069 root         INFO     ====> Epoch: 6 Average loss: 0.3902\n",
      "2019-04-09 23:31:50,096 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 0.543241\n",
      "Reconstruction: 0.295962, Regularization: 0.179998, Discriminator: 0.040415; Generator: 0.026865,\n",
      "D(x): 0.524, D(G(z)): 0.443\n",
      "2019-04-09 23:31:50,208 root         INFO     Train Epoch: 7 [512/8000 (6%)]\tTotal Loss: 0.297301\n",
      "Reconstruction: 0.155303, Regularization: 0.074405, Discriminator: 0.041339; Generator: 0.026254,\n",
      "D(x): 0.513, D(G(z)): 0.452\n",
      "2019-04-09 23:31:50,319 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 0.291433\n",
      "Reconstruction: 0.187702, Regularization: 0.036004, Discriminator: 0.042717; Generator: 0.025011,\n",
      "D(x): 0.499, D(G(z)): 0.465\n",
      "2019-04-09 23:31:50,430 root         INFO     Train Epoch: 7 [1536/8000 (19%)]\tTotal Loss: 0.283233\n",
      "Reconstruction: 0.129860, Regularization: 0.084313, Discriminator: 0.043227; Generator: 0.025833,\n",
      "D(x): 0.479, D(G(z)): 0.453\n",
      "2019-04-09 23:31:50,541 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 0.835397\n",
      "Reconstruction: 0.642531, Regularization: 0.124769, Discriminator: 0.042901; Generator: 0.025196,\n",
      "D(x): 0.495, D(G(z)): 0.459\n",
      "2019-04-09 23:31:50,652 root         INFO     Train Epoch: 7 [2560/8000 (32%)]\tTotal Loss: 0.285975\n",
      "Reconstruction: 0.171232, Regularization: 0.046612, Discriminator: 0.043473; Generator: 0.024658,\n",
      "D(x): 0.483, D(G(z)): 0.467\n",
      "2019-04-09 23:31:50,763 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 0.398769\n",
      "Reconstruction: 0.264978, Regularization: 0.066143, Discriminator: 0.041667; Generator: 0.025981,\n",
      "D(x): 0.498, D(G(z)): 0.450\n",
      "2019-04-09 23:31:50,874 root         INFO     Train Epoch: 7 [3584/8000 (45%)]\tTotal Loss: 0.299701\n",
      "Reconstruction: 0.176761, Regularization: 0.056950, Discriminator: 0.042501; Generator: 0.023490,\n",
      "D(x): 0.525, D(G(z)): 0.487\n",
      "2019-04-09 23:31:50,985 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 0.412239\n",
      "Reconstruction: 0.280155, Regularization: 0.065566, Discriminator: 0.042600; Generator: 0.023919,\n",
      "D(x): 0.507, D(G(z)): 0.476\n",
      "2019-04-09 23:31:51,097 root         INFO     Train Epoch: 7 [4608/8000 (58%)]\tTotal Loss: 0.271700\n",
      "Reconstruction: 0.136800, Regularization: 0.068839, Discriminator: 0.042225; Generator: 0.023836,\n",
      "D(x): 0.533, D(G(z)): 0.485\n",
      "2019-04-09 23:31:51,208 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 0.463984\n",
      "Reconstruction: 0.293375, Regularization: 0.103785, Discriminator: 0.041600; Generator: 0.025224,\n",
      "D(x): 0.506, D(G(z)): 0.457\n",
      "2019-04-09 23:31:51,320 root         INFO     Train Epoch: 7 [5632/8000 (70%)]\tTotal Loss: 0.419694\n",
      "Reconstruction: 0.243206, Regularization: 0.110520, Discriminator: 0.042879; Generator: 0.023089,\n",
      "D(x): 0.515, D(G(z)): 0.487\n",
      "2019-04-09 23:31:51,431 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 0.349558\n",
      "Reconstruction: 0.141361, Regularization: 0.141953, Discriminator: 0.041693; Generator: 0.024552,\n",
      "D(x): 0.520, D(G(z)): 0.469\n",
      "2019-04-09 23:31:51,543 root         INFO     Train Epoch: 7 [6656/8000 (83%)]\tTotal Loss: 0.289527\n",
      "Reconstruction: 0.141734, Regularization: 0.079336, Discriminator: 0.043394; Generator: 0.025063,\n",
      "D(x): 0.489, D(G(z)): 0.465\n",
      "2019-04-09 23:31:51,654 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 0.552758\n",
      "Reconstruction: 0.262704, Regularization: 0.224495, Discriminator: 0.040722; Generator: 0.024836,\n",
      "D(x): 0.534, D(G(z)): 0.469\n",
      "2019-04-09 23:31:51,765 root         INFO     Train Epoch: 7 [7680/8000 (96%)]\tTotal Loss: 0.316897\n",
      "Reconstruction: 0.149457, Regularization: 0.102964, Discriminator: 0.042755; Generator: 0.021720,\n",
      "D(x): 0.526, D(G(z)): 0.504\n",
      "2019-04-09 23:31:51,846 root         INFO     ====> Epoch: 7 Average loss: 0.3751\n",
      "2019-04-09 23:31:51,873 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 0.307027\n",
      "Reconstruction: 0.196229, Regularization: 0.044229, Discriminator: 0.041902; Generator: 0.024667,\n",
      "D(x): 0.502, D(G(z)): 0.463\n",
      "2019-04-09 23:31:51,984 root         INFO     Train Epoch: 8 [512/8000 (6%)]\tTotal Loss: 0.251648\n",
      "Reconstruction: 0.149777, Regularization: 0.036657, Discriminator: 0.041930; Generator: 0.023284,\n",
      "D(x): 0.521, D(G(z)): 0.483\n",
      "2019-04-09 23:31:52,094 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 0.247796\n",
      "Reconstruction: 0.133639, Regularization: 0.049172, Discriminator: 0.040578; Generator: 0.024407,\n",
      "D(x): 0.524, D(G(z)): 0.465\n",
      "2019-04-09 23:31:52,203 root         INFO     Train Epoch: 8 [1536/8000 (19%)]\tTotal Loss: 0.354928\n",
      "Reconstruction: 0.241014, Regularization: 0.047573, Discriminator: 0.042772; Generator: 0.023569,\n",
      "D(x): 0.507, D(G(z)): 0.479\n",
      "2019-04-09 23:31:52,312 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 0.406831\n",
      "Reconstruction: 0.224032, Regularization: 0.116454, Discriminator: 0.041824; Generator: 0.024522,\n",
      "D(x): 0.506, D(G(z)): 0.464\n",
      "2019-04-09 23:31:52,421 root         INFO     Train Epoch: 8 [2560/8000 (32%)]\tTotal Loss: 0.396803\n",
      "Reconstruction: 0.238047, Regularization: 0.092827, Discriminator: 0.043071; Generator: 0.022858,\n",
      "D(x): 0.509, D(G(z)): 0.487\n",
      "2019-04-09 23:31:52,530 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 0.284915\n",
      "Reconstruction: 0.134532, Regularization: 0.084661, Discriminator: 0.040681; Generator: 0.025041,\n",
      "D(x): 0.518, D(G(z)): 0.458\n",
      "2019-04-09 23:31:52,640 root         INFO     Train Epoch: 8 [3584/8000 (45%)]\tTotal Loss: 0.271028\n",
      "Reconstruction: 0.152138, Regularization: 0.053221, Discriminator: 0.040872; Generator: 0.024796,\n",
      "D(x): 0.520, D(G(z)): 0.463\n",
      "2019-04-09 23:31:52,750 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 0.650828\n",
      "Reconstruction: 0.359853, Regularization: 0.223891, Discriminator: 0.044647; Generator: 0.022437,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-09 23:31:52,858 root         INFO     Train Epoch: 8 [4608/8000 (58%)]\tTotal Loss: 0.247296\n",
      "Reconstruction: 0.136979, Regularization: 0.046315, Discriminator: 0.040436; Generator: 0.023567,\n",
      "D(x): 0.548, D(G(z)): 0.481\n",
      "2019-04-09 23:31:52,967 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 0.430900\n",
      "Reconstruction: 0.234381, Regularization: 0.130748, Discriminator: 0.041437; Generator: 0.024335,\n",
      "D(x): 0.525, D(G(z)): 0.473\n",
      "2019-04-09 23:31:53,076 root         INFO     Train Epoch: 8 [5632/8000 (70%)]\tTotal Loss: 0.800548\n",
      "Reconstruction: 0.556617, Regularization: 0.176113, Discriminator: 0.044000; Generator: 0.023817,\n",
      "D(x): 0.486, D(G(z)): 0.477\n",
      "2019-04-09 23:31:53,185 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 0.388957\n",
      "Reconstruction: 0.261975, Regularization: 0.060991, Discriminator: 0.043149; Generator: 0.022842,\n",
      "D(x): 0.506, D(G(z)): 0.488\n",
      "2019-04-09 23:31:53,293 root         INFO     Train Epoch: 8 [6656/8000 (83%)]\tTotal Loss: 0.854893\n",
      "Reconstruction: 0.669452, Regularization: 0.119999, Discriminator: 0.041513; Generator: 0.023930,\n",
      "D(x): 0.519, D(G(z)): 0.474\n",
      "2019-04-09 23:31:53,402 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 0.348010\n",
      "Reconstruction: 0.206952, Regularization: 0.076506, Discriminator: 0.041465; Generator: 0.023087,\n",
      "D(x): 0.532, D(G(z)): 0.486\n",
      "2019-04-09 23:31:53,512 root         INFO     Train Epoch: 8 [7680/8000 (96%)]\tTotal Loss: 0.423477\n",
      "Reconstruction: 0.304186, Regularization: 0.053765, Discriminator: 0.041970; Generator: 0.023557,\n",
      "D(x): 0.520, D(G(z)): 0.482\n",
      "2019-04-09 23:31:53,592 root         INFO     ====> Epoch: 8 Average loss: 0.3683\n",
      "2019-04-09 23:31:53,619 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 0.311413\n",
      "Reconstruction: 0.182090, Regularization: 0.063647, Discriminator: 0.042834; Generator: 0.022842,\n",
      "D(x): 0.506, D(G(z)): 0.487\n",
      "2019-04-09 23:31:53,731 root         INFO     Train Epoch: 9 [512/8000 (6%)]\tTotal Loss: 0.254444\n",
      "Reconstruction: 0.155509, Regularization: 0.034719, Discriminator: 0.039851; Generator: 0.024365,\n",
      "D(x): 0.543, D(G(z)): 0.469\n",
      "2019-04-09 23:31:53,841 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 0.432079\n",
      "Reconstruction: 0.288309, Regularization: 0.077123, Discriminator: 0.044060; Generator: 0.022587,\n",
      "D(x): 0.492, D(G(z)): 0.491\n",
      "2019-04-09 23:31:53,951 root         INFO     Train Epoch: 9 [1536/8000 (19%)]\tTotal Loss: 0.268733\n",
      "Reconstruction: 0.160956, Regularization: 0.041935, Discriminator: 0.041508; Generator: 0.024334,\n",
      "D(x): 0.513, D(G(z)): 0.468\n",
      "2019-04-09 23:31:54,061 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 0.610336\n",
      "Reconstruction: 0.182787, Regularization: 0.363228, Discriminator: 0.040390; Generator: 0.023932,\n",
      "D(x): 0.531, D(G(z)): 0.471\n",
      "2019-04-09 23:31:54,171 root         INFO     Train Epoch: 9 [2560/8000 (32%)]\tTotal Loss: 0.277308\n",
      "Reconstruction: 0.179365, Regularization: 0.035804, Discriminator: 0.038874; Generator: 0.023265,\n",
      "D(x): 0.567, D(G(z)): 0.481\n",
      "2019-04-09 23:31:54,280 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 0.339518\n",
      "Reconstruction: 0.225177, Regularization: 0.049299, Discriminator: 0.040785; Generator: 0.024257,\n",
      "D(x): 0.518, D(G(z)): 0.465\n",
      "2019-04-09 23:31:54,390 root         INFO     Train Epoch: 9 [3584/8000 (45%)]\tTotal Loss: 0.294024\n",
      "Reconstruction: 0.168682, Regularization: 0.061438, Discriminator: 0.040761; Generator: 0.023142,\n",
      "D(x): 0.538, D(G(z)): 0.483\n",
      "2019-04-09 23:31:54,500 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 0.250181\n",
      "Reconstruction: 0.137617, Regularization: 0.045744, Discriminator: 0.044131; Generator: 0.022688,\n",
      "D(x): 0.490, D(G(z)): 0.490\n",
      "2019-04-09 23:31:54,611 root         INFO     Train Epoch: 9 [4608/8000 (58%)]\tTotal Loss: 0.383082\n",
      "Reconstruction: 0.244199, Regularization: 0.073743, Discriminator: 0.041609; Generator: 0.023531,\n",
      "D(x): 0.526, D(G(z)): 0.479\n",
      "2019-04-09 23:31:54,721 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 0.317605\n",
      "Reconstruction: 0.162418, Regularization: 0.089474, Discriminator: 0.040064; Generator: 0.025648,\n",
      "D(x): 0.517, D(G(z)): 0.447\n",
      "2019-04-09 23:31:54,831 root         INFO     Train Epoch: 9 [5632/8000 (70%)]\tTotal Loss: 0.444137\n",
      "Reconstruction: 0.222069, Regularization: 0.155024, Discriminator: 0.043325; Generator: 0.023719,\n",
      "D(x): 0.489, D(G(z)): 0.472\n",
      "2019-04-09 23:31:54,941 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 0.284511\n",
      "Reconstruction: 0.156784, Regularization: 0.062098, Discriminator: 0.042871; Generator: 0.022758,\n",
      "D(x): 0.509, D(G(z)): 0.489\n",
      "2019-04-09 23:31:55,051 root         INFO     Train Epoch: 9 [6656/8000 (83%)]\tTotal Loss: 0.281024\n",
      "Reconstruction: 0.149280, Regularization: 0.066521, Discriminator: 0.042932; Generator: 0.022292,\n",
      "D(x): 0.514, D(G(z)): 0.496\n",
      "2019-04-09 23:31:55,161 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 0.706411\n",
      "Reconstruction: 0.547527, Regularization: 0.093771, Discriminator: 0.042837; Generator: 0.022276,\n",
      "D(x): 0.511, D(G(z)): 0.493\n",
      "2019-04-09 23:31:55,271 root         INFO     Train Epoch: 9 [7680/8000 (96%)]\tTotal Loss: 0.288483\n",
      "Reconstruction: 0.183316, Regularization: 0.040952, Discriminator: 0.040185; Generator: 0.024031,\n",
      "D(x): 0.536, D(G(z)): 0.471\n",
      "2019-04-09 23:31:55,351 root         INFO     ====> Epoch: 9 Average loss: 0.4114\n",
      "2019-04-09 23:31:55,377 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 0.265741\n",
      "Reconstruction: 0.166229, Regularization: 0.034902, Discriminator: 0.041876; Generator: 0.022734,\n",
      "D(x): 0.522, D(G(z)): 0.488\n",
      "2019-04-09 23:31:55,489 root         INFO     Train Epoch: 10 [512/8000 (6%)]\tTotal Loss: 0.266851\n",
      "Reconstruction: 0.156864, Regularization: 0.045716, Discriminator: 0.042104; Generator: 0.022166,\n",
      "D(x): 0.526, D(G(z)): 0.497\n",
      "2019-04-09 23:31:55,599 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 0.289049\n",
      "Reconstruction: 0.159703, Regularization: 0.064830, Discriminator: 0.040574; Generator: 0.023942,\n",
      "D(x): 0.526, D(G(z)): 0.470\n",
      "2019-04-09 23:31:55,710 root         INFO     Train Epoch: 10 [1536/8000 (19%)]\tTotal Loss: 0.245100\n",
      "Reconstruction: 0.129944, Regularization: 0.052272, Discriminator: 0.039750; Generator: 0.023134,\n",
      "D(x): 0.551, D(G(z)): 0.480\n",
      "2019-04-09 23:31:55,822 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 0.362648\n",
      "Reconstruction: 0.229488, Regularization: 0.067542, Discriminator: 0.041894; Generator: 0.023725,\n",
      "D(x): 0.504, D(G(z)): 0.472\n",
      "2019-04-09 23:31:55,932 root         INFO     Train Epoch: 10 [2560/8000 (32%)]\tTotal Loss: 0.432842\n",
      "Reconstruction: 0.253748, Regularization: 0.114103, Discriminator: 0.042549; Generator: 0.022442,\n",
      "D(x): 0.513, D(G(z)): 0.491\n",
      "2019-04-09 23:31:56,043 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 0.235427\n",
      "Reconstruction: 0.132936, Regularization: 0.037754, Discriminator: 0.041854; Generator: 0.022885,\n",
      "D(x): 0.520, D(G(z)): 0.485\n",
      "2019-04-09 23:31:56,153 root         INFO     Train Epoch: 10 [3584/8000 (45%)]\tTotal Loss: 0.330487\n",
      "Reconstruction: 0.216975, Regularization: 0.049695, Discriminator: 0.041008; Generator: 0.022808,\n",
      "D(x): 0.535, D(G(z)): 0.486\n",
      "2019-04-09 23:31:56,264 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 0.400888\n",
      "Reconstruction: 0.236853, Regularization: 0.098989, Discriminator: 0.041985; Generator: 0.023061,\n",
      "D(x): 0.515, D(G(z)): 0.481\n",
      "2019-04-09 23:31:56,375 root         INFO     Train Epoch: 10 [4608/8000 (58%)]\tTotal Loss: 0.294981\n",
      "Reconstruction: 0.189524, Regularization: 0.043017, Discriminator: 0.041201; Generator: 0.021240,\n",
      "D(x): 0.556, D(G(z)): 0.511\n",
      "2019-04-09 23:31:56,485 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 0.274342\n",
      "Reconstruction: 0.159692, Regularization: 0.051118, Discriminator: 0.040312; Generator: 0.023220,\n",
      "D(x): 0.535, D(G(z)): 0.477\n",
      "2019-04-09 23:31:56,596 root         INFO     Train Epoch: 10 [5632/8000 (70%)]\tTotal Loss: 0.759370\n",
      "Reconstruction: 0.396264, Regularization: 0.298613, Discriminator: 0.042186; Generator: 0.022307,\n",
      "D(x): 0.519, D(G(z)): 0.492\n",
      "2019-04-09 23:31:56,706 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 0.267944\n",
      "Reconstruction: 0.144492, Regularization: 0.057701, Discriminator: 0.043282; Generator: 0.022470,\n",
      "D(x): 0.504, D(G(z)): 0.491\n",
      "2019-04-09 23:31:56,817 root         INFO     Train Epoch: 10 [6656/8000 (83%)]\tTotal Loss: 0.311723\n",
      "Reconstruction: 0.185952, Regularization: 0.062855, Discriminator: 0.039837; Generator: 0.023080,\n",
      "D(x): 0.547, D(G(z)): 0.481\n",
      "2019-04-09 23:31:56,927 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 0.367099\n",
      "Reconstruction: 0.222479, Regularization: 0.079359, Discriminator: 0.042129; Generator: 0.023132,\n",
      "D(x): 0.509, D(G(z)): 0.481\n",
      "2019-04-09 23:31:57,038 root         INFO     Train Epoch: 10 [7680/8000 (96%)]\tTotal Loss: 0.566115\n",
      "Reconstruction: 0.385222, Regularization: 0.116757, Discriminator: 0.042625; Generator: 0.021510,\n",
      "D(x): 0.526, D(G(z)): 0.505\n",
      "2019-04-09 23:31:57,118 root         INFO     ====> Epoch: 10 Average loss: 0.4128\n",
      "2019-04-09 23:31:57,145 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.305135\n",
      "Reconstruction: 0.159154, Regularization: 0.080166, Discriminator: 0.042146; Generator: 0.023668,\n",
      "D(x): 0.499, D(G(z)): 0.471\n",
      "2019-04-09 23:31:57,255 root         INFO     Train Epoch: 11 [512/8000 (6%)]\tTotal Loss: 0.475909\n",
      "Reconstruction: 0.347784, Regularization: 0.063321, Discriminator: 0.041580; Generator: 0.023225,\n",
      "D(x): 0.515, D(G(z)): 0.478\n",
      "2019-04-09 23:31:57,363 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 0.385337\n",
      "Reconstruction: 0.247533, Regularization: 0.073310, Discriminator: 0.042319; Generator: 0.022174,\n",
      "D(x): 0.517, D(G(z)): 0.494\n",
      "2019-04-09 23:31:57,473 root         INFO     Train Epoch: 11 [1536/8000 (19%)]\tTotal Loss: 0.344921\n",
      "Reconstruction: 0.238451, Regularization: 0.040793, Discriminator: 0.043636; Generator: 0.022041,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-04-09 23:31:57,582 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.387679\n",
      "Reconstruction: 0.252116, Regularization: 0.070915, Discriminator: 0.042228; Generator: 0.022421,\n",
      "D(x): 0.514, D(G(z)): 0.489\n",
      "2019-04-09 23:31:57,691 root         INFO     Train Epoch: 11 [2560/8000 (32%)]\tTotal Loss: 0.496028\n",
      "Reconstruction: 0.276156, Regularization: 0.155116, Discriminator: 0.042392; Generator: 0.022364,\n",
      "D(x): 0.511, D(G(z)): 0.491\n",
      "2019-04-09 23:31:57,800 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 0.553597\n",
      "Reconstruction: 0.239113, Regularization: 0.248790, Discriminator: 0.043176; Generator: 0.022518,\n",
      "D(x): 0.501, D(G(z)): 0.488\n",
      "2019-04-09 23:31:57,909 root         INFO     Train Epoch: 11 [3584/8000 (45%)]\tTotal Loss: 0.805771\n",
      "Reconstruction: 0.660460, Regularization: 0.080047, Discriminator: 0.042197; Generator: 0.023067,\n",
      "D(x): 0.511, D(G(z)): 0.480\n",
      "2019-04-09 23:31:58,018 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 0.239481\n",
      "Reconstruction: 0.124857, Regularization: 0.050647, Discriminator: 0.042201; Generator: 0.021776,\n",
      "D(x): 0.525, D(G(z)): 0.499\n",
      "2019-04-09 23:31:58,128 root         INFO     Train Epoch: 11 [4608/8000 (58%)]\tTotal Loss: 0.268021\n",
      "Reconstruction: 0.152175, Regularization: 0.052013, Discriminator: 0.041720; Generator: 0.022114,\n",
      "D(x): 0.528, D(G(z)): 0.494\n",
      "2019-04-09 23:31:58,237 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 0.234952\n",
      "Reconstruction: 0.139940, Regularization: 0.030383, Discriminator: 0.042511; Generator: 0.022118,\n",
      "D(x): 0.517, D(G(z)): 0.494\n",
      "2019-04-09 23:31:58,346 root         INFO     Train Epoch: 11 [5632/8000 (70%)]\tTotal Loss: 0.460362\n",
      "Reconstruction: 0.322515, Regularization: 0.074043, Discriminator: 0.041944; Generator: 0.021860,\n",
      "D(x): 0.531, D(G(z)): 0.498\n",
      "2019-04-09 23:31:58,455 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.379926\n",
      "Reconstruction: 0.206022, Regularization: 0.108524, Discriminator: 0.042740; Generator: 0.022640,\n",
      "D(x): 0.503, D(G(z)): 0.486\n",
      "2019-04-09 23:31:58,564 root         INFO     Train Epoch: 11 [6656/8000 (83%)]\tTotal Loss: 0.398383\n",
      "Reconstruction: 0.249737, Regularization: 0.084713, Discriminator: 0.041607; Generator: 0.022326,\n",
      "D(x): 0.527, D(G(z)): 0.490\n",
      "2019-04-09 23:31:58,673 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 0.440620\n",
      "Reconstruction: 0.326272, Regularization: 0.049370, Discriminator: 0.042368; Generator: 0.022610,\n",
      "D(x): 0.511, D(G(z)): 0.486\n",
      "2019-04-09 23:31:58,782 root         INFO     Train Epoch: 11 [7680/8000 (96%)]\tTotal Loss: 0.268687\n",
      "Reconstruction: 0.137700, Regularization: 0.066289, Discriminator: 0.042615; Generator: 0.022082,\n",
      "D(x): 0.513, D(G(z)): 0.495\n",
      "2019-04-09 23:31:58,861 root         INFO     ====> Epoch: 11 Average loss: 0.4372\n",
      "2019-04-09 23:31:58,888 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 0.288309\n",
      "Reconstruction: 0.171949, Regularization: 0.052466, Discriminator: 0.041800; Generator: 0.022094,\n",
      "D(x): 0.525, D(G(z)): 0.494\n",
      "2019-04-09 23:31:58,999 root         INFO     Train Epoch: 12 [512/8000 (6%)]\tTotal Loss: 1.147938\n",
      "Reconstruction: 0.719945, Regularization: 0.363863, Discriminator: 0.041882; Generator: 0.022247,\n",
      "D(x): 0.520, D(G(z)): 0.492\n",
      "2019-04-09 23:31:59,109 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 0.430271\n",
      "Reconstruction: 0.275955, Regularization: 0.091140, Discriminator: 0.040174; Generator: 0.023001,\n",
      "D(x): 0.537, D(G(z)): 0.480\n",
      "2019-04-09 23:31:59,220 root         INFO     Train Epoch: 12 [1536/8000 (19%)]\tTotal Loss: 0.310612\n",
      "Reconstruction: 0.183343, Regularization: 0.062002, Discriminator: 0.042796; Generator: 0.022472,\n",
      "D(x): 0.507, D(G(z)): 0.488\n",
      "2019-04-09 23:31:59,330 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 0.340229\n",
      "Reconstruction: 0.201699, Regularization: 0.074964, Discriminator: 0.042008; Generator: 0.021557,\n",
      "D(x): 0.532, D(G(z)): 0.502\n",
      "2019-04-09 23:31:59,439 root         INFO     Train Epoch: 12 [2560/8000 (32%)]\tTotal Loss: 0.326963\n",
      "Reconstruction: 0.209087, Regularization: 0.054683, Discriminator: 0.040955; Generator: 0.022239,\n",
      "D(x): 0.538, D(G(z)): 0.492\n",
      "2019-04-09 23:31:59,548 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 0.390584\n",
      "Reconstruction: 0.253867, Regularization: 0.073111, Discriminator: 0.041260; Generator: 0.022345,\n",
      "D(x): 0.532, D(G(z)): 0.490\n",
      "2019-04-09 23:31:59,657 root         INFO     Train Epoch: 12 [3584/8000 (45%)]\tTotal Loss: 0.477207\n",
      "Reconstruction: 0.289576, Regularization: 0.124352, Discriminator: 0.041010; Generator: 0.022270,\n",
      "D(x): 0.538, D(G(z)): 0.492\n",
      "2019-04-09 23:31:59,766 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 31.442333\n",
      "Reconstruction: 31.053915, Regularization: 0.324239, Discriminator: 0.042227; Generator: 0.021952,\n",
      "D(x): 0.520, D(G(z)): 0.496\n",
      "2019-04-09 23:31:59,875 root         INFO     Train Epoch: 12 [4608/8000 (58%)]\tTotal Loss: 0.525226\n",
      "Reconstruction: 0.387166, Regularization: 0.074503, Discriminator: 0.041372; Generator: 0.022185,\n",
      "D(x): 0.534, D(G(z)): 0.492\n",
      "2019-04-09 23:31:59,984 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.325601\n",
      "Reconstruction: 0.206451, Regularization: 0.054089, Discriminator: 0.043073; Generator: 0.021987,\n",
      "D(x): 0.508, D(G(z)): 0.495\n",
      "2019-04-09 23:32:00,094 root         INFO     Train Epoch: 12 [5632/8000 (70%)]\tTotal Loss: 0.377421\n",
      "Reconstruction: 0.226843, Regularization: 0.084010, Discriminator: 0.044889; Generator: 0.021680,\n",
      "D(x): 0.486, D(G(z)): 0.500\n",
      "2019-04-09 23:32:00,203 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.253752\n",
      "Reconstruction: 0.143419, Regularization: 0.045450, Discriminator: 0.042412; Generator: 0.022471,\n",
      "D(x): 0.511, D(G(z)): 0.488\n",
      "2019-04-09 23:32:00,312 root         INFO     Train Epoch: 12 [6656/8000 (83%)]\tTotal Loss: 0.261103\n",
      "Reconstruction: 0.140478, Regularization: 0.057666, Discriminator: 0.040751; Generator: 0.022208,\n",
      "D(x): 0.545, D(G(z)): 0.492\n",
      "2019-04-09 23:32:00,421 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 0.458444\n",
      "Reconstruction: 0.308690, Regularization: 0.084981, Discriminator: 0.042805; Generator: 0.021970,\n",
      "D(x): 0.515, D(G(z)): 0.496\n",
      "2019-04-09 23:32:00,530 root         INFO     Train Epoch: 12 [7680/8000 (96%)]\tTotal Loss: 0.461643\n",
      "Reconstruction: 0.313244, Regularization: 0.085018, Discriminator: 0.041293; Generator: 0.022087,\n",
      "D(x): 0.533, D(G(z)): 0.494\n",
      "2019-04-09 23:32:00,609 root         INFO     ====> Epoch: 12 Average loss: 1.3992\n",
      "2019-04-09 23:32:00,636 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 0.538014\n",
      "Reconstruction: 0.367948, Regularization: 0.103784, Discriminator: 0.043870; Generator: 0.022413,\n",
      "D(x): 0.489, D(G(z)): 0.489\n",
      "2019-04-09 23:32:00,747 root         INFO     Train Epoch: 13 [512/8000 (6%)]\tTotal Loss: 0.291980\n",
      "Reconstruction: 0.145976, Regularization: 0.081815, Discriminator: 0.041754; Generator: 0.022434,\n",
      "D(x): 0.519, D(G(z)): 0.488\n",
      "2019-04-09 23:32:00,858 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 0.421160\n",
      "Reconstruction: 0.300644, Regularization: 0.055993, Discriminator: 0.042386; Generator: 0.022137,\n",
      "D(x): 0.516, D(G(z)): 0.493\n",
      "2019-04-09 23:32:00,968 root         INFO     Train Epoch: 13 [1536/8000 (19%)]\tTotal Loss: 0.235349\n",
      "Reconstruction: 0.131901, Regularization: 0.036984, Discriminator: 0.044297; Generator: 0.022167,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-04-09 23:32:01,078 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 0.250491\n",
      "Reconstruction: 0.133596, Regularization: 0.050566, Discriminator: 0.044504; Generator: 0.021825,\n",
      "D(x): 0.489, D(G(z)): 0.498\n",
      "2019-04-09 23:32:01,188 root         INFO     Train Epoch: 13 [2560/8000 (32%)]\tTotal Loss: 0.519927\n",
      "Reconstruction: 0.276868, Regularization: 0.177833, Discriminator: 0.043274; Generator: 0.021951,\n",
      "D(x): 0.504, D(G(z)): 0.496\n",
      "2019-04-09 23:32:01,299 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 2.055787\n",
      "Reconstruction: 1.695486, Regularization: 0.294398, Discriminator: 0.043839; Generator: 0.022064,\n",
      "D(x): 0.498, D(G(z)): 0.494\n",
      "2019-04-09 23:32:01,409 root         INFO     Train Epoch: 13 [3584/8000 (45%)]\tTotal Loss: 0.355056\n",
      "Reconstruction: 0.204317, Regularization: 0.085906, Discriminator: 0.042771; Generator: 0.022062,\n",
      "D(x): 0.510, D(G(z)): 0.494\n",
      "2019-04-09 23:32:01,520 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 4.088720\n",
      "Reconstruction: 3.927144, Regularization: 0.095254, Discriminator: 0.044088; Generator: 0.022235,\n",
      "D(x): 0.490, D(G(z)): 0.491\n",
      "2019-04-09 23:32:01,630 root         INFO     Train Epoch: 13 [4608/8000 (58%)]\tTotal Loss: 0.253423\n",
      "Reconstruction: 0.150358, Regularization: 0.038466, Discriminator: 0.042382; Generator: 0.022217,\n",
      "D(x): 0.514, D(G(z)): 0.491\n",
      "2019-04-09 23:32:01,740 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 0.265517\n",
      "Reconstruction: 0.165859, Regularization: 0.033968, Discriminator: 0.043434; Generator: 0.022256,\n",
      "D(x): 0.502, D(G(z)): 0.491\n",
      "2019-04-09 23:32:01,850 root         INFO     Train Epoch: 13 [5632/8000 (70%)]\tTotal Loss: 0.391793\n",
      "Reconstruction: 0.243057, Regularization: 0.083872, Discriminator: 0.042729; Generator: 0.022135,\n",
      "D(x): 0.510, D(G(z)): 0.493\n",
      "2019-04-09 23:32:01,961 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 0.747145\n",
      "Reconstruction: 0.620740, Regularization: 0.062617, Discriminator: 0.041461; Generator: 0.022326,\n",
      "D(x): 0.529, D(G(z)): 0.490\n",
      "2019-04-09 23:32:02,071 root         INFO     Train Epoch: 13 [6656/8000 (83%)]\tTotal Loss: 0.687459\n",
      "Reconstruction: 0.341051, Regularization: 0.280557, Discriminator: 0.043575; Generator: 0.022276,\n",
      "D(x): 0.492, D(G(z)): 0.490\n",
      "2019-04-09 23:32:02,182 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 0.347968\n",
      "Reconstruction: 0.199809, Regularization: 0.085088, Discriminator: 0.040885; Generator: 0.022186,\n",
      "D(x): 0.537, D(G(z)): 0.492\n",
      "2019-04-09 23:32:02,292 root         INFO     Train Epoch: 13 [7680/8000 (96%)]\tTotal Loss: 0.356642\n",
      "Reconstruction: 0.208897, Regularization: 0.079304, Discriminator: 0.046274; Generator: 0.022167,\n",
      "D(x): 0.455, D(G(z)): 0.492\n",
      "2019-04-09 23:32:02,372 root         INFO     ====> Epoch: 13 Average loss: 71.1425\n",
      "2019-04-09 23:32:02,399 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.246393\n",
      "Reconstruction: 0.137697, Regularization: 0.041707, Discriminator: 0.044627; Generator: 0.022361,\n",
      "D(x): 0.478, D(G(z)): 0.489\n",
      "2019-04-09 23:32:02,511 root         INFO     Train Epoch: 14 [512/8000 (6%)]\tTotal Loss: 0.288094\n",
      "Reconstruction: 0.149205, Regularization: 0.074911, Discriminator: 0.041714; Generator: 0.022266,\n",
      "D(x): 0.522, D(G(z)): 0.491\n",
      "2019-04-09 23:32:02,621 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.369469\n",
      "Reconstruction: 0.261432, Regularization: 0.042871, Discriminator: 0.043111; Generator: 0.022056,\n",
      "D(x): 0.508, D(G(z)): 0.494\n",
      "2019-04-09 23:32:02,732 root         INFO     Train Epoch: 14 [1536/8000 (19%)]\tTotal Loss: 0.248103\n",
      "Reconstruction: 0.143674, Regularization: 0.038272, Discriminator: 0.043997; Generator: 0.022160,\n",
      "D(x): 0.493, D(G(z)): 0.492\n",
      "2019-04-09 23:32:02,843 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 0.237290\n",
      "Reconstruction: 0.141311, Regularization: 0.029633, Discriminator: 0.044334; Generator: 0.022011,\n",
      "D(x): 0.484, D(G(z)): 0.495\n",
      "2019-04-09 23:32:02,954 root         INFO     Train Epoch: 14 [2560/8000 (32%)]\tTotal Loss: 4.140099\n",
      "Reconstruction: 3.961482, Regularization: 0.113804, Discriminator: 0.042657; Generator: 0.022156,\n",
      "D(x): 0.517, D(G(z)): 0.492\n",
      "2019-04-09 23:32:03,064 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.301250\n",
      "Reconstruction: 0.166214, Regularization: 0.068669, Discriminator: 0.044602; Generator: 0.021765,\n",
      "D(x): 0.489, D(G(z)): 0.499\n",
      "2019-04-09 23:32:03,174 root         INFO     Train Epoch: 14 [3584/8000 (45%)]\tTotal Loss: 0.646793\n",
      "Reconstruction: 0.195905, Regularization: 0.387209, Discriminator: 0.041668; Generator: 0.022011,\n",
      "D(x): 0.529, D(G(z)): 0.495\n",
      "2019-04-09 23:32:03,285 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.302758\n",
      "Reconstruction: 0.192989, Regularization: 0.043144, Discriminator: 0.044623; Generator: 0.022001,\n",
      "D(x): 0.483, D(G(z)): 0.495\n",
      "2019-04-09 23:32:03,395 root         INFO     Train Epoch: 14 [4608/8000 (58%)]\tTotal Loss: 0.225907\n",
      "Reconstruction: 0.130948, Regularization: 0.029358, Discriminator: 0.043437; Generator: 0.022163,\n",
      "D(x): 0.500, D(G(z)): 0.492\n",
      "2019-04-09 23:32:03,506 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 0.362835\n",
      "Reconstruction: 0.228162, Regularization: 0.070180, Discriminator: 0.042398; Generator: 0.022095,\n",
      "D(x): 0.517, D(G(z)): 0.493\n",
      "2019-04-09 23:32:03,617 root         INFO     Train Epoch: 14 [5632/8000 (70%)]\tTotal Loss: 0.656696\n",
      "Reconstruction: 0.549980, Regularization: 0.041513, Discriminator: 0.043202; Generator: 0.022001,\n",
      "D(x): 0.505, D(G(z)): 0.495\n",
      "2019-04-09 23:32:03,728 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.269525\n",
      "Reconstruction: 0.147809, Regularization: 0.057328, Discriminator: 0.042319; Generator: 0.022069,\n",
      "D(x): 0.518, D(G(z)): 0.494\n",
      "2019-04-09 23:32:03,838 root         INFO     Train Epoch: 14 [6656/8000 (83%)]\tTotal Loss: 0.462412\n",
      "Reconstruction: 0.356701, Regularization: 0.040612, Discriminator: 0.043112; Generator: 0.021987,\n",
      "D(x): 0.506, D(G(z)): 0.495\n",
      "2019-04-09 23:32:03,948 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.210809\n",
      "Reconstruction: 0.108602, Regularization: 0.036855, Discriminator: 0.043335; Generator: 0.022017,\n",
      "D(x): 0.499, D(G(z)): 0.494\n",
      "2019-04-09 23:32:04,059 root         INFO     Train Epoch: 14 [7680/8000 (96%)]\tTotal Loss: 0.293538\n",
      "Reconstruction: 0.179697, Regularization: 0.048930, Discriminator: 0.042809; Generator: 0.022101,\n",
      "D(x): 0.510, D(G(z)): 0.493\n",
      "2019-04-09 23:32:04,139 root         INFO     ====> Epoch: 14 Average loss: 105.2316\n",
      "2019-04-09 23:32:04,166 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 11.087481\n",
      "Reconstruction: 10.913499, Regularization: 0.108552, Discriminator: 0.043411; Generator: 0.022019,\n",
      "D(x): 0.499, D(G(z)): 0.494\n",
      "2019-04-09 23:32:04,277 root         INFO     Train Epoch: 15 [512/8000 (6%)]\tTotal Loss: 0.218776\n",
      "Reconstruction: 0.125349, Regularization: 0.027224, Discriminator: 0.044237; Generator: 0.021965,\n",
      "D(x): 0.487, D(G(z)): 0.495\n",
      "2019-04-09 23:32:04,387 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 0.535588\n",
      "Reconstruction: 0.420239, Regularization: 0.048614, Discriminator: 0.044804; Generator: 0.021932,\n",
      "D(x): 0.479, D(G(z)): 0.496\n",
      "2019-04-09 23:32:04,498 root         INFO     Train Epoch: 15 [1536/8000 (19%)]\tTotal Loss: 0.240758\n",
      "Reconstruction: 0.126844, Regularization: 0.049700, Discriminator: 0.042393; Generator: 0.021821,\n",
      "D(x): 0.521, D(G(z)): 0.498\n",
      "2019-04-09 23:32:04,608 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.304119\n",
      "Reconstruction: 0.199004, Regularization: 0.038148, Discriminator: 0.045006; Generator: 0.021960,\n",
      "D(x): 0.474, D(G(z)): 0.495\n",
      "2019-04-09 23:32:04,719 root         INFO     Train Epoch: 15 [2560/8000 (32%)]\tTotal Loss: 2307.952881\n",
      "Reconstruction: 2307.768799, Regularization: 0.117167, Discriminator: 0.045085; Generator: 0.021845,\n",
      "D(x): 0.478, D(G(z)): 0.497\n",
      "2019-04-09 23:32:04,830 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.238042\n",
      "Reconstruction: 0.123088, Regularization: 0.048183, Discriminator: 0.044904; Generator: 0.021868,\n",
      "D(x): 0.478, D(G(z)): 0.497\n",
      "2019-04-09 23:32:04,940 root         INFO     Train Epoch: 15 [3584/8000 (45%)]\tTotal Loss: 0.252666\n",
      "Reconstruction: 0.131051, Regularization: 0.054651, Discriminator: 0.044999; Generator: 0.021965,\n",
      "D(x): 0.476, D(G(z)): 0.495\n",
      "2019-04-09 23:32:05,050 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.252403\n",
      "Reconstruction: 0.138531, Regularization: 0.048275, Discriminator: 0.043729; Generator: 0.021869,\n",
      "D(x): 0.498, D(G(z)): 0.497\n",
      "2019-04-09 23:32:05,161 root         INFO     Train Epoch: 15 [4608/8000 (58%)]\tTotal Loss: 0.278882\n",
      "Reconstruction: 0.158871, Regularization: 0.053575, Discriminator: 0.044658; Generator: 0.021779,\n",
      "D(x): 0.483, D(G(z)): 0.498\n",
      "2019-04-09 23:32:05,271 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.491200\n",
      "Reconstruction: 0.391671, Regularization: 0.032685, Discriminator: 0.044954; Generator: 0.021890,\n",
      "D(x): 0.477, D(G(z)): 0.496\n",
      "2019-04-09 23:32:05,382 root         INFO     Train Epoch: 15 [5632/8000 (70%)]\tTotal Loss: 1.371898\n",
      "Reconstruction: 1.252885, Regularization: 0.053214, Discriminator: 0.044048; Generator: 0.021750,\n",
      "D(x): 0.493, D(G(z)): 0.499\n",
      "2019-04-09 23:32:05,492 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.500272\n",
      "Reconstruction: 0.391055, Regularization: 0.043366, Discriminator: 0.043895; Generator: 0.021956,\n",
      "D(x): 0.492, D(G(z)): 0.495\n",
      "2019-04-09 23:32:05,602 root         INFO     Train Epoch: 15 [6656/8000 (83%)]\tTotal Loss: 0.514615\n",
      "Reconstruction: 0.393977, Regularization: 0.054945, Discriminator: 0.043788; Generator: 0.021904,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-04-09 23:32:05,713 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 0.768087\n",
      "Reconstruction: 0.646183, Regularization: 0.056356, Discriminator: 0.043572; Generator: 0.021975,\n",
      "D(x): 0.496, D(G(z)): 0.495\n",
      "2019-04-09 23:32:05,823 root         INFO     Train Epoch: 15 [7680/8000 (96%)]\tTotal Loss: 0.754398\n",
      "Reconstruction: 0.359856, Regularization: 0.329110, Discriminator: 0.043680; Generator: 0.021753,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:32:05,903 root         INFO     ====> Epoch: 15 Average loss: 22.9021\n",
      "2019-04-09 23:32:05,930 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 1.020780\n",
      "Reconstruction: 0.848874, Regularization: 0.105819, Discriminator: 0.044154; Generator: 0.021934,\n",
      "D(x): 0.488, D(G(z)): 0.496\n",
      "2019-04-09 23:32:06,041 root         INFO     Train Epoch: 16 [512/8000 (6%)]\tTotal Loss: 2038.003174\n",
      "Reconstruction: 2037.755737, Regularization: 0.182120, Discriminator: 0.043777; Generator: 0.021551,\n",
      "D(x): 0.498, D(G(z)): 0.502\n",
      "2019-04-09 23:32:06,152 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 2.133293\n",
      "Reconstruction: 1.942555, Regularization: 0.125151, Discriminator: 0.043718; Generator: 0.021869,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-09 23:32:06,262 root         INFO     Train Epoch: 16 [1536/8000 (19%)]\tTotal Loss: 0.308386\n",
      "Reconstruction: 0.207674, Regularization: 0.033379, Discriminator: 0.045847; Generator: 0.021486,\n",
      "D(x): 0.473, D(G(z)): 0.503\n",
      "2019-04-09 23:32:06,373 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.254511\n",
      "Reconstruction: 0.154542, Regularization: 0.033928, Discriminator: 0.044085; Generator: 0.021956,\n",
      "D(x): 0.489, D(G(z)): 0.495\n",
      "2019-04-09 23:32:06,485 root         INFO     Train Epoch: 16 [2560/8000 (32%)]\tTotal Loss: 2.890773\n",
      "Reconstruction: 2.737740, Regularization: 0.088427, Discriminator: 0.042605; Generator: 0.022001,\n",
      "D(x): 0.512, D(G(z)): 0.495\n",
      "2019-04-09 23:32:06,595 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 6.117012\n",
      "Reconstruction: 5.928271, Regularization: 0.123302, Discriminator: 0.043619; Generator: 0.021820,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 23:32:06,708 root         INFO     Train Epoch: 16 [3584/8000 (45%)]\tTotal Loss: 3.812070\n",
      "Reconstruction: 3.699836, Regularization: 0.045836, Discriminator: 0.044604; Generator: 0.021794,\n",
      "D(x): 0.484, D(G(z)): 0.498\n",
      "2019-04-09 23:32:06,819 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 1.562259\n",
      "Reconstruction: 1.433419, Regularization: 0.062727, Discriminator: 0.043983; Generator: 0.022131,\n",
      "D(x): 0.489, D(G(z)): 0.493\n",
      "2019-04-09 23:32:06,929 root         INFO     Train Epoch: 16 [4608/8000 (58%)]\tTotal Loss: 1.605128\n",
      "Reconstruction: 1.470394, Regularization: 0.068732, Discriminator: 0.044226; Generator: 0.021776,\n",
      "D(x): 0.490, D(G(z)): 0.498\n",
      "2019-04-09 23:32:07,040 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 45.591175\n",
      "Reconstruction: 45.200142, Regularization: 0.325557, Discriminator: 0.043625; Generator: 0.021850,\n",
      "D(x): 0.496, D(G(z)): 0.497\n",
      "2019-04-09 23:32:07,150 root         INFO     Train Epoch: 16 [5632/8000 (70%)]\tTotal Loss: 0.469702\n",
      "Reconstruction: 0.363773, Regularization: 0.040597, Discriminator: 0.043612; Generator: 0.021719,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:32:07,261 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 65.683968\n",
      "Reconstruction: 65.471527, Regularization: 0.146983, Discriminator: 0.043708; Generator: 0.021749,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:32:07,372 root         INFO     Train Epoch: 16 [6656/8000 (83%)]\tTotal Loss: 0.995988\n",
      "Reconstruction: 0.866956, Regularization: 0.061736, Discriminator: 0.045740; Generator: 0.021556,\n",
      "D(x): 0.468, D(G(z)): 0.502\n",
      "2019-04-09 23:32:07,480 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.347245\n",
      "Reconstruction: 0.216769, Regularization: 0.064600, Discriminator: 0.044114; Generator: 0.021763,\n",
      "D(x): 0.489, D(G(z)): 0.498\n",
      "2019-04-09 23:32:07,589 root         INFO     Train Epoch: 16 [7680/8000 (96%)]\tTotal Loss: 0.412891\n",
      "Reconstruction: 0.236776, Regularization: 0.110092, Discriminator: 0.044229; Generator: 0.021794,\n",
      "D(x): 0.488, D(G(z)): 0.498\n",
      "2019-04-09 23:32:07,669 root         INFO     ====> Epoch: 16 Average loss: 89.5008\n",
      "2019-04-09 23:32:07,696 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.341540\n",
      "Reconstruction: 0.239946, Regularization: 0.036354, Discriminator: 0.043464; Generator: 0.021776,\n",
      "D(x): 0.502, D(G(z)): 0.498\n",
      "2019-04-09 23:32:07,808 root         INFO     Train Epoch: 17 [512/8000 (6%)]\tTotal Loss: 0.427926\n",
      "Reconstruction: 0.305442, Regularization: 0.057718, Discriminator: 0.043043; Generator: 0.021722,\n",
      "D(x): 0.507, D(G(z)): 0.499\n",
      "2019-04-09 23:32:07,919 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 0.493943\n",
      "Reconstruction: 0.393808, Regularization: 0.034503, Discriminator: 0.044160; Generator: 0.021472,\n",
      "D(x): 0.494, D(G(z)): 0.503\n",
      "2019-04-09 23:32:08,031 root         INFO     Train Epoch: 17 [1536/8000 (19%)]\tTotal Loss: 0.581223\n",
      "Reconstruction: 0.469047, Regularization: 0.046641, Discriminator: 0.043799; Generator: 0.021736,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 23:32:08,141 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.302462\n",
      "Reconstruction: 0.197653, Regularization: 0.037964, Discriminator: 0.045080; Generator: 0.021766,\n",
      "D(x): 0.474, D(G(z)): 0.498\n",
      "2019-04-09 23:32:08,252 root         INFO     Train Epoch: 17 [2560/8000 (32%)]\tTotal Loss: 34.574139\n",
      "Reconstruction: 34.238865, Regularization: 0.269676, Discriminator: 0.043676; Generator: 0.021921,\n",
      "D(x): 0.494, D(G(z)): 0.496\n",
      "2019-04-09 23:32:08,363 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 1.183802\n",
      "Reconstruction: 1.076545, Regularization: 0.040433, Discriminator: 0.044841; Generator: 0.021983,\n",
      "D(x): 0.475, D(G(z)): 0.495\n",
      "2019-04-09 23:32:08,474 root         INFO     Train Epoch: 17 [3584/8000 (45%)]\tTotal Loss: 0.796811\n",
      "Reconstruction: 0.674933, Regularization: 0.055632, Discriminator: 0.044537; Generator: 0.021709,\n",
      "D(x): 0.484, D(G(z)): 0.499\n",
      "2019-04-09 23:32:08,586 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.464754\n",
      "Reconstruction: 0.365502, Regularization: 0.033578, Discriminator: 0.043844; Generator: 0.021830,\n",
      "D(x): 0.492, D(G(z)): 0.497\n",
      "2019-04-09 23:32:08,699 root         INFO     Train Epoch: 17 [4608/8000 (58%)]\tTotal Loss: 0.949679\n",
      "Reconstruction: 0.839815, Regularization: 0.043560, Discriminator: 0.044692; Generator: 0.021612,\n",
      "D(x): 0.482, D(G(z)): 0.501\n",
      "2019-04-09 23:32:08,811 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 7.301005\n",
      "Reconstruction: 7.177032, Regularization: 0.057186, Discriminator: 0.045028; Generator: 0.021760,\n",
      "D(x): 0.476, D(G(z)): 0.499\n",
      "2019-04-09 23:32:08,922 root         INFO     Train Epoch: 17 [5632/8000 (70%)]\tTotal Loss: 0.693746\n",
      "Reconstruction: 0.536313, Regularization: 0.089914, Discriminator: 0.045710; Generator: 0.021810,\n",
      "D(x): 0.463, D(G(z)): 0.498\n",
      "2019-04-09 23:32:09,034 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 10.643178\n",
      "Reconstruction: 10.514347, Regularization: 0.063261, Discriminator: 0.043701; Generator: 0.021869,\n",
      "D(x): 0.494, D(G(z)): 0.497\n",
      "2019-04-09 23:32:09,146 root         INFO     Train Epoch: 17 [6656/8000 (83%)]\tTotal Loss: 0.419555\n",
      "Reconstruction: 0.313104, Regularization: 0.040185, Discriminator: 0.044582; Generator: 0.021684,\n",
      "D(x): 0.483, D(G(z)): 0.500\n",
      "2019-04-09 23:32:09,257 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 2.055559\n",
      "Reconstruction: 1.935305, Regularization: 0.054503, Discriminator: 0.044022; Generator: 0.021730,\n",
      "D(x): 0.491, D(G(z)): 0.499\n",
      "2019-04-09 23:32:09,367 root         INFO     Train Epoch: 17 [7680/8000 (96%)]\tTotal Loss: 0.444659\n",
      "Reconstruction: 0.341588, Regularization: 0.037205, Discriminator: 0.043831; Generator: 0.022035,\n",
      "D(x): 0.489, D(G(z)): 0.494\n",
      "2019-04-09 23:32:09,447 root         INFO     ====> Epoch: 17 Average loss: 283692.8422\n",
      "2019-04-09 23:32:09,474 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 6040.031250\n",
      "Reconstruction: 6039.873047, Regularization: 0.091577, Discriminator: 0.044586; Generator: 0.021887,\n",
      "D(x): 0.480, D(G(z)): 0.497\n",
      "2019-04-09 23:32:09,587 root         INFO     Train Epoch: 18 [512/8000 (6%)]\tTotal Loss: 51.577320\n",
      "Reconstruction: 51.379829, Regularization: 0.131268, Discriminator: 0.044202; Generator: 0.022022,\n",
      "D(x): 0.484, D(G(z)): 0.494\n",
      "2019-04-09 23:32:09,700 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.730884\n",
      "Reconstruction: 0.615365, Regularization: 0.048809, Discriminator: 0.044993; Generator: 0.021718,\n",
      "D(x): 0.476, D(G(z)): 0.499\n",
      "2019-04-09 23:32:09,813 root         INFO     Train Epoch: 18 [1536/8000 (19%)]\tTotal Loss: 0.263675\n",
      "Reconstruction: 0.142742, Regularization: 0.054746, Discriminator: 0.044412; Generator: 0.021775,\n",
      "D(x): 0.484, D(G(z)): 0.498\n",
      "2019-04-09 23:32:09,925 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 1.503814\n",
      "Reconstruction: 1.363337, Regularization: 0.073942, Discriminator: 0.044970; Generator: 0.021566,\n",
      "D(x): 0.478, D(G(z)): 0.502\n",
      "2019-04-09 23:32:10,036 root         INFO     Train Epoch: 18 [2560/8000 (32%)]\tTotal Loss: 0.383377\n",
      "Reconstruction: 0.270026, Regularization: 0.047033, Discriminator: 0.044308; Generator: 0.022009,\n",
      "D(x): 0.482, D(G(z)): 0.495\n",
      "2019-04-09 23:32:10,149 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.328217\n",
      "Reconstruction: 0.214606, Regularization: 0.047548, Discriminator: 0.044517; Generator: 0.021547,\n",
      "D(x): 0.486, D(G(z)): 0.502\n",
      "2019-04-09 23:32:10,261 root         INFO     Train Epoch: 18 [3584/8000 (45%)]\tTotal Loss: 0.516288\n",
      "Reconstruction: 0.419057, Regularization: 0.030762, Discriminator: 0.044694; Generator: 0.021775,\n",
      "D(x): 0.479, D(G(z)): 0.498\n",
      "2019-04-09 23:32:10,373 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 2.410261\n",
      "Reconstruction: 2.294819, Regularization: 0.049649, Discriminator: 0.044121; Generator: 0.021671,\n",
      "D(x): 0.490, D(G(z)): 0.500\n",
      "2019-04-09 23:32:10,485 root         INFO     Train Epoch: 18 [4608/8000 (58%)]\tTotal Loss: 0.387635\n",
      "Reconstruction: 0.271608, Regularization: 0.049890, Discriminator: 0.044403; Generator: 0.021735,\n",
      "D(x): 0.484, D(G(z)): 0.499\n",
      "2019-04-09 23:32:10,597 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.534021\n",
      "Reconstruction: 0.415149, Regularization: 0.053053, Discriminator: 0.044237; Generator: 0.021582,\n",
      "D(x): 0.489, D(G(z)): 0.501\n",
      "2019-04-09 23:32:10,709 root         INFO     Train Epoch: 18 [5632/8000 (70%)]\tTotal Loss: 6.745879\n",
      "Reconstruction: 6.522832, Regularization: 0.157547, Discriminator: 0.043596; Generator: 0.021904,\n",
      "D(x): 0.494, D(G(z)): 0.496\n",
      "2019-04-09 23:32:10,821 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 0.318190\n",
      "Reconstruction: 0.212527, Regularization: 0.038929, Discriminator: 0.044853; Generator: 0.021880,\n",
      "D(x): 0.475, D(G(z)): 0.497\n",
      "2019-04-09 23:32:10,933 root         INFO     Train Epoch: 18 [6656/8000 (83%)]\tTotal Loss: 0.622060\n",
      "Reconstruction: 0.484687, Regularization: 0.071527, Discriminator: 0.044219; Generator: 0.021627,\n",
      "D(x): 0.489, D(G(z)): 0.501\n",
      "2019-04-09 23:32:11,045 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 1.766720\n",
      "Reconstruction: 1.661784, Regularization: 0.038499, Discriminator: 0.044786; Generator: 0.021650,\n",
      "D(x): 0.479, D(G(z)): 0.501\n",
      "2019-04-09 23:32:11,157 root         INFO     Train Epoch: 18 [7680/8000 (96%)]\tTotal Loss: 1.621722\n",
      "Reconstruction: 1.504689, Regularization: 0.050677, Discriminator: 0.044523; Generator: 0.021835,\n",
      "D(x): 0.482, D(G(z)): 0.498\n",
      "2019-04-09 23:32:11,238 root         INFO     ====> Epoch: 18 Average loss: 36206450146.6870\n",
      "2019-04-09 23:32:11,264 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 8.064442\n",
      "Reconstruction: 7.932393, Regularization: 0.065795, Discriminator: 0.044437; Generator: 0.021816,\n",
      "D(x): 0.482, D(G(z)): 0.498\n",
      "2019-04-09 23:32:11,376 root         INFO     Train Epoch: 19 [512/8000 (6%)]\tTotal Loss: 0.427242\n",
      "Reconstruction: 0.310553, Regularization: 0.051086, Discriminator: 0.043899; Generator: 0.021704,\n",
      "D(x): 0.492, D(G(z)): 0.500\n",
      "2019-04-09 23:32:11,487 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 0.649777\n",
      "Reconstruction: 0.498133, Regularization: 0.085118, Discriminator: 0.044701; Generator: 0.021824,\n",
      "D(x): 0.478, D(G(z)): 0.498\n",
      "2019-04-09 23:32:11,598 root         INFO     Train Epoch: 19 [1536/8000 (19%)]\tTotal Loss: 1.717353\n",
      "Reconstruction: 1.533369, Regularization: 0.117830, Discriminator: 0.044297; Generator: 0.021858,\n",
      "D(x): 0.483, D(G(z)): 0.497\n",
      "2019-04-09 23:32:11,707 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 2.570236\n",
      "Reconstruction: 2.438264, Regularization: 0.065361, Discriminator: 0.044869; Generator: 0.021743,\n",
      "D(x): 0.477, D(G(z)): 0.499\n",
      "2019-04-09 23:32:11,817 root         INFO     Train Epoch: 19 [2560/8000 (32%)]\tTotal Loss: 0.424350\n",
      "Reconstruction: 0.300543, Regularization: 0.057915, Discriminator: 0.044014; Generator: 0.021878,\n",
      "D(x): 0.487, D(G(z)): 0.497\n",
      "2019-04-09 23:32:11,927 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 2.380589\n",
      "Reconstruction: 2.270767, Regularization: 0.043452, Discriminator: 0.044495; Generator: 0.021874,\n",
      "D(x): 0.480, D(G(z)): 0.497\n",
      "2019-04-09 23:32:12,037 root         INFO     Train Epoch: 19 [3584/8000 (45%)]\tTotal Loss: 0.455571\n",
      "Reconstruction: 0.331866, Regularization: 0.058065, Discriminator: 0.043776; Generator: 0.021865,\n",
      "D(x): 0.492, D(G(z)): 0.497\n",
      "2019-04-09 23:32:12,146 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 2.053105\n",
      "Reconstruction: 1.868322, Regularization: 0.118479, Discriminator: 0.044458; Generator: 0.021846,\n",
      "D(x): 0.482, D(G(z)): 0.497\n",
      "2019-04-09 23:32:12,257 root         INFO     Train Epoch: 19 [4608/8000 (58%)]\tTotal Loss: 5.584898\n",
      "Reconstruction: 5.461335, Regularization: 0.057182, Discriminator: 0.044298; Generator: 0.022084,\n",
      "D(x): 0.480, D(G(z)): 0.494\n",
      "2019-04-09 23:32:12,369 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 1.025823\n",
      "Reconstruction: 0.919788, Regularization: 0.039420, Discriminator: 0.044470; Generator: 0.022145,\n",
      "D(x): 0.476, D(G(z)): 0.493\n",
      "2019-04-09 23:32:12,480 root         INFO     Train Epoch: 19 [5632/8000 (70%)]\tTotal Loss: 21.110271\n",
      "Reconstruction: 20.969261, Regularization: 0.075132, Discriminator: 0.044090; Generator: 0.021788,\n",
      "D(x): 0.487, D(G(z)): 0.498\n",
      "2019-04-09 23:32:12,591 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 1.064807\n",
      "Reconstruction: 0.949068, Regularization: 0.049708, Discriminator: 0.043977; Generator: 0.022054,\n",
      "D(x): 0.485, D(G(z)): 0.494\n",
      "2019-04-09 23:32:12,703 root         INFO     Train Epoch: 19 [6656/8000 (83%)]\tTotal Loss: 2.205979\n",
      "Reconstruction: 2.032943, Regularization: 0.106765, Discriminator: 0.044205; Generator: 0.022066,\n",
      "D(x): 0.481, D(G(z)): 0.494\n",
      "2019-04-09 23:32:12,816 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.938650\n",
      "Reconstruction: 0.828418, Regularization: 0.043967, Discriminator: 0.044440; Generator: 0.021825,\n",
      "D(x): 0.481, D(G(z)): 0.498\n",
      "2019-04-09 23:32:12,928 root         INFO     Train Epoch: 19 [7680/8000 (96%)]\tTotal Loss: 42.083759\n",
      "Reconstruction: 41.969391, Regularization: 0.048742, Discriminator: 0.043671; Generator: 0.021958,\n",
      "D(x): 0.492, D(G(z)): 0.496\n",
      "2019-04-09 23:32:13,010 root         INFO     ====> Epoch: 19 Average loss: 59878586.8386\n",
      "2019-04-09 23:32:13,037 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 3181.546875\n",
      "Reconstruction: 3181.345947, Regularization: 0.134185, Discriminator: 0.044254; Generator: 0.022282,\n",
      "D(x): 0.477, D(G(z)): 0.491\n",
      "2019-04-09 23:32:13,150 root         INFO     Train Epoch: 20 [512/8000 (6%)]\tTotal Loss: 1.889823\n",
      "Reconstruction: 1.794935, Regularization: 0.028687, Discriminator: 0.043871; Generator: 0.022330,\n",
      "D(x): 0.482, D(G(z)): 0.490\n",
      "2019-04-09 23:32:13,262 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 0.664355\n",
      "Reconstruction: 0.563367, Regularization: 0.034537, Discriminator: 0.044331; Generator: 0.022119,\n",
      "D(x): 0.478, D(G(z)): 0.493\n",
      "2019-04-09 23:32:13,374 root         INFO     Train Epoch: 20 [1536/8000 (19%)]\tTotal Loss: 508789.031250\n",
      "Reconstruction: 508788.781250, Regularization: 0.190273, Discriminator: 0.043901; Generator: 0.021803,\n",
      "D(x): 0.490, D(G(z)): 0.498\n",
      "2019-04-09 23:32:13,486 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 436758080.000000\n",
      "Reconstruction: 436758080.000000, Regularization: 0.203695, Discriminator: 0.044179; Generator: 0.021828,\n",
      "D(x): 0.485, D(G(z)): 0.498\n",
      "2019-04-09 23:32:13,598 root         INFO     Train Epoch: 20 [2560/8000 (32%)]\tTotal Loss: 6.266575\n",
      "Reconstruction: 6.141014, Regularization: 0.059872, Discriminator: 0.043351; Generator: 0.022339,\n",
      "D(x): 0.490, D(G(z)): 0.489\n",
      "2019-04-09 23:32:13,710 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 28.725651\n",
      "Reconstruction: 28.579454, Regularization: 0.080337, Discriminator: 0.043637; Generator: 0.022222,\n",
      "D(x): 0.487, D(G(z)): 0.491\n",
      "2019-04-09 23:32:13,821 root         INFO     Train Epoch: 20 [3584/8000 (45%)]\tTotal Loss: 2285045547008.000000\n",
      "Reconstruction: 2285045547008.000000, Regularization: 0.271207, Discriminator: 0.043966; Generator: 0.021908,\n",
      "D(x): 0.487, D(G(z)): 0.496\n",
      "2019-04-09 23:32:13,933 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 16.917793\n",
      "Reconstruction: 16.781010, Regularization: 0.071167, Discriminator: 0.043974; Generator: 0.021644,\n",
      "D(x): 0.491, D(G(z)): 0.501\n",
      "2019-04-09 23:32:14,045 root         INFO     Train Epoch: 20 [4608/8000 (58%)]\tTotal Loss: 247.894913\n",
      "Reconstruction: 247.741791, Regularization: 0.087356, Discriminator: 0.043921; Generator: 0.021852,\n",
      "D(x): 0.489, D(G(z)): 0.497\n",
      "2019-04-09 23:32:14,157 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 0.467980\n",
      "Reconstruction: 0.366922, Regularization: 0.035041, Discriminator: 0.044810; Generator: 0.021207,\n",
      "D(x): 0.485, D(G(z)): 0.508\n",
      "2019-04-09 23:32:14,269 root         INFO     Train Epoch: 20 [5632/8000 (70%)]\tTotal Loss: 13.926498\n",
      "Reconstruction: 13.789255, Regularization: 0.071247, Discriminator: 0.043879; Generator: 0.022117,\n",
      "D(x): 0.485, D(G(z)): 0.493\n",
      "2019-04-09 23:32:14,381 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 0.709808\n",
      "Reconstruction: 0.619273, Regularization: 0.024407, Discriminator: 0.043948; Generator: 0.022180,\n",
      "D(x): 0.483, D(G(z)): 0.492\n",
      "2019-04-09 23:32:14,493 root         INFO     Train Epoch: 20 [6656/8000 (83%)]\tTotal Loss: 6.300289\n",
      "Reconstruction: 6.174956, Regularization: 0.059359, Discriminator: 0.043746; Generator: 0.022229,\n",
      "D(x): 0.485, D(G(z)): 0.491\n",
      "2019-04-09 23:32:14,604 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 107264.343750\n",
      "Reconstruction: 107264.164062, Regularization: 0.116164, Discriminator: 0.043921; Generator: 0.022277,\n",
      "D(x): 0.482, D(G(z)): 0.491\n",
      "2019-04-09 23:32:14,715 root         INFO     Train Epoch: 20 [7680/8000 (96%)]\tTotal Loss: 0.729514\n",
      "Reconstruction: 0.579565, Regularization: 0.083772, Discriminator: 0.044243; Generator: 0.021933,\n",
      "D(x): 0.483, D(G(z)): 0.496\n",
      "2019-04-09 23:32:14,795 root         INFO     ====> Epoch: 20 Average loss: 36867005478.7838\n",
      "2019-04-09 23:32:14,822 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.445693\n",
      "Reconstruction: 0.334739, Regularization: 0.044903, Discriminator: 0.044124; Generator: 0.021927,\n",
      "D(x): 0.484, D(G(z)): 0.496\n",
      "2019-04-09 23:32:14,934 root         INFO     Train Epoch: 21 [512/8000 (6%)]\tTotal Loss: 0.692765\n",
      "Reconstruction: 0.583426, Regularization: 0.043559, Discriminator: 0.044083; Generator: 0.021696,\n",
      "D(x): 0.488, D(G(z)): 0.500\n",
      "2019-04-09 23:32:15,045 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 4.227095\n",
      "Reconstruction: 4.124422, Regularization: 0.037100, Discriminator: 0.043450; Generator: 0.022122,\n",
      "D(x): 0.491, D(G(z)): 0.493\n",
      "2019-04-09 23:32:15,157 root         INFO     Train Epoch: 21 [1536/8000 (19%)]\tTotal Loss: 1.861134\n",
      "Reconstruction: 1.686363, Regularization: 0.108932, Discriminator: 0.043974; Generator: 0.021866,\n",
      "D(x): 0.487, D(G(z)): 0.497\n",
      "2019-04-09 23:32:15,268 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 2.763917\n",
      "Reconstruction: 2.646012, Regularization: 0.051487, Discriminator: 0.044381; Generator: 0.022038,\n",
      "D(x): 0.479, D(G(z)): 0.495\n",
      "2019-04-09 23:32:15,380 root         INFO     Train Epoch: 21 [2560/8000 (32%)]\tTotal Loss: 2.324522\n",
      "Reconstruction: 2.144451, Regularization: 0.114252, Discriminator: 0.043597; Generator: 0.022221,\n",
      "D(x): 0.488, D(G(z)): 0.491\n",
      "2019-04-09 23:32:15,491 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 300493.968750\n",
      "Reconstruction: 300493.812500, Regularization: 0.087595, Discriminator: 0.044196; Generator: 0.021919,\n",
      "D(x): 0.483, D(G(z)): 0.496\n",
      "2019-04-09 23:32:15,603 root         INFO     Train Epoch: 21 [3584/8000 (45%)]\tTotal Loss: 0.555209\n",
      "Reconstruction: 0.420273, Regularization: 0.068877, Discriminator: 0.044098; Generator: 0.021961,\n",
      "D(x): 0.484, D(G(z)): 0.495\n",
      "2019-04-09 23:32:15,714 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.814883\n",
      "Reconstruction: 0.722133, Regularization: 0.026999, Discriminator: 0.043991; Generator: 0.021759,\n",
      "D(x): 0.489, D(G(z)): 0.499\n",
      "2019-04-09 23:32:15,825 root         INFO     Train Epoch: 21 [4608/8000 (58%)]\tTotal Loss: 1.119076\n",
      "Reconstruction: 1.003912, Regularization: 0.049126, Discriminator: 0.043925; Generator: 0.022113,\n",
      "D(x): 0.484, D(G(z)): 0.493\n",
      "2019-04-09 23:32:15,937 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 715550.000000\n",
      "Reconstruction: 715549.812500, Regularization: 0.136157, Discriminator: 0.043624; Generator: 0.021980,\n",
      "D(x): 0.491, D(G(z)): 0.495\n",
      "2019-04-09 23:32:16,048 root         INFO     Train Epoch: 21 [5632/8000 (70%)]\tTotal Loss: 89699.281250\n",
      "Reconstruction: 89699.148438, Regularization: 0.073391, Discriminator: 0.043902; Generator: 0.021856,\n",
      "D(x): 0.488, D(G(z)): 0.497\n",
      "2019-04-09 23:32:16,160 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 18410179745808384.000000\n",
      "Reconstruction: 18410179745808384.000000, Regularization: 0.225437, Discriminator: 0.044032; Generator: 0.021918,\n",
      "D(x): 0.486, D(G(z)): 0.496\n",
      "2019-04-09 23:32:16,271 root         INFO     Train Epoch: 21 [6656/8000 (83%)]\tTotal Loss: 1.182790\n",
      "Reconstruction: 1.097995, Regularization: 0.019100, Discriminator: 0.043453; Generator: 0.022243,\n",
      "D(x): 0.490, D(G(z)): 0.491\n",
      "2019-04-09 23:32:16,382 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.545434\n",
      "Reconstruction: 0.422228, Regularization: 0.057411, Discriminator: 0.043683; Generator: 0.022111,\n",
      "D(x): 0.488, D(G(z)): 0.493\n",
      "2019-04-09 23:32:16,492 root         INFO     Train Epoch: 21 [7680/8000 (96%)]\tTotal Loss: 3.167809\n",
      "Reconstruction: 3.063272, Regularization: 0.038831, Discriminator: 0.044014; Generator: 0.021692,\n",
      "D(x): 0.489, D(G(z)): 0.500\n",
      "2019-04-09 23:32:16,573 root         INFO     ====> Epoch: 21 Average loss: 73701254803460.3438\n",
      "2019-04-09 23:32:16,601 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 3.217080\n",
      "Reconstruction: 3.124448, Regularization: 0.027021, Discriminator: 0.043736; Generator: 0.021876,\n",
      "D(x): 0.491, D(G(z)): 0.497\n",
      "2019-04-09 23:32:16,713 root         INFO     Train Epoch: 22 [512/8000 (6%)]\tTotal Loss: 1.510295\n",
      "Reconstruction: 1.405423, Regularization: 0.039136, Discriminator: 0.043597; Generator: 0.022138,\n",
      "D(x): 0.489, D(G(z)): 0.493\n",
      "2019-04-09 23:32:16,825 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 1.889898\n",
      "Reconstruction: 1.777451, Regularization: 0.046721, Discriminator: 0.043447; Generator: 0.022279,\n",
      "D(x): 0.489, D(G(z)): 0.491\n",
      "2019-04-09 23:32:16,937 root         INFO     Train Epoch: 22 [1536/8000 (19%)]\tTotal Loss: 4.330514\n",
      "Reconstruction: 4.223529, Regularization: 0.041216, Discriminator: 0.043708; Generator: 0.022061,\n",
      "D(x): 0.488, D(G(z)): 0.494\n",
      "2019-04-09 23:32:17,047 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 2247230.250000\n",
      "Reconstruction: 2247230.250000, Regularization: 0.080369, Discriminator: 0.043771; Generator: 0.022002,\n",
      "D(x): 0.488, D(G(z)): 0.495\n",
      "2019-04-09 23:32:17,158 root         INFO     Train Epoch: 22 [2560/8000 (32%)]\tTotal Loss: 1.944733\n",
      "Reconstruction: 1.812508, Regularization: 0.066466, Discriminator: 0.043981; Generator: 0.021778,\n",
      "D(x): 0.488, D(G(z)): 0.498\n",
      "2019-04-09 23:32:17,269 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 1917.827881\n",
      "Reconstruction: 1917.668213, Regularization: 0.094074, Discriminator: 0.043547; Generator: 0.022059,\n",
      "D(x): 0.491, D(G(z)): 0.494\n",
      "2019-04-09 23:32:17,382 root         INFO     Train Epoch: 22 [3584/8000 (45%)]\tTotal Loss: 0.714036\n",
      "Reconstruction: 0.627872, Regularization: 0.020402, Discriminator: 0.043816; Generator: 0.021946,\n",
      "D(x): 0.488, D(G(z)): 0.496\n",
      "2019-04-09 23:32:17,494 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.705474\n",
      "Reconstruction: 0.597825, Regularization: 0.042009, Discriminator: 0.043435; Generator: 0.022205,\n",
      "D(x): 0.490, D(G(z)): 0.492\n",
      "2019-04-09 23:32:17,605 root         INFO     Train Epoch: 22 [4608/8000 (58%)]\tTotal Loss: 2.933230\n",
      "Reconstruction: 2.779157, Regularization: 0.088264, Discriminator: 0.044055; Generator: 0.021753,\n",
      "D(x): 0.488, D(G(z)): 0.499\n",
      "2019-04-09 23:32:17,717 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 304.784637\n",
      "Reconstruction: 304.549591, Regularization: 0.169403, Discriminator: 0.043783; Generator: 0.021851,\n",
      "D(x): 0.490, D(G(z)): 0.497\n",
      "2019-04-09 23:32:17,828 root         INFO     Train Epoch: 22 [5632/8000 (70%)]\tTotal Loss: 16.464899\n",
      "Reconstruction: 16.349623, Regularization: 0.049696, Discriminator: 0.043624; Generator: 0.021955,\n",
      "D(x): 0.491, D(G(z)): 0.496\n",
      "2019-04-09 23:32:17,940 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 4.821315\n",
      "Reconstruction: 4.707745, Regularization: 0.047809, Discriminator: 0.043870; Generator: 0.021891,\n",
      "D(x): 0.488, D(G(z)): 0.497\n",
      "2019-04-09 23:32:18,051 root         INFO     Train Epoch: 22 [6656/8000 (83%)]\tTotal Loss: 3.356665\n",
      "Reconstruction: 3.258368, Regularization: 0.032710, Discriminator: 0.043849; Generator: 0.021738,\n",
      "D(x): 0.491, D(G(z)): 0.499\n",
      "2019-04-09 23:32:18,163 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 1.381315\n",
      "Reconstruction: 1.266862, Regularization: 0.048955, Discriminator: 0.043508; Generator: 0.021990,\n",
      "D(x): 0.492, D(G(z)): 0.495\n",
      "2019-04-09 23:32:18,274 root         INFO     Train Epoch: 22 [7680/8000 (96%)]\tTotal Loss: 21234824.000000\n",
      "Reconstruction: 21234824.000000, Regularization: 0.223779, Discriminator: 0.043759; Generator: 0.021817,\n",
      "D(x): 0.491, D(G(z)): 0.498\n",
      "2019-04-09 23:32:18,356 root         INFO     ====> Epoch: 22 Average loss: 31825523.1661\n",
      "2019-04-09 23:32:18,383 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 54.510159\n",
      "Reconstruction: 54.287685, Regularization: 0.156866, Discriminator: 0.043790; Generator: 0.021817,\n",
      "D(x): 0.491, D(G(z)): 0.498\n",
      "2019-04-09 23:32:18,496 root         INFO     Train Epoch: 23 [512/8000 (6%)]\tTotal Loss: 198.461517\n",
      "Reconstruction: 198.258011, Regularization: 0.137950, Discriminator: 0.043544; Generator: 0.022013,\n",
      "D(x): 0.491, D(G(z)): 0.495\n",
      "2019-04-09 23:32:18,608 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 1.747470\n",
      "Reconstruction: 1.658343, Regularization: 0.023700, Discriminator: 0.043671; Generator: 0.021756,\n",
      "D(x): 0.493, D(G(z)): 0.499\n",
      "2019-04-09 23:32:18,721 root         INFO     Train Epoch: 23 [1536/8000 (19%)]\tTotal Loss: 1.591613\n",
      "Reconstruction: 1.467969, Regularization: 0.058122, Discriminator: 0.043784; Generator: 0.021738,\n",
      "D(x): 0.492, D(G(z)): 0.499\n",
      "2019-04-09 23:32:18,835 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 1.383659\n",
      "Reconstruction: 1.279292, Regularization: 0.038891, Discriminator: 0.043546; Generator: 0.021931,\n",
      "D(x): 0.493, D(G(z)): 0.496\n",
      "2019-04-09 23:32:18,949 root         INFO     Train Epoch: 23 [2560/8000 (32%)]\tTotal Loss: 0.459300\n",
      "Reconstruction: 0.355214, Regularization: 0.038704, Discriminator: 0.043378; Generator: 0.022004,\n",
      "D(x): 0.494, D(G(z)): 0.495\n",
      "2019-04-09 23:32:19,062 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 1.253283\n",
      "Reconstruction: 1.126763, Regularization: 0.061042, Discriminator: 0.043575; Generator: 0.021903,\n",
      "D(x): 0.493, D(G(z)): 0.496\n",
      "2019-04-09 23:32:19,174 root         INFO     Train Epoch: 23 [3584/8000 (45%)]\tTotal Loss: 4.166656\n",
      "Reconstruction: 4.058538, Regularization: 0.042663, Discriminator: 0.043653; Generator: 0.021802,\n",
      "D(x): 0.493, D(G(z)): 0.498\n",
      "2019-04-09 23:32:19,285 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 1.138025\n",
      "Reconstruction: 1.016673, Regularization: 0.055909, Discriminator: 0.043571; Generator: 0.021871,\n",
      "D(x): 0.493, D(G(z)): 0.497\n",
      "2019-04-09 23:32:19,404 root         INFO     Train Epoch: 23 [4608/8000 (58%)]\tTotal Loss: 63178399744.000000\n",
      "Reconstruction: 63178399744.000000, Regularization: 0.288514, Discriminator: 0.043520; Generator: 0.021851,\n",
      "D(x): 0.494, D(G(z)): 0.497\n",
      "2019-04-09 23:32:19,514 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 1.705319\n",
      "Reconstruction: 1.569265, Regularization: 0.070556, Discriminator: 0.043553; Generator: 0.021945,\n",
      "D(x): 0.492, D(G(z)): 0.496\n",
      "2019-04-09 23:32:19,623 root         INFO     Train Epoch: 23 [5632/8000 (70%)]\tTotal Loss: 4141.864746\n",
      "Reconstruction: 4141.569824, Regularization: 0.229633, Discriminator: 0.043554; Generator: 0.021816,\n",
      "D(x): 0.494, D(G(z)): 0.498\n",
      "2019-04-09 23:32:19,732 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 2.322900\n",
      "Reconstruction: 2.184957, Regularization: 0.072525, Discriminator: 0.043552; Generator: 0.021866,\n",
      "D(x): 0.493, D(G(z)): 0.497\n",
      "2019-04-09 23:32:19,842 root         INFO     Train Epoch: 23 [6656/8000 (83%)]\tTotal Loss: 92520392.000000\n",
      "Reconstruction: 92520392.000000, Regularization: 0.318948, Discriminator: 0.043382; Generator: 0.022048,\n",
      "D(x): 0.493, D(G(z)): 0.494\n",
      "2019-04-09 23:32:19,954 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 63.184086\n",
      "Reconstruction: 63.073872, Regularization: 0.044870, Discriminator: 0.043423; Generator: 0.021921,\n",
      "D(x): 0.494, D(G(z)): 0.496\n",
      "2019-04-09 23:32:20,064 root         INFO     Train Epoch: 23 [7680/8000 (96%)]\tTotal Loss: 1.044614\n",
      "Reconstruction: 0.920048, Regularization: 0.059271, Discriminator: 0.043248; Generator: 0.022047,\n",
      "D(x): 0.495, D(G(z)): 0.494\n",
      "2019-04-09 23:32:20,144 root         INFO     ====> Epoch: 23 Average loss: 32000103419.3229\n",
      "2019-04-09 23:32:20,171 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.873523\n",
      "Reconstruction: 0.748368, Regularization: 0.059846, Discriminator: 0.043531; Generator: 0.021778,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 23:32:20,282 root         INFO     Train Epoch: 24 [512/8000 (6%)]\tTotal Loss: 0.691241\n",
      "Reconstruction: 0.600729, Regularization: 0.025293, Discriminator: 0.043513; Generator: 0.021706,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 23:32:20,393 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 5896.031738\n",
      "Reconstruction: 5895.908691, Regularization: 0.057450, Discriminator: 0.043377; Generator: 0.021870,\n",
      "D(x): 0.496, D(G(z)): 0.497\n",
      "2019-04-09 23:32:20,504 root         INFO     Train Epoch: 24 [1536/8000 (19%)]\tTotal Loss: 2.062202\n",
      "Reconstruction: 1.930353, Regularization: 0.066585, Discriminator: 0.043424; Generator: 0.021841,\n",
      "D(x): 0.496, D(G(z)): 0.497\n",
      "2019-04-09 23:32:20,614 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 0.702579\n",
      "Reconstruction: 0.602383, Regularization: 0.035033, Discriminator: 0.043303; Generator: 0.021861,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-09 23:32:20,725 root         INFO     Train Epoch: 24 [2560/8000 (32%)]\tTotal Loss: 2.185204\n",
      "Reconstruction: 2.085378, Regularization: 0.034663, Discriminator: 0.043388; Generator: 0.021775,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 23:32:20,835 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 4.297981\n",
      "Reconstruction: 3.993122, Regularization: 0.239729, Discriminator: 0.043348; Generator: 0.021782,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 23:32:20,946 root         INFO     Train Epoch: 24 [3584/8000 (45%)]\tTotal Loss: 1115599.375000\n",
      "Reconstruction: 1115599.125000, Regularization: 0.113422, Discriminator: 0.043384; Generator: 0.021797,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 23:32:21,056 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 4.956249\n",
      "Reconstruction: 4.820906, Regularization: 0.070182, Discriminator: 0.043453; Generator: 0.021708,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:32:21,165 root         INFO     Train Epoch: 24 [4608/8000 (58%)]\tTotal Loss: 15.187662\n",
      "Reconstruction: 14.975285, Regularization: 0.147278, Discriminator: 0.043331; Generator: 0.021768,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 23:32:21,274 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 2.900147\n",
      "Reconstruction: 2.793447, Regularization: 0.041658, Discriminator: 0.043283; Generator: 0.021760,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 23:32:21,383 root         INFO     Train Epoch: 24 [5632/8000 (70%)]\tTotal Loss: 5.064974\n",
      "Reconstruction: 4.968298, Regularization: 0.031657, Discriminator: 0.043194; Generator: 0.021825,\n",
      "D(x): 0.499, D(G(z)): 0.497\n",
      "2019-04-09 23:32:21,492 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 0.962989\n",
      "Reconstruction: 0.861271, Regularization: 0.036744, Discriminator: 0.043183; Generator: 0.021791,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 23:32:21,600 root         INFO     Train Epoch: 24 [6656/8000 (83%)]\tTotal Loss: 82.509850\n",
      "Reconstruction: 82.380844, Regularization: 0.063969, Discriminator: 0.043234; Generator: 0.021798,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 23:32:21,709 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 0.784352\n",
      "Reconstruction: 0.688778, Regularization: 0.030659, Discriminator: 0.043190; Generator: 0.021724,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:32:21,818 root         INFO     Train Epoch: 24 [7680/8000 (96%)]\tTotal Loss: 0.651411\n",
      "Reconstruction: 0.544331, Regularization: 0.042132, Discriminator: 0.043228; Generator: 0.021720,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:32:21,897 root         INFO     ====> Epoch: 24 Average loss: 25839526491.8264\n",
      "2019-04-09 23:32:21,924 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 2.210519\n",
      "Reconstruction: 2.106294, Regularization: 0.039396, Discriminator: 0.043070; Generator: 0.021758,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 23:32:22,035 root         INFO     Train Epoch: 25 [512/8000 (6%)]\tTotal Loss: 3.242969\n",
      "Reconstruction: 3.137726, Regularization: 0.040421, Discriminator: 0.043067; Generator: 0.021756,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 23:32:22,146 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 24324.460938\n",
      "Reconstruction: 24324.298828, Regularization: 0.097571, Discriminator: 0.043134; Generator: 0.021731,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 23:32:22,257 root         INFO     Train Epoch: 25 [1536/8000 (19%)]\tTotal Loss: 12.556597\n",
      "Reconstruction: 12.410299, Regularization: 0.081429, Discriminator: 0.043144; Generator: 0.021725,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 23:32:22,368 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 867.863525\n",
      "Reconstruction: 867.545898, Regularization: 0.252663, Discriminator: 0.043206; Generator: 0.021733,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:32:22,479 root         INFO     Train Epoch: 25 [2560/8000 (32%)]\tTotal Loss: 37.470928\n",
      "Reconstruction: 37.376297, Regularization: 0.029850, Discriminator: 0.043042; Generator: 0.021740,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 23:32:22,591 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 1.165778\n",
      "Reconstruction: 1.027276, Regularization: 0.073686, Discriminator: 0.043132; Generator: 0.021684,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:32:22,702 root         INFO     Train Epoch: 25 [3584/8000 (45%)]\tTotal Loss: 41.459770\n",
      "Reconstruction: 41.345554, Regularization: 0.049421, Discriminator: 0.043078; Generator: 0.021719,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 23:32:22,813 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 108.379326\n",
      "Reconstruction: 108.255661, Regularization: 0.058889, Discriminator: 0.043100; Generator: 0.021673,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:32:22,924 root         INFO     Train Epoch: 25 [4608/8000 (58%)]\tTotal Loss: 37.019165\n",
      "Reconstruction: 36.895222, Regularization: 0.059281, Discriminator: 0.043069; Generator: 0.021595,\n",
      "D(x): 0.505, D(G(z)): 0.501\n",
      "2019-04-09 23:32:23,034 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 551.521729\n",
      "Reconstruction: 551.379944, Regularization: 0.076962, Discriminator: 0.043124; Generator: 0.021670,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:32:23,144 root         INFO     Train Epoch: 25 [5632/8000 (70%)]\tTotal Loss: 694.518555\n",
      "Reconstruction: 694.381653, Regularization: 0.072111, Discriminator: 0.043102; Generator: 0.021735,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 23:32:23,254 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.781611\n",
      "Reconstruction: 0.666203, Regularization: 0.050549, Discriminator: 0.043110; Generator: 0.021749,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 23:32:23,364 root         INFO     Train Epoch: 25 [6656/8000 (83%)]\tTotal Loss: 2.073731\n",
      "Reconstruction: 1.961818, Regularization: 0.047307, Discriminator: 0.042908; Generator: 0.021699,\n",
      "D(x): 0.506, D(G(z)): 0.499\n",
      "2019-04-09 23:32:23,474 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 2.644437\n",
      "Reconstruction: 2.540962, Regularization: 0.038848, Discriminator: 0.042827; Generator: 0.021801,\n",
      "D(x): 0.506, D(G(z)): 0.498\n",
      "2019-04-09 23:32:23,584 root         INFO     Train Epoch: 25 [7680/8000 (96%)]\tTotal Loss: 1.689569\n",
      "Reconstruction: 1.595093, Regularization: 0.029797, Discriminator: 0.042939; Generator: 0.021741,\n",
      "D(x): 0.505, D(G(z)): 0.499\n",
      "2019-04-09 23:32:23,666 root         INFO     ====> Epoch: 25 Average loss: 3500494779251.6904\n",
      "2019-04-09 23:32:23,693 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 2.299179\n",
      "Reconstruction: 2.178431, Regularization: 0.056040, Discriminator: 0.043093; Generator: 0.021616,\n",
      "D(x): 0.505, D(G(z)): 0.501\n",
      "2019-04-09 23:32:23,803 root         INFO     Train Epoch: 26 [512/8000 (6%)]\tTotal Loss: 1.192180\n",
      "Reconstruction: 1.061241, Regularization: 0.066476, Discriminator: 0.042928; Generator: 0.021535,\n",
      "D(x): 0.509, D(G(z)): 0.502\n",
      "2019-04-09 23:32:23,914 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 1.826108\n",
      "Reconstruction: 1.689863, Regularization: 0.071782, Discriminator: 0.042768; Generator: 0.021696,\n",
      "D(x): 0.509, D(G(z)): 0.500\n",
      "2019-04-09 23:32:24,024 root         INFO     Train Epoch: 26 [1536/8000 (19%)]\tTotal Loss: 0.788009\n",
      "Reconstruction: 0.624139, Regularization: 0.099440, Discriminator: 0.042671; Generator: 0.021760,\n",
      "D(x): 0.509, D(G(z)): 0.499\n",
      "2019-04-09 23:32:24,135 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 1.353760\n",
      "Reconstruction: 1.209169, Regularization: 0.079970, Discriminator: 0.042903; Generator: 0.021718,\n",
      "D(x): 0.506, D(G(z)): 0.499\n",
      "2019-04-09 23:32:24,246 root         INFO     Train Epoch: 26 [2560/8000 (32%)]\tTotal Loss: 15.634089\n",
      "Reconstruction: 15.527970, Regularization: 0.041450, Discriminator: 0.043227; Generator: 0.021442,\n",
      "D(x): 0.505, D(G(z)): 0.504\n",
      "2019-04-09 23:32:24,357 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 3835038.750000\n",
      "Reconstruction: 3835038.750000, Regularization: 0.074802, Discriminator: 0.042806; Generator: 0.021699,\n",
      "D(x): 0.508, D(G(z)): 0.500\n",
      "2019-04-09 23:32:24,468 root         INFO     Train Epoch: 26 [3584/8000 (45%)]\tTotal Loss: 310.040192\n",
      "Reconstruction: 309.904846, Regularization: 0.070744, Discriminator: 0.043267; Generator: 0.021339,\n",
      "D(x): 0.507, D(G(z)): 0.505\n",
      "2019-04-09 23:32:24,579 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.314342\n",
      "Reconstruction: 0.222534, Regularization: 0.026951, Discriminator: 0.043397; Generator: 0.021460,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-09 23:32:24,690 root         INFO     Train Epoch: 26 [4608/8000 (58%)]\tTotal Loss: 4.722187\n",
      "Reconstruction: 4.605606, Regularization: 0.052377, Discriminator: 0.042720; Generator: 0.021484,\n",
      "D(x): 0.513, D(G(z)): 0.503\n",
      "2019-04-09 23:32:24,801 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 19.873466\n",
      "Reconstruction: 19.774416, Regularization: 0.034681, Discriminator: 0.042426; Generator: 0.021944,\n",
      "D(x): 0.510, D(G(z)): 0.496\n",
      "2019-04-09 23:32:24,912 root         INFO     Train Epoch: 26 [5632/8000 (70%)]\tTotal Loss: 0.490302\n",
      "Reconstruction: 0.394764, Regularization: 0.031381, Discriminator: 0.042769; Generator: 0.021388,\n",
      "D(x): 0.514, D(G(z)): 0.505\n",
      "2019-04-09 23:32:25,023 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 32.848633\n",
      "Reconstruction: 32.719826, Regularization: 0.064420, Discriminator: 0.042822; Generator: 0.021565,\n",
      "D(x): 0.510, D(G(z)): 0.502\n",
      "2019-04-09 23:32:25,134 root         INFO     Train Epoch: 26 [6656/8000 (83%)]\tTotal Loss: 69.317932\n",
      "Reconstruction: 69.181694, Regularization: 0.071785, Discriminator: 0.042365; Generator: 0.022091,\n",
      "D(x): 0.509, D(G(z)): 0.493\n",
      "2019-04-09 23:32:25,245 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 3.522086\n",
      "Reconstruction: 3.358532, Regularization: 0.098825, Discriminator: 0.043142; Generator: 0.021586,\n",
      "D(x): 0.505, D(G(z)): 0.502\n",
      "2019-04-09 23:32:25,356 root         INFO     Train Epoch: 26 [7680/8000 (96%)]\tTotal Loss: 0.339323\n",
      "Reconstruction: 0.243723, Regularization: 0.030814, Discriminator: 0.043027; Generator: 0.021759,\n",
      "D(x): 0.504, D(G(z)): 0.499\n",
      "2019-04-09 23:32:25,436 root         INFO     ====> Epoch: 26 Average loss: 2117927126.6577\n",
      "2019-04-09 23:32:25,463 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 0.847077\n",
      "Reconstruction: 0.657088, Regularization: 0.125614, Discriminator: 0.042905; Generator: 0.021471,\n",
      "D(x): 0.511, D(G(z)): 0.503\n",
      "2019-04-09 23:32:25,575 root         INFO     Train Epoch: 27 [512/8000 (6%)]\tTotal Loss: 5.691997\n",
      "Reconstruction: 5.552535, Regularization: 0.074861, Discriminator: 0.042795; Generator: 0.021807,\n",
      "D(x): 0.507, D(G(z)): 0.498\n",
      "2019-04-09 23:32:25,687 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.378532\n",
      "Reconstruction: 0.284206, Regularization: 0.029934, Discriminator: 0.042654; Generator: 0.021738,\n",
      "D(x): 0.510, D(G(z)): 0.499\n",
      "2019-04-09 23:32:25,797 root         INFO     Train Epoch: 27 [1536/8000 (19%)]\tTotal Loss: 5.826857\n",
      "Reconstruction: 5.680371, Regularization: 0.082024, Discriminator: 0.042730; Generator: 0.021732,\n",
      "D(x): 0.509, D(G(z)): 0.499\n",
      "2019-04-09 23:32:25,906 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 1.086032\n",
      "Reconstruction: 0.990405, Regularization: 0.031247, Discriminator: 0.042368; Generator: 0.022011,\n",
      "D(x): 0.512, D(G(z)): 0.495\n",
      "2019-04-09 23:32:26,016 root         INFO     Train Epoch: 27 [2560/8000 (32%)]\tTotal Loss: 7.568831\n",
      "Reconstruction: 7.456610, Regularization: 0.047495, Discriminator: 0.043031; Generator: 0.021696,\n",
      "D(x): 0.506, D(G(z)): 0.500\n",
      "2019-04-09 23:32:26,127 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.851301\n",
      "Reconstruction: 0.557183, Regularization: 0.229885, Discriminator: 0.042328; Generator: 0.021906,\n",
      "D(x): 0.514, D(G(z)): 0.497\n",
      "2019-04-09 23:32:26,237 root         INFO     Train Epoch: 27 [3584/8000 (45%)]\tTotal Loss: 0.303104\n",
      "Reconstruction: 0.191780, Regularization: 0.046603, Discriminator: 0.042932; Generator: 0.021789,\n",
      "D(x): 0.506, D(G(z)): 0.499\n",
      "2019-04-09 23:32:26,347 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 734.349976\n",
      "Reconstruction: 734.123840, Regularization: 0.161884, Discriminator: 0.042609; Generator: 0.021641,\n",
      "D(x): 0.513, D(G(z)): 0.501\n",
      "2019-04-09 23:32:26,458 root         INFO     Train Epoch: 27 [4608/8000 (58%)]\tTotal Loss: 0.323402\n",
      "Reconstruction: 0.215751, Regularization: 0.043429, Discriminator: 0.042254; Generator: 0.021969,\n",
      "D(x): 0.514, D(G(z)): 0.496\n",
      "2019-04-09 23:32:26,569 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.538838\n",
      "Reconstruction: 0.439018, Regularization: 0.035281, Discriminator: 0.042621; Generator: 0.021918,\n",
      "D(x): 0.509, D(G(z)): 0.496\n",
      "2019-04-09 23:32:26,683 root         INFO     Train Epoch: 27 [5632/8000 (70%)]\tTotal Loss: 0.328972\n",
      "Reconstruction: 0.213088, Regularization: 0.051615, Discriminator: 0.042124; Generator: 0.022145,\n",
      "D(x): 0.513, D(G(z)): 0.493\n",
      "2019-04-09 23:32:26,796 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.494449\n",
      "Reconstruction: 0.399285, Regularization: 0.030325, Discriminator: 0.043088; Generator: 0.021751,\n",
      "D(x): 0.504, D(G(z)): 0.499\n",
      "2019-04-09 23:32:26,909 root         INFO     Train Epoch: 27 [6656/8000 (83%)]\tTotal Loss: 19.145039\n",
      "Reconstruction: 19.004017, Regularization: 0.076404, Discriminator: 0.042680; Generator: 0.021938,\n",
      "D(x): 0.507, D(G(z)): 0.496\n",
      "2019-04-09 23:32:27,021 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 17.103559\n",
      "Reconstruction: 16.986740, Regularization: 0.052843, Discriminator: 0.042218; Generator: 0.021758,\n",
      "D(x): 0.518, D(G(z)): 0.499\n",
      "2019-04-09 23:32:27,133 root         INFO     Train Epoch: 27 [7680/8000 (96%)]\tTotal Loss: 0.377311\n",
      "Reconstruction: 0.247474, Regularization: 0.065427, Discriminator: 0.042615; Generator: 0.021796,\n",
      "D(x): 0.510, D(G(z)): 0.498\n",
      "2019-04-09 23:32:27,215 root         INFO     ====> Epoch: 27 Average loss: 2539275.7248\n",
      "2019-04-09 23:32:27,242 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.232125\n",
      "Reconstruction: 0.145109, Regularization: 0.022459, Discriminator: 0.042887; Generator: 0.021671,\n",
      "D(x): 0.508, D(G(z)): 0.500\n",
      "2019-04-09 23:32:27,354 root         INFO     Train Epoch: 28 [512/8000 (6%)]\tTotal Loss: 22.460516\n",
      "Reconstruction: 22.318632, Regularization: 0.077387, Discriminator: 0.042861; Generator: 0.021635,\n",
      "D(x): 0.509, D(G(z)): 0.501\n",
      "2019-04-09 23:32:27,466 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.344820\n",
      "Reconstruction: 0.248391, Regularization: 0.031493, Discriminator: 0.043208; Generator: 0.021727,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:32:27,578 root         INFO     Train Epoch: 28 [1536/8000 (19%)]\tTotal Loss: 0.818924\n",
      "Reconstruction: 0.718916, Regularization: 0.035231, Discriminator: 0.042696; Generator: 0.022081,\n",
      "D(x): 0.505, D(G(z)): 0.494\n",
      "2019-04-09 23:32:27,689 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 177.058029\n",
      "Reconstruction: 176.856888, Regularization: 0.136752, Discriminator: 0.042915; Generator: 0.021482,\n",
      "D(x): 0.511, D(G(z)): 0.503\n",
      "2019-04-09 23:32:27,800 root         INFO     Train Epoch: 28 [2560/8000 (32%)]\tTotal Loss: 1.209483\n",
      "Reconstruction: 1.074037, Regularization: 0.070323, Discriminator: 0.043202; Generator: 0.021920,\n",
      "D(x): 0.500, D(G(z)): 0.496\n",
      "2019-04-09 23:32:27,912 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.326582\n",
      "Reconstruction: 0.210359, Regularization: 0.051348, Discriminator: 0.043078; Generator: 0.021797,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 23:32:28,023 root         INFO     Train Epoch: 28 [3584/8000 (45%)]\tTotal Loss: 0.237661\n",
      "Reconstruction: 0.144747, Regularization: 0.028514, Discriminator: 0.042765; Generator: 0.021635,\n",
      "D(x): 0.511, D(G(z)): 0.501\n",
      "2019-04-09 23:32:28,135 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.371789\n",
      "Reconstruction: 0.274427, Regularization: 0.033005, Discriminator: 0.042611; Generator: 0.021746,\n",
      "D(x): 0.512, D(G(z)): 0.499\n",
      "2019-04-09 23:32:28,247 root         INFO     Train Epoch: 28 [4608/8000 (58%)]\tTotal Loss: 0.360610\n",
      "Reconstruction: 0.220478, Regularization: 0.075118, Discriminator: 0.043186; Generator: 0.021828,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 23:32:28,356 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.422728\n",
      "Reconstruction: 0.288482, Regularization: 0.070085, Discriminator: 0.042788; Generator: 0.021372,\n",
      "D(x): 0.515, D(G(z)): 0.505\n",
      "2019-04-09 23:32:28,464 root         INFO     Train Epoch: 28 [5632/8000 (70%)]\tTotal Loss: 47.577282\n",
      "Reconstruction: 47.385075, Regularization: 0.127589, Discriminator: 0.043199; Generator: 0.021418,\n",
      "D(x): 0.508, D(G(z)): 0.504\n",
      "2019-04-09 23:32:28,573 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.459673\n",
      "Reconstruction: 0.329658, Regularization: 0.065775, Discriminator: 0.042798; Generator: 0.021442,\n",
      "D(x): 0.514, D(G(z)): 0.504\n",
      "2019-04-09 23:32:28,681 root         INFO     Train Epoch: 28 [6656/8000 (83%)]\tTotal Loss: 0.260172\n",
      "Reconstruction: 0.166001, Regularization: 0.029716, Discriminator: 0.042642; Generator: 0.021813,\n",
      "D(x): 0.510, D(G(z)): 0.498\n",
      "2019-04-09 23:32:28,789 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.279740\n",
      "Reconstruction: 0.181346, Regularization: 0.033447, Discriminator: 0.043407; Generator: 0.021540,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 23:32:28,897 root         INFO     Train Epoch: 28 [7680/8000 (96%)]\tTotal Loss: 0.269140\n",
      "Reconstruction: 0.170258, Regularization: 0.034496, Discriminator: 0.042959; Generator: 0.021427,\n",
      "D(x): 0.512, D(G(z)): 0.504\n",
      "2019-04-09 23:32:28,976 root         INFO     ====> Epoch: 28 Average loss: 74486.6504\n",
      "2019-04-09 23:32:29,003 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 1.095302\n",
      "Reconstruction: 0.986092, Regularization: 0.044274, Discriminator: 0.042867; Generator: 0.022070,\n",
      "D(x): 0.503, D(G(z)): 0.494\n",
      "2019-04-09 23:32:29,114 root         INFO     Train Epoch: 29 [512/8000 (6%)]\tTotal Loss: 0.273525\n",
      "Reconstruction: 0.167761, Regularization: 0.040851, Discriminator: 0.042932; Generator: 0.021981,\n",
      "D(x): 0.503, D(G(z)): 0.495\n",
      "2019-04-09 23:32:29,223 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 1.001911\n",
      "Reconstruction: 0.858261, Regularization: 0.078975, Discriminator: 0.043006; Generator: 0.021669,\n",
      "D(x): 0.507, D(G(z)): 0.500\n",
      "2019-04-09 23:32:29,332 root         INFO     Train Epoch: 29 [1536/8000 (19%)]\tTotal Loss: 0.351442\n",
      "Reconstruction: 0.215572, Regularization: 0.071019, Discriminator: 0.043113; Generator: 0.021738,\n",
      "D(x): 0.504, D(G(z)): 0.499\n",
      "2019-04-09 23:32:29,441 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 161.838959\n",
      "Reconstruction: 161.653275, Regularization: 0.120844, Discriminator: 0.042794; Generator: 0.022041,\n",
      "D(x): 0.505, D(G(z)): 0.494\n",
      "2019-04-09 23:32:29,551 root         INFO     Train Epoch: 29 [2560/8000 (32%)]\tTotal Loss: 0.362859\n",
      "Reconstruction: 0.258003, Regularization: 0.040748, Discriminator: 0.042355; Generator: 0.021752,\n",
      "D(x): 0.516, D(G(z)): 0.499\n",
      "2019-04-09 23:32:29,660 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 1.343261\n",
      "Reconstruction: 1.227540, Regularization: 0.051177, Discriminator: 0.042699; Generator: 0.021844,\n",
      "D(x): 0.509, D(G(z)): 0.497\n",
      "2019-04-09 23:32:29,768 root         INFO     Train Epoch: 29 [3584/8000 (45%)]\tTotal Loss: 3.726409\n",
      "Reconstruction: 3.557648, Regularization: 0.103927, Discriminator: 0.042781; Generator: 0.022053,\n",
      "D(x): 0.504, D(G(z)): 0.494\n",
      "2019-04-09 23:32:29,877 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.331502\n",
      "Reconstruction: 0.222966, Regularization: 0.044321, Discriminator: 0.042323; Generator: 0.021892,\n",
      "D(x): 0.515, D(G(z)): 0.497\n",
      "2019-04-09 23:32:29,986 root         INFO     Train Epoch: 29 [4608/8000 (58%)]\tTotal Loss: 2.272111\n",
      "Reconstruction: 1.995093, Regularization: 0.212612, Discriminator: 0.042739; Generator: 0.021667,\n",
      "D(x): 0.511, D(G(z)): 0.500\n",
      "2019-04-09 23:32:30,095 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 0.433353\n",
      "Reconstruction: 0.322169, Regularization: 0.046057, Discriminator: 0.043105; Generator: 0.022022,\n",
      "D(x): 0.499, D(G(z)): 0.495\n",
      "2019-04-09 23:32:30,203 root         INFO     Train Epoch: 29 [5632/8000 (70%)]\tTotal Loss: 0.234663\n",
      "Reconstruction: 0.127905, Regularization: 0.041503, Discriminator: 0.043808; Generator: 0.021447,\n",
      "D(x): 0.497, D(G(z)): 0.504\n",
      "2019-04-09 23:32:30,312 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 15.792526\n",
      "Reconstruction: 15.673497, Regularization: 0.054110, Discriminator: 0.043081; Generator: 0.021838,\n",
      "D(x): 0.503, D(G(z)): 0.497\n",
      "2019-04-09 23:32:30,423 root         INFO     Train Epoch: 29 [6656/8000 (83%)]\tTotal Loss: 0.611537\n",
      "Reconstruction: 0.463008, Regularization: 0.083639, Discriminator: 0.043034; Generator: 0.021855,\n",
      "D(x): 0.503, D(G(z)): 0.497\n",
      "2019-04-09 23:32:30,534 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.489401\n",
      "Reconstruction: 0.370513, Regularization: 0.053998, Discriminator: 0.043123; Generator: 0.021767,\n",
      "D(x): 0.504, D(G(z)): 0.499\n",
      "2019-04-09 23:32:30,644 root         INFO     Train Epoch: 29 [7680/8000 (96%)]\tTotal Loss: 0.339736\n",
      "Reconstruction: 0.190431, Regularization: 0.084850, Discriminator: 0.042635; Generator: 0.021820,\n",
      "D(x): 0.510, D(G(z)): 0.498\n",
      "2019-04-09 23:32:30,724 root         INFO     ====> Epoch: 29 Average loss: 979924.7379\n",
      "2019-04-09 23:32:30,752 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.269764\n",
      "Reconstruction: 0.131134, Regularization: 0.073311, Discriminator: 0.043231; Generator: 0.022088,\n",
      "D(x): 0.497, D(G(z)): 0.494\n",
      "2019-04-09 23:32:30,865 root         INFO     Train Epoch: 30 [512/8000 (6%)]\tTotal Loss: 0.288010\n",
      "Reconstruction: 0.183997, Regularization: 0.038796, Discriminator: 0.043199; Generator: 0.022019,\n",
      "D(x): 0.498, D(G(z)): 0.494\n",
      "2019-04-09 23:32:30,978 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.237442\n",
      "Reconstruction: 0.151365, Regularization: 0.021363, Discriminator: 0.043210; Generator: 0.021504,\n",
      "D(x): 0.506, D(G(z)): 0.503\n",
      "2019-04-09 23:32:31,090 root         INFO     Train Epoch: 30 [1536/8000 (19%)]\tTotal Loss: 0.595391\n",
      "Reconstruction: 0.502910, Regularization: 0.027074, Discriminator: 0.043493; Generator: 0.021913,\n",
      "D(x): 0.495, D(G(z)): 0.496\n",
      "2019-04-09 23:32:31,202 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.252585\n",
      "Reconstruction: 0.122150, Regularization: 0.065502, Discriminator: 0.043257; Generator: 0.021676,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:32:31,314 root         INFO     Train Epoch: 30 [2560/8000 (32%)]\tTotal Loss: 210253.593750\n",
      "Reconstruction: 210253.156250, Regularization: 0.381392, Discriminator: 0.043430; Generator: 0.021745,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:32:31,427 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.221347\n",
      "Reconstruction: 0.115999, Regularization: 0.040518, Discriminator: 0.043251; Generator: 0.021580,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 23:32:31,539 root         INFO     Train Epoch: 30 [3584/8000 (45%)]\tTotal Loss: 0.802340\n",
      "Reconstruction: 0.662342, Regularization: 0.074598, Discriminator: 0.043614; Generator: 0.021785,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 23:32:31,652 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.810392\n",
      "Reconstruction: 0.679954, Regularization: 0.064631, Discriminator: 0.043910; Generator: 0.021897,\n",
      "D(x): 0.489, D(G(z)): 0.496\n",
      "2019-04-09 23:32:31,764 root         INFO     Train Epoch: 30 [4608/8000 (58%)]\tTotal Loss: 0.246778\n",
      "Reconstruction: 0.121476, Regularization: 0.060735, Discriminator: 0.042645; Generator: 0.021921,\n",
      "D(x): 0.508, D(G(z)): 0.496\n",
      "2019-04-09 23:32:31,876 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.335696\n",
      "Reconstruction: 0.225694, Regularization: 0.044662, Discriminator: 0.043918; Generator: 0.021423,\n",
      "D(x): 0.496, D(G(z)): 0.504\n",
      "2019-04-09 23:32:31,989 root         INFO     Train Epoch: 30 [5632/8000 (70%)]\tTotal Loss: 0.239072\n",
      "Reconstruction: 0.115804, Regularization: 0.058521, Discriminator: 0.042748; Generator: 0.021999,\n",
      "D(x): 0.505, D(G(z)): 0.495\n",
      "2019-04-09 23:32:32,102 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.242511\n",
      "Reconstruction: 0.128143, Regularization: 0.048962, Discriminator: 0.043665; Generator: 0.021740,\n",
      "D(x): 0.495, D(G(z)): 0.499\n",
      "2019-04-09 23:32:32,215 root         INFO     Train Epoch: 30 [6656/8000 (83%)]\tTotal Loss: 0.231556\n",
      "Reconstruction: 0.138272, Regularization: 0.028457, Discriminator: 0.043115; Generator: 0.021712,\n",
      "D(x): 0.504, D(G(z)): 0.499\n",
      "2019-04-09 23:32:32,328 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 8.943832\n",
      "Reconstruction: 8.727568, Regularization: 0.150898, Discriminator: 0.043581; Generator: 0.021786,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 23:32:32,441 root         INFO     Train Epoch: 30 [7680/8000 (96%)]\tTotal Loss: 0.351827\n",
      "Reconstruction: 0.225517, Regularization: 0.060846, Discriminator: 0.043653; Generator: 0.021812,\n",
      "D(x): 0.494, D(G(z)): 0.498\n",
      "2019-04-09 23:32:32,522 root         INFO     ====> Epoch: 30 Average loss: 865.3605\n",
      "2019-04-09 23:32:32,550 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.405813\n",
      "Reconstruction: 0.290339, Regularization: 0.049693, Discriminator: 0.044095; Generator: 0.021685,\n",
      "D(x): 0.489, D(G(z)): 0.500\n",
      "2019-04-09 23:32:32,661 root         INFO     Train Epoch: 31 [512/8000 (6%)]\tTotal Loss: 0.306967\n",
      "Reconstruction: 0.173840, Regularization: 0.068507, Discriminator: 0.042847; Generator: 0.021773,\n",
      "D(x): 0.507, D(G(z)): 0.498\n",
      "2019-04-09 23:32:32,772 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.238727\n",
      "Reconstruction: 0.138979, Regularization: 0.034291, Discriminator: 0.043935; Generator: 0.021522,\n",
      "D(x): 0.494, D(G(z)): 0.502\n",
      "2019-04-09 23:32:32,882 root         INFO     Train Epoch: 31 [1536/8000 (19%)]\tTotal Loss: 0.736268\n",
      "Reconstruction: 0.473880, Regularization: 0.197365, Discriminator: 0.043369; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:32,993 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 0.255589\n",
      "Reconstruction: 0.135865, Regularization: 0.054455, Discriminator: 0.043659; Generator: 0.021610,\n",
      "D(x): 0.496, D(G(z)): 0.501\n",
      "2019-04-09 23:32:33,103 root         INFO     Train Epoch: 31 [2560/8000 (32%)]\tTotal Loss: 0.254582\n",
      "Reconstruction: 0.157325, Regularization: 0.032297, Discriminator: 0.043145; Generator: 0.021814,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 23:32:33,211 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.241138\n",
      "Reconstruction: 0.119507, Regularization: 0.056195, Discriminator: 0.043668; Generator: 0.021768,\n",
      "D(x): 0.494, D(G(z)): 0.498\n",
      "2019-04-09 23:32:33,322 root         INFO     Train Epoch: 31 [3584/8000 (45%)]\tTotal Loss: 0.229491\n",
      "Reconstruction: 0.122150, Regularization: 0.042289, Discriminator: 0.043387; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:33,431 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.305637\n",
      "Reconstruction: 0.220094, Regularization: 0.020033, Discriminator: 0.043930; Generator: 0.021580,\n",
      "D(x): 0.492, D(G(z)): 0.501\n",
      "2019-04-09 23:32:33,540 root         INFO     Train Epoch: 31 [4608/8000 (58%)]\tTotal Loss: 0.223563\n",
      "Reconstruction: 0.120952, Regularization: 0.038192, Discriminator: 0.042809; Generator: 0.021610,\n",
      "D(x): 0.510, D(G(z)): 0.501\n",
      "2019-04-09 23:32:33,650 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.291538\n",
      "Reconstruction: 0.165437, Regularization: 0.060691, Discriminator: 0.043957; Generator: 0.021453,\n",
      "D(x): 0.494, D(G(z)): 0.503\n",
      "2019-04-09 23:32:33,760 root         INFO     Train Epoch: 31 [5632/8000 (70%)]\tTotal Loss: 0.252374\n",
      "Reconstruction: 0.134006, Regularization: 0.052797, Discriminator: 0.043909; Generator: 0.021661,\n",
      "D(x): 0.492, D(G(z)): 0.500\n",
      "2019-04-09 23:32:33,868 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 0.346575\n",
      "Reconstruction: 0.237467, Regularization: 0.043728, Discriminator: 0.043748; Generator: 0.021632,\n",
      "D(x): 0.494, D(G(z)): 0.501\n",
      "2019-04-09 23:32:33,977 root         INFO     Train Epoch: 31 [6656/8000 (83%)]\tTotal Loss: 0.394953\n",
      "Reconstruction: 0.133746, Regularization: 0.195757, Discriminator: 0.043730; Generator: 0.021721,\n",
      "D(x): 0.493, D(G(z)): 0.499\n",
      "2019-04-09 23:32:34,084 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 1.208682\n",
      "Reconstruction: 0.960758, Regularization: 0.182522, Discriminator: 0.043678; Generator: 0.021724,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 23:32:34,193 root         INFO     Train Epoch: 31 [7680/8000 (96%)]\tTotal Loss: 0.247068\n",
      "Reconstruction: 0.150543, Regularization: 0.031260, Discriminator: 0.043594; Generator: 0.021671,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 23:32:34,273 root         INFO     ====> Epoch: 31 Average loss: 347.6327\n",
      "2019-04-09 23:32:34,301 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.381917\n",
      "Reconstruction: 0.233460, Regularization: 0.082841, Discriminator: 0.044043; Generator: 0.021573,\n",
      "D(x): 0.491, D(G(z)): 0.501\n",
      "2019-04-09 23:32:34,413 root         INFO     Train Epoch: 32 [512/8000 (6%)]\tTotal Loss: 0.220038\n",
      "Reconstruction: 0.129936, Regularization: 0.024820, Discriminator: 0.043661; Generator: 0.021621,\n",
      "D(x): 0.496, D(G(z)): 0.501\n",
      "2019-04-09 23:32:34,525 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.236576\n",
      "Reconstruction: 0.126271, Regularization: 0.044866, Discriminator: 0.043737; Generator: 0.021701,\n",
      "D(x): 0.493, D(G(z)): 0.499\n",
      "2019-04-09 23:32:34,636 root         INFO     Train Epoch: 32 [1536/8000 (19%)]\tTotal Loss: 0.387351\n",
      "Reconstruction: 0.280039, Regularization: 0.042125, Discriminator: 0.043495; Generator: 0.021692,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:32:34,748 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.259366\n",
      "Reconstruction: 0.139278, Regularization: 0.054930, Discriminator: 0.043546; Generator: 0.021612,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 23:32:34,861 root         INFO     Train Epoch: 32 [2560/8000 (32%)]\tTotal Loss: 0.575236\n",
      "Reconstruction: 0.262453, Regularization: 0.247485, Discriminator: 0.043649; Generator: 0.021649,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 23:32:34,973 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.389342\n",
      "Reconstruction: 0.223854, Regularization: 0.100212, Discriminator: 0.043599; Generator: 0.021677,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 23:32:35,085 root         INFO     Train Epoch: 32 [3584/8000 (45%)]\tTotal Loss: 0.381378\n",
      "Reconstruction: 0.262647, Regularization: 0.053532, Discriminator: 0.043591; Generator: 0.021608,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 23:32:35,197 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.858658\n",
      "Reconstruction: 0.724651, Regularization: 0.068600, Discriminator: 0.043628; Generator: 0.021779,\n",
      "D(x): 0.494, D(G(z)): 0.498\n",
      "2019-04-09 23:32:35,309 root         INFO     Train Epoch: 32 [4608/8000 (58%)]\tTotal Loss: 0.302281\n",
      "Reconstruction: 0.184494, Regularization: 0.052253, Discriminator: 0.043879; Generator: 0.021655,\n",
      "D(x): 0.492, D(G(z)): 0.500\n",
      "2019-04-09 23:32:35,420 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 0.280559\n",
      "Reconstruction: 0.176869, Regularization: 0.037856, Discriminator: 0.044167; Generator: 0.021667,\n",
      "D(x): 0.487, D(G(z)): 0.500\n",
      "2019-04-09 23:32:35,533 root         INFO     Train Epoch: 32 [5632/8000 (70%)]\tTotal Loss: 0.344326\n",
      "Reconstruction: 0.227270, Regularization: 0.051832, Discriminator: 0.043563; Generator: 0.021662,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:32:35,645 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.293131\n",
      "Reconstruction: 0.161622, Regularization: 0.066706, Discriminator: 0.043148; Generator: 0.021655,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:32:35,756 root         INFO     Train Epoch: 32 [6656/8000 (83%)]\tTotal Loss: 0.219722\n",
      "Reconstruction: 0.121916, Regularization: 0.032677, Discriminator: 0.043505; Generator: 0.021624,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 23:32:35,867 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.274721\n",
      "Reconstruction: 0.149190, Regularization: 0.060318, Discriminator: 0.043405; Generator: 0.021809,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 23:32:35,978 root         INFO     Train Epoch: 32 [7680/8000 (96%)]\tTotal Loss: 0.385681\n",
      "Reconstruction: 0.222303, Regularization: 0.098321, Discriminator: 0.043345; Generator: 0.021712,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:32:36,060 root         INFO     ====> Epoch: 32 Average loss: 8.3345\n",
      "2019-04-09 23:32:36,087 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.913768\n",
      "Reconstruction: 0.601196, Regularization: 0.247204, Discriminator: 0.043719; Generator: 0.021648,\n",
      "D(x): 0.494, D(G(z)): 0.500\n",
      "2019-04-09 23:32:36,199 root         INFO     Train Epoch: 33 [512/8000 (6%)]\tTotal Loss: 0.398936\n",
      "Reconstruction: 0.257446, Regularization: 0.075948, Discriminator: 0.043882; Generator: 0.021661,\n",
      "D(x): 0.491, D(G(z)): 0.500\n",
      "2019-04-09 23:32:36,311 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.215798\n",
      "Reconstruction: 0.120561, Regularization: 0.030035, Discriminator: 0.043582; Generator: 0.021621,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 23:32:36,422 root         INFO     Train Epoch: 33 [1536/8000 (19%)]\tTotal Loss: 0.276844\n",
      "Reconstruction: 0.163248, Regularization: 0.048079, Discriminator: 0.043804; Generator: 0.021714,\n",
      "D(x): 0.492, D(G(z)): 0.499\n",
      "2019-04-09 23:32:36,533 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.384602\n",
      "Reconstruction: 0.252996, Regularization: 0.066258, Discriminator: 0.043645; Generator: 0.021702,\n",
      "D(x): 0.495, D(G(z)): 0.499\n",
      "2019-04-09 23:32:36,644 root         INFO     Train Epoch: 33 [2560/8000 (32%)]\tTotal Loss: 0.421223\n",
      "Reconstruction: 0.310513, Regularization: 0.045711, Discriminator: 0.043289; Generator: 0.021710,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:32:36,754 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.253364\n",
      "Reconstruction: 0.140813, Regularization: 0.047329, Discriminator: 0.043523; Generator: 0.021699,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:32:36,863 root         INFO     Train Epoch: 33 [3584/8000 (45%)]\tTotal Loss: 0.265822\n",
      "Reconstruction: 0.168036, Regularization: 0.032794, Discriminator: 0.043367; Generator: 0.021626,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:32:36,973 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 0.217227\n",
      "Reconstruction: 0.125796, Regularization: 0.025906, Discriminator: 0.043811; Generator: 0.021714,\n",
      "D(x): 0.492, D(G(z)): 0.499\n",
      "2019-04-09 23:32:37,084 root         INFO     Train Epoch: 33 [4608/8000 (58%)]\tTotal Loss: 0.555597\n",
      "Reconstruction: 0.419888, Regularization: 0.070337, Discriminator: 0.043696; Generator: 0.021676,\n",
      "D(x): 0.494, D(G(z)): 0.500\n",
      "2019-04-09 23:32:37,194 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.257393\n",
      "Reconstruction: 0.159199, Regularization: 0.032979, Discriminator: 0.043567; Generator: 0.021647,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 23:32:37,305 root         INFO     Train Epoch: 33 [5632/8000 (70%)]\tTotal Loss: 0.247583\n",
      "Reconstruction: 0.143640, Regularization: 0.038820, Discriminator: 0.043469; Generator: 0.021653,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:32:37,415 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 0.555636\n",
      "Reconstruction: 0.425978, Regularization: 0.064527, Discriminator: 0.043430; Generator: 0.021701,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:32:37,526 root         INFO     Train Epoch: 33 [6656/8000 (83%)]\tTotal Loss: 0.301784\n",
      "Reconstruction: 0.146954, Regularization: 0.089567, Discriminator: 0.043569; Generator: 0.021694,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 23:32:37,637 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.311627\n",
      "Reconstruction: 0.170821, Regularization: 0.075376, Discriminator: 0.043794; Generator: 0.021636,\n",
      "D(x): 0.493, D(G(z)): 0.500\n",
      "2019-04-09 23:32:37,748 root         INFO     Train Epoch: 33 [7680/8000 (96%)]\tTotal Loss: 0.203821\n",
      "Reconstruction: 0.113293, Regularization: 0.025226, Discriminator: 0.043627; Generator: 0.021674,\n",
      "D(x): 0.495, D(G(z)): 0.500\n",
      "2019-04-09 23:32:37,829 root         INFO     ====> Epoch: 33 Average loss: 1.1616\n",
      "2019-04-09 23:32:37,856 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.245274\n",
      "Reconstruction: 0.129992, Regularization: 0.049805, Discriminator: 0.043801; Generator: 0.021676,\n",
      "D(x): 0.492, D(G(z)): 0.500\n",
      "2019-04-09 23:32:37,966 root         INFO     Train Epoch: 34 [512/8000 (6%)]\tTotal Loss: 0.269229\n",
      "Reconstruction: 0.138547, Regularization: 0.065565, Discriminator: 0.043448; Generator: 0.021668,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:32:38,075 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.303095\n",
      "Reconstruction: 0.162131, Regularization: 0.075705, Discriminator: 0.043539; Generator: 0.021720,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 23:32:38,183 root         INFO     Train Epoch: 34 [1536/8000 (19%)]\tTotal Loss: 0.515565\n",
      "Reconstruction: 0.370686, Regularization: 0.079972, Discriminator: 0.043167; Generator: 0.021739,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:32:38,292 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.230847\n",
      "Reconstruction: 0.124278, Regularization: 0.041225, Discriminator: 0.043609; Generator: 0.021734,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 23:32:38,402 root         INFO     Train Epoch: 34 [2560/8000 (32%)]\tTotal Loss: 0.267402\n",
      "Reconstruction: 0.159110, Regularization: 0.043020, Discriminator: 0.043562; Generator: 0.021710,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 23:32:38,512 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.277986\n",
      "Reconstruction: 0.161369, Regularization: 0.051462, Discriminator: 0.043527; Generator: 0.021628,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 23:32:38,622 root         INFO     Train Epoch: 34 [3584/8000 (45%)]\tTotal Loss: 0.254186\n",
      "Reconstruction: 0.143025, Regularization: 0.045904, Discriminator: 0.043564; Generator: 0.021693,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 23:32:38,732 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.213140\n",
      "Reconstruction: 0.113482, Regularization: 0.034622, Discriminator: 0.043393; Generator: 0.021644,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:38,842 root         INFO     Train Epoch: 34 [4608/8000 (58%)]\tTotal Loss: 0.241874\n",
      "Reconstruction: 0.121745, Regularization: 0.054875, Discriminator: 0.043544; Generator: 0.021711,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 23:32:38,951 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.377279\n",
      "Reconstruction: 0.218910, Regularization: 0.093050, Discriminator: 0.043703; Generator: 0.021615,\n",
      "D(x): 0.495, D(G(z)): 0.501\n",
      "2019-04-09 23:32:39,061 root         INFO     Train Epoch: 34 [5632/8000 (70%)]\tTotal Loss: 0.228008\n",
      "Reconstruction: 0.136159, Regularization: 0.026700, Discriminator: 0.043506; Generator: 0.021644,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:32:39,170 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.293850\n",
      "Reconstruction: 0.162054, Regularization: 0.066612, Discriminator: 0.043485; Generator: 0.021699,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:32:39,279 root         INFO     Train Epoch: 34 [6656/8000 (83%)]\tTotal Loss: 0.364619\n",
      "Reconstruction: 0.235020, Regularization: 0.064448, Discriminator: 0.043460; Generator: 0.021689,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:32:39,388 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 2.798362\n",
      "Reconstruction: 2.517793, Regularization: 0.215526, Discriminator: 0.043343; Generator: 0.021700,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:32:39,498 root         INFO     Train Epoch: 34 [7680/8000 (96%)]\tTotal Loss: 0.333825\n",
      "Reconstruction: 0.152323, Regularization: 0.116440, Discriminator: 0.043388; Generator: 0.021674,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:39,578 root         INFO     ====> Epoch: 34 Average loss: 0.7342\n",
      "2019-04-09 23:32:39,605 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.310525\n",
      "Reconstruction: 0.146610, Regularization: 0.098733, Discriminator: 0.043517; Generator: 0.021665,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:32:39,717 root         INFO     Train Epoch: 35 [512/8000 (6%)]\tTotal Loss: 0.374189\n",
      "Reconstruction: 0.210155, Regularization: 0.098938, Discriminator: 0.043424; Generator: 0.021671,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:32:39,827 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.229700\n",
      "Reconstruction: 0.131680, Regularization: 0.032964, Discriminator: 0.043385; Generator: 0.021672,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:39,937 root         INFO     Train Epoch: 35 [1536/8000 (19%)]\tTotal Loss: 0.348075\n",
      "Reconstruction: 0.186797, Regularization: 0.096108, Discriminator: 0.043505; Generator: 0.021665,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:32:40,047 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.248365\n",
      "Reconstruction: 0.144923, Regularization: 0.038250, Discriminator: 0.043519; Generator: 0.021673,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:32:40,158 root         INFO     Train Epoch: 35 [2560/8000 (32%)]\tTotal Loss: 0.435822\n",
      "Reconstruction: 0.316567, Regularization: 0.054227, Discriminator: 0.043354; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:40,268 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.513740\n",
      "Reconstruction: 0.373915, Regularization: 0.074830, Discriminator: 0.043316; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:40,378 root         INFO     Train Epoch: 35 [3584/8000 (45%)]\tTotal Loss: 60.769833\n",
      "Reconstruction: 60.496864, Regularization: 0.207741, Discriminator: 0.043556; Generator: 0.021671,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 23:32:40,488 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.214141\n",
      "Reconstruction: 0.115820, Regularization: 0.033237, Discriminator: 0.043411; Generator: 0.021673,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:32:40,598 root         INFO     Train Epoch: 35 [4608/8000 (58%)]\tTotal Loss: 0.314757\n",
      "Reconstruction: 0.190696, Regularization: 0.058938, Discriminator: 0.043420; Generator: 0.021703,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:32:40,709 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.227170\n",
      "Reconstruction: 0.125622, Regularization: 0.036399, Discriminator: 0.043473; Generator: 0.021675,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:32:40,821 root         INFO     Train Epoch: 35 [5632/8000 (70%)]\tTotal Loss: 2.798389\n",
      "Reconstruction: 2.506234, Regularization: 0.227167, Discriminator: 0.043314; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:40,932 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.206023\n",
      "Reconstruction: 0.113343, Regularization: 0.027671, Discriminator: 0.043341; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:41,043 root         INFO     Train Epoch: 35 [6656/8000 (83%)]\tTotal Loss: 0.212588\n",
      "Reconstruction: 0.108125, Regularization: 0.039431, Discriminator: 0.043379; Generator: 0.021652,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:41,154 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.247605\n",
      "Reconstruction: 0.141585, Regularization: 0.040973, Discriminator: 0.043420; Generator: 0.021628,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:32:41,265 root         INFO     Train Epoch: 35 [7680/8000 (96%)]\tTotal Loss: 0.224385\n",
      "Reconstruction: 0.120521, Regularization: 0.038730, Discriminator: 0.043461; Generator: 0.021672,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:32:41,346 root         INFO     ====> Epoch: 35 Average loss: 0.6627\n",
      "2019-04-09 23:32:41,373 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 1.458103\n",
      "Reconstruction: 1.286438, Regularization: 0.106635, Discriminator: 0.043373; Generator: 0.021657,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:41,485 root         INFO     Train Epoch: 36 [512/8000 (6%)]\tTotal Loss: 0.224916\n",
      "Reconstruction: 0.134255, Regularization: 0.025680, Discriminator: 0.043331; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:41,596 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.260769\n",
      "Reconstruction: 0.132017, Regularization: 0.063738, Discriminator: 0.043363; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:41,708 root         INFO     Train Epoch: 36 [1536/8000 (19%)]\tTotal Loss: 0.421787\n",
      "Reconstruction: 0.257114, Regularization: 0.099616, Discriminator: 0.043384; Generator: 0.021673,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:41,818 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.299928\n",
      "Reconstruction: 0.185070, Regularization: 0.049781, Discriminator: 0.043417; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:41,928 root         INFO     Train Epoch: 36 [2560/8000 (32%)]\tTotal Loss: 0.509161\n",
      "Reconstruction: 0.232371, Regularization: 0.211631, Discriminator: 0.043469; Generator: 0.021689,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:32:42,039 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.328934\n",
      "Reconstruction: 0.196800, Regularization: 0.067103, Discriminator: 0.043335; Generator: 0.021696,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:32:42,148 root         INFO     Train Epoch: 36 [3584/8000 (45%)]\tTotal Loss: 0.383919\n",
      "Reconstruction: 0.239454, Regularization: 0.079461, Discriminator: 0.043335; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:42,259 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.285340\n",
      "Reconstruction: 0.163679, Regularization: 0.056690, Discriminator: 0.043270; Generator: 0.021702,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:32:42,370 root         INFO     Train Epoch: 36 [4608/8000 (58%)]\tTotal Loss: 0.302754\n",
      "Reconstruction: 0.166821, Regularization: 0.070923, Discriminator: 0.043292; Generator: 0.021719,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:32:42,480 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.532647\n",
      "Reconstruction: 0.377949, Regularization: 0.089595, Discriminator: 0.043427; Generator: 0.021676,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:32:42,590 root         INFO     Train Epoch: 36 [5632/8000 (70%)]\tTotal Loss: 0.316105\n",
      "Reconstruction: 0.213801, Regularization: 0.037251, Discriminator: 0.043365; Generator: 0.021688,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:42,701 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 0.321997\n",
      "Reconstruction: 0.200279, Regularization: 0.056635, Discriminator: 0.043349; Generator: 0.021734,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:32:42,812 root         INFO     Train Epoch: 36 [6656/8000 (83%)]\tTotal Loss: 0.268505\n",
      "Reconstruction: 0.169224, Regularization: 0.034264, Discriminator: 0.043377; Generator: 0.021640,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:42,922 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.318176\n",
      "Reconstruction: 0.209826, Regularization: 0.043303, Discriminator: 0.043440; Generator: 0.021606,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:32:43,033 root         INFO     Train Epoch: 36 [7680/8000 (96%)]\tTotal Loss: 0.250312\n",
      "Reconstruction: 0.144979, Regularization: 0.040292, Discriminator: 0.043331; Generator: 0.021710,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:32:43,115 root         INFO     ====> Epoch: 36 Average loss: 0.3885\n",
      "2019-04-09 23:32:43,141 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.697288\n",
      "Reconstruction: 0.526828, Regularization: 0.105437, Discriminator: 0.043314; Generator: 0.021710,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:32:43,253 root         INFO     Train Epoch: 37 [512/8000 (6%)]\tTotal Loss: 0.296770\n",
      "Reconstruction: 0.176059, Regularization: 0.055729, Discriminator: 0.043328; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:43,365 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.313568\n",
      "Reconstruction: 0.173461, Regularization: 0.075072, Discriminator: 0.043349; Generator: 0.021686,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:43,476 root         INFO     Train Epoch: 37 [1536/8000 (19%)]\tTotal Loss: 0.236632\n",
      "Reconstruction: 0.128907, Regularization: 0.042744, Discriminator: 0.043276; Generator: 0.021705,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:32:43,588 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.259073\n",
      "Reconstruction: 0.131808, Regularization: 0.062317, Discriminator: 0.043257; Generator: 0.021691,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:43,700 root         INFO     Train Epoch: 37 [2560/8000 (32%)]\tTotal Loss: 0.624016\n",
      "Reconstruction: 0.407587, Regularization: 0.151400, Discriminator: 0.043378; Generator: 0.021651,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:43,810 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 0.324139\n",
      "Reconstruction: 0.223285, Regularization: 0.035883, Discriminator: 0.043249; Generator: 0.021721,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:32:43,920 root         INFO     Train Epoch: 37 [3584/8000 (45%)]\tTotal Loss: 0.282891\n",
      "Reconstruction: 0.172759, Regularization: 0.045154, Discriminator: 0.043300; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:44,031 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.251641\n",
      "Reconstruction: 0.148670, Regularization: 0.037982, Discriminator: 0.043302; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:44,142 root         INFO     Train Epoch: 37 [4608/8000 (58%)]\tTotal Loss: 0.558856\n",
      "Reconstruction: 0.410804, Regularization: 0.083109, Discriminator: 0.043310; Generator: 0.021633,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:44,252 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.258231\n",
      "Reconstruction: 0.155737, Regularization: 0.037516, Discriminator: 0.043289; Generator: 0.021689,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:44,363 root         INFO     Train Epoch: 37 [5632/8000 (70%)]\tTotal Loss: 0.234060\n",
      "Reconstruction: 0.136995, Regularization: 0.032101, Discriminator: 0.043303; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:44,474 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.345016\n",
      "Reconstruction: 0.214534, Regularization: 0.065534, Discriminator: 0.043276; Generator: 0.021672,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:44,584 root         INFO     Train Epoch: 37 [6656/8000 (83%)]\tTotal Loss: 0.339538\n",
      "Reconstruction: 0.196917, Regularization: 0.077662, Discriminator: 0.043270; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:44,695 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.236767\n",
      "Reconstruction: 0.140571, Regularization: 0.031244, Discriminator: 0.043286; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:44,805 root         INFO     Train Epoch: 37 [7680/8000 (96%)]\tTotal Loss: 0.396455\n",
      "Reconstruction: 0.239363, Regularization: 0.092161, Discriminator: 0.043245; Generator: 0.021686,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:44,887 root         INFO     ====> Epoch: 37 Average loss: 0.4736\n",
      "2019-04-09 23:32:44,914 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.264611\n",
      "Reconstruction: 0.129539, Regularization: 0.070094, Discriminator: 0.043295; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:45,026 root         INFO     Train Epoch: 38 [512/8000 (6%)]\tTotal Loss: 0.261064\n",
      "Reconstruction: 0.160598, Regularization: 0.035614, Discriminator: 0.043159; Generator: 0.021693,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 23:32:45,138 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.356951\n",
      "Reconstruction: 0.239169, Regularization: 0.052847, Discriminator: 0.043270; Generator: 0.021665,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:45,250 root         INFO     Train Epoch: 38 [1536/8000 (19%)]\tTotal Loss: 0.255525\n",
      "Reconstruction: 0.115342, Regularization: 0.075267, Discriminator: 0.043245; Generator: 0.021670,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:45,361 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.261922\n",
      "Reconstruction: 0.145241, Regularization: 0.051797, Discriminator: 0.043226; Generator: 0.021657,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:32:45,473 root         INFO     Train Epoch: 38 [2560/8000 (32%)]\tTotal Loss: 0.365736\n",
      "Reconstruction: 0.216239, Regularization: 0.084649, Discriminator: 0.043199; Generator: 0.021649,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:32:45,583 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 0.231291\n",
      "Reconstruction: 0.135081, Regularization: 0.031279, Discriminator: 0.043271; Generator: 0.021660,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:45,694 root         INFO     Train Epoch: 38 [3584/8000 (45%)]\tTotal Loss: 0.619640\n",
      "Reconstruction: 0.203362, Regularization: 0.351357, Discriminator: 0.043246; Generator: 0.021675,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:45,804 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.225274\n",
      "Reconstruction: 0.125449, Regularization: 0.034956, Discriminator: 0.043206; Generator: 0.021664,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:32:45,915 root         INFO     Train Epoch: 38 [4608/8000 (58%)]\tTotal Loss: 0.757035\n",
      "Reconstruction: 0.601189, Regularization: 0.090995, Discriminator: 0.043184; Generator: 0.021667,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:32:46,025 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.369605\n",
      "Reconstruction: 0.239114, Regularization: 0.065522, Discriminator: 0.043305; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:46,136 root         INFO     Train Epoch: 38 [5632/8000 (70%)]\tTotal Loss: 0.349381\n",
      "Reconstruction: 0.225046, Regularization: 0.059470, Discriminator: 0.043207; Generator: 0.021659,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:32:46,246 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.455215\n",
      "Reconstruction: 0.124992, Regularization: 0.265284, Discriminator: 0.043271; Generator: 0.021668,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:46,356 root         INFO     Train Epoch: 38 [6656/8000 (83%)]\tTotal Loss: 1.456610\n",
      "Reconstruction: 1.275293, Regularization: 0.116262, Discriminator: 0.043367; Generator: 0.021688,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:46,467 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.743854\n",
      "Reconstruction: 0.298566, Regularization: 0.380341, Discriminator: 0.043274; Generator: 0.021674,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:46,576 root         INFO     Train Epoch: 38 [7680/8000 (96%)]\tTotal Loss: 0.252105\n",
      "Reconstruction: 0.140549, Regularization: 0.046711, Discriminator: 0.043174; Generator: 0.021671,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:32:46,657 root         INFO     ====> Epoch: 38 Average loss: 0.6500\n",
      "2019-04-09 23:32:46,684 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 0.240661\n",
      "Reconstruction: 0.136259, Regularization: 0.039643, Discriminator: 0.043088; Generator: 0.021670,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 23:32:46,797 root         INFO     Train Epoch: 39 [512/8000 (6%)]\tTotal Loss: 0.232049\n",
      "Reconstruction: 0.129577, Regularization: 0.037688, Discriminator: 0.043116; Generator: 0.021667,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:32:46,910 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.345555\n",
      "Reconstruction: 0.213658, Regularization: 0.066930, Discriminator: 0.043304; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:47,022 root         INFO     Train Epoch: 39 [1536/8000 (19%)]\tTotal Loss: 0.278340\n",
      "Reconstruction: 0.161354, Regularization: 0.052101, Discriminator: 0.043212; Generator: 0.021674,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:32:47,134 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.306134\n",
      "Reconstruction: 0.178298, Regularization: 0.062995, Discriminator: 0.043168; Generator: 0.021674,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:32:47,246 root         INFO     Train Epoch: 39 [2560/8000 (32%)]\tTotal Loss: 0.522065\n",
      "Reconstruction: 0.397163, Regularization: 0.060062, Discriminator: 0.043178; Generator: 0.021662,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:32:47,358 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.238092\n",
      "Reconstruction: 0.130843, Regularization: 0.042418, Discriminator: 0.043170; Generator: 0.021663,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:32:47,470 root         INFO     Train Epoch: 39 [3584/8000 (45%)]\tTotal Loss: 0.239587\n",
      "Reconstruction: 0.133264, Regularization: 0.041389, Discriminator: 0.043262; Generator: 0.021672,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:47,582 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.262142\n",
      "Reconstruction: 0.135727, Regularization: 0.061461, Discriminator: 0.043286; Generator: 0.021668,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:47,694 root         INFO     Train Epoch: 39 [4608/8000 (58%)]\tTotal Loss: 0.322856\n",
      "Reconstruction: 0.179718, Regularization: 0.078342, Discriminator: 0.043113; Generator: 0.021683,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:32:47,806 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.249800\n",
      "Reconstruction: 0.128134, Regularization: 0.056710, Discriminator: 0.043278; Generator: 0.021677,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:47,917 root         INFO     Train Epoch: 39 [5632/8000 (70%)]\tTotal Loss: 0.262202\n",
      "Reconstruction: 0.154230, Regularization: 0.043225, Discriminator: 0.043066; Generator: 0.021680,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 23:32:48,029 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.304302\n",
      "Reconstruction: 0.192541, Regularization: 0.046931, Discriminator: 0.043156; Generator: 0.021674,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:32:48,141 root         INFO     Train Epoch: 39 [6656/8000 (83%)]\tTotal Loss: 0.422577\n",
      "Reconstruction: 0.309214, Regularization: 0.048280, Discriminator: 0.043410; Generator: 0.021672,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:48,251 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.241880\n",
      "Reconstruction: 0.136896, Regularization: 0.040041, Discriminator: 0.043257; Generator: 0.021686,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:48,361 root         INFO     Train Epoch: 39 [7680/8000 (96%)]\tTotal Loss: 0.240880\n",
      "Reconstruction: 0.136994, Regularization: 0.039054, Discriminator: 0.043139; Generator: 0.021693,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 23:32:48,441 root         INFO     ====> Epoch: 39 Average loss: 5.5941\n",
      "2019-04-09 23:32:48,468 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.277712\n",
      "Reconstruction: 0.131154, Regularization: 0.081850, Discriminator: 0.043016; Generator: 0.021691,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 23:32:48,580 root         INFO     Train Epoch: 40 [512/8000 (6%)]\tTotal Loss: 0.240968\n",
      "Reconstruction: 0.129713, Regularization: 0.046529, Discriminator: 0.043041; Generator: 0.021685,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 23:32:48,691 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.299080\n",
      "Reconstruction: 0.160639, Regularization: 0.073575, Discriminator: 0.043173; Generator: 0.021693,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 23:32:48,802 root         INFO     Train Epoch: 40 [1536/8000 (19%)]\tTotal Loss: 0.857311\n",
      "Reconstruction: 0.588832, Regularization: 0.203771, Discriminator: 0.043053; Generator: 0.021656,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 23:32:48,912 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.305354\n",
      "Reconstruction: 0.144709, Regularization: 0.095918, Discriminator: 0.043065; Generator: 0.021662,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 23:32:49,023 root         INFO     Train Epoch: 40 [2560/8000 (32%)]\tTotal Loss: 0.410510\n",
      "Reconstruction: 0.249570, Regularization: 0.095908, Discriminator: 0.043349; Generator: 0.021682,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:49,134 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.263325\n",
      "Reconstruction: 0.147559, Regularization: 0.050774, Discriminator: 0.043300; Generator: 0.021692,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:49,245 root         INFO     Train Epoch: 40 [3584/8000 (45%)]\tTotal Loss: 0.253521\n",
      "Reconstruction: 0.141908, Regularization: 0.046646, Discriminator: 0.043261; Generator: 0.021707,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:32:49,356 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.305878\n",
      "Reconstruction: 0.148502, Regularization: 0.092710, Discriminator: 0.043017; Generator: 0.021648,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 23:32:49,466 root         INFO     Train Epoch: 40 [4608/8000 (58%)]\tTotal Loss: 0.237350\n",
      "Reconstruction: 0.147787, Regularization: 0.024685, Discriminator: 0.043218; Generator: 0.021660,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:32:49,577 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 0.614900\n",
      "Reconstruction: 0.467407, Regularization: 0.082550, Discriminator: 0.043304; Generator: 0.021639,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:49,688 root         INFO     Train Epoch: 40 [5632/8000 (70%)]\tTotal Loss: 0.246962\n",
      "Reconstruction: 0.144027, Regularization: 0.038166, Discriminator: 0.043101; Generator: 0.021669,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 23:32:49,797 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.401052\n",
      "Reconstruction: 0.278685, Regularization: 0.057488, Discriminator: 0.043289; Generator: 0.021590,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 23:32:49,906 root         INFO     Train Epoch: 40 [6656/8000 (83%)]\tTotal Loss: 0.269386\n",
      "Reconstruction: 0.135460, Regularization: 0.068835, Discriminator: 0.043346; Generator: 0.021745,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:32:50,015 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.358789\n",
      "Reconstruction: 0.217753, Regularization: 0.076175, Discriminator: 0.043150; Generator: 0.021711,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 23:32:50,124 root         INFO     Train Epoch: 40 [7680/8000 (96%)]\tTotal Loss: 0.285496\n",
      "Reconstruction: 0.169252, Regularization: 0.051481, Discriminator: 0.042997; Generator: 0.021767,\n",
      "D(x): 0.504, D(G(z)): 0.498\n",
      "2019-04-09 23:32:50,204 root         INFO     ====> Epoch: 40 Average loss: 2.8182\n",
      "2019-04-09 23:32:50,231 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 0.253013\n",
      "Reconstruction: 0.132634, Regularization: 0.055390, Discriminator: 0.043240; Generator: 0.021749,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:32:50,344 root         INFO     Train Epoch: 41 [512/8000 (6%)]\tTotal Loss: 0.350285\n",
      "Reconstruction: 0.238804, Regularization: 0.046414, Discriminator: 0.043376; Generator: 0.021691,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:50,457 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.238724\n",
      "Reconstruction: 0.133227, Regularization: 0.040549, Discriminator: 0.043257; Generator: 0.021691,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:50,570 root         INFO     Train Epoch: 41 [1536/8000 (19%)]\tTotal Loss: 0.552906\n",
      "Reconstruction: 0.443948, Regularization: 0.044003, Discriminator: 0.043278; Generator: 0.021676,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:50,683 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 1.914862\n",
      "Reconstruction: 1.774838, Regularization: 0.075210, Discriminator: 0.043101; Generator: 0.021714,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 23:32:50,797 root         INFO     Train Epoch: 41 [2560/8000 (32%)]\tTotal Loss: 0.301587\n",
      "Reconstruction: 0.168953, Regularization: 0.067820, Discriminator: 0.043155; Generator: 0.021659,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:32:50,910 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.267138\n",
      "Reconstruction: 0.146053, Regularization: 0.055874, Discriminator: 0.043507; Generator: 0.021704,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:32:51,023 root         INFO     Train Epoch: 41 [3584/8000 (45%)]\tTotal Loss: 0.384495\n",
      "Reconstruction: 0.259639, Regularization: 0.059810, Discriminator: 0.043363; Generator: 0.021683,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:51,135 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.357953\n",
      "Reconstruction: 0.241503, Regularization: 0.051670, Discriminator: 0.043144; Generator: 0.021636,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 23:32:51,246 root         INFO     Train Epoch: 41 [4608/8000 (58%)]\tTotal Loss: 0.393758\n",
      "Reconstruction: 0.290625, Regularization: 0.037921, Discriminator: 0.043488; Generator: 0.021725,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:32:51,359 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 0.455448\n",
      "Reconstruction: 0.318705, Regularization: 0.072087, Discriminator: 0.042932; Generator: 0.021724,\n",
      "D(x): 0.505, D(G(z)): 0.499\n",
      "2019-04-09 23:32:51,471 root         INFO     Train Epoch: 41 [5632/8000 (70%)]\tTotal Loss: 0.262488\n",
      "Reconstruction: 0.145575, Regularization: 0.052086, Discriminator: 0.043148; Generator: 0.021679,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:32:51,584 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.308092\n",
      "Reconstruction: 0.206632, Regularization: 0.036339, Discriminator: 0.043468; Generator: 0.021653,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:32:51,696 root         INFO     Train Epoch: 41 [6656/8000 (83%)]\tTotal Loss: 0.206680\n",
      "Reconstruction: 0.112848, Regularization: 0.029044, Discriminator: 0.043113; Generator: 0.021676,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:32:51,808 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.292685\n",
      "Reconstruction: 0.167692, Regularization: 0.059900, Discriminator: 0.043420; Generator: 0.021673,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:51,921 root         INFO     Train Epoch: 41 [7680/8000 (96%)]\tTotal Loss: 0.701181\n",
      "Reconstruction: 0.580900, Regularization: 0.055267, Discriminator: 0.043255; Generator: 0.021758,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 23:32:52,003 root         INFO     ====> Epoch: 41 Average loss: 10.6123\n",
      "2019-04-09 23:32:52,029 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.229597\n",
      "Reconstruction: 0.109433, Regularization: 0.055161, Discriminator: 0.043356; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:52,141 root         INFO     Train Epoch: 42 [512/8000 (6%)]\tTotal Loss: 0.204285\n",
      "Reconstruction: 0.105786, Regularization: 0.033774, Discriminator: 0.043150; Generator: 0.021575,\n",
      "D(x): 0.504, D(G(z)): 0.501\n",
      "2019-04-09 23:32:52,252 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.246758\n",
      "Reconstruction: 0.132493, Regularization: 0.049220, Discriminator: 0.043285; Generator: 0.021761,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 23:32:52,363 root         INFO     Train Epoch: 42 [1536/8000 (19%)]\tTotal Loss: 2.224485\n",
      "Reconstruction: 2.127006, Regularization: 0.032808, Discriminator: 0.043046; Generator: 0.021625,\n",
      "D(x): 0.505, D(G(z)): 0.501\n",
      "2019-04-09 23:32:52,473 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 2.840015\n",
      "Reconstruction: 2.692928, Regularization: 0.082028, Discriminator: 0.043381; Generator: 0.021678,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:52,584 root         INFO     Train Epoch: 42 [2560/8000 (32%)]\tTotal Loss: 0.243888\n",
      "Reconstruction: 0.124254, Regularization: 0.054411, Discriminator: 0.043477; Generator: 0.021746,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 23:32:52,695 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 35.034367\n",
      "Reconstruction: 34.881470, Regularization: 0.088089, Discriminator: 0.043156; Generator: 0.021653,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:32:52,806 root         INFO     Train Epoch: 42 [3584/8000 (45%)]\tTotal Loss: 1.119833\n",
      "Reconstruction: 1.009348, Regularization: 0.045470, Discriminator: 0.043293; Generator: 0.021722,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:32:52,915 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.245725\n",
      "Reconstruction: 0.136590, Regularization: 0.044181, Discriminator: 0.043495; Generator: 0.021459,\n",
      "D(x): 0.501, D(G(z)): 0.503\n",
      "2019-04-09 23:32:53,025 root         INFO     Train Epoch: 42 [4608/8000 (58%)]\tTotal Loss: 0.232276\n",
      "Reconstruction: 0.132727, Regularization: 0.034355, Discriminator: 0.043652; Generator: 0.021542,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 23:32:53,135 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.273938\n",
      "Reconstruction: 0.101957, Regularization: 0.107148, Discriminator: 0.043305; Generator: 0.021528,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-09 23:32:53,245 root         INFO     Train Epoch: 42 [5632/8000 (70%)]\tTotal Loss: 0.261689\n",
      "Reconstruction: 0.139968, Regularization: 0.056533, Discriminator: 0.043489; Generator: 0.021699,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:32:53,356 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.229959\n",
      "Reconstruction: 0.124433, Regularization: 0.040790, Discriminator: 0.043288; Generator: 0.021447,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-09 23:32:53,466 root         INFO     Train Epoch: 42 [6656/8000 (83%)]\tTotal Loss: 0.328687\n",
      "Reconstruction: 0.157761, Regularization: 0.105709, Discriminator: 0.043463; Generator: 0.021754,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:32:53,576 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.325261\n",
      "Reconstruction: 0.215890, Regularization: 0.044259, Discriminator: 0.043624; Generator: 0.021487,\n",
      "D(x): 0.498, D(G(z)): 0.503\n",
      "2019-04-09 23:32:53,689 root         INFO     Train Epoch: 42 [7680/8000 (96%)]\tTotal Loss: 0.321242\n",
      "Reconstruction: 0.169275, Regularization: 0.087443, Discriminator: 0.042777; Generator: 0.021748,\n",
      "D(x): 0.508, D(G(z)): 0.499\n",
      "2019-04-09 23:32:53,769 root         INFO     ====> Epoch: 42 Average loss: 190.1797\n",
      "2019-04-09 23:32:53,796 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.225933\n",
      "Reconstruction: 0.130438, Regularization: 0.030486, Discriminator: 0.043269; Generator: 0.021740,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:32:53,908 root         INFO     Train Epoch: 43 [512/8000 (6%)]\tTotal Loss: 0.541793\n",
      "Reconstruction: 0.194241, Regularization: 0.282749, Discriminator: 0.043287; Generator: 0.021515,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-09 23:32:54,019 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.337325\n",
      "Reconstruction: 0.243335, Regularization: 0.028746, Discriminator: 0.043566; Generator: 0.021678,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 23:32:54,130 root         INFO     Train Epoch: 43 [1536/8000 (19%)]\tTotal Loss: 0.271292\n",
      "Reconstruction: 0.161732, Regularization: 0.044596, Discriminator: 0.043321; Generator: 0.021643,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:54,242 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.264043\n",
      "Reconstruction: 0.168605, Regularization: 0.030037, Discriminator: 0.043674; Generator: 0.021727,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 23:32:54,352 root         INFO     Train Epoch: 43 [2560/8000 (32%)]\tTotal Loss: 0.490597\n",
      "Reconstruction: 0.373056, Regularization: 0.052422, Discriminator: 0.043532; Generator: 0.021587,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 23:32:54,463 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 5.465613\n",
      "Reconstruction: 5.323667, Regularization: 0.076947, Discriminator: 0.043353; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:54,574 root         INFO     Train Epoch: 43 [3584/8000 (45%)]\tTotal Loss: 3.086999\n",
      "Reconstruction: 2.933003, Regularization: 0.088857, Discriminator: 0.043448; Generator: 0.021691,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:32:54,685 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.400996\n",
      "Reconstruction: 0.282560, Regularization: 0.052981, Discriminator: 0.043748; Generator: 0.021707,\n",
      "D(x): 0.493, D(G(z)): 0.499\n",
      "2019-04-09 23:32:54,796 root         INFO     Train Epoch: 43 [4608/8000 (58%)]\tTotal Loss: 0.332819\n",
      "Reconstruction: 0.221303, Regularization: 0.046244, Discriminator: 0.043627; Generator: 0.021646,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 23:32:54,907 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.357248\n",
      "Reconstruction: 0.235989, Regularization: 0.056029, Discriminator: 0.043566; Generator: 0.021664,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 23:32:55,018 root         INFO     Train Epoch: 43 [5632/8000 (70%)]\tTotal Loss: 0.301756\n",
      "Reconstruction: 0.189445, Regularization: 0.047185, Discriminator: 0.043462; Generator: 0.021663,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:32:55,129 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 110.985558\n",
      "Reconstruction: 110.735764, Regularization: 0.184823, Discriminator: 0.043361; Generator: 0.021611,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:32:55,240 root         INFO     Train Epoch: 43 [6656/8000 (83%)]\tTotal Loss: 0.437052\n",
      "Reconstruction: 0.308044, Regularization: 0.063987, Discriminator: 0.043292; Generator: 0.021729,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:32:55,351 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.270220\n",
      "Reconstruction: 0.180102, Regularization: 0.025137, Discriminator: 0.043352; Generator: 0.021629,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:32:55,462 root         INFO     Train Epoch: 43 [7680/8000 (96%)]\tTotal Loss: 7.445596\n",
      "Reconstruction: 7.326800, Regularization: 0.053780, Discriminator: 0.043289; Generator: 0.021726,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:32:55,542 root         INFO     ====> Epoch: 43 Average loss: 93.9470\n",
      "2019-04-09 23:32:55,569 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 10.802981\n",
      "Reconstruction: 10.571909, Regularization: 0.165972, Discriminator: 0.043427; Generator: 0.021674,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:32:55,680 root         INFO     Train Epoch: 44 [512/8000 (6%)]\tTotal Loss: 0.251745\n",
      "Reconstruction: 0.133976, Regularization: 0.052748, Discriminator: 0.043393; Generator: 0.021630,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:32:55,790 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 12.759962\n",
      "Reconstruction: 12.604157, Regularization: 0.090716, Discriminator: 0.043447; Generator: 0.021641,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:32:55,901 root         INFO     Train Epoch: 44 [1536/8000 (19%)]\tTotal Loss: 1.210120\n",
      "Reconstruction: 1.107781, Regularization: 0.037200, Discriminator: 0.043517; Generator: 0.021622,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 23:32:56,012 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.254893\n",
      "Reconstruction: 0.149894, Regularization: 0.039825, Discriminator: 0.043557; Generator: 0.021618,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 23:32:56,123 root         INFO     Train Epoch: 44 [2560/8000 (32%)]\tTotal Loss: 0.729792\n",
      "Reconstruction: 0.602932, Regularization: 0.061637, Discriminator: 0.043530; Generator: 0.021693,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 23:32:56,234 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.280726\n",
      "Reconstruction: 0.154545, Regularization: 0.061010, Discriminator: 0.043516; Generator: 0.021655,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:32:56,347 root         INFO     Train Epoch: 44 [3584/8000 (45%)]\tTotal Loss: 0.692501\n",
      "Reconstruction: 0.552399, Regularization: 0.075185, Discriminator: 0.043309; Generator: 0.021609,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:32:56,459 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.481825\n",
      "Reconstruction: 0.364647, Regularization: 0.052015, Discriminator: 0.043468; Generator: 0.021695,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:32:56,571 root         INFO     Train Epoch: 44 [4608/8000 (58%)]\tTotal Loss: 0.437607\n",
      "Reconstruction: 0.336973, Regularization: 0.035532, Discriminator: 0.043409; Generator: 0.021693,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:32:56,683 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.600000\n",
      "Reconstruction: 0.477190, Regularization: 0.057864, Discriminator: 0.043315; Generator: 0.021633,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:56,795 root         INFO     Train Epoch: 44 [5632/8000 (70%)]\tTotal Loss: 0.282299\n",
      "Reconstruction: 0.193118, Regularization: 0.024019, Discriminator: 0.043522; Generator: 0.021641,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:32:56,907 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.359035\n",
      "Reconstruction: 0.254072, Regularization: 0.039828, Discriminator: 0.043450; Generator: 0.021686,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:32:57,019 root         INFO     Train Epoch: 44 [6656/8000 (83%)]\tTotal Loss: 1235647.250000\n",
      "Reconstruction: 1235647.000000, Regularization: 0.106175, Discriminator: 0.043497; Generator: 0.021672,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:32:57,131 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.321589\n",
      "Reconstruction: 0.205747, Regularization: 0.050771, Discriminator: 0.043419; Generator: 0.021651,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:57,243 root         INFO     Train Epoch: 44 [7680/8000 (96%)]\tTotal Loss: 7.511188\n",
      "Reconstruction: 7.386425, Regularization: 0.059705, Discriminator: 0.043449; Generator: 0.021610,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:32:57,324 root         INFO     ====> Epoch: 44 Average loss: 9149837.2523\n",
      "2019-04-09 23:32:57,351 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 2.040146\n",
      "Reconstruction: 1.914070, Regularization: 0.061039, Discriminator: 0.043362; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:57,464 root         INFO     Train Epoch: 45 [512/8000 (6%)]\tTotal Loss: 0.314527\n",
      "Reconstruction: 0.220870, Regularization: 0.028657, Discriminator: 0.043374; Generator: 0.021626,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:32:57,576 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 482.974518\n",
      "Reconstruction: 482.833862, Regularization: 0.075663, Discriminator: 0.043385; Generator: 0.021629,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:32:57,684 root         INFO     Train Epoch: 45 [1536/8000 (19%)]\tTotal Loss: 0.403674\n",
      "Reconstruction: 0.284699, Regularization: 0.053959, Discriminator: 0.043358; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:57,792 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 26.401495\n",
      "Reconstruction: 26.137781, Regularization: 0.198697, Discriminator: 0.043332; Generator: 0.021683,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:57,900 root         INFO     Train Epoch: 45 [2560/8000 (32%)]\tTotal Loss: 0.458635\n",
      "Reconstruction: 0.351089, Regularization: 0.042486, Discriminator: 0.043400; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:58,011 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.420494\n",
      "Reconstruction: 0.319510, Regularization: 0.035893, Discriminator: 0.043466; Generator: 0.021625,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 23:32:58,120 root         INFO     Train Epoch: 45 [3584/8000 (45%)]\tTotal Loss: 0.441590\n",
      "Reconstruction: 0.314705, Regularization: 0.061859, Discriminator: 0.043369; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:58,229 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.400575\n",
      "Reconstruction: 0.280342, Regularization: 0.055172, Discriminator: 0.043385; Generator: 0.021676,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:58,338 root         INFO     Train Epoch: 45 [4608/8000 (58%)]\tTotal Loss: 0.477484\n",
      "Reconstruction: 0.360506, Regularization: 0.051950, Discriminator: 0.043372; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:58,449 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.299297\n",
      "Reconstruction: 0.194264, Regularization: 0.040039, Discriminator: 0.043355; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:58,560 root         INFO     Train Epoch: 45 [5632/8000 (70%)]\tTotal Loss: 0.795735\n",
      "Reconstruction: 0.699202, Regularization: 0.031552, Discriminator: 0.043333; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:58,672 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.808045\n",
      "Reconstruction: 0.710073, Regularization: 0.032982, Discriminator: 0.043364; Generator: 0.021626,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:32:58,783 root         INFO     Train Epoch: 45 [6656/8000 (83%)]\tTotal Loss: 5.073944\n",
      "Reconstruction: 4.935877, Regularization: 0.073053, Discriminator: 0.043336; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:58,895 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.510092\n",
      "Reconstruction: 0.381279, Regularization: 0.063815, Discriminator: 0.043317; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:59,006 root         INFO     Train Epoch: 45 [7680/8000 (96%)]\tTotal Loss: 0.311149\n",
      "Reconstruction: 0.202463, Regularization: 0.043678, Discriminator: 0.043330; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:59,087 root         INFO     ====> Epoch: 45 Average loss: 65378437.5742\n",
      "2019-04-09 23:32:59,114 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 3053667.250000\n",
      "Reconstruction: 3053667.000000, Regularization: 0.248711, Discriminator: 0.043304; Generator: 0.021646,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:32:59,227 root         INFO     Train Epoch: 46 [512/8000 (6%)]\tTotal Loss: 3.489605\n",
      "Reconstruction: 3.147057, Regularization: 0.277577, Discriminator: 0.043300; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:59,336 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.511926\n",
      "Reconstruction: 0.360978, Regularization: 0.085964, Discriminator: 0.043313; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:59,445 root         INFO     Train Epoch: 46 [1536/8000 (19%)]\tTotal Loss: 3.022061\n",
      "Reconstruction: 2.843553, Regularization: 0.113536, Discriminator: 0.043291; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:59,553 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.736920\n",
      "Reconstruction: 0.633203, Regularization: 0.038762, Discriminator: 0.043276; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:59,662 root         INFO     Train Epoch: 46 [2560/8000 (32%)]\tTotal Loss: 31737851904.000000\n",
      "Reconstruction: 31737851904.000000, Regularization: 0.272909, Discriminator: 0.043346; Generator: 0.021683,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:32:59,772 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.452334\n",
      "Reconstruction: 0.329414, Regularization: 0.058040, Discriminator: 0.043203; Generator: 0.021678,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:32:59,881 root         INFO     Train Epoch: 46 [3584/8000 (45%)]\tTotal Loss: 3528879.000000\n",
      "Reconstruction: 3528878.750000, Regularization: 0.328376, Discriminator: 0.043308; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:32:59,990 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.277738\n",
      "Reconstruction: 0.184967, Regularization: 0.027855, Discriminator: 0.043240; Generator: 0.021676,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:00,099 root         INFO     Train Epoch: 46 [4608/8000 (58%)]\tTotal Loss: 0.419343\n",
      "Reconstruction: 0.280543, Regularization: 0.073877, Discriminator: 0.043235; Generator: 0.021688,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:00,208 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.423577\n",
      "Reconstruction: 0.290998, Regularization: 0.067641, Discriminator: 0.043255; Generator: 0.021682,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:00,318 root         INFO     Train Epoch: 46 [5632/8000 (70%)]\tTotal Loss: 7.303980\n",
      "Reconstruction: 7.180570, Regularization: 0.058467, Discriminator: 0.043269; Generator: 0.021674,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:00,428 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.997557\n",
      "Reconstruction: 0.865551, Regularization: 0.067036, Discriminator: 0.043259; Generator: 0.021712,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:00,537 root         INFO     Train Epoch: 46 [6656/8000 (83%)]\tTotal Loss: 0.339435\n",
      "Reconstruction: 0.241431, Regularization: 0.033199, Discriminator: 0.043089; Generator: 0.021715,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 23:33:00,647 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 93.968620\n",
      "Reconstruction: 93.849197, Regularization: 0.054429, Discriminator: 0.043340; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:00,756 root         INFO     Train Epoch: 46 [7680/8000 (96%)]\tTotal Loss: 0.263723\n",
      "Reconstruction: 0.172269, Regularization: 0.026523, Discriminator: 0.043233; Generator: 0.021698,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:33:00,837 root         INFO     ====> Epoch: 46 Average loss: 127826120.7060\n",
      "2019-04-09 23:33:00,864 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.430309\n",
      "Reconstruction: 0.300631, Regularization: 0.064629, Discriminator: 0.043373; Generator: 0.021677,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:00,976 root         INFO     Train Epoch: 47 [512/8000 (6%)]\tTotal Loss: 1.070544\n",
      "Reconstruction: 0.909724, Regularization: 0.095951, Discriminator: 0.043163; Generator: 0.021705,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 23:33:01,087 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 1.002398\n",
      "Reconstruction: 0.885496, Regularization: 0.051966, Discriminator: 0.043239; Generator: 0.021697,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:33:01,198 root         INFO     Train Epoch: 47 [1536/8000 (19%)]\tTotal Loss: 1.595769\n",
      "Reconstruction: 1.466655, Regularization: 0.064115, Discriminator: 0.043304; Generator: 0.021695,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:01,309 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.913894\n",
      "Reconstruction: 0.785624, Regularization: 0.063329, Discriminator: 0.043187; Generator: 0.021755,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:33:01,420 root         INFO     Train Epoch: 47 [2560/8000 (32%)]\tTotal Loss: 64.231552\n",
      "Reconstruction: 64.052994, Regularization: 0.113571, Discriminator: 0.043227; Generator: 0.021758,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 23:33:01,529 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 37.633690\n",
      "Reconstruction: 37.362804, Regularization: 0.205997, Discriminator: 0.043098; Generator: 0.021788,\n",
      "D(x): 0.502, D(G(z)): 0.498\n",
      "2019-04-09 23:33:01,640 root         INFO     Train Epoch: 47 [3584/8000 (45%)]\tTotal Loss: 1.477641\n",
      "Reconstruction: 1.375991, Regularization: 0.036753, Discriminator: 0.043111; Generator: 0.021786,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 23:33:01,750 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.269237\n",
      "Reconstruction: 0.141201, Regularization: 0.063121, Discriminator: 0.043147; Generator: 0.021769,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 23:33:01,860 root         INFO     Train Epoch: 47 [4608/8000 (58%)]\tTotal Loss: 428.842377\n",
      "Reconstruction: 428.447662, Regularization: 0.329772, Discriminator: 0.043209; Generator: 0.021747,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:33:01,970 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 1.952649\n",
      "Reconstruction: 1.766504, Regularization: 0.121181, Discriminator: 0.043291; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:02,080 root         INFO     Train Epoch: 47 [5632/8000 (70%)]\tTotal Loss: 6922.420898\n",
      "Reconstruction: 6921.997559, Regularization: 0.358588, Discriminator: 0.043252; Generator: 0.021750,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:02,191 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.325812\n",
      "Reconstruction: 0.217071, Regularization: 0.043808, Discriminator: 0.043267; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:02,301 root         INFO     Train Epoch: 47 [6656/8000 (83%)]\tTotal Loss: 2.564440\n",
      "Reconstruction: 2.437039, Regularization: 0.062691, Discriminator: 0.043062; Generator: 0.021648,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 23:33:02,413 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.949920\n",
      "Reconstruction: 0.830121, Regularization: 0.055172, Discriminator: 0.042926; Generator: 0.021701,\n",
      "D(x): 0.506, D(G(z)): 0.499\n",
      "2019-04-09 23:33:02,524 root         INFO     Train Epoch: 47 [7680/8000 (96%)]\tTotal Loss: 0.357081\n",
      "Reconstruction: 0.220387, Regularization: 0.071769, Discriminator: 0.043341; Generator: 0.021584,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:33:02,605 root         INFO     ====> Epoch: 47 Average loss: 3850684.1531\n",
      "2019-04-09 23:33:02,633 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.731475\n",
      "Reconstruction: 0.610524, Regularization: 0.055990, Discriminator: 0.043296; Generator: 0.021665,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:02,745 root         INFO     Train Epoch: 48 [512/8000 (6%)]\tTotal Loss: 7.031886\n",
      "Reconstruction: 6.784064, Regularization: 0.182757, Discriminator: 0.043349; Generator: 0.021715,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:33:02,857 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.395488\n",
      "Reconstruction: 0.253793, Regularization: 0.076827, Discriminator: 0.043183; Generator: 0.021685,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:33:02,968 root         INFO     Train Epoch: 48 [1536/8000 (19%)]\tTotal Loss: 0.468020\n",
      "Reconstruction: 0.313193, Regularization: 0.089769, Discriminator: 0.043306; Generator: 0.021752,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:33:03,080 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.577498\n",
      "Reconstruction: 0.462383, Regularization: 0.050405, Discriminator: 0.043028; Generator: 0.021682,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 23:33:03,189 root         INFO     Train Epoch: 48 [2560/8000 (32%)]\tTotal Loss: 0.359916\n",
      "Reconstruction: 0.249680, Regularization: 0.045061, Discriminator: 0.043538; Generator: 0.021637,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:33:03,298 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.752052\n",
      "Reconstruction: 0.644150, Regularization: 0.042937, Discriminator: 0.043267; Generator: 0.021699,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:03,408 root         INFO     Train Epoch: 48 [3584/8000 (45%)]\tTotal Loss: 1.009997\n",
      "Reconstruction: 0.898547, Regularization: 0.046518, Discriminator: 0.043247; Generator: 0.021685,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:03,520 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.256916\n",
      "Reconstruction: 0.162945, Regularization: 0.029152, Discriminator: 0.043092; Generator: 0.021727,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 23:33:03,632 root         INFO     Train Epoch: 48 [4608/8000 (58%)]\tTotal Loss: 0.263671\n",
      "Reconstruction: 0.155064, Regularization: 0.043526, Discriminator: 0.043398; Generator: 0.021683,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:03,741 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 28.845530\n",
      "Reconstruction: 28.691767, Regularization: 0.088748, Discriminator: 0.043361; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:03,850 root         INFO     Train Epoch: 48 [5632/8000 (70%)]\tTotal Loss: 0.220481\n",
      "Reconstruction: 0.112686, Regularization: 0.042802, Discriminator: 0.043282; Generator: 0.021711,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:03,959 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.518173\n",
      "Reconstruction: 0.257664, Regularization: 0.195371, Discriminator: 0.043441; Generator: 0.021697,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:33:04,070 root         INFO     Train Epoch: 48 [6656/8000 (83%)]\tTotal Loss: 0.497708\n",
      "Reconstruction: 0.239830, Regularization: 0.193005, Discriminator: 0.043161; Generator: 0.021712,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 23:33:04,181 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.536023\n",
      "Reconstruction: 0.400004, Regularization: 0.070878, Discriminator: 0.043496; Generator: 0.021645,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:33:04,292 root         INFO     Train Epoch: 48 [7680/8000 (96%)]\tTotal Loss: 0.276674\n",
      "Reconstruction: 0.157399, Regularization: 0.054293, Discriminator: 0.043299; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:04,373 root         INFO     ====> Epoch: 48 Average loss: 1127.2443\n",
      "2019-04-09 23:33:04,400 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.391936\n",
      "Reconstruction: 0.268988, Regularization: 0.057898, Discriminator: 0.043440; Generator: 0.021610,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:33:04,514 root         INFO     Train Epoch: 49 [512/8000 (6%)]\tTotal Loss: 0.395184\n",
      "Reconstruction: 0.235469, Regularization: 0.094535, Discriminator: 0.043470; Generator: 0.021710,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:33:04,626 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.286937\n",
      "Reconstruction: 0.176018, Regularization: 0.046138, Discriminator: 0.043117; Generator: 0.021665,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:33:04,738 root         INFO     Train Epoch: 49 [1536/8000 (19%)]\tTotal Loss: 0.239050\n",
      "Reconstruction: 0.137508, Regularization: 0.036480, Discriminator: 0.043353; Generator: 0.021709,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:33:04,851 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.257174\n",
      "Reconstruction: 0.139556, Regularization: 0.052758, Discriminator: 0.043207; Generator: 0.021652,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:33:04,962 root         INFO     Train Epoch: 49 [2560/8000 (32%)]\tTotal Loss: 0.647561\n",
      "Reconstruction: 0.387915, Regularization: 0.194570, Discriminator: 0.043451; Generator: 0.021625,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:33:05,074 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.224695\n",
      "Reconstruction: 0.118515, Regularization: 0.041082, Discriminator: 0.043440; Generator: 0.021657,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:33:05,186 root         INFO     Train Epoch: 49 [3584/8000 (45%)]\tTotal Loss: 0.283917\n",
      "Reconstruction: 0.151611, Regularization: 0.067345, Discriminator: 0.043328; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:05,297 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.360708\n",
      "Reconstruction: 0.166932, Regularization: 0.128875, Discriminator: 0.043229; Generator: 0.021672,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:05,408 root         INFO     Train Epoch: 49 [4608/8000 (58%)]\tTotal Loss: 0.302325\n",
      "Reconstruction: 0.170682, Regularization: 0.066568, Discriminator: 0.043353; Generator: 0.021721,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:33:05,519 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 3.314269\n",
      "Reconstruction: 3.173375, Regularization: 0.075985, Discriminator: 0.043298; Generator: 0.021611,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:33:05,629 root         INFO     Train Epoch: 49 [5632/8000 (70%)]\tTotal Loss: 0.224125\n",
      "Reconstruction: 0.120979, Regularization: 0.038201, Discriminator: 0.043333; Generator: 0.021613,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:33:05,738 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.273249\n",
      "Reconstruction: 0.116848, Regularization: 0.091346, Discriminator: 0.043396; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:05,847 root         INFO     Train Epoch: 49 [6656/8000 (83%)]\tTotal Loss: 0.247404\n",
      "Reconstruction: 0.141573, Regularization: 0.040978, Discriminator: 0.043215; Generator: 0.021639,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:33:05,956 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.546722\n",
      "Reconstruction: 0.362240, Regularization: 0.119525, Discriminator: 0.043343; Generator: 0.021613,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:33:06,064 root         INFO     Train Epoch: 49 [7680/8000 (96%)]\tTotal Loss: 0.877605\n",
      "Reconstruction: 0.766200, Regularization: 0.046447, Discriminator: 0.043307; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:06,144 root         INFO     ====> Epoch: 49 Average loss: 1460.2129\n",
      "2019-04-09 23:33:06,171 root         INFO     Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 0.345453\n",
      "Reconstruction: 0.181588, Regularization: 0.098728, Discriminator: 0.043493; Generator: 0.021645,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:33:06,284 root         INFO     Train Epoch: 50 [512/8000 (6%)]\tTotal Loss: 0.199545\n",
      "Reconstruction: 0.108018, Regularization: 0.026535, Discriminator: 0.043328; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:06,394 root         INFO     Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 0.497294\n",
      "Reconstruction: 0.388905, Regularization: 0.043325, Discriminator: 0.043406; Generator: 0.021658,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:06,505 root         INFO     Train Epoch: 50 [1536/8000 (19%)]\tTotal Loss: 0.531613\n",
      "Reconstruction: 0.254959, Regularization: 0.211576, Discriminator: 0.043420; Generator: 0.021658,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:06,616 root         INFO     Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 0.296506\n",
      "Reconstruction: 0.140800, Regularization: 0.090697, Discriminator: 0.043354; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:06,726 root         INFO     Train Epoch: 50 [2560/8000 (32%)]\tTotal Loss: 0.462964\n",
      "Reconstruction: 0.172434, Regularization: 0.225481, Discriminator: 0.043405; Generator: 0.021644,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:06,836 root         INFO     Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 0.302291\n",
      "Reconstruction: 0.173874, Regularization: 0.063465, Discriminator: 0.043294; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:06,947 root         INFO     Train Epoch: 50 [3584/8000 (45%)]\tTotal Loss: 0.252835\n",
      "Reconstruction: 0.128208, Regularization: 0.059419, Discriminator: 0.043530; Generator: 0.021679,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 23:33:07,057 root         INFO     Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 0.454508\n",
      "Reconstruction: 0.318942, Regularization: 0.070550, Discriminator: 0.043364; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:07,166 root         INFO     Train Epoch: 50 [4608/8000 (58%)]\tTotal Loss: 2.878556\n",
      "Reconstruction: 2.744852, Regularization: 0.068578, Discriminator: 0.043487; Generator: 0.021639,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:33:07,277 root         INFO     Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 47.375271\n",
      "Reconstruction: 47.133099, Regularization: 0.177085, Discriminator: 0.043434; Generator: 0.021651,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:33:07,388 root         INFO     Train Epoch: 50 [5632/8000 (70%)]\tTotal Loss: 0.241224\n",
      "Reconstruction: 0.123164, Regularization: 0.053090, Discriminator: 0.043340; Generator: 0.021630,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:07,498 root         INFO     Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 0.253575\n",
      "Reconstruction: 0.150039, Regularization: 0.038650, Discriminator: 0.043241; Generator: 0.021645,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:33:07,609 root         INFO     Train Epoch: 50 [6656/8000 (83%)]\tTotal Loss: 0.368260\n",
      "Reconstruction: 0.228978, Regularization: 0.074301, Discriminator: 0.043362; Generator: 0.021618,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:33:07,718 root         INFO     Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 0.227158\n",
      "Reconstruction: 0.131132, Regularization: 0.030934, Discriminator: 0.043441; Generator: 0.021650,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:33:07,827 root         INFO     Train Epoch: 50 [7680/8000 (96%)]\tTotal Loss: 1.028505\n",
      "Reconstruction: 0.919186, Regularization: 0.044303, Discriminator: 0.043348; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:07,908 root         INFO     ====> Epoch: 50 Average loss: 4.9071\n",
      "2019-04-09 23:33:07,935 root         INFO     Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 0.264668\n",
      "Reconstruction: 0.151046, Regularization: 0.048661, Discriminator: 0.043309; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:08,048 root         INFO     Train Epoch: 51 [512/8000 (6%)]\tTotal Loss: 0.324560\n",
      "Reconstruction: 0.154250, Regularization: 0.105271, Discriminator: 0.043368; Generator: 0.021671,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:08,160 root         INFO     Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 0.249440\n",
      "Reconstruction: 0.130768, Regularization: 0.053667, Discriminator: 0.043357; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:08,272 root         INFO     Train Epoch: 51 [1536/8000 (19%)]\tTotal Loss: 0.226590\n",
      "Reconstruction: 0.130024, Regularization: 0.031569, Discriminator: 0.043333; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:08,386 root         INFO     Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 0.272246\n",
      "Reconstruction: 0.137937, Regularization: 0.069273, Discriminator: 0.043397; Generator: 0.021638,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:08,497 root         INFO     Train Epoch: 51 [2560/8000 (32%)]\tTotal Loss: 0.342732\n",
      "Reconstruction: 0.241333, Regularization: 0.036419, Discriminator: 0.043333; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:08,610 root         INFO     Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 0.285551\n",
      "Reconstruction: 0.156135, Regularization: 0.064517, Discriminator: 0.043259; Generator: 0.021640,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:08,722 root         INFO     Train Epoch: 51 [3584/8000 (45%)]\tTotal Loss: 0.291826\n",
      "Reconstruction: 0.128207, Regularization: 0.098566, Discriminator: 0.043405; Generator: 0.021649,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:08,833 root         INFO     Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 0.255204\n",
      "Reconstruction: 0.160519, Regularization: 0.029661, Discriminator: 0.043363; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:08,945 root         INFO     Train Epoch: 51 [4608/8000 (58%)]\tTotal Loss: 0.286257\n",
      "Reconstruction: 0.152684, Regularization: 0.068589, Discriminator: 0.043342; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:09,056 root         INFO     Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 0.722976\n",
      "Reconstruction: 0.451327, Regularization: 0.206603, Discriminator: 0.043385; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:09,168 root         INFO     Train Epoch: 51 [5632/8000 (70%)]\tTotal Loss: 0.293654\n",
      "Reconstruction: 0.156725, Regularization: 0.071933, Discriminator: 0.043340; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:09,279 root         INFO     Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 0.321898\n",
      "Reconstruction: 0.163255, Regularization: 0.093534, Discriminator: 0.043474; Generator: 0.021636,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:33:09,390 root         INFO     Train Epoch: 51 [6656/8000 (83%)]\tTotal Loss: 0.333168\n",
      "Reconstruction: 0.153360, Regularization: 0.114815, Discriminator: 0.043360; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:09,502 root         INFO     Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 0.218454\n",
      "Reconstruction: 0.121155, Regularization: 0.032267, Discriminator: 0.043390; Generator: 0.021643,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:09,612 root         INFO     Train Epoch: 51 [7680/8000 (96%)]\tTotal Loss: 0.436132\n",
      "Reconstruction: 0.290327, Regularization: 0.080796, Discriminator: 0.043371; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:09,694 root         INFO     ====> Epoch: 51 Average loss: 13.8548\n",
      "2019-04-09 23:33:09,722 root         INFO     Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 0.400873\n",
      "Reconstruction: 0.242662, Regularization: 0.093092, Discriminator: 0.043476; Generator: 0.021642,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:33:09,833 root         INFO     Train Epoch: 52 [512/8000 (6%)]\tTotal Loss: 0.215014\n",
      "Reconstruction: 0.127509, Regularization: 0.022485, Discriminator: 0.043351; Generator: 0.021669,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:09,944 root         INFO     Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 0.276113\n",
      "Reconstruction: 0.145720, Regularization: 0.065382, Discriminator: 0.043341; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:10,056 root         INFO     Train Epoch: 52 [1536/8000 (19%)]\tTotal Loss: 0.225973\n",
      "Reconstruction: 0.125261, Regularization: 0.035709, Discriminator: 0.043342; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:10,167 root         INFO     Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 0.389432\n",
      "Reconstruction: 0.286094, Regularization: 0.038352, Discriminator: 0.043320; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:10,280 root         INFO     Train Epoch: 52 [2560/8000 (32%)]\tTotal Loss: 0.310311\n",
      "Reconstruction: 0.178596, Regularization: 0.066731, Discriminator: 0.043336; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:10,393 root         INFO     Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 15.576053\n",
      "Reconstruction: 15.297322, Regularization: 0.213736, Discriminator: 0.043329; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:10,507 root         INFO     Train Epoch: 52 [3584/8000 (45%)]\tTotal Loss: 0.285839\n",
      "Reconstruction: 0.154869, Regularization: 0.065977, Discriminator: 0.043336; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:10,620 root         INFO     Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 0.365064\n",
      "Reconstruction: 0.149905, Regularization: 0.150183, Discriminator: 0.043331; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:10,733 root         INFO     Train Epoch: 52 [4608/8000 (58%)]\tTotal Loss: 0.222329\n",
      "Reconstruction: 0.125904, Regularization: 0.031432, Discriminator: 0.043335; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:10,847 root         INFO     Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 0.240859\n",
      "Reconstruction: 0.139088, Regularization: 0.036780, Discriminator: 0.043327; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:10,960 root         INFO     Train Epoch: 52 [5632/8000 (70%)]\tTotal Loss: 0.208821\n",
      "Reconstruction: 0.100395, Regularization: 0.043446, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:11,073 root         INFO     Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 0.279431\n",
      "Reconstruction: 0.186418, Regularization: 0.028023, Discriminator: 0.043324; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:11,186 root         INFO     Train Epoch: 52 [6656/8000 (83%)]\tTotal Loss: 0.246226\n",
      "Reconstruction: 0.144955, Regularization: 0.036289, Discriminator: 0.043313; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:11,299 root         INFO     Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 12.275120\n",
      "Reconstruction: 12.071517, Regularization: 0.138635, Discriminator: 0.043310; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:11,413 root         INFO     Train Epoch: 52 [7680/8000 (96%)]\tTotal Loss: 5.874897\n",
      "Reconstruction: 5.751211, Regularization: 0.058699, Discriminator: 0.043322; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:11,494 root         INFO     ====> Epoch: 52 Average loss: 2.5189\n",
      "2019-04-09 23:33:11,521 root         INFO     Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 0.327624\n",
      "Reconstruction: 0.165973, Regularization: 0.096716, Discriminator: 0.043268; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:11,633 root         INFO     Train Epoch: 53 [512/8000 (6%)]\tTotal Loss: 0.249876\n",
      "Reconstruction: 0.128408, Regularization: 0.056518, Discriminator: 0.043266; Generator: 0.021684,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:11,745 root         INFO     Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 0.333360\n",
      "Reconstruction: 0.207643, Regularization: 0.060760, Discriminator: 0.043318; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:11,856 root         INFO     Train Epoch: 53 [1536/8000 (19%)]\tTotal Loss: 0.380035\n",
      "Reconstruction: 0.223071, Regularization: 0.092019, Discriminator: 0.043299; Generator: 0.021646,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:11,966 root         INFO     Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 0.647346\n",
      "Reconstruction: 0.493763, Regularization: 0.088587, Discriminator: 0.043362; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:12,077 root         INFO     Train Epoch: 53 [2560/8000 (32%)]\tTotal Loss: 0.232357\n",
      "Reconstruction: 0.121501, Regularization: 0.045868, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:12,188 root         INFO     Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 0.595005\n",
      "Reconstruction: 0.465241, Regularization: 0.064841, Discriminator: 0.043290; Generator: 0.021633,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:12,299 root         INFO     Train Epoch: 53 [3584/8000 (45%)]\tTotal Loss: 0.233516\n",
      "Reconstruction: 0.123750, Regularization: 0.044786, Discriminator: 0.043331; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:12,410 root         INFO     Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 0.262700\n",
      "Reconstruction: 0.136919, Regularization: 0.060850, Discriminator: 0.043269; Generator: 0.021663,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:12,521 root         INFO     Train Epoch: 53 [4608/8000 (58%)]\tTotal Loss: 0.283294\n",
      "Reconstruction: 0.137721, Regularization: 0.080632, Discriminator: 0.043283; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:12,633 root         INFO     Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 0.229450\n",
      "Reconstruction: 0.132350, Regularization: 0.032171, Discriminator: 0.043252; Generator: 0.021677,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:12,745 root         INFO     Train Epoch: 53 [5632/8000 (70%)]\tTotal Loss: 0.267396\n",
      "Reconstruction: 0.140287, Regularization: 0.062135, Discriminator: 0.043301; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:12,857 root         INFO     Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 0.307219\n",
      "Reconstruction: 0.199228, Regularization: 0.043031, Discriminator: 0.043278; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:12,970 root         INFO     Train Epoch: 53 [6656/8000 (83%)]\tTotal Loss: 0.190732\n",
      "Reconstruction: 0.096082, Regularization: 0.029605, Discriminator: 0.043363; Generator: 0.021682,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:13,087 root         INFO     Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 0.190863\n",
      "Reconstruction: 0.104241, Regularization: 0.021719, Discriminator: 0.043230; Generator: 0.021672,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:13,202 root         INFO     Train Epoch: 53 [7680/8000 (96%)]\tTotal Loss: 0.276111\n",
      "Reconstruction: 0.142080, Regularization: 0.069081, Discriminator: 0.043276; Generator: 0.021673,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:13,282 root         INFO     ====> Epoch: 53 Average loss: 2.2716\n",
      "2019-04-09 23:33:13,309 root         INFO     Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 0.269632\n",
      "Reconstruction: 0.164123, Regularization: 0.040582, Discriminator: 0.043212; Generator: 0.021715,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:33:13,421 root         INFO     Train Epoch: 54 [512/8000 (6%)]\tTotal Loss: 0.208447\n",
      "Reconstruction: 0.113581, Regularization: 0.029967, Discriminator: 0.043202; Generator: 0.021696,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:33:13,531 root         INFO     Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 0.344416\n",
      "Reconstruction: 0.219431, Regularization: 0.059997, Discriminator: 0.043320; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:13,641 root         INFO     Train Epoch: 54 [1536/8000 (19%)]\tTotal Loss: 0.270179\n",
      "Reconstruction: 0.145052, Regularization: 0.060101, Discriminator: 0.043293; Generator: 0.021733,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:33:13,753 root         INFO     Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 2.114005\n",
      "Reconstruction: 1.983635, Regularization: 0.065318, Discriminator: 0.043406; Generator: 0.021646,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:13,864 root         INFO     Train Epoch: 54 [2560/8000 (32%)]\tTotal Loss: 0.262812\n",
      "Reconstruction: 0.148061, Regularization: 0.049833, Discriminator: 0.043251; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:13,976 root         INFO     Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 0.207664\n",
      "Reconstruction: 0.102211, Regularization: 0.040432, Discriminator: 0.043348; Generator: 0.021674,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:14,087 root         INFO     Train Epoch: 54 [3584/8000 (45%)]\tTotal Loss: 0.513477\n",
      "Reconstruction: 0.281688, Regularization: 0.166820, Discriminator: 0.043278; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:14,199 root         INFO     Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 0.273888\n",
      "Reconstruction: 0.161484, Regularization: 0.047433, Discriminator: 0.043279; Generator: 0.021693,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:14,311 root         INFO     Train Epoch: 54 [4608/8000 (58%)]\tTotal Loss: 0.284714\n",
      "Reconstruction: 0.154540, Regularization: 0.065178, Discriminator: 0.043295; Generator: 0.021701,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:14,422 root         INFO     Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 0.339673\n",
      "Reconstruction: 0.200502, Regularization: 0.074199, Discriminator: 0.043260; Generator: 0.021712,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:14,534 root         INFO     Train Epoch: 54 [5632/8000 (70%)]\tTotal Loss: 0.514084\n",
      "Reconstruction: 0.352886, Regularization: 0.096342, Discriminator: 0.043178; Generator: 0.021677,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:33:14,645 root         INFO     Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 0.287510\n",
      "Reconstruction: 0.193162, Regularization: 0.029404, Discriminator: 0.043245; Generator: 0.021699,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:33:14,757 root         INFO     Train Epoch: 54 [6656/8000 (83%)]\tTotal Loss: 0.324555\n",
      "Reconstruction: 0.115886, Regularization: 0.143751, Discriminator: 0.043249; Generator: 0.021669,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:14,869 root         INFO     Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 0.705205\n",
      "Reconstruction: 0.541194, Regularization: 0.099143, Discriminator: 0.043147; Generator: 0.021721,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 23:33:14,980 root         INFO     Train Epoch: 54 [7680/8000 (96%)]\tTotal Loss: 0.265348\n",
      "Reconstruction: 0.149114, Regularization: 0.051089, Discriminator: 0.043409; Generator: 0.021736,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:33:15,062 root         INFO     ====> Epoch: 54 Average loss: 11.7967\n",
      "2019-04-09 23:33:15,089 root         INFO     Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 0.605625\n",
      "Reconstruction: 0.446357, Regularization: 0.094316, Discriminator: 0.043280; Generator: 0.021671,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:15,201 root         INFO     Train Epoch: 55 [512/8000 (6%)]\tTotal Loss: 0.260475\n",
      "Reconstruction: 0.140354, Regularization: 0.055029, Discriminator: 0.043460; Generator: 0.021631,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:33:15,312 root         INFO     Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 0.286147\n",
      "Reconstruction: 0.140383, Regularization: 0.080722, Discriminator: 0.043383; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:15,423 root         INFO     Train Epoch: 55 [1536/8000 (19%)]\tTotal Loss: 0.222005\n",
      "Reconstruction: 0.122937, Regularization: 0.033998, Discriminator: 0.043414; Generator: 0.021657,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:15,534 root         INFO     Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 0.235901\n",
      "Reconstruction: 0.115062, Regularization: 0.055824, Discriminator: 0.043311; Generator: 0.021705,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:15,645 root         INFO     Train Epoch: 55 [2560/8000 (32%)]\tTotal Loss: 0.302644\n",
      "Reconstruction: 0.185844, Regularization: 0.051777, Discriminator: 0.043374; Generator: 0.021649,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:15,756 root         INFO     Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 0.288498\n",
      "Reconstruction: 0.138453, Regularization: 0.084902, Discriminator: 0.043445; Generator: 0.021698,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:33:15,865 root         INFO     Train Epoch: 55 [3584/8000 (45%)]\tTotal Loss: 0.256160\n",
      "Reconstruction: 0.155184, Regularization: 0.036135, Discriminator: 0.043139; Generator: 0.021702,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 23:33:15,975 root         INFO     Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 0.857502\n",
      "Reconstruction: 0.327081, Regularization: 0.465485, Discriminator: 0.043257; Generator: 0.021680,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:16,083 root         INFO     Train Epoch: 55 [4608/8000 (58%)]\tTotal Loss: 0.320103\n",
      "Reconstruction: 0.207298, Regularization: 0.047819, Discriminator: 0.043309; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:16,191 root         INFO     Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 1.580385\n",
      "Reconstruction: 1.432713, Regularization: 0.082889, Discriminator: 0.043152; Generator: 0.021632,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:33:16,300 root         INFO     Train Epoch: 55 [5632/8000 (70%)]\tTotal Loss: 2.576351\n",
      "Reconstruction: 2.435120, Regularization: 0.076243, Discriminator: 0.043347; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:16,408 root         INFO     Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 22.366150\n",
      "Reconstruction: 22.244501, Regularization: 0.056461, Discriminator: 0.043514; Generator: 0.021675,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:33:16,516 root         INFO     Train Epoch: 55 [6656/8000 (83%)]\tTotal Loss: 0.465144\n",
      "Reconstruction: 0.231169, Regularization: 0.168812, Discriminator: 0.043506; Generator: 0.021657,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:33:16,624 root         INFO     Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 54.123016\n",
      "Reconstruction: 54.007969, Regularization: 0.050055, Discriminator: 0.043345; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:16,732 root         INFO     Train Epoch: 55 [7680/8000 (96%)]\tTotal Loss: 1.828025\n",
      "Reconstruction: 1.650910, Regularization: 0.112126, Discriminator: 0.043325; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:16,810 root         INFO     ====> Epoch: 55 Average loss: 15.2341\n",
      "2019-04-09 23:33:16,838 root         INFO     Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 0.309183\n",
      "Reconstruction: 0.204051, Regularization: 0.040124, Discriminator: 0.043324; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:16,945 root         INFO     Train Epoch: 56 [512/8000 (6%)]\tTotal Loss: 1.067106\n",
      "Reconstruction: 0.947497, Regularization: 0.054433, Discriminator: 0.043510; Generator: 0.021666,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:33:17,052 root         INFO     Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 1.351602\n",
      "Reconstruction: 1.209540, Regularization: 0.077098, Discriminator: 0.043311; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:17,159 root         INFO     Train Epoch: 56 [1536/8000 (19%)]\tTotal Loss: 0.215151\n",
      "Reconstruction: 0.125392, Regularization: 0.024680, Discriminator: 0.043419; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:17,265 root         INFO     Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 0.307819\n",
      "Reconstruction: 0.206662, Regularization: 0.036093, Discriminator: 0.043415; Generator: 0.021648,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:17,372 root         INFO     Train Epoch: 56 [2560/8000 (32%)]\tTotal Loss: 1460.912964\n",
      "Reconstruction: 1460.728394, Regularization: 0.119653, Discriminator: 0.043244; Generator: 0.021652,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:17,479 root         INFO     Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 1.067058\n",
      "Reconstruction: 0.932674, Regularization: 0.069286, Discriminator: 0.043489; Generator: 0.021609,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 23:33:17,585 root         INFO     Train Epoch: 56 [3584/8000 (45%)]\tTotal Loss: 0.538761\n",
      "Reconstruction: 0.412298, Regularization: 0.061425, Discriminator: 0.043440; Generator: 0.021597,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:33:17,692 root         INFO     Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 0.345681\n",
      "Reconstruction: 0.219662, Regularization: 0.061059, Discriminator: 0.043334; Generator: 0.021626,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:33:17,799 root         INFO     Train Epoch: 56 [4608/8000 (58%)]\tTotal Loss: 0.228957\n",
      "Reconstruction: 0.120418, Regularization: 0.043471, Discriminator: 0.043497; Generator: 0.021571,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:33:17,908 root         INFO     Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 0.389239\n",
      "Reconstruction: 0.262371, Regularization: 0.061846, Discriminator: 0.043348; Generator: 0.021673,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:18,019 root         INFO     Train Epoch: 56 [5632/8000 (70%)]\tTotal Loss: 0.293437\n",
      "Reconstruction: 0.165910, Regularization: 0.062587, Discriminator: 0.043423; Generator: 0.021518,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-09 23:33:18,130 root         INFO     Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 0.249044\n",
      "Reconstruction: 0.114297, Regularization: 0.069694, Discriminator: 0.043412; Generator: 0.021642,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:18,241 root         INFO     Train Epoch: 56 [6656/8000 (83%)]\tTotal Loss: 2.421901\n",
      "Reconstruction: 2.296416, Regularization: 0.060383, Discriminator: 0.043434; Generator: 0.021668,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:33:18,352 root         INFO     Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 0.200558\n",
      "Reconstruction: 0.114951, Regularization: 0.020585, Discriminator: 0.043441; Generator: 0.021580,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:33:18,463 root         INFO     Train Epoch: 56 [7680/8000 (96%)]\tTotal Loss: 1.320743\n",
      "Reconstruction: 1.175809, Regularization: 0.079945, Discriminator: 0.043383; Generator: 0.021607,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:33:18,544 root         INFO     ====> Epoch: 56 Average loss: 35.7325\n",
      "2019-04-09 23:33:18,571 root         INFO     Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 1.622383\n",
      "Reconstruction: 1.524952, Regularization: 0.032421, Discriminator: 0.043327; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:18,682 root         INFO     Train Epoch: 57 [512/8000 (6%)]\tTotal Loss: 0.331250\n",
      "Reconstruction: 0.202051, Regularization: 0.064228, Discriminator: 0.043289; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:18,793 root         INFO     Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 0.848876\n",
      "Reconstruction: 0.685863, Regularization: 0.097900, Discriminator: 0.043403; Generator: 0.021710,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:33:18,905 root         INFO     Train Epoch: 57 [1536/8000 (19%)]\tTotal Loss: 0.394541\n",
      "Reconstruction: 0.281273, Regularization: 0.048263, Discriminator: 0.043330; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:19,015 root         INFO     Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 0.306355\n",
      "Reconstruction: 0.197109, Regularization: 0.044140, Discriminator: 0.043432; Generator: 0.021674,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:33:19,126 root         INFO     Train Epoch: 57 [2560/8000 (32%)]\tTotal Loss: 116860.359375\n",
      "Reconstruction: 116860.164062, Regularization: 0.136324, Discriminator: 0.043342; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:19,236 root         INFO     Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 0.385573\n",
      "Reconstruction: 0.264302, Regularization: 0.056174, Discriminator: 0.043400; Generator: 0.021696,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:33:19,346 root         INFO     Train Epoch: 57 [3584/8000 (45%)]\tTotal Loss: 0.326405\n",
      "Reconstruction: 0.228627, Regularization: 0.032711, Discriminator: 0.043396; Generator: 0.021671,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:19,457 root         INFO     Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 0.272338\n",
      "Reconstruction: 0.156503, Regularization: 0.050910, Discriminator: 0.043271; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:19,568 root         INFO     Train Epoch: 57 [4608/8000 (58%)]\tTotal Loss: 13.350379\n",
      "Reconstruction: 13.169377, Regularization: 0.115969, Discriminator: 0.043365; Generator: 0.021666,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:19,679 root         INFO     Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 0.332709\n",
      "Reconstruction: 0.144250, Regularization: 0.123557, Discriminator: 0.043244; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:19,789 root         INFO     Train Epoch: 57 [5632/8000 (70%)]\tTotal Loss: 0.286860\n",
      "Reconstruction: 0.160877, Regularization: 0.060933, Discriminator: 0.043400; Generator: 0.021651,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:19,900 root         INFO     Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 1.013224\n",
      "Reconstruction: 0.899875, Regularization: 0.048297, Discriminator: 0.043367; Generator: 0.021685,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:20,011 root         INFO     Train Epoch: 57 [6656/8000 (83%)]\tTotal Loss: 0.531557\n",
      "Reconstruction: 0.388410, Regularization: 0.078164, Discriminator: 0.043344; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:20,122 root         INFO     Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 0.286421\n",
      "Reconstruction: 0.175903, Regularization: 0.045561, Discriminator: 0.043313; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:20,233 root         INFO     Train Epoch: 57 [7680/8000 (96%)]\tTotal Loss: 0.353068\n",
      "Reconstruction: 0.236739, Regularization: 0.051340, Discriminator: 0.043320; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:20,313 root         INFO     ====> Epoch: 57 Average loss: 1379331.7144\n",
      "2019-04-09 23:33:20,340 root         INFO     Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 1.122370\n",
      "Reconstruction: 1.031925, Regularization: 0.025487, Discriminator: 0.043315; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:20,453 root         INFO     Train Epoch: 58 [512/8000 (6%)]\tTotal Loss: 0.965581\n",
      "Reconstruction: 0.794922, Regularization: 0.105664, Discriminator: 0.043327; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:20,565 root         INFO     Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 0.337755\n",
      "Reconstruction: 0.238924, Regularization: 0.033830, Discriminator: 0.043369; Generator: 0.021632,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:20,677 root         INFO     Train Epoch: 58 [1536/8000 (19%)]\tTotal Loss: 1.961374\n",
      "Reconstruction: 1.814461, Regularization: 0.081924, Discriminator: 0.043324; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:20,789 root         INFO     Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 0.388645\n",
      "Reconstruction: 0.255617, Regularization: 0.068058, Discriminator: 0.043317; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:20,900 root         INFO     Train Epoch: 58 [2560/8000 (32%)]\tTotal Loss: 2.437217\n",
      "Reconstruction: 2.087285, Regularization: 0.284938, Discriminator: 0.043328; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:21,013 root         INFO     Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 2.050492\n",
      "Reconstruction: 1.954150, Regularization: 0.031355, Discriminator: 0.043347; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:21,124 root         INFO     Train Epoch: 58 [3584/8000 (45%)]\tTotal Loss: 150.120163\n",
      "Reconstruction: 149.934052, Regularization: 0.121136, Discriminator: 0.043327; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:21,236 root         INFO     Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 0.357141\n",
      "Reconstruction: 0.248299, Regularization: 0.043866, Discriminator: 0.043314; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:21,348 root         INFO     Train Epoch: 58 [4608/8000 (58%)]\tTotal Loss: 1.375236\n",
      "Reconstruction: 1.153553, Regularization: 0.156731, Discriminator: 0.043287; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:21,459 root         INFO     Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 10919353.000000\n",
      "Reconstruction: 10919353.000000, Regularization: 0.343050, Discriminator: 0.043320; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:21,571 root         INFO     Train Epoch: 58 [5632/8000 (70%)]\tTotal Loss: 1.514564\n",
      "Reconstruction: 1.396297, Regularization: 0.053345, Discriminator: 0.043264; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:21,684 root         INFO     Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 983.606934\n",
      "Reconstruction: 983.415161, Regularization: 0.126791, Discriminator: 0.043362; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:21,795 root         INFO     Train Epoch: 58 [6656/8000 (83%)]\tTotal Loss: 0.675199\n",
      "Reconstruction: 0.528053, Regularization: 0.082119, Discriminator: 0.043370; Generator: 0.021657,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:21,907 root         INFO     Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 4.651928\n",
      "Reconstruction: 4.336410, Regularization: 0.250573, Discriminator: 0.043276; Generator: 0.021669,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:22,019 root         INFO     Train Epoch: 58 [7680/8000 (96%)]\tTotal Loss: 0.316691\n",
      "Reconstruction: 0.196295, Regularization: 0.055379, Discriminator: 0.043323; Generator: 0.021694,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:33:22,100 root         INFO     ====> Epoch: 58 Average loss: 59155.4213\n",
      "2019-04-09 23:33:22,127 root         INFO     Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 0.369955\n",
      "Reconstruction: 0.262616, Regularization: 0.042368, Discriminator: 0.043278; Generator: 0.021694,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:22,241 root         INFO     Train Epoch: 59 [512/8000 (6%)]\tTotal Loss: 0.509627\n",
      "Reconstruction: 0.379827, Regularization: 0.064826, Discriminator: 0.043297; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:22,353 root         INFO     Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 1.815029\n",
      "Reconstruction: 1.706715, Regularization: 0.043332, Discriminator: 0.043293; Generator: 0.021689,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:22,466 root         INFO     Train Epoch: 59 [1536/8000 (19%)]\tTotal Loss: 0.287506\n",
      "Reconstruction: 0.176526, Regularization: 0.046059, Discriminator: 0.043244; Generator: 0.021676,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:22,578 root         INFO     Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 0.908900\n",
      "Reconstruction: 0.813906, Regularization: 0.030077, Discriminator: 0.043251; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:22,689 root         INFO     Train Epoch: 59 [2560/8000 (32%)]\tTotal Loss: 0.318103\n",
      "Reconstruction: 0.179175, Regularization: 0.074003, Discriminator: 0.043247; Generator: 0.021679,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:22,802 root         INFO     Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 0.420041\n",
      "Reconstruction: 0.277699, Regularization: 0.077428, Discriminator: 0.043237; Generator: 0.021677,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:22,914 root         INFO     Train Epoch: 59 [3584/8000 (45%)]\tTotal Loss: 1.312041\n",
      "Reconstruction: 1.180522, Regularization: 0.066533, Discriminator: 0.043318; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:23,025 root         INFO     Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 0.592820\n",
      "Reconstruction: 0.459660, Regularization: 0.068248, Discriminator: 0.043228; Generator: 0.021684,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:23,137 root         INFO     Train Epoch: 59 [4608/8000 (58%)]\tTotal Loss: 0.425522\n",
      "Reconstruction: 0.155945, Regularization: 0.204620, Discriminator: 0.043265; Generator: 0.021692,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:23,249 root         INFO     Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 0.247020\n",
      "Reconstruction: 0.148370, Regularization: 0.033751, Discriminator: 0.043213; Generator: 0.021685,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:23,361 root         INFO     Train Epoch: 59 [5632/8000 (70%)]\tTotal Loss: 0.281756\n",
      "Reconstruction: 0.168152, Regularization: 0.048699, Discriminator: 0.043208; Generator: 0.021697,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:33:23,473 root         INFO     Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 0.697845\n",
      "Reconstruction: 0.588409, Regularization: 0.044505, Discriminator: 0.043245; Generator: 0.021686,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:23,585 root         INFO     Train Epoch: 59 [6656/8000 (83%)]\tTotal Loss: 0.286382\n",
      "Reconstruction: 0.186350, Regularization: 0.035163, Discriminator: 0.043181; Generator: 0.021688,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:33:23,696 root         INFO     Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 0.273590\n",
      "Reconstruction: 0.139890, Regularization: 0.068752, Discriminator: 0.043222; Generator: 0.021727,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:33:23,807 root         INFO     Train Epoch: 59 [7680/8000 (96%)]\tTotal Loss: 0.302978\n",
      "Reconstruction: 0.166101, Regularization: 0.071961, Discriminator: 0.043225; Generator: 0.021691,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:23,888 root         INFO     ====> Epoch: 59 Average loss: 207882.9073\n",
      "2019-04-09 23:33:23,914 root         INFO     Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 0.266077\n",
      "Reconstruction: 0.157309, Regularization: 0.043637, Discriminator: 0.043416; Generator: 0.021715,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:33:24,025 root         INFO     Train Epoch: 60 [512/8000 (6%)]\tTotal Loss: 63104.910156\n",
      "Reconstruction: 63104.558594, Regularization: 0.286818, Discriminator: 0.043336; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:24,135 root         INFO     Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 0.216391\n",
      "Reconstruction: 0.118612, Regularization: 0.032758, Discriminator: 0.043347; Generator: 0.021674,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:24,246 root         INFO     Train Epoch: 60 [1536/8000 (19%)]\tTotal Loss: 0.487414\n",
      "Reconstruction: 0.165805, Regularization: 0.256709, Discriminator: 0.043265; Generator: 0.021635,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:24,356 root         INFO     Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 0.878003\n",
      "Reconstruction: 0.709241, Regularization: 0.103716, Discriminator: 0.043388; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:24,467 root         INFO     Train Epoch: 60 [2560/8000 (32%)]\tTotal Loss: 0.230720\n",
      "Reconstruction: 0.134163, Regularization: 0.031538, Discriminator: 0.043371; Generator: 0.021648,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:24,577 root         INFO     Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 0.238995\n",
      "Reconstruction: 0.135618, Regularization: 0.038423, Discriminator: 0.043324; Generator: 0.021629,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:33:24,688 root         INFO     Train Epoch: 60 [3584/8000 (45%)]\tTotal Loss: 0.303496\n",
      "Reconstruction: 0.198580, Regularization: 0.040087, Discriminator: 0.043128; Generator: 0.021701,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 23:33:24,798 root         INFO     Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 0.378742\n",
      "Reconstruction: 0.232834, Regularization: 0.080938, Discriminator: 0.043295; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:24,909 root         INFO     Train Epoch: 60 [4608/8000 (58%)]\tTotal Loss: 679.738159\n",
      "Reconstruction: 679.509155, Regularization: 0.163861, Discriminator: 0.043413; Generator: 0.021730,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:33:25,020 root         INFO     Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 0.388580\n",
      "Reconstruction: 0.278439, Regularization: 0.045267, Discriminator: 0.043240; Generator: 0.021634,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:33:25,130 root         INFO     Train Epoch: 60 [5632/8000 (70%)]\tTotal Loss: 0.259997\n",
      "Reconstruction: 0.137798, Regularization: 0.057253, Discriminator: 0.043218; Generator: 0.021728,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:33:25,241 root         INFO     Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 0.379026\n",
      "Reconstruction: 0.255645, Regularization: 0.058462, Discriminator: 0.043230; Generator: 0.021689,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:25,351 root         INFO     Train Epoch: 60 [6656/8000 (83%)]\tTotal Loss: 0.320892\n",
      "Reconstruction: 0.197419, Regularization: 0.058530, Discriminator: 0.043310; Generator: 0.021633,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:25,462 root         INFO     Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 0.398443\n",
      "Reconstruction: 0.274550, Regularization: 0.058890, Discriminator: 0.043367; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:25,571 root         INFO     Train Epoch: 60 [7680/8000 (96%)]\tTotal Loss: 0.594067\n",
      "Reconstruction: 0.340778, Regularization: 0.188253, Discriminator: 0.043419; Generator: 0.021617,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:33:25,650 root         INFO     ====> Epoch: 60 Average loss: 271.4037\n",
      "2019-04-09 23:33:25,678 root         INFO     Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 4.097602\n",
      "Reconstruction: 3.950123, Regularization: 0.082486, Discriminator: 0.043342; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:25,790 root         INFO     Train Epoch: 61 [512/8000 (6%)]\tTotal Loss: 0.346681\n",
      "Reconstruction: 0.238412, Regularization: 0.043306, Discriminator: 0.043285; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:25,900 root         INFO     Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 0.366107\n",
      "Reconstruction: 0.213670, Regularization: 0.087446, Discriminator: 0.043320; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:26,011 root         INFO     Train Epoch: 61 [1536/8000 (19%)]\tTotal Loss: 0.243649\n",
      "Reconstruction: 0.114516, Regularization: 0.064174, Discriminator: 0.043296; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:26,122 root         INFO     Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 0.521946\n",
      "Reconstruction: 0.317065, Regularization: 0.140002, Discriminator: 0.043234; Generator: 0.021644,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:33:26,234 root         INFO     Train Epoch: 61 [2560/8000 (32%)]\tTotal Loss: 0.249551\n",
      "Reconstruction: 0.120585, Regularization: 0.064109, Discriminator: 0.043194; Generator: 0.021663,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:33:26,345 root         INFO     Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 0.509733\n",
      "Reconstruction: 0.402125, Regularization: 0.042693, Discriminator: 0.043263; Generator: 0.021651,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:26,456 root         INFO     Train Epoch: 61 [3584/8000 (45%)]\tTotal Loss: 0.275231\n",
      "Reconstruction: 0.162991, Regularization: 0.047298, Discriminator: 0.043283; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:26,567 root         INFO     Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 1.042119\n",
      "Reconstruction: 0.744629, Regularization: 0.232483, Discriminator: 0.043363; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:26,678 root         INFO     Train Epoch: 61 [4608/8000 (58%)]\tTotal Loss: 0.257802\n",
      "Reconstruction: 0.132836, Regularization: 0.060020, Discriminator: 0.043302; Generator: 0.021644,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:26,789 root         INFO     Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 0.368396\n",
      "Reconstruction: 0.197089, Regularization: 0.106264, Discriminator: 0.043392; Generator: 0.021651,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:26,899 root         INFO     Train Epoch: 61 [5632/8000 (70%)]\tTotal Loss: 0.235238\n",
      "Reconstruction: 0.120464, Regularization: 0.049751, Discriminator: 0.043370; Generator: 0.021654,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:27,009 root         INFO     Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 0.280485\n",
      "Reconstruction: 0.128675, Regularization: 0.086818, Discriminator: 0.043340; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:27,119 root         INFO     Train Epoch: 61 [6656/8000 (83%)]\tTotal Loss: 0.353293\n",
      "Reconstruction: 0.256707, Regularization: 0.031496, Discriminator: 0.043428; Generator: 0.021662,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:33:27,229 root         INFO     Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 0.245343\n",
      "Reconstruction: 0.143924, Regularization: 0.036385, Discriminator: 0.043393; Generator: 0.021641,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:27,339 root         INFO     Train Epoch: 61 [7680/8000 (96%)]\tTotal Loss: 1.261912\n",
      "Reconstruction: 1.104464, Regularization: 0.092513, Discriminator: 0.043280; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:27,419 root         INFO     ====> Epoch: 61 Average loss: 21.2267\n",
      "2019-04-09 23:33:27,447 root         INFO     Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 0.197018\n",
      "Reconstruction: 0.105394, Regularization: 0.026605, Discriminator: 0.043368; Generator: 0.021650,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:27,558 root         INFO     Train Epoch: 62 [512/8000 (6%)]\tTotal Loss: 0.225191\n",
      "Reconstruction: 0.123853, Regularization: 0.036251, Discriminator: 0.043441; Generator: 0.021647,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:33:27,669 root         INFO     Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 0.456020\n",
      "Reconstruction: 0.349212, Regularization: 0.041820, Discriminator: 0.043323; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:27,780 root         INFO     Train Epoch: 62 [1536/8000 (19%)]\tTotal Loss: 0.251206\n",
      "Reconstruction: 0.119389, Regularization: 0.066879, Discriminator: 0.043269; Generator: 0.021668,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:27,891 root         INFO     Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 0.234302\n",
      "Reconstruction: 0.120493, Regularization: 0.048833, Discriminator: 0.043320; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:28,002 root         INFO     Train Epoch: 62 [2560/8000 (32%)]\tTotal Loss: 0.262644\n",
      "Reconstruction: 0.150649, Regularization: 0.047035, Discriminator: 0.043315; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:28,111 root         INFO     Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 0.212964\n",
      "Reconstruction: 0.120949, Regularization: 0.027008, Discriminator: 0.043380; Generator: 0.021626,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:33:28,219 root         INFO     Train Epoch: 62 [3584/8000 (45%)]\tTotal Loss: 0.402455\n",
      "Reconstruction: 0.222821, Regularization: 0.114634, Discriminator: 0.043333; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:28,328 root         INFO     Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 0.375107\n",
      "Reconstruction: 0.256457, Regularization: 0.053644, Discriminator: 0.043349; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:28,437 root         INFO     Train Epoch: 62 [4608/8000 (58%)]\tTotal Loss: 0.726936\n",
      "Reconstruction: 0.629046, Regularization: 0.032889, Discriminator: 0.043377; Generator: 0.021623,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:33:28,546 root         INFO     Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 0.381059\n",
      "Reconstruction: 0.207673, Regularization: 0.108443, Discriminator: 0.043362; Generator: 0.021581,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:33:28,657 root         INFO     Train Epoch: 62 [5632/8000 (70%)]\tTotal Loss: 0.222190\n",
      "Reconstruction: 0.118610, Regularization: 0.038565, Discriminator: 0.043341; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:28,768 root         INFO     Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 2.395192\n",
      "Reconstruction: 2.252083, Regularization: 0.078162, Discriminator: 0.043370; Generator: 0.021578,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:33:28,878 root         INFO     Train Epoch: 62 [6656/8000 (83%)]\tTotal Loss: 0.532724\n",
      "Reconstruction: 0.219985, Regularization: 0.247770, Discriminator: 0.043281; Generator: 0.021689,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:28,989 root         INFO     Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 0.333866\n",
      "Reconstruction: 0.177264, Regularization: 0.091617, Discriminator: 0.043373; Generator: 0.021612,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:33:29,098 root         INFO     Train Epoch: 62 [7680/8000 (96%)]\tTotal Loss: 0.609496\n",
      "Reconstruction: 0.492287, Regularization: 0.052223, Discriminator: 0.043361; Generator: 0.021625,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:33:29,178 root         INFO     ====> Epoch: 62 Average loss: 0.9746\n",
      "2019-04-09 23:33:29,205 root         INFO     Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 0.262154\n",
      "Reconstruction: 0.164958, Regularization: 0.032204, Discriminator: 0.043337; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:29,313 root         INFO     Train Epoch: 63 [512/8000 (6%)]\tTotal Loss: 0.294961\n",
      "Reconstruction: 0.143613, Regularization: 0.086372, Discriminator: 0.043310; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:29,421 root         INFO     Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 0.343263\n",
      "Reconstruction: 0.209375, Regularization: 0.068909, Discriminator: 0.043329; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:29,529 root         INFO     Train Epoch: 63 [1536/8000 (19%)]\tTotal Loss: 0.269543\n",
      "Reconstruction: 0.144482, Regularization: 0.060075, Discriminator: 0.043329; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:29,637 root         INFO     Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 0.249934\n",
      "Reconstruction: 0.160036, Regularization: 0.024922, Discriminator: 0.043321; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:29,746 root         INFO     Train Epoch: 63 [2560/8000 (32%)]\tTotal Loss: 0.255095\n",
      "Reconstruction: 0.140412, Regularization: 0.049712, Discriminator: 0.043308; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:29,855 root         INFO     Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 0.277778\n",
      "Reconstruction: 0.143752, Regularization: 0.069037, Discriminator: 0.043351; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:29,963 root         INFO     Train Epoch: 63 [3584/8000 (45%)]\tTotal Loss: 0.316799\n",
      "Reconstruction: 0.149489, Regularization: 0.102334, Discriminator: 0.043312; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:30,072 root         INFO     Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 0.437245\n",
      "Reconstruction: 0.269144, Regularization: 0.103131, Discriminator: 0.043360; Generator: 0.021609,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:33:30,185 root         INFO     Train Epoch: 63 [4608/8000 (58%)]\tTotal Loss: 0.439050\n",
      "Reconstruction: 0.297248, Regularization: 0.076813, Discriminator: 0.043242; Generator: 0.021747,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:30,296 root         INFO     Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 0.191078\n",
      "Reconstruction: 0.098414, Regularization: 0.027737, Discriminator: 0.043260; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:30,408 root         INFO     Train Epoch: 63 [5632/8000 (70%)]\tTotal Loss: 1.954540\n",
      "Reconstruction: 1.538036, Regularization: 0.351498, Discriminator: 0.043346; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:30,519 root         INFO     Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 0.439142\n",
      "Reconstruction: 0.320253, Regularization: 0.053924, Discriminator: 0.043339; Generator: 0.021626,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:33:30,630 root         INFO     Train Epoch: 63 [6656/8000 (83%)]\tTotal Loss: 0.240702\n",
      "Reconstruction: 0.131737, Regularization: 0.043987, Discriminator: 0.043294; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:30,740 root         INFO     Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 0.277373\n",
      "Reconstruction: 0.149410, Regularization: 0.062982, Discriminator: 0.043303; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:30,850 root         INFO     Train Epoch: 63 [7680/8000 (96%)]\tTotal Loss: 1196.528320\n",
      "Reconstruction: 1196.238770, Regularization: 0.224523, Discriminator: 0.043268; Generator: 0.021751,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:33:30,930 root         INFO     ====> Epoch: 63 Average loss: 16.3263\n",
      "2019-04-09 23:33:30,957 root         INFO     Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 0.849577\n",
      "Reconstruction: 0.737151, Regularization: 0.047455, Discriminator: 0.043311; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:31,066 root         INFO     Train Epoch: 64 [512/8000 (6%)]\tTotal Loss: 0.218150\n",
      "Reconstruction: 0.106183, Regularization: 0.047047, Discriminator: 0.043242; Generator: 0.021679,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:31,175 root         INFO     Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 1.026058\n",
      "Reconstruction: 0.875549, Regularization: 0.085457, Discriminator: 0.043358; Generator: 0.021695,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:33:31,283 root         INFO     Train Epoch: 64 [1536/8000 (19%)]\tTotal Loss: 0.451396\n",
      "Reconstruction: 0.267079, Regularization: 0.119367, Discriminator: 0.043295; Generator: 0.021656,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:31,392 root         INFO     Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 0.375670\n",
      "Reconstruction: 0.182936, Regularization: 0.127772, Discriminator: 0.043320; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:31,501 root         INFO     Train Epoch: 64 [2560/8000 (32%)]\tTotal Loss: 0.449699\n",
      "Reconstruction: 0.326945, Regularization: 0.057733, Discriminator: 0.043343; Generator: 0.021679,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:31,610 root         INFO     Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 0.278144\n",
      "Reconstruction: 0.152625, Regularization: 0.060545, Discriminator: 0.043266; Generator: 0.021707,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:31,720 root         INFO     Train Epoch: 64 [3584/8000 (45%)]\tTotal Loss: 0.239787\n",
      "Reconstruction: 0.111501, Regularization: 0.063323, Discriminator: 0.043279; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:31,829 root         INFO     Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 0.341008\n",
      "Reconstruction: 0.205827, Regularization: 0.070274, Discriminator: 0.043232; Generator: 0.021675,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:31,938 root         INFO     Train Epoch: 64 [4608/8000 (58%)]\tTotal Loss: 0.238478\n",
      "Reconstruction: 0.133481, Regularization: 0.040049, Discriminator: 0.043255; Generator: 0.021693,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:33:32,047 root         INFO     Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 0.224496\n",
      "Reconstruction: 0.122504, Regularization: 0.036984, Discriminator: 0.043328; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:32,157 root         INFO     Train Epoch: 64 [5632/8000 (70%)]\tTotal Loss: 0.414456\n",
      "Reconstruction: 0.251377, Regularization: 0.098142, Discriminator: 0.043239; Generator: 0.021698,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:33:32,268 root         INFO     Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 0.292641\n",
      "Reconstruction: 0.161913, Regularization: 0.065825, Discriminator: 0.043212; Generator: 0.021690,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:32,381 root         INFO     Train Epoch: 64 [6656/8000 (83%)]\tTotal Loss: 0.275314\n",
      "Reconstruction: 0.156379, Regularization: 0.054040, Discriminator: 0.043214; Generator: 0.021681,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:32,491 root         INFO     Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 0.244332\n",
      "Reconstruction: 0.135189, Regularization: 0.044189, Discriminator: 0.043317; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:32,600 root         INFO     Train Epoch: 64 [7680/8000 (96%)]\tTotal Loss: 0.273635\n",
      "Reconstruction: 0.127038, Regularization: 0.081605, Discriminator: 0.043316; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:32,681 root         INFO     ====> Epoch: 64 Average loss: 165.4925\n",
      "2019-04-09 23:33:32,708 root         INFO     Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 0.299787\n",
      "Reconstruction: 0.192891, Regularization: 0.041963, Discriminator: 0.043283; Generator: 0.021649,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:32,818 root         INFO     Train Epoch: 65 [512/8000 (6%)]\tTotal Loss: 0.214176\n",
      "Reconstruction: 0.117288, Regularization: 0.031925, Discriminator: 0.043281; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:32,928 root         INFO     Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 0.527976\n",
      "Reconstruction: 0.379175, Regularization: 0.083814, Discriminator: 0.043312; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:33,039 root         INFO     Train Epoch: 65 [1536/8000 (19%)]\tTotal Loss: 0.251847\n",
      "Reconstruction: 0.127367, Regularization: 0.059562, Discriminator: 0.043307; Generator: 0.021612,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:33:33,149 root         INFO     Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 0.340182\n",
      "Reconstruction: 0.234004, Regularization: 0.041183, Discriminator: 0.043356; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:33,259 root         INFO     Train Epoch: 65 [2560/8000 (32%)]\tTotal Loss: 0.473919\n",
      "Reconstruction: 0.342266, Regularization: 0.066657, Discriminator: 0.043354; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:33,369 root         INFO     Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 0.254490\n",
      "Reconstruction: 0.140311, Regularization: 0.049238, Discriminator: 0.043286; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:33,478 root         INFO     Train Epoch: 65 [3584/8000 (45%)]\tTotal Loss: 0.436821\n",
      "Reconstruction: 0.321994, Regularization: 0.049967, Discriminator: 0.043194; Generator: 0.021665,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:33:33,587 root         INFO     Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 0.770283\n",
      "Reconstruction: 0.621702, Regularization: 0.083596, Discriminator: 0.043339; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:33,697 root         INFO     Train Epoch: 65 [4608/8000 (58%)]\tTotal Loss: 0.252745\n",
      "Reconstruction: 0.119404, Regularization: 0.068421, Discriminator: 0.043270; Generator: 0.021650,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:33,809 root         INFO     Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 0.228588\n",
      "Reconstruction: 0.121261, Regularization: 0.042438, Discriminator: 0.043235; Generator: 0.021654,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:33:33,920 root         INFO     Train Epoch: 65 [5632/8000 (70%)]\tTotal Loss: 0.266557\n",
      "Reconstruction: 0.157811, Regularization: 0.043755, Discriminator: 0.043337; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:34,032 root         INFO     Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 0.242731\n",
      "Reconstruction: 0.114482, Regularization: 0.063169, Discriminator: 0.043489; Generator: 0.021590,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 23:33:34,144 root         INFO     Train Epoch: 65 [6656/8000 (83%)]\tTotal Loss: 0.431326\n",
      "Reconstruction: 0.308670, Regularization: 0.057744, Discriminator: 0.043287; Generator: 0.021625,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:33:34,255 root         INFO     Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 0.285023\n",
      "Reconstruction: 0.129149, Regularization: 0.090946, Discriminator: 0.043264; Generator: 0.021664,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:34,367 root         INFO     Train Epoch: 65 [7680/8000 (96%)]\tTotal Loss: 3.527158\n",
      "Reconstruction: 3.416846, Regularization: 0.045421, Discriminator: 0.043288; Generator: 0.021603,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 23:33:34,448 root         INFO     ====> Epoch: 65 Average loss: 59.1859\n",
      "2019-04-09 23:33:34,475 root         INFO     Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 0.231805\n",
      "Reconstruction: 0.121672, Regularization: 0.045140, Discriminator: 0.043347; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:34,587 root         INFO     Train Epoch: 66 [512/8000 (6%)]\tTotal Loss: 0.689945\n",
      "Reconstruction: 0.511160, Regularization: 0.113730, Discriminator: 0.043415; Generator: 0.021640,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:34,698 root         INFO     Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 0.254417\n",
      "Reconstruction: 0.143323, Regularization: 0.046083, Discriminator: 0.043365; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:34,809 root         INFO     Train Epoch: 66 [1536/8000 (19%)]\tTotal Loss: 12.991276\n",
      "Reconstruction: 12.779891, Regularization: 0.146400, Discriminator: 0.043376; Generator: 0.021609,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:33:34,920 root         INFO     Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 0.259430\n",
      "Reconstruction: 0.115269, Regularization: 0.079196, Discriminator: 0.043322; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:35,030 root         INFO     Train Epoch: 66 [2560/8000 (32%)]\tTotal Loss: 1.582069\n",
      "Reconstruction: 1.472469, Regularization: 0.044602, Discriminator: 0.043399; Generator: 0.021598,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:33:35,141 root         INFO     Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 0.243883\n",
      "Reconstruction: 0.141273, Regularization: 0.037630, Discriminator: 0.043349; Generator: 0.021631,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:35,251 root         INFO     Train Epoch: 66 [3584/8000 (45%)]\tTotal Loss: 19.890751\n",
      "Reconstruction: 19.775892, Regularization: 0.049887, Discriminator: 0.043372; Generator: 0.021600,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:33:35,362 root         INFO     Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 0.483848\n",
      "Reconstruction: 0.376043, Regularization: 0.042835, Discriminator: 0.043302; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:35,472 root         INFO     Train Epoch: 66 [4608/8000 (58%)]\tTotal Loss: 0.279098\n",
      "Reconstruction: 0.163372, Regularization: 0.050693, Discriminator: 0.043370; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:35,584 root         INFO     Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 0.215362\n",
      "Reconstruction: 0.104059, Regularization: 0.046371, Discriminator: 0.043296; Generator: 0.021635,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:35,694 root         INFO     Train Epoch: 66 [5632/8000 (70%)]\tTotal Loss: 0.510601\n",
      "Reconstruction: 0.410720, Regularization: 0.034935, Discriminator: 0.043331; Generator: 0.021616,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:33:35,805 root         INFO     Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 0.316412\n",
      "Reconstruction: 0.207085, Regularization: 0.044310, Discriminator: 0.043389; Generator: 0.021628,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:33:35,915 root         INFO     Train Epoch: 66 [6656/8000 (83%)]\tTotal Loss: 14.486463\n",
      "Reconstruction: 14.309611, Regularization: 0.111859, Discriminator: 0.043352; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:36,026 root         INFO     Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 0.264705\n",
      "Reconstruction: 0.162222, Regularization: 0.037486, Discriminator: 0.043350; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:36,136 root         INFO     Train Epoch: 66 [7680/8000 (96%)]\tTotal Loss: 0.253004\n",
      "Reconstruction: 0.150497, Regularization: 0.037497, Discriminator: 0.043355; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:36,217 root         INFO     ====> Epoch: 66 Average loss: 71.1217\n",
      "2019-04-09 23:33:36,244 root         INFO     Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 0.599313\n",
      "Reconstruction: 0.480568, Regularization: 0.053683, Discriminator: 0.043413; Generator: 0.021650,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:36,357 root         INFO     Train Epoch: 67 [512/8000 (6%)]\tTotal Loss: 0.254963\n",
      "Reconstruction: 0.130625, Regularization: 0.059338, Discriminator: 0.043339; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:36,468 root         INFO     Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 0.405578\n",
      "Reconstruction: 0.258980, Regularization: 0.081623, Discriminator: 0.043325; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:36,579 root         INFO     Train Epoch: 67 [1536/8000 (19%)]\tTotal Loss: 3.498932\n",
      "Reconstruction: 3.364432, Regularization: 0.069510, Discriminator: 0.043337; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:36,690 root         INFO     Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 0.975526\n",
      "Reconstruction: 0.830460, Regularization: 0.080084, Discriminator: 0.043334; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:36,801 root         INFO     Train Epoch: 67 [2560/8000 (32%)]\tTotal Loss: 0.682949\n",
      "Reconstruction: 0.544668, Regularization: 0.073305, Discriminator: 0.043283; Generator: 0.021693,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:36,912 root         INFO     Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 0.963459\n",
      "Reconstruction: 0.799694, Regularization: 0.098817, Discriminator: 0.043300; Generator: 0.021648,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:37,023 root         INFO     Train Epoch: 67 [3584/8000 (45%)]\tTotal Loss: 0.661780\n",
      "Reconstruction: 0.527558, Regularization: 0.069203, Discriminator: 0.043323; Generator: 0.021696,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:33:37,134 root         INFO     Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 2.387524\n",
      "Reconstruction: 2.158719, Regularization: 0.163832, Discriminator: 0.043306; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:37,245 root         INFO     Train Epoch: 67 [4608/8000 (58%)]\tTotal Loss: 0.307028\n",
      "Reconstruction: 0.171050, Regularization: 0.071010, Discriminator: 0.043347; Generator: 0.021621,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:33:37,356 root         INFO     Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 0.310943\n",
      "Reconstruction: 0.191663, Regularization: 0.054302, Discriminator: 0.043329; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:37,467 root         INFO     Train Epoch: 67 [5632/8000 (70%)]\tTotal Loss: 11.267889\n",
      "Reconstruction: 11.149598, Regularization: 0.053319, Discriminator: 0.043323; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:37,578 root         INFO     Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 0.385884\n",
      "Reconstruction: 0.152958, Regularization: 0.167934, Discriminator: 0.043322; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:37,688 root         INFO     Train Epoch: 67 [6656/8000 (83%)]\tTotal Loss: 0.415080\n",
      "Reconstruction: 0.219060, Regularization: 0.131045, Discriminator: 0.043313; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:37,800 root         INFO     Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 0.341668\n",
      "Reconstruction: 0.231141, Regularization: 0.045535, Discriminator: 0.043339; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:37,911 root         INFO     Train Epoch: 67 [7680/8000 (96%)]\tTotal Loss: 2.274601\n",
      "Reconstruction: 2.129396, Regularization: 0.080252, Discriminator: 0.043290; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:37,992 root         INFO     ====> Epoch: 67 Average loss: 141858072343.2847\n",
      "2019-04-09 23:33:38,019 root         INFO     Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 569.933777\n",
      "Reconstruction: 569.726685, Regularization: 0.142086, Discriminator: 0.043314; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:38,131 root         INFO     Train Epoch: 68 [512/8000 (6%)]\tTotal Loss: 0.724026\n",
      "Reconstruction: 0.587479, Regularization: 0.071528, Discriminator: 0.043362; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:38,242 root         INFO     Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 0.242403\n",
      "Reconstruction: 0.132696, Regularization: 0.044755, Discriminator: 0.043280; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:38,353 root         INFO     Train Epoch: 68 [1536/8000 (19%)]\tTotal Loss: 1.661644\n",
      "Reconstruction: 1.499154, Regularization: 0.097482, Discriminator: 0.043324; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:38,463 root         INFO     Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 2.823658\n",
      "Reconstruction: 2.713727, Regularization: 0.044972, Discriminator: 0.043280; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:38,573 root         INFO     Train Epoch: 68 [2560/8000 (32%)]\tTotal Loss: 1.387675\n",
      "Reconstruction: 1.261043, Regularization: 0.061667, Discriminator: 0.043294; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:38,684 root         INFO     Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 0.826802\n",
      "Reconstruction: 0.726277, Regularization: 0.035609, Discriminator: 0.043258; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:38,795 root         INFO     Train Epoch: 68 [3584/8000 (45%)]\tTotal Loss: 0.214089\n",
      "Reconstruction: 0.106912, Regularization: 0.042205, Discriminator: 0.043302; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:38,907 root         INFO     Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 0.492834\n",
      "Reconstruction: 0.322722, Regularization: 0.105108, Discriminator: 0.043323; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:39,019 root         INFO     Train Epoch: 68 [4608/8000 (58%)]\tTotal Loss: 0.327301\n",
      "Reconstruction: 0.224103, Regularization: 0.038247, Discriminator: 0.043274; Generator: 0.021676,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:39,129 root         INFO     Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 0.299913\n",
      "Reconstruction: 0.184151, Regularization: 0.050853, Discriminator: 0.043245; Generator: 0.021665,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:39,240 root         INFO     Train Epoch: 68 [5632/8000 (70%)]\tTotal Loss: 0.302476\n",
      "Reconstruction: 0.193701, Regularization: 0.043881, Discriminator: 0.043226; Generator: 0.021668,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:39,352 root         INFO     Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 0.442653\n",
      "Reconstruction: 0.301834, Regularization: 0.075865, Discriminator: 0.043266; Generator: 0.021688,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:39,466 root         INFO     Train Epoch: 68 [6656/8000 (83%)]\tTotal Loss: 0.464811\n",
      "Reconstruction: 0.310773, Regularization: 0.089090, Discriminator: 0.043274; Generator: 0.021674,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:39,578 root         INFO     Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 0.197296\n",
      "Reconstruction: 0.101639, Regularization: 0.030716, Discriminator: 0.043273; Generator: 0.021668,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:39,690 root         INFO     Train Epoch: 68 [7680/8000 (96%)]\tTotal Loss: 2.243362\n",
      "Reconstruction: 2.086762, Regularization: 0.091619, Discriminator: 0.043308; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:39,770 root         INFO     ====> Epoch: 68 Average loss: 391.4427\n",
      "2019-04-09 23:33:39,798 root         INFO     Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 0.328411\n",
      "Reconstruction: 0.232268, Regularization: 0.031168, Discriminator: 0.043310; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:39,909 root         INFO     Train Epoch: 69 [512/8000 (6%)]\tTotal Loss: 0.266328\n",
      "Reconstruction: 0.155937, Regularization: 0.045442, Discriminator: 0.043292; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:40,020 root         INFO     Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 0.559774\n",
      "Reconstruction: 0.395916, Regularization: 0.098864, Discriminator: 0.043340; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:40,130 root         INFO     Train Epoch: 69 [1536/8000 (19%)]\tTotal Loss: 15.719686\n",
      "Reconstruction: 15.466890, Regularization: 0.187757, Discriminator: 0.043386; Generator: 0.021653,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:40,241 root         INFO     Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 0.217668\n",
      "Reconstruction: 0.123407, Regularization: 0.029304, Discriminator: 0.043315; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:40,352 root         INFO     Train Epoch: 69 [2560/8000 (32%)]\tTotal Loss: 0.372871\n",
      "Reconstruction: 0.169956, Regularization: 0.137902, Discriminator: 0.043378; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:40,462 root         INFO     Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 0.624993\n",
      "Reconstruction: 0.417207, Regularization: 0.142833, Discriminator: 0.043294; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:40,571 root         INFO     Train Epoch: 69 [3584/8000 (45%)]\tTotal Loss: 1.048071\n",
      "Reconstruction: 0.916548, Regularization: 0.066588, Discriminator: 0.043278; Generator: 0.021656,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:40,682 root         INFO     Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 0.323454\n",
      "Reconstruction: 0.191634, Regularization: 0.066814, Discriminator: 0.043347; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:40,792 root         INFO     Train Epoch: 69 [4608/8000 (58%)]\tTotal Loss: 0.328866\n",
      "Reconstruction: 0.226016, Regularization: 0.037930, Discriminator: 0.043279; Generator: 0.021640,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:40,902 root         INFO     Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 0.250456\n",
      "Reconstruction: 0.155115, Regularization: 0.030324, Discriminator: 0.043323; Generator: 0.021694,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:33:41,012 root         INFO     Train Epoch: 69 [5632/8000 (70%)]\tTotal Loss: 0.228037\n",
      "Reconstruction: 0.116671, Regularization: 0.046405, Discriminator: 0.043300; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:41,123 root         INFO     Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 2.030729\n",
      "Reconstruction: 1.898909, Regularization: 0.066750, Discriminator: 0.043406; Generator: 0.021664,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:41,233 root         INFO     Train Epoch: 69 [6656/8000 (83%)]\tTotal Loss: 8.982948\n",
      "Reconstruction: 8.669108, Regularization: 0.248854, Discriminator: 0.043300; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:41,343 root         INFO     Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 0.216474\n",
      "Reconstruction: 0.114817, Regularization: 0.036689, Discriminator: 0.043301; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:41,453 root         INFO     Train Epoch: 69 [7680/8000 (96%)]\tTotal Loss: 0.250069\n",
      "Reconstruction: 0.139149, Regularization: 0.045844, Discriminator: 0.043435; Generator: 0.021641,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:41,534 root         INFO     ====> Epoch: 69 Average loss: 281.1543\n",
      "2019-04-09 23:33:41,562 root         INFO     Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 0.357606\n",
      "Reconstruction: 0.155809, Regularization: 0.136805, Discriminator: 0.043330; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:41,674 root         INFO     Train Epoch: 70 [512/8000 (6%)]\tTotal Loss: 0.258410\n",
      "Reconstruction: 0.156430, Regularization: 0.036979, Discriminator: 0.043363; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:41,785 root         INFO     Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 0.370299\n",
      "Reconstruction: 0.249631, Regularization: 0.055724, Discriminator: 0.043345; Generator: 0.021599,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:33:41,896 root         INFO     Train Epoch: 70 [1536/8000 (19%)]\tTotal Loss: 0.200752\n",
      "Reconstruction: 0.105177, Regularization: 0.030545, Discriminator: 0.043405; Generator: 0.021625,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:33:42,007 root         INFO     Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 1.955550\n",
      "Reconstruction: 1.785795, Regularization: 0.104742, Discriminator: 0.043363; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:42,117 root         INFO     Train Epoch: 70 [2560/8000 (32%)]\tTotal Loss: 0.216179\n",
      "Reconstruction: 0.120977, Regularization: 0.030270, Discriminator: 0.043296; Generator: 0.021637,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:42,228 root         INFO     Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 0.234457\n",
      "Reconstruction: 0.129648, Regularization: 0.039766, Discriminator: 0.043376; Generator: 0.021666,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:42,339 root         INFO     Train Epoch: 70 [3584/8000 (45%)]\tTotal Loss: 0.228369\n",
      "Reconstruction: 0.114116, Regularization: 0.049251, Discriminator: 0.043347; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:42,450 root         INFO     Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 0.393438\n",
      "Reconstruction: 0.162566, Regularization: 0.165868, Discriminator: 0.043354; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:42,562 root         INFO     Train Epoch: 70 [4608/8000 (58%)]\tTotal Loss: 0.400336\n",
      "Reconstruction: 0.279137, Regularization: 0.056111, Discriminator: 0.043431; Generator: 0.021657,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:33:42,672 root         INFO     Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 0.670316\n",
      "Reconstruction: 0.505423, Regularization: 0.099838, Discriminator: 0.043394; Generator: 0.021661,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:42,782 root         INFO     Train Epoch: 70 [5632/8000 (70%)]\tTotal Loss: 0.765124\n",
      "Reconstruction: 0.593093, Regularization: 0.107026, Discriminator: 0.043350; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:42,891 root         INFO     Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 0.323915\n",
      "Reconstruction: 0.180923, Regularization: 0.078007, Discriminator: 0.043339; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:43,002 root         INFO     Train Epoch: 70 [6656/8000 (83%)]\tTotal Loss: 0.270147\n",
      "Reconstruction: 0.140847, Regularization: 0.064298, Discriminator: 0.043345; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:43,112 root         INFO     Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 0.417715\n",
      "Reconstruction: 0.285557, Regularization: 0.067202, Discriminator: 0.043308; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:43,222 root         INFO     Train Epoch: 70 [7680/8000 (96%)]\tTotal Loss: 0.260883\n",
      "Reconstruction: 0.143872, Regularization: 0.052090, Discriminator: 0.043268; Generator: 0.021653,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:43,303 root         INFO     ====> Epoch: 70 Average loss: 77.3681\n",
      "2019-04-09 23:33:43,330 root         INFO     Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 0.228170\n",
      "Reconstruction: 0.123992, Regularization: 0.039193, Discriminator: 0.043318; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:43,442 root         INFO     Train Epoch: 71 [512/8000 (6%)]\tTotal Loss: 0.230775\n",
      "Reconstruction: 0.133946, Regularization: 0.031836, Discriminator: 0.043344; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:43,552 root         INFO     Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 0.539081\n",
      "Reconstruction: 0.373107, Regularization: 0.100961, Discriminator: 0.043350; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:43,664 root         INFO     Train Epoch: 71 [1536/8000 (19%)]\tTotal Loss: 0.216654\n",
      "Reconstruction: 0.120852, Regularization: 0.030827, Discriminator: 0.043321; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:43,774 root         INFO     Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 0.603495\n",
      "Reconstruction: 0.489833, Regularization: 0.048672, Discriminator: 0.043338; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:43,885 root         INFO     Train Epoch: 71 [2560/8000 (32%)]\tTotal Loss: 0.241226\n",
      "Reconstruction: 0.128938, Regularization: 0.047287, Discriminator: 0.043336; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:43,996 root         INFO     Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 0.347916\n",
      "Reconstruction: 0.235810, Regularization: 0.047113, Discriminator: 0.043332; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:44,106 root         INFO     Train Epoch: 71 [3584/8000 (45%)]\tTotal Loss: 0.231849\n",
      "Reconstruction: 0.112159, Regularization: 0.054723, Discriminator: 0.043311; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:44,217 root         INFO     Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 0.235375\n",
      "Reconstruction: 0.144787, Regularization: 0.025625, Discriminator: 0.043303; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:44,328 root         INFO     Train Epoch: 71 [4608/8000 (58%)]\tTotal Loss: 0.306182\n",
      "Reconstruction: 0.157983, Regularization: 0.083210, Discriminator: 0.043318; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:44,439 root         INFO     Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 0.427133\n",
      "Reconstruction: 0.233284, Regularization: 0.128853, Discriminator: 0.043334; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:44,549 root         INFO     Train Epoch: 71 [5632/8000 (70%)]\tTotal Loss: 1.432792\n",
      "Reconstruction: 1.296496, Regularization: 0.071315, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:44,658 root         INFO     Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 0.299015\n",
      "Reconstruction: 0.145412, Regularization: 0.088624, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:44,767 root         INFO     Train Epoch: 71 [6656/8000 (83%)]\tTotal Loss: 0.217867\n",
      "Reconstruction: 0.116755, Regularization: 0.036148, Discriminator: 0.043301; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:44,876 root         INFO     Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 0.379547\n",
      "Reconstruction: 0.216660, Regularization: 0.097902, Discriminator: 0.043318; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:44,984 root         INFO     Train Epoch: 71 [7680/8000 (96%)]\tTotal Loss: 0.310534\n",
      "Reconstruction: 0.153301, Regularization: 0.092258, Discriminator: 0.043310; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:45,064 root         INFO     ====> Epoch: 71 Average loss: 86.2797\n",
      "2019-04-09 23:33:45,092 root         INFO     Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 0.224727\n",
      "Reconstruction: 0.121996, Regularization: 0.037749, Discriminator: 0.043317; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:45,206 root         INFO     Train Epoch: 72 [512/8000 (6%)]\tTotal Loss: 0.451796\n",
      "Reconstruction: 0.265984, Regularization: 0.120862, Discriminator: 0.043310; Generator: 0.021639,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:45,318 root         INFO     Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 288.232056\n",
      "Reconstruction: 287.913788, Regularization: 0.253246, Discriminator: 0.043350; Generator: 0.021678,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:45,430 root         INFO     Train Epoch: 72 [1536/8000 (19%)]\tTotal Loss: 0.513406\n",
      "Reconstruction: 0.299527, Regularization: 0.148898, Discriminator: 0.043300; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:45,542 root         INFO     Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 0.412926\n",
      "Reconstruction: 0.297960, Regularization: 0.050012, Discriminator: 0.043321; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:45,654 root         INFO     Train Epoch: 72 [2560/8000 (32%)]\tTotal Loss: 0.291278\n",
      "Reconstruction: 0.182319, Regularization: 0.043992, Discriminator: 0.043299; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:45,766 root         INFO     Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 0.293821\n",
      "Reconstruction: 0.154675, Regularization: 0.074162, Discriminator: 0.043317; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:45,878 root         INFO     Train Epoch: 72 [3584/8000 (45%)]\tTotal Loss: 0.309629\n",
      "Reconstruction: 0.190152, Regularization: 0.054466, Discriminator: 0.043346; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:45,990 root         INFO     Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 0.377534\n",
      "Reconstruction: 0.285865, Regularization: 0.026694, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:46,102 root         INFO     Train Epoch: 72 [4608/8000 (58%)]\tTotal Loss: 0.281361\n",
      "Reconstruction: 0.176621, Regularization: 0.039794, Discriminator: 0.043271; Generator: 0.021675,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:46,214 root         INFO     Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 0.239397\n",
      "Reconstruction: 0.136964, Regularization: 0.037434, Discriminator: 0.043330; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:46,325 root         INFO     Train Epoch: 72 [5632/8000 (70%)]\tTotal Loss: 0.304859\n",
      "Reconstruction: 0.187661, Regularization: 0.052256, Discriminator: 0.043274; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:46,437 root         INFO     Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 0.225982\n",
      "Reconstruction: 0.113491, Regularization: 0.047495, Discriminator: 0.043304; Generator: 0.021692,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:46,549 root         INFO     Train Epoch: 72 [6656/8000 (83%)]\tTotal Loss: 0.649274\n",
      "Reconstruction: 0.530302, Regularization: 0.054037, Discriminator: 0.043277; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:46,661 root         INFO     Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 0.387123\n",
      "Reconstruction: 0.252435, Regularization: 0.069796, Discriminator: 0.043242; Generator: 0.021650,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:46,774 root         INFO     Train Epoch: 72 [7680/8000 (96%)]\tTotal Loss: 0.246279\n",
      "Reconstruction: 0.124254, Regularization: 0.057088, Discriminator: 0.043301; Generator: 0.021637,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:46,856 root         INFO     ====> Epoch: 72 Average loss: 3.1163\n",
      "2019-04-09 23:33:46,883 root         INFO     Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 0.241027\n",
      "Reconstruction: 0.135854, Regularization: 0.040166, Discriminator: 0.043337; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:46,995 root         INFO     Train Epoch: 73 [512/8000 (6%)]\tTotal Loss: 14.493812\n",
      "Reconstruction: 14.300248, Regularization: 0.128624, Discriminator: 0.043273; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:47,105 root         INFO     Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 0.396016\n",
      "Reconstruction: 0.271913, Regularization: 0.059116, Discriminator: 0.043339; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:47,216 root         INFO     Train Epoch: 73 [1536/8000 (19%)]\tTotal Loss: 10.877342\n",
      "Reconstruction: 10.702229, Regularization: 0.110164, Discriminator: 0.043247; Generator: 0.021702,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:33:47,327 root         INFO     Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 0.363994\n",
      "Reconstruction: 0.237569, Regularization: 0.061430, Discriminator: 0.043339; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:47,438 root         INFO     Train Epoch: 73 [2560/8000 (32%)]\tTotal Loss: 0.620536\n",
      "Reconstruction: 0.346691, Regularization: 0.208870, Discriminator: 0.043339; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:47,548 root         INFO     Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 0.274457\n",
      "Reconstruction: 0.117709, Regularization: 0.091763, Discriminator: 0.043328; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:47,659 root         INFO     Train Epoch: 73 [3584/8000 (45%)]\tTotal Loss: 0.548865\n",
      "Reconstruction: 0.394012, Regularization: 0.089962, Discriminator: 0.043239; Generator: 0.021652,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:33:47,769 root         INFO     Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 3.765129\n",
      "Reconstruction: 3.564687, Regularization: 0.135477, Discriminator: 0.043305; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:47,879 root         INFO     Train Epoch: 73 [4608/8000 (58%)]\tTotal Loss: 0.405783\n",
      "Reconstruction: 0.215015, Regularization: 0.125773, Discriminator: 0.043344; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:47,989 root         INFO     Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 0.239642\n",
      "Reconstruction: 0.138634, Regularization: 0.036051, Discriminator: 0.043276; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:48,099 root         INFO     Train Epoch: 73 [5632/8000 (70%)]\tTotal Loss: 0.561541\n",
      "Reconstruction: 0.463327, Regularization: 0.033250, Discriminator: 0.043285; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:48,210 root         INFO     Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 0.561464\n",
      "Reconstruction: 0.435465, Regularization: 0.061003, Discriminator: 0.043302; Generator: 0.021695,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:48,319 root         INFO     Train Epoch: 73 [6656/8000 (83%)]\tTotal Loss: 0.463129\n",
      "Reconstruction: 0.346764, Regularization: 0.051328, Discriminator: 0.043375; Generator: 0.021661,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:48,430 root         INFO     Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 0.363745\n",
      "Reconstruction: 0.252796, Regularization: 0.045904, Discriminator: 0.043356; Generator: 0.021690,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:48,540 root         INFO     Train Epoch: 73 [7680/8000 (96%)]\tTotal Loss: 0.289673\n",
      "Reconstruction: 0.151195, Regularization: 0.073514, Discriminator: 0.043320; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:48,621 root         INFO     ====> Epoch: 73 Average loss: 5826187.5315\n",
      "2019-04-09 23:33:48,648 root         INFO     Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 2.253233\n",
      "Reconstruction: 2.132703, Regularization: 0.055444, Discriminator: 0.043423; Generator: 0.021663,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:33:48,761 root         INFO     Train Epoch: 74 [512/8000 (6%)]\tTotal Loss: 0.227045\n",
      "Reconstruction: 0.131614, Regularization: 0.030471, Discriminator: 0.043268; Generator: 0.021691,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:48,872 root         INFO     Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 3.484125\n",
      "Reconstruction: 3.355765, Regularization: 0.063352, Discriminator: 0.043333; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:48,982 root         INFO     Train Epoch: 74 [1536/8000 (19%)]\tTotal Loss: 0.261792\n",
      "Reconstruction: 0.163061, Regularization: 0.033727, Discriminator: 0.043351; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:49,093 root         INFO     Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 4.282946\n",
      "Reconstruction: 4.100618, Regularization: 0.117365, Discriminator: 0.043320; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:49,204 root         INFO     Train Epoch: 74 [2560/8000 (32%)]\tTotal Loss: 0.226956\n",
      "Reconstruction: 0.134406, Regularization: 0.027545, Discriminator: 0.043336; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:49,316 root         INFO     Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 0.397569\n",
      "Reconstruction: 0.263833, Regularization: 0.068775, Discriminator: 0.043285; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:49,428 root         INFO     Train Epoch: 74 [3584/8000 (45%)]\tTotal Loss: 0.330987\n",
      "Reconstruction: 0.220753, Regularization: 0.045212, Discriminator: 0.043381; Generator: 0.021641,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:49,539 root         INFO     Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 1369.748047\n",
      "Reconstruction: 1369.122437, Regularization: 0.560721, Discriminator: 0.043338; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:49,651 root         INFO     Train Epoch: 74 [4608/8000 (58%)]\tTotal Loss: 0.379239\n",
      "Reconstruction: 0.290613, Regularization: 0.023601, Discriminator: 0.043338; Generator: 0.021688,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:49,763 root         INFO     Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 10.516627\n",
      "Reconstruction: 10.332170, Regularization: 0.119492, Discriminator: 0.043314; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:49,874 root         INFO     Train Epoch: 74 [5632/8000 (70%)]\tTotal Loss: 0.522747\n",
      "Reconstruction: 0.423804, Regularization: 0.033964, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:49,986 root         INFO     Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 0.333797\n",
      "Reconstruction: 0.219010, Regularization: 0.049794, Discriminator: 0.043335; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:50,097 root         INFO     Train Epoch: 74 [6656/8000 (83%)]\tTotal Loss: 0.263389\n",
      "Reconstruction: 0.161619, Regularization: 0.036768, Discriminator: 0.043331; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:50,207 root         INFO     Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 2.232926\n",
      "Reconstruction: 2.114461, Regularization: 0.053489, Discriminator: 0.043333; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:50,319 root         INFO     Train Epoch: 74 [7680/8000 (96%)]\tTotal Loss: 0.268615\n",
      "Reconstruction: 0.136398, Regularization: 0.067243, Discriminator: 0.043328; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:50,401 root         INFO     ====> Epoch: 74 Average loss: 102223.7984\n",
      "2019-04-09 23:33:50,429 root         INFO     Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 0.267850\n",
      "Reconstruction: 0.152232, Regularization: 0.050632, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:50,541 root         INFO     Train Epoch: 75 [512/8000 (6%)]\tTotal Loss: 0.707952\n",
      "Reconstruction: 0.577675, Regularization: 0.065297, Discriminator: 0.043315; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:50,653 root         INFO     Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 1.897781\n",
      "Reconstruction: 1.784340, Regularization: 0.048451, Discriminator: 0.043331; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:50,764 root         INFO     Train Epoch: 75 [1536/8000 (19%)]\tTotal Loss: 0.287870\n",
      "Reconstruction: 0.145996, Regularization: 0.076901, Discriminator: 0.043315; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:50,876 root         INFO     Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 1.924817\n",
      "Reconstruction: 1.800176, Regularization: 0.059676, Discriminator: 0.043295; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:50,987 root         INFO     Train Epoch: 75 [2560/8000 (32%)]\tTotal Loss: 0.353011\n",
      "Reconstruction: 0.233012, Regularization: 0.054998, Discriminator: 0.043333; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:51,099 root         INFO     Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 9.435073\n",
      "Reconstruction: 9.282728, Regularization: 0.087364, Discriminator: 0.043310; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:51,211 root         INFO     Train Epoch: 75 [3584/8000 (45%)]\tTotal Loss: 0.221051\n",
      "Reconstruction: 0.128331, Regularization: 0.027761, Discriminator: 0.043290; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:51,322 root         INFO     Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 0.270159\n",
      "Reconstruction: 0.157699, Regularization: 0.047470, Discriminator: 0.043340; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:51,434 root         INFO     Train Epoch: 75 [4608/8000 (58%)]\tTotal Loss: 0.617265\n",
      "Reconstruction: 0.510153, Regularization: 0.042127, Discriminator: 0.043329; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:51,546 root         INFO     Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 0.628957\n",
      "Reconstruction: 0.502464, Regularization: 0.061558, Discriminator: 0.043275; Generator: 0.021660,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:51,658 root         INFO     Train Epoch: 75 [5632/8000 (70%)]\tTotal Loss: 0.299780\n",
      "Reconstruction: 0.196019, Regularization: 0.038781, Discriminator: 0.043307; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:51,769 root         INFO     Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 0.305096\n",
      "Reconstruction: 0.194323, Regularization: 0.045878, Discriminator: 0.043236; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:51,880 root         INFO     Train Epoch: 75 [6656/8000 (83%)]\tTotal Loss: 1.815746\n",
      "Reconstruction: 1.625288, Regularization: 0.125485, Discriminator: 0.043311; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:51,992 root         INFO     Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 0.250045\n",
      "Reconstruction: 0.147671, Regularization: 0.037462, Discriminator: 0.043239; Generator: 0.021673,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:52,104 root         INFO     Train Epoch: 75 [7680/8000 (96%)]\tTotal Loss: 0.321352\n",
      "Reconstruction: 0.218515, Regularization: 0.037841, Discriminator: 0.043322; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:52,186 root         INFO     ====> Epoch: 75 Average loss: 7120737.6157\n",
      "2019-04-09 23:33:52,213 root         INFO     Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 0.245499\n",
      "Reconstruction: 0.131649, Regularization: 0.048863, Discriminator: 0.043308; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:52,325 root         INFO     Train Epoch: 76 [512/8000 (6%)]\tTotal Loss: 0.217755\n",
      "Reconstruction: 0.132969, Regularization: 0.019779, Discriminator: 0.043329; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:52,436 root         INFO     Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 0.466703\n",
      "Reconstruction: 0.331130, Regularization: 0.070549, Discriminator: 0.043368; Generator: 0.021655,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:52,547 root         INFO     Train Epoch: 76 [1536/8000 (19%)]\tTotal Loss: 0.357177\n",
      "Reconstruction: 0.248180, Regularization: 0.044057, Discriminator: 0.043253; Generator: 0.021687,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:52,658 root         INFO     Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 0.604696\n",
      "Reconstruction: 0.488220, Regularization: 0.051442, Discriminator: 0.043388; Generator: 0.021645,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:52,769 root         INFO     Train Epoch: 76 [2560/8000 (32%)]\tTotal Loss: 0.323329\n",
      "Reconstruction: 0.189407, Regularization: 0.068969, Discriminator: 0.043328; Generator: 0.021625,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:33:52,880 root         INFO     Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 0.343833\n",
      "Reconstruction: 0.242729, Regularization: 0.036071, Discriminator: 0.043337; Generator: 0.021696,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:33:52,991 root         INFO     Train Epoch: 76 [3584/8000 (45%)]\tTotal Loss: 0.242552\n",
      "Reconstruction: 0.146866, Regularization: 0.030739, Discriminator: 0.043300; Generator: 0.021647,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:53,102 root         INFO     Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 0.261138\n",
      "Reconstruction: 0.131428, Regularization: 0.064734, Discriminator: 0.043313; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:53,212 root         INFO     Train Epoch: 76 [4608/8000 (58%)]\tTotal Loss: 0.357562\n",
      "Reconstruction: 0.251104, Regularization: 0.041474, Discriminator: 0.043316; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:53,323 root         INFO     Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 0.202345\n",
      "Reconstruction: 0.109548, Regularization: 0.027808, Discriminator: 0.043344; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:53,434 root         INFO     Train Epoch: 76 [5632/8000 (70%)]\tTotal Loss: 0.268402\n",
      "Reconstruction: 0.149360, Regularization: 0.054031, Discriminator: 0.043338; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:53,545 root         INFO     Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 0.264826\n",
      "Reconstruction: 0.131159, Regularization: 0.068652, Discriminator: 0.043323; Generator: 0.021691,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:53,654 root         INFO     Train Epoch: 76 [6656/8000 (83%)]\tTotal Loss: 0.270878\n",
      "Reconstruction: 0.163316, Regularization: 0.042602, Discriminator: 0.043339; Generator: 0.021620,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:33:53,764 root         INFO     Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 0.210454\n",
      "Reconstruction: 0.102549, Regularization: 0.042935, Discriminator: 0.043308; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:53,873 root         INFO     Train Epoch: 76 [7680/8000 (96%)]\tTotal Loss: 0.324594\n",
      "Reconstruction: 0.190259, Regularization: 0.069363, Discriminator: 0.043372; Generator: 0.021599,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:33:53,954 root         INFO     ====> Epoch: 76 Average loss: 23552.0835\n",
      "2019-04-09 23:33:53,981 root         INFO     Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 5.845689\n",
      "Reconstruction: 5.500856, Regularization: 0.279864, Discriminator: 0.043316; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:54,092 root         INFO     Train Epoch: 77 [512/8000 (6%)]\tTotal Loss: 0.209857\n",
      "Reconstruction: 0.096910, Regularization: 0.047951, Discriminator: 0.043321; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:54,202 root         INFO     Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 0.257192\n",
      "Reconstruction: 0.152996, Regularization: 0.039252, Discriminator: 0.043244; Generator: 0.021700,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:33:54,313 root         INFO     Train Epoch: 77 [1536/8000 (19%)]\tTotal Loss: 0.229800\n",
      "Reconstruction: 0.126537, Regularization: 0.038257, Discriminator: 0.043345; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:54,423 root         INFO     Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 0.218501\n",
      "Reconstruction: 0.118436, Regularization: 0.035100, Discriminator: 0.043310; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:54,534 root         INFO     Train Epoch: 77 [2560/8000 (32%)]\tTotal Loss: 0.463970\n",
      "Reconstruction: 0.330108, Regularization: 0.068868, Discriminator: 0.043325; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:54,646 root         INFO     Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 0.223248\n",
      "Reconstruction: 0.123999, Regularization: 0.034305, Discriminator: 0.043293; Generator: 0.021651,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:54,757 root         INFO     Train Epoch: 77 [3584/8000 (45%)]\tTotal Loss: 8.848921\n",
      "Reconstruction: 8.662525, Regularization: 0.121460, Discriminator: 0.043283; Generator: 0.021652,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:54,868 root         INFO     Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 0.270643\n",
      "Reconstruction: 0.157775, Regularization: 0.047887, Discriminator: 0.043349; Generator: 0.021631,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:54,979 root         INFO     Train Epoch: 77 [4608/8000 (58%)]\tTotal Loss: 0.257671\n",
      "Reconstruction: 0.122822, Regularization: 0.069862, Discriminator: 0.043333; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:55,089 root         INFO     Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 0.298123\n",
      "Reconstruction: 0.128275, Regularization: 0.104861, Discriminator: 0.043344; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:55,201 root         INFO     Train Epoch: 77 [5632/8000 (70%)]\tTotal Loss: 0.202981\n",
      "Reconstruction: 0.111051, Regularization: 0.026964, Discriminator: 0.043315; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:55,313 root         INFO     Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 0.221187\n",
      "Reconstruction: 0.125516, Regularization: 0.030703, Discriminator: 0.043323; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:55,426 root         INFO     Train Epoch: 77 [6656/8000 (83%)]\tTotal Loss: 0.604669\n",
      "Reconstruction: 0.479420, Regularization: 0.060260, Discriminator: 0.043316; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:55,539 root         INFO     Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 0.434993\n",
      "Reconstruction: 0.281156, Regularization: 0.088806, Discriminator: 0.043378; Generator: 0.021652,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:55,651 root         INFO     Train Epoch: 77 [7680/8000 (96%)]\tTotal Loss: 0.274841\n",
      "Reconstruction: 0.134327, Regularization: 0.075533, Discriminator: 0.043330; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:55,732 root         INFO     ====> Epoch: 77 Average loss: 688.1469\n",
      "2019-04-09 23:33:55,761 root         INFO     Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 0.679780\n",
      "Reconstruction: 0.539318, Regularization: 0.075465, Discriminator: 0.043340; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:55,874 root         INFO     Train Epoch: 78 [512/8000 (6%)]\tTotal Loss: 1.704910\n",
      "Reconstruction: 1.542811, Regularization: 0.097103, Discriminator: 0.043336; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:55,985 root         INFO     Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 0.951030\n",
      "Reconstruction: 0.819660, Regularization: 0.066380, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:56,097 root         INFO     Train Epoch: 78 [1536/8000 (19%)]\tTotal Loss: 0.247769\n",
      "Reconstruction: 0.124599, Regularization: 0.058176, Discriminator: 0.043344; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:56,209 root         INFO     Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 0.352850\n",
      "Reconstruction: 0.191232, Regularization: 0.096643, Discriminator: 0.043321; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:56,321 root         INFO     Train Epoch: 78 [2560/8000 (32%)]\tTotal Loss: 0.213991\n",
      "Reconstruction: 0.113377, Regularization: 0.035629, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:56,433 root         INFO     Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 0.231971\n",
      "Reconstruction: 0.124535, Regularization: 0.042444, Discriminator: 0.043334; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:56,544 root         INFO     Train Epoch: 78 [3584/8000 (45%)]\tTotal Loss: 0.472445\n",
      "Reconstruction: 0.315245, Regularization: 0.092209, Discriminator: 0.043321; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:56,655 root         INFO     Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 0.563820\n",
      "Reconstruction: 0.379491, Regularization: 0.119330, Discriminator: 0.043306; Generator: 0.021692,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:33:56,766 root         INFO     Train Epoch: 78 [4608/8000 (58%)]\tTotal Loss: 0.292407\n",
      "Reconstruction: 0.197749, Regularization: 0.029687, Discriminator: 0.043338; Generator: 0.021632,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:56,876 root         INFO     Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 0.215177\n",
      "Reconstruction: 0.102242, Regularization: 0.047944, Discriminator: 0.043304; Generator: 0.021688,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:56,987 root         INFO     Train Epoch: 78 [5632/8000 (70%)]\tTotal Loss: 0.221784\n",
      "Reconstruction: 0.125084, Regularization: 0.031687, Discriminator: 0.043363; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:57,098 root         INFO     Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 0.209355\n",
      "Reconstruction: 0.118947, Regularization: 0.025420, Discriminator: 0.043331; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:57,209 root         INFO     Train Epoch: 78 [6656/8000 (83%)]\tTotal Loss: 0.210405\n",
      "Reconstruction: 0.111267, Regularization: 0.034137, Discriminator: 0.043346; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:57,320 root         INFO     Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 10.471393\n",
      "Reconstruction: 10.341592, Regularization: 0.064803, Discriminator: 0.043314; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:57,430 root         INFO     Train Epoch: 78 [7680/8000 (96%)]\tTotal Loss: 0.245302\n",
      "Reconstruction: 0.147176, Regularization: 0.033142, Discriminator: 0.043325; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:57,510 root         INFO     ====> Epoch: 78 Average loss: 18.5155\n",
      "2019-04-09 23:33:57,538 root         INFO     Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 0.237382\n",
      "Reconstruction: 0.118919, Regularization: 0.053480, Discriminator: 0.043313; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:57,652 root         INFO     Train Epoch: 79 [512/8000 (6%)]\tTotal Loss: 0.360412\n",
      "Reconstruction: 0.242864, Regularization: 0.052561, Discriminator: 0.043321; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:57,764 root         INFO     Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 0.295238\n",
      "Reconstruction: 0.167179, Regularization: 0.063125, Discriminator: 0.043264; Generator: 0.021671,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:57,877 root         INFO     Train Epoch: 79 [1536/8000 (19%)]\tTotal Loss: 0.214058\n",
      "Reconstruction: 0.112701, Regularization: 0.036428, Discriminator: 0.043273; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:57,988 root         INFO     Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 0.244623\n",
      "Reconstruction: 0.151344, Regularization: 0.028309, Discriminator: 0.043321; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:58,100 root         INFO     Train Epoch: 79 [2560/8000 (32%)]\tTotal Loss: 0.895099\n",
      "Reconstruction: 0.755990, Regularization: 0.074136, Discriminator: 0.043293; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:58,212 root         INFO     Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 0.385526\n",
      "Reconstruction: 0.277144, Regularization: 0.043376, Discriminator: 0.043347; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:58,322 root         INFO     Train Epoch: 79 [3584/8000 (45%)]\tTotal Loss: 0.683446\n",
      "Reconstruction: 0.531844, Regularization: 0.086641, Discriminator: 0.043274; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:58,433 root         INFO     Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 0.215417\n",
      "Reconstruction: 0.103474, Regularization: 0.046964, Discriminator: 0.043301; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:58,545 root         INFO     Train Epoch: 79 [4608/8000 (58%)]\tTotal Loss: 0.284652\n",
      "Reconstruction: 0.182147, Regularization: 0.037562, Discriminator: 0.043326; Generator: 0.021617,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:33:58,657 root         INFO     Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 0.264996\n",
      "Reconstruction: 0.127414, Regularization: 0.072536, Discriminator: 0.043401; Generator: 0.021646,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:58,766 root         INFO     Train Epoch: 79 [5632/8000 (70%)]\tTotal Loss: 0.212128\n",
      "Reconstruction: 0.109875, Regularization: 0.037289, Discriminator: 0.043296; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:58,878 root         INFO     Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 0.576958\n",
      "Reconstruction: 0.413052, Regularization: 0.098982, Discriminator: 0.043243; Generator: 0.021681,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:58,990 root         INFO     Train Epoch: 79 [6656/8000 (83%)]\tTotal Loss: 0.249210\n",
      "Reconstruction: 0.129030, Regularization: 0.055180, Discriminator: 0.043329; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:59,104 root         INFO     Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 0.257351\n",
      "Reconstruction: 0.139576, Regularization: 0.052804, Discriminator: 0.043317; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:59,214 root         INFO     Train Epoch: 79 [7680/8000 (96%)]\tTotal Loss: 0.268501\n",
      "Reconstruction: 0.168691, Regularization: 0.034870, Discriminator: 0.043243; Generator: 0.021697,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:33:59,295 root         INFO     ====> Epoch: 79 Average loss: 5.2184\n",
      "2019-04-09 23:33:59,323 root         INFO     Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 0.269625\n",
      "Reconstruction: 0.153858, Regularization: 0.050740, Discriminator: 0.043344; Generator: 0.021683,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:33:59,435 root         INFO     Train Epoch: 80 [512/8000 (6%)]\tTotal Loss: 0.259027\n",
      "Reconstruction: 0.134748, Regularization: 0.059312, Discriminator: 0.043301; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:59,547 root         INFO     Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 0.261261\n",
      "Reconstruction: 0.135301, Regularization: 0.060957, Discriminator: 0.043363; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:59,660 root         INFO     Train Epoch: 80 [1536/8000 (19%)]\tTotal Loss: 0.256858\n",
      "Reconstruction: 0.139005, Regularization: 0.052901, Discriminator: 0.043282; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:59,773 root         INFO     Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 52.286877\n",
      "Reconstruction: 52.176674, Regularization: 0.045207, Discriminator: 0.043330; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:33:59,886 root         INFO     Train Epoch: 80 [2560/8000 (32%)]\tTotal Loss: 0.471598\n",
      "Reconstruction: 0.342375, Regularization: 0.064301, Discriminator: 0.043286; Generator: 0.021636,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:33:59,999 root         INFO     Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 0.454279\n",
      "Reconstruction: 0.351561, Regularization: 0.037754, Discriminator: 0.043314; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:00,112 root         INFO     Train Epoch: 80 [3584/8000 (45%)]\tTotal Loss: 0.874113\n",
      "Reconstruction: 0.741705, Regularization: 0.067426, Discriminator: 0.043316; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:00,225 root         INFO     Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 0.232822\n",
      "Reconstruction: 0.123832, Regularization: 0.043995, Discriminator: 0.043324; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:00,338 root         INFO     Train Epoch: 80 [4608/8000 (58%)]\tTotal Loss: 0.474256\n",
      "Reconstruction: 0.358687, Regularization: 0.050567, Discriminator: 0.043359; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:00,451 root         INFO     Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 0.593962\n",
      "Reconstruction: 0.432342, Regularization: 0.096615, Discriminator: 0.043345; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:00,564 root         INFO     Train Epoch: 80 [5632/8000 (70%)]\tTotal Loss: 0.310880\n",
      "Reconstruction: 0.214282, Regularization: 0.031614, Discriminator: 0.043357; Generator: 0.021626,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:00,677 root         INFO     Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 0.782268\n",
      "Reconstruction: 0.645105, Regularization: 0.072267, Discriminator: 0.043224; Generator: 0.021672,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:00,790 root         INFO     Train Epoch: 80 [6656/8000 (83%)]\tTotal Loss: 0.442646\n",
      "Reconstruction: 0.255598, Regularization: 0.122054, Discriminator: 0.043318; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:00,903 root         INFO     Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 0.267866\n",
      "Reconstruction: 0.169407, Regularization: 0.033503, Discriminator: 0.043309; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:01,016 root         INFO     Train Epoch: 80 [7680/8000 (96%)]\tTotal Loss: 0.292076\n",
      "Reconstruction: 0.190839, Regularization: 0.036196, Discriminator: 0.043383; Generator: 0.021658,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:01,097 root         INFO     ====> Epoch: 80 Average loss: 424.8132\n",
      "2019-04-09 23:34:01,125 root         INFO     Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 0.270641\n",
      "Reconstruction: 0.169360, Regularization: 0.036264, Discriminator: 0.043341; Generator: 0.021676,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:01,240 root         INFO     Train Epoch: 81 [512/8000 (6%)]\tTotal Loss: 1.094943\n",
      "Reconstruction: 0.768702, Regularization: 0.261294, Discriminator: 0.043295; Generator: 0.021653,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:01,353 root         INFO     Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 0.796853\n",
      "Reconstruction: 0.679473, Regularization: 0.052405, Discriminator: 0.043339; Generator: 0.021635,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:01,466 root         INFO     Train Epoch: 81 [1536/8000 (19%)]\tTotal Loss: 0.712795\n",
      "Reconstruction: 0.595224, Regularization: 0.052579, Discriminator: 0.043336; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:01,579 root         INFO     Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 160.159409\n",
      "Reconstruction: 159.964691, Regularization: 0.129727, Discriminator: 0.043340; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:01,692 root         INFO     Train Epoch: 81 [2560/8000 (32%)]\tTotal Loss: 1.274390\n",
      "Reconstruction: 1.142098, Regularization: 0.067306, Discriminator: 0.043330; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:01,805 root         INFO     Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 40.604107\n",
      "Reconstruction: 40.347717, Regularization: 0.191375, Discriminator: 0.043353; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:01,919 root         INFO     Train Epoch: 81 [3584/8000 (45%)]\tTotal Loss: 2.506733\n",
      "Reconstruction: 2.396809, Regularization: 0.044947, Discriminator: 0.043300; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:02,032 root         INFO     Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 1.903450\n",
      "Reconstruction: 1.712426, Regularization: 0.126038, Discriminator: 0.043357; Generator: 0.021629,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:02,145 root         INFO     Train Epoch: 81 [4608/8000 (58%)]\tTotal Loss: 0.240796\n",
      "Reconstruction: 0.138886, Regularization: 0.036951, Discriminator: 0.043259; Generator: 0.021700,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:02,258 root         INFO     Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 21.771027\n",
      "Reconstruction: 21.624201, Regularization: 0.081839, Discriminator: 0.043358; Generator: 0.021631,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:02,370 root         INFO     Train Epoch: 81 [5632/8000 (70%)]\tTotal Loss: 0.262549\n",
      "Reconstruction: 0.153326, Regularization: 0.044294, Discriminator: 0.043226; Generator: 0.021703,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:34:02,483 root         INFO     Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 0.335280\n",
      "Reconstruction: 0.171251, Regularization: 0.099046, Discriminator: 0.043292; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:02,595 root         INFO     Train Epoch: 81 [6656/8000 (83%)]\tTotal Loss: 0.269892\n",
      "Reconstruction: 0.137324, Regularization: 0.067631, Discriminator: 0.043308; Generator: 0.021630,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:34:02,705 root         INFO     Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 0.238333\n",
      "Reconstruction: 0.111746, Regularization: 0.061621, Discriminator: 0.043335; Generator: 0.021631,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:02,816 root         INFO     Train Epoch: 81 [7680/8000 (96%)]\tTotal Loss: 0.386409\n",
      "Reconstruction: 0.259998, Regularization: 0.061434, Discriminator: 0.043300; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:02,896 root         INFO     ====> Epoch: 81 Average loss: 112.2493\n",
      "2019-04-09 23:34:02,924 root         INFO     Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 0.308210\n",
      "Reconstruction: 0.197345, Regularization: 0.045857, Discriminator: 0.043282; Generator: 0.021726,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:03,037 root         INFO     Train Epoch: 82 [512/8000 (6%)]\tTotal Loss: 0.325841\n",
      "Reconstruction: 0.173608, Regularization: 0.087188, Discriminator: 0.043298; Generator: 0.021746,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:34:03,150 root         INFO     Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 0.249136\n",
      "Reconstruction: 0.131118, Regularization: 0.052966, Discriminator: 0.043351; Generator: 0.021701,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:34:03,263 root         INFO     Train Epoch: 82 [1536/8000 (19%)]\tTotal Loss: 0.220399\n",
      "Reconstruction: 0.130962, Regularization: 0.024435, Discriminator: 0.043325; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:03,376 root         INFO     Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 0.292915\n",
      "Reconstruction: 0.148041, Regularization: 0.079900, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:03,487 root         INFO     Train Epoch: 82 [2560/8000 (32%)]\tTotal Loss: 0.252230\n",
      "Reconstruction: 0.156776, Regularization: 0.030479, Discriminator: 0.043310; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:03,599 root         INFO     Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 0.239930\n",
      "Reconstruction: 0.138800, Regularization: 0.036165, Discriminator: 0.043317; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:03,711 root         INFO     Train Epoch: 82 [3584/8000 (45%)]\tTotal Loss: 0.233367\n",
      "Reconstruction: 0.125964, Regularization: 0.042400, Discriminator: 0.043302; Generator: 0.021701,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:03,823 root         INFO     Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 0.276433\n",
      "Reconstruction: 0.191502, Regularization: 0.019909, Discriminator: 0.043317; Generator: 0.021706,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:34:03,936 root         INFO     Train Epoch: 82 [4608/8000 (58%)]\tTotal Loss: 3.408577\n",
      "Reconstruction: 3.259584, Regularization: 0.084067, Discriminator: 0.043274; Generator: 0.021652,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:04,049 root         INFO     Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 0.264293\n",
      "Reconstruction: 0.133560, Regularization: 0.065780, Discriminator: 0.043377; Generator: 0.021576,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:34:04,161 root         INFO     Train Epoch: 82 [5632/8000 (70%)]\tTotal Loss: 2.958571\n",
      "Reconstruction: 2.856038, Regularization: 0.037500, Discriminator: 0.043523; Generator: 0.021510,\n",
      "D(x): 0.499, D(G(z)): 0.502\n",
      "2019-04-09 23:34:04,273 root         INFO     Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 1.032660\n",
      "Reconstruction: 0.885007, Regularization: 0.082742, Discriminator: 0.043141; Generator: 0.021770,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 23:34:04,385 root         INFO     Train Epoch: 82 [6656/8000 (83%)]\tTotal Loss: 0.240623\n",
      "Reconstruction: 0.132911, Regularization: 0.042702, Discriminator: 0.043337; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:04,497 root         INFO     Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 0.222237\n",
      "Reconstruction: 0.122403, Regularization: 0.034793, Discriminator: 0.043400; Generator: 0.021641,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:04,610 root         INFO     Train Epoch: 82 [7680/8000 (96%)]\tTotal Loss: 1.407668\n",
      "Reconstruction: 1.278578, Regularization: 0.064107, Discriminator: 0.043288; Generator: 0.021696,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:04,692 root         INFO     ====> Epoch: 82 Average loss: 17.1218\n",
      "2019-04-09 23:34:04,719 root         INFO     Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 0.217789\n",
      "Reconstruction: 0.116959, Regularization: 0.035815, Discriminator: 0.043412; Generator: 0.021602,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:04,830 root         INFO     Train Epoch: 83 [512/8000 (6%)]\tTotal Loss: 0.248161\n",
      "Reconstruction: 0.146701, Regularization: 0.036442, Discriminator: 0.043245; Generator: 0.021774,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 23:34:04,939 root         INFO     Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 0.270122\n",
      "Reconstruction: 0.136988, Regularization: 0.068159, Discriminator: 0.043392; Generator: 0.021583,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:05,051 root         INFO     Train Epoch: 83 [1536/8000 (19%)]\tTotal Loss: 0.397892\n",
      "Reconstruction: 0.240168, Regularization: 0.092782, Discriminator: 0.043337; Generator: 0.021605,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:34:05,163 root         INFO     Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 0.234947\n",
      "Reconstruction: 0.132569, Regularization: 0.037359, Discriminator: 0.043344; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:05,274 root         INFO     Train Epoch: 83 [2560/8000 (32%)]\tTotal Loss: 0.246400\n",
      "Reconstruction: 0.147575, Regularization: 0.033841, Discriminator: 0.043345; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:05,386 root         INFO     Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 0.290892\n",
      "Reconstruction: 0.175549, Regularization: 0.050351, Discriminator: 0.043341; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:05,499 root         INFO     Train Epoch: 83 [3584/8000 (45%)]\tTotal Loss: 0.259228\n",
      "Reconstruction: 0.140757, Regularization: 0.053493, Discriminator: 0.043315; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:05,610 root         INFO     Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 5.007257\n",
      "Reconstruction: 4.704056, Regularization: 0.238245, Discriminator: 0.043294; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:05,721 root         INFO     Train Epoch: 83 [4608/8000 (58%)]\tTotal Loss: 0.270481\n",
      "Reconstruction: 0.153212, Regularization: 0.052262, Discriminator: 0.043342; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:05,832 root         INFO     Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 0.325082\n",
      "Reconstruction: 0.174928, Regularization: 0.085191, Discriminator: 0.043311; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:05,943 root         INFO     Train Epoch: 83 [5632/8000 (70%)]\tTotal Loss: 260.859985\n",
      "Reconstruction: 260.713684, Regularization: 0.081339, Discriminator: 0.043300; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:06,053 root         INFO     Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 0.378730\n",
      "Reconstruction: 0.263242, Regularization: 0.050572, Discriminator: 0.043264; Generator: 0.021653,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:06,164 root         INFO     Train Epoch: 83 [6656/8000 (83%)]\tTotal Loss: 0.205384\n",
      "Reconstruction: 0.111595, Regularization: 0.028836, Discriminator: 0.043303; Generator: 0.021650,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:06,275 root         INFO     Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 0.248825\n",
      "Reconstruction: 0.144537, Regularization: 0.039377, Discriminator: 0.043276; Generator: 0.021635,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:06,386 root         INFO     Train Epoch: 83 [7680/8000 (96%)]\tTotal Loss: 0.248723\n",
      "Reconstruction: 0.109944, Regularization: 0.073752, Discriminator: 0.043394; Generator: 0.021634,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:06,467 root         INFO     ====> Epoch: 83 Average loss: 1946592.5216\n",
      "2019-04-09 23:34:06,494 root         INFO     Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 0.255531\n",
      "Reconstruction: 0.141492, Regularization: 0.049081, Discriminator: 0.043152; Generator: 0.021806,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 23:34:06,608 root         INFO     Train Epoch: 84 [512/8000 (6%)]\tTotal Loss: 0.326833\n",
      "Reconstruction: 0.212196, Regularization: 0.049671, Discriminator: 0.043326; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:06,721 root         INFO     Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 0.270000\n",
      "Reconstruction: 0.135460, Regularization: 0.069628, Discriminator: 0.043346; Generator: 0.021565,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-09 23:34:06,832 root         INFO     Train Epoch: 84 [1536/8000 (19%)]\tTotal Loss: 0.229530\n",
      "Reconstruction: 0.119123, Regularization: 0.045471, Discriminator: 0.043410; Generator: 0.021526,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-09 23:34:06,943 root         INFO     Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 0.315484\n",
      "Reconstruction: 0.188430, Regularization: 0.062144, Discriminator: 0.043281; Generator: 0.021628,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:34:07,053 root         INFO     Train Epoch: 84 [2560/8000 (32%)]\tTotal Loss: 0.372635\n",
      "Reconstruction: 0.243786, Regularization: 0.063864, Discriminator: 0.043468; Generator: 0.021516,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 23:34:07,165 root         INFO     Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 0.496242\n",
      "Reconstruction: 0.327690, Regularization: 0.103456, Discriminator: 0.043557; Generator: 0.021539,\n",
      "D(x): 0.498, D(G(z)): 0.502\n",
      "2019-04-09 23:34:07,274 root         INFO     Train Epoch: 84 [3584/8000 (45%)]\tTotal Loss: 0.446173\n",
      "Reconstruction: 0.287519, Regularization: 0.093610, Discriminator: 0.043363; Generator: 0.021681,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:07,383 root         INFO     Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 0.289893\n",
      "Reconstruction: 0.149023, Regularization: 0.075887, Discriminator: 0.043380; Generator: 0.021604,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:07,493 root         INFO     Train Epoch: 84 [4608/8000 (58%)]\tTotal Loss: 0.226749\n",
      "Reconstruction: 0.114889, Regularization: 0.046936, Discriminator: 0.043269; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:07,602 root         INFO     Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 0.292521\n",
      "Reconstruction: 0.127798, Regularization: 0.099714, Discriminator: 0.043308; Generator: 0.021702,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:07,711 root         INFO     Train Epoch: 84 [5632/8000 (70%)]\tTotal Loss: 0.216975\n",
      "Reconstruction: 0.116744, Regularization: 0.035187, Discriminator: 0.043405; Generator: 0.021639,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:07,820 root         INFO     Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 0.234978\n",
      "Reconstruction: 0.121129, Regularization: 0.048847, Discriminator: 0.043329; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:07,928 root         INFO     Train Epoch: 84 [6656/8000 (83%)]\tTotal Loss: 0.337202\n",
      "Reconstruction: 0.193226, Regularization: 0.078985, Discriminator: 0.043318; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:08,037 root         INFO     Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 0.306914\n",
      "Reconstruction: 0.145300, Regularization: 0.096642, Discriminator: 0.043321; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:08,146 root         INFO     Train Epoch: 84 [7680/8000 (96%)]\tTotal Loss: 1.380826\n",
      "Reconstruction: 1.193844, Regularization: 0.121998, Discriminator: 0.043314; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:08,226 root         INFO     ====> Epoch: 84 Average loss: 2.3580\n",
      "2019-04-09 23:34:08,253 root         INFO     Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 0.366636\n",
      "Reconstruction: 0.263171, Regularization: 0.038481, Discriminator: 0.043312; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:08,364 root         INFO     Train Epoch: 85 [512/8000 (6%)]\tTotal Loss: 0.236704\n",
      "Reconstruction: 0.133029, Regularization: 0.038701, Discriminator: 0.043311; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:08,474 root         INFO     Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 0.216508\n",
      "Reconstruction: 0.116728, Regularization: 0.034732, Discriminator: 0.043369; Generator: 0.021678,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:08,584 root         INFO     Train Epoch: 85 [1536/8000 (19%)]\tTotal Loss: 0.254630\n",
      "Reconstruction: 0.132891, Regularization: 0.056786, Discriminator: 0.043250; Generator: 0.021702,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:34:08,695 root         INFO     Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 1.113225\n",
      "Reconstruction: 0.944269, Regularization: 0.103966, Discriminator: 0.043229; Generator: 0.021762,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 23:34:08,805 root         INFO     Train Epoch: 85 [2560/8000 (32%)]\tTotal Loss: 0.220828\n",
      "Reconstruction: 0.109516, Regularization: 0.046340, Discriminator: 0.043262; Generator: 0.021711,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:08,915 root         INFO     Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 1.458162\n",
      "Reconstruction: 1.319693, Regularization: 0.073460, Discriminator: 0.043332; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:09,026 root         INFO     Train Epoch: 85 [3584/8000 (45%)]\tTotal Loss: 0.313409\n",
      "Reconstruction: 0.186912, Regularization: 0.061501, Discriminator: 0.043310; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:09,136 root         INFO     Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 0.275085\n",
      "Reconstruction: 0.140797, Regularization: 0.069356, Discriminator: 0.043158; Generator: 0.021775,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 23:34:09,246 root         INFO     Train Epoch: 85 [4608/8000 (58%)]\tTotal Loss: 0.292318\n",
      "Reconstruction: 0.188685, Regularization: 0.038636, Discriminator: 0.043386; Generator: 0.021612,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:09,356 root         INFO     Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 0.277743\n",
      "Reconstruction: 0.184602, Regularization: 0.028112, Discriminator: 0.043422; Generator: 0.021607,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:34:09,466 root         INFO     Train Epoch: 85 [5632/8000 (70%)]\tTotal Loss: 0.224725\n",
      "Reconstruction: 0.122880, Regularization: 0.036803, Discriminator: 0.043367; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:09,576 root         INFO     Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 0.348303\n",
      "Reconstruction: 0.232305, Regularization: 0.050938, Discriminator: 0.043438; Generator: 0.021621,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:34:09,687 root         INFO     Train Epoch: 85 [6656/8000 (83%)]\tTotal Loss: 0.352321\n",
      "Reconstruction: 0.113971, Regularization: 0.173306, Discriminator: 0.043354; Generator: 0.021689,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:09,797 root         INFO     Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 0.246902\n",
      "Reconstruction: 0.131570, Regularization: 0.050425, Discriminator: 0.043265; Generator: 0.021642,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:09,907 root         INFO     Train Epoch: 85 [7680/8000 (96%)]\tTotal Loss: 0.254552\n",
      "Reconstruction: 0.146575, Regularization: 0.043025, Discriminator: 0.043257; Generator: 0.021694,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:34:09,988 root         INFO     ====> Epoch: 85 Average loss: 10025.6748\n",
      "2019-04-09 23:34:10,015 root         INFO     Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 0.201007\n",
      "Reconstruction: 0.109255, Regularization: 0.026732, Discriminator: 0.043351; Generator: 0.021669,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:10,127 root         INFO     Train Epoch: 86 [512/8000 (6%)]\tTotal Loss: 0.270321\n",
      "Reconstruction: 0.129465, Regularization: 0.075948, Discriminator: 0.043301; Generator: 0.021607,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:34:10,237 root         INFO     Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 0.315554\n",
      "Reconstruction: 0.136023, Regularization: 0.114584, Discriminator: 0.043346; Generator: 0.021601,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:34:10,348 root         INFO     Train Epoch: 86 [1536/8000 (19%)]\tTotal Loss: 42.339252\n",
      "Reconstruction: 41.911472, Regularization: 0.362886, Discriminator: 0.043218; Generator: 0.021677,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:10,458 root         INFO     Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 0.270505\n",
      "Reconstruction: 0.143307, Regularization: 0.062214, Discriminator: 0.043414; Generator: 0.021570,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:10,567 root         INFO     Train Epoch: 86 [2560/8000 (32%)]\tTotal Loss: 0.549913\n",
      "Reconstruction: 0.424483, Regularization: 0.060399, Discriminator: 0.043374; Generator: 0.021657,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:10,677 root         INFO     Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 0.406342\n",
      "Reconstruction: 0.283478, Regularization: 0.057864, Discriminator: 0.043341; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:10,786 root         INFO     Train Epoch: 86 [3584/8000 (45%)]\tTotal Loss: 0.290583\n",
      "Reconstruction: 0.120372, Regularization: 0.105226, Discriminator: 0.043341; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:10,895 root         INFO     Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 0.467363\n",
      "Reconstruction: 0.308193, Regularization: 0.094242, Discriminator: 0.043275; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:11,005 root         INFO     Train Epoch: 86 [4608/8000 (58%)]\tTotal Loss: 0.210757\n",
      "Reconstruction: 0.098722, Regularization: 0.047086, Discriminator: 0.043305; Generator: 0.021644,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:11,114 root         INFO     Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 0.674720\n",
      "Reconstruction: 0.520885, Regularization: 0.088857, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:11,224 root         INFO     Train Epoch: 86 [5632/8000 (70%)]\tTotal Loss: 0.331662\n",
      "Reconstruction: 0.223395, Regularization: 0.043281, Discriminator: 0.043354; Generator: 0.021631,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:11,334 root         INFO     Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 1.105903\n",
      "Reconstruction: 1.000417, Regularization: 0.040530, Discriminator: 0.043306; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:11,444 root         INFO     Train Epoch: 86 [6656/8000 (83%)]\tTotal Loss: 0.251823\n",
      "Reconstruction: 0.154276, Regularization: 0.032633, Discriminator: 0.043271; Generator: 0.021642,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:11,555 root         INFO     Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 0.297135\n",
      "Reconstruction: 0.183594, Regularization: 0.048554, Discriminator: 0.043319; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:11,665 root         INFO     Train Epoch: 86 [7680/8000 (96%)]\tTotal Loss: 72.191422\n",
      "Reconstruction: 71.864815, Regularization: 0.261593, Discriminator: 0.043359; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:11,746 root         INFO     ====> Epoch: 86 Average loss: 11.3518\n",
      "2019-04-09 23:34:11,773 root         INFO     Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 1.022217\n",
      "Reconstruction: 0.900151, Regularization: 0.057064, Discriminator: 0.043250; Generator: 0.021751,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:11,882 root         INFO     Train Epoch: 87 [512/8000 (6%)]\tTotal Loss: 0.394130\n",
      "Reconstruction: 0.250876, Regularization: 0.078298, Discriminator: 0.043335; Generator: 0.021621,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:11,990 root         INFO     Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 0.902934\n",
      "Reconstruction: 0.779130, Regularization: 0.058828, Discriminator: 0.043385; Generator: 0.021590,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:12,098 root         INFO     Train Epoch: 87 [1536/8000 (19%)]\tTotal Loss: 0.535825\n",
      "Reconstruction: 0.402461, Regularization: 0.068274, Discriminator: 0.043403; Generator: 0.021687,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:34:12,207 root         INFO     Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 0.261105\n",
      "Reconstruction: 0.163626, Regularization: 0.032426, Discriminator: 0.043464; Generator: 0.021589,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:34:12,314 root         INFO     Train Epoch: 87 [2560/8000 (32%)]\tTotal Loss: 0.421790\n",
      "Reconstruction: 0.296409, Regularization: 0.060422, Discriminator: 0.043289; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:12,423 root         INFO     Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 0.323437\n",
      "Reconstruction: 0.221569, Regularization: 0.036903, Discriminator: 0.043344; Generator: 0.021622,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:12,532 root         INFO     Train Epoch: 87 [3584/8000 (45%)]\tTotal Loss: 0.272425\n",
      "Reconstruction: 0.160726, Regularization: 0.046761, Discriminator: 0.043347; Generator: 0.021592,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:34:12,641 root         INFO     Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 0.457251\n",
      "Reconstruction: 0.346160, Regularization: 0.046050, Discriminator: 0.043413; Generator: 0.021628,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:34:12,749 root         INFO     Train Epoch: 87 [4608/8000 (58%)]\tTotal Loss: 0.487464\n",
      "Reconstruction: 0.359813, Regularization: 0.062675, Discriminator: 0.043248; Generator: 0.021728,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:12,857 root         INFO     Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 0.245860\n",
      "Reconstruction: 0.120623, Regularization: 0.060247, Discriminator: 0.043418; Generator: 0.021573,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:12,965 root         INFO     Train Epoch: 87 [5632/8000 (70%)]\tTotal Loss: 0.418854\n",
      "Reconstruction: 0.227706, Regularization: 0.126091, Discriminator: 0.043435; Generator: 0.021623,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:34:13,074 root         INFO     Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 0.998361\n",
      "Reconstruction: 0.875467, Regularization: 0.057897, Discriminator: 0.043342; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:13,183 root         INFO     Train Epoch: 87 [6656/8000 (83%)]\tTotal Loss: 0.569776\n",
      "Reconstruction: 0.379834, Regularization: 0.124924, Discriminator: 0.043329; Generator: 0.021689,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:13,294 root         INFO     Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 0.391583\n",
      "Reconstruction: 0.218970, Regularization: 0.107625, Discriminator: 0.043327; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:13,406 root         INFO     Train Epoch: 87 [7680/8000 (96%)]\tTotal Loss: 0.504883\n",
      "Reconstruction: 0.335374, Regularization: 0.104503, Discriminator: 0.043337; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:13,487 root         INFO     ====> Epoch: 87 Average loss: 28.1152\n",
      "2019-04-09 23:34:13,515 root         INFO     Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 2.108612\n",
      "Reconstruction: 1.973903, Regularization: 0.069712, Discriminator: 0.043327; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:13,626 root         INFO     Train Epoch: 88 [512/8000 (6%)]\tTotal Loss: 0.240029\n",
      "Reconstruction: 0.140208, Regularization: 0.034830, Discriminator: 0.043327; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:13,737 root         INFO     Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 0.549911\n",
      "Reconstruction: 0.411799, Regularization: 0.073142, Discriminator: 0.043319; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:13,848 root         INFO     Train Epoch: 88 [1536/8000 (19%)]\tTotal Loss: 0.411600\n",
      "Reconstruction: 0.204167, Regularization: 0.142482, Discriminator: 0.043293; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:13,957 root         INFO     Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 0.316337\n",
      "Reconstruction: 0.181321, Regularization: 0.070042, Discriminator: 0.043290; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:14,068 root         INFO     Train Epoch: 88 [2560/8000 (32%)]\tTotal Loss: 0.219602\n",
      "Reconstruction: 0.112862, Regularization: 0.041754, Discriminator: 0.043284; Generator: 0.021702,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:14,175 root         INFO     Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 0.331901\n",
      "Reconstruction: 0.171614, Regularization: 0.095311, Discriminator: 0.043374; Generator: 0.021602,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:14,281 root         INFO     Train Epoch: 88 [3584/8000 (45%)]\tTotal Loss: 0.324065\n",
      "Reconstruction: 0.211360, Regularization: 0.047756, Discriminator: 0.043226; Generator: 0.021723,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:34:14,388 root         INFO     Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 0.286557\n",
      "Reconstruction: 0.186550, Regularization: 0.035001, Discriminator: 0.043356; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:14,494 root         INFO     Train Epoch: 88 [4608/8000 (58%)]\tTotal Loss: 3.780260\n",
      "Reconstruction: 3.635932, Regularization: 0.079375, Discriminator: 0.043228; Generator: 0.021725,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:34:14,601 root         INFO     Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 1.246307\n",
      "Reconstruction: 1.115421, Regularization: 0.065920, Discriminator: 0.043330; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:14,708 root         INFO     Train Epoch: 88 [5632/8000 (70%)]\tTotal Loss: 0.308692\n",
      "Reconstruction: 0.170631, Regularization: 0.073012, Discriminator: 0.043347; Generator: 0.021703,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:34:14,815 root         INFO     Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 0.380986\n",
      "Reconstruction: 0.266475, Regularization: 0.049532, Discriminator: 0.043307; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:14,922 root         INFO     Train Epoch: 88 [6656/8000 (83%)]\tTotal Loss: 0.285943\n",
      "Reconstruction: 0.155939, Regularization: 0.065070, Discriminator: 0.043289; Generator: 0.021645,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:15,029 root         INFO     Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 8509.600586\n",
      "Reconstruction: 8509.284180, Regularization: 0.251345, Discriminator: 0.043324; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:15,135 root         INFO     Train Epoch: 88 [7680/8000 (96%)]\tTotal Loss: 0.267751\n",
      "Reconstruction: 0.166454, Regularization: 0.036345, Discriminator: 0.043259; Generator: 0.021693,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:34:15,214 root         INFO     ====> Epoch: 88 Average loss: 31511.3474\n",
      "2019-04-09 23:34:15,242 root         INFO     Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 0.419451\n",
      "Reconstruction: 0.291368, Regularization: 0.063138, Discriminator: 0.043322; Generator: 0.021622,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:34:15,351 root         INFO     Train Epoch: 89 [512/8000 (6%)]\tTotal Loss: 0.514949\n",
      "Reconstruction: 0.403996, Regularization: 0.046004, Discriminator: 0.043238; Generator: 0.021711,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:34:15,460 root         INFO     Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 0.294761\n",
      "Reconstruction: 0.161333, Regularization: 0.068487, Discriminator: 0.043302; Generator: 0.021638,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:15,569 root         INFO     Train Epoch: 89 [1536/8000 (19%)]\tTotal Loss: 0.287163\n",
      "Reconstruction: 0.171516, Regularization: 0.050704, Discriminator: 0.043274; Generator: 0.021670,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:15,678 root         INFO     Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 0.209586\n",
      "Reconstruction: 0.103218, Regularization: 0.041404, Discriminator: 0.043350; Generator: 0.021614,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:15,787 root         INFO     Train Epoch: 89 [2560/8000 (32%)]\tTotal Loss: 0.247482\n",
      "Reconstruction: 0.107537, Regularization: 0.074944, Discriminator: 0.043347; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:15,896 root         INFO     Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 0.322916\n",
      "Reconstruction: 0.213039, Regularization: 0.044876, Discriminator: 0.043334; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:16,005 root         INFO     Train Epoch: 89 [3584/8000 (45%)]\tTotal Loss: 0.225447\n",
      "Reconstruction: 0.111069, Regularization: 0.049381, Discriminator: 0.043342; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:16,114 root         INFO     Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 0.256475\n",
      "Reconstruction: 0.147970, Regularization: 0.043526, Discriminator: 0.043328; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:16,223 root         INFO     Train Epoch: 89 [4608/8000 (58%)]\tTotal Loss: 12.002316\n",
      "Reconstruction: 11.859749, Regularization: 0.077552, Discriminator: 0.043356; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:16,332 root         INFO     Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 0.251359\n",
      "Reconstruction: 0.125845, Regularization: 0.060580, Discriminator: 0.043294; Generator: 0.021640,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:16,440 root         INFO     Train Epoch: 89 [5632/8000 (70%)]\tTotal Loss: 0.794501\n",
      "Reconstruction: 0.660890, Regularization: 0.068710, Discriminator: 0.043241; Generator: 0.021660,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:16,549 root         INFO     Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 0.923772\n",
      "Reconstruction: 0.825655, Regularization: 0.033088, Discriminator: 0.043376; Generator: 0.021652,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:16,658 root         INFO     Train Epoch: 89 [6656/8000 (83%)]\tTotal Loss: 0.219520\n",
      "Reconstruction: 0.125255, Regularization: 0.029330, Discriminator: 0.043302; Generator: 0.021633,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:16,767 root         INFO     Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 2.913571\n",
      "Reconstruction: 2.760857, Regularization: 0.087700, Discriminator: 0.043349; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:16,877 root         INFO     Train Epoch: 89 [7680/8000 (96%)]\tTotal Loss: 101.790970\n",
      "Reconstruction: 101.531609, Regularization: 0.194391, Discriminator: 0.043369; Generator: 0.021604,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:16,956 root         INFO     ====> Epoch: 89 Average loss: 98317.3932\n",
      "2019-04-09 23:34:16,984 root         INFO     Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 1.775286\n",
      "Reconstruction: 1.621875, Regularization: 0.088425, Discriminator: 0.043328; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:17,093 root         INFO     Train Epoch: 90 [512/8000 (6%)]\tTotal Loss: 0.229480\n",
      "Reconstruction: 0.127677, Regularization: 0.036855, Discriminator: 0.043312; Generator: 0.021636,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:17,203 root         INFO     Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 0.292484\n",
      "Reconstruction: 0.165330, Regularization: 0.062118, Discriminator: 0.043389; Generator: 0.021647,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:17,313 root         INFO     Train Epoch: 90 [1536/8000 (19%)]\tTotal Loss: 0.283589\n",
      "Reconstruction: 0.144861, Regularization: 0.073750, Discriminator: 0.043342; Generator: 0.021635,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:17,422 root         INFO     Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 0.426711\n",
      "Reconstruction: 0.270317, Regularization: 0.091411, Discriminator: 0.043328; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:17,534 root         INFO     Train Epoch: 90 [2560/8000 (32%)]\tTotal Loss: 0.197344\n",
      "Reconstruction: 0.098748, Regularization: 0.033643, Discriminator: 0.043272; Generator: 0.021681,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:17,647 root         INFO     Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 0.284827\n",
      "Reconstruction: 0.173681, Regularization: 0.046203, Discriminator: 0.043316; Generator: 0.021628,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:34:17,759 root         INFO     Train Epoch: 90 [3584/8000 (45%)]\tTotal Loss: 24.721970\n",
      "Reconstruction: 24.514137, Regularization: 0.142801, Discriminator: 0.043406; Generator: 0.021625,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:34:17,870 root         INFO     Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 0.532676\n",
      "Reconstruction: 0.410498, Regularization: 0.057169, Discriminator: 0.043352; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:17,982 root         INFO     Train Epoch: 90 [4608/8000 (58%)]\tTotal Loss: 0.249773\n",
      "Reconstruction: 0.136778, Regularization: 0.048018, Discriminator: 0.043318; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:18,094 root         INFO     Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 0.975236\n",
      "Reconstruction: 0.846988, Regularization: 0.063271, Discriminator: 0.043281; Generator: 0.021697,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:18,204 root         INFO     Train Epoch: 90 [5632/8000 (70%)]\tTotal Loss: 0.215799\n",
      "Reconstruction: 0.110701, Regularization: 0.040092, Discriminator: 0.043339; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:18,316 root         INFO     Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 0.267933\n",
      "Reconstruction: 0.136736, Regularization: 0.066212, Discriminator: 0.043358; Generator: 0.021627,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:18,428 root         INFO     Train Epoch: 90 [6656/8000 (83%)]\tTotal Loss: 0.223974\n",
      "Reconstruction: 0.128684, Regularization: 0.030328, Discriminator: 0.043301; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:18,539 root         INFO     Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 0.269940\n",
      "Reconstruction: 0.138465, Regularization: 0.066485, Discriminator: 0.043314; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:18,651 root         INFO     Train Epoch: 90 [7680/8000 (96%)]\tTotal Loss: 1.553448\n",
      "Reconstruction: 1.398957, Regularization: 0.089498, Discriminator: 0.043344; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:18,733 root         INFO     ====> Epoch: 90 Average loss: 25.5916\n",
      "2019-04-09 23:34:18,761 root         INFO     Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 0.358464\n",
      "Reconstruction: 0.222944, Regularization: 0.070549, Discriminator: 0.043315; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:18,874 root         INFO     Train Epoch: 91 [512/8000 (6%)]\tTotal Loss: 0.232926\n",
      "Reconstruction: 0.129406, Regularization: 0.038534, Discriminator: 0.043349; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:18,988 root         INFO     Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 0.262961\n",
      "Reconstruction: 0.157845, Regularization: 0.040133, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:19,101 root         INFO     Train Epoch: 91 [1536/8000 (19%)]\tTotal Loss: 0.279060\n",
      "Reconstruction: 0.144317, Regularization: 0.069739, Discriminator: 0.043323; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:19,214 root         INFO     Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 0.590053\n",
      "Reconstruction: 0.468891, Regularization: 0.056170, Discriminator: 0.043323; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:19,325 root         INFO     Train Epoch: 91 [2560/8000 (32%)]\tTotal Loss: 0.296474\n",
      "Reconstruction: 0.183906, Regularization: 0.047568, Discriminator: 0.043339; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:19,435 root         INFO     Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 13.380252\n",
      "Reconstruction: 13.013544, Regularization: 0.301716, Discriminator: 0.043316; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:19,546 root         INFO     Train Epoch: 91 [3584/8000 (45%)]\tTotal Loss: 8.200215\n",
      "Reconstruction: 7.959013, Regularization: 0.176281, Discriminator: 0.043252; Generator: 0.021669,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:19,657 root         INFO     Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 0.213808\n",
      "Reconstruction: 0.104783, Regularization: 0.043986, Discriminator: 0.043345; Generator: 0.021694,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:34:19,767 root         INFO     Train Epoch: 91 [4608/8000 (58%)]\tTotal Loss: 0.294801\n",
      "Reconstruction: 0.141474, Regularization: 0.088369, Discriminator: 0.043287; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:19,876 root         INFO     Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 0.386558\n",
      "Reconstruction: 0.263710, Regularization: 0.057890, Discriminator: 0.043261; Generator: 0.021697,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:19,989 root         INFO     Train Epoch: 91 [5632/8000 (70%)]\tTotal Loss: 0.332294\n",
      "Reconstruction: 0.227731, Regularization: 0.039631, Discriminator: 0.043242; Generator: 0.021689,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:20,101 root         INFO     Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 0.247129\n",
      "Reconstruction: 0.124305, Regularization: 0.057793, Discriminator: 0.043312; Generator: 0.021719,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:34:20,213 root         INFO     Train Epoch: 91 [6656/8000 (83%)]\tTotal Loss: 0.250753\n",
      "Reconstruction: 0.145933, Regularization: 0.039786, Discriminator: 0.043353; Generator: 0.021681,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:20,325 root         INFO     Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 1.679374\n",
      "Reconstruction: 1.519637, Regularization: 0.094804, Discriminator: 0.043244; Generator: 0.021690,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:20,438 root         INFO     Train Epoch: 91 [7680/8000 (96%)]\tTotal Loss: 0.961784\n",
      "Reconstruction: 0.548342, Regularization: 0.348476, Discriminator: 0.043285; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:20,518 root         INFO     ====> Epoch: 91 Average loss: 8808654.2859\n",
      "2019-04-09 23:34:20,545 root         INFO     Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 0.271913\n",
      "Reconstruction: 0.140776, Regularization: 0.066171, Discriminator: 0.043273; Generator: 0.021693,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:20,657 root         INFO     Train Epoch: 92 [512/8000 (6%)]\tTotal Loss: 0.324620\n",
      "Reconstruction: 0.186851, Regularization: 0.072825, Discriminator: 0.043299; Generator: 0.021646,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:20,768 root         INFO     Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 0.232284\n",
      "Reconstruction: 0.129332, Regularization: 0.037964, Discriminator: 0.043344; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:20,880 root         INFO     Train Epoch: 92 [1536/8000 (19%)]\tTotal Loss: 0.290467\n",
      "Reconstruction: 0.131930, Regularization: 0.093507, Discriminator: 0.043407; Generator: 0.021622,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:34:20,991 root         INFO     Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 1015.921021\n",
      "Reconstruction: 1015.561707, Regularization: 0.294342, Discriminator: 0.043318; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:21,102 root         INFO     Train Epoch: 92 [2560/8000 (32%)]\tTotal Loss: 3.422623\n",
      "Reconstruction: 3.233400, Regularization: 0.124291, Discriminator: 0.043283; Generator: 0.021648,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:21,213 root         INFO     Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 0.210884\n",
      "Reconstruction: 0.109312, Regularization: 0.036581, Discriminator: 0.043343; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:21,324 root         INFO     Train Epoch: 92 [3584/8000 (45%)]\tTotal Loss: 0.255272\n",
      "Reconstruction: 0.109033, Regularization: 0.081247, Discriminator: 0.043334; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:21,435 root         INFO     Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 0.362672\n",
      "Reconstruction: 0.210884, Regularization: 0.086869, Discriminator: 0.043247; Generator: 0.021671,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:21,547 root         INFO     Train Epoch: 92 [4608/8000 (58%)]\tTotal Loss: 0.243502\n",
      "Reconstruction: 0.127540, Regularization: 0.050971, Discriminator: 0.043321; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:21,660 root         INFO     Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 0.281248\n",
      "Reconstruction: 0.159817, Regularization: 0.056482, Discriminator: 0.043279; Generator: 0.021670,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:21,772 root         INFO     Train Epoch: 92 [5632/8000 (70%)]\tTotal Loss: 0.280821\n",
      "Reconstruction: 0.151277, Regularization: 0.064550, Discriminator: 0.043315; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:21,882 root         INFO     Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 0.253359\n",
      "Reconstruction: 0.154784, Regularization: 0.033584, Discriminator: 0.043321; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:21,991 root         INFO     Train Epoch: 92 [6656/8000 (83%)]\tTotal Loss: 0.220953\n",
      "Reconstruction: 0.112065, Regularization: 0.043905, Discriminator: 0.043352; Generator: 0.021631,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:22,101 root         INFO     Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 0.263376\n",
      "Reconstruction: 0.146762, Regularization: 0.051644, Discriminator: 0.043222; Generator: 0.021749,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:22,210 root         INFO     Train Epoch: 92 [7680/8000 (96%)]\tTotal Loss: 0.570116\n",
      "Reconstruction: 0.369580, Regularization: 0.135516, Discriminator: 0.043370; Generator: 0.021650,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:22,290 root         INFO     ====> Epoch: 92 Average loss: 70715.1889\n",
      "2019-04-09 23:34:22,318 root         INFO     Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 0.293813\n",
      "Reconstruction: 0.157643, Regularization: 0.071180, Discriminator: 0.043239; Generator: 0.021752,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:22,430 root         INFO     Train Epoch: 93 [512/8000 (6%)]\tTotal Loss: 0.285472\n",
      "Reconstruction: 0.185643, Regularization: 0.034861, Discriminator: 0.043316; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:22,541 root         INFO     Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 0.375258\n",
      "Reconstruction: 0.233844, Regularization: 0.076396, Discriminator: 0.043328; Generator: 0.021691,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:22,653 root         INFO     Train Epoch: 93 [1536/8000 (19%)]\tTotal Loss: 0.672646\n",
      "Reconstruction: 0.522744, Regularization: 0.084923, Discriminator: 0.043273; Generator: 0.021706,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:22,765 root         INFO     Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 27817.355469\n",
      "Reconstruction: 27817.222656, Regularization: 0.068539, Discriminator: 0.043358; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:22,874 root         INFO     Train Epoch: 93 [2560/8000 (32%)]\tTotal Loss: 0.640269\n",
      "Reconstruction: 0.518766, Regularization: 0.056569, Discriminator: 0.043326; Generator: 0.021608,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:34:22,984 root         INFO     Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 0.204148\n",
      "Reconstruction: 0.106069, Regularization: 0.033086, Discriminator: 0.043321; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:23,093 root         INFO     Train Epoch: 93 [3584/8000 (45%)]\tTotal Loss: 1.406354\n",
      "Reconstruction: 1.291996, Regularization: 0.049347, Discriminator: 0.043386; Generator: 0.021626,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:23,203 root         INFO     Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 0.245017\n",
      "Reconstruction: 0.131622, Regularization: 0.048346, Discriminator: 0.043294; Generator: 0.021754,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:34:23,313 root         INFO     Train Epoch: 93 [4608/8000 (58%)]\tTotal Loss: 0.207664\n",
      "Reconstruction: 0.112849, Regularization: 0.029835, Discriminator: 0.043372; Generator: 0.021608,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:23,422 root         INFO     Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 0.544396\n",
      "Reconstruction: 0.402244, Regularization: 0.077120, Discriminator: 0.043385; Generator: 0.021647,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:23,532 root         INFO     Train Epoch: 93 [5632/8000 (70%)]\tTotal Loss: 0.277974\n",
      "Reconstruction: 0.169254, Regularization: 0.043718, Discriminator: 0.043356; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:23,641 root         INFO     Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 0.258074\n",
      "Reconstruction: 0.135484, Regularization: 0.057595, Discriminator: 0.043348; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:23,749 root         INFO     Train Epoch: 93 [6656/8000 (83%)]\tTotal Loss: 39496516.000000\n",
      "Reconstruction: 39496516.000000, Regularization: 0.250797, Discriminator: 0.043327; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:23,858 root         INFO     Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 0.246018\n",
      "Reconstruction: 0.140648, Regularization: 0.040384, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:23,966 root         INFO     Train Epoch: 93 [7680/8000 (96%)]\tTotal Loss: 0.402148\n",
      "Reconstruction: 0.271228, Regularization: 0.065948, Discriminator: 0.043291; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:24,046 root         INFO     ====> Epoch: 93 Average loss: 158134.7690\n",
      "2019-04-09 23:34:24,073 root         INFO     Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 0.259791\n",
      "Reconstruction: 0.156505, Regularization: 0.038306, Discriminator: 0.043307; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:24,184 root         INFO     Train Epoch: 94 [512/8000 (6%)]\tTotal Loss: 0.249154\n",
      "Reconstruction: 0.142847, Regularization: 0.041322, Discriminator: 0.043320; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:24,294 root         INFO     Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 0.409012\n",
      "Reconstruction: 0.202570, Regularization: 0.141453, Discriminator: 0.043304; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:24,405 root         INFO     Train Epoch: 94 [1536/8000 (19%)]\tTotal Loss: 0.910010\n",
      "Reconstruction: 0.775526, Regularization: 0.069510, Discriminator: 0.043336; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:24,517 root         INFO     Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 4.732532\n",
      "Reconstruction: 4.485395, Regularization: 0.182187, Discriminator: 0.043269; Generator: 0.021681,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:24,629 root         INFO     Train Epoch: 94 [2560/8000 (32%)]\tTotal Loss: 0.258096\n",
      "Reconstruction: 0.134712, Regularization: 0.058385, Discriminator: 0.043338; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:24,740 root         INFO     Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 0.342593\n",
      "Reconstruction: 0.210630, Regularization: 0.066941, Discriminator: 0.043361; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:24,852 root         INFO     Train Epoch: 94 [3584/8000 (45%)]\tTotal Loss: 0.495210\n",
      "Reconstruction: 0.366686, Regularization: 0.063564, Discriminator: 0.043322; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:24,963 root         INFO     Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 0.346703\n",
      "Reconstruction: 0.223560, Regularization: 0.058177, Discriminator: 0.043318; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:25,074 root         INFO     Train Epoch: 94 [4608/8000 (58%)]\tTotal Loss: 0.581176\n",
      "Reconstruction: 0.323560, Regularization: 0.192689, Discriminator: 0.043273; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:25,185 root         INFO     Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 0.318121\n",
      "Reconstruction: 0.186541, Regularization: 0.066582, Discriminator: 0.043387; Generator: 0.021611,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:25,296 root         INFO     Train Epoch: 94 [5632/8000 (70%)]\tTotal Loss: 0.258431\n",
      "Reconstruction: 0.128082, Regularization: 0.065378, Discriminator: 0.043305; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:25,406 root         INFO     Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 0.230200\n",
      "Reconstruction: 0.132550, Regularization: 0.032672, Discriminator: 0.043289; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:25,519 root         INFO     Train Epoch: 94 [6656/8000 (83%)]\tTotal Loss: 0.385071\n",
      "Reconstruction: 0.250608, Regularization: 0.069476, Discriminator: 0.043333; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:25,631 root         INFO     Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 0.256788\n",
      "Reconstruction: 0.121665, Regularization: 0.070086, Discriminator: 0.043330; Generator: 0.021707,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:34:25,741 root         INFO     Train Epoch: 94 [7680/8000 (96%)]\tTotal Loss: 0.272479\n",
      "Reconstruction: 0.163819, Regularization: 0.043678, Discriminator: 0.043218; Generator: 0.021764,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 23:34:25,821 root         INFO     ====> Epoch: 94 Average loss: 2287.4217\n",
      "2019-04-09 23:34:25,848 root         INFO     Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 0.411173\n",
      "Reconstruction: 0.272999, Regularization: 0.073246, Discriminator: 0.043227; Generator: 0.021701,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:34:25,959 root         INFO     Train Epoch: 95 [512/8000 (6%)]\tTotal Loss: 0.228397\n",
      "Reconstruction: 0.102505, Regularization: 0.060893, Discriminator: 0.043400; Generator: 0.021599,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:26,069 root         INFO     Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 0.442314\n",
      "Reconstruction: 0.317442, Regularization: 0.059880, Discriminator: 0.043372; Generator: 0.021620,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:26,179 root         INFO     Train Epoch: 95 [1536/8000 (19%)]\tTotal Loss: 0.219357\n",
      "Reconstruction: 0.123188, Regularization: 0.031191, Discriminator: 0.043307; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:26,289 root         INFO     Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 0.421741\n",
      "Reconstruction: 0.266919, Regularization: 0.089887, Discriminator: 0.043262; Generator: 0.021673,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:26,399 root         INFO     Train Epoch: 95 [2560/8000 (32%)]\tTotal Loss: 0.390080\n",
      "Reconstruction: 0.276742, Regularization: 0.048370, Discriminator: 0.043302; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:26,510 root         INFO     Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 0.215637\n",
      "Reconstruction: 0.111627, Regularization: 0.039039, Discriminator: 0.043313; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:26,622 root         INFO     Train Epoch: 95 [3584/8000 (45%)]\tTotal Loss: 0.229748\n",
      "Reconstruction: 0.113119, Regularization: 0.051625, Discriminator: 0.043350; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:26,734 root         INFO     Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 0.299716\n",
      "Reconstruction: 0.163324, Regularization: 0.071432, Discriminator: 0.043305; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:26,847 root         INFO     Train Epoch: 95 [4608/8000 (58%)]\tTotal Loss: 0.353879\n",
      "Reconstruction: 0.247128, Regularization: 0.041799, Discriminator: 0.043306; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:26,959 root         INFO     Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 0.224318\n",
      "Reconstruction: 0.131199, Regularization: 0.028144, Discriminator: 0.043310; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:27,071 root         INFO     Train Epoch: 95 [5632/8000 (70%)]\tTotal Loss: 0.350519\n",
      "Reconstruction: 0.239256, Regularization: 0.046320, Discriminator: 0.043287; Generator: 0.021656,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:27,183 root         INFO     Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 0.248222\n",
      "Reconstruction: 0.141492, Regularization: 0.041783, Discriminator: 0.043329; Generator: 0.021617,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:34:27,293 root         INFO     Train Epoch: 95 [6656/8000 (83%)]\tTotal Loss: 0.257801\n",
      "Reconstruction: 0.156311, Regularization: 0.036522, Discriminator: 0.043313; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:27,404 root         INFO     Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 0.265847\n",
      "Reconstruction: 0.161316, Regularization: 0.039550, Discriminator: 0.043385; Generator: 0.021595,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:27,515 root         INFO     Train Epoch: 95 [7680/8000 (96%)]\tTotal Loss: 0.202716\n",
      "Reconstruction: 0.105583, Regularization: 0.032147, Discriminator: 0.043318; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:27,596 root         INFO     ====> Epoch: 95 Average loss: 3.7310\n",
      "2019-04-09 23:34:27,623 root         INFO     Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 0.363221\n",
      "Reconstruction: 0.238051, Regularization: 0.060154, Discriminator: 0.043388; Generator: 0.021628,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:34:27,736 root         INFO     Train Epoch: 96 [512/8000 (6%)]\tTotal Loss: 0.304711\n",
      "Reconstruction: 0.194126, Regularization: 0.045592, Discriminator: 0.043353; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:27,849 root         INFO     Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 0.247019\n",
      "Reconstruction: 0.137601, Regularization: 0.044438, Discriminator: 0.043312; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:27,961 root         INFO     Train Epoch: 96 [1536/8000 (19%)]\tTotal Loss: 0.255296\n",
      "Reconstruction: 0.116060, Regularization: 0.074272, Discriminator: 0.043287; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:28,071 root         INFO     Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 0.967886\n",
      "Reconstruction: 0.764302, Regularization: 0.138600, Discriminator: 0.043303; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:28,181 root         INFO     Train Epoch: 96 [2560/8000 (32%)]\tTotal Loss: 0.651365\n",
      "Reconstruction: 0.507852, Regularization: 0.078543, Discriminator: 0.043325; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:28,291 root         INFO     Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 0.228153\n",
      "Reconstruction: 0.133482, Regularization: 0.029709, Discriminator: 0.043294; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:28,401 root         INFO     Train Epoch: 96 [3584/8000 (45%)]\tTotal Loss: 0.467439\n",
      "Reconstruction: 0.327296, Regularization: 0.075145, Discriminator: 0.043347; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:28,511 root         INFO     Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 0.520549\n",
      "Reconstruction: 0.407319, Regularization: 0.048222, Discriminator: 0.043337; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:28,620 root         INFO     Train Epoch: 96 [4608/8000 (58%)]\tTotal Loss: 0.501494\n",
      "Reconstruction: 0.319951, Regularization: 0.116561, Discriminator: 0.043316; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:28,729 root         INFO     Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 4.571792\n",
      "Reconstruction: 4.416629, Regularization: 0.090194, Discriminator: 0.043302; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:28,838 root         INFO     Train Epoch: 96 [5632/8000 (70%)]\tTotal Loss: 0.218105\n",
      "Reconstruction: 0.112154, Regularization: 0.040949, Discriminator: 0.043328; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:28,950 root         INFO     Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 0.249792\n",
      "Reconstruction: 0.131550, Regularization: 0.053237, Discriminator: 0.043340; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:29,062 root         INFO     Train Epoch: 96 [6656/8000 (83%)]\tTotal Loss: 0.314624\n",
      "Reconstruction: 0.193233, Regularization: 0.056409, Discriminator: 0.043294; Generator: 0.021688,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:29,173 root         INFO     Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 0.204137\n",
      "Reconstruction: 0.106884, Regularization: 0.032271, Discriminator: 0.043298; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:29,285 root         INFO     Train Epoch: 96 [7680/8000 (96%)]\tTotal Loss: 0.740149\n",
      "Reconstruction: 0.562516, Regularization: 0.112672, Discriminator: 0.043314; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:29,367 root         INFO     ====> Epoch: 96 Average loss: 2251.9960\n",
      "2019-04-09 23:34:29,394 root         INFO     Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 0.232154\n",
      "Reconstruction: 0.128829, Regularization: 0.038349, Discriminator: 0.043286; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:29,508 root         INFO     Train Epoch: 97 [512/8000 (6%)]\tTotal Loss: 0.305594\n",
      "Reconstruction: 0.198073, Regularization: 0.042519, Discriminator: 0.043343; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:29,621 root         INFO     Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 0.259386\n",
      "Reconstruction: 0.140573, Regularization: 0.053850, Discriminator: 0.043277; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:29,734 root         INFO     Train Epoch: 97 [1536/8000 (19%)]\tTotal Loss: 0.304294\n",
      "Reconstruction: 0.169833, Regularization: 0.069422, Discriminator: 0.043384; Generator: 0.021654,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:29,845 root         INFO     Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 0.205913\n",
      "Reconstruction: 0.106720, Regularization: 0.034172, Discriminator: 0.043354; Generator: 0.021666,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:29,954 root         INFO     Train Epoch: 97 [2560/8000 (32%)]\tTotal Loss: 0.259405\n",
      "Reconstruction: 0.130583, Regularization: 0.063851, Discriminator: 0.043311; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:30,063 root         INFO     Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 0.231233\n",
      "Reconstruction: 0.108865, Regularization: 0.057402, Discriminator: 0.043303; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:30,172 root         INFO     Train Epoch: 97 [3584/8000 (45%)]\tTotal Loss: 0.281058\n",
      "Reconstruction: 0.158926, Regularization: 0.057119, Discriminator: 0.043367; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:30,282 root         INFO     Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 0.283763\n",
      "Reconstruction: 0.154117, Regularization: 0.064641, Discriminator: 0.043337; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:30,391 root         INFO     Train Epoch: 97 [4608/8000 (58%)]\tTotal Loss: 0.376111\n",
      "Reconstruction: 0.245524, Regularization: 0.065618, Discriminator: 0.043319; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:30,501 root         INFO     Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 0.301866\n",
      "Reconstruction: 0.158280, Regularization: 0.078601, Discriminator: 0.043328; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:30,611 root         INFO     Train Epoch: 97 [5632/8000 (70%)]\tTotal Loss: 0.437382\n",
      "Reconstruction: 0.329937, Regularization: 0.042467, Discriminator: 0.043320; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:30,721 root         INFO     Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 0.357896\n",
      "Reconstruction: 0.185346, Regularization: 0.107584, Discriminator: 0.043298; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:30,831 root         INFO     Train Epoch: 97 [6656/8000 (83%)]\tTotal Loss: 0.371823\n",
      "Reconstruction: 0.239098, Regularization: 0.067748, Discriminator: 0.043301; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:30,940 root         INFO     Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 52.714508\n",
      "Reconstruction: 52.562042, Regularization: 0.087473, Discriminator: 0.043309; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:31,050 root         INFO     Train Epoch: 97 [7680/8000 (96%)]\tTotal Loss: 1.378099\n",
      "Reconstruction: 1.248724, Regularization: 0.064360, Discriminator: 0.043384; Generator: 0.021631,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:31,131 root         INFO     ====> Epoch: 97 Average loss: 485.4876\n",
      "2019-04-09 23:34:31,158 root         INFO     Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 6.911188\n",
      "Reconstruction: 6.720398, Regularization: 0.125762, Discriminator: 0.043371; Generator: 0.021657,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:31,267 root         INFO     Train Epoch: 98 [512/8000 (6%)]\tTotal Loss: 0.795404\n",
      "Reconstruction: 0.680037, Regularization: 0.050364, Discriminator: 0.043349; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:31,377 root         INFO     Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 0.330743\n",
      "Reconstruction: 0.206354, Regularization: 0.059395, Discriminator: 0.043304; Generator: 0.021691,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:31,487 root         INFO     Train Epoch: 98 [1536/8000 (19%)]\tTotal Loss: 0.404771\n",
      "Reconstruction: 0.275040, Regularization: 0.064751, Discriminator: 0.043316; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:31,596 root         INFO     Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 0.292227\n",
      "Reconstruction: 0.181347, Regularization: 0.045896, Discriminator: 0.043299; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:31,706 root         INFO     Train Epoch: 98 [2560/8000 (32%)]\tTotal Loss: 0.283546\n",
      "Reconstruction: 0.174895, Regularization: 0.043680, Discriminator: 0.043304; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:31,818 root         INFO     Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 0.230871\n",
      "Reconstruction: 0.113757, Regularization: 0.052132, Discriminator: 0.043333; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:31,930 root         INFO     Train Epoch: 98 [3584/8000 (45%)]\tTotal Loss: 5.846462\n",
      "Reconstruction: 5.553344, Regularization: 0.228137, Discriminator: 0.043314; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:32,042 root         INFO     Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 0.249267\n",
      "Reconstruction: 0.127430, Regularization: 0.056865, Discriminator: 0.043344; Generator: 0.021629,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:32,156 root         INFO     Train Epoch: 98 [4608/8000 (58%)]\tTotal Loss: 0.251027\n",
      "Reconstruction: 0.145434, Regularization: 0.040624, Discriminator: 0.043325; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:32,268 root         INFO     Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 808.918274\n",
      "Reconstruction: 808.752563, Regularization: 0.100698, Discriminator: 0.043314; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:32,381 root         INFO     Train Epoch: 98 [5632/8000 (70%)]\tTotal Loss: 0.303627\n",
      "Reconstruction: 0.201116, Regularization: 0.037530, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:32,493 root         INFO     Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 0.220070\n",
      "Reconstruction: 0.127115, Regularization: 0.027967, Discriminator: 0.043314; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:32,606 root         INFO     Train Epoch: 98 [6656/8000 (83%)]\tTotal Loss: 1.964938\n",
      "Reconstruction: 1.845366, Regularization: 0.054618, Discriminator: 0.043311; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:32,718 root         INFO     Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 0.208315\n",
      "Reconstruction: 0.110383, Regularization: 0.032945, Discriminator: 0.043317; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:32,830 root         INFO     Train Epoch: 98 [7680/8000 (96%)]\tTotal Loss: 0.224806\n",
      "Reconstruction: 0.110509, Regularization: 0.049308, Discriminator: 0.043323; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:32,912 root         INFO     ====> Epoch: 98 Average loss: 1946.5403\n",
      "2019-04-09 23:34:32,939 root         INFO     Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 0.460423\n",
      "Reconstruction: 0.319716, Regularization: 0.075724, Discriminator: 0.043321; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:33,053 root         INFO     Train Epoch: 99 [512/8000 (6%)]\tTotal Loss: 0.209732\n",
      "Reconstruction: 0.115995, Regularization: 0.028757, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:33,163 root         INFO     Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 0.619987\n",
      "Reconstruction: 0.459475, Regularization: 0.095523, Discriminator: 0.043321; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:33,273 root         INFO     Train Epoch: 99 [1536/8000 (19%)]\tTotal Loss: 0.482958\n",
      "Reconstruction: 0.372897, Regularization: 0.045074, Discriminator: 0.043322; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:33,383 root         INFO     Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 0.224123\n",
      "Reconstruction: 0.134601, Regularization: 0.024547, Discriminator: 0.043312; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:33,494 root         INFO     Train Epoch: 99 [2560/8000 (32%)]\tTotal Loss: 7.281945\n",
      "Reconstruction: 7.108927, Regularization: 0.108051, Discriminator: 0.043286; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:33,604 root         INFO     Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 0.375868\n",
      "Reconstruction: 0.265959, Regularization: 0.044930, Discriminator: 0.043300; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:33,714 root         INFO     Train Epoch: 99 [3584/8000 (45%)]\tTotal Loss: 0.387673\n",
      "Reconstruction: 0.237928, Regularization: 0.084766, Discriminator: 0.043351; Generator: 0.021628,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:33,824 root         INFO     Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 0.282881\n",
      "Reconstruction: 0.150604, Regularization: 0.067321, Discriminator: 0.043316; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:33,935 root         INFO     Train Epoch: 99 [4608/8000 (58%)]\tTotal Loss: 0.251833\n",
      "Reconstruction: 0.155786, Regularization: 0.031068, Discriminator: 0.043272; Generator: 0.021707,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:34,045 root         INFO     Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 60977.984375\n",
      "Reconstruction: 60977.585938, Regularization: 0.330691, Discriminator: 0.043260; Generator: 0.021704,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:34,155 root         INFO     Train Epoch: 99 [5632/8000 (70%)]\tTotal Loss: 2379.995850\n",
      "Reconstruction: 2379.843262, Regularization: 0.087613, Discriminator: 0.043335; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:34,265 root         INFO     Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 0.307107\n",
      "Reconstruction: 0.208119, Regularization: 0.033995, Discriminator: 0.043312; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:34,376 root         INFO     Train Epoch: 99 [6656/8000 (83%)]\tTotal Loss: 0.203614\n",
      "Reconstruction: 0.114930, Regularization: 0.023693, Discriminator: 0.043351; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:34,488 root         INFO     Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 1.189916\n",
      "Reconstruction: 1.018748, Regularization: 0.106193, Discriminator: 0.043320; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:34,600 root         INFO     Train Epoch: 99 [7680/8000 (96%)]\tTotal Loss: 32.709381\n",
      "Reconstruction: 32.531609, Regularization: 0.112771, Discriminator: 0.043361; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:34,682 root         INFO     ====> Epoch: 99 Average loss: 9238.3981\n",
      "2019-04-09 23:34:34,709 root         INFO     Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 0.204463\n",
      "Reconstruction: 0.110771, Regularization: 0.028698, Discriminator: 0.043317; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:34,823 root         INFO     Train Epoch: 100 [512/8000 (6%)]\tTotal Loss: 0.557627\n",
      "Reconstruction: 0.407733, Regularization: 0.084920, Discriminator: 0.043304; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:34,935 root         INFO     Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 0.620763\n",
      "Reconstruction: 0.463936, Regularization: 0.091839, Discriminator: 0.043335; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:35,047 root         INFO     Train Epoch: 100 [1536/8000 (19%)]\tTotal Loss: 4.156295\n",
      "Reconstruction: 4.017673, Regularization: 0.073650, Discriminator: 0.043313; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:35,160 root         INFO     Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 0.913058\n",
      "Reconstruction: 0.788764, Regularization: 0.059337, Discriminator: 0.043299; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:35,272 root         INFO     Train Epoch: 100 [2560/8000 (32%)]\tTotal Loss: 0.249802\n",
      "Reconstruction: 0.140304, Regularization: 0.044549, Discriminator: 0.043287; Generator: 0.021662,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:35,384 root         INFO     Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 0.257442\n",
      "Reconstruction: 0.137364, Regularization: 0.055061, Discriminator: 0.043361; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:35,496 root         INFO     Train Epoch: 100 [3584/8000 (45%)]\tTotal Loss: 2.008157\n",
      "Reconstruction: 1.841938, Regularization: 0.101231, Discriminator: 0.043326; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:35,608 root         INFO     Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 0.658692\n",
      "Reconstruction: 0.523715, Regularization: 0.070006, Discriminator: 0.043313; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:35,721 root         INFO     Train Epoch: 100 [4608/8000 (58%)]\tTotal Loss: 0.333193\n",
      "Reconstruction: 0.197079, Regularization: 0.071105, Discriminator: 0.043352; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:35,833 root         INFO     Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 0.403790\n",
      "Reconstruction: 0.270353, Regularization: 0.068447, Discriminator: 0.043331; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:35,944 root         INFO     Train Epoch: 100 [5632/8000 (70%)]\tTotal Loss: 0.321494\n",
      "Reconstruction: 0.204075, Regularization: 0.052448, Discriminator: 0.043304; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:36,054 root         INFO     Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 0.241980\n",
      "Reconstruction: 0.115808, Regularization: 0.061179, Discriminator: 0.043320; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:36,165 root         INFO     Train Epoch: 100 [6656/8000 (83%)]\tTotal Loss: 1.886314\n",
      "Reconstruction: 1.767563, Regularization: 0.053798, Discriminator: 0.043296; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:36,276 root         INFO     Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 0.487385\n",
      "Reconstruction: 0.316419, Regularization: 0.105954, Discriminator: 0.043354; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:36,386 root         INFO     Train Epoch: 100 [7680/8000 (96%)]\tTotal Loss: 1.782135\n",
      "Reconstruction: 1.602504, Regularization: 0.114640, Discriminator: 0.043335; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:36,467 root         INFO     ====> Epoch: 100 Average loss: 3.1462\n",
      "2019-04-09 23:34:36,495 root         INFO     Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 0.184856\n",
      "Reconstruction: 0.090689, Regularization: 0.029199, Discriminator: 0.043298; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:36,606 root         INFO     Train Epoch: 101 [512/8000 (6%)]\tTotal Loss: 0.201190\n",
      "Reconstruction: 0.107830, Regularization: 0.028382, Discriminator: 0.043284; Generator: 0.021694,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:36,716 root         INFO     Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 0.241581\n",
      "Reconstruction: 0.136627, Regularization: 0.040009, Discriminator: 0.043303; Generator: 0.021642,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:36,827 root         INFO     Train Epoch: 101 [1536/8000 (19%)]\tTotal Loss: 223.502258\n",
      "Reconstruction: 223.310287, Regularization: 0.126989, Discriminator: 0.043341; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:36,938 root         INFO     Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 2.560276\n",
      "Reconstruction: 2.420457, Regularization: 0.074784, Discriminator: 0.043354; Generator: 0.021681,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:37,049 root         INFO     Train Epoch: 101 [2560/8000 (32%)]\tTotal Loss: 0.383745\n",
      "Reconstruction: 0.156794, Regularization: 0.161931, Discriminator: 0.043396; Generator: 0.021624,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:34:37,159 root         INFO     Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 0.200222\n",
      "Reconstruction: 0.108053, Regularization: 0.027193, Discriminator: 0.043324; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:37,269 root         INFO     Train Epoch: 101 [3584/8000 (45%)]\tTotal Loss: 0.225168\n",
      "Reconstruction: 0.112571, Regularization: 0.047608, Discriminator: 0.043349; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:37,381 root         INFO     Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 0.237513\n",
      "Reconstruction: 0.125134, Regularization: 0.047398, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:37,494 root         INFO     Train Epoch: 101 [4608/8000 (58%)]\tTotal Loss: 0.354074\n",
      "Reconstruction: 0.178396, Regularization: 0.110696, Discriminator: 0.043305; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:37,606 root         INFO     Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 0.208430\n",
      "Reconstruction: 0.102215, Regularization: 0.041192, Discriminator: 0.043344; Generator: 0.021679,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:37,717 root         INFO     Train Epoch: 101 [5632/8000 (70%)]\tTotal Loss: 0.237856\n",
      "Reconstruction: 0.124366, Regularization: 0.048515, Discriminator: 0.043333; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:37,827 root         INFO     Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 2.578510\n",
      "Reconstruction: 2.410040, Regularization: 0.103495, Discriminator: 0.043341; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:37,937 root         INFO     Train Epoch: 101 [6656/8000 (83%)]\tTotal Loss: 0.270857\n",
      "Reconstruction: 0.162997, Regularization: 0.042890, Discriminator: 0.043313; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:38,047 root         INFO     Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 0.318959\n",
      "Reconstruction: 0.196840, Regularization: 0.057110, Discriminator: 0.043330; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:38,157 root         INFO     Train Epoch: 101 [7680/8000 (96%)]\tTotal Loss: 33.690308\n",
      "Reconstruction: 33.330162, Regularization: 0.295233, Discriminator: 0.043313; Generator: 0.021597,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:34:38,239 root         INFO     ====> Epoch: 101 Average loss: 38.1538\n",
      "2019-04-09 23:34:38,267 root         INFO     Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 2.561262\n",
      "Reconstruction: 2.273711, Regularization: 0.222551, Discriminator: 0.043353; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:38,380 root         INFO     Train Epoch: 102 [512/8000 (6%)]\tTotal Loss: 0.266812\n",
      "Reconstruction: 0.119047, Regularization: 0.082801, Discriminator: 0.043294; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:38,491 root         INFO     Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 0.198887\n",
      "Reconstruction: 0.099389, Regularization: 0.034426, Discriminator: 0.043386; Generator: 0.021685,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:38,604 root         INFO     Train Epoch: 102 [1536/8000 (19%)]\tTotal Loss: 0.426941\n",
      "Reconstruction: 0.300711, Regularization: 0.061265, Discriminator: 0.043279; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:38,715 root         INFO     Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 0.339288\n",
      "Reconstruction: 0.223809, Regularization: 0.050459, Discriminator: 0.043383; Generator: 0.021638,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:38,827 root         INFO     Train Epoch: 102 [2560/8000 (32%)]\tTotal Loss: 24854.126953\n",
      "Reconstruction: 24853.716797, Regularization: 0.345255, Discriminator: 0.043318; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:38,939 root         INFO     Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 0.403807\n",
      "Reconstruction: 0.256855, Regularization: 0.081995, Discriminator: 0.043315; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:39,050 root         INFO     Train Epoch: 102 [3584/8000 (45%)]\tTotal Loss: 0.493098\n",
      "Reconstruction: 0.359589, Regularization: 0.068520, Discriminator: 0.043338; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:39,161 root         INFO     Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 0.219772\n",
      "Reconstruction: 0.119247, Regularization: 0.035537, Discriminator: 0.043328; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:39,272 root         INFO     Train Epoch: 102 [4608/8000 (58%)]\tTotal Loss: 0.238275\n",
      "Reconstruction: 0.129255, Regularization: 0.043974, Discriminator: 0.043390; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:39,384 root         INFO     Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 13.717880\n",
      "Reconstruction: 13.585041, Regularization: 0.067837, Discriminator: 0.043352; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:39,496 root         INFO     Train Epoch: 102 [5632/8000 (70%)]\tTotal Loss: 96.854607\n",
      "Reconstruction: 96.519966, Regularization: 0.269632, Discriminator: 0.043350; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:39,608 root         INFO     Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 0.196670\n",
      "Reconstruction: 0.105051, Regularization: 0.026647, Discriminator: 0.043307; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:39,719 root         INFO     Train Epoch: 102 [6656/8000 (83%)]\tTotal Loss: 0.290698\n",
      "Reconstruction: 0.183049, Regularization: 0.042672, Discriminator: 0.043331; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:39,831 root         INFO     Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 0.281393\n",
      "Reconstruction: 0.127423, Regularization: 0.088982, Discriminator: 0.043331; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:39,942 root         INFO     Train Epoch: 102 [7680/8000 (96%)]\tTotal Loss: 0.297346\n",
      "Reconstruction: 0.160895, Regularization: 0.071432, Discriminator: 0.043416; Generator: 0.021603,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:34:40,024 root         INFO     ====> Epoch: 102 Average loss: 6438.1994\n",
      "2019-04-09 23:34:40,051 root         INFO     Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 0.321651\n",
      "Reconstruction: 0.172505, Regularization: 0.084130, Discriminator: 0.043318; Generator: 0.021699,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:34:40,163 root         INFO     Train Epoch: 103 [512/8000 (6%)]\tTotal Loss: 644.783203\n",
      "Reconstruction: 644.604797, Regularization: 0.113432, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:40,273 root         INFO     Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 0.703651\n",
      "Reconstruction: 0.604937, Regularization: 0.033719, Discriminator: 0.043332; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:40,383 root         INFO     Train Epoch: 103 [1536/8000 (19%)]\tTotal Loss: 0.258850\n",
      "Reconstruction: 0.147521, Regularization: 0.046346, Discriminator: 0.043337; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:40,494 root         INFO     Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 0.244369\n",
      "Reconstruction: 0.143772, Regularization: 0.035641, Discriminator: 0.043341; Generator: 0.021615,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:40,604 root         INFO     Train Epoch: 103 [2560/8000 (32%)]\tTotal Loss: 0.355982\n",
      "Reconstruction: 0.228245, Regularization: 0.062773, Discriminator: 0.043298; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:40,715 root         INFO     Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 4.891645\n",
      "Reconstruction: 4.755038, Regularization: 0.071587, Discriminator: 0.043360; Generator: 0.021661,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:40,826 root         INFO     Train Epoch: 103 [3584/8000 (45%)]\tTotal Loss: 0.242239\n",
      "Reconstruction: 0.137667, Regularization: 0.039603, Discriminator: 0.043271; Generator: 0.021698,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:40,937 root         INFO     Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 0.492892\n",
      "Reconstruction: 0.400293, Regularization: 0.027626, Discriminator: 0.043325; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:41,047 root         INFO     Train Epoch: 103 [4608/8000 (58%)]\tTotal Loss: 21211.736328\n",
      "Reconstruction: 21211.484375, Regularization: 0.187898, Discriminator: 0.043342; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:41,157 root         INFO     Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 1.102588\n",
      "Reconstruction: 0.982635, Regularization: 0.054942, Discriminator: 0.043326; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:41,267 root         INFO     Train Epoch: 103 [5632/8000 (70%)]\tTotal Loss: 0.274346\n",
      "Reconstruction: 0.146551, Regularization: 0.062824, Discriminator: 0.043306; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:41,378 root         INFO     Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 0.289467\n",
      "Reconstruction: 0.178551, Regularization: 0.045932, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:41,487 root         INFO     Train Epoch: 103 [6656/8000 (83%)]\tTotal Loss: 5.563133\n",
      "Reconstruction: 5.303305, Regularization: 0.194841, Discriminator: 0.043328; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:41,597 root         INFO     Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 0.292690\n",
      "Reconstruction: 0.185570, Regularization: 0.042135, Discriminator: 0.043322; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:41,708 root         INFO     Train Epoch: 103 [7680/8000 (96%)]\tTotal Loss: 0.671029\n",
      "Reconstruction: 0.479280, Regularization: 0.126773, Discriminator: 0.043317; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:41,788 root         INFO     ====> Epoch: 103 Average loss: 17521.6433\n",
      "2019-04-09 23:34:41,815 root         INFO     Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 0.201839\n",
      "Reconstruction: 0.114144, Regularization: 0.022711, Discriminator: 0.043306; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:41,929 root         INFO     Train Epoch: 104 [512/8000 (6%)]\tTotal Loss: 0.260356\n",
      "Reconstruction: 0.151136, Regularization: 0.044226, Discriminator: 0.043311; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:42,042 root         INFO     Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 0.281065\n",
      "Reconstruction: 0.177093, Regularization: 0.039007, Discriminator: 0.043289; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:42,155 root         INFO     Train Epoch: 104 [1536/8000 (19%)]\tTotal Loss: 0.291984\n",
      "Reconstruction: 0.118017, Regularization: 0.108980, Discriminator: 0.043305; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:42,269 root         INFO     Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 0.251772\n",
      "Reconstruction: 0.150727, Regularization: 0.036066, Discriminator: 0.043318; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:42,383 root         INFO     Train Epoch: 104 [2560/8000 (32%)]\tTotal Loss: 0.236763\n",
      "Reconstruction: 0.125360, Regularization: 0.046425, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:42,494 root         INFO     Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 0.264485\n",
      "Reconstruction: 0.159891, Regularization: 0.039610, Discriminator: 0.043324; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:42,606 root         INFO     Train Epoch: 104 [3584/8000 (45%)]\tTotal Loss: 0.264166\n",
      "Reconstruction: 0.144374, Regularization: 0.054798, Discriminator: 0.043323; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:42,718 root         INFO     Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 0.320898\n",
      "Reconstruction: 0.205631, Regularization: 0.050328, Discriminator: 0.043317; Generator: 0.021622,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:34:42,831 root         INFO     Train Epoch: 104 [4608/8000 (58%)]\tTotal Loss: 0.291312\n",
      "Reconstruction: 0.170613, Regularization: 0.055731, Discriminator: 0.043312; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:42,942 root         INFO     Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 0.205478\n",
      "Reconstruction: 0.115193, Regularization: 0.025264, Discriminator: 0.043395; Generator: 0.021626,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:34:43,054 root         INFO     Train Epoch: 104 [5632/8000 (70%)]\tTotal Loss: 0.242691\n",
      "Reconstruction: 0.132418, Regularization: 0.045268, Discriminator: 0.043385; Generator: 0.021620,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:43,166 root         INFO     Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 0.220308\n",
      "Reconstruction: 0.121972, Regularization: 0.033324, Discriminator: 0.043334; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:43,277 root         INFO     Train Epoch: 104 [6656/8000 (83%)]\tTotal Loss: 0.271722\n",
      "Reconstruction: 0.128634, Regularization: 0.078104, Discriminator: 0.043339; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:43,386 root         INFO     Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 0.198319\n",
      "Reconstruction: 0.102083, Regularization: 0.031212, Discriminator: 0.043352; Generator: 0.021672,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:43,494 root         INFO     Train Epoch: 104 [7680/8000 (96%)]\tTotal Loss: 0.376305\n",
      "Reconstruction: 0.229848, Regularization: 0.081489, Discriminator: 0.043275; Generator: 0.021693,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:43,573 root         INFO     ====> Epoch: 104 Average loss: 141.7404\n",
      "2019-04-09 23:34:43,601 root         INFO     Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 0.218542\n",
      "Reconstruction: 0.116537, Regularization: 0.037012, Discriminator: 0.043312; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:43,712 root         INFO     Train Epoch: 105 [512/8000 (6%)]\tTotal Loss: 0.229002\n",
      "Reconstruction: 0.126826, Regularization: 0.037178, Discriminator: 0.043333; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:43,823 root         INFO     Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 0.203534\n",
      "Reconstruction: 0.089238, Regularization: 0.049311, Discriminator: 0.043332; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:43,934 root         INFO     Train Epoch: 105 [1536/8000 (19%)]\tTotal Loss: 0.211386\n",
      "Reconstruction: 0.114683, Regularization: 0.031721, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:44,044 root         INFO     Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 0.248923\n",
      "Reconstruction: 0.137565, Regularization: 0.046386, Discriminator: 0.043313; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:44,155 root         INFO     Train Epoch: 105 [2560/8000 (32%)]\tTotal Loss: 0.363475\n",
      "Reconstruction: 0.262715, Regularization: 0.035790, Discriminator: 0.043317; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:44,266 root         INFO     Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 0.243772\n",
      "Reconstruction: 0.130031, Regularization: 0.048788, Discriminator: 0.043292; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:44,376 root         INFO     Train Epoch: 105 [3584/8000 (45%)]\tTotal Loss: 0.205382\n",
      "Reconstruction: 0.113080, Regularization: 0.027338, Discriminator: 0.043283; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:44,488 root         INFO     Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 0.261576\n",
      "Reconstruction: 0.112235, Regularization: 0.084366, Discriminator: 0.043325; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:44,598 root         INFO     Train Epoch: 105 [4608/8000 (58%)]\tTotal Loss: 0.417009\n",
      "Reconstruction: 0.299832, Regularization: 0.052186, Discriminator: 0.043259; Generator: 0.021733,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:44,709 root         INFO     Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 1.236371\n",
      "Reconstruction: 1.110933, Regularization: 0.060437, Discriminator: 0.043342; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:44,820 root         INFO     Train Epoch: 105 [5632/8000 (70%)]\tTotal Loss: 0.223262\n",
      "Reconstruction: 0.104534, Regularization: 0.053726, Discriminator: 0.043317; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:44,930 root         INFO     Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 1.534057\n",
      "Reconstruction: 1.422850, Regularization: 0.046279, Discriminator: 0.043263; Generator: 0.021666,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:45,042 root         INFO     Train Epoch: 105 [6656/8000 (83%)]\tTotal Loss: 0.277207\n",
      "Reconstruction: 0.127335, Regularization: 0.084898, Discriminator: 0.043301; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:45,156 root         INFO     Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 0.273435\n",
      "Reconstruction: 0.121261, Regularization: 0.087148, Discriminator: 0.043390; Generator: 0.021635,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:45,268 root         INFO     Train Epoch: 105 [7680/8000 (96%)]\tTotal Loss: 0.236511\n",
      "Reconstruction: 0.135625, Regularization: 0.035883, Discriminator: 0.043285; Generator: 0.021719,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:45,350 root         INFO     ====> Epoch: 105 Average loss: 132363.2223\n",
      "2019-04-09 23:34:45,377 root         INFO     Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 0.235951\n",
      "Reconstruction: 0.115145, Regularization: 0.055810, Discriminator: 0.043306; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:45,490 root         INFO     Train Epoch: 106 [512/8000 (6%)]\tTotal Loss: 0.282586\n",
      "Reconstruction: 0.135335, Regularization: 0.082255, Discriminator: 0.043389; Generator: 0.021608,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:45,601 root         INFO     Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 0.218479\n",
      "Reconstruction: 0.104481, Regularization: 0.049000, Discriminator: 0.043329; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:45,713 root         INFO     Train Epoch: 106 [1536/8000 (19%)]\tTotal Loss: 0.316992\n",
      "Reconstruction: 0.184593, Regularization: 0.067415, Discriminator: 0.043318; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:45,823 root         INFO     Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 0.446603\n",
      "Reconstruction: 0.312041, Regularization: 0.069572, Discriminator: 0.043325; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:45,934 root         INFO     Train Epoch: 106 [2560/8000 (32%)]\tTotal Loss: 28.947458\n",
      "Reconstruction: 28.780964, Regularization: 0.101499, Discriminator: 0.043331; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:46,045 root         INFO     Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 0.260251\n",
      "Reconstruction: 0.118751, Regularization: 0.076514, Discriminator: 0.043329; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:46,156 root         INFO     Train Epoch: 106 [3584/8000 (45%)]\tTotal Loss: 1.986103\n",
      "Reconstruction: 1.850341, Regularization: 0.070786, Discriminator: 0.043350; Generator: 0.021626,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:46,267 root         INFO     Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 0.330163\n",
      "Reconstruction: 0.185194, Regularization: 0.079997, Discriminator: 0.043291; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:46,379 root         INFO     Train Epoch: 106 [4608/8000 (58%)]\tTotal Loss: 0.248504\n",
      "Reconstruction: 0.124582, Regularization: 0.058950, Discriminator: 0.043329; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:46,489 root         INFO     Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 0.210886\n",
      "Reconstruction: 0.110562, Regularization: 0.035346, Discriminator: 0.043305; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:46,599 root         INFO     Train Epoch: 106 [5632/8000 (70%)]\tTotal Loss: 0.231354\n",
      "Reconstruction: 0.114439, Regularization: 0.051890, Discriminator: 0.043360; Generator: 0.021665,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:46,710 root         INFO     Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 1.311758\n",
      "Reconstruction: 1.127756, Regularization: 0.119002, Discriminator: 0.043356; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:46,820 root         INFO     Train Epoch: 106 [6656/8000 (83%)]\tTotal Loss: 0.251402\n",
      "Reconstruction: 0.125565, Regularization: 0.060871, Discriminator: 0.043298; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:46,933 root         INFO     Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 0.258621\n",
      "Reconstruction: 0.150639, Regularization: 0.042983, Discriminator: 0.043313; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:47,045 root         INFO     Train Epoch: 106 [7680/8000 (96%)]\tTotal Loss: 1.032807\n",
      "Reconstruction: 0.854238, Regularization: 0.113591, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:47,126 root         INFO     ====> Epoch: 106 Average loss: 4219.6764\n",
      "2019-04-09 23:34:47,154 root         INFO     Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 0.260590\n",
      "Reconstruction: 0.124830, Regularization: 0.070805, Discriminator: 0.043299; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:47,266 root         INFO     Train Epoch: 107 [512/8000 (6%)]\tTotal Loss: 0.280396\n",
      "Reconstruction: 0.189300, Regularization: 0.026117, Discriminator: 0.043329; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:47,379 root         INFO     Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 0.238693\n",
      "Reconstruction: 0.138009, Regularization: 0.035705, Discriminator: 0.043314; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:47,491 root         INFO     Train Epoch: 107 [1536/8000 (19%)]\tTotal Loss: 0.349942\n",
      "Reconstruction: 0.166150, Regularization: 0.118787, Discriminator: 0.043341; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:47,603 root         INFO     Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 0.261131\n",
      "Reconstruction: 0.164019, Regularization: 0.032129, Discriminator: 0.043328; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:47,716 root         INFO     Train Epoch: 107 [2560/8000 (32%)]\tTotal Loss: 0.571510\n",
      "Reconstruction: 0.459874, Regularization: 0.046634, Discriminator: 0.043341; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:47,829 root         INFO     Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 0.582041\n",
      "Reconstruction: 0.445761, Regularization: 0.071324, Discriminator: 0.043308; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:47,941 root         INFO     Train Epoch: 107 [3584/8000 (45%)]\tTotal Loss: 0.289204\n",
      "Reconstruction: 0.129411, Regularization: 0.094806, Discriminator: 0.043330; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:48,054 root         INFO     Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 0.262163\n",
      "Reconstruction: 0.152826, Regularization: 0.044374, Discriminator: 0.043302; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:48,166 root         INFO     Train Epoch: 107 [4608/8000 (58%)]\tTotal Loss: 0.295108\n",
      "Reconstruction: 0.150711, Regularization: 0.079390, Discriminator: 0.043343; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:48,279 root         INFO     Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 0.375251\n",
      "Reconstruction: 0.250095, Regularization: 0.060187, Discriminator: 0.043331; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:48,392 root         INFO     Train Epoch: 107 [5632/8000 (70%)]\tTotal Loss: 0.233552\n",
      "Reconstruction: 0.120467, Regularization: 0.048119, Discriminator: 0.043327; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:48,504 root         INFO     Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 8.296404\n",
      "Reconstruction: 8.141324, Regularization: 0.090096, Discriminator: 0.043306; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:48,617 root         INFO     Train Epoch: 107 [6656/8000 (83%)]\tTotal Loss: 0.230813\n",
      "Reconstruction: 0.127356, Regularization: 0.038496, Discriminator: 0.043307; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:48,730 root         INFO     Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 0.251452\n",
      "Reconstruction: 0.134340, Regularization: 0.052145, Discriminator: 0.043363; Generator: 0.021604,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:48,842 root         INFO     Train Epoch: 107 [7680/8000 (96%)]\tTotal Loss: 0.622150\n",
      "Reconstruction: 0.479267, Regularization: 0.077851, Discriminator: 0.043348; Generator: 0.021684,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:48,925 root         INFO     ====> Epoch: 107 Average loss: 81.4737\n",
      "2019-04-09 23:34:48,952 root         INFO     Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 0.358444\n",
      "Reconstruction: 0.221479, Regularization: 0.072014, Discriminator: 0.043315; Generator: 0.021636,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:49,064 root         INFO     Train Epoch: 108 [512/8000 (6%)]\tTotal Loss: 0.498686\n",
      "Reconstruction: 0.384898, Regularization: 0.048819, Discriminator: 0.043325; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:49,176 root         INFO     Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 38.258827\n",
      "Reconstruction: 38.079857, Regularization: 0.114009, Discriminator: 0.043380; Generator: 0.021582,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:49,289 root         INFO     Train Epoch: 108 [1536/8000 (19%)]\tTotal Loss: 44.353786\n",
      "Reconstruction: 44.208424, Regularization: 0.080380, Discriminator: 0.043261; Generator: 0.021722,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:49,401 root         INFO     Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 0.365685\n",
      "Reconstruction: 0.222235, Regularization: 0.078461, Discriminator: 0.043313; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:49,512 root         INFO     Train Epoch: 108 [2560/8000 (32%)]\tTotal Loss: 1.061325\n",
      "Reconstruction: 0.931072, Regularization: 0.065217, Discriminator: 0.043383; Generator: 0.021654,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:49,622 root         INFO     Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 1.076950\n",
      "Reconstruction: 0.941785, Regularization: 0.070169, Discriminator: 0.043342; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:49,733 root         INFO     Train Epoch: 108 [3584/8000 (45%)]\tTotal Loss: 0.750836\n",
      "Reconstruction: 0.506830, Regularization: 0.179033, Discriminator: 0.043313; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:49,844 root         INFO     Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 1.275887\n",
      "Reconstruction: 1.119445, Regularization: 0.091452, Discriminator: 0.043310; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:49,955 root         INFO     Train Epoch: 108 [4608/8000 (58%)]\tTotal Loss: 0.326778\n",
      "Reconstruction: 0.210881, Regularization: 0.050925, Discriminator: 0.043333; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:50,068 root         INFO     Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 0.270187\n",
      "Reconstruction: 0.138967, Regularization: 0.066264, Discriminator: 0.043278; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:50,180 root         INFO     Train Epoch: 108 [5632/8000 (70%)]\tTotal Loss: 0.440126\n",
      "Reconstruction: 0.309846, Regularization: 0.065346, Discriminator: 0.043262; Generator: 0.021672,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:50,292 root         INFO     Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 1.732113\n",
      "Reconstruction: 1.596392, Regularization: 0.070702, Discriminator: 0.043313; Generator: 0.021706,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:34:50,404 root         INFO     Train Epoch: 108 [6656/8000 (83%)]\tTotal Loss: 0.273014\n",
      "Reconstruction: 0.144476, Regularization: 0.063564, Discriminator: 0.043343; Generator: 0.021630,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:50,514 root         INFO     Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 0.316736\n",
      "Reconstruction: 0.183119, Regularization: 0.068651, Discriminator: 0.043332; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:50,625 root         INFO     Train Epoch: 108 [7680/8000 (96%)]\tTotal Loss: 0.236887\n",
      "Reconstruction: 0.124844, Regularization: 0.047019, Discriminator: 0.043335; Generator: 0.021689,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:50,704 root         INFO     ====> Epoch: 108 Average loss: 15812.1277\n",
      "2019-04-09 23:34:50,733 root         INFO     Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 0.217936\n",
      "Reconstruction: 0.119092, Regularization: 0.033826, Discriminator: 0.043352; Generator: 0.021666,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:50,845 root         INFO     Train Epoch: 109 [512/8000 (6%)]\tTotal Loss: 0.222448\n",
      "Reconstruction: 0.114703, Regularization: 0.042762, Discriminator: 0.043319; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:50,956 root         INFO     Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 14.200813\n",
      "Reconstruction: 14.067842, Regularization: 0.067983, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:51,067 root         INFO     Train Epoch: 109 [1536/8000 (19%)]\tTotal Loss: 0.296501\n",
      "Reconstruction: 0.163155, Regularization: 0.068385, Discriminator: 0.043269; Generator: 0.021691,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:51,178 root         INFO     Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 0.324483\n",
      "Reconstruction: 0.183062, Regularization: 0.076462, Discriminator: 0.043333; Generator: 0.021627,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:51,289 root         INFO     Train Epoch: 109 [2560/8000 (32%)]\tTotal Loss: 0.279680\n",
      "Reconstruction: 0.144643, Regularization: 0.070043, Discriminator: 0.043337; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:51,400 root         INFO     Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 0.384380\n",
      "Reconstruction: 0.265796, Regularization: 0.053594, Discriminator: 0.043348; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:51,511 root         INFO     Train Epoch: 109 [3584/8000 (45%)]\tTotal Loss: 0.351100\n",
      "Reconstruction: 0.221777, Regularization: 0.064358, Discriminator: 0.043278; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:51,623 root         INFO     Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 0.247557\n",
      "Reconstruction: 0.132361, Regularization: 0.050228, Discriminator: 0.043320; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:51,735 root         INFO     Train Epoch: 109 [4608/8000 (58%)]\tTotal Loss: 0.461637\n",
      "Reconstruction: 0.343105, Regularization: 0.053539, Discriminator: 0.043333; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:51,847 root         INFO     Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 0.215379\n",
      "Reconstruction: 0.113230, Regularization: 0.037167, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:51,959 root         INFO     Train Epoch: 109 [5632/8000 (70%)]\tTotal Loss: 4.213177\n",
      "Reconstruction: 4.016008, Regularization: 0.132193, Discriminator: 0.043323; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:52,070 root         INFO     Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 0.504206\n",
      "Reconstruction: 0.356349, Regularization: 0.082879, Discriminator: 0.043325; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:52,182 root         INFO     Train Epoch: 109 [6656/8000 (83%)]\tTotal Loss: 0.342808\n",
      "Reconstruction: 0.117874, Regularization: 0.159964, Discriminator: 0.043291; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:52,294 root         INFO     Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 0.259115\n",
      "Reconstruction: 0.143000, Regularization: 0.051132, Discriminator: 0.043336; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:52,406 root         INFO     Train Epoch: 109 [7680/8000 (96%)]\tTotal Loss: 0.451731\n",
      "Reconstruction: 0.126621, Regularization: 0.260107, Discriminator: 0.043374; Generator: 0.021629,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:52,488 root         INFO     ====> Epoch: 109 Average loss: 11.1215\n",
      "2019-04-09 23:34:52,515 root         INFO     Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 0.325053\n",
      "Reconstruction: 0.159810, Regularization: 0.100230, Discriminator: 0.043350; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:52,627 root         INFO     Train Epoch: 110 [512/8000 (6%)]\tTotal Loss: 0.225417\n",
      "Reconstruction: 0.110348, Regularization: 0.050090, Discriminator: 0.043352; Generator: 0.021626,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:52,738 root         INFO     Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 0.243151\n",
      "Reconstruction: 0.131524, Regularization: 0.046622, Discriminator: 0.043348; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:52,851 root         INFO     Train Epoch: 110 [1536/8000 (19%)]\tTotal Loss: 0.663675\n",
      "Reconstruction: 0.554950, Regularization: 0.043720, Discriminator: 0.043326; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:52,963 root         INFO     Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 0.290170\n",
      "Reconstruction: 0.158510, Regularization: 0.066690, Discriminator: 0.043277; Generator: 0.021693,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:53,076 root         INFO     Train Epoch: 110 [2560/8000 (32%)]\tTotal Loss: 0.205521\n",
      "Reconstruction: 0.096975, Regularization: 0.043570, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:53,187 root         INFO     Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 0.336011\n",
      "Reconstruction: 0.182674, Regularization: 0.088356, Discriminator: 0.043315; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:53,299 root         INFO     Train Epoch: 110 [3584/8000 (45%)]\tTotal Loss: 0.198662\n",
      "Reconstruction: 0.104451, Regularization: 0.029230, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:53,410 root         INFO     Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 0.576330\n",
      "Reconstruction: 0.360332, Regularization: 0.150998, Discriminator: 0.043337; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:53,523 root         INFO     Train Epoch: 110 [4608/8000 (58%)]\tTotal Loss: 0.240408\n",
      "Reconstruction: 0.120767, Regularization: 0.054663, Discriminator: 0.043321; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:53,635 root         INFO     Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 0.218914\n",
      "Reconstruction: 0.124649, Regularization: 0.029296, Discriminator: 0.043314; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:53,747 root         INFO     Train Epoch: 110 [5632/8000 (70%)]\tTotal Loss: 0.224090\n",
      "Reconstruction: 0.119185, Regularization: 0.039915, Discriminator: 0.043321; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:53,860 root         INFO     Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 0.520177\n",
      "Reconstruction: 0.340555, Regularization: 0.114645, Discriminator: 0.043293; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:53,973 root         INFO     Train Epoch: 110 [6656/8000 (83%)]\tTotal Loss: 0.250237\n",
      "Reconstruction: 0.133777, Regularization: 0.051469, Discriminator: 0.043349; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:54,086 root         INFO     Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 0.476294\n",
      "Reconstruction: 0.173681, Regularization: 0.237610, Discriminator: 0.043356; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:54,198 root         INFO     Train Epoch: 110 [7680/8000 (96%)]\tTotal Loss: 0.560573\n",
      "Reconstruction: 0.373569, Regularization: 0.122026, Discriminator: 0.043324; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:54,280 root         INFO     ====> Epoch: 110 Average loss: 11.5440\n",
      "2019-04-09 23:34:54,307 root         INFO     Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 0.259133\n",
      "Reconstruction: 0.148998, Regularization: 0.045156, Discriminator: 0.043338; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:54,420 root         INFO     Train Epoch: 111 [512/8000 (6%)]\tTotal Loss: 0.248060\n",
      "Reconstruction: 0.139558, Regularization: 0.043513, Discriminator: 0.043338; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:54,530 root         INFO     Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 0.275366\n",
      "Reconstruction: 0.135178, Regularization: 0.075215, Discriminator: 0.043319; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:54,642 root         INFO     Train Epoch: 111 [1536/8000 (19%)]\tTotal Loss: 0.224580\n",
      "Reconstruction: 0.119515, Regularization: 0.040050, Discriminator: 0.043354; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:54,753 root         INFO     Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 0.204887\n",
      "Reconstruction: 0.109310, Regularization: 0.030587, Discriminator: 0.043341; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:54,865 root         INFO     Train Epoch: 111 [2560/8000 (32%)]\tTotal Loss: 0.251523\n",
      "Reconstruction: 0.146955, Regularization: 0.039596, Discriminator: 0.043320; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:54,976 root         INFO     Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 2.026076\n",
      "Reconstruction: 1.895433, Regularization: 0.065697, Discriminator: 0.043284; Generator: 0.021662,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:34:55,086 root         INFO     Train Epoch: 111 [3584/8000 (45%)]\tTotal Loss: 2.268466\n",
      "Reconstruction: 1.944169, Regularization: 0.259336, Discriminator: 0.043309; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:55,197 root         INFO     Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 0.239207\n",
      "Reconstruction: 0.143641, Regularization: 0.030576, Discriminator: 0.043329; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:55,307 root         INFO     Train Epoch: 111 [4608/8000 (58%)]\tTotal Loss: 0.243865\n",
      "Reconstruction: 0.147602, Regularization: 0.031283, Discriminator: 0.043313; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:55,418 root         INFO     Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 6.664232\n",
      "Reconstruction: 6.542994, Regularization: 0.056281, Discriminator: 0.043302; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:55,527 root         INFO     Train Epoch: 111 [5632/8000 (70%)]\tTotal Loss: 0.555165\n",
      "Reconstruction: 0.428338, Regularization: 0.061869, Discriminator: 0.043293; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:55,639 root         INFO     Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 0.265379\n",
      "Reconstruction: 0.138423, Regularization: 0.061963, Discriminator: 0.043337; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:55,751 root         INFO     Train Epoch: 111 [6656/8000 (83%)]\tTotal Loss: 1.964393\n",
      "Reconstruction: 1.772025, Regularization: 0.127385, Discriminator: 0.043340; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:55,863 root         INFO     Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 0.308965\n",
      "Reconstruction: 0.166164, Regularization: 0.077784, Discriminator: 0.043337; Generator: 0.021679,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:55,973 root         INFO     Train Epoch: 111 [7680/8000 (96%)]\tTotal Loss: 0.253995\n",
      "Reconstruction: 0.150621, Regularization: 0.038409, Discriminator: 0.043304; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:56,055 root         INFO     ====> Epoch: 111 Average loss: 1170.2137\n",
      "2019-04-09 23:34:56,083 root         INFO     Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 0.252634\n",
      "Reconstruction: 0.119763, Regularization: 0.067879, Discriminator: 0.043276; Generator: 0.021716,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:56,195 root         INFO     Train Epoch: 112 [512/8000 (6%)]\tTotal Loss: 0.264253\n",
      "Reconstruction: 0.155693, Regularization: 0.043578, Discriminator: 0.043336; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:56,307 root         INFO     Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 31.402943\n",
      "Reconstruction: 31.297228, Regularization: 0.040737, Discriminator: 0.043325; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:56,418 root         INFO     Train Epoch: 112 [1536/8000 (19%)]\tTotal Loss: 0.519934\n",
      "Reconstruction: 0.391139, Regularization: 0.063816, Discriminator: 0.043328; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:56,529 root         INFO     Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 0.344867\n",
      "Reconstruction: 0.232305, Regularization: 0.047580, Discriminator: 0.043325; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:56,641 root         INFO     Train Epoch: 112 [2560/8000 (32%)]\tTotal Loss: 0.272879\n",
      "Reconstruction: 0.149692, Regularization: 0.058205, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:56,749 root         INFO     Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 0.295513\n",
      "Reconstruction: 0.119814, Regularization: 0.110719, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:56,857 root         INFO     Train Epoch: 112 [3584/8000 (45%)]\tTotal Loss: 0.223552\n",
      "Reconstruction: 0.128257, Regularization: 0.030309, Discriminator: 0.043323; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:56,967 root         INFO     Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 0.267410\n",
      "Reconstruction: 0.141558, Regularization: 0.060858, Discriminator: 0.043327; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:57,077 root         INFO     Train Epoch: 112 [4608/8000 (58%)]\tTotal Loss: 18.982517\n",
      "Reconstruction: 18.866814, Regularization: 0.050706, Discriminator: 0.043332; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:57,187 root         INFO     Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 0.240244\n",
      "Reconstruction: 0.133700, Regularization: 0.041578, Discriminator: 0.043309; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:57,298 root         INFO     Train Epoch: 112 [5632/8000 (70%)]\tTotal Loss: 0.480338\n",
      "Reconstruction: 0.369137, Regularization: 0.046222, Discriminator: 0.043314; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:57,410 root         INFO     Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 0.248247\n",
      "Reconstruction: 0.108385, Regularization: 0.074869, Discriminator: 0.043314; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:57,521 root         INFO     Train Epoch: 112 [6656/8000 (83%)]\tTotal Loss: 0.326421\n",
      "Reconstruction: 0.201529, Regularization: 0.059904, Discriminator: 0.043285; Generator: 0.021702,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:34:57,632 root         INFO     Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 6006485.500000\n",
      "Reconstruction: 6006485.000000, Regularization: 0.340001, Discriminator: 0.043374; Generator: 0.021620,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:34:57,743 root         INFO     Train Epoch: 112 [7680/8000 (96%)]\tTotal Loss: 0.335237\n",
      "Reconstruction: 0.185094, Regularization: 0.085159, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:57,825 root         INFO     ====> Epoch: 112 Average loss: 26887.3433\n",
      "2019-04-09 23:34:57,853 root         INFO     Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 0.334270\n",
      "Reconstruction: 0.128030, Regularization: 0.141262, Discriminator: 0.043330; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:57,963 root         INFO     Train Epoch: 113 [512/8000 (6%)]\tTotal Loss: 0.291557\n",
      "Reconstruction: 0.172935, Regularization: 0.053641, Discriminator: 0.043317; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:58,074 root         INFO     Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 2.289022\n",
      "Reconstruction: 2.155118, Regularization: 0.068915, Discriminator: 0.043323; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:58,183 root         INFO     Train Epoch: 113 [1536/8000 (19%)]\tTotal Loss: 1.384293\n",
      "Reconstruction: 1.202925, Regularization: 0.116370, Discriminator: 0.043335; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:58,293 root         INFO     Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 0.238648\n",
      "Reconstruction: 0.132085, Regularization: 0.041573, Discriminator: 0.043327; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:58,403 root         INFO     Train Epoch: 113 [2560/8000 (32%)]\tTotal Loss: 0.781603\n",
      "Reconstruction: 0.657393, Regularization: 0.059231, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:58,512 root         INFO     Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 1.000505\n",
      "Reconstruction: 0.906794, Regularization: 0.028741, Discriminator: 0.043296; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:58,620 root         INFO     Train Epoch: 113 [3584/8000 (45%)]\tTotal Loss: 0.324249\n",
      "Reconstruction: 0.226939, Regularization: 0.032336, Discriminator: 0.043304; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:58,729 root         INFO     Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 1.017756\n",
      "Reconstruction: 0.831546, Regularization: 0.121230, Discriminator: 0.043347; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:58,838 root         INFO     Train Epoch: 113 [4608/8000 (58%)]\tTotal Loss: 0.217562\n",
      "Reconstruction: 0.112784, Regularization: 0.039804, Discriminator: 0.043310; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:58,947 root         INFO     Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 0.689314\n",
      "Reconstruction: 0.506440, Regularization: 0.117875, Discriminator: 0.043351; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:59,056 root         INFO     Train Epoch: 113 [5632/8000 (70%)]\tTotal Loss: 1.514889\n",
      "Reconstruction: 1.412409, Regularization: 0.037465, Discriminator: 0.043345; Generator: 0.021669,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:34:59,165 root         INFO     Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 0.203550\n",
      "Reconstruction: 0.111799, Regularization: 0.026767, Discriminator: 0.043310; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:59,274 root         INFO     Train Epoch: 113 [6656/8000 (83%)]\tTotal Loss: 0.186136\n",
      "Reconstruction: 0.091232, Regularization: 0.029904, Discriminator: 0.043333; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:59,383 root         INFO     Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 4.025579\n",
      "Reconstruction: 3.902023, Regularization: 0.058550, Discriminator: 0.043358; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:59,494 root         INFO     Train Epoch: 113 [7680/8000 (96%)]\tTotal Loss: 0.278106\n",
      "Reconstruction: 0.156694, Regularization: 0.056438, Discriminator: 0.043322; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:59,574 root         INFO     ====> Epoch: 113 Average loss: 523.2528\n",
      "2019-04-09 23:34:59,601 root         INFO     Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 0.205053\n",
      "Reconstruction: 0.096066, Regularization: 0.043982, Discriminator: 0.043345; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:59,714 root         INFO     Train Epoch: 114 [512/8000 (6%)]\tTotal Loss: 0.285154\n",
      "Reconstruction: 0.126789, Regularization: 0.093377, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:59,826 root         INFO     Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 0.304277\n",
      "Reconstruction: 0.214063, Regularization: 0.025227, Discriminator: 0.043345; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:34:59,938 root         INFO     Train Epoch: 114 [1536/8000 (19%)]\tTotal Loss: 0.326992\n",
      "Reconstruction: 0.163426, Regularization: 0.098590, Discriminator: 0.043319; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:00,049 root         INFO     Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 0.234484\n",
      "Reconstruction: 0.127689, Regularization: 0.041816, Discriminator: 0.043331; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:00,160 root         INFO     Train Epoch: 114 [2560/8000 (32%)]\tTotal Loss: 0.202465\n",
      "Reconstruction: 0.107339, Regularization: 0.030131, Discriminator: 0.043322; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:00,272 root         INFO     Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 0.250482\n",
      "Reconstruction: 0.123797, Regularization: 0.061695, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:00,383 root         INFO     Train Epoch: 114 [3584/8000 (45%)]\tTotal Loss: 0.255652\n",
      "Reconstruction: 0.157789, Regularization: 0.032876, Discriminator: 0.043334; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:00,493 root         INFO     Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 0.742218\n",
      "Reconstruction: 0.568373, Regularization: 0.108872, Discriminator: 0.043302; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:00,603 root         INFO     Train Epoch: 114 [4608/8000 (58%)]\tTotal Loss: 0.316802\n",
      "Reconstruction: 0.186178, Regularization: 0.065655, Discriminator: 0.043293; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:00,711 root         INFO     Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 0.238908\n",
      "Reconstruction: 0.115231, Regularization: 0.058699, Discriminator: 0.043310; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:00,820 root         INFO     Train Epoch: 114 [5632/8000 (70%)]\tTotal Loss: 0.194816\n",
      "Reconstruction: 0.101498, Regularization: 0.028316, Discriminator: 0.043355; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:00,929 root         INFO     Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 4.120869\n",
      "Reconstruction: 3.886499, Regularization: 0.169404, Discriminator: 0.043316; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:01,038 root         INFO     Train Epoch: 114 [6656/8000 (83%)]\tTotal Loss: 0.222122\n",
      "Reconstruction: 0.109329, Regularization: 0.047813, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:01,147 root         INFO     Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 0.333686\n",
      "Reconstruction: 0.211304, Regularization: 0.057403, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:01,265 root         INFO     Train Epoch: 114 [7680/8000 (96%)]\tTotal Loss: 0.311756\n",
      "Reconstruction: 0.174031, Regularization: 0.072752, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:01,350 root         INFO     ====> Epoch: 114 Average loss: 62.7814\n",
      "2019-04-09 23:35:01,377 root         INFO     Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 0.198588\n",
      "Reconstruction: 0.106140, Regularization: 0.027486, Discriminator: 0.043301; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:01,492 root         INFO     Train Epoch: 115 [512/8000 (6%)]\tTotal Loss: 0.223005\n",
      "Reconstruction: 0.118639, Regularization: 0.039384, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:01,605 root         INFO     Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 35.436646\n",
      "Reconstruction: 35.209141, Regularization: 0.162521, Discriminator: 0.043280; Generator: 0.021702,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:01,714 root         INFO     Train Epoch: 115 [1536/8000 (19%)]\tTotal Loss: 0.252359\n",
      "Reconstruction: 0.126277, Regularization: 0.061112, Discriminator: 0.043340; Generator: 0.021631,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:01,823 root         INFO     Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 0.250958\n",
      "Reconstruction: 0.117978, Regularization: 0.067988, Discriminator: 0.043333; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:01,932 root         INFO     Train Epoch: 115 [2560/8000 (32%)]\tTotal Loss: 1.020308\n",
      "Reconstruction: 0.904054, Regularization: 0.051225, Discriminator: 0.043396; Generator: 0.021634,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:02,041 root         INFO     Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 1.757392\n",
      "Reconstruction: 1.604666, Regularization: 0.087717, Discriminator: 0.043298; Generator: 0.021712,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:02,150 root         INFO     Train Epoch: 115 [3584/8000 (45%)]\tTotal Loss: 1.388732\n",
      "Reconstruction: 1.206215, Regularization: 0.117569, Discriminator: 0.043295; Generator: 0.021653,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:02,259 root         INFO     Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 0.234962\n",
      "Reconstruction: 0.114374, Regularization: 0.055582, Discriminator: 0.043320; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:02,368 root         INFO     Train Epoch: 115 [4608/8000 (58%)]\tTotal Loss: 0.223351\n",
      "Reconstruction: 0.122305, Regularization: 0.036044, Discriminator: 0.043319; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:02,477 root         INFO     Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 0.349819\n",
      "Reconstruction: 0.214223, Regularization: 0.070611, Discriminator: 0.043339; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:02,587 root         INFO     Train Epoch: 115 [5632/8000 (70%)]\tTotal Loss: 0.299320\n",
      "Reconstruction: 0.168399, Regularization: 0.065934, Discriminator: 0.043319; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:02,699 root         INFO     Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 0.653100\n",
      "Reconstruction: 0.488759, Regularization: 0.099343, Discriminator: 0.043327; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:02,813 root         INFO     Train Epoch: 115 [6656/8000 (83%)]\tTotal Loss: 0.460246\n",
      "Reconstruction: 0.260081, Regularization: 0.135172, Discriminator: 0.043323; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:02,926 root         INFO     Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 0.907426\n",
      "Reconstruction: 0.759511, Regularization: 0.082941, Discriminator: 0.043297; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:03,040 root         INFO     Train Epoch: 115 [7680/8000 (96%)]\tTotal Loss: 0.227903\n",
      "Reconstruction: 0.119850, Regularization: 0.043082, Discriminator: 0.043310; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:03,122 root         INFO     ====> Epoch: 115 Average loss: 1625.2017\n",
      "2019-04-09 23:35:03,149 root         INFO     Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 0.836488\n",
      "Reconstruction: 0.727184, Regularization: 0.044325, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:03,266 root         INFO     Train Epoch: 116 [512/8000 (6%)]\tTotal Loss: 0.399673\n",
      "Reconstruction: 0.242124, Regularization: 0.092584, Discriminator: 0.043343; Generator: 0.021622,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:03,380 root         INFO     Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 0.219772\n",
      "Reconstruction: 0.127371, Regularization: 0.027363, Discriminator: 0.043365; Generator: 0.021674,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:03,496 root         INFO     Train Epoch: 116 [1536/8000 (19%)]\tTotal Loss: 0.224040\n",
      "Reconstruction: 0.122121, Regularization: 0.036913, Discriminator: 0.043357; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:03,610 root         INFO     Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 1.633466\n",
      "Reconstruction: 1.513423, Regularization: 0.055074, Discriminator: 0.043331; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:03,725 root         INFO     Train Epoch: 116 [2560/8000 (32%)]\tTotal Loss: 0.329183\n",
      "Reconstruction: 0.136934, Regularization: 0.127276, Discriminator: 0.043309; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:03,841 root         INFO     Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 0.263759\n",
      "Reconstruction: 0.153027, Regularization: 0.045749, Discriminator: 0.043301; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:03,956 root         INFO     Train Epoch: 116 [3584/8000 (45%)]\tTotal Loss: 0.308052\n",
      "Reconstruction: 0.190324, Regularization: 0.052773, Discriminator: 0.043285; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:04,071 root         INFO     Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 0.455407\n",
      "Reconstruction: 0.323571, Regularization: 0.066862, Discriminator: 0.043310; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:04,187 root         INFO     Train Epoch: 116 [4608/8000 (58%)]\tTotal Loss: 256.149872\n",
      "Reconstruction: 255.993530, Regularization: 0.091369, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:04,301 root         INFO     Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 1545.070068\n",
      "Reconstruction: 1544.848877, Regularization: 0.156226, Discriminator: 0.043318; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:04,416 root         INFO     Train Epoch: 116 [5632/8000 (70%)]\tTotal Loss: 0.363817\n",
      "Reconstruction: 0.192644, Regularization: 0.106171, Discriminator: 0.043332; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:04,530 root         INFO     Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 0.275231\n",
      "Reconstruction: 0.152032, Regularization: 0.058228, Discriminator: 0.043320; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:04,644 root         INFO     Train Epoch: 116 [6656/8000 (83%)]\tTotal Loss: 0.322610\n",
      "Reconstruction: 0.205570, Regularization: 0.052058, Discriminator: 0.043300; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:04,759 root         INFO     Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 0.290255\n",
      "Reconstruction: 0.152501, Regularization: 0.072748, Discriminator: 0.043321; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:04,876 root         INFO     Train Epoch: 116 [7680/8000 (96%)]\tTotal Loss: 0.585908\n",
      "Reconstruction: 0.432793, Regularization: 0.088150, Discriminator: 0.043290; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:04,961 root         INFO     ====> Epoch: 116 Average loss: 93283.3126\n",
      "2019-04-09 23:35:04,988 root         INFO     Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 1.815269\n",
      "Reconstruction: 1.668152, Regularization: 0.082140, Discriminator: 0.043298; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:05,111 root         INFO     Train Epoch: 117 [512/8000 (6%)]\tTotal Loss: 0.245261\n",
      "Reconstruction: 0.149615, Regularization: 0.030665, Discriminator: 0.043283; Generator: 0.021698,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:05,250 root         INFO     Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 0.253665\n",
      "Reconstruction: 0.153282, Regularization: 0.035437, Discriminator: 0.043249; Generator: 0.021696,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:35:05,376 root         INFO     Train Epoch: 117 [1536/8000 (19%)]\tTotal Loss: 0.313175\n",
      "Reconstruction: 0.152718, Regularization: 0.095523, Discriminator: 0.043270; Generator: 0.021664,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:05,522 root         INFO     Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 0.419941\n",
      "Reconstruction: 0.243433, Regularization: 0.111503, Discriminator: 0.043336; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:05,668 root         INFO     Train Epoch: 117 [2560/8000 (32%)]\tTotal Loss: 0.272901\n",
      "Reconstruction: 0.152439, Regularization: 0.055477, Discriminator: 0.043305; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:05,789 root         INFO     Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 0.292611\n",
      "Reconstruction: 0.185569, Regularization: 0.042111, Discriminator: 0.043299; Generator: 0.021632,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:05,901 root         INFO     Train Epoch: 117 [3584/8000 (45%)]\tTotal Loss: 0.236060\n",
      "Reconstruction: 0.121061, Regularization: 0.049976, Discriminator: 0.043356; Generator: 0.021667,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:06,014 root         INFO     Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 0.442747\n",
      "Reconstruction: 0.123926, Regularization: 0.253832, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:06,123 root         INFO     Train Epoch: 117 [4608/8000 (58%)]\tTotal Loss: 0.843804\n",
      "Reconstruction: 0.697027, Regularization: 0.081787, Discriminator: 0.043316; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:06,232 root         INFO     Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 0.319569\n",
      "Reconstruction: 0.208745, Regularization: 0.045834, Discriminator: 0.043340; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:06,341 root         INFO     Train Epoch: 117 [5632/8000 (70%)]\tTotal Loss: 0.239179\n",
      "Reconstruction: 0.124109, Regularization: 0.050109, Discriminator: 0.043275; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:06,449 root         INFO     Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 0.275963\n",
      "Reconstruction: 0.179325, Regularization: 0.031663, Discriminator: 0.043285; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:06,558 root         INFO     Train Epoch: 117 [6656/8000 (83%)]\tTotal Loss: 0.262356\n",
      "Reconstruction: 0.124901, Regularization: 0.072529, Discriminator: 0.043211; Generator: 0.021714,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:35:06,666 root         INFO     Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 0.411833\n",
      "Reconstruction: 0.171129, Regularization: 0.175723, Discriminator: 0.043313; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:06,775 root         INFO     Train Epoch: 117 [7680/8000 (96%)]\tTotal Loss: 0.292908\n",
      "Reconstruction: 0.164930, Regularization: 0.063035, Discriminator: 0.043257; Generator: 0.021686,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:06,856 root         INFO     ====> Epoch: 117 Average loss: 24.4772\n",
      "2019-04-09 23:35:06,883 root         INFO     Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 0.315362\n",
      "Reconstruction: 0.181289, Regularization: 0.069104, Discriminator: 0.043269; Generator: 0.021699,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:06,995 root         INFO     Train Epoch: 118 [512/8000 (6%)]\tTotal Loss: 0.406612\n",
      "Reconstruction: 0.274833, Regularization: 0.066801, Discriminator: 0.043303; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:07,106 root         INFO     Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 0.326144\n",
      "Reconstruction: 0.203948, Regularization: 0.057210, Discriminator: 0.043367; Generator: 0.021618,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:07,217 root         INFO     Train Epoch: 118 [1536/8000 (19%)]\tTotal Loss: 2.092426\n",
      "Reconstruction: 1.914598, Regularization: 0.112852, Discriminator: 0.043354; Generator: 0.021621,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:07,328 root         INFO     Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 0.344363\n",
      "Reconstruction: 0.147430, Regularization: 0.131953, Discriminator: 0.043341; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:07,440 root         INFO     Train Epoch: 118 [2560/8000 (32%)]\tTotal Loss: 0.310850\n",
      "Reconstruction: 0.138328, Regularization: 0.107547, Discriminator: 0.043333; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:07,550 root         INFO     Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 0.356231\n",
      "Reconstruction: 0.186551, Regularization: 0.104680, Discriminator: 0.043337; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:07,661 root         INFO     Train Epoch: 118 [3584/8000 (45%)]\tTotal Loss: 0.218489\n",
      "Reconstruction: 0.123059, Regularization: 0.030440, Discriminator: 0.043331; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:07,771 root         INFO     Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 1.765458\n",
      "Reconstruction: 1.629399, Regularization: 0.071085, Discriminator: 0.043324; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:07,884 root         INFO     Train Epoch: 118 [4608/8000 (58%)]\tTotal Loss: 46.502838\n",
      "Reconstruction: 46.327702, Regularization: 0.110129, Discriminator: 0.043344; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:07,998 root         INFO     Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 0.405076\n",
      "Reconstruction: 0.238209, Regularization: 0.101886, Discriminator: 0.043323; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:08,112 root         INFO     Train Epoch: 118 [5632/8000 (70%)]\tTotal Loss: 0.245643\n",
      "Reconstruction: 0.118788, Regularization: 0.061866, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:08,226 root         INFO     Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 0.209489\n",
      "Reconstruction: 0.106645, Regularization: 0.037860, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:08,341 root         INFO     Train Epoch: 118 [6656/8000 (83%)]\tTotal Loss: 0.230724\n",
      "Reconstruction: 0.110093, Regularization: 0.055649, Discriminator: 0.043328; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:08,455 root         INFO     Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 0.244994\n",
      "Reconstruction: 0.137165, Regularization: 0.042855, Discriminator: 0.043325; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:08,569 root         INFO     Train Epoch: 118 [7680/8000 (96%)]\tTotal Loss: 0.325737\n",
      "Reconstruction: 0.129439, Regularization: 0.131317, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:08,651 root         INFO     ====> Epoch: 118 Average loss: 294.5071\n",
      "2019-04-09 23:35:08,678 root         INFO     Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 0.238483\n",
      "Reconstruction: 0.121765, Regularization: 0.051753, Discriminator: 0.043290; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:08,791 root         INFO     Train Epoch: 119 [512/8000 (6%)]\tTotal Loss: 0.216717\n",
      "Reconstruction: 0.104999, Regularization: 0.046752, Discriminator: 0.043300; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:08,905 root         INFO     Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 0.344520\n",
      "Reconstruction: 0.146557, Regularization: 0.132977, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:09,017 root         INFO     Train Epoch: 119 [1536/8000 (19%)]\tTotal Loss: 0.194346\n",
      "Reconstruction: 0.102791, Regularization: 0.026614, Discriminator: 0.043256; Generator: 0.021685,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:09,129 root         INFO     Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 0.954952\n",
      "Reconstruction: 0.832646, Regularization: 0.057299, Discriminator: 0.043357; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:09,242 root         INFO     Train Epoch: 119 [2560/8000 (32%)]\tTotal Loss: 0.269452\n",
      "Reconstruction: 0.142072, Regularization: 0.062381, Discriminator: 0.043360; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:09,354 root         INFO     Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 1.294068\n",
      "Reconstruction: 1.143282, Regularization: 0.085771, Discriminator: 0.043396; Generator: 0.021619,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:35:09,466 root         INFO     Train Epoch: 119 [3584/8000 (45%)]\tTotal Loss: 0.235330\n",
      "Reconstruction: 0.141259, Regularization: 0.029105, Discriminator: 0.043273; Generator: 0.021693,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:09,578 root         INFO     Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 0.471665\n",
      "Reconstruction: 0.351485, Regularization: 0.055195, Discriminator: 0.043279; Generator: 0.021706,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:09,692 root         INFO     Train Epoch: 119 [4608/8000 (58%)]\tTotal Loss: 0.249901\n",
      "Reconstruction: 0.145434, Regularization: 0.039463, Discriminator: 0.043329; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:09,804 root         INFO     Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 0.668596\n",
      "Reconstruction: 0.522500, Regularization: 0.081111, Discriminator: 0.043336; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:09,915 root         INFO     Train Epoch: 119 [5632/8000 (70%)]\tTotal Loss: 0.295783\n",
      "Reconstruction: 0.131500, Regularization: 0.099309, Discriminator: 0.043325; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:10,027 root         INFO     Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 0.224233\n",
      "Reconstruction: 0.121735, Regularization: 0.037502, Discriminator: 0.043352; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:10,138 root         INFO     Train Epoch: 119 [6656/8000 (83%)]\tTotal Loss: 0.456703\n",
      "Reconstruction: 0.286937, Regularization: 0.104761, Discriminator: 0.043334; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:10,249 root         INFO     Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 0.245785\n",
      "Reconstruction: 0.133212, Regularization: 0.047604, Discriminator: 0.043309; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:10,361 root         INFO     Train Epoch: 119 [7680/8000 (96%)]\tTotal Loss: 0.236935\n",
      "Reconstruction: 0.120756, Regularization: 0.051186, Discriminator: 0.043333; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:10,442 root         INFO     ====> Epoch: 119 Average loss: 30.4519\n",
      "2019-04-09 23:35:10,469 root         INFO     Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 0.235848\n",
      "Reconstruction: 0.136887, Regularization: 0.033984, Discriminator: 0.043308; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:10,581 root         INFO     Train Epoch: 120 [512/8000 (6%)]\tTotal Loss: 0.217735\n",
      "Reconstruction: 0.124899, Regularization: 0.027864, Discriminator: 0.043279; Generator: 0.021693,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:10,693 root         INFO     Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 24.282290\n",
      "Reconstruction: 24.130260, Regularization: 0.087083, Discriminator: 0.043286; Generator: 0.021662,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:10,804 root         INFO     Train Epoch: 120 [1536/8000 (19%)]\tTotal Loss: 0.274364\n",
      "Reconstruction: 0.175593, Regularization: 0.033790, Discriminator: 0.043306; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:10,916 root         INFO     Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 0.335323\n",
      "Reconstruction: 0.244825, Regularization: 0.025529, Discriminator: 0.043338; Generator: 0.021632,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:11,027 root         INFO     Train Epoch: 120 [2560/8000 (32%)]\tTotal Loss: 0.349499\n",
      "Reconstruction: 0.202825, Regularization: 0.081715, Discriminator: 0.043272; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:11,139 root         INFO     Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 3.121924\n",
      "Reconstruction: 2.966473, Regularization: 0.090491, Discriminator: 0.043336; Generator: 0.021623,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:11,251 root         INFO     Train Epoch: 120 [3584/8000 (45%)]\tTotal Loss: 0.315815\n",
      "Reconstruction: 0.196301, Regularization: 0.054523, Discriminator: 0.043316; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:11,363 root         INFO     Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 0.626574\n",
      "Reconstruction: 0.498632, Regularization: 0.062942, Discriminator: 0.043307; Generator: 0.021694,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:11,475 root         INFO     Train Epoch: 120 [4608/8000 (58%)]\tTotal Loss: 0.473047\n",
      "Reconstruction: 0.353257, Regularization: 0.054794, Discriminator: 0.043344; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:11,588 root         INFO     Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 3.822977\n",
      "Reconstruction: 3.700172, Regularization: 0.057808, Discriminator: 0.043313; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:11,700 root         INFO     Train Epoch: 120 [5632/8000 (70%)]\tTotal Loss: 1.826235\n",
      "Reconstruction: 1.670918, Regularization: 0.090342, Discriminator: 0.043326; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:11,813 root         INFO     Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 0.241320\n",
      "Reconstruction: 0.140007, Regularization: 0.036311, Discriminator: 0.043351; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:11,925 root         INFO     Train Epoch: 120 [6656/8000 (83%)]\tTotal Loss: 0.229671\n",
      "Reconstruction: 0.124457, Regularization: 0.040219, Discriminator: 0.043340; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:12,037 root         INFO     Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 0.308632\n",
      "Reconstruction: 0.149432, Regularization: 0.094218, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:12,149 root         INFO     Train Epoch: 120 [7680/8000 (96%)]\tTotal Loss: 0.324725\n",
      "Reconstruction: 0.189783, Regularization: 0.069960, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:12,231 root         INFO     ====> Epoch: 120 Average loss: 5222.9307\n",
      "2019-04-09 23:35:12,258 root         INFO     Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 0.293298\n",
      "Reconstruction: 0.194532, Regularization: 0.033788, Discriminator: 0.043315; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:12,371 root         INFO     Train Epoch: 121 [512/8000 (6%)]\tTotal Loss: 0.302410\n",
      "Reconstruction: 0.156181, Regularization: 0.081256, Discriminator: 0.043309; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:12,482 root         INFO     Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 1.311342\n",
      "Reconstruction: 1.176786, Regularization: 0.069569, Discriminator: 0.043316; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:12,593 root         INFO     Train Epoch: 121 [1536/8000 (19%)]\tTotal Loss: 2.412592\n",
      "Reconstruction: 2.264398, Regularization: 0.083197, Discriminator: 0.043354; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:12,704 root         INFO     Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 0.569294\n",
      "Reconstruction: 0.425507, Regularization: 0.078826, Discriminator: 0.043322; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:12,815 root         INFO     Train Epoch: 121 [2560/8000 (32%)]\tTotal Loss: 0.230837\n",
      "Reconstruction: 0.113320, Regularization: 0.052539, Discriminator: 0.043329; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:12,925 root         INFO     Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 0.220497\n",
      "Reconstruction: 0.110343, Regularization: 0.045192, Discriminator: 0.043281; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:13,034 root         INFO     Train Epoch: 121 [3584/8000 (45%)]\tTotal Loss: 0.245951\n",
      "Reconstruction: 0.122294, Regularization: 0.058695, Discriminator: 0.043313; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:13,143 root         INFO     Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 715.929016\n",
      "Reconstruction: 715.772766, Regularization: 0.091234, Discriminator: 0.043375; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:13,252 root         INFO     Train Epoch: 121 [4608/8000 (58%)]\tTotal Loss: 17.689312\n",
      "Reconstruction: 17.575565, Regularization: 0.048749, Discriminator: 0.043345; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:13,362 root         INFO     Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 0.210412\n",
      "Reconstruction: 0.111621, Regularization: 0.033848, Discriminator: 0.043298; Generator: 0.021645,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:13,472 root         INFO     Train Epoch: 121 [5632/8000 (70%)]\tTotal Loss: 0.229170\n",
      "Reconstruction: 0.115354, Regularization: 0.048866, Discriminator: 0.043320; Generator: 0.021631,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:13,582 root         INFO     Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 0.505787\n",
      "Reconstruction: 0.383407, Regularization: 0.057369, Discriminator: 0.043365; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:13,692 root         INFO     Train Epoch: 121 [6656/8000 (83%)]\tTotal Loss: 0.564345\n",
      "Reconstruction: 0.440357, Regularization: 0.059009, Discriminator: 0.043376; Generator: 0.021603,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:13,803 root         INFO     Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 0.239107\n",
      "Reconstruction: 0.135623, Regularization: 0.038479, Discriminator: 0.043326; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:13,914 root         INFO     Train Epoch: 121 [7680/8000 (96%)]\tTotal Loss: 0.529584\n",
      "Reconstruction: 0.381826, Regularization: 0.082757, Discriminator: 0.043323; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:13,996 root         INFO     ====> Epoch: 121 Average loss: 134497.5004\n",
      "2019-04-09 23:35:14,023 root         INFO     Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 0.368791\n",
      "Reconstruction: 0.232352, Regularization: 0.071444, Discriminator: 0.043349; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:14,136 root         INFO     Train Epoch: 122 [512/8000 (6%)]\tTotal Loss: 0.206851\n",
      "Reconstruction: 0.116527, Regularization: 0.025348, Discriminator: 0.043317; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:14,248 root         INFO     Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 0.335069\n",
      "Reconstruction: 0.246285, Regularization: 0.023777, Discriminator: 0.043333; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:14,358 root         INFO     Train Epoch: 122 [1536/8000 (19%)]\tTotal Loss: 0.626623\n",
      "Reconstruction: 0.450651, Regularization: 0.110985, Discriminator: 0.043324; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:14,468 root         INFO     Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 4237.004883\n",
      "Reconstruction: 4236.710449, Regularization: 0.229264, Discriminator: 0.043308; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:14,577 root         INFO     Train Epoch: 122 [2560/8000 (32%)]\tTotal Loss: 0.233496\n",
      "Reconstruction: 0.137166, Regularization: 0.031348, Discriminator: 0.043329; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:14,687 root         INFO     Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 0.224051\n",
      "Reconstruction: 0.110855, Regularization: 0.048215, Discriminator: 0.043309; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:14,798 root         INFO     Train Epoch: 122 [3584/8000 (45%)]\tTotal Loss: 2.727409\n",
      "Reconstruction: 2.512938, Regularization: 0.149467, Discriminator: 0.043260; Generator: 0.021744,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:14,908 root         INFO     Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 0.272861\n",
      "Reconstruction: 0.137750, Regularization: 0.070124, Discriminator: 0.043366; Generator: 0.021621,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:15,019 root         INFO     Train Epoch: 122 [4608/8000 (58%)]\tTotal Loss: 2.179908\n",
      "Reconstruction: 2.001930, Regularization: 0.113049, Discriminator: 0.043278; Generator: 0.021652,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:15,129 root         INFO     Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 0.282481\n",
      "Reconstruction: 0.133064, Regularization: 0.084458, Discriminator: 0.043302; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:15,240 root         INFO     Train Epoch: 122 [5632/8000 (70%)]\tTotal Loss: 0.279741\n",
      "Reconstruction: 0.145256, Regularization: 0.069506, Discriminator: 0.043312; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:15,350 root         INFO     Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 0.513511\n",
      "Reconstruction: 0.382064, Regularization: 0.066457, Discriminator: 0.043388; Generator: 0.021603,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:15,461 root         INFO     Train Epoch: 122 [6656/8000 (83%)]\tTotal Loss: 0.515420\n",
      "Reconstruction: 0.407296, Regularization: 0.043089, Discriminator: 0.043437; Generator: 0.021599,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:35:15,572 root         INFO     Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 0.366102\n",
      "Reconstruction: 0.216295, Regularization: 0.084814, Discriminator: 0.043306; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:15,682 root         INFO     Train Epoch: 122 [7680/8000 (96%)]\tTotal Loss: 0.263737\n",
      "Reconstruction: 0.164978, Regularization: 0.033708, Discriminator: 0.043427; Generator: 0.021625,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:35:15,763 root         INFO     ====> Epoch: 122 Average loss: 211.1987\n",
      "2019-04-09 23:35:15,790 root         INFO     Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 0.233262\n",
      "Reconstruction: 0.131426, Regularization: 0.036821, Discriminator: 0.043338; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:15,901 root         INFO     Train Epoch: 123 [512/8000 (6%)]\tTotal Loss: 0.260110\n",
      "Reconstruction: 0.140919, Regularization: 0.054187, Discriminator: 0.043343; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:16,011 root         INFO     Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 0.215490\n",
      "Reconstruction: 0.108756, Regularization: 0.041712, Discriminator: 0.043347; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:16,122 root         INFO     Train Epoch: 123 [1536/8000 (19%)]\tTotal Loss: 0.206485\n",
      "Reconstruction: 0.113550, Regularization: 0.027946, Discriminator: 0.043338; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:16,232 root         INFO     Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 0.917499\n",
      "Reconstruction: 0.762625, Regularization: 0.089891, Discriminator: 0.043331; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:16,342 root         INFO     Train Epoch: 123 [2560/8000 (32%)]\tTotal Loss: 24.173792\n",
      "Reconstruction: 24.019703, Regularization: 0.089110, Discriminator: 0.043325; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:16,452 root         INFO     Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 1.637249\n",
      "Reconstruction: 1.470818, Regularization: 0.101456, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:16,563 root         INFO     Train Epoch: 123 [3584/8000 (45%)]\tTotal Loss: 0.317593\n",
      "Reconstruction: 0.165191, Regularization: 0.087406, Discriminator: 0.043333; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:16,673 root         INFO     Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 0.203695\n",
      "Reconstruction: 0.111319, Regularization: 0.027402, Discriminator: 0.043288; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:16,783 root         INFO     Train Epoch: 123 [4608/8000 (58%)]\tTotal Loss: 0.649638\n",
      "Reconstruction: 0.535572, Regularization: 0.049070, Discriminator: 0.043324; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:16,894 root         INFO     Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 0.230149\n",
      "Reconstruction: 0.140720, Regularization: 0.024445, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:17,004 root         INFO     Train Epoch: 123 [5632/8000 (70%)]\tTotal Loss: 0.269988\n",
      "Reconstruction: 0.142265, Regularization: 0.062742, Discriminator: 0.043357; Generator: 0.021623,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:17,114 root         INFO     Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 0.263461\n",
      "Reconstruction: 0.162685, Regularization: 0.035817, Discriminator: 0.043261; Generator: 0.021698,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:17,225 root         INFO     Train Epoch: 123 [6656/8000 (83%)]\tTotal Loss: 1.930969\n",
      "Reconstruction: 1.769333, Regularization: 0.096630, Discriminator: 0.043348; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:17,336 root         INFO     Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 0.265099\n",
      "Reconstruction: 0.130490, Regularization: 0.069597, Discriminator: 0.043241; Generator: 0.021770,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 23:35:17,446 root         INFO     Train Epoch: 123 [7680/8000 (96%)]\tTotal Loss: 0.301538\n",
      "Reconstruction: 0.151489, Regularization: 0.085001, Discriminator: 0.043356; Generator: 0.021691,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:17,527 root         INFO     ====> Epoch: 123 Average loss: 311.3748\n",
      "2019-04-09 23:35:17,555 root         INFO     Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 0.314481\n",
      "Reconstruction: 0.131929, Regularization: 0.117587, Discriminator: 0.043325; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:17,665 root         INFO     Train Epoch: 124 [512/8000 (6%)]\tTotal Loss: 0.219970\n",
      "Reconstruction: 0.122700, Regularization: 0.032315, Discriminator: 0.043270; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:17,774 root         INFO     Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 0.333476\n",
      "Reconstruction: 0.205297, Regularization: 0.063152, Discriminator: 0.043361; Generator: 0.021666,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:17,883 root         INFO     Train Epoch: 124 [1536/8000 (19%)]\tTotal Loss: 0.264989\n",
      "Reconstruction: 0.128909, Regularization: 0.071086, Discriminator: 0.043330; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:17,993 root         INFO     Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 0.687688\n",
      "Reconstruction: 0.526875, Regularization: 0.095818, Discriminator: 0.043335; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:18,102 root         INFO     Train Epoch: 124 [2560/8000 (32%)]\tTotal Loss: 1.582998\n",
      "Reconstruction: 1.423657, Regularization: 0.094360, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:18,211 root         INFO     Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 0.233725\n",
      "Reconstruction: 0.138704, Regularization: 0.030037, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:18,320 root         INFO     Train Epoch: 124 [3584/8000 (45%)]\tTotal Loss: 0.334912\n",
      "Reconstruction: 0.158209, Regularization: 0.111721, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:18,430 root         INFO     Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 0.353796\n",
      "Reconstruction: 0.140436, Regularization: 0.148377, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:18,540 root         INFO     Train Epoch: 124 [4608/8000 (58%)]\tTotal Loss: 0.268584\n",
      "Reconstruction: 0.159249, Regularization: 0.044347, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:18,649 root         INFO     Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 0.318611\n",
      "Reconstruction: 0.211485, Regularization: 0.042137, Discriminator: 0.043334; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:18,759 root         INFO     Train Epoch: 124 [5632/8000 (70%)]\tTotal Loss: 0.335085\n",
      "Reconstruction: 0.192380, Regularization: 0.077720, Discriminator: 0.043337; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:18,868 root         INFO     Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 0.274741\n",
      "Reconstruction: 0.171335, Regularization: 0.038412, Discriminator: 0.043340; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:18,978 root         INFO     Train Epoch: 124 [6656/8000 (83%)]\tTotal Loss: 0.447645\n",
      "Reconstruction: 0.311062, Regularization: 0.071618, Discriminator: 0.043290; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:19,087 root         INFO     Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 45364372.000000\n",
      "Reconstruction: 45364372.000000, Regularization: 0.428557, Discriminator: 0.043271; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:19,196 root         INFO     Train Epoch: 124 [7680/8000 (96%)]\tTotal Loss: 0.285810\n",
      "Reconstruction: 0.143976, Regularization: 0.076862, Discriminator: 0.043325; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:19,276 root         INFO     ====> Epoch: 124 Average loss: 1370029.3766\n",
      "2019-04-09 23:35:19,304 root         INFO     Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 0.361754\n",
      "Reconstruction: 0.181814, Regularization: 0.114975, Discriminator: 0.043285; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:19,411 root         INFO     Train Epoch: 125 [512/8000 (6%)]\tTotal Loss: 0.236116\n",
      "Reconstruction: 0.129782, Regularization: 0.041343, Discriminator: 0.043311; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:19,518 root         INFO     Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 0.697498\n",
      "Reconstruction: 0.593394, Regularization: 0.039097, Discriminator: 0.043323; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:19,625 root         INFO     Train Epoch: 125 [1536/8000 (19%)]\tTotal Loss: 0.614716\n",
      "Reconstruction: 0.464003, Regularization: 0.085739, Discriminator: 0.043323; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:19,732 root         INFO     Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 2.325177\n",
      "Reconstruction: 2.173527, Regularization: 0.086673, Discriminator: 0.043320; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:19,839 root         INFO     Train Epoch: 125 [2560/8000 (32%)]\tTotal Loss: 0.225001\n",
      "Reconstruction: 0.125590, Regularization: 0.034439, Discriminator: 0.043312; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:19,946 root         INFO     Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 0.411452\n",
      "Reconstruction: 0.285756, Regularization: 0.060718, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:20,052 root         INFO     Train Epoch: 125 [3584/8000 (45%)]\tTotal Loss: 0.344367\n",
      "Reconstruction: 0.239483, Regularization: 0.039893, Discriminator: 0.043327; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:20,159 root         INFO     Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 1.329967\n",
      "Reconstruction: 1.208988, Regularization: 0.055997, Discriminator: 0.043325; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:20,266 root         INFO     Train Epoch: 125 [4608/8000 (58%)]\tTotal Loss: 0.536525\n",
      "Reconstruction: 0.355663, Regularization: 0.115874, Discriminator: 0.043321; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:20,374 root         INFO     Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 0.312289\n",
      "Reconstruction: 0.212257, Regularization: 0.035042, Discriminator: 0.043323; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:20,482 root         INFO     Train Epoch: 125 [5632/8000 (70%)]\tTotal Loss: 0.266464\n",
      "Reconstruction: 0.142009, Regularization: 0.059478, Discriminator: 0.043310; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:20,589 root         INFO     Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 0.262096\n",
      "Reconstruction: 0.124858, Regularization: 0.072258, Discriminator: 0.043317; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:20,697 root         INFO     Train Epoch: 125 [6656/8000 (83%)]\tTotal Loss: 0.324689\n",
      "Reconstruction: 0.223753, Regularization: 0.035958, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:20,804 root         INFO     Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 37.906658\n",
      "Reconstruction: 37.798084, Regularization: 0.043589, Discriminator: 0.043315; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:20,912 root         INFO     Train Epoch: 125 [7680/8000 (96%)]\tTotal Loss: 1.462585\n",
      "Reconstruction: 1.311444, Regularization: 0.086149, Discriminator: 0.043318; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:20,991 root         INFO     ====> Epoch: 125 Average loss: 75163.7841\n",
      "2019-04-09 23:35:21,018 root         INFO     Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 0.210656\n",
      "Reconstruction: 0.116437, Regularization: 0.029231, Discriminator: 0.043336; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:21,128 root         INFO     Train Epoch: 126 [512/8000 (6%)]\tTotal Loss: 0.457044\n",
      "Reconstruction: 0.304970, Regularization: 0.087097, Discriminator: 0.043287; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:21,238 root         INFO     Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 0.529197\n",
      "Reconstruction: 0.371727, Regularization: 0.092495, Discriminator: 0.043328; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:21,348 root         INFO     Train Epoch: 126 [1536/8000 (19%)]\tTotal Loss: 0.279427\n",
      "Reconstruction: 0.160959, Regularization: 0.053489, Discriminator: 0.043315; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:21,457 root         INFO     Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 0.409606\n",
      "Reconstruction: 0.276719, Regularization: 0.067920, Discriminator: 0.043318; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:21,566 root         INFO     Train Epoch: 126 [2560/8000 (32%)]\tTotal Loss: 0.198342\n",
      "Reconstruction: 0.106955, Regularization: 0.026382, Discriminator: 0.043333; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:21,675 root         INFO     Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 0.409554\n",
      "Reconstruction: 0.282788, Regularization: 0.061769, Discriminator: 0.043368; Generator: 0.021629,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:21,784 root         INFO     Train Epoch: 126 [3584/8000 (45%)]\tTotal Loss: 0.234902\n",
      "Reconstruction: 0.134509, Regularization: 0.035412, Discriminator: 0.043341; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:21,892 root         INFO     Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 0.260107\n",
      "Reconstruction: 0.137990, Regularization: 0.057152, Discriminator: 0.043311; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:22,000 root         INFO     Train Epoch: 126 [4608/8000 (58%)]\tTotal Loss: 0.242099\n",
      "Reconstruction: 0.119125, Regularization: 0.058009, Discriminator: 0.043295; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:22,110 root         INFO     Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 0.233737\n",
      "Reconstruction: 0.136958, Regularization: 0.031786, Discriminator: 0.043319; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:22,221 root         INFO     Train Epoch: 126 [5632/8000 (70%)]\tTotal Loss: 0.210556\n",
      "Reconstruction: 0.111320, Regularization: 0.034264, Discriminator: 0.043259; Generator: 0.021712,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:22,334 root         INFO     Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 0.224595\n",
      "Reconstruction: 0.132674, Regularization: 0.026968, Discriminator: 0.043280; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:22,446 root         INFO     Train Epoch: 126 [6656/8000 (83%)]\tTotal Loss: 0.225068\n",
      "Reconstruction: 0.119956, Regularization: 0.040104, Discriminator: 0.043302; Generator: 0.021706,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:22,553 root         INFO     Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 0.290013\n",
      "Reconstruction: 0.164083, Regularization: 0.060923, Discriminator: 0.043280; Generator: 0.021728,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:22,660 root         INFO     Train Epoch: 126 [7680/8000 (96%)]\tTotal Loss: 0.262795\n",
      "Reconstruction: 0.139798, Regularization: 0.058010, Discriminator: 0.043306; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:22,740 root         INFO     ====> Epoch: 126 Average loss: 10340.8746\n",
      "2019-04-09 23:35:22,767 root         INFO     Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 0.254599\n",
      "Reconstruction: 0.123843, Regularization: 0.065785, Discriminator: 0.043323; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:22,878 root         INFO     Train Epoch: 127 [512/8000 (6%)]\tTotal Loss: 0.199544\n",
      "Reconstruction: 0.103813, Regularization: 0.030754, Discriminator: 0.043301; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:22,988 root         INFO     Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 0.284901\n",
      "Reconstruction: 0.164124, Regularization: 0.055782, Discriminator: 0.043322; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:23,098 root         INFO     Train Epoch: 127 [1536/8000 (19%)]\tTotal Loss: 0.490147\n",
      "Reconstruction: 0.385807, Regularization: 0.039361, Discriminator: 0.043324; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:23,209 root         INFO     Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 0.233260\n",
      "Reconstruction: 0.120070, Regularization: 0.048205, Discriminator: 0.043313; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:23,321 root         INFO     Train Epoch: 127 [2560/8000 (32%)]\tTotal Loss: 0.451846\n",
      "Reconstruction: 0.269275, Regularization: 0.117594, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:23,433 root         INFO     Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 0.338069\n",
      "Reconstruction: 0.209535, Regularization: 0.063560, Discriminator: 0.043314; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:23,543 root         INFO     Train Epoch: 127 [3584/8000 (45%)]\tTotal Loss: 0.242948\n",
      "Reconstruction: 0.130477, Regularization: 0.047478, Discriminator: 0.043314; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:23,654 root         INFO     Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 0.529686\n",
      "Reconstruction: 0.418357, Regularization: 0.046329, Discriminator: 0.043325; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:23,764 root         INFO     Train Epoch: 127 [4608/8000 (58%)]\tTotal Loss: 0.314780\n",
      "Reconstruction: 0.174282, Regularization: 0.075509, Discriminator: 0.043326; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:23,875 root         INFO     Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 0.296862\n",
      "Reconstruction: 0.155838, Regularization: 0.076056, Discriminator: 0.043284; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:23,986 root         INFO     Train Epoch: 127 [5632/8000 (70%)]\tTotal Loss: 0.276283\n",
      "Reconstruction: 0.132169, Regularization: 0.079125, Discriminator: 0.043326; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:24,097 root         INFO     Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 0.249058\n",
      "Reconstruction: 0.150749, Regularization: 0.033319, Discriminator: 0.043316; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:24,206 root         INFO     Train Epoch: 127 [6656/8000 (83%)]\tTotal Loss: 0.239780\n",
      "Reconstruction: 0.134601, Regularization: 0.040201, Discriminator: 0.043301; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:24,317 root         INFO     Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 2.306264\n",
      "Reconstruction: 2.193868, Regularization: 0.047427, Discriminator: 0.043323; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:24,426 root         INFO     Train Epoch: 127 [7680/8000 (96%)]\tTotal Loss: 1.132581\n",
      "Reconstruction: 1.025101, Regularization: 0.042491, Discriminator: 0.043310; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:24,507 root         INFO     ====> Epoch: 127 Average loss: 3.3995\n",
      "2019-04-09 23:35:24,534 root         INFO     Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 0.208179\n",
      "Reconstruction: 0.109556, Regularization: 0.033630, Discriminator: 0.043332; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:24,647 root         INFO     Train Epoch: 128 [512/8000 (6%)]\tTotal Loss: 0.247748\n",
      "Reconstruction: 0.126492, Regularization: 0.056232, Discriminator: 0.043375; Generator: 0.021649,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:24,759 root         INFO     Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 0.237380\n",
      "Reconstruction: 0.126852, Regularization: 0.045534, Discriminator: 0.043336; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:24,871 root         INFO     Train Epoch: 128 [1536/8000 (19%)]\tTotal Loss: 0.296418\n",
      "Reconstruction: 0.139751, Regularization: 0.091681, Discriminator: 0.043327; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:24,983 root         INFO     Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 1.473593\n",
      "Reconstruction: 1.356865, Regularization: 0.051758, Discriminator: 0.043310; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:25,094 root         INFO     Train Epoch: 128 [2560/8000 (32%)]\tTotal Loss: 0.456363\n",
      "Reconstruction: 0.331313, Regularization: 0.060049, Discriminator: 0.043344; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:25,207 root         INFO     Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 0.441839\n",
      "Reconstruction: 0.145424, Regularization: 0.231433, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:25,319 root         INFO     Train Epoch: 128 [3584/8000 (45%)]\tTotal Loss: 0.324008\n",
      "Reconstruction: 0.197659, Regularization: 0.061362, Discriminator: 0.043327; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:25,431 root         INFO     Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 0.270458\n",
      "Reconstruction: 0.104128, Regularization: 0.101352, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:25,543 root         INFO     Train Epoch: 128 [4608/8000 (58%)]\tTotal Loss: 0.288530\n",
      "Reconstruction: 0.121546, Regularization: 0.102004, Discriminator: 0.043325; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:25,655 root         INFO     Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 0.352830\n",
      "Reconstruction: 0.147264, Regularization: 0.140584, Discriminator: 0.043316; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:25,765 root         INFO     Train Epoch: 128 [5632/8000 (70%)]\tTotal Loss: 0.896815\n",
      "Reconstruction: 0.779017, Regularization: 0.052820, Discriminator: 0.043329; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:25,876 root         INFO     Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 0.216220\n",
      "Reconstruction: 0.114973, Regularization: 0.036270, Discriminator: 0.043321; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:25,985 root         INFO     Train Epoch: 128 [6656/8000 (83%)]\tTotal Loss: 0.342507\n",
      "Reconstruction: 0.224768, Regularization: 0.052736, Discriminator: 0.043349; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:26,096 root         INFO     Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 2.545833\n",
      "Reconstruction: 2.376932, Regularization: 0.103918, Discriminator: 0.043311; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:26,206 root         INFO     Train Epoch: 128 [7680/8000 (96%)]\tTotal Loss: 0.494014\n",
      "Reconstruction: 0.375563, Regularization: 0.053469, Discriminator: 0.043296; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:26,286 root         INFO     ====> Epoch: 128 Average loss: 505.4750\n",
      "2019-04-09 23:35:26,313 root         INFO     Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 0.282378\n",
      "Reconstruction: 0.177850, Regularization: 0.039549, Discriminator: 0.043353; Generator: 0.021627,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:26,426 root         INFO     Train Epoch: 129 [512/8000 (6%)]\tTotal Loss: 0.310344\n",
      "Reconstruction: 0.196320, Regularization: 0.049074, Discriminator: 0.043296; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:26,537 root         INFO     Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 0.454729\n",
      "Reconstruction: 0.297494, Regularization: 0.092206, Discriminator: 0.043370; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:26,648 root         INFO     Train Epoch: 129 [1536/8000 (19%)]\tTotal Loss: 0.458858\n",
      "Reconstruction: 0.212217, Regularization: 0.181616, Discriminator: 0.043370; Generator: 0.021655,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:26,759 root         INFO     Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 0.216330\n",
      "Reconstruction: 0.118743, Regularization: 0.032615, Discriminator: 0.043332; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:26,871 root         INFO     Train Epoch: 129 [2560/8000 (32%)]\tTotal Loss: 0.305199\n",
      "Reconstruction: 0.139779, Regularization: 0.100428, Discriminator: 0.043299; Generator: 0.021693,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:26,981 root         INFO     Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 0.185464\n",
      "Reconstruction: 0.098694, Regularization: 0.021783, Discriminator: 0.043322; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:27,091 root         INFO     Train Epoch: 129 [3584/8000 (45%)]\tTotal Loss: 0.259315\n",
      "Reconstruction: 0.130685, Regularization: 0.063652, Discriminator: 0.043307; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:27,201 root         INFO     Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 0.725655\n",
      "Reconstruction: 0.541866, Regularization: 0.118822, Discriminator: 0.043311; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:27,313 root         INFO     Train Epoch: 129 [4608/8000 (58%)]\tTotal Loss: 0.767839\n",
      "Reconstruction: 0.604477, Regularization: 0.098390, Discriminator: 0.043313; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:27,426 root         INFO     Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 0.364485\n",
      "Reconstruction: 0.241824, Regularization: 0.057678, Discriminator: 0.043326; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:27,538 root         INFO     Train Epoch: 129 [5632/8000 (70%)]\tTotal Loss: 3.876321\n",
      "Reconstruction: 3.723207, Regularization: 0.088138, Discriminator: 0.043286; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:27,649 root         INFO     Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 0.256041\n",
      "Reconstruction: 0.150391, Regularization: 0.040656, Discriminator: 0.043283; Generator: 0.021711,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:27,760 root         INFO     Train Epoch: 129 [6656/8000 (83%)]\tTotal Loss: 0.455453\n",
      "Reconstruction: 0.350479, Regularization: 0.039972, Discriminator: 0.043385; Generator: 0.021617,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:27,871 root         INFO     Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 0.570829\n",
      "Reconstruction: 0.465585, Regularization: 0.040233, Discriminator: 0.043356; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:27,981 root         INFO     Train Epoch: 129 [7680/8000 (96%)]\tTotal Loss: 0.237079\n",
      "Reconstruction: 0.130962, Regularization: 0.041145, Discriminator: 0.043288; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:28,062 root         INFO     ====> Epoch: 129 Average loss: 2419.9721\n",
      "2019-04-09 23:35:28,090 root         INFO     Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 0.216984\n",
      "Reconstruction: 0.106047, Regularization: 0.045918, Discriminator: 0.043353; Generator: 0.021665,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:28,201 root         INFO     Train Epoch: 130 [512/8000 (6%)]\tTotal Loss: 0.591761\n",
      "Reconstruction: 0.472163, Regularization: 0.054601, Discriminator: 0.043383; Generator: 0.021615,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:28,312 root         INFO     Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 120.437576\n",
      "Reconstruction: 120.206261, Regularization: 0.166369, Discriminator: 0.043344; Generator: 0.021607,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:35:28,423 root         INFO     Train Epoch: 130 [1536/8000 (19%)]\tTotal Loss: 0.257799\n",
      "Reconstruction: 0.154225, Regularization: 0.038568, Discriminator: 0.043366; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:28,534 root         INFO     Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 0.205741\n",
      "Reconstruction: 0.103419, Regularization: 0.037338, Discriminator: 0.043355; Generator: 0.021629,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:28,645 root         INFO     Train Epoch: 130 [2560/8000 (32%)]\tTotal Loss: 0.233516\n",
      "Reconstruction: 0.106267, Regularization: 0.062265, Discriminator: 0.043316; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:28,757 root         INFO     Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 3.804729\n",
      "Reconstruction: 3.664377, Regularization: 0.075385, Discriminator: 0.043318; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:28,870 root         INFO     Train Epoch: 130 [3584/8000 (45%)]\tTotal Loss: 0.475183\n",
      "Reconstruction: 0.306099, Regularization: 0.104082, Discriminator: 0.043352; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:28,981 root         INFO     Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 0.272964\n",
      "Reconstruction: 0.172222, Regularization: 0.035760, Discriminator: 0.043325; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:29,091 root         INFO     Train Epoch: 130 [4608/8000 (58%)]\tTotal Loss: 0.244768\n",
      "Reconstruction: 0.109091, Regularization: 0.070693, Discriminator: 0.043326; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:29,202 root         INFO     Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 0.476580\n",
      "Reconstruction: 0.355064, Regularization: 0.056535, Discriminator: 0.043326; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:29,313 root         INFO     Train Epoch: 130 [5632/8000 (70%)]\tTotal Loss: 0.230513\n",
      "Reconstruction: 0.136395, Regularization: 0.029143, Discriminator: 0.043317; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:29,423 root         INFO     Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 0.214956\n",
      "Reconstruction: 0.121128, Regularization: 0.028868, Discriminator: 0.043285; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:29,534 root         INFO     Train Epoch: 130 [6656/8000 (83%)]\tTotal Loss: 0.200681\n",
      "Reconstruction: 0.105950, Regularization: 0.029768, Discriminator: 0.043312; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:29,647 root         INFO     Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 0.232344\n",
      "Reconstruction: 0.120408, Regularization: 0.046968, Discriminator: 0.043293; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:29,759 root         INFO     Train Epoch: 130 [7680/8000 (96%)]\tTotal Loss: 0.279562\n",
      "Reconstruction: 0.115690, Regularization: 0.098941, Discriminator: 0.043258; Generator: 0.021673,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:29,840 root         INFO     ====> Epoch: 130 Average loss: 105.0449\n",
      "2019-04-09 23:35:29,868 root         INFO     Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 0.340494\n",
      "Reconstruction: 0.176209, Regularization: 0.099290, Discriminator: 0.043339; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:29,980 root         INFO     Train Epoch: 131 [512/8000 (6%)]\tTotal Loss: 1.490589\n",
      "Reconstruction: 1.362928, Regularization: 0.062658, Discriminator: 0.043324; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:30,092 root         INFO     Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 0.231609\n",
      "Reconstruction: 0.128148, Regularization: 0.038480, Discriminator: 0.043315; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:30,205 root         INFO     Train Epoch: 131 [1536/8000 (19%)]\tTotal Loss: 0.325333\n",
      "Reconstruction: 0.209551, Regularization: 0.050769, Discriminator: 0.043298; Generator: 0.021715,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:30,316 root         INFO     Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 0.292901\n",
      "Reconstruction: 0.159914, Regularization: 0.068000, Discriminator: 0.043354; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:30,426 root         INFO     Train Epoch: 131 [2560/8000 (32%)]\tTotal Loss: 4.050303\n",
      "Reconstruction: 3.607116, Regularization: 0.378158, Discriminator: 0.043357; Generator: 0.021673,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:30,536 root         INFO     Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 0.750906\n",
      "Reconstruction: 0.639722, Regularization: 0.046217, Discriminator: 0.043275; Generator: 0.021692,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:30,646 root         INFO     Train Epoch: 131 [3584/8000 (45%)]\tTotal Loss: 0.748529\n",
      "Reconstruction: 0.613848, Regularization: 0.069680, Discriminator: 0.043284; Generator: 0.021717,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:30,755 root         INFO     Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 0.229400\n",
      "Reconstruction: 0.109872, Regularization: 0.054565, Discriminator: 0.043303; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:30,863 root         INFO     Train Epoch: 131 [4608/8000 (58%)]\tTotal Loss: 0.262470\n",
      "Reconstruction: 0.145995, Regularization: 0.051489, Discriminator: 0.043357; Generator: 0.021629,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:30,971 root         INFO     Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 0.235346\n",
      "Reconstruction: 0.118426, Regularization: 0.051928, Discriminator: 0.043323; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:31,079 root         INFO     Train Epoch: 131 [5632/8000 (70%)]\tTotal Loss: 1.244106\n",
      "Reconstruction: 0.862776, Regularization: 0.316353, Discriminator: 0.043331; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:31,188 root         INFO     Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 1.725894\n",
      "Reconstruction: 1.553208, Regularization: 0.107701, Discriminator: 0.043321; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:31,296 root         INFO     Train Epoch: 131 [6656/8000 (83%)]\tTotal Loss: 0.439469\n",
      "Reconstruction: 0.219953, Regularization: 0.154512, Discriminator: 0.043343; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:31,404 root         INFO     Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 0.523040\n",
      "Reconstruction: 0.180585, Regularization: 0.277496, Discriminator: 0.043285; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:31,511 root         INFO     Train Epoch: 131 [7680/8000 (96%)]\tTotal Loss: 0.331243\n",
      "Reconstruction: 0.150684, Regularization: 0.115581, Discriminator: 0.043300; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:31,590 root         INFO     ====> Epoch: 131 Average loss: 6.5059\n",
      "2019-04-09 23:35:31,617 root         INFO     Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 0.309879\n",
      "Reconstruction: 0.206224, Regularization: 0.038642, Discriminator: 0.043311; Generator: 0.021701,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:31,730 root         INFO     Train Epoch: 132 [512/8000 (6%)]\tTotal Loss: 0.209746\n",
      "Reconstruction: 0.113546, Regularization: 0.031209, Discriminator: 0.043352; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:31,841 root         INFO     Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 0.260241\n",
      "Reconstruction: 0.130440, Regularization: 0.064837, Discriminator: 0.043286; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:31,952 root         INFO     Train Epoch: 132 [1536/8000 (19%)]\tTotal Loss: 0.263197\n",
      "Reconstruction: 0.135389, Regularization: 0.062802, Discriminator: 0.043340; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:32,063 root         INFO     Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 0.581593\n",
      "Reconstruction: 0.465663, Regularization: 0.050971, Discriminator: 0.043316; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:32,174 root         INFO     Train Epoch: 132 [2560/8000 (32%)]\tTotal Loss: 0.208663\n",
      "Reconstruction: 0.112968, Regularization: 0.030707, Discriminator: 0.043345; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:32,286 root         INFO     Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 0.484530\n",
      "Reconstruction: 0.276546, Regularization: 0.143033, Discriminator: 0.043304; Generator: 0.021647,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:32,397 root         INFO     Train Epoch: 132 [3584/8000 (45%)]\tTotal Loss: 0.404240\n",
      "Reconstruction: 0.249249, Regularization: 0.089996, Discriminator: 0.043342; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:32,507 root         INFO     Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 0.269125\n",
      "Reconstruction: 0.170796, Regularization: 0.033332, Discriminator: 0.043342; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:32,616 root         INFO     Train Epoch: 132 [4608/8000 (58%)]\tTotal Loss: 0.196930\n",
      "Reconstruction: 0.098452, Regularization: 0.033501, Discriminator: 0.043328; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:32,724 root         INFO     Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 0.648063\n",
      "Reconstruction: 0.445285, Regularization: 0.137802, Discriminator: 0.043299; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:32,834 root         INFO     Train Epoch: 132 [5632/8000 (70%)]\tTotal Loss: 0.247182\n",
      "Reconstruction: 0.124979, Regularization: 0.057218, Discriminator: 0.043328; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:32,943 root         INFO     Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 4463.158203\n",
      "Reconstruction: 4462.964355, Regularization: 0.129146, Discriminator: 0.043324; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:33,052 root         INFO     Train Epoch: 132 [6656/8000 (83%)]\tTotal Loss: 0.269186\n",
      "Reconstruction: 0.158364, Regularization: 0.045856, Discriminator: 0.043307; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:33,161 root         INFO     Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 0.268325\n",
      "Reconstruction: 0.121321, Regularization: 0.082019, Discriminator: 0.043327; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:33,272 root         INFO     Train Epoch: 132 [7680/8000 (96%)]\tTotal Loss: 0.250815\n",
      "Reconstruction: 0.139106, Regularization: 0.046718, Discriminator: 0.043330; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:33,352 root         INFO     ====> Epoch: 132 Average loss: 9980475.0187\n",
      "2019-04-09 23:35:33,380 root         INFO     Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 0.267264\n",
      "Reconstruction: 0.164690, Regularization: 0.037598, Discriminator: 0.043300; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:33,489 root         INFO     Train Epoch: 133 [512/8000 (6%)]\tTotal Loss: 0.230102\n",
      "Reconstruction: 0.115950, Regularization: 0.049192, Discriminator: 0.043329; Generator: 0.021631,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:33,598 root         INFO     Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 13882.672852\n",
      "Reconstruction: 13882.384766, Regularization: 0.222695, Discriminator: 0.043316; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:33,707 root         INFO     Train Epoch: 133 [1536/8000 (19%)]\tTotal Loss: 0.526049\n",
      "Reconstruction: 0.353411, Regularization: 0.107660, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:33,815 root         INFO     Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 0.533937\n",
      "Reconstruction: 0.392703, Regularization: 0.076253, Discriminator: 0.043318; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:33,924 root         INFO     Train Epoch: 133 [2560/8000 (32%)]\tTotal Loss: 0.261038\n",
      "Reconstruction: 0.127500, Regularization: 0.068545, Discriminator: 0.043314; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:34,033 root         INFO     Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 0.665117\n",
      "Reconstruction: 0.433301, Regularization: 0.166809, Discriminator: 0.043324; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:34,142 root         INFO     Train Epoch: 133 [3584/8000 (45%)]\tTotal Loss: 0.340952\n",
      "Reconstruction: 0.241073, Regularization: 0.034894, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:34,251 root         INFO     Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 0.221971\n",
      "Reconstruction: 0.126972, Regularization: 0.030015, Discriminator: 0.043314; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:34,359 root         INFO     Train Epoch: 133 [4608/8000 (58%)]\tTotal Loss: 2.416869\n",
      "Reconstruction: 2.137102, Regularization: 0.214801, Discriminator: 0.043304; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:34,468 root         INFO     Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 0.332818\n",
      "Reconstruction: 0.127318, Regularization: 0.140504, Discriminator: 0.043335; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:34,576 root         INFO     Train Epoch: 133 [5632/8000 (70%)]\tTotal Loss: 0.277795\n",
      "Reconstruction: 0.163819, Regularization: 0.048971, Discriminator: 0.043306; Generator: 0.021699,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:34,687 root         INFO     Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 0.201046\n",
      "Reconstruction: 0.115470, Regularization: 0.020556, Discriminator: 0.043377; Generator: 0.021642,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:34,799 root         INFO     Train Epoch: 133 [6656/8000 (83%)]\tTotal Loss: 0.316718\n",
      "Reconstruction: 0.185300, Regularization: 0.066429, Discriminator: 0.043318; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:34,910 root         INFO     Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 0.198475\n",
      "Reconstruction: 0.096907, Regularization: 0.036535, Discriminator: 0.043343; Generator: 0.021690,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:35,022 root         INFO     Train Epoch: 133 [7680/8000 (96%)]\tTotal Loss: 0.633416\n",
      "Reconstruction: 0.459620, Regularization: 0.108852, Discriminator: 0.043273; Generator: 0.021670,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:35,103 root         INFO     ====> Epoch: 133 Average loss: 74.2836\n",
      "2019-04-09 23:35:35,130 root         INFO     Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 0.308248\n",
      "Reconstruction: 0.199522, Regularization: 0.043734, Discriminator: 0.043371; Generator: 0.021621,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:35,242 root         INFO     Train Epoch: 134 [512/8000 (6%)]\tTotal Loss: 4.369835\n",
      "Reconstruction: 4.194360, Regularization: 0.110515, Discriminator: 0.043312; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:35,353 root         INFO     Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 0.907233\n",
      "Reconstruction: 0.717868, Regularization: 0.124375, Discriminator: 0.043390; Generator: 0.021600,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:35,465 root         INFO     Train Epoch: 134 [1536/8000 (19%)]\tTotal Loss: 0.516561\n",
      "Reconstruction: 0.298417, Regularization: 0.153153, Discriminator: 0.043375; Generator: 0.021617,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:35,577 root         INFO     Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 0.204188\n",
      "Reconstruction: 0.107970, Regularization: 0.031236, Discriminator: 0.043368; Generator: 0.021615,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:35,688 root         INFO     Train Epoch: 134 [2560/8000 (32%)]\tTotal Loss: 0.257156\n",
      "Reconstruction: 0.128375, Regularization: 0.063777, Discriminator: 0.043356; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:35,799 root         INFO     Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 0.190522\n",
      "Reconstruction: 0.095204, Regularization: 0.030326, Discriminator: 0.043333; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:35,910 root         INFO     Train Epoch: 134 [3584/8000 (45%)]\tTotal Loss: 0.237966\n",
      "Reconstruction: 0.105495, Regularization: 0.067481, Discriminator: 0.043338; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:36,021 root         INFO     Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 0.305439\n",
      "Reconstruction: 0.189483, Regularization: 0.050988, Discriminator: 0.043312; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:36,133 root         INFO     Train Epoch: 134 [4608/8000 (58%)]\tTotal Loss: 15.062755\n",
      "Reconstruction: 14.909599, Regularization: 0.088165, Discriminator: 0.043337; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:36,244 root         INFO     Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 0.326510\n",
      "Reconstruction: 0.148281, Regularization: 0.113237, Discriminator: 0.043327; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:36,353 root         INFO     Train Epoch: 134 [5632/8000 (70%)]\tTotal Loss: 1.172311\n",
      "Reconstruction: 0.991650, Regularization: 0.115699, Discriminator: 0.043312; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:36,463 root         INFO     Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 0.250985\n",
      "Reconstruction: 0.123543, Regularization: 0.062463, Discriminator: 0.043330; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:36,572 root         INFO     Train Epoch: 134 [6656/8000 (83%)]\tTotal Loss: 0.221445\n",
      "Reconstruction: 0.095037, Regularization: 0.061430, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:36,682 root         INFO     Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 0.751826\n",
      "Reconstruction: 0.586457, Regularization: 0.100371, Discriminator: 0.043336; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:36,791 root         INFO     Train Epoch: 134 [7680/8000 (96%)]\tTotal Loss: 0.179687\n",
      "Reconstruction: 0.093231, Regularization: 0.021505, Discriminator: 0.043280; Generator: 0.021671,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:36,871 root         INFO     ====> Epoch: 134 Average loss: 9823.3418\n",
      "2019-04-09 23:35:36,898 root         INFO     Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 0.261038\n",
      "Reconstruction: 0.126678, Regularization: 0.069369, Discriminator: 0.043342; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:37,009 root         INFO     Train Epoch: 135 [512/8000 (6%)]\tTotal Loss: 0.222084\n",
      "Reconstruction: 0.120109, Regularization: 0.037015, Discriminator: 0.043277; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:37,123 root         INFO     Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 0.211947\n",
      "Reconstruction: 0.102411, Regularization: 0.044579, Discriminator: 0.043294; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:37,235 root         INFO     Train Epoch: 135 [1536/8000 (19%)]\tTotal Loss: 0.264862\n",
      "Reconstruction: 0.158543, Regularization: 0.041378, Discriminator: 0.043293; Generator: 0.021647,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:37,347 root         INFO     Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 0.240164\n",
      "Reconstruction: 0.133182, Regularization: 0.041969, Discriminator: 0.043300; Generator: 0.021714,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:37,457 root         INFO     Train Epoch: 135 [2560/8000 (32%)]\tTotal Loss: 0.220171\n",
      "Reconstruction: 0.112461, Regularization: 0.042762, Discriminator: 0.043356; Generator: 0.021592,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:35:37,571 root         INFO     Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 0.200613\n",
      "Reconstruction: 0.104154, Regularization: 0.031464, Discriminator: 0.043369; Generator: 0.021627,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:37,685 root         INFO     Train Epoch: 135 [3584/8000 (45%)]\tTotal Loss: 0.351929\n",
      "Reconstruction: 0.208198, Regularization: 0.078738, Discriminator: 0.043343; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:37,794 root         INFO     Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 0.605198\n",
      "Reconstruction: 0.462841, Regularization: 0.077390, Discriminator: 0.043290; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:37,905 root         INFO     Train Epoch: 135 [4608/8000 (58%)]\tTotal Loss: 0.867082\n",
      "Reconstruction: 0.751008, Regularization: 0.051080, Discriminator: 0.043320; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:38,015 root         INFO     Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 0.395187\n",
      "Reconstruction: 0.299100, Regularization: 0.031088, Discriminator: 0.043318; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:38,125 root         INFO     Train Epoch: 135 [5632/8000 (70%)]\tTotal Loss: 0.311794\n",
      "Reconstruction: 0.194259, Regularization: 0.052562, Discriminator: 0.043290; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:38,234 root         INFO     Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 0.857436\n",
      "Reconstruction: 0.749509, Regularization: 0.042970, Discriminator: 0.043304; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:38,344 root         INFO     Train Epoch: 135 [6656/8000 (83%)]\tTotal Loss: 0.220570\n",
      "Reconstruction: 0.115416, Regularization: 0.040169, Discriminator: 0.043311; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:38,455 root         INFO     Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 0.235100\n",
      "Reconstruction: 0.122011, Regularization: 0.048085, Discriminator: 0.043347; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:38,565 root         INFO     Train Epoch: 135 [7680/8000 (96%)]\tTotal Loss: 0.217592\n",
      "Reconstruction: 0.119161, Regularization: 0.033405, Discriminator: 0.043382; Generator: 0.021644,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:38,646 root         INFO     ====> Epoch: 135 Average loss: 88.6080\n",
      "2019-04-09 23:35:38,673 root         INFO     Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 1.138706\n",
      "Reconstruction: 0.944701, Regularization: 0.129096, Discriminator: 0.043240; Generator: 0.021670,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:38,781 root         INFO     Train Epoch: 136 [512/8000 (6%)]\tTotal Loss: 0.235995\n",
      "Reconstruction: 0.122882, Regularization: 0.048165, Discriminator: 0.043388; Generator: 0.021561,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-09 23:35:38,888 root         INFO     Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 0.227945\n",
      "Reconstruction: 0.124021, Regularization: 0.038930, Discriminator: 0.043275; Generator: 0.021719,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:38,995 root         INFO     Train Epoch: 136 [1536/8000 (19%)]\tTotal Loss: 0.683375\n",
      "Reconstruction: 0.558901, Regularization: 0.059486, Discriminator: 0.043381; Generator: 0.021607,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:39,107 root         INFO     Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 0.285526\n",
      "Reconstruction: 0.169380, Regularization: 0.051151, Discriminator: 0.043319; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:39,221 root         INFO     Train Epoch: 136 [2560/8000 (32%)]\tTotal Loss: 44.169727\n",
      "Reconstruction: 44.007282, Regularization: 0.097454, Discriminator: 0.043318; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:39,334 root         INFO     Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 0.432061\n",
      "Reconstruction: 0.257395, Regularization: 0.109668, Discriminator: 0.043325; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:39,448 root         INFO     Train Epoch: 136 [3584/8000 (45%)]\tTotal Loss: 0.275639\n",
      "Reconstruction: 0.150100, Regularization: 0.060549, Discriminator: 0.043352; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:39,561 root         INFO     Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 0.286253\n",
      "Reconstruction: 0.192102, Regularization: 0.029152, Discriminator: 0.043349; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:39,675 root         INFO     Train Epoch: 136 [4608/8000 (58%)]\tTotal Loss: 0.641187\n",
      "Reconstruction: 0.322347, Regularization: 0.253858, Discriminator: 0.043334; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:39,788 root         INFO     Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 0.540403\n",
      "Reconstruction: 0.412571, Regularization: 0.062865, Discriminator: 0.043315; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:39,902 root         INFO     Train Epoch: 136 [5632/8000 (70%)]\tTotal Loss: 0.322339\n",
      "Reconstruction: 0.187206, Regularization: 0.070152, Discriminator: 0.043316; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:40,014 root         INFO     Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 0.289318\n",
      "Reconstruction: 0.143050, Regularization: 0.081295, Discriminator: 0.043294; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:40,126 root         INFO     Train Epoch: 136 [6656/8000 (83%)]\tTotal Loss: 0.294463\n",
      "Reconstruction: 0.175265, Regularization: 0.054196, Discriminator: 0.043295; Generator: 0.021707,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:40,237 root         INFO     Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 0.276935\n",
      "Reconstruction: 0.176536, Regularization: 0.035452, Discriminator: 0.043272; Generator: 0.021675,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:40,349 root         INFO     Train Epoch: 136 [7680/8000 (96%)]\tTotal Loss: 4.305594\n",
      "Reconstruction: 4.089696, Regularization: 0.150857, Discriminator: 0.043430; Generator: 0.021611,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:35:40,430 root         INFO     ====> Epoch: 136 Average loss: 34.3597\n",
      "2019-04-09 23:35:40,458 root         INFO     Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 1.624959\n",
      "Reconstruction: 1.497941, Regularization: 0.062015, Discriminator: 0.043348; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:40,570 root         INFO     Train Epoch: 137 [512/8000 (6%)]\tTotal Loss: 0.230925\n",
      "Reconstruction: 0.136567, Regularization: 0.029338, Discriminator: 0.043297; Generator: 0.021723,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:35:40,682 root         INFO     Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 0.318017\n",
      "Reconstruction: 0.140596, Regularization: 0.112398, Discriminator: 0.043356; Generator: 0.021667,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:40,794 root         INFO     Train Epoch: 137 [1536/8000 (19%)]\tTotal Loss: 0.243518\n",
      "Reconstruction: 0.151951, Regularization: 0.026553, Discriminator: 0.043287; Generator: 0.021726,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:40,906 root         INFO     Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 23.316570\n",
      "Reconstruction: 23.171099, Regularization: 0.080456, Discriminator: 0.043371; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:41,018 root         INFO     Train Epoch: 137 [2560/8000 (32%)]\tTotal Loss: 0.312499\n",
      "Reconstruction: 0.125706, Regularization: 0.121826, Discriminator: 0.043290; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:41,130 root         INFO     Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 0.318592\n",
      "Reconstruction: 0.188709, Regularization: 0.064897, Discriminator: 0.043296; Generator: 0.021689,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:41,241 root         INFO     Train Epoch: 137 [3584/8000 (45%)]\tTotal Loss: 0.326004\n",
      "Reconstruction: 0.219249, Regularization: 0.041749, Discriminator: 0.043334; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:41,354 root         INFO     Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 0.323233\n",
      "Reconstruction: 0.181654, Regularization: 0.076567, Discriminator: 0.043338; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:41,464 root         INFO     Train Epoch: 137 [4608/8000 (58%)]\tTotal Loss: 0.236365\n",
      "Reconstruction: 0.141195, Regularization: 0.030199, Discriminator: 0.043305; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:41,576 root         INFO     Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 0.224135\n",
      "Reconstruction: 0.136170, Regularization: 0.022997, Discriminator: 0.043304; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:41,687 root         INFO     Train Epoch: 137 [5632/8000 (70%)]\tTotal Loss: 3821310.750000\n",
      "Reconstruction: 3821310.500000, Regularization: 0.234362, Discriminator: 0.043341; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:41,796 root         INFO     Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 261.597870\n",
      "Reconstruction: 261.329926, Regularization: 0.202931, Discriminator: 0.043341; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:41,905 root         INFO     Train Epoch: 137 [6656/8000 (83%)]\tTotal Loss: 0.190918\n",
      "Reconstruction: 0.100509, Regularization: 0.025409, Discriminator: 0.043329; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:42,015 root         INFO     Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 0.213310\n",
      "Reconstruction: 0.111623, Regularization: 0.036685, Discriminator: 0.043339; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:42,125 root         INFO     Train Epoch: 137 [7680/8000 (96%)]\tTotal Loss: 27.145832\n",
      "Reconstruction: 26.925175, Regularization: 0.155664, Discriminator: 0.043329; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:42,207 root         INFO     ====> Epoch: 137 Average loss: 15303.9257\n",
      "2019-04-09 23:35:42,234 root         INFO     Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 0.216382\n",
      "Reconstruction: 0.117818, Regularization: 0.033567, Discriminator: 0.043336; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:42,345 root         INFO     Train Epoch: 138 [512/8000 (6%)]\tTotal Loss: 0.219335\n",
      "Reconstruction: 0.119091, Regularization: 0.035272, Discriminator: 0.043329; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:42,454 root         INFO     Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 0.228988\n",
      "Reconstruction: 0.124507, Regularization: 0.039500, Discriminator: 0.043271; Generator: 0.021710,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:42,565 root         INFO     Train Epoch: 138 [1536/8000 (19%)]\tTotal Loss: 0.806125\n",
      "Reconstruction: 0.659118, Regularization: 0.082059, Discriminator: 0.043305; Generator: 0.021643,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:42,677 root         INFO     Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 0.250936\n",
      "Reconstruction: 0.127187, Regularization: 0.058784, Discriminator: 0.043287; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:42,788 root         INFO     Train Epoch: 138 [2560/8000 (32%)]\tTotal Loss: 0.329608\n",
      "Reconstruction: 0.225497, Regularization: 0.039132, Discriminator: 0.043342; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:42,899 root         INFO     Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 0.209230\n",
      "Reconstruction: 0.103498, Regularization: 0.040762, Discriminator: 0.043309; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:43,010 root         INFO     Train Epoch: 138 [3584/8000 (45%)]\tTotal Loss: 0.205852\n",
      "Reconstruction: 0.109334, Regularization: 0.031534, Discriminator: 0.043303; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:43,121 root         INFO     Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 0.272724\n",
      "Reconstruction: 0.121725, Regularization: 0.086015, Discriminator: 0.043355; Generator: 0.021630,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:43,230 root         INFO     Train Epoch: 138 [4608/8000 (58%)]\tTotal Loss: 0.257789\n",
      "Reconstruction: 0.141673, Regularization: 0.051133, Discriminator: 0.043304; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:43,339 root         INFO     Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 0.267987\n",
      "Reconstruction: 0.131218, Regularization: 0.071777, Discriminator: 0.043329; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:43,448 root         INFO     Train Epoch: 138 [5632/8000 (70%)]\tTotal Loss: 0.288947\n",
      "Reconstruction: 0.119841, Regularization: 0.104121, Discriminator: 0.043344; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:43,558 root         INFO     Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 0.227876\n",
      "Reconstruction: 0.125513, Regularization: 0.037383, Discriminator: 0.043347; Generator: 0.021632,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:43,667 root         INFO     Train Epoch: 138 [6656/8000 (83%)]\tTotal Loss: 0.304403\n",
      "Reconstruction: 0.163604, Regularization: 0.075820, Discriminator: 0.043307; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:43,776 root         INFO     Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 0.268942\n",
      "Reconstruction: 0.140268, Regularization: 0.063696, Discriminator: 0.043331; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:43,885 root         INFO     Train Epoch: 138 [7680/8000 (96%)]\tTotal Loss: 0.287536\n",
      "Reconstruction: 0.162148, Regularization: 0.060394, Discriminator: 0.043321; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:43,964 root         INFO     ====> Epoch: 138 Average loss: 19392.4458\n",
      "2019-04-09 23:35:43,991 root         INFO     Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 0.340560\n",
      "Reconstruction: 0.234311, Regularization: 0.041270, Discriminator: 0.043325; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:44,104 root         INFO     Train Epoch: 139 [512/8000 (6%)]\tTotal Loss: 0.275091\n",
      "Reconstruction: 0.131849, Regularization: 0.078256, Discriminator: 0.043326; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:44,214 root         INFO     Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 0.225002\n",
      "Reconstruction: 0.118434, Regularization: 0.041582, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:44,325 root         INFO     Train Epoch: 139 [1536/8000 (19%)]\tTotal Loss: 0.361180\n",
      "Reconstruction: 0.225646, Regularization: 0.070550, Discriminator: 0.043328; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:44,436 root         INFO     Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 0.304458\n",
      "Reconstruction: 0.176181, Regularization: 0.063295, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:44,546 root         INFO     Train Epoch: 139 [2560/8000 (32%)]\tTotal Loss: 0.295955\n",
      "Reconstruction: 0.185748, Regularization: 0.045224, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:44,657 root         INFO     Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 0.226246\n",
      "Reconstruction: 0.119691, Regularization: 0.041576, Discriminator: 0.043295; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:44,766 root         INFO     Train Epoch: 139 [3584/8000 (45%)]\tTotal Loss: 0.209429\n",
      "Reconstruction: 0.117299, Regularization: 0.027168, Discriminator: 0.043312; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:44,877 root         INFO     Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 149.152237\n",
      "Reconstruction: 148.967834, Regularization: 0.119418, Discriminator: 0.043331; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:44,988 root         INFO     Train Epoch: 139 [4608/8000 (58%)]\tTotal Loss: 0.221105\n",
      "Reconstruction: 0.106474, Regularization: 0.049659, Discriminator: 0.043356; Generator: 0.021617,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:45,098 root         INFO     Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 0.246318\n",
      "Reconstruction: 0.130376, Regularization: 0.050929, Discriminator: 0.043296; Generator: 0.021718,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:45,209 root         INFO     Train Epoch: 139 [5632/8000 (70%)]\tTotal Loss: 0.238266\n",
      "Reconstruction: 0.124396, Regularization: 0.048875, Discriminator: 0.043326; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:45,319 root         INFO     Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 0.273059\n",
      "Reconstruction: 0.147068, Regularization: 0.061001, Discriminator: 0.043312; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:45,430 root         INFO     Train Epoch: 139 [6656/8000 (83%)]\tTotal Loss: 0.290762\n",
      "Reconstruction: 0.168476, Regularization: 0.057326, Discriminator: 0.043297; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:45,541 root         INFO     Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 0.271588\n",
      "Reconstruction: 0.155832, Regularization: 0.050718, Discriminator: 0.043349; Generator: 0.021689,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:45,651 root         INFO     Train Epoch: 139 [7680/8000 (96%)]\tTotal Loss: 0.518496\n",
      "Reconstruction: 0.188405, Regularization: 0.265122, Discriminator: 0.043286; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:45,732 root         INFO     ====> Epoch: 139 Average loss: 4.1935\n",
      "2019-04-09 23:35:45,759 root         INFO     Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 39.475437\n",
      "Reconstruction: 39.320694, Regularization: 0.089745, Discriminator: 0.043367; Generator: 0.021632,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:45,870 root         INFO     Train Epoch: 140 [512/8000 (6%)]\tTotal Loss: 0.273163\n",
      "Reconstruction: 0.143879, Regularization: 0.064271, Discriminator: 0.043342; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:45,980 root         INFO     Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 0.215100\n",
      "Reconstruction: 0.117108, Regularization: 0.033010, Discriminator: 0.043308; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:46,091 root         INFO     Train Epoch: 140 [1536/8000 (19%)]\tTotal Loss: 0.211134\n",
      "Reconstruction: 0.113716, Regularization: 0.032436, Discriminator: 0.043349; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:46,201 root         INFO     Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 0.289133\n",
      "Reconstruction: 0.158380, Regularization: 0.065763, Discriminator: 0.043324; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:46,312 root         INFO     Train Epoch: 140 [2560/8000 (32%)]\tTotal Loss: 0.270298\n",
      "Reconstruction: 0.156499, Regularization: 0.048788, Discriminator: 0.043344; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:46,423 root         INFO     Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 0.222936\n",
      "Reconstruction: 0.114994, Regularization: 0.042949, Discriminator: 0.043336; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:46,535 root         INFO     Train Epoch: 140 [3584/8000 (45%)]\tTotal Loss: 0.233502\n",
      "Reconstruction: 0.139597, Regularization: 0.028917, Discriminator: 0.043316; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:46,647 root         INFO     Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 0.752912\n",
      "Reconstruction: 0.631896, Regularization: 0.056005, Discriminator: 0.043338; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:46,760 root         INFO     Train Epoch: 140 [4608/8000 (58%)]\tTotal Loss: 0.208381\n",
      "Reconstruction: 0.108983, Regularization: 0.034417, Discriminator: 0.043309; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:46,872 root         INFO     Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 0.498590\n",
      "Reconstruction: 0.368547, Regularization: 0.065088, Discriminator: 0.043303; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:46,985 root         INFO     Train Epoch: 140 [5632/8000 (70%)]\tTotal Loss: 0.238686\n",
      "Reconstruction: 0.137553, Regularization: 0.036151, Discriminator: 0.043309; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:47,097 root         INFO     Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 7.771960\n",
      "Reconstruction: 7.653942, Regularization: 0.053050, Discriminator: 0.043318; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:47,209 root         INFO     Train Epoch: 140 [6656/8000 (83%)]\tTotal Loss: 11.063627\n",
      "Reconstruction: 10.828288, Regularization: 0.170338, Discriminator: 0.043373; Generator: 0.021628,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:47,321 root         INFO     Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 0.527913\n",
      "Reconstruction: 0.399023, Regularization: 0.063905, Discriminator: 0.043314; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:47,433 root         INFO     Train Epoch: 140 [7680/8000 (96%)]\tTotal Loss: 0.245557\n",
      "Reconstruction: 0.153364, Regularization: 0.027200, Discriminator: 0.043371; Generator: 0.021622,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:47,514 root         INFO     ====> Epoch: 140 Average loss: 43489.9216\n",
      "2019-04-09 23:35:47,542 root         INFO     Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 0.191644\n",
      "Reconstruction: 0.098248, Regularization: 0.028401, Discriminator: 0.043351; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:47,655 root         INFO     Train Epoch: 141 [512/8000 (6%)]\tTotal Loss: 0.238102\n",
      "Reconstruction: 0.148315, Regularization: 0.024820, Discriminator: 0.043285; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:47,768 root         INFO     Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 0.217796\n",
      "Reconstruction: 0.094356, Regularization: 0.058454, Discriminator: 0.043331; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:47,881 root         INFO     Train Epoch: 141 [1536/8000 (19%)]\tTotal Loss: 0.335414\n",
      "Reconstruction: 0.202555, Regularization: 0.067857, Discriminator: 0.043350; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:47,994 root         INFO     Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 0.234510\n",
      "Reconstruction: 0.137858, Regularization: 0.031674, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:48,108 root         INFO     Train Epoch: 141 [2560/8000 (32%)]\tTotal Loss: 0.433784\n",
      "Reconstruction: 0.293762, Regularization: 0.075046, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:48,221 root         INFO     Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 0.226579\n",
      "Reconstruction: 0.124591, Regularization: 0.037009, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:48,334 root         INFO     Train Epoch: 141 [3584/8000 (45%)]\tTotal Loss: 0.647241\n",
      "Reconstruction: 0.548627, Regularization: 0.033653, Discriminator: 0.043294; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:48,447 root         INFO     Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 0.266447\n",
      "Reconstruction: 0.141428, Regularization: 0.060070, Discriminator: 0.043305; Generator: 0.021644,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:35:48,560 root         INFO     Train Epoch: 141 [4608/8000 (58%)]\tTotal Loss: 0.381405\n",
      "Reconstruction: 0.209702, Regularization: 0.106723, Discriminator: 0.043291; Generator: 0.021689,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:48,673 root         INFO     Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 0.284999\n",
      "Reconstruction: 0.181359, Regularization: 0.038666, Discriminator: 0.043299; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:48,786 root         INFO     Train Epoch: 141 [5632/8000 (70%)]\tTotal Loss: 0.214649\n",
      "Reconstruction: 0.112605, Regularization: 0.037122, Discriminator: 0.043224; Generator: 0.021699,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:35:48,899 root         INFO     Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 0.274203\n",
      "Reconstruction: 0.163913, Regularization: 0.045273, Discriminator: 0.043334; Generator: 0.021683,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:49,013 root         INFO     Train Epoch: 141 [6656/8000 (83%)]\tTotal Loss: 0.236524\n",
      "Reconstruction: 0.127530, Regularization: 0.044072, Discriminator: 0.043355; Generator: 0.021566,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-09 23:35:49,126 root         INFO     Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 0.355627\n",
      "Reconstruction: 0.165301, Regularization: 0.125346, Discriminator: 0.043337; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:49,239 root         INFO     Train Epoch: 141 [7680/8000 (96%)]\tTotal Loss: 12.684101\n",
      "Reconstruction: 12.509437, Regularization: 0.109637, Discriminator: 0.043358; Generator: 0.021670,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:49,321 root         INFO     ====> Epoch: 141 Average loss: 87181.0505\n",
      "2019-04-09 23:35:49,349 root         INFO     Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 0.416157\n",
      "Reconstruction: 0.271827, Regularization: 0.079341, Discriminator: 0.043366; Generator: 0.021623,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:35:49,463 root         INFO     Train Epoch: 142 [512/8000 (6%)]\tTotal Loss: 0.466951\n",
      "Reconstruction: 0.302280, Regularization: 0.099684, Discriminator: 0.043346; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:49,575 root         INFO     Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 0.341928\n",
      "Reconstruction: 0.193678, Regularization: 0.083252, Discriminator: 0.043301; Generator: 0.021697,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:49,688 root         INFO     Train Epoch: 142 [1536/8000 (19%)]\tTotal Loss: 0.347329\n",
      "Reconstruction: 0.183599, Regularization: 0.098724, Discriminator: 0.043338; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:49,800 root         INFO     Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 0.210362\n",
      "Reconstruction: 0.108469, Regularization: 0.036904, Discriminator: 0.043324; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:49,911 root         INFO     Train Epoch: 142 [2560/8000 (32%)]\tTotal Loss: 0.251795\n",
      "Reconstruction: 0.140769, Regularization: 0.046049, Discriminator: 0.043315; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:50,022 root         INFO     Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 0.256897\n",
      "Reconstruction: 0.153687, Regularization: 0.038213, Discriminator: 0.043324; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:50,132 root         INFO     Train Epoch: 142 [3584/8000 (45%)]\tTotal Loss: 0.737993\n",
      "Reconstruction: 0.557861, Regularization: 0.115147, Discriminator: 0.043317; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:50,243 root         INFO     Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 55.188877\n",
      "Reconstruction: 55.059696, Regularization: 0.064185, Discriminator: 0.043328; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:50,354 root         INFO     Train Epoch: 142 [4608/8000 (58%)]\tTotal Loss: 0.262636\n",
      "Reconstruction: 0.135173, Regularization: 0.062485, Discriminator: 0.043340; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:50,465 root         INFO     Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 1.092463\n",
      "Reconstruction: 0.674775, Regularization: 0.352711, Discriminator: 0.043312; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:50,575 root         INFO     Train Epoch: 142 [5632/8000 (70%)]\tTotal Loss: 2.281362\n",
      "Reconstruction: 1.993949, Regularization: 0.222429, Discriminator: 0.043331; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:50,686 root         INFO     Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 0.467901\n",
      "Reconstruction: 0.362821, Regularization: 0.040104, Discriminator: 0.043302; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:50,797 root         INFO     Train Epoch: 142 [6656/8000 (83%)]\tTotal Loss: 0.417471\n",
      "Reconstruction: 0.211520, Regularization: 0.140979, Discriminator: 0.043338; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:50,907 root         INFO     Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 0.283563\n",
      "Reconstruction: 0.171440, Regularization: 0.047136, Discriminator: 0.043314; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:51,018 root         INFO     Train Epoch: 142 [7680/8000 (96%)]\tTotal Loss: 0.287647\n",
      "Reconstruction: 0.158989, Regularization: 0.063671, Discriminator: 0.043340; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:51,100 root         INFO     ====> Epoch: 142 Average loss: 7474.4918\n",
      "2019-04-09 23:35:51,127 root         INFO     Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 0.259108\n",
      "Reconstruction: 0.136951, Regularization: 0.057189, Discriminator: 0.043334; Generator: 0.021635,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:51,238 root         INFO     Train Epoch: 143 [512/8000 (6%)]\tTotal Loss: 0.321447\n",
      "Reconstruction: 0.119568, Regularization: 0.136879, Discriminator: 0.043329; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:51,350 root         INFO     Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 0.220581\n",
      "Reconstruction: 0.122017, Regularization: 0.033567, Discriminator: 0.043352; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:51,461 root         INFO     Train Epoch: 143 [1536/8000 (19%)]\tTotal Loss: 0.265269\n",
      "Reconstruction: 0.141436, Regularization: 0.058874, Discriminator: 0.043310; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:51,573 root         INFO     Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 0.222983\n",
      "Reconstruction: 0.121546, Regularization: 0.036437, Discriminator: 0.043331; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:51,684 root         INFO     Train Epoch: 143 [2560/8000 (32%)]\tTotal Loss: 0.240671\n",
      "Reconstruction: 0.138014, Regularization: 0.037645, Discriminator: 0.043371; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:51,795 root         INFO     Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 7.833230\n",
      "Reconstruction: 7.562518, Regularization: 0.205735, Discriminator: 0.043311; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:51,906 root         INFO     Train Epoch: 143 [3584/8000 (45%)]\tTotal Loss: 0.339732\n",
      "Reconstruction: 0.146144, Regularization: 0.128615, Discriminator: 0.043320; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:52,017 root         INFO     Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 0.335713\n",
      "Reconstruction: 0.214898, Regularization: 0.055834, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:52,129 root         INFO     Train Epoch: 143 [4608/8000 (58%)]\tTotal Loss: 0.253563\n",
      "Reconstruction: 0.121516, Regularization: 0.067068, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:52,240 root         INFO     Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 0.443925\n",
      "Reconstruction: 0.287273, Regularization: 0.091672, Discriminator: 0.043327; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:52,351 root         INFO     Train Epoch: 143 [5632/8000 (70%)]\tTotal Loss: 0.236815\n",
      "Reconstruction: 0.118449, Regularization: 0.053388, Discriminator: 0.043325; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:52,462 root         INFO     Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 0.382467\n",
      "Reconstruction: 0.282607, Regularization: 0.034888, Discriminator: 0.043320; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:52,574 root         INFO     Train Epoch: 143 [6656/8000 (83%)]\tTotal Loss: 0.229708\n",
      "Reconstruction: 0.115586, Regularization: 0.049129, Discriminator: 0.043338; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:52,685 root         INFO     Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 0.230830\n",
      "Reconstruction: 0.124982, Regularization: 0.040880, Discriminator: 0.043323; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:52,796 root         INFO     Train Epoch: 143 [7680/8000 (96%)]\tTotal Loss: 0.402571\n",
      "Reconstruction: 0.243167, Regularization: 0.094389, Discriminator: 0.043360; Generator: 0.021655,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:35:52,877 root         INFO     ====> Epoch: 143 Average loss: 114.7912\n",
      "2019-04-09 23:35:52,904 root         INFO     Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 0.256912\n",
      "Reconstruction: 0.163442, Regularization: 0.028485, Discriminator: 0.043343; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:53,015 root         INFO     Train Epoch: 144 [512/8000 (6%)]\tTotal Loss: 0.228429\n",
      "Reconstruction: 0.111924, Regularization: 0.051533, Discriminator: 0.043296; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:53,126 root         INFO     Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 0.264526\n",
      "Reconstruction: 0.145563, Regularization: 0.053973, Discriminator: 0.043287; Generator: 0.021703,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:35:53,237 root         INFO     Train Epoch: 144 [1536/8000 (19%)]\tTotal Loss: 0.576475\n",
      "Reconstruction: 0.218805, Regularization: 0.292659, Discriminator: 0.043352; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:53,349 root         INFO     Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 0.266298\n",
      "Reconstruction: 0.149138, Regularization: 0.052191, Discriminator: 0.043319; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:53,460 root         INFO     Train Epoch: 144 [2560/8000 (32%)]\tTotal Loss: 0.614082\n",
      "Reconstruction: 0.488648, Regularization: 0.060436, Discriminator: 0.043338; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:53,571 root         INFO     Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 0.220478\n",
      "Reconstruction: 0.120860, Regularization: 0.034637, Discriminator: 0.043301; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:53,682 root         INFO     Train Epoch: 144 [3584/8000 (45%)]\tTotal Loss: 0.254026\n",
      "Reconstruction: 0.134473, Regularization: 0.054564, Discriminator: 0.043330; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:53,794 root         INFO     Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 0.364814\n",
      "Reconstruction: 0.214208, Regularization: 0.085615, Discriminator: 0.043334; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:53,906 root         INFO     Train Epoch: 144 [4608/8000 (58%)]\tTotal Loss: 0.244448\n",
      "Reconstruction: 0.138464, Regularization: 0.041003, Discriminator: 0.043316; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:54,018 root         INFO     Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 0.268947\n",
      "Reconstruction: 0.155558, Regularization: 0.048405, Discriminator: 0.043315; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:54,130 root         INFO     Train Epoch: 144 [5632/8000 (70%)]\tTotal Loss: 0.539027\n",
      "Reconstruction: 0.440089, Regularization: 0.033961, Discriminator: 0.043324; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:54,241 root         INFO     Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 0.216327\n",
      "Reconstruction: 0.119566, Regularization: 0.031772, Discriminator: 0.043334; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:54,354 root         INFO     Train Epoch: 144 [6656/8000 (83%)]\tTotal Loss: 0.212485\n",
      "Reconstruction: 0.112579, Regularization: 0.034924, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:54,467 root         INFO     Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 0.342544\n",
      "Reconstruction: 0.231996, Regularization: 0.045553, Discriminator: 0.043334; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:54,580 root         INFO     Train Epoch: 144 [7680/8000 (96%)]\tTotal Loss: 0.209310\n",
      "Reconstruction: 0.121256, Regularization: 0.023071, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:54,661 root         INFO     ====> Epoch: 144 Average loss: 1179.2294\n",
      "2019-04-09 23:35:54,688 root         INFO     Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 0.430180\n",
      "Reconstruction: 0.296769, Regularization: 0.068410, Discriminator: 0.043341; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:54,800 root         INFO     Train Epoch: 145 [512/8000 (6%)]\tTotal Loss: 1.516959\n",
      "Reconstruction: 1.327062, Regularization: 0.124924, Discriminator: 0.043308; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:54,911 root         INFO     Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 0.852849\n",
      "Reconstruction: 0.722641, Regularization: 0.065227, Discriminator: 0.043328; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:55,022 root         INFO     Train Epoch: 145 [1536/8000 (19%)]\tTotal Loss: 0.432819\n",
      "Reconstruction: 0.305253, Regularization: 0.062585, Discriminator: 0.043316; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:55,133 root         INFO     Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 0.544560\n",
      "Reconstruction: 0.253412, Regularization: 0.226150, Discriminator: 0.043330; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:55,244 root         INFO     Train Epoch: 145 [2560/8000 (32%)]\tTotal Loss: 2.816864\n",
      "Reconstruction: 2.706815, Regularization: 0.045074, Discriminator: 0.043320; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:55,355 root         INFO     Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 0.996007\n",
      "Reconstruction: 0.785064, Regularization: 0.145957, Discriminator: 0.043320; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:55,467 root         INFO     Train Epoch: 145 [3584/8000 (45%)]\tTotal Loss: 0.294182\n",
      "Reconstruction: 0.143074, Regularization: 0.086124, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:55,578 root         INFO     Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 0.393509\n",
      "Reconstruction: 0.281844, Regularization: 0.046683, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:55,689 root         INFO     Train Epoch: 145 [4608/8000 (58%)]\tTotal Loss: 0.721037\n",
      "Reconstruction: 0.503426, Regularization: 0.152631, Discriminator: 0.043314; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:55,800 root         INFO     Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 0.243855\n",
      "Reconstruction: 0.139093, Regularization: 0.039779, Discriminator: 0.043325; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:55,911 root         INFO     Train Epoch: 145 [5632/8000 (70%)]\tTotal Loss: 0.743628\n",
      "Reconstruction: 0.598606, Regularization: 0.080039, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:56,021 root         INFO     Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 0.290640\n",
      "Reconstruction: 0.143243, Regularization: 0.082415, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:56,133 root         INFO     Train Epoch: 145 [6656/8000 (83%)]\tTotal Loss: 0.289512\n",
      "Reconstruction: 0.185455, Regularization: 0.039063, Discriminator: 0.043329; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:56,244 root         INFO     Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 0.233794\n",
      "Reconstruction: 0.125727, Regularization: 0.043090, Discriminator: 0.043316; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:56,355 root         INFO     Train Epoch: 145 [7680/8000 (96%)]\tTotal Loss: 0.221576\n",
      "Reconstruction: 0.112849, Regularization: 0.043745, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:56,437 root         INFO     ====> Epoch: 145 Average loss: 215405.4952\n",
      "2019-04-09 23:35:56,464 root         INFO     Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 0.188996\n",
      "Reconstruction: 0.104390, Regularization: 0.019620, Discriminator: 0.043323; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:56,576 root         INFO     Train Epoch: 146 [512/8000 (6%)]\tTotal Loss: 0.366550\n",
      "Reconstruction: 0.182855, Regularization: 0.118710, Discriminator: 0.043319; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:56,687 root         INFO     Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 0.270131\n",
      "Reconstruction: 0.142628, Regularization: 0.062528, Discriminator: 0.043319; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:56,799 root         INFO     Train Epoch: 146 [1536/8000 (19%)]\tTotal Loss: 2.779067\n",
      "Reconstruction: 2.682903, Regularization: 0.031192, Discriminator: 0.043313; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:56,910 root         INFO     Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 0.606243\n",
      "Reconstruction: 0.261252, Regularization: 0.280010, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:57,020 root         INFO     Train Epoch: 146 [2560/8000 (32%)]\tTotal Loss: 0.200144\n",
      "Reconstruction: 0.102737, Regularization: 0.032420, Discriminator: 0.043320; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:57,131 root         INFO     Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 0.428200\n",
      "Reconstruction: 0.292914, Regularization: 0.070291, Discriminator: 0.043327; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:57,242 root         INFO     Train Epoch: 146 [3584/8000 (45%)]\tTotal Loss: 0.672926\n",
      "Reconstruction: 0.519850, Regularization: 0.088081, Discriminator: 0.043330; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:57,353 root         INFO     Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 0.284912\n",
      "Reconstruction: 0.160961, Regularization: 0.058959, Discriminator: 0.043322; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:57,464 root         INFO     Train Epoch: 146 [4608/8000 (58%)]\tTotal Loss: 0.236559\n",
      "Reconstruction: 0.141831, Regularization: 0.029746, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:57,577 root         INFO     Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 0.221118\n",
      "Reconstruction: 0.120497, Regularization: 0.035635, Discriminator: 0.043339; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:57,691 root         INFO     Train Epoch: 146 [5632/8000 (70%)]\tTotal Loss: 0.225659\n",
      "Reconstruction: 0.114745, Regularization: 0.045920, Discriminator: 0.043328; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:57,803 root         INFO     Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 0.224293\n",
      "Reconstruction: 0.111272, Regularization: 0.048033, Discriminator: 0.043328; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:57,915 root         INFO     Train Epoch: 146 [6656/8000 (83%)]\tTotal Loss: 0.207726\n",
      "Reconstruction: 0.107250, Regularization: 0.035488, Discriminator: 0.043327; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:58,026 root         INFO     Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 0.262916\n",
      "Reconstruction: 0.152083, Regularization: 0.045878, Discriminator: 0.043300; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:58,137 root         INFO     Train Epoch: 146 [7680/8000 (96%)]\tTotal Loss: 0.249875\n",
      "Reconstruction: 0.138517, Regularization: 0.046375, Discriminator: 0.043330; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:58,217 root         INFO     ====> Epoch: 146 Average loss: 5.7331\n",
      "2019-04-09 23:35:58,245 root         INFO     Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 0.211188\n",
      "Reconstruction: 0.109840, Regularization: 0.036364, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:58,357 root         INFO     Train Epoch: 147 [512/8000 (6%)]\tTotal Loss: 0.275767\n",
      "Reconstruction: 0.138569, Regularization: 0.072232, Discriminator: 0.043304; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:58,468 root         INFO     Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 0.234479\n",
      "Reconstruction: 0.113054, Regularization: 0.056438, Discriminator: 0.043331; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:58,579 root         INFO     Train Epoch: 147 [1536/8000 (19%)]\tTotal Loss: 0.222892\n",
      "Reconstruction: 0.109589, Regularization: 0.048306, Discriminator: 0.043330; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:58,689 root         INFO     Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 0.241082\n",
      "Reconstruction: 0.101285, Regularization: 0.074810, Discriminator: 0.043318; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:58,799 root         INFO     Train Epoch: 147 [2560/8000 (32%)]\tTotal Loss: 0.220854\n",
      "Reconstruction: 0.121996, Regularization: 0.033868, Discriminator: 0.043324; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:58,911 root         INFO     Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 0.201320\n",
      "Reconstruction: 0.110936, Regularization: 0.025402, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:59,021 root         INFO     Train Epoch: 147 [3584/8000 (45%)]\tTotal Loss: 0.271435\n",
      "Reconstruction: 0.137619, Regularization: 0.068831, Discriminator: 0.043316; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:59,132 root         INFO     Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 0.249685\n",
      "Reconstruction: 0.128122, Regularization: 0.056575, Discriminator: 0.043315; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:59,243 root         INFO     Train Epoch: 147 [4608/8000 (58%)]\tTotal Loss: 0.354783\n",
      "Reconstruction: 0.246408, Regularization: 0.043392, Discriminator: 0.043332; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:59,354 root         INFO     Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 0.218399\n",
      "Reconstruction: 0.124448, Regularization: 0.028968, Discriminator: 0.043327; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:59,465 root         INFO     Train Epoch: 147 [5632/8000 (70%)]\tTotal Loss: 0.449842\n",
      "Reconstruction: 0.298267, Regularization: 0.086592, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:59,576 root         INFO     Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 0.224696\n",
      "Reconstruction: 0.115523, Regularization: 0.044191, Discriminator: 0.043310; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:59,687 root         INFO     Train Epoch: 147 [6656/8000 (83%)]\tTotal Loss: 0.223704\n",
      "Reconstruction: 0.130400, Regularization: 0.028327, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:59,798 root         INFO     Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 0.233900\n",
      "Reconstruction: 0.124822, Regularization: 0.044101, Discriminator: 0.043327; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:59,910 root         INFO     Train Epoch: 147 [7680/8000 (96%)]\tTotal Loss: 0.724165\n",
      "Reconstruction: 0.369267, Regularization: 0.289920, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:35:59,991 root         INFO     ====> Epoch: 147 Average loss: 34.2577\n",
      "2019-04-09 23:36:00,019 root         INFO     Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 0.623646\n",
      "Reconstruction: 0.424246, Regularization: 0.134416, Discriminator: 0.043325; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:00,131 root         INFO     Train Epoch: 148 [512/8000 (6%)]\tTotal Loss: 0.232493\n",
      "Reconstruction: 0.112084, Regularization: 0.055428, Discriminator: 0.043333; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:00,243 root         INFO     Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 0.305039\n",
      "Reconstruction: 0.163967, Regularization: 0.076088, Discriminator: 0.043309; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:00,356 root         INFO     Train Epoch: 148 [1536/8000 (19%)]\tTotal Loss: 0.343486\n",
      "Reconstruction: 0.197646, Regularization: 0.080858, Discriminator: 0.043318; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:00,469 root         INFO     Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 0.276801\n",
      "Reconstruction: 0.119176, Regularization: 0.092641, Discriminator: 0.043327; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:00,581 root         INFO     Train Epoch: 148 [2560/8000 (32%)]\tTotal Loss: 0.501965\n",
      "Reconstruction: 0.335335, Regularization: 0.101639, Discriminator: 0.043316; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:00,694 root         INFO     Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 0.655821\n",
      "Reconstruction: 0.542356, Regularization: 0.048489, Discriminator: 0.043319; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:00,807 root         INFO     Train Epoch: 148 [3584/8000 (45%)]\tTotal Loss: 6.469211\n",
      "Reconstruction: 6.218169, Regularization: 0.186048, Discriminator: 0.043327; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:00,920 root         INFO     Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 0.205975\n",
      "Reconstruction: 0.109886, Regularization: 0.031106, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:01,033 root         INFO     Train Epoch: 148 [4608/8000 (58%)]\tTotal Loss: 0.284740\n",
      "Reconstruction: 0.137699, Regularization: 0.082053, Discriminator: 0.043331; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:01,145 root         INFO     Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 0.320115\n",
      "Reconstruction: 0.196230, Regularization: 0.058904, Discriminator: 0.043311; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:01,258 root         INFO     Train Epoch: 148 [5632/8000 (70%)]\tTotal Loss: 0.277073\n",
      "Reconstruction: 0.134996, Regularization: 0.077104, Discriminator: 0.043314; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:01,369 root         INFO     Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 0.187979\n",
      "Reconstruction: 0.100386, Regularization: 0.022615, Discriminator: 0.043324; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:01,480 root         INFO     Train Epoch: 148 [6656/8000 (83%)]\tTotal Loss: 1.224150\n",
      "Reconstruction: 1.101139, Regularization: 0.058028, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:01,593 root         INFO     Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 0.218102\n",
      "Reconstruction: 0.104512, Regularization: 0.048618, Discriminator: 0.043311; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:01,705 root         INFO     Train Epoch: 148 [7680/8000 (96%)]\tTotal Loss: 0.265241\n",
      "Reconstruction: 0.135084, Regularization: 0.065174, Discriminator: 0.043328; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:01,786 root         INFO     ====> Epoch: 148 Average loss: 3.0810\n",
      "2019-04-09 23:36:01,813 root         INFO     Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 0.194843\n",
      "Reconstruction: 0.111428, Regularization: 0.018428, Discriminator: 0.043336; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:01,926 root         INFO     Train Epoch: 149 [512/8000 (6%)]\tTotal Loss: 0.360654\n",
      "Reconstruction: 0.131933, Regularization: 0.163720, Discriminator: 0.043338; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:02,039 root         INFO     Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 0.428730\n",
      "Reconstruction: 0.295034, Regularization: 0.068710, Discriminator: 0.043349; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:02,152 root         INFO     Train Epoch: 149 [1536/8000 (19%)]\tTotal Loss: 0.232252\n",
      "Reconstruction: 0.115335, Regularization: 0.051933, Discriminator: 0.043315; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:02,264 root         INFO     Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 0.808923\n",
      "Reconstruction: 0.554679, Regularization: 0.189242, Discriminator: 0.043354; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:02,377 root         INFO     Train Epoch: 149 [2560/8000 (32%)]\tTotal Loss: 0.705904\n",
      "Reconstruction: 0.595571, Regularization: 0.045354, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:02,488 root         INFO     Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 0.227497\n",
      "Reconstruction: 0.122987, Regularization: 0.039537, Discriminator: 0.043314; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:02,598 root         INFO     Train Epoch: 149 [3584/8000 (45%)]\tTotal Loss: 2.105074\n",
      "Reconstruction: 1.850639, Regularization: 0.189449, Discriminator: 0.043330; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:02,708 root         INFO     Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 0.335887\n",
      "Reconstruction: 0.214589, Regularization: 0.056312, Discriminator: 0.043325; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:02,819 root         INFO     Train Epoch: 149 [4608/8000 (58%)]\tTotal Loss: 0.276508\n",
      "Reconstruction: 0.165668, Regularization: 0.045854, Discriminator: 0.043317; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:02,929 root         INFO     Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 0.381413\n",
      "Reconstruction: 0.261678, Regularization: 0.054765, Discriminator: 0.043306; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:03,038 root         INFO     Train Epoch: 149 [5632/8000 (70%)]\tTotal Loss: 0.421457\n",
      "Reconstruction: 0.274633, Regularization: 0.081850, Discriminator: 0.043309; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:03,149 root         INFO     Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 0.255863\n",
      "Reconstruction: 0.137744, Regularization: 0.053143, Discriminator: 0.043324; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:03,259 root         INFO     Train Epoch: 149 [6656/8000 (83%)]\tTotal Loss: 0.287925\n",
      "Reconstruction: 0.171504, Regularization: 0.051439, Discriminator: 0.043296; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:03,369 root         INFO     Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 0.227232\n",
      "Reconstruction: 0.123313, Regularization: 0.038939, Discriminator: 0.043338; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:03,480 root         INFO     Train Epoch: 149 [7680/8000 (96%)]\tTotal Loss: 0.301141\n",
      "Reconstruction: 0.182057, Regularization: 0.054111, Discriminator: 0.043318; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:03,562 root         INFO     ====> Epoch: 149 Average loss: 376.4684\n",
      "2019-04-09 23:36:03,590 root         INFO     Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 0.313521\n",
      "Reconstruction: 0.200874, Regularization: 0.047666, Discriminator: 0.043306; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:03,701 root         INFO     Train Epoch: 150 [512/8000 (6%)]\tTotal Loss: 0.228564\n",
      "Reconstruction: 0.127704, Regularization: 0.035867, Discriminator: 0.043319; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:03,811 root         INFO     Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 0.221321\n",
      "Reconstruction: 0.124479, Regularization: 0.031857, Discriminator: 0.043301; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:03,919 root         INFO     Train Epoch: 150 [1536/8000 (19%)]\tTotal Loss: 0.220050\n",
      "Reconstruction: 0.118228, Regularization: 0.036832, Discriminator: 0.043323; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:04,026 root         INFO     Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 0.222364\n",
      "Reconstruction: 0.115255, Regularization: 0.042117, Discriminator: 0.043335; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:04,135 root         INFO     Train Epoch: 150 [2560/8000 (32%)]\tTotal Loss: 0.301841\n",
      "Reconstruction: 0.169190, Regularization: 0.067677, Discriminator: 0.043309; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:04,244 root         INFO     Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 0.226884\n",
      "Reconstruction: 0.132284, Regularization: 0.029623, Discriminator: 0.043300; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:04,352 root         INFO     Train Epoch: 150 [3584/8000 (45%)]\tTotal Loss: 0.328228\n",
      "Reconstruction: 0.148417, Regularization: 0.114835, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:04,461 root         INFO     Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 0.248113\n",
      "Reconstruction: 0.113465, Regularization: 0.069664, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:04,570 root         INFO     Train Epoch: 150 [4608/8000 (58%)]\tTotal Loss: 0.290979\n",
      "Reconstruction: 0.165069, Regularization: 0.060927, Discriminator: 0.043321; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:04,679 root         INFO     Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 0.220179\n",
      "Reconstruction: 0.122816, Regularization: 0.032407, Discriminator: 0.043300; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:04,787 root         INFO     Train Epoch: 150 [5632/8000 (70%)]\tTotal Loss: 0.221043\n",
      "Reconstruction: 0.118982, Regularization: 0.037092, Discriminator: 0.043295; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:04,895 root         INFO     Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 0.230328\n",
      "Reconstruction: 0.126368, Regularization: 0.038985, Discriminator: 0.043303; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:05,004 root         INFO     Train Epoch: 150 [6656/8000 (83%)]\tTotal Loss: 0.449192\n",
      "Reconstruction: 0.265388, Regularization: 0.118793, Discriminator: 0.043347; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:05,115 root         INFO     Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 0.241424\n",
      "Reconstruction: 0.120603, Regularization: 0.055827, Discriminator: 0.043310; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:05,225 root         INFO     Train Epoch: 150 [7680/8000 (96%)]\tTotal Loss: 0.251766\n",
      "Reconstruction: 0.151798, Regularization: 0.034966, Discriminator: 0.043325; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:05,306 root         INFO     ====> Epoch: 150 Average loss: 1520.1093\n",
      "2019-04-09 23:36:05,334 root         INFO     Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 123.034081\n",
      "Reconstruction: 122.806305, Regularization: 0.162792, Discriminator: 0.043338; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:05,445 root         INFO     Train Epoch: 151 [512/8000 (6%)]\tTotal Loss: 0.275549\n",
      "Reconstruction: 0.172397, Regularization: 0.038153, Discriminator: 0.043336; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:05,556 root         INFO     Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 0.335807\n",
      "Reconstruction: 0.243792, Regularization: 0.027020, Discriminator: 0.043336; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:05,667 root         INFO     Train Epoch: 151 [1536/8000 (19%)]\tTotal Loss: 0.236780\n",
      "Reconstruction: 0.109008, Regularization: 0.062789, Discriminator: 0.043328; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:05,777 root         INFO     Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 0.267052\n",
      "Reconstruction: 0.124349, Regularization: 0.077714, Discriminator: 0.043314; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:05,889 root         INFO     Train Epoch: 151 [2560/8000 (32%)]\tTotal Loss: 0.282288\n",
      "Reconstruction: 0.152540, Regularization: 0.064778, Discriminator: 0.043304; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:06,000 root         INFO     Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 0.306293\n",
      "Reconstruction: 0.179870, Regularization: 0.061443, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:06,112 root         INFO     Train Epoch: 151 [3584/8000 (45%)]\tTotal Loss: 0.244258\n",
      "Reconstruction: 0.125118, Regularization: 0.054173, Discriminator: 0.043288; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:06,222 root         INFO     Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 0.405794\n",
      "Reconstruction: 0.164091, Regularization: 0.176740, Discriminator: 0.043321; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:06,333 root         INFO     Train Epoch: 151 [4608/8000 (58%)]\tTotal Loss: 0.376164\n",
      "Reconstruction: 0.258144, Regularization: 0.053033, Discriminator: 0.043310; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:06,445 root         INFO     Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 0.215312\n",
      "Reconstruction: 0.115732, Regularization: 0.034613, Discriminator: 0.043322; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:06,556 root         INFO     Train Epoch: 151 [5632/8000 (70%)]\tTotal Loss: 0.203415\n",
      "Reconstruction: 0.118224, Regularization: 0.020208, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:06,667 root         INFO     Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 0.356794\n",
      "Reconstruction: 0.213660, Regularization: 0.078137, Discriminator: 0.043323; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:06,779 root         INFO     Train Epoch: 151 [6656/8000 (83%)]\tTotal Loss: 0.388921\n",
      "Reconstruction: 0.189010, Regularization: 0.134948, Discriminator: 0.043311; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:06,888 root         INFO     Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 0.931903\n",
      "Reconstruction: 0.807333, Regularization: 0.059589, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:06,998 root         INFO     Train Epoch: 151 [7680/8000 (96%)]\tTotal Loss: 0.218202\n",
      "Reconstruction: 0.107123, Regularization: 0.046086, Discriminator: 0.043321; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:07,078 root         INFO     ====> Epoch: 151 Average loss: 158.8418\n",
      "2019-04-09 23:36:07,105 root         INFO     Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 0.354893\n",
      "Reconstruction: 0.224300, Regularization: 0.065618, Discriminator: 0.043314; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:07,217 root         INFO     Train Epoch: 152 [512/8000 (6%)]\tTotal Loss: 0.181102\n",
      "Reconstruction: 0.094033, Regularization: 0.022121, Discriminator: 0.043296; Generator: 0.021652,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:07,328 root         INFO     Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 0.250665\n",
      "Reconstruction: 0.131015, Regularization: 0.054709, Discriminator: 0.043288; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:07,438 root         INFO     Train Epoch: 152 [1536/8000 (19%)]\tTotal Loss: 0.215648\n",
      "Reconstruction: 0.113495, Regularization: 0.037168, Discriminator: 0.043267; Generator: 0.021718,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:36:07,548 root         INFO     Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 0.465566\n",
      "Reconstruction: 0.320064, Regularization: 0.080506, Discriminator: 0.043389; Generator: 0.021606,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:07,658 root         INFO     Train Epoch: 152 [2560/8000 (32%)]\tTotal Loss: 0.214978\n",
      "Reconstruction: 0.114773, Regularization: 0.035229, Discriminator: 0.043234; Generator: 0.021742,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:36:07,769 root         INFO     Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 1.503199\n",
      "Reconstruction: 1.396388, Regularization: 0.041839, Discriminator: 0.043308; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:07,879 root         INFO     Train Epoch: 152 [3584/8000 (45%)]\tTotal Loss: 0.734832\n",
      "Reconstruction: 0.349537, Regularization: 0.320309, Discriminator: 0.043311; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:07,989 root         INFO     Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 0.291736\n",
      "Reconstruction: 0.153404, Regularization: 0.073307, Discriminator: 0.043363; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:08,100 root         INFO     Train Epoch: 152 [4608/8000 (58%)]\tTotal Loss: 6.539666\n",
      "Reconstruction: 6.345288, Regularization: 0.129380, Discriminator: 0.043330; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:08,210 root         INFO     Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 0.323931\n",
      "Reconstruction: 0.193288, Regularization: 0.065665, Discriminator: 0.043321; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:08,320 root         INFO     Train Epoch: 152 [5632/8000 (70%)]\tTotal Loss: 3.732180\n",
      "Reconstruction: 3.539004, Regularization: 0.128187, Discriminator: 0.043329; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:08,430 root         INFO     Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 1.727471\n",
      "Reconstruction: 1.556666, Regularization: 0.105821, Discriminator: 0.043316; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:08,540 root         INFO     Train Epoch: 152 [6656/8000 (83%)]\tTotal Loss: 1523.559570\n",
      "Reconstruction: 1523.256714, Regularization: 0.237870, Discriminator: 0.043299; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:08,651 root         INFO     Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 0.351037\n",
      "Reconstruction: 0.206226, Regularization: 0.079827, Discriminator: 0.043329; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:08,762 root         INFO     Train Epoch: 152 [7680/8000 (96%)]\tTotal Loss: 317.357758\n",
      "Reconstruction: 317.191620, Regularization: 0.101165, Discriminator: 0.043305; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:08,842 root         INFO     ====> Epoch: 152 Average loss: 36.4633\n",
      "2019-04-09 23:36:08,869 root         INFO     Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 126.898621\n",
      "Reconstruction: 126.758255, Regularization: 0.075360, Discriminator: 0.043365; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:08,981 root         INFO     Train Epoch: 153 [512/8000 (6%)]\tTotal Loss: 0.257187\n",
      "Reconstruction: 0.162013, Regularization: 0.030173, Discriminator: 0.043320; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:09,092 root         INFO     Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 0.214503\n",
      "Reconstruction: 0.115753, Regularization: 0.033760, Discriminator: 0.043316; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:09,203 root         INFO     Train Epoch: 153 [1536/8000 (19%)]\tTotal Loss: 0.377308\n",
      "Reconstruction: 0.217053, Regularization: 0.095297, Discriminator: 0.043301; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:09,312 root         INFO     Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 0.222210\n",
      "Reconstruction: 0.116415, Regularization: 0.040826, Discriminator: 0.043318; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:09,426 root         INFO     Train Epoch: 153 [2560/8000 (32%)]\tTotal Loss: 4.909934\n",
      "Reconstruction: 4.777866, Regularization: 0.067117, Discriminator: 0.043305; Generator: 0.021645,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:09,541 root         INFO     Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 282.991974\n",
      "Reconstruction: 282.736267, Regularization: 0.190779, Discriminator: 0.043289; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:09,656 root         INFO     Train Epoch: 153 [3584/8000 (45%)]\tTotal Loss: 0.261854\n",
      "Reconstruction: 0.152674, Regularization: 0.044215, Discriminator: 0.043287; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:09,770 root         INFO     Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 0.318353\n",
      "Reconstruction: 0.140133, Regularization: 0.113224, Discriminator: 0.043325; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:09,883 root         INFO     Train Epoch: 153 [4608/8000 (58%)]\tTotal Loss: 0.658406\n",
      "Reconstruction: 0.532433, Regularization: 0.060975, Discriminator: 0.043333; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:09,997 root         INFO     Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 0.292417\n",
      "Reconstruction: 0.143755, Regularization: 0.083664, Discriminator: 0.043332; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:10,111 root         INFO     Train Epoch: 153 [5632/8000 (70%)]\tTotal Loss: 5.870033\n",
      "Reconstruction: 5.758651, Regularization: 0.046409, Discriminator: 0.043316; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:10,224 root         INFO     Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 0.238948\n",
      "Reconstruction: 0.139961, Regularization: 0.034019, Discriminator: 0.043304; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:10,336 root         INFO     Train Epoch: 153 [6656/8000 (83%)]\tTotal Loss: 0.257760\n",
      "Reconstruction: 0.144196, Regularization: 0.048581, Discriminator: 0.043320; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:10,448 root         INFO     Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 236887.828125\n",
      "Reconstruction: 236887.515625, Regularization: 0.247242, Discriminator: 0.043325; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:10,561 root         INFO     Train Epoch: 153 [7680/8000 (96%)]\tTotal Loss: 0.234331\n",
      "Reconstruction: 0.119205, Regularization: 0.050115, Discriminator: 0.043362; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:10,643 root         INFO     ====> Epoch: 153 Average loss: 7361927.5422\n",
      "2019-04-09 23:36:10,670 root         INFO     Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 0.215572\n",
      "Reconstruction: 0.118420, Regularization: 0.032180, Discriminator: 0.043303; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:10,783 root         INFO     Train Epoch: 154 [512/8000 (6%)]\tTotal Loss: 0.208960\n",
      "Reconstruction: 0.111625, Regularization: 0.032356, Discriminator: 0.043357; Generator: 0.021622,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:10,897 root         INFO     Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 0.263799\n",
      "Reconstruction: 0.101191, Regularization: 0.097594, Discriminator: 0.043333; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:11,009 root         INFO     Train Epoch: 154 [1536/8000 (19%)]\tTotal Loss: 0.244991\n",
      "Reconstruction: 0.111639, Regularization: 0.068385, Discriminator: 0.043279; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:11,121 root         INFO     Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 0.331090\n",
      "Reconstruction: 0.175907, Regularization: 0.090159, Discriminator: 0.043368; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:11,232 root         INFO     Train Epoch: 154 [2560/8000 (32%)]\tTotal Loss: 0.248385\n",
      "Reconstruction: 0.141716, Regularization: 0.041663, Discriminator: 0.043344; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:11,344 root         INFO     Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 0.220485\n",
      "Reconstruction: 0.128729, Regularization: 0.026766, Discriminator: 0.043329; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:11,456 root         INFO     Train Epoch: 154 [3584/8000 (45%)]\tTotal Loss: 0.205766\n",
      "Reconstruction: 0.112960, Regularization: 0.027830, Discriminator: 0.043325; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:11,568 root         INFO     Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 0.236261\n",
      "Reconstruction: 0.129603, Regularization: 0.041670, Discriminator: 0.043313; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:11,678 root         INFO     Train Epoch: 154 [4608/8000 (58%)]\tTotal Loss: 0.319938\n",
      "Reconstruction: 0.201010, Regularization: 0.053944, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:11,789 root         INFO     Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 0.257501\n",
      "Reconstruction: 0.117833, Regularization: 0.074688, Discriminator: 0.043304; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:11,899 root         INFO     Train Epoch: 154 [5632/8000 (70%)]\tTotal Loss: 0.219898\n",
      "Reconstruction: 0.125245, Regularization: 0.029664, Discriminator: 0.043339; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:12,009 root         INFO     Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 0.349139\n",
      "Reconstruction: 0.114240, Regularization: 0.169910, Discriminator: 0.043308; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:12,122 root         INFO     Train Epoch: 154 [6656/8000 (83%)]\tTotal Loss: 0.648817\n",
      "Reconstruction: 0.523272, Regularization: 0.060596, Discriminator: 0.043279; Generator: 0.021670,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:12,235 root         INFO     Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 0.187103\n",
      "Reconstruction: 0.094880, Regularization: 0.027188, Discriminator: 0.043379; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:12,348 root         INFO     Train Epoch: 154 [7680/8000 (96%)]\tTotal Loss: 0.268722\n",
      "Reconstruction: 0.101755, Regularization: 0.102029, Discriminator: 0.043241; Generator: 0.021696,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:36:12,431 root         INFO     ====> Epoch: 154 Average loss: 443.1013\n",
      "2019-04-09 23:36:12,458 root         INFO     Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 0.225180\n",
      "Reconstruction: 0.125977, Regularization: 0.034185, Discriminator: 0.043355; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:12,570 root         INFO     Train Epoch: 155 [512/8000 (6%)]\tTotal Loss: 0.217576\n",
      "Reconstruction: 0.115616, Regularization: 0.036999, Discriminator: 0.043284; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:12,681 root         INFO     Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 0.220273\n",
      "Reconstruction: 0.113980, Regularization: 0.041311, Discriminator: 0.043337; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:12,792 root         INFO     Train Epoch: 155 [1536/8000 (19%)]\tTotal Loss: 2.605223\n",
      "Reconstruction: 2.404714, Regularization: 0.135526, Discriminator: 0.043316; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:12,903 root         INFO     Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 0.338298\n",
      "Reconstruction: 0.136540, Regularization: 0.136765, Discriminator: 0.043357; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:13,014 root         INFO     Train Epoch: 155 [2560/8000 (32%)]\tTotal Loss: 0.222828\n",
      "Reconstruction: 0.110991, Regularization: 0.046839, Discriminator: 0.043335; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:13,125 root         INFO     Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 0.305046\n",
      "Reconstruction: 0.177794, Regularization: 0.062262, Discriminator: 0.043325; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:13,236 root         INFO     Train Epoch: 155 [3584/8000 (45%)]\tTotal Loss: 0.277691\n",
      "Reconstruction: 0.157685, Regularization: 0.055007, Discriminator: 0.043330; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:13,347 root         INFO     Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 0.269197\n",
      "Reconstruction: 0.126635, Regularization: 0.077556, Discriminator: 0.043348; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:13,459 root         INFO     Train Epoch: 155 [4608/8000 (58%)]\tTotal Loss: 23.833385\n",
      "Reconstruction: 23.709867, Regularization: 0.058475, Discriminator: 0.043374; Generator: 0.021669,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:13,570 root         INFO     Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 0.321194\n",
      "Reconstruction: 0.184488, Regularization: 0.071731, Discriminator: 0.043329; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:13,681 root         INFO     Train Epoch: 155 [5632/8000 (70%)]\tTotal Loss: 0.291162\n",
      "Reconstruction: 0.194786, Regularization: 0.031407, Discriminator: 0.043307; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:13,792 root         INFO     Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 0.291021\n",
      "Reconstruction: 0.179375, Regularization: 0.046682, Discriminator: 0.043283; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:13,903 root         INFO     Train Epoch: 155 [6656/8000 (83%)]\tTotal Loss: 0.208120\n",
      "Reconstruction: 0.112096, Regularization: 0.031049, Discriminator: 0.043335; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:14,014 root         INFO     Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 2.207641\n",
      "Reconstruction: 2.063226, Regularization: 0.079411, Discriminator: 0.043298; Generator: 0.021706,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:36:14,125 root         INFO     Train Epoch: 155 [7680/8000 (96%)]\tTotal Loss: 0.263439\n",
      "Reconstruction: 0.146799, Regularization: 0.051637, Discriminator: 0.043356; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:14,206 root         INFO     ====> Epoch: 155 Average loss: 12.5401\n",
      "2019-04-09 23:36:14,234 root         INFO     Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 0.383904\n",
      "Reconstruction: 0.169069, Regularization: 0.149811, Discriminator: 0.043387; Generator: 0.021636,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:14,345 root         INFO     Train Epoch: 156 [512/8000 (6%)]\tTotal Loss: 0.246166\n",
      "Reconstruction: 0.135417, Regularization: 0.045811, Discriminator: 0.043316; Generator: 0.021623,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:36:14,457 root         INFO     Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 0.261047\n",
      "Reconstruction: 0.171154, Regularization: 0.024949, Discriminator: 0.043297; Generator: 0.021647,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:14,567 root         INFO     Train Epoch: 156 [1536/8000 (19%)]\tTotal Loss: 0.501945\n",
      "Reconstruction: 0.295510, Regularization: 0.141408, Discriminator: 0.043369; Generator: 0.021658,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:14,678 root         INFO     Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 0.223825\n",
      "Reconstruction: 0.128805, Regularization: 0.030047, Discriminator: 0.043385; Generator: 0.021587,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:14,790 root         INFO     Train Epoch: 156 [2560/8000 (32%)]\tTotal Loss: 0.283517\n",
      "Reconstruction: 0.146175, Regularization: 0.072368, Discriminator: 0.043308; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:14,901 root         INFO     Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 0.231562\n",
      "Reconstruction: 0.124667, Regularization: 0.041923, Discriminator: 0.043315; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:15,012 root         INFO     Train Epoch: 156 [3584/8000 (45%)]\tTotal Loss: 0.259818\n",
      "Reconstruction: 0.102195, Regularization: 0.092625, Discriminator: 0.043354; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:15,123 root         INFO     Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 0.620056\n",
      "Reconstruction: 0.441945, Regularization: 0.113104, Discriminator: 0.043374; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:15,234 root         INFO     Train Epoch: 156 [4608/8000 (58%)]\tTotal Loss: 0.929425\n",
      "Reconstruction: 0.801488, Regularization: 0.062926, Discriminator: 0.043322; Generator: 0.021688,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:15,345 root         INFO     Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 0.278334\n",
      "Reconstruction: 0.133354, Regularization: 0.079992, Discriminator: 0.043326; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:15,457 root         INFO     Train Epoch: 156 [5632/8000 (70%)]\tTotal Loss: 0.518605\n",
      "Reconstruction: 0.240102, Regularization: 0.213511, Discriminator: 0.043322; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:15,569 root         INFO     Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 0.234943\n",
      "Reconstruction: 0.142129, Regularization: 0.027823, Discriminator: 0.043326; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:15,681 root         INFO     Train Epoch: 156 [6656/8000 (83%)]\tTotal Loss: 0.215150\n",
      "Reconstruction: 0.127642, Regularization: 0.022512, Discriminator: 0.043319; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:15,793 root         INFO     Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 0.212212\n",
      "Reconstruction: 0.117564, Regularization: 0.029673, Discriminator: 0.043319; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:15,905 root         INFO     Train Epoch: 156 [7680/8000 (96%)]\tTotal Loss: 0.203934\n",
      "Reconstruction: 0.104875, Regularization: 0.034065, Discriminator: 0.043322; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:15,985 root         INFO     ====> Epoch: 156 Average loss: 132.7930\n",
      "2019-04-09 23:36:16,013 root         INFO     Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 0.602906\n",
      "Reconstruction: 0.497273, Regularization: 0.040655, Discriminator: 0.043298; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:16,125 root         INFO     Train Epoch: 157 [512/8000 (6%)]\tTotal Loss: 0.290443\n",
      "Reconstruction: 0.170440, Regularization: 0.055022, Discriminator: 0.043332; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:16,236 root         INFO     Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 496.495605\n",
      "Reconstruction: 496.136902, Regularization: 0.293730, Discriminator: 0.043257; Generator: 0.021712,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:36:16,346 root         INFO     Train Epoch: 157 [1536/8000 (19%)]\tTotal Loss: 1.205487\n",
      "Reconstruction: 1.042583, Regularization: 0.097935, Discriminator: 0.043281; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:16,457 root         INFO     Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 0.304096\n",
      "Reconstruction: 0.196938, Regularization: 0.042163, Discriminator: 0.043303; Generator: 0.021691,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:16,568 root         INFO     Train Epoch: 157 [2560/8000 (32%)]\tTotal Loss: 0.307577\n",
      "Reconstruction: 0.179798, Regularization: 0.062801, Discriminator: 0.043367; Generator: 0.021611,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:16,679 root         INFO     Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 0.222079\n",
      "Reconstruction: 0.109429, Regularization: 0.047677, Discriminator: 0.043350; Generator: 0.021623,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:16,790 root         INFO     Train Epoch: 157 [3584/8000 (45%)]\tTotal Loss: 0.236231\n",
      "Reconstruction: 0.117326, Regularization: 0.053923, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:16,901 root         INFO     Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 0.306327\n",
      "Reconstruction: 0.185506, Regularization: 0.055828, Discriminator: 0.043322; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:17,012 root         INFO     Train Epoch: 157 [4608/8000 (58%)]\tTotal Loss: 1.527605\n",
      "Reconstruction: 1.409965, Regularization: 0.052661, Discriminator: 0.043342; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:17,123 root         INFO     Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 0.279128\n",
      "Reconstruction: 0.137914, Regularization: 0.076245, Discriminator: 0.043306; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:17,234 root         INFO     Train Epoch: 157 [5632/8000 (70%)]\tTotal Loss: 0.216128\n",
      "Reconstruction: 0.112825, Regularization: 0.038322, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:17,345 root         INFO     Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 0.274192\n",
      "Reconstruction: 0.167747, Regularization: 0.041477, Discriminator: 0.043309; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:17,456 root         INFO     Train Epoch: 157 [6656/8000 (83%)]\tTotal Loss: 0.273731\n",
      "Reconstruction: 0.159349, Regularization: 0.049421, Discriminator: 0.043294; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:17,567 root         INFO     Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 0.332281\n",
      "Reconstruction: 0.228733, Regularization: 0.038550, Discriminator: 0.043344; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:17,678 root         INFO     Train Epoch: 157 [7680/8000 (96%)]\tTotal Loss: 0.261878\n",
      "Reconstruction: 0.140294, Regularization: 0.056565, Discriminator: 0.043378; Generator: 0.021641,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:17,759 root         INFO     ====> Epoch: 157 Average loss: 1056.5312\n",
      "2019-04-09 23:36:17,786 root         INFO     Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 0.241836\n",
      "Reconstruction: 0.108499, Regularization: 0.068366, Discriminator: 0.043298; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:17,898 root         INFO     Train Epoch: 158 [512/8000 (6%)]\tTotal Loss: 0.268297\n",
      "Reconstruction: 0.105492, Regularization: 0.097842, Discriminator: 0.043301; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:18,008 root         INFO     Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 0.605843\n",
      "Reconstruction: 0.466027, Regularization: 0.074841, Discriminator: 0.043306; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:18,120 root         INFO     Train Epoch: 158 [1536/8000 (19%)]\tTotal Loss: 0.211888\n",
      "Reconstruction: 0.103759, Regularization: 0.043131, Discriminator: 0.043322; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:18,229 root         INFO     Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 0.826331\n",
      "Reconstruction: 0.710126, Regularization: 0.051196, Discriminator: 0.043345; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:18,339 root         INFO     Train Epoch: 158 [2560/8000 (32%)]\tTotal Loss: 0.241600\n",
      "Reconstruction: 0.122457, Regularization: 0.054162, Discriminator: 0.043317; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:18,448 root         INFO     Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 0.339766\n",
      "Reconstruction: 0.119368, Regularization: 0.155425, Discriminator: 0.043334; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:18,558 root         INFO     Train Epoch: 158 [3584/8000 (45%)]\tTotal Loss: 0.255821\n",
      "Reconstruction: 0.145145, Regularization: 0.045701, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:18,668 root         INFO     Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 0.225956\n",
      "Reconstruction: 0.118794, Regularization: 0.042180, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:18,778 root         INFO     Train Epoch: 158 [4608/8000 (58%)]\tTotal Loss: 0.275091\n",
      "Reconstruction: 0.162719, Regularization: 0.047390, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:18,888 root         INFO     Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 0.205487\n",
      "Reconstruction: 0.099547, Regularization: 0.040958, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:18,997 root         INFO     Train Epoch: 158 [5632/8000 (70%)]\tTotal Loss: 0.188527\n",
      "Reconstruction: 0.092353, Regularization: 0.031187, Discriminator: 0.043323; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:19,106 root         INFO     Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 0.251107\n",
      "Reconstruction: 0.135886, Regularization: 0.050238, Discriminator: 0.043312; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:19,216 root         INFO     Train Epoch: 158 [6656/8000 (83%)]\tTotal Loss: 1.088311\n",
      "Reconstruction: 0.979559, Regularization: 0.043765, Discriminator: 0.043318; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:19,326 root         INFO     Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 0.194172\n",
      "Reconstruction: 0.099262, Regularization: 0.029927, Discriminator: 0.043334; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:19,435 root         INFO     Train Epoch: 158 [7680/8000 (96%)]\tTotal Loss: 0.274350\n",
      "Reconstruction: 0.166984, Regularization: 0.042371, Discriminator: 0.043353; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:19,515 root         INFO     ====> Epoch: 158 Average loss: 49189.5685\n",
      "2019-04-09 23:36:19,542 root         INFO     Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 0.406788\n",
      "Reconstruction: 0.258550, Regularization: 0.083266, Discriminator: 0.043299; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:19,652 root         INFO     Train Epoch: 159 [512/8000 (6%)]\tTotal Loss: 0.600898\n",
      "Reconstruction: 0.419383, Regularization: 0.116543, Discriminator: 0.043302; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:19,762 root         INFO     Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 0.202312\n",
      "Reconstruction: 0.106343, Regularization: 0.030975, Discriminator: 0.043322; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:19,871 root         INFO     Train Epoch: 159 [1536/8000 (19%)]\tTotal Loss: 2.773934\n",
      "Reconstruction: 2.641529, Regularization: 0.067419, Discriminator: 0.043318; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:19,980 root         INFO     Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 0.342693\n",
      "Reconstruction: 0.212681, Regularization: 0.065027, Discriminator: 0.043318; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:20,089 root         INFO     Train Epoch: 159 [2560/8000 (32%)]\tTotal Loss: 0.221909\n",
      "Reconstruction: 0.112214, Regularization: 0.044709, Discriminator: 0.043317; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:20,199 root         INFO     Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 0.221866\n",
      "Reconstruction: 0.118372, Regularization: 0.038520, Discriminator: 0.043318; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:20,308 root         INFO     Train Epoch: 159 [3584/8000 (45%)]\tTotal Loss: 0.234655\n",
      "Reconstruction: 0.123800, Regularization: 0.045852, Discriminator: 0.043335; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:20,420 root         INFO     Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 0.237317\n",
      "Reconstruction: 0.114369, Regularization: 0.057995, Discriminator: 0.043309; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:20,530 root         INFO     Train Epoch: 159 [4608/8000 (58%)]\tTotal Loss: 0.392278\n",
      "Reconstruction: 0.262826, Regularization: 0.064445, Discriminator: 0.043366; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:20,638 root         INFO     Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 0.265209\n",
      "Reconstruction: 0.147513, Regularization: 0.052723, Discriminator: 0.043303; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:20,746 root         INFO     Train Epoch: 159 [5632/8000 (70%)]\tTotal Loss: 0.214536\n",
      "Reconstruction: 0.122083, Regularization: 0.027482, Discriminator: 0.043307; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:20,853 root         INFO     Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 0.218879\n",
      "Reconstruction: 0.115459, Regularization: 0.038431, Discriminator: 0.043343; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:20,961 root         INFO     Train Epoch: 159 [6656/8000 (83%)]\tTotal Loss: 0.229351\n",
      "Reconstruction: 0.117044, Regularization: 0.047332, Discriminator: 0.043301; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:21,071 root         INFO     Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 0.744695\n",
      "Reconstruction: 0.505961, Regularization: 0.173754, Discriminator: 0.043348; Generator: 0.021632,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:21,180 root         INFO     Train Epoch: 159 [7680/8000 (96%)]\tTotal Loss: 0.602773\n",
      "Reconstruction: 0.488024, Regularization: 0.049768, Discriminator: 0.043310; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:21,259 root         INFO     ====> Epoch: 159 Average loss: 2043.5656\n",
      "2019-04-09 23:36:21,287 root         INFO     Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 0.418027\n",
      "Reconstruction: 0.272224, Regularization: 0.080810, Discriminator: 0.043345; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:21,400 root         INFO     Train Epoch: 160 [512/8000 (6%)]\tTotal Loss: 1.191950\n",
      "Reconstruction: 0.938774, Regularization: 0.188180, Discriminator: 0.043331; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:21,512 root         INFO     Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 0.241869\n",
      "Reconstruction: 0.121675, Regularization: 0.055224, Discriminator: 0.043314; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:21,625 root         INFO     Train Epoch: 160 [1536/8000 (19%)]\tTotal Loss: 0.360488\n",
      "Reconstruction: 0.246682, Regularization: 0.048822, Discriminator: 0.043327; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:21,737 root         INFO     Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 0.274366\n",
      "Reconstruction: 0.160903, Regularization: 0.048478, Discriminator: 0.043319; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:21,847 root         INFO     Train Epoch: 160 [2560/8000 (32%)]\tTotal Loss: 0.366574\n",
      "Reconstruction: 0.273335, Regularization: 0.028259, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:21,959 root         INFO     Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 0.527363\n",
      "Reconstruction: 0.359035, Regularization: 0.103340, Discriminator: 0.043319; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:22,071 root         INFO     Train Epoch: 160 [3584/8000 (45%)]\tTotal Loss: 0.276658\n",
      "Reconstruction: 0.157377, Regularization: 0.054307, Discriminator: 0.043311; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:22,183 root         INFO     Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 0.238245\n",
      "Reconstruction: 0.121471, Regularization: 0.051799, Discriminator: 0.043316; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:22,295 root         INFO     Train Epoch: 160 [4608/8000 (58%)]\tTotal Loss: 0.321169\n",
      "Reconstruction: 0.211433, Regularization: 0.044759, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:22,407 root         INFO     Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 0.989654\n",
      "Reconstruction: 0.836686, Regularization: 0.087991, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:22,519 root         INFO     Train Epoch: 160 [5632/8000 (70%)]\tTotal Loss: 0.297732\n",
      "Reconstruction: 0.184844, Regularization: 0.047910, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:22,631 root         INFO     Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 0.373118\n",
      "Reconstruction: 0.236014, Regularization: 0.072111, Discriminator: 0.043337; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:22,743 root         INFO     Train Epoch: 160 [6656/8000 (83%)]\tTotal Loss: 0.228377\n",
      "Reconstruction: 0.115162, Regularization: 0.048238, Discriminator: 0.043330; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:22,855 root         INFO     Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 0.249844\n",
      "Reconstruction: 0.137533, Regularization: 0.047342, Discriminator: 0.043319; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:22,967 root         INFO     Train Epoch: 160 [7680/8000 (96%)]\tTotal Loss: 0.742293\n",
      "Reconstruction: 0.620368, Regularization: 0.056948, Discriminator: 0.043308; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:23,049 root         INFO     ====> Epoch: 160 Average loss: 99.3119\n",
      "2019-04-09 23:36:23,077 root         INFO     Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 0.281430\n",
      "Reconstruction: 0.139806, Regularization: 0.076620, Discriminator: 0.043346; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:23,186 root         INFO     Train Epoch: 161 [512/8000 (6%)]\tTotal Loss: 0.672929\n",
      "Reconstruction: 0.333730, Regularization: 0.274235, Discriminator: 0.043325; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:23,296 root         INFO     Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 0.337998\n",
      "Reconstruction: 0.194043, Regularization: 0.078957, Discriminator: 0.043361; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:23,406 root         INFO     Train Epoch: 161 [1536/8000 (19%)]\tTotal Loss: 0.267969\n",
      "Reconstruction: 0.151928, Regularization: 0.051042, Discriminator: 0.043341; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:23,515 root         INFO     Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 0.263982\n",
      "Reconstruction: 0.135738, Regularization: 0.063244, Discriminator: 0.043330; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:23,624 root         INFO     Train Epoch: 161 [2560/8000 (32%)]\tTotal Loss: 0.241453\n",
      "Reconstruction: 0.112685, Regularization: 0.063780, Discriminator: 0.043336; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:23,734 root         INFO     Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 6.398960\n",
      "Reconstruction: 6.283796, Regularization: 0.050194, Discriminator: 0.043301; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:23,843 root         INFO     Train Epoch: 161 [3584/8000 (45%)]\tTotal Loss: 0.236867\n",
      "Reconstruction: 0.104966, Regularization: 0.066918, Discriminator: 0.043311; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:23,953 root         INFO     Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 0.256607\n",
      "Reconstruction: 0.154176, Regularization: 0.037451, Discriminator: 0.043326; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:24,062 root         INFO     Train Epoch: 161 [4608/8000 (58%)]\tTotal Loss: 0.354421\n",
      "Reconstruction: 0.224557, Regularization: 0.064914, Discriminator: 0.043261; Generator: 0.021689,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:24,171 root         INFO     Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 0.337863\n",
      "Reconstruction: 0.193692, Regularization: 0.079205, Discriminator: 0.043350; Generator: 0.021617,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:24,280 root         INFO     Train Epoch: 161 [5632/8000 (70%)]\tTotal Loss: 0.350899\n",
      "Reconstruction: 0.194292, Regularization: 0.091623, Discriminator: 0.043276; Generator: 0.021708,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:36:24,390 root         INFO     Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 0.524714\n",
      "Reconstruction: 0.416400, Regularization: 0.043339, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:24,500 root         INFO     Train Epoch: 161 [6656/8000 (83%)]\tTotal Loss: 0.214814\n",
      "Reconstruction: 0.121099, Regularization: 0.028679, Discriminator: 0.043424; Generator: 0.021612,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:36:24,609 root         INFO     Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 0.349765\n",
      "Reconstruction: 0.244937, Regularization: 0.039855, Discriminator: 0.043311; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:24,718 root         INFO     Train Epoch: 161 [7680/8000 (96%)]\tTotal Loss: 0.269521\n",
      "Reconstruction: 0.165701, Regularization: 0.038821, Discriminator: 0.043352; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:24,799 root         INFO     ====> Epoch: 161 Average loss: 282350.1855\n",
      "2019-04-09 23:36:24,826 root         INFO     Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 0.214440\n",
      "Reconstruction: 0.105847, Regularization: 0.043576, Discriminator: 0.043314; Generator: 0.021703,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:36:24,936 root         INFO     Train Epoch: 162 [512/8000 (6%)]\tTotal Loss: 0.247591\n",
      "Reconstruction: 0.126748, Regularization: 0.055805, Discriminator: 0.043374; Generator: 0.021665,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:25,046 root         INFO     Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 0.321483\n",
      "Reconstruction: 0.202256, Regularization: 0.054250, Discriminator: 0.043358; Generator: 0.021619,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:25,155 root         INFO     Train Epoch: 162 [1536/8000 (19%)]\tTotal Loss: 0.217089\n",
      "Reconstruction: 0.105047, Regularization: 0.047038, Discriminator: 0.043343; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:25,265 root         INFO     Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 0.422641\n",
      "Reconstruction: 0.294044, Regularization: 0.063619, Discriminator: 0.043315; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:25,374 root         INFO     Train Epoch: 162 [2560/8000 (32%)]\tTotal Loss: 0.282207\n",
      "Reconstruction: 0.131455, Regularization: 0.085743, Discriminator: 0.043360; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:25,484 root         INFO     Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 0.221487\n",
      "Reconstruction: 0.112615, Regularization: 0.043890, Discriminator: 0.043325; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:25,593 root         INFO     Train Epoch: 162 [3584/8000 (45%)]\tTotal Loss: 0.221941\n",
      "Reconstruction: 0.116244, Regularization: 0.040728, Discriminator: 0.043315; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:25,703 root         INFO     Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 0.221185\n",
      "Reconstruction: 0.112162, Regularization: 0.044053, Discriminator: 0.043325; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:25,812 root         INFO     Train Epoch: 162 [4608/8000 (58%)]\tTotal Loss: 0.254156\n",
      "Reconstruction: 0.153754, Regularization: 0.035447, Discriminator: 0.043296; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:25,923 root         INFO     Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 0.257037\n",
      "Reconstruction: 0.115387, Regularization: 0.076667, Discriminator: 0.043348; Generator: 0.021635,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:26,034 root         INFO     Train Epoch: 162 [5632/8000 (70%)]\tTotal Loss: 0.222507\n",
      "Reconstruction: 0.120710, Regularization: 0.036874, Discriminator: 0.043273; Generator: 0.021650,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:26,143 root         INFO     Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 0.419062\n",
      "Reconstruction: 0.277491, Regularization: 0.076552, Discriminator: 0.043374; Generator: 0.021644,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:26,252 root         INFO     Train Epoch: 162 [6656/8000 (83%)]\tTotal Loss: 0.316097\n",
      "Reconstruction: 0.123549, Regularization: 0.127561, Discriminator: 0.043408; Generator: 0.021579,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:26,362 root         INFO     Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 92.275368\n",
      "Reconstruction: 92.141945, Regularization: 0.068385, Discriminator: 0.043326; Generator: 0.021716,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:36:26,471 root         INFO     Train Epoch: 162 [7680/8000 (96%)]\tTotal Loss: 0.227863\n",
      "Reconstruction: 0.113938, Regularization: 0.048911, Discriminator: 0.043397; Generator: 0.021617,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:26,551 root         INFO     ====> Epoch: 162 Average loss: 3.8189\n",
      "2019-04-09 23:36:26,578 root         INFO     Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 5.545857\n",
      "Reconstruction: 5.309914, Regularization: 0.170964, Discriminator: 0.043304; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:26,688 root         INFO     Train Epoch: 163 [512/8000 (6%)]\tTotal Loss: 1.124814\n",
      "Reconstruction: 0.806535, Regularization: 0.253260, Discriminator: 0.043368; Generator: 0.021651,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:26,798 root         INFO     Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 0.247078\n",
      "Reconstruction: 0.121040, Regularization: 0.061029, Discriminator: 0.043334; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:26,908 root         INFO     Train Epoch: 163 [1536/8000 (19%)]\tTotal Loss: 0.241774\n",
      "Reconstruction: 0.152915, Regularization: 0.023894, Discriminator: 0.043294; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:27,018 root         INFO     Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 1.626017\n",
      "Reconstruction: 1.494273, Regularization: 0.066741, Discriminator: 0.043331; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:27,128 root         INFO     Train Epoch: 163 [2560/8000 (32%)]\tTotal Loss: 0.359820\n",
      "Reconstruction: 0.231540, Regularization: 0.063297, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:27,237 root         INFO     Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 0.565002\n",
      "Reconstruction: 0.446242, Regularization: 0.053776, Discriminator: 0.043317; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:27,347 root         INFO     Train Epoch: 163 [3584/8000 (45%)]\tTotal Loss: 0.276563\n",
      "Reconstruction: 0.126453, Regularization: 0.085131, Discriminator: 0.043313; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:27,457 root         INFO     Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 16.239622\n",
      "Reconstruction: 15.924082, Regularization: 0.250562, Discriminator: 0.043292; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:27,566 root         INFO     Train Epoch: 163 [4608/8000 (58%)]\tTotal Loss: 0.481525\n",
      "Reconstruction: 0.351117, Regularization: 0.065412, Discriminator: 0.043363; Generator: 0.021632,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:27,676 root         INFO     Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 0.220862\n",
      "Reconstruction: 0.117146, Regularization: 0.038733, Discriminator: 0.043319; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:27,785 root         INFO     Train Epoch: 163 [5632/8000 (70%)]\tTotal Loss: 0.234923\n",
      "Reconstruction: 0.108814, Regularization: 0.061143, Discriminator: 0.043301; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:27,895 root         INFO     Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 0.230683\n",
      "Reconstruction: 0.120600, Regularization: 0.045085, Discriminator: 0.043327; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:28,005 root         INFO     Train Epoch: 163 [6656/8000 (83%)]\tTotal Loss: 2.161076\n",
      "Reconstruction: 1.982333, Regularization: 0.113813, Discriminator: 0.043277; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:28,116 root         INFO     Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 0.215895\n",
      "Reconstruction: 0.117311, Regularization: 0.033594, Discriminator: 0.043378; Generator: 0.021613,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:28,227 root         INFO     Train Epoch: 163 [7680/8000 (96%)]\tTotal Loss: 0.272817\n",
      "Reconstruction: 0.116324, Regularization: 0.091517, Discriminator: 0.043299; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:28,308 root         INFO     ====> Epoch: 163 Average loss: 25.0840\n",
      "2019-04-09 23:36:28,336 root         INFO     Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 0.283590\n",
      "Reconstruction: 0.111146, Regularization: 0.107506, Discriminator: 0.043313; Generator: 0.021626,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:36:28,449 root         INFO     Train Epoch: 164 [512/8000 (6%)]\tTotal Loss: 0.219580\n",
      "Reconstruction: 0.106992, Regularization: 0.047596, Discriminator: 0.043335; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:28,562 root         INFO     Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 5.133718\n",
      "Reconstruction: 5.000978, Regularization: 0.067722, Discriminator: 0.043356; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:28,675 root         INFO     Train Epoch: 164 [1536/8000 (19%)]\tTotal Loss: 3.977541\n",
      "Reconstruction: 3.825726, Regularization: 0.086843, Discriminator: 0.043332; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:28,788 root         INFO     Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 22.985069\n",
      "Reconstruction: 22.813328, Regularization: 0.106771, Discriminator: 0.043322; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:28,901 root         INFO     Train Epoch: 164 [2560/8000 (32%)]\tTotal Loss: 0.238030\n",
      "Reconstruction: 0.121912, Regularization: 0.051134, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:29,015 root         INFO     Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 0.241902\n",
      "Reconstruction: 0.141018, Regularization: 0.035898, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:29,128 root         INFO     Train Epoch: 164 [3584/8000 (45%)]\tTotal Loss: 0.767285\n",
      "Reconstruction: 0.657665, Regularization: 0.044639, Discriminator: 0.043316; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:29,240 root         INFO     Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 0.258605\n",
      "Reconstruction: 0.143470, Regularization: 0.050172, Discriminator: 0.043297; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:29,350 root         INFO     Train Epoch: 164 [4608/8000 (58%)]\tTotal Loss: 0.264996\n",
      "Reconstruction: 0.156473, Regularization: 0.043529, Discriminator: 0.043347; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:29,461 root         INFO     Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 0.242913\n",
      "Reconstruction: 0.092245, Regularization: 0.085692, Discriminator: 0.043331; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:29,572 root         INFO     Train Epoch: 164 [5632/8000 (70%)]\tTotal Loss: 0.829185\n",
      "Reconstruction: 0.697184, Regularization: 0.067017, Discriminator: 0.043329; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:29,683 root         INFO     Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 0.229239\n",
      "Reconstruction: 0.131699, Regularization: 0.032614, Discriminator: 0.043329; Generator: 0.021597,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:36:29,795 root         INFO     Train Epoch: 164 [6656/8000 (83%)]\tTotal Loss: 0.240845\n",
      "Reconstruction: 0.138960, Regularization: 0.036937, Discriminator: 0.043336; Generator: 0.021612,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:36:29,907 root         INFO     Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 0.553359\n",
      "Reconstruction: 0.135020, Regularization: 0.353378, Discriminator: 0.043320; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:30,020 root         INFO     Train Epoch: 164 [7680/8000 (96%)]\tTotal Loss: 1.066363\n",
      "Reconstruction: 0.893894, Regularization: 0.107446, Discriminator: 0.043342; Generator: 0.021682,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:30,101 root         INFO     ====> Epoch: 164 Average loss: 15.1306\n",
      "2019-04-09 23:36:30,128 root         INFO     Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 12.871226\n",
      "Reconstruction: 12.746932, Regularization: 0.059307, Discriminator: 0.043320; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:30,240 root         INFO     Train Epoch: 165 [512/8000 (6%)]\tTotal Loss: 0.269076\n",
      "Reconstruction: 0.172302, Regularization: 0.031795, Discriminator: 0.043337; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:30,351 root         INFO     Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 0.290055\n",
      "Reconstruction: 0.180762, Regularization: 0.044319, Discriminator: 0.043307; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:30,461 root         INFO     Train Epoch: 165 [1536/8000 (19%)]\tTotal Loss: 0.408934\n",
      "Reconstruction: 0.313082, Regularization: 0.030854, Discriminator: 0.043336; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:30,572 root         INFO     Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 39.521488\n",
      "Reconstruction: 39.315704, Regularization: 0.140787, Discriminator: 0.043328; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:30,683 root         INFO     Train Epoch: 165 [2560/8000 (32%)]\tTotal Loss: 4.397226\n",
      "Reconstruction: 4.221623, Regularization: 0.110615, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:30,794 root         INFO     Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 0.752839\n",
      "Reconstruction: 0.606096, Regularization: 0.081776, Discriminator: 0.043298; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:30,905 root         INFO     Train Epoch: 165 [3584/8000 (45%)]\tTotal Loss: 0.245256\n",
      "Reconstruction: 0.098367, Regularization: 0.081915, Discriminator: 0.043307; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:31,015 root         INFO     Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 0.349769\n",
      "Reconstruction: 0.221094, Regularization: 0.063699, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:31,125 root         INFO     Train Epoch: 165 [4608/8000 (58%)]\tTotal Loss: 0.311687\n",
      "Reconstruction: 0.172193, Regularization: 0.074496, Discriminator: 0.043344; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:31,236 root         INFO     Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 0.349780\n",
      "Reconstruction: 0.177819, Regularization: 0.106986, Discriminator: 0.043350; Generator: 0.021624,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:31,347 root         INFO     Train Epoch: 165 [5632/8000 (70%)]\tTotal Loss: 0.237404\n",
      "Reconstruction: 0.130027, Regularization: 0.042428, Discriminator: 0.043264; Generator: 0.021685,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:31,457 root         INFO     Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 0.383063\n",
      "Reconstruction: 0.268782, Regularization: 0.049271, Discriminator: 0.043372; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:31,567 root         INFO     Train Epoch: 165 [6656/8000 (83%)]\tTotal Loss: 0.246248\n",
      "Reconstruction: 0.125506, Regularization: 0.055731, Discriminator: 0.043400; Generator: 0.021612,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:31,677 root         INFO     Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 0.267324\n",
      "Reconstruction: 0.130047, Regularization: 0.072277, Discriminator: 0.043331; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:31,787 root         INFO     Train Epoch: 165 [7680/8000 (96%)]\tTotal Loss: 0.348256\n",
      "Reconstruction: 0.191909, Regularization: 0.091392, Discriminator: 0.043306; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:31,868 root         INFO     ====> Epoch: 165 Average loss: 42.2020\n",
      "2019-04-09 23:36:31,896 root         INFO     Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 0.280691\n",
      "Reconstruction: 0.134214, Regularization: 0.081536, Discriminator: 0.043301; Generator: 0.021641,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:32,009 root         INFO     Train Epoch: 166 [512/8000 (6%)]\tTotal Loss: 0.293184\n",
      "Reconstruction: 0.170553, Regularization: 0.057643, Discriminator: 0.043340; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:32,121 root         INFO     Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 0.243543\n",
      "Reconstruction: 0.135359, Regularization: 0.043212, Discriminator: 0.043342; Generator: 0.021631,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:32,233 root         INFO     Train Epoch: 166 [1536/8000 (19%)]\tTotal Loss: 0.494759\n",
      "Reconstruction: 0.323281, Regularization: 0.106499, Discriminator: 0.043308; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:32,345 root         INFO     Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 0.439865\n",
      "Reconstruction: 0.165260, Regularization: 0.209634, Discriminator: 0.043311; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:32,458 root         INFO     Train Epoch: 166 [2560/8000 (32%)]\tTotal Loss: 0.230060\n",
      "Reconstruction: 0.132897, Regularization: 0.032184, Discriminator: 0.043332; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:32,571 root         INFO     Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 3.394340\n",
      "Reconstruction: 3.210687, Regularization: 0.118687, Discriminator: 0.043311; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:32,683 root         INFO     Train Epoch: 166 [3584/8000 (45%)]\tTotal Loss: 0.227571\n",
      "Reconstruction: 0.116126, Regularization: 0.046453, Discriminator: 0.043338; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:32,796 root         INFO     Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 17.914940\n",
      "Reconstruction: 17.753481, Regularization: 0.096472, Discriminator: 0.043333; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:32,908 root         INFO     Train Epoch: 166 [4608/8000 (58%)]\tTotal Loss: 0.308823\n",
      "Reconstruction: 0.193984, Regularization: 0.049850, Discriminator: 0.043331; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:33,020 root         INFO     Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 0.280571\n",
      "Reconstruction: 0.173541, Regularization: 0.042056, Discriminator: 0.043316; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:33,129 root         INFO     Train Epoch: 166 [5632/8000 (70%)]\tTotal Loss: 16.573681\n",
      "Reconstruction: 16.338888, Regularization: 0.169807, Discriminator: 0.043313; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:33,238 root         INFO     Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 0.289648\n",
      "Reconstruction: 0.174911, Regularization: 0.049765, Discriminator: 0.043325; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:33,347 root         INFO     Train Epoch: 166 [6656/8000 (83%)]\tTotal Loss: 0.275173\n",
      "Reconstruction: 0.140690, Regularization: 0.069500, Discriminator: 0.043314; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:33,457 root         INFO     Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 0.379495\n",
      "Reconstruction: 0.229087, Regularization: 0.085400, Discriminator: 0.043328; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:33,566 root         INFO     Train Epoch: 166 [7680/8000 (96%)]\tTotal Loss: 0.333446\n",
      "Reconstruction: 0.101017, Regularization: 0.167461, Discriminator: 0.043312; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:33,646 root         INFO     ====> Epoch: 166 Average loss: 9.2156\n",
      "2019-04-09 23:36:33,673 root         INFO     Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 0.237630\n",
      "Reconstruction: 0.124073, Regularization: 0.048581, Discriminator: 0.043319; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:33,786 root         INFO     Train Epoch: 167 [512/8000 (6%)]\tTotal Loss: 0.227621\n",
      "Reconstruction: 0.118999, Regularization: 0.043639, Discriminator: 0.043380; Generator: 0.021602,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:33,897 root         INFO     Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 0.237196\n",
      "Reconstruction: 0.118678, Regularization: 0.053533, Discriminator: 0.043266; Generator: 0.021719,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:36:34,008 root         INFO     Train Epoch: 167 [1536/8000 (19%)]\tTotal Loss: 0.226596\n",
      "Reconstruction: 0.124813, Regularization: 0.036799, Discriminator: 0.043318; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:34,120 root         INFO     Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 0.249475\n",
      "Reconstruction: 0.135432, Regularization: 0.049061, Discriminator: 0.043307; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:34,231 root         INFO     Train Epoch: 167 [2560/8000 (32%)]\tTotal Loss: 0.213737\n",
      "Reconstruction: 0.117784, Regularization: 0.031001, Discriminator: 0.043277; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:34,342 root         INFO     Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 1.115285\n",
      "Reconstruction: 0.943046, Regularization: 0.107225, Discriminator: 0.043372; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:34,453 root         INFO     Train Epoch: 167 [3584/8000 (45%)]\tTotal Loss: 0.794492\n",
      "Reconstruction: 0.689994, Regularization: 0.039513, Discriminator: 0.043341; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:34,563 root         INFO     Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 0.231697\n",
      "Reconstruction: 0.126292, Regularization: 0.040426, Discriminator: 0.043324; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:34,673 root         INFO     Train Epoch: 167 [4608/8000 (58%)]\tTotal Loss: 0.286904\n",
      "Reconstruction: 0.104480, Regularization: 0.117443, Discriminator: 0.043308; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:34,784 root         INFO     Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 0.458813\n",
      "Reconstruction: 0.266773, Regularization: 0.127055, Discriminator: 0.043323; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:34,894 root         INFO     Train Epoch: 167 [5632/8000 (70%)]\tTotal Loss: 0.442263\n",
      "Reconstruction: 0.290399, Regularization: 0.086918, Discriminator: 0.043291; Generator: 0.021655,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:35,005 root         INFO     Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 1.853938\n",
      "Reconstruction: 1.696242, Regularization: 0.092716, Discriminator: 0.043315; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:35,116 root         INFO     Train Epoch: 167 [6656/8000 (83%)]\tTotal Loss: 0.246217\n",
      "Reconstruction: 0.115827, Regularization: 0.065408, Discriminator: 0.043317; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:35,226 root         INFO     Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 0.601050\n",
      "Reconstruction: 0.498461, Regularization: 0.037605, Discriminator: 0.043311; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:35,341 root         INFO     Train Epoch: 167 [7680/8000 (96%)]\tTotal Loss: 0.249061\n",
      "Reconstruction: 0.143686, Regularization: 0.040409, Discriminator: 0.043284; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:35,425 root         INFO     ====> Epoch: 167 Average loss: 32.1194\n",
      "2019-04-09 23:36:35,452 root         INFO     Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 0.239156\n",
      "Reconstruction: 0.138720, Regularization: 0.035433, Discriminator: 0.043322; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:35,564 root         INFO     Train Epoch: 168 [512/8000 (6%)]\tTotal Loss: 0.234661\n",
      "Reconstruction: 0.114291, Regularization: 0.055361, Discriminator: 0.043337; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:35,674 root         INFO     Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 7.725749\n",
      "Reconstruction: 7.542055, Regularization: 0.118763, Discriminator: 0.043304; Generator: 0.021627,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:36:35,784 root         INFO     Train Epoch: 168 [1536/8000 (19%)]\tTotal Loss: 0.217206\n",
      "Reconstruction: 0.112082, Regularization: 0.040138, Discriminator: 0.043329; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:35,895 root         INFO     Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 0.306549\n",
      "Reconstruction: 0.176568, Regularization: 0.064983, Discriminator: 0.043350; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:36,003 root         INFO     Train Epoch: 168 [2560/8000 (32%)]\tTotal Loss: 39.126312\n",
      "Reconstruction: 38.993961, Regularization: 0.067379, Discriminator: 0.043324; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:36,112 root         INFO     Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 0.335643\n",
      "Reconstruction: 0.125416, Regularization: 0.145185, Discriminator: 0.043430; Generator: 0.021611,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:36:36,221 root         INFO     Train Epoch: 168 [3584/8000 (45%)]\tTotal Loss: 0.217411\n",
      "Reconstruction: 0.121264, Regularization: 0.031133, Discriminator: 0.043356; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:36,330 root         INFO     Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 0.271001\n",
      "Reconstruction: 0.126527, Regularization: 0.079481, Discriminator: 0.043303; Generator: 0.021691,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:36,439 root         INFO     Train Epoch: 168 [4608/8000 (58%)]\tTotal Loss: 0.251498\n",
      "Reconstruction: 0.152499, Regularization: 0.034016, Discriminator: 0.043314; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:36,548 root         INFO     Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 0.325477\n",
      "Reconstruction: 0.188076, Regularization: 0.072423, Discriminator: 0.043323; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:36,658 root         INFO     Train Epoch: 168 [5632/8000 (70%)]\tTotal Loss: 0.248119\n",
      "Reconstruction: 0.144526, Regularization: 0.038611, Discriminator: 0.043324; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:36,766 root         INFO     Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 2.971468\n",
      "Reconstruction: 2.734940, Regularization: 0.171548, Discriminator: 0.043324; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:36,876 root         INFO     Train Epoch: 168 [6656/8000 (83%)]\tTotal Loss: 0.209257\n",
      "Reconstruction: 0.116165, Regularization: 0.028155, Discriminator: 0.043258; Generator: 0.021678,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:36,985 root         INFO     Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 0.333000\n",
      "Reconstruction: 0.228276, Regularization: 0.039782, Discriminator: 0.043283; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:37,094 root         INFO     Train Epoch: 168 [7680/8000 (96%)]\tTotal Loss: 0.622028\n",
      "Reconstruction: 0.512890, Regularization: 0.044216, Discriminator: 0.043282; Generator: 0.021639,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:37,172 root         INFO     ====> Epoch: 168 Average loss: 647.9677\n",
      "2019-04-09 23:36:37,199 root         INFO     Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 0.242918\n",
      "Reconstruction: 0.131204, Regularization: 0.046786, Discriminator: 0.043288; Generator: 0.021639,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:37,311 root         INFO     Train Epoch: 169 [512/8000 (6%)]\tTotal Loss: 0.257254\n",
      "Reconstruction: 0.139711, Regularization: 0.052593, Discriminator: 0.043300; Generator: 0.021649,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:37,423 root         INFO     Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 0.341861\n",
      "Reconstruction: 0.206151, Regularization: 0.070724, Discriminator: 0.043358; Generator: 0.021627,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:37,535 root         INFO     Train Epoch: 169 [1536/8000 (19%)]\tTotal Loss: 0.313313\n",
      "Reconstruction: 0.208197, Regularization: 0.040072, Discriminator: 0.043366; Generator: 0.021679,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:37,646 root         INFO     Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 0.306412\n",
      "Reconstruction: 0.156155, Regularization: 0.085251, Discriminator: 0.043312; Generator: 0.021694,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:36:37,757 root         INFO     Train Epoch: 169 [2560/8000 (32%)]\tTotal Loss: 0.288451\n",
      "Reconstruction: 0.180110, Regularization: 0.043310, Discriminator: 0.043366; Generator: 0.021664,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:37,870 root         INFO     Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 0.273533\n",
      "Reconstruction: 0.153752, Regularization: 0.054790, Discriminator: 0.043390; Generator: 0.021601,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:37,982 root         INFO     Train Epoch: 169 [3584/8000 (45%)]\tTotal Loss: 0.226234\n",
      "Reconstruction: 0.113633, Regularization: 0.047625, Discriminator: 0.043361; Generator: 0.021615,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:38,092 root         INFO     Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 0.258380\n",
      "Reconstruction: 0.121791, Regularization: 0.071568, Discriminator: 0.043342; Generator: 0.021679,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:38,202 root         INFO     Train Epoch: 169 [4608/8000 (58%)]\tTotal Loss: 1.270173\n",
      "Reconstruction: 1.131636, Regularization: 0.073477, Discriminator: 0.043401; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:38,312 root         INFO     Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 0.260912\n",
      "Reconstruction: 0.125096, Regularization: 0.070834, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:38,422 root         INFO     Train Epoch: 169 [5632/8000 (70%)]\tTotal Loss: 0.286215\n",
      "Reconstruction: 0.122887, Regularization: 0.098312, Discriminator: 0.043352; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:38,535 root         INFO     Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 0.198669\n",
      "Reconstruction: 0.098874, Regularization: 0.034810, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:38,648 root         INFO     Train Epoch: 169 [6656/8000 (83%)]\tTotal Loss: 0.284551\n",
      "Reconstruction: 0.177039, Regularization: 0.042526, Discriminator: 0.043319; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:38,760 root         INFO     Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 0.372915\n",
      "Reconstruction: 0.232088, Regularization: 0.075831, Discriminator: 0.043332; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:38,872 root         INFO     Train Epoch: 169 [7680/8000 (96%)]\tTotal Loss: 0.220069\n",
      "Reconstruction: 0.126986, Regularization: 0.028113, Discriminator: 0.043310; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:38,954 root         INFO     ====> Epoch: 169 Average loss: 157.6694\n",
      "2019-04-09 23:36:38,981 root         INFO     Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 0.372984\n",
      "Reconstruction: 0.255419, Regularization: 0.052547, Discriminator: 0.043334; Generator: 0.021684,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:39,094 root         INFO     Train Epoch: 170 [512/8000 (6%)]\tTotal Loss: 0.904567\n",
      "Reconstruction: 0.785442, Regularization: 0.054178, Discriminator: 0.043235; Generator: 0.021712,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:36:39,207 root         INFO     Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 0.256817\n",
      "Reconstruction: 0.137759, Regularization: 0.054104, Discriminator: 0.043286; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:39,319 root         INFO     Train Epoch: 170 [1536/8000 (19%)]\tTotal Loss: 0.206045\n",
      "Reconstruction: 0.117838, Regularization: 0.023208, Discriminator: 0.043282; Generator: 0.021718,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:36:39,430 root         INFO     Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 0.443562\n",
      "Reconstruction: 0.258717, Regularization: 0.119859, Discriminator: 0.043296; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:39,539 root         INFO     Train Epoch: 170 [2560/8000 (32%)]\tTotal Loss: 0.307454\n",
      "Reconstruction: 0.215565, Regularization: 0.026835, Discriminator: 0.043438; Generator: 0.021616,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:36:39,648 root         INFO     Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 0.234524\n",
      "Reconstruction: 0.112809, Regularization: 0.056714, Discriminator: 0.043332; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:39,757 root         INFO     Train Epoch: 170 [3584/8000 (45%)]\tTotal Loss: 8.880663\n",
      "Reconstruction: 8.727428, Regularization: 0.088298, Discriminator: 0.043273; Generator: 0.021664,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:39,867 root         INFO     Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 0.196164\n",
      "Reconstruction: 0.104578, Regularization: 0.026561, Discriminator: 0.043310; Generator: 0.021715,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:36:39,978 root         INFO     Train Epoch: 170 [4608/8000 (58%)]\tTotal Loss: 0.612017\n",
      "Reconstruction: 0.502419, Regularization: 0.044655, Discriminator: 0.043264; Generator: 0.021679,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:40,088 root         INFO     Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 0.188691\n",
      "Reconstruction: 0.101827, Regularization: 0.021868, Discriminator: 0.043324; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:40,198 root         INFO     Train Epoch: 170 [5632/8000 (70%)]\tTotal Loss: 0.206100\n",
      "Reconstruction: 0.100382, Regularization: 0.040684, Discriminator: 0.043337; Generator: 0.021698,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:36:40,309 root         INFO     Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 0.232389\n",
      "Reconstruction: 0.126815, Regularization: 0.040567, Discriminator: 0.043328; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:40,419 root         INFO     Train Epoch: 170 [6656/8000 (83%)]\tTotal Loss: 0.209977\n",
      "Reconstruction: 0.108130, Regularization: 0.036860, Discriminator: 0.043341; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:40,530 root         INFO     Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 3.534692\n",
      "Reconstruction: 3.393071, Regularization: 0.076636, Discriminator: 0.043331; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:40,640 root         INFO     Train Epoch: 170 [7680/8000 (96%)]\tTotal Loss: 0.215953\n",
      "Reconstruction: 0.103935, Regularization: 0.047042, Discriminator: 0.043323; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:40,721 root         INFO     ====> Epoch: 170 Average loss: 12.8492\n",
      "2019-04-09 23:36:40,749 root         INFO     Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 356.409790\n",
      "Reconstruction: 356.155457, Regularization: 0.189358, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:40,860 root         INFO     Train Epoch: 171 [512/8000 (6%)]\tTotal Loss: 0.258239\n",
      "Reconstruction: 0.118488, Regularization: 0.074760, Discriminator: 0.043339; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:40,969 root         INFO     Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 0.388175\n",
      "Reconstruction: 0.273949, Regularization: 0.049222, Discriminator: 0.043363; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:41,079 root         INFO     Train Epoch: 171 [1536/8000 (19%)]\tTotal Loss: 0.369323\n",
      "Reconstruction: 0.207559, Regularization: 0.096792, Discriminator: 0.043309; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:41,189 root         INFO     Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 0.213481\n",
      "Reconstruction: 0.113043, Regularization: 0.035495, Discriminator: 0.043306; Generator: 0.021637,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:41,298 root         INFO     Train Epoch: 171 [2560/8000 (32%)]\tTotal Loss: 0.328313\n",
      "Reconstruction: 0.235150, Regularization: 0.028203, Discriminator: 0.043330; Generator: 0.021629,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:41,408 root         INFO     Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 0.233358\n",
      "Reconstruction: 0.123628, Regularization: 0.044730, Discriminator: 0.043335; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:41,519 root         INFO     Train Epoch: 171 [3584/8000 (45%)]\tTotal Loss: 0.219942\n",
      "Reconstruction: 0.123308, Regularization: 0.031643, Discriminator: 0.043248; Generator: 0.021743,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:36:41,631 root         INFO     Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 0.302202\n",
      "Reconstruction: 0.135163, Regularization: 0.102039, Discriminator: 0.043334; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:41,742 root         INFO     Train Epoch: 171 [4608/8000 (58%)]\tTotal Loss: 0.327797\n",
      "Reconstruction: 0.203189, Regularization: 0.059611, Discriminator: 0.043345; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:41,851 root         INFO     Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 0.251261\n",
      "Reconstruction: 0.110241, Regularization: 0.076012, Discriminator: 0.043363; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:41,960 root         INFO     Train Epoch: 171 [5632/8000 (70%)]\tTotal Loss: 0.350709\n",
      "Reconstruction: 0.140555, Regularization: 0.145126, Discriminator: 0.043379; Generator: 0.021650,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:42,067 root         INFO     Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 0.256183\n",
      "Reconstruction: 0.141758, Regularization: 0.049491, Discriminator: 0.043208; Generator: 0.021725,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:36:42,176 root         INFO     Train Epoch: 171 [6656/8000 (83%)]\tTotal Loss: 0.239360\n",
      "Reconstruction: 0.119759, Regularization: 0.054602, Discriminator: 0.043343; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:42,285 root         INFO     Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 0.233080\n",
      "Reconstruction: 0.131379, Regularization: 0.036724, Discriminator: 0.043323; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:42,394 root         INFO     Train Epoch: 171 [7680/8000 (96%)]\tTotal Loss: 0.221738\n",
      "Reconstruction: 0.100927, Regularization: 0.055836, Discriminator: 0.043322; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:42,474 root         INFO     ====> Epoch: 171 Average loss: 14.8771\n",
      "2019-04-09 23:36:42,500 root         INFO     Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 1.046508\n",
      "Reconstruction: 0.911719, Regularization: 0.069791, Discriminator: 0.043326; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:42,613 root         INFO     Train Epoch: 172 [512/8000 (6%)]\tTotal Loss: 0.227420\n",
      "Reconstruction: 0.116674, Regularization: 0.045762, Discriminator: 0.043308; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:42,725 root         INFO     Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 0.326899\n",
      "Reconstruction: 0.179070, Regularization: 0.082837, Discriminator: 0.043326; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:42,837 root         INFO     Train Epoch: 172 [1536/8000 (19%)]\tTotal Loss: 0.914810\n",
      "Reconstruction: 0.648736, Regularization: 0.201073, Discriminator: 0.043338; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:42,949 root         INFO     Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 0.422113\n",
      "Reconstruction: 0.311896, Regularization: 0.045235, Discriminator: 0.043337; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:43,061 root         INFO     Train Epoch: 172 [2560/8000 (32%)]\tTotal Loss: 1.069245\n",
      "Reconstruction: 0.939271, Regularization: 0.064996, Discriminator: 0.043313; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:43,173 root         INFO     Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 0.368997\n",
      "Reconstruction: 0.170131, Regularization: 0.133878, Discriminator: 0.043326; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:43,286 root         INFO     Train Epoch: 172 [3584/8000 (45%)]\tTotal Loss: 0.217215\n",
      "Reconstruction: 0.116345, Regularization: 0.035893, Discriminator: 0.043301; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:43,398 root         INFO     Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 0.230844\n",
      "Reconstruction: 0.118873, Regularization: 0.046953, Discriminator: 0.043342; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:43,510 root         INFO     Train Epoch: 172 [4608/8000 (58%)]\tTotal Loss: 0.198126\n",
      "Reconstruction: 0.102965, Regularization: 0.030178, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:43,621 root         INFO     Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 0.248457\n",
      "Reconstruction: 0.122120, Regularization: 0.061381, Discriminator: 0.043297; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:43,732 root         INFO     Train Epoch: 172 [5632/8000 (70%)]\tTotal Loss: 0.228140\n",
      "Reconstruction: 0.119636, Regularization: 0.043479, Discriminator: 0.043363; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:43,842 root         INFO     Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 0.368424\n",
      "Reconstruction: 0.264463, Regularization: 0.038985, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:43,953 root         INFO     Train Epoch: 172 [6656/8000 (83%)]\tTotal Loss: 17.074463\n",
      "Reconstruction: 16.925970, Regularization: 0.083535, Discriminator: 0.043275; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:44,065 root         INFO     Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 0.230723\n",
      "Reconstruction: 0.123806, Regularization: 0.041903, Discriminator: 0.043350; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:44,176 root         INFO     Train Epoch: 172 [7680/8000 (96%)]\tTotal Loss: 0.401911\n",
      "Reconstruction: 0.224981, Regularization: 0.111965, Discriminator: 0.043305; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:44,256 root         INFO     ====> Epoch: 172 Average loss: 1287.7638\n",
      "2019-04-09 23:36:44,283 root         INFO     Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 0.252189\n",
      "Reconstruction: 0.125050, Regularization: 0.062198, Discriminator: 0.043294; Generator: 0.021648,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:44,396 root         INFO     Train Epoch: 173 [512/8000 (6%)]\tTotal Loss: 0.229652\n",
      "Reconstruction: 0.126836, Regularization: 0.037769, Discriminator: 0.043399; Generator: 0.021648,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:44,507 root         INFO     Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 0.204792\n",
      "Reconstruction: 0.110160, Regularization: 0.029558, Discriminator: 0.043395; Generator: 0.021679,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:44,618 root         INFO     Train Epoch: 173 [1536/8000 (19%)]\tTotal Loss: 0.232407\n",
      "Reconstruction: 0.129073, Regularization: 0.038326, Discriminator: 0.043366; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:44,729 root         INFO     Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 0.301146\n",
      "Reconstruction: 0.150600, Regularization: 0.085566, Discriminator: 0.043335; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:44,840 root         INFO     Train Epoch: 173 [2560/8000 (32%)]\tTotal Loss: 0.240531\n",
      "Reconstruction: 0.131608, Regularization: 0.043934, Discriminator: 0.043329; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:44,952 root         INFO     Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 0.287365\n",
      "Reconstruction: 0.134671, Regularization: 0.087712, Discriminator: 0.043328; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:45,063 root         INFO     Train Epoch: 173 [3584/8000 (45%)]\tTotal Loss: 0.245223\n",
      "Reconstruction: 0.143167, Regularization: 0.037076, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:45,174 root         INFO     Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 0.281861\n",
      "Reconstruction: 0.132887, Regularization: 0.083992, Discriminator: 0.043326; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:45,285 root         INFO     Train Epoch: 173 [4608/8000 (58%)]\tTotal Loss: 0.256659\n",
      "Reconstruction: 0.150302, Regularization: 0.041396, Discriminator: 0.043308; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:45,396 root         INFO     Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 0.217523\n",
      "Reconstruction: 0.110888, Regularization: 0.041668, Discriminator: 0.043291; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:45,507 root         INFO     Train Epoch: 173 [5632/8000 (70%)]\tTotal Loss: 1.245982\n",
      "Reconstruction: 0.887030, Regularization: 0.293952, Discriminator: 0.043360; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:45,618 root         INFO     Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 0.264540\n",
      "Reconstruction: 0.125694, Regularization: 0.073866, Discriminator: 0.043314; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:45,729 root         INFO     Train Epoch: 173 [6656/8000 (83%)]\tTotal Loss: 0.230631\n",
      "Reconstruction: 0.120049, Regularization: 0.045595, Discriminator: 0.043315; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:45,841 root         INFO     Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 0.267565\n",
      "Reconstruction: 0.137864, Regularization: 0.064792, Discriminator: 0.043228; Generator: 0.021681,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:45,952 root         INFO     Train Epoch: 173 [7680/8000 (96%)]\tTotal Loss: 0.459325\n",
      "Reconstruction: 0.120159, Regularization: 0.274147, Discriminator: 0.043332; Generator: 0.021687,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:46,033 root         INFO     ====> Epoch: 173 Average loss: 2518.4319\n",
      "2019-04-09 23:36:46,060 root         INFO     Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 0.256678\n",
      "Reconstruction: 0.115262, Regularization: 0.076434, Discriminator: 0.043357; Generator: 0.021626,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:46,172 root         INFO     Train Epoch: 174 [512/8000 (6%)]\tTotal Loss: 0.290330\n",
      "Reconstruction: 0.167739, Regularization: 0.057628, Discriminator: 0.043242; Generator: 0.021720,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:36:46,282 root         INFO     Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 0.511968\n",
      "Reconstruction: 0.223302, Regularization: 0.223629, Discriminator: 0.043406; Generator: 0.021631,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:46,393 root         INFO     Train Epoch: 174 [1536/8000 (19%)]\tTotal Loss: 0.239875\n",
      "Reconstruction: 0.127728, Regularization: 0.047116, Discriminator: 0.043343; Generator: 0.021689,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:46,504 root         INFO     Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 0.256614\n",
      "Reconstruction: 0.137022, Regularization: 0.054620, Discriminator: 0.043287; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:46,614 root         INFO     Train Epoch: 174 [2560/8000 (32%)]\tTotal Loss: 0.390522\n",
      "Reconstruction: 0.215685, Regularization: 0.109821, Discriminator: 0.043323; Generator: 0.021692,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:46,724 root         INFO     Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 0.253018\n",
      "Reconstruction: 0.102332, Regularization: 0.085681, Discriminator: 0.043340; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:46,835 root         INFO     Train Epoch: 174 [3584/8000 (45%)]\tTotal Loss: 1.979487\n",
      "Reconstruction: 1.847858, Regularization: 0.066647, Discriminator: 0.043311; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:46,945 root         INFO     Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 0.249802\n",
      "Reconstruction: 0.125823, Regularization: 0.058996, Discriminator: 0.043317; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:47,055 root         INFO     Train Epoch: 174 [4608/8000 (58%)]\tTotal Loss: 0.295963\n",
      "Reconstruction: 0.191054, Regularization: 0.039927, Discriminator: 0.043306; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:47,165 root         INFO     Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 0.355286\n",
      "Reconstruction: 0.247121, Regularization: 0.043171, Discriminator: 0.043337; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:47,275 root         INFO     Train Epoch: 174 [5632/8000 (70%)]\tTotal Loss: 1.045171\n",
      "Reconstruction: 0.783251, Regularization: 0.196953, Discriminator: 0.043318; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:47,385 root         INFO     Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 0.216573\n",
      "Reconstruction: 0.105786, Regularization: 0.045814, Discriminator: 0.043297; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:47,496 root         INFO     Train Epoch: 174 [6656/8000 (83%)]\tTotal Loss: 0.286004\n",
      "Reconstruction: 0.164247, Regularization: 0.056765, Discriminator: 0.043274; Generator: 0.021718,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:36:47,606 root         INFO     Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 0.257593\n",
      "Reconstruction: 0.125209, Regularization: 0.067423, Discriminator: 0.043324; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:47,716 root         INFO     Train Epoch: 174 [7680/8000 (96%)]\tTotal Loss: 0.228400\n",
      "Reconstruction: 0.122437, Regularization: 0.040945, Discriminator: 0.043326; Generator: 0.021692,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:47,796 root         INFO     ====> Epoch: 174 Average loss: 903.5731\n",
      "2019-04-09 23:36:47,823 root         INFO     Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 0.970535\n",
      "Reconstruction: 0.847066, Regularization: 0.058537, Discriminator: 0.043309; Generator: 0.021623,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:36:47,934 root         INFO     Train Epoch: 175 [512/8000 (6%)]\tTotal Loss: 0.270998\n",
      "Reconstruction: 0.136105, Regularization: 0.069879, Discriminator: 0.043281; Generator: 0.021733,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:36:48,044 root         INFO     Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 0.215029\n",
      "Reconstruction: 0.119197, Regularization: 0.030835, Discriminator: 0.043409; Generator: 0.021589,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:36:48,155 root         INFO     Train Epoch: 175 [1536/8000 (19%)]\tTotal Loss: 0.314610\n",
      "Reconstruction: 0.182590, Regularization: 0.067077, Discriminator: 0.043229; Generator: 0.021715,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:36:48,265 root         INFO     Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 0.349926\n",
      "Reconstruction: 0.202677, Regularization: 0.082274, Discriminator: 0.043304; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:48,375 root         INFO     Train Epoch: 175 [2560/8000 (32%)]\tTotal Loss: 0.232929\n",
      "Reconstruction: 0.121254, Regularization: 0.046713, Discriminator: 0.043290; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:48,486 root         INFO     Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 0.240239\n",
      "Reconstruction: 0.128936, Regularization: 0.046313, Discriminator: 0.043340; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:48,596 root         INFO     Train Epoch: 175 [3584/8000 (45%)]\tTotal Loss: 0.285554\n",
      "Reconstruction: 0.150254, Regularization: 0.070323, Discriminator: 0.043296; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:48,707 root         INFO     Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 0.241670\n",
      "Reconstruction: 0.139308, Regularization: 0.037375, Discriminator: 0.043336; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:48,818 root         INFO     Train Epoch: 175 [4608/8000 (58%)]\tTotal Loss: 0.211552\n",
      "Reconstruction: 0.116254, Regularization: 0.030309, Discriminator: 0.043340; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:48,929 root         INFO     Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 1.650034\n",
      "Reconstruction: 1.462995, Regularization: 0.122056, Discriminator: 0.043326; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:49,040 root         INFO     Train Epoch: 175 [5632/8000 (70%)]\tTotal Loss: 0.222884\n",
      "Reconstruction: 0.127471, Regularization: 0.030449, Discriminator: 0.043304; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:49,151 root         INFO     Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 0.268315\n",
      "Reconstruction: 0.161749, Regularization: 0.041591, Discriminator: 0.043324; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:49,261 root         INFO     Train Epoch: 175 [6656/8000 (83%)]\tTotal Loss: 0.291586\n",
      "Reconstruction: 0.123292, Regularization: 0.103310, Discriminator: 0.043310; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:49,372 root         INFO     Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 0.273110\n",
      "Reconstruction: 0.122569, Regularization: 0.085533, Discriminator: 0.043288; Generator: 0.021720,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:36:49,483 root         INFO     Train Epoch: 175 [7680/8000 (96%)]\tTotal Loss: 0.910131\n",
      "Reconstruction: 0.757712, Regularization: 0.087386, Discriminator: 0.043318; Generator: 0.021715,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:36:49,563 root         INFO     ====> Epoch: 175 Average loss: 36.6495\n",
      "2019-04-09 23:36:49,591 root         INFO     Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 0.573103\n",
      "Reconstruction: 0.449392, Regularization: 0.058722, Discriminator: 0.043348; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:49,702 root         INFO     Train Epoch: 176 [512/8000 (6%)]\tTotal Loss: 0.209032\n",
      "Reconstruction: 0.101718, Regularization: 0.042382, Discriminator: 0.043219; Generator: 0.021713,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:36:49,812 root         INFO     Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 0.364146\n",
      "Reconstruction: 0.250430, Regularization: 0.048763, Discriminator: 0.043289; Generator: 0.021663,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:49,920 root         INFO     Train Epoch: 176 [1536/8000 (19%)]\tTotal Loss: 1.196216\n",
      "Reconstruction: 0.991551, Regularization: 0.139567, Discriminator: 0.043452; Generator: 0.021645,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:36:50,029 root         INFO     Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 0.267358\n",
      "Reconstruction: 0.127958, Regularization: 0.074385, Discriminator: 0.043354; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:50,140 root         INFO     Train Epoch: 176 [2560/8000 (32%)]\tTotal Loss: 0.350881\n",
      "Reconstruction: 0.188182, Regularization: 0.097660, Discriminator: 0.043364; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:50,250 root         INFO     Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 0.196837\n",
      "Reconstruction: 0.095686, Regularization: 0.036198, Discriminator: 0.043249; Generator: 0.021703,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:36:50,361 root         INFO     Train Epoch: 176 [3584/8000 (45%)]\tTotal Loss: 0.323284\n",
      "Reconstruction: 0.205865, Regularization: 0.052443, Discriminator: 0.043308; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:50,471 root         INFO     Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 0.885104\n",
      "Reconstruction: 0.738602, Regularization: 0.081512, Discriminator: 0.043311; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:50,582 root         INFO     Train Epoch: 176 [4608/8000 (58%)]\tTotal Loss: 0.291437\n",
      "Reconstruction: 0.139018, Regularization: 0.087396, Discriminator: 0.043356; Generator: 0.021667,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:50,692 root         INFO     Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 0.245921\n",
      "Reconstruction: 0.127200, Regularization: 0.053716, Discriminator: 0.043330; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:50,803 root         INFO     Train Epoch: 176 [5632/8000 (70%)]\tTotal Loss: 20.751894\n",
      "Reconstruction: 20.598396, Regularization: 0.088528, Discriminator: 0.043304; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:50,914 root         INFO     Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 0.249732\n",
      "Reconstruction: 0.132075, Regularization: 0.052660, Discriminator: 0.043328; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:51,026 root         INFO     Train Epoch: 176 [6656/8000 (83%)]\tTotal Loss: 0.227453\n",
      "Reconstruction: 0.124240, Regularization: 0.038257, Discriminator: 0.043298; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:51,137 root         INFO     Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 0.443612\n",
      "Reconstruction: 0.286902, Regularization: 0.091729, Discriminator: 0.043317; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:51,250 root         INFO     Train Epoch: 176 [7680/8000 (96%)]\tTotal Loss: 0.281339\n",
      "Reconstruction: 0.121966, Regularization: 0.094382, Discriminator: 0.043324; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:51,332 root         INFO     ====> Epoch: 176 Average loss: 59230.0525\n",
      "2019-04-09 23:36:51,359 root         INFO     Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 0.316070\n",
      "Reconstruction: 0.150338, Regularization: 0.100776, Discriminator: 0.043287; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:51,472 root         INFO     Train Epoch: 177 [512/8000 (6%)]\tTotal Loss: 0.545878\n",
      "Reconstruction: 0.402402, Regularization: 0.078519, Discriminator: 0.043265; Generator: 0.021692,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:36:51,585 root         INFO     Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 0.240117\n",
      "Reconstruction: 0.136952, Regularization: 0.038180, Discriminator: 0.043330; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:51,698 root         INFO     Train Epoch: 177 [1536/8000 (19%)]\tTotal Loss: 0.248210\n",
      "Reconstruction: 0.128160, Regularization: 0.055051, Discriminator: 0.043327; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:51,808 root         INFO     Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 0.263183\n",
      "Reconstruction: 0.142888, Regularization: 0.055311, Discriminator: 0.043305; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:51,916 root         INFO     Train Epoch: 177 [2560/8000 (32%)]\tTotal Loss: 0.292023\n",
      "Reconstruction: 0.175887, Regularization: 0.051114, Discriminator: 0.043378; Generator: 0.021645,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:52,024 root         INFO     Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 0.334020\n",
      "Reconstruction: 0.110021, Regularization: 0.159027, Discriminator: 0.043303; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:52,130 root         INFO     Train Epoch: 177 [3584/8000 (45%)]\tTotal Loss: 0.218759\n",
      "Reconstruction: 0.116173, Regularization: 0.037583, Discriminator: 0.043364; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:52,237 root         INFO     Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 0.203016\n",
      "Reconstruction: 0.110004, Regularization: 0.028006, Discriminator: 0.043365; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:52,346 root         INFO     Train Epoch: 177 [4608/8000 (58%)]\tTotal Loss: 5.144405\n",
      "Reconstruction: 4.907491, Regularization: 0.171931, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:52,456 root         INFO     Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 0.809792\n",
      "Reconstruction: 0.663841, Regularization: 0.080958, Discriminator: 0.043334; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:52,565 root         INFO     Train Epoch: 177 [5632/8000 (70%)]\tTotal Loss: 0.235841\n",
      "Reconstruction: 0.136726, Regularization: 0.034124, Discriminator: 0.043319; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:52,675 root         INFO     Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 0.338701\n",
      "Reconstruction: 0.223779, Regularization: 0.049927, Discriminator: 0.043331; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:52,784 root         INFO     Train Epoch: 177 [6656/8000 (83%)]\tTotal Loss: 0.313215\n",
      "Reconstruction: 0.186885, Regularization: 0.061357, Discriminator: 0.043321; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:52,891 root         INFO     Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 0.456966\n",
      "Reconstruction: 0.114140, Regularization: 0.277840, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:52,998 root         INFO     Train Epoch: 177 [7680/8000 (96%)]\tTotal Loss: 0.302919\n",
      "Reconstruction: 0.151975, Regularization: 0.085969, Discriminator: 0.043319; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:53,076 root         INFO     ====> Epoch: 177 Average loss: 497.1928\n",
      "2019-04-09 23:36:53,104 root         INFO     Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 0.265672\n",
      "Reconstruction: 0.159629, Regularization: 0.041058, Discriminator: 0.043321; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:53,215 root         INFO     Train Epoch: 178 [512/8000 (6%)]\tTotal Loss: 0.243408\n",
      "Reconstruction: 0.152488, Regularization: 0.025949, Discriminator: 0.043312; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:53,326 root         INFO     Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 1.803546\n",
      "Reconstruction: 1.660094, Regularization: 0.078472, Discriminator: 0.043325; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:53,437 root         INFO     Train Epoch: 178 [1536/8000 (19%)]\tTotal Loss: 1.314034\n",
      "Reconstruction: 1.162988, Regularization: 0.086069, Discriminator: 0.043321; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:53,547 root         INFO     Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 0.394011\n",
      "Reconstruction: 0.246420, Regularization: 0.082623, Discriminator: 0.043303; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:53,658 root         INFO     Train Epoch: 178 [2560/8000 (32%)]\tTotal Loss: 0.211737\n",
      "Reconstruction: 0.112095, Regularization: 0.034684, Discriminator: 0.043295; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:53,768 root         INFO     Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 0.348201\n",
      "Reconstruction: 0.222589, Regularization: 0.060619, Discriminator: 0.043333; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:53,879 root         INFO     Train Epoch: 178 [3584/8000 (45%)]\tTotal Loss: 0.270977\n",
      "Reconstruction: 0.161148, Regularization: 0.044861, Discriminator: 0.043299; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:53,989 root         INFO     Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 0.388846\n",
      "Reconstruction: 0.189885, Regularization: 0.133991, Discriminator: 0.043318; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:54,100 root         INFO     Train Epoch: 178 [4608/8000 (58%)]\tTotal Loss: 0.299100\n",
      "Reconstruction: 0.134824, Regularization: 0.099276, Discriminator: 0.043341; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:54,210 root         INFO     Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 0.379829\n",
      "Reconstruction: 0.233163, Regularization: 0.081695, Discriminator: 0.043309; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:54,321 root         INFO     Train Epoch: 178 [5632/8000 (70%)]\tTotal Loss: 0.289088\n",
      "Reconstruction: 0.160201, Regularization: 0.063926, Discriminator: 0.043303; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:54,432 root         INFO     Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 0.278164\n",
      "Reconstruction: 0.156399, Regularization: 0.056789, Discriminator: 0.043315; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:54,542 root         INFO     Train Epoch: 178 [6656/8000 (83%)]\tTotal Loss: 0.276775\n",
      "Reconstruction: 0.136583, Regularization: 0.075245, Discriminator: 0.043282; Generator: 0.021666,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:36:54,653 root         INFO     Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 0.229979\n",
      "Reconstruction: 0.100834, Regularization: 0.064144, Discriminator: 0.043334; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:54,765 root         INFO     Train Epoch: 178 [7680/8000 (96%)]\tTotal Loss: 0.360238\n",
      "Reconstruction: 0.193693, Regularization: 0.101572, Discriminator: 0.043317; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:54,845 root         INFO     ====> Epoch: 178 Average loss: 41.0453\n",
      "2019-04-09 23:36:54,872 root         INFO     Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 0.311681\n",
      "Reconstruction: 0.103610, Regularization: 0.143075, Discriminator: 0.043350; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:54,982 root         INFO     Train Epoch: 179 [512/8000 (6%)]\tTotal Loss: 0.223446\n",
      "Reconstruction: 0.110001, Regularization: 0.048486, Discriminator: 0.043290; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:55,091 root         INFO     Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 0.253174\n",
      "Reconstruction: 0.142929, Regularization: 0.045234, Discriminator: 0.043352; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:55,200 root         INFO     Train Epoch: 179 [1536/8000 (19%)]\tTotal Loss: 0.235729\n",
      "Reconstruction: 0.126355, Regularization: 0.044396, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:55,309 root         INFO     Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 0.234944\n",
      "Reconstruction: 0.130956, Regularization: 0.039035, Discriminator: 0.043300; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:55,418 root         INFO     Train Epoch: 179 [2560/8000 (32%)]\tTotal Loss: 0.254315\n",
      "Reconstruction: 0.128945, Regularization: 0.060393, Discriminator: 0.043326; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:55,527 root         INFO     Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 0.257604\n",
      "Reconstruction: 0.140041, Regularization: 0.052574, Discriminator: 0.043330; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:55,635 root         INFO     Train Epoch: 179 [3584/8000 (45%)]\tTotal Loss: 0.323251\n",
      "Reconstruction: 0.179625, Regularization: 0.078648, Discriminator: 0.043316; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:55,743 root         INFO     Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 0.410471\n",
      "Reconstruction: 0.264113, Regularization: 0.081390, Discriminator: 0.043309; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:55,852 root         INFO     Train Epoch: 179 [4608/8000 (58%)]\tTotal Loss: 0.249816\n",
      "Reconstruction: 0.134849, Regularization: 0.049974, Discriminator: 0.043317; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:55,962 root         INFO     Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 0.237738\n",
      "Reconstruction: 0.110621, Regularization: 0.062126, Discriminator: 0.043322; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:56,071 root         INFO     Train Epoch: 179 [5632/8000 (70%)]\tTotal Loss: 3.167762\n",
      "Reconstruction: 2.944817, Regularization: 0.157960, Discriminator: 0.043313; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:56,181 root         INFO     Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 0.205981\n",
      "Reconstruction: 0.108298, Regularization: 0.032651, Discriminator: 0.043348; Generator: 0.021685,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:36:56,290 root         INFO     Train Epoch: 179 [6656/8000 (83%)]\tTotal Loss: 0.297781\n",
      "Reconstruction: 0.113660, Regularization: 0.119149, Discriminator: 0.043327; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:56,400 root         INFO     Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 0.272017\n",
      "Reconstruction: 0.164118, Regularization: 0.042925, Discriminator: 0.043294; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:56,510 root         INFO     Train Epoch: 179 [7680/8000 (96%)]\tTotal Loss: 0.239609\n",
      "Reconstruction: 0.108845, Regularization: 0.065770, Discriminator: 0.043317; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:56,589 root         INFO     ====> Epoch: 179 Average loss: 3994.4696\n",
      "2019-04-09 23:36:56,617 root         INFO     Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 0.222442\n",
      "Reconstruction: 0.117232, Regularization: 0.040230, Discriminator: 0.043313; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:56,727 root         INFO     Train Epoch: 180 [512/8000 (6%)]\tTotal Loss: 0.747182\n",
      "Reconstruction: 0.618951, Regularization: 0.063273, Discriminator: 0.043301; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:56,835 root         INFO     Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 0.197614\n",
      "Reconstruction: 0.106804, Regularization: 0.025830, Discriminator: 0.043337; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:56,943 root         INFO     Train Epoch: 180 [1536/8000 (19%)]\tTotal Loss: 0.285082\n",
      "Reconstruction: 0.115731, Regularization: 0.104383, Discriminator: 0.043305; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:57,051 root         INFO     Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 3.354628\n",
      "Reconstruction: 3.220733, Regularization: 0.068898, Discriminator: 0.043330; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:57,160 root         INFO     Train Epoch: 180 [2560/8000 (32%)]\tTotal Loss: 0.255321\n",
      "Reconstruction: 0.121888, Regularization: 0.068447, Discriminator: 0.043328; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:57,267 root         INFO     Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 0.526709\n",
      "Reconstruction: 0.197454, Regularization: 0.264274, Discriminator: 0.043330; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:57,375 root         INFO     Train Epoch: 180 [3584/8000 (45%)]\tTotal Loss: 0.218804\n",
      "Reconstruction: 0.114743, Regularization: 0.039073, Discriminator: 0.043331; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:57,483 root         INFO     Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 0.195192\n",
      "Reconstruction: 0.105477, Regularization: 0.024745, Discriminator: 0.043302; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:57,592 root         INFO     Train Epoch: 180 [4608/8000 (58%)]\tTotal Loss: 0.207712\n",
      "Reconstruction: 0.105159, Regularization: 0.037593, Discriminator: 0.043295; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:57,700 root         INFO     Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 0.246021\n",
      "Reconstruction: 0.122966, Regularization: 0.058057, Discriminator: 0.043315; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:57,808 root         INFO     Train Epoch: 180 [5632/8000 (70%)]\tTotal Loss: 0.265239\n",
      "Reconstruction: 0.170469, Regularization: 0.029820, Discriminator: 0.043324; Generator: 0.021626,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:36:57,916 root         INFO     Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 0.267501\n",
      "Reconstruction: 0.128195, Regularization: 0.074326, Discriminator: 0.043326; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:58,024 root         INFO     Train Epoch: 180 [6656/8000 (83%)]\tTotal Loss: 0.208578\n",
      "Reconstruction: 0.107047, Regularization: 0.036552, Discriminator: 0.043306; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:58,133 root         INFO     Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 2.358628\n",
      "Reconstruction: 2.214783, Regularization: 0.078846, Discriminator: 0.043331; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:58,243 root         INFO     Train Epoch: 180 [7680/8000 (96%)]\tTotal Loss: 0.233399\n",
      "Reconstruction: 0.125085, Regularization: 0.043333, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:58,323 root         INFO     ====> Epoch: 180 Average loss: 7837.4897\n",
      "2019-04-09 23:36:58,350 root         INFO     Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 0.627124\n",
      "Reconstruction: 0.493819, Regularization: 0.068306, Discriminator: 0.043319; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:58,460 root         INFO     Train Epoch: 181 [512/8000 (6%)]\tTotal Loss: 1.027242\n",
      "Reconstruction: 0.887126, Regularization: 0.075105, Discriminator: 0.043346; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:58,570 root         INFO     Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 0.266549\n",
      "Reconstruction: 0.173068, Regularization: 0.028505, Discriminator: 0.043319; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:58,680 root         INFO     Train Epoch: 181 [1536/8000 (19%)]\tTotal Loss: 0.300740\n",
      "Reconstruction: 0.130105, Regularization: 0.105642, Discriminator: 0.043350; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:58,790 root         INFO     Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 3.868056\n",
      "Reconstruction: 3.739137, Regularization: 0.063934, Discriminator: 0.043318; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:58,899 root         INFO     Train Epoch: 181 [2560/8000 (32%)]\tTotal Loss: 0.305373\n",
      "Reconstruction: 0.135790, Regularization: 0.104609, Discriminator: 0.043304; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:59,009 root         INFO     Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 1.212753\n",
      "Reconstruction: 0.990836, Regularization: 0.156938, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:59,119 root         INFO     Train Epoch: 181 [3584/8000 (45%)]\tTotal Loss: 0.260488\n",
      "Reconstruction: 0.105759, Regularization: 0.089743, Discriminator: 0.043321; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:59,228 root         INFO     Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 0.350190\n",
      "Reconstruction: 0.223308, Regularization: 0.061905, Discriminator: 0.043324; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:59,338 root         INFO     Train Epoch: 181 [4608/8000 (58%)]\tTotal Loss: 0.207234\n",
      "Reconstruction: 0.112553, Regularization: 0.029689, Discriminator: 0.043331; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:59,447 root         INFO     Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 1.528156\n",
      "Reconstruction: 1.339725, Regularization: 0.123447, Discriminator: 0.043325; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:59,555 root         INFO     Train Epoch: 181 [5632/8000 (70%)]\tTotal Loss: 0.259634\n",
      "Reconstruction: 0.127395, Regularization: 0.067258, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:59,664 root         INFO     Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 0.411735\n",
      "Reconstruction: 0.243448, Regularization: 0.103306, Discriminator: 0.043311; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:59,773 root         INFO     Train Epoch: 181 [6656/8000 (83%)]\tTotal Loss: 1.055041\n",
      "Reconstruction: 0.920447, Regularization: 0.069613, Discriminator: 0.043313; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:59,881 root         INFO     Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 0.995449\n",
      "Reconstruction: 0.758650, Regularization: 0.171824, Discriminator: 0.043336; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:36:59,988 root         INFO     Train Epoch: 181 [7680/8000 (96%)]\tTotal Loss: 0.237744\n",
      "Reconstruction: 0.118193, Regularization: 0.054565, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:00,067 root         INFO     ====> Epoch: 181 Average loss: 62.3137\n",
      "2019-04-09 23:37:00,094 root         INFO     Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 0.962900\n",
      "Reconstruction: 0.739323, Regularization: 0.158606, Discriminator: 0.043311; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:00,201 root         INFO     Train Epoch: 182 [512/8000 (6%)]\tTotal Loss: 0.222616\n",
      "Reconstruction: 0.123210, Regularization: 0.034410, Discriminator: 0.043327; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:00,308 root         INFO     Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 0.234185\n",
      "Reconstruction: 0.129325, Regularization: 0.039875, Discriminator: 0.043327; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:00,415 root         INFO     Train Epoch: 182 [1536/8000 (19%)]\tTotal Loss: 1.100130\n",
      "Reconstruction: 0.909743, Regularization: 0.125405, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:00,521 root         INFO     Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 0.277798\n",
      "Reconstruction: 0.173256, Regularization: 0.039558, Discriminator: 0.043328; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:00,629 root         INFO     Train Epoch: 182 [2560/8000 (32%)]\tTotal Loss: 0.228433\n",
      "Reconstruction: 0.135760, Regularization: 0.027680, Discriminator: 0.043286; Generator: 0.021708,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:37:00,739 root         INFO     Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 0.229871\n",
      "Reconstruction: 0.105349, Regularization: 0.059529, Discriminator: 0.043315; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:00,846 root         INFO     Train Epoch: 182 [3584/8000 (45%)]\tTotal Loss: 17.133474\n",
      "Reconstruction: 16.891380, Regularization: 0.177112, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:00,955 root         INFO     Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 0.600102\n",
      "Reconstruction: 0.477955, Regularization: 0.057174, Discriminator: 0.043327; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:01,064 root         INFO     Train Epoch: 182 [4608/8000 (58%)]\tTotal Loss: 0.329222\n",
      "Reconstruction: 0.162261, Regularization: 0.101972, Discriminator: 0.043311; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:01,172 root         INFO     Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 0.254140\n",
      "Reconstruction: 0.136098, Regularization: 0.053059, Discriminator: 0.043318; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:01,279 root         INFO     Train Epoch: 182 [5632/8000 (70%)]\tTotal Loss: 0.255346\n",
      "Reconstruction: 0.120116, Regularization: 0.070245, Discriminator: 0.043330; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:01,387 root         INFO     Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 0.220921\n",
      "Reconstruction: 0.129535, Regularization: 0.026398, Discriminator: 0.043323; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:01,496 root         INFO     Train Epoch: 182 [6656/8000 (83%)]\tTotal Loss: 0.226548\n",
      "Reconstruction: 0.118878, Regularization: 0.042676, Discriminator: 0.043338; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:01,604 root         INFO     Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 0.225767\n",
      "Reconstruction: 0.122736, Regularization: 0.038063, Discriminator: 0.043302; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:01,712 root         INFO     Train Epoch: 182 [7680/8000 (96%)]\tTotal Loss: 0.513052\n",
      "Reconstruction: 0.236193, Regularization: 0.211883, Discriminator: 0.043313; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:01,792 root         INFO     ====> Epoch: 182 Average loss: 6.4898\n",
      "2019-04-09 23:37:01,819 root         INFO     Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 0.433876\n",
      "Reconstruction: 0.279316, Regularization: 0.089584, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:01,929 root         INFO     Train Epoch: 183 [512/8000 (6%)]\tTotal Loss: 0.216986\n",
      "Reconstruction: 0.114139, Regularization: 0.037841, Discriminator: 0.043345; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:02,038 root         INFO     Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 0.201180\n",
      "Reconstruction: 0.112754, Regularization: 0.023449, Discriminator: 0.043314; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:02,148 root         INFO     Train Epoch: 183 [1536/8000 (19%)]\tTotal Loss: 0.301462\n",
      "Reconstruction: 0.138076, Regularization: 0.098417, Discriminator: 0.043323; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:02,257 root         INFO     Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 0.343825\n",
      "Reconstruction: 0.218544, Regularization: 0.060319, Discriminator: 0.043309; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:02,367 root         INFO     Train Epoch: 183 [2560/8000 (32%)]\tTotal Loss: 0.236975\n",
      "Reconstruction: 0.145054, Regularization: 0.026975, Discriminator: 0.043294; Generator: 0.021651,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:37:02,474 root         INFO     Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 0.199294\n",
      "Reconstruction: 0.101732, Regularization: 0.032559, Discriminator: 0.043332; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:02,581 root         INFO     Train Epoch: 183 [3584/8000 (45%)]\tTotal Loss: 0.276866\n",
      "Reconstruction: 0.125884, Regularization: 0.085971, Discriminator: 0.043358; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:02,689 root         INFO     Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 0.299736\n",
      "Reconstruction: 0.150585, Regularization: 0.084167, Discriminator: 0.043326; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:02,798 root         INFO     Train Epoch: 183 [4608/8000 (58%)]\tTotal Loss: 0.227646\n",
      "Reconstruction: 0.119490, Regularization: 0.043176, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:02,907 root         INFO     Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 0.231717\n",
      "Reconstruction: 0.139669, Regularization: 0.027067, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:03,016 root         INFO     Train Epoch: 183 [5632/8000 (70%)]\tTotal Loss: 0.385076\n",
      "Reconstruction: 0.272330, Regularization: 0.047752, Discriminator: 0.043332; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:03,124 root         INFO     Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 0.437200\n",
      "Reconstruction: 0.273297, Regularization: 0.098915, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:03,233 root         INFO     Train Epoch: 183 [6656/8000 (83%)]\tTotal Loss: 0.276608\n",
      "Reconstruction: 0.148707, Regularization: 0.062927, Discriminator: 0.043293; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:03,341 root         INFO     Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 0.235862\n",
      "Reconstruction: 0.136941, Regularization: 0.033978, Discriminator: 0.043288; Generator: 0.021656,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:37:03,452 root         INFO     Train Epoch: 183 [7680/8000 (96%)]\tTotal Loss: 0.269528\n",
      "Reconstruction: 0.151993, Regularization: 0.052546, Discriminator: 0.043304; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:03,533 root         INFO     ====> Epoch: 183 Average loss: 867.4108\n",
      "2019-04-09 23:37:03,561 root         INFO     Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 0.264230\n",
      "Reconstruction: 0.154458, Regularization: 0.044802, Discriminator: 0.043297; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:03,674 root         INFO     Train Epoch: 184 [512/8000 (6%)]\tTotal Loss: 0.212673\n",
      "Reconstruction: 0.098637, Regularization: 0.049015, Discriminator: 0.043400; Generator: 0.021621,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:37:03,786 root         INFO     Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 0.467114\n",
      "Reconstruction: 0.350768, Regularization: 0.051382, Discriminator: 0.043286; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:03,898 root         INFO     Train Epoch: 184 [1536/8000 (19%)]\tTotal Loss: 0.297504\n",
      "Reconstruction: 0.134412, Regularization: 0.098131, Discriminator: 0.043316; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:04,009 root         INFO     Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 0.288091\n",
      "Reconstruction: 0.137728, Regularization: 0.085382, Discriminator: 0.043348; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:04,120 root         INFO     Train Epoch: 184 [2560/8000 (32%)]\tTotal Loss: 0.861572\n",
      "Reconstruction: 0.733658, Regularization: 0.062963, Discriminator: 0.043251; Generator: 0.021700,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:37:04,232 root         INFO     Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 0.249792\n",
      "Reconstruction: 0.119863, Regularization: 0.064956, Discriminator: 0.043321; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:04,344 root         INFO     Train Epoch: 184 [3584/8000 (45%)]\tTotal Loss: 0.851388\n",
      "Reconstruction: 0.547728, Regularization: 0.238726, Discriminator: 0.043287; Generator: 0.021648,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:37:04,456 root         INFO     Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 0.489825\n",
      "Reconstruction: 0.351318, Regularization: 0.073532, Discriminator: 0.043305; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:04,568 root         INFO     Train Epoch: 184 [4608/8000 (58%)]\tTotal Loss: 0.210988\n",
      "Reconstruction: 0.101355, Regularization: 0.044644, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:04,679 root         INFO     Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 0.348941\n",
      "Reconstruction: 0.235905, Regularization: 0.048051, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:04,791 root         INFO     Train Epoch: 184 [5632/8000 (70%)]\tTotal Loss: 0.274805\n",
      "Reconstruction: 0.131977, Regularization: 0.077862, Discriminator: 0.043308; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:04,902 root         INFO     Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 1.966275\n",
      "Reconstruction: 1.818517, Regularization: 0.082778, Discriminator: 0.043308; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:05,014 root         INFO     Train Epoch: 184 [6656/8000 (83%)]\tTotal Loss: 0.222468\n",
      "Reconstruction: 0.101659, Regularization: 0.055840, Discriminator: 0.043298; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:05,126 root         INFO     Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 0.208785\n",
      "Reconstruction: 0.112644, Regularization: 0.031170, Discriminator: 0.043276; Generator: 0.021695,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:37:05,238 root         INFO     Train Epoch: 184 [7680/8000 (96%)]\tTotal Loss: 0.282117\n",
      "Reconstruction: 0.146618, Regularization: 0.070515, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:05,319 root         INFO     ====> Epoch: 184 Average loss: 3.7160\n",
      "2019-04-09 23:37:05,346 root         INFO     Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 0.419484\n",
      "Reconstruction: 0.260304, Regularization: 0.094214, Discriminator: 0.043333; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:05,458 root         INFO     Train Epoch: 185 [512/8000 (6%)]\tTotal Loss: 0.286012\n",
      "Reconstruction: 0.167181, Regularization: 0.053937, Discriminator: 0.043205; Generator: 0.021688,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:37:05,568 root         INFO     Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 0.241689\n",
      "Reconstruction: 0.118033, Regularization: 0.058656, Discriminator: 0.043346; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:05,678 root         INFO     Train Epoch: 185 [1536/8000 (19%)]\tTotal Loss: 17.602390\n",
      "Reconstruction: 17.469156, Regularization: 0.068221, Discriminator: 0.043420; Generator: 0.021595,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:37:05,788 root         INFO     Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 0.339105\n",
      "Reconstruction: 0.207440, Regularization: 0.066728, Discriminator: 0.043316; Generator: 0.021621,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:37:05,898 root         INFO     Train Epoch: 185 [2560/8000 (32%)]\tTotal Loss: 0.452900\n",
      "Reconstruction: 0.294470, Regularization: 0.093483, Discriminator: 0.043332; Generator: 0.021615,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:37:06,008 root         INFO     Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 0.243534\n",
      "Reconstruction: 0.124617, Regularization: 0.053957, Discriminator: 0.043306; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:06,119 root         INFO     Train Epoch: 185 [3584/8000 (45%)]\tTotal Loss: 0.301248\n",
      "Reconstruction: 0.142242, Regularization: 0.094015, Discriminator: 0.043384; Generator: 0.021607,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:37:06,229 root         INFO     Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 12.040757\n",
      "Reconstruction: 11.877212, Regularization: 0.098509, Discriminator: 0.043399; Generator: 0.021638,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:37:06,339 root         INFO     Train Epoch: 185 [4608/8000 (58%)]\tTotal Loss: 0.272263\n",
      "Reconstruction: 0.129064, Regularization: 0.078208, Discriminator: 0.043331; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:06,450 root         INFO     Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 0.268347\n",
      "Reconstruction: 0.160055, Regularization: 0.043313, Discriminator: 0.043313; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:06,561 root         INFO     Train Epoch: 185 [5632/8000 (70%)]\tTotal Loss: 0.255938\n",
      "Reconstruction: 0.126332, Regularization: 0.064619, Discriminator: 0.043322; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:06,671 root         INFO     Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 0.249777\n",
      "Reconstruction: 0.125250, Regularization: 0.059557, Discriminator: 0.043281; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:06,782 root         INFO     Train Epoch: 185 [6656/8000 (83%)]\tTotal Loss: 114.754761\n",
      "Reconstruction: 114.612663, Regularization: 0.077151, Discriminator: 0.043266; Generator: 0.021685,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:37:06,892 root         INFO     Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 0.268869\n",
      "Reconstruction: 0.120679, Regularization: 0.083263, Discriminator: 0.043238; Generator: 0.021689,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:37:07,003 root         INFO     Train Epoch: 185 [7680/8000 (96%)]\tTotal Loss: 0.233990\n",
      "Reconstruction: 0.118847, Regularization: 0.050252, Discriminator: 0.043225; Generator: 0.021666,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:37:07,083 root         INFO     ====> Epoch: 185 Average loss: 8.1484\n",
      "2019-04-09 23:37:07,110 root         INFO     Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 0.221153\n",
      "Reconstruction: 0.120712, Regularization: 0.035437, Discriminator: 0.043329; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:07,221 root         INFO     Train Epoch: 186 [512/8000 (6%)]\tTotal Loss: 0.283297\n",
      "Reconstruction: 0.127391, Regularization: 0.090883, Discriminator: 0.043388; Generator: 0.021635,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:37:07,330 root         INFO     Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 0.234257\n",
      "Reconstruction: 0.136329, Regularization: 0.032899, Discriminator: 0.043350; Generator: 0.021680,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:37:07,440 root         INFO     Train Epoch: 186 [1536/8000 (19%)]\tTotal Loss: 0.228569\n",
      "Reconstruction: 0.126466, Regularization: 0.037080, Discriminator: 0.043350; Generator: 0.021673,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:37:07,551 root         INFO     Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 0.260573\n",
      "Reconstruction: 0.110353, Regularization: 0.085166, Discriminator: 0.043469; Generator: 0.021585,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:37:07,662 root         INFO     Train Epoch: 186 [2560/8000 (32%)]\tTotal Loss: 0.212141\n",
      "Reconstruction: 0.109151, Regularization: 0.037981, Discriminator: 0.043348; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:07,773 root         INFO     Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 0.204749\n",
      "Reconstruction: 0.112727, Regularization: 0.027020, Discriminator: 0.043332; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:07,884 root         INFO     Train Epoch: 186 [3584/8000 (45%)]\tTotal Loss: 10.579228\n",
      "Reconstruction: 10.468786, Regularization: 0.045448, Discriminator: 0.043356; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:07,996 root         INFO     Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 0.308073\n",
      "Reconstruction: 0.180495, Regularization: 0.062578, Discriminator: 0.043313; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:08,107 root         INFO     Train Epoch: 186 [4608/8000 (58%)]\tTotal Loss: 0.315203\n",
      "Reconstruction: 0.182257, Regularization: 0.067967, Discriminator: 0.043283; Generator: 0.021696,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:37:08,218 root         INFO     Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 1.135981\n",
      "Reconstruction: 0.894507, Regularization: 0.176504, Discriminator: 0.043312; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:08,330 root         INFO     Train Epoch: 186 [5632/8000 (70%)]\tTotal Loss: 0.209067\n",
      "Reconstruction: 0.109059, Regularization: 0.035023, Discriminator: 0.043321; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:08,443 root         INFO     Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 0.482064\n",
      "Reconstruction: 0.389424, Regularization: 0.027662, Discriminator: 0.043326; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:08,552 root         INFO     Train Epoch: 186 [6656/8000 (83%)]\tTotal Loss: 0.645140\n",
      "Reconstruction: 0.502814, Regularization: 0.077335, Discriminator: 0.043329; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:08,662 root         INFO     Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 1.702257\n",
      "Reconstruction: 1.571394, Regularization: 0.065894, Discriminator: 0.043302; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:08,770 root         INFO     Train Epoch: 186 [7680/8000 (96%)]\tTotal Loss: 0.272355\n",
      "Reconstruction: 0.122237, Regularization: 0.085117, Discriminator: 0.043369; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:08,850 root         INFO     ====> Epoch: 186 Average loss: 2395.5059\n",
      "2019-04-09 23:37:08,878 root         INFO     Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 0.594801\n",
      "Reconstruction: 0.488355, Regularization: 0.041470, Discriminator: 0.043325; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:08,991 root         INFO     Train Epoch: 187 [512/8000 (6%)]\tTotal Loss: 1.747373\n",
      "Reconstruction: 1.614497, Regularization: 0.067869, Discriminator: 0.043332; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:09,102 root         INFO     Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 0.387550\n",
      "Reconstruction: 0.263833, Regularization: 0.058730, Discriminator: 0.043330; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:09,213 root         INFO     Train Epoch: 187 [1536/8000 (19%)]\tTotal Loss: 15.373734\n",
      "Reconstruction: 15.134419, Regularization: 0.174304, Discriminator: 0.043327; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:09,326 root         INFO     Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 0.217994\n",
      "Reconstruction: 0.122845, Regularization: 0.030156, Discriminator: 0.043324; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:09,438 root         INFO     Train Epoch: 187 [2560/8000 (32%)]\tTotal Loss: 1.120726\n",
      "Reconstruction: 0.960089, Regularization: 0.095659, Discriminator: 0.043315; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:09,549 root         INFO     Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 0.274385\n",
      "Reconstruction: 0.132765, Regularization: 0.076663, Discriminator: 0.043323; Generator: 0.021635,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:09,660 root         INFO     Train Epoch: 187 [3584/8000 (45%)]\tTotal Loss: 0.317643\n",
      "Reconstruction: 0.210752, Regularization: 0.041894, Discriminator: 0.043307; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:09,771 root         INFO     Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 0.352697\n",
      "Reconstruction: 0.197678, Regularization: 0.089953, Discriminator: 0.043427; Generator: 0.021639,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:37:09,882 root         INFO     Train Epoch: 187 [4608/8000 (58%)]\tTotal Loss: 0.224395\n",
      "Reconstruction: 0.114630, Regularization: 0.044769, Discriminator: 0.043387; Generator: 0.021608,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:37:09,993 root         INFO     Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 0.232246\n",
      "Reconstruction: 0.125437, Regularization: 0.041847, Discriminator: 0.043296; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:10,103 root         INFO     Train Epoch: 187 [5632/8000 (70%)]\tTotal Loss: 0.458363\n",
      "Reconstruction: 0.254841, Regularization: 0.138512, Discriminator: 0.043377; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:10,211 root         INFO     Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 0.211869\n",
      "Reconstruction: 0.118963, Regularization: 0.027923, Discriminator: 0.043343; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:10,319 root         INFO     Train Epoch: 187 [6656/8000 (83%)]\tTotal Loss: 0.203809\n",
      "Reconstruction: 0.111621, Regularization: 0.027211, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:10,426 root         INFO     Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 2.079215\n",
      "Reconstruction: 1.921796, Regularization: 0.092441, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:10,534 root         INFO     Train Epoch: 187 [7680/8000 (96%)]\tTotal Loss: 0.224529\n",
      "Reconstruction: 0.125901, Regularization: 0.033637, Discriminator: 0.043332; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:10,613 root         INFO     ====> Epoch: 187 Average loss: 55.1821\n",
      "2019-04-09 23:37:10,640 root         INFO     Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 0.184463\n",
      "Reconstruction: 0.096101, Regularization: 0.023380, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:10,752 root         INFO     Train Epoch: 188 [512/8000 (6%)]\tTotal Loss: 0.260060\n",
      "Reconstruction: 0.148862, Regularization: 0.046206, Discriminator: 0.043326; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:10,864 root         INFO     Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 0.289523\n",
      "Reconstruction: 0.143654, Regularization: 0.080890, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:10,975 root         INFO     Train Epoch: 188 [1536/8000 (19%)]\tTotal Loss: 0.299381\n",
      "Reconstruction: 0.156752, Regularization: 0.077643, Discriminator: 0.043301; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:11,086 root         INFO     Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 0.287770\n",
      "Reconstruction: 0.130630, Regularization: 0.092152, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:11,197 root         INFO     Train Epoch: 188 [2560/8000 (32%)]\tTotal Loss: 0.307280\n",
      "Reconstruction: 0.183981, Regularization: 0.058332, Discriminator: 0.043330; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:11,308 root         INFO     Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 0.259865\n",
      "Reconstruction: 0.145552, Regularization: 0.049335, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:11,420 root         INFO     Train Epoch: 188 [3584/8000 (45%)]\tTotal Loss: 0.193964\n",
      "Reconstruction: 0.101107, Regularization: 0.027859, Discriminator: 0.043339; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:11,531 root         INFO     Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 0.230061\n",
      "Reconstruction: 0.120630, Regularization: 0.044449, Discriminator: 0.043334; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:11,643 root         INFO     Train Epoch: 188 [4608/8000 (58%)]\tTotal Loss: 2.004566\n",
      "Reconstruction: 1.836401, Regularization: 0.103202, Discriminator: 0.043292; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:11,754 root         INFO     Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 0.212526\n",
      "Reconstruction: 0.112626, Regularization: 0.034902, Discriminator: 0.043339; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:11,864 root         INFO     Train Epoch: 188 [5632/8000 (70%)]\tTotal Loss: 0.393288\n",
      "Reconstruction: 0.213076, Regularization: 0.115220, Discriminator: 0.043325; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:11,975 root         INFO     Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 0.341138\n",
      "Reconstruction: 0.216630, Regularization: 0.059526, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:12,085 root         INFO     Train Epoch: 188 [6656/8000 (83%)]\tTotal Loss: 0.376015\n",
      "Reconstruction: 0.229427, Regularization: 0.081631, Discriminator: 0.043294; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:12,195 root         INFO     Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 0.255095\n",
      "Reconstruction: 0.128431, Regularization: 0.061683, Discriminator: 0.043315; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:12,306 root         INFO     Train Epoch: 188 [7680/8000 (96%)]\tTotal Loss: 0.395989\n",
      "Reconstruction: 0.281451, Regularization: 0.049543, Discriminator: 0.043335; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:12,387 root         INFO     ====> Epoch: 188 Average loss: 20.1420\n",
      "2019-04-09 23:37:12,414 root         INFO     Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 0.247613\n",
      "Reconstruction: 0.120715, Regularization: 0.061923, Discriminator: 0.043314; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:12,526 root         INFO     Train Epoch: 189 [512/8000 (6%)]\tTotal Loss: 0.186640\n",
      "Reconstruction: 0.099478, Regularization: 0.022182, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:12,637 root         INFO     Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 1.868543\n",
      "Reconstruction: 1.728418, Regularization: 0.075143, Discriminator: 0.043325; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:12,749 root         INFO     Train Epoch: 189 [1536/8000 (19%)]\tTotal Loss: 0.216410\n",
      "Reconstruction: 0.109863, Regularization: 0.041565, Discriminator: 0.043309; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:12,860 root         INFO     Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 0.331559\n",
      "Reconstruction: 0.230323, Regularization: 0.036251, Discriminator: 0.043329; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:12,971 root         INFO     Train Epoch: 189 [2560/8000 (32%)]\tTotal Loss: 0.246524\n",
      "Reconstruction: 0.121826, Regularization: 0.059710, Discriminator: 0.043332; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:13,083 root         INFO     Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 0.238088\n",
      "Reconstruction: 0.113062, Regularization: 0.060054, Discriminator: 0.043312; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:13,193 root         INFO     Train Epoch: 189 [3584/8000 (45%)]\tTotal Loss: 0.694032\n",
      "Reconstruction: 0.555353, Regularization: 0.073707, Discriminator: 0.043315; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:13,303 root         INFO     Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 0.205632\n",
      "Reconstruction: 0.110898, Regularization: 0.029739, Discriminator: 0.043336; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:13,413 root         INFO     Train Epoch: 189 [4608/8000 (58%)]\tTotal Loss: 0.430978\n",
      "Reconstruction: 0.119332, Regularization: 0.246683, Discriminator: 0.043299; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:13,524 root         INFO     Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 0.306532\n",
      "Reconstruction: 0.180967, Regularization: 0.060562, Discriminator: 0.043350; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:13,634 root         INFO     Train Epoch: 189 [5632/8000 (70%)]\tTotal Loss: 0.227703\n",
      "Reconstruction: 0.110107, Regularization: 0.052637, Discriminator: 0.043302; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:13,744 root         INFO     Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 0.200853\n",
      "Reconstruction: 0.098245, Regularization: 0.037650, Discriminator: 0.043305; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:13,854 root         INFO     Train Epoch: 189 [6656/8000 (83%)]\tTotal Loss: 0.236431\n",
      "Reconstruction: 0.142863, Regularization: 0.028594, Discriminator: 0.043311; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:13,965 root         INFO     Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 0.614600\n",
      "Reconstruction: 0.471050, Regularization: 0.078592, Discriminator: 0.043298; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:14,074 root         INFO     Train Epoch: 189 [7680/8000 (96%)]\tTotal Loss: 0.258039\n",
      "Reconstruction: 0.140758, Regularization: 0.052292, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:14,154 root         INFO     ====> Epoch: 189 Average loss: 10.6869\n",
      "2019-04-09 23:37:14,181 root         INFO     Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 6.657422\n",
      "Reconstruction: 6.484117, Regularization: 0.108297, Discriminator: 0.043344; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:14,294 root         INFO     Train Epoch: 190 [512/8000 (6%)]\tTotal Loss: 0.552589\n",
      "Reconstruction: 0.433781, Regularization: 0.053821, Discriminator: 0.043331; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:14,406 root         INFO     Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 0.307094\n",
      "Reconstruction: 0.161842, Regularization: 0.080263, Discriminator: 0.043327; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:14,519 root         INFO     Train Epoch: 190 [1536/8000 (19%)]\tTotal Loss: 22.293388\n",
      "Reconstruction: 21.922041, Regularization: 0.306360, Discriminator: 0.043322; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:14,631 root         INFO     Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 0.328085\n",
      "Reconstruction: 0.193318, Regularization: 0.069788, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:14,744 root         INFO     Train Epoch: 190 [2560/8000 (32%)]\tTotal Loss: 0.240885\n",
      "Reconstruction: 0.123935, Regularization: 0.051967, Discriminator: 0.043319; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:14,856 root         INFO     Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 0.322872\n",
      "Reconstruction: 0.221705, Regularization: 0.036176, Discriminator: 0.043323; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:14,968 root         INFO     Train Epoch: 190 [3584/8000 (45%)]\tTotal Loss: 0.243330\n",
      "Reconstruction: 0.131359, Regularization: 0.046978, Discriminator: 0.043323; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:15,079 root         INFO     Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 0.215744\n",
      "Reconstruction: 0.122065, Regularization: 0.028692, Discriminator: 0.043333; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:15,191 root         INFO     Train Epoch: 190 [4608/8000 (58%)]\tTotal Loss: 0.243253\n",
      "Reconstruction: 0.131708, Regularization: 0.046565, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:15,304 root         INFO     Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 0.256523\n",
      "Reconstruction: 0.138704, Regularization: 0.052838, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:15,415 root         INFO     Train Epoch: 190 [5632/8000 (70%)]\tTotal Loss: 0.367851\n",
      "Reconstruction: 0.239284, Regularization: 0.063595, Discriminator: 0.043302; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:15,528 root         INFO     Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 0.276291\n",
      "Reconstruction: 0.152771, Regularization: 0.058537, Discriminator: 0.043332; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:15,639 root         INFO     Train Epoch: 190 [6656/8000 (83%)]\tTotal Loss: 0.234221\n",
      "Reconstruction: 0.139991, Regularization: 0.029249, Discriminator: 0.043325; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:15,752 root         INFO     Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 0.384188\n",
      "Reconstruction: 0.267702, Regularization: 0.051498, Discriminator: 0.043324; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:15,864 root         INFO     Train Epoch: 190 [7680/8000 (96%)]\tTotal Loss: 0.240338\n",
      "Reconstruction: 0.118860, Regularization: 0.056493, Discriminator: 0.043317; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:15,945 root         INFO     ====> Epoch: 190 Average loss: 10217.9892\n",
      "2019-04-09 23:37:15,972 root         INFO     Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 1.589430\n",
      "Reconstruction: 1.430658, Regularization: 0.093793, Discriminator: 0.043323; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:16,085 root         INFO     Train Epoch: 191 [512/8000 (6%)]\tTotal Loss: 0.457438\n",
      "Reconstruction: 0.312962, Regularization: 0.079501, Discriminator: 0.043314; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:16,196 root         INFO     Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 0.201307\n",
      "Reconstruction: 0.110517, Regularization: 0.025795, Discriminator: 0.043333; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:16,307 root         INFO     Train Epoch: 191 [1536/8000 (19%)]\tTotal Loss: 0.244504\n",
      "Reconstruction: 0.114819, Regularization: 0.064700, Discriminator: 0.043321; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:16,418 root         INFO     Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 0.232130\n",
      "Reconstruction: 0.122870, Regularization: 0.044272, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:16,530 root         INFO     Train Epoch: 191 [2560/8000 (32%)]\tTotal Loss: 0.247798\n",
      "Reconstruction: 0.135911, Regularization: 0.046920, Discriminator: 0.043311; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:16,642 root         INFO     Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 0.339603\n",
      "Reconstruction: 0.201191, Regularization: 0.073410, Discriminator: 0.043332; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:16,755 root         INFO     Train Epoch: 191 [3584/8000 (45%)]\tTotal Loss: 0.257342\n",
      "Reconstruction: 0.145537, Regularization: 0.046825, Discriminator: 0.043312; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:16,868 root         INFO     Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 0.281341\n",
      "Reconstruction: 0.142709, Regularization: 0.073655, Discriminator: 0.043336; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:16,981 root         INFO     Train Epoch: 191 [4608/8000 (58%)]\tTotal Loss: 0.273340\n",
      "Reconstruction: 0.134431, Regularization: 0.073921, Discriminator: 0.043323; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:17,093 root         INFO     Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 0.249336\n",
      "Reconstruction: 0.109731, Regularization: 0.074623, Discriminator: 0.043328; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:17,206 root         INFO     Train Epoch: 191 [5632/8000 (70%)]\tTotal Loss: 0.401981\n",
      "Reconstruction: 0.291087, Regularization: 0.045909, Discriminator: 0.043314; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:17,316 root         INFO     Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 0.291908\n",
      "Reconstruction: 0.123541, Regularization: 0.103388, Discriminator: 0.043310; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:17,427 root         INFO     Train Epoch: 191 [6656/8000 (83%)]\tTotal Loss: 0.627697\n",
      "Reconstruction: 0.499927, Regularization: 0.062776, Discriminator: 0.043328; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:17,538 root         INFO     Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 0.253776\n",
      "Reconstruction: 0.130026, Regularization: 0.058770, Discriminator: 0.043308; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:17,649 root         INFO     Train Epoch: 191 [7680/8000 (96%)]\tTotal Loss: 0.207096\n",
      "Reconstruction: 0.108332, Regularization: 0.033780, Discriminator: 0.043342; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:17,730 root         INFO     ====> Epoch: 191 Average loss: 22.2750\n",
      "2019-04-09 23:37:17,757 root         INFO     Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 0.429572\n",
      "Reconstruction: 0.222581, Regularization: 0.142030, Discriminator: 0.043284; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:17,868 root         INFO     Train Epoch: 192 [512/8000 (6%)]\tTotal Loss: 0.629570\n",
      "Reconstruction: 0.499890, Regularization: 0.064720, Discriminator: 0.043278; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:17,979 root         INFO     Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 0.250327\n",
      "Reconstruction: 0.129967, Regularization: 0.055373, Discriminator: 0.043317; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:18,090 root         INFO     Train Epoch: 192 [1536/8000 (19%)]\tTotal Loss: 0.225247\n",
      "Reconstruction: 0.105741, Regularization: 0.054522, Discriminator: 0.043310; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:18,200 root         INFO     Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.268336\n",
      "Reconstruction: 0.171335, Regularization: 0.032007, Discriminator: 0.043333; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:18,311 root         INFO     Train Epoch: 192 [2560/8000 (32%)]\tTotal Loss: 0.284895\n",
      "Reconstruction: 0.158920, Regularization: 0.060988, Discriminator: 0.043319; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:18,422 root         INFO     Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 0.255866\n",
      "Reconstruction: 0.155303, Regularization: 0.035571, Discriminator: 0.043337; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:18,534 root         INFO     Train Epoch: 192 [3584/8000 (45%)]\tTotal Loss: 0.231909\n",
      "Reconstruction: 0.110712, Regularization: 0.056221, Discriminator: 0.043321; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:18,644 root         INFO     Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 0.250096\n",
      "Reconstruction: 0.114049, Regularization: 0.071065, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:18,754 root         INFO     Train Epoch: 192 [4608/8000 (58%)]\tTotal Loss: 0.549277\n",
      "Reconstruction: 0.368537, Regularization: 0.115756, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:18,863 root         INFO     Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 0.226130\n",
      "Reconstruction: 0.124601, Regularization: 0.036553, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:18,972 root         INFO     Train Epoch: 192 [5632/8000 (70%)]\tTotal Loss: 0.557259\n",
      "Reconstruction: 0.445442, Regularization: 0.046834, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:19,081 root         INFO     Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 0.462761\n",
      "Reconstruction: 0.362359, Regularization: 0.035429, Discriminator: 0.043317; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:19,191 root         INFO     Train Epoch: 192 [6656/8000 (83%)]\tTotal Loss: 0.242361\n",
      "Reconstruction: 0.108376, Regularization: 0.069020, Discriminator: 0.043296; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:19,300 root         INFO     Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 0.251886\n",
      "Reconstruction: 0.141677, Regularization: 0.045231, Discriminator: 0.043328; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:19,410 root         INFO     Train Epoch: 192 [7680/8000 (96%)]\tTotal Loss: 1.121931\n",
      "Reconstruction: 0.975940, Regularization: 0.081007, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:19,490 root         INFO     ====> Epoch: 192 Average loss: 91.2321\n",
      "2019-04-09 23:37:19,517 root         INFO     Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 0.202564\n",
      "Reconstruction: 0.105609, Regularization: 0.031992, Discriminator: 0.043308; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:19,628 root         INFO     Train Epoch: 193 [512/8000 (6%)]\tTotal Loss: 0.240200\n",
      "Reconstruction: 0.132092, Regularization: 0.043151, Discriminator: 0.043298; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:19,740 root         INFO     Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 0.296222\n",
      "Reconstruction: 0.178196, Regularization: 0.053042, Discriminator: 0.043308; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:19,853 root         INFO     Train Epoch: 193 [1536/8000 (19%)]\tTotal Loss: 0.271432\n",
      "Reconstruction: 0.130364, Regularization: 0.076084, Discriminator: 0.043314; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:19,966 root         INFO     Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 0.281781\n",
      "Reconstruction: 0.129422, Regularization: 0.087352, Discriminator: 0.043354; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:20,078 root         INFO     Train Epoch: 193 [2560/8000 (32%)]\tTotal Loss: 0.205887\n",
      "Reconstruction: 0.109324, Regularization: 0.031582, Discriminator: 0.043309; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:20,191 root         INFO     Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 0.258914\n",
      "Reconstruction: 0.150885, Regularization: 0.043023, Discriminator: 0.043333; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:20,304 root         INFO     Train Epoch: 193 [3584/8000 (45%)]\tTotal Loss: 0.217739\n",
      "Reconstruction: 0.104058, Regularization: 0.048692, Discriminator: 0.043324; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:20,417 root         INFO     Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 0.405772\n",
      "Reconstruction: 0.306993, Regularization: 0.033790, Discriminator: 0.043320; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:20,530 root         INFO     Train Epoch: 193 [4608/8000 (58%)]\tTotal Loss: 3.694724\n",
      "Reconstruction: 3.565605, Regularization: 0.064136, Discriminator: 0.043312; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:20,643 root         INFO     Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 0.253567\n",
      "Reconstruction: 0.126419, Regularization: 0.062155, Discriminator: 0.043326; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:20,756 root         INFO     Train Epoch: 193 [5632/8000 (70%)]\tTotal Loss: 0.238969\n",
      "Reconstruction: 0.118464, Regularization: 0.055499, Discriminator: 0.043330; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:20,869 root         INFO     Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 0.268115\n",
      "Reconstruction: 0.110009, Regularization: 0.093129, Discriminator: 0.043329; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:20,982 root         INFO     Train Epoch: 193 [6656/8000 (83%)]\tTotal Loss: 0.270153\n",
      "Reconstruction: 0.143845, Regularization: 0.061321, Discriminator: 0.043331; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:21,094 root         INFO     Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 0.328036\n",
      "Reconstruction: 0.114485, Regularization: 0.148547, Discriminator: 0.043358; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:21,205 root         INFO     Train Epoch: 193 [7680/8000 (96%)]\tTotal Loss: 0.717728\n",
      "Reconstruction: 0.555793, Regularization: 0.096967, Discriminator: 0.043329; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:21,286 root         INFO     ====> Epoch: 193 Average loss: 14.3471\n",
      "2019-04-09 23:37:21,313 root         INFO     Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 0.246453\n",
      "Reconstruction: 0.144460, Regularization: 0.036987, Discriminator: 0.043359; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:21,426 root         INFO     Train Epoch: 194 [512/8000 (6%)]\tTotal Loss: 0.471948\n",
      "Reconstruction: 0.326842, Regularization: 0.080124, Discriminator: 0.043313; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:21,539 root         INFO     Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 0.435701\n",
      "Reconstruction: 0.306802, Regularization: 0.063922, Discriminator: 0.043338; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:21,651 root         INFO     Train Epoch: 194 [1536/8000 (19%)]\tTotal Loss: 0.339392\n",
      "Reconstruction: 0.122001, Regularization: 0.152425, Discriminator: 0.043318; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:21,764 root         INFO     Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 0.235679\n",
      "Reconstruction: 0.112940, Regularization: 0.057755, Discriminator: 0.043330; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:21,876 root         INFO     Train Epoch: 194 [2560/8000 (32%)]\tTotal Loss: 0.275814\n",
      "Reconstruction: 0.149380, Regularization: 0.061452, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:21,988 root         INFO     Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 0.229476\n",
      "Reconstruction: 0.099274, Regularization: 0.065219, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:22,101 root         INFO     Train Epoch: 194 [3584/8000 (45%)]\tTotal Loss: 0.253350\n",
      "Reconstruction: 0.146764, Regularization: 0.041596, Discriminator: 0.043334; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:22,213 root         INFO     Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 0.256283\n",
      "Reconstruction: 0.112392, Regularization: 0.078898, Discriminator: 0.043330; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:22,325 root         INFO     Train Epoch: 194 [4608/8000 (58%)]\tTotal Loss: 0.227015\n",
      "Reconstruction: 0.108925, Regularization: 0.053109, Discriminator: 0.043317; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:22,438 root         INFO     Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 0.222433\n",
      "Reconstruction: 0.114195, Regularization: 0.043273, Discriminator: 0.043305; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:22,550 root         INFO     Train Epoch: 194 [5632/8000 (70%)]\tTotal Loss: 0.241055\n",
      "Reconstruction: 0.127072, Regularization: 0.048993, Discriminator: 0.043298; Generator: 0.021692,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:37:22,663 root         INFO     Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 0.263046\n",
      "Reconstruction: 0.124502, Regularization: 0.073591, Discriminator: 0.043299; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:22,776 root         INFO     Train Epoch: 194 [6656/8000 (83%)]\tTotal Loss: 0.378162\n",
      "Reconstruction: 0.192919, Regularization: 0.120211, Discriminator: 0.043367; Generator: 0.021664,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:37:22,888 root         INFO     Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 0.260776\n",
      "Reconstruction: 0.145718, Regularization: 0.050041, Discriminator: 0.043368; Generator: 0.021649,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:37:23,000 root         INFO     Train Epoch: 194 [7680/8000 (96%)]\tTotal Loss: 0.555670\n",
      "Reconstruction: 0.433783, Regularization: 0.056908, Discriminator: 0.043338; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:23,082 root         INFO     ====> Epoch: 194 Average loss: 74.3551\n",
      "2019-04-09 23:37:23,108 root         INFO     Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 0.384709\n",
      "Reconstruction: 0.132700, Regularization: 0.187020, Discriminator: 0.043318; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:23,220 root         INFO     Train Epoch: 195 [512/8000 (6%)]\tTotal Loss: 0.209714\n",
      "Reconstruction: 0.102827, Regularization: 0.041911, Discriminator: 0.043308; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:23,333 root         INFO     Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 15.687531\n",
      "Reconstruction: 15.475305, Regularization: 0.147222, Discriminator: 0.043371; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:23,445 root         INFO     Train Epoch: 195 [1536/8000 (19%)]\tTotal Loss: 1.722891\n",
      "Reconstruction: 1.607129, Regularization: 0.050790, Discriminator: 0.043309; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:23,558 root         INFO     Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 0.198138\n",
      "Reconstruction: 0.107200, Regularization: 0.025969, Discriminator: 0.043307; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:23,670 root         INFO     Train Epoch: 195 [2560/8000 (32%)]\tTotal Loss: 2.649133\n",
      "Reconstruction: 2.511779, Regularization: 0.072374, Discriminator: 0.043329; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:23,782 root         INFO     Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 0.215057\n",
      "Reconstruction: 0.112313, Regularization: 0.037774, Discriminator: 0.043325; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:23,894 root         INFO     Train Epoch: 195 [3584/8000 (45%)]\tTotal Loss: 0.812329\n",
      "Reconstruction: 0.636275, Regularization: 0.111092, Discriminator: 0.043303; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:24,005 root         INFO     Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 0.244768\n",
      "Reconstruction: 0.110864, Regularization: 0.068878, Discriminator: 0.043361; Generator: 0.021666,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:37:24,118 root         INFO     Train Epoch: 195 [4608/8000 (58%)]\tTotal Loss: 0.226503\n",
      "Reconstruction: 0.128538, Regularization: 0.032965, Discriminator: 0.043313; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:24,229 root         INFO     Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 0.217893\n",
      "Reconstruction: 0.110395, Regularization: 0.042522, Discriminator: 0.043322; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:24,341 root         INFO     Train Epoch: 195 [5632/8000 (70%)]\tTotal Loss: 0.338629\n",
      "Reconstruction: 0.130966, Regularization: 0.142707, Discriminator: 0.043320; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:24,453 root         INFO     Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 19.383827\n",
      "Reconstruction: 19.211794, Regularization: 0.107084, Discriminator: 0.043317; Generator: 0.021632,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:37:24,564 root         INFO     Train Epoch: 195 [6656/8000 (83%)]\tTotal Loss: 0.358538\n",
      "Reconstruction: 0.227715, Regularization: 0.065821, Discriminator: 0.043346; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:24,675 root         INFO     Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 0.284840\n",
      "Reconstruction: 0.113730, Regularization: 0.106127, Discriminator: 0.043357; Generator: 0.021625,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:37:24,787 root         INFO     Train Epoch: 195 [7680/8000 (96%)]\tTotal Loss: 0.253948\n",
      "Reconstruction: 0.121985, Regularization: 0.066984, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:24,868 root         INFO     ====> Epoch: 195 Average loss: 230.7066\n",
      "2019-04-09 23:37:24,895 root         INFO     Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 0.215984\n",
      "Reconstruction: 0.102537, Regularization: 0.048463, Discriminator: 0.043324; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:25,007 root         INFO     Train Epoch: 196 [512/8000 (6%)]\tTotal Loss: 0.241170\n",
      "Reconstruction: 0.124040, Regularization: 0.052147, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:25,119 root         INFO     Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 0.522538\n",
      "Reconstruction: 0.378211, Regularization: 0.079353, Discriminator: 0.043315; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:25,230 root         INFO     Train Epoch: 196 [1536/8000 (19%)]\tTotal Loss: 0.213297\n",
      "Reconstruction: 0.112596, Regularization: 0.035718, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:25,342 root         INFO     Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 0.408878\n",
      "Reconstruction: 0.202331, Regularization: 0.141552, Discriminator: 0.043336; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:25,453 root         INFO     Train Epoch: 196 [2560/8000 (32%)]\tTotal Loss: 0.250317\n",
      "Reconstruction: 0.155125, Regularization: 0.030212, Discriminator: 0.043313; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:25,565 root         INFO     Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 0.262834\n",
      "Reconstruction: 0.141154, Regularization: 0.056683, Discriminator: 0.043331; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:25,676 root         INFO     Train Epoch: 196 [3584/8000 (45%)]\tTotal Loss: 0.207248\n",
      "Reconstruction: 0.111352, Regularization: 0.030894, Discriminator: 0.043347; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:25,788 root         INFO     Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 2.242435\n",
      "Reconstruction: 1.937298, Regularization: 0.240185, Discriminator: 0.043301; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:25,899 root         INFO     Train Epoch: 196 [4608/8000 (58%)]\tTotal Loss: 0.312951\n",
      "Reconstruction: 0.130376, Regularization: 0.117572, Discriminator: 0.043322; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:26,011 root         INFO     Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 0.638451\n",
      "Reconstruction: 0.159721, Regularization: 0.413733, Discriminator: 0.043348; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:26,122 root         INFO     Train Epoch: 196 [5632/8000 (70%)]\tTotal Loss: 0.264275\n",
      "Reconstruction: 0.133528, Regularization: 0.065770, Discriminator: 0.043314; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:26,234 root         INFO     Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 18.567520\n",
      "Reconstruction: 18.399973, Regularization: 0.102568, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:26,345 root         INFO     Train Epoch: 196 [6656/8000 (83%)]\tTotal Loss: 0.225843\n",
      "Reconstruction: 0.104308, Regularization: 0.056546, Discriminator: 0.043316; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:26,457 root         INFO     Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 0.249000\n",
      "Reconstruction: 0.115432, Regularization: 0.068604, Discriminator: 0.043274; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:26,569 root         INFO     Train Epoch: 196 [7680/8000 (96%)]\tTotal Loss: 0.188136\n",
      "Reconstruction: 0.092089, Regularization: 0.031088, Discriminator: 0.043297; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:26,650 root         INFO     ====> Epoch: 196 Average loss: 12.3576\n",
      "2019-04-09 23:37:26,676 root         INFO     Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 0.299051\n",
      "Reconstruction: 0.145387, Regularization: 0.088664, Discriminator: 0.043322; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:26,789 root         INFO     Train Epoch: 197 [512/8000 (6%)]\tTotal Loss: 0.225653\n",
      "Reconstruction: 0.124271, Regularization: 0.036379, Discriminator: 0.043331; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:26,900 root         INFO     Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 1.565032\n",
      "Reconstruction: 1.394857, Regularization: 0.105218, Discriminator: 0.043308; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:27,009 root         INFO     Train Epoch: 197 [1536/8000 (19%)]\tTotal Loss: 0.252809\n",
      "Reconstruction: 0.122493, Regularization: 0.065336, Discriminator: 0.043301; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:27,119 root         INFO     Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 0.239201\n",
      "Reconstruction: 0.129961, Regularization: 0.044258, Discriminator: 0.043317; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:27,228 root         INFO     Train Epoch: 197 [2560/8000 (32%)]\tTotal Loss: 0.311363\n",
      "Reconstruction: 0.194739, Regularization: 0.051629, Discriminator: 0.043338; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:27,338 root         INFO     Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 0.389538\n",
      "Reconstruction: 0.268080, Regularization: 0.056484, Discriminator: 0.043294; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:27,449 root         INFO     Train Epoch: 197 [3584/8000 (45%)]\tTotal Loss: 0.664704\n",
      "Reconstruction: 0.521087, Regularization: 0.078636, Discriminator: 0.043326; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:27,560 root         INFO     Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 1.004061\n",
      "Reconstruction: 0.874026, Regularization: 0.065044, Discriminator: 0.043333; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:27,672 root         INFO     Train Epoch: 197 [4608/8000 (58%)]\tTotal Loss: 0.488102\n",
      "Reconstruction: 0.355211, Regularization: 0.067886, Discriminator: 0.043339; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:27,783 root         INFO     Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 0.365970\n",
      "Reconstruction: 0.216106, Regularization: 0.084866, Discriminator: 0.043355; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:27,895 root         INFO     Train Epoch: 197 [5632/8000 (70%)]\tTotal Loss: 1.902720\n",
      "Reconstruction: 1.783072, Regularization: 0.054651, Discriminator: 0.043337; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:28,005 root         INFO     Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 0.191303\n",
      "Reconstruction: 0.097885, Regularization: 0.028432, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:28,115 root         INFO     Train Epoch: 197 [6656/8000 (83%)]\tTotal Loss: 0.226884\n",
      "Reconstruction: 0.133147, Regularization: 0.028747, Discriminator: 0.043317; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:28,224 root         INFO     Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 8.939015\n",
      "Reconstruction: 8.786314, Regularization: 0.087723, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:28,333 root         INFO     Train Epoch: 197 [7680/8000 (96%)]\tTotal Loss: 0.242005\n",
      "Reconstruction: 0.119243, Regularization: 0.057781, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:28,413 root         INFO     ====> Epoch: 197 Average loss: 15.6776\n",
      "2019-04-09 23:37:28,440 root         INFO     Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 0.258704\n",
      "Reconstruction: 0.148378, Regularization: 0.045347, Discriminator: 0.043317; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:28,552 root         INFO     Train Epoch: 198 [512/8000 (6%)]\tTotal Loss: 1.288874\n",
      "Reconstruction: 0.950338, Regularization: 0.273541, Discriminator: 0.043332; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:28,663 root         INFO     Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.268418\n",
      "Reconstruction: 0.152914, Regularization: 0.050509, Discriminator: 0.043334; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:28,774 root         INFO     Train Epoch: 198 [1536/8000 (19%)]\tTotal Loss: 0.237481\n",
      "Reconstruction: 0.138922, Regularization: 0.033580, Discriminator: 0.043335; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:28,885 root         INFO     Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 0.253560\n",
      "Reconstruction: 0.141612, Regularization: 0.046953, Discriminator: 0.043331; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:28,993 root         INFO     Train Epoch: 198 [2560/8000 (32%)]\tTotal Loss: 0.321666\n",
      "Reconstruction: 0.209821, Regularization: 0.046859, Discriminator: 0.043315; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:29,100 root         INFO     Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 0.205059\n",
      "Reconstruction: 0.113948, Regularization: 0.026133, Discriminator: 0.043311; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:29,207 root         INFO     Train Epoch: 198 [3584/8000 (45%)]\tTotal Loss: 0.266426\n",
      "Reconstruction: 0.119830, Regularization: 0.081616, Discriminator: 0.043298; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:29,314 root         INFO     Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 38.500244\n",
      "Reconstruction: 38.376038, Regularization: 0.059228, Discriminator: 0.043317; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:29,421 root         INFO     Train Epoch: 198 [4608/8000 (58%)]\tTotal Loss: 0.283653\n",
      "Reconstruction: 0.115670, Regularization: 0.102974, Discriminator: 0.043334; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:29,528 root         INFO     Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 0.294294\n",
      "Reconstruction: 0.161380, Regularization: 0.067968, Discriminator: 0.043292; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:37:29,635 root         INFO     Train Epoch: 198 [5632/8000 (70%)]\tTotal Loss: 1.698522\n",
      "Reconstruction: 1.514190, Regularization: 0.119349, Discriminator: 0.043328; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:29,742 root         INFO     Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 0.337649\n",
      "Reconstruction: 0.206625, Regularization: 0.066047, Discriminator: 0.043313; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:29,849 root         INFO     Train Epoch: 198 [6656/8000 (83%)]\tTotal Loss: 0.220883\n",
      "Reconstruction: 0.109777, Regularization: 0.046138, Discriminator: 0.043306; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:29,957 root         INFO     Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 0.248683\n",
      "Reconstruction: 0.125040, Regularization: 0.058661, Discriminator: 0.043329; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:30,064 root         INFO     Train Epoch: 198 [7680/8000 (96%)]\tTotal Loss: 0.244934\n",
      "Reconstruction: 0.128235, Regularization: 0.051709, Discriminator: 0.043319; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:30,142 root         INFO     ====> Epoch: 198 Average loss: 133636.6833\n",
      "2019-04-09 23:37:30,169 root         INFO     Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 0.276853\n",
      "Reconstruction: 0.133859, Regularization: 0.078040, Discriminator: 0.043301; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:30,276 root         INFO     Train Epoch: 199 [512/8000 (6%)]\tTotal Loss: 0.261345\n",
      "Reconstruction: 0.116328, Regularization: 0.080030, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:30,389 root         INFO     Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 0.561181\n",
      "Reconstruction: 0.211234, Regularization: 0.284968, Discriminator: 0.043287; Generator: 0.021692,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:30,502 root         INFO     Train Epoch: 199 [1536/8000 (19%)]\tTotal Loss: 0.279515\n",
      "Reconstruction: 0.130245, Regularization: 0.084282, Discriminator: 0.043334; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:30,613 root         INFO     Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 0.277180\n",
      "Reconstruction: 0.157731, Regularization: 0.054480, Discriminator: 0.043315; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:30,725 root         INFO     Train Epoch: 199 [2560/8000 (32%)]\tTotal Loss: 0.229439\n",
      "Reconstruction: 0.106830, Regularization: 0.057622, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:30,834 root         INFO     Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 0.431355\n",
      "Reconstruction: 0.295981, Regularization: 0.070380, Discriminator: 0.043335; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:30,942 root         INFO     Train Epoch: 199 [3584/8000 (45%)]\tTotal Loss: 0.218818\n",
      "Reconstruction: 0.109431, Regularization: 0.044414, Discriminator: 0.043314; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:31,050 root         INFO     Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 0.367627\n",
      "Reconstruction: 0.188894, Regularization: 0.113753, Discriminator: 0.043336; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:31,159 root         INFO     Train Epoch: 199 [4608/8000 (58%)]\tTotal Loss: 0.232644\n",
      "Reconstruction: 0.124498, Regularization: 0.043162, Discriminator: 0.043327; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:31,267 root         INFO     Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 0.240469\n",
      "Reconstruction: 0.112049, Regularization: 0.063435, Discriminator: 0.043326; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:31,377 root         INFO     Train Epoch: 199 [5632/8000 (70%)]\tTotal Loss: 0.314855\n",
      "Reconstruction: 0.143560, Regularization: 0.106312, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:31,485 root         INFO     Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.342112\n",
      "Reconstruction: 0.206202, Regularization: 0.070928, Discriminator: 0.043318; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:31,593 root         INFO     Train Epoch: 199 [6656/8000 (83%)]\tTotal Loss: 0.190535\n",
      "Reconstruction: 0.091328, Regularization: 0.034224, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:31,701 root         INFO     Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 0.272858\n",
      "Reconstruction: 0.131170, Regularization: 0.076697, Discriminator: 0.043321; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:31,809 root         INFO     Train Epoch: 199 [7680/8000 (96%)]\tTotal Loss: 0.218658\n",
      "Reconstruction: 0.119658, Regularization: 0.034007, Discriminator: 0.043324; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:37:31,890 root         INFO     ====> Epoch: 199 Average loss: 542.4535\n",
      "2019-04-09 23:37:31,903 luigi-interface INFO     [pid 19881] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=19881) done      TrainVEM()\n",
      "2019-04-09 23:37:31,903 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 23:37:31,904 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   DONE\n",
      "2019-04-09 23:37:31,904 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 23:37:31,904 luigi-interface DEBUG    Pending tasks: 2\n",
      "2019-04-09 23:37:31,904 luigi-interface INFO     [pid 19881] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=19881) running   TrainVAE()\n",
      "2019-04-09 23:37:31,905 root         INFO     --Dataset tensor: (10000, 2)\n",
      "2019-04-09 23:37:31,905 root         INFO     -- Train tensor: (8000, 2)\n",
      "2019-04-09 23:37:31,906 root         INFO     Values of VAE's decoder parameters before training:\n",
      "2019-04-09 23:37:31,906 root         INFO     layers.0.weight\n",
      "2019-04-09 23:37:31,906 root         INFO     tensor([[-0.6497],\n",
      "        [ 0.9626]], device='cuda:0')\n",
      "2019-04-09 23:37:31,907 root         INFO     layers.0.bias\n",
      "2019-04-09 23:37:31,907 root         INFO     tensor([-0.9750, -0.2332], device='cuda:0')\n",
      "2019-04-09 23:37:31,908 root         INFO     layers.1.weight\n",
      "2019-04-09 23:37:31,908 root         INFO     tensor([[-0.1379, -0.5922],\n",
      "        [-0.2357,  0.5636]], device='cuda:0')\n",
      "2019-04-09 23:37:31,909 root         INFO     layers.1.bias\n",
      "2019-04-09 23:37:31,910 root         INFO     tensor([-0.1943,  0.0769], device='cuda:0')\n",
      "2019-04-09 23:37:31,911 root         INFO     layers.2.weight\n",
      "2019-04-09 23:37:31,911 root         INFO     tensor([[ 0.6644, -0.5124],\n",
      "        [-0.4031, -0.4051]], device='cuda:0')\n",
      "2019-04-09 23:37:31,912 root         INFO     layers.2.bias\n",
      "2019-04-09 23:37:31,912 root         INFO     tensor([-0.5565,  0.1725], device='cuda:0')\n",
      "2019-04-09 23:37:31,913 root         INFO     layers.3.weight\n",
      "2019-04-09 23:37:31,913 root         INFO     tensor([[-0.3523, -0.6266],\n",
      "        [-0.3515, -0.2904]], device='cuda:0')\n",
      "2019-04-09 23:37:31,914 root         INFO     layers.3.bias\n",
      "2019-04-09 23:37:31,914 root         INFO     tensor([-0.3550,  0.0500], device='cuda:0')\n",
      "2019-04-09 23:37:31,915 root         INFO     layers.4.weight\n",
      "2019-04-09 23:37:31,915 root         INFO     tensor([[ 0.2561, -0.3836],\n",
      "        [ 0.3839,  0.2321]], device='cuda:0')\n",
      "2019-04-09 23:37:31,916 root         INFO     layers.4.bias\n",
      "2019-04-09 23:37:31,916 root         INFO     tensor([-0.6679, -0.5838], device='cuda:0')\n",
      "2019-04-09 23:37:31,917 root         INFO     layers.5.weight\n",
      "2019-04-09 23:37:31,917 root         INFO     tensor([[-0.1573,  0.5253],\n",
      "        [ 0.6630,  0.1170]], device='cuda:0')\n",
      "2019-04-09 23:37:31,918 root         INFO     layers.5.bias\n",
      "2019-04-09 23:37:31,918 root         INFO     tensor([ 0.4975, -0.3834], device='cuda:0')\n",
      "2019-04-09 23:37:31,943 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 0.133221\n",
      "Reconstruction: 0.119917, Regularization: 0.013305\n",
      "2019-04-09 23:37:32,007 root         INFO     Train Epoch: 0 [512/8000 (6%)]\tTotal Loss: 0.118532\n",
      "Reconstruction: 0.103465, Regularization: 0.015067\n",
      "2019-04-09 23:37:32,071 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 0.126935\n",
      "Reconstruction: 0.113749, Regularization: 0.013186\n",
      "2019-04-09 23:37:32,135 root         INFO     Train Epoch: 0 [1536/8000 (19%)]\tTotal Loss: 0.136277\n",
      "Reconstruction: 0.122209, Regularization: 0.014068\n",
      "2019-04-09 23:37:32,199 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 0.117990\n",
      "Reconstruction: 0.104557, Regularization: 0.013433\n",
      "2019-04-09 23:37:32,263 root         INFO     Train Epoch: 0 [2560/8000 (32%)]\tTotal Loss: 0.108919\n",
      "Reconstruction: 0.096401, Regularization: 0.012518\n",
      "2019-04-09 23:37:32,327 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 0.135506\n",
      "Reconstruction: 0.121543, Regularization: 0.013964\n",
      "2019-04-09 23:37:32,391 root         INFO     Train Epoch: 0 [3584/8000 (45%)]\tTotal Loss: 0.126486\n",
      "Reconstruction: 0.107935, Regularization: 0.018551\n",
      "2019-04-09 23:37:32,455 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 0.105814\n",
      "Reconstruction: 0.097533, Regularization: 0.008281\n",
      "2019-04-09 23:37:32,519 root         INFO     Train Epoch: 0 [4608/8000 (58%)]\tTotal Loss: 0.115935\n",
      "Reconstruction: 0.104903, Regularization: 0.011032\n",
      "2019-04-09 23:37:32,583 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 0.125322\n",
      "Reconstruction: 0.112470, Regularization: 0.012852\n",
      "2019-04-09 23:37:32,647 root         INFO     Train Epoch: 0 [5632/8000 (70%)]\tTotal Loss: 0.126177\n",
      "Reconstruction: 0.110100, Regularization: 0.016077\n",
      "2019-04-09 23:37:32,711 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 0.112648\n",
      "Reconstruction: 0.101549, Regularization: 0.011099\n",
      "2019-04-09 23:37:32,775 root         INFO     Train Epoch: 0 [6656/8000 (83%)]\tTotal Loss: 0.106631\n",
      "Reconstruction: 0.096740, Regularization: 0.009891\n",
      "2019-04-09 23:37:32,839 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 0.115697\n",
      "Reconstruction: 0.104552, Regularization: 0.011145\n",
      "2019-04-09 23:37:32,903 root         INFO     Train Epoch: 0 [7680/8000 (96%)]\tTotal Loss: 0.105996\n",
      "Reconstruction: 0.095222, Regularization: 0.010775\n",
      "2019-04-09 23:37:32,957 root         INFO     ====> Epoch: 0 Average loss: 0.1221\n",
      "2019-04-09 23:37:32,981 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 0.114935\n",
      "Reconstruction: 0.105850, Regularization: 0.009085\n",
      "2019-04-09 23:37:33,046 root         INFO     Train Epoch: 1 [512/8000 (6%)]\tTotal Loss: 0.116545\n",
      "Reconstruction: 0.102419, Regularization: 0.014125\n",
      "2019-04-09 23:37:33,108 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 0.115708\n",
      "Reconstruction: 0.102545, Regularization: 0.013163\n",
      "2019-04-09 23:37:33,170 root         INFO     Train Epoch: 1 [1536/8000 (19%)]\tTotal Loss: 0.112790\n",
      "Reconstruction: 0.103133, Regularization: 0.009657\n",
      "2019-04-09 23:37:33,232 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 0.123946\n",
      "Reconstruction: 0.114685, Regularization: 0.009261\n",
      "2019-04-09 23:37:33,296 root         INFO     Train Epoch: 1 [2560/8000 (32%)]\tTotal Loss: 0.139927\n",
      "Reconstruction: 0.122261, Regularization: 0.017665\n",
      "2019-04-09 23:37:33,361 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 0.128112\n",
      "Reconstruction: 0.112160, Regularization: 0.015952\n",
      "2019-04-09 23:37:33,422 root         INFO     Train Epoch: 1 [3584/8000 (45%)]\tTotal Loss: 0.123361\n",
      "Reconstruction: 0.111276, Regularization: 0.012085\n",
      "2019-04-09 23:37:33,484 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 0.128341\n",
      "Reconstruction: 0.112596, Regularization: 0.015745\n",
      "2019-04-09 23:37:33,545 root         INFO     Train Epoch: 1 [4608/8000 (58%)]\tTotal Loss: 0.108582\n",
      "Reconstruction: 0.099942, Regularization: 0.008640\n",
      "2019-04-09 23:37:33,608 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 0.114128\n",
      "Reconstruction: 0.100148, Regularization: 0.013980\n",
      "2019-04-09 23:37:33,671 root         INFO     Train Epoch: 1 [5632/8000 (70%)]\tTotal Loss: 0.118103\n",
      "Reconstruction: 0.107937, Regularization: 0.010165\n",
      "2019-04-09 23:37:33,734 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 0.115790\n",
      "Reconstruction: 0.104273, Regularization: 0.011517\n",
      "2019-04-09 23:37:33,797 root         INFO     Train Epoch: 1 [6656/8000 (83%)]\tTotal Loss: 0.106180\n",
      "Reconstruction: 0.095746, Regularization: 0.010433\n",
      "2019-04-09 23:37:33,860 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 0.106166\n",
      "Reconstruction: 0.096838, Regularization: 0.009328\n",
      "2019-04-09 23:37:33,923 root         INFO     Train Epoch: 1 [7680/8000 (96%)]\tTotal Loss: 0.113141\n",
      "Reconstruction: 0.099388, Regularization: 0.013753\n",
      "2019-04-09 23:37:33,978 root         INFO     ====> Epoch: 1 Average loss: 0.1172\n",
      "2019-04-09 23:37:34,001 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 0.135949\n",
      "Reconstruction: 0.120661, Regularization: 0.015288\n",
      "2019-04-09 23:37:34,066 root         INFO     Train Epoch: 2 [512/8000 (6%)]\tTotal Loss: 0.102917\n",
      "Reconstruction: 0.091050, Regularization: 0.011867\n",
      "2019-04-09 23:37:34,130 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 0.104345\n",
      "Reconstruction: 0.095836, Regularization: 0.008509\n",
      "2019-04-09 23:37:34,195 root         INFO     Train Epoch: 2 [1536/8000 (19%)]\tTotal Loss: 0.120352\n",
      "Reconstruction: 0.110446, Regularization: 0.009906\n",
      "2019-04-09 23:37:34,259 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 0.123343\n",
      "Reconstruction: 0.110390, Regularization: 0.012953\n",
      "2019-04-09 23:37:34,323 root         INFO     Train Epoch: 2 [2560/8000 (32%)]\tTotal Loss: 0.114139\n",
      "Reconstruction: 0.101090, Regularization: 0.013049\n",
      "2019-04-09 23:37:34,387 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 0.106103\n",
      "Reconstruction: 0.096365, Regularization: 0.009738\n",
      "2019-04-09 23:37:34,451 root         INFO     Train Epoch: 2 [3584/8000 (45%)]\tTotal Loss: 0.122935\n",
      "Reconstruction: 0.110251, Regularization: 0.012684\n",
      "2019-04-09 23:37:34,515 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 0.116029\n",
      "Reconstruction: 0.102786, Regularization: 0.013243\n",
      "2019-04-09 23:37:34,579 root         INFO     Train Epoch: 2 [4608/8000 (58%)]\tTotal Loss: 0.114931\n",
      "Reconstruction: 0.104272, Regularization: 0.010659\n",
      "2019-04-09 23:37:34,642 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 0.114593\n",
      "Reconstruction: 0.105278, Regularization: 0.009315\n",
      "2019-04-09 23:37:34,705 root         INFO     Train Epoch: 2 [5632/8000 (70%)]\tTotal Loss: 0.124010\n",
      "Reconstruction: 0.112250, Regularization: 0.011760\n",
      "2019-04-09 23:37:34,768 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 0.109330\n",
      "Reconstruction: 0.098448, Regularization: 0.010882\n",
      "2019-04-09 23:37:34,832 root         INFO     Train Epoch: 2 [6656/8000 (83%)]\tTotal Loss: 0.118586\n",
      "Reconstruction: 0.111005, Regularization: 0.007581\n",
      "2019-04-09 23:37:34,895 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 0.120461\n",
      "Reconstruction: 0.111774, Regularization: 0.008687\n",
      "2019-04-09 23:37:34,958 root         INFO     Train Epoch: 2 [7680/8000 (96%)]\tTotal Loss: 0.121449\n",
      "Reconstruction: 0.111981, Regularization: 0.009468\n",
      "2019-04-09 23:37:35,012 root         INFO     ====> Epoch: 2 Average loss: 0.1124\n",
      "2019-04-09 23:37:35,035 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 0.104048\n",
      "Reconstruction: 0.096865, Regularization: 0.007183\n",
      "2019-04-09 23:37:35,099 root         INFO     Train Epoch: 3 [512/8000 (6%)]\tTotal Loss: 0.114423\n",
      "Reconstruction: 0.103408, Regularization: 0.011015\n",
      "2019-04-09 23:37:35,163 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 0.106560\n",
      "Reconstruction: 0.095062, Regularization: 0.011498\n",
      "2019-04-09 23:37:35,226 root         INFO     Train Epoch: 3 [1536/8000 (19%)]\tTotal Loss: 0.115582\n",
      "Reconstruction: 0.104596, Regularization: 0.010986\n",
      "2019-04-09 23:37:35,290 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 0.102369\n",
      "Reconstruction: 0.092989, Regularization: 0.009379\n",
      "2019-04-09 23:37:35,354 root         INFO     Train Epoch: 3 [2560/8000 (32%)]\tTotal Loss: 0.111617\n",
      "Reconstruction: 0.101885, Regularization: 0.009732\n",
      "2019-04-09 23:37:35,418 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 0.110607\n",
      "Reconstruction: 0.101006, Regularization: 0.009601\n",
      "2019-04-09 23:37:35,482 root         INFO     Train Epoch: 3 [3584/8000 (45%)]\tTotal Loss: 0.099974\n",
      "Reconstruction: 0.092891, Regularization: 0.007084\n",
      "2019-04-09 23:37:35,546 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 0.106340\n",
      "Reconstruction: 0.099612, Regularization: 0.006728\n",
      "2019-04-09 23:37:35,609 root         INFO     Train Epoch: 3 [4608/8000 (58%)]\tTotal Loss: 0.091017\n",
      "Reconstruction: 0.084938, Regularization: 0.006080\n",
      "2019-04-09 23:37:35,673 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 0.107447\n",
      "Reconstruction: 0.099304, Regularization: 0.008143\n",
      "2019-04-09 23:37:35,737 root         INFO     Train Epoch: 3 [5632/8000 (70%)]\tTotal Loss: 0.095031\n",
      "Reconstruction: 0.086452, Regularization: 0.008579\n",
      "2019-04-09 23:37:35,801 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 0.107902\n",
      "Reconstruction: 0.098428, Regularization: 0.009474\n",
      "2019-04-09 23:37:35,865 root         INFO     Train Epoch: 3 [6656/8000 (83%)]\tTotal Loss: 0.104800\n",
      "Reconstruction: 0.096649, Regularization: 0.008152\n",
      "2019-04-09 23:37:35,929 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 0.114047\n",
      "Reconstruction: 0.103531, Regularization: 0.010516\n",
      "2019-04-09 23:37:35,993 root         INFO     Train Epoch: 3 [7680/8000 (96%)]\tTotal Loss: 0.108208\n",
      "Reconstruction: 0.099734, Regularization: 0.008474\n",
      "2019-04-09 23:37:36,047 root         INFO     ====> Epoch: 3 Average loss: 0.1080\n",
      "2019-04-09 23:37:36,070 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 0.102497\n",
      "Reconstruction: 0.093154, Regularization: 0.009343\n",
      "2019-04-09 23:37:36,134 root         INFO     Train Epoch: 4 [512/8000 (6%)]\tTotal Loss: 0.107200\n",
      "Reconstruction: 0.098111, Regularization: 0.009089\n",
      "2019-04-09 23:37:36,197 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 0.106753\n",
      "Reconstruction: 0.097399, Regularization: 0.009354\n",
      "2019-04-09 23:37:36,260 root         INFO     Train Epoch: 4 [1536/8000 (19%)]\tTotal Loss: 0.098164\n",
      "Reconstruction: 0.089931, Regularization: 0.008233\n",
      "2019-04-09 23:37:36,324 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 0.115687\n",
      "Reconstruction: 0.106800, Regularization: 0.008887\n",
      "2019-04-09 23:37:36,387 root         INFO     Train Epoch: 4 [2560/8000 (32%)]\tTotal Loss: 0.110652\n",
      "Reconstruction: 0.100075, Regularization: 0.010577\n",
      "2019-04-09 23:37:36,451 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 0.110730\n",
      "Reconstruction: 0.100543, Regularization: 0.010187\n",
      "2019-04-09 23:37:36,514 root         INFO     Train Epoch: 4 [3584/8000 (45%)]\tTotal Loss: 0.105559\n",
      "Reconstruction: 0.097364, Regularization: 0.008195\n",
      "2019-04-09 23:37:36,577 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 0.102971\n",
      "Reconstruction: 0.096298, Regularization: 0.006673\n",
      "2019-04-09 23:37:36,641 root         INFO     Train Epoch: 4 [4608/8000 (58%)]\tTotal Loss: 0.105309\n",
      "Reconstruction: 0.095784, Regularization: 0.009524\n",
      "2019-04-09 23:37:36,704 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 0.090829\n",
      "Reconstruction: 0.084871, Regularization: 0.005958\n",
      "2019-04-09 23:37:36,768 root         INFO     Train Epoch: 4 [5632/8000 (70%)]\tTotal Loss: 0.097608\n",
      "Reconstruction: 0.090671, Regularization: 0.006936\n",
      "2019-04-09 23:37:36,831 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 0.103626\n",
      "Reconstruction: 0.094273, Regularization: 0.009353\n",
      "2019-04-09 23:37:36,895 root         INFO     Train Epoch: 4 [6656/8000 (83%)]\tTotal Loss: 0.095760\n",
      "Reconstruction: 0.089343, Regularization: 0.006416\n",
      "2019-04-09 23:37:36,958 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 0.095764\n",
      "Reconstruction: 0.088846, Regularization: 0.006918\n",
      "2019-04-09 23:37:37,022 root         INFO     Train Epoch: 4 [7680/8000 (96%)]\tTotal Loss: 0.120545\n",
      "Reconstruction: 0.108292, Regularization: 0.012254\n",
      "2019-04-09 23:37:37,075 root         INFO     ====> Epoch: 4 Average loss: 0.1041\n",
      "2019-04-09 23:37:37,099 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 0.102565\n",
      "Reconstruction: 0.094378, Regularization: 0.008187\n",
      "2019-04-09 23:37:37,163 root         INFO     Train Epoch: 5 [512/8000 (6%)]\tTotal Loss: 0.103838\n",
      "Reconstruction: 0.095844, Regularization: 0.007994\n",
      "2019-04-09 23:37:37,226 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 0.095758\n",
      "Reconstruction: 0.090784, Regularization: 0.004974\n",
      "2019-04-09 23:37:37,289 root         INFO     Train Epoch: 5 [1536/8000 (19%)]\tTotal Loss: 0.097143\n",
      "Reconstruction: 0.090412, Regularization: 0.006731\n",
      "2019-04-09 23:37:37,352 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 0.094159\n",
      "Reconstruction: 0.085957, Regularization: 0.008202\n",
      "2019-04-09 23:37:37,415 root         INFO     Train Epoch: 5 [2560/8000 (32%)]\tTotal Loss: 0.108650\n",
      "Reconstruction: 0.101111, Regularization: 0.007539\n",
      "2019-04-09 23:37:37,478 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 0.097128\n",
      "Reconstruction: 0.090132, Regularization: 0.006995\n",
      "2019-04-09 23:37:37,541 root         INFO     Train Epoch: 5 [3584/8000 (45%)]\tTotal Loss: 0.096948\n",
      "Reconstruction: 0.090165, Regularization: 0.006782\n",
      "2019-04-09 23:37:37,603 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 0.097646\n",
      "Reconstruction: 0.088471, Regularization: 0.009174\n",
      "2019-04-09 23:37:37,666 root         INFO     Train Epoch: 5 [4608/8000 (58%)]\tTotal Loss: 0.099210\n",
      "Reconstruction: 0.093346, Regularization: 0.005865\n",
      "2019-04-09 23:37:37,728 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 0.106586\n",
      "Reconstruction: 0.099377, Regularization: 0.007210\n",
      "2019-04-09 23:37:37,790 root         INFO     Train Epoch: 5 [5632/8000 (70%)]\tTotal Loss: 0.099562\n",
      "Reconstruction: 0.091904, Regularization: 0.007658\n",
      "2019-04-09 23:37:37,852 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 0.095212\n",
      "Reconstruction: 0.088307, Regularization: 0.006906\n",
      "2019-04-09 23:37:37,915 root         INFO     Train Epoch: 5 [6656/8000 (83%)]\tTotal Loss: 0.124133\n",
      "Reconstruction: 0.114518, Regularization: 0.009615\n",
      "2019-04-09 23:37:37,978 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 0.097070\n",
      "Reconstruction: 0.088485, Regularization: 0.008585\n",
      "2019-04-09 23:37:38,040 root         INFO     Train Epoch: 5 [7680/8000 (96%)]\tTotal Loss: 0.104645\n",
      "Reconstruction: 0.097362, Regularization: 0.007283\n",
      "2019-04-09 23:37:38,094 root         INFO     ====> Epoch: 5 Average loss: 0.1010\n",
      "2019-04-09 23:37:38,117 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 0.099349\n",
      "Reconstruction: 0.093150, Regularization: 0.006199\n",
      "2019-04-09 23:37:38,182 root         INFO     Train Epoch: 6 [512/8000 (6%)]\tTotal Loss: 0.088039\n",
      "Reconstruction: 0.081180, Regularization: 0.006859\n",
      "2019-04-09 23:37:38,245 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 0.113949\n",
      "Reconstruction: 0.108184, Regularization: 0.005765\n",
      "2019-04-09 23:37:38,309 root         INFO     Train Epoch: 6 [1536/8000 (19%)]\tTotal Loss: 0.093392\n",
      "Reconstruction: 0.086578, Regularization: 0.006814\n",
      "2019-04-09 23:37:38,373 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 0.088190\n",
      "Reconstruction: 0.082091, Regularization: 0.006099\n",
      "2019-04-09 23:37:38,437 root         INFO     Train Epoch: 6 [2560/8000 (32%)]\tTotal Loss: 0.083481\n",
      "Reconstruction: 0.078233, Regularization: 0.005248\n",
      "2019-04-09 23:37:38,501 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 0.091651\n",
      "Reconstruction: 0.085828, Regularization: 0.005822\n",
      "2019-04-09 23:37:38,564 root         INFO     Train Epoch: 6 [3584/8000 (45%)]\tTotal Loss: 0.091032\n",
      "Reconstruction: 0.086244, Regularization: 0.004788\n",
      "2019-04-09 23:37:38,628 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 0.089560\n",
      "Reconstruction: 0.084634, Regularization: 0.004926\n",
      "2019-04-09 23:37:38,691 root         INFO     Train Epoch: 6 [4608/8000 (58%)]\tTotal Loss: 0.105474\n",
      "Reconstruction: 0.099158, Regularization: 0.006317\n",
      "2019-04-09 23:37:38,756 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 0.096989\n",
      "Reconstruction: 0.089358, Regularization: 0.007631\n",
      "2019-04-09 23:37:38,819 root         INFO     Train Epoch: 6 [5632/8000 (70%)]\tTotal Loss: 0.092851\n",
      "Reconstruction: 0.087108, Regularization: 0.005743\n",
      "2019-04-09 23:37:38,883 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 0.086162\n",
      "Reconstruction: 0.081018, Regularization: 0.005144\n",
      "2019-04-09 23:37:38,947 root         INFO     Train Epoch: 6 [6656/8000 (83%)]\tTotal Loss: 0.108403\n",
      "Reconstruction: 0.101368, Regularization: 0.007036\n",
      "2019-04-09 23:37:39,010 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 0.098566\n",
      "Reconstruction: 0.091067, Regularization: 0.007499\n",
      "2019-04-09 23:37:39,074 root         INFO     Train Epoch: 6 [7680/8000 (96%)]\tTotal Loss: 0.093824\n",
      "Reconstruction: 0.088248, Regularization: 0.005576\n",
      "2019-04-09 23:37:39,128 root         INFO     ====> Epoch: 6 Average loss: 0.0988\n",
      "2019-04-09 23:37:39,152 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 0.088486\n",
      "Reconstruction: 0.081762, Regularization: 0.006724\n",
      "2019-04-09 23:37:39,215 root         INFO     Train Epoch: 7 [512/8000 (6%)]\tTotal Loss: 0.088184\n",
      "Reconstruction: 0.084762, Regularization: 0.003423\n",
      "2019-04-09 23:37:39,278 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 0.087825\n",
      "Reconstruction: 0.082459, Regularization: 0.005366\n",
      "2019-04-09 23:37:39,341 root         INFO     Train Epoch: 7 [1536/8000 (19%)]\tTotal Loss: 0.087027\n",
      "Reconstruction: 0.081359, Regularization: 0.005667\n",
      "2019-04-09 23:37:39,404 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 0.091342\n",
      "Reconstruction: 0.086110, Regularization: 0.005231\n",
      "2019-04-09 23:37:39,467 root         INFO     Train Epoch: 7 [2560/8000 (32%)]\tTotal Loss: 0.116668\n",
      "Reconstruction: 0.109020, Regularization: 0.007648\n",
      "2019-04-09 23:37:39,531 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 0.101203\n",
      "Reconstruction: 0.094965, Regularization: 0.006238\n",
      "2019-04-09 23:37:39,594 root         INFO     Train Epoch: 7 [3584/8000 (45%)]\tTotal Loss: 0.099793\n",
      "Reconstruction: 0.094088, Regularization: 0.005705\n",
      "2019-04-09 23:37:39,657 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 0.126580\n",
      "Reconstruction: 0.118180, Regularization: 0.008401\n",
      "2019-04-09 23:37:39,720 root         INFO     Train Epoch: 7 [4608/8000 (58%)]\tTotal Loss: 0.100207\n",
      "Reconstruction: 0.093325, Regularization: 0.006881\n",
      "2019-04-09 23:37:39,783 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 0.103224\n",
      "Reconstruction: 0.097690, Regularization: 0.005534\n",
      "2019-04-09 23:37:39,846 root         INFO     Train Epoch: 7 [5632/8000 (70%)]\tTotal Loss: 0.088874\n",
      "Reconstruction: 0.084146, Regularization: 0.004728\n",
      "2019-04-09 23:37:39,909 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 0.089885\n",
      "Reconstruction: 0.084939, Regularization: 0.004946\n",
      "2019-04-09 23:37:39,972 root         INFO     Train Epoch: 7 [6656/8000 (83%)]\tTotal Loss: 0.100598\n",
      "Reconstruction: 0.096287, Regularization: 0.004310\n",
      "2019-04-09 23:37:40,035 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 0.096955\n",
      "Reconstruction: 0.092203, Regularization: 0.004752\n",
      "2019-04-09 23:37:40,098 root         INFO     Train Epoch: 7 [7680/8000 (96%)]\tTotal Loss: 0.089940\n",
      "Reconstruction: 0.084078, Regularization: 0.005862\n",
      "2019-04-09 23:37:40,151 root         INFO     ====> Epoch: 7 Average loss: 0.0970\n",
      "2019-04-09 23:37:40,175 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 0.080215\n",
      "Reconstruction: 0.076261, Regularization: 0.003954\n",
      "2019-04-09 23:37:40,240 root         INFO     Train Epoch: 8 [512/8000 (6%)]\tTotal Loss: 0.103756\n",
      "Reconstruction: 0.096513, Regularization: 0.007244\n",
      "2019-04-09 23:37:40,303 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 0.099198\n",
      "Reconstruction: 0.092995, Regularization: 0.006203\n",
      "2019-04-09 23:37:40,367 root         INFO     Train Epoch: 8 [1536/8000 (19%)]\tTotal Loss: 0.089225\n",
      "Reconstruction: 0.085904, Regularization: 0.003321\n",
      "2019-04-09 23:37:40,432 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 0.092632\n",
      "Reconstruction: 0.087592, Regularization: 0.005041\n",
      "2019-04-09 23:37:40,495 root         INFO     Train Epoch: 8 [2560/8000 (32%)]\tTotal Loss: 0.093848\n",
      "Reconstruction: 0.087839, Regularization: 0.006008\n",
      "2019-04-09 23:37:40,559 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 0.097225\n",
      "Reconstruction: 0.091361, Regularization: 0.005864\n",
      "2019-04-09 23:37:40,623 root         INFO     Train Epoch: 8 [3584/8000 (45%)]\tTotal Loss: 0.082222\n",
      "Reconstruction: 0.077598, Regularization: 0.004624\n",
      "2019-04-09 23:37:40,687 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 0.089172\n",
      "Reconstruction: 0.083269, Regularization: 0.005903\n",
      "2019-04-09 23:37:40,751 root         INFO     Train Epoch: 8 [4608/8000 (58%)]\tTotal Loss: 0.098451\n",
      "Reconstruction: 0.094038, Regularization: 0.004413\n",
      "2019-04-09 23:37:40,815 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 0.100355\n",
      "Reconstruction: 0.093883, Regularization: 0.006472\n",
      "2019-04-09 23:37:40,879 root         INFO     Train Epoch: 8 [5632/8000 (70%)]\tTotal Loss: 0.095131\n",
      "Reconstruction: 0.089771, Regularization: 0.005359\n",
      "2019-04-09 23:37:40,942 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 0.095082\n",
      "Reconstruction: 0.090543, Regularization: 0.004540\n",
      "2019-04-09 23:37:41,006 root         INFO     Train Epoch: 8 [6656/8000 (83%)]\tTotal Loss: 0.087798\n",
      "Reconstruction: 0.083115, Regularization: 0.004683\n",
      "2019-04-09 23:37:41,070 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 0.102541\n",
      "Reconstruction: 0.096628, Regularization: 0.005913\n",
      "2019-04-09 23:37:41,134 root         INFO     Train Epoch: 8 [7680/8000 (96%)]\tTotal Loss: 0.086321\n",
      "Reconstruction: 0.082120, Regularization: 0.004200\n",
      "2019-04-09 23:37:41,188 root         INFO     ====> Epoch: 8 Average loss: 0.0956\n",
      "2019-04-09 23:37:41,212 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 0.078384\n",
      "Reconstruction: 0.075816, Regularization: 0.002568\n",
      "2019-04-09 23:37:41,276 root         INFO     Train Epoch: 9 [512/8000 (6%)]\tTotal Loss: 0.097887\n",
      "Reconstruction: 0.091086, Regularization: 0.006802\n",
      "2019-04-09 23:37:41,339 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 0.090569\n",
      "Reconstruction: 0.087327, Regularization: 0.003241\n",
      "2019-04-09 23:37:41,403 root         INFO     Train Epoch: 9 [1536/8000 (19%)]\tTotal Loss: 0.084327\n",
      "Reconstruction: 0.080780, Regularization: 0.003547\n",
      "2019-04-09 23:37:41,466 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 0.095318\n",
      "Reconstruction: 0.090523, Regularization: 0.004796\n",
      "2019-04-09 23:37:41,530 root         INFO     Train Epoch: 9 [2560/8000 (32%)]\tTotal Loss: 0.088711\n",
      "Reconstruction: 0.084605, Regularization: 0.004107\n",
      "2019-04-09 23:37:41,593 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 0.088307\n",
      "Reconstruction: 0.084642, Regularization: 0.003665\n",
      "2019-04-09 23:37:41,657 root         INFO     Train Epoch: 9 [3584/8000 (45%)]\tTotal Loss: 0.098661\n",
      "Reconstruction: 0.093388, Regularization: 0.005272\n",
      "2019-04-09 23:37:41,720 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 0.114754\n",
      "Reconstruction: 0.106710, Regularization: 0.008044\n",
      "2019-04-09 23:37:41,784 root         INFO     Train Epoch: 9 [4608/8000 (58%)]\tTotal Loss: 0.105273\n",
      "Reconstruction: 0.099624, Regularization: 0.005649\n",
      "2019-04-09 23:37:41,848 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 0.096776\n",
      "Reconstruction: 0.092111, Regularization: 0.004665\n",
      "2019-04-09 23:37:41,910 root         INFO     Train Epoch: 9 [5632/8000 (70%)]\tTotal Loss: 0.089394\n",
      "Reconstruction: 0.085125, Regularization: 0.004270\n",
      "2019-04-09 23:37:41,972 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 0.096927\n",
      "Reconstruction: 0.093682, Regularization: 0.003246\n",
      "2019-04-09 23:37:42,033 root         INFO     Train Epoch: 9 [6656/8000 (83%)]\tTotal Loss: 0.089115\n",
      "Reconstruction: 0.084529, Regularization: 0.004585\n",
      "2019-04-09 23:37:42,095 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 0.087532\n",
      "Reconstruction: 0.084450, Regularization: 0.003083\n",
      "2019-04-09 23:37:42,157 root         INFO     Train Epoch: 9 [7680/8000 (96%)]\tTotal Loss: 0.093844\n",
      "Reconstruction: 0.091134, Regularization: 0.002710\n",
      "2019-04-09 23:37:42,210 root         INFO     ====> Epoch: 9 Average loss: 0.0948\n",
      "2019-04-09 23:37:42,234 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 0.098162\n",
      "Reconstruction: 0.093125, Regularization: 0.005037\n",
      "2019-04-09 23:37:42,298 root         INFO     Train Epoch: 10 [512/8000 (6%)]\tTotal Loss: 0.093498\n",
      "Reconstruction: 0.089753, Regularization: 0.003745\n",
      "2019-04-09 23:37:42,362 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 0.112729\n",
      "Reconstruction: 0.107698, Regularization: 0.005031\n",
      "2019-04-09 23:37:42,427 root         INFO     Train Epoch: 10 [1536/8000 (19%)]\tTotal Loss: 0.104834\n",
      "Reconstruction: 0.100699, Regularization: 0.004135\n",
      "2019-04-09 23:37:42,491 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 0.106021\n",
      "Reconstruction: 0.100136, Regularization: 0.005885\n",
      "2019-04-09 23:37:42,555 root         INFO     Train Epoch: 10 [2560/8000 (32%)]\tTotal Loss: 0.100400\n",
      "Reconstruction: 0.095878, Regularization: 0.004522\n",
      "2019-04-09 23:37:42,619 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 0.094164\n",
      "Reconstruction: 0.089303, Regularization: 0.004860\n",
      "2019-04-09 23:37:42,682 root         INFO     Train Epoch: 10 [3584/8000 (45%)]\tTotal Loss: 0.097872\n",
      "Reconstruction: 0.094604, Regularization: 0.003268\n",
      "2019-04-09 23:37:42,746 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 0.092076\n",
      "Reconstruction: 0.089654, Regularization: 0.002422\n",
      "2019-04-09 23:37:42,811 root         INFO     Train Epoch: 10 [4608/8000 (58%)]\tTotal Loss: 0.093963\n",
      "Reconstruction: 0.090099, Regularization: 0.003864\n",
      "2019-04-09 23:37:42,874 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 0.092032\n",
      "Reconstruction: 0.088580, Regularization: 0.003452\n",
      "2019-04-09 23:37:42,938 root         INFO     Train Epoch: 10 [5632/8000 (70%)]\tTotal Loss: 0.085602\n",
      "Reconstruction: 0.082044, Regularization: 0.003558\n",
      "2019-04-09 23:37:43,002 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 0.101212\n",
      "Reconstruction: 0.097151, Regularization: 0.004061\n",
      "2019-04-09 23:37:43,066 root         INFO     Train Epoch: 10 [6656/8000 (83%)]\tTotal Loss: 0.095100\n",
      "Reconstruction: 0.091032, Regularization: 0.004068\n",
      "2019-04-09 23:37:43,130 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 0.099378\n",
      "Reconstruction: 0.094445, Regularization: 0.004933\n",
      "2019-04-09 23:37:43,193 root         INFO     Train Epoch: 10 [7680/8000 (96%)]\tTotal Loss: 0.090587\n",
      "Reconstruction: 0.086274, Regularization: 0.004314\n",
      "2019-04-09 23:37:43,247 root         INFO     ====> Epoch: 10 Average loss: 0.0935\n",
      "2019-04-09 23:37:43,271 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.081372\n",
      "Reconstruction: 0.077567, Regularization: 0.003805\n",
      "2019-04-09 23:37:43,336 root         INFO     Train Epoch: 11 [512/8000 (6%)]\tTotal Loss: 0.094398\n",
      "Reconstruction: 0.090997, Regularization: 0.003401\n",
      "2019-04-09 23:37:43,399 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 0.093159\n",
      "Reconstruction: 0.089192, Regularization: 0.003967\n",
      "2019-04-09 23:37:43,464 root         INFO     Train Epoch: 11 [1536/8000 (19%)]\tTotal Loss: 0.081430\n",
      "Reconstruction: 0.077895, Regularization: 0.003536\n",
      "2019-04-09 23:37:43,528 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.087047\n",
      "Reconstruction: 0.084112, Regularization: 0.002935\n",
      "2019-04-09 23:37:43,592 root         INFO     Train Epoch: 11 [2560/8000 (32%)]\tTotal Loss: 0.109621\n",
      "Reconstruction: 0.107097, Regularization: 0.002524\n",
      "2019-04-09 23:37:43,656 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 0.090270\n",
      "Reconstruction: 0.085424, Regularization: 0.004846\n",
      "2019-04-09 23:37:43,720 root         INFO     Train Epoch: 11 [3584/8000 (45%)]\tTotal Loss: 0.084239\n",
      "Reconstruction: 0.080475, Regularization: 0.003764\n",
      "2019-04-09 23:37:43,784 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 0.096880\n",
      "Reconstruction: 0.092382, Regularization: 0.004499\n",
      "2019-04-09 23:37:43,848 root         INFO     Train Epoch: 11 [4608/8000 (58%)]\tTotal Loss: 0.091864\n",
      "Reconstruction: 0.087036, Regularization: 0.004828\n",
      "2019-04-09 23:37:43,912 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 0.092341\n",
      "Reconstruction: 0.089694, Regularization: 0.002647\n",
      "2019-04-09 23:37:43,976 root         INFO     Train Epoch: 11 [5632/8000 (70%)]\tTotal Loss: 0.086129\n",
      "Reconstruction: 0.082419, Regularization: 0.003710\n",
      "2019-04-09 23:37:44,040 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.082372\n",
      "Reconstruction: 0.079622, Regularization: 0.002750\n",
      "2019-04-09 23:37:44,104 root         INFO     Train Epoch: 11 [6656/8000 (83%)]\tTotal Loss: 0.087851\n",
      "Reconstruction: 0.084128, Regularization: 0.003723\n",
      "2019-04-09 23:37:44,167 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 0.089442\n",
      "Reconstruction: 0.086849, Regularization: 0.002592\n",
      "2019-04-09 23:37:44,232 root         INFO     Train Epoch: 11 [7680/8000 (96%)]\tTotal Loss: 0.090954\n",
      "Reconstruction: 0.088459, Regularization: 0.002496\n",
      "2019-04-09 23:37:44,286 root         INFO     ====> Epoch: 11 Average loss: 0.0929\n",
      "2019-04-09 23:37:44,309 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 0.084758\n",
      "Reconstruction: 0.081729, Regularization: 0.003029\n",
      "2019-04-09 23:37:44,373 root         INFO     Train Epoch: 12 [512/8000 (6%)]\tTotal Loss: 0.095869\n",
      "Reconstruction: 0.091339, Regularization: 0.004531\n",
      "2019-04-09 23:37:44,437 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 0.094625\n",
      "Reconstruction: 0.090917, Regularization: 0.003708\n",
      "2019-04-09 23:37:44,501 root         INFO     Train Epoch: 12 [1536/8000 (19%)]\tTotal Loss: 0.092282\n",
      "Reconstruction: 0.089490, Regularization: 0.002792\n",
      "2019-04-09 23:37:44,563 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 0.091146\n",
      "Reconstruction: 0.087781, Regularization: 0.003364\n",
      "2019-04-09 23:37:44,627 root         INFO     Train Epoch: 12 [2560/8000 (32%)]\tTotal Loss: 0.087876\n",
      "Reconstruction: 0.085463, Regularization: 0.002413\n",
      "2019-04-09 23:37:44,689 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 0.090148\n",
      "Reconstruction: 0.086249, Regularization: 0.003899\n",
      "2019-04-09 23:37:44,752 root         INFO     Train Epoch: 12 [3584/8000 (45%)]\tTotal Loss: 0.090043\n",
      "Reconstruction: 0.085807, Regularization: 0.004237\n",
      "2019-04-09 23:37:44,815 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 0.085441\n",
      "Reconstruction: 0.083130, Regularization: 0.002311\n",
      "2019-04-09 23:37:44,877 root         INFO     Train Epoch: 12 [4608/8000 (58%)]\tTotal Loss: 0.092345\n",
      "Reconstruction: 0.089300, Regularization: 0.003045\n",
      "2019-04-09 23:37:44,939 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.084485\n",
      "Reconstruction: 0.081330, Regularization: 0.003155\n",
      "2019-04-09 23:37:45,000 root         INFO     Train Epoch: 12 [5632/8000 (70%)]\tTotal Loss: 0.080710\n",
      "Reconstruction: 0.078402, Regularization: 0.002307\n",
      "2019-04-09 23:37:45,062 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.094376\n",
      "Reconstruction: 0.090298, Regularization: 0.004078\n",
      "2019-04-09 23:37:45,124 root         INFO     Train Epoch: 12 [6656/8000 (83%)]\tTotal Loss: 0.096647\n",
      "Reconstruction: 0.092964, Regularization: 0.003683\n",
      "2019-04-09 23:37:45,186 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 0.092319\n",
      "Reconstruction: 0.088298, Regularization: 0.004021\n",
      "2019-04-09 23:37:45,247 root         INFO     Train Epoch: 12 [7680/8000 (96%)]\tTotal Loss: 0.089987\n",
      "Reconstruction: 0.087793, Regularization: 0.002193\n",
      "2019-04-09 23:37:45,300 root         INFO     ====> Epoch: 12 Average loss: 0.0921\n",
      "2019-04-09 23:37:45,324 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 0.086884\n",
      "Reconstruction: 0.083992, Regularization: 0.002892\n",
      "2019-04-09 23:37:45,389 root         INFO     Train Epoch: 13 [512/8000 (6%)]\tTotal Loss: 0.097384\n",
      "Reconstruction: 0.093310, Regularization: 0.004075\n",
      "2019-04-09 23:37:45,453 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 0.091595\n",
      "Reconstruction: 0.088758, Regularization: 0.002838\n",
      "2019-04-09 23:37:45,517 root         INFO     Train Epoch: 13 [1536/8000 (19%)]\tTotal Loss: 0.086615\n",
      "Reconstruction: 0.083894, Regularization: 0.002721\n",
      "2019-04-09 23:37:45,581 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 0.091008\n",
      "Reconstruction: 0.088535, Regularization: 0.002472\n",
      "2019-04-09 23:37:45,645 root         INFO     Train Epoch: 13 [2560/8000 (32%)]\tTotal Loss: 0.097410\n",
      "Reconstruction: 0.094102, Regularization: 0.003308\n",
      "2019-04-09 23:37:45,709 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 0.093849\n",
      "Reconstruction: 0.091816, Regularization: 0.002032\n",
      "2019-04-09 23:37:45,772 root         INFO     Train Epoch: 13 [3584/8000 (45%)]\tTotal Loss: 0.085299\n",
      "Reconstruction: 0.082625, Regularization: 0.002674\n",
      "2019-04-09 23:37:45,834 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 0.092917\n",
      "Reconstruction: 0.090135, Regularization: 0.002782\n",
      "2019-04-09 23:37:45,897 root         INFO     Train Epoch: 13 [4608/8000 (58%)]\tTotal Loss: 0.088584\n",
      "Reconstruction: 0.085693, Regularization: 0.002890\n",
      "2019-04-09 23:37:45,960 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 0.082559\n",
      "Reconstruction: 0.080539, Regularization: 0.002020\n",
      "2019-04-09 23:37:46,022 root         INFO     Train Epoch: 13 [5632/8000 (70%)]\tTotal Loss: 0.097037\n",
      "Reconstruction: 0.093835, Regularization: 0.003202\n",
      "2019-04-09 23:37:46,084 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 0.094987\n",
      "Reconstruction: 0.091631, Regularization: 0.003355\n",
      "2019-04-09 23:37:46,146 root         INFO     Train Epoch: 13 [6656/8000 (83%)]\tTotal Loss: 0.094098\n",
      "Reconstruction: 0.091067, Regularization: 0.003031\n",
      "2019-04-09 23:37:46,209 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 0.098487\n",
      "Reconstruction: 0.095626, Regularization: 0.002861\n",
      "2019-04-09 23:37:46,272 root         INFO     Train Epoch: 13 [7680/8000 (96%)]\tTotal Loss: 0.111469\n",
      "Reconstruction: 0.107369, Regularization: 0.004100\n",
      "2019-04-09 23:37:46,325 root         INFO     ====> Epoch: 13 Average loss: 0.0917\n",
      "2019-04-09 23:37:46,348 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.095046\n",
      "Reconstruction: 0.091967, Regularization: 0.003078\n",
      "2019-04-09 23:37:46,411 root         INFO     Train Epoch: 14 [512/8000 (6%)]\tTotal Loss: 0.085690\n",
      "Reconstruction: 0.083750, Regularization: 0.001939\n",
      "2019-04-09 23:37:46,474 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.092312\n",
      "Reconstruction: 0.088519, Regularization: 0.003793\n",
      "2019-04-09 23:37:46,537 root         INFO     Train Epoch: 14 [1536/8000 (19%)]\tTotal Loss: 0.088658\n",
      "Reconstruction: 0.085348, Regularization: 0.003309\n",
      "2019-04-09 23:37:46,600 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 0.085506\n",
      "Reconstruction: 0.082491, Regularization: 0.003015\n",
      "2019-04-09 23:37:46,663 root         INFO     Train Epoch: 14 [2560/8000 (32%)]\tTotal Loss: 0.094522\n",
      "Reconstruction: 0.091877, Regularization: 0.002645\n",
      "2019-04-09 23:37:46,725 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.090093\n",
      "Reconstruction: 0.088345, Regularization: 0.001748\n",
      "2019-04-09 23:37:46,787 root         INFO     Train Epoch: 14 [3584/8000 (45%)]\tTotal Loss: 0.084000\n",
      "Reconstruction: 0.081662, Regularization: 0.002338\n",
      "2019-04-09 23:37:46,849 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.087465\n",
      "Reconstruction: 0.085003, Regularization: 0.002462\n",
      "2019-04-09 23:37:46,913 root         INFO     Train Epoch: 14 [4608/8000 (58%)]\tTotal Loss: 0.088654\n",
      "Reconstruction: 0.085534, Regularization: 0.003120\n",
      "2019-04-09 23:37:46,978 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 0.098066\n",
      "Reconstruction: 0.095969, Regularization: 0.002097\n",
      "2019-04-09 23:37:47,041 root         INFO     Train Epoch: 14 [5632/8000 (70%)]\tTotal Loss: 0.092431\n",
      "Reconstruction: 0.089545, Regularization: 0.002886\n",
      "2019-04-09 23:37:47,105 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.089694\n",
      "Reconstruction: 0.087465, Regularization: 0.002229\n",
      "2019-04-09 23:37:47,169 root         INFO     Train Epoch: 14 [6656/8000 (83%)]\tTotal Loss: 0.089808\n",
      "Reconstruction: 0.087265, Regularization: 0.002543\n",
      "2019-04-09 23:37:47,233 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.085272\n",
      "Reconstruction: 0.083288, Regularization: 0.001984\n",
      "2019-04-09 23:37:47,295 root         INFO     Train Epoch: 14 [7680/8000 (96%)]\tTotal Loss: 0.098707\n",
      "Reconstruction: 0.095419, Regularization: 0.003288\n",
      "2019-04-09 23:37:47,348 root         INFO     ====> Epoch: 14 Average loss: 0.0912\n",
      "2019-04-09 23:37:47,372 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 0.086242\n",
      "Reconstruction: 0.084128, Regularization: 0.002115\n",
      "2019-04-09 23:37:47,436 root         INFO     Train Epoch: 15 [512/8000 (6%)]\tTotal Loss: 0.093746\n",
      "Reconstruction: 0.091243, Regularization: 0.002503\n",
      "2019-04-09 23:37:47,499 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 0.099411\n",
      "Reconstruction: 0.095618, Regularization: 0.003793\n",
      "2019-04-09 23:37:47,562 root         INFO     Train Epoch: 15 [1536/8000 (19%)]\tTotal Loss: 0.092363\n",
      "Reconstruction: 0.090386, Regularization: 0.001977\n",
      "2019-04-09 23:37:47,625 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.090316\n",
      "Reconstruction: 0.087974, Regularization: 0.002342\n",
      "2019-04-09 23:37:47,689 root         INFO     Train Epoch: 15 [2560/8000 (32%)]\tTotal Loss: 0.101518\n",
      "Reconstruction: 0.097976, Regularization: 0.003542\n",
      "2019-04-09 23:37:47,753 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.097509\n",
      "Reconstruction: 0.094121, Regularization: 0.003388\n",
      "2019-04-09 23:37:47,816 root         INFO     Train Epoch: 15 [3584/8000 (45%)]\tTotal Loss: 0.089440\n",
      "Reconstruction: 0.086379, Regularization: 0.003061\n",
      "2019-04-09 23:37:47,880 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.099039\n",
      "Reconstruction: 0.096317, Regularization: 0.002722\n",
      "2019-04-09 23:37:47,942 root         INFO     Train Epoch: 15 [4608/8000 (58%)]\tTotal Loss: 0.094035\n",
      "Reconstruction: 0.091060, Regularization: 0.002975\n",
      "2019-04-09 23:37:48,004 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.089450\n",
      "Reconstruction: 0.087455, Regularization: 0.001995\n",
      "2019-04-09 23:37:48,066 root         INFO     Train Epoch: 15 [5632/8000 (70%)]\tTotal Loss: 0.085449\n",
      "Reconstruction: 0.083276, Regularization: 0.002172\n",
      "2019-04-09 23:37:48,128 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.083946\n",
      "Reconstruction: 0.082339, Regularization: 0.001607\n",
      "2019-04-09 23:37:48,191 root         INFO     Train Epoch: 15 [6656/8000 (83%)]\tTotal Loss: 0.094798\n",
      "Reconstruction: 0.092603, Regularization: 0.002195\n",
      "2019-04-09 23:37:48,252 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 0.083853\n",
      "Reconstruction: 0.081361, Regularization: 0.002492\n",
      "2019-04-09 23:37:48,313 root         INFO     Train Epoch: 15 [7680/8000 (96%)]\tTotal Loss: 0.088321\n",
      "Reconstruction: 0.086006, Regularization: 0.002315\n",
      "2019-04-09 23:37:48,366 root         INFO     ====> Epoch: 15 Average loss: 0.0907\n",
      "2019-04-09 23:37:48,391 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 0.090005\n",
      "Reconstruction: 0.087985, Regularization: 0.002020\n",
      "2019-04-09 23:37:48,455 root         INFO     Train Epoch: 16 [512/8000 (6%)]\tTotal Loss: 0.090604\n",
      "Reconstruction: 0.088820, Regularization: 0.001783\n",
      "2019-04-09 23:37:48,519 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 0.089516\n",
      "Reconstruction: 0.087904, Regularization: 0.001613\n",
      "2019-04-09 23:37:48,583 root         INFO     Train Epoch: 16 [1536/8000 (19%)]\tTotal Loss: 0.088059\n",
      "Reconstruction: 0.086047, Regularization: 0.002012\n",
      "2019-04-09 23:37:48,646 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.091674\n",
      "Reconstruction: 0.089357, Regularization: 0.002317\n",
      "2019-04-09 23:37:48,709 root         INFO     Train Epoch: 16 [2560/8000 (32%)]\tTotal Loss: 0.099206\n",
      "Reconstruction: 0.096603, Regularization: 0.002602\n",
      "2019-04-09 23:37:48,772 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 0.092232\n",
      "Reconstruction: 0.090572, Regularization: 0.001659\n",
      "2019-04-09 23:37:48,834 root         INFO     Train Epoch: 16 [3584/8000 (45%)]\tTotal Loss: 0.096354\n",
      "Reconstruction: 0.094276, Regularization: 0.002078\n",
      "2019-04-09 23:37:48,896 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 0.086200\n",
      "Reconstruction: 0.084194, Regularization: 0.002007\n",
      "2019-04-09 23:37:48,958 root         INFO     Train Epoch: 16 [4608/8000 (58%)]\tTotal Loss: 0.083943\n",
      "Reconstruction: 0.081624, Regularization: 0.002319\n",
      "2019-04-09 23:37:49,021 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 0.098004\n",
      "Reconstruction: 0.095178, Regularization: 0.002826\n",
      "2019-04-09 23:37:49,083 root         INFO     Train Epoch: 16 [5632/8000 (70%)]\tTotal Loss: 0.091339\n",
      "Reconstruction: 0.089411, Regularization: 0.001929\n",
      "2019-04-09 23:37:49,145 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 0.085326\n",
      "Reconstruction: 0.083847, Regularization: 0.001479\n",
      "2019-04-09 23:37:49,207 root         INFO     Train Epoch: 16 [6656/8000 (83%)]\tTotal Loss: 0.087535\n",
      "Reconstruction: 0.085155, Regularization: 0.002380\n",
      "2019-04-09 23:37:49,269 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.097732\n",
      "Reconstruction: 0.095559, Regularization: 0.002173\n",
      "2019-04-09 23:37:49,331 root         INFO     Train Epoch: 16 [7680/8000 (96%)]\tTotal Loss: 0.083545\n",
      "Reconstruction: 0.081882, Regularization: 0.001663\n",
      "2019-04-09 23:37:49,385 root         INFO     ====> Epoch: 16 Average loss: 0.0904\n",
      "2019-04-09 23:37:49,409 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.104424\n",
      "Reconstruction: 0.101790, Regularization: 0.002634\n",
      "2019-04-09 23:37:49,471 root         INFO     Train Epoch: 17 [512/8000 (6%)]\tTotal Loss: 0.084002\n",
      "Reconstruction: 0.082454, Regularization: 0.001548\n",
      "2019-04-09 23:37:49,534 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 0.082566\n",
      "Reconstruction: 0.080901, Regularization: 0.001665\n",
      "2019-04-09 23:37:49,596 root         INFO     Train Epoch: 17 [1536/8000 (19%)]\tTotal Loss: 0.088634\n",
      "Reconstruction: 0.086836, Regularization: 0.001798\n",
      "2019-04-09 23:37:49,658 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.092240\n",
      "Reconstruction: 0.089906, Regularization: 0.002334\n",
      "2019-04-09 23:37:49,720 root         INFO     Train Epoch: 17 [2560/8000 (32%)]\tTotal Loss: 0.088683\n",
      "Reconstruction: 0.086826, Regularization: 0.001857\n",
      "2019-04-09 23:37:49,783 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 0.102250\n",
      "Reconstruction: 0.100615, Regularization: 0.001634\n",
      "2019-04-09 23:37:49,845 root         INFO     Train Epoch: 17 [3584/8000 (45%)]\tTotal Loss: 0.086784\n",
      "Reconstruction: 0.085071, Regularization: 0.001714\n",
      "2019-04-09 23:37:49,907 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.094636\n",
      "Reconstruction: 0.092918, Regularization: 0.001719\n",
      "2019-04-09 23:37:49,969 root         INFO     Train Epoch: 17 [4608/8000 (58%)]\tTotal Loss: 0.093575\n",
      "Reconstruction: 0.091809, Regularization: 0.001766\n",
      "2019-04-09 23:37:50,031 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 0.090307\n",
      "Reconstruction: 0.088669, Regularization: 0.001638\n",
      "2019-04-09 23:37:50,092 root         INFO     Train Epoch: 17 [5632/8000 (70%)]\tTotal Loss: 0.085801\n",
      "Reconstruction: 0.083786, Regularization: 0.002015\n",
      "2019-04-09 23:37:50,153 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 0.086008\n",
      "Reconstruction: 0.084672, Regularization: 0.001336\n",
      "2019-04-09 23:37:50,214 root         INFO     Train Epoch: 17 [6656/8000 (83%)]\tTotal Loss: 0.080229\n",
      "Reconstruction: 0.078092, Regularization: 0.002137\n",
      "2019-04-09 23:37:50,274 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 0.087488\n",
      "Reconstruction: 0.086220, Regularization: 0.001268\n",
      "2019-04-09 23:37:50,335 root         INFO     Train Epoch: 17 [7680/8000 (96%)]\tTotal Loss: 0.092599\n",
      "Reconstruction: 0.090839, Regularization: 0.001760\n",
      "2019-04-09 23:37:50,388 root         INFO     ====> Epoch: 17 Average loss: 0.0902\n",
      "2019-04-09 23:37:50,412 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 0.089712\n",
      "Reconstruction: 0.088187, Regularization: 0.001526\n",
      "2019-04-09 23:37:50,475 root         INFO     Train Epoch: 18 [512/8000 (6%)]\tTotal Loss: 0.086897\n",
      "Reconstruction: 0.084906, Regularization: 0.001991\n",
      "2019-04-09 23:37:50,537 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.087293\n",
      "Reconstruction: 0.085951, Regularization: 0.001342\n",
      "2019-04-09 23:37:50,600 root         INFO     Train Epoch: 18 [1536/8000 (19%)]\tTotal Loss: 0.086513\n",
      "Reconstruction: 0.084814, Regularization: 0.001700\n",
      "2019-04-09 23:37:50,662 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 0.105541\n",
      "Reconstruction: 0.102935, Regularization: 0.002606\n",
      "2019-04-09 23:37:50,724 root         INFO     Train Epoch: 18 [2560/8000 (32%)]\tTotal Loss: 0.085509\n",
      "Reconstruction: 0.084358, Regularization: 0.001150\n",
      "2019-04-09 23:37:50,786 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.095135\n",
      "Reconstruction: 0.092946, Regularization: 0.002190\n",
      "2019-04-09 23:37:50,849 root         INFO     Train Epoch: 18 [3584/8000 (45%)]\tTotal Loss: 0.093027\n",
      "Reconstruction: 0.090693, Regularization: 0.002334\n",
      "2019-04-09 23:37:50,911 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 0.094004\n",
      "Reconstruction: 0.092094, Regularization: 0.001911\n",
      "2019-04-09 23:37:50,973 root         INFO     Train Epoch: 18 [4608/8000 (58%)]\tTotal Loss: 0.094973\n",
      "Reconstruction: 0.092769, Regularization: 0.002204\n",
      "2019-04-09 23:37:51,036 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.098732\n",
      "Reconstruction: 0.096882, Regularization: 0.001850\n",
      "2019-04-09 23:37:51,098 root         INFO     Train Epoch: 18 [5632/8000 (70%)]\tTotal Loss: 0.097841\n",
      "Reconstruction: 0.094912, Regularization: 0.002929\n",
      "2019-04-09 23:37:51,161 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 0.092574\n",
      "Reconstruction: 0.090636, Regularization: 0.001938\n",
      "2019-04-09 23:37:51,223 root         INFO     Train Epoch: 18 [6656/8000 (83%)]\tTotal Loss: 0.088363\n",
      "Reconstruction: 0.086401, Regularization: 0.001962\n",
      "2019-04-09 23:37:51,286 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 0.086537\n",
      "Reconstruction: 0.084861, Regularization: 0.001675\n",
      "2019-04-09 23:37:51,349 root         INFO     Train Epoch: 18 [7680/8000 (96%)]\tTotal Loss: 0.085004\n",
      "Reconstruction: 0.083780, Regularization: 0.001224\n",
      "2019-04-09 23:37:51,402 root         INFO     ====> Epoch: 18 Average loss: 0.0900\n",
      "2019-04-09 23:37:51,426 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 0.087936\n",
      "Reconstruction: 0.086056, Regularization: 0.001880\n",
      "2019-04-09 23:37:51,488 root         INFO     Train Epoch: 19 [512/8000 (6%)]\tTotal Loss: 0.088633\n",
      "Reconstruction: 0.087306, Regularization: 0.001327\n",
      "2019-04-09 23:37:51,550 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 0.098611\n",
      "Reconstruction: 0.096764, Regularization: 0.001847\n",
      "2019-04-09 23:37:51,612 root         INFO     Train Epoch: 19 [1536/8000 (19%)]\tTotal Loss: 0.082582\n",
      "Reconstruction: 0.080699, Regularization: 0.001883\n",
      "2019-04-09 23:37:51,674 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 0.097873\n",
      "Reconstruction: 0.095426, Regularization: 0.002448\n",
      "2019-04-09 23:37:51,737 root         INFO     Train Epoch: 19 [2560/8000 (32%)]\tTotal Loss: 0.080968\n",
      "Reconstruction: 0.079683, Regularization: 0.001285\n",
      "2019-04-09 23:37:51,798 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 0.085182\n",
      "Reconstruction: 0.083084, Regularization: 0.002098\n",
      "2019-04-09 23:37:51,860 root         INFO     Train Epoch: 19 [3584/8000 (45%)]\tTotal Loss: 0.084107\n",
      "Reconstruction: 0.083169, Regularization: 0.000938\n",
      "2019-04-09 23:37:51,922 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 0.095831\n",
      "Reconstruction: 0.094822, Regularization: 0.001009\n",
      "2019-04-09 23:37:51,984 root         INFO     Train Epoch: 19 [4608/8000 (58%)]\tTotal Loss: 0.080502\n",
      "Reconstruction: 0.079322, Regularization: 0.001180\n",
      "2019-04-09 23:37:52,046 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 0.083364\n",
      "Reconstruction: 0.081963, Regularization: 0.001401\n",
      "2019-04-09 23:37:52,108 root         INFO     Train Epoch: 19 [5632/8000 (70%)]\tTotal Loss: 0.099758\n",
      "Reconstruction: 0.098427, Regularization: 0.001330\n",
      "2019-04-09 23:37:52,171 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 0.086004\n",
      "Reconstruction: 0.084807, Regularization: 0.001197\n",
      "2019-04-09 23:37:52,233 root         INFO     Train Epoch: 19 [6656/8000 (83%)]\tTotal Loss: 0.086274\n",
      "Reconstruction: 0.085099, Regularization: 0.001175\n",
      "2019-04-09 23:37:52,295 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.095823\n",
      "Reconstruction: 0.094268, Regularization: 0.001555\n",
      "2019-04-09 23:37:52,357 root         INFO     Train Epoch: 19 [7680/8000 (96%)]\tTotal Loss: 0.097962\n",
      "Reconstruction: 0.095852, Regularization: 0.002110\n",
      "2019-04-09 23:37:52,411 root         INFO     ====> Epoch: 19 Average loss: 0.0896\n",
      "2019-04-09 23:37:52,435 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 0.094420\n",
      "Reconstruction: 0.092975, Regularization: 0.001445\n",
      "2019-04-09 23:37:52,497 root         INFO     Train Epoch: 20 [512/8000 (6%)]\tTotal Loss: 0.091774\n",
      "Reconstruction: 0.090328, Regularization: 0.001446\n",
      "2019-04-09 23:37:52,560 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 0.091051\n",
      "Reconstruction: 0.089995, Regularization: 0.001056\n",
      "2019-04-09 23:37:52,622 root         INFO     Train Epoch: 20 [1536/8000 (19%)]\tTotal Loss: 0.103346\n",
      "Reconstruction: 0.101518, Regularization: 0.001829\n",
      "2019-04-09 23:37:52,684 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 0.095584\n",
      "Reconstruction: 0.094460, Regularization: 0.001124\n",
      "2019-04-09 23:37:52,745 root         INFO     Train Epoch: 20 [2560/8000 (32%)]\tTotal Loss: 0.098692\n",
      "Reconstruction: 0.097108, Regularization: 0.001585\n",
      "2019-04-09 23:37:52,807 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 0.092583\n",
      "Reconstruction: 0.090700, Regularization: 0.001883\n",
      "2019-04-09 23:37:52,869 root         INFO     Train Epoch: 20 [3584/8000 (45%)]\tTotal Loss: 0.092099\n",
      "Reconstruction: 0.090776, Regularization: 0.001323\n",
      "2019-04-09 23:37:52,931 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 0.091958\n",
      "Reconstruction: 0.090609, Regularization: 0.001349\n",
      "2019-04-09 23:37:52,994 root         INFO     Train Epoch: 20 [4608/8000 (58%)]\tTotal Loss: 0.085384\n",
      "Reconstruction: 0.084189, Regularization: 0.001194\n",
      "2019-04-09 23:37:53,056 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 0.088888\n",
      "Reconstruction: 0.087548, Regularization: 0.001340\n",
      "2019-04-09 23:37:53,118 root         INFO     Train Epoch: 20 [5632/8000 (70%)]\tTotal Loss: 0.099976\n",
      "Reconstruction: 0.098575, Regularization: 0.001401\n",
      "2019-04-09 23:37:53,180 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 0.097012\n",
      "Reconstruction: 0.095774, Regularization: 0.001237\n",
      "2019-04-09 23:37:53,242 root         INFO     Train Epoch: 20 [6656/8000 (83%)]\tTotal Loss: 0.094927\n",
      "Reconstruction: 0.093225, Regularization: 0.001703\n",
      "2019-04-09 23:37:53,304 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 0.093128\n",
      "Reconstruction: 0.091516, Regularization: 0.001613\n",
      "2019-04-09 23:37:53,367 root         INFO     Train Epoch: 20 [7680/8000 (96%)]\tTotal Loss: 0.096324\n",
      "Reconstruction: 0.095276, Regularization: 0.001048\n",
      "2019-04-09 23:37:53,420 root         INFO     ====> Epoch: 20 Average loss: 0.0893\n",
      "2019-04-09 23:37:53,444 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.085141\n",
      "Reconstruction: 0.083630, Regularization: 0.001512\n",
      "2019-04-09 23:37:53,506 root         INFO     Train Epoch: 21 [512/8000 (6%)]\tTotal Loss: 0.086995\n",
      "Reconstruction: 0.085462, Regularization: 0.001533\n",
      "2019-04-09 23:37:53,568 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 0.090502\n",
      "Reconstruction: 0.088752, Regularization: 0.001750\n",
      "2019-04-09 23:37:53,631 root         INFO     Train Epoch: 21 [1536/8000 (19%)]\tTotal Loss: 0.092060\n",
      "Reconstruction: 0.090788, Regularization: 0.001273\n",
      "2019-04-09 23:37:53,693 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 0.086571\n",
      "Reconstruction: 0.085402, Regularization: 0.001169\n",
      "2019-04-09 23:37:53,756 root         INFO     Train Epoch: 21 [2560/8000 (32%)]\tTotal Loss: 0.086701\n",
      "Reconstruction: 0.085900, Regularization: 0.000801\n",
      "2019-04-09 23:37:53,818 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 0.087530\n",
      "Reconstruction: 0.086580, Regularization: 0.000950\n",
      "2019-04-09 23:37:53,880 root         INFO     Train Epoch: 21 [3584/8000 (45%)]\tTotal Loss: 0.090765\n",
      "Reconstruction: 0.089198, Regularization: 0.001567\n",
      "2019-04-09 23:37:53,942 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.093637\n",
      "Reconstruction: 0.092955, Regularization: 0.000683\n",
      "2019-04-09 23:37:54,004 root         INFO     Train Epoch: 21 [4608/8000 (58%)]\tTotal Loss: 0.099359\n",
      "Reconstruction: 0.097729, Regularization: 0.001630\n",
      "2019-04-09 23:37:54,064 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 0.093583\n",
      "Reconstruction: 0.092170, Regularization: 0.001413\n",
      "2019-04-09 23:37:54,125 root         INFO     Train Epoch: 21 [5632/8000 (70%)]\tTotal Loss: 0.103603\n",
      "Reconstruction: 0.101648, Regularization: 0.001955\n",
      "2019-04-09 23:37:54,186 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 0.083076\n",
      "Reconstruction: 0.082090, Regularization: 0.000986\n",
      "2019-04-09 23:37:54,247 root         INFO     Train Epoch: 21 [6656/8000 (83%)]\tTotal Loss: 0.090041\n",
      "Reconstruction: 0.088569, Regularization: 0.001472\n",
      "2019-04-09 23:37:54,308 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.094569\n",
      "Reconstruction: 0.093703, Regularization: 0.000866\n",
      "2019-04-09 23:37:54,369 root         INFO     Train Epoch: 21 [7680/8000 (96%)]\tTotal Loss: 0.084750\n",
      "Reconstruction: 0.083777, Regularization: 0.000973\n",
      "2019-04-09 23:37:54,422 root         INFO     ====> Epoch: 21 Average loss: 0.0893\n",
      "2019-04-09 23:37:54,446 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 0.088227\n",
      "Reconstruction: 0.086810, Regularization: 0.001416\n",
      "2019-04-09 23:37:54,508 root         INFO     Train Epoch: 22 [512/8000 (6%)]\tTotal Loss: 0.088516\n",
      "Reconstruction: 0.087121, Regularization: 0.001395\n",
      "2019-04-09 23:37:54,570 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 0.089006\n",
      "Reconstruction: 0.088031, Regularization: 0.000975\n",
      "2019-04-09 23:37:54,633 root         INFO     Train Epoch: 22 [1536/8000 (19%)]\tTotal Loss: 0.086369\n",
      "Reconstruction: 0.085125, Regularization: 0.001244\n",
      "2019-04-09 23:37:54,695 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 0.088418\n",
      "Reconstruction: 0.087284, Regularization: 0.001134\n",
      "2019-04-09 23:37:54,757 root         INFO     Train Epoch: 22 [2560/8000 (32%)]\tTotal Loss: 0.087827\n",
      "Reconstruction: 0.086681, Regularization: 0.001146\n",
      "2019-04-09 23:37:54,819 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 0.087068\n",
      "Reconstruction: 0.086177, Regularization: 0.000891\n",
      "2019-04-09 23:37:54,881 root         INFO     Train Epoch: 22 [3584/8000 (45%)]\tTotal Loss: 0.090178\n",
      "Reconstruction: 0.088964, Regularization: 0.001214\n",
      "2019-04-09 23:37:54,943 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.088168\n",
      "Reconstruction: 0.086914, Regularization: 0.001253\n",
      "2019-04-09 23:37:55,005 root         INFO     Train Epoch: 22 [4608/8000 (58%)]\tTotal Loss: 0.082237\n",
      "Reconstruction: 0.080967, Regularization: 0.001270\n",
      "2019-04-09 23:37:55,067 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 0.094555\n",
      "Reconstruction: 0.093196, Regularization: 0.001359\n",
      "2019-04-09 23:37:55,130 root         INFO     Train Epoch: 22 [5632/8000 (70%)]\tTotal Loss: 0.092044\n",
      "Reconstruction: 0.090958, Regularization: 0.001086\n",
      "2019-04-09 23:37:55,192 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 0.086745\n",
      "Reconstruction: 0.085520, Regularization: 0.001225\n",
      "2019-04-09 23:37:55,254 root         INFO     Train Epoch: 22 [6656/8000 (83%)]\tTotal Loss: 0.083617\n",
      "Reconstruction: 0.082837, Regularization: 0.000780\n",
      "2019-04-09 23:37:55,315 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 0.089691\n",
      "Reconstruction: 0.088722, Regularization: 0.000969\n",
      "2019-04-09 23:37:55,377 root         INFO     Train Epoch: 22 [7680/8000 (96%)]\tTotal Loss: 0.083169\n",
      "Reconstruction: 0.082184, Regularization: 0.000985\n",
      "2019-04-09 23:37:55,430 root         INFO     ====> Epoch: 22 Average loss: 0.0893\n",
      "2019-04-09 23:37:55,454 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 0.080919\n",
      "Reconstruction: 0.080189, Regularization: 0.000730\n",
      "2019-04-09 23:37:55,516 root         INFO     Train Epoch: 23 [512/8000 (6%)]\tTotal Loss: 0.092401\n",
      "Reconstruction: 0.091056, Regularization: 0.001344\n",
      "2019-04-09 23:37:55,578 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 0.087452\n",
      "Reconstruction: 0.086413, Regularization: 0.001039\n",
      "2019-04-09 23:37:55,640 root         INFO     Train Epoch: 23 [1536/8000 (19%)]\tTotal Loss: 0.080261\n",
      "Reconstruction: 0.079160, Regularization: 0.001101\n",
      "2019-04-09 23:37:55,701 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 0.086380\n",
      "Reconstruction: 0.085728, Regularization: 0.000651\n",
      "2019-04-09 23:37:55,762 root         INFO     Train Epoch: 23 [2560/8000 (32%)]\tTotal Loss: 0.087635\n",
      "Reconstruction: 0.086957, Regularization: 0.000677\n",
      "2019-04-09 23:37:55,823 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 0.082682\n",
      "Reconstruction: 0.081795, Regularization: 0.000887\n",
      "2019-04-09 23:37:55,886 root         INFO     Train Epoch: 23 [3584/8000 (45%)]\tTotal Loss: 0.088470\n",
      "Reconstruction: 0.087599, Regularization: 0.000872\n",
      "2019-04-09 23:37:55,948 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 0.088451\n",
      "Reconstruction: 0.087578, Regularization: 0.000874\n",
      "2019-04-09 23:37:56,010 root         INFO     Train Epoch: 23 [4608/8000 (58%)]\tTotal Loss: 0.083806\n",
      "Reconstruction: 0.083007, Regularization: 0.000799\n",
      "2019-04-09 23:37:56,072 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 0.079170\n",
      "Reconstruction: 0.078505, Regularization: 0.000666\n",
      "2019-04-09 23:37:56,133 root         INFO     Train Epoch: 23 [5632/8000 (70%)]\tTotal Loss: 0.081906\n",
      "Reconstruction: 0.081000, Regularization: 0.000906\n",
      "2019-04-09 23:37:56,194 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 0.087131\n",
      "Reconstruction: 0.085838, Regularization: 0.001293\n",
      "2019-04-09 23:37:56,259 root         INFO     Train Epoch: 23 [6656/8000 (83%)]\tTotal Loss: 0.075689\n",
      "Reconstruction: 0.075021, Regularization: 0.000668\n",
      "2019-04-09 23:37:56,324 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 0.088574\n",
      "Reconstruction: 0.087754, Regularization: 0.000819\n",
      "2019-04-09 23:37:56,388 root         INFO     Train Epoch: 23 [7680/8000 (96%)]\tTotal Loss: 0.088493\n",
      "Reconstruction: 0.087441, Regularization: 0.001052\n",
      "2019-04-09 23:37:56,442 root         INFO     ====> Epoch: 23 Average loss: 0.0892\n",
      "2019-04-09 23:37:56,466 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.087222\n",
      "Reconstruction: 0.086375, Regularization: 0.000847\n",
      "2019-04-09 23:37:56,530 root         INFO     Train Epoch: 24 [512/8000 (6%)]\tTotal Loss: 0.097832\n",
      "Reconstruction: 0.096540, Regularization: 0.001291\n",
      "2019-04-09 23:37:56,594 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 0.078767\n",
      "Reconstruction: 0.078219, Regularization: 0.000548\n",
      "2019-04-09 23:37:56,658 root         INFO     Train Epoch: 24 [1536/8000 (19%)]\tTotal Loss: 0.102569\n",
      "Reconstruction: 0.101093, Regularization: 0.001477\n",
      "2019-04-09 23:37:56,722 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 0.083357\n",
      "Reconstruction: 0.082333, Regularization: 0.001024\n",
      "2019-04-09 23:37:56,786 root         INFO     Train Epoch: 24 [2560/8000 (32%)]\tTotal Loss: 0.092096\n",
      "Reconstruction: 0.090940, Regularization: 0.001156\n",
      "2019-04-09 23:37:56,848 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 0.088983\n",
      "Reconstruction: 0.087385, Regularization: 0.001598\n",
      "2019-04-09 23:37:56,910 root         INFO     Train Epoch: 24 [3584/8000 (45%)]\tTotal Loss: 0.074195\n",
      "Reconstruction: 0.073478, Regularization: 0.000716\n",
      "2019-04-09 23:37:56,972 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 0.083088\n",
      "Reconstruction: 0.082093, Regularization: 0.000995\n",
      "2019-04-09 23:37:57,035 root         INFO     Train Epoch: 24 [4608/8000 (58%)]\tTotal Loss: 0.085392\n",
      "Reconstruction: 0.084513, Regularization: 0.000879\n",
      "2019-04-09 23:37:57,098 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 0.084099\n",
      "Reconstruction: 0.083164, Regularization: 0.000935\n",
      "2019-04-09 23:37:57,161 root         INFO     Train Epoch: 24 [5632/8000 (70%)]\tTotal Loss: 0.098513\n",
      "Reconstruction: 0.097591, Regularization: 0.000922\n",
      "2019-04-09 23:37:57,223 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 0.089000\n",
      "Reconstruction: 0.088046, Regularization: 0.000954\n",
      "2019-04-09 23:37:57,286 root         INFO     Train Epoch: 24 [6656/8000 (83%)]\tTotal Loss: 0.083595\n",
      "Reconstruction: 0.082761, Regularization: 0.000834\n",
      "2019-04-09 23:37:57,348 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 0.092106\n",
      "Reconstruction: 0.091032, Regularization: 0.001073\n",
      "2019-04-09 23:37:57,411 root         INFO     Train Epoch: 24 [7680/8000 (96%)]\tTotal Loss: 0.087779\n",
      "Reconstruction: 0.086641, Regularization: 0.001137\n",
      "2019-04-09 23:37:57,464 root         INFO     ====> Epoch: 24 Average loss: 0.0890\n",
      "2019-04-09 23:37:57,488 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 0.090518\n",
      "Reconstruction: 0.089670, Regularization: 0.000848\n",
      "2019-04-09 23:37:57,550 root         INFO     Train Epoch: 25 [512/8000 (6%)]\tTotal Loss: 0.102471\n",
      "Reconstruction: 0.101305, Regularization: 0.001165\n",
      "2019-04-09 23:37:57,610 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 0.090975\n",
      "Reconstruction: 0.090316, Regularization: 0.000659\n",
      "2019-04-09 23:37:57,671 root         INFO     Train Epoch: 25 [1536/8000 (19%)]\tTotal Loss: 0.086540\n",
      "Reconstruction: 0.085807, Regularization: 0.000733\n",
      "2019-04-09 23:37:57,732 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 0.089568\n",
      "Reconstruction: 0.088666, Regularization: 0.000902\n",
      "2019-04-09 23:37:57,793 root         INFO     Train Epoch: 25 [2560/8000 (32%)]\tTotal Loss: 0.088985\n",
      "Reconstruction: 0.088144, Regularization: 0.000841\n",
      "2019-04-09 23:37:57,854 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 0.092287\n",
      "Reconstruction: 0.091312, Regularization: 0.000976\n",
      "2019-04-09 23:37:57,915 root         INFO     Train Epoch: 25 [3584/8000 (45%)]\tTotal Loss: 0.089202\n",
      "Reconstruction: 0.088284, Regularization: 0.000918\n",
      "2019-04-09 23:37:57,976 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 0.087891\n",
      "Reconstruction: 0.086887, Regularization: 0.001003\n",
      "2019-04-09 23:37:58,037 root         INFO     Train Epoch: 25 [4608/8000 (58%)]\tTotal Loss: 0.087793\n",
      "Reconstruction: 0.086967, Regularization: 0.000826\n",
      "2019-04-09 23:37:58,098 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 0.089005\n",
      "Reconstruction: 0.088211, Regularization: 0.000794\n",
      "2019-04-09 23:37:58,158 root         INFO     Train Epoch: 25 [5632/8000 (70%)]\tTotal Loss: 0.084504\n",
      "Reconstruction: 0.083855, Regularization: 0.000650\n",
      "2019-04-09 23:37:58,220 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.088093\n",
      "Reconstruction: 0.087053, Regularization: 0.001040\n",
      "2019-04-09 23:37:58,280 root         INFO     Train Epoch: 25 [6656/8000 (83%)]\tTotal Loss: 0.094112\n",
      "Reconstruction: 0.093172, Regularization: 0.000940\n",
      "2019-04-09 23:37:58,341 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 0.085150\n",
      "Reconstruction: 0.084469, Regularization: 0.000681\n",
      "2019-04-09 23:37:58,402 root         INFO     Train Epoch: 25 [7680/8000 (96%)]\tTotal Loss: 0.083621\n",
      "Reconstruction: 0.082828, Regularization: 0.000793\n",
      "2019-04-09 23:37:58,455 root         INFO     ====> Epoch: 25 Average loss: 0.0889\n",
      "2019-04-09 23:37:58,478 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 0.082227\n",
      "Reconstruction: 0.081236, Regularization: 0.000991\n",
      "2019-04-09 23:37:58,542 root         INFO     Train Epoch: 26 [512/8000 (6%)]\tTotal Loss: 0.090154\n",
      "Reconstruction: 0.089403, Regularization: 0.000750\n",
      "2019-04-09 23:37:58,605 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 0.088255\n",
      "Reconstruction: 0.087395, Regularization: 0.000860\n",
      "2019-04-09 23:37:58,667 root         INFO     Train Epoch: 26 [1536/8000 (19%)]\tTotal Loss: 0.083489\n",
      "Reconstruction: 0.082655, Regularization: 0.000835\n",
      "2019-04-09 23:37:58,730 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 0.105463\n",
      "Reconstruction: 0.103695, Regularization: 0.001768\n",
      "2019-04-09 23:37:58,793 root         INFO     Train Epoch: 26 [2560/8000 (32%)]\tTotal Loss: 0.083112\n",
      "Reconstruction: 0.082436, Regularization: 0.000676\n",
      "2019-04-09 23:37:58,856 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 0.089247\n",
      "Reconstruction: 0.088156, Regularization: 0.001091\n",
      "2019-04-09 23:37:58,919 root         INFO     Train Epoch: 26 [3584/8000 (45%)]\tTotal Loss: 0.093365\n",
      "Reconstruction: 0.092820, Regularization: 0.000546\n",
      "2019-04-09 23:37:58,983 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.089521\n",
      "Reconstruction: 0.088485, Regularization: 0.001036\n",
      "2019-04-09 23:37:59,046 root         INFO     Train Epoch: 26 [4608/8000 (58%)]\tTotal Loss: 0.091136\n",
      "Reconstruction: 0.090108, Regularization: 0.001028\n",
      "2019-04-09 23:37:59,109 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 0.093121\n",
      "Reconstruction: 0.092521, Regularization: 0.000600\n",
      "2019-04-09 23:37:59,172 root         INFO     Train Epoch: 26 [5632/8000 (70%)]\tTotal Loss: 0.083015\n",
      "Reconstruction: 0.082229, Regularization: 0.000786\n",
      "2019-04-09 23:37:59,234 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 0.090813\n",
      "Reconstruction: 0.089728, Regularization: 0.001085\n",
      "2019-04-09 23:37:59,296 root         INFO     Train Epoch: 26 [6656/8000 (83%)]\tTotal Loss: 0.089283\n",
      "Reconstruction: 0.088258, Regularization: 0.001025\n",
      "2019-04-09 23:37:59,358 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 0.086965\n",
      "Reconstruction: 0.086309, Regularization: 0.000656\n",
      "2019-04-09 23:37:59,421 root         INFO     Train Epoch: 26 [7680/8000 (96%)]\tTotal Loss: 0.088784\n",
      "Reconstruction: 0.087823, Regularization: 0.000961\n",
      "2019-04-09 23:37:59,475 root         INFO     ====> Epoch: 26 Average loss: 0.0890\n",
      "2019-04-09 23:37:59,499 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 0.091560\n",
      "Reconstruction: 0.090325, Regularization: 0.001235\n",
      "2019-04-09 23:37:59,562 root         INFO     Train Epoch: 27 [512/8000 (6%)]\tTotal Loss: 0.088026\n",
      "Reconstruction: 0.087390, Regularization: 0.000636\n",
      "2019-04-09 23:37:59,625 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.092695\n",
      "Reconstruction: 0.091489, Regularization: 0.001206\n",
      "2019-04-09 23:37:59,688 root         INFO     Train Epoch: 27 [1536/8000 (19%)]\tTotal Loss: 0.081588\n",
      "Reconstruction: 0.080954, Regularization: 0.000634\n",
      "2019-04-09 23:37:59,751 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 0.089313\n",
      "Reconstruction: 0.088557, Regularization: 0.000755\n",
      "2019-04-09 23:37:59,814 root         INFO     Train Epoch: 27 [2560/8000 (32%)]\tTotal Loss: 0.084722\n",
      "Reconstruction: 0.083915, Regularization: 0.000807\n",
      "2019-04-09 23:37:59,877 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.097374\n",
      "Reconstruction: 0.096737, Regularization: 0.000637\n",
      "2019-04-09 23:37:59,941 root         INFO     Train Epoch: 27 [3584/8000 (45%)]\tTotal Loss: 0.095379\n",
      "Reconstruction: 0.094327, Regularization: 0.001052\n",
      "2019-04-09 23:38:00,002 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 0.087256\n",
      "Reconstruction: 0.086554, Regularization: 0.000702\n",
      "2019-04-09 23:38:00,065 root         INFO     Train Epoch: 27 [4608/8000 (58%)]\tTotal Loss: 0.088949\n",
      "Reconstruction: 0.088160, Regularization: 0.000790\n",
      "2019-04-09 23:38:00,127 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.082742\n",
      "Reconstruction: 0.082186, Regularization: 0.000556\n",
      "2019-04-09 23:38:00,189 root         INFO     Train Epoch: 27 [5632/8000 (70%)]\tTotal Loss: 0.083192\n",
      "Reconstruction: 0.082617, Regularization: 0.000575\n",
      "2019-04-09 23:38:00,252 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.085143\n",
      "Reconstruction: 0.084470, Regularization: 0.000673\n",
      "2019-04-09 23:38:00,314 root         INFO     Train Epoch: 27 [6656/8000 (83%)]\tTotal Loss: 0.098283\n",
      "Reconstruction: 0.097234, Regularization: 0.001048\n",
      "2019-04-09 23:38:00,378 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 0.085352\n",
      "Reconstruction: 0.084870, Regularization: 0.000481\n",
      "2019-04-09 23:38:00,440 root         INFO     Train Epoch: 27 [7680/8000 (96%)]\tTotal Loss: 0.092396\n",
      "Reconstruction: 0.091558, Regularization: 0.000839\n",
      "2019-04-09 23:38:00,494 root         INFO     ====> Epoch: 27 Average loss: 0.0890\n",
      "2019-04-09 23:38:00,517 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.074138\n",
      "Reconstruction: 0.073688, Regularization: 0.000450\n",
      "2019-04-09 23:38:00,581 root         INFO     Train Epoch: 28 [512/8000 (6%)]\tTotal Loss: 0.090069\n",
      "Reconstruction: 0.089341, Regularization: 0.000728\n",
      "2019-04-09 23:38:00,644 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.091829\n",
      "Reconstruction: 0.091072, Regularization: 0.000757\n",
      "2019-04-09 23:38:00,707 root         INFO     Train Epoch: 28 [1536/8000 (19%)]\tTotal Loss: 0.081610\n",
      "Reconstruction: 0.080978, Regularization: 0.000632\n",
      "2019-04-09 23:38:00,770 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 0.092731\n",
      "Reconstruction: 0.091712, Regularization: 0.001019\n",
      "2019-04-09 23:38:00,833 root         INFO     Train Epoch: 28 [2560/8000 (32%)]\tTotal Loss: 0.095730\n",
      "Reconstruction: 0.094899, Regularization: 0.000832\n",
      "2019-04-09 23:38:00,896 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.089642\n",
      "Reconstruction: 0.088624, Regularization: 0.001018\n",
      "2019-04-09 23:38:00,959 root         INFO     Train Epoch: 28 [3584/8000 (45%)]\tTotal Loss: 0.088465\n",
      "Reconstruction: 0.087801, Regularization: 0.000664\n",
      "2019-04-09 23:38:01,022 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.097767\n",
      "Reconstruction: 0.097232, Regularization: 0.000535\n",
      "2019-04-09 23:38:01,085 root         INFO     Train Epoch: 28 [4608/8000 (58%)]\tTotal Loss: 0.092604\n",
      "Reconstruction: 0.091668, Regularization: 0.000936\n",
      "2019-04-09 23:38:01,148 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.094092\n",
      "Reconstruction: 0.093472, Regularization: 0.000620\n",
      "2019-04-09 23:38:01,212 root         INFO     Train Epoch: 28 [5632/8000 (70%)]\tTotal Loss: 0.090959\n",
      "Reconstruction: 0.090138, Regularization: 0.000821\n",
      "2019-04-09 23:38:01,274 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.087077\n",
      "Reconstruction: 0.086261, Regularization: 0.000816\n",
      "2019-04-09 23:38:01,337 root         INFO     Train Epoch: 28 [6656/8000 (83%)]\tTotal Loss: 0.087942\n",
      "Reconstruction: 0.087368, Regularization: 0.000574\n",
      "2019-04-09 23:38:01,400 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.085369\n",
      "Reconstruction: 0.084751, Regularization: 0.000618\n",
      "2019-04-09 23:38:01,464 root         INFO     Train Epoch: 28 [7680/8000 (96%)]\tTotal Loss: 0.081855\n",
      "Reconstruction: 0.081317, Regularization: 0.000538\n",
      "2019-04-09 23:38:01,517 root         INFO     ====> Epoch: 28 Average loss: 0.0889\n",
      "2019-04-09 23:38:01,541 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 0.093345\n",
      "Reconstruction: 0.092546, Regularization: 0.000799\n",
      "2019-04-09 23:38:01,606 root         INFO     Train Epoch: 29 [512/8000 (6%)]\tTotal Loss: 0.087343\n",
      "Reconstruction: 0.086593, Regularization: 0.000749\n",
      "2019-04-09 23:38:01,671 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 0.089860\n",
      "Reconstruction: 0.089203, Regularization: 0.000658\n",
      "2019-04-09 23:38:01,735 root         INFO     Train Epoch: 29 [1536/8000 (19%)]\tTotal Loss: 0.080594\n",
      "Reconstruction: 0.079969, Regularization: 0.000625\n",
      "2019-04-09 23:38:01,799 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 0.086296\n",
      "Reconstruction: 0.085701, Regularization: 0.000595\n",
      "2019-04-09 23:38:01,863 root         INFO     Train Epoch: 29 [2560/8000 (32%)]\tTotal Loss: 0.086037\n",
      "Reconstruction: 0.085364, Regularization: 0.000673\n",
      "2019-04-09 23:38:01,927 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 0.077336\n",
      "Reconstruction: 0.076961, Regularization: 0.000375\n",
      "2019-04-09 23:38:01,991 root         INFO     Train Epoch: 29 [3584/8000 (45%)]\tTotal Loss: 0.089852\n",
      "Reconstruction: 0.089247, Regularization: 0.000606\n",
      "2019-04-09 23:38:02,055 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.097240\n",
      "Reconstruction: 0.096577, Regularization: 0.000664\n",
      "2019-04-09 23:38:02,119 root         INFO     Train Epoch: 29 [4608/8000 (58%)]\tTotal Loss: 0.085178\n",
      "Reconstruction: 0.084359, Regularization: 0.000819\n",
      "2019-04-09 23:38:02,182 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 0.082033\n",
      "Reconstruction: 0.081357, Regularization: 0.000676\n",
      "2019-04-09 23:38:02,247 root         INFO     Train Epoch: 29 [5632/8000 (70%)]\tTotal Loss: 0.083713\n",
      "Reconstruction: 0.083191, Regularization: 0.000522\n",
      "2019-04-09 23:38:02,310 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 0.084433\n",
      "Reconstruction: 0.083760, Regularization: 0.000673\n",
      "2019-04-09 23:38:02,374 root         INFO     Train Epoch: 29 [6656/8000 (83%)]\tTotal Loss: 0.083874\n",
      "Reconstruction: 0.083394, Regularization: 0.000480\n",
      "2019-04-09 23:38:02,437 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.088846\n",
      "Reconstruction: 0.088001, Regularization: 0.000844\n",
      "2019-04-09 23:38:02,501 root         INFO     Train Epoch: 29 [7680/8000 (96%)]\tTotal Loss: 0.080265\n",
      "Reconstruction: 0.079755, Regularization: 0.000510\n",
      "2019-04-09 23:38:02,554 root         INFO     ====> Epoch: 29 Average loss: 0.0889\n",
      "2019-04-09 23:38:02,578 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.092656\n",
      "Reconstruction: 0.092091, Regularization: 0.000565\n",
      "2019-04-09 23:38:02,642 root         INFO     Train Epoch: 30 [512/8000 (6%)]\tTotal Loss: 0.089589\n",
      "Reconstruction: 0.088832, Regularization: 0.000757\n",
      "2019-04-09 23:38:02,705 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.091025\n",
      "Reconstruction: 0.090355, Regularization: 0.000670\n",
      "2019-04-09 23:38:02,768 root         INFO     Train Epoch: 30 [1536/8000 (19%)]\tTotal Loss: 0.094540\n",
      "Reconstruction: 0.094004, Regularization: 0.000536\n",
      "2019-04-09 23:38:02,830 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.092253\n",
      "Reconstruction: 0.091522, Regularization: 0.000731\n",
      "2019-04-09 23:38:02,891 root         INFO     Train Epoch: 30 [2560/8000 (32%)]\tTotal Loss: 0.097385\n",
      "Reconstruction: 0.096588, Regularization: 0.000797\n",
      "2019-04-09 23:38:02,951 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.095027\n",
      "Reconstruction: 0.094169, Regularization: 0.000858\n",
      "2019-04-09 23:38:03,013 root         INFO     Train Epoch: 30 [3584/8000 (45%)]\tTotal Loss: 0.088598\n",
      "Reconstruction: 0.087879, Regularization: 0.000718\n",
      "2019-04-09 23:38:03,074 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.080903\n",
      "Reconstruction: 0.080573, Regularization: 0.000330\n",
      "2019-04-09 23:38:03,135 root         INFO     Train Epoch: 30 [4608/8000 (58%)]\tTotal Loss: 0.083018\n",
      "Reconstruction: 0.082585, Regularization: 0.000433\n",
      "2019-04-09 23:38:03,197 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.081257\n",
      "Reconstruction: 0.080863, Regularization: 0.000394\n",
      "2019-04-09 23:38:03,258 root         INFO     Train Epoch: 30 [5632/8000 (70%)]\tTotal Loss: 0.088664\n",
      "Reconstruction: 0.087775, Regularization: 0.000888\n",
      "2019-04-09 23:38:03,319 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.095516\n",
      "Reconstruction: 0.094734, Regularization: 0.000782\n",
      "2019-04-09 23:38:03,381 root         INFO     Train Epoch: 30 [6656/8000 (83%)]\tTotal Loss: 0.090824\n",
      "Reconstruction: 0.090435, Regularization: 0.000389\n",
      "2019-04-09 23:38:03,443 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 0.088972\n",
      "Reconstruction: 0.088442, Regularization: 0.000530\n",
      "2019-04-09 23:38:03,506 root         INFO     Train Epoch: 30 [7680/8000 (96%)]\tTotal Loss: 0.089845\n",
      "Reconstruction: 0.089242, Regularization: 0.000603\n",
      "2019-04-09 23:38:03,561 root         INFO     ====> Epoch: 30 Average loss: 0.0888\n",
      "2019-04-09 23:38:03,584 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.084541\n",
      "Reconstruction: 0.084051, Regularization: 0.000489\n",
      "2019-04-09 23:38:03,646 root         INFO     Train Epoch: 31 [512/8000 (6%)]\tTotal Loss: 0.080966\n",
      "Reconstruction: 0.080386, Regularization: 0.000580\n",
      "2019-04-09 23:38:03,708 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.086320\n",
      "Reconstruction: 0.085750, Regularization: 0.000570\n",
      "2019-04-09 23:38:03,769 root         INFO     Train Epoch: 31 [1536/8000 (19%)]\tTotal Loss: 0.085136\n",
      "Reconstruction: 0.084650, Regularization: 0.000486\n",
      "2019-04-09 23:38:03,831 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 0.092686\n",
      "Reconstruction: 0.092128, Regularization: 0.000558\n",
      "2019-04-09 23:38:03,892 root         INFO     Train Epoch: 31 [2560/8000 (32%)]\tTotal Loss: 0.081229\n",
      "Reconstruction: 0.080706, Regularization: 0.000523\n",
      "2019-04-09 23:38:03,954 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.090037\n",
      "Reconstruction: 0.089341, Regularization: 0.000696\n",
      "2019-04-09 23:38:04,015 root         INFO     Train Epoch: 31 [3584/8000 (45%)]\tTotal Loss: 0.094677\n",
      "Reconstruction: 0.094247, Regularization: 0.000430\n",
      "2019-04-09 23:38:04,076 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.089368\n",
      "Reconstruction: 0.088898, Regularization: 0.000470\n",
      "2019-04-09 23:38:04,138 root         INFO     Train Epoch: 31 [4608/8000 (58%)]\tTotal Loss: 0.087836\n",
      "Reconstruction: 0.087410, Regularization: 0.000425\n",
      "2019-04-09 23:38:04,199 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.087188\n",
      "Reconstruction: 0.086722, Regularization: 0.000466\n",
      "2019-04-09 23:38:04,261 root         INFO     Train Epoch: 31 [5632/8000 (70%)]\tTotal Loss: 0.111747\n",
      "Reconstruction: 0.111382, Regularization: 0.000366\n",
      "2019-04-09 23:38:04,322 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 0.084242\n",
      "Reconstruction: 0.083629, Regularization: 0.000612\n",
      "2019-04-09 23:38:04,384 root         INFO     Train Epoch: 31 [6656/8000 (83%)]\tTotal Loss: 0.089586\n",
      "Reconstruction: 0.089049, Regularization: 0.000537\n",
      "2019-04-09 23:38:04,446 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 0.095670\n",
      "Reconstruction: 0.095097, Regularization: 0.000573\n",
      "2019-04-09 23:38:04,508 root         INFO     Train Epoch: 31 [7680/8000 (96%)]\tTotal Loss: 0.079784\n",
      "Reconstruction: 0.079424, Regularization: 0.000360\n",
      "2019-04-09 23:38:04,560 root         INFO     ====> Epoch: 31 Average loss: 0.0888\n",
      "2019-04-09 23:38:04,584 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.095706\n",
      "Reconstruction: 0.095231, Regularization: 0.000476\n",
      "2019-04-09 23:38:04,647 root         INFO     Train Epoch: 32 [512/8000 (6%)]\tTotal Loss: 0.086707\n",
      "Reconstruction: 0.086251, Regularization: 0.000456\n",
      "2019-04-09 23:38:04,709 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.084510\n",
      "Reconstruction: 0.084112, Regularization: 0.000398\n",
      "2019-04-09 23:38:04,772 root         INFO     Train Epoch: 32 [1536/8000 (19%)]\tTotal Loss: 0.091866\n",
      "Reconstruction: 0.091379, Regularization: 0.000487\n",
      "2019-04-09 23:38:04,834 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.085557\n",
      "Reconstruction: 0.084976, Regularization: 0.000581\n",
      "2019-04-09 23:38:04,896 root         INFO     Train Epoch: 32 [2560/8000 (32%)]\tTotal Loss: 0.089648\n",
      "Reconstruction: 0.089130, Regularization: 0.000517\n",
      "2019-04-09 23:38:04,958 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.086137\n",
      "Reconstruction: 0.085571, Regularization: 0.000566\n",
      "2019-04-09 23:38:05,020 root         INFO     Train Epoch: 32 [3584/8000 (45%)]\tTotal Loss: 0.082792\n",
      "Reconstruction: 0.082331, Regularization: 0.000461\n",
      "2019-04-09 23:38:05,082 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.086088\n",
      "Reconstruction: 0.085595, Regularization: 0.000492\n",
      "2019-04-09 23:38:05,144 root         INFO     Train Epoch: 32 [4608/8000 (58%)]\tTotal Loss: 0.086458\n",
      "Reconstruction: 0.086006, Regularization: 0.000452\n",
      "2019-04-09 23:38:05,206 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 0.079740\n",
      "Reconstruction: 0.079299, Regularization: 0.000441\n",
      "2019-04-09 23:38:05,269 root         INFO     Train Epoch: 32 [5632/8000 (70%)]\tTotal Loss: 0.099472\n",
      "Reconstruction: 0.098970, Regularization: 0.000502\n",
      "2019-04-09 23:38:05,330 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.092645\n",
      "Reconstruction: 0.091879, Regularization: 0.000766\n",
      "2019-04-09 23:38:05,393 root         INFO     Train Epoch: 32 [6656/8000 (83%)]\tTotal Loss: 0.093715\n",
      "Reconstruction: 0.093145, Regularization: 0.000570\n",
      "2019-04-09 23:38:05,455 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.088927\n",
      "Reconstruction: 0.088263, Regularization: 0.000664\n",
      "2019-04-09 23:38:05,516 root         INFO     Train Epoch: 32 [7680/8000 (96%)]\tTotal Loss: 0.088477\n",
      "Reconstruction: 0.088043, Regularization: 0.000434\n",
      "2019-04-09 23:38:05,569 root         INFO     ====> Epoch: 32 Average loss: 0.0889\n",
      "2019-04-09 23:38:05,593 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.083828\n",
      "Reconstruction: 0.083376, Regularization: 0.000451\n",
      "2019-04-09 23:38:05,655 root         INFO     Train Epoch: 33 [512/8000 (6%)]\tTotal Loss: 0.094682\n",
      "Reconstruction: 0.094135, Regularization: 0.000547\n",
      "2019-04-09 23:38:05,716 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.083115\n",
      "Reconstruction: 0.082680, Regularization: 0.000435\n",
      "2019-04-09 23:38:05,778 root         INFO     Train Epoch: 33 [1536/8000 (19%)]\tTotal Loss: 0.089573\n",
      "Reconstruction: 0.089009, Regularization: 0.000563\n",
      "2019-04-09 23:38:05,841 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.092627\n",
      "Reconstruction: 0.092257, Regularization: 0.000370\n",
      "2019-04-09 23:38:05,904 root         INFO     Train Epoch: 33 [2560/8000 (32%)]\tTotal Loss: 0.099482\n",
      "Reconstruction: 0.098740, Regularization: 0.000743\n",
      "2019-04-09 23:38:05,967 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.081568\n",
      "Reconstruction: 0.081138, Regularization: 0.000430\n",
      "2019-04-09 23:38:06,030 root         INFO     Train Epoch: 33 [3584/8000 (45%)]\tTotal Loss: 0.093075\n",
      "Reconstruction: 0.092473, Regularization: 0.000601\n",
      "2019-04-09 23:38:06,093 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 0.081616\n",
      "Reconstruction: 0.081111, Regularization: 0.000505\n",
      "2019-04-09 23:38:06,156 root         INFO     Train Epoch: 33 [4608/8000 (58%)]\tTotal Loss: 0.083662\n",
      "Reconstruction: 0.083374, Regularization: 0.000288\n",
      "2019-04-09 23:38:06,219 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.093428\n",
      "Reconstruction: 0.092872, Regularization: 0.000556\n",
      "2019-04-09 23:38:06,282 root         INFO     Train Epoch: 33 [5632/8000 (70%)]\tTotal Loss: 0.095383\n",
      "Reconstruction: 0.094705, Regularization: 0.000678\n",
      "2019-04-09 23:38:06,345 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 0.087777\n",
      "Reconstruction: 0.087419, Regularization: 0.000357\n",
      "2019-04-09 23:38:06,409 root         INFO     Train Epoch: 33 [6656/8000 (83%)]\tTotal Loss: 0.082223\n",
      "Reconstruction: 0.082004, Regularization: 0.000219\n",
      "2019-04-09 23:38:06,472 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.091139\n",
      "Reconstruction: 0.090702, Regularization: 0.000437\n",
      "2019-04-09 23:38:06,535 root         INFO     Train Epoch: 33 [7680/8000 (96%)]\tTotal Loss: 0.085116\n",
      "Reconstruction: 0.084837, Regularization: 0.000279\n",
      "2019-04-09 23:38:06,590 root         INFO     ====> Epoch: 33 Average loss: 0.0888\n",
      "2019-04-09 23:38:06,613 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.088128\n",
      "Reconstruction: 0.087637, Regularization: 0.000491\n",
      "2019-04-09 23:38:06,677 root         INFO     Train Epoch: 34 [512/8000 (6%)]\tTotal Loss: 0.094320\n",
      "Reconstruction: 0.093697, Regularization: 0.000623\n",
      "2019-04-09 23:38:06,741 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.094814\n",
      "Reconstruction: 0.094237, Regularization: 0.000577\n",
      "2019-04-09 23:38:06,803 root         INFO     Train Epoch: 34 [1536/8000 (19%)]\tTotal Loss: 0.082077\n",
      "Reconstruction: 0.081830, Regularization: 0.000247\n",
      "2019-04-09 23:38:06,867 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.093241\n",
      "Reconstruction: 0.092752, Regularization: 0.000488\n",
      "2019-04-09 23:38:06,930 root         INFO     Train Epoch: 34 [2560/8000 (32%)]\tTotal Loss: 0.088514\n",
      "Reconstruction: 0.088131, Regularization: 0.000383\n",
      "2019-04-09 23:38:06,993 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.094284\n",
      "Reconstruction: 0.093915, Regularization: 0.000368\n",
      "2019-04-09 23:38:07,056 root         INFO     Train Epoch: 34 [3584/8000 (45%)]\tTotal Loss: 0.085899\n",
      "Reconstruction: 0.085507, Regularization: 0.000392\n",
      "2019-04-09 23:38:07,118 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.089002\n",
      "Reconstruction: 0.088706, Regularization: 0.000297\n",
      "2019-04-09 23:38:07,181 root         INFO     Train Epoch: 34 [4608/8000 (58%)]\tTotal Loss: 0.095841\n",
      "Reconstruction: 0.095287, Regularization: 0.000554\n",
      "2019-04-09 23:38:07,244 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.094988\n",
      "Reconstruction: 0.094503, Regularization: 0.000485\n",
      "2019-04-09 23:38:07,307 root         INFO     Train Epoch: 34 [5632/8000 (70%)]\tTotal Loss: 0.081113\n",
      "Reconstruction: 0.080716, Regularization: 0.000397\n",
      "2019-04-09 23:38:07,369 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.091334\n",
      "Reconstruction: 0.090759, Regularization: 0.000575\n",
      "2019-04-09 23:38:07,433 root         INFO     Train Epoch: 34 [6656/8000 (83%)]\tTotal Loss: 0.090126\n",
      "Reconstruction: 0.089778, Regularization: 0.000349\n",
      "2019-04-09 23:38:07,495 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 0.085702\n",
      "Reconstruction: 0.085356, Regularization: 0.000346\n",
      "2019-04-09 23:38:07,558 root         INFO     Train Epoch: 34 [7680/8000 (96%)]\tTotal Loss: 0.087262\n",
      "Reconstruction: 0.087023, Regularization: 0.000239\n",
      "2019-04-09 23:38:07,613 root         INFO     ====> Epoch: 34 Average loss: 0.0888\n",
      "2019-04-09 23:38:07,636 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.096394\n",
      "Reconstruction: 0.095900, Regularization: 0.000493\n",
      "2019-04-09 23:38:07,701 root         INFO     Train Epoch: 35 [512/8000 (6%)]\tTotal Loss: 0.087156\n",
      "Reconstruction: 0.086844, Regularization: 0.000312\n",
      "2019-04-09 23:38:07,765 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.090156\n",
      "Reconstruction: 0.089756, Regularization: 0.000399\n",
      "2019-04-09 23:38:07,829 root         INFO     Train Epoch: 35 [1536/8000 (19%)]\tTotal Loss: 0.089151\n",
      "Reconstruction: 0.088858, Regularization: 0.000293\n",
      "2019-04-09 23:38:07,893 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.087926\n",
      "Reconstruction: 0.087562, Regularization: 0.000365\n",
      "2019-04-09 23:38:07,957 root         INFO     Train Epoch: 35 [2560/8000 (32%)]\tTotal Loss: 0.085294\n",
      "Reconstruction: 0.084924, Regularization: 0.000370\n",
      "2019-04-09 23:38:08,021 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.094106\n",
      "Reconstruction: 0.093622, Regularization: 0.000484\n",
      "2019-04-09 23:38:08,085 root         INFO     Train Epoch: 35 [3584/8000 (45%)]\tTotal Loss: 0.085455\n",
      "Reconstruction: 0.085109, Regularization: 0.000346\n",
      "2019-04-09 23:38:08,149 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.087283\n",
      "Reconstruction: 0.086977, Regularization: 0.000307\n",
      "2019-04-09 23:38:08,213 root         INFO     Train Epoch: 35 [4608/8000 (58%)]\tTotal Loss: 0.085259\n",
      "Reconstruction: 0.084998, Regularization: 0.000260\n",
      "2019-04-09 23:38:08,277 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.087086\n",
      "Reconstruction: 0.086747, Regularization: 0.000340\n",
      "2019-04-09 23:38:08,340 root         INFO     Train Epoch: 35 [5632/8000 (70%)]\tTotal Loss: 0.085854\n",
      "Reconstruction: 0.085513, Regularization: 0.000340\n",
      "2019-04-09 23:38:08,402 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.083820\n",
      "Reconstruction: 0.083564, Regularization: 0.000255\n",
      "2019-04-09 23:38:08,464 root         INFO     Train Epoch: 35 [6656/8000 (83%)]\tTotal Loss: 0.086211\n",
      "Reconstruction: 0.085872, Regularization: 0.000339\n",
      "2019-04-09 23:38:08,526 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.092387\n",
      "Reconstruction: 0.092064, Regularization: 0.000323\n",
      "2019-04-09 23:38:08,589 root         INFO     Train Epoch: 35 [7680/8000 (96%)]\tTotal Loss: 0.093160\n",
      "Reconstruction: 0.092861, Regularization: 0.000299\n",
      "2019-04-09 23:38:08,641 root         INFO     ====> Epoch: 35 Average loss: 0.0888\n",
      "2019-04-09 23:38:08,665 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 0.088238\n",
      "Reconstruction: 0.087897, Regularization: 0.000342\n",
      "2019-04-09 23:38:08,727 root         INFO     Train Epoch: 36 [512/8000 (6%)]\tTotal Loss: 0.085059\n",
      "Reconstruction: 0.084720, Regularization: 0.000339\n",
      "2019-04-09 23:38:08,788 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.086295\n",
      "Reconstruction: 0.086001, Regularization: 0.000294\n",
      "2019-04-09 23:38:08,849 root         INFO     Train Epoch: 36 [1536/8000 (19%)]\tTotal Loss: 0.086446\n",
      "Reconstruction: 0.086194, Regularization: 0.000252\n",
      "2019-04-09 23:38:08,909 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.093856\n",
      "Reconstruction: 0.093381, Regularization: 0.000475\n",
      "2019-04-09 23:38:08,970 root         INFO     Train Epoch: 36 [2560/8000 (32%)]\tTotal Loss: 0.089321\n",
      "Reconstruction: 0.089036, Regularization: 0.000285\n",
      "2019-04-09 23:38:09,030 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.094307\n",
      "Reconstruction: 0.093962, Regularization: 0.000345\n",
      "2019-04-09 23:38:09,091 root         INFO     Train Epoch: 36 [3584/8000 (45%)]\tTotal Loss: 0.087614\n",
      "Reconstruction: 0.087361, Regularization: 0.000253\n",
      "2019-04-09 23:38:09,151 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.085982\n",
      "Reconstruction: 0.085668, Regularization: 0.000314\n",
      "2019-04-09 23:38:09,212 root         INFO     Train Epoch: 36 [4608/8000 (58%)]\tTotal Loss: 0.094193\n",
      "Reconstruction: 0.093830, Regularization: 0.000363\n",
      "2019-04-09 23:38:09,272 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.087456\n",
      "Reconstruction: 0.087139, Regularization: 0.000317\n",
      "2019-04-09 23:38:09,333 root         INFO     Train Epoch: 36 [5632/8000 (70%)]\tTotal Loss: 0.093884\n",
      "Reconstruction: 0.093476, Regularization: 0.000408\n",
      "2019-04-09 23:38:09,393 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 0.093182\n",
      "Reconstruction: 0.092824, Regularization: 0.000359\n",
      "2019-04-09 23:38:09,454 root         INFO     Train Epoch: 36 [6656/8000 (83%)]\tTotal Loss: 0.089109\n",
      "Reconstruction: 0.088766, Regularization: 0.000344\n",
      "2019-04-09 23:38:09,514 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.090762\n",
      "Reconstruction: 0.090494, Regularization: 0.000268\n",
      "2019-04-09 23:38:09,575 root         INFO     Train Epoch: 36 [7680/8000 (96%)]\tTotal Loss: 0.083360\n",
      "Reconstruction: 0.083189, Regularization: 0.000171\n",
      "2019-04-09 23:38:09,629 root         INFO     ====> Epoch: 36 Average loss: 0.0888\n",
      "2019-04-09 23:38:09,652 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.078397\n",
      "Reconstruction: 0.078192, Regularization: 0.000205\n",
      "2019-04-09 23:38:09,715 root         INFO     Train Epoch: 37 [512/8000 (6%)]\tTotal Loss: 0.086122\n",
      "Reconstruction: 0.085887, Regularization: 0.000235\n",
      "2019-04-09 23:38:09,777 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.087189\n",
      "Reconstruction: 0.086906, Regularization: 0.000283\n",
      "2019-04-09 23:38:09,840 root         INFO     Train Epoch: 37 [1536/8000 (19%)]\tTotal Loss: 0.088709\n",
      "Reconstruction: 0.088478, Regularization: 0.000231\n",
      "2019-04-09 23:38:09,902 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.080868\n",
      "Reconstruction: 0.080606, Regularization: 0.000262\n",
      "2019-04-09 23:38:09,964 root         INFO     Train Epoch: 37 [2560/8000 (32%)]\tTotal Loss: 0.084184\n",
      "Reconstruction: 0.083948, Regularization: 0.000237\n",
      "2019-04-09 23:38:10,025 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 0.087897\n",
      "Reconstruction: 0.087636, Regularization: 0.000261\n",
      "2019-04-09 23:38:10,085 root         INFO     Train Epoch: 37 [3584/8000 (45%)]\tTotal Loss: 0.084653\n",
      "Reconstruction: 0.084343, Regularization: 0.000310\n",
      "2019-04-09 23:38:10,146 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.084777\n",
      "Reconstruction: 0.084548, Regularization: 0.000229\n",
      "2019-04-09 23:38:10,207 root         INFO     Train Epoch: 37 [4608/8000 (58%)]\tTotal Loss: 0.097367\n",
      "Reconstruction: 0.097129, Regularization: 0.000238\n",
      "2019-04-09 23:38:10,268 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.082559\n",
      "Reconstruction: 0.082340, Regularization: 0.000219\n",
      "2019-04-09 23:38:10,331 root         INFO     Train Epoch: 37 [5632/8000 (70%)]\tTotal Loss: 0.088531\n",
      "Reconstruction: 0.088285, Regularization: 0.000246\n",
      "2019-04-09 23:38:10,395 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.083774\n",
      "Reconstruction: 0.083516, Regularization: 0.000259\n",
      "2019-04-09 23:38:10,459 root         INFO     Train Epoch: 37 [6656/8000 (83%)]\tTotal Loss: 0.085598\n",
      "Reconstruction: 0.085387, Regularization: 0.000211\n",
      "2019-04-09 23:38:10,523 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.089535\n",
      "Reconstruction: 0.089335, Regularization: 0.000199\n",
      "2019-04-09 23:38:10,587 root         INFO     Train Epoch: 37 [7680/8000 (96%)]\tTotal Loss: 0.083735\n",
      "Reconstruction: 0.083531, Regularization: 0.000204\n",
      "2019-04-09 23:38:10,641 root         INFO     ====> Epoch: 37 Average loss: 0.0887\n",
      "2019-04-09 23:38:10,665 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.082911\n",
      "Reconstruction: 0.082699, Regularization: 0.000212\n",
      "2019-04-09 23:38:10,729 root         INFO     Train Epoch: 38 [512/8000 (6%)]\tTotal Loss: 0.090255\n",
      "Reconstruction: 0.089944, Regularization: 0.000311\n",
      "2019-04-09 23:38:10,793 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.091214\n",
      "Reconstruction: 0.090974, Regularization: 0.000240\n",
      "2019-04-09 23:38:10,856 root         INFO     Train Epoch: 38 [1536/8000 (19%)]\tTotal Loss: 0.091997\n",
      "Reconstruction: 0.091708, Regularization: 0.000288\n",
      "2019-04-09 23:38:10,920 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.086445\n",
      "Reconstruction: 0.086100, Regularization: 0.000345\n",
      "2019-04-09 23:38:10,984 root         INFO     Train Epoch: 38 [2560/8000 (32%)]\tTotal Loss: 0.092875\n",
      "Reconstruction: 0.092574, Regularization: 0.000301\n",
      "2019-04-09 23:38:11,047 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 0.083881\n",
      "Reconstruction: 0.083697, Regularization: 0.000184\n",
      "2019-04-09 23:38:11,111 root         INFO     Train Epoch: 38 [3584/8000 (45%)]\tTotal Loss: 0.088022\n",
      "Reconstruction: 0.087782, Regularization: 0.000240\n",
      "2019-04-09 23:38:11,175 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.090405\n",
      "Reconstruction: 0.090162, Regularization: 0.000243\n",
      "2019-04-09 23:38:11,239 root         INFO     Train Epoch: 38 [4608/8000 (58%)]\tTotal Loss: 0.076667\n",
      "Reconstruction: 0.076538, Regularization: 0.000129\n",
      "2019-04-09 23:38:11,302 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.089795\n",
      "Reconstruction: 0.089520, Regularization: 0.000275\n",
      "2019-04-09 23:38:11,366 root         INFO     Train Epoch: 38 [5632/8000 (70%)]\tTotal Loss: 0.097356\n",
      "Reconstruction: 0.097047, Regularization: 0.000309\n",
      "2019-04-09 23:38:11,429 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.079877\n",
      "Reconstruction: 0.079699, Regularization: 0.000178\n",
      "2019-04-09 23:38:11,491 root         INFO     Train Epoch: 38 [6656/8000 (83%)]\tTotal Loss: 0.087841\n",
      "Reconstruction: 0.087595, Regularization: 0.000246\n",
      "2019-04-09 23:38:11,554 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.098282\n",
      "Reconstruction: 0.097997, Regularization: 0.000285\n",
      "2019-04-09 23:38:11,617 root         INFO     Train Epoch: 38 [7680/8000 (96%)]\tTotal Loss: 0.093285\n",
      "Reconstruction: 0.093006, Regularization: 0.000279\n",
      "2019-04-09 23:38:11,671 root         INFO     ====> Epoch: 38 Average loss: 0.0887\n",
      "2019-04-09 23:38:11,695 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 0.092432\n",
      "Reconstruction: 0.092183, Regularization: 0.000250\n",
      "2019-04-09 23:38:11,759 root         INFO     Train Epoch: 39 [512/8000 (6%)]\tTotal Loss: 0.102283\n",
      "Reconstruction: 0.101874, Regularization: 0.000409\n",
      "2019-04-09 23:38:11,823 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.093781\n",
      "Reconstruction: 0.093534, Regularization: 0.000247\n",
      "2019-04-09 23:38:11,887 root         INFO     Train Epoch: 39 [1536/8000 (19%)]\tTotal Loss: 0.099753\n",
      "Reconstruction: 0.099516, Regularization: 0.000237\n",
      "2019-04-09 23:38:11,951 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.084982\n",
      "Reconstruction: 0.084770, Regularization: 0.000212\n",
      "2019-04-09 23:38:12,014 root         INFO     Train Epoch: 39 [2560/8000 (32%)]\tTotal Loss: 0.090273\n",
      "Reconstruction: 0.090114, Regularization: 0.000159\n",
      "2019-04-09 23:38:12,076 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.084984\n",
      "Reconstruction: 0.084729, Regularization: 0.000255\n",
      "2019-04-09 23:38:12,139 root         INFO     Train Epoch: 39 [3584/8000 (45%)]\tTotal Loss: 0.086533\n",
      "Reconstruction: 0.086360, Regularization: 0.000174\n",
      "2019-04-09 23:38:12,202 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.093024\n",
      "Reconstruction: 0.092780, Regularization: 0.000245\n",
      "2019-04-09 23:38:12,264 root         INFO     Train Epoch: 39 [4608/8000 (58%)]\tTotal Loss: 0.083313\n",
      "Reconstruction: 0.083110, Regularization: 0.000203\n",
      "2019-04-09 23:38:12,327 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.094475\n",
      "Reconstruction: 0.094243, Regularization: 0.000232\n",
      "2019-04-09 23:38:12,390 root         INFO     Train Epoch: 39 [5632/8000 (70%)]\tTotal Loss: 0.091035\n",
      "Reconstruction: 0.090744, Regularization: 0.000291\n",
      "2019-04-09 23:38:12,454 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.085092\n",
      "Reconstruction: 0.084933, Regularization: 0.000159\n",
      "2019-04-09 23:38:12,517 root         INFO     Train Epoch: 39 [6656/8000 (83%)]\tTotal Loss: 0.089006\n",
      "Reconstruction: 0.088780, Regularization: 0.000226\n",
      "2019-04-09 23:38:12,579 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.088222\n",
      "Reconstruction: 0.088046, Regularization: 0.000177\n",
      "2019-04-09 23:38:12,642 root         INFO     Train Epoch: 39 [7680/8000 (96%)]\tTotal Loss: 0.083475\n",
      "Reconstruction: 0.083326, Regularization: 0.000150\n",
      "2019-04-09 23:38:12,696 root         INFO     ====> Epoch: 39 Average loss: 0.0888\n",
      "2019-04-09 23:38:12,720 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.075575\n",
      "Reconstruction: 0.075436, Regularization: 0.000139\n",
      "2019-04-09 23:38:12,784 root         INFO     Train Epoch: 40 [512/8000 (6%)]\tTotal Loss: 0.081417\n",
      "Reconstruction: 0.081242, Regularization: 0.000175\n",
      "2019-04-09 23:38:12,848 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.092572\n",
      "Reconstruction: 0.092340, Regularization: 0.000232\n",
      "2019-04-09 23:38:12,911 root         INFO     Train Epoch: 40 [1536/8000 (19%)]\tTotal Loss: 0.081945\n",
      "Reconstruction: 0.081777, Regularization: 0.000167\n",
      "2019-04-09 23:38:12,974 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.092134\n",
      "Reconstruction: 0.091880, Regularization: 0.000253\n",
      "2019-04-09 23:38:13,038 root         INFO     Train Epoch: 40 [2560/8000 (32%)]\tTotal Loss: 0.087482\n",
      "Reconstruction: 0.087283, Regularization: 0.000199\n",
      "2019-04-09 23:38:13,101 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.088998\n",
      "Reconstruction: 0.088846, Regularization: 0.000152\n",
      "2019-04-09 23:38:13,164 root         INFO     Train Epoch: 40 [3584/8000 (45%)]\tTotal Loss: 0.084933\n",
      "Reconstruction: 0.084764, Regularization: 0.000169\n",
      "2019-04-09 23:38:13,228 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.096947\n",
      "Reconstruction: 0.096689, Regularization: 0.000258\n",
      "2019-04-09 23:38:13,290 root         INFO     Train Epoch: 40 [4608/8000 (58%)]\tTotal Loss: 0.087621\n",
      "Reconstruction: 0.087481, Regularization: 0.000140\n",
      "2019-04-09 23:38:13,353 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 0.088102\n",
      "Reconstruction: 0.087954, Regularization: 0.000147\n",
      "2019-04-09 23:38:13,416 root         INFO     Train Epoch: 40 [5632/8000 (70%)]\tTotal Loss: 0.085487\n",
      "Reconstruction: 0.085307, Regularization: 0.000180\n",
      "2019-04-09 23:38:13,479 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.081966\n",
      "Reconstruction: 0.081772, Regularization: 0.000194\n",
      "2019-04-09 23:38:13,541 root         INFO     Train Epoch: 40 [6656/8000 (83%)]\tTotal Loss: 0.091432\n",
      "Reconstruction: 0.091231, Regularization: 0.000201\n",
      "2019-04-09 23:38:13,604 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.086532\n",
      "Reconstruction: 0.086342, Regularization: 0.000190\n",
      "2019-04-09 23:38:13,667 root         INFO     Train Epoch: 40 [7680/8000 (96%)]\tTotal Loss: 0.087154\n",
      "Reconstruction: 0.086990, Regularization: 0.000163\n",
      "2019-04-09 23:38:13,721 root         INFO     ====> Epoch: 40 Average loss: 0.0888\n",
      "2019-04-09 23:38:13,744 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 0.079041\n",
      "Reconstruction: 0.078898, Regularization: 0.000143\n",
      "2019-04-09 23:38:13,808 root         INFO     Train Epoch: 41 [512/8000 (6%)]\tTotal Loss: 0.084904\n",
      "Reconstruction: 0.084802, Regularization: 0.000101\n",
      "2019-04-09 23:38:13,870 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.093317\n",
      "Reconstruction: 0.093129, Regularization: 0.000188\n",
      "2019-04-09 23:38:13,933 root         INFO     Train Epoch: 41 [1536/8000 (19%)]\tTotal Loss: 0.098323\n",
      "Reconstruction: 0.098025, Regularization: 0.000298\n",
      "2019-04-09 23:38:13,995 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 0.084325\n",
      "Reconstruction: 0.084155, Regularization: 0.000171\n",
      "2019-04-09 23:38:14,057 root         INFO     Train Epoch: 41 [2560/8000 (32%)]\tTotal Loss: 0.086417\n",
      "Reconstruction: 0.086245, Regularization: 0.000172\n",
      "2019-04-09 23:38:14,119 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.097490\n",
      "Reconstruction: 0.097243, Regularization: 0.000247\n",
      "2019-04-09 23:38:14,182 root         INFO     Train Epoch: 41 [3584/8000 (45%)]\tTotal Loss: 0.086587\n",
      "Reconstruction: 0.086417, Regularization: 0.000170\n",
      "2019-04-09 23:38:14,245 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.083377\n",
      "Reconstruction: 0.083207, Regularization: 0.000170\n",
      "2019-04-09 23:38:14,307 root         INFO     Train Epoch: 41 [4608/8000 (58%)]\tTotal Loss: 0.092858\n",
      "Reconstruction: 0.092690, Regularization: 0.000168\n",
      "2019-04-09 23:38:14,369 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 0.087490\n",
      "Reconstruction: 0.087322, Regularization: 0.000168\n",
      "2019-04-09 23:38:14,431 root         INFO     Train Epoch: 41 [5632/8000 (70%)]\tTotal Loss: 0.089924\n",
      "Reconstruction: 0.089722, Regularization: 0.000201\n",
      "2019-04-09 23:38:14,493 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.083829\n",
      "Reconstruction: 0.083660, Regularization: 0.000169\n",
      "2019-04-09 23:38:14,555 root         INFO     Train Epoch: 41 [6656/8000 (83%)]\tTotal Loss: 0.095283\n",
      "Reconstruction: 0.095090, Regularization: 0.000193\n",
      "2019-04-09 23:38:14,617 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.085701\n",
      "Reconstruction: 0.085545, Regularization: 0.000156\n",
      "2019-04-09 23:38:14,678 root         INFO     Train Epoch: 41 [7680/8000 (96%)]\tTotal Loss: 0.087838\n",
      "Reconstruction: 0.087620, Regularization: 0.000218\n",
      "2019-04-09 23:38:14,731 root         INFO     ====> Epoch: 41 Average loss: 0.0887\n",
      "2019-04-09 23:38:14,755 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.097424\n",
      "Reconstruction: 0.097243, Regularization: 0.000181\n",
      "2019-04-09 23:38:14,818 root         INFO     Train Epoch: 42 [512/8000 (6%)]\tTotal Loss: 0.089718\n",
      "Reconstruction: 0.089502, Regularization: 0.000216\n",
      "2019-04-09 23:38:14,881 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.093423\n",
      "Reconstruction: 0.093275, Regularization: 0.000148\n",
      "2019-04-09 23:38:14,944 root         INFO     Train Epoch: 42 [1536/8000 (19%)]\tTotal Loss: 0.082554\n",
      "Reconstruction: 0.082437, Regularization: 0.000117\n",
      "2019-04-09 23:38:15,007 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.083367\n",
      "Reconstruction: 0.083233, Regularization: 0.000134\n",
      "2019-04-09 23:38:15,071 root         INFO     Train Epoch: 42 [2560/8000 (32%)]\tTotal Loss: 0.097643\n",
      "Reconstruction: 0.097429, Regularization: 0.000214\n",
      "2019-04-09 23:38:15,133 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 0.094262\n",
      "Reconstruction: 0.094105, Regularization: 0.000157\n",
      "2019-04-09 23:38:15,197 root         INFO     Train Epoch: 42 [3584/8000 (45%)]\tTotal Loss: 0.088054\n",
      "Reconstruction: 0.087887, Regularization: 0.000167\n",
      "2019-04-09 23:38:15,260 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.087524\n",
      "Reconstruction: 0.087390, Regularization: 0.000135\n",
      "2019-04-09 23:38:15,322 root         INFO     Train Epoch: 42 [4608/8000 (58%)]\tTotal Loss: 0.095974\n",
      "Reconstruction: 0.095825, Regularization: 0.000149\n",
      "2019-04-09 23:38:15,385 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.094152\n",
      "Reconstruction: 0.093984, Regularization: 0.000168\n",
      "2019-04-09 23:38:15,448 root         INFO     Train Epoch: 42 [5632/8000 (70%)]\tTotal Loss: 0.089836\n",
      "Reconstruction: 0.089662, Regularization: 0.000174\n",
      "2019-04-09 23:38:15,511 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.081337\n",
      "Reconstruction: 0.081201, Regularization: 0.000136\n",
      "2019-04-09 23:38:15,574 root         INFO     Train Epoch: 42 [6656/8000 (83%)]\tTotal Loss: 0.091666\n",
      "Reconstruction: 0.091487, Regularization: 0.000179\n",
      "2019-04-09 23:38:15,637 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.090627\n",
      "Reconstruction: 0.090455, Regularization: 0.000172\n",
      "2019-04-09 23:38:15,700 root         INFO     Train Epoch: 42 [7680/8000 (96%)]\tTotal Loss: 0.080116\n",
      "Reconstruction: 0.080029, Regularization: 0.000087\n",
      "2019-04-09 23:38:15,754 root         INFO     ====> Epoch: 42 Average loss: 0.0888\n",
      "2019-04-09 23:38:15,778 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.099085\n",
      "Reconstruction: 0.098896, Regularization: 0.000189\n",
      "2019-04-09 23:38:15,841 root         INFO     Train Epoch: 43 [512/8000 (6%)]\tTotal Loss: 0.087890\n",
      "Reconstruction: 0.087734, Regularization: 0.000156\n",
      "2019-04-09 23:38:15,904 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.092078\n",
      "Reconstruction: 0.091876, Regularization: 0.000201\n",
      "2019-04-09 23:38:15,967 root         INFO     Train Epoch: 43 [1536/8000 (19%)]\tTotal Loss: 0.086993\n",
      "Reconstruction: 0.086839, Regularization: 0.000154\n",
      "2019-04-09 23:38:16,031 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.084790\n",
      "Reconstruction: 0.084698, Regularization: 0.000092\n",
      "2019-04-09 23:38:16,093 root         INFO     Train Epoch: 43 [2560/8000 (32%)]\tTotal Loss: 0.096961\n",
      "Reconstruction: 0.096769, Regularization: 0.000193\n",
      "2019-04-09 23:38:16,156 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.096769\n",
      "Reconstruction: 0.096595, Regularization: 0.000174\n",
      "2019-04-09 23:38:16,219 root         INFO     Train Epoch: 43 [3584/8000 (45%)]\tTotal Loss: 0.085794\n",
      "Reconstruction: 0.085675, Regularization: 0.000119\n",
      "2019-04-09 23:38:16,282 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.095625\n",
      "Reconstruction: 0.095458, Regularization: 0.000167\n",
      "2019-04-09 23:38:16,344 root         INFO     Train Epoch: 43 [4608/8000 (58%)]\tTotal Loss: 0.093693\n",
      "Reconstruction: 0.093567, Regularization: 0.000127\n",
      "2019-04-09 23:38:16,407 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.083060\n",
      "Reconstruction: 0.082989, Regularization: 0.000071\n",
      "2019-04-09 23:38:16,470 root         INFO     Train Epoch: 43 [5632/8000 (70%)]\tTotal Loss: 0.096544\n",
      "Reconstruction: 0.096406, Regularization: 0.000139\n",
      "2019-04-09 23:38:16,532 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.083255\n",
      "Reconstruction: 0.083133, Regularization: 0.000122\n",
      "2019-04-09 23:38:16,595 root         INFO     Train Epoch: 43 [6656/8000 (83%)]\tTotal Loss: 0.076692\n",
      "Reconstruction: 0.076637, Regularization: 0.000055\n",
      "2019-04-09 23:38:16,657 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.086715\n",
      "Reconstruction: 0.086658, Regularization: 0.000056\n",
      "2019-04-09 23:38:16,720 root         INFO     Train Epoch: 43 [7680/8000 (96%)]\tTotal Loss: 0.092946\n",
      "Reconstruction: 0.092791, Regularization: 0.000154\n",
      "2019-04-09 23:38:16,773 root         INFO     ====> Epoch: 43 Average loss: 0.0887\n",
      "2019-04-09 23:38:16,797 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.091269\n",
      "Reconstruction: 0.091108, Regularization: 0.000161\n",
      "2019-04-09 23:38:16,860 root         INFO     Train Epoch: 44 [512/8000 (6%)]\tTotal Loss: 0.087647\n",
      "Reconstruction: 0.087546, Regularization: 0.000102\n",
      "2019-04-09 23:38:16,923 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.087526\n",
      "Reconstruction: 0.087401, Regularization: 0.000125\n",
      "2019-04-09 23:38:16,986 root         INFO     Train Epoch: 44 [1536/8000 (19%)]\tTotal Loss: 0.084911\n",
      "Reconstruction: 0.084803, Regularization: 0.000108\n",
      "2019-04-09 23:38:17,049 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.096499\n",
      "Reconstruction: 0.096328, Regularization: 0.000172\n",
      "2019-04-09 23:38:17,112 root         INFO     Train Epoch: 44 [2560/8000 (32%)]\tTotal Loss: 0.109664\n",
      "Reconstruction: 0.109473, Regularization: 0.000191\n",
      "2019-04-09 23:38:17,175 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.088779\n",
      "Reconstruction: 0.088671, Regularization: 0.000107\n",
      "2019-04-09 23:38:17,238 root         INFO     Train Epoch: 44 [3584/8000 (45%)]\tTotal Loss: 0.095131\n",
      "Reconstruction: 0.094989, Regularization: 0.000142\n",
      "2019-04-09 23:38:17,301 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.087568\n",
      "Reconstruction: 0.087459, Regularization: 0.000108\n",
      "2019-04-09 23:38:17,364 root         INFO     Train Epoch: 44 [4608/8000 (58%)]\tTotal Loss: 0.092688\n",
      "Reconstruction: 0.092574, Regularization: 0.000114\n",
      "2019-04-09 23:38:17,427 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.089715\n",
      "Reconstruction: 0.089649, Regularization: 0.000066\n",
      "2019-04-09 23:38:17,490 root         INFO     Train Epoch: 44 [5632/8000 (70%)]\tTotal Loss: 0.083345\n",
      "Reconstruction: 0.083266, Regularization: 0.000079\n",
      "2019-04-09 23:38:17,553 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.091693\n",
      "Reconstruction: 0.091579, Regularization: 0.000114\n",
      "2019-04-09 23:38:17,616 root         INFO     Train Epoch: 44 [6656/8000 (83%)]\tTotal Loss: 0.094884\n",
      "Reconstruction: 0.094706, Regularization: 0.000178\n",
      "2019-04-09 23:38:17,679 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.086071\n",
      "Reconstruction: 0.085988, Regularization: 0.000083\n",
      "2019-04-09 23:38:17,742 root         INFO     Train Epoch: 44 [7680/8000 (96%)]\tTotal Loss: 0.095274\n",
      "Reconstruction: 0.095122, Regularization: 0.000151\n",
      "2019-04-09 23:38:17,796 root         INFO     ====> Epoch: 44 Average loss: 0.0887\n",
      "2019-04-09 23:38:17,819 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.094827\n",
      "Reconstruction: 0.094708, Regularization: 0.000120\n",
      "2019-04-09 23:38:17,883 root         INFO     Train Epoch: 45 [512/8000 (6%)]\tTotal Loss: 0.092126\n",
      "Reconstruction: 0.092018, Regularization: 0.000108\n",
      "2019-04-09 23:38:17,946 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 0.086829\n",
      "Reconstruction: 0.086720, Regularization: 0.000109\n",
      "2019-04-09 23:38:18,009 root         INFO     Train Epoch: 45 [1536/8000 (19%)]\tTotal Loss: 0.093715\n",
      "Reconstruction: 0.093629, Regularization: 0.000086\n",
      "2019-04-09 23:38:18,072 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.086716\n",
      "Reconstruction: 0.086634, Regularization: 0.000083\n",
      "2019-04-09 23:38:18,135 root         INFO     Train Epoch: 45 [2560/8000 (32%)]\tTotal Loss: 0.087979\n",
      "Reconstruction: 0.087889, Regularization: 0.000090\n",
      "2019-04-09 23:38:18,198 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.092657\n",
      "Reconstruction: 0.092541, Regularization: 0.000116\n",
      "2019-04-09 23:38:18,261 root         INFO     Train Epoch: 45 [3584/8000 (45%)]\tTotal Loss: 0.080939\n",
      "Reconstruction: 0.080860, Regularization: 0.000079\n",
      "2019-04-09 23:38:18,324 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.099012\n",
      "Reconstruction: 0.098903, Regularization: 0.000109\n",
      "2019-04-09 23:38:18,387 root         INFO     Train Epoch: 45 [4608/8000 (58%)]\tTotal Loss: 0.088670\n",
      "Reconstruction: 0.088595, Regularization: 0.000076\n",
      "2019-04-09 23:38:18,449 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.083230\n",
      "Reconstruction: 0.083165, Regularization: 0.000065\n",
      "2019-04-09 23:38:18,510 root         INFO     Train Epoch: 45 [5632/8000 (70%)]\tTotal Loss: 0.094808\n",
      "Reconstruction: 0.094688, Regularization: 0.000120\n",
      "2019-04-09 23:38:18,572 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.079538\n",
      "Reconstruction: 0.079481, Regularization: 0.000057\n",
      "2019-04-09 23:38:18,633 root         INFO     Train Epoch: 45 [6656/8000 (83%)]\tTotal Loss: 0.082750\n",
      "Reconstruction: 0.082685, Regularization: 0.000065\n",
      "2019-04-09 23:38:18,695 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.082527\n",
      "Reconstruction: 0.082445, Regularization: 0.000082\n",
      "2019-04-09 23:38:18,756 root         INFO     Train Epoch: 45 [7680/8000 (96%)]\tTotal Loss: 0.079345\n",
      "Reconstruction: 0.079291, Regularization: 0.000054\n",
      "2019-04-09 23:38:18,809 root         INFO     ====> Epoch: 45 Average loss: 0.0888\n",
      "2019-04-09 23:38:18,833 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.078324\n",
      "Reconstruction: 0.078264, Regularization: 0.000060\n",
      "2019-04-09 23:38:18,896 root         INFO     Train Epoch: 46 [512/8000 (6%)]\tTotal Loss: 0.080960\n",
      "Reconstruction: 0.080904, Regularization: 0.000056\n",
      "2019-04-09 23:38:18,959 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.094179\n",
      "Reconstruction: 0.094060, Regularization: 0.000119\n",
      "2019-04-09 23:38:19,022 root         INFO     Train Epoch: 46 [1536/8000 (19%)]\tTotal Loss: 0.089816\n",
      "Reconstruction: 0.089723, Regularization: 0.000093\n",
      "2019-04-09 23:38:19,085 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.094816\n",
      "Reconstruction: 0.094731, Regularization: 0.000085\n",
      "2019-04-09 23:38:19,148 root         INFO     Train Epoch: 46 [2560/8000 (32%)]\tTotal Loss: 0.084778\n",
      "Reconstruction: 0.084715, Regularization: 0.000063\n",
      "2019-04-09 23:38:19,211 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.085262\n",
      "Reconstruction: 0.085209, Regularization: 0.000053\n",
      "2019-04-09 23:38:19,273 root         INFO     Train Epoch: 46 [3584/8000 (45%)]\tTotal Loss: 0.090972\n",
      "Reconstruction: 0.090887, Regularization: 0.000085\n",
      "2019-04-09 23:38:19,336 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.086318\n",
      "Reconstruction: 0.086258, Regularization: 0.000060\n",
      "2019-04-09 23:38:19,399 root         INFO     Train Epoch: 46 [4608/8000 (58%)]\tTotal Loss: 0.087786\n",
      "Reconstruction: 0.087714, Regularization: 0.000071\n",
      "2019-04-09 23:38:19,462 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.092480\n",
      "Reconstruction: 0.092391, Regularization: 0.000088\n",
      "2019-04-09 23:38:19,524 root         INFO     Train Epoch: 46 [5632/8000 (70%)]\tTotal Loss: 0.081070\n",
      "Reconstruction: 0.081010, Regularization: 0.000061\n",
      "2019-04-09 23:38:19,587 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.087369\n",
      "Reconstruction: 0.087302, Regularization: 0.000067\n",
      "2019-04-09 23:38:19,650 root         INFO     Train Epoch: 46 [6656/8000 (83%)]\tTotal Loss: 0.094217\n",
      "Reconstruction: 0.094166, Regularization: 0.000051\n",
      "2019-04-09 23:38:19,713 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.087946\n",
      "Reconstruction: 0.087897, Regularization: 0.000048\n",
      "2019-04-09 23:38:19,777 root         INFO     Train Epoch: 46 [7680/8000 (96%)]\tTotal Loss: 0.086160\n",
      "Reconstruction: 0.086105, Regularization: 0.000054\n",
      "2019-04-09 23:38:19,830 root         INFO     ====> Epoch: 46 Average loss: 0.0887\n",
      "2019-04-09 23:38:19,854 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.092868\n",
      "Reconstruction: 0.092800, Regularization: 0.000068\n",
      "2019-04-09 23:38:19,917 root         INFO     Train Epoch: 47 [512/8000 (6%)]\tTotal Loss: 0.087760\n",
      "Reconstruction: 0.087687, Regularization: 0.000073\n",
      "2019-04-09 23:38:19,981 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.091195\n",
      "Reconstruction: 0.091136, Regularization: 0.000058\n",
      "2019-04-09 23:38:20,043 root         INFO     Train Epoch: 47 [1536/8000 (19%)]\tTotal Loss: 0.088298\n",
      "Reconstruction: 0.088244, Regularization: 0.000054\n",
      "2019-04-09 23:38:20,106 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.088442\n",
      "Reconstruction: 0.088389, Regularization: 0.000054\n",
      "2019-04-09 23:38:20,168 root         INFO     Train Epoch: 47 [2560/8000 (32%)]\tTotal Loss: 0.100962\n",
      "Reconstruction: 0.100888, Regularization: 0.000074\n",
      "2019-04-09 23:38:20,231 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.085631\n",
      "Reconstruction: 0.085593, Regularization: 0.000037\n",
      "2019-04-09 23:38:20,294 root         INFO     Train Epoch: 47 [3584/8000 (45%)]\tTotal Loss: 0.087280\n",
      "Reconstruction: 0.087239, Regularization: 0.000041\n",
      "2019-04-09 23:38:20,357 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.090912\n",
      "Reconstruction: 0.090858, Regularization: 0.000054\n",
      "2019-04-09 23:38:20,419 root         INFO     Train Epoch: 47 [4608/8000 (58%)]\tTotal Loss: 0.088620\n",
      "Reconstruction: 0.088572, Regularization: 0.000048\n",
      "2019-04-09 23:38:20,482 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.087184\n",
      "Reconstruction: 0.087133, Regularization: 0.000050\n",
      "2019-04-09 23:38:20,545 root         INFO     Train Epoch: 47 [5632/8000 (70%)]\tTotal Loss: 0.084398\n",
      "Reconstruction: 0.084350, Regularization: 0.000047\n",
      "2019-04-09 23:38:20,607 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.090778\n",
      "Reconstruction: 0.090718, Regularization: 0.000060\n",
      "2019-04-09 23:38:20,670 root         INFO     Train Epoch: 47 [6656/8000 (83%)]\tTotal Loss: 0.090151\n",
      "Reconstruction: 0.090092, Regularization: 0.000059\n",
      "2019-04-09 23:38:20,734 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.093063\n",
      "Reconstruction: 0.093003, Regularization: 0.000060\n",
      "2019-04-09 23:38:20,797 root         INFO     Train Epoch: 47 [7680/8000 (96%)]\tTotal Loss: 0.093581\n",
      "Reconstruction: 0.093518, Regularization: 0.000063\n",
      "2019-04-09 23:38:20,852 root         INFO     ====> Epoch: 47 Average loss: 0.0887\n",
      "2019-04-09 23:38:20,876 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.094558\n",
      "Reconstruction: 0.094475, Regularization: 0.000083\n",
      "2019-04-09 23:38:20,940 root         INFO     Train Epoch: 48 [512/8000 (6%)]\tTotal Loss: 0.078919\n",
      "Reconstruction: 0.078884, Regularization: 0.000035\n",
      "2019-04-09 23:38:21,003 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.090289\n",
      "Reconstruction: 0.090211, Regularization: 0.000078\n",
      "2019-04-09 23:38:21,066 root         INFO     Train Epoch: 48 [1536/8000 (19%)]\tTotal Loss: 0.085428\n",
      "Reconstruction: 0.085394, Regularization: 0.000034\n",
      "2019-04-09 23:38:21,129 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.089363\n",
      "Reconstruction: 0.089303, Regularization: 0.000059\n",
      "2019-04-09 23:38:21,191 root         INFO     Train Epoch: 48 [2560/8000 (32%)]\tTotal Loss: 0.087882\n",
      "Reconstruction: 0.087832, Regularization: 0.000050\n",
      "2019-04-09 23:38:21,254 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.084571\n",
      "Reconstruction: 0.084529, Regularization: 0.000042\n",
      "2019-04-09 23:38:21,317 root         INFO     Train Epoch: 48 [3584/8000 (45%)]\tTotal Loss: 0.088253\n",
      "Reconstruction: 0.088211, Regularization: 0.000043\n",
      "2019-04-09 23:38:21,380 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.080451\n",
      "Reconstruction: 0.080416, Regularization: 0.000035\n",
      "2019-04-09 23:38:21,443 root         INFO     Train Epoch: 48 [4608/8000 (58%)]\tTotal Loss: 0.077181\n",
      "Reconstruction: 0.077144, Regularization: 0.000038\n",
      "2019-04-09 23:38:21,505 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.091307\n",
      "Reconstruction: 0.091254, Regularization: 0.000054\n",
      "2019-04-09 23:38:21,569 root         INFO     Train Epoch: 48 [5632/8000 (70%)]\tTotal Loss: 0.087315\n",
      "Reconstruction: 0.087274, Regularization: 0.000041\n",
      "2019-04-09 23:38:21,631 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.087839\n",
      "Reconstruction: 0.087785, Regularization: 0.000054\n",
      "2019-04-09 23:38:21,694 root         INFO     Train Epoch: 48 [6656/8000 (83%)]\tTotal Loss: 0.084437\n",
      "Reconstruction: 0.084399, Regularization: 0.000038\n",
      "2019-04-09 23:38:21,757 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.085199\n",
      "Reconstruction: 0.085158, Regularization: 0.000040\n",
      "2019-04-09 23:38:21,819 root         INFO     Train Epoch: 48 [7680/8000 (96%)]\tTotal Loss: 0.087634\n",
      "Reconstruction: 0.087592, Regularization: 0.000042\n",
      "2019-04-09 23:38:21,873 root         INFO     ====> Epoch: 48 Average loss: 0.0887\n",
      "2019-04-09 23:38:21,897 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.082418\n",
      "Reconstruction: 0.082388, Regularization: 0.000030\n",
      "2019-04-09 23:38:21,961 root         INFO     Train Epoch: 49 [512/8000 (6%)]\tTotal Loss: 0.084032\n",
      "Reconstruction: 0.083996, Regularization: 0.000036\n",
      "2019-04-09 23:38:22,024 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.097129\n",
      "Reconstruction: 0.097052, Regularization: 0.000077\n",
      "2019-04-09 23:38:22,087 root         INFO     Train Epoch: 49 [1536/8000 (19%)]\tTotal Loss: 0.097135\n",
      "Reconstruction: 0.097071, Regularization: 0.000064\n",
      "2019-04-09 23:38:22,150 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.083741\n",
      "Reconstruction: 0.083689, Regularization: 0.000052\n",
      "2019-04-09 23:38:22,213 root         INFO     Train Epoch: 49 [2560/8000 (32%)]\tTotal Loss: 0.091055\n",
      "Reconstruction: 0.090997, Regularization: 0.000058\n",
      "2019-04-09 23:38:22,275 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.085068\n",
      "Reconstruction: 0.085036, Regularization: 0.000032\n",
      "2019-04-09 23:38:22,338 root         INFO     Train Epoch: 49 [3584/8000 (45%)]\tTotal Loss: 0.093040\n",
      "Reconstruction: 0.092995, Regularization: 0.000045\n",
      "2019-04-09 23:38:22,402 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.092621\n",
      "Reconstruction: 0.092571, Regularization: 0.000050\n",
      "2019-04-09 23:38:22,465 root         INFO     Train Epoch: 49 [4608/8000 (58%)]\tTotal Loss: 0.087587\n",
      "Reconstruction: 0.087554, Regularization: 0.000033\n",
      "2019-04-09 23:38:22,528 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.079763\n",
      "Reconstruction: 0.079719, Regularization: 0.000044\n",
      "2019-04-09 23:38:22,591 root         INFO     Train Epoch: 49 [5632/8000 (70%)]\tTotal Loss: 0.091116\n",
      "Reconstruction: 0.091048, Regularization: 0.000067\n",
      "2019-04-09 23:38:22,654 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.081802\n",
      "Reconstruction: 0.081761, Regularization: 0.000041\n",
      "2019-04-09 23:38:22,717 root         INFO     Train Epoch: 49 [6656/8000 (83%)]\tTotal Loss: 0.081232\n",
      "Reconstruction: 0.081192, Regularization: 0.000040\n",
      "2019-04-09 23:38:22,780 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.085557\n",
      "Reconstruction: 0.085510, Regularization: 0.000047\n",
      "2019-04-09 23:38:22,843 root         INFO     Train Epoch: 49 [7680/8000 (96%)]\tTotal Loss: 0.085085\n",
      "Reconstruction: 0.085041, Regularization: 0.000044\n",
      "2019-04-09 23:38:22,896 root         INFO     ====> Epoch: 49 Average loss: 0.0887\n",
      "2019-04-09 23:38:22,920 root         INFO     Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 0.104102\n",
      "Reconstruction: 0.104016, Regularization: 0.000086\n",
      "2019-04-09 23:38:22,983 root         INFO     Train Epoch: 50 [512/8000 (6%)]\tTotal Loss: 0.099283\n",
      "Reconstruction: 0.099226, Regularization: 0.000058\n",
      "2019-04-09 23:38:23,046 root         INFO     Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 0.092138\n",
      "Reconstruction: 0.092089, Regularization: 0.000049\n",
      "2019-04-09 23:38:23,109 root         INFO     Train Epoch: 50 [1536/8000 (19%)]\tTotal Loss: 0.090229\n",
      "Reconstruction: 0.090175, Regularization: 0.000054\n",
      "2019-04-09 23:38:23,172 root         INFO     Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 0.080278\n",
      "Reconstruction: 0.080247, Regularization: 0.000031\n",
      "2019-04-09 23:38:23,235 root         INFO     Train Epoch: 50 [2560/8000 (32%)]\tTotal Loss: 0.079716\n",
      "Reconstruction: 0.079692, Regularization: 0.000024\n",
      "2019-04-09 23:38:23,298 root         INFO     Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 0.089641\n",
      "Reconstruction: 0.089606, Regularization: 0.000036\n",
      "2019-04-09 23:38:23,361 root         INFO     Train Epoch: 50 [3584/8000 (45%)]\tTotal Loss: 0.084356\n",
      "Reconstruction: 0.084326, Regularization: 0.000030\n",
      "2019-04-09 23:38:23,424 root         INFO     Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 0.088553\n",
      "Reconstruction: 0.088500, Regularization: 0.000053\n",
      "2019-04-09 23:38:23,485 root         INFO     Train Epoch: 50 [4608/8000 (58%)]\tTotal Loss: 0.087099\n",
      "Reconstruction: 0.087068, Regularization: 0.000031\n",
      "2019-04-09 23:38:23,547 root         INFO     Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 0.095406\n",
      "Reconstruction: 0.095360, Regularization: 0.000046\n",
      "2019-04-09 23:38:23,609 root         INFO     Train Epoch: 50 [5632/8000 (70%)]\tTotal Loss: 0.082744\n",
      "Reconstruction: 0.082719, Regularization: 0.000025\n",
      "2019-04-09 23:38:23,671 root         INFO     Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 0.080126\n",
      "Reconstruction: 0.080105, Regularization: 0.000021\n",
      "2019-04-09 23:38:23,734 root         INFO     Train Epoch: 50 [6656/8000 (83%)]\tTotal Loss: 0.090176\n",
      "Reconstruction: 0.090136, Regularization: 0.000040\n",
      "2019-04-09 23:38:23,796 root         INFO     Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 0.084625\n",
      "Reconstruction: 0.084597, Regularization: 0.000027\n",
      "2019-04-09 23:38:23,859 root         INFO     Train Epoch: 50 [7680/8000 (96%)]\tTotal Loss: 0.093634\n",
      "Reconstruction: 0.093589, Regularization: 0.000045\n",
      "2019-04-09 23:38:23,912 root         INFO     ====> Epoch: 50 Average loss: 0.0887\n",
      "2019-04-09 23:38:23,936 root         INFO     Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 0.084176\n",
      "Reconstruction: 0.084142, Regularization: 0.000034\n",
      "2019-04-09 23:38:24,000 root         INFO     Train Epoch: 51 [512/8000 (6%)]\tTotal Loss: 0.089644\n",
      "Reconstruction: 0.089612, Regularization: 0.000031\n",
      "2019-04-09 23:38:24,063 root         INFO     Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 0.095894\n",
      "Reconstruction: 0.095860, Regularization: 0.000034\n",
      "2019-04-09 23:38:24,125 root         INFO     Train Epoch: 51 [1536/8000 (19%)]\tTotal Loss: 0.096838\n",
      "Reconstruction: 0.096795, Regularization: 0.000043\n",
      "2019-04-09 23:38:24,189 root         INFO     Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 0.082648\n",
      "Reconstruction: 0.082615, Regularization: 0.000032\n",
      "2019-04-09 23:38:24,251 root         INFO     Train Epoch: 51 [2560/8000 (32%)]\tTotal Loss: 0.080844\n",
      "Reconstruction: 0.080825, Regularization: 0.000019\n",
      "2019-04-09 23:38:24,313 root         INFO     Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 0.090663\n",
      "Reconstruction: 0.090636, Regularization: 0.000028\n",
      "2019-04-09 23:38:24,376 root         INFO     Train Epoch: 51 [3584/8000 (45%)]\tTotal Loss: 0.102777\n",
      "Reconstruction: 0.102735, Regularization: 0.000041\n",
      "2019-04-09 23:38:24,438 root         INFO     Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 0.088688\n",
      "Reconstruction: 0.088648, Regularization: 0.000040\n",
      "2019-04-09 23:38:24,500 root         INFO     Train Epoch: 51 [4608/8000 (58%)]\tTotal Loss: 0.089338\n",
      "Reconstruction: 0.089317, Regularization: 0.000020\n",
      "2019-04-09 23:38:24,563 root         INFO     Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 0.088672\n",
      "Reconstruction: 0.088646, Regularization: 0.000026\n",
      "2019-04-09 23:38:24,626 root         INFO     Train Epoch: 51 [5632/8000 (70%)]\tTotal Loss: 0.083729\n",
      "Reconstruction: 0.083698, Regularization: 0.000031\n",
      "2019-04-09 23:38:24,689 root         INFO     Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 0.090168\n",
      "Reconstruction: 0.090133, Regularization: 0.000035\n",
      "2019-04-09 23:38:24,751 root         INFO     Train Epoch: 51 [6656/8000 (83%)]\tTotal Loss: 0.077234\n",
      "Reconstruction: 0.077218, Regularization: 0.000017\n",
      "2019-04-09 23:38:24,813 root         INFO     Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 0.083531\n",
      "Reconstruction: 0.083514, Regularization: 0.000016\n",
      "2019-04-09 23:38:24,875 root         INFO     Train Epoch: 51 [7680/8000 (96%)]\tTotal Loss: 0.083729\n",
      "Reconstruction: 0.083709, Regularization: 0.000021\n",
      "2019-04-09 23:38:24,929 root         INFO     ====> Epoch: 51 Average loss: 0.0887\n",
      "2019-04-09 23:38:24,953 root         INFO     Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 0.098686\n",
      "Reconstruction: 0.098652, Regularization: 0.000034\n",
      "2019-04-09 23:38:25,016 root         INFO     Train Epoch: 52 [512/8000 (6%)]\tTotal Loss: 0.094259\n",
      "Reconstruction: 0.094235, Regularization: 0.000025\n",
      "2019-04-09 23:38:25,078 root         INFO     Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 0.090307\n",
      "Reconstruction: 0.090277, Regularization: 0.000029\n",
      "2019-04-09 23:38:25,139 root         INFO     Train Epoch: 52 [1536/8000 (19%)]\tTotal Loss: 0.095810\n",
      "Reconstruction: 0.095790, Regularization: 0.000019\n",
      "2019-04-09 23:38:25,201 root         INFO     Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 0.081135\n",
      "Reconstruction: 0.081117, Regularization: 0.000018\n",
      "2019-04-09 23:38:25,263 root         INFO     Train Epoch: 52 [2560/8000 (32%)]\tTotal Loss: 0.083938\n",
      "Reconstruction: 0.083926, Regularization: 0.000013\n",
      "2019-04-09 23:38:25,325 root         INFO     Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 0.086801\n",
      "Reconstruction: 0.086776, Regularization: 0.000025\n",
      "2019-04-09 23:38:25,387 root         INFO     Train Epoch: 52 [3584/8000 (45%)]\tTotal Loss: 0.085415\n",
      "Reconstruction: 0.085398, Regularization: 0.000016\n",
      "2019-04-09 23:38:25,450 root         INFO     Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 0.083405\n",
      "Reconstruction: 0.083391, Regularization: 0.000014\n",
      "2019-04-09 23:38:25,512 root         INFO     Train Epoch: 52 [4608/8000 (58%)]\tTotal Loss: 0.096973\n",
      "Reconstruction: 0.096946, Regularization: 0.000027\n",
      "2019-04-09 23:38:25,575 root         INFO     Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 0.092270\n",
      "Reconstruction: 0.092256, Regularization: 0.000014\n",
      "2019-04-09 23:38:25,637 root         INFO     Train Epoch: 52 [5632/8000 (70%)]\tTotal Loss: 0.095116\n",
      "Reconstruction: 0.095095, Regularization: 0.000021\n",
      "2019-04-09 23:38:25,699 root         INFO     Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 0.097102\n",
      "Reconstruction: 0.097082, Regularization: 0.000020\n",
      "2019-04-09 23:38:25,761 root         INFO     Train Epoch: 52 [6656/8000 (83%)]\tTotal Loss: 0.085058\n",
      "Reconstruction: 0.085046, Regularization: 0.000012\n",
      "2019-04-09 23:38:25,823 root         INFO     Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 0.087112\n",
      "Reconstruction: 0.087098, Regularization: 0.000014\n",
      "2019-04-09 23:38:25,885 root         INFO     Train Epoch: 52 [7680/8000 (96%)]\tTotal Loss: 0.089565\n",
      "Reconstruction: 0.089548, Regularization: 0.000017\n",
      "2019-04-09 23:38:25,938 root         INFO     ====> Epoch: 52 Average loss: 0.0887\n",
      "2019-04-09 23:38:25,962 root         INFO     Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 0.090683\n",
      "Reconstruction: 0.090667, Regularization: 0.000016\n",
      "2019-04-09 23:38:26,025 root         INFO     Train Epoch: 53 [512/8000 (6%)]\tTotal Loss: 0.093986\n",
      "Reconstruction: 0.093964, Regularization: 0.000021\n",
      "2019-04-09 23:38:26,088 root         INFO     Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 0.082684\n",
      "Reconstruction: 0.082669, Regularization: 0.000015\n",
      "2019-04-09 23:38:26,151 root         INFO     Train Epoch: 53 [1536/8000 (19%)]\tTotal Loss: 0.100219\n",
      "Reconstruction: 0.100196, Regularization: 0.000023\n",
      "2019-04-09 23:38:26,214 root         INFO     Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 0.084658\n",
      "Reconstruction: 0.084639, Regularization: 0.000019\n",
      "2019-04-09 23:38:26,277 root         INFO     Train Epoch: 53 [2560/8000 (32%)]\tTotal Loss: 0.093884\n",
      "Reconstruction: 0.093860, Regularization: 0.000024\n",
      "2019-04-09 23:38:26,340 root         INFO     Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 0.086677\n",
      "Reconstruction: 0.086653, Regularization: 0.000024\n",
      "2019-04-09 23:38:26,403 root         INFO     Train Epoch: 53 [3584/8000 (45%)]\tTotal Loss: 0.100022\n",
      "Reconstruction: 0.099997, Regularization: 0.000025\n",
      "2019-04-09 23:38:26,466 root         INFO     Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 0.085734\n",
      "Reconstruction: 0.085713, Regularization: 0.000021\n",
      "2019-04-09 23:38:26,530 root         INFO     Train Epoch: 53 [4608/8000 (58%)]\tTotal Loss: 0.085832\n",
      "Reconstruction: 0.085817, Regularization: 0.000015\n",
      "2019-04-09 23:38:26,592 root         INFO     Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 0.087828\n",
      "Reconstruction: 0.087807, Regularization: 0.000021\n",
      "2019-04-09 23:38:26,655 root         INFO     Train Epoch: 53 [5632/8000 (70%)]\tTotal Loss: 0.080927\n",
      "Reconstruction: 0.080913, Regularization: 0.000015\n",
      "2019-04-09 23:38:26,718 root         INFO     Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 0.085417\n",
      "Reconstruction: 0.085399, Regularization: 0.000018\n",
      "2019-04-09 23:38:26,782 root         INFO     Train Epoch: 53 [6656/8000 (83%)]\tTotal Loss: 0.098466\n",
      "Reconstruction: 0.098436, Regularization: 0.000030\n",
      "2019-04-09 23:38:26,844 root         INFO     Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 0.085403\n",
      "Reconstruction: 0.085390, Regularization: 0.000014\n",
      "2019-04-09 23:38:26,907 root         INFO     Train Epoch: 53 [7680/8000 (96%)]\tTotal Loss: 0.085263\n",
      "Reconstruction: 0.085250, Regularization: 0.000012\n",
      "2019-04-09 23:38:26,961 root         INFO     ====> Epoch: 53 Average loss: 0.0887\n",
      "2019-04-09 23:38:26,985 root         INFO     Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 0.094210\n",
      "Reconstruction: 0.094187, Regularization: 0.000023\n",
      "2019-04-09 23:38:27,049 root         INFO     Train Epoch: 54 [512/8000 (6%)]\tTotal Loss: 0.096455\n",
      "Reconstruction: 0.096432, Regularization: 0.000023\n",
      "2019-04-09 23:38:27,113 root         INFO     Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 0.086360\n",
      "Reconstruction: 0.086343, Regularization: 0.000017\n",
      "2019-04-09 23:38:27,177 root         INFO     Train Epoch: 54 [1536/8000 (19%)]\tTotal Loss: 0.083093\n",
      "Reconstruction: 0.083077, Regularization: 0.000016\n",
      "2019-04-09 23:38:27,241 root         INFO     Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 0.097608\n",
      "Reconstruction: 0.097589, Regularization: 0.000019\n",
      "2019-04-09 23:38:27,304 root         INFO     Train Epoch: 54 [2560/8000 (32%)]\tTotal Loss: 0.083064\n",
      "Reconstruction: 0.083053, Regularization: 0.000012\n",
      "2019-04-09 23:38:27,368 root         INFO     Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 0.095085\n",
      "Reconstruction: 0.095064, Regularization: 0.000021\n",
      "2019-04-09 23:38:27,432 root         INFO     Train Epoch: 54 [3584/8000 (45%)]\tTotal Loss: 0.081515\n",
      "Reconstruction: 0.081503, Regularization: 0.000013\n",
      "2019-04-09 23:38:27,495 root         INFO     Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 0.086270\n",
      "Reconstruction: 0.086260, Regularization: 0.000010\n",
      "2019-04-09 23:38:27,559 root         INFO     Train Epoch: 54 [4608/8000 (58%)]\tTotal Loss: 0.093091\n",
      "Reconstruction: 0.093074, Regularization: 0.000017\n",
      "2019-04-09 23:38:27,622 root         INFO     Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 0.076805\n",
      "Reconstruction: 0.076793, Regularization: 0.000013\n",
      "2019-04-09 23:38:27,686 root         INFO     Train Epoch: 54 [5632/8000 (70%)]\tTotal Loss: 0.082897\n",
      "Reconstruction: 0.082879, Regularization: 0.000019\n",
      "2019-04-09 23:38:27,749 root         INFO     Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 0.091998\n",
      "Reconstruction: 0.091973, Regularization: 0.000025\n",
      "2019-04-09 23:38:27,813 root         INFO     Train Epoch: 54 [6656/8000 (83%)]\tTotal Loss: 0.095958\n",
      "Reconstruction: 0.095938, Regularization: 0.000020\n",
      "2019-04-09 23:38:27,876 root         INFO     Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 0.093375\n",
      "Reconstruction: 0.093353, Regularization: 0.000022\n",
      "2019-04-09 23:38:27,939 root         INFO     Train Epoch: 54 [7680/8000 (96%)]\tTotal Loss: 0.077616\n",
      "Reconstruction: 0.077605, Regularization: 0.000011\n",
      "2019-04-09 23:38:27,992 root         INFO     ====> Epoch: 54 Average loss: 0.0887\n",
      "2019-04-09 23:38:28,016 root         INFO     Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 0.089455\n",
      "Reconstruction: 0.089443, Regularization: 0.000012\n",
      "2019-04-09 23:38:28,080 root         INFO     Train Epoch: 55 [512/8000 (6%)]\tTotal Loss: 0.098814\n",
      "Reconstruction: 0.098787, Regularization: 0.000027\n",
      "2019-04-09 23:38:28,142 root         INFO     Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 0.086210\n",
      "Reconstruction: 0.086196, Regularization: 0.000015\n",
      "2019-04-09 23:38:28,205 root         INFO     Train Epoch: 55 [1536/8000 (19%)]\tTotal Loss: 0.092450\n",
      "Reconstruction: 0.092435, Regularization: 0.000015\n",
      "2019-04-09 23:38:28,269 root         INFO     Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 0.090279\n",
      "Reconstruction: 0.090262, Regularization: 0.000017\n",
      "2019-04-09 23:38:28,334 root         INFO     Train Epoch: 55 [2560/8000 (32%)]\tTotal Loss: 0.089896\n",
      "Reconstruction: 0.089880, Regularization: 0.000016\n",
      "2019-04-09 23:38:28,400 root         INFO     Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 0.099551\n",
      "Reconstruction: 0.099535, Regularization: 0.000015\n",
      "2019-04-09 23:38:28,464 root         INFO     Train Epoch: 55 [3584/8000 (45%)]\tTotal Loss: 0.084723\n",
      "Reconstruction: 0.084713, Regularization: 0.000010\n",
      "2019-04-09 23:38:28,531 root         INFO     Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 0.081394\n",
      "Reconstruction: 0.081385, Regularization: 0.000009\n",
      "2019-04-09 23:38:28,597 root         INFO     Train Epoch: 55 [4608/8000 (58%)]\tTotal Loss: 0.083550\n",
      "Reconstruction: 0.083543, Regularization: 0.000007\n",
      "2019-04-09 23:38:28,662 root         INFO     Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 0.081391\n",
      "Reconstruction: 0.081379, Regularization: 0.000012\n",
      "2019-04-09 23:38:28,727 root         INFO     Train Epoch: 55 [5632/8000 (70%)]\tTotal Loss: 0.094465\n",
      "Reconstruction: 0.094448, Regularization: 0.000016\n",
      "2019-04-09 23:38:28,792 root         INFO     Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 0.084251\n",
      "Reconstruction: 0.084236, Regularization: 0.000015\n",
      "2019-04-09 23:38:28,857 root         INFO     Train Epoch: 55 [6656/8000 (83%)]\tTotal Loss: 0.083698\n",
      "Reconstruction: 0.083688, Regularization: 0.000011\n",
      "2019-04-09 23:38:28,922 root         INFO     Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 0.094318\n",
      "Reconstruction: 0.094306, Regularization: 0.000012\n",
      "2019-04-09 23:38:28,987 root         INFO     Train Epoch: 55 [7680/8000 (96%)]\tTotal Loss: 0.088874\n",
      "Reconstruction: 0.088865, Regularization: 0.000010\n",
      "2019-04-09 23:38:29,041 root         INFO     ====> Epoch: 55 Average loss: 0.0887\n",
      "2019-04-09 23:38:29,065 root         INFO     Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 0.089556\n",
      "Reconstruction: 0.089546, Regularization: 0.000009\n",
      "2019-04-09 23:38:29,129 root         INFO     Train Epoch: 56 [512/8000 (6%)]\tTotal Loss: 0.095124\n",
      "Reconstruction: 0.095113, Regularization: 0.000011\n",
      "2019-04-09 23:38:29,193 root         INFO     Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 0.084534\n",
      "Reconstruction: 0.084528, Regularization: 0.000006\n",
      "2019-04-09 23:38:29,256 root         INFO     Train Epoch: 56 [1536/8000 (19%)]\tTotal Loss: 0.087091\n",
      "Reconstruction: 0.087082, Regularization: 0.000009\n",
      "2019-04-09 23:38:29,319 root         INFO     Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 0.090453\n",
      "Reconstruction: 0.090446, Regularization: 0.000008\n",
      "2019-04-09 23:38:29,382 root         INFO     Train Epoch: 56 [2560/8000 (32%)]\tTotal Loss: 0.089638\n",
      "Reconstruction: 0.089630, Regularization: 0.000008\n",
      "2019-04-09 23:38:29,445 root         INFO     Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 0.090520\n",
      "Reconstruction: 0.090513, Regularization: 0.000007\n",
      "2019-04-09 23:38:29,509 root         INFO     Train Epoch: 56 [3584/8000 (45%)]\tTotal Loss: 0.089920\n",
      "Reconstruction: 0.089912, Regularization: 0.000008\n",
      "2019-04-09 23:38:29,573 root         INFO     Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 0.091832\n",
      "Reconstruction: 0.091823, Regularization: 0.000009\n",
      "2019-04-09 23:38:29,638 root         INFO     Train Epoch: 56 [4608/8000 (58%)]\tTotal Loss: 0.079486\n",
      "Reconstruction: 0.079482, Regularization: 0.000005\n",
      "2019-04-09 23:38:29,702 root         INFO     Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 0.093991\n",
      "Reconstruction: 0.093983, Regularization: 0.000008\n",
      "2019-04-09 23:38:29,767 root         INFO     Train Epoch: 56 [5632/8000 (70%)]\tTotal Loss: 0.085022\n",
      "Reconstruction: 0.085015, Regularization: 0.000006\n",
      "2019-04-09 23:38:29,832 root         INFO     Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 0.087626\n",
      "Reconstruction: 0.087619, Regularization: 0.000007\n",
      "2019-04-09 23:38:29,896 root         INFO     Train Epoch: 56 [6656/8000 (83%)]\tTotal Loss: 0.082235\n",
      "Reconstruction: 0.082229, Regularization: 0.000005\n",
      "2019-04-09 23:38:29,960 root         INFO     Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 0.084189\n",
      "Reconstruction: 0.084181, Regularization: 0.000008\n",
      "2019-04-09 23:38:30,023 root         INFO     Train Epoch: 56 [7680/8000 (96%)]\tTotal Loss: 0.082791\n",
      "Reconstruction: 0.082785, Regularization: 0.000006\n",
      "2019-04-09 23:38:30,078 root         INFO     ====> Epoch: 56 Average loss: 0.0887\n",
      "2019-04-09 23:38:30,102 root         INFO     Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 0.094203\n",
      "Reconstruction: 0.094195, Regularization: 0.000008\n",
      "2019-04-09 23:38:30,166 root         INFO     Train Epoch: 57 [512/8000 (6%)]\tTotal Loss: 0.092077\n",
      "Reconstruction: 0.092068, Regularization: 0.000009\n",
      "2019-04-09 23:38:30,229 root         INFO     Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 0.091116\n",
      "Reconstruction: 0.091111, Regularization: 0.000005\n",
      "2019-04-09 23:38:30,293 root         INFO     Train Epoch: 57 [1536/8000 (19%)]\tTotal Loss: 0.090665\n",
      "Reconstruction: 0.090660, Regularization: 0.000006\n",
      "2019-04-09 23:38:30,356 root         INFO     Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 0.089828\n",
      "Reconstruction: 0.089822, Regularization: 0.000006\n",
      "2019-04-09 23:38:30,419 root         INFO     Train Epoch: 57 [2560/8000 (32%)]\tTotal Loss: 0.090953\n",
      "Reconstruction: 0.090945, Regularization: 0.000008\n",
      "2019-04-09 23:38:30,481 root         INFO     Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 0.091680\n",
      "Reconstruction: 0.091674, Regularization: 0.000006\n",
      "2019-04-09 23:38:30,544 root         INFO     Train Epoch: 57 [3584/8000 (45%)]\tTotal Loss: 0.096750\n",
      "Reconstruction: 0.096743, Regularization: 0.000007\n",
      "2019-04-09 23:38:30,607 root         INFO     Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 0.090502\n",
      "Reconstruction: 0.090496, Regularization: 0.000006\n",
      "2019-04-09 23:38:30,669 root         INFO     Train Epoch: 57 [4608/8000 (58%)]\tTotal Loss: 0.093146\n",
      "Reconstruction: 0.093140, Regularization: 0.000006\n",
      "2019-04-09 23:38:30,732 root         INFO     Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 0.089732\n",
      "Reconstruction: 0.089727, Regularization: 0.000005\n",
      "2019-04-09 23:38:30,795 root         INFO     Train Epoch: 57 [5632/8000 (70%)]\tTotal Loss: 0.092752\n",
      "Reconstruction: 0.092746, Regularization: 0.000005\n",
      "2019-04-09 23:38:30,858 root         INFO     Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 0.087026\n",
      "Reconstruction: 0.087024, Regularization: 0.000002\n",
      "2019-04-09 23:38:30,920 root         INFO     Train Epoch: 57 [6656/8000 (83%)]\tTotal Loss: 0.092449\n",
      "Reconstruction: 0.092445, Regularization: 0.000004\n",
      "2019-04-09 23:38:30,983 root         INFO     Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 0.086209\n",
      "Reconstruction: 0.086206, Regularization: 0.000003\n",
      "2019-04-09 23:38:31,045 root         INFO     Train Epoch: 57 [7680/8000 (96%)]\tTotal Loss: 0.096921\n",
      "Reconstruction: 0.096917, Regularization: 0.000004\n",
      "2019-04-09 23:38:31,099 root         INFO     ====> Epoch: 57 Average loss: 0.0887\n",
      "2019-04-09 23:38:31,122 root         INFO     Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 0.088254\n",
      "Reconstruction: 0.088251, Regularization: 0.000003\n",
      "2019-04-09 23:38:31,186 root         INFO     Train Epoch: 58 [512/8000 (6%)]\tTotal Loss: 0.084369\n",
      "Reconstruction: 0.084366, Regularization: 0.000002\n",
      "2019-04-09 23:38:31,248 root         INFO     Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 0.097626\n",
      "Reconstruction: 0.097622, Regularization: 0.000004\n",
      "2019-04-09 23:38:31,311 root         INFO     Train Epoch: 58 [1536/8000 (19%)]\tTotal Loss: 0.091282\n",
      "Reconstruction: 0.091279, Regularization: 0.000003\n",
      "2019-04-09 23:38:31,373 root         INFO     Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 0.082624\n",
      "Reconstruction: 0.082622, Regularization: 0.000002\n",
      "2019-04-09 23:38:31,436 root         INFO     Train Epoch: 58 [2560/8000 (32%)]\tTotal Loss: 0.079747\n",
      "Reconstruction: 0.079744, Regularization: 0.000002\n",
      "2019-04-09 23:38:31,499 root         INFO     Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 0.086598\n",
      "Reconstruction: 0.086595, Regularization: 0.000003\n",
      "2019-04-09 23:38:31,561 root         INFO     Train Epoch: 58 [3584/8000 (45%)]\tTotal Loss: 0.089461\n",
      "Reconstruction: 0.089457, Regularization: 0.000003\n",
      "2019-04-09 23:38:31,625 root         INFO     Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 0.089864\n",
      "Reconstruction: 0.089860, Regularization: 0.000003\n",
      "2019-04-09 23:38:31,688 root         INFO     Train Epoch: 58 [4608/8000 (58%)]\tTotal Loss: 0.090074\n",
      "Reconstruction: 0.090070, Regularization: 0.000004\n",
      "2019-04-09 23:38:31,751 root         INFO     Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 0.088071\n",
      "Reconstruction: 0.088068, Regularization: 0.000003\n",
      "2019-04-09 23:38:31,813 root         INFO     Train Epoch: 58 [5632/8000 (70%)]\tTotal Loss: 0.089610\n",
      "Reconstruction: 0.089607, Regularization: 0.000003\n",
      "2019-04-09 23:38:31,876 root         INFO     Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 0.090668\n",
      "Reconstruction: 0.090666, Regularization: 0.000002\n",
      "2019-04-09 23:38:31,939 root         INFO     Train Epoch: 58 [6656/8000 (83%)]\tTotal Loss: 0.082511\n",
      "Reconstruction: 0.082508, Regularization: 0.000002\n",
      "2019-04-09 23:38:32,002 root         INFO     Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 0.086742\n",
      "Reconstruction: 0.086739, Regularization: 0.000003\n",
      "2019-04-09 23:38:32,064 root         INFO     Train Epoch: 58 [7680/8000 (96%)]\tTotal Loss: 0.084108\n",
      "Reconstruction: 0.084105, Regularization: 0.000004\n",
      "2019-04-09 23:38:32,117 root         INFO     ====> Epoch: 58 Average loss: 0.0887\n",
      "2019-04-09 23:38:32,141 root         INFO     Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 0.092118\n",
      "Reconstruction: 0.092115, Regularization: 0.000003\n",
      "2019-04-09 23:38:32,204 root         INFO     Train Epoch: 59 [512/8000 (6%)]\tTotal Loss: 0.089322\n",
      "Reconstruction: 0.089320, Regularization: 0.000003\n",
      "2019-04-09 23:38:32,266 root         INFO     Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 0.086648\n",
      "Reconstruction: 0.086645, Regularization: 0.000003\n",
      "2019-04-09 23:38:32,329 root         INFO     Train Epoch: 59 [1536/8000 (19%)]\tTotal Loss: 0.082917\n",
      "Reconstruction: 0.082915, Regularization: 0.000002\n",
      "2019-04-09 23:38:32,391 root         INFO     Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 0.090760\n",
      "Reconstruction: 0.090758, Regularization: 0.000003\n",
      "2019-04-09 23:38:32,454 root         INFO     Train Epoch: 59 [2560/8000 (32%)]\tTotal Loss: 0.079772\n",
      "Reconstruction: 0.079771, Regularization: 0.000002\n",
      "2019-04-09 23:38:32,517 root         INFO     Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 0.086952\n",
      "Reconstruction: 0.086950, Regularization: 0.000002\n",
      "2019-04-09 23:38:32,579 root         INFO     Train Epoch: 59 [3584/8000 (45%)]\tTotal Loss: 0.088233\n",
      "Reconstruction: 0.088231, Regularization: 0.000003\n",
      "2019-04-09 23:38:32,642 root         INFO     Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 0.088002\n",
      "Reconstruction: 0.088000, Regularization: 0.000002\n",
      "2019-04-09 23:38:32,705 root         INFO     Train Epoch: 59 [4608/8000 (58%)]\tTotal Loss: 0.084407\n",
      "Reconstruction: 0.084405, Regularization: 0.000001\n",
      "2019-04-09 23:38:32,767 root         INFO     Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 0.088620\n",
      "Reconstruction: 0.088618, Regularization: 0.000002\n",
      "2019-04-09 23:38:32,830 root         INFO     Train Epoch: 59 [5632/8000 (70%)]\tTotal Loss: 0.085373\n",
      "Reconstruction: 0.085372, Regularization: 0.000001\n",
      "2019-04-09 23:38:32,892 root         INFO     Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 0.087573\n",
      "Reconstruction: 0.087571, Regularization: 0.000001\n",
      "2019-04-09 23:38:32,955 root         INFO     Train Epoch: 59 [6656/8000 (83%)]\tTotal Loss: 0.103528\n",
      "Reconstruction: 0.103526, Regularization: 0.000002\n",
      "2019-04-09 23:38:33,018 root         INFO     Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 0.080597\n",
      "Reconstruction: 0.080596, Regularization: 0.000001\n",
      "2019-04-09 23:38:33,080 root         INFO     Train Epoch: 59 [7680/8000 (96%)]\tTotal Loss: 0.101676\n",
      "Reconstruction: 0.101674, Regularization: 0.000002\n",
      "2019-04-09 23:38:33,135 root         INFO     ====> Epoch: 59 Average loss: 0.0887\n",
      "2019-04-09 23:38:33,159 root         INFO     Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 0.089830\n",
      "Reconstruction: 0.089829, Regularization: 0.000001\n",
      "2019-04-09 23:38:33,222 root         INFO     Train Epoch: 60 [512/8000 (6%)]\tTotal Loss: 0.091721\n",
      "Reconstruction: 0.091720, Regularization: 0.000001\n",
      "2019-04-09 23:38:33,285 root         INFO     Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 0.085691\n",
      "Reconstruction: 0.085690, Regularization: 0.000001\n",
      "2019-04-09 23:38:33,347 root         INFO     Train Epoch: 60 [1536/8000 (19%)]\tTotal Loss: 0.082945\n",
      "Reconstruction: 0.082944, Regularization: 0.000001\n",
      "2019-04-09 23:38:33,410 root         INFO     Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 0.088541\n",
      "Reconstruction: 0.088540, Regularization: 0.000001\n",
      "2019-04-09 23:38:33,473 root         INFO     Train Epoch: 60 [2560/8000 (32%)]\tTotal Loss: 0.091793\n",
      "Reconstruction: 0.091792, Regularization: 0.000001\n",
      "2019-04-09 23:38:33,535 root         INFO     Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 0.083449\n",
      "Reconstruction: 0.083448, Regularization: 0.000001\n",
      "2019-04-09 23:38:33,598 root         INFO     Train Epoch: 60 [3584/8000 (45%)]\tTotal Loss: 0.102156\n",
      "Reconstruction: 0.102156, Regularization: 0.000001\n",
      "2019-04-09 23:38:33,661 root         INFO     Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 0.092549\n",
      "Reconstruction: 0.092548, Regularization: 0.000001\n",
      "2019-04-09 23:38:33,723 root         INFO     Train Epoch: 60 [4608/8000 (58%)]\tTotal Loss: 0.086789\n",
      "Reconstruction: 0.086788, Regularization: 0.000001\n",
      "2019-04-09 23:38:33,785 root         INFO     Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 0.090953\n",
      "Reconstruction: 0.090952, Regularization: 0.000000\n",
      "2019-04-09 23:38:33,847 root         INFO     Train Epoch: 60 [5632/8000 (70%)]\tTotal Loss: 0.089387\n",
      "Reconstruction: 0.089386, Regularization: 0.000001\n",
      "2019-04-09 23:38:33,910 root         INFO     Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 0.085596\n",
      "Reconstruction: 0.085596, Regularization: 0.000000\n",
      "2019-04-09 23:38:33,973 root         INFO     Train Epoch: 60 [6656/8000 (83%)]\tTotal Loss: 0.085177\n",
      "Reconstruction: 0.085176, Regularization: 0.000001\n",
      "2019-04-09 23:38:34,035 root         INFO     Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 0.076340\n",
      "Reconstruction: 0.076339, Regularization: 0.000000\n",
      "2019-04-09 23:38:34,098 root         INFO     Train Epoch: 60 [7680/8000 (96%)]\tTotal Loss: 0.081257\n",
      "Reconstruction: 0.081257, Regularization: 0.000000\n",
      "2019-04-09 23:38:34,152 root         INFO     ====> Epoch: 60 Average loss: 0.0887\n",
      "2019-04-09 23:38:34,176 root         INFO     Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 0.092954\n",
      "Reconstruction: 0.092953, Regularization: 0.000001\n",
      "2019-04-09 23:38:34,240 root         INFO     Train Epoch: 61 [512/8000 (6%)]\tTotal Loss: 0.084033\n",
      "Reconstruction: 0.084032, Regularization: 0.000000\n",
      "2019-04-09 23:38:34,304 root         INFO     Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 0.088768\n",
      "Reconstruction: 0.088767, Regularization: 0.000001\n",
      "2019-04-09 23:38:34,368 root         INFO     Train Epoch: 61 [1536/8000 (19%)]\tTotal Loss: 0.095220\n",
      "Reconstruction: 0.095219, Regularization: 0.000001\n",
      "2019-04-09 23:38:34,431 root         INFO     Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 0.086987\n",
      "Reconstruction: 0.086987, Regularization: 0.000000\n",
      "2019-04-09 23:38:34,495 root         INFO     Train Epoch: 61 [2560/8000 (32%)]\tTotal Loss: 0.093715\n",
      "Reconstruction: 0.093714, Regularization: 0.000000\n",
      "2019-04-09 23:38:34,559 root         INFO     Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 0.086980\n",
      "Reconstruction: 0.086980, Regularization: 0.000000\n",
      "2019-04-09 23:38:34,623 root         INFO     Train Epoch: 61 [3584/8000 (45%)]\tTotal Loss: 0.089592\n",
      "Reconstruction: 0.089591, Regularization: 0.000000\n",
      "2019-04-09 23:38:34,687 root         INFO     Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 0.091417\n",
      "Reconstruction: 0.091417, Regularization: 0.000000\n",
      "2019-04-09 23:38:34,750 root         INFO     Train Epoch: 61 [4608/8000 (58%)]\tTotal Loss: 0.094831\n",
      "Reconstruction: 0.094831, Regularization: 0.000000\n",
      "2019-04-09 23:38:34,814 root         INFO     Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 0.082791\n",
      "Reconstruction: 0.082791, Regularization: 0.000000\n",
      "2019-04-09 23:38:34,877 root         INFO     Train Epoch: 61 [5632/8000 (70%)]\tTotal Loss: 0.096685\n",
      "Reconstruction: 0.096685, Regularization: 0.000000\n",
      "2019-04-09 23:38:34,939 root         INFO     Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 0.084113\n",
      "Reconstruction: 0.084113, Regularization: 0.000000\n",
      "2019-04-09 23:38:35,002 root         INFO     Train Epoch: 61 [6656/8000 (83%)]\tTotal Loss: 0.086884\n",
      "Reconstruction: 0.086884, Regularization: 0.000000\n",
      "2019-04-09 23:38:35,065 root         INFO     Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 0.077144\n",
      "Reconstruction: 0.077144, Regularization: 0.000000\n",
      "2019-04-09 23:38:35,129 root         INFO     Train Epoch: 61 [7680/8000 (96%)]\tTotal Loss: 0.087320\n",
      "Reconstruction: 0.087320, Regularization: 0.000000\n",
      "2019-04-09 23:38:35,183 root         INFO     ====> Epoch: 61 Average loss: 0.0887\n",
      "2019-04-09 23:38:35,208 root         INFO     Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 0.087733\n",
      "Reconstruction: 0.087733, Regularization: 0.000000\n",
      "2019-04-09 23:38:35,276 root         INFO     Train Epoch: 62 [512/8000 (6%)]\tTotal Loss: 0.086271\n",
      "Reconstruction: 0.086271, Regularization: 0.000000\n",
      "2019-04-09 23:38:35,344 root         INFO     Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 0.089343\n",
      "Reconstruction: 0.089342, Regularization: 0.000000\n",
      "2019-04-09 23:38:35,414 root         INFO     Train Epoch: 62 [1536/8000 (19%)]\tTotal Loss: 0.097361\n",
      "Reconstruction: 0.097360, Regularization: 0.000001\n",
      "2019-04-09 23:38:35,495 root         INFO     Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 0.088308\n",
      "Reconstruction: 0.088308, Regularization: 0.000000\n",
      "2019-04-09 23:38:35,564 root         INFO     Train Epoch: 62 [2560/8000 (32%)]\tTotal Loss: 0.081717\n",
      "Reconstruction: 0.081717, Regularization: 0.000000\n",
      "2019-04-09 23:38:35,633 root         INFO     Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 0.085036\n",
      "Reconstruction: 0.085036, Regularization: 0.000000\n",
      "2019-04-09 23:38:35,702 root         INFO     Train Epoch: 62 [3584/8000 (45%)]\tTotal Loss: 0.085102\n",
      "Reconstruction: 0.085102, Regularization: 0.000000\n",
      "2019-04-09 23:38:35,772 root         INFO     Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 0.079006\n",
      "Reconstruction: 0.079006, Regularization: 0.000000\n",
      "2019-04-09 23:38:35,842 root         INFO     Train Epoch: 62 [4608/8000 (58%)]\tTotal Loss: 0.088084\n",
      "Reconstruction: 0.088084, Regularization: 0.000000\n",
      "2019-04-09 23:38:35,913 root         INFO     Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 0.090692\n",
      "Reconstruction: 0.090691, Regularization: 0.000000\n",
      "2019-04-09 23:38:35,980 root         INFO     Train Epoch: 62 [5632/8000 (70%)]\tTotal Loss: 0.078574\n",
      "Reconstruction: 0.078574, Regularization: 0.000000\n",
      "2019-04-09 23:38:36,047 root         INFO     Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 0.089551\n",
      "Reconstruction: 0.089550, Regularization: 0.000000\n",
      "2019-04-09 23:38:36,112 root         INFO     Train Epoch: 62 [6656/8000 (83%)]\tTotal Loss: 0.090520\n",
      "Reconstruction: 0.090519, Regularization: 0.000001\n",
      "2019-04-09 23:38:36,175 root         INFO     Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 0.088335\n",
      "Reconstruction: 0.088334, Regularization: 0.000001\n",
      "2019-04-09 23:38:36,238 root         INFO     Train Epoch: 62 [7680/8000 (96%)]\tTotal Loss: 0.086387\n",
      "Reconstruction: 0.086387, Regularization: 0.000001\n",
      "2019-04-09 23:38:36,294 root         INFO     ====> Epoch: 62 Average loss: 0.0887\n",
      "2019-04-09 23:38:36,317 root         INFO     Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 0.094795\n",
      "Reconstruction: 0.094794, Regularization: 0.000001\n",
      "2019-04-09 23:38:36,379 root         INFO     Train Epoch: 63 [512/8000 (6%)]\tTotal Loss: 0.098465\n",
      "Reconstruction: 0.098464, Regularization: 0.000001\n",
      "2019-04-09 23:38:36,441 root         INFO     Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 0.083291\n",
      "Reconstruction: 0.083291, Regularization: 0.000000\n",
      "2019-04-09 23:38:36,502 root         INFO     Train Epoch: 63 [1536/8000 (19%)]\tTotal Loss: 0.098536\n",
      "Reconstruction: 0.098535, Regularization: 0.000001\n",
      "2019-04-09 23:38:36,563 root         INFO     Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 0.091307\n",
      "Reconstruction: 0.091306, Regularization: 0.000001\n",
      "2019-04-09 23:38:36,624 root         INFO     Train Epoch: 63 [2560/8000 (32%)]\tTotal Loss: 0.083930\n",
      "Reconstruction: 0.083928, Regularization: 0.000002\n",
      "2019-04-09 23:38:36,685 root         INFO     Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 0.096509\n",
      "Reconstruction: 0.096507, Regularization: 0.000002\n",
      "2019-04-09 23:38:36,747 root         INFO     Train Epoch: 63 [3584/8000 (45%)]\tTotal Loss: 0.088716\n",
      "Reconstruction: 0.088714, Regularization: 0.000002\n",
      "2019-04-09 23:38:36,808 root         INFO     Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 0.100183\n",
      "Reconstruction: 0.100181, Regularization: 0.000002\n",
      "2019-04-09 23:38:36,870 root         INFO     Train Epoch: 63 [4608/8000 (58%)]\tTotal Loss: 0.081414\n",
      "Reconstruction: 0.081413, Regularization: 0.000001\n",
      "2019-04-09 23:38:36,931 root         INFO     Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 0.087674\n",
      "Reconstruction: 0.087673, Regularization: 0.000001\n",
      "2019-04-09 23:38:36,992 root         INFO     Train Epoch: 63 [5632/8000 (70%)]\tTotal Loss: 0.085562\n",
      "Reconstruction: 0.085561, Regularization: 0.000001\n",
      "2019-04-09 23:38:37,053 root         INFO     Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 0.085075\n",
      "Reconstruction: 0.085074, Regularization: 0.000001\n",
      "2019-04-09 23:38:37,114 root         INFO     Train Epoch: 63 [6656/8000 (83%)]\tTotal Loss: 0.089286\n",
      "Reconstruction: 0.089285, Regularization: 0.000001\n",
      "2019-04-09 23:38:37,175 root         INFO     Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 0.092988\n",
      "Reconstruction: 0.092987, Regularization: 0.000001\n",
      "2019-04-09 23:38:37,236 root         INFO     Train Epoch: 63 [7680/8000 (96%)]\tTotal Loss: 0.085122\n",
      "Reconstruction: 0.085121, Regularization: 0.000001\n",
      "2019-04-09 23:38:37,288 root         INFO     ====> Epoch: 63 Average loss: 0.0887\n",
      "2019-04-09 23:38:37,312 root         INFO     Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 0.085794\n",
      "Reconstruction: 0.085793, Regularization: 0.000001\n",
      "2019-04-09 23:38:37,374 root         INFO     Train Epoch: 64 [512/8000 (6%)]\tTotal Loss: 0.088500\n",
      "Reconstruction: 0.088499, Regularization: 0.000001\n",
      "2019-04-09 23:38:37,437 root         INFO     Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 0.092193\n",
      "Reconstruction: 0.092192, Regularization: 0.000001\n",
      "2019-04-09 23:38:37,499 root         INFO     Train Epoch: 64 [1536/8000 (19%)]\tTotal Loss: 0.100390\n",
      "Reconstruction: 0.100388, Regularization: 0.000001\n",
      "2019-04-09 23:38:37,561 root         INFO     Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 0.084827\n",
      "Reconstruction: 0.084826, Regularization: 0.000001\n",
      "2019-04-09 23:38:37,623 root         INFO     Train Epoch: 64 [2560/8000 (32%)]\tTotal Loss: 0.088278\n",
      "Reconstruction: 0.088278, Regularization: 0.000000\n",
      "2019-04-09 23:38:37,685 root         INFO     Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 0.090429\n",
      "Reconstruction: 0.090429, Regularization: 0.000001\n",
      "2019-04-09 23:38:37,747 root         INFO     Train Epoch: 64 [3584/8000 (45%)]\tTotal Loss: 0.079453\n",
      "Reconstruction: 0.079452, Regularization: 0.000001\n",
      "2019-04-09 23:38:37,810 root         INFO     Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 0.085929\n",
      "Reconstruction: 0.085928, Regularization: 0.000001\n",
      "2019-04-09 23:38:37,872 root         INFO     Train Epoch: 64 [4608/8000 (58%)]\tTotal Loss: 0.099355\n",
      "Reconstruction: 0.099353, Regularization: 0.000002\n",
      "2019-04-09 23:38:37,934 root         INFO     Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 0.083250\n",
      "Reconstruction: 0.083249, Regularization: 0.000001\n",
      "2019-04-09 23:38:37,996 root         INFO     Train Epoch: 64 [5632/8000 (70%)]\tTotal Loss: 0.088617\n",
      "Reconstruction: 0.088615, Regularization: 0.000002\n",
      "2019-04-09 23:38:38,057 root         INFO     Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 0.089507\n",
      "Reconstruction: 0.089505, Regularization: 0.000002\n",
      "2019-04-09 23:38:38,119 root         INFO     Train Epoch: 64 [6656/8000 (83%)]\tTotal Loss: 0.090737\n",
      "Reconstruction: 0.090736, Regularization: 0.000001\n",
      "2019-04-09 23:38:38,181 root         INFO     Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 0.084622\n",
      "Reconstruction: 0.084621, Regularization: 0.000001\n",
      "2019-04-09 23:38:38,243 root         INFO     Train Epoch: 64 [7680/8000 (96%)]\tTotal Loss: 0.093571\n",
      "Reconstruction: 0.093570, Regularization: 0.000002\n",
      "2019-04-09 23:38:38,296 root         INFO     ====> Epoch: 64 Average loss: 0.0887\n",
      "2019-04-09 23:38:38,319 root         INFO     Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 0.091319\n",
      "Reconstruction: 0.091317, Regularization: 0.000001\n",
      "2019-04-09 23:38:38,382 root         INFO     Train Epoch: 65 [512/8000 (6%)]\tTotal Loss: 0.086256\n",
      "Reconstruction: 0.086254, Regularization: 0.000002\n",
      "2019-04-09 23:38:38,444 root         INFO     Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 0.083875\n",
      "Reconstruction: 0.083873, Regularization: 0.000002\n",
      "2019-04-09 23:38:38,506 root         INFO     Train Epoch: 65 [1536/8000 (19%)]\tTotal Loss: 0.089032\n",
      "Reconstruction: 0.089029, Regularization: 0.000002\n",
      "2019-04-09 23:38:38,568 root         INFO     Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 0.088672\n",
      "Reconstruction: 0.088669, Regularization: 0.000003\n",
      "2019-04-09 23:38:38,630 root         INFO     Train Epoch: 65 [2560/8000 (32%)]\tTotal Loss: 0.098105\n",
      "Reconstruction: 0.098102, Regularization: 0.000004\n",
      "2019-04-09 23:38:38,692 root         INFO     Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 0.092606\n",
      "Reconstruction: 0.092604, Regularization: 0.000002\n",
      "2019-04-09 23:38:38,753 root         INFO     Train Epoch: 65 [3584/8000 (45%)]\tTotal Loss: 0.094820\n",
      "Reconstruction: 0.094816, Regularization: 0.000004\n",
      "2019-04-09 23:38:38,816 root         INFO     Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 0.093013\n",
      "Reconstruction: 0.093009, Regularization: 0.000003\n",
      "2019-04-09 23:38:38,878 root         INFO     Train Epoch: 65 [4608/8000 (58%)]\tTotal Loss: 0.099010\n",
      "Reconstruction: 0.099006, Regularization: 0.000004\n",
      "2019-04-09 23:38:38,940 root         INFO     Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 0.098526\n",
      "Reconstruction: 0.098521, Regularization: 0.000005\n",
      "2019-04-09 23:38:39,002 root         INFO     Train Epoch: 65 [5632/8000 (70%)]\tTotal Loss: 0.089959\n",
      "Reconstruction: 0.089954, Regularization: 0.000005\n",
      "2019-04-09 23:38:39,064 root         INFO     Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 0.085079\n",
      "Reconstruction: 0.085076, Regularization: 0.000003\n",
      "2019-04-09 23:38:39,127 root         INFO     Train Epoch: 65 [6656/8000 (83%)]\tTotal Loss: 0.091064\n",
      "Reconstruction: 0.091060, Regularization: 0.000004\n",
      "2019-04-09 23:38:39,188 root         INFO     Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 0.087286\n",
      "Reconstruction: 0.087283, Regularization: 0.000003\n",
      "2019-04-09 23:38:39,250 root         INFO     Train Epoch: 65 [7680/8000 (96%)]\tTotal Loss: 0.086029\n",
      "Reconstruction: 0.086026, Regularization: 0.000003\n",
      "2019-04-09 23:38:39,303 root         INFO     ====> Epoch: 65 Average loss: 0.0887\n",
      "2019-04-09 23:38:39,327 root         INFO     Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 0.088468\n",
      "Reconstruction: 0.088465, Regularization: 0.000004\n",
      "2019-04-09 23:38:39,391 root         INFO     Train Epoch: 66 [512/8000 (6%)]\tTotal Loss: 0.084271\n",
      "Reconstruction: 0.084267, Regularization: 0.000004\n",
      "2019-04-09 23:38:39,454 root         INFO     Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 0.096656\n",
      "Reconstruction: 0.096653, Regularization: 0.000004\n",
      "2019-04-09 23:38:39,517 root         INFO     Train Epoch: 66 [1536/8000 (19%)]\tTotal Loss: 0.085912\n",
      "Reconstruction: 0.085907, Regularization: 0.000005\n",
      "2019-04-09 23:38:39,580 root         INFO     Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 0.086498\n",
      "Reconstruction: 0.086495, Regularization: 0.000003\n",
      "2019-04-09 23:38:39,643 root         INFO     Train Epoch: 66 [2560/8000 (32%)]\tTotal Loss: 0.085052\n",
      "Reconstruction: 0.085049, Regularization: 0.000003\n",
      "2019-04-09 23:38:39,706 root         INFO     Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 0.087453\n",
      "Reconstruction: 0.087451, Regularization: 0.000002\n",
      "2019-04-09 23:38:39,770 root         INFO     Train Epoch: 66 [3584/8000 (45%)]\tTotal Loss: 0.093325\n",
      "Reconstruction: 0.093321, Regularization: 0.000004\n",
      "2019-04-09 23:38:39,833 root         INFO     Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 0.084782\n",
      "Reconstruction: 0.084778, Regularization: 0.000004\n",
      "2019-04-09 23:38:39,897 root         INFO     Train Epoch: 66 [4608/8000 (58%)]\tTotal Loss: 0.090657\n",
      "Reconstruction: 0.090653, Regularization: 0.000004\n",
      "2019-04-09 23:38:39,961 root         INFO     Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 0.086317\n",
      "Reconstruction: 0.086314, Regularization: 0.000003\n",
      "2019-04-09 23:38:40,025 root         INFO     Train Epoch: 66 [5632/8000 (70%)]\tTotal Loss: 0.080599\n",
      "Reconstruction: 0.080597, Regularization: 0.000002\n",
      "2019-04-09 23:38:40,088 root         INFO     Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 0.091962\n",
      "Reconstruction: 0.091960, Regularization: 0.000002\n",
      "2019-04-09 23:38:40,153 root         INFO     Train Epoch: 66 [6656/8000 (83%)]\tTotal Loss: 0.081979\n",
      "Reconstruction: 0.081977, Regularization: 0.000002\n",
      "2019-04-09 23:38:40,217 root         INFO     Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 0.081832\n",
      "Reconstruction: 0.081829, Regularization: 0.000003\n",
      "2019-04-09 23:38:40,281 root         INFO     Train Epoch: 66 [7680/8000 (96%)]\tTotal Loss: 0.082961\n",
      "Reconstruction: 0.082959, Regularization: 0.000003\n",
      "2019-04-09 23:38:40,335 root         INFO     ====> Epoch: 66 Average loss: 0.0887\n",
      "2019-04-09 23:38:40,359 root         INFO     Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 0.090446\n",
      "Reconstruction: 0.090443, Regularization: 0.000003\n",
      "2019-04-09 23:38:40,422 root         INFO     Train Epoch: 67 [512/8000 (6%)]\tTotal Loss: 0.081854\n",
      "Reconstruction: 0.081852, Regularization: 0.000002\n",
      "2019-04-09 23:38:40,486 root         INFO     Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 0.081185\n",
      "Reconstruction: 0.081182, Regularization: 0.000002\n",
      "2019-04-09 23:38:40,549 root         INFO     Train Epoch: 67 [1536/8000 (19%)]\tTotal Loss: 0.078870\n",
      "Reconstruction: 0.078868, Regularization: 0.000002\n",
      "2019-04-09 23:38:40,612 root         INFO     Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 0.078545\n",
      "Reconstruction: 0.078543, Regularization: 0.000002\n",
      "2019-04-09 23:38:40,675 root         INFO     Train Epoch: 67 [2560/8000 (32%)]\tTotal Loss: 0.095824\n",
      "Reconstruction: 0.095819, Regularization: 0.000005\n",
      "2019-04-09 23:38:40,742 root         INFO     Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 0.084189\n",
      "Reconstruction: 0.084186, Regularization: 0.000003\n",
      "2019-04-09 23:38:40,805 root         INFO     Train Epoch: 67 [3584/8000 (45%)]\tTotal Loss: 0.080583\n",
      "Reconstruction: 0.080581, Regularization: 0.000002\n",
      "2019-04-09 23:38:40,868 root         INFO     Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 0.093382\n",
      "Reconstruction: 0.093380, Regularization: 0.000003\n",
      "2019-04-09 23:38:40,930 root         INFO     Train Epoch: 67 [4608/8000 (58%)]\tTotal Loss: 0.082948\n",
      "Reconstruction: 0.082946, Regularization: 0.000002\n",
      "2019-04-09 23:38:40,993 root         INFO     Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 0.084109\n",
      "Reconstruction: 0.084108, Regularization: 0.000002\n",
      "2019-04-09 23:38:41,056 root         INFO     Train Epoch: 67 [5632/8000 (70%)]\tTotal Loss: 0.098884\n",
      "Reconstruction: 0.098883, Regularization: 0.000001\n",
      "2019-04-09 23:38:41,118 root         INFO     Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 0.079649\n",
      "Reconstruction: 0.079649, Regularization: 0.000001\n",
      "2019-04-09 23:38:41,181 root         INFO     Train Epoch: 67 [6656/8000 (83%)]\tTotal Loss: 0.084075\n",
      "Reconstruction: 0.084074, Regularization: 0.000001\n",
      "2019-04-09 23:38:41,242 root         INFO     Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 0.102168\n",
      "Reconstruction: 0.102167, Regularization: 0.000001\n",
      "2019-04-09 23:38:41,305 root         INFO     Train Epoch: 67 [7680/8000 (96%)]\tTotal Loss: 0.086844\n",
      "Reconstruction: 0.086844, Regularization: 0.000001\n",
      "2019-04-09 23:38:41,358 root         INFO     ====> Epoch: 67 Average loss: 0.0887\n",
      "2019-04-09 23:38:41,382 root         INFO     Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 0.094265\n",
      "Reconstruction: 0.094264, Regularization: 0.000001\n",
      "2019-04-09 23:38:41,446 root         INFO     Train Epoch: 68 [512/8000 (6%)]\tTotal Loss: 0.090202\n",
      "Reconstruction: 0.090201, Regularization: 0.000001\n",
      "2019-04-09 23:38:41,509 root         INFO     Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 0.082722\n",
      "Reconstruction: 0.082721, Regularization: 0.000001\n",
      "2019-04-09 23:38:41,572 root         INFO     Train Epoch: 68 [1536/8000 (19%)]\tTotal Loss: 0.085510\n",
      "Reconstruction: 0.085509, Regularization: 0.000001\n",
      "2019-04-09 23:38:41,635 root         INFO     Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 0.083391\n",
      "Reconstruction: 0.083390, Regularization: 0.000001\n",
      "2019-04-09 23:38:41,698 root         INFO     Train Epoch: 68 [2560/8000 (32%)]\tTotal Loss: 0.093436\n",
      "Reconstruction: 0.093434, Regularization: 0.000002\n",
      "2019-04-09 23:38:41,761 root         INFO     Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 0.083658\n",
      "Reconstruction: 0.083657, Regularization: 0.000001\n",
      "2019-04-09 23:38:41,824 root         INFO     Train Epoch: 68 [3584/8000 (45%)]\tTotal Loss: 0.085004\n",
      "Reconstruction: 0.085003, Regularization: 0.000001\n",
      "2019-04-09 23:38:41,888 root         INFO     Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 0.081021\n",
      "Reconstruction: 0.081020, Regularization: 0.000001\n",
      "2019-04-09 23:38:41,950 root         INFO     Train Epoch: 68 [4608/8000 (58%)]\tTotal Loss: 0.084708\n",
      "Reconstruction: 0.084707, Regularization: 0.000001\n",
      "2019-04-09 23:38:42,013 root         INFO     Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 0.079939\n",
      "Reconstruction: 0.079938, Regularization: 0.000001\n",
      "2019-04-09 23:38:42,077 root         INFO     Train Epoch: 68 [5632/8000 (70%)]\tTotal Loss: 0.095985\n",
      "Reconstruction: 0.095984, Regularization: 0.000001\n",
      "2019-04-09 23:38:42,140 root         INFO     Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 0.092801\n",
      "Reconstruction: 0.092800, Regularization: 0.000001\n",
      "2019-04-09 23:38:42,203 root         INFO     Train Epoch: 68 [6656/8000 (83%)]\tTotal Loss: 0.081389\n",
      "Reconstruction: 0.081389, Regularization: 0.000001\n",
      "2019-04-09 23:38:42,266 root         INFO     Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 0.090395\n",
      "Reconstruction: 0.090394, Regularization: 0.000001\n",
      "2019-04-09 23:38:42,330 root         INFO     Train Epoch: 68 [7680/8000 (96%)]\tTotal Loss: 0.084330\n",
      "Reconstruction: 0.084329, Regularization: 0.000001\n",
      "2019-04-09 23:38:42,384 root         INFO     ====> Epoch: 68 Average loss: 0.0887\n",
      "2019-04-09 23:38:42,408 root         INFO     Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 0.096337\n",
      "Reconstruction: 0.096335, Regularization: 0.000002\n",
      "2019-04-09 23:38:42,472 root         INFO     Train Epoch: 69 [512/8000 (6%)]\tTotal Loss: 0.081905\n",
      "Reconstruction: 0.081903, Regularization: 0.000001\n",
      "2019-04-09 23:38:42,534 root         INFO     Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 0.085984\n",
      "Reconstruction: 0.085981, Regularization: 0.000003\n",
      "2019-04-09 23:38:42,598 root         INFO     Train Epoch: 69 [1536/8000 (19%)]\tTotal Loss: 0.091941\n",
      "Reconstruction: 0.091936, Regularization: 0.000005\n",
      "2019-04-09 23:38:42,661 root         INFO     Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 0.083590\n",
      "Reconstruction: 0.083587, Regularization: 0.000004\n",
      "2019-04-09 23:38:42,724 root         INFO     Train Epoch: 69 [2560/8000 (32%)]\tTotal Loss: 0.083068\n",
      "Reconstruction: 0.083064, Regularization: 0.000003\n",
      "2019-04-09 23:38:42,787 root         INFO     Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 0.094634\n",
      "Reconstruction: 0.094629, Regularization: 0.000005\n",
      "2019-04-09 23:38:42,850 root         INFO     Train Epoch: 69 [3584/8000 (45%)]\tTotal Loss: 0.085447\n",
      "Reconstruction: 0.085441, Regularization: 0.000005\n",
      "2019-04-09 23:38:42,913 root         INFO     Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 0.088986\n",
      "Reconstruction: 0.088981, Regularization: 0.000005\n",
      "2019-04-09 23:38:42,976 root         INFO     Train Epoch: 69 [4608/8000 (58%)]\tTotal Loss: 0.088177\n",
      "Reconstruction: 0.088173, Regularization: 0.000004\n",
      "2019-04-09 23:38:43,039 root         INFO     Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 0.087205\n",
      "Reconstruction: 0.087202, Regularization: 0.000003\n",
      "2019-04-09 23:38:43,102 root         INFO     Train Epoch: 69 [5632/8000 (70%)]\tTotal Loss: 0.094088\n",
      "Reconstruction: 0.094085, Regularization: 0.000002\n",
      "2019-04-09 23:38:43,165 root         INFO     Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 0.088071\n",
      "Reconstruction: 0.088069, Regularization: 0.000002\n",
      "2019-04-09 23:38:43,228 root         INFO     Train Epoch: 69 [6656/8000 (83%)]\tTotal Loss: 0.087178\n",
      "Reconstruction: 0.087177, Regularization: 0.000002\n",
      "2019-04-09 23:38:43,291 root         INFO     Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 0.090404\n",
      "Reconstruction: 0.090402, Regularization: 0.000002\n",
      "2019-04-09 23:38:43,353 root         INFO     Train Epoch: 69 [7680/8000 (96%)]\tTotal Loss: 0.091919\n",
      "Reconstruction: 0.091917, Regularization: 0.000002\n",
      "2019-04-09 23:38:43,408 root         INFO     ====> Epoch: 69 Average loss: 0.0887\n",
      "2019-04-09 23:38:43,432 root         INFO     Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 0.089940\n",
      "Reconstruction: 0.089939, Regularization: 0.000001\n",
      "2019-04-09 23:38:43,495 root         INFO     Train Epoch: 70 [512/8000 (6%)]\tTotal Loss: 0.088054\n",
      "Reconstruction: 0.088053, Regularization: 0.000002\n",
      "2019-04-09 23:38:43,558 root         INFO     Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 0.086035\n",
      "Reconstruction: 0.086033, Regularization: 0.000001\n",
      "2019-04-09 23:38:43,621 root         INFO     Train Epoch: 70 [1536/8000 (19%)]\tTotal Loss: 0.083236\n",
      "Reconstruction: 0.083235, Regularization: 0.000001\n",
      "2019-04-09 23:38:43,684 root         INFO     Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 0.089522\n",
      "Reconstruction: 0.089521, Regularization: 0.000001\n",
      "2019-04-09 23:38:43,747 root         INFO     Train Epoch: 70 [2560/8000 (32%)]\tTotal Loss: 0.096509\n",
      "Reconstruction: 0.096506, Regularization: 0.000003\n",
      "2019-04-09 23:38:43,810 root         INFO     Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 0.089110\n",
      "Reconstruction: 0.089107, Regularization: 0.000002\n",
      "2019-04-09 23:38:43,873 root         INFO     Train Epoch: 70 [3584/8000 (45%)]\tTotal Loss: 0.093084\n",
      "Reconstruction: 0.093082, Regularization: 0.000003\n",
      "2019-04-09 23:38:43,936 root         INFO     Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 0.091400\n",
      "Reconstruction: 0.091397, Regularization: 0.000003\n",
      "2019-04-09 23:38:44,000 root         INFO     Train Epoch: 70 [4608/8000 (58%)]\tTotal Loss: 0.091264\n",
      "Reconstruction: 0.091262, Regularization: 0.000002\n",
      "2019-04-09 23:38:44,062 root         INFO     Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 0.088970\n",
      "Reconstruction: 0.088966, Regularization: 0.000004\n",
      "2019-04-09 23:38:44,125 root         INFO     Train Epoch: 70 [5632/8000 (70%)]\tTotal Loss: 0.084446\n",
      "Reconstruction: 0.084443, Regularization: 0.000002\n",
      "2019-04-09 23:38:44,187 root         INFO     Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 0.091600\n",
      "Reconstruction: 0.091596, Regularization: 0.000005\n",
      "2019-04-09 23:38:44,250 root         INFO     Train Epoch: 70 [6656/8000 (83%)]\tTotal Loss: 0.093579\n",
      "Reconstruction: 0.093574, Regularization: 0.000005\n",
      "2019-04-09 23:38:44,312 root         INFO     Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 0.090166\n",
      "Reconstruction: 0.090161, Regularization: 0.000004\n",
      "2019-04-09 23:38:44,375 root         INFO     Train Epoch: 70 [7680/8000 (96%)]\tTotal Loss: 0.088103\n",
      "Reconstruction: 0.088101, Regularization: 0.000003\n",
      "2019-04-09 23:38:44,429 root         INFO     ====> Epoch: 70 Average loss: 0.0887\n",
      "2019-04-09 23:38:44,453 root         INFO     Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 0.084298\n",
      "Reconstruction: 0.084296, Regularization: 0.000002\n",
      "2019-04-09 23:38:44,517 root         INFO     Train Epoch: 71 [512/8000 (6%)]\tTotal Loss: 0.084375\n",
      "Reconstruction: 0.084372, Regularization: 0.000003\n",
      "2019-04-09 23:38:44,579 root         INFO     Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 0.087291\n",
      "Reconstruction: 0.087289, Regularization: 0.000002\n",
      "2019-04-09 23:38:44,642 root         INFO     Train Epoch: 71 [1536/8000 (19%)]\tTotal Loss: 0.081635\n",
      "Reconstruction: 0.081633, Regularization: 0.000002\n",
      "2019-04-09 23:38:44,705 root         INFO     Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 0.083796\n",
      "Reconstruction: 0.083794, Regularization: 0.000002\n",
      "2019-04-09 23:38:44,768 root         INFO     Train Epoch: 71 [2560/8000 (32%)]\tTotal Loss: 0.097175\n",
      "Reconstruction: 0.097171, Regularization: 0.000004\n",
      "2019-04-09 23:38:44,830 root         INFO     Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 0.094626\n",
      "Reconstruction: 0.094624, Regularization: 0.000003\n",
      "2019-04-09 23:38:44,894 root         INFO     Train Epoch: 71 [3584/8000 (45%)]\tTotal Loss: 0.084578\n",
      "Reconstruction: 0.084574, Regularization: 0.000003\n",
      "2019-04-09 23:38:44,958 root         INFO     Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 0.094285\n",
      "Reconstruction: 0.094281, Regularization: 0.000004\n",
      "2019-04-09 23:38:45,022 root         INFO     Train Epoch: 71 [4608/8000 (58%)]\tTotal Loss: 0.083743\n",
      "Reconstruction: 0.083740, Regularization: 0.000003\n",
      "2019-04-09 23:38:45,086 root         INFO     Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 0.087460\n",
      "Reconstruction: 0.087456, Regularization: 0.000004\n",
      "2019-04-09 23:38:45,149 root         INFO     Train Epoch: 71 [5632/8000 (70%)]\tTotal Loss: 0.080985\n",
      "Reconstruction: 0.080982, Regularization: 0.000003\n",
      "2019-04-09 23:38:45,213 root         INFO     Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 0.090162\n",
      "Reconstruction: 0.090159, Regularization: 0.000003\n",
      "2019-04-09 23:38:45,277 root         INFO     Train Epoch: 71 [6656/8000 (83%)]\tTotal Loss: 0.082855\n",
      "Reconstruction: 0.082852, Regularization: 0.000003\n",
      "2019-04-09 23:38:45,341 root         INFO     Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 0.083961\n",
      "Reconstruction: 0.083958, Regularization: 0.000003\n",
      "2019-04-09 23:38:45,406 root         INFO     Train Epoch: 71 [7680/8000 (96%)]\tTotal Loss: 0.089378\n",
      "Reconstruction: 0.089375, Regularization: 0.000003\n",
      "2019-04-09 23:38:45,460 root         INFO     ====> Epoch: 71 Average loss: 0.0887\n",
      "2019-04-09 23:38:45,484 root         INFO     Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 0.094098\n",
      "Reconstruction: 0.094094, Regularization: 0.000004\n",
      "2019-04-09 23:38:45,549 root         INFO     Train Epoch: 72 [512/8000 (6%)]\tTotal Loss: 0.091146\n",
      "Reconstruction: 0.091143, Regularization: 0.000003\n",
      "2019-04-09 23:38:45,613 root         INFO     Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 0.080959\n",
      "Reconstruction: 0.080958, Regularization: 0.000002\n",
      "2019-04-09 23:38:45,676 root         INFO     Train Epoch: 72 [1536/8000 (19%)]\tTotal Loss: 0.093954\n",
      "Reconstruction: 0.093950, Regularization: 0.000004\n",
      "2019-04-09 23:38:45,740 root         INFO     Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 0.080258\n",
      "Reconstruction: 0.080256, Regularization: 0.000002\n",
      "2019-04-09 23:38:45,804 root         INFO     Train Epoch: 72 [2560/8000 (32%)]\tTotal Loss: 0.089733\n",
      "Reconstruction: 0.089730, Regularization: 0.000003\n",
      "2019-04-09 23:38:45,867 root         INFO     Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 0.088452\n",
      "Reconstruction: 0.088449, Regularization: 0.000003\n",
      "2019-04-09 23:38:45,930 root         INFO     Train Epoch: 72 [3584/8000 (45%)]\tTotal Loss: 0.086827\n",
      "Reconstruction: 0.086823, Regularization: 0.000004\n",
      "2019-04-09 23:38:45,994 root         INFO     Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 0.090782\n",
      "Reconstruction: 0.090778, Regularization: 0.000004\n",
      "2019-04-09 23:38:46,057 root         INFO     Train Epoch: 72 [4608/8000 (58%)]\tTotal Loss: 0.089634\n",
      "Reconstruction: 0.089632, Regularization: 0.000003\n",
      "2019-04-09 23:38:46,119 root         INFO     Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 0.084996\n",
      "Reconstruction: 0.084994, Regularization: 0.000002\n",
      "2019-04-09 23:38:46,183 root         INFO     Train Epoch: 72 [5632/8000 (70%)]\tTotal Loss: 0.095436\n",
      "Reconstruction: 0.095432, Regularization: 0.000004\n",
      "2019-04-09 23:38:46,246 root         INFO     Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 0.084807\n",
      "Reconstruction: 0.084805, Regularization: 0.000002\n",
      "2019-04-09 23:38:46,309 root         INFO     Train Epoch: 72 [6656/8000 (83%)]\tTotal Loss: 0.085367\n",
      "Reconstruction: 0.085364, Regularization: 0.000003\n",
      "2019-04-09 23:38:46,372 root         INFO     Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 0.089261\n",
      "Reconstruction: 0.089258, Regularization: 0.000004\n",
      "2019-04-09 23:38:46,435 root         INFO     Train Epoch: 72 [7680/8000 (96%)]\tTotal Loss: 0.098182\n",
      "Reconstruction: 0.098177, Regularization: 0.000006\n",
      "2019-04-09 23:38:46,489 root         INFO     ====> Epoch: 72 Average loss: 0.0887\n",
      "2019-04-09 23:38:46,513 root         INFO     Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 0.086324\n",
      "Reconstruction: 0.086321, Regularization: 0.000003\n",
      "2019-04-09 23:38:46,577 root         INFO     Train Epoch: 73 [512/8000 (6%)]\tTotal Loss: 0.093051\n",
      "Reconstruction: 0.093045, Regularization: 0.000006\n",
      "2019-04-09 23:38:46,642 root         INFO     Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 0.084501\n",
      "Reconstruction: 0.084497, Regularization: 0.000004\n",
      "2019-04-09 23:38:46,705 root         INFO     Train Epoch: 73 [1536/8000 (19%)]\tTotal Loss: 0.090119\n",
      "Reconstruction: 0.090113, Regularization: 0.000006\n",
      "2019-04-09 23:38:46,769 root         INFO     Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 0.084635\n",
      "Reconstruction: 0.084631, Regularization: 0.000004\n",
      "2019-04-09 23:38:46,833 root         INFO     Train Epoch: 73 [2560/8000 (32%)]\tTotal Loss: 0.088281\n",
      "Reconstruction: 0.088277, Regularization: 0.000003\n",
      "2019-04-09 23:38:46,897 root         INFO     Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 0.095292\n",
      "Reconstruction: 0.095288, Regularization: 0.000004\n",
      "2019-04-09 23:38:46,961 root         INFO     Train Epoch: 73 [3584/8000 (45%)]\tTotal Loss: 0.080327\n",
      "Reconstruction: 0.080324, Regularization: 0.000003\n",
      "2019-04-09 23:38:47,024 root         INFO     Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 0.083449\n",
      "Reconstruction: 0.083447, Regularization: 0.000002\n",
      "2019-04-09 23:38:47,087 root         INFO     Train Epoch: 73 [4608/8000 (58%)]\tTotal Loss: 0.087329\n",
      "Reconstruction: 0.087325, Regularization: 0.000004\n",
      "2019-04-09 23:38:47,151 root         INFO     Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 0.089269\n",
      "Reconstruction: 0.089265, Regularization: 0.000004\n",
      "2019-04-09 23:38:47,215 root         INFO     Train Epoch: 73 [5632/8000 (70%)]\tTotal Loss: 0.094810\n",
      "Reconstruction: 0.094806, Regularization: 0.000004\n",
      "2019-04-09 23:38:47,278 root         INFO     Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 0.090025\n",
      "Reconstruction: 0.090021, Regularization: 0.000005\n",
      "2019-04-09 23:38:47,341 root         INFO     Train Epoch: 73 [6656/8000 (83%)]\tTotal Loss: 0.087555\n",
      "Reconstruction: 0.087552, Regularization: 0.000004\n",
      "2019-04-09 23:38:47,405 root         INFO     Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 0.092426\n",
      "Reconstruction: 0.092423, Regularization: 0.000003\n",
      "2019-04-09 23:38:47,468 root         INFO     Train Epoch: 73 [7680/8000 (96%)]\tTotal Loss: 0.083811\n",
      "Reconstruction: 0.083809, Regularization: 0.000002\n",
      "2019-04-09 23:38:47,522 root         INFO     ====> Epoch: 73 Average loss: 0.0887\n",
      "2019-04-09 23:38:47,546 root         INFO     Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 0.085680\n",
      "Reconstruction: 0.085678, Regularization: 0.000002\n",
      "2019-04-09 23:38:47,611 root         INFO     Train Epoch: 74 [512/8000 (6%)]\tTotal Loss: 0.083886\n",
      "Reconstruction: 0.083884, Regularization: 0.000002\n",
      "2019-04-09 23:38:47,676 root         INFO     Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 0.084442\n",
      "Reconstruction: 0.084441, Regularization: 0.000002\n",
      "2019-04-09 23:38:47,740 root         INFO     Train Epoch: 74 [1536/8000 (19%)]\tTotal Loss: 0.086668\n",
      "Reconstruction: 0.086666, Regularization: 0.000002\n",
      "2019-04-09 23:38:47,804 root         INFO     Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 0.081881\n",
      "Reconstruction: 0.081880, Regularization: 0.000001\n",
      "2019-04-09 23:38:47,867 root         INFO     Train Epoch: 74 [2560/8000 (32%)]\tTotal Loss: 0.079584\n",
      "Reconstruction: 0.079583, Regularization: 0.000001\n",
      "2019-04-09 23:38:47,931 root         INFO     Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 0.098608\n",
      "Reconstruction: 0.098607, Regularization: 0.000001\n",
      "2019-04-09 23:38:47,993 root         INFO     Train Epoch: 74 [3584/8000 (45%)]\tTotal Loss: 0.087537\n",
      "Reconstruction: 0.087536, Regularization: 0.000001\n",
      "2019-04-09 23:38:48,056 root         INFO     Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 0.083567\n",
      "Reconstruction: 0.083566, Regularization: 0.000001\n",
      "2019-04-09 23:38:48,119 root         INFO     Train Epoch: 74 [4608/8000 (58%)]\tTotal Loss: 0.082387\n",
      "Reconstruction: 0.082387, Regularization: 0.000001\n",
      "2019-04-09 23:38:48,182 root         INFO     Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 0.095230\n",
      "Reconstruction: 0.095229, Regularization: 0.000001\n",
      "2019-04-09 23:38:48,245 root         INFO     Train Epoch: 74 [5632/8000 (70%)]\tTotal Loss: 0.084336\n",
      "Reconstruction: 0.084336, Regularization: 0.000001\n",
      "2019-04-09 23:38:48,308 root         INFO     Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 0.093310\n",
      "Reconstruction: 0.093308, Regularization: 0.000002\n",
      "2019-04-09 23:38:48,371 root         INFO     Train Epoch: 74 [6656/8000 (83%)]\tTotal Loss: 0.092188\n",
      "Reconstruction: 0.092186, Regularization: 0.000002\n",
      "2019-04-09 23:38:48,434 root         INFO     Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 0.080358\n",
      "Reconstruction: 0.080357, Regularization: 0.000001\n",
      "2019-04-09 23:38:48,496 root         INFO     Train Epoch: 74 [7680/8000 (96%)]\tTotal Loss: 0.084819\n",
      "Reconstruction: 0.084818, Regularization: 0.000001\n",
      "2019-04-09 23:38:48,550 root         INFO     ====> Epoch: 74 Average loss: 0.0887\n",
      "2019-04-09 23:38:48,574 root         INFO     Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 0.088140\n",
      "Reconstruction: 0.088138, Regularization: 0.000002\n",
      "2019-04-09 23:38:48,638 root         INFO     Train Epoch: 75 [512/8000 (6%)]\tTotal Loss: 0.090489\n",
      "Reconstruction: 0.090487, Regularization: 0.000002\n",
      "2019-04-09 23:38:48,707 root         INFO     Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 0.091043\n",
      "Reconstruction: 0.091041, Regularization: 0.000002\n",
      "2019-04-09 23:38:48,772 root         INFO     Train Epoch: 75 [1536/8000 (19%)]\tTotal Loss: 0.087309\n",
      "Reconstruction: 0.087307, Regularization: 0.000001\n",
      "2019-04-09 23:38:48,836 root         INFO     Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 0.093246\n",
      "Reconstruction: 0.093244, Regularization: 0.000002\n",
      "2019-04-09 23:38:48,899 root         INFO     Train Epoch: 75 [2560/8000 (32%)]\tTotal Loss: 0.096699\n",
      "Reconstruction: 0.096696, Regularization: 0.000003\n",
      "2019-04-09 23:38:48,962 root         INFO     Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 0.087728\n",
      "Reconstruction: 0.087726, Regularization: 0.000003\n",
      "2019-04-09 23:38:49,025 root         INFO     Train Epoch: 75 [3584/8000 (45%)]\tTotal Loss: 0.091526\n",
      "Reconstruction: 0.091524, Regularization: 0.000003\n",
      "2019-04-09 23:38:49,088 root         INFO     Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 0.083395\n",
      "Reconstruction: 0.083392, Regularization: 0.000003\n",
      "2019-04-09 23:38:49,150 root         INFO     Train Epoch: 75 [4608/8000 (58%)]\tTotal Loss: 0.088478\n",
      "Reconstruction: 0.088476, Regularization: 0.000002\n",
      "2019-04-09 23:38:49,213 root         INFO     Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 0.082183\n",
      "Reconstruction: 0.082182, Regularization: 0.000001\n",
      "2019-04-09 23:38:49,276 root         INFO     Train Epoch: 75 [5632/8000 (70%)]\tTotal Loss: 0.087724\n",
      "Reconstruction: 0.087723, Regularization: 0.000002\n",
      "2019-04-09 23:38:49,339 root         INFO     Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 0.089585\n",
      "Reconstruction: 0.089582, Regularization: 0.000002\n",
      "2019-04-09 23:38:49,401 root         INFO     Train Epoch: 75 [6656/8000 (83%)]\tTotal Loss: 0.098862\n",
      "Reconstruction: 0.098860, Regularization: 0.000003\n",
      "2019-04-09 23:38:49,463 root         INFO     Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 0.088285\n",
      "Reconstruction: 0.088282, Regularization: 0.000003\n",
      "2019-04-09 23:38:49,525 root         INFO     Train Epoch: 75 [7680/8000 (96%)]\tTotal Loss: 0.091389\n",
      "Reconstruction: 0.091386, Regularization: 0.000003\n",
      "2019-04-09 23:38:49,578 root         INFO     ====> Epoch: 75 Average loss: 0.0887\n",
      "2019-04-09 23:38:49,603 root         INFO     Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 0.083494\n",
      "Reconstruction: 0.083491, Regularization: 0.000003\n",
      "2019-04-09 23:38:49,667 root         INFO     Train Epoch: 76 [512/8000 (6%)]\tTotal Loss: 0.088422\n",
      "Reconstruction: 0.088419, Regularization: 0.000003\n",
      "2019-04-09 23:38:49,730 root         INFO     Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 0.093622\n",
      "Reconstruction: 0.093621, Regularization: 0.000001\n",
      "2019-04-09 23:38:49,793 root         INFO     Train Epoch: 76 [1536/8000 (19%)]\tTotal Loss: 0.096289\n",
      "Reconstruction: 0.096287, Regularization: 0.000002\n",
      "2019-04-09 23:38:49,855 root         INFO     Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 0.083001\n",
      "Reconstruction: 0.082999, Regularization: 0.000002\n",
      "2019-04-09 23:38:49,916 root         INFO     Train Epoch: 76 [2560/8000 (32%)]\tTotal Loss: 0.082409\n",
      "Reconstruction: 0.082407, Regularization: 0.000002\n",
      "2019-04-09 23:38:49,977 root         INFO     Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 0.086687\n",
      "Reconstruction: 0.086685, Regularization: 0.000002\n",
      "2019-04-09 23:38:50,038 root         INFO     Train Epoch: 76 [3584/8000 (45%)]\tTotal Loss: 0.081964\n",
      "Reconstruction: 0.081963, Regularization: 0.000001\n",
      "2019-04-09 23:38:50,099 root         INFO     Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 0.081451\n",
      "Reconstruction: 0.081450, Regularization: 0.000001\n",
      "2019-04-09 23:38:50,160 root         INFO     Train Epoch: 76 [4608/8000 (58%)]\tTotal Loss: 0.080603\n",
      "Reconstruction: 0.080602, Regularization: 0.000001\n",
      "2019-04-09 23:38:50,220 root         INFO     Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 0.098639\n",
      "Reconstruction: 0.098637, Regularization: 0.000001\n",
      "2019-04-09 23:38:50,281 root         INFO     Train Epoch: 76 [5632/8000 (70%)]\tTotal Loss: 0.081351\n",
      "Reconstruction: 0.081351, Regularization: 0.000000\n",
      "2019-04-09 23:38:50,343 root         INFO     Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 0.092533\n",
      "Reconstruction: 0.092533, Regularization: 0.000001\n",
      "2019-04-09 23:38:50,405 root         INFO     Train Epoch: 76 [6656/8000 (83%)]\tTotal Loss: 0.084508\n",
      "Reconstruction: 0.084508, Regularization: 0.000001\n",
      "2019-04-09 23:38:50,467 root         INFO     Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 0.092165\n",
      "Reconstruction: 0.092164, Regularization: 0.000001\n",
      "2019-04-09 23:38:50,531 root         INFO     Train Epoch: 76 [7680/8000 (96%)]\tTotal Loss: 0.084674\n",
      "Reconstruction: 0.084673, Regularization: 0.000001\n",
      "2019-04-09 23:38:50,584 root         INFO     ====> Epoch: 76 Average loss: 0.0887\n",
      "2019-04-09 23:38:50,608 root         INFO     Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 0.084060\n",
      "Reconstruction: 0.084059, Regularization: 0.000001\n",
      "2019-04-09 23:38:50,673 root         INFO     Train Epoch: 77 [512/8000 (6%)]\tTotal Loss: 0.088763\n",
      "Reconstruction: 0.088763, Regularization: 0.000001\n",
      "2019-04-09 23:38:50,736 root         INFO     Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 0.097939\n",
      "Reconstruction: 0.097938, Regularization: 0.000001\n",
      "2019-04-09 23:38:50,799 root         INFO     Train Epoch: 77 [1536/8000 (19%)]\tTotal Loss: 0.083796\n",
      "Reconstruction: 0.083796, Regularization: 0.000000\n",
      "2019-04-09 23:38:50,862 root         INFO     Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 0.091672\n",
      "Reconstruction: 0.091671, Regularization: 0.000001\n",
      "2019-04-09 23:38:50,925 root         INFO     Train Epoch: 77 [2560/8000 (32%)]\tTotal Loss: 0.090263\n",
      "Reconstruction: 0.090262, Regularization: 0.000001\n",
      "2019-04-09 23:38:50,989 root         INFO     Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 0.079731\n",
      "Reconstruction: 0.079730, Regularization: 0.000001\n",
      "2019-04-09 23:38:51,053 root         INFO     Train Epoch: 77 [3584/8000 (45%)]\tTotal Loss: 0.093110\n",
      "Reconstruction: 0.093109, Regularization: 0.000001\n",
      "2019-04-09 23:38:51,115 root         INFO     Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 0.085021\n",
      "Reconstruction: 0.085020, Regularization: 0.000001\n",
      "2019-04-09 23:38:51,179 root         INFO     Train Epoch: 77 [4608/8000 (58%)]\tTotal Loss: 0.086581\n",
      "Reconstruction: 0.086580, Regularization: 0.000000\n",
      "2019-04-09 23:38:51,243 root         INFO     Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 0.087950\n",
      "Reconstruction: 0.087950, Regularization: 0.000000\n",
      "2019-04-09 23:38:51,307 root         INFO     Train Epoch: 77 [5632/8000 (70%)]\tTotal Loss: 0.089926\n",
      "Reconstruction: 0.089926, Regularization: 0.000000\n",
      "2019-04-09 23:38:51,371 root         INFO     Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 0.088284\n",
      "Reconstruction: 0.088284, Regularization: 0.000000\n",
      "2019-04-09 23:38:51,434 root         INFO     Train Epoch: 77 [6656/8000 (83%)]\tTotal Loss: 0.096082\n",
      "Reconstruction: 0.096082, Regularization: 0.000000\n",
      "2019-04-09 23:38:51,497 root         INFO     Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 0.096516\n",
      "Reconstruction: 0.096516, Regularization: 0.000000\n",
      "2019-04-09 23:38:51,561 root         INFO     Train Epoch: 77 [7680/8000 (96%)]\tTotal Loss: 0.089631\n",
      "Reconstruction: 0.089631, Regularization: 0.000000\n",
      "2019-04-09 23:38:51,615 root         INFO     ====> Epoch: 77 Average loss: 0.0887\n",
      "2019-04-09 23:38:51,639 root         INFO     Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 0.092594\n",
      "Reconstruction: 0.092594, Regularization: 0.000000\n",
      "2019-04-09 23:38:51,704 root         INFO     Train Epoch: 78 [512/8000 (6%)]\tTotal Loss: 0.085354\n",
      "Reconstruction: 0.085354, Regularization: 0.000000\n",
      "2019-04-09 23:38:51,767 root         INFO     Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 0.084237\n",
      "Reconstruction: 0.084237, Regularization: 0.000000\n",
      "2019-04-09 23:38:51,831 root         INFO     Train Epoch: 78 [1536/8000 (19%)]\tTotal Loss: 0.084653\n",
      "Reconstruction: 0.084653, Regularization: 0.000000\n",
      "2019-04-09 23:38:51,894 root         INFO     Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 0.089320\n",
      "Reconstruction: 0.089320, Regularization: 0.000000\n",
      "2019-04-09 23:38:51,958 root         INFO     Train Epoch: 78 [2560/8000 (32%)]\tTotal Loss: 0.083034\n",
      "Reconstruction: 0.083034, Regularization: 0.000000\n",
      "2019-04-09 23:38:52,021 root         INFO     Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 0.088500\n",
      "Reconstruction: 0.088500, Regularization: 0.000000\n",
      "2019-04-09 23:38:52,085 root         INFO     Train Epoch: 78 [3584/8000 (45%)]\tTotal Loss: 0.080862\n",
      "Reconstruction: 0.080862, Regularization: 0.000000\n",
      "2019-04-09 23:38:52,148 root         INFO     Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 0.094811\n",
      "Reconstruction: 0.094810, Regularization: 0.000001\n",
      "2019-04-09 23:38:52,211 root         INFO     Train Epoch: 78 [4608/8000 (58%)]\tTotal Loss: 0.082770\n",
      "Reconstruction: 0.082769, Regularization: 0.000001\n",
      "2019-04-09 23:38:52,275 root         INFO     Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 0.082146\n",
      "Reconstruction: 0.082145, Regularization: 0.000001\n",
      "2019-04-09 23:38:52,339 root         INFO     Train Epoch: 78 [5632/8000 (70%)]\tTotal Loss: 0.092819\n",
      "Reconstruction: 0.092818, Regularization: 0.000001\n",
      "2019-04-09 23:38:52,402 root         INFO     Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 0.083748\n",
      "Reconstruction: 0.083747, Regularization: 0.000000\n",
      "2019-04-09 23:38:52,466 root         INFO     Train Epoch: 78 [6656/8000 (83%)]\tTotal Loss: 0.094232\n",
      "Reconstruction: 0.094231, Regularization: 0.000001\n",
      "2019-04-09 23:38:52,530 root         INFO     Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 0.103876\n",
      "Reconstruction: 0.103875, Regularization: 0.000001\n",
      "2019-04-09 23:38:52,593 root         INFO     Train Epoch: 78 [7680/8000 (96%)]\tTotal Loss: 0.089772\n",
      "Reconstruction: 0.089772, Regularization: 0.000000\n",
      "2019-04-09 23:38:52,646 root         INFO     ====> Epoch: 78 Average loss: 0.0887\n",
      "2019-04-09 23:38:52,670 root         INFO     Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 0.081179\n",
      "Reconstruction: 0.081179, Regularization: 0.000000\n",
      "2019-04-09 23:38:52,733 root         INFO     Train Epoch: 79 [512/8000 (6%)]\tTotal Loss: 0.088803\n",
      "Reconstruction: 0.088803, Regularization: 0.000000\n",
      "2019-04-09 23:38:52,797 root         INFO     Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 0.083962\n",
      "Reconstruction: 0.083962, Regularization: 0.000000\n",
      "2019-04-09 23:38:52,860 root         INFO     Train Epoch: 79 [1536/8000 (19%)]\tTotal Loss: 0.087688\n",
      "Reconstruction: 0.087688, Regularization: 0.000000\n",
      "2019-04-09 23:38:52,923 root         INFO     Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 0.087511\n",
      "Reconstruction: 0.087511, Regularization: 0.000000\n",
      "2019-04-09 23:38:52,986 root         INFO     Train Epoch: 79 [2560/8000 (32%)]\tTotal Loss: 0.088547\n",
      "Reconstruction: 0.088547, Regularization: 0.000000\n",
      "2019-04-09 23:38:53,049 root         INFO     Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 0.102007\n",
      "Reconstruction: 0.102007, Regularization: 0.000000\n",
      "2019-04-09 23:38:53,112 root         INFO     Train Epoch: 79 [3584/8000 (45%)]\tTotal Loss: 0.091162\n",
      "Reconstruction: 0.091162, Regularization: 0.000000\n",
      "2019-04-09 23:38:53,176 root         INFO     Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 0.095585\n",
      "Reconstruction: 0.095585, Regularization: 0.000000\n",
      "2019-04-09 23:38:53,239 root         INFO     Train Epoch: 79 [4608/8000 (58%)]\tTotal Loss: 0.087762\n",
      "Reconstruction: 0.087762, Regularization: 0.000000\n",
      "2019-04-09 23:38:53,302 root         INFO     Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 0.086785\n",
      "Reconstruction: 0.086784, Regularization: 0.000000\n",
      "2019-04-09 23:38:53,366 root         INFO     Train Epoch: 79 [5632/8000 (70%)]\tTotal Loss: 0.094072\n",
      "Reconstruction: 0.094072, Regularization: 0.000000\n",
      "2019-04-09 23:38:53,429 root         INFO     Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 0.090369\n",
      "Reconstruction: 0.090369, Regularization: 0.000000\n",
      "2019-04-09 23:38:53,492 root         INFO     Train Epoch: 79 [6656/8000 (83%)]\tTotal Loss: 0.093742\n",
      "Reconstruction: 0.093742, Regularization: 0.000000\n",
      "2019-04-09 23:38:53,555 root         INFO     Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 0.098620\n",
      "Reconstruction: 0.098620, Regularization: 0.000000\n",
      "2019-04-09 23:38:53,619 root         INFO     Train Epoch: 79 [7680/8000 (96%)]\tTotal Loss: 0.083535\n",
      "Reconstruction: 0.083535, Regularization: 0.000000\n",
      "2019-04-09 23:38:53,673 root         INFO     ====> Epoch: 79 Average loss: 0.0887\n",
      "2019-04-09 23:38:53,697 root         INFO     Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 0.086599\n",
      "Reconstruction: 0.086599, Regularization: 0.000000\n",
      "2019-04-09 23:38:53,761 root         INFO     Train Epoch: 80 [512/8000 (6%)]\tTotal Loss: 0.088194\n",
      "Reconstruction: 0.088194, Regularization: 0.000000\n",
      "2019-04-09 23:38:53,823 root         INFO     Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 0.098333\n",
      "Reconstruction: 0.098333, Regularization: 0.000000\n",
      "2019-04-09 23:38:53,886 root         INFO     Train Epoch: 80 [1536/8000 (19%)]\tTotal Loss: 0.099686\n",
      "Reconstruction: 0.099685, Regularization: 0.000000\n",
      "2019-04-09 23:38:53,949 root         INFO     Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 0.100262\n",
      "Reconstruction: 0.100262, Regularization: 0.000000\n",
      "2019-04-09 23:38:54,011 root         INFO     Train Epoch: 80 [2560/8000 (32%)]\tTotal Loss: 0.082899\n",
      "Reconstruction: 0.082899, Regularization: 0.000000\n",
      "2019-04-09 23:38:54,074 root         INFO     Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 0.094865\n",
      "Reconstruction: 0.094864, Regularization: 0.000000\n",
      "2019-04-09 23:38:54,136 root         INFO     Train Epoch: 80 [3584/8000 (45%)]\tTotal Loss: 0.093634\n",
      "Reconstruction: 0.093634, Regularization: 0.000000\n",
      "2019-04-09 23:38:54,199 root         INFO     Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 0.087911\n",
      "Reconstruction: 0.087911, Regularization: 0.000000\n",
      "2019-04-09 23:38:54,261 root         INFO     Train Epoch: 80 [4608/8000 (58%)]\tTotal Loss: 0.100707\n",
      "Reconstruction: 0.100707, Regularization: 0.000000\n",
      "2019-04-09 23:38:54,324 root         INFO     Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 0.086023\n",
      "Reconstruction: 0.086023, Regularization: 0.000000\n",
      "2019-04-09 23:38:54,386 root         INFO     Train Epoch: 80 [5632/8000 (70%)]\tTotal Loss: 0.094663\n",
      "Reconstruction: 0.094663, Regularization: 0.000000\n",
      "2019-04-09 23:38:54,449 root         INFO     Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 0.080751\n",
      "Reconstruction: 0.080751, Regularization: 0.000000\n",
      "2019-04-09 23:38:54,512 root         INFO     Train Epoch: 80 [6656/8000 (83%)]\tTotal Loss: 0.089638\n",
      "Reconstruction: 0.089638, Regularization: 0.000000\n",
      "2019-04-09 23:38:54,575 root         INFO     Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 0.106836\n",
      "Reconstruction: 0.106836, Regularization: 0.000000\n",
      "2019-04-09 23:38:54,639 root         INFO     Train Epoch: 80 [7680/8000 (96%)]\tTotal Loss: 0.087403\n",
      "Reconstruction: 0.087402, Regularization: 0.000000\n",
      "2019-04-09 23:38:54,692 root         INFO     ====> Epoch: 80 Average loss: 0.0887\n",
      "2019-04-09 23:38:54,716 root         INFO     Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 0.087499\n",
      "Reconstruction: 0.087498, Regularization: 0.000000\n",
      "2019-04-09 23:38:54,779 root         INFO     Train Epoch: 81 [512/8000 (6%)]\tTotal Loss: 0.089998\n",
      "Reconstruction: 0.089997, Regularization: 0.000001\n",
      "2019-04-09 23:38:54,842 root         INFO     Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 0.086188\n",
      "Reconstruction: 0.086187, Regularization: 0.000000\n",
      "2019-04-09 23:38:54,906 root         INFO     Train Epoch: 81 [1536/8000 (19%)]\tTotal Loss: 0.091649\n",
      "Reconstruction: 0.091649, Regularization: 0.000001\n",
      "2019-04-09 23:38:54,969 root         INFO     Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 0.087799\n",
      "Reconstruction: 0.087798, Regularization: 0.000001\n",
      "2019-04-09 23:38:55,032 root         INFO     Train Epoch: 81 [2560/8000 (32%)]\tTotal Loss: 0.087695\n",
      "Reconstruction: 0.087693, Regularization: 0.000001\n",
      "2019-04-09 23:38:55,095 root         INFO     Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 0.084805\n",
      "Reconstruction: 0.084804, Regularization: 0.000001\n",
      "2019-04-09 23:38:55,157 root         INFO     Train Epoch: 81 [3584/8000 (45%)]\tTotal Loss: 0.088934\n",
      "Reconstruction: 0.088933, Regularization: 0.000001\n",
      "2019-04-09 23:38:55,220 root         INFO     Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 0.090057\n",
      "Reconstruction: 0.090057, Regularization: 0.000000\n",
      "2019-04-09 23:38:55,283 root         INFO     Train Epoch: 81 [4608/8000 (58%)]\tTotal Loss: 0.091592\n",
      "Reconstruction: 0.091592, Regularization: 0.000000\n",
      "2019-04-09 23:38:55,345 root         INFO     Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 0.098409\n",
      "Reconstruction: 0.098408, Regularization: 0.000000\n",
      "2019-04-09 23:38:55,409 root         INFO     Train Epoch: 81 [5632/8000 (70%)]\tTotal Loss: 0.080629\n",
      "Reconstruction: 0.080629, Regularization: 0.000000\n",
      "2019-04-09 23:38:55,472 root         INFO     Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 0.083667\n",
      "Reconstruction: 0.083667, Regularization: 0.000000\n",
      "2019-04-09 23:38:55,534 root         INFO     Train Epoch: 81 [6656/8000 (83%)]\tTotal Loss: 0.084865\n",
      "Reconstruction: 0.084864, Regularization: 0.000000\n",
      "2019-04-09 23:38:55,597 root         INFO     Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 0.084346\n",
      "Reconstruction: 0.084346, Regularization: 0.000000\n",
      "2019-04-09 23:38:55,660 root         INFO     Train Epoch: 81 [7680/8000 (96%)]\tTotal Loss: 0.090951\n",
      "Reconstruction: 0.090951, Regularization: 0.000001\n",
      "2019-04-09 23:38:55,714 root         INFO     ====> Epoch: 81 Average loss: 0.0887\n",
      "2019-04-09 23:38:55,738 root         INFO     Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 0.090820\n",
      "Reconstruction: 0.090820, Regularization: 0.000000\n",
      "2019-04-09 23:38:55,802 root         INFO     Train Epoch: 82 [512/8000 (6%)]\tTotal Loss: 0.098062\n",
      "Reconstruction: 0.098062, Regularization: 0.000000\n",
      "2019-04-09 23:38:55,864 root         INFO     Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 0.086557\n",
      "Reconstruction: 0.086557, Regularization: 0.000000\n",
      "2019-04-09 23:38:55,927 root         INFO     Train Epoch: 82 [1536/8000 (19%)]\tTotal Loss: 0.085076\n",
      "Reconstruction: 0.085076, Regularization: 0.000000\n",
      "2019-04-09 23:38:55,990 root         INFO     Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 0.095592\n",
      "Reconstruction: 0.095592, Regularization: 0.000000\n",
      "2019-04-09 23:38:56,053 root         INFO     Train Epoch: 82 [2560/8000 (32%)]\tTotal Loss: 0.097455\n",
      "Reconstruction: 0.097455, Regularization: 0.000000\n",
      "2019-04-09 23:38:56,116 root         INFO     Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 0.086911\n",
      "Reconstruction: 0.086911, Regularization: 0.000000\n",
      "2019-04-09 23:38:56,178 root         INFO     Train Epoch: 82 [3584/8000 (45%)]\tTotal Loss: 0.099213\n",
      "Reconstruction: 0.099213, Regularization: 0.000000\n",
      "2019-04-09 23:38:56,241 root         INFO     Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 0.094165\n",
      "Reconstruction: 0.094164, Regularization: 0.000000\n",
      "2019-04-09 23:38:56,304 root         INFO     Train Epoch: 82 [4608/8000 (58%)]\tTotal Loss: 0.095302\n",
      "Reconstruction: 0.095301, Regularization: 0.000000\n",
      "2019-04-09 23:38:56,367 root         INFO     Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 0.084419\n",
      "Reconstruction: 0.084419, Regularization: 0.000000\n",
      "2019-04-09 23:38:56,430 root         INFO     Train Epoch: 82 [5632/8000 (70%)]\tTotal Loss: 0.095233\n",
      "Reconstruction: 0.095233, Regularization: 0.000000\n",
      "2019-04-09 23:38:56,494 root         INFO     Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 0.080990\n",
      "Reconstruction: 0.080990, Regularization: 0.000000\n",
      "2019-04-09 23:38:56,557 root         INFO     Train Epoch: 82 [6656/8000 (83%)]\tTotal Loss: 0.090454\n",
      "Reconstruction: 0.090454, Regularization: 0.000000\n",
      "2019-04-09 23:38:56,620 root         INFO     Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 0.085352\n",
      "Reconstruction: 0.085352, Regularization: 0.000000\n",
      "2019-04-09 23:38:56,682 root         INFO     Train Epoch: 82 [7680/8000 (96%)]\tTotal Loss: 0.088851\n",
      "Reconstruction: 0.088851, Regularization: 0.000000\n",
      "2019-04-09 23:38:56,736 root         INFO     ====> Epoch: 82 Average loss: 0.0887\n",
      "2019-04-09 23:38:56,760 root         INFO     Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 0.090152\n",
      "Reconstruction: 0.090152, Regularization: 0.000000\n",
      "2019-04-09 23:38:56,823 root         INFO     Train Epoch: 83 [512/8000 (6%)]\tTotal Loss: 0.092785\n",
      "Reconstruction: 0.092785, Regularization: 0.000000\n",
      "2019-04-09 23:38:56,886 root         INFO     Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 0.093856\n",
      "Reconstruction: 0.093856, Regularization: 0.000000\n",
      "2019-04-09 23:38:56,949 root         INFO     Train Epoch: 83 [1536/8000 (19%)]\tTotal Loss: 0.085028\n",
      "Reconstruction: 0.085028, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,011 root         INFO     Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 0.085575\n",
      "Reconstruction: 0.085575, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,074 root         INFO     Train Epoch: 83 [2560/8000 (32%)]\tTotal Loss: 0.092245\n",
      "Reconstruction: 0.092245, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,137 root         INFO     Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 0.092480\n",
      "Reconstruction: 0.092480, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,200 root         INFO     Train Epoch: 83 [3584/8000 (45%)]\tTotal Loss: 0.082791\n",
      "Reconstruction: 0.082791, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,263 root         INFO     Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 0.088037\n",
      "Reconstruction: 0.088037, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,325 root         INFO     Train Epoch: 83 [4608/8000 (58%)]\tTotal Loss: 0.095686\n",
      "Reconstruction: 0.095685, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,389 root         INFO     Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 0.087191\n",
      "Reconstruction: 0.087191, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,453 root         INFO     Train Epoch: 83 [5632/8000 (70%)]\tTotal Loss: 0.082503\n",
      "Reconstruction: 0.082503, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,517 root         INFO     Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 0.082223\n",
      "Reconstruction: 0.082223, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,580 root         INFO     Train Epoch: 83 [6656/8000 (83%)]\tTotal Loss: 0.089347\n",
      "Reconstruction: 0.089347, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,643 root         INFO     Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 0.092889\n",
      "Reconstruction: 0.092889, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,707 root         INFO     Train Epoch: 83 [7680/8000 (96%)]\tTotal Loss: 0.086699\n",
      "Reconstruction: 0.086699, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,760 root         INFO     ====> Epoch: 83 Average loss: 0.0887\n",
      "2019-04-09 23:38:57,785 root         INFO     Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 0.082516\n",
      "Reconstruction: 0.082516, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,848 root         INFO     Train Epoch: 84 [512/8000 (6%)]\tTotal Loss: 0.093748\n",
      "Reconstruction: 0.093748, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,912 root         INFO     Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 0.082085\n",
      "Reconstruction: 0.082085, Regularization: 0.000000\n",
      "2019-04-09 23:38:57,975 root         INFO     Train Epoch: 84 [1536/8000 (19%)]\tTotal Loss: 0.094240\n",
      "Reconstruction: 0.094240, Regularization: 0.000000\n",
      "2019-04-09 23:38:58,038 root         INFO     Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 0.087641\n",
      "Reconstruction: 0.087641, Regularization: 0.000000\n",
      "2019-04-09 23:38:58,101 root         INFO     Train Epoch: 84 [2560/8000 (32%)]\tTotal Loss: 0.096413\n",
      "Reconstruction: 0.096413, Regularization: 0.000000\n",
      "2019-04-09 23:38:58,164 root         INFO     Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 0.101682\n",
      "Reconstruction: 0.101682, Regularization: 0.000000\n",
      "2019-04-09 23:38:58,227 root         INFO     Train Epoch: 84 [3584/8000 (45%)]\tTotal Loss: 0.092982\n",
      "Reconstruction: 0.092982, Regularization: 0.000000\n",
      "2019-04-09 23:38:58,290 root         INFO     Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 0.087302\n",
      "Reconstruction: 0.087302, Regularization: 0.000000\n",
      "2019-04-09 23:38:58,353 root         INFO     Train Epoch: 84 [4608/8000 (58%)]\tTotal Loss: 0.088013\n",
      "Reconstruction: 0.088013, Regularization: 0.000000\n",
      "2019-04-09 23:38:58,416 root         INFO     Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 0.084029\n",
      "Reconstruction: 0.084029, Regularization: 0.000000\n",
      "2019-04-09 23:38:58,478 root         INFO     Train Epoch: 84 [5632/8000 (70%)]\tTotal Loss: 0.086077\n",
      "Reconstruction: 0.086077, Regularization: 0.000001\n",
      "2019-04-09 23:38:58,540 root         INFO     Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 0.088586\n",
      "Reconstruction: 0.088585, Regularization: 0.000001\n",
      "2019-04-09 23:38:58,603 root         INFO     Train Epoch: 84 [6656/8000 (83%)]\tTotal Loss: 0.097094\n",
      "Reconstruction: 0.097093, Regularization: 0.000001\n",
      "2019-04-09 23:38:58,665 root         INFO     Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 0.089866\n",
      "Reconstruction: 0.089866, Regularization: 0.000001\n",
      "2019-04-09 23:38:58,727 root         INFO     Train Epoch: 84 [7680/8000 (96%)]\tTotal Loss: 0.082398\n",
      "Reconstruction: 0.082398, Regularization: 0.000000\n",
      "2019-04-09 23:38:58,780 root         INFO     ====> Epoch: 84 Average loss: 0.0887\n",
      "2019-04-09 23:38:58,804 root         INFO     Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 0.082169\n",
      "Reconstruction: 0.082169, Regularization: 0.000000\n",
      "2019-04-09 23:38:58,868 root         INFO     Train Epoch: 85 [512/8000 (6%)]\tTotal Loss: 0.085278\n",
      "Reconstruction: 0.085277, Regularization: 0.000000\n",
      "2019-04-09 23:38:58,932 root         INFO     Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 0.097289\n",
      "Reconstruction: 0.097289, Regularization: 0.000000\n",
      "2019-04-09 23:38:58,996 root         INFO     Train Epoch: 85 [1536/8000 (19%)]\tTotal Loss: 0.097112\n",
      "Reconstruction: 0.097111, Regularization: 0.000001\n",
      "2019-04-09 23:38:59,060 root         INFO     Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 0.091316\n",
      "Reconstruction: 0.091315, Regularization: 0.000001\n",
      "2019-04-09 23:38:59,124 root         INFO     Train Epoch: 85 [2560/8000 (32%)]\tTotal Loss: 0.092718\n",
      "Reconstruction: 0.092717, Regularization: 0.000001\n",
      "2019-04-09 23:38:59,188 root         INFO     Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 0.080565\n",
      "Reconstruction: 0.080564, Regularization: 0.000000\n",
      "2019-04-09 23:38:59,252 root         INFO     Train Epoch: 85 [3584/8000 (45%)]\tTotal Loss: 0.091011\n",
      "Reconstruction: 0.091011, Regularization: 0.000000\n",
      "2019-04-09 23:38:59,315 root         INFO     Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 0.091615\n",
      "Reconstruction: 0.091614, Regularization: 0.000001\n",
      "2019-04-09 23:38:59,380 root         INFO     Train Epoch: 85 [4608/8000 (58%)]\tTotal Loss: 0.090538\n",
      "Reconstruction: 0.090538, Regularization: 0.000000\n",
      "2019-04-09 23:38:59,444 root         INFO     Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 0.094809\n",
      "Reconstruction: 0.094808, Regularization: 0.000000\n",
      "2019-04-09 23:38:59,508 root         INFO     Train Epoch: 85 [5632/8000 (70%)]\tTotal Loss: 0.100431\n",
      "Reconstruction: 0.100430, Regularization: 0.000000\n",
      "2019-04-09 23:38:59,572 root         INFO     Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 0.079704\n",
      "Reconstruction: 0.079704, Regularization: 0.000000\n",
      "2019-04-09 23:38:59,636 root         INFO     Train Epoch: 85 [6656/8000 (83%)]\tTotal Loss: 0.098964\n",
      "Reconstruction: 0.098964, Regularization: 0.000000\n",
      "2019-04-09 23:38:59,700 root         INFO     Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 0.087461\n",
      "Reconstruction: 0.087461, Regularization: 0.000000\n",
      "2019-04-09 23:38:59,764 root         INFO     Train Epoch: 85 [7680/8000 (96%)]\tTotal Loss: 0.083014\n",
      "Reconstruction: 0.083014, Regularization: 0.000000\n",
      "2019-04-09 23:38:59,818 root         INFO     ====> Epoch: 85 Average loss: 0.0887\n",
      "2019-04-09 23:38:59,842 root         INFO     Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 0.087517\n",
      "Reconstruction: 0.087517, Regularization: 0.000000\n",
      "2019-04-09 23:38:59,906 root         INFO     Train Epoch: 86 [512/8000 (6%)]\tTotal Loss: 0.093726\n",
      "Reconstruction: 0.093726, Regularization: 0.000000\n",
      "2019-04-09 23:38:59,969 root         INFO     Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 0.097292\n",
      "Reconstruction: 0.097292, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,032 root         INFO     Train Epoch: 86 [1536/8000 (19%)]\tTotal Loss: 0.091080\n",
      "Reconstruction: 0.091080, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,095 root         INFO     Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 0.090615\n",
      "Reconstruction: 0.090615, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,158 root         INFO     Train Epoch: 86 [2560/8000 (32%)]\tTotal Loss: 0.088403\n",
      "Reconstruction: 0.088403, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,222 root         INFO     Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 0.093838\n",
      "Reconstruction: 0.093838, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,285 root         INFO     Train Epoch: 86 [3584/8000 (45%)]\tTotal Loss: 0.086491\n",
      "Reconstruction: 0.086491, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,348 root         INFO     Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 0.096887\n",
      "Reconstruction: 0.096887, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,411 root         INFO     Train Epoch: 86 [4608/8000 (58%)]\tTotal Loss: 0.091439\n",
      "Reconstruction: 0.091439, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,474 root         INFO     Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 0.094877\n",
      "Reconstruction: 0.094877, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,537 root         INFO     Train Epoch: 86 [5632/8000 (70%)]\tTotal Loss: 0.087144\n",
      "Reconstruction: 0.087144, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,601 root         INFO     Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 0.090421\n",
      "Reconstruction: 0.090421, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,664 root         INFO     Train Epoch: 86 [6656/8000 (83%)]\tTotal Loss: 0.096906\n",
      "Reconstruction: 0.096906, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,726 root         INFO     Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 0.082017\n",
      "Reconstruction: 0.082017, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,789 root         INFO     Train Epoch: 86 [7680/8000 (96%)]\tTotal Loss: 0.092295\n",
      "Reconstruction: 0.092295, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,843 root         INFO     ====> Epoch: 86 Average loss: 0.0887\n",
      "2019-04-09 23:39:00,867 root         INFO     Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 0.089280\n",
      "Reconstruction: 0.089280, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,931 root         INFO     Train Epoch: 87 [512/8000 (6%)]\tTotal Loss: 0.076129\n",
      "Reconstruction: 0.076129, Regularization: 0.000000\n",
      "2019-04-09 23:39:00,995 root         INFO     Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 0.090602\n",
      "Reconstruction: 0.090602, Regularization: 0.000000\n",
      "2019-04-09 23:39:01,058 root         INFO     Train Epoch: 87 [1536/8000 (19%)]\tTotal Loss: 0.085914\n",
      "Reconstruction: 0.085914, Regularization: 0.000000\n",
      "2019-04-09 23:39:01,122 root         INFO     Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 0.089910\n",
      "Reconstruction: 0.089910, Regularization: 0.000000\n",
      "2019-04-09 23:39:01,186 root         INFO     Train Epoch: 87 [2560/8000 (32%)]\tTotal Loss: 0.080961\n",
      "Reconstruction: 0.080960, Regularization: 0.000000\n",
      "2019-04-09 23:39:01,250 root         INFO     Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 0.091337\n",
      "Reconstruction: 0.091336, Regularization: 0.000000\n",
      "2019-04-09 23:39:01,314 root         INFO     Train Epoch: 87 [3584/8000 (45%)]\tTotal Loss: 0.087399\n",
      "Reconstruction: 0.087399, Regularization: 0.000000\n",
      "2019-04-09 23:39:01,378 root         INFO     Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 0.087109\n",
      "Reconstruction: 0.087109, Regularization: 0.000000\n",
      "2019-04-09 23:39:01,442 root         INFO     Train Epoch: 87 [4608/8000 (58%)]\tTotal Loss: 0.088568\n",
      "Reconstruction: 0.088568, Regularization: 0.000000\n",
      "2019-04-09 23:39:01,507 root         INFO     Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 0.085191\n",
      "Reconstruction: 0.085190, Regularization: 0.000001\n",
      "2019-04-09 23:39:01,570 root         INFO     Train Epoch: 87 [5632/8000 (70%)]\tTotal Loss: 0.086695\n",
      "Reconstruction: 0.086694, Regularization: 0.000000\n",
      "2019-04-09 23:39:01,633 root         INFO     Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 0.086213\n",
      "Reconstruction: 0.086212, Regularization: 0.000000\n",
      "2019-04-09 23:39:01,696 root         INFO     Train Epoch: 87 [6656/8000 (83%)]\tTotal Loss: 0.083232\n",
      "Reconstruction: 0.083232, Regularization: 0.000000\n",
      "2019-04-09 23:39:01,759 root         INFO     Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 0.084792\n",
      "Reconstruction: 0.084792, Regularization: 0.000000\n",
      "2019-04-09 23:39:01,822 root         INFO     Train Epoch: 87 [7680/8000 (96%)]\tTotal Loss: 0.084814\n",
      "Reconstruction: 0.084814, Regularization: 0.000000\n",
      "2019-04-09 23:39:01,876 root         INFO     ====> Epoch: 87 Average loss: 0.0887\n",
      "2019-04-09 23:39:01,901 root         INFO     Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 0.088609\n",
      "Reconstruction: 0.088609, Regularization: 0.000000\n",
      "2019-04-09 23:39:01,964 root         INFO     Train Epoch: 88 [512/8000 (6%)]\tTotal Loss: 0.089665\n",
      "Reconstruction: 0.089665, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,026 root         INFO     Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 0.088157\n",
      "Reconstruction: 0.088157, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,089 root         INFO     Train Epoch: 88 [1536/8000 (19%)]\tTotal Loss: 0.076340\n",
      "Reconstruction: 0.076339, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,152 root         INFO     Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 0.083276\n",
      "Reconstruction: 0.083276, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,215 root         INFO     Train Epoch: 88 [2560/8000 (32%)]\tTotal Loss: 0.089761\n",
      "Reconstruction: 0.089760, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,278 root         INFO     Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 0.078497\n",
      "Reconstruction: 0.078497, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,341 root         INFO     Train Epoch: 88 [3584/8000 (45%)]\tTotal Loss: 0.091719\n",
      "Reconstruction: 0.091719, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,404 root         INFO     Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 0.084499\n",
      "Reconstruction: 0.084498, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,467 root         INFO     Train Epoch: 88 [4608/8000 (58%)]\tTotal Loss: 0.089010\n",
      "Reconstruction: 0.089009, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,530 root         INFO     Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 0.083336\n",
      "Reconstruction: 0.083336, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,592 root         INFO     Train Epoch: 88 [5632/8000 (70%)]\tTotal Loss: 0.091011\n",
      "Reconstruction: 0.091011, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,654 root         INFO     Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 0.088067\n",
      "Reconstruction: 0.088067, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,717 root         INFO     Train Epoch: 88 [6656/8000 (83%)]\tTotal Loss: 0.084037\n",
      "Reconstruction: 0.084037, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,779 root         INFO     Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 0.084361\n",
      "Reconstruction: 0.084361, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,840 root         INFO     Train Epoch: 88 [7680/8000 (96%)]\tTotal Loss: 0.088952\n",
      "Reconstruction: 0.088952, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,893 root         INFO     ====> Epoch: 88 Average loss: 0.0887\n",
      "2019-04-09 23:39:02,918 root         INFO     Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 0.089232\n",
      "Reconstruction: 0.089232, Regularization: 0.000000\n",
      "2019-04-09 23:39:02,983 root         INFO     Train Epoch: 89 [512/8000 (6%)]\tTotal Loss: 0.094738\n",
      "Reconstruction: 0.094738, Regularization: 0.000000\n",
      "2019-04-09 23:39:03,047 root         INFO     Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 0.082520\n",
      "Reconstruction: 0.082520, Regularization: 0.000000\n",
      "2019-04-09 23:39:03,111 root         INFO     Train Epoch: 89 [1536/8000 (19%)]\tTotal Loss: 0.088787\n",
      "Reconstruction: 0.088787, Regularization: 0.000000\n",
      "2019-04-09 23:39:03,175 root         INFO     Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 0.085402\n",
      "Reconstruction: 0.085402, Regularization: 0.000000\n",
      "2019-04-09 23:39:03,239 root         INFO     Train Epoch: 89 [2560/8000 (32%)]\tTotal Loss: 0.090002\n",
      "Reconstruction: 0.090002, Regularization: 0.000000\n",
      "2019-04-09 23:39:03,303 root         INFO     Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 0.089598\n",
      "Reconstruction: 0.089598, Regularization: 0.000000\n",
      "2019-04-09 23:39:03,368 root         INFO     Train Epoch: 89 [3584/8000 (45%)]\tTotal Loss: 0.078481\n",
      "Reconstruction: 0.078481, Regularization: 0.000000\n",
      "2019-04-09 23:39:03,431 root         INFO     Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 0.085732\n",
      "Reconstruction: 0.085732, Regularization: 0.000000\n",
      "2019-04-09 23:39:03,495 root         INFO     Train Epoch: 89 [4608/8000 (58%)]\tTotal Loss: 0.081479\n",
      "Reconstruction: 0.081479, Regularization: 0.000000\n",
      "2019-04-09 23:39:03,559 root         INFO     Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 0.086498\n",
      "Reconstruction: 0.086498, Regularization: 0.000000\n",
      "2019-04-09 23:39:03,623 root         INFO     Train Epoch: 89 [5632/8000 (70%)]\tTotal Loss: 0.096413\n",
      "Reconstruction: 0.096413, Regularization: 0.000000\n",
      "2019-04-09 23:39:03,687 root         INFO     Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 0.089851\n",
      "Reconstruction: 0.089851, Regularization: 0.000000\n",
      "2019-04-09 23:39:03,751 root         INFO     Train Epoch: 89 [6656/8000 (83%)]\tTotal Loss: 0.080261\n",
      "Reconstruction: 0.080261, Regularization: 0.000000\n",
      "2019-04-09 23:39:03,815 root         INFO     Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 0.097391\n",
      "Reconstruction: 0.097391, Regularization: 0.000000\n",
      "2019-04-09 23:39:03,879 root         INFO     Train Epoch: 89 [7680/8000 (96%)]\tTotal Loss: 0.096257\n",
      "Reconstruction: 0.096256, Regularization: 0.000000\n",
      "2019-04-09 23:39:03,933 root         INFO     ====> Epoch: 89 Average loss: 0.0887\n",
      "2019-04-09 23:39:03,957 root         INFO     Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 0.091430\n",
      "Reconstruction: 0.091430, Regularization: 0.000000\n",
      "2019-04-09 23:39:04,021 root         INFO     Train Epoch: 90 [512/8000 (6%)]\tTotal Loss: 0.091842\n",
      "Reconstruction: 0.091841, Regularization: 0.000000\n",
      "2019-04-09 23:39:04,084 root         INFO     Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 0.086975\n",
      "Reconstruction: 0.086975, Regularization: 0.000000\n",
      "2019-04-09 23:39:04,147 root         INFO     Train Epoch: 90 [1536/8000 (19%)]\tTotal Loss: 0.084910\n",
      "Reconstruction: 0.084910, Regularization: 0.000000\n",
      "2019-04-09 23:39:04,210 root         INFO     Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 0.087204\n",
      "Reconstruction: 0.087204, Regularization: 0.000000\n",
      "2019-04-09 23:39:04,273 root         INFO     Train Epoch: 90 [2560/8000 (32%)]\tTotal Loss: 0.081488\n",
      "Reconstruction: 0.081488, Regularization: 0.000000\n",
      "2019-04-09 23:39:04,336 root         INFO     Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 0.087172\n",
      "Reconstruction: 0.087172, Regularization: 0.000000\n",
      "2019-04-09 23:39:04,399 root         INFO     Train Epoch: 90 [3584/8000 (45%)]\tTotal Loss: 0.086375\n",
      "Reconstruction: 0.086375, Regularization: 0.000000\n",
      "2019-04-09 23:39:04,462 root         INFO     Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 0.089268\n",
      "Reconstruction: 0.089268, Regularization: 0.000000\n",
      "2019-04-09 23:39:04,525 root         INFO     Train Epoch: 90 [4608/8000 (58%)]\tTotal Loss: 0.084384\n",
      "Reconstruction: 0.084384, Regularization: 0.000000\n",
      "2019-04-09 23:39:04,588 root         INFO     Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 0.090216\n",
      "Reconstruction: 0.090215, Regularization: 0.000000\n",
      "2019-04-09 23:39:04,650 root         INFO     Train Epoch: 90 [5632/8000 (70%)]\tTotal Loss: 0.101251\n",
      "Reconstruction: 0.101250, Regularization: 0.000001\n",
      "2019-04-09 23:39:04,713 root         INFO     Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 0.083581\n",
      "Reconstruction: 0.083581, Regularization: 0.000001\n",
      "2019-04-09 23:39:04,776 root         INFO     Train Epoch: 90 [6656/8000 (83%)]\tTotal Loss: 0.094616\n",
      "Reconstruction: 0.094615, Regularization: 0.000001\n",
      "2019-04-09 23:39:04,839 root         INFO     Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 0.091970\n",
      "Reconstruction: 0.091969, Regularization: 0.000001\n",
      "2019-04-09 23:39:04,902 root         INFO     Train Epoch: 90 [7680/8000 (96%)]\tTotal Loss: 0.086546\n",
      "Reconstruction: 0.086546, Regularization: 0.000000\n",
      "2019-04-09 23:39:04,955 root         INFO     ====> Epoch: 90 Average loss: 0.0887\n",
      "2019-04-09 23:39:04,979 root         INFO     Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 0.090499\n",
      "Reconstruction: 0.090498, Regularization: 0.000001\n",
      "2019-04-09 23:39:05,042 root         INFO     Train Epoch: 91 [512/8000 (6%)]\tTotal Loss: 0.088370\n",
      "Reconstruction: 0.088369, Regularization: 0.000001\n",
      "2019-04-09 23:39:05,105 root         INFO     Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 0.094548\n",
      "Reconstruction: 0.094547, Regularization: 0.000001\n",
      "2019-04-09 23:39:05,169 root         INFO     Train Epoch: 91 [1536/8000 (19%)]\tTotal Loss: 0.090699\n",
      "Reconstruction: 0.090698, Regularization: 0.000001\n",
      "2019-04-09 23:39:05,232 root         INFO     Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 0.082221\n",
      "Reconstruction: 0.082221, Regularization: 0.000000\n",
      "2019-04-09 23:39:05,295 root         INFO     Train Epoch: 91 [2560/8000 (32%)]\tTotal Loss: 0.091938\n",
      "Reconstruction: 0.091938, Regularization: 0.000001\n",
      "2019-04-09 23:39:05,358 root         INFO     Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 0.093596\n",
      "Reconstruction: 0.093595, Regularization: 0.000001\n",
      "2019-04-09 23:39:05,421 root         INFO     Train Epoch: 91 [3584/8000 (45%)]\tTotal Loss: 0.087587\n",
      "Reconstruction: 0.087586, Regularization: 0.000001\n",
      "2019-04-09 23:39:05,483 root         INFO     Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 0.087744\n",
      "Reconstruction: 0.087743, Regularization: 0.000002\n",
      "2019-04-09 23:39:05,546 root         INFO     Train Epoch: 91 [4608/8000 (58%)]\tTotal Loss: 0.095281\n",
      "Reconstruction: 0.095280, Regularization: 0.000001\n",
      "2019-04-09 23:39:05,609 root         INFO     Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 0.085954\n",
      "Reconstruction: 0.085953, Regularization: 0.000001\n",
      "2019-04-09 23:39:05,672 root         INFO     Train Epoch: 91 [5632/8000 (70%)]\tTotal Loss: 0.080745\n",
      "Reconstruction: 0.080744, Regularization: 0.000001\n",
      "2019-04-09 23:39:05,735 root         INFO     Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 0.084015\n",
      "Reconstruction: 0.084014, Regularization: 0.000001\n",
      "2019-04-09 23:39:05,798 root         INFO     Train Epoch: 91 [6656/8000 (83%)]\tTotal Loss: 0.083564\n",
      "Reconstruction: 0.083564, Regularization: 0.000000\n",
      "2019-04-09 23:39:05,860 root         INFO     Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 0.091518\n",
      "Reconstruction: 0.091517, Regularization: 0.000000\n",
      "2019-04-09 23:39:05,923 root         INFO     Train Epoch: 91 [7680/8000 (96%)]\tTotal Loss: 0.088887\n",
      "Reconstruction: 0.088887, Regularization: 0.000000\n",
      "2019-04-09 23:39:05,977 root         INFO     ====> Epoch: 91 Average loss: 0.0887\n",
      "2019-04-09 23:39:06,001 root         INFO     Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 0.088086\n",
      "Reconstruction: 0.088086, Regularization: 0.000000\n",
      "2019-04-09 23:39:06,065 root         INFO     Train Epoch: 92 [512/8000 (6%)]\tTotal Loss: 0.088733\n",
      "Reconstruction: 0.088733, Regularization: 0.000000\n",
      "2019-04-09 23:39:06,129 root         INFO     Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 0.089134\n",
      "Reconstruction: 0.089134, Regularization: 0.000000\n",
      "2019-04-09 23:39:06,192 root         INFO     Train Epoch: 92 [1536/8000 (19%)]\tTotal Loss: 0.088953\n",
      "Reconstruction: 0.088953, Regularization: 0.000000\n",
      "2019-04-09 23:39:06,257 root         INFO     Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 0.085297\n",
      "Reconstruction: 0.085297, Regularization: 0.000000\n",
      "2019-04-09 23:39:06,321 root         INFO     Train Epoch: 92 [2560/8000 (32%)]\tTotal Loss: 0.091213\n",
      "Reconstruction: 0.091213, Regularization: 0.000000\n",
      "2019-04-09 23:39:06,385 root         INFO     Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 0.089883\n",
      "Reconstruction: 0.089883, Regularization: 0.000000\n",
      "2019-04-09 23:39:06,449 root         INFO     Train Epoch: 92 [3584/8000 (45%)]\tTotal Loss: 0.093587\n",
      "Reconstruction: 0.093587, Regularization: 0.000000\n",
      "2019-04-09 23:39:06,513 root         INFO     Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 0.085603\n",
      "Reconstruction: 0.085603, Regularization: 0.000000\n",
      "2019-04-09 23:39:06,577 root         INFO     Train Epoch: 92 [4608/8000 (58%)]\tTotal Loss: 0.093267\n",
      "Reconstruction: 0.093267, Regularization: 0.000000\n",
      "2019-04-09 23:39:06,641 root         INFO     Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 0.093486\n",
      "Reconstruction: 0.093486, Regularization: 0.000000\n",
      "2019-04-09 23:39:06,705 root         INFO     Train Epoch: 92 [5632/8000 (70%)]\tTotal Loss: 0.080003\n",
      "Reconstruction: 0.080003, Regularization: 0.000000\n",
      "2019-04-09 23:39:06,769 root         INFO     Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 0.095243\n",
      "Reconstruction: 0.095243, Regularization: 0.000000\n",
      "2019-04-09 23:39:06,832 root         INFO     Train Epoch: 92 [6656/8000 (83%)]\tTotal Loss: 0.093323\n",
      "Reconstruction: 0.093323, Regularization: 0.000000\n",
      "2019-04-09 23:39:06,895 root         INFO     Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 0.087804\n",
      "Reconstruction: 0.087804, Regularization: 0.000000\n",
      "2019-04-09 23:39:06,958 root         INFO     Train Epoch: 92 [7680/8000 (96%)]\tTotal Loss: 0.076314\n",
      "Reconstruction: 0.076314, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,011 root         INFO     ====> Epoch: 92 Average loss: 0.0887\n",
      "2019-04-09 23:39:07,035 root         INFO     Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 0.084190\n",
      "Reconstruction: 0.084190, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,098 root         INFO     Train Epoch: 93 [512/8000 (6%)]\tTotal Loss: 0.085590\n",
      "Reconstruction: 0.085590, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,162 root         INFO     Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 0.094266\n",
      "Reconstruction: 0.094266, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,225 root         INFO     Train Epoch: 93 [1536/8000 (19%)]\tTotal Loss: 0.089087\n",
      "Reconstruction: 0.089087, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,289 root         INFO     Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 0.086660\n",
      "Reconstruction: 0.086660, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,353 root         INFO     Train Epoch: 93 [2560/8000 (32%)]\tTotal Loss: 0.084016\n",
      "Reconstruction: 0.084016, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,417 root         INFO     Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 0.084265\n",
      "Reconstruction: 0.084265, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,479 root         INFO     Train Epoch: 93 [3584/8000 (45%)]\tTotal Loss: 0.095838\n",
      "Reconstruction: 0.095838, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,542 root         INFO     Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 0.081994\n",
      "Reconstruction: 0.081994, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,605 root         INFO     Train Epoch: 93 [4608/8000 (58%)]\tTotal Loss: 0.087313\n",
      "Reconstruction: 0.087313, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,668 root         INFO     Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 0.086373\n",
      "Reconstruction: 0.086373, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,731 root         INFO     Train Epoch: 93 [5632/8000 (70%)]\tTotal Loss: 0.100581\n",
      "Reconstruction: 0.100581, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,795 root         INFO     Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 0.093652\n",
      "Reconstruction: 0.093652, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,858 root         INFO     Train Epoch: 93 [6656/8000 (83%)]\tTotal Loss: 0.088920\n",
      "Reconstruction: 0.088920, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,921 root         INFO     Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 0.087671\n",
      "Reconstruction: 0.087671, Regularization: 0.000000\n",
      "2019-04-09 23:39:07,984 root         INFO     Train Epoch: 93 [7680/8000 (96%)]\tTotal Loss: 0.089206\n",
      "Reconstruction: 0.089206, Regularization: 0.000000\n",
      "2019-04-09 23:39:08,038 root         INFO     ====> Epoch: 93 Average loss: 0.0887\n",
      "2019-04-09 23:39:08,061 root         INFO     Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 0.090541\n",
      "Reconstruction: 0.090541, Regularization: 0.000000\n",
      "2019-04-09 23:39:08,125 root         INFO     Train Epoch: 94 [512/8000 (6%)]\tTotal Loss: 0.087212\n",
      "Reconstruction: 0.087212, Regularization: 0.000000\n",
      "2019-04-09 23:39:08,189 root         INFO     Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 0.093088\n",
      "Reconstruction: 0.093088, Regularization: 0.000000\n",
      "2019-04-09 23:39:08,252 root         INFO     Train Epoch: 94 [1536/8000 (19%)]\tTotal Loss: 0.084600\n",
      "Reconstruction: 0.084599, Regularization: 0.000000\n",
      "2019-04-09 23:39:08,315 root         INFO     Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 0.083460\n",
      "Reconstruction: 0.083459, Regularization: 0.000001\n",
      "2019-04-09 23:39:08,380 root         INFO     Train Epoch: 94 [2560/8000 (32%)]\tTotal Loss: 0.091185\n",
      "Reconstruction: 0.091184, Regularization: 0.000001\n",
      "2019-04-09 23:39:08,442 root         INFO     Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 0.087356\n",
      "Reconstruction: 0.087355, Regularization: 0.000001\n",
      "2019-04-09 23:39:08,504 root         INFO     Train Epoch: 94 [3584/8000 (45%)]\tTotal Loss: 0.085637\n",
      "Reconstruction: 0.085637, Regularization: 0.000001\n",
      "2019-04-09 23:39:08,566 root         INFO     Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 0.088494\n",
      "Reconstruction: 0.088493, Regularization: 0.000001\n",
      "2019-04-09 23:39:08,628 root         INFO     Train Epoch: 94 [4608/8000 (58%)]\tTotal Loss: 0.088737\n",
      "Reconstruction: 0.088737, Regularization: 0.000000\n",
      "2019-04-09 23:39:08,690 root         INFO     Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 0.092651\n",
      "Reconstruction: 0.092650, Regularization: 0.000000\n",
      "2019-04-09 23:39:08,752 root         INFO     Train Epoch: 94 [5632/8000 (70%)]\tTotal Loss: 0.079771\n",
      "Reconstruction: 0.079771, Regularization: 0.000000\n",
      "2019-04-09 23:39:08,813 root         INFO     Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 0.085061\n",
      "Reconstruction: 0.085061, Regularization: 0.000000\n",
      "2019-04-09 23:39:08,875 root         INFO     Train Epoch: 94 [6656/8000 (83%)]\tTotal Loss: 0.087912\n",
      "Reconstruction: 0.087911, Regularization: 0.000000\n",
      "2019-04-09 23:39:08,937 root         INFO     Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 0.093279\n",
      "Reconstruction: 0.093279, Regularization: 0.000000\n",
      "2019-04-09 23:39:08,999 root         INFO     Train Epoch: 94 [7680/8000 (96%)]\tTotal Loss: 0.087906\n",
      "Reconstruction: 0.087906, Regularization: 0.000000\n",
      "2019-04-09 23:39:09,051 root         INFO     ====> Epoch: 94 Average loss: 0.0887\n",
      "2019-04-09 23:39:09,075 root         INFO     Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 0.093777\n",
      "Reconstruction: 0.093777, Regularization: 0.000000\n",
      "2019-04-09 23:39:09,139 root         INFO     Train Epoch: 95 [512/8000 (6%)]\tTotal Loss: 0.089060\n",
      "Reconstruction: 0.089060, Regularization: 0.000000\n",
      "2019-04-09 23:39:09,202 root         INFO     Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 0.087721\n",
      "Reconstruction: 0.087721, Regularization: 0.000000\n",
      "2019-04-09 23:39:09,265 root         INFO     Train Epoch: 95 [1536/8000 (19%)]\tTotal Loss: 0.094954\n",
      "Reconstruction: 0.094953, Regularization: 0.000000\n",
      "2019-04-09 23:39:09,328 root         INFO     Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 0.083023\n",
      "Reconstruction: 0.083023, Regularization: 0.000001\n",
      "2019-04-09 23:39:09,391 root         INFO     Train Epoch: 95 [2560/8000 (32%)]\tTotal Loss: 0.091410\n",
      "Reconstruction: 0.091409, Regularization: 0.000001\n",
      "2019-04-09 23:39:09,454 root         INFO     Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 0.090222\n",
      "Reconstruction: 0.090221, Regularization: 0.000001\n",
      "2019-04-09 23:39:09,517 root         INFO     Train Epoch: 95 [3584/8000 (45%)]\tTotal Loss: 0.086969\n",
      "Reconstruction: 0.086968, Regularization: 0.000001\n",
      "2019-04-09 23:39:09,580 root         INFO     Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 0.090861\n",
      "Reconstruction: 0.090861, Regularization: 0.000000\n",
      "2019-04-09 23:39:09,642 root         INFO     Train Epoch: 95 [4608/8000 (58%)]\tTotal Loss: 0.091405\n",
      "Reconstruction: 0.091405, Regularization: 0.000000\n",
      "2019-04-09 23:39:09,705 root         INFO     Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 0.088497\n",
      "Reconstruction: 0.088497, Regularization: 0.000000\n",
      "2019-04-09 23:39:09,769 root         INFO     Train Epoch: 95 [5632/8000 (70%)]\tTotal Loss: 0.094271\n",
      "Reconstruction: 0.094270, Regularization: 0.000000\n",
      "2019-04-09 23:39:09,832 root         INFO     Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 0.091546\n",
      "Reconstruction: 0.091545, Regularization: 0.000000\n",
      "2019-04-09 23:39:09,895 root         INFO     Train Epoch: 95 [6656/8000 (83%)]\tTotal Loss: 0.088611\n",
      "Reconstruction: 0.088611, Regularization: 0.000000\n",
      "2019-04-09 23:39:09,958 root         INFO     Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 0.093908\n",
      "Reconstruction: 0.093907, Regularization: 0.000000\n",
      "2019-04-09 23:39:10,021 root         INFO     Train Epoch: 95 [7680/8000 (96%)]\tTotal Loss: 0.090704\n",
      "Reconstruction: 0.090703, Regularization: 0.000000\n",
      "2019-04-09 23:39:10,075 root         INFO     ====> Epoch: 95 Average loss: 0.0887\n",
      "2019-04-09 23:39:10,098 root         INFO     Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 0.087493\n",
      "Reconstruction: 0.087492, Regularization: 0.000001\n",
      "2019-04-09 23:39:10,161 root         INFO     Train Epoch: 96 [512/8000 (6%)]\tTotal Loss: 0.083799\n",
      "Reconstruction: 0.083799, Regularization: 0.000001\n",
      "2019-04-09 23:39:10,224 root         INFO     Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 0.087658\n",
      "Reconstruction: 0.087657, Regularization: 0.000001\n",
      "2019-04-09 23:39:10,288 root         INFO     Train Epoch: 96 [1536/8000 (19%)]\tTotal Loss: 0.085387\n",
      "Reconstruction: 0.085386, Regularization: 0.000001\n",
      "2019-04-09 23:39:10,351 root         INFO     Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 0.094701\n",
      "Reconstruction: 0.094700, Regularization: 0.000001\n",
      "2019-04-09 23:39:10,414 root         INFO     Train Epoch: 96 [2560/8000 (32%)]\tTotal Loss: 0.089171\n",
      "Reconstruction: 0.089170, Regularization: 0.000000\n",
      "2019-04-09 23:39:10,477 root         INFO     Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 0.090184\n",
      "Reconstruction: 0.090184, Regularization: 0.000000\n",
      "2019-04-09 23:39:10,540 root         INFO     Train Epoch: 96 [3584/8000 (45%)]\tTotal Loss: 0.090103\n",
      "Reconstruction: 0.090102, Regularization: 0.000000\n",
      "2019-04-09 23:39:10,603 root         INFO     Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 0.088463\n",
      "Reconstruction: 0.088462, Regularization: 0.000000\n",
      "2019-04-09 23:39:10,666 root         INFO     Train Epoch: 96 [4608/8000 (58%)]\tTotal Loss: 0.088132\n",
      "Reconstruction: 0.088132, Regularization: 0.000000\n",
      "2019-04-09 23:39:10,730 root         INFO     Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 0.090835\n",
      "Reconstruction: 0.090835, Regularization: 0.000000\n",
      "2019-04-09 23:39:10,792 root         INFO     Train Epoch: 96 [5632/8000 (70%)]\tTotal Loss: 0.085535\n",
      "Reconstruction: 0.085535, Regularization: 0.000000\n",
      "2019-04-09 23:39:10,853 root         INFO     Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 0.084936\n",
      "Reconstruction: 0.084936, Regularization: 0.000000\n",
      "2019-04-09 23:39:10,915 root         INFO     Train Epoch: 96 [6656/8000 (83%)]\tTotal Loss: 0.091095\n",
      "Reconstruction: 0.091094, Regularization: 0.000000\n",
      "2019-04-09 23:39:10,976 root         INFO     Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 0.088245\n",
      "Reconstruction: 0.088245, Regularization: 0.000000\n",
      "2019-04-09 23:39:11,038 root         INFO     Train Epoch: 96 [7680/8000 (96%)]\tTotal Loss: 0.089876\n",
      "Reconstruction: 0.089876, Regularization: 0.000000\n",
      "2019-04-09 23:39:11,091 root         INFO     ====> Epoch: 96 Average loss: 0.0887\n",
      "2019-04-09 23:39:11,115 root         INFO     Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 0.082844\n",
      "Reconstruction: 0.082843, Regularization: 0.000000\n",
      "2019-04-09 23:39:11,178 root         INFO     Train Epoch: 97 [512/8000 (6%)]\tTotal Loss: 0.086490\n",
      "Reconstruction: 0.086490, Regularization: 0.000001\n",
      "2019-04-09 23:39:11,240 root         INFO     Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 0.085884\n",
      "Reconstruction: 0.085883, Regularization: 0.000001\n",
      "2019-04-09 23:39:11,303 root         INFO     Train Epoch: 97 [1536/8000 (19%)]\tTotal Loss: 0.091343\n",
      "Reconstruction: 0.091342, Regularization: 0.000001\n",
      "2019-04-09 23:39:11,367 root         INFO     Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 0.101643\n",
      "Reconstruction: 0.101641, Regularization: 0.000002\n",
      "2019-04-09 23:39:11,430 root         INFO     Train Epoch: 97 [2560/8000 (32%)]\tTotal Loss: 0.080788\n",
      "Reconstruction: 0.080787, Regularization: 0.000001\n",
      "2019-04-09 23:39:11,493 root         INFO     Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 0.091564\n",
      "Reconstruction: 0.091562, Regularization: 0.000001\n",
      "2019-04-09 23:39:11,556 root         INFO     Train Epoch: 97 [3584/8000 (45%)]\tTotal Loss: 0.086282\n",
      "Reconstruction: 0.086281, Regularization: 0.000002\n",
      "2019-04-09 23:39:11,618 root         INFO     Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 0.084307\n",
      "Reconstruction: 0.084304, Regularization: 0.000002\n",
      "2019-04-09 23:39:11,681 root         INFO     Train Epoch: 97 [4608/8000 (58%)]\tTotal Loss: 0.094604\n",
      "Reconstruction: 0.094602, Regularization: 0.000002\n",
      "2019-04-09 23:39:11,745 root         INFO     Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 0.086052\n",
      "Reconstruction: 0.086050, Regularization: 0.000002\n",
      "2019-04-09 23:39:11,808 root         INFO     Train Epoch: 97 [5632/8000 (70%)]\tTotal Loss: 0.086680\n",
      "Reconstruction: 0.086677, Regularization: 0.000003\n",
      "2019-04-09 23:39:11,871 root         INFO     Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 0.080539\n",
      "Reconstruction: 0.080537, Regularization: 0.000002\n",
      "2019-04-09 23:39:11,934 root         INFO     Train Epoch: 97 [6656/8000 (83%)]\tTotal Loss: 0.078216\n",
      "Reconstruction: 0.078214, Regularization: 0.000001\n",
      "2019-04-09 23:39:11,997 root         INFO     Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 0.082695\n",
      "Reconstruction: 0.082693, Regularization: 0.000001\n",
      "2019-04-09 23:39:12,060 root         INFO     Train Epoch: 97 [7680/8000 (96%)]\tTotal Loss: 0.094081\n",
      "Reconstruction: 0.094079, Regularization: 0.000002\n",
      "2019-04-09 23:39:12,114 root         INFO     ====> Epoch: 97 Average loss: 0.0887\n",
      "2019-04-09 23:39:12,138 root         INFO     Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 0.081816\n",
      "Reconstruction: 0.081816, Regularization: 0.000001\n",
      "2019-04-09 23:39:12,201 root         INFO     Train Epoch: 98 [512/8000 (6%)]\tTotal Loss: 0.093463\n",
      "Reconstruction: 0.093462, Regularization: 0.000001\n",
      "2019-04-09 23:39:12,264 root         INFO     Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 0.079335\n",
      "Reconstruction: 0.079334, Regularization: 0.000000\n",
      "2019-04-09 23:39:12,327 root         INFO     Train Epoch: 98 [1536/8000 (19%)]\tTotal Loss: 0.088846\n",
      "Reconstruction: 0.088845, Regularization: 0.000000\n",
      "2019-04-09 23:39:12,390 root         INFO     Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 0.093783\n",
      "Reconstruction: 0.093782, Regularization: 0.000001\n",
      "2019-04-09 23:39:12,454 root         INFO     Train Epoch: 98 [2560/8000 (32%)]\tTotal Loss: 0.074119\n",
      "Reconstruction: 0.074119, Regularization: 0.000000\n",
      "2019-04-09 23:39:12,517 root         INFO     Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 0.094496\n",
      "Reconstruction: 0.094496, Regularization: 0.000000\n",
      "2019-04-09 23:39:12,581 root         INFO     Train Epoch: 98 [3584/8000 (45%)]\tTotal Loss: 0.088966\n",
      "Reconstruction: 0.088966, Regularization: 0.000000\n",
      "2019-04-09 23:39:12,644 root         INFO     Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 0.081812\n",
      "Reconstruction: 0.081812, Regularization: 0.000000\n",
      "2019-04-09 23:39:12,707 root         INFO     Train Epoch: 98 [4608/8000 (58%)]\tTotal Loss: 0.086970\n",
      "Reconstruction: 0.086970, Regularization: 0.000001\n",
      "2019-04-09 23:39:12,770 root         INFO     Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 0.085422\n",
      "Reconstruction: 0.085422, Regularization: 0.000001\n",
      "2019-04-09 23:39:12,832 root         INFO     Train Epoch: 98 [5632/8000 (70%)]\tTotal Loss: 0.081377\n",
      "Reconstruction: 0.081376, Regularization: 0.000000\n",
      "2019-04-09 23:39:12,894 root         INFO     Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 0.092312\n",
      "Reconstruction: 0.092312, Regularization: 0.000001\n",
      "2019-04-09 23:39:12,955 root         INFO     Train Epoch: 98 [6656/8000 (83%)]\tTotal Loss: 0.090674\n",
      "Reconstruction: 0.090674, Regularization: 0.000001\n",
      "2019-04-09 23:39:13,016 root         INFO     Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 0.087063\n",
      "Reconstruction: 0.087063, Regularization: 0.000000\n",
      "2019-04-09 23:39:13,076 root         INFO     Train Epoch: 98 [7680/8000 (96%)]\tTotal Loss: 0.087278\n",
      "Reconstruction: 0.087277, Regularization: 0.000001\n",
      "2019-04-09 23:39:13,129 root         INFO     ====> Epoch: 98 Average loss: 0.0887\n",
      "2019-04-09 23:39:13,153 root         INFO     Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 0.093767\n",
      "Reconstruction: 0.093767, Regularization: 0.000000\n",
      "2019-04-09 23:39:13,216 root         INFO     Train Epoch: 99 [512/8000 (6%)]\tTotal Loss: 0.087186\n",
      "Reconstruction: 0.087186, Regularization: 0.000000\n",
      "2019-04-09 23:39:13,279 root         INFO     Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 0.083148\n",
      "Reconstruction: 0.083148, Regularization: 0.000000\n",
      "2019-04-09 23:39:13,342 root         INFO     Train Epoch: 99 [1536/8000 (19%)]\tTotal Loss: 0.088137\n",
      "Reconstruction: 0.088137, Regularization: 0.000000\n",
      "2019-04-09 23:39:13,406 root         INFO     Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 0.106297\n",
      "Reconstruction: 0.106297, Regularization: 0.000000\n",
      "2019-04-09 23:39:13,470 root         INFO     Train Epoch: 99 [2560/8000 (32%)]\tTotal Loss: 0.083202\n",
      "Reconstruction: 0.083202, Regularization: 0.000000\n",
      "2019-04-09 23:39:13,533 root         INFO     Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 0.088869\n",
      "Reconstruction: 0.088869, Regularization: 0.000000\n",
      "2019-04-09 23:39:13,597 root         INFO     Train Epoch: 99 [3584/8000 (45%)]\tTotal Loss: 0.086384\n",
      "Reconstruction: 0.086384, Regularization: 0.000000\n",
      "2019-04-09 23:39:13,660 root         INFO     Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 0.081369\n",
      "Reconstruction: 0.081369, Regularization: 0.000000\n",
      "2019-04-09 23:39:13,722 root         INFO     Train Epoch: 99 [4608/8000 (58%)]\tTotal Loss: 0.089610\n",
      "Reconstruction: 0.089610, Regularization: 0.000000\n",
      "2019-04-09 23:39:13,785 root         INFO     Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 0.087606\n",
      "Reconstruction: 0.087606, Regularization: 0.000000\n",
      "2019-04-09 23:39:13,847 root         INFO     Train Epoch: 99 [5632/8000 (70%)]\tTotal Loss: 0.088050\n",
      "Reconstruction: 0.088050, Regularization: 0.000000\n",
      "2019-04-09 23:39:13,910 root         INFO     Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 0.098308\n",
      "Reconstruction: 0.098308, Regularization: 0.000000\n",
      "2019-04-09 23:39:13,973 root         INFO     Train Epoch: 99 [6656/8000 (83%)]\tTotal Loss: 0.091967\n",
      "Reconstruction: 0.091967, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,035 root         INFO     Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 0.090907\n",
      "Reconstruction: 0.090907, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,098 root         INFO     Train Epoch: 99 [7680/8000 (96%)]\tTotal Loss: 0.091041\n",
      "Reconstruction: 0.091040, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,152 root         INFO     ====> Epoch: 99 Average loss: 0.0887\n",
      "2019-04-09 23:39:14,176 root         INFO     Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 0.085369\n",
      "Reconstruction: 0.085368, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,239 root         INFO     Train Epoch: 100 [512/8000 (6%)]\tTotal Loss: 0.085111\n",
      "Reconstruction: 0.085111, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,303 root         INFO     Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 0.098029\n",
      "Reconstruction: 0.098029, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,366 root         INFO     Train Epoch: 100 [1536/8000 (19%)]\tTotal Loss: 0.074395\n",
      "Reconstruction: 0.074395, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,430 root         INFO     Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 0.088654\n",
      "Reconstruction: 0.088654, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,494 root         INFO     Train Epoch: 100 [2560/8000 (32%)]\tTotal Loss: 0.087653\n",
      "Reconstruction: 0.087653, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,557 root         INFO     Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 0.080134\n",
      "Reconstruction: 0.080134, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,620 root         INFO     Train Epoch: 100 [3584/8000 (45%)]\tTotal Loss: 0.090727\n",
      "Reconstruction: 0.090727, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,683 root         INFO     Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 0.096475\n",
      "Reconstruction: 0.096475, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,747 root         INFO     Train Epoch: 100 [4608/8000 (58%)]\tTotal Loss: 0.086843\n",
      "Reconstruction: 0.086842, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,809 root         INFO     Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 0.087208\n",
      "Reconstruction: 0.087208, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,871 root         INFO     Train Epoch: 100 [5632/8000 (70%)]\tTotal Loss: 0.089237\n",
      "Reconstruction: 0.089237, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,933 root         INFO     Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 0.082195\n",
      "Reconstruction: 0.082194, Regularization: 0.000000\n",
      "2019-04-09 23:39:14,997 root         INFO     Train Epoch: 100 [6656/8000 (83%)]\tTotal Loss: 0.080764\n",
      "Reconstruction: 0.080764, Regularization: 0.000000\n",
      "2019-04-09 23:39:15,059 root         INFO     Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 0.092211\n",
      "Reconstruction: 0.092210, Regularization: 0.000001\n",
      "2019-04-09 23:39:15,121 root         INFO     Train Epoch: 100 [7680/8000 (96%)]\tTotal Loss: 0.086092\n",
      "Reconstruction: 0.086091, Regularization: 0.000001\n",
      "2019-04-09 23:39:15,175 root         INFO     ====> Epoch: 100 Average loss: 0.0887\n",
      "2019-04-09 23:39:15,200 root         INFO     Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 0.083038\n",
      "Reconstruction: 0.083038, Regularization: 0.000000\n",
      "2019-04-09 23:39:15,264 root         INFO     Train Epoch: 101 [512/8000 (6%)]\tTotal Loss: 0.087216\n",
      "Reconstruction: 0.087216, Regularization: 0.000000\n",
      "2019-04-09 23:39:15,327 root         INFO     Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 0.081672\n",
      "Reconstruction: 0.081672, Regularization: 0.000000\n",
      "2019-04-09 23:39:15,388 root         INFO     Train Epoch: 101 [1536/8000 (19%)]\tTotal Loss: 0.093135\n",
      "Reconstruction: 0.093134, Regularization: 0.000001\n",
      "2019-04-09 23:39:15,449 root         INFO     Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 0.090204\n",
      "Reconstruction: 0.090203, Regularization: 0.000001\n",
      "2019-04-09 23:39:15,509 root         INFO     Train Epoch: 101 [2560/8000 (32%)]\tTotal Loss: 0.091858\n",
      "Reconstruction: 0.091857, Regularization: 0.000001\n",
      "2019-04-09 23:39:15,570 root         INFO     Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 0.099502\n",
      "Reconstruction: 0.099501, Regularization: 0.000001\n",
      "2019-04-09 23:39:15,631 root         INFO     Train Epoch: 101 [3584/8000 (45%)]\tTotal Loss: 0.087517\n",
      "Reconstruction: 0.087517, Regularization: 0.000001\n",
      "2019-04-09 23:39:15,692 root         INFO     Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 0.091588\n",
      "Reconstruction: 0.091587, Regularization: 0.000001\n",
      "2019-04-09 23:39:15,753 root         INFO     Train Epoch: 101 [4608/8000 (58%)]\tTotal Loss: 0.086000\n",
      "Reconstruction: 0.085999, Regularization: 0.000001\n",
      "2019-04-09 23:39:15,814 root         INFO     Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 0.091359\n",
      "Reconstruction: 0.091358, Regularization: 0.000000\n",
      "2019-04-09 23:39:15,875 root         INFO     Train Epoch: 101 [5632/8000 (70%)]\tTotal Loss: 0.080396\n",
      "Reconstruction: 0.080396, Regularization: 0.000000\n",
      "2019-04-09 23:39:15,936 root         INFO     Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 0.087352\n",
      "Reconstruction: 0.087352, Regularization: 0.000000\n",
      "2019-04-09 23:39:15,997 root         INFO     Train Epoch: 101 [6656/8000 (83%)]\tTotal Loss: 0.086970\n",
      "Reconstruction: 0.086970, Regularization: 0.000000\n",
      "2019-04-09 23:39:16,058 root         INFO     Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 0.085339\n",
      "Reconstruction: 0.085339, Regularization: 0.000000\n",
      "2019-04-09 23:39:16,119 root         INFO     Train Epoch: 101 [7680/8000 (96%)]\tTotal Loss: 0.091645\n",
      "Reconstruction: 0.091644, Regularization: 0.000001\n",
      "2019-04-09 23:39:16,172 root         INFO     ====> Epoch: 101 Average loss: 0.0887\n",
      "2019-04-09 23:39:16,197 root         INFO     Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 0.088053\n",
      "Reconstruction: 0.088052, Regularization: 0.000000\n",
      "2019-04-09 23:39:16,260 root         INFO     Train Epoch: 102 [512/8000 (6%)]\tTotal Loss: 0.084487\n",
      "Reconstruction: 0.084487, Regularization: 0.000000\n",
      "2019-04-09 23:39:16,322 root         INFO     Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 0.083050\n",
      "Reconstruction: 0.083050, Regularization: 0.000000\n",
      "2019-04-09 23:39:16,384 root         INFO     Train Epoch: 102 [1536/8000 (19%)]\tTotal Loss: 0.095226\n",
      "Reconstruction: 0.095226, Regularization: 0.000000\n",
      "2019-04-09 23:39:16,447 root         INFO     Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 0.093335\n",
      "Reconstruction: 0.093335, Regularization: 0.000000\n",
      "2019-04-09 23:39:16,509 root         INFO     Train Epoch: 102 [2560/8000 (32%)]\tTotal Loss: 0.091498\n",
      "Reconstruction: 0.091498, Regularization: 0.000000\n",
      "2019-04-09 23:39:16,571 root         INFO     Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 0.086918\n",
      "Reconstruction: 0.086918, Regularization: 0.000000\n",
      "2019-04-09 23:39:16,633 root         INFO     Train Epoch: 102 [3584/8000 (45%)]\tTotal Loss: 0.091100\n",
      "Reconstruction: 0.091100, Regularization: 0.000000\n",
      "2019-04-09 23:39:16,695 root         INFO     Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 0.088894\n",
      "Reconstruction: 0.088894, Regularization: 0.000000\n",
      "2019-04-09 23:39:16,757 root         INFO     Train Epoch: 102 [4608/8000 (58%)]\tTotal Loss: 0.091099\n",
      "Reconstruction: 0.091099, Regularization: 0.000000\n",
      "2019-04-09 23:39:16,819 root         INFO     Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 0.094858\n",
      "Reconstruction: 0.094858, Regularization: 0.000000\n",
      "2019-04-09 23:39:16,881 root         INFO     Train Epoch: 102 [5632/8000 (70%)]\tTotal Loss: 0.092700\n",
      "Reconstruction: 0.092700, Regularization: 0.000000\n",
      "2019-04-09 23:39:16,943 root         INFO     Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 0.084100\n",
      "Reconstruction: 0.084100, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,005 root         INFO     Train Epoch: 102 [6656/8000 (83%)]\tTotal Loss: 0.095150\n",
      "Reconstruction: 0.095150, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,067 root         INFO     Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 0.102565\n",
      "Reconstruction: 0.102564, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,129 root         INFO     Train Epoch: 102 [7680/8000 (96%)]\tTotal Loss: 0.086206\n",
      "Reconstruction: 0.086206, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,182 root         INFO     ====> Epoch: 102 Average loss: 0.0887\n",
      "2019-04-09 23:39:17,206 root         INFO     Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 0.093703\n",
      "Reconstruction: 0.093703, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,268 root         INFO     Train Epoch: 103 [512/8000 (6%)]\tTotal Loss: 0.093279\n",
      "Reconstruction: 0.093279, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,329 root         INFO     Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 0.080726\n",
      "Reconstruction: 0.080726, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,390 root         INFO     Train Epoch: 103 [1536/8000 (19%)]\tTotal Loss: 0.084508\n",
      "Reconstruction: 0.084508, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,452 root         INFO     Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 0.086086\n",
      "Reconstruction: 0.086086, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,515 root         INFO     Train Epoch: 103 [2560/8000 (32%)]\tTotal Loss: 0.090788\n",
      "Reconstruction: 0.090788, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,577 root         INFO     Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 0.088158\n",
      "Reconstruction: 0.088158, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,640 root         INFO     Train Epoch: 103 [3584/8000 (45%)]\tTotal Loss: 0.091216\n",
      "Reconstruction: 0.091216, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,702 root         INFO     Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 0.086085\n",
      "Reconstruction: 0.086085, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,764 root         INFO     Train Epoch: 103 [4608/8000 (58%)]\tTotal Loss: 0.087361\n",
      "Reconstruction: 0.087360, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,827 root         INFO     Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 0.082598\n",
      "Reconstruction: 0.082598, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,889 root         INFO     Train Epoch: 103 [5632/8000 (70%)]\tTotal Loss: 0.081918\n",
      "Reconstruction: 0.081918, Regularization: 0.000000\n",
      "2019-04-09 23:39:17,951 root         INFO     Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 0.087825\n",
      "Reconstruction: 0.087825, Regularization: 0.000000\n",
      "2019-04-09 23:39:18,013 root         INFO     Train Epoch: 103 [6656/8000 (83%)]\tTotal Loss: 0.090771\n",
      "Reconstruction: 0.090771, Regularization: 0.000000\n",
      "2019-04-09 23:39:18,075 root         INFO     Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 0.094509\n",
      "Reconstruction: 0.094509, Regularization: 0.000000\n",
      "2019-04-09 23:39:18,138 root         INFO     Train Epoch: 103 [7680/8000 (96%)]\tTotal Loss: 0.088277\n",
      "Reconstruction: 0.088276, Regularization: 0.000000\n",
      "2019-04-09 23:39:18,192 root         INFO     ====> Epoch: 103 Average loss: 0.0887\n",
      "2019-04-09 23:39:18,215 root         INFO     Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 0.084586\n",
      "Reconstruction: 0.084586, Regularization: 0.000000\n",
      "2019-04-09 23:39:18,277 root         INFO     Train Epoch: 104 [512/8000 (6%)]\tTotal Loss: 0.090809\n",
      "Reconstruction: 0.090808, Regularization: 0.000000\n",
      "2019-04-09 23:39:18,340 root         INFO     Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 0.082728\n",
      "Reconstruction: 0.082727, Regularization: 0.000000\n",
      "2019-04-09 23:39:18,401 root         INFO     Train Epoch: 104 [1536/8000 (19%)]\tTotal Loss: 0.088278\n",
      "Reconstruction: 0.088278, Regularization: 0.000000\n",
      "2019-04-09 23:39:18,463 root         INFO     Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 0.091104\n",
      "Reconstruction: 0.091103, Regularization: 0.000001\n",
      "2019-04-09 23:39:18,525 root         INFO     Train Epoch: 104 [2560/8000 (32%)]\tTotal Loss: 0.087934\n",
      "Reconstruction: 0.087933, Regularization: 0.000001\n",
      "2019-04-09 23:39:18,586 root         INFO     Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 0.087420\n",
      "Reconstruction: 0.087420, Regularization: 0.000001\n",
      "2019-04-09 23:39:18,648 root         INFO     Train Epoch: 104 [3584/8000 (45%)]\tTotal Loss: 0.086419\n",
      "Reconstruction: 0.086418, Regularization: 0.000001\n",
      "2019-04-09 23:39:18,709 root         INFO     Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 0.092870\n",
      "Reconstruction: 0.092869, Regularization: 0.000001\n",
      "2019-04-09 23:39:18,771 root         INFO     Train Epoch: 104 [4608/8000 (58%)]\tTotal Loss: 0.087370\n",
      "Reconstruction: 0.087369, Regularization: 0.000001\n",
      "2019-04-09 23:39:18,832 root         INFO     Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 0.086703\n",
      "Reconstruction: 0.086702, Regularization: 0.000001\n",
      "2019-04-09 23:39:18,893 root         INFO     Train Epoch: 104 [5632/8000 (70%)]\tTotal Loss: 0.091755\n",
      "Reconstruction: 0.091754, Regularization: 0.000000\n",
      "2019-04-09 23:39:18,955 root         INFO     Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 0.092072\n",
      "Reconstruction: 0.092072, Regularization: 0.000000\n",
      "2019-04-09 23:39:19,017 root         INFO     Train Epoch: 104 [6656/8000 (83%)]\tTotal Loss: 0.090953\n",
      "Reconstruction: 0.090952, Regularization: 0.000000\n",
      "2019-04-09 23:39:19,078 root         INFO     Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 0.094481\n",
      "Reconstruction: 0.094481, Regularization: 0.000001\n",
      "2019-04-09 23:39:19,141 root         INFO     Train Epoch: 104 [7680/8000 (96%)]\tTotal Loss: 0.084598\n",
      "Reconstruction: 0.084597, Regularization: 0.000000\n",
      "2019-04-09 23:39:19,196 root         INFO     ====> Epoch: 104 Average loss: 0.0887\n",
      "2019-04-09 23:39:19,220 root         INFO     Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 0.085337\n",
      "Reconstruction: 0.085337, Regularization: 0.000000\n",
      "2019-04-09 23:39:19,284 root         INFO     Train Epoch: 105 [512/8000 (6%)]\tTotal Loss: 0.081752\n",
      "Reconstruction: 0.081752, Regularization: 0.000000\n",
      "2019-04-09 23:39:19,349 root         INFO     Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 0.088415\n",
      "Reconstruction: 0.088414, Regularization: 0.000001\n",
      "2019-04-09 23:39:19,414 root         INFO     Train Epoch: 105 [1536/8000 (19%)]\tTotal Loss: 0.088555\n",
      "Reconstruction: 0.088553, Regularization: 0.000001\n",
      "2019-04-09 23:39:19,478 root         INFO     Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 0.089776\n",
      "Reconstruction: 0.089774, Regularization: 0.000001\n",
      "2019-04-09 23:39:19,543 root         INFO     Train Epoch: 105 [2560/8000 (32%)]\tTotal Loss: 0.101168\n",
      "Reconstruction: 0.101166, Regularization: 0.000002\n",
      "2019-04-09 23:39:19,607 root         INFO     Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 0.090312\n",
      "Reconstruction: 0.090311, Regularization: 0.000001\n",
      "2019-04-09 23:39:19,672 root         INFO     Train Epoch: 105 [3584/8000 (45%)]\tTotal Loss: 0.097666\n",
      "Reconstruction: 0.097665, Regularization: 0.000001\n",
      "2019-04-09 23:39:19,736 root         INFO     Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 0.085046\n",
      "Reconstruction: 0.085045, Regularization: 0.000000\n",
      "2019-04-09 23:39:19,801 root         INFO     Train Epoch: 105 [4608/8000 (58%)]\tTotal Loss: 0.091900\n",
      "Reconstruction: 0.091900, Regularization: 0.000001\n",
      "2019-04-09 23:39:19,866 root         INFO     Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 0.085404\n",
      "Reconstruction: 0.085403, Regularization: 0.000001\n",
      "2019-04-09 23:39:19,930 root         INFO     Train Epoch: 105 [5632/8000 (70%)]\tTotal Loss: 0.092159\n",
      "Reconstruction: 0.092158, Regularization: 0.000001\n",
      "2019-04-09 23:39:19,995 root         INFO     Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 0.097371\n",
      "Reconstruction: 0.097370, Regularization: 0.000001\n",
      "2019-04-09 23:39:20,060 root         INFO     Train Epoch: 105 [6656/8000 (83%)]\tTotal Loss: 0.095928\n",
      "Reconstruction: 0.095927, Regularization: 0.000001\n",
      "2019-04-09 23:39:20,125 root         INFO     Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 0.081465\n",
      "Reconstruction: 0.081465, Regularization: 0.000001\n",
      "2019-04-09 23:39:20,190 root         INFO     Train Epoch: 105 [7680/8000 (96%)]\tTotal Loss: 0.096756\n",
      "Reconstruction: 0.096756, Regularization: 0.000001\n",
      "2019-04-09 23:39:20,244 root         INFO     ====> Epoch: 105 Average loss: 0.0887\n",
      "2019-04-09 23:39:20,268 root         INFO     Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 0.096608\n",
      "Reconstruction: 0.096608, Regularization: 0.000000\n",
      "2019-04-09 23:39:20,332 root         INFO     Train Epoch: 106 [512/8000 (6%)]\tTotal Loss: 0.085502\n",
      "Reconstruction: 0.085502, Regularization: 0.000000\n",
      "2019-04-09 23:39:20,396 root         INFO     Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 0.089682\n",
      "Reconstruction: 0.089682, Regularization: 0.000000\n",
      "2019-04-09 23:39:20,459 root         INFO     Train Epoch: 106 [1536/8000 (19%)]\tTotal Loss: 0.086282\n",
      "Reconstruction: 0.086282, Regularization: 0.000000\n",
      "2019-04-09 23:39:20,523 root         INFO     Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 0.081410\n",
      "Reconstruction: 0.081410, Regularization: 0.000000\n",
      "2019-04-09 23:39:20,586 root         INFO     Train Epoch: 106 [2560/8000 (32%)]\tTotal Loss: 0.089659\n",
      "Reconstruction: 0.089658, Regularization: 0.000001\n",
      "2019-04-09 23:39:20,650 root         INFO     Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 0.097848\n",
      "Reconstruction: 0.097848, Regularization: 0.000000\n",
      "2019-04-09 23:39:20,714 root         INFO     Train Epoch: 106 [3584/8000 (45%)]\tTotal Loss: 0.085593\n",
      "Reconstruction: 0.085593, Regularization: 0.000000\n",
      "2019-04-09 23:39:20,777 root         INFO     Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 0.092889\n",
      "Reconstruction: 0.092889, Regularization: 0.000000\n",
      "2019-04-09 23:39:20,841 root         INFO     Train Epoch: 106 [4608/8000 (58%)]\tTotal Loss: 0.096828\n",
      "Reconstruction: 0.096827, Regularization: 0.000000\n",
      "2019-04-09 23:39:20,905 root         INFO     Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 0.092486\n",
      "Reconstruction: 0.092486, Regularization: 0.000000\n",
      "2019-04-09 23:39:20,968 root         INFO     Train Epoch: 106 [5632/8000 (70%)]\tTotal Loss: 0.083806\n",
      "Reconstruction: 0.083806, Regularization: 0.000000\n",
      "2019-04-09 23:39:21,032 root         INFO     Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 0.092615\n",
      "Reconstruction: 0.092615, Regularization: 0.000000\n",
      "2019-04-09 23:39:21,095 root         INFO     Train Epoch: 106 [6656/8000 (83%)]\tTotal Loss: 0.084615\n",
      "Reconstruction: 0.084615, Regularization: 0.000000\n",
      "2019-04-09 23:39:21,159 root         INFO     Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 0.086953\n",
      "Reconstruction: 0.086953, Regularization: 0.000000\n",
      "2019-04-09 23:39:21,223 root         INFO     Train Epoch: 106 [7680/8000 (96%)]\tTotal Loss: 0.086781\n",
      "Reconstruction: 0.086781, Regularization: 0.000000\n",
      "2019-04-09 23:39:21,277 root         INFO     ====> Epoch: 106 Average loss: 0.0887\n",
      "2019-04-09 23:39:21,301 root         INFO     Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 0.084741\n",
      "Reconstruction: 0.084741, Regularization: 0.000000\n",
      "2019-04-09 23:39:21,366 root         INFO     Train Epoch: 107 [512/8000 (6%)]\tTotal Loss: 0.082670\n",
      "Reconstruction: 0.082670, Regularization: 0.000000\n",
      "2019-04-09 23:39:21,430 root         INFO     Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 0.092435\n",
      "Reconstruction: 0.092435, Regularization: 0.000000\n",
      "2019-04-09 23:39:21,494 root         INFO     Train Epoch: 107 [1536/8000 (19%)]\tTotal Loss: 0.093438\n",
      "Reconstruction: 0.093437, Regularization: 0.000000\n",
      "2019-04-09 23:39:21,558 root         INFO     Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 0.093213\n",
      "Reconstruction: 0.093213, Regularization: 0.000000\n",
      "2019-04-09 23:39:21,622 root         INFO     Train Epoch: 107 [2560/8000 (32%)]\tTotal Loss: 0.083356\n",
      "Reconstruction: 0.083356, Regularization: 0.000000\n",
      "2019-04-09 23:39:21,686 root         INFO     Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 0.083057\n",
      "Reconstruction: 0.083057, Regularization: 0.000000\n",
      "2019-04-09 23:39:21,749 root         INFO     Train Epoch: 107 [3584/8000 (45%)]\tTotal Loss: 0.084552\n",
      "Reconstruction: 0.084552, Regularization: 0.000000\n",
      "2019-04-09 23:39:21,813 root         INFO     Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 0.082717\n",
      "Reconstruction: 0.082717, Regularization: 0.000000\n",
      "2019-04-09 23:39:21,877 root         INFO     Train Epoch: 107 [4608/8000 (58%)]\tTotal Loss: 0.098755\n",
      "Reconstruction: 0.098755, Regularization: 0.000000\n",
      "2019-04-09 23:39:21,941 root         INFO     Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 0.094047\n",
      "Reconstruction: 0.094047, Regularization: 0.000000\n",
      "2019-04-09 23:39:22,005 root         INFO     Train Epoch: 107 [5632/8000 (70%)]\tTotal Loss: 0.104049\n",
      "Reconstruction: 0.104049, Regularization: 0.000000\n",
      "2019-04-09 23:39:22,068 root         INFO     Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 0.086844\n",
      "Reconstruction: 0.086844, Regularization: 0.000000\n",
      "2019-04-09 23:39:22,133 root         INFO     Train Epoch: 107 [6656/8000 (83%)]\tTotal Loss: 0.083976\n",
      "Reconstruction: 0.083976, Regularization: 0.000000\n",
      "2019-04-09 23:39:22,197 root         INFO     Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 0.089430\n",
      "Reconstruction: 0.089430, Regularization: 0.000000\n",
      "2019-04-09 23:39:22,261 root         INFO     Train Epoch: 107 [7680/8000 (96%)]\tTotal Loss: 0.086655\n",
      "Reconstruction: 0.086655, Regularization: 0.000000\n",
      "2019-04-09 23:39:22,315 root         INFO     ====> Epoch: 107 Average loss: 0.0887\n",
      "2019-04-09 23:39:22,339 root         INFO     Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 0.086533\n",
      "Reconstruction: 0.086533, Regularization: 0.000000\n",
      "2019-04-09 23:39:22,403 root         INFO     Train Epoch: 108 [512/8000 (6%)]\tTotal Loss: 0.083278\n",
      "Reconstruction: 0.083278, Regularization: 0.000000\n",
      "2019-04-09 23:39:22,466 root         INFO     Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 0.099403\n",
      "Reconstruction: 0.099403, Regularization: 0.000000\n",
      "2019-04-09 23:39:22,530 root         INFO     Train Epoch: 108 [1536/8000 (19%)]\tTotal Loss: 0.088126\n",
      "Reconstruction: 0.088126, Regularization: 0.000000\n",
      "2019-04-09 23:39:22,593 root         INFO     Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 0.088646\n",
      "Reconstruction: 0.088646, Regularization: 0.000000\n",
      "2019-04-09 23:39:22,657 root         INFO     Train Epoch: 108 [2560/8000 (32%)]\tTotal Loss: 0.086573\n",
      "Reconstruction: 0.086573, Regularization: 0.000000\n",
      "2019-04-09 23:39:22,720 root         INFO     Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 0.086148\n",
      "Reconstruction: 0.086148, Regularization: 0.000000\n",
      "2019-04-09 23:39:22,783 root         INFO     Train Epoch: 108 [3584/8000 (45%)]\tTotal Loss: 0.096230\n",
      "Reconstruction: 0.096229, Regularization: 0.000001\n",
      "2019-04-09 23:39:22,847 root         INFO     Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 0.090970\n",
      "Reconstruction: 0.090970, Regularization: 0.000001\n",
      "2019-04-09 23:39:22,910 root         INFO     Train Epoch: 108 [4608/8000 (58%)]\tTotal Loss: 0.093345\n",
      "Reconstruction: 0.093344, Regularization: 0.000001\n",
      "2019-04-09 23:39:22,974 root         INFO     Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 0.092665\n",
      "Reconstruction: 0.092664, Regularization: 0.000001\n",
      "2019-04-09 23:39:23,038 root         INFO     Train Epoch: 108 [5632/8000 (70%)]\tTotal Loss: 0.089602\n",
      "Reconstruction: 0.089601, Regularization: 0.000001\n",
      "2019-04-09 23:39:23,101 root         INFO     Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 0.103095\n",
      "Reconstruction: 0.103094, Regularization: 0.000001\n",
      "2019-04-09 23:39:23,165 root         INFO     Train Epoch: 108 [6656/8000 (83%)]\tTotal Loss: 0.088128\n",
      "Reconstruction: 0.088127, Regularization: 0.000000\n",
      "2019-04-09 23:39:23,228 root         INFO     Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 0.084771\n",
      "Reconstruction: 0.084771, Regularization: 0.000000\n",
      "2019-04-09 23:39:23,291 root         INFO     Train Epoch: 108 [7680/8000 (96%)]\tTotal Loss: 0.089617\n",
      "Reconstruction: 0.089617, Regularization: 0.000000\n",
      "2019-04-09 23:39:23,346 root         INFO     ====> Epoch: 108 Average loss: 0.0887\n",
      "2019-04-09 23:39:23,369 root         INFO     Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 0.089813\n",
      "Reconstruction: 0.089813, Regularization: 0.000000\n",
      "2019-04-09 23:39:23,434 root         INFO     Train Epoch: 109 [512/8000 (6%)]\tTotal Loss: 0.083633\n",
      "Reconstruction: 0.083633, Regularization: 0.000000\n",
      "2019-04-09 23:39:23,499 root         INFO     Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 0.094956\n",
      "Reconstruction: 0.094956, Regularization: 0.000000\n",
      "2019-04-09 23:39:23,563 root         INFO     Train Epoch: 109 [1536/8000 (19%)]\tTotal Loss: 0.091003\n",
      "Reconstruction: 0.091002, Regularization: 0.000000\n",
      "2019-04-09 23:39:23,627 root         INFO     Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 0.082656\n",
      "Reconstruction: 0.082656, Regularization: 0.000000\n",
      "2019-04-09 23:39:23,691 root         INFO     Train Epoch: 109 [2560/8000 (32%)]\tTotal Loss: 0.093521\n",
      "Reconstruction: 0.093521, Regularization: 0.000001\n",
      "2019-04-09 23:39:23,755 root         INFO     Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 0.089862\n",
      "Reconstruction: 0.089861, Regularization: 0.000001\n",
      "2019-04-09 23:39:23,820 root         INFO     Train Epoch: 109 [3584/8000 (45%)]\tTotal Loss: 0.092637\n",
      "Reconstruction: 0.092636, Regularization: 0.000000\n",
      "2019-04-09 23:39:23,884 root         INFO     Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 0.091777\n",
      "Reconstruction: 0.091776, Regularization: 0.000001\n",
      "2019-04-09 23:39:23,948 root         INFO     Train Epoch: 109 [4608/8000 (58%)]\tTotal Loss: 0.082989\n",
      "Reconstruction: 0.082988, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,012 root         INFO     Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 0.093443\n",
      "Reconstruction: 0.093443, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,077 root         INFO     Train Epoch: 109 [5632/8000 (70%)]\tTotal Loss: 0.093495\n",
      "Reconstruction: 0.093495, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,141 root         INFO     Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 0.087160\n",
      "Reconstruction: 0.087160, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,206 root         INFO     Train Epoch: 109 [6656/8000 (83%)]\tTotal Loss: 0.082014\n",
      "Reconstruction: 0.082014, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,270 root         INFO     Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 0.080640\n",
      "Reconstruction: 0.080640, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,335 root         INFO     Train Epoch: 109 [7680/8000 (96%)]\tTotal Loss: 0.108354\n",
      "Reconstruction: 0.108354, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,389 root         INFO     ====> Epoch: 109 Average loss: 0.0887\n",
      "2019-04-09 23:39:24,413 root         INFO     Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 0.077654\n",
      "Reconstruction: 0.077654, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,478 root         INFO     Train Epoch: 110 [512/8000 (6%)]\tTotal Loss: 0.082210\n",
      "Reconstruction: 0.082210, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,543 root         INFO     Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 0.080228\n",
      "Reconstruction: 0.080228, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,607 root         INFO     Train Epoch: 110 [1536/8000 (19%)]\tTotal Loss: 0.089313\n",
      "Reconstruction: 0.089313, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,671 root         INFO     Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 0.088056\n",
      "Reconstruction: 0.088056, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,735 root         INFO     Train Epoch: 110 [2560/8000 (32%)]\tTotal Loss: 0.080900\n",
      "Reconstruction: 0.080900, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,800 root         INFO     Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 0.093040\n",
      "Reconstruction: 0.093040, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,864 root         INFO     Train Epoch: 110 [3584/8000 (45%)]\tTotal Loss: 0.078057\n",
      "Reconstruction: 0.078057, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,928 root         INFO     Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 0.081996\n",
      "Reconstruction: 0.081996, Regularization: 0.000000\n",
      "2019-04-09 23:39:24,992 root         INFO     Train Epoch: 110 [4608/8000 (58%)]\tTotal Loss: 0.093625\n",
      "Reconstruction: 0.093625, Regularization: 0.000000\n",
      "2019-04-09 23:39:25,056 root         INFO     Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 0.096610\n",
      "Reconstruction: 0.096610, Regularization: 0.000000\n",
      "2019-04-09 23:39:25,120 root         INFO     Train Epoch: 110 [5632/8000 (70%)]\tTotal Loss: 0.091018\n",
      "Reconstruction: 0.091018, Regularization: 0.000000\n",
      "2019-04-09 23:39:25,184 root         INFO     Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 0.101236\n",
      "Reconstruction: 0.101236, Regularization: 0.000000\n",
      "2019-04-09 23:39:25,248 root         INFO     Train Epoch: 110 [6656/8000 (83%)]\tTotal Loss: 0.086792\n",
      "Reconstruction: 0.086792, Regularization: 0.000000\n",
      "2019-04-09 23:39:25,312 root         INFO     Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 0.092202\n",
      "Reconstruction: 0.092202, Regularization: 0.000000\n",
      "2019-04-09 23:39:25,376 root         INFO     Train Epoch: 110 [7680/8000 (96%)]\tTotal Loss: 0.090511\n",
      "Reconstruction: 0.090511, Regularization: 0.000000\n",
      "2019-04-09 23:39:25,430 root         INFO     ====> Epoch: 110 Average loss: 0.0887\n",
      "2019-04-09 23:39:25,454 root         INFO     Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 0.091156\n",
      "Reconstruction: 0.091156, Regularization: 0.000000\n",
      "2019-04-09 23:39:25,518 root         INFO     Train Epoch: 111 [512/8000 (6%)]\tTotal Loss: 0.085754\n",
      "Reconstruction: 0.085753, Regularization: 0.000000\n",
      "2019-04-09 23:39:25,582 root         INFO     Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 0.081128\n",
      "Reconstruction: 0.081128, Regularization: 0.000000\n",
      "2019-04-09 23:39:25,646 root         INFO     Train Epoch: 111 [1536/8000 (19%)]\tTotal Loss: 0.085668\n",
      "Reconstruction: 0.085668, Regularization: 0.000000\n",
      "2019-04-09 23:39:25,711 root         INFO     Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 0.093302\n",
      "Reconstruction: 0.093302, Regularization: 0.000000\n",
      "2019-04-09 23:39:25,776 root         INFO     Train Epoch: 111 [2560/8000 (32%)]\tTotal Loss: 0.084833\n",
      "Reconstruction: 0.084833, Regularization: 0.000000\n",
      "2019-04-09 23:39:25,840 root         INFO     Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 0.098515\n",
      "Reconstruction: 0.098513, Regularization: 0.000001\n",
      "2019-04-09 23:39:25,904 root         INFO     Train Epoch: 111 [3584/8000 (45%)]\tTotal Loss: 0.090431\n",
      "Reconstruction: 0.090430, Regularization: 0.000001\n",
      "2019-04-09 23:39:25,968 root         INFO     Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 0.089316\n",
      "Reconstruction: 0.089315, Regularization: 0.000001\n",
      "2019-04-09 23:39:26,032 root         INFO     Train Epoch: 111 [4608/8000 (58%)]\tTotal Loss: 0.084627\n",
      "Reconstruction: 0.084626, Regularization: 0.000001\n",
      "2019-04-09 23:39:26,096 root         INFO     Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 0.093146\n",
      "Reconstruction: 0.093145, Regularization: 0.000001\n",
      "2019-04-09 23:39:26,160 root         INFO     Train Epoch: 111 [5632/8000 (70%)]\tTotal Loss: 0.089372\n",
      "Reconstruction: 0.089372, Regularization: 0.000001\n",
      "2019-04-09 23:39:26,224 root         INFO     Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 0.091533\n",
      "Reconstruction: 0.091533, Regularization: 0.000000\n",
      "2019-04-09 23:39:26,288 root         INFO     Train Epoch: 111 [6656/8000 (83%)]\tTotal Loss: 0.086827\n",
      "Reconstruction: 0.086826, Regularization: 0.000000\n",
      "2019-04-09 23:39:26,352 root         INFO     Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 0.083465\n",
      "Reconstruction: 0.083464, Regularization: 0.000000\n",
      "2019-04-09 23:39:26,416 root         INFO     Train Epoch: 111 [7680/8000 (96%)]\tTotal Loss: 0.093747\n",
      "Reconstruction: 0.093747, Regularization: 0.000000\n",
      "2019-04-09 23:39:26,470 root         INFO     ====> Epoch: 111 Average loss: 0.0887\n",
      "2019-04-09 23:39:26,494 root         INFO     Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 0.089823\n",
      "Reconstruction: 0.089822, Regularization: 0.000000\n",
      "2019-04-09 23:39:26,558 root         INFO     Train Epoch: 112 [512/8000 (6%)]\tTotal Loss: 0.082760\n",
      "Reconstruction: 0.082759, Regularization: 0.000000\n",
      "2019-04-09 23:39:26,622 root         INFO     Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 0.085653\n",
      "Reconstruction: 0.085653, Regularization: 0.000000\n",
      "2019-04-09 23:39:26,686 root         INFO     Train Epoch: 112 [1536/8000 (19%)]\tTotal Loss: 0.089920\n",
      "Reconstruction: 0.089920, Regularization: 0.000000\n",
      "2019-04-09 23:39:26,750 root         INFO     Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 0.092901\n",
      "Reconstruction: 0.092901, Regularization: 0.000000\n",
      "2019-04-09 23:39:26,813 root         INFO     Train Epoch: 112 [2560/8000 (32%)]\tTotal Loss: 0.086083\n",
      "Reconstruction: 0.086082, Regularization: 0.000000\n",
      "2019-04-09 23:39:26,877 root         INFO     Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 0.091095\n",
      "Reconstruction: 0.091095, Regularization: 0.000000\n",
      "2019-04-09 23:39:26,941 root         INFO     Train Epoch: 112 [3584/8000 (45%)]\tTotal Loss: 0.090408\n",
      "Reconstruction: 0.090408, Regularization: 0.000000\n",
      "2019-04-09 23:39:27,004 root         INFO     Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 0.092868\n",
      "Reconstruction: 0.092867, Regularization: 0.000000\n",
      "2019-04-09 23:39:27,068 root         INFO     Train Epoch: 112 [4608/8000 (58%)]\tTotal Loss: 0.081043\n",
      "Reconstruction: 0.081042, Regularization: 0.000000\n",
      "2019-04-09 23:39:27,131 root         INFO     Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 0.093352\n",
      "Reconstruction: 0.093352, Regularization: 0.000000\n",
      "2019-04-09 23:39:27,195 root         INFO     Train Epoch: 112 [5632/8000 (70%)]\tTotal Loss: 0.078095\n",
      "Reconstruction: 0.078095, Regularization: 0.000000\n",
      "2019-04-09 23:39:27,258 root         INFO     Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 0.081169\n",
      "Reconstruction: 0.081169, Regularization: 0.000000\n",
      "2019-04-09 23:39:27,322 root         INFO     Train Epoch: 112 [6656/8000 (83%)]\tTotal Loss: 0.076276\n",
      "Reconstruction: 0.076276, Regularization: 0.000000\n",
      "2019-04-09 23:39:27,386 root         INFO     Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 0.086848\n",
      "Reconstruction: 0.086848, Regularization: 0.000000\n",
      "2019-04-09 23:39:27,449 root         INFO     Train Epoch: 112 [7680/8000 (96%)]\tTotal Loss: 0.082856\n",
      "Reconstruction: 0.082856, Regularization: 0.000000\n",
      "2019-04-09 23:39:27,503 root         INFO     ====> Epoch: 112 Average loss: 0.0887\n",
      "2019-04-09 23:39:27,527 root         INFO     Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 0.083596\n",
      "Reconstruction: 0.083596, Regularization: 0.000000\n",
      "2019-04-09 23:39:27,593 root         INFO     Train Epoch: 113 [512/8000 (6%)]\tTotal Loss: 0.091743\n",
      "Reconstruction: 0.091743, Regularization: 0.000000\n",
      "2019-04-09 23:39:27,655 root         INFO     Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 0.092746\n",
      "Reconstruction: 0.092746, Regularization: 0.000001\n",
      "2019-04-09 23:39:27,718 root         INFO     Train Epoch: 113 [1536/8000 (19%)]\tTotal Loss: 0.085065\n",
      "Reconstruction: 0.085065, Regularization: 0.000001\n",
      "2019-04-09 23:39:27,781 root         INFO     Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 0.089628\n",
      "Reconstruction: 0.089627, Regularization: 0.000000\n",
      "2019-04-09 23:39:27,844 root         INFO     Train Epoch: 113 [2560/8000 (32%)]\tTotal Loss: 0.102208\n",
      "Reconstruction: 0.102208, Regularization: 0.000000\n",
      "2019-04-09 23:39:27,906 root         INFO     Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 0.088614\n",
      "Reconstruction: 0.088614, Regularization: 0.000000\n",
      "2019-04-09 23:39:27,969 root         INFO     Train Epoch: 113 [3584/8000 (45%)]\tTotal Loss: 0.092728\n",
      "Reconstruction: 0.092727, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,031 root         INFO     Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 0.082702\n",
      "Reconstruction: 0.082701, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,093 root         INFO     Train Epoch: 113 [4608/8000 (58%)]\tTotal Loss: 0.091855\n",
      "Reconstruction: 0.091854, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,156 root         INFO     Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 0.090793\n",
      "Reconstruction: 0.090792, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,218 root         INFO     Train Epoch: 113 [5632/8000 (70%)]\tTotal Loss: 0.083519\n",
      "Reconstruction: 0.083519, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,280 root         INFO     Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 0.083031\n",
      "Reconstruction: 0.083031, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,343 root         INFO     Train Epoch: 113 [6656/8000 (83%)]\tTotal Loss: 0.086684\n",
      "Reconstruction: 0.086684, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,405 root         INFO     Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 0.092023\n",
      "Reconstruction: 0.092023, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,467 root         INFO     Train Epoch: 113 [7680/8000 (96%)]\tTotal Loss: 0.085306\n",
      "Reconstruction: 0.085306, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,520 root         INFO     ====> Epoch: 113 Average loss: 0.0887\n",
      "2019-04-09 23:39:28,544 root         INFO     Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 0.085919\n",
      "Reconstruction: 0.085919, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,608 root         INFO     Train Epoch: 114 [512/8000 (6%)]\tTotal Loss: 0.085607\n",
      "Reconstruction: 0.085607, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,671 root         INFO     Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 0.083699\n",
      "Reconstruction: 0.083699, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,735 root         INFO     Train Epoch: 114 [1536/8000 (19%)]\tTotal Loss: 0.086815\n",
      "Reconstruction: 0.086815, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,800 root         INFO     Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 0.088991\n",
      "Reconstruction: 0.088991, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,864 root         INFO     Train Epoch: 114 [2560/8000 (32%)]\tTotal Loss: 0.091848\n",
      "Reconstruction: 0.091847, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,928 root         INFO     Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 0.080755\n",
      "Reconstruction: 0.080755, Regularization: 0.000000\n",
      "2019-04-09 23:39:28,992 root         INFO     Train Epoch: 114 [3584/8000 (45%)]\tTotal Loss: 0.096187\n",
      "Reconstruction: 0.096187, Regularization: 0.000000\n",
      "2019-04-09 23:39:29,054 root         INFO     Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 0.096850\n",
      "Reconstruction: 0.096850, Regularization: 0.000000\n",
      "2019-04-09 23:39:29,117 root         INFO     Train Epoch: 114 [4608/8000 (58%)]\tTotal Loss: 0.082142\n",
      "Reconstruction: 0.082141, Regularization: 0.000001\n",
      "2019-04-09 23:39:29,179 root         INFO     Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 0.090876\n",
      "Reconstruction: 0.090876, Regularization: 0.000001\n",
      "2019-04-09 23:39:29,242 root         INFO     Train Epoch: 114 [5632/8000 (70%)]\tTotal Loss: 0.094447\n",
      "Reconstruction: 0.094446, Regularization: 0.000001\n",
      "2019-04-09 23:39:29,305 root         INFO     Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 0.083551\n",
      "Reconstruction: 0.083550, Regularization: 0.000001\n",
      "2019-04-09 23:39:29,368 root         INFO     Train Epoch: 114 [6656/8000 (83%)]\tTotal Loss: 0.091764\n",
      "Reconstruction: 0.091763, Regularization: 0.000001\n",
      "2019-04-09 23:39:29,430 root         INFO     Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 0.087403\n",
      "Reconstruction: 0.087402, Regularization: 0.000001\n",
      "2019-04-09 23:39:29,494 root         INFO     Train Epoch: 114 [7680/8000 (96%)]\tTotal Loss: 0.085568\n",
      "Reconstruction: 0.085567, Regularization: 0.000001\n",
      "2019-04-09 23:39:29,548 root         INFO     ====> Epoch: 114 Average loss: 0.0887\n",
      "2019-04-09 23:39:29,572 root         INFO     Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 0.095871\n",
      "Reconstruction: 0.095870, Regularization: 0.000001\n",
      "2019-04-09 23:39:29,635 root         INFO     Train Epoch: 115 [512/8000 (6%)]\tTotal Loss: 0.088665\n",
      "Reconstruction: 0.088665, Regularization: 0.000001\n",
      "2019-04-09 23:39:29,699 root         INFO     Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 0.088639\n",
      "Reconstruction: 0.088638, Regularization: 0.000001\n",
      "2019-04-09 23:39:29,762 root         INFO     Train Epoch: 115 [1536/8000 (19%)]\tTotal Loss: 0.091536\n",
      "Reconstruction: 0.091535, Regularization: 0.000001\n",
      "2019-04-09 23:39:29,824 root         INFO     Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 0.100357\n",
      "Reconstruction: 0.100356, Regularization: 0.000002\n",
      "2019-04-09 23:39:29,887 root         INFO     Train Epoch: 115 [2560/8000 (32%)]\tTotal Loss: 0.089112\n",
      "Reconstruction: 0.089111, Regularization: 0.000001\n",
      "2019-04-09 23:39:29,949 root         INFO     Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 0.089671\n",
      "Reconstruction: 0.089669, Regularization: 0.000001\n",
      "2019-04-09 23:39:30,011 root         INFO     Train Epoch: 115 [3584/8000 (45%)]\tTotal Loss: 0.086311\n",
      "Reconstruction: 0.086310, Regularization: 0.000001\n",
      "2019-04-09 23:39:30,073 root         INFO     Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 0.089295\n",
      "Reconstruction: 0.089293, Regularization: 0.000001\n",
      "2019-04-09 23:39:30,135 root         INFO     Train Epoch: 115 [4608/8000 (58%)]\tTotal Loss: 0.088652\n",
      "Reconstruction: 0.088651, Regularization: 0.000001\n",
      "2019-04-09 23:39:30,197 root         INFO     Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 0.101349\n",
      "Reconstruction: 0.101348, Regularization: 0.000001\n",
      "2019-04-09 23:39:30,259 root         INFO     Train Epoch: 115 [5632/8000 (70%)]\tTotal Loss: 0.082134\n",
      "Reconstruction: 0.082134, Regularization: 0.000001\n",
      "2019-04-09 23:39:30,321 root         INFO     Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 0.084078\n",
      "Reconstruction: 0.084077, Regularization: 0.000000\n",
      "2019-04-09 23:39:30,383 root         INFO     Train Epoch: 115 [6656/8000 (83%)]\tTotal Loss: 0.090228\n",
      "Reconstruction: 0.090228, Regularization: 0.000000\n",
      "2019-04-09 23:39:30,446 root         INFO     Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 0.096348\n",
      "Reconstruction: 0.096348, Regularization: 0.000000\n",
      "2019-04-09 23:39:30,508 root         INFO     Train Epoch: 115 [7680/8000 (96%)]\tTotal Loss: 0.088276\n",
      "Reconstruction: 0.088276, Regularization: 0.000000\n",
      "2019-04-09 23:39:30,562 root         INFO     ====> Epoch: 115 Average loss: 0.0887\n",
      "2019-04-09 23:39:30,586 root         INFO     Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 0.080093\n",
      "Reconstruction: 0.080093, Regularization: 0.000000\n",
      "2019-04-09 23:39:30,651 root         INFO     Train Epoch: 116 [512/8000 (6%)]\tTotal Loss: 0.094632\n",
      "Reconstruction: 0.094632, Regularization: 0.000000\n",
      "2019-04-09 23:39:30,713 root         INFO     Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 0.091729\n",
      "Reconstruction: 0.091729, Regularization: 0.000000\n",
      "2019-04-09 23:39:30,776 root         INFO     Train Epoch: 116 [1536/8000 (19%)]\tTotal Loss: 0.085596\n",
      "Reconstruction: 0.085596, Regularization: 0.000000\n",
      "2019-04-09 23:39:30,838 root         INFO     Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 0.085978\n",
      "Reconstruction: 0.085978, Regularization: 0.000000\n",
      "2019-04-09 23:39:30,901 root         INFO     Train Epoch: 116 [2560/8000 (32%)]\tTotal Loss: 0.094308\n",
      "Reconstruction: 0.094308, Regularization: 0.000000\n",
      "2019-04-09 23:39:30,965 root         INFO     Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 0.078765\n",
      "Reconstruction: 0.078764, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,029 root         INFO     Train Epoch: 116 [3584/8000 (45%)]\tTotal Loss: 0.086910\n",
      "Reconstruction: 0.086909, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,093 root         INFO     Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 0.087132\n",
      "Reconstruction: 0.087132, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,157 root         INFO     Train Epoch: 116 [4608/8000 (58%)]\tTotal Loss: 0.092020\n",
      "Reconstruction: 0.092020, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,219 root         INFO     Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 0.084143\n",
      "Reconstruction: 0.084143, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,281 root         INFO     Train Epoch: 116 [5632/8000 (70%)]\tTotal Loss: 0.084613\n",
      "Reconstruction: 0.084613, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,343 root         INFO     Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 0.094726\n",
      "Reconstruction: 0.094726, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,406 root         INFO     Train Epoch: 116 [6656/8000 (83%)]\tTotal Loss: 0.094248\n",
      "Reconstruction: 0.094248, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,468 root         INFO     Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 0.087537\n",
      "Reconstruction: 0.087537, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,530 root         INFO     Train Epoch: 116 [7680/8000 (96%)]\tTotal Loss: 0.096474\n",
      "Reconstruction: 0.096474, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,584 root         INFO     ====> Epoch: 116 Average loss: 0.0887\n",
      "2019-04-09 23:39:31,608 root         INFO     Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 0.087193\n",
      "Reconstruction: 0.087193, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,672 root         INFO     Train Epoch: 117 [512/8000 (6%)]\tTotal Loss: 0.078171\n",
      "Reconstruction: 0.078171, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,735 root         INFO     Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 0.086415\n",
      "Reconstruction: 0.086415, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,799 root         INFO     Train Epoch: 117 [1536/8000 (19%)]\tTotal Loss: 0.085077\n",
      "Reconstruction: 0.085076, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,861 root         INFO     Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 0.095080\n",
      "Reconstruction: 0.095080, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,924 root         INFO     Train Epoch: 117 [2560/8000 (32%)]\tTotal Loss: 0.092628\n",
      "Reconstruction: 0.092628, Regularization: 0.000000\n",
      "2019-04-09 23:39:31,987 root         INFO     Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 0.090796\n",
      "Reconstruction: 0.090796, Regularization: 0.000000\n",
      "2019-04-09 23:39:32,050 root         INFO     Train Epoch: 117 [3584/8000 (45%)]\tTotal Loss: 0.089103\n",
      "Reconstruction: 0.089102, Regularization: 0.000001\n",
      "2019-04-09 23:39:32,113 root         INFO     Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 0.086147\n",
      "Reconstruction: 0.086147, Regularization: 0.000000\n",
      "2019-04-09 23:39:32,176 root         INFO     Train Epoch: 117 [4608/8000 (58%)]\tTotal Loss: 0.081641\n",
      "Reconstruction: 0.081641, Regularization: 0.000000\n",
      "2019-04-09 23:39:32,238 root         INFO     Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 0.085787\n",
      "Reconstruction: 0.085787, Regularization: 0.000000\n",
      "2019-04-09 23:39:32,301 root         INFO     Train Epoch: 117 [5632/8000 (70%)]\tTotal Loss: 0.087489\n",
      "Reconstruction: 0.087489, Regularization: 0.000000\n",
      "2019-04-09 23:39:32,363 root         INFO     Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 0.094230\n",
      "Reconstruction: 0.094230, Regularization: 0.000000\n",
      "2019-04-09 23:39:32,426 root         INFO     Train Epoch: 117 [6656/8000 (83%)]\tTotal Loss: 0.096208\n",
      "Reconstruction: 0.096208, Regularization: 0.000000\n",
      "2019-04-09 23:39:32,490 root         INFO     Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 0.078329\n",
      "Reconstruction: 0.078329, Regularization: 0.000000\n",
      "2019-04-09 23:39:32,553 root         INFO     Train Epoch: 117 [7680/8000 (96%)]\tTotal Loss: 0.080370\n",
      "Reconstruction: 0.080370, Regularization: 0.000000\n",
      "2019-04-09 23:39:32,606 root         INFO     ====> Epoch: 117 Average loss: 0.0887\n",
      "2019-04-09 23:39:32,630 root         INFO     Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 0.083055\n",
      "Reconstruction: 0.083055, Regularization: 0.000000\n",
      "2019-04-09 23:39:32,693 root         INFO     Train Epoch: 118 [512/8000 (6%)]\tTotal Loss: 0.087222\n",
      "Reconstruction: 0.087222, Regularization: 0.000000\n",
      "2019-04-09 23:39:32,754 root         INFO     Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 0.089630\n",
      "Reconstruction: 0.089630, Regularization: 0.000000\n",
      "2019-04-09 23:39:32,816 root         INFO     Train Epoch: 118 [1536/8000 (19%)]\tTotal Loss: 0.091444\n",
      "Reconstruction: 0.091444, Regularization: 0.000000\n",
      "2019-04-09 23:39:32,878 root         INFO     Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 0.091298\n",
      "Reconstruction: 0.091298, Regularization: 0.000000\n",
      "2019-04-09 23:39:32,941 root         INFO     Train Epoch: 118 [2560/8000 (32%)]\tTotal Loss: 0.096233\n",
      "Reconstruction: 0.096233, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,003 root         INFO     Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 0.082624\n",
      "Reconstruction: 0.082624, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,066 root         INFO     Train Epoch: 118 [3584/8000 (45%)]\tTotal Loss: 0.096870\n",
      "Reconstruction: 0.096870, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,129 root         INFO     Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 0.095806\n",
      "Reconstruction: 0.095806, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,193 root         INFO     Train Epoch: 118 [4608/8000 (58%)]\tTotal Loss: 0.082791\n",
      "Reconstruction: 0.082791, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,255 root         INFO     Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 0.093337\n",
      "Reconstruction: 0.093337, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,318 root         INFO     Train Epoch: 118 [5632/8000 (70%)]\tTotal Loss: 0.086840\n",
      "Reconstruction: 0.086840, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,382 root         INFO     Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 0.099944\n",
      "Reconstruction: 0.099944, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,445 root         INFO     Train Epoch: 118 [6656/8000 (83%)]\tTotal Loss: 0.081393\n",
      "Reconstruction: 0.081393, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,509 root         INFO     Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 0.084169\n",
      "Reconstruction: 0.084169, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,573 root         INFO     Train Epoch: 118 [7680/8000 (96%)]\tTotal Loss: 0.108663\n",
      "Reconstruction: 0.108663, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,627 root         INFO     ====> Epoch: 118 Average loss: 0.0887\n",
      "2019-04-09 23:39:33,651 root         INFO     Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 0.097760\n",
      "Reconstruction: 0.097760, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,715 root         INFO     Train Epoch: 119 [512/8000 (6%)]\tTotal Loss: 0.091134\n",
      "Reconstruction: 0.091134, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,779 root         INFO     Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 0.098811\n",
      "Reconstruction: 0.098811, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,843 root         INFO     Train Epoch: 119 [1536/8000 (19%)]\tTotal Loss: 0.084515\n",
      "Reconstruction: 0.084515, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,906 root         INFO     Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 0.092860\n",
      "Reconstruction: 0.092860, Regularization: 0.000000\n",
      "2019-04-09 23:39:33,970 root         INFO     Train Epoch: 119 [2560/8000 (32%)]\tTotal Loss: 0.087547\n",
      "Reconstruction: 0.087547, Regularization: 0.000000\n",
      "2019-04-09 23:39:34,033 root         INFO     Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 0.087693\n",
      "Reconstruction: 0.087692, Regularization: 0.000001\n",
      "2019-04-09 23:39:34,097 root         INFO     Train Epoch: 119 [3584/8000 (45%)]\tTotal Loss: 0.089709\n",
      "Reconstruction: 0.089708, Regularization: 0.000001\n",
      "2019-04-09 23:39:34,160 root         INFO     Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 0.078507\n",
      "Reconstruction: 0.078506, Regularization: 0.000000\n",
      "2019-04-09 23:39:34,224 root         INFO     Train Epoch: 119 [4608/8000 (58%)]\tTotal Loss: 0.082560\n",
      "Reconstruction: 0.082560, Regularization: 0.000000\n",
      "2019-04-09 23:39:34,286 root         INFO     Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 0.090512\n",
      "Reconstruction: 0.090511, Regularization: 0.000000\n",
      "2019-04-09 23:39:34,350 root         INFO     Train Epoch: 119 [5632/8000 (70%)]\tTotal Loss: 0.094933\n",
      "Reconstruction: 0.094933, Regularization: 0.000000\n",
      "2019-04-09 23:39:34,413 root         INFO     Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 0.087294\n",
      "Reconstruction: 0.087293, Regularization: 0.000000\n",
      "2019-04-09 23:39:34,477 root         INFO     Train Epoch: 119 [6656/8000 (83%)]\tTotal Loss: 0.081241\n",
      "Reconstruction: 0.081241, Regularization: 0.000000\n",
      "2019-04-09 23:39:34,539 root         INFO     Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 0.082133\n",
      "Reconstruction: 0.082133, Regularization: 0.000000\n",
      "2019-04-09 23:39:34,603 root         INFO     Train Epoch: 119 [7680/8000 (96%)]\tTotal Loss: 0.092078\n",
      "Reconstruction: 0.092077, Regularization: 0.000000\n",
      "2019-04-09 23:39:34,657 root         INFO     ====> Epoch: 119 Average loss: 0.0887\n",
      "2019-04-09 23:39:34,681 root         INFO     Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 0.083779\n",
      "Reconstruction: 0.083779, Regularization: 0.000000\n",
      "2019-04-09 23:39:34,746 root         INFO     Train Epoch: 120 [512/8000 (6%)]\tTotal Loss: 0.090985\n",
      "Reconstruction: 0.090985, Regularization: 0.000000\n",
      "2019-04-09 23:39:34,811 root         INFO     Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 0.081443\n",
      "Reconstruction: 0.081443, Regularization: 0.000000\n",
      "2019-04-09 23:39:34,875 root         INFO     Train Epoch: 120 [1536/8000 (19%)]\tTotal Loss: 0.088839\n",
      "Reconstruction: 0.088838, Regularization: 0.000000\n",
      "2019-04-09 23:39:34,939 root         INFO     Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 0.090606\n",
      "Reconstruction: 0.090605, Regularization: 0.000001\n",
      "2019-04-09 23:39:35,003 root         INFO     Train Epoch: 120 [2560/8000 (32%)]\tTotal Loss: 0.093053\n",
      "Reconstruction: 0.093053, Regularization: 0.000000\n",
      "2019-04-09 23:39:35,068 root         INFO     Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 0.088514\n",
      "Reconstruction: 0.088514, Regularization: 0.000000\n",
      "2019-04-09 23:39:35,135 root         INFO     Train Epoch: 120 [3584/8000 (45%)]\tTotal Loss: 0.080906\n",
      "Reconstruction: 0.080906, Regularization: 0.000000\n",
      "2019-04-09 23:39:35,201 root         INFO     Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 0.081446\n",
      "Reconstruction: 0.081445, Regularization: 0.000000\n",
      "2019-04-09 23:39:35,267 root         INFO     Train Epoch: 120 [4608/8000 (58%)]\tTotal Loss: 0.086859\n",
      "Reconstruction: 0.086858, Regularization: 0.000000\n",
      "2019-04-09 23:39:35,332 root         INFO     Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 0.086359\n",
      "Reconstruction: 0.086358, Regularization: 0.000000\n",
      "2019-04-09 23:39:35,399 root         INFO     Train Epoch: 120 [5632/8000 (70%)]\tTotal Loss: 0.085545\n",
      "Reconstruction: 0.085545, Regularization: 0.000000\n",
      "2019-04-09 23:39:35,464 root         INFO     Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 0.093569\n",
      "Reconstruction: 0.093569, Regularization: 0.000000\n",
      "2019-04-09 23:39:35,530 root         INFO     Train Epoch: 120 [6656/8000 (83%)]\tTotal Loss: 0.085033\n",
      "Reconstruction: 0.085033, Regularization: 0.000000\n",
      "2019-04-09 23:39:35,596 root         INFO     Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 0.089911\n",
      "Reconstruction: 0.089911, Regularization: 0.000000\n",
      "2019-04-09 23:39:35,660 root         INFO     Train Epoch: 120 [7680/8000 (96%)]\tTotal Loss: 0.095378\n",
      "Reconstruction: 0.095377, Regularization: 0.000001\n",
      "2019-04-09 23:39:35,715 root         INFO     ====> Epoch: 120 Average loss: 0.0887\n",
      "2019-04-09 23:39:35,739 root         INFO     Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 0.102454\n",
      "Reconstruction: 0.102453, Regularization: 0.000001\n",
      "2019-04-09 23:39:35,804 root         INFO     Train Epoch: 121 [512/8000 (6%)]\tTotal Loss: 0.080341\n",
      "Reconstruction: 0.080340, Regularization: 0.000001\n",
      "2019-04-09 23:39:35,868 root         INFO     Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 0.087801\n",
      "Reconstruction: 0.087799, Regularization: 0.000002\n",
      "2019-04-09 23:39:35,932 root         INFO     Train Epoch: 121 [1536/8000 (19%)]\tTotal Loss: 0.085439\n",
      "Reconstruction: 0.085437, Regularization: 0.000002\n",
      "2019-04-09 23:39:35,995 root         INFO     Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 0.093309\n",
      "Reconstruction: 0.093308, Regularization: 0.000001\n",
      "2019-04-09 23:39:36,058 root         INFO     Train Epoch: 121 [2560/8000 (32%)]\tTotal Loss: 0.080285\n",
      "Reconstruction: 0.080285, Regularization: 0.000000\n",
      "2019-04-09 23:39:36,121 root         INFO     Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 0.087777\n",
      "Reconstruction: 0.087776, Regularization: 0.000000\n",
      "2019-04-09 23:39:36,184 root         INFO     Train Epoch: 121 [3584/8000 (45%)]\tTotal Loss: 0.088541\n",
      "Reconstruction: 0.088541, Regularization: 0.000000\n",
      "2019-04-09 23:39:36,247 root         INFO     Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 0.088146\n",
      "Reconstruction: 0.088146, Regularization: 0.000000\n",
      "2019-04-09 23:39:36,310 root         INFO     Train Epoch: 121 [4608/8000 (58%)]\tTotal Loss: 0.086502\n",
      "Reconstruction: 0.086502, Regularization: 0.000000\n",
      "2019-04-09 23:39:36,373 root         INFO     Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 0.088313\n",
      "Reconstruction: 0.088313, Regularization: 0.000000\n",
      "2019-04-09 23:39:36,436 root         INFO     Train Epoch: 121 [5632/8000 (70%)]\tTotal Loss: 0.088602\n",
      "Reconstruction: 0.088602, Regularization: 0.000000\n",
      "2019-04-09 23:39:36,500 root         INFO     Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 0.089072\n",
      "Reconstruction: 0.089072, Regularization: 0.000000\n",
      "2019-04-09 23:39:36,563 root         INFO     Train Epoch: 121 [6656/8000 (83%)]\tTotal Loss: 0.089803\n",
      "Reconstruction: 0.089803, Regularization: 0.000000\n",
      "2019-04-09 23:39:36,626 root         INFO     Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 0.094392\n",
      "Reconstruction: 0.094392, Regularization: 0.000000\n",
      "2019-04-09 23:39:36,689 root         INFO     Train Epoch: 121 [7680/8000 (96%)]\tTotal Loss: 0.086419\n",
      "Reconstruction: 0.086419, Regularization: 0.000000\n",
      "2019-04-09 23:39:36,742 root         INFO     ====> Epoch: 121 Average loss: 0.0887\n",
      "2019-04-09 23:39:36,767 root         INFO     Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 0.090334\n",
      "Reconstruction: 0.090334, Regularization: 0.000000\n",
      "2019-04-09 23:39:36,831 root         INFO     Train Epoch: 122 [512/8000 (6%)]\tTotal Loss: 0.088632\n",
      "Reconstruction: 0.088632, Regularization: 0.000000\n",
      "2019-04-09 23:39:36,895 root         INFO     Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 0.088388\n",
      "Reconstruction: 0.088387, Regularization: 0.000000\n",
      "2019-04-09 23:39:36,959 root         INFO     Train Epoch: 122 [1536/8000 (19%)]\tTotal Loss: 0.089162\n",
      "Reconstruction: 0.089161, Regularization: 0.000001\n",
      "2019-04-09 23:39:37,022 root         INFO     Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 0.089199\n",
      "Reconstruction: 0.089199, Regularization: 0.000000\n",
      "2019-04-09 23:39:37,086 root         INFO     Train Epoch: 122 [2560/8000 (32%)]\tTotal Loss: 0.077808\n",
      "Reconstruction: 0.077807, Regularization: 0.000000\n",
      "2019-04-09 23:39:37,150 root         INFO     Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 0.084328\n",
      "Reconstruction: 0.084328, Regularization: 0.000000\n",
      "2019-04-09 23:39:37,213 root         INFO     Train Epoch: 122 [3584/8000 (45%)]\tTotal Loss: 0.082537\n",
      "Reconstruction: 0.082536, Regularization: 0.000000\n",
      "2019-04-09 23:39:37,277 root         INFO     Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 0.096681\n",
      "Reconstruction: 0.096680, Regularization: 0.000001\n",
      "2019-04-09 23:39:37,341 root         INFO     Train Epoch: 122 [4608/8000 (58%)]\tTotal Loss: 0.092042\n",
      "Reconstruction: 0.092041, Regularization: 0.000001\n",
      "2019-04-09 23:39:37,404 root         INFO     Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 0.082527\n",
      "Reconstruction: 0.082525, Regularization: 0.000002\n",
      "2019-04-09 23:39:37,467 root         INFO     Train Epoch: 122 [5632/8000 (70%)]\tTotal Loss: 0.090897\n",
      "Reconstruction: 0.090894, Regularization: 0.000002\n",
      "2019-04-09 23:39:37,530 root         INFO     Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 0.081257\n",
      "Reconstruction: 0.081255, Regularization: 0.000002\n",
      "2019-04-09 23:39:37,594 root         INFO     Train Epoch: 122 [6656/8000 (83%)]\tTotal Loss: 0.084853\n",
      "Reconstruction: 0.084850, Regularization: 0.000003\n",
      "2019-04-09 23:39:37,658 root         INFO     Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 0.081973\n",
      "Reconstruction: 0.081970, Regularization: 0.000002\n",
      "2019-04-09 23:39:37,721 root         INFO     Train Epoch: 122 [7680/8000 (96%)]\tTotal Loss: 0.090073\n",
      "Reconstruction: 0.090069, Regularization: 0.000004\n",
      "2019-04-09 23:39:37,775 root         INFO     ====> Epoch: 122 Average loss: 0.0887\n",
      "2019-04-09 23:39:37,799 root         INFO     Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 0.079468\n",
      "Reconstruction: 0.079467, Regularization: 0.000001\n",
      "2019-04-09 23:39:37,863 root         INFO     Train Epoch: 123 [512/8000 (6%)]\tTotal Loss: 0.097446\n",
      "Reconstruction: 0.097443, Regularization: 0.000003\n",
      "2019-04-09 23:39:37,928 root         INFO     Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 0.088411\n",
      "Reconstruction: 0.088409, Regularization: 0.000002\n",
      "2019-04-09 23:39:37,991 root         INFO     Train Epoch: 123 [1536/8000 (19%)]\tTotal Loss: 0.086649\n",
      "Reconstruction: 0.086647, Regularization: 0.000002\n",
      "2019-04-09 23:39:38,055 root         INFO     Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 0.084064\n",
      "Reconstruction: 0.084063, Regularization: 0.000002\n",
      "2019-04-09 23:39:38,120 root         INFO     Train Epoch: 123 [2560/8000 (32%)]\tTotal Loss: 0.091254\n",
      "Reconstruction: 0.091252, Regularization: 0.000003\n",
      "2019-04-09 23:39:38,183 root         INFO     Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 0.086817\n",
      "Reconstruction: 0.086815, Regularization: 0.000002\n",
      "2019-04-09 23:39:38,247 root         INFO     Train Epoch: 123 [3584/8000 (45%)]\tTotal Loss: 0.101850\n",
      "Reconstruction: 0.101845, Regularization: 0.000004\n",
      "2019-04-09 23:39:38,311 root         INFO     Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 0.085172\n",
      "Reconstruction: 0.085170, Regularization: 0.000002\n",
      "2019-04-09 23:39:38,375 root         INFO     Train Epoch: 123 [4608/8000 (58%)]\tTotal Loss: 0.081512\n",
      "Reconstruction: 0.081510, Regularization: 0.000002\n",
      "2019-04-09 23:39:38,439 root         INFO     Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 0.100293\n",
      "Reconstruction: 0.100290, Regularization: 0.000002\n",
      "2019-04-09 23:39:38,504 root         INFO     Train Epoch: 123 [5632/8000 (70%)]\tTotal Loss: 0.093413\n",
      "Reconstruction: 0.093411, Regularization: 0.000002\n",
      "2019-04-09 23:39:38,566 root         INFO     Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 0.094157\n",
      "Reconstruction: 0.094156, Regularization: 0.000001\n",
      "2019-04-09 23:39:38,628 root         INFO     Train Epoch: 123 [6656/8000 (83%)]\tTotal Loss: 0.080411\n",
      "Reconstruction: 0.080410, Regularization: 0.000001\n",
      "2019-04-09 23:39:38,690 root         INFO     Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 0.084963\n",
      "Reconstruction: 0.084962, Regularization: 0.000001\n",
      "2019-04-09 23:39:38,752 root         INFO     Train Epoch: 123 [7680/8000 (96%)]\tTotal Loss: 0.085232\n",
      "Reconstruction: 0.085232, Regularization: 0.000000\n",
      "2019-04-09 23:39:38,805 root         INFO     ====> Epoch: 123 Average loss: 0.0887\n",
      "2019-04-09 23:39:38,830 root         INFO     Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 0.076874\n",
      "Reconstruction: 0.076874, Regularization: 0.000000\n",
      "2019-04-09 23:39:38,893 root         INFO     Train Epoch: 124 [512/8000 (6%)]\tTotal Loss: 0.090100\n",
      "Reconstruction: 0.090100, Regularization: 0.000000\n",
      "2019-04-09 23:39:38,956 root         INFO     Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 0.086805\n",
      "Reconstruction: 0.086805, Regularization: 0.000000\n",
      "2019-04-09 23:39:39,019 root         INFO     Train Epoch: 124 [1536/8000 (19%)]\tTotal Loss: 0.092408\n",
      "Reconstruction: 0.092407, Regularization: 0.000000\n",
      "2019-04-09 23:39:39,082 root         INFO     Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 0.097607\n",
      "Reconstruction: 0.097607, Regularization: 0.000000\n",
      "2019-04-09 23:39:39,145 root         INFO     Train Epoch: 124 [2560/8000 (32%)]\tTotal Loss: 0.085894\n",
      "Reconstruction: 0.085894, Regularization: 0.000000\n",
      "2019-04-09 23:39:39,208 root         INFO     Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 0.082168\n",
      "Reconstruction: 0.082168, Regularization: 0.000000\n",
      "2019-04-09 23:39:39,272 root         INFO     Train Epoch: 124 [3584/8000 (45%)]\tTotal Loss: 0.089991\n",
      "Reconstruction: 0.089991, Regularization: 0.000000\n",
      "2019-04-09 23:39:39,335 root         INFO     Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 0.087720\n",
      "Reconstruction: 0.087720, Regularization: 0.000000\n",
      "2019-04-09 23:39:39,398 root         INFO     Train Epoch: 124 [4608/8000 (58%)]\tTotal Loss: 0.088372\n",
      "Reconstruction: 0.088372, Regularization: 0.000000\n",
      "2019-04-09 23:39:39,461 root         INFO     Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 0.084522\n",
      "Reconstruction: 0.084522, Regularization: 0.000000\n",
      "2019-04-09 23:39:39,524 root         INFO     Train Epoch: 124 [5632/8000 (70%)]\tTotal Loss: 0.087054\n",
      "Reconstruction: 0.087054, Regularization: 0.000000\n",
      "2019-04-09 23:39:39,587 root         INFO     Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 0.088293\n",
      "Reconstruction: 0.088292, Regularization: 0.000000\n",
      "2019-04-09 23:39:39,650 root         INFO     Train Epoch: 124 [6656/8000 (83%)]\tTotal Loss: 0.087891\n",
      "Reconstruction: 0.087891, Regularization: 0.000000\n",
      "2019-04-09 23:39:39,713 root         INFO     Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 0.086085\n",
      "Reconstruction: 0.086084, Regularization: 0.000000\n",
      "2019-04-09 23:39:39,776 root         INFO     Train Epoch: 124 [7680/8000 (96%)]\tTotal Loss: 0.085195\n",
      "Reconstruction: 0.085195, Regularization: 0.000000\n",
      "2019-04-09 23:39:39,830 root         INFO     ====> Epoch: 124 Average loss: 0.0887\n",
      "2019-04-09 23:39:39,854 root         INFO     Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 0.091214\n",
      "Reconstruction: 0.091213, Regularization: 0.000001\n",
      "2019-04-09 23:39:39,918 root         INFO     Train Epoch: 125 [512/8000 (6%)]\tTotal Loss: 0.086181\n",
      "Reconstruction: 0.086180, Regularization: 0.000001\n",
      "2019-04-09 23:39:39,981 root         INFO     Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 0.085662\n",
      "Reconstruction: 0.085661, Regularization: 0.000001\n",
      "2019-04-09 23:39:40,044 root         INFO     Train Epoch: 125 [1536/8000 (19%)]\tTotal Loss: 0.087473\n",
      "Reconstruction: 0.087472, Regularization: 0.000001\n",
      "2019-04-09 23:39:40,107 root         INFO     Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 0.090436\n",
      "Reconstruction: 0.090435, Regularization: 0.000001\n",
      "2019-04-09 23:39:40,170 root         INFO     Train Epoch: 125 [2560/8000 (32%)]\tTotal Loss: 0.099485\n",
      "Reconstruction: 0.099483, Regularization: 0.000002\n",
      "2019-04-09 23:39:40,233 root         INFO     Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 0.088555\n",
      "Reconstruction: 0.088553, Regularization: 0.000001\n",
      "2019-04-09 23:39:40,297 root         INFO     Train Epoch: 125 [3584/8000 (45%)]\tTotal Loss: 0.081870\n",
      "Reconstruction: 0.081869, Regularization: 0.000001\n",
      "2019-04-09 23:39:40,360 root         INFO     Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 0.087180\n",
      "Reconstruction: 0.087179, Regularization: 0.000001\n",
      "2019-04-09 23:39:40,423 root         INFO     Train Epoch: 125 [4608/8000 (58%)]\tTotal Loss: 0.086482\n",
      "Reconstruction: 0.086481, Regularization: 0.000001\n",
      "2019-04-09 23:39:40,487 root         INFO     Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 0.091392\n",
      "Reconstruction: 0.091391, Regularization: 0.000001\n",
      "2019-04-09 23:39:40,550 root         INFO     Train Epoch: 125 [5632/8000 (70%)]\tTotal Loss: 0.091592\n",
      "Reconstruction: 0.091591, Regularization: 0.000000\n",
      "2019-04-09 23:39:40,613 root         INFO     Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 0.090294\n",
      "Reconstruction: 0.090294, Regularization: 0.000000\n",
      "2019-04-09 23:39:40,676 root         INFO     Train Epoch: 125 [6656/8000 (83%)]\tTotal Loss: 0.089045\n",
      "Reconstruction: 0.089045, Regularization: 0.000000\n",
      "2019-04-09 23:39:40,742 root         INFO     Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 0.090144\n",
      "Reconstruction: 0.090144, Regularization: 0.000000\n",
      "2019-04-09 23:39:40,805 root         INFO     Train Epoch: 125 [7680/8000 (96%)]\tTotal Loss: 0.088898\n",
      "Reconstruction: 0.088897, Regularization: 0.000000\n",
      "2019-04-09 23:39:40,858 root         INFO     ====> Epoch: 125 Average loss: 0.0887\n",
      "2019-04-09 23:39:40,882 root         INFO     Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 0.087399\n",
      "Reconstruction: 0.087399, Regularization: 0.000000\n",
      "2019-04-09 23:39:40,946 root         INFO     Train Epoch: 126 [512/8000 (6%)]\tTotal Loss: 0.093232\n",
      "Reconstruction: 0.093232, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,010 root         INFO     Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 0.083680\n",
      "Reconstruction: 0.083680, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,074 root         INFO     Train Epoch: 126 [1536/8000 (19%)]\tTotal Loss: 0.095992\n",
      "Reconstruction: 0.095991, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,138 root         INFO     Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 0.087376\n",
      "Reconstruction: 0.087376, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,202 root         INFO     Train Epoch: 126 [2560/8000 (32%)]\tTotal Loss: 0.077937\n",
      "Reconstruction: 0.077937, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,265 root         INFO     Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 0.082965\n",
      "Reconstruction: 0.082965, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,329 root         INFO     Train Epoch: 126 [3584/8000 (45%)]\tTotal Loss: 0.079653\n",
      "Reconstruction: 0.079653, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,393 root         INFO     Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 0.090176\n",
      "Reconstruction: 0.090176, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,457 root         INFO     Train Epoch: 126 [4608/8000 (58%)]\tTotal Loss: 0.102616\n",
      "Reconstruction: 0.102616, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,520 root         INFO     Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 0.084476\n",
      "Reconstruction: 0.084475, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,583 root         INFO     Train Epoch: 126 [5632/8000 (70%)]\tTotal Loss: 0.082159\n",
      "Reconstruction: 0.082159, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,647 root         INFO     Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 0.083100\n",
      "Reconstruction: 0.083100, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,710 root         INFO     Train Epoch: 126 [6656/8000 (83%)]\tTotal Loss: 0.093040\n",
      "Reconstruction: 0.093040, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,774 root         INFO     Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 0.083406\n",
      "Reconstruction: 0.083405, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,838 root         INFO     Train Epoch: 126 [7680/8000 (96%)]\tTotal Loss: 0.088837\n",
      "Reconstruction: 0.088837, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,892 root         INFO     ====> Epoch: 126 Average loss: 0.0887\n",
      "2019-04-09 23:39:41,916 root         INFO     Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 0.085591\n",
      "Reconstruction: 0.085590, Regularization: 0.000000\n",
      "2019-04-09 23:39:41,980 root         INFO     Train Epoch: 127 [512/8000 (6%)]\tTotal Loss: 0.095857\n",
      "Reconstruction: 0.095857, Regularization: 0.000001\n",
      "2019-04-09 23:39:42,043 root         INFO     Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 0.087299\n",
      "Reconstruction: 0.087299, Regularization: 0.000001\n",
      "2019-04-09 23:39:42,107 root         INFO     Train Epoch: 127 [1536/8000 (19%)]\tTotal Loss: 0.093863\n",
      "Reconstruction: 0.093862, Regularization: 0.000001\n",
      "2019-04-09 23:39:42,171 root         INFO     Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 0.086963\n",
      "Reconstruction: 0.086963, Regularization: 0.000000\n",
      "2019-04-09 23:39:42,234 root         INFO     Train Epoch: 127 [2560/8000 (32%)]\tTotal Loss: 0.080305\n",
      "Reconstruction: 0.080305, Regularization: 0.000001\n",
      "2019-04-09 23:39:42,298 root         INFO     Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 0.089222\n",
      "Reconstruction: 0.089221, Regularization: 0.000001\n",
      "2019-04-09 23:39:42,362 root         INFO     Train Epoch: 127 [3584/8000 (45%)]\tTotal Loss: 0.081527\n",
      "Reconstruction: 0.081525, Regularization: 0.000002\n",
      "2019-04-09 23:39:42,425 root         INFO     Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 0.086341\n",
      "Reconstruction: 0.086338, Regularization: 0.000003\n",
      "2019-04-09 23:39:42,489 root         INFO     Train Epoch: 127 [4608/8000 (58%)]\tTotal Loss: 0.096629\n",
      "Reconstruction: 0.096623, Regularization: 0.000005\n",
      "2019-04-09 23:39:42,553 root         INFO     Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 0.095041\n",
      "Reconstruction: 0.095035, Regularization: 0.000006\n",
      "2019-04-09 23:39:42,617 root         INFO     Train Epoch: 127 [5632/8000 (70%)]\tTotal Loss: 0.085121\n",
      "Reconstruction: 0.085116, Regularization: 0.000005\n",
      "2019-04-09 23:39:42,681 root         INFO     Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 0.092807\n",
      "Reconstruction: 0.092802, Regularization: 0.000005\n",
      "2019-04-09 23:39:42,745 root         INFO     Train Epoch: 127 [6656/8000 (83%)]\tTotal Loss: 0.092729\n",
      "Reconstruction: 0.092724, Regularization: 0.000004\n",
      "2019-04-09 23:39:42,808 root         INFO     Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 0.086253\n",
      "Reconstruction: 0.086250, Regularization: 0.000003\n",
      "2019-04-09 23:39:42,872 root         INFO     Train Epoch: 127 [7680/8000 (96%)]\tTotal Loss: 0.097500\n",
      "Reconstruction: 0.097495, Regularization: 0.000005\n",
      "2019-04-09 23:39:42,926 root         INFO     ====> Epoch: 127 Average loss: 0.0887\n",
      "2019-04-09 23:39:42,950 root         INFO     Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 0.088803\n",
      "Reconstruction: 0.088799, Regularization: 0.000005\n",
      "2019-04-09 23:39:43,014 root         INFO     Train Epoch: 128 [512/8000 (6%)]\tTotal Loss: 0.091053\n",
      "Reconstruction: 0.091049, Regularization: 0.000004\n",
      "2019-04-09 23:39:43,078 root         INFO     Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 0.088141\n",
      "Reconstruction: 0.088138, Regularization: 0.000003\n",
      "2019-04-09 23:39:43,141 root         INFO     Train Epoch: 128 [1536/8000 (19%)]\tTotal Loss: 0.092044\n",
      "Reconstruction: 0.092036, Regularization: 0.000007\n",
      "2019-04-09 23:39:43,206 root         INFO     Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 0.096272\n",
      "Reconstruction: 0.096265, Regularization: 0.000007\n",
      "2019-04-09 23:39:43,269 root         INFO     Train Epoch: 128 [2560/8000 (32%)]\tTotal Loss: 0.081722\n",
      "Reconstruction: 0.081719, Regularization: 0.000003\n",
      "2019-04-09 23:39:43,333 root         INFO     Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 0.087721\n",
      "Reconstruction: 0.087718, Regularization: 0.000004\n",
      "2019-04-09 23:39:43,397 root         INFO     Train Epoch: 128 [3584/8000 (45%)]\tTotal Loss: 0.087586\n",
      "Reconstruction: 0.087583, Regularization: 0.000003\n",
      "2019-04-09 23:39:43,461 root         INFO     Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 0.081769\n",
      "Reconstruction: 0.081767, Regularization: 0.000003\n",
      "2019-04-09 23:39:43,524 root         INFO     Train Epoch: 128 [4608/8000 (58%)]\tTotal Loss: 0.096745\n",
      "Reconstruction: 0.096742, Regularization: 0.000003\n",
      "2019-04-09 23:39:43,589 root         INFO     Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 0.084496\n",
      "Reconstruction: 0.084494, Regularization: 0.000002\n",
      "2019-04-09 23:39:43,653 root         INFO     Train Epoch: 128 [5632/8000 (70%)]\tTotal Loss: 0.088810\n",
      "Reconstruction: 0.088809, Regularization: 0.000001\n",
      "2019-04-09 23:39:43,716 root         INFO     Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 0.085107\n",
      "Reconstruction: 0.085106, Regularization: 0.000001\n",
      "2019-04-09 23:39:43,778 root         INFO     Train Epoch: 128 [6656/8000 (83%)]\tTotal Loss: 0.084153\n",
      "Reconstruction: 0.084152, Regularization: 0.000001\n",
      "2019-04-09 23:39:43,841 root         INFO     Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 0.098830\n",
      "Reconstruction: 0.098828, Regularization: 0.000002\n",
      "2019-04-09 23:39:43,905 root         INFO     Train Epoch: 128 [7680/8000 (96%)]\tTotal Loss: 0.086235\n",
      "Reconstruction: 0.086234, Regularization: 0.000002\n",
      "2019-04-09 23:39:43,959 root         INFO     ====> Epoch: 128 Average loss: 0.0887\n",
      "2019-04-09 23:39:43,983 root         INFO     Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 0.086684\n",
      "Reconstruction: 0.086682, Regularization: 0.000002\n",
      "2019-04-09 23:39:44,047 root         INFO     Train Epoch: 129 [512/8000 (6%)]\tTotal Loss: 0.089804\n",
      "Reconstruction: 0.089802, Regularization: 0.000002\n",
      "2019-04-09 23:39:44,111 root         INFO     Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 0.095542\n",
      "Reconstruction: 0.095539, Regularization: 0.000003\n",
      "2019-04-09 23:39:44,174 root         INFO     Train Epoch: 129 [1536/8000 (19%)]\tTotal Loss: 0.085322\n",
      "Reconstruction: 0.085321, Regularization: 0.000001\n",
      "2019-04-09 23:39:44,237 root         INFO     Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 0.089305\n",
      "Reconstruction: 0.089303, Regularization: 0.000002\n",
      "2019-04-09 23:39:44,301 root         INFO     Train Epoch: 129 [2560/8000 (32%)]\tTotal Loss: 0.088878\n",
      "Reconstruction: 0.088876, Regularization: 0.000002\n",
      "2019-04-09 23:39:44,365 root         INFO     Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 0.084783\n",
      "Reconstruction: 0.084782, Regularization: 0.000001\n",
      "2019-04-09 23:39:44,429 root         INFO     Train Epoch: 129 [3584/8000 (45%)]\tTotal Loss: 0.091617\n",
      "Reconstruction: 0.091616, Regularization: 0.000001\n",
      "2019-04-09 23:39:44,493 root         INFO     Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 0.083435\n",
      "Reconstruction: 0.083434, Regularization: 0.000001\n",
      "2019-04-09 23:39:44,557 root         INFO     Train Epoch: 129 [4608/8000 (58%)]\tTotal Loss: 0.083271\n",
      "Reconstruction: 0.083269, Regularization: 0.000002\n",
      "2019-04-09 23:39:44,621 root         INFO     Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 0.093001\n",
      "Reconstruction: 0.092999, Regularization: 0.000002\n",
      "2019-04-09 23:39:44,685 root         INFO     Train Epoch: 129 [5632/8000 (70%)]\tTotal Loss: 0.085444\n",
      "Reconstruction: 0.085442, Regularization: 0.000002\n",
      "2019-04-09 23:39:44,748 root         INFO     Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 0.086323\n",
      "Reconstruction: 0.086321, Regularization: 0.000002\n",
      "2019-04-09 23:39:44,812 root         INFO     Train Epoch: 129 [6656/8000 (83%)]\tTotal Loss: 0.086929\n",
      "Reconstruction: 0.086926, Regularization: 0.000003\n",
      "2019-04-09 23:39:44,875 root         INFO     Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 0.088416\n",
      "Reconstruction: 0.088413, Regularization: 0.000003\n",
      "2019-04-09 23:39:44,939 root         INFO     Train Epoch: 129 [7680/8000 (96%)]\tTotal Loss: 0.079323\n",
      "Reconstruction: 0.079320, Regularization: 0.000003\n",
      "2019-04-09 23:39:44,992 root         INFO     ====> Epoch: 129 Average loss: 0.0887\n",
      "2019-04-09 23:39:45,016 root         INFO     Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 0.083981\n",
      "Reconstruction: 0.083978, Regularization: 0.000003\n",
      "2019-04-09 23:39:45,079 root         INFO     Train Epoch: 130 [512/8000 (6%)]\tTotal Loss: 0.085022\n",
      "Reconstruction: 0.085018, Regularization: 0.000004\n",
      "2019-04-09 23:39:45,141 root         INFO     Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 0.088818\n",
      "Reconstruction: 0.088815, Regularization: 0.000003\n",
      "2019-04-09 23:39:45,203 root         INFO     Train Epoch: 130 [1536/8000 (19%)]\tTotal Loss: 0.094552\n",
      "Reconstruction: 0.094549, Regularization: 0.000003\n",
      "2019-04-09 23:39:45,264 root         INFO     Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 0.094598\n",
      "Reconstruction: 0.094596, Regularization: 0.000002\n",
      "2019-04-09 23:39:45,327 root         INFO     Train Epoch: 130 [2560/8000 (32%)]\tTotal Loss: 0.086466\n",
      "Reconstruction: 0.086462, Regularization: 0.000004\n",
      "2019-04-09 23:39:45,390 root         INFO     Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 0.087181\n",
      "Reconstruction: 0.087177, Regularization: 0.000004\n",
      "2019-04-09 23:39:45,453 root         INFO     Train Epoch: 130 [3584/8000 (45%)]\tTotal Loss: 0.092180\n",
      "Reconstruction: 0.092175, Regularization: 0.000005\n",
      "2019-04-09 23:39:45,516 root         INFO     Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 0.081447\n",
      "Reconstruction: 0.081444, Regularization: 0.000004\n",
      "2019-04-09 23:39:45,579 root         INFO     Train Epoch: 130 [4608/8000 (58%)]\tTotal Loss: 0.092035\n",
      "Reconstruction: 0.092031, Regularization: 0.000005\n",
      "2019-04-09 23:39:45,641 root         INFO     Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 0.090408\n",
      "Reconstruction: 0.090404, Regularization: 0.000004\n",
      "2019-04-09 23:39:45,703 root         INFO     Train Epoch: 130 [5632/8000 (70%)]\tTotal Loss: 0.077031\n",
      "Reconstruction: 0.077029, Regularization: 0.000002\n",
      "2019-04-09 23:39:45,765 root         INFO     Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 0.090893\n",
      "Reconstruction: 0.090891, Regularization: 0.000002\n",
      "2019-04-09 23:39:45,826 root         INFO     Train Epoch: 130 [6656/8000 (83%)]\tTotal Loss: 0.099406\n",
      "Reconstruction: 0.099403, Regularization: 0.000003\n",
      "2019-04-09 23:39:45,888 root         INFO     Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 0.093538\n",
      "Reconstruction: 0.093535, Regularization: 0.000002\n",
      "2019-04-09 23:39:45,950 root         INFO     Train Epoch: 130 [7680/8000 (96%)]\tTotal Loss: 0.085943\n",
      "Reconstruction: 0.085941, Regularization: 0.000002\n",
      "2019-04-09 23:39:46,004 root         INFO     ====> Epoch: 130 Average loss: 0.0887\n",
      "2019-04-09 23:39:46,028 root         INFO     Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 0.092500\n",
      "Reconstruction: 0.092497, Regularization: 0.000003\n",
      "2019-04-09 23:39:46,091 root         INFO     Train Epoch: 131 [512/8000 (6%)]\tTotal Loss: 0.090972\n",
      "Reconstruction: 0.090970, Regularization: 0.000003\n",
      "2019-04-09 23:39:46,155 root         INFO     Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 0.090279\n",
      "Reconstruction: 0.090275, Regularization: 0.000004\n",
      "2019-04-09 23:39:46,218 root         INFO     Train Epoch: 131 [1536/8000 (19%)]\tTotal Loss: 0.086205\n",
      "Reconstruction: 0.086201, Regularization: 0.000004\n",
      "2019-04-09 23:39:46,282 root         INFO     Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 0.087464\n",
      "Reconstruction: 0.087460, Regularization: 0.000004\n",
      "2019-04-09 23:39:46,345 root         INFO     Train Epoch: 131 [2560/8000 (32%)]\tTotal Loss: 0.096145\n",
      "Reconstruction: 0.096141, Regularization: 0.000004\n",
      "2019-04-09 23:39:46,408 root         INFO     Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 0.084301\n",
      "Reconstruction: 0.084298, Regularization: 0.000003\n",
      "2019-04-09 23:39:46,472 root         INFO     Train Epoch: 131 [3584/8000 (45%)]\tTotal Loss: 0.096851\n",
      "Reconstruction: 0.096846, Regularization: 0.000005\n",
      "2019-04-09 23:39:46,535 root         INFO     Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 0.093173\n",
      "Reconstruction: 0.093167, Regularization: 0.000006\n",
      "2019-04-09 23:39:46,597 root         INFO     Train Epoch: 131 [4608/8000 (58%)]\tTotal Loss: 0.079389\n",
      "Reconstruction: 0.079388, Regularization: 0.000002\n",
      "2019-04-09 23:39:46,660 root         INFO     Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 0.090456\n",
      "Reconstruction: 0.090454, Regularization: 0.000002\n",
      "2019-04-09 23:39:46,723 root         INFO     Train Epoch: 131 [5632/8000 (70%)]\tTotal Loss: 0.090301\n",
      "Reconstruction: 0.090299, Regularization: 0.000002\n",
      "2019-04-09 23:39:46,786 root         INFO     Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 0.096284\n",
      "Reconstruction: 0.096281, Regularization: 0.000003\n",
      "2019-04-09 23:39:46,849 root         INFO     Train Epoch: 131 [6656/8000 (83%)]\tTotal Loss: 0.085859\n",
      "Reconstruction: 0.085858, Regularization: 0.000002\n",
      "2019-04-09 23:39:46,912 root         INFO     Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 0.084454\n",
      "Reconstruction: 0.084453, Regularization: 0.000001\n",
      "2019-04-09 23:39:46,975 root         INFO     Train Epoch: 131 [7680/8000 (96%)]\tTotal Loss: 0.093258\n",
      "Reconstruction: 0.093256, Regularization: 0.000002\n",
      "2019-04-09 23:39:47,028 root         INFO     ====> Epoch: 131 Average loss: 0.0887\n",
      "2019-04-09 23:39:47,051 root         INFO     Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 0.086962\n",
      "Reconstruction: 0.086960, Regularization: 0.000001\n",
      "2019-04-09 23:39:47,115 root         INFO     Train Epoch: 132 [512/8000 (6%)]\tTotal Loss: 0.082000\n",
      "Reconstruction: 0.081999, Regularization: 0.000001\n",
      "2019-04-09 23:39:47,179 root         INFO     Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 0.089433\n",
      "Reconstruction: 0.089431, Regularization: 0.000001\n",
      "2019-04-09 23:39:47,243 root         INFO     Train Epoch: 132 [1536/8000 (19%)]\tTotal Loss: 0.094791\n",
      "Reconstruction: 0.094789, Regularization: 0.000002\n",
      "2019-04-09 23:39:47,306 root         INFO     Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 0.086239\n",
      "Reconstruction: 0.086238, Regularization: 0.000001\n",
      "2019-04-09 23:39:47,370 root         INFO     Train Epoch: 132 [2560/8000 (32%)]\tTotal Loss: 0.095787\n",
      "Reconstruction: 0.095786, Regularization: 0.000001\n",
      "2019-04-09 23:39:47,433 root         INFO     Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 0.091259\n",
      "Reconstruction: 0.091258, Regularization: 0.000001\n",
      "2019-04-09 23:39:47,497 root         INFO     Train Epoch: 132 [3584/8000 (45%)]\tTotal Loss: 0.086360\n",
      "Reconstruction: 0.086358, Regularization: 0.000001\n",
      "2019-04-09 23:39:47,560 root         INFO     Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 0.094430\n",
      "Reconstruction: 0.094428, Regularization: 0.000002\n",
      "2019-04-09 23:39:47,623 root         INFO     Train Epoch: 132 [4608/8000 (58%)]\tTotal Loss: 0.081735\n",
      "Reconstruction: 0.081734, Regularization: 0.000001\n",
      "2019-04-09 23:39:47,686 root         INFO     Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 0.084512\n",
      "Reconstruction: 0.084511, Regularization: 0.000001\n",
      "2019-04-09 23:39:47,749 root         INFO     Train Epoch: 132 [5632/8000 (70%)]\tTotal Loss: 0.080225\n",
      "Reconstruction: 0.080224, Regularization: 0.000001\n",
      "2019-04-09 23:39:47,812 root         INFO     Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 0.092377\n",
      "Reconstruction: 0.092375, Regularization: 0.000002\n",
      "2019-04-09 23:39:47,875 root         INFO     Train Epoch: 132 [6656/8000 (83%)]\tTotal Loss: 0.087574\n",
      "Reconstruction: 0.087573, Regularization: 0.000002\n",
      "2019-04-09 23:39:47,938 root         INFO     Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 0.084579\n",
      "Reconstruction: 0.084578, Regularization: 0.000001\n",
      "2019-04-09 23:39:48,001 root         INFO     Train Epoch: 132 [7680/8000 (96%)]\tTotal Loss: 0.094793\n",
      "Reconstruction: 0.094792, Regularization: 0.000001\n",
      "2019-04-09 23:39:48,055 root         INFO     ====> Epoch: 132 Average loss: 0.0887\n",
      "2019-04-09 23:39:48,080 root         INFO     Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 0.081328\n",
      "Reconstruction: 0.081328, Regularization: 0.000000\n",
      "2019-04-09 23:39:48,144 root         INFO     Train Epoch: 133 [512/8000 (6%)]\tTotal Loss: 0.077144\n",
      "Reconstruction: 0.077144, Regularization: 0.000000\n",
      "2019-04-09 23:39:48,207 root         INFO     Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 0.077748\n",
      "Reconstruction: 0.077748, Regularization: 0.000000\n",
      "2019-04-09 23:39:48,271 root         INFO     Train Epoch: 133 [1536/8000 (19%)]\tTotal Loss: 0.093769\n",
      "Reconstruction: 0.093769, Regularization: 0.000000\n",
      "2019-04-09 23:39:48,334 root         INFO     Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 0.088684\n",
      "Reconstruction: 0.088684, Regularization: 0.000000\n",
      "2019-04-09 23:39:48,398 root         INFO     Train Epoch: 133 [2560/8000 (32%)]\tTotal Loss: 0.093366\n",
      "Reconstruction: 0.093366, Regularization: 0.000000\n",
      "2019-04-09 23:39:48,462 root         INFO     Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 0.090054\n",
      "Reconstruction: 0.090054, Regularization: 0.000000\n",
      "2019-04-09 23:39:48,525 root         INFO     Train Epoch: 133 [3584/8000 (45%)]\tTotal Loss: 0.094464\n",
      "Reconstruction: 0.094464, Regularization: 0.000000\n",
      "2019-04-09 23:39:48,589 root         INFO     Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 0.090678\n",
      "Reconstruction: 0.090678, Regularization: 0.000000\n",
      "2019-04-09 23:39:48,653 root         INFO     Train Epoch: 133 [4608/8000 (58%)]\tTotal Loss: 0.099075\n",
      "Reconstruction: 0.099075, Regularization: 0.000000\n",
      "2019-04-09 23:39:48,716 root         INFO     Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 0.082442\n",
      "Reconstruction: 0.082442, Regularization: 0.000000\n",
      "2019-04-09 23:39:48,781 root         INFO     Train Epoch: 133 [5632/8000 (70%)]\tTotal Loss: 0.085299\n",
      "Reconstruction: 0.085299, Regularization: 0.000000\n",
      "2019-04-09 23:39:48,844 root         INFO     Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 0.084194\n",
      "Reconstruction: 0.084194, Regularization: 0.000000\n",
      "2019-04-09 23:39:48,906 root         INFO     Train Epoch: 133 [6656/8000 (83%)]\tTotal Loss: 0.093265\n",
      "Reconstruction: 0.093265, Regularization: 0.000000\n",
      "2019-04-09 23:39:48,969 root         INFO     Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 0.090782\n",
      "Reconstruction: 0.090782, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,031 root         INFO     Train Epoch: 133 [7680/8000 (96%)]\tTotal Loss: 0.086086\n",
      "Reconstruction: 0.086086, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,085 root         INFO     ====> Epoch: 133 Average loss: 0.0887\n",
      "2019-04-09 23:39:49,109 root         INFO     Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 0.075671\n",
      "Reconstruction: 0.075671, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,173 root         INFO     Train Epoch: 134 [512/8000 (6%)]\tTotal Loss: 0.084548\n",
      "Reconstruction: 0.084548, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,237 root         INFO     Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 0.097846\n",
      "Reconstruction: 0.097846, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,301 root         INFO     Train Epoch: 134 [1536/8000 (19%)]\tTotal Loss: 0.085636\n",
      "Reconstruction: 0.085636, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,364 root         INFO     Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 0.085266\n",
      "Reconstruction: 0.085266, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,428 root         INFO     Train Epoch: 134 [2560/8000 (32%)]\tTotal Loss: 0.084756\n",
      "Reconstruction: 0.084756, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,491 root         INFO     Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 0.085735\n",
      "Reconstruction: 0.085735, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,554 root         INFO     Train Epoch: 134 [3584/8000 (45%)]\tTotal Loss: 0.086449\n",
      "Reconstruction: 0.086449, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,617 root         INFO     Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 0.088928\n",
      "Reconstruction: 0.088928, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,681 root         INFO     Train Epoch: 134 [4608/8000 (58%)]\tTotal Loss: 0.093804\n",
      "Reconstruction: 0.093804, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,745 root         INFO     Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 0.086105\n",
      "Reconstruction: 0.086105, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,809 root         INFO     Train Epoch: 134 [5632/8000 (70%)]\tTotal Loss: 0.089137\n",
      "Reconstruction: 0.089137, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,872 root         INFO     Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 0.095024\n",
      "Reconstruction: 0.095024, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,935 root         INFO     Train Epoch: 134 [6656/8000 (83%)]\tTotal Loss: 0.087329\n",
      "Reconstruction: 0.087329, Regularization: 0.000000\n",
      "2019-04-09 23:39:49,999 root         INFO     Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 0.092688\n",
      "Reconstruction: 0.092688, Regularization: 0.000000\n",
      "2019-04-09 23:39:50,062 root         INFO     Train Epoch: 134 [7680/8000 (96%)]\tTotal Loss: 0.095814\n",
      "Reconstruction: 0.095814, Regularization: 0.000000\n",
      "2019-04-09 23:39:50,116 root         INFO     ====> Epoch: 134 Average loss: 0.0887\n",
      "2019-04-09 23:39:50,139 root         INFO     Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 0.093282\n",
      "Reconstruction: 0.093282, Regularization: 0.000000\n",
      "2019-04-09 23:39:50,203 root         INFO     Train Epoch: 135 [512/8000 (6%)]\tTotal Loss: 0.082254\n",
      "Reconstruction: 0.082254, Regularization: 0.000000\n",
      "2019-04-09 23:39:50,265 root         INFO     Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 0.093061\n",
      "Reconstruction: 0.093061, Regularization: 0.000000\n",
      "2019-04-09 23:39:50,328 root         INFO     Train Epoch: 135 [1536/8000 (19%)]\tTotal Loss: 0.090654\n",
      "Reconstruction: 0.090653, Regularization: 0.000001\n",
      "2019-04-09 23:39:50,392 root         INFO     Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 0.083696\n",
      "Reconstruction: 0.083695, Regularization: 0.000000\n",
      "2019-04-09 23:39:50,455 root         INFO     Train Epoch: 135 [2560/8000 (32%)]\tTotal Loss: 0.085030\n",
      "Reconstruction: 0.085029, Regularization: 0.000001\n",
      "2019-04-09 23:39:50,518 root         INFO     Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 0.097333\n",
      "Reconstruction: 0.097332, Regularization: 0.000001\n",
      "2019-04-09 23:39:50,582 root         INFO     Train Epoch: 135 [3584/8000 (45%)]\tTotal Loss: 0.084912\n",
      "Reconstruction: 0.084911, Regularization: 0.000001\n",
      "2019-04-09 23:39:50,646 root         INFO     Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 0.081286\n",
      "Reconstruction: 0.081285, Regularization: 0.000001\n",
      "2019-04-09 23:39:50,709 root         INFO     Train Epoch: 135 [4608/8000 (58%)]\tTotal Loss: 0.091682\n",
      "Reconstruction: 0.091681, Regularization: 0.000001\n",
      "2019-04-09 23:39:50,772 root         INFO     Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 0.095541\n",
      "Reconstruction: 0.095540, Regularization: 0.000001\n",
      "2019-04-09 23:39:50,836 root         INFO     Train Epoch: 135 [5632/8000 (70%)]\tTotal Loss: 0.087282\n",
      "Reconstruction: 0.087280, Regularization: 0.000002\n",
      "2019-04-09 23:39:50,900 root         INFO     Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 0.089877\n",
      "Reconstruction: 0.089875, Regularization: 0.000002\n",
      "2019-04-09 23:39:50,963 root         INFO     Train Epoch: 135 [6656/8000 (83%)]\tTotal Loss: 0.087150\n",
      "Reconstruction: 0.087149, Regularization: 0.000001\n",
      "2019-04-09 23:39:51,026 root         INFO     Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 0.087413\n",
      "Reconstruction: 0.087411, Regularization: 0.000001\n",
      "2019-04-09 23:39:51,089 root         INFO     Train Epoch: 135 [7680/8000 (96%)]\tTotal Loss: 0.090833\n",
      "Reconstruction: 0.090832, Regularization: 0.000001\n",
      "2019-04-09 23:39:51,143 root         INFO     ====> Epoch: 135 Average loss: 0.0887\n",
      "2019-04-09 23:39:51,167 root         INFO     Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 0.085622\n",
      "Reconstruction: 0.085621, Regularization: 0.000002\n",
      "2019-04-09 23:39:51,230 root         INFO     Train Epoch: 136 [512/8000 (6%)]\tTotal Loss: 0.085007\n",
      "Reconstruction: 0.085005, Regularization: 0.000001\n",
      "2019-04-09 23:39:51,294 root         INFO     Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 0.088451\n",
      "Reconstruction: 0.088449, Regularization: 0.000002\n",
      "2019-04-09 23:39:51,358 root         INFO     Train Epoch: 136 [1536/8000 (19%)]\tTotal Loss: 0.082297\n",
      "Reconstruction: 0.082296, Regularization: 0.000001\n",
      "2019-04-09 23:39:51,422 root         INFO     Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 0.089630\n",
      "Reconstruction: 0.089629, Regularization: 0.000001\n",
      "2019-04-09 23:39:51,485 root         INFO     Train Epoch: 136 [2560/8000 (32%)]\tTotal Loss: 0.087126\n",
      "Reconstruction: 0.087126, Regularization: 0.000001\n",
      "2019-04-09 23:39:51,548 root         INFO     Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 0.094224\n",
      "Reconstruction: 0.094223, Regularization: 0.000001\n",
      "2019-04-09 23:39:51,611 root         INFO     Train Epoch: 136 [3584/8000 (45%)]\tTotal Loss: 0.081146\n",
      "Reconstruction: 0.081145, Regularization: 0.000001\n",
      "2019-04-09 23:39:51,675 root         INFO     Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 0.104022\n",
      "Reconstruction: 0.104020, Regularization: 0.000002\n",
      "2019-04-09 23:39:51,738 root         INFO     Train Epoch: 136 [4608/8000 (58%)]\tTotal Loss: 0.080106\n",
      "Reconstruction: 0.080105, Regularization: 0.000001\n",
      "2019-04-09 23:39:51,801 root         INFO     Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 0.103814\n",
      "Reconstruction: 0.103811, Regularization: 0.000004\n",
      "2019-04-09 23:39:51,863 root         INFO     Train Epoch: 136 [5632/8000 (70%)]\tTotal Loss: 0.087258\n",
      "Reconstruction: 0.087257, Regularization: 0.000001\n",
      "2019-04-09 23:39:51,926 root         INFO     Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 0.082794\n",
      "Reconstruction: 0.082793, Regularization: 0.000001\n",
      "2019-04-09 23:39:51,989 root         INFO     Train Epoch: 136 [6656/8000 (83%)]\tTotal Loss: 0.088386\n",
      "Reconstruction: 0.088385, Regularization: 0.000002\n",
      "2019-04-09 23:39:52,053 root         INFO     Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 0.089251\n",
      "Reconstruction: 0.089249, Regularization: 0.000002\n",
      "2019-04-09 23:39:52,116 root         INFO     Train Epoch: 136 [7680/8000 (96%)]\tTotal Loss: 0.086212\n",
      "Reconstruction: 0.086211, Regularization: 0.000001\n",
      "2019-04-09 23:39:52,169 root         INFO     ====> Epoch: 136 Average loss: 0.0887\n",
      "2019-04-09 23:39:52,193 root         INFO     Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 0.088641\n",
      "Reconstruction: 0.088639, Regularization: 0.000002\n",
      "2019-04-09 23:39:52,257 root         INFO     Train Epoch: 137 [512/8000 (6%)]\tTotal Loss: 0.085191\n",
      "Reconstruction: 0.085190, Regularization: 0.000001\n",
      "2019-04-09 23:39:52,320 root         INFO     Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 0.095384\n",
      "Reconstruction: 0.095382, Regularization: 0.000002\n",
      "2019-04-09 23:39:52,384 root         INFO     Train Epoch: 137 [1536/8000 (19%)]\tTotal Loss: 0.088768\n",
      "Reconstruction: 0.088766, Regularization: 0.000001\n",
      "2019-04-09 23:39:52,448 root         INFO     Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 0.090778\n",
      "Reconstruction: 0.090777, Regularization: 0.000001\n",
      "2019-04-09 23:39:52,510 root         INFO     Train Epoch: 137 [2560/8000 (32%)]\tTotal Loss: 0.095637\n",
      "Reconstruction: 0.095635, Regularization: 0.000001\n",
      "2019-04-09 23:39:52,571 root         INFO     Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 0.090328\n",
      "Reconstruction: 0.090326, Regularization: 0.000002\n",
      "2019-04-09 23:39:52,633 root         INFO     Train Epoch: 137 [3584/8000 (45%)]\tTotal Loss: 0.096861\n",
      "Reconstruction: 0.096860, Regularization: 0.000001\n",
      "2019-04-09 23:39:52,695 root         INFO     Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 0.097426\n",
      "Reconstruction: 0.097425, Regularization: 0.000001\n",
      "2019-04-09 23:39:52,757 root         INFO     Train Epoch: 137 [4608/8000 (58%)]\tTotal Loss: 0.096334\n",
      "Reconstruction: 0.096334, Regularization: 0.000000\n",
      "2019-04-09 23:39:52,819 root         INFO     Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 0.088093\n",
      "Reconstruction: 0.088092, Regularization: 0.000000\n",
      "2019-04-09 23:39:52,880 root         INFO     Train Epoch: 137 [5632/8000 (70%)]\tTotal Loss: 0.089048\n",
      "Reconstruction: 0.089047, Regularization: 0.000001\n",
      "2019-04-09 23:39:52,941 root         INFO     Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 0.090348\n",
      "Reconstruction: 0.090347, Regularization: 0.000001\n",
      "2019-04-09 23:39:53,003 root         INFO     Train Epoch: 137 [6656/8000 (83%)]\tTotal Loss: 0.087584\n",
      "Reconstruction: 0.087584, Regularization: 0.000001\n",
      "2019-04-09 23:39:53,065 root         INFO     Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 0.088106\n",
      "Reconstruction: 0.088105, Regularization: 0.000001\n",
      "2019-04-09 23:39:53,126 root         INFO     Train Epoch: 137 [7680/8000 (96%)]\tTotal Loss: 0.084041\n",
      "Reconstruction: 0.084041, Regularization: 0.000000\n",
      "2019-04-09 23:39:53,180 root         INFO     ====> Epoch: 137 Average loss: 0.0887\n",
      "2019-04-09 23:39:53,204 root         INFO     Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 0.093213\n",
      "Reconstruction: 0.093212, Regularization: 0.000001\n",
      "2019-04-09 23:39:53,266 root         INFO     Train Epoch: 138 [512/8000 (6%)]\tTotal Loss: 0.093888\n",
      "Reconstruction: 0.093888, Regularization: 0.000000\n",
      "2019-04-09 23:39:53,328 root         INFO     Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 0.085479\n",
      "Reconstruction: 0.085479, Regularization: 0.000000\n",
      "2019-04-09 23:39:53,389 root         INFO     Train Epoch: 138 [1536/8000 (19%)]\tTotal Loss: 0.085006\n",
      "Reconstruction: 0.085006, Regularization: 0.000000\n",
      "2019-04-09 23:39:53,450 root         INFO     Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 0.096761\n",
      "Reconstruction: 0.096761, Regularization: 0.000000\n",
      "2019-04-09 23:39:53,512 root         INFO     Train Epoch: 138 [2560/8000 (32%)]\tTotal Loss: 0.088604\n",
      "Reconstruction: 0.088604, Regularization: 0.000000\n",
      "2019-04-09 23:39:53,573 root         INFO     Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 0.108807\n",
      "Reconstruction: 0.108806, Regularization: 0.000001\n",
      "2019-04-09 23:39:53,634 root         INFO     Train Epoch: 138 [3584/8000 (45%)]\tTotal Loss: 0.088051\n",
      "Reconstruction: 0.088051, Regularization: 0.000000\n",
      "2019-04-09 23:39:53,695 root         INFO     Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 0.086910\n",
      "Reconstruction: 0.086910, Regularization: 0.000000\n",
      "2019-04-09 23:39:53,756 root         INFO     Train Epoch: 138 [4608/8000 (58%)]\tTotal Loss: 0.091883\n",
      "Reconstruction: 0.091883, Regularization: 0.000000\n",
      "2019-04-09 23:39:53,817 root         INFO     Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 0.088210\n",
      "Reconstruction: 0.088210, Regularization: 0.000000\n",
      "2019-04-09 23:39:53,878 root         INFO     Train Epoch: 138 [5632/8000 (70%)]\tTotal Loss: 0.092738\n",
      "Reconstruction: 0.092738, Regularization: 0.000000\n",
      "2019-04-09 23:39:53,939 root         INFO     Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 0.083887\n",
      "Reconstruction: 0.083887, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,000 root         INFO     Train Epoch: 138 [6656/8000 (83%)]\tTotal Loss: 0.085081\n",
      "Reconstruction: 0.085081, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,061 root         INFO     Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 0.086956\n",
      "Reconstruction: 0.086956, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,122 root         INFO     Train Epoch: 138 [7680/8000 (96%)]\tTotal Loss: 0.087418\n",
      "Reconstruction: 0.087418, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,174 root         INFO     ====> Epoch: 138 Average loss: 0.0887\n",
      "2019-04-09 23:39:54,198 root         INFO     Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 0.100041\n",
      "Reconstruction: 0.100041, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,259 root         INFO     Train Epoch: 139 [512/8000 (6%)]\tTotal Loss: 0.090588\n",
      "Reconstruction: 0.090588, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,321 root         INFO     Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 0.087231\n",
      "Reconstruction: 0.087231, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,383 root         INFO     Train Epoch: 139 [1536/8000 (19%)]\tTotal Loss: 0.090078\n",
      "Reconstruction: 0.090077, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,445 root         INFO     Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 0.086279\n",
      "Reconstruction: 0.086279, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,506 root         INFO     Train Epoch: 139 [2560/8000 (32%)]\tTotal Loss: 0.097294\n",
      "Reconstruction: 0.097294, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,567 root         INFO     Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 0.091005\n",
      "Reconstruction: 0.091005, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,629 root         INFO     Train Epoch: 139 [3584/8000 (45%)]\tTotal Loss: 0.091351\n",
      "Reconstruction: 0.091351, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,690 root         INFO     Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 0.090738\n",
      "Reconstruction: 0.090738, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,752 root         INFO     Train Epoch: 139 [4608/8000 (58%)]\tTotal Loss: 0.082439\n",
      "Reconstruction: 0.082439, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,813 root         INFO     Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 0.096080\n",
      "Reconstruction: 0.096080, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,874 root         INFO     Train Epoch: 139 [5632/8000 (70%)]\tTotal Loss: 0.086071\n",
      "Reconstruction: 0.086071, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,935 root         INFO     Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 0.085252\n",
      "Reconstruction: 0.085252, Regularization: 0.000000\n",
      "2019-04-09 23:39:54,996 root         INFO     Train Epoch: 139 [6656/8000 (83%)]\tTotal Loss: 0.080574\n",
      "Reconstruction: 0.080573, Regularization: 0.000000\n",
      "2019-04-09 23:39:55,057 root         INFO     Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 0.083255\n",
      "Reconstruction: 0.083255, Regularization: 0.000000\n",
      "2019-04-09 23:39:55,119 root         INFO     Train Epoch: 139 [7680/8000 (96%)]\tTotal Loss: 0.094938\n",
      "Reconstruction: 0.094938, Regularization: 0.000000\n",
      "2019-04-09 23:39:55,171 root         INFO     ====> Epoch: 139 Average loss: 0.0887\n",
      "2019-04-09 23:39:55,195 root         INFO     Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 0.090684\n",
      "Reconstruction: 0.090684, Regularization: 0.000000\n",
      "2019-04-09 23:39:55,256 root         INFO     Train Epoch: 140 [512/8000 (6%)]\tTotal Loss: 0.088589\n",
      "Reconstruction: 0.088589, Regularization: 0.000000\n",
      "2019-04-09 23:39:55,317 root         INFO     Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 0.085421\n",
      "Reconstruction: 0.085421, Regularization: 0.000000\n",
      "2019-04-09 23:39:55,378 root         INFO     Train Epoch: 140 [1536/8000 (19%)]\tTotal Loss: 0.093930\n",
      "Reconstruction: 0.093929, Regularization: 0.000000\n",
      "2019-04-09 23:39:55,440 root         INFO     Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 0.086291\n",
      "Reconstruction: 0.086291, Regularization: 0.000000\n",
      "2019-04-09 23:39:55,502 root         INFO     Train Epoch: 140 [2560/8000 (32%)]\tTotal Loss: 0.080117\n",
      "Reconstruction: 0.080117, Regularization: 0.000000\n",
      "2019-04-09 23:39:55,565 root         INFO     Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 0.094445\n",
      "Reconstruction: 0.094444, Regularization: 0.000000\n",
      "2019-04-09 23:39:55,629 root         INFO     Train Epoch: 140 [3584/8000 (45%)]\tTotal Loss: 0.096378\n",
      "Reconstruction: 0.096378, Regularization: 0.000000\n",
      "2019-04-09 23:39:55,693 root         INFO     Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 0.085048\n",
      "Reconstruction: 0.085048, Regularization: 0.000000\n",
      "2019-04-09 23:39:55,758 root         INFO     Train Epoch: 140 [4608/8000 (58%)]\tTotal Loss: 0.093925\n",
      "Reconstruction: 0.093925, Regularization: 0.000000\n",
      "2019-04-09 23:39:55,822 root         INFO     Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 0.088789\n",
      "Reconstruction: 0.088789, Regularization: 0.000000\n",
      "2019-04-09 23:39:55,885 root         INFO     Train Epoch: 140 [5632/8000 (70%)]\tTotal Loss: 0.084602\n",
      "Reconstruction: 0.084602, Regularization: 0.000000\n",
      "2019-04-09 23:39:55,949 root         INFO     Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 0.084600\n",
      "Reconstruction: 0.084600, Regularization: 0.000000\n",
      "2019-04-09 23:39:56,013 root         INFO     Train Epoch: 140 [6656/8000 (83%)]\tTotal Loss: 0.087907\n",
      "Reconstruction: 0.087906, Regularization: 0.000001\n",
      "2019-04-09 23:39:56,075 root         INFO     Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 0.096007\n",
      "Reconstruction: 0.096006, Regularization: 0.000001\n",
      "2019-04-09 23:39:56,136 root         INFO     Train Epoch: 140 [7680/8000 (96%)]\tTotal Loss: 0.084476\n",
      "Reconstruction: 0.084476, Regularization: 0.000001\n",
      "2019-04-09 23:39:56,189 root         INFO     ====> Epoch: 140 Average loss: 0.0887\n",
      "2019-04-09 23:39:56,213 root         INFO     Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 0.085694\n",
      "Reconstruction: 0.085693, Regularization: 0.000001\n",
      "2019-04-09 23:39:56,277 root         INFO     Train Epoch: 141 [512/8000 (6%)]\tTotal Loss: 0.080846\n",
      "Reconstruction: 0.080845, Regularization: 0.000001\n",
      "2019-04-09 23:39:56,340 root         INFO     Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 0.094682\n",
      "Reconstruction: 0.094680, Regularization: 0.000001\n",
      "2019-04-09 23:39:56,403 root         INFO     Train Epoch: 141 [1536/8000 (19%)]\tTotal Loss: 0.084142\n",
      "Reconstruction: 0.084141, Regularization: 0.000001\n",
      "2019-04-09 23:39:56,466 root         INFO     Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 0.092070\n",
      "Reconstruction: 0.092069, Regularization: 0.000001\n",
      "2019-04-09 23:39:56,529 root         INFO     Train Epoch: 141 [2560/8000 (32%)]\tTotal Loss: 0.088800\n",
      "Reconstruction: 0.088798, Regularization: 0.000001\n",
      "2019-04-09 23:39:56,592 root         INFO     Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 0.089971\n",
      "Reconstruction: 0.089969, Regularization: 0.000002\n",
      "2019-04-09 23:39:56,655 root         INFO     Train Epoch: 141 [3584/8000 (45%)]\tTotal Loss: 0.097283\n",
      "Reconstruction: 0.097281, Regularization: 0.000003\n",
      "2019-04-09 23:39:56,717 root         INFO     Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 0.086693\n",
      "Reconstruction: 0.086690, Regularization: 0.000003\n",
      "2019-04-09 23:39:56,780 root         INFO     Train Epoch: 141 [4608/8000 (58%)]\tTotal Loss: 0.083429\n",
      "Reconstruction: 0.083426, Regularization: 0.000003\n",
      "2019-04-09 23:39:56,843 root         INFO     Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 0.081648\n",
      "Reconstruction: 0.081645, Regularization: 0.000002\n",
      "2019-04-09 23:39:56,905 root         INFO     Train Epoch: 141 [5632/8000 (70%)]\tTotal Loss: 0.081176\n",
      "Reconstruction: 0.081174, Regularization: 0.000002\n",
      "2019-04-09 23:39:56,968 root         INFO     Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 0.089329\n",
      "Reconstruction: 0.089326, Regularization: 0.000003\n",
      "2019-04-09 23:39:57,030 root         INFO     Train Epoch: 141 [6656/8000 (83%)]\tTotal Loss: 0.087821\n",
      "Reconstruction: 0.087818, Regularization: 0.000002\n",
      "2019-04-09 23:39:57,092 root         INFO     Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 0.084690\n",
      "Reconstruction: 0.084688, Regularization: 0.000002\n",
      "2019-04-09 23:39:57,154 root         INFO     Train Epoch: 141 [7680/8000 (96%)]\tTotal Loss: 0.085168\n",
      "Reconstruction: 0.085165, Regularization: 0.000003\n",
      "2019-04-09 23:39:57,208 root         INFO     ====> Epoch: 141 Average loss: 0.0887\n",
      "2019-04-09 23:39:57,232 root         INFO     Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 0.081154\n",
      "Reconstruction: 0.081152, Regularization: 0.000002\n",
      "2019-04-09 23:39:57,296 root         INFO     Train Epoch: 142 [512/8000 (6%)]\tTotal Loss: 0.081836\n",
      "Reconstruction: 0.081833, Regularization: 0.000003\n",
      "2019-04-09 23:39:57,359 root         INFO     Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 0.090385\n",
      "Reconstruction: 0.090380, Regularization: 0.000004\n",
      "2019-04-09 23:39:57,421 root         INFO     Train Epoch: 142 [1536/8000 (19%)]\tTotal Loss: 0.084448\n",
      "Reconstruction: 0.084445, Regularization: 0.000003\n",
      "2019-04-09 23:39:57,483 root         INFO     Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 0.086012\n",
      "Reconstruction: 0.086009, Regularization: 0.000003\n",
      "2019-04-09 23:39:57,545 root         INFO     Train Epoch: 142 [2560/8000 (32%)]\tTotal Loss: 0.099981\n",
      "Reconstruction: 0.099977, Regularization: 0.000004\n",
      "2019-04-09 23:39:57,606 root         INFO     Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 0.087002\n",
      "Reconstruction: 0.087000, Regularization: 0.000001\n",
      "2019-04-09 23:39:57,669 root         INFO     Train Epoch: 142 [3584/8000 (45%)]\tTotal Loss: 0.101708\n",
      "Reconstruction: 0.101705, Regularization: 0.000003\n",
      "2019-04-09 23:39:57,731 root         INFO     Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 0.084786\n",
      "Reconstruction: 0.084785, Regularization: 0.000001\n",
      "2019-04-09 23:39:57,793 root         INFO     Train Epoch: 142 [4608/8000 (58%)]\tTotal Loss: 0.099025\n",
      "Reconstruction: 0.099024, Regularization: 0.000001\n",
      "2019-04-09 23:39:57,855 root         INFO     Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 0.089930\n",
      "Reconstruction: 0.089929, Regularization: 0.000001\n",
      "2019-04-09 23:39:57,918 root         INFO     Train Epoch: 142 [5632/8000 (70%)]\tTotal Loss: 0.084714\n",
      "Reconstruction: 0.084714, Regularization: 0.000000\n",
      "2019-04-09 23:39:57,981 root         INFO     Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 0.091542\n",
      "Reconstruction: 0.091541, Regularization: 0.000001\n",
      "2019-04-09 23:39:58,043 root         INFO     Train Epoch: 142 [6656/8000 (83%)]\tTotal Loss: 0.081734\n",
      "Reconstruction: 0.081734, Regularization: 0.000001\n",
      "2019-04-09 23:39:58,104 root         INFO     Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 0.091357\n",
      "Reconstruction: 0.091355, Regularization: 0.000001\n",
      "2019-04-09 23:39:58,165 root         INFO     Train Epoch: 142 [7680/8000 (96%)]\tTotal Loss: 0.084098\n",
      "Reconstruction: 0.084097, Regularization: 0.000001\n",
      "2019-04-09 23:39:58,217 root         INFO     ====> Epoch: 142 Average loss: 0.0887\n",
      "2019-04-09 23:39:58,241 root         INFO     Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 0.092908\n",
      "Reconstruction: 0.092906, Regularization: 0.000002\n",
      "2019-04-09 23:39:58,304 root         INFO     Train Epoch: 143 [512/8000 (6%)]\tTotal Loss: 0.094299\n",
      "Reconstruction: 0.094297, Regularization: 0.000001\n",
      "2019-04-09 23:39:58,368 root         INFO     Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 0.082690\n",
      "Reconstruction: 0.082689, Regularization: 0.000001\n",
      "2019-04-09 23:39:58,431 root         INFO     Train Epoch: 143 [1536/8000 (19%)]\tTotal Loss: 0.091634\n",
      "Reconstruction: 0.091633, Regularization: 0.000001\n",
      "2019-04-09 23:39:58,494 root         INFO     Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 0.087406\n",
      "Reconstruction: 0.087406, Regularization: 0.000000\n",
      "2019-04-09 23:39:58,557 root         INFO     Train Epoch: 143 [2560/8000 (32%)]\tTotal Loss: 0.089941\n",
      "Reconstruction: 0.089941, Regularization: 0.000000\n",
      "2019-04-09 23:39:58,620 root         INFO     Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 0.095935\n",
      "Reconstruction: 0.095934, Regularization: 0.000000\n",
      "2019-04-09 23:39:58,684 root         INFO     Train Epoch: 143 [3584/8000 (45%)]\tTotal Loss: 0.088385\n",
      "Reconstruction: 0.088385, Regularization: 0.000000\n",
      "2019-04-09 23:39:58,747 root         INFO     Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 0.085261\n",
      "Reconstruction: 0.085260, Regularization: 0.000000\n",
      "2019-04-09 23:39:58,810 root         INFO     Train Epoch: 143 [4608/8000 (58%)]\tTotal Loss: 0.081400\n",
      "Reconstruction: 0.081400, Regularization: 0.000000\n",
      "2019-04-09 23:39:58,873 root         INFO     Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 0.086609\n",
      "Reconstruction: 0.086609, Regularization: 0.000000\n",
      "2019-04-09 23:39:58,937 root         INFO     Train Epoch: 143 [5632/8000 (70%)]\tTotal Loss: 0.084874\n",
      "Reconstruction: 0.084873, Regularization: 0.000001\n",
      "2019-04-09 23:39:59,000 root         INFO     Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 0.092376\n",
      "Reconstruction: 0.092376, Regularization: 0.000001\n",
      "2019-04-09 23:39:59,064 root         INFO     Train Epoch: 143 [6656/8000 (83%)]\tTotal Loss: 0.093624\n",
      "Reconstruction: 0.093623, Regularization: 0.000001\n",
      "2019-04-09 23:39:59,126 root         INFO     Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 0.092756\n",
      "Reconstruction: 0.092755, Regularization: 0.000001\n",
      "2019-04-09 23:39:59,189 root         INFO     Train Epoch: 143 [7680/8000 (96%)]\tTotal Loss: 0.088850\n",
      "Reconstruction: 0.088849, Regularization: 0.000001\n",
      "2019-04-09 23:39:59,243 root         INFO     ====> Epoch: 143 Average loss: 0.0887\n",
      "2019-04-09 23:39:59,267 root         INFO     Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 0.085550\n",
      "Reconstruction: 0.085549, Regularization: 0.000001\n",
      "2019-04-09 23:39:59,330 root         INFO     Train Epoch: 144 [512/8000 (6%)]\tTotal Loss: 0.088888\n",
      "Reconstruction: 0.088887, Regularization: 0.000001\n",
      "2019-04-09 23:39:59,393 root         INFO     Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 0.090993\n",
      "Reconstruction: 0.090992, Regularization: 0.000001\n",
      "2019-04-09 23:39:59,456 root         INFO     Train Epoch: 144 [1536/8000 (19%)]\tTotal Loss: 0.086832\n",
      "Reconstruction: 0.086830, Regularization: 0.000001\n",
      "2019-04-09 23:39:59,519 root         INFO     Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 0.095868\n",
      "Reconstruction: 0.095866, Regularization: 0.000002\n",
      "2019-04-09 23:39:59,582 root         INFO     Train Epoch: 144 [2560/8000 (32%)]\tTotal Loss: 0.090579\n",
      "Reconstruction: 0.090577, Regularization: 0.000001\n",
      "2019-04-09 23:39:59,645 root         INFO     Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 0.090088\n",
      "Reconstruction: 0.090086, Regularization: 0.000002\n",
      "2019-04-09 23:39:59,708 root         INFO     Train Epoch: 144 [3584/8000 (45%)]\tTotal Loss: 0.099099\n",
      "Reconstruction: 0.099097, Regularization: 0.000002\n",
      "2019-04-09 23:39:59,770 root         INFO     Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 0.091455\n",
      "Reconstruction: 0.091454, Regularization: 0.000001\n",
      "2019-04-09 23:39:59,833 root         INFO     Train Epoch: 144 [4608/8000 (58%)]\tTotal Loss: 0.076091\n",
      "Reconstruction: 0.076091, Regularization: 0.000000\n",
      "2019-04-09 23:39:59,896 root         INFO     Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 0.082324\n",
      "Reconstruction: 0.082323, Regularization: 0.000001\n",
      "2019-04-09 23:39:59,958 root         INFO     Train Epoch: 144 [5632/8000 (70%)]\tTotal Loss: 0.082668\n",
      "Reconstruction: 0.082667, Regularization: 0.000001\n",
      "2019-04-09 23:40:00,021 root         INFO     Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 0.092011\n",
      "Reconstruction: 0.092010, Regularization: 0.000001\n",
      "2019-04-09 23:40:00,084 root         INFO     Train Epoch: 144 [6656/8000 (83%)]\tTotal Loss: 0.081474\n",
      "Reconstruction: 0.081474, Regularization: 0.000000\n",
      "2019-04-09 23:40:00,148 root         INFO     Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 0.091068\n",
      "Reconstruction: 0.091067, Regularization: 0.000001\n",
      "2019-04-09 23:40:00,211 root         INFO     Train Epoch: 144 [7680/8000 (96%)]\tTotal Loss: 0.084748\n",
      "Reconstruction: 0.084747, Regularization: 0.000001\n",
      "2019-04-09 23:40:00,264 root         INFO     ====> Epoch: 144 Average loss: 0.0887\n",
      "2019-04-09 23:40:00,288 root         INFO     Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 0.094126\n",
      "Reconstruction: 0.094125, Regularization: 0.000001\n",
      "2019-04-09 23:40:00,350 root         INFO     Train Epoch: 145 [512/8000 (6%)]\tTotal Loss: 0.091790\n",
      "Reconstruction: 0.091789, Regularization: 0.000001\n",
      "2019-04-09 23:40:00,411 root         INFO     Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 0.075045\n",
      "Reconstruction: 0.075045, Regularization: 0.000000\n",
      "2019-04-09 23:40:00,473 root         INFO     Train Epoch: 145 [1536/8000 (19%)]\tTotal Loss: 0.090464\n",
      "Reconstruction: 0.090464, Regularization: 0.000000\n",
      "2019-04-09 23:40:00,534 root         INFO     Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 0.096373\n",
      "Reconstruction: 0.096373, Regularization: 0.000000\n",
      "2019-04-09 23:40:00,596 root         INFO     Train Epoch: 145 [2560/8000 (32%)]\tTotal Loss: 0.085518\n",
      "Reconstruction: 0.085518, Regularization: 0.000000\n",
      "2019-04-09 23:40:00,657 root         INFO     Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 0.088821\n",
      "Reconstruction: 0.088821, Regularization: 0.000000\n",
      "2019-04-09 23:40:00,719 root         INFO     Train Epoch: 145 [3584/8000 (45%)]\tTotal Loss: 0.084824\n",
      "Reconstruction: 0.084824, Regularization: 0.000000\n",
      "2019-04-09 23:40:00,781 root         INFO     Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 0.089151\n",
      "Reconstruction: 0.089151, Regularization: 0.000000\n",
      "2019-04-09 23:40:00,842 root         INFO     Train Epoch: 145 [4608/8000 (58%)]\tTotal Loss: 0.091130\n",
      "Reconstruction: 0.091129, Regularization: 0.000000\n",
      "2019-04-09 23:40:00,903 root         INFO     Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 0.087669\n",
      "Reconstruction: 0.087669, Regularization: 0.000000\n",
      "2019-04-09 23:40:00,965 root         INFO     Train Epoch: 145 [5632/8000 (70%)]\tTotal Loss: 0.094900\n",
      "Reconstruction: 0.094900, Regularization: 0.000001\n",
      "2019-04-09 23:40:01,029 root         INFO     Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 0.087182\n",
      "Reconstruction: 0.087181, Regularization: 0.000001\n",
      "2019-04-09 23:40:01,098 root         INFO     Train Epoch: 145 [6656/8000 (83%)]\tTotal Loss: 0.086925\n",
      "Reconstruction: 0.086924, Regularization: 0.000001\n",
      "2019-04-09 23:40:01,164 root         INFO     Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 0.081403\n",
      "Reconstruction: 0.081402, Regularization: 0.000001\n",
      "2019-04-09 23:40:01,230 root         INFO     Train Epoch: 145 [7680/8000 (96%)]\tTotal Loss: 0.087508\n",
      "Reconstruction: 0.087507, Regularization: 0.000001\n",
      "2019-04-09 23:40:01,287 root         INFO     ====> Epoch: 145 Average loss: 0.0887\n",
      "2019-04-09 23:40:01,311 root         INFO     Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 0.105018\n",
      "Reconstruction: 0.105015, Regularization: 0.000002\n",
      "2019-04-09 23:40:01,374 root         INFO     Train Epoch: 146 [512/8000 (6%)]\tTotal Loss: 0.078023\n",
      "Reconstruction: 0.078023, Regularization: 0.000001\n",
      "2019-04-09 23:40:01,437 root         INFO     Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 0.093441\n",
      "Reconstruction: 0.093439, Regularization: 0.000001\n",
      "2019-04-09 23:40:01,500 root         INFO     Train Epoch: 146 [1536/8000 (19%)]\tTotal Loss: 0.084266\n",
      "Reconstruction: 0.084265, Regularization: 0.000001\n",
      "2019-04-09 23:40:01,563 root         INFO     Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 0.086666\n",
      "Reconstruction: 0.086665, Regularization: 0.000001\n",
      "2019-04-09 23:40:01,626 root         INFO     Train Epoch: 146 [2560/8000 (32%)]\tTotal Loss: 0.096817\n",
      "Reconstruction: 0.096815, Regularization: 0.000002\n",
      "2019-04-09 23:40:01,689 root         INFO     Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 0.096580\n",
      "Reconstruction: 0.096579, Regularization: 0.000001\n",
      "2019-04-09 23:40:01,753 root         INFO     Train Epoch: 146 [3584/8000 (45%)]\tTotal Loss: 0.090595\n",
      "Reconstruction: 0.090594, Regularization: 0.000001\n",
      "2019-04-09 23:40:01,815 root         INFO     Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 0.083055\n",
      "Reconstruction: 0.083055, Regularization: 0.000000\n",
      "2019-04-09 23:40:01,877 root         INFO     Train Epoch: 146 [4608/8000 (58%)]\tTotal Loss: 0.096050\n",
      "Reconstruction: 0.096050, Regularization: 0.000000\n",
      "2019-04-09 23:40:01,939 root         INFO     Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 0.086338\n",
      "Reconstruction: 0.086338, Regularization: 0.000000\n",
      "2019-04-09 23:40:02,002 root         INFO     Train Epoch: 146 [5632/8000 (70%)]\tTotal Loss: 0.084394\n",
      "Reconstruction: 0.084394, Regularization: 0.000000\n",
      "2019-04-09 23:40:02,064 root         INFO     Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 0.086870\n",
      "Reconstruction: 0.086870, Regularization: 0.000000\n",
      "2019-04-09 23:40:02,126 root         INFO     Train Epoch: 146 [6656/8000 (83%)]\tTotal Loss: 0.085500\n",
      "Reconstruction: 0.085499, Regularization: 0.000000\n",
      "2019-04-09 23:40:02,188 root         INFO     Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 0.088896\n",
      "Reconstruction: 0.088896, Regularization: 0.000001\n",
      "2019-04-09 23:40:02,250 root         INFO     Train Epoch: 146 [7680/8000 (96%)]\tTotal Loss: 0.093302\n",
      "Reconstruction: 0.093301, Regularization: 0.000001\n",
      "2019-04-09 23:40:02,304 root         INFO     ====> Epoch: 146 Average loss: 0.0887\n",
      "2019-04-09 23:40:02,328 root         INFO     Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 0.089603\n",
      "Reconstruction: 0.089602, Regularization: 0.000001\n",
      "2019-04-09 23:40:02,392 root         INFO     Train Epoch: 147 [512/8000 (6%)]\tTotal Loss: 0.086037\n",
      "Reconstruction: 0.086037, Regularization: 0.000000\n",
      "2019-04-09 23:40:02,455 root         INFO     Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 0.085881\n",
      "Reconstruction: 0.085881, Regularization: 0.000000\n",
      "2019-04-09 23:40:02,519 root         INFO     Train Epoch: 147 [1536/8000 (19%)]\tTotal Loss: 0.094851\n",
      "Reconstruction: 0.094851, Regularization: 0.000000\n",
      "2019-04-09 23:40:02,584 root         INFO     Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 0.087710\n",
      "Reconstruction: 0.087710, Regularization: 0.000000\n",
      "2019-04-09 23:40:02,647 root         INFO     Train Epoch: 147 [2560/8000 (32%)]\tTotal Loss: 0.086365\n",
      "Reconstruction: 0.086364, Regularization: 0.000000\n",
      "2019-04-09 23:40:02,712 root         INFO     Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 0.099498\n",
      "Reconstruction: 0.099498, Regularization: 0.000000\n",
      "2019-04-09 23:40:02,775 root         INFO     Train Epoch: 147 [3584/8000 (45%)]\tTotal Loss: 0.088705\n",
      "Reconstruction: 0.088705, Regularization: 0.000000\n",
      "2019-04-09 23:40:02,839 root         INFO     Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 0.081479\n",
      "Reconstruction: 0.081479, Regularization: 0.000000\n",
      "2019-04-09 23:40:02,904 root         INFO     Train Epoch: 147 [4608/8000 (58%)]\tTotal Loss: 0.093667\n",
      "Reconstruction: 0.093667, Regularization: 0.000001\n",
      "2019-04-09 23:40:02,967 root         INFO     Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 0.091436\n",
      "Reconstruction: 0.091435, Regularization: 0.000001\n",
      "2019-04-09 23:40:03,031 root         INFO     Train Epoch: 147 [5632/8000 (70%)]\tTotal Loss: 0.084477\n",
      "Reconstruction: 0.084476, Regularization: 0.000000\n",
      "2019-04-09 23:40:03,094 root         INFO     Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 0.082049\n",
      "Reconstruction: 0.082049, Regularization: 0.000000\n",
      "2019-04-09 23:40:03,158 root         INFO     Train Epoch: 147 [6656/8000 (83%)]\tTotal Loss: 0.090871\n",
      "Reconstruction: 0.090871, Regularization: 0.000000\n",
      "2019-04-09 23:40:03,221 root         INFO     Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 0.084974\n",
      "Reconstruction: 0.084974, Regularization: 0.000000\n",
      "2019-04-09 23:40:03,283 root         INFO     Train Epoch: 147 [7680/8000 (96%)]\tTotal Loss: 0.096576\n",
      "Reconstruction: 0.096576, Regularization: 0.000000\n",
      "2019-04-09 23:40:03,336 root         INFO     ====> Epoch: 147 Average loss: 0.0887\n",
      "2019-04-09 23:40:03,360 root         INFO     Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 0.091818\n",
      "Reconstruction: 0.091818, Regularization: 0.000000\n",
      "2019-04-09 23:40:03,426 root         INFO     Train Epoch: 148 [512/8000 (6%)]\tTotal Loss: 0.089462\n",
      "Reconstruction: 0.089462, Regularization: 0.000000\n",
      "2019-04-09 23:40:03,491 root         INFO     Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 0.093451\n",
      "Reconstruction: 0.093451, Regularization: 0.000000\n",
      "2019-04-09 23:40:03,556 root         INFO     Train Epoch: 148 [1536/8000 (19%)]\tTotal Loss: 0.092002\n",
      "Reconstruction: 0.092002, Regularization: 0.000000\n",
      "2019-04-09 23:40:03,621 root         INFO     Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 0.099682\n",
      "Reconstruction: 0.099682, Regularization: 0.000000\n",
      "2019-04-09 23:40:03,686 root         INFO     Train Epoch: 148 [2560/8000 (32%)]\tTotal Loss: 0.090642\n",
      "Reconstruction: 0.090642, Regularization: 0.000000\n",
      "2019-04-09 23:40:03,751 root         INFO     Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 0.103694\n",
      "Reconstruction: 0.103694, Regularization: 0.000000\n",
      "2019-04-09 23:40:03,815 root         INFO     Train Epoch: 148 [3584/8000 (45%)]\tTotal Loss: 0.090295\n",
      "Reconstruction: 0.090295, Regularization: 0.000000\n",
      "2019-04-09 23:40:03,880 root         INFO     Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 0.089706\n",
      "Reconstruction: 0.089706, Regularization: 0.000000\n",
      "2019-04-09 23:40:03,944 root         INFO     Train Epoch: 148 [4608/8000 (58%)]\tTotal Loss: 0.087826\n",
      "Reconstruction: 0.087826, Regularization: 0.000000\n",
      "2019-04-09 23:40:04,009 root         INFO     Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 0.076810\n",
      "Reconstruction: 0.076810, Regularization: 0.000000\n",
      "2019-04-09 23:40:04,072 root         INFO     Train Epoch: 148 [5632/8000 (70%)]\tTotal Loss: 0.098867\n",
      "Reconstruction: 0.098866, Regularization: 0.000000\n",
      "2019-04-09 23:40:04,136 root         INFO     Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 0.087095\n",
      "Reconstruction: 0.087095, Regularization: 0.000000\n",
      "2019-04-09 23:40:04,201 root         INFO     Train Epoch: 148 [6656/8000 (83%)]\tTotal Loss: 0.077434\n",
      "Reconstruction: 0.077434, Regularization: 0.000000\n",
      "2019-04-09 23:40:04,267 root         INFO     Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 0.081917\n",
      "Reconstruction: 0.081917, Regularization: 0.000000\n",
      "2019-04-09 23:40:04,334 root         INFO     Train Epoch: 148 [7680/8000 (96%)]\tTotal Loss: 0.088638\n",
      "Reconstruction: 0.088638, Regularization: 0.000000\n",
      "2019-04-09 23:40:04,389 root         INFO     ====> Epoch: 148 Average loss: 0.0887\n",
      "2019-04-09 23:40:04,413 root         INFO     Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 0.087079\n",
      "Reconstruction: 0.087079, Regularization: 0.000000\n",
      "2019-04-09 23:40:04,477 root         INFO     Train Epoch: 149 [512/8000 (6%)]\tTotal Loss: 0.089985\n",
      "Reconstruction: 0.089984, Regularization: 0.000000\n",
      "2019-04-09 23:40:04,542 root         INFO     Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 0.089811\n",
      "Reconstruction: 0.089811, Regularization: 0.000000\n",
      "2019-04-09 23:40:04,607 root         INFO     Train Epoch: 149 [1536/8000 (19%)]\tTotal Loss: 0.105200\n",
      "Reconstruction: 0.105200, Regularization: 0.000000\n",
      "2019-04-09 23:40:04,672 root         INFO     Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 0.087142\n",
      "Reconstruction: 0.087142, Regularization: 0.000000\n",
      "2019-04-09 23:40:04,739 root         INFO     Train Epoch: 149 [2560/8000 (32%)]\tTotal Loss: 0.078858\n",
      "Reconstruction: 0.078858, Regularization: 0.000000\n",
      "2019-04-09 23:40:04,804 root         INFO     Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 0.082462\n",
      "Reconstruction: 0.082461, Regularization: 0.000000\n",
      "2019-04-09 23:40:04,870 root         INFO     Train Epoch: 149 [3584/8000 (45%)]\tTotal Loss: 0.091387\n",
      "Reconstruction: 0.091386, Regularization: 0.000000\n",
      "2019-04-09 23:40:04,943 root         INFO     Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 0.097233\n",
      "Reconstruction: 0.097232, Regularization: 0.000000\n",
      "2019-04-09 23:40:05,021 root         INFO     Train Epoch: 149 [4608/8000 (58%)]\tTotal Loss: 0.085944\n",
      "Reconstruction: 0.085944, Regularization: 0.000000\n",
      "2019-04-09 23:40:05,101 root         INFO     Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 0.091582\n",
      "Reconstruction: 0.091582, Regularization: 0.000000\n",
      "2019-04-09 23:40:05,174 root         INFO     Train Epoch: 149 [5632/8000 (70%)]\tTotal Loss: 0.094814\n",
      "Reconstruction: 0.094814, Regularization: 0.000000\n",
      "2019-04-09 23:40:05,246 root         INFO     Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 0.088475\n",
      "Reconstruction: 0.088475, Regularization: 0.000000\n",
      "2019-04-09 23:40:05,318 root         INFO     Train Epoch: 149 [6656/8000 (83%)]\tTotal Loss: 0.087718\n",
      "Reconstruction: 0.087718, Regularization: 0.000000\n",
      "2019-04-09 23:40:05,388 root         INFO     Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 0.089337\n",
      "Reconstruction: 0.089337, Regularization: 0.000000\n",
      "2019-04-09 23:40:05,460 root         INFO     Train Epoch: 149 [7680/8000 (96%)]\tTotal Loss: 0.088586\n",
      "Reconstruction: 0.088586, Regularization: 0.000000\n",
      "2019-04-09 23:40:05,519 root         INFO     ====> Epoch: 149 Average loss: 0.0887\n",
      "2019-04-09 23:40:05,543 root         INFO     Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 0.082029\n",
      "Reconstruction: 0.082029, Regularization: 0.000000\n",
      "2019-04-09 23:40:05,614 root         INFO     Train Epoch: 150 [512/8000 (6%)]\tTotal Loss: 0.081367\n",
      "Reconstruction: 0.081367, Regularization: 0.000000\n",
      "2019-04-09 23:40:05,685 root         INFO     Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 0.083346\n",
      "Reconstruction: 0.083346, Regularization: 0.000000\n",
      "2019-04-09 23:40:05,755 root         INFO     Train Epoch: 150 [1536/8000 (19%)]\tTotal Loss: 0.087940\n",
      "Reconstruction: 0.087940, Regularization: 0.000000\n",
      "2019-04-09 23:40:05,825 root         INFO     Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 0.088119\n",
      "Reconstruction: 0.088119, Regularization: 0.000000\n",
      "2019-04-09 23:40:05,890 root         INFO     Train Epoch: 150 [2560/8000 (32%)]\tTotal Loss: 0.081362\n",
      "Reconstruction: 0.081362, Regularization: 0.000000\n",
      "2019-04-09 23:40:05,955 root         INFO     Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 0.087838\n",
      "Reconstruction: 0.087838, Regularization: 0.000000\n",
      "2019-04-09 23:40:06,019 root         INFO     Train Epoch: 150 [3584/8000 (45%)]\tTotal Loss: 0.093858\n",
      "Reconstruction: 0.093858, Regularization: 0.000000\n",
      "2019-04-09 23:40:06,083 root         INFO     Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 0.093933\n",
      "Reconstruction: 0.093932, Regularization: 0.000000\n",
      "2019-04-09 23:40:06,147 root         INFO     Train Epoch: 150 [4608/8000 (58%)]\tTotal Loss: 0.107702\n",
      "Reconstruction: 0.107701, Regularization: 0.000001\n",
      "2019-04-09 23:40:06,211 root         INFO     Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 0.085345\n",
      "Reconstruction: 0.085345, Regularization: 0.000001\n",
      "2019-04-09 23:40:06,275 root         INFO     Train Epoch: 150 [5632/8000 (70%)]\tTotal Loss: 0.089514\n",
      "Reconstruction: 0.089514, Regularization: 0.000001\n",
      "2019-04-09 23:40:06,339 root         INFO     Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 0.086513\n",
      "Reconstruction: 0.086512, Regularization: 0.000000\n",
      "2019-04-09 23:40:06,403 root         INFO     Train Epoch: 150 [6656/8000 (83%)]\tTotal Loss: 0.083627\n",
      "Reconstruction: 0.083627, Regularization: 0.000000\n",
      "2019-04-09 23:40:06,467 root         INFO     Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 0.090960\n",
      "Reconstruction: 0.090960, Regularization: 0.000000\n",
      "2019-04-09 23:40:06,531 root         INFO     Train Epoch: 150 [7680/8000 (96%)]\tTotal Loss: 0.086938\n",
      "Reconstruction: 0.086938, Regularization: 0.000000\n",
      "2019-04-09 23:40:06,586 root         INFO     ====> Epoch: 150 Average loss: 0.0887\n",
      "2019-04-09 23:40:06,610 root         INFO     Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 0.082488\n",
      "Reconstruction: 0.082488, Regularization: 0.000000\n",
      "2019-04-09 23:40:06,674 root         INFO     Train Epoch: 151 [512/8000 (6%)]\tTotal Loss: 0.093007\n",
      "Reconstruction: 0.093007, Regularization: 0.000000\n",
      "2019-04-09 23:40:06,738 root         INFO     Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 0.086108\n",
      "Reconstruction: 0.086108, Regularization: 0.000000\n",
      "2019-04-09 23:40:06,802 root         INFO     Train Epoch: 151 [1536/8000 (19%)]\tTotal Loss: 0.091081\n",
      "Reconstruction: 0.091081, Regularization: 0.000000\n",
      "2019-04-09 23:40:06,867 root         INFO     Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 0.079655\n",
      "Reconstruction: 0.079655, Regularization: 0.000000\n",
      "2019-04-09 23:40:06,931 root         INFO     Train Epoch: 151 [2560/8000 (32%)]\tTotal Loss: 0.095648\n",
      "Reconstruction: 0.095648, Regularization: 0.000000\n",
      "2019-04-09 23:40:06,995 root         INFO     Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 0.093990\n",
      "Reconstruction: 0.093990, Regularization: 0.000000\n",
      "2019-04-09 23:40:07,059 root         INFO     Train Epoch: 151 [3584/8000 (45%)]\tTotal Loss: 0.096144\n",
      "Reconstruction: 0.096144, Regularization: 0.000000\n",
      "2019-04-09 23:40:07,123 root         INFO     Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 0.092107\n",
      "Reconstruction: 0.092106, Regularization: 0.000000\n",
      "2019-04-09 23:40:07,187 root         INFO     Train Epoch: 151 [4608/8000 (58%)]\tTotal Loss: 0.094534\n",
      "Reconstruction: 0.094534, Regularization: 0.000000\n",
      "2019-04-09 23:40:07,251 root         INFO     Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 0.091165\n",
      "Reconstruction: 0.091165, Regularization: 0.000001\n",
      "2019-04-09 23:40:07,314 root         INFO     Train Epoch: 151 [5632/8000 (70%)]\tTotal Loss: 0.087394\n",
      "Reconstruction: 0.087394, Regularization: 0.000001\n",
      "2019-04-09 23:40:07,378 root         INFO     Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 0.102091\n",
      "Reconstruction: 0.102090, Regularization: 0.000001\n",
      "2019-04-09 23:40:07,441 root         INFO     Train Epoch: 151 [6656/8000 (83%)]\tTotal Loss: 0.088159\n",
      "Reconstruction: 0.088158, Regularization: 0.000001\n",
      "2019-04-09 23:40:07,505 root         INFO     Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 0.095149\n",
      "Reconstruction: 0.095148, Regularization: 0.000001\n",
      "2019-04-09 23:40:07,568 root         INFO     Train Epoch: 151 [7680/8000 (96%)]\tTotal Loss: 0.086692\n",
      "Reconstruction: 0.086692, Regularization: 0.000001\n",
      "2019-04-09 23:40:07,622 root         INFO     ====> Epoch: 151 Average loss: 0.0887\n",
      "2019-04-09 23:40:07,646 root         INFO     Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 0.094118\n",
      "Reconstruction: 0.094117, Regularization: 0.000001\n",
      "2019-04-09 23:40:07,709 root         INFO     Train Epoch: 152 [512/8000 (6%)]\tTotal Loss: 0.093171\n",
      "Reconstruction: 0.093170, Regularization: 0.000002\n",
      "2019-04-09 23:40:07,773 root         INFO     Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 0.089013\n",
      "Reconstruction: 0.089011, Regularization: 0.000001\n",
      "2019-04-09 23:40:07,836 root         INFO     Train Epoch: 152 [1536/8000 (19%)]\tTotal Loss: 0.091582\n",
      "Reconstruction: 0.091581, Regularization: 0.000001\n",
      "2019-04-09 23:40:07,900 root         INFO     Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 0.094840\n",
      "Reconstruction: 0.094839, Regularization: 0.000001\n",
      "2019-04-09 23:40:07,963 root         INFO     Train Epoch: 152 [2560/8000 (32%)]\tTotal Loss: 0.097472\n",
      "Reconstruction: 0.097472, Regularization: 0.000001\n",
      "2019-04-09 23:40:08,026 root         INFO     Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 0.093456\n",
      "Reconstruction: 0.093454, Regularization: 0.000001\n",
      "2019-04-09 23:40:08,089 root         INFO     Train Epoch: 152 [3584/8000 (45%)]\tTotal Loss: 0.088137\n",
      "Reconstruction: 0.088135, Regularization: 0.000002\n",
      "2019-04-09 23:40:08,153 root         INFO     Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 0.091689\n",
      "Reconstruction: 0.091686, Regularization: 0.000002\n",
      "2019-04-09 23:40:08,216 root         INFO     Train Epoch: 152 [4608/8000 (58%)]\tTotal Loss: 0.087941\n",
      "Reconstruction: 0.087939, Regularization: 0.000002\n",
      "2019-04-09 23:40:08,279 root         INFO     Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 0.095218\n",
      "Reconstruction: 0.095214, Regularization: 0.000003\n",
      "2019-04-09 23:40:08,342 root         INFO     Train Epoch: 152 [5632/8000 (70%)]\tTotal Loss: 0.091051\n",
      "Reconstruction: 0.091049, Regularization: 0.000003\n",
      "2019-04-09 23:40:08,405 root         INFO     Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 0.084171\n",
      "Reconstruction: 0.084170, Regularization: 0.000001\n",
      "2019-04-09 23:40:08,469 root         INFO     Train Epoch: 152 [6656/8000 (83%)]\tTotal Loss: 0.075030\n",
      "Reconstruction: 0.075029, Regularization: 0.000001\n",
      "2019-04-09 23:40:08,532 root         INFO     Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 0.092833\n",
      "Reconstruction: 0.092832, Regularization: 0.000001\n",
      "2019-04-09 23:40:08,595 root         INFO     Train Epoch: 152 [7680/8000 (96%)]\tTotal Loss: 0.084041\n",
      "Reconstruction: 0.084040, Regularization: 0.000001\n",
      "2019-04-09 23:40:08,649 root         INFO     ====> Epoch: 152 Average loss: 0.0887\n",
      "2019-04-09 23:40:08,673 root         INFO     Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 0.085879\n",
      "Reconstruction: 0.085878, Regularization: 0.000001\n",
      "2019-04-09 23:40:08,737 root         INFO     Train Epoch: 153 [512/8000 (6%)]\tTotal Loss: 0.083394\n",
      "Reconstruction: 0.083392, Regularization: 0.000002\n",
      "2019-04-09 23:40:08,800 root         INFO     Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 0.091566\n",
      "Reconstruction: 0.091564, Regularization: 0.000002\n",
      "2019-04-09 23:40:08,864 root         INFO     Train Epoch: 153 [1536/8000 (19%)]\tTotal Loss: 0.080435\n",
      "Reconstruction: 0.080433, Regularization: 0.000002\n",
      "2019-04-09 23:40:08,927 root         INFO     Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 0.098376\n",
      "Reconstruction: 0.098373, Regularization: 0.000003\n",
      "2019-04-09 23:40:08,990 root         INFO     Train Epoch: 153 [2560/8000 (32%)]\tTotal Loss: 0.085413\n",
      "Reconstruction: 0.085411, Regularization: 0.000002\n",
      "2019-04-09 23:40:09,053 root         INFO     Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 0.091828\n",
      "Reconstruction: 0.091825, Regularization: 0.000003\n",
      "2019-04-09 23:40:09,116 root         INFO     Train Epoch: 153 [3584/8000 (45%)]\tTotal Loss: 0.099785\n",
      "Reconstruction: 0.099782, Regularization: 0.000003\n",
      "2019-04-09 23:40:09,179 root         INFO     Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 0.094970\n",
      "Reconstruction: 0.094968, Regularization: 0.000002\n",
      "2019-04-09 23:40:09,242 root         INFO     Train Epoch: 153 [4608/8000 (58%)]\tTotal Loss: 0.088811\n",
      "Reconstruction: 0.088810, Regularization: 0.000001\n",
      "2019-04-09 23:40:09,304 root         INFO     Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 0.088299\n",
      "Reconstruction: 0.088299, Regularization: 0.000001\n",
      "2019-04-09 23:40:09,367 root         INFO     Train Epoch: 153 [5632/8000 (70%)]\tTotal Loss: 0.083558\n",
      "Reconstruction: 0.083557, Regularization: 0.000001\n",
      "2019-04-09 23:40:09,429 root         INFO     Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 0.091363\n",
      "Reconstruction: 0.091361, Regularization: 0.000001\n",
      "2019-04-09 23:40:09,492 root         INFO     Train Epoch: 153 [6656/8000 (83%)]\tTotal Loss: 0.091215\n",
      "Reconstruction: 0.091214, Regularization: 0.000001\n",
      "2019-04-09 23:40:09,555 root         INFO     Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 0.091394\n",
      "Reconstruction: 0.091393, Regularization: 0.000001\n",
      "2019-04-09 23:40:09,616 root         INFO     Train Epoch: 153 [7680/8000 (96%)]\tTotal Loss: 0.092700\n",
      "Reconstruction: 0.092699, Regularization: 0.000001\n",
      "2019-04-09 23:40:09,670 root         INFO     ====> Epoch: 153 Average loss: 0.0887\n",
      "2019-04-09 23:40:09,693 root         INFO     Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 0.100719\n",
      "Reconstruction: 0.100718, Regularization: 0.000001\n",
      "2019-04-09 23:40:09,757 root         INFO     Train Epoch: 154 [512/8000 (6%)]\tTotal Loss: 0.085916\n",
      "Reconstruction: 0.085915, Regularization: 0.000001\n",
      "2019-04-09 23:40:09,821 root         INFO     Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 0.086819\n",
      "Reconstruction: 0.086818, Regularization: 0.000001\n",
      "2019-04-09 23:40:09,883 root         INFO     Train Epoch: 154 [1536/8000 (19%)]\tTotal Loss: 0.086267\n",
      "Reconstruction: 0.086266, Regularization: 0.000001\n",
      "2019-04-09 23:40:09,946 root         INFO     Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 0.090056\n",
      "Reconstruction: 0.090055, Regularization: 0.000001\n",
      "2019-04-09 23:40:10,008 root         INFO     Train Epoch: 154 [2560/8000 (32%)]\tTotal Loss: 0.085947\n",
      "Reconstruction: 0.085946, Regularization: 0.000001\n",
      "2019-04-09 23:40:10,069 root         INFO     Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 0.079144\n",
      "Reconstruction: 0.079143, Regularization: 0.000001\n",
      "2019-04-09 23:40:10,131 root         INFO     Train Epoch: 154 [3584/8000 (45%)]\tTotal Loss: 0.093041\n",
      "Reconstruction: 0.093040, Regularization: 0.000001\n",
      "2019-04-09 23:40:10,193 root         INFO     Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 0.082577\n",
      "Reconstruction: 0.082576, Regularization: 0.000001\n",
      "2019-04-09 23:40:10,256 root         INFO     Train Epoch: 154 [4608/8000 (58%)]\tTotal Loss: 0.085317\n",
      "Reconstruction: 0.085316, Regularization: 0.000001\n",
      "2019-04-09 23:40:10,317 root         INFO     Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 0.085476\n",
      "Reconstruction: 0.085474, Regularization: 0.000001\n",
      "2019-04-09 23:40:10,380 root         INFO     Train Epoch: 154 [5632/8000 (70%)]\tTotal Loss: 0.082301\n",
      "Reconstruction: 0.082300, Regularization: 0.000001\n",
      "2019-04-09 23:40:10,443 root         INFO     Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 0.085953\n",
      "Reconstruction: 0.085953, Regularization: 0.000001\n",
      "2019-04-09 23:40:10,506 root         INFO     Train Epoch: 154 [6656/8000 (83%)]\tTotal Loss: 0.101314\n",
      "Reconstruction: 0.101313, Regularization: 0.000001\n",
      "2019-04-09 23:40:10,569 root         INFO     Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 0.086256\n",
      "Reconstruction: 0.086255, Regularization: 0.000001\n",
      "2019-04-09 23:40:10,632 root         INFO     Train Epoch: 154 [7680/8000 (96%)]\tTotal Loss: 0.088104\n",
      "Reconstruction: 0.088103, Regularization: 0.000001\n",
      "2019-04-09 23:40:10,685 root         INFO     ====> Epoch: 154 Average loss: 0.0887\n",
      "2019-04-09 23:40:10,711 root         INFO     Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 0.090629\n",
      "Reconstruction: 0.090627, Regularization: 0.000002\n",
      "2019-04-09 23:40:10,774 root         INFO     Train Epoch: 155 [512/8000 (6%)]\tTotal Loss: 0.089388\n",
      "Reconstruction: 0.089387, Regularization: 0.000001\n",
      "2019-04-09 23:40:10,836 root         INFO     Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 0.084372\n",
      "Reconstruction: 0.084371, Regularization: 0.000001\n",
      "2019-04-09 23:40:10,899 root         INFO     Train Epoch: 155 [1536/8000 (19%)]\tTotal Loss: 0.083419\n",
      "Reconstruction: 0.083417, Regularization: 0.000001\n",
      "2019-04-09 23:40:10,962 root         INFO     Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 0.095289\n",
      "Reconstruction: 0.095286, Regularization: 0.000002\n",
      "2019-04-09 23:40:11,024 root         INFO     Train Epoch: 155 [2560/8000 (32%)]\tTotal Loss: 0.101906\n",
      "Reconstruction: 0.101903, Regularization: 0.000003\n",
      "2019-04-09 23:40:11,086 root         INFO     Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 0.087922\n",
      "Reconstruction: 0.087920, Regularization: 0.000002\n",
      "2019-04-09 23:40:11,149 root         INFO     Train Epoch: 155 [3584/8000 (45%)]\tTotal Loss: 0.088608\n",
      "Reconstruction: 0.088605, Regularization: 0.000003\n",
      "2019-04-09 23:40:11,211 root         INFO     Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 0.092271\n",
      "Reconstruction: 0.092269, Regularization: 0.000003\n",
      "2019-04-09 23:40:11,276 root         INFO     Train Epoch: 155 [4608/8000 (58%)]\tTotal Loss: 0.082346\n",
      "Reconstruction: 0.082344, Regularization: 0.000002\n",
      "2019-04-09 23:40:11,340 root         INFO     Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 0.083132\n",
      "Reconstruction: 0.083130, Regularization: 0.000002\n",
      "2019-04-09 23:40:11,404 root         INFO     Train Epoch: 155 [5632/8000 (70%)]\tTotal Loss: 0.096334\n",
      "Reconstruction: 0.096332, Regularization: 0.000002\n",
      "2019-04-09 23:40:11,467 root         INFO     Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 0.090281\n",
      "Reconstruction: 0.090280, Regularization: 0.000002\n",
      "2019-04-09 23:40:11,530 root         INFO     Train Epoch: 155 [6656/8000 (83%)]\tTotal Loss: 0.094977\n",
      "Reconstruction: 0.094976, Regularization: 0.000002\n",
      "2019-04-09 23:40:11,593 root         INFO     Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 0.086919\n",
      "Reconstruction: 0.086918, Regularization: 0.000001\n",
      "2019-04-09 23:40:11,655 root         INFO     Train Epoch: 155 [7680/8000 (96%)]\tTotal Loss: 0.083238\n",
      "Reconstruction: 0.083237, Regularization: 0.000001\n",
      "2019-04-09 23:40:11,708 root         INFO     ====> Epoch: 155 Average loss: 0.0887\n",
      "2019-04-09 23:40:11,732 root         INFO     Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 0.087749\n",
      "Reconstruction: 0.087749, Regularization: 0.000001\n",
      "2019-04-09 23:40:11,797 root         INFO     Train Epoch: 156 [512/8000 (6%)]\tTotal Loss: 0.085323\n",
      "Reconstruction: 0.085323, Regularization: 0.000001\n",
      "2019-04-09 23:40:11,861 root         INFO     Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 0.101352\n",
      "Reconstruction: 0.101351, Regularization: 0.000001\n",
      "2019-04-09 23:40:11,925 root         INFO     Train Epoch: 156 [1536/8000 (19%)]\tTotal Loss: 0.087606\n",
      "Reconstruction: 0.087605, Regularization: 0.000001\n",
      "2019-04-09 23:40:11,988 root         INFO     Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 0.078295\n",
      "Reconstruction: 0.078295, Regularization: 0.000000\n",
      "2019-04-09 23:40:12,052 root         INFO     Train Epoch: 156 [2560/8000 (32%)]\tTotal Loss: 0.091429\n",
      "Reconstruction: 0.091429, Regularization: 0.000000\n",
      "2019-04-09 23:40:12,116 root         INFO     Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 0.088593\n",
      "Reconstruction: 0.088593, Regularization: 0.000000\n",
      "2019-04-09 23:40:12,180 root         INFO     Train Epoch: 156 [3584/8000 (45%)]\tTotal Loss: 0.084044\n",
      "Reconstruction: 0.084044, Regularization: 0.000000\n",
      "2019-04-09 23:40:12,243 root         INFO     Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 0.086717\n",
      "Reconstruction: 0.086716, Regularization: 0.000000\n",
      "2019-04-09 23:40:12,306 root         INFO     Train Epoch: 156 [4608/8000 (58%)]\tTotal Loss: 0.078513\n",
      "Reconstruction: 0.078512, Regularization: 0.000000\n",
      "2019-04-09 23:40:12,369 root         INFO     Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 0.083646\n",
      "Reconstruction: 0.083645, Regularization: 0.000001\n",
      "2019-04-09 23:40:12,431 root         INFO     Train Epoch: 156 [5632/8000 (70%)]\tTotal Loss: 0.086976\n",
      "Reconstruction: 0.086975, Regularization: 0.000001\n",
      "2019-04-09 23:40:12,494 root         INFO     Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 0.091414\n",
      "Reconstruction: 0.091412, Regularization: 0.000002\n",
      "2019-04-09 23:40:12,556 root         INFO     Train Epoch: 156 [6656/8000 (83%)]\tTotal Loss: 0.094006\n",
      "Reconstruction: 0.094003, Regularization: 0.000003\n",
      "2019-04-09 23:40:12,619 root         INFO     Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 0.086255\n",
      "Reconstruction: 0.086252, Regularization: 0.000002\n",
      "2019-04-09 23:40:12,682 root         INFO     Train Epoch: 156 [7680/8000 (96%)]\tTotal Loss: 0.087426\n",
      "Reconstruction: 0.087424, Regularization: 0.000002\n",
      "2019-04-09 23:40:12,735 root         INFO     ====> Epoch: 156 Average loss: 0.0887\n",
      "2019-04-09 23:40:12,759 root         INFO     Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 0.091895\n",
      "Reconstruction: 0.091893, Regularization: 0.000003\n",
      "2019-04-09 23:40:12,822 root         INFO     Train Epoch: 157 [512/8000 (6%)]\tTotal Loss: 0.083568\n",
      "Reconstruction: 0.083565, Regularization: 0.000003\n",
      "2019-04-09 23:40:12,885 root         INFO     Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 0.083906\n",
      "Reconstruction: 0.083904, Regularization: 0.000002\n",
      "2019-04-09 23:40:12,947 root         INFO     Train Epoch: 157 [1536/8000 (19%)]\tTotal Loss: 0.101187\n",
      "Reconstruction: 0.101184, Regularization: 0.000003\n",
      "2019-04-09 23:40:13,010 root         INFO     Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 0.090379\n",
      "Reconstruction: 0.090377, Regularization: 0.000002\n",
      "2019-04-09 23:40:13,072 root         INFO     Train Epoch: 157 [2560/8000 (32%)]\tTotal Loss: 0.090429\n",
      "Reconstruction: 0.090428, Regularization: 0.000001\n",
      "2019-04-09 23:40:13,134 root         INFO     Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 0.095365\n",
      "Reconstruction: 0.095363, Regularization: 0.000002\n",
      "2019-04-09 23:40:13,197 root         INFO     Train Epoch: 157 [3584/8000 (45%)]\tTotal Loss: 0.087546\n",
      "Reconstruction: 0.087543, Regularization: 0.000002\n",
      "2019-04-09 23:40:13,258 root         INFO     Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 0.083630\n",
      "Reconstruction: 0.083628, Regularization: 0.000001\n",
      "2019-04-09 23:40:13,320 root         INFO     Train Epoch: 157 [4608/8000 (58%)]\tTotal Loss: 0.086972\n",
      "Reconstruction: 0.086970, Regularization: 0.000002\n",
      "2019-04-09 23:40:13,383 root         INFO     Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 0.083056\n",
      "Reconstruction: 0.083055, Regularization: 0.000001\n",
      "2019-04-09 23:40:13,446 root         INFO     Train Epoch: 157 [5632/8000 (70%)]\tTotal Loss: 0.091032\n",
      "Reconstruction: 0.091030, Regularization: 0.000002\n",
      "2019-04-09 23:40:13,509 root         INFO     Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 0.087417\n",
      "Reconstruction: 0.087415, Regularization: 0.000002\n",
      "2019-04-09 23:40:13,572 root         INFO     Train Epoch: 157 [6656/8000 (83%)]\tTotal Loss: 0.099549\n",
      "Reconstruction: 0.099547, Regularization: 0.000003\n",
      "2019-04-09 23:40:13,636 root         INFO     Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 0.093031\n",
      "Reconstruction: 0.093028, Regularization: 0.000003\n",
      "2019-04-09 23:40:13,700 root         INFO     Train Epoch: 157 [7680/8000 (96%)]\tTotal Loss: 0.097280\n",
      "Reconstruction: 0.097278, Regularization: 0.000002\n",
      "2019-04-09 23:40:13,754 root         INFO     ====> Epoch: 157 Average loss: 0.0887\n",
      "2019-04-09 23:40:13,778 root         INFO     Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 0.092726\n",
      "Reconstruction: 0.092725, Regularization: 0.000001\n",
      "2019-04-09 23:40:13,841 root         INFO     Train Epoch: 158 [512/8000 (6%)]\tTotal Loss: 0.086578\n",
      "Reconstruction: 0.086577, Regularization: 0.000001\n",
      "2019-04-09 23:40:13,905 root         INFO     Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 0.087119\n",
      "Reconstruction: 0.087118, Regularization: 0.000001\n",
      "2019-04-09 23:40:13,968 root         INFO     Train Epoch: 158 [1536/8000 (19%)]\tTotal Loss: 0.089066\n",
      "Reconstruction: 0.089065, Regularization: 0.000001\n",
      "2019-04-09 23:40:14,030 root         INFO     Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 0.097828\n",
      "Reconstruction: 0.097827, Regularization: 0.000001\n",
      "2019-04-09 23:40:14,093 root         INFO     Train Epoch: 158 [2560/8000 (32%)]\tTotal Loss: 0.091762\n",
      "Reconstruction: 0.091761, Regularization: 0.000001\n",
      "2019-04-09 23:40:14,156 root         INFO     Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 0.085344\n",
      "Reconstruction: 0.085343, Regularization: 0.000001\n",
      "2019-04-09 23:40:14,220 root         INFO     Train Epoch: 158 [3584/8000 (45%)]\tTotal Loss: 0.096650\n",
      "Reconstruction: 0.096649, Regularization: 0.000001\n",
      "2019-04-09 23:40:14,283 root         INFO     Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 0.092392\n",
      "Reconstruction: 0.092392, Regularization: 0.000001\n",
      "2019-04-09 23:40:14,347 root         INFO     Train Epoch: 158 [4608/8000 (58%)]\tTotal Loss: 0.094987\n",
      "Reconstruction: 0.094986, Regularization: 0.000001\n",
      "2019-04-09 23:40:14,410 root         INFO     Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 0.085847\n",
      "Reconstruction: 0.085846, Regularization: 0.000000\n",
      "2019-04-09 23:40:14,473 root         INFO     Train Epoch: 158 [5632/8000 (70%)]\tTotal Loss: 0.090431\n",
      "Reconstruction: 0.090430, Regularization: 0.000001\n",
      "2019-04-09 23:40:14,535 root         INFO     Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 0.093766\n",
      "Reconstruction: 0.093765, Regularization: 0.000001\n",
      "2019-04-09 23:40:14,599 root         INFO     Train Epoch: 158 [6656/8000 (83%)]\tTotal Loss: 0.089379\n",
      "Reconstruction: 0.089378, Regularization: 0.000001\n",
      "2019-04-09 23:40:14,662 root         INFO     Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 0.087044\n",
      "Reconstruction: 0.087041, Regularization: 0.000003\n",
      "2019-04-09 23:40:14,724 root         INFO     Train Epoch: 158 [7680/8000 (96%)]\tTotal Loss: 0.079807\n",
      "Reconstruction: 0.079805, Regularization: 0.000002\n",
      "2019-04-09 23:40:14,779 root         INFO     ====> Epoch: 158 Average loss: 0.0887\n",
      "2019-04-09 23:40:14,803 root         INFO     Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 0.087106\n",
      "Reconstruction: 0.087101, Regularization: 0.000004\n",
      "2019-04-09 23:40:14,864 root         INFO     Train Epoch: 159 [512/8000 (6%)]\tTotal Loss: 0.093017\n",
      "Reconstruction: 0.093012, Regularization: 0.000005\n",
      "2019-04-09 23:40:14,928 root         INFO     Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 0.085743\n",
      "Reconstruction: 0.085738, Regularization: 0.000005\n",
      "2019-04-09 23:40:14,990 root         INFO     Train Epoch: 159 [1536/8000 (19%)]\tTotal Loss: 0.087873\n",
      "Reconstruction: 0.087865, Regularization: 0.000007\n",
      "2019-04-09 23:40:15,052 root         INFO     Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 0.090272\n",
      "Reconstruction: 0.090266, Regularization: 0.000006\n",
      "2019-04-09 23:40:15,115 root         INFO     Train Epoch: 159 [2560/8000 (32%)]\tTotal Loss: 0.084534\n",
      "Reconstruction: 0.084527, Regularization: 0.000006\n",
      "2019-04-09 23:40:15,177 root         INFO     Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 0.076236\n",
      "Reconstruction: 0.076232, Regularization: 0.000004\n",
      "2019-04-09 23:40:15,239 root         INFO     Train Epoch: 159 [3584/8000 (45%)]\tTotal Loss: 0.085567\n",
      "Reconstruction: 0.085561, Regularization: 0.000006\n",
      "2019-04-09 23:40:15,301 root         INFO     Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 0.086094\n",
      "Reconstruction: 0.086090, Regularization: 0.000004\n",
      "2019-04-09 23:40:15,363 root         INFO     Train Epoch: 159 [4608/8000 (58%)]\tTotal Loss: 0.083804\n",
      "Reconstruction: 0.083796, Regularization: 0.000008\n",
      "2019-04-09 23:40:15,425 root         INFO     Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 0.086192\n",
      "Reconstruction: 0.086186, Regularization: 0.000006\n",
      "2019-04-09 23:40:15,488 root         INFO     Train Epoch: 159 [5632/8000 (70%)]\tTotal Loss: 0.083410\n",
      "Reconstruction: 0.083402, Regularization: 0.000007\n",
      "2019-04-09 23:40:15,550 root         INFO     Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 0.086434\n",
      "Reconstruction: 0.086427, Regularization: 0.000007\n",
      "2019-04-09 23:40:15,612 root         INFO     Train Epoch: 159 [6656/8000 (83%)]\tTotal Loss: 0.085137\n",
      "Reconstruction: 0.085131, Regularization: 0.000006\n",
      "2019-04-09 23:40:15,674 root         INFO     Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 0.082017\n",
      "Reconstruction: 0.082014, Regularization: 0.000003\n",
      "2019-04-09 23:40:15,736 root         INFO     Train Epoch: 159 [7680/8000 (96%)]\tTotal Loss: 0.090646\n",
      "Reconstruction: 0.090641, Regularization: 0.000005\n",
      "2019-04-09 23:40:15,789 root         INFO     ====> Epoch: 159 Average loss: 0.0887\n",
      "2019-04-09 23:40:15,813 root         INFO     Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 0.095094\n",
      "Reconstruction: 0.095091, Regularization: 0.000003\n",
      "2019-04-09 23:40:15,877 root         INFO     Train Epoch: 160 [512/8000 (6%)]\tTotal Loss: 0.092614\n",
      "Reconstruction: 0.092608, Regularization: 0.000006\n",
      "2019-04-09 23:40:15,940 root         INFO     Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 0.095610\n",
      "Reconstruction: 0.095605, Regularization: 0.000005\n",
      "2019-04-09 23:40:16,003 root         INFO     Train Epoch: 160 [1536/8000 (19%)]\tTotal Loss: 0.086097\n",
      "Reconstruction: 0.086089, Regularization: 0.000008\n",
      "2019-04-09 23:40:16,065 root         INFO     Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 0.094530\n",
      "Reconstruction: 0.094522, Regularization: 0.000008\n",
      "2019-04-09 23:40:16,127 root         INFO     Train Epoch: 160 [2560/8000 (32%)]\tTotal Loss: 0.086546\n",
      "Reconstruction: 0.086539, Regularization: 0.000007\n",
      "2019-04-09 23:40:16,189 root         INFO     Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 0.085438\n",
      "Reconstruction: 0.085432, Regularization: 0.000006\n",
      "2019-04-09 23:40:16,251 root         INFO     Train Epoch: 160 [3584/8000 (45%)]\tTotal Loss: 0.081332\n",
      "Reconstruction: 0.081328, Regularization: 0.000004\n",
      "2019-04-09 23:40:16,315 root         INFO     Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 0.083455\n",
      "Reconstruction: 0.083451, Regularization: 0.000004\n",
      "2019-04-09 23:40:16,379 root         INFO     Train Epoch: 160 [4608/8000 (58%)]\tTotal Loss: 0.087895\n",
      "Reconstruction: 0.087892, Regularization: 0.000004\n",
      "2019-04-09 23:40:16,441 root         INFO     Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 0.090555\n",
      "Reconstruction: 0.090551, Regularization: 0.000004\n",
      "2019-04-09 23:40:16,503 root         INFO     Train Epoch: 160 [5632/8000 (70%)]\tTotal Loss: 0.087000\n",
      "Reconstruction: 0.086997, Regularization: 0.000003\n",
      "2019-04-09 23:40:16,565 root         INFO     Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 0.084646\n",
      "Reconstruction: 0.084643, Regularization: 0.000003\n",
      "2019-04-09 23:40:16,627 root         INFO     Train Epoch: 160 [6656/8000 (83%)]\tTotal Loss: 0.108913\n",
      "Reconstruction: 0.108909, Regularization: 0.000004\n",
      "2019-04-09 23:40:16,690 root         INFO     Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 0.089418\n",
      "Reconstruction: 0.089416, Regularization: 0.000002\n",
      "2019-04-09 23:40:16,753 root         INFO     Train Epoch: 160 [7680/8000 (96%)]\tTotal Loss: 0.084637\n",
      "Reconstruction: 0.084636, Regularization: 0.000002\n",
      "2019-04-09 23:40:16,806 root         INFO     ====> Epoch: 160 Average loss: 0.0887\n",
      "2019-04-09 23:40:16,830 root         INFO     Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 0.084764\n",
      "Reconstruction: 0.084763, Regularization: 0.000001\n",
      "2019-04-09 23:40:16,892 root         INFO     Train Epoch: 161 [512/8000 (6%)]\tTotal Loss: 0.093565\n",
      "Reconstruction: 0.093564, Regularization: 0.000001\n",
      "2019-04-09 23:40:16,953 root         INFO     Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 0.086668\n",
      "Reconstruction: 0.086667, Regularization: 0.000001\n",
      "2019-04-09 23:40:17,015 root         INFO     Train Epoch: 161 [1536/8000 (19%)]\tTotal Loss: 0.088809\n",
      "Reconstruction: 0.088808, Regularization: 0.000001\n",
      "2019-04-09 23:40:17,076 root         INFO     Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 0.095113\n",
      "Reconstruction: 0.095113, Regularization: 0.000000\n",
      "2019-04-09 23:40:17,137 root         INFO     Train Epoch: 161 [2560/8000 (32%)]\tTotal Loss: 0.094593\n",
      "Reconstruction: 0.094593, Regularization: 0.000001\n",
      "2019-04-09 23:40:17,199 root         INFO     Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 0.083418\n",
      "Reconstruction: 0.083418, Regularization: 0.000000\n",
      "2019-04-09 23:40:17,260 root         INFO     Train Epoch: 161 [3584/8000 (45%)]\tTotal Loss: 0.086512\n",
      "Reconstruction: 0.086512, Regularization: 0.000001\n",
      "2019-04-09 23:40:17,322 root         INFO     Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 0.090725\n",
      "Reconstruction: 0.090725, Regularization: 0.000001\n",
      "2019-04-09 23:40:17,383 root         INFO     Train Epoch: 161 [4608/8000 (58%)]\tTotal Loss: 0.098891\n",
      "Reconstruction: 0.098890, Regularization: 0.000001\n",
      "2019-04-09 23:40:17,444 root         INFO     Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 0.084275\n",
      "Reconstruction: 0.084275, Regularization: 0.000001\n",
      "2019-04-09 23:40:17,505 root         INFO     Train Epoch: 161 [5632/8000 (70%)]\tTotal Loss: 0.079263\n",
      "Reconstruction: 0.079262, Regularization: 0.000001\n",
      "2019-04-09 23:40:17,567 root         INFO     Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 0.082135\n",
      "Reconstruction: 0.082134, Regularization: 0.000001\n",
      "2019-04-09 23:40:17,628 root         INFO     Train Epoch: 161 [6656/8000 (83%)]\tTotal Loss: 0.095035\n",
      "Reconstruction: 0.095033, Regularization: 0.000002\n",
      "2019-04-09 23:40:17,689 root         INFO     Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 0.083837\n",
      "Reconstruction: 0.083836, Regularization: 0.000001\n",
      "2019-04-09 23:40:17,751 root         INFO     Train Epoch: 161 [7680/8000 (96%)]\tTotal Loss: 0.088681\n",
      "Reconstruction: 0.088679, Regularization: 0.000001\n",
      "2019-04-09 23:40:17,803 root         INFO     ====> Epoch: 161 Average loss: 0.0887\n",
      "2019-04-09 23:40:17,827 root         INFO     Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 0.090630\n",
      "Reconstruction: 0.090629, Regularization: 0.000001\n",
      "2019-04-09 23:40:17,890 root         INFO     Train Epoch: 162 [512/8000 (6%)]\tTotal Loss: 0.090761\n",
      "Reconstruction: 0.090760, Regularization: 0.000001\n",
      "2019-04-09 23:40:17,951 root         INFO     Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 0.089989\n",
      "Reconstruction: 0.089988, Regularization: 0.000001\n",
      "2019-04-09 23:40:18,012 root         INFO     Train Epoch: 162 [1536/8000 (19%)]\tTotal Loss: 0.093337\n",
      "Reconstruction: 0.093336, Regularization: 0.000001\n",
      "2019-04-09 23:40:18,073 root         INFO     Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 0.091877\n",
      "Reconstruction: 0.091876, Regularization: 0.000002\n",
      "2019-04-09 23:40:18,134 root         INFO     Train Epoch: 162 [2560/8000 (32%)]\tTotal Loss: 0.083828\n",
      "Reconstruction: 0.083827, Regularization: 0.000001\n",
      "2019-04-09 23:40:18,197 root         INFO     Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 0.096090\n",
      "Reconstruction: 0.096089, Regularization: 0.000001\n",
      "2019-04-09 23:40:18,259 root         INFO     Train Epoch: 162 [3584/8000 (45%)]\tTotal Loss: 0.081543\n",
      "Reconstruction: 0.081542, Regularization: 0.000001\n",
      "2019-04-09 23:40:18,321 root         INFO     Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 0.094453\n",
      "Reconstruction: 0.094451, Regularization: 0.000002\n",
      "2019-04-09 23:40:18,384 root         INFO     Train Epoch: 162 [4608/8000 (58%)]\tTotal Loss: 0.081340\n",
      "Reconstruction: 0.081339, Regularization: 0.000001\n",
      "2019-04-09 23:40:18,446 root         INFO     Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 0.085594\n",
      "Reconstruction: 0.085593, Regularization: 0.000001\n",
      "2019-04-09 23:40:18,508 root         INFO     Train Epoch: 162 [5632/8000 (70%)]\tTotal Loss: 0.086470\n",
      "Reconstruction: 0.086469, Regularization: 0.000001\n",
      "2019-04-09 23:40:18,570 root         INFO     Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 0.088145\n",
      "Reconstruction: 0.088144, Regularization: 0.000001\n",
      "2019-04-09 23:40:18,632 root         INFO     Train Epoch: 162 [6656/8000 (83%)]\tTotal Loss: 0.086759\n",
      "Reconstruction: 0.086758, Regularization: 0.000001\n",
      "2019-04-09 23:40:18,695 root         INFO     Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 0.082273\n",
      "Reconstruction: 0.082272, Regularization: 0.000001\n",
      "2019-04-09 23:40:18,757 root         INFO     Train Epoch: 162 [7680/8000 (96%)]\tTotal Loss: 0.094759\n",
      "Reconstruction: 0.094758, Regularization: 0.000001\n",
      "2019-04-09 23:40:18,811 root         INFO     ====> Epoch: 162 Average loss: 0.0887\n",
      "2019-04-09 23:40:18,835 root         INFO     Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 0.099003\n",
      "Reconstruction: 0.099001, Regularization: 0.000002\n",
      "2019-04-09 23:40:18,898 root         INFO     Train Epoch: 163 [512/8000 (6%)]\tTotal Loss: 0.087758\n",
      "Reconstruction: 0.087758, Regularization: 0.000000\n",
      "2019-04-09 23:40:18,960 root         INFO     Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 0.088264\n",
      "Reconstruction: 0.088263, Regularization: 0.000001\n",
      "2019-04-09 23:40:19,023 root         INFO     Train Epoch: 163 [1536/8000 (19%)]\tTotal Loss: 0.086594\n",
      "Reconstruction: 0.086594, Regularization: 0.000001\n",
      "2019-04-09 23:40:19,085 root         INFO     Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 0.109384\n",
      "Reconstruction: 0.109383, Regularization: 0.000001\n",
      "2019-04-09 23:40:19,147 root         INFO     Train Epoch: 163 [2560/8000 (32%)]\tTotal Loss: 0.082514\n",
      "Reconstruction: 0.082513, Regularization: 0.000000\n",
      "2019-04-09 23:40:19,210 root         INFO     Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 0.088912\n",
      "Reconstruction: 0.088911, Regularization: 0.000001\n",
      "2019-04-09 23:40:19,272 root         INFO     Train Epoch: 163 [3584/8000 (45%)]\tTotal Loss: 0.086073\n",
      "Reconstruction: 0.086072, Regularization: 0.000001\n",
      "2019-04-09 23:40:19,334 root         INFO     Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 0.093811\n",
      "Reconstruction: 0.093809, Regularization: 0.000002\n",
      "2019-04-09 23:40:19,396 root         INFO     Train Epoch: 163 [4608/8000 (58%)]\tTotal Loss: 0.099023\n",
      "Reconstruction: 0.099021, Regularization: 0.000002\n",
      "2019-04-09 23:40:19,458 root         INFO     Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 0.086972\n",
      "Reconstruction: 0.086970, Regularization: 0.000002\n",
      "2019-04-09 23:40:19,521 root         INFO     Train Epoch: 163 [5632/8000 (70%)]\tTotal Loss: 0.089651\n",
      "Reconstruction: 0.089650, Regularization: 0.000002\n",
      "2019-04-09 23:40:19,583 root         INFO     Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 0.087413\n",
      "Reconstruction: 0.087411, Regularization: 0.000002\n",
      "2019-04-09 23:40:19,646 root         INFO     Train Epoch: 163 [6656/8000 (83%)]\tTotal Loss: 0.089083\n",
      "Reconstruction: 0.089081, Regularization: 0.000002\n",
      "2019-04-09 23:40:19,708 root         INFO     Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 0.085193\n",
      "Reconstruction: 0.085191, Regularization: 0.000002\n",
      "2019-04-09 23:40:19,770 root         INFO     Train Epoch: 163 [7680/8000 (96%)]\tTotal Loss: 0.083507\n",
      "Reconstruction: 0.083504, Regularization: 0.000003\n",
      "2019-04-09 23:40:19,823 root         INFO     ====> Epoch: 163 Average loss: 0.0887\n",
      "2019-04-09 23:40:19,847 root         INFO     Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 0.089463\n",
      "Reconstruction: 0.089459, Regularization: 0.000004\n",
      "2019-04-09 23:40:19,909 root         INFO     Train Epoch: 164 [512/8000 (6%)]\tTotal Loss: 0.081038\n",
      "Reconstruction: 0.081036, Regularization: 0.000002\n",
      "2019-04-09 23:40:19,972 root         INFO     Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 0.094440\n",
      "Reconstruction: 0.094435, Regularization: 0.000005\n",
      "2019-04-09 23:40:20,034 root         INFO     Train Epoch: 164 [1536/8000 (19%)]\tTotal Loss: 0.085843\n",
      "Reconstruction: 0.085840, Regularization: 0.000003\n",
      "2019-04-09 23:40:20,096 root         INFO     Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 0.099327\n",
      "Reconstruction: 0.099323, Regularization: 0.000004\n",
      "2019-04-09 23:40:20,159 root         INFO     Train Epoch: 164 [2560/8000 (32%)]\tTotal Loss: 0.091460\n",
      "Reconstruction: 0.091458, Regularization: 0.000003\n",
      "2019-04-09 23:40:20,221 root         INFO     Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 0.087958\n",
      "Reconstruction: 0.087955, Regularization: 0.000003\n",
      "2019-04-09 23:40:20,283 root         INFO     Train Epoch: 164 [3584/8000 (45%)]\tTotal Loss: 0.093023\n",
      "Reconstruction: 0.093020, Regularization: 0.000004\n",
      "2019-04-09 23:40:20,346 root         INFO     Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 0.089189\n",
      "Reconstruction: 0.089186, Regularization: 0.000003\n",
      "2019-04-09 23:40:20,408 root         INFO     Train Epoch: 164 [4608/8000 (58%)]\tTotal Loss: 0.092069\n",
      "Reconstruction: 0.092067, Regularization: 0.000002\n",
      "2019-04-09 23:40:20,471 root         INFO     Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 0.080801\n",
      "Reconstruction: 0.080798, Regularization: 0.000003\n",
      "2019-04-09 23:40:20,533 root         INFO     Train Epoch: 164 [5632/8000 (70%)]\tTotal Loss: 0.088106\n",
      "Reconstruction: 0.088102, Regularization: 0.000003\n",
      "2019-04-09 23:40:20,594 root         INFO     Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 0.086611\n",
      "Reconstruction: 0.086606, Regularization: 0.000005\n",
      "2019-04-09 23:40:20,656 root         INFO     Train Epoch: 164 [6656/8000 (83%)]\tTotal Loss: 0.085887\n",
      "Reconstruction: 0.085883, Regularization: 0.000004\n",
      "2019-04-09 23:40:20,718 root         INFO     Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 0.089689\n",
      "Reconstruction: 0.089684, Regularization: 0.000005\n",
      "2019-04-09 23:40:20,779 root         INFO     Train Epoch: 164 [7680/8000 (96%)]\tTotal Loss: 0.097464\n",
      "Reconstruction: 0.097459, Regularization: 0.000005\n",
      "2019-04-09 23:40:20,831 root         INFO     ====> Epoch: 164 Average loss: 0.0887\n",
      "2019-04-09 23:40:20,855 root         INFO     Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 0.084030\n",
      "Reconstruction: 0.084028, Regularization: 0.000003\n",
      "2019-04-09 23:40:20,916 root         INFO     Train Epoch: 165 [512/8000 (6%)]\tTotal Loss: 0.093071\n",
      "Reconstruction: 0.093069, Regularization: 0.000002\n",
      "2019-04-09 23:40:20,978 root         INFO     Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 0.097441\n",
      "Reconstruction: 0.097438, Regularization: 0.000002\n",
      "2019-04-09 23:40:21,039 root         INFO     Train Epoch: 165 [1536/8000 (19%)]\tTotal Loss: 0.089312\n",
      "Reconstruction: 0.089310, Regularization: 0.000002\n",
      "2019-04-09 23:40:21,101 root         INFO     Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 0.098122\n",
      "Reconstruction: 0.098120, Regularization: 0.000002\n",
      "2019-04-09 23:40:21,163 root         INFO     Train Epoch: 165 [2560/8000 (32%)]\tTotal Loss: 0.089982\n",
      "Reconstruction: 0.089980, Regularization: 0.000001\n",
      "2019-04-09 23:40:21,224 root         INFO     Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 0.082686\n",
      "Reconstruction: 0.082685, Regularization: 0.000001\n",
      "2019-04-09 23:40:21,285 root         INFO     Train Epoch: 165 [3584/8000 (45%)]\tTotal Loss: 0.084944\n",
      "Reconstruction: 0.084943, Regularization: 0.000001\n",
      "2019-04-09 23:40:21,347 root         INFO     Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 0.079833\n",
      "Reconstruction: 0.079832, Regularization: 0.000000\n",
      "2019-04-09 23:40:21,409 root         INFO     Train Epoch: 165 [4608/8000 (58%)]\tTotal Loss: 0.082429\n",
      "Reconstruction: 0.082429, Regularization: 0.000000\n",
      "2019-04-09 23:40:21,470 root         INFO     Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 0.094401\n",
      "Reconstruction: 0.094401, Regularization: 0.000000\n",
      "2019-04-09 23:40:21,532 root         INFO     Train Epoch: 165 [5632/8000 (70%)]\tTotal Loss: 0.085990\n",
      "Reconstruction: 0.085990, Regularization: 0.000000\n",
      "2019-04-09 23:40:21,593 root         INFO     Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 0.092363\n",
      "Reconstruction: 0.092363, Regularization: 0.000000\n",
      "2019-04-09 23:40:21,655 root         INFO     Train Epoch: 165 [6656/8000 (83%)]\tTotal Loss: 0.089962\n",
      "Reconstruction: 0.089962, Regularization: 0.000000\n",
      "2019-04-09 23:40:21,716 root         INFO     Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 0.086157\n",
      "Reconstruction: 0.086157, Regularization: 0.000000\n",
      "2019-04-09 23:40:21,777 root         INFO     Train Epoch: 165 [7680/8000 (96%)]\tTotal Loss: 0.102236\n",
      "Reconstruction: 0.102236, Regularization: 0.000000\n",
      "2019-04-09 23:40:21,831 root         INFO     ====> Epoch: 165 Average loss: 0.0887\n",
      "2019-04-09 23:40:21,855 root         INFO     Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 0.095689\n",
      "Reconstruction: 0.095689, Regularization: 0.000000\n",
      "2019-04-09 23:40:21,918 root         INFO     Train Epoch: 166 [512/8000 (6%)]\tTotal Loss: 0.095632\n",
      "Reconstruction: 0.095632, Regularization: 0.000000\n",
      "2019-04-09 23:40:21,980 root         INFO     Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 0.078212\n",
      "Reconstruction: 0.078212, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,043 root         INFO     Train Epoch: 166 [1536/8000 (19%)]\tTotal Loss: 0.092625\n",
      "Reconstruction: 0.092625, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,106 root         INFO     Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 0.090423\n",
      "Reconstruction: 0.090423, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,168 root         INFO     Train Epoch: 166 [2560/8000 (32%)]\tTotal Loss: 0.080611\n",
      "Reconstruction: 0.080611, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,230 root         INFO     Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 0.086926\n",
      "Reconstruction: 0.086926, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,293 root         INFO     Train Epoch: 166 [3584/8000 (45%)]\tTotal Loss: 0.083717\n",
      "Reconstruction: 0.083717, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,354 root         INFO     Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 0.091249\n",
      "Reconstruction: 0.091249, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,416 root         INFO     Train Epoch: 166 [4608/8000 (58%)]\tTotal Loss: 0.092819\n",
      "Reconstruction: 0.092818, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,478 root         INFO     Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 0.088055\n",
      "Reconstruction: 0.088054, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,540 root         INFO     Train Epoch: 166 [5632/8000 (70%)]\tTotal Loss: 0.090136\n",
      "Reconstruction: 0.090136, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,602 root         INFO     Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 0.098491\n",
      "Reconstruction: 0.098491, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,663 root         INFO     Train Epoch: 166 [6656/8000 (83%)]\tTotal Loss: 0.105299\n",
      "Reconstruction: 0.105298, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,725 root         INFO     Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 0.092080\n",
      "Reconstruction: 0.092080, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,787 root         INFO     Train Epoch: 166 [7680/8000 (96%)]\tTotal Loss: 0.086429\n",
      "Reconstruction: 0.086429, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,840 root         INFO     ====> Epoch: 166 Average loss: 0.0887\n",
      "2019-04-09 23:40:22,864 root         INFO     Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 0.087428\n",
      "Reconstruction: 0.087428, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,927 root         INFO     Train Epoch: 167 [512/8000 (6%)]\tTotal Loss: 0.082442\n",
      "Reconstruction: 0.082442, Regularization: 0.000000\n",
      "2019-04-09 23:40:22,989 root         INFO     Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 0.085001\n",
      "Reconstruction: 0.085001, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,050 root         INFO     Train Epoch: 167 [1536/8000 (19%)]\tTotal Loss: 0.086426\n",
      "Reconstruction: 0.086426, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,112 root         INFO     Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 0.088372\n",
      "Reconstruction: 0.088372, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,173 root         INFO     Train Epoch: 167 [2560/8000 (32%)]\tTotal Loss: 0.091333\n",
      "Reconstruction: 0.091333, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,234 root         INFO     Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 0.085348\n",
      "Reconstruction: 0.085348, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,295 root         INFO     Train Epoch: 167 [3584/8000 (45%)]\tTotal Loss: 0.090005\n",
      "Reconstruction: 0.090005, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,355 root         INFO     Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 0.086988\n",
      "Reconstruction: 0.086988, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,416 root         INFO     Train Epoch: 167 [4608/8000 (58%)]\tTotal Loss: 0.098464\n",
      "Reconstruction: 0.098464, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,477 root         INFO     Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 0.095054\n",
      "Reconstruction: 0.095054, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,538 root         INFO     Train Epoch: 167 [5632/8000 (70%)]\tTotal Loss: 0.093510\n",
      "Reconstruction: 0.093510, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,598 root         INFO     Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 0.089706\n",
      "Reconstruction: 0.089706, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,659 root         INFO     Train Epoch: 167 [6656/8000 (83%)]\tTotal Loss: 0.097724\n",
      "Reconstruction: 0.097723, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,720 root         INFO     Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 0.094152\n",
      "Reconstruction: 0.094152, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,781 root         INFO     Train Epoch: 167 [7680/8000 (96%)]\tTotal Loss: 0.090254\n",
      "Reconstruction: 0.090254, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,833 root         INFO     ====> Epoch: 167 Average loss: 0.0887\n",
      "2019-04-09 23:40:23,857 root         INFO     Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 0.094067\n",
      "Reconstruction: 0.094067, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,919 root         INFO     Train Epoch: 168 [512/8000 (6%)]\tTotal Loss: 0.075048\n",
      "Reconstruction: 0.075048, Regularization: 0.000000\n",
      "2019-04-09 23:40:23,981 root         INFO     Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 0.090255\n",
      "Reconstruction: 0.090255, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,043 root         INFO     Train Epoch: 168 [1536/8000 (19%)]\tTotal Loss: 0.089943\n",
      "Reconstruction: 0.089943, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,104 root         INFO     Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 0.086201\n",
      "Reconstruction: 0.086201, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,166 root         INFO     Train Epoch: 168 [2560/8000 (32%)]\tTotal Loss: 0.107194\n",
      "Reconstruction: 0.107194, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,227 root         INFO     Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 0.078255\n",
      "Reconstruction: 0.078255, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,289 root         INFO     Train Epoch: 168 [3584/8000 (45%)]\tTotal Loss: 0.081449\n",
      "Reconstruction: 0.081449, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,350 root         INFO     Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 0.089504\n",
      "Reconstruction: 0.089504, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,411 root         INFO     Train Epoch: 168 [4608/8000 (58%)]\tTotal Loss: 0.088094\n",
      "Reconstruction: 0.088094, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,471 root         INFO     Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 0.089370\n",
      "Reconstruction: 0.089370, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,532 root         INFO     Train Epoch: 168 [5632/8000 (70%)]\tTotal Loss: 0.088668\n",
      "Reconstruction: 0.088668, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,593 root         INFO     Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 0.089079\n",
      "Reconstruction: 0.089078, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,654 root         INFO     Train Epoch: 168 [6656/8000 (83%)]\tTotal Loss: 0.091223\n",
      "Reconstruction: 0.091223, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,714 root         INFO     Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 0.086777\n",
      "Reconstruction: 0.086777, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,775 root         INFO     Train Epoch: 168 [7680/8000 (96%)]\tTotal Loss: 0.090814\n",
      "Reconstruction: 0.090814, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,827 root         INFO     ====> Epoch: 168 Average loss: 0.0887\n",
      "2019-04-09 23:40:24,851 root         INFO     Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 0.087385\n",
      "Reconstruction: 0.087385, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,914 root         INFO     Train Epoch: 169 [512/8000 (6%)]\tTotal Loss: 0.089421\n",
      "Reconstruction: 0.089421, Regularization: 0.000000\n",
      "2019-04-09 23:40:24,976 root         INFO     Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 0.091173\n",
      "Reconstruction: 0.091173, Regularization: 0.000000\n",
      "2019-04-09 23:40:25,039 root         INFO     Train Epoch: 169 [1536/8000 (19%)]\tTotal Loss: 0.085195\n",
      "Reconstruction: 0.085194, Regularization: 0.000000\n",
      "2019-04-09 23:40:25,101 root         INFO     Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 0.089055\n",
      "Reconstruction: 0.089055, Regularization: 0.000000\n",
      "2019-04-09 23:40:25,164 root         INFO     Train Epoch: 169 [2560/8000 (32%)]\tTotal Loss: 0.085625\n",
      "Reconstruction: 0.085625, Regularization: 0.000000\n",
      "2019-04-09 23:40:25,226 root         INFO     Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 0.089025\n",
      "Reconstruction: 0.089024, Regularization: 0.000001\n",
      "2019-04-09 23:40:25,288 root         INFO     Train Epoch: 169 [3584/8000 (45%)]\tTotal Loss: 0.087813\n",
      "Reconstruction: 0.087811, Regularization: 0.000002\n",
      "2019-04-09 23:40:25,350 root         INFO     Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 0.086427\n",
      "Reconstruction: 0.086425, Regularization: 0.000002\n",
      "2019-04-09 23:40:25,413 root         INFO     Train Epoch: 169 [4608/8000 (58%)]\tTotal Loss: 0.090647\n",
      "Reconstruction: 0.090646, Regularization: 0.000001\n",
      "2019-04-09 23:40:25,476 root         INFO     Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 0.081683\n",
      "Reconstruction: 0.081682, Regularization: 0.000001\n",
      "2019-04-09 23:40:25,538 root         INFO     Train Epoch: 169 [5632/8000 (70%)]\tTotal Loss: 0.088669\n",
      "Reconstruction: 0.088668, Regularization: 0.000001\n",
      "2019-04-09 23:40:25,601 root         INFO     Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 0.094467\n",
      "Reconstruction: 0.094466, Regularization: 0.000001\n",
      "2019-04-09 23:40:25,663 root         INFO     Train Epoch: 169 [6656/8000 (83%)]\tTotal Loss: 0.089716\n",
      "Reconstruction: 0.089715, Regularization: 0.000001\n",
      "2019-04-09 23:40:25,726 root         INFO     Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 0.090859\n",
      "Reconstruction: 0.090859, Regularization: 0.000001\n",
      "2019-04-09 23:40:25,790 root         INFO     Train Epoch: 169 [7680/8000 (96%)]\tTotal Loss: 0.081954\n",
      "Reconstruction: 0.081954, Regularization: 0.000000\n",
      "2019-04-09 23:40:25,843 root         INFO     ====> Epoch: 169 Average loss: 0.0887\n",
      "2019-04-09 23:40:25,867 root         INFO     Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 0.089725\n",
      "Reconstruction: 0.089725, Regularization: 0.000000\n",
      "2019-04-09 23:40:25,930 root         INFO     Train Epoch: 170 [512/8000 (6%)]\tTotal Loss: 0.083173\n",
      "Reconstruction: 0.083172, Regularization: 0.000000\n",
      "2019-04-09 23:40:25,992 root         INFO     Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 0.091127\n",
      "Reconstruction: 0.091126, Regularization: 0.000001\n",
      "2019-04-09 23:40:26,054 root         INFO     Train Epoch: 170 [1536/8000 (19%)]\tTotal Loss: 0.086695\n",
      "Reconstruction: 0.086694, Regularization: 0.000001\n",
      "2019-04-09 23:40:26,117 root         INFO     Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 0.100437\n",
      "Reconstruction: 0.100436, Regularization: 0.000000\n",
      "2019-04-09 23:40:26,180 root         INFO     Train Epoch: 170 [2560/8000 (32%)]\tTotal Loss: 0.080596\n",
      "Reconstruction: 0.080596, Regularization: 0.000000\n",
      "2019-04-09 23:40:26,242 root         INFO     Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 0.096665\n",
      "Reconstruction: 0.096664, Regularization: 0.000000\n",
      "2019-04-09 23:40:26,304 root         INFO     Train Epoch: 170 [3584/8000 (45%)]\tTotal Loss: 0.077920\n",
      "Reconstruction: 0.077920, Regularization: 0.000000\n",
      "2019-04-09 23:40:26,365 root         INFO     Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 0.083473\n",
      "Reconstruction: 0.083472, Regularization: 0.000000\n",
      "2019-04-09 23:40:26,427 root         INFO     Train Epoch: 170 [4608/8000 (58%)]\tTotal Loss: 0.085640\n",
      "Reconstruction: 0.085640, Regularization: 0.000000\n",
      "2019-04-09 23:40:26,488 root         INFO     Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 0.081652\n",
      "Reconstruction: 0.081652, Regularization: 0.000000\n",
      "2019-04-09 23:40:26,550 root         INFO     Train Epoch: 170 [5632/8000 (70%)]\tTotal Loss: 0.081850\n",
      "Reconstruction: 0.081850, Regularization: 0.000000\n",
      "2019-04-09 23:40:26,611 root         INFO     Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 0.099563\n",
      "Reconstruction: 0.099563, Regularization: 0.000000\n",
      "2019-04-09 23:40:26,673 root         INFO     Train Epoch: 170 [6656/8000 (83%)]\tTotal Loss: 0.081984\n",
      "Reconstruction: 0.081984, Regularization: 0.000000\n",
      "2019-04-09 23:40:26,735 root         INFO     Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 0.089722\n",
      "Reconstruction: 0.089722, Regularization: 0.000000\n",
      "2019-04-09 23:40:26,796 root         INFO     Train Epoch: 170 [7680/8000 (96%)]\tTotal Loss: 0.085346\n",
      "Reconstruction: 0.085345, Regularization: 0.000000\n",
      "2019-04-09 23:40:26,849 root         INFO     ====> Epoch: 170 Average loss: 0.0887\n",
      "2019-04-09 23:40:26,873 root         INFO     Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 0.089112\n",
      "Reconstruction: 0.089112, Regularization: 0.000000\n",
      "2019-04-09 23:40:26,934 root         INFO     Train Epoch: 171 [512/8000 (6%)]\tTotal Loss: 0.091900\n",
      "Reconstruction: 0.091899, Regularization: 0.000000\n",
      "2019-04-09 23:40:26,996 root         INFO     Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 0.081824\n",
      "Reconstruction: 0.081824, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,057 root         INFO     Train Epoch: 171 [1536/8000 (19%)]\tTotal Loss: 0.085322\n",
      "Reconstruction: 0.085322, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,118 root         INFO     Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 0.080399\n",
      "Reconstruction: 0.080399, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,180 root         INFO     Train Epoch: 171 [2560/8000 (32%)]\tTotal Loss: 0.079486\n",
      "Reconstruction: 0.079486, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,241 root         INFO     Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 0.098954\n",
      "Reconstruction: 0.098954, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,302 root         INFO     Train Epoch: 171 [3584/8000 (45%)]\tTotal Loss: 0.078235\n",
      "Reconstruction: 0.078235, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,363 root         INFO     Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 0.087908\n",
      "Reconstruction: 0.087908, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,424 root         INFO     Train Epoch: 171 [4608/8000 (58%)]\tTotal Loss: 0.092936\n",
      "Reconstruction: 0.092935, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,485 root         INFO     Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 0.093013\n",
      "Reconstruction: 0.093013, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,547 root         INFO     Train Epoch: 171 [5632/8000 (70%)]\tTotal Loss: 0.088139\n",
      "Reconstruction: 0.088139, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,608 root         INFO     Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 0.085411\n",
      "Reconstruction: 0.085410, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,669 root         INFO     Train Epoch: 171 [6656/8000 (83%)]\tTotal Loss: 0.090222\n",
      "Reconstruction: 0.090222, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,731 root         INFO     Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 0.084831\n",
      "Reconstruction: 0.084831, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,794 root         INFO     Train Epoch: 171 [7680/8000 (96%)]\tTotal Loss: 0.086820\n",
      "Reconstruction: 0.086819, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,848 root         INFO     ====> Epoch: 171 Average loss: 0.0887\n",
      "2019-04-09 23:40:27,871 root         INFO     Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 0.074390\n",
      "Reconstruction: 0.074390, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,933 root         INFO     Train Epoch: 172 [512/8000 (6%)]\tTotal Loss: 0.080382\n",
      "Reconstruction: 0.080381, Regularization: 0.000000\n",
      "2019-04-09 23:40:27,995 root         INFO     Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 0.082936\n",
      "Reconstruction: 0.082936, Regularization: 0.000000\n",
      "2019-04-09 23:40:28,057 root         INFO     Train Epoch: 172 [1536/8000 (19%)]\tTotal Loss: 0.088154\n",
      "Reconstruction: 0.088154, Regularization: 0.000000\n",
      "2019-04-09 23:40:28,119 root         INFO     Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 0.085147\n",
      "Reconstruction: 0.085147, Regularization: 0.000000\n",
      "2019-04-09 23:40:28,181 root         INFO     Train Epoch: 172 [2560/8000 (32%)]\tTotal Loss: 0.081586\n",
      "Reconstruction: 0.081585, Regularization: 0.000001\n",
      "2019-04-09 23:40:28,242 root         INFO     Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 0.082459\n",
      "Reconstruction: 0.082458, Regularization: 0.000001\n",
      "2019-04-09 23:40:28,305 root         INFO     Train Epoch: 172 [3584/8000 (45%)]\tTotal Loss: 0.100020\n",
      "Reconstruction: 0.100019, Regularization: 0.000001\n",
      "2019-04-09 23:40:28,367 root         INFO     Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 0.084149\n",
      "Reconstruction: 0.084148, Regularization: 0.000001\n",
      "2019-04-09 23:40:28,430 root         INFO     Train Epoch: 172 [4608/8000 (58%)]\tTotal Loss: 0.089791\n",
      "Reconstruction: 0.089790, Regularization: 0.000001\n",
      "2019-04-09 23:40:28,493 root         INFO     Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 0.082749\n",
      "Reconstruction: 0.082748, Regularization: 0.000001\n",
      "2019-04-09 23:40:28,554 root         INFO     Train Epoch: 172 [5632/8000 (70%)]\tTotal Loss: 0.085745\n",
      "Reconstruction: 0.085745, Regularization: 0.000001\n",
      "2019-04-09 23:40:28,616 root         INFO     Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 0.079341\n",
      "Reconstruction: 0.079341, Regularization: 0.000000\n",
      "2019-04-09 23:40:28,677 root         INFO     Train Epoch: 172 [6656/8000 (83%)]\tTotal Loss: 0.097087\n",
      "Reconstruction: 0.097086, Regularization: 0.000001\n",
      "2019-04-09 23:40:28,739 root         INFO     Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 0.077117\n",
      "Reconstruction: 0.077116, Regularization: 0.000000\n",
      "2019-04-09 23:40:28,800 root         INFO     Train Epoch: 172 [7680/8000 (96%)]\tTotal Loss: 0.088868\n",
      "Reconstruction: 0.088867, Regularization: 0.000001\n",
      "2019-04-09 23:40:28,854 root         INFO     ====> Epoch: 172 Average loss: 0.0887\n",
      "2019-04-09 23:40:28,878 root         INFO     Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 0.084270\n",
      "Reconstruction: 0.084269, Regularization: 0.000001\n",
      "2019-04-09 23:40:28,942 root         INFO     Train Epoch: 173 [512/8000 (6%)]\tTotal Loss: 0.084940\n",
      "Reconstruction: 0.084940, Regularization: 0.000000\n",
      "2019-04-09 23:40:29,009 root         INFO     Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 0.085036\n",
      "Reconstruction: 0.085036, Regularization: 0.000000\n",
      "2019-04-09 23:40:29,073 root         INFO     Train Epoch: 173 [1536/8000 (19%)]\tTotal Loss: 0.085137\n",
      "Reconstruction: 0.085137, Regularization: 0.000000\n",
      "2019-04-09 23:40:29,137 root         INFO     Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 0.087878\n",
      "Reconstruction: 0.087878, Regularization: 0.000000\n",
      "2019-04-09 23:40:29,201 root         INFO     Train Epoch: 173 [2560/8000 (32%)]\tTotal Loss: 0.086042\n",
      "Reconstruction: 0.086042, Regularization: 0.000000\n",
      "2019-04-09 23:40:29,264 root         INFO     Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 0.084757\n",
      "Reconstruction: 0.084757, Regularization: 0.000000\n",
      "2019-04-09 23:40:29,329 root         INFO     Train Epoch: 173 [3584/8000 (45%)]\tTotal Loss: 0.086834\n",
      "Reconstruction: 0.086834, Regularization: 0.000000\n",
      "2019-04-09 23:40:29,393 root         INFO     Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 0.099856\n",
      "Reconstruction: 0.099855, Regularization: 0.000001\n",
      "2019-04-09 23:40:29,457 root         INFO     Train Epoch: 173 [4608/8000 (58%)]\tTotal Loss: 0.081520\n",
      "Reconstruction: 0.081519, Regularization: 0.000001\n",
      "2019-04-09 23:40:29,521 root         INFO     Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 0.094582\n",
      "Reconstruction: 0.094582, Regularization: 0.000000\n",
      "2019-04-09 23:40:29,586 root         INFO     Train Epoch: 173 [5632/8000 (70%)]\tTotal Loss: 0.101142\n",
      "Reconstruction: 0.101142, Regularization: 0.000000\n",
      "2019-04-09 23:40:29,651 root         INFO     Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 0.091679\n",
      "Reconstruction: 0.091679, Regularization: 0.000000\n",
      "2019-04-09 23:40:29,715 root         INFO     Train Epoch: 173 [6656/8000 (83%)]\tTotal Loss: 0.082895\n",
      "Reconstruction: 0.082895, Regularization: 0.000000\n",
      "2019-04-09 23:40:29,778 root         INFO     Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 0.081282\n",
      "Reconstruction: 0.081282, Regularization: 0.000000\n",
      "2019-04-09 23:40:29,842 root         INFO     Train Epoch: 173 [7680/8000 (96%)]\tTotal Loss: 0.078889\n",
      "Reconstruction: 0.078889, Regularization: 0.000000\n",
      "2019-04-09 23:40:29,895 root         INFO     ====> Epoch: 173 Average loss: 0.0887\n",
      "2019-04-09 23:40:29,919 root         INFO     Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 0.093715\n",
      "Reconstruction: 0.093714, Regularization: 0.000001\n",
      "2019-04-09 23:40:29,983 root         INFO     Train Epoch: 174 [512/8000 (6%)]\tTotal Loss: 0.087920\n",
      "Reconstruction: 0.087919, Regularization: 0.000001\n",
      "2019-04-09 23:40:30,046 root         INFO     Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 0.090730\n",
      "Reconstruction: 0.090729, Regularization: 0.000001\n",
      "2019-04-09 23:40:30,110 root         INFO     Train Epoch: 174 [1536/8000 (19%)]\tTotal Loss: 0.087325\n",
      "Reconstruction: 0.087323, Regularization: 0.000002\n",
      "2019-04-09 23:40:30,173 root         INFO     Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 0.084224\n",
      "Reconstruction: 0.084222, Regularization: 0.000002\n",
      "2019-04-09 23:40:30,237 root         INFO     Train Epoch: 174 [2560/8000 (32%)]\tTotal Loss: 0.081444\n",
      "Reconstruction: 0.081442, Regularization: 0.000002\n",
      "2019-04-09 23:40:30,300 root         INFO     Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 0.088346\n",
      "Reconstruction: 0.088344, Regularization: 0.000002\n",
      "2019-04-09 23:40:30,364 root         INFO     Train Epoch: 174 [3584/8000 (45%)]\tTotal Loss: 0.080191\n",
      "Reconstruction: 0.080189, Regularization: 0.000002\n",
      "2019-04-09 23:40:30,427 root         INFO     Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 0.085460\n",
      "Reconstruction: 0.085458, Regularization: 0.000002\n",
      "2019-04-09 23:40:30,490 root         INFO     Train Epoch: 174 [4608/8000 (58%)]\tTotal Loss: 0.090423\n",
      "Reconstruction: 0.090421, Regularization: 0.000002\n",
      "2019-04-09 23:40:30,553 root         INFO     Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 0.087543\n",
      "Reconstruction: 0.087541, Regularization: 0.000002\n",
      "2019-04-09 23:40:30,617 root         INFO     Train Epoch: 174 [5632/8000 (70%)]\tTotal Loss: 0.081489\n",
      "Reconstruction: 0.081487, Regularization: 0.000001\n",
      "2019-04-09 23:40:30,680 root         INFO     Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 0.086753\n",
      "Reconstruction: 0.086752, Regularization: 0.000002\n",
      "2019-04-09 23:40:30,742 root         INFO     Train Epoch: 174 [6656/8000 (83%)]\tTotal Loss: 0.094985\n",
      "Reconstruction: 0.094984, Regularization: 0.000001\n",
      "2019-04-09 23:40:30,806 root         INFO     Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 0.091225\n",
      "Reconstruction: 0.091225, Regularization: 0.000001\n",
      "2019-04-09 23:40:30,869 root         INFO     Train Epoch: 174 [7680/8000 (96%)]\tTotal Loss: 0.089521\n",
      "Reconstruction: 0.089520, Regularization: 0.000000\n",
      "2019-04-09 23:40:30,923 root         INFO     ====> Epoch: 174 Average loss: 0.0887\n",
      "2019-04-09 23:40:30,947 root         INFO     Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 0.085120\n",
      "Reconstruction: 0.085119, Regularization: 0.000001\n",
      "2019-04-09 23:40:31,011 root         INFO     Train Epoch: 175 [512/8000 (6%)]\tTotal Loss: 0.085598\n",
      "Reconstruction: 0.085598, Regularization: 0.000001\n",
      "2019-04-09 23:40:31,074 root         INFO     Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 0.086141\n",
      "Reconstruction: 0.086140, Regularization: 0.000000\n",
      "2019-04-09 23:40:31,137 root         INFO     Train Epoch: 175 [1536/8000 (19%)]\tTotal Loss: 0.092768\n",
      "Reconstruction: 0.092768, Regularization: 0.000000\n",
      "2019-04-09 23:40:31,201 root         INFO     Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 0.093412\n",
      "Reconstruction: 0.093411, Regularization: 0.000001\n",
      "2019-04-09 23:40:31,264 root         INFO     Train Epoch: 175 [2560/8000 (32%)]\tTotal Loss: 0.086942\n",
      "Reconstruction: 0.086942, Regularization: 0.000001\n",
      "2019-04-09 23:40:31,327 root         INFO     Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 0.084508\n",
      "Reconstruction: 0.084507, Regularization: 0.000001\n",
      "2019-04-09 23:40:31,391 root         INFO     Train Epoch: 175 [3584/8000 (45%)]\tTotal Loss: 0.097700\n",
      "Reconstruction: 0.097699, Regularization: 0.000000\n",
      "2019-04-09 23:40:31,454 root         INFO     Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 0.088944\n",
      "Reconstruction: 0.088944, Regularization: 0.000000\n",
      "2019-04-09 23:40:31,518 root         INFO     Train Epoch: 175 [4608/8000 (58%)]\tTotal Loss: 0.090171\n",
      "Reconstruction: 0.090171, Regularization: 0.000000\n",
      "2019-04-09 23:40:31,581 root         INFO     Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 0.087590\n",
      "Reconstruction: 0.087590, Regularization: 0.000000\n",
      "2019-04-09 23:40:31,645 root         INFO     Train Epoch: 175 [5632/8000 (70%)]\tTotal Loss: 0.092865\n",
      "Reconstruction: 0.092865, Regularization: 0.000000\n",
      "2019-04-09 23:40:31,708 root         INFO     Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 0.086729\n",
      "Reconstruction: 0.086729, Regularization: 0.000000\n",
      "2019-04-09 23:40:31,770 root         INFO     Train Epoch: 175 [6656/8000 (83%)]\tTotal Loss: 0.090082\n",
      "Reconstruction: 0.090082, Regularization: 0.000000\n",
      "2019-04-09 23:40:31,833 root         INFO     Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 0.091802\n",
      "Reconstruction: 0.091802, Regularization: 0.000000\n",
      "2019-04-09 23:40:31,895 root         INFO     Train Epoch: 175 [7680/8000 (96%)]\tTotal Loss: 0.083832\n",
      "Reconstruction: 0.083832, Regularization: 0.000000\n",
      "2019-04-09 23:40:31,949 root         INFO     ====> Epoch: 175 Average loss: 0.0887\n",
      "2019-04-09 23:40:31,973 root         INFO     Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 0.086322\n",
      "Reconstruction: 0.086322, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,036 root         INFO     Train Epoch: 176 [512/8000 (6%)]\tTotal Loss: 0.088421\n",
      "Reconstruction: 0.088421, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,101 root         INFO     Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 0.085204\n",
      "Reconstruction: 0.085204, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,167 root         INFO     Train Epoch: 176 [1536/8000 (19%)]\tTotal Loss: 0.093391\n",
      "Reconstruction: 0.093391, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,232 root         INFO     Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 0.101868\n",
      "Reconstruction: 0.101868, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,296 root         INFO     Train Epoch: 176 [2560/8000 (32%)]\tTotal Loss: 0.094316\n",
      "Reconstruction: 0.094316, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,360 root         INFO     Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 0.092108\n",
      "Reconstruction: 0.092108, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,424 root         INFO     Train Epoch: 176 [3584/8000 (45%)]\tTotal Loss: 0.098800\n",
      "Reconstruction: 0.098800, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,487 root         INFO     Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 0.096356\n",
      "Reconstruction: 0.096356, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,551 root         INFO     Train Epoch: 176 [4608/8000 (58%)]\tTotal Loss: 0.109250\n",
      "Reconstruction: 0.109250, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,616 root         INFO     Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 0.083544\n",
      "Reconstruction: 0.083544, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,680 root         INFO     Train Epoch: 176 [5632/8000 (70%)]\tTotal Loss: 0.095776\n",
      "Reconstruction: 0.095776, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,744 root         INFO     Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 0.086428\n",
      "Reconstruction: 0.086428, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,807 root         INFO     Train Epoch: 176 [6656/8000 (83%)]\tTotal Loss: 0.094060\n",
      "Reconstruction: 0.094060, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,872 root         INFO     Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 0.082459\n",
      "Reconstruction: 0.082459, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,936 root         INFO     Train Epoch: 176 [7680/8000 (96%)]\tTotal Loss: 0.097549\n",
      "Reconstruction: 0.097549, Regularization: 0.000000\n",
      "2019-04-09 23:40:32,990 root         INFO     ====> Epoch: 176 Average loss: 0.0887\n",
      "2019-04-09 23:40:33,013 root         INFO     Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 0.083143\n",
      "Reconstruction: 0.083143, Regularization: 0.000000\n",
      "2019-04-09 23:40:33,078 root         INFO     Train Epoch: 177 [512/8000 (6%)]\tTotal Loss: 0.080581\n",
      "Reconstruction: 0.080581, Regularization: 0.000000\n",
      "2019-04-09 23:40:33,141 root         INFO     Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 0.078935\n",
      "Reconstruction: 0.078935, Regularization: 0.000000\n",
      "2019-04-09 23:40:33,203 root         INFO     Train Epoch: 177 [1536/8000 (19%)]\tTotal Loss: 0.098197\n",
      "Reconstruction: 0.098197, Regularization: 0.000000\n",
      "2019-04-09 23:40:33,264 root         INFO     Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 0.084516\n",
      "Reconstruction: 0.084516, Regularization: 0.000000\n",
      "2019-04-09 23:40:33,326 root         INFO     Train Epoch: 177 [2560/8000 (32%)]\tTotal Loss: 0.089102\n",
      "Reconstruction: 0.089102, Regularization: 0.000000\n",
      "2019-04-09 23:40:33,388 root         INFO     Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 0.093739\n",
      "Reconstruction: 0.093739, Regularization: 0.000000\n",
      "2019-04-09 23:40:33,450 root         INFO     Train Epoch: 177 [3584/8000 (45%)]\tTotal Loss: 0.086898\n",
      "Reconstruction: 0.086898, Regularization: 0.000000\n",
      "2019-04-09 23:40:33,512 root         INFO     Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 0.088809\n",
      "Reconstruction: 0.088809, Regularization: 0.000000\n",
      "2019-04-09 23:40:33,574 root         INFO     Train Epoch: 177 [4608/8000 (58%)]\tTotal Loss: 0.090513\n",
      "Reconstruction: 0.090513, Regularization: 0.000000\n",
      "2019-04-09 23:40:33,636 root         INFO     Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 0.080501\n",
      "Reconstruction: 0.080501, Regularization: 0.000000\n",
      "2019-04-09 23:40:33,698 root         INFO     Train Epoch: 177 [5632/8000 (70%)]\tTotal Loss: 0.082714\n",
      "Reconstruction: 0.082713, Regularization: 0.000000\n",
      "2019-04-09 23:40:33,760 root         INFO     Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 0.091241\n",
      "Reconstruction: 0.091241, Regularization: 0.000000\n",
      "2019-04-09 23:40:33,822 root         INFO     Train Epoch: 177 [6656/8000 (83%)]\tTotal Loss: 0.084592\n",
      "Reconstruction: 0.084592, Regularization: 0.000000\n",
      "2019-04-09 23:40:33,884 root         INFO     Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 0.088369\n",
      "Reconstruction: 0.088369, Regularization: 0.000000\n",
      "2019-04-09 23:40:33,947 root         INFO     Train Epoch: 177 [7680/8000 (96%)]\tTotal Loss: 0.096330\n",
      "Reconstruction: 0.096329, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,002 root         INFO     ====> Epoch: 177 Average loss: 0.0887\n",
      "2019-04-09 23:40:34,025 root         INFO     Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 0.089742\n",
      "Reconstruction: 0.089742, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,089 root         INFO     Train Epoch: 178 [512/8000 (6%)]\tTotal Loss: 0.086715\n",
      "Reconstruction: 0.086715, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,152 root         INFO     Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 0.091911\n",
      "Reconstruction: 0.091911, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,214 root         INFO     Train Epoch: 178 [1536/8000 (19%)]\tTotal Loss: 0.091916\n",
      "Reconstruction: 0.091916, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,276 root         INFO     Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 0.092410\n",
      "Reconstruction: 0.092410, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,339 root         INFO     Train Epoch: 178 [2560/8000 (32%)]\tTotal Loss: 0.093383\n",
      "Reconstruction: 0.093383, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,402 root         INFO     Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 0.094716\n",
      "Reconstruction: 0.094716, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,464 root         INFO     Train Epoch: 178 [3584/8000 (45%)]\tTotal Loss: 0.112401\n",
      "Reconstruction: 0.112401, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,526 root         INFO     Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 0.088609\n",
      "Reconstruction: 0.088609, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,589 root         INFO     Train Epoch: 178 [4608/8000 (58%)]\tTotal Loss: 0.093570\n",
      "Reconstruction: 0.093570, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,652 root         INFO     Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 0.087168\n",
      "Reconstruction: 0.087168, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,714 root         INFO     Train Epoch: 178 [5632/8000 (70%)]\tTotal Loss: 0.082463\n",
      "Reconstruction: 0.082463, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,776 root         INFO     Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 0.089696\n",
      "Reconstruction: 0.089696, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,839 root         INFO     Train Epoch: 178 [6656/8000 (83%)]\tTotal Loss: 0.087717\n",
      "Reconstruction: 0.087717, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,901 root         INFO     Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 0.087710\n",
      "Reconstruction: 0.087710, Regularization: 0.000000\n",
      "2019-04-09 23:40:34,964 root         INFO     Train Epoch: 178 [7680/8000 (96%)]\tTotal Loss: 0.088892\n",
      "Reconstruction: 0.088892, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,018 root         INFO     ====> Epoch: 178 Average loss: 0.0887\n",
      "2019-04-09 23:40:35,042 root         INFO     Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 0.086395\n",
      "Reconstruction: 0.086395, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,105 root         INFO     Train Epoch: 179 [512/8000 (6%)]\tTotal Loss: 0.085532\n",
      "Reconstruction: 0.085531, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,167 root         INFO     Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 0.091450\n",
      "Reconstruction: 0.091450, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,231 root         INFO     Train Epoch: 179 [1536/8000 (19%)]\tTotal Loss: 0.091939\n",
      "Reconstruction: 0.091938, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,293 root         INFO     Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 0.092650\n",
      "Reconstruction: 0.092650, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,356 root         INFO     Train Epoch: 179 [2560/8000 (32%)]\tTotal Loss: 0.079419\n",
      "Reconstruction: 0.079419, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,419 root         INFO     Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 0.097043\n",
      "Reconstruction: 0.097043, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,483 root         INFO     Train Epoch: 179 [3584/8000 (45%)]\tTotal Loss: 0.082328\n",
      "Reconstruction: 0.082328, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,547 root         INFO     Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 0.083967\n",
      "Reconstruction: 0.083967, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,610 root         INFO     Train Epoch: 179 [4608/8000 (58%)]\tTotal Loss: 0.084368\n",
      "Reconstruction: 0.084368, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,672 root         INFO     Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 0.094718\n",
      "Reconstruction: 0.094717, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,735 root         INFO     Train Epoch: 179 [5632/8000 (70%)]\tTotal Loss: 0.098032\n",
      "Reconstruction: 0.098032, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,798 root         INFO     Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 0.088881\n",
      "Reconstruction: 0.088881, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,861 root         INFO     Train Epoch: 179 [6656/8000 (83%)]\tTotal Loss: 0.086277\n",
      "Reconstruction: 0.086276, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,925 root         INFO     Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 0.088065\n",
      "Reconstruction: 0.088065, Regularization: 0.000000\n",
      "2019-04-09 23:40:35,987 root         INFO     Train Epoch: 179 [7680/8000 (96%)]\tTotal Loss: 0.090071\n",
      "Reconstruction: 0.090070, Regularization: 0.000001\n",
      "2019-04-09 23:40:36,041 root         INFO     ====> Epoch: 179 Average loss: 0.0887\n",
      "2019-04-09 23:40:36,065 root         INFO     Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 0.094212\n",
      "Reconstruction: 0.094211, Regularization: 0.000001\n",
      "2019-04-09 23:40:36,129 root         INFO     Train Epoch: 180 [512/8000 (6%)]\tTotal Loss: 0.090598\n",
      "Reconstruction: 0.090598, Regularization: 0.000001\n",
      "2019-04-09 23:40:36,193 root         INFO     Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 0.087136\n",
      "Reconstruction: 0.087135, Regularization: 0.000001\n",
      "2019-04-09 23:40:36,258 root         INFO     Train Epoch: 180 [1536/8000 (19%)]\tTotal Loss: 0.087087\n",
      "Reconstruction: 0.087085, Regularization: 0.000002\n",
      "2019-04-09 23:40:36,322 root         INFO     Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 0.087223\n",
      "Reconstruction: 0.087222, Regularization: 0.000001\n",
      "2019-04-09 23:40:36,386 root         INFO     Train Epoch: 180 [2560/8000 (32%)]\tTotal Loss: 0.091434\n",
      "Reconstruction: 0.091433, Regularization: 0.000001\n",
      "2019-04-09 23:40:36,450 root         INFO     Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 0.087567\n",
      "Reconstruction: 0.087566, Regularization: 0.000001\n",
      "2019-04-09 23:40:36,514 root         INFO     Train Epoch: 180 [3584/8000 (45%)]\tTotal Loss: 0.084851\n",
      "Reconstruction: 0.084851, Regularization: 0.000001\n",
      "2019-04-09 23:40:36,579 root         INFO     Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 0.089924\n",
      "Reconstruction: 0.089923, Regularization: 0.000001\n",
      "2019-04-09 23:40:36,642 root         INFO     Train Epoch: 180 [4608/8000 (58%)]\tTotal Loss: 0.091097\n",
      "Reconstruction: 0.091096, Regularization: 0.000001\n",
      "2019-04-09 23:40:36,706 root         INFO     Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 0.085905\n",
      "Reconstruction: 0.085905, Regularization: 0.000000\n",
      "2019-04-09 23:40:36,770 root         INFO     Train Epoch: 180 [5632/8000 (70%)]\tTotal Loss: 0.095796\n",
      "Reconstruction: 0.095796, Regularization: 0.000000\n",
      "2019-04-09 23:40:36,834 root         INFO     Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 0.087596\n",
      "Reconstruction: 0.087596, Regularization: 0.000000\n",
      "2019-04-09 23:40:36,897 root         INFO     Train Epoch: 180 [6656/8000 (83%)]\tTotal Loss: 0.085069\n",
      "Reconstruction: 0.085069, Regularization: 0.000000\n",
      "2019-04-09 23:40:36,961 root         INFO     Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 0.090059\n",
      "Reconstruction: 0.090059, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,025 root         INFO     Train Epoch: 180 [7680/8000 (96%)]\tTotal Loss: 0.087399\n",
      "Reconstruction: 0.087399, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,079 root         INFO     ====> Epoch: 180 Average loss: 0.0887\n",
      "2019-04-09 23:40:37,103 root         INFO     Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 0.099571\n",
      "Reconstruction: 0.099570, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,166 root         INFO     Train Epoch: 181 [512/8000 (6%)]\tTotal Loss: 0.085127\n",
      "Reconstruction: 0.085127, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,230 root         INFO     Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 0.080855\n",
      "Reconstruction: 0.080855, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,293 root         INFO     Train Epoch: 181 [1536/8000 (19%)]\tTotal Loss: 0.087028\n",
      "Reconstruction: 0.087028, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,359 root         INFO     Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 0.085918\n",
      "Reconstruction: 0.085918, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,422 root         INFO     Train Epoch: 181 [2560/8000 (32%)]\tTotal Loss: 0.082340\n",
      "Reconstruction: 0.082340, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,487 root         INFO     Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 0.078720\n",
      "Reconstruction: 0.078720, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,551 root         INFO     Train Epoch: 181 [3584/8000 (45%)]\tTotal Loss: 0.089221\n",
      "Reconstruction: 0.089221, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,615 root         INFO     Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 0.080156\n",
      "Reconstruction: 0.080156, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,679 root         INFO     Train Epoch: 181 [4608/8000 (58%)]\tTotal Loss: 0.088026\n",
      "Reconstruction: 0.088026, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,743 root         INFO     Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 0.089085\n",
      "Reconstruction: 0.089085, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,806 root         INFO     Train Epoch: 181 [5632/8000 (70%)]\tTotal Loss: 0.088050\n",
      "Reconstruction: 0.088050, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,869 root         INFO     Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 0.087190\n",
      "Reconstruction: 0.087190, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,934 root         INFO     Train Epoch: 181 [6656/8000 (83%)]\tTotal Loss: 0.093371\n",
      "Reconstruction: 0.093371, Regularization: 0.000000\n",
      "2019-04-09 23:40:37,998 root         INFO     Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 0.087865\n",
      "Reconstruction: 0.087865, Regularization: 0.000000\n",
      "2019-04-09 23:40:38,063 root         INFO     Train Epoch: 181 [7680/8000 (96%)]\tTotal Loss: 0.086455\n",
      "Reconstruction: 0.086455, Regularization: 0.000000\n",
      "2019-04-09 23:40:38,118 root         INFO     ====> Epoch: 181 Average loss: 0.0887\n",
      "2019-04-09 23:40:38,142 root         INFO     Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 0.097500\n",
      "Reconstruction: 0.097500, Regularization: 0.000000\n",
      "2019-04-09 23:40:38,206 root         INFO     Train Epoch: 182 [512/8000 (6%)]\tTotal Loss: 0.086585\n",
      "Reconstruction: 0.086585, Regularization: 0.000000\n",
      "2019-04-09 23:40:38,269 root         INFO     Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 0.098540\n",
      "Reconstruction: 0.098540, Regularization: 0.000000\n",
      "2019-04-09 23:40:38,333 root         INFO     Train Epoch: 182 [1536/8000 (19%)]\tTotal Loss: 0.088760\n",
      "Reconstruction: 0.088760, Regularization: 0.000000\n",
      "2019-04-09 23:40:38,397 root         INFO     Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 0.086855\n",
      "Reconstruction: 0.086855, Regularization: 0.000000\n",
      "2019-04-09 23:40:38,460 root         INFO     Train Epoch: 182 [2560/8000 (32%)]\tTotal Loss: 0.097454\n",
      "Reconstruction: 0.097454, Regularization: 0.000000\n",
      "2019-04-09 23:40:38,522 root         INFO     Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 0.087140\n",
      "Reconstruction: 0.087140, Regularization: 0.000000\n",
      "2019-04-09 23:40:38,585 root         INFO     Train Epoch: 182 [3584/8000 (45%)]\tTotal Loss: 0.083466\n",
      "Reconstruction: 0.083466, Regularization: 0.000000\n",
      "2019-04-09 23:40:38,648 root         INFO     Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 0.082794\n",
      "Reconstruction: 0.082794, Regularization: 0.000000\n",
      "2019-04-09 23:40:38,710 root         INFO     Train Epoch: 182 [4608/8000 (58%)]\tTotal Loss: 0.086314\n",
      "Reconstruction: 0.086313, Regularization: 0.000000\n",
      "2019-04-09 23:40:38,773 root         INFO     Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 0.078328\n",
      "Reconstruction: 0.078328, Regularization: 0.000000\n",
      "2019-04-09 23:40:38,836 root         INFO     Train Epoch: 182 [5632/8000 (70%)]\tTotal Loss: 0.087679\n",
      "Reconstruction: 0.087679, Regularization: 0.000000\n",
      "2019-04-09 23:40:38,897 root         INFO     Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 0.094021\n",
      "Reconstruction: 0.094021, Regularization: 0.000000\n",
      "2019-04-09 23:40:38,959 root         INFO     Train Epoch: 182 [6656/8000 (83%)]\tTotal Loss: 0.084715\n",
      "Reconstruction: 0.084714, Regularization: 0.000000\n",
      "2019-04-09 23:40:39,022 root         INFO     Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 0.084941\n",
      "Reconstruction: 0.084940, Regularization: 0.000000\n",
      "2019-04-09 23:40:39,084 root         INFO     Train Epoch: 182 [7680/8000 (96%)]\tTotal Loss: 0.079550\n",
      "Reconstruction: 0.079550, Regularization: 0.000000\n",
      "2019-04-09 23:40:39,137 root         INFO     ====> Epoch: 182 Average loss: 0.0887\n",
      "2019-04-09 23:40:39,161 root         INFO     Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 0.089860\n",
      "Reconstruction: 0.089859, Regularization: 0.000001\n",
      "2019-04-09 23:40:39,225 root         INFO     Train Epoch: 183 [512/8000 (6%)]\tTotal Loss: 0.090042\n",
      "Reconstruction: 0.090041, Regularization: 0.000001\n",
      "2019-04-09 23:40:39,289 root         INFO     Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 0.090686\n",
      "Reconstruction: 0.090685, Regularization: 0.000001\n",
      "2019-04-09 23:40:39,353 root         INFO     Train Epoch: 183 [1536/8000 (19%)]\tTotal Loss: 0.092794\n",
      "Reconstruction: 0.092794, Regularization: 0.000001\n",
      "2019-04-09 23:40:39,417 root         INFO     Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 0.084376\n",
      "Reconstruction: 0.084376, Regularization: 0.000001\n",
      "2019-04-09 23:40:39,481 root         INFO     Train Epoch: 183 [2560/8000 (32%)]\tTotal Loss: 0.086852\n",
      "Reconstruction: 0.086851, Regularization: 0.000000\n",
      "2019-04-09 23:40:39,545 root         INFO     Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 0.090780\n",
      "Reconstruction: 0.090780, Regularization: 0.000000\n",
      "2019-04-09 23:40:39,608 root         INFO     Train Epoch: 183 [3584/8000 (45%)]\tTotal Loss: 0.099396\n",
      "Reconstruction: 0.099396, Regularization: 0.000000\n",
      "2019-04-09 23:40:39,673 root         INFO     Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 0.081252\n",
      "Reconstruction: 0.081251, Regularization: 0.000000\n",
      "2019-04-09 23:40:39,736 root         INFO     Train Epoch: 183 [4608/8000 (58%)]\tTotal Loss: 0.090406\n",
      "Reconstruction: 0.090406, Regularization: 0.000000\n",
      "2019-04-09 23:40:39,799 root         INFO     Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 0.087464\n",
      "Reconstruction: 0.087464, Regularization: 0.000000\n",
      "2019-04-09 23:40:39,862 root         INFO     Train Epoch: 183 [5632/8000 (70%)]\tTotal Loss: 0.086888\n",
      "Reconstruction: 0.086888, Regularization: 0.000000\n",
      "2019-04-09 23:40:39,926 root         INFO     Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 0.087842\n",
      "Reconstruction: 0.087842, Regularization: 0.000000\n",
      "2019-04-09 23:40:39,989 root         INFO     Train Epoch: 183 [6656/8000 (83%)]\tTotal Loss: 0.089239\n",
      "Reconstruction: 0.089239, Regularization: 0.000000\n",
      "2019-04-09 23:40:40,051 root         INFO     Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 0.085255\n",
      "Reconstruction: 0.085255, Regularization: 0.000000\n",
      "2019-04-09 23:40:40,114 root         INFO     Train Epoch: 183 [7680/8000 (96%)]\tTotal Loss: 0.097843\n",
      "Reconstruction: 0.097843, Regularization: 0.000000\n",
      "2019-04-09 23:40:40,168 root         INFO     ====> Epoch: 183 Average loss: 0.0887\n",
      "2019-04-09 23:40:40,192 root         INFO     Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 0.088290\n",
      "Reconstruction: 0.088290, Regularization: 0.000000\n",
      "2019-04-09 23:40:40,255 root         INFO     Train Epoch: 184 [512/8000 (6%)]\tTotal Loss: 0.086677\n",
      "Reconstruction: 0.086677, Regularization: 0.000000\n",
      "2019-04-09 23:40:40,318 root         INFO     Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 0.082579\n",
      "Reconstruction: 0.082579, Regularization: 0.000000\n",
      "2019-04-09 23:40:40,382 root         INFO     Train Epoch: 184 [1536/8000 (19%)]\tTotal Loss: 0.090612\n",
      "Reconstruction: 0.090612, Regularization: 0.000000\n",
      "2019-04-09 23:40:40,445 root         INFO     Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 0.086036\n",
      "Reconstruction: 0.086036, Regularization: 0.000000\n",
      "2019-04-09 23:40:40,507 root         INFO     Train Epoch: 184 [2560/8000 (32%)]\tTotal Loss: 0.098883\n",
      "Reconstruction: 0.098883, Regularization: 0.000000\n",
      "2019-04-09 23:40:40,571 root         INFO     Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 0.088773\n",
      "Reconstruction: 0.088773, Regularization: 0.000000\n",
      "2019-04-09 23:40:40,633 root         INFO     Train Epoch: 184 [3584/8000 (45%)]\tTotal Loss: 0.086601\n",
      "Reconstruction: 0.086601, Regularization: 0.000000\n",
      "2019-04-09 23:40:40,696 root         INFO     Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 0.093097\n",
      "Reconstruction: 0.093097, Regularization: 0.000000\n",
      "2019-04-09 23:40:40,761 root         INFO     Train Epoch: 184 [4608/8000 (58%)]\tTotal Loss: 0.085658\n",
      "Reconstruction: 0.085658, Regularization: 0.000000\n",
      "2019-04-09 23:40:40,825 root         INFO     Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 0.096970\n",
      "Reconstruction: 0.096970, Regularization: 0.000000\n",
      "2019-04-09 23:40:40,888 root         INFO     Train Epoch: 184 [5632/8000 (70%)]\tTotal Loss: 0.081090\n",
      "Reconstruction: 0.081090, Regularization: 0.000000\n",
      "2019-04-09 23:40:40,951 root         INFO     Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 0.087457\n",
      "Reconstruction: 0.087456, Regularization: 0.000000\n",
      "2019-04-09 23:40:41,013 root         INFO     Train Epoch: 184 [6656/8000 (83%)]\tTotal Loss: 0.087802\n",
      "Reconstruction: 0.087802, Regularization: 0.000000\n",
      "2019-04-09 23:40:41,075 root         INFO     Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 0.089966\n",
      "Reconstruction: 0.089966, Regularization: 0.000000\n",
      "2019-04-09 23:40:41,137 root         INFO     Train Epoch: 184 [7680/8000 (96%)]\tTotal Loss: 0.096449\n",
      "Reconstruction: 0.096449, Regularization: 0.000000\n",
      "2019-04-09 23:40:41,190 root         INFO     ====> Epoch: 184 Average loss: 0.0887\n",
      "2019-04-09 23:40:41,215 root         INFO     Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 0.085958\n",
      "Reconstruction: 0.085957, Regularization: 0.000000\n",
      "2019-04-09 23:40:41,278 root         INFO     Train Epoch: 185 [512/8000 (6%)]\tTotal Loss: 0.085839\n",
      "Reconstruction: 0.085838, Regularization: 0.000000\n",
      "2019-04-09 23:40:41,342 root         INFO     Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 0.090286\n",
      "Reconstruction: 0.090285, Regularization: 0.000000\n",
      "2019-04-09 23:40:41,406 root         INFO     Train Epoch: 185 [1536/8000 (19%)]\tTotal Loss: 0.085976\n",
      "Reconstruction: 0.085976, Regularization: 0.000001\n",
      "2019-04-09 23:40:41,470 root         INFO     Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 0.094046\n",
      "Reconstruction: 0.094045, Regularization: 0.000001\n",
      "2019-04-09 23:40:41,533 root         INFO     Train Epoch: 185 [2560/8000 (32%)]\tTotal Loss: 0.084600\n",
      "Reconstruction: 0.084600, Regularization: 0.000000\n",
      "2019-04-09 23:40:41,597 root         INFO     Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 0.097315\n",
      "Reconstruction: 0.097314, Regularization: 0.000001\n",
      "2019-04-09 23:40:41,660 root         INFO     Train Epoch: 185 [3584/8000 (45%)]\tTotal Loss: 0.097796\n",
      "Reconstruction: 0.097796, Regularization: 0.000000\n",
      "2019-04-09 23:40:41,724 root         INFO     Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 0.085785\n",
      "Reconstruction: 0.085785, Regularization: 0.000000\n",
      "2019-04-09 23:40:41,786 root         INFO     Train Epoch: 185 [4608/8000 (58%)]\tTotal Loss: 0.077763\n",
      "Reconstruction: 0.077763, Regularization: 0.000000\n",
      "2019-04-09 23:40:41,849 root         INFO     Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 0.095403\n",
      "Reconstruction: 0.095403, Regularization: 0.000000\n",
      "2019-04-09 23:40:41,911 root         INFO     Train Epoch: 185 [5632/8000 (70%)]\tTotal Loss: 0.090768\n",
      "Reconstruction: 0.090768, Regularization: 0.000000\n",
      "2019-04-09 23:40:41,974 root         INFO     Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 0.088639\n",
      "Reconstruction: 0.088639, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,037 root         INFO     Train Epoch: 185 [6656/8000 (83%)]\tTotal Loss: 0.079651\n",
      "Reconstruction: 0.079651, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,099 root         INFO     Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 0.084071\n",
      "Reconstruction: 0.084070, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,161 root         INFO     Train Epoch: 185 [7680/8000 (96%)]\tTotal Loss: 0.086399\n",
      "Reconstruction: 0.086399, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,213 root         INFO     ====> Epoch: 185 Average loss: 0.0887\n",
      "2019-04-09 23:40:42,238 root         INFO     Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 0.090400\n",
      "Reconstruction: 0.090400, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,301 root         INFO     Train Epoch: 186 [512/8000 (6%)]\tTotal Loss: 0.088378\n",
      "Reconstruction: 0.088378, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,365 root         INFO     Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 0.093761\n",
      "Reconstruction: 0.093761, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,427 root         INFO     Train Epoch: 186 [1536/8000 (19%)]\tTotal Loss: 0.080472\n",
      "Reconstruction: 0.080472, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,491 root         INFO     Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 0.086384\n",
      "Reconstruction: 0.086384, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,555 root         INFO     Train Epoch: 186 [2560/8000 (32%)]\tTotal Loss: 0.087806\n",
      "Reconstruction: 0.087806, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,619 root         INFO     Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 0.077473\n",
      "Reconstruction: 0.077473, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,682 root         INFO     Train Epoch: 186 [3584/8000 (45%)]\tTotal Loss: 0.094593\n",
      "Reconstruction: 0.094593, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,746 root         INFO     Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 0.097049\n",
      "Reconstruction: 0.097049, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,809 root         INFO     Train Epoch: 186 [4608/8000 (58%)]\tTotal Loss: 0.080900\n",
      "Reconstruction: 0.080900, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,872 root         INFO     Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 0.085915\n",
      "Reconstruction: 0.085915, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,934 root         INFO     Train Epoch: 186 [5632/8000 (70%)]\tTotal Loss: 0.095898\n",
      "Reconstruction: 0.095898, Regularization: 0.000000\n",
      "2019-04-09 23:40:42,996 root         INFO     Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 0.076316\n",
      "Reconstruction: 0.076316, Regularization: 0.000000\n",
      "2019-04-09 23:40:43,058 root         INFO     Train Epoch: 186 [6656/8000 (83%)]\tTotal Loss: 0.080389\n",
      "Reconstruction: 0.080389, Regularization: 0.000000\n",
      "2019-04-09 23:40:43,120 root         INFO     Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 0.098521\n",
      "Reconstruction: 0.098521, Regularization: 0.000000\n",
      "2019-04-09 23:40:43,182 root         INFO     Train Epoch: 186 [7680/8000 (96%)]\tTotal Loss: 0.093141\n",
      "Reconstruction: 0.093141, Regularization: 0.000000\n",
      "2019-04-09 23:40:43,235 root         INFO     ====> Epoch: 186 Average loss: 0.0887\n",
      "2019-04-09 23:40:43,259 root         INFO     Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 0.091443\n",
      "Reconstruction: 0.091443, Regularization: 0.000000\n",
      "2019-04-09 23:40:43,323 root         INFO     Train Epoch: 187 [512/8000 (6%)]\tTotal Loss: 0.090184\n",
      "Reconstruction: 0.090184, Regularization: 0.000000\n",
      "2019-04-09 23:40:43,387 root         INFO     Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 0.077416\n",
      "Reconstruction: 0.077416, Regularization: 0.000000\n",
      "2019-04-09 23:40:43,451 root         INFO     Train Epoch: 187 [1536/8000 (19%)]\tTotal Loss: 0.079787\n",
      "Reconstruction: 0.079787, Regularization: 0.000000\n",
      "2019-04-09 23:40:43,515 root         INFO     Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 0.087267\n",
      "Reconstruction: 0.087267, Regularization: 0.000000\n",
      "2019-04-09 23:40:43,579 root         INFO     Train Epoch: 187 [2560/8000 (32%)]\tTotal Loss: 0.087207\n",
      "Reconstruction: 0.087207, Regularization: 0.000000\n",
      "2019-04-09 23:40:43,642 root         INFO     Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 0.096030\n",
      "Reconstruction: 0.096030, Regularization: 0.000000\n",
      "2019-04-09 23:40:43,706 root         INFO     Train Epoch: 187 [3584/8000 (45%)]\tTotal Loss: 0.095586\n",
      "Reconstruction: 0.095586, Regularization: 0.000000\n",
      "2019-04-09 23:40:43,769 root         INFO     Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 0.084824\n",
      "Reconstruction: 0.084824, Regularization: 0.000000\n",
      "2019-04-09 23:40:43,832 root         INFO     Train Epoch: 187 [4608/8000 (58%)]\tTotal Loss: 0.089725\n",
      "Reconstruction: 0.089725, Regularization: 0.000000\n",
      "2019-04-09 23:40:43,895 root         INFO     Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 0.098773\n",
      "Reconstruction: 0.098773, Regularization: 0.000000\n",
      "2019-04-09 23:40:43,959 root         INFO     Train Epoch: 187 [5632/8000 (70%)]\tTotal Loss: 0.092759\n",
      "Reconstruction: 0.092759, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,023 root         INFO     Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 0.095029\n",
      "Reconstruction: 0.095028, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,086 root         INFO     Train Epoch: 187 [6656/8000 (83%)]\tTotal Loss: 0.087332\n",
      "Reconstruction: 0.087332, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,150 root         INFO     Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 0.088661\n",
      "Reconstruction: 0.088661, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,214 root         INFO     Train Epoch: 187 [7680/8000 (96%)]\tTotal Loss: 0.086494\n",
      "Reconstruction: 0.086494, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,268 root         INFO     ====> Epoch: 187 Average loss: 0.0887\n",
      "2019-04-09 23:40:44,292 root         INFO     Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 0.094309\n",
      "Reconstruction: 0.094309, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,356 root         INFO     Train Epoch: 188 [512/8000 (6%)]\tTotal Loss: 0.103324\n",
      "Reconstruction: 0.103324, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,419 root         INFO     Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 0.090898\n",
      "Reconstruction: 0.090898, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,481 root         INFO     Train Epoch: 188 [1536/8000 (19%)]\tTotal Loss: 0.091693\n",
      "Reconstruction: 0.091693, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,543 root         INFO     Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 0.084453\n",
      "Reconstruction: 0.084452, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,605 root         INFO     Train Epoch: 188 [2560/8000 (32%)]\tTotal Loss: 0.083644\n",
      "Reconstruction: 0.083644, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,666 root         INFO     Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 0.092782\n",
      "Reconstruction: 0.092782, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,729 root         INFO     Train Epoch: 188 [3584/8000 (45%)]\tTotal Loss: 0.090421\n",
      "Reconstruction: 0.090421, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,791 root         INFO     Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 0.094113\n",
      "Reconstruction: 0.094113, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,853 root         INFO     Train Epoch: 188 [4608/8000 (58%)]\tTotal Loss: 0.085095\n",
      "Reconstruction: 0.085095, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,915 root         INFO     Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 0.096882\n",
      "Reconstruction: 0.096882, Regularization: 0.000000\n",
      "2019-04-09 23:40:44,977 root         INFO     Train Epoch: 188 [5632/8000 (70%)]\tTotal Loss: 0.093964\n",
      "Reconstruction: 0.093964, Regularization: 0.000000\n",
      "2019-04-09 23:40:45,039 root         INFO     Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 0.105799\n",
      "Reconstruction: 0.105799, Regularization: 0.000000\n",
      "2019-04-09 23:40:45,101 root         INFO     Train Epoch: 188 [6656/8000 (83%)]\tTotal Loss: 0.077276\n",
      "Reconstruction: 0.077276, Regularization: 0.000000\n",
      "2019-04-09 23:40:45,163 root         INFO     Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 0.099476\n",
      "Reconstruction: 0.099476, Regularization: 0.000000\n",
      "2019-04-09 23:40:45,224 root         INFO     Train Epoch: 188 [7680/8000 (96%)]\tTotal Loss: 0.096052\n",
      "Reconstruction: 0.096051, Regularization: 0.000000\n",
      "2019-04-09 23:40:45,277 root         INFO     ====> Epoch: 188 Average loss: 0.0887\n",
      "2019-04-09 23:40:45,301 root         INFO     Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 0.106963\n",
      "Reconstruction: 0.106963, Regularization: 0.000000\n",
      "2019-04-09 23:40:45,363 root         INFO     Train Epoch: 189 [512/8000 (6%)]\tTotal Loss: 0.089032\n",
      "Reconstruction: 0.089032, Regularization: 0.000000\n",
      "2019-04-09 23:40:45,425 root         INFO     Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 0.087187\n",
      "Reconstruction: 0.087187, Regularization: 0.000000\n",
      "2019-04-09 23:40:45,487 root         INFO     Train Epoch: 189 [1536/8000 (19%)]\tTotal Loss: 0.084480\n",
      "Reconstruction: 0.084480, Regularization: 0.000001\n",
      "2019-04-09 23:40:45,548 root         INFO     Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 0.097197\n",
      "Reconstruction: 0.097197, Regularization: 0.000000\n",
      "2019-04-09 23:40:45,611 root         INFO     Train Epoch: 189 [2560/8000 (32%)]\tTotal Loss: 0.085785\n",
      "Reconstruction: 0.085785, Regularization: 0.000000\n",
      "2019-04-09 23:40:45,673 root         INFO     Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 0.105731\n",
      "Reconstruction: 0.105731, Regularization: 0.000000\n",
      "2019-04-09 23:40:45,735 root         INFO     Train Epoch: 189 [3584/8000 (45%)]\tTotal Loss: 0.082074\n",
      "Reconstruction: 0.082074, Regularization: 0.000000\n",
      "2019-04-09 23:40:45,797 root         INFO     Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 0.080557\n",
      "Reconstruction: 0.080557, Regularization: 0.000000\n",
      "2019-04-09 23:40:45,860 root         INFO     Train Epoch: 189 [4608/8000 (58%)]\tTotal Loss: 0.080408\n",
      "Reconstruction: 0.080408, Regularization: 0.000000\n",
      "2019-04-09 23:40:45,923 root         INFO     Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 0.083956\n",
      "Reconstruction: 0.083956, Regularization: 0.000001\n",
      "2019-04-09 23:40:45,986 root         INFO     Train Epoch: 189 [5632/8000 (70%)]\tTotal Loss: 0.085053\n",
      "Reconstruction: 0.085053, Regularization: 0.000000\n",
      "2019-04-09 23:40:46,049 root         INFO     Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 0.096443\n",
      "Reconstruction: 0.096443, Regularization: 0.000000\n",
      "2019-04-09 23:40:46,112 root         INFO     Train Epoch: 189 [6656/8000 (83%)]\tTotal Loss: 0.085171\n",
      "Reconstruction: 0.085171, Regularization: 0.000000\n",
      "2019-04-09 23:40:46,175 root         INFO     Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 0.083585\n",
      "Reconstruction: 0.083585, Regularization: 0.000000\n",
      "2019-04-09 23:40:46,238 root         INFO     Train Epoch: 189 [7680/8000 (96%)]\tTotal Loss: 0.091239\n",
      "Reconstruction: 0.091238, Regularization: 0.000001\n",
      "2019-04-09 23:40:46,292 root         INFO     ====> Epoch: 189 Average loss: 0.0887\n",
      "2019-04-09 23:40:46,316 root         INFO     Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 0.079806\n",
      "Reconstruction: 0.079805, Regularization: 0.000001\n",
      "2019-04-09 23:40:46,379 root         INFO     Train Epoch: 190 [512/8000 (6%)]\tTotal Loss: 0.099713\n",
      "Reconstruction: 0.099712, Regularization: 0.000001\n",
      "2019-04-09 23:40:46,442 root         INFO     Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 0.091254\n",
      "Reconstruction: 0.091254, Regularization: 0.000000\n",
      "2019-04-09 23:40:46,504 root         INFO     Train Epoch: 190 [1536/8000 (19%)]\tTotal Loss: 0.089104\n",
      "Reconstruction: 0.089104, Regularization: 0.000000\n",
      "2019-04-09 23:40:46,568 root         INFO     Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 0.087838\n",
      "Reconstruction: 0.087838, Regularization: 0.000000\n",
      "2019-04-09 23:40:46,630 root         INFO     Train Epoch: 190 [2560/8000 (32%)]\tTotal Loss: 0.079633\n",
      "Reconstruction: 0.079633, Regularization: 0.000000\n",
      "2019-04-09 23:40:46,693 root         INFO     Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 0.087337\n",
      "Reconstruction: 0.087336, Regularization: 0.000000\n",
      "2019-04-09 23:40:46,756 root         INFO     Train Epoch: 190 [3584/8000 (45%)]\tTotal Loss: 0.097105\n",
      "Reconstruction: 0.097105, Regularization: 0.000001\n",
      "2019-04-09 23:40:46,819 root         INFO     Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 0.090822\n",
      "Reconstruction: 0.090822, Regularization: 0.000000\n",
      "2019-04-09 23:40:46,881 root         INFO     Train Epoch: 190 [4608/8000 (58%)]\tTotal Loss: 0.087902\n",
      "Reconstruction: 0.087902, Regularization: 0.000000\n",
      "2019-04-09 23:40:46,945 root         INFO     Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 0.087029\n",
      "Reconstruction: 0.087029, Regularization: 0.000000\n",
      "2019-04-09 23:40:47,008 root         INFO     Train Epoch: 190 [5632/8000 (70%)]\tTotal Loss: 0.086552\n",
      "Reconstruction: 0.086552, Regularization: 0.000000\n",
      "2019-04-09 23:40:47,070 root         INFO     Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 0.084869\n",
      "Reconstruction: 0.084869, Regularization: 0.000000\n",
      "2019-04-09 23:40:47,133 root         INFO     Train Epoch: 190 [6656/8000 (83%)]\tTotal Loss: 0.096799\n",
      "Reconstruction: 0.096798, Regularization: 0.000001\n",
      "2019-04-09 23:40:47,195 root         INFO     Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 0.088668\n",
      "Reconstruction: 0.088667, Regularization: 0.000001\n",
      "2019-04-09 23:40:47,258 root         INFO     Train Epoch: 190 [7680/8000 (96%)]\tTotal Loss: 0.088329\n",
      "Reconstruction: 0.088327, Regularization: 0.000002\n",
      "2019-04-09 23:40:47,311 root         INFO     ====> Epoch: 190 Average loss: 0.0887\n",
      "2019-04-09 23:40:47,335 root         INFO     Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 0.083449\n",
      "Reconstruction: 0.083448, Regularization: 0.000001\n",
      "2019-04-09 23:40:47,398 root         INFO     Train Epoch: 191 [512/8000 (6%)]\tTotal Loss: 0.086999\n",
      "Reconstruction: 0.086996, Regularization: 0.000002\n",
      "2019-04-09 23:40:47,462 root         INFO     Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 0.093079\n",
      "Reconstruction: 0.093077, Regularization: 0.000002\n",
      "2019-04-09 23:40:47,524 root         INFO     Train Epoch: 191 [1536/8000 (19%)]\tTotal Loss: 0.096036\n",
      "Reconstruction: 0.096033, Regularization: 0.000003\n",
      "2019-04-09 23:40:47,587 root         INFO     Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 0.088427\n",
      "Reconstruction: 0.088425, Regularization: 0.000003\n",
      "2019-04-09 23:40:47,650 root         INFO     Train Epoch: 191 [2560/8000 (32%)]\tTotal Loss: 0.091383\n",
      "Reconstruction: 0.091380, Regularization: 0.000003\n",
      "2019-04-09 23:40:47,713 root         INFO     Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 0.090461\n",
      "Reconstruction: 0.090458, Regularization: 0.000003\n",
      "2019-04-09 23:40:47,776 root         INFO     Train Epoch: 191 [3584/8000 (45%)]\tTotal Loss: 0.096557\n",
      "Reconstruction: 0.096554, Regularization: 0.000003\n",
      "2019-04-09 23:40:47,838 root         INFO     Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 0.092612\n",
      "Reconstruction: 0.092609, Regularization: 0.000003\n",
      "2019-04-09 23:40:47,901 root         INFO     Train Epoch: 191 [4608/8000 (58%)]\tTotal Loss: 0.100088\n",
      "Reconstruction: 0.100083, Regularization: 0.000005\n",
      "2019-04-09 23:40:47,964 root         INFO     Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 0.081429\n",
      "Reconstruction: 0.081427, Regularization: 0.000002\n",
      "2019-04-09 23:40:48,027 root         INFO     Train Epoch: 191 [5632/8000 (70%)]\tTotal Loss: 0.084389\n",
      "Reconstruction: 0.084387, Regularization: 0.000002\n",
      "2019-04-09 23:40:48,090 root         INFO     Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 0.088599\n",
      "Reconstruction: 0.088596, Regularization: 0.000003\n",
      "2019-04-09 23:40:48,152 root         INFO     Train Epoch: 191 [6656/8000 (83%)]\tTotal Loss: 0.090419\n",
      "Reconstruction: 0.090417, Regularization: 0.000002\n",
      "2019-04-09 23:40:48,215 root         INFO     Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 0.088687\n",
      "Reconstruction: 0.088684, Regularization: 0.000003\n",
      "2019-04-09 23:40:48,277 root         INFO     Train Epoch: 191 [7680/8000 (96%)]\tTotal Loss: 0.088351\n",
      "Reconstruction: 0.088349, Regularization: 0.000003\n",
      "2019-04-09 23:40:48,331 root         INFO     ====> Epoch: 191 Average loss: 0.0887\n",
      "2019-04-09 23:40:48,355 root         INFO     Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 0.091013\n",
      "Reconstruction: 0.091010, Regularization: 0.000003\n",
      "2019-04-09 23:40:48,419 root         INFO     Train Epoch: 192 [512/8000 (6%)]\tTotal Loss: 0.087826\n",
      "Reconstruction: 0.087824, Regularization: 0.000002\n",
      "2019-04-09 23:40:48,482 root         INFO     Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 0.087449\n",
      "Reconstruction: 0.087447, Regularization: 0.000002\n",
      "2019-04-09 23:40:48,545 root         INFO     Train Epoch: 192 [1536/8000 (19%)]\tTotal Loss: 0.080170\n",
      "Reconstruction: 0.080169, Regularization: 0.000001\n",
      "2019-04-09 23:40:48,607 root         INFO     Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.091198\n",
      "Reconstruction: 0.091197, Regularization: 0.000002\n",
      "2019-04-09 23:40:48,670 root         INFO     Train Epoch: 192 [2560/8000 (32%)]\tTotal Loss: 0.095034\n",
      "Reconstruction: 0.095033, Regularization: 0.000001\n",
      "2019-04-09 23:40:48,733 root         INFO     Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 0.084567\n",
      "Reconstruction: 0.084566, Regularization: 0.000001\n",
      "2019-04-09 23:40:48,795 root         INFO     Train Epoch: 192 [3584/8000 (45%)]\tTotal Loss: 0.091722\n",
      "Reconstruction: 0.091722, Regularization: 0.000001\n",
      "2019-04-09 23:40:48,857 root         INFO     Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 0.089365\n",
      "Reconstruction: 0.089364, Regularization: 0.000001\n",
      "2019-04-09 23:40:48,919 root         INFO     Train Epoch: 192 [4608/8000 (58%)]\tTotal Loss: 0.081174\n",
      "Reconstruction: 0.081173, Regularization: 0.000001\n",
      "2019-04-09 23:40:48,982 root         INFO     Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 0.095415\n",
      "Reconstruction: 0.095413, Regularization: 0.000002\n",
      "2019-04-09 23:40:49,045 root         INFO     Train Epoch: 192 [5632/8000 (70%)]\tTotal Loss: 0.079087\n",
      "Reconstruction: 0.079085, Regularization: 0.000002\n",
      "2019-04-09 23:40:49,107 root         INFO     Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 0.099368\n",
      "Reconstruction: 0.099365, Regularization: 0.000003\n",
      "2019-04-09 23:40:49,169 root         INFO     Train Epoch: 192 [6656/8000 (83%)]\tTotal Loss: 0.082092\n",
      "Reconstruction: 0.082090, Regularization: 0.000002\n",
      "2019-04-09 23:40:49,231 root         INFO     Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 0.089218\n",
      "Reconstruction: 0.089217, Regularization: 0.000001\n",
      "2019-04-09 23:40:49,294 root         INFO     Train Epoch: 192 [7680/8000 (96%)]\tTotal Loss: 0.095451\n",
      "Reconstruction: 0.095449, Regularization: 0.000001\n",
      "2019-04-09 23:40:49,347 root         INFO     ====> Epoch: 192 Average loss: 0.0887\n",
      "2019-04-09 23:40:49,371 root         INFO     Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 0.098087\n",
      "Reconstruction: 0.098085, Regularization: 0.000002\n",
      "2019-04-09 23:40:49,434 root         INFO     Train Epoch: 193 [512/8000 (6%)]\tTotal Loss: 0.086996\n",
      "Reconstruction: 0.086996, Regularization: 0.000001\n",
      "2019-04-09 23:40:49,497 root         INFO     Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 0.088449\n",
      "Reconstruction: 0.088448, Regularization: 0.000001\n",
      "2019-04-09 23:40:49,560 root         INFO     Train Epoch: 193 [1536/8000 (19%)]\tTotal Loss: 0.089161\n",
      "Reconstruction: 0.089161, Regularization: 0.000001\n",
      "2019-04-09 23:40:49,623 root         INFO     Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 0.080592\n",
      "Reconstruction: 0.080592, Regularization: 0.000001\n",
      "2019-04-09 23:40:49,686 root         INFO     Train Epoch: 193 [2560/8000 (32%)]\tTotal Loss: 0.091426\n",
      "Reconstruction: 0.091425, Regularization: 0.000001\n",
      "2019-04-09 23:40:49,749 root         INFO     Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 0.105091\n",
      "Reconstruction: 0.105090, Regularization: 0.000000\n",
      "2019-04-09 23:40:49,812 root         INFO     Train Epoch: 193 [3584/8000 (45%)]\tTotal Loss: 0.085320\n",
      "Reconstruction: 0.085320, Regularization: 0.000000\n",
      "2019-04-09 23:40:49,875 root         INFO     Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 0.086215\n",
      "Reconstruction: 0.086215, Regularization: 0.000000\n",
      "2019-04-09 23:40:49,938 root         INFO     Train Epoch: 193 [4608/8000 (58%)]\tTotal Loss: 0.093396\n",
      "Reconstruction: 0.093395, Regularization: 0.000001\n",
      "2019-04-09 23:40:50,000 root         INFO     Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 0.081268\n",
      "Reconstruction: 0.081268, Regularization: 0.000000\n",
      "2019-04-09 23:40:50,063 root         INFO     Train Epoch: 193 [5632/8000 (70%)]\tTotal Loss: 0.084911\n",
      "Reconstruction: 0.084910, Regularization: 0.000001\n",
      "2019-04-09 23:40:50,125 root         INFO     Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 0.085001\n",
      "Reconstruction: 0.085000, Regularization: 0.000000\n",
      "2019-04-09 23:40:50,188 root         INFO     Train Epoch: 193 [6656/8000 (83%)]\tTotal Loss: 0.089357\n",
      "Reconstruction: 0.089357, Regularization: 0.000000\n",
      "2019-04-09 23:40:50,251 root         INFO     Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 0.095868\n",
      "Reconstruction: 0.095868, Regularization: 0.000000\n",
      "2019-04-09 23:40:50,313 root         INFO     Train Epoch: 193 [7680/8000 (96%)]\tTotal Loss: 0.091075\n",
      "Reconstruction: 0.091075, Regularization: 0.000000\n",
      "2019-04-09 23:40:50,367 root         INFO     ====> Epoch: 193 Average loss: 0.0887\n",
      "2019-04-09 23:40:50,390 root         INFO     Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 0.086265\n",
      "Reconstruction: 0.086265, Regularization: 0.000000\n",
      "2019-04-09 23:40:50,454 root         INFO     Train Epoch: 194 [512/8000 (6%)]\tTotal Loss: 0.086678\n",
      "Reconstruction: 0.086678, Regularization: 0.000000\n",
      "2019-04-09 23:40:50,517 root         INFO     Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 0.081092\n",
      "Reconstruction: 0.081092, Regularization: 0.000000\n",
      "2019-04-09 23:40:50,580 root         INFO     Train Epoch: 194 [1536/8000 (19%)]\tTotal Loss: 0.092319\n",
      "Reconstruction: 0.092318, Regularization: 0.000000\n",
      "2019-04-09 23:40:50,644 root         INFO     Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 0.094796\n",
      "Reconstruction: 0.094796, Regularization: 0.000000\n",
      "2019-04-09 23:40:50,706 root         INFO     Train Epoch: 194 [2560/8000 (32%)]\tTotal Loss: 0.080545\n",
      "Reconstruction: 0.080544, Regularization: 0.000000\n",
      "2019-04-09 23:40:50,769 root         INFO     Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 0.093299\n",
      "Reconstruction: 0.093298, Regularization: 0.000001\n",
      "2019-04-09 23:40:50,833 root         INFO     Train Epoch: 194 [3584/8000 (45%)]\tTotal Loss: 0.085256\n",
      "Reconstruction: 0.085255, Regularization: 0.000000\n",
      "2019-04-09 23:40:50,896 root         INFO     Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 0.081194\n",
      "Reconstruction: 0.081193, Regularization: 0.000000\n",
      "2019-04-09 23:40:50,958 root         INFO     Train Epoch: 194 [4608/8000 (58%)]\tTotal Loss: 0.086344\n",
      "Reconstruction: 0.086343, Regularization: 0.000000\n",
      "2019-04-09 23:40:51,019 root         INFO     Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 0.095868\n",
      "Reconstruction: 0.095867, Regularization: 0.000001\n",
      "2019-04-09 23:40:51,081 root         INFO     Train Epoch: 194 [5632/8000 (70%)]\tTotal Loss: 0.086510\n",
      "Reconstruction: 0.086510, Regularization: 0.000000\n",
      "2019-04-09 23:40:51,142 root         INFO     Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 0.091482\n",
      "Reconstruction: 0.091482, Regularization: 0.000000\n",
      "2019-04-09 23:40:51,203 root         INFO     Train Epoch: 194 [6656/8000 (83%)]\tTotal Loss: 0.088904\n",
      "Reconstruction: 0.088904, Regularization: 0.000000\n",
      "2019-04-09 23:40:51,264 root         INFO     Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 0.089085\n",
      "Reconstruction: 0.089085, Regularization: 0.000000\n",
      "2019-04-09 23:40:51,326 root         INFO     Train Epoch: 194 [7680/8000 (96%)]\tTotal Loss: 0.078761\n",
      "Reconstruction: 0.078761, Regularization: 0.000000\n",
      "2019-04-09 23:40:51,379 root         INFO     ====> Epoch: 194 Average loss: 0.0887\n",
      "2019-04-09 23:40:51,402 root         INFO     Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 0.095716\n",
      "Reconstruction: 0.095716, Regularization: 0.000000\n",
      "2019-04-09 23:40:51,465 root         INFO     Train Epoch: 195 [512/8000 (6%)]\tTotal Loss: 0.092595\n",
      "Reconstruction: 0.092595, Regularization: 0.000000\n",
      "2019-04-09 23:40:51,528 root         INFO     Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 0.096833\n",
      "Reconstruction: 0.096833, Regularization: 0.000000\n",
      "2019-04-09 23:40:51,590 root         INFO     Train Epoch: 195 [1536/8000 (19%)]\tTotal Loss: 0.092020\n",
      "Reconstruction: 0.092020, Regularization: 0.000000\n",
      "2019-04-09 23:40:51,651 root         INFO     Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 0.087783\n",
      "Reconstruction: 0.087782, Regularization: 0.000000\n",
      "2019-04-09 23:40:51,712 root         INFO     Train Epoch: 195 [2560/8000 (32%)]\tTotal Loss: 0.085708\n",
      "Reconstruction: 0.085707, Regularization: 0.000001\n",
      "2019-04-09 23:40:51,774 root         INFO     Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 0.085304\n",
      "Reconstruction: 0.085302, Regularization: 0.000001\n",
      "2019-04-09 23:40:51,835 root         INFO     Train Epoch: 195 [3584/8000 (45%)]\tTotal Loss: 0.096004\n",
      "Reconstruction: 0.096003, Regularization: 0.000002\n",
      "2019-04-09 23:40:51,896 root         INFO     Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 0.090797\n",
      "Reconstruction: 0.090795, Regularization: 0.000002\n",
      "2019-04-09 23:40:51,956 root         INFO     Train Epoch: 195 [4608/8000 (58%)]\tTotal Loss: 0.078009\n",
      "Reconstruction: 0.078008, Regularization: 0.000001\n",
      "2019-04-09 23:40:52,017 root         INFO     Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 0.088689\n",
      "Reconstruction: 0.088688, Regularization: 0.000001\n",
      "2019-04-09 23:40:52,079 root         INFO     Train Epoch: 195 [5632/8000 (70%)]\tTotal Loss: 0.083910\n",
      "Reconstruction: 0.083910, Regularization: 0.000001\n",
      "2019-04-09 23:40:52,140 root         INFO     Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 0.089826\n",
      "Reconstruction: 0.089826, Regularization: 0.000000\n",
      "2019-04-09 23:40:52,201 root         INFO     Train Epoch: 195 [6656/8000 (83%)]\tTotal Loss: 0.089023\n",
      "Reconstruction: 0.089023, Regularization: 0.000000\n",
      "2019-04-09 23:40:52,263 root         INFO     Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 0.096212\n",
      "Reconstruction: 0.096212, Regularization: 0.000000\n",
      "2019-04-09 23:40:52,324 root         INFO     Train Epoch: 195 [7680/8000 (96%)]\tTotal Loss: 0.095679\n",
      "Reconstruction: 0.095679, Regularization: 0.000000\n",
      "2019-04-09 23:40:52,378 root         INFO     ====> Epoch: 195 Average loss: 0.0887\n",
      "2019-04-09 23:40:52,402 root         INFO     Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 0.083942\n",
      "Reconstruction: 0.083942, Regularization: 0.000000\n",
      "2019-04-09 23:40:52,464 root         INFO     Train Epoch: 196 [512/8000 (6%)]\tTotal Loss: 0.085066\n",
      "Reconstruction: 0.085066, Regularization: 0.000000\n",
      "2019-04-09 23:40:52,526 root         INFO     Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 0.086013\n",
      "Reconstruction: 0.086012, Regularization: 0.000000\n",
      "2019-04-09 23:40:52,589 root         INFO     Train Epoch: 196 [1536/8000 (19%)]\tTotal Loss: 0.092435\n",
      "Reconstruction: 0.092434, Regularization: 0.000000\n",
      "2019-04-09 23:40:52,651 root         INFO     Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 0.087051\n",
      "Reconstruction: 0.087051, Regularization: 0.000000\n",
      "2019-04-09 23:40:52,713 root         INFO     Train Epoch: 196 [2560/8000 (32%)]\tTotal Loss: 0.075507\n",
      "Reconstruction: 0.075507, Regularization: 0.000000\n",
      "2019-04-09 23:40:52,775 root         INFO     Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 0.088668\n",
      "Reconstruction: 0.088667, Regularization: 0.000000\n",
      "2019-04-09 23:40:52,837 root         INFO     Train Epoch: 196 [3584/8000 (45%)]\tTotal Loss: 0.091743\n",
      "Reconstruction: 0.091743, Regularization: 0.000000\n",
      "2019-04-09 23:40:52,898 root         INFO     Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 0.086395\n",
      "Reconstruction: 0.086395, Regularization: 0.000000\n",
      "2019-04-09 23:40:52,959 root         INFO     Train Epoch: 196 [4608/8000 (58%)]\tTotal Loss: 0.084933\n",
      "Reconstruction: 0.084933, Regularization: 0.000000\n",
      "2019-04-09 23:40:53,020 root         INFO     Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 0.081374\n",
      "Reconstruction: 0.081374, Regularization: 0.000000\n",
      "2019-04-09 23:40:53,081 root         INFO     Train Epoch: 196 [5632/8000 (70%)]\tTotal Loss: 0.086775\n",
      "Reconstruction: 0.086775, Regularization: 0.000000\n",
      "2019-04-09 23:40:53,143 root         INFO     Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 0.091378\n",
      "Reconstruction: 0.091378, Regularization: 0.000000\n",
      "2019-04-09 23:40:53,204 root         INFO     Train Epoch: 196 [6656/8000 (83%)]\tTotal Loss: 0.084686\n",
      "Reconstruction: 0.084685, Regularization: 0.000000\n",
      "2019-04-09 23:40:53,265 root         INFO     Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 0.094086\n",
      "Reconstruction: 0.094086, Regularization: 0.000000\n",
      "2019-04-09 23:40:53,326 root         INFO     Train Epoch: 196 [7680/8000 (96%)]\tTotal Loss: 0.096784\n",
      "Reconstruction: 0.096784, Regularization: 0.000000\n",
      "2019-04-09 23:40:53,378 root         INFO     ====> Epoch: 196 Average loss: 0.0887\n",
      "2019-04-09 23:40:53,402 root         INFO     Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 0.085139\n",
      "Reconstruction: 0.085139, Regularization: 0.000000\n",
      "2019-04-09 23:40:53,465 root         INFO     Train Epoch: 197 [512/8000 (6%)]\tTotal Loss: 0.089325\n",
      "Reconstruction: 0.089325, Regularization: 0.000000\n",
      "2019-04-09 23:40:53,526 root         INFO     Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 0.089239\n",
      "Reconstruction: 0.089239, Regularization: 0.000001\n",
      "2019-04-09 23:40:53,589 root         INFO     Train Epoch: 197 [1536/8000 (19%)]\tTotal Loss: 0.085201\n",
      "Reconstruction: 0.085201, Regularization: 0.000000\n",
      "2019-04-09 23:40:53,651 root         INFO     Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 0.084846\n",
      "Reconstruction: 0.084846, Regularization: 0.000000\n",
      "2019-04-09 23:40:53,713 root         INFO     Train Epoch: 197 [2560/8000 (32%)]\tTotal Loss: 0.086524\n",
      "Reconstruction: 0.086524, Regularization: 0.000000\n",
      "2019-04-09 23:40:53,774 root         INFO     Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 0.082697\n",
      "Reconstruction: 0.082697, Regularization: 0.000000\n",
      "2019-04-09 23:40:53,836 root         INFO     Train Epoch: 197 [3584/8000 (45%)]\tTotal Loss: 0.079786\n",
      "Reconstruction: 0.079786, Regularization: 0.000000\n",
      "2019-04-09 23:40:53,898 root         INFO     Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 0.093537\n",
      "Reconstruction: 0.093537, Regularization: 0.000000\n",
      "2019-04-09 23:40:53,960 root         INFO     Train Epoch: 197 [4608/8000 (58%)]\tTotal Loss: 0.079036\n",
      "Reconstruction: 0.079036, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,022 root         INFO     Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 0.086041\n",
      "Reconstruction: 0.086041, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,084 root         INFO     Train Epoch: 197 [5632/8000 (70%)]\tTotal Loss: 0.091382\n",
      "Reconstruction: 0.091381, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,145 root         INFO     Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 0.078694\n",
      "Reconstruction: 0.078694, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,208 root         INFO     Train Epoch: 197 [6656/8000 (83%)]\tTotal Loss: 0.082378\n",
      "Reconstruction: 0.082378, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,269 root         INFO     Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 0.084063\n",
      "Reconstruction: 0.084063, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,331 root         INFO     Train Epoch: 197 [7680/8000 (96%)]\tTotal Loss: 0.085425\n",
      "Reconstruction: 0.085425, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,384 root         INFO     ====> Epoch: 197 Average loss: 0.0887\n",
      "2019-04-09 23:40:54,408 root         INFO     Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 0.093481\n",
      "Reconstruction: 0.093481, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,471 root         INFO     Train Epoch: 198 [512/8000 (6%)]\tTotal Loss: 0.086472\n",
      "Reconstruction: 0.086472, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,534 root         INFO     Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.094135\n",
      "Reconstruction: 0.094135, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,596 root         INFO     Train Epoch: 198 [1536/8000 (19%)]\tTotal Loss: 0.087943\n",
      "Reconstruction: 0.087943, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,659 root         INFO     Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 0.082420\n",
      "Reconstruction: 0.082420, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,721 root         INFO     Train Epoch: 198 [2560/8000 (32%)]\tTotal Loss: 0.086452\n",
      "Reconstruction: 0.086452, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,784 root         INFO     Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 0.087606\n",
      "Reconstruction: 0.087606, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,846 root         INFO     Train Epoch: 198 [3584/8000 (45%)]\tTotal Loss: 0.083908\n",
      "Reconstruction: 0.083908, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,909 root         INFO     Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 0.083226\n",
      "Reconstruction: 0.083226, Regularization: 0.000000\n",
      "2019-04-09 23:40:54,972 root         INFO     Train Epoch: 198 [4608/8000 (58%)]\tTotal Loss: 0.090583\n",
      "Reconstruction: 0.090583, Regularization: 0.000000\n",
      "2019-04-09 23:40:55,034 root         INFO     Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 0.088959\n",
      "Reconstruction: 0.088959, Regularization: 0.000000\n",
      "2019-04-09 23:40:55,096 root         INFO     Train Epoch: 198 [5632/8000 (70%)]\tTotal Loss: 0.078838\n",
      "Reconstruction: 0.078838, Regularization: 0.000000\n",
      "2019-04-09 23:40:55,159 root         INFO     Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 0.088646\n",
      "Reconstruction: 0.088646, Regularization: 0.000000\n",
      "2019-04-09 23:40:55,221 root         INFO     Train Epoch: 198 [6656/8000 (83%)]\tTotal Loss: 0.085738\n",
      "Reconstruction: 0.085738, Regularization: 0.000000\n",
      "2019-04-09 23:40:55,284 root         INFO     Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 0.088010\n",
      "Reconstruction: 0.088009, Regularization: 0.000000\n",
      "2019-04-09 23:40:55,346 root         INFO     Train Epoch: 198 [7680/8000 (96%)]\tTotal Loss: 0.084828\n",
      "Reconstruction: 0.084828, Regularization: 0.000000\n",
      "2019-04-09 23:40:55,399 root         INFO     ====> Epoch: 198 Average loss: 0.0887\n",
      "2019-04-09 23:40:55,423 root         INFO     Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 0.095664\n",
      "Reconstruction: 0.095664, Regularization: 0.000000\n",
      "2019-04-09 23:40:55,486 root         INFO     Train Epoch: 199 [512/8000 (6%)]\tTotal Loss: 0.085972\n",
      "Reconstruction: 0.085972, Regularization: 0.000000\n",
      "2019-04-09 23:40:55,548 root         INFO     Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 0.095379\n",
      "Reconstruction: 0.095379, Regularization: 0.000000\n",
      "2019-04-09 23:40:55,610 root         INFO     Train Epoch: 199 [1536/8000 (19%)]\tTotal Loss: 0.076463\n",
      "Reconstruction: 0.076463, Regularization: 0.000000\n",
      "2019-04-09 23:40:55,673 root         INFO     Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 0.090596\n",
      "Reconstruction: 0.090596, Regularization: 0.000000\n",
      "2019-04-09 23:40:55,736 root         INFO     Train Epoch: 199 [2560/8000 (32%)]\tTotal Loss: 0.092794\n",
      "Reconstruction: 0.092794, Regularization: 0.000000\n",
      "2019-04-09 23:40:55,799 root         INFO     Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 0.085940\n",
      "Reconstruction: 0.085940, Regularization: 0.000000\n",
      "2019-04-09 23:40:55,864 root         INFO     Train Epoch: 199 [3584/8000 (45%)]\tTotal Loss: 0.092351\n",
      "Reconstruction: 0.092351, Regularization: 0.000000\n",
      "2019-04-09 23:40:55,930 root         INFO     Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 0.088888\n",
      "Reconstruction: 0.088888, Regularization: 0.000001\n",
      "2019-04-09 23:40:55,995 root         INFO     Train Epoch: 199 [4608/8000 (58%)]\tTotal Loss: 0.092484\n",
      "Reconstruction: 0.092483, Regularization: 0.000001\n",
      "2019-04-09 23:40:56,060 root         INFO     Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 0.084555\n",
      "Reconstruction: 0.084554, Regularization: 0.000001\n",
      "2019-04-09 23:40:56,126 root         INFO     Train Epoch: 199 [5632/8000 (70%)]\tTotal Loss: 0.082077\n",
      "Reconstruction: 0.082076, Regularization: 0.000001\n",
      "2019-04-09 23:40:56,191 root         INFO     Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.085225\n",
      "Reconstruction: 0.085225, Regularization: 0.000001\n",
      "2019-04-09 23:40:56,257 root         INFO     Train Epoch: 199 [6656/8000 (83%)]\tTotal Loss: 0.083319\n",
      "Reconstruction: 0.083318, Regularization: 0.000001\n",
      "2019-04-09 23:40:56,321 root         INFO     Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 0.085306\n",
      "Reconstruction: 0.085305, Regularization: 0.000001\n",
      "2019-04-09 23:40:56,386 root         INFO     Train Epoch: 199 [7680/8000 (96%)]\tTotal Loss: 0.083944\n",
      "Reconstruction: 0.083943, Regularization: 0.000002\n",
      "2019-04-09 23:40:56,440 root         INFO     ====> Epoch: 199 Average loss: 0.0887\n",
      "2019-04-09 23:40:56,448 luigi-interface INFO     [pid 19881] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=19881) done      TrainVAE()\n",
      "2019-04-09 23:40:56,448 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 23:40:56,449 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   DONE\n",
      "2019-04-09 23:40:56,449 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 23:40:56,449 luigi-interface DEBUG    Pending tasks: 1\n",
      "2019-04-09 23:40:56,449 luigi-interface INFO     [pid 19881] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=19881) running   RunAll()\n",
      "2019-04-09 23:40:56,449 luigi-interface INFO     [pid 19881] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=19881) done      RunAll()\n",
      "2019-04-09 23:40:56,450 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 23:40:56,450 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   DONE\n",
      "2019-04-09 23:40:56,450 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 23:40:56,450 luigi-interface DEBUG    Done\n",
      "2019-04-09 23:40:56,450 luigi-interface DEBUG    There are no more tasks to run at this time\n",
      "2019-04-09 23:40:56,450 luigi-interface INFO     Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=19881) was stopped. Shutting down Keep-Alive thread\n",
      "2019-04-09 23:40:56,451 luigi-interface INFO     \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 4 tasks of which:\n",
      "* 4 ran successfully:\n",
      "    - 1 MakeDataSet()\n",
      "    - 1 RunAll()\n",
      "    - 1 TrainVAE()\n",
      "    - 1 TrainVEM()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pattern = 'logs'\n",
    "logs = []\n",
    "for filename in os.listdir(OUTPUT):\n",
    "    if re.search(pattern, filename):\n",
    "        logs.append(filename)\n",
    "\n",
    "print('Found %d log files.' % len(logs))\n",
    "        \n",
    "for filename in logs:\n",
    "    path = os.path.join(OUTPUT, filename)\n",
    "    print('\\n-- Log file: %s\\n' % filename)\n",
    "    with open(path, 'r') as f:\n",
    "        message = f.read()\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
