{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import importlib\n",
    "import toylosses\n",
    "importlib.reload(toylosses)\n",
    "import toynn\n",
    "importlib.reload(toynn)\n",
    "import toyvis\n",
    "importlib.reload(toyvis)\n",
    "\n",
    "import torch\n",
    "sns.set()\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "OUTPUT = '/scratch/users/nmiolane/toyoutput'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide on experiment's configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.563953742650922,\n",
       " 10.594000468888417,\n",
       " -10.225683040149995,\n",
       " 7.333276314998985)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_DIM = 2\n",
    "LATENT_DIM = 1\n",
    "N_DECODER_LAYERS = 2\n",
    "NONLINEARITY = False\n",
    "N_SAMPLES = 10000\n",
    "WITH_BIASX = True\n",
    "WITH_LOGVARX = True\n",
    "\n",
    "W_TRUE = {}\n",
    "B_TRUE = {}\n",
    "\n",
    "W_TRUE[0] = [[1.], [-1.]]\n",
    "B_TRUE[0] = [0., -1.]\n",
    "\n",
    "# For the reconstruction\n",
    "W_TRUE[1] = [[1., -1.], [-1., 1.]]\n",
    "B_TRUE[1] = [1., 0.]\n",
    "\n",
    "# For the logvarx\n",
    "W_TRUE[2] = [[0., 0.], [0., 0.]]\n",
    "B_TRUE[2] = [0., 0.]\n",
    "\n",
    "if WITH_LOGVARX:\n",
    "    assert len(W_TRUE) == N_DECODER_LAYERS + 1\n",
    "else:\n",
    "    assert len(W_TRUE) == N_DECODER_LAYERS\n",
    "\n",
    "WITH_BIASZ = True\n",
    "WITH_LOGVARZ = True\n",
    "\n",
    "decoder_true = toynn.make_decoder_true(\n",
    "    w_true=W_TRUE, b_true=B_TRUE, latent_dim=LATENT_DIM, \n",
    "    data_dim=DATA_DIM, n_layers=N_DECODER_LAYERS,\n",
    "    nonlinearity=NONLINEARITY, with_biasx=WITH_BIASX, with_logvarx=WITH_LOGVARX)\n",
    "\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, N_SAMPLES)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = toyvis.plot_data(generated_true_x, color='green', label='from decoder true', ax=ax)\n",
    "ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect generation of synthetic data from decoder_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight tensor([[ 1.],\n",
      "        [-1.]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0., -1.], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 1., -1.],\n",
      "        [-1.,  1.]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([1., 0.], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0., 0.], device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(nina): Add a comparison to a FA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results from standard VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[ 1.],\n",
      "        [-1.]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0., -1.], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 1., -1.],\n",
      "        [-1.,  1.]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([1., 0.], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0., 0.], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[-0.9087],\n",
      "        [-0.7535]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([-0.8474, -0.8034], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[-1.4454, -0.7546],\n",
      "        [ 0.7309,  1.7251]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([0.2081, 0.9557], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 0.9867, -1.1876],\n",
      "        [-0.4921,  0.6541]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([ 0.0839, -0.0275], device='cuda:0') \n",
      "\n",
      "Last losses:\n",
      "[0.12270733362436295, 0.1224738909304142, 0.12270222470164299, 0.12261139038205147, 0.12274660050868988]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "decoder_path = glob.glob(f'{OUTPUT}/train_vae/models/decoder.pth')[0]\n",
    "decoder = torch.load(decoder_path, map_location=DEVICE)\n",
    "\n",
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "losses_vae_path = glob.glob(f'{OUTPUT}/train_vae/train_losses.pkl')[0]\n",
    "train_losses_all_epochs = pickle.load(open(losses_vae_path, 'rb'))\n",
    "\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 4))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(range(n_epochs), train_losses_total)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(range(90, n_epochs), train_losses_total[90:])\n",
    "\n",
    "ax = axes[2]\n",
    "ax.plot(range(160, n_epochs), train_losses_total[160:])\n",
    "\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.7177698210131105,\n",
       " 10.423648551978268,\n",
       " -8.289101585396416,\n",
       " 7.830095436650975)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "\n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)\n",
    "ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results from VEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[ 1.],\n",
      "        [-1.]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0., -1.], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 1., -1.],\n",
      "        [-1.,  1.]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([1., 0.], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0., 0.], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[ 0.0951],\n",
      "        [-0.1564]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0.5625, -1.2811], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 0.0191, -1.0750],\n",
      "        [-0.9462,  0.0215]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([ 0.6573, -0.5549], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[-0.7531, -0.6405],\n",
      "        [ 0.4120,  0.3713]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0.0504, 0.3872], device='cuda:0') \n",
      "\n",
      "Last losses:\n",
      "[0.2445923548936844, 0.2446701561808586, 0.24467400634288788, 0.24451486265659333, 0.24435074037313462]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "decoder_path = glob.glob(f'{OUTPUT}/train_vem/models/decoder.pth')[0]\n",
    "decoder = torch.load(decoder_path, map_location=DEVICE)\n",
    "\n",
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "losses_vae_path = glob.glob(f'{OUTPUT}/train_vem/train_losses.pkl')[0]\n",
    "train_losses_all_epochs = pickle.load(open(losses_vae_path, 'rb'))\n",
    "\n",
    "plt.figure()\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "plt.plot(range(n_epochs), train_losses_total)\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.816312599174317, 9.246898963473779, -7.944190882133851, 6.029284965477779)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6oAAAEBCAYAAABxOFgaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsvXt8VOW1///ee88lySSZXCAkoAYR1GO1UuuvsQoqYKtV2gSsB461jRTbChVtKpRSlFIs2hyx8VIjXy3GHOtRq9wqWm3lJqDktLW0VauiwSjCCCQwSSaXuez9+2Myk0xmT66TZBLW+/XyhZnMPHvNTGbNZz3PuiiGYRgIgiAIgiAIgiAIQoKgDrUBgiAIgiAIgiAIgtARCVQFQRAEQRAEQRCEhEICVUEQBEEQBEEQBCGhkEBVEARBEARBEARBSCgkUBUEQRAEQRAEQRASCglUBUEQBEEQBEEQhIRCAlVBEARBEARBEAQhoZBAVRAEQRAEQRAEQUgoJFAVBEEQBEEQBEEQEgpLvBZqbW3l7rvv5o033sButzN58mTuuuuueC0vCIIgCIIgDBKi6wRBGGriFqjee++92O12XnnlFRRF4dixY/FaWhAEQRAEQRhERNcJgjDUKIZhGP1dxOPxcNlll7Fz504cDkc87BIEQRAEQRCGANF1giAkAnE5Uf3kk0/IyMjgN7/5DVVVVTgcDm677TYuvPDCeCwvCIKQMCxcuJCDBw+iqiopKSnceeed/Md//MdQmyUIghA3RNcJgpAIxCVQ9fv9fPLJJ5xzzjksXbqUf/zjH9x88838+c9/JjU1tUdrHD/uQdf7fbjbb7KzU6mtbRxqM6JIVLtAbOsrYlvXqKpCZmbi7eSXlpaSlpYGwKuvvsrPfvYzNm7c2OPHD7SvS4T3biAYqc8LRu5zG6nPC+L73BLR14muGxzEtt6TqHaB2NYdffF1cQlUx44di8ViYebMmQCcf/75ZGZmcuDAAc4777weraHrRkI4NCBh7OhMotoFYltfEduGH6EgFaCxsRFFUXr1+MHwdSP1vRupzwtG7nMbqc8LRvZzE103eIhtvSdR7QKxLd7EJVDNysqioKCAPXv2MGXKFA4cOEBtbS35+fnxWF4QBCGhWL58OXv27MEwDH77298OtTmCIAhxRXSdIAiJQFyaKUGwnuFnP/sZJ06cwGKx8KMf/YjLLrusx4+vrW1MiEh/9Og0jh5tGGozokhUu0Bs6ytiW9eoqkJ2ds9SzIaKTZs28eKLL/LYY48NtSmCIAhxRXTdwCO29Z5EtQvEtu7oi66L23iaU089lSeffDJeywmCICQ8RUVFrFixguPHj5OZmdmjxwy0eEuEL6OBYKQ+Lxi5z22kPi+I73NL1E050XWCIAw16lAbIAiCMFzweDwcPnw4/PO2bdtwOp1kZGQMoVWCIAiCIAgjj7idqA4lmqbgMdz4Al6smg2H4iQQGPp0E0EQRhbNzc3cdtttNDc3o6oqTqeTtWvX9rqhkiD0BIumkGpxo+JFx0aj34lfvtuEkwDRdYIgwAgIVDVN4ePGDygqL6Kmtob87Hw2LdzEaakTxakJghBXRo0axe9///uhNkM4CbBoCk7jA9TtReCpQXPk45yyCbc2UYJVYUQjuk4QhBDDPvXXY7jDzgygpraGovIiPIZ7iC0TBEEQhL6RanGj7g4GqQB4alB3F5Fqke82YWQjuk4QhBDDPlD1BbxhZxaiprYGf8A3RBYJgiAIQv9Q8bYHqSE8NajId5swshFdJwhCiGEfqFo1G/nZkXO98rPzsWjWIbJIEARBEPqHjg0cnWZWOvLRke82YWQjuk4QhBDDPlB1KE42LdwUdmqhWgaH4hxiywRBEAShbzT6nehTNrUHq4589CmbaPTLd5swshFdJwhCiGHfTCkQMDgtdSK7luzBH/Bh0azSHU4QBEEY1vgDBm5tIqnT9qDiQ8cqXX+FkwLRdYIghBj2gSoEnVoS6aAAOgQQZyYIgiAMb/wBgxOB9A63yHebcHIguk4QBBghgWp/6DyrS9cdfXqc7PYJgiAIgiAMLaLrBGHkcFIHqmazujb/cDOnOs7o0jnJjC9BEARhoLFoSnBMDV50bJL6KwjdILpOEEYWw76ZUn8wm9VV+HBht7O6ZMaXIAiCMJBYNAWn8QHW7ZegbZmAdfslOI0PsGjKUJsmCAmL6DpBGFmc1IFqX2d1yYwvQRAEYSBJtbhRdxe1z1L11KDuLiLVIsJZEGIhuk4QRhYndaDa11ldMuOrf2iaQotaT4NxjBa1Hk1OCARBECJQ8bYHqSE8NaiIcBaEWIiuGxpE1wkDxUkdqJrN6tr8w83dzuqSGV99J1QHMvXeSzhj+QSm3nsJHzd+IE5NEAShAzq29hmqIRz56IhwFoRYiK4bfETXCQPJSd1MyWxW17jMPGprPb1+3FB1hxtuXepi1YHsWrIn2IpeEARBoNHvxDllU3v6ryMffcomGv1OZEyNIJgjum7wEV0nDCQndaAK0bO6VLVnh8yJMONrOHap67IORDbfBEEQgOAMVbc2kdRpe1DxoWOVrr+C0ANE1w0uouuEgeSkTv3tD4mQj9+bLnWJYC9IHYggCEJP8QcMTrSmU9eazYnWdAlSBWEASQSdJLpOECKRQLUPJEo+fk+71CWKvSB1IIIgCIIgJBaJopNE1wlCJBKo9oFEmbfV012sRLEXIutAqlcfYNeSPQmd0iIIgiAIwsgmUXSS6DpBiEQC1T6QKPO2erqLFW97O6eb6Lreq8cHAgZJejqpSjZJero4M0EQBEEQhoyTXddB/7Sd6DphoDjpmyn1hdCOV0cnEd7x6l3MFqYvXd562qUunvaaFfpv/uFmTnWcIY5JEARBEIRhx8ms60K2irYTEpG4n6j+5je/4ayzzuL999+P99KDTqxC9Xjn4/en1qAnu1jxtNcs3aTw4cIhSTcRhMHm+PHjfO973+PKK6/k61//Orfccgt1dXVDbZYgCMKAIbqub9cZLroORNsJiUtcT1Tffvtt9u3bx9ixY+O57JDQXYvweMzbCu22ef2tHHIfIteZS01tTbczqHq7S9dfeztezwgY0oZcOGlRFIWbbrqJgoICAEpLS1mzZg133333EFsmCIIQf0TXjUxd1/maou2ERCVuJ6per5dVq1bx85//HEUZ/n/V3RWq9zcfv+Nu28TlZ7DwqYWsLlpNwYSC8PX8AV9496+mtoYWtR6rVe3TLl1f7e28K/jeZ+9KG3LhpCUjIyMcpAJMnjyZQ4cODaFFgiAIA4PouoHVdQ3GMVxu16Drus62irYTEpm4nag+8MADfOMb3+DUU0/t0+Ozs1PjZUq/GT06jZraOtPdJR0/o0en9fsaLrcr7DALJhSw9KqlJFmTeLz4cb5b+V1cbhepSQ4+cX9I4cOF4d2/rbdvNXW0e5ftJTcrt992dWUnwKotq6i4sYJ5T8yLqGMYl5nX46Hag0083q+BQmwbvui6ztNPP8306dN79bjB8HUj9b0bPcoBLUdAbwXVDkk5oCSm3+ktI/Y9G6HPC0b2cwPRdb1luOi6zrbC8NN2ifzZE9viS1wC1b///e/861//YvHixX1eo7a2EV0f+oLt0aPTOHq0AVW1mBaqq1g4erSh39dpMprDzmx10WrmV84PO4eKGyvIc+bR6vOGnRkEnZfL7TJ1tM2tLXGxK5adIaqqq1i2cRk7F+9E1w0smpVxmXnU1nrifu14EHo/ExGxrWtUVUkoodOZu+66i5SUFG644YZePW6gfV0ivHcDwehRDvS6f6LuLgJPDTjy0adswq1MxD/Mm32M2PdshD4viO9zS0RfJ7qu9wwXXdfR1hDDSdslsl8R27qmL74uLtskf/nLX6iurmbGjBlMnz4dl8vF/Pnz2b17dzyWHxIGeoBxqGPb0quWhp0ZBJ3TvCfmkWJLoTXQEuW8jjQcGdT0DLOZXi63C1WxhNNNEnG3TRAGktLSUmpqarj//vvl73+waDnSHqQCeGpQdxeRapFmH4IQb0TX9Z7hous62toR0XZCIhKXE9Xvf//7fP/73w//PH36dNauXcuZZ54Zj+WHhHgV1sci5DA9Xo/pTtonxz8JO6+Ov698vZKNCzcyq3xWRDMAh+IkQPx3LkN2dm4+MFDXE4REp6ysjLfeeotHH30Um8021OacPOit7UFqCE8NKoM757C3WDSFVIsbFS86Nhr9zmF/AiyMfETX9Z7hous62iraTkh0ZI5qFwQCRrA7mwLoxPXDG3KYjUadaSrKkYYjlL5cyrridRHpIyu/vpLx6ZMGzNHGsnOwricIicz+/ftZu3Yt48ePZ+7cuQCccsopPPzww0Ns2UmAagdHfmSw6shHJ3GbfVg0BafxAer24Emw5sjHOWUTbm34pysLwnBEdF2kraLthERHMQwjIf4qE62WYbAwa5e+rngdyzctp6q6KlyQ//lTPo9NTUoYR9KxrXmKPZkkI42GwIleDbYeDBIhJz8WYlvXJGLdVjyQGtW+MRxrVDPs9Vi3XxIVXPum7eFEa/uIiqF6zwb6tHek/i3CyK9RjQei67rRdeM+j8PuwBZITQi91HlETp5zDIfdn4mu6wViW9f0xdfJiWoX9HauVV/ovKulaSq3PnMrVdVVQLDAveTZEvYu24vmdSRESoaZE16/YD13bbmLzfs2R80mEwTh5CPuQZCi4lYmkjptDyo+dKwJn0ar4k3YdGU57RVORhJJ1+1asodcZ+6QBw9grus2LNjAqi2rRNcJQ4pUSseg84ypns616gsdZ2GlKlms/PrKqGL/nLScPq/fcWZXi1rf4+cQ63Fms8iufeRaii8uDv/ccTZZf2wQBGH4EQqCrNsvQdsyAev2S3AaH2Dp5+feHzA40ZpOXWs2J1rTEz6g0rEF05U7kiDpyqkWtzSnEk4qEk3X9aeJU380ldljzXTd7Edmi64Thhw5UY1BrMHQu5bsCdY3DBCx6gb62n3NbJesJ7tiXT3O5/eaNgrISsmK+Nkf8IHSdxsEQRiepFrc4ZM6oD0ImraHE4GB85+JRqPfiXPKpqh05Ua/E4Y4OyaRT3sFYSBINF3XV/3TH00V67HO5AzRdUJCIieqMfAFzIMxf2Dgv8Q77sQl6en9+tCbOeaVL6yk0aiL2AXrvDPWqnhMHbrHcJu2Nc/PzqeuqS7i51Br9VhfDh135gRBGDlIEBTEHzBwKxPxTdtDYOYBfNP2JExNbSKf9grCQHCy6TqIPvWMpe00VRVdJyQkEqjGIFYwNpBzreJBZ6cERoRjLphQwKLpi7j03kvDqS9HWg9GpcO46g+R68yNWDvk0M1mka1fsJ7K1yvDP3dMaxnKLwdBEAYfCYLaSdR05Ua/E33Kpvb3KeK0VxBGHieTrvu48QOsVrXH2k5Fi9J1GxZsEF0nDDkSqMZgoAdDDwRm9RfHPEcpnFwYvo/ZIOrqY9VRO2OzHpnFipkrItYPOfSOaSzVqw+wd9leznCezUNzH6Z69QF2LdkTkf4xXL8cBEHoGxIE9QyLppBhrwdPDRn2+n7X8PaGRD7tFYSB4GTSdUXlRdQHanus7QyI0HW7luzh8+M+L7pOGHKkRjUGAzVjqruOc/3pSGeWijGrfBZbf7yVfZ/sI9eZy7ljz6VyXiV1TXWUvlxKVXUVDpvDdGfszDFnhmeBdR4G3XEW2WhnsOV1rNlkMlhaEE4u/AEDtza8OvQONp277lqHoOuuP2B0qhmW90cYuZxMuq6mtgZfwGeq7SblTDLXdp1mzFosFpJ00XXC0CKBahfEezB0d8XnXf2+J8RKxVAVjTeWVuGqP8RXyr4SNdfL4/WYDqdWUHhjaRUtvuYIh97Z6eq6o0u7AgGD8emTeG3Ja/gCPqyalXQtG59P7/2LKAjCsECCoK5JtbhR/74SLigDWxZ461DfWknqFx7ud8OpgZ6PKgjDlUTSdT0JVvuq61xuF1bNaqrtkq0O02C9N9pOdJ0wWEjq7yDSXfF5f4vTY6ZiqFb8up9Zj8yKWHt+5XxWzFzBhFET2LhwY0Q6zLriddz+3O34dX9E8b9ZGsq/Pv1Xl23JNU3ho/r9XHrvpUxcPpFL772Uj+r3SytzQRBOWlTVgLMWwZslsPXy4L9nLaKPDd7DDNRooI7rZ9jrybIfG/R0ZUFINBJV121auIkkSwoVN1ZEaLuKGyvQFC2qsVNvtZ3oOmGwkEB1EOmu+Ly/xeld1V/EWvvs3LPJsZ/CKMdoyuaUsWPxDsrmlLF803I279scdW0zp1v4cCGNRl1MBxXLUXf1GEEQhHiQqIGVgg5V8yNG+FA1H4VAv9YdyPmoAx0EC8JwI1F13WmpE2lsbWDZxmUR2m7ZxmW0+JqjrhNL2zXFCKhF1wmDhaT+DiKhnbHOaRgWzQp6N7/vAV3VX8Ra26rag+knqkLJsyUxbQsRyzF+cvwTHLY603SWvjwmRE9rO/pTAyIIwuAxmGmpnetAtSGoA42FoeumI3wMvX+pcwM5Gkjm4wpCJP3SdT34qPdH11k1Gy63i9nls7u9diyd1uxvIsUaraf6o+ugZ5pN0xR8qgen2oKFAIZip9GXuI2vhIFBTlQHke46zsWjI12sWV1pWgbrF6yPGimTpmX06tqx0lBGp47mkPsQrYonyqZYjznScKTLFBizVJSPGz+I2q3r6f0EQRhaBvtErieni0N14qpj7fEIn97YOJCjgWQ+riBEMhJ0HcTWaX7dH1ddBz3TbJqmcKz1IJbGd0jafhmWLWdg3XYJTj4AQ+pgTyYUwzAS4tiptrYRXR96U0aPDnaw7Q9d7RSFfher41ys3/fXrha1nkXP/JDii4vJc+aRnpSON+AlKyWLdC2bhsAJwMBAJ6DrWFTzAnubZqPR28BVD1wVLt6vuLGCZRuX4XK72LhgI/lpk6KeU+dmAqGC/6rqKqpXHyBVyTa1eeq9l0TtFu5asifYia4H9zs1e1y/38+BIh5/awNFItimqgrZ2alDasNAMNC+LhHeu1hk2Ouxbr8kMthx5OObtocTrV2fyPXleWXZj6FtmRB1e2DmAepas9tPXEPBbNsYncEY09LTa/fWxoF8Tr19/xL5b7G/xPO5ia8bWBJV1/XXtnjpOqtmI03L4ID7/XDNa0inPbTtIX4+8+dx03Uhu7vTdi1qPUeO/YMvvrswyt/w1b0cbey6iedQkcg+LxFs64uvk9TfOGO1qhyof59Z5e0f9o4d3rrrOBfvjnQhfAEvm/dtxlXvYnXRauY+OpdcZy4rZq5gYs5EDp84zNINS3G5XT3qWPfG0jdwt7ipPlbNso3LqKquAmDWI7OCzoZ20RJKXXltyWt8cvwTjjQcCTuzrlJguqztUHp4P0EQEobBPpHTsaE58qOETuh0cShTWTuO8LFqfnwBi2kadG9t7O1ooN6kYjf6nTinbIoKgoPzcYc+IBGEgaC7zr2JpOtqamsonFzImuvWcNxznIMnDlL5eiUrv76yW103LuNU/njbH6nz1EXotH2f7IubrgvZ3Z228wW8ZCU5TL8v0FuBxAxUhfgjqb9xRNMUar2ucJAKve/wNlCE0jRCg6FznbmsLlrNwqcWctYdZ1FcUczqotXkOnN71LEuoOtoqsY1D14TDlJDvw8FiJqm0KLW02Acw2O4SdeycdgclDxbEnZmXaXA9HSgtAyeFoThwUCmpZrR6HeiT9nUfs2IwKpngfNApgb7A0bwJNKRz4nWdNMAMaaNKjHtCq1b15odc93Qc+tNKrY/YOBWJuKbtofAzAP4pu3p1Ultoja2EoSuaIqhg2I1GhosOuu6mtoaCiYUsGj6Iq749RV86e4vUfJsCYumL2LlCyu71XVefysW1cKU0inMLp8d1nbx1HUd7e5IZ81m1WzUtXhMvy9Q7f1+7YThgwSqccRjuHHVu4bkdK+j82hR66PqM0O1CjlpOeQ6c3m8+HGSrEmUzSmjYEJBuK350quWRtjr180HRnv1VuwWe0xnY1aD8FH9fsanT2LXkj1Urz7AriV7uiy472l9RTxqQLqiu9dWEISe0V3gGG+6C6y6C5wTocutqY3jClG9RyLsymA/dlvvvtL70iG4p0FwZxLhtRSEvtAaaI2pgwaS3uq6DQs3UHFjBa3+VnKduWE751fOp/ji4m51nU/3YbckDaiu62h3V5rNoThJS59A7RcrIr8vpm6CpJy+vaAdEF03fJDU3zjiC3g50nCkXx3e+kLnNI7CyYXcd919qIoWUZNwWupEWpUG7pl1D1c/eLVpXUFWSla7U1IUdH/A9Pm863qXVVtWUXFjBfOemBeRPuJQnDF37MI1CD1Igemq211f7heP17a3w7oFQWint2mp8bpmZIps+7W6S2WNmXY7ffC63JrZaFxwH8q2GRF2KbtmkTZ9KwFtTI9fz8FMxZaOwcJwRVM1Ux2kKdqAZbz3Rdd11GIddV1NbQ05aTnd6jrdCFDyzI9YV7wufEIbb10HPdNsgYDBKPspYBmFPmMniuHHUKw0BrJJV/p3xia6bnghJ6pxxKrZqHy9knXF6yJ2ijYu3Bi30z0zOjqPUNrHjF/PYMLPTo/ophYIGAR0PezMgIiT1PzsfDxeT9hej+Hm9uduj3o+z938HKu2rKKquoplG5dR/q1yPrz7w4idtHjVjcbqdtfX+/WW/g7rFgQhkr6eyHVFX1NKo05cp+9Bt+eRbjlKhr0+GLCZBHIWo8n0GrHs6E/Kq9mpsG5opnYpLa5ezUsdzFRs6RgsDFfsWhIVN1ZE6KCKGyuwaUkDds146bqQvbnpuV3quo0LN3L7c7ezed9mlm9aTtmcMnYv3c1rS16Lu66Dnmk2BcjwHUTdehnKCxNRt15Kqn9/v7v+iq4bXsiJahxxKE5Wfn0lK19YSdmcsmA6Rnou2bZcfL6Ba6fd0Xl0rFWATjteBDvCmTmanLQcnr/5eRpaGhjtyCEQMPDjCxfql80pIysli7qmOuwWO0uvWhr+edWWVTw9/5mgs2nbSevv7DAgqtuwplpo9jUN6pzUnjZ0Ek4eSktLeeWVV/j000954YUXOPPMM4fapJOa/s5KDZ24du6WqznyMaZvDQZynZoxKQ37SU1LiTgJjGVHo20Sqf79/Zrl2vlUOMNeb9okipYjqPZxMV+nzk2TBrM5UneNrQQhUbEbDvKceZR/qxyHzYHH6yHPmYfdcMStMVJn4qHrQhlyz/3gORzWVAL+2LpuVOooii8upuSKEuqa6ih9uTTcvTegDI2ui5WFwVf30p9mSqLrhhdyohpHQukMD819mMnjvsBpmePJtIwZ0CAVwNahMD0rJStG7UErVquKRdNM6w8yUzK55elbmPfEPAyCzkQ3gukhVdVVzC6fzeVrLqfk2RLsFjslz5aEf75n1j0kWZMj1oxVg5CmZfSoLqBzLcSUey/h3c/e4fp1/zWoc1KlUZPQmRkzZvDUU08xbpx5QCAMLn2ps+zpOsqbt2NM3RhRI0XBOnhrVdRJYEw7tNq42NeRRr/T3K7qyphzWM3qQ4F+NUfqrc2DWZ8sCPEiEDDIsZ/CeWPP57TMfM4bez459lMGdLM8Hrouz5lH2ZwyVr+0Gp/u71LXef3eCF23umg1hZMLI7ROV7WlPan57K2ui5WFQT9rg0XXDS8kUI0z/U1BtVpVmtXj1BtHaFZPELA00WAcw+V2xQ7qVAvrb15P4eRCRqeNNv0Avut6lw/d7/LQtoeiUj4qbqzgu5XfDY+m6S49ZOn6pRE7e/OemIdPb41wUB1rEEIF9uPTJ/FR/f4uhzyHMEvNmPfEvHCzp8FK0xjoRk3C8OPCCy8kLy9vqM1IOOLZ0bU3a8UrpdR0nU83g30MXFgOM3bABWXwj+XQ4ooKCGPZoRjm6cN9TXkNnYzqthyMGTvgyv8L2vXeQ+jnrjQN/LoK5gciFduM/nYMFoShpD/aTtMUWtV66o2jeJQ6DFsrrW1BXSxtFw9d952K71DybAkrv76yR2m/nVOH7597P37d16WuOy11IkBUkyUzbddbXRerNKG/XX9F1w0vFMMwEuJbYiQNhu4rVqvKh+53ufaRa8MF3hU3VrBs47Ko+aYdaTCOUes5BgqsfnE1i6YviiiED6X0PrD1AYovLqb05VKWXrWUnLQcTs08Fatqp8XXTJI1mYDuxxvwoqoqcx+bAxCR5nvR+IvY+9FeslKy8Aa8WFQLqqIyNmMs3378213a2ZMhzxB06sf9R5i4/Iyo12jH4h1cvuZygC4HSoeI56DveDdqSoThy7FIBNv6Mhh6MJk+fTpr166V1F8I1gyd+Be8VhhOIeXSzZBxHvS28UVv12p2wZ8uMh0KT3Juz68ba50r/wLNh7q3J9bjr9gFr07tu32GDi1HgqcIqh28bthxZbstUzdC0pigLUk55q+RpwY2j4++vfCjaCHYUzrbFevawkmL6Drzxj3P3/w8v3zxl2zetzlmI5946TqLZiVNy6AhcAJvoIV/fvpPtvxjCzPPnxkXXQc903Z90XWdyzFCWRhq1uc5eszT7/dFdN3g0xddF5ca1ePHj/OTn/yEjz/+GJvNRn5+PqtWrSIrKysey5801Adqw0EqtO82lc0pY3b57IiahBCapmAxNJq8TRRXFFNTW4Or3sWrP36VgB7gw6MfcsvTt+Byu3j+5ucZ5RjF5/I+B4A/4McwDOyGA7vFwccNkc40FCTPLp9NwYQC1ly3BleDi5JnSyLus3TDUlxuV7jLXFF5EbuX7MFOZCfHntQFWK0qB+rf57D7cLgWomBCQdgBZ6ZkUjChAJfbNaCdlDsyUMO6hZOTgRZvQ/FllGGvxxoK5CD472uF+KbtCc4JjcNafHUvRxuj65IsWqppnaW7ORV/Y89fh5jrNCUDZ0R3Ku4klOy2NNKmb0Xx1oHFAQEvhjWNJj2L5G7si/WemQk1LqqApNzgz54a2DWr7XV2QKO5eMuwW7Ca1If6AhZO9OFvJZaADJ2Qhk59rZofX8Ay4J2dh4J4fs4ScVNOdF18MDtF/Obab1I2p4zN+zZH1ZuGsGm2fus6i5KCpih8VL8/Qtt17Ai8+KuLGZ89vs+6DrrXdqFg/ZD7UESNa8GEAlZ8138LAAAgAElEQVTMXEFOeg4bFm6g8vXKCF0Xq0t8Zhw2xETXDR/iEqgqisJNN91EQUEBEGw2smbNGu6+++54LH/S4AuYz7bKSskK/3/HoC704V/5wkp+de2vyHXmhovjNUVj8frFbN63ObzWN9d+k9/d9DsWXL6Ab679ZkRb7jFpeaYpGeXfKmfVllXcM+se6pvrueG3N8QMpOdXzg//f7O/iRRr5A5V50L8kJPS0WlR60nTMqj1uphVPotcZy7ritfx0LaHonYSK26sIM+ZF9wBE+ciCENOPDu6dl2XFB2oxmvkTax1ANJsHjT8YARQFZU0m4cGryN8DYumkOrfj9IxoCxYh/KvlSSfu5JGyySS+2CfWTMR3n0ALnocfPVgTQd/MxbVj0VTYq4Z76ZJqVY36jbzUTONOCOaSln70DxKGHpE18WHWEFcSNeFfu6s7RpbG8h15kZs1gN8ePTD8NQF6FrXnZY60TRQDmm1ytcr+cFlP+CKX1/RZ10Hkdqu48GCpqloikJTmw0hXTe/cj65ztyokTrrF6wnTcvAp7efQHQ1Xkw4OYhLoJqRkRF2ZgCTJ0/m6aefjsfSJxVWzWraUa2uqS78/x13mzo6oJXfWGk6R8tV7wo7tJraGnJSc/jq/V+N6h63Y/HOCCcTSgk5b9x5bPjBBvZ9uo8zRp/RpcPNdebyubzPsXvpbvy6n1bFg4WU8H3TtAy2/ngrrnoXXr8Xi2bh2+u+HbZ348KN+AN+amprqKmtYfmm5Txe/Hh45mvoevOemMfuJXtk3pUgJAjx7Ogaa62u6pLiJWY6r2PRwKkeRPUchr3zwkGe5ctP4rSNxs0p+APm81apmg8XlKHuLiI56mS5j3NOswvgrEWw4+rIgPitu3CeuzJmMBjP+bUWTcFiNMXcmJB5qSMD0XXxIVan3JCuC/3cWdtd9cBVPHXTUxROLozarI+akRpD1+1asgdfwBtxiBHq6Hv+KefzwNwHaPG1mOq6/MzT2HPbBsZn5pGZlsu+FX831XWapqAY8OeSP/NZw2cE9ADFjxdHBMzpyekRuq5sThmfy/tclM3XPnJt1MmyIMS9oETXdZ5++mmmT58e76VHPOlaNusXrI8qiC99udS02LvjTl2yNbnLOVqh9QJGwNQp6UaAwsmFrC5aHdH57VjjMepb61n41EI+rvvYtKDfG/BSMKGAe2bdw1fv/ypTSqfwtQe+hqv+EJqmBBsJaA3Uel3oho7X78VqsYaD1IIJBZTNKaPJ28So1FHha1RVV3G04ah5t7sOc7t60m1OEOLFL3/5Sy699FJcLhfz5s3jmmuuGWqThpx4dnSNtRZJOX22r6+NnlItblRPdXuQCsF/3/g2qqc63Lk35imwLatfjZOimomcszQYAHcOiCcUd9tJOF5Nk1ItbpSG/THnr8q81JGH6Lq+Y9a45/mbn6fy9crwz7G0ndfvpfTa0qjRNJ1npMbSdf6Aj2RrCvfMuidqUoNVtXLZvZeZ6rqiyYWcm2pw8YcljN35ZZK3X85YavnZhmVRuu64/zOa/U0cPH4QIBykhnSdx+tBU7UIXTe7fDZHG821XWgmq+g6IUTc56jeddddpKSkcMMNN/TqcYlUnzF6dNqQXfv81PPZ9ZNdeNtmTCVZknj2+89it9jJSctBVdv3FgJuT8ROXaz5qEB4F+7g8YOmu3spthTu+8/7mHHfjIj1ZpXPovxb5dTU1mBRLVTcWBFxaltxYwUAK2auiAqUZz0yi73L9vJZ/WcUPlwY8ZjMlExynbnkOnNZXbQ67IgLJxeyfsH6cK2ux+sxtTfZnsRoZxq6rvOvT/8Vsf7mH27mvHHnhV+roXw/u0NsG37ccccd3HHHHUNtRkIRzxO77uqSzOaBdnWd/sxZVfEG603NglCLAxUfFk1BUTXTeat46/o1KzQqZTcpp0cBcW9fo96g4oW3VgXH4YSCZkc+xtSNNPqdpFrcMi91hCG6rn9kZHyevcv20uRtQlM10mxprL1hLQ/MfaBLbacqKsebjnc5I7UrXZdsTwKMKG0274l5VM6rjKnrnvivUmy7rozYEBv95nyWXFYWF12Xn53PmPQxbSN0crnv60vJS8uirsVDerKDTIdDdN0Akci2xSKugWppaSk1NTWsXbs24kPXE6Q7XDtJZJAEEAj+l0IwKOtsl01LZdPCTRSVFxHQA6aOamzGWPav3o8v4GPNK2uo9dTy/M3PR9QybFy4EVsgFb8WiEoPqaquwmEL1oWpisrSDUsj7rNs4zIq5wV3Bs2cqcfrCTub0G2h2tcVM1fQ6m+N2C0M1dS+dOtLHG04it1qZ/3N67l2bbuD27RwE7ZAKkePNtCi1ketX/hwYbjbXCK8n7EQ27omERuMCLGJZy1RrLX6EnT2JxVVx4bm95gHoX4PhpZMhn8/yt9+ERW4UbAuODKmH7WgoaDdOeM11OZPwJbZbUDcn8C8J+jY0FpcwTE9F5QFg2S/h4BtLP5mI1ijGsd6WGFoEV0XHzQcpOEINu5pAQ0rKTi61HaH3IdibtbnZ+fzx9v+2K2uO+E/apr6G8JM13maj+M02RDLS8uKi67zBrw0tDbw8m0vMzpwmOy/BTNWTnfko4/exNF6vd+6biA367oiEf7WYpEItg1Z11+AsrIy3nrrLR599FFsNlu8lhW6oONMK6tqidqxWr9gPSXPloRboG9YsIEmXxOP7Hgk7JQ8Xg+5abl49BMc8xyN6PwWambk8QY7SdY11eFyu5hdPjtsQ352PjbNhl/3mzpTXddNA1iHzUGuM5djjceifr9532ZKrihh6YalrC5azUPbHqJsThk5aTnkpueSbcvF5wsWc/Skk7AgCCODvgSd/UlFbfQ7cTomoF5UEVGjypefRLePRjOaUHbNCt7e4goGbkk5kDwWWuswvng/BhZSdTeN9P2E2dAD8OcpwRrVGAGxMXUjimrpstFRPGpEI055d80OB6INXgdgRJyIj+SuvycDouuGhpC2G5OWh7vluGkm29zH5uJyu7rUdSd8R0m2JnHPrHt4cOsDLLmsmAtH5/DKDyr5yNMEmOu6vy5+kbEmG2KHG+riputmPTyLP9z0GNlvfy/SV+0qwjltZ7903UBv1gmDS1wC1f3797N27VrGjx/P3LlzATjllFN4+OGH47G80AXhFts6nOE8m9eW7KLV34Jf97Nsw7LwTlZNbQ2zH5lN2ZwyHt/zOI/veTy8xu6luznScCQcpIbuP79yPn8q+RO+gI/87HxKXy6NcpjritdR8vsS7p9zf7ibW0dnGislxeP1YLPYOCXz1JiNBpZetTS8Xuh5hGdztRXbx2pUMFijawRBGDy6Cjpj7aD3p9GTP2Dg5hTSHJloM3aC4QfFSoBgYydL8wft69ZWBQM3gBk7YG8xykWVaFsv77dQCj+H2qr2k8yUUzDsYwADZeL3Uf6yAEuLC2Panwe0RrQnad6hE/HRo9Paxt+IOBxuiK4bWgIBAwsp5NgdZOWNYuuPt+IL+Kg+Vs2yjcvCTTK70nVTSqewY/EOHtz6AI9+YxGj32zf4Dp3ykaKJhea6jrdNgr3//ckzr98O3z/oxes494/PNQjXXdqD3VdmtVm6qssmGcI9lTXSUO3kUVcAtVJkybx3nvvxWMpoR/4fDqKqvKVsq9QOa8yYjQNRNashsjPzudIwxGyUrJMd7DqPHX86o+/YsfiHdTU1qBpGjuX7OTg8YMcaTgS7jz3/Uu/z6OvPRre0ctz5vGdiu8AmAawuc5csqw5GAamJ8HP/N8zfG/q96icVxmRhtx5Vy3UqKDjjLCXb3sZheDA7IDbg01LlQ7BgjACiBl0KtaYO+j9Hc3iDxgcb06BDp0uAbLsx6DlSMy0YC6qAC0ZTv8unDITVffgTK7D7c2KDlYNnQx7fcw0tYjnUFsFb5agT9lEwNCwbrsk4vrhRkcmgXm80uFkZMTIR3RdYhAIGLQarcz49Qwq51VyzYORzfu60nUhllxW3B6kQtBH7p7F09/ZSdWhj6J03aJnbkUBXvr+H/F6G7FYHXzS2Ezptf/dI10XCBhRuuz5m5/nly/+kjuvuTOsE9Mdo019lapaeG/Zn3nLtZ9bNqzisNvVK10nDd1GFnFvpiQMLaFU2LqmOgonF1J8cXG47qDy9cpwAXuuM5cVM1cwMWdisGbA7zXdwcpMyeSe2fcAoBs6/7P7f7hj5h34A/6I667asory68uZ/chsamprePHWF3G5XRHtyHPSchiXMY6DJw5S66kl1ZZOkp7edhL8Gr6AD6tmJdOWzfUF14dbl3dsx+5yuyJ21TqmP/sDPpKsyXzWcJirHrgqoqb1tNSJEqwKwjAnVtCpKJb22yByB701PeIE0FCTMQw/6cZRdEvfgzUdG1p1ZXQq7pTnwdcA+5ZBUi6cuxx2Xxe0yZFPxtSN6Mmj0XWlvSvyiX9hfa0wZpparFPMdONotCB7a1UwDTiUktz2GjUbGTiN/THT4YaqpksQhK7pqOtC+i00RtDj9YRPMDvruoIJBdQ11XHhaPMmbJrhj6nr9lZX8bVH5wV13QNX91rXnZY6kd1L9uDVW9EUjVRbGo9c/wiuBlc4e69ociHPznke255vtjdlu+wlVM8B7MAXU2H3gic4rozioPtgj3VdPMelCUOPYhhGQnwTSdF912RnO/j0+GH8ug9NVbGqNny6l4CuY1GtOJTgEOYWtZ6p917CjLNnRA2AXr9gPXv27+G8U84jLSkt4neV360k25HNx3Uf47A5wgX8yzcuD9e4Pjn/SbJTs7m6zWl1DiDfWPoGrYHWtnE3OqqqRszTCtW8Lpq+iOWblvP0/GdIVbIjnqemKRz3f8aMX8+ICpp/d9PvyEvPQ1W0iOesaQoew40v4MWiaVx676VRjw0V4ScSifq3Bolh20htpjTQvi4R3ruBIPS82gOqDgGb5SjalglRjwnMPEBda7uPCdcudQh0jakbadDOpNUbmVPWXeAWXuutlTChGJyfA/fb8E5p8NQTYOoGeLMk+sT1grL2U1Hb6OCpaFJucPxMW3MiPeMLGIGWLoPGDHs91u2XRK3vn1GFofsjXqNUixvrB/fDGfNA0cAIwIcV+Cb+KLgB0Ol10adswq30r6ZrpP4tQnyfm/i6gSVR/w41TcGrNdLsbUFTVRRULKqVgO7HG/Bi1Ww4FCcew83Uey8h15nLg3MfxNPqiUjV/d/v/S9W1YqiKBG6bl3xOt748A1uv/RbJG+fFuUn/nZ2OU1qWre6zqf78AV8fFz3cZ913ceNH3DIfYiFTy2M0Gc/uXIxv7jyFjTDj6Ylo3o+hDfaU465qILW1LM4666LY+q6zr662cgg1b+/S382UBtzifq3Bolh25A2UxIGDk1TIlp1F04u5I5r7ohwSKHdJQfOcLe40O+hfZjyY995jDHpY7j6wasjflf8eDGv/vhVHn3tUYovLiYnLQerZiXbkR2+z7fXfZvf3fS7iO5wD217iBUzVzAmfQwtvhb+/dm/w44oNEfrlIxTGJU2irrGOoovLjY9GQ09z0ajDle9K/z40K6hbug4rI5wABt6zuPTJ/FR/f5wisnupbuluZIgxJFEO2nzB4KdZUM2pVrcGGpKdArZuEIUVSXLfixst1ntkrJrFmnTtxLQxkSImM6pxJ1PQsOnnF94GBUfiqqidg5Kuxsns7sIZfq2YJB6/uqIk1l1ynp4vxzttGvJSJuE35pCo6+LlOAOgqzB6+j0Hhmodg3y58COqyNOf1XNQipS0yUIg0koeOuYHvv7H/yeVn9reMZ8R50TSqV1N7v53v98L0K/Xf/Y9Wy/fTvT7psW1Wfk1R+/yso/lbPqsuewv35d+LN//MJKrM0645NUUm0KV/zHDK75/MzwKe2a69aQYk2hxdfCtF9Po2xOGSXPloQ7CE8afQYT0tOwojN5zt0sffG+LnVdUXkRlfMqIzoQhw40zl59GTW1NbSseR97KEiF4L9752GZsT2mrrNYon21NmUTjZZJJMeoo5dmS8MLCVSHAR7DHdGqu/ji4qggtKi8KLy7dFrqRNKS0k0/2KdlnRbVkS0UEOqGTum1pSxdvzR8ivrcD57j7cNvU1VdRa4zlyRLUlRn4DPHnEmKxUFVzV7GpI9h++LtuJvdHDh2gMrXKyn5SglHG47yn//vPyOcr0NxEmirbQo5bY/Xw5GGIxROLmTR9EXMr5zPjLNncMfMOzh04hBlc8rC9apF5UW8tuS1sKMHONJwRJorCUKcSMQvdDOb9Kmb0C97GXXnVUFxM64Q49w7UbdeGmG3QYZp4Ki0uEi1J4WDslSLG/XvK9vHr3jrUP71C7QJxWhvlkS8BqHHWDQlKmg0knJRYo2Tabs2igbnrmgPUkO3774Wpr0C269E8dRg7UVKsNl7oxqtsPubna7xTdQZO1AV3bypidJChp0h35wQhJGGx3BHaJea2hqONR6LOHHsqO1CJU7eQIuptvMFfDF13Xen3MSKnb+l8OwyTs3IITstD631OJ//67VhX1V+zfPMefaXbApNiVi4gTOyz2BP9R6e+f4zZKZksmPxDt45/A4b3lxP6YwbSNn+DfDUkO3I576rnsM26w5s+NCpp9HvxICwrgtl2t0z657wafBfl/+Vzxo+C/ciUYyA+caeHqBociFLLismLy2Lww113LuzEotmjdk4Kbmt7KOddv8lzZaGFxKoDgM6j2CJ1fgodGoYCBjYNLtpwPbh0Q9p9beGf1cwoSBiMHMo+HTVu6iqrmL1S6t5vPhx6lvqGZM+BnezOyJYnF85n10/2cXHx2vCDja0RuXrlSy/Zjlrd6yl1lPL1h9vjUrbDRFy2hU3VpCVksWa69bw/mfvc9OUm7jq3KuYtmZaVFpKVXUVft0f8RxLXy6NKvLvHBQLgtAzEvEL3dSmXUX4pu8h0BawKaoaDlI72q3PeM28+VHLEVT7uPBNqmrAWYuix8BYM2K+BlFBo2JFUe1onepFKVgX7Nzbdu0ASVjSJpkLtNZj3b72PW5sZPjNg3RPTbD5k8nrojRWY/2/73W5OZFoJ+6CMBwwG63nsDliaruA0jbhQcNU23UcERhL1/24TTf9+2c7OPufxRG+xbbnm/ziysfYtG9zcEpE+Wy2/nhrlK579LVH+d231pC684r2xyfl4qQRtl8XsTF4wnoKgeZDTM45nX//bAfJaadxsO3A4e1P30ZRlIj1v/LTV7GZ+KFDnkaenXNHuJb19HGFbPjOGgx8KIoSzEjp+JhuOsH3pNmS+LXEoXfTm4UhITSCJUSooL4j4VPDNkLdcEP3y8/OZ+OCjazasioczOVn50e0Cof2dJGlVy2lYEIBi6Yv4uoHr+bL93yZaWumUdtYS+XrlawuWk3BhII2J+pn1iOzyHXmsmHhBirnVdLqb+W2Gbdx3drrWDFzBQ/NfZhMyxhSySZJTw8HqZqm0KLW4w20UHFjBTaLjeKKYiYtn8TCpxYy90tzo06PQ/blZ+ejqVrEa1FVXcVD2x7itSWvUb36AHuX7WVMWh4n/EdpUevRNMn/FYSe0t04mAx7PVn2Y2TY67EM0mcrpk2GjxOt6dS1Zgfnjprcx0DDmLoxGJRBe+BYXRnRaENBjz7hrJoPluT265l0kPQHDE60plPvH4XmPYrl1QtR/rIALizHmPk+xozt8N5DwRrWjvNHrWntNoVoC6CjnmcfO1caitX8Gt46eGsVfPnJyNflogqwOiEpNxggW9xRa4ZOt63bL0HbMgHr9ktwGh8M2t+CIAxXOus6INwbpCM90Xbritdx35/u67Guy88cY+ofJ406jYIJBeHHuOpdprrueONnkY8/Z2n7nOm2tdS3VpLp/4QvvrsQxx/P4ex/FpPhPcji526n5NkS5n5pbrj5Zuh6335qMb5L1kf4oeMXVnLCc7S94VJ2AZy1CGXbFagvnI6y9TKYfE/w9vCLlI+hJsf0TTo2U18Y+g4Qv5ZYSDOlTiRCsXFnNE2hpnE/s8pndVuj2vGUMtRkyB/wYdGsWFQLXy4tiKj/PCfvHM6+8+yoa+5YvIO6prqI2aoQdIqhWoXQv68vfZ33PnuP9OT0iDEzGxds5Dfbf8Md19xJKtlR1+hYo5HrzKXixgrqPHUcaTjCln9sYeb5M2Pat3vpblp8LZw15myONR6NqPMIvRYAn3g+DKdNJ1oH4ET8WwuRCLZJg5G+Ec/3rqtmPWrr4bg33+mK0POKZZOvQ6pXV/dpNjJIU10oLa5gIFhdiX7uygjbs+y1aFtOjzbiqr+C52NIysFIPo0ANhS9KWrHPeb1p+8Bg6g03dGjHOh1/4x4PZnyHNT8HkZfHE4/proS3xce7pTSFqS7EwC7TSXN/y7K7vZ0v/Dpbm0VTN8GgWawOILXeqcUWlzB9Odds6MaU3X3Op9oTWf0KAe+hsMj8lRCmil1j+i62HTWdV3VqHal7TRN5dZnbmXzvs091nWnpdj54rsLTZsrfdzUyuzy2eHSr1CDpjxnLr+ZvYJzcyehG5D8jyXwadsIxBk7YOvlkReb9if4v+9FXeODLzzFwSYvBWPH4zr+MYcb6rj9hVL2ts2F/fhXHzHaBlYMmgMBvv3U7fx6Zgmn72lbP1aDugvLYec14e+icJM6E9/UXfO4nnzHxCIR/9ZCJIJt0kxphBIIGJw39jy2/ngrdZ46HHYHqqqyY/EODAPTVNrQ45JIDzYR0kFTFDYu2MisR2ZRVV1FybMlvPKjV2IOZs5JyzFNQwmlHuek5fDybS/zWcNnNPuaw3UHofvNemQWO5fsRFVUWox60rQMGgInAAMDHX/AzyH3IWacPYPrC67naw98LaJD8V1b7qL44mJT+8Y6x1Ly+xIenPtgxHgaixbZAbljbW9ELS9ShyAI3RGrWY9h+GOPgxnglOCezEXt7j5+NQlLUh4kn0LgwqkYemvEuBodK9q4wmA33w5BIpbU4L8TilEAi30UvP3faEe24pyyiUbbJJKVE1iUlpinvpHBXpvPVlTcSscROjZUzY4yfi7KrvbA0pi6HlXTyLDX97o5SKtXB9vZpM54DcXwodS/1x6kAmg22DY9+gV3ngOXvYihJkf9qrsT9+7G7gjCyUogYHB6+plsvX0rdY1BXecNeMlLz2P3T17H5/dG6JnOjw1pO01R+PnMn7Pvk3091nW3PHc7f7hhXftsVUc+3kue55bHbuFXs0vD8+g1VeMrZV8hz5nLH25YHbz/39p80ZT1wf6Un242Lx1IOdXUN0zIzCNTrSF5+zROb0vjfW1hJUcbj3O4MVi7v+2jtzlv7Pk4lFE8OPdhRlv97eu3NaLrvK6Rfhb6Nw6iEMDQdSy0xvRN3dX2yxzWxEIC1WGCxWIh0zIGW3pSVECGjmn9paYpNBluWgOtaKqGXUkiL30s5d8qJ8uRRWZKJr/d9duoms4NCzZg0SxYVEtMZ5efnc9pWaehGzpXPXAVlfMqTYPag8cPYrfYefYvzzL3S3N55v+e4apzr4q43is/eoUr778yqkNxqBa2s33P3/w8J1pO8KtrfxW+VpLeHpCHXguzGhDpACwIPadX8zsH6Yu8Jw2EYt0HCAZ024rCTZe0c+8MnzKGuvsGLPkY590ZFSQqh16Jrl2d8hzUv4361krSzvt5sB71gjLTms+u5viFak3DQWfLIfjrwojNAGXXtWhfegytU91oT2uJW706rWQGr5HUgNriCtsWs/GT+x14swR16iYsnWeuqmrM55lqccP2woSqbxaERMLn0zk9+3RsalDXpdmdYV1n76RnQvRW13U8CfWjcaTV4LDbxTd+t5z7vl5GXloWdS0eGo41kJuey0Vjx/PBz7biVyy8d+I4NbU1/O8NZe1BLQR90e5r8U/fQe2Zy3Gm5WGZsh5Lx2wNzW5e965oZP9tXkQar3XHlYz11DDWkU9g6kYOO7JQaA/IvYaKPVTr760z7zOgWFFaj7ZvTl72Ypc+2Kx7fCPB7xGZw5pYSKA6jOh8QtpVcyCz1ucVN1YwafQkzhpzFq56Fx/XfUzhFwo5NeNUdi55jYDuR1VU5j42l6rqKgomFPDcD57juv93XdTMrOdvfp7G1kbqPHURg6g7B7VHGo5Q8mwJr/74VRY/t5i7Z90dNRqncxdigFxnLp/L+xyls0vxBrxU3FjBqVmnoqkaAT3AFb++ott03lANSKwOwB3nr4bmlSVCSrAgJBJmzXp0S++/yGOlpvalaUVPGgiZ3SfDXh8Z0E0obk+FhbZgcBaWy/8Iuzrffi1c/lL7eJe229l9XfB2FJTGA8HGHu+UBtNqOwS0nU99YxEOOi+qNG+w5DitvW50ejDoU/FF3je7AM5ZGrNrr1kg7yWDlOlbI1KiOWtR8NS1rWFV6rQ9NOJsP71Nyg3Wsobq09rm0iqqBUVvllMJQegGVVVNN9rNiKXrxmeNZ8KoCVQfqwbgu1O+i9Pu5I2fvkFOwIW2exb8rQa7I5+MCyt5adGLXP3QNVzywOywrvvT2y/x+7l3Yt12GXhqsDjyOfvi5yiaXEhemvkp5mH3p7xb34Tv2FEee+1RKue+RLp+POg/mj8LbuK1HA2WE/g9kDQaQ7WhXFAGyXmQNAb+VhLhT7Vds9DOLueox05+qhMFSPXvR3nrF20bgKcH0393zW4Pir/8JIZiiczyeWtVlG/q6INNs1CmbkJPzkPBCPqxDk3weuq/hfgjgeoIxaz1+QNbH2D5Ncu5bm174Llx4UZ0XWfar4NddV+89UVc7uAue1V1FWt3ruWVH71CfXM96cnp2FQb98+5HxWVW5+9NZyaa3byGerOG2q4dNuM20i2JYdbkZe+XApAZkomu5fu5kjDkfBt98y6h6/e/9UIZ3ys8RjpSelRgW5ReRE7Fu9EUy0RwaZDcbL5h5ujalQdihM0Ihx+4eRC7rvuvphdiQVBaKcn6bcdsZpxcs8AACAASURBVNvUiLpQrboS57krabRNCg5mH6TxNyreYHAVGjsTa86posa4XTO/3Xsc/jwlsu7zH8vhgjKMjM/jN5J6XJ8ZTjuLdXLQ8GGwecmu2ViMJiyaE6XjyWZ2QXgma6yxNhAZyAdF236UzjWy769tTw1uCzIjTm89NbBvWbBZVPpZKPXvofxlAZYWF8b0rb0+VRYEITZmum7eE/P43U2/w2FzRHTQ3bBgAyl6A3mduvtm/rWY2i88FaXrfnHlLeEgNXRf++vXUfFfr/Dh0Q853eSz/MmJI5yRcz5+3c+PrihBUxV4ZUrw96d/F876YXtWiCMf4/KXMZoPt9eYhvxliyvCz2QlOZhWPosdi3eSZ1faM2A+3Rxc99zlwbpYww+ttRjJeaB3StetrYJ9ywhM345u6OiKlRY9G783OKcw1epuX7ftuuquItRQreu4QozpW9ENrcuxX8LAI11/Ryh+3Rd1Sll8cXE4SIXgqeVh92FaA62UzSmjYEIBq7as4rmbnwt3lNv67lbczW4CRoCGlgam/Xoapy87nUvXXMqi6Yt4+9O3ef7m53G5XSzftJw/3vZHdi/dTdmcsvAImfzsfJIsSaQnpTNtzTQuX3M5Jc8G60tLry3l6gevZkrpFEqeLWF10WrWXLcmqt513hPzGJU6iuNNx03TeWtqP2LqvZfwceMH4c6+gYDBeePOY9eSPVSvPhCeRRYIGBEOP9TdeMavZzDhZ6dHrSMIQiT+gIFbmYhv2h4CMw/gm7YnZiMli6aQFngfZduMYDD3ZgmcewdqoJE0rc681tWkw6zZup27Dnd3m6pa4MKHgjZsvRwaD5h3wjUC5rer5t0iw915PTXBU9RzlgaF0psl+I0kTrSmR9STZtjryUp2k518nCx7LTS7yExuIst+DEXVgmu+UwpTno/uUPzWquBphCMfpWE/qRY3Bmrwd4784LU7dSwOvaaxOjWnWtxR7wO7r4NTZkY8Tx1rdP1WbRXsvCa4CbHzmuDPnhqUN2+HTh2W2zczBEHoLWa6rqa2hpzUnHBTpoIJBZTNKaPZ18yErHGmG2t2lShdd7juI9P7trbW02Ak45+yIbIbb8HvGZcxlnH2AA3uD/jphqW8e6SDPx0/t/3Us20tpbEabXfkbWF/GcKRz+GGurCuO+L+pP3+p38XzlwQrKX/w+mw7Yrg5qFiDY6p6eybW1zsO/RvbLdP5KzVl3LAvR+t7TvBYjSZbzpaHMH//3QzyrYZ6Fgj/Lcw+EigOgLRNAXdCES1Oe/YHCk0Z2vhUwv5jxX/EQ4SAVRUyuaU8c6qdyj/Vjm3PnMrh92HTcfEzL5gNr988ZfBetLZpbjcLnRDp+TZknCQWnFjBT7dx7Vrr41K+S1+vDhqzXEZ40yd8Wf1n3Gk4Yhp+/a6prrw6arHaBe5obSaVCVyLE7H+lWzVu6d1xEEIZLQKJa61uwuv8hTLe72FCpoC4K+Cb560GM0HeomPdR0fAAf4FQPxr7tjf9Ccf8LrOnwpceCJ4+h9LDOweA790XfflEFVD8VPGmMun9phP3YssKBWbOR0R4cJtUH7fn7D9Ea30Pdemmwu/CfLsLSehCt6SPU9x/CmLI+ePJry4Rpf4Zr3gna/I/lwdMHWyZc8nt4a1UwdVdXgmNvvvQYZJxn+ppalFYyrC6sRj2arw5rwz9wqgexaErM5iEk5YSfZyilV1e6CdZDfLoZksb0aDNDEISuiaXr8rPzUVU1Yn5qybMlTCmdwr9c75t+VrPTxnL3S3dH6LrDDXXR9x1XSFbqKApyx9JqcdI0bRefXLqbf36uAlVvJf9vc7C/eCZffHchf7hhNWv3rqf2i21+M+WUaJ9icXTrZ45esI7bXygN67pPThxpt+uc24PfHZ2+SxS9BWXPnCifXfvFCm7ZsAqI1HWpFjdKw/7Y47o62CalCkOPBKojEI/h5vbnbqfyu5URs7ZGpY4K/xxrztb/zPsfUuwpVL5eybwn5mG32HG5XeFOvx2pqa3BolrYvG8zs8tnc/may5l+33SWPL+EP5f8mR2Ld1D+rXJS7akoitLj4dYtvhZTZ9zkbSLVnsrLP3qZF299MTgPrC3FOJQyXFNbg1dvwW9p6vJE1KrZKJxcyIaFGzgn75zYTZcEQegXMYMgiyOmWOguPdTsBFDdVYTqqTa/LSk3mA7714Ww5ezg2ITzgxtz7FuGccVrMPPd4IiDfyyHI1tBc8D0V+Gqv2PM2AlaMmR+LpgOe0EZzNgRvD00F7WD/UbbKJpm2yTSAu+3B8/bLkFtPQxn/jB6Tuvua4PjYcZehXJ0D8Z5P4dtM2DLmbDja8HT3C+sgWkvQ7MLDB1aXOG0NH3yr0C1QL25OFXq30V5YVJwLXT4bDtq62HSbJ6YcwWxZWHMfB8uqgym9G4tQAs0oE/d1H7/thQ5Uk4J1o6F5hk68kFRw3NlAdItRwd15q4gjBRi6bp1xev49PinpvNTb9mwqj1whHDwduumX7Jo+qKIw4vbXyjl6AXrIj7X+rl3YN02jeSXzsaxYwY231HSHbmcmzse51++HeG/Rr85n3lfnMnMJ5fRMm0HupYU7VNC3YE74sgH+yj4ym7803ewbNv/ctjtCuu6218oxXdJ2+ZgrNIL3RdO9eXCcgIz99M8bTszn1wWHnsD7bpOxRvcpCxYF/HacFFF5KajlCokBFKjOkzpqhGQL+Bl877NuOpdvPKjVzjWeIwjDUf475f/O1xHGivwPOw+THFFcXg8zPJNyyn/Vjn52fmmjYmsmjXqdpfbhWEY5KTnoCkan574lCZvU9T9QsOtO6958PjBqHrXjQs34Q/4Iho7bViwgSZfE4ufW0xVmzPKz87nPdd7JFuTyXPmkaGfafr6pWkZ3DnzznB34a6aLglCRw4cOMBPf/pTTpw4QUZGBqWlpYwfP36ozUpYYnVQDM3q7EvTiq6CX9PbTNJhqZofDDjfLMEwQPn70uA4msmlQdvevhvOvRNDUYJD5TvWVLWdbAZmVKGeuxL1xL6I3ysH/4Dl1CIsugul+TDkzAim0dqygmIt/ezY9u8thstfQunctGlvcTCQfnVq8DpTNwQDZSP4faBo9mDjkKTcqEZOXFQRFHGhtXZfB9Negb8vRfviA5zwZ0fVHAdPitegnHYtpJ4efA3fKUXdeRX+GVUEpu1BVUH1HgmmdXd83HsPoZ+7EjUpB0tzU7ejc6D7ObCCMNLpi65bvmk5AE/OfxJVUSN0zN7qKmY+uYyXf/An6puOkpmaS4NP5dV/b+WtQ29TcWNFWPvsra7iG79bzm9ml/P5vLNo9XtJ3fW1CB9k2T0b54XlkSejbY3bsGVxgT2P3PRcXF5oafyUszs1MyL1dPjyk/DGtyMaIaFYwT4KDZ1HvnkXXv8KDrsP8vT1pRxuqKNBSSPrgjJQzTsJY/iD/99WhuC/+t/oho/fzF7B2r3rmffFmeHuxim2ZHT8aC2ucB8BbFkAGEljgiUMbetKA6XEQALVYYhZ57eOnW9Dp4XFFxcDhJsUVVVX8fbht3np1pdMA8z87HxGp40m15nLXVvu4oG5D+AP+EmxpqAoGhsXbowYTv3k/Cf5rOEzXvlRsNh+1ZZVuNwuNizYwHcqvhMOHiGYavzirS9SU1uDw+bA4/VwWtZprF+wnmsfuTaqARNA+bfKOX3U6Rw4doBkaxI/fWFlRH2tq97FmWPOZMXMFeFrhx7vcrso/1Y5GSkZaHQSr0BD4ET4umaNoEJNl7rqwDeQSEfixOXnP/85119/PYWFhWzevJkVK1bwP/8/e+ceGEV59f/PzOxmN9ncSEhIiBoNF1HQUuRnUBK5RAUVG0Ap3toUqTcsYiqYF1GKWKVUaKq8pl6KNK3VWi6BV1BQAwECEl8vtKKvXEQjICHknmyy2cvM749nZ6+zgIpAdc8/kNmZZ56Z2T1zvs855/v9619P97TOWDMiXgoCezG90Y4hNWNkEcGv2x68o74tgvYe1nQRjHhSiR80L2iOWn4FxCQjVY4KB7hDy9BiM+n0xOOR+pJUsAW564Aof61/B7LGIr19hdg/qxAGPewvWfOCTLIKRXls4FydTV7SJtOxgbi9FrZORLr0BcyqC1NCPyRNFiC1scYfgMWdg2bpieQ47AOaeg8p3Q0CmGseHwtwcsFmJPsXYh6fvwzn3RIixbMCNA2FblQ8SChIHz0adn/Ugi20OlPoIcknJJ1zIjqwUYva99m+TVwHEGeyckFqT778TTUHWup54LWF7Nhfw+HWOo444eOj9Wx/ZzXTR0+n8tcbiTVZkSQpKK473FpHp5zA+w1HGdKzp7EPsqSAu0vIv1h7AapY+LLXYrVls/ymVXzpcWO19cZtcmDSga3b7l2Im+IHh6pTgM+No0UPqy0bc94KzGj0/fxJyCnivF7paDFmkM6F/S8JHxToS/NWiFYN3bIKsZgsWFQnl2T247nCB5A3i0W/82zZqGmr6ZD6oejvpK0T/aCUs4n9mu+ir/uMo3Hd17coUP0PNCPmt/Fl49k6axtWEoOyhaEAsGZ/Dc2dzTyw/AFDlt6HKh7i6ZuepsvVxYgnR5CRlMGCCQuY8pcpZCRlUHZrGf3S+xFrjqWju4OxT40N0jdtd7Tj9Dh9zMG6ZSRm4HQ7g1jpXrnjFXrYegTpf5WsLPH1tqbFp7FowyJe3PYi2anZlE4uZc3ONb4+jFBt1XZHO7MrZvscty3GRre7mzgDoBrYo1qzv4Y5q+dQOrmUi7MuJkaxnlYHcrwXVtROnzU2NvLJJ5+wbNkyAMaNG8djjz1GU1MTKSkpp3l2Z5YFZsg8UhrqlTUonjZR7usFqVp+BRAqn3L873iHO4nkkEwsw8pFea4OYG3ZokRVtoryXyMG2tizaXWm4HaqeJS+JBTUoOAQZEqSGam7zjhYiz8P6bMXSeg/DWQNkMHjFEBw2IvBEjY5ReF9VVsnioxmSCaWf80RIFmxGGuahvRPYTsHNo1BCs2cNtaIuQxe4JffCVkgIKYHWHqiSSZMioTbo+FWTZh3FIn981eJsmY9qHQ2Qe2rkP1TpMorUI7B2qmpqu95Rsp+B/Z+nagObNSi9n21bxPXScDFCTLmTaOIs9dyti2b/7ltKXf+zxLuK5jBz5f9nIzEDB6+7mGuePKKiHFdnNlGe3cbY58ay8u3lXK5kQ+KSQGpHWqm+CpSQrOuWaM34+pqxORsh4QcAUalGMFJ4KgT/g+Ej3n3jnD+gsteCtKrlvTFvZxb4fBGwfirdotjPC7RqgHeRcFHQF9ctGUjD1smFvDstb52kLiC7bR6vPJcMkh40FSVWFq+9rvoRC0a131zkzRNOyPuUGNjB6p6+qeSlpbA0aPtp3saYRY4r3atgT5zcsjNyaVkbAkpcSk0dTbx/865FIuaiENuI//J4UHZ0sLBhTwx4Qns3XbSE9Np7mym2d5M7+TevhISfXVua8lW2rra6JXQixRbCg0dDRxsOej7PDs1m00zNzFq0aiwjGzp5FIWrl8YBiQ3PrCR0YtHh+1fdmsZ1z19HQC3D7+dmWNmYlbMON1Olm1bxthBY30Au7qkmryFeayatoriV4sNzz2xbGLQ2EPOGYLiDAeqRvcoOzVbvBTUUxMYRfqunclzO5UmyxKpqfGndQ6htmvXLkpKSli3bp1v27XXXsuTTz7JwIEDT2iM79rXnQnPzpchC5WvMfUjVm7BpHUKwLprvuiz1D+TWiKWfoZeV4/YTkyt74tVem8ZMdYM1EueRlNV34o4QEKMHcX5VViJcSC5j9GcGbUBNo0JD9ZylwkJGx3U6SBRsUFMMqw9379/QZVgGA61cXvQFAt4uoPuhZZfAeZkpM4vgsvmAkGoPo9Rb0HrLn+mNHBbTIp/foFzH1oGsRmADPbPYX856qB5tEp9AUiSDwpgn3QBdOwPzqhGuh9DSv3Bpy0b16httHQnkpaWgKvtEOZNw8OOcY3eBpoAsrKkIb3WJ+wWecZ9TlN3aqSv2Wm1k/k7OxN93cmwaFx3fNPn9m3iurNizSRuuSr4N5ZViGtIKUfbjvBF82EstrM40nH0mHHd5lmbGfHkCGobaxmWk8uWO5Zg3jYprKyfvncKhu8Ivk27/jOkztpg/3XZ3yA2S0h56YtnV1ULJvhQG7cbNl1t6Lu02Ew0Swby25eJz/XSY2s6WuxZ/jaNwOMC/ROgjdtDu9Ybj0czfE99G9K3aFx3bPsmvi6aUf0PNL0EZPro6SF9nBVkxyfhcjuDfgy6/IquP1o4uJCFNyzEZXGhyAovVr/Ii9teJDcnl40PbCTOHMeiDYuYPnq6j6lXX717ueZlxv1oHB7V4wOlegaztrGWlLgUavbXsGTjEjbN3ERDewOJsYm4PMa06rYYm2+Ot+TewjVPXRN0viUbl1AytoTiV4vpldiL7NTsiP216QmCOU5nGs5MyiQ9IZ3GxpByQESPauWvK6lrq6O+vZ7y7eXMu37eaS331S0w26ubj9xJOk2TitpJs1MRkKalJXzn5zimddXBm+EZssSrdwAKvBkcVMm75pF40W/ACyQVWzY9rlgDPS8SgNBrQdel2cCVBVsK/SW2QxYjo4HZimJNp4d+rBYHigajN4KsgBSDjEYPqUMwTkqy4Zz5sESw/FYHBGt5y8HZAjUhmYAdUwQItPYKzt5G0kOVZCQlFqyZ4vxDFoOjHsltF/chUO8VBOFIQP8Uw5aJXi9HnT9T2lgDXV+JLMeot4yzwYnnwwcPiLJjb/Ap75pHj0ufFfeipVuQTo18Pbyvt7shYgm1b175FZhjYklLEL7dnJAJV6zxPydbNlyxBrPaAVVe0DtineE9UsxWMY6jXmRQZIv/eZ0Bdtp/Z1H73ti3ies23VNOYuBvJzUXzp+OeeMoettr6W3LxpW3koff38TVA8dGjOtcHpcvrtuxv4ajLpnegRUVuo8ZUCzOE9G3KX6QCuLfd34mgK0lBQo2CT8V0yNCz6kauZJl52wYugQ1fzXyR/NExYo1Hc2aISphjI6LCah2sglZr4QkK25JNqzkSCrYgqZ6TmqvfDSu++YWBar/gWaTklg8aTEFfygIKhOZUDaBrbO2YVZigvpPA5ngdOc25o9jfI5q+d3LAbgl9xa6XF1M+csUSieXhrECL9m4hDnXzgkiNFp+13JkSebL5i8p315OWkIa1SXV9IzvSZO9iYMtByl+rpg373/TsCfW7rSHzVE/39TyqZROLiU9IZ2X73iZTmcnm2Zu8h0bOtbZPc7msyc+Q5EUYhQrFs2GLIcHNIoi8UXb3qASjIppFZyb2A+X6/SzJ4U+P4iSO50plpmZyZEjR/B4PCiKgsfjob6+nszMzBMe44eQUU2xdInS0ECz16K52lHl2PDPcop8IFXfly2FvswcGF+XSenjK98KJfXRV8aB8Eypnp30ZnNbpb4kmgzmfGiNYAceUioAkqUnfPx76HeHcUBksomMQd5Kf9Zgf3l4X1X+KtGz1bYbLT4Haed/+ftVC6p8ZWqBWQDGvCcyufHngqcbOg/4zxtADOXrc9UZlUODwLbdAtzmr/KTO50/A4/Lgeo6jFkHlK628Gt01BuOqcVmIV1VLT7/6FEYMAPVkomc1J+jDXb/c/L2fkmyCVNlrn8cXSYoIAOj5q2mw5lAfOe/T2rG42RZNKMatZNp3yaua3c5g3+XBuRx5uobeHDk61yy6NoTjuss5lh4tzjch+hcAJ8s9BO3WTNg0FxI6AuSFEwgp6mC8EjthvbPID4H4rLB1Sr8kK63qvecyiZj39XxOQyaIxbzzEloF/3GVyUj2bIF+3jocVmFwncXVIl5W3rC+/fBZX/DFIFFWO46AG/lndRe+Whc983tzFiWjNrXMo9HQ5aUiKszNimJ1dNW+yjMAynIjQDhpGcn8fC4h5laPtUnGWOUtSy6vMjnzHzHPjeJL5u/pPjVYh4Z9whvf/I29e31NHQ0kGJL4bye55GRlIEiK6y8e2UQrfrKe1aSnZJ93CxpVnIWmQmZ/OS/f0LO7ByKXy0WxwaMtXraauKlFBJII05LweSOi1j3b9QLMqFsAu2eFhRFwiG30a414JDbjilx811Z6PMLJHeK2um11NRULrjgAtauXQvA2rVrueCCC6L9qSEWSe5Eat+LhBr+mTVdBDr5q0RAkb8KrBnH1bDTtVxVlWCtVmsGsuMrks31JMU0Ie+aF579vLDE3wtpao04Z02x4ulxKS7ruWKBob5SaLEaySy47dB9VGQNhpaJa8kpgj1/En9f/xmMehM+mg9v/Ajem4bUfRTOn+Efx2mgZ2jLFsARVfRfrbvAL7GTmuvPagZquu6aL+5jgPyCll8BX64Ux31QLMr23psG5kQ0OTa4n7TrcPg89peH6chq+RVI798vSvi2ThSAe8cUUT7s1VZ1ezQhoYMZGafoA7ZmBI+tutFGV6L95AvcBTW0Sn1FKXioDJH3eUUtat8n+zZxXZPbFCxDY003BGBxJoWrLiig9Xcf41z0Ka2/+5jfjX8c2XmUTfeUs23GKjKTMnxx3S9ffQjX8JVBv3dPfgVu27liW2ONKAW+cgv8vzKv/Nf5gkiu/z3CX+wsERnDd+8Q0mDvTQPHYZH9fH0Q/O80sch29Tsw8nW02Cw8chxaiO8id6nwadWTQDYhdX4pfL7+3hhWjtR1WPi4AIkdBj0iJLl0X+fpAmuGeBep3ca+VteEPon+JhrXfXOLZlT/Q80kG7P2mhQzHo/GOfF9qZ61jS53J27V7ds3EiB0uUVpblNnk09oOXT8QMcYeKw+5mNrH2PuuLlM/NPEoEzlK798hf+r+z9Wvr/S17T/VctX3PvyvWQkZrDh/g0osmJ4PT3je3L/q/dz5xV3+j5bs1NkHjbP2oxH9RAjW4jzkh+Fsqqpqig/C9yueTTjl4Hq4suu09/srj+/rbO24fa4MCnmKDvcGWTz5s3jv/7rvygrKyMxMZGFCxce/6AfmBmSHXnLU7XL/oEawgKsxZ2DNHhBWE+mJsf6B9VUki1thj2sQQDrvNth4IPQ3YDU8i+k/eWCmEMn/NF7mpIuFAHOJwuRcdHm7knyyPVIHfuFJqg5ATQVSfMgKWZktx2PkoBaUIMiOZGGlYf3qFp6iUBIdYkeLt1Sc0EdB2jQvs9fwusridss9tFJkEJlHYYtA9UdTjxSM1UA3/Z9ooR4+y3+HlZHHZiTxOfdR0UmwZQEF84UYHhIqb+3tfoGtNHb0ALZlAOzJfpzuug3eCxno43ehqyJ7KgsgxLIXqzPzWTzEp7Ywlh9wyRzfvQ41Ez1kULJeatB6ntCREwn06ISOVE7nfZN4zpJkhn3txIWX19KZkIKqXIPEg0ykh4Unht3D3K1IHszZxWScNEjSO9NA7tgxf2f25byk5fmkBKXwuqda3h+wGjuLqhC83TTrcLRrk6yEuO90lgeJEkR2VI9Kwp+UqQhpeLv0DLgHVNE+a8OEk3xorff0YDkbEbZfqsAoKPeEiXCgWXHIHxh3Nl+fezAPvqRbwjg7OkW86q6JuTcRaLX/p0iGPpMuJSX3kah20nyN9G47pvbScuofv7550yePJkxY8YwefJkvvjii5M1dNQMzGh1puKeCkyyCUWR8Hg0NOCq0quY8pcpLC1aGgRAAy07Ndvn9HSplvLt5b5j9H0ykzINj3V6nIDIuOogFfyZyp0HdzLt79O4JfcW5q+dz1WlV9HU2UTN/hrW7FzDmD+O4UDTAVZNWxV0vuV3Lef363/Pmp1rfL2suq3ZuYZOZyejF4+mwX4UWZbolttodB3mo6/+xS1Lbyb/yeF8dOgjzGaZLzv2kf/kcPrMyeFg8wEKBxeyatoqqmZWsWraKgoHF6LIsiHrnl37+qtp3zYz6/FoWNVE4qVUrGpi1JmdQdanTx+WL1/Ohg0bWL58OTk5Oad7SmecuT0anpje/qzikFIf26yKmVapL65R2/CM+1z8qxn0NO2YgubVxzMpErR8hHnTcJS1OZg3DSdJ2ye2E5DBTc2F/ncLwp+38kTW8PzpYtX/whLxuZ5NXDtA/Dt4gR8Qe7pg3/MC2FWOgtf6wqarkbsOoHz8W8wbhyN3H8atyvBpKVz6Alz3iQCDkhkcR0TJr+YRq/n5q0TJ7tAl4lyv9RWr+nomVL9WTxcMXiC2OepQLZloBVsF2cilL0BMuiiXMyo37joM701Dc7X4s5R6Cd3eZ6H1Y3Ev9v0ZydMhgj5Hvch2BGRkZc0lsp55q4OyJdroSt9zaqEfzZ0WWhyJNHWn0uFOQtYckbPLsgXwsvqGZEbZMUWUChqUKR4vy61i/jZfT0PTwXSk79gP0aJx3am1bxPXHW6tY/hTE8n57UjGPH97cIbVlo1z+ApMsgk5kIE8pwhp6w1Bv720D6by3xPn4vQ4GZaTyx0/uhylciSmdQOwbRnDuUoL5m0/RXp/BpKzCSpHgP2AsW+KzYysGa26YPTbcFm5YGu3HwBrGjhb/TJbrbsEsNw6MZhEznFElA3/eFGY75CqroGm9+HDWSCbjc/tbBYLeZ1fChmuka/DuE/FguFX68V+enXPiHVociwmRSLZ2kYPy1ESLE2o5s5oXHeK7KQBVV1bcMOGDdxyyy3MnTv3ZA0dNQMLXF3b89s9lN1axj0v38NlC3P5smMfZrOM09NNbWNtkPxKn7Q+ojk/wBEuLVrK4jcXs7RoKXWtdcxZPYc7r7iTnJ45bLh/A+/MfofSyaU025t9AtH6sct+sQyTLBLzx8u4Ti2fSsnYEt+2wH1iTDFkJGTwxow3ePehd3n9vteRJZlxPxpH4eBCXy+rbtmp2SjeMpl5r83j87Y95D05nP4P92fa36fx+PjHyUjKoPCZQto8jT4AmpuTS2p8Kg9f9zDFrxYzctFIX9myWY6J3Oz+NUynIdeBcf6Tw/myY99pKSOOWtROl7U7RcE+5AAAIABJREFUbajW3v5AQ2f39WapWroF2GnpThQlWEaZM0389uJNrX4yHv2z6vEkxTSRYmkACbSR6wXw0YmPvPtRM1WU38adJaRjQgmCvIA43tQqMsA5ReH7VN8AFz7gO68kmVAHzRMZznUXCoZKtRv+NVvsr2mi5OyDYhEMGc3pwhLxty0bFAu4u9DyVuEatY1W9SxU1S0A5hf/ALVL9JYaAUJvT6q0dSL8+Pdw/T4RYCHBeUUiWzHmPTj3Zth4pTGA94I/t0ejw9QPtWAL2vX7UC95mnY1w/ecQrOL8aZWpA8eENJAgWV6w5ah2nJ8JEuRMqNa4vloyRdHzJoGAWfv2Pp36GSbEZj+oZcZR+O6U2vfNK47p8c5QXHd4dY69rts7Pvx3+m69lPeH1DG4pr1WGTEbzV/lVigiqAvfWGvPphkE89PeoyYbTeG+UsuLAmW3YrUrhDTQ/SVGn0mm4Q/eqcINFdwabC+gKZXdYT4FjRVcBrEneWfW2qurwSYpIECiLbtiTCvVLhyKyT/SFTfdHwh5lE5ArJv8i8sesuFZU8zSXyGeeNwTGv7YN00AlPHJzR0H4zGdafATkrpb1Rb8PSYx6OhyWJ1LRBgjS8bT+WvK9l9ZLevNKRmfw0TyyaSnZrNOyU1bJm1hQPNB6hvr/fJvzTaG9kyawsej4okw00v3ORj9AWomlnF7IrZlE4u9VGnz66YzcKJC31lukZlK02dQvtPB6iB2/R90hLSKH27lHtG3INdsvsYirNTs3n9vteJi4mjuqSa+vZ6tu/bzl0j7kJC4uNHP6a5s9knWK2fZ2r5VF74+Qt0dHcEMQ6XjC3hy6YvfXqu+v43/OkGtszaclKa3Y+nhxa1qP0QzO3RaFX6BpHoRCqlVANLTnWzZSPLkij3lbXjkl5o+RWQ0Md4Bd2aLoImx5FjAGLvOSIEb0iK7/+S2kWr1Jekgi1iDo56f2maLVus5HtF5iOOF5PiD7y23ewlOKqgg364PRqqyXtPLnxA6LJaM45dpmavFdcQQChF3grY84wIKkP0Dn0ETNZ0H/gzKRDv3otcNd5HUBKftxpPBDIRWdbE2IpFlNNJZtDcaEo8rd2JPtblSM9Xavm3yLoafKYD5xP9Dn1bO9Vlxme6ReO602MnK66b/o/7qNlfQ+HgQp699U882DMTqXJksO/QvHwB1gwBPr3kaofam5Elmf49z47su0zxflZyTRUAMbAVIn+VYE131IV/NmwZdDf6zxtaTaP7pq0TxWLayNfBcVQA4p2zYfBC74Kg2z//0BLg3KUiWxpG1rRcZHNdLcFs7rovrb5BVAIFLlh17BcAOmBb6vtT+GJAGbE9E6Jx3XdsJyWjevjwYXr16oWiiBe5oiikp6dz+PDhkzF81I5hkSiv69rqmL92flj57uppq4mV4ul0duJ0Oyl+tdinoTXv+nnESynES6mYJDN1rXVh56trrWNi2URGLhrJxLKJ1LXWkZmUyRsz3mDDrg1hJEdLi5aycP1C3992p50Vd6+gfHu5b9uKu1ew8I2FLHpzESoqNz57o++aMpIyONJ2hJGLRpK3MI/y7eXcfOnNXPmHK+k7py/XPn1txEzuOSnnUPxqMf8+9G/fnFLiUnyEUaH7u1V3WLZ59bTVmGTT1yrhPSYNedSi9gOy0MxpJIDRpSWj5a0MWzmXtk3G/OG9yFo3jHnXnwnQ9wkgvZC2TkDTQU+g2bKFdMEHM/2stSGfq5j9ZaaRsgMgzn9VNZKXTbzVmYIq2wQI1EFq/ip8oBcij2c7RwREujaq9xriza3eXlyXYLFUYv0BnTnZW6b2f+LYwL4tW7Zg1LTXins0pFRkeQc/IUrwjALOpIFocWejmZOJN7WSEGM/4ayiSZGQnUfFtb95mVdf9XPY9wKa5ibRdBS66jApkmFm1Ef8pDP+Rsianuh36NvaqSwz/k+waFx3+uxkx3WpiopSPSEcDEqykIYavCAog5imuDgvNRuTYuxPUZ2A6j+mZorwU8PKYdwe4aNiUgSxWmONALKBbSA7ZwuQqIPjYy3kDZgBO24X5/lkoaiasaaLeTtbxWLcoLnhVTA1U+GcG8DaW7RmjNstFtN2PQ7tuyNXudhrBRleoJls4XO0ZjCwV18yzA6SLW0/6BaB79rOGDKlM4ma/UzVRjOal6fVbpgFrG+vDyoNSYlL4dye53J2j7Opb69n7FNjyUjK8H1md9rJSs4iJVE8B7c7lsoHKqlrrfNlMdMT01n2i2VM+csUX7Zzxd0reGHrC0waOomxF43lwRUPUjq5lMykTHrE9aBkZYnPYa68eyVpCWm0dLXw+xt+z6JJiwC4belt1OyvITcnF0VWKJ9STlNnEwvXL6RkbInvfAD3jro3rA92b/1ew3vw2dHPqG2s9fXdTi2fSlNnExaTxXB/h8vByzUvU/lApejlkGTs3XYuW5jr059dPGkxkiRhVsxkJmZiMvl/QqqqUt9eD06NdfetY/7a+b6MdHZqNrEWK2lJwc/wTP2uwZk9t6idOXYyCGhipRakXY+JICZxgCgX04l2zp8eJDvjE50/f3oY6YWKGTmUxClvOZLqEkGTrjkasPKu5q2mS0smTukQDLYfPRqeucxbCa4OX1ZS1mULpL60SiLjZ5K6kToPCEZgveTMXmtISkTecpGhDSRc8l6DSetE2nRVADnIevjxk4J0KfD42MxgXdW8lfDevf4+3MDzjdpgLPeAhvT2FSjWDJRBc9ES+ome2H8/4gfAEbKK8aZWpE3hwa82+m3k9+/z6RsmWzNoVzNo9ej3ySEyqYEge+dstILNqKr2nWZNj2Ud7iSSQki+/IA52kv2TSwa152Yhc7tZMd1ZrkzcqWJqw0+fcqfHXU2kbR3MZ3n/wYtNi1Yakuv0rCmC7Ki3GXw+UtChkZzicU3jwc8TlBsosfeUQ+mWNg4OvzC9WzsiHVeaa8m4S8ddcK/DSsHS5r4OzVXAOpAkrm8lYAEyYOMry+xP3QdEvMf9aZ3Ma1W6MAeCxzH9BCkfLq8jjUdBsyEtMv9c5ZNWDdf7ZuLT/fb4HmeSXYmzy2SSZqmfWsP3NjYyJgxY6ipqfFpC+bm5vLmm2+ecInId60teKJ2JmgQGlmkeen9kKGaoI++9qiPHReEk9s6axtWNZF2rYE+c8IJYPY//jlJpp50aq10uTvZW7+X+WvnU9daR+WvKyn4QwEFAwp4cOyDNHQ0UN9eT/n2cuaOm4skS9hibJz/8Pm+8XJzcikZW8LAzIG4VTeL31zMbcNuCwK6y+9ezvRXpgPw+PjHg4SulxYtJTk2maGPD/WNdVHWRfSb0y9o3rk5uZTdUhbENrzqnlVMe3maDyjqxw89Zyh2p53DrYeD5lF+ezmlb5UyffR0lmxcwuJJi9l9ZLevRDg3JzdsfivvWUmfpAG4XKrhc1j2i2XMrphNXWudIXvwmfpdgzNjbt9XbcHvk46qj801kME3v4J2pT/dzhOvl0+xNKCs9fqkgiqxeg4iO/lBcTjAKtgE7xf7tUe9212jt9HhShKSNHpJ7icLxUq5Po7O+ms7Dy2mB5qmIeERvZaOOhg0Fy15kOgz1TxokglJMiO9fVnYPAJ1Xk2KRJJ8ENlkFUDbnODv4coqhCGLoLtBkB/pmYHAcjL92oaWBQPYEeuM97tyq8iYyjHgcSAYhT8TmY2aKcH7ZxUK8GqvFQGh2y7G8BJcGZbNBZQyB16n4TMLtLEfgrMxmC04v4IWb0lzsqUN86bhx7yXp8v8iy7HLzP+vuuoRuO6U2NGczvZcd1ZsWbMG8N/c4x6ExSr0FwO+f1r8X2RKkf49VET+wMSfPCA8LuBC26BpbUj1gnAGbiwNmqDHyQGnn/4q+L4QI3pYcvAki7Kc2OSBcOv4wjEZYn3gpG/jM0Qkl+OuqASZsyJ4vre+5UYd92F4rhI75WhZaKN4av1kP1Tf9Y1qxAuegR04qkIPtk1ahvmxKzjftdOF7v4mfA7+Ca+7qRkVAO1BQsLC6PagqfQjCivE5Rk5l0/j50HdgbJrNikJDxoEYWHreZYvmwPdo5Li5bycs3LqJpK+ZRy0hLSGPPHMUHH7jywk7Jby+h2dweNW7O/huJXi9lw/wZuL789LDuqa7iW3VpGrDmWLldXUDZ1avlU3pjxBjOvnskv839JQ0dDkIyNDj7TE9LpldDL119rUsyYZVNQ6bI+l62ztpFuOYukXj2omlWFw+mg0d4oymWuLMbutDOjYAZ1bXVBJcJG+rN6X2ssPQz7Uqf8ZQqbZ25GlkxRGvKofS8t3tTqlxwBX/lqwuhKPEqvE375BvUw6qWyx+rvdBwRGdWWnUEBjiSZcHs0NNUjSIN0C8xqNtbA/nK0ix5Bqhzhk0RhWLlYKZdkpJZduJMuodkRB3hBmcE8TJKDZAu+QEO19EB2fCmAojVDBD4JfaCrDuwHgrMKus5pQJCn5Vcg/e89wefRy850gO3NeqB5MxfOluBAb+QbcNnfRf9WYIZCdfiDKz0boQd2RmVzQ0rhg2K0/ArDrKIqGfedEpMEW8O/E/GjttHiSRSZyxHrhc6qFzSrtpwzInPp9mi0eALB8g/XZ0fjutNnJzuu+7yjmfOGL8e8LaQn88MH4ZJSw9+/VLDJz767+bpwcGavFX2jodvsteHbPiwJ7xW9/GWI7Q1v5wfvu2OKqOrYdLXIyMoxAqRqbuN3gckmxh39NnQeCJH1KoddvxVAu/Pgsatc8leB6oH3pwufGFganFPkB6lgXAp8gv3soVJdil6dE4EHIGonsfQ3qi14+szj0UQztwSo4FLVY+o16RTooXqhHtUdBraWbFzCnGvn+Br7q0uqDXsnbDE2X+9EYNZx+d1CYqZmfw0pcSlBZSk6IB3QawAtXS1BGc6lRUuZs3oOceY4br70Zh843lqylWW/WMZTlU8xffT0oHNVTKsgO15kW1tdR3mz+E06nZ3EKDHYu+2k2FJIUJJxuVQsio1Oj51f/OUX4ZnSu1fiUl3Ut9cfU382IykDVVNp1xoiarOqqkaclIjnBxzwRO3U26lasY1EQCM56oi3WEOC/sgWVHYZqCMaCFp1s2X7s5JDSoUeausnsHM20mX/AOLCyXu8Uivqle8gaU5A8xOLeOfMjiJ/NtOWjZK/ih6xWXR64pFkJXgeqbkwaC6S6sTcsZskWw6tnIWiOfwBjr3WNxaj3xY9soHm0zl9CyQJuo4gue3+cl79PNZ0kaXUXMHkH3nLBWjVSZtABJaOuuBgLXepICwKkaHwkYZECLpIuhCGlKJaehPvaUU2+b9LAIqn3UDvtVxkjY8XxIWC5vzVJ/Q9gajW6am0aFx3+uxkxHVvzlhPiqkbt6eRWhecO3oTJsdXotJk9xJcA+cgq2rwIpy+IKY6hXTMx7+Hz1809hMnuu3QGrhongCgcWcJsjk5Fjq/MPY9coyfg+CDYuHnY3sbvwu8rOdoHgOJsyKhqappYr9RbwpwfmiNV3rrbSRnswCxH82HgQ/BxY+JEuZAnenQBdMI7yUVM8pxnqvR4q5cPd63kBe1cDtpQFXXFozamWGhTi4QKEUSHm5xHw0DW0WXFzHpuUm+7YHgTTedxTewd+KirIswK2Y6ujuo/LQSEGQMCyYsCAKky36xDJfqCus7nVo+lbJby0CCiX+a6AO4JtlERkoGf5j0B0b/YXSYZmv1rG0oskxTVxOPrX0sDMyunraacxP7Udd1AA2Nv93+tyB2vdrGWm549gbeKn6L+1+9P6i3tXBwIUWXF5ESl4LT4yQ5NpmRi0ZS21jLuvvWnRTG4KhF7Vubpp6yFdtIbK446pEtWSc8Tii7qybHoo3ehklWkfKWG7MzNtb4g5itE4OIbwz7DX/0O+g+grR1vABUkVbnvf+Xtk7ENOotEjyHkHbO96/AWzOEfIHjqI/MSfa0k2Cxi2DJaFxXa3gGOG+FKKPzlhuT0FeMmbdcEH6cP0OUrlVd48tuBgPNSaJMOvB8kRg0Q/fTP0voI8qFjZ6h/UuwpCF3f4Xi7flVbNkk51fgsfRGfnusuBd6b5vbLjLSgZmLgPH0Z2MYqG09sUAtmo04tRaN684s+zpxXVxMLGlqHfLGsZzt9Tntl/6dz+1O+qQO4NOMO/nVC9PZcOeLJOq/V6P+9rzl0Paxv10g8HetbwtkDbamG/sTUyxsvcNfOmtN85Pbhe7rtvv9vL1WAEdTkigh7m7w60APeliA0IIqkEzCFx1c6+8t1VThUwN7bPNXwcXzUc2JyO/f728fSc0Fj13I5Oj7Dv+n8N2xmcHzDFxM1d8v3n72Hsd5hlF28a9vJ01HNWpnvimKhENuo11rwK61YpOSgoSHY7ylI4EWyqirExMFMs4tv3u5j9lXL7Hdc2QP5/7XucypmMOG+zfw7kPvck6Pc8JKf6f8ZQoaxtnIPml9cHvcZCRl8Pj4xyl+tZjLFlzGlX+4kpauFjKSMsKO6fY4aHG08Njax7h31L1h5brjy8bTqbVyuPUw1zx1DV+1fGV4blmWmTtuLslxyWyauYnhOcN5ZNwjPu3VO/56Bx3dHb45zF87P0xjVi/LiVrUTqk56k+ZHmSHO0nIwoSyue4v/9psqYHsrs1dcbQ4ElE9bnhvughArn5HBCq7lwiQmlUo/o7NhBHrUEesD2KKbZX64hq1Dc+4z8W/SgLyR/N8kiyMWOdnENbn7vTLZumr9NLWiSKY+dcccWzeKnB3iIxg5Ujxr7sDRXKLTIEt26/p5xWMx9nmP37cbsGKueu3/v7Q96bB2vPhnVtBMqNdUuolSzoigsBIJdC6PINux9rvqupw1mRkcUzeihDG5XLRH+Zq8xNTeceStk5A0brEtsYasUhQOVJkjyXZUPtQy69Akk2CKThCoCbKqI3ZM02KkClKNtcjO74S98R73A9d6zRq32/Tv/splgbD30ekuC5FcSNvDdaeTnj3ViTc7GxsYuii69ixv4YOZ5f/92rUBlA9SSykWXqKdoFAP2FNE60GgazBO2eH+5PcpXCkWnALXL8XkgcKLdP95eE6qfmrRJ+9vhiZVQiWTAEYN43x60APmgOH1oOnQ2ROX+srtvefJsatHAmeLj9I1a9n60QwJyJpnmCOg9BFPmuGH7i+8/NgZnJHHaolE9do8X5RC7agWXoKP6QdOzMRZRf/+nbGsP5G7bs1o+b8QIIfRZHo6G4PY/UN1Uat2V/Dko1LeP2+1znafpTMpEwsJouvHzSQRAhgzc417Dywky2ztuCMQLluNVkNs5EtnQKMzh03NwxwTvzTRMpuLeO6p68LOubfh/5N8avF/POuf5IUm2R4vm5Pt+8anR6n4bnR8BEpZadm8/av3+aGP90QBrJLJ5cysWwiNftrmF0xm80zBXNlaFlO1KJ2ykztPmUrtm6PRntMfxJGVyI56nwlZeqgeSel51CVYlAcdSK4AMHEOHgB2tAl0N2ApBN0GJSPhvYbpsS2iaxmYLZg2DIRWDnq/P/XzZYtgJeeNYw7B8zxoHaBu0ts10t8d0wRPV3dDSKYc7cFl8Re9jcx5v5ytCGLkLqbRZCUvyo4MLRmgKtZZH0DMxoeZwTWXkRQqPeoGmU9bNmChVgvQ/ayJmsX/QbpnZ+JYFCXs4lJQbNlgxSD9PblETPPkqYZM3U6m3xl1lrBViTVAe17kf73HkyOOpLyVuOR0ow1VdVuzDsfIGnQvKAMaWgWNSyrHs1GRO17aserIDhWXGfC+D3Qv+fZfOGQfHHPF41f0ruxXCyeSUr4MdYM0QbQ3SgWry7/h+hDl80gWwFN+MNh5X5fsOu3YjxnsyjZxSSOrRzl/w2PeB0GPQI627s1XZxLw9/LOuQpOOsnoHWHA87qSeIcVdeGbL/Bq7taF7mtwV6LJCnBPixUwisQuNprxbthaBla4gDcWOhSk4mlBRkXUute2DVfvKuuWINJ6ROxwiPKLv71LQpUfyBmRPYzvmy8YIwjEbvWGkZt3ju5N79743f8865/0tDRgC3Ght0paNNvL7+dutY6ym4to3+v/rwx4w2a7E2kxaf5ZGUC+1DdqhsZmXX3rcMWY/Ntr2ut42DLQVbcvcKnn6rL3vSM78kXDV/QN72vIeDs36u/bzy7007P+J7c94/7qG2spaGjgYaOBkMQqqqqb5tJNvnAuQ6K+6b35WDzQTKSMqhtrKW2sZYjbUcM55AS5yeWqGutQ5ZMxEmJYWU5UYvaKTNdSzRC6eXJtm6nikfpRbzFimzJQv3xpSetb1CSTP4SK2sG5NwGVdcgGZTCHqt8VGTyXOHZgh1T0AqqBKGSpWew3EvuUqHTN3iBkG84f7oIqryyK0H9W/ZasUBQPUlkeUODqnd+Js6jqULCJi7LW/7W6/ilu9WTRCYiEJDq8/tgJgycA6Mrxdw9TgGKAxk3AwG4txRYLdiCigWTNUOAZZ2g6dNSJP367LXGvVhZheBqDidmsqTAR78V37VB8/BoMmZdZsdrcvV41IIa1JBAjdylsPMhOH868q55xP/4Gd9zNCoVpmaqCEZ33C6yGyf43Y72t0btP8mO1894rLiuh6QYvgfMJiu/X/8YS4uWsmTjEpymZFwDH8G88yH48cLwXvzBC/xsu7o/2XG/WCS66h0BWAN9gb6I5Dgqjrt2F5h7gClRZF87Dwr5q389JGS3Bi8QZbs68O064AXNFnC3iDEitWoYAWt7rQDIP3pcZDeNFu5Up+iDDZx3qIRXaHWKl1RKGvMuipJAvHoUuSpkQXHPs7ClMOg9ZORzdEmzE2EXj1oUqP5gLJKAtFt14ZDbcHocPlA2sUxkL1ZNW0WjvZEuV1dQdnHF3SvISMxgwYQFxFviOdB0gJd2vETJNSVomsaDYx+kZGUJa3au8WVYY02x7GvYFzTOsl8sw2ax8dzm55iSN4VNMzehqqJs4oHlD/iOf7P4TWPAqalB4628ZyULJixgdsVsbDE2SlaVhJE7vX7f67hVN9Ul1dS315NoTeTeV+5l2S+WkWBNCALLOqFTzf6aiL25dqfd9/+KaRWAhkNui2ZTo3b6zJoeBgS+6xXb74otVVI7BcgaUgpJAwUTpL02YolrpMxavKkVqfuo4TGaBu7YvphMssiKqk7Ra/rJYjj3JlH6NaTUr91q1L/l8LL62mtFABSgSagTckjdRwFJlKkFHp9V6C9Bi1S62/WVEK4PHFfPKA4oBjVBAO3uBgFWR70F3fVCg/Cdn/uzpt4+MgmNbi0eZdAjSKEaiXv+JHq8bNli7qE9wj9eGCw1oWcxhpahnf8rPBc9QbvTRqJmcL+tGSg4UC090Qo2I3XXi8BVv5aWnTCkNOg5RioVxtkMgxegWjJP6Lsd7W+N2n+aHa+f8VhxnUuyEBNGdraMdpfHxxsy59o5THpuElddUEDp9QuIU+KQAnWoB801ICia4ieds6RC4GKUvVb4yWHLxN8FVaKMt2N3uP6pu8N/rA6AJbNgAbZli8W3j7zZ1tAeURB/ax5DkjtiUoREWExKOOFb7lJA9vthfd4flkB+BejXHqk6xZyI3FUXfry+oOi4A5Ps9pVoG/ocqW+IFFfU/xzLokD1B2KRqMtVzUP+kyMpnVwa9nn59nIWT1pMwR8Kglbsbnz2RqpmVnGw5SCyLPPSjpf4+eU/5+rSq4N0SWcUzECWZOxOO3aXnZ8t/VlY6ezbxW9z14i7+OlzP/WREungU9/vwRUPsvyu5T5Sp+zUbJbftZwHVzwYJhfzxow3ePqmp3F6nNS11gUJYyuKQqezMwiMLr9rORmJGUGsw/p4U8un+kp7y7eXh81h9bTV9ErIZP8Tn6NqniBwrX/W5erErMREgWvUTp1J8n/sim2gjqUkyyKjOmiukHIZvNAfGByDddHIZJwRSX6QZLrUZBIce/xBig7alFjxd2ymyKQa9W/pOn67nxGg09nsz/YGlNpishmUqU0SARmI8WN7izFyivyAdH+5KKmOzTLW/nPb0WSz0IHtf69g1VQsYu7t+wSIDiFJkWzZxOVXIO16LGQ+N/rZLnXyqD3PimyDpkHHfnF9RsDRZEPaOgFt9DbxDGXZMDsjVY4QLKP6vdGZNfVxrOlBz/FYhF18UIx6ZU0YK7HRdz3Kthm1/zSL9N3Xfx/Hiusm/+UeXr35cWJ0Zm+3nWbNxu8qn2XVPauoa6vzgdSy6+7G/NFs4Xds5wmAqQp2dKPfupp4Ptq4vSgSwYRqXnkvqq4JXoz79KlgP+M4Ei5hs2OKAHoFVcLveRz+hUFrhgHD+DKxmBhYcTN4QTggNsULtmFTnH/hLvBdotuhNXDJH/3A2NrLoDqlXADawQsiLyi+lYfkBaSqJRO5MsTn7JpH0iVPo6meaFXHCVqUTOkHYjp1eSDZT8W0Ch5Y/gC1jbWGJEnTR0+nzdFmuGLndDtJi0/DYrJw06U3UfRiURDIK3qxiC5XFyMXjWTa36ehaqrhOEfaj2DvtvtIiQK1S3Vbs3MNsiRTdmsZex/fS+nkUmwWG0WXF1E1s4pV01aRm5NLbWMtHY4OkmKTyEzKZNPMTSyatIiUuBTsTju9k3r7QKp+/knPTWLRpEVhpFH65ylxKWSnZvPQtQ/h0Ty8VfwW+57YR/WsbaIPxB2HSTZT8IcCnxC3Xn7z4cH36TMnh/wnh/Nlxz4UA5IQ3QIJERxy2zH3jVrUjmeBxEQt3Yln/IvQpEj0iO0kmb2YNw1HWXsecuUVSO17YN/zIjDQy7hAMDvmLQ8i4fBnjcNNJcZP3JFVKMpdr6qGURuQ9ywhQa4LIw2i+kY0k03sH9PDXw4baPZaiD9PSBvk3CY0CfX+Kv3zmqloQxYLoGevDSZaGlIqSt4u+o0AoR//TvRt6cQkHxQLZsuj24UWqwFJkTv5EjTJAkMWC3bMjs+h+qfwxStoyT9Cy18lwH4IyJa2ThCBaej1JA4Q/9+9BLVIHmp5AAAgAElEQVRgC56Bj+CWk9HkGJFF6TpsSAaiy0SY6MLc/i+k7obgZ2SUnamZKrK8AeNo1oyg59jhTkLNWx1OzvLJQpGh7f7K+53JwbxpOEnaPkNCpmNlp45HWBO1qJ0OM/ruB/q5Y8V1q3euYdprf6Altg8HXCa2N3dz+8onuHrgWJ7Z9Aw5PXPITMqgbPyDmD9+XIDCD4ph/Y+F73G1+snhAs2WjQeZBnszOBqCiZQ8XSLTqLcUDCsXJcDnzwgeI1LvqKfb7/dMcX6f1Vjj6xHl+r1CJ9p2HvS9XSQjR70pQGVY28QN4DgsKnHeygMkMTd9oTPkuvB0inN3HRb9tB/OEj66oEqcW4kTPlOJNT7eywKvL4IpOIKvMzVXtDdUXnFcfxU1v0WB6g/EAqnL9z/+OVtnbaOnLc0HrgKlZXY/tpvSyaUs2biERGtiGBNwdmo2Hx/+mDF/HENLVwvn9Twvoraq/v999fsMx6lvr2fKX6ZQMlYEK02dTYb7HWk/QnaK2F6+vRx7t93HwFv8ajGPj3+cwsGFJMYmMuaPY+j7UF9GLRqFy+2iZFUJ0/4+DZfHZTjPho4GesT1MDzvOann8NIvX6LL1cVNz99E/4f7U7C4gAb7Ud9+kcpvAq9/fNl47JoxM6VOiJD/5PATBrZRi9r3xfSSTFPr+wI8BQY5nm4R5OyYAgl9BMNwViGcd4uQcBlSCldVo42upCumH/GmVkOw0eFOQh00D75aDxfNFcHIW3mihLX3WCRdiy/Q7LVI3UcFyPywRJTWGgUnnQfFavyOKWiaahyAAZpiFXP/0ePBQLS7AT56VOx31jgD0pAboe8d8MH9fvDoZTJuoR9oINv3wsYCWDtAZCp+9Dgc3Yr09nAkSzoknm88L2t6+PV0fC5Kagf/jlZnio+F2a1Z/OXAoUydOnC0ZQs2zfemwYah4hmN2oB2/WdoiQOOPQcv8G5XM4IWVnQGZ7Vgi1hcGFLqLxUeNDdsgSESC3Aktk1NjiVJ23dCYDdqUTuV5vZodJj6CVbZ6/ehFmyhw9TP9/s4Xly3tPpFxj5XxHtH6+mVfjF3XHEnc1bPofLTSlLikqj+1SuYZSVytUjnV2ELguSvwry3jPTEXqL0NxAcmmzCfwf6uPemCfKl824PuDB7BF96wH/+UD1mb48ozmbR1lA5UvjwjaNFljRC9hdLin/89r0w9CnoMVi8Y0J92GfLxPXqxE665I6zCb5cCbIirmvbTcEswIE+MODcWigruwGrcpS1/PgWBao/IPN4NKxqok+SBqQgcKZLy1jNVgZn/ZglNz1DakxG2Ird0qKlLFy/kIykDKwmK3uO7DEEeU2dfqmH+Wvns/LulRHHGZg5kKqZVcRb4ll+1/Kg/Vbds4peCb2Is8Qxc/lMFt6wMEjbVS/TXTRpESUrS8LKi0vGim2fHf3McJ6HWw/zUMVDrLpnVdB5l/1iGfZuO2nxaWEZ4/Fl42nXGjGbZV/5zbGuv7axFrcnuH9OVVUcchttaqMhIUIkYBu1qH2fLN7UKvppIwU55gSvHIlGC/1QL3lavOwPrRHZy7fykDYWEEddRLDhAzv9pxtmPDHZjAMnXVc1pwi+WB4etA1bJohA9LEk4wyEpDpFae6QxeEB4daJ/sxmpB5VZ5MgDRo0zwce9Uy5giNyplIP+NCMQZq1V3iwtWu+YDFWLEG7d7iTUEesF5lRczKMegtt3B6RafjXHHDUiYWED0v8czm0RiwGSIof6IbOIfYsXxDervSn2xku7+D2aLQ6U1Blm/huNNaIYxP6HbOHL2z+BtkpTXOfMjmnqEXt65hJkYh37xXVJa/1Ra68gnj33qBFlBON6yyKlYt6/4hXpv6DDx56jzTPYZSNo6Dlo8jVIrIJkP1ZxSGlghjp/PtExYSrJfg4Z5Nh9QZbJ8LAB0VG0ZYtWiUu/3uw78lbIUiWdNNbNQLNli3Kd5Mv9i9oFlQJX6dYjfeP6emrnuHLlaC6RbZ09zNim774tXsJZP8UDm3wlxEHLigOfND/7gjM8F73f4L8SZdNCzj3gdYGjg4JWNSLcJ+jrOXHtihQ/QGbUdnI6mmriZdSfE7P5VI5J74vW2ZtobqkmtLJpT6Cobnj5nLjszcyf+38sLLhZb9Y5tNWBcGIm5GYQdXMKt596F1ev+91kmOTWTBhAU/e+CRX//Fqnz6pIitsnrmZvY/vZfOszRxoOkC8NR6P6mHNzjU0dzYbZjA1TfOtJAZu15l556+dz4q7V4RpwA4+azALb1iI1WzlhZ+/wN7H91I1swqAX/71l9S11hme72DzQT5r/ZREU3LYfQy9/uzUbEyKv+9KUSQ+OvQR+U8Op7bxC2NCBE/UeUXt+2mWGJnU2GZ6WusxyW5IL4gc5FTfKLbLFtweDU01zloGZUUDwIZe1ploOoqkuSOUnDn9K+ypuYKRd9Sb4DiKtP1WEaikXyb6Nb1ZXEa+LoIVyfsazSoUpWOhK+3DysHdKUCbu+PYWcUIJWmaNRNt9EY8MWnhN1PzGI8Zk+IF27GCHTg0C5q3Amnvc2gFVf4gNEDyRer6KhysqQ5/tnTTVWiaB3fSYLTLX0Yr2CyyzofWhM9F8xgCRS1/FZKzGanl38jv30e8ey+WGDmoDFf/O9F0NEi70DVqG24pzvB+GfUqG2nrtkp9kbVjE9ZELWqny3yLeF9jESVSXBcnJfkAbbLcKfSh7bUiCxipWsScBJ1fin1UJyRe4PV3mmh3MCcGH/fJQkjoY+yPuhtg+D9ET/7/ToMPHggGwEpsMNDbX26g77xMZDO7DvuB5M4SwXSvacb6rWj+6pmc28TCor1WsLV//Htx7dZ0sVhY+084d5LQndYlyALnb5Th1eV5Bs0J8a8ryUpK58//foftfUr5fHgVbXKPE/ZXUfNblEzpB2yBZSNujyui9qfHoxGvpGCLaaL41WIfmVCftD4+puA5q+fwws9f4JyUc6hrrSM2JjZIW3Vp0VL21O/ho4Mfkdcvj2ufvtZHnvR85fM+wqOmzibmr53PnVfcyXVPX+fruShZWcITE57wZUCNCARcHpfhdj2zmZGYQYI1gTdmvIFJNmGLsdHl6uK3637Lzy/7OU6Pkzv+egdvzHiDjw595LtWvRw5dNz69nqKXy1my6wt9ErIpOzWMmwxNpweJzaLLej6V09bLe6tl93NrrVS+EzhMcc3KWY4tnZ01KIW0c5UKQ5LjEyC+1OkqhC22UPrRZBgEORoCf2QrOnQYUcKJekBHxtj6HGyHMy6yIh1hsdq5gSkQ+sEmUd3k7/8Vp+bqx12PyWCmQ+KRQDklUbRwaU2ZDHSxoJgchG9xM3T5S2r3W88dz1Q/GRhGGmIlr8S6f0ZcGgNZls4U60bC2ajMd12f6B2aI2YayBrcEwKfLoI+v8qmMFSP95Rj2zJ8j8zpREplBikaizS6Epx3ce4v25EdtYTk4Y0eqOQlZBkpPemi7l5SVdkk5UEzx5fOa9iy8aUt1KQPnn3U72smW6PJsrGvwbDtRE7tWo6NmFN1KJ2uux4rL9GdiJxnaS5gsd1NIiFufZ9oqLC4e2HV+JEf/zghSFs5StFS8aHJX6yOF3WSrYEM5mDv3/TkiYyn446f6ZV/3z02/7jsgoFsRGS2C6ZxP879nsvwASuNgF8Y3qIeejHjdogyoO7Dot5DX7Cd9/YMSVYhuascX4Gc51wLlCbO1Cv2VFv7Ls7D4oe2NRcKNgIqgvaP4P37sXkqGPm8OVc8cJ0duyvYfzgQlbcVIFSPeGE/FXUhEmapp0Rd6exsQNVPf1TSUtL4OjR9tM9jTA7E+ZlNsu0eRpxeVyYFBMxcgyXLbwsCGAVDi7kiQlP0OXsIjYmljZHG4nWRB6qeIih2UO56dKbuPIPV/qOeW/Oe7R0tQRJyCwtWkpaQhqfHf3MR4QUa47lpR0vMW3UNP7x7j/46dCfBjHwrrpnFVlJWRxsPcgNf7ohSAJndsVsMhIzePi6h8O0Wn+77rfMuW4OqXGpuFQXbV1tJMcl8/yW55n8/yZz47M3kpEkpHh0VuBQ6ZrPnvgMCZmch87z3YfcnFxKxpZwcdbFxCjWsBdFu9ZAnzk5vn0fH/940D3QRbtPF1PwmfB9k2WJ1NT40zqHQFuzZg1//vOf+eyzz3jooYe47bbbvtE437WvS0tLoLmpQwC0kABeD/BPp6XGNiNXXhH+wi+oEivZG68M+8w1ehvmhCyOHm2nZ1yLIFkKlInJXQq2HHgtxy/DYk1Hiz0LqXKEf7zzbof+dwfLreQth6PvoKXnIbnajUHb0DLBpJvQD1p2+YO5vOUQkwptn6IlDkB6rU/4BRdUwaG10O8ucHWA5go5/woEyUeaKEuTFLGPs1kAWHenAOGaR9wfTcWtpNDcKcCfSZFIYh/y1vHBgaSrDf41Gy77q1/WJ/CaRr0Jm67GXVCD4vzK3+up38/dS3D9+Bm6tGQSPLuRPF1eQpIQu6rav13XXQwA2mr+ajqUfqKEMVA7Vdd31bMoWYWCjKpyVPhch5QGBbWuUdt88g6BTNHfhOHaJ1vzNX8rJ9NHnmm+7mRZNK47vh1rbsmWNsybhof7w4Dv/zcxnw/WWy2CJLdWQkyyWMwyJ4vyX6PfZMEmaN4JzR/DWdf6y2L1MQIWl8hbIVh8QbCSdzeEa0LvXiJ8h7tTgNnu+nBZmd1LYOBDwkcGLiYGAkrdX3xQLOZx6A3YFVBSPOZd4Rtrpopql8qRYnv+KmNWdd33ZBWKrGmg7x62DBQbvH+feB8UbDK8V9v7lHLLS8Wsnraa85L6ESe1nBZG/jPhd/BNfF0UqIbYmfAgjex0z0sn/NF7KXUwZTVbGfvUWN+2imkVPPrao0EluIWDC/ndxN8hSRINHQ3kLfQHOx8/+rEvu6pbdmo2VTOrGLloZBAQbe1q5eweZ9Pe3c6jrz1K0eVFpCek0zO+J79f/3sqP63kjRlv4HA5SLAmcKj5EKqmkpmciaZpzF41m6LLi3yZ2/Lt5RRdXkTxq8WUTi6l+NViVty9gqykLNq62yhZWeLbX9VUzut5HodaDlHfXs/C9Qup2V9Ddmo2m2dtxu1xB8n46NdRPWsbGoJwSZepAejQmjjQfMA3FsDccXMZkDEAs2w57XI2p/v7Bmde8LZnzx5kWeb555/n4osvPqOBqqvt0HcS4JwM62mtR3qtb/gH1+8T5WAhWqVafgXtSn8SY9rxuLqQZRlpz39D2uVBEi7aJX9Eev/+4OPHvAsbLhXj6yvmgav/1l5QtxmsKSKAikkBo7kVVAkAW1AFrZ/45B6w9BRBSmMN2k++CAbFIIKZS18Q5XL6nAbMFHP0dAtyDx30XvY3AVQ9XYLpWL+O9ALof09QYKflr6RdGUC3UxVAzdyKiW6QFDySFdndjFw1Vux/5VYBfEOlHUyJqCh0mPoRp7SiaF1ImioyBLufEv2wUl+SYppEUKsHf6HXl7tM9Krpz+LgWrSL5qKqGorZSnNXPPGmVsPvoy8I1J+NYjUGwwVV/oAS8Iz7nKbu1KBdvk0FwTcBu1GgenyLxnXHt2PN7ZsuohzPLDEyCZ5PkbpCZGLAvzC3+ToveVIF7P5vUSobaLpPHLUhWFdZH6Ngs2gVaP8sYGFvpfC57k6hPx2iNc24T8X+YDyvIaUiYxvpM30x6/p9wucefA2SBwaD2FEbRAa2/71i4bFypBgrxMeEXWfuUvj8ZZGFtaaLTK5eVTO0TCw0mpNhbf+wIVzj9lHnCk9YnGo7E34H38TXRUt/o3ZCZtdawwh/5r02j6dueor1M9YLvVSXnZTYFJ688UnuvOJO5q+dT11rHTMKZtBobyRGiaG+vT6ozDWS/M3R9qNB55r4p4mU3VoGEkwom0BtY60PDGenZlM6uZQXt73INU9dQ+WvKzErZswmM7e8cAsZSRm88stXKL6q2EeKpGu9xsfE+/pYdY3Yt3/9NnHmuCBQu3D9Qp65+RkcLkdQ+fPSoqXIkswDyx9gadHSoKxoxbQKOpztQUB+/Yz1OFyOIMC/tGgpSzYuoXdSb5KVdDwezVciHLUzx/r3Fy8gWT7zW/u/ScnYqTJNMiMZlVBJsmGJqhqTTnz3Xqga79ffzFsBu37rL/f68ULQVLRLnhJlsnopl95DZa8NZlzUy9L0zEDlKL9Wn9Hc9P5X1SkYdB11EH+uCFR0Yh8pBvIrgjOTeStEQPPBA/459R4rsrKhwdY7PxNZTle7KFdzNov7kHRhcCBor0XaegPxBVvwKCkikN3oD2SV/ApUS6ZgClVVJMWC3H1YBFM6wDYnoVky0DSNBOcepKoJQQsDDF2CR5XBFVAmGKitql/fiHXi3gTqxg5bhgcr7W4bPcwdJJqOit+MNSP4evU+WvA/myGlke9/wN+aHBP0nfIF9B/Og5wiFGs6ydYM2pUMQ3KmUDMqCY5a1E63uT0arcrJ18Tudqoo1gHEmZORjPpJdRI5e63Qlh61QQBLvfoh0CeG9m7qx2nucABbfYNfd3p/eXh5MJLwr50HI/fd6/+P9JktG1r+7W/R2L1E+JcPioU//mK5WKiUY4R0Tn6FuMYI2tyaLRspsH9fB+zj9ohxP1kIif1h73No/e+N8G6zYlUTo3HdN7QoUI3aCVmoBEtuTi7TR09nxJMjgkppZ7w6gzU71/iAmt1pZ+bymTxz8zPEW+PZ/t52Nty/gYaOBurb6+l2dRv2Zx5sORh0fl3u5UjbkYh6p/r/69rqsJgsLN26lM2zNuNwOVBkxVDrtWpmFdUl1fSI60FuTi41+2tQNZW69rowQNrl7mL9rvW8ft/rKLKCR/WwbNsy+qb3Zc3ONdS11QX12vaM70n+7/ODzrm/YT/T/j4tjLF4y6wtxEspp3W1LWrfHzueUPzptA5PKgl5K5FC+0C7joj/N9YElXnKBVuRHF+JfiRzoiCucByBIX8QmqOosGmMCLj0Ut6YVLHyrfdQ1UyNzKiLJLKetrNFr1beivCytH95iTLa94mMgDkZdj7kX6XPXYr83j1og38Hw18V4LR9H7z3K3+/l6POD8iGlRvPRTKJ66m6VgC7QXNFmduQUn/WwbuvpLlEFnBTcN+o9NGjKJf8ETwONMWCqqmCvOTCEsAmtBFVN9Lbl6OEZkntXn3VIaWYPygmKW81SKn+5/KvOWIuiReIfjFniwDYAcezYwpcWUOStg/eDFhcCC311ftowc+GaQSG9UUJ/Zhhy1AkDyZF8gXs8aZWAVIDsumSLZuE/Ao8Sr/TXu4etah9U/uuFlE6HSoxVqtxf3vgwpAORgfN9WdZdZ+Ymit8nSE4U4x9nMkm/PvoSmjZ6f+d568SfaDWXv7efqN5yZbInwXOzV7rX/xKvtjLP9AAOT8T97CrDtRuiO0lgLjqFnMIKGE+OmQprc119DWqJEEVYHvwAnC2op17C9LB/xHvn4DyYC2/gg5XtAf121gUqEbthEyXYNEBVsnYEl/2EPBlI0snl7Jm5xpqG2uZUDaB0sml1OyvITkumbbuNm669CbG/HGMDwC+MeMNXrnjFW5+4eagMt/5a+cHnT+QFOlYhEk6ydHgswYz+9rZHGw+SH17PQN7DzQEuE6Pk/p2IdJcPqWcP2/9Mx7Vw6Rnw+Vvqh+s5qZLb/KVKmenZrPynpXEmxPITs2mZn8NE8sm+uZRNXNz2DltMTZjhl/VDco3fz5R+/Y2YcIEvvrqK8PPtm/fjqKcnAd0Kkr8zAmZcMUa2FLoDwSuWIM5IfP/s3fu8VFV5/r/7r1nJpOZ3EMgXEoqF4sIiugxCAkCUcuptBEUwdo2IrVVPIipYA6iqCi1KDRSa7R6IOZ4L4TLT6AiRMJNSI+2VPEKhka5hEBCbpOZTGb2/v2xsmdmz+zhJiLqPJ8PH5KZPWuv2bNn5X3W+77PQ0bSOZARVi+Gq7aIviVJEUGDrATLsvTeppGrkfyuYPZRD0T2PgeDHxTlVhtHGonStolBQY3QDG1898gAZ8BM0ftpcUDTxyLwuHi+MJS3dxFlaJ3WK4EAyFMryOhlT8HQhUI8o20/eGqRKseKkrfwEmA9YNLJcvjufXo2XLJQZJUtieL8shW23xi1D0uSbVgJUzHuNJTXy9mkzgwr9swg+c9dAX+/LZiFiJadcAmFUX78XjDrUF/VmZlYJgI8v8f09RY8EKZWys4pxpLCkashvgdcd0BkX679WLx/b5PYOLA4IL4nfPCIyIAMKBTXbddspKGLSE2wiswMgKvB1AtS2jqe1Gt2Bo87w8jISPxaxo0hhjOF45XEu9UULOFVIPqGkg5dCClpAFz7kfBZ/tcc8dzF88WGXcTm0jKxph+vOsXbYBQf+r9pnX2elaKlIkxUztCjOqzMKO6Uu1L01YZmPkE8ryuq672jgdaHBECBbTcG1nd/4o/Yc1EZfdJ7YpFtKO4WetocaOHXKHuJ+DvVpwB2TsE1cj1xVgeWf8wQa3BIRZDf1gWfO0ZSvwpiRDWGk4Iuea6XrHZN7HrczKb+e9fErmT3yabR3cjh5sMR2cTZK2az4PoFvDnjTexWO7XNtbz691eZO24uu77cFSFelJmUyfLblxtEkXTBJP24Dw98yOCegzncfJi6ljrK3injyUlPmhJcq2I1ZE5X3LEiUA4c/t78mj8g1KQ/dv0z17Nt1nbDtdH7d+MUe8Q5XV6X6Tw+qf2EHsnN36iA0vcdK1euPCvnORs9qkeOurAofSNLxo66vrbzniosShrJ8n7k9gPGgCRnOQx+CNWWhkoclopsI+HRSd/W8Whj3jYvXWs/Gtzp1zO06dnG4KdnPtoPbwoq1oaSwX6/gX/eI4SILntaWLx0NAdKvbS4DGg/GhbglcGuIjTNZz6n5AsFIXNmGTOH9kxBen2twX4pPZjSy2VD3/c/CtFyV+AnHkVrQ+qZLwImW5og7rvuM16vrePR8iqRQBB3R6/g81HK3QIZFXsmWlsN0gfzxLn1vt6OFqHg6WsxL5dT/abXQEsagDpuX+B+pA2SOWAUgrriRUjsh6b50ZCRvfVBkq3Pz1OHP64nDa2i3yolzoI1ikehv8MTOO5MItajGsO5jkBJfGfVheIMqoYDJPj2IO1+uHNjLkMo5SrxQY9Se1dBGvf+jyB2sk0osA+aKzbSdHKqbwbau4rNpe2TxQTCCWxodUrbflF6G94C0bZfbB4m9BWkVfUCmhCiG/KYINGh7SE+F8R1g9Y9weqQEEE94nvCZ0+bb5qBOG7rBDHPMZuY8loRa375GOnvTSFNn3feJqNiuk6GB4jzNbiO0jX5B1hMKoJ8oytRFMkQ152rivznKmJENYaTgi55vmXWFjwdHnyq77iZTf33Hik9mDtuLtc/cz1lU8pMy4dDM6zLfruMBlcDsiyz8Xcb0TSNwy2HcXvdLJq4iG5J3ejwd/DSr18iM0nskltkC6/f9jrVR6tZ98E6brr8poCysE5ej7mPUXpLqUG5t/SWUg40Hojohf3bjL+Zvjef30dNfU1A0Vcv8QVM5eDRiCCwF3S7gPI7yg3KxMtvX84zlc9Q8UkFW2dtx843K3YTw3cD53rfnc+v4bcmIu8cG5YRvQGGFqNZUpDkDmOAoJe/2tJEMCUp5kTL14bm+AGM3oAUKlhkSRLZViQ0Oc4ofhRKBhP7iuPbDoCEUWFyWCmaHI+8dUxY8FMAw8qQVK/5nJo+7PQGLBfj/WsOXFaCljwQqekjY8CmB1OhAiGuGki5CO2qLSDZsbR+Iq7DoPsjS5U9tcYy4fYjMHiusHyQLKK31OIUQeCIv5pnbgEGzQ36LYb29Q4tFp6x/7gnIhhVc1bhj2KZ49PiQsS8NFLimiNKl9nxS7isBGnztUidwlEBkh2SWVEvuTwwdKsvmRR7pml/2LlQ7h5DDF83zMiPWWuAvO06EkZvBwg+16cAdtwsfj7vVqO6bc98UTkC0PwZ0o5fivVl9IbguKHk7NqPgvYz/5rT2VbR21idkrtCVE5Y4o12XpoKkgQ7CoKtD4l9wPUlvN+p3HvZn8V6t3VCUGG4/ag4R84yIdQU3w1aqsX6pFfDHNlqzLRanIJ8WxMFIfY2gCSz5ralpG//iXFNavrYXEiuc6MvPakHhzx+eoxYjm17cC32jljOg289zX+NvjsQ1x1v8yBGVs0RI6rfMyiKhEtrMqjQnmwGT/dT7ZAPc2/5vRHiQeV3lPPImkfI7pPN3HFz6ZshrBouyLzA1C/UrHx44l8msv7u9RxsPMhD/+8h/nzTn3HanPzif35hILOKpBjIaOktpWQmZzJ9zHRGPjEyomz3+V89T6/UXgGvU5fXRbfkbhxuOkzlzMqAYFJVdRVN7iZKbyllccXigLJwZlImjW2N5A/JZ/qY6RGiSVkJwkwbCVAJNM2HE1gJeGTNI4Ze1kfXPkrB8AKWbl+Kz98hxojhnMOaNWt4/PHHaW5upqKigueee46lS5fSr5+JSmwMJwVZMxd9wt4VTY5H8R40CvXo5V+aCkMeE8JJYT1BDCsDayKSXhKs9z/FdQPNK5Qge/xYKOFGOTfuWkFolfjI0uKdU5Cu2gyj/iZ2/99/QARArhpw9ITdj5mXrYWWpOVVQvsRNFuaMKq3OKOX4OpwZkHzp0gJ5wEuiEsXJXmhdjqGjHOIR6HFKTKtlzwBuqDWrqKg2nDeJjRNE96mnz0d7L1N7Gs+r6QLAE1kI/a9Egg0NecPafKmQwcn5W8aTfQrVMxF2nq9yAgPnCXe76dPoQ56KGIsv5yMElaiF/MojOH7AJtNJsH3Gcqm8Qbyo8ldTL9fQlRPCz4X2gLQa1xwPdVbCXTLsNC1rGWP+YZce4NYO9uPiu/rZ08L4itb4T+eBVuyOMbvFqq7oXZWV66FqinmtjmBtV+DUes6bbzUTsuvNvApgqSGlgTrczVbEwGhb3BN4Hg5dyWSSuQ12z0von9Vn2/CXm4AACAASURBVI+Wu5JW1cGoRdlcdUEeC65dh8Oi4PGrVDe38vj6hdw+8s5AXHe8zQPjxnIMOmJE9XuEaBYzp1Ju6vdrpNsyefCnD/LwGw9TPKk4QOSS4lKY+eOZ2C12Q2nuymkryR+Sz4I3FxjIbbTy4aOtR7FZbEwfM533D7wfUS7c5m2joNQojDTlhSmU3FxCny59TMd02BzUu+o5v9v5qJqKq92FhBThjfrU20+RZE9i40cbefCnDwYUhvOH5PP4DY+zaOIiPj38KZnJmdTU1wR6cbfO2o5TSTbdBLATJLAt2lFW71ptsO8BeODaB1h711pUVDxy8zcuYx5DJMaNG8e4ceO+6Wl8pxBN9EmzZ4oSWp10QJCEjdkoduM9h0XpleoXj3kOi8BIUoIBhf66rROM3nr/LELqU2AeaNm7gbsWTdOQ2utNAz2pbb+wUQkp+cVTK57ftxSaP0TL2wyaD6nxfSNJPbAaLnkCzd4d1A4kzRtdPEQXG9JLot/9Lxi6SGQKBs0VapPRyHbgdctEJnnQHNh0dWQQt+OXIhOsq/fmLEM7/78ACantS/N5tVZHCqt4avGN3h7ICjQp/Ui9Zif+Dk9UtdJon3+4mIuqghr3Q+S4nqiXXG4YK5Ch2HhdZxl1CVpif3ySg9aOWEldDN9tKIqEotWibBsfQX7UvC2m31+9yiDw3QutAgklraFK6Z3jBkjf7nnB6pDQsn3ZGlT71ftH7ZniX/sRY69oznL4ZHFwfHu3TqXzC43ez/p58zaJzcHKkI3J4a+IXnc02HycTbvQNXFYqcjAhnqeujp72vM2R14zeybEdRVZZPyAJAhyv9/gt/Wgta2NmvoalmxbypJtQRufypmV5A/JR1FkWvxHsSo2sUkQdfMgBjOcA6oaMZwtmFnMXFdyHS6t6ZTG6ehQyUroz1OTn2ZIz0vom9GXdFsmjZ4GjrQcCZBU/RzjS8azaOIiaptqmbNqDiU3l/Dpo5/SK7UXWelZhrF1MaQ0ZxpTy6aaig91TTInuE6bE1mSTcfsktCFmctmctUfr+JQ4yHiLHH85+L/DIyTmZxJu6+dP03+ExbZwuTLJ9PsbiYzOTNQonxN8TX0m9OPaS9P40+T/8RbhW9RObOS4knFWGULX7TuJfeJEfSd04fcJ0bwReteFEVsoymKhEduRpYj55c/JB8VlWkvT6PfnL4Rr40hhu8qWn3JqDmrgjvcnSqJLWpm1GyrpmloFqcola0YBe9MFiW6fi8kX4gW3z16dtJVIwKrPgXBPtGQc5O7AlQfWnx32uQfoOn2NqHQxUX0cXcWCNI4rFSU1Y55G4YsEP2okkWQP52kgiil03xIqgdJ9QhRDl08JHQuw18WGd28StFP1dEiyLDfK7IN706Dxg/M52dLhWt2iMzG7vnQ8H/BLIk+76qpIhB11QixoY8WdF6fiUhNHwISKLbIeeUsgy/KjeMMmhuSvRTw+TWIz6ShPZ3G9iRTwtjqS0bNXRU5/rEPxWeRVwlXrkWT42lsTzIdK8HSFMzc1lfB5muRNl0NGjGSGsN3Hi6tiWOtteZrpapGrK/69zSw9vbMh4Q+kFtuVM+F44uteWpF3/7oDWKtGbNR9L/rbQT6sVvHw7F/QsO7kRuI224QazGI7C2qWC/dh8zPq6mRKuPv/FyUC0cRdsOWJt5PfE/hqz2mAhLOFyJOZpuQvlY0/VqAuD6DHoCNOcIjddNYQZZ3P4Ia34N6n7Csu25IPttnrKD6/kq2z1jBdUPyURSFB8Y9wMgnRgbiQrfqN12zYy0K0REjqt8jhFvMQKfirP/Ud3L8fg27mkSClE5mciYt/kb21O2JmiWVJYWts7bzyq9f4fxu59PU1sSf3/4zK+5YESBuelaz7J0yLLLFUC4cCotsMSWjAAcaD7CkYIlhzGW/Xcbjbz5OVXUVNfU1ZCZnYlWsgXlm98lm/nXzeW7Lc+yp28M1T15D/zn9KSgtYMH1C3j1169it9opnlRMdp9sMpMzcbW7uO1/b2PUwlEUvl7IoZaDPPTGQxGbAK1aA1arHCCxk5+fROktpYb5LZq4KEJl+HQ2EGKI4dsGn1+jSepHx+jt+Mfto2P0dhrpT7tXRcVm+gddatmD1FodVo5bIErJmj4U5NCMvOlZOj14CbVbGfepKCfTNDQlnjYyiZfqhXhI7kojkcpeIkidDleNCPQsCUKhVgJ2FiC90U+UJkcEPfdD5X/CG/3FnA6shvfuEtWpo98SPV55m+GjJ+DtMeK9KXHw6WJB4jRfMMthQra13HJR5us+JDIbB1YfP+B0ZoHri8j+La1DkFwlQQShV2/rzKTMh/N+3hlYiuO1pAE0SafeY+Xza7Qq/dHGVBjH7zlW9PNWjIJ3pyF7D2GJsnF3LnsGxxDD140Ov5cvG+uikp9WS3/hqfzTz9HyNqPFZZBgEbFFq6U/2uAHRYWG6hfVIalDxDoTTlpDxsXnEhtJB9eJdcKaDM2fic00s3UmLk2oBps95+glfh5YFNxMi3ZezW8+Rtt+sakXba7ZS+C9uzvn+SmoHrE+mh0vSUgfPCLWorxK4WmtZ43181VNRb10MXvb7WT/IZtXq16k/FcLGd6tK+fJDQyvL+Ovkx+gX5e+EQKcv3z5Hvw5K003D2IwR6z093uEcIsZEETJoljhxJ7ox0WH38u8NfMom1Jmfg7ZKgyPpQbGLBpDZnImRWOLSI5PpuJ3FdQ211LXUsdTbz/F3HFzibfGR5QLZyZnMnfcXOIscRGCRMtuX0aqI5XH1j1Gvas+4HX6+ZHPmf7adKqqqwK9s5qmYbPayB+Sz+pdqwO9ssWTiiN6ZguWFlBycwnX/unaAJFWNTVQMqwfp1vxhJb01tTX8OWxL3HY6nn4jYcDpcKzV86m5OYSBmQOwCrH4VM7om8gxJKqMXzHEU30qdWXTIqZLcC/5oiMZShcNaKf8p9F+C8djpy7yqgkGyoQFEpadbsVvTzMmYX/6ndxeD4Nigj1zEcbsxFQkCTgvbAMqTNLEMn2ehh0nwj6QgWg/v2ayLJqPmG/0vxZUM3XUxdUJn57jBivZz5c8rgo8R26EFFm1oI2dBHSnmeh57hg0BRKtlMuAtkCcrwoiXb0DB4XTd3X54q0o+iZHyyTG7oQkMFzSMw11Mt12FKh2ulz4Zecp529jJcbg8rLOhp3ifd0YLUgnVuj93Cdy57BMcTwdcOq2HhicxnP/WwJGf8I9nT6c1bi1lJI8O1BrgyuhUr2EpRPnyJ50EOoSnekSuGbzPYbxf87C4ICR47ekRoAuSuEj7RsgT63CM/n0FLenvlB4TUItlP4PeZrkC1VvCZ0M83MTzl3Bfg7zMfw1Anv7NDeWN1qzJooNjHPv1MQ6XeniZJlR2+hM9C6T2zM+VyissXnFvPX30NepSk59qs+7l3x33RPzmRm9o+Rw/p4rbsfIeWSJyNiu1W7VnP4pqfJCFfkj1V/RMVXJqoPP/wwO3bswGaz4XA4mDNnDoMHDz4Tc4vhDCPcYkbvUXVKyQHxn9OFVbFR21TL428+zrLfLmPiXyaansOv+gOETfccfXfOu7R52xjYfSCFVxXS5G7C3eFm4cSF/GXzX5izag7lt5cjSRITnplATX0NM6+ZycbfbQxY0MxfO58ZeTOYkjMFh9WB0+ZEkiS6JXWjtqmW7D7ZPDb+MUNP6vLblwOQ5kgLWOtEKynWf55aNpW/zfib6XFdE7saHtPLmAtfLzSQ2KrqKq7907X8+w//JlFJoVE78rVtIMQQw7cVPr+GP74HlstKRCCh2wJ4aoO9mzqcWeCuRR30EC1eJ9CPhDHbsdCOhCbIIwixjsR+Yjc9PVuMlbMMPntWkJtRb6L4m4IkFeDAaqTGXWh5W0Tm80fTjUb1Octg+02dapblwucvVEV3xF+ho0mUwIUT548WiOBOV+3VM64hAh/krkCLy0SVrCg/vFn4i4YGa6Fk+x+FSMNKQXGK7IN+3EcLIr0Hc8rR7F1B9SHp/bUhGV8p9P3tXQp1FWLe+14RGdWQAFXOXY1F6XvKwZZFkbBobdGzvSG/R8uQtvqST0q4KYZTQyy2+3bAKSXz4E8fYlHVy9w3eh0OiwVJseHWMojXGoPfCzD0bcrbrkPK22xsi9D/1/v6QayTozeAt16QylCf63ALrW03iOqL0PXxyrUi4/nxokjSm70E/jFTZC31Shh7psiuWlMEkZQUUSnzwTyxNo1cA1vGGcfY9wqc38s4ds5yUNth47XGx+yZIkN6xUvi70qoR/ewMlFeHLq+Rtnka+3wUjC8gG5WsG43aasYWoyMuTuGXyNE/Rxi69Tx8ZWJ6siRI7nvvvuwWq1s2rSJwsJCNm7ceCbmFsMZhm4xE26jciZEe0JJ8IeHPqTk5hLO73Y+NsWGhIxLa8KpJBOnxUV8cQ+3HAagqLwoQlF3xR0rmPwfk4m3xfOTP/0k8Lrh/YYHVH917PpyF5UzK2n2NOPxeXBYHWQmZlJycwn9MvpxzZPXGLKgNzx7A5UzK/H5fQFrnRNZ7tTU1wRKj8OP65bULfB4qPdrNBLrsDrY1/gZD7/xcISC8sppK8/IBkIMMZwtnClvOMM4mg3V2Qd589hAMKHlrgQlPmhF0vmY39aDFm8ws9foTxJCO7ZG5Mv+DO11RtXGnHLRY7V7vth5v/C/kSQZKUrvElqHCNBCPfy8DYAczDJuvV70k4YGLe1HI61nQkU+/B7xGotTeBlWhlkjbJ2Ab8x2JEkF/PDPeyOzDbrQkqsm6BGoqUGlSoBOux40nwgc371TENRhZUYPxIpRYX1kE0WmovlDcc5R6yLmKG/NJ2FMdNXK8HvDraUQLzVikX1ITVHUQ0MFlY6TIfX5NZqUfpGewbEMxVdCLLb7dsDv1zgvuT/zR/8cZVtw88iRswrNmnL8fn3d11knY2akzFMrekDbG4Q/qqHlYkqkhVb7UbH+JPYFFCGutLmTLA56wNyPdOAssZk44q/gdxkV04eVBSs5GneJtWjU38TrPXVijNCyYX0e226IXIs7rc/4aIEoOXYfCP5eXxWwGCO3XKzlrppOS7HlBgsw74jlzFqzkCkjbqW71Wd+je1dqa4/EBHbnank0PcJX5mojh49OvDzkCFDqK2tRVVVZDnW/nouIlyF9kx9WcJJsN0az+GWQxHZ2x8m9Y/I6nZJ6EJyfDIFwwsiSm8nPDOBsillOOIcBmIYLfvp6fBw8cMXk5Wexau3vUrfLn3JTMrkSOsR0+PdHW5mr5hN2a1lFG8o5q+//StHW48GLGwyEjKY/tr0wGuy0rNQJIWyW8soWFpgINTr3l/Hpns2cbDpIHUtdbxS9QpFY4vomtiVnik9A6XG+rXwa/6AqnBtc21AQTnVkUpSXEz1N4ZvD07HG86M2AIR46i5q/DlVWGRPGiqD0n3xutUd0W2oyKhqb7IcSUb+FuFSm04Wdx2vQhSPLWCxO6cIrKIV641J076jn+YoTtDi4PH6f2dhjd6HOsZvfRN8weDJLN+S60DSfIHgyedLNu7inGU+MgeU7UdHD1E5kCxi9Li0CyEfiwE38/V28zn2n5UBINbJ4jrYHKMhfaon3P4Z2rJKUfa/Qhc+N9CPdSMeO9+NHCNT5QhPdc9g7+NiMV23x44pMZTUv3VCanUtj9o+xL6f3jJ7YF10PMn0dex0LHdh4Iep9ml4PyBOC49W/immvmR2rt1ijM1wd9vCyPDBUEy7KoRGVbVJ/7pY9m7ms8tfC121UDyILjsqeCGXGiFS32VGEv32/YeE+/nwJswah2aHIcfBR8W/px/Lyh2apuPml7jDlsXprxWgAaB2K5Xai8SpfRYbHeKOKM9qi+//DKjRo2KLWTfU4SSYI/abKowvHXWdnon9GNH0Q5ava34VB/7j+2nw9/BeV3OM/iL6r6mPVJ6sKdujyGLGS37+eWxLwPnu+n5myi5uYR5a+YFBIzCj69rrgtY7czIm4EiKwE7HN0bNjMpM3D8i1NfxOP3ULyhOLD4dEnowvrd67lq4FV0qB30SO6BRbZw/7X34/F5aHI38dGhj/jDhD/w58lPoyEy0C2++sB8qqqrAqXQ24q2kRh3/Mb6r+KHG0MMZxqn6g0Xjdj6bRnIb4eNs/U61LwqQBYZQF2xd/O1SJ39nIr7EAqQktAX/G6klj2wex6Kp1aUp8UdR0xoYFFwBx8EcQrzQdVyV9CmdSE+rMQ0or9T7/sMRTTrGecPg36AIIK6+O6mx8oySO2HjeW+OrnMqwz2lOpjx/cQGWDVLywhQoNDeyb428XcW/eJzKsOvWfWtAesk1jLtihEXon4nMH83pD0TQJrkghQ/zVHCEm5D4kg+rNnxOc8oDDgzXo2MqRnqirgu4ZYbHduI5qgmIaCGr5mhfh/St5GUWI75PeC+A35PZolEfI2I/laRSZVsgjf6fZ6Y2muLU2sbTpR1dsEkAW5/WiBUA2XLKKl4EfThchbOBHOXiKUzIcWg7P38cmwM0uo9bYfher/DWZn43tE78EPhTNLrItmCui6fVnrPrSUIUjuznYISwL0uAYqf4LkqsHizMKir/ueWn6QsxL/lW+ihFX9TFv1ODurxeahHtt9/vvPT5gcisV2kTghUR0/fjwHDx40fe6dd95BUcQfp7Vr1/LGG2/w8ssvn9ZE0tMTTut1XwcyMhK/6SmY4lydF0TOraa+wUAKs/tkUzS2CK/fgzVOoamtibGLxwYI4Zrpa/D6vBS+Xhjha7qnbg/z1swz9L6WvVPG8tuXG/xay24to6i8KGQONfTN6EvR2CIWrl9I6S2lhh7VZbcvo1tiNzQ0Sm4qoUPr4MonrjSQ6+ufuZ4NhRt4bMJjKJKCTbHR1tFGwfACeqf2Jt4WT2t7K2MHj+Xe5fdS21zLY+MfY3HF4ogy5tJbShnUI52MpAwAvE2tpuQ5MzmTnqndowYFqqrywYEPyH86PzD26jtXM7jn4DMaSJzL91sMZw8nE7yfqvJqNGIrjXk7chx7Jor3QKTZut4rGdLPKYUEEIFd8p1TBCGMllkIV8StrxJjjH4L2o+g2TNpI5M2j4rf1p+EvC1IWgeSpgKSsKbRxTjiM0XAF1qWnDIYKdTntboMLv49eI8GM6Q66f1wQQRJJnclkmSBuIzowVhHc/D3YaXCwsFTK4JRR6/ga9KzRZlzaKA4rEw8Xl8l5hbF2J5+vxF9rUoiku6faM8U7z+xLyBjUaSTvjdEoOsOBq5NHxoJ9b6l4MwyeLN+nTidqoBvM85GbBeL604OX3lubvPNMEVRIO0iuGanqLBAFhtKlz8rSGrV+IjvuXT5syDZRU9q6Dpw1RZBRH2tYZt4K5GuOwi+5sj+VUdnJcrQhaIXtU9BZ+/pOrFuWRLgo4Uw8B6x2RbaVx/yPgIlyTnLxfF1FcaS47H/NKnKKAdUw1rMsDKx5kQp1WVYKVp8784KmwLj2hzaixtS8qxsG09H3jYU/RrLcTT4FDZ8XGE4RVZ6Fg6bg4zk6J/12YjtzuXvQTRImqZ95RV4w4YNLFiwgBdeeIFevXqd1hj19a2o6jf/xyAjI5EjR1q+6WlE4FydF5jPzSM3k/vECGrqawL2L+GkbfbK2VR17jitvWttIJOpIys9i42/28jR1qMkxyfjtDl574v3AhnXNf9aw7iLx3FRz4uwKBZmvDbDoLqblZ5F8aRiCl8vZEnBEl6peoUHxj2AqqlomsY9y+5h9a7V5A/J5/5r76fd107OgpyI91c5s5JRC0eRlZ7F8796ntb2VsreKYsgoksKliBLMlNemBI4b/j72Txrc6D0Iz3dyfv73zeUQa+ctpLzks6noyO6ilLotQ0de+us7dhV8x6xU8W5cL/JsnROBTpnCl/3WncmP7tA8B4mVBNuRZIS14x104jI8qfR28NEIwTS4o6irOkT8bj2s38jVVxpHOfKtcay3c6xI3ol9cdDFHy5/HlBZH/8LnQ0hhG0TlI7aK7p+FreZnyqJUDMI67FgJnww58bRZJyV0J8LzTVjaaqIMchew4Y+puExYwK2ydFzj2vsjOg1ABZ+MMm9IGKK0WgdMkTQR9B/T1YEoL/Gj8QGWG9DNiZhZZXiVQxSrx+2FJRzhaq4KtfS+8xNHsmWNOQvHVG9cxB9wvFzE8Xo136FJrPhew9KkqKQ96blruSFuV82r1i/crISKSj+YDpvREoma4uEwGsozegGgRRzO61rwuneg+fye/ZubrWfdXYLhbXnRhnYm4nu07riHava2MqaFEzSZRrI5W4r94mlqUdN0d+l6/aDBuvjHx8WJkgmYnni83D8Exq4o+gdU+Q+OpibqHrZe5KsKUI5d6PFokNLBDk1HtM9JpKslivfG3iZ28DHHlHqJ+rXkGAW6vh/QfgokeM5cX6e79qC+1+FVVTcVSOif53RUdepSgfBjrG7aXF1w2/XyMjI5GGhla+aN0b0frWO6HfcbOjX3dsdy58D05nrfvKpb+bNm3iscceo7S09LRJagzfPYSKK+n2L6GZSp3M6SURTpvTtIcUYPJzk6mpr2HtXWsjyF/FJxXsKKqiQ23nD9f/gd+M/A3z1syjtqnWIGY0tWwqJTeXIEkSDa0NgUwsQMHwAm549gaKJxVHFVPSyXVCXAKv/f01Fk5caBBz0s/x1t1vHVdBeP+x/ThsDWQm9gCcpuJWxyOpcAI/XOlkP6EYYjgxTrak91SVV6NZivixR1rLJPY13wGXlOOXiblqRCnZgJlCKRc6VSQtgoBZHGgjXhPjhNngqDmrQspNtchrkZ4N/X4tfEp1Kwdbmihd7QyqWskiUToaDLr0OW2bKJQxTTLHtNcHPft0Itr2ZXAn/5+zhGE9mpi3psLu34sMw+i3hGhJ2PVQsSKPehPJc8hoJRHal+U9BhtykHSxqk//DBcWiexwnwIh1NRJftVLnqRZ7UWyw4FcMdJY0rt1PIljKvAr3QIBstm9oek9qp5aGPKYIVDVxlSgaspZF0WK+bEaEYvtvj04VUGxaPe6qinES42ixSL8eU8dJF1gvuaqUQSFQKyLkhQkqfpzVVMF2QttuwhYwmwWFSeuL4RlzMZc4/g984UlmARsujq4pl3xolgjPbWC4HrqOslszyA5lSyRVSvDStnf3ABxaXSVPcf/uwJGsTdnFm6/Sk3rHro4M6htcmEj4bSES2OxnTm+MlGdPXs2VquVu+66K/DYCy+8QGpq6lcdOoZvMULFlbx+j+mXL80R/OK7vC5TkvjZ4c8Cj+m9pqHlu2/OeDNCtGnFHStIjk/m9+t+H8jY6mXAM16bwR+u/4OpMFOoZ2ugR/X2ctKd6fxtxt/Yf2w/89fN58kbn8Srmi8ofs0fVUE4f0g+qY5UjrUdo6W9iabDx3DaEgCJZEsX/H7tpMStvk4/3BhiCMXJBu+nGihFI7Zt/gQSZHtQBdfnEoTMrBwsWq9kSABBy+fQ/7ege9z1zEcbukj0gqIhvXe3CGouWYh21XbRv6T5kSQribgMKsKGazGwSOzg2zMjS2lzypH8bhIcCdEN6iWryBTrtjsfLRCZ3XBj+Z1TRFY4FN5G2P2IIJD2rnDhvcb3H3Y9ZHzCriY0IAzvy7KlCvINSO5DQoVT88EnxRGeiLr6rqSZB6eSp5aEOHtgI8Ps3nBrKcRf8jQyHWhyPNqY7cha533TEXrfnL1sXMyP1YhYbPftwqkIih3vXpfxmveqV5fBpU9G708/3lpscZivg2ZryIHVYv3RqznSsiOJ5dCFwo86XCBvxy8F+UWDI1WQ1E9kYkOV0iUZdhUZ1Yd3zabX8FdQvfUorkPH73cNrcZxZuEbsZxWzU6bt442m4ui14p48KcP0sWZQSy2OzP4ykR1586dZ2IeMXwHERBXUjD98rm8rsDPXRK6UH5HOdc/c72BcE57ZVrgNVXVVcxeOZu37n4LDY3Pj3yOw+YM9LpCUCm45OYSfp79cz489CFV1VVkpWcBUNtcS5zFaJGjk8qq6ipeqXqFdXetwyJbsFvttLS3MGrRKMOcbBYb++v3s/autThtzoDwU21TLfuP7af0llLWfbCO9Xev52jrUepa6nhn7ztM+o9JAYsdPUMLsLhiMYsmLkKWFCzyiXfevk4/3BhiCMWpBO+nEihFI7YJUiNy5djI3fNw/71hpfDBozD8FXjn55HlvKEZw6GLglnQH00PlrQ5szrtENzw8UKkH003EE7LFS+SbMugiV74/Jq4Fj3zBUFMHghNHwlyGZ4p2HY9jH4LSfOhSZagjU7o+2k/EubfVyqsYcyCOT0bDIIg735ECJMYyPEyQUaveNFYGnzFi0it1aI8LlpfVvYSIXIyZIFQDw71gM0RXtN635maswq3lkKytgep+aB5QGdLJbSdyrzHWaWdaKVs38waFvNjNSIW2313cbx7PcHShFJdFtnzOXiuIGsm2Ui8jaInNLwaRBeau6LMfK1QvdHF2xy9hJ1N2z4xTiix9DZFV1N31Yj+0twVtMd1x2pNQdZtxUatE5uEnlpjGa8zC0ltF8rJXfOE4m9I64M2+EEkazJcswOQ0OK7Iw1dBJ46LB8+SlzfGcxcNptDnZV8ujinu8NN/679ibc4cJxERjUW25njjPSongnEehmOj3N1XnDiuSmKFFGv/8ptr9AtsRs+1Ydf9VO6vZQbL7uRpPikALnLSMzgF//ziwiCW3JzCe2+diaUTGDv/L30m9Mv4pyVMyspKC0w9Kg+9fZT3HPNPQzsNpBjnmMcbj5sIJGPrn3U0HcarW9286zN/Lv+3wZ7mtJbSslMzsRusdPoacTv9xuEnjb+bmOE76v+uF42fLxehnAluEQlhRZ/4xn3w9VxLtxv52rf1lfFd7FH9aueQycysiwjbZ8U7LHUce3HoMShaSrINvzYkDQfsqQiNX7QacfiFWVdik1kCHfeGrRx2TpBiASFWyPo7Jw5vwAAIABJREFU/a96ZtGkx6ojvh+N7Uk47DIODiF5DovxPy+FflNhzQWRb+raj9Fkq7DSCSeVo9eLkuHwc41+KygMFfK4lrcJqelj8R7je4Dr36Y9VoypQJOt+DULiuZBavtSEM8vlhmzyqGvGbVOXCe9V/WyEmP5cGevrqZp+DVrIJC1bhohssmXPWXcQNAVRQc/SCP9SU11oDa8f9z751xS2g3O5cRVAd+HHtWvilhcd2J8U3OLdq8H1vzdD4lNOed5YEsWarueOtEL7z4YrHhJ6CP+t3eD5o8h4TyhJm5NDm56DZgJP7wpUqStbgf0+om5eNulT4rNQNkaud7lVYpzmmkXhGgUqHmVfNl4mKz3OvUA8ipFNjW8CiZ7iRB5evfOyOdyV8CnT4v2iuwlot3CZP19p28x97yxgD9PmMvArn3wSxZ++fJMVoVYEpr1qJ7N2O5c+B58Iz2qMcRwIhg8VtUOLIpCS3sLeX/MM9jApDnSGL1odIDMZffJjij1Lb2lFGeck7teuytQEhGtr7SmvoYLu19I8aRi5qyaEygDnnPtHCY+O9GQJe2R1IPFkxcbVH+j9c12+DsCJFV/bHHFYhZPXkxdcx1pzjT2H9tP2ZSyQLb1cPPhqD244f27uo2PvTPjYEb0A4uepJ1RP9wYYgjFqZb0huJkCEi40mogO+htFKW93gZwfSlIn/sgUucOtzzoIfy2DBT3F5F9mSACEk8tWu4KpA/micfC1X0huCtv9lxnxlGmA4si4ej4zNDHSk652Nk3yQhoShzSe4UiExnieao5foDkj6I6KdtMbHFWCeuG0Ozr6PVR+sE0UDvQNAVVtqF4G0TpnK64GaGKuSxIUvUxTHwHJfd+fHE/7BQU0pAt3mDm4rNnIW+TCFw9dYGeV6lxFyl5m6HtWJCkdo4X2uN8JpR2zyTRjfmxxvB9QbR7PbDmX/I0VkUV61fFaOO6IVtBtgj9gA8fFyQud7XQBEASpHbPX4JZUJ8L7D2EuJKjFzR/GlRt/2Be0BM6rgvs/R8YMAO2TxbnHvFX8bpQFV5nb5HxDM/u5iwX/fQg1i5NxZbwA5r+40WS/++X4u+JmR3Wv+aIahWzCpmtE8T89i0Vz436m+n6+8PU7vy/X8wn4x9T4T0xn+d+toTa5lp2VldFxHUQi+1OFjGiGsNZgd+vkWhNoYUG/KqfY65jFE8qDnil6jYwoWROL/XdPGszPtWHIimgiX7WF299EUmSsCnWiJJhXUQpKz2LDw99GBBsAiGcpJNUMJYKhxPTaF6taBgey+6TzfQx07nyiSvJTM7ksfGPGcj1koIleH3ekxpLn1No87xLa4rqSWuPWj4XQwxnBicbvBsIg2RD8bcgbxp7XAISIdZkzxT2B/qOdc98tMEPGMt1s5cg734Iaegfo/p+as4f4hu9Ha+UgmPwg0iNu4IWB6HH6h6nZs85s0CyoGIlwdKEtGl8ZInvVdsgt9xgM6PlrkSVE1H03s76KtGDevFjQizJHaUHSvWCkiACKE0FSULyHIGtRqJHy+fmr2/+DGnztVh1QSTneSIjovqMhFkvn5Osxsy1U7RHkLsieEx1GcRlYJF9AesZQzn4vqXQ/zbYEKaW7qpBcv1bBLPH6XE+Vf/dUFgUiQRrExatzeCb+122lIkhhtPByW4ahh+TqjREeo5umyg2p5o+hn/cI9aQ9GzoaICtYSXBu2Z3is0tBL8L7BliQ06Jg97XB0mhvlY6swQR/Ghh0Ku1/aiw5tLJbHxPsZa9d7dYU0e/JbQA2vYDUnBN65mPH5kUWtjb5qHPlRU48QTtt8LtsPavEQJyZpuAoQJ9UfpxE+xJJG2bbLhWGf+YyqKfFjNi8QRTUaRYbHdyiLk3x3BWoCgSte4v2XtkL6MWjiJnQQ6Frxcy/7r5ZPfJFl9i1RfoJdVR21SLz+8jb1Ee580+j1GLRuHucDNr+Sz6z+nPFX+4gnRnOq//5nU+ffRTSm4uYc6qOdQ21bLijhWUvVNmGK9rYldTYqj3moaef8GbCyi9pTTwmJ59rW2pNRwXqmpcNLYoQFL1saeWTUWWZFbcscIwVvkd5Xx57MuI9xxonu/EcZXgYojhHICeGbNuGoGypg/Wt0cgtx8SQQoECYilyfC6CLGmgUVG0Z8+BUhbwwSGqqYKAiYpgkhlLwmSLN0ixd+FxvYk2jwqjfSnY/R2/KmXo416U5T75lWK/xPPF0TTZBzhGerAraUY55meLYKdYWWiv1Wyiyzn1dtgaDHSBw8je74Uvaj68RfPB79bZGR3z4s817AyQbqtCcKSRs8ox2cKMaVOoSNAvD53RdjrS8XjnddI2joezZYiAjtJFsfUV4kArWKUCNAs8RHXTbNniOf0YwbdDx8uQKq4kmRtLxZFotWXjJqzKvhaf3vwZx06+dc3EsKe03ucT1dpN3C/vT0Cac35IuN88XywZ5reZzHE8H1FxNq8aUTgu3zcY9grNs/MiJvqFZUsOikMX7ddNeL3nNeFqnfzZ4JItv5bCNZ9+pQoETYbu6NJZFr1dejdaUI1uLoM/B5RVtzemRl9ewys+RGsHSg2Nz2HxTg989EGPYDl7VHErxvA4A9vQ3XXoloTgxlcR2+RHdbXp97XC4XgaGuZ/rOnDi2n3LB21l9aSqvXvFKme6IgueFxHcRiu5NFjKjGcFbg0pqoPlptSuKKxhaRlZ7F/mP7WVKwxEDmVk5byT3L7jG85oZnb6BgeEHg96c3PY1FsXDv8ntp97WzaOIiNv5uIxkJGcwdN9cwXrekbqbEUC/RXfbbZUHhpaZaEuISeP5Xz7OtaBvr716PJEvYFBtlt5YFjgslv9FsabqndOfpTU9TcnMJnzzyCRX3VNAjuQcXdBtIxe8q2Fa0jRXTVpA/JD/QPK9DV4ILn3P4ohdDDN8UEixNESWe7JwiAhgdJgRExWYMDMJLcKOV5CZdgF9yog56SAQ9Q4sFUczbhKR6SZQOkmJvDmQBG9uTaPYmC2L57rRgAOQ+AJ+WoF26GC2hH4zeAOM+Eb2a796JtHEECb49qFLnPNOz4dI/gRwn5tKyB6zxoud0Q44gggdWC6J46ZOCDA99UpBrvcy4vqpT5KlYEOYxG0Uv6Y5fiGtmTQDVLcrt3ugvArAhC4Jk1VMLmiZe9+O/i+zGrtnG7KirBk1D+KJ66gSRDSW2ueWixK7zumlXbUGypSB5j4nH0rM7syc3QK9xgY2GZJsI2JqkfoL8j9uHmjQokjhnLxFZ5I8WRJDyoECRyeevH3MCpV3T+61qqrjfToLoxhDD9wVm35XwzRzTY7ZeJ0p4zYibph5/3e4cA9Uv1qvQNbe9Hi56SBBOs7GtySYCdTeInlVk2PeSKBEeVio2A3NXiLV/TAWkXCTW76F/FFoCw8rE8/ZMEv9+M7LqFdnbrRNg/WXw7nSx3o37BJIGAJL5WvnRAoO43OdtKu/0LaZj3B72XvIyn3qspDrTTN9PWmJ31t61ljdnvGmI6yAW250sYqW/MZwVdPi9UXs+uyZ2pfSWUmavFApxxZOK6ZrYlR4pPbDIFlbvWh3xmlBrm+H9hgdKf/Vj84fks3jyYpxxTjYWbsQiW3D73DS1NVF+eznXPxssFX5x6ovMWj6Lquoqnt38LOvvXo/b6yYpPokmTxNZaVmomorNYsOv+rnjpTuM80zuESjrjVYurGkaS7cvZen2pWSlZ1E5s5KMhAx2H9wdKP3IH5LPwokLkZBo05pwKKKJPqYEF8O5jmiZsXDvuVACYlEkJNmCFuphqpfi6mNFK8ltrUaO9+C29cdx6Z+Q3F+KXk7XF7CzAMlVg9WZRUruSvzxPWjxOs3Ld3cWwLAyNCQ0VUWWbUjvzTBYssjbrkPNqxLz9LlECdtJ9IxKrhrY+5xQHR7xGliTgu9Fz27qgka66MjQYvAcibRd2FkQFHzKWS4CxbevCh7vqTWe35mFHytuNYPEeBkJv5inbBPZCCkOuo0WAij2bkjthw3lywaP1ZCyN9n9JclyA01SiMCU75AovRu1TnwG1gTY91qQOH/6FGreFjRVRZWsSJKFJPUIqsWGW0tBOQ2l3ePebydBdGOI4fuCk6laiPp98rVF9ofmrhSZzZzlQY/o8HUbOlsnlMhMa81f4fxpkBgvNtv+MTOgKk7uSjTFIdbO8Lmo7fDpYiFO98UyGHCPUCIOFWLKWSbGz5pkXKP19QwpOM/0bLGxZe8q1lM6xDoc6ovtc6HFdUca9oLws979KEf6TOeXL83kUFMt6+9ez4BHRNvDdUPyWT55pVAO7jxv/aWljPvLr+iWlMmiiYto8h81ODvEYruTQyyjGsNZgVWxBbxSQ5GVnsUPUn9A9+Tu1DbVUlVdReHrhXg6PBS+XoiqqVEzoDp6pfSK2jM64IEBXFV8Ffvq9zHlhSlc/+z1OOOcbJm1hb2/38u2e7eRkZBBbZMI9Co+qaDJ3YQzzolFsoAG1zx5DRfMvYDRC0fT5m0jMykzME+71U5JZUkgE2xWLrzst8uwKTZWTFsRKHNWNY2jrqOBBUqf81V/vIp+c/qR88QIvmjdi6JIBjGq6vn72Dpru6l6XAwxnGlYFImUuGbS4o6SEtdsKBcLRbTMWKj3XGgmTS81s1RkI/3fHXBZCdq4z/ClXIqaG1JWWl0WUWZF9hLYPQ9563U45AYk1S2ymR2NwYAKAiWwlqb3hGAPHebBWHwP5IqRKGvOQ6q4UgRCoaW2rhok1U2Lcj6ao1dk4KX3jIa/d9Urxno7D966QljA5Cw3vpcr14psqr7z7+gd3XYh+UIRQO1+VJTz2jPF8Up85Li5K1A6PWK0jiZBatcMEFlaVHj/flEq3NEIje8HSap+Lj07aVL2pmdjAgJTb18F6y+Hyp+At14EnlnXBz/3QQ/R5E2j2dcFxXsES0V2oLwwwbeHVkv/QHa2Y/T2k1KUPt79FnqfxRDDdw0nuybrOJmqhejfp1axvlxWIqo/LitBU+LR4rqhxfdEzduC+tO9YhNuWFnEGgSqcS1Lz4asG8U6tGaAWJcGz4Wf7YOrtqDZM9HQzOcCcOF9cPBNOP9O8LeCu9bQXsK2idB3SpBA649XTRVCSa3VwUzsxfPFxt+GHKj8TzRJMW4iVoyCzdciub+AyrFocel8kjWTn700h0NNtRFx3apdq6mVuuDN24pv3Oe8N6CEcS/ORgOmj5lO3h/z6HPfeeTGYrtTRsyeJgzngnyzGc7VecHJzU1RJOra93Oo6ZBBaGjVtNX0TuiLSzvGu1+8S5ojLVCGW1VdxRcLvqC+td6w47T89uU8uvZRVu9azcxrZnL7lbcHFIQBVkxbQeHrhRFZzeJJxUwomRCwhWnvaKemoYZeqb1ItCeiqiqqptLY1ohf89MtqRujF46OGOetu9/Cr/nRNI3S7aUM7zec3qm9ibfFo8gKR1qP4Pa6SbQnkupIpai8iNWdEuW6Tc5vRv6G/l37c/795x93zltmbUFCRkPFr6on5bN6JnAu3G/nmmXDww8/zI4dO7DZbDgcDubMmcPgwYNPeZxviz3NqVjTmB6buwrV1h1JdUeoBafENQuLk7Ad+I7R2wMWKLrKsFtLIVE5KsR5vA2iDEvP1v10T9D4fViZCC7CkVcJOwtQ87YgV4yM3PU3sWQJWBzo8xqznUZPEl3sR5De6GscPz0b/qMkcmdf9cM7k43nGzBTWMV4Dovso2wx+p7mLBM9nzt+ETnPsDmRt1kQw60TRLA2aK5Q4XTXigxB1RS0MRVBIarwsUAEatGu29XbQLYLywZPrSHL6h+3DxWr6WfI0GK0lItQNQXFaueYOwGfXzvuZy4UhU8eZveblrsSv01kz8+GkFLMnubEiMV1J8apzO107MJO5jXR1m85Lh025kZ+x0f9DVWTaJF+QJxyDLtrD3yyWGgHdKr3atZUUNuRQl9vZhHmzBJ9+LJFbALaM0Vfa6iar25Zc8FM4SsdbmejV3+AKONdMyDyQoz7BHaIljGGlULlfxrnoVuVRVt3nVk05q7nk8ZjUeO6guEFFL5eyIbCDScV2wGxuO4kECv9jeGswO/X6BrXi+RuqWyeuRm/5scmxwVMkCVZNnyZs/tks/autXj9HaQ709lQuIG6ljrqWup4pvIZCoYX8NDPHiIxLpF7lt3DkoIlAUGjaIJJAzIHUDmzkoa2BhQULIqFTZ9s4te5v+Zg40HqWuooe6eMGXkzmL1yNosmLjId51DTocDvC99aCG8Fn8/uk80zNz/DL/7nFxRPKmbyc5MjenLX372egtKCQP+sXspsdi5Ph4dmT7PBkzWaH1cMXy9GjhzJfffdh9VqZdOmTRQWFrJx48ZvelpfG05FkTWqjY1bAxydRwXv1+OVo0WqDKskxEtIodlSCO6y6+JE0crPvA2iZxPFWGas9xzpdgYh88DeNfj6YaUo/hYsSjI+4rCGn8NTC8iijM1zWPSE7p4Pl/wh8j1mDA/6mYYHbXpGYMzGSNuFYWXC/y90jmp7MGBz1QiyrZci7ygAeyaSGiWLbO8q1IBdNdHLq21paJbkgLE9+14JlMpJsoyMFnVsTbLS4EklIykRX2vLCT/zU8Xx77fYuhjDdxOno5J9MhZj0Y5J1erNv+PeBmTVi9OZiqT6RI+8rtLrqRNqwMNfEj3voaro9q7m4zl6BYmjq0aMd1mJEFxq/kSsPX0KwNEzaJWjv7ZqqoFMItuilyEPLBIbnZ66yHnsnifszMxIcOe5WtqOcqip7rhxXU19DXvq9pwwtmv3tXN18dWxuO4kECv9jeGswe/XsPgcOLQ0EsnAISXj0ppo0Y6iyBZWTRO7U9l9snls/GNMe3ka/e7rS+4TuRxsOogzzknh64Us3b6UwtcLcdgc1DbXsnrXauasmkPxpGIqZ1aS6kg1LRfed3QfoxaOovD1Qo65j6GhceNlN/LjJ38cUCGePmY6iysWUzS2iLqWOtNxXF4XDW0NESrBIASYuji7UDypmIHdB5ouUK3trVRVVzFvzTyW3748UMpsdi6/5g+QVP3115Vch0uLqVqebYwePRqrVZRLDRkyhNraWlRV/YZn9fXhVImFLlrU0J5OY3vScbNapyqioyFHKuVmLwGkoC+eWQmsLurjzEJVEeW7YyoCCr34Pab9ndhSxTGj10P1S8ibx5JgacKtpqCFCwfllItx3r7KIKhES3XkewwN1KIIkGjIYO8uMsE/3QtXbRECIwOLgiXJzizRF2oaRB4TP188XxBnszI6e7cgsTcRPOKKF0Gxg+oRgkxH3gkqcW7IQa4Yiew9ElQ2Dhlbs3ej1Z8e8RmafuY985Fk+aTLGENxKvdbDDF8F3C6mz0n810xPUaJM18/PHWwcwoKHrFme2rFuqdvpg1dhCQpol9UI1g6bDMXHEIvu9VRXyU23jx1Yn3S1x7XF8ftTWdYKZpk7bTnClnPhpXCO78QY1w8P/h4KDy1tFu7Uj9iHe0/+VjMOTRT68zCYU89YVwHnFRst6duTyyuO0nEMqoxfCMwMzp+c8abbJu1Hb/m48qFVxq+xAVLC9j4u40Bv1OXV/S+6WSyqroq4JeaPySfFXesYMIzEwJjh4o16d6plTMrGfuXsRE7Y8WTiklzpFG0ooiyW8soWFpgGCchLoHpr00nMykzwsN12e3LqD5aTeHrhRRPKjYVVkqISyC7Tza1TbW0eFoonlRM79TeLPvtMib+ZaLhXG3tbSf0WY3h7OPll19m1KhRyPKp7/WdjRK/jIzErz6I2zxDqVjtZCR9xfE1J4xcDVvyg7vXI1djTexORpLJNXW7guq+usfnp0/BZU8Fs49vjxGltXmVgsSpXuHH56kNjG2VZNDOE32gjl6gOCLnkb0Edt4qAhS99GvfUqyKD6vcAh+/KhQmJVmcR1IiAy0I2siE7tDbuwWvaZRMpqT5RYDoa4P2w+YlcD+aLuwezDIH7kOC1FZNhexSk+xsKcgOSLk4OL9/zRGBWWI/QVA7WqBitBA1cWaJ9xtaQtzZ/8uYCmjcZRBakRxZJIWoVgbuRTVeCLHoGe2e+TB4bqAcW3FmkTpyNXQZ3HltVRGoqu1CZVm32jmHcEa+ZzHEcJIweBjr+DrFw+xdUcPEzgJZRlcNaH5afekk56xC3v2QWJd0xV69lWH3I0FxuvRssQkW2u6QvURYcpmtZT5XcC07XvWHoydqXiWfHd1PcpzMtFcfZt6Pn2dQt/OQmj8zqqJXTRVK6WHz6BhRzh+3vECTu4kHr5mGP6EvyqC5Yh331OIdsZxfv34fvxpeEBHXXTckn4GpaRx4aAf/PnaIJzaXGWK7ldNWMr5kvKF97b9eNVbyxOK66IgR1Ri+EZgZHY9dPJats7bjV1VTcna4+TDX/inYS7b2rrWUvVNmKPvNSs9izrVz6JHcg8qZldQ215KZlMnk5ycHdrv08XyqL6oKcV1LHVXVVRRvKGbLrC20eduQJZkWTwsZiRk8Nfkp9jfu57W/v8b6u9cD8PmRz+ni7MJNr97Ey79+mSfWPxFBPpcULKGovIi54+aSkZiBjEyju5E7X72TzKRMtszagt+vIskw+fnJAeuecLJrUazw3U3mfSMYP348Bw8eNH3unXfeQVEUANauXcsbb7zByy+/fFrn+fb0qCaIACS8t8mdECjnPL1xO43llWSkvC1oKKgqohztqCvqXFIvethAKIVoThoO50CUvM2CxLQfRaoYFejZ1C78b7joIVp8abQfdUWa2rfHoyj9SMjbgqR1IKnt8NGiYFATslvf4bcgaz6U3hOh7Qsj+ctZLohXiFpwoCQ4lFzvfixIDj9aYF7i29EolHwhUv23aiqM+pt4DYggzxAYlovAcEBnSbEkiyxH6Bx2zYYryoSljj2zk6D2FdmKHb8Sva7h5/XUmmYy/JqCGl5S2OABPEDwXoyzySTKtUiaL6AOrNlSxGcVep4t+YE+5VPtxTvbiPWoxnC20epLNl2TT6SSfdqQZJqkfqTkbUZy7xcbR3op7JVrAU1Umkj9cVz6ZOT3edtEsfaErotynFhz4tJE5co/i8T6Er4WDn9VlPqGernq1R+ha96wUjS/l9+ufoz/2baUvfP3smrXalbtWs2Bh3bQI1R/oHNeftWH5uyHOmYLkubFh8IXbe3cnH0z3anHtml0SK/uCjpsmdxZ/gAzfzwrIq67bkg+r0+6H9um0cS7aujhzOKvk8r53BtPo7uRR9Y+wjM//wtbZ23H6/fw/oH3afG0BAQ8dcTiuuiIEdUYvhEcz+hY95YKJ2d1LXWG4+etmccLt7zAUddR3rr7LVRNxaJYhL2Ltw1Zlpn83GSe/9XzpouCIium5+mS0IWl25ay9q619O/an31H91G0oihAdEOFmQD21O1h8eTFnNflPLx+L5lJmXh9Xn4z8jd0SegSyNA2tDUwZ9UcqqqrWDhxITOXzQw045feUkr35O4kSGn4JY12qZnaploWvLkggojH5Mu/HqxcufKEx2zYsIHi4mJeeOEFunTpchZm9c3hZHqbThUB0Y5NYYHWCQiIz69Bl8H48qpQ8IDmQ5KsOGjtFM9xCLGereMF+bp4PlRNDWQEE3JXga0/Cb49gXMrziySr3wT/B7kyrCMQfOH4sSD5oK9G9qYCtxqCgnUQ/vRSCK37QYY/ZYxuzisVJjbh4o/ObOg321wxcsQ302IFeVVQvsRkSHVVBHcDSsLjh0KnXzqxPHTp0R5ss8NtmTx/5Dfi0yx3p+rl+XpcGYJUjr6LUCDpo9ET6s+RzPVYU+daSZDlaw0ekJ74yI/Q4sikej/DKlyvOEaS1Hen0zHafXixRDDdx1fx5p8MudUUVD8HlE6GyJ2pNuAWXJXik2oaP3wOgYWBa24QGRYB82FxD4g24Wfs69NWMH4PbBxpBBa0tce3YP6shLxmqaPYddsJE8tUy4tZsPHFciyHIjr/n3sED1M1q0OrBxsc/NJ7SfMWzMvENu9O3MtWZ8Y13Z56wQseZtJd6aZxnWD0jOwbf+J4TXW7dfT0LeYwtcLKb+jnHgpgQ5VRVKg8PVCMpMzY3HdKSCm+huGc0EVywzn6rzg9ObmkZvJfWJEBEncOms7Tik5oix45bSVPPzGw9Q211I0tijgo9otqRtjF481HNczuSdun5uGtgb8fj+Prn2U6WOmGxaF8jvKee3vrzF20FjD4yunraR3ShZfHKth/DPjDZnQV6peYdzF4+id2pv0hHRqm0XpbnJ8Mjf+5UZDWYemaVz++8t5q/Atbvvf2yLeZ/nt5TS0NdArtReKpFDXWke/9P4oPiE8E1oanZmcydxxc+nftT/xFkdAgOrrxLlwv51rWYZNmzbxyCOPUFpaSlZW1olfEAXflozq14HTUX7Vs6BWi4TmOWwUQxpWihrXnSa1F0mWIyhr+kRVljRV/e1UBI4oJQtVoQwh1NhSkNtqzFVyx30irGoszqA6sadWBFW75wVVeSVFeJnqAVtoOd2QBWLs3BUi82CmQnn588I2Ir676F21poDnkLHE+IoXRQb1X3Miy/H08uE+BWLM8Gtlpn7ZMx9t8INRr320QDkjI5GO5gPm6sCj1glLG5N7QcYrPssw+Mfto6E9sv/1m0Aso3pixOK6E+PbMLeUuGas/7xTrBnJF8Kma076+2xQHr96m+jjD0depVgzq8uC65WuRp6eLdbFUC9XXVyuPlgl9+XIbdT57Ya4rntyJmt++Rjp7wXX8Y6ccm587RFWdSYJym4tQ1VVkuxJDE5Nxra2f+T8rt5Gh2RnT7udCx8aZFDyrb6/kvO2j4p4Sce4PWw7+CWLKxbz1OSnsatJsbiO01vrYkQ1DOfCB2mGc3VecHpzM+tRDVU9UxQJl9aEz9+BRbGSqKRQ6/4yYG+jf8n7ZvTli4YveGD1A1RVVxnIbl37fvyqH1mWsVvsIIFf9aOqKveW38ucVKXlAAAgAElEQVTqXavJ7pNN0dgiuiZ2Jc2ZRoo9DZ/qMyXR6+9eT1F5UQTpLb2llJd2vsS4i8eR5kjD5XUxpNcQhi8Yzmu/eQ23122w5Fn222XIsmzobdUzqpnxP6DF30iH34tNsaHIFjwdbiyKkC8HUTbd4fdiVWxfm6T5uXC/nWvB27Bhw7BaraSlpQUee+GFF0hNTT2lcb7PRDUt7ugpERCDbcLQYnNrg8tK6Ei8GEAQohGvCd/SMGg//VxkWP/V2a+Ung1XvABrLjA5dq+prYuWtxmp6UNB5OyZQaVLnwuSB8L/Oy/yTf+sWggchRLJYaXGvqlwyxh7Jlz6J/C7wkqMy4M9X84sGP4yxHURZbyuGqOJfVxXkaWNS0ezJiHpWdvqMhgwQ5zfnok26AGkbdcHz3HlWvC7g16EuvVLXA8sje9FEPHjbTJkZCTib95n+pnz47+jSRYD+dXLexMsTWfMyubrQoyonhixuO7E+DbMzbAOR7OzGvtPYZcVsinWMWIZh7QudLfbkLUOZFkSXtXha/jQYrFmbcgJrmGhhDhkXdMcvZDenWEsJ3Zm4R5dyU0v3s3qXauZmnMrC669B6dFATkORYlD9rfjk2Qm/+9drNoVfG1WehYv/fol2jvaSZHbufSTKBY1/yjEM2Yzk/93BunOdO4cfScTnpnAK78oZvjnkX+X3htQQrMWjzPOSe+ULDpUX9S4LjTm/Tpju3PhXosR1TOAc+GDNMO5Oi+IPrcTffHCyeiJvpjtcjM5T4wgMzmT+dfNN5DFJQVLAmW11fP3kSClo9k8+FUf7Wo7qqoiyzLN7mZsio0L5kYGp589+hnp1u40+o7Qd04fsvtk80j+/2fv3cOrqO79/9fM7Fuyk+yQQAx4iUVordXWKi0qBLnYSiscLsqDrfqLyGkrseqhipFDD1IVMQf8olJjT/tFmqOttQoJFS3WInckrVqttl+qCAIKMZCQnfu+zMzvj8me7MvsnZ37Tliv5+lTksystWaSvXx/1uf2kOn1zHBk0Ohv5FTTKWoaa8xeryEj9trHr43wzGa7slFRuXn9zaYXuK6ljgxnhqWXtXxBOWdlncWhU4fMglGjh48mz3kOqqpjt8scbvgwIim/r0qap8LfmxBv3SMVfnfx6KpHNeL6aTvi9klV0wpo1kcYIaaKK7ZHnrvAyO1sqwbFDW/fZQifOF5LfdpOpD+cHzvXvx1GV1uRgk2GVzOeERluMKadA/HEWXhI7rf2GG0dxq0zclRdZxk5XJJihBADtJ0CPQjOXGg6DNkXG2Fy79wDX1sF9swIAzPkPdXHrSOoych6AE2yI0k2s79tq55NmlSPTABZcSA1fQQH1kb0RFSVbFBbuuzlTORR1aduo1HLN+cOD2PsTr/I/kYYqp0jdF3npMraYvL3gx6G5WSYawv93CYHLY1Nfdp2pLcXm/uG7srntO6BoMvUJ1af69AeFbj0v7HvCPPU5o6P6aeqF25CTStACdYjtVUbKQmHyglevJxPtWF84T9Hc8Xo8fzh5pWMeKfDYNYKK/EyhtPt2u62Cbdxz7fvQZGNuhOZzkwO1x4mEPTztUyZYW8VRa6vvfrvsUl7OKmmkZ2WTYOvgcOnDlMw7Dy+4tZw7ptn3nPysvX823PLOOGt7lTXKYqET2qmuuF4RBRfX2i7VPhb685el1ol9ARDhpDHtHD1BC5YNprC1RM42nQQJaz9gKrquLQsMqRcXFpWpx9If3tea8n0EtNIhY5qvaHCQzbFjt0uc6z+KFeWXskX7v8CUx+bSrOvmVZ/Ky67y7JceJot3TAIFQezLp1F6fWl/OB/f8BFyy/i249/m+rGauyyHZfNhdPm5Mkbn2T86PEcqT3CqaZT5nryPfmc8J5AQyPNlsbyGctNI7V0aynpjnTL/NzQfcW/KWbymskU/6aYE94T+KRmFEWi1l9tGqmhe0RJc8FgoinoMUJow1oHdBQDiSWiHUOo4mM47ZUhdTmNjOBHSDW7DY+fVSubYIshenynOozIUA/WsGv1wgpUXNZzaT6kf64xwm1DAgra81Svh8vWGEWVvrbSbOWCz6JnX/MRI3Q3bGw97RzUCRvRJZthPL82Dt75iZG/+sY18PJY2HejUQU32GK0b2g5BqrfEHThXtDQHFUL4eurkZqPYMNnGIMBD6db0802FD6/Zral0PWgEWL32WbDiH59Imy/Fkn3dbmlUKLfuV5YQaOWHzF3eNuMoKrjlcYQmLIXdcZhAlP2ppSRKhAMJUIGpH37BJQto7Fvn4BHP2jkzLcTVHUagx4+amylefxvY9u/qG0Ex/0PqufrBJznUx84C9XnjNB10Z9rbdoughlfZF9uEe/Xeam9fEPHuG3VeMmg6eo/o153AMaVIf3rKWwNfzeiXV6fCO8sRrvkAY4GM0GSKMgt4LGZJR1GKrTnmc4mw+Ylw5HO4Qf2UzanhNbGT7h1QxHXPn4t1Q3VDEsfRkuglePk0jzptY4WZqEWNe3taVoDrThtTtLsaeRl5nHk9FHuePUXeAv/xOEJO9h3wVr+7bll7D9UlZSuO9p0kL99+rZppILQdtEIQ1XQJ1hV9e3pBy9UZCleA+W8zDwzIb1BrTVDa8EwHmsaapj/y/nc+KsbeXbhs6axGjq9Sm8PrXVLHh6b95jZliY0/tyn53Lg8wPUt9bzy12/pNnXzKo5qyIKPY0fPZ6Vs1dS/Jtiblp/E4dqD5kb1OIXFrNqzirOyjrL0lB22pxmiHBozgW/XoBfbaNZ91LdUG353AHNR6N+ija5IeIgQCBINbpqgEQYR1b9Pq/YgOYeja4HjVN697mGpzHUymbaDuP//7XOqNTbfARsbvTsr6KlndvRgzV07bgyVMcofHpGbC++8euNCpXnzIDW49bGZ6AJLl9rtHi5bK3hFbC5rY1eu6fj3xNfQsOGhNoRCguGd8LK+LSlYfYz1IOG0WxVBKn5CKDDmzcjvXyBKUDj9SvVNc1yDEmSsClSzDvRCuMfMtgUCVqrybKdRHOOJDC143dez1h8/sTlLUWfVIGgf8iweTu8nGAWL6MtsoBls+7l209MN6I9Qr1Rv/kr0EHy16HobTQEhyf8vIZ/rr3+HFRd59zsPC7weLh/23Psu2CtafBNf+ZOVE1D2XGtcTB3zoyYA0J59xzy7EEefuUhnl34LOdm51nuYTIBcrXjnP/2fJyvfInLDxSz54c/5w//voGHtjyIIiv8ctcvqWk8yYH6Bmp9fuOwsd1IDbWnuefFe/iw5kOuffxaJpZOZPELi/neN7/PuydPMOXpIiY8MZf9YYU3O9N1s8tmk+O21rR+tU3oOoShKugjElX17S5uyUNlcSXN/mZLQ+/cYeeaoRIBNRAx/6o5q2gNtFK+oJyHZj3EsPRhlN1Uxo57d1B2UxkuuytiPB3dcv1uh5uF5QspuqqIBb9ewDnDzuHFH71I+b5yxo8ezzNFz5je3pLpJdyy/paYDcqhOHj+B89HGMobbt2ALMmWc6q6SkD10+JvsXzuY3XH4nqtBYJUoysGSIQ3rrbKCGOdug195sfo03YSdF+EVzsHWfd3tJJ5t8QoyPHOYiNU+J3FcPFPDUO33QMbxIWqK+hTXjeKHP3TKNahuQwjNd1/AOn9nxnG5rf2wNQ/Q82bhqcx1ObFwvjU7ZmwbYp52s/XVoIWtPbwyk7TOEZtQ9NA0gORIsuRE6fyr81Y08l9IDuM78XzOLeeiDDa5Q9WkGGzPjDUsMeOcfYspLZqpD9fhfTXRcZ6ZxwwctVsHjLsXnKcp8h2NpgGcMhDw5+uQNkyGtu28Sj+kzEi1qZIZDsbYu4PJ5lrBAJB94mIXAnRfMSI3ggjpOscUtAwHN8tMaqQVy2A1ycibbs64UFYOKE9wvnGJM7dNRHP7m+zZvrtZLo6wkLzs/KNPNPQ2uLshxlqHWXXLWKUZyQZaTmW+6Akyyjhh4DNR1D23MBX01r55b/dSVug1dR1WenZHAq48Ra+xrFJe6gvfI35LzxM5bubKZleEmN4LixfyAUjLuCFH77QZV2X78lnWPowS23398/+LnQdwlAV9BEh72c4Zp+obqKqOudljOHr51xOxaKKGI9ohpRjhpnYFbv58/Gjx5PpyjQ9mz/43x9wsvEkD255kMlrJnPdk9cx/YnpNOl1NOqnaNLr+Oz0Z5brr2up40jtEdOrK8vGR+i/ZvwXq+as4nTLaXNTiuf5Pdl0krZAm2kor52/lqUVS418B4s5HbITu+IgzZHGhls3xGyEWnt4jggXEQw1wj2wzPqEwNefoj5wFqfaRnCqNYfTrent7RMcke1YorykOIYZBYqu2ICWMRpFbcT+xgSkLV+Et4rRv/E0wWlVeKUxpEm1RnGh8PDXN66Bgrkdc4R6oEaFs0rv3BPr/ZRt1h7e+veMMFt7JjhH0BT0oEvthmLueKPyb9pIa+PT+w94514Y+yOj16C7wNrjPHEjKGmRRvuX7kSO819+qzBdvl5qtMwJtYfYeZ1RvEnXkFs/wf5GZLigmetm4aEJN5DjhRuGi9xkrhEIBD0jXlg/sjPiWyFd1xpUjZ9fVNJRPAksP+chog+cMh3NkXuEKx8PTVzyjx/whb2Tuerjxbx443+BktGxtniHcW01OPbewHCbypItazh5WeQ+qE6sQEOyNsZtbka8s5Bz0hwRuq7J18xP/vDfnAjY+dyPWYApnq77vPFzWvwtXdZ1y2csp2RjCeuL1kdouxd/9CKlW0uFrkMYqoI+IuT9jDYmQ5Vru4uq6tiC6RRkjmX3kr0cWnmY3Uv2xiSdZym5bFy0kYLcAkqml3DDL26I8WyWTC8xrz9Se4Rjpw3P5KTVk0hzpMV4PdcXrad0a6lpsBbkFnDo5CFWvrqSXHcuC369gJrGGvOe0DXhFOQWkOHMIM2RxnVPXsfkNZOZWzaXqkNVlGwqoaI42gDfjCLbCGoBzsk+h+f2P8fa+WsjNkJZkiOeI9xrrSgSbXJDl0KDFUWi2lstwokFKUHIA4u7wPTGRYueVj3bMLAOlRvGWqh36P4iUJzwzj3olzxAMOMSNGUY8s7pEeJK2j0HXQsSVPVYr2b7NUg2wzhtr3YbHc6Kc3hkJcrQfaof/ZL/ivXwZn8NpryO7j4fMkYTVHWa1Fz0q181ck7fWQxv/n8xBjHj18OnWwyv8RvXwAerYOKLHQb6uDL0GR+iT9uN7hoZ2bew3XiWUOO+6/DQbH3aTqNisdX7SD87Ngxvz2w8jjpsUltHtc7CTR3e3DDFkYwxm8w1AoGgZ8SrHRDRA5UOXffI9g1oE18yfh4nzDYcqwMnxX/cODwMcVGJsZ+48o0944pybG2fA3SszeKAkPHrje83H6Gh5RTXfXUG//bcMjOEuGHS60z85SLe++x9ayPXXwfNRwgGmiN03RPbnuC+6feR687l45Mf95muu2jkRVQ3VLOsclmEtpMl2ezveqbrOttAL0AwNAl5P3cv2Zt0Vd+uju8iCyRAA5Wo8t6qgzHZF7L7vt34g9ZhyKFerEBEnumR2iM88uojrJy9ku33biegBjhYc5Bllcuo9lazvmg9695Yx2/+/Tc8s+cZ7px6J5/Vf8aR2iOUbi01GzlveW8LL93+kmkkh3qs/t/d/5d/L/x3syl1iGpvNfmZo8x3ZlfsNPkbubJ0fEQbm6UVS80NLGQ0hz+HTbGD1nkLICu6c49A0J+YlSO3zwZXPsrFy7FljkV15qFd/j9IBJGv2YnU8qmRY9VeDEOqfxe9vUdnInGlS3YkiybxyHbQgcseQ087B68/F7R2Y0rWQfN3NKYPu093DKNFH07atF1IesBYl67BG1MNI9ldAIUV2BQjbzM9LRvbzvZ+hM1HjDYy48og64tQ/77xPCFPhisfvvB9+GCl2eJBd+UbhYpaNXKctSgWz6pr8fNDg6pOvWpUYM52NmD31Vk+F7pq/R5bjxnv/exZMT1c5cIKbIpxWGmTg0b4cMhDXVsVI3I7+11F/11EVy0Vea0CQecEVR2vMoaMKXsjKnAPkyJ9WSFdd8eU/6DWZmO40ma5V0YXWMuweY39OupwkHFlRoQGGGG9rnwjXSJsz1AKK2hwFpA5bSeSHgTZgX7NPuSWwxH7O+4CjtXXkJOew/5DVUx4Yi4FuQWsnb+W/Yeq+PGmB9la9Cyev94SW9HXXYDTmUX5vnI2LtrIH9//I3dOvZNrH7+W8gXlPLjlwX7RdXPLjCrwoXWHONN1Xa95VKuqqvjyl7/Mc88911tDCgY5Xanqm8wJUaJrrKoMH6r/0KjQq1hX+W32N5v/DnlLQxRdVcR1667j3WPvct9L9+EL+nh8/uO8eter5GbksmruKvxBPzO+NoOF5QtNT2rVoSrzZOz+79zPw688HHFK9vArD3PVmKtwKI6YMN7K4kqcuhuXloXHNhwNldrmWtbOX2tWF17w6wUsn7HcvGfjoo2U7yuPGCO832pXC1r1RREsgaA3Mb1sIVHzVjHSli9i23YVsv8EkuZHUtuMkN3dczt6pl62FpvUhiQrhhEVTpi4alJz0SdujAqhfQnef9gwLl+faBQwgg4vwem/GmG/0aG3V78Ckkw6nyOhg5xmGLQhL2f7ulBbDE+kIiFpUcZZKNwWOkLxQrlaIYM1LExZemMaaVI9ECfnNIlKvSGagh4092hrL0ZbjbWHwjHM8Ph+vTQmLFDaPYcMuxePftBocRHyMH9tpfEuotaWbKVhESLcdwhtd2aQbO2AkK7Dn069PzdhFfeQZoM2ywMnPXNsx73BZqNeQPSe8f7PSG/7GHnb1Ugvj0H6cyH4alDtuRHFjk5etp7VO8vj6rr9h6r4W0OQA18tR5/xL8NIfm8ZtFUTnLiJGr/OI3Me4aEtDzH3srlmrZG6ljqqvR0ez5LpJULX9TO94lFtampizZo1TJo0qTeGE5xhJHPa09k1PqmZ497jlC8oN9vAzHl6DmU3lTF6+Ggqiytj7j0rcyTHHv0UlSA1DTWUTC8xe6PmZeaZHtJ4PVtL55aa+Qpb3tvCa//xmtljtXxfOY9e/yib393M5ncjwwGXXLuE/1f9/3hwy4Osnb+WnPQcmv3N5GeOpFnzgqxzqulkRL/U8D6xF+ZfyKGVh7EpdjKVbNbd+BRr5z0e47VOWNAqjn7rzj0CQX9ietkuWxubH7V7ttEvtelwhxcwd7x5Si+1ezD1iRuNP+e2arh4uSGYJHA6ZNKkejTX2cjTdoIeNAzHf66Bw88Y87gL0CV7pJfAkWMYi23VxrocOaBr6JrfEFahE/wrNkDmmJh10XwE2V2Ap7ASScm19mDWv28Isys2dHhv4xQXCXkcm4IePBMrY/qRGkKy85P0oKrj5RwyM4ajtL8PJBua5ELXQS6sNN55uIfi3f80PKmBJsu12fAhRYXzUrXQCFl2nUWrng1oXVq/lcdG3jObjCl7Te+woOsIbSdIRDxPbLC9P2hIs/325rVcZbGnBaV0mLoXTWvh8OnPGTtsRGwEyOgi7HvnxezzbVN20nr1Nk43VXOsvobVf1jHAzNXcFbmSA6tPIzL7uTDmg8pnVtqakK7zcGXH5nIwom3sWbmfTR+5THj3t89yI+n3mlqrNLrS00dFK3tvK1eoev6mV4xVB999FEWLlzIjh07emM4wRlGvNOePUv2osvGh8ymK5bX7F6yF7fi4dOG4xT/pjhmA3A73Ex/YjpvllSxZ8le/JoPWVJwKi7SpAw+af4owoANhfXmZ+Wbp2KarvHHu/+ITbYhSzI3rb+Jam81zf5mfEEfsy6dxffHf59rH7/WHGfTok3UNtXGhIEU5BaQn5XPPS/eQ9WhKuaWzWX86PGUTC+hKdDIh59/SJo9zbKq3Nr5a1n8wmLsstM40dQgoGkxIdAhQoUPoucPhZBYkWZP55W7XsHtcJube7W3OuE9AkFv0lkIp4YDJYGRhiR39EetWmhZ8EPacz3aNW8i+aqRds9Baj6C3V2ArXAT0ifPw4E1hlE0eSuorUg124x7243cJjUXtxTWHzVU5KO2yvBsAlz9CtLuyBxO9i8wDOnoQiS54+GiEmS1GdR0mPD7Dq9reIhaaIxrdrXnpZ60NGpDHsdEQrIrobJy26cdxqW7AGliJQ3SGGAMnmm7OsJ9Q2F49e/ClNesDW5Jsf69ZXwB6d2lpH39KXxkdbr+iPV1IURYkDxC2wk6IzxVwMD4bIbrunteLuUPN6/v6G/aXuCoUXfillqoaayhrukkhxUbY6L3jDh5sCcbPsXmHgNp5zPSeTZP3Hg5EjJBLcgwxwg+afiIog1FEeG15w07j4LcAj44/g/+Wn2Uc4adw4gReayZ9xg3rb+JqkNVFOQWoGqqodU8+THa7s8/+bPQdf1Mj0N/d+7cSUNDA9OnT++N9QjOQOKd9rQGW8xQ3mOnj8U9EWrWvTHNkheWL2T5jOVmlV5VC3Kq+SRTH5vKF5aez5Wl46n1V8cYvwvLF/LkjU8y3JnPH+/+I6vmrOIH//sDLlp+Ed9a+y0+rf+U/Kx8KooryErL4rxh57Fm3hrT4xoaZ+7Tc9HR2bRoU0wltwZfA9XeaqCj7+riFxYzdtlYin9TTKYrk3xPfsyzhveJTYauFrRSFInPG0/E9H3devfWHhfBEpwZ9LSVSDIhnK16NvrUbZA2yjr0VNciK/96LrIUOpLuj+xZ2nwEafdcGPPvhuHYfAR5x3RU59lo03ahzzqKPm0nuiOXNKkeXU5P2ONVzxxrbZAFvEY/0pAAC3lW31lshBVv/zaorTB+g9EGJrzpfGiMlmPw1p1gz0Iv3JSwt6lVSF9XQmUTFTQKqjq6pkaGWYMRlq2pMSHDWmElKi7r31vDAfhsc4xxmUxIYrIhwoLkEdpO0BPCdd3+Q1VmgaPAjIO8fWEZt2/5OXrD+2Z7mqs+Xkyu7OP0+N9H7BkBx3DLz/ax+hraAq24JQ/e1nomrZ7EefefS+HqCZbabsGvFyBJClvvfi1G1x33HgfaNdrtLwLw4o9eZPmM5THa7t4X7xW6rp/p1KM6Z84cjh8/bvmzrVu38thjj7Fhw4YeLyQ3N6Pzi/qJESMyB3oJlqTquqBna1O9zZYnRB/VfGR+L5QDGn1NmtOFL+izNGIvGHEBRRuKKMgtQJe0mI2ruqHa8j4dnVYascm2mBOwomeK2LVkF6M8o/jHiX8w66lZbFy00XKcsz1n41ScZhiIX/XT5GsiTU9j20+2cc+L91B0VVHMRnjDL26g7KYyrnvyuohnPS/nPM7OPttsiZMM2dlfZf/S/fiCPpw2J3mZeXHvr/Zab+77l+4nx5M6n09BahJR5Kj5CIq7AM/ESrzKmKSL2iQK4YQMwwsY/Mjw7rW3mzErz7YbQkgu5ND3d8818kQtiwEFrQ1J3ynD27l7rmG8qq14g8ONZ9szG6k9TFcrrES7eqtRQTi8xysKEqpRNMlqXl8dqudyZHzIcVo8sL8Ivvkro2DRO4tjPaZp56Jf+Ts0yY6i+5HGlYHNbeR5ya5OT8m7EirbmbfS9HCHX3PxcnjvP+FLd8OUPxnP0VaD5hhJo98dE84bXtSkO8ZlT0Ocz0T6Q9sJXZccQ3Ft0bpu/6Eqvv/cYlPb7L17E7lvR0acDHuriPe/8isOXVjGV0d+ib8e/TsbKv+bR6ZGemNPjytndeVanr75Svw0Ja3tVD1AujPWs3nL+lvYsWQHLpsLb6uXax+/lmkXTmPpd5fGjLP53c2su3Gd0HX9SKeGakVFRdyfvfXWW5w8eZJ58+YBcPr0abZv3059fT0//vGPu7SQ2tomNG3g/4MyYkQmJ082DvQyYkjVdUHP1+ZQMmJySCsWVbDot4vMa8Kr6YbnmTrUDAKolkbs0bqjVHurqSyuJKiqMRtOPONX16Et4ENHt9zsAmqAE97PyUnP5c2SN/FrfstxFFlB1XUWv7CYfE8+K2evNDfIgtwCKoor8KR54hrZoTHNEzOGUVvb3OX3q+AmHTf4SXh/i95q7dn2tQ3I354sSykldASJ6Y08wc6Moog5wiri6lkXEtSdhmEShEx3entOpYoqu2NyKfWJG+Mbkm01Rlhx+9ca7fmof1vRkX/qr0N+fwWBy55CDQ9LDXjIdDRj874NrrOM8NxQD9L2HFXNaRhr0G6wac3WBrP7PPhbSUcIc5gB5vXnEFR1sp0NyNunRNwvuwvImLKXJjyWob02RcIm+ToNlTVDg2U5YXixlZGoe76C9KU7oWpBhDEqEewI5526F5vegtT4kVnUpLvGZbIhwoIO+kPbCV3XOUN1bZ3pupGZ1qkb2a50ajU3nwdcfP+5xRypPcIHx//BYzPXcm52Hpnpw7nt+RIemLkCh5pBffBk0tpOQiIQDFgbsapKAJV0u9vUdf6gtbbTEbquu3RH1/UoR3XcuHG8+eab5tf3338/F198MTfffHNPhhWcYVi1srHJNjOMAqDqUBXr3ljHriW7kFHQUFE1jWbdS6aSHbshFlcwwp3H/qX7cagZNOvemA2nfF85FcUVEcntzy58lht/NZ9qbzXb790e1wAtXD2BfE8+q+as4oltT5hGdL4nn+UzljN6xGgAc23HvcdjTtjmlM1hx707LOeo9laz7SfbkCUFm9y7rX3i0Z3cB4EgRG/kCVp659qNIsVqjvaKuNqMw0av1XYD53RrOpBuXmYLM2IkWUZ++y4jPDjKCGT8evjXOhhdFOGVy3LUx7RaYfx6ZAkaAh0GYaaj2egP+Faxcd3Zs4xcTf9pdFc+Kmk0+t2mAeVVxuBJqzM8q9EGc2u1sQ6bGya/CqofzZFjGqkJ37liI1v6HKmtGtpqUA6V47l4BU2OsYZHurXJ8DTb3B3tYdqqTeMzugVQjOc6zKC0MhIVVKRoL3HVQqRpu4COvDab4iEjMx35yt/12LiMlysn6DpC2wl6Sme67kRjHV+w2NIahBMAACAASURBVPdGZJ2NFLCTEabrQt7YiuIKJD2Dp2/+BQ41A1XVLXXLvoP7YrTd+qL13PW7u3h8/uNJ6boFv15AviefDbduMP+9fMZyxuaNRZZsbL17K4dOHRK6rh8QfVQFKUF0X1RFkmKMzxUzV5Cl5PJJw0cxFXzPzxpr2bN1hMc4EXQrnpjxHp37KABlN5Xhdrhp9jfjtBntH47UHqFsexkbF23k+qevN+/ZuGgjT21/iiO1R1g7f615kpbrzmXbT7bhbfUy9+m5MWvLdGVZnmrVt9bHbKgVxRUMdw9HQia9/TnUKNEV0TNWcVhueMlcE04o9yH63bolT8z8AkE0iYzMZEkUwjmsB3OEGzE5zlNGhV7oyGN15EDaSPjbfeiXPIDmyEObstc0nCS02PDcqoXI03aS7WxA8tXAXxfB19dAoCGyP+j2a2FcGUHHudT70gk3oIKqjtefw7BJm2HXrA6PZGEFkhboCPttN4x1x4jYwlJnzzIM2vTzwJYGqg9ZazLa5Xy2ucOo/mAFGZc/ifzuCrhwcYcxHebpDRmfyXiuw9cRbSTmOGstDejo/q3CuBQIhi6JdN09L5ey5ZYNHeG/7gJqL9/AjKdu5ER7JFxnug5idcusS2dx4zdv5Gcv/4y189eSl5nH8Izh/PfW/2bzu5sZmzc2aV0Xyindee9OaptrY7TdJaMu6ZKuy8/Mpy3oS2ikdqbbzkRdJ+m6nhIrFSEiiUnVdUHfrS30gQzfpJp1L4WrJ8ScDu1esteomJZgbdHjScBEi7HWzl9rNl4+vvo4ftVPUA1iV+zYZQej7hsJwJtL3+TKVVeaifO+oM+sPBy9tkRzjTtvHDo6qqah6Sr3vHgPm9/dHLcpc3fb+RgG8AhA6nST1AgiY+uXE794DNXQ377e6wZqrzC9cFFGpldKPkc1NI7hoYwM4RwxIpPTdU09niPb2YB9+4QYY1eftougplh69XKctShbvhA72LV/gWATpJ0Lss1oG9N40Kg6HPLYvrcM/cpnqQ+OjLvGEcPdBBpPmB5fSZKQ6t83xgkVKHIXoE3bRW3rMPM+p0MmM3gA6YOHLD2+ZhEmdwFcthY9+6tI9X+3zHvVp+1G04JoOJBlHeUP5xo/a69IjCMH3X0+9f7cTt91vHesTduFrqmdVhkeDPTm50zsdX3LmaifeoPeXptNkciwe5F0H0EUWnCTKfmQdB/vnTjAjzc9yP5Dxn6XrK6DSG2nKDKTVk9KqOtOrK7Gp7YRVIPYFBtOxcXIJYZRuuPeHUxeM9nUdeGVeaPH3LVkV9y5xhWMMzWdQ3HR5Gtg+hPT42q20HMk0nZnqq7rcdVfgaCvCDWWzpBycWlZqKqeuB9UF8fzxxkrJ93ITyvILSCoaqRrOWRJeaRpwwi2ly0HyHJlUZBbQMn0EhaWL8TtcFuvTQvQ5G/kxdtfjKjU9vsf/Z6c9Bya/E18cPwDbLLCtP8zzezPdaTWuilzMs2bra6ZUzaHt47+lcLVEzjadBDFosJn6B0V5BaY71wgSIagquOVxhCYshd1xmECU/Z22UgNjROvymvEHP/2qWH42LPJsHmTrjDcFPQYRZfCKktyxQb0YEtc40nDbl2ptuVTOPAEBE7Dtsmw5UuGp/JrK42Q2aqFcPFyo18gxK+ILMk0BT1IgXrkbZOQNp9njDPu5zD1DbMKcbRHMk2qR9pzveFRtfD4clFJx9euPHTJHrfdg9R6FOXN72FvfA9Za4VpO+ALt3VUJN42GWnb1Xj0gzgdcsLqzk1BD9rEyHesT9yI/PZdnVYZFggEQw+z0vgbE7BtuQDX9qvJDnxKU8DD0TaJcWuuM41USF7XQaS2s6pHEq3rAmrQ1HXpWg4BNWhqs7qWughdF7rXaky/6o+r65p9zfzt2Dv85Pc/wRdsNY3U0L3d0XZnqq4Tob+CQUVvxtvHGyu0UVmFR4SHUbT6W1lftB6X3cWR2iPmfdHjabrK/ZvuJ9edazaO9gf9+IK+iD5fG2/fSL4nP+J+YzNsAwXzFCxkrIf6dOWk51DXUhfRtzmeQR/acEM9aF0kV+RGMPToSh/NZOmPUM6gqtOEJ8Kz2pUKw0FVR0sbiRyqlOuvg3eXIrdVxy38ZBWSbHosLyrpKJgEHUbiN38FwSb0rC8iSRIe+VPkv90Po4tQXHlku/JpVPLx+Y2Ny6oYFXtugHFlhrH4r3UROaQZNi82qc3IX1XSrAsyhRWF0l35NKm5ZLoCSFY5scEWY56qhUihZ5z4InywMrJA1gcryLzkAbO1j9W7D+WtDvv2ftRAW0decCjkuhuFtgQCweAlUbG9Jj11dF3p1lI23r6RtmCbOYZftS6q9Nnpz/jfN/83oa5bX7SeRl+jdWFOzYdbkUzDsTNtd6bqOuFRFQwqutpDKoSiSLTJDTTqp2iTG1AUiUwlm4riioixKoor+MZ532T3kr0xYRkQWSBgeMZw1r2xjmHpwyjILaB0aykv/ijydG190XqzXPkze5+haEMRNY01nJ19NresvyXiZOz6X1zP8hnLI+YryC3g75/9PeK0zK44mHXpLLNPV6g31snmGvM0LbRZR49V11JnzpfsaaVg6NGVPpqpSLzenh5HXVI9XCWtBXZeZ3hBQ/0/ExR+CnlytWm74Ft7InubxvFQ4j4P3lmM9PJYbNuuQlYbjdzQ9n6p0hvTyFQ/NNcZrzASNjdULUS/7DGagp6I35308hjY8V2jpc7ZsyLvdRcYRnh7zmujZhjFjVq+0cc13KM8fj1Itliv7J55hrc2nNFFMf1nQ31Vo98ZafnU+XKNXqshIzXs2bpSaEsgEAxeEhXbSyVd9/zC3zHKM4ocd445hk22seHWDRFjbrh1A5qudarrFpYvxBFHjx2oPhDhBe1M252puk54VAWDCqtKconi8qu91QTkIKeaTkYktlcWV+KyuyIS7vOz8sl15BMIGEd48RLNQwUCFEVixcwV/GfFf5pVf2VJNvtr1bXU8duq31J0VREXjbyITcWbKN1aytyyuewp2WN5MjY2b2xE+fL1RetZVrks4rTMLXl4bN5jTPs/02JCQEKnaZlKNtt+so3qhmpqGmso31fOnVPvZFnlMmDwVX1LBZ5++mleffVVFEVB13V+9KMf8d3vfnegl9UteqOVzEASV/RobeD9h1nlNp6HNdmiTDFeZzWXDOU08js3dXhWncOt29w0fhxp9LWd7Chg1P49afccs0dsvDXhr2v/niFmrD2v84zqwvXvRhRkiigK1e659fk1VGVsbBXkCxdbG8quvMjvxTHMExmdvVFoSyAQDF4S7QGppOuQQNElJLxmxV9ZkinZVBKh7Z7b/xz3f+d+dty7g7qWOkq3lvLYvMcsdV2zr9myCvGyymVUe6tN3daZtjtTdZ0wVAWDjuhKclYbT3jSeXQifMjoK7upjM3vbjZzQs3k/STDJkKb67obn0ICdi3ZhY7O9b8wqsndNuE2br/6dub9z7yIzWndG+vIz8q3DCVp8jXx6l2v4rA5eP+z91lWuYyq9ryN0GmZKunIkhI3V1exSTGVkTct2sTzf3meqkNVg7LqWypw8803s2iR0QPu888/5zvf+Q4TJkzA40l86puK9EYrmYEkrlHn/YfhsQxVuf36U0mH8kb38Ixu0aJcvByb5ytgy0Gf+gZIMkh243+FlUhhfVop3AR/LY6c1OZO+M4Thhe7C5AaDpCd5kWXhlkblP7TZsGkoO4yjNPW0Oc78nMeHqJtUyQ8X3sUWdINb3FbjVGtuL0Ik+7K7wgVjv467N0nMjqTed8CgWDo0tkekCq6Dgxtl+c8B89Zw9h57050SafaW83csrmMHz2eVXNWUTy5mG+t/ZapsTbcuoFR2aMsdZ0n3YO3xcv2e7dztPYodS11EdouqAZAMuaNp+0kOGN1nQj9FQxJwpPO4yXCux3umO91NWwilKTu1LJI04aRKeVSWVzJrEtncd/0+0wjNTT+wvKFPHnjk+Q68tl8x+aIUJLf/uC3BNQA333yuxyrO4bT5qR0bimbijcxfvT4jtMywCbbLUNAbIrdMuF+7tNzuXPqnRxaeThu+IsgMZmZmea/W1pakCQJTRucR5caDsviQIPFw2VVrIfx6w0DK5QjOrqo01DeRIWfzPBiV76Ru3nwl0hNB5H+XIj08gVI2yYjNR5A+usP0WUXganGWNq0XejOfKPqb8SkzdbvXLJDazVZtpNozpEEp+1Dn/GhkZv63jJjnAm/B9mOpBp/d5aFnVpPwDuLCequmCJUnaK1wY7vwOsTDUP/ayvh7FloEytp1PIj3lOjlh/z7jsEpzW9VWhLIBAMTnpjD+gvXQeGtrMF00nXc8iShpu6buXslbQGWk2HRGiOBb9eQJqSHqPrXrr9JfxBP/P+Zx6fnPqEZn8zOek5lEwvidF1EF/baahnrK4THlXBkCQ86TxekaNmf3PEPb0RNhHysj5545McO33MciNVVY2ApnHJ2ZeYoS6SLHH41CG+/+vvk+/JR5Zls9VN6LRupGekeVqWqDdWffBk3HkzpNy4p5WCznn++ecpLy+nurqaRx55hGHDhnV+UxT90YZixIjMxBfobojq3cmkzdgzRzIiK3XPLyOeS/8qfHu/YQDW/70jZxTMkFXF7mJEVqJ3YfwuFF1jWFsNaD6QnUZ4a0t7yO1law3DN/T/0UWTLluLvHM68rf3Q9rZ7WvToLACQrmc7gJwnQUTXzIKJIW/c60J/nQtStj38HwFFAdcWmqMpbbCX35ghAufPQsKN8Lu6yM9r/9aB4UVXf8dtlbDn2bHPtc1u5HTzyZLkgFD/ClgHGWE3n37+5JdeQyTrOeM/FvMMMfp+icn9ej0cyYQCEx6WmwvFXTdpNWTKF9QbqmxWgOtlrruhl/ckJSug/h9T1VNO2N1nTBUBUOS8MpvpVtLzRzS6FyG8HzQ3gqbUFWdoK5S01iTsJKdLMtGjzAJ2qQGHDYHR2qNhtNFzxSZ9+V78mkNtGJX7DRotThtLhTdHTenI17VO0WRaVRPJdUkWtM02uSGpJtKDwXmzJnD8ePHLX+2b98+FEXhe9/7Ht/73vf417/+xb333suVV17ZZWM1Vfqo2pQLzDxFs1/pqeZO7xsorJ/LTbZTxW7VF9SVT31rBsGm+O/CpkhkOppR/Mc7CgS1ewg150hs7gKjcm6ogm68yrqufHTVh9ZwGE1yIEk2FOdwpMl/hIDX8Ha+dQe48tt7iWpo2JFkG7Zt4yONxF2zCEzZC9iw7y8yDOTw5wsVJZr8KgQawJ4FwVYYXYTqyKOui7/DHGerYSRHPZeqqp2M5SZkwNJkfV0q94jsKaKPqkDQv6SCrkvU4cGm2Huk65y6O26+brPuPWN1nTBUBUOS8FOpqkNVrHtjHdt+sg1ZUrDJdrOaXDLJ+93BoTgo31ces5FWFFdYbppuyWPmrYaHtIQ3nY4+hctznmNuiOGnaVYnchsXbeSu393F5nc3x202HUJRJN7/7H1mPTUrYrMfqmElISoqKpK+9ktf+hJ5eXn85S9/4dprr+3DVfUd/dFKpj9o1bOxTdxo9BM1CwltpIV8gmr8Y3QzB9V7PKbIkbxnNurUvWgTK5HbjkdU0I3Ji9U1uHQV0rarUdrbtXDFBnh3qRG2e8UGIyS5rRpt3C/w+nPMcLcc56lY49eVj00OoqGgF1YgqS2x13y2GS5eZhjAqs9Y26FytK9/s8vvb7AWOuqL9koCgSB1SQVdF+rwYGUkR1cp7q6us8rXdStnrq6TdF1PiRX2tZchWVL1BDhV1wWpuzZFkfArTbT62np9w+ps3hrfp5zwnuCJbU9QdFWRZfW56Pdmt8scbviQE94TZnjIpuJNEQUDwDhFK7upjEtGfc0wVOOsoVn3GsWVFNnczEL9ufIy8zh32LnYZSetgZaI07U2uYHC1RNi5ty9ZG/c+fqCVPMyfPzxx1xwwQUAHDt2jPnz5/Pss8+a30uWVPGoDjbiPVe2swH73+4w2qg4ckyjLfD1p2gKeuIaM9nOBuzbJ8AV5UabmijUGYdpCA7v8Li+/zP40p0d4b/hbV32F8UasJetNVrfuAvQp+0kqNki5rcpEh5HHfK2SR335o6HS1fB/gXG986ehX7540jbJsd6jKf+GemNazqM84kbabRdaPZlTRbTYI8qctIbOaQjRmRyuq6p1w3KvlxzsgiPaucIXdc5Ym1dIxV03YJfLyDfk8/yGcsZmzeWNFs66e3rELouMd3Z64RHVTBkUVWd/Jx8Y9Pox/j9Zt3L9Cemk+/Jp2R6CecNO490ZzqSJNGo1uNWrDfWQECjIGMs+ZmjqFhUwZyn5yQsGBCq8Nuse2NCOcJP5BrVU+ZmZnWKt7RiKdXeaiqLKzk/ayzNwSDlC8rNkutVh6o6ChJI/fIKU5Inn3ySgwcPYrPZUBSFn/70p102UgW9j4zf8DBG9emUL3+qo2pvu6fTM7HSbFljVj6O4ynVsBNUdU63pmNTxpLx9aeQZZCm7TK8qJKMjoKs+5DihQS3/1vTdOp9WcRUFH57hWHshozfi5d3GKkAn21GAsOzGhaarBdWIL1zb2Srmz3XkzZlL74uNnsPqjpeZUxsGHhviD9dS/g76C6Dvb2SQCDoHqmg69bOX2vqOkVWEq6gO7oOqcMojdZ23dF152WMAV2PaK8T0naDQdcJQ1Ug6CGKIuGTmvGpbaiaih0b+Z58qg5VUbq1lJWzV5oV4sLDLeLlC9hIpyBzLLuX7EXTg3ELBtgVu1mqPVEoRyivo2R6ibmZQUelurXz1zK3bC4rXl7BAzMfiNvrayj25+oKTzzxxEAvQWBBvNBVCbXD4wYxxox53z9LI41Fi9YpsWHSHWQ7G7DH63/a/u/oMNoIQ6ut2vC+uvKM1i8WYb7a5U+hhRmSsqyjRBnmPWkv1Gdh4G01CX8H3WWwt1cSCASpTXd1XejeCCMTD7ZgcrrOpthRJKlTbZesrptdNps3S6o41XTS9OKGt0ocDLoudcs7CgSDgFA4yIHP/8nkNVczZtkFTFo9idU3rDbDMaI3kdlls/FJzbz/2fsUrp7ABctGU7h6AkebDqIoxtFWqO2NxzacTYs2RZQ733DrBkYPH40iyzHlymeXzaZZ90asMZTXkZeZZ3mKl5NueH6KrioyjdTQzxaWL2T5jOWW+RcCQSpg1apGm1iJrmmd9i3VJlYahuJ7y2BcGfqMDwlM7VrbBMtWOaG81DitWyIMrdoqI0T49YlGGLFVCxsN6n1Z1PlyqfdloWnWLWpSLq9U81n+DmySD5vS/WP8wd5eSSAQpC7d1XXNuhdN0zjadNBS2yWj62yyjRaLFoPR2i5ZXXek9gh+tc1S2z0277FBoeuER1VwRhMvvCJZmnUvh04dMnMPwNgEbll/C2U3leF2uC03Eb/aZia1h743u2w2u5fsxa14zDXZVIU9H+3htf94DUVWsMk2Tree5oT3BLXNtZZjR4dyhKrINenWlerqWgzPT7wN78L8C8lW8lI+4V5wZhIvdDUDb8IiQYlDXpP/W48ZR7IjSTakK38XN4w2nhdYxYU8sTIm9zLcuwuGcexJ4roBR3ZahlVLDQfwuBq6HQI8aJ5fIBD0OwOl64JqgJrGGksjc8+Svegyneq66U9M5/XFr3eq7ZLVdQW5BQQ11XI8WVIGha4THlXBGYuiSHFPvuJd3yY30Kifok1uQFEkAqo/7qZ1Yf6FnJ97vmXz5ngbR0DzcaTxI3NNd/3uLq4acxXXPn4tY5eNZfKaydQ11ZHlyjLb30SPHd48OoSq6mRIOVQWV8ac4pVuLaUgt8CsThc9nl12DorNTHDmElT1CI9jUNXjelrDvZtW9/V4/rYsTremJxwz3toa/W680hgCU/aizjhMYIq1dzeo6kldFw+bIpHtbCDHeYpsZ0OPvJsJceXFepvHr4cPHjRCgG3exPfHoafPLxAIhiYDqetsih1f0GfdYzXYkpSuO1J7hI9qPkpK2yWj6yqLK3EqTuvx5MERgSIMVcEZS3MS4RUh4m1+DsVBs785roGXKefGbCKJNg5f0MecpztCNIquKuKGX9wQE7KR5kgzS6RHjx0vlCO8P9ehlYfZs2QvF551Ec8v/B27l+wl15FvudbBEBoiEESTysZM9Nr49n5zbckaz901skOFnOzbJ6BsGY19+wQ8+sG+MVYlGa80Bn3aTpi2w8jFfW+ZEe7cw5zS3jpkEAgEQ4eB1HVuyYPTZq3tPqr5KCldB/DglgepWFSRlBbrTNedlzGG9PYw4cGq7UTor+CMJaD6kwqdhfib3/6SKr581pd58fYXmfeLebFNpuM0bwbYfMfmiJ5WG27dQIuvJWJN8arDNbQ1mH3Edi3ZhapquOxpqFqQ+uDJuOEu0f250CBDSgcNAppmrlUjiIxt0DSEFgwNers3Zir3ig1f24isTIJN1m0gevud9HfF3KCqE9Rs2C1a+IicUoFA0Jv0hq57s5u6TlV18rLzYvud3r6RO56/w5w3ka4DqPZWk581it1L9rZLNRVV02jWvZZdIxLpulBV5PMyxrB/6f5+b+vTGwhDVXDGEqqaFh3bb1UFLd7m51Pb+NT7KY/96THWzl9r2S81tImEWsmEDMmvjPwKe5bspTXYAsAtz9xCyfSSiDXVtVjnH5zwnqAgt4AVM1eQIeWADY42Jq4Sl0zeRmitoV5giUq/9zQPRCAIx2zZ0sutTACcDpkMpRZJD6BLdprU3C73Gx0I4r2TJsdY0qT6bhmvA1ExV+SUCgSC/qA3dJ2qBzndepqVr6yM0HXDnfn4/Yl1Hbg5P2ss236yjeqGakZkjOCz+s+o9labc3Sm6yqLK3HqbpwSnVb/TVaHdaWtT6ppOxH6KzhjcXchHCK0+YVTkFtAS6CFW9bfwuZ3NzO3bC4TSycy7f9Mo1Gtj7jWKsTkHyf+gSLL1DTWEFAD5Gflx4Tzlu8rZ+OijRFrrCiu4BvnfdMM61BVvdNwl87yNqLzNDQtsYjvah6IQNAZGTavdSuTbuYxhnA6ZDKDB5C3TUJ6eQzytklkBg/gdKT+f/4s38kHK8hUP+x26O5AVMxN5TBsgUAwdOgNXafqQeY+PTdG13mDtRHXWumg9z97n1a9geqGamoaa/is/jOe2PbEoNB1yYw5EEi6rqfEfylqa5vQtIFfSsiTlGqk6rpgcK8tdHIUHb4Rjd0uU+uvNjef8n3lPDDjAXyqjytXXRlz/aGVh8mQcs2v2+QGCldPiDlBK7upjOuevI6C3AJeuv0lHn7lYaobqlk+Yzlj88aSZksnQ8mmUa1PuMZG/RQXLBsddx3x5t+9ZC9uyRNzarf5js2c674g7ilaovFcWu+ED8qyRG5uRq+MlUr09V6Xyp/HROQ4T6Fsif0bVmccps6X2+3nyk07jbxtUmzY6bRd1LYO68mSe414z2b5Tgo3wTuLY54nMGUv9b7OP3umlzbKu2llOPY07Hiw/i0mQ28+m9jr+pZU/jsUa+s6vaXrQm1oDp06hNvhptnfzOjho7ErdsYsGxNz/cGVB8mS8syvk9F15beVk2ZP45FXH6HoqqII72xDMLV0XaJn6i1t1529ToT+Cs5oomP7rcIhFEXik4aPIj7wFcUVnO05l7eO/iWpMJN4ISZuh9v89w2/uIHt924nqAbJcGTg1DNRVZ2ApkWsUbZLNOl1BNQAdsVOlpKLXU0c7pIob6NZiT21m/XULGNjwnpj6koeiECQDPFatvTU0yfpgdhQV1c+Eho5zlO9kvcZj54aepbvxJUXtzdpMs+TuC1P5Npjwo4LK9HSRiJpLX363gQCgaC7JKPrQrQF2sw2NCHva7rDbamn7N3QdUXPFPHaf7zGo3MfxeVw4ZTTcOpu/P7U03WJnmkgtV3qxz4JBAOMVfjFnLI5+IM+Rg8fzYZbN3QaZhIvxCTU6yo07tHao3xr7bf4vPFzy7XY7TIfew8wafUkxiwbw6TVk/jYe4AsW3bCcJd489sUe+KNKQ6JxhMIukMy7WS6gy7ZI0Ndc8fDpauQtk3u06q3vVFd1+qd6K58y9BdqeFA0vMkUzHXMux492xs3rf7vlqwQCAQ9DHxQmsdsiMmNHfjoo1kKbkR9yer6041neLLy7/M5NWT+bzxRMw6UkXXdTbmQNErhuqzzz7L9OnTmTlzJrNnz+6NIQWClCHeBz6gBshznsOFZ13Eznt38vEjH7MnLL8gHKu8iVCvqxChDS5ROfUGtZbrn74+YmO9/unr8QZrI0qU745aR6K8je5sTJlKNtt+so09JXvYVLyJWZfOGlTlzgWpR1/lMTapuegTN3YYdxcvh/0Lej0XNppEObfRfUzRrXOHrN5Jo5Yf25v0ig3wwYO9+jzxii5hc/fqPILURWg7wVAmnrZrDbRygedCdi3ZxcGVB9m1ZBcXeC40C2SGSFbX1TTWmGNbabtU0XWKIiEBry9+nVfueoXxo8enRCubHof+/ulPf2Lr1q289NJLZGRkcPLkyd5Yl0CQMiSqIqeqOjbSsZFu/CBOmEl0OXO7Yqc50GRWgivILWB90XqWVS4D4odaBNRAXKNZleKHuyQqp+5WPDHl1Dffsdn4eRdCoc/PGhuzkQsEXaEv2sn4/Bo4LiRj2i4jDBiQeqHqbWdhvXGr68rEhNQyaTM25QJLozz2nWioYaG7siwh7Z1v9CbtwfNEEy8UG3+Ht6CvqwULBg6h7QRDnUTaLhDQSGMYae16KmBRiKirug6stV2q6LronNaKRRXkZ43CqbsHtOpvjw3VZ555hrvvvpuMDCM5dsSIET1elECQSoROraJLhMf7wMcjOm9iVN5Idi/ZS0DzcaD6AMsql1F1yBCb8cqp2xV7UrkT0XRWbvyszJHsuHcniiyj6zo6etyeXfFCoTvLfRAIBgqfX8OHUTgp29mAvYe5sMm00olniudFwAAAE3tJREFU6EmoMZ5Wds3qUh/TcOM129mAva068oJeyO21ainDFRvg3aW9Oo8gNRHaTjDU6Q1tF0/XBdUAiiJz1+/uMnUdWGu7lNV1Txu6zjbABdF6HPr78ccf895773HjjTcyd+5cfv/73/fGugSClCH81Moq/KK7yLKMS8siW8ljlGdUxClcvFCLLCU3qdyJcBKVGw/97MrS8dz4q/kcrDnIpNWTOP/+8+OWJe9u7oNAkAr0Ri5sMq104s2ja1qv9jHtq9zemLDjqXvRnCMhZBT30jyC1ERoO8FQpy+0XUjXZUi5ZEg5rJi5otMaJkLXJabT9jRz5szh+PHjlj/bt28f3/jGN5g5cyYPPPAAp0+f5nvf+x4rV67kG9/4Rp8sWCAY7GiaRk1jDb6gD6fNSV6mUe48+nuybH2OFAwGOdFwAr/qx6E4GJk1EpstfnDEyYaT/PXIX3E73NS11FG6tZRqbzX7l+4H4IpVV3Ck9gibijex+IXFMad6+5fuJ9+Tb667xd/CgeoDPLjlwQgPcOg6QWJEe5ru0ZvP1RG2G7/qbSI6a6WTaJ4Mmxf79gmGsZo7Hi4qAVceWtq5eP053crJ7enz9NU8Q/VvEQZ/exqh7QSC3sNK18myHPf70QyUrgut/bP6zzhad5SaxhpKt5ZSdagqZXRdp6G/FRUVCX8+atQoZsyYgSzL5ObmctVVV/H3v/+9y5uZ6LeVmFRdF4i1dQWrPIDK4krOyxiDorpJxw1+qK1tTjiOi2xcACqcPt2acL5PGz+NKL8eyplo9bWho5sbWE56jnVhAV8bdXVNMevecOsGllYspdpbTWVxJQ41o1ff9VDtLSgYeHqaC5tsKx2reZpoD6n9YAV86U6oWmh4VC3Ch/vreVJtHkHf0x/aTui6zhFr6zqptq5Euk5VdRSS03b9retOnmy0XPv6ovWse2MdK2auSAld1+PQ3xkzZrB7924AWlpaePvtt7nwwgt7OqxAMCTxSc0c9x6nfEE5m4o3ke/Jj1vhtzdo1r3MeXpORN7BwvKFLJ+xHJtij6gMV9dSF7dKnFX+woJfL+CFH7zQa6HQAsFgoSfhtqGQWu3yJ00jFYhbRTe6QrBoByPoD4S2EwiSY7DqutBY0dpuYflCnrzxyZTRdT02VG+99VZOnDjBddddx7x585g5cyYTJkzojbUJBEMKRZGobjhO8W+KmbxmMotfWMzK2SvJ9+T3WR5AULOuJjc2byxuyRNR3rx0a2ncnrDx8hc0TcelZaXEZiYQ9Bc9baUTVHV0Te00V7U3erEKBN1BaDuBoHMGQtfF02Nj88aSqWQnresSjaWqWsrouh5X/XW5XKxevbo31iIQDGninYKV3VRmWeE3Hp1Veou4VpYtq8k5bS7znvDy5i57GnuW7EUliIzNHDtRGfdk1z1UqKqq4tZbb2XZsmXcfPPNA70cwQDRH+HDGTavWVkY6PC6dqFCsEDQHYS2Ewg6ZyB0XTw9drz+OK7h6bi0rKR0XaKxUknb9dijKhAIkiPRKViyzZQTVXqzQkJmfdH6iNO09UXrkcM++qqqm1XqbMF0nFoWBbkFEZ7SRI2lzySamppYs2YNkyZNGuilCAY5yYQPx+3FKnqXCgQCwYAzELrOLXmoWFQRo+tKNpWYXtxkdF1orFTXdj32qAoEguSId3KVZktPOsTCKp9gdtnsBD1MJda9sY6189eSk55DXUsd695Yx7obn+rS2hM1lj6TePTRR1m4cCE7duwY6KUIBjlBVcerjCFjyl7sSpCAaoupopts0SaBQCAQ9D8DoetUVSc/axRlN5WZVX+XVS6j2lvdZU/oYNB2wqMqEPQT8U6u0rtwctXVXlduycOKmStY/MJiM39ixcwV3TotCz+hOxPzUnfu3ElDQwPTp08f6KUIBgmdFUIKqjr1vixwF1Dvy4rJce2rHqkCgUAg6DkDoesAnLqbUZ5RFG0oYm7ZXLP7wlDUdsKjKhD0E9EnV2lOFw41o0ubQlfzCQbDaVmqkKiv4NatW3nsscfYsGFDj+fpj5Y7I0Zk9vkcA8Ggei5dg/r3YfssaD6C4i5g2KTNMPwSkGLPiOM+m/5V+PZ+0HwgO5FdeQyzuD9VGVS/sy4ylJ9NIBB0zkDoOqt5h7K2E4aqQNCPqKqOiywUm4SfJuqDJztNnA8ndHoX3a/LLXlQ24u5xCTl48GlZYEEitT+M73zhP0zjUR9Bd966y1OnjzJvHnzADh9+jTbt2+nvr6eH//4x12ap697C6Zaj7neYrA9V7azAfuuWRGFkNg1i8CUvYYXNYzOn83d/j+gKXGP5VRisP3OukJvPpvoGS0QDF4GRNe1j+1i6Gs7YagKBP1MZ82hE9HZKVqisYFuz3umM27cON58803z6/vvv5+LL75YVP0VxEUUQhIIBIIzg4HSdaqq92juwcDgiR8SCIYI8RLnk20OnSifINHYPZ1XIBAkj4ajI7c0hCiEJBAIBEOOgdJ1vTF3qiM8qgJBP5Mwcd66GnmvjK2j99m8ZxqPPvroQC9BkOI0BT14JlYi72nvgxpRCGnwn3ILBAKBwGCgdB1S386dCgiPqkDQz4QS58MxE+f7cOy+nFcgEEQSVHW80hgCU/aizjhMYMpevNKYmMq+AoFAIBjcDJSu6+u5UwFhqAoE/UxfNlhONPZgaOwsEAwlQu1n6ny5lu1nBAKBQDD4GShd19dzpwIi9Fcg6GdCifP7l+6n1dfWq2XFO0vKP1PKmQsEAoFAIBD0BwOp64Z6qxphqAoEA4Cq6uTn5BvtDTTMEuS9NXaoZHn02Il+JhAIBAKBQCDoOgOl65L5+WBGGKoCgSACRZGo9lbTord2uR9XvF5fAsFQxKZIZNi8yPjRcNAU9IjwXoFAIBCkFINZ14kcVYFAYBLqx3XFqiu4YNloCldP4GjTQRSl89JxoXsLV0/o8r0CwWDDpkh49IPYt09A2TIa+/YJePSD2MTfu0AgEAhShMGu64ShKhAITHrSj2uo9/ISCMLJsHk7Ws8ANB9B3jObDJv4excIBAJBajDYdZ0wVAUCgUnCflx9eK9AMNiQ8XcYqSGajyAj/t4FAoFAkBoMdl0nDFWBQGDSk35cQ72Xl0AQjoYD3JF/77gL0BB/7wKBQCBIDQa7rhOGqkAgMOlJP66h3stLIAinKehBm1jZYay6C9AmVtIUFH/vAoFAIEgNBruuE1V/BQKBSU96gQ31Xl4CQThBVcerjCFjyl5kAmjYRdVfgUAgEKQUg13XCUNVIBBE0JNeYEO5l5dAEE1Q1alXs8K+I/7eBQKBQJBaDGZdJ0J/BQKBQCAQCAQCgUCQUghDVSAQCAQCgUAgEAgEKYUwVAUCgUAgEAgEAoFAkFIIQ1UgEAgEAoFAIBAIBClFyhRTkmVpoJdgkkprCSdV1wVibd1FrC115+8r+uO5xLsbfAzVZxuqzwW992xD9R2l0nOl0lqiEWvrOqm6LhBr6+35JV3XRZlCgUAgEAgEAoFAIBCkDCL0VyAQCAQCgUAgEAgEKYUwVAUCgUAgEAgEAoFAkFIIQ1UgEAgEAoFAIBAIBCmFMFQFAoFAIBAIBAKBQJBSCENVIBAIBAKBQCAQCAQphTBUBQKBQCAQCAQCgUCQUghDVSAQCAQCgUAgEAgEKYUwVAUCgUAgEAgEAoFAkFIIQ1UgEAgEAoFAIBAIBCmFbaAXMJDcf//97Nu3j2HDhgEwffp0Fi1aZHnt73//e371q1+h6zqTJk3ipz/9KbLcd3b+z372M958800cDgfp6eksW7aMSy65JOa6qqoqfvjDH3L++ecD4HA4ePHFF3t9PYcPH+b++++nvr6e7OxsSktLzTlDqKrKww8/zO7du5EkiR/+8IfMmzev19cSzunTp7nvvvs4evQoDoeDgoICHnzwQXJyciKuW7duHb/97W/Jy8sD4LLLLuOBBx7o07UBTJ06FYfDgdPpBODee++lsLAw4pqBeG+ffvopd9xxh/l1Y2MjTU1N/OUvf4m4bqDem6BnJLt/DAaS2XsGI8nuXYOZn//856xbt46XX36ZL37xiwO9nF7B5/PxyCOP8Oabb+J0Orn00kt56KGHBnpZgjBSVdulmq4Doe26g9B1/Yx+BlNSUqI/++yznV539OhRvbCwUK+trdVVVdVvu+02vaKiok/X9sYbb+h+v9/897Rp0yyv279/vz5nzpw+XYuu6/ott9yiV1ZW6rqu65WVlfott9wSc01FRYV+22236aqq6rW1tXphYaF+7NixPl3X6dOn9f3795tfP/roo/rSpUtjrnvyySf1Rx99tE/XYsWUKVP0f/3rXwmvGYj3Fs3DDz+s/+xnP4v5/kC9N0HPSHb/GAwks/cMRpLduwYrH3zwgb5w4UJ98uTJne6Bg4mHHnpIX7lypa5pmq7run7y5MkBXpEgmlTVdqmm63RdaLvuIHRd/yJCf5Pgtdde45prriEnJwdZlpk3bx6vvvpqn845ZcoU7HY7AJdeeinV1dVomtanc8ajtraWf/7zn8yYMQOAGTNm8M9//pO6urqI61599VXmzZuHLMvk5ORwzTXXsHXr1j5dW3Z2NuPHjze/vvTSSzl+/HifztnbDMR7C8fv9/Pyyy9z/fXX99ucgr4llfaPnpDs3jMYGQp7Vzz8fj8PPvggDzzwAJIkDfRyeo3m5mYqKyu5++67zecaPnz4AK9K0F36W9ul2r4stF3fIXRd73HGG6obNmxg5syZFBcX8/HHH1tec+LECUaNGmV+PWrUKE6cONFfS+Q3v/kNkydPjhuO8sknnzBnzhzmzZtHRUVFr89/4sQJzjrrLBRFAUBRFPLy8mLeQfR7GjlyJNXV1b2+nnhomsbzzz/P1KlTLX/+yiuv/P/t3U1IFHEYx/Gv265EWGSh25TS26VNejlVVCRUsAXZ26UXCnrbkCApkIyKCCMWI5AgwUOCh6RAgiDz4rIRtV2MJCo6SEUMhSsoYtAhmt0O4qK4vpS7zoz+PqfFGfDHI/vM8/8zM1JWVsapU6fo6OiYslyVlZWUlZVx48YN+vv7Rxy3u27RaBS/309JSUna43bVTTJjvP7hZBPtPW43Xu9ym7t377J3716Ki4vtjpJRpmkyf/587t27x8GDBzl+/Dhv3ryxO5ak4fTZzu65DjTbTYbmuqkzrZ9RPXDgwKg7MK9fv+bixYsUFBTg8Xh48uQJZ86cIRKJpL60dmYbzPDs2TOePn1KU1NT2nNLSkp48eIFc+fOxTRNTp48id/vZ/PmzVnL7lQ3b95kzpw5HDt2bMSxw4cPU15ejs/nIxaLce7cOVpbW1PPsGRLU1MThmHw+/dvbt26RXV1NXfu3Mnq7/xXjx8/HnXXza66ydgy1T/EGcbqXW7T0dHB+/fvqaystDtKxv358wfTNFm9ejVVVVW8e/eO8vJy2trayMvLszvejOHU2U5zXXY4bbbTXDe1pvVCdbxdKL/fn/q8f/9+wuEwXV1dLFmyZNh5hmEMaz4/fvzAMIysZgNoa2ujtraWxsbGUW8vGnpxLC4uZufOnbx9+zajDc0wDOLxOJZlMWvWLCzLoru7e0QNBuu0du1aYOSOUjbV1NTw7ds36uvr0+5QFhQUpD5v2bIFwzDo7Oxkw4YNWc01WKPc3FyOHj2a9oUOdtYtHo/T3t7O7du30x63q24ytkz1D6ebaO9xs/F6l9u0t7fz5csXduzYAUBXVxenT58mHA6zdetWm9NNzuLFi/F6valbJdetW0d+fj5fv3517cvK3Mips52b5jrQbPe/NNdNLfdfFSchHo+nPr98+RKPxzOswQ0KBoNEIhF6e3tJJBI0Nzeze/furGZ7/vw54XCYhoYGioqKRj2vu7ubZDIJQF9fH7FYjFWrVmU0y8KFCwkEArS0tADQ0tJCIBAY8fa1Xbt20dzcTCKRoLe3l0gkQjAYzGiWdGpra/nw4QN1dXXk5uamPWfo3/rTp098//6d5cuXZzXXr1+/+PnzJwDJZJLW1lYCgcCI8+yqGwxcWEtLS0fdSbOjbjJ5E+0fTjfR3uNWE+ldbnP27FlevXpFNBolGo2yaNEiGhoaXL9IBViwYAEbN24kFosBA29M7enpYenSpTYnk6GcOts5aa4DzXb/Q3Pd1MtJDn4bZqATJ07Q09NDTk4OeXl5XLp0ifXr1wMDz9gUFhZy5MgRAB49esT9+/eBgR2I69evZ/U2kk2bNuHz+YY1jMbGRvLz84dle/DgAQ8fPsTr9WJZFvv27SMUCmU8z+fPn7l8+TL9/f3MmzePmpoaVqxYQSgUoqKigjVr1mBZFtXV1amLeCgU4tChQxnPMlRnZyd79uxh2bJlzJ49G4CioiLq6uqGZauqquLjx494PB58Ph8VFRWUlpZmNZtpmpw/fx7LskgkEqxcuZJr165RWFhoe90GBYNBrl69yrZt21I/s7tuMnlj9Q+3Ga33uN1YvWs62b59O/X19dPm39OYpsmVK1fo6+vD6/Vy4cIF9USHceps57S5DjTb/SvNdVNvRi9URURERERExHlm9K2/IiIiIiIi4jxaqIqIiIiIiIijaKEqIiIiIiIijqKFqoiIiIiIiDiKFqoiIiIiIiLiKFqoioiIiIiIiKNooSoiIiIiIiKOooWqiIiIiIiIOMpfEPGHj5WDFzYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "\n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='orange', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "toyvis.plot_data(generated_x, color='orange', ax=ax)\n",
    "ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print pipeline logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 log files.\n",
      "\n",
      "-- Log file: logs2019-04-09 22:55:18.642151.txt\n",
      "\n",
      "2019-04-09 22:55:18,642 root         INFO     start\n",
      "2019-04-09 22:55:18,657 luigi        INFO     logging configured by default settings\n",
      "2019-04-09 22:55:18,686 luigi-interface DEBUG    Checking if RunAll() is complete\n",
      "2019-04-09 22:55:18,687 luigi-interface DEBUG    Checking if TrainVAE() is complete\n",
      "2019-04-09 22:55:18,688 luigi-interface DEBUG    Checking if TrainVEM() is complete\n",
      "2019-04-09 22:55:18,688 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   PENDING\n",
      "2019-04-09 22:55:18,688 luigi-interface DEBUG    Checking if MakeDataSet() is complete\n",
      "2019-04-09 22:55:18,689 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   PENDING\n",
      "2019-04-09 22:55:18,689 luigi-interface INFO     Informed scheduler that task   MakeDataSet__99914b932b   has status   PENDING\n",
      "2019-04-09 22:55:18,690 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   PENDING\n",
      "2019-04-09 22:55:18,690 luigi-interface INFO     Done scheduling tasks\n",
      "2019-04-09 22:55:18,690 luigi-interface INFO     Running Worker with 1 processes\n",
      "2019-04-09 22:55:18,690 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 22:55:18,690 luigi-interface DEBUG    Pending tasks: 4\n",
      "2019-04-09 22:55:18,690 luigi-interface INFO     [pid 11233] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=11233) running   MakeDataSet()\n",
      "2019-04-09 22:55:18,690 root         INFO     Configuration:\n",
      "2019-04-09 22:55:18,691 root         INFO     DATA_DIM = 2\n",
      "2019-04-09 22:55:18,691 root         INFO     LATENT_DIM = 1\n",
      "2019-04-09 22:55:18,691 root         INFO     N_DECODER_LAYERS = 2\n",
      "2019-04-09 22:55:18,691 root         INFO     NONLINEARITY=False\n",
      "2019-04-09 22:55:18,691 root         INFO     WITH_BIASX=True\n",
      "2019-04-09 22:55:18,691 root         INFO     WITH_LOGVARX=True\n",
      "2019-04-09 22:55:18,691 root         INFO     WITH_BIASZ=True\n",
      "2019-04-09 22:55:18,691 root         INFO     WITH_LOGVARZ=True\n",
      "2019-04-09 22:55:18,691 root         INFO     N_SAMPLES=10000\n",
      "2019-04-09 22:55:18,691 root         INFO     W_TRUE:\n",
      "2019-04-09 22:55:18,691 root         INFO     {0: [[1.0], [-1.0]], 1: [[1.0, -1.0], [-1.0, 1.0]], 2: [[0.0, 0.0], [0.0, 0.0]]}\n",
      "2019-04-09 22:55:18,691 root         INFO     B_TRUE:\n",
      "2019-04-09 22:55:18,691 root         INFO     {0: [0.0, -1.0], 1: [1.0, 0.0], 2: [0.0, 0.0]}\n",
      "2019-04-09 22:55:22,505 root         INFO     Values of true 'decoder' parameters:\n",
      "2019-04-09 22:55:22,505 root         INFO     layers.0.weight\n",
      "2019-04-09 22:55:22,505 root         INFO     tensor([[ 1.],\n",
      "        [-1.]], device='cuda:0')\n",
      "2019-04-09 22:55:22,526 root         INFO     layers.0.bias\n",
      "2019-04-09 22:55:22,526 root         INFO     tensor([ 0., -1.], device='cuda:0')\n",
      "2019-04-09 22:55:22,527 root         INFO     layers.1.weight\n",
      "2019-04-09 22:55:22,527 root         INFO     tensor([[ 1., -1.],\n",
      "        [-1.,  1.]], device='cuda:0')\n",
      "2019-04-09 22:55:22,528 root         INFO     layers.1.bias\n",
      "2019-04-09 22:55:22,528 root         INFO     tensor([1., 0.], device='cuda:0')\n",
      "2019-04-09 22:55:22,529 root         INFO     layers.2.weight\n",
      "2019-04-09 22:55:22,529 root         INFO     tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "2019-04-09 22:55:22,530 root         INFO     layers.2.bias\n",
      "2019-04-09 22:55:22,530 root         INFO     tensor([0., 0.], device='cuda:0')\n",
      "2019-04-09 22:55:22,636 luigi-interface INFO     [pid 11233] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=11233) done      MakeDataSet()\n",
      "2019-04-09 22:55:22,636 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 22:55:22,637 luigi-interface INFO     Informed scheduler that task   MakeDataSet__99914b932b   has status   DONE\n",
      "2019-04-09 22:55:22,637 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 22:55:22,637 luigi-interface DEBUG    Pending tasks: 3\n",
      "2019-04-09 22:55:22,637 luigi-interface INFO     [pid 11233] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=11233) running   TrainVAE()\n",
      "2019-04-09 22:55:22,639 root         INFO     --Dataset tensor: (10000, 2)\n",
      "2019-04-09 22:55:22,639 root         INFO     -- Train tensor: (8000, 2)\n",
      "2019-04-09 22:55:22,640 root         INFO     Values of VAE's decoder parameters before training:\n",
      "2019-04-09 22:55:22,640 root         INFO     layers.0.weight\n",
      "2019-04-09 22:55:22,641 root         INFO     tensor([[-0.8110],\n",
      "        [ 0.7163]], device='cuda:0')\n",
      "2019-04-09 22:55:22,642 root         INFO     layers.0.bias\n",
      "2019-04-09 22:55:22,642 root         INFO     tensor([-0.7052,  0.2492], device='cuda:0')\n",
      "2019-04-09 22:55:22,643 root         INFO     layers.1.weight\n",
      "2019-04-09 22:55:22,643 root         INFO     tensor([[-0.3539, -0.5961],\n",
      "        [-0.0450,  0.2346]], device='cuda:0')\n",
      "2019-04-09 22:55:22,644 root         INFO     layers.1.bias\n",
      "2019-04-09 22:55:22,644 root         INFO     tensor([-0.6488,  0.0511], device='cuda:0')\n",
      "2019-04-09 22:55:22,646 root         INFO     layers.2.weight\n",
      "2019-04-09 22:55:22,646 root         INFO     tensor([[-0.2659, -0.1007],\n",
      "        [-0.3153, -0.0881]], device='cuda:0')\n",
      "2019-04-09 22:55:22,647 root         INFO     layers.2.bias\n",
      "2019-04-09 22:55:22,647 root         INFO     tensor([ 0.6361, -0.6798], device='cuda:0')\n",
      "2019-04-09 22:55:22,708 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 0.634384\n",
      "Reconstruction: 0.610876, Regularization: 0.023508\n",
      "2019-04-09 22:55:22,765 root         INFO     Train Epoch: 0 [512/8000 (6%)]\tTotal Loss: 0.933034\n",
      "Reconstruction: 0.901752, Regularization: 0.031283\n",
      "2019-04-09 22:55:22,821 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 1.049413\n",
      "Reconstruction: 1.029353, Regularization: 0.020060\n",
      "2019-04-09 22:55:22,878 root         INFO     Train Epoch: 0 [1536/8000 (19%)]\tTotal Loss: 0.515236\n",
      "Reconstruction: 0.496999, Regularization: 0.018237\n",
      "2019-04-09 22:55:22,934 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 0.533953\n",
      "Reconstruction: 0.510931, Regularization: 0.023023\n",
      "2019-04-09 22:55:22,990 root         INFO     Train Epoch: 0 [2560/8000 (32%)]\tTotal Loss: 0.581189\n",
      "Reconstruction: 0.562647, Regularization: 0.018542\n",
      "2019-04-09 22:55:23,045 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 0.520156\n",
      "Reconstruction: 0.502351, Regularization: 0.017805\n",
      "2019-04-09 22:55:23,100 root         INFO     Train Epoch: 0 [3584/8000 (45%)]\tTotal Loss: 0.606332\n",
      "Reconstruction: 0.586731, Regularization: 0.019601\n",
      "2019-04-09 22:55:23,156 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 0.665385\n",
      "Reconstruction: 0.638624, Regularization: 0.026761\n",
      "2019-04-09 22:55:23,211 root         INFO     Train Epoch: 0 [4608/8000 (58%)]\tTotal Loss: 0.458430\n",
      "Reconstruction: 0.445036, Regularization: 0.013395\n",
      "2019-04-09 22:55:23,266 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 0.546617\n",
      "Reconstruction: 0.530598, Regularization: 0.016019\n",
      "2019-04-09 22:55:23,321 root         INFO     Train Epoch: 0 [5632/8000 (70%)]\tTotal Loss: 0.452491\n",
      "Reconstruction: 0.436806, Regularization: 0.015685\n",
      "2019-04-09 22:55:23,377 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 0.462223\n",
      "Reconstruction: 0.445404, Regularization: 0.016819\n",
      "2019-04-09 22:55:23,432 root         INFO     Train Epoch: 0 [6656/8000 (83%)]\tTotal Loss: 0.732259\n",
      "Reconstruction: 0.698484, Regularization: 0.033775\n",
      "2019-04-09 22:55:23,488 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 0.705214\n",
      "Reconstruction: 0.684158, Regularization: 0.021056\n",
      "2019-04-09 22:55:23,543 root         INFO     Train Epoch: 0 [7680/8000 (96%)]\tTotal Loss: 0.712910\n",
      "Reconstruction: 0.696055, Regularization: 0.016854\n",
      "2019-04-09 22:55:23,593 root         INFO     ====> Epoch: 0 Average loss: 1.2769\n",
      "2019-04-09 22:55:23,617 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 1.078284\n",
      "Reconstruction: 1.054051, Regularization: 0.024233\n",
      "2019-04-09 22:55:23,675 root         INFO     Train Epoch: 1 [512/8000 (6%)]\tTotal Loss: 0.679289\n",
      "Reconstruction: 0.660457, Regularization: 0.018833\n",
      "2019-04-09 22:55:23,732 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 0.535805\n",
      "Reconstruction: 0.520002, Regularization: 0.015803\n",
      "2019-04-09 22:55:23,790 root         INFO     Train Epoch: 1 [1536/8000 (19%)]\tTotal Loss: 0.573682\n",
      "Reconstruction: 0.552814, Regularization: 0.020868\n",
      "2019-04-09 22:55:23,847 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 0.577991\n",
      "Reconstruction: 0.553457, Regularization: 0.024534\n",
      "2019-04-09 22:55:23,904 root         INFO     Train Epoch: 1 [2560/8000 (32%)]\tTotal Loss: 0.485211\n",
      "Reconstruction: 0.465366, Regularization: 0.019845\n",
      "2019-04-09 22:55:23,961 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 0.508460\n",
      "Reconstruction: 0.492397, Regularization: 0.016063\n",
      "2019-04-09 22:55:24,018 root         INFO     Train Epoch: 1 [3584/8000 (45%)]\tTotal Loss: 0.491779\n",
      "Reconstruction: 0.474448, Regularization: 0.017331\n",
      "2019-04-09 22:55:24,074 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 2.128957\n",
      "Reconstruction: 2.097986, Regularization: 0.030971\n",
      "2019-04-09 22:55:24,130 root         INFO     Train Epoch: 1 [4608/8000 (58%)]\tTotal Loss: 0.579735\n",
      "Reconstruction: 0.561319, Regularization: 0.018416\n",
      "2019-04-09 22:55:24,186 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 0.530878\n",
      "Reconstruction: 0.515689, Regularization: 0.015188\n",
      "2019-04-09 22:55:24,242 root         INFO     Train Epoch: 1 [5632/8000 (70%)]\tTotal Loss: 0.719062\n",
      "Reconstruction: 0.691660, Regularization: 0.027402\n",
      "2019-04-09 22:55:24,298 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 0.402975\n",
      "Reconstruction: 0.387435, Regularization: 0.015540\n",
      "2019-04-09 22:55:24,354 root         INFO     Train Epoch: 1 [6656/8000 (83%)]\tTotal Loss: 0.706878\n",
      "Reconstruction: 0.683165, Regularization: 0.023712\n",
      "2019-04-09 22:55:24,409 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 0.501436\n",
      "Reconstruction: 0.483617, Regularization: 0.017818\n",
      "2019-04-09 22:55:24,465 root         INFO     Train Epoch: 1 [7680/8000 (96%)]\tTotal Loss: 0.706381\n",
      "Reconstruction: 0.688203, Regularization: 0.018178\n",
      "2019-04-09 22:55:24,514 root         INFO     ====> Epoch: 1 Average loss: 23.0859\n",
      "2019-04-09 22:55:24,537 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 0.578824\n",
      "Reconstruction: 0.559167, Regularization: 0.019656\n",
      "2019-04-09 22:55:24,593 root         INFO     Train Epoch: 2 [512/8000 (6%)]\tTotal Loss: 0.487930\n",
      "Reconstruction: 0.467535, Regularization: 0.020395\n",
      "2019-04-09 22:55:24,650 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 0.630233\n",
      "Reconstruction: 0.608319, Regularization: 0.021914\n",
      "2019-04-09 22:55:24,706 root         INFO     Train Epoch: 2 [1536/8000 (19%)]\tTotal Loss: 0.524058\n",
      "Reconstruction: 0.509125, Regularization: 0.014933\n",
      "2019-04-09 22:55:24,762 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 0.512714\n",
      "Reconstruction: 0.496918, Regularization: 0.015796\n",
      "2019-04-09 22:55:24,818 root         INFO     Train Epoch: 2 [2560/8000 (32%)]\tTotal Loss: 0.667448\n",
      "Reconstruction: 0.651115, Regularization: 0.016333\n",
      "2019-04-09 22:55:24,874 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 0.734766\n",
      "Reconstruction: 0.706093, Regularization: 0.028673\n",
      "2019-04-09 22:55:24,930 root         INFO     Train Epoch: 2 [3584/8000 (45%)]\tTotal Loss: 0.545165\n",
      "Reconstruction: 0.530045, Regularization: 0.015120\n",
      "2019-04-09 22:55:24,986 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 0.875529\n",
      "Reconstruction: 0.857131, Regularization: 0.018398\n",
      "2019-04-09 22:55:25,042 root         INFO     Train Epoch: 2 [4608/8000 (58%)]\tTotal Loss: 0.560604\n",
      "Reconstruction: 0.542408, Regularization: 0.018196\n",
      "2019-04-09 22:55:25,098 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 0.274594\n",
      "Reconstruction: 0.265290, Regularization: 0.009304\n",
      "2019-04-09 22:55:25,154 root         INFO     Train Epoch: 2 [5632/8000 (70%)]\tTotal Loss: 0.549622\n",
      "Reconstruction: 0.533537, Regularization: 0.016085\n",
      "2019-04-09 22:55:25,210 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 0.406370\n",
      "Reconstruction: 0.394248, Regularization: 0.012122\n",
      "2019-04-09 22:55:25,266 root         INFO     Train Epoch: 2 [6656/8000 (83%)]\tTotal Loss: 0.613596\n",
      "Reconstruction: 0.591678, Regularization: 0.021918\n",
      "2019-04-09 22:55:25,323 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 0.412388\n",
      "Reconstruction: 0.392905, Regularization: 0.019483\n",
      "2019-04-09 22:55:25,379 root         INFO     Train Epoch: 2 [7680/8000 (96%)]\tTotal Loss: 0.525097\n",
      "Reconstruction: 0.506244, Regularization: 0.018853\n",
      "2019-04-09 22:55:25,429 root         INFO     ====> Epoch: 2 Average loss: 7369.2603\n",
      "2019-04-09 22:55:25,452 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 0.605336\n",
      "Reconstruction: 0.586581, Regularization: 0.018755\n",
      "2019-04-09 22:55:25,509 root         INFO     Train Epoch: 3 [512/8000 (6%)]\tTotal Loss: 0.583876\n",
      "Reconstruction: 0.564651, Regularization: 0.019226\n",
      "2019-04-09 22:55:25,565 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 0.442120\n",
      "Reconstruction: 0.427403, Regularization: 0.014718\n",
      "2019-04-09 22:55:25,620 root         INFO     Train Epoch: 3 [1536/8000 (19%)]\tTotal Loss: 0.534763\n",
      "Reconstruction: 0.518529, Regularization: 0.016235\n",
      "2019-04-09 22:55:25,675 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 0.536658\n",
      "Reconstruction: 0.517715, Regularization: 0.018943\n",
      "2019-04-09 22:55:25,729 root         INFO     Train Epoch: 3 [2560/8000 (32%)]\tTotal Loss: 0.628952\n",
      "Reconstruction: 0.605804, Regularization: 0.023148\n",
      "2019-04-09 22:55:25,784 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 0.477069\n",
      "Reconstruction: 0.454184, Regularization: 0.022885\n",
      "2019-04-09 22:55:25,839 root         INFO     Train Epoch: 3 [3584/8000 (45%)]\tTotal Loss: 0.520489\n",
      "Reconstruction: 0.503424, Regularization: 0.017065\n",
      "2019-04-09 22:55:25,894 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 1.094797\n",
      "Reconstruction: 1.076053, Regularization: 0.018744\n",
      "2019-04-09 22:55:25,949 root         INFO     Train Epoch: 3 [4608/8000 (58%)]\tTotal Loss: 0.589872\n",
      "Reconstruction: 0.565045, Regularization: 0.024827\n",
      "2019-04-09 22:55:26,004 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 0.554980\n",
      "Reconstruction: 0.539652, Regularization: 0.015328\n",
      "2019-04-09 22:55:26,059 root         INFO     Train Epoch: 3 [5632/8000 (70%)]\tTotal Loss: 0.488965\n",
      "Reconstruction: 0.470518, Regularization: 0.018447\n",
      "2019-04-09 22:55:26,114 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 0.485824\n",
      "Reconstruction: 0.471903, Regularization: 0.013920\n",
      "2019-04-09 22:55:26,169 root         INFO     Train Epoch: 3 [6656/8000 (83%)]\tTotal Loss: 0.519953\n",
      "Reconstruction: 0.501304, Regularization: 0.018649\n",
      "2019-04-09 22:55:26,224 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 0.570942\n",
      "Reconstruction: 0.551051, Regularization: 0.019891\n",
      "2019-04-09 22:55:26,279 root         INFO     Train Epoch: 3 [7680/8000 (96%)]\tTotal Loss: 0.563228\n",
      "Reconstruction: 0.545227, Regularization: 0.018002\n",
      "2019-04-09 22:55:26,329 root         INFO     ====> Epoch: 3 Average loss: 1.8252\n",
      "2019-04-09 22:55:26,352 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 0.507474\n",
      "Reconstruction: 0.490941, Regularization: 0.016533\n",
      "2019-04-09 22:55:26,408 root         INFO     Train Epoch: 4 [512/8000 (6%)]\tTotal Loss: 0.607930\n",
      "Reconstruction: 0.586448, Regularization: 0.021482\n",
      "2019-04-09 22:55:26,464 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 0.549596\n",
      "Reconstruction: 0.500687, Regularization: 0.048909\n",
      "2019-04-09 22:55:26,520 root         INFO     Train Epoch: 4 [1536/8000 (19%)]\tTotal Loss: 0.509270\n",
      "Reconstruction: 0.493875, Regularization: 0.015396\n",
      "2019-04-09 22:55:26,576 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 0.618471\n",
      "Reconstruction: 0.597368, Regularization: 0.021103\n",
      "2019-04-09 22:55:26,632 root         INFO     Train Epoch: 4 [2560/8000 (32%)]\tTotal Loss: 0.597483\n",
      "Reconstruction: 0.564667, Regularization: 0.032816\n",
      "2019-04-09 22:55:26,688 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 0.618608\n",
      "Reconstruction: 0.599234, Regularization: 0.019375\n",
      "2019-04-09 22:55:26,745 root         INFO     Train Epoch: 4 [3584/8000 (45%)]\tTotal Loss: 0.432397\n",
      "Reconstruction: 0.407504, Regularization: 0.024893\n",
      "2019-04-09 22:55:26,801 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 0.586080\n",
      "Reconstruction: 0.556467, Regularization: 0.029613\n",
      "2019-04-09 22:55:26,857 root         INFO     Train Epoch: 4 [4608/8000 (58%)]\tTotal Loss: 0.731389\n",
      "Reconstruction: 0.708802, Regularization: 0.022586\n",
      "2019-04-09 22:55:26,913 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 0.564980\n",
      "Reconstruction: 0.548741, Regularization: 0.016239\n",
      "2019-04-09 22:55:26,969 root         INFO     Train Epoch: 4 [5632/8000 (70%)]\tTotal Loss: 0.437531\n",
      "Reconstruction: 0.416509, Regularization: 0.021022\n",
      "2019-04-09 22:55:27,025 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 0.618252\n",
      "Reconstruction: 0.597026, Regularization: 0.021226\n",
      "2019-04-09 22:55:27,081 root         INFO     Train Epoch: 4 [6656/8000 (83%)]\tTotal Loss: 0.670246\n",
      "Reconstruction: 0.648283, Regularization: 0.021963\n",
      "2019-04-09 22:55:27,140 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 0.490309\n",
      "Reconstruction: 0.465685, Regularization: 0.024624\n",
      "2019-04-09 22:55:27,198 root         INFO     Train Epoch: 4 [7680/8000 (96%)]\tTotal Loss: 0.666550\n",
      "Reconstruction: 0.648002, Regularization: 0.018548\n",
      "2019-04-09 22:55:27,248 root         INFO     ====> Epoch: 4 Average loss: 0.6757\n",
      "2019-04-09 22:55:27,271 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 0.705878\n",
      "Reconstruction: 0.687752, Regularization: 0.018125\n",
      "2019-04-09 22:55:27,328 root         INFO     Train Epoch: 5 [512/8000 (6%)]\tTotal Loss: 0.759768\n",
      "Reconstruction: 0.738936, Regularization: 0.020832\n",
      "2019-04-09 22:55:27,384 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 0.472492\n",
      "Reconstruction: 0.448484, Regularization: 0.024008\n",
      "2019-04-09 22:55:27,439 root         INFO     Train Epoch: 5 [1536/8000 (19%)]\tTotal Loss: 0.469889\n",
      "Reconstruction: 0.454368, Regularization: 0.015521\n",
      "2019-04-09 22:55:27,493 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 0.499908\n",
      "Reconstruction: 0.484140, Regularization: 0.015768\n",
      "2019-04-09 22:55:27,548 root         INFO     Train Epoch: 5 [2560/8000 (32%)]\tTotal Loss: 0.569535\n",
      "Reconstruction: 0.542017, Regularization: 0.027518\n",
      "2019-04-09 22:55:27,602 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 0.553382\n",
      "Reconstruction: 0.524370, Regularization: 0.029012\n",
      "2019-04-09 22:55:27,656 root         INFO     Train Epoch: 5 [3584/8000 (45%)]\tTotal Loss: 0.438773\n",
      "Reconstruction: 0.424821, Regularization: 0.013953\n",
      "2019-04-09 22:55:27,709 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 0.599885\n",
      "Reconstruction: 0.582764, Regularization: 0.017121\n",
      "2019-04-09 22:55:27,762 root         INFO     Train Epoch: 5 [4608/8000 (58%)]\tTotal Loss: 0.670318\n",
      "Reconstruction: 0.649594, Regularization: 0.020724\n",
      "2019-04-09 22:55:27,815 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 0.494061\n",
      "Reconstruction: 0.477208, Regularization: 0.016853\n",
      "2019-04-09 22:55:27,869 root         INFO     Train Epoch: 5 [5632/8000 (70%)]\tTotal Loss: 0.680238\n",
      "Reconstruction: 0.659208, Regularization: 0.021029\n",
      "2019-04-09 22:55:27,923 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 0.443826\n",
      "Reconstruction: 0.427350, Regularization: 0.016476\n",
      "2019-04-09 22:55:27,977 root         INFO     Train Epoch: 5 [6656/8000 (83%)]\tTotal Loss: 0.428915\n",
      "Reconstruction: 0.415298, Regularization: 0.013617\n",
      "2019-04-09 22:55:28,030 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 0.556471\n",
      "Reconstruction: 0.539789, Regularization: 0.016683\n",
      "2019-04-09 22:55:28,083 root         INFO     Train Epoch: 5 [7680/8000 (96%)]\tTotal Loss: 0.561536\n",
      "Reconstruction: 0.516698, Regularization: 0.044838\n",
      "2019-04-09 22:55:28,131 root         INFO     ====> Epoch: 5 Average loss: 3.0713\n",
      "2019-04-09 22:55:28,154 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 0.700615\n",
      "Reconstruction: 0.680092, Regularization: 0.020523\n",
      "2019-04-09 22:55:28,211 root         INFO     Train Epoch: 6 [512/8000 (6%)]\tTotal Loss: 0.477997\n",
      "Reconstruction: 0.458415, Regularization: 0.019583\n",
      "2019-04-09 22:55:28,267 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 0.484580\n",
      "Reconstruction: 0.468542, Regularization: 0.016038\n",
      "2019-04-09 22:55:28,323 root         INFO     Train Epoch: 6 [1536/8000 (19%)]\tTotal Loss: 0.589026\n",
      "Reconstruction: 0.570303, Regularization: 0.018723\n",
      "2019-04-09 22:55:28,380 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 0.571751\n",
      "Reconstruction: 0.546541, Regularization: 0.025209\n",
      "2019-04-09 22:55:28,436 root         INFO     Train Epoch: 6 [2560/8000 (32%)]\tTotal Loss: 0.775941\n",
      "Reconstruction: 0.756185, Regularization: 0.019756\n",
      "2019-04-09 22:55:28,493 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 0.563178\n",
      "Reconstruction: 0.541758, Regularization: 0.021420\n",
      "2019-04-09 22:55:28,549 root         INFO     Train Epoch: 6 [3584/8000 (45%)]\tTotal Loss: 0.565269\n",
      "Reconstruction: 0.544684, Regularization: 0.020585\n",
      "2019-04-09 22:55:28,606 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 0.572942\n",
      "Reconstruction: 0.556319, Regularization: 0.016623\n",
      "2019-04-09 22:55:28,663 root         INFO     Train Epoch: 6 [4608/8000 (58%)]\tTotal Loss: 0.760234\n",
      "Reconstruction: 0.742841, Regularization: 0.017393\n",
      "2019-04-09 22:55:28,719 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 0.506425\n",
      "Reconstruction: 0.488201, Regularization: 0.018225\n",
      "2019-04-09 22:55:28,776 root         INFO     Train Epoch: 6 [5632/8000 (70%)]\tTotal Loss: 0.554881\n",
      "Reconstruction: 0.530179, Regularization: 0.024702\n",
      "2019-04-09 22:55:28,833 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 0.549785\n",
      "Reconstruction: 0.528469, Regularization: 0.021316\n",
      "2019-04-09 22:55:28,889 root         INFO     Train Epoch: 6 [6656/8000 (83%)]\tTotal Loss: 0.479541\n",
      "Reconstruction: 0.462044, Regularization: 0.017497\n",
      "2019-04-09 22:55:28,946 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 0.578192\n",
      "Reconstruction: 0.559452, Regularization: 0.018740\n",
      "2019-04-09 22:55:29,002 root         INFO     Train Epoch: 6 [7680/8000 (96%)]\tTotal Loss: 1.670146\n",
      "Reconstruction: 1.629908, Regularization: 0.040238\n",
      "2019-04-09 22:55:29,052 root         INFO     ====> Epoch: 6 Average loss: 0.7174\n",
      "2019-04-09 22:55:29,075 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 0.636915\n",
      "Reconstruction: 0.617534, Regularization: 0.019381\n",
      "2019-04-09 22:55:29,132 root         INFO     Train Epoch: 7 [512/8000 (6%)]\tTotal Loss: 0.428384\n",
      "Reconstruction: 0.408707, Regularization: 0.019677\n",
      "2019-04-09 22:55:29,189 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 0.444488\n",
      "Reconstruction: 0.418226, Regularization: 0.026262\n",
      "2019-04-09 22:55:29,245 root         INFO     Train Epoch: 7 [1536/8000 (19%)]\tTotal Loss: 0.594676\n",
      "Reconstruction: 0.576815, Regularization: 0.017862\n",
      "2019-04-09 22:55:29,302 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 0.481676\n",
      "Reconstruction: 0.464507, Regularization: 0.017170\n",
      "2019-04-09 22:55:29,358 root         INFO     Train Epoch: 7 [2560/8000 (32%)]\tTotal Loss: 0.414407\n",
      "Reconstruction: 0.401404, Regularization: 0.013003\n",
      "2019-04-09 22:55:29,415 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 0.452985\n",
      "Reconstruction: 0.436363, Regularization: 0.016622\n",
      "2019-04-09 22:55:29,472 root         INFO     Train Epoch: 7 [3584/8000 (45%)]\tTotal Loss: 0.630403\n",
      "Reconstruction: 0.612872, Regularization: 0.017530\n",
      "2019-04-09 22:55:29,528 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 0.633777\n",
      "Reconstruction: 0.616257, Regularization: 0.017520\n",
      "2019-04-09 22:55:29,585 root         INFO     Train Epoch: 7 [4608/8000 (58%)]\tTotal Loss: 0.561497\n",
      "Reconstruction: 0.538131, Regularization: 0.023366\n",
      "2019-04-09 22:55:29,642 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 0.477790\n",
      "Reconstruction: 0.460630, Regularization: 0.017160\n",
      "2019-04-09 22:55:29,699 root         INFO     Train Epoch: 7 [5632/8000 (70%)]\tTotal Loss: 0.411080\n",
      "Reconstruction: 0.396602, Regularization: 0.014478\n",
      "2019-04-09 22:55:29,755 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 0.723953\n",
      "Reconstruction: 0.699550, Regularization: 0.024403\n",
      "2019-04-09 22:55:29,812 root         INFO     Train Epoch: 7 [6656/8000 (83%)]\tTotal Loss: 0.536211\n",
      "Reconstruction: 0.520335, Regularization: 0.015876\n",
      "2019-04-09 22:55:29,868 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 0.559157\n",
      "Reconstruction: 0.539708, Regularization: 0.019449\n",
      "2019-04-09 22:55:29,925 root         INFO     Train Epoch: 7 [7680/8000 (96%)]\tTotal Loss: 0.497418\n",
      "Reconstruction: 0.481196, Regularization: 0.016222\n",
      "2019-04-09 22:55:29,977 root         INFO     ====> Epoch: 7 Average loss: 0.9004\n",
      "2019-04-09 22:55:30,000 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 0.500037\n",
      "Reconstruction: 0.485221, Regularization: 0.014817\n",
      "2019-04-09 22:55:30,057 root         INFO     Train Epoch: 8 [512/8000 (6%)]\tTotal Loss: 0.597275\n",
      "Reconstruction: 0.575318, Regularization: 0.021957\n",
      "2019-04-09 22:55:30,114 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 0.409256\n",
      "Reconstruction: 0.394631, Regularization: 0.014626\n",
      "2019-04-09 22:55:30,171 root         INFO     Train Epoch: 8 [1536/8000 (19%)]\tTotal Loss: 0.460837\n",
      "Reconstruction: 0.445773, Regularization: 0.015064\n",
      "2019-04-09 22:55:30,228 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 0.545815\n",
      "Reconstruction: 0.525972, Regularization: 0.019843\n",
      "2019-04-09 22:55:30,285 root         INFO     Train Epoch: 8 [2560/8000 (32%)]\tTotal Loss: 0.535284\n",
      "Reconstruction: 0.506391, Regularization: 0.028894\n",
      "2019-04-09 22:55:30,342 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 0.422265\n",
      "Reconstruction: 0.406056, Regularization: 0.016209\n",
      "2019-04-09 22:55:30,399 root         INFO     Train Epoch: 8 [3584/8000 (45%)]\tTotal Loss: 0.834280\n",
      "Reconstruction: 0.790928, Regularization: 0.043352\n",
      "2019-04-09 22:55:30,455 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 0.709743\n",
      "Reconstruction: 0.686915, Regularization: 0.022828\n",
      "2019-04-09 22:55:30,512 root         INFO     Train Epoch: 8 [4608/8000 (58%)]\tTotal Loss: 0.414641\n",
      "Reconstruction: 0.401144, Regularization: 0.013497\n",
      "2019-04-09 22:55:30,569 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 0.656057\n",
      "Reconstruction: 0.634032, Regularization: 0.022024\n",
      "2019-04-09 22:55:30,626 root         INFO     Train Epoch: 8 [5632/8000 (70%)]\tTotal Loss: 0.505790\n",
      "Reconstruction: 0.489357, Regularization: 0.016433\n",
      "2019-04-09 22:55:30,683 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 0.552175\n",
      "Reconstruction: 0.531718, Regularization: 0.020456\n",
      "2019-04-09 22:55:30,740 root         INFO     Train Epoch: 8 [6656/8000 (83%)]\tTotal Loss: 0.463193\n",
      "Reconstruction: 0.448079, Regularization: 0.015115\n",
      "2019-04-09 22:55:30,796 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 0.370854\n",
      "Reconstruction: 0.357673, Regularization: 0.013181\n",
      "2019-04-09 22:55:30,853 root         INFO     Train Epoch: 8 [7680/8000 (96%)]\tTotal Loss: 1.572112\n",
      "Reconstruction: 1.535119, Regularization: 0.036993\n",
      "2019-04-09 22:55:30,903 root         INFO     ====> Epoch: 8 Average loss: 0.7946\n",
      "2019-04-09 22:55:30,927 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 0.537128\n",
      "Reconstruction: 0.522406, Regularization: 0.014722\n",
      "2019-04-09 22:55:30,983 root         INFO     Train Epoch: 9 [512/8000 (6%)]\tTotal Loss: 0.416896\n",
      "Reconstruction: 0.401347, Regularization: 0.015549\n",
      "2019-04-09 22:55:31,041 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 0.618308\n",
      "Reconstruction: 0.591296, Regularization: 0.027012\n",
      "2019-04-09 22:55:31,098 root         INFO     Train Epoch: 9 [1536/8000 (19%)]\tTotal Loss: 0.453360\n",
      "Reconstruction: 0.438486, Regularization: 0.014874\n",
      "2019-04-09 22:55:31,155 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 0.399994\n",
      "Reconstruction: 0.385467, Regularization: 0.014527\n",
      "2019-04-09 22:55:31,212 root         INFO     Train Epoch: 9 [2560/8000 (32%)]\tTotal Loss: 0.709063\n",
      "Reconstruction: 0.690189, Regularization: 0.018873\n",
      "2019-04-09 22:55:31,269 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 0.544935\n",
      "Reconstruction: 0.528943, Regularization: 0.015992\n",
      "2019-04-09 22:55:31,326 root         INFO     Train Epoch: 9 [3584/8000 (45%)]\tTotal Loss: 0.576576\n",
      "Reconstruction: 0.555870, Regularization: 0.020706\n",
      "2019-04-09 22:55:31,383 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 0.452833\n",
      "Reconstruction: 0.434461, Regularization: 0.018372\n",
      "2019-04-09 22:55:31,439 root         INFO     Train Epoch: 9 [4608/8000 (58%)]\tTotal Loss: 0.420509\n",
      "Reconstruction: 0.406376, Regularization: 0.014134\n",
      "2019-04-09 22:55:31,494 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 0.744164\n",
      "Reconstruction: 0.717776, Regularization: 0.026388\n",
      "2019-04-09 22:55:31,550 root         INFO     Train Epoch: 9 [5632/8000 (70%)]\tTotal Loss: 0.434474\n",
      "Reconstruction: 0.410949, Regularization: 0.023525\n",
      "2019-04-09 22:55:31,606 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 0.408257\n",
      "Reconstruction: 0.383589, Regularization: 0.024667\n",
      "2019-04-09 22:55:31,661 root         INFO     Train Epoch: 9 [6656/8000 (83%)]\tTotal Loss: 0.463915\n",
      "Reconstruction: 0.446116, Regularization: 0.017800\n",
      "2019-04-09 22:55:31,716 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 0.588283\n",
      "Reconstruction: 0.569078, Regularization: 0.019205\n",
      "2019-04-09 22:55:31,771 root         INFO     Train Epoch: 9 [7680/8000 (96%)]\tTotal Loss: 0.478774\n",
      "Reconstruction: 0.458486, Regularization: 0.020288\n",
      "2019-04-09 22:55:31,821 root         INFO     ====> Epoch: 9 Average loss: 0.5829\n",
      "2019-04-09 22:55:31,844 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 21.297550\n",
      "Reconstruction: 21.272858, Regularization: 0.024692\n",
      "2019-04-09 22:55:31,901 root         INFO     Train Epoch: 10 [512/8000 (6%)]\tTotal Loss: 0.482340\n",
      "Reconstruction: 0.465415, Regularization: 0.016925\n",
      "2019-04-09 22:55:31,958 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 0.623082\n",
      "Reconstruction: 0.605623, Regularization: 0.017459\n",
      "2019-04-09 22:55:32,014 root         INFO     Train Epoch: 10 [1536/8000 (19%)]\tTotal Loss: 0.664715\n",
      "Reconstruction: 0.642976, Regularization: 0.021739\n",
      "2019-04-09 22:55:32,070 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 0.622195\n",
      "Reconstruction: 0.597639, Regularization: 0.024556\n",
      "2019-04-09 22:55:32,125 root         INFO     Train Epoch: 10 [2560/8000 (32%)]\tTotal Loss: 0.575785\n",
      "Reconstruction: 0.553129, Regularization: 0.022656\n",
      "2019-04-09 22:55:32,180 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 0.414972\n",
      "Reconstruction: 0.399947, Regularization: 0.015026\n",
      "2019-04-09 22:55:32,235 root         INFO     Train Epoch: 10 [3584/8000 (45%)]\tTotal Loss: 0.534064\n",
      "Reconstruction: 0.521253, Regularization: 0.012811\n",
      "2019-04-09 22:55:32,291 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 0.443754\n",
      "Reconstruction: 0.425524, Regularization: 0.018230\n",
      "2019-04-09 22:55:32,347 root         INFO     Train Epoch: 10 [4608/8000 (58%)]\tTotal Loss: 0.589645\n",
      "Reconstruction: 0.572038, Regularization: 0.017607\n",
      "2019-04-09 22:55:32,403 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 0.494429\n",
      "Reconstruction: 0.477573, Regularization: 0.016855\n",
      "2019-04-09 22:55:32,460 root         INFO     Train Epoch: 10 [5632/8000 (70%)]\tTotal Loss: 0.500498\n",
      "Reconstruction: 0.481238, Regularization: 0.019260\n",
      "2019-04-09 22:55:32,517 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 0.439090\n",
      "Reconstruction: 0.413528, Regularization: 0.025562\n",
      "2019-04-09 22:55:32,573 root         INFO     Train Epoch: 10 [6656/8000 (83%)]\tTotal Loss: 0.465279\n",
      "Reconstruction: 0.448242, Regularization: 0.017037\n",
      "2019-04-09 22:55:32,630 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 0.579245\n",
      "Reconstruction: 0.548727, Regularization: 0.030518\n",
      "2019-04-09 22:55:32,686 root         INFO     Train Epoch: 10 [7680/8000 (96%)]\tTotal Loss: 0.561119\n",
      "Reconstruction: 0.545288, Regularization: 0.015831\n",
      "2019-04-09 22:55:32,737 root         INFO     ====> Epoch: 10 Average loss: 0.8414\n",
      "2019-04-09 22:55:32,760 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.549753\n",
      "Reconstruction: 0.532286, Regularization: 0.017467\n",
      "2019-04-09 22:55:32,816 root         INFO     Train Epoch: 11 [512/8000 (6%)]\tTotal Loss: 0.584522\n",
      "Reconstruction: 0.558234, Regularization: 0.026288\n",
      "2019-04-09 22:55:32,871 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 0.372294\n",
      "Reconstruction: 0.359191, Regularization: 0.013103\n",
      "2019-04-09 22:55:32,927 root         INFO     Train Epoch: 11 [1536/8000 (19%)]\tTotal Loss: 0.515819\n",
      "Reconstruction: 0.500088, Regularization: 0.015731\n",
      "2019-04-09 22:55:32,982 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.486984\n",
      "Reconstruction: 0.467214, Regularization: 0.019770\n",
      "2019-04-09 22:55:33,038 root         INFO     Train Epoch: 11 [2560/8000 (32%)]\tTotal Loss: 0.504165\n",
      "Reconstruction: 0.486808, Regularization: 0.017357\n",
      "2019-04-09 22:55:33,094 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 0.676522\n",
      "Reconstruction: 0.648291, Regularization: 0.028231\n",
      "2019-04-09 22:55:33,150 root         INFO     Train Epoch: 11 [3584/8000 (45%)]\tTotal Loss: 0.542896\n",
      "Reconstruction: 0.526092, Regularization: 0.016804\n",
      "2019-04-09 22:55:33,204 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 0.449536\n",
      "Reconstruction: 0.434475, Regularization: 0.015061\n",
      "2019-04-09 22:55:33,259 root         INFO     Train Epoch: 11 [4608/8000 (58%)]\tTotal Loss: 0.568129\n",
      "Reconstruction: 0.543263, Regularization: 0.024866\n",
      "2019-04-09 22:55:33,313 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 0.493776\n",
      "Reconstruction: 0.474499, Regularization: 0.019276\n",
      "2019-04-09 22:55:33,367 root         INFO     Train Epoch: 11 [5632/8000 (70%)]\tTotal Loss: 0.516718\n",
      "Reconstruction: 0.499778, Regularization: 0.016940\n",
      "2019-04-09 22:55:33,421 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.494181\n",
      "Reconstruction: 0.463323, Regularization: 0.030858\n",
      "2019-04-09 22:55:33,475 root         INFO     Train Epoch: 11 [6656/8000 (83%)]\tTotal Loss: 0.509586\n",
      "Reconstruction: 0.490203, Regularization: 0.019384\n",
      "2019-04-09 22:55:33,529 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 0.441092\n",
      "Reconstruction: 0.423184, Regularization: 0.017909\n",
      "2019-04-09 22:55:33,584 root         INFO     Train Epoch: 11 [7680/8000 (96%)]\tTotal Loss: 0.543048\n",
      "Reconstruction: 0.514265, Regularization: 0.028783\n",
      "2019-04-09 22:55:33,632 root         INFO     ====> Epoch: 11 Average loss: 0.6417\n",
      "2019-04-09 22:55:33,656 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 0.717178\n",
      "Reconstruction: 0.699543, Regularization: 0.017636\n",
      "2019-04-09 22:55:33,712 root         INFO     Train Epoch: 12 [512/8000 (6%)]\tTotal Loss: 0.434935\n",
      "Reconstruction: 0.414742, Regularization: 0.020193\n",
      "2019-04-09 22:55:33,766 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 0.652646\n",
      "Reconstruction: 0.630348, Regularization: 0.022298\n",
      "2019-04-09 22:55:33,822 root         INFO     Train Epoch: 12 [1536/8000 (19%)]\tTotal Loss: 0.566737\n",
      "Reconstruction: 0.548206, Regularization: 0.018530\n",
      "2019-04-09 22:55:33,877 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 7.677977\n",
      "Reconstruction: 7.652288, Regularization: 0.025689\n",
      "2019-04-09 22:55:33,933 root         INFO     Train Epoch: 12 [2560/8000 (32%)]\tTotal Loss: 0.607748\n",
      "Reconstruction: 0.587163, Regularization: 0.020585\n",
      "2019-04-09 22:55:33,988 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 0.581366\n",
      "Reconstruction: 0.561648, Regularization: 0.019718\n",
      "2019-04-09 22:55:34,042 root         INFO     Train Epoch: 12 [3584/8000 (45%)]\tTotal Loss: 4.403195\n",
      "Reconstruction: 4.364326, Regularization: 0.038869\n",
      "2019-04-09 22:55:34,097 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 3.280997\n",
      "Reconstruction: 3.253374, Regularization: 0.027623\n",
      "2019-04-09 22:55:34,151 root         INFO     Train Epoch: 12 [4608/8000 (58%)]\tTotal Loss: 0.578077\n",
      "Reconstruction: 0.555675, Regularization: 0.022403\n",
      "2019-04-09 22:55:34,205 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.518424\n",
      "Reconstruction: 0.501559, Regularization: 0.016865\n",
      "2019-04-09 22:55:34,258 root         INFO     Train Epoch: 12 [5632/8000 (70%)]\tTotal Loss: 0.539804\n",
      "Reconstruction: 0.511538, Regularization: 0.028267\n",
      "2019-04-09 22:55:34,312 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.495955\n",
      "Reconstruction: 0.477333, Regularization: 0.018622\n",
      "2019-04-09 22:55:34,365 root         INFO     Train Epoch: 12 [6656/8000 (83%)]\tTotal Loss: 0.501438\n",
      "Reconstruction: 0.479932, Regularization: 0.021506\n",
      "2019-04-09 22:55:34,419 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 0.437738\n",
      "Reconstruction: 0.422963, Regularization: 0.014775\n",
      "2019-04-09 22:55:34,472 root         INFO     Train Epoch: 12 [7680/8000 (96%)]\tTotal Loss: 0.761144\n",
      "Reconstruction: 0.716810, Regularization: 0.044334\n",
      "2019-04-09 22:55:34,521 root         INFO     ====> Epoch: 12 Average loss: 0.6772\n",
      "2019-04-09 22:55:34,544 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 0.430475\n",
      "Reconstruction: 0.412992, Regularization: 0.017483\n",
      "2019-04-09 22:55:34,600 root         INFO     Train Epoch: 13 [512/8000 (6%)]\tTotal Loss: 0.374808\n",
      "Reconstruction: 0.360273, Regularization: 0.014535\n",
      "2019-04-09 22:55:34,656 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 0.597356\n",
      "Reconstruction: 0.572662, Regularization: 0.024694\n",
      "2019-04-09 22:55:34,712 root         INFO     Train Epoch: 13 [1536/8000 (19%)]\tTotal Loss: 0.488911\n",
      "Reconstruction: 0.474690, Regularization: 0.014221\n",
      "2019-04-09 22:55:34,768 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 0.486884\n",
      "Reconstruction: 0.458569, Regularization: 0.028315\n",
      "2019-04-09 22:55:34,824 root         INFO     Train Epoch: 13 [2560/8000 (32%)]\tTotal Loss: 0.496148\n",
      "Reconstruction: 0.474876, Regularization: 0.021272\n",
      "2019-04-09 22:55:34,881 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 0.612905\n",
      "Reconstruction: 0.587638, Regularization: 0.025267\n",
      "2019-04-09 22:55:34,937 root         INFO     Train Epoch: 13 [3584/8000 (45%)]\tTotal Loss: 0.566914\n",
      "Reconstruction: 0.547967, Regularization: 0.018947\n",
      "2019-04-09 22:55:34,993 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 0.549432\n",
      "Reconstruction: 0.531770, Regularization: 0.017662\n",
      "2019-04-09 22:55:35,050 root         INFO     Train Epoch: 13 [4608/8000 (58%)]\tTotal Loss: 0.468654\n",
      "Reconstruction: 0.447671, Regularization: 0.020983\n",
      "2019-04-09 22:55:35,105 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 0.603521\n",
      "Reconstruction: 0.585702, Regularization: 0.017820\n",
      "2019-04-09 22:55:35,161 root         INFO     Train Epoch: 13 [5632/8000 (70%)]\tTotal Loss: 0.475913\n",
      "Reconstruction: 0.457723, Regularization: 0.018191\n",
      "2019-04-09 22:55:35,218 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 1.284590\n",
      "Reconstruction: 1.256310, Regularization: 0.028280\n",
      "2019-04-09 22:55:35,274 root         INFO     Train Epoch: 13 [6656/8000 (83%)]\tTotal Loss: 0.640751\n",
      "Reconstruction: 0.621055, Regularization: 0.019696\n",
      "2019-04-09 22:55:35,330 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 0.469788\n",
      "Reconstruction: 0.453111, Regularization: 0.016677\n",
      "2019-04-09 22:55:35,386 root         INFO     Train Epoch: 13 [7680/8000 (96%)]\tTotal Loss: 0.577239\n",
      "Reconstruction: 0.558810, Regularization: 0.018429\n",
      "2019-04-09 22:55:35,437 root         INFO     ====> Epoch: 13 Average loss: 236.2183\n",
      "2019-04-09 22:55:35,460 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.458605\n",
      "Reconstruction: 0.437779, Regularization: 0.020826\n",
      "2019-04-09 22:55:35,516 root         INFO     Train Epoch: 14 [512/8000 (6%)]\tTotal Loss: 0.702280\n",
      "Reconstruction: 0.687809, Regularization: 0.014472\n",
      "2019-04-09 22:55:35,573 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.541711\n",
      "Reconstruction: 0.522506, Regularization: 0.019205\n",
      "2019-04-09 22:55:35,629 root         INFO     Train Epoch: 14 [1536/8000 (19%)]\tTotal Loss: 0.462709\n",
      "Reconstruction: 0.446376, Regularization: 0.016333\n",
      "2019-04-09 22:55:35,685 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 1.036983\n",
      "Reconstruction: 0.964979, Regularization: 0.072004\n",
      "2019-04-09 22:55:35,741 root         INFO     Train Epoch: 14 [2560/8000 (32%)]\tTotal Loss: 0.540641\n",
      "Reconstruction: 0.525051, Regularization: 0.015590\n",
      "2019-04-09 22:55:35,797 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.480049\n",
      "Reconstruction: 0.460926, Regularization: 0.019122\n",
      "2019-04-09 22:55:35,853 root         INFO     Train Epoch: 14 [3584/8000 (45%)]\tTotal Loss: 0.450477\n",
      "Reconstruction: 0.406821, Regularization: 0.043656\n",
      "2019-04-09 22:55:35,909 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.322234\n",
      "Reconstruction: 0.309629, Regularization: 0.012605\n",
      "2019-04-09 22:55:35,965 root         INFO     Train Epoch: 14 [4608/8000 (58%)]\tTotal Loss: 0.609614\n",
      "Reconstruction: 0.595669, Regularization: 0.013945\n",
      "2019-04-09 22:55:36,021 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 0.537549\n",
      "Reconstruction: 0.520572, Regularization: 0.016977\n",
      "2019-04-09 22:55:36,076 root         INFO     Train Epoch: 14 [5632/8000 (70%)]\tTotal Loss: 0.487256\n",
      "Reconstruction: 0.461234, Regularization: 0.026022\n",
      "2019-04-09 22:55:36,130 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.549445\n",
      "Reconstruction: 0.519707, Regularization: 0.029739\n",
      "2019-04-09 22:55:36,185 root         INFO     Train Epoch: 14 [6656/8000 (83%)]\tTotal Loss: 0.564462\n",
      "Reconstruction: 0.543876, Regularization: 0.020587\n",
      "2019-04-09 22:55:36,239 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.569228\n",
      "Reconstruction: 0.550496, Regularization: 0.018732\n",
      "2019-04-09 22:55:36,293 root         INFO     Train Epoch: 14 [7680/8000 (96%)]\tTotal Loss: 0.486063\n",
      "Reconstruction: 0.460826, Regularization: 0.025236\n",
      "2019-04-09 22:55:36,343 root         INFO     ====> Epoch: 14 Average loss: 3.0548\n",
      "2019-04-09 22:55:36,366 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 0.601511\n",
      "Reconstruction: 0.582058, Regularization: 0.019453\n",
      "2019-04-09 22:55:36,422 root         INFO     Train Epoch: 15 [512/8000 (6%)]\tTotal Loss: 0.379664\n",
      "Reconstruction: 0.367009, Regularization: 0.012655\n",
      "2019-04-09 22:55:36,478 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 0.460629\n",
      "Reconstruction: 0.408931, Regularization: 0.051698\n",
      "2019-04-09 22:55:36,534 root         INFO     Train Epoch: 15 [1536/8000 (19%)]\tTotal Loss: 0.518387\n",
      "Reconstruction: 0.499821, Regularization: 0.018566\n",
      "2019-04-09 22:55:36,590 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.617094\n",
      "Reconstruction: 0.598376, Regularization: 0.018719\n",
      "2019-04-09 22:55:36,645 root         INFO     Train Epoch: 15 [2560/8000 (32%)]\tTotal Loss: 0.380901\n",
      "Reconstruction: 0.367957, Regularization: 0.012944\n",
      "2019-04-09 22:55:36,700 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.640330\n",
      "Reconstruction: 0.619173, Regularization: 0.021157\n",
      "2019-04-09 22:55:36,755 root         INFO     Train Epoch: 15 [3584/8000 (45%)]\tTotal Loss: 0.616025\n",
      "Reconstruction: 0.592029, Regularization: 0.023996\n",
      "2019-04-09 22:55:36,810 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.512420\n",
      "Reconstruction: 0.496437, Regularization: 0.015982\n",
      "2019-04-09 22:55:36,864 root         INFO     Train Epoch: 15 [4608/8000 (58%)]\tTotal Loss: 0.714460\n",
      "Reconstruction: 0.692723, Regularization: 0.021737\n",
      "2019-04-09 22:55:36,919 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.549468\n",
      "Reconstruction: 0.532493, Regularization: 0.016975\n",
      "2019-04-09 22:55:36,974 root         INFO     Train Epoch: 15 [5632/8000 (70%)]\tTotal Loss: 0.552615\n",
      "Reconstruction: 0.535149, Regularization: 0.017467\n",
      "2019-04-09 22:55:37,028 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.547507\n",
      "Reconstruction: 0.530041, Regularization: 0.017466\n",
      "2019-04-09 22:55:37,083 root         INFO     Train Epoch: 15 [6656/8000 (83%)]\tTotal Loss: 0.555407\n",
      "Reconstruction: 0.537235, Regularization: 0.018172\n",
      "2019-04-09 22:55:37,140 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 0.612234\n",
      "Reconstruction: 0.591671, Regularization: 0.020563\n",
      "2019-04-09 22:55:37,194 root         INFO     Train Epoch: 15 [7680/8000 (96%)]\tTotal Loss: 0.420098\n",
      "Reconstruction: 0.404177, Regularization: 0.015921\n",
      "2019-04-09 22:55:37,243 root         INFO     ====> Epoch: 15 Average loss: 3.3292\n",
      "2019-04-09 22:55:37,266 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 0.534681\n",
      "Reconstruction: 0.508738, Regularization: 0.025943\n",
      "2019-04-09 22:55:37,322 root         INFO     Train Epoch: 16 [512/8000 (6%)]\tTotal Loss: 0.624222\n",
      "Reconstruction: 0.607803, Regularization: 0.016419\n",
      "2019-04-09 22:55:37,379 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 0.622888\n",
      "Reconstruction: 0.593686, Regularization: 0.029201\n",
      "2019-04-09 22:55:37,435 root         INFO     Train Epoch: 16 [1536/8000 (19%)]\tTotal Loss: 0.512836\n",
      "Reconstruction: 0.478099, Regularization: 0.034738\n",
      "2019-04-09 22:55:37,490 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.615798\n",
      "Reconstruction: 0.601284, Regularization: 0.014514\n",
      "2019-04-09 22:55:37,545 root         INFO     Train Epoch: 16 [2560/8000 (32%)]\tTotal Loss: 0.425605\n",
      "Reconstruction: 0.407370, Regularization: 0.018234\n",
      "2019-04-09 22:55:37,600 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 0.475350\n",
      "Reconstruction: 0.456803, Regularization: 0.018547\n",
      "2019-04-09 22:55:37,655 root         INFO     Train Epoch: 16 [3584/8000 (45%)]\tTotal Loss: 0.526890\n",
      "Reconstruction: 0.507330, Regularization: 0.019560\n",
      "2019-04-09 22:55:37,712 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 0.673943\n",
      "Reconstruction: 0.647146, Regularization: 0.026797\n",
      "2019-04-09 22:55:37,768 root         INFO     Train Epoch: 16 [4608/8000 (58%)]\tTotal Loss: 0.467819\n",
      "Reconstruction: 0.445176, Regularization: 0.022643\n",
      "2019-04-09 22:55:37,824 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 0.384800\n",
      "Reconstruction: 0.369894, Regularization: 0.014906\n",
      "2019-04-09 22:55:37,881 root         INFO     Train Epoch: 16 [5632/8000 (70%)]\tTotal Loss: 1.730531\n",
      "Reconstruction: 1.702507, Regularization: 0.028023\n",
      "2019-04-09 22:55:37,935 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 0.497107\n",
      "Reconstruction: 0.476393, Regularization: 0.020715\n",
      "2019-04-09 22:55:37,991 root         INFO     Train Epoch: 16 [6656/8000 (83%)]\tTotal Loss: 0.529396\n",
      "Reconstruction: 0.511361, Regularization: 0.018035\n",
      "2019-04-09 22:55:38,047 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.602551\n",
      "Reconstruction: 0.586288, Regularization: 0.016262\n",
      "2019-04-09 22:55:38,102 root         INFO     Train Epoch: 16 [7680/8000 (96%)]\tTotal Loss: 0.544636\n",
      "Reconstruction: 0.524164, Regularization: 0.020471\n",
      "2019-04-09 22:55:38,152 root         INFO     ====> Epoch: 16 Average loss: 0.5988\n",
      "2019-04-09 22:55:38,175 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.525245\n",
      "Reconstruction: 0.509571, Regularization: 0.015673\n",
      "2019-04-09 22:55:38,231 root         INFO     Train Epoch: 17 [512/8000 (6%)]\tTotal Loss: 0.480461\n",
      "Reconstruction: 0.460279, Regularization: 0.020182\n",
      "2019-04-09 22:55:38,288 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 213.625427\n",
      "Reconstruction: 213.603851, Regularization: 0.021574\n",
      "2019-04-09 22:55:38,344 root         INFO     Train Epoch: 17 [1536/8000 (19%)]\tTotal Loss: 0.498555\n",
      "Reconstruction: 0.484338, Regularization: 0.014217\n",
      "2019-04-09 22:55:38,401 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.425516\n",
      "Reconstruction: 0.407580, Regularization: 0.017936\n",
      "2019-04-09 22:55:38,458 root         INFO     Train Epoch: 17 [2560/8000 (32%)]\tTotal Loss: 0.509869\n",
      "Reconstruction: 0.488729, Regularization: 0.021140\n",
      "2019-04-09 22:55:38,514 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 0.662925\n",
      "Reconstruction: 0.638836, Regularization: 0.024089\n",
      "2019-04-09 22:55:38,570 root         INFO     Train Epoch: 17 [3584/8000 (45%)]\tTotal Loss: 0.663254\n",
      "Reconstruction: 0.641038, Regularization: 0.022216\n",
      "2019-04-09 22:55:38,626 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.505620\n",
      "Reconstruction: 0.481407, Regularization: 0.024213\n",
      "2019-04-09 22:55:38,682 root         INFO     Train Epoch: 17 [4608/8000 (58%)]\tTotal Loss: 0.463867\n",
      "Reconstruction: 0.445602, Regularization: 0.018265\n",
      "2019-04-09 22:55:38,738 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 0.443132\n",
      "Reconstruction: 0.414281, Regularization: 0.028851\n",
      "2019-04-09 22:55:38,793 root         INFO     Train Epoch: 17 [5632/8000 (70%)]\tTotal Loss: 0.468506\n",
      "Reconstruction: 0.452332, Regularization: 0.016174\n",
      "2019-04-09 22:55:38,849 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 0.479276\n",
      "Reconstruction: 0.453433, Regularization: 0.025843\n",
      "2019-04-09 22:55:38,903 root         INFO     Train Epoch: 17 [6656/8000 (83%)]\tTotal Loss: 0.421240\n",
      "Reconstruction: 0.404018, Regularization: 0.017223\n",
      "2019-04-09 22:55:38,958 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 0.508950\n",
      "Reconstruction: 0.493254, Regularization: 0.015695\n",
      "2019-04-09 22:55:39,014 root         INFO     Train Epoch: 17 [7680/8000 (96%)]\tTotal Loss: 0.559012\n",
      "Reconstruction: 0.538074, Regularization: 0.020938\n",
      "2019-04-09 22:55:39,064 root         INFO     ====> Epoch: 17 Average loss: 1.4480\n",
      "2019-04-09 22:55:39,087 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 0.976323\n",
      "Reconstruction: 0.959167, Regularization: 0.017156\n",
      "2019-04-09 22:55:39,144 root         INFO     Train Epoch: 18 [512/8000 (6%)]\tTotal Loss: 0.646518\n",
      "Reconstruction: 0.623199, Regularization: 0.023319\n",
      "2019-04-09 22:55:39,202 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.576860\n",
      "Reconstruction: 0.557701, Regularization: 0.019159\n",
      "2019-04-09 22:55:39,259 root         INFO     Train Epoch: 18 [1536/8000 (19%)]\tTotal Loss: 0.512724\n",
      "Reconstruction: 0.491224, Regularization: 0.021500\n",
      "2019-04-09 22:55:39,316 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 0.526520\n",
      "Reconstruction: 0.508390, Regularization: 0.018130\n",
      "2019-04-09 22:55:39,374 root         INFO     Train Epoch: 18 [2560/8000 (32%)]\tTotal Loss: 0.401803\n",
      "Reconstruction: 0.376217, Regularization: 0.025586\n",
      "2019-04-09 22:55:39,430 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.492970\n",
      "Reconstruction: 0.478083, Regularization: 0.014887\n",
      "2019-04-09 22:55:39,486 root         INFO     Train Epoch: 18 [3584/8000 (45%)]\tTotal Loss: 0.466166\n",
      "Reconstruction: 0.438627, Regularization: 0.027539\n",
      "2019-04-09 22:55:39,541 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 0.583822\n",
      "Reconstruction: 0.563337, Regularization: 0.020485\n",
      "2019-04-09 22:55:39,596 root         INFO     Train Epoch: 18 [4608/8000 (58%)]\tTotal Loss: 0.486126\n",
      "Reconstruction: 0.460228, Regularization: 0.025898\n",
      "2019-04-09 22:55:39,652 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.558636\n",
      "Reconstruction: 0.527978, Regularization: 0.030658\n",
      "2019-04-09 22:55:39,707 root         INFO     Train Epoch: 18 [5632/8000 (70%)]\tTotal Loss: 0.656772\n",
      "Reconstruction: 0.636004, Regularization: 0.020768\n",
      "2019-04-09 22:55:39,763 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 0.490819\n",
      "Reconstruction: 0.473372, Regularization: 0.017447\n",
      "2019-04-09 22:55:39,819 root         INFO     Train Epoch: 18 [6656/8000 (83%)]\tTotal Loss: 0.417610\n",
      "Reconstruction: 0.391785, Regularization: 0.025825\n",
      "2019-04-09 22:55:39,874 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 0.428170\n",
      "Reconstruction: 0.410902, Regularization: 0.017268\n",
      "2019-04-09 22:55:39,930 root         INFO     Train Epoch: 18 [7680/8000 (96%)]\tTotal Loss: 0.638709\n",
      "Reconstruction: 0.618375, Regularization: 0.020333\n",
      "2019-04-09 22:55:39,979 root         INFO     ====> Epoch: 18 Average loss: 9.7366\n",
      "2019-04-09 22:55:40,002 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 0.629834\n",
      "Reconstruction: 0.611448, Regularization: 0.018386\n",
      "2019-04-09 22:55:40,058 root         INFO     Train Epoch: 19 [512/8000 (6%)]\tTotal Loss: 0.608792\n",
      "Reconstruction: 0.587945, Regularization: 0.020847\n",
      "2019-04-09 22:55:40,114 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 0.491555\n",
      "Reconstruction: 0.475669, Regularization: 0.015886\n",
      "2019-04-09 22:55:40,169 root         INFO     Train Epoch: 19 [1536/8000 (19%)]\tTotal Loss: 0.676428\n",
      "Reconstruction: 0.647682, Regularization: 0.028746\n",
      "2019-04-09 22:55:40,225 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 0.330289\n",
      "Reconstruction: 0.315649, Regularization: 0.014641\n",
      "2019-04-09 22:55:40,281 root         INFO     Train Epoch: 19 [2560/8000 (32%)]\tTotal Loss: 0.519696\n",
      "Reconstruction: 0.501214, Regularization: 0.018483\n",
      "2019-04-09 22:55:40,337 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 3.258028\n",
      "Reconstruction: 3.237951, Regularization: 0.020077\n",
      "2019-04-09 22:55:40,393 root         INFO     Train Epoch: 19 [3584/8000 (45%)]\tTotal Loss: 0.450802\n",
      "Reconstruction: 0.434574, Regularization: 0.016228\n",
      "2019-04-09 22:55:40,448 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 0.640808\n",
      "Reconstruction: 0.605253, Regularization: 0.035554\n",
      "2019-04-09 22:55:40,504 root         INFO     Train Epoch: 19 [4608/8000 (58%)]\tTotal Loss: 0.703354\n",
      "Reconstruction: 0.658007, Regularization: 0.045347\n",
      "2019-04-09 22:55:40,560 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 0.464453\n",
      "Reconstruction: 0.448088, Regularization: 0.016365\n",
      "2019-04-09 22:55:40,615 root         INFO     Train Epoch: 19 [5632/8000 (70%)]\tTotal Loss: 0.577452\n",
      "Reconstruction: 0.559560, Regularization: 0.017893\n",
      "2019-04-09 22:55:40,671 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 0.480731\n",
      "Reconstruction: 0.465217, Regularization: 0.015515\n",
      "2019-04-09 22:55:40,726 root         INFO     Train Epoch: 19 [6656/8000 (83%)]\tTotal Loss: 0.481540\n",
      "Reconstruction: 0.449721, Regularization: 0.031819\n",
      "2019-04-09 22:55:40,782 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.477537\n",
      "Reconstruction: 0.458826, Regularization: 0.018711\n",
      "2019-04-09 22:55:40,838 root         INFO     Train Epoch: 19 [7680/8000 (96%)]\tTotal Loss: 0.369621\n",
      "Reconstruction: 0.354478, Regularization: 0.015143\n",
      "2019-04-09 22:55:40,887 root         INFO     ====> Epoch: 19 Average loss: 1.6004\n",
      "2019-04-09 22:55:40,910 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 0.489252\n",
      "Reconstruction: 0.465837, Regularization: 0.023414\n",
      "2019-04-09 22:55:40,967 root         INFO     Train Epoch: 20 [512/8000 (6%)]\tTotal Loss: 0.564928\n",
      "Reconstruction: 0.539284, Regularization: 0.025643\n",
      "2019-04-09 22:55:41,023 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 13.131721\n",
      "Reconstruction: 13.090603, Regularization: 0.041117\n",
      "2019-04-09 22:55:41,078 root         INFO     Train Epoch: 20 [1536/8000 (19%)]\tTotal Loss: 0.472134\n",
      "Reconstruction: 0.437036, Regularization: 0.035097\n",
      "2019-04-09 22:55:41,134 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 0.425164\n",
      "Reconstruction: 0.408003, Regularization: 0.017162\n",
      "2019-04-09 22:55:41,189 root         INFO     Train Epoch: 20 [2560/8000 (32%)]\tTotal Loss: 0.495998\n",
      "Reconstruction: 0.481204, Regularization: 0.014794\n",
      "2019-04-09 22:55:41,244 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 0.454914\n",
      "Reconstruction: 0.437731, Regularization: 0.017183\n",
      "2019-04-09 22:55:41,300 root         INFO     Train Epoch: 20 [3584/8000 (45%)]\tTotal Loss: 0.392170\n",
      "Reconstruction: 0.377518, Regularization: 0.014652\n",
      "2019-04-09 22:55:41,355 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 0.444615\n",
      "Reconstruction: 0.429842, Regularization: 0.014773\n",
      "2019-04-09 22:55:41,410 root         INFO     Train Epoch: 20 [4608/8000 (58%)]\tTotal Loss: 0.426415\n",
      "Reconstruction: 0.408197, Regularization: 0.018219\n",
      "2019-04-09 22:55:41,465 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 0.469790\n",
      "Reconstruction: 0.453849, Regularization: 0.015941\n",
      "2019-04-09 22:55:41,521 root         INFO     Train Epoch: 20 [5632/8000 (70%)]\tTotal Loss: 0.559040\n",
      "Reconstruction: 0.542620, Regularization: 0.016420\n",
      "2019-04-09 22:55:41,577 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 0.803166\n",
      "Reconstruction: 0.787520, Regularization: 0.015646\n",
      "2019-04-09 22:55:41,632 root         INFO     Train Epoch: 20 [6656/8000 (83%)]\tTotal Loss: 0.505934\n",
      "Reconstruction: 0.481995, Regularization: 0.023939\n",
      "2019-04-09 22:55:41,687 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 0.483618\n",
      "Reconstruction: 0.436965, Regularization: 0.046653\n",
      "2019-04-09 22:55:41,742 root         INFO     Train Epoch: 20 [7680/8000 (96%)]\tTotal Loss: 0.396924\n",
      "Reconstruction: 0.376715, Regularization: 0.020208\n",
      "2019-04-09 22:55:41,791 root         INFO     ====> Epoch: 20 Average loss: 1.0902\n",
      "2019-04-09 22:55:41,815 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.519133\n",
      "Reconstruction: 0.499859, Regularization: 0.019274\n",
      "2019-04-09 22:55:41,871 root         INFO     Train Epoch: 21 [512/8000 (6%)]\tTotal Loss: 0.543828\n",
      "Reconstruction: 0.525241, Regularization: 0.018586\n",
      "2019-04-09 22:55:41,926 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 0.490882\n",
      "Reconstruction: 0.473733, Regularization: 0.017149\n",
      "2019-04-09 22:55:41,981 root         INFO     Train Epoch: 21 [1536/8000 (19%)]\tTotal Loss: 1.401101\n",
      "Reconstruction: 1.365656, Regularization: 0.035445\n",
      "2019-04-09 22:55:42,035 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 0.504458\n",
      "Reconstruction: 0.484489, Regularization: 0.019969\n",
      "2019-04-09 22:55:42,090 root         INFO     Train Epoch: 21 [2560/8000 (32%)]\tTotal Loss: 0.666692\n",
      "Reconstruction: 0.642223, Regularization: 0.024469\n",
      "2019-04-09 22:55:42,144 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 0.562216\n",
      "Reconstruction: 0.544855, Regularization: 0.017361\n",
      "2019-04-09 22:55:42,198 root         INFO     Train Epoch: 21 [3584/8000 (45%)]\tTotal Loss: 0.549947\n",
      "Reconstruction: 0.534580, Regularization: 0.015366\n",
      "2019-04-09 22:55:42,252 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.611205\n",
      "Reconstruction: 0.565212, Regularization: 0.045993\n",
      "2019-04-09 22:55:42,307 root         INFO     Train Epoch: 21 [4608/8000 (58%)]\tTotal Loss: 0.496551\n",
      "Reconstruction: 0.480867, Regularization: 0.015684\n",
      "2019-04-09 22:55:42,361 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 0.439164\n",
      "Reconstruction: 0.422929, Regularization: 0.016234\n",
      "2019-04-09 22:55:42,415 root         INFO     Train Epoch: 21 [5632/8000 (70%)]\tTotal Loss: 0.471674\n",
      "Reconstruction: 0.450609, Regularization: 0.021065\n",
      "2019-04-09 22:55:42,471 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 0.502791\n",
      "Reconstruction: 0.483856, Regularization: 0.018935\n",
      "2019-04-09 22:55:42,525 root         INFO     Train Epoch: 21 [6656/8000 (83%)]\tTotal Loss: 0.614110\n",
      "Reconstruction: 0.588037, Regularization: 0.026073\n",
      "2019-04-09 22:55:42,579 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.586372\n",
      "Reconstruction: 0.529027, Regularization: 0.057345\n",
      "2019-04-09 22:55:42,634 root         INFO     Train Epoch: 21 [7680/8000 (96%)]\tTotal Loss: 0.441115\n",
      "Reconstruction: 0.424004, Regularization: 0.017112\n",
      "2019-04-09 22:55:42,684 root         INFO     ====> Epoch: 21 Average loss: 0.7844\n",
      "2019-04-09 22:55:42,708 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 0.410988\n",
      "Reconstruction: 0.396821, Regularization: 0.014167\n",
      "2019-04-09 22:55:42,763 root         INFO     Train Epoch: 22 [512/8000 (6%)]\tTotal Loss: 0.522410\n",
      "Reconstruction: 0.502561, Regularization: 0.019849\n",
      "2019-04-09 22:55:42,818 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 0.453809\n",
      "Reconstruction: 0.436620, Regularization: 0.017189\n",
      "2019-04-09 22:55:42,874 root         INFO     Train Epoch: 22 [1536/8000 (19%)]\tTotal Loss: 0.424571\n",
      "Reconstruction: 0.411627, Regularization: 0.012944\n",
      "2019-04-09 22:55:42,929 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 0.551227\n",
      "Reconstruction: 0.531970, Regularization: 0.019257\n",
      "2019-04-09 22:55:42,984 root         INFO     Train Epoch: 22 [2560/8000 (32%)]\tTotal Loss: 0.670179\n",
      "Reconstruction: 0.649205, Regularization: 0.020974\n",
      "2019-04-09 22:55:43,040 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 0.549818\n",
      "Reconstruction: 0.527394, Regularization: 0.022424\n",
      "2019-04-09 22:55:43,095 root         INFO     Train Epoch: 22 [3584/8000 (45%)]\tTotal Loss: 0.559926\n",
      "Reconstruction: 0.540149, Regularization: 0.019777\n",
      "2019-04-09 22:55:43,150 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.352317\n",
      "Reconstruction: 0.337897, Regularization: 0.014420\n",
      "2019-04-09 22:55:43,206 root         INFO     Train Epoch: 22 [4608/8000 (58%)]\tTotal Loss: 0.380916\n",
      "Reconstruction: 0.354917, Regularization: 0.025999\n",
      "2019-04-09 22:55:43,261 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 0.447953\n",
      "Reconstruction: 0.428243, Regularization: 0.019710\n",
      "2019-04-09 22:55:43,317 root         INFO     Train Epoch: 22 [5632/8000 (70%)]\tTotal Loss: 0.683869\n",
      "Reconstruction: 0.653717, Regularization: 0.030152\n",
      "2019-04-09 22:55:43,371 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 0.569939\n",
      "Reconstruction: 0.548356, Regularization: 0.021583\n",
      "2019-04-09 22:55:43,427 root         INFO     Train Epoch: 22 [6656/8000 (83%)]\tTotal Loss: 0.464036\n",
      "Reconstruction: 0.447790, Regularization: 0.016246\n",
      "2019-04-09 22:55:43,482 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 0.592713\n",
      "Reconstruction: 0.568246, Regularization: 0.024467\n",
      "2019-04-09 22:55:43,538 root         INFO     Train Epoch: 22 [7680/8000 (96%)]\tTotal Loss: 9.109556\n",
      "Reconstruction: 9.081271, Regularization: 0.028285\n",
      "2019-04-09 22:55:43,588 root         INFO     ====> Epoch: 22 Average loss: 0.7818\n",
      "2019-04-09 22:55:43,611 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 0.605838\n",
      "Reconstruction: 0.585561, Regularization: 0.020277\n",
      "2019-04-09 22:55:43,667 root         INFO     Train Epoch: 23 [512/8000 (6%)]\tTotal Loss: 0.550308\n",
      "Reconstruction: 0.531123, Regularization: 0.019185\n",
      "2019-04-09 22:55:43,724 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 0.543418\n",
      "Reconstruction: 0.524983, Regularization: 0.018434\n",
      "2019-04-09 22:55:43,780 root         INFO     Train Epoch: 23 [1536/8000 (19%)]\tTotal Loss: 0.563304\n",
      "Reconstruction: 0.540865, Regularization: 0.022438\n",
      "2019-04-09 22:55:43,836 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 0.788013\n",
      "Reconstruction: 0.766863, Regularization: 0.021150\n",
      "2019-04-09 22:55:43,893 root         INFO     Train Epoch: 23 [2560/8000 (32%)]\tTotal Loss: 0.664287\n",
      "Reconstruction: 0.642373, Regularization: 0.021914\n",
      "2019-04-09 22:55:43,949 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 0.436638\n",
      "Reconstruction: 0.420587, Regularization: 0.016050\n",
      "2019-04-09 22:55:44,006 root         INFO     Train Epoch: 23 [3584/8000 (45%)]\tTotal Loss: 0.607439\n",
      "Reconstruction: 0.585635, Regularization: 0.021804\n",
      "2019-04-09 22:55:44,062 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 0.483931\n",
      "Reconstruction: 0.467847, Regularization: 0.016084\n",
      "2019-04-09 22:55:44,118 root         INFO     Train Epoch: 23 [4608/8000 (58%)]\tTotal Loss: 0.580870\n",
      "Reconstruction: 0.558258, Regularization: 0.022611\n",
      "2019-04-09 22:55:44,174 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 0.439426\n",
      "Reconstruction: 0.400437, Regularization: 0.038989\n",
      "2019-04-09 22:55:44,229 root         INFO     Train Epoch: 23 [5632/8000 (70%)]\tTotal Loss: 0.514825\n",
      "Reconstruction: 0.497062, Regularization: 0.017763\n",
      "2019-04-09 22:55:44,285 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 0.446256\n",
      "Reconstruction: 0.429689, Regularization: 0.016567\n",
      "2019-04-09 22:55:44,340 root         INFO     Train Epoch: 23 [6656/8000 (83%)]\tTotal Loss: 0.429679\n",
      "Reconstruction: 0.412814, Regularization: 0.016865\n",
      "2019-04-09 22:55:44,396 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 0.463208\n",
      "Reconstruction: 0.444965, Regularization: 0.018242\n",
      "2019-04-09 22:55:44,452 root         INFO     Train Epoch: 23 [7680/8000 (96%)]\tTotal Loss: 0.424227\n",
      "Reconstruction: 0.408822, Regularization: 0.015405\n",
      "2019-04-09 22:55:44,501 root         INFO     ====> Epoch: 23 Average loss: 0.6502\n",
      "2019-04-09 22:55:44,525 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.431761\n",
      "Reconstruction: 0.416723, Regularization: 0.015038\n",
      "2019-04-09 22:55:44,582 root         INFO     Train Epoch: 24 [512/8000 (6%)]\tTotal Loss: 0.471121\n",
      "Reconstruction: 0.449523, Regularization: 0.021598\n",
      "2019-04-09 22:55:44,638 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 0.995005\n",
      "Reconstruction: 0.965289, Regularization: 0.029716\n",
      "2019-04-09 22:55:44,694 root         INFO     Train Epoch: 24 [1536/8000 (19%)]\tTotal Loss: 0.494258\n",
      "Reconstruction: 0.474083, Regularization: 0.020175\n",
      "2019-04-09 22:55:44,750 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 0.386683\n",
      "Reconstruction: 0.374073, Regularization: 0.012609\n",
      "2019-04-09 22:55:44,807 root         INFO     Train Epoch: 24 [2560/8000 (32%)]\tTotal Loss: 0.554337\n",
      "Reconstruction: 0.530022, Regularization: 0.024315\n",
      "2019-04-09 22:55:44,863 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 0.758097\n",
      "Reconstruction: 0.739689, Regularization: 0.018409\n",
      "2019-04-09 22:55:44,918 root         INFO     Train Epoch: 24 [3584/8000 (45%)]\tTotal Loss: 0.410948\n",
      "Reconstruction: 0.396322, Regularization: 0.014626\n",
      "2019-04-09 22:55:44,973 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 0.487866\n",
      "Reconstruction: 0.461008, Regularization: 0.026858\n",
      "2019-04-09 22:55:45,028 root         INFO     Train Epoch: 24 [4608/8000 (58%)]\tTotal Loss: 0.442869\n",
      "Reconstruction: 0.424617, Regularization: 0.018252\n",
      "2019-04-09 22:55:45,083 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 0.483641\n",
      "Reconstruction: 0.466819, Regularization: 0.016823\n",
      "2019-04-09 22:55:45,138 root         INFO     Train Epoch: 24 [5632/8000 (70%)]\tTotal Loss: 0.359720\n",
      "Reconstruction: 0.342435, Regularization: 0.017285\n",
      "2019-04-09 22:55:45,193 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 1.018414\n",
      "Reconstruction: 0.991534, Regularization: 0.026880\n",
      "2019-04-09 22:55:45,247 root         INFO     Train Epoch: 24 [6656/8000 (83%)]\tTotal Loss: 0.374470\n",
      "Reconstruction: 0.355798, Regularization: 0.018672\n",
      "2019-04-09 22:55:45,303 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 0.523537\n",
      "Reconstruction: 0.505586, Regularization: 0.017951\n",
      "2019-04-09 22:55:45,358 root         INFO     Train Epoch: 24 [7680/8000 (96%)]\tTotal Loss: 0.853732\n",
      "Reconstruction: 0.827088, Regularization: 0.026644\n",
      "2019-04-09 22:55:45,407 root         INFO     ====> Epoch: 24 Average loss: 0.8030\n",
      "2019-04-09 22:55:45,431 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 0.451739\n",
      "Reconstruction: 0.435611, Regularization: 0.016127\n",
      "2019-04-09 22:55:45,487 root         INFO     Train Epoch: 25 [512/8000 (6%)]\tTotal Loss: 0.470109\n",
      "Reconstruction: 0.451504, Regularization: 0.018605\n",
      "2019-04-09 22:55:45,543 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 0.370068\n",
      "Reconstruction: 0.354475, Regularization: 0.015593\n",
      "2019-04-09 22:55:45,600 root         INFO     Train Epoch: 25 [1536/8000 (19%)]\tTotal Loss: 0.475290\n",
      "Reconstruction: 0.455010, Regularization: 0.020280\n",
      "2019-04-09 22:55:45,656 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 0.475242\n",
      "Reconstruction: 0.460183, Regularization: 0.015059\n",
      "2019-04-09 22:55:45,712 root         INFO     Train Epoch: 25 [2560/8000 (32%)]\tTotal Loss: 0.738994\n",
      "Reconstruction: 0.718056, Regularization: 0.020938\n",
      "2019-04-09 22:55:45,768 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 0.361273\n",
      "Reconstruction: 0.346269, Regularization: 0.015004\n",
      "2019-04-09 22:55:45,825 root         INFO     Train Epoch: 25 [3584/8000 (45%)]\tTotal Loss: 0.541634\n",
      "Reconstruction: 0.522744, Regularization: 0.018890\n",
      "2019-04-09 22:55:45,881 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 0.492190\n",
      "Reconstruction: 0.469392, Regularization: 0.022798\n",
      "2019-04-09 22:55:45,937 root         INFO     Train Epoch: 25 [4608/8000 (58%)]\tTotal Loss: 0.450403\n",
      "Reconstruction: 0.436912, Regularization: 0.013491\n",
      "2019-04-09 22:55:45,991 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 0.753551\n",
      "Reconstruction: 0.717929, Regularization: 0.035623\n",
      "2019-04-09 22:55:46,046 root         INFO     Train Epoch: 25 [5632/8000 (70%)]\tTotal Loss: 0.503719\n",
      "Reconstruction: 0.485114, Regularization: 0.018606\n",
      "2019-04-09 22:55:46,101 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.525737\n",
      "Reconstruction: 0.500877, Regularization: 0.024860\n",
      "2019-04-09 22:55:46,155 root         INFO     Train Epoch: 25 [6656/8000 (83%)]\tTotal Loss: 0.462285\n",
      "Reconstruction: 0.439170, Regularization: 0.023116\n",
      "2019-04-09 22:55:46,210 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 0.585143\n",
      "Reconstruction: 0.566048, Regularization: 0.019096\n",
      "2019-04-09 22:55:46,264 root         INFO     Train Epoch: 25 [7680/8000 (96%)]\tTotal Loss: 0.406455\n",
      "Reconstruction: 0.393432, Regularization: 0.013024\n",
      "2019-04-09 22:55:46,314 root         INFO     ====> Epoch: 25 Average loss: 0.9883\n",
      "2019-04-09 22:55:46,337 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 0.685279\n",
      "Reconstruction: 0.664873, Regularization: 0.020406\n",
      "2019-04-09 22:55:46,393 root         INFO     Train Epoch: 26 [512/8000 (6%)]\tTotal Loss: 0.664434\n",
      "Reconstruction: 0.641482, Regularization: 0.022952\n",
      "2019-04-09 22:55:46,449 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 0.408008\n",
      "Reconstruction: 0.391421, Regularization: 0.016588\n",
      "2019-04-09 22:55:46,504 root         INFO     Train Epoch: 26 [1536/8000 (19%)]\tTotal Loss: 0.525192\n",
      "Reconstruction: 0.502441, Regularization: 0.022751\n",
      "2019-04-09 22:55:46,560 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 0.565000\n",
      "Reconstruction: 0.545588, Regularization: 0.019411\n",
      "2019-04-09 22:55:46,617 root         INFO     Train Epoch: 26 [2560/8000 (32%)]\tTotal Loss: 0.446074\n",
      "Reconstruction: 0.429094, Regularization: 0.016979\n",
      "2019-04-09 22:55:46,673 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 0.338061\n",
      "Reconstruction: 0.324700, Regularization: 0.013361\n",
      "2019-04-09 22:55:46,729 root         INFO     Train Epoch: 26 [3584/8000 (45%)]\tTotal Loss: 0.507934\n",
      "Reconstruction: 0.490281, Regularization: 0.017653\n",
      "2019-04-09 22:55:46,784 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.537591\n",
      "Reconstruction: 0.514271, Regularization: 0.023319\n",
      "2019-04-09 22:55:46,841 root         INFO     Train Epoch: 26 [4608/8000 (58%)]\tTotal Loss: 0.548066\n",
      "Reconstruction: 0.527058, Regularization: 0.021008\n",
      "2019-04-09 22:55:46,896 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 0.488794\n",
      "Reconstruction: 0.465725, Regularization: 0.023069\n",
      "2019-04-09 22:55:46,951 root         INFO     Train Epoch: 26 [5632/8000 (70%)]\tTotal Loss: 0.556896\n",
      "Reconstruction: 0.535311, Regularization: 0.021585\n",
      "2019-04-09 22:55:47,006 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 0.465991\n",
      "Reconstruction: 0.450155, Regularization: 0.015836\n",
      "2019-04-09 22:55:47,062 root         INFO     Train Epoch: 26 [6656/8000 (83%)]\tTotal Loss: 0.407654\n",
      "Reconstruction: 0.391158, Regularization: 0.016497\n",
      "2019-04-09 22:55:47,117 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 0.521409\n",
      "Reconstruction: 0.502080, Regularization: 0.019329\n",
      "2019-04-09 22:55:47,173 root         INFO     Train Epoch: 26 [7680/8000 (96%)]\tTotal Loss: 0.479925\n",
      "Reconstruction: 0.462435, Regularization: 0.017490\n",
      "2019-04-09 22:55:47,222 root         INFO     ====> Epoch: 26 Average loss: 0.5967\n",
      "2019-04-09 22:55:47,245 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 0.451723\n",
      "Reconstruction: 0.432248, Regularization: 0.019475\n",
      "2019-04-09 22:55:47,300 root         INFO     Train Epoch: 27 [512/8000 (6%)]\tTotal Loss: 0.501695\n",
      "Reconstruction: 0.486015, Regularization: 0.015680\n",
      "2019-04-09 22:55:47,355 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.493541\n",
      "Reconstruction: 0.469523, Regularization: 0.024018\n",
      "2019-04-09 22:55:47,411 root         INFO     Train Epoch: 27 [1536/8000 (19%)]\tTotal Loss: 0.590763\n",
      "Reconstruction: 0.569055, Regularization: 0.021708\n",
      "2019-04-09 22:55:47,466 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 0.509535\n",
      "Reconstruction: 0.470077, Regularization: 0.039459\n",
      "2019-04-09 22:55:47,521 root         INFO     Train Epoch: 27 [2560/8000 (32%)]\tTotal Loss: 0.420954\n",
      "Reconstruction: 0.398214, Regularization: 0.022740\n",
      "2019-04-09 22:55:47,575 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.740741\n",
      "Reconstruction: 0.720561, Regularization: 0.020180\n",
      "2019-04-09 22:55:47,630 root         INFO     Train Epoch: 27 [3584/8000 (45%)]\tTotal Loss: 0.388129\n",
      "Reconstruction: 0.374395, Regularization: 0.013733\n",
      "2019-04-09 22:55:47,684 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 0.422477\n",
      "Reconstruction: 0.404013, Regularization: 0.018464\n",
      "2019-04-09 22:55:47,738 root         INFO     Train Epoch: 27 [4608/8000 (58%)]\tTotal Loss: 0.431780\n",
      "Reconstruction: 0.413911, Regularization: 0.017869\n",
      "2019-04-09 22:55:47,792 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.532035\n",
      "Reconstruction: 0.512241, Regularization: 0.019794\n",
      "2019-04-09 22:55:47,848 root         INFO     Train Epoch: 27 [5632/8000 (70%)]\tTotal Loss: 0.410261\n",
      "Reconstruction: 0.383366, Regularization: 0.026896\n",
      "2019-04-09 22:55:47,904 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.481404\n",
      "Reconstruction: 0.467796, Regularization: 0.013608\n",
      "2019-04-09 22:55:47,959 root         INFO     Train Epoch: 27 [6656/8000 (83%)]\tTotal Loss: 0.533010\n",
      "Reconstruction: 0.511128, Regularization: 0.021882\n",
      "2019-04-09 22:55:48,014 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 0.389789\n",
      "Reconstruction: 0.374009, Regularization: 0.015781\n",
      "2019-04-09 22:55:48,070 root         INFO     Train Epoch: 27 [7680/8000 (96%)]\tTotal Loss: 0.493314\n",
      "Reconstruction: 0.475227, Regularization: 0.018086\n",
      "2019-04-09 22:55:48,118 root         INFO     ====> Epoch: 27 Average loss: 0.7877\n",
      "2019-04-09 22:55:48,141 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.617422\n",
      "Reconstruction: 0.595129, Regularization: 0.022293\n",
      "2019-04-09 22:55:48,196 root         INFO     Train Epoch: 28 [512/8000 (6%)]\tTotal Loss: 0.405467\n",
      "Reconstruction: 0.384449, Regularization: 0.021018\n",
      "2019-04-09 22:55:48,251 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.450399\n",
      "Reconstruction: 0.421548, Regularization: 0.028852\n",
      "2019-04-09 22:55:48,306 root         INFO     Train Epoch: 28 [1536/8000 (19%)]\tTotal Loss: 0.538262\n",
      "Reconstruction: 0.521340, Regularization: 0.016922\n",
      "2019-04-09 22:55:48,362 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 0.499301\n",
      "Reconstruction: 0.477151, Regularization: 0.022150\n",
      "2019-04-09 22:55:48,417 root         INFO     Train Epoch: 28 [2560/8000 (32%)]\tTotal Loss: 0.487412\n",
      "Reconstruction: 0.466215, Regularization: 0.021198\n",
      "2019-04-09 22:55:48,472 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.540322\n",
      "Reconstruction: 0.520126, Regularization: 0.020196\n",
      "2019-04-09 22:55:48,527 root         INFO     Train Epoch: 28 [3584/8000 (45%)]\tTotal Loss: 0.402294\n",
      "Reconstruction: 0.387372, Regularization: 0.014921\n",
      "2019-04-09 22:55:48,582 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.602594\n",
      "Reconstruction: 0.581293, Regularization: 0.021301\n",
      "2019-04-09 22:55:48,637 root         INFO     Train Epoch: 28 [4608/8000 (58%)]\tTotal Loss: 0.454331\n",
      "Reconstruction: 0.439220, Regularization: 0.015111\n",
      "2019-04-09 22:55:48,692 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.457400\n",
      "Reconstruction: 0.440305, Regularization: 0.017095\n",
      "2019-04-09 22:55:48,748 root         INFO     Train Epoch: 28 [5632/8000 (70%)]\tTotal Loss: 0.553791\n",
      "Reconstruction: 0.534484, Regularization: 0.019307\n",
      "2019-04-09 22:55:48,803 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.389652\n",
      "Reconstruction: 0.368804, Regularization: 0.020848\n",
      "2019-04-09 22:55:48,858 root         INFO     Train Epoch: 28 [6656/8000 (83%)]\tTotal Loss: 0.457510\n",
      "Reconstruction: 0.438566, Regularization: 0.018944\n",
      "2019-04-09 22:55:48,914 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.545597\n",
      "Reconstruction: 0.532948, Regularization: 0.012648\n",
      "2019-04-09 22:55:48,970 root         INFO     Train Epoch: 28 [7680/8000 (96%)]\tTotal Loss: 0.349022\n",
      "Reconstruction: 0.334627, Regularization: 0.014395\n",
      "2019-04-09 22:55:49,020 root         INFO     ====> Epoch: 28 Average loss: 7.6690\n",
      "2019-04-09 22:55:49,043 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 0.444117\n",
      "Reconstruction: 0.420560, Regularization: 0.023556\n",
      "2019-04-09 22:55:49,099 root         INFO     Train Epoch: 29 [512/8000 (6%)]\tTotal Loss: 0.378509\n",
      "Reconstruction: 0.355897, Regularization: 0.022612\n",
      "2019-04-09 22:55:49,155 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 0.474082\n",
      "Reconstruction: 0.458263, Regularization: 0.015819\n",
      "2019-04-09 22:55:49,211 root         INFO     Train Epoch: 29 [1536/8000 (19%)]\tTotal Loss: 0.317144\n",
      "Reconstruction: 0.304992, Regularization: 0.012151\n",
      "2019-04-09 22:55:49,267 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 0.439725\n",
      "Reconstruction: 0.424977, Regularization: 0.014747\n",
      "2019-04-09 22:55:49,323 root         INFO     Train Epoch: 29 [2560/8000 (32%)]\tTotal Loss: 0.428728\n",
      "Reconstruction: 0.414780, Regularization: 0.013949\n",
      "2019-04-09 22:55:49,379 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 0.429795\n",
      "Reconstruction: 0.411973, Regularization: 0.017823\n",
      "2019-04-09 22:55:49,435 root         INFO     Train Epoch: 29 [3584/8000 (45%)]\tTotal Loss: 0.569604\n",
      "Reconstruction: 0.543063, Regularization: 0.026541\n",
      "2019-04-09 22:55:49,491 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.439128\n",
      "Reconstruction: 0.410901, Regularization: 0.028227\n",
      "2019-04-09 22:55:49,547 root         INFO     Train Epoch: 29 [4608/8000 (58%)]\tTotal Loss: 0.470547\n",
      "Reconstruction: 0.447733, Regularization: 0.022814\n",
      "2019-04-09 22:55:49,603 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 1.468343\n",
      "Reconstruction: 1.433559, Regularization: 0.034784\n",
      "2019-04-09 22:55:49,659 root         INFO     Train Epoch: 29 [5632/8000 (70%)]\tTotal Loss: 0.627802\n",
      "Reconstruction: 0.602004, Regularization: 0.025797\n",
      "2019-04-09 22:55:49,715 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 0.461538\n",
      "Reconstruction: 0.432607, Regularization: 0.028931\n",
      "2019-04-09 22:55:49,771 root         INFO     Train Epoch: 29 [6656/8000 (83%)]\tTotal Loss: 0.414931\n",
      "Reconstruction: 0.400333, Regularization: 0.014598\n",
      "2019-04-09 22:55:49,827 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.437615\n",
      "Reconstruction: 0.419501, Regularization: 0.018114\n",
      "2019-04-09 22:55:49,883 root         INFO     Train Epoch: 29 [7680/8000 (96%)]\tTotal Loss: 0.547910\n",
      "Reconstruction: 0.530965, Regularization: 0.016945\n",
      "2019-04-09 22:55:49,933 root         INFO     ====> Epoch: 29 Average loss: 1.1701\n",
      "2019-04-09 22:55:49,956 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.521009\n",
      "Reconstruction: 0.498703, Regularization: 0.022307\n",
      "2019-04-09 22:55:50,012 root         INFO     Train Epoch: 30 [512/8000 (6%)]\tTotal Loss: 0.389318\n",
      "Reconstruction: 0.373322, Regularization: 0.015996\n",
      "2019-04-09 22:55:50,069 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.635922\n",
      "Reconstruction: 0.601598, Regularization: 0.034324\n",
      "2019-04-09 22:55:50,125 root         INFO     Train Epoch: 30 [1536/8000 (19%)]\tTotal Loss: 0.423907\n",
      "Reconstruction: 0.407568, Regularization: 0.016339\n",
      "2019-04-09 22:55:50,181 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.395129\n",
      "Reconstruction: 0.378326, Regularization: 0.016803\n",
      "2019-04-09 22:55:50,237 root         INFO     Train Epoch: 30 [2560/8000 (32%)]\tTotal Loss: 0.646248\n",
      "Reconstruction: 0.628689, Regularization: 0.017559\n",
      "2019-04-09 22:55:50,293 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.440861\n",
      "Reconstruction: 0.425162, Regularization: 0.015699\n",
      "2019-04-09 22:55:50,349 root         INFO     Train Epoch: 30 [3584/8000 (45%)]\tTotal Loss: 0.497923\n",
      "Reconstruction: 0.479330, Regularization: 0.018592\n",
      "2019-04-09 22:55:50,405 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.382465\n",
      "Reconstruction: 0.368769, Regularization: 0.013697\n",
      "2019-04-09 22:55:50,462 root         INFO     Train Epoch: 30 [4608/8000 (58%)]\tTotal Loss: 0.435078\n",
      "Reconstruction: 0.419364, Regularization: 0.015715\n",
      "2019-04-09 22:55:50,519 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.511783\n",
      "Reconstruction: 0.496080, Regularization: 0.015703\n",
      "2019-04-09 22:55:50,576 root         INFO     Train Epoch: 30 [5632/8000 (70%)]\tTotal Loss: 0.526415\n",
      "Reconstruction: 0.510654, Regularization: 0.015761\n",
      "2019-04-09 22:55:50,634 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.511522\n",
      "Reconstruction: 0.490406, Regularization: 0.021116\n",
      "2019-04-09 22:55:50,691 root         INFO     Train Epoch: 30 [6656/8000 (83%)]\tTotal Loss: 0.394771\n",
      "Reconstruction: 0.379311, Regularization: 0.015460\n",
      "2019-04-09 22:55:50,749 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 0.532347\n",
      "Reconstruction: 0.511203, Regularization: 0.021144\n",
      "2019-04-09 22:55:50,807 root         INFO     Train Epoch: 30 [7680/8000 (96%)]\tTotal Loss: 0.533310\n",
      "Reconstruction: 0.514997, Regularization: 0.018313\n",
      "2019-04-09 22:55:50,857 root         INFO     ====> Epoch: 30 Average loss: 14.5869\n",
      "2019-04-09 22:55:50,880 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.526844\n",
      "Reconstruction: 0.506832, Regularization: 0.020012\n",
      "2019-04-09 22:55:50,937 root         INFO     Train Epoch: 31 [512/8000 (6%)]\tTotal Loss: 0.457764\n",
      "Reconstruction: 0.438900, Regularization: 0.018864\n",
      "2019-04-09 22:55:50,995 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.499490\n",
      "Reconstruction: 0.475960, Regularization: 0.023531\n",
      "2019-04-09 22:55:51,052 root         INFO     Train Epoch: 31 [1536/8000 (19%)]\tTotal Loss: 0.472103\n",
      "Reconstruction: 0.452652, Regularization: 0.019451\n",
      "2019-04-09 22:55:51,109 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 1.135404\n",
      "Reconstruction: 1.109954, Regularization: 0.025450\n",
      "2019-04-09 22:55:51,166 root         INFO     Train Epoch: 31 [2560/8000 (32%)]\tTotal Loss: 0.403107\n",
      "Reconstruction: 0.388260, Regularization: 0.014847\n",
      "2019-04-09 22:55:51,221 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.377694\n",
      "Reconstruction: 0.363887, Regularization: 0.013807\n",
      "2019-04-09 22:55:51,277 root         INFO     Train Epoch: 31 [3584/8000 (45%)]\tTotal Loss: 0.458731\n",
      "Reconstruction: 0.437681, Regularization: 0.021050\n",
      "2019-04-09 22:55:51,333 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.398818\n",
      "Reconstruction: 0.380007, Regularization: 0.018811\n",
      "2019-04-09 22:55:51,388 root         INFO     Train Epoch: 31 [4608/8000 (58%)]\tTotal Loss: 0.521159\n",
      "Reconstruction: 0.501417, Regularization: 0.019742\n",
      "2019-04-09 22:55:51,443 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.449504\n",
      "Reconstruction: 0.434057, Regularization: 0.015447\n",
      "2019-04-09 22:55:51,498 root         INFO     Train Epoch: 31 [5632/8000 (70%)]\tTotal Loss: 7.447954\n",
      "Reconstruction: 7.421510, Regularization: 0.026444\n",
      "2019-04-09 22:55:51,553 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 2.841626\n",
      "Reconstruction: 2.808770, Regularization: 0.032856\n",
      "2019-04-09 22:55:51,608 root         INFO     Train Epoch: 31 [6656/8000 (83%)]\tTotal Loss: 0.462767\n",
      "Reconstruction: 0.445289, Regularization: 0.017478\n",
      "2019-04-09 22:55:51,664 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 0.374433\n",
      "Reconstruction: 0.361791, Regularization: 0.012642\n",
      "2019-04-09 22:55:51,719 root         INFO     Train Epoch: 31 [7680/8000 (96%)]\tTotal Loss: 0.329434\n",
      "Reconstruction: 0.312631, Regularization: 0.016803\n",
      "2019-04-09 22:55:51,768 root         INFO     ====> Epoch: 31 Average loss: 350.9218\n",
      "2019-04-09 22:55:51,791 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.421998\n",
      "Reconstruction: 0.407736, Regularization: 0.014262\n",
      "2019-04-09 22:55:51,847 root         INFO     Train Epoch: 32 [512/8000 (6%)]\tTotal Loss: 0.530213\n",
      "Reconstruction: 0.511296, Regularization: 0.018917\n",
      "2019-04-09 22:55:51,904 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.412884\n",
      "Reconstruction: 0.396136, Regularization: 0.016748\n",
      "2019-04-09 22:55:51,960 root         INFO     Train Epoch: 32 [1536/8000 (19%)]\tTotal Loss: 0.478888\n",
      "Reconstruction: 0.458340, Regularization: 0.020548\n",
      "2019-04-09 22:55:52,017 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.538879\n",
      "Reconstruction: 0.521170, Regularization: 0.017709\n",
      "2019-04-09 22:55:52,073 root         INFO     Train Epoch: 32 [2560/8000 (32%)]\tTotal Loss: 0.438935\n",
      "Reconstruction: 0.394382, Regularization: 0.044553\n",
      "2019-04-09 22:55:52,129 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.665819\n",
      "Reconstruction: 0.639780, Regularization: 0.026039\n",
      "2019-04-09 22:55:52,185 root         INFO     Train Epoch: 32 [3584/8000 (45%)]\tTotal Loss: 0.579924\n",
      "Reconstruction: 0.547978, Regularization: 0.031946\n",
      "2019-04-09 22:55:52,241 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.465197\n",
      "Reconstruction: 0.445931, Regularization: 0.019265\n",
      "2019-04-09 22:55:52,297 root         INFO     Train Epoch: 32 [4608/8000 (58%)]\tTotal Loss: 0.419534\n",
      "Reconstruction: 0.404967, Regularization: 0.014567\n",
      "2019-04-09 22:55:52,353 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 0.428624\n",
      "Reconstruction: 0.412084, Regularization: 0.016540\n",
      "2019-04-09 22:55:52,409 root         INFO     Train Epoch: 32 [5632/8000 (70%)]\tTotal Loss: 0.396067\n",
      "Reconstruction: 0.380531, Regularization: 0.015537\n",
      "2019-04-09 22:55:52,465 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.401338\n",
      "Reconstruction: 0.381425, Regularization: 0.019914\n",
      "2019-04-09 22:55:52,520 root         INFO     Train Epoch: 32 [6656/8000 (83%)]\tTotal Loss: 0.516600\n",
      "Reconstruction: 0.497746, Regularization: 0.018854\n",
      "2019-04-09 22:55:52,574 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.452866\n",
      "Reconstruction: 0.433431, Regularization: 0.019436\n",
      "2019-04-09 22:55:52,628 root         INFO     Train Epoch: 32 [7680/8000 (96%)]\tTotal Loss: 0.577382\n",
      "Reconstruction: 0.555559, Regularization: 0.021823\n",
      "2019-04-09 22:55:52,677 root         INFO     ====> Epoch: 32 Average loss: 0.6138\n",
      "2019-04-09 22:55:52,700 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.542984\n",
      "Reconstruction: 0.523151, Regularization: 0.019833\n",
      "2019-04-09 22:55:52,756 root         INFO     Train Epoch: 33 [512/8000 (6%)]\tTotal Loss: 0.457462\n",
      "Reconstruction: 0.439581, Regularization: 0.017881\n",
      "2019-04-09 22:55:52,811 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.503698\n",
      "Reconstruction: 0.485238, Regularization: 0.018460\n",
      "2019-04-09 22:55:52,865 root         INFO     Train Epoch: 33 [1536/8000 (19%)]\tTotal Loss: 0.451087\n",
      "Reconstruction: 0.435426, Regularization: 0.015661\n",
      "2019-04-09 22:55:52,920 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.445545\n",
      "Reconstruction: 0.430071, Regularization: 0.015474\n",
      "2019-04-09 22:55:52,975 root         INFO     Train Epoch: 33 [2560/8000 (32%)]\tTotal Loss: 0.522518\n",
      "Reconstruction: 0.488019, Regularization: 0.034499\n",
      "2019-04-09 22:55:53,030 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.441672\n",
      "Reconstruction: 0.425704, Regularization: 0.015968\n",
      "2019-04-09 22:55:53,085 root         INFO     Train Epoch: 33 [3584/8000 (45%)]\tTotal Loss: 0.486016\n",
      "Reconstruction: 0.468217, Regularization: 0.017799\n",
      "2019-04-09 22:55:53,140 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 2.153745\n",
      "Reconstruction: 2.131671, Regularization: 0.022075\n",
      "2019-04-09 22:55:53,195 root         INFO     Train Epoch: 33 [4608/8000 (58%)]\tTotal Loss: 0.507139\n",
      "Reconstruction: 0.489406, Regularization: 0.017732\n",
      "2019-04-09 22:55:53,250 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.487717\n",
      "Reconstruction: 0.465750, Regularization: 0.021967\n",
      "2019-04-09 22:55:53,305 root         INFO     Train Epoch: 33 [5632/8000 (70%)]\tTotal Loss: 0.492814\n",
      "Reconstruction: 0.474210, Regularization: 0.018604\n",
      "2019-04-09 22:55:53,360 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 0.576307\n",
      "Reconstruction: 0.555327, Regularization: 0.020980\n",
      "2019-04-09 22:55:53,416 root         INFO     Train Epoch: 33 [6656/8000 (83%)]\tTotal Loss: 0.525804\n",
      "Reconstruction: 0.505290, Regularization: 0.020514\n",
      "2019-04-09 22:55:53,471 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.632405\n",
      "Reconstruction: 0.606673, Regularization: 0.025732\n",
      "2019-04-09 22:55:53,526 root         INFO     Train Epoch: 33 [7680/8000 (96%)]\tTotal Loss: 0.435265\n",
      "Reconstruction: 0.417233, Regularization: 0.018032\n",
      "2019-04-09 22:55:53,575 root         INFO     ====> Epoch: 33 Average loss: 1984.6368\n",
      "2019-04-09 22:55:53,598 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.419469\n",
      "Reconstruction: 0.403616, Regularization: 0.015853\n",
      "2019-04-09 22:55:53,655 root         INFO     Train Epoch: 34 [512/8000 (6%)]\tTotal Loss: 0.697910\n",
      "Reconstruction: 0.672409, Regularization: 0.025501\n",
      "2019-04-09 22:55:53,712 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.418894\n",
      "Reconstruction: 0.401781, Regularization: 0.017113\n",
      "2019-04-09 22:55:53,768 root         INFO     Train Epoch: 34 [1536/8000 (19%)]\tTotal Loss: 0.534311\n",
      "Reconstruction: 0.513894, Regularization: 0.020417\n",
      "2019-04-09 22:55:53,824 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.484673\n",
      "Reconstruction: 0.465739, Regularization: 0.018934\n",
      "2019-04-09 22:55:53,880 root         INFO     Train Epoch: 34 [2560/8000 (32%)]\tTotal Loss: 0.486130\n",
      "Reconstruction: 0.468422, Regularization: 0.017708\n",
      "2019-04-09 22:55:53,936 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.361456\n",
      "Reconstruction: 0.347629, Regularization: 0.013827\n",
      "2019-04-09 22:55:53,991 root         INFO     Train Epoch: 34 [3584/8000 (45%)]\tTotal Loss: 0.389499\n",
      "Reconstruction: 0.376486, Regularization: 0.013013\n",
      "2019-04-09 22:55:54,047 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.408192\n",
      "Reconstruction: 0.395511, Regularization: 0.012681\n",
      "2019-04-09 22:55:54,103 root         INFO     Train Epoch: 34 [4608/8000 (58%)]\tTotal Loss: 0.426745\n",
      "Reconstruction: 0.413645, Regularization: 0.013100\n",
      "2019-04-09 22:55:54,158 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.509790\n",
      "Reconstruction: 0.478812, Regularization: 0.030978\n",
      "2019-04-09 22:55:54,215 root         INFO     Train Epoch: 34 [5632/8000 (70%)]\tTotal Loss: 0.590506\n",
      "Reconstruction: 0.572117, Regularization: 0.018389\n",
      "2019-04-09 22:55:54,270 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.455180\n",
      "Reconstruction: 0.436725, Regularization: 0.018455\n",
      "2019-04-09 22:55:54,325 root         INFO     Train Epoch: 34 [6656/8000 (83%)]\tTotal Loss: 0.512219\n",
      "Reconstruction: 0.493640, Regularization: 0.018578\n",
      "2019-04-09 22:55:54,380 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 11.477923\n",
      "Reconstruction: 11.456579, Regularization: 0.021345\n",
      "2019-04-09 22:55:54,435 root         INFO     Train Epoch: 34 [7680/8000 (96%)]\tTotal Loss: 0.524878\n",
      "Reconstruction: 0.497538, Regularization: 0.027340\n",
      "2019-04-09 22:55:54,484 root         INFO     ====> Epoch: 34 Average loss: 38.0621\n",
      "2019-04-09 22:55:54,507 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.544116\n",
      "Reconstruction: 0.525275, Regularization: 0.018841\n",
      "2019-04-09 22:55:54,564 root         INFO     Train Epoch: 35 [512/8000 (6%)]\tTotal Loss: 0.419636\n",
      "Reconstruction: 0.402713, Regularization: 0.016923\n",
      "2019-04-09 22:55:54,620 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.412421\n",
      "Reconstruction: 0.398654, Regularization: 0.013766\n",
      "2019-04-09 22:55:54,676 root         INFO     Train Epoch: 35 [1536/8000 (19%)]\tTotal Loss: 0.377139\n",
      "Reconstruction: 0.364784, Regularization: 0.012355\n",
      "2019-04-09 22:55:54,732 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.450326\n",
      "Reconstruction: 0.431823, Regularization: 0.018502\n",
      "2019-04-09 22:55:54,787 root         INFO     Train Epoch: 35 [2560/8000 (32%)]\tTotal Loss: 0.500189\n",
      "Reconstruction: 0.486165, Regularization: 0.014024\n",
      "2019-04-09 22:55:54,843 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.572897\n",
      "Reconstruction: 0.553323, Regularization: 0.019575\n",
      "2019-04-09 22:55:54,899 root         INFO     Train Epoch: 35 [3584/8000 (45%)]\tTotal Loss: 0.491142\n",
      "Reconstruction: 0.468845, Regularization: 0.022297\n",
      "2019-04-09 22:55:54,954 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.454402\n",
      "Reconstruction: 0.437533, Regularization: 0.016869\n",
      "2019-04-09 22:55:55,009 root         INFO     Train Epoch: 35 [4608/8000 (58%)]\tTotal Loss: 0.337028\n",
      "Reconstruction: 0.324357, Regularization: 0.012670\n",
      "2019-04-09 22:55:55,064 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.410922\n",
      "Reconstruction: 0.392332, Regularization: 0.018590\n",
      "2019-04-09 22:55:55,120 root         INFO     Train Epoch: 35 [5632/8000 (70%)]\tTotal Loss: 0.423296\n",
      "Reconstruction: 0.410410, Regularization: 0.012887\n",
      "2019-04-09 22:55:55,175 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.390637\n",
      "Reconstruction: 0.372045, Regularization: 0.018591\n",
      "2019-04-09 22:55:55,230 root         INFO     Train Epoch: 35 [6656/8000 (83%)]\tTotal Loss: 0.488828\n",
      "Reconstruction: 0.469061, Regularization: 0.019767\n",
      "2019-04-09 22:55:55,286 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.517377\n",
      "Reconstruction: 0.500163, Regularization: 0.017214\n",
      "2019-04-09 22:55:55,341 root         INFO     Train Epoch: 35 [7680/8000 (96%)]\tTotal Loss: 0.391093\n",
      "Reconstruction: 0.376874, Regularization: 0.014219\n",
      "2019-04-09 22:55:55,390 root         INFO     ====> Epoch: 35 Average loss: 0.8232\n",
      "2019-04-09 22:55:55,413 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 0.475838\n",
      "Reconstruction: 0.464406, Regularization: 0.011432\n",
      "2019-04-09 22:55:55,470 root         INFO     Train Epoch: 36 [512/8000 (6%)]\tTotal Loss: 0.455089\n",
      "Reconstruction: 0.439553, Regularization: 0.015536\n",
      "2019-04-09 22:55:55,527 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.411108\n",
      "Reconstruction: 0.396574, Regularization: 0.014535\n",
      "2019-04-09 22:55:55,583 root         INFO     Train Epoch: 36 [1536/8000 (19%)]\tTotal Loss: 0.391906\n",
      "Reconstruction: 0.379248, Regularization: 0.012658\n",
      "2019-04-09 22:55:55,638 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.552697\n",
      "Reconstruction: 0.524342, Regularization: 0.028354\n",
      "2019-04-09 22:55:55,694 root         INFO     Train Epoch: 36 [2560/8000 (32%)]\tTotal Loss: 0.409888\n",
      "Reconstruction: 0.389933, Regularization: 0.019955\n",
      "2019-04-09 22:55:55,750 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.337914\n",
      "Reconstruction: 0.324378, Regularization: 0.013536\n",
      "2019-04-09 22:55:55,805 root         INFO     Train Epoch: 36 [3584/8000 (45%)]\tTotal Loss: 0.457326\n",
      "Reconstruction: 0.443460, Regularization: 0.013866\n",
      "2019-04-09 22:55:55,860 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.557799\n",
      "Reconstruction: 0.526609, Regularization: 0.031190\n",
      "2019-04-09 22:55:55,915 root         INFO     Train Epoch: 36 [4608/8000 (58%)]\tTotal Loss: 0.442245\n",
      "Reconstruction: 0.426202, Regularization: 0.016043\n",
      "2019-04-09 22:55:55,969 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.479681\n",
      "Reconstruction: 0.458829, Regularization: 0.020852\n",
      "2019-04-09 22:55:56,024 root         INFO     Train Epoch: 36 [5632/8000 (70%)]\tTotal Loss: 0.450664\n",
      "Reconstruction: 0.432140, Regularization: 0.018524\n",
      "2019-04-09 22:55:56,079 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 0.459978\n",
      "Reconstruction: 0.443286, Regularization: 0.016692\n",
      "2019-04-09 22:55:56,133 root         INFO     Train Epoch: 36 [6656/8000 (83%)]\tTotal Loss: 0.474151\n",
      "Reconstruction: 0.449297, Regularization: 0.024854\n",
      "2019-04-09 22:55:56,188 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.919894\n",
      "Reconstruction: 0.892232, Regularization: 0.027662\n",
      "2019-04-09 22:55:56,242 root         INFO     Train Epoch: 36 [7680/8000 (96%)]\tTotal Loss: 0.495070\n",
      "Reconstruction: 0.477975, Regularization: 0.017095\n",
      "2019-04-09 22:55:56,290 root         INFO     ====> Epoch: 36 Average loss: 9.4023\n",
      "2019-04-09 22:55:56,314 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.559121\n",
      "Reconstruction: 0.542935, Regularization: 0.016186\n",
      "2019-04-09 22:55:56,370 root         INFO     Train Epoch: 37 [512/8000 (6%)]\tTotal Loss: 0.505077\n",
      "Reconstruction: 0.490615, Regularization: 0.014462\n",
      "2019-04-09 22:55:56,426 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.584970\n",
      "Reconstruction: 0.555902, Regularization: 0.029069\n",
      "2019-04-09 22:55:56,481 root         INFO     Train Epoch: 37 [1536/8000 (19%)]\tTotal Loss: 0.418542\n",
      "Reconstruction: 0.393703, Regularization: 0.024839\n",
      "2019-04-09 22:55:56,536 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.497536\n",
      "Reconstruction: 0.477314, Regularization: 0.020222\n",
      "2019-04-09 22:55:56,592 root         INFO     Train Epoch: 37 [2560/8000 (32%)]\tTotal Loss: 0.511822\n",
      "Reconstruction: 0.494797, Regularization: 0.017025\n",
      "2019-04-09 22:55:56,648 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 1.555115\n",
      "Reconstruction: 1.520297, Regularization: 0.034818\n",
      "2019-04-09 22:55:56,704 root         INFO     Train Epoch: 37 [3584/8000 (45%)]\tTotal Loss: 0.514346\n",
      "Reconstruction: 0.494150, Regularization: 0.020196\n",
      "2019-04-09 22:55:56,759 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.396166\n",
      "Reconstruction: 0.380455, Regularization: 0.015711\n",
      "2019-04-09 22:55:56,814 root         INFO     Train Epoch: 37 [4608/8000 (58%)]\tTotal Loss: 0.345577\n",
      "Reconstruction: 0.332764, Regularization: 0.012813\n",
      "2019-04-09 22:55:56,870 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.388906\n",
      "Reconstruction: 0.373521, Regularization: 0.015385\n",
      "2019-04-09 22:55:56,926 root         INFO     Train Epoch: 37 [5632/8000 (70%)]\tTotal Loss: 0.551567\n",
      "Reconstruction: 0.531756, Regularization: 0.019811\n",
      "2019-04-09 22:55:56,983 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.530985\n",
      "Reconstruction: 0.510067, Regularization: 0.020918\n",
      "2019-04-09 22:55:57,040 root         INFO     Train Epoch: 37 [6656/8000 (83%)]\tTotal Loss: 0.399179\n",
      "Reconstruction: 0.386410, Regularization: 0.012768\n",
      "2019-04-09 22:55:57,096 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.483045\n",
      "Reconstruction: 0.457294, Regularization: 0.025751\n",
      "2019-04-09 22:55:57,152 root         INFO     Train Epoch: 37 [7680/8000 (96%)]\tTotal Loss: 0.436110\n",
      "Reconstruction: 0.419808, Regularization: 0.016302\n",
      "2019-04-09 22:55:57,203 root         INFO     ====> Epoch: 37 Average loss: 0.6286\n",
      "2019-04-09 22:55:57,227 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.349317\n",
      "Reconstruction: 0.337554, Regularization: 0.011762\n",
      "2019-04-09 22:55:57,284 root         INFO     Train Epoch: 38 [512/8000 (6%)]\tTotal Loss: 0.417752\n",
      "Reconstruction: 0.404129, Regularization: 0.013623\n",
      "2019-04-09 22:55:57,341 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.518798\n",
      "Reconstruction: 0.500348, Regularization: 0.018450\n",
      "2019-04-09 22:55:57,398 root         INFO     Train Epoch: 38 [1536/8000 (19%)]\tTotal Loss: 0.420755\n",
      "Reconstruction: 0.404945, Regularization: 0.015810\n",
      "2019-04-09 22:55:57,454 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.456311\n",
      "Reconstruction: 0.439687, Regularization: 0.016623\n",
      "2019-04-09 22:55:57,509 root         INFO     Train Epoch: 38 [2560/8000 (32%)]\tTotal Loss: 19.451496\n",
      "Reconstruction: 19.418427, Regularization: 0.033069\n",
      "2019-04-09 22:55:57,565 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 0.530350\n",
      "Reconstruction: 0.510006, Regularization: 0.020344\n",
      "2019-04-09 22:55:57,620 root         INFO     Train Epoch: 38 [3584/8000 (45%)]\tTotal Loss: 0.433047\n",
      "Reconstruction: 0.416311, Regularization: 0.016737\n",
      "2019-04-09 22:55:57,675 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.658361\n",
      "Reconstruction: 0.633940, Regularization: 0.024422\n",
      "2019-04-09 22:55:57,731 root         INFO     Train Epoch: 38 [4608/8000 (58%)]\tTotal Loss: 0.369182\n",
      "Reconstruction: 0.354728, Regularization: 0.014454\n",
      "2019-04-09 22:55:57,786 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.726928\n",
      "Reconstruction: 0.689965, Regularization: 0.036964\n",
      "2019-04-09 22:55:57,842 root         INFO     Train Epoch: 38 [5632/8000 (70%)]\tTotal Loss: 0.440802\n",
      "Reconstruction: 0.423121, Regularization: 0.017681\n",
      "2019-04-09 22:55:57,897 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.549674\n",
      "Reconstruction: 0.530532, Regularization: 0.019141\n",
      "2019-04-09 22:55:57,953 root         INFO     Train Epoch: 38 [6656/8000 (83%)]\tTotal Loss: 0.491958\n",
      "Reconstruction: 0.473083, Regularization: 0.018875\n",
      "2019-04-09 22:55:58,008 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.480723\n",
      "Reconstruction: 0.463308, Regularization: 0.017415\n",
      "2019-04-09 22:55:58,063 root         INFO     Train Epoch: 38 [7680/8000 (96%)]\tTotal Loss: 0.300564\n",
      "Reconstruction: 0.288349, Regularization: 0.012215\n",
      "2019-04-09 22:55:58,112 root         INFO     ====> Epoch: 38 Average loss: 0.7369\n",
      "2019-04-09 22:55:58,135 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 0.531793\n",
      "Reconstruction: 0.513023, Regularization: 0.018770\n",
      "2019-04-09 22:55:58,192 root         INFO     Train Epoch: 39 [512/8000 (6%)]\tTotal Loss: 0.490646\n",
      "Reconstruction: 0.473664, Regularization: 0.016982\n",
      "2019-04-09 22:55:58,248 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.569137\n",
      "Reconstruction: 0.545396, Regularization: 0.023741\n",
      "2019-04-09 22:55:58,303 root         INFO     Train Epoch: 39 [1536/8000 (19%)]\tTotal Loss: 0.371649\n",
      "Reconstruction: 0.353723, Regularization: 0.017926\n",
      "2019-04-09 22:55:58,359 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.426506\n",
      "Reconstruction: 0.411302, Regularization: 0.015204\n",
      "2019-04-09 22:55:58,414 root         INFO     Train Epoch: 39 [2560/8000 (32%)]\tTotal Loss: 0.490400\n",
      "Reconstruction: 0.474482, Regularization: 0.015918\n",
      "2019-04-09 22:55:58,470 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.442519\n",
      "Reconstruction: 0.429202, Regularization: 0.013317\n",
      "2019-04-09 22:55:58,525 root         INFO     Train Epoch: 39 [3584/8000 (45%)]\tTotal Loss: 0.497167\n",
      "Reconstruction: 0.477423, Regularization: 0.019744\n",
      "2019-04-09 22:55:58,580 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.572833\n",
      "Reconstruction: 0.553130, Regularization: 0.019703\n",
      "2019-04-09 22:55:58,636 root         INFO     Train Epoch: 39 [4608/8000 (58%)]\tTotal Loss: 0.476740\n",
      "Reconstruction: 0.458108, Regularization: 0.018631\n",
      "2019-04-09 22:55:58,691 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.439308\n",
      "Reconstruction: 0.419618, Regularization: 0.019690\n",
      "2019-04-09 22:55:58,747 root         INFO     Train Epoch: 39 [5632/8000 (70%)]\tTotal Loss: 0.428007\n",
      "Reconstruction: 0.411943, Regularization: 0.016064\n",
      "2019-04-09 22:55:58,802 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.352548\n",
      "Reconstruction: 0.338619, Regularization: 0.013930\n",
      "2019-04-09 22:55:58,858 root         INFO     Train Epoch: 39 [6656/8000 (83%)]\tTotal Loss: 0.548657\n",
      "Reconstruction: 0.530841, Regularization: 0.017817\n",
      "2019-04-09 22:55:58,913 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.380739\n",
      "Reconstruction: 0.361254, Regularization: 0.019485\n",
      "2019-04-09 22:55:58,969 root         INFO     Train Epoch: 39 [7680/8000 (96%)]\tTotal Loss: 0.461462\n",
      "Reconstruction: 0.446356, Regularization: 0.015106\n",
      "2019-04-09 22:55:59,018 root         INFO     ====> Epoch: 39 Average loss: 1.1388\n",
      "2019-04-09 22:55:59,041 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.417640\n",
      "Reconstruction: 0.401450, Regularization: 0.016191\n",
      "2019-04-09 22:55:59,098 root         INFO     Train Epoch: 40 [512/8000 (6%)]\tTotal Loss: 0.454694\n",
      "Reconstruction: 0.436854, Regularization: 0.017840\n",
      "2019-04-09 22:55:59,154 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.370614\n",
      "Reconstruction: 0.357426, Regularization: 0.013189\n",
      "2019-04-09 22:55:59,210 root         INFO     Train Epoch: 40 [1536/8000 (19%)]\tTotal Loss: 0.411077\n",
      "Reconstruction: 0.389918, Regularization: 0.021159\n",
      "2019-04-09 22:55:59,267 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.490446\n",
      "Reconstruction: 0.469136, Regularization: 0.021310\n",
      "2019-04-09 22:55:59,323 root         INFO     Train Epoch: 40 [2560/8000 (32%)]\tTotal Loss: 0.563100\n",
      "Reconstruction: 0.543598, Regularization: 0.019502\n",
      "2019-04-09 22:55:59,380 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.504499\n",
      "Reconstruction: 0.482445, Regularization: 0.022054\n",
      "2019-04-09 22:55:59,436 root         INFO     Train Epoch: 40 [3584/8000 (45%)]\tTotal Loss: 0.493725\n",
      "Reconstruction: 0.468760, Regularization: 0.024965\n",
      "2019-04-09 22:55:59,493 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.468784\n",
      "Reconstruction: 0.451821, Regularization: 0.016964\n",
      "2019-04-09 22:55:59,550 root         INFO     Train Epoch: 40 [4608/8000 (58%)]\tTotal Loss: 0.537794\n",
      "Reconstruction: 0.522132, Regularization: 0.015662\n",
      "2019-04-09 22:55:59,607 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 1.211886\n",
      "Reconstruction: 1.189563, Regularization: 0.022324\n",
      "2019-04-09 22:55:59,663 root         INFO     Train Epoch: 40 [5632/8000 (70%)]\tTotal Loss: 0.502209\n",
      "Reconstruction: 0.480647, Regularization: 0.021562\n",
      "2019-04-09 22:55:59,720 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.817797\n",
      "Reconstruction: 0.766747, Regularization: 0.051050\n",
      "2019-04-09 22:55:59,776 root         INFO     Train Epoch: 40 [6656/8000 (83%)]\tTotal Loss: 0.519791\n",
      "Reconstruction: 0.499121, Regularization: 0.020670\n",
      "2019-04-09 22:55:59,832 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.500712\n",
      "Reconstruction: 0.474112, Regularization: 0.026600\n",
      "2019-04-09 22:55:59,889 root         INFO     Train Epoch: 40 [7680/8000 (96%)]\tTotal Loss: 0.419558\n",
      "Reconstruction: 0.403837, Regularization: 0.015722\n",
      "2019-04-09 22:55:59,939 root         INFO     ====> Epoch: 40 Average loss: 1.1679\n",
      "2019-04-09 22:55:59,962 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 0.590999\n",
      "Reconstruction: 0.571663, Regularization: 0.019336\n",
      "2019-04-09 22:56:00,019 root         INFO     Train Epoch: 41 [512/8000 (6%)]\tTotal Loss: 0.442883\n",
      "Reconstruction: 0.430778, Regularization: 0.012105\n",
      "2019-04-09 22:56:00,075 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.545449\n",
      "Reconstruction: 0.524859, Regularization: 0.020591\n",
      "2019-04-09 22:56:00,131 root         INFO     Train Epoch: 41 [1536/8000 (19%)]\tTotal Loss: 0.587801\n",
      "Reconstruction: 0.567672, Regularization: 0.020129\n",
      "2019-04-09 22:56:00,187 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 0.389163\n",
      "Reconstruction: 0.372518, Regularization: 0.016646\n",
      "2019-04-09 22:56:00,243 root         INFO     Train Epoch: 41 [2560/8000 (32%)]\tTotal Loss: 0.386138\n",
      "Reconstruction: 0.374039, Regularization: 0.012099\n",
      "2019-04-09 22:56:00,300 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.431953\n",
      "Reconstruction: 0.408596, Regularization: 0.023356\n",
      "2019-04-09 22:56:00,356 root         INFO     Train Epoch: 41 [3584/8000 (45%)]\tTotal Loss: 0.489100\n",
      "Reconstruction: 0.470865, Regularization: 0.018235\n",
      "2019-04-09 22:56:00,413 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.398650\n",
      "Reconstruction: 0.383692, Regularization: 0.014958\n",
      "2019-04-09 22:56:00,469 root         INFO     Train Epoch: 41 [4608/8000 (58%)]\tTotal Loss: 0.378994\n",
      "Reconstruction: 0.363250, Regularization: 0.015745\n",
      "2019-04-09 22:56:00,525 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 0.384929\n",
      "Reconstruction: 0.365969, Regularization: 0.018961\n",
      "2019-04-09 22:56:00,582 root         INFO     Train Epoch: 41 [5632/8000 (70%)]\tTotal Loss: 0.480914\n",
      "Reconstruction: 0.459009, Regularization: 0.021905\n",
      "2019-04-09 22:56:00,638 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.499875\n",
      "Reconstruction: 0.479588, Regularization: 0.020287\n",
      "2019-04-09 22:56:00,694 root         INFO     Train Epoch: 41 [6656/8000 (83%)]\tTotal Loss: 0.449443\n",
      "Reconstruction: 0.432758, Regularization: 0.016685\n",
      "2019-04-09 22:56:00,750 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.595016\n",
      "Reconstruction: 0.572229, Regularization: 0.022787\n",
      "2019-04-09 22:56:00,806 root         INFO     Train Epoch: 41 [7680/8000 (96%)]\tTotal Loss: 0.716581\n",
      "Reconstruction: 0.687811, Regularization: 0.028770\n",
      "2019-04-09 22:56:00,855 root         INFO     ====> Epoch: 41 Average loss: 3.0864\n",
      "2019-04-09 22:56:00,879 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.494862\n",
      "Reconstruction: 0.468116, Regularization: 0.026746\n",
      "2019-04-09 22:56:00,935 root         INFO     Train Epoch: 42 [512/8000 (6%)]\tTotal Loss: 0.428170\n",
      "Reconstruction: 0.393264, Regularization: 0.034906\n",
      "2019-04-09 22:56:00,992 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.437205\n",
      "Reconstruction: 0.421278, Regularization: 0.015927\n",
      "2019-04-09 22:56:01,048 root         INFO     Train Epoch: 42 [1536/8000 (19%)]\tTotal Loss: 0.447022\n",
      "Reconstruction: 0.430430, Regularization: 0.016592\n",
      "2019-04-09 22:56:01,105 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.427784\n",
      "Reconstruction: 0.410879, Regularization: 0.016905\n",
      "2019-04-09 22:56:01,162 root         INFO     Train Epoch: 42 [2560/8000 (32%)]\tTotal Loss: 0.484741\n",
      "Reconstruction: 0.461443, Regularization: 0.023298\n",
      "2019-04-09 22:56:01,219 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 0.363228\n",
      "Reconstruction: 0.347315, Regularization: 0.015913\n",
      "2019-04-09 22:56:01,276 root         INFO     Train Epoch: 42 [3584/8000 (45%)]\tTotal Loss: 0.579946\n",
      "Reconstruction: 0.558937, Regularization: 0.021009\n",
      "2019-04-09 22:56:01,332 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.320087\n",
      "Reconstruction: 0.306890, Regularization: 0.013198\n",
      "2019-04-09 22:56:01,389 root         INFO     Train Epoch: 42 [4608/8000 (58%)]\tTotal Loss: 0.338822\n",
      "Reconstruction: 0.327640, Regularization: 0.011183\n",
      "2019-04-09 22:56:01,446 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.319485\n",
      "Reconstruction: 0.300079, Regularization: 0.019406\n",
      "2019-04-09 22:56:01,501 root         INFO     Train Epoch: 42 [5632/8000 (70%)]\tTotal Loss: 0.545139\n",
      "Reconstruction: 0.522666, Regularization: 0.022473\n",
      "2019-04-09 22:56:01,556 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.361287\n",
      "Reconstruction: 0.348124, Regularization: 0.013162\n",
      "2019-04-09 22:56:01,612 root         INFO     Train Epoch: 42 [6656/8000 (83%)]\tTotal Loss: 0.342101\n",
      "Reconstruction: 0.327654, Regularization: 0.014447\n",
      "2019-04-09 22:56:01,667 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.517002\n",
      "Reconstruction: 0.498794, Regularization: 0.018208\n",
      "2019-04-09 22:56:01,722 root         INFO     Train Epoch: 42 [7680/8000 (96%)]\tTotal Loss: 0.577450\n",
      "Reconstruction: 0.559592, Regularization: 0.017857\n",
      "2019-04-09 22:56:01,772 root         INFO     ====> Epoch: 42 Average loss: 283.7514\n",
      "2019-04-09 22:56:01,796 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.432312\n",
      "Reconstruction: 0.414552, Regularization: 0.017760\n",
      "2019-04-09 22:56:01,853 root         INFO     Train Epoch: 43 [512/8000 (6%)]\tTotal Loss: 0.481714\n",
      "Reconstruction: 0.464929, Regularization: 0.016784\n",
      "2019-04-09 22:56:01,911 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.508171\n",
      "Reconstruction: 0.484832, Regularization: 0.023339\n",
      "2019-04-09 22:56:01,969 root         INFO     Train Epoch: 43 [1536/8000 (19%)]\tTotal Loss: 0.505835\n",
      "Reconstruction: 0.480818, Regularization: 0.025017\n",
      "2019-04-09 22:56:02,027 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.407539\n",
      "Reconstruction: 0.382655, Regularization: 0.024883\n",
      "2019-04-09 22:56:02,085 root         INFO     Train Epoch: 43 [2560/8000 (32%)]\tTotal Loss: 0.328137\n",
      "Reconstruction: 0.317145, Regularization: 0.010993\n",
      "2019-04-09 22:56:02,142 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.475570\n",
      "Reconstruction: 0.453902, Regularization: 0.021667\n",
      "2019-04-09 22:56:02,199 root         INFO     Train Epoch: 43 [3584/8000 (45%)]\tTotal Loss: 0.503112\n",
      "Reconstruction: 0.481927, Regularization: 0.021186\n",
      "2019-04-09 22:56:02,257 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.427295\n",
      "Reconstruction: 0.406805, Regularization: 0.020491\n",
      "2019-04-09 22:56:02,315 root         INFO     Train Epoch: 43 [4608/8000 (58%)]\tTotal Loss: 0.381127\n",
      "Reconstruction: 0.366719, Regularization: 0.014408\n",
      "2019-04-09 22:56:02,373 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.414781\n",
      "Reconstruction: 0.401750, Regularization: 0.013032\n",
      "2019-04-09 22:56:02,430 root         INFO     Train Epoch: 43 [5632/8000 (70%)]\tTotal Loss: 0.482575\n",
      "Reconstruction: 0.467460, Regularization: 0.015115\n",
      "2019-04-09 22:56:02,488 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.545158\n",
      "Reconstruction: 0.525394, Regularization: 0.019764\n",
      "2019-04-09 22:56:02,545 root         INFO     Train Epoch: 43 [6656/8000 (83%)]\tTotal Loss: 3.194123\n",
      "Reconstruction: 3.164951, Regularization: 0.029172\n",
      "2019-04-09 22:56:02,603 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.585853\n",
      "Reconstruction: 0.559469, Regularization: 0.026383\n",
      "2019-04-09 22:56:02,661 root         INFO     Train Epoch: 43 [7680/8000 (96%)]\tTotal Loss: 0.500669\n",
      "Reconstruction: 0.485823, Regularization: 0.014845\n",
      "2019-04-09 22:56:02,711 root         INFO     ====> Epoch: 43 Average loss: 176.9515\n",
      "2019-04-09 22:56:02,735 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.484037\n",
      "Reconstruction: 0.464337, Regularization: 0.019700\n",
      "2019-04-09 22:56:02,792 root         INFO     Train Epoch: 44 [512/8000 (6%)]\tTotal Loss: 0.446930\n",
      "Reconstruction: 0.420918, Regularization: 0.026013\n",
      "2019-04-09 22:56:02,849 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.415838\n",
      "Reconstruction: 0.392232, Regularization: 0.023605\n",
      "2019-04-09 22:56:02,906 root         INFO     Train Epoch: 44 [1536/8000 (19%)]\tTotal Loss: 0.369648\n",
      "Reconstruction: 0.356676, Regularization: 0.012972\n",
      "2019-04-09 22:56:02,964 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.611393\n",
      "Reconstruction: 0.595357, Regularization: 0.016036\n",
      "2019-04-09 22:56:03,019 root         INFO     Train Epoch: 44 [2560/8000 (32%)]\tTotal Loss: 0.330181\n",
      "Reconstruction: 0.318425, Regularization: 0.011755\n",
      "2019-04-09 22:56:03,075 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.585624\n",
      "Reconstruction: 0.570162, Regularization: 0.015462\n",
      "2019-04-09 22:56:03,131 root         INFO     Train Epoch: 44 [3584/8000 (45%)]\tTotal Loss: 0.446522\n",
      "Reconstruction: 0.429321, Regularization: 0.017201\n",
      "2019-04-09 22:56:03,187 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.447147\n",
      "Reconstruction: 0.429458, Regularization: 0.017688\n",
      "2019-04-09 22:56:03,242 root         INFO     Train Epoch: 44 [4608/8000 (58%)]\tTotal Loss: 0.537050\n",
      "Reconstruction: 0.512019, Regularization: 0.025032\n",
      "2019-04-09 22:56:03,298 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.466140\n",
      "Reconstruction: 0.450835, Regularization: 0.015305\n",
      "2019-04-09 22:56:03,354 root         INFO     Train Epoch: 44 [5632/8000 (70%)]\tTotal Loss: 0.400067\n",
      "Reconstruction: 0.385011, Regularization: 0.015055\n",
      "2019-04-09 22:56:03,410 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.475844\n",
      "Reconstruction: 0.462004, Regularization: 0.013840\n",
      "2019-04-09 22:56:03,465 root         INFO     Train Epoch: 44 [6656/8000 (83%)]\tTotal Loss: 0.381832\n",
      "Reconstruction: 0.367960, Regularization: 0.013872\n",
      "2019-04-09 22:56:03,520 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.511726\n",
      "Reconstruction: 0.493742, Regularization: 0.017984\n",
      "2019-04-09 22:56:03,576 root         INFO     Train Epoch: 44 [7680/8000 (96%)]\tTotal Loss: 0.576583\n",
      "Reconstruction: 0.556267, Regularization: 0.020316\n",
      "2019-04-09 22:56:03,626 root         INFO     ====> Epoch: 44 Average loss: 0.5371\n",
      "2019-04-09 22:56:03,649 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.457055\n",
      "Reconstruction: 0.443274, Regularization: 0.013781\n",
      "2019-04-09 22:56:03,706 root         INFO     Train Epoch: 45 [512/8000 (6%)]\tTotal Loss: 0.533055\n",
      "Reconstruction: 0.516837, Regularization: 0.016218\n",
      "2019-04-09 22:56:03,763 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 0.489081\n",
      "Reconstruction: 0.468706, Regularization: 0.020376\n",
      "2019-04-09 22:56:03,820 root         INFO     Train Epoch: 45 [1536/8000 (19%)]\tTotal Loss: 0.640606\n",
      "Reconstruction: 0.624144, Regularization: 0.016462\n",
      "2019-04-09 22:56:03,876 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.414928\n",
      "Reconstruction: 0.394026, Regularization: 0.020902\n",
      "2019-04-09 22:56:03,933 root         INFO     Train Epoch: 45 [2560/8000 (32%)]\tTotal Loss: 0.485616\n",
      "Reconstruction: 0.467734, Regularization: 0.017882\n",
      "2019-04-09 22:56:03,990 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.499769\n",
      "Reconstruction: 0.480756, Regularization: 0.019013\n",
      "2019-04-09 22:56:04,046 root         INFO     Train Epoch: 45 [3584/8000 (45%)]\tTotal Loss: 0.366230\n",
      "Reconstruction: 0.352864, Regularization: 0.013367\n",
      "2019-04-09 22:56:04,103 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.597054\n",
      "Reconstruction: 0.583641, Regularization: 0.013413\n",
      "2019-04-09 22:56:04,159 root         INFO     Train Epoch: 45 [4608/8000 (58%)]\tTotal Loss: 0.488854\n",
      "Reconstruction: 0.472679, Regularization: 0.016174\n",
      "2019-04-09 22:56:04,217 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.507836\n",
      "Reconstruction: 0.488883, Regularization: 0.018953\n",
      "2019-04-09 22:56:04,274 root         INFO     Train Epoch: 45 [5632/8000 (70%)]\tTotal Loss: 0.521552\n",
      "Reconstruction: 0.488321, Regularization: 0.033231\n",
      "2019-04-09 22:56:04,331 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.438340\n",
      "Reconstruction: 0.418611, Regularization: 0.019729\n",
      "2019-04-09 22:56:04,387 root         INFO     Train Epoch: 45 [6656/8000 (83%)]\tTotal Loss: 0.377596\n",
      "Reconstruction: 0.361362, Regularization: 0.016235\n",
      "2019-04-09 22:56:04,444 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.521222\n",
      "Reconstruction: 0.501096, Regularization: 0.020126\n",
      "2019-04-09 22:56:04,498 root         INFO     Train Epoch: 45 [7680/8000 (96%)]\tTotal Loss: 0.491232\n",
      "Reconstruction: 0.467997, Regularization: 0.023234\n",
      "2019-04-09 22:56:04,548 root         INFO     ====> Epoch: 45 Average loss: 0.8785\n",
      "2019-04-09 22:56:04,571 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.430861\n",
      "Reconstruction: 0.412826, Regularization: 0.018035\n",
      "2019-04-09 22:56:04,626 root         INFO     Train Epoch: 46 [512/8000 (6%)]\tTotal Loss: 0.541781\n",
      "Reconstruction: 0.520013, Regularization: 0.021768\n",
      "2019-04-09 22:56:04,681 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.458264\n",
      "Reconstruction: 0.443074, Regularization: 0.015191\n",
      "2019-04-09 22:56:04,737 root         INFO     Train Epoch: 46 [1536/8000 (19%)]\tTotal Loss: 0.477268\n",
      "Reconstruction: 0.457763, Regularization: 0.019506\n",
      "2019-04-09 22:56:04,792 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.370907\n",
      "Reconstruction: 0.355889, Regularization: 0.015017\n",
      "2019-04-09 22:56:04,846 root         INFO     Train Epoch: 46 [2560/8000 (32%)]\tTotal Loss: 0.494612\n",
      "Reconstruction: 0.476056, Regularization: 0.018556\n",
      "2019-04-09 22:56:04,902 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.526254\n",
      "Reconstruction: 0.505093, Regularization: 0.021161\n",
      "2019-04-09 22:56:04,958 root         INFO     Train Epoch: 46 [3584/8000 (45%)]\tTotal Loss: 0.440572\n",
      "Reconstruction: 0.426203, Regularization: 0.014369\n",
      "2019-04-09 22:56:05,014 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.627538\n",
      "Reconstruction: 0.603307, Regularization: 0.024232\n",
      "2019-04-09 22:56:05,070 root         INFO     Train Epoch: 46 [4608/8000 (58%)]\tTotal Loss: 0.357872\n",
      "Reconstruction: 0.344182, Regularization: 0.013690\n",
      "2019-04-09 22:56:05,125 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 2.798442\n",
      "Reconstruction: 2.784038, Regularization: 0.014404\n",
      "2019-04-09 22:56:05,180 root         INFO     Train Epoch: 46 [5632/8000 (70%)]\tTotal Loss: 0.538918\n",
      "Reconstruction: 0.516764, Regularization: 0.022154\n",
      "2019-04-09 22:56:05,235 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.446233\n",
      "Reconstruction: 0.433566, Regularization: 0.012667\n",
      "2019-04-09 22:56:05,290 root         INFO     Train Epoch: 46 [6656/8000 (83%)]\tTotal Loss: 0.327779\n",
      "Reconstruction: 0.313961, Regularization: 0.013818\n",
      "2019-04-09 22:56:05,345 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.566492\n",
      "Reconstruction: 0.546594, Regularization: 0.019898\n",
      "2019-04-09 22:56:05,400 root         INFO     Train Epoch: 46 [7680/8000 (96%)]\tTotal Loss: 0.469629\n",
      "Reconstruction: 0.451498, Regularization: 0.018131\n",
      "2019-04-09 22:56:05,448 root         INFO     ====> Epoch: 46 Average loss: 1.0051\n",
      "2019-04-09 22:56:05,472 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.484496\n",
      "Reconstruction: 0.462556, Regularization: 0.021941\n",
      "2019-04-09 22:56:05,527 root         INFO     Train Epoch: 47 [512/8000 (6%)]\tTotal Loss: 0.456598\n",
      "Reconstruction: 0.432942, Regularization: 0.023656\n",
      "2019-04-09 22:56:05,581 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.413003\n",
      "Reconstruction: 0.395852, Regularization: 0.017151\n",
      "2019-04-09 22:56:05,636 root         INFO     Train Epoch: 47 [1536/8000 (19%)]\tTotal Loss: 0.588553\n",
      "Reconstruction: 0.571056, Regularization: 0.017498\n",
      "2019-04-09 22:56:05,691 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.467243\n",
      "Reconstruction: 0.450000, Regularization: 0.017243\n",
      "2019-04-09 22:56:05,746 root         INFO     Train Epoch: 47 [2560/8000 (32%)]\tTotal Loss: 0.924676\n",
      "Reconstruction: 0.905976, Regularization: 0.018700\n",
      "2019-04-09 22:56:05,800 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.402226\n",
      "Reconstruction: 0.386431, Regularization: 0.015795\n",
      "2019-04-09 22:56:05,855 root         INFO     Train Epoch: 47 [3584/8000 (45%)]\tTotal Loss: 0.418391\n",
      "Reconstruction: 0.400424, Regularization: 0.017967\n",
      "2019-04-09 22:56:05,910 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.537194\n",
      "Reconstruction: 0.513616, Regularization: 0.023578\n",
      "2019-04-09 22:56:05,966 root         INFO     Train Epoch: 47 [4608/8000 (58%)]\tTotal Loss: 0.422031\n",
      "Reconstruction: 0.407877, Regularization: 0.014154\n",
      "2019-04-09 22:56:06,021 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.469010\n",
      "Reconstruction: 0.453488, Regularization: 0.015522\n",
      "2019-04-09 22:56:06,077 root         INFO     Train Epoch: 47 [5632/8000 (70%)]\tTotal Loss: 0.371641\n",
      "Reconstruction: 0.357044, Regularization: 0.014598\n",
      "2019-04-09 22:56:06,133 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.510190\n",
      "Reconstruction: 0.489052, Regularization: 0.021138\n",
      "2019-04-09 22:56:06,190 root         INFO     Train Epoch: 47 [6656/8000 (83%)]\tTotal Loss: 0.715491\n",
      "Reconstruction: 0.689852, Regularization: 0.025639\n",
      "2019-04-09 22:56:06,246 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.626165\n",
      "Reconstruction: 0.606184, Regularization: 0.019980\n",
      "2019-04-09 22:56:06,301 root         INFO     Train Epoch: 47 [7680/8000 (96%)]\tTotal Loss: 0.484432\n",
      "Reconstruction: 0.465922, Regularization: 0.018510\n",
      "2019-04-09 22:56:06,350 root         INFO     ====> Epoch: 47 Average loss: 1.6239\n",
      "2019-04-09 22:56:06,373 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.490426\n",
      "Reconstruction: 0.469600, Regularization: 0.020826\n",
      "2019-04-09 22:56:06,430 root         INFO     Train Epoch: 48 [512/8000 (6%)]\tTotal Loss: 0.431751\n",
      "Reconstruction: 0.416977, Regularization: 0.014774\n",
      "2019-04-09 22:56:06,487 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.419068\n",
      "Reconstruction: 0.398104, Regularization: 0.020964\n",
      "2019-04-09 22:56:06,544 root         INFO     Train Epoch: 48 [1536/8000 (19%)]\tTotal Loss: 0.564560\n",
      "Reconstruction: 0.540181, Regularization: 0.024378\n",
      "2019-04-09 22:56:06,601 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.356454\n",
      "Reconstruction: 0.337462, Regularization: 0.018992\n",
      "2019-04-09 22:56:06,657 root         INFO     Train Epoch: 48 [2560/8000 (32%)]\tTotal Loss: 0.457895\n",
      "Reconstruction: 0.441595, Regularization: 0.016301\n",
      "2019-04-09 22:56:06,714 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.441143\n",
      "Reconstruction: 0.425511, Regularization: 0.015632\n",
      "2019-04-09 22:56:06,770 root         INFO     Train Epoch: 48 [3584/8000 (45%)]\tTotal Loss: 0.448384\n",
      "Reconstruction: 0.428608, Regularization: 0.019776\n",
      "2019-04-09 22:56:06,827 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 3.227014\n",
      "Reconstruction: 3.187629, Regularization: 0.039385\n",
      "2019-04-09 22:56:06,884 root         INFO     Train Epoch: 48 [4608/8000 (58%)]\tTotal Loss: 0.463833\n",
      "Reconstruction: 0.449971, Regularization: 0.013862\n",
      "2019-04-09 22:56:06,940 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.496396\n",
      "Reconstruction: 0.467521, Regularization: 0.028876\n",
      "2019-04-09 22:56:06,997 root         INFO     Train Epoch: 48 [5632/8000 (70%)]\tTotal Loss: 0.408079\n",
      "Reconstruction: 0.392749, Regularization: 0.015330\n",
      "2019-04-09 22:56:07,053 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.389466\n",
      "Reconstruction: 0.370374, Regularization: 0.019091\n",
      "2019-04-09 22:56:07,109 root         INFO     Train Epoch: 48 [6656/8000 (83%)]\tTotal Loss: 0.482895\n",
      "Reconstruction: 0.464633, Regularization: 0.018262\n",
      "2019-04-09 22:56:07,164 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.393259\n",
      "Reconstruction: 0.381753, Regularization: 0.011506\n",
      "2019-04-09 22:56:07,220 root         INFO     Train Epoch: 48 [7680/8000 (96%)]\tTotal Loss: 0.445988\n",
      "Reconstruction: 0.427675, Regularization: 0.018312\n",
      "2019-04-09 22:56:07,269 root         INFO     ====> Epoch: 48 Average loss: 0.4909\n",
      "2019-04-09 22:56:07,292 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.493323\n",
      "Reconstruction: 0.478626, Regularization: 0.014697\n",
      "2019-04-09 22:56:07,349 root         INFO     Train Epoch: 49 [512/8000 (6%)]\tTotal Loss: 0.359064\n",
      "Reconstruction: 0.340449, Regularization: 0.018615\n",
      "2019-04-09 22:56:07,406 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.443998\n",
      "Reconstruction: 0.420304, Regularization: 0.023693\n",
      "2019-04-09 22:56:07,463 root         INFO     Train Epoch: 49 [1536/8000 (19%)]\tTotal Loss: 0.759999\n",
      "Reconstruction: 0.734854, Regularization: 0.025145\n",
      "2019-04-09 22:56:07,520 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.495918\n",
      "Reconstruction: 0.469210, Regularization: 0.026708\n",
      "2019-04-09 22:56:07,576 root         INFO     Train Epoch: 49 [2560/8000 (32%)]\tTotal Loss: 0.374463\n",
      "Reconstruction: 0.360008, Regularization: 0.014455\n",
      "2019-04-09 22:56:07,633 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.439287\n",
      "Reconstruction: 0.419844, Regularization: 0.019443\n",
      "2019-04-09 22:56:07,689 root         INFO     Train Epoch: 49 [3584/8000 (45%)]\tTotal Loss: 0.470691\n",
      "Reconstruction: 0.450104, Regularization: 0.020587\n",
      "2019-04-09 22:56:07,746 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 1.038878\n",
      "Reconstruction: 1.009116, Regularization: 0.029762\n",
      "2019-04-09 22:56:07,801 root         INFO     Train Epoch: 49 [4608/8000 (58%)]\tTotal Loss: 0.352619\n",
      "Reconstruction: 0.337239, Regularization: 0.015379\n",
      "2019-04-09 22:56:07,857 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.355628\n",
      "Reconstruction: 0.345724, Regularization: 0.009904\n",
      "2019-04-09 22:56:07,911 root         INFO     Train Epoch: 49 [5632/8000 (70%)]\tTotal Loss: 0.545874\n",
      "Reconstruction: 0.523554, Regularization: 0.022320\n",
      "2019-04-09 22:56:07,966 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.516323\n",
      "Reconstruction: 0.495110, Regularization: 0.021213\n",
      "2019-04-09 22:56:08,022 root         INFO     Train Epoch: 49 [6656/8000 (83%)]\tTotal Loss: 0.335851\n",
      "Reconstruction: 0.324366, Regularization: 0.011484\n",
      "2019-04-09 22:56:08,077 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.523288\n",
      "Reconstruction: 0.503451, Regularization: 0.019837\n",
      "2019-04-09 22:56:08,132 root         INFO     Train Epoch: 49 [7680/8000 (96%)]\tTotal Loss: 0.456602\n",
      "Reconstruction: 0.437746, Regularization: 0.018856\n",
      "2019-04-09 22:56:08,181 root         INFO     ====> Epoch: 49 Average loss: 0.5946\n",
      "2019-04-09 22:56:08,205 root         INFO     Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 0.311683\n",
      "Reconstruction: 0.299266, Regularization: 0.012417\n",
      "2019-04-09 22:56:08,261 root         INFO     Train Epoch: 50 [512/8000 (6%)]\tTotal Loss: 0.463033\n",
      "Reconstruction: 0.446112, Regularization: 0.016920\n",
      "2019-04-09 22:56:08,317 root         INFO     Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 0.592865\n",
      "Reconstruction: 0.569473, Regularization: 0.023392\n",
      "2019-04-09 22:56:08,373 root         INFO     Train Epoch: 50 [1536/8000 (19%)]\tTotal Loss: 0.411585\n",
      "Reconstruction: 0.392320, Regularization: 0.019264\n",
      "2019-04-09 22:56:08,428 root         INFO     Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 0.418672\n",
      "Reconstruction: 0.402450, Regularization: 0.016222\n",
      "2019-04-09 22:56:08,485 root         INFO     Train Epoch: 50 [2560/8000 (32%)]\tTotal Loss: 7.985518\n",
      "Reconstruction: 7.960707, Regularization: 0.024811\n",
      "2019-04-09 22:56:08,540 root         INFO     Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 0.527785\n",
      "Reconstruction: 0.507328, Regularization: 0.020458\n",
      "2019-04-09 22:56:08,597 root         INFO     Train Epoch: 50 [3584/8000 (45%)]\tTotal Loss: 0.406372\n",
      "Reconstruction: 0.373800, Regularization: 0.032572\n",
      "2019-04-09 22:56:08,653 root         INFO     Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 0.581374\n",
      "Reconstruction: 0.560587, Regularization: 0.020787\n",
      "2019-04-09 22:56:08,708 root         INFO     Train Epoch: 50 [4608/8000 (58%)]\tTotal Loss: 0.461734\n",
      "Reconstruction: 0.442365, Regularization: 0.019370\n",
      "2019-04-09 22:56:08,764 root         INFO     Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 0.400949\n",
      "Reconstruction: 0.373873, Regularization: 0.027076\n",
      "2019-04-09 22:56:08,820 root         INFO     Train Epoch: 50 [5632/8000 (70%)]\tTotal Loss: 0.432701\n",
      "Reconstruction: 0.399745, Regularization: 0.032956\n",
      "2019-04-09 22:56:08,876 root         INFO     Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 1.085922\n",
      "Reconstruction: 1.056946, Regularization: 0.028976\n",
      "2019-04-09 22:56:08,932 root         INFO     Train Epoch: 50 [6656/8000 (83%)]\tTotal Loss: 0.401569\n",
      "Reconstruction: 0.388255, Regularization: 0.013314\n",
      "2019-04-09 22:56:08,987 root         INFO     Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 0.435745\n",
      "Reconstruction: 0.418622, Regularization: 0.017122\n",
      "2019-04-09 22:56:09,043 root         INFO     Train Epoch: 50 [7680/8000 (96%)]\tTotal Loss: 0.409795\n",
      "Reconstruction: 0.391104, Regularization: 0.018691\n",
      "2019-04-09 22:56:09,092 root         INFO     ====> Epoch: 50 Average loss: 0.8314\n",
      "2019-04-09 22:56:09,116 root         INFO     Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 0.419045\n",
      "Reconstruction: 0.404396, Regularization: 0.014649\n",
      "2019-04-09 22:56:09,172 root         INFO     Train Epoch: 51 [512/8000 (6%)]\tTotal Loss: 0.415911\n",
      "Reconstruction: 0.400969, Regularization: 0.014942\n",
      "2019-04-09 22:56:09,228 root         INFO     Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 0.459354\n",
      "Reconstruction: 0.435350, Regularization: 0.024004\n",
      "2019-04-09 22:56:09,283 root         INFO     Train Epoch: 51 [1536/8000 (19%)]\tTotal Loss: 0.453943\n",
      "Reconstruction: 0.433392, Regularization: 0.020551\n",
      "2019-04-09 22:56:09,339 root         INFO     Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 0.430363\n",
      "Reconstruction: 0.414953, Regularization: 0.015410\n",
      "2019-04-09 22:56:09,395 root         INFO     Train Epoch: 51 [2560/8000 (32%)]\tTotal Loss: 0.428417\n",
      "Reconstruction: 0.409911, Regularization: 0.018506\n",
      "2019-04-09 22:56:09,450 root         INFO     Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 2.289455\n",
      "Reconstruction: 2.266459, Regularization: 0.022996\n",
      "2019-04-09 22:56:09,506 root         INFO     Train Epoch: 51 [3584/8000 (45%)]\tTotal Loss: 0.355131\n",
      "Reconstruction: 0.340136, Regularization: 0.014996\n",
      "2019-04-09 22:56:09,562 root         INFO     Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 0.539544\n",
      "Reconstruction: 0.518476, Regularization: 0.021068\n",
      "2019-04-09 22:56:09,617 root         INFO     Train Epoch: 51 [4608/8000 (58%)]\tTotal Loss: 0.489127\n",
      "Reconstruction: 0.465656, Regularization: 0.023472\n",
      "2019-04-09 22:56:09,673 root         INFO     Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 0.396888\n",
      "Reconstruction: 0.370052, Regularization: 0.026836\n",
      "2019-04-09 22:56:09,729 root         INFO     Train Epoch: 51 [5632/8000 (70%)]\tTotal Loss: 0.492257\n",
      "Reconstruction: 0.475561, Regularization: 0.016696\n",
      "2019-04-09 22:56:09,785 root         INFO     Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 0.568776\n",
      "Reconstruction: 0.549716, Regularization: 0.019060\n",
      "2019-04-09 22:56:09,841 root         INFO     Train Epoch: 51 [6656/8000 (83%)]\tTotal Loss: 0.462079\n",
      "Reconstruction: 0.443315, Regularization: 0.018764\n",
      "2019-04-09 22:56:09,897 root         INFO     Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 0.410500\n",
      "Reconstruction: 0.369153, Regularization: 0.041347\n",
      "2019-04-09 22:56:09,952 root         INFO     Train Epoch: 51 [7680/8000 (96%)]\tTotal Loss: 2.399439\n",
      "Reconstruction: 2.375071, Regularization: 0.024368\n",
      "2019-04-09 22:56:10,001 root         INFO     ====> Epoch: 51 Average loss: 0.9126\n",
      "2019-04-09 22:56:10,024 root         INFO     Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 0.475215\n",
      "Reconstruction: 0.452421, Regularization: 0.022794\n",
      "2019-04-09 22:56:10,079 root         INFO     Train Epoch: 52 [512/8000 (6%)]\tTotal Loss: 0.544407\n",
      "Reconstruction: 0.527169, Regularization: 0.017238\n",
      "2019-04-09 22:56:10,134 root         INFO     Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 0.497780\n",
      "Reconstruction: 0.480177, Regularization: 0.017603\n",
      "2019-04-09 22:56:10,189 root         INFO     Train Epoch: 52 [1536/8000 (19%)]\tTotal Loss: 0.479268\n",
      "Reconstruction: 0.455227, Regularization: 0.024040\n",
      "2019-04-09 22:56:10,244 root         INFO     Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 0.462597\n",
      "Reconstruction: 0.444975, Regularization: 0.017623\n",
      "2019-04-09 22:56:10,298 root         INFO     Train Epoch: 52 [2560/8000 (32%)]\tTotal Loss: 0.393367\n",
      "Reconstruction: 0.378291, Regularization: 0.015076\n",
      "2019-04-09 22:56:10,353 root         INFO     Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 0.576393\n",
      "Reconstruction: 0.553308, Regularization: 0.023085\n",
      "2019-04-09 22:56:10,408 root         INFO     Train Epoch: 52 [3584/8000 (45%)]\tTotal Loss: 0.501008\n",
      "Reconstruction: 0.476279, Regularization: 0.024729\n",
      "2019-04-09 22:56:10,463 root         INFO     Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 0.349151\n",
      "Reconstruction: 0.333997, Regularization: 0.015153\n",
      "2019-04-09 22:56:10,518 root         INFO     Train Epoch: 52 [4608/8000 (58%)]\tTotal Loss: 0.418425\n",
      "Reconstruction: 0.403184, Regularization: 0.015241\n",
      "2019-04-09 22:56:10,572 root         INFO     Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 0.477103\n",
      "Reconstruction: 0.458926, Regularization: 0.018177\n",
      "2019-04-09 22:56:10,627 root         INFO     Train Epoch: 52 [5632/8000 (70%)]\tTotal Loss: 0.429989\n",
      "Reconstruction: 0.414149, Regularization: 0.015839\n",
      "2019-04-09 22:56:10,682 root         INFO     Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 0.393242\n",
      "Reconstruction: 0.374214, Regularization: 0.019028\n",
      "2019-04-09 22:56:10,737 root         INFO     Train Epoch: 52 [6656/8000 (83%)]\tTotal Loss: 0.452309\n",
      "Reconstruction: 0.433729, Regularization: 0.018580\n",
      "2019-04-09 22:56:10,791 root         INFO     Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 0.666840\n",
      "Reconstruction: 0.644583, Regularization: 0.022258\n",
      "2019-04-09 22:56:10,846 root         INFO     Train Epoch: 52 [7680/8000 (96%)]\tTotal Loss: 0.488177\n",
      "Reconstruction: 0.470003, Regularization: 0.018175\n",
      "2019-04-09 22:56:10,896 root         INFO     ====> Epoch: 52 Average loss: 0.5032\n",
      "2019-04-09 22:56:10,919 root         INFO     Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 0.435581\n",
      "Reconstruction: 0.417809, Regularization: 0.017772\n",
      "2019-04-09 22:56:10,976 root         INFO     Train Epoch: 53 [512/8000 (6%)]\tTotal Loss: 0.524441\n",
      "Reconstruction: 0.505578, Regularization: 0.018863\n",
      "2019-04-09 22:56:11,031 root         INFO     Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 0.560027\n",
      "Reconstruction: 0.543379, Regularization: 0.016649\n",
      "2019-04-09 22:56:11,087 root         INFO     Train Epoch: 53 [1536/8000 (19%)]\tTotal Loss: 0.510612\n",
      "Reconstruction: 0.490124, Regularization: 0.020488\n",
      "2019-04-09 22:56:11,143 root         INFO     Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 0.490000\n",
      "Reconstruction: 0.467198, Regularization: 0.022802\n",
      "2019-04-09 22:56:11,200 root         INFO     Train Epoch: 53 [2560/8000 (32%)]\tTotal Loss: 0.359716\n",
      "Reconstruction: 0.342932, Regularization: 0.016784\n",
      "2019-04-09 22:56:11,256 root         INFO     Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 0.504453\n",
      "Reconstruction: 0.481756, Regularization: 0.022697\n",
      "2019-04-09 22:56:11,311 root         INFO     Train Epoch: 53 [3584/8000 (45%)]\tTotal Loss: 0.368180\n",
      "Reconstruction: 0.357421, Regularization: 0.010760\n",
      "2019-04-09 22:56:11,367 root         INFO     Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 0.434945\n",
      "Reconstruction: 0.419336, Regularization: 0.015609\n",
      "2019-04-09 22:56:11,423 root         INFO     Train Epoch: 53 [4608/8000 (58%)]\tTotal Loss: 0.440774\n",
      "Reconstruction: 0.419904, Regularization: 0.020870\n",
      "2019-04-09 22:56:11,479 root         INFO     Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 0.427344\n",
      "Reconstruction: 0.404159, Regularization: 0.023185\n",
      "2019-04-09 22:56:11,535 root         INFO     Train Epoch: 53 [5632/8000 (70%)]\tTotal Loss: 0.376109\n",
      "Reconstruction: 0.362377, Regularization: 0.013732\n",
      "2019-04-09 22:56:11,591 root         INFO     Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 0.425926\n",
      "Reconstruction: 0.409237, Regularization: 0.016689\n",
      "2019-04-09 22:56:11,646 root         INFO     Train Epoch: 53 [6656/8000 (83%)]\tTotal Loss: 0.355369\n",
      "Reconstruction: 0.338946, Regularization: 0.016424\n",
      "2019-04-09 22:56:11,702 root         INFO     Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 0.391968\n",
      "Reconstruction: 0.376023, Regularization: 0.015945\n",
      "2019-04-09 22:56:11,758 root         INFO     Train Epoch: 53 [7680/8000 (96%)]\tTotal Loss: 214.401566\n",
      "Reconstruction: 214.370712, Regularization: 0.030859\n",
      "2019-04-09 22:56:11,807 root         INFO     ====> Epoch: 53 Average loss: 1.3551\n",
      "2019-04-09 22:56:11,831 root         INFO     Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 0.612189\n",
      "Reconstruction: 0.580380, Regularization: 0.031809\n",
      "2019-04-09 22:56:11,886 root         INFO     Train Epoch: 54 [512/8000 (6%)]\tTotal Loss: 0.345885\n",
      "Reconstruction: 0.332949, Regularization: 0.012936\n",
      "2019-04-09 22:56:11,941 root         INFO     Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 0.409986\n",
      "Reconstruction: 0.393670, Regularization: 0.016316\n",
      "2019-04-09 22:56:11,997 root         INFO     Train Epoch: 54 [1536/8000 (19%)]\tTotal Loss: 0.434465\n",
      "Reconstruction: 0.418298, Regularization: 0.016166\n",
      "2019-04-09 22:56:12,052 root         INFO     Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 0.422879\n",
      "Reconstruction: 0.404846, Regularization: 0.018033\n",
      "2019-04-09 22:56:12,107 root         INFO     Train Epoch: 54 [2560/8000 (32%)]\tTotal Loss: 0.375128\n",
      "Reconstruction: 0.359671, Regularization: 0.015457\n",
      "2019-04-09 22:56:12,162 root         INFO     Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 0.459220\n",
      "Reconstruction: 0.440087, Regularization: 0.019133\n",
      "2019-04-09 22:56:12,218 root         INFO     Train Epoch: 54 [3584/8000 (45%)]\tTotal Loss: 0.397643\n",
      "Reconstruction: 0.384321, Regularization: 0.013322\n",
      "2019-04-09 22:56:12,273 root         INFO     Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 0.374596\n",
      "Reconstruction: 0.357761, Regularization: 0.016835\n",
      "2019-04-09 22:56:12,329 root         INFO     Train Epoch: 54 [4608/8000 (58%)]\tTotal Loss: 0.400371\n",
      "Reconstruction: 0.384725, Regularization: 0.015645\n",
      "2019-04-09 22:56:12,385 root         INFO     Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 0.331211\n",
      "Reconstruction: 0.318322, Regularization: 0.012889\n",
      "2019-04-09 22:56:12,441 root         INFO     Train Epoch: 54 [5632/8000 (70%)]\tTotal Loss: 0.382144\n",
      "Reconstruction: 0.358412, Regularization: 0.023732\n",
      "2019-04-09 22:56:12,496 root         INFO     Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 0.395575\n",
      "Reconstruction: 0.381698, Regularization: 0.013878\n",
      "2019-04-09 22:56:12,552 root         INFO     Train Epoch: 54 [6656/8000 (83%)]\tTotal Loss: 0.710780\n",
      "Reconstruction: 0.687180, Regularization: 0.023600\n",
      "2019-04-09 22:56:12,608 root         INFO     Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 1.662556\n",
      "Reconstruction: 1.642452, Regularization: 0.020104\n",
      "2019-04-09 22:56:12,664 root         INFO     Train Epoch: 54 [7680/8000 (96%)]\tTotal Loss: 0.541932\n",
      "Reconstruction: 0.520994, Regularization: 0.020938\n",
      "2019-04-09 22:56:12,713 root         INFO     ====> Epoch: 54 Average loss: 0.5170\n",
      "2019-04-09 22:56:12,737 root         INFO     Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 0.478397\n",
      "Reconstruction: 0.453177, Regularization: 0.025219\n",
      "2019-04-09 22:56:12,792 root         INFO     Train Epoch: 55 [512/8000 (6%)]\tTotal Loss: 0.355676\n",
      "Reconstruction: 0.342405, Regularization: 0.013270\n",
      "2019-04-09 22:56:12,847 root         INFO     Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 0.410555\n",
      "Reconstruction: 0.393899, Regularization: 0.016657\n",
      "2019-04-09 22:56:12,903 root         INFO     Train Epoch: 55 [1536/8000 (19%)]\tTotal Loss: 0.517478\n",
      "Reconstruction: 0.498950, Regularization: 0.018527\n",
      "2019-04-09 22:56:12,958 root         INFO     Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 0.457700\n",
      "Reconstruction: 0.442142, Regularization: 0.015559\n",
      "2019-04-09 22:56:13,015 root         INFO     Train Epoch: 55 [2560/8000 (32%)]\tTotal Loss: 0.454110\n",
      "Reconstruction: 0.438671, Regularization: 0.015439\n",
      "2019-04-09 22:56:13,071 root         INFO     Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 0.456816\n",
      "Reconstruction: 0.437720, Regularization: 0.019096\n",
      "2019-04-09 22:56:13,127 root         INFO     Train Epoch: 55 [3584/8000 (45%)]\tTotal Loss: 0.493132\n",
      "Reconstruction: 0.468578, Regularization: 0.024554\n",
      "2019-04-09 22:56:13,183 root         INFO     Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 0.478893\n",
      "Reconstruction: 0.459021, Regularization: 0.019872\n",
      "2019-04-09 22:56:13,239 root         INFO     Train Epoch: 55 [4608/8000 (58%)]\tTotal Loss: 0.485106\n",
      "Reconstruction: 0.462525, Regularization: 0.022581\n",
      "2019-04-09 22:56:13,295 root         INFO     Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 0.435677\n",
      "Reconstruction: 0.417491, Regularization: 0.018186\n",
      "2019-04-09 22:56:13,352 root         INFO     Train Epoch: 55 [5632/8000 (70%)]\tTotal Loss: 0.472165\n",
      "Reconstruction: 0.451822, Regularization: 0.020343\n",
      "2019-04-09 22:56:13,408 root         INFO     Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 0.452244\n",
      "Reconstruction: 0.437268, Regularization: 0.014976\n",
      "2019-04-09 22:56:13,464 root         INFO     Train Epoch: 55 [6656/8000 (83%)]\tTotal Loss: 0.443238\n",
      "Reconstruction: 0.426990, Regularization: 0.016248\n",
      "2019-04-09 22:56:13,520 root         INFO     Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 0.657724\n",
      "Reconstruction: 0.637045, Regularization: 0.020678\n",
      "2019-04-09 22:56:13,576 root         INFO     Train Epoch: 55 [7680/8000 (96%)]\tTotal Loss: 0.512159\n",
      "Reconstruction: 0.488258, Regularization: 0.023900\n",
      "2019-04-09 22:56:13,626 root         INFO     ====> Epoch: 55 Average loss: 0.6503\n",
      "2019-04-09 22:56:13,649 root         INFO     Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 0.494079\n",
      "Reconstruction: 0.475271, Regularization: 0.018808\n",
      "2019-04-09 22:56:13,706 root         INFO     Train Epoch: 56 [512/8000 (6%)]\tTotal Loss: 0.475928\n",
      "Reconstruction: 0.445213, Regularization: 0.030714\n",
      "2019-04-09 22:56:13,762 root         INFO     Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 0.528644\n",
      "Reconstruction: 0.510521, Regularization: 0.018124\n",
      "2019-04-09 22:56:13,818 root         INFO     Train Epoch: 56 [1536/8000 (19%)]\tTotal Loss: 0.558430\n",
      "Reconstruction: 0.536345, Regularization: 0.022085\n",
      "2019-04-09 22:56:13,874 root         INFO     Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 0.389624\n",
      "Reconstruction: 0.375938, Regularization: 0.013685\n",
      "2019-04-09 22:56:13,931 root         INFO     Train Epoch: 56 [2560/8000 (32%)]\tTotal Loss: 0.576092\n",
      "Reconstruction: 0.554433, Regularization: 0.021659\n",
      "2019-04-09 22:56:13,987 root         INFO     Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 0.454169\n",
      "Reconstruction: 0.423103, Regularization: 0.031066\n",
      "2019-04-09 22:56:14,044 root         INFO     Train Epoch: 56 [3584/8000 (45%)]\tTotal Loss: 0.416640\n",
      "Reconstruction: 0.399532, Regularization: 0.017108\n",
      "2019-04-09 22:56:14,100 root         INFO     Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 0.383159\n",
      "Reconstruction: 0.367722, Regularization: 0.015437\n",
      "2019-04-09 22:56:14,157 root         INFO     Train Epoch: 56 [4608/8000 (58%)]\tTotal Loss: 0.457231\n",
      "Reconstruction: 0.442594, Regularization: 0.014638\n",
      "2019-04-09 22:56:14,213 root         INFO     Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 0.368639\n",
      "Reconstruction: 0.348811, Regularization: 0.019828\n",
      "2019-04-09 22:56:14,270 root         INFO     Train Epoch: 56 [5632/8000 (70%)]\tTotal Loss: 0.449655\n",
      "Reconstruction: 0.434080, Regularization: 0.015575\n",
      "2019-04-09 22:56:14,326 root         INFO     Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 0.324071\n",
      "Reconstruction: 0.310580, Regularization: 0.013491\n",
      "2019-04-09 22:56:14,383 root         INFO     Train Epoch: 56 [6656/8000 (83%)]\tTotal Loss: 0.426763\n",
      "Reconstruction: 0.407495, Regularization: 0.019268\n",
      "2019-04-09 22:56:14,438 root         INFO     Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 0.626497\n",
      "Reconstruction: 0.599834, Regularization: 0.026663\n",
      "2019-04-09 22:56:14,494 root         INFO     Train Epoch: 56 [7680/8000 (96%)]\tTotal Loss: 0.485046\n",
      "Reconstruction: 0.467009, Regularization: 0.018037\n",
      "2019-04-09 22:56:14,544 root         INFO     ====> Epoch: 56 Average loss: 1.2605\n",
      "2019-04-09 22:56:14,567 root         INFO     Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 0.406912\n",
      "Reconstruction: 0.391490, Regularization: 0.015422\n",
      "2019-04-09 22:56:14,624 root         INFO     Train Epoch: 57 [512/8000 (6%)]\tTotal Loss: 0.460354\n",
      "Reconstruction: 0.443066, Regularization: 0.017288\n",
      "2019-04-09 22:56:14,680 root         INFO     Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 0.463823\n",
      "Reconstruction: 0.445419, Regularization: 0.018404\n",
      "2019-04-09 22:56:14,736 root         INFO     Train Epoch: 57 [1536/8000 (19%)]\tTotal Loss: 0.300265\n",
      "Reconstruction: 0.284681, Regularization: 0.015584\n",
      "2019-04-09 22:56:14,793 root         INFO     Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 0.413328\n",
      "Reconstruction: 0.395237, Regularization: 0.018091\n",
      "2019-04-09 22:56:14,849 root         INFO     Train Epoch: 57 [2560/8000 (32%)]\tTotal Loss: 0.435938\n",
      "Reconstruction: 0.423024, Regularization: 0.012914\n",
      "2019-04-09 22:56:14,905 root         INFO     Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 0.351009\n",
      "Reconstruction: 0.332923, Regularization: 0.018086\n",
      "2019-04-09 22:56:14,961 root         INFO     Train Epoch: 57 [3584/8000 (45%)]\tTotal Loss: 0.448225\n",
      "Reconstruction: 0.424741, Regularization: 0.023485\n",
      "2019-04-09 22:56:15,017 root         INFO     Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 0.373593\n",
      "Reconstruction: 0.359247, Regularization: 0.014346\n",
      "2019-04-09 22:56:15,072 root         INFO     Train Epoch: 57 [4608/8000 (58%)]\tTotal Loss: 1.378984\n",
      "Reconstruction: 1.344345, Regularization: 0.034639\n",
      "2019-04-09 22:56:15,128 root         INFO     Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 0.510974\n",
      "Reconstruction: 0.491073, Regularization: 0.019901\n",
      "2019-04-09 22:56:15,183 root         INFO     Train Epoch: 57 [5632/8000 (70%)]\tTotal Loss: 0.501901\n",
      "Reconstruction: 0.485248, Regularization: 0.016654\n",
      "2019-04-09 22:56:15,238 root         INFO     Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 0.497095\n",
      "Reconstruction: 0.479017, Regularization: 0.018078\n",
      "2019-04-09 22:56:15,293 root         INFO     Train Epoch: 57 [6656/8000 (83%)]\tTotal Loss: 3.428037\n",
      "Reconstruction: 3.392986, Regularization: 0.035051\n",
      "2019-04-09 22:56:15,347 root         INFO     Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 0.492910\n",
      "Reconstruction: 0.474258, Regularization: 0.018652\n",
      "2019-04-09 22:56:15,402 root         INFO     Train Epoch: 57 [7680/8000 (96%)]\tTotal Loss: 0.439091\n",
      "Reconstruction: 0.422981, Regularization: 0.016110\n",
      "2019-04-09 22:56:15,451 root         INFO     ====> Epoch: 57 Average loss: 0.5547\n",
      "2019-04-09 22:56:15,475 root         INFO     Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 0.475227\n",
      "Reconstruction: 0.458584, Regularization: 0.016643\n",
      "2019-04-09 22:56:15,531 root         INFO     Train Epoch: 58 [512/8000 (6%)]\tTotal Loss: 0.382274\n",
      "Reconstruction: 0.368735, Regularization: 0.013539\n",
      "2019-04-09 22:56:15,587 root         INFO     Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 0.308183\n",
      "Reconstruction: 0.294909, Regularization: 0.013273\n",
      "2019-04-09 22:56:15,642 root         INFO     Train Epoch: 58 [1536/8000 (19%)]\tTotal Loss: 0.484286\n",
      "Reconstruction: 0.460635, Regularization: 0.023651\n",
      "2019-04-09 22:56:15,698 root         INFO     Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 0.464417\n",
      "Reconstruction: 0.449115, Regularization: 0.015302\n",
      "2019-04-09 22:56:15,753 root         INFO     Train Epoch: 58 [2560/8000 (32%)]\tTotal Loss: 0.405191\n",
      "Reconstruction: 0.386192, Regularization: 0.018999\n",
      "2019-04-09 22:56:15,809 root         INFO     Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 0.543446\n",
      "Reconstruction: 0.525954, Regularization: 0.017492\n",
      "2019-04-09 22:56:15,865 root         INFO     Train Epoch: 58 [3584/8000 (45%)]\tTotal Loss: 0.508823\n",
      "Reconstruction: 0.490883, Regularization: 0.017941\n",
      "2019-04-09 22:56:15,920 root         INFO     Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 0.575609\n",
      "Reconstruction: 0.556469, Regularization: 0.019140\n",
      "2019-04-09 22:56:15,975 root         INFO     Train Epoch: 58 [4608/8000 (58%)]\tTotal Loss: 0.480234\n",
      "Reconstruction: 0.466159, Regularization: 0.014074\n",
      "2019-04-09 22:56:16,031 root         INFO     Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 0.427108\n",
      "Reconstruction: 0.406108, Regularization: 0.021000\n",
      "2019-04-09 22:56:16,085 root         INFO     Train Epoch: 58 [5632/8000 (70%)]\tTotal Loss: 0.392845\n",
      "Reconstruction: 0.373079, Regularization: 0.019766\n",
      "2019-04-09 22:56:16,140 root         INFO     Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 0.450585\n",
      "Reconstruction: 0.433087, Regularization: 0.017498\n",
      "2019-04-09 22:56:16,195 root         INFO     Train Epoch: 58 [6656/8000 (83%)]\tTotal Loss: 0.539360\n",
      "Reconstruction: 0.512783, Regularization: 0.026577\n",
      "2019-04-09 22:56:16,250 root         INFO     Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 0.594940\n",
      "Reconstruction: 0.567865, Regularization: 0.027075\n",
      "2019-04-09 22:56:16,306 root         INFO     Train Epoch: 58 [7680/8000 (96%)]\tTotal Loss: 0.374420\n",
      "Reconstruction: 0.356255, Regularization: 0.018165\n",
      "2019-04-09 22:56:16,354 root         INFO     ====> Epoch: 58 Average loss: 7.9024\n",
      "2019-04-09 22:56:16,377 root         INFO     Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 0.391231\n",
      "Reconstruction: 0.371977, Regularization: 0.019254\n",
      "2019-04-09 22:56:16,434 root         INFO     Train Epoch: 59 [512/8000 (6%)]\tTotal Loss: 0.494739\n",
      "Reconstruction: 0.477056, Regularization: 0.017683\n",
      "2019-04-09 22:56:16,490 root         INFO     Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 0.525015\n",
      "Reconstruction: 0.507706, Regularization: 0.017309\n",
      "2019-04-09 22:56:16,546 root         INFO     Train Epoch: 59 [1536/8000 (19%)]\tTotal Loss: 0.372624\n",
      "Reconstruction: 0.356293, Regularization: 0.016331\n",
      "2019-04-09 22:56:16,602 root         INFO     Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 0.479762\n",
      "Reconstruction: 0.461946, Regularization: 0.017816\n",
      "2019-04-09 22:56:16,659 root         INFO     Train Epoch: 59 [2560/8000 (32%)]\tTotal Loss: 0.338882\n",
      "Reconstruction: 0.324161, Regularization: 0.014721\n",
      "2019-04-09 22:56:16,715 root         INFO     Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 0.469610\n",
      "Reconstruction: 0.453196, Regularization: 0.016414\n",
      "2019-04-09 22:56:16,771 root         INFO     Train Epoch: 59 [3584/8000 (45%)]\tTotal Loss: 0.358712\n",
      "Reconstruction: 0.341823, Regularization: 0.016890\n",
      "2019-04-09 22:56:16,827 root         INFO     Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 0.571946\n",
      "Reconstruction: 0.551926, Regularization: 0.020019\n",
      "2019-04-09 22:56:16,883 root         INFO     Train Epoch: 59 [4608/8000 (58%)]\tTotal Loss: 0.418933\n",
      "Reconstruction: 0.393941, Regularization: 0.024992\n",
      "2019-04-09 22:56:16,939 root         INFO     Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 0.401618\n",
      "Reconstruction: 0.385210, Regularization: 0.016408\n",
      "2019-04-09 22:56:16,996 root         INFO     Train Epoch: 59 [5632/8000 (70%)]\tTotal Loss: 0.456403\n",
      "Reconstruction: 0.432159, Regularization: 0.024244\n",
      "2019-04-09 22:56:17,052 root         INFO     Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 0.463935\n",
      "Reconstruction: 0.440542, Regularization: 0.023393\n",
      "2019-04-09 22:56:17,108 root         INFO     Train Epoch: 59 [6656/8000 (83%)]\tTotal Loss: 0.315396\n",
      "Reconstruction: 0.295173, Regularization: 0.020222\n",
      "2019-04-09 22:56:17,165 root         INFO     Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 0.380612\n",
      "Reconstruction: 0.365930, Regularization: 0.014682\n",
      "2019-04-09 22:56:17,221 root         INFO     Train Epoch: 59 [7680/8000 (96%)]\tTotal Loss: 0.379126\n",
      "Reconstruction: 0.351638, Regularization: 0.027488\n",
      "2019-04-09 22:56:17,270 root         INFO     ====> Epoch: 59 Average loss: 0.6492\n",
      "2019-04-09 22:56:17,293 root         INFO     Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 0.472351\n",
      "Reconstruction: 0.450522, Regularization: 0.021829\n",
      "2019-04-09 22:56:17,351 root         INFO     Train Epoch: 60 [512/8000 (6%)]\tTotal Loss: 0.352039\n",
      "Reconstruction: 0.338383, Regularization: 0.013657\n",
      "2019-04-09 22:56:17,407 root         INFO     Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 0.574073\n",
      "Reconstruction: 0.558180, Regularization: 0.015893\n",
      "2019-04-09 22:56:17,464 root         INFO     Train Epoch: 60 [1536/8000 (19%)]\tTotal Loss: 0.412355\n",
      "Reconstruction: 0.397334, Regularization: 0.015021\n",
      "2019-04-09 22:56:17,521 root         INFO     Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 0.463491\n",
      "Reconstruction: 0.434783, Regularization: 0.028708\n",
      "2019-04-09 22:56:17,576 root         INFO     Train Epoch: 60 [2560/8000 (32%)]\tTotal Loss: 0.516310\n",
      "Reconstruction: 0.497173, Regularization: 0.019137\n",
      "2019-04-09 22:56:17,633 root         INFO     Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 0.345331\n",
      "Reconstruction: 0.330550, Regularization: 0.014782\n",
      "2019-04-09 22:56:17,687 root         INFO     Train Epoch: 60 [3584/8000 (45%)]\tTotal Loss: 0.295748\n",
      "Reconstruction: 0.279854, Regularization: 0.015894\n",
      "2019-04-09 22:56:17,742 root         INFO     Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 0.439686\n",
      "Reconstruction: 0.425494, Regularization: 0.014192\n",
      "2019-04-09 22:56:17,798 root         INFO     Train Epoch: 60 [4608/8000 (58%)]\tTotal Loss: 0.497265\n",
      "Reconstruction: 0.478297, Regularization: 0.018968\n",
      "2019-04-09 22:56:17,854 root         INFO     Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 0.489230\n",
      "Reconstruction: 0.471597, Regularization: 0.017633\n",
      "2019-04-09 22:56:17,909 root         INFO     Train Epoch: 60 [5632/8000 (70%)]\tTotal Loss: 0.346019\n",
      "Reconstruction: 0.324492, Regularization: 0.021526\n",
      "2019-04-09 22:56:17,963 root         INFO     Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 0.410750\n",
      "Reconstruction: 0.394065, Regularization: 0.016685\n",
      "2019-04-09 22:56:18,019 root         INFO     Train Epoch: 60 [6656/8000 (83%)]\tTotal Loss: 0.382351\n",
      "Reconstruction: 0.356221, Regularization: 0.026130\n",
      "2019-04-09 22:56:18,076 root         INFO     Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 0.491570\n",
      "Reconstruction: 0.473183, Regularization: 0.018388\n",
      "2019-04-09 22:56:18,131 root         INFO     Train Epoch: 60 [7680/8000 (96%)]\tTotal Loss: 0.407359\n",
      "Reconstruction: 0.389820, Regularization: 0.017539\n",
      "2019-04-09 22:56:18,180 root         INFO     ====> Epoch: 60 Average loss: 0.5512\n",
      "2019-04-09 22:56:18,204 root         INFO     Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 0.430674\n",
      "Reconstruction: 0.412572, Regularization: 0.018102\n",
      "2019-04-09 22:56:18,263 root         INFO     Train Epoch: 61 [512/8000 (6%)]\tTotal Loss: 0.480263\n",
      "Reconstruction: 0.453327, Regularization: 0.026936\n",
      "2019-04-09 22:56:18,319 root         INFO     Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 0.457248\n",
      "Reconstruction: 0.439146, Regularization: 0.018102\n",
      "2019-04-09 22:56:18,376 root         INFO     Train Epoch: 61 [1536/8000 (19%)]\tTotal Loss: 0.527694\n",
      "Reconstruction: 0.505185, Regularization: 0.022508\n",
      "2019-04-09 22:56:18,434 root         INFO     Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 0.656036\n",
      "Reconstruction: 0.634909, Regularization: 0.021127\n",
      "2019-04-09 22:56:18,491 root         INFO     Train Epoch: 61 [2560/8000 (32%)]\tTotal Loss: 0.423500\n",
      "Reconstruction: 0.405634, Regularization: 0.017866\n",
      "2019-04-09 22:56:18,547 root         INFO     Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 0.425556\n",
      "Reconstruction: 0.409989, Regularization: 0.015567\n",
      "2019-04-09 22:56:18,605 root         INFO     Train Epoch: 61 [3584/8000 (45%)]\tTotal Loss: 0.580520\n",
      "Reconstruction: 0.554015, Regularization: 0.026505\n",
      "2019-04-09 22:56:18,663 root         INFO     Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 0.460164\n",
      "Reconstruction: 0.442943, Regularization: 0.017220\n",
      "2019-04-09 22:56:18,719 root         INFO     Train Epoch: 61 [4608/8000 (58%)]\tTotal Loss: 0.489552\n",
      "Reconstruction: 0.468906, Regularization: 0.020647\n",
      "2019-04-09 22:56:18,777 root         INFO     Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 0.395237\n",
      "Reconstruction: 0.380109, Regularization: 0.015128\n",
      "2019-04-09 22:56:18,835 root         INFO     Train Epoch: 61 [5632/8000 (70%)]\tTotal Loss: 0.470581\n",
      "Reconstruction: 0.452649, Regularization: 0.017932\n",
      "2019-04-09 22:56:18,892 root         INFO     Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 0.378214\n",
      "Reconstruction: 0.362884, Regularization: 0.015331\n",
      "2019-04-09 22:56:18,949 root         INFO     Train Epoch: 61 [6656/8000 (83%)]\tTotal Loss: 0.411471\n",
      "Reconstruction: 0.391707, Regularization: 0.019764\n",
      "2019-04-09 22:56:19,008 root         INFO     Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 0.521036\n",
      "Reconstruction: 0.502233, Regularization: 0.018803\n",
      "2019-04-09 22:56:19,065 root         INFO     Train Epoch: 61 [7680/8000 (96%)]\tTotal Loss: 0.354650\n",
      "Reconstruction: 0.342343, Regularization: 0.012306\n",
      "2019-04-09 22:56:19,115 root         INFO     ====> Epoch: 61 Average loss: 105.4810\n",
      "2019-04-09 22:56:19,138 root         INFO     Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 0.438369\n",
      "Reconstruction: 0.413871, Regularization: 0.024498\n",
      "2019-04-09 22:56:19,197 root         INFO     Train Epoch: 62 [512/8000 (6%)]\tTotal Loss: 0.485492\n",
      "Reconstruction: 0.469441, Regularization: 0.016051\n",
      "2019-04-09 22:56:19,255 root         INFO     Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 0.441910\n",
      "Reconstruction: 0.423855, Regularization: 0.018054\n",
      "2019-04-09 22:56:19,312 root         INFO     Train Epoch: 62 [1536/8000 (19%)]\tTotal Loss: 0.370323\n",
      "Reconstruction: 0.357451, Regularization: 0.012872\n",
      "2019-04-09 22:56:19,367 root         INFO     Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 0.429816\n",
      "Reconstruction: 0.413224, Regularization: 0.016592\n",
      "2019-04-09 22:56:19,427 root         INFO     Train Epoch: 62 [2560/8000 (32%)]\tTotal Loss: 0.352391\n",
      "Reconstruction: 0.337950, Regularization: 0.014441\n",
      "2019-04-09 22:56:19,484 root         INFO     Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 0.630877\n",
      "Reconstruction: 0.609895, Regularization: 0.020982\n",
      "2019-04-09 22:56:19,540 root         INFO     Train Epoch: 62 [3584/8000 (45%)]\tTotal Loss: 0.433588\n",
      "Reconstruction: 0.419096, Regularization: 0.014492\n",
      "2019-04-09 22:56:19,595 root         INFO     Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 0.428095\n",
      "Reconstruction: 0.402156, Regularization: 0.025939\n",
      "2019-04-09 22:56:19,650 root         INFO     Train Epoch: 62 [4608/8000 (58%)]\tTotal Loss: 0.492697\n",
      "Reconstruction: 0.474335, Regularization: 0.018362\n",
      "2019-04-09 22:56:19,705 root         INFO     Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 0.420642\n",
      "Reconstruction: 0.403774, Regularization: 0.016869\n",
      "2019-04-09 22:56:19,760 root         INFO     Train Epoch: 62 [5632/8000 (70%)]\tTotal Loss: 0.693296\n",
      "Reconstruction: 0.676516, Regularization: 0.016780\n",
      "2019-04-09 22:56:19,815 root         INFO     Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 0.469370\n",
      "Reconstruction: 0.451480, Regularization: 0.017890\n",
      "2019-04-09 22:56:19,870 root         INFO     Train Epoch: 62 [6656/8000 (83%)]\tTotal Loss: 0.429651\n",
      "Reconstruction: 0.412581, Regularization: 0.017070\n",
      "2019-04-09 22:56:19,925 root         INFO     Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 0.544173\n",
      "Reconstruction: 0.523880, Regularization: 0.020293\n",
      "2019-04-09 22:56:19,980 root         INFO     Train Epoch: 62 [7680/8000 (96%)]\tTotal Loss: 0.538299\n",
      "Reconstruction: 0.520021, Regularization: 0.018278\n",
      "2019-04-09 22:56:20,028 root         INFO     ====> Epoch: 62 Average loss: 1.4753\n",
      "2019-04-09 22:56:20,051 root         INFO     Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 0.387583\n",
      "Reconstruction: 0.373314, Regularization: 0.014269\n",
      "2019-04-09 22:56:20,108 root         INFO     Train Epoch: 63 [512/8000 (6%)]\tTotal Loss: 0.398473\n",
      "Reconstruction: 0.381291, Regularization: 0.017182\n",
      "2019-04-09 22:56:20,164 root         INFO     Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 0.428193\n",
      "Reconstruction: 0.412860, Regularization: 0.015333\n",
      "2019-04-09 22:56:20,221 root         INFO     Train Epoch: 63 [1536/8000 (19%)]\tTotal Loss: 0.809531\n",
      "Reconstruction: 0.780076, Regularization: 0.029455\n",
      "2019-04-09 22:56:20,277 root         INFO     Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 0.398752\n",
      "Reconstruction: 0.384089, Regularization: 0.014664\n",
      "2019-04-09 22:56:20,334 root         INFO     Train Epoch: 63 [2560/8000 (32%)]\tTotal Loss: 0.387448\n",
      "Reconstruction: 0.373214, Regularization: 0.014235\n",
      "2019-04-09 22:56:20,391 root         INFO     Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 0.445274\n",
      "Reconstruction: 0.418870, Regularization: 0.026403\n",
      "2019-04-09 22:56:20,447 root         INFO     Train Epoch: 63 [3584/8000 (45%)]\tTotal Loss: 0.340240\n",
      "Reconstruction: 0.326441, Regularization: 0.013799\n",
      "2019-04-09 22:56:20,503 root         INFO     Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 0.431239\n",
      "Reconstruction: 0.414911, Regularization: 0.016327\n",
      "2019-04-09 22:56:20,559 root         INFO     Train Epoch: 63 [4608/8000 (58%)]\tTotal Loss: 0.443564\n",
      "Reconstruction: 0.428470, Regularization: 0.015094\n",
      "2019-04-09 22:56:20,616 root         INFO     Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 0.412515\n",
      "Reconstruction: 0.393253, Regularization: 0.019262\n",
      "2019-04-09 22:56:20,672 root         INFO     Train Epoch: 63 [5632/8000 (70%)]\tTotal Loss: 0.412862\n",
      "Reconstruction: 0.398651, Regularization: 0.014211\n",
      "2019-04-09 22:56:20,728 root         INFO     Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 0.406428\n",
      "Reconstruction: 0.393524, Regularization: 0.012903\n",
      "2019-04-09 22:56:20,785 root         INFO     Train Epoch: 63 [6656/8000 (83%)]\tTotal Loss: 0.455762\n",
      "Reconstruction: 0.440215, Regularization: 0.015546\n",
      "2019-04-09 22:56:20,841 root         INFO     Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 0.482448\n",
      "Reconstruction: 0.462492, Regularization: 0.019956\n",
      "2019-04-09 22:56:20,897 root         INFO     Train Epoch: 63 [7680/8000 (96%)]\tTotal Loss: 0.593984\n",
      "Reconstruction: 0.569632, Regularization: 0.024352\n",
      "2019-04-09 22:56:20,948 root         INFO     ====> Epoch: 63 Average loss: 0.5045\n",
      "2019-04-09 22:56:20,971 root         INFO     Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 0.356478\n",
      "Reconstruction: 0.332700, Regularization: 0.023778\n",
      "2019-04-09 22:56:21,028 root         INFO     Train Epoch: 64 [512/8000 (6%)]\tTotal Loss: 0.465282\n",
      "Reconstruction: 0.447329, Regularization: 0.017953\n",
      "2019-04-09 22:56:21,084 root         INFO     Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 0.701719\n",
      "Reconstruction: 0.671568, Regularization: 0.030151\n",
      "2019-04-09 22:56:21,141 root         INFO     Train Epoch: 64 [1536/8000 (19%)]\tTotal Loss: 0.383527\n",
      "Reconstruction: 0.368531, Regularization: 0.014996\n",
      "2019-04-09 22:56:21,197 root         INFO     Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 0.438977\n",
      "Reconstruction: 0.421223, Regularization: 0.017754\n",
      "2019-04-09 22:56:21,254 root         INFO     Train Epoch: 64 [2560/8000 (32%)]\tTotal Loss: 0.414550\n",
      "Reconstruction: 0.394813, Regularization: 0.019737\n",
      "2019-04-09 22:56:21,310 root         INFO     Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 0.427581\n",
      "Reconstruction: 0.385695, Regularization: 0.041886\n",
      "2019-04-09 22:56:21,367 root         INFO     Train Epoch: 64 [3584/8000 (45%)]\tTotal Loss: 0.471124\n",
      "Reconstruction: 0.454646, Regularization: 0.016477\n",
      "2019-04-09 22:56:21,423 root         INFO     Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 0.356526\n",
      "Reconstruction: 0.341363, Regularization: 0.015162\n",
      "2019-04-09 22:56:21,480 root         INFO     Train Epoch: 64 [4608/8000 (58%)]\tTotal Loss: 0.590452\n",
      "Reconstruction: 0.568171, Regularization: 0.022281\n",
      "2019-04-09 22:56:21,536 root         INFO     Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 0.464036\n",
      "Reconstruction: 0.443567, Regularization: 0.020470\n",
      "2019-04-09 22:56:21,593 root         INFO     Train Epoch: 64 [5632/8000 (70%)]\tTotal Loss: 0.455689\n",
      "Reconstruction: 0.439241, Regularization: 0.016448\n",
      "2019-04-09 22:56:21,649 root         INFO     Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 0.457141\n",
      "Reconstruction: 0.437559, Regularization: 0.019582\n",
      "2019-04-09 22:56:21,705 root         INFO     Train Epoch: 64 [6656/8000 (83%)]\tTotal Loss: 0.598861\n",
      "Reconstruction: 0.578060, Regularization: 0.020801\n",
      "2019-04-09 22:56:21,762 root         INFO     Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 0.389141\n",
      "Reconstruction: 0.375161, Regularization: 0.013981\n",
      "2019-04-09 22:56:21,818 root         INFO     Train Epoch: 64 [7680/8000 (96%)]\tTotal Loss: 0.407100\n",
      "Reconstruction: 0.378395, Regularization: 0.028705\n",
      "2019-04-09 22:56:21,868 root         INFO     ====> Epoch: 64 Average loss: 0.4782\n",
      "2019-04-09 22:56:21,891 root         INFO     Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 0.364519\n",
      "Reconstruction: 0.350486, Regularization: 0.014033\n",
      "2019-04-09 22:56:21,947 root         INFO     Train Epoch: 65 [512/8000 (6%)]\tTotal Loss: 0.530095\n",
      "Reconstruction: 0.497334, Regularization: 0.032761\n",
      "2019-04-09 22:56:22,004 root         INFO     Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 0.477498\n",
      "Reconstruction: 0.459694, Regularization: 0.017804\n",
      "2019-04-09 22:56:22,060 root         INFO     Train Epoch: 65 [1536/8000 (19%)]\tTotal Loss: 0.585722\n",
      "Reconstruction: 0.555243, Regularization: 0.030479\n",
      "2019-04-09 22:56:22,117 root         INFO     Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 0.474981\n",
      "Reconstruction: 0.455192, Regularization: 0.019788\n",
      "2019-04-09 22:56:22,173 root         INFO     Train Epoch: 65 [2560/8000 (32%)]\tTotal Loss: 0.482194\n",
      "Reconstruction: 0.458185, Regularization: 0.024009\n",
      "2019-04-09 22:56:22,229 root         INFO     Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 0.570209\n",
      "Reconstruction: 0.549246, Regularization: 0.020963\n",
      "2019-04-09 22:56:22,284 root         INFO     Train Epoch: 65 [3584/8000 (45%)]\tTotal Loss: 0.375672\n",
      "Reconstruction: 0.361839, Regularization: 0.013834\n",
      "2019-04-09 22:56:22,339 root         INFO     Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 0.556119\n",
      "Reconstruction: 0.535465, Regularization: 0.020654\n",
      "2019-04-09 22:56:22,393 root         INFO     Train Epoch: 65 [4608/8000 (58%)]\tTotal Loss: 0.403986\n",
      "Reconstruction: 0.389199, Regularization: 0.014787\n",
      "2019-04-09 22:56:22,448 root         INFO     Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 0.504435\n",
      "Reconstruction: 0.486273, Regularization: 0.018161\n",
      "2019-04-09 22:56:22,504 root         INFO     Train Epoch: 65 [5632/8000 (70%)]\tTotal Loss: 0.417461\n",
      "Reconstruction: 0.399072, Regularization: 0.018388\n",
      "2019-04-09 22:56:22,559 root         INFO     Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 0.412952\n",
      "Reconstruction: 0.398538, Regularization: 0.014414\n",
      "2019-04-09 22:56:22,614 root         INFO     Train Epoch: 65 [6656/8000 (83%)]\tTotal Loss: 0.509391\n",
      "Reconstruction: 0.489975, Regularization: 0.019416\n",
      "2019-04-09 22:56:22,669 root         INFO     Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 0.657131\n",
      "Reconstruction: 0.633167, Regularization: 0.023964\n",
      "2019-04-09 22:56:22,726 root         INFO     Train Epoch: 65 [7680/8000 (96%)]\tTotal Loss: 0.463324\n",
      "Reconstruction: 0.430073, Regularization: 0.033250\n",
      "2019-04-09 22:56:22,775 root         INFO     ====> Epoch: 65 Average loss: 0.7359\n",
      "2019-04-09 22:56:22,799 root         INFO     Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 0.415360\n",
      "Reconstruction: 0.399517, Regularization: 0.015843\n",
      "2019-04-09 22:56:22,858 root         INFO     Train Epoch: 66 [512/8000 (6%)]\tTotal Loss: 0.543777\n",
      "Reconstruction: 0.523431, Regularization: 0.020347\n",
      "2019-04-09 22:56:22,916 root         INFO     Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 0.488970\n",
      "Reconstruction: 0.470626, Regularization: 0.018344\n",
      "2019-04-09 22:56:22,974 root         INFO     Train Epoch: 66 [1536/8000 (19%)]\tTotal Loss: 0.528230\n",
      "Reconstruction: 0.505106, Regularization: 0.023123\n",
      "2019-04-09 22:56:23,032 root         INFO     Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 0.375555\n",
      "Reconstruction: 0.356016, Regularization: 0.019539\n",
      "2019-04-09 22:56:23,087 root         INFO     Train Epoch: 66 [2560/8000 (32%)]\tTotal Loss: 0.375965\n",
      "Reconstruction: 0.357629, Regularization: 0.018336\n",
      "2019-04-09 22:56:23,142 root         INFO     Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 0.442471\n",
      "Reconstruction: 0.408113, Regularization: 0.034358\n",
      "2019-04-09 22:56:23,197 root         INFO     Train Epoch: 66 [3584/8000 (45%)]\tTotal Loss: 0.400992\n",
      "Reconstruction: 0.383267, Regularization: 0.017725\n",
      "2019-04-09 22:56:23,260 root         INFO     Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 0.507530\n",
      "Reconstruction: 0.484188, Regularization: 0.023341\n",
      "2019-04-09 22:56:23,317 root         INFO     Train Epoch: 66 [4608/8000 (58%)]\tTotal Loss: 0.533974\n",
      "Reconstruction: 0.513123, Regularization: 0.020851\n",
      "2019-04-09 22:56:23,373 root         INFO     Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 0.385015\n",
      "Reconstruction: 0.368271, Regularization: 0.016744\n",
      "2019-04-09 22:56:23,430 root         INFO     Train Epoch: 66 [5632/8000 (70%)]\tTotal Loss: 0.403978\n",
      "Reconstruction: 0.386135, Regularization: 0.017843\n",
      "2019-04-09 22:56:23,487 root         INFO     Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 0.439710\n",
      "Reconstruction: 0.426001, Regularization: 0.013709\n",
      "2019-04-09 22:56:23,543 root         INFO     Train Epoch: 66 [6656/8000 (83%)]\tTotal Loss: 0.429927\n",
      "Reconstruction: 0.413861, Regularization: 0.016067\n",
      "2019-04-09 22:56:23,598 root         INFO     Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 0.590127\n",
      "Reconstruction: 0.562080, Regularization: 0.028047\n",
      "2019-04-09 22:56:23,654 root         INFO     Train Epoch: 66 [7680/8000 (96%)]\tTotal Loss: 0.404168\n",
      "Reconstruction: 0.387638, Regularization: 0.016530\n",
      "2019-04-09 22:56:23,704 root         INFO     ====> Epoch: 66 Average loss: 0.5409\n",
      "2019-04-09 22:56:23,727 root         INFO     Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 1.804931\n",
      "Reconstruction: 1.780334, Regularization: 0.024597\n",
      "2019-04-09 22:56:23,783 root         INFO     Train Epoch: 67 [512/8000 (6%)]\tTotal Loss: 0.400110\n",
      "Reconstruction: 0.379876, Regularization: 0.020234\n",
      "2019-04-09 22:56:23,839 root         INFO     Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 0.565575\n",
      "Reconstruction: 0.548139, Regularization: 0.017436\n",
      "2019-04-09 22:56:23,896 root         INFO     Train Epoch: 67 [1536/8000 (19%)]\tTotal Loss: 0.393474\n",
      "Reconstruction: 0.371826, Regularization: 0.021647\n",
      "2019-04-09 22:56:23,952 root         INFO     Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 0.321838\n",
      "Reconstruction: 0.303133, Regularization: 0.018706\n",
      "2019-04-09 22:56:24,007 root         INFO     Train Epoch: 67 [2560/8000 (32%)]\tTotal Loss: 0.510938\n",
      "Reconstruction: 0.490390, Regularization: 0.020549\n",
      "2019-04-09 22:56:24,063 root         INFO     Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 0.464232\n",
      "Reconstruction: 0.445675, Regularization: 0.018556\n",
      "2019-04-09 22:56:24,118 root         INFO     Train Epoch: 67 [3584/8000 (45%)]\tTotal Loss: 0.430919\n",
      "Reconstruction: 0.414406, Regularization: 0.016512\n",
      "2019-04-09 22:56:24,173 root         INFO     Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 0.494645\n",
      "Reconstruction: 0.477746, Regularization: 0.016898\n",
      "2019-04-09 22:56:24,229 root         INFO     Train Epoch: 67 [4608/8000 (58%)]\tTotal Loss: 0.324995\n",
      "Reconstruction: 0.313481, Regularization: 0.011514\n",
      "2019-04-09 22:56:24,284 root         INFO     Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 0.388866\n",
      "Reconstruction: 0.371580, Regularization: 0.017285\n",
      "2019-04-09 22:56:24,339 root         INFO     Train Epoch: 67 [5632/8000 (70%)]\tTotal Loss: 7.947486\n",
      "Reconstruction: 7.893934, Regularization: 0.053553\n",
      "2019-04-09 22:56:24,394 root         INFO     Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 0.519427\n",
      "Reconstruction: 0.503284, Regularization: 0.016143\n",
      "2019-04-09 22:56:24,450 root         INFO     Train Epoch: 67 [6656/8000 (83%)]\tTotal Loss: 0.395715\n",
      "Reconstruction: 0.380843, Regularization: 0.014871\n",
      "2019-04-09 22:56:24,505 root         INFO     Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 0.382678\n",
      "Reconstruction: 0.368391, Regularization: 0.014287\n",
      "2019-04-09 22:56:24,560 root         INFO     Train Epoch: 67 [7680/8000 (96%)]\tTotal Loss: 0.324766\n",
      "Reconstruction: 0.312354, Regularization: 0.012412\n",
      "2019-04-09 22:56:24,609 root         INFO     ====> Epoch: 67 Average loss: 0.5770\n",
      "2019-04-09 22:56:24,632 root         INFO     Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 0.425621\n",
      "Reconstruction: 0.403728, Regularization: 0.021893\n",
      "2019-04-09 22:56:24,688 root         INFO     Train Epoch: 68 [512/8000 (6%)]\tTotal Loss: 0.432978\n",
      "Reconstruction: 0.414549, Regularization: 0.018428\n",
      "2019-04-09 22:56:24,743 root         INFO     Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 0.491498\n",
      "Reconstruction: 0.474925, Regularization: 0.016573\n",
      "2019-04-09 22:56:24,798 root         INFO     Train Epoch: 68 [1536/8000 (19%)]\tTotal Loss: 1.493810\n",
      "Reconstruction: 1.466158, Regularization: 0.027652\n",
      "2019-04-09 22:56:24,853 root         INFO     Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 0.406660\n",
      "Reconstruction: 0.388779, Regularization: 0.017881\n",
      "2019-04-09 22:56:24,908 root         INFO     Train Epoch: 68 [2560/8000 (32%)]\tTotal Loss: 0.366831\n",
      "Reconstruction: 0.351649, Regularization: 0.015181\n",
      "2019-04-09 22:56:24,962 root         INFO     Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 0.529192\n",
      "Reconstruction: 0.506648, Regularization: 0.022544\n",
      "2019-04-09 22:56:25,017 root         INFO     Train Epoch: 68 [3584/8000 (45%)]\tTotal Loss: 0.541241\n",
      "Reconstruction: 0.520469, Regularization: 0.020772\n",
      "2019-04-09 22:56:25,071 root         INFO     Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 0.340475\n",
      "Reconstruction: 0.323888, Regularization: 0.016587\n",
      "2019-04-09 22:56:25,126 root         INFO     Train Epoch: 68 [4608/8000 (58%)]\tTotal Loss: 0.555566\n",
      "Reconstruction: 0.531166, Regularization: 0.024399\n",
      "2019-04-09 22:56:25,180 root         INFO     Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 0.412108\n",
      "Reconstruction: 0.398273, Regularization: 0.013835\n",
      "2019-04-09 22:56:25,235 root         INFO     Train Epoch: 68 [5632/8000 (70%)]\tTotal Loss: 0.414786\n",
      "Reconstruction: 0.399891, Regularization: 0.014895\n",
      "2019-04-09 22:56:25,289 root         INFO     Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 0.490713\n",
      "Reconstruction: 0.472192, Regularization: 0.018521\n",
      "2019-04-09 22:56:25,344 root         INFO     Train Epoch: 68 [6656/8000 (83%)]\tTotal Loss: 0.379062\n",
      "Reconstruction: 0.359953, Regularization: 0.019109\n",
      "2019-04-09 22:56:25,398 root         INFO     Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 1.457277\n",
      "Reconstruction: 1.434801, Regularization: 0.022477\n",
      "2019-04-09 22:56:25,452 root         INFO     Train Epoch: 68 [7680/8000 (96%)]\tTotal Loss: 0.442361\n",
      "Reconstruction: 0.427650, Regularization: 0.014711\n",
      "2019-04-09 22:56:25,501 root         INFO     ====> Epoch: 68 Average loss: 0.5973\n",
      "2019-04-09 22:56:25,524 root         INFO     Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 0.328298\n",
      "Reconstruction: 0.314732, Regularization: 0.013566\n",
      "2019-04-09 22:56:25,580 root         INFO     Train Epoch: 69 [512/8000 (6%)]\tTotal Loss: 0.444153\n",
      "Reconstruction: 0.424693, Regularization: 0.019460\n",
      "2019-04-09 22:56:25,636 root         INFO     Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 0.511535\n",
      "Reconstruction: 0.492577, Regularization: 0.018958\n",
      "2019-04-09 22:56:25,692 root         INFO     Train Epoch: 69 [1536/8000 (19%)]\tTotal Loss: 0.485246\n",
      "Reconstruction: 0.467614, Regularization: 0.017632\n",
      "2019-04-09 22:56:25,747 root         INFO     Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 0.486298\n",
      "Reconstruction: 0.462593, Regularization: 0.023705\n",
      "2019-04-09 22:56:25,803 root         INFO     Train Epoch: 69 [2560/8000 (32%)]\tTotal Loss: 2.864051\n",
      "Reconstruction: 2.818342, Regularization: 0.045709\n",
      "2019-04-09 22:56:25,859 root         INFO     Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 0.393538\n",
      "Reconstruction: 0.378027, Regularization: 0.015512\n",
      "2019-04-09 22:56:25,915 root         INFO     Train Epoch: 69 [3584/8000 (45%)]\tTotal Loss: 0.456828\n",
      "Reconstruction: 0.442260, Regularization: 0.014567\n",
      "2019-04-09 22:56:25,970 root         INFO     Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 0.537461\n",
      "Reconstruction: 0.517488, Regularization: 0.019973\n",
      "2019-04-09 22:56:26,026 root         INFO     Train Epoch: 69 [4608/8000 (58%)]\tTotal Loss: 0.428365\n",
      "Reconstruction: 0.412084, Regularization: 0.016281\n",
      "2019-04-09 22:56:26,082 root         INFO     Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 0.442915\n",
      "Reconstruction: 0.426456, Regularization: 0.016459\n",
      "2019-04-09 22:56:26,137 root         INFO     Train Epoch: 69 [5632/8000 (70%)]\tTotal Loss: 0.405845\n",
      "Reconstruction: 0.391990, Regularization: 0.013855\n",
      "2019-04-09 22:56:26,193 root         INFO     Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 0.465386\n",
      "Reconstruction: 0.440690, Regularization: 0.024696\n",
      "2019-04-09 22:56:26,249 root         INFO     Train Epoch: 69 [6656/8000 (83%)]\tTotal Loss: 0.400135\n",
      "Reconstruction: 0.387670, Regularization: 0.012466\n",
      "2019-04-09 22:56:26,304 root         INFO     Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 0.375209\n",
      "Reconstruction: 0.360978, Regularization: 0.014231\n",
      "2019-04-09 22:56:26,360 root         INFO     Train Epoch: 69 [7680/8000 (96%)]\tTotal Loss: 1.402258\n",
      "Reconstruction: 1.380241, Regularization: 0.022017\n",
      "2019-04-09 22:56:26,409 root         INFO     ====> Epoch: 69 Average loss: 0.4862\n",
      "2019-04-09 22:56:26,433 root         INFO     Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 0.605510\n",
      "Reconstruction: 0.583729, Regularization: 0.021781\n",
      "2019-04-09 22:56:26,490 root         INFO     Train Epoch: 70 [512/8000 (6%)]\tTotal Loss: 0.487579\n",
      "Reconstruction: 0.473615, Regularization: 0.013963\n",
      "2019-04-09 22:56:26,546 root         INFO     Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 0.426260\n",
      "Reconstruction: 0.406398, Regularization: 0.019861\n",
      "2019-04-09 22:56:26,602 root         INFO     Train Epoch: 70 [1536/8000 (19%)]\tTotal Loss: 0.492091\n",
      "Reconstruction: 0.472103, Regularization: 0.019988\n",
      "2019-04-09 22:56:26,658 root         INFO     Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 0.464409\n",
      "Reconstruction: 0.446650, Regularization: 0.017759\n",
      "2019-04-09 22:56:26,714 root         INFO     Train Epoch: 70 [2560/8000 (32%)]\tTotal Loss: 0.479364\n",
      "Reconstruction: 0.461392, Regularization: 0.017971\n",
      "2019-04-09 22:56:26,770 root         INFO     Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 0.423943\n",
      "Reconstruction: 0.406974, Regularization: 0.016969\n",
      "2019-04-09 22:56:26,826 root         INFO     Train Epoch: 70 [3584/8000 (45%)]\tTotal Loss: 0.434495\n",
      "Reconstruction: 0.419772, Regularization: 0.014723\n",
      "2019-04-09 22:56:26,882 root         INFO     Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 0.464621\n",
      "Reconstruction: 0.444388, Regularization: 0.020233\n",
      "2019-04-09 22:56:26,938 root         INFO     Train Epoch: 70 [4608/8000 (58%)]\tTotal Loss: 0.490358\n",
      "Reconstruction: 0.470604, Regularization: 0.019754\n",
      "2019-04-09 22:56:26,994 root         INFO     Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 3.975650\n",
      "Reconstruction: 3.938482, Regularization: 0.037168\n",
      "2019-04-09 22:56:27,050 root         INFO     Train Epoch: 70 [5632/8000 (70%)]\tTotal Loss: 0.412047\n",
      "Reconstruction: 0.395684, Regularization: 0.016363\n",
      "2019-04-09 22:56:27,106 root         INFO     Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 0.451436\n",
      "Reconstruction: 0.436821, Regularization: 0.014615\n",
      "2019-04-09 22:56:27,162 root         INFO     Train Epoch: 70 [6656/8000 (83%)]\tTotal Loss: 0.358026\n",
      "Reconstruction: 0.345809, Regularization: 0.012218\n",
      "2019-04-09 22:56:27,218 root         INFO     Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 0.333394\n",
      "Reconstruction: 0.320188, Regularization: 0.013206\n",
      "2019-04-09 22:56:27,274 root         INFO     Train Epoch: 70 [7680/8000 (96%)]\tTotal Loss: 0.366056\n",
      "Reconstruction: 0.351540, Regularization: 0.014516\n",
      "2019-04-09 22:56:27,324 root         INFO     ====> Epoch: 70 Average loss: 1.0833\n",
      "2019-04-09 22:56:27,347 root         INFO     Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 0.320538\n",
      "Reconstruction: 0.306486, Regularization: 0.014052\n",
      "2019-04-09 22:56:27,403 root         INFO     Train Epoch: 71 [512/8000 (6%)]\tTotal Loss: 0.491250\n",
      "Reconstruction: 0.474847, Regularization: 0.016402\n",
      "2019-04-09 22:56:27,458 root         INFO     Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 0.362450\n",
      "Reconstruction: 0.347314, Regularization: 0.015135\n",
      "2019-04-09 22:56:27,514 root         INFO     Train Epoch: 71 [1536/8000 (19%)]\tTotal Loss: 1.096297\n",
      "Reconstruction: 1.067243, Regularization: 0.029054\n",
      "2019-04-09 22:56:27,569 root         INFO     Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 0.463232\n",
      "Reconstruction: 0.446601, Regularization: 0.016631\n",
      "2019-04-09 22:56:27,625 root         INFO     Train Epoch: 71 [2560/8000 (32%)]\tTotal Loss: 0.323038\n",
      "Reconstruction: 0.310163, Regularization: 0.012876\n",
      "2019-04-09 22:56:27,680 root         INFO     Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 0.408922\n",
      "Reconstruction: 0.389408, Regularization: 0.019514\n",
      "2019-04-09 22:56:27,735 root         INFO     Train Epoch: 71 [3584/8000 (45%)]\tTotal Loss: 0.550694\n",
      "Reconstruction: 0.523757, Regularization: 0.026936\n",
      "2019-04-09 22:56:27,791 root         INFO     Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 0.445597\n",
      "Reconstruction: 0.420559, Regularization: 0.025038\n",
      "2019-04-09 22:56:27,847 root         INFO     Train Epoch: 71 [4608/8000 (58%)]\tTotal Loss: 0.619935\n",
      "Reconstruction: 0.590004, Regularization: 0.029931\n",
      "2019-04-09 22:56:27,902 root         INFO     Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 0.461666\n",
      "Reconstruction: 0.443218, Regularization: 0.018448\n",
      "2019-04-09 22:56:27,958 root         INFO     Train Epoch: 71 [5632/8000 (70%)]\tTotal Loss: 0.454408\n",
      "Reconstruction: 0.435583, Regularization: 0.018825\n",
      "2019-04-09 22:56:28,013 root         INFO     Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 0.427807\n",
      "Reconstruction: 0.408507, Regularization: 0.019301\n",
      "2019-04-09 22:56:28,068 root         INFO     Train Epoch: 71 [6656/8000 (83%)]\tTotal Loss: 0.375752\n",
      "Reconstruction: 0.360816, Regularization: 0.014936\n",
      "2019-04-09 22:56:28,123 root         INFO     Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 0.557118\n",
      "Reconstruction: 0.539149, Regularization: 0.017969\n",
      "2019-04-09 22:56:28,178 root         INFO     Train Epoch: 71 [7680/8000 (96%)]\tTotal Loss: 0.466117\n",
      "Reconstruction: 0.447620, Regularization: 0.018496\n",
      "2019-04-09 22:56:28,228 root         INFO     ====> Epoch: 71 Average loss: 0.4598\n",
      "2019-04-09 22:56:28,251 root         INFO     Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 0.413944\n",
      "Reconstruction: 0.398824, Regularization: 0.015120\n",
      "2019-04-09 22:56:28,308 root         INFO     Train Epoch: 72 [512/8000 (6%)]\tTotal Loss: 0.386458\n",
      "Reconstruction: 0.358417, Regularization: 0.028042\n",
      "2019-04-09 22:56:28,365 root         INFO     Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 0.447267\n",
      "Reconstruction: 0.430549, Regularization: 0.016717\n",
      "2019-04-09 22:56:28,421 root         INFO     Train Epoch: 72 [1536/8000 (19%)]\tTotal Loss: 0.440387\n",
      "Reconstruction: 0.420501, Regularization: 0.019885\n",
      "2019-04-09 22:56:28,478 root         INFO     Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 0.510996\n",
      "Reconstruction: 0.490226, Regularization: 0.020770\n",
      "2019-04-09 22:56:28,534 root         INFO     Train Epoch: 72 [2560/8000 (32%)]\tTotal Loss: 0.421602\n",
      "Reconstruction: 0.392373, Regularization: 0.029229\n",
      "2019-04-09 22:56:28,591 root         INFO     Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 0.399764\n",
      "Reconstruction: 0.382274, Regularization: 0.017490\n",
      "2019-04-09 22:56:28,647 root         INFO     Train Epoch: 72 [3584/8000 (45%)]\tTotal Loss: 0.390332\n",
      "Reconstruction: 0.371776, Regularization: 0.018557\n",
      "2019-04-09 22:56:28,703 root         INFO     Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 0.447084\n",
      "Reconstruction: 0.429532, Regularization: 0.017552\n",
      "2019-04-09 22:56:28,759 root         INFO     Train Epoch: 72 [4608/8000 (58%)]\tTotal Loss: 0.404406\n",
      "Reconstruction: 0.386668, Regularization: 0.017737\n",
      "2019-04-09 22:56:28,815 root         INFO     Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 0.457493\n",
      "Reconstruction: 0.441553, Regularization: 0.015940\n",
      "2019-04-09 22:56:28,871 root         INFO     Train Epoch: 72 [5632/8000 (70%)]\tTotal Loss: 0.370275\n",
      "Reconstruction: 0.356846, Regularization: 0.013429\n",
      "2019-04-09 22:56:28,926 root         INFO     Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 0.416041\n",
      "Reconstruction: 0.400933, Regularization: 0.015108\n",
      "2019-04-09 22:56:28,981 root         INFO     Train Epoch: 72 [6656/8000 (83%)]\tTotal Loss: 0.469134\n",
      "Reconstruction: 0.452983, Regularization: 0.016151\n",
      "2019-04-09 22:56:29,036 root         INFO     Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 0.422446\n",
      "Reconstruction: 0.405179, Regularization: 0.017266\n",
      "2019-04-09 22:56:29,092 root         INFO     Train Epoch: 72 [7680/8000 (96%)]\tTotal Loss: 0.439228\n",
      "Reconstruction: 0.419896, Regularization: 0.019332\n",
      "2019-04-09 22:56:29,140 root         INFO     ====> Epoch: 72 Average loss: 0.5474\n",
      "2019-04-09 22:56:29,164 root         INFO     Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 0.541443\n",
      "Reconstruction: 0.521567, Regularization: 0.019876\n",
      "2019-04-09 22:56:29,218 root         INFO     Train Epoch: 73 [512/8000 (6%)]\tTotal Loss: 0.474112\n",
      "Reconstruction: 0.457299, Regularization: 0.016813\n",
      "2019-04-09 22:56:29,273 root         INFO     Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 0.407934\n",
      "Reconstruction: 0.382381, Regularization: 0.025553\n",
      "2019-04-09 22:56:29,328 root         INFO     Train Epoch: 73 [1536/8000 (19%)]\tTotal Loss: 0.387198\n",
      "Reconstruction: 0.369662, Regularization: 0.017537\n",
      "2019-04-09 22:56:29,383 root         INFO     Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 0.486833\n",
      "Reconstruction: 0.466275, Regularization: 0.020558\n",
      "2019-04-09 22:56:29,438 root         INFO     Train Epoch: 73 [2560/8000 (32%)]\tTotal Loss: 0.420168\n",
      "Reconstruction: 0.394970, Regularization: 0.025199\n",
      "2019-04-09 22:56:29,493 root         INFO     Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 0.333529\n",
      "Reconstruction: 0.320112, Regularization: 0.013417\n",
      "2019-04-09 22:56:29,548 root         INFO     Train Epoch: 73 [3584/8000 (45%)]\tTotal Loss: 0.515257\n",
      "Reconstruction: 0.498365, Regularization: 0.016893\n",
      "2019-04-09 22:56:29,603 root         INFO     Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 0.480849\n",
      "Reconstruction: 0.461884, Regularization: 0.018965\n",
      "2019-04-09 22:56:29,658 root         INFO     Train Epoch: 73 [4608/8000 (58%)]\tTotal Loss: 0.483458\n",
      "Reconstruction: 0.463282, Regularization: 0.020176\n",
      "2019-04-09 22:56:29,712 root         INFO     Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 0.392310\n",
      "Reconstruction: 0.375527, Regularization: 0.016783\n",
      "2019-04-09 22:56:29,767 root         INFO     Train Epoch: 73 [5632/8000 (70%)]\tTotal Loss: 0.401611\n",
      "Reconstruction: 0.386796, Regularization: 0.014815\n",
      "2019-04-09 22:56:29,821 root         INFO     Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 0.388155\n",
      "Reconstruction: 0.375403, Regularization: 0.012752\n",
      "2019-04-09 22:56:29,876 root         INFO     Train Epoch: 73 [6656/8000 (83%)]\tTotal Loss: 0.348776\n",
      "Reconstruction: 0.332955, Regularization: 0.015821\n",
      "2019-04-09 22:56:29,931 root         INFO     Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 0.454672\n",
      "Reconstruction: 0.440185, Regularization: 0.014486\n",
      "2019-04-09 22:56:29,985 root         INFO     Train Epoch: 73 [7680/8000 (96%)]\tTotal Loss: 0.432172\n",
      "Reconstruction: 0.412972, Regularization: 0.019201\n",
      "2019-04-09 22:56:30,033 root         INFO     ====> Epoch: 73 Average loss: 0.4812\n",
      "2019-04-09 22:56:30,057 root         INFO     Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 0.409929\n",
      "Reconstruction: 0.393294, Regularization: 0.016635\n",
      "2019-04-09 22:56:30,112 root         INFO     Train Epoch: 74 [512/8000 (6%)]\tTotal Loss: 0.427925\n",
      "Reconstruction: 0.401665, Regularization: 0.026260\n",
      "2019-04-09 22:56:30,167 root         INFO     Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 0.362230\n",
      "Reconstruction: 0.349565, Regularization: 0.012665\n",
      "2019-04-09 22:56:30,222 root         INFO     Train Epoch: 74 [1536/8000 (19%)]\tTotal Loss: 0.361762\n",
      "Reconstruction: 0.345416, Regularization: 0.016346\n",
      "2019-04-09 22:56:30,277 root         INFO     Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 0.368982\n",
      "Reconstruction: 0.351677, Regularization: 0.017305\n",
      "2019-04-09 22:56:30,331 root         INFO     Train Epoch: 74 [2560/8000 (32%)]\tTotal Loss: 0.399429\n",
      "Reconstruction: 0.382904, Regularization: 0.016525\n",
      "2019-04-09 22:56:30,386 root         INFO     Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 0.580447\n",
      "Reconstruction: 0.558514, Regularization: 0.021933\n",
      "2019-04-09 22:56:30,441 root         INFO     Train Epoch: 74 [3584/8000 (45%)]\tTotal Loss: 0.406050\n",
      "Reconstruction: 0.390111, Regularization: 0.015940\n",
      "2019-04-09 22:56:30,496 root         INFO     Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 0.461835\n",
      "Reconstruction: 0.446254, Regularization: 0.015581\n",
      "2019-04-09 22:56:30,550 root         INFO     Train Epoch: 74 [4608/8000 (58%)]\tTotal Loss: 0.327473\n",
      "Reconstruction: 0.312305, Regularization: 0.015168\n",
      "2019-04-09 22:56:30,605 root         INFO     Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 0.321208\n",
      "Reconstruction: 0.304434, Regularization: 0.016774\n",
      "2019-04-09 22:56:30,660 root         INFO     Train Epoch: 74 [5632/8000 (70%)]\tTotal Loss: 0.414301\n",
      "Reconstruction: 0.393483, Regularization: 0.020818\n",
      "2019-04-09 22:56:30,716 root         INFO     Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 0.594971\n",
      "Reconstruction: 0.568046, Regularization: 0.026925\n",
      "2019-04-09 22:56:30,771 root         INFO     Train Epoch: 74 [6656/8000 (83%)]\tTotal Loss: 0.569131\n",
      "Reconstruction: 0.551666, Regularization: 0.017466\n",
      "2019-04-09 22:56:30,826 root         INFO     Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 0.497190\n",
      "Reconstruction: 0.449120, Regularization: 0.048070\n",
      "2019-04-09 22:56:30,881 root         INFO     Train Epoch: 74 [7680/8000 (96%)]\tTotal Loss: 0.436868\n",
      "Reconstruction: 0.420962, Regularization: 0.015907\n",
      "2019-04-09 22:56:30,930 root         INFO     ====> Epoch: 74 Average loss: 0.4990\n",
      "2019-04-09 22:56:30,953 root         INFO     Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 0.452212\n",
      "Reconstruction: 0.431451, Regularization: 0.020761\n",
      "2019-04-09 22:56:31,009 root         INFO     Train Epoch: 75 [512/8000 (6%)]\tTotal Loss: 0.477960\n",
      "Reconstruction: 0.460764, Regularization: 0.017196\n",
      "2019-04-09 22:56:31,065 root         INFO     Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 0.359526\n",
      "Reconstruction: 0.343148, Regularization: 0.016378\n",
      "2019-04-09 22:56:31,120 root         INFO     Train Epoch: 75 [1536/8000 (19%)]\tTotal Loss: 0.498859\n",
      "Reconstruction: 0.477517, Regularization: 0.021342\n",
      "2019-04-09 22:56:31,175 root         INFO     Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 0.349348\n",
      "Reconstruction: 0.333295, Regularization: 0.016053\n",
      "2019-04-09 22:56:31,231 root         INFO     Train Epoch: 75 [2560/8000 (32%)]\tTotal Loss: 0.408131\n",
      "Reconstruction: 0.393646, Regularization: 0.014485\n",
      "2019-04-09 22:56:31,286 root         INFO     Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 0.525172\n",
      "Reconstruction: 0.480679, Regularization: 0.044493\n",
      "2019-04-09 22:56:31,342 root         INFO     Train Epoch: 75 [3584/8000 (45%)]\tTotal Loss: 0.597697\n",
      "Reconstruction: 0.572935, Regularization: 0.024762\n",
      "2019-04-09 22:56:31,397 root         INFO     Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 0.503189\n",
      "Reconstruction: 0.486810, Regularization: 0.016379\n",
      "2019-04-09 22:56:31,452 root         INFO     Train Epoch: 75 [4608/8000 (58%)]\tTotal Loss: 0.422963\n",
      "Reconstruction: 0.405109, Regularization: 0.017854\n",
      "2019-04-09 22:56:31,507 root         INFO     Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 0.386958\n",
      "Reconstruction: 0.370615, Regularization: 0.016344\n",
      "2019-04-09 22:56:31,562 root         INFO     Train Epoch: 75 [5632/8000 (70%)]\tTotal Loss: 0.462831\n",
      "Reconstruction: 0.440406, Regularization: 0.022425\n",
      "2019-04-09 22:56:31,617 root         INFO     Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 0.457938\n",
      "Reconstruction: 0.434385, Regularization: 0.023553\n",
      "2019-04-09 22:56:31,672 root         INFO     Train Epoch: 75 [6656/8000 (83%)]\tTotal Loss: 0.497257\n",
      "Reconstruction: 0.477455, Regularization: 0.019802\n",
      "2019-04-09 22:56:31,727 root         INFO     Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 0.382581\n",
      "Reconstruction: 0.368132, Regularization: 0.014449\n",
      "2019-04-09 22:56:31,782 root         INFO     Train Epoch: 75 [7680/8000 (96%)]\tTotal Loss: 0.388156\n",
      "Reconstruction: 0.375019, Regularization: 0.013137\n",
      "2019-04-09 22:56:31,831 root         INFO     ====> Epoch: 75 Average loss: 42.5759\n",
      "2019-04-09 22:56:31,854 root         INFO     Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 0.415907\n",
      "Reconstruction: 0.390424, Regularization: 0.025483\n",
      "2019-04-09 22:56:31,910 root         INFO     Train Epoch: 76 [512/8000 (6%)]\tTotal Loss: 0.388537\n",
      "Reconstruction: 0.370552, Regularization: 0.017984\n",
      "2019-04-09 22:56:31,966 root         INFO     Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 0.449371\n",
      "Reconstruction: 0.422412, Regularization: 0.026959\n",
      "2019-04-09 22:56:32,022 root         INFO     Train Epoch: 76 [1536/8000 (19%)]\tTotal Loss: 0.380795\n",
      "Reconstruction: 0.364998, Regularization: 0.015797\n",
      "2019-04-09 22:56:32,078 root         INFO     Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 0.380042\n",
      "Reconstruction: 0.364069, Regularization: 0.015973\n",
      "2019-04-09 22:56:32,134 root         INFO     Train Epoch: 76 [2560/8000 (32%)]\tTotal Loss: 0.407972\n",
      "Reconstruction: 0.367551, Regularization: 0.040421\n",
      "2019-04-09 22:56:32,190 root         INFO     Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 0.373273\n",
      "Reconstruction: 0.358458, Regularization: 0.014815\n",
      "2019-04-09 22:56:32,246 root         INFO     Train Epoch: 76 [3584/8000 (45%)]\tTotal Loss: 0.371737\n",
      "Reconstruction: 0.358836, Regularization: 0.012901\n",
      "2019-04-09 22:56:32,302 root         INFO     Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 0.439204\n",
      "Reconstruction: 0.416384, Regularization: 0.022820\n",
      "2019-04-09 22:56:32,358 root         INFO     Train Epoch: 76 [4608/8000 (58%)]\tTotal Loss: 0.519136\n",
      "Reconstruction: 0.500171, Regularization: 0.018965\n",
      "2019-04-09 22:56:32,414 root         INFO     Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 0.491839\n",
      "Reconstruction: 0.471815, Regularization: 0.020024\n",
      "2019-04-09 22:56:32,468 root         INFO     Train Epoch: 76 [5632/8000 (70%)]\tTotal Loss: 0.437216\n",
      "Reconstruction: 0.421339, Regularization: 0.015877\n",
      "2019-04-09 22:56:32,522 root         INFO     Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 0.387507\n",
      "Reconstruction: 0.374757, Regularization: 0.012750\n",
      "2019-04-09 22:56:32,577 root         INFO     Train Epoch: 76 [6656/8000 (83%)]\tTotal Loss: 0.364355\n",
      "Reconstruction: 0.350791, Regularization: 0.013564\n",
      "2019-04-09 22:56:32,631 root         INFO     Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 0.376186\n",
      "Reconstruction: 0.359058, Regularization: 0.017128\n",
      "2019-04-09 22:56:32,686 root         INFO     Train Epoch: 76 [7680/8000 (96%)]\tTotal Loss: 0.373832\n",
      "Reconstruction: 0.359440, Regularization: 0.014392\n",
      "2019-04-09 22:56:32,734 root         INFO     ====> Epoch: 76 Average loss: 0.5307\n",
      "2019-04-09 22:56:32,758 root         INFO     Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 0.336564\n",
      "Reconstruction: 0.320216, Regularization: 0.016348\n",
      "2019-04-09 22:56:32,813 root         INFO     Train Epoch: 77 [512/8000 (6%)]\tTotal Loss: 0.479424\n",
      "Reconstruction: 0.460657, Regularization: 0.018767\n",
      "2019-04-09 22:56:32,868 root         INFO     Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 0.414008\n",
      "Reconstruction: 0.397466, Regularization: 0.016542\n",
      "2019-04-09 22:56:32,923 root         INFO     Train Epoch: 77 [1536/8000 (19%)]\tTotal Loss: 0.395094\n",
      "Reconstruction: 0.377254, Regularization: 0.017841\n",
      "2019-04-09 22:56:32,977 root         INFO     Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 0.336898\n",
      "Reconstruction: 0.323441, Regularization: 0.013457\n",
      "2019-04-09 22:56:33,032 root         INFO     Train Epoch: 77 [2560/8000 (32%)]\tTotal Loss: 0.463866\n",
      "Reconstruction: 0.446947, Regularization: 0.016919\n",
      "2019-04-09 22:56:33,087 root         INFO     Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 0.389099\n",
      "Reconstruction: 0.368209, Regularization: 0.020889\n",
      "2019-04-09 22:56:33,142 root         INFO     Train Epoch: 77 [3584/8000 (45%)]\tTotal Loss: 0.372778\n",
      "Reconstruction: 0.349070, Regularization: 0.023709\n",
      "2019-04-09 22:56:33,200 root         INFO     Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 0.479257\n",
      "Reconstruction: 0.461916, Regularization: 0.017341\n",
      "2019-04-09 22:56:33,257 root         INFO     Train Epoch: 77 [4608/8000 (58%)]\tTotal Loss: 0.457590\n",
      "Reconstruction: 0.429242, Regularization: 0.028348\n",
      "2019-04-09 22:56:33,315 root         INFO     Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 0.461596\n",
      "Reconstruction: 0.441295, Regularization: 0.020300\n",
      "2019-04-09 22:56:33,373 root         INFO     Train Epoch: 77 [5632/8000 (70%)]\tTotal Loss: 0.467841\n",
      "Reconstruction: 0.448047, Regularization: 0.019794\n",
      "2019-04-09 22:56:33,430 root         INFO     Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 0.394236\n",
      "Reconstruction: 0.373716, Regularization: 0.020520\n",
      "2019-04-09 22:56:33,488 root         INFO     Train Epoch: 77 [6656/8000 (83%)]\tTotal Loss: 0.366028\n",
      "Reconstruction: 0.347655, Regularization: 0.018373\n",
      "2019-04-09 22:56:33,546 root         INFO     Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 0.403030\n",
      "Reconstruction: 0.387498, Regularization: 0.015532\n",
      "2019-04-09 22:56:33,603 root         INFO     Train Epoch: 77 [7680/8000 (96%)]\tTotal Loss: 0.503771\n",
      "Reconstruction: 0.479464, Regularization: 0.024307\n",
      "2019-04-09 22:56:33,654 root         INFO     ====> Epoch: 77 Average loss: 0.5419\n",
      "2019-04-09 22:56:33,677 root         INFO     Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 0.580054\n",
      "Reconstruction: 0.544567, Regularization: 0.035487\n",
      "2019-04-09 22:56:33,734 root         INFO     Train Epoch: 78 [512/8000 (6%)]\tTotal Loss: 0.349641\n",
      "Reconstruction: 0.332079, Regularization: 0.017562\n",
      "2019-04-09 22:56:33,790 root         INFO     Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 0.437052\n",
      "Reconstruction: 0.417338, Regularization: 0.019715\n",
      "2019-04-09 22:56:33,847 root         INFO     Train Epoch: 78 [1536/8000 (19%)]\tTotal Loss: 0.423465\n",
      "Reconstruction: 0.407323, Regularization: 0.016142\n",
      "2019-04-09 22:56:33,904 root         INFO     Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 0.389133\n",
      "Reconstruction: 0.372317, Regularization: 0.016816\n",
      "2019-04-09 22:56:33,961 root         INFO     Train Epoch: 78 [2560/8000 (32%)]\tTotal Loss: 0.487055\n",
      "Reconstruction: 0.470337, Regularization: 0.016718\n",
      "2019-04-09 22:56:34,018 root         INFO     Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 0.368613\n",
      "Reconstruction: 0.354765, Regularization: 0.013849\n",
      "2019-04-09 22:56:34,074 root         INFO     Train Epoch: 78 [3584/8000 (45%)]\tTotal Loss: 0.427775\n",
      "Reconstruction: 0.400526, Regularization: 0.027249\n",
      "2019-04-09 22:56:34,131 root         INFO     Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 0.519303\n",
      "Reconstruction: 0.499968, Regularization: 0.019335\n",
      "2019-04-09 22:56:34,187 root         INFO     Train Epoch: 78 [4608/8000 (58%)]\tTotal Loss: 0.369197\n",
      "Reconstruction: 0.347707, Regularization: 0.021490\n",
      "2019-04-09 22:56:34,244 root         INFO     Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 2.072929\n",
      "Reconstruction: 2.054894, Regularization: 0.018035\n",
      "2019-04-09 22:56:34,301 root         INFO     Train Epoch: 78 [5632/8000 (70%)]\tTotal Loss: 0.708105\n",
      "Reconstruction: 0.665260, Regularization: 0.042845\n",
      "2019-04-09 22:56:34,358 root         INFO     Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 0.522819\n",
      "Reconstruction: 0.498198, Regularization: 0.024621\n",
      "2019-04-09 22:56:34,414 root         INFO     Train Epoch: 78 [6656/8000 (83%)]\tTotal Loss: 0.403892\n",
      "Reconstruction: 0.386288, Regularization: 0.017604\n",
      "2019-04-09 22:56:34,471 root         INFO     Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 0.351107\n",
      "Reconstruction: 0.330041, Regularization: 0.021067\n",
      "2019-04-09 22:56:34,526 root         INFO     Train Epoch: 78 [7680/8000 (96%)]\tTotal Loss: 0.407009\n",
      "Reconstruction: 0.393052, Regularization: 0.013956\n",
      "2019-04-09 22:56:34,575 root         INFO     ====> Epoch: 78 Average loss: 0.4546\n",
      "2019-04-09 22:56:34,598 root         INFO     Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 64.666931\n",
      "Reconstruction: 64.643150, Regularization: 0.023784\n",
      "2019-04-09 22:56:34,654 root         INFO     Train Epoch: 79 [512/8000 (6%)]\tTotal Loss: 0.500832\n",
      "Reconstruction: 0.479785, Regularization: 0.021047\n",
      "2019-04-09 22:56:34,710 root         INFO     Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 0.341657\n",
      "Reconstruction: 0.327576, Regularization: 0.014081\n",
      "2019-04-09 22:56:34,766 root         INFO     Train Epoch: 79 [1536/8000 (19%)]\tTotal Loss: 0.438122\n",
      "Reconstruction: 0.424326, Regularization: 0.013796\n",
      "2019-04-09 22:56:34,821 root         INFO     Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 0.441863\n",
      "Reconstruction: 0.420978, Regularization: 0.020884\n",
      "2019-04-09 22:56:34,875 root         INFO     Train Epoch: 79 [2560/8000 (32%)]\tTotal Loss: 0.350349\n",
      "Reconstruction: 0.337342, Regularization: 0.013007\n",
      "2019-04-09 22:56:34,930 root         INFO     Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 0.368484\n",
      "Reconstruction: 0.349447, Regularization: 0.019037\n",
      "2019-04-09 22:56:34,984 root         INFO     Train Epoch: 79 [3584/8000 (45%)]\tTotal Loss: 0.413529\n",
      "Reconstruction: 0.393669, Regularization: 0.019860\n",
      "2019-04-09 22:56:35,039 root         INFO     Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 0.431486\n",
      "Reconstruction: 0.398456, Regularization: 0.033030\n",
      "2019-04-09 22:56:35,093 root         INFO     Train Epoch: 79 [4608/8000 (58%)]\tTotal Loss: 0.363344\n",
      "Reconstruction: 0.338596, Regularization: 0.024748\n",
      "2019-04-09 22:56:35,147 root         INFO     Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 0.467804\n",
      "Reconstruction: 0.451410, Regularization: 0.016394\n",
      "2019-04-09 22:56:35,203 root         INFO     Train Epoch: 79 [5632/8000 (70%)]\tTotal Loss: 0.526968\n",
      "Reconstruction: 0.506775, Regularization: 0.020193\n",
      "2019-04-09 22:56:35,259 root         INFO     Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 0.450778\n",
      "Reconstruction: 0.434442, Regularization: 0.016336\n",
      "2019-04-09 22:56:35,315 root         INFO     Train Epoch: 79 [6656/8000 (83%)]\tTotal Loss: 0.302668\n",
      "Reconstruction: 0.291130, Regularization: 0.011538\n",
      "2019-04-09 22:56:35,371 root         INFO     Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 0.395010\n",
      "Reconstruction: 0.369363, Regularization: 0.025646\n",
      "2019-04-09 22:56:35,427 root         INFO     Train Epoch: 79 [7680/8000 (96%)]\tTotal Loss: 0.355162\n",
      "Reconstruction: 0.339073, Regularization: 0.016089\n",
      "2019-04-09 22:56:35,477 root         INFO     ====> Epoch: 79 Average loss: 0.7085\n",
      "2019-04-09 22:56:35,500 root         INFO     Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 0.387816\n",
      "Reconstruction: 0.365561, Regularization: 0.022256\n",
      "2019-04-09 22:56:35,557 root         INFO     Train Epoch: 80 [512/8000 (6%)]\tTotal Loss: 0.500578\n",
      "Reconstruction: 0.480683, Regularization: 0.019895\n",
      "2019-04-09 22:56:35,613 root         INFO     Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 0.429010\n",
      "Reconstruction: 0.411547, Regularization: 0.017464\n",
      "2019-04-09 22:56:35,670 root         INFO     Train Epoch: 80 [1536/8000 (19%)]\tTotal Loss: 0.446779\n",
      "Reconstruction: 0.423705, Regularization: 0.023074\n",
      "2019-04-09 22:56:35,727 root         INFO     Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 0.485208\n",
      "Reconstruction: 0.463910, Regularization: 0.021298\n",
      "2019-04-09 22:56:35,784 root         INFO     Train Epoch: 80 [2560/8000 (32%)]\tTotal Loss: 0.436582\n",
      "Reconstruction: 0.420628, Regularization: 0.015954\n",
      "2019-04-09 22:56:35,841 root         INFO     Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 0.399295\n",
      "Reconstruction: 0.374468, Regularization: 0.024826\n",
      "2019-04-09 22:56:35,898 root         INFO     Train Epoch: 80 [3584/8000 (45%)]\tTotal Loss: 0.547118\n",
      "Reconstruction: 0.522024, Regularization: 0.025094\n",
      "2019-04-09 22:56:35,955 root         INFO     Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 0.435929\n",
      "Reconstruction: 0.413804, Regularization: 0.022125\n",
      "2019-04-09 22:56:36,012 root         INFO     Train Epoch: 80 [4608/8000 (58%)]\tTotal Loss: 0.454222\n",
      "Reconstruction: 0.440851, Regularization: 0.013372\n",
      "2019-04-09 22:56:36,068 root         INFO     Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 0.335584\n",
      "Reconstruction: 0.314620, Regularization: 0.020964\n",
      "2019-04-09 22:56:36,125 root         INFO     Train Epoch: 80 [5632/8000 (70%)]\tTotal Loss: 0.467425\n",
      "Reconstruction: 0.450711, Regularization: 0.016715\n",
      "2019-04-09 22:56:36,182 root         INFO     Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 0.526945\n",
      "Reconstruction: 0.499013, Regularization: 0.027932\n",
      "2019-04-09 22:56:36,239 root         INFO     Train Epoch: 80 [6656/8000 (83%)]\tTotal Loss: 0.412704\n",
      "Reconstruction: 0.397277, Regularization: 0.015427\n",
      "2019-04-09 22:56:36,297 root         INFO     Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 0.414295\n",
      "Reconstruction: 0.397641, Regularization: 0.016654\n",
      "2019-04-09 22:56:36,353 root         INFO     Train Epoch: 80 [7680/8000 (96%)]\tTotal Loss: 0.473892\n",
      "Reconstruction: 0.456903, Regularization: 0.016990\n",
      "2019-04-09 22:56:36,404 root         INFO     ====> Epoch: 80 Average loss: 0.4611\n",
      "2019-04-09 22:56:36,427 root         INFO     Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 0.384165\n",
      "Reconstruction: 0.355957, Regularization: 0.028208\n",
      "2019-04-09 22:56:36,484 root         INFO     Train Epoch: 81 [512/8000 (6%)]\tTotal Loss: 0.395800\n",
      "Reconstruction: 0.374777, Regularization: 0.021023\n",
      "2019-04-09 22:56:36,541 root         INFO     Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 0.367884\n",
      "Reconstruction: 0.347874, Regularization: 0.020010\n",
      "2019-04-09 22:56:36,598 root         INFO     Train Epoch: 81 [1536/8000 (19%)]\tTotal Loss: 0.569494\n",
      "Reconstruction: 0.549045, Regularization: 0.020448\n",
      "2019-04-09 22:56:36,655 root         INFO     Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 0.420800\n",
      "Reconstruction: 0.402540, Regularization: 0.018261\n",
      "2019-04-09 22:56:36,711 root         INFO     Train Epoch: 81 [2560/8000 (32%)]\tTotal Loss: 0.476044\n",
      "Reconstruction: 0.459964, Regularization: 0.016080\n",
      "2019-04-09 22:56:36,768 root         INFO     Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 0.464535\n",
      "Reconstruction: 0.438843, Regularization: 0.025692\n",
      "2019-04-09 22:56:36,825 root         INFO     Train Epoch: 81 [3584/8000 (45%)]\tTotal Loss: 0.478052\n",
      "Reconstruction: 0.460046, Regularization: 0.018006\n",
      "2019-04-09 22:56:36,882 root         INFO     Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 0.443354\n",
      "Reconstruction: 0.427969, Regularization: 0.015385\n",
      "2019-04-09 22:56:36,939 root         INFO     Train Epoch: 81 [4608/8000 (58%)]\tTotal Loss: 0.479708\n",
      "Reconstruction: 0.460505, Regularization: 0.019203\n",
      "2019-04-09 22:56:36,995 root         INFO     Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 0.376489\n",
      "Reconstruction: 0.362635, Regularization: 0.013854\n",
      "2019-04-09 22:56:37,052 root         INFO     Train Epoch: 81 [5632/8000 (70%)]\tTotal Loss: 0.419856\n",
      "Reconstruction: 0.401730, Regularization: 0.018125\n",
      "2019-04-09 22:56:37,108 root         INFO     Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 0.337348\n",
      "Reconstruction: 0.309501, Regularization: 0.027847\n",
      "2019-04-09 22:56:37,165 root         INFO     Train Epoch: 81 [6656/8000 (83%)]\tTotal Loss: 0.381617\n",
      "Reconstruction: 0.361305, Regularization: 0.020313\n",
      "2019-04-09 22:56:37,221 root         INFO     Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 0.769586\n",
      "Reconstruction: 0.748887, Regularization: 0.020699\n",
      "2019-04-09 22:56:37,278 root         INFO     Train Epoch: 81 [7680/8000 (96%)]\tTotal Loss: 0.509508\n",
      "Reconstruction: 0.494421, Regularization: 0.015087\n",
      "2019-04-09 22:56:37,328 root         INFO     ====> Epoch: 81 Average loss: 0.4605\n",
      "2019-04-09 22:56:37,351 root         INFO     Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 0.450009\n",
      "Reconstruction: 0.428894, Regularization: 0.021115\n",
      "2019-04-09 22:56:37,408 root         INFO     Train Epoch: 82 [512/8000 (6%)]\tTotal Loss: 0.366133\n",
      "Reconstruction: 0.348583, Regularization: 0.017550\n",
      "2019-04-09 22:56:37,465 root         INFO     Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 0.335999\n",
      "Reconstruction: 0.322080, Regularization: 0.013919\n",
      "2019-04-09 22:56:37,522 root         INFO     Train Epoch: 82 [1536/8000 (19%)]\tTotal Loss: 0.416367\n",
      "Reconstruction: 0.397898, Regularization: 0.018469\n",
      "2019-04-09 22:56:37,579 root         INFO     Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 0.446145\n",
      "Reconstruction: 0.429932, Regularization: 0.016213\n",
      "2019-04-09 22:56:37,637 root         INFO     Train Epoch: 82 [2560/8000 (32%)]\tTotal Loss: 0.304580\n",
      "Reconstruction: 0.280577, Regularization: 0.024002\n",
      "2019-04-09 22:56:37,695 root         INFO     Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 0.418442\n",
      "Reconstruction: 0.397205, Regularization: 0.021237\n",
      "2019-04-09 22:56:37,752 root         INFO     Train Epoch: 82 [3584/8000 (45%)]\tTotal Loss: 0.386909\n",
      "Reconstruction: 0.371945, Regularization: 0.014965\n",
      "2019-04-09 22:56:37,808 root         INFO     Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 0.429360\n",
      "Reconstruction: 0.413171, Regularization: 0.016189\n",
      "2019-04-09 22:56:37,863 root         INFO     Train Epoch: 82 [4608/8000 (58%)]\tTotal Loss: 0.431415\n",
      "Reconstruction: 0.415070, Regularization: 0.016345\n",
      "2019-04-09 22:56:37,919 root         INFO     Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 0.434877\n",
      "Reconstruction: 0.419451, Regularization: 0.015426\n",
      "2019-04-09 22:56:37,974 root         INFO     Train Epoch: 82 [5632/8000 (70%)]\tTotal Loss: 1.600168\n",
      "Reconstruction: 1.579043, Regularization: 0.021125\n",
      "2019-04-09 22:56:38,029 root         INFO     Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 0.349668\n",
      "Reconstruction: 0.338288, Regularization: 0.011379\n",
      "2019-04-09 22:56:38,084 root         INFO     Train Epoch: 82 [6656/8000 (83%)]\tTotal Loss: 0.413030\n",
      "Reconstruction: 0.397218, Regularization: 0.015813\n",
      "2019-04-09 22:56:38,138 root         INFO     Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 0.379725\n",
      "Reconstruction: 0.365959, Regularization: 0.013767\n",
      "2019-04-09 22:56:38,193 root         INFO     Train Epoch: 82 [7680/8000 (96%)]\tTotal Loss: 0.409167\n",
      "Reconstruction: 0.393936, Regularization: 0.015232\n",
      "2019-04-09 22:56:38,242 root         INFO     ====> Epoch: 82 Average loss: 0.5179\n",
      "2019-04-09 22:56:38,266 root         INFO     Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 0.399101\n",
      "Reconstruction: 0.360193, Regularization: 0.038908\n",
      "2019-04-09 22:56:38,323 root         INFO     Train Epoch: 83 [512/8000 (6%)]\tTotal Loss: 0.509596\n",
      "Reconstruction: 0.476839, Regularization: 0.032757\n",
      "2019-04-09 22:56:38,380 root         INFO     Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 0.371925\n",
      "Reconstruction: 0.357073, Regularization: 0.014852\n",
      "2019-04-09 22:56:38,437 root         INFO     Train Epoch: 83 [1536/8000 (19%)]\tTotal Loss: 0.409737\n",
      "Reconstruction: 0.392531, Regularization: 0.017206\n",
      "2019-04-09 22:56:38,494 root         INFO     Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 0.433862\n",
      "Reconstruction: 0.413908, Regularization: 0.019953\n",
      "2019-04-09 22:56:38,552 root         INFO     Train Epoch: 83 [2560/8000 (32%)]\tTotal Loss: 0.413045\n",
      "Reconstruction: 0.397325, Regularization: 0.015719\n",
      "2019-04-09 22:56:38,608 root         INFO     Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 0.450664\n",
      "Reconstruction: 0.426398, Regularization: 0.024266\n",
      "2019-04-09 22:56:38,665 root         INFO     Train Epoch: 83 [3584/8000 (45%)]\tTotal Loss: 0.351731\n",
      "Reconstruction: 0.334090, Regularization: 0.017640\n",
      "2019-04-09 22:56:38,722 root         INFO     Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 0.506599\n",
      "Reconstruction: 0.491106, Regularization: 0.015493\n",
      "2019-04-09 22:56:38,779 root         INFO     Train Epoch: 83 [4608/8000 (58%)]\tTotal Loss: 0.535711\n",
      "Reconstruction: 0.521082, Regularization: 0.014630\n",
      "2019-04-09 22:56:38,836 root         INFO     Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 0.294913\n",
      "Reconstruction: 0.278491, Regularization: 0.016422\n",
      "2019-04-09 22:56:38,892 root         INFO     Train Epoch: 83 [5632/8000 (70%)]\tTotal Loss: 0.333542\n",
      "Reconstruction: 0.317734, Regularization: 0.015808\n",
      "2019-04-09 22:56:38,949 root         INFO     Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 0.455050\n",
      "Reconstruction: 0.437146, Regularization: 0.017904\n",
      "2019-04-09 22:56:39,006 root         INFO     Train Epoch: 83 [6656/8000 (83%)]\tTotal Loss: 0.270839\n",
      "Reconstruction: 0.259394, Regularization: 0.011445\n",
      "2019-04-09 22:56:39,063 root         INFO     Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 0.483086\n",
      "Reconstruction: 0.462434, Regularization: 0.020652\n",
      "2019-04-09 22:56:39,120 root         INFO     Train Epoch: 83 [7680/8000 (96%)]\tTotal Loss: 0.503015\n",
      "Reconstruction: 0.475684, Regularization: 0.027331\n",
      "2019-04-09 22:56:39,170 root         INFO     ====> Epoch: 83 Average loss: 0.5354\n",
      "2019-04-09 22:56:39,193 root         INFO     Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 0.531006\n",
      "Reconstruction: 0.515172, Regularization: 0.015834\n",
      "2019-04-09 22:56:39,250 root         INFO     Train Epoch: 84 [512/8000 (6%)]\tTotal Loss: 0.434394\n",
      "Reconstruction: 0.421241, Regularization: 0.013153\n",
      "2019-04-09 22:56:39,306 root         INFO     Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 0.405989\n",
      "Reconstruction: 0.388544, Regularization: 0.017445\n",
      "2019-04-09 22:56:39,363 root         INFO     Train Epoch: 84 [1536/8000 (19%)]\tTotal Loss: 0.439293\n",
      "Reconstruction: 0.425935, Regularization: 0.013359\n",
      "2019-04-09 22:56:39,420 root         INFO     Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 0.397718\n",
      "Reconstruction: 0.378009, Regularization: 0.019709\n",
      "2019-04-09 22:56:39,477 root         INFO     Train Epoch: 84 [2560/8000 (32%)]\tTotal Loss: 0.353990\n",
      "Reconstruction: 0.334495, Regularization: 0.019495\n",
      "2019-04-09 22:56:39,533 root         INFO     Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 0.392450\n",
      "Reconstruction: 0.379525, Regularization: 0.012925\n",
      "2019-04-09 22:56:39,590 root         INFO     Train Epoch: 84 [3584/8000 (45%)]\tTotal Loss: 0.372364\n",
      "Reconstruction: 0.352459, Regularization: 0.019905\n",
      "2019-04-09 22:56:39,647 root         INFO     Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 0.423073\n",
      "Reconstruction: 0.402339, Regularization: 0.020734\n",
      "2019-04-09 22:56:39,703 root         INFO     Train Epoch: 84 [4608/8000 (58%)]\tTotal Loss: 0.399742\n",
      "Reconstruction: 0.384742, Regularization: 0.015001\n",
      "2019-04-09 22:56:39,759 root         INFO     Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 0.398657\n",
      "Reconstruction: 0.383000, Regularization: 0.015657\n",
      "2019-04-09 22:56:39,817 root         INFO     Train Epoch: 84 [5632/8000 (70%)]\tTotal Loss: 0.384543\n",
      "Reconstruction: 0.365691, Regularization: 0.018852\n",
      "2019-04-09 22:56:39,873 root         INFO     Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 0.706926\n",
      "Reconstruction: 0.685105, Regularization: 0.021820\n",
      "2019-04-09 22:56:39,928 root         INFO     Train Epoch: 84 [6656/8000 (83%)]\tTotal Loss: 0.407674\n",
      "Reconstruction: 0.390195, Regularization: 0.017480\n",
      "2019-04-09 22:56:39,984 root         INFO     Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 0.370419\n",
      "Reconstruction: 0.355522, Regularization: 0.014898\n",
      "2019-04-09 22:56:40,039 root         INFO     Train Epoch: 84 [7680/8000 (96%)]\tTotal Loss: 0.446314\n",
      "Reconstruction: 0.424421, Regularization: 0.021893\n",
      "2019-04-09 22:56:40,088 root         INFO     ====> Epoch: 84 Average loss: 0.4902\n",
      "2019-04-09 22:56:40,111 root         INFO     Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 0.506910\n",
      "Reconstruction: 0.489944, Regularization: 0.016965\n",
      "2019-04-09 22:56:40,168 root         INFO     Train Epoch: 85 [512/8000 (6%)]\tTotal Loss: 0.361480\n",
      "Reconstruction: 0.337999, Regularization: 0.023481\n",
      "2019-04-09 22:56:40,224 root         INFO     Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 0.501304\n",
      "Reconstruction: 0.482002, Regularization: 0.019301\n",
      "2019-04-09 22:56:40,281 root         INFO     Train Epoch: 85 [1536/8000 (19%)]\tTotal Loss: 0.478322\n",
      "Reconstruction: 0.457495, Regularization: 0.020827\n",
      "2019-04-09 22:56:40,338 root         INFO     Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 0.385659\n",
      "Reconstruction: 0.363591, Regularization: 0.022068\n",
      "2019-04-09 22:56:40,395 root         INFO     Train Epoch: 85 [2560/8000 (32%)]\tTotal Loss: 0.316373\n",
      "Reconstruction: 0.304057, Regularization: 0.012316\n",
      "2019-04-09 22:56:40,451 root         INFO     Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 1.079618\n",
      "Reconstruction: 1.066471, Regularization: 0.013147\n",
      "2019-04-09 22:56:40,508 root         INFO     Train Epoch: 85 [3584/8000 (45%)]\tTotal Loss: 0.385518\n",
      "Reconstruction: 0.369257, Regularization: 0.016261\n",
      "2019-04-09 22:56:40,565 root         INFO     Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 0.481644\n",
      "Reconstruction: 0.448924, Regularization: 0.032720\n",
      "2019-04-09 22:56:40,621 root         INFO     Train Epoch: 85 [4608/8000 (58%)]\tTotal Loss: 0.335646\n",
      "Reconstruction: 0.317519, Regularization: 0.018127\n",
      "2019-04-09 22:56:40,678 root         INFO     Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 0.417913\n",
      "Reconstruction: 0.398720, Regularization: 0.019193\n",
      "2019-04-09 22:56:40,734 root         INFO     Train Epoch: 85 [5632/8000 (70%)]\tTotal Loss: 0.458188\n",
      "Reconstruction: 0.441580, Regularization: 0.016608\n",
      "2019-04-09 22:56:40,791 root         INFO     Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 0.488279\n",
      "Reconstruction: 0.467312, Regularization: 0.020967\n",
      "2019-04-09 22:56:40,848 root         INFO     Train Epoch: 85 [6656/8000 (83%)]\tTotal Loss: 0.357862\n",
      "Reconstruction: 0.337472, Regularization: 0.020390\n",
      "2019-04-09 22:56:40,904 root         INFO     Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 0.425475\n",
      "Reconstruction: 0.408498, Regularization: 0.016977\n",
      "2019-04-09 22:56:40,961 root         INFO     Train Epoch: 85 [7680/8000 (96%)]\tTotal Loss: 0.836477\n",
      "Reconstruction: 0.801925, Regularization: 0.034552\n",
      "2019-04-09 22:56:41,009 root         INFO     ====> Epoch: 85 Average loss: 6.5502\n",
      "2019-04-09 22:56:41,033 root         INFO     Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 0.491954\n",
      "Reconstruction: 0.470850, Regularization: 0.021104\n",
      "2019-04-09 22:56:41,089 root         INFO     Train Epoch: 86 [512/8000 (6%)]\tTotal Loss: 0.534990\n",
      "Reconstruction: 0.516847, Regularization: 0.018143\n",
      "2019-04-09 22:56:41,144 root         INFO     Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 0.462880\n",
      "Reconstruction: 0.445864, Regularization: 0.017015\n",
      "2019-04-09 22:56:41,200 root         INFO     Train Epoch: 86 [1536/8000 (19%)]\tTotal Loss: 0.384127\n",
      "Reconstruction: 0.366411, Regularization: 0.017715\n",
      "2019-04-09 22:56:41,256 root         INFO     Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 0.453852\n",
      "Reconstruction: 0.438250, Regularization: 0.015602\n",
      "2019-04-09 22:56:41,311 root         INFO     Train Epoch: 86 [2560/8000 (32%)]\tTotal Loss: 0.386314\n",
      "Reconstruction: 0.371078, Regularization: 0.015236\n",
      "2019-04-09 22:56:41,367 root         INFO     Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 0.469781\n",
      "Reconstruction: 0.451378, Regularization: 0.018403\n",
      "2019-04-09 22:56:41,422 root         INFO     Train Epoch: 86 [3584/8000 (45%)]\tTotal Loss: 0.465884\n",
      "Reconstruction: 0.447628, Regularization: 0.018256\n",
      "2019-04-09 22:56:41,478 root         INFO     Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 0.552542\n",
      "Reconstruction: 0.534673, Regularization: 0.017869\n",
      "2019-04-09 22:56:41,534 root         INFO     Train Epoch: 86 [4608/8000 (58%)]\tTotal Loss: 0.517581\n",
      "Reconstruction: 0.498828, Regularization: 0.018753\n",
      "2019-04-09 22:56:41,589 root         INFO     Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 7.680126\n",
      "Reconstruction: 7.655324, Regularization: 0.024802\n",
      "2019-04-09 22:56:41,645 root         INFO     Train Epoch: 86 [5632/8000 (70%)]\tTotal Loss: 0.357276\n",
      "Reconstruction: 0.343264, Regularization: 0.014011\n",
      "2019-04-09 22:56:41,701 root         INFO     Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 0.361023\n",
      "Reconstruction: 0.346964, Regularization: 0.014059\n",
      "2019-04-09 22:56:41,756 root         INFO     Train Epoch: 86 [6656/8000 (83%)]\tTotal Loss: 0.767070\n",
      "Reconstruction: 0.724582, Regularization: 0.042488\n",
      "2019-04-09 22:56:41,811 root         INFO     Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 0.353918\n",
      "Reconstruction: 0.334610, Regularization: 0.019308\n",
      "2019-04-09 22:56:41,866 root         INFO     Train Epoch: 86 [7680/8000 (96%)]\tTotal Loss: 0.491489\n",
      "Reconstruction: 0.473775, Regularization: 0.017715\n",
      "2019-04-09 22:56:41,915 root         INFO     ====> Epoch: 86 Average loss: 0.4795\n",
      "2019-04-09 22:56:41,938 root         INFO     Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 0.371490\n",
      "Reconstruction: 0.358284, Regularization: 0.013206\n",
      "2019-04-09 22:56:41,993 root         INFO     Train Epoch: 87 [512/8000 (6%)]\tTotal Loss: 0.567001\n",
      "Reconstruction: 0.539586, Regularization: 0.027415\n",
      "2019-04-09 22:56:42,049 root         INFO     Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 0.432306\n",
      "Reconstruction: 0.409813, Regularization: 0.022493\n",
      "2019-04-09 22:56:42,105 root         INFO     Train Epoch: 87 [1536/8000 (19%)]\tTotal Loss: 0.365327\n",
      "Reconstruction: 0.351374, Regularization: 0.013953\n",
      "2019-04-09 22:56:42,160 root         INFO     Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 0.400904\n",
      "Reconstruction: 0.379683, Regularization: 0.021221\n",
      "2019-04-09 22:56:42,215 root         INFO     Train Epoch: 87 [2560/8000 (32%)]\tTotal Loss: 0.447248\n",
      "Reconstruction: 0.429067, Regularization: 0.018180\n",
      "2019-04-09 22:56:42,270 root         INFO     Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 0.531501\n",
      "Reconstruction: 0.505474, Regularization: 0.026027\n",
      "2019-04-09 22:56:42,325 root         INFO     Train Epoch: 87 [3584/8000 (45%)]\tTotal Loss: 0.700248\n",
      "Reconstruction: 0.684075, Regularization: 0.016173\n",
      "2019-04-09 22:56:42,380 root         INFO     Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 0.368121\n",
      "Reconstruction: 0.350004, Regularization: 0.018117\n",
      "2019-04-09 22:56:42,435 root         INFO     Train Epoch: 87 [4608/8000 (58%)]\tTotal Loss: 0.477816\n",
      "Reconstruction: 0.462249, Regularization: 0.015567\n",
      "2019-04-09 22:56:42,490 root         INFO     Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 2.150828\n",
      "Reconstruction: 2.127956, Regularization: 0.022872\n",
      "2019-04-09 22:56:42,545 root         INFO     Train Epoch: 87 [5632/8000 (70%)]\tTotal Loss: 0.456818\n",
      "Reconstruction: 0.439745, Regularization: 0.017073\n",
      "2019-04-09 22:56:42,600 root         INFO     Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 0.281452\n",
      "Reconstruction: 0.268836, Regularization: 0.012616\n",
      "2019-04-09 22:56:42,655 root         INFO     Train Epoch: 87 [6656/8000 (83%)]\tTotal Loss: 0.409481\n",
      "Reconstruction: 0.396169, Regularization: 0.013312\n",
      "2019-04-09 22:56:42,710 root         INFO     Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 0.394969\n",
      "Reconstruction: 0.364736, Regularization: 0.030234\n",
      "2019-04-09 22:56:42,766 root         INFO     Train Epoch: 87 [7680/8000 (96%)]\tTotal Loss: 0.496957\n",
      "Reconstruction: 0.474172, Regularization: 0.022785\n",
      "2019-04-09 22:56:42,815 root         INFO     ====> Epoch: 87 Average loss: 0.4899\n",
      "2019-04-09 22:56:42,838 root         INFO     Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 0.400132\n",
      "Reconstruction: 0.385021, Regularization: 0.015110\n",
      "2019-04-09 22:56:42,896 root         INFO     Train Epoch: 88 [512/8000 (6%)]\tTotal Loss: 0.388546\n",
      "Reconstruction: 0.356728, Regularization: 0.031818\n",
      "2019-04-09 22:56:42,953 root         INFO     Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 0.415562\n",
      "Reconstruction: 0.395403, Regularization: 0.020159\n",
      "2019-04-09 22:56:43,010 root         INFO     Train Epoch: 88 [1536/8000 (19%)]\tTotal Loss: 0.363096\n",
      "Reconstruction: 0.347107, Regularization: 0.015989\n",
      "2019-04-09 22:56:43,067 root         INFO     Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 0.521977\n",
      "Reconstruction: 0.504184, Regularization: 0.017793\n",
      "2019-04-09 22:56:43,123 root         INFO     Train Epoch: 88 [2560/8000 (32%)]\tTotal Loss: 0.403728\n",
      "Reconstruction: 0.388159, Regularization: 0.015569\n",
      "2019-04-09 22:56:43,180 root         INFO     Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 0.393913\n",
      "Reconstruction: 0.379994, Regularization: 0.013918\n",
      "2019-04-09 22:56:43,237 root         INFO     Train Epoch: 88 [3584/8000 (45%)]\tTotal Loss: 0.474664\n",
      "Reconstruction: 0.456347, Regularization: 0.018318\n",
      "2019-04-09 22:56:43,293 root         INFO     Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 0.509951\n",
      "Reconstruction: 0.495647, Regularization: 0.014304\n",
      "2019-04-09 22:56:43,350 root         INFO     Train Epoch: 88 [4608/8000 (58%)]\tTotal Loss: 0.348269\n",
      "Reconstruction: 0.333344, Regularization: 0.014925\n",
      "2019-04-09 22:56:43,406 root         INFO     Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 0.493125\n",
      "Reconstruction: 0.474037, Regularization: 0.019087\n",
      "2019-04-09 22:56:43,463 root         INFO     Train Epoch: 88 [5632/8000 (70%)]\tTotal Loss: 0.438057\n",
      "Reconstruction: 0.416094, Regularization: 0.021963\n",
      "2019-04-09 22:56:43,519 root         INFO     Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 0.445848\n",
      "Reconstruction: 0.429954, Regularization: 0.015894\n",
      "2019-04-09 22:56:43,576 root         INFO     Train Epoch: 88 [6656/8000 (83%)]\tTotal Loss: 0.557280\n",
      "Reconstruction: 0.521144, Regularization: 0.036136\n",
      "2019-04-09 22:56:43,632 root         INFO     Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 0.430550\n",
      "Reconstruction: 0.413434, Regularization: 0.017117\n",
      "2019-04-09 22:56:43,689 root         INFO     Train Epoch: 88 [7680/8000 (96%)]\tTotal Loss: 0.443106\n",
      "Reconstruction: 0.423415, Regularization: 0.019690\n",
      "2019-04-09 22:56:43,739 root         INFO     ====> Epoch: 88 Average loss: 0.4533\n",
      "2019-04-09 22:56:43,762 root         INFO     Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 0.350776\n",
      "Reconstruction: 0.335955, Regularization: 0.014822\n",
      "2019-04-09 22:56:43,818 root         INFO     Train Epoch: 89 [512/8000 (6%)]\tTotal Loss: 0.480815\n",
      "Reconstruction: 0.463019, Regularization: 0.017797\n",
      "2019-04-09 22:56:43,873 root         INFO     Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 0.415158\n",
      "Reconstruction: 0.397663, Regularization: 0.017495\n",
      "2019-04-09 22:56:43,929 root         INFO     Train Epoch: 89 [1536/8000 (19%)]\tTotal Loss: 0.334945\n",
      "Reconstruction: 0.317576, Regularization: 0.017369\n",
      "2019-04-09 22:56:43,985 root         INFO     Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 0.354402\n",
      "Reconstruction: 0.338520, Regularization: 0.015882\n",
      "2019-04-09 22:56:44,040 root         INFO     Train Epoch: 89 [2560/8000 (32%)]\tTotal Loss: 0.437849\n",
      "Reconstruction: 0.418533, Regularization: 0.019315\n",
      "2019-04-09 22:56:44,096 root         INFO     Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 0.360366\n",
      "Reconstruction: 0.346964, Regularization: 0.013403\n",
      "2019-04-09 22:56:44,152 root         INFO     Train Epoch: 89 [3584/8000 (45%)]\tTotal Loss: 0.369862\n",
      "Reconstruction: 0.356213, Regularization: 0.013650\n",
      "2019-04-09 22:56:44,208 root         INFO     Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 0.420150\n",
      "Reconstruction: 0.403625, Regularization: 0.016525\n",
      "2019-04-09 22:56:44,264 root         INFO     Train Epoch: 89 [4608/8000 (58%)]\tTotal Loss: 0.469988\n",
      "Reconstruction: 0.448745, Regularization: 0.021244\n",
      "2019-04-09 22:56:44,319 root         INFO     Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 0.411160\n",
      "Reconstruction: 0.392971, Regularization: 0.018189\n",
      "2019-04-09 22:56:44,375 root         INFO     Train Epoch: 89 [5632/8000 (70%)]\tTotal Loss: 0.468641\n",
      "Reconstruction: 0.452679, Regularization: 0.015962\n",
      "2019-04-09 22:56:44,431 root         INFO     Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 0.371692\n",
      "Reconstruction: 0.352428, Regularization: 0.019264\n",
      "2019-04-09 22:56:44,486 root         INFO     Train Epoch: 89 [6656/8000 (83%)]\tTotal Loss: 0.359186\n",
      "Reconstruction: 0.343236, Regularization: 0.015951\n",
      "2019-04-09 22:56:44,541 root         INFO     Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 0.675515\n",
      "Reconstruction: 0.650797, Regularization: 0.024718\n",
      "2019-04-09 22:56:44,596 root         INFO     Train Epoch: 89 [7680/8000 (96%)]\tTotal Loss: 0.458961\n",
      "Reconstruction: 0.421896, Regularization: 0.037065\n",
      "2019-04-09 22:56:44,645 root         INFO     ====> Epoch: 89 Average loss: 0.5441\n",
      "2019-04-09 22:56:44,668 root         INFO     Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 0.396050\n",
      "Reconstruction: 0.382395, Regularization: 0.013655\n",
      "2019-04-09 22:56:44,725 root         INFO     Train Epoch: 90 [512/8000 (6%)]\tTotal Loss: 0.378059\n",
      "Reconstruction: 0.361645, Regularization: 0.016414\n",
      "2019-04-09 22:56:44,782 root         INFO     Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 0.390644\n",
      "Reconstruction: 0.368661, Regularization: 0.021983\n",
      "2019-04-09 22:56:44,838 root         INFO     Train Epoch: 90 [1536/8000 (19%)]\tTotal Loss: 0.379559\n",
      "Reconstruction: 0.362258, Regularization: 0.017301\n",
      "2019-04-09 22:56:44,893 root         INFO     Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 0.426468\n",
      "Reconstruction: 0.410505, Regularization: 0.015964\n",
      "2019-04-09 22:56:44,947 root         INFO     Train Epoch: 90 [2560/8000 (32%)]\tTotal Loss: 0.427596\n",
      "Reconstruction: 0.410570, Regularization: 0.017026\n",
      "2019-04-09 22:56:45,002 root         INFO     Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 0.326336\n",
      "Reconstruction: 0.311650, Regularization: 0.014686\n",
      "2019-04-09 22:56:45,056 root         INFO     Train Epoch: 90 [3584/8000 (45%)]\tTotal Loss: 0.479396\n",
      "Reconstruction: 0.459925, Regularization: 0.019471\n",
      "2019-04-09 22:56:45,111 root         INFO     Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 0.514103\n",
      "Reconstruction: 0.489034, Regularization: 0.025069\n",
      "2019-04-09 22:56:45,165 root         INFO     Train Epoch: 90 [4608/8000 (58%)]\tTotal Loss: 0.328394\n",
      "Reconstruction: 0.315946, Regularization: 0.012447\n",
      "2019-04-09 22:56:45,219 root         INFO     Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 0.513308\n",
      "Reconstruction: 0.488233, Regularization: 0.025075\n",
      "2019-04-09 22:56:45,274 root         INFO     Train Epoch: 90 [5632/8000 (70%)]\tTotal Loss: 0.628943\n",
      "Reconstruction: 0.594377, Regularization: 0.034566\n",
      "2019-04-09 22:56:45,328 root         INFO     Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 0.456493\n",
      "Reconstruction: 0.435792, Regularization: 0.020700\n",
      "2019-04-09 22:56:45,382 root         INFO     Train Epoch: 90 [6656/8000 (83%)]\tTotal Loss: 0.421226\n",
      "Reconstruction: 0.408307, Regularization: 0.012920\n",
      "2019-04-09 22:56:45,437 root         INFO     Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 0.355304\n",
      "Reconstruction: 0.338330, Regularization: 0.016974\n",
      "2019-04-09 22:56:45,493 root         INFO     Train Epoch: 90 [7680/8000 (96%)]\tTotal Loss: 0.426644\n",
      "Reconstruction: 0.406917, Regularization: 0.019727\n",
      "2019-04-09 22:56:45,542 root         INFO     ====> Epoch: 90 Average loss: 1079.9671\n",
      "2019-04-09 22:56:45,565 root         INFO     Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 0.442820\n",
      "Reconstruction: 0.423604, Regularization: 0.019216\n",
      "2019-04-09 22:56:45,621 root         INFO     Train Epoch: 91 [512/8000 (6%)]\tTotal Loss: 0.378701\n",
      "Reconstruction: 0.363056, Regularization: 0.015645\n",
      "2019-04-09 22:56:45,676 root         INFO     Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 0.299989\n",
      "Reconstruction: 0.285895, Regularization: 0.014094\n",
      "2019-04-09 22:56:45,730 root         INFO     Train Epoch: 91 [1536/8000 (19%)]\tTotal Loss: 0.452425\n",
      "Reconstruction: 0.436485, Regularization: 0.015940\n",
      "2019-04-09 22:56:45,785 root         INFO     Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 0.362020\n",
      "Reconstruction: 0.348200, Regularization: 0.013820\n",
      "2019-04-09 22:56:45,840 root         INFO     Train Epoch: 91 [2560/8000 (32%)]\tTotal Loss: 0.402112\n",
      "Reconstruction: 0.385479, Regularization: 0.016633\n",
      "2019-04-09 22:56:45,894 root         INFO     Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 0.530472\n",
      "Reconstruction: 0.490356, Regularization: 0.040116\n",
      "2019-04-09 22:56:45,949 root         INFO     Train Epoch: 91 [3584/8000 (45%)]\tTotal Loss: 0.452592\n",
      "Reconstruction: 0.436591, Regularization: 0.016001\n",
      "2019-04-09 22:56:46,003 root         INFO     Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 0.480282\n",
      "Reconstruction: 0.465165, Regularization: 0.015117\n",
      "2019-04-09 22:56:46,058 root         INFO     Train Epoch: 91 [4608/8000 (58%)]\tTotal Loss: 0.404317\n",
      "Reconstruction: 0.391419, Regularization: 0.012898\n",
      "2019-04-09 22:56:46,112 root         INFO     Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 0.360567\n",
      "Reconstruction: 0.342721, Regularization: 0.017846\n",
      "2019-04-09 22:56:46,167 root         INFO     Train Epoch: 91 [5632/8000 (70%)]\tTotal Loss: 0.434550\n",
      "Reconstruction: 0.416613, Regularization: 0.017936\n",
      "2019-04-09 22:56:46,221 root         INFO     Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 0.415515\n",
      "Reconstruction: 0.395840, Regularization: 0.019676\n",
      "2019-04-09 22:56:46,275 root         INFO     Train Epoch: 91 [6656/8000 (83%)]\tTotal Loss: 0.501942\n",
      "Reconstruction: 0.476585, Regularization: 0.025357\n",
      "2019-04-09 22:56:46,330 root         INFO     Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 0.434755\n",
      "Reconstruction: 0.419215, Regularization: 0.015540\n",
      "2019-04-09 22:56:46,384 root         INFO     Train Epoch: 91 [7680/8000 (96%)]\tTotal Loss: 0.389438\n",
      "Reconstruction: 0.375520, Regularization: 0.013919\n",
      "2019-04-09 22:56:46,433 root         INFO     ====> Epoch: 91 Average loss: 0.4870\n",
      "2019-04-09 22:56:46,456 root         INFO     Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 0.394041\n",
      "Reconstruction: 0.374510, Regularization: 0.019531\n",
      "2019-04-09 22:56:46,511 root         INFO     Train Epoch: 92 [512/8000 (6%)]\tTotal Loss: 0.427092\n",
      "Reconstruction: 0.412418, Regularization: 0.014675\n",
      "2019-04-09 22:56:46,565 root         INFO     Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 0.450792\n",
      "Reconstruction: 0.436959, Regularization: 0.013833\n",
      "2019-04-09 22:56:46,619 root         INFO     Train Epoch: 92 [1536/8000 (19%)]\tTotal Loss: 0.358338\n",
      "Reconstruction: 0.345060, Regularization: 0.013278\n",
      "2019-04-09 22:56:46,674 root         INFO     Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 0.463942\n",
      "Reconstruction: 0.444061, Regularization: 0.019880\n",
      "2019-04-09 22:56:46,729 root         INFO     Train Epoch: 92 [2560/8000 (32%)]\tTotal Loss: 0.427615\n",
      "Reconstruction: 0.411206, Regularization: 0.016409\n",
      "2019-04-09 22:56:46,783 root         INFO     Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 553433.437500\n",
      "Reconstruction: 553433.375000, Regularization: 0.037395\n",
      "2019-04-09 22:56:46,838 root         INFO     Train Epoch: 92 [3584/8000 (45%)]\tTotal Loss: 0.518018\n",
      "Reconstruction: 0.499731, Regularization: 0.018287\n",
      "2019-04-09 22:56:46,893 root         INFO     Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 0.394918\n",
      "Reconstruction: 0.379398, Regularization: 0.015520\n",
      "2019-04-09 22:56:46,947 root         INFO     Train Epoch: 92 [4608/8000 (58%)]\tTotal Loss: 0.363967\n",
      "Reconstruction: 0.349241, Regularization: 0.014726\n",
      "2019-04-09 22:56:47,002 root         INFO     Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 0.376041\n",
      "Reconstruction: 0.358839, Regularization: 0.017202\n",
      "2019-04-09 22:56:47,058 root         INFO     Train Epoch: 92 [5632/8000 (70%)]\tTotal Loss: 0.427430\n",
      "Reconstruction: 0.411994, Regularization: 0.015437\n",
      "2019-04-09 22:56:47,113 root         INFO     Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 1.570251\n",
      "Reconstruction: 1.524801, Regularization: 0.045449\n",
      "2019-04-09 22:56:47,168 root         INFO     Train Epoch: 92 [6656/8000 (83%)]\tTotal Loss: 0.413202\n",
      "Reconstruction: 0.392806, Regularization: 0.020397\n",
      "2019-04-09 22:56:47,223 root         INFO     Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 0.421433\n",
      "Reconstruction: 0.401072, Regularization: 0.020361\n",
      "2019-04-09 22:56:47,277 root         INFO     Train Epoch: 92 [7680/8000 (96%)]\tTotal Loss: 0.319821\n",
      "Reconstruction: 0.302365, Regularization: 0.017456\n",
      "2019-04-09 22:56:47,326 root         INFO     ====> Epoch: 92 Average loss: 2250.2046\n",
      "2019-04-09 22:56:47,349 root         INFO     Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 0.442274\n",
      "Reconstruction: 0.425719, Regularization: 0.016554\n",
      "2019-04-09 22:56:47,404 root         INFO     Train Epoch: 93 [512/8000 (6%)]\tTotal Loss: 0.720526\n",
      "Reconstruction: 0.697260, Regularization: 0.023266\n",
      "2019-04-09 22:56:47,459 root         INFO     Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 0.302545\n",
      "Reconstruction: 0.292183, Regularization: 0.010362\n",
      "2019-04-09 22:56:47,514 root         INFO     Train Epoch: 93 [1536/8000 (19%)]\tTotal Loss: 0.357465\n",
      "Reconstruction: 0.342372, Regularization: 0.015093\n",
      "2019-04-09 22:56:47,568 root         INFO     Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 0.374137\n",
      "Reconstruction: 0.359995, Regularization: 0.014142\n",
      "2019-04-09 22:56:47,623 root         INFO     Train Epoch: 93 [2560/8000 (32%)]\tTotal Loss: 0.458760\n",
      "Reconstruction: 0.436060, Regularization: 0.022699\n",
      "2019-04-09 22:56:47,678 root         INFO     Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 0.284189\n",
      "Reconstruction: 0.272179, Regularization: 0.012010\n",
      "2019-04-09 22:56:47,735 root         INFO     Train Epoch: 93 [3584/8000 (45%)]\tTotal Loss: 0.423766\n",
      "Reconstruction: 0.409804, Regularization: 0.013962\n",
      "2019-04-09 22:56:47,791 root         INFO     Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 0.429017\n",
      "Reconstruction: 0.406728, Regularization: 0.022289\n",
      "2019-04-09 22:56:47,847 root         INFO     Train Epoch: 93 [4608/8000 (58%)]\tTotal Loss: 0.396564\n",
      "Reconstruction: 0.382391, Regularization: 0.014173\n",
      "2019-04-09 22:56:47,902 root         INFO     Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 0.446908\n",
      "Reconstruction: 0.434442, Regularization: 0.012466\n",
      "2019-04-09 22:56:47,959 root         INFO     Train Epoch: 93 [5632/8000 (70%)]\tTotal Loss: 0.305004\n",
      "Reconstruction: 0.290121, Regularization: 0.014883\n",
      "2019-04-09 22:56:48,015 root         INFO     Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 0.390815\n",
      "Reconstruction: 0.374715, Regularization: 0.016100\n",
      "2019-04-09 22:56:48,071 root         INFO     Train Epoch: 93 [6656/8000 (83%)]\tTotal Loss: 0.331304\n",
      "Reconstruction: 0.312418, Regularization: 0.018885\n",
      "2019-04-09 22:56:48,126 root         INFO     Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 0.363380\n",
      "Reconstruction: 0.350813, Regularization: 0.012567\n",
      "2019-04-09 22:56:48,182 root         INFO     Train Epoch: 93 [7680/8000 (96%)]\tTotal Loss: 0.444553\n",
      "Reconstruction: 0.422089, Regularization: 0.022464\n",
      "2019-04-09 22:56:48,232 root         INFO     ====> Epoch: 93 Average loss: 0.4341\n",
      "2019-04-09 22:56:48,255 root         INFO     Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 0.450218\n",
      "Reconstruction: 0.435351, Regularization: 0.014867\n",
      "2019-04-09 22:56:48,311 root         INFO     Train Epoch: 94 [512/8000 (6%)]\tTotal Loss: 0.454110\n",
      "Reconstruction: 0.435979, Regularization: 0.018131\n",
      "2019-04-09 22:56:48,366 root         INFO     Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 0.416799\n",
      "Reconstruction: 0.402344, Regularization: 0.014455\n",
      "2019-04-09 22:56:48,422 root         INFO     Train Epoch: 94 [1536/8000 (19%)]\tTotal Loss: 0.338938\n",
      "Reconstruction: 0.325817, Regularization: 0.013121\n",
      "2019-04-09 22:56:48,477 root         INFO     Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 0.361217\n",
      "Reconstruction: 0.346722, Regularization: 0.014495\n",
      "2019-04-09 22:56:48,534 root         INFO     Train Epoch: 94 [2560/8000 (32%)]\tTotal Loss: 0.528578\n",
      "Reconstruction: 0.505780, Regularization: 0.022798\n",
      "2019-04-09 22:56:48,592 root         INFO     Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 0.473805\n",
      "Reconstruction: 0.456106, Regularization: 0.017699\n",
      "2019-04-09 22:56:48,649 root         INFO     Train Epoch: 94 [3584/8000 (45%)]\tTotal Loss: 0.457803\n",
      "Reconstruction: 0.435858, Regularization: 0.021946\n",
      "2019-04-09 22:56:48,706 root         INFO     Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 0.336894\n",
      "Reconstruction: 0.321959, Regularization: 0.014935\n",
      "2019-04-09 22:56:48,763 root         INFO     Train Epoch: 94 [4608/8000 (58%)]\tTotal Loss: 0.343529\n",
      "Reconstruction: 0.320235, Regularization: 0.023295\n",
      "2019-04-09 22:56:48,819 root         INFO     Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 0.469866\n",
      "Reconstruction: 0.454007, Regularization: 0.015858\n",
      "2019-04-09 22:56:48,876 root         INFO     Train Epoch: 94 [5632/8000 (70%)]\tTotal Loss: 0.373916\n",
      "Reconstruction: 0.359287, Regularization: 0.014629\n",
      "2019-04-09 22:56:48,933 root         INFO     Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 0.329130\n",
      "Reconstruction: 0.315430, Regularization: 0.013700\n",
      "2019-04-09 22:56:48,990 root         INFO     Train Epoch: 94 [6656/8000 (83%)]\tTotal Loss: 0.421427\n",
      "Reconstruction: 0.403908, Regularization: 0.017519\n",
      "2019-04-09 22:56:49,046 root         INFO     Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 0.529579\n",
      "Reconstruction: 0.508760, Regularization: 0.020819\n",
      "2019-04-09 22:56:49,103 root         INFO     Train Epoch: 94 [7680/8000 (96%)]\tTotal Loss: 0.374999\n",
      "Reconstruction: 0.362734, Regularization: 0.012265\n",
      "2019-04-09 22:56:49,152 root         INFO     ====> Epoch: 94 Average loss: 0.7171\n",
      "2019-04-09 22:56:49,175 root         INFO     Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 0.520927\n",
      "Reconstruction: 0.502981, Regularization: 0.017945\n",
      "2019-04-09 22:56:49,232 root         INFO     Train Epoch: 95 [512/8000 (6%)]\tTotal Loss: 0.357102\n",
      "Reconstruction: 0.345698, Regularization: 0.011404\n",
      "2019-04-09 22:56:49,288 root         INFO     Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 0.368437\n",
      "Reconstruction: 0.355354, Regularization: 0.013083\n",
      "2019-04-09 22:56:49,345 root         INFO     Train Epoch: 95 [1536/8000 (19%)]\tTotal Loss: 0.408923\n",
      "Reconstruction: 0.397063, Regularization: 0.011860\n",
      "2019-04-09 22:56:49,401 root         INFO     Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 0.387473\n",
      "Reconstruction: 0.364934, Regularization: 0.022539\n",
      "2019-04-09 22:56:49,455 root         INFO     Train Epoch: 95 [2560/8000 (32%)]\tTotal Loss: 0.480035\n",
      "Reconstruction: 0.462036, Regularization: 0.018000\n",
      "2019-04-09 22:56:49,510 root         INFO     Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 0.364158\n",
      "Reconstruction: 0.349007, Regularization: 0.015151\n",
      "2019-04-09 22:56:49,565 root         INFO     Train Epoch: 95 [3584/8000 (45%)]\tTotal Loss: 0.330863\n",
      "Reconstruction: 0.317914, Regularization: 0.012949\n",
      "2019-04-09 22:56:49,619 root         INFO     Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 0.393530\n",
      "Reconstruction: 0.375854, Regularization: 0.017677\n",
      "2019-04-09 22:56:49,674 root         INFO     Train Epoch: 95 [4608/8000 (58%)]\tTotal Loss: 0.310475\n",
      "Reconstruction: 0.298166, Regularization: 0.012309\n",
      "2019-04-09 22:56:49,729 root         INFO     Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 0.423090\n",
      "Reconstruction: 0.407398, Regularization: 0.015692\n",
      "2019-04-09 22:56:49,784 root         INFO     Train Epoch: 95 [5632/8000 (70%)]\tTotal Loss: 0.357809\n",
      "Reconstruction: 0.338016, Regularization: 0.019792\n",
      "2019-04-09 22:56:49,838 root         INFO     Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 0.385870\n",
      "Reconstruction: 0.349985, Regularization: 0.035885\n",
      "2019-04-09 22:56:49,894 root         INFO     Train Epoch: 95 [6656/8000 (83%)]\tTotal Loss: 0.420827\n",
      "Reconstruction: 0.397597, Regularization: 0.023231\n",
      "2019-04-09 22:56:49,950 root         INFO     Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 0.402466\n",
      "Reconstruction: 0.382264, Regularization: 0.020202\n",
      "2019-04-09 22:56:50,006 root         INFO     Train Epoch: 95 [7680/8000 (96%)]\tTotal Loss: 0.415903\n",
      "Reconstruction: 0.397177, Regularization: 0.018726\n",
      "2019-04-09 22:56:50,057 root         INFO     ====> Epoch: 95 Average loss: 0.4279\n",
      "2019-04-09 22:56:50,080 root         INFO     Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 0.453287\n",
      "Reconstruction: 0.437590, Regularization: 0.015698\n",
      "2019-04-09 22:56:50,137 root         INFO     Train Epoch: 96 [512/8000 (6%)]\tTotal Loss: 0.396944\n",
      "Reconstruction: 0.380229, Regularization: 0.016716\n",
      "2019-04-09 22:56:50,194 root         INFO     Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 0.477054\n",
      "Reconstruction: 0.458652, Regularization: 0.018402\n",
      "2019-04-09 22:56:50,250 root         INFO     Train Epoch: 96 [1536/8000 (19%)]\tTotal Loss: 0.482919\n",
      "Reconstruction: 0.461877, Regularization: 0.021042\n",
      "2019-04-09 22:56:50,307 root         INFO     Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 0.859557\n",
      "Reconstruction: 0.839425, Regularization: 0.020132\n",
      "2019-04-09 22:56:50,363 root         INFO     Train Epoch: 96 [2560/8000 (32%)]\tTotal Loss: 0.391641\n",
      "Reconstruction: 0.379313, Regularization: 0.012328\n",
      "2019-04-09 22:56:50,420 root         INFO     Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 0.490698\n",
      "Reconstruction: 0.466013, Regularization: 0.024685\n",
      "2019-04-09 22:56:50,477 root         INFO     Train Epoch: 96 [3584/8000 (45%)]\tTotal Loss: 0.532297\n",
      "Reconstruction: 0.504926, Regularization: 0.027371\n",
      "2019-04-09 22:56:50,534 root         INFO     Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 0.480948\n",
      "Reconstruction: 0.463289, Regularization: 0.017659\n",
      "2019-04-09 22:56:50,590 root         INFO     Train Epoch: 96 [4608/8000 (58%)]\tTotal Loss: 0.425771\n",
      "Reconstruction: 0.410239, Regularization: 0.015532\n",
      "2019-04-09 22:56:50,647 root         INFO     Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 0.380613\n",
      "Reconstruction: 0.365880, Regularization: 0.014733\n",
      "2019-04-09 22:56:50,703 root         INFO     Train Epoch: 96 [5632/8000 (70%)]\tTotal Loss: 0.347037\n",
      "Reconstruction: 0.334033, Regularization: 0.013004\n",
      "2019-04-09 22:56:50,759 root         INFO     Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 0.526743\n",
      "Reconstruction: 0.501189, Regularization: 0.025555\n",
      "2019-04-09 22:56:50,815 root         INFO     Train Epoch: 96 [6656/8000 (83%)]\tTotal Loss: 0.397049\n",
      "Reconstruction: 0.375583, Regularization: 0.021466\n",
      "2019-04-09 22:56:50,871 root         INFO     Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 0.400885\n",
      "Reconstruction: 0.384481, Regularization: 0.016403\n",
      "2019-04-09 22:56:50,927 root         INFO     Train Epoch: 96 [7680/8000 (96%)]\tTotal Loss: 0.515964\n",
      "Reconstruction: 0.493336, Regularization: 0.022628\n",
      "2019-04-09 22:56:50,978 root         INFO     ====> Epoch: 96 Average loss: 0.4246\n",
      "2019-04-09 22:56:51,001 root         INFO     Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 0.353601\n",
      "Reconstruction: 0.339664, Regularization: 0.013937\n",
      "2019-04-09 22:56:51,058 root         INFO     Train Epoch: 97 [512/8000 (6%)]\tTotal Loss: 0.343159\n",
      "Reconstruction: 0.330631, Regularization: 0.012528\n",
      "2019-04-09 22:56:51,115 root         INFO     Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 0.433058\n",
      "Reconstruction: 0.416337, Regularization: 0.016721\n",
      "2019-04-09 22:56:51,172 root         INFO     Train Epoch: 97 [1536/8000 (19%)]\tTotal Loss: 0.338642\n",
      "Reconstruction: 0.326465, Regularization: 0.012177\n",
      "2019-04-09 22:56:51,229 root         INFO     Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 0.414382\n",
      "Reconstruction: 0.397791, Regularization: 0.016591\n",
      "2019-04-09 22:56:51,285 root         INFO     Train Epoch: 97 [2560/8000 (32%)]\tTotal Loss: 0.372933\n",
      "Reconstruction: 0.358632, Regularization: 0.014301\n",
      "2019-04-09 22:56:51,341 root         INFO     Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 0.561787\n",
      "Reconstruction: 0.543015, Regularization: 0.018772\n",
      "2019-04-09 22:56:51,396 root         INFO     Train Epoch: 97 [3584/8000 (45%)]\tTotal Loss: 0.551762\n",
      "Reconstruction: 0.505424, Regularization: 0.046338\n",
      "2019-04-09 22:56:51,451 root         INFO     Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 0.383429\n",
      "Reconstruction: 0.369372, Regularization: 0.014058\n",
      "2019-04-09 22:56:51,506 root         INFO     Train Epoch: 97 [4608/8000 (58%)]\tTotal Loss: 0.433110\n",
      "Reconstruction: 0.414501, Regularization: 0.018610\n",
      "2019-04-09 22:56:51,562 root         INFO     Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 0.496717\n",
      "Reconstruction: 0.478891, Regularization: 0.017827\n",
      "2019-04-09 22:56:51,619 root         INFO     Train Epoch: 97 [5632/8000 (70%)]\tTotal Loss: 0.482288\n",
      "Reconstruction: 0.468927, Regularization: 0.013361\n",
      "2019-04-09 22:56:51,675 root         INFO     Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 0.346274\n",
      "Reconstruction: 0.323240, Regularization: 0.023034\n",
      "2019-04-09 22:56:51,731 root         INFO     Train Epoch: 97 [6656/8000 (83%)]\tTotal Loss: 0.438889\n",
      "Reconstruction: 0.422670, Regularization: 0.016219\n",
      "2019-04-09 22:56:51,787 root         INFO     Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 0.392456\n",
      "Reconstruction: 0.377465, Regularization: 0.014991\n",
      "2019-04-09 22:56:51,844 root         INFO     Train Epoch: 97 [7680/8000 (96%)]\tTotal Loss: 0.493692\n",
      "Reconstruction: 0.472981, Regularization: 0.020712\n",
      "2019-04-09 22:56:51,894 root         INFO     ====> Epoch: 97 Average loss: 0.4537\n",
      "2019-04-09 22:56:51,917 root         INFO     Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 0.466079\n",
      "Reconstruction: 0.449883, Regularization: 0.016196\n",
      "2019-04-09 22:56:51,974 root         INFO     Train Epoch: 98 [512/8000 (6%)]\tTotal Loss: 0.327988\n",
      "Reconstruction: 0.314969, Regularization: 0.013020\n",
      "2019-04-09 22:56:52,031 root         INFO     Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 0.367603\n",
      "Reconstruction: 0.351346, Regularization: 0.016257\n",
      "2019-04-09 22:56:52,088 root         INFO     Train Epoch: 98 [1536/8000 (19%)]\tTotal Loss: 0.395656\n",
      "Reconstruction: 0.381046, Regularization: 0.014610\n",
      "2019-04-09 22:56:52,145 root         INFO     Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 0.749760\n",
      "Reconstruction: 0.724349, Regularization: 0.025410\n",
      "2019-04-09 22:56:52,202 root         INFO     Train Epoch: 98 [2560/8000 (32%)]\tTotal Loss: 0.324958\n",
      "Reconstruction: 0.309000, Regularization: 0.015958\n",
      "2019-04-09 22:56:52,259 root         INFO     Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 0.354206\n",
      "Reconstruction: 0.337260, Regularization: 0.016945\n",
      "2019-04-09 22:56:52,315 root         INFO     Train Epoch: 98 [3584/8000 (45%)]\tTotal Loss: 0.347082\n",
      "Reconstruction: 0.335226, Regularization: 0.011856\n",
      "2019-04-09 22:56:52,372 root         INFO     Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 0.410568\n",
      "Reconstruction: 0.395095, Regularization: 0.015473\n",
      "2019-04-09 22:56:52,429 root         INFO     Train Epoch: 98 [4608/8000 (58%)]\tTotal Loss: 0.351893\n",
      "Reconstruction: 0.339263, Regularization: 0.012631\n",
      "2019-04-09 22:56:52,486 root         INFO     Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 0.316646\n",
      "Reconstruction: 0.302363, Regularization: 0.014283\n",
      "2019-04-09 22:56:52,542 root         INFO     Train Epoch: 98 [5632/8000 (70%)]\tTotal Loss: 0.579069\n",
      "Reconstruction: 0.554603, Regularization: 0.024466\n",
      "2019-04-09 22:56:52,599 root         INFO     Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 0.447822\n",
      "Reconstruction: 0.430147, Regularization: 0.017674\n",
      "2019-04-09 22:56:52,656 root         INFO     Train Epoch: 98 [6656/8000 (83%)]\tTotal Loss: 0.310234\n",
      "Reconstruction: 0.295900, Regularization: 0.014334\n",
      "2019-04-09 22:56:52,714 root         INFO     Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 0.437544\n",
      "Reconstruction: 0.418613, Regularization: 0.018931\n",
      "2019-04-09 22:56:52,768 root         INFO     Train Epoch: 98 [7680/8000 (96%)]\tTotal Loss: 0.554228\n",
      "Reconstruction: 0.535316, Regularization: 0.018912\n",
      "2019-04-09 22:56:52,817 root         INFO     ====> Epoch: 98 Average loss: 0.5149\n",
      "2019-04-09 22:56:52,840 root         INFO     Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 0.366142\n",
      "Reconstruction: 0.344363, Regularization: 0.021779\n",
      "2019-04-09 22:56:52,894 root         INFO     Train Epoch: 99 [512/8000 (6%)]\tTotal Loss: 0.335982\n",
      "Reconstruction: 0.324796, Regularization: 0.011185\n",
      "2019-04-09 22:56:52,949 root         INFO     Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 0.398180\n",
      "Reconstruction: 0.375036, Regularization: 0.023144\n",
      "2019-04-09 22:56:53,003 root         INFO     Train Epoch: 99 [1536/8000 (19%)]\tTotal Loss: 0.359805\n",
      "Reconstruction: 0.348218, Regularization: 0.011587\n",
      "2019-04-09 22:56:53,057 root         INFO     Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 0.410993\n",
      "Reconstruction: 0.397509, Regularization: 0.013484\n",
      "2019-04-09 22:56:53,111 root         INFO     Train Epoch: 99 [2560/8000 (32%)]\tTotal Loss: 0.465065\n",
      "Reconstruction: 0.443374, Regularization: 0.021691\n",
      "2019-04-09 22:56:53,165 root         INFO     Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 0.367024\n",
      "Reconstruction: 0.350785, Regularization: 0.016239\n",
      "2019-04-09 22:56:53,219 root         INFO     Train Epoch: 99 [3584/8000 (45%)]\tTotal Loss: 0.423757\n",
      "Reconstruction: 0.405438, Regularization: 0.018318\n",
      "2019-04-09 22:56:53,274 root         INFO     Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 0.419321\n",
      "Reconstruction: 0.404189, Regularization: 0.015132\n",
      "2019-04-09 22:56:53,328 root         INFO     Train Epoch: 99 [4608/8000 (58%)]\tTotal Loss: 0.394334\n",
      "Reconstruction: 0.380086, Regularization: 0.014247\n",
      "2019-04-09 22:56:53,382 root         INFO     Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 0.373481\n",
      "Reconstruction: 0.355629, Regularization: 0.017851\n",
      "2019-04-09 22:56:53,436 root         INFO     Train Epoch: 99 [5632/8000 (70%)]\tTotal Loss: 0.461250\n",
      "Reconstruction: 0.443472, Regularization: 0.017778\n",
      "2019-04-09 22:56:53,490 root         INFO     Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 0.382702\n",
      "Reconstruction: 0.364788, Regularization: 0.017913\n",
      "2019-04-09 22:56:53,545 root         INFO     Train Epoch: 99 [6656/8000 (83%)]\tTotal Loss: 0.478507\n",
      "Reconstruction: 0.452369, Regularization: 0.026138\n",
      "2019-04-09 22:56:53,599 root         INFO     Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 0.373839\n",
      "Reconstruction: 0.357569, Regularization: 0.016270\n",
      "2019-04-09 22:56:53,653 root         INFO     Train Epoch: 99 [7680/8000 (96%)]\tTotal Loss: 0.607710\n",
      "Reconstruction: 0.591690, Regularization: 0.016019\n",
      "2019-04-09 22:56:53,702 root         INFO     ====> Epoch: 99 Average loss: 0.4338\n",
      "2019-04-09 22:56:53,725 root         INFO     Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 0.327525\n",
      "Reconstruction: 0.314479, Regularization: 0.013045\n",
      "2019-04-09 22:56:53,780 root         INFO     Train Epoch: 100 [512/8000 (6%)]\tTotal Loss: 0.414944\n",
      "Reconstruction: 0.397994, Regularization: 0.016950\n",
      "2019-04-09 22:56:53,835 root         INFO     Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 0.411528\n",
      "Reconstruction: 0.394344, Regularization: 0.017185\n",
      "2019-04-09 22:56:53,890 root         INFO     Train Epoch: 100 [1536/8000 (19%)]\tTotal Loss: 0.432780\n",
      "Reconstruction: 0.418137, Regularization: 0.014643\n",
      "2019-04-09 22:56:53,945 root         INFO     Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 0.424402\n",
      "Reconstruction: 0.405265, Regularization: 0.019137\n",
      "2019-04-09 22:56:54,000 root         INFO     Train Epoch: 100 [2560/8000 (32%)]\tTotal Loss: 0.375706\n",
      "Reconstruction: 0.362810, Regularization: 0.012896\n",
      "2019-04-09 22:56:54,054 root         INFO     Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 0.306848\n",
      "Reconstruction: 0.294381, Regularization: 0.012467\n",
      "2019-04-09 22:56:54,109 root         INFO     Train Epoch: 100 [3584/8000 (45%)]\tTotal Loss: 0.398692\n",
      "Reconstruction: 0.378954, Regularization: 0.019738\n",
      "2019-04-09 22:56:54,164 root         INFO     Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 0.365806\n",
      "Reconstruction: 0.346629, Regularization: 0.019177\n",
      "2019-04-09 22:56:54,219 root         INFO     Train Epoch: 100 [4608/8000 (58%)]\tTotal Loss: 0.354250\n",
      "Reconstruction: 0.339262, Regularization: 0.014987\n",
      "2019-04-09 22:56:54,274 root         INFO     Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 0.514345\n",
      "Reconstruction: 0.491168, Regularization: 0.023177\n",
      "2019-04-09 22:56:54,328 root         INFO     Train Epoch: 100 [5632/8000 (70%)]\tTotal Loss: 0.325071\n",
      "Reconstruction: 0.312925, Regularization: 0.012147\n",
      "2019-04-09 22:56:54,384 root         INFO     Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 0.434877\n",
      "Reconstruction: 0.419068, Regularization: 0.015809\n",
      "2019-04-09 22:56:54,439 root         INFO     Train Epoch: 100 [6656/8000 (83%)]\tTotal Loss: 0.363425\n",
      "Reconstruction: 0.349470, Regularization: 0.013955\n",
      "2019-04-09 22:56:54,494 root         INFO     Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 0.389102\n",
      "Reconstruction: 0.373342, Regularization: 0.015760\n",
      "2019-04-09 22:56:54,550 root         INFO     Train Epoch: 100 [7680/8000 (96%)]\tTotal Loss: 0.232325\n",
      "Reconstruction: 0.222779, Regularization: 0.009546\n",
      "2019-04-09 22:56:54,599 root         INFO     ====> Epoch: 100 Average loss: 0.4784\n",
      "2019-04-09 22:56:54,622 root         INFO     Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 0.448130\n",
      "Reconstruction: 0.427122, Regularization: 0.021008\n",
      "2019-04-09 22:56:54,677 root         INFO     Train Epoch: 101 [512/8000 (6%)]\tTotal Loss: 0.330088\n",
      "Reconstruction: 0.310562, Regularization: 0.019526\n",
      "2019-04-09 22:56:54,732 root         INFO     Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 0.457307\n",
      "Reconstruction: 0.441034, Regularization: 0.016273\n",
      "2019-04-09 22:56:54,787 root         INFO     Train Epoch: 101 [1536/8000 (19%)]\tTotal Loss: 0.355314\n",
      "Reconstruction: 0.338537, Regularization: 0.016777\n",
      "2019-04-09 22:56:54,842 root         INFO     Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 0.412738\n",
      "Reconstruction: 0.396441, Regularization: 0.016296\n",
      "2019-04-09 22:56:54,896 root         INFO     Train Epoch: 101 [2560/8000 (32%)]\tTotal Loss: 0.442697\n",
      "Reconstruction: 0.428073, Regularization: 0.014624\n",
      "2019-04-09 22:56:54,952 root         INFO     Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 0.528134\n",
      "Reconstruction: 0.505812, Regularization: 0.022322\n",
      "2019-04-09 22:56:55,007 root         INFO     Train Epoch: 101 [3584/8000 (45%)]\tTotal Loss: 0.373516\n",
      "Reconstruction: 0.356837, Regularization: 0.016679\n",
      "2019-04-09 22:56:55,061 root         INFO     Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 0.437273\n",
      "Reconstruction: 0.420252, Regularization: 0.017022\n",
      "2019-04-09 22:56:55,116 root         INFO     Train Epoch: 101 [4608/8000 (58%)]\tTotal Loss: 0.354606\n",
      "Reconstruction: 0.333449, Regularization: 0.021158\n",
      "2019-04-09 22:56:55,171 root         INFO     Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 0.390484\n",
      "Reconstruction: 0.379408, Regularization: 0.011076\n",
      "2019-04-09 22:56:55,226 root         INFO     Train Epoch: 101 [5632/8000 (70%)]\tTotal Loss: 0.345136\n",
      "Reconstruction: 0.322616, Regularization: 0.022520\n",
      "2019-04-09 22:56:55,281 root         INFO     Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 0.319496\n",
      "Reconstruction: 0.307256, Regularization: 0.012239\n",
      "2019-04-09 22:56:55,336 root         INFO     Train Epoch: 101 [6656/8000 (83%)]\tTotal Loss: 0.632898\n",
      "Reconstruction: 0.613898, Regularization: 0.019000\n",
      "2019-04-09 22:56:55,392 root         INFO     Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 0.357855\n",
      "Reconstruction: 0.341890, Regularization: 0.015965\n",
      "2019-04-09 22:56:55,447 root         INFO     Train Epoch: 101 [7680/8000 (96%)]\tTotal Loss: 0.444592\n",
      "Reconstruction: 0.427434, Regularization: 0.017159\n",
      "2019-04-09 22:56:55,495 root         INFO     ====> Epoch: 101 Average loss: 0.7250\n",
      "2019-04-09 22:56:55,519 root         INFO     Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 0.355902\n",
      "Reconstruction: 0.338217, Regularization: 0.017685\n",
      "2019-04-09 22:56:55,575 root         INFO     Train Epoch: 102 [512/8000 (6%)]\tTotal Loss: 0.496713\n",
      "Reconstruction: 0.479426, Regularization: 0.017286\n",
      "2019-04-09 22:56:55,631 root         INFO     Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 0.476468\n",
      "Reconstruction: 0.446269, Regularization: 0.030199\n",
      "2019-04-09 22:56:55,686 root         INFO     Train Epoch: 102 [1536/8000 (19%)]\tTotal Loss: 0.418921\n",
      "Reconstruction: 0.396307, Regularization: 0.022614\n",
      "2019-04-09 22:56:55,742 root         INFO     Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 0.363729\n",
      "Reconstruction: 0.349808, Regularization: 0.013920\n",
      "2019-04-09 22:56:55,797 root         INFO     Train Epoch: 102 [2560/8000 (32%)]\tTotal Loss: 0.359240\n",
      "Reconstruction: 0.345372, Regularization: 0.013867\n",
      "2019-04-09 22:56:55,853 root         INFO     Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 0.492025\n",
      "Reconstruction: 0.450805, Regularization: 0.041220\n",
      "2019-04-09 22:56:55,908 root         INFO     Train Epoch: 102 [3584/8000 (45%)]\tTotal Loss: 0.378508\n",
      "Reconstruction: 0.368535, Regularization: 0.009973\n",
      "2019-04-09 22:56:55,964 root         INFO     Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 0.376738\n",
      "Reconstruction: 0.359806, Regularization: 0.016932\n",
      "2019-04-09 22:56:56,019 root         INFO     Train Epoch: 102 [4608/8000 (58%)]\tTotal Loss: 0.404103\n",
      "Reconstruction: 0.388440, Regularization: 0.015663\n",
      "2019-04-09 22:56:56,074 root         INFO     Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 0.390502\n",
      "Reconstruction: 0.376049, Regularization: 0.014453\n",
      "2019-04-09 22:56:56,130 root         INFO     Train Epoch: 102 [5632/8000 (70%)]\tTotal Loss: 0.375100\n",
      "Reconstruction: 0.360626, Regularization: 0.014474\n",
      "2019-04-09 22:56:56,185 root         INFO     Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 0.379857\n",
      "Reconstruction: 0.364421, Regularization: 0.015436\n",
      "2019-04-09 22:56:56,240 root         INFO     Train Epoch: 102 [6656/8000 (83%)]\tTotal Loss: 0.358853\n",
      "Reconstruction: 0.337724, Regularization: 0.021129\n",
      "2019-04-09 22:56:56,295 root         INFO     Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 0.383610\n",
      "Reconstruction: 0.369321, Regularization: 0.014289\n",
      "2019-04-09 22:56:56,351 root         INFO     Train Epoch: 102 [7680/8000 (96%)]\tTotal Loss: 0.374936\n",
      "Reconstruction: 0.361263, Regularization: 0.013674\n",
      "2019-04-09 22:56:56,400 root         INFO     ====> Epoch: 102 Average loss: 0.8389\n",
      "2019-04-09 22:56:56,423 root         INFO     Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 0.396025\n",
      "Reconstruction: 0.377777, Regularization: 0.018248\n",
      "2019-04-09 22:56:56,479 root         INFO     Train Epoch: 103 [512/8000 (6%)]\tTotal Loss: 0.391779\n",
      "Reconstruction: 0.376292, Regularization: 0.015487\n",
      "2019-04-09 22:56:56,534 root         INFO     Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 0.587833\n",
      "Reconstruction: 0.569952, Regularization: 0.017881\n",
      "2019-04-09 22:56:56,590 root         INFO     Train Epoch: 103 [1536/8000 (19%)]\tTotal Loss: 0.438122\n",
      "Reconstruction: 0.424042, Regularization: 0.014080\n",
      "2019-04-09 22:56:56,646 root         INFO     Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 0.494314\n",
      "Reconstruction: 0.480267, Regularization: 0.014047\n",
      "2019-04-09 22:56:56,701 root         INFO     Train Epoch: 103 [2560/8000 (32%)]\tTotal Loss: 0.388572\n",
      "Reconstruction: 0.374246, Regularization: 0.014326\n",
      "2019-04-09 22:56:56,757 root         INFO     Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 0.470224\n",
      "Reconstruction: 0.442054, Regularization: 0.028170\n",
      "2019-04-09 22:56:56,813 root         INFO     Train Epoch: 103 [3584/8000 (45%)]\tTotal Loss: 0.371004\n",
      "Reconstruction: 0.349075, Regularization: 0.021929\n",
      "2019-04-09 22:56:56,870 root         INFO     Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 0.449005\n",
      "Reconstruction: 0.431552, Regularization: 0.017453\n",
      "2019-04-09 22:56:56,926 root         INFO     Train Epoch: 103 [4608/8000 (58%)]\tTotal Loss: 0.343704\n",
      "Reconstruction: 0.331837, Regularization: 0.011866\n",
      "2019-04-09 22:56:56,982 root         INFO     Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 0.310843\n",
      "Reconstruction: 0.297983, Regularization: 0.012860\n",
      "2019-04-09 22:56:57,039 root         INFO     Train Epoch: 103 [5632/8000 (70%)]\tTotal Loss: 0.439902\n",
      "Reconstruction: 0.416162, Regularization: 0.023740\n",
      "2019-04-09 22:56:57,095 root         INFO     Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 0.337387\n",
      "Reconstruction: 0.324472, Regularization: 0.012915\n",
      "2019-04-09 22:56:57,152 root         INFO     Train Epoch: 103 [6656/8000 (83%)]\tTotal Loss: 0.386457\n",
      "Reconstruction: 0.365221, Regularization: 0.021236\n",
      "2019-04-09 22:56:57,208 root         INFO     Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 0.449641\n",
      "Reconstruction: 0.432106, Regularization: 0.017535\n",
      "2019-04-09 22:56:57,264 root         INFO     Train Epoch: 103 [7680/8000 (96%)]\tTotal Loss: 0.370409\n",
      "Reconstruction: 0.349023, Regularization: 0.021386\n",
      "2019-04-09 22:56:57,315 root         INFO     ====> Epoch: 103 Average loss: 0.4551\n",
      "2019-04-09 22:56:57,338 root         INFO     Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 0.375100\n",
      "Reconstruction: 0.355657, Regularization: 0.019443\n",
      "2019-04-09 22:56:57,394 root         INFO     Train Epoch: 104 [512/8000 (6%)]\tTotal Loss: 0.328000\n",
      "Reconstruction: 0.315207, Regularization: 0.012794\n",
      "2019-04-09 22:56:57,451 root         INFO     Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 0.300410\n",
      "Reconstruction: 0.283849, Regularization: 0.016561\n",
      "2019-04-09 22:56:57,508 root         INFO     Train Epoch: 104 [1536/8000 (19%)]\tTotal Loss: 0.345083\n",
      "Reconstruction: 0.332180, Regularization: 0.012904\n",
      "2019-04-09 22:56:57,564 root         INFO     Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 0.424570\n",
      "Reconstruction: 0.405756, Regularization: 0.018814\n",
      "2019-04-09 22:56:57,621 root         INFO     Train Epoch: 104 [2560/8000 (32%)]\tTotal Loss: 0.448085\n",
      "Reconstruction: 0.432319, Regularization: 0.015765\n",
      "2019-04-09 22:56:57,677 root         INFO     Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 0.437718\n",
      "Reconstruction: 0.420788, Regularization: 0.016930\n",
      "2019-04-09 22:56:57,734 root         INFO     Train Epoch: 104 [3584/8000 (45%)]\tTotal Loss: 0.418313\n",
      "Reconstruction: 0.400670, Regularization: 0.017642\n",
      "2019-04-09 22:56:57,790 root         INFO     Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 0.448395\n",
      "Reconstruction: 0.432143, Regularization: 0.016252\n",
      "2019-04-09 22:56:57,847 root         INFO     Train Epoch: 104 [4608/8000 (58%)]\tTotal Loss: 0.387222\n",
      "Reconstruction: 0.371656, Regularization: 0.015566\n",
      "2019-04-09 22:56:57,904 root         INFO     Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 0.456955\n",
      "Reconstruction: 0.436255, Regularization: 0.020700\n",
      "2019-04-09 22:56:57,961 root         INFO     Train Epoch: 104 [5632/8000 (70%)]\tTotal Loss: 0.351881\n",
      "Reconstruction: 0.331177, Regularization: 0.020705\n",
      "2019-04-09 22:56:58,017 root         INFO     Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 0.369235\n",
      "Reconstruction: 0.349226, Regularization: 0.020008\n",
      "2019-04-09 22:56:58,074 root         INFO     Train Epoch: 104 [6656/8000 (83%)]\tTotal Loss: 0.406498\n",
      "Reconstruction: 0.388653, Regularization: 0.017845\n",
      "2019-04-09 22:56:58,130 root         INFO     Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 0.459352\n",
      "Reconstruction: 0.441737, Regularization: 0.017615\n",
      "2019-04-09 22:56:58,186 root         INFO     Train Epoch: 104 [7680/8000 (96%)]\tTotal Loss: 0.724263\n",
      "Reconstruction: 0.685740, Regularization: 0.038523\n",
      "2019-04-09 22:56:58,236 root         INFO     ====> Epoch: 104 Average loss: 0.4348\n",
      "2019-04-09 22:56:58,260 root         INFO     Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 0.361148\n",
      "Reconstruction: 0.347665, Regularization: 0.013483\n",
      "2019-04-09 22:56:58,316 root         INFO     Train Epoch: 105 [512/8000 (6%)]\tTotal Loss: 0.396759\n",
      "Reconstruction: 0.381628, Regularization: 0.015130\n",
      "2019-04-09 22:56:58,373 root         INFO     Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 0.429777\n",
      "Reconstruction: 0.415420, Regularization: 0.014357\n",
      "2019-04-09 22:56:58,430 root         INFO     Train Epoch: 105 [1536/8000 (19%)]\tTotal Loss: 0.431539\n",
      "Reconstruction: 0.413292, Regularization: 0.018247\n",
      "2019-04-09 22:56:58,486 root         INFO     Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 0.356626\n",
      "Reconstruction: 0.344143, Regularization: 0.012483\n",
      "2019-04-09 22:56:58,542 root         INFO     Train Epoch: 105 [2560/8000 (32%)]\tTotal Loss: 0.357140\n",
      "Reconstruction: 0.335046, Regularization: 0.022094\n",
      "2019-04-09 22:56:58,598 root         INFO     Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 6.135701\n",
      "Reconstruction: 6.114173, Regularization: 0.021528\n",
      "2019-04-09 22:56:58,654 root         INFO     Train Epoch: 105 [3584/8000 (45%)]\tTotal Loss: 0.366551\n",
      "Reconstruction: 0.352239, Regularization: 0.014312\n",
      "2019-04-09 22:56:58,710 root         INFO     Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 0.491819\n",
      "Reconstruction: 0.471470, Regularization: 0.020349\n",
      "2019-04-09 22:56:58,766 root         INFO     Train Epoch: 105 [4608/8000 (58%)]\tTotal Loss: 0.432912\n",
      "Reconstruction: 0.417105, Regularization: 0.015807\n",
      "2019-04-09 22:56:58,821 root         INFO     Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 0.403416\n",
      "Reconstruction: 0.386545, Regularization: 0.016871\n",
      "2019-04-09 22:56:58,876 root         INFO     Train Epoch: 105 [5632/8000 (70%)]\tTotal Loss: 0.432570\n",
      "Reconstruction: 0.416570, Regularization: 0.016000\n",
      "2019-04-09 22:56:58,932 root         INFO     Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 0.408521\n",
      "Reconstruction: 0.390542, Regularization: 0.017979\n",
      "2019-04-09 22:56:58,988 root         INFO     Train Epoch: 105 [6656/8000 (83%)]\tTotal Loss: 0.404586\n",
      "Reconstruction: 0.388634, Regularization: 0.015952\n",
      "2019-04-09 22:56:59,044 root         INFO     Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 0.443748\n",
      "Reconstruction: 0.425658, Regularization: 0.018090\n",
      "2019-04-09 22:56:59,099 root         INFO     Train Epoch: 105 [7680/8000 (96%)]\tTotal Loss: 0.407576\n",
      "Reconstruction: 0.386725, Regularization: 0.020850\n",
      "2019-04-09 22:56:59,148 root         INFO     ====> Epoch: 105 Average loss: 0.4518\n",
      "2019-04-09 22:56:59,171 root         INFO     Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 0.425859\n",
      "Reconstruction: 0.406428, Regularization: 0.019431\n",
      "2019-04-09 22:56:59,227 root         INFO     Train Epoch: 106 [512/8000 (6%)]\tTotal Loss: 0.322807\n",
      "Reconstruction: 0.310909, Regularization: 0.011897\n",
      "2019-04-09 22:56:59,283 root         INFO     Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 0.368807\n",
      "Reconstruction: 0.355055, Regularization: 0.013753\n",
      "2019-04-09 22:56:59,339 root         INFO     Train Epoch: 106 [1536/8000 (19%)]\tTotal Loss: 0.436315\n",
      "Reconstruction: 0.417468, Regularization: 0.018847\n",
      "2019-04-09 22:56:59,395 root         INFO     Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 0.411192\n",
      "Reconstruction: 0.396180, Regularization: 0.015012\n",
      "2019-04-09 22:56:59,451 root         INFO     Train Epoch: 106 [2560/8000 (32%)]\tTotal Loss: 0.342484\n",
      "Reconstruction: 0.329225, Regularization: 0.013259\n",
      "2019-04-09 22:56:59,506 root         INFO     Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 0.458736\n",
      "Reconstruction: 0.441948, Regularization: 0.016787\n",
      "2019-04-09 22:56:59,561 root         INFO     Train Epoch: 106 [3584/8000 (45%)]\tTotal Loss: 0.312547\n",
      "Reconstruction: 0.294632, Regularization: 0.017915\n",
      "2019-04-09 22:56:59,618 root         INFO     Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 0.347084\n",
      "Reconstruction: 0.331113, Regularization: 0.015971\n",
      "2019-04-09 22:56:59,675 root         INFO     Train Epoch: 106 [4608/8000 (58%)]\tTotal Loss: 0.383935\n",
      "Reconstruction: 0.367689, Regularization: 0.016246\n",
      "2019-04-09 22:56:59,730 root         INFO     Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 0.408747\n",
      "Reconstruction: 0.392659, Regularization: 0.016088\n",
      "2019-04-09 22:56:59,785 root         INFO     Train Epoch: 106 [5632/8000 (70%)]\tTotal Loss: 0.403843\n",
      "Reconstruction: 0.386602, Regularization: 0.017241\n",
      "2019-04-09 22:56:59,841 root         INFO     Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 0.412878\n",
      "Reconstruction: 0.398049, Regularization: 0.014829\n",
      "2019-04-09 22:56:59,896 root         INFO     Train Epoch: 106 [6656/8000 (83%)]\tTotal Loss: 0.325536\n",
      "Reconstruction: 0.310630, Regularization: 0.014906\n",
      "2019-04-09 22:56:59,953 root         INFO     Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 0.431363\n",
      "Reconstruction: 0.416231, Regularization: 0.015132\n",
      "2019-04-09 22:57:00,010 root         INFO     Train Epoch: 106 [7680/8000 (96%)]\tTotal Loss: 0.371971\n",
      "Reconstruction: 0.350824, Regularization: 0.021147\n",
      "2019-04-09 22:57:00,061 root         INFO     ====> Epoch: 106 Average loss: 0.4289\n",
      "2019-04-09 22:57:00,084 root         INFO     Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 0.399325\n",
      "Reconstruction: 0.384997, Regularization: 0.014328\n",
      "2019-04-09 22:57:00,141 root         INFO     Train Epoch: 107 [512/8000 (6%)]\tTotal Loss: 0.437835\n",
      "Reconstruction: 0.419007, Regularization: 0.018828\n",
      "2019-04-09 22:57:00,197 root         INFO     Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 0.441126\n",
      "Reconstruction: 0.410647, Regularization: 0.030478\n",
      "2019-04-09 22:57:00,254 root         INFO     Train Epoch: 107 [1536/8000 (19%)]\tTotal Loss: 0.369342\n",
      "Reconstruction: 0.351142, Regularization: 0.018200\n",
      "2019-04-09 22:57:00,310 root         INFO     Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 0.384084\n",
      "Reconstruction: 0.370139, Regularization: 0.013946\n",
      "2019-04-09 22:57:00,367 root         INFO     Train Epoch: 107 [2560/8000 (32%)]\tTotal Loss: 0.456915\n",
      "Reconstruction: 0.438843, Regularization: 0.018072\n",
      "2019-04-09 22:57:00,423 root         INFO     Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 0.415683\n",
      "Reconstruction: 0.398445, Regularization: 0.017238\n",
      "2019-04-09 22:57:00,479 root         INFO     Train Epoch: 107 [3584/8000 (45%)]\tTotal Loss: 0.345644\n",
      "Reconstruction: 0.333583, Regularization: 0.012061\n",
      "2019-04-09 22:57:00,536 root         INFO     Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 0.291391\n",
      "Reconstruction: 0.279550, Regularization: 0.011841\n",
      "2019-04-09 22:57:00,593 root         INFO     Train Epoch: 107 [4608/8000 (58%)]\tTotal Loss: 0.355720\n",
      "Reconstruction: 0.342477, Regularization: 0.013243\n",
      "2019-04-09 22:57:00,649 root         INFO     Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 0.457791\n",
      "Reconstruction: 0.440000, Regularization: 0.017791\n",
      "2019-04-09 22:57:00,705 root         INFO     Train Epoch: 107 [5632/8000 (70%)]\tTotal Loss: 0.335478\n",
      "Reconstruction: 0.322082, Regularization: 0.013396\n",
      "2019-04-09 22:57:00,761 root         INFO     Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 0.438843\n",
      "Reconstruction: 0.424007, Regularization: 0.014836\n",
      "2019-04-09 22:57:00,817 root         INFO     Train Epoch: 107 [6656/8000 (83%)]\tTotal Loss: 0.479192\n",
      "Reconstruction: 0.461096, Regularization: 0.018097\n",
      "2019-04-09 22:57:00,873 root         INFO     Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 0.436204\n",
      "Reconstruction: 0.418868, Regularization: 0.017336\n",
      "2019-04-09 22:57:00,929 root         INFO     Train Epoch: 107 [7680/8000 (96%)]\tTotal Loss: 0.418872\n",
      "Reconstruction: 0.402278, Regularization: 0.016595\n",
      "2019-04-09 22:57:00,978 root         INFO     ====> Epoch: 107 Average loss: 0.4564\n",
      "2019-04-09 22:57:01,001 root         INFO     Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 0.448179\n",
      "Reconstruction: 0.430603, Regularization: 0.017576\n",
      "2019-04-09 22:57:01,058 root         INFO     Train Epoch: 108 [512/8000 (6%)]\tTotal Loss: 0.503901\n",
      "Reconstruction: 0.486524, Regularization: 0.017377\n",
      "2019-04-09 22:57:01,116 root         INFO     Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 0.370796\n",
      "Reconstruction: 0.355956, Regularization: 0.014840\n",
      "2019-04-09 22:57:01,172 root         INFO     Train Epoch: 108 [1536/8000 (19%)]\tTotal Loss: 0.530146\n",
      "Reconstruction: 0.504483, Regularization: 0.025662\n",
      "2019-04-09 22:57:01,229 root         INFO     Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 0.466513\n",
      "Reconstruction: 0.449581, Regularization: 0.016932\n",
      "2019-04-09 22:57:01,285 root         INFO     Train Epoch: 108 [2560/8000 (32%)]\tTotal Loss: 0.312095\n",
      "Reconstruction: 0.300643, Regularization: 0.011452\n",
      "2019-04-09 22:57:01,341 root         INFO     Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 0.476844\n",
      "Reconstruction: 0.460170, Regularization: 0.016674\n",
      "2019-04-09 22:57:01,397 root         INFO     Train Epoch: 108 [3584/8000 (45%)]\tTotal Loss: 0.380067\n",
      "Reconstruction: 0.362613, Regularization: 0.017454\n",
      "2019-04-09 22:57:01,453 root         INFO     Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 0.412646\n",
      "Reconstruction: 0.395148, Regularization: 0.017497\n",
      "2019-04-09 22:57:01,509 root         INFO     Train Epoch: 108 [4608/8000 (58%)]\tTotal Loss: 0.420044\n",
      "Reconstruction: 0.398850, Regularization: 0.021195\n",
      "2019-04-09 22:57:01,566 root         INFO     Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 0.470154\n",
      "Reconstruction: 0.450452, Regularization: 0.019702\n",
      "2019-04-09 22:57:01,622 root         INFO     Train Epoch: 108 [5632/8000 (70%)]\tTotal Loss: 0.382404\n",
      "Reconstruction: 0.368275, Regularization: 0.014129\n",
      "2019-04-09 22:57:01,679 root         INFO     Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 0.375242\n",
      "Reconstruction: 0.363931, Regularization: 0.011311\n",
      "2019-04-09 22:57:01,735 root         INFO     Train Epoch: 108 [6656/8000 (83%)]\tTotal Loss: 0.352591\n",
      "Reconstruction: 0.340282, Regularization: 0.012310\n",
      "2019-04-09 22:57:01,791 root         INFO     Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 0.455631\n",
      "Reconstruction: 0.440104, Regularization: 0.015527\n",
      "2019-04-09 22:57:01,846 root         INFO     Train Epoch: 108 [7680/8000 (96%)]\tTotal Loss: 0.558892\n",
      "Reconstruction: 0.541846, Regularization: 0.017046\n",
      "2019-04-09 22:57:01,896 root         INFO     ====> Epoch: 108 Average loss: 0.8367\n",
      "2019-04-09 22:57:01,920 root         INFO     Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 0.538777\n",
      "Reconstruction: 0.520101, Regularization: 0.018677\n",
      "2019-04-09 22:57:01,977 root         INFO     Train Epoch: 109 [512/8000 (6%)]\tTotal Loss: 0.256860\n",
      "Reconstruction: 0.246680, Regularization: 0.010180\n",
      "2019-04-09 22:57:02,034 root         INFO     Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 0.427761\n",
      "Reconstruction: 0.410891, Regularization: 0.016870\n",
      "2019-04-09 22:57:02,091 root         INFO     Train Epoch: 109 [1536/8000 (19%)]\tTotal Loss: 0.311231\n",
      "Reconstruction: 0.298737, Regularization: 0.012494\n",
      "2019-04-09 22:57:02,148 root         INFO     Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 0.430895\n",
      "Reconstruction: 0.412246, Regularization: 0.018650\n",
      "2019-04-09 22:57:02,205 root         INFO     Train Epoch: 109 [2560/8000 (32%)]\tTotal Loss: 0.345831\n",
      "Reconstruction: 0.309372, Regularization: 0.036459\n",
      "2019-04-09 22:57:02,262 root         INFO     Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 0.420958\n",
      "Reconstruction: 0.404488, Regularization: 0.016470\n",
      "2019-04-09 22:57:02,319 root         INFO     Train Epoch: 109 [3584/8000 (45%)]\tTotal Loss: 0.379001\n",
      "Reconstruction: 0.365813, Regularization: 0.013189\n",
      "2019-04-09 22:57:02,375 root         INFO     Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 0.393474\n",
      "Reconstruction: 0.377630, Regularization: 0.015843\n",
      "2019-04-09 22:57:02,433 root         INFO     Train Epoch: 109 [4608/8000 (58%)]\tTotal Loss: 0.372271\n",
      "Reconstruction: 0.355720, Regularization: 0.016551\n",
      "2019-04-09 22:57:02,491 root         INFO     Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 0.417574\n",
      "Reconstruction: 0.399364, Regularization: 0.018210\n",
      "2019-04-09 22:57:02,548 root         INFO     Train Epoch: 109 [5632/8000 (70%)]\tTotal Loss: 0.393042\n",
      "Reconstruction: 0.378079, Regularization: 0.014963\n",
      "2019-04-09 22:57:02,604 root         INFO     Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 0.522666\n",
      "Reconstruction: 0.486732, Regularization: 0.035933\n",
      "2019-04-09 22:57:02,660 root         INFO     Train Epoch: 109 [6656/8000 (83%)]\tTotal Loss: 0.384934\n",
      "Reconstruction: 0.367786, Regularization: 0.017149\n",
      "2019-04-09 22:57:02,715 root         INFO     Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 0.488063\n",
      "Reconstruction: 0.467826, Regularization: 0.020237\n",
      "2019-04-09 22:57:02,771 root         INFO     Train Epoch: 109 [7680/8000 (96%)]\tTotal Loss: 0.401855\n",
      "Reconstruction: 0.383684, Regularization: 0.018171\n",
      "2019-04-09 22:57:02,822 root         INFO     ====> Epoch: 109 Average loss: 0.4159\n",
      "2019-04-09 22:57:02,846 root         INFO     Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 0.513965\n",
      "Reconstruction: 0.490203, Regularization: 0.023761\n",
      "2019-04-09 22:57:02,903 root         INFO     Train Epoch: 110 [512/8000 (6%)]\tTotal Loss: 0.379376\n",
      "Reconstruction: 0.357472, Regularization: 0.021905\n",
      "2019-04-09 22:57:02,960 root         INFO     Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 0.394106\n",
      "Reconstruction: 0.376987, Regularization: 0.017119\n",
      "2019-04-09 22:57:03,017 root         INFO     Train Epoch: 110 [1536/8000 (19%)]\tTotal Loss: 0.440544\n",
      "Reconstruction: 0.427034, Regularization: 0.013511\n",
      "2019-04-09 22:57:03,074 root         INFO     Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 0.435849\n",
      "Reconstruction: 0.411983, Regularization: 0.023866\n",
      "2019-04-09 22:57:03,130 root         INFO     Train Epoch: 110 [2560/8000 (32%)]\tTotal Loss: 0.345304\n",
      "Reconstruction: 0.329140, Regularization: 0.016163\n",
      "2019-04-09 22:57:03,187 root         INFO     Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 0.435384\n",
      "Reconstruction: 0.411460, Regularization: 0.023924\n",
      "2019-04-09 22:57:03,244 root         INFO     Train Epoch: 110 [3584/8000 (45%)]\tTotal Loss: 0.405225\n",
      "Reconstruction: 0.387340, Regularization: 0.017885\n",
      "2019-04-09 22:57:03,300 root         INFO     Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 0.471977\n",
      "Reconstruction: 0.448873, Regularization: 0.023104\n",
      "2019-04-09 22:57:03,357 root         INFO     Train Epoch: 110 [4608/8000 (58%)]\tTotal Loss: 0.374898\n",
      "Reconstruction: 0.360999, Regularization: 0.013899\n",
      "2019-04-09 22:57:03,414 root         INFO     Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 0.394314\n",
      "Reconstruction: 0.380463, Regularization: 0.013850\n",
      "2019-04-09 22:57:03,471 root         INFO     Train Epoch: 110 [5632/8000 (70%)]\tTotal Loss: 0.427782\n",
      "Reconstruction: 0.410517, Regularization: 0.017265\n",
      "2019-04-09 22:57:03,527 root         INFO     Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 0.394306\n",
      "Reconstruction: 0.378277, Regularization: 0.016029\n",
      "2019-04-09 22:57:03,584 root         INFO     Train Epoch: 110 [6656/8000 (83%)]\tTotal Loss: 0.427411\n",
      "Reconstruction: 0.414309, Regularization: 0.013102\n",
      "2019-04-09 22:57:03,640 root         INFO     Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 0.435013\n",
      "Reconstruction: 0.419600, Regularization: 0.015413\n",
      "2019-04-09 22:57:03,697 root         INFO     Train Epoch: 110 [7680/8000 (96%)]\tTotal Loss: 0.357492\n",
      "Reconstruction: 0.343449, Regularization: 0.014043\n",
      "2019-04-09 22:57:03,746 root         INFO     ====> Epoch: 110 Average loss: 0.4839\n",
      "2019-04-09 22:57:03,769 root         INFO     Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 0.386208\n",
      "Reconstruction: 0.367768, Regularization: 0.018440\n",
      "2019-04-09 22:57:03,827 root         INFO     Train Epoch: 111 [512/8000 (6%)]\tTotal Loss: 0.505957\n",
      "Reconstruction: 0.477528, Regularization: 0.028429\n",
      "2019-04-09 22:57:03,883 root         INFO     Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 0.509869\n",
      "Reconstruction: 0.490727, Regularization: 0.019143\n",
      "2019-04-09 22:57:03,940 root         INFO     Train Epoch: 111 [1536/8000 (19%)]\tTotal Loss: 0.448687\n",
      "Reconstruction: 0.428948, Regularization: 0.019738\n",
      "2019-04-09 22:57:03,996 root         INFO     Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 0.402748\n",
      "Reconstruction: 0.389547, Regularization: 0.013201\n",
      "2019-04-09 22:57:04,052 root         INFO     Train Epoch: 111 [2560/8000 (32%)]\tTotal Loss: 0.470293\n",
      "Reconstruction: 0.452003, Regularization: 0.018291\n",
      "2019-04-09 22:57:04,108 root         INFO     Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 0.395221\n",
      "Reconstruction: 0.378003, Regularization: 0.017217\n",
      "2019-04-09 22:57:04,163 root         INFO     Train Epoch: 111 [3584/8000 (45%)]\tTotal Loss: 0.383345\n",
      "Reconstruction: 0.359671, Regularization: 0.023674\n",
      "2019-04-09 22:57:04,219 root         INFO     Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 0.460553\n",
      "Reconstruction: 0.443840, Regularization: 0.016713\n",
      "2019-04-09 22:57:04,275 root         INFO     Train Epoch: 111 [4608/8000 (58%)]\tTotal Loss: 0.410270\n",
      "Reconstruction: 0.395797, Regularization: 0.014473\n",
      "2019-04-09 22:57:04,330 root         INFO     Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 0.373076\n",
      "Reconstruction: 0.358525, Regularization: 0.014550\n",
      "2019-04-09 22:57:04,386 root         INFO     Train Epoch: 111 [5632/8000 (70%)]\tTotal Loss: 0.453413\n",
      "Reconstruction: 0.435171, Regularization: 0.018243\n",
      "2019-04-09 22:57:04,442 root         INFO     Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 0.492990\n",
      "Reconstruction: 0.466228, Regularization: 0.026762\n",
      "2019-04-09 22:57:04,498 root         INFO     Train Epoch: 111 [6656/8000 (83%)]\tTotal Loss: 0.373796\n",
      "Reconstruction: 0.346085, Regularization: 0.027711\n",
      "2019-04-09 22:57:04,553 root         INFO     Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 0.419798\n",
      "Reconstruction: 0.404547, Regularization: 0.015251\n",
      "2019-04-09 22:57:04,608 root         INFO     Train Epoch: 111 [7680/8000 (96%)]\tTotal Loss: 0.469299\n",
      "Reconstruction: 0.448869, Regularization: 0.020430\n",
      "2019-04-09 22:57:04,658 root         INFO     ====> Epoch: 111 Average loss: 0.7084\n",
      "2019-04-09 22:57:04,681 root         INFO     Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 0.391358\n",
      "Reconstruction: 0.377671, Regularization: 0.013688\n",
      "2019-04-09 22:57:04,738 root         INFO     Train Epoch: 112 [512/8000 (6%)]\tTotal Loss: 0.392151\n",
      "Reconstruction: 0.377953, Regularization: 0.014197\n",
      "2019-04-09 22:57:04,794 root         INFO     Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 0.394351\n",
      "Reconstruction: 0.381316, Regularization: 0.013035\n",
      "2019-04-09 22:57:04,851 root         INFO     Train Epoch: 112 [1536/8000 (19%)]\tTotal Loss: 0.270605\n",
      "Reconstruction: 0.258146, Regularization: 0.012459\n",
      "2019-04-09 22:57:04,908 root         INFO     Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 0.523831\n",
      "Reconstruction: 0.501201, Regularization: 0.022630\n",
      "2019-04-09 22:57:04,963 root         INFO     Train Epoch: 112 [2560/8000 (32%)]\tTotal Loss: 0.452878\n",
      "Reconstruction: 0.433772, Regularization: 0.019106\n",
      "2019-04-09 22:57:05,019 root         INFO     Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 0.498095\n",
      "Reconstruction: 0.479018, Regularization: 0.019077\n",
      "2019-04-09 22:57:05,076 root         INFO     Train Epoch: 112 [3584/8000 (45%)]\tTotal Loss: 0.418649\n",
      "Reconstruction: 0.399569, Regularization: 0.019079\n",
      "2019-04-09 22:57:05,133 root         INFO     Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 0.429344\n",
      "Reconstruction: 0.409606, Regularization: 0.019737\n",
      "2019-04-09 22:57:05,190 root         INFO     Train Epoch: 112 [4608/8000 (58%)]\tTotal Loss: 0.386583\n",
      "Reconstruction: 0.366015, Regularization: 0.020568\n",
      "2019-04-09 22:57:05,246 root         INFO     Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 0.375012\n",
      "Reconstruction: 0.360930, Regularization: 0.014081\n",
      "2019-04-09 22:57:05,303 root         INFO     Train Epoch: 112 [5632/8000 (70%)]\tTotal Loss: 0.473709\n",
      "Reconstruction: 0.458091, Regularization: 0.015617\n",
      "2019-04-09 22:57:05,358 root         INFO     Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 0.417298\n",
      "Reconstruction: 0.395521, Regularization: 0.021777\n",
      "2019-04-09 22:57:05,413 root         INFO     Train Epoch: 112 [6656/8000 (83%)]\tTotal Loss: 0.530185\n",
      "Reconstruction: 0.510715, Regularization: 0.019470\n",
      "2019-04-09 22:57:05,468 root         INFO     Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 0.302029\n",
      "Reconstruction: 0.287253, Regularization: 0.014776\n",
      "2019-04-09 22:57:05,524 root         INFO     Train Epoch: 112 [7680/8000 (96%)]\tTotal Loss: 0.416826\n",
      "Reconstruction: 0.401448, Regularization: 0.015379\n",
      "2019-04-09 22:57:05,574 root         INFO     ====> Epoch: 112 Average loss: 0.4272\n",
      "2019-04-09 22:57:05,597 root         INFO     Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 0.291087\n",
      "Reconstruction: 0.274777, Regularization: 0.016310\n",
      "2019-04-09 22:57:05,654 root         INFO     Train Epoch: 113 [512/8000 (6%)]\tTotal Loss: 0.453154\n",
      "Reconstruction: 0.434041, Regularization: 0.019113\n",
      "2019-04-09 22:57:05,711 root         INFO     Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 0.416918\n",
      "Reconstruction: 0.403365, Regularization: 0.013553\n",
      "2019-04-09 22:57:05,768 root         INFO     Train Epoch: 113 [1536/8000 (19%)]\tTotal Loss: 0.479265\n",
      "Reconstruction: 0.460728, Regularization: 0.018537\n",
      "2019-04-09 22:57:05,825 root         INFO     Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 0.401370\n",
      "Reconstruction: 0.380066, Regularization: 0.021304\n",
      "2019-04-09 22:57:05,882 root         INFO     Train Epoch: 113 [2560/8000 (32%)]\tTotal Loss: 0.466085\n",
      "Reconstruction: 0.447227, Regularization: 0.018858\n",
      "2019-04-09 22:57:05,938 root         INFO     Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 0.398174\n",
      "Reconstruction: 0.386669, Regularization: 0.011505\n",
      "2019-04-09 22:57:05,995 root         INFO     Train Epoch: 113 [3584/8000 (45%)]\tTotal Loss: 0.298854\n",
      "Reconstruction: 0.285857, Regularization: 0.012997\n",
      "2019-04-09 22:57:06,052 root         INFO     Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 0.365929\n",
      "Reconstruction: 0.353591, Regularization: 0.012338\n",
      "2019-04-09 22:57:06,109 root         INFO     Train Epoch: 113 [4608/8000 (58%)]\tTotal Loss: 0.443126\n",
      "Reconstruction: 0.427440, Regularization: 0.015687\n",
      "2019-04-09 22:57:06,165 root         INFO     Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 0.356570\n",
      "Reconstruction: 0.342056, Regularization: 0.014514\n",
      "2019-04-09 22:57:06,221 root         INFO     Train Epoch: 113 [5632/8000 (70%)]\tTotal Loss: 0.365687\n",
      "Reconstruction: 0.351469, Regularization: 0.014218\n",
      "2019-04-09 22:57:06,278 root         INFO     Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 0.398960\n",
      "Reconstruction: 0.382119, Regularization: 0.016841\n",
      "2019-04-09 22:57:06,334 root         INFO     Train Epoch: 113 [6656/8000 (83%)]\tTotal Loss: 0.414447\n",
      "Reconstruction: 0.397363, Regularization: 0.017084\n",
      "2019-04-09 22:57:06,391 root         INFO     Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 0.368122\n",
      "Reconstruction: 0.349340, Regularization: 0.018782\n",
      "2019-04-09 22:57:06,448 root         INFO     Train Epoch: 113 [7680/8000 (96%)]\tTotal Loss: 0.385447\n",
      "Reconstruction: 0.364682, Regularization: 0.020765\n",
      "2019-04-09 22:57:06,498 root         INFO     ====> Epoch: 113 Average loss: 0.4202\n",
      "2019-04-09 22:57:06,521 root         INFO     Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 0.463947\n",
      "Reconstruction: 0.444033, Regularization: 0.019914\n",
      "2019-04-09 22:57:06,578 root         INFO     Train Epoch: 114 [512/8000 (6%)]\tTotal Loss: 0.371591\n",
      "Reconstruction: 0.349767, Regularization: 0.021824\n",
      "2019-04-09 22:57:06,635 root         INFO     Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 13.117705\n",
      "Reconstruction: 13.097239, Regularization: 0.020465\n",
      "2019-04-09 22:57:06,691 root         INFO     Train Epoch: 114 [1536/8000 (19%)]\tTotal Loss: 0.420620\n",
      "Reconstruction: 0.405233, Regularization: 0.015387\n",
      "2019-04-09 22:57:06,748 root         INFO     Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 0.354577\n",
      "Reconstruction: 0.340294, Regularization: 0.014283\n",
      "2019-04-09 22:57:06,804 root         INFO     Train Epoch: 114 [2560/8000 (32%)]\tTotal Loss: 0.380169\n",
      "Reconstruction: 0.356033, Regularization: 0.024136\n",
      "2019-04-09 22:57:06,861 root         INFO     Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 0.351626\n",
      "Reconstruction: 0.335847, Regularization: 0.015779\n",
      "2019-04-09 22:57:06,917 root         INFO     Train Epoch: 114 [3584/8000 (45%)]\tTotal Loss: 0.378589\n",
      "Reconstruction: 0.361303, Regularization: 0.017286\n",
      "2019-04-09 22:57:06,974 root         INFO     Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 0.383317\n",
      "Reconstruction: 0.369025, Regularization: 0.014292\n",
      "2019-04-09 22:57:07,030 root         INFO     Train Epoch: 114 [4608/8000 (58%)]\tTotal Loss: 0.445656\n",
      "Reconstruction: 0.428621, Regularization: 0.017035\n",
      "2019-04-09 22:57:07,087 root         INFO     Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 0.370463\n",
      "Reconstruction: 0.356311, Regularization: 0.014153\n",
      "2019-04-09 22:57:07,143 root         INFO     Train Epoch: 114 [5632/8000 (70%)]\tTotal Loss: 0.438743\n",
      "Reconstruction: 0.396769, Regularization: 0.041974\n",
      "2019-04-09 22:57:07,199 root         INFO     Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 0.488063\n",
      "Reconstruction: 0.468812, Regularization: 0.019250\n",
      "2019-04-09 22:57:07,256 root         INFO     Train Epoch: 114 [6656/8000 (83%)]\tTotal Loss: 0.451099\n",
      "Reconstruction: 0.434221, Regularization: 0.016878\n",
      "2019-04-09 22:57:07,312 root         INFO     Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 0.477847\n",
      "Reconstruction: 0.453938, Regularization: 0.023909\n",
      "2019-04-09 22:57:07,368 root         INFO     Train Epoch: 114 [7680/8000 (96%)]\tTotal Loss: 0.382256\n",
      "Reconstruction: 0.367868, Regularization: 0.014388\n",
      "2019-04-09 22:57:07,418 root         INFO     ====> Epoch: 114 Average loss: 0.4759\n",
      "2019-04-09 22:57:07,441 root         INFO     Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 0.414402\n",
      "Reconstruction: 0.396566, Regularization: 0.017836\n",
      "2019-04-09 22:57:07,498 root         INFO     Train Epoch: 115 [512/8000 (6%)]\tTotal Loss: 0.478457\n",
      "Reconstruction: 0.461470, Regularization: 0.016987\n",
      "2019-04-09 22:57:07,554 root         INFO     Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 0.453227\n",
      "Reconstruction: 0.435070, Regularization: 0.018157\n",
      "2019-04-09 22:57:07,611 root         INFO     Train Epoch: 115 [1536/8000 (19%)]\tTotal Loss: 0.424094\n",
      "Reconstruction: 0.406930, Regularization: 0.017164\n",
      "2019-04-09 22:57:07,667 root         INFO     Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 0.341892\n",
      "Reconstruction: 0.325211, Regularization: 0.016681\n",
      "2019-04-09 22:57:07,725 root         INFO     Train Epoch: 115 [2560/8000 (32%)]\tTotal Loss: 0.451156\n",
      "Reconstruction: 0.426040, Regularization: 0.025116\n",
      "2019-04-09 22:57:07,782 root         INFO     Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 0.468170\n",
      "Reconstruction: 0.451262, Regularization: 0.016908\n",
      "2019-04-09 22:57:07,839 root         INFO     Train Epoch: 115 [3584/8000 (45%)]\tTotal Loss: 0.412749\n",
      "Reconstruction: 0.399598, Regularization: 0.013151\n",
      "2019-04-09 22:57:07,898 root         INFO     Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 0.321296\n",
      "Reconstruction: 0.307622, Regularization: 0.013675\n",
      "2019-04-09 22:57:07,953 root         INFO     Train Epoch: 115 [4608/8000 (58%)]\tTotal Loss: 0.425851\n",
      "Reconstruction: 0.411241, Regularization: 0.014610\n",
      "2019-04-09 22:57:08,008 root         INFO     Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 1.669736\n",
      "Reconstruction: 1.645400, Regularization: 0.024336\n",
      "2019-04-09 22:57:08,064 root         INFO     Train Epoch: 115 [5632/8000 (70%)]\tTotal Loss: 0.324076\n",
      "Reconstruction: 0.309911, Regularization: 0.014165\n",
      "2019-04-09 22:57:08,119 root         INFO     Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 0.322928\n",
      "Reconstruction: 0.310904, Regularization: 0.012023\n",
      "2019-04-09 22:57:08,174 root         INFO     Train Epoch: 115 [6656/8000 (83%)]\tTotal Loss: 0.442459\n",
      "Reconstruction: 0.425246, Regularization: 0.017214\n",
      "2019-04-09 22:57:08,230 root         INFO     Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 0.308527\n",
      "Reconstruction: 0.295946, Regularization: 0.012581\n",
      "2019-04-09 22:57:08,285 root         INFO     Train Epoch: 115 [7680/8000 (96%)]\tTotal Loss: 0.520367\n",
      "Reconstruction: 0.492153, Regularization: 0.028215\n",
      "2019-04-09 22:57:08,335 root         INFO     ====> Epoch: 115 Average loss: 1.3194\n",
      "2019-04-09 22:57:08,359 root         INFO     Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 0.480705\n",
      "Reconstruction: 0.445595, Regularization: 0.035111\n",
      "2019-04-09 22:57:08,414 root         INFO     Train Epoch: 116 [512/8000 (6%)]\tTotal Loss: 0.310580\n",
      "Reconstruction: 0.298288, Regularization: 0.012292\n",
      "2019-04-09 22:57:08,469 root         INFO     Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 0.327685\n",
      "Reconstruction: 0.310854, Regularization: 0.016830\n",
      "2019-04-09 22:57:08,524 root         INFO     Train Epoch: 116 [1536/8000 (19%)]\tTotal Loss: 0.407805\n",
      "Reconstruction: 0.391011, Regularization: 0.016794\n",
      "2019-04-09 22:57:08,579 root         INFO     Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 0.384740\n",
      "Reconstruction: 0.365461, Regularization: 0.019280\n",
      "2019-04-09 22:57:08,633 root         INFO     Train Epoch: 116 [2560/8000 (32%)]\tTotal Loss: 0.372511\n",
      "Reconstruction: 0.356820, Regularization: 0.015690\n",
      "2019-04-09 22:57:08,688 root         INFO     Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 0.462903\n",
      "Reconstruction: 0.421213, Regularization: 0.041690\n",
      "2019-04-09 22:57:08,743 root         INFO     Train Epoch: 116 [3584/8000 (45%)]\tTotal Loss: 0.455629\n",
      "Reconstruction: 0.440311, Regularization: 0.015319\n",
      "2019-04-09 22:57:08,798 root         INFO     Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 0.438120\n",
      "Reconstruction: 0.415484, Regularization: 0.022636\n",
      "2019-04-09 22:57:08,854 root         INFO     Train Epoch: 116 [4608/8000 (58%)]\tTotal Loss: 0.430900\n",
      "Reconstruction: 0.412705, Regularization: 0.018195\n",
      "2019-04-09 22:57:08,909 root         INFO     Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 0.379208\n",
      "Reconstruction: 0.364134, Regularization: 0.015074\n",
      "2019-04-09 22:57:08,964 root         INFO     Train Epoch: 116 [5632/8000 (70%)]\tTotal Loss: 0.425769\n",
      "Reconstruction: 0.409666, Regularization: 0.016103\n",
      "2019-04-09 22:57:09,020 root         INFO     Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 0.288298\n",
      "Reconstruction: 0.276457, Regularization: 0.011840\n",
      "2019-04-09 22:57:09,075 root         INFO     Train Epoch: 116 [6656/8000 (83%)]\tTotal Loss: 0.380134\n",
      "Reconstruction: 0.367190, Regularization: 0.012944\n",
      "2019-04-09 22:57:09,130 root         INFO     Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 0.411148\n",
      "Reconstruction: 0.390110, Regularization: 0.021038\n",
      "2019-04-09 22:57:09,186 root         INFO     Train Epoch: 116 [7680/8000 (96%)]\tTotal Loss: 0.790828\n",
      "Reconstruction: 0.774854, Regularization: 0.015974\n",
      "2019-04-09 22:57:09,235 root         INFO     ====> Epoch: 116 Average loss: 0.4607\n",
      "2019-04-09 22:57:09,258 root         INFO     Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 0.345587\n",
      "Reconstruction: 0.330527, Regularization: 0.015060\n",
      "2019-04-09 22:57:09,314 root         INFO     Train Epoch: 117 [512/8000 (6%)]\tTotal Loss: 0.395555\n",
      "Reconstruction: 0.374701, Regularization: 0.020854\n",
      "2019-04-09 22:57:09,371 root         INFO     Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 0.481350\n",
      "Reconstruction: 0.461126, Regularization: 0.020223\n",
      "2019-04-09 22:57:09,428 root         INFO     Train Epoch: 117 [1536/8000 (19%)]\tTotal Loss: 0.449503\n",
      "Reconstruction: 0.429797, Regularization: 0.019706\n",
      "2019-04-09 22:57:09,484 root         INFO     Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 0.458033\n",
      "Reconstruction: 0.437167, Regularization: 0.020866\n",
      "2019-04-09 22:57:09,540 root         INFO     Train Epoch: 117 [2560/8000 (32%)]\tTotal Loss: 0.438757\n",
      "Reconstruction: 0.422830, Regularization: 0.015927\n",
      "2019-04-09 22:57:09,597 root         INFO     Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 0.287390\n",
      "Reconstruction: 0.276854, Regularization: 0.010536\n",
      "2019-04-09 22:57:09,654 root         INFO     Train Epoch: 117 [3584/8000 (45%)]\tTotal Loss: 0.405541\n",
      "Reconstruction: 0.388106, Regularization: 0.017435\n",
      "2019-04-09 22:57:09,710 root         INFO     Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 0.357930\n",
      "Reconstruction: 0.343366, Regularization: 0.014564\n",
      "2019-04-09 22:57:09,767 root         INFO     Train Epoch: 117 [4608/8000 (58%)]\tTotal Loss: 0.502387\n",
      "Reconstruction: 0.485662, Regularization: 0.016725\n",
      "2019-04-09 22:57:09,824 root         INFO     Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 0.410592\n",
      "Reconstruction: 0.391896, Regularization: 0.018696\n",
      "2019-04-09 22:57:09,881 root         INFO     Train Epoch: 117 [5632/8000 (70%)]\tTotal Loss: 0.485845\n",
      "Reconstruction: 0.465713, Regularization: 0.020132\n",
      "2019-04-09 22:57:09,937 root         INFO     Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 0.388035\n",
      "Reconstruction: 0.372749, Regularization: 0.015286\n",
      "2019-04-09 22:57:09,994 root         INFO     Train Epoch: 117 [6656/8000 (83%)]\tTotal Loss: 0.397695\n",
      "Reconstruction: 0.381300, Regularization: 0.016395\n",
      "2019-04-09 22:57:10,051 root         INFO     Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 0.448712\n",
      "Reconstruction: 0.432034, Regularization: 0.016678\n",
      "2019-04-09 22:57:10,108 root         INFO     Train Epoch: 117 [7680/8000 (96%)]\tTotal Loss: 0.373034\n",
      "Reconstruction: 0.356691, Regularization: 0.016344\n",
      "2019-04-09 22:57:10,158 root         INFO     ====> Epoch: 117 Average loss: 0.6120\n",
      "2019-04-09 22:57:10,181 root         INFO     Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 0.471859\n",
      "Reconstruction: 0.457860, Regularization: 0.014000\n",
      "2019-04-09 22:57:10,237 root         INFO     Train Epoch: 118 [512/8000 (6%)]\tTotal Loss: 0.421007\n",
      "Reconstruction: 0.397497, Regularization: 0.023510\n",
      "2019-04-09 22:57:10,293 root         INFO     Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 0.314719\n",
      "Reconstruction: 0.300466, Regularization: 0.014254\n",
      "2019-04-09 22:57:10,348 root         INFO     Train Epoch: 118 [1536/8000 (19%)]\tTotal Loss: 0.403630\n",
      "Reconstruction: 0.382899, Regularization: 0.020730\n",
      "2019-04-09 22:57:10,403 root         INFO     Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 0.498570\n",
      "Reconstruction: 0.482434, Regularization: 0.016136\n",
      "2019-04-09 22:57:10,459 root         INFO     Train Epoch: 118 [2560/8000 (32%)]\tTotal Loss: 0.451436\n",
      "Reconstruction: 0.433427, Regularization: 0.018009\n",
      "2019-04-09 22:57:10,513 root         INFO     Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 0.333869\n",
      "Reconstruction: 0.319450, Regularization: 0.014419\n",
      "2019-04-09 22:57:10,567 root         INFO     Train Epoch: 118 [3584/8000 (45%)]\tTotal Loss: 0.482387\n",
      "Reconstruction: 0.464100, Regularization: 0.018287\n",
      "2019-04-09 22:57:10,622 root         INFO     Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 0.398202\n",
      "Reconstruction: 0.385406, Regularization: 0.012796\n",
      "2019-04-09 22:57:10,677 root         INFO     Train Epoch: 118 [4608/8000 (58%)]\tTotal Loss: 7.982132\n",
      "Reconstruction: 7.949931, Regularization: 0.032202\n",
      "2019-04-09 22:57:10,733 root         INFO     Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 0.416537\n",
      "Reconstruction: 0.400333, Regularization: 0.016204\n",
      "2019-04-09 22:57:10,788 root         INFO     Train Epoch: 118 [5632/8000 (70%)]\tTotal Loss: 0.359769\n",
      "Reconstruction: 0.340883, Regularization: 0.018886\n",
      "2019-04-09 22:57:10,843 root         INFO     Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 0.377660\n",
      "Reconstruction: 0.354991, Regularization: 0.022669\n",
      "2019-04-09 22:57:10,898 root         INFO     Train Epoch: 118 [6656/8000 (83%)]\tTotal Loss: 0.339950\n",
      "Reconstruction: 0.329903, Regularization: 0.010047\n",
      "2019-04-09 22:57:10,952 root         INFO     Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 0.571345\n",
      "Reconstruction: 0.549522, Regularization: 0.021823\n",
      "2019-04-09 22:57:11,007 root         INFO     Train Epoch: 118 [7680/8000 (96%)]\tTotal Loss: 0.499242\n",
      "Reconstruction: 0.478900, Regularization: 0.020342\n",
      "2019-04-09 22:57:11,055 root         INFO     ====> Epoch: 118 Average loss: 1.1369\n",
      "2019-04-09 22:57:11,079 root         INFO     Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 0.422172\n",
      "Reconstruction: 0.404759, Regularization: 0.017413\n",
      "2019-04-09 22:57:11,134 root         INFO     Train Epoch: 119 [512/8000 (6%)]\tTotal Loss: 0.356698\n",
      "Reconstruction: 0.340104, Regularization: 0.016594\n",
      "2019-04-09 22:57:11,189 root         INFO     Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 0.374042\n",
      "Reconstruction: 0.360648, Regularization: 0.013393\n",
      "2019-04-09 22:57:11,243 root         INFO     Train Epoch: 119 [1536/8000 (19%)]\tTotal Loss: 0.531590\n",
      "Reconstruction: 0.510256, Regularization: 0.021334\n",
      "2019-04-09 22:57:11,298 root         INFO     Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 0.437287\n",
      "Reconstruction: 0.413292, Regularization: 0.023995\n",
      "2019-04-09 22:57:11,353 root         INFO     Train Epoch: 119 [2560/8000 (32%)]\tTotal Loss: 0.437447\n",
      "Reconstruction: 0.417695, Regularization: 0.019752\n",
      "2019-04-09 22:57:11,408 root         INFO     Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 0.427960\n",
      "Reconstruction: 0.397551, Regularization: 0.030410\n",
      "2019-04-09 22:57:11,463 root         INFO     Train Epoch: 119 [3584/8000 (45%)]\tTotal Loss: 0.502252\n",
      "Reconstruction: 0.483854, Regularization: 0.018398\n",
      "2019-04-09 22:57:11,517 root         INFO     Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 0.435968\n",
      "Reconstruction: 0.416560, Regularization: 0.019408\n",
      "2019-04-09 22:57:11,571 root         INFO     Train Epoch: 119 [4608/8000 (58%)]\tTotal Loss: 0.343723\n",
      "Reconstruction: 0.329845, Regularization: 0.013877\n",
      "2019-04-09 22:57:11,625 root         INFO     Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 0.497068\n",
      "Reconstruction: 0.478571, Regularization: 0.018497\n",
      "2019-04-09 22:57:11,679 root         INFO     Train Epoch: 119 [5632/8000 (70%)]\tTotal Loss: 0.398005\n",
      "Reconstruction: 0.376643, Regularization: 0.021362\n",
      "2019-04-09 22:57:11,733 root         INFO     Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 0.435527\n",
      "Reconstruction: 0.418121, Regularization: 0.017406\n",
      "2019-04-09 22:57:11,788 root         INFO     Train Epoch: 119 [6656/8000 (83%)]\tTotal Loss: 0.416261\n",
      "Reconstruction: 0.401738, Regularization: 0.014523\n",
      "2019-04-09 22:57:11,842 root         INFO     Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 0.437991\n",
      "Reconstruction: 0.421199, Regularization: 0.016792\n",
      "2019-04-09 22:57:11,896 root         INFO     Train Epoch: 119 [7680/8000 (96%)]\tTotal Loss: 0.359221\n",
      "Reconstruction: 0.344682, Regularization: 0.014539\n",
      "2019-04-09 22:57:11,944 root         INFO     ====> Epoch: 119 Average loss: 0.4445\n",
      "2019-04-09 22:57:11,968 root         INFO     Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 0.356483\n",
      "Reconstruction: 0.337677, Regularization: 0.018805\n",
      "2019-04-09 22:57:12,024 root         INFO     Train Epoch: 120 [512/8000 (6%)]\tTotal Loss: 0.339477\n",
      "Reconstruction: 0.316640, Regularization: 0.022837\n",
      "2019-04-09 22:57:12,078 root         INFO     Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 0.660716\n",
      "Reconstruction: 0.636576, Regularization: 0.024141\n",
      "2019-04-09 22:57:12,133 root         INFO     Train Epoch: 120 [1536/8000 (19%)]\tTotal Loss: 0.349762\n",
      "Reconstruction: 0.335513, Regularization: 0.014248\n",
      "2019-04-09 22:57:12,187 root         INFO     Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 0.362146\n",
      "Reconstruction: 0.344700, Regularization: 0.017446\n",
      "2019-04-09 22:57:12,242 root         INFO     Train Epoch: 120 [2560/8000 (32%)]\tTotal Loss: 0.401147\n",
      "Reconstruction: 0.374485, Regularization: 0.026662\n",
      "2019-04-09 22:57:12,296 root         INFO     Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 0.440065\n",
      "Reconstruction: 0.423740, Regularization: 0.016325\n",
      "2019-04-09 22:57:12,351 root         INFO     Train Epoch: 120 [3584/8000 (45%)]\tTotal Loss: 0.465979\n",
      "Reconstruction: 0.443364, Regularization: 0.022615\n",
      "2019-04-09 22:57:12,405 root         INFO     Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 0.380377\n",
      "Reconstruction: 0.364054, Regularization: 0.016323\n",
      "2019-04-09 22:57:12,460 root         INFO     Train Epoch: 120 [4608/8000 (58%)]\tTotal Loss: 0.338170\n",
      "Reconstruction: 0.323037, Regularization: 0.015132\n",
      "2019-04-09 22:57:12,514 root         INFO     Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 0.380836\n",
      "Reconstruction: 0.362002, Regularization: 0.018834\n",
      "2019-04-09 22:57:12,568 root         INFO     Train Epoch: 120 [5632/8000 (70%)]\tTotal Loss: 0.411422\n",
      "Reconstruction: 0.397624, Regularization: 0.013798\n",
      "2019-04-09 22:57:12,623 root         INFO     Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 0.347604\n",
      "Reconstruction: 0.332901, Regularization: 0.014703\n",
      "2019-04-09 22:57:12,677 root         INFO     Train Epoch: 120 [6656/8000 (83%)]\tTotal Loss: 0.430948\n",
      "Reconstruction: 0.412975, Regularization: 0.017973\n",
      "2019-04-09 22:57:12,731 root         INFO     Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 0.334669\n",
      "Reconstruction: 0.322044, Regularization: 0.012625\n",
      "2019-04-09 22:57:12,786 root         INFO     Train Epoch: 120 [7680/8000 (96%)]\tTotal Loss: 0.515126\n",
      "Reconstruction: 0.497214, Regularization: 0.017912\n",
      "2019-04-09 22:57:12,834 root         INFO     ====> Epoch: 120 Average loss: 0.4687\n",
      "2019-04-09 22:57:12,858 root         INFO     Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 0.363807\n",
      "Reconstruction: 0.342411, Regularization: 0.021397\n",
      "2019-04-09 22:57:12,914 root         INFO     Train Epoch: 121 [512/8000 (6%)]\tTotal Loss: 0.450660\n",
      "Reconstruction: 0.429440, Regularization: 0.021220\n",
      "2019-04-09 22:57:12,969 root         INFO     Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 0.459394\n",
      "Reconstruction: 0.444004, Regularization: 0.015390\n",
      "2019-04-09 22:57:13,025 root         INFO     Train Epoch: 121 [1536/8000 (19%)]\tTotal Loss: 0.398441\n",
      "Reconstruction: 0.384471, Regularization: 0.013970\n",
      "2019-04-09 22:57:13,081 root         INFO     Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 0.398520\n",
      "Reconstruction: 0.376907, Regularization: 0.021613\n",
      "2019-04-09 22:57:13,136 root         INFO     Train Epoch: 121 [2560/8000 (32%)]\tTotal Loss: 0.377999\n",
      "Reconstruction: 0.364166, Regularization: 0.013833\n",
      "2019-04-09 22:57:13,192 root         INFO     Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 0.456515\n",
      "Reconstruction: 0.439362, Regularization: 0.017153\n",
      "2019-04-09 22:57:13,247 root         INFO     Train Epoch: 121 [3584/8000 (45%)]\tTotal Loss: 0.413525\n",
      "Reconstruction: 0.398885, Regularization: 0.014640\n",
      "2019-04-09 22:57:13,303 root         INFO     Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 0.411944\n",
      "Reconstruction: 0.398587, Regularization: 0.013357\n",
      "2019-04-09 22:57:13,358 root         INFO     Train Epoch: 121 [4608/8000 (58%)]\tTotal Loss: 0.338534\n",
      "Reconstruction: 0.324726, Regularization: 0.013808\n",
      "2019-04-09 22:57:13,414 root         INFO     Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 0.460590\n",
      "Reconstruction: 0.443645, Regularization: 0.016945\n",
      "2019-04-09 22:57:13,468 root         INFO     Train Epoch: 121 [5632/8000 (70%)]\tTotal Loss: 0.557504\n",
      "Reconstruction: 0.538393, Regularization: 0.019111\n",
      "2019-04-09 22:57:13,523 root         INFO     Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 0.542423\n",
      "Reconstruction: 0.516896, Regularization: 0.025527\n",
      "2019-04-09 22:57:13,577 root         INFO     Train Epoch: 121 [6656/8000 (83%)]\tTotal Loss: 0.384707\n",
      "Reconstruction: 0.368608, Regularization: 0.016099\n",
      "2019-04-09 22:57:13,631 root         INFO     Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 0.413087\n",
      "Reconstruction: 0.396977, Regularization: 0.016109\n",
      "2019-04-09 22:57:13,685 root         INFO     Train Epoch: 121 [7680/8000 (96%)]\tTotal Loss: 0.439839\n",
      "Reconstruction: 0.423552, Regularization: 0.016287\n",
      "2019-04-09 22:57:13,734 root         INFO     ====> Epoch: 121 Average loss: 0.4306\n",
      "2019-04-09 22:57:13,757 root         INFO     Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 0.317356\n",
      "Reconstruction: 0.306424, Regularization: 0.010932\n",
      "2019-04-09 22:57:13,812 root         INFO     Train Epoch: 122 [512/8000 (6%)]\tTotal Loss: 0.493954\n",
      "Reconstruction: 0.472036, Regularization: 0.021919\n",
      "2019-04-09 22:57:13,867 root         INFO     Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 0.434584\n",
      "Reconstruction: 0.416632, Regularization: 0.017951\n",
      "2019-04-09 22:57:13,924 root         INFO     Train Epoch: 122 [1536/8000 (19%)]\tTotal Loss: 0.393173\n",
      "Reconstruction: 0.358862, Regularization: 0.034311\n",
      "2019-04-09 22:57:13,981 root         INFO     Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 0.296214\n",
      "Reconstruction: 0.283225, Regularization: 0.012989\n",
      "2019-04-09 22:57:14,038 root         INFO     Train Epoch: 122 [2560/8000 (32%)]\tTotal Loss: 0.471982\n",
      "Reconstruction: 0.449201, Regularization: 0.022780\n",
      "2019-04-09 22:57:14,095 root         INFO     Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 0.431363\n",
      "Reconstruction: 0.414144, Regularization: 0.017219\n",
      "2019-04-09 22:57:14,151 root         INFO     Train Epoch: 122 [3584/8000 (45%)]\tTotal Loss: 0.375935\n",
      "Reconstruction: 0.358756, Regularization: 0.017179\n",
      "2019-04-09 22:57:14,208 root         INFO     Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 0.389024\n",
      "Reconstruction: 0.370076, Regularization: 0.018948\n",
      "2019-04-09 22:57:14,264 root         INFO     Train Epoch: 122 [4608/8000 (58%)]\tTotal Loss: 0.349412\n",
      "Reconstruction: 0.335967, Regularization: 0.013445\n",
      "2019-04-09 22:57:14,320 root         INFO     Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 0.372792\n",
      "Reconstruction: 0.356559, Regularization: 0.016233\n",
      "2019-04-09 22:57:14,377 root         INFO     Train Epoch: 122 [5632/8000 (70%)]\tTotal Loss: 0.429004\n",
      "Reconstruction: 0.413385, Regularization: 0.015619\n",
      "2019-04-09 22:57:14,433 root         INFO     Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 0.514913\n",
      "Reconstruction: 0.497903, Regularization: 0.017010\n",
      "2019-04-09 22:57:14,490 root         INFO     Train Epoch: 122 [6656/8000 (83%)]\tTotal Loss: 0.362540\n",
      "Reconstruction: 0.348101, Regularization: 0.014439\n",
      "2019-04-09 22:57:14,547 root         INFO     Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 0.392742\n",
      "Reconstruction: 0.378240, Regularization: 0.014502\n",
      "2019-04-09 22:57:14,604 root         INFO     Train Epoch: 122 [7680/8000 (96%)]\tTotal Loss: 0.347077\n",
      "Reconstruction: 0.334534, Regularization: 0.012543\n",
      "2019-04-09 22:57:14,654 root         INFO     ====> Epoch: 122 Average loss: 0.4326\n",
      "2019-04-09 22:57:14,677 root         INFO     Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 0.415419\n",
      "Reconstruction: 0.374496, Regularization: 0.040922\n",
      "2019-04-09 22:57:14,733 root         INFO     Train Epoch: 123 [512/8000 (6%)]\tTotal Loss: 0.351398\n",
      "Reconstruction: 0.336288, Regularization: 0.015110\n",
      "2019-04-09 22:57:14,788 root         INFO     Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 0.392354\n",
      "Reconstruction: 0.377819, Regularization: 0.014535\n",
      "2019-04-09 22:57:14,843 root         INFO     Train Epoch: 123 [1536/8000 (19%)]\tTotal Loss: 0.346293\n",
      "Reconstruction: 0.332000, Regularization: 0.014293\n",
      "2019-04-09 22:57:14,899 root         INFO     Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 0.416937\n",
      "Reconstruction: 0.402855, Regularization: 0.014082\n",
      "2019-04-09 22:57:14,953 root         INFO     Train Epoch: 123 [2560/8000 (32%)]\tTotal Loss: 0.453865\n",
      "Reconstruction: 0.432720, Regularization: 0.021146\n",
      "2019-04-09 22:57:15,007 root         INFO     Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 0.468248\n",
      "Reconstruction: 0.450772, Regularization: 0.017476\n",
      "2019-04-09 22:57:15,061 root         INFO     Train Epoch: 123 [3584/8000 (45%)]\tTotal Loss: 0.419879\n",
      "Reconstruction: 0.400620, Regularization: 0.019259\n",
      "2019-04-09 22:57:15,115 root         INFO     Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 0.361338\n",
      "Reconstruction: 0.338022, Regularization: 0.023316\n",
      "2019-04-09 22:57:15,170 root         INFO     Train Epoch: 123 [4608/8000 (58%)]\tTotal Loss: 0.387243\n",
      "Reconstruction: 0.370026, Regularization: 0.017217\n",
      "2019-04-09 22:57:15,225 root         INFO     Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 0.506113\n",
      "Reconstruction: 0.484078, Regularization: 0.022035\n",
      "2019-04-09 22:57:15,279 root         INFO     Train Epoch: 123 [5632/8000 (70%)]\tTotal Loss: 0.432948\n",
      "Reconstruction: 0.402395, Regularization: 0.030553\n",
      "2019-04-09 22:57:15,334 root         INFO     Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 0.383123\n",
      "Reconstruction: 0.367961, Regularization: 0.015161\n",
      "2019-04-09 22:57:15,388 root         INFO     Train Epoch: 123 [6656/8000 (83%)]\tTotal Loss: 0.445868\n",
      "Reconstruction: 0.429098, Regularization: 0.016769\n",
      "2019-04-09 22:57:15,443 root         INFO     Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 0.443812\n",
      "Reconstruction: 0.428061, Regularization: 0.015751\n",
      "2019-04-09 22:57:15,497 root         INFO     Train Epoch: 123 [7680/8000 (96%)]\tTotal Loss: 0.387332\n",
      "Reconstruction: 0.367847, Regularization: 0.019485\n",
      "2019-04-09 22:57:15,546 root         INFO     ====> Epoch: 123 Average loss: 0.4352\n",
      "2019-04-09 22:57:15,570 root         INFO     Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 0.363229\n",
      "Reconstruction: 0.348563, Regularization: 0.014666\n",
      "2019-04-09 22:57:15,626 root         INFO     Train Epoch: 124 [512/8000 (6%)]\tTotal Loss: 0.359968\n",
      "Reconstruction: 0.341174, Regularization: 0.018794\n",
      "2019-04-09 22:57:15,681 root         INFO     Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 0.405898\n",
      "Reconstruction: 0.387990, Regularization: 0.017908\n",
      "2019-04-09 22:57:15,737 root         INFO     Train Epoch: 124 [1536/8000 (19%)]\tTotal Loss: 0.422966\n",
      "Reconstruction: 0.406099, Regularization: 0.016866\n",
      "2019-04-09 22:57:15,792 root         INFO     Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 0.491248\n",
      "Reconstruction: 0.470916, Regularization: 0.020333\n",
      "2019-04-09 22:57:15,848 root         INFO     Train Epoch: 124 [2560/8000 (32%)]\tTotal Loss: 0.346671\n",
      "Reconstruction: 0.324154, Regularization: 0.022517\n",
      "2019-04-09 22:57:15,903 root         INFO     Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 0.362216\n",
      "Reconstruction: 0.345762, Regularization: 0.016454\n",
      "2019-04-09 22:57:15,959 root         INFO     Train Epoch: 124 [3584/8000 (45%)]\tTotal Loss: 0.584161\n",
      "Reconstruction: 0.569512, Regularization: 0.014649\n",
      "2019-04-09 22:57:16,014 root         INFO     Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 0.559005\n",
      "Reconstruction: 0.520533, Regularization: 0.038472\n",
      "2019-04-09 22:57:16,070 root         INFO     Train Epoch: 124 [4608/8000 (58%)]\tTotal Loss: 1.346396\n",
      "Reconstruction: 1.331478, Regularization: 0.014918\n",
      "2019-04-09 22:57:16,125 root         INFO     Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 0.422317\n",
      "Reconstruction: 0.406273, Regularization: 0.016044\n",
      "2019-04-09 22:57:16,181 root         INFO     Train Epoch: 124 [5632/8000 (70%)]\tTotal Loss: 0.373394\n",
      "Reconstruction: 0.361031, Regularization: 0.012363\n",
      "2019-04-09 22:57:16,237 root         INFO     Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 0.256404\n",
      "Reconstruction: 0.245904, Regularization: 0.010500\n",
      "2019-04-09 22:57:16,292 root         INFO     Train Epoch: 124 [6656/8000 (83%)]\tTotal Loss: 0.349766\n",
      "Reconstruction: 0.334066, Regularization: 0.015701\n",
      "2019-04-09 22:57:16,347 root         INFO     Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 0.416824\n",
      "Reconstruction: 0.401370, Regularization: 0.015454\n",
      "2019-04-09 22:57:16,402 root         INFO     Train Epoch: 124 [7680/8000 (96%)]\tTotal Loss: 0.351265\n",
      "Reconstruction: 0.334046, Regularization: 0.017220\n",
      "2019-04-09 22:57:16,450 root         INFO     ====> Epoch: 124 Average loss: 0.4385\n",
      "2019-04-09 22:57:16,474 root         INFO     Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 0.462391\n",
      "Reconstruction: 0.440782, Regularization: 0.021609\n",
      "2019-04-09 22:57:16,530 root         INFO     Train Epoch: 125 [512/8000 (6%)]\tTotal Loss: 0.241219\n",
      "Reconstruction: 0.229318, Regularization: 0.011902\n",
      "2019-04-09 22:57:16,586 root         INFO     Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 0.412133\n",
      "Reconstruction: 0.392889, Regularization: 0.019244\n",
      "2019-04-09 22:57:16,643 root         INFO     Train Epoch: 125 [1536/8000 (19%)]\tTotal Loss: 0.443356\n",
      "Reconstruction: 0.424027, Regularization: 0.019330\n",
      "2019-04-09 22:57:16,700 root         INFO     Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 0.413395\n",
      "Reconstruction: 0.394274, Regularization: 0.019121\n",
      "2019-04-09 22:57:16,756 root         INFO     Train Epoch: 125 [2560/8000 (32%)]\tTotal Loss: 0.401925\n",
      "Reconstruction: 0.386323, Regularization: 0.015602\n",
      "2019-04-09 22:57:16,813 root         INFO     Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 0.410273\n",
      "Reconstruction: 0.394185, Regularization: 0.016088\n",
      "2019-04-09 22:57:16,869 root         INFO     Train Epoch: 125 [3584/8000 (45%)]\tTotal Loss: 0.414156\n",
      "Reconstruction: 0.394328, Regularization: 0.019828\n",
      "2019-04-09 22:57:16,926 root         INFO     Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 0.386529\n",
      "Reconstruction: 0.371776, Regularization: 0.014753\n",
      "2019-04-09 22:57:16,983 root         INFO     Train Epoch: 125 [4608/8000 (58%)]\tTotal Loss: 0.454871\n",
      "Reconstruction: 0.439662, Regularization: 0.015210\n",
      "2019-04-09 22:57:17,040 root         INFO     Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 0.446997\n",
      "Reconstruction: 0.428644, Regularization: 0.018352\n",
      "2019-04-09 22:57:17,096 root         INFO     Train Epoch: 125 [5632/8000 (70%)]\tTotal Loss: 0.397007\n",
      "Reconstruction: 0.382262, Regularization: 0.014745\n",
      "2019-04-09 22:57:17,150 root         INFO     Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 0.431644\n",
      "Reconstruction: 0.416920, Regularization: 0.014725\n",
      "2019-04-09 22:57:17,205 root         INFO     Train Epoch: 125 [6656/8000 (83%)]\tTotal Loss: 0.366757\n",
      "Reconstruction: 0.352999, Regularization: 0.013757\n",
      "2019-04-09 22:57:17,260 root         INFO     Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 0.338908\n",
      "Reconstruction: 0.323866, Regularization: 0.015043\n",
      "2019-04-09 22:57:17,315 root         INFO     Train Epoch: 125 [7680/8000 (96%)]\tTotal Loss: 0.501571\n",
      "Reconstruction: 0.469087, Regularization: 0.032484\n",
      "2019-04-09 22:57:17,364 root         INFO     ====> Epoch: 125 Average loss: 0.4184\n",
      "2019-04-09 22:57:17,387 root         INFO     Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 0.372109\n",
      "Reconstruction: 0.359773, Regularization: 0.012336\n",
      "2019-04-09 22:57:17,443 root         INFO     Train Epoch: 126 [512/8000 (6%)]\tTotal Loss: 0.446650\n",
      "Reconstruction: 0.423393, Regularization: 0.023257\n",
      "2019-04-09 22:57:17,499 root         INFO     Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 0.357677\n",
      "Reconstruction: 0.342175, Regularization: 0.015502\n",
      "2019-04-09 22:57:17,555 root         INFO     Train Epoch: 126 [1536/8000 (19%)]\tTotal Loss: 0.515402\n",
      "Reconstruction: 0.500620, Regularization: 0.014782\n",
      "2019-04-09 22:57:17,611 root         INFO     Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 0.490315\n",
      "Reconstruction: 0.467730, Regularization: 0.022585\n",
      "2019-04-09 22:57:17,667 root         INFO     Train Epoch: 126 [2560/8000 (32%)]\tTotal Loss: 0.342853\n",
      "Reconstruction: 0.325251, Regularization: 0.017602\n",
      "2019-04-09 22:57:17,723 root         INFO     Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 0.455499\n",
      "Reconstruction: 0.437809, Regularization: 0.017690\n",
      "2019-04-09 22:57:17,779 root         INFO     Train Epoch: 126 [3584/8000 (45%)]\tTotal Loss: 0.366625\n",
      "Reconstruction: 0.348529, Regularization: 0.018096\n",
      "2019-04-09 22:57:17,835 root         INFO     Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 0.436783\n",
      "Reconstruction: 0.420924, Regularization: 0.015859\n",
      "2019-04-09 22:57:17,891 root         INFO     Train Epoch: 126 [4608/8000 (58%)]\tTotal Loss: 0.397419\n",
      "Reconstruction: 0.386487, Regularization: 0.010933\n",
      "2019-04-09 22:57:17,947 root         INFO     Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 0.447895\n",
      "Reconstruction: 0.427761, Regularization: 0.020134\n",
      "2019-04-09 22:57:18,003 root         INFO     Train Epoch: 126 [5632/8000 (70%)]\tTotal Loss: 0.338011\n",
      "Reconstruction: 0.323510, Regularization: 0.014501\n",
      "2019-04-09 22:57:18,059 root         INFO     Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 0.433872\n",
      "Reconstruction: 0.400714, Regularization: 0.033158\n",
      "2019-04-09 22:57:18,115 root         INFO     Train Epoch: 126 [6656/8000 (83%)]\tTotal Loss: 0.304480\n",
      "Reconstruction: 0.292936, Regularization: 0.011545\n",
      "2019-04-09 22:57:18,171 root         INFO     Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 0.377278\n",
      "Reconstruction: 0.360807, Regularization: 0.016471\n",
      "2019-04-09 22:57:18,227 root         INFO     Train Epoch: 126 [7680/8000 (96%)]\tTotal Loss: 0.403142\n",
      "Reconstruction: 0.382591, Regularization: 0.020551\n",
      "2019-04-09 22:57:18,277 root         INFO     ====> Epoch: 126 Average loss: 0.4281\n",
      "2019-04-09 22:57:18,300 root         INFO     Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 0.352304\n",
      "Reconstruction: 0.338444, Regularization: 0.013860\n",
      "2019-04-09 22:57:18,357 root         INFO     Train Epoch: 127 [512/8000 (6%)]\tTotal Loss: 0.441272\n",
      "Reconstruction: 0.427793, Regularization: 0.013479\n",
      "2019-04-09 22:57:18,413 root         INFO     Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 0.431032\n",
      "Reconstruction: 0.416777, Regularization: 0.014254\n",
      "2019-04-09 22:57:18,469 root         INFO     Train Epoch: 127 [1536/8000 (19%)]\tTotal Loss: 0.292646\n",
      "Reconstruction: 0.280676, Regularization: 0.011970\n",
      "2019-04-09 22:57:18,524 root         INFO     Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 0.330088\n",
      "Reconstruction: 0.315554, Regularization: 0.014534\n",
      "2019-04-09 22:57:18,579 root         INFO     Train Epoch: 127 [2560/8000 (32%)]\tTotal Loss: 0.448870\n",
      "Reconstruction: 0.433607, Regularization: 0.015263\n",
      "2019-04-09 22:57:18,634 root         INFO     Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 0.454151\n",
      "Reconstruction: 0.429437, Regularization: 0.024713\n",
      "2019-04-09 22:57:18,688 root         INFO     Train Epoch: 127 [3584/8000 (45%)]\tTotal Loss: 0.445637\n",
      "Reconstruction: 0.421310, Regularization: 0.024326\n",
      "2019-04-09 22:57:18,743 root         INFO     Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 0.487870\n",
      "Reconstruction: 0.471723, Regularization: 0.016147\n",
      "2019-04-09 22:57:18,797 root         INFO     Train Epoch: 127 [4608/8000 (58%)]\tTotal Loss: 0.413768\n",
      "Reconstruction: 0.392868, Regularization: 0.020900\n",
      "2019-04-09 22:57:18,852 root         INFO     Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 0.396622\n",
      "Reconstruction: 0.378860, Regularization: 0.017762\n",
      "2019-04-09 22:57:18,906 root         INFO     Train Epoch: 127 [5632/8000 (70%)]\tTotal Loss: 0.566232\n",
      "Reconstruction: 0.541388, Regularization: 0.024843\n",
      "2019-04-09 22:57:18,961 root         INFO     Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 0.367606\n",
      "Reconstruction: 0.353433, Regularization: 0.014173\n",
      "2019-04-09 22:57:19,015 root         INFO     Train Epoch: 127 [6656/8000 (83%)]\tTotal Loss: 0.410093\n",
      "Reconstruction: 0.374744, Regularization: 0.035349\n",
      "2019-04-09 22:57:19,069 root         INFO     Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 0.580776\n",
      "Reconstruction: 0.556774, Regularization: 0.024003\n",
      "2019-04-09 22:57:19,123 root         INFO     Train Epoch: 127 [7680/8000 (96%)]\tTotal Loss: 0.473926\n",
      "Reconstruction: 0.454911, Regularization: 0.019014\n",
      "2019-04-09 22:57:19,173 root         INFO     ====> Epoch: 127 Average loss: 0.5856\n",
      "2019-04-09 22:57:19,196 root         INFO     Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 0.531318\n",
      "Reconstruction: 0.510803, Regularization: 0.020515\n",
      "2019-04-09 22:57:19,251 root         INFO     Train Epoch: 128 [512/8000 (6%)]\tTotal Loss: 0.369049\n",
      "Reconstruction: 0.345235, Regularization: 0.023813\n",
      "2019-04-09 22:57:19,307 root         INFO     Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 0.458813\n",
      "Reconstruction: 0.443069, Regularization: 0.015745\n",
      "2019-04-09 22:57:19,363 root         INFO     Train Epoch: 128 [1536/8000 (19%)]\tTotal Loss: 0.522795\n",
      "Reconstruction: 0.505530, Regularization: 0.017265\n",
      "2019-04-09 22:57:19,418 root         INFO     Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 0.407174\n",
      "Reconstruction: 0.389919, Regularization: 0.017255\n",
      "2019-04-09 22:57:19,474 root         INFO     Train Epoch: 128 [2560/8000 (32%)]\tTotal Loss: 0.548834\n",
      "Reconstruction: 0.528826, Regularization: 0.020008\n",
      "2019-04-09 22:57:19,530 root         INFO     Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 0.468207\n",
      "Reconstruction: 0.432929, Regularization: 0.035278\n",
      "2019-04-09 22:57:19,585 root         INFO     Train Epoch: 128 [3584/8000 (45%)]\tTotal Loss: 0.450049\n",
      "Reconstruction: 0.429316, Regularization: 0.020733\n",
      "2019-04-09 22:57:19,641 root         INFO     Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 0.338652\n",
      "Reconstruction: 0.328153, Regularization: 0.010500\n",
      "2019-04-09 22:57:19,696 root         INFO     Train Epoch: 128 [4608/8000 (58%)]\tTotal Loss: 0.268704\n",
      "Reconstruction: 0.253330, Regularization: 0.015374\n",
      "2019-04-09 22:57:19,752 root         INFO     Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 0.383949\n",
      "Reconstruction: 0.360788, Regularization: 0.023161\n",
      "2019-04-09 22:57:19,807 root         INFO     Train Epoch: 128 [5632/8000 (70%)]\tTotal Loss: 0.375935\n",
      "Reconstruction: 0.359111, Regularization: 0.016825\n",
      "2019-04-09 22:57:19,862 root         INFO     Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 0.358472\n",
      "Reconstruction: 0.337535, Regularization: 0.020937\n",
      "2019-04-09 22:57:19,917 root         INFO     Train Epoch: 128 [6656/8000 (83%)]\tTotal Loss: 0.338930\n",
      "Reconstruction: 0.312511, Regularization: 0.026418\n",
      "2019-04-09 22:57:19,972 root         INFO     Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 0.449093\n",
      "Reconstruction: 0.432244, Regularization: 0.016849\n",
      "2019-04-09 22:57:20,027 root         INFO     Train Epoch: 128 [7680/8000 (96%)]\tTotal Loss: 0.415162\n",
      "Reconstruction: 0.391600, Regularization: 0.023562\n",
      "2019-04-09 22:57:20,076 root         INFO     ====> Epoch: 128 Average loss: 0.4548\n",
      "2019-04-09 22:57:20,100 root         INFO     Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 0.373618\n",
      "Reconstruction: 0.361071, Regularization: 0.012546\n",
      "2019-04-09 22:57:20,155 root         INFO     Train Epoch: 129 [512/8000 (6%)]\tTotal Loss: 0.467543\n",
      "Reconstruction: 0.451964, Regularization: 0.015579\n",
      "2019-04-09 22:57:20,211 root         INFO     Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 0.385596\n",
      "Reconstruction: 0.373524, Regularization: 0.012071\n",
      "2019-04-09 22:57:20,266 root         INFO     Train Epoch: 129 [1536/8000 (19%)]\tTotal Loss: 0.405474\n",
      "Reconstruction: 0.387964, Regularization: 0.017510\n",
      "2019-04-09 22:57:20,322 root         INFO     Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 0.417945\n",
      "Reconstruction: 0.402847, Regularization: 0.015098\n",
      "2019-04-09 22:57:20,377 root         INFO     Train Epoch: 129 [2560/8000 (32%)]\tTotal Loss: 0.375022\n",
      "Reconstruction: 0.362534, Regularization: 0.012488\n",
      "2019-04-09 22:57:20,433 root         INFO     Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 0.364854\n",
      "Reconstruction: 0.341745, Regularization: 0.023109\n",
      "2019-04-09 22:57:20,489 root         INFO     Train Epoch: 129 [3584/8000 (45%)]\tTotal Loss: 0.419943\n",
      "Reconstruction: 0.402340, Regularization: 0.017604\n",
      "2019-04-09 22:57:20,544 root         INFO     Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 0.447174\n",
      "Reconstruction: 0.431641, Regularization: 0.015533\n",
      "2019-04-09 22:57:20,600 root         INFO     Train Epoch: 129 [4608/8000 (58%)]\tTotal Loss: 0.382765\n",
      "Reconstruction: 0.364794, Regularization: 0.017971\n",
      "2019-04-09 22:57:20,655 root         INFO     Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 0.291212\n",
      "Reconstruction: 0.280035, Regularization: 0.011177\n",
      "2019-04-09 22:57:20,711 root         INFO     Train Epoch: 129 [5632/8000 (70%)]\tTotal Loss: 0.475253\n",
      "Reconstruction: 0.457161, Regularization: 0.018092\n",
      "2019-04-09 22:57:20,766 root         INFO     Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 0.466868\n",
      "Reconstruction: 0.451018, Regularization: 0.015850\n",
      "2019-04-09 22:57:20,822 root         INFO     Train Epoch: 129 [6656/8000 (83%)]\tTotal Loss: 0.407846\n",
      "Reconstruction: 0.388430, Regularization: 0.019416\n",
      "2019-04-09 22:57:20,877 root         INFO     Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 0.371313\n",
      "Reconstruction: 0.355033, Regularization: 0.016279\n",
      "2019-04-09 22:57:20,932 root         INFO     Train Epoch: 129 [7680/8000 (96%)]\tTotal Loss: 0.352908\n",
      "Reconstruction: 0.340553, Regularization: 0.012355\n",
      "2019-04-09 22:57:20,982 root         INFO     ====> Epoch: 129 Average loss: 0.5683\n",
      "2019-04-09 22:57:21,005 root         INFO     Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 0.290207\n",
      "Reconstruction: 0.277672, Regularization: 0.012534\n",
      "2019-04-09 22:57:21,060 root         INFO     Train Epoch: 130 [512/8000 (6%)]\tTotal Loss: 0.434320\n",
      "Reconstruction: 0.412678, Regularization: 0.021642\n",
      "2019-04-09 22:57:21,116 root         INFO     Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 0.415902\n",
      "Reconstruction: 0.401404, Regularization: 0.014498\n",
      "2019-04-09 22:57:21,172 root         INFO     Train Epoch: 130 [1536/8000 (19%)]\tTotal Loss: 0.550947\n",
      "Reconstruction: 0.527424, Regularization: 0.023523\n",
      "2019-04-09 22:57:21,227 root         INFO     Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 0.323890\n",
      "Reconstruction: 0.311153, Regularization: 0.012737\n",
      "2019-04-09 22:57:21,283 root         INFO     Train Epoch: 130 [2560/8000 (32%)]\tTotal Loss: 0.456352\n",
      "Reconstruction: 0.439496, Regularization: 0.016856\n",
      "2019-04-09 22:57:21,338 root         INFO     Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 0.358214\n",
      "Reconstruction: 0.338871, Regularization: 0.019343\n",
      "2019-04-09 22:57:21,393 root         INFO     Train Epoch: 130 [3584/8000 (45%)]\tTotal Loss: 0.327751\n",
      "Reconstruction: 0.315879, Regularization: 0.011873\n",
      "2019-04-09 22:57:21,447 root         INFO     Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 0.404803\n",
      "Reconstruction: 0.388719, Regularization: 0.016084\n",
      "2019-04-09 22:57:21,501 root         INFO     Train Epoch: 130 [4608/8000 (58%)]\tTotal Loss: 0.488826\n",
      "Reconstruction: 0.472476, Regularization: 0.016349\n",
      "2019-04-09 22:57:21,555 root         INFO     Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 0.395032\n",
      "Reconstruction: 0.379115, Regularization: 0.015916\n",
      "2019-04-09 22:57:21,608 root         INFO     Train Epoch: 130 [5632/8000 (70%)]\tTotal Loss: 0.504447\n",
      "Reconstruction: 0.484342, Regularization: 0.020105\n",
      "2019-04-09 22:57:21,662 root         INFO     Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 0.413464\n",
      "Reconstruction: 0.398229, Regularization: 0.015235\n",
      "2019-04-09 22:57:21,716 root         INFO     Train Epoch: 130 [6656/8000 (83%)]\tTotal Loss: 0.407671\n",
      "Reconstruction: 0.388512, Regularization: 0.019158\n",
      "2019-04-09 22:57:21,770 root         INFO     Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 0.506517\n",
      "Reconstruction: 0.483433, Regularization: 0.023084\n",
      "2019-04-09 22:57:21,824 root         INFO     Train Epoch: 130 [7680/8000 (96%)]\tTotal Loss: 0.373079\n",
      "Reconstruction: 0.352843, Regularization: 0.020236\n",
      "2019-04-09 22:57:21,872 root         INFO     ====> Epoch: 130 Average loss: 0.7945\n",
      "2019-04-09 22:57:21,896 root         INFO     Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 0.343763\n",
      "Reconstruction: 0.331017, Regularization: 0.012747\n",
      "2019-04-09 22:57:21,951 root         INFO     Train Epoch: 131 [512/8000 (6%)]\tTotal Loss: 0.505975\n",
      "Reconstruction: 0.466768, Regularization: 0.039206\n",
      "2019-04-09 22:57:22,006 root         INFO     Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 0.357527\n",
      "Reconstruction: 0.337958, Regularization: 0.019570\n",
      "2019-04-09 22:57:22,060 root         INFO     Train Epoch: 131 [1536/8000 (19%)]\tTotal Loss: 0.379123\n",
      "Reconstruction: 0.366513, Regularization: 0.012611\n",
      "2019-04-09 22:57:22,113 root         INFO     Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 0.378731\n",
      "Reconstruction: 0.360684, Regularization: 0.018046\n",
      "2019-04-09 22:57:22,167 root         INFO     Train Epoch: 131 [2560/8000 (32%)]\tTotal Loss: 0.287833\n",
      "Reconstruction: 0.276639, Regularization: 0.011194\n",
      "2019-04-09 22:57:22,221 root         INFO     Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 0.362695\n",
      "Reconstruction: 0.348347, Regularization: 0.014348\n",
      "2019-04-09 22:57:22,274 root         INFO     Train Epoch: 131 [3584/8000 (45%)]\tTotal Loss: 0.374732\n",
      "Reconstruction: 0.360076, Regularization: 0.014656\n",
      "2019-04-09 22:57:22,328 root         INFO     Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 0.418958\n",
      "Reconstruction: 0.391796, Regularization: 0.027162\n",
      "2019-04-09 22:57:22,381 root         INFO     Train Epoch: 131 [4608/8000 (58%)]\tTotal Loss: 0.319580\n",
      "Reconstruction: 0.308573, Regularization: 0.011007\n",
      "2019-04-09 22:57:22,435 root         INFO     Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 0.396784\n",
      "Reconstruction: 0.384309, Regularization: 0.012475\n",
      "2019-04-09 22:57:22,488 root         INFO     Train Epoch: 131 [5632/8000 (70%)]\tTotal Loss: 0.335071\n",
      "Reconstruction: 0.321037, Regularization: 0.014034\n",
      "2019-04-09 22:57:22,542 root         INFO     Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 0.447747\n",
      "Reconstruction: 0.431070, Regularization: 0.016677\n",
      "2019-04-09 22:57:22,596 root         INFO     Train Epoch: 131 [6656/8000 (83%)]\tTotal Loss: 0.382208\n",
      "Reconstruction: 0.367511, Regularization: 0.014697\n",
      "2019-04-09 22:57:22,649 root         INFO     Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 0.311276\n",
      "Reconstruction: 0.292062, Regularization: 0.019214\n",
      "2019-04-09 22:57:22,704 root         INFO     Train Epoch: 131 [7680/8000 (96%)]\tTotal Loss: 0.420995\n",
      "Reconstruction: 0.396803, Regularization: 0.024192\n",
      "2019-04-09 22:57:22,753 root         INFO     ====> Epoch: 131 Average loss: 0.4665\n",
      "2019-04-09 22:57:22,776 root         INFO     Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 0.327065\n",
      "Reconstruction: 0.315528, Regularization: 0.011537\n",
      "2019-04-09 22:57:22,831 root         INFO     Train Epoch: 132 [512/8000 (6%)]\tTotal Loss: 0.423952\n",
      "Reconstruction: 0.410477, Regularization: 0.013475\n",
      "2019-04-09 22:57:22,886 root         INFO     Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 0.408399\n",
      "Reconstruction: 0.393053, Regularization: 0.015346\n",
      "2019-04-09 22:57:22,941 root         INFO     Train Epoch: 132 [1536/8000 (19%)]\tTotal Loss: 0.478830\n",
      "Reconstruction: 0.457439, Regularization: 0.021391\n",
      "2019-04-09 22:57:22,996 root         INFO     Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 0.405292\n",
      "Reconstruction: 0.390513, Regularization: 0.014779\n",
      "2019-04-09 22:57:23,051 root         INFO     Train Epoch: 132 [2560/8000 (32%)]\tTotal Loss: 0.300205\n",
      "Reconstruction: 0.288229, Regularization: 0.011976\n",
      "2019-04-09 22:57:23,105 root         INFO     Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 0.475716\n",
      "Reconstruction: 0.455633, Regularization: 0.020083\n",
      "2019-04-09 22:57:23,160 root         INFO     Train Epoch: 132 [3584/8000 (45%)]\tTotal Loss: 0.541161\n",
      "Reconstruction: 0.520014, Regularization: 0.021147\n",
      "2019-04-09 22:57:23,215 root         INFO     Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 0.407374\n",
      "Reconstruction: 0.387873, Regularization: 0.019500\n",
      "2019-04-09 22:57:23,270 root         INFO     Train Epoch: 132 [4608/8000 (58%)]\tTotal Loss: 0.358366\n",
      "Reconstruction: 0.340530, Regularization: 0.017836\n",
      "2019-04-09 22:57:23,325 root         INFO     Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 0.414637\n",
      "Reconstruction: 0.395863, Regularization: 0.018774\n",
      "2019-04-09 22:57:23,380 root         INFO     Train Epoch: 132 [5632/8000 (70%)]\tTotal Loss: 0.486118\n",
      "Reconstruction: 0.468719, Regularization: 0.017399\n",
      "2019-04-09 22:57:23,435 root         INFO     Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 0.415225\n",
      "Reconstruction: 0.400783, Regularization: 0.014442\n",
      "2019-04-09 22:57:23,490 root         INFO     Train Epoch: 132 [6656/8000 (83%)]\tTotal Loss: 0.436039\n",
      "Reconstruction: 0.411458, Regularization: 0.024581\n",
      "2019-04-09 22:57:23,545 root         INFO     Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 0.317078\n",
      "Reconstruction: 0.303997, Regularization: 0.013081\n",
      "2019-04-09 22:57:23,599 root         INFO     Train Epoch: 132 [7680/8000 (96%)]\tTotal Loss: 0.511685\n",
      "Reconstruction: 0.495977, Regularization: 0.015708\n",
      "2019-04-09 22:57:23,648 root         INFO     ====> Epoch: 132 Average loss: 4.2019\n",
      "2019-04-09 22:57:23,671 root         INFO     Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 0.325456\n",
      "Reconstruction: 0.313956, Regularization: 0.011499\n",
      "2019-04-09 22:57:23,726 root         INFO     Train Epoch: 133 [512/8000 (6%)]\tTotal Loss: 0.427421\n",
      "Reconstruction: 0.408712, Regularization: 0.018710\n",
      "2019-04-09 22:57:23,780 root         INFO     Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 0.287433\n",
      "Reconstruction: 0.276481, Regularization: 0.010951\n",
      "2019-04-09 22:57:23,835 root         INFO     Train Epoch: 133 [1536/8000 (19%)]\tTotal Loss: 0.426379\n",
      "Reconstruction: 0.408958, Regularization: 0.017420\n",
      "2019-04-09 22:57:23,889 root         INFO     Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 0.388368\n",
      "Reconstruction: 0.373044, Regularization: 0.015324\n",
      "2019-04-09 22:57:23,943 root         INFO     Train Epoch: 133 [2560/8000 (32%)]\tTotal Loss: 0.367633\n",
      "Reconstruction: 0.350958, Regularization: 0.016675\n",
      "2019-04-09 22:57:23,998 root         INFO     Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 0.393662\n",
      "Reconstruction: 0.380292, Regularization: 0.013370\n",
      "2019-04-09 22:57:24,053 root         INFO     Train Epoch: 133 [3584/8000 (45%)]\tTotal Loss: 0.407200\n",
      "Reconstruction: 0.392406, Regularization: 0.014794\n",
      "2019-04-09 22:57:24,108 root         INFO     Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 0.374092\n",
      "Reconstruction: 0.361912, Regularization: 0.012180\n",
      "2019-04-09 22:57:24,163 root         INFO     Train Epoch: 133 [4608/8000 (58%)]\tTotal Loss: 0.307407\n",
      "Reconstruction: 0.295681, Regularization: 0.011725\n",
      "2019-04-09 22:57:24,218 root         INFO     Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 0.478484\n",
      "Reconstruction: 0.460412, Regularization: 0.018072\n",
      "2019-04-09 22:57:24,273 root         INFO     Train Epoch: 133 [5632/8000 (70%)]\tTotal Loss: 0.461383\n",
      "Reconstruction: 0.444707, Regularization: 0.016676\n",
      "2019-04-09 22:57:24,328 root         INFO     Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 0.447662\n",
      "Reconstruction: 0.425880, Regularization: 0.021782\n",
      "2019-04-09 22:57:24,383 root         INFO     Train Epoch: 133 [6656/8000 (83%)]\tTotal Loss: 0.436070\n",
      "Reconstruction: 0.421758, Regularization: 0.014311\n",
      "2019-04-09 22:57:24,438 root         INFO     Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 0.363389\n",
      "Reconstruction: 0.351003, Regularization: 0.012386\n",
      "2019-04-09 22:57:24,492 root         INFO     Train Epoch: 133 [7680/8000 (96%)]\tTotal Loss: 0.419907\n",
      "Reconstruction: 0.395777, Regularization: 0.024130\n",
      "2019-04-09 22:57:24,541 root         INFO     ====> Epoch: 133 Average loss: 5.0498\n",
      "2019-04-09 22:57:24,565 root         INFO     Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 0.556924\n",
      "Reconstruction: 0.536951, Regularization: 0.019972\n",
      "2019-04-09 22:57:24,621 root         INFO     Train Epoch: 134 [512/8000 (6%)]\tTotal Loss: 0.367271\n",
      "Reconstruction: 0.352425, Regularization: 0.014846\n",
      "2019-04-09 22:57:24,677 root         INFO     Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 0.480159\n",
      "Reconstruction: 0.464565, Regularization: 0.015594\n",
      "2019-04-09 22:57:24,734 root         INFO     Train Epoch: 134 [1536/8000 (19%)]\tTotal Loss: 0.376003\n",
      "Reconstruction: 0.358091, Regularization: 0.017911\n",
      "2019-04-09 22:57:24,790 root         INFO     Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 0.427453\n",
      "Reconstruction: 0.411945, Regularization: 0.015509\n",
      "2019-04-09 22:57:24,847 root         INFO     Train Epoch: 134 [2560/8000 (32%)]\tTotal Loss: 0.449546\n",
      "Reconstruction: 0.432749, Regularization: 0.016797\n",
      "2019-04-09 22:57:24,903 root         INFO     Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 0.424435\n",
      "Reconstruction: 0.406165, Regularization: 0.018270\n",
      "2019-04-09 22:57:24,958 root         INFO     Train Epoch: 134 [3584/8000 (45%)]\tTotal Loss: 0.374928\n",
      "Reconstruction: 0.361461, Regularization: 0.013466\n",
      "2019-04-09 22:57:25,014 root         INFO     Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 0.384221\n",
      "Reconstruction: 0.369610, Regularization: 0.014611\n",
      "2019-04-09 22:57:25,068 root         INFO     Train Epoch: 134 [4608/8000 (58%)]\tTotal Loss: 0.423545\n",
      "Reconstruction: 0.412222, Regularization: 0.011324\n",
      "2019-04-09 22:57:25,123 root         INFO     Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 0.320855\n",
      "Reconstruction: 0.306657, Regularization: 0.014198\n",
      "2019-04-09 22:57:25,177 root         INFO     Train Epoch: 134 [5632/8000 (70%)]\tTotal Loss: 0.306036\n",
      "Reconstruction: 0.291652, Regularization: 0.014384\n",
      "2019-04-09 22:57:25,231 root         INFO     Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 0.397050\n",
      "Reconstruction: 0.378991, Regularization: 0.018058\n",
      "2019-04-09 22:57:25,286 root         INFO     Train Epoch: 134 [6656/8000 (83%)]\tTotal Loss: 0.366564\n",
      "Reconstruction: 0.349987, Regularization: 0.016576\n",
      "2019-04-09 22:57:25,341 root         INFO     Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 0.338165\n",
      "Reconstruction: 0.323797, Regularization: 0.014368\n",
      "2019-04-09 22:57:25,396 root         INFO     Train Epoch: 134 [7680/8000 (96%)]\tTotal Loss: 0.271535\n",
      "Reconstruction: 0.259114, Regularization: 0.012421\n",
      "2019-04-09 22:57:25,444 root         INFO     ====> Epoch: 134 Average loss: 0.4345\n",
      "2019-04-09 22:57:25,468 root         INFO     Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 0.339564\n",
      "Reconstruction: 0.322615, Regularization: 0.016949\n",
      "2019-04-09 22:57:25,524 root         INFO     Train Epoch: 135 [512/8000 (6%)]\tTotal Loss: 0.368772\n",
      "Reconstruction: 0.354971, Regularization: 0.013801\n",
      "2019-04-09 22:57:25,579 root         INFO     Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 0.428242\n",
      "Reconstruction: 0.413454, Regularization: 0.014788\n",
      "2019-04-09 22:57:25,634 root         INFO     Train Epoch: 135 [1536/8000 (19%)]\tTotal Loss: 0.371456\n",
      "Reconstruction: 0.357360, Regularization: 0.014096\n",
      "2019-04-09 22:57:25,689 root         INFO     Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 0.427139\n",
      "Reconstruction: 0.406253, Regularization: 0.020885\n",
      "2019-04-09 22:57:25,744 root         INFO     Train Epoch: 135 [2560/8000 (32%)]\tTotal Loss: 0.385741\n",
      "Reconstruction: 0.369607, Regularization: 0.016134\n",
      "2019-04-09 22:57:25,799 root         INFO     Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 0.345081\n",
      "Reconstruction: 0.330211, Regularization: 0.014870\n",
      "2019-04-09 22:57:25,855 root         INFO     Train Epoch: 135 [3584/8000 (45%)]\tTotal Loss: 0.355838\n",
      "Reconstruction: 0.341748, Regularization: 0.014090\n",
      "2019-04-09 22:57:25,910 root         INFO     Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 0.479520\n",
      "Reconstruction: 0.459515, Regularization: 0.020005\n",
      "2019-04-09 22:57:25,965 root         INFO     Train Epoch: 135 [4608/8000 (58%)]\tTotal Loss: 0.300287\n",
      "Reconstruction: 0.286078, Regularization: 0.014209\n",
      "2019-04-09 22:57:26,020 root         INFO     Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 0.430895\n",
      "Reconstruction: 0.413485, Regularization: 0.017410\n",
      "2019-04-09 22:57:26,075 root         INFO     Train Epoch: 135 [5632/8000 (70%)]\tTotal Loss: 0.353300\n",
      "Reconstruction: 0.338769, Regularization: 0.014531\n",
      "2019-04-09 22:57:26,130 root         INFO     Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 0.424932\n",
      "Reconstruction: 0.406323, Regularization: 0.018609\n",
      "2019-04-09 22:57:26,185 root         INFO     Train Epoch: 135 [6656/8000 (83%)]\tTotal Loss: 0.332728\n",
      "Reconstruction: 0.317843, Regularization: 0.014885\n",
      "2019-04-09 22:57:26,240 root         INFO     Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 0.390221\n",
      "Reconstruction: 0.371552, Regularization: 0.018669\n",
      "2019-04-09 22:57:26,295 root         INFO     Train Epoch: 135 [7680/8000 (96%)]\tTotal Loss: 0.350039\n",
      "Reconstruction: 0.330356, Regularization: 0.019683\n",
      "2019-04-09 22:57:26,345 root         INFO     ====> Epoch: 135 Average loss: 0.4192\n",
      "2019-04-09 22:57:26,368 root         INFO     Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 0.443764\n",
      "Reconstruction: 0.425453, Regularization: 0.018311\n",
      "2019-04-09 22:57:26,423 root         INFO     Train Epoch: 136 [512/8000 (6%)]\tTotal Loss: 0.545759\n",
      "Reconstruction: 0.527282, Regularization: 0.018477\n",
      "2019-04-09 22:57:26,479 root         INFO     Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 0.530086\n",
      "Reconstruction: 0.507607, Regularization: 0.022479\n",
      "2019-04-09 22:57:26,534 root         INFO     Train Epoch: 136 [1536/8000 (19%)]\tTotal Loss: 0.487552\n",
      "Reconstruction: 0.465288, Regularization: 0.022264\n",
      "2019-04-09 22:57:26,589 root         INFO     Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 0.343365\n",
      "Reconstruction: 0.329570, Regularization: 0.013795\n",
      "2019-04-09 22:57:26,645 root         INFO     Train Epoch: 136 [2560/8000 (32%)]\tTotal Loss: 0.401747\n",
      "Reconstruction: 0.387663, Regularization: 0.014084\n",
      "2019-04-09 22:57:26,700 root         INFO     Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 0.431842\n",
      "Reconstruction: 0.407277, Regularization: 0.024565\n",
      "2019-04-09 22:57:26,755 root         INFO     Train Epoch: 136 [3584/8000 (45%)]\tTotal Loss: 0.384695\n",
      "Reconstruction: 0.368127, Regularization: 0.016568\n",
      "2019-04-09 22:57:26,810 root         INFO     Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 0.388599\n",
      "Reconstruction: 0.374374, Regularization: 0.014225\n",
      "2019-04-09 22:57:26,865 root         INFO     Train Epoch: 136 [4608/8000 (58%)]\tTotal Loss: 0.332462\n",
      "Reconstruction: 0.317657, Regularization: 0.014805\n",
      "2019-04-09 22:57:26,920 root         INFO     Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 0.409580\n",
      "Reconstruction: 0.393458, Regularization: 0.016123\n",
      "2019-04-09 22:57:26,975 root         INFO     Train Epoch: 136 [5632/8000 (70%)]\tTotal Loss: 0.408782\n",
      "Reconstruction: 0.383186, Regularization: 0.025596\n",
      "2019-04-09 22:57:27,030 root         INFO     Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 0.415282\n",
      "Reconstruction: 0.396558, Regularization: 0.018724\n",
      "2019-04-09 22:57:27,085 root         INFO     Train Epoch: 136 [6656/8000 (83%)]\tTotal Loss: 0.335958\n",
      "Reconstruction: 0.322124, Regularization: 0.013835\n",
      "2019-04-09 22:57:27,141 root         INFO     Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 0.363284\n",
      "Reconstruction: 0.347962, Regularization: 0.015322\n",
      "2019-04-09 22:57:27,196 root         INFO     Train Epoch: 136 [7680/8000 (96%)]\tTotal Loss: 0.421873\n",
      "Reconstruction: 0.400729, Regularization: 0.021144\n",
      "2019-04-09 22:57:27,245 root         INFO     ====> Epoch: 136 Average loss: 4.0302\n",
      "2019-04-09 22:57:27,269 root         INFO     Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 0.514842\n",
      "Reconstruction: 0.496800, Regularization: 0.018042\n",
      "2019-04-09 22:57:27,325 root         INFO     Train Epoch: 137 [512/8000 (6%)]\tTotal Loss: 0.386769\n",
      "Reconstruction: 0.373208, Regularization: 0.013561\n",
      "2019-04-09 22:57:27,382 root         INFO     Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 0.373365\n",
      "Reconstruction: 0.361041, Regularization: 0.012324\n",
      "2019-04-09 22:57:27,439 root         INFO     Train Epoch: 137 [1536/8000 (19%)]\tTotal Loss: 0.304764\n",
      "Reconstruction: 0.294866, Regularization: 0.009899\n",
      "2019-04-09 22:57:27,496 root         INFO     Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 0.332331\n",
      "Reconstruction: 0.317514, Regularization: 0.014817\n",
      "2019-04-09 22:57:27,553 root         INFO     Train Epoch: 137 [2560/8000 (32%)]\tTotal Loss: 0.380485\n",
      "Reconstruction: 0.364934, Regularization: 0.015551\n",
      "2019-04-09 22:57:27,609 root         INFO     Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 0.444386\n",
      "Reconstruction: 0.429654, Regularization: 0.014732\n",
      "2019-04-09 22:57:27,666 root         INFO     Train Epoch: 137 [3584/8000 (45%)]\tTotal Loss: 0.425722\n",
      "Reconstruction: 0.403615, Regularization: 0.022106\n",
      "2019-04-09 22:57:27,723 root         INFO     Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 0.468271\n",
      "Reconstruction: 0.447960, Regularization: 0.020311\n",
      "2019-04-09 22:57:27,780 root         INFO     Train Epoch: 137 [4608/8000 (58%)]\tTotal Loss: 0.345772\n",
      "Reconstruction: 0.329385, Regularization: 0.016387\n",
      "2019-04-09 22:57:27,837 root         INFO     Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 0.412216\n",
      "Reconstruction: 0.395098, Regularization: 0.017117\n",
      "2019-04-09 22:57:27,894 root         INFO     Train Epoch: 137 [5632/8000 (70%)]\tTotal Loss: 0.407034\n",
      "Reconstruction: 0.389998, Regularization: 0.017035\n",
      "2019-04-09 22:57:27,951 root         INFO     Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 0.528284\n",
      "Reconstruction: 0.490854, Regularization: 0.037430\n",
      "2019-04-09 22:57:28,008 root         INFO     Train Epoch: 137 [6656/8000 (83%)]\tTotal Loss: 0.377058\n",
      "Reconstruction: 0.354322, Regularization: 0.022737\n",
      "2019-04-09 22:57:28,064 root         INFO     Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 0.397517\n",
      "Reconstruction: 0.386626, Regularization: 0.010891\n",
      "2019-04-09 22:57:28,119 root         INFO     Train Epoch: 137 [7680/8000 (96%)]\tTotal Loss: 0.474137\n",
      "Reconstruction: 0.456294, Regularization: 0.017843\n",
      "2019-04-09 22:57:28,169 root         INFO     ====> Epoch: 137 Average loss: 0.4840\n",
      "2019-04-09 22:57:28,192 root         INFO     Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 0.421234\n",
      "Reconstruction: 0.405427, Regularization: 0.015806\n",
      "2019-04-09 22:57:28,248 root         INFO     Train Epoch: 138 [512/8000 (6%)]\tTotal Loss: 0.440720\n",
      "Reconstruction: 0.424644, Regularization: 0.016076\n",
      "2019-04-09 22:57:28,305 root         INFO     Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 0.363257\n",
      "Reconstruction: 0.350111, Regularization: 0.013145\n",
      "2019-04-09 22:57:28,361 root         INFO     Train Epoch: 138 [1536/8000 (19%)]\tTotal Loss: 0.346975\n",
      "Reconstruction: 0.329785, Regularization: 0.017190\n",
      "2019-04-09 22:57:28,415 root         INFO     Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 0.272828\n",
      "Reconstruction: 0.261963, Regularization: 0.010865\n",
      "2019-04-09 22:57:28,471 root         INFO     Train Epoch: 138 [2560/8000 (32%)]\tTotal Loss: 0.445743\n",
      "Reconstruction: 0.428858, Regularization: 0.016884\n",
      "2019-04-09 22:57:28,528 root         INFO     Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 0.546451\n",
      "Reconstruction: 0.530951, Regularization: 0.015500\n",
      "2019-04-09 22:57:28,584 root         INFO     Train Epoch: 138 [3584/8000 (45%)]\tTotal Loss: 0.423045\n",
      "Reconstruction: 0.404251, Regularization: 0.018794\n",
      "2019-04-09 22:57:28,640 root         INFO     Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 0.425008\n",
      "Reconstruction: 0.399808, Regularization: 0.025200\n",
      "2019-04-09 22:57:28,696 root         INFO     Train Epoch: 138 [4608/8000 (58%)]\tTotal Loss: 0.354917\n",
      "Reconstruction: 0.336201, Regularization: 0.018716\n",
      "2019-04-09 22:57:28,752 root         INFO     Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 0.328214\n",
      "Reconstruction: 0.314669, Regularization: 0.013545\n",
      "2019-04-09 22:57:28,808 root         INFO     Train Epoch: 138 [5632/8000 (70%)]\tTotal Loss: 0.307151\n",
      "Reconstruction: 0.289102, Regularization: 0.018050\n",
      "2019-04-09 22:57:28,864 root         INFO     Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 0.407773\n",
      "Reconstruction: 0.394242, Regularization: 0.013531\n",
      "2019-04-09 22:57:28,921 root         INFO     Train Epoch: 138 [6656/8000 (83%)]\tTotal Loss: 0.376389\n",
      "Reconstruction: 0.355923, Regularization: 0.020466\n",
      "2019-04-09 22:57:28,977 root         INFO     Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 0.376758\n",
      "Reconstruction: 0.361511, Regularization: 0.015247\n",
      "2019-04-09 22:57:29,033 root         INFO     Train Epoch: 138 [7680/8000 (96%)]\tTotal Loss: 0.360403\n",
      "Reconstruction: 0.343405, Regularization: 0.016998\n",
      "2019-04-09 22:57:29,083 root         INFO     ====> Epoch: 138 Average loss: 0.4163\n",
      "2019-04-09 22:57:29,106 root         INFO     Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 0.448034\n",
      "Reconstruction: 0.429083, Regularization: 0.018950\n",
      "2019-04-09 22:57:29,162 root         INFO     Train Epoch: 139 [512/8000 (6%)]\tTotal Loss: 0.446749\n",
      "Reconstruction: 0.428167, Regularization: 0.018582\n",
      "2019-04-09 22:57:29,219 root         INFO     Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 0.382434\n",
      "Reconstruction: 0.366163, Regularization: 0.016271\n",
      "2019-04-09 22:57:29,275 root         INFO     Train Epoch: 139 [1536/8000 (19%)]\tTotal Loss: 0.332385\n",
      "Reconstruction: 0.319167, Regularization: 0.013218\n",
      "2019-04-09 22:57:29,332 root         INFO     Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 0.452654\n",
      "Reconstruction: 0.434748, Regularization: 0.017906\n",
      "2019-04-09 22:57:29,388 root         INFO     Train Epoch: 139 [2560/8000 (32%)]\tTotal Loss: 0.379261\n",
      "Reconstruction: 0.362564, Regularization: 0.016697\n",
      "2019-04-09 22:57:29,444 root         INFO     Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 0.400515\n",
      "Reconstruction: 0.384767, Regularization: 0.015748\n",
      "2019-04-09 22:57:29,500 root         INFO     Train Epoch: 139 [3584/8000 (45%)]\tTotal Loss: 0.516442\n",
      "Reconstruction: 0.494071, Regularization: 0.022371\n",
      "2019-04-09 22:57:29,556 root         INFO     Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 0.369654\n",
      "Reconstruction: 0.355262, Regularization: 0.014392\n",
      "2019-04-09 22:57:29,613 root         INFO     Train Epoch: 139 [4608/8000 (58%)]\tTotal Loss: 0.375157\n",
      "Reconstruction: 0.360341, Regularization: 0.014815\n",
      "2019-04-09 22:57:29,669 root         INFO     Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 0.409246\n",
      "Reconstruction: 0.383242, Regularization: 0.026003\n",
      "2019-04-09 22:57:29,726 root         INFO     Train Epoch: 139 [5632/8000 (70%)]\tTotal Loss: 0.572080\n",
      "Reconstruction: 0.550717, Regularization: 0.021363\n",
      "2019-04-09 22:57:29,783 root         INFO     Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 0.276321\n",
      "Reconstruction: 0.254861, Regularization: 0.021459\n",
      "2019-04-09 22:57:29,839 root         INFO     Train Epoch: 139 [6656/8000 (83%)]\tTotal Loss: 0.326986\n",
      "Reconstruction: 0.313082, Regularization: 0.013904\n",
      "2019-04-09 22:57:29,896 root         INFO     Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 0.431129\n",
      "Reconstruction: 0.408732, Regularization: 0.022397\n",
      "2019-04-09 22:57:29,952 root         INFO     Train Epoch: 139 [7680/8000 (96%)]\tTotal Loss: 0.433392\n",
      "Reconstruction: 0.417020, Regularization: 0.016372\n",
      "2019-04-09 22:57:30,002 root         INFO     ====> Epoch: 139 Average loss: 0.4007\n",
      "2019-04-09 22:57:30,026 root         INFO     Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 0.491114\n",
      "Reconstruction: 0.470172, Regularization: 0.020942\n",
      "2019-04-09 22:57:30,081 root         INFO     Train Epoch: 140 [512/8000 (6%)]\tTotal Loss: 0.261477\n",
      "Reconstruction: 0.247732, Regularization: 0.013745\n",
      "2019-04-09 22:57:30,137 root         INFO     Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 0.324205\n",
      "Reconstruction: 0.311161, Regularization: 0.013043\n",
      "2019-04-09 22:57:30,192 root         INFO     Train Epoch: 140 [1536/8000 (19%)]\tTotal Loss: 0.421048\n",
      "Reconstruction: 0.407689, Regularization: 0.013358\n",
      "2019-04-09 22:57:30,248 root         INFO     Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 0.331563\n",
      "Reconstruction: 0.319813, Regularization: 0.011750\n",
      "2019-04-09 22:57:30,304 root         INFO     Train Epoch: 140 [2560/8000 (32%)]\tTotal Loss: 0.369611\n",
      "Reconstruction: 0.354672, Regularization: 0.014939\n",
      "2019-04-09 22:57:30,359 root         INFO     Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 0.518235\n",
      "Reconstruction: 0.497881, Regularization: 0.020354\n",
      "2019-04-09 22:57:30,414 root         INFO     Train Epoch: 140 [3584/8000 (45%)]\tTotal Loss: 0.457243\n",
      "Reconstruction: 0.440073, Regularization: 0.017171\n",
      "2019-04-09 22:57:30,470 root         INFO     Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 0.383878\n",
      "Reconstruction: 0.368023, Regularization: 0.015854\n",
      "2019-04-09 22:57:30,525 root         INFO     Train Epoch: 140 [4608/8000 (58%)]\tTotal Loss: 0.630983\n",
      "Reconstruction: 0.612956, Regularization: 0.018027\n",
      "2019-04-09 22:57:30,581 root         INFO     Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 0.455074\n",
      "Reconstruction: 0.438520, Regularization: 0.016554\n",
      "2019-04-09 22:57:30,636 root         INFO     Train Epoch: 140 [5632/8000 (70%)]\tTotal Loss: 0.452451\n",
      "Reconstruction: 0.435150, Regularization: 0.017301\n",
      "2019-04-09 22:57:30,691 root         INFO     Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 0.436070\n",
      "Reconstruction: 0.419976, Regularization: 0.016094\n",
      "2019-04-09 22:57:30,746 root         INFO     Train Epoch: 140 [6656/8000 (83%)]\tTotal Loss: 0.405493\n",
      "Reconstruction: 0.387546, Regularization: 0.017947\n",
      "2019-04-09 22:57:30,801 root         INFO     Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 0.408557\n",
      "Reconstruction: 0.389915, Regularization: 0.018643\n",
      "2019-04-09 22:57:30,855 root         INFO     Train Epoch: 140 [7680/8000 (96%)]\tTotal Loss: 0.345284\n",
      "Reconstruction: 0.333314, Regularization: 0.011970\n",
      "2019-04-09 22:57:30,904 root         INFO     ====> Epoch: 140 Average loss: 4.0679\n",
      "2019-04-09 22:57:30,927 root         INFO     Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 0.453212\n",
      "Reconstruction: 0.436063, Regularization: 0.017149\n",
      "2019-04-09 22:57:30,984 root         INFO     Train Epoch: 141 [512/8000 (6%)]\tTotal Loss: 0.431328\n",
      "Reconstruction: 0.413946, Regularization: 0.017383\n",
      "2019-04-09 22:57:31,040 root         INFO     Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 0.378117\n",
      "Reconstruction: 0.362940, Regularization: 0.015177\n",
      "2019-04-09 22:57:31,097 root         INFO     Train Epoch: 141 [1536/8000 (19%)]\tTotal Loss: 0.431404\n",
      "Reconstruction: 0.415272, Regularization: 0.016132\n",
      "2019-04-09 22:57:31,153 root         INFO     Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 0.484602\n",
      "Reconstruction: 0.468110, Regularization: 0.016493\n",
      "2019-04-09 22:57:31,209 root         INFO     Train Epoch: 141 [2560/8000 (32%)]\tTotal Loss: 0.437425\n",
      "Reconstruction: 0.419738, Regularization: 0.017688\n",
      "2019-04-09 22:57:31,266 root         INFO     Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 1.008372\n",
      "Reconstruction: 0.968044, Regularization: 0.040328\n",
      "2019-04-09 22:57:31,322 root         INFO     Train Epoch: 141 [3584/8000 (45%)]\tTotal Loss: 0.360784\n",
      "Reconstruction: 0.335750, Regularization: 0.025034\n",
      "2019-04-09 22:57:31,378 root         INFO     Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 0.420860\n",
      "Reconstruction: 0.401284, Regularization: 0.019576\n",
      "2019-04-09 22:57:31,434 root         INFO     Train Epoch: 141 [4608/8000 (58%)]\tTotal Loss: 0.402099\n",
      "Reconstruction: 0.387789, Regularization: 0.014310\n",
      "2019-04-09 22:57:31,491 root         INFO     Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 0.401059\n",
      "Reconstruction: 0.380027, Regularization: 0.021032\n",
      "2019-04-09 22:57:31,546 root         INFO     Train Epoch: 141 [5632/8000 (70%)]\tTotal Loss: 0.378064\n",
      "Reconstruction: 0.365465, Regularization: 0.012599\n",
      "2019-04-09 22:57:31,603 root         INFO     Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 0.413612\n",
      "Reconstruction: 0.396323, Regularization: 0.017288\n",
      "2019-04-09 22:57:31,659 root         INFO     Train Epoch: 141 [6656/8000 (83%)]\tTotal Loss: 0.391917\n",
      "Reconstruction: 0.371503, Regularization: 0.020414\n",
      "2019-04-09 22:57:31,714 root         INFO     Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 0.404452\n",
      "Reconstruction: 0.387158, Regularization: 0.017294\n",
      "2019-04-09 22:57:31,771 root         INFO     Train Epoch: 141 [7680/8000 (96%)]\tTotal Loss: 0.366406\n",
      "Reconstruction: 0.350808, Regularization: 0.015597\n",
      "2019-04-09 22:57:31,820 root         INFO     ====> Epoch: 141 Average loss: 0.4123\n",
      "2019-04-09 22:57:31,844 root         INFO     Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 0.432447\n",
      "Reconstruction: 0.418025, Regularization: 0.014422\n",
      "2019-04-09 22:57:31,899 root         INFO     Train Epoch: 142 [512/8000 (6%)]\tTotal Loss: 0.385796\n",
      "Reconstruction: 0.367412, Regularization: 0.018384\n",
      "2019-04-09 22:57:31,954 root         INFO     Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 0.430952\n",
      "Reconstruction: 0.411092, Regularization: 0.019860\n",
      "2019-04-09 22:57:32,010 root         INFO     Train Epoch: 142 [1536/8000 (19%)]\tTotal Loss: 0.310437\n",
      "Reconstruction: 0.295560, Regularization: 0.014877\n",
      "2019-04-09 22:57:32,067 root         INFO     Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 0.374291\n",
      "Reconstruction: 0.358169, Regularization: 0.016122\n",
      "2019-04-09 22:57:32,124 root         INFO     Train Epoch: 142 [2560/8000 (32%)]\tTotal Loss: 0.498062\n",
      "Reconstruction: 0.483831, Regularization: 0.014231\n",
      "2019-04-09 22:57:32,179 root         INFO     Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 0.377813\n",
      "Reconstruction: 0.348591, Regularization: 0.029223\n",
      "2019-04-09 22:57:32,234 root         INFO     Train Epoch: 142 [3584/8000 (45%)]\tTotal Loss: 0.465303\n",
      "Reconstruction: 0.430706, Regularization: 0.034597\n",
      "2019-04-09 22:57:32,290 root         INFO     Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 0.329347\n",
      "Reconstruction: 0.318025, Regularization: 0.011322\n",
      "2019-04-09 22:57:32,345 root         INFO     Train Epoch: 142 [4608/8000 (58%)]\tTotal Loss: 0.272887\n",
      "Reconstruction: 0.252194, Regularization: 0.020694\n",
      "2019-04-09 22:57:32,400 root         INFO     Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 0.352067\n",
      "Reconstruction: 0.339843, Regularization: 0.012224\n",
      "2019-04-09 22:57:32,456 root         INFO     Train Epoch: 142 [5632/8000 (70%)]\tTotal Loss: 0.364591\n",
      "Reconstruction: 0.348452, Regularization: 0.016139\n",
      "2019-04-09 22:57:32,511 root         INFO     Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 0.369375\n",
      "Reconstruction: 0.353783, Regularization: 0.015592\n",
      "2019-04-09 22:57:32,567 root         INFO     Train Epoch: 142 [6656/8000 (83%)]\tTotal Loss: 0.392657\n",
      "Reconstruction: 0.375588, Regularization: 0.017068\n",
      "2019-04-09 22:57:32,621 root         INFO     Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 0.326137\n",
      "Reconstruction: 0.307619, Regularization: 0.018518\n",
      "2019-04-09 22:57:32,677 root         INFO     Train Epoch: 142 [7680/8000 (96%)]\tTotal Loss: 0.659465\n",
      "Reconstruction: 0.637593, Regularization: 0.021872\n",
      "2019-04-09 22:57:32,726 root         INFO     ====> Epoch: 142 Average loss: 2.2409\n",
      "2019-04-09 22:57:32,749 root         INFO     Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 0.421048\n",
      "Reconstruction: 0.396124, Regularization: 0.024924\n",
      "2019-04-09 22:57:32,806 root         INFO     Train Epoch: 143 [512/8000 (6%)]\tTotal Loss: 0.445370\n",
      "Reconstruction: 0.424180, Regularization: 0.021189\n",
      "2019-04-09 22:57:32,863 root         INFO     Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 0.356965\n",
      "Reconstruction: 0.340850, Regularization: 0.016115\n",
      "2019-04-09 22:57:32,919 root         INFO     Train Epoch: 143 [1536/8000 (19%)]\tTotal Loss: 0.329827\n",
      "Reconstruction: 0.317257, Regularization: 0.012570\n",
      "2019-04-09 22:57:32,976 root         INFO     Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 0.317900\n",
      "Reconstruction: 0.297529, Regularization: 0.020371\n",
      "2019-04-09 22:57:33,032 root         INFO     Train Epoch: 143 [2560/8000 (32%)]\tTotal Loss: 0.346429\n",
      "Reconstruction: 0.328484, Regularization: 0.017944\n",
      "2019-04-09 22:57:33,090 root         INFO     Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 0.445898\n",
      "Reconstruction: 0.428511, Regularization: 0.017387\n",
      "2019-04-09 22:57:33,145 root         INFO     Train Epoch: 143 [3584/8000 (45%)]\tTotal Loss: 0.279683\n",
      "Reconstruction: 0.265759, Regularization: 0.013924\n",
      "2019-04-09 22:57:33,201 root         INFO     Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 0.324580\n",
      "Reconstruction: 0.310958, Regularization: 0.013622\n",
      "2019-04-09 22:57:33,257 root         INFO     Train Epoch: 143 [4608/8000 (58%)]\tTotal Loss: 0.536379\n",
      "Reconstruction: 0.520881, Regularization: 0.015498\n",
      "2019-04-09 22:57:33,314 root         INFO     Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 0.476715\n",
      "Reconstruction: 0.455478, Regularization: 0.021237\n",
      "2019-04-09 22:57:33,370 root         INFO     Train Epoch: 143 [5632/8000 (70%)]\tTotal Loss: 0.387312\n",
      "Reconstruction: 0.371594, Regularization: 0.015718\n",
      "2019-04-09 22:57:33,427 root         INFO     Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 0.420286\n",
      "Reconstruction: 0.404264, Regularization: 0.016023\n",
      "2019-04-09 22:57:33,483 root         INFO     Train Epoch: 143 [6656/8000 (83%)]\tTotal Loss: 0.380006\n",
      "Reconstruction: 0.361414, Regularization: 0.018592\n",
      "2019-04-09 22:57:33,540 root         INFO     Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 0.404699\n",
      "Reconstruction: 0.390830, Regularization: 0.013870\n",
      "2019-04-09 22:57:33,597 root         INFO     Train Epoch: 143 [7680/8000 (96%)]\tTotal Loss: 0.439651\n",
      "Reconstruction: 0.421230, Regularization: 0.018421\n",
      "2019-04-09 22:57:33,648 root         INFO     ====> Epoch: 143 Average loss: 0.4117\n",
      "2019-04-09 22:57:33,671 root         INFO     Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 0.429340\n",
      "Reconstruction: 0.410454, Regularization: 0.018887\n",
      "2019-04-09 22:57:33,727 root         INFO     Train Epoch: 144 [512/8000 (6%)]\tTotal Loss: 0.380106\n",
      "Reconstruction: 0.362255, Regularization: 0.017852\n",
      "2019-04-09 22:57:33,784 root         INFO     Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 0.410057\n",
      "Reconstruction: 0.395474, Regularization: 0.014582\n",
      "2019-04-09 22:57:33,839 root         INFO     Train Epoch: 144 [1536/8000 (19%)]\tTotal Loss: 0.342908\n",
      "Reconstruction: 0.328912, Regularization: 0.013995\n",
      "2019-04-09 22:57:33,894 root         INFO     Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 0.406608\n",
      "Reconstruction: 0.393523, Regularization: 0.013085\n",
      "2019-04-09 22:57:33,950 root         INFO     Train Epoch: 144 [2560/8000 (32%)]\tTotal Loss: 0.359138\n",
      "Reconstruction: 0.344919, Regularization: 0.014219\n",
      "2019-04-09 22:57:34,006 root         INFO     Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 0.416202\n",
      "Reconstruction: 0.401849, Regularization: 0.014353\n",
      "2019-04-09 22:57:34,063 root         INFO     Train Epoch: 144 [3584/8000 (45%)]\tTotal Loss: 0.463464\n",
      "Reconstruction: 0.446905, Regularization: 0.016559\n",
      "2019-04-09 22:57:34,118 root         INFO     Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 0.451054\n",
      "Reconstruction: 0.429799, Regularization: 0.021255\n",
      "2019-04-09 22:57:34,173 root         INFO     Train Epoch: 144 [4608/8000 (58%)]\tTotal Loss: 0.423321\n",
      "Reconstruction: 0.407575, Regularization: 0.015746\n",
      "2019-04-09 22:57:34,228 root         INFO     Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 0.448237\n",
      "Reconstruction: 0.427881, Regularization: 0.020356\n",
      "2019-04-09 22:57:34,284 root         INFO     Train Epoch: 144 [5632/8000 (70%)]\tTotal Loss: 0.399005\n",
      "Reconstruction: 0.382574, Regularization: 0.016431\n",
      "2019-04-09 22:57:34,340 root         INFO     Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 0.379663\n",
      "Reconstruction: 0.365769, Regularization: 0.013894\n",
      "2019-04-09 22:57:34,396 root         INFO     Train Epoch: 144 [6656/8000 (83%)]\tTotal Loss: 0.350362\n",
      "Reconstruction: 0.340465, Regularization: 0.009897\n",
      "2019-04-09 22:57:34,451 root         INFO     Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 0.307763\n",
      "Reconstruction: 0.287970, Regularization: 0.019793\n",
      "2019-04-09 22:57:34,507 root         INFO     Train Epoch: 144 [7680/8000 (96%)]\tTotal Loss: 0.346807\n",
      "Reconstruction: 0.329149, Regularization: 0.017659\n",
      "2019-04-09 22:57:34,557 root         INFO     ====> Epoch: 144 Average loss: 0.3973\n",
      "2019-04-09 22:57:34,580 root         INFO     Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 0.439661\n",
      "Reconstruction: 0.415150, Regularization: 0.024511\n",
      "2019-04-09 22:57:34,637 root         INFO     Train Epoch: 145 [512/8000 (6%)]\tTotal Loss: 0.466926\n",
      "Reconstruction: 0.449705, Regularization: 0.017221\n",
      "2019-04-09 22:57:34,694 root         INFO     Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 0.410520\n",
      "Reconstruction: 0.392554, Regularization: 0.017966\n",
      "2019-04-09 22:57:34,751 root         INFO     Train Epoch: 145 [1536/8000 (19%)]\tTotal Loss: 0.352992\n",
      "Reconstruction: 0.337812, Regularization: 0.015180\n",
      "2019-04-09 22:57:34,808 root         INFO     Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 0.403415\n",
      "Reconstruction: 0.385696, Regularization: 0.017719\n",
      "2019-04-09 22:57:34,864 root         INFO     Train Epoch: 145 [2560/8000 (32%)]\tTotal Loss: 0.403312\n",
      "Reconstruction: 0.391037, Regularization: 0.012275\n",
      "2019-04-09 22:57:34,921 root         INFO     Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 0.370028\n",
      "Reconstruction: 0.352560, Regularization: 0.017468\n",
      "2019-04-09 22:57:34,977 root         INFO     Train Epoch: 145 [3584/8000 (45%)]\tTotal Loss: 0.483743\n",
      "Reconstruction: 0.467101, Regularization: 0.016641\n",
      "2019-04-09 22:57:35,031 root         INFO     Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 0.333352\n",
      "Reconstruction: 0.315398, Regularization: 0.017955\n",
      "2019-04-09 22:57:35,086 root         INFO     Train Epoch: 145 [4608/8000 (58%)]\tTotal Loss: 0.402802\n",
      "Reconstruction: 0.388391, Regularization: 0.014411\n",
      "2019-04-09 22:57:35,140 root         INFO     Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 0.301358\n",
      "Reconstruction: 0.292620, Regularization: 0.008738\n",
      "2019-04-09 22:57:35,195 root         INFO     Train Epoch: 145 [5632/8000 (70%)]\tTotal Loss: 0.485863\n",
      "Reconstruction: 0.467618, Regularization: 0.018245\n",
      "2019-04-09 22:57:35,249 root         INFO     Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 0.393962\n",
      "Reconstruction: 0.375781, Regularization: 0.018180\n",
      "2019-04-09 22:57:35,303 root         INFO     Train Epoch: 145 [6656/8000 (83%)]\tTotal Loss: 0.386134\n",
      "Reconstruction: 0.370005, Regularization: 0.016129\n",
      "2019-04-09 22:57:35,358 root         INFO     Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 0.388823\n",
      "Reconstruction: 0.373633, Regularization: 0.015191\n",
      "2019-04-09 22:57:35,413 root         INFO     Train Epoch: 145 [7680/8000 (96%)]\tTotal Loss: 0.314079\n",
      "Reconstruction: 0.298265, Regularization: 0.015815\n",
      "2019-04-09 22:57:35,462 root         INFO     ====> Epoch: 145 Average loss: 0.4054\n",
      "2019-04-09 22:57:35,485 root         INFO     Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 0.432624\n",
      "Reconstruction: 0.416003, Regularization: 0.016621\n",
      "2019-04-09 22:57:35,542 root         INFO     Train Epoch: 146 [512/8000 (6%)]\tTotal Loss: 0.441031\n",
      "Reconstruction: 0.412170, Regularization: 0.028861\n",
      "2019-04-09 22:57:35,597 root         INFO     Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 0.798387\n",
      "Reconstruction: 0.778518, Regularization: 0.019868\n",
      "2019-04-09 22:57:35,653 root         INFO     Train Epoch: 146 [1536/8000 (19%)]\tTotal Loss: 0.373682\n",
      "Reconstruction: 0.357589, Regularization: 0.016093\n",
      "2019-04-09 22:57:35,709 root         INFO     Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 0.357660\n",
      "Reconstruction: 0.346289, Regularization: 0.011371\n",
      "2019-04-09 22:57:35,765 root         INFO     Train Epoch: 146 [2560/8000 (32%)]\tTotal Loss: 0.421229\n",
      "Reconstruction: 0.405529, Regularization: 0.015700\n",
      "2019-04-09 22:57:35,821 root         INFO     Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 0.647783\n",
      "Reconstruction: 0.626202, Regularization: 0.021581\n",
      "2019-04-09 22:57:35,877 root         INFO     Train Epoch: 146 [3584/8000 (45%)]\tTotal Loss: 0.417588\n",
      "Reconstruction: 0.398092, Regularization: 0.019496\n",
      "2019-04-09 22:57:35,931 root         INFO     Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 0.332862\n",
      "Reconstruction: 0.319463, Regularization: 0.013398\n",
      "2019-04-09 22:57:35,987 root         INFO     Train Epoch: 146 [4608/8000 (58%)]\tTotal Loss: 0.419068\n",
      "Reconstruction: 0.400233, Regularization: 0.018835\n",
      "2019-04-09 22:57:36,041 root         INFO     Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 0.316549\n",
      "Reconstruction: 0.304984, Regularization: 0.011566\n",
      "2019-04-09 22:57:36,097 root         INFO     Train Epoch: 146 [5632/8000 (70%)]\tTotal Loss: 0.427725\n",
      "Reconstruction: 0.405620, Regularization: 0.022104\n",
      "2019-04-09 22:57:36,152 root         INFO     Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 0.438857\n",
      "Reconstruction: 0.420867, Regularization: 0.017990\n",
      "2019-04-09 22:57:36,207 root         INFO     Train Epoch: 146 [6656/8000 (83%)]\tTotal Loss: 0.456326\n",
      "Reconstruction: 0.436122, Regularization: 0.020204\n",
      "2019-04-09 22:57:36,263 root         INFO     Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 0.315615\n",
      "Reconstruction: 0.301471, Regularization: 0.014144\n",
      "2019-04-09 22:57:36,318 root         INFO     Train Epoch: 146 [7680/8000 (96%)]\tTotal Loss: 0.351420\n",
      "Reconstruction: 0.333151, Regularization: 0.018269\n",
      "2019-04-09 22:57:36,368 root         INFO     ====> Epoch: 146 Average loss: 0.4618\n",
      "2019-04-09 22:57:36,392 root         INFO     Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 0.361785\n",
      "Reconstruction: 0.350267, Regularization: 0.011518\n",
      "2019-04-09 22:57:36,448 root         INFO     Train Epoch: 147 [512/8000 (6%)]\tTotal Loss: 0.349175\n",
      "Reconstruction: 0.329088, Regularization: 0.020087\n",
      "2019-04-09 22:57:36,505 root         INFO     Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 0.396517\n",
      "Reconstruction: 0.382026, Regularization: 0.014491\n",
      "2019-04-09 22:57:36,561 root         INFO     Train Epoch: 147 [1536/8000 (19%)]\tTotal Loss: 0.305910\n",
      "Reconstruction: 0.294666, Regularization: 0.011243\n",
      "2019-04-09 22:57:36,616 root         INFO     Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 0.382904\n",
      "Reconstruction: 0.367226, Regularization: 0.015678\n",
      "2019-04-09 22:57:36,672 root         INFO     Train Epoch: 147 [2560/8000 (32%)]\tTotal Loss: 0.435129\n",
      "Reconstruction: 0.419369, Regularization: 0.015760\n",
      "2019-04-09 22:57:36,727 root         INFO     Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 0.403694\n",
      "Reconstruction: 0.385884, Regularization: 0.017809\n",
      "2019-04-09 22:57:36,783 root         INFO     Train Epoch: 147 [3584/8000 (45%)]\tTotal Loss: 0.449432\n",
      "Reconstruction: 0.431190, Regularization: 0.018242\n",
      "2019-04-09 22:57:36,839 root         INFO     Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 0.345394\n",
      "Reconstruction: 0.330292, Regularization: 0.015102\n",
      "2019-04-09 22:57:36,894 root         INFO     Train Epoch: 147 [4608/8000 (58%)]\tTotal Loss: 0.366695\n",
      "Reconstruction: 0.349826, Regularization: 0.016869\n",
      "2019-04-09 22:57:36,950 root         INFO     Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 0.435287\n",
      "Reconstruction: 0.419000, Regularization: 0.016287\n",
      "2019-04-09 22:57:37,005 root         INFO     Train Epoch: 147 [5632/8000 (70%)]\tTotal Loss: 0.362795\n",
      "Reconstruction: 0.342462, Regularization: 0.020333\n",
      "2019-04-09 22:57:37,060 root         INFO     Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 0.440867\n",
      "Reconstruction: 0.423551, Regularization: 0.017317\n",
      "2019-04-09 22:57:37,116 root         INFO     Train Epoch: 147 [6656/8000 (83%)]\tTotal Loss: 0.318898\n",
      "Reconstruction: 0.308562, Regularization: 0.010336\n",
      "2019-04-09 22:57:37,171 root         INFO     Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 0.309913\n",
      "Reconstruction: 0.291042, Regularization: 0.018871\n",
      "2019-04-09 22:57:37,227 root         INFO     Train Epoch: 147 [7680/8000 (96%)]\tTotal Loss: 0.371620\n",
      "Reconstruction: 0.351418, Regularization: 0.020202\n",
      "2019-04-09 22:57:37,276 root         INFO     ====> Epoch: 147 Average loss: 0.4560\n",
      "2019-04-09 22:57:37,300 root         INFO     Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 0.394575\n",
      "Reconstruction: 0.381581, Regularization: 0.012994\n",
      "2019-04-09 22:57:37,356 root         INFO     Train Epoch: 148 [512/8000 (6%)]\tTotal Loss: 0.466102\n",
      "Reconstruction: 0.444241, Regularization: 0.021860\n",
      "2019-04-09 22:57:37,412 root         INFO     Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 0.401948\n",
      "Reconstruction: 0.383605, Regularization: 0.018344\n",
      "2019-04-09 22:57:37,468 root         INFO     Train Epoch: 148 [1536/8000 (19%)]\tTotal Loss: 0.405951\n",
      "Reconstruction: 0.388536, Regularization: 0.017415\n",
      "2019-04-09 22:57:37,524 root         INFO     Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 0.353197\n",
      "Reconstruction: 0.338996, Regularization: 0.014200\n",
      "2019-04-09 22:57:37,580 root         INFO     Train Epoch: 148 [2560/8000 (32%)]\tTotal Loss: 0.384627\n",
      "Reconstruction: 0.366606, Regularization: 0.018021\n",
      "2019-04-09 22:57:37,636 root         INFO     Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 0.378178\n",
      "Reconstruction: 0.354959, Regularization: 0.023219\n",
      "2019-04-09 22:57:37,692 root         INFO     Train Epoch: 148 [3584/8000 (45%)]\tTotal Loss: 0.315096\n",
      "Reconstruction: 0.301226, Regularization: 0.013870\n",
      "2019-04-09 22:57:37,749 root         INFO     Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 0.393301\n",
      "Reconstruction: 0.380062, Regularization: 0.013239\n",
      "2019-04-09 22:57:37,804 root         INFO     Train Epoch: 148 [4608/8000 (58%)]\tTotal Loss: 0.378448\n",
      "Reconstruction: 0.348338, Regularization: 0.030109\n",
      "2019-04-09 22:57:37,859 root         INFO     Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 0.440175\n",
      "Reconstruction: 0.423241, Regularization: 0.016934\n",
      "2019-04-09 22:57:37,914 root         INFO     Train Epoch: 148 [5632/8000 (70%)]\tTotal Loss: 0.608781\n",
      "Reconstruction: 0.589138, Regularization: 0.019643\n",
      "2019-04-09 22:57:37,970 root         INFO     Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 0.324327\n",
      "Reconstruction: 0.311175, Regularization: 0.013152\n",
      "2019-04-09 22:57:38,026 root         INFO     Train Epoch: 148 [6656/8000 (83%)]\tTotal Loss: 0.372769\n",
      "Reconstruction: 0.355079, Regularization: 0.017690\n",
      "2019-04-09 22:57:38,081 root         INFO     Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 0.360160\n",
      "Reconstruction: 0.339730, Regularization: 0.020430\n",
      "2019-04-09 22:57:38,136 root         INFO     Train Epoch: 148 [7680/8000 (96%)]\tTotal Loss: 0.623559\n",
      "Reconstruction: 0.600061, Regularization: 0.023498\n",
      "2019-04-09 22:57:38,186 root         INFO     ====> Epoch: 148 Average loss: 0.5941\n",
      "2019-04-09 22:57:38,210 root         INFO     Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 0.365814\n",
      "Reconstruction: 0.340774, Regularization: 0.025041\n",
      "2019-04-09 22:57:38,265 root         INFO     Train Epoch: 149 [512/8000 (6%)]\tTotal Loss: 0.371848\n",
      "Reconstruction: 0.357607, Regularization: 0.014242\n",
      "2019-04-09 22:57:38,320 root         INFO     Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 0.406891\n",
      "Reconstruction: 0.391791, Regularization: 0.015100\n",
      "2019-04-09 22:57:38,375 root         INFO     Train Epoch: 149 [1536/8000 (19%)]\tTotal Loss: 0.377351\n",
      "Reconstruction: 0.356428, Regularization: 0.020923\n",
      "2019-04-09 22:57:38,430 root         INFO     Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 0.336418\n",
      "Reconstruction: 0.314076, Regularization: 0.022342\n",
      "2019-04-09 22:57:38,485 root         INFO     Train Epoch: 149 [2560/8000 (32%)]\tTotal Loss: 0.435772\n",
      "Reconstruction: 0.421855, Regularization: 0.013916\n",
      "2019-04-09 22:57:38,540 root         INFO     Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 0.323069\n",
      "Reconstruction: 0.305687, Regularization: 0.017382\n",
      "2019-04-09 22:57:38,595 root         INFO     Train Epoch: 149 [3584/8000 (45%)]\tTotal Loss: 0.328967\n",
      "Reconstruction: 0.308735, Regularization: 0.020232\n",
      "2019-04-09 22:57:38,650 root         INFO     Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 0.359398\n",
      "Reconstruction: 0.345865, Regularization: 0.013533\n",
      "2019-04-09 22:57:38,705 root         INFO     Train Epoch: 149 [4608/8000 (58%)]\tTotal Loss: 0.372271\n",
      "Reconstruction: 0.356678, Regularization: 0.015593\n",
      "2019-04-09 22:57:38,760 root         INFO     Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 0.390369\n",
      "Reconstruction: 0.377123, Regularization: 0.013246\n",
      "2019-04-09 22:57:38,815 root         INFO     Train Epoch: 149 [5632/8000 (70%)]\tTotal Loss: 0.383605\n",
      "Reconstruction: 0.362855, Regularization: 0.020750\n",
      "2019-04-09 22:57:38,871 root         INFO     Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 0.440342\n",
      "Reconstruction: 0.422753, Regularization: 0.017589\n",
      "2019-04-09 22:57:38,925 root         INFO     Train Epoch: 149 [6656/8000 (83%)]\tTotal Loss: 0.351976\n",
      "Reconstruction: 0.337364, Regularization: 0.014613\n",
      "2019-04-09 22:57:38,981 root         INFO     Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 0.442575\n",
      "Reconstruction: 0.419995, Regularization: 0.022581\n",
      "2019-04-09 22:57:39,036 root         INFO     Train Epoch: 149 [7680/8000 (96%)]\tTotal Loss: 0.395917\n",
      "Reconstruction: 0.381484, Regularization: 0.014433\n",
      "2019-04-09 22:57:39,085 root         INFO     ====> Epoch: 149 Average loss: 0.6696\n",
      "2019-04-09 22:57:39,108 root         INFO     Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 0.430971\n",
      "Reconstruction: 0.410703, Regularization: 0.020268\n",
      "2019-04-09 22:57:39,164 root         INFO     Train Epoch: 150 [512/8000 (6%)]\tTotal Loss: 0.345493\n",
      "Reconstruction: 0.319738, Regularization: 0.025755\n",
      "2019-04-09 22:57:39,220 root         INFO     Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 0.350486\n",
      "Reconstruction: 0.337951, Regularization: 0.012534\n",
      "2019-04-09 22:57:39,275 root         INFO     Train Epoch: 150 [1536/8000 (19%)]\tTotal Loss: 0.343962\n",
      "Reconstruction: 0.328267, Regularization: 0.015695\n",
      "2019-04-09 22:57:39,331 root         INFO     Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 0.331028\n",
      "Reconstruction: 0.319259, Regularization: 0.011770\n",
      "2019-04-09 22:57:39,386 root         INFO     Train Epoch: 150 [2560/8000 (32%)]\tTotal Loss: 0.359951\n",
      "Reconstruction: 0.340608, Regularization: 0.019343\n",
      "2019-04-09 22:57:39,442 root         INFO     Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 0.361187\n",
      "Reconstruction: 0.343709, Regularization: 0.017478\n",
      "2019-04-09 22:57:39,498 root         INFO     Train Epoch: 150 [3584/8000 (45%)]\tTotal Loss: 0.403741\n",
      "Reconstruction: 0.389025, Regularization: 0.014716\n",
      "2019-04-09 22:57:39,554 root         INFO     Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 0.385847\n",
      "Reconstruction: 0.370309, Regularization: 0.015538\n",
      "2019-04-09 22:57:39,610 root         INFO     Train Epoch: 150 [4608/8000 (58%)]\tTotal Loss: 0.383842\n",
      "Reconstruction: 0.368838, Regularization: 0.015004\n",
      "2019-04-09 22:57:39,664 root         INFO     Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 0.476305\n",
      "Reconstruction: 0.455284, Regularization: 0.021021\n",
      "2019-04-09 22:57:39,718 root         INFO     Train Epoch: 150 [5632/8000 (70%)]\tTotal Loss: 0.364856\n",
      "Reconstruction: 0.352015, Regularization: 0.012841\n",
      "2019-04-09 22:57:39,775 root         INFO     Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 0.471986\n",
      "Reconstruction: 0.453700, Regularization: 0.018286\n",
      "2019-04-09 22:57:39,829 root         INFO     Train Epoch: 150 [6656/8000 (83%)]\tTotal Loss: 0.382611\n",
      "Reconstruction: 0.364821, Regularization: 0.017789\n",
      "2019-04-09 22:57:39,883 root         INFO     Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 0.420351\n",
      "Reconstruction: 0.406484, Regularization: 0.013868\n",
      "2019-04-09 22:57:39,938 root         INFO     Train Epoch: 150 [7680/8000 (96%)]\tTotal Loss: 0.400112\n",
      "Reconstruction: 0.380944, Regularization: 0.019168\n",
      "2019-04-09 22:57:39,987 root         INFO     ====> Epoch: 150 Average loss: 0.4386\n",
      "2019-04-09 22:57:40,012 root         INFO     Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 0.447011\n",
      "Reconstruction: 0.430137, Regularization: 0.016874\n",
      "2019-04-09 22:57:40,068 root         INFO     Train Epoch: 151 [512/8000 (6%)]\tTotal Loss: 0.299415\n",
      "Reconstruction: 0.286077, Regularization: 0.013338\n",
      "2019-04-09 22:57:40,123 root         INFO     Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 0.372876\n",
      "Reconstruction: 0.357493, Regularization: 0.015383\n",
      "2019-04-09 22:57:40,179 root         INFO     Train Epoch: 151 [1536/8000 (19%)]\tTotal Loss: 0.400715\n",
      "Reconstruction: 0.386220, Regularization: 0.014496\n",
      "2019-04-09 22:57:40,234 root         INFO     Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 0.421151\n",
      "Reconstruction: 0.407395, Regularization: 0.013755\n",
      "2019-04-09 22:57:40,289 root         INFO     Train Epoch: 151 [2560/8000 (32%)]\tTotal Loss: 0.391353\n",
      "Reconstruction: 0.375120, Regularization: 0.016233\n",
      "2019-04-09 22:57:40,344 root         INFO     Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 0.354324\n",
      "Reconstruction: 0.339113, Regularization: 0.015211\n",
      "2019-04-09 22:57:40,399 root         INFO     Train Epoch: 151 [3584/8000 (45%)]\tTotal Loss: 0.324390\n",
      "Reconstruction: 0.311566, Regularization: 0.012824\n",
      "2019-04-09 22:57:40,455 root         INFO     Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 0.342530\n",
      "Reconstruction: 0.327565, Regularization: 0.014965\n",
      "2019-04-09 22:57:40,510 root         INFO     Train Epoch: 151 [4608/8000 (58%)]\tTotal Loss: 0.342377\n",
      "Reconstruction: 0.329891, Regularization: 0.012486\n",
      "2019-04-09 22:57:40,566 root         INFO     Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 0.341055\n",
      "Reconstruction: 0.329822, Regularization: 0.011233\n",
      "2019-04-09 22:57:40,622 root         INFO     Train Epoch: 151 [5632/8000 (70%)]\tTotal Loss: 0.278318\n",
      "Reconstruction: 0.266615, Regularization: 0.011703\n",
      "2019-04-09 22:57:40,678 root         INFO     Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 0.413441\n",
      "Reconstruction: 0.380448, Regularization: 0.032993\n",
      "2019-04-09 22:57:40,735 root         INFO     Train Epoch: 151 [6656/8000 (83%)]\tTotal Loss: 0.305862\n",
      "Reconstruction: 0.286421, Regularization: 0.019442\n",
      "2019-04-09 22:57:40,790 root         INFO     Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 0.423401\n",
      "Reconstruction: 0.408343, Regularization: 0.015058\n",
      "2019-04-09 22:57:40,846 root         INFO     Train Epoch: 151 [7680/8000 (96%)]\tTotal Loss: 0.318060\n",
      "Reconstruction: 0.301534, Regularization: 0.016526\n",
      "2019-04-09 22:57:40,896 root         INFO     ====> Epoch: 151 Average loss: 4.0857\n",
      "2019-04-09 22:57:40,920 root         INFO     Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 0.443781\n",
      "Reconstruction: 0.427599, Regularization: 0.016182\n",
      "2019-04-09 22:57:40,977 root         INFO     Train Epoch: 152 [512/8000 (6%)]\tTotal Loss: 0.401980\n",
      "Reconstruction: 0.386080, Regularization: 0.015900\n",
      "2019-04-09 22:57:41,033 root         INFO     Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 0.366792\n",
      "Reconstruction: 0.350754, Regularization: 0.016037\n",
      "2019-04-09 22:57:41,089 root         INFO     Train Epoch: 152 [1536/8000 (19%)]\tTotal Loss: 0.449024\n",
      "Reconstruction: 0.426244, Regularization: 0.022780\n",
      "2019-04-09 22:57:41,144 root         INFO     Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 0.360686\n",
      "Reconstruction: 0.346452, Regularization: 0.014234\n",
      "2019-04-09 22:57:41,200 root         INFO     Train Epoch: 152 [2560/8000 (32%)]\tTotal Loss: 0.406976\n",
      "Reconstruction: 0.387595, Regularization: 0.019380\n",
      "2019-04-09 22:57:41,256 root         INFO     Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 0.376281\n",
      "Reconstruction: 0.362087, Regularization: 0.014195\n",
      "2019-04-09 22:57:41,312 root         INFO     Train Epoch: 152 [3584/8000 (45%)]\tTotal Loss: 0.490524\n",
      "Reconstruction: 0.471562, Regularization: 0.018962\n",
      "2019-04-09 22:57:41,369 root         INFO     Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 0.390813\n",
      "Reconstruction: 0.367225, Regularization: 0.023589\n",
      "2019-04-09 22:57:41,425 root         INFO     Train Epoch: 152 [4608/8000 (58%)]\tTotal Loss: 0.429935\n",
      "Reconstruction: 0.410874, Regularization: 0.019060\n",
      "2019-04-09 22:57:41,481 root         INFO     Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 0.470331\n",
      "Reconstruction: 0.452601, Regularization: 0.017730\n",
      "2019-04-09 22:57:41,536 root         INFO     Train Epoch: 152 [5632/8000 (70%)]\tTotal Loss: 0.481066\n",
      "Reconstruction: 0.448811, Regularization: 0.032255\n",
      "2019-04-09 22:57:41,593 root         INFO     Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 0.338869\n",
      "Reconstruction: 0.323077, Regularization: 0.015792\n",
      "2019-04-09 22:57:41,648 root         INFO     Train Epoch: 152 [6656/8000 (83%)]\tTotal Loss: 0.359866\n",
      "Reconstruction: 0.341290, Regularization: 0.018577\n",
      "2019-04-09 22:57:41,703 root         INFO     Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 0.395575\n",
      "Reconstruction: 0.379285, Regularization: 0.016290\n",
      "2019-04-09 22:57:41,758 root         INFO     Train Epoch: 152 [7680/8000 (96%)]\tTotal Loss: 0.335016\n",
      "Reconstruction: 0.322627, Regularization: 0.012389\n",
      "2019-04-09 22:57:41,807 root         INFO     ====> Epoch: 152 Average loss: 0.3945\n",
      "2019-04-09 22:57:41,830 root         INFO     Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 0.415953\n",
      "Reconstruction: 0.396993, Regularization: 0.018960\n",
      "2019-04-09 22:57:41,887 root         INFO     Train Epoch: 153 [512/8000 (6%)]\tTotal Loss: 0.388116\n",
      "Reconstruction: 0.375935, Regularization: 0.012181\n",
      "2019-04-09 22:57:41,943 root         INFO     Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 0.398453\n",
      "Reconstruction: 0.381270, Regularization: 0.017183\n",
      "2019-04-09 22:57:42,000 root         INFO     Train Epoch: 153 [1536/8000 (19%)]\tTotal Loss: 0.388782\n",
      "Reconstruction: 0.369634, Regularization: 0.019148\n",
      "2019-04-09 22:57:42,057 root         INFO     Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 0.412959\n",
      "Reconstruction: 0.399179, Regularization: 0.013780\n",
      "2019-04-09 22:57:42,114 root         INFO     Train Epoch: 153 [2560/8000 (32%)]\tTotal Loss: 0.341190\n",
      "Reconstruction: 0.327067, Regularization: 0.014122\n",
      "2019-04-09 22:57:42,169 root         INFO     Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 0.390439\n",
      "Reconstruction: 0.370435, Regularization: 0.020004\n",
      "2019-04-09 22:57:42,222 root         INFO     Train Epoch: 153 [3584/8000 (45%)]\tTotal Loss: 0.407816\n",
      "Reconstruction: 0.372800, Regularization: 0.035015\n",
      "2019-04-09 22:57:42,276 root         INFO     Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 0.407056\n",
      "Reconstruction: 0.393572, Regularization: 0.013485\n",
      "2019-04-09 22:57:42,330 root         INFO     Train Epoch: 153 [4608/8000 (58%)]\tTotal Loss: 0.410301\n",
      "Reconstruction: 0.393086, Regularization: 0.017215\n",
      "2019-04-09 22:57:42,385 root         INFO     Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 0.500418\n",
      "Reconstruction: 0.476949, Regularization: 0.023468\n",
      "2019-04-09 22:57:42,438 root         INFO     Train Epoch: 153 [5632/8000 (70%)]\tTotal Loss: 0.570397\n",
      "Reconstruction: 0.539008, Regularization: 0.031390\n",
      "2019-04-09 22:57:42,492 root         INFO     Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 0.382004\n",
      "Reconstruction: 0.362377, Regularization: 0.019627\n",
      "2019-04-09 22:57:42,546 root         INFO     Train Epoch: 153 [6656/8000 (83%)]\tTotal Loss: 0.384956\n",
      "Reconstruction: 0.366014, Regularization: 0.018942\n",
      "2019-04-09 22:57:42,600 root         INFO     Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 0.438303\n",
      "Reconstruction: 0.419940, Regularization: 0.018363\n",
      "2019-04-09 22:57:42,654 root         INFO     Train Epoch: 153 [7680/8000 (96%)]\tTotal Loss: 0.378187\n",
      "Reconstruction: 0.360480, Regularization: 0.017707\n",
      "2019-04-09 22:57:42,703 root         INFO     ====> Epoch: 153 Average loss: 0.4037\n",
      "2019-04-09 22:57:42,728 root         INFO     Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 0.406270\n",
      "Reconstruction: 0.388866, Regularization: 0.017404\n",
      "2019-04-09 22:57:42,784 root         INFO     Train Epoch: 154 [512/8000 (6%)]\tTotal Loss: 0.295381\n",
      "Reconstruction: 0.284550, Regularization: 0.010830\n",
      "2019-04-09 22:57:42,840 root         INFO     Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 0.418047\n",
      "Reconstruction: 0.397251, Regularization: 0.020796\n",
      "2019-04-09 22:57:42,895 root         INFO     Train Epoch: 154 [1536/8000 (19%)]\tTotal Loss: 0.384782\n",
      "Reconstruction: 0.365362, Regularization: 0.019419\n",
      "2019-04-09 22:57:42,950 root         INFO     Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 0.311432\n",
      "Reconstruction: 0.295272, Regularization: 0.016160\n",
      "2019-04-09 22:57:43,005 root         INFO     Train Epoch: 154 [2560/8000 (32%)]\tTotal Loss: 0.381642\n",
      "Reconstruction: 0.364804, Regularization: 0.016838\n",
      "2019-04-09 22:57:43,061 root         INFO     Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 0.629145\n",
      "Reconstruction: 0.611836, Regularization: 0.017309\n",
      "2019-04-09 22:57:43,116 root         INFO     Train Epoch: 154 [3584/8000 (45%)]\tTotal Loss: 0.372270\n",
      "Reconstruction: 0.353195, Regularization: 0.019075\n",
      "2019-04-09 22:57:43,171 root         INFO     Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 0.434670\n",
      "Reconstruction: 0.419213, Regularization: 0.015457\n",
      "2019-04-09 22:57:43,226 root         INFO     Train Epoch: 154 [4608/8000 (58%)]\tTotal Loss: 0.448495\n",
      "Reconstruction: 0.412876, Regularization: 0.035619\n",
      "2019-04-09 22:57:43,282 root         INFO     Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 0.310229\n",
      "Reconstruction: 0.299297, Regularization: 0.010933\n",
      "2019-04-09 22:57:43,337 root         INFO     Train Epoch: 154 [5632/8000 (70%)]\tTotal Loss: 0.311233\n",
      "Reconstruction: 0.299298, Regularization: 0.011935\n",
      "2019-04-09 22:57:43,392 root         INFO     Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 0.350858\n",
      "Reconstruction: 0.334385, Regularization: 0.016473\n",
      "2019-04-09 22:57:43,447 root         INFO     Train Epoch: 154 [6656/8000 (83%)]\tTotal Loss: 0.551779\n",
      "Reconstruction: 0.512197, Regularization: 0.039582\n",
      "2019-04-09 22:57:43,502 root         INFO     Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 0.339774\n",
      "Reconstruction: 0.328050, Regularization: 0.011724\n",
      "2019-04-09 22:57:43,556 root         INFO     Train Epoch: 154 [7680/8000 (96%)]\tTotal Loss: 0.331823\n",
      "Reconstruction: 0.320847, Regularization: 0.010975\n",
      "2019-04-09 22:57:43,607 root         INFO     ====> Epoch: 154 Average loss: 0.3996\n",
      "2019-04-09 22:57:43,630 root         INFO     Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 0.377335\n",
      "Reconstruction: 0.360714, Regularization: 0.016621\n",
      "2019-04-09 22:57:43,686 root         INFO     Train Epoch: 155 [512/8000 (6%)]\tTotal Loss: 0.488022\n",
      "Reconstruction: 0.469886, Regularization: 0.018136\n",
      "2019-04-09 22:57:43,741 root         INFO     Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 0.447774\n",
      "Reconstruction: 0.431952, Regularization: 0.015822\n",
      "2019-04-09 22:57:43,796 root         INFO     Train Epoch: 155 [1536/8000 (19%)]\tTotal Loss: 0.417108\n",
      "Reconstruction: 0.399222, Regularization: 0.017887\n",
      "2019-04-09 22:57:43,852 root         INFO     Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 0.411058\n",
      "Reconstruction: 0.390833, Regularization: 0.020225\n",
      "2019-04-09 22:57:43,908 root         INFO     Train Epoch: 155 [2560/8000 (32%)]\tTotal Loss: 0.374120\n",
      "Reconstruction: 0.359956, Regularization: 0.014164\n",
      "2019-04-09 22:57:43,963 root         INFO     Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 0.348292\n",
      "Reconstruction: 0.333925, Regularization: 0.014367\n",
      "2019-04-09 22:57:44,019 root         INFO     Train Epoch: 155 [3584/8000 (45%)]\tTotal Loss: 0.393003\n",
      "Reconstruction: 0.370609, Regularization: 0.022394\n",
      "2019-04-09 22:57:44,075 root         INFO     Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 0.350766\n",
      "Reconstruction: 0.338083, Regularization: 0.012683\n",
      "2019-04-09 22:57:44,131 root         INFO     Train Epoch: 155 [4608/8000 (58%)]\tTotal Loss: 0.398244\n",
      "Reconstruction: 0.380625, Regularization: 0.017620\n",
      "2019-04-09 22:57:44,187 root         INFO     Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 0.348306\n",
      "Reconstruction: 0.333951, Regularization: 0.014355\n",
      "2019-04-09 22:57:44,243 root         INFO     Train Epoch: 155 [5632/8000 (70%)]\tTotal Loss: 0.406161\n",
      "Reconstruction: 0.385618, Regularization: 0.020543\n",
      "2019-04-09 22:57:44,299 root         INFO     Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 0.394843\n",
      "Reconstruction: 0.366179, Regularization: 0.028664\n",
      "2019-04-09 22:57:44,356 root         INFO     Train Epoch: 155 [6656/8000 (83%)]\tTotal Loss: 0.406007\n",
      "Reconstruction: 0.385453, Regularization: 0.020553\n",
      "2019-04-09 22:57:44,411 root         INFO     Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 0.358591\n",
      "Reconstruction: 0.344771, Regularization: 0.013820\n",
      "2019-04-09 22:57:44,466 root         INFO     Train Epoch: 155 [7680/8000 (96%)]\tTotal Loss: 0.361077\n",
      "Reconstruction: 0.348552, Regularization: 0.012525\n",
      "2019-04-09 22:57:44,515 root         INFO     ====> Epoch: 155 Average loss: 0.4011\n",
      "2019-04-09 22:57:44,539 root         INFO     Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 0.364396\n",
      "Reconstruction: 0.348082, Regularization: 0.016314\n",
      "2019-04-09 22:57:44,596 root         INFO     Train Epoch: 156 [512/8000 (6%)]\tTotal Loss: 0.390551\n",
      "Reconstruction: 0.375465, Regularization: 0.015086\n",
      "2019-04-09 22:57:44,652 root         INFO     Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 0.336353\n",
      "Reconstruction: 0.326147, Regularization: 0.010206\n",
      "2019-04-09 22:57:44,708 root         INFO     Train Epoch: 156 [1536/8000 (19%)]\tTotal Loss: 0.468495\n",
      "Reconstruction: 0.437768, Regularization: 0.030727\n",
      "2019-04-09 22:57:44,764 root         INFO     Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 0.390113\n",
      "Reconstruction: 0.372779, Regularization: 0.017334\n",
      "2019-04-09 22:57:44,819 root         INFO     Train Epoch: 156 [2560/8000 (32%)]\tTotal Loss: 0.415431\n",
      "Reconstruction: 0.396129, Regularization: 0.019302\n",
      "2019-04-09 22:57:44,875 root         INFO     Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 0.371854\n",
      "Reconstruction: 0.360170, Regularization: 0.011684\n",
      "2019-04-09 22:57:44,931 root         INFO     Train Epoch: 156 [3584/8000 (45%)]\tTotal Loss: 0.523079\n",
      "Reconstruction: 0.492941, Regularization: 0.030137\n",
      "2019-04-09 22:57:44,987 root         INFO     Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 0.401519\n",
      "Reconstruction: 0.385912, Regularization: 0.015607\n",
      "2019-04-09 22:57:45,044 root         INFO     Train Epoch: 156 [4608/8000 (58%)]\tTotal Loss: 0.333565\n",
      "Reconstruction: 0.313842, Regularization: 0.019723\n",
      "2019-04-09 22:57:45,100 root         INFO     Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 0.399838\n",
      "Reconstruction: 0.384943, Regularization: 0.014895\n",
      "2019-04-09 22:57:45,156 root         INFO     Train Epoch: 156 [5632/8000 (70%)]\tTotal Loss: 0.491201\n",
      "Reconstruction: 0.473828, Regularization: 0.017373\n",
      "2019-04-09 22:57:45,212 root         INFO     Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 0.370213\n",
      "Reconstruction: 0.354414, Regularization: 0.015799\n",
      "2019-04-09 22:57:45,268 root         INFO     Train Epoch: 156 [6656/8000 (83%)]\tTotal Loss: 0.381807\n",
      "Reconstruction: 0.356986, Regularization: 0.024821\n",
      "2019-04-09 22:57:45,323 root         INFO     Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 0.455013\n",
      "Reconstruction: 0.430201, Regularization: 0.024812\n",
      "2019-04-09 22:57:45,377 root         INFO     Train Epoch: 156 [7680/8000 (96%)]\tTotal Loss: 0.469262\n",
      "Reconstruction: 0.444691, Regularization: 0.024571\n",
      "2019-04-09 22:57:45,426 root         INFO     ====> Epoch: 156 Average loss: 0.7227\n",
      "2019-04-09 22:57:45,450 root         INFO     Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 0.461367\n",
      "Reconstruction: 0.445589, Regularization: 0.015778\n",
      "2019-04-09 22:57:45,506 root         INFO     Train Epoch: 157 [512/8000 (6%)]\tTotal Loss: 0.383425\n",
      "Reconstruction: 0.361173, Regularization: 0.022252\n",
      "2019-04-09 22:57:45,562 root         INFO     Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 0.309133\n",
      "Reconstruction: 0.296155, Regularization: 0.012979\n",
      "2019-04-09 22:57:45,618 root         INFO     Train Epoch: 157 [1536/8000 (19%)]\tTotal Loss: 0.462175\n",
      "Reconstruction: 0.444203, Regularization: 0.017972\n",
      "2019-04-09 22:57:45,675 root         INFO     Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 0.403192\n",
      "Reconstruction: 0.387464, Regularization: 0.015728\n",
      "2019-04-09 22:57:45,733 root         INFO     Train Epoch: 157 [2560/8000 (32%)]\tTotal Loss: 0.290252\n",
      "Reconstruction: 0.279754, Regularization: 0.010498\n",
      "2019-04-09 22:57:45,790 root         INFO     Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 0.340285\n",
      "Reconstruction: 0.326458, Regularization: 0.013827\n",
      "2019-04-09 22:57:45,848 root         INFO     Train Epoch: 157 [3584/8000 (45%)]\tTotal Loss: 0.403427\n",
      "Reconstruction: 0.362683, Regularization: 0.040745\n",
      "2019-04-09 22:57:45,905 root         INFO     Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 0.398335\n",
      "Reconstruction: 0.368285, Regularization: 0.030051\n",
      "2019-04-09 22:57:45,962 root         INFO     Train Epoch: 157 [4608/8000 (58%)]\tTotal Loss: 0.430575\n",
      "Reconstruction: 0.408445, Regularization: 0.022131\n",
      "2019-04-09 22:57:46,020 root         INFO     Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 0.410346\n",
      "Reconstruction: 0.394119, Regularization: 0.016227\n",
      "2019-04-09 22:57:46,077 root         INFO     Train Epoch: 157 [5632/8000 (70%)]\tTotal Loss: 0.430538\n",
      "Reconstruction: 0.413616, Regularization: 0.016921\n",
      "2019-04-09 22:57:46,135 root         INFO     Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 0.395196\n",
      "Reconstruction: 0.379951, Regularization: 0.015244\n",
      "2019-04-09 22:57:46,192 root         INFO     Train Epoch: 157 [6656/8000 (83%)]\tTotal Loss: 0.307916\n",
      "Reconstruction: 0.296543, Regularization: 0.011373\n",
      "2019-04-09 22:57:46,249 root         INFO     Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 0.391880\n",
      "Reconstruction: 0.379572, Regularization: 0.012308\n",
      "2019-04-09 22:57:46,307 root         INFO     Train Epoch: 157 [7680/8000 (96%)]\tTotal Loss: 0.413114\n",
      "Reconstruction: 0.399182, Regularization: 0.013933\n",
      "2019-04-09 22:57:46,358 root         INFO     ====> Epoch: 157 Average loss: 12.8864\n",
      "2019-04-09 22:57:46,381 root         INFO     Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 0.426557\n",
      "Reconstruction: 0.409831, Regularization: 0.016726\n",
      "2019-04-09 22:57:46,438 root         INFO     Train Epoch: 158 [512/8000 (6%)]\tTotal Loss: 0.423689\n",
      "Reconstruction: 0.404723, Regularization: 0.018967\n",
      "2019-04-09 22:57:46,494 root         INFO     Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 0.353229\n",
      "Reconstruction: 0.336334, Regularization: 0.016895\n",
      "2019-04-09 22:57:46,551 root         INFO     Train Epoch: 158 [1536/8000 (19%)]\tTotal Loss: 0.357591\n",
      "Reconstruction: 0.341438, Regularization: 0.016153\n",
      "2019-04-09 22:57:46,607 root         INFO     Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 0.833507\n",
      "Reconstruction: 0.814850, Regularization: 0.018656\n",
      "2019-04-09 22:57:46,664 root         INFO     Train Epoch: 158 [2560/8000 (32%)]\tTotal Loss: 0.432450\n",
      "Reconstruction: 0.417767, Regularization: 0.014683\n",
      "2019-04-09 22:57:46,720 root         INFO     Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 0.476685\n",
      "Reconstruction: 0.459675, Regularization: 0.017010\n",
      "2019-04-09 22:57:46,777 root         INFO     Train Epoch: 158 [3584/8000 (45%)]\tTotal Loss: 0.480236\n",
      "Reconstruction: 0.459992, Regularization: 0.020243\n",
      "2019-04-09 22:57:46,833 root         INFO     Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 0.393832\n",
      "Reconstruction: 0.376482, Regularization: 0.017349\n",
      "2019-04-09 22:57:46,890 root         INFO     Train Epoch: 158 [4608/8000 (58%)]\tTotal Loss: 0.337705\n",
      "Reconstruction: 0.326429, Regularization: 0.011276\n",
      "2019-04-09 22:57:46,947 root         INFO     Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 0.414530\n",
      "Reconstruction: 0.399733, Regularization: 0.014796\n",
      "2019-04-09 22:57:47,003 root         INFO     Train Epoch: 158 [5632/8000 (70%)]\tTotal Loss: 0.376163\n",
      "Reconstruction: 0.362628, Regularization: 0.013535\n",
      "2019-04-09 22:57:47,060 root         INFO     Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 0.421824\n",
      "Reconstruction: 0.386875, Regularization: 0.034949\n",
      "2019-04-09 22:57:47,117 root         INFO     Train Epoch: 158 [6656/8000 (83%)]\tTotal Loss: 0.355527\n",
      "Reconstruction: 0.336283, Regularization: 0.019244\n",
      "2019-04-09 22:57:47,173 root         INFO     Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 0.387958\n",
      "Reconstruction: 0.373447, Regularization: 0.014511\n",
      "2019-04-09 22:57:47,230 root         INFO     Train Epoch: 158 [7680/8000 (96%)]\tTotal Loss: 0.336618\n",
      "Reconstruction: 0.323695, Regularization: 0.012923\n",
      "2019-04-09 22:57:47,280 root         INFO     ====> Epoch: 158 Average loss: 0.4065\n",
      "2019-04-09 22:57:47,303 root         INFO     Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 0.400224\n",
      "Reconstruction: 0.382767, Regularization: 0.017457\n",
      "2019-04-09 22:57:47,360 root         INFO     Train Epoch: 159 [512/8000 (6%)]\tTotal Loss: 0.356517\n",
      "Reconstruction: 0.341407, Regularization: 0.015110\n",
      "2019-04-09 22:57:47,416 root         INFO     Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 0.415004\n",
      "Reconstruction: 0.398425, Regularization: 0.016579\n",
      "2019-04-09 22:57:47,472 root         INFO     Train Epoch: 159 [1536/8000 (19%)]\tTotal Loss: 0.432380\n",
      "Reconstruction: 0.415682, Regularization: 0.016698\n",
      "2019-04-09 22:57:47,528 root         INFO     Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 0.535792\n",
      "Reconstruction: 0.515766, Regularization: 0.020026\n",
      "2019-04-09 22:57:47,583 root         INFO     Train Epoch: 159 [2560/8000 (32%)]\tTotal Loss: 0.404193\n",
      "Reconstruction: 0.386313, Regularization: 0.017880\n",
      "2019-04-09 22:57:47,638 root         INFO     Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 0.422949\n",
      "Reconstruction: 0.400308, Regularization: 0.022641\n",
      "2019-04-09 22:57:47,693 root         INFO     Train Epoch: 159 [3584/8000 (45%)]\tTotal Loss: 0.421546\n",
      "Reconstruction: 0.391992, Regularization: 0.029554\n",
      "2019-04-09 22:57:47,748 root         INFO     Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 0.443473\n",
      "Reconstruction: 0.428277, Regularization: 0.015196\n",
      "2019-04-09 22:57:47,803 root         INFO     Train Epoch: 159 [4608/8000 (58%)]\tTotal Loss: 0.324940\n",
      "Reconstruction: 0.307937, Regularization: 0.017002\n",
      "2019-04-09 22:57:47,858 root         INFO     Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 0.434025\n",
      "Reconstruction: 0.415902, Regularization: 0.018123\n",
      "2019-04-09 22:57:47,913 root         INFO     Train Epoch: 159 [5632/8000 (70%)]\tTotal Loss: 0.368131\n",
      "Reconstruction: 0.357504, Regularization: 0.010628\n",
      "2019-04-09 22:57:47,968 root         INFO     Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 0.381313\n",
      "Reconstruction: 0.365957, Regularization: 0.015356\n",
      "2019-04-09 22:57:48,024 root         INFO     Train Epoch: 159 [6656/8000 (83%)]\tTotal Loss: 0.398347\n",
      "Reconstruction: 0.383293, Regularization: 0.015054\n",
      "2019-04-09 22:57:48,079 root         INFO     Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 0.374206\n",
      "Reconstruction: 0.358576, Regularization: 0.015630\n",
      "2019-04-09 22:57:48,134 root         INFO     Train Epoch: 159 [7680/8000 (96%)]\tTotal Loss: 0.352362\n",
      "Reconstruction: 0.320428, Regularization: 0.031933\n",
      "2019-04-09 22:57:48,184 root         INFO     ====> Epoch: 159 Average loss: 0.4060\n",
      "2019-04-09 22:57:48,207 root         INFO     Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 0.323889\n",
      "Reconstruction: 0.311732, Regularization: 0.012157\n",
      "2019-04-09 22:57:48,263 root         INFO     Train Epoch: 160 [512/8000 (6%)]\tTotal Loss: 0.469101\n",
      "Reconstruction: 0.448799, Regularization: 0.020302\n",
      "2019-04-09 22:57:48,319 root         INFO     Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 0.372882\n",
      "Reconstruction: 0.353412, Regularization: 0.019469\n",
      "2019-04-09 22:57:48,374 root         INFO     Train Epoch: 160 [1536/8000 (19%)]\tTotal Loss: 0.340007\n",
      "Reconstruction: 0.325585, Regularization: 0.014423\n",
      "2019-04-09 22:57:48,428 root         INFO     Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 0.389431\n",
      "Reconstruction: 0.376366, Regularization: 0.013065\n",
      "2019-04-09 22:57:48,483 root         INFO     Train Epoch: 160 [2560/8000 (32%)]\tTotal Loss: 0.390802\n",
      "Reconstruction: 0.374440, Regularization: 0.016363\n",
      "2019-04-09 22:57:48,537 root         INFO     Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 0.354729\n",
      "Reconstruction: 0.340911, Regularization: 0.013818\n",
      "2019-04-09 22:57:48,592 root         INFO     Train Epoch: 160 [3584/8000 (45%)]\tTotal Loss: 0.332418\n",
      "Reconstruction: 0.320263, Regularization: 0.012155\n",
      "2019-04-09 22:57:48,647 root         INFO     Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 0.405818\n",
      "Reconstruction: 0.392406, Regularization: 0.013412\n",
      "2019-04-09 22:57:48,701 root         INFO     Train Epoch: 160 [4608/8000 (58%)]\tTotal Loss: 0.396272\n",
      "Reconstruction: 0.378092, Regularization: 0.018180\n",
      "2019-04-09 22:57:48,757 root         INFO     Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 0.323683\n",
      "Reconstruction: 0.309544, Regularization: 0.014139\n",
      "2019-04-09 22:57:48,813 root         INFO     Train Epoch: 160 [5632/8000 (70%)]\tTotal Loss: 0.357011\n",
      "Reconstruction: 0.342133, Regularization: 0.014878\n",
      "2019-04-09 22:57:48,869 root         INFO     Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 0.470481\n",
      "Reconstruction: 0.454495, Regularization: 0.015986\n",
      "2019-04-09 22:57:48,925 root         INFO     Train Epoch: 160 [6656/8000 (83%)]\tTotal Loss: 0.389492\n",
      "Reconstruction: 0.374101, Regularization: 0.015391\n",
      "2019-04-09 22:57:48,981 root         INFO     Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 0.374561\n",
      "Reconstruction: 0.360863, Regularization: 0.013698\n",
      "2019-04-09 22:57:49,037 root         INFO     Train Epoch: 160 [7680/8000 (96%)]\tTotal Loss: 0.379203\n",
      "Reconstruction: 0.363603, Regularization: 0.015600\n",
      "2019-04-09 22:57:49,087 root         INFO     ====> Epoch: 160 Average loss: 0.3925\n",
      "2019-04-09 22:57:49,110 root         INFO     Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 0.436109\n",
      "Reconstruction: 0.419066, Regularization: 0.017043\n",
      "2019-04-09 22:57:49,166 root         INFO     Train Epoch: 161 [512/8000 (6%)]\tTotal Loss: 0.306629\n",
      "Reconstruction: 0.292809, Regularization: 0.013820\n",
      "2019-04-09 22:57:49,223 root         INFO     Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 0.497679\n",
      "Reconstruction: 0.474888, Regularization: 0.022791\n",
      "2019-04-09 22:57:49,279 root         INFO     Train Epoch: 161 [1536/8000 (19%)]\tTotal Loss: 0.454623\n",
      "Reconstruction: 0.436940, Regularization: 0.017684\n",
      "2019-04-09 22:57:49,334 root         INFO     Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 0.395159\n",
      "Reconstruction: 0.375367, Regularization: 0.019791\n",
      "2019-04-09 22:57:49,390 root         INFO     Train Epoch: 161 [2560/8000 (32%)]\tTotal Loss: 0.344239\n",
      "Reconstruction: 0.326016, Regularization: 0.018223\n",
      "2019-04-09 22:57:49,445 root         INFO     Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 0.325573\n",
      "Reconstruction: 0.313880, Regularization: 0.011693\n",
      "2019-04-09 22:57:49,501 root         INFO     Train Epoch: 161 [3584/8000 (45%)]\tTotal Loss: 0.401435\n",
      "Reconstruction: 0.382953, Regularization: 0.018482\n",
      "2019-04-09 22:57:49,556 root         INFO     Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 0.452051\n",
      "Reconstruction: 0.436314, Regularization: 0.015738\n",
      "2019-04-09 22:57:49,612 root         INFO     Train Epoch: 161 [4608/8000 (58%)]\tTotal Loss: 0.341321\n",
      "Reconstruction: 0.328988, Regularization: 0.012333\n",
      "2019-04-09 22:57:49,667 root         INFO     Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 0.312206\n",
      "Reconstruction: 0.301777, Regularization: 0.010430\n",
      "2019-04-09 22:57:49,723 root         INFO     Train Epoch: 161 [5632/8000 (70%)]\tTotal Loss: 0.315636\n",
      "Reconstruction: 0.304102, Regularization: 0.011534\n",
      "2019-04-09 22:57:49,779 root         INFO     Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 0.362469\n",
      "Reconstruction: 0.348626, Regularization: 0.013843\n",
      "2019-04-09 22:57:49,835 root         INFO     Train Epoch: 161 [6656/8000 (83%)]\tTotal Loss: 0.448407\n",
      "Reconstruction: 0.432519, Regularization: 0.015887\n",
      "2019-04-09 22:57:49,891 root         INFO     Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 0.305880\n",
      "Reconstruction: 0.294948, Regularization: 0.010932\n",
      "2019-04-09 22:57:49,947 root         INFO     Train Epoch: 161 [7680/8000 (96%)]\tTotal Loss: 0.443468\n",
      "Reconstruction: 0.427734, Regularization: 0.015734\n",
      "2019-04-09 22:57:49,996 root         INFO     ====> Epoch: 161 Average loss: 0.3804\n",
      "2019-04-09 22:57:50,020 root         INFO     Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 0.382073\n",
      "Reconstruction: 0.368300, Regularization: 0.013773\n",
      "2019-04-09 22:57:50,077 root         INFO     Train Epoch: 162 [512/8000 (6%)]\tTotal Loss: 0.334797\n",
      "Reconstruction: 0.320210, Regularization: 0.014587\n",
      "2019-04-09 22:57:50,133 root         INFO     Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 0.351468\n",
      "Reconstruction: 0.339137, Regularization: 0.012331\n",
      "2019-04-09 22:57:50,189 root         INFO     Train Epoch: 162 [1536/8000 (19%)]\tTotal Loss: 0.335155\n",
      "Reconstruction: 0.319888, Regularization: 0.015267\n",
      "2019-04-09 22:57:50,244 root         INFO     Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 0.338912\n",
      "Reconstruction: 0.324300, Regularization: 0.014612\n",
      "2019-04-09 22:57:50,300 root         INFO     Train Epoch: 162 [2560/8000 (32%)]\tTotal Loss: 0.337592\n",
      "Reconstruction: 0.324124, Regularization: 0.013468\n",
      "2019-04-09 22:57:50,355 root         INFO     Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 0.412562\n",
      "Reconstruction: 0.399153, Regularization: 0.013409\n",
      "2019-04-09 22:57:50,410 root         INFO     Train Epoch: 162 [3584/8000 (45%)]\tTotal Loss: 0.354391\n",
      "Reconstruction: 0.334932, Regularization: 0.019460\n",
      "2019-04-09 22:57:50,466 root         INFO     Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 0.376624\n",
      "Reconstruction: 0.358292, Regularization: 0.018332\n",
      "2019-04-09 22:57:50,522 root         INFO     Train Epoch: 162 [4608/8000 (58%)]\tTotal Loss: 0.378447\n",
      "Reconstruction: 0.363742, Regularization: 0.014705\n",
      "2019-04-09 22:57:50,578 root         INFO     Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 0.406836\n",
      "Reconstruction: 0.391028, Regularization: 0.015807\n",
      "2019-04-09 22:57:50,633 root         INFO     Train Epoch: 162 [5632/8000 (70%)]\tTotal Loss: 0.384822\n",
      "Reconstruction: 0.370617, Regularization: 0.014206\n",
      "2019-04-09 22:57:50,689 root         INFO     Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 0.299318\n",
      "Reconstruction: 0.285609, Regularization: 0.013709\n",
      "2019-04-09 22:57:50,745 root         INFO     Train Epoch: 162 [6656/8000 (83%)]\tTotal Loss: 0.407619\n",
      "Reconstruction: 0.391100, Regularization: 0.016519\n",
      "2019-04-09 22:57:50,801 root         INFO     Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 0.470794\n",
      "Reconstruction: 0.454932, Regularization: 0.015862\n",
      "2019-04-09 22:57:50,857 root         INFO     Train Epoch: 162 [7680/8000 (96%)]\tTotal Loss: 0.482586\n",
      "Reconstruction: 0.464541, Regularization: 0.018045\n",
      "2019-04-09 22:57:50,907 root         INFO     ====> Epoch: 162 Average loss: 0.4216\n",
      "2019-04-09 22:57:50,931 root         INFO     Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 0.391687\n",
      "Reconstruction: 0.376562, Regularization: 0.015125\n",
      "2019-04-09 22:57:50,988 root         INFO     Train Epoch: 163 [512/8000 (6%)]\tTotal Loss: 0.300052\n",
      "Reconstruction: 0.286996, Regularization: 0.013055\n",
      "2019-04-09 22:57:51,042 root         INFO     Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 0.388473\n",
      "Reconstruction: 0.372886, Regularization: 0.015586\n",
      "2019-04-09 22:57:51,097 root         INFO     Train Epoch: 163 [1536/8000 (19%)]\tTotal Loss: 0.358317\n",
      "Reconstruction: 0.340918, Regularization: 0.017399\n",
      "2019-04-09 22:57:51,151 root         INFO     Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 0.340243\n",
      "Reconstruction: 0.328846, Regularization: 0.011397\n",
      "2019-04-09 22:57:51,206 root         INFO     Train Epoch: 163 [2560/8000 (32%)]\tTotal Loss: 0.341635\n",
      "Reconstruction: 0.326391, Regularization: 0.015244\n",
      "2019-04-09 22:57:51,260 root         INFO     Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 0.351863\n",
      "Reconstruction: 0.331767, Regularization: 0.020096\n",
      "2019-04-09 22:57:51,315 root         INFO     Train Epoch: 163 [3584/8000 (45%)]\tTotal Loss: 0.358332\n",
      "Reconstruction: 0.344208, Regularization: 0.014124\n",
      "2019-04-09 22:57:51,370 root         INFO     Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 0.417265\n",
      "Reconstruction: 0.389969, Regularization: 0.027297\n",
      "2019-04-09 22:57:51,424 root         INFO     Train Epoch: 163 [4608/8000 (58%)]\tTotal Loss: 0.394598\n",
      "Reconstruction: 0.370889, Regularization: 0.023709\n",
      "2019-04-09 22:57:51,479 root         INFO     Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 0.476269\n",
      "Reconstruction: 0.445782, Regularization: 0.030488\n",
      "2019-04-09 22:57:51,534 root         INFO     Train Epoch: 163 [5632/8000 (70%)]\tTotal Loss: 0.308002\n",
      "Reconstruction: 0.294642, Regularization: 0.013360\n",
      "2019-04-09 22:57:51,589 root         INFO     Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 0.349676\n",
      "Reconstruction: 0.336639, Regularization: 0.013036\n",
      "2019-04-09 22:57:51,644 root         INFO     Train Epoch: 163 [6656/8000 (83%)]\tTotal Loss: 0.448100\n",
      "Reconstruction: 0.431168, Regularization: 0.016932\n",
      "2019-04-09 22:57:51,698 root         INFO     Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 0.292091\n",
      "Reconstruction: 0.277019, Regularization: 0.015072\n",
      "2019-04-09 22:57:51,753 root         INFO     Train Epoch: 163 [7680/8000 (96%)]\tTotal Loss: 0.445698\n",
      "Reconstruction: 0.423215, Regularization: 0.022483\n",
      "2019-04-09 22:57:51,803 root         INFO     ====> Epoch: 163 Average loss: 0.3925\n",
      "2019-04-09 22:57:51,826 root         INFO     Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 0.296599\n",
      "Reconstruction: 0.278111, Regularization: 0.018488\n",
      "2019-04-09 22:57:51,882 root         INFO     Train Epoch: 164 [512/8000 (6%)]\tTotal Loss: 0.395243\n",
      "Reconstruction: 0.381744, Regularization: 0.013499\n",
      "2019-04-09 22:57:51,939 root         INFO     Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 0.499731\n",
      "Reconstruction: 0.466166, Regularization: 0.033565\n",
      "2019-04-09 22:57:51,995 root         INFO     Train Epoch: 164 [1536/8000 (19%)]\tTotal Loss: 0.412705\n",
      "Reconstruction: 0.395648, Regularization: 0.017057\n",
      "2019-04-09 22:57:52,051 root         INFO     Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 0.295297\n",
      "Reconstruction: 0.281069, Regularization: 0.014229\n",
      "2019-04-09 22:57:52,107 root         INFO     Train Epoch: 164 [2560/8000 (32%)]\tTotal Loss: 0.347023\n",
      "Reconstruction: 0.309982, Regularization: 0.037041\n",
      "2019-04-09 22:57:52,163 root         INFO     Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 0.433899\n",
      "Reconstruction: 0.417208, Regularization: 0.016692\n",
      "2019-04-09 22:57:52,219 root         INFO     Train Epoch: 164 [3584/8000 (45%)]\tTotal Loss: 0.407466\n",
      "Reconstruction: 0.386872, Regularization: 0.020593\n",
      "2019-04-09 22:57:52,274 root         INFO     Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 0.353385\n",
      "Reconstruction: 0.338982, Regularization: 0.014403\n",
      "2019-04-09 22:57:52,330 root         INFO     Train Epoch: 164 [4608/8000 (58%)]\tTotal Loss: 0.329500\n",
      "Reconstruction: 0.309973, Regularization: 0.019527\n",
      "2019-04-09 22:57:52,386 root         INFO     Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 0.383243\n",
      "Reconstruction: 0.366361, Regularization: 0.016882\n",
      "2019-04-09 22:57:52,441 root         INFO     Train Epoch: 164 [5632/8000 (70%)]\tTotal Loss: 0.332875\n",
      "Reconstruction: 0.321310, Regularization: 0.011565\n",
      "2019-04-09 22:57:52,497 root         INFO     Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 0.375017\n",
      "Reconstruction: 0.360727, Regularization: 0.014290\n",
      "2019-04-09 22:57:52,552 root         INFO     Train Epoch: 164 [6656/8000 (83%)]\tTotal Loss: 0.327122\n",
      "Reconstruction: 0.307727, Regularization: 0.019394\n",
      "2019-04-09 22:57:52,607 root         INFO     Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 0.375655\n",
      "Reconstruction: 0.356653, Regularization: 0.019002\n",
      "2019-04-09 22:57:52,662 root         INFO     Train Epoch: 164 [7680/8000 (96%)]\tTotal Loss: 0.379999\n",
      "Reconstruction: 0.357210, Regularization: 0.022789\n",
      "2019-04-09 22:57:52,713 root         INFO     ====> Epoch: 164 Average loss: 0.3821\n",
      "2019-04-09 22:57:52,736 root         INFO     Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 0.336512\n",
      "Reconstruction: 0.321867, Regularization: 0.014645\n",
      "2019-04-09 22:57:52,793 root         INFO     Train Epoch: 165 [512/8000 (6%)]\tTotal Loss: 0.414173\n",
      "Reconstruction: 0.400067, Regularization: 0.014106\n",
      "2019-04-09 22:57:52,849 root         INFO     Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 0.459960\n",
      "Reconstruction: 0.427852, Regularization: 0.032108\n",
      "2019-04-09 22:57:52,905 root         INFO     Train Epoch: 165 [1536/8000 (19%)]\tTotal Loss: 0.401107\n",
      "Reconstruction: 0.385996, Regularization: 0.015111\n",
      "2019-04-09 22:57:52,961 root         INFO     Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 0.354535\n",
      "Reconstruction: 0.342219, Regularization: 0.012316\n",
      "2019-04-09 22:57:53,017 root         INFO     Train Epoch: 165 [2560/8000 (32%)]\tTotal Loss: 0.414037\n",
      "Reconstruction: 0.400482, Regularization: 0.013556\n",
      "2019-04-09 22:57:53,073 root         INFO     Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 0.476824\n",
      "Reconstruction: 0.452929, Regularization: 0.023895\n",
      "2019-04-09 22:57:53,129 root         INFO     Train Epoch: 165 [3584/8000 (45%)]\tTotal Loss: 0.467358\n",
      "Reconstruction: 0.448385, Regularization: 0.018972\n",
      "2019-04-09 22:57:53,184 root         INFO     Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 0.317690\n",
      "Reconstruction: 0.298477, Regularization: 0.019213\n",
      "2019-04-09 22:57:53,240 root         INFO     Train Epoch: 165 [4608/8000 (58%)]\tTotal Loss: 0.372405\n",
      "Reconstruction: 0.355902, Regularization: 0.016503\n",
      "2019-04-09 22:57:53,295 root         INFO     Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 0.464565\n",
      "Reconstruction: 0.441932, Regularization: 0.022633\n",
      "2019-04-09 22:57:53,351 root         INFO     Train Epoch: 165 [5632/8000 (70%)]\tTotal Loss: 0.395570\n",
      "Reconstruction: 0.381275, Regularization: 0.014295\n",
      "2019-04-09 22:57:53,406 root         INFO     Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 0.432151\n",
      "Reconstruction: 0.419043, Regularization: 0.013109\n",
      "2019-04-09 22:57:53,462 root         INFO     Train Epoch: 165 [6656/8000 (83%)]\tTotal Loss: 0.415590\n",
      "Reconstruction: 0.400711, Regularization: 0.014879\n",
      "2019-04-09 22:57:53,518 root         INFO     Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 0.343743\n",
      "Reconstruction: 0.330097, Regularization: 0.013646\n",
      "2019-04-09 22:57:53,573 root         INFO     Train Epoch: 165 [7680/8000 (96%)]\tTotal Loss: 0.335768\n",
      "Reconstruction: 0.305707, Regularization: 0.030061\n",
      "2019-04-09 22:57:53,622 root         INFO     ====> Epoch: 165 Average loss: 0.3843\n",
      "2019-04-09 22:57:53,646 root         INFO     Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 0.324242\n",
      "Reconstruction: 0.312711, Regularization: 0.011531\n",
      "2019-04-09 22:57:53,702 root         INFO     Train Epoch: 166 [512/8000 (6%)]\tTotal Loss: 0.360769\n",
      "Reconstruction: 0.346596, Regularization: 0.014173\n",
      "2019-04-09 22:57:53,759 root         INFO     Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 0.383599\n",
      "Reconstruction: 0.365459, Regularization: 0.018140\n",
      "2019-04-09 22:57:53,816 root         INFO     Train Epoch: 166 [1536/8000 (19%)]\tTotal Loss: 0.375443\n",
      "Reconstruction: 0.355302, Regularization: 0.020141\n",
      "2019-04-09 22:57:53,872 root         INFO     Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 0.346226\n",
      "Reconstruction: 0.331520, Regularization: 0.014706\n",
      "2019-04-09 22:57:53,929 root         INFO     Train Epoch: 166 [2560/8000 (32%)]\tTotal Loss: 0.416727\n",
      "Reconstruction: 0.397518, Regularization: 0.019209\n",
      "2019-04-09 22:57:53,985 root         INFO     Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 0.614009\n",
      "Reconstruction: 0.593141, Regularization: 0.020868\n",
      "2019-04-09 22:57:54,041 root         INFO     Train Epoch: 166 [3584/8000 (45%)]\tTotal Loss: 0.401288\n",
      "Reconstruction: 0.386645, Regularization: 0.014643\n",
      "2019-04-09 22:57:54,098 root         INFO     Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 0.372713\n",
      "Reconstruction: 0.359461, Regularization: 0.013252\n",
      "2019-04-09 22:57:54,155 root         INFO     Train Epoch: 166 [4608/8000 (58%)]\tTotal Loss: 0.303251\n",
      "Reconstruction: 0.287364, Regularization: 0.015887\n",
      "2019-04-09 22:57:54,211 root         INFO     Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 0.429973\n",
      "Reconstruction: 0.414584, Regularization: 0.015389\n",
      "2019-04-09 22:57:54,268 root         INFO     Train Epoch: 166 [5632/8000 (70%)]\tTotal Loss: 0.347964\n",
      "Reconstruction: 0.330012, Regularization: 0.017953\n",
      "2019-04-09 22:57:54,325 root         INFO     Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 0.417288\n",
      "Reconstruction: 0.401556, Regularization: 0.015732\n",
      "2019-04-09 22:57:54,381 root         INFO     Train Epoch: 166 [6656/8000 (83%)]\tTotal Loss: 0.405934\n",
      "Reconstruction: 0.389837, Regularization: 0.016097\n",
      "2019-04-09 22:57:54,437 root         INFO     Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 0.319237\n",
      "Reconstruction: 0.306699, Regularization: 0.012537\n",
      "2019-04-09 22:57:54,494 root         INFO     Train Epoch: 166 [7680/8000 (96%)]\tTotal Loss: 0.403332\n",
      "Reconstruction: 0.381650, Regularization: 0.021682\n",
      "2019-04-09 22:57:54,544 root         INFO     ====> Epoch: 166 Average loss: 0.3903\n",
      "2019-04-09 22:57:54,567 root         INFO     Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 0.320560\n",
      "Reconstruction: 0.306109, Regularization: 0.014451\n",
      "2019-04-09 22:57:54,624 root         INFO     Train Epoch: 167 [512/8000 (6%)]\tTotal Loss: 0.400461\n",
      "Reconstruction: 0.384025, Regularization: 0.016435\n",
      "2019-04-09 22:57:54,679 root         INFO     Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 0.334693\n",
      "Reconstruction: 0.319060, Regularization: 0.015634\n",
      "2019-04-09 22:57:54,734 root         INFO     Train Epoch: 167 [1536/8000 (19%)]\tTotal Loss: 0.464732\n",
      "Reconstruction: 0.444939, Regularization: 0.019793\n",
      "2019-04-09 22:57:54,790 root         INFO     Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 0.389187\n",
      "Reconstruction: 0.372458, Regularization: 0.016729\n",
      "2019-04-09 22:57:54,845 root         INFO     Train Epoch: 167 [2560/8000 (32%)]\tTotal Loss: 0.281077\n",
      "Reconstruction: 0.264731, Regularization: 0.016346\n",
      "2019-04-09 22:57:54,901 root         INFO     Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 0.385597\n",
      "Reconstruction: 0.372357, Regularization: 0.013240\n",
      "2019-04-09 22:57:54,956 root         INFO     Train Epoch: 167 [3584/8000 (45%)]\tTotal Loss: 0.369161\n",
      "Reconstruction: 0.356759, Regularization: 0.012402\n",
      "2019-04-09 22:57:55,011 root         INFO     Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 0.255884\n",
      "Reconstruction: 0.236568, Regularization: 0.019316\n",
      "2019-04-09 22:57:55,067 root         INFO     Train Epoch: 167 [4608/8000 (58%)]\tTotal Loss: 0.428875\n",
      "Reconstruction: 0.411251, Regularization: 0.017624\n",
      "2019-04-09 22:57:55,122 root         INFO     Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 0.425325\n",
      "Reconstruction: 0.410016, Regularization: 0.015309\n",
      "2019-04-09 22:57:55,177 root         INFO     Train Epoch: 167 [5632/8000 (70%)]\tTotal Loss: 0.411840\n",
      "Reconstruction: 0.388712, Regularization: 0.023128\n",
      "2019-04-09 22:57:55,233 root         INFO     Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 0.359915\n",
      "Reconstruction: 0.339419, Regularization: 0.020496\n",
      "2019-04-09 22:57:55,288 root         INFO     Train Epoch: 167 [6656/8000 (83%)]\tTotal Loss: 0.424216\n",
      "Reconstruction: 0.406435, Regularization: 0.017781\n",
      "2019-04-09 22:57:55,344 root         INFO     Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 0.429367\n",
      "Reconstruction: 0.413339, Regularization: 0.016028\n",
      "2019-04-09 22:57:55,399 root         INFO     Train Epoch: 167 [7680/8000 (96%)]\tTotal Loss: 0.408580\n",
      "Reconstruction: 0.390112, Regularization: 0.018469\n",
      "2019-04-09 22:57:55,448 root         INFO     ====> Epoch: 167 Average loss: 0.5325\n",
      "2019-04-09 22:57:55,471 root         INFO     Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 0.347438\n",
      "Reconstruction: 0.324561, Regularization: 0.022878\n",
      "2019-04-09 22:57:55,528 root         INFO     Train Epoch: 168 [512/8000 (6%)]\tTotal Loss: 0.318913\n",
      "Reconstruction: 0.305722, Regularization: 0.013191\n",
      "2019-04-09 22:57:55,584 root         INFO     Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 0.466598\n",
      "Reconstruction: 0.453744, Regularization: 0.012854\n",
      "2019-04-09 22:57:55,641 root         INFO     Train Epoch: 168 [1536/8000 (19%)]\tTotal Loss: 0.419571\n",
      "Reconstruction: 0.399252, Regularization: 0.020319\n",
      "2019-04-09 22:57:55,697 root         INFO     Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 0.276257\n",
      "Reconstruction: 0.256048, Regularization: 0.020209\n",
      "2019-04-09 22:57:55,753 root         INFO     Train Epoch: 168 [2560/8000 (32%)]\tTotal Loss: 0.356899\n",
      "Reconstruction: 0.343001, Regularization: 0.013898\n",
      "2019-04-09 22:57:55,809 root         INFO     Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 0.344862\n",
      "Reconstruction: 0.328672, Regularization: 0.016190\n",
      "2019-04-09 22:57:55,864 root         INFO     Train Epoch: 168 [3584/8000 (45%)]\tTotal Loss: 0.448919\n",
      "Reconstruction: 0.429008, Regularization: 0.019911\n",
      "2019-04-09 22:57:55,920 root         INFO     Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 0.483450\n",
      "Reconstruction: 0.464393, Regularization: 0.019057\n",
      "2019-04-09 22:57:55,976 root         INFO     Train Epoch: 168 [4608/8000 (58%)]\tTotal Loss: 0.287098\n",
      "Reconstruction: 0.269646, Regularization: 0.017453\n",
      "2019-04-09 22:57:56,031 root         INFO     Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 0.389163\n",
      "Reconstruction: 0.370943, Regularization: 0.018220\n",
      "2019-04-09 22:57:56,086 root         INFO     Train Epoch: 168 [5632/8000 (70%)]\tTotal Loss: 0.464476\n",
      "Reconstruction: 0.446146, Regularization: 0.018329\n",
      "2019-04-09 22:57:56,141 root         INFO     Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 0.394378\n",
      "Reconstruction: 0.373575, Regularization: 0.020803\n",
      "2019-04-09 22:57:56,195 root         INFO     Train Epoch: 168 [6656/8000 (83%)]\tTotal Loss: 0.541185\n",
      "Reconstruction: 0.521621, Regularization: 0.019565\n",
      "2019-04-09 22:57:56,249 root         INFO     Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 0.447780\n",
      "Reconstruction: 0.431549, Regularization: 0.016231\n",
      "2019-04-09 22:57:56,303 root         INFO     Train Epoch: 168 [7680/8000 (96%)]\tTotal Loss: 0.330159\n",
      "Reconstruction: 0.317226, Regularization: 0.012934\n",
      "2019-04-09 22:57:56,352 root         INFO     ====> Epoch: 168 Average loss: 0.3832\n",
      "2019-04-09 22:57:56,375 root         INFO     Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 0.362271\n",
      "Reconstruction: 0.348926, Regularization: 0.013346\n",
      "2019-04-09 22:57:56,431 root         INFO     Train Epoch: 169 [512/8000 (6%)]\tTotal Loss: 0.278874\n",
      "Reconstruction: 0.266730, Regularization: 0.012145\n",
      "2019-04-09 22:57:56,488 root         INFO     Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 0.407877\n",
      "Reconstruction: 0.391007, Regularization: 0.016870\n",
      "2019-04-09 22:57:56,544 root         INFO     Train Epoch: 169 [1536/8000 (19%)]\tTotal Loss: 0.293354\n",
      "Reconstruction: 0.281495, Regularization: 0.011859\n",
      "2019-04-09 22:57:56,601 root         INFO     Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 0.358792\n",
      "Reconstruction: 0.345505, Regularization: 0.013288\n",
      "2019-04-09 22:57:56,657 root         INFO     Train Epoch: 169 [2560/8000 (32%)]\tTotal Loss: 0.412176\n",
      "Reconstruction: 0.396234, Regularization: 0.015942\n",
      "2019-04-09 22:57:56,714 root         INFO     Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 0.308631\n",
      "Reconstruction: 0.292884, Regularization: 0.015747\n",
      "2019-04-09 22:57:56,771 root         INFO     Train Epoch: 169 [3584/8000 (45%)]\tTotal Loss: 0.349660\n",
      "Reconstruction: 0.336356, Regularization: 0.013304\n",
      "2019-04-09 22:57:56,828 root         INFO     Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 0.385236\n",
      "Reconstruction: 0.370364, Regularization: 0.014873\n",
      "2019-04-09 22:57:56,885 root         INFO     Train Epoch: 169 [4608/8000 (58%)]\tTotal Loss: 0.491380\n",
      "Reconstruction: 0.475422, Regularization: 0.015958\n",
      "2019-04-09 22:57:56,942 root         INFO     Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 0.430394\n",
      "Reconstruction: 0.411367, Regularization: 0.019027\n",
      "2019-04-09 22:57:56,999 root         INFO     Train Epoch: 169 [5632/8000 (70%)]\tTotal Loss: 0.363010\n",
      "Reconstruction: 0.336296, Regularization: 0.026713\n",
      "2019-04-09 22:57:57,056 root         INFO     Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 0.479723\n",
      "Reconstruction: 0.460523, Regularization: 0.019200\n",
      "2019-04-09 22:57:57,111 root         INFO     Train Epoch: 169 [6656/8000 (83%)]\tTotal Loss: 0.375015\n",
      "Reconstruction: 0.358457, Regularization: 0.016558\n",
      "2019-04-09 22:57:57,165 root         INFO     Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 0.326641\n",
      "Reconstruction: 0.313115, Regularization: 0.013526\n",
      "2019-04-09 22:57:57,220 root         INFO     Train Epoch: 169 [7680/8000 (96%)]\tTotal Loss: 0.354030\n",
      "Reconstruction: 0.338940, Regularization: 0.015090\n",
      "2019-04-09 22:57:57,269 root         INFO     ====> Epoch: 169 Average loss: 0.3833\n",
      "2019-04-09 22:57:57,293 root         INFO     Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 0.424611\n",
      "Reconstruction: 0.410601, Regularization: 0.014010\n",
      "2019-04-09 22:57:57,349 root         INFO     Train Epoch: 170 [512/8000 (6%)]\tTotal Loss: 0.319082\n",
      "Reconstruction: 0.303088, Regularization: 0.015994\n",
      "2019-04-09 22:57:57,405 root         INFO     Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 0.323677\n",
      "Reconstruction: 0.306402, Regularization: 0.017275\n",
      "2019-04-09 22:57:57,462 root         INFO     Train Epoch: 170 [1536/8000 (19%)]\tTotal Loss: 0.350414\n",
      "Reconstruction: 0.336837, Regularization: 0.013577\n",
      "2019-04-09 22:57:57,518 root         INFO     Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 0.421849\n",
      "Reconstruction: 0.391029, Regularization: 0.030820\n",
      "2019-04-09 22:57:57,572 root         INFO     Train Epoch: 170 [2560/8000 (32%)]\tTotal Loss: 0.323348\n",
      "Reconstruction: 0.311658, Regularization: 0.011690\n",
      "2019-04-09 22:57:57,626 root         INFO     Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 0.417215\n",
      "Reconstruction: 0.402646, Regularization: 0.014569\n",
      "2019-04-09 22:57:57,681 root         INFO     Train Epoch: 170 [3584/8000 (45%)]\tTotal Loss: 0.243803\n",
      "Reconstruction: 0.228726, Regularization: 0.015077\n",
      "2019-04-09 22:57:57,736 root         INFO     Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 0.357852\n",
      "Reconstruction: 0.343529, Regularization: 0.014323\n",
      "2019-04-09 22:57:57,791 root         INFO     Train Epoch: 170 [4608/8000 (58%)]\tTotal Loss: 0.357061\n",
      "Reconstruction: 0.343206, Regularization: 0.013856\n",
      "2019-04-09 22:57:57,846 root         INFO     Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 0.443097\n",
      "Reconstruction: 0.421609, Regularization: 0.021488\n",
      "2019-04-09 22:57:57,902 root         INFO     Train Epoch: 170 [5632/8000 (70%)]\tTotal Loss: 0.360800\n",
      "Reconstruction: 0.347871, Regularization: 0.012930\n",
      "2019-04-09 22:57:57,958 root         INFO     Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 0.398636\n",
      "Reconstruction: 0.374807, Regularization: 0.023829\n",
      "2019-04-09 22:57:58,014 root         INFO     Train Epoch: 170 [6656/8000 (83%)]\tTotal Loss: 0.404189\n",
      "Reconstruction: 0.388033, Regularization: 0.016155\n",
      "2019-04-09 22:57:58,070 root         INFO     Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 0.312953\n",
      "Reconstruction: 0.299345, Regularization: 0.013608\n",
      "2019-04-09 22:57:58,127 root         INFO     Train Epoch: 170 [7680/8000 (96%)]\tTotal Loss: 0.422425\n",
      "Reconstruction: 0.399197, Regularization: 0.023228\n",
      "2019-04-09 22:57:58,177 root         INFO     ====> Epoch: 170 Average loss: 0.3727\n",
      "2019-04-09 22:57:58,200 root         INFO     Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 0.341565\n",
      "Reconstruction: 0.323660, Regularization: 0.017906\n",
      "2019-04-09 22:57:58,257 root         INFO     Train Epoch: 171 [512/8000 (6%)]\tTotal Loss: 0.345914\n",
      "Reconstruction: 0.331547, Regularization: 0.014366\n",
      "2019-04-09 22:57:58,313 root         INFO     Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 0.331460\n",
      "Reconstruction: 0.318792, Regularization: 0.012668\n",
      "2019-04-09 22:57:58,370 root         INFO     Train Epoch: 171 [1536/8000 (19%)]\tTotal Loss: 0.297083\n",
      "Reconstruction: 0.274106, Regularization: 0.022977\n",
      "2019-04-09 22:57:58,427 root         INFO     Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 0.378334\n",
      "Reconstruction: 0.363899, Regularization: 0.014435\n",
      "2019-04-09 22:57:58,484 root         INFO     Train Epoch: 171 [2560/8000 (32%)]\tTotal Loss: 0.401246\n",
      "Reconstruction: 0.383632, Regularization: 0.017614\n",
      "2019-04-09 22:57:58,540 root         INFO     Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 0.473643\n",
      "Reconstruction: 0.452166, Regularization: 0.021477\n",
      "2019-04-09 22:57:58,597 root         INFO     Train Epoch: 171 [3584/8000 (45%)]\tTotal Loss: 0.414699\n",
      "Reconstruction: 0.391293, Regularization: 0.023406\n",
      "2019-04-09 22:57:58,654 root         INFO     Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 0.389251\n",
      "Reconstruction: 0.366034, Regularization: 0.023217\n",
      "2019-04-09 22:57:58,710 root         INFO     Train Epoch: 171 [4608/8000 (58%)]\tTotal Loss: 0.356203\n",
      "Reconstruction: 0.341134, Regularization: 0.015068\n",
      "2019-04-09 22:57:58,767 root         INFO     Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 0.416027\n",
      "Reconstruction: 0.399284, Regularization: 0.016743\n",
      "2019-04-09 22:57:58,824 root         INFO     Train Epoch: 171 [5632/8000 (70%)]\tTotal Loss: 0.490475\n",
      "Reconstruction: 0.473187, Regularization: 0.017288\n",
      "2019-04-09 22:57:58,881 root         INFO     Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 0.404316\n",
      "Reconstruction: 0.383032, Regularization: 0.021285\n",
      "2019-04-09 22:57:58,937 root         INFO     Train Epoch: 171 [6656/8000 (83%)]\tTotal Loss: 0.307743\n",
      "Reconstruction: 0.289735, Regularization: 0.018008\n",
      "2019-04-09 22:57:58,994 root         INFO     Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 0.346846\n",
      "Reconstruction: 0.328811, Regularization: 0.018035\n",
      "2019-04-09 22:57:59,050 root         INFO     Train Epoch: 171 [7680/8000 (96%)]\tTotal Loss: 0.364215\n",
      "Reconstruction: 0.350011, Regularization: 0.014205\n",
      "2019-04-09 22:57:59,099 root         INFO     ====> Epoch: 171 Average loss: 0.4082\n",
      "2019-04-09 22:57:59,122 root         INFO     Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 0.399607\n",
      "Reconstruction: 0.384009, Regularization: 0.015599\n",
      "2019-04-09 22:57:59,179 root         INFO     Train Epoch: 172 [512/8000 (6%)]\tTotal Loss: 0.264391\n",
      "Reconstruction: 0.251756, Regularization: 0.012635\n",
      "2019-04-09 22:57:59,235 root         INFO     Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 0.330869\n",
      "Reconstruction: 0.318124, Regularization: 0.012745\n",
      "2019-04-09 22:57:59,291 root         INFO     Train Epoch: 172 [1536/8000 (19%)]\tTotal Loss: 0.414573\n",
      "Reconstruction: 0.394745, Regularization: 0.019828\n",
      "2019-04-09 22:57:59,348 root         INFO     Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 0.473575\n",
      "Reconstruction: 0.451147, Regularization: 0.022427\n",
      "2019-04-09 22:57:59,404 root         INFO     Train Epoch: 172 [2560/8000 (32%)]\tTotal Loss: 0.363272\n",
      "Reconstruction: 0.348379, Regularization: 0.014892\n",
      "2019-04-09 22:57:59,459 root         INFO     Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 0.432756\n",
      "Reconstruction: 0.421874, Regularization: 0.010883\n",
      "2019-04-09 22:57:59,515 root         INFO     Train Epoch: 172 [3584/8000 (45%)]\tTotal Loss: 0.378875\n",
      "Reconstruction: 0.364581, Regularization: 0.014294\n",
      "2019-04-09 22:57:59,570 root         INFO     Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 0.324551\n",
      "Reconstruction: 0.311415, Regularization: 0.013135\n",
      "2019-04-09 22:57:59,626 root         INFO     Train Epoch: 172 [4608/8000 (58%)]\tTotal Loss: 0.348969\n",
      "Reconstruction: 0.330820, Regularization: 0.018149\n",
      "2019-04-09 22:57:59,681 root         INFO     Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 0.389628\n",
      "Reconstruction: 0.374931, Regularization: 0.014696\n",
      "2019-04-09 22:57:59,737 root         INFO     Train Epoch: 172 [5632/8000 (70%)]\tTotal Loss: 0.381661\n",
      "Reconstruction: 0.367395, Regularization: 0.014266\n",
      "2019-04-09 22:57:59,792 root         INFO     Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 0.457705\n",
      "Reconstruction: 0.440222, Regularization: 0.017483\n",
      "2019-04-09 22:57:59,847 root         INFO     Train Epoch: 172 [6656/8000 (83%)]\tTotal Loss: 0.417519\n",
      "Reconstruction: 0.399189, Regularization: 0.018330\n",
      "2019-04-09 22:57:59,903 root         INFO     Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 0.420411\n",
      "Reconstruction: 0.403526, Regularization: 0.016885\n",
      "2019-04-09 22:57:59,958 root         INFO     Train Epoch: 172 [7680/8000 (96%)]\tTotal Loss: 0.413941\n",
      "Reconstruction: 0.381415, Regularization: 0.032525\n",
      "2019-04-09 22:58:00,009 root         INFO     ====> Epoch: 172 Average loss: 0.3809\n",
      "2019-04-09 22:58:00,032 root         INFO     Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 0.301220\n",
      "Reconstruction: 0.287535, Regularization: 0.013686\n",
      "2019-04-09 22:58:00,089 root         INFO     Train Epoch: 173 [512/8000 (6%)]\tTotal Loss: 0.319370\n",
      "Reconstruction: 0.307741, Regularization: 0.011629\n",
      "2019-04-09 22:58:00,146 root         INFO     Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 0.466301\n",
      "Reconstruction: 0.448608, Regularization: 0.017693\n",
      "2019-04-09 22:58:00,202 root         INFO     Train Epoch: 173 [1536/8000 (19%)]\tTotal Loss: 0.304922\n",
      "Reconstruction: 0.293025, Regularization: 0.011897\n",
      "2019-04-09 22:58:00,258 root         INFO     Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 0.331922\n",
      "Reconstruction: 0.317246, Regularization: 0.014676\n",
      "2019-04-09 22:58:00,314 root         INFO     Train Epoch: 173 [2560/8000 (32%)]\tTotal Loss: 0.411055\n",
      "Reconstruction: 0.387263, Regularization: 0.023791\n",
      "2019-04-09 22:58:00,370 root         INFO     Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 0.341278\n",
      "Reconstruction: 0.326487, Regularization: 0.014791\n",
      "2019-04-09 22:58:00,426 root         INFO     Train Epoch: 173 [3584/8000 (45%)]\tTotal Loss: 0.421397\n",
      "Reconstruction: 0.405303, Regularization: 0.016094\n",
      "2019-04-09 22:58:00,482 root         INFO     Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 0.422609\n",
      "Reconstruction: 0.405197, Regularization: 0.017412\n",
      "2019-04-09 22:58:00,538 root         INFO     Train Epoch: 173 [4608/8000 (58%)]\tTotal Loss: 0.319014\n",
      "Reconstruction: 0.300531, Regularization: 0.018483\n",
      "2019-04-09 22:58:00,594 root         INFO     Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 0.386020\n",
      "Reconstruction: 0.372997, Regularization: 0.013023\n",
      "2019-04-09 22:58:00,650 root         INFO     Train Epoch: 173 [5632/8000 (70%)]\tTotal Loss: 0.420509\n",
      "Reconstruction: 0.405773, Regularization: 0.014736\n",
      "2019-04-09 22:58:00,706 root         INFO     Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 0.317791\n",
      "Reconstruction: 0.301619, Regularization: 0.016172\n",
      "2019-04-09 22:58:00,762 root         INFO     Train Epoch: 173 [6656/8000 (83%)]\tTotal Loss: 0.320034\n",
      "Reconstruction: 0.307384, Regularization: 0.012650\n",
      "2019-04-09 22:58:00,818 root         INFO     Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 0.371755\n",
      "Reconstruction: 0.358085, Regularization: 0.013670\n",
      "2019-04-09 22:58:00,874 root         INFO     Train Epoch: 173 [7680/8000 (96%)]\tTotal Loss: 0.332580\n",
      "Reconstruction: 0.315192, Regularization: 0.017389\n",
      "2019-04-09 22:58:00,923 root         INFO     ====> Epoch: 173 Average loss: 0.3961\n",
      "2019-04-09 22:58:00,947 root         INFO     Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 0.345883\n",
      "Reconstruction: 0.330753, Regularization: 0.015130\n",
      "2019-04-09 22:58:01,004 root         INFO     Train Epoch: 174 [512/8000 (6%)]\tTotal Loss: 0.448754\n",
      "Reconstruction: 0.426750, Regularization: 0.022004\n",
      "2019-04-09 22:58:01,060 root         INFO     Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 0.368450\n",
      "Reconstruction: 0.352820, Regularization: 0.015630\n",
      "2019-04-09 22:58:01,117 root         INFO     Train Epoch: 174 [1536/8000 (19%)]\tTotal Loss: 0.387605\n",
      "Reconstruction: 0.371513, Regularization: 0.016092\n",
      "2019-04-09 22:58:01,173 root         INFO     Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 0.367374\n",
      "Reconstruction: 0.353298, Regularization: 0.014076\n",
      "2019-04-09 22:58:01,230 root         INFO     Train Epoch: 174 [2560/8000 (32%)]\tTotal Loss: 0.318208\n",
      "Reconstruction: 0.304046, Regularization: 0.014162\n",
      "2019-04-09 22:58:01,287 root         INFO     Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 0.390232\n",
      "Reconstruction: 0.372577, Regularization: 0.017655\n",
      "2019-04-09 22:58:01,343 root         INFO     Train Epoch: 174 [3584/8000 (45%)]\tTotal Loss: 0.293743\n",
      "Reconstruction: 0.280467, Regularization: 0.013276\n",
      "2019-04-09 22:58:01,400 root         INFO     Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 0.330867\n",
      "Reconstruction: 0.316810, Regularization: 0.014057\n",
      "2019-04-09 22:58:01,456 root         INFO     Train Epoch: 174 [4608/8000 (58%)]\tTotal Loss: 0.329561\n",
      "Reconstruction: 0.315823, Regularization: 0.013738\n",
      "2019-04-09 22:58:01,513 root         INFO     Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 0.449959\n",
      "Reconstruction: 0.429531, Regularization: 0.020428\n",
      "2019-04-09 22:58:01,569 root         INFO     Train Epoch: 174 [5632/8000 (70%)]\tTotal Loss: 0.353607\n",
      "Reconstruction: 0.335066, Regularization: 0.018541\n",
      "2019-04-09 22:58:01,625 root         INFO     Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 0.368886\n",
      "Reconstruction: 0.347755, Regularization: 0.021131\n",
      "2019-04-09 22:58:01,680 root         INFO     Train Epoch: 174 [6656/8000 (83%)]\tTotal Loss: 0.337043\n",
      "Reconstruction: 0.320039, Regularization: 0.017004\n",
      "2019-04-09 22:58:01,736 root         INFO     Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 0.320034\n",
      "Reconstruction: 0.303987, Regularization: 0.016047\n",
      "2019-04-09 22:58:01,791 root         INFO     Train Epoch: 174 [7680/8000 (96%)]\tTotal Loss: 0.348791\n",
      "Reconstruction: 0.325434, Regularization: 0.023357\n",
      "2019-04-09 22:58:01,840 root         INFO     ====> Epoch: 174 Average loss: 0.3837\n",
      "2019-04-09 22:58:01,864 root         INFO     Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 0.365977\n",
      "Reconstruction: 0.347685, Regularization: 0.018292\n",
      "2019-04-09 22:58:01,921 root         INFO     Train Epoch: 175 [512/8000 (6%)]\tTotal Loss: 0.366077\n",
      "Reconstruction: 0.352156, Regularization: 0.013922\n",
      "2019-04-09 22:58:01,977 root         INFO     Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 0.440851\n",
      "Reconstruction: 0.426670, Regularization: 0.014181\n",
      "2019-04-09 22:58:02,034 root         INFO     Train Epoch: 175 [1536/8000 (19%)]\tTotal Loss: 0.377453\n",
      "Reconstruction: 0.363806, Regularization: 0.013647\n",
      "2019-04-09 22:58:02,091 root         INFO     Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 0.337214\n",
      "Reconstruction: 0.319275, Regularization: 0.017939\n",
      "2019-04-09 22:58:02,147 root         INFO     Train Epoch: 175 [2560/8000 (32%)]\tTotal Loss: 0.441943\n",
      "Reconstruction: 0.423963, Regularization: 0.017979\n",
      "2019-04-09 22:58:02,204 root         INFO     Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 0.368804\n",
      "Reconstruction: 0.352067, Regularization: 0.016737\n",
      "2019-04-09 22:58:02,261 root         INFO     Train Epoch: 175 [3584/8000 (45%)]\tTotal Loss: 0.339573\n",
      "Reconstruction: 0.321301, Regularization: 0.018272\n",
      "2019-04-09 22:58:02,317 root         INFO     Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 0.373128\n",
      "Reconstruction: 0.360036, Regularization: 0.013093\n",
      "2019-04-09 22:58:02,373 root         INFO     Train Epoch: 175 [4608/8000 (58%)]\tTotal Loss: 0.332239\n",
      "Reconstruction: 0.317855, Regularization: 0.014384\n",
      "2019-04-09 22:58:02,429 root         INFO     Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 0.378555\n",
      "Reconstruction: 0.363877, Regularization: 0.014678\n",
      "2019-04-09 22:58:02,485 root         INFO     Train Epoch: 175 [5632/8000 (70%)]\tTotal Loss: 0.541100\n",
      "Reconstruction: 0.520361, Regularization: 0.020739\n",
      "2019-04-09 22:58:02,540 root         INFO     Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 0.370770\n",
      "Reconstruction: 0.352111, Regularization: 0.018659\n",
      "2019-04-09 22:58:02,595 root         INFO     Train Epoch: 175 [6656/8000 (83%)]\tTotal Loss: 0.361887\n",
      "Reconstruction: 0.347356, Regularization: 0.014532\n",
      "2019-04-09 22:58:02,649 root         INFO     Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 0.352863\n",
      "Reconstruction: 0.331736, Regularization: 0.021127\n",
      "2019-04-09 22:58:02,705 root         INFO     Train Epoch: 175 [7680/8000 (96%)]\tTotal Loss: 0.420200\n",
      "Reconstruction: 0.401905, Regularization: 0.018295\n",
      "2019-04-09 22:58:02,755 root         INFO     ====> Epoch: 175 Average loss: 0.4396\n",
      "2019-04-09 22:58:02,779 root         INFO     Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 0.375706\n",
      "Reconstruction: 0.362445, Regularization: 0.013261\n",
      "2019-04-09 22:58:02,836 root         INFO     Train Epoch: 176 [512/8000 (6%)]\tTotal Loss: 0.404487\n",
      "Reconstruction: 0.381865, Regularization: 0.022622\n",
      "2019-04-09 22:58:02,893 root         INFO     Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 0.431791\n",
      "Reconstruction: 0.417906, Regularization: 0.013886\n",
      "2019-04-09 22:58:02,950 root         INFO     Train Epoch: 176 [1536/8000 (19%)]\tTotal Loss: 0.444172\n",
      "Reconstruction: 0.424278, Regularization: 0.019894\n",
      "2019-04-09 22:58:03,006 root         INFO     Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 0.403298\n",
      "Reconstruction: 0.387998, Regularization: 0.015300\n",
      "2019-04-09 22:58:03,063 root         INFO     Train Epoch: 176 [2560/8000 (32%)]\tTotal Loss: 0.313489\n",
      "Reconstruction: 0.300732, Regularization: 0.012757\n",
      "2019-04-09 22:58:03,120 root         INFO     Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 0.387411\n",
      "Reconstruction: 0.364419, Regularization: 0.022992\n",
      "2019-04-09 22:58:03,177 root         INFO     Train Epoch: 176 [3584/8000 (45%)]\tTotal Loss: 0.551950\n",
      "Reconstruction: 0.535797, Regularization: 0.016153\n",
      "2019-04-09 22:58:03,233 root         INFO     Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 0.371406\n",
      "Reconstruction: 0.357397, Regularization: 0.014009\n",
      "2019-04-09 22:58:03,290 root         INFO     Train Epoch: 176 [4608/8000 (58%)]\tTotal Loss: 0.348910\n",
      "Reconstruction: 0.336020, Regularization: 0.012890\n",
      "2019-04-09 22:58:03,347 root         INFO     Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 0.293074\n",
      "Reconstruction: 0.275078, Regularization: 0.017996\n",
      "2019-04-09 22:58:03,404 root         INFO     Train Epoch: 176 [5632/8000 (70%)]\tTotal Loss: 0.425778\n",
      "Reconstruction: 0.409947, Regularization: 0.015830\n",
      "2019-04-09 22:58:03,461 root         INFO     Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 0.306610\n",
      "Reconstruction: 0.291116, Regularization: 0.015494\n",
      "2019-04-09 22:58:03,517 root         INFO     Train Epoch: 176 [6656/8000 (83%)]\tTotal Loss: 0.277380\n",
      "Reconstruction: 0.263498, Regularization: 0.013882\n",
      "2019-04-09 22:58:03,574 root         INFO     Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 0.413893\n",
      "Reconstruction: 0.394630, Regularization: 0.019263\n",
      "2019-04-09 22:58:03,631 root         INFO     Train Epoch: 176 [7680/8000 (96%)]\tTotal Loss: 0.440647\n",
      "Reconstruction: 0.418973, Regularization: 0.021674\n",
      "2019-04-09 22:58:03,682 root         INFO     ====> Epoch: 176 Average loss: 0.3715\n",
      "2019-04-09 22:58:03,705 root         INFO     Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 0.352549\n",
      "Reconstruction: 0.337254, Regularization: 0.015295\n",
      "2019-04-09 22:58:03,761 root         INFO     Train Epoch: 177 [512/8000 (6%)]\tTotal Loss: 0.355272\n",
      "Reconstruction: 0.337352, Regularization: 0.017921\n",
      "2019-04-09 22:58:03,817 root         INFO     Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 0.462851\n",
      "Reconstruction: 0.443007, Regularization: 0.019844\n",
      "2019-04-09 22:58:03,873 root         INFO     Train Epoch: 177 [1536/8000 (19%)]\tTotal Loss: 0.425436\n",
      "Reconstruction: 0.404607, Regularization: 0.020829\n",
      "2019-04-09 22:58:03,929 root         INFO     Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 0.605767\n",
      "Reconstruction: 0.584793, Regularization: 0.020975\n",
      "2019-04-09 22:58:03,985 root         INFO     Train Epoch: 177 [2560/8000 (32%)]\tTotal Loss: 0.411285\n",
      "Reconstruction: 0.393827, Regularization: 0.017458\n",
      "2019-04-09 22:58:04,042 root         INFO     Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 0.420805\n",
      "Reconstruction: 0.404458, Regularization: 0.016347\n",
      "2019-04-09 22:58:04,098 root         INFO     Train Epoch: 177 [3584/8000 (45%)]\tTotal Loss: 0.452222\n",
      "Reconstruction: 0.434776, Regularization: 0.017446\n",
      "2019-04-09 22:58:04,154 root         INFO     Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 0.393972\n",
      "Reconstruction: 0.377566, Regularization: 0.016407\n",
      "2019-04-09 22:58:04,210 root         INFO     Train Epoch: 177 [4608/8000 (58%)]\tTotal Loss: 0.372604\n",
      "Reconstruction: 0.347689, Regularization: 0.024915\n",
      "2019-04-09 22:58:04,266 root         INFO     Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 0.465731\n",
      "Reconstruction: 0.446423, Regularization: 0.019308\n",
      "2019-04-09 22:58:04,322 root         INFO     Train Epoch: 177 [5632/8000 (70%)]\tTotal Loss: 0.363097\n",
      "Reconstruction: 0.349783, Regularization: 0.013314\n",
      "2019-04-09 22:58:04,378 root         INFO     Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 0.436309\n",
      "Reconstruction: 0.407574, Regularization: 0.028735\n",
      "2019-04-09 22:58:04,434 root         INFO     Train Epoch: 177 [6656/8000 (83%)]\tTotal Loss: 0.362043\n",
      "Reconstruction: 0.347170, Regularization: 0.014873\n",
      "2019-04-09 22:58:04,491 root         INFO     Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 0.413385\n",
      "Reconstruction: 0.398046, Regularization: 0.015339\n",
      "2019-04-09 22:58:04,547 root         INFO     Train Epoch: 177 [7680/8000 (96%)]\tTotal Loss: 0.436853\n",
      "Reconstruction: 0.419424, Regularization: 0.017429\n",
      "2019-04-09 22:58:04,596 root         INFO     ====> Epoch: 177 Average loss: 0.3716\n",
      "2019-04-09 22:58:04,619 root         INFO     Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 0.402141\n",
      "Reconstruction: 0.382919, Regularization: 0.019222\n",
      "2019-04-09 22:58:04,676 root         INFO     Train Epoch: 178 [512/8000 (6%)]\tTotal Loss: 0.240007\n",
      "Reconstruction: 0.225969, Regularization: 0.014038\n",
      "2019-04-09 22:58:04,732 root         INFO     Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 0.453260\n",
      "Reconstruction: 0.427538, Regularization: 0.025722\n",
      "2019-04-09 22:58:04,787 root         INFO     Train Epoch: 178 [1536/8000 (19%)]\tTotal Loss: 0.391783\n",
      "Reconstruction: 0.374800, Regularization: 0.016982\n",
      "2019-04-09 22:58:04,843 root         INFO     Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 0.379868\n",
      "Reconstruction: 0.365330, Regularization: 0.014538\n",
      "2019-04-09 22:58:04,898 root         INFO     Train Epoch: 178 [2560/8000 (32%)]\tTotal Loss: 0.331839\n",
      "Reconstruction: 0.318629, Regularization: 0.013210\n",
      "2019-04-09 22:58:04,954 root         INFO     Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 0.514269\n",
      "Reconstruction: 0.494462, Regularization: 0.019806\n",
      "2019-04-09 22:58:05,009 root         INFO     Train Epoch: 178 [3584/8000 (45%)]\tTotal Loss: 0.345403\n",
      "Reconstruction: 0.325950, Regularization: 0.019453\n",
      "2019-04-09 22:58:05,063 root         INFO     Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 0.294823\n",
      "Reconstruction: 0.283181, Regularization: 0.011642\n",
      "2019-04-09 22:58:05,118 root         INFO     Train Epoch: 178 [4608/8000 (58%)]\tTotal Loss: 0.315537\n",
      "Reconstruction: 0.297048, Regularization: 0.018489\n",
      "2019-04-09 22:58:05,173 root         INFO     Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 0.426502\n",
      "Reconstruction: 0.411101, Regularization: 0.015401\n",
      "2019-04-09 22:58:05,229 root         INFO     Train Epoch: 178 [5632/8000 (70%)]\tTotal Loss: 0.351430\n",
      "Reconstruction: 0.322426, Regularization: 0.029003\n",
      "2019-04-09 22:58:05,284 root         INFO     Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 0.312550\n",
      "Reconstruction: 0.283694, Regularization: 0.028856\n",
      "2019-04-09 22:58:05,339 root         INFO     Train Epoch: 178 [6656/8000 (83%)]\tTotal Loss: 0.381280\n",
      "Reconstruction: 0.365074, Regularization: 0.016207\n",
      "2019-04-09 22:58:05,395 root         INFO     Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 0.354432\n",
      "Reconstruction: 0.334792, Regularization: 0.019639\n",
      "2019-04-09 22:58:05,450 root         INFO     Train Epoch: 178 [7680/8000 (96%)]\tTotal Loss: 0.434726\n",
      "Reconstruction: 0.416448, Regularization: 0.018278\n",
      "2019-04-09 22:58:05,500 root         INFO     ====> Epoch: 178 Average loss: 0.3784\n",
      "2019-04-09 22:58:05,523 root         INFO     Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 0.358211\n",
      "Reconstruction: 0.343466, Regularization: 0.014745\n",
      "2019-04-09 22:58:05,579 root         INFO     Train Epoch: 179 [512/8000 (6%)]\tTotal Loss: 0.330172\n",
      "Reconstruction: 0.314115, Regularization: 0.016057\n",
      "2019-04-09 22:58:05,636 root         INFO     Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 0.323610\n",
      "Reconstruction: 0.311722, Regularization: 0.011888\n",
      "2019-04-09 22:58:05,692 root         INFO     Train Epoch: 179 [1536/8000 (19%)]\tTotal Loss: 0.370385\n",
      "Reconstruction: 0.354032, Regularization: 0.016353\n",
      "2019-04-09 22:58:05,748 root         INFO     Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 0.307941\n",
      "Reconstruction: 0.283114, Regularization: 0.024827\n",
      "2019-04-09 22:58:05,803 root         INFO     Train Epoch: 179 [2560/8000 (32%)]\tTotal Loss: 0.387851\n",
      "Reconstruction: 0.372397, Regularization: 0.015454\n",
      "2019-04-09 22:58:05,859 root         INFO     Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 0.388832\n",
      "Reconstruction: 0.374337, Regularization: 0.014495\n",
      "2019-04-09 22:58:05,915 root         INFO     Train Epoch: 179 [3584/8000 (45%)]\tTotal Loss: 0.349244\n",
      "Reconstruction: 0.333144, Regularization: 0.016100\n",
      "2019-04-09 22:58:05,971 root         INFO     Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 0.361267\n",
      "Reconstruction: 0.343125, Regularization: 0.018143\n",
      "2019-04-09 22:58:06,027 root         INFO     Train Epoch: 179 [4608/8000 (58%)]\tTotal Loss: 0.367805\n",
      "Reconstruction: 0.348427, Regularization: 0.019378\n",
      "2019-04-09 22:58:06,082 root         INFO     Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 0.444553\n",
      "Reconstruction: 0.426997, Regularization: 0.017555\n",
      "2019-04-09 22:58:06,138 root         INFO     Train Epoch: 179 [5632/8000 (70%)]\tTotal Loss: 0.465187\n",
      "Reconstruction: 0.447304, Regularization: 0.017883\n",
      "2019-04-09 22:58:06,194 root         INFO     Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 0.305780\n",
      "Reconstruction: 0.290660, Regularization: 0.015120\n",
      "2019-04-09 22:58:06,250 root         INFO     Train Epoch: 179 [6656/8000 (83%)]\tTotal Loss: 0.346007\n",
      "Reconstruction: 0.330283, Regularization: 0.015724\n",
      "2019-04-09 22:58:06,305 root         INFO     Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 0.333065\n",
      "Reconstruction: 0.314896, Regularization: 0.018168\n",
      "2019-04-09 22:58:06,361 root         INFO     Train Epoch: 179 [7680/8000 (96%)]\tTotal Loss: 0.354643\n",
      "Reconstruction: 0.340415, Regularization: 0.014228\n",
      "2019-04-09 22:58:06,412 root         INFO     ====> Epoch: 179 Average loss: 0.4409\n",
      "2019-04-09 22:58:06,435 root         INFO     Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 0.358193\n",
      "Reconstruction: 0.343772, Regularization: 0.014421\n",
      "2019-04-09 22:58:06,491 root         INFO     Train Epoch: 180 [512/8000 (6%)]\tTotal Loss: 0.345534\n",
      "Reconstruction: 0.328185, Regularization: 0.017349\n",
      "2019-04-09 22:58:06,548 root         INFO     Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 0.389660\n",
      "Reconstruction: 0.373186, Regularization: 0.016475\n",
      "2019-04-09 22:58:06,604 root         INFO     Train Epoch: 180 [1536/8000 (19%)]\tTotal Loss: 0.381828\n",
      "Reconstruction: 0.366495, Regularization: 0.015333\n",
      "2019-04-09 22:58:06,660 root         INFO     Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 0.342310\n",
      "Reconstruction: 0.317949, Regularization: 0.024361\n",
      "2019-04-09 22:58:06,716 root         INFO     Train Epoch: 180 [2560/8000 (32%)]\tTotal Loss: 0.392852\n",
      "Reconstruction: 0.376844, Regularization: 0.016007\n",
      "2019-04-09 22:58:06,771 root         INFO     Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 0.309841\n",
      "Reconstruction: 0.297648, Regularization: 0.012193\n",
      "2019-04-09 22:58:06,827 root         INFO     Train Epoch: 180 [3584/8000 (45%)]\tTotal Loss: 0.395644\n",
      "Reconstruction: 0.380356, Regularization: 0.015289\n",
      "2019-04-09 22:58:06,883 root         INFO     Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 0.358226\n",
      "Reconstruction: 0.335830, Regularization: 0.022396\n",
      "2019-04-09 22:58:06,939 root         INFO     Train Epoch: 180 [4608/8000 (58%)]\tTotal Loss: 0.329255\n",
      "Reconstruction: 0.315307, Regularization: 0.013947\n",
      "2019-04-09 22:58:06,995 root         INFO     Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 0.473918\n",
      "Reconstruction: 0.455314, Regularization: 0.018605\n",
      "2019-04-09 22:58:07,050 root         INFO     Train Epoch: 180 [5632/8000 (70%)]\tTotal Loss: 0.417954\n",
      "Reconstruction: 0.377392, Regularization: 0.040563\n",
      "2019-04-09 22:58:07,106 root         INFO     Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 0.377653\n",
      "Reconstruction: 0.364339, Regularization: 0.013314\n",
      "2019-04-09 22:58:07,162 root         INFO     Train Epoch: 180 [6656/8000 (83%)]\tTotal Loss: 0.332592\n",
      "Reconstruction: 0.317760, Regularization: 0.014832\n",
      "2019-04-09 22:58:07,217 root         INFO     Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 0.304456\n",
      "Reconstruction: 0.282960, Regularization: 0.021496\n",
      "2019-04-09 22:58:07,272 root         INFO     Train Epoch: 180 [7680/8000 (96%)]\tTotal Loss: 0.367406\n",
      "Reconstruction: 0.351178, Regularization: 0.016228\n",
      "2019-04-09 22:58:07,322 root         INFO     ====> Epoch: 180 Average loss: 0.3608\n",
      "2019-04-09 22:58:07,345 root         INFO     Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 0.330474\n",
      "Reconstruction: 0.317148, Regularization: 0.013326\n",
      "2019-04-09 22:58:07,402 root         INFO     Train Epoch: 181 [512/8000 (6%)]\tTotal Loss: 0.362550\n",
      "Reconstruction: 0.347452, Regularization: 0.015098\n",
      "2019-04-09 22:58:07,459 root         INFO     Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 0.428539\n",
      "Reconstruction: 0.408536, Regularization: 0.020003\n",
      "2019-04-09 22:58:07,515 root         INFO     Train Epoch: 181 [1536/8000 (19%)]\tTotal Loss: 0.243505\n",
      "Reconstruction: 0.234625, Regularization: 0.008880\n",
      "2019-04-09 22:58:07,571 root         INFO     Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 0.394326\n",
      "Reconstruction: 0.369493, Regularization: 0.024832\n",
      "2019-04-09 22:58:07,627 root         INFO     Train Epoch: 181 [2560/8000 (32%)]\tTotal Loss: 0.389200\n",
      "Reconstruction: 0.370918, Regularization: 0.018282\n",
      "2019-04-09 22:58:07,684 root         INFO     Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 0.341747\n",
      "Reconstruction: 0.326759, Regularization: 0.014989\n",
      "2019-04-09 22:58:07,740 root         INFO     Train Epoch: 181 [3584/8000 (45%)]\tTotal Loss: 0.336390\n",
      "Reconstruction: 0.321356, Regularization: 0.015035\n",
      "2019-04-09 22:58:07,796 root         INFO     Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 0.314011\n",
      "Reconstruction: 0.300294, Regularization: 0.013717\n",
      "2019-04-09 22:58:07,851 root         INFO     Train Epoch: 181 [4608/8000 (58%)]\tTotal Loss: 0.347866\n",
      "Reconstruction: 0.330421, Regularization: 0.017445\n",
      "2019-04-09 22:58:07,906 root         INFO     Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 0.386226\n",
      "Reconstruction: 0.367151, Regularization: 0.019075\n",
      "2019-04-09 22:58:07,961 root         INFO     Train Epoch: 181 [5632/8000 (70%)]\tTotal Loss: 0.438188\n",
      "Reconstruction: 0.420623, Regularization: 0.017565\n",
      "2019-04-09 22:58:08,016 root         INFO     Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 0.376236\n",
      "Reconstruction: 0.357528, Regularization: 0.018709\n",
      "2019-04-09 22:58:08,071 root         INFO     Train Epoch: 181 [6656/8000 (83%)]\tTotal Loss: 0.322205\n",
      "Reconstruction: 0.302645, Regularization: 0.019559\n",
      "2019-04-09 22:58:08,125 root         INFO     Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 0.410491\n",
      "Reconstruction: 0.393858, Regularization: 0.016632\n",
      "2019-04-09 22:58:08,180 root         INFO     Train Epoch: 181 [7680/8000 (96%)]\tTotal Loss: 0.395113\n",
      "Reconstruction: 0.377091, Regularization: 0.018022\n",
      "2019-04-09 22:58:08,230 root         INFO     ====> Epoch: 181 Average loss: 0.3794\n",
      "2019-04-09 22:58:08,253 root         INFO     Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 0.304427\n",
      "Reconstruction: 0.288778, Regularization: 0.015649\n",
      "2019-04-09 22:58:08,309 root         INFO     Train Epoch: 182 [512/8000 (6%)]\tTotal Loss: 0.292969\n",
      "Reconstruction: 0.281429, Regularization: 0.011539\n",
      "2019-04-09 22:58:08,366 root         INFO     Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 0.388274\n",
      "Reconstruction: 0.374148, Regularization: 0.014126\n",
      "2019-04-09 22:58:08,421 root         INFO     Train Epoch: 182 [1536/8000 (19%)]\tTotal Loss: 0.404233\n",
      "Reconstruction: 0.388787, Regularization: 0.015446\n",
      "2019-04-09 22:58:08,476 root         INFO     Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 0.371812\n",
      "Reconstruction: 0.355295, Regularization: 0.016517\n",
      "2019-04-09 22:58:08,532 root         INFO     Train Epoch: 182 [2560/8000 (32%)]\tTotal Loss: 0.288396\n",
      "Reconstruction: 0.277111, Regularization: 0.011285\n",
      "2019-04-09 22:58:08,587 root         INFO     Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 0.332809\n",
      "Reconstruction: 0.319279, Regularization: 0.013531\n",
      "2019-04-09 22:58:08,642 root         INFO     Train Epoch: 182 [3584/8000 (45%)]\tTotal Loss: 0.359666\n",
      "Reconstruction: 0.345552, Regularization: 0.014114\n",
      "2019-04-09 22:58:08,698 root         INFO     Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 0.370107\n",
      "Reconstruction: 0.352239, Regularization: 0.017869\n",
      "2019-04-09 22:58:08,753 root         INFO     Train Epoch: 182 [4608/8000 (58%)]\tTotal Loss: 0.383797\n",
      "Reconstruction: 0.368793, Regularization: 0.015004\n",
      "2019-04-09 22:58:08,809 root         INFO     Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 0.412675\n",
      "Reconstruction: 0.394161, Regularization: 0.018514\n",
      "2019-04-09 22:58:08,864 root         INFO     Train Epoch: 182 [5632/8000 (70%)]\tTotal Loss: 0.381026\n",
      "Reconstruction: 0.364640, Regularization: 0.016386\n",
      "2019-04-09 22:58:08,919 root         INFO     Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 0.348552\n",
      "Reconstruction: 0.328603, Regularization: 0.019950\n",
      "2019-04-09 22:58:08,975 root         INFO     Train Epoch: 182 [6656/8000 (83%)]\tTotal Loss: 0.322404\n",
      "Reconstruction: 0.310610, Regularization: 0.011794\n",
      "2019-04-09 22:58:09,029 root         INFO     Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 0.325574\n",
      "Reconstruction: 0.305808, Regularization: 0.019766\n",
      "2019-04-09 22:58:09,084 root         INFO     Train Epoch: 182 [7680/8000 (96%)]\tTotal Loss: 0.340720\n",
      "Reconstruction: 0.324785, Regularization: 0.015935\n",
      "2019-04-09 22:58:09,134 root         INFO     ====> Epoch: 182 Average loss: 0.3729\n",
      "2019-04-09 22:58:09,158 root         INFO     Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 0.376164\n",
      "Reconstruction: 0.356165, Regularization: 0.019999\n",
      "2019-04-09 22:58:09,214 root         INFO     Train Epoch: 183 [512/8000 (6%)]\tTotal Loss: 0.337070\n",
      "Reconstruction: 0.323778, Regularization: 0.013292\n",
      "2019-04-09 22:58:09,271 root         INFO     Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 0.253308\n",
      "Reconstruction: 0.236389, Regularization: 0.016920\n",
      "2019-04-09 22:58:09,327 root         INFO     Train Epoch: 183 [1536/8000 (19%)]\tTotal Loss: 0.332258\n",
      "Reconstruction: 0.318496, Regularization: 0.013762\n",
      "2019-04-09 22:58:09,383 root         INFO     Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 0.382697\n",
      "Reconstruction: 0.366312, Regularization: 0.016385\n",
      "2019-04-09 22:58:09,439 root         INFO     Train Epoch: 183 [2560/8000 (32%)]\tTotal Loss: 0.340252\n",
      "Reconstruction: 0.317652, Regularization: 0.022600\n",
      "2019-04-09 22:58:09,495 root         INFO     Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 0.345568\n",
      "Reconstruction: 0.331205, Regularization: 0.014363\n",
      "2019-04-09 22:58:09,552 root         INFO     Train Epoch: 183 [3584/8000 (45%)]\tTotal Loss: 0.353531\n",
      "Reconstruction: 0.337289, Regularization: 0.016242\n",
      "2019-04-09 22:58:09,608 root         INFO     Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 0.312993\n",
      "Reconstruction: 0.300981, Regularization: 0.012012\n",
      "2019-04-09 22:58:09,664 root         INFO     Train Epoch: 183 [4608/8000 (58%)]\tTotal Loss: 0.339676\n",
      "Reconstruction: 0.325209, Regularization: 0.014467\n",
      "2019-04-09 22:58:09,720 root         INFO     Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 0.351853\n",
      "Reconstruction: 0.338026, Regularization: 0.013827\n",
      "2019-04-09 22:58:09,775 root         INFO     Train Epoch: 183 [5632/8000 (70%)]\tTotal Loss: 0.327463\n",
      "Reconstruction: 0.307183, Regularization: 0.020279\n",
      "2019-04-09 22:58:09,831 root         INFO     Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 0.434029\n",
      "Reconstruction: 0.414333, Regularization: 0.019696\n",
      "2019-04-09 22:58:09,887 root         INFO     Train Epoch: 183 [6656/8000 (83%)]\tTotal Loss: 0.302811\n",
      "Reconstruction: 0.290726, Regularization: 0.012085\n",
      "2019-04-09 22:58:09,943 root         INFO     Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 0.418362\n",
      "Reconstruction: 0.380243, Regularization: 0.038119\n",
      "2019-04-09 22:58:09,999 root         INFO     Train Epoch: 183 [7680/8000 (96%)]\tTotal Loss: 0.424718\n",
      "Reconstruction: 0.407687, Regularization: 0.017030\n",
      "2019-04-09 22:58:10,049 root         INFO     ====> Epoch: 183 Average loss: 0.3771\n",
      "2019-04-09 22:58:10,072 root         INFO     Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 0.421848\n",
      "Reconstruction: 0.405417, Regularization: 0.016431\n",
      "2019-04-09 22:58:10,128 root         INFO     Train Epoch: 184 [512/8000 (6%)]\tTotal Loss: 0.313193\n",
      "Reconstruction: 0.297925, Regularization: 0.015268\n",
      "2019-04-09 22:58:10,184 root         INFO     Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 0.368279\n",
      "Reconstruction: 0.352331, Regularization: 0.015948\n",
      "2019-04-09 22:58:10,239 root         INFO     Train Epoch: 184 [1536/8000 (19%)]\tTotal Loss: 0.392018\n",
      "Reconstruction: 0.372181, Regularization: 0.019837\n",
      "2019-04-09 22:58:10,294 root         INFO     Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 0.395586\n",
      "Reconstruction: 0.380078, Regularization: 0.015508\n",
      "2019-04-09 22:58:10,350 root         INFO     Train Epoch: 184 [2560/8000 (32%)]\tTotal Loss: 0.372492\n",
      "Reconstruction: 0.358261, Regularization: 0.014231\n",
      "2019-04-09 22:58:10,405 root         INFO     Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 0.335894\n",
      "Reconstruction: 0.322209, Regularization: 0.013684\n",
      "2019-04-09 22:58:10,459 root         INFO     Train Epoch: 184 [3584/8000 (45%)]\tTotal Loss: 0.404847\n",
      "Reconstruction: 0.390015, Regularization: 0.014832\n",
      "2019-04-09 22:58:10,514 root         INFO     Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 0.419527\n",
      "Reconstruction: 0.400561, Regularization: 0.018967\n",
      "2019-04-09 22:58:10,568 root         INFO     Train Epoch: 184 [4608/8000 (58%)]\tTotal Loss: 0.404285\n",
      "Reconstruction: 0.381086, Regularization: 0.023199\n",
      "2019-04-09 22:58:10,624 root         INFO     Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 0.307828\n",
      "Reconstruction: 0.291458, Regularization: 0.016371\n",
      "2019-04-09 22:58:10,680 root         INFO     Train Epoch: 184 [5632/8000 (70%)]\tTotal Loss: 0.414848\n",
      "Reconstruction: 0.397357, Regularization: 0.017491\n",
      "2019-04-09 22:58:10,737 root         INFO     Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 0.311229\n",
      "Reconstruction: 0.293058, Regularization: 0.018171\n",
      "2019-04-09 22:58:10,794 root         INFO     Train Epoch: 184 [6656/8000 (83%)]\tTotal Loss: 0.464216\n",
      "Reconstruction: 0.436570, Regularization: 0.027646\n",
      "2019-04-09 22:58:10,851 root         INFO     Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 0.322913\n",
      "Reconstruction: 0.308435, Regularization: 0.014478\n",
      "2019-04-09 22:58:10,908 root         INFO     Train Epoch: 184 [7680/8000 (96%)]\tTotal Loss: 0.290240\n",
      "Reconstruction: 0.276820, Regularization: 0.013420\n",
      "2019-04-09 22:58:10,958 root         INFO     ====> Epoch: 184 Average loss: 0.3843\n",
      "2019-04-09 22:58:10,982 root         INFO     Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 0.395043\n",
      "Reconstruction: 0.374385, Regularization: 0.020658\n",
      "2019-04-09 22:58:11,038 root         INFO     Train Epoch: 185 [512/8000 (6%)]\tTotal Loss: 0.341668\n",
      "Reconstruction: 0.322362, Regularization: 0.019306\n",
      "2019-04-09 22:58:11,093 root         INFO     Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 0.307479\n",
      "Reconstruction: 0.293839, Regularization: 0.013640\n",
      "2019-04-09 22:58:11,149 root         INFO     Train Epoch: 185 [1536/8000 (19%)]\tTotal Loss: 0.578840\n",
      "Reconstruction: 0.560317, Regularization: 0.018523\n",
      "2019-04-09 22:58:11,203 root         INFO     Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 0.348086\n",
      "Reconstruction: 0.327546, Regularization: 0.020540\n",
      "2019-04-09 22:58:11,258 root         INFO     Train Epoch: 185 [2560/8000 (32%)]\tTotal Loss: 0.312814\n",
      "Reconstruction: 0.297067, Regularization: 0.015747\n",
      "2019-04-09 22:58:11,313 root         INFO     Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 0.309953\n",
      "Reconstruction: 0.297709, Regularization: 0.012244\n",
      "2019-04-09 22:58:11,368 root         INFO     Train Epoch: 185 [3584/8000 (45%)]\tTotal Loss: 0.422757\n",
      "Reconstruction: 0.407081, Regularization: 0.015676\n",
      "2019-04-09 22:58:11,424 root         INFO     Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 0.396569\n",
      "Reconstruction: 0.378101, Regularization: 0.018468\n",
      "2019-04-09 22:58:11,479 root         INFO     Train Epoch: 185 [4608/8000 (58%)]\tTotal Loss: 0.334788\n",
      "Reconstruction: 0.319137, Regularization: 0.015651\n",
      "2019-04-09 22:58:11,534 root         INFO     Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 0.276578\n",
      "Reconstruction: 0.265406, Regularization: 0.011172\n",
      "2019-04-09 22:58:11,590 root         INFO     Train Epoch: 185 [5632/8000 (70%)]\tTotal Loss: 0.337750\n",
      "Reconstruction: 0.319568, Regularization: 0.018182\n",
      "2019-04-09 22:58:11,645 root         INFO     Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 0.349123\n",
      "Reconstruction: 0.331728, Regularization: 0.017395\n",
      "2019-04-09 22:58:11,700 root         INFO     Train Epoch: 185 [6656/8000 (83%)]\tTotal Loss: 0.292654\n",
      "Reconstruction: 0.278632, Regularization: 0.014022\n",
      "2019-04-09 22:58:11,755 root         INFO     Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 0.335797\n",
      "Reconstruction: 0.318010, Regularization: 0.017787\n",
      "2019-04-09 22:58:11,809 root         INFO     Train Epoch: 185 [7680/8000 (96%)]\tTotal Loss: 0.390096\n",
      "Reconstruction: 0.374656, Regularization: 0.015440\n",
      "2019-04-09 22:58:11,858 root         INFO     ====> Epoch: 185 Average loss: 0.3716\n",
      "2019-04-09 22:58:11,881 root         INFO     Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 0.320092\n",
      "Reconstruction: 0.305718, Regularization: 0.014374\n",
      "2019-04-09 22:58:11,939 root         INFO     Train Epoch: 186 [512/8000 (6%)]\tTotal Loss: 0.286072\n",
      "Reconstruction: 0.272661, Regularization: 0.013411\n",
      "2019-04-09 22:58:11,995 root         INFO     Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 0.370407\n",
      "Reconstruction: 0.352226, Regularization: 0.018181\n",
      "2019-04-09 22:58:12,051 root         INFO     Train Epoch: 186 [1536/8000 (19%)]\tTotal Loss: 0.363749\n",
      "Reconstruction: 0.349332, Regularization: 0.014417\n",
      "2019-04-09 22:58:12,108 root         INFO     Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 0.308139\n",
      "Reconstruction: 0.294399, Regularization: 0.013739\n",
      "2019-04-09 22:58:12,164 root         INFO     Train Epoch: 186 [2560/8000 (32%)]\tTotal Loss: 0.336541\n",
      "Reconstruction: 0.323597, Regularization: 0.012944\n",
      "2019-04-09 22:58:12,220 root         INFO     Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 0.345077\n",
      "Reconstruction: 0.327547, Regularization: 0.017530\n",
      "2019-04-09 22:58:12,276 root         INFO     Train Epoch: 186 [3584/8000 (45%)]\tTotal Loss: 0.383782\n",
      "Reconstruction: 0.364016, Regularization: 0.019766\n",
      "2019-04-09 22:58:12,333 root         INFO     Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 0.381603\n",
      "Reconstruction: 0.362868, Regularization: 0.018735\n",
      "2019-04-09 22:58:12,389 root         INFO     Train Epoch: 186 [4608/8000 (58%)]\tTotal Loss: 0.397578\n",
      "Reconstruction: 0.379336, Regularization: 0.018242\n",
      "2019-04-09 22:58:12,445 root         INFO     Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 0.323848\n",
      "Reconstruction: 0.304444, Regularization: 0.019404\n",
      "2019-04-09 22:58:12,501 root         INFO     Train Epoch: 186 [5632/8000 (70%)]\tTotal Loss: 0.352057\n",
      "Reconstruction: 0.337028, Regularization: 0.015029\n",
      "2019-04-09 22:58:12,558 root         INFO     Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 0.336128\n",
      "Reconstruction: 0.321797, Regularization: 0.014331\n",
      "2019-04-09 22:58:12,615 root         INFO     Train Epoch: 186 [6656/8000 (83%)]\tTotal Loss: 0.328757\n",
      "Reconstruction: 0.306526, Regularization: 0.022231\n",
      "2019-04-09 22:58:12,672 root         INFO     Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 0.307315\n",
      "Reconstruction: 0.292664, Regularization: 0.014651\n",
      "2019-04-09 22:58:12,729 root         INFO     Train Epoch: 186 [7680/8000 (96%)]\tTotal Loss: 0.340861\n",
      "Reconstruction: 0.327144, Regularization: 0.013717\n",
      "2019-04-09 22:58:12,780 root         INFO     ====> Epoch: 186 Average loss: 0.3428\n",
      "2019-04-09 22:58:12,804 root         INFO     Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 0.329313\n",
      "Reconstruction: 0.306831, Regularization: 0.022482\n",
      "2019-04-09 22:58:12,860 root         INFO     Train Epoch: 187 [512/8000 (6%)]\tTotal Loss: 0.389693\n",
      "Reconstruction: 0.364625, Regularization: 0.025069\n",
      "2019-04-09 22:58:12,916 root         INFO     Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 0.482842\n",
      "Reconstruction: 0.463708, Regularization: 0.019134\n",
      "2019-04-09 22:58:12,973 root         INFO     Train Epoch: 187 [1536/8000 (19%)]\tTotal Loss: 0.336029\n",
      "Reconstruction: 0.320538, Regularization: 0.015492\n",
      "2019-04-09 22:58:13,029 root         INFO     Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 0.335986\n",
      "Reconstruction: 0.319728, Regularization: 0.016258\n",
      "2019-04-09 22:58:13,085 root         INFO     Train Epoch: 187 [2560/8000 (32%)]\tTotal Loss: 0.340364\n",
      "Reconstruction: 0.324154, Regularization: 0.016210\n",
      "2019-04-09 22:58:13,142 root         INFO     Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 0.287545\n",
      "Reconstruction: 0.274507, Regularization: 0.013038\n",
      "2019-04-09 22:58:13,198 root         INFO     Train Epoch: 187 [3584/8000 (45%)]\tTotal Loss: 0.359222\n",
      "Reconstruction: 0.341775, Regularization: 0.017447\n",
      "2019-04-09 22:58:13,254 root         INFO     Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 0.272540\n",
      "Reconstruction: 0.259659, Regularization: 0.012881\n",
      "2019-04-09 22:58:13,310 root         INFO     Train Epoch: 187 [4608/8000 (58%)]\tTotal Loss: 0.325677\n",
      "Reconstruction: 0.312025, Regularization: 0.013652\n",
      "2019-04-09 22:58:13,366 root         INFO     Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 0.282035\n",
      "Reconstruction: 0.265047, Regularization: 0.016989\n",
      "2019-04-09 22:58:13,421 root         INFO     Train Epoch: 187 [5632/8000 (70%)]\tTotal Loss: 0.308740\n",
      "Reconstruction: 0.296410, Regularization: 0.012329\n",
      "2019-04-09 22:58:13,477 root         INFO     Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 0.360106\n",
      "Reconstruction: 0.342869, Regularization: 0.017237\n",
      "2019-04-09 22:58:13,533 root         INFO     Train Epoch: 187 [6656/8000 (83%)]\tTotal Loss: 0.275538\n",
      "Reconstruction: 0.259800, Regularization: 0.015738\n",
      "2019-04-09 22:58:13,588 root         INFO     Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 0.313877\n",
      "Reconstruction: 0.299146, Regularization: 0.014731\n",
      "2019-04-09 22:58:13,644 root         INFO     Train Epoch: 187 [7680/8000 (96%)]\tTotal Loss: 0.300891\n",
      "Reconstruction: 0.289221, Regularization: 0.011671\n",
      "2019-04-09 22:58:13,694 root         INFO     ====> Epoch: 187 Average loss: 0.3462\n",
      "2019-04-09 22:58:13,717 root         INFO     Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 0.301886\n",
      "Reconstruction: 0.284995, Regularization: 0.016891\n",
      "2019-04-09 22:58:13,774 root         INFO     Train Epoch: 188 [512/8000 (6%)]\tTotal Loss: 0.291960\n",
      "Reconstruction: 0.277234, Regularization: 0.014726\n",
      "2019-04-09 22:58:13,830 root         INFO     Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 0.279519\n",
      "Reconstruction: 0.267402, Regularization: 0.012116\n",
      "2019-04-09 22:58:13,885 root         INFO     Train Epoch: 188 [1536/8000 (19%)]\tTotal Loss: 0.375594\n",
      "Reconstruction: 0.358842, Regularization: 0.016752\n",
      "2019-04-09 22:58:13,941 root         INFO     Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 0.394624\n",
      "Reconstruction: 0.357792, Regularization: 0.036832\n",
      "2019-04-09 22:58:13,997 root         INFO     Train Epoch: 188 [2560/8000 (32%)]\tTotal Loss: 0.367438\n",
      "Reconstruction: 0.352357, Regularization: 0.015081\n",
      "2019-04-09 22:58:14,053 root         INFO     Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 0.328544\n",
      "Reconstruction: 0.313262, Regularization: 0.015282\n",
      "2019-04-09 22:58:14,109 root         INFO     Train Epoch: 188 [3584/8000 (45%)]\tTotal Loss: 0.360241\n",
      "Reconstruction: 0.344133, Regularization: 0.016108\n",
      "2019-04-09 22:58:14,165 root         INFO     Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 0.284305\n",
      "Reconstruction: 0.264363, Regularization: 0.019942\n",
      "2019-04-09 22:58:14,221 root         INFO     Train Epoch: 188 [4608/8000 (58%)]\tTotal Loss: 0.288911\n",
      "Reconstruction: 0.269448, Regularization: 0.019464\n",
      "2019-04-09 22:58:14,277 root         INFO     Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 0.300464\n",
      "Reconstruction: 0.288329, Regularization: 0.012134\n",
      "2019-04-09 22:58:14,333 root         INFO     Train Epoch: 188 [5632/8000 (70%)]\tTotal Loss: 0.329897\n",
      "Reconstruction: 0.309146, Regularization: 0.020751\n",
      "2019-04-09 22:58:14,388 root         INFO     Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 0.334516\n",
      "Reconstruction: 0.320183, Regularization: 0.014333\n",
      "2019-04-09 22:58:14,444 root         INFO     Train Epoch: 188 [6656/8000 (83%)]\tTotal Loss: 0.280561\n",
      "Reconstruction: 0.265490, Regularization: 0.015071\n",
      "2019-04-09 22:58:14,500 root         INFO     Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 0.285604\n",
      "Reconstruction: 0.274029, Regularization: 0.011576\n",
      "2019-04-09 22:58:14,557 root         INFO     Train Epoch: 188 [7680/8000 (96%)]\tTotal Loss: 0.296357\n",
      "Reconstruction: 0.283212, Regularization: 0.013145\n",
      "2019-04-09 22:58:14,606 root         INFO     ====> Epoch: 188 Average loss: 200.1548\n",
      "2019-04-09 22:58:14,630 root         INFO     Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 0.342275\n",
      "Reconstruction: 0.329091, Regularization: 0.013185\n",
      "2019-04-09 22:58:14,686 root         INFO     Train Epoch: 189 [512/8000 (6%)]\tTotal Loss: 0.279909\n",
      "Reconstruction: 0.261090, Regularization: 0.018819\n",
      "2019-04-09 22:58:14,742 root         INFO     Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 0.317388\n",
      "Reconstruction: 0.299867, Regularization: 0.017521\n",
      "2019-04-09 22:58:14,797 root         INFO     Train Epoch: 189 [1536/8000 (19%)]\tTotal Loss: 0.343969\n",
      "Reconstruction: 0.328723, Regularization: 0.015246\n",
      "2019-04-09 22:58:14,854 root         INFO     Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 0.335022\n",
      "Reconstruction: 0.320220, Regularization: 0.014802\n",
      "2019-04-09 22:58:14,911 root         INFO     Train Epoch: 189 [2560/8000 (32%)]\tTotal Loss: 0.292021\n",
      "Reconstruction: 0.278311, Regularization: 0.013710\n",
      "2019-04-09 22:58:14,967 root         INFO     Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 0.357491\n",
      "Reconstruction: 0.341093, Regularization: 0.016398\n",
      "2019-04-09 22:58:15,023 root         INFO     Train Epoch: 189 [3584/8000 (45%)]\tTotal Loss: 0.393206\n",
      "Reconstruction: 0.375384, Regularization: 0.017822\n",
      "2019-04-09 22:58:15,079 root         INFO     Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 0.310944\n",
      "Reconstruction: 0.295418, Regularization: 0.015526\n",
      "2019-04-09 22:58:15,136 root         INFO     Train Epoch: 189 [4608/8000 (58%)]\tTotal Loss: 0.316112\n",
      "Reconstruction: 0.301797, Regularization: 0.014315\n",
      "2019-04-09 22:58:15,191 root         INFO     Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 0.366457\n",
      "Reconstruction: 0.350028, Regularization: 0.016429\n",
      "2019-04-09 22:58:15,246 root         INFO     Train Epoch: 189 [5632/8000 (70%)]\tTotal Loss: 0.421996\n",
      "Reconstruction: 0.404258, Regularization: 0.017737\n",
      "2019-04-09 22:58:15,302 root         INFO     Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 0.267481\n",
      "Reconstruction: 0.254346, Regularization: 0.013135\n",
      "2019-04-09 22:58:15,359 root         INFO     Train Epoch: 189 [6656/8000 (83%)]\tTotal Loss: 0.359820\n",
      "Reconstruction: 0.339419, Regularization: 0.020401\n",
      "2019-04-09 22:58:15,415 root         INFO     Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 0.396441\n",
      "Reconstruction: 0.378783, Regularization: 0.017658\n",
      "2019-04-09 22:58:15,472 root         INFO     Train Epoch: 189 [7680/8000 (96%)]\tTotal Loss: 0.440574\n",
      "Reconstruction: 0.426252, Regularization: 0.014322\n",
      "2019-04-09 22:58:15,522 root         INFO     ====> Epoch: 189 Average loss: 0.3371\n",
      "2019-04-09 22:58:15,545 root         INFO     Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 0.312579\n",
      "Reconstruction: 0.297435, Regularization: 0.015145\n",
      "2019-04-09 22:58:15,601 root         INFO     Train Epoch: 190 [512/8000 (6%)]\tTotal Loss: 0.245788\n",
      "Reconstruction: 0.234961, Regularization: 0.010827\n",
      "2019-04-09 22:58:15,656 root         INFO     Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 0.287693\n",
      "Reconstruction: 0.273318, Regularization: 0.014376\n",
      "2019-04-09 22:58:15,712 root         INFO     Train Epoch: 190 [1536/8000 (19%)]\tTotal Loss: 0.395161\n",
      "Reconstruction: 0.376098, Regularization: 0.019063\n",
      "2019-04-09 22:58:15,769 root         INFO     Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 0.360756\n",
      "Reconstruction: 0.342234, Regularization: 0.018521\n",
      "2019-04-09 22:58:15,823 root         INFO     Train Epoch: 190 [2560/8000 (32%)]\tTotal Loss: 0.329548\n",
      "Reconstruction: 0.313160, Regularization: 0.016388\n",
      "2019-04-09 22:58:15,878 root         INFO     Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 0.359468\n",
      "Reconstruction: 0.343361, Regularization: 0.016107\n",
      "2019-04-09 22:58:15,933 root         INFO     Train Epoch: 190 [3584/8000 (45%)]\tTotal Loss: 0.313154\n",
      "Reconstruction: 0.295016, Regularization: 0.018138\n",
      "2019-04-09 22:58:15,987 root         INFO     Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 0.307008\n",
      "Reconstruction: 0.292064, Regularization: 0.014944\n",
      "2019-04-09 22:58:16,042 root         INFO     Train Epoch: 190 [4608/8000 (58%)]\tTotal Loss: 0.298696\n",
      "Reconstruction: 0.280687, Regularization: 0.018008\n",
      "2019-04-09 22:58:16,096 root         INFO     Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 0.270256\n",
      "Reconstruction: 0.256540, Regularization: 0.013717\n",
      "2019-04-09 22:58:16,151 root         INFO     Train Epoch: 190 [5632/8000 (70%)]\tTotal Loss: 0.339547\n",
      "Reconstruction: 0.326896, Regularization: 0.012650\n",
      "2019-04-09 22:58:16,205 root         INFO     Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 0.416108\n",
      "Reconstruction: 0.394799, Regularization: 0.021309\n",
      "2019-04-09 22:58:16,260 root         INFO     Train Epoch: 190 [6656/8000 (83%)]\tTotal Loss: 0.321898\n",
      "Reconstruction: 0.306814, Regularization: 0.015084\n",
      "2019-04-09 22:58:16,314 root         INFO     Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 0.385754\n",
      "Reconstruction: 0.357741, Regularization: 0.028014\n",
      "2019-04-09 22:58:16,369 root         INFO     Train Epoch: 190 [7680/8000 (96%)]\tTotal Loss: 0.316662\n",
      "Reconstruction: 0.301714, Regularization: 0.014948\n",
      "2019-04-09 22:58:16,419 root         INFO     ====> Epoch: 190 Average loss: 0.3379\n",
      "2019-04-09 22:58:16,443 root         INFO     Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 0.360624\n",
      "Reconstruction: 0.345429, Regularization: 0.015195\n",
      "2019-04-09 22:58:16,500 root         INFO     Train Epoch: 191 [512/8000 (6%)]\tTotal Loss: 0.362938\n",
      "Reconstruction: 0.345729, Regularization: 0.017209\n",
      "2019-04-09 22:58:16,557 root         INFO     Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 0.306424\n",
      "Reconstruction: 0.292312, Regularization: 0.014112\n",
      "2019-04-09 22:58:16,614 root         INFO     Train Epoch: 191 [1536/8000 (19%)]\tTotal Loss: 0.244105\n",
      "Reconstruction: 0.232206, Regularization: 0.011899\n",
      "2019-04-09 22:58:16,671 root         INFO     Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 0.393705\n",
      "Reconstruction: 0.375971, Regularization: 0.017734\n",
      "2019-04-09 22:58:16,727 root         INFO     Train Epoch: 191 [2560/8000 (32%)]\tTotal Loss: 0.331764\n",
      "Reconstruction: 0.311464, Regularization: 0.020300\n",
      "2019-04-09 22:58:16,784 root         INFO     Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 0.270126\n",
      "Reconstruction: 0.258142, Regularization: 0.011984\n",
      "2019-04-09 22:58:16,841 root         INFO     Train Epoch: 191 [3584/8000 (45%)]\tTotal Loss: 0.322460\n",
      "Reconstruction: 0.309802, Regularization: 0.012658\n",
      "2019-04-09 22:58:16,898 root         INFO     Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 0.249424\n",
      "Reconstruction: 0.235863, Regularization: 0.013561\n",
      "2019-04-09 22:58:16,954 root         INFO     Train Epoch: 191 [4608/8000 (58%)]\tTotal Loss: 0.412772\n",
      "Reconstruction: 0.389935, Regularization: 0.022837\n",
      "2019-04-09 22:58:17,010 root         INFO     Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 0.331968\n",
      "Reconstruction: 0.311363, Regularization: 0.020605\n",
      "2019-04-09 22:58:17,066 root         INFO     Train Epoch: 191 [5632/8000 (70%)]\tTotal Loss: 0.293851\n",
      "Reconstruction: 0.274094, Regularization: 0.019757\n",
      "2019-04-09 22:58:17,122 root         INFO     Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 0.828463\n",
      "Reconstruction: 0.811203, Regularization: 0.017260\n",
      "2019-04-09 22:58:17,178 root         INFO     Train Epoch: 191 [6656/8000 (83%)]\tTotal Loss: 0.699077\n",
      "Reconstruction: 0.678250, Regularization: 0.020828\n",
      "2019-04-09 22:58:17,234 root         INFO     Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 0.283304\n",
      "Reconstruction: 0.268829, Regularization: 0.014475\n",
      "2019-04-09 22:58:17,290 root         INFO     Train Epoch: 191 [7680/8000 (96%)]\tTotal Loss: 0.350257\n",
      "Reconstruction: 0.330095, Regularization: 0.020161\n",
      "2019-04-09 22:58:17,341 root         INFO     ====> Epoch: 191 Average loss: 0.3491\n",
      "2019-04-09 22:58:17,364 root         INFO     Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 0.434427\n",
      "Reconstruction: 0.410513, Regularization: 0.023913\n",
      "2019-04-09 22:58:17,421 root         INFO     Train Epoch: 192 [512/8000 (6%)]\tTotal Loss: 0.363672\n",
      "Reconstruction: 0.345441, Regularization: 0.018231\n",
      "2019-04-09 22:58:17,478 root         INFO     Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 0.385769\n",
      "Reconstruction: 0.368123, Regularization: 0.017646\n",
      "2019-04-09 22:58:17,535 root         INFO     Train Epoch: 192 [1536/8000 (19%)]\tTotal Loss: 0.362153\n",
      "Reconstruction: 0.346687, Regularization: 0.015466\n",
      "2019-04-09 22:58:17,592 root         INFO     Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.363563\n",
      "Reconstruction: 0.344392, Regularization: 0.019171\n",
      "2019-04-09 22:58:17,649 root         INFO     Train Epoch: 192 [2560/8000 (32%)]\tTotal Loss: 0.309284\n",
      "Reconstruction: 0.291332, Regularization: 0.017952\n",
      "2019-04-09 22:58:17,706 root         INFO     Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 0.316819\n",
      "Reconstruction: 0.299156, Regularization: 0.017663\n",
      "2019-04-09 22:58:17,763 root         INFO     Train Epoch: 192 [3584/8000 (45%)]\tTotal Loss: 0.409812\n",
      "Reconstruction: 0.388805, Regularization: 0.021007\n",
      "2019-04-09 22:58:17,819 root         INFO     Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 0.275224\n",
      "Reconstruction: 0.263557, Regularization: 0.011667\n",
      "2019-04-09 22:58:17,875 root         INFO     Train Epoch: 192 [4608/8000 (58%)]\tTotal Loss: 0.364429\n",
      "Reconstruction: 0.350529, Regularization: 0.013900\n",
      "2019-04-09 22:58:17,931 root         INFO     Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 0.360629\n",
      "Reconstruction: 0.343663, Regularization: 0.016966\n",
      "2019-04-09 22:58:17,987 root         INFO     Train Epoch: 192 [5632/8000 (70%)]\tTotal Loss: 0.312806\n",
      "Reconstruction: 0.296152, Regularization: 0.016654\n",
      "2019-04-09 22:58:18,043 root         INFO     Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 0.294723\n",
      "Reconstruction: 0.280237, Regularization: 0.014486\n",
      "2019-04-09 22:58:18,099 root         INFO     Train Epoch: 192 [6656/8000 (83%)]\tTotal Loss: 0.269537\n",
      "Reconstruction: 0.259359, Regularization: 0.010178\n",
      "2019-04-09 22:58:18,155 root         INFO     Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 0.257897\n",
      "Reconstruction: 0.247823, Regularization: 0.010074\n",
      "2019-04-09 22:58:18,211 root         INFO     Train Epoch: 192 [7680/8000 (96%)]\tTotal Loss: 0.323815\n",
      "Reconstruction: 0.306366, Regularization: 0.017449\n",
      "2019-04-09 22:58:18,261 root         INFO     ====> Epoch: 192 Average loss: 0.3371\n",
      "2019-04-09 22:58:18,285 root         INFO     Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 0.362051\n",
      "Reconstruction: 0.342271, Regularization: 0.019780\n",
      "2019-04-09 22:58:18,342 root         INFO     Train Epoch: 193 [512/8000 (6%)]\tTotal Loss: 0.393263\n",
      "Reconstruction: 0.369970, Regularization: 0.023293\n",
      "2019-04-09 22:58:18,398 root         INFO     Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 0.367419\n",
      "Reconstruction: 0.354076, Regularization: 0.013343\n",
      "2019-04-09 22:58:18,455 root         INFO     Train Epoch: 193 [1536/8000 (19%)]\tTotal Loss: 0.356558\n",
      "Reconstruction: 0.341388, Regularization: 0.015169\n",
      "2019-04-09 22:58:18,512 root         INFO     Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 0.299729\n",
      "Reconstruction: 0.282467, Regularization: 0.017263\n",
      "2019-04-09 22:58:18,569 root         INFO     Train Epoch: 193 [2560/8000 (32%)]\tTotal Loss: 0.367361\n",
      "Reconstruction: 0.347287, Regularization: 0.020074\n",
      "2019-04-09 22:58:18,625 root         INFO     Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 0.372963\n",
      "Reconstruction: 0.356801, Regularization: 0.016163\n",
      "2019-04-09 22:58:18,681 root         INFO     Train Epoch: 193 [3584/8000 (45%)]\tTotal Loss: 0.399040\n",
      "Reconstruction: 0.380917, Regularization: 0.018124\n",
      "2019-04-09 22:58:18,738 root         INFO     Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 0.369538\n",
      "Reconstruction: 0.346418, Regularization: 0.023120\n",
      "2019-04-09 22:58:18,794 root         INFO     Train Epoch: 193 [4608/8000 (58%)]\tTotal Loss: 0.333389\n",
      "Reconstruction: 0.315419, Regularization: 0.017970\n",
      "2019-04-09 22:58:18,851 root         INFO     Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 0.321532\n",
      "Reconstruction: 0.305949, Regularization: 0.015583\n",
      "2019-04-09 22:58:18,908 root         INFO     Train Epoch: 193 [5632/8000 (70%)]\tTotal Loss: 0.337124\n",
      "Reconstruction: 0.323739, Regularization: 0.013385\n",
      "2019-04-09 22:58:18,964 root         INFO     Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 0.310508\n",
      "Reconstruction: 0.293653, Regularization: 0.016855\n",
      "2019-04-09 22:58:19,021 root         INFO     Train Epoch: 193 [6656/8000 (83%)]\tTotal Loss: 0.353586\n",
      "Reconstruction: 0.335699, Regularization: 0.017887\n",
      "2019-04-09 22:58:19,077 root         INFO     Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 0.346372\n",
      "Reconstruction: 0.323632, Regularization: 0.022740\n",
      "2019-04-09 22:58:19,133 root         INFO     Train Epoch: 193 [7680/8000 (96%)]\tTotal Loss: 0.399169\n",
      "Reconstruction: 0.382530, Regularization: 0.016639\n",
      "2019-04-09 22:58:19,183 root         INFO     ====> Epoch: 193 Average loss: 0.3357\n",
      "2019-04-09 22:58:19,206 root         INFO     Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 0.347571\n",
      "Reconstruction: 0.329414, Regularization: 0.018157\n",
      "2019-04-09 22:58:19,261 root         INFO     Train Epoch: 194 [512/8000 (6%)]\tTotal Loss: 0.425295\n",
      "Reconstruction: 0.405783, Regularization: 0.019512\n",
      "2019-04-09 22:58:19,316 root         INFO     Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 0.293375\n",
      "Reconstruction: 0.281369, Regularization: 0.012006\n",
      "2019-04-09 22:58:19,371 root         INFO     Train Epoch: 194 [1536/8000 (19%)]\tTotal Loss: 0.278374\n",
      "Reconstruction: 0.259207, Regularization: 0.019167\n",
      "2019-04-09 22:58:19,427 root         INFO     Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 0.340014\n",
      "Reconstruction: 0.324105, Regularization: 0.015909\n",
      "2019-04-09 22:58:19,482 root         INFO     Train Epoch: 194 [2560/8000 (32%)]\tTotal Loss: 0.285697\n",
      "Reconstruction: 0.265298, Regularization: 0.020399\n",
      "2019-04-09 22:58:19,537 root         INFO     Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 0.336567\n",
      "Reconstruction: 0.317735, Regularization: 0.018832\n",
      "2019-04-09 22:58:19,592 root         INFO     Train Epoch: 194 [3584/8000 (45%)]\tTotal Loss: 0.326344\n",
      "Reconstruction: 0.309126, Regularization: 0.017219\n",
      "2019-04-09 22:58:19,646 root         INFO     Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 0.395633\n",
      "Reconstruction: 0.379860, Regularization: 0.015773\n",
      "2019-04-09 22:58:19,701 root         INFO     Train Epoch: 194 [4608/8000 (58%)]\tTotal Loss: 0.428569\n",
      "Reconstruction: 0.413122, Regularization: 0.015446\n",
      "2019-04-09 22:58:19,756 root         INFO     Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 0.427224\n",
      "Reconstruction: 0.409584, Regularization: 0.017639\n",
      "2019-04-09 22:58:19,812 root         INFO     Train Epoch: 194 [5632/8000 (70%)]\tTotal Loss: 0.388420\n",
      "Reconstruction: 0.367967, Regularization: 0.020453\n",
      "2019-04-09 22:58:19,868 root         INFO     Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 0.362871\n",
      "Reconstruction: 0.344612, Regularization: 0.018259\n",
      "2019-04-09 22:58:19,924 root         INFO     Train Epoch: 194 [6656/8000 (83%)]\tTotal Loss: 0.361856\n",
      "Reconstruction: 0.345145, Regularization: 0.016712\n",
      "2019-04-09 22:58:19,979 root         INFO     Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 0.294077\n",
      "Reconstruction: 0.280244, Regularization: 0.013833\n",
      "2019-04-09 22:58:20,034 root         INFO     Train Epoch: 194 [7680/8000 (96%)]\tTotal Loss: 0.338903\n",
      "Reconstruction: 0.322032, Regularization: 0.016871\n",
      "2019-04-09 22:58:20,084 root         INFO     ====> Epoch: 194 Average loss: 0.3433\n",
      "2019-04-09 22:58:20,107 root         INFO     Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 0.386593\n",
      "Reconstruction: 0.367487, Regularization: 0.019106\n",
      "2019-04-09 22:58:20,162 root         INFO     Train Epoch: 195 [512/8000 (6%)]\tTotal Loss: 0.344426\n",
      "Reconstruction: 0.327191, Regularization: 0.017236\n",
      "2019-04-09 22:58:20,217 root         INFO     Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 0.321140\n",
      "Reconstruction: 0.307859, Regularization: 0.013282\n",
      "2019-04-09 22:58:20,271 root         INFO     Train Epoch: 195 [1536/8000 (19%)]\tTotal Loss: 0.296227\n",
      "Reconstruction: 0.279353, Regularization: 0.016874\n",
      "2019-04-09 22:58:20,326 root         INFO     Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 0.313892\n",
      "Reconstruction: 0.297669, Regularization: 0.016223\n",
      "2019-04-09 22:58:20,381 root         INFO     Train Epoch: 195 [2560/8000 (32%)]\tTotal Loss: 0.269532\n",
      "Reconstruction: 0.254572, Regularization: 0.014960\n",
      "2019-04-09 22:58:20,436 root         INFO     Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 0.334046\n",
      "Reconstruction: 0.313263, Regularization: 0.020783\n",
      "2019-04-09 22:58:20,490 root         INFO     Train Epoch: 195 [3584/8000 (45%)]\tTotal Loss: 0.352047\n",
      "Reconstruction: 0.335373, Regularization: 0.016674\n",
      "2019-04-09 22:58:20,545 root         INFO     Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 0.349658\n",
      "Reconstruction: 0.331448, Regularization: 0.018210\n",
      "2019-04-09 22:58:20,600 root         INFO     Train Epoch: 195 [4608/8000 (58%)]\tTotal Loss: 0.362762\n",
      "Reconstruction: 0.348431, Regularization: 0.014331\n",
      "2019-04-09 22:58:20,654 root         INFO     Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 0.413508\n",
      "Reconstruction: 0.397022, Regularization: 0.016486\n",
      "2019-04-09 22:58:20,708 root         INFO     Train Epoch: 195 [5632/8000 (70%)]\tTotal Loss: 0.334791\n",
      "Reconstruction: 0.319503, Regularization: 0.015288\n",
      "2019-04-09 22:58:20,762 root         INFO     Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 0.391762\n",
      "Reconstruction: 0.368542, Regularization: 0.023221\n",
      "2019-04-09 22:58:20,816 root         INFO     Train Epoch: 195 [6656/8000 (83%)]\tTotal Loss: 0.343139\n",
      "Reconstruction: 0.328031, Regularization: 0.015107\n",
      "2019-04-09 22:58:20,869 root         INFO     Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 0.298016\n",
      "Reconstruction: 0.280916, Regularization: 0.017100\n",
      "2019-04-09 22:58:20,922 root         INFO     Train Epoch: 195 [7680/8000 (96%)]\tTotal Loss: 0.295365\n",
      "Reconstruction: 0.282559, Regularization: 0.012806\n",
      "2019-04-09 22:58:20,970 root         INFO     ====> Epoch: 195 Average loss: 0.3619\n",
      "2019-04-09 22:58:20,994 root         INFO     Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 0.401938\n",
      "Reconstruction: 0.385779, Regularization: 0.016159\n",
      "2019-04-09 22:58:21,049 root         INFO     Train Epoch: 196 [512/8000 (6%)]\tTotal Loss: 0.287783\n",
      "Reconstruction: 0.274234, Regularization: 0.013549\n",
      "2019-04-09 22:58:21,104 root         INFO     Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 0.243443\n",
      "Reconstruction: 0.230044, Regularization: 0.013399\n",
      "2019-04-09 22:58:21,159 root         INFO     Train Epoch: 196 [1536/8000 (19%)]\tTotal Loss: 0.314575\n",
      "Reconstruction: 0.299274, Regularization: 0.015301\n",
      "2019-04-09 22:58:21,213 root         INFO     Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 0.303533\n",
      "Reconstruction: 0.286700, Regularization: 0.016833\n",
      "2019-04-09 22:58:21,268 root         INFO     Train Epoch: 196 [2560/8000 (32%)]\tTotal Loss: 0.316975\n",
      "Reconstruction: 0.303027, Regularization: 0.013948\n",
      "2019-04-09 22:58:21,323 root         INFO     Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 0.538243\n",
      "Reconstruction: 0.518254, Regularization: 0.019989\n",
      "2019-04-09 22:58:21,378 root         INFO     Train Epoch: 196 [3584/8000 (45%)]\tTotal Loss: 0.287950\n",
      "Reconstruction: 0.274257, Regularization: 0.013692\n",
      "2019-04-09 22:58:21,433 root         INFO     Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 0.299003\n",
      "Reconstruction: 0.283124, Regularization: 0.015879\n",
      "2019-04-09 22:58:21,487 root         INFO     Train Epoch: 196 [4608/8000 (58%)]\tTotal Loss: 0.321890\n",
      "Reconstruction: 0.307511, Regularization: 0.014379\n",
      "2019-04-09 22:58:21,543 root         INFO     Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 0.314658\n",
      "Reconstruction: 0.300164, Regularization: 0.014494\n",
      "2019-04-09 22:58:21,598 root         INFO     Train Epoch: 196 [5632/8000 (70%)]\tTotal Loss: 0.333069\n",
      "Reconstruction: 0.319016, Regularization: 0.014053\n",
      "2019-04-09 22:58:21,654 root         INFO     Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 0.331312\n",
      "Reconstruction: 0.314509, Regularization: 0.016803\n",
      "2019-04-09 22:58:21,709 root         INFO     Train Epoch: 196 [6656/8000 (83%)]\tTotal Loss: 0.412136\n",
      "Reconstruction: 0.392648, Regularization: 0.019488\n",
      "2019-04-09 22:58:21,764 root         INFO     Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 0.425276\n",
      "Reconstruction: 0.409120, Regularization: 0.016156\n",
      "2019-04-09 22:58:21,820 root         INFO     Train Epoch: 196 [7680/8000 (96%)]\tTotal Loss: 0.373684\n",
      "Reconstruction: 0.352403, Regularization: 0.021281\n",
      "2019-04-09 22:58:21,869 root         INFO     ====> Epoch: 196 Average loss: 0.3331\n",
      "2019-04-09 22:58:21,892 root         INFO     Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 0.354185\n",
      "Reconstruction: 0.336811, Regularization: 0.017373\n",
      "2019-04-09 22:58:21,947 root         INFO     Train Epoch: 197 [512/8000 (6%)]\tTotal Loss: 0.336519\n",
      "Reconstruction: 0.321612, Regularization: 0.014907\n",
      "2019-04-09 22:58:22,002 root         INFO     Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 0.255335\n",
      "Reconstruction: 0.244093, Regularization: 0.011241\n",
      "2019-04-09 22:58:22,057 root         INFO     Train Epoch: 197 [1536/8000 (19%)]\tTotal Loss: 0.390551\n",
      "Reconstruction: 0.372295, Regularization: 0.018256\n",
      "2019-04-09 22:58:22,111 root         INFO     Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 0.444588\n",
      "Reconstruction: 0.427513, Regularization: 0.017076\n",
      "2019-04-09 22:58:22,166 root         INFO     Train Epoch: 197 [2560/8000 (32%)]\tTotal Loss: 0.345580\n",
      "Reconstruction: 0.330250, Regularization: 0.015330\n",
      "2019-04-09 22:58:22,220 root         INFO     Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 0.424088\n",
      "Reconstruction: 0.393792, Regularization: 0.030297\n",
      "2019-04-09 22:58:22,275 root         INFO     Train Epoch: 197 [3584/8000 (45%)]\tTotal Loss: 0.317345\n",
      "Reconstruction: 0.298692, Regularization: 0.018654\n",
      "2019-04-09 22:58:22,329 root         INFO     Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 0.283269\n",
      "Reconstruction: 0.270027, Regularization: 0.013242\n",
      "2019-04-09 22:58:22,384 root         INFO     Train Epoch: 197 [4608/8000 (58%)]\tTotal Loss: 0.295492\n",
      "Reconstruction: 0.282050, Regularization: 0.013442\n",
      "2019-04-09 22:58:22,439 root         INFO     Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 0.356294\n",
      "Reconstruction: 0.340726, Regularization: 0.015568\n",
      "2019-04-09 22:58:22,494 root         INFO     Train Epoch: 197 [5632/8000 (70%)]\tTotal Loss: 0.332266\n",
      "Reconstruction: 0.314921, Regularization: 0.017345\n",
      "2019-04-09 22:58:22,549 root         INFO     Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 0.274922\n",
      "Reconstruction: 0.261077, Regularization: 0.013845\n",
      "2019-04-09 22:58:22,606 root         INFO     Train Epoch: 197 [6656/8000 (83%)]\tTotal Loss: 0.313985\n",
      "Reconstruction: 0.295397, Regularization: 0.018588\n",
      "2019-04-09 22:58:22,661 root         INFO     Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 0.321039\n",
      "Reconstruction: 0.302926, Regularization: 0.018113\n",
      "2019-04-09 22:58:22,720 root         INFO     Train Epoch: 197 [7680/8000 (96%)]\tTotal Loss: 0.319785\n",
      "Reconstruction: 0.308914, Regularization: 0.010871\n",
      "2019-04-09 22:58:22,771 root         INFO     ====> Epoch: 197 Average loss: 0.3332\n",
      "2019-04-09 22:58:22,794 root         INFO     Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 0.430507\n",
      "Reconstruction: 0.407499, Regularization: 0.023008\n",
      "2019-04-09 22:58:22,851 root         INFO     Train Epoch: 198 [512/8000 (6%)]\tTotal Loss: 0.308441\n",
      "Reconstruction: 0.292212, Regularization: 0.016230\n",
      "2019-04-09 22:58:22,908 root         INFO     Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.346091\n",
      "Reconstruction: 0.330448, Regularization: 0.015643\n",
      "2019-04-09 22:58:22,964 root         INFO     Train Epoch: 198 [1536/8000 (19%)]\tTotal Loss: 0.263884\n",
      "Reconstruction: 0.250424, Regularization: 0.013460\n",
      "2019-04-09 22:58:23,019 root         INFO     Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 0.352010\n",
      "Reconstruction: 0.335651, Regularization: 0.016359\n",
      "2019-04-09 22:58:23,075 root         INFO     Train Epoch: 198 [2560/8000 (32%)]\tTotal Loss: 0.355851\n",
      "Reconstruction: 0.339769, Regularization: 0.016082\n",
      "2019-04-09 22:58:23,131 root         INFO     Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 0.312473\n",
      "Reconstruction: 0.298663, Regularization: 0.013810\n",
      "2019-04-09 22:58:23,186 root         INFO     Train Epoch: 198 [3584/8000 (45%)]\tTotal Loss: 0.360028\n",
      "Reconstruction: 0.342542, Regularization: 0.017485\n",
      "2019-04-09 22:58:23,242 root         INFO     Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 0.291726\n",
      "Reconstruction: 0.280430, Regularization: 0.011296\n",
      "2019-04-09 22:58:23,299 root         INFO     Train Epoch: 198 [4608/8000 (58%)]\tTotal Loss: 0.370617\n",
      "Reconstruction: 0.352640, Regularization: 0.017977\n",
      "2019-04-09 22:58:23,356 root         INFO     Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 0.399721\n",
      "Reconstruction: 0.367100, Regularization: 0.032621\n",
      "2019-04-09 22:58:23,412 root         INFO     Train Epoch: 198 [5632/8000 (70%)]\tTotal Loss: 0.318176\n",
      "Reconstruction: 0.302787, Regularization: 0.015389\n",
      "2019-04-09 22:58:23,468 root         INFO     Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 0.280574\n",
      "Reconstruction: 0.267227, Regularization: 0.013347\n",
      "2019-04-09 22:58:23,525 root         INFO     Train Epoch: 198 [6656/8000 (83%)]\tTotal Loss: 0.355476\n",
      "Reconstruction: 0.333532, Regularization: 0.021943\n",
      "2019-04-09 22:58:23,582 root         INFO     Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 0.293973\n",
      "Reconstruction: 0.283033, Regularization: 0.010940\n",
      "2019-04-09 22:58:23,638 root         INFO     Train Epoch: 198 [7680/8000 (96%)]\tTotal Loss: 0.294011\n",
      "Reconstruction: 0.277314, Regularization: 0.016697\n",
      "2019-04-09 22:58:23,687 root         INFO     ====> Epoch: 198 Average loss: 0.3328\n",
      "2019-04-09 22:58:23,711 root         INFO     Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 0.381629\n",
      "Reconstruction: 0.362187, Regularization: 0.019442\n",
      "2019-04-09 22:58:23,767 root         INFO     Train Epoch: 199 [512/8000 (6%)]\tTotal Loss: 0.344767\n",
      "Reconstruction: 0.328072, Regularization: 0.016695\n",
      "2019-04-09 22:58:23,822 root         INFO     Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 0.284839\n",
      "Reconstruction: 0.272027, Regularization: 0.012812\n",
      "2019-04-09 22:58:23,878 root         INFO     Train Epoch: 199 [1536/8000 (19%)]\tTotal Loss: 0.291075\n",
      "Reconstruction: 0.276547, Regularization: 0.014529\n",
      "2019-04-09 22:58:23,934 root         INFO     Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 0.284868\n",
      "Reconstruction: 0.273460, Regularization: 0.011408\n",
      "2019-04-09 22:58:23,989 root         INFO     Train Epoch: 199 [2560/8000 (32%)]\tTotal Loss: 0.431329\n",
      "Reconstruction: 0.410376, Regularization: 0.020953\n",
      "2019-04-09 22:58:24,044 root         INFO     Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 0.252546\n",
      "Reconstruction: 0.232020, Regularization: 0.020525\n",
      "2019-04-09 22:58:24,100 root         INFO     Train Epoch: 199 [3584/8000 (45%)]\tTotal Loss: 0.375635\n",
      "Reconstruction: 0.359285, Regularization: 0.016351\n",
      "2019-04-09 22:58:24,156 root         INFO     Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 0.314875\n",
      "Reconstruction: 0.295873, Regularization: 0.019002\n",
      "2019-04-09 22:58:24,211 root         INFO     Train Epoch: 199 [4608/8000 (58%)]\tTotal Loss: 0.387654\n",
      "Reconstruction: 0.371288, Regularization: 0.016366\n",
      "2019-04-09 22:58:24,267 root         INFO     Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 0.319057\n",
      "Reconstruction: 0.303150, Regularization: 0.015908\n",
      "2019-04-09 22:58:24,323 root         INFO     Train Epoch: 199 [5632/8000 (70%)]\tTotal Loss: 0.354155\n",
      "Reconstruction: 0.333236, Regularization: 0.020919\n",
      "2019-04-09 22:58:24,379 root         INFO     Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.371749\n",
      "Reconstruction: 0.349123, Regularization: 0.022626\n",
      "2019-04-09 22:58:24,434 root         INFO     Train Epoch: 199 [6656/8000 (83%)]\tTotal Loss: 0.351387\n",
      "Reconstruction: 0.336698, Regularization: 0.014689\n",
      "2019-04-09 22:58:24,489 root         INFO     Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 0.308805\n",
      "Reconstruction: 0.293150, Regularization: 0.015655\n",
      "2019-04-09 22:58:24,547 root         INFO     Train Epoch: 199 [7680/8000 (96%)]\tTotal Loss: 0.303948\n",
      "Reconstruction: 0.285314, Regularization: 0.018634\n",
      "2019-04-09 22:58:24,597 root         INFO     ====> Epoch: 199 Average loss: 0.3295\n",
      "2019-04-09 22:58:24,605 luigi-interface INFO     [pid 11233] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=11233) done      TrainVAE()\n",
      "2019-04-09 22:58:24,605 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 22:58:24,606 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   DONE\n",
      "2019-04-09 22:58:24,606 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 22:58:24,606 luigi-interface DEBUG    Pending tasks: 2\n",
      "2019-04-09 22:58:24,606 luigi-interface INFO     [pid 11233] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=11233) running   TrainVEM()\n",
      "2019-04-09 22:58:24,607 root         INFO     --Dataset tensor: (10000, 2)\n",
      "2019-04-09 22:58:24,607 root         INFO     -- Train tensor: (8000, 2)\n",
      "2019-04-09 22:58:24,608 root         INFO     Values of VEM's decoder parameters before training:\n",
      "2019-04-09 22:58:24,609 root         INFO     layers.0.weight\n",
      "2019-04-09 22:58:24,609 root         INFO     tensor([[-0.2374],\n",
      "        [ 0.6884]], device='cuda:0')\n",
      "2019-04-09 22:58:24,610 root         INFO     layers.0.bias\n",
      "2019-04-09 22:58:24,610 root         INFO     tensor([ 0.3217, -0.8257], device='cuda:0')\n",
      "2019-04-09 22:58:24,611 root         INFO     layers.1.weight\n",
      "2019-04-09 22:58:24,611 root         INFO     tensor([[ 0.2860, -0.3716],\n",
      "        [-0.3862,  0.6990]], device='cuda:0')\n",
      "2019-04-09 22:58:24,612 root         INFO     layers.1.bias\n",
      "2019-04-09 22:58:24,612 root         INFO     tensor([ 0.5977, -0.1070], device='cuda:0')\n",
      "2019-04-09 22:58:24,613 root         INFO     layers.2.weight\n",
      "2019-04-09 22:58:24,613 root         INFO     tensor([[-0.0261, -0.3444],\n",
      "        [-0.4158, -0.3905]], device='cuda:0')\n",
      "2019-04-09 22:58:24,614 root         INFO     layers.2.bias\n",
      "2019-04-09 22:58:24,614 root         INFO     tensor([0.0504, 0.3872], device='cuda:0')\n",
      "2019-04-09 22:58:24,644 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 0.467439\n",
      "Reconstruction: 0.201430, Regularization: 0.028728, Discriminator: 0.187960; Generator: 0.049321,\n",
      "D(x): 0.171, D(G(z)): 0.215\n",
      "2019-04-09 22:58:24,744 root         INFO     Train Epoch: 0 [512/8000 (6%)]\tTotal Loss: 0.429348\n",
      "Reconstruction: 0.207457, Regularization: 0.024853, Discriminator: 0.146413; Generator: 0.050625,\n",
      "D(x): 0.283, D(G(z)): 0.211\n",
      "2019-04-09 22:58:24,843 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 0.470199\n",
      "Reconstruction: 0.209283, Regularization: 0.025603, Discriminator: 0.188036; Generator: 0.047276,\n",
      "D(x): 0.179, D(G(z)): 0.228\n",
      "2019-04-09 22:58:24,942 root         INFO     Train Epoch: 0 [1536/8000 (19%)]\tTotal Loss: 0.438697\n",
      "Reconstruction: 0.188632, Regularization: 0.025322, Discriminator: 0.175261; Generator: 0.049481,\n",
      "D(x): 0.240, D(G(z)): 0.215\n",
      "2019-04-09 22:58:25,041 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 0.575637\n",
      "Reconstruction: 0.267127, Regularization: 0.038692, Discriminator: 0.219419; Generator: 0.050399,\n",
      "D(x): 0.098, D(G(z)): 0.213\n",
      "2019-04-09 22:58:25,141 root         INFO     Train Epoch: 0 [2560/8000 (32%)]\tTotal Loss: 0.426954\n",
      "Reconstruction: 0.219569, Regularization: 0.024479, Discriminator: 0.138449; Generator: 0.044457,\n",
      "D(x): 0.391, D(G(z)): 0.249\n",
      "2019-04-09 22:58:25,241 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 0.584761\n",
      "Reconstruction: 0.276019, Regularization: 0.026860, Discriminator: 0.236767; Generator: 0.045116,\n",
      "D(x): 0.153, D(G(z)): 0.249\n",
      "2019-04-09 22:58:25,341 root         INFO     Train Epoch: 0 [3584/8000 (45%)]\tTotal Loss: 0.337821\n",
      "Reconstruction: 0.158751, Regularization: 0.023652, Discriminator: 0.110739; Generator: 0.044679,\n",
      "D(x): 0.365, D(G(z)): 0.245\n",
      "2019-04-09 22:58:25,440 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 0.400597\n",
      "Reconstruction: 0.181929, Regularization: 0.014980, Discriminator: 0.161960; Generator: 0.041727,\n",
      "D(x): 0.236, D(G(z)): 0.273\n",
      "2019-04-09 22:58:25,540 root         INFO     Train Epoch: 0 [4608/8000 (58%)]\tTotal Loss: 0.486085\n",
      "Reconstruction: 0.226498, Regularization: 0.020555, Discriminator: 0.201673; Generator: 0.037359,\n",
      "D(x): 0.218, D(G(z)): 0.308\n",
      "2019-04-09 22:58:25,640 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 0.463332\n",
      "Reconstruction: 0.235405, Regularization: 0.032444, Discriminator: 0.154158; Generator: 0.041325,\n",
      "D(x): 0.237, D(G(z)): 0.277\n",
      "2019-04-09 22:58:25,740 root         INFO     Train Epoch: 0 [5632/8000 (70%)]\tTotal Loss: 0.564892\n",
      "Reconstruction: 0.268938, Regularization: 0.026056, Discriminator: 0.228318; Generator: 0.041582,\n",
      "D(x): 0.108, D(G(z)): 0.269\n",
      "2019-04-09 22:58:25,840 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 0.404751\n",
      "Reconstruction: 0.198815, Regularization: 0.017685, Discriminator: 0.152102; Generator: 0.036148,\n",
      "D(x): 0.254, D(G(z)): 0.327\n",
      "2019-04-09 22:58:25,940 root         INFO     Train Epoch: 0 [6656/8000 (83%)]\tTotal Loss: 0.499026\n",
      "Reconstruction: 0.274031, Regularization: 0.024504, Discriminator: 0.162268; Generator: 0.038224,\n",
      "D(x): 0.292, D(G(z)): 0.302\n",
      "2019-04-09 22:58:26,040 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 0.386895\n",
      "Reconstruction: 0.186389, Regularization: 0.015931, Discriminator: 0.144714; Generator: 0.039861,\n",
      "D(x): 0.251, D(G(z)): 0.288\n",
      "2019-04-09 22:58:26,140 root         INFO     Train Epoch: 0 [7680/8000 (96%)]\tTotal Loss: 0.519396\n",
      "Reconstruction: 0.261528, Regularization: 0.023539, Discriminator: 0.197162; Generator: 0.037167,\n",
      "D(x): 0.161, D(G(z)): 0.318\n",
      "2019-04-09 22:58:26,214 root         INFO     ====> Epoch: 0 Average loss: 0.4686\n",
      "2019-04-09 22:58:26,240 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 0.393199\n",
      "Reconstruction: 0.201017, Regularization: 0.020503, Discriminator: 0.133150; Generator: 0.038528,\n",
      "D(x): 0.315, D(G(z)): 0.301\n",
      "2019-04-09 22:58:26,339 root         INFO     Train Epoch: 1 [512/8000 (6%)]\tTotal Loss: 0.463997\n",
      "Reconstruction: 0.244230, Regularization: 0.032372, Discriminator: 0.151032; Generator: 0.036362,\n",
      "D(x): 0.294, D(G(z)): 0.324\n",
      "2019-04-09 22:58:26,437 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 0.402062\n",
      "Reconstruction: 0.198345, Regularization: 0.021830, Discriminator: 0.147462; Generator: 0.034425,\n",
      "D(x): 0.273, D(G(z)): 0.345\n",
      "2019-04-09 22:58:26,535 root         INFO     Train Epoch: 1 [1536/8000 (19%)]\tTotal Loss: 0.415539\n",
      "Reconstruction: 0.221208, Regularization: 0.020884, Discriminator: 0.141076; Generator: 0.032372,\n",
      "D(x): 0.319, D(G(z)): 0.363\n",
      "2019-04-09 22:58:26,633 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 0.478887\n",
      "Reconstruction: 0.267194, Regularization: 0.027835, Discriminator: 0.151912; Generator: 0.031946,\n",
      "D(x): 0.258, D(G(z)): 0.371\n",
      "2019-04-09 22:58:26,731 root         INFO     Train Epoch: 1 [2560/8000 (32%)]\tTotal Loss: 0.420337\n",
      "Reconstruction: 0.217171, Regularization: 0.017669, Discriminator: 0.152946; Generator: 0.032551,\n",
      "D(x): 0.211, D(G(z)): 0.362\n",
      "2019-04-09 22:58:26,829 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 0.474749\n",
      "Reconstruction: 0.244030, Regularization: 0.026220, Discriminator: 0.174500; Generator: 0.029999,\n",
      "D(x): 0.185, D(G(z)): 0.397\n",
      "2019-04-09 22:58:26,927 root         INFO     Train Epoch: 1 [3584/8000 (45%)]\tTotal Loss: 0.472813\n",
      "Reconstruction: 0.232577, Regularization: 0.022651, Discriminator: 0.187420; Generator: 0.030165,\n",
      "D(x): 0.118, D(G(z)): 0.393\n",
      "2019-04-09 22:58:27,030 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 0.389501\n",
      "Reconstruction: 0.202658, Regularization: 0.016109, Discriminator: 0.139823; Generator: 0.030911,\n",
      "D(x): 0.236, D(G(z)): 0.384\n",
      "2019-04-09 22:58:27,132 root         INFO     Train Epoch: 1 [4608/8000 (58%)]\tTotal Loss: 0.444922\n",
      "Reconstruction: 0.231795, Regularization: 0.017641, Discriminator: 0.168446; Generator: 0.027040,\n",
      "D(x): 0.250, D(G(z)): 0.436\n",
      "2019-04-09 22:58:27,233 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 0.409583\n",
      "Reconstruction: 0.207551, Regularization: 0.014880, Discriminator: 0.157706; Generator: 0.029446,\n",
      "D(x): 0.231, D(G(z)): 0.396\n",
      "2019-04-09 22:58:27,334 root         INFO     Train Epoch: 1 [5632/8000 (70%)]\tTotal Loss: 0.386734\n",
      "Reconstruction: 0.201859, Regularization: 0.017827, Discriminator: 0.136291; Generator: 0.030757,\n",
      "D(x): 0.281, D(G(z)): 0.380\n",
      "2019-04-09 22:58:27,436 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 0.392729\n",
      "Reconstruction: 0.206531, Regularization: 0.017473, Discriminator: 0.137750; Generator: 0.030975,\n",
      "D(x): 0.281, D(G(z)): 0.380\n",
      "2019-04-09 22:58:27,537 root         INFO     Train Epoch: 1 [6656/8000 (83%)]\tTotal Loss: 0.497048\n",
      "Reconstruction: 0.267724, Regularization: 0.020376, Discriminator: 0.180008; Generator: 0.028940,\n",
      "D(x): 0.177, D(G(z)): 0.403\n",
      "2019-04-09 22:58:27,638 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 0.454136\n",
      "Reconstruction: 0.260929, Regularization: 0.021125, Discriminator: 0.145011; Generator: 0.027071,\n",
      "D(x): 0.273, D(G(z)): 0.433\n",
      "2019-04-09 22:58:27,740 root         INFO     Train Epoch: 1 [7680/8000 (96%)]\tTotal Loss: 0.337997\n",
      "Reconstruction: 0.174144, Regularization: 0.020434, Discriminator: 0.116752; Generator: 0.026668,\n",
      "D(x): 0.255, D(G(z)): 0.436\n",
      "2019-04-09 22:58:27,815 root         INFO     ====> Epoch: 1 Average loss: 0.4225\n",
      "2019-04-09 22:58:27,842 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 0.384492\n",
      "Reconstruction: 0.213195, Regularization: 0.020601, Discriminator: 0.123147; Generator: 0.027549,\n",
      "D(x): 0.328, D(G(z)): 0.423\n",
      "2019-04-09 22:58:27,943 root         INFO     Train Epoch: 2 [512/8000 (6%)]\tTotal Loss: 0.418733\n",
      "Reconstruction: 0.238835, Regularization: 0.022556, Discriminator: 0.131187; Generator: 0.026155,\n",
      "D(x): 0.326, D(G(z)): 0.440\n",
      "2019-04-09 22:58:28,043 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 0.444440\n",
      "Reconstruction: 0.252608, Regularization: 0.022683, Discriminator: 0.143226; Generator: 0.025923,\n",
      "D(x): 0.257, D(G(z)): 0.442\n",
      "2019-04-09 22:58:28,142 root         INFO     Train Epoch: 2 [1536/8000 (19%)]\tTotal Loss: 0.351453\n",
      "Reconstruction: 0.183197, Regularization: 0.019577, Discriminator: 0.123700; Generator: 0.024979,\n",
      "D(x): 0.269, D(G(z)): 0.454\n",
      "2019-04-09 22:58:28,242 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 0.373001\n",
      "Reconstruction: 0.190211, Regularization: 0.020076, Discriminator: 0.139104; Generator: 0.023610,\n",
      "D(x): 0.221, D(G(z)): 0.476\n",
      "2019-04-09 22:58:28,341 root         INFO     Train Epoch: 2 [2560/8000 (32%)]\tTotal Loss: 0.434133\n",
      "Reconstruction: 0.262337, Regularization: 0.016905, Discriminator: 0.129539; Generator: 0.025352,\n",
      "D(x): 0.384, D(G(z)): 0.454\n",
      "2019-04-09 22:58:28,441 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 0.337895\n",
      "Reconstruction: 0.183919, Regularization: 0.023657, Discriminator: 0.102907; Generator: 0.027413,\n",
      "D(x): 0.328, D(G(z)): 0.422\n",
      "2019-04-09 22:58:28,541 root         INFO     Train Epoch: 2 [3584/8000 (45%)]\tTotal Loss: 0.479129\n",
      "Reconstruction: 0.263226, Regularization: 0.021416, Discriminator: 0.170447; Generator: 0.024040,\n",
      "D(x): 0.149, D(G(z)): 0.469\n",
      "2019-04-09 22:58:28,640 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 0.382740\n",
      "Reconstruction: 0.212143, Regularization: 0.017334, Discriminator: 0.130019; Generator: 0.023245,\n",
      "D(x): 0.289, D(G(z)): 0.487\n",
      "2019-04-09 22:58:28,740 root         INFO     Train Epoch: 2 [4608/8000 (58%)]\tTotal Loss: 0.416701\n",
      "Reconstruction: 0.225465, Regularization: 0.016676, Discriminator: 0.150552; Generator: 0.024008,\n",
      "D(x): 0.250, D(G(z)): 0.468\n",
      "2019-04-09 22:58:28,839 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 0.362695\n",
      "Reconstruction: 0.193369, Regularization: 0.021248, Discriminator: 0.125192; Generator: 0.022885,\n",
      "D(x): 0.284, D(G(z)): 0.485\n",
      "2019-04-09 22:58:28,939 root         INFO     Train Epoch: 2 [5632/8000 (70%)]\tTotal Loss: 0.338718\n",
      "Reconstruction: 0.173968, Regularization: 0.019958, Discriminator: 0.121300; Generator: 0.023491,\n",
      "D(x): 0.257, D(G(z)): 0.480\n",
      "2019-04-09 22:58:29,039 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 0.366127\n",
      "Reconstruction: 0.198923, Regularization: 0.019901, Discriminator: 0.125169; Generator: 0.022134,\n",
      "D(x): 0.249, D(G(z)): 0.498\n",
      "2019-04-09 22:58:29,138 root         INFO     Train Epoch: 2 [6656/8000 (83%)]\tTotal Loss: 0.376784\n",
      "Reconstruction: 0.214020, Regularization: 0.011939, Discriminator: 0.127699; Generator: 0.023126,\n",
      "D(x): 0.271, D(G(z)): 0.483\n",
      "2019-04-09 22:58:29,238 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 0.460167\n",
      "Reconstruction: 0.265298, Regularization: 0.019093, Discriminator: 0.153516; Generator: 0.022260,\n",
      "D(x): 0.187, D(G(z)): 0.494\n",
      "2019-04-09 22:58:29,338 root         INFO     Train Epoch: 2 [7680/8000 (96%)]\tTotal Loss: 0.412422\n",
      "Reconstruction: 0.241306, Regularization: 0.017838, Discriminator: 0.131110; Generator: 0.022168,\n",
      "D(x): 0.241, D(G(z)): 0.494\n",
      "2019-04-09 22:58:29,412 root         INFO     ====> Epoch: 2 Average loss: 0.3908\n",
      "2019-04-09 22:58:29,439 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 0.358079\n",
      "Reconstruction: 0.204662, Regularization: 0.026874, Discriminator: 0.104033; Generator: 0.022509,\n",
      "D(x): 0.359, D(G(z)): 0.492\n",
      "2019-04-09 22:58:29,541 root         INFO     Train Epoch: 3 [512/8000 (6%)]\tTotal Loss: 0.287907\n",
      "Reconstruction: 0.159414, Regularization: 0.014303, Discriminator: 0.093012; Generator: 0.021179,\n",
      "D(x): 0.387, D(G(z)): 0.513\n",
      "2019-04-09 22:58:29,642 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 0.358843\n",
      "Reconstruction: 0.215751, Regularization: 0.016970, Discriminator: 0.103769; Generator: 0.022353,\n",
      "D(x): 0.412, D(G(z)): 0.493\n",
      "2019-04-09 22:58:29,741 root         INFO     Train Epoch: 3 [1536/8000 (19%)]\tTotal Loss: 0.328803\n",
      "Reconstruction: 0.186675, Regularization: 0.017423, Discriminator: 0.103525; Generator: 0.021179,\n",
      "D(x): 0.339, D(G(z)): 0.512\n",
      "2019-04-09 22:58:29,840 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 0.354818\n",
      "Reconstruction: 0.191855, Regularization: 0.016558, Discriminator: 0.124252; Generator: 0.022153,\n",
      "D(x): 0.180, D(G(z)): 0.498\n",
      "2019-04-09 22:58:29,939 root         INFO     Train Epoch: 3 [2560/8000 (32%)]\tTotal Loss: 0.297044\n",
      "Reconstruction: 0.163241, Regularization: 0.016086, Discriminator: 0.097926; Generator: 0.019791,\n",
      "D(x): 0.349, D(G(z)): 0.534\n",
      "2019-04-09 22:58:30,039 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 0.381651\n",
      "Reconstruction: 0.230001, Regularization: 0.019936, Discriminator: 0.110840; Generator: 0.020873,\n",
      "D(x): 0.307, D(G(z)): 0.517\n",
      "2019-04-09 22:58:30,137 root         INFO     Train Epoch: 3 [3584/8000 (45%)]\tTotal Loss: 0.366341\n",
      "Reconstruction: 0.207301, Regularization: 0.022873, Discriminator: 0.115235; Generator: 0.020932,\n",
      "D(x): 0.271, D(G(z)): 0.515\n",
      "2019-04-09 22:58:30,234 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 0.369103\n",
      "Reconstruction: 0.201225, Regularization: 0.012523, Discriminator: 0.135195; Generator: 0.020159,\n",
      "D(x): 0.152, D(G(z)): 0.528\n",
      "2019-04-09 22:58:30,330 root         INFO     Train Epoch: 3 [4608/8000 (58%)]\tTotal Loss: 0.348273\n",
      "Reconstruction: 0.202511, Regularization: 0.016393, Discriminator: 0.109169; Generator: 0.020200,\n",
      "D(x): 0.299, D(G(z)): 0.529\n",
      "2019-04-09 22:58:30,429 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 0.315951\n",
      "Reconstruction: 0.170908, Regularization: 0.019785, Discriminator: 0.104633; Generator: 0.020625,\n",
      "D(x): 0.255, D(G(z)): 0.523\n",
      "2019-04-09 22:58:30,528 root         INFO     Train Epoch: 3 [5632/8000 (70%)]\tTotal Loss: 0.328315\n",
      "Reconstruction: 0.188212, Regularization: 0.017700, Discriminator: 0.103609; Generator: 0.018794,\n",
      "D(x): 0.334, D(G(z)): 0.553\n",
      "2019-04-09 22:58:30,627 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 0.292368\n",
      "Reconstruction: 0.176310, Regularization: 0.013743, Discriminator: 0.082892; Generator: 0.019422,\n",
      "D(x): 0.420, D(G(z)): 0.540\n",
      "2019-04-09 22:58:30,726 root         INFO     Train Epoch: 3 [6656/8000 (83%)]\tTotal Loss: 0.345224\n",
      "Reconstruction: 0.204702, Regularization: 0.013120, Discriminator: 0.107362; Generator: 0.020040,\n",
      "D(x): 0.308, D(G(z)): 0.530\n",
      "2019-04-09 22:58:30,829 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 0.324151\n",
      "Reconstruction: 0.177973, Regularization: 0.012836, Discriminator: 0.113690; Generator: 0.019653,\n",
      "D(x): 0.211, D(G(z)): 0.536\n",
      "2019-04-09 22:58:30,931 root         INFO     Train Epoch: 3 [7680/8000 (96%)]\tTotal Loss: 0.334320\n",
      "Reconstruction: 0.202385, Regularization: 0.014073, Discriminator: 0.099377; Generator: 0.018484,\n",
      "D(x): 0.328, D(G(z)): 0.558\n",
      "2019-04-09 22:58:31,007 root         INFO     ====> Epoch: 3 Average loss: 0.3682\n",
      "2019-04-09 22:58:31,033 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 0.344730\n",
      "Reconstruction: 0.196889, Regularization: 0.012981, Discriminator: 0.116029; Generator: 0.018832,\n",
      "D(x): 0.208, D(G(z)): 0.552\n",
      "2019-04-09 22:58:31,135 root         INFO     Train Epoch: 4 [512/8000 (6%)]\tTotal Loss: 0.347969\n",
      "Reconstruction: 0.204619, Regularization: 0.016925, Discriminator: 0.107503; Generator: 0.018923,\n",
      "D(x): 0.309, D(G(z)): 0.548\n",
      "2019-04-09 22:58:31,237 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 0.371119\n",
      "Reconstruction: 0.227085, Regularization: 0.014060, Discriminator: 0.110017; Generator: 0.019957,\n",
      "D(x): 0.309, D(G(z)): 0.533\n",
      "2019-04-09 22:58:31,338 root         INFO     Train Epoch: 4 [1536/8000 (19%)]\tTotal Loss: 0.341069\n",
      "Reconstruction: 0.220626, Regularization: 0.016600, Discriminator: 0.085752; Generator: 0.018090,\n",
      "D(x): 0.416, D(G(z)): 0.563\n",
      "2019-04-09 22:58:31,440 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 0.349737\n",
      "Reconstruction: 0.221795, Regularization: 0.019993, Discriminator: 0.088754; Generator: 0.019195,\n",
      "D(x): 0.410, D(G(z)): 0.545\n",
      "2019-04-09 22:58:31,541 root         INFO     Train Epoch: 4 [2560/8000 (32%)]\tTotal Loss: 0.327382\n",
      "Reconstruction: 0.182042, Regularization: 0.017855, Discriminator: 0.109771; Generator: 0.017714,\n",
      "D(x): 0.215, D(G(z)): 0.571\n",
      "2019-04-09 22:58:31,642 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 0.362844\n",
      "Reconstruction: 0.231079, Regularization: 0.016111, Discriminator: 0.097161; Generator: 0.018493,\n",
      "D(x): 0.404, D(G(z)): 0.556\n",
      "2019-04-09 22:58:31,744 root         INFO     Train Epoch: 4 [3584/8000 (45%)]\tTotal Loss: 0.359341\n",
      "Reconstruction: 0.215494, Regularization: 0.019288, Discriminator: 0.107173; Generator: 0.017386,\n",
      "D(x): 0.304, D(G(z)): 0.578\n",
      "2019-04-09 22:58:31,846 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 0.421067\n",
      "Reconstruction: 0.269542, Regularization: 0.018489, Discriminator: 0.114181; Generator: 0.018856,\n",
      "D(x): 0.276, D(G(z)): 0.552\n",
      "2019-04-09 22:58:31,948 root         INFO     Train Epoch: 4 [4608/8000 (58%)]\tTotal Loss: 0.370534\n",
      "Reconstruction: 0.229193, Regularization: 0.015324, Discriminator: 0.107216; Generator: 0.018802,\n",
      "D(x): 0.279, D(G(z)): 0.550\n",
      "2019-04-09 22:58:32,050 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 0.375902\n",
      "Reconstruction: 0.231646, Regularization: 0.016384, Discriminator: 0.109519; Generator: 0.018354,\n",
      "D(x): 0.295, D(G(z)): 0.558\n",
      "2019-04-09 22:58:32,152 root         INFO     Train Epoch: 4 [5632/8000 (70%)]\tTotal Loss: 0.314773\n",
      "Reconstruction: 0.194324, Regularization: 0.016092, Discriminator: 0.087178; Generator: 0.017178,\n",
      "D(x): 0.379, D(G(z)): 0.580\n",
      "2019-04-09 22:58:32,254 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 0.354848\n",
      "Reconstruction: 0.224743, Regularization: 0.016884, Discriminator: 0.096991; Generator: 0.016229,\n",
      "D(x): 0.290, D(G(z)): 0.597\n",
      "2019-04-09 22:58:32,355 root         INFO     Train Epoch: 4 [6656/8000 (83%)]\tTotal Loss: 0.337590\n",
      "Reconstruction: 0.217270, Regularization: 0.015875, Discriminator: 0.087816; Generator: 0.016629,\n",
      "D(x): 0.352, D(G(z)): 0.589\n",
      "2019-04-09 22:58:32,457 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 0.314153\n",
      "Reconstruction: 0.195469, Regularization: 0.010427, Discriminator: 0.091946; Generator: 0.016310,\n",
      "D(x): 0.363, D(G(z)): 0.595\n",
      "2019-04-09 22:58:32,559 root         INFO     Train Epoch: 4 [7680/8000 (96%)]\tTotal Loss: 0.345567\n",
      "Reconstruction: 0.227212, Regularization: 0.017073, Discriminator: 0.083916; Generator: 0.017366,\n",
      "D(x): 0.408, D(G(z)): 0.576\n",
      "2019-04-09 22:58:32,634 root         INFO     ====> Epoch: 4 Average loss: 0.3523\n",
      "2019-04-09 22:58:32,661 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 0.412712\n",
      "Reconstruction: 0.263806, Regularization: 0.012543, Discriminator: 0.119420; Generator: 0.016944,\n",
      "D(x): 0.272, D(G(z)): 0.584\n",
      "2019-04-09 22:58:32,761 root         INFO     Train Epoch: 5 [512/8000 (6%)]\tTotal Loss: 0.301591\n",
      "Reconstruction: 0.171787, Regularization: 0.016685, Discriminator: 0.096313; Generator: 0.016806,\n",
      "D(x): 0.257, D(G(z)): 0.586\n",
      "2019-04-09 22:58:32,862 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 0.270381\n",
      "Reconstruction: 0.151123, Regularization: 0.020756, Discriminator: 0.081429; Generator: 0.017073,\n",
      "D(x): 0.376, D(G(z)): 0.581\n",
      "2019-04-09 22:58:32,962 root         INFO     Train Epoch: 5 [1536/8000 (19%)]\tTotal Loss: 0.429011\n",
      "Reconstruction: 0.271627, Regularization: 0.016183, Discriminator: 0.124361; Generator: 0.016841,\n",
      "D(x): 0.158, D(G(z)): 0.586\n",
      "2019-04-09 22:58:33,063 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 0.350023\n",
      "Reconstruction: 0.211208, Regularization: 0.013694, Discriminator: 0.108548; Generator: 0.016573,\n",
      "D(x): 0.236, D(G(z)): 0.590\n",
      "2019-04-09 22:58:33,164 root         INFO     Train Epoch: 5 [2560/8000 (32%)]\tTotal Loss: 0.403424\n",
      "Reconstruction: 0.262726, Regularization: 0.012671, Discriminator: 0.112012; Generator: 0.016014,\n",
      "D(x): 0.258, D(G(z)): 0.601\n",
      "2019-04-09 22:58:33,265 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 0.420091\n",
      "Reconstruction: 0.276697, Regularization: 0.014334, Discriminator: 0.112755; Generator: 0.016305,\n",
      "D(x): 0.300, D(G(z)): 0.596\n",
      "2019-04-09 22:58:33,366 root         INFO     Train Epoch: 5 [3584/8000 (45%)]\tTotal Loss: 0.390604\n",
      "Reconstruction: 0.254952, Regularization: 0.016732, Discriminator: 0.101320; Generator: 0.017600,\n",
      "D(x): 0.326, D(G(z)): 0.572\n",
      "2019-04-09 22:58:33,467 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 0.335497\n",
      "Reconstruction: 0.206376, Regularization: 0.013772, Discriminator: 0.098725; Generator: 0.016625,\n",
      "D(x): 0.285, D(G(z)): 0.589\n",
      "2019-04-09 22:58:33,567 root         INFO     Train Epoch: 5 [4608/8000 (58%)]\tTotal Loss: 0.322343\n",
      "Reconstruction: 0.197511, Regularization: 0.017120, Discriminator: 0.090688; Generator: 0.017024,\n",
      "D(x): 0.312, D(G(z)): 0.581\n",
      "2019-04-09 22:58:33,668 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 0.324765\n",
      "Reconstruction: 0.198167, Regularization: 0.016054, Discriminator: 0.094361; Generator: 0.016183,\n",
      "D(x): 0.271, D(G(z)): 0.599\n",
      "2019-04-09 22:58:33,769 root         INFO     Train Epoch: 5 [5632/8000 (70%)]\tTotal Loss: 0.377898\n",
      "Reconstruction: 0.241042, Regularization: 0.013615, Discriminator: 0.106468; Generator: 0.016773,\n",
      "D(x): 0.259, D(G(z)): 0.587\n",
      "2019-04-09 22:58:33,870 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 0.303358\n",
      "Reconstruction: 0.186487, Regularization: 0.014063, Discriminator: 0.086610; Generator: 0.016198,\n",
      "D(x): 0.357, D(G(z)): 0.597\n",
      "2019-04-09 22:58:33,971 root         INFO     Train Epoch: 5 [6656/8000 (83%)]\tTotal Loss: 0.358044\n",
      "Reconstruction: 0.232548, Regularization: 0.016526, Discriminator: 0.093278; Generator: 0.015692,\n",
      "D(x): 0.338, D(G(z)): 0.606\n",
      "2019-04-09 22:58:34,071 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 0.313885\n",
      "Reconstruction: 0.197819, Regularization: 0.011387, Discriminator: 0.088461; Generator: 0.016218,\n",
      "D(x): 0.370, D(G(z)): 0.598\n",
      "2019-04-09 22:58:34,172 root         INFO     Train Epoch: 5 [7680/8000 (96%)]\tTotal Loss: 0.298328\n",
      "Reconstruction: 0.187830, Regularization: 0.019925, Discriminator: 0.074448; Generator: 0.016126,\n",
      "D(x): 0.422, D(G(z)): 0.599\n",
      "2019-04-09 22:58:34,246 root         INFO     ====> Epoch: 5 Average loss: 0.3404\n",
      "2019-04-09 22:58:34,273 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 0.322620\n",
      "Reconstruction: 0.209265, Regularization: 0.009450, Discriminator: 0.087519; Generator: 0.016387,\n",
      "D(x): 0.353, D(G(z)): 0.593\n",
      "2019-04-09 22:58:34,371 root         INFO     Train Epoch: 6 [512/8000 (6%)]\tTotal Loss: 0.291382\n",
      "Reconstruction: 0.178790, Regularization: 0.012555, Discriminator: 0.084220; Generator: 0.015817,\n",
      "D(x): 0.356, D(G(z)): 0.604\n",
      "2019-04-09 22:58:34,470 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 0.382384\n",
      "Reconstruction: 0.264546, Regularization: 0.009570, Discriminator: 0.092160; Generator: 0.016107,\n",
      "D(x): 0.404, D(G(z)): 0.598\n",
      "2019-04-09 22:58:34,569 root         INFO     Train Epoch: 6 [1536/8000 (19%)]\tTotal Loss: 0.320635\n",
      "Reconstruction: 0.208347, Regularization: 0.010246, Discriminator: 0.085733; Generator: 0.016308,\n",
      "D(x): 0.358, D(G(z)): 0.596\n",
      "2019-04-09 22:58:34,667 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 0.302378\n",
      "Reconstruction: 0.192676, Regularization: 0.013226, Discriminator: 0.079512; Generator: 0.016964,\n",
      "D(x): 0.368, D(G(z)): 0.583\n",
      "2019-04-09 22:58:34,765 root         INFO     Train Epoch: 6 [2560/8000 (32%)]\tTotal Loss: 0.343334\n",
      "Reconstruction: 0.226543, Regularization: 0.014939, Discriminator: 0.085894; Generator: 0.015958,\n",
      "D(x): 0.364, D(G(z)): 0.603\n",
      "2019-04-09 22:58:34,864 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 0.339580\n",
      "Reconstruction: 0.224287, Regularization: 0.011004, Discriminator: 0.088940; Generator: 0.015349,\n",
      "D(x): 0.349, D(G(z)): 0.613\n",
      "2019-04-09 22:58:34,963 root         INFO     Train Epoch: 6 [3584/8000 (45%)]\tTotal Loss: 0.307132\n",
      "Reconstruction: 0.204398, Regularization: 0.012725, Discriminator: 0.074506; Generator: 0.015502,\n",
      "D(x): 0.445, D(G(z)): 0.610\n",
      "2019-04-09 22:58:35,062 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 0.410566\n",
      "Reconstruction: 0.283380, Regularization: 0.011043, Discriminator: 0.099744; Generator: 0.016399,\n",
      "D(x): 0.308, D(G(z)): 0.594\n",
      "2019-04-09 22:58:35,160 root         INFO     Train Epoch: 6 [4608/8000 (58%)]\tTotal Loss: 0.368397\n",
      "Reconstruction: 0.249125, Regularization: 0.013497, Discriminator: 0.089603; Generator: 0.016172,\n",
      "D(x): 0.345, D(G(z)): 0.598\n",
      "2019-04-09 22:58:35,257 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 0.300802\n",
      "Reconstruction: 0.191422, Regularization: 0.012114, Discriminator: 0.082102; Generator: 0.015164,\n",
      "D(x): 0.330, D(G(z)): 0.617\n",
      "2019-04-09 22:58:35,355 root         INFO     Train Epoch: 6 [5632/8000 (70%)]\tTotal Loss: 0.323574\n",
      "Reconstruction: 0.202566, Regularization: 0.016605, Discriminator: 0.088125; Generator: 0.016279,\n",
      "D(x): 0.264, D(G(z)): 0.596\n",
      "2019-04-09 22:58:35,453 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 0.394762\n",
      "Reconstruction: 0.267269, Regularization: 0.011249, Discriminator: 0.100624; Generator: 0.015620,\n",
      "D(x): 0.259, D(G(z)): 0.607\n",
      "2019-04-09 22:58:35,551 root         INFO     Train Epoch: 6 [6656/8000 (83%)]\tTotal Loss: 0.334829\n",
      "Reconstruction: 0.221340, Regularization: 0.011100, Discriminator: 0.086276; Generator: 0.016112,\n",
      "D(x): 0.330, D(G(z)): 0.599\n",
      "2019-04-09 22:58:35,649 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 0.302297\n",
      "Reconstruction: 0.188548, Regularization: 0.013613, Discriminator: 0.084187; Generator: 0.015950,\n",
      "D(x): 0.304, D(G(z)): 0.602\n",
      "2019-04-09 22:58:35,747 root         INFO     Train Epoch: 6 [7680/8000 (96%)]\tTotal Loss: 0.317286\n",
      "Reconstruction: 0.205424, Regularization: 0.009569, Discriminator: 0.086579; Generator: 0.015714,\n",
      "D(x): 0.311, D(G(z)): 0.606\n",
      "2019-04-09 22:58:35,822 root         INFO     ====> Epoch: 6 Average loss: 0.3318\n",
      "2019-04-09 22:58:35,848 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 0.307234\n",
      "Reconstruction: 0.194066, Regularization: 0.016654, Discriminator: 0.080420; Generator: 0.016094,\n",
      "D(x): 0.380, D(G(z)): 0.599\n",
      "2019-04-09 22:58:35,950 root         INFO     Train Epoch: 7 [512/8000 (6%)]\tTotal Loss: 0.353129\n",
      "Reconstruction: 0.239426, Regularization: 0.013250, Discriminator: 0.085136; Generator: 0.015317,\n",
      "D(x): 0.384, D(G(z)): 0.613\n",
      "2019-04-09 22:58:36,047 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 0.305457\n",
      "Reconstruction: 0.198089, Regularization: 0.013020, Discriminator: 0.078877; Generator: 0.015471,\n",
      "D(x): 0.365, D(G(z)): 0.610\n",
      "2019-04-09 22:58:36,144 root         INFO     Train Epoch: 7 [1536/8000 (19%)]\tTotal Loss: 0.289712\n",
      "Reconstruction: 0.193337, Regularization: 0.010607, Discriminator: 0.069288; Generator: 0.016479,\n",
      "D(x): 0.435, D(G(z)): 0.592\n",
      "2019-04-09 22:58:36,241 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 0.322415\n",
      "Reconstruction: 0.214337, Regularization: 0.013331, Discriminator: 0.079185; Generator: 0.015562,\n",
      "D(x): 0.391, D(G(z)): 0.609\n",
      "2019-04-09 22:58:36,340 root         INFO     Train Epoch: 7 [2560/8000 (32%)]\tTotal Loss: 0.328848\n",
      "Reconstruction: 0.218523, Regularization: 0.012660, Discriminator: 0.081864; Generator: 0.015802,\n",
      "D(x): 0.337, D(G(z)): 0.604\n",
      "2019-04-09 22:58:36,438 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 0.312835\n",
      "Reconstruction: 0.206922, Regularization: 0.012626, Discriminator: 0.077142; Generator: 0.016145,\n",
      "D(x): 0.378, D(G(z)): 0.597\n",
      "2019-04-09 22:58:36,536 root         INFO     Train Epoch: 7 [3584/8000 (45%)]\tTotal Loss: 0.273114\n",
      "Reconstruction: 0.171377, Regularization: 0.014318, Discriminator: 0.071377; Generator: 0.016041,\n",
      "D(x): 0.383, D(G(z)): 0.600\n",
      "2019-04-09 22:58:36,634 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 0.393454\n",
      "Reconstruction: 0.273035, Regularization: 0.013230, Discriminator: 0.091359; Generator: 0.015830,\n",
      "D(x): 0.297, D(G(z)): 0.604\n",
      "2019-04-09 22:58:36,732 root         INFO     Train Epoch: 7 [4608/8000 (58%)]\tTotal Loss: 0.347627\n",
      "Reconstruction: 0.230361, Regularization: 0.010120, Discriminator: 0.091504; Generator: 0.015642,\n",
      "D(x): 0.258, D(G(z)): 0.607\n",
      "2019-04-09 22:58:36,830 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 0.344131\n",
      "Reconstruction: 0.229028, Regularization: 0.011678, Discriminator: 0.087654; Generator: 0.015771,\n",
      "D(x): 0.283, D(G(z)): 0.605\n",
      "2019-04-09 22:58:36,928 root         INFO     Train Epoch: 7 [5632/8000 (70%)]\tTotal Loss: 0.315494\n",
      "Reconstruction: 0.209632, Regularization: 0.012218, Discriminator: 0.077464; Generator: 0.016180,\n",
      "D(x): 0.355, D(G(z)): 0.597\n",
      "2019-04-09 22:58:37,026 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 0.334305\n",
      "Reconstruction: 0.227102, Regularization: 0.011560, Discriminator: 0.079933; Generator: 0.015710,\n",
      "D(x): 0.353, D(G(z)): 0.605\n",
      "2019-04-09 22:58:37,124 root         INFO     Train Epoch: 7 [6656/8000 (83%)]\tTotal Loss: 0.342207\n",
      "Reconstruction: 0.237083, Regularization: 0.009019, Discriminator: 0.080910; Generator: 0.015196,\n",
      "D(x): 0.345, D(G(z)): 0.616\n",
      "2019-04-09 22:58:37,221 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 0.348442\n",
      "Reconstruction: 0.240015, Regularization: 0.010596, Discriminator: 0.082879; Generator: 0.014951,\n",
      "D(x): 0.329, D(G(z)): 0.621\n",
      "2019-04-09 22:58:37,319 root         INFO     Train Epoch: 7 [7680/8000 (96%)]\tTotal Loss: 0.389643\n",
      "Reconstruction: 0.282562, Regularization: 0.010458, Discriminator: 0.081065; Generator: 0.015558,\n",
      "D(x): 0.375, D(G(z)): 0.609\n",
      "2019-04-09 22:58:37,392 root         INFO     ====> Epoch: 7 Average loss: 0.3247\n",
      "2019-04-09 22:58:37,419 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 0.313251\n",
      "Reconstruction: 0.202646, Regularization: 0.014470, Discriminator: 0.080788; Generator: 0.015347,\n",
      "D(x): 0.296, D(G(z)): 0.613\n",
      "2019-04-09 22:58:37,521 root         INFO     Train Epoch: 8 [512/8000 (6%)]\tTotal Loss: 0.274458\n",
      "Reconstruction: 0.173277, Regularization: 0.010671, Discriminator: 0.074793; Generator: 0.015717,\n",
      "D(x): 0.322, D(G(z)): 0.606\n",
      "2019-04-09 22:58:37,623 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 0.330416\n",
      "Reconstruction: 0.223686, Regularization: 0.016004, Discriminator: 0.074898; Generator: 0.015827,\n",
      "D(x): 0.366, D(G(z)): 0.603\n",
      "2019-04-09 22:58:37,723 root         INFO     Train Epoch: 8 [1536/8000 (19%)]\tTotal Loss: 0.367348\n",
      "Reconstruction: 0.258358, Regularization: 0.011506, Discriminator: 0.081896; Generator: 0.015589,\n",
      "D(x): 0.356, D(G(z)): 0.608\n",
      "2019-04-09 22:58:37,824 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 0.281572\n",
      "Reconstruction: 0.184257, Regularization: 0.009414, Discriminator: 0.072097; Generator: 0.015804,\n",
      "D(x): 0.352, D(G(z)): 0.604\n",
      "2019-04-09 22:58:37,925 root         INFO     Train Epoch: 8 [2560/8000 (32%)]\tTotal Loss: 0.320970\n",
      "Reconstruction: 0.221956, Regularization: 0.011192, Discriminator: 0.072502; Generator: 0.015320,\n",
      "D(x): 0.361, D(G(z)): 0.613\n",
      "2019-04-09 22:58:38,025 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 0.371164\n",
      "Reconstruction: 0.261199, Regularization: 0.011748, Discriminator: 0.082017; Generator: 0.016200,\n",
      "D(x): 0.302, D(G(z)): 0.596\n",
      "2019-04-09 22:58:38,126 root         INFO     Train Epoch: 8 [3584/8000 (45%)]\tTotal Loss: 0.327762\n",
      "Reconstruction: 0.219627, Regularization: 0.011196, Discriminator: 0.081209; Generator: 0.015729,\n",
      "D(x): 0.318, D(G(z)): 0.605\n",
      "2019-04-09 22:58:38,226 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 0.313966\n",
      "Reconstruction: 0.213776, Regularization: 0.008268, Discriminator: 0.075859; Generator: 0.016062,\n",
      "D(x): 0.347, D(G(z)): 0.599\n",
      "2019-04-09 22:58:38,326 root         INFO     Train Epoch: 8 [4608/8000 (58%)]\tTotal Loss: 0.351170\n",
      "Reconstruction: 0.248208, Regularization: 0.011709, Discriminator: 0.075590; Generator: 0.015663,\n",
      "D(x): 0.355, D(G(z)): 0.607\n",
      "2019-04-09 22:58:38,427 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 0.449528\n",
      "Reconstruction: 0.333248, Regularization: 0.011920, Discriminator: 0.088319; Generator: 0.016041,\n",
      "D(x): 0.288, D(G(z)): 0.599\n",
      "2019-04-09 22:58:38,528 root         INFO     Train Epoch: 8 [5632/8000 (70%)]\tTotal Loss: 0.351128\n",
      "Reconstruction: 0.247981, Regularization: 0.012954, Discriminator: 0.073898; Generator: 0.016296,\n",
      "D(x): 0.381, D(G(z)): 0.594\n",
      "2019-04-09 22:58:38,629 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 0.286870\n",
      "Reconstruction: 0.194061, Regularization: 0.009679, Discriminator: 0.067531; Generator: 0.015598,\n",
      "D(x): 0.427, D(G(z)): 0.608\n",
      "2019-04-09 22:58:38,729 root         INFO     Train Epoch: 8 [6656/8000 (83%)]\tTotal Loss: 0.294825\n",
      "Reconstruction: 0.194184, Regularization: 0.013202, Discriminator: 0.072194; Generator: 0.015245,\n",
      "D(x): 0.364, D(G(z)): 0.615\n",
      "2019-04-09 22:58:38,829 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 0.289595\n",
      "Reconstruction: 0.193527, Regularization: 0.012584, Discriminator: 0.067818; Generator: 0.015666,\n",
      "D(x): 0.415, D(G(z)): 0.606\n",
      "2019-04-09 22:58:38,929 root         INFO     Train Epoch: 8 [7680/8000 (96%)]\tTotal Loss: 0.260573\n",
      "Reconstruction: 0.167154, Regularization: 0.010851, Discriminator: 0.066525; Generator: 0.016043,\n",
      "D(x): 0.395, D(G(z)): 0.599\n",
      "2019-04-09 22:58:39,005 root         INFO     ====> Epoch: 8 Average loss: 0.3199\n",
      "2019-04-09 22:58:39,032 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 0.316063\n",
      "Reconstruction: 0.218386, Regularization: 0.009093, Discriminator: 0.072858; Generator: 0.015726,\n",
      "D(x): 0.365, D(G(z)): 0.605\n",
      "2019-04-09 22:58:39,134 root         INFO     Train Epoch: 9 [512/8000 (6%)]\tTotal Loss: 0.353739\n",
      "Reconstruction: 0.248529, Regularization: 0.009953, Discriminator: 0.079581; Generator: 0.015676,\n",
      "D(x): 0.302, D(G(z)): 0.606\n",
      "2019-04-09 22:58:39,235 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 0.342139\n",
      "Reconstruction: 0.247668, Regularization: 0.009615, Discriminator: 0.068276; Generator: 0.016580,\n",
      "D(x): 0.411, D(G(z)): 0.589\n",
      "2019-04-09 22:58:39,336 root         INFO     Train Epoch: 9 [1536/8000 (19%)]\tTotal Loss: 0.266807\n",
      "Reconstruction: 0.173732, Regularization: 0.011189, Discriminator: 0.065487; Generator: 0.016399,\n",
      "D(x): 0.393, D(G(z)): 0.592\n",
      "2019-04-09 22:58:39,437 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 0.234251\n",
      "Reconstruction: 0.151148, Regularization: 0.007805, Discriminator: 0.059206; Generator: 0.016091,\n",
      "D(x): 0.445, D(G(z)): 0.598\n",
      "2019-04-09 22:58:39,538 root         INFO     Train Epoch: 9 [2560/8000 (32%)]\tTotal Loss: 0.376861\n",
      "Reconstruction: 0.267035, Regularization: 0.021235, Discriminator: 0.072828; Generator: 0.015762,\n",
      "D(x): 0.384, D(G(z)): 0.605\n",
      "2019-04-09 22:58:39,638 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 0.302456\n",
      "Reconstruction: 0.204057, Regularization: 0.010255, Discriminator: 0.072309; Generator: 0.015835,\n",
      "D(x): 0.339, D(G(z)): 0.603\n",
      "2019-04-09 22:58:39,738 root         INFO     Train Epoch: 9 [3584/8000 (45%)]\tTotal Loss: 0.350194\n",
      "Reconstruction: 0.253014, Regularization: 0.011461, Discriminator: 0.069926; Generator: 0.015792,\n",
      "D(x): 0.402, D(G(z)): 0.604\n",
      "2019-04-09 22:58:39,837 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 0.340549\n",
      "Reconstruction: 0.240071, Regularization: 0.009913, Discriminator: 0.075074; Generator: 0.015492,\n",
      "D(x): 0.332, D(G(z)): 0.610\n",
      "2019-04-09 22:58:39,936 root         INFO     Train Epoch: 9 [4608/8000 (58%)]\tTotal Loss: 0.351975\n",
      "Reconstruction: 0.253703, Regularization: 0.010018, Discriminator: 0.071990; Generator: 0.016265,\n",
      "D(x): 0.372, D(G(z)): 0.595\n",
      "2019-04-09 22:58:40,038 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 0.311882\n",
      "Reconstruction: 0.215788, Regularization: 0.010729, Discriminator: 0.069130; Generator: 0.016235,\n",
      "D(x): 0.349, D(G(z)): 0.595\n",
      "2019-04-09 22:58:40,139 root         INFO     Train Epoch: 9 [5632/8000 (70%)]\tTotal Loss: 0.370050\n",
      "Reconstruction: 0.263718, Regularization: 0.011394, Discriminator: 0.078668; Generator: 0.016269,\n",
      "D(x): 0.304, D(G(z)): 0.595\n",
      "2019-04-09 22:58:40,240 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 0.355262\n",
      "Reconstruction: 0.252090, Regularization: 0.008862, Discriminator: 0.078487; Generator: 0.015823,\n",
      "D(x): 0.311, D(G(z)): 0.603\n",
      "2019-04-09 22:58:40,341 root         INFO     Train Epoch: 9 [6656/8000 (83%)]\tTotal Loss: 0.308232\n",
      "Reconstruction: 0.212182, Regularization: 0.012381, Discriminator: 0.067366; Generator: 0.016303,\n",
      "D(x): 0.368, D(G(z)): 0.594\n",
      "2019-04-09 22:58:40,442 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 0.285746\n",
      "Reconstruction: 0.192246, Regularization: 0.013852, Discriminator: 0.063878; Generator: 0.015769,\n",
      "D(x): 0.423, D(G(z)): 0.604\n",
      "2019-04-09 22:58:40,543 root         INFO     Train Epoch: 9 [7680/8000 (96%)]\tTotal Loss: 0.367748\n",
      "Reconstruction: 0.267690, Regularization: 0.014843, Discriminator: 0.069074; Generator: 0.016141,\n",
      "D(x): 0.383, D(G(z)): 0.597\n",
      "2019-04-09 22:58:40,618 root         INFO     ====> Epoch: 9 Average loss: 0.3162\n",
      "2019-04-09 22:58:40,644 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 0.314036\n",
      "Reconstruction: 0.228105, Regularization: 0.011824, Discriminator: 0.057904; Generator: 0.016203,\n",
      "D(x): 0.490, D(G(z)): 0.596\n",
      "2019-04-09 22:58:40,744 root         INFO     Train Epoch: 10 [512/8000 (6%)]\tTotal Loss: 0.264384\n",
      "Reconstruction: 0.177866, Regularization: 0.010491, Discriminator: 0.059616; Generator: 0.016411,\n",
      "D(x): 0.438, D(G(z)): 0.592\n",
      "2019-04-09 22:58:40,844 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 0.245703\n",
      "Reconstruction: 0.159686, Regularization: 0.011961, Discriminator: 0.057777; Generator: 0.016280,\n",
      "D(x): 0.460, D(G(z)): 0.594\n",
      "2019-04-09 22:58:40,944 root         INFO     Train Epoch: 10 [1536/8000 (19%)]\tTotal Loss: 0.306706\n",
      "Reconstruction: 0.219061, Regularization: 0.006608, Discriminator: 0.064735; Generator: 0.016301,\n",
      "D(x): 0.416, D(G(z)): 0.594\n",
      "2019-04-09 22:58:41,045 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 0.305690\n",
      "Reconstruction: 0.213858, Regularization: 0.007595, Discriminator: 0.068248; Generator: 0.015988,\n",
      "D(x): 0.364, D(G(z)): 0.600\n",
      "2019-04-09 22:58:41,147 root         INFO     Train Epoch: 10 [2560/8000 (32%)]\tTotal Loss: 0.280141\n",
      "Reconstruction: 0.191151, Regularization: 0.008744, Discriminator: 0.064177; Generator: 0.016068,\n",
      "D(x): 0.394, D(G(z)): 0.598\n",
      "2019-04-09 22:58:41,249 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 0.345769\n",
      "Reconstruction: 0.250137, Regularization: 0.009241, Discriminator: 0.069943; Generator: 0.016447,\n",
      "D(x): 0.356, D(G(z)): 0.591\n",
      "2019-04-09 22:58:41,351 root         INFO     Train Epoch: 10 [3584/8000 (45%)]\tTotal Loss: 0.324898\n",
      "Reconstruction: 0.227278, Regularization: 0.013069, Discriminator: 0.068290; Generator: 0.016261,\n",
      "D(x): 0.365, D(G(z)): 0.595\n",
      "2019-04-09 22:58:41,452 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 0.330821\n",
      "Reconstruction: 0.237150, Regularization: 0.009336, Discriminator: 0.067846; Generator: 0.016488,\n",
      "D(x): 0.398, D(G(z)): 0.590\n",
      "2019-04-09 22:58:41,551 root         INFO     Train Epoch: 10 [4608/8000 (58%)]\tTotal Loss: 0.285060\n",
      "Reconstruction: 0.200012, Regularization: 0.010223, Discriminator: 0.058072; Generator: 0.016753,\n",
      "D(x): 0.461, D(G(z)): 0.585\n",
      "2019-04-09 22:58:41,650 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 0.297785\n",
      "Reconstruction: 0.209924, Regularization: 0.011183, Discriminator: 0.060394; Generator: 0.016283,\n",
      "D(x): 0.425, D(G(z)): 0.594\n",
      "2019-04-09 22:58:41,749 root         INFO     Train Epoch: 10 [5632/8000 (70%)]\tTotal Loss: 0.295514\n",
      "Reconstruction: 0.207885, Regularization: 0.011784, Discriminator: 0.059420; Generator: 0.016425,\n",
      "D(x): 0.442, D(G(z)): 0.592\n",
      "2019-04-09 22:58:41,847 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 0.309766\n",
      "Reconstruction: 0.221285, Regularization: 0.007624, Discriminator: 0.064304; Generator: 0.016553,\n",
      "D(x): 0.391, D(G(z)): 0.589\n",
      "2019-04-09 22:58:41,946 root         INFO     Train Epoch: 10 [6656/8000 (83%)]\tTotal Loss: 0.294741\n",
      "Reconstruction: 0.200369, Regularization: 0.010798, Discriminator: 0.066951; Generator: 0.016623,\n",
      "D(x): 0.334, D(G(z)): 0.588\n",
      "2019-04-09 22:58:42,045 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 0.323116\n",
      "Reconstruction: 0.231616, Regularization: 0.009156, Discriminator: 0.066065; Generator: 0.016280,\n",
      "D(x): 0.380, D(G(z)): 0.594\n",
      "2019-04-09 22:58:42,144 root         INFO     Train Epoch: 10 [7680/8000 (96%)]\tTotal Loss: 0.274711\n",
      "Reconstruction: 0.186771, Regularization: 0.008036, Discriminator: 0.063398; Generator: 0.016507,\n",
      "D(x): 0.387, D(G(z)): 0.590\n",
      "2019-04-09 22:58:42,217 root         INFO     ====> Epoch: 10 Average loss: 0.3133\n",
      "2019-04-09 22:58:42,244 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.349013\n",
      "Reconstruction: 0.255766, Regularization: 0.007128, Discriminator: 0.069721; Generator: 0.016397,\n",
      "D(x): 0.346, D(G(z)): 0.592\n",
      "2019-04-09 22:58:42,345 root         INFO     Train Epoch: 11 [512/8000 (6%)]\tTotal Loss: 0.292860\n",
      "Reconstruction: 0.205214, Regularization: 0.008591, Discriminator: 0.062610; Generator: 0.016445,\n",
      "D(x): 0.413, D(G(z)): 0.591\n",
      "2019-04-09 22:58:42,446 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 0.308856\n",
      "Reconstruction: 0.216812, Regularization: 0.006846, Discriminator: 0.068732; Generator: 0.016466,\n",
      "D(x): 0.326, D(G(z)): 0.591\n",
      "2019-04-09 22:58:42,547 root         INFO     Train Epoch: 11 [1536/8000 (19%)]\tTotal Loss: 0.266955\n",
      "Reconstruction: 0.182202, Regularization: 0.009349, Discriminator: 0.059042; Generator: 0.016362,\n",
      "D(x): 0.450, D(G(z)): 0.593\n",
      "2019-04-09 22:58:42,648 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.325039\n",
      "Reconstruction: 0.233444, Regularization: 0.010936, Discriminator: 0.063945; Generator: 0.016715,\n",
      "D(x): 0.402, D(G(z)): 0.586\n",
      "2019-04-09 22:58:42,749 root         INFO     Train Epoch: 11 [2560/8000 (32%)]\tTotal Loss: 0.363659\n",
      "Reconstruction: 0.269230, Regularization: 0.009716, Discriminator: 0.068171; Generator: 0.016542,\n",
      "D(x): 0.360, D(G(z)): 0.589\n",
      "2019-04-09 22:58:42,850 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 0.288179\n",
      "Reconstruction: 0.206731, Regularization: 0.010054, Discriminator: 0.054876; Generator: 0.016519,\n",
      "D(x): 0.487, D(G(z)): 0.590\n",
      "2019-04-09 22:58:42,949 root         INFO     Train Epoch: 11 [3584/8000 (45%)]\tTotal Loss: 0.270288\n",
      "Reconstruction: 0.185829, Regularization: 0.008565, Discriminator: 0.059108; Generator: 0.016785,\n",
      "D(x): 0.431, D(G(z)): 0.585\n",
      "2019-04-09 22:58:43,049 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 0.331391\n",
      "Reconstruction: 0.237760, Regularization: 0.011118, Discriminator: 0.065728; Generator: 0.016785,\n",
      "D(x): 0.370, D(G(z)): 0.585\n",
      "2019-04-09 22:58:43,146 root         INFO     Train Epoch: 11 [4608/8000 (58%)]\tTotal Loss: 0.311159\n",
      "Reconstruction: 0.219669, Regularization: 0.010217, Discriminator: 0.064592; Generator: 0.016681,\n",
      "D(x): 0.380, D(G(z)): 0.587\n",
      "2019-04-09 22:58:43,242 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 0.313036\n",
      "Reconstruction: 0.224697, Regularization: 0.010989, Discriminator: 0.060575; Generator: 0.016775,\n",
      "D(x): 0.413, D(G(z)): 0.585\n",
      "2019-04-09 22:58:43,338 root         INFO     Train Epoch: 11 [5632/8000 (70%)]\tTotal Loss: 0.359203\n",
      "Reconstruction: 0.269534, Regularization: 0.008384, Discriminator: 0.064616; Generator: 0.016669,\n",
      "D(x): 0.380, D(G(z)): 0.587\n",
      "2019-04-09 22:58:43,435 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.332421\n",
      "Reconstruction: 0.239494, Regularization: 0.010211, Discriminator: 0.065939; Generator: 0.016777,\n",
      "D(x): 0.365, D(G(z)): 0.585\n",
      "2019-04-09 22:58:43,531 root         INFO     Train Epoch: 11 [6656/8000 (83%)]\tTotal Loss: 0.310488\n",
      "Reconstruction: 0.222371, Regularization: 0.009079, Discriminator: 0.061967; Generator: 0.017070,\n",
      "D(x): 0.389, D(G(z)): 0.579\n",
      "2019-04-09 22:58:43,628 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 0.323621\n",
      "Reconstruction: 0.232956, Regularization: 0.010328, Discriminator: 0.063457; Generator: 0.016881,\n",
      "D(x): 0.377, D(G(z)): 0.583\n",
      "2019-04-09 22:58:43,724 root         INFO     Train Epoch: 11 [7680/8000 (96%)]\tTotal Loss: 0.294778\n",
      "Reconstruction: 0.205593, Regularization: 0.013682, Discriminator: 0.058203; Generator: 0.017299,\n",
      "D(x): 0.424, D(G(z)): 0.575\n",
      "2019-04-09 22:58:43,796 root         INFO     ====> Epoch: 11 Average loss: 0.3113\n",
      "2019-04-09 22:58:43,823 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 0.336109\n",
      "Reconstruction: 0.241279, Regularization: 0.012704, Discriminator: 0.065331; Generator: 0.016795,\n",
      "D(x): 0.347, D(G(z)): 0.584\n",
      "2019-04-09 22:58:43,925 root         INFO     Train Epoch: 12 [512/8000 (6%)]\tTotal Loss: 0.279245\n",
      "Reconstruction: 0.193671, Regularization: 0.009686, Discriminator: 0.059256; Generator: 0.016632,\n",
      "D(x): 0.419, D(G(z)): 0.588\n",
      "2019-04-09 22:58:44,027 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 0.283600\n",
      "Reconstruction: 0.201072, Regularization: 0.010026, Discriminator: 0.055571; Generator: 0.016932,\n",
      "D(x): 0.460, D(G(z)): 0.582\n",
      "2019-04-09 22:58:44,128 root         INFO     Train Epoch: 12 [1536/8000 (19%)]\tTotal Loss: 0.342675\n",
      "Reconstruction: 0.256046, Regularization: 0.009709, Discriminator: 0.059927; Generator: 0.016994,\n",
      "D(x): 0.435, D(G(z)): 0.581\n",
      "2019-04-09 22:58:44,230 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 0.325639\n",
      "Reconstruction: 0.236454, Regularization: 0.011979, Discriminator: 0.060043; Generator: 0.017163,\n",
      "D(x): 0.417, D(G(z)): 0.578\n",
      "2019-04-09 22:58:44,330 root         INFO     Train Epoch: 12 [2560/8000 (32%)]\tTotal Loss: 0.302605\n",
      "Reconstruction: 0.214720, Regularization: 0.009746, Discriminator: 0.060841; Generator: 0.017297,\n",
      "D(x): 0.380, D(G(z)): 0.575\n",
      "2019-04-09 22:58:44,430 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 0.290300\n",
      "Reconstruction: 0.205326, Regularization: 0.010793, Discriminator: 0.056891; Generator: 0.017290,\n",
      "D(x): 0.435, D(G(z)): 0.575\n",
      "2019-04-09 22:58:44,530 root         INFO     Train Epoch: 12 [3584/8000 (45%)]\tTotal Loss: 0.288316\n",
      "Reconstruction: 0.205796, Regularization: 0.012729, Discriminator: 0.052591; Generator: 0.017200,\n",
      "D(x): 0.496, D(G(z)): 0.577\n",
      "2019-04-09 22:58:44,630 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 0.279837\n",
      "Reconstruction: 0.192655, Regularization: 0.010734, Discriminator: 0.059496; Generator: 0.016952,\n",
      "D(x): 0.391, D(G(z)): 0.581\n",
      "2019-04-09 22:58:44,730 root         INFO     Train Epoch: 12 [4608/8000 (58%)]\tTotal Loss: 0.243684\n",
      "Reconstruction: 0.165836, Regularization: 0.008660, Discriminator: 0.051832; Generator: 0.017355,\n",
      "D(x): 0.483, D(G(z)): 0.574\n",
      "2019-04-09 22:58:44,831 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.304105\n",
      "Reconstruction: 0.216740, Regularization: 0.013832, Discriminator: 0.056202; Generator: 0.017331,\n",
      "D(x): 0.451, D(G(z)): 0.574\n",
      "2019-04-09 22:58:44,931 root         INFO     Train Epoch: 12 [5632/8000 (70%)]\tTotal Loss: 0.244143\n",
      "Reconstruction: 0.163776, Regularization: 0.008714, Discriminator: 0.054408; Generator: 0.017245,\n",
      "D(x): 0.444, D(G(z)): 0.576\n",
      "2019-04-09 22:58:45,031 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.314739\n",
      "Reconstruction: 0.227602, Regularization: 0.012104, Discriminator: 0.057719; Generator: 0.017313,\n",
      "D(x): 0.425, D(G(z)): 0.575\n",
      "2019-04-09 22:58:45,131 root         INFO     Train Epoch: 12 [6656/8000 (83%)]\tTotal Loss: 0.287258\n",
      "Reconstruction: 0.206444, Regularization: 0.006728, Discriminator: 0.056836; Generator: 0.017250,\n",
      "D(x): 0.434, D(G(z)): 0.576\n",
      "2019-04-09 22:58:45,231 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 0.325558\n",
      "Reconstruction: 0.242232, Regularization: 0.007016, Discriminator: 0.059051; Generator: 0.017258,\n",
      "D(x): 0.414, D(G(z)): 0.576\n",
      "2019-04-09 22:58:45,331 root         INFO     Train Epoch: 12 [7680/8000 (96%)]\tTotal Loss: 0.280613\n",
      "Reconstruction: 0.197057, Regularization: 0.010352, Discriminator: 0.056008; Generator: 0.017196,\n",
      "D(x): 0.432, D(G(z)): 0.577\n",
      "2019-04-09 22:58:45,406 root         INFO     ====> Epoch: 12 Average loss: 0.3097\n",
      "2019-04-09 22:58:45,432 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 0.355379\n",
      "Reconstruction: 0.264916, Regularization: 0.010045, Discriminator: 0.062791; Generator: 0.017627,\n",
      "D(x): 0.366, D(G(z)): 0.569\n",
      "2019-04-09 22:58:45,532 root         INFO     Train Epoch: 13 [512/8000 (6%)]\tTotal Loss: 0.271318\n",
      "Reconstruction: 0.187957, Regularization: 0.010493, Discriminator: 0.055524; Generator: 0.017343,\n",
      "D(x): 0.436, D(G(z)): 0.574\n",
      "2019-04-09 22:58:45,632 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 0.252282\n",
      "Reconstruction: 0.170029, Regularization: 0.010747, Discriminator: 0.054044; Generator: 0.017462,\n",
      "D(x): 0.451, D(G(z)): 0.572\n",
      "2019-04-09 22:58:45,732 root         INFO     Train Epoch: 13 [1536/8000 (19%)]\tTotal Loss: 0.247744\n",
      "Reconstruction: 0.165125, Regularization: 0.009734, Discriminator: 0.055376; Generator: 0.017509,\n",
      "D(x): 0.423, D(G(z)): 0.571\n",
      "2019-04-09 22:58:45,831 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 0.285824\n",
      "Reconstruction: 0.199170, Regularization: 0.009593, Discriminator: 0.059856; Generator: 0.017205,\n",
      "D(x): 0.383, D(G(z)): 0.577\n",
      "2019-04-09 22:58:45,931 root         INFO     Train Epoch: 13 [2560/8000 (32%)]\tTotal Loss: 0.249838\n",
      "Reconstruction: 0.163326, Regularization: 0.014754, Discriminator: 0.054169; Generator: 0.017589,\n",
      "D(x): 0.441, D(G(z)): 0.570\n",
      "2019-04-09 22:58:46,031 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 0.342455\n",
      "Reconstruction: 0.254539, Regularization: 0.011110, Discriminator: 0.059240; Generator: 0.017566,\n",
      "D(x): 0.398, D(G(z)): 0.570\n",
      "2019-04-09 22:58:46,128 root         INFO     Train Epoch: 13 [3584/8000 (45%)]\tTotal Loss: 0.344208\n",
      "Reconstruction: 0.260908, Regularization: 0.008292, Discriminator: 0.057304; Generator: 0.017705,\n",
      "D(x): 0.427, D(G(z)): 0.568\n",
      "2019-04-09 22:58:46,226 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 0.289852\n",
      "Reconstruction: 0.211855, Regularization: 0.007894, Discriminator: 0.052465; Generator: 0.017637,\n",
      "D(x): 0.479, D(G(z)): 0.569\n",
      "2019-04-09 22:58:46,324 root         INFO     Train Epoch: 13 [4608/8000 (58%)]\tTotal Loss: 0.267678\n",
      "Reconstruction: 0.188345, Regularization: 0.006694, Discriminator: 0.055037; Generator: 0.017602,\n",
      "D(x): 0.435, D(G(z)): 0.569\n",
      "2019-04-09 22:58:46,422 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 0.311519\n",
      "Reconstruction: 0.229820, Regularization: 0.007421, Discriminator: 0.056812; Generator: 0.017466,\n",
      "D(x): 0.430, D(G(z)): 0.572\n",
      "2019-04-09 22:58:46,520 root         INFO     Train Epoch: 13 [5632/8000 (70%)]\tTotal Loss: 0.264938\n",
      "Reconstruction: 0.183854, Regularization: 0.010280, Discriminator: 0.053213; Generator: 0.017592,\n",
      "D(x): 0.450, D(G(z)): 0.570\n",
      "2019-04-09 22:58:46,618 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 0.336409\n",
      "Reconstruction: 0.252969, Regularization: 0.008550, Discriminator: 0.057073; Generator: 0.017816,\n",
      "D(x): 0.423, D(G(z)): 0.566\n",
      "2019-04-09 22:58:46,717 root         INFO     Train Epoch: 13 [6656/8000 (83%)]\tTotal Loss: 0.306249\n",
      "Reconstruction: 0.229356, Regularization: 0.008276, Discriminator: 0.050690; Generator: 0.017926,\n",
      "D(x): 0.508, D(G(z)): 0.564\n",
      "2019-04-09 22:58:46,818 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 0.275401\n",
      "Reconstruction: 0.198447, Regularization: 0.006549, Discriminator: 0.052729; Generator: 0.017676,\n",
      "D(x): 0.466, D(G(z)): 0.568\n",
      "2019-04-09 22:58:46,919 root         INFO     Train Epoch: 13 [7680/8000 (96%)]\tTotal Loss: 0.307321\n",
      "Reconstruction: 0.224851, Regularization: 0.007026, Discriminator: 0.057469; Generator: 0.017974,\n",
      "D(x): 0.400, D(G(z)): 0.563\n",
      "2019-04-09 22:58:46,994 root         INFO     ====> Epoch: 13 Average loss: 0.3093\n",
      "2019-04-09 22:58:47,022 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.278935\n",
      "Reconstruction: 0.198082, Regularization: 0.006160, Discriminator: 0.057000; Generator: 0.017694,\n",
      "D(x): 0.401, D(G(z)): 0.568\n",
      "2019-04-09 22:58:47,123 root         INFO     Train Epoch: 14 [512/8000 (6%)]\tTotal Loss: 0.306676\n",
      "Reconstruction: 0.224870, Regularization: 0.007838, Discriminator: 0.056116; Generator: 0.017851,\n",
      "D(x): 0.422, D(G(z)): 0.565\n",
      "2019-04-09 22:58:47,223 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.309447\n",
      "Reconstruction: 0.228930, Regularization: 0.007701, Discriminator: 0.054829; Generator: 0.017986,\n",
      "D(x): 0.434, D(G(z)): 0.562\n",
      "2019-04-09 22:58:47,322 root         INFO     Train Epoch: 14 [1536/8000 (19%)]\tTotal Loss: 0.287177\n",
      "Reconstruction: 0.207589, Regularization: 0.008051, Discriminator: 0.053515; Generator: 0.018023,\n",
      "D(x): 0.446, D(G(z)): 0.562\n",
      "2019-04-09 22:58:47,422 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 0.357520\n",
      "Reconstruction: 0.276794, Regularization: 0.005919, Discriminator: 0.056753; Generator: 0.018053,\n",
      "D(x): 0.428, D(G(z)): 0.561\n",
      "2019-04-09 22:58:47,522 root         INFO     Train Epoch: 14 [2560/8000 (32%)]\tTotal Loss: 0.329933\n",
      "Reconstruction: 0.244706, Regularization: 0.010548, Discriminator: 0.056672; Generator: 0.018006,\n",
      "D(x): 0.412, D(G(z)): 0.562\n",
      "2019-04-09 22:58:47,622 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.346676\n",
      "Reconstruction: 0.260590, Regularization: 0.011223, Discriminator: 0.056772; Generator: 0.018091,\n",
      "D(x): 0.409, D(G(z)): 0.561\n",
      "2019-04-09 22:58:47,722 root         INFO     Train Epoch: 14 [3584/8000 (45%)]\tTotal Loss: 0.286336\n",
      "Reconstruction: 0.201947, Regularization: 0.009772, Discriminator: 0.056620; Generator: 0.017997,\n",
      "D(x): 0.398, D(G(z)): 0.562\n",
      "2019-04-09 22:58:47,822 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.259896\n",
      "Reconstruction: 0.180684, Regularization: 0.008964, Discriminator: 0.052188; Generator: 0.018061,\n",
      "D(x): 0.459, D(G(z)): 0.561\n",
      "2019-04-09 22:58:47,922 root         INFO     Train Epoch: 14 [4608/8000 (58%)]\tTotal Loss: 0.386614\n",
      "Reconstruction: 0.301300, Regularization: 0.010705, Discriminator: 0.056679; Generator: 0.017930,\n",
      "D(x): 0.424, D(G(z)): 0.563\n",
      "2019-04-09 22:58:48,020 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 0.273212\n",
      "Reconstruction: 0.193870, Regularization: 0.008028, Discriminator: 0.053198; Generator: 0.018116,\n",
      "D(x): 0.441, D(G(z)): 0.560\n",
      "2019-04-09 22:58:48,118 root         INFO     Train Epoch: 14 [5632/8000 (70%)]\tTotal Loss: 0.283659\n",
      "Reconstruction: 0.205757, Regularization: 0.006808, Discriminator: 0.052890; Generator: 0.018205,\n",
      "D(x): 0.448, D(G(z)): 0.559\n",
      "2019-04-09 22:58:48,216 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.311384\n",
      "Reconstruction: 0.228331, Regularization: 0.009348, Discriminator: 0.055435; Generator: 0.018270,\n",
      "D(x): 0.415, D(G(z)): 0.557\n",
      "2019-04-09 22:58:48,314 root         INFO     Train Epoch: 14 [6656/8000 (83%)]\tTotal Loss: 0.267998\n",
      "Reconstruction: 0.188993, Regularization: 0.008199, Discriminator: 0.052652; Generator: 0.018154,\n",
      "D(x): 0.447, D(G(z)): 0.559\n",
      "2019-04-09 22:58:48,410 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.276090\n",
      "Reconstruction: 0.197248, Regularization: 0.008168, Discriminator: 0.052365; Generator: 0.018309,\n",
      "D(x): 0.447, D(G(z)): 0.557\n",
      "2019-04-09 22:58:48,508 root         INFO     Train Epoch: 14 [7680/8000 (96%)]\tTotal Loss: 0.318772\n",
      "Reconstruction: 0.234115, Regularization: 0.011328, Discriminator: 0.055132; Generator: 0.018197,\n",
      "D(x): 0.419, D(G(z)): 0.559\n",
      "2019-04-09 22:58:48,582 root         INFO     ====> Epoch: 14 Average loss: 0.3084\n",
      "2019-04-09 22:58:48,609 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 0.300997\n",
      "Reconstruction: 0.220000, Regularization: 0.009192, Discriminator: 0.053419; Generator: 0.018385,\n",
      "D(x): 0.434, D(G(z)): 0.555\n",
      "2019-04-09 22:58:48,710 root         INFO     Train Epoch: 15 [512/8000 (6%)]\tTotal Loss: 0.294371\n",
      "Reconstruction: 0.214458, Regularization: 0.009572, Discriminator: 0.052162; Generator: 0.018180,\n",
      "D(x): 0.463, D(G(z)): 0.559\n",
      "2019-04-09 22:58:48,811 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 0.310941\n",
      "Reconstruction: 0.226809, Regularization: 0.010100, Discriminator: 0.055623; Generator: 0.018409,\n",
      "D(x): 0.402, D(G(z)): 0.555\n",
      "2019-04-09 22:58:48,912 root         INFO     Train Epoch: 15 [1536/8000 (19%)]\tTotal Loss: 0.275430\n",
      "Reconstruction: 0.200732, Regularization: 0.005712, Discriminator: 0.050617; Generator: 0.018369,\n",
      "D(x): 0.473, D(G(z)): 0.556\n",
      "2019-04-09 22:58:49,012 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.287445\n",
      "Reconstruction: 0.206681, Regularization: 0.010558, Discriminator: 0.051854; Generator: 0.018353,\n",
      "D(x): 0.458, D(G(z)): 0.556\n",
      "2019-04-09 22:58:49,113 root         INFO     Train Epoch: 15 [2560/8000 (32%)]\tTotal Loss: 0.322042\n",
      "Reconstruction: 0.243425, Regularization: 0.005851, Discriminator: 0.054267; Generator: 0.018499,\n",
      "D(x): 0.433, D(G(z)): 0.553\n",
      "2019-04-09 22:58:49,213 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.380722\n",
      "Reconstruction: 0.292795, Regularization: 0.010907, Discriminator: 0.058424; Generator: 0.018597,\n",
      "D(x): 0.376, D(G(z)): 0.552\n",
      "2019-04-09 22:58:49,314 root         INFO     Train Epoch: 15 [3584/8000 (45%)]\tTotal Loss: 0.291210\n",
      "Reconstruction: 0.215120, Regularization: 0.004940, Discriminator: 0.052645; Generator: 0.018505,\n",
      "D(x): 0.444, D(G(z)): 0.553\n",
      "2019-04-09 22:58:49,414 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.285916\n",
      "Reconstruction: 0.205559, Regularization: 0.008646, Discriminator: 0.053271; Generator: 0.018439,\n",
      "D(x): 0.432, D(G(z)): 0.554\n",
      "2019-04-09 22:58:49,515 root         INFO     Train Epoch: 15 [4608/8000 (58%)]\tTotal Loss: 0.344695\n",
      "Reconstruction: 0.263519, Regularization: 0.006907, Discriminator: 0.055692; Generator: 0.018577,\n",
      "D(x): 0.406, D(G(z)): 0.552\n",
      "2019-04-09 22:58:49,616 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.326797\n",
      "Reconstruction: 0.248521, Regularization: 0.006020, Discriminator: 0.053671; Generator: 0.018585,\n",
      "D(x): 0.432, D(G(z)): 0.552\n",
      "2019-04-09 22:58:49,717 root         INFO     Train Epoch: 15 [5632/8000 (70%)]\tTotal Loss: 0.248869\n",
      "Reconstruction: 0.173972, Regularization: 0.007168, Discriminator: 0.048950; Generator: 0.018779,\n",
      "D(x): 0.484, D(G(z)): 0.548\n",
      "2019-04-09 22:58:49,817 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.297081\n",
      "Reconstruction: 0.213606, Regularization: 0.011082, Discriminator: 0.053767; Generator: 0.018626,\n",
      "D(x): 0.418, D(G(z)): 0.551\n",
      "2019-04-09 22:58:49,918 root         INFO     Train Epoch: 15 [6656/8000 (83%)]\tTotal Loss: 0.334006\n",
      "Reconstruction: 0.253334, Regularization: 0.009800, Discriminator: 0.052229; Generator: 0.018644,\n",
      "D(x): 0.446, D(G(z)): 0.551\n",
      "2019-04-09 22:58:50,019 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 0.273204\n",
      "Reconstruction: 0.196990, Regularization: 0.005669, Discriminator: 0.051915; Generator: 0.018630,\n",
      "D(x): 0.441, D(G(z)): 0.551\n",
      "2019-04-09 22:58:50,119 root         INFO     Train Epoch: 15 [7680/8000 (96%)]\tTotal Loss: 0.290667\n",
      "Reconstruction: 0.214490, Regularization: 0.005056, Discriminator: 0.052250; Generator: 0.018870,\n",
      "D(x): 0.438, D(G(z)): 0.547\n",
      "2019-04-09 22:58:50,195 root         INFO     ====> Epoch: 15 Average loss: 0.3082\n",
      "2019-04-09 22:58:50,221 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 0.296291\n",
      "Reconstruction: 0.216511, Regularization: 0.007940, Discriminator: 0.053145; Generator: 0.018694,\n",
      "D(x): 0.425, D(G(z)): 0.550\n",
      "2019-04-09 22:58:50,322 root         INFO     Train Epoch: 16 [512/8000 (6%)]\tTotal Loss: 0.315528\n",
      "Reconstruction: 0.237291, Regularization: 0.007914, Discriminator: 0.051661; Generator: 0.018661,\n",
      "D(x): 0.455, D(G(z)): 0.550\n",
      "2019-04-09 22:58:50,423 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 0.290774\n",
      "Reconstruction: 0.212934, Regularization: 0.008149, Discriminator: 0.050915; Generator: 0.018776,\n",
      "D(x): 0.459, D(G(z)): 0.548\n",
      "2019-04-09 22:58:50,524 root         INFO     Train Epoch: 16 [1536/8000 (19%)]\tTotal Loss: 0.280605\n",
      "Reconstruction: 0.205157, Regularization: 0.005823, Discriminator: 0.050854; Generator: 0.018770,\n",
      "D(x): 0.456, D(G(z)): 0.548\n",
      "2019-04-09 22:58:50,626 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.321320\n",
      "Reconstruction: 0.241137, Regularization: 0.008826, Discriminator: 0.052601; Generator: 0.018756,\n",
      "D(x): 0.440, D(G(z)): 0.549\n",
      "2019-04-09 22:58:50,728 root         INFO     Train Epoch: 16 [2560/8000 (32%)]\tTotal Loss: 0.384390\n",
      "Reconstruction: 0.303481, Regularization: 0.005638, Discriminator: 0.056403; Generator: 0.018868,\n",
      "D(x): 0.391, D(G(z)): 0.547\n",
      "2019-04-09 22:58:50,830 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 0.291178\n",
      "Reconstruction: 0.216830, Regularization: 0.006947, Discriminator: 0.048651; Generator: 0.018750,\n",
      "D(x): 0.496, D(G(z)): 0.549\n",
      "2019-04-09 22:58:50,932 root         INFO     Train Epoch: 16 [3584/8000 (45%)]\tTotal Loss: 0.347456\n",
      "Reconstruction: 0.265876, Regularization: 0.009025, Discriminator: 0.053658; Generator: 0.018897,\n",
      "D(x): 0.421, D(G(z)): 0.546\n",
      "2019-04-09 22:58:51,034 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 0.340433\n",
      "Reconstruction: 0.261564, Regularization: 0.006778, Discriminator: 0.053083; Generator: 0.019008,\n",
      "D(x): 0.430, D(G(z)): 0.544\n",
      "2019-04-09 22:58:51,136 root         INFO     Train Epoch: 16 [4608/8000 (58%)]\tTotal Loss: 0.302077\n",
      "Reconstruction: 0.224561, Regularization: 0.006346, Discriminator: 0.052250; Generator: 0.018921,\n",
      "D(x): 0.436, D(G(z)): 0.546\n",
      "2019-04-09 22:58:51,237 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 0.241221\n",
      "Reconstruction: 0.169098, Regularization: 0.006220, Discriminator: 0.047054; Generator: 0.018850,\n",
      "D(x): 0.507, D(G(z)): 0.547\n",
      "2019-04-09 22:58:51,339 root         INFO     Train Epoch: 16 [5632/8000 (70%)]\tTotal Loss: 0.317660\n",
      "Reconstruction: 0.236596, Regularization: 0.009338, Discriminator: 0.052767; Generator: 0.018959,\n",
      "D(x): 0.421, D(G(z)): 0.545\n",
      "2019-04-09 22:58:51,441 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 0.357844\n",
      "Reconstruction: 0.277880, Regularization: 0.006060, Discriminator: 0.054891; Generator: 0.019013,\n",
      "D(x): 0.402, D(G(z)): 0.544\n",
      "2019-04-09 22:58:51,542 root         INFO     Train Epoch: 16 [6656/8000 (83%)]\tTotal Loss: 0.320695\n",
      "Reconstruction: 0.241562, Regularization: 0.007544, Discriminator: 0.052620; Generator: 0.018968,\n",
      "D(x): 0.430, D(G(z)): 0.545\n",
      "2019-04-09 22:58:51,644 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.280166\n",
      "Reconstruction: 0.205818, Regularization: 0.005320, Discriminator: 0.050093; Generator: 0.018935,\n",
      "D(x): 0.461, D(G(z)): 0.546\n",
      "2019-04-09 22:58:51,745 root         INFO     Train Epoch: 16 [7680/8000 (96%)]\tTotal Loss: 0.292300\n",
      "Reconstruction: 0.216373, Regularization: 0.008193, Discriminator: 0.048702; Generator: 0.019033,\n",
      "D(x): 0.483, D(G(z)): 0.544\n",
      "2019-04-09 22:58:51,820 root         INFO     ====> Epoch: 16 Average loss: 0.3081\n",
      "2019-04-09 22:58:51,846 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.352911\n",
      "Reconstruction: 0.269894, Regularization: 0.010384, Discriminator: 0.053570; Generator: 0.019063,\n",
      "D(x): 0.415, D(G(z)): 0.543\n",
      "2019-04-09 22:58:51,948 root         INFO     Train Epoch: 17 [512/8000 (6%)]\tTotal Loss: 0.236727\n",
      "Reconstruction: 0.160859, Regularization: 0.008387, Discriminator: 0.048359; Generator: 0.019123,\n",
      "D(x): 0.475, D(G(z)): 0.542\n",
      "2019-04-09 22:58:52,048 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 0.337867\n",
      "Reconstruction: 0.257575, Regularization: 0.010452, Discriminator: 0.050772; Generator: 0.019067,\n",
      "D(x): 0.453, D(G(z)): 0.543\n",
      "2019-04-09 22:58:52,148 root         INFO     Train Epoch: 17 [1536/8000 (19%)]\tTotal Loss: 0.405591\n",
      "Reconstruction: 0.330939, Regularization: 0.003354, Discriminator: 0.052278; Generator: 0.019020,\n",
      "D(x): 0.448, D(G(z)): 0.544\n",
      "2019-04-09 22:58:52,248 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.324775\n",
      "Reconstruction: 0.246511, Regularization: 0.007354, Discriminator: 0.051781; Generator: 0.019128,\n",
      "D(x): 0.437, D(G(z)): 0.542\n",
      "2019-04-09 22:58:52,348 root         INFO     Train Epoch: 17 [2560/8000 (32%)]\tTotal Loss: 0.315878\n",
      "Reconstruction: 0.240060, Regularization: 0.005056, Discriminator: 0.051561; Generator: 0.019201,\n",
      "D(x): 0.437, D(G(z)): 0.541\n",
      "2019-04-09 22:58:52,448 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 0.279457\n",
      "Reconstruction: 0.203721, Regularization: 0.006702, Discriminator: 0.049865; Generator: 0.019169,\n",
      "D(x): 0.456, D(G(z)): 0.542\n",
      "2019-04-09 22:58:52,546 root         INFO     Train Epoch: 17 [3584/8000 (45%)]\tTotal Loss: 0.277515\n",
      "Reconstruction: 0.200491, Regularization: 0.007720, Discriminator: 0.050075; Generator: 0.019230,\n",
      "D(x): 0.450, D(G(z)): 0.540\n",
      "2019-04-09 22:58:52,646 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.350951\n",
      "Reconstruction: 0.269543, Regularization: 0.010251, Discriminator: 0.052043; Generator: 0.019114,\n",
      "D(x): 0.435, D(G(z)): 0.542\n",
      "2019-04-09 22:58:52,746 root         INFO     Train Epoch: 17 [4608/8000 (58%)]\tTotal Loss: 0.334560\n",
      "Reconstruction: 0.255159, Regularization: 0.009122, Discriminator: 0.051066; Generator: 0.019213,\n",
      "D(x): 0.445, D(G(z)): 0.541\n",
      "2019-04-09 22:58:52,842 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 0.320956\n",
      "Reconstruction: 0.243185, Regularization: 0.007549, Discriminator: 0.051013; Generator: 0.019209,\n",
      "D(x): 0.442, D(G(z)): 0.541\n",
      "2019-04-09 22:58:52,938 root         INFO     Train Epoch: 17 [5632/8000 (70%)]\tTotal Loss: 0.334775\n",
      "Reconstruction: 0.254336, Regularization: 0.009674, Discriminator: 0.051502; Generator: 0.019263,\n",
      "D(x): 0.435, D(G(z)): 0.540\n",
      "2019-04-09 22:58:53,033 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 0.252642\n",
      "Reconstruction: 0.178489, Regularization: 0.007104, Discriminator: 0.047749; Generator: 0.019299,\n",
      "D(x): 0.483, D(G(z)): 0.539\n",
      "2019-04-09 22:58:53,128 root         INFO     Train Epoch: 17 [6656/8000 (83%)]\tTotal Loss: 0.277050\n",
      "Reconstruction: 0.199808, Regularization: 0.008479, Discriminator: 0.049535; Generator: 0.019228,\n",
      "D(x): 0.457, D(G(z)): 0.540\n",
      "2019-04-09 22:58:53,224 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 0.307736\n",
      "Reconstruction: 0.231422, Regularization: 0.007202, Discriminator: 0.049803; Generator: 0.019308,\n",
      "D(x): 0.459, D(G(z)): 0.539\n",
      "2019-04-09 22:58:53,319 root         INFO     Train Epoch: 17 [7680/8000 (96%)]\tTotal Loss: 0.304512\n",
      "Reconstruction: 0.227318, Regularization: 0.005759, Discriminator: 0.052113; Generator: 0.019322,\n",
      "D(x): 0.418, D(G(z)): 0.539\n",
      "2019-04-09 22:58:53,391 root         INFO     ====> Epoch: 17 Average loss: 0.3081\n",
      "2019-04-09 22:58:53,418 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 0.256084\n",
      "Reconstruction: 0.182702, Regularization: 0.006850, Discriminator: 0.047211; Generator: 0.019321,\n",
      "D(x): 0.490, D(G(z)): 0.539\n",
      "2019-04-09 22:58:53,516 root         INFO     Train Epoch: 18 [512/8000 (6%)]\tTotal Loss: 0.365289\n",
      "Reconstruction: 0.288346, Regularization: 0.006040, Discriminator: 0.051544; Generator: 0.019359,\n",
      "D(x): 0.438, D(G(z)): 0.538\n",
      "2019-04-09 22:58:53,615 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.271930\n",
      "Reconstruction: 0.197967, Regularization: 0.006223, Discriminator: 0.048377; Generator: 0.019363,\n",
      "D(x): 0.473, D(G(z)): 0.538\n",
      "2019-04-09 22:58:53,714 root         INFO     Train Epoch: 18 [1536/8000 (19%)]\tTotal Loss: 0.266057\n",
      "Reconstruction: 0.189375, Regularization: 0.008670, Discriminator: 0.048641; Generator: 0.019372,\n",
      "D(x): 0.467, D(G(z)): 0.538\n",
      "2019-04-09 22:58:53,812 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 0.323050\n",
      "Reconstruction: 0.246899, Regularization: 0.005252, Discriminator: 0.051475; Generator: 0.019423,\n",
      "D(x): 0.428, D(G(z)): 0.537\n",
      "2019-04-09 22:58:53,911 root         INFO     Train Epoch: 18 [2560/8000 (32%)]\tTotal Loss: 0.342377\n",
      "Reconstruction: 0.265075, Regularization: 0.005681, Discriminator: 0.052190; Generator: 0.019431,\n",
      "D(x): 0.419, D(G(z)): 0.537\n",
      "2019-04-09 22:58:54,009 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.329246\n",
      "Reconstruction: 0.249675, Regularization: 0.009848, Discriminator: 0.050283; Generator: 0.019440,\n",
      "D(x): 0.449, D(G(z)): 0.537\n",
      "2019-04-09 22:58:54,108 root         INFO     Train Epoch: 18 [3584/8000 (45%)]\tTotal Loss: 0.301135\n",
      "Reconstruction: 0.226833, Regularization: 0.005643, Discriminator: 0.049213; Generator: 0.019445,\n",
      "D(x): 0.463, D(G(z)): 0.537\n",
      "2019-04-09 22:58:54,206 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 0.301525\n",
      "Reconstruction: 0.226622, Regularization: 0.005405, Discriminator: 0.050003; Generator: 0.019495,\n",
      "D(x): 0.447, D(G(z)): 0.536\n",
      "2019-04-09 22:58:54,304 root         INFO     Train Epoch: 18 [4608/8000 (58%)]\tTotal Loss: 0.300492\n",
      "Reconstruction: 0.224460, Regularization: 0.006568, Discriminator: 0.049961; Generator: 0.019502,\n",
      "D(x): 0.447, D(G(z)): 0.536\n",
      "2019-04-09 22:58:54,402 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.259864\n",
      "Reconstruction: 0.186756, Regularization: 0.006355, Discriminator: 0.047286; Generator: 0.019467,\n",
      "D(x): 0.487, D(G(z)): 0.536\n",
      "2019-04-09 22:58:54,501 root         INFO     Train Epoch: 18 [5632/8000 (70%)]\tTotal Loss: 0.323092\n",
      "Reconstruction: 0.250043, Regularization: 0.006001, Discriminator: 0.047525; Generator: 0.019523,\n",
      "D(x): 0.489, D(G(z)): 0.535\n",
      "2019-04-09 22:58:54,599 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 0.292771\n",
      "Reconstruction: 0.219122, Regularization: 0.005593, Discriminator: 0.048515; Generator: 0.019540,\n",
      "D(x): 0.468, D(G(z)): 0.535\n",
      "2019-04-09 22:58:54,696 root         INFO     Train Epoch: 18 [6656/8000 (83%)]\tTotal Loss: 0.329261\n",
      "Reconstruction: 0.253810, Regularization: 0.007603, Discriminator: 0.048330; Generator: 0.019518,\n",
      "D(x): 0.476, D(G(z)): 0.535\n",
      "2019-04-09 22:58:54,794 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 0.282398\n",
      "Reconstruction: 0.207265, Regularization: 0.007927, Discriminator: 0.047625; Generator: 0.019581,\n",
      "D(x): 0.479, D(G(z)): 0.534\n",
      "2019-04-09 22:58:54,892 root         INFO     Train Epoch: 18 [7680/8000 (96%)]\tTotal Loss: 0.263039\n",
      "Reconstruction: 0.189260, Regularization: 0.006276, Discriminator: 0.047912; Generator: 0.019590,\n",
      "D(x): 0.471, D(G(z)): 0.534\n",
      "2019-04-09 22:58:54,966 root         INFO     ====> Epoch: 18 Average loss: 0.3085\n",
      "2019-04-09 22:58:54,992 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 0.289089\n",
      "Reconstruction: 0.215728, Regularization: 0.006136, Discriminator: 0.047633; Generator: 0.019593,\n",
      "D(x): 0.480, D(G(z)): 0.534\n",
      "2019-04-09 22:58:55,092 root         INFO     Train Epoch: 19 [512/8000 (6%)]\tTotal Loss: 0.298242\n",
      "Reconstruction: 0.225970, Regularization: 0.005241, Discriminator: 0.047408; Generator: 0.019623,\n",
      "D(x): 0.485, D(G(z)): 0.534\n",
      "2019-04-09 22:58:55,191 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 0.260339\n",
      "Reconstruction: 0.187662, Regularization: 0.005257, Discriminator: 0.047786; Generator: 0.019634,\n",
      "D(x): 0.473, D(G(z)): 0.534\n",
      "2019-04-09 22:58:55,288 root         INFO     Train Epoch: 19 [1536/8000 (19%)]\tTotal Loss: 0.337182\n",
      "Reconstruction: 0.260459, Regularization: 0.008887, Discriminator: 0.048178; Generator: 0.019658,\n",
      "D(x): 0.475, D(G(z)): 0.533\n",
      "2019-04-09 22:58:55,386 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 0.272993\n",
      "Reconstruction: 0.198309, Regularization: 0.007056, Discriminator: 0.047974; Generator: 0.019654,\n",
      "D(x): 0.469, D(G(z)): 0.533\n",
      "2019-04-09 22:58:55,484 root         INFO     Train Epoch: 19 [2560/8000 (32%)]\tTotal Loss: 0.329735\n",
      "Reconstruction: 0.249368, Regularization: 0.012600, Discriminator: 0.048084; Generator: 0.019682,\n",
      "D(x): 0.473, D(G(z)): 0.533\n",
      "2019-04-09 22:58:55,584 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 0.318167\n",
      "Reconstruction: 0.241874, Regularization: 0.007979, Discriminator: 0.048618; Generator: 0.019696,\n",
      "D(x): 0.463, D(G(z)): 0.532\n",
      "2019-04-09 22:58:55,681 root         INFO     Train Epoch: 19 [3584/8000 (45%)]\tTotal Loss: 0.286146\n",
      "Reconstruction: 0.210153, Regularization: 0.008236, Discriminator: 0.048051; Generator: 0.019707,\n",
      "D(x): 0.469, D(G(z)): 0.532\n",
      "2019-04-09 22:58:55,778 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 0.342561\n",
      "Reconstruction: 0.267978, Regularization: 0.005789, Discriminator: 0.049065; Generator: 0.019728,\n",
      "D(x): 0.460, D(G(z)): 0.532\n",
      "2019-04-09 22:58:55,876 root         INFO     Train Epoch: 19 [4608/8000 (58%)]\tTotal Loss: 0.378991\n",
      "Reconstruction: 0.303242, Regularization: 0.007369, Discriminator: 0.048642; Generator: 0.019738,\n",
      "D(x): 0.469, D(G(z)): 0.532\n",
      "2019-04-09 22:58:55,974 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 0.283802\n",
      "Reconstruction: 0.209696, Regularization: 0.007176, Discriminator: 0.047184; Generator: 0.019746,\n",
      "D(x): 0.483, D(G(z)): 0.532\n",
      "2019-04-09 22:58:56,072 root         INFO     Train Epoch: 19 [5632/8000 (70%)]\tTotal Loss: 0.317476\n",
      "Reconstruction: 0.243671, Regularization: 0.005402, Discriminator: 0.048644; Generator: 0.019759,\n",
      "D(x): 0.460, D(G(z)): 0.531\n",
      "2019-04-09 22:58:56,169 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 0.332615\n",
      "Reconstruction: 0.254398, Regularization: 0.008926, Discriminator: 0.049504; Generator: 0.019787,\n",
      "D(x): 0.447, D(G(z)): 0.531\n",
      "2019-04-09 22:58:56,266 root         INFO     Train Epoch: 19 [6656/8000 (83%)]\tTotal Loss: 0.348627\n",
      "Reconstruction: 0.271118, Regularization: 0.009088, Discriminator: 0.048607; Generator: 0.019814,\n",
      "D(x): 0.463, D(G(z)): 0.530\n",
      "2019-04-09 22:58:56,363 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.287572\n",
      "Reconstruction: 0.212708, Regularization: 0.008060, Discriminator: 0.046977; Generator: 0.019827,\n",
      "D(x): 0.483, D(G(z)): 0.530\n",
      "2019-04-09 22:58:56,460 root         INFO     Train Epoch: 19 [7680/8000 (96%)]\tTotal Loss: 0.343119\n",
      "Reconstruction: 0.268288, Regularization: 0.006532, Discriminator: 0.048461; Generator: 0.019837,\n",
      "D(x): 0.464, D(G(z)): 0.530\n",
      "2019-04-09 22:58:56,534 root         INFO     ====> Epoch: 19 Average loss: 0.3088\n",
      "2019-04-09 22:58:56,561 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 0.281191\n",
      "Reconstruction: 0.208669, Regularization: 0.006020, Discriminator: 0.046645; Generator: 0.019856,\n",
      "D(x): 0.487, D(G(z)): 0.530\n",
      "2019-04-09 22:58:56,661 root         INFO     Train Epoch: 20 [512/8000 (6%)]\tTotal Loss: 0.253927\n",
      "Reconstruction: 0.182338, Regularization: 0.005390, Discriminator: 0.046327; Generator: 0.019873,\n",
      "D(x): 0.489, D(G(z)): 0.529\n",
      "2019-04-09 22:58:56,760 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 0.298114\n",
      "Reconstruction: 0.223036, Regularization: 0.007625, Discriminator: 0.047553; Generator: 0.019901,\n",
      "D(x): 0.472, D(G(z)): 0.529\n",
      "2019-04-09 22:58:56,860 root         INFO     Train Epoch: 20 [1536/8000 (19%)]\tTotal Loss: 0.351217\n",
      "Reconstruction: 0.274965, Regularization: 0.007530, Discriminator: 0.048804; Generator: 0.019919,\n",
      "D(x): 0.458, D(G(z)): 0.529\n",
      "2019-04-09 22:58:56,960 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 0.312194\n",
      "Reconstruction: 0.236581, Regularization: 0.008891, Discriminator: 0.046786; Generator: 0.019936,\n",
      "D(x): 0.488, D(G(z)): 0.528\n",
      "2019-04-09 22:58:57,059 root         INFO     Train Epoch: 20 [2560/8000 (32%)]\tTotal Loss: 0.330056\n",
      "Reconstruction: 0.254557, Regularization: 0.007568, Discriminator: 0.047979; Generator: 0.019952,\n",
      "D(x): 0.467, D(G(z)): 0.528\n",
      "2019-04-09 22:58:57,159 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 0.370866\n",
      "Reconstruction: 0.295019, Regularization: 0.006879, Discriminator: 0.049001; Generator: 0.019968,\n",
      "D(x): 0.453, D(G(z)): 0.528\n",
      "2019-04-09 22:58:57,259 root         INFO     Train Epoch: 20 [3584/8000 (45%)]\tTotal Loss: 0.305846\n",
      "Reconstruction: 0.230966, Regularization: 0.008395, Discriminator: 0.046505; Generator: 0.019980,\n",
      "D(x): 0.488, D(G(z)): 0.528\n",
      "2019-04-09 22:58:57,358 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 0.265235\n",
      "Reconstruction: 0.190458, Regularization: 0.008481, Discriminator: 0.046310; Generator: 0.019987,\n",
      "D(x): 0.488, D(G(z)): 0.528\n",
      "2019-04-09 22:58:57,458 root         INFO     Train Epoch: 20 [4608/8000 (58%)]\tTotal Loss: 0.386583\n",
      "Reconstruction: 0.308881, Regularization: 0.007352, Discriminator: 0.050343; Generator: 0.020006,\n",
      "D(x): 0.432, D(G(z)): 0.527\n",
      "2019-04-09 22:58:57,558 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 0.324688\n",
      "Reconstruction: 0.248658, Regularization: 0.007336, Discriminator: 0.048683; Generator: 0.020011,\n",
      "D(x): 0.454, D(G(z)): 0.527\n",
      "2019-04-09 22:58:57,657 root         INFO     Train Epoch: 20 [5632/8000 (70%)]\tTotal Loss: 0.311905\n",
      "Reconstruction: 0.237833, Regularization: 0.006272, Discriminator: 0.047778; Generator: 0.020022,\n",
      "D(x): 0.467, D(G(z)): 0.527\n",
      "2019-04-09 22:58:57,757 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 0.338309\n",
      "Reconstruction: 0.264034, Regularization: 0.005494, Discriminator: 0.048748; Generator: 0.020033,\n",
      "D(x): 0.451, D(G(z)): 0.527\n",
      "2019-04-09 22:58:57,856 root         INFO     Train Epoch: 20 [6656/8000 (83%)]\tTotal Loss: 0.297939\n",
      "Reconstruction: 0.224321, Regularization: 0.006113, Discriminator: 0.047458; Generator: 0.020047,\n",
      "D(x): 0.470, D(G(z)): 0.526\n",
      "2019-04-09 22:58:57,955 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 0.298747\n",
      "Reconstruction: 0.226293, Regularization: 0.005288, Discriminator: 0.047115; Generator: 0.020051,\n",
      "D(x): 0.475, D(G(z)): 0.526\n",
      "2019-04-09 22:58:58,055 root         INFO     Train Epoch: 20 [7680/8000 (96%)]\tTotal Loss: 0.310671\n",
      "Reconstruction: 0.234853, Regularization: 0.008352, Discriminator: 0.047398; Generator: 0.020068,\n",
      "D(x): 0.470, D(G(z)): 0.526\n",
      "2019-04-09 22:58:58,129 root         INFO     ====> Epoch: 20 Average loss: 0.3091\n",
      "2019-04-09 22:58:58,155 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.347304\n",
      "Reconstruction: 0.271410, Regularization: 0.007499, Discriminator: 0.048306; Generator: 0.020089,\n",
      "D(x): 0.459, D(G(z)): 0.526\n",
      "2019-04-09 22:58:58,255 root         INFO     Train Epoch: 21 [512/8000 (6%)]\tTotal Loss: 0.278168\n",
      "Reconstruction: 0.202570, Regularization: 0.008222, Discriminator: 0.047291; Generator: 0.020085,\n",
      "D(x): 0.469, D(G(z)): 0.526\n",
      "2019-04-09 22:58:58,356 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 0.262310\n",
      "Reconstruction: 0.188107, Regularization: 0.007316, Discriminator: 0.046800; Generator: 0.020087,\n",
      "D(x): 0.477, D(G(z)): 0.526\n",
      "2019-04-09 22:58:58,456 root         INFO     Train Epoch: 21 [1536/8000 (19%)]\tTotal Loss: 0.288018\n",
      "Reconstruction: 0.213962, Regularization: 0.006402, Discriminator: 0.047544; Generator: 0.020110,\n",
      "D(x): 0.465, D(G(z)): 0.525\n",
      "2019-04-09 22:58:58,556 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 0.291460\n",
      "Reconstruction: 0.217874, Regularization: 0.005950, Discriminator: 0.047484; Generator: 0.020151,\n",
      "D(x): 0.465, D(G(z)): 0.525\n",
      "2019-04-09 22:58:58,655 root         INFO     Train Epoch: 21 [2560/8000 (32%)]\tTotal Loss: 0.351749\n",
      "Reconstruction: 0.279370, Regularization: 0.005141, Discriminator: 0.047117; Generator: 0.020120,\n",
      "D(x): 0.478, D(G(z)): 0.525\n",
      "2019-04-09 22:58:58,754 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 0.344189\n",
      "Reconstruction: 0.271973, Regularization: 0.005279, Discriminator: 0.046764; Generator: 0.020174,\n",
      "D(x): 0.482, D(G(z)): 0.524\n",
      "2019-04-09 22:58:58,853 root         INFO     Train Epoch: 21 [3584/8000 (45%)]\tTotal Loss: 0.300298\n",
      "Reconstruction: 0.228667, Regularization: 0.004418, Discriminator: 0.047024; Generator: 0.020190,\n",
      "D(x): 0.473, D(G(z)): 0.524\n",
      "2019-04-09 22:58:58,952 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.275947\n",
      "Reconstruction: 0.204709, Regularization: 0.005302, Discriminator: 0.045724; Generator: 0.020212,\n",
      "D(x): 0.492, D(G(z)): 0.524\n",
      "2019-04-09 22:58:59,050 root         INFO     Train Epoch: 21 [4608/8000 (58%)]\tTotal Loss: 0.352651\n",
      "Reconstruction: 0.280984, Regularization: 0.004717, Discriminator: 0.046731; Generator: 0.020220,\n",
      "D(x): 0.481, D(G(z)): 0.524\n",
      "2019-04-09 22:58:59,149 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 0.257344\n",
      "Reconstruction: 0.185118, Regularization: 0.006462, Discriminator: 0.045560; Generator: 0.020204,\n",
      "D(x): 0.494, D(G(z)): 0.524\n",
      "2019-04-09 22:58:59,250 root         INFO     Train Epoch: 21 [5632/8000 (70%)]\tTotal Loss: 0.293404\n",
      "Reconstruction: 0.219937, Regularization: 0.007148, Discriminator: 0.046070; Generator: 0.020249,\n",
      "D(x): 0.488, D(G(z)): 0.523\n",
      "2019-04-09 22:58:59,349 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 0.286148\n",
      "Reconstruction: 0.212916, Regularization: 0.007053, Discriminator: 0.045934; Generator: 0.020246,\n",
      "D(x): 0.489, D(G(z)): 0.523\n",
      "2019-04-09 22:58:59,450 root         INFO     Train Epoch: 21 [6656/8000 (83%)]\tTotal Loss: 0.313580\n",
      "Reconstruction: 0.241236, Regularization: 0.005108, Discriminator: 0.046972; Generator: 0.020264,\n",
      "D(x): 0.472, D(G(z)): 0.523\n",
      "2019-04-09 22:58:59,550 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.305282\n",
      "Reconstruction: 0.232507, Regularization: 0.005537, Discriminator: 0.046908; Generator: 0.020330,\n",
      "D(x): 0.472, D(G(z)): 0.522\n",
      "2019-04-09 22:58:59,649 root         INFO     Train Epoch: 21 [7680/8000 (96%)]\tTotal Loss: 0.325495\n",
      "Reconstruction: 0.249370, Regularization: 0.008545, Discriminator: 0.047288; Generator: 0.020292,\n",
      "D(x): 0.467, D(G(z)): 0.522\n",
      "2019-04-09 22:58:59,724 root         INFO     ====> Epoch: 21 Average loss: 0.3098\n",
      "2019-04-09 22:58:59,751 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 0.279619\n",
      "Reconstruction: 0.207736, Regularization: 0.005902, Discriminator: 0.045688; Generator: 0.020292,\n",
      "D(x): 0.491, D(G(z)): 0.522\n",
      "2019-04-09 22:58:59,852 root         INFO     Train Epoch: 22 [512/8000 (6%)]\tTotal Loss: 0.321181\n",
      "Reconstruction: 0.248222, Regularization: 0.005273, Discriminator: 0.047353; Generator: 0.020333,\n",
      "D(x): 0.464, D(G(z)): 0.522\n",
      "2019-04-09 22:58:59,952 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 0.320805\n",
      "Reconstruction: 0.249212, Regularization: 0.005485, Discriminator: 0.045798; Generator: 0.020311,\n",
      "D(x): 0.491, D(G(z)): 0.522\n",
      "2019-04-09 22:59:00,052 root         INFO     Train Epoch: 22 [1536/8000 (19%)]\tTotal Loss: 0.417021\n",
      "Reconstruction: 0.341299, Regularization: 0.007533, Discriminator: 0.047854; Generator: 0.020336,\n",
      "D(x): 0.463, D(G(z)): 0.522\n",
      "2019-04-09 22:59:00,152 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 0.378811\n",
      "Reconstruction: 0.302014, Regularization: 0.008766, Discriminator: 0.047653; Generator: 0.020379,\n",
      "D(x): 0.461, D(G(z)): 0.521\n",
      "2019-04-09 22:59:00,252 root         INFO     Train Epoch: 22 [2560/8000 (32%)]\tTotal Loss: 0.265361\n",
      "Reconstruction: 0.193770, Regularization: 0.006595, Discriminator: 0.044616; Generator: 0.020380,\n",
      "D(x): 0.506, D(G(z)): 0.521\n",
      "2019-04-09 22:59:00,351 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 0.396958\n",
      "Reconstruction: 0.320163, Regularization: 0.007905, Discriminator: 0.048537; Generator: 0.020352,\n",
      "D(x): 0.449, D(G(z)): 0.521\n",
      "2019-04-09 22:59:00,450 root         INFO     Train Epoch: 22 [3584/8000 (45%)]\tTotal Loss: 0.276804\n",
      "Reconstruction: 0.204665, Regularization: 0.005903, Discriminator: 0.045867; Generator: 0.020369,\n",
      "D(x): 0.485, D(G(z)): 0.521\n",
      "2019-04-09 22:59:00,549 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.351199\n",
      "Reconstruction: 0.280389, Regularization: 0.004399, Discriminator: 0.045993; Generator: 0.020418,\n",
      "D(x): 0.487, D(G(z)): 0.520\n",
      "2019-04-09 22:59:00,652 root         INFO     Train Epoch: 22 [4608/8000 (58%)]\tTotal Loss: 0.291595\n",
      "Reconstruction: 0.219612, Regularization: 0.005791, Discriminator: 0.045769; Generator: 0.020423,\n",
      "D(x): 0.486, D(G(z)): 0.520\n",
      "2019-04-09 22:59:00,755 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 0.288861\n",
      "Reconstruction: 0.215320, Regularization: 0.006837, Discriminator: 0.046280; Generator: 0.020424,\n",
      "D(x): 0.479, D(G(z)): 0.520\n",
      "2019-04-09 22:59:00,858 root         INFO     Train Epoch: 22 [5632/8000 (70%)]\tTotal Loss: 0.342582\n",
      "Reconstruction: 0.267662, Regularization: 0.007109, Discriminator: 0.047358; Generator: 0.020452,\n",
      "D(x): 0.464, D(G(z)): 0.520\n",
      "2019-04-09 22:59:00,961 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 0.300643\n",
      "Reconstruction: 0.229502, Regularization: 0.004996, Discriminator: 0.045682; Generator: 0.020463,\n",
      "D(x): 0.488, D(G(z)): 0.520\n",
      "2019-04-09 22:59:01,058 root         INFO     Train Epoch: 22 [6656/8000 (83%)]\tTotal Loss: 0.331478\n",
      "Reconstruction: 0.258555, Regularization: 0.005128, Discriminator: 0.047313; Generator: 0.020482,\n",
      "D(x): 0.461, D(G(z)): 0.519\n",
      "2019-04-09 22:59:01,155 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 0.284211\n",
      "Reconstruction: 0.209609, Regularization: 0.008041, Discriminator: 0.046132; Generator: 0.020429,\n",
      "D(x): 0.481, D(G(z)): 0.520\n",
      "2019-04-09 22:59:01,252 root         INFO     Train Epoch: 22 [7680/8000 (96%)]\tTotal Loss: 0.282098\n",
      "Reconstruction: 0.211976, Regularization: 0.003912, Discriminator: 0.045760; Generator: 0.020451,\n",
      "D(x): 0.486, D(G(z)): 0.520\n",
      "2019-04-09 22:59:01,325 root         INFO     ====> Epoch: 22 Average loss: 0.3105\n",
      "2019-04-09 22:59:01,352 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 0.287039\n",
      "Reconstruction: 0.215701, Regularization: 0.005486, Discriminator: 0.045330; Generator: 0.020522,\n",
      "D(x): 0.492, D(G(z)): 0.519\n",
      "2019-04-09 22:59:01,452 root         INFO     Train Epoch: 23 [512/8000 (6%)]\tTotal Loss: 0.317730\n",
      "Reconstruction: 0.244494, Regularization: 0.006561, Discriminator: 0.046182; Generator: 0.020493,\n",
      "D(x): 0.479, D(G(z)): 0.519\n",
      "2019-04-09 22:59:01,552 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 0.250809\n",
      "Reconstruction: 0.180737, Regularization: 0.004648, Discriminator: 0.044972; Generator: 0.020452,\n",
      "D(x): 0.498, D(G(z)): 0.520\n",
      "2019-04-09 22:59:01,652 root         INFO     Train Epoch: 23 [1536/8000 (19%)]\tTotal Loss: 0.356819\n",
      "Reconstruction: 0.285744, Regularization: 0.004235, Discriminator: 0.046298; Generator: 0.020542,\n",
      "D(x): 0.478, D(G(z)): 0.518\n",
      "2019-04-09 22:59:01,750 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 0.276827\n",
      "Reconstruction: 0.206506, Regularization: 0.004412, Discriminator: 0.045346; Generator: 0.020562,\n",
      "D(x): 0.489, D(G(z)): 0.518\n",
      "2019-04-09 22:59:01,849 root         INFO     Train Epoch: 23 [2560/8000 (32%)]\tTotal Loss: 0.321350\n",
      "Reconstruction: 0.249060, Regularization: 0.005801, Discriminator: 0.045927; Generator: 0.020562,\n",
      "D(x): 0.482, D(G(z)): 0.518\n",
      "2019-04-09 22:59:01,949 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 0.321944\n",
      "Reconstruction: 0.250975, Regularization: 0.005042, Discriminator: 0.045371; Generator: 0.020556,\n",
      "D(x): 0.491, D(G(z)): 0.518\n",
      "2019-04-09 22:59:02,049 root         INFO     Train Epoch: 23 [3584/8000 (45%)]\tTotal Loss: 0.267582\n",
      "Reconstruction: 0.196072, Regularization: 0.004835, Discriminator: 0.046110; Generator: 0.020564,\n",
      "D(x): 0.476, D(G(z)): 0.518\n",
      "2019-04-09 22:59:02,149 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 0.355730\n",
      "Reconstruction: 0.281120, Regularization: 0.006636, Discriminator: 0.047440; Generator: 0.020535,\n",
      "D(x): 0.459, D(G(z)): 0.518\n",
      "2019-04-09 22:59:02,249 root         INFO     Train Epoch: 23 [4608/8000 (58%)]\tTotal Loss: 0.273894\n",
      "Reconstruction: 0.202556, Regularization: 0.005407, Discriminator: 0.045374; Generator: 0.020556,\n",
      "D(x): 0.490, D(G(z)): 0.518\n",
      "2019-04-09 22:59:02,348 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 0.357712\n",
      "Reconstruction: 0.283165, Regularization: 0.007335, Discriminator: 0.046596; Generator: 0.020616,\n",
      "D(x): 0.472, D(G(z)): 0.517\n",
      "2019-04-09 22:59:02,449 root         INFO     Train Epoch: 23 [5632/8000 (70%)]\tTotal Loss: 0.296090\n",
      "Reconstruction: 0.224651, Regularization: 0.005248, Discriminator: 0.045557; Generator: 0.020634,\n",
      "D(x): 0.485, D(G(z)): 0.517\n",
      "2019-04-09 22:59:02,550 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 0.286067\n",
      "Reconstruction: 0.215375, Regularization: 0.004705, Discriminator: 0.045386; Generator: 0.020600,\n",
      "D(x): 0.489, D(G(z)): 0.517\n",
      "2019-04-09 22:59:02,650 root         INFO     Train Epoch: 23 [6656/8000 (83%)]\tTotal Loss: 0.272353\n",
      "Reconstruction: 0.200105, Regularization: 0.006744, Discriminator: 0.044878; Generator: 0.020626,\n",
      "D(x): 0.495, D(G(z)): 0.517\n",
      "2019-04-09 22:59:02,751 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 0.299470\n",
      "Reconstruction: 0.227760, Regularization: 0.006286, Discriminator: 0.044810; Generator: 0.020614,\n",
      "D(x): 0.498, D(G(z)): 0.517\n",
      "2019-04-09 22:59:02,851 root         INFO     Train Epoch: 23 [7680/8000 (96%)]\tTotal Loss: 0.304940\n",
      "Reconstruction: 0.233337, Regularization: 0.005106, Discriminator: 0.045784; Generator: 0.020714,\n",
      "D(x): 0.480, D(G(z)): 0.515\n",
      "2019-04-09 22:59:02,926 root         INFO     ====> Epoch: 23 Average loss: 0.3102\n",
      "2019-04-09 22:59:02,953 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.268585\n",
      "Reconstruction: 0.198167, Regularization: 0.004620, Discriminator: 0.045021; Generator: 0.020777,\n",
      "D(x): 0.490, D(G(z)): 0.514\n",
      "2019-04-09 22:59:03,055 root         INFO     Train Epoch: 24 [512/8000 (6%)]\tTotal Loss: 0.308428\n",
      "Reconstruction: 0.235994, Regularization: 0.006220, Discriminator: 0.045562; Generator: 0.020652,\n",
      "D(x): 0.485, D(G(z)): 0.516\n",
      "2019-04-09 22:59:03,155 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 0.271933\n",
      "Reconstruction: 0.199654, Regularization: 0.006280, Discriminator: 0.045302; Generator: 0.020697,\n",
      "D(x): 0.487, D(G(z)): 0.516\n",
      "2019-04-09 22:59:03,255 root         INFO     Train Epoch: 24 [1536/8000 (19%)]\tTotal Loss: 0.330861\n",
      "Reconstruction: 0.258932, Regularization: 0.005226, Discriminator: 0.046006; Generator: 0.020697,\n",
      "D(x): 0.478, D(G(z)): 0.516\n",
      "2019-04-09 22:59:03,355 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 0.323384\n",
      "Reconstruction: 0.251706, Regularization: 0.005662, Discriminator: 0.045302; Generator: 0.020714,\n",
      "D(x): 0.489, D(G(z)): 0.515\n",
      "2019-04-09 22:59:03,455 root         INFO     Train Epoch: 24 [2560/8000 (32%)]\tTotal Loss: 0.304210\n",
      "Reconstruction: 0.232178, Regularization: 0.005879, Discriminator: 0.045402; Generator: 0.020751,\n",
      "D(x): 0.486, D(G(z)): 0.515\n",
      "2019-04-09 22:59:03,554 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 0.337397\n",
      "Reconstruction: 0.265730, Regularization: 0.005270, Discriminator: 0.045654; Generator: 0.020743,\n",
      "D(x): 0.483, D(G(z)): 0.515\n",
      "2019-04-09 22:59:03,653 root         INFO     Train Epoch: 24 [3584/8000 (45%)]\tTotal Loss: 0.272773\n",
      "Reconstruction: 0.199954, Regularization: 0.007295, Discriminator: 0.044784; Generator: 0.020741,\n",
      "D(x): 0.495, D(G(z)): 0.515\n",
      "2019-04-09 22:59:03,752 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 0.319559\n",
      "Reconstruction: 0.248247, Regularization: 0.005156, Discriminator: 0.045356; Generator: 0.020800,\n",
      "D(x): 0.486, D(G(z)): 0.514\n",
      "2019-04-09 22:59:03,852 root         INFO     Train Epoch: 24 [4608/8000 (58%)]\tTotal Loss: 0.406225\n",
      "Reconstruction: 0.332901, Regularization: 0.005649, Discriminator: 0.046929; Generator: 0.020747,\n",
      "D(x): 0.463, D(G(z)): 0.515\n",
      "2019-04-09 22:59:03,951 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 0.285626\n",
      "Reconstruction: 0.215149, Regularization: 0.004899, Discriminator: 0.044712; Generator: 0.020865,\n",
      "D(x): 0.494, D(G(z)): 0.513\n",
      "2019-04-09 22:59:04,050 root         INFO     Train Epoch: 24 [5632/8000 (70%)]\tTotal Loss: 0.312371\n",
      "Reconstruction: 0.242250, Regularization: 0.004779, Discriminator: 0.044533; Generator: 0.020809,\n",
      "D(x): 0.499, D(G(z)): 0.514\n",
      "2019-04-09 22:59:04,150 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 0.348215\n",
      "Reconstruction: 0.275412, Regularization: 0.005956, Discriminator: 0.046080; Generator: 0.020766,\n",
      "D(x): 0.475, D(G(z)): 0.515\n",
      "2019-04-09 22:59:04,249 root         INFO     Train Epoch: 24 [6656/8000 (83%)]\tTotal Loss: 0.307391\n",
      "Reconstruction: 0.238985, Regularization: 0.003443, Discriminator: 0.044157; Generator: 0.020805,\n",
      "D(x): 0.505, D(G(z)): 0.514\n",
      "2019-04-09 22:59:04,348 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 0.333065\n",
      "Reconstruction: 0.260216, Regularization: 0.006537, Discriminator: 0.045527; Generator: 0.020785,\n",
      "D(x): 0.485, D(G(z)): 0.514\n",
      "2019-04-09 22:59:04,447 root         INFO     Train Epoch: 24 [7680/8000 (96%)]\tTotal Loss: 0.403314\n",
      "Reconstruction: 0.329212, Regularization: 0.006997, Discriminator: 0.046292; Generator: 0.020813,\n",
      "D(x): 0.471, D(G(z)): 0.514\n",
      "2019-04-09 22:59:04,521 root         INFO     ====> Epoch: 24 Average loss: 0.3100\n",
      "2019-04-09 22:59:04,547 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 0.293184\n",
      "Reconstruction: 0.221836, Regularization: 0.005713, Discriminator: 0.044855; Generator: 0.020780,\n",
      "D(x): 0.493, D(G(z)): 0.514\n",
      "2019-04-09 22:59:04,649 root         INFO     Train Epoch: 25 [512/8000 (6%)]\tTotal Loss: 0.297174\n",
      "Reconstruction: 0.224012, Regularization: 0.006551, Discriminator: 0.045714; Generator: 0.020897,\n",
      "D(x): 0.478, D(G(z)): 0.512\n",
      "2019-04-09 22:59:04,751 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 0.339603\n",
      "Reconstruction: 0.268413, Regularization: 0.005127, Discriminator: 0.045188; Generator: 0.020874,\n",
      "D(x): 0.487, D(G(z)): 0.513\n",
      "2019-04-09 22:59:04,852 root         INFO     Train Epoch: 25 [1536/8000 (19%)]\tTotal Loss: 0.336454\n",
      "Reconstruction: 0.264814, Regularization: 0.005479, Discriminator: 0.045296; Generator: 0.020866,\n",
      "D(x): 0.485, D(G(z)): 0.513\n",
      "2019-04-09 22:59:04,953 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 0.455827\n",
      "Reconstruction: 0.380017, Regularization: 0.008067, Discriminator: 0.046826; Generator: 0.020916,\n",
      "D(x): 0.461, D(G(z)): 0.512\n",
      "2019-04-09 22:59:05,052 root         INFO     Train Epoch: 25 [2560/8000 (32%)]\tTotal Loss: 0.297890\n",
      "Reconstruction: 0.227199, Regularization: 0.005225, Discriminator: 0.044596; Generator: 0.020871,\n",
      "D(x): 0.495, D(G(z)): 0.513\n",
      "2019-04-09 22:59:05,151 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 0.363221\n",
      "Reconstruction: 0.291925, Regularization: 0.004771, Discriminator: 0.045621; Generator: 0.020905,\n",
      "D(x): 0.479, D(G(z)): 0.512\n",
      "2019-04-09 22:59:05,250 root         INFO     Train Epoch: 25 [3584/8000 (45%)]\tTotal Loss: 0.395191\n",
      "Reconstruction: 0.322179, Regularization: 0.005864, Discriminator: 0.046277; Generator: 0.020871,\n",
      "D(x): 0.471, D(G(z)): 0.513\n",
      "2019-04-09 22:59:05,349 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 0.328052\n",
      "Reconstruction: 0.258170, Regularization: 0.004511, Discriminator: 0.044409; Generator: 0.020962,\n",
      "D(x): 0.498, D(G(z)): 0.511\n",
      "2019-04-09 22:59:05,448 root         INFO     Train Epoch: 25 [4608/8000 (58%)]\tTotal Loss: 0.344260\n",
      "Reconstruction: 0.271250, Regularization: 0.006411, Discriminator: 0.045668; Generator: 0.020931,\n",
      "D(x): 0.478, D(G(z)): 0.512\n",
      "2019-04-09 22:59:05,550 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 0.318998\n",
      "Reconstruction: 0.247925, Regularization: 0.004770, Discriminator: 0.045377; Generator: 0.020925,\n",
      "D(x): 0.482, D(G(z)): 0.512\n",
      "2019-04-09 22:59:05,652 root         INFO     Train Epoch: 25 [5632/8000 (70%)]\tTotal Loss: 0.310338\n",
      "Reconstruction: 0.239048, Regularization: 0.005283, Discriminator: 0.045079; Generator: 0.020929,\n",
      "D(x): 0.487, D(G(z)): 0.512\n",
      "2019-04-09 22:59:05,754 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.278663\n",
      "Reconstruction: 0.207871, Regularization: 0.005119, Discriminator: 0.044690; Generator: 0.020983,\n",
      "D(x): 0.491, D(G(z)): 0.511\n",
      "2019-04-09 22:59:05,855 root         INFO     Train Epoch: 25 [6656/8000 (83%)]\tTotal Loss: 0.306901\n",
      "Reconstruction: 0.234885, Regularization: 0.006142, Discriminator: 0.044868; Generator: 0.021006,\n",
      "D(x): 0.488, D(G(z)): 0.511\n",
      "2019-04-09 22:59:05,956 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 0.338030\n",
      "Reconstruction: 0.267326, Regularization: 0.004523, Discriminator: 0.045185; Generator: 0.020997,\n",
      "D(x): 0.484, D(G(z)): 0.511\n",
      "2019-04-09 22:59:06,056 root         INFO     Train Epoch: 25 [7680/8000 (96%)]\tTotal Loss: 0.313697\n",
      "Reconstruction: 0.239390, Regularization: 0.008186, Discriminator: 0.045181; Generator: 0.020940,\n",
      "D(x): 0.484, D(G(z)): 0.512\n",
      "2019-04-09 22:59:06,130 root         INFO     ====> Epoch: 25 Average loss: 0.3101\n",
      "2019-04-09 22:59:06,157 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 0.334529\n",
      "Reconstruction: 0.262579, Regularization: 0.005858, Discriminator: 0.045128; Generator: 0.020964,\n",
      "D(x): 0.485, D(G(z)): 0.511\n",
      "2019-04-09 22:59:06,257 root         INFO     Train Epoch: 26 [512/8000 (6%)]\tTotal Loss: 0.313403\n",
      "Reconstruction: 0.244984, Regularization: 0.003303, Discriminator: 0.044161; Generator: 0.020955,\n",
      "D(x): 0.501, D(G(z)): 0.511\n",
      "2019-04-09 22:59:06,357 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 0.329315\n",
      "Reconstruction: 0.257596, Regularization: 0.005403, Discriminator: 0.045334; Generator: 0.020981,\n",
      "D(x): 0.482, D(G(z)): 0.511\n",
      "2019-04-09 22:59:06,457 root         INFO     Train Epoch: 26 [1536/8000 (19%)]\tTotal Loss: 0.331007\n",
      "Reconstruction: 0.259137, Regularization: 0.006160, Discriminator: 0.044602; Generator: 0.021108,\n",
      "D(x): 0.492, D(G(z)): 0.509\n",
      "2019-04-09 22:59:06,557 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 0.279000\n",
      "Reconstruction: 0.209592, Regularization: 0.004206, Discriminator: 0.044149; Generator: 0.021053,\n",
      "D(x): 0.499, D(G(z)): 0.510\n",
      "2019-04-09 22:59:06,658 root         INFO     Train Epoch: 26 [2560/8000 (32%)]\tTotal Loss: 0.308612\n",
      "Reconstruction: 0.236034, Regularization: 0.006088, Discriminator: 0.045393; Generator: 0.021097,\n",
      "D(x): 0.479, D(G(z)): 0.509\n",
      "2019-04-09 22:59:06,759 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 0.328773\n",
      "Reconstruction: 0.258985, Regularization: 0.004567, Discriminator: 0.044144; Generator: 0.021077,\n",
      "D(x): 0.500, D(G(z)): 0.509\n",
      "2019-04-09 22:59:06,859 root         INFO     Train Epoch: 26 [3584/8000 (45%)]\tTotal Loss: 0.405426\n",
      "Reconstruction: 0.332935, Regularization: 0.005845, Discriminator: 0.045656; Generator: 0.020991,\n",
      "D(x): 0.477, D(G(z)): 0.511\n",
      "2019-04-09 22:59:06,958 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.271393\n",
      "Reconstruction: 0.200276, Regularization: 0.005805, Discriminator: 0.044389; Generator: 0.020924,\n",
      "D(x): 0.497, D(G(z)): 0.512\n",
      "2019-04-09 22:59:07,059 root         INFO     Train Epoch: 26 [4608/8000 (58%)]\tTotal Loss: 0.262673\n",
      "Reconstruction: 0.191525, Regularization: 0.005608, Discriminator: 0.044464; Generator: 0.021076,\n",
      "D(x): 0.494, D(G(z)): 0.509\n",
      "2019-04-09 22:59:07,159 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 0.308716\n",
      "Reconstruction: 0.237299, Regularization: 0.005428, Discriminator: 0.044920; Generator: 0.021069,\n",
      "D(x): 0.487, D(G(z)): 0.510\n",
      "2019-04-09 22:59:07,259 root         INFO     Train Epoch: 26 [5632/8000 (70%)]\tTotal Loss: 0.263267\n",
      "Reconstruction: 0.193712, Regularization: 0.004712, Discriminator: 0.043779; Generator: 0.021064,\n",
      "D(x): 0.504, D(G(z)): 0.510\n",
      "2019-04-09 22:59:07,359 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 0.378456\n",
      "Reconstruction: 0.307755, Regularization: 0.004424, Discriminator: 0.045213; Generator: 0.021064,\n",
      "D(x): 0.482, D(G(z)): 0.510\n",
      "2019-04-09 22:59:07,458 root         INFO     Train Epoch: 26 [6656/8000 (83%)]\tTotal Loss: 0.271360\n",
      "Reconstruction: 0.201347, Regularization: 0.004039, Discriminator: 0.044886; Generator: 0.021089,\n",
      "D(x): 0.486, D(G(z)): 0.509\n",
      "2019-04-09 22:59:07,558 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 0.336070\n",
      "Reconstruction: 0.266329, Regularization: 0.004697, Discriminator: 0.043903; Generator: 0.021142,\n",
      "D(x): 0.502, D(G(z)): 0.508\n",
      "2019-04-09 22:59:07,658 root         INFO     Train Epoch: 26 [7680/8000 (96%)]\tTotal Loss: 0.320818\n",
      "Reconstruction: 0.251106, Regularization: 0.004910, Discriminator: 0.043720; Generator: 0.021082,\n",
      "D(x): 0.506, D(G(z)): 0.509\n",
      "2019-04-09 22:59:07,734 root         INFO     ====> Epoch: 26 Average loss: 0.3100\n",
      "2019-04-09 22:59:07,761 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 0.366838\n",
      "Reconstruction: 0.294635, Regularization: 0.006061, Discriminator: 0.045061; Generator: 0.021081,\n",
      "D(x): 0.484, D(G(z)): 0.509\n",
      "2019-04-09 22:59:07,862 root         INFO     Train Epoch: 27 [512/8000 (6%)]\tTotal Loss: 0.347873\n",
      "Reconstruction: 0.276851, Regularization: 0.005249, Discriminator: 0.044654; Generator: 0.021120,\n",
      "D(x): 0.489, D(G(z)): 0.509\n",
      "2019-04-09 22:59:07,964 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.344698\n",
      "Reconstruction: 0.274650, Regularization: 0.004681, Discriminator: 0.044236; Generator: 0.021131,\n",
      "D(x): 0.497, D(G(z)): 0.509\n",
      "2019-04-09 22:59:08,064 root         INFO     Train Epoch: 27 [1536/8000 (19%)]\tTotal Loss: 0.289624\n",
      "Reconstruction: 0.220792, Regularization: 0.003759, Discriminator: 0.043914; Generator: 0.021159,\n",
      "D(x): 0.500, D(G(z)): 0.508\n",
      "2019-04-09 22:59:08,163 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 0.307130\n",
      "Reconstruction: 0.237078, Regularization: 0.004565, Discriminator: 0.044404; Generator: 0.021082,\n",
      "D(x): 0.494, D(G(z)): 0.509\n",
      "2019-04-09 22:59:08,263 root         INFO     Train Epoch: 27 [2560/8000 (32%)]\tTotal Loss: 0.305956\n",
      "Reconstruction: 0.235939, Regularization: 0.004475, Discriminator: 0.044427; Generator: 0.021115,\n",
      "D(x): 0.493, D(G(z)): 0.509\n",
      "2019-04-09 22:59:08,363 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.280252\n",
      "Reconstruction: 0.209770, Regularization: 0.004522, Discriminator: 0.044819; Generator: 0.021141,\n",
      "D(x): 0.486, D(G(z)): 0.508\n",
      "2019-04-09 22:59:08,462 root         INFO     Train Epoch: 27 [3584/8000 (45%)]\tTotal Loss: 0.333209\n",
      "Reconstruction: 0.263743, Regularization: 0.003711, Discriminator: 0.044597; Generator: 0.021158,\n",
      "D(x): 0.490, D(G(z)): 0.508\n",
      "2019-04-09 22:59:08,558 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 0.315943\n",
      "Reconstruction: 0.245332, Regularization: 0.004901, Discriminator: 0.044494; Generator: 0.021217,\n",
      "D(x): 0.490, D(G(z)): 0.507\n",
      "2019-04-09 22:59:08,653 root         INFO     Train Epoch: 27 [4608/8000 (58%)]\tTotal Loss: 0.302074\n",
      "Reconstruction: 0.231844, Regularization: 0.004821, Discriminator: 0.044221; Generator: 0.021188,\n",
      "D(x): 0.495, D(G(z)): 0.508\n",
      "2019-04-09 22:59:08,749 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.301134\n",
      "Reconstruction: 0.230768, Regularization: 0.004661, Discriminator: 0.044533; Generator: 0.021172,\n",
      "D(x): 0.491, D(G(z)): 0.508\n",
      "2019-04-09 22:59:08,845 root         INFO     Train Epoch: 27 [5632/8000 (70%)]\tTotal Loss: 0.342873\n",
      "Reconstruction: 0.270248, Regularization: 0.005837, Discriminator: 0.045626; Generator: 0.021161,\n",
      "D(x): 0.473, D(G(z)): 0.508\n",
      "2019-04-09 22:59:08,941 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.293874\n",
      "Reconstruction: 0.223433, Regularization: 0.005413, Discriminator: 0.043845; Generator: 0.021182,\n",
      "D(x): 0.501, D(G(z)): 0.508\n",
      "2019-04-09 22:59:09,037 root         INFO     Train Epoch: 27 [6656/8000 (83%)]\tTotal Loss: 0.298139\n",
      "Reconstruction: 0.227437, Regularization: 0.005087, Discriminator: 0.044380; Generator: 0.021235,\n",
      "D(x): 0.492, D(G(z)): 0.507\n",
      "2019-04-09 22:59:09,133 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 0.297608\n",
      "Reconstruction: 0.227930, Regularization: 0.004929, Discriminator: 0.043483; Generator: 0.021265,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-09 22:59:09,230 root         INFO     Train Epoch: 27 [7680/8000 (96%)]\tTotal Loss: 0.343080\n",
      "Reconstruction: 0.274192, Regularization: 0.003694, Discriminator: 0.043969; Generator: 0.021225,\n",
      "D(x): 0.498, D(G(z)): 0.507\n",
      "2019-04-09 22:59:09,303 root         INFO     ====> Epoch: 27 Average loss: 0.3093\n",
      "2019-04-09 22:59:09,330 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.283499\n",
      "Reconstruction: 0.213962, Regularization: 0.004348, Discriminator: 0.043968; Generator: 0.021221,\n",
      "D(x): 0.498, D(G(z)): 0.507\n",
      "2019-04-09 22:59:09,431 root         INFO     Train Epoch: 28 [512/8000 (6%)]\tTotal Loss: 0.315108\n",
      "Reconstruction: 0.244941, Regularization: 0.004927, Discriminator: 0.043999; Generator: 0.021242,\n",
      "D(x): 0.498, D(G(z)): 0.507\n",
      "2019-04-09 22:59:09,530 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.298161\n",
      "Reconstruction: 0.228502, Regularization: 0.004460, Discriminator: 0.044015; Generator: 0.021184,\n",
      "D(x): 0.498, D(G(z)): 0.508\n",
      "2019-04-09 22:59:09,628 root         INFO     Train Epoch: 28 [1536/8000 (19%)]\tTotal Loss: 0.304000\n",
      "Reconstruction: 0.233360, Regularization: 0.005141, Discriminator: 0.044166; Generator: 0.021333,\n",
      "D(x): 0.493, D(G(z)): 0.505\n",
      "2019-04-09 22:59:09,727 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 0.346661\n",
      "Reconstruction: 0.274750, Regularization: 0.005654, Discriminator: 0.045083; Generator: 0.021174,\n",
      "D(x): 0.482, D(G(z)): 0.508\n",
      "2019-04-09 22:59:09,825 root         INFO     Train Epoch: 28 [2560/8000 (32%)]\tTotal Loss: 0.287814\n",
      "Reconstruction: 0.219136, Regularization: 0.003793, Discriminator: 0.043640; Generator: 0.021245,\n",
      "D(x): 0.503, D(G(z)): 0.507\n",
      "2019-04-09 22:59:09,924 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.265543\n",
      "Reconstruction: 0.196944, Regularization: 0.003451, Discriminator: 0.043838; Generator: 0.021311,\n",
      "D(x): 0.499, D(G(z)): 0.506\n",
      "2019-04-09 22:59:10,023 root         INFO     Train Epoch: 28 [3584/8000 (45%)]\tTotal Loss: 0.253099\n",
      "Reconstruction: 0.186028, Regularization: 0.002675, Discriminator: 0.043053; Generator: 0.021342,\n",
      "D(x): 0.511, D(G(z)): 0.505\n",
      "2019-04-09 22:59:10,123 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.325183\n",
      "Reconstruction: 0.254411, Regularization: 0.004577, Discriminator: 0.045006; Generator: 0.021189,\n",
      "D(x): 0.482, D(G(z)): 0.508\n",
      "2019-04-09 22:59:10,223 root         INFO     Train Epoch: 28 [4608/8000 (58%)]\tTotal Loss: 0.295981\n",
      "Reconstruction: 0.226152, Regularization: 0.004346, Discriminator: 0.044195; Generator: 0.021288,\n",
      "D(x): 0.493, D(G(z)): 0.506\n",
      "2019-04-09 22:59:10,325 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.348591\n",
      "Reconstruction: 0.278419, Regularization: 0.004645, Discriminator: 0.044299; Generator: 0.021229,\n",
      "D(x): 0.493, D(G(z)): 0.507\n",
      "2019-04-09 22:59:10,425 root         INFO     Train Epoch: 28 [5632/8000 (70%)]\tTotal Loss: 0.331308\n",
      "Reconstruction: 0.260957, Regularization: 0.004667, Discriminator: 0.044345; Generator: 0.021339,\n",
      "D(x): 0.491, D(G(z)): 0.505\n",
      "2019-04-09 22:59:10,526 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.325907\n",
      "Reconstruction: 0.257029, Regularization: 0.003923, Discriminator: 0.043584; Generator: 0.021370,\n",
      "D(x): 0.502, D(G(z)): 0.505\n",
      "2019-04-09 22:59:10,625 root         INFO     Train Epoch: 28 [6656/8000 (83%)]\tTotal Loss: 0.314164\n",
      "Reconstruction: 0.243311, Regularization: 0.004928, Discriminator: 0.044672; Generator: 0.021253,\n",
      "D(x): 0.487, D(G(z)): 0.507\n",
      "2019-04-09 22:59:10,726 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.251182\n",
      "Reconstruction: 0.183057, Regularization: 0.003392, Discriminator: 0.043485; Generator: 0.021248,\n",
      "D(x): 0.505, D(G(z)): 0.507\n",
      "2019-04-09 22:59:10,827 root         INFO     Train Epoch: 28 [7680/8000 (96%)]\tTotal Loss: 0.281720\n",
      "Reconstruction: 0.213232, Regularization: 0.003327, Discriminator: 0.043871; Generator: 0.021290,\n",
      "D(x): 0.499, D(G(z)): 0.506\n",
      "2019-04-09 22:59:10,903 root         INFO     ====> Epoch: 28 Average loss: 0.3084\n",
      "2019-04-09 22:59:10,929 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 0.229334\n",
      "Reconstruction: 0.160477, Regularization: 0.003710, Discriminator: 0.043819; Generator: 0.021328,\n",
      "D(x): 0.499, D(G(z)): 0.505\n",
      "2019-04-09 22:59:11,029 root         INFO     Train Epoch: 29 [512/8000 (6%)]\tTotal Loss: 0.300209\n",
      "Reconstruction: 0.230490, Regularization: 0.004688, Discriminator: 0.043702; Generator: 0.021329,\n",
      "D(x): 0.502, D(G(z)): 0.505\n",
      "2019-04-09 22:59:11,129 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 0.277581\n",
      "Reconstruction: 0.208326, Regularization: 0.003708, Discriminator: 0.044306; Generator: 0.021240,\n",
      "D(x): 0.492, D(G(z)): 0.507\n",
      "2019-04-09 22:59:11,229 root         INFO     Train Epoch: 29 [1536/8000 (19%)]\tTotal Loss: 0.317217\n",
      "Reconstruction: 0.248038, Regularization: 0.004153, Discriminator: 0.043652; Generator: 0.021374,\n",
      "D(x): 0.501, D(G(z)): 0.505\n",
      "2019-04-09 22:59:11,328 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 0.298699\n",
      "Reconstruction: 0.229824, Regularization: 0.003744, Discriminator: 0.043776; Generator: 0.021354,\n",
      "D(x): 0.499, D(G(z)): 0.505\n",
      "2019-04-09 22:59:11,426 root         INFO     Train Epoch: 29 [2560/8000 (32%)]\tTotal Loss: 0.245115\n",
      "Reconstruction: 0.177250, Regularization: 0.003076, Discriminator: 0.043490; Generator: 0.021298,\n",
      "D(x): 0.505, D(G(z)): 0.506\n",
      "2019-04-09 22:59:11,524 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 0.311089\n",
      "Reconstruction: 0.243134, Regularization: 0.002975, Discriminator: 0.043627; Generator: 0.021353,\n",
      "D(x): 0.501, D(G(z)): 0.505\n",
      "2019-04-09 22:59:11,622 root         INFO     Train Epoch: 29 [3584/8000 (45%)]\tTotal Loss: 0.286591\n",
      "Reconstruction: 0.217416, Regularization: 0.003579, Discriminator: 0.044228; Generator: 0.021368,\n",
      "D(x): 0.491, D(G(z)): 0.505\n",
      "2019-04-09 22:59:11,720 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.272511\n",
      "Reconstruction: 0.203151, Regularization: 0.003791, Discriminator: 0.044220; Generator: 0.021349,\n",
      "D(x): 0.492, D(G(z)): 0.505\n",
      "2019-04-09 22:59:11,818 root         INFO     Train Epoch: 29 [4608/8000 (58%)]\tTotal Loss: 0.275465\n",
      "Reconstruction: 0.205242, Regularization: 0.004508, Discriminator: 0.044362; Generator: 0.021353,\n",
      "D(x): 0.490, D(G(z)): 0.505\n",
      "2019-04-09 22:59:11,917 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 0.251882\n",
      "Reconstruction: 0.184259, Regularization: 0.003118, Discriminator: 0.043215; Generator: 0.021290,\n",
      "D(x): 0.509, D(G(z)): 0.506\n",
      "2019-04-09 22:59:12,015 root         INFO     Train Epoch: 29 [5632/8000 (70%)]\tTotal Loss: 0.279867\n",
      "Reconstruction: 0.211719, Regularization: 0.003198, Discriminator: 0.043608; Generator: 0.021343,\n",
      "D(x): 0.502, D(G(z)): 0.505\n",
      "2019-04-09 22:59:12,114 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 0.239565\n",
      "Reconstruction: 0.172470, Regularization: 0.002332, Discriminator: 0.043325; Generator: 0.021438,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-09 22:59:12,213 root         INFO     Train Epoch: 29 [6656/8000 (83%)]\tTotal Loss: 0.249624\n",
      "Reconstruction: 0.180150, Regularization: 0.004211, Discriminator: 0.043841; Generator: 0.021422,\n",
      "D(x): 0.497, D(G(z)): 0.504\n",
      "2019-04-09 22:59:12,311 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.364168\n",
      "Reconstruction: 0.295482, Regularization: 0.003608, Discriminator: 0.043699; Generator: 0.021379,\n",
      "D(x): 0.500, D(G(z)): 0.505\n",
      "2019-04-09 22:59:12,409 root         INFO     Train Epoch: 29 [7680/8000 (96%)]\tTotal Loss: 0.265979\n",
      "Reconstruction: 0.196800, Regularization: 0.003780, Discriminator: 0.044018; Generator: 0.021380,\n",
      "D(x): 0.495, D(G(z)): 0.505\n",
      "2019-04-09 22:59:12,484 root         INFO     ====> Epoch: 29 Average loss: 0.3076\n",
      "2019-04-09 22:59:12,510 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.275689\n",
      "Reconstruction: 0.207654, Regularization: 0.003423, Discriminator: 0.043126; Generator: 0.021486,\n",
      "D(x): 0.507, D(G(z)): 0.503\n",
      "2019-04-09 22:59:12,608 root         INFO     Train Epoch: 30 [512/8000 (6%)]\tTotal Loss: 0.262309\n",
      "Reconstruction: 0.195134, Regularization: 0.002483, Discriminator: 0.043274; Generator: 0.021419,\n",
      "D(x): 0.505, D(G(z)): 0.504\n",
      "2019-04-09 22:59:12,705 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.327687\n",
      "Reconstruction: 0.256921, Regularization: 0.004846, Discriminator: 0.044456; Generator: 0.021464,\n",
      "D(x): 0.487, D(G(z)): 0.503\n",
      "2019-04-09 22:59:12,803 root         INFO     Train Epoch: 30 [1536/8000 (19%)]\tTotal Loss: 0.302705\n",
      "Reconstruction: 0.234602, Regularization: 0.002887, Discriminator: 0.043831; Generator: 0.021385,\n",
      "D(x): 0.497, D(G(z)): 0.504\n",
      "2019-04-09 22:59:12,900 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.314329\n",
      "Reconstruction: 0.245993, Regularization: 0.003131, Discriminator: 0.043805; Generator: 0.021400,\n",
      "D(x): 0.497, D(G(z)): 0.504\n",
      "2019-04-09 22:59:12,998 root         INFO     Train Epoch: 30 [2560/8000 (32%)]\tTotal Loss: 0.306279\n",
      "Reconstruction: 0.236792, Regularization: 0.004108, Discriminator: 0.043885; Generator: 0.021494,\n",
      "D(x): 0.495, D(G(z)): 0.503\n",
      "2019-04-09 22:59:13,094 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.314933\n",
      "Reconstruction: 0.245668, Regularization: 0.004003, Discriminator: 0.043971; Generator: 0.021292,\n",
      "D(x): 0.497, D(G(z)): 0.506\n",
      "2019-04-09 22:59:13,192 root         INFO     Train Epoch: 30 [3584/8000 (45%)]\tTotal Loss: 0.318310\n",
      "Reconstruction: 0.249781, Regularization: 0.003146, Discriminator: 0.043929; Generator: 0.021454,\n",
      "D(x): 0.494, D(G(z)): 0.503\n",
      "2019-04-09 22:59:13,288 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.383613\n",
      "Reconstruction: 0.313416, Regularization: 0.004368, Discriminator: 0.044369; Generator: 0.021460,\n",
      "D(x): 0.489, D(G(z)): 0.503\n",
      "2019-04-09 22:59:13,385 root         INFO     Train Epoch: 30 [4608/8000 (58%)]\tTotal Loss: 0.285510\n",
      "Reconstruction: 0.216948, Regularization: 0.003493, Discriminator: 0.043669; Generator: 0.021400,\n",
      "D(x): 0.500, D(G(z)): 0.504\n",
      "2019-04-09 22:59:13,482 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.240774\n",
      "Reconstruction: 0.172927, Regularization: 0.002689, Discriminator: 0.043746; Generator: 0.021412,\n",
      "D(x): 0.498, D(G(z)): 0.504\n",
      "2019-04-09 22:59:13,580 root         INFO     Train Epoch: 30 [5632/8000 (70%)]\tTotal Loss: 0.308772\n",
      "Reconstruction: 0.240615, Regularization: 0.003162, Discriminator: 0.043589; Generator: 0.021406,\n",
      "D(x): 0.501, D(G(z)): 0.504\n",
      "2019-04-09 22:59:13,677 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.322231\n",
      "Reconstruction: 0.255275, Regularization: 0.002471, Discriminator: 0.043057; Generator: 0.021429,\n",
      "D(x): 0.509, D(G(z)): 0.504\n",
      "2019-04-09 22:59:13,774 root         INFO     Train Epoch: 30 [6656/8000 (83%)]\tTotal Loss: 0.326510\n",
      "Reconstruction: 0.257337, Regularization: 0.003649, Discriminator: 0.044144; Generator: 0.021380,\n",
      "D(x): 0.493, D(G(z)): 0.505\n",
      "2019-04-09 22:59:13,872 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 0.259630\n",
      "Reconstruction: 0.191764, Regularization: 0.003059, Discriminator: 0.043278; Generator: 0.021529,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 22:59:13,971 root         INFO     Train Epoch: 30 [7680/8000 (96%)]\tTotal Loss: 0.321049\n",
      "Reconstruction: 0.253420, Regularization: 0.002897, Discriminator: 0.043197; Generator: 0.021534,\n",
      "D(x): 0.505, D(G(z)): 0.502\n",
      "2019-04-09 22:59:14,044 root         INFO     ====> Epoch: 30 Average loss: 0.3068\n",
      "2019-04-09 22:59:14,071 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.224568\n",
      "Reconstruction: 0.157624, Regularization: 0.002298, Discriminator: 0.043251; Generator: 0.021395,\n",
      "D(x): 0.507, D(G(z)): 0.504\n",
      "2019-04-09 22:59:14,169 root         INFO     Train Epoch: 31 [512/8000 (6%)]\tTotal Loss: 0.347649\n",
      "Reconstruction: 0.279144, Regularization: 0.003005, Discriminator: 0.044072; Generator: 0.021428,\n",
      "D(x): 0.493, D(G(z)): 0.504\n",
      "2019-04-09 22:59:14,268 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.282244\n",
      "Reconstruction: 0.213754, Regularization: 0.003655, Discriminator: 0.043296; Generator: 0.021539,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 22:59:14,366 root         INFO     Train Epoch: 31 [1536/8000 (19%)]\tTotal Loss: 0.365015\n",
      "Reconstruction: 0.296808, Regularization: 0.003081, Discriminator: 0.043668; Generator: 0.021458,\n",
      "D(x): 0.499, D(G(z)): 0.503\n",
      "2019-04-09 22:59:14,464 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 0.324915\n",
      "Reconstruction: 0.256926, Regularization: 0.002774, Discriminator: 0.043875; Generator: 0.021339,\n",
      "D(x): 0.498, D(G(z)): 0.505\n",
      "2019-04-09 22:59:14,562 root         INFO     Train Epoch: 31 [2560/8000 (32%)]\tTotal Loss: 0.270463\n",
      "Reconstruction: 0.202490, Regularization: 0.003048, Discriminator: 0.043544; Generator: 0.021381,\n",
      "D(x): 0.502, D(G(z)): 0.505\n",
      "2019-04-09 22:59:14,660 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.284401\n",
      "Reconstruction: 0.216433, Regularization: 0.002558, Discriminator: 0.044009; Generator: 0.021401,\n",
      "D(x): 0.494, D(G(z)): 0.504\n",
      "2019-04-09 22:59:14,759 root         INFO     Train Epoch: 31 [3584/8000 (45%)]\tTotal Loss: 0.270976\n",
      "Reconstruction: 0.203219, Regularization: 0.003324, Discriminator: 0.043054; Generator: 0.021378,\n",
      "D(x): 0.510, D(G(z)): 0.505\n",
      "2019-04-09 22:59:14,857 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.247896\n",
      "Reconstruction: 0.179556, Regularization: 0.002960, Discriminator: 0.043904; Generator: 0.021477,\n",
      "D(x): 0.495, D(G(z)): 0.503\n",
      "2019-04-09 22:59:14,954 root         INFO     Train Epoch: 31 [4608/8000 (58%)]\tTotal Loss: 0.347587\n",
      "Reconstruction: 0.279731, Regularization: 0.002751, Discriminator: 0.043574; Generator: 0.021530,\n",
      "D(x): 0.499, D(G(z)): 0.502\n",
      "2019-04-09 22:59:15,052 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.295026\n",
      "Reconstruction: 0.227328, Regularization: 0.002835, Discriminator: 0.043298; Generator: 0.021565,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-09 22:59:15,150 root         INFO     Train Epoch: 31 [5632/8000 (70%)]\tTotal Loss: 0.255849\n",
      "Reconstruction: 0.188117, Regularization: 0.002568, Discriminator: 0.043685; Generator: 0.021479,\n",
      "D(x): 0.498, D(G(z)): 0.503\n",
      "2019-04-09 22:59:15,247 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 0.330323\n",
      "Reconstruction: 0.261562, Regularization: 0.003029, Discriminator: 0.044258; Generator: 0.021473,\n",
      "D(x): 0.489, D(G(z)): 0.503\n",
      "2019-04-09 22:59:15,344 root         INFO     Train Epoch: 31 [6656/8000 (83%)]\tTotal Loss: 0.308908\n",
      "Reconstruction: 0.240511, Regularization: 0.003385, Discriminator: 0.043647; Generator: 0.021365,\n",
      "D(x): 0.501, D(G(z)): 0.505\n",
      "2019-04-09 22:59:15,441 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 0.318829\n",
      "Reconstruction: 0.251362, Regularization: 0.002286, Discriminator: 0.043725; Generator: 0.021455,\n",
      "D(x): 0.497, D(G(z)): 0.503\n",
      "2019-04-09 22:59:15,538 root         INFO     Train Epoch: 31 [7680/8000 (96%)]\tTotal Loss: 0.334394\n",
      "Reconstruction: 0.266667, Regularization: 0.002348, Discriminator: 0.043810; Generator: 0.021568,\n",
      "D(x): 0.494, D(G(z)): 0.502\n",
      "2019-04-09 22:59:15,610 root         INFO     ====> Epoch: 31 Average loss: 0.3060\n",
      "2019-04-09 22:59:15,636 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.368090\n",
      "Reconstruction: 0.300343, Regularization: 0.002494, Discriminator: 0.043700; Generator: 0.021552,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 22:59:15,736 root         INFO     Train Epoch: 32 [512/8000 (6%)]\tTotal Loss: 0.291703\n",
      "Reconstruction: 0.224313, Regularization: 0.002217, Discriminator: 0.043738; Generator: 0.021435,\n",
      "D(x): 0.498, D(G(z)): 0.504\n",
      "2019-04-09 22:59:15,834 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.377072\n",
      "Reconstruction: 0.308251, Regularization: 0.003516, Discriminator: 0.043859; Generator: 0.021447,\n",
      "D(x): 0.496, D(G(z)): 0.503\n",
      "2019-04-09 22:59:15,933 root         INFO     Train Epoch: 32 [1536/8000 (19%)]\tTotal Loss: 0.379765\n",
      "Reconstruction: 0.311528, Regularization: 0.002624, Discriminator: 0.044187; Generator: 0.021427,\n",
      "D(x): 0.491, D(G(z)): 0.504\n",
      "2019-04-09 22:59:16,031 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.298687\n",
      "Reconstruction: 0.231423, Regularization: 0.002181, Discriminator: 0.043589; Generator: 0.021495,\n",
      "D(x): 0.499, D(G(z)): 0.503\n",
      "2019-04-09 22:59:16,129 root         INFO     Train Epoch: 32 [2560/8000 (32%)]\tTotal Loss: 0.368444\n",
      "Reconstruction: 0.300934, Regularization: 0.002409, Discriminator: 0.043603; Generator: 0.021498,\n",
      "D(x): 0.499, D(G(z)): 0.503\n",
      "2019-04-09 22:59:16,226 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.340086\n",
      "Reconstruction: 0.273741, Regularization: 0.001760, Discriminator: 0.043128; Generator: 0.021456,\n",
      "D(x): 0.507, D(G(z)): 0.503\n",
      "2019-04-09 22:59:16,324 root         INFO     Train Epoch: 32 [3584/8000 (45%)]\tTotal Loss: 0.281785\n",
      "Reconstruction: 0.214482, Regularization: 0.002361, Discriminator: 0.043401; Generator: 0.021540,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 22:59:16,421 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.346554\n",
      "Reconstruction: 0.277395, Regularization: 0.003774, Discriminator: 0.043977; Generator: 0.021408,\n",
      "D(x): 0.495, D(G(z)): 0.504\n",
      "2019-04-09 22:59:16,518 root         INFO     Train Epoch: 32 [4608/8000 (58%)]\tTotal Loss: 0.284301\n",
      "Reconstruction: 0.216716, Regularization: 0.002703, Discriminator: 0.043450; Generator: 0.021432,\n",
      "D(x): 0.503, D(G(z)): 0.504\n",
      "2019-04-09 22:59:16,615 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 0.279773\n",
      "Reconstruction: 0.213303, Regularization: 0.001807, Discriminator: 0.043144; Generator: 0.021520,\n",
      "D(x): 0.506, D(G(z)): 0.502\n",
      "2019-04-09 22:59:16,712 root         INFO     Train Epoch: 32 [5632/8000 (70%)]\tTotal Loss: 0.397324\n",
      "Reconstruction: 0.328585, Regularization: 0.003232, Discriminator: 0.043996; Generator: 0.021510,\n",
      "D(x): 0.493, D(G(z)): 0.502\n",
      "2019-04-09 22:59:16,809 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.330833\n",
      "Reconstruction: 0.261899, Regularization: 0.003416, Discriminator: 0.043932; Generator: 0.021586,\n",
      "D(x): 0.493, D(G(z)): 0.501\n",
      "2019-04-09 22:59:16,907 root         INFO     Train Epoch: 32 [6656/8000 (83%)]\tTotal Loss: 0.273486\n",
      "Reconstruction: 0.206434, Regularization: 0.002956, Discriminator: 0.042708; Generator: 0.021389,\n",
      "D(x): 0.516, D(G(z)): 0.504\n",
      "2019-04-09 22:59:17,003 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.286131\n",
      "Reconstruction: 0.218784, Regularization: 0.002766, Discriminator: 0.043104; Generator: 0.021477,\n",
      "D(x): 0.508, D(G(z)): 0.503\n",
      "2019-04-09 22:59:17,100 root         INFO     Train Epoch: 32 [7680/8000 (96%)]\tTotal Loss: 0.332656\n",
      "Reconstruction: 0.264434, Regularization: 0.002713, Discriminator: 0.043996; Generator: 0.021514,\n",
      "D(x): 0.493, D(G(z)): 0.502\n",
      "2019-04-09 22:59:17,174 root         INFO     ====> Epoch: 32 Average loss: 0.3056\n",
      "2019-04-09 22:59:17,200 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.312718\n",
      "Reconstruction: 0.246062, Regularization: 0.001893, Discriminator: 0.043233; Generator: 0.021531,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 22:59:17,299 root         INFO     Train Epoch: 33 [512/8000 (6%)]\tTotal Loss: 0.293291\n",
      "Reconstruction: 0.225431, Regularization: 0.002850, Discriminator: 0.043550; Generator: 0.021461,\n",
      "D(x): 0.501, D(G(z)): 0.503\n",
      "2019-04-09 22:59:17,398 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.350553\n",
      "Reconstruction: 0.283055, Regularization: 0.002237, Discriminator: 0.043840; Generator: 0.021421,\n",
      "D(x): 0.496, D(G(z)): 0.504\n",
      "2019-04-09 22:59:17,496 root         INFO     Train Epoch: 33 [1536/8000 (19%)]\tTotal Loss: 0.427919\n",
      "Reconstruction: 0.360497, Regularization: 0.002033, Discriminator: 0.043798; Generator: 0.021591,\n",
      "D(x): 0.494, D(G(z)): 0.501\n",
      "2019-04-09 22:59:17,594 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.259052\n",
      "Reconstruction: 0.191662, Regularization: 0.002185, Discriminator: 0.043707; Generator: 0.021498,\n",
      "D(x): 0.497, D(G(z)): 0.503\n",
      "2019-04-09 22:59:17,692 root         INFO     Train Epoch: 33 [2560/8000 (32%)]\tTotal Loss: 0.302693\n",
      "Reconstruction: 0.236116, Regularization: 0.001779, Discriminator: 0.043218; Generator: 0.021580,\n",
      "D(x): 0.504, D(G(z)): 0.501\n",
      "2019-04-09 22:59:17,790 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.277143\n",
      "Reconstruction: 0.211688, Regularization: 0.000915, Discriminator: 0.043085; Generator: 0.021454,\n",
      "D(x): 0.508, D(G(z)): 0.503\n",
      "2019-04-09 22:59:17,888 root         INFO     Train Epoch: 33 [3584/8000 (45%)]\tTotal Loss: 0.274345\n",
      "Reconstruction: 0.207449, Regularization: 0.001739, Discriminator: 0.043678; Generator: 0.021480,\n",
      "D(x): 0.498, D(G(z)): 0.503\n",
      "2019-04-09 22:59:17,986 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 0.311448\n",
      "Reconstruction: 0.244699, Regularization: 0.002046, Discriminator: 0.043177; Generator: 0.021526,\n",
      "D(x): 0.505, D(G(z)): 0.502\n",
      "2019-04-09 22:59:18,082 root         INFO     Train Epoch: 33 [4608/8000 (58%)]\tTotal Loss: 0.340917\n",
      "Reconstruction: 0.273559, Regularization: 0.001951, Discriminator: 0.043982; Generator: 0.021425,\n",
      "D(x): 0.494, D(G(z)): 0.504\n",
      "2019-04-09 22:59:18,178 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.263739\n",
      "Reconstruction: 0.196685, Regularization: 0.001918, Discriminator: 0.043642; Generator: 0.021494,\n",
      "D(x): 0.498, D(G(z)): 0.503\n",
      "2019-04-09 22:59:18,274 root         INFO     Train Epoch: 33 [5632/8000 (70%)]\tTotal Loss: 0.317752\n",
      "Reconstruction: 0.250733, Regularization: 0.002365, Discriminator: 0.043185; Generator: 0.021469,\n",
      "D(x): 0.506, D(G(z)): 0.503\n",
      "2019-04-09 22:59:18,369 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 0.305975\n",
      "Reconstruction: 0.238151, Regularization: 0.002418, Discriminator: 0.043885; Generator: 0.021521,\n",
      "D(x): 0.494, D(G(z)): 0.502\n",
      "2019-04-09 22:59:18,465 root         INFO     Train Epoch: 33 [6656/8000 (83%)]\tTotal Loss: 0.309266\n",
      "Reconstruction: 0.241784, Regularization: 0.002449, Discriminator: 0.043606; Generator: 0.021427,\n",
      "D(x): 0.500, D(G(z)): 0.504\n",
      "2019-04-09 22:59:18,561 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.348597\n",
      "Reconstruction: 0.281626, Regularization: 0.002111, Discriminator: 0.043398; Generator: 0.021462,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-09 22:59:18,657 root         INFO     Train Epoch: 33 [7680/8000 (96%)]\tTotal Loss: 0.262022\n",
      "Reconstruction: 0.194871, Regularization: 0.001870, Discriminator: 0.043849; Generator: 0.021432,\n",
      "D(x): 0.496, D(G(z)): 0.504\n",
      "2019-04-09 22:59:18,729 root         INFO     ====> Epoch: 33 Average loss: 0.3052\n",
      "2019-04-09 22:59:18,756 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.331553\n",
      "Reconstruction: 0.264372, Regularization: 0.002312, Discriminator: 0.043506; Generator: 0.021363,\n",
      "D(x): 0.503, D(G(z)): 0.505\n",
      "2019-04-09 22:59:18,854 root         INFO     Train Epoch: 34 [512/8000 (6%)]\tTotal Loss: 0.263697\n",
      "Reconstruction: 0.195407, Regularization: 0.002886, Discriminator: 0.043995; Generator: 0.021410,\n",
      "D(x): 0.494, D(G(z)): 0.504\n",
      "2019-04-09 22:59:18,951 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.257205\n",
      "Reconstruction: 0.190617, Regularization: 0.001634, Discriminator: 0.043522; Generator: 0.021432,\n",
      "D(x): 0.501, D(G(z)): 0.504\n",
      "2019-04-09 22:59:19,048 root         INFO     Train Epoch: 34 [1536/8000 (19%)]\tTotal Loss: 0.311555\n",
      "Reconstruction: 0.244820, Regularization: 0.001772, Discriminator: 0.043560; Generator: 0.021403,\n",
      "D(x): 0.501, D(G(z)): 0.504\n",
      "2019-04-09 22:59:19,144 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.342873\n",
      "Reconstruction: 0.274396, Regularization: 0.002800, Discriminator: 0.044191; Generator: 0.021486,\n",
      "D(x): 0.490, D(G(z)): 0.503\n",
      "2019-04-09 22:59:19,241 root         INFO     Train Epoch: 34 [2560/8000 (32%)]\tTotal Loss: 0.333546\n",
      "Reconstruction: 0.267249, Regularization: 0.001205, Discriminator: 0.043655; Generator: 0.021436,\n",
      "D(x): 0.499, D(G(z)): 0.504\n",
      "2019-04-09 22:59:19,337 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.309031\n",
      "Reconstruction: 0.241831, Regularization: 0.002269, Discriminator: 0.043489; Generator: 0.021442,\n",
      "D(x): 0.502, D(G(z)): 0.504\n",
      "2019-04-09 22:59:19,433 root         INFO     Train Epoch: 34 [3584/8000 (45%)]\tTotal Loss: 0.361385\n",
      "Reconstruction: 0.293172, Regularization: 0.002748, Discriminator: 0.044063; Generator: 0.021403,\n",
      "D(x): 0.493, D(G(z)): 0.504\n",
      "2019-04-09 22:59:19,529 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.343645\n",
      "Reconstruction: 0.276471, Regularization: 0.001907, Discriminator: 0.043878; Generator: 0.021389,\n",
      "D(x): 0.496, D(G(z)): 0.504\n",
      "2019-04-09 22:59:19,627 root         INFO     Train Epoch: 34 [4608/8000 (58%)]\tTotal Loss: 0.259152\n",
      "Reconstruction: 0.192629, Regularization: 0.001936, Discriminator: 0.043097; Generator: 0.021490,\n",
      "D(x): 0.507, D(G(z)): 0.503\n",
      "2019-04-09 22:59:19,725 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.319723\n",
      "Reconstruction: 0.252344, Regularization: 0.002263, Discriminator: 0.043713; Generator: 0.021403,\n",
      "D(x): 0.499, D(G(z)): 0.504\n",
      "2019-04-09 22:59:19,822 root         INFO     Train Epoch: 34 [5632/8000 (70%)]\tTotal Loss: 0.322792\n",
      "Reconstruction: 0.254462, Regularization: 0.003012, Discriminator: 0.043842; Generator: 0.021476,\n",
      "D(x): 0.496, D(G(z)): 0.503\n",
      "2019-04-09 22:59:19,920 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.312971\n",
      "Reconstruction: 0.245693, Regularization: 0.002199, Discriminator: 0.043690; Generator: 0.021388,\n",
      "D(x): 0.500, D(G(z)): 0.504\n",
      "2019-04-09 22:59:20,018 root         INFO     Train Epoch: 34 [6656/8000 (83%)]\tTotal Loss: 0.293253\n",
      "Reconstruction: 0.225129, Regularization: 0.002612, Discriminator: 0.044173; Generator: 0.021340,\n",
      "D(x): 0.493, D(G(z)): 0.505\n",
      "2019-04-09 22:59:20,116 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 0.270617\n",
      "Reconstruction: 0.204642, Regularization: 0.001292, Discriminator: 0.043285; Generator: 0.021398,\n",
      "D(x): 0.506, D(G(z)): 0.504\n",
      "2019-04-09 22:59:20,214 root         INFO     Train Epoch: 34 [7680/8000 (96%)]\tTotal Loss: 0.309538\n",
      "Reconstruction: 0.243342, Regularization: 0.001540, Discriminator: 0.043134; Generator: 0.021522,\n",
      "D(x): 0.506, D(G(z)): 0.502\n",
      "2019-04-09 22:59:20,287 root         INFO     ====> Epoch: 34 Average loss: 0.3053\n",
      "2019-04-09 22:59:20,314 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.279581\n",
      "Reconstruction: 0.211804, Regularization: 0.002554, Discriminator: 0.043704; Generator: 0.021519,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 22:59:20,412 root         INFO     Train Epoch: 35 [512/8000 (6%)]\tTotal Loss: 0.358444\n",
      "Reconstruction: 0.291319, Regularization: 0.001942, Discriminator: 0.043748; Generator: 0.021435,\n",
      "D(x): 0.498, D(G(z)): 0.504\n",
      "2019-04-09 22:59:20,511 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.271308\n",
      "Reconstruction: 0.205355, Regularization: 0.001485, Discriminator: 0.042979; Generator: 0.021489,\n",
      "D(x): 0.509, D(G(z)): 0.503\n",
      "2019-04-09 22:59:20,610 root         INFO     Train Epoch: 35 [1536/8000 (19%)]\tTotal Loss: 0.355737\n",
      "Reconstruction: 0.290174, Regularization: 0.000912, Discriminator: 0.043207; Generator: 0.021445,\n",
      "D(x): 0.506, D(G(z)): 0.503\n",
      "2019-04-09 22:59:20,708 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.341831\n",
      "Reconstruction: 0.275684, Regularization: 0.001506, Discriminator: 0.043232; Generator: 0.021410,\n",
      "D(x): 0.506, D(G(z)): 0.504\n",
      "2019-04-09 22:59:20,806 root         INFO     Train Epoch: 35 [2560/8000 (32%)]\tTotal Loss: 0.294452\n",
      "Reconstruction: 0.228011, Regularization: 0.001565, Discriminator: 0.043377; Generator: 0.021499,\n",
      "D(x): 0.502, D(G(z)): 0.503\n",
      "2019-04-09 22:59:20,904 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.308646\n",
      "Reconstruction: 0.242741, Regularization: 0.001169, Discriminator: 0.043263; Generator: 0.021473,\n",
      "D(x): 0.505, D(G(z)): 0.503\n",
      "2019-04-09 22:59:21,002 root         INFO     Train Epoch: 35 [3584/8000 (45%)]\tTotal Loss: 0.289313\n",
      "Reconstruction: 0.222013, Regularization: 0.002124, Discriminator: 0.043738; Generator: 0.021439,\n",
      "D(x): 0.498, D(G(z)): 0.504\n",
      "2019-04-09 22:59:21,100 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.266298\n",
      "Reconstruction: 0.199314, Regularization: 0.001597, Discriminator: 0.043964; Generator: 0.021423,\n",
      "D(x): 0.494, D(G(z)): 0.504\n",
      "2019-04-09 22:59:21,198 root         INFO     Train Epoch: 35 [4608/8000 (58%)]\tTotal Loss: 0.326188\n",
      "Reconstruction: 0.258391, Regularization: 0.002364, Discriminator: 0.043937; Generator: 0.021497,\n",
      "D(x): 0.494, D(G(z)): 0.503\n",
      "2019-04-09 22:59:21,296 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.280807\n",
      "Reconstruction: 0.214014, Regularization: 0.001433, Discriminator: 0.044071; Generator: 0.021289,\n",
      "D(x): 0.495, D(G(z)): 0.506\n",
      "2019-04-09 22:59:21,395 root         INFO     Train Epoch: 35 [5632/8000 (70%)]\tTotal Loss: 0.285526\n",
      "Reconstruction: 0.219354, Regularization: 0.001197, Discriminator: 0.043582; Generator: 0.021393,\n",
      "D(x): 0.501, D(G(z)): 0.504\n",
      "2019-04-09 22:59:21,493 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.276262\n",
      "Reconstruction: 0.210399, Regularization: 0.001442, Discriminator: 0.043065; Generator: 0.021355,\n",
      "D(x): 0.510, D(G(z)): 0.505\n",
      "2019-04-09 22:59:21,591 root         INFO     Train Epoch: 35 [6656/8000 (83%)]\tTotal Loss: 0.297961\n",
      "Reconstruction: 0.231269, Regularization: 0.001793, Discriminator: 0.043629; Generator: 0.021271,\n",
      "D(x): 0.502, D(G(z)): 0.506\n",
      "2019-04-09 22:59:21,689 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.269154\n",
      "Reconstruction: 0.202034, Regularization: 0.001792, Discriminator: 0.043873; Generator: 0.021454,\n",
      "D(x): 0.495, D(G(z)): 0.503\n",
      "2019-04-09 22:59:21,786 root         INFO     Train Epoch: 35 [7680/8000 (96%)]\tTotal Loss: 0.315583\n",
      "Reconstruction: 0.248384, Regularization: 0.002096, Discriminator: 0.043717; Generator: 0.021385,\n",
      "D(x): 0.499, D(G(z)): 0.504\n",
      "2019-04-09 22:59:21,860 root         INFO     ====> Epoch: 35 Average loss: 0.3061\n",
      "2019-04-09 22:59:21,886 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 0.257780\n",
      "Reconstruction: 0.191179, Regularization: 0.002032, Discriminator: 0.043272; Generator: 0.021297,\n",
      "D(x): 0.508, D(G(z)): 0.506\n",
      "2019-04-09 22:59:21,984 root         INFO     Train Epoch: 36 [512/8000 (6%)]\tTotal Loss: 0.272389\n",
      "Reconstruction: 0.206350, Regularization: 0.001389, Discriminator: 0.043245; Generator: 0.021406,\n",
      "D(x): 0.506, D(G(z)): 0.504\n",
      "2019-04-09 22:59:22,084 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.262728\n",
      "Reconstruction: 0.196370, Regularization: 0.001268, Discriminator: 0.043593; Generator: 0.021497,\n",
      "D(x): 0.499, D(G(z)): 0.503\n",
      "2019-04-09 22:59:22,183 root         INFO     Train Epoch: 36 [1536/8000 (19%)]\tTotal Loss: 0.290393\n",
      "Reconstruction: 0.223518, Regularization: 0.001482, Discriminator: 0.043962; Generator: 0.021432,\n",
      "D(x): 0.494, D(G(z)): 0.504\n",
      "2019-04-09 22:59:22,281 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.386131\n",
      "Reconstruction: 0.319059, Regularization: 0.001664, Discriminator: 0.044033; Generator: 0.021375,\n",
      "D(x): 0.494, D(G(z)): 0.505\n",
      "2019-04-09 22:59:22,380 root         INFO     Train Epoch: 36 [2560/8000 (32%)]\tTotal Loss: 0.278490\n",
      "Reconstruction: 0.211852, Regularization: 0.001672, Discriminator: 0.043524; Generator: 0.021441,\n",
      "D(x): 0.501, D(G(z)): 0.504\n",
      "2019-04-09 22:59:22,479 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.299056\n",
      "Reconstruction: 0.232527, Regularization: 0.001367, Discriminator: 0.043728; Generator: 0.021434,\n",
      "D(x): 0.498, D(G(z)): 0.504\n",
      "2019-04-09 22:59:22,577 root         INFO     Train Epoch: 36 [3584/8000 (45%)]\tTotal Loss: 0.255751\n",
      "Reconstruction: 0.188341, Regularization: 0.002127, Discriminator: 0.043923; Generator: 0.021360,\n",
      "D(x): 0.496, D(G(z)): 0.505\n",
      "2019-04-09 22:59:22,674 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.297433\n",
      "Reconstruction: 0.230590, Regularization: 0.001590, Discriminator: 0.043843; Generator: 0.021410,\n",
      "D(x): 0.496, D(G(z)): 0.504\n",
      "2019-04-09 22:59:22,772 root         INFO     Train Epoch: 36 [4608/8000 (58%)]\tTotal Loss: 0.269507\n",
      "Reconstruction: 0.203262, Regularization: 0.001464, Discriminator: 0.043451; Generator: 0.021331,\n",
      "D(x): 0.504, D(G(z)): 0.505\n",
      "2019-04-09 22:59:22,869 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.333771\n",
      "Reconstruction: 0.266485, Regularization: 0.002126, Discriminator: 0.043770; Generator: 0.021391,\n",
      "D(x): 0.498, D(G(z)): 0.504\n",
      "2019-04-09 22:59:22,966 root         INFO     Train Epoch: 36 [5632/8000 (70%)]\tTotal Loss: 0.288460\n",
      "Reconstruction: 0.222501, Regularization: 0.001332, Discriminator: 0.043275; Generator: 0.021352,\n",
      "D(x): 0.506, D(G(z)): 0.505\n",
      "2019-04-09 22:59:23,063 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 0.261342\n",
      "Reconstruction: 0.193516, Regularization: 0.002308, Discriminator: 0.044133; Generator: 0.021385,\n",
      "D(x): 0.492, D(G(z)): 0.504\n",
      "2019-04-09 22:59:23,160 root         INFO     Train Epoch: 36 [6656/8000 (83%)]\tTotal Loss: 0.276888\n",
      "Reconstruction: 0.210144, Regularization: 0.001514, Discriminator: 0.043895; Generator: 0.021335,\n",
      "D(x): 0.497, D(G(z)): 0.505\n",
      "2019-04-09 22:59:23,256 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.320803\n",
      "Reconstruction: 0.254080, Regularization: 0.001627, Discriminator: 0.043692; Generator: 0.021403,\n",
      "D(x): 0.499, D(G(z)): 0.504\n",
      "2019-04-09 22:59:23,353 root         INFO     Train Epoch: 36 [7680/8000 (96%)]\tTotal Loss: 0.279742\n",
      "Reconstruction: 0.213729, Regularization: 0.001138, Discriminator: 0.043486; Generator: 0.021389,\n",
      "D(x): 0.502, D(G(z)): 0.504\n",
      "2019-04-09 22:59:23,427 root         INFO     ====> Epoch: 36 Average loss: 0.3070\n",
      "2019-04-09 22:59:23,453 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.300809\n",
      "Reconstruction: 0.235101, Regularization: 0.000921, Discriminator: 0.043389; Generator: 0.021398,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-09 22:59:23,554 root         INFO     Train Epoch: 37 [512/8000 (6%)]\tTotal Loss: 0.229756\n",
      "Reconstruction: 0.162059, Regularization: 0.002040, Discriminator: 0.044226; Generator: 0.021430,\n",
      "D(x): 0.490, D(G(z)): 0.504\n",
      "2019-04-09 22:59:23,653 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.361377\n",
      "Reconstruction: 0.294126, Regularization: 0.001954, Discriminator: 0.043895; Generator: 0.021403,\n",
      "D(x): 0.496, D(G(z)): 0.504\n",
      "2019-04-09 22:59:23,752 root         INFO     Train Epoch: 37 [1536/8000 (19%)]\tTotal Loss: 0.360697\n",
      "Reconstruction: 0.293312, Regularization: 0.002081, Discriminator: 0.043847; Generator: 0.021456,\n",
      "D(x): 0.496, D(G(z)): 0.503\n",
      "2019-04-09 22:59:23,851 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.308384\n",
      "Reconstruction: 0.242739, Regularization: 0.000890, Discriminator: 0.043390; Generator: 0.021365,\n",
      "D(x): 0.504, D(G(z)): 0.505\n",
      "2019-04-09 22:59:23,950 root         INFO     Train Epoch: 37 [2560/8000 (32%)]\tTotal Loss: 0.372267\n",
      "Reconstruction: 0.305915, Regularization: 0.001427, Discriminator: 0.043487; Generator: 0.021438,\n",
      "D(x): 0.501, D(G(z)): 0.504\n",
      "2019-04-09 22:59:24,047 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 0.307908\n",
      "Reconstruction: 0.241920, Regularization: 0.001072, Discriminator: 0.043506; Generator: 0.021409,\n",
      "D(x): 0.501, D(G(z)): 0.504\n",
      "2019-04-09 22:59:24,143 root         INFO     Train Epoch: 37 [3584/8000 (45%)]\tTotal Loss: 0.386329\n",
      "Reconstruction: 0.319751, Regularization: 0.001727, Discriminator: 0.043441; Generator: 0.021410,\n",
      "D(x): 0.503, D(G(z)): 0.504\n",
      "2019-04-09 22:59:24,239 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.306170\n",
      "Reconstruction: 0.239176, Regularization: 0.001707, Discriminator: 0.043902; Generator: 0.021386,\n",
      "D(x): 0.496, D(G(z)): 0.504\n",
      "2019-04-09 22:59:24,335 root         INFO     Train Epoch: 37 [4608/8000 (58%)]\tTotal Loss: 0.284792\n",
      "Reconstruction: 0.218854, Regularization: 0.001266, Discriminator: 0.043266; Generator: 0.021405,\n",
      "D(x): 0.505, D(G(z)): 0.504\n",
      "2019-04-09 22:59:24,431 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.298965\n",
      "Reconstruction: 0.231411, Regularization: 0.002231, Discriminator: 0.043882; Generator: 0.021441,\n",
      "D(x): 0.495, D(G(z)): 0.504\n",
      "2019-04-09 22:59:24,527 root         INFO     Train Epoch: 37 [5632/8000 (70%)]\tTotal Loss: 0.308502\n",
      "Reconstruction: 0.241893, Regularization: 0.001581, Discriminator: 0.043612; Generator: 0.021416,\n",
      "D(x): 0.500, D(G(z)): 0.504\n",
      "2019-04-09 22:59:24,624 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.278677\n",
      "Reconstruction: 0.211774, Regularization: 0.001745, Discriminator: 0.043716; Generator: 0.021442,\n",
      "D(x): 0.498, D(G(z)): 0.504\n",
      "2019-04-09 22:59:24,720 root         INFO     Train Epoch: 37 [6656/8000 (83%)]\tTotal Loss: 0.225963\n",
      "Reconstruction: 0.159701, Regularization: 0.001260, Discriminator: 0.043623; Generator: 0.021379,\n",
      "D(x): 0.500, D(G(z)): 0.505\n",
      "2019-04-09 22:59:24,818 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.340382\n",
      "Reconstruction: 0.273232, Regularization: 0.001992, Discriminator: 0.043734; Generator: 0.021424,\n",
      "D(x): 0.498, D(G(z)): 0.504\n",
      "2019-04-09 22:59:24,914 root         INFO     Train Epoch: 37 [7680/8000 (96%)]\tTotal Loss: 0.298722\n",
      "Reconstruction: 0.232039, Regularization: 0.001711, Discriminator: 0.043561; Generator: 0.021411,\n",
      "D(x): 0.501, D(G(z)): 0.504\n",
      "2019-04-09 22:59:24,986 root         INFO     ====> Epoch: 37 Average loss: 0.3087\n",
      "2019-04-09 22:59:25,012 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.316191\n",
      "Reconstruction: 0.248932, Regularization: 0.002319, Discriminator: 0.043494; Generator: 0.021446,\n",
      "D(x): 0.501, D(G(z)): 0.503\n",
      "2019-04-09 22:59:25,112 root         INFO     Train Epoch: 38 [512/8000 (6%)]\tTotal Loss: 0.284987\n",
      "Reconstruction: 0.218380, Regularization: 0.001677, Discriminator: 0.043540; Generator: 0.021389,\n",
      "D(x): 0.501, D(G(z)): 0.504\n",
      "2019-04-09 22:59:25,210 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.257717\n",
      "Reconstruction: 0.189860, Regularization: 0.002324, Discriminator: 0.044114; Generator: 0.021419,\n",
      "D(x): 0.492, D(G(z)): 0.504\n",
      "2019-04-09 22:59:25,309 root         INFO     Train Epoch: 38 [1536/8000 (19%)]\tTotal Loss: 0.373192\n",
      "Reconstruction: 0.306432, Regularization: 0.001725, Discriminator: 0.043549; Generator: 0.021486,\n",
      "D(x): 0.500, D(G(z)): 0.503\n",
      "2019-04-09 22:59:25,407 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.282976\n",
      "Reconstruction: 0.216029, Regularization: 0.001740, Discriminator: 0.043754; Generator: 0.021453,\n",
      "D(x): 0.497, D(G(z)): 0.503\n",
      "2019-04-09 22:59:25,506 root         INFO     Train Epoch: 38 [2560/8000 (32%)]\tTotal Loss: 0.301177\n",
      "Reconstruction: 0.234915, Regularization: 0.001367, Discriminator: 0.043480; Generator: 0.021415,\n",
      "D(x): 0.502, D(G(z)): 0.504\n",
      "2019-04-09 22:59:25,604 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 0.373625\n",
      "Reconstruction: 0.307111, Regularization: 0.001550, Discriminator: 0.043513; Generator: 0.021451,\n",
      "D(x): 0.501, D(G(z)): 0.503\n",
      "2019-04-09 22:59:25,703 root         INFO     Train Epoch: 38 [3584/8000 (45%)]\tTotal Loss: 0.378781\n",
      "Reconstruction: 0.312149, Regularization: 0.001531, Discriminator: 0.043716; Generator: 0.021386,\n",
      "D(x): 0.498, D(G(z)): 0.504\n",
      "2019-04-09 22:59:25,803 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.310360\n",
      "Reconstruction: 0.243855, Regularization: 0.001816, Discriminator: 0.043260; Generator: 0.021430,\n",
      "D(x): 0.505, D(G(z)): 0.504\n",
      "2019-04-09 22:59:25,902 root         INFO     Train Epoch: 38 [4608/8000 (58%)]\tTotal Loss: 0.267675\n",
      "Reconstruction: 0.201219, Regularization: 0.001462, Discriminator: 0.043588; Generator: 0.021407,\n",
      "D(x): 0.500, D(G(z)): 0.504\n",
      "2019-04-09 22:59:26,001 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.313108\n",
      "Reconstruction: 0.246272, Regularization: 0.001969, Discriminator: 0.043436; Generator: 0.021431,\n",
      "D(x): 0.502, D(G(z)): 0.504\n",
      "2019-04-09 22:59:26,100 root         INFO     Train Epoch: 38 [5632/8000 (70%)]\tTotal Loss: 0.362702\n",
      "Reconstruction: 0.296654, Regularization: 0.001119, Discriminator: 0.043487; Generator: 0.021442,\n",
      "D(x): 0.501, D(G(z)): 0.504\n",
      "2019-04-09 22:59:26,200 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.292216\n",
      "Reconstruction: 0.226223, Regularization: 0.001226, Discriminator: 0.043309; Generator: 0.021458,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-09 22:59:26,299 root         INFO     Train Epoch: 38 [6656/8000 (83%)]\tTotal Loss: 0.293061\n",
      "Reconstruction: 0.225250, Regularization: 0.002339, Discriminator: 0.044024; Generator: 0.021447,\n",
      "D(x): 0.493, D(G(z)): 0.503\n",
      "2019-04-09 22:59:26,398 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.306975\n",
      "Reconstruction: 0.239784, Regularization: 0.002180, Discriminator: 0.043526; Generator: 0.021486,\n",
      "D(x): 0.500, D(G(z)): 0.503\n",
      "2019-04-09 22:59:26,496 root         INFO     Train Epoch: 38 [7680/8000 (96%)]\tTotal Loss: 0.311015\n",
      "Reconstruction: 0.243868, Regularization: 0.001833, Discriminator: 0.043901; Generator: 0.021413,\n",
      "D(x): 0.495, D(G(z)): 0.504\n",
      "2019-04-09 22:59:26,570 root         INFO     ====> Epoch: 38 Average loss: 0.3104\n",
      "2019-04-09 22:59:26,597 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 0.309097\n",
      "Reconstruction: 0.242166, Regularization: 0.002034, Discriminator: 0.043438; Generator: 0.021458,\n",
      "D(x): 0.502, D(G(z)): 0.503\n",
      "2019-04-09 22:59:26,697 root         INFO     Train Epoch: 39 [512/8000 (6%)]\tTotal Loss: 0.228702\n",
      "Reconstruction: 0.161461, Regularization: 0.002164, Discriminator: 0.043661; Generator: 0.021417,\n",
      "D(x): 0.499, D(G(z)): 0.504\n",
      "2019-04-09 22:59:26,797 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.354844\n",
      "Reconstruction: 0.287517, Regularization: 0.002279, Discriminator: 0.043591; Generator: 0.021457,\n",
      "D(x): 0.499, D(G(z)): 0.503\n",
      "2019-04-09 22:59:26,896 root         INFO     Train Epoch: 39 [1536/8000 (19%)]\tTotal Loss: 0.329613\n",
      "Reconstruction: 0.262226, Regularization: 0.002312, Discriminator: 0.043615; Generator: 0.021460,\n",
      "D(x): 0.499, D(G(z)): 0.503\n",
      "2019-04-09 22:59:26,995 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.313153\n",
      "Reconstruction: 0.245828, Regularization: 0.002151, Discriminator: 0.043692; Generator: 0.021481,\n",
      "D(x): 0.497, D(G(z)): 0.503\n",
      "2019-04-09 22:59:27,095 root         INFO     Train Epoch: 39 [2560/8000 (32%)]\tTotal Loss: 0.330059\n",
      "Reconstruction: 0.262156, Regularization: 0.002806, Discriminator: 0.043624; Generator: 0.021473,\n",
      "D(x): 0.499, D(G(z)): 0.503\n",
      "2019-04-09 22:59:27,195 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.401777\n",
      "Reconstruction: 0.334438, Regularization: 0.002652, Discriminator: 0.043217; Generator: 0.021471,\n",
      "D(x): 0.505, D(G(z)): 0.503\n",
      "2019-04-09 22:59:27,294 root         INFO     Train Epoch: 39 [3584/8000 (45%)]\tTotal Loss: 0.284143\n",
      "Reconstruction: 0.217830, Regularization: 0.001536, Discriminator: 0.043315; Generator: 0.021463,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-09 22:59:27,394 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.278472\n",
      "Reconstruction: 0.210955, Regularization: 0.002258, Discriminator: 0.043770; Generator: 0.021489,\n",
      "D(x): 0.496, D(G(z)): 0.503\n",
      "2019-04-09 22:59:27,494 root         INFO     Train Epoch: 39 [4608/8000 (58%)]\tTotal Loss: 0.321655\n",
      "Reconstruction: 0.253789, Regularization: 0.002587, Discriminator: 0.043821; Generator: 0.021458,\n",
      "D(x): 0.496, D(G(z)): 0.503\n",
      "2019-04-09 22:59:27,592 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.229991\n",
      "Reconstruction: 0.163635, Regularization: 0.001179, Discriminator: 0.043711; Generator: 0.021466,\n",
      "D(x): 0.497, D(G(z)): 0.503\n",
      "2019-04-09 22:59:27,692 root         INFO     Train Epoch: 39 [5632/8000 (70%)]\tTotal Loss: 0.347280\n",
      "Reconstruction: 0.280550, Regularization: 0.001737, Discriminator: 0.043529; Generator: 0.021464,\n",
      "D(x): 0.500, D(G(z)): 0.503\n",
      "2019-04-09 22:59:27,791 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.284232\n",
      "Reconstruction: 0.217498, Regularization: 0.001628, Discriminator: 0.043678; Generator: 0.021428,\n",
      "D(x): 0.498, D(G(z)): 0.504\n",
      "2019-04-09 22:59:27,890 root         INFO     Train Epoch: 39 [6656/8000 (83%)]\tTotal Loss: 0.344264\n",
      "Reconstruction: 0.276864, Regularization: 0.002194, Discriminator: 0.043720; Generator: 0.021486,\n",
      "D(x): 0.497, D(G(z)): 0.503\n",
      "2019-04-09 22:59:27,989 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.270380\n",
      "Reconstruction: 0.203547, Regularization: 0.001630, Discriminator: 0.043674; Generator: 0.021529,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 22:59:28,088 root         INFO     Train Epoch: 39 [7680/8000 (96%)]\tTotal Loss: 0.337464\n",
      "Reconstruction: 0.270612, Regularization: 0.001883, Discriminator: 0.043481; Generator: 0.021488,\n",
      "D(x): 0.500, D(G(z)): 0.503\n",
      "2019-04-09 22:59:28,161 root         INFO     ====> Epoch: 39 Average loss: 0.3123\n",
      "2019-04-09 22:59:28,188 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.259973\n",
      "Reconstruction: 0.193118, Regularization: 0.001835, Discriminator: 0.043544; Generator: 0.021476,\n",
      "D(x): 0.500, D(G(z)): 0.503\n",
      "2019-04-09 22:59:28,286 root         INFO     Train Epoch: 40 [512/8000 (6%)]\tTotal Loss: 0.318327\n",
      "Reconstruction: 0.250302, Regularization: 0.002703, Discriminator: 0.043820; Generator: 0.021502,\n",
      "D(x): 0.495, D(G(z)): 0.503\n",
      "2019-04-09 22:59:28,385 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.292057\n",
      "Reconstruction: 0.225004, Regularization: 0.002001, Discriminator: 0.043534; Generator: 0.021518,\n",
      "D(x): 0.499, D(G(z)): 0.502\n",
      "2019-04-09 22:59:28,483 root         INFO     Train Epoch: 40 [1536/8000 (19%)]\tTotal Loss: 0.298339\n",
      "Reconstruction: 0.231689, Regularization: 0.001768, Discriminator: 0.043361; Generator: 0.021520,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 22:59:28,582 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.371273\n",
      "Reconstruction: 0.304031, Regularization: 0.002090, Discriminator: 0.043623; Generator: 0.021530,\n",
      "D(x): 0.498, D(G(z)): 0.502\n",
      "2019-04-09 22:59:28,679 root         INFO     Train Epoch: 40 [2560/8000 (32%)]\tTotal Loss: 0.327350\n",
      "Reconstruction: 0.259904, Regularization: 0.002251, Discriminator: 0.043649; Generator: 0.021546,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 22:59:28,779 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.329140\n",
      "Reconstruction: 0.261987, Regularization: 0.002374, Discriminator: 0.043245; Generator: 0.021533,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-09 22:59:28,877 root         INFO     Train Epoch: 40 [3584/8000 (45%)]\tTotal Loss: 0.242740\n",
      "Reconstruction: 0.176161, Regularization: 0.001540, Discriminator: 0.043523; Generator: 0.021516,\n",
      "D(x): 0.499, D(G(z)): 0.502\n",
      "2019-04-09 22:59:28,976 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.262661\n",
      "Reconstruction: 0.195664, Regularization: 0.001823, Discriminator: 0.043675; Generator: 0.021500,\n",
      "D(x): 0.497, D(G(z)): 0.503\n",
      "2019-04-09 22:59:29,075 root         INFO     Train Epoch: 40 [4608/8000 (58%)]\tTotal Loss: 0.312202\n",
      "Reconstruction: 0.244909, Regularization: 0.002299, Discriminator: 0.043474; Generator: 0.021520,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 22:59:29,175 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 0.383776\n",
      "Reconstruction: 0.315968, Regularization: 0.002651, Discriminator: 0.043621; Generator: 0.021535,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 22:59:29,276 root         INFO     Train Epoch: 40 [5632/8000 (70%)]\tTotal Loss: 0.314460\n",
      "Reconstruction: 0.247547, Regularization: 0.002059, Discriminator: 0.043321; Generator: 0.021533,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 22:59:29,376 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.290565\n",
      "Reconstruction: 0.222298, Regularization: 0.003125, Discriminator: 0.043587; Generator: 0.021555,\n",
      "D(x): 0.498, D(G(z)): 0.502\n",
      "2019-04-09 22:59:29,474 root         INFO     Train Epoch: 40 [6656/8000 (83%)]\tTotal Loss: 0.258868\n",
      "Reconstruction: 0.191216, Regularization: 0.002506, Discriminator: 0.043612; Generator: 0.021534,\n",
      "D(x): 0.498, D(G(z)): 0.502\n",
      "2019-04-09 22:59:29,571 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.329811\n",
      "Reconstruction: 0.263269, Regularization: 0.001686, Discriminator: 0.043294; Generator: 0.021562,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 22:59:29,668 root         INFO     Train Epoch: 40 [7680/8000 (96%)]\tTotal Loss: 0.300564\n",
      "Reconstruction: 0.233754, Regularization: 0.001911, Discriminator: 0.043340; Generator: 0.021559,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 22:59:29,741 root         INFO     ====> Epoch: 40 Average loss: 0.3140\n",
      "2019-04-09 22:59:29,768 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 0.303479\n",
      "Reconstruction: 0.236217, Regularization: 0.002246, Discriminator: 0.043470; Generator: 0.021545,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 22:59:29,868 root         INFO     Train Epoch: 41 [512/8000 (6%)]\tTotal Loss: 0.284056\n",
      "Reconstruction: 0.217100, Regularization: 0.001938, Discriminator: 0.043448; Generator: 0.021570,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 22:59:29,968 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.296944\n",
      "Reconstruction: 0.229488, Regularization: 0.002582, Discriminator: 0.043296; Generator: 0.021578,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 22:59:30,068 root         INFO     Train Epoch: 41 [1536/8000 (19%)]\tTotal Loss: 0.339492\n",
      "Reconstruction: 0.272476, Regularization: 0.002337, Discriminator: 0.043105; Generator: 0.021574,\n",
      "D(x): 0.505, D(G(z)): 0.501\n",
      "2019-04-09 22:59:30,167 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 0.288756\n",
      "Reconstruction: 0.221715, Regularization: 0.002206, Discriminator: 0.043247; Generator: 0.021588,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 22:59:30,267 root         INFO     Train Epoch: 41 [2560/8000 (32%)]\tTotal Loss: 0.337073\n",
      "Reconstruction: 0.269784, Regularization: 0.002321, Discriminator: 0.043366; Generator: 0.021602,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 22:59:30,365 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.289128\n",
      "Reconstruction: 0.221556, Regularization: 0.002651, Discriminator: 0.043292; Generator: 0.021629,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 22:59:30,464 root         INFO     Train Epoch: 41 [3584/8000 (45%)]\tTotal Loss: 0.315293\n",
      "Reconstruction: 0.248105, Regularization: 0.002361, Discriminator: 0.043201; Generator: 0.021627,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 22:59:30,563 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.329278\n",
      "Reconstruction: 0.262130, Regularization: 0.002533, Discriminator: 0.042985; Generator: 0.021630,\n",
      "D(x): 0.506, D(G(z)): 0.500\n",
      "2019-04-09 22:59:30,663 root         INFO     Train Epoch: 41 [4608/8000 (58%)]\tTotal Loss: 0.337936\n",
      "Reconstruction: 0.270057, Regularization: 0.003070, Discriminator: 0.043174; Generator: 0.021635,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 22:59:30,762 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 0.254393\n",
      "Reconstruction: 0.187551, Regularization: 0.001924, Discriminator: 0.043269; Generator: 0.021649,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:59:30,861 root         INFO     Train Epoch: 41 [5632/8000 (70%)]\tTotal Loss: 0.328989\n",
      "Reconstruction: 0.261658, Regularization: 0.002511, Discriminator: 0.043174; Generator: 0.021646,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 22:59:30,961 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.292990\n",
      "Reconstruction: 0.224796, Regularization: 0.003164, Discriminator: 0.043361; Generator: 0.021669,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:59:31,060 root         INFO     Train Epoch: 41 [6656/8000 (83%)]\tTotal Loss: 0.419582\n",
      "Reconstruction: 0.352030, Regularization: 0.003046, Discriminator: 0.042838; Generator: 0.021668,\n",
      "D(x): 0.508, D(G(z)): 0.500\n",
      "2019-04-09 22:59:31,159 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.256575\n",
      "Reconstruction: 0.189786, Regularization: 0.001731, Discriminator: 0.043353; Generator: 0.021704,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:59:31,258 root         INFO     Train Epoch: 41 [7680/8000 (96%)]\tTotal Loss: 0.295698\n",
      "Reconstruction: 0.229110, Regularization: 0.001843, Discriminator: 0.043041; Generator: 0.021704,\n",
      "D(x): 0.504, D(G(z)): 0.499\n",
      "2019-04-09 22:59:31,332 root         INFO     ====> Epoch: 41 Average loss: 0.3156\n",
      "2019-04-09 22:59:31,358 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.355279\n",
      "Reconstruction: 0.286981, Regularization: 0.003490, Discriminator: 0.043092; Generator: 0.021715,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 22:59:31,456 root         INFO     Train Epoch: 42 [512/8000 (6%)]\tTotal Loss: 0.315002\n",
      "Reconstruction: 0.247987, Regularization: 0.002332, Discriminator: 0.042984; Generator: 0.021700,\n",
      "D(x): 0.505, D(G(z)): 0.499\n",
      "2019-04-09 22:59:31,553 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.393427\n",
      "Reconstruction: 0.325930, Regularization: 0.003050, Discriminator: 0.042720; Generator: 0.021728,\n",
      "D(x): 0.509, D(G(z)): 0.499\n",
      "2019-04-09 22:59:31,650 root         INFO     Train Epoch: 42 [1536/8000 (19%)]\tTotal Loss: 0.348839\n",
      "Reconstruction: 0.281863, Regularization: 0.002561, Discriminator: 0.042683; Generator: 0.021732,\n",
      "D(x): 0.509, D(G(z)): 0.499\n",
      "2019-04-09 22:59:31,749 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.294697\n",
      "Reconstruction: 0.227481, Regularization: 0.002477, Discriminator: 0.042970; Generator: 0.021770,\n",
      "D(x): 0.504, D(G(z)): 0.498\n",
      "2019-04-09 22:59:31,852 root         INFO     Train Epoch: 42 [2560/8000 (32%)]\tTotal Loss: 0.288703\n",
      "Reconstruction: 0.221772, Regularization: 0.002149, Discriminator: 0.042989; Generator: 0.021793,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 22:59:31,953 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 0.323694\n",
      "Reconstruction: 0.256294, Regularization: 0.002787, Discriminator: 0.042824; Generator: 0.021788,\n",
      "D(x): 0.506, D(G(z)): 0.498\n",
      "2019-04-09 22:59:32,054 root         INFO     Train Epoch: 42 [3584/8000 (45%)]\tTotal Loss: 0.423748\n",
      "Reconstruction: 0.355935, Regularization: 0.003263, Discriminator: 0.042746; Generator: 0.021804,\n",
      "D(x): 0.507, D(G(z)): 0.498\n",
      "2019-04-09 22:59:32,155 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.276833\n",
      "Reconstruction: 0.209757, Regularization: 0.002456, Discriminator: 0.042801; Generator: 0.021819,\n",
      "D(x): 0.506, D(G(z)): 0.497\n",
      "2019-04-09 22:59:32,256 root         INFO     Train Epoch: 42 [4608/8000 (58%)]\tTotal Loss: 0.283755\n",
      "Reconstruction: 0.216735, Regularization: 0.002121, Discriminator: 0.043053; Generator: 0.021845,\n",
      "D(x): 0.502, D(G(z)): 0.497\n",
      "2019-04-09 22:59:32,357 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.303468\n",
      "Reconstruction: 0.236746, Regularization: 0.002072, Discriminator: 0.042788; Generator: 0.021863,\n",
      "D(x): 0.506, D(G(z)): 0.497\n",
      "2019-04-09 22:59:32,458 root         INFO     Train Epoch: 42 [5632/8000 (70%)]\tTotal Loss: 0.254139\n",
      "Reconstruction: 0.187405, Regularization: 0.002087, Discriminator: 0.042770; Generator: 0.021877,\n",
      "D(x): 0.506, D(G(z)): 0.497\n",
      "2019-04-09 22:59:32,559 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.286212\n",
      "Reconstruction: 0.219399, Regularization: 0.002358, Discriminator: 0.042550; Generator: 0.021905,\n",
      "D(x): 0.509, D(G(z)): 0.496\n",
      "2019-04-09 22:59:32,661 root         INFO     Train Epoch: 42 [6656/8000 (83%)]\tTotal Loss: 0.332376\n",
      "Reconstruction: 0.265811, Regularization: 0.001862, Discriminator: 0.042777; Generator: 0.021925,\n",
      "D(x): 0.505, D(G(z)): 0.496\n",
      "2019-04-09 22:59:32,761 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.357203\n",
      "Reconstruction: 0.289631, Regularization: 0.003462, Discriminator: 0.042162; Generator: 0.021948,\n",
      "D(x): 0.515, D(G(z)): 0.495\n",
      "2019-04-09 22:59:32,861 root         INFO     Train Epoch: 42 [7680/8000 (96%)]\tTotal Loss: 0.279631\n",
      "Reconstruction: 0.212817, Regularization: 0.001964, Discriminator: 0.042880; Generator: 0.021970,\n",
      "D(x): 0.503, D(G(z)): 0.495\n",
      "2019-04-09 22:59:32,935 root         INFO     ====> Epoch: 42 Average loss: 0.3155\n",
      "2019-04-09 22:59:32,962 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.341105\n",
      "Reconstruction: 0.273531, Regularization: 0.003362, Discriminator: 0.042232; Generator: 0.021980,\n",
      "D(x): 0.513, D(G(z)): 0.495\n",
      "2019-04-09 22:59:33,063 root         INFO     Train Epoch: 43 [512/8000 (6%)]\tTotal Loss: 0.316676\n",
      "Reconstruction: 0.250240, Regularization: 0.002060, Discriminator: 0.042363; Generator: 0.022013,\n",
      "D(x): 0.510, D(G(z)): 0.494\n",
      "2019-04-09 22:59:33,163 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.293981\n",
      "Reconstruction: 0.227321, Regularization: 0.002307, Discriminator: 0.042309; Generator: 0.022044,\n",
      "D(x): 0.511, D(G(z)): 0.494\n",
      "2019-04-09 22:59:33,263 root         INFO     Train Epoch: 43 [1536/8000 (19%)]\tTotal Loss: 0.273651\n",
      "Reconstruction: 0.206977, Regularization: 0.002089, Discriminator: 0.042520; Generator: 0.022065,\n",
      "D(x): 0.507, D(G(z)): 0.494\n",
      "2019-04-09 22:59:33,363 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.261226\n",
      "Reconstruction: 0.194814, Regularization: 0.001982, Discriminator: 0.042328; Generator: 0.022102,\n",
      "D(x): 0.510, D(G(z)): 0.493\n",
      "2019-04-09 22:59:33,462 root         INFO     Train Epoch: 43 [2560/8000 (32%)]\tTotal Loss: 0.254834\n",
      "Reconstruction: 0.188645, Regularization: 0.001945, Discriminator: 0.042111; Generator: 0.022134,\n",
      "D(x): 0.513, D(G(z)): 0.492\n",
      "2019-04-09 22:59:33,561 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.300783\n",
      "Reconstruction: 0.233819, Regularization: 0.003112, Discriminator: 0.041685; Generator: 0.022166,\n",
      "D(x): 0.519, D(G(z)): 0.492\n",
      "2019-04-09 22:59:33,660 root         INFO     Train Epoch: 43 [3584/8000 (45%)]\tTotal Loss: 0.310238\n",
      "Reconstruction: 0.243280, Regularization: 0.003120, Discriminator: 0.041610; Generator: 0.022227,\n",
      "D(x): 0.520, D(G(z)): 0.491\n",
      "2019-04-09 22:59:33,758 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.317138\n",
      "Reconstruction: 0.249509, Regularization: 0.003873, Discriminator: 0.041521; Generator: 0.022235,\n",
      "D(x): 0.521, D(G(z)): 0.491\n",
      "2019-04-09 22:59:33,857 root         INFO     Train Epoch: 43 [4608/8000 (58%)]\tTotal Loss: 0.357166\n",
      "Reconstruction: 0.290579, Regularization: 0.002481, Discriminator: 0.041835; Generator: 0.022270,\n",
      "D(x): 0.516, D(G(z)): 0.490\n",
      "2019-04-09 22:59:33,956 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.244492\n",
      "Reconstruction: 0.177620, Regularization: 0.002379, Discriminator: 0.042199; Generator: 0.022295,\n",
      "D(x): 0.509, D(G(z)): 0.490\n",
      "2019-04-09 22:59:34,054 root         INFO     Train Epoch: 43 [5632/8000 (70%)]\tTotal Loss: 0.317882\n",
      "Reconstruction: 0.250703, Regularization: 0.002912, Discriminator: 0.041879; Generator: 0.022388,\n",
      "D(x): 0.513, D(G(z)): 0.488\n",
      "2019-04-09 22:59:34,153 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.281729\n",
      "Reconstruction: 0.215053, Regularization: 0.002691, Discriminator: 0.041605; Generator: 0.022380,\n",
      "D(x): 0.518, D(G(z)): 0.489\n",
      "2019-04-09 22:59:34,252 root         INFO     Train Epoch: 43 [6656/8000 (83%)]\tTotal Loss: 0.315607\n",
      "Reconstruction: 0.249548, Regularization: 0.002120, Discriminator: 0.041525; Generator: 0.022414,\n",
      "D(x): 0.519, D(G(z)): 0.488\n",
      "2019-04-09 22:59:34,351 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.331679\n",
      "Reconstruction: 0.265663, Regularization: 0.002803, Discriminator: 0.040771; Generator: 0.022441,\n",
      "D(x): 0.531, D(G(z)): 0.488\n",
      "2019-04-09 22:59:34,449 root         INFO     Train Epoch: 43 [7680/8000 (96%)]\tTotal Loss: 0.318987\n",
      "Reconstruction: 0.253042, Regularization: 0.002935, Discriminator: 0.040476; Generator: 0.022534,\n",
      "D(x): 0.534, D(G(z)): 0.486\n",
      "2019-04-09 22:59:34,523 root         INFO     ====> Epoch: 43 Average loss: 0.3124\n",
      "2019-04-09 22:59:34,549 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.285889\n",
      "Reconstruction: 0.218960, Regularization: 0.002977, Discriminator: 0.041417; Generator: 0.022535,\n",
      "D(x): 0.519, D(G(z)): 0.486\n",
      "2019-04-09 22:59:34,650 root         INFO     Train Epoch: 44 [512/8000 (6%)]\tTotal Loss: 0.303444\n",
      "Reconstruction: 0.237877, Regularization: 0.002071, Discriminator: 0.040919; Generator: 0.022575,\n",
      "D(x): 0.526, D(G(z)): 0.486\n",
      "2019-04-09 22:59:34,748 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.292941\n",
      "Reconstruction: 0.226119, Regularization: 0.002602, Discriminator: 0.041580; Generator: 0.022640,\n",
      "D(x): 0.516, D(G(z)): 0.485\n",
      "2019-04-09 22:59:34,847 root         INFO     Train Epoch: 44 [1536/8000 (19%)]\tTotal Loss: 0.394399\n",
      "Reconstruction: 0.328474, Regularization: 0.003214, Discriminator: 0.040040; Generator: 0.022671,\n",
      "D(x): 0.541, D(G(z)): 0.484\n",
      "2019-04-09 22:59:34,946 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.316622\n",
      "Reconstruction: 0.251194, Regularization: 0.002437, Discriminator: 0.040294; Generator: 0.022697,\n",
      "D(x): 0.536, D(G(z)): 0.484\n",
      "2019-04-09 22:59:35,043 root         INFO     Train Epoch: 44 [2560/8000 (32%)]\tTotal Loss: 0.438497\n",
      "Reconstruction: 0.372589, Regularization: 0.003249, Discriminator: 0.039924; Generator: 0.022735,\n",
      "D(x): 0.544, D(G(z)): 0.483\n",
      "2019-04-09 22:59:35,140 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.327396\n",
      "Reconstruction: 0.262349, Regularization: 0.002221, Discriminator: 0.040077; Generator: 0.022750,\n",
      "D(x): 0.539, D(G(z)): 0.483\n",
      "2019-04-09 22:59:35,237 root         INFO     Train Epoch: 44 [3584/8000 (45%)]\tTotal Loss: 0.254339\n",
      "Reconstruction: 0.188274, Regularization: 0.002102, Discriminator: 0.041173; Generator: 0.022789,\n",
      "D(x): 0.520, D(G(z)): 0.482\n",
      "2019-04-09 22:59:35,333 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.250484\n",
      "Reconstruction: 0.185026, Regularization: 0.002074, Discriminator: 0.040529; Generator: 0.022856,\n",
      "D(x): 0.529, D(G(z)): 0.481\n",
      "2019-04-09 22:59:35,430 root         INFO     Train Epoch: 44 [4608/8000 (58%)]\tTotal Loss: 0.344366\n",
      "Reconstruction: 0.279204, Regularization: 0.002563, Discriminator: 0.039681; Generator: 0.022918,\n",
      "D(x): 0.544, D(G(z)): 0.480\n",
      "2019-04-09 22:59:35,526 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.297270\n",
      "Reconstruction: 0.230054, Regularization: 0.002955, Discriminator: 0.041294; Generator: 0.022967,\n",
      "D(x): 0.519, D(G(z)): 0.480\n",
      "2019-04-09 22:59:35,623 root         INFO     Train Epoch: 44 [5632/8000 (70%)]\tTotal Loss: 0.279571\n",
      "Reconstruction: 0.214218, Regularization: 0.001508, Discriminator: 0.040837; Generator: 0.023008,\n",
      "D(x): 0.523, D(G(z)): 0.479\n",
      "2019-04-09 22:59:35,720 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.246754\n",
      "Reconstruction: 0.181082, Regularization: 0.001574, Discriminator: 0.041064; Generator: 0.023033,\n",
      "D(x): 0.518, D(G(z)): 0.479\n",
      "2019-04-09 22:59:35,816 root         INFO     Train Epoch: 44 [6656/8000 (83%)]\tTotal Loss: 0.315573\n",
      "Reconstruction: 0.249876, Regularization: 0.002483, Discriminator: 0.040123; Generator: 0.023092,\n",
      "D(x): 0.536, D(G(z)): 0.478\n",
      "2019-04-09 22:59:35,913 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.316249\n",
      "Reconstruction: 0.251290, Regularization: 0.002171, Discriminator: 0.039663; Generator: 0.023125,\n",
      "D(x): 0.543, D(G(z)): 0.477\n",
      "2019-04-09 22:59:36,009 root         INFO     Train Epoch: 44 [7680/8000 (96%)]\tTotal Loss: 0.244426\n",
      "Reconstruction: 0.179081, Regularization: 0.001818, Discriminator: 0.040385; Generator: 0.023142,\n",
      "D(x): 0.529, D(G(z)): 0.477\n",
      "2019-04-09 22:59:36,083 root         INFO     ====> Epoch: 44 Average loss: 0.3047\n",
      "2019-04-09 22:59:36,109 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.311361\n",
      "Reconstruction: 0.246874, Regularization: 0.002514, Discriminator: 0.038852; Generator: 0.023121,\n",
      "D(x): 0.556, D(G(z)): 0.477\n",
      "2019-04-09 22:59:36,210 root         INFO     Train Epoch: 45 [512/8000 (6%)]\tTotal Loss: 0.281151\n",
      "Reconstruction: 0.215167, Regularization: 0.001654, Discriminator: 0.041189; Generator: 0.023140,\n",
      "D(x): 0.519, D(G(z)): 0.477\n",
      "2019-04-09 22:59:36,310 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 0.301647\n",
      "Reconstruction: 0.236381, Regularization: 0.002304, Discriminator: 0.039729; Generator: 0.023233,\n",
      "D(x): 0.542, D(G(z)): 0.475\n",
      "2019-04-09 22:59:36,409 root         INFO     Train Epoch: 45 [1536/8000 (19%)]\tTotal Loss: 0.306690\n",
      "Reconstruction: 0.241401, Regularization: 0.001977, Discriminator: 0.040122; Generator: 0.023190,\n",
      "D(x): 0.537, D(G(z)): 0.476\n",
      "2019-04-09 22:59:36,508 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.312712\n",
      "Reconstruction: 0.248461, Regularization: 0.002323, Discriminator: 0.038672; Generator: 0.023256,\n",
      "D(x): 0.560, D(G(z)): 0.475\n",
      "2019-04-09 22:59:36,607 root         INFO     Train Epoch: 45 [2560/8000 (32%)]\tTotal Loss: 0.252994\n",
      "Reconstruction: 0.187588, Regularization: 0.002331, Discriminator: 0.039728; Generator: 0.023347,\n",
      "D(x): 0.540, D(G(z)): 0.474\n",
      "2019-04-09 22:59:36,706 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.287032\n",
      "Reconstruction: 0.222351, Regularization: 0.001519, Discriminator: 0.039706; Generator: 0.023456,\n",
      "D(x): 0.540, D(G(z)): 0.472\n",
      "2019-04-09 22:59:36,805 root         INFO     Train Epoch: 45 [3584/8000 (45%)]\tTotal Loss: 0.322302\n",
      "Reconstruction: 0.257915, Regularization: 0.001573, Discriminator: 0.039353; Generator: 0.023461,\n",
      "D(x): 0.547, D(G(z)): 0.472\n",
      "2019-04-09 22:59:36,905 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.289533\n",
      "Reconstruction: 0.225809, Regularization: 0.001803, Discriminator: 0.038398; Generator: 0.023522,\n",
      "D(x): 0.560, D(G(z)): 0.471\n",
      "2019-04-09 22:59:37,004 root         INFO     Train Epoch: 45 [4608/8000 (58%)]\tTotal Loss: 0.288358\n",
      "Reconstruction: 0.223201, Regularization: 0.001737, Discriminator: 0.039865; Generator: 0.023555,\n",
      "D(x): 0.540, D(G(z)): 0.471\n",
      "2019-04-09 22:59:37,103 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.301544\n",
      "Reconstruction: 0.236229, Regularization: 0.001712, Discriminator: 0.040022; Generator: 0.023580,\n",
      "D(x): 0.537, D(G(z)): 0.470\n",
      "2019-04-09 22:59:37,202 root         INFO     Train Epoch: 45 [5632/8000 (70%)]\tTotal Loss: 0.326949\n",
      "Reconstruction: 0.264266, Regularization: 0.001649, Discriminator: 0.037250; Generator: 0.023784,\n",
      "D(x): 0.578, D(G(z)): 0.467\n",
      "2019-04-09 22:59:37,302 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.232590\n",
      "Reconstruction: 0.167298, Regularization: 0.001287, Discriminator: 0.040295; Generator: 0.023710,\n",
      "D(x): 0.526, D(G(z)): 0.468\n",
      "2019-04-09 22:59:37,401 root         INFO     Train Epoch: 45 [6656/8000 (83%)]\tTotal Loss: 0.323733\n",
      "Reconstruction: 0.260659, Regularization: 0.002463, Discriminator: 0.036871; Generator: 0.023740,\n",
      "D(x): 0.587, D(G(z)): 0.468\n",
      "2019-04-09 22:59:37,500 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.262793\n",
      "Reconstruction: 0.198153, Regularization: 0.001782, Discriminator: 0.039085; Generator: 0.023772,\n",
      "D(x): 0.549, D(G(z)): 0.467\n",
      "2019-04-09 22:59:37,598 root         INFO     Train Epoch: 45 [7680/8000 (96%)]\tTotal Loss: 0.358515\n",
      "Reconstruction: 0.294339, Regularization: 0.001558, Discriminator: 0.038847; Generator: 0.023770,\n",
      "D(x): 0.559, D(G(z)): 0.467\n",
      "2019-04-09 22:59:37,672 root         INFO     ====> Epoch: 45 Average loss: 0.2959\n",
      "2019-04-09 22:59:37,700 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.285971\n",
      "Reconstruction: 0.221575, Regularization: 0.001614, Discriminator: 0.038978; Generator: 0.023803,\n",
      "D(x): 0.552, D(G(z)): 0.467\n",
      "2019-04-09 22:59:37,798 root         INFO     Train Epoch: 46 [512/8000 (6%)]\tTotal Loss: 0.332071\n",
      "Reconstruction: 0.267956, Regularization: 0.002171, Discriminator: 0.038051; Generator: 0.023893,\n",
      "D(x): 0.569, D(G(z)): 0.466\n",
      "2019-04-09 22:59:37,896 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.236882\n",
      "Reconstruction: 0.171684, Regularization: 0.001194, Discriminator: 0.040116; Generator: 0.023889,\n",
      "D(x): 0.530, D(G(z)): 0.466\n",
      "2019-04-09 22:59:37,993 root         INFO     Train Epoch: 46 [1536/8000 (19%)]\tTotal Loss: 0.310015\n",
      "Reconstruction: 0.245817, Regularization: 0.002150, Discriminator: 0.038083; Generator: 0.023965,\n",
      "D(x): 0.570, D(G(z)): 0.464\n",
      "2019-04-09 22:59:38,090 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.294515\n",
      "Reconstruction: 0.229471, Regularization: 0.002158, Discriminator: 0.038759; Generator: 0.024127,\n",
      "D(x): 0.561, D(G(z)): 0.462\n",
      "2019-04-09 22:59:38,188 root         INFO     Train Epoch: 46 [2560/8000 (32%)]\tTotal Loss: 0.270764\n",
      "Reconstruction: 0.205587, Regularization: 0.001221, Discriminator: 0.039943; Generator: 0.024013,\n",
      "D(x): 0.539, D(G(z)): 0.464\n",
      "2019-04-09 22:59:38,285 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.239604\n",
      "Reconstruction: 0.174847, Regularization: 0.001677, Discriminator: 0.038938; Generator: 0.024141,\n",
      "D(x): 0.549, D(G(z)): 0.462\n",
      "2019-04-09 22:59:38,382 root         INFO     Train Epoch: 46 [3584/8000 (45%)]\tTotal Loss: 0.276756\n",
      "Reconstruction: 0.209870, Regularization: 0.002159, Discriminator: 0.040615; Generator: 0.024113,\n",
      "D(x): 0.533, D(G(z)): 0.462\n",
      "2019-04-09 22:59:38,479 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.278652\n",
      "Reconstruction: 0.214155, Regularization: 0.002480, Discriminator: 0.037815; Generator: 0.024203,\n",
      "D(x): 0.571, D(G(z)): 0.461\n",
      "2019-04-09 22:59:38,576 root         INFO     Train Epoch: 46 [4608/8000 (58%)]\tTotal Loss: 0.293314\n",
      "Reconstruction: 0.229869, Regularization: 0.001248, Discriminator: 0.038007; Generator: 0.024191,\n",
      "D(x): 0.567, D(G(z)): 0.461\n",
      "2019-04-09 22:59:38,674 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.259586\n",
      "Reconstruction: 0.193775, Regularization: 0.001145, Discriminator: 0.040413; Generator: 0.024253,\n",
      "D(x): 0.534, D(G(z)): 0.460\n",
      "2019-04-09 22:59:38,771 root         INFO     Train Epoch: 46 [5632/8000 (70%)]\tTotal Loss: 0.329643\n",
      "Reconstruction: 0.265563, Regularization: 0.001612, Discriminator: 0.038213; Generator: 0.024256,\n",
      "D(x): 0.578, D(G(z)): 0.460\n",
      "2019-04-09 22:59:38,868 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.317598\n",
      "Reconstruction: 0.254734, Regularization: 0.001145, Discriminator: 0.037529; Generator: 0.024191,\n",
      "D(x): 0.576, D(G(z)): 0.461\n",
      "2019-04-09 22:59:38,966 root         INFO     Train Epoch: 46 [6656/8000 (83%)]\tTotal Loss: 0.371201\n",
      "Reconstruction: 0.304316, Regularization: 0.001536, Discriminator: 0.040997; Generator: 0.024351,\n",
      "D(x): 0.544, D(G(z)): 0.459\n",
      "2019-04-09 22:59:39,064 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.355096\n",
      "Reconstruction: 0.294698, Regularization: 0.001297, Discriminator: 0.034880; Generator: 0.024222,\n",
      "D(x): 0.627, D(G(z)): 0.461\n",
      "2019-04-09 22:59:39,161 root         INFO     Train Epoch: 46 [7680/8000 (96%)]\tTotal Loss: 0.259395\n",
      "Reconstruction: 0.197077, Regularization: 0.001049, Discriminator: 0.036890; Generator: 0.024379,\n",
      "D(x): 0.580, D(G(z)): 0.458\n",
      "2019-04-09 22:59:39,234 root         INFO     ====> Epoch: 46 Average loss: 0.2886\n",
      "2019-04-09 22:59:39,261 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.346744\n",
      "Reconstruction: 0.279750, Regularization: 0.000929, Discriminator: 0.041712; Generator: 0.024353,\n",
      "D(x): 0.535, D(G(z)): 0.459\n",
      "2019-04-09 22:59:39,361 root         INFO     Train Epoch: 47 [512/8000 (6%)]\tTotal Loss: 0.246845\n",
      "Reconstruction: 0.181512, Regularization: 0.001050, Discriminator: 0.039880; Generator: 0.024403,\n",
      "D(x): 0.535, D(G(z)): 0.458\n",
      "2019-04-09 22:59:39,460 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.265058\n",
      "Reconstruction: 0.201741, Regularization: 0.001511, Discriminator: 0.037463; Generator: 0.024342,\n",
      "D(x): 0.576, D(G(z)): 0.459\n",
      "2019-04-09 22:59:39,558 root         INFO     Train Epoch: 47 [1536/8000 (19%)]\tTotal Loss: 0.266712\n",
      "Reconstruction: 0.202460, Regularization: 0.001355, Discriminator: 0.038412; Generator: 0.024485,\n",
      "D(x): 0.560, D(G(z)): 0.457\n",
      "2019-04-09 22:59:39,657 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.266849\n",
      "Reconstruction: 0.203297, Regularization: 0.001173, Discriminator: 0.037910; Generator: 0.024469,\n",
      "D(x): 0.575, D(G(z)): 0.457\n",
      "2019-04-09 22:59:39,755 root         INFO     Train Epoch: 47 [2560/8000 (32%)]\tTotal Loss: 0.309944\n",
      "Reconstruction: 0.248146, Regularization: 0.001854, Discriminator: 0.035352; Generator: 0.024591,\n",
      "D(x): 0.615, D(G(z)): 0.455\n",
      "2019-04-09 22:59:39,853 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.278444\n",
      "Reconstruction: 0.216597, Regularization: 0.001370, Discriminator: 0.035951; Generator: 0.024525,\n",
      "D(x): 0.600, D(G(z)): 0.456\n",
      "2019-04-09 22:59:39,952 root         INFO     Train Epoch: 47 [3584/8000 (45%)]\tTotal Loss: 0.234401\n",
      "Reconstruction: 0.168548, Regularization: 0.001301, Discriminator: 0.039983; Generator: 0.024569,\n",
      "D(x): 0.533, D(G(z)): 0.456\n",
      "2019-04-09 22:59:40,050 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.304830\n",
      "Reconstruction: 0.240465, Regularization: 0.001370, Discriminator: 0.038242; Generator: 0.024753,\n",
      "D(x): 0.580, D(G(z)): 0.453\n",
      "2019-04-09 22:59:40,148 root         INFO     Train Epoch: 47 [4608/8000 (58%)]\tTotal Loss: 0.313399\n",
      "Reconstruction: 0.250761, Regularization: 0.000840, Discriminator: 0.036888; Generator: 0.024910,\n",
      "D(x): 0.591, D(G(z)): 0.451\n",
      "2019-04-09 22:59:40,246 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.211631\n",
      "Reconstruction: 0.145949, Regularization: 0.001066, Discriminator: 0.040061; Generator: 0.024555,\n",
      "D(x): 0.534, D(G(z)): 0.456\n",
      "2019-04-09 22:59:40,344 root         INFO     Train Epoch: 47 [5632/8000 (70%)]\tTotal Loss: 0.278761\n",
      "Reconstruction: 0.213848, Regularization: 0.001107, Discriminator: 0.039068; Generator: 0.024738,\n",
      "D(x): 0.556, D(G(z)): 0.453\n",
      "2019-04-09 22:59:40,443 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.279274\n",
      "Reconstruction: 0.214678, Regularization: 0.000407, Discriminator: 0.039371; Generator: 0.024818,\n",
      "D(x): 0.548, D(G(z)): 0.452\n",
      "2019-04-09 22:59:40,541 root         INFO     Train Epoch: 47 [6656/8000 (83%)]\tTotal Loss: 0.270491\n",
      "Reconstruction: 0.205772, Regularization: 0.001169, Discriminator: 0.038842; Generator: 0.024708,\n",
      "D(x): 0.555, D(G(z)): 0.454\n",
      "2019-04-09 22:59:40,639 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.273382\n",
      "Reconstruction: 0.211552, Regularization: 0.000768, Discriminator: 0.036247; Generator: 0.024815,\n",
      "D(x): 0.600, D(G(z)): 0.452\n",
      "2019-04-09 22:59:40,737 root         INFO     Train Epoch: 47 [7680/8000 (96%)]\tTotal Loss: 0.276821\n",
      "Reconstruction: 0.210231, Regularization: 0.001243, Discriminator: 0.040724; Generator: 0.024623,\n",
      "D(x): 0.539, D(G(z)): 0.455\n",
      "2019-04-09 22:59:40,811 root         INFO     ====> Epoch: 47 Average loss: 0.2820\n",
      "2019-04-09 22:59:40,837 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.315236\n",
      "Reconstruction: 0.251806, Regularization: 0.001346, Discriminator: 0.037356; Generator: 0.024728,\n",
      "D(x): 0.592, D(G(z)): 0.453\n",
      "2019-04-09 22:59:40,937 root         INFO     Train Epoch: 48 [512/8000 (6%)]\tTotal Loss: 0.298277\n",
      "Reconstruction: 0.233082, Regularization: 0.001342, Discriminator: 0.039094; Generator: 0.024758,\n",
      "D(x): 0.570, D(G(z)): 0.453\n",
      "2019-04-09 22:59:41,037 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.265261\n",
      "Reconstruction: 0.199678, Regularization: 0.000886, Discriminator: 0.039937; Generator: 0.024760,\n",
      "D(x): 0.547, D(G(z)): 0.453\n",
      "2019-04-09 22:59:41,136 root         INFO     Train Epoch: 48 [1536/8000 (19%)]\tTotal Loss: 0.295229\n",
      "Reconstruction: 0.228972, Regularization: 0.001041, Discriminator: 0.040462; Generator: 0.024753,\n",
      "D(x): 0.560, D(G(z)): 0.453\n",
      "2019-04-09 22:59:41,236 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.305376\n",
      "Reconstruction: 0.238069, Regularization: 0.001295, Discriminator: 0.041362; Generator: 0.024649,\n",
      "D(x): 0.553, D(G(z)): 0.455\n",
      "2019-04-09 22:59:41,335 root         INFO     Train Epoch: 48 [2560/8000 (32%)]\tTotal Loss: 0.253525\n",
      "Reconstruction: 0.190250, Regularization: 0.000997, Discriminator: 0.037498; Generator: 0.024780,\n",
      "D(x): 0.585, D(G(z)): 0.453\n",
      "2019-04-09 22:59:41,435 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.264842\n",
      "Reconstruction: 0.200761, Regularization: 0.001389, Discriminator: 0.037762; Generator: 0.024929,\n",
      "D(x): 0.583, D(G(z)): 0.450\n",
      "2019-04-09 22:59:41,534 root         INFO     Train Epoch: 48 [3584/8000 (45%)]\tTotal Loss: 0.263333\n",
      "Reconstruction: 0.197609, Regularization: 0.001235, Discriminator: 0.039654; Generator: 0.024834,\n",
      "D(x): 0.547, D(G(z)): 0.452\n",
      "2019-04-09 22:59:41,634 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.302132\n",
      "Reconstruction: 0.239601, Regularization: 0.001465, Discriminator: 0.036238; Generator: 0.024829,\n",
      "D(x): 0.611, D(G(z)): 0.452\n",
      "2019-04-09 22:59:41,734 root         INFO     Train Epoch: 48 [4608/8000 (58%)]\tTotal Loss: 0.252146\n",
      "Reconstruction: 0.186873, Regularization: 0.000894, Discriminator: 0.039249; Generator: 0.025130,\n",
      "D(x): 0.546, D(G(z)): 0.448\n",
      "2019-04-09 22:59:41,834 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.254764\n",
      "Reconstruction: 0.190821, Regularization: 0.001013, Discriminator: 0.037918; Generator: 0.025012,\n",
      "D(x): 0.576, D(G(z)): 0.449\n",
      "2019-04-09 22:59:41,933 root         INFO     Train Epoch: 48 [5632/8000 (70%)]\tTotal Loss: 0.320191\n",
      "Reconstruction: 0.250969, Regularization: 0.001248, Discriminator: 0.042994; Generator: 0.024979,\n",
      "D(x): 0.521, D(G(z)): 0.450\n",
      "2019-04-09 22:59:42,033 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.280788\n",
      "Reconstruction: 0.217832, Regularization: 0.001145, Discriminator: 0.036769; Generator: 0.025042,\n",
      "D(x): 0.597, D(G(z)): 0.449\n",
      "2019-04-09 22:59:42,133 root         INFO     Train Epoch: 48 [6656/8000 (83%)]\tTotal Loss: 0.326914\n",
      "Reconstruction: 0.262369, Regularization: 0.000951, Discriminator: 0.038649; Generator: 0.024944,\n",
      "D(x): 0.585, D(G(z)): 0.450\n",
      "2019-04-09 22:59:42,232 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.256131\n",
      "Reconstruction: 0.187194, Regularization: 0.000814, Discriminator: 0.043241; Generator: 0.024882,\n",
      "D(x): 0.504, D(G(z)): 0.451\n",
      "2019-04-09 22:59:42,330 root         INFO     Train Epoch: 48 [7680/8000 (96%)]\tTotal Loss: 0.256473\n",
      "Reconstruction: 0.193250, Regularization: 0.001009, Discriminator: 0.037408; Generator: 0.024806,\n",
      "D(x): 0.585, D(G(z)): 0.452\n",
      "2019-04-09 22:59:42,403 root         INFO     ====> Epoch: 48 Average loss: 0.2759\n",
      "2019-04-09 22:59:42,430 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.327407\n",
      "Reconstruction: 0.262166, Regularization: 0.001425, Discriminator: 0.038856; Generator: 0.024960,\n",
      "D(x): 0.592, D(G(z)): 0.450\n",
      "2019-04-09 22:59:42,530 root         INFO     Train Epoch: 49 [512/8000 (6%)]\tTotal Loss: 0.291243\n",
      "Reconstruction: 0.226956, Regularization: 0.001425, Discriminator: 0.037508; Generator: 0.025354,\n",
      "D(x): 0.582, D(G(z)): 0.444\n",
      "2019-04-09 22:59:42,630 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.251549\n",
      "Reconstruction: 0.187676, Regularization: 0.001355, Discriminator: 0.037429; Generator: 0.025087,\n",
      "D(x): 0.579, D(G(z)): 0.448\n",
      "2019-04-09 22:59:42,730 root         INFO     Train Epoch: 49 [1536/8000 (19%)]\tTotal Loss: 0.337907\n",
      "Reconstruction: 0.273945, Regularization: 0.001271, Discriminator: 0.037556; Generator: 0.025134,\n",
      "D(x): 0.596, D(G(z)): 0.447\n",
      "2019-04-09 22:59:42,830 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.293500\n",
      "Reconstruction: 0.228038, Regularization: 0.001329, Discriminator: 0.039046; Generator: 0.025087,\n",
      "D(x): 0.562, D(G(z)): 0.448\n",
      "2019-04-09 22:59:42,930 root         INFO     Train Epoch: 49 [2560/8000 (32%)]\tTotal Loss: 0.343409\n",
      "Reconstruction: 0.276996, Regularization: 0.001030, Discriminator: 0.040344; Generator: 0.025039,\n",
      "D(x): 0.575, D(G(z)): 0.449\n",
      "2019-04-09 22:59:43,029 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.284595\n",
      "Reconstruction: 0.217885, Regularization: 0.000993, Discriminator: 0.040928; Generator: 0.024788,\n",
      "D(x): 0.547, D(G(z)): 0.453\n",
      "2019-04-09 22:59:43,129 root         INFO     Train Epoch: 49 [3584/8000 (45%)]\tTotal Loss: 0.295770\n",
      "Reconstruction: 0.231285, Regularization: 0.001201, Discriminator: 0.038311; Generator: 0.024973,\n",
      "D(x): 0.579, D(G(z)): 0.450\n",
      "2019-04-09 22:59:43,228 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.262348\n",
      "Reconstruction: 0.199278, Regularization: 0.001411, Discriminator: 0.036627; Generator: 0.025032,\n",
      "D(x): 0.592, D(G(z)): 0.449\n",
      "2019-04-09 22:59:43,328 root         INFO     Train Epoch: 49 [4608/8000 (58%)]\tTotal Loss: 0.256474\n",
      "Reconstruction: 0.195338, Regularization: 0.001033, Discriminator: 0.035049; Generator: 0.025053,\n",
      "D(x): 0.616, D(G(z)): 0.449\n",
      "2019-04-09 22:59:43,427 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.251040\n",
      "Reconstruction: 0.186042, Regularization: 0.001302, Discriminator: 0.038929; Generator: 0.024767,\n",
      "D(x): 0.555, D(G(z)): 0.453\n",
      "2019-04-09 22:59:43,527 root         INFO     Train Epoch: 49 [5632/8000 (70%)]\tTotal Loss: 0.264649\n",
      "Reconstruction: 0.198524, Regularization: 0.001068, Discriminator: 0.039962; Generator: 0.025095,\n",
      "D(x): 0.553, D(G(z)): 0.448\n",
      "2019-04-09 22:59:43,627 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.300703\n",
      "Reconstruction: 0.239603, Regularization: 0.001179, Discriminator: 0.035149; Generator: 0.024771,\n",
      "D(x): 0.627, D(G(z)): 0.453\n",
      "2019-04-09 22:59:43,727 root         INFO     Train Epoch: 49 [6656/8000 (83%)]\tTotal Loss: 0.304767\n",
      "Reconstruction: 0.241277, Regularization: 0.001330, Discriminator: 0.037052; Generator: 0.025108,\n",
      "D(x): 0.609, D(G(z)): 0.448\n",
      "2019-04-09 22:59:43,826 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.240494\n",
      "Reconstruction: 0.176275, Regularization: 0.000870, Discriminator: 0.038234; Generator: 0.025115,\n",
      "D(x): 0.566, D(G(z)): 0.448\n",
      "2019-04-09 22:59:43,926 root         INFO     Train Epoch: 49 [7680/8000 (96%)]\tTotal Loss: 0.295402\n",
      "Reconstruction: 0.227327, Regularization: 0.001282, Discriminator: 0.041594; Generator: 0.025200,\n",
      "D(x): 0.538, D(G(z)): 0.447\n",
      "2019-04-09 22:59:44,000 root         INFO     ====> Epoch: 49 Average loss: 0.2712\n",
      "2019-04-09 22:59:44,026 root         INFO     Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 0.301513\n",
      "Reconstruction: 0.240787, Regularization: 0.000893, Discriminator: 0.034846; Generator: 0.024986,\n",
      "D(x): 0.635, D(G(z)): 0.450\n",
      "2019-04-09 22:59:44,127 root         INFO     Train Epoch: 50 [512/8000 (6%)]\tTotal Loss: 0.265466\n",
      "Reconstruction: 0.193830, Regularization: 0.000825, Discriminator: 0.045867; Generator: 0.024944,\n",
      "D(x): 0.481, D(G(z)): 0.450\n",
      "2019-04-09 22:59:44,224 root         INFO     Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 0.252891\n",
      "Reconstruction: 0.188765, Regularization: 0.001349, Discriminator: 0.038085; Generator: 0.024693,\n",
      "D(x): 0.585, D(G(z)): 0.454\n",
      "2019-04-09 22:59:44,321 root         INFO     Train Epoch: 50 [1536/8000 (19%)]\tTotal Loss: 0.231668\n",
      "Reconstruction: 0.166698, Regularization: 0.000718, Discriminator: 0.039345; Generator: 0.024907,\n",
      "D(x): 0.547, D(G(z)): 0.451\n",
      "2019-04-09 22:59:44,418 root         INFO     Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 0.257734\n",
      "Reconstruction: 0.193621, Regularization: 0.001061, Discriminator: 0.038252; Generator: 0.024800,\n",
      "D(x): 0.577, D(G(z)): 0.452\n",
      "2019-04-09 22:59:44,516 root         INFO     Train Epoch: 50 [2560/8000 (32%)]\tTotal Loss: 0.336495\n",
      "Reconstruction: 0.268716, Regularization: 0.001491, Discriminator: 0.041465; Generator: 0.024824,\n",
      "D(x): 0.558, D(G(z)): 0.452\n",
      "2019-04-09 22:59:44,612 root         INFO     Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 0.236365\n",
      "Reconstruction: 0.169794, Regularization: 0.000656, Discriminator: 0.040842; Generator: 0.025072,\n",
      "D(x): 0.529, D(G(z)): 0.448\n",
      "2019-04-09 22:59:44,710 root         INFO     Train Epoch: 50 [3584/8000 (45%)]\tTotal Loss: 0.278168\n",
      "Reconstruction: 0.212034, Regularization: 0.001280, Discriminator: 0.039890; Generator: 0.024965,\n",
      "D(x): 0.565, D(G(z)): 0.450\n",
      "2019-04-09 22:59:44,807 root         INFO     Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 0.294421\n",
      "Reconstruction: 0.223044, Regularization: 0.001074, Discriminator: 0.045496; Generator: 0.024807,\n",
      "D(x): 0.507, D(G(z)): 0.452\n",
      "2019-04-09 22:59:44,903 root         INFO     Train Epoch: 50 [4608/8000 (58%)]\tTotal Loss: 0.259131\n",
      "Reconstruction: 0.192411, Regularization: 0.000992, Discriminator: 0.040796; Generator: 0.024931,\n",
      "D(x): 0.535, D(G(z)): 0.450\n",
      "2019-04-09 22:59:45,001 root         INFO     Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 0.251665\n",
      "Reconstruction: 0.182677, Regularization: 0.000753, Discriminator: 0.043549; Generator: 0.024686,\n",
      "D(x): 0.499, D(G(z)): 0.454\n",
      "2019-04-09 22:59:45,099 root         INFO     Train Epoch: 50 [5632/8000 (70%)]\tTotal Loss: 0.227272\n",
      "Reconstruction: 0.157645, Regularization: 0.001108, Discriminator: 0.043649; Generator: 0.024869,\n",
      "D(x): 0.499, D(G(z)): 0.451\n",
      "2019-04-09 22:59:45,197 root         INFO     Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 0.299941\n",
      "Reconstruction: 0.236671, Regularization: 0.001309, Discriminator: 0.037086; Generator: 0.024875,\n",
      "D(x): 0.603, D(G(z)): 0.451\n",
      "2019-04-09 22:59:45,296 root         INFO     Train Epoch: 50 [6656/8000 (83%)]\tTotal Loss: 0.281489\n",
      "Reconstruction: 0.211698, Regularization: 0.001291, Discriminator: 0.043634; Generator: 0.024866,\n",
      "D(x): 0.517, D(G(z)): 0.451\n",
      "2019-04-09 22:59:45,394 root         INFO     Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 0.261909\n",
      "Reconstruction: 0.192060, Regularization: 0.000684, Discriminator: 0.044296; Generator: 0.024869,\n",
      "D(x): 0.496, D(G(z)): 0.451\n",
      "2019-04-09 22:59:45,492 root         INFO     Train Epoch: 50 [7680/8000 (96%)]\tTotal Loss: 0.210564\n",
      "Reconstruction: 0.145232, Regularization: 0.000762, Discriminator: 0.039784; Generator: 0.024786,\n",
      "D(x): 0.545, D(G(z)): 0.453\n",
      "2019-04-09 22:59:45,566 root         INFO     ====> Epoch: 50 Average loss: 0.2669\n",
      "2019-04-09 22:59:45,592 root         INFO     Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 0.265273\n",
      "Reconstruction: 0.196815, Regularization: 0.001000, Discriminator: 0.042618; Generator: 0.024840,\n",
      "D(x): 0.516, D(G(z)): 0.452\n",
      "2019-04-09 22:59:45,692 root         INFO     Train Epoch: 51 [512/8000 (6%)]\tTotal Loss: 0.275879\n",
      "Reconstruction: 0.213077, Regularization: 0.001433, Discriminator: 0.036830; Generator: 0.024540,\n",
      "D(x): 0.601, D(G(z)): 0.456\n",
      "2019-04-09 22:59:45,791 root         INFO     Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 0.282033\n",
      "Reconstruction: 0.216895, Regularization: 0.001272, Discriminator: 0.038729; Generator: 0.025137,\n",
      "D(x): 0.576, D(G(z)): 0.447\n",
      "2019-04-09 22:59:45,889 root         INFO     Train Epoch: 51 [1536/8000 (19%)]\tTotal Loss: 0.265400\n",
      "Reconstruction: 0.204412, Regularization: 0.001135, Discriminator: 0.035185; Generator: 0.024668,\n",
      "D(x): 0.624, D(G(z)): 0.454\n",
      "2019-04-09 22:59:45,988 root         INFO     Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 0.288777\n",
      "Reconstruction: 0.222491, Regularization: 0.001162, Discriminator: 0.040547; Generator: 0.024576,\n",
      "D(x): 0.552, D(G(z)): 0.456\n",
      "2019-04-09 22:59:46,091 root         INFO     Train Epoch: 51 [2560/8000 (32%)]\tTotal Loss: 0.246285\n",
      "Reconstruction: 0.179329, Regularization: 0.000986, Discriminator: 0.040969; Generator: 0.025001,\n",
      "D(x): 0.530, D(G(z)): 0.449\n",
      "2019-04-09 22:59:46,193 root         INFO     Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 0.266253\n",
      "Reconstruction: 0.198408, Regularization: 0.001046, Discriminator: 0.042035; Generator: 0.024765,\n",
      "D(x): 0.526, D(G(z)): 0.453\n",
      "2019-04-09 22:59:46,296 root         INFO     Train Epoch: 51 [3584/8000 (45%)]\tTotal Loss: 0.320619\n",
      "Reconstruction: 0.252072, Regularization: 0.001181, Discriminator: 0.042781; Generator: 0.024585,\n",
      "D(x): 0.543, D(G(z)): 0.455\n",
      "2019-04-09 22:59:46,399 root         INFO     Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 0.268970\n",
      "Reconstruction: 0.199067, Regularization: 0.001360, Discriminator: 0.044041; Generator: 0.024502,\n",
      "D(x): 0.513, D(G(z)): 0.457\n",
      "2019-04-09 22:59:46,502 root         INFO     Train Epoch: 51 [4608/8000 (58%)]\tTotal Loss: 0.207110\n",
      "Reconstruction: 0.139824, Regularization: 0.001035, Discriminator: 0.041508; Generator: 0.024743,\n",
      "D(x): 0.514, D(G(z)): 0.453\n",
      "2019-04-09 22:59:46,604 root         INFO     Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 0.307624\n",
      "Reconstruction: 0.237944, Regularization: 0.001638, Discriminator: 0.043540; Generator: 0.024501,\n",
      "D(x): 0.525, D(G(z)): 0.457\n",
      "2019-04-09 22:59:46,707 root         INFO     Train Epoch: 51 [5632/8000 (70%)]\tTotal Loss: 0.255930\n",
      "Reconstruction: 0.191159, Regularization: 0.001357, Discriminator: 0.038539; Generator: 0.024875,\n",
      "D(x): 0.572, D(G(z)): 0.451\n",
      "2019-04-09 22:59:46,810 root         INFO     Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 0.280010\n",
      "Reconstruction: 0.212686, Regularization: 0.001294, Discriminator: 0.041322; Generator: 0.024708,\n",
      "D(x): 0.547, D(G(z)): 0.454\n",
      "2019-04-09 22:59:46,913 root         INFO     Train Epoch: 51 [6656/8000 (83%)]\tTotal Loss: 0.259207\n",
      "Reconstruction: 0.193730, Regularization: 0.001446, Discriminator: 0.039424; Generator: 0.024606,\n",
      "D(x): 0.559, D(G(z)): 0.455\n",
      "2019-04-09 22:59:47,013 root         INFO     Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 0.316221\n",
      "Reconstruction: 0.252292, Regularization: 0.001786, Discriminator: 0.037434; Generator: 0.024709,\n",
      "D(x): 0.604, D(G(z)): 0.454\n",
      "2019-04-09 22:59:47,112 root         INFO     Train Epoch: 51 [7680/8000 (96%)]\tTotal Loss: 0.225435\n",
      "Reconstruction: 0.160273, Regularization: 0.000900, Discriminator: 0.039725; Generator: 0.024536,\n",
      "D(x): 0.546, D(G(z)): 0.456\n",
      "2019-04-09 22:59:47,186 root         INFO     ====> Epoch: 51 Average loss: 0.2636\n",
      "2019-04-09 22:59:47,213 root         INFO     Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 0.262497\n",
      "Reconstruction: 0.194364, Regularization: 0.000899, Discriminator: 0.042792; Generator: 0.024443,\n",
      "D(x): 0.514, D(G(z)): 0.458\n",
      "2019-04-09 22:59:47,314 root         INFO     Train Epoch: 52 [512/8000 (6%)]\tTotal Loss: 0.302986\n",
      "Reconstruction: 0.238889, Regularization: 0.001853, Discriminator: 0.037876; Generator: 0.024369,\n",
      "D(x): 0.586, D(G(z)): 0.459\n",
      "2019-04-09 22:59:47,413 root         INFO     Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 0.248992\n",
      "Reconstruction: 0.179873, Regularization: 0.001131, Discriminator: 0.043425; Generator: 0.024563,\n",
      "D(x): 0.506, D(G(z)): 0.456\n",
      "2019-04-09 22:59:47,513 root         INFO     Train Epoch: 52 [1536/8000 (19%)]\tTotal Loss: 0.269293\n",
      "Reconstruction: 0.201741, Regularization: 0.001099, Discriminator: 0.041984; Generator: 0.024470,\n",
      "D(x): 0.530, D(G(z)): 0.457\n",
      "2019-04-09 22:59:47,613 root         INFO     Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 0.296072\n",
      "Reconstruction: 0.232599, Regularization: 0.001284, Discriminator: 0.037790; Generator: 0.024398,\n",
      "D(x): 0.592, D(G(z)): 0.458\n",
      "2019-04-09 22:59:47,712 root         INFO     Train Epoch: 52 [2560/8000 (32%)]\tTotal Loss: 0.236103\n",
      "Reconstruction: 0.165438, Regularization: 0.000970, Discriminator: 0.045223; Generator: 0.024472,\n",
      "D(x): 0.476, D(G(z)): 0.457\n",
      "2019-04-09 22:59:47,812 root         INFO     Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 0.222750\n",
      "Reconstruction: 0.153359, Regularization: 0.000919, Discriminator: 0.044044; Generator: 0.024429,\n",
      "D(x): 0.480, D(G(z)): 0.458\n",
      "2019-04-09 22:59:47,912 root         INFO     Train Epoch: 52 [3584/8000 (45%)]\tTotal Loss: 0.253295\n",
      "Reconstruction: 0.180949, Regularization: 0.001071, Discriminator: 0.046799; Generator: 0.024477,\n",
      "D(x): 0.453, D(G(z)): 0.457\n",
      "2019-04-09 22:59:48,011 root         INFO     Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 0.287513\n",
      "Reconstruction: 0.223702, Regularization: 0.001633, Discriminator: 0.037812; Generator: 0.024367,\n",
      "D(x): 0.585, D(G(z)): 0.459\n",
      "2019-04-09 22:59:48,111 root         INFO     Train Epoch: 52 [4608/8000 (58%)]\tTotal Loss: 0.245844\n",
      "Reconstruction: 0.178363, Regularization: 0.001470, Discriminator: 0.041765; Generator: 0.024246,\n",
      "D(x): 0.521, D(G(z)): 0.460\n",
      "2019-04-09 22:59:48,210 root         INFO     Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 0.265284\n",
      "Reconstruction: 0.197855, Regularization: 0.001371, Discriminator: 0.041572; Generator: 0.024486,\n",
      "D(x): 0.545, D(G(z)): 0.457\n",
      "2019-04-09 22:59:48,309 root         INFO     Train Epoch: 52 [5632/8000 (70%)]\tTotal Loss: 0.246742\n",
      "Reconstruction: 0.179624, Regularization: 0.001274, Discriminator: 0.041792; Generator: 0.024053,\n",
      "D(x): 0.534, D(G(z)): 0.463\n",
      "2019-04-09 22:59:48,408 root         INFO     Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 0.291728\n",
      "Reconstruction: 0.224847, Regularization: 0.001380, Discriminator: 0.041246; Generator: 0.024256,\n",
      "D(x): 0.545, D(G(z)): 0.460\n",
      "2019-04-09 22:59:48,507 root         INFO     Train Epoch: 52 [6656/8000 (83%)]\tTotal Loss: 0.269303\n",
      "Reconstruction: 0.201958, Regularization: 0.001539, Discriminator: 0.041517; Generator: 0.024289,\n",
      "D(x): 0.541, D(G(z)): 0.460\n",
      "2019-04-09 22:59:48,605 root         INFO     Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 0.236019\n",
      "Reconstruction: 0.168821, Regularization: 0.000830, Discriminator: 0.042075; Generator: 0.024293,\n",
      "D(x): 0.515, D(G(z)): 0.460\n",
      "2019-04-09 22:59:48,703 root         INFO     Train Epoch: 52 [7680/8000 (96%)]\tTotal Loss: 0.241698\n",
      "Reconstruction: 0.176251, Regularization: 0.001361, Discriminator: 0.039809; Generator: 0.024278,\n",
      "D(x): 0.549, D(G(z)): 0.460\n",
      "2019-04-09 22:59:48,777 root         INFO     ====> Epoch: 52 Average loss: 0.2605\n",
      "2019-04-09 22:59:48,804 root         INFO     Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 0.254035\n",
      "Reconstruction: 0.187500, Regularization: 0.001648, Discriminator: 0.040552; Generator: 0.024335,\n",
      "D(x): 0.555, D(G(z)): 0.459\n",
      "2019-04-09 22:59:48,904 root         INFO     Train Epoch: 53 [512/8000 (6%)]\tTotal Loss: 0.248288\n",
      "Reconstruction: 0.183999, Regularization: 0.000928, Discriminator: 0.038953; Generator: 0.024408,\n",
      "D(x): 0.561, D(G(z)): 0.458\n",
      "2019-04-09 22:59:49,003 root         INFO     Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 0.232439\n",
      "Reconstruction: 0.164870, Regularization: 0.001337, Discriminator: 0.042069; Generator: 0.024163,\n",
      "D(x): 0.520, D(G(z)): 0.462\n",
      "2019-04-09 22:59:49,101 root         INFO     Train Epoch: 53 [1536/8000 (19%)]\tTotal Loss: 0.270623\n",
      "Reconstruction: 0.205141, Regularization: 0.001499, Discriminator: 0.039906; Generator: 0.024077,\n",
      "D(x): 0.554, D(G(z)): 0.463\n",
      "2019-04-09 22:59:49,200 root         INFO     Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 0.255225\n",
      "Reconstruction: 0.191284, Regularization: 0.001433, Discriminator: 0.038136; Generator: 0.024372,\n",
      "D(x): 0.573, D(G(z)): 0.459\n",
      "2019-04-09 22:59:49,300 root         INFO     Train Epoch: 53 [2560/8000 (32%)]\tTotal Loss: 0.322816\n",
      "Reconstruction: 0.254426, Regularization: 0.001854, Discriminator: 0.042481; Generator: 0.024055,\n",
      "D(x): 0.529, D(G(z)): 0.463\n",
      "2019-04-09 22:59:49,399 root         INFO     Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 0.273646\n",
      "Reconstruction: 0.206480, Regularization: 0.001340, Discriminator: 0.041876; Generator: 0.023951,\n",
      "D(x): 0.529, D(G(z)): 0.465\n",
      "2019-04-09 22:59:49,498 root         INFO     Train Epoch: 53 [3584/8000 (45%)]\tTotal Loss: 0.257585\n",
      "Reconstruction: 0.192207, Regularization: 0.001072, Discriminator: 0.040266; Generator: 0.024040,\n",
      "D(x): 0.554, D(G(z)): 0.464\n",
      "2019-04-09 22:59:49,598 root         INFO     Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 0.262881\n",
      "Reconstruction: 0.195775, Regularization: 0.001185, Discriminator: 0.041800; Generator: 0.024121,\n",
      "D(x): 0.525, D(G(z)): 0.462\n",
      "2019-04-09 22:59:49,698 root         INFO     Train Epoch: 53 [4608/8000 (58%)]\tTotal Loss: 0.259224\n",
      "Reconstruction: 0.190210, Regularization: 0.001566, Discriminator: 0.043412; Generator: 0.024036,\n",
      "D(x): 0.512, D(G(z)): 0.464\n",
      "2019-04-09 22:59:49,798 root         INFO     Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 0.249744\n",
      "Reconstruction: 0.178586, Regularization: 0.000906, Discriminator: 0.046226; Generator: 0.024026,\n",
      "D(x): 0.465, D(G(z)): 0.464\n",
      "2019-04-09 22:59:49,897 root         INFO     Train Epoch: 53 [5632/8000 (70%)]\tTotal Loss: 0.316726\n",
      "Reconstruction: 0.248042, Regularization: 0.001941, Discriminator: 0.043012; Generator: 0.023730,\n",
      "D(x): 0.532, D(G(z)): 0.468\n",
      "2019-04-09 22:59:49,997 root         INFO     Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 0.251205\n",
      "Reconstruction: 0.184003, Regularization: 0.001278, Discriminator: 0.042107; Generator: 0.023817,\n",
      "D(x): 0.521, D(G(z)): 0.467\n",
      "2019-04-09 22:59:50,096 root         INFO     Train Epoch: 53 [6656/8000 (83%)]\tTotal Loss: 0.243101\n",
      "Reconstruction: 0.174820, Regularization: 0.000999, Discriminator: 0.043376; Generator: 0.023906,\n",
      "D(x): 0.504, D(G(z)): 0.465\n",
      "2019-04-09 22:59:50,196 root         INFO     Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 0.253570\n",
      "Reconstruction: 0.183432, Regularization: 0.001440, Discriminator: 0.044984; Generator: 0.023714,\n",
      "D(x): 0.488, D(G(z)): 0.468\n",
      "2019-04-09 22:59:50,296 root         INFO     Train Epoch: 53 [7680/8000 (96%)]\tTotal Loss: 0.238720\n",
      "Reconstruction: 0.171394, Regularization: 0.001460, Discriminator: 0.041778; Generator: 0.024087,\n",
      "D(x): 0.523, D(G(z)): 0.463\n",
      "2019-04-09 22:59:50,370 root         INFO     ====> Epoch: 53 Average loss: 0.2576\n",
      "2019-04-09 22:59:50,397 root         INFO     Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 0.299926\n",
      "Reconstruction: 0.233285, Regularization: 0.001548, Discriminator: 0.041108; Generator: 0.023985,\n",
      "D(x): 0.549, D(G(z)): 0.464\n",
      "2019-04-09 22:59:50,499 root         INFO     Train Epoch: 54 [512/8000 (6%)]\tTotal Loss: 0.268215\n",
      "Reconstruction: 0.198848, Regularization: 0.001547, Discriminator: 0.043800; Generator: 0.024020,\n",
      "D(x): 0.498, D(G(z)): 0.464\n",
      "2019-04-09 22:59:50,599 root         INFO     Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 0.317752\n",
      "Reconstruction: 0.251075, Regularization: 0.001859, Discriminator: 0.040974; Generator: 0.023843,\n",
      "D(x): 0.545, D(G(z)): 0.466\n",
      "2019-04-09 22:59:50,700 root         INFO     Train Epoch: 54 [1536/8000 (19%)]\tTotal Loss: 0.289923\n",
      "Reconstruction: 0.222165, Regularization: 0.001491, Discriminator: 0.042455; Generator: 0.023812,\n",
      "D(x): 0.529, D(G(z)): 0.467\n",
      "2019-04-09 22:59:50,800 root         INFO     Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 0.265002\n",
      "Reconstruction: 0.196846, Regularization: 0.001571, Discriminator: 0.042867; Generator: 0.023718,\n",
      "D(x): 0.521, D(G(z)): 0.468\n",
      "2019-04-09 22:59:50,900 root         INFO     Train Epoch: 54 [2560/8000 (32%)]\tTotal Loss: 0.224425\n",
      "Reconstruction: 0.155101, Regularization: 0.001295, Discriminator: 0.044484; Generator: 0.023544,\n",
      "D(x): 0.490, D(G(z)): 0.471\n",
      "2019-04-09 22:59:51,001 root         INFO     Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 0.218295\n",
      "Reconstruction: 0.150121, Regularization: 0.001165, Discriminator: 0.043256; Generator: 0.023753,\n",
      "D(x): 0.499, D(G(z)): 0.468\n",
      "2019-04-09 22:59:51,101 root         INFO     Train Epoch: 54 [3584/8000 (45%)]\tTotal Loss: 0.242664\n",
      "Reconstruction: 0.177270, Regularization: 0.001002, Discriminator: 0.040494; Generator: 0.023898,\n",
      "D(x): 0.537, D(G(z)): 0.466\n",
      "2019-04-09 22:59:51,202 root         INFO     Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 0.252193\n",
      "Reconstruction: 0.184651, Regularization: 0.001410, Discriminator: 0.042292; Generator: 0.023839,\n",
      "D(x): 0.518, D(G(z)): 0.466\n",
      "2019-04-09 22:59:51,302 root         INFO     Train Epoch: 54 [4608/8000 (58%)]\tTotal Loss: 0.323734\n",
      "Reconstruction: 0.254382, Regularization: 0.001904, Discriminator: 0.043251; Generator: 0.024198,\n",
      "D(x): 0.521, D(G(z)): 0.461\n",
      "2019-04-09 22:59:51,402 root         INFO     Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 0.276422\n",
      "Reconstruction: 0.210798, Regularization: 0.001594, Discriminator: 0.039949; Generator: 0.024081,\n",
      "D(x): 0.549, D(G(z)): 0.463\n",
      "2019-04-09 22:59:51,503 root         INFO     Train Epoch: 54 [5632/8000 (70%)]\tTotal Loss: 0.282208\n",
      "Reconstruction: 0.214636, Regularization: 0.001506, Discriminator: 0.042507; Generator: 0.023560,\n",
      "D(x): 0.521, D(G(z)): 0.471\n",
      "2019-04-09 22:59:51,603 root         INFO     Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 0.223187\n",
      "Reconstruction: 0.157873, Regularization: 0.001262, Discriminator: 0.040418; Generator: 0.023634,\n",
      "D(x): 0.541, D(G(z)): 0.469\n",
      "2019-04-09 22:59:51,703 root         INFO     Train Epoch: 54 [6656/8000 (83%)]\tTotal Loss: 0.197886\n",
      "Reconstruction: 0.129951, Regularization: 0.000906, Discriminator: 0.043399; Generator: 0.023631,\n",
      "D(x): 0.489, D(G(z)): 0.470\n",
      "2019-04-09 22:59:51,804 root         INFO     Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 0.230505\n",
      "Reconstruction: 0.165656, Regularization: 0.001177, Discriminator: 0.039894; Generator: 0.023778,\n",
      "D(x): 0.545, D(G(z)): 0.467\n",
      "2019-04-09 22:59:51,904 root         INFO     Train Epoch: 54 [7680/8000 (96%)]\tTotal Loss: 0.259289\n",
      "Reconstruction: 0.191395, Regularization: 0.001896, Discriminator: 0.042578; Generator: 0.023420,\n",
      "D(x): 0.523, D(G(z)): 0.473\n",
      "2019-04-09 22:59:51,979 root         INFO     ====> Epoch: 54 Average loss: 0.2551\n",
      "2019-04-09 22:59:52,006 root         INFO     Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 0.331984\n",
      "Reconstruction: 0.265282, Regularization: 0.002231, Discriminator: 0.040884; Generator: 0.023587,\n",
      "D(x): 0.552, D(G(z)): 0.470\n",
      "2019-04-09 22:59:52,107 root         INFO     Train Epoch: 55 [512/8000 (6%)]\tTotal Loss: 0.278975\n",
      "Reconstruction: 0.209918, Regularization: 0.001500, Discriminator: 0.044012; Generator: 0.023545,\n",
      "D(x): 0.495, D(G(z)): 0.471\n",
      "2019-04-09 22:59:52,208 root         INFO     Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 0.254275\n",
      "Reconstruction: 0.190534, Regularization: 0.001512, Discriminator: 0.038506; Generator: 0.023724,\n",
      "D(x): 0.569, D(G(z)): 0.468\n",
      "2019-04-09 22:59:52,309 root         INFO     Train Epoch: 55 [1536/8000 (19%)]\tTotal Loss: 0.233394\n",
      "Reconstruction: 0.165425, Regularization: 0.001305, Discriminator: 0.043171; Generator: 0.023493,\n",
      "D(x): 0.503, D(G(z)): 0.472\n",
      "2019-04-09 22:59:52,410 root         INFO     Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 0.258030\n",
      "Reconstruction: 0.191852, Regularization: 0.001539, Discriminator: 0.041210; Generator: 0.023429,\n",
      "D(x): 0.538, D(G(z)): 0.473\n",
      "2019-04-09 22:59:52,511 root         INFO     Train Epoch: 55 [2560/8000 (32%)]\tTotal Loss: 0.239969\n",
      "Reconstruction: 0.172269, Regularization: 0.001555, Discriminator: 0.042541; Generator: 0.023603,\n",
      "D(x): 0.513, D(G(z)): 0.470\n",
      "2019-04-09 22:59:52,611 root         INFO     Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 0.269811\n",
      "Reconstruction: 0.201028, Regularization: 0.001383, Discriminator: 0.043976; Generator: 0.023423,\n",
      "D(x): 0.498, D(G(z)): 0.473\n",
      "2019-04-09 22:59:52,714 root         INFO     Train Epoch: 55 [3584/8000 (45%)]\tTotal Loss: 0.229319\n",
      "Reconstruction: 0.164034, Regularization: 0.001210, Discriminator: 0.040586; Generator: 0.023490,\n",
      "D(x): 0.538, D(G(z)): 0.472\n",
      "2019-04-09 22:59:52,815 root         INFO     Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 0.207256\n",
      "Reconstruction: 0.139230, Regularization: 0.001176, Discriminator: 0.043476; Generator: 0.023374,\n",
      "D(x): 0.498, D(G(z)): 0.473\n",
      "2019-04-09 22:59:52,917 root         INFO     Train Epoch: 55 [4608/8000 (58%)]\tTotal Loss: 0.238110\n",
      "Reconstruction: 0.169997, Regularization: 0.001221, Discriminator: 0.043593; Generator: 0.023299,\n",
      "D(x): 0.499, D(G(z)): 0.475\n",
      "2019-04-09 22:59:53,019 root         INFO     Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 0.274368\n",
      "Reconstruction: 0.204556, Regularization: 0.001979, Discriminator: 0.044436; Generator: 0.023397,\n",
      "D(x): 0.501, D(G(z)): 0.473\n",
      "2019-04-09 22:59:53,121 root         INFO     Train Epoch: 55 [5632/8000 (70%)]\tTotal Loss: 0.271458\n",
      "Reconstruction: 0.205753, Regularization: 0.002032, Discriminator: 0.040254; Generator: 0.023419,\n",
      "D(x): 0.554, D(G(z)): 0.473\n",
      "2019-04-09 22:59:53,221 root         INFO     Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 0.245550\n",
      "Reconstruction: 0.175744, Regularization: 0.001427, Discriminator: 0.045107; Generator: 0.023272,\n",
      "D(x): 0.474, D(G(z)): 0.475\n",
      "2019-04-09 22:59:53,319 root         INFO     Train Epoch: 55 [6656/8000 (83%)]\tTotal Loss: 0.277034\n",
      "Reconstruction: 0.210120, Regularization: 0.001535, Discriminator: 0.041885; Generator: 0.023495,\n",
      "D(x): 0.523, D(G(z)): 0.472\n",
      "2019-04-09 22:59:53,416 root         INFO     Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 0.285913\n",
      "Reconstruction: 0.221323, Regularization: 0.002420, Discriminator: 0.038850; Generator: 0.023320,\n",
      "D(x): 0.575, D(G(z)): 0.474\n",
      "2019-04-09 22:59:53,514 root         INFO     Train Epoch: 55 [7680/8000 (96%)]\tTotal Loss: 0.272262\n",
      "Reconstruction: 0.204862, Regularization: 0.001722, Discriminator: 0.042254; Generator: 0.023424,\n",
      "D(x): 0.523, D(G(z)): 0.473\n",
      "2019-04-09 22:59:53,588 root         INFO     ====> Epoch: 55 Average loss: 0.2530\n",
      "2019-04-09 22:59:53,614 root         INFO     Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 0.282116\n",
      "Reconstruction: 0.212826, Regularization: 0.001989, Discriminator: 0.043882; Generator: 0.023420,\n",
      "D(x): 0.505, D(G(z)): 0.473\n",
      "2019-04-09 22:59:53,713 root         INFO     Train Epoch: 56 [512/8000 (6%)]\tTotal Loss: 0.261822\n",
      "Reconstruction: 0.197656, Regularization: 0.001809, Discriminator: 0.039001; Generator: 0.023356,\n",
      "D(x): 0.565, D(G(z)): 0.474\n",
      "2019-04-09 22:59:53,813 root         INFO     Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 0.277309\n",
      "Reconstruction: 0.208334, Regularization: 0.001750, Discriminator: 0.043853; Generator: 0.023372,\n",
      "D(x): 0.498, D(G(z)): 0.473\n",
      "2019-04-09 22:59:53,913 root         INFO     Train Epoch: 56 [1536/8000 (19%)]\tTotal Loss: 0.261423\n",
      "Reconstruction: 0.192142, Regularization: 0.001658, Discriminator: 0.044437; Generator: 0.023186,\n",
      "D(x): 0.490, D(G(z)): 0.476\n",
      "2019-04-09 22:59:54,014 root         INFO     Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 0.237977\n",
      "Reconstruction: 0.167958, Regularization: 0.001250, Discriminator: 0.045535; Generator: 0.023235,\n",
      "D(x): 0.471, D(G(z)): 0.476\n",
      "2019-04-09 22:59:54,116 root         INFO     Train Epoch: 56 [2560/8000 (32%)]\tTotal Loss: 0.239890\n",
      "Reconstruction: 0.173077, Regularization: 0.001565, Discriminator: 0.042082; Generator: 0.023166,\n",
      "D(x): 0.522, D(G(z)): 0.477\n",
      "2019-04-09 22:59:54,217 root         INFO     Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 0.245291\n",
      "Reconstruction: 0.178001, Regularization: 0.001517, Discriminator: 0.042771; Generator: 0.023002,\n",
      "D(x): 0.517, D(G(z)): 0.479\n",
      "2019-04-09 22:59:54,318 root         INFO     Train Epoch: 56 [3584/8000 (45%)]\tTotal Loss: 0.255189\n",
      "Reconstruction: 0.189930, Regularization: 0.001773, Discriminator: 0.040352; Generator: 0.023133,\n",
      "D(x): 0.548, D(G(z)): 0.477\n",
      "2019-04-09 22:59:54,420 root         INFO     Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 0.217884\n",
      "Reconstruction: 0.153569, Regularization: 0.001160, Discriminator: 0.039894; Generator: 0.023260,\n",
      "D(x): 0.546, D(G(z)): 0.475\n",
      "2019-04-09 22:59:54,521 root         INFO     Train Epoch: 56 [4608/8000 (58%)]\tTotal Loss: 0.260051\n",
      "Reconstruction: 0.190383, Regularization: 0.001668, Discriminator: 0.045018; Generator: 0.022983,\n",
      "D(x): 0.488, D(G(z)): 0.479\n",
      "2019-04-09 22:59:54,622 root         INFO     Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 0.277890\n",
      "Reconstruction: 0.211601, Regularization: 0.002159, Discriminator: 0.041137; Generator: 0.022993,\n",
      "D(x): 0.545, D(G(z)): 0.479\n",
      "2019-04-09 22:59:54,724 root         INFO     Train Epoch: 56 [5632/8000 (70%)]\tTotal Loss: 0.272385\n",
      "Reconstruction: 0.206300, Regularization: 0.002200, Discriminator: 0.040629; Generator: 0.023256,\n",
      "D(x): 0.547, D(G(z)): 0.475\n",
      "2019-04-09 22:59:54,825 root         INFO     Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 0.237118\n",
      "Reconstruction: 0.170793, Regularization: 0.001648, Discriminator: 0.041576; Generator: 0.023101,\n",
      "D(x): 0.529, D(G(z)): 0.478\n",
      "2019-04-09 22:59:54,926 root         INFO     Train Epoch: 56 [6656/8000 (83%)]\tTotal Loss: 0.239176\n",
      "Reconstruction: 0.171277, Regularization: 0.001845, Discriminator: 0.042929; Generator: 0.023125,\n",
      "D(x): 0.509, D(G(z)): 0.477\n",
      "2019-04-09 22:59:55,027 root         INFO     Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 0.249072\n",
      "Reconstruction: 0.181593, Regularization: 0.001726, Discriminator: 0.042602; Generator: 0.023152,\n",
      "D(x): 0.514, D(G(z)): 0.477\n",
      "2019-04-09 22:59:55,123 root         INFO     Train Epoch: 56 [7680/8000 (96%)]\tTotal Loss: 0.238245\n",
      "Reconstruction: 0.173907, Regularization: 0.001621, Discriminator: 0.039737; Generator: 0.022980,\n",
      "D(x): 0.555, D(G(z)): 0.479\n",
      "2019-04-09 22:59:55,197 root         INFO     ====> Epoch: 56 Average loss: 0.2511\n",
      "2019-04-09 22:59:55,223 root         INFO     Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 0.265125\n",
      "Reconstruction: 0.200221, Regularization: 0.002245, Discriminator: 0.039711; Generator: 0.022948,\n",
      "D(x): 0.559, D(G(z)): 0.480\n",
      "2019-04-09 22:59:55,325 root         INFO     Train Epoch: 57 [512/8000 (6%)]\tTotal Loss: 0.243896\n",
      "Reconstruction: 0.174340, Regularization: 0.001618, Discriminator: 0.044823; Generator: 0.023115,\n",
      "D(x): 0.479, D(G(z)): 0.477\n",
      "2019-04-09 22:59:55,426 root         INFO     Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 0.205498\n",
      "Reconstruction: 0.139972, Regularization: 0.001101, Discriminator: 0.041332; Generator: 0.023093,\n",
      "D(x): 0.521, D(G(z)): 0.478\n",
      "2019-04-09 22:59:55,528 root         INFO     Train Epoch: 57 [1536/8000 (19%)]\tTotal Loss: 0.239904\n",
      "Reconstruction: 0.173995, Regularization: 0.001614, Discriminator: 0.041431; Generator: 0.022865,\n",
      "D(x): 0.529, D(G(z)): 0.481\n",
      "2019-04-09 22:59:55,629 root         INFO     Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 0.261745\n",
      "Reconstruction: 0.193000, Regularization: 0.002004, Discriminator: 0.043790; Generator: 0.022951,\n",
      "D(x): 0.499, D(G(z)): 0.480\n",
      "2019-04-09 22:59:55,730 root         INFO     Train Epoch: 57 [2560/8000 (32%)]\tTotal Loss: 0.216604\n",
      "Reconstruction: 0.149038, Regularization: 0.001415, Discriminator: 0.043198; Generator: 0.022952,\n",
      "D(x): 0.499, D(G(z)): 0.480\n",
      "2019-04-09 22:59:55,832 root         INFO     Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 0.233654\n",
      "Reconstruction: 0.166259, Regularization: 0.001492, Discriminator: 0.042896; Generator: 0.023007,\n",
      "D(x): 0.503, D(G(z)): 0.479\n",
      "2019-04-09 22:59:55,934 root         INFO     Train Epoch: 57 [3584/8000 (45%)]\tTotal Loss: 0.218456\n",
      "Reconstruction: 0.149580, Regularization: 0.001494, Discriminator: 0.044531; Generator: 0.022852,\n",
      "D(x): 0.482, D(G(z)): 0.481\n",
      "2019-04-09 22:59:56,035 root         INFO     Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 0.278661\n",
      "Reconstruction: 0.211174, Regularization: 0.002386, Discriminator: 0.042257; Generator: 0.022845,\n",
      "D(x): 0.526, D(G(z)): 0.481\n",
      "2019-04-09 22:59:56,137 root         INFO     Train Epoch: 57 [4608/8000 (58%)]\tTotal Loss: 0.257599\n",
      "Reconstruction: 0.189526, Regularization: 0.001965, Discriminator: 0.043342; Generator: 0.022766,\n",
      "D(x): 0.506, D(G(z)): 0.483\n",
      "2019-04-09 22:59:56,238 root         INFO     Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 0.285111\n",
      "Reconstruction: 0.216739, Regularization: 0.002282, Discriminator: 0.043407; Generator: 0.022683,\n",
      "D(x): 0.509, D(G(z)): 0.484\n",
      "2019-04-09 22:59:56,339 root         INFO     Train Epoch: 57 [5632/8000 (70%)]\tTotal Loss: 0.312115\n",
      "Reconstruction: 0.241967, Regularization: 0.002785, Discriminator: 0.044394; Generator: 0.022970,\n",
      "D(x): 0.495, D(G(z)): 0.480\n",
      "2019-04-09 22:59:56,440 root         INFO     Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 0.249355\n",
      "Reconstruction: 0.181341, Regularization: 0.001789, Discriminator: 0.043276; Generator: 0.022949,\n",
      "D(x): 0.499, D(G(z)): 0.480\n",
      "2019-04-09 22:59:56,541 root         INFO     Train Epoch: 57 [6656/8000 (83%)]\tTotal Loss: 0.248398\n",
      "Reconstruction: 0.182723, Regularization: 0.002038, Discriminator: 0.040707; Generator: 0.022930,\n",
      "D(x): 0.540, D(G(z)): 0.480\n",
      "2019-04-09 22:59:56,643 root         INFO     Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 0.244249\n",
      "Reconstruction: 0.175070, Regularization: 0.001885, Discriminator: 0.044303; Generator: 0.022991,\n",
      "D(x): 0.487, D(G(z)): 0.479\n",
      "2019-04-09 22:59:56,744 root         INFO     Train Epoch: 57 [7680/8000 (96%)]\tTotal Loss: 0.269887\n",
      "Reconstruction: 0.205915, Regularization: 0.002446, Discriminator: 0.038402; Generator: 0.023124,\n",
      "D(x): 0.573, D(G(z)): 0.477\n",
      "2019-04-09 22:59:56,818 root         INFO     ====> Epoch: 57 Average loss: 0.2495\n",
      "2019-04-09 22:59:56,846 root         INFO     Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 0.233543\n",
      "Reconstruction: 0.164965, Regularization: 0.001573, Discriminator: 0.044309; Generator: 0.022696,\n",
      "D(x): 0.487, D(G(z)): 0.484\n",
      "2019-04-09 22:59:56,948 root         INFO     Train Epoch: 58 [512/8000 (6%)]\tTotal Loss: 0.271667\n",
      "Reconstruction: 0.201317, Regularization: 0.002258, Discriminator: 0.045222; Generator: 0.022870,\n",
      "D(x): 0.478, D(G(z)): 0.481\n",
      "2019-04-09 22:59:57,050 root         INFO     Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 0.231103\n",
      "Reconstruction: 0.166163, Regularization: 0.001393, Discriminator: 0.040860; Generator: 0.022687,\n",
      "D(x): 0.536, D(G(z)): 0.484\n",
      "2019-04-09 22:59:57,151 root         INFO     Train Epoch: 58 [1536/8000 (19%)]\tTotal Loss: 0.231158\n",
      "Reconstruction: 0.164039, Regularization: 0.001791, Discriminator: 0.042712; Generator: 0.022616,\n",
      "D(x): 0.512, D(G(z)): 0.485\n",
      "2019-04-09 22:59:57,253 root         INFO     Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 0.256437\n",
      "Reconstruction: 0.189477, Regularization: 0.002229, Discriminator: 0.042072; Generator: 0.022659,\n",
      "D(x): 0.524, D(G(z)): 0.484\n",
      "2019-04-09 22:59:57,355 root         INFO     Train Epoch: 58 [2560/8000 (32%)]\tTotal Loss: 0.226897\n",
      "Reconstruction: 0.159214, Regularization: 0.001416, Discriminator: 0.043553; Generator: 0.022714,\n",
      "D(x): 0.494, D(G(z)): 0.483\n",
      "2019-04-09 22:59:57,456 root         INFO     Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 0.231828\n",
      "Reconstruction: 0.164701, Regularization: 0.001833, Discriminator: 0.042508; Generator: 0.022786,\n",
      "D(x): 0.511, D(G(z)): 0.482\n",
      "2019-04-09 22:59:57,557 root         INFO     Train Epoch: 58 [3584/8000 (45%)]\tTotal Loss: 0.218872\n",
      "Reconstruction: 0.152092, Regularization: 0.001225, Discriminator: 0.042689; Generator: 0.022867,\n",
      "D(x): 0.503, D(G(z)): 0.481\n",
      "2019-04-09 22:59:57,659 root         INFO     Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 0.233601\n",
      "Reconstruction: 0.166377, Regularization: 0.001869, Discriminator: 0.042760; Generator: 0.022596,\n",
      "D(x): 0.510, D(G(z)): 0.485\n",
      "2019-04-09 22:59:57,759 root         INFO     Train Epoch: 58 [4608/8000 (58%)]\tTotal Loss: 0.274667\n",
      "Reconstruction: 0.204103, Regularization: 0.002206, Discriminator: 0.045902; Generator: 0.022457,\n",
      "D(x): 0.468, D(G(z)): 0.487\n",
      "2019-04-09 22:59:57,860 root         INFO     Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 0.214124\n",
      "Reconstruction: 0.147847, Regularization: 0.001373, Discriminator: 0.042214; Generator: 0.022690,\n",
      "D(x): 0.514, D(G(z)): 0.484\n",
      "2019-04-09 22:59:57,960 root         INFO     Train Epoch: 58 [5632/8000 (70%)]\tTotal Loss: 0.239407\n",
      "Reconstruction: 0.170298, Regularization: 0.001944, Discriminator: 0.044476; Generator: 0.022689,\n",
      "D(x): 0.485, D(G(z)): 0.484\n",
      "2019-04-09 22:59:58,060 root         INFO     Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 0.239448\n",
      "Reconstruction: 0.170646, Regularization: 0.001824, Discriminator: 0.044167; Generator: 0.022810,\n",
      "D(x): 0.488, D(G(z)): 0.482\n",
      "2019-04-09 22:59:58,160 root         INFO     Train Epoch: 58 [6656/8000 (83%)]\tTotal Loss: 0.203364\n",
      "Reconstruction: 0.135949, Regularization: 0.001239, Discriminator: 0.043346; Generator: 0.022831,\n",
      "D(x): 0.493, D(G(z)): 0.482\n",
      "2019-04-09 22:59:58,259 root         INFO     Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 0.236125\n",
      "Reconstruction: 0.169229, Regularization: 0.001695, Discriminator: 0.042569; Generator: 0.022632,\n",
      "D(x): 0.511, D(G(z)): 0.485\n",
      "2019-04-09 22:59:58,359 root         INFO     Train Epoch: 58 [7680/8000 (96%)]\tTotal Loss: 0.240771\n",
      "Reconstruction: 0.173187, Regularization: 0.002074, Discriminator: 0.042728; Generator: 0.022783,\n",
      "D(x): 0.507, D(G(z)): 0.482\n",
      "2019-04-09 22:59:58,434 root         INFO     ====> Epoch: 58 Average loss: 0.2482\n",
      "2019-04-09 22:59:58,460 root         INFO     Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 0.252011\n",
      "Reconstruction: 0.182605, Regularization: 0.001995, Discriminator: 0.044715; Generator: 0.022696,\n",
      "D(x): 0.481, D(G(z)): 0.484\n",
      "2019-04-09 22:59:58,563 root         INFO     Train Epoch: 59 [512/8000 (6%)]\tTotal Loss: 0.220361\n",
      "Reconstruction: 0.153605, Regularization: 0.001536, Discriminator: 0.042661; Generator: 0.022559,\n",
      "D(x): 0.508, D(G(z)): 0.486\n",
      "2019-04-09 22:59:58,663 root         INFO     Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 0.243321\n",
      "Reconstruction: 0.172533, Regularization: 0.001857, Discriminator: 0.046597; Generator: 0.022334,\n",
      "D(x): 0.456, D(G(z)): 0.489\n",
      "2019-04-09 22:59:58,762 root         INFO     Train Epoch: 59 [1536/8000 (19%)]\tTotal Loss: 0.247009\n",
      "Reconstruction: 0.178623, Regularization: 0.002117, Discriminator: 0.043659; Generator: 0.022610,\n",
      "D(x): 0.498, D(G(z)): 0.485\n",
      "2019-04-09 22:59:58,861 root         INFO     Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 0.218982\n",
      "Reconstruction: 0.150163, Regularization: 0.001495, Discriminator: 0.044838; Generator: 0.022486,\n",
      "D(x): 0.475, D(G(z)): 0.487\n",
      "2019-04-09 22:59:58,960 root         INFO     Train Epoch: 59 [2560/8000 (32%)]\tTotal Loss: 0.256921\n",
      "Reconstruction: 0.189741, Regularization: 0.002523, Discriminator: 0.042062; Generator: 0.022595,\n",
      "D(x): 0.523, D(G(z)): 0.485\n",
      "2019-04-09 22:59:59,059 root         INFO     Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 0.224381\n",
      "Reconstruction: 0.157245, Regularization: 0.001706, Discriminator: 0.042707; Generator: 0.022723,\n",
      "D(x): 0.504, D(G(z)): 0.483\n",
      "2019-04-09 22:59:59,160 root         INFO     Train Epoch: 59 [3584/8000 (45%)]\tTotal Loss: 0.244316\n",
      "Reconstruction: 0.174808, Regularization: 0.002022, Discriminator: 0.044893; Generator: 0.022593,\n",
      "D(x): 0.477, D(G(z)): 0.485\n",
      "2019-04-09 22:59:59,261 root         INFO     Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 0.197517\n",
      "Reconstruction: 0.132226, Regularization: 0.001085, Discriminator: 0.041509; Generator: 0.022697,\n",
      "D(x): 0.519, D(G(z)): 0.484\n",
      "2019-04-09 22:59:59,363 root         INFO     Train Epoch: 59 [4608/8000 (58%)]\tTotal Loss: 0.255136\n",
      "Reconstruction: 0.187273, Regularization: 0.002316, Discriminator: 0.043105; Generator: 0.022443,\n",
      "D(x): 0.507, D(G(z)): 0.488\n",
      "2019-04-09 22:59:59,462 root         INFO     Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 0.270495\n",
      "Reconstruction: 0.202678, Regularization: 0.002258, Discriminator: 0.043081; Generator: 0.022478,\n",
      "D(x): 0.507, D(G(z)): 0.487\n",
      "2019-04-09 22:59:59,562 root         INFO     Train Epoch: 59 [5632/8000 (70%)]\tTotal Loss: 0.237540\n",
      "Reconstruction: 0.168649, Regularization: 0.001899, Discriminator: 0.044632; Generator: 0.022360,\n",
      "D(x): 0.482, D(G(z)): 0.489\n",
      "2019-04-09 22:59:59,661 root         INFO     Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 0.263297\n",
      "Reconstruction: 0.193116, Regularization: 0.002383, Discriminator: 0.045342; Generator: 0.022455,\n",
      "D(x): 0.474, D(G(z)): 0.488\n",
      "2019-04-09 22:59:59,760 root         INFO     Train Epoch: 59 [6656/8000 (83%)]\tTotal Loss: 0.263509\n",
      "Reconstruction: 0.197290, Regularization: 0.002236, Discriminator: 0.041570; Generator: 0.022413,\n",
      "D(x): 0.529, D(G(z)): 0.488\n",
      "2019-04-09 22:59:59,859 root         INFO     Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 0.230569\n",
      "Reconstruction: 0.163481, Regularization: 0.001628, Discriminator: 0.042928; Generator: 0.022532,\n",
      "D(x): 0.503, D(G(z)): 0.486\n",
      "2019-04-09 22:59:59,958 root         INFO     Train Epoch: 59 [7680/8000 (96%)]\tTotal Loss: 0.222593\n",
      "Reconstruction: 0.154242, Regularization: 0.001568, Discriminator: 0.044378; Generator: 0.022406,\n",
      "D(x): 0.482, D(G(z)): 0.488\n",
      "2019-04-09 23:00:00,033 root         INFO     ====> Epoch: 59 Average loss: 0.2472\n",
      "2019-04-09 23:00:00,059 root         INFO     Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 0.272668\n",
      "Reconstruction: 0.204148, Regularization: 0.002565, Discriminator: 0.043548; Generator: 0.022408,\n",
      "D(x): 0.501, D(G(z)): 0.488\n",
      "2019-04-09 23:00:00,161 root         INFO     Train Epoch: 60 [512/8000 (6%)]\tTotal Loss: 0.246478\n",
      "Reconstruction: 0.179362, Regularization: 0.002030, Discriminator: 0.042709; Generator: 0.022377,\n",
      "D(x): 0.510, D(G(z)): 0.489\n",
      "2019-04-09 23:00:00,262 root         INFO     Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 0.236914\n",
      "Reconstruction: 0.168679, Regularization: 0.002138, Discriminator: 0.043717; Generator: 0.022381,\n",
      "D(x): 0.494, D(G(z)): 0.489\n",
      "2019-04-09 23:00:00,363 root         INFO     Train Epoch: 60 [1536/8000 (19%)]\tTotal Loss: 0.259954\n",
      "Reconstruction: 0.189683, Regularization: 0.002336, Discriminator: 0.045430; Generator: 0.022505,\n",
      "D(x): 0.470, D(G(z)): 0.487\n",
      "2019-04-09 23:00:00,464 root         INFO     Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 0.286855\n",
      "Reconstruction: 0.217319, Regularization: 0.002697, Discriminator: 0.044444; Generator: 0.022395,\n",
      "D(x): 0.488, D(G(z)): 0.488\n",
      "2019-04-09 23:00:00,565 root         INFO     Train Epoch: 60 [2560/8000 (32%)]\tTotal Loss: 0.252437\n",
      "Reconstruction: 0.187480, Regularization: 0.002494, Discriminator: 0.039950; Generator: 0.022513,\n",
      "D(x): 0.551, D(G(z)): 0.487\n",
      "2019-04-09 23:00:00,666 root         INFO     Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 0.220710\n",
      "Reconstruction: 0.154738, Regularization: 0.001545, Discriminator: 0.042058; Generator: 0.022369,\n",
      "D(x): 0.517, D(G(z)): 0.489\n",
      "2019-04-09 23:00:00,768 root         INFO     Train Epoch: 60 [3584/8000 (45%)]\tTotal Loss: 0.288694\n",
      "Reconstruction: 0.221762, Regularization: 0.002643, Discriminator: 0.042086; Generator: 0.022202,\n",
      "D(x): 0.526, D(G(z)): 0.491\n",
      "2019-04-09 23:00:00,869 root         INFO     Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 0.277840\n",
      "Reconstruction: 0.210203, Regularization: 0.002875, Discriminator: 0.042330; Generator: 0.022433,\n",
      "D(x): 0.517, D(G(z)): 0.488\n",
      "2019-04-09 23:00:00,970 root         INFO     Train Epoch: 60 [4608/8000 (58%)]\tTotal Loss: 0.299461\n",
      "Reconstruction: 0.230613, Regularization: 0.003017, Discriminator: 0.043506; Generator: 0.022324,\n",
      "D(x): 0.501, D(G(z)): 0.490\n",
      "2019-04-09 23:00:01,071 root         INFO     Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 0.260788\n",
      "Reconstruction: 0.192537, Regularization: 0.002491, Discriminator: 0.043408; Generator: 0.022351,\n",
      "D(x): 0.501, D(G(z)): 0.489\n",
      "2019-04-09 23:00:01,172 root         INFO     Train Epoch: 60 [5632/8000 (70%)]\tTotal Loss: 0.245564\n",
      "Reconstruction: 0.178528, Regularization: 0.002119, Discriminator: 0.042426; Generator: 0.022490,\n",
      "D(x): 0.511, D(G(z)): 0.487\n",
      "2019-04-09 23:00:01,273 root         INFO     Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 0.272504\n",
      "Reconstruction: 0.203888, Regularization: 0.002420, Discriminator: 0.043958; Generator: 0.022237,\n",
      "D(x): 0.493, D(G(z)): 0.491\n",
      "2019-04-09 23:00:01,374 root         INFO     Train Epoch: 60 [6656/8000 (83%)]\tTotal Loss: 0.266909\n",
      "Reconstruction: 0.197412, Regularization: 0.002313, Discriminator: 0.044891; Generator: 0.022293,\n",
      "D(x): 0.477, D(G(z)): 0.490\n",
      "2019-04-09 23:00:01,475 root         INFO     Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 0.262997\n",
      "Reconstruction: 0.195807, Regularization: 0.002784, Discriminator: 0.042231; Generator: 0.022176,\n",
      "D(x): 0.521, D(G(z)): 0.492\n",
      "2019-04-09 23:00:01,575 root         INFO     Train Epoch: 60 [7680/8000 (96%)]\tTotal Loss: 0.256859\n",
      "Reconstruction: 0.188439, Regularization: 0.002315, Discriminator: 0.043781; Generator: 0.022324,\n",
      "D(x): 0.494, D(G(z)): 0.490\n",
      "2019-04-09 23:00:01,651 root         INFO     ====> Epoch: 60 Average loss: 0.2464\n",
      "2019-04-09 23:00:01,677 root         INFO     Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 0.256601\n",
      "Reconstruction: 0.189012, Regularization: 0.002460, Discriminator: 0.042813; Generator: 0.022317,\n",
      "D(x): 0.509, D(G(z)): 0.490\n",
      "2019-04-09 23:00:01,780 root         INFO     Train Epoch: 61 [512/8000 (6%)]\tTotal Loss: 0.234685\n",
      "Reconstruction: 0.166699, Regularization: 0.002313, Discriminator: 0.043434; Generator: 0.022239,\n",
      "D(x): 0.499, D(G(z)): 0.491\n",
      "2019-04-09 23:00:01,885 root         INFO     Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 0.210343\n",
      "Reconstruction: 0.143595, Regularization: 0.001369, Discriminator: 0.043095; Generator: 0.022284,\n",
      "D(x): 0.500, D(G(z)): 0.490\n",
      "2019-04-09 23:00:01,986 root         INFO     Train Epoch: 61 [1536/8000 (19%)]\tTotal Loss: 0.223600\n",
      "Reconstruction: 0.157765, Regularization: 0.001622, Discriminator: 0.041989; Generator: 0.022224,\n",
      "D(x): 0.519, D(G(z)): 0.491\n",
      "2019-04-09 23:00:02,085 root         INFO     Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 0.222589\n",
      "Reconstruction: 0.154402, Regularization: 0.001917, Discriminator: 0.044093; Generator: 0.022177,\n",
      "D(x): 0.489, D(G(z)): 0.492\n",
      "2019-04-09 23:00:02,185 root         INFO     Train Epoch: 61 [2560/8000 (32%)]\tTotal Loss: 0.253617\n",
      "Reconstruction: 0.185182, Regularization: 0.002069, Discriminator: 0.044265; Generator: 0.022101,\n",
      "D(x): 0.488, D(G(z)): 0.493\n",
      "2019-04-09 23:00:02,282 root         INFO     Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 0.263532\n",
      "Reconstruction: 0.193813, Regularization: 0.002298, Discriminator: 0.045161; Generator: 0.022259,\n",
      "D(x): 0.473, D(G(z)): 0.491\n",
      "2019-04-09 23:00:02,379 root         INFO     Train Epoch: 61 [3584/8000 (45%)]\tTotal Loss: 0.256157\n",
      "Reconstruction: 0.186942, Regularization: 0.002260, Discriminator: 0.044670; Generator: 0.022284,\n",
      "D(x): 0.479, D(G(z)): 0.490\n",
      "2019-04-09 23:00:02,476 root         INFO     Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 0.226902\n",
      "Reconstruction: 0.158964, Regularization: 0.001869, Discriminator: 0.043966; Generator: 0.022103,\n",
      "D(x): 0.491, D(G(z)): 0.493\n",
      "2019-04-09 23:00:02,572 root         INFO     Train Epoch: 61 [4608/8000 (58%)]\tTotal Loss: 0.253789\n",
      "Reconstruction: 0.186106, Regularization: 0.002427, Discriminator: 0.042908; Generator: 0.022348,\n",
      "D(x): 0.505, D(G(z)): 0.489\n",
      "2019-04-09 23:00:02,669 root         INFO     Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 0.225119\n",
      "Reconstruction: 0.158494, Regularization: 0.001527, Discriminator: 0.042901; Generator: 0.022197,\n",
      "D(x): 0.504, D(G(z)): 0.492\n",
      "2019-04-09 23:00:02,765 root         INFO     Train Epoch: 61 [5632/8000 (70%)]\tTotal Loss: 0.233310\n",
      "Reconstruction: 0.165120, Regularization: 0.001901, Discriminator: 0.044002; Generator: 0.022288,\n",
      "D(x): 0.487, D(G(z)): 0.490\n",
      "2019-04-09 23:00:02,861 root         INFO     Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 0.262710\n",
      "Reconstruction: 0.193450, Regularization: 0.002250, Discriminator: 0.044676; Generator: 0.022334,\n",
      "D(x): 0.477, D(G(z)): 0.489\n",
      "2019-04-09 23:00:02,958 root         INFO     Train Epoch: 61 [6656/8000 (83%)]\tTotal Loss: 0.247588\n",
      "Reconstruction: 0.181835, Regularization: 0.002691, Discriminator: 0.040985; Generator: 0.022077,\n",
      "D(x): 0.538, D(G(z)): 0.493\n",
      "2019-04-09 23:00:03,055 root         INFO     Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 0.259899\n",
      "Reconstruction: 0.191177, Regularization: 0.002254, Discriminator: 0.044183; Generator: 0.022285,\n",
      "D(x): 0.485, D(G(z)): 0.490\n",
      "2019-04-09 23:00:03,155 root         INFO     Train Epoch: 61 [7680/8000 (96%)]\tTotal Loss: 0.228800\n",
      "Reconstruction: 0.161514, Regularization: 0.001870, Discriminator: 0.043239; Generator: 0.022176,\n",
      "D(x): 0.500, D(G(z)): 0.492\n",
      "2019-04-09 23:00:03,229 root         INFO     ====> Epoch: 61 Average loss: 0.2458\n",
      "2019-04-09 23:00:03,256 root         INFO     Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 0.309389\n",
      "Reconstruction: 0.239988, Regularization: 0.003551, Discriminator: 0.043508; Generator: 0.022342,\n",
      "D(x): 0.498, D(G(z)): 0.489\n",
      "2019-04-09 23:00:03,359 root         INFO     Train Epoch: 62 [512/8000 (6%)]\tTotal Loss: 0.260877\n",
      "Reconstruction: 0.193178, Regularization: 0.002421, Discriminator: 0.043089; Generator: 0.022189,\n",
      "D(x): 0.504, D(G(z)): 0.492\n",
      "2019-04-09 23:00:03,461 root         INFO     Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 0.261824\n",
      "Reconstruction: 0.194346, Regularization: 0.002777, Discriminator: 0.042697; Generator: 0.022004,\n",
      "D(x): 0.513, D(G(z)): 0.495\n",
      "2019-04-09 23:00:03,560 root         INFO     Train Epoch: 62 [1536/8000 (19%)]\tTotal Loss: 0.201446\n",
      "Reconstruction: 0.133547, Regularization: 0.001136, Discriminator: 0.044575; Generator: 0.022187,\n",
      "D(x): 0.476, D(G(z)): 0.492\n",
      "2019-04-09 23:00:03,664 root         INFO     Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 0.277095\n",
      "Reconstruction: 0.208278, Regularization: 0.003086, Discriminator: 0.043576; Generator: 0.022155,\n",
      "D(x): 0.499, D(G(z)): 0.492\n",
      "2019-04-09 23:00:03,769 root         INFO     Train Epoch: 62 [2560/8000 (32%)]\tTotal Loss: 0.249100\n",
      "Reconstruction: 0.181312, Regularization: 0.002022, Discriminator: 0.043627; Generator: 0.022138,\n",
      "D(x): 0.494, D(G(z)): 0.492\n",
      "2019-04-09 23:00:03,872 root         INFO     Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 0.290439\n",
      "Reconstruction: 0.221403, Regularization: 0.003105, Discriminator: 0.043824; Generator: 0.022108,\n",
      "D(x): 0.495, D(G(z)): 0.493\n",
      "2019-04-09 23:00:03,973 root         INFO     Train Epoch: 62 [3584/8000 (45%)]\tTotal Loss: 0.261030\n",
      "Reconstruction: 0.193536, Regularization: 0.002604, Discriminator: 0.042766; Generator: 0.022125,\n",
      "D(x): 0.509, D(G(z)): 0.493\n",
      "2019-04-09 23:00:04,074 root         INFO     Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 0.233332\n",
      "Reconstruction: 0.164470, Regularization: 0.001848, Discriminator: 0.044821; Generator: 0.022194,\n",
      "D(x): 0.474, D(G(z)): 0.492\n",
      "2019-04-09 23:00:04,180 root         INFO     Train Epoch: 62 [4608/8000 (58%)]\tTotal Loss: 0.263209\n",
      "Reconstruction: 0.194454, Regularization: 0.002442, Discriminator: 0.044115; Generator: 0.022198,\n",
      "D(x): 0.487, D(G(z)): 0.492\n",
      "2019-04-09 23:00:04,281 root         INFO     Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 0.278767\n",
      "Reconstruction: 0.210273, Regularization: 0.002975, Discriminator: 0.043405; Generator: 0.022113,\n",
      "D(x): 0.500, D(G(z)): 0.493\n",
      "2019-04-09 23:00:04,382 root         INFO     Train Epoch: 62 [5632/8000 (70%)]\tTotal Loss: 0.243584\n",
      "Reconstruction: 0.176071, Regularization: 0.002430, Discriminator: 0.042888; Generator: 0.022195,\n",
      "D(x): 0.505, D(G(z)): 0.492\n",
      "2019-04-09 23:00:04,484 root         INFO     Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 0.218632\n",
      "Reconstruction: 0.150877, Regularization: 0.001712, Discriminator: 0.043885; Generator: 0.022157,\n",
      "D(x): 0.488, D(G(z)): 0.492\n",
      "2019-04-09 23:00:04,586 root         INFO     Train Epoch: 62 [6656/8000 (83%)]\tTotal Loss: 0.217885\n",
      "Reconstruction: 0.150208, Regularization: 0.001928, Discriminator: 0.043737; Generator: 0.022012,\n",
      "D(x): 0.493, D(G(z)): 0.494\n",
      "2019-04-09 23:00:04,690 root         INFO     Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 0.245162\n",
      "Reconstruction: 0.176663, Regularization: 0.002179, Discriminator: 0.044253; Generator: 0.022067,\n",
      "D(x): 0.485, D(G(z)): 0.494\n",
      "2019-04-09 23:00:04,794 root         INFO     Train Epoch: 62 [7680/8000 (96%)]\tTotal Loss: 0.234043\n",
      "Reconstruction: 0.164931, Regularization: 0.002210, Discriminator: 0.044703; Generator: 0.022199,\n",
      "D(x): 0.476, D(G(z)): 0.491\n",
      "2019-04-09 23:00:04,869 root         INFO     ====> Epoch: 62 Average loss: 0.2453\n",
      "2019-04-09 23:00:04,896 root         INFO     Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 0.231685\n",
      "Reconstruction: 0.163767, Regularization: 0.001976, Discriminator: 0.043790; Generator: 0.022151,\n",
      "D(x): 0.490, D(G(z)): 0.492\n",
      "2019-04-09 23:00:04,996 root         INFO     Train Epoch: 63 [512/8000 (6%)]\tTotal Loss: 0.263829\n",
      "Reconstruction: 0.195105, Regularization: 0.002349, Discriminator: 0.044433; Generator: 0.021942,\n",
      "D(x): 0.484, D(G(z)): 0.496\n",
      "2019-04-09 23:00:05,096 root         INFO     Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 0.252786\n",
      "Reconstruction: 0.184343, Regularization: 0.002260, Discriminator: 0.044228; Generator: 0.021956,\n",
      "D(x): 0.487, D(G(z)): 0.495\n",
      "2019-04-09 23:00:05,195 root         INFO     Train Epoch: 63 [1536/8000 (19%)]\tTotal Loss: 0.269345\n",
      "Reconstruction: 0.200670, Regularization: 0.002705, Discriminator: 0.043881; Generator: 0.022089,\n",
      "D(x): 0.492, D(G(z)): 0.493\n",
      "2019-04-09 23:00:05,292 root         INFO     Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 0.212550\n",
      "Reconstruction: 0.144698, Regularization: 0.001755, Discriminator: 0.043976; Generator: 0.022121,\n",
      "D(x): 0.487, D(G(z)): 0.493\n",
      "2019-04-09 23:00:05,393 root         INFO     Train Epoch: 63 [2560/8000 (32%)]\tTotal Loss: 0.201239\n",
      "Reconstruction: 0.135142, Regularization: 0.001336, Discriminator: 0.042700; Generator: 0.022062,\n",
      "D(x): 0.506, D(G(z)): 0.494\n",
      "2019-04-09 23:00:05,494 root         INFO     Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 0.231559\n",
      "Reconstruction: 0.163827, Regularization: 0.002152, Discriminator: 0.043430; Generator: 0.022149,\n",
      "D(x): 0.496, D(G(z)): 0.492\n",
      "2019-04-09 23:00:05,599 root         INFO     Train Epoch: 63 [3584/8000 (45%)]\tTotal Loss: 0.266865\n",
      "Reconstruction: 0.199726, Regularization: 0.003083, Discriminator: 0.041951; Generator: 0.022105,\n",
      "D(x): 0.521, D(G(z)): 0.493\n",
      "2019-04-09 23:00:05,705 root         INFO     Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 0.222404\n",
      "Reconstruction: 0.154326, Regularization: 0.001557, Discriminator: 0.044390; Generator: 0.022131,\n",
      "D(x): 0.480, D(G(z)): 0.493\n",
      "2019-04-09 23:00:05,817 root         INFO     Train Epoch: 63 [4608/8000 (58%)]\tTotal Loss: 0.221772\n",
      "Reconstruction: 0.154605, Regularization: 0.001890, Discriminator: 0.043236; Generator: 0.022041,\n",
      "D(x): 0.499, D(G(z)): 0.494\n",
      "2019-04-09 23:00:05,927 root         INFO     Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 0.275769\n",
      "Reconstruction: 0.206967, Regularization: 0.002931, Discriminator: 0.043936; Generator: 0.021935,\n",
      "D(x): 0.492, D(G(z)): 0.496\n",
      "2019-04-09 23:00:06,029 root         INFO     Train Epoch: 63 [5632/8000 (70%)]\tTotal Loss: 0.239477\n",
      "Reconstruction: 0.172563, Regularization: 0.002272, Discriminator: 0.042519; Generator: 0.022123,\n",
      "D(x): 0.510, D(G(z)): 0.493\n",
      "2019-04-09 23:00:06,130 root         INFO     Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 0.205353\n",
      "Reconstruction: 0.138020, Regularization: 0.001412, Discriminator: 0.043949; Generator: 0.021971,\n",
      "D(x): 0.488, D(G(z)): 0.495\n",
      "2019-04-09 23:00:06,231 root         INFO     Train Epoch: 63 [6656/8000 (83%)]\tTotal Loss: 0.301189\n",
      "Reconstruction: 0.230567, Regularization: 0.003324, Discriminator: 0.045288; Generator: 0.022009,\n",
      "D(x): 0.470, D(G(z)): 0.494\n",
      "2019-04-09 23:00:06,333 root         INFO     Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 0.220736\n",
      "Reconstruction: 0.153903, Regularization: 0.001543, Discriminator: 0.043253; Generator: 0.022037,\n",
      "D(x): 0.498, D(G(z)): 0.494\n",
      "2019-04-09 23:00:06,434 root         INFO     Train Epoch: 63 [7680/8000 (96%)]\tTotal Loss: 0.236589\n",
      "Reconstruction: 0.169050, Regularization: 0.002119, Discriminator: 0.043411; Generator: 0.022009,\n",
      "D(x): 0.497, D(G(z)): 0.494\n",
      "2019-04-09 23:00:06,510 root         INFO     ====> Epoch: 63 Average loss: 0.2451\n",
      "2019-04-09 23:00:06,537 root         INFO     Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 0.254516\n",
      "Reconstruction: 0.187024, Regularization: 0.002468, Discriminator: 0.043056; Generator: 0.021968,\n",
      "D(x): 0.504, D(G(z)): 0.495\n",
      "2019-04-09 23:00:06,642 root         INFO     Train Epoch: 64 [512/8000 (6%)]\tTotal Loss: 0.243527\n",
      "Reconstruction: 0.173717, Regularization: 0.002538, Discriminator: 0.045379; Generator: 0.021893,\n",
      "D(x): 0.469, D(G(z)): 0.496\n",
      "2019-04-09 23:00:06,746 root         INFO     Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 0.237762\n",
      "Reconstruction: 0.169371, Regularization: 0.002051, Discriminator: 0.044372; Generator: 0.021967,\n",
      "D(x): 0.483, D(G(z)): 0.495\n",
      "2019-04-09 23:00:06,848 root         INFO     Train Epoch: 64 [1536/8000 (19%)]\tTotal Loss: 0.263850\n",
      "Reconstruction: 0.195820, Regularization: 0.002636, Discriminator: 0.043378; Generator: 0.022016,\n",
      "D(x): 0.498, D(G(z)): 0.494\n",
      "2019-04-09 23:00:06,952 root         INFO     Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 0.261587\n",
      "Reconstruction: 0.193473, Regularization: 0.002538, Discriminator: 0.043581; Generator: 0.021996,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-04-09 23:00:07,057 root         INFO     Train Epoch: 64 [2560/8000 (32%)]\tTotal Loss: 0.265138\n",
      "Reconstruction: 0.196554, Regularization: 0.002827, Discriminator: 0.043655; Generator: 0.022102,\n",
      "D(x): 0.492, D(G(z)): 0.493\n",
      "2019-04-09 23:00:07,160 root         INFO     Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 0.259725\n",
      "Reconstruction: 0.190467, Regularization: 0.002613, Discriminator: 0.044609; Generator: 0.022037,\n",
      "D(x): 0.478, D(G(z)): 0.494\n",
      "2019-04-09 23:00:07,260 root         INFO     Train Epoch: 64 [3584/8000 (45%)]\tTotal Loss: 0.195635\n",
      "Reconstruction: 0.128417, Regularization: 0.001413, Discriminator: 0.043768; Generator: 0.022037,\n",
      "D(x): 0.489, D(G(z)): 0.494\n",
      "2019-04-09 23:00:07,360 root         INFO     Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 0.239675\n",
      "Reconstruction: 0.172151, Regularization: 0.002034, Discriminator: 0.043510; Generator: 0.021980,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-04-09 23:00:07,460 root         INFO     Train Epoch: 64 [4608/8000 (58%)]\tTotal Loss: 0.247563\n",
      "Reconstruction: 0.180099, Regularization: 0.002474, Discriminator: 0.042995; Generator: 0.021994,\n",
      "D(x): 0.504, D(G(z)): 0.495\n",
      "2019-04-09 23:00:07,561 root         INFO     Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 0.288577\n",
      "Reconstruction: 0.217925, Regularization: 0.003274, Discriminator: 0.045424; Generator: 0.021954,\n",
      "D(x): 0.467, D(G(z)): 0.495\n",
      "2019-04-09 23:00:07,660 root         INFO     Train Epoch: 64 [5632/8000 (70%)]\tTotal Loss: 0.251200\n",
      "Reconstruction: 0.183845, Regularization: 0.002515, Discriminator: 0.042880; Generator: 0.021961,\n",
      "D(x): 0.506, D(G(z)): 0.495\n",
      "2019-04-09 23:00:07,761 root         INFO     Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 0.256473\n",
      "Reconstruction: 0.188295, Regularization: 0.002586, Discriminator: 0.043571; Generator: 0.022022,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-04-09 23:00:07,858 root         INFO     Train Epoch: 64 [6656/8000 (83%)]\tTotal Loss: 0.259227\n",
      "Reconstruction: 0.192362, Regularization: 0.002346, Discriminator: 0.042527; Generator: 0.021991,\n",
      "D(x): 0.510, D(G(z)): 0.495\n",
      "2019-04-09 23:00:07,954 root         INFO     Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 0.215653\n",
      "Reconstruction: 0.148255, Regularization: 0.001898, Discriminator: 0.043506; Generator: 0.021995,\n",
      "D(x): 0.494, D(G(z)): 0.495\n",
      "2019-04-09 23:00:08,050 root         INFO     Train Epoch: 64 [7680/8000 (96%)]\tTotal Loss: 0.253538\n",
      "Reconstruction: 0.185531, Regularization: 0.002388, Discriminator: 0.043722; Generator: 0.021896,\n",
      "D(x): 0.493, D(G(z)): 0.496\n",
      "2019-04-09 23:00:08,122 root         INFO     ====> Epoch: 64 Average loss: 0.2450\n",
      "2019-04-09 23:00:08,148 root         INFO     Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 0.251255\n",
      "Reconstruction: 0.183373, Regularization: 0.002971, Discriminator: 0.042912; Generator: 0.021999,\n",
      "D(x): 0.505, D(G(z)): 0.495\n",
      "2019-04-09 23:00:08,251 root         INFO     Train Epoch: 65 [512/8000 (6%)]\tTotal Loss: 0.239742\n",
      "Reconstruction: 0.171804, Regularization: 0.002357, Discriminator: 0.043654; Generator: 0.021927,\n",
      "D(x): 0.493, D(G(z)): 0.496\n",
      "2019-04-09 23:00:08,353 root         INFO     Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 0.269275\n",
      "Reconstruction: 0.200657, Regularization: 0.003210, Discriminator: 0.043484; Generator: 0.021923,\n",
      "D(x): 0.497, D(G(z)): 0.496\n",
      "2019-04-09 23:00:08,454 root         INFO     Train Epoch: 65 [1536/8000 (19%)]\tTotal Loss: 0.223177\n",
      "Reconstruction: 0.154664, Regularization: 0.001969, Discriminator: 0.044611; Generator: 0.021934,\n",
      "D(x): 0.478, D(G(z)): 0.496\n",
      "2019-04-09 23:00:08,555 root         INFO     Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 0.231863\n",
      "Reconstruction: 0.164237, Regularization: 0.002148, Discriminator: 0.043526; Generator: 0.021952,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-04-09 23:00:08,656 root         INFO     Train Epoch: 65 [2560/8000 (32%)]\tTotal Loss: 0.292194\n",
      "Reconstruction: 0.223224, Regularization: 0.003947, Discriminator: 0.043016; Generator: 0.022006,\n",
      "D(x): 0.504, D(G(z)): 0.495\n",
      "2019-04-09 23:00:08,758 root         INFO     Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 0.263518\n",
      "Reconstruction: 0.195559, Regularization: 0.002683, Discriminator: 0.043346; Generator: 0.021931,\n",
      "D(x): 0.498, D(G(z)): 0.496\n",
      "2019-04-09 23:00:08,857 root         INFO     Train Epoch: 65 [3584/8000 (45%)]\tTotal Loss: 0.239822\n",
      "Reconstruction: 0.171359, Regularization: 0.002293, Discriminator: 0.044228; Generator: 0.021942,\n",
      "D(x): 0.484, D(G(z)): 0.496\n",
      "2019-04-09 23:00:08,955 root         INFO     Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 0.213381\n",
      "Reconstruction: 0.145705, Regularization: 0.001708, Discriminator: 0.044075; Generator: 0.021892,\n",
      "D(x): 0.486, D(G(z)): 0.496\n",
      "2019-04-09 23:00:09,054 root         INFO     Train Epoch: 65 [4608/8000 (58%)]\tTotal Loss: 0.263970\n",
      "Reconstruction: 0.195546, Regularization: 0.002760, Discriminator: 0.043770; Generator: 0.021895,\n",
      "D(x): 0.492, D(G(z)): 0.496\n",
      "2019-04-09 23:00:09,153 root         INFO     Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 0.217748\n",
      "Reconstruction: 0.150389, Regularization: 0.001979, Discriminator: 0.043488; Generator: 0.021891,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-04-09 23:00:09,251 root         INFO     Train Epoch: 65 [5632/8000 (70%)]\tTotal Loss: 0.239374\n",
      "Reconstruction: 0.171915, Regularization: 0.002274, Discriminator: 0.043332; Generator: 0.021853,\n",
      "D(x): 0.499, D(G(z)): 0.497\n",
      "2019-04-09 23:00:09,351 root         INFO     Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 0.257997\n",
      "Reconstruction: 0.189556, Regularization: 0.002827, Discriminator: 0.043690; Generator: 0.021924,\n",
      "D(x): 0.493, D(G(z)): 0.496\n",
      "2019-04-09 23:00:09,450 root         INFO     Train Epoch: 65 [6656/8000 (83%)]\tTotal Loss: 0.267709\n",
      "Reconstruction: 0.200147, Regularization: 0.003188, Discriminator: 0.042458; Generator: 0.021917,\n",
      "D(x): 0.512, D(G(z)): 0.496\n",
      "2019-04-09 23:00:09,550 root         INFO     Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 0.274364\n",
      "Reconstruction: 0.205768, Regularization: 0.002944, Discriminator: 0.043706; Generator: 0.021946,\n",
      "D(x): 0.492, D(G(z)): 0.495\n",
      "2019-04-09 23:00:09,648 root         INFO     Train Epoch: 65 [7680/8000 (96%)]\tTotal Loss: 0.292416\n",
      "Reconstruction: 0.224124, Regularization: 0.003314, Discriminator: 0.043064; Generator: 0.021913,\n",
      "D(x): 0.503, D(G(z)): 0.496\n",
      "2019-04-09 23:00:09,723 root         INFO     ====> Epoch: 65 Average loss: 0.2448\n",
      "2019-04-09 23:00:09,749 root         INFO     Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 0.296069\n",
      "Reconstruction: 0.225792, Regularization: 0.003806, Discriminator: 0.044522; Generator: 0.021949,\n",
      "D(x): 0.480, D(G(z)): 0.495\n",
      "2019-04-09 23:00:09,850 root         INFO     Train Epoch: 66 [512/8000 (6%)]\tTotal Loss: 0.177042\n",
      "Reconstruction: 0.110537, Regularization: 0.001170, Discriminator: 0.043371; Generator: 0.021963,\n",
      "D(x): 0.496, D(G(z)): 0.495\n",
      "2019-04-09 23:00:09,950 root         INFO     Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 0.237787\n",
      "Reconstruction: 0.169523, Regularization: 0.002264, Discriminator: 0.044118; Generator: 0.021882,\n",
      "D(x): 0.486, D(G(z)): 0.496\n",
      "2019-04-09 23:00:10,050 root         INFO     Train Epoch: 66 [1536/8000 (19%)]\tTotal Loss: 0.270454\n",
      "Reconstruction: 0.202508, Regularization: 0.003139, Discriminator: 0.042880; Generator: 0.021928,\n",
      "D(x): 0.505, D(G(z)): 0.496\n",
      "2019-04-09 23:00:10,150 root         INFO     Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 0.201665\n",
      "Reconstruction: 0.135504, Regularization: 0.001556, Discriminator: 0.042658; Generator: 0.021946,\n",
      "D(x): 0.507, D(G(z)): 0.495\n",
      "2019-04-09 23:00:10,250 root         INFO     Train Epoch: 66 [2560/8000 (32%)]\tTotal Loss: 0.254424\n",
      "Reconstruction: 0.186435, Regularization: 0.002540, Discriminator: 0.043569; Generator: 0.021880,\n",
      "D(x): 0.494, D(G(z)): 0.497\n",
      "2019-04-09 23:00:10,350 root         INFO     Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 0.282126\n",
      "Reconstruction: 0.213232, Regularization: 0.003046, Discriminator: 0.043921; Generator: 0.021927,\n",
      "D(x): 0.489, D(G(z)): 0.496\n",
      "2019-04-09 23:00:10,449 root         INFO     Train Epoch: 66 [3584/8000 (45%)]\tTotal Loss: 0.245710\n",
      "Reconstruction: 0.178281, Regularization: 0.002687, Discriminator: 0.042827; Generator: 0.021915,\n",
      "D(x): 0.506, D(G(z)): 0.496\n",
      "2019-04-09 23:00:10,550 root         INFO     Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 0.256228\n",
      "Reconstruction: 0.187880, Regularization: 0.002946, Discriminator: 0.043460; Generator: 0.021942,\n",
      "D(x): 0.495, D(G(z)): 0.496\n",
      "2019-04-09 23:00:10,650 root         INFO     Train Epoch: 66 [4608/8000 (58%)]\tTotal Loss: 0.249893\n",
      "Reconstruction: 0.181814, Regularization: 0.002558, Discriminator: 0.043630; Generator: 0.021891,\n",
      "D(x): 0.493, D(G(z)): 0.496\n",
      "2019-04-09 23:00:10,750 root         INFO     Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 0.215087\n",
      "Reconstruction: 0.146966, Regularization: 0.001920, Discriminator: 0.044311; Generator: 0.021890,\n",
      "D(x): 0.482, D(G(z)): 0.496\n",
      "2019-04-09 23:00:10,850 root         INFO     Train Epoch: 66 [5632/8000 (70%)]\tTotal Loss: 0.197413\n",
      "Reconstruction: 0.130384, Regularization: 0.001513, Discriminator: 0.043609; Generator: 0.021907,\n",
      "D(x): 0.493, D(G(z)): 0.496\n",
      "2019-04-09 23:00:10,950 root         INFO     Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 0.246092\n",
      "Reconstruction: 0.177485, Regularization: 0.002550, Discriminator: 0.044114; Generator: 0.021943,\n",
      "D(x): 0.485, D(G(z)): 0.496\n",
      "2019-04-09 23:00:11,051 root         INFO     Train Epoch: 66 [6656/8000 (83%)]\tTotal Loss: 0.224002\n",
      "Reconstruction: 0.156646, Regularization: 0.002070, Discriminator: 0.043401; Generator: 0.021885,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-04-09 23:00:11,153 root         INFO     Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 0.220369\n",
      "Reconstruction: 0.153275, Regularization: 0.001858, Discriminator: 0.043363; Generator: 0.021873,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-09 23:00:11,254 root         INFO     Train Epoch: 66 [7680/8000 (96%)]\tTotal Loss: 0.190316\n",
      "Reconstruction: 0.123727, Regularization: 0.001376, Discriminator: 0.043333; Generator: 0.021880,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-09 23:00:11,330 root         INFO     ====> Epoch: 66 Average loss: 0.2451\n",
      "2019-04-09 23:00:11,356 root         INFO     Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 0.237523\n",
      "Reconstruction: 0.170158, Regularization: 0.002247, Discriminator: 0.043176; Generator: 0.021942,\n",
      "D(x): 0.499, D(G(z)): 0.496\n",
      "2019-04-09 23:00:11,456 root         INFO     Train Epoch: 67 [512/8000 (6%)]\tTotal Loss: 0.269714\n",
      "Reconstruction: 0.201079, Regularization: 0.003390, Discriminator: 0.043371; Generator: 0.021873,\n",
      "D(x): 0.498, D(G(z)): 0.497\n",
      "2019-04-09 23:00:11,556 root         INFO     Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 0.235834\n",
      "Reconstruction: 0.168548, Regularization: 0.002492, Discriminator: 0.042902; Generator: 0.021891,\n",
      "D(x): 0.504, D(G(z)): 0.496\n",
      "2019-04-09 23:00:11,657 root         INFO     Train Epoch: 67 [1536/8000 (19%)]\tTotal Loss: 0.276871\n",
      "Reconstruction: 0.208190, Regularization: 0.003647, Discriminator: 0.043183; Generator: 0.021851,\n",
      "D(x): 0.501, D(G(z)): 0.497\n",
      "2019-04-09 23:00:11,757 root         INFO     Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 0.217274\n",
      "Reconstruction: 0.149515, Regularization: 0.001923, Discriminator: 0.043995; Generator: 0.021841,\n",
      "D(x): 0.487, D(G(z)): 0.497\n",
      "2019-04-09 23:00:11,857 root         INFO     Train Epoch: 67 [2560/8000 (32%)]\tTotal Loss: 0.304018\n",
      "Reconstruction: 0.233991, Regularization: 0.003826, Discriminator: 0.044379; Generator: 0.021822,\n",
      "D(x): 0.483, D(G(z)): 0.497\n",
      "2019-04-09 23:00:11,957 root         INFO     Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 0.231904\n",
      "Reconstruction: 0.164722, Regularization: 0.002057, Discriminator: 0.043247; Generator: 0.021879,\n",
      "D(x): 0.499, D(G(z)): 0.497\n",
      "2019-04-09 23:00:12,057 root         INFO     Train Epoch: 67 [3584/8000 (45%)]\tTotal Loss: 0.262683\n",
      "Reconstruction: 0.193797, Regularization: 0.003144, Discriminator: 0.043856; Generator: 0.021886,\n",
      "D(x): 0.489, D(G(z)): 0.496\n",
      "2019-04-09 23:00:12,157 root         INFO     Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 0.226311\n",
      "Reconstruction: 0.158390, Regularization: 0.002245, Discriminator: 0.043810; Generator: 0.021865,\n",
      "D(x): 0.490, D(G(z)): 0.497\n",
      "2019-04-09 23:00:12,257 root         INFO     Train Epoch: 67 [4608/8000 (58%)]\tTotal Loss: 0.265706\n",
      "Reconstruction: 0.196504, Regularization: 0.003177, Discriminator: 0.044166; Generator: 0.021860,\n",
      "D(x): 0.485, D(G(z)): 0.497\n",
      "2019-04-09 23:00:12,357 root         INFO     Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 0.274589\n",
      "Reconstruction: 0.206234, Regularization: 0.003354, Discriminator: 0.043179; Generator: 0.021822,\n",
      "D(x): 0.501, D(G(z)): 0.497\n",
      "2019-04-09 23:00:12,456 root         INFO     Train Epoch: 67 [5632/8000 (70%)]\tTotal Loss: 0.249673\n",
      "Reconstruction: 0.180766, Regularization: 0.002756, Discriminator: 0.044319; Generator: 0.021832,\n",
      "D(x): 0.483, D(G(z)): 0.497\n",
      "2019-04-09 23:00:12,556 root         INFO     Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 0.238621\n",
      "Reconstruction: 0.171135, Regularization: 0.002268, Discriminator: 0.043392; Generator: 0.021826,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-09 23:00:12,656 root         INFO     Train Epoch: 67 [6656/8000 (83%)]\tTotal Loss: 0.223639\n",
      "Reconstruction: 0.156229, Regularization: 0.001954, Discriminator: 0.043574; Generator: 0.021882,\n",
      "D(x): 0.493, D(G(z)): 0.496\n",
      "2019-04-09 23:00:12,756 root         INFO     Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 0.271930\n",
      "Reconstruction: 0.203032, Regularization: 0.003471, Discriminator: 0.043557; Generator: 0.021870,\n",
      "D(x): 0.494, D(G(z)): 0.497\n",
      "2019-04-09 23:00:12,856 root         INFO     Train Epoch: 67 [7680/8000 (96%)]\tTotal Loss: 0.235923\n",
      "Reconstruction: 0.168602, Regularization: 0.002462, Discriminator: 0.043015; Generator: 0.021844,\n",
      "D(x): 0.503, D(G(z)): 0.497\n",
      "2019-04-09 23:00:12,930 root         INFO     ====> Epoch: 67 Average loss: 0.2451\n",
      "2019-04-09 23:00:12,957 root         INFO     Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 0.263224\n",
      "Reconstruction: 0.194300, Regularization: 0.003135, Discriminator: 0.043970; Generator: 0.021819,\n",
      "D(x): 0.488, D(G(z)): 0.497\n",
      "2019-04-09 23:00:13,057 root         INFO     Train Epoch: 68 [512/8000 (6%)]\tTotal Loss: 0.266282\n",
      "Reconstruction: 0.197063, Regularization: 0.003268, Discriminator: 0.044114; Generator: 0.021836,\n",
      "D(x): 0.486, D(G(z)): 0.497\n",
      "2019-04-09 23:00:13,159 root         INFO     Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 0.255903\n",
      "Reconstruction: 0.187425, Regularization: 0.003023, Discriminator: 0.043625; Generator: 0.021830,\n",
      "D(x): 0.493, D(G(z)): 0.497\n",
      "2019-04-09 23:00:13,260 root         INFO     Train Epoch: 68 [1536/8000 (19%)]\tTotal Loss: 0.216246\n",
      "Reconstruction: 0.149070, Regularization: 0.002140, Discriminator: 0.043188; Generator: 0.021847,\n",
      "D(x): 0.500, D(G(z)): 0.497\n",
      "2019-04-09 23:00:13,360 root         INFO     Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 0.216539\n",
      "Reconstruction: 0.149296, Regularization: 0.001800, Discriminator: 0.043618; Generator: 0.021824,\n",
      "D(x): 0.493, D(G(z)): 0.497\n",
      "2019-04-09 23:00:13,461 root         INFO     Train Epoch: 68 [2560/8000 (32%)]\tTotal Loss: 0.271480\n",
      "Reconstruction: 0.202115, Regularization: 0.003347, Discriminator: 0.044140; Generator: 0.021878,\n",
      "D(x): 0.484, D(G(z)): 0.497\n",
      "2019-04-09 23:00:13,562 root         INFO     Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 0.266056\n",
      "Reconstruction: 0.197791, Regularization: 0.003431, Discriminator: 0.043014; Generator: 0.021820,\n",
      "D(x): 0.503, D(G(z)): 0.497\n",
      "2019-04-09 23:00:13,663 root         INFO     Train Epoch: 68 [3584/8000 (45%)]\tTotal Loss: 0.266986\n",
      "Reconstruction: 0.198624, Regularization: 0.003123, Discriminator: 0.043360; Generator: 0.021877,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-09 23:00:13,763 root         INFO     Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 0.252247\n",
      "Reconstruction: 0.184061, Regularization: 0.002714, Discriminator: 0.043614; Generator: 0.021858,\n",
      "D(x): 0.493, D(G(z)): 0.497\n",
      "2019-04-09 23:00:13,864 root         INFO     Train Epoch: 68 [4608/8000 (58%)]\tTotal Loss: 0.237932\n",
      "Reconstruction: 0.170063, Regularization: 0.002471, Discriminator: 0.043590; Generator: 0.021807,\n",
      "D(x): 0.494, D(G(z)): 0.498\n",
      "2019-04-09 23:00:13,965 root         INFO     Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 0.245719\n",
      "Reconstruction: 0.177616, Regularization: 0.002915, Discriminator: 0.043321; Generator: 0.021867,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-09 23:00:14,066 root         INFO     Train Epoch: 68 [5632/8000 (70%)]\tTotal Loss: 0.249102\n",
      "Reconstruction: 0.180633, Regularization: 0.002856, Discriminator: 0.043799; Generator: 0.021814,\n",
      "D(x): 0.491, D(G(z)): 0.498\n",
      "2019-04-09 23:00:14,166 root         INFO     Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 0.229559\n",
      "Reconstruction: 0.162069, Regularization: 0.002406, Discriminator: 0.043293; Generator: 0.021791,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 23:00:14,265 root         INFO     Train Epoch: 68 [6656/8000 (83%)]\tTotal Loss: 0.227361\n",
      "Reconstruction: 0.159573, Regularization: 0.002457, Discriminator: 0.043522; Generator: 0.021809,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 23:00:14,363 root         INFO     Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 0.219305\n",
      "Reconstruction: 0.151558, Regularization: 0.002270, Discriminator: 0.043667; Generator: 0.021810,\n",
      "D(x): 0.493, D(G(z)): 0.498\n",
      "2019-04-09 23:00:14,462 root         INFO     Train Epoch: 68 [7680/8000 (96%)]\tTotal Loss: 0.250537\n",
      "Reconstruction: 0.182499, Regularization: 0.003029, Discriminator: 0.043228; Generator: 0.021781,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 23:00:14,537 root         INFO     ====> Epoch: 68 Average loss: 0.2452\n",
      "2019-04-09 23:00:14,563 root         INFO     Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 0.277246\n",
      "Reconstruction: 0.208123, Regularization: 0.003456, Discriminator: 0.043944; Generator: 0.021723,\n",
      "D(x): 0.490, D(G(z)): 0.499\n",
      "2019-04-09 23:00:14,665 root         INFO     Train Epoch: 69 [512/8000 (6%)]\tTotal Loss: 0.220530\n",
      "Reconstruction: 0.153059, Regularization: 0.002228, Discriminator: 0.043455; Generator: 0.021788,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 23:00:14,764 root         INFO     Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 0.280788\n",
      "Reconstruction: 0.211229, Regularization: 0.003897, Discriminator: 0.043864; Generator: 0.021798,\n",
      "D(x): 0.490, D(G(z)): 0.498\n",
      "2019-04-09 23:00:14,863 root         INFO     Train Epoch: 69 [1536/8000 (19%)]\tTotal Loss: 0.268491\n",
      "Reconstruction: 0.199643, Regularization: 0.003606, Discriminator: 0.043470; Generator: 0.021772,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 23:00:14,962 root         INFO     Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 0.237616\n",
      "Reconstruction: 0.169372, Regularization: 0.002575, Discriminator: 0.043883; Generator: 0.021786,\n",
      "D(x): 0.489, D(G(z)): 0.498\n",
      "2019-04-09 23:00:15,060 root         INFO     Train Epoch: 69 [2560/8000 (32%)]\tTotal Loss: 0.268480\n",
      "Reconstruction: 0.200052, Regularization: 0.003568, Discriminator: 0.043046; Generator: 0.021813,\n",
      "D(x): 0.502, D(G(z)): 0.498\n",
      "2019-04-09 23:00:15,159 root         INFO     Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 0.251394\n",
      "Reconstruction: 0.183290, Regularization: 0.002827, Discriminator: 0.043514; Generator: 0.021763,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 23:00:15,258 root         INFO     Train Epoch: 69 [3584/8000 (45%)]\tTotal Loss: 0.219347\n",
      "Reconstruction: 0.151680, Regularization: 0.002090, Discriminator: 0.043773; Generator: 0.021804,\n",
      "D(x): 0.491, D(G(z)): 0.498\n",
      "2019-04-09 23:00:15,356 root         INFO     Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 0.229094\n",
      "Reconstruction: 0.161371, Regularization: 0.002380, Discriminator: 0.043579; Generator: 0.021763,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 23:00:15,454 root         INFO     Train Epoch: 69 [4608/8000 (58%)]\tTotal Loss: 0.243046\n",
      "Reconstruction: 0.174817, Regularization: 0.002674, Discriminator: 0.043768; Generator: 0.021787,\n",
      "D(x): 0.491, D(G(z)): 0.498\n",
      "2019-04-09 23:00:15,553 root         INFO     Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 0.272656\n",
      "Reconstruction: 0.204287, Regularization: 0.003460, Discriminator: 0.043139; Generator: 0.021770,\n",
      "D(x): 0.502, D(G(z)): 0.498\n",
      "2019-04-09 23:00:15,653 root         INFO     Train Epoch: 69 [5632/8000 (70%)]\tTotal Loss: 0.236804\n",
      "Reconstruction: 0.169088, Regularization: 0.002614, Discriminator: 0.043349; Generator: 0.021753,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:00:15,753 root         INFO     Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 0.255792\n",
      "Reconstruction: 0.187304, Regularization: 0.003174, Discriminator: 0.043530; Generator: 0.021784,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 23:00:15,853 root         INFO     Train Epoch: 69 [6656/8000 (83%)]\tTotal Loss: 0.249930\n",
      "Reconstruction: 0.181385, Regularization: 0.003113, Discriminator: 0.043686; Generator: 0.021746,\n",
      "D(x): 0.493, D(G(z)): 0.499\n",
      "2019-04-09 23:00:15,953 root         INFO     Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 0.268582\n",
      "Reconstruction: 0.199921, Regularization: 0.003274, Discriminator: 0.043619; Generator: 0.021769,\n",
      "D(x): 0.494, D(G(z)): 0.498\n",
      "2019-04-09 23:00:16,052 root         INFO     Train Epoch: 69 [7680/8000 (96%)]\tTotal Loss: 0.294520\n",
      "Reconstruction: 0.224997, Regularization: 0.004137, Discriminator: 0.043592; Generator: 0.021793,\n",
      "D(x): 0.494, D(G(z)): 0.498\n",
      "2019-04-09 23:00:16,127 root         INFO     ====> Epoch: 69 Average loss: 0.2459\n",
      "2019-04-09 23:00:16,154 root         INFO     Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 0.223136\n",
      "Reconstruction: 0.155883, Regularization: 0.002075, Discriminator: 0.043416; Generator: 0.021762,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 23:00:16,254 root         INFO     Train Epoch: 70 [512/8000 (6%)]\tTotal Loss: 0.250870\n",
      "Reconstruction: 0.182755, Regularization: 0.003084, Discriminator: 0.043252; Generator: 0.021779,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 23:00:16,354 root         INFO     Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 0.282938\n",
      "Reconstruction: 0.213520, Regularization: 0.003985, Discriminator: 0.043657; Generator: 0.021776,\n",
      "D(x): 0.493, D(G(z)): 0.498\n",
      "2019-04-09 23:00:16,453 root         INFO     Train Epoch: 70 [1536/8000 (19%)]\tTotal Loss: 0.203408\n",
      "Reconstruction: 0.136524, Regularization: 0.001628, Discriminator: 0.043494; Generator: 0.021763,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 23:00:16,552 root         INFO     Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 0.286737\n",
      "Reconstruction: 0.217033, Regularization: 0.004320, Discriminator: 0.043634; Generator: 0.021750,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 23:00:16,651 root         INFO     Train Epoch: 70 [2560/8000 (32%)]\tTotal Loss: 0.272454\n",
      "Reconstruction: 0.203918, Regularization: 0.003512, Discriminator: 0.043266; Generator: 0.021759,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 23:00:16,750 root         INFO     Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 0.230184\n",
      "Reconstruction: 0.162718, Regularization: 0.002371, Discriminator: 0.043329; Generator: 0.021765,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 23:00:16,850 root         INFO     Train Epoch: 70 [3584/8000 (45%)]\tTotal Loss: 0.229989\n",
      "Reconstruction: 0.162406, Regularization: 0.002607, Discriminator: 0.043212; Generator: 0.021764,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 23:00:16,949 root         INFO     Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 0.254780\n",
      "Reconstruction: 0.186411, Regularization: 0.003170, Discriminator: 0.043447; Generator: 0.021751,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:00:17,047 root         INFO     Train Epoch: 70 [4608/8000 (58%)]\tTotal Loss: 0.221269\n",
      "Reconstruction: 0.153537, Regularization: 0.002506, Discriminator: 0.043484; Generator: 0.021742,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 23:00:17,146 root         INFO     Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 0.265367\n",
      "Reconstruction: 0.196136, Regularization: 0.003928, Discriminator: 0.043524; Generator: 0.021779,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 23:00:17,245 root         INFO     Train Epoch: 70 [5632/8000 (70%)]\tTotal Loss: 0.222501\n",
      "Reconstruction: 0.155004, Regularization: 0.002328, Discriminator: 0.043419; Generator: 0.021750,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:00:17,343 root         INFO     Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 0.231462\n",
      "Reconstruction: 0.164037, Regularization: 0.002311, Discriminator: 0.043363; Generator: 0.021752,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:00:17,442 root         INFO     Train Epoch: 70 [6656/8000 (83%)]\tTotal Loss: 0.249788\n",
      "Reconstruction: 0.181624, Regularization: 0.002935, Discriminator: 0.043470; Generator: 0.021760,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 23:00:17,540 root         INFO     Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 0.242472\n",
      "Reconstruction: 0.174595, Regularization: 0.002807, Discriminator: 0.043311; Generator: 0.021759,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 23:00:17,639 root         INFO     Train Epoch: 70 [7680/8000 (96%)]\tTotal Loss: 0.237808\n",
      "Reconstruction: 0.169727, Regularization: 0.002790, Discriminator: 0.043530; Generator: 0.021761,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 23:00:17,713 root         INFO     ====> Epoch: 70 Average loss: 0.2462\n",
      "2019-04-09 23:00:17,740 root         INFO     Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 0.224221\n",
      "Reconstruction: 0.156213, Regularization: 0.002756, Discriminator: 0.043483; Generator: 0.021769,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 23:00:17,840 root         INFO     Train Epoch: 71 [512/8000 (6%)]\tTotal Loss: 0.271122\n",
      "Reconstruction: 0.202033, Regularization: 0.003948, Discriminator: 0.043392; Generator: 0.021750,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:00:17,942 root         INFO     Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 0.299403\n",
      "Reconstruction: 0.229630, Regularization: 0.004459, Discriminator: 0.043559; Generator: 0.021755,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 23:00:18,043 root         INFO     Train Epoch: 71 [1536/8000 (19%)]\tTotal Loss: 0.202064\n",
      "Reconstruction: 0.135116, Regularization: 0.001763, Discriminator: 0.043425; Generator: 0.021761,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 23:00:18,144 root         INFO     Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 0.260391\n",
      "Reconstruction: 0.191553, Regularization: 0.003656, Discriminator: 0.043434; Generator: 0.021748,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:00:18,246 root         INFO     Train Epoch: 71 [2560/8000 (32%)]\tTotal Loss: 0.218240\n",
      "Reconstruction: 0.150943, Regularization: 0.002225, Discriminator: 0.043319; Generator: 0.021754,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:18,347 root         INFO     Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 0.258138\n",
      "Reconstruction: 0.189573, Regularization: 0.003331, Discriminator: 0.043482; Generator: 0.021751,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 23:00:18,447 root         INFO     Train Epoch: 71 [3584/8000 (45%)]\tTotal Loss: 0.278074\n",
      "Reconstruction: 0.208700, Regularization: 0.004183, Discriminator: 0.043449; Generator: 0.021741,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:00:18,548 root         INFO     Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 0.208136\n",
      "Reconstruction: 0.141135, Regularization: 0.001863, Discriminator: 0.043382; Generator: 0.021755,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 23:00:18,650 root         INFO     Train Epoch: 71 [4608/8000 (58%)]\tTotal Loss: 0.291274\n",
      "Reconstruction: 0.221999, Regularization: 0.004177, Discriminator: 0.043346; Generator: 0.021751,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:00:18,752 root         INFO     Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 0.229907\n",
      "Reconstruction: 0.162065, Regularization: 0.002684, Discriminator: 0.043406; Generator: 0.021752,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:00:18,853 root         INFO     Train Epoch: 71 [5632/8000 (70%)]\tTotal Loss: 0.229297\n",
      "Reconstruction: 0.161428, Regularization: 0.002726, Discriminator: 0.043396; Generator: 0.021747,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:00:18,953 root         INFO     Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 0.283013\n",
      "Reconstruction: 0.213472, Regularization: 0.004325, Discriminator: 0.043472; Generator: 0.021745,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 23:00:19,054 root         INFO     Train Epoch: 71 [6656/8000 (83%)]\tTotal Loss: 0.231137\n",
      "Reconstruction: 0.163305, Regularization: 0.002691, Discriminator: 0.043381; Generator: 0.021760,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 23:00:19,155 root         INFO     Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 0.304572\n",
      "Reconstruction: 0.234892, Regularization: 0.004540, Discriminator: 0.043396; Generator: 0.021743,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:00:19,256 root         INFO     Train Epoch: 71 [7680/8000 (96%)]\tTotal Loss: 0.227122\n",
      "Reconstruction: 0.159423, Regularization: 0.002639, Discriminator: 0.043310; Generator: 0.021750,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:19,331 root         INFO     ====> Epoch: 71 Average loss: 0.2462\n",
      "2019-04-09 23:00:19,357 root         INFO     Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 0.238621\n",
      "Reconstruction: 0.170780, Regularization: 0.002706, Discriminator: 0.043382; Generator: 0.021754,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:00:19,458 root         INFO     Train Epoch: 72 [512/8000 (6%)]\tTotal Loss: 0.270532\n",
      "Reconstruction: 0.201954, Regularization: 0.003423, Discriminator: 0.043406; Generator: 0.021749,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:00:19,558 root         INFO     Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 0.266562\n",
      "Reconstruction: 0.197549, Regularization: 0.003908, Discriminator: 0.043351; Generator: 0.021754,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:00:19,658 root         INFO     Train Epoch: 72 [1536/8000 (19%)]\tTotal Loss: 0.230503\n",
      "Reconstruction: 0.162580, Regularization: 0.002816, Discriminator: 0.043349; Generator: 0.021758,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 23:00:19,758 root         INFO     Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 0.241726\n",
      "Reconstruction: 0.173771, Regularization: 0.002867, Discriminator: 0.043330; Generator: 0.021758,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 23:00:19,858 root         INFO     Train Epoch: 72 [2560/8000 (32%)]\tTotal Loss: 0.241765\n",
      "Reconstruction: 0.173647, Regularization: 0.003015, Discriminator: 0.043352; Generator: 0.021751,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:00:19,958 root         INFO     Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 0.257545\n",
      "Reconstruction: 0.188977, Regularization: 0.003491, Discriminator: 0.043332; Generator: 0.021746,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:00:20,058 root         INFO     Train Epoch: 72 [3584/8000 (45%)]\tTotal Loss: 0.259995\n",
      "Reconstruction: 0.191444, Regularization: 0.003427, Discriminator: 0.043384; Generator: 0.021739,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:00:20,158 root         INFO     Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 0.275458\n",
      "Reconstruction: 0.206301, Regularization: 0.004057, Discriminator: 0.043349; Generator: 0.021751,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:00:20,258 root         INFO     Train Epoch: 72 [4608/8000 (58%)]\tTotal Loss: 0.236988\n",
      "Reconstruction: 0.168926, Regularization: 0.002990, Discriminator: 0.043335; Generator: 0.021737,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:20,358 root         INFO     Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 0.248979\n",
      "Reconstruction: 0.180570, Regularization: 0.003366, Discriminator: 0.043308; Generator: 0.021735,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:20,459 root         INFO     Train Epoch: 72 [5632/8000 (70%)]\tTotal Loss: 0.267143\n",
      "Reconstruction: 0.198456, Regularization: 0.003645, Discriminator: 0.043301; Generator: 0.021741,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:20,559 root         INFO     Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 0.250410\n",
      "Reconstruction: 0.182072, Regularization: 0.003287, Discriminator: 0.043317; Generator: 0.021734,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:20,659 root         INFO     Train Epoch: 72 [6656/8000 (83%)]\tTotal Loss: 0.254880\n",
      "Reconstruction: 0.186589, Regularization: 0.003258, Discriminator: 0.043308; Generator: 0.021724,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:20,759 root         INFO     Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 0.248191\n",
      "Reconstruction: 0.180037, Regularization: 0.003113, Discriminator: 0.043312; Generator: 0.021729,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:20,858 root         INFO     Train Epoch: 72 [7680/8000 (96%)]\tTotal Loss: 0.207869\n",
      "Reconstruction: 0.140735, Regularization: 0.002077, Discriminator: 0.043318; Generator: 0.021740,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:20,933 root         INFO     ====> Epoch: 72 Average loss: 0.2464\n",
      "2019-04-09 23:00:20,959 root         INFO     Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 0.232001\n",
      "Reconstruction: 0.164303, Regularization: 0.002652, Discriminator: 0.043305; Generator: 0.021741,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:21,059 root         INFO     Train Epoch: 73 [512/8000 (6%)]\tTotal Loss: 0.255695\n",
      "Reconstruction: 0.186941, Regularization: 0.003626, Discriminator: 0.043368; Generator: 0.021760,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 23:00:21,160 root         INFO     Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 0.222104\n",
      "Reconstruction: 0.154830, Regularization: 0.002241, Discriminator: 0.043283; Generator: 0.021750,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:21,260 root         INFO     Train Epoch: 73 [1536/8000 (19%)]\tTotal Loss: 0.275604\n",
      "Reconstruction: 0.206447, Regularization: 0.004082, Discriminator: 0.043326; Generator: 0.021750,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:21,360 root         INFO     Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 0.262936\n",
      "Reconstruction: 0.194240, Regularization: 0.003676, Discriminator: 0.043272; Generator: 0.021748,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:21,460 root         INFO     Train Epoch: 73 [2560/8000 (32%)]\tTotal Loss: 0.228186\n",
      "Reconstruction: 0.160328, Regularization: 0.002876, Discriminator: 0.043247; Generator: 0.021735,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:00:21,560 root         INFO     Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 0.235049\n",
      "Reconstruction: 0.167131, Regularization: 0.002959, Discriminator: 0.043213; Generator: 0.021746,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:00:21,659 root         INFO     Train Epoch: 73 [3584/8000 (45%)]\tTotal Loss: 0.287252\n",
      "Reconstruction: 0.217541, Regularization: 0.004643, Discriminator: 0.043323; Generator: 0.021745,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:21,758 root         INFO     Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 0.253410\n",
      "Reconstruction: 0.184779, Regularization: 0.003569, Discriminator: 0.043308; Generator: 0.021754,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:21,858 root         INFO     Train Epoch: 73 [4608/8000 (58%)]\tTotal Loss: 0.231509\n",
      "Reconstruction: 0.163796, Regularization: 0.002692, Discriminator: 0.043282; Generator: 0.021739,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:21,957 root         INFO     Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 0.215456\n",
      "Reconstruction: 0.148268, Regularization: 0.002167, Discriminator: 0.043287; Generator: 0.021733,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:22,056 root         INFO     Train Epoch: 73 [5632/8000 (70%)]\tTotal Loss: 0.273903\n",
      "Reconstruction: 0.204767, Regularization: 0.004049, Discriminator: 0.043339; Generator: 0.021749,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:00:22,152 root         INFO     Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 0.236947\n",
      "Reconstruction: 0.168968, Regularization: 0.002996, Discriminator: 0.043216; Generator: 0.021767,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 23:00:22,248 root         INFO     Train Epoch: 73 [6656/8000 (83%)]\tTotal Loss: 0.272838\n",
      "Reconstruction: 0.203682, Regularization: 0.004024, Discriminator: 0.043383; Generator: 0.021749,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:00:22,344 root         INFO     Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 0.225711\n",
      "Reconstruction: 0.158154, Regularization: 0.002613, Discriminator: 0.043183; Generator: 0.021760,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 23:00:22,440 root         INFO     Train Epoch: 73 [7680/8000 (96%)]\tTotal Loss: 0.230249\n",
      "Reconstruction: 0.162243, Regularization: 0.002771, Discriminator: 0.043452; Generator: 0.021783,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 23:00:22,513 root         INFO     ====> Epoch: 73 Average loss: 0.2465\n",
      "2019-04-09 23:00:22,539 root         INFO     Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 0.282733\n",
      "Reconstruction: 0.213350, Regularization: 0.004454, Discriminator: 0.043173; Generator: 0.021757,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 23:00:22,639 root         INFO     Train Epoch: 74 [512/8000 (6%)]\tTotal Loss: 0.236045\n",
      "Reconstruction: 0.168280, Regularization: 0.002728, Discriminator: 0.043274; Generator: 0.021762,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 23:00:22,741 root         INFO     Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 0.221497\n",
      "Reconstruction: 0.154286, Regularization: 0.002330, Discriminator: 0.043113; Generator: 0.021768,\n",
      "D(x): 0.502, D(G(z)): 0.498\n",
      "2019-04-09 23:00:22,841 root         INFO     Train Epoch: 74 [1536/8000 (19%)]\tTotal Loss: 0.268730\n",
      "Reconstruction: 0.199603, Regularization: 0.004019, Discriminator: 0.043339; Generator: 0.021769,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 23:00:22,941 root         INFO     Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 0.238014\n",
      "Reconstruction: 0.170303, Regularization: 0.002808, Discriminator: 0.043135; Generator: 0.021768,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 23:00:23,041 root         INFO     Train Epoch: 74 [2560/8000 (32%)]\tTotal Loss: 0.248988\n",
      "Reconstruction: 0.180607, Regularization: 0.003145, Discriminator: 0.043458; Generator: 0.021778,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 23:00:23,140 root         INFO     Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 0.263853\n",
      "Reconstruction: 0.195230, Regularization: 0.003640, Discriminator: 0.043205; Generator: 0.021778,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 23:00:23,239 root         INFO     Train Epoch: 74 [3584/8000 (45%)]\tTotal Loss: 0.218499\n",
      "Reconstruction: 0.150783, Regularization: 0.002463, Discriminator: 0.043485; Generator: 0.021768,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 23:00:23,339 root         INFO     Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 0.267050\n",
      "Reconstruction: 0.198004, Regularization: 0.004044, Discriminator: 0.043261; Generator: 0.021741,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 23:00:23,438 root         INFO     Train Epoch: 74 [4608/8000 (58%)]\tTotal Loss: 0.301736\n",
      "Reconstruction: 0.232043, Regularization: 0.004789, Discriminator: 0.043157; Generator: 0.021747,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:00:23,537 root         INFO     Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 0.279576\n",
      "Reconstruction: 0.210242, Regularization: 0.004171, Discriminator: 0.043399; Generator: 0.021763,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 23:00:23,635 root         INFO     Train Epoch: 74 [5632/8000 (70%)]\tTotal Loss: 0.296136\n",
      "Reconstruction: 0.226231, Regularization: 0.004884, Discriminator: 0.043252; Generator: 0.021768,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 23:00:23,734 root         INFO     Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 0.250861\n",
      "Reconstruction: 0.182656, Regularization: 0.003343, Discriminator: 0.043108; Generator: 0.021754,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 23:00:23,833 root         INFO     Train Epoch: 74 [6656/8000 (83%)]\tTotal Loss: 0.225491\n",
      "Reconstruction: 0.157876, Regularization: 0.002460, Discriminator: 0.043397; Generator: 0.021758,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 23:00:23,930 root         INFO     Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 0.247454\n",
      "Reconstruction: 0.179194, Regularization: 0.003320, Discriminator: 0.043171; Generator: 0.021770,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 23:00:24,027 root         INFO     Train Epoch: 74 [7680/8000 (96%)]\tTotal Loss: 0.254328\n",
      "Reconstruction: 0.185952, Regularization: 0.003421, Discriminator: 0.043160; Generator: 0.021796,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 23:00:24,101 root         INFO     ====> Epoch: 74 Average loss: 0.2464\n",
      "2019-04-09 23:00:24,128 root         INFO     Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 0.255593\n",
      "Reconstruction: 0.187479, Regularization: 0.003234, Discriminator: 0.043111; Generator: 0.021769,\n",
      "D(x): 0.502, D(G(z)): 0.498\n",
      "2019-04-09 23:00:24,229 root         INFO     Train Epoch: 75 [512/8000 (6%)]\tTotal Loss: 0.249122\n",
      "Reconstruction: 0.180440, Regularization: 0.003481, Discriminator: 0.043437; Generator: 0.021764,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 23:00:24,328 root         INFO     Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 0.265428\n",
      "Reconstruction: 0.196800, Regularization: 0.003585, Discriminator: 0.043278; Generator: 0.021765,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 23:00:24,426 root         INFO     Train Epoch: 75 [1536/8000 (19%)]\tTotal Loss: 0.260880\n",
      "Reconstruction: 0.192444, Regularization: 0.003640, Discriminator: 0.043025; Generator: 0.021771,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 23:00:24,524 root         INFO     Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 0.208898\n",
      "Reconstruction: 0.141890, Regularization: 0.001887, Discriminator: 0.043334; Generator: 0.021787,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 23:00:24,623 root         INFO     Train Epoch: 75 [2560/8000 (32%)]\tTotal Loss: 0.243377\n",
      "Reconstruction: 0.175521, Regularization: 0.002880, Discriminator: 0.043195; Generator: 0.021781,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 23:00:24,720 root         INFO     Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 0.224090\n",
      "Reconstruction: 0.156812, Regularization: 0.002651, Discriminator: 0.042871; Generator: 0.021755,\n",
      "D(x): 0.506, D(G(z)): 0.498\n",
      "2019-04-09 23:00:24,817 root         INFO     Train Epoch: 75 [3584/8000 (45%)]\tTotal Loss: 0.243364\n",
      "Reconstruction: 0.175541, Regularization: 0.003057, Discriminator: 0.043005; Generator: 0.021761,\n",
      "D(x): 0.504, D(G(z)): 0.498\n",
      "2019-04-09 23:00:24,914 root         INFO     Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 0.229030\n",
      "Reconstruction: 0.161058, Regularization: 0.002710, Discriminator: 0.043501; Generator: 0.021761,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 23:00:25,011 root         INFO     Train Epoch: 75 [4608/8000 (58%)]\tTotal Loss: 0.253797\n",
      "Reconstruction: 0.185260, Regularization: 0.003366, Discriminator: 0.043419; Generator: 0.021751,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 23:00:25,107 root         INFO     Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 0.258666\n",
      "Reconstruction: 0.190193, Regularization: 0.003729, Discriminator: 0.043007; Generator: 0.021736,\n",
      "D(x): 0.504, D(G(z)): 0.499\n",
      "2019-04-09 23:00:25,204 root         INFO     Train Epoch: 75 [5632/8000 (70%)]\tTotal Loss: 0.283907\n",
      "Reconstruction: 0.214842, Regularization: 0.003915, Discriminator: 0.043361; Generator: 0.021789,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 23:00:25,301 root         INFO     Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 0.262871\n",
      "Reconstruction: 0.194576, Regularization: 0.003368, Discriminator: 0.043159; Generator: 0.021767,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 23:00:25,397 root         INFO     Train Epoch: 75 [6656/8000 (83%)]\tTotal Loss: 0.264448\n",
      "Reconstruction: 0.195289, Regularization: 0.003557, Discriminator: 0.043816; Generator: 0.021786,\n",
      "D(x): 0.491, D(G(z)): 0.498\n",
      "2019-04-09 23:00:25,494 root         INFO     Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 0.261747\n",
      "Reconstruction: 0.193309, Regularization: 0.003490, Discriminator: 0.043212; Generator: 0.021736,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:00:25,590 root         INFO     Train Epoch: 75 [7680/8000 (96%)]\tTotal Loss: 0.238162\n",
      "Reconstruction: 0.170081, Regularization: 0.003123, Discriminator: 0.043197; Generator: 0.021761,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 23:00:25,664 root         INFO     ====> Epoch: 75 Average loss: 0.2455\n",
      "2019-04-09 23:00:25,691 root         INFO     Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 0.214720\n",
      "Reconstruction: 0.147351, Regularization: 0.002260, Discriminator: 0.043358; Generator: 0.021751,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:00:25,790 root         INFO     Train Epoch: 76 [512/8000 (6%)]\tTotal Loss: 0.221703\n",
      "Reconstruction: 0.154604, Regularization: 0.002157, Discriminator: 0.043172; Generator: 0.021770,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 23:00:25,890 root         INFO     Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 0.283404\n",
      "Reconstruction: 0.214520, Regularization: 0.004031, Discriminator: 0.043103; Generator: 0.021749,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 23:00:25,990 root         INFO     Train Epoch: 76 [1536/8000 (19%)]\tTotal Loss: 0.233448\n",
      "Reconstruction: 0.165853, Regularization: 0.003047, Discriminator: 0.042771; Generator: 0.021776,\n",
      "D(x): 0.507, D(G(z)): 0.498\n",
      "2019-04-09 23:00:26,089 root         INFO     Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 0.244349\n",
      "Reconstruction: 0.176169, Regularization: 0.003256, Discriminator: 0.043177; Generator: 0.021748,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:00:26,189 root         INFO     Train Epoch: 76 [2560/8000 (32%)]\tTotal Loss: 0.293021\n",
      "Reconstruction: 0.223945, Regularization: 0.004151, Discriminator: 0.043184; Generator: 0.021741,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:00:26,288 root         INFO     Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 0.212961\n",
      "Reconstruction: 0.146151, Regularization: 0.001983, Discriminator: 0.043080; Generator: 0.021748,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 23:00:26,388 root         INFO     Train Epoch: 76 [3584/8000 (45%)]\tTotal Loss: 0.317541\n",
      "Reconstruction: 0.247157, Regularization: 0.004944, Discriminator: 0.043697; Generator: 0.021744,\n",
      "D(x): 0.493, D(G(z)): 0.499\n",
      "2019-04-09 23:00:26,488 root         INFO     Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 0.237348\n",
      "Reconstruction: 0.169694, Regularization: 0.002720, Discriminator: 0.043141; Generator: 0.021793,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 23:00:26,587 root         INFO     Train Epoch: 76 [4608/8000 (58%)]\tTotal Loss: 0.229431\n",
      "Reconstruction: 0.162174, Regularization: 0.002156, Discriminator: 0.043309; Generator: 0.021792,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 23:00:26,685 root         INFO     Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 0.237800\n",
      "Reconstruction: 0.170613, Regularization: 0.002364, Discriminator: 0.043008; Generator: 0.021815,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 23:00:26,783 root         INFO     Train Epoch: 76 [5632/8000 (70%)]\tTotal Loss: 0.256188\n",
      "Reconstruction: 0.187877, Regularization: 0.003400, Discriminator: 0.043138; Generator: 0.021774,\n",
      "D(x): 0.502, D(G(z)): 0.498\n",
      "2019-04-09 23:00:26,881 root         INFO     Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 0.298675\n",
      "Reconstruction: 0.229334, Regularization: 0.004721, Discriminator: 0.042885; Generator: 0.021734,\n",
      "D(x): 0.507, D(G(z)): 0.499\n",
      "2019-04-09 23:00:26,980 root         INFO     Train Epoch: 76 [6656/8000 (83%)]\tTotal Loss: 0.257989\n",
      "Reconstruction: 0.189276, Regularization: 0.003590, Discriminator: 0.043400; Generator: 0.021723,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 23:00:27,078 root         INFO     Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 0.232860\n",
      "Reconstruction: 0.164788, Regularization: 0.002269, Discriminator: 0.044065; Generator: 0.021739,\n",
      "D(x): 0.487, D(G(z)): 0.499\n",
      "2019-04-09 23:00:27,177 root         INFO     Train Epoch: 76 [7680/8000 (96%)]\tTotal Loss: 0.235682\n",
      "Reconstruction: 0.168142, Regularization: 0.002752, Discriminator: 0.043095; Generator: 0.021693,\n",
      "D(x): 0.504, D(G(z)): 0.499\n",
      "2019-04-09 23:00:27,250 root         INFO     ====> Epoch: 76 Average loss: 0.2451\n",
      "2019-04-09 23:00:27,276 root         INFO     Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 0.293022\n",
      "Reconstruction: 0.224054, Regularization: 0.004015, Discriminator: 0.043282; Generator: 0.021672,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:27,376 root         INFO     Train Epoch: 77 [512/8000 (6%)]\tTotal Loss: 0.219995\n",
      "Reconstruction: 0.152719, Regularization: 0.002050, Discriminator: 0.043543; Generator: 0.021682,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 23:00:27,475 root         INFO     Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 0.188450\n",
      "Reconstruction: 0.121930, Regularization: 0.001189, Discriminator: 0.043652; Generator: 0.021679,\n",
      "D(x): 0.495, D(G(z)): 0.500\n",
      "2019-04-09 23:00:27,575 root         INFO     Train Epoch: 77 [1536/8000 (19%)]\tTotal Loss: 0.227155\n",
      "Reconstruction: 0.160074, Regularization: 0.002192, Discriminator: 0.043193; Generator: 0.021696,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 23:00:27,674 root         INFO     Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 0.206981\n",
      "Reconstruction: 0.139949, Regularization: 0.001960, Discriminator: 0.043413; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:27,773 root         INFO     Train Epoch: 77 [2560/8000 (32%)]\tTotal Loss: 0.230951\n",
      "Reconstruction: 0.163650, Regularization: 0.002384, Discriminator: 0.043251; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:27,872 root         INFO     Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 0.189558\n",
      "Reconstruction: 0.122895, Regularization: 0.001529, Discriminator: 0.043442; Generator: 0.021691,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:00:27,969 root         INFO     Train Epoch: 77 [3584/8000 (45%)]\tTotal Loss: 0.253267\n",
      "Reconstruction: 0.185098, Regularization: 0.003130, Discriminator: 0.043361; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:28,068 root         INFO     Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 0.229612\n",
      "Reconstruction: 0.162512, Regularization: 0.002033, Discriminator: 0.043297; Generator: 0.021770,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 23:00:28,167 root         INFO     Train Epoch: 77 [4608/8000 (58%)]\tTotal Loss: 0.242032\n",
      "Reconstruction: 0.174586, Regularization: 0.002485, Discriminator: 0.043215; Generator: 0.021747,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 23:00:28,267 root         INFO     Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 0.231401\n",
      "Reconstruction: 0.163384, Regularization: 0.002671, Discriminator: 0.043588; Generator: 0.021758,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 23:00:28,366 root         INFO     Train Epoch: 77 [5632/8000 (70%)]\tTotal Loss: 0.198785\n",
      "Reconstruction: 0.132315, Regularization: 0.001391, Discriminator: 0.043316; Generator: 0.021763,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 23:00:28,467 root         INFO     Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 0.193364\n",
      "Reconstruction: 0.127057, Regularization: 0.001222, Discriminator: 0.043373; Generator: 0.021712,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:28,566 root         INFO     Train Epoch: 77 [6656/8000 (83%)]\tTotal Loss: 0.281358\n",
      "Reconstruction: 0.212704, Regularization: 0.003679, Discriminator: 0.043302; Generator: 0.021673,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:28,666 root         INFO     Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 0.263611\n",
      "Reconstruction: 0.195102, Regularization: 0.003893, Discriminator: 0.042948; Generator: 0.021668,\n",
      "D(x): 0.507, D(G(z)): 0.500\n",
      "2019-04-09 23:00:28,766 root         INFO     Train Epoch: 77 [7680/8000 (96%)]\tTotal Loss: 0.207082\n",
      "Reconstruction: 0.140484, Regularization: 0.001838, Discriminator: 0.043151; Generator: 0.021609,\n",
      "D(x): 0.504, D(G(z)): 0.501\n",
      "2019-04-09 23:00:28,840 root         INFO     ====> Epoch: 77 Average loss: 0.2444\n",
      "2019-04-09 23:00:28,867 root         INFO     Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 0.231556\n",
      "Reconstruction: 0.163785, Regularization: 0.002507, Discriminator: 0.043613; Generator: 0.021651,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 23:00:28,967 root         INFO     Train Epoch: 78 [512/8000 (6%)]\tTotal Loss: 0.212098\n",
      "Reconstruction: 0.145052, Regularization: 0.001875, Discriminator: 0.043532; Generator: 0.021638,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:00:29,067 root         INFO     Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 0.240328\n",
      "Reconstruction: 0.172353, Regularization: 0.002920, Discriminator: 0.043362; Generator: 0.021693,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 23:00:29,166 root         INFO     Train Epoch: 78 [1536/8000 (19%)]\tTotal Loss: 0.250659\n",
      "Reconstruction: 0.182879, Regularization: 0.003368, Discriminator: 0.042733; Generator: 0.021679,\n",
      "D(x): 0.510, D(G(z)): 0.500\n",
      "2019-04-09 23:00:29,263 root         INFO     Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 0.251188\n",
      "Reconstruction: 0.183729, Regularization: 0.002946, Discriminator: 0.042807; Generator: 0.021706,\n",
      "D(x): 0.508, D(G(z)): 0.499\n",
      "2019-04-09 23:00:29,361 root         INFO     Train Epoch: 78 [2560/8000 (32%)]\tTotal Loss: 0.218348\n",
      "Reconstruction: 0.151556, Regularization: 0.002072, Discriminator: 0.043090; Generator: 0.021630,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 23:00:29,459 root         INFO     Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 0.297601\n",
      "Reconstruction: 0.228773, Regularization: 0.003907, Discriminator: 0.043258; Generator: 0.021664,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:00:29,558 root         INFO     Train Epoch: 78 [3584/8000 (45%)]\tTotal Loss: 0.240947\n",
      "Reconstruction: 0.173602, Regularization: 0.002637, Discriminator: 0.043009; Generator: 0.021698,\n",
      "D(x): 0.505, D(G(z)): 0.499\n",
      "2019-04-09 23:00:29,656 root         INFO     Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 0.221606\n",
      "Reconstruction: 0.153774, Regularization: 0.002140, Discriminator: 0.043992; Generator: 0.021700,\n",
      "D(x): 0.489, D(G(z)): 0.499\n",
      "2019-04-09 23:00:29,755 root         INFO     Train Epoch: 78 [4608/8000 (58%)]\tTotal Loss: 0.272052\n",
      "Reconstruction: 0.203848, Regularization: 0.003232, Discriminator: 0.043322; Generator: 0.021650,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:29,853 root         INFO     Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 0.195790\n",
      "Reconstruction: 0.129405, Regularization: 0.001377, Discriminator: 0.043327; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:29,951 root         INFO     Train Epoch: 78 [5632/8000 (70%)]\tTotal Loss: 0.282332\n",
      "Reconstruction: 0.213714, Regularization: 0.003612, Discriminator: 0.043360; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:30,050 root         INFO     Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 0.227217\n",
      "Reconstruction: 0.160211, Regularization: 0.002186, Discriminator: 0.043188; Generator: 0.021632,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:00:30,148 root         INFO     Train Epoch: 78 [6656/8000 (83%)]\tTotal Loss: 0.286423\n",
      "Reconstruction: 0.217791, Regularization: 0.003707, Discriminator: 0.043289; Generator: 0.021636,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:00:30,246 root         INFO     Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 0.206620\n",
      "Reconstruction: 0.140143, Regularization: 0.001805, Discriminator: 0.043080; Generator: 0.021591,\n",
      "D(x): 0.505, D(G(z)): 0.501\n",
      "2019-04-09 23:00:30,344 root         INFO     Train Epoch: 78 [7680/8000 (96%)]\tTotal Loss: 0.244492\n",
      "Reconstruction: 0.177199, Regularization: 0.002416, Discriminator: 0.043256; Generator: 0.021621,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 23:00:30,418 root         INFO     ====> Epoch: 78 Average loss: 0.2443\n",
      "2019-04-09 23:00:30,445 root         INFO     Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 0.263008\n",
      "Reconstruction: 0.195359, Regularization: 0.002763, Discriminator: 0.043268; Generator: 0.021618,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 23:00:30,548 root         INFO     Train Epoch: 79 [512/8000 (6%)]\tTotal Loss: 0.262101\n",
      "Reconstruction: 0.194416, Regularization: 0.002852, Discriminator: 0.043251; Generator: 0.021582,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 23:00:30,649 root         INFO     Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 0.232348\n",
      "Reconstruction: 0.165222, Regularization: 0.002072, Discriminator: 0.043484; Generator: 0.021570,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:00:30,750 root         INFO     Train Epoch: 79 [1536/8000 (19%)]\tTotal Loss: 0.274859\n",
      "Reconstruction: 0.206214, Regularization: 0.003451, Discriminator: 0.043557; Generator: 0.021637,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:00:30,850 root         INFO     Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 0.250490\n",
      "Reconstruction: 0.182622, Regularization: 0.002794, Discriminator: 0.043446; Generator: 0.021628,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:00:30,949 root         INFO     Train Epoch: 79 [2560/8000 (32%)]\tTotal Loss: 0.204058\n",
      "Reconstruction: 0.137339, Regularization: 0.001605, Discriminator: 0.043491; Generator: 0.021623,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 23:00:31,047 root         INFO     Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 0.222653\n",
      "Reconstruction: 0.155993, Regularization: 0.001681, Discriminator: 0.043346; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:31,145 root         INFO     Train Epoch: 79 [3584/8000 (45%)]\tTotal Loss: 0.267862\n",
      "Reconstruction: 0.199600, Regularization: 0.003153, Discriminator: 0.043495; Generator: 0.021614,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 23:00:31,244 root         INFO     Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 0.275471\n",
      "Reconstruction: 0.206691, Regularization: 0.003438, Discriminator: 0.043688; Generator: 0.021654,\n",
      "D(x): 0.495, D(G(z)): 0.500\n",
      "2019-04-09 23:00:31,343 root         INFO     Train Epoch: 79 [4608/8000 (58%)]\tTotal Loss: 0.236331\n",
      "Reconstruction: 0.169119, Regularization: 0.002286, Discriminator: 0.043300; Generator: 0.021625,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:00:31,442 root         INFO     Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 0.253263\n",
      "Reconstruction: 0.185513, Regularization: 0.002427, Discriminator: 0.043713; Generator: 0.021610,\n",
      "D(x): 0.495, D(G(z)): 0.501\n",
      "2019-04-09 23:00:31,541 root         INFO     Train Epoch: 79 [5632/8000 (70%)]\tTotal Loss: 0.276877\n",
      "Reconstruction: 0.208488, Regularization: 0.003186, Discriminator: 0.043596; Generator: 0.021607,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 23:00:31,639 root         INFO     Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 0.211786\n",
      "Reconstruction: 0.145240, Regularization: 0.001605, Discriminator: 0.043298; Generator: 0.021643,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:31,738 root         INFO     Train Epoch: 79 [6656/8000 (83%)]\tTotal Loss: 0.216545\n",
      "Reconstruction: 0.149518, Regularization: 0.001939, Discriminator: 0.043490; Generator: 0.021598,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:00:31,836 root         INFO     Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 0.239299\n",
      "Reconstruction: 0.171966, Regularization: 0.002241, Discriminator: 0.043447; Generator: 0.021646,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:00:31,935 root         INFO     Train Epoch: 79 [7680/8000 (96%)]\tTotal Loss: 0.237565\n",
      "Reconstruction: 0.170414, Regularization: 0.002149, Discriminator: 0.043401; Generator: 0.021601,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:00:32,009 root         INFO     ====> Epoch: 79 Average loss: 0.2446\n",
      "2019-04-09 23:00:32,035 root         INFO     Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 0.249542\n",
      "Reconstruction: 0.181905, Regularization: 0.002402, Discriminator: 0.043582; Generator: 0.021652,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 23:00:32,137 root         INFO     Train Epoch: 80 [512/8000 (6%)]\tTotal Loss: 0.224268\n",
      "Reconstruction: 0.157418, Regularization: 0.001643, Discriminator: 0.043591; Generator: 0.021615,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 23:00:32,238 root         INFO     Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 0.300386\n",
      "Reconstruction: 0.231938, Regularization: 0.003549, Discriminator: 0.043291; Generator: 0.021608,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 23:00:32,336 root         INFO     Train Epoch: 80 [1536/8000 (19%)]\tTotal Loss: 0.284530\n",
      "Reconstruction: 0.216415, Regularization: 0.003291, Discriminator: 0.043194; Generator: 0.021630,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:00:32,435 root         INFO     Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 0.206874\n",
      "Reconstruction: 0.140433, Regularization: 0.001545, Discriminator: 0.043303; Generator: 0.021592,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 23:00:32,532 root         INFO     Train Epoch: 80 [2560/8000 (32%)]\tTotal Loss: 0.260144\n",
      "Reconstruction: 0.192161, Regularization: 0.003031, Discriminator: 0.043321; Generator: 0.021631,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:32,632 root         INFO     Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 0.249308\n",
      "Reconstruction: 0.181855, Regularization: 0.002538, Discriminator: 0.043322; Generator: 0.021593,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:00:32,732 root         INFO     Train Epoch: 80 [3584/8000 (45%)]\tTotal Loss: 0.218272\n",
      "Reconstruction: 0.151335, Regularization: 0.002030, Discriminator: 0.043306; Generator: 0.021600,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:00:32,832 root         INFO     Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 0.233591\n",
      "Reconstruction: 0.166588, Regularization: 0.001974, Discriminator: 0.043412; Generator: 0.021618,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:00:32,931 root         INFO     Train Epoch: 80 [4608/8000 (58%)]\tTotal Loss: 0.219951\n",
      "Reconstruction: 0.152844, Regularization: 0.001899, Discriminator: 0.043617; Generator: 0.021592,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 23:00:33,030 root         INFO     Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 0.237721\n",
      "Reconstruction: 0.170363, Regularization: 0.002299, Discriminator: 0.043451; Generator: 0.021609,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:00:33,129 root         INFO     Train Epoch: 80 [5632/8000 (70%)]\tTotal Loss: 0.210033\n",
      "Reconstruction: 0.143797, Regularization: 0.001399, Discriminator: 0.043217; Generator: 0.021621,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 23:00:33,229 root         INFO     Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 0.204233\n",
      "Reconstruction: 0.137898, Regularization: 0.001305, Discriminator: 0.043421; Generator: 0.021610,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:00:33,328 root         INFO     Train Epoch: 80 [6656/8000 (83%)]\tTotal Loss: 0.258907\n",
      "Reconstruction: 0.191271, Regularization: 0.002603, Discriminator: 0.043421; Generator: 0.021611,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:00:33,427 root         INFO     Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 0.231673\n",
      "Reconstruction: 0.164963, Regularization: 0.002021, Discriminator: 0.043090; Generator: 0.021599,\n",
      "D(x): 0.505, D(G(z)): 0.501\n",
      "2019-04-09 23:00:33,524 root         INFO     Train Epoch: 80 [7680/8000 (96%)]\tTotal Loss: 0.225161\n",
      "Reconstruction: 0.158616, Regularization: 0.001829, Discriminator: 0.043097; Generator: 0.021619,\n",
      "D(x): 0.504, D(G(z)): 0.501\n",
      "2019-04-09 23:00:33,597 root         INFO     ====> Epoch: 80 Average loss: 0.2446\n",
      "2019-04-09 23:00:33,624 root         INFO     Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 0.218072\n",
      "Reconstruction: 0.151582, Regularization: 0.001503, Discriminator: 0.043377; Generator: 0.021610,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:00:33,725 root         INFO     Train Epoch: 81 [512/8000 (6%)]\tTotal Loss: 0.202173\n",
      "Reconstruction: 0.135818, Regularization: 0.001473, Discriminator: 0.043268; Generator: 0.021614,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 23:00:33,825 root         INFO     Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 0.265226\n",
      "Reconstruction: 0.197515, Regularization: 0.002544, Discriminator: 0.043534; Generator: 0.021633,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:00:33,925 root         INFO     Train Epoch: 81 [1536/8000 (19%)]\tTotal Loss: 0.204810\n",
      "Reconstruction: 0.138065, Regularization: 0.001685, Discriminator: 0.043436; Generator: 0.021625,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:00:34,024 root         INFO     Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 0.274031\n",
      "Reconstruction: 0.206091, Regularization: 0.002772, Discriminator: 0.043552; Generator: 0.021617,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 23:00:34,124 root         INFO     Train Epoch: 81 [2560/8000 (32%)]\tTotal Loss: 0.286638\n",
      "Reconstruction: 0.218449, Regularization: 0.003289, Discriminator: 0.043325; Generator: 0.021575,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:00:34,224 root         INFO     Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 0.238396\n",
      "Reconstruction: 0.171626, Regularization: 0.001759, Discriminator: 0.043416; Generator: 0.021595,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:00:34,322 root         INFO     Train Epoch: 81 [3584/8000 (45%)]\tTotal Loss: 0.297395\n",
      "Reconstruction: 0.228625, Regularization: 0.003897, Discriminator: 0.043278; Generator: 0.021595,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 23:00:34,420 root         INFO     Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 0.312701\n",
      "Reconstruction: 0.244244, Regularization: 0.003412, Discriminator: 0.043436; Generator: 0.021608,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:00:34,518 root         INFO     Train Epoch: 81 [4608/8000 (58%)]\tTotal Loss: 0.248128\n",
      "Reconstruction: 0.180747, Regularization: 0.002381, Discriminator: 0.043412; Generator: 0.021588,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:00:34,616 root         INFO     Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 0.251181\n",
      "Reconstruction: 0.184058, Regularization: 0.002180, Discriminator: 0.043335; Generator: 0.021608,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:00:34,714 root         INFO     Train Epoch: 81 [5632/8000 (70%)]\tTotal Loss: 0.207610\n",
      "Reconstruction: 0.141240, Regularization: 0.001293, Discriminator: 0.043455; Generator: 0.021621,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:00:34,811 root         INFO     Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 0.183230\n",
      "Reconstruction: 0.117291, Regularization: 0.000932, Discriminator: 0.043362; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:34,909 root         INFO     Train Epoch: 81 [6656/8000 (83%)]\tTotal Loss: 0.222862\n",
      "Reconstruction: 0.156263, Regularization: 0.001677, Discriminator: 0.043295; Generator: 0.021627,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:00:35,007 root         INFO     Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 0.264745\n",
      "Reconstruction: 0.197414, Regularization: 0.002491, Discriminator: 0.043215; Generator: 0.021625,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 23:00:35,104 root         INFO     Train Epoch: 81 [7680/8000 (96%)]\tTotal Loss: 0.279876\n",
      "Reconstruction: 0.212046, Regularization: 0.002847, Discriminator: 0.043374; Generator: 0.021609,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:00:35,178 root         INFO     ====> Epoch: 81 Average loss: 0.2451\n",
      "2019-04-09 23:00:35,204 root         INFO     Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 0.268708\n",
      "Reconstruction: 0.201040, Regularization: 0.002584, Discriminator: 0.043471; Generator: 0.021613,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 23:00:35,304 root         INFO     Train Epoch: 82 [512/8000 (6%)]\tTotal Loss: 0.292040\n",
      "Reconstruction: 0.223898, Regularization: 0.003176, Discriminator: 0.043345; Generator: 0.021622,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:00:35,404 root         INFO     Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 0.206562\n",
      "Reconstruction: 0.140293, Regularization: 0.001260, Discriminator: 0.043380; Generator: 0.021630,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:00:35,503 root         INFO     Train Epoch: 82 [1536/8000 (19%)]\tTotal Loss: 0.238324\n",
      "Reconstruction: 0.171230, Regularization: 0.002011, Discriminator: 0.043458; Generator: 0.021625,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 23:00:35,604 root         INFO     Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 0.280672\n",
      "Reconstruction: 0.212770, Regularization: 0.002983, Discriminator: 0.043310; Generator: 0.021610,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:00:35,703 root         INFO     Train Epoch: 82 [2560/8000 (32%)]\tTotal Loss: 0.299796\n",
      "Reconstruction: 0.231451, Regularization: 0.003423, Discriminator: 0.043278; Generator: 0.021644,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:35,803 root         INFO     Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 0.233242\n",
      "Reconstruction: 0.166285, Regularization: 0.001989, Discriminator: 0.043349; Generator: 0.021619,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:00:35,903 root         INFO     Train Epoch: 82 [3584/8000 (45%)]\tTotal Loss: 0.243822\n",
      "Reconstruction: 0.176585, Regularization: 0.002328, Discriminator: 0.043293; Generator: 0.021615,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:00:36,002 root         INFO     Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 0.235488\n",
      "Reconstruction: 0.168377, Regularization: 0.002134, Discriminator: 0.043357; Generator: 0.021619,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:00:36,100 root         INFO     Train Epoch: 82 [4608/8000 (58%)]\tTotal Loss: 0.238969\n",
      "Reconstruction: 0.171947, Regularization: 0.002075, Discriminator: 0.043331; Generator: 0.021615,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:00:36,198 root         INFO     Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 0.349775\n",
      "Reconstruction: 0.280227, Regularization: 0.004475, Discriminator: 0.043454; Generator: 0.021619,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 23:00:36,297 root         INFO     Train Epoch: 82 [5632/8000 (70%)]\tTotal Loss: 0.206295\n",
      "Reconstruction: 0.139853, Regularization: 0.001527, Discriminator: 0.043305; Generator: 0.021610,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:00:36,396 root         INFO     Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 0.233304\n",
      "Reconstruction: 0.166482, Regularization: 0.001849, Discriminator: 0.043350; Generator: 0.021623,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:00:36,494 root         INFO     Train Epoch: 82 [6656/8000 (83%)]\tTotal Loss: 0.266507\n",
      "Reconstruction: 0.198739, Regularization: 0.002753, Discriminator: 0.043394; Generator: 0.021620,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:00:36,593 root         INFO     Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 0.242681\n",
      "Reconstruction: 0.175561, Regularization: 0.002172, Discriminator: 0.043322; Generator: 0.021626,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:00:36,692 root         INFO     Train Epoch: 82 [7680/8000 (96%)]\tTotal Loss: 0.293793\n",
      "Reconstruction: 0.225732, Regularization: 0.003074, Discriminator: 0.043359; Generator: 0.021627,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:00:36,766 root         INFO     ====> Epoch: 82 Average loss: 0.2453\n",
      "2019-04-09 23:00:36,792 root         INFO     Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 0.242655\n",
      "Reconstruction: 0.176097, Regularization: 0.001590, Discriminator: 0.043339; Generator: 0.021629,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:00:36,894 root         INFO     Train Epoch: 83 [512/8000 (6%)]\tTotal Loss: 0.248224\n",
      "Reconstruction: 0.181050, Regularization: 0.002259, Discriminator: 0.043298; Generator: 0.021617,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:00:36,996 root         INFO     Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 0.221341\n",
      "Reconstruction: 0.154545, Regularization: 0.001863, Discriminator: 0.043306; Generator: 0.021626,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:00:37,097 root         INFO     Train Epoch: 83 [1536/8000 (19%)]\tTotal Loss: 0.201357\n",
      "Reconstruction: 0.135137, Regularization: 0.001214, Discriminator: 0.043362; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:37,198 root         INFO     Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 0.254812\n",
      "Reconstruction: 0.187517, Regularization: 0.002331, Discriminator: 0.043315; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:37,298 root         INFO     Train Epoch: 83 [2560/8000 (32%)]\tTotal Loss: 0.221260\n",
      "Reconstruction: 0.154659, Regularization: 0.001631, Discriminator: 0.043332; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:37,399 root         INFO     Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 0.265998\n",
      "Reconstruction: 0.198602, Regularization: 0.002454, Discriminator: 0.043310; Generator: 0.021632,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:37,499 root         INFO     Train Epoch: 83 [3584/8000 (45%)]\tTotal Loss: 0.243650\n",
      "Reconstruction: 0.176744, Regularization: 0.001969, Discriminator: 0.043316; Generator: 0.021621,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 23:00:37,600 root         INFO     Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 0.241849\n",
      "Reconstruction: 0.174862, Regularization: 0.002035, Discriminator: 0.043325; Generator: 0.021627,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:00:37,702 root         INFO     Train Epoch: 83 [4608/8000 (58%)]\tTotal Loss: 0.263386\n",
      "Reconstruction: 0.196176, Regularization: 0.002252, Discriminator: 0.043324; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:37,799 root         INFO     Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 0.276351\n",
      "Reconstruction: 0.209076, Regularization: 0.002315, Discriminator: 0.043322; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:37,896 root         INFO     Train Epoch: 83 [5632/8000 (70%)]\tTotal Loss: 0.263732\n",
      "Reconstruction: 0.196240, Regularization: 0.002536, Discriminator: 0.043312; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:37,995 root         INFO     Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 0.218134\n",
      "Reconstruction: 0.151376, Regularization: 0.001782, Discriminator: 0.043329; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:38,094 root         INFO     Train Epoch: 83 [6656/8000 (83%)]\tTotal Loss: 0.284346\n",
      "Reconstruction: 0.216324, Regularization: 0.003045, Discriminator: 0.043327; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:38,192 root         INFO     Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 0.260981\n",
      "Reconstruction: 0.193598, Regularization: 0.002433, Discriminator: 0.043313; Generator: 0.021637,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:38,291 root         INFO     Train Epoch: 83 [7680/8000 (96%)]\tTotal Loss: 0.256112\n",
      "Reconstruction: 0.188794, Regularization: 0.002358, Discriminator: 0.043330; Generator: 0.021630,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 23:00:38,365 root         INFO     ====> Epoch: 83 Average loss: 0.2455\n",
      "2019-04-09 23:00:38,392 root         INFO     Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 0.253321\n",
      "Reconstruction: 0.185851, Regularization: 0.002506, Discriminator: 0.043325; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:38,490 root         INFO     Train Epoch: 84 [512/8000 (6%)]\tTotal Loss: 0.259637\n",
      "Reconstruction: 0.192394, Regularization: 0.002263, Discriminator: 0.043340; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:38,589 root         INFO     Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 0.229137\n",
      "Reconstruction: 0.162567, Regularization: 0.001633, Discriminator: 0.043295; Generator: 0.021642,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:38,686 root         INFO     Train Epoch: 84 [1536/8000 (19%)]\tTotal Loss: 0.280122\n",
      "Reconstruction: 0.212680, Regularization: 0.002530, Discriminator: 0.043258; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:38,783 root         INFO     Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 0.223794\n",
      "Reconstruction: 0.157478, Regularization: 0.001393, Discriminator: 0.043272; Generator: 0.021651,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:38,882 root         INFO     Train Epoch: 84 [2560/8000 (32%)]\tTotal Loss: 0.219940\n",
      "Reconstruction: 0.153341, Regularization: 0.001624, Discriminator: 0.043329; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:38,981 root         INFO     Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 0.254196\n",
      "Reconstruction: 0.187086, Regularization: 0.002179, Discriminator: 0.043284; Generator: 0.021647,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:39,079 root         INFO     Train Epoch: 84 [3584/8000 (45%)]\tTotal Loss: 0.207027\n",
      "Reconstruction: 0.140849, Regularization: 0.001232, Discriminator: 0.043301; Generator: 0.021645,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:39,178 root         INFO     Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 0.231249\n",
      "Reconstruction: 0.164526, Regularization: 0.001826, Discriminator: 0.043243; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:39,280 root         INFO     Train Epoch: 84 [4608/8000 (58%)]\tTotal Loss: 0.257109\n",
      "Reconstruction: 0.189853, Regularization: 0.002318, Discriminator: 0.043281; Generator: 0.021656,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:39,379 root         INFO     Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 0.228746\n",
      "Reconstruction: 0.162281, Regularization: 0.001462, Discriminator: 0.043346; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:39,478 root         INFO     Train Epoch: 84 [5632/8000 (70%)]\tTotal Loss: 0.211556\n",
      "Reconstruction: 0.144999, Regularization: 0.001473, Discriminator: 0.043425; Generator: 0.021658,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:00:39,577 root         INFO     Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 0.209093\n",
      "Reconstruction: 0.142902, Regularization: 0.001227, Discriminator: 0.043299; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:39,677 root         INFO     Train Epoch: 84 [6656/8000 (83%)]\tTotal Loss: 0.278912\n",
      "Reconstruction: 0.211464, Regularization: 0.002583, Discriminator: 0.043203; Generator: 0.021661,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:00:39,776 root         INFO     Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 0.235836\n",
      "Reconstruction: 0.169109, Regularization: 0.001805, Discriminator: 0.043262; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:39,876 root         INFO     Train Epoch: 84 [7680/8000 (96%)]\tTotal Loss: 0.244458\n",
      "Reconstruction: 0.177863, Regularization: 0.001743, Discriminator: 0.043207; Generator: 0.021645,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:00:39,949 root         INFO     ====> Epoch: 84 Average loss: 0.2456\n",
      "2019-04-09 23:00:39,976 root         INFO     Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 0.275042\n",
      "Reconstruction: 0.207237, Regularization: 0.002725, Discriminator: 0.043430; Generator: 0.021650,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:00:40,074 root         INFO     Train Epoch: 85 [512/8000 (6%)]\tTotal Loss: 0.251332\n",
      "Reconstruction: 0.184230, Regularization: 0.002162, Discriminator: 0.043272; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:40,172 root         INFO     Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 0.208208\n",
      "Reconstruction: 0.141878, Regularization: 0.001343, Discriminator: 0.043322; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:40,270 root         INFO     Train Epoch: 85 [1536/8000 (19%)]\tTotal Loss: 0.256413\n",
      "Reconstruction: 0.189108, Regularization: 0.002269, Discriminator: 0.043384; Generator: 0.021652,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:40,368 root         INFO     Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 0.216985\n",
      "Reconstruction: 0.150492, Regularization: 0.001491, Discriminator: 0.043333; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:40,466 root         INFO     Train Epoch: 85 [2560/8000 (32%)]\tTotal Loss: 0.233914\n",
      "Reconstruction: 0.167076, Regularization: 0.001808, Discriminator: 0.043367; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:40,564 root         INFO     Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 0.279795\n",
      "Reconstruction: 0.212213, Regularization: 0.002586, Discriminator: 0.043336; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:40,663 root         INFO     Train Epoch: 85 [3584/8000 (45%)]\tTotal Loss: 0.240642\n",
      "Reconstruction: 0.173833, Regularization: 0.001845, Discriminator: 0.043294; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:40,762 root         INFO     Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 0.227340\n",
      "Reconstruction: 0.160652, Regularization: 0.001684, Discriminator: 0.043350; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:40,860 root         INFO     Train Epoch: 85 [4608/8000 (58%)]\tTotal Loss: 0.228119\n",
      "Reconstruction: 0.161575, Regularization: 0.001665, Discriminator: 0.043219; Generator: 0.021660,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:00:40,958 root         INFO     Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 0.245980\n",
      "Reconstruction: 0.178524, Regularization: 0.002336, Discriminator: 0.043456; Generator: 0.021664,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:00:41,057 root         INFO     Train Epoch: 85 [5632/8000 (70%)]\tTotal Loss: 0.247895\n",
      "Reconstruction: 0.180831, Regularization: 0.002251, Discriminator: 0.043156; Generator: 0.021657,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:00:41,156 root         INFO     Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 0.240861\n",
      "Reconstruction: 0.174034, Regularization: 0.001914, Discriminator: 0.043251; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:41,254 root         INFO     Train Epoch: 85 [6656/8000 (83%)]\tTotal Loss: 0.271067\n",
      "Reconstruction: 0.203486, Regularization: 0.002460, Discriminator: 0.043453; Generator: 0.021668,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:00:41,353 root         INFO     Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 0.245131\n",
      "Reconstruction: 0.177946, Regularization: 0.002221, Discriminator: 0.043293; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:41,452 root         INFO     Train Epoch: 85 [7680/8000 (96%)]\tTotal Loss: 0.254443\n",
      "Reconstruction: 0.187322, Regularization: 0.002152, Discriminator: 0.043308; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:41,527 root         INFO     ====> Epoch: 85 Average loss: 0.2453\n",
      "2019-04-09 23:00:41,553 root         INFO     Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 0.235194\n",
      "Reconstruction: 0.168251, Regularization: 0.001990, Discriminator: 0.043302; Generator: 0.021652,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:41,653 root         INFO     Train Epoch: 86 [512/8000 (6%)]\tTotal Loss: 0.225318\n",
      "Reconstruction: 0.158488, Regularization: 0.001800, Discriminator: 0.043369; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:41,752 root         INFO     Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 0.264470\n",
      "Reconstruction: 0.197078, Regularization: 0.002477, Discriminator: 0.043243; Generator: 0.021672,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:41,851 root         INFO     Train Epoch: 86 [1536/8000 (19%)]\tTotal Loss: 0.241312\n",
      "Reconstruction: 0.174144, Regularization: 0.002059, Discriminator: 0.043422; Generator: 0.021687,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:00:41,949 root         INFO     Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 0.204772\n",
      "Reconstruction: 0.138557, Regularization: 0.001258, Discriminator: 0.043303; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:42,047 root         INFO     Train Epoch: 86 [2560/8000 (32%)]\tTotal Loss: 0.288225\n",
      "Reconstruction: 0.220273, Regularization: 0.003145, Discriminator: 0.043136; Generator: 0.021671,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:00:42,145 root         INFO     Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 0.211378\n",
      "Reconstruction: 0.145130, Regularization: 0.001264, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:42,243 root         INFO     Train Epoch: 86 [3584/8000 (45%)]\tTotal Loss: 0.205748\n",
      "Reconstruction: 0.139330, Regularization: 0.001458, Discriminator: 0.043298; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:42,340 root         INFO     Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 0.255252\n",
      "Reconstruction: 0.188182, Regularization: 0.002148, Discriminator: 0.043253; Generator: 0.021669,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:42,438 root         INFO     Train Epoch: 86 [4608/8000 (58%)]\tTotal Loss: 0.246013\n",
      "Reconstruction: 0.178919, Regularization: 0.002146, Discriminator: 0.043275; Generator: 0.021674,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:42,534 root         INFO     Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 0.253698\n",
      "Reconstruction: 0.186416, Regularization: 0.002482, Discriminator: 0.043127; Generator: 0.021672,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:00:42,633 root         INFO     Train Epoch: 86 [5632/8000 (70%)]\tTotal Loss: 0.254676\n",
      "Reconstruction: 0.187135, Regularization: 0.002556, Discriminator: 0.043332; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:42,730 root         INFO     Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 0.241720\n",
      "Reconstruction: 0.174589, Regularization: 0.002029, Discriminator: 0.043439; Generator: 0.021663,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:00:42,828 root         INFO     Train Epoch: 86 [6656/8000 (83%)]\tTotal Loss: 0.218926\n",
      "Reconstruction: 0.152422, Regularization: 0.001737, Discriminator: 0.043106; Generator: 0.021662,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 23:00:42,926 root         INFO     Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 0.232487\n",
      "Reconstruction: 0.165727, Regularization: 0.001803, Discriminator: 0.043300; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:43,022 root         INFO     Train Epoch: 86 [7680/8000 (96%)]\tTotal Loss: 0.248814\n",
      "Reconstruction: 0.181676, Regularization: 0.002094, Discriminator: 0.043389; Generator: 0.021655,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:43,095 root         INFO     ====> Epoch: 86 Average loss: 0.2448\n",
      "2019-04-09 23:00:43,122 root         INFO     Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 0.218199\n",
      "Reconstruction: 0.151558, Regularization: 0.001692, Discriminator: 0.043291; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:43,220 root         INFO     Train Epoch: 87 [512/8000 (6%)]\tTotal Loss: 0.239045\n",
      "Reconstruction: 0.172281, Regularization: 0.001956, Discriminator: 0.043150; Generator: 0.021657,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:00:43,320 root         INFO     Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 0.223196\n",
      "Reconstruction: 0.156382, Regularization: 0.001777, Discriminator: 0.043356; Generator: 0.021680,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:43,418 root         INFO     Train Epoch: 87 [1536/8000 (19%)]\tTotal Loss: 0.233340\n",
      "Reconstruction: 0.166581, Regularization: 0.001889, Discriminator: 0.043189; Generator: 0.021681,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:00:43,516 root         INFO     Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 0.256276\n",
      "Reconstruction: 0.188931, Regularization: 0.002418, Discriminator: 0.043242; Generator: 0.021684,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:43,615 root         INFO     Train Epoch: 87 [2560/8000 (32%)]\tTotal Loss: 0.200725\n",
      "Reconstruction: 0.134651, Regularization: 0.001154, Discriminator: 0.043260; Generator: 0.021660,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:43,714 root         INFO     Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 0.227503\n",
      "Reconstruction: 0.160464, Regularization: 0.002028, Discriminator: 0.043344; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:43,815 root         INFO     Train Epoch: 87 [3584/8000 (45%)]\tTotal Loss: 0.274712\n",
      "Reconstruction: 0.206978, Regularization: 0.002789, Discriminator: 0.043261; Generator: 0.021685,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:43,915 root         INFO     Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 0.250666\n",
      "Reconstruction: 0.183254, Regularization: 0.002455, Discriminator: 0.043284; Generator: 0.021674,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:44,016 root         INFO     Train Epoch: 87 [4608/8000 (58%)]\tTotal Loss: 0.257146\n",
      "Reconstruction: 0.189726, Regularization: 0.002587, Discriminator: 0.043174; Generator: 0.021659,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:00:44,117 root         INFO     Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 0.236501\n",
      "Reconstruction: 0.169104, Regularization: 0.002349, Discriminator: 0.043393; Generator: 0.021654,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:44,217 root         INFO     Train Epoch: 87 [5632/8000 (70%)]\tTotal Loss: 0.223618\n",
      "Reconstruction: 0.156618, Regularization: 0.001976, Discriminator: 0.043377; Generator: 0.021648,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:44,317 root         INFO     Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 0.258644\n",
      "Reconstruction: 0.191298, Regularization: 0.002561, Discriminator: 0.043133; Generator: 0.021651,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:00:44,416 root         INFO     Train Epoch: 87 [6656/8000 (83%)]\tTotal Loss: 0.244476\n",
      "Reconstruction: 0.177142, Regularization: 0.002318, Discriminator: 0.043352; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:44,515 root         INFO     Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 0.224194\n",
      "Reconstruction: 0.157332, Regularization: 0.001898, Discriminator: 0.043307; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:44,614 root         INFO     Train Epoch: 87 [7680/8000 (96%)]\tTotal Loss: 0.209863\n",
      "Reconstruction: 0.143310, Regularization: 0.001539, Discriminator: 0.043352; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:44,690 root         INFO     ====> Epoch: 87 Average loss: 0.2445\n",
      "2019-04-09 23:00:44,716 root         INFO     Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 0.239137\n",
      "Reconstruction: 0.171854, Regularization: 0.002369, Discriminator: 0.043260; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:44,816 root         INFO     Train Epoch: 88 [512/8000 (6%)]\tTotal Loss: 0.244832\n",
      "Reconstruction: 0.177028, Regularization: 0.002804, Discriminator: 0.043346; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:44,916 root         INFO     Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 0.271030\n",
      "Reconstruction: 0.202883, Regularization: 0.003086, Discriminator: 0.043391; Generator: 0.021671,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:45,015 root         INFO     Train Epoch: 88 [1536/8000 (19%)]\tTotal Loss: 0.276235\n",
      "Reconstruction: 0.208204, Regularization: 0.003137, Discriminator: 0.043223; Generator: 0.021672,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:00:45,115 root         INFO     Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 0.235703\n",
      "Reconstruction: 0.168789, Regularization: 0.001955, Discriminator: 0.043295; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:45,214 root         INFO     Train Epoch: 88 [2560/8000 (32%)]\tTotal Loss: 0.237008\n",
      "Reconstruction: 0.169855, Regularization: 0.002005, Discriminator: 0.043490; Generator: 0.021658,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:00:45,313 root         INFO     Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 0.249425\n",
      "Reconstruction: 0.181891, Regularization: 0.002360, Discriminator: 0.043500; Generator: 0.021674,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 23:00:45,413 root         INFO     Train Epoch: 88 [3584/8000 (45%)]\tTotal Loss: 0.230265\n",
      "Reconstruction: 0.162974, Regularization: 0.002155, Discriminator: 0.043485; Generator: 0.021652,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:00:45,512 root         INFO     Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 0.263687\n",
      "Reconstruction: 0.195549, Regularization: 0.003123, Discriminator: 0.043349; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:45,610 root         INFO     Train Epoch: 88 [4608/8000 (58%)]\tTotal Loss: 0.225372\n",
      "Reconstruction: 0.158433, Regularization: 0.001920, Discriminator: 0.043351; Generator: 0.021667,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:45,710 root         INFO     Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 0.248033\n",
      "Reconstruction: 0.180536, Regularization: 0.002480, Discriminator: 0.043353; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:45,809 root         INFO     Train Epoch: 88 [5632/8000 (70%)]\tTotal Loss: 0.219289\n",
      "Reconstruction: 0.152436, Regularization: 0.001980, Discriminator: 0.043216; Generator: 0.021657,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:00:45,909 root         INFO     Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 0.234264\n",
      "Reconstruction: 0.167033, Regularization: 0.002237, Discriminator: 0.043329; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:46,004 root         INFO     Train Epoch: 88 [6656/8000 (83%)]\tTotal Loss: 0.238203\n",
      "Reconstruction: 0.171080, Regularization: 0.002126, Discriminator: 0.043329; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:46,099 root         INFO     Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 0.221729\n",
      "Reconstruction: 0.154665, Regularization: 0.002125, Discriminator: 0.043267; Generator: 0.021672,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:46,195 root         INFO     Train Epoch: 88 [7680/8000 (96%)]\tTotal Loss: 0.204378\n",
      "Reconstruction: 0.137887, Regularization: 0.001392, Discriminator: 0.043429; Generator: 0.021670,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:00:46,267 root         INFO     ====> Epoch: 88 Average loss: 0.2445\n",
      "2019-04-09 23:00:46,293 root         INFO     Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 0.233885\n",
      "Reconstruction: 0.166439, Regularization: 0.002412, Discriminator: 0.043376; Generator: 0.021658,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:46,391 root         INFO     Train Epoch: 89 [512/8000 (6%)]\tTotal Loss: 0.230024\n",
      "Reconstruction: 0.162935, Regularization: 0.002098, Discriminator: 0.043313; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:46,489 root         INFO     Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 0.298744\n",
      "Reconstruction: 0.230014, Regularization: 0.003714, Discriminator: 0.043352; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:46,586 root         INFO     Train Epoch: 89 [1536/8000 (19%)]\tTotal Loss: 0.290720\n",
      "Reconstruction: 0.222265, Regularization: 0.003400, Discriminator: 0.043391; Generator: 0.021664,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:46,684 root         INFO     Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 0.261893\n",
      "Reconstruction: 0.193916, Regularization: 0.003024, Discriminator: 0.043296; Generator: 0.021656,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:46,782 root         INFO     Train Epoch: 89 [2560/8000 (32%)]\tTotal Loss: 0.251582\n",
      "Reconstruction: 0.183812, Regularization: 0.002721, Discriminator: 0.043391; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:46,880 root         INFO     Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 0.246327\n",
      "Reconstruction: 0.178483, Regularization: 0.002792, Discriminator: 0.043381; Generator: 0.021671,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:46,978 root         INFO     Train Epoch: 89 [3584/8000 (45%)]\tTotal Loss: 0.209314\n",
      "Reconstruction: 0.142530, Regularization: 0.001732, Discriminator: 0.043379; Generator: 0.021673,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:47,077 root         INFO     Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 0.223394\n",
      "Reconstruction: 0.156395, Regularization: 0.001996, Discriminator: 0.043325; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:47,175 root         INFO     Train Epoch: 89 [4608/8000 (58%)]\tTotal Loss: 0.244943\n",
      "Reconstruction: 0.177885, Regularization: 0.002083, Discriminator: 0.043306; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:47,272 root         INFO     Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 0.270496\n",
      "Reconstruction: 0.202259, Regularization: 0.003233, Discriminator: 0.043333; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:47,370 root         INFO     Train Epoch: 89 [5632/8000 (70%)]\tTotal Loss: 0.218734\n",
      "Reconstruction: 0.151827, Regularization: 0.001925, Discriminator: 0.043314; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:47,468 root         INFO     Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 0.232206\n",
      "Reconstruction: 0.165071, Regularization: 0.002157, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:47,565 root         INFO     Train Epoch: 89 [6656/8000 (83%)]\tTotal Loss: 0.246981\n",
      "Reconstruction: 0.179264, Regularization: 0.002715, Discriminator: 0.043335; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:47,662 root         INFO     Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 0.248645\n",
      "Reconstruction: 0.181186, Regularization: 0.002477, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:47,760 root         INFO     Train Epoch: 89 [7680/8000 (96%)]\tTotal Loss: 0.225676\n",
      "Reconstruction: 0.158622, Regularization: 0.002098, Discriminator: 0.043297; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:47,834 root         INFO     ====> Epoch: 89 Average loss: 0.2444\n",
      "2019-04-09 23:00:47,860 root         INFO     Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 0.294693\n",
      "Reconstruction: 0.226090, Regularization: 0.003561, Discriminator: 0.043375; Generator: 0.021668,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:47,958 root         INFO     Train Epoch: 90 [512/8000 (6%)]\tTotal Loss: 0.280042\n",
      "Reconstruction: 0.211908, Regularization: 0.003055, Discriminator: 0.043412; Generator: 0.021667,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:00:48,056 root         INFO     Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 0.246861\n",
      "Reconstruction: 0.179315, Regularization: 0.002539, Discriminator: 0.043332; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:48,154 root         INFO     Train Epoch: 90 [1536/8000 (19%)]\tTotal Loss: 0.184854\n",
      "Reconstruction: 0.118570, Regularization: 0.001304, Discriminator: 0.043301; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:48,252 root         INFO     Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 0.248030\n",
      "Reconstruction: 0.180169, Regularization: 0.002839, Discriminator: 0.043352; Generator: 0.021670,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:48,350 root         INFO     Train Epoch: 90 [2560/8000 (32%)]\tTotal Loss: 0.284349\n",
      "Reconstruction: 0.215991, Regularization: 0.003344, Discriminator: 0.043345; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:48,448 root         INFO     Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 0.248236\n",
      "Reconstruction: 0.180441, Regularization: 0.002805, Discriminator: 0.043321; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:48,546 root         INFO     Train Epoch: 90 [3584/8000 (45%)]\tTotal Loss: 0.227610\n",
      "Reconstruction: 0.160343, Regularization: 0.002271, Discriminator: 0.043324; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:48,644 root         INFO     Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 0.204486\n",
      "Reconstruction: 0.137848, Regularization: 0.001647, Discriminator: 0.043320; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:48,741 root         INFO     Train Epoch: 90 [4608/8000 (58%)]\tTotal Loss: 0.249662\n",
      "Reconstruction: 0.182171, Regularization: 0.002495, Discriminator: 0.043322; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:48,839 root         INFO     Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 0.256673\n",
      "Reconstruction: 0.188712, Regularization: 0.002982, Discriminator: 0.043309; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:48,937 root         INFO     Train Epoch: 90 [5632/8000 (70%)]\tTotal Loss: 0.264603\n",
      "Reconstruction: 0.196529, Regularization: 0.003072, Discriminator: 0.043325; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:49,035 root         INFO     Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 0.259246\n",
      "Reconstruction: 0.190796, Regularization: 0.003450, Discriminator: 0.043330; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:49,134 root         INFO     Train Epoch: 90 [6656/8000 (83%)]\tTotal Loss: 0.226612\n",
      "Reconstruction: 0.159532, Regularization: 0.002090, Discriminator: 0.043326; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:49,233 root         INFO     Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 0.203873\n",
      "Reconstruction: 0.137267, Regularization: 0.001617, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:49,331 root         INFO     Train Epoch: 90 [7680/8000 (96%)]\tTotal Loss: 0.236431\n",
      "Reconstruction: 0.169119, Regularization: 0.002341, Discriminator: 0.043314; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:49,405 root         INFO     ====> Epoch: 90 Average loss: 0.2448\n",
      "2019-04-09 23:00:49,431 root         INFO     Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 0.263122\n",
      "Reconstruction: 0.195034, Regularization: 0.003103, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:49,530 root         INFO     Train Epoch: 91 [512/8000 (6%)]\tTotal Loss: 0.225259\n",
      "Reconstruction: 0.158152, Regularization: 0.002130, Discriminator: 0.043320; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:49,628 root         INFO     Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 0.229730\n",
      "Reconstruction: 0.162383, Regularization: 0.002359, Discriminator: 0.043320; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:49,726 root         INFO     Train Epoch: 91 [1536/8000 (19%)]\tTotal Loss: 0.231168\n",
      "Reconstruction: 0.163808, Regularization: 0.002398, Discriminator: 0.043293; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:49,826 root         INFO     Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 0.207011\n",
      "Reconstruction: 0.140306, Regularization: 0.001752, Discriminator: 0.043283; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:49,926 root         INFO     Train Epoch: 91 [2560/8000 (32%)]\tTotal Loss: 0.226520\n",
      "Reconstruction: 0.159269, Regularization: 0.002259, Discriminator: 0.043319; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:50,026 root         INFO     Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 0.238776\n",
      "Reconstruction: 0.171293, Regularization: 0.002484, Discriminator: 0.043323; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:50,122 root         INFO     Train Epoch: 91 [3584/8000 (45%)]\tTotal Loss: 0.237349\n",
      "Reconstruction: 0.169907, Regularization: 0.002470, Discriminator: 0.043301; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:50,219 root         INFO     Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 0.218057\n",
      "Reconstruction: 0.151006, Regularization: 0.002055, Discriminator: 0.043320; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:50,316 root         INFO     Train Epoch: 91 [4608/8000 (58%)]\tTotal Loss: 0.220925\n",
      "Reconstruction: 0.153864, Regularization: 0.002102, Discriminator: 0.043280; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:50,414 root         INFO     Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 0.268760\n",
      "Reconstruction: 0.200385, Regularization: 0.003382, Discriminator: 0.043310; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:50,510 root         INFO     Train Epoch: 91 [5632/8000 (70%)]\tTotal Loss: 0.275889\n",
      "Reconstruction: 0.207469, Regularization: 0.003509, Discriminator: 0.043244; Generator: 0.021668,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:50,608 root         INFO     Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 0.229456\n",
      "Reconstruction: 0.162121, Regularization: 0.002338, Discriminator: 0.043324; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:50,706 root         INFO     Train Epoch: 91 [6656/8000 (83%)]\tTotal Loss: 0.240427\n",
      "Reconstruction: 0.173050, Regularization: 0.002439, Discriminator: 0.043256; Generator: 0.021682,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:50,804 root         INFO     Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 0.251640\n",
      "Reconstruction: 0.183602, Regularization: 0.003097, Discriminator: 0.043282; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:50,902 root         INFO     Train Epoch: 91 [7680/8000 (96%)]\tTotal Loss: 0.249389\n",
      "Reconstruction: 0.181743, Regularization: 0.002705, Discriminator: 0.043281; Generator: 0.021660,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:50,974 root         INFO     ====> Epoch: 91 Average loss: 0.2447\n",
      "2019-04-09 23:00:51,000 root         INFO     Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 0.213742\n",
      "Reconstruction: 0.146664, Regularization: 0.002052, Discriminator: 0.043350; Generator: 0.021677,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:51,098 root         INFO     Train Epoch: 92 [512/8000 (6%)]\tTotal Loss: 0.226985\n",
      "Reconstruction: 0.159689, Regularization: 0.002206, Discriminator: 0.043414; Generator: 0.021677,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 23:00:51,195 root         INFO     Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 0.272532\n",
      "Reconstruction: 0.204228, Regularization: 0.003459, Discriminator: 0.043187; Generator: 0.021657,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:00:51,291 root         INFO     Train Epoch: 92 [1536/8000 (19%)]\tTotal Loss: 0.212398\n",
      "Reconstruction: 0.145528, Regularization: 0.001884, Discriminator: 0.043301; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:51,388 root         INFO     Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 0.287521\n",
      "Reconstruction: 0.218860, Regularization: 0.003767, Discriminator: 0.043240; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:51,485 root         INFO     Train Epoch: 92 [2560/8000 (32%)]\tTotal Loss: 0.215124\n",
      "Reconstruction: 0.148009, Regularization: 0.002098, Discriminator: 0.043339; Generator: 0.021678,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:51,583 root         INFO     Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 0.279627\n",
      "Reconstruction: 0.211058, Regularization: 0.003552, Discriminator: 0.043352; Generator: 0.021665,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:51,681 root         INFO     Train Epoch: 92 [3584/8000 (45%)]\tTotal Loss: 0.276735\n",
      "Reconstruction: 0.208487, Regularization: 0.003254, Discriminator: 0.043314; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:51,778 root         INFO     Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 0.249821\n",
      "Reconstruction: 0.181906, Regularization: 0.002881, Discriminator: 0.043373; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:51,875 root         INFO     Train Epoch: 92 [4608/8000 (58%)]\tTotal Loss: 0.240574\n",
      "Reconstruction: 0.173073, Regularization: 0.002556, Discriminator: 0.043272; Generator: 0.021674,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:51,973 root         INFO     Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 0.248465\n",
      "Reconstruction: 0.180775, Regularization: 0.002819, Discriminator: 0.043200; Generator: 0.021671,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:00:52,071 root         INFO     Train Epoch: 92 [5632/8000 (70%)]\tTotal Loss: 0.227988\n",
      "Reconstruction: 0.160681, Regularization: 0.002297, Discriminator: 0.043354; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:52,168 root         INFO     Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 0.308431\n",
      "Reconstruction: 0.239288, Regularization: 0.004214, Discriminator: 0.043250; Generator: 0.021679,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:52,265 root         INFO     Train Epoch: 92 [6656/8000 (83%)]\tTotal Loss: 0.209058\n",
      "Reconstruction: 0.142380, Regularization: 0.001679, Discriminator: 0.043319; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:52,362 root         INFO     Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 0.268544\n",
      "Reconstruction: 0.200486, Regularization: 0.003183, Discriminator: 0.043228; Generator: 0.021647,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:00:52,459 root         INFO     Train Epoch: 92 [7680/8000 (96%)]\tTotal Loss: 0.216012\n",
      "Reconstruction: 0.148995, Regularization: 0.002019, Discriminator: 0.043333; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:52,532 root         INFO     ====> Epoch: 92 Average loss: 0.2445\n",
      "2019-04-09 23:00:52,559 root         INFO     Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 0.272470\n",
      "Reconstruction: 0.204222, Regularization: 0.003279, Discriminator: 0.043304; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:52,655 root         INFO     Train Epoch: 93 [512/8000 (6%)]\tTotal Loss: 0.205312\n",
      "Reconstruction: 0.138694, Regularization: 0.001696, Discriminator: 0.043251; Generator: 0.021671,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:52,754 root         INFO     Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 0.230617\n",
      "Reconstruction: 0.163479, Regularization: 0.002151, Discriminator: 0.043339; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:52,850 root         INFO     Train Epoch: 93 [1536/8000 (19%)]\tTotal Loss: 0.265296\n",
      "Reconstruction: 0.197372, Regularization: 0.002962, Discriminator: 0.043311; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:52,947 root         INFO     Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 0.255896\n",
      "Reconstruction: 0.188207, Regularization: 0.002797, Discriminator: 0.043214; Generator: 0.021678,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:53,044 root         INFO     Train Epoch: 93 [2560/8000 (32%)]\tTotal Loss: 0.224604\n",
      "Reconstruction: 0.157686, Regularization: 0.001854, Discriminator: 0.043377; Generator: 0.021686,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:53,141 root         INFO     Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 0.250335\n",
      "Reconstruction: 0.182636, Regularization: 0.002697, Discriminator: 0.043314; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:53,238 root         INFO     Train Epoch: 93 [3584/8000 (45%)]\tTotal Loss: 0.199924\n",
      "Reconstruction: 0.133546, Regularization: 0.001389, Discriminator: 0.043341; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:53,336 root         INFO     Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 0.245647\n",
      "Reconstruction: 0.178094, Regularization: 0.002541, Discriminator: 0.043334; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:53,433 root         INFO     Train Epoch: 93 [4608/8000 (58%)]\tTotal Loss: 0.221896\n",
      "Reconstruction: 0.155018, Regularization: 0.001880, Discriminator: 0.043348; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:53,530 root         INFO     Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 0.226950\n",
      "Reconstruction: 0.160012, Regularization: 0.002025, Discriminator: 0.043245; Generator: 0.021669,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:53,628 root         INFO     Train Epoch: 93 [5632/8000 (70%)]\tTotal Loss: 0.238245\n",
      "Reconstruction: 0.170744, Regularization: 0.002471, Discriminator: 0.043374; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:53,725 root         INFO     Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 0.247229\n",
      "Reconstruction: 0.179756, Regularization: 0.002478, Discriminator: 0.043341; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:53,821 root         INFO     Train Epoch: 93 [6656/8000 (83%)]\tTotal Loss: 0.277023\n",
      "Reconstruction: 0.208605, Regularization: 0.003371, Discriminator: 0.043396; Generator: 0.021651,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:53,918 root         INFO     Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 0.236720\n",
      "Reconstruction: 0.169540, Regularization: 0.002176, Discriminator: 0.043336; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:54,016 root         INFO     Train Epoch: 93 [7680/8000 (96%)]\tTotal Loss: 0.285208\n",
      "Reconstruction: 0.216579, Regularization: 0.003843, Discriminator: 0.043108; Generator: 0.021678,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 23:00:54,089 root         INFO     ====> Epoch: 93 Average loss: 0.2445\n",
      "2019-04-09 23:00:54,115 root         INFO     Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 0.252599\n",
      "Reconstruction: 0.184904, Regularization: 0.002763, Discriminator: 0.043282; Generator: 0.021651,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:54,214 root         INFO     Train Epoch: 94 [512/8000 (6%)]\tTotal Loss: 0.256289\n",
      "Reconstruction: 0.188373, Regularization: 0.002946, Discriminator: 0.043321; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:54,313 root         INFO     Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 0.255178\n",
      "Reconstruction: 0.187510, Regularization: 0.002750, Discriminator: 0.043287; Generator: 0.021630,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:54,411 root         INFO     Train Epoch: 94 [1536/8000 (19%)]\tTotal Loss: 0.293567\n",
      "Reconstruction: 0.224972, Regularization: 0.003668, Discriminator: 0.043270; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:54,511 root         INFO     Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 0.208291\n",
      "Reconstruction: 0.141643, Regularization: 0.001650, Discriminator: 0.043347; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:54,612 root         INFO     Train Epoch: 94 [2560/8000 (32%)]\tTotal Loss: 0.238317\n",
      "Reconstruction: 0.170984, Regularization: 0.002402, Discriminator: 0.043288; Generator: 0.021643,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:54,711 root         INFO     Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 0.248551\n",
      "Reconstruction: 0.181429, Regularization: 0.002102, Discriminator: 0.043364; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:54,809 root         INFO     Train Epoch: 94 [3584/8000 (45%)]\tTotal Loss: 0.206872\n",
      "Reconstruction: 0.140347, Regularization: 0.001610, Discriminator: 0.043270; Generator: 0.021644,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:54,908 root         INFO     Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 0.201462\n",
      "Reconstruction: 0.135064, Regularization: 0.001376, Discriminator: 0.043351; Generator: 0.021671,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:55,006 root         INFO     Train Epoch: 94 [4608/8000 (58%)]\tTotal Loss: 0.245816\n",
      "Reconstruction: 0.178623, Regularization: 0.002218, Discriminator: 0.043314; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:55,104 root         INFO     Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 0.230709\n",
      "Reconstruction: 0.163688, Regularization: 0.002058, Discriminator: 0.043295; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:55,203 root         INFO     Train Epoch: 94 [5632/8000 (70%)]\tTotal Loss: 0.320794\n",
      "Reconstruction: 0.251412, Regularization: 0.004443, Discriminator: 0.043281; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:55,301 root         INFO     Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 0.243856\n",
      "Reconstruction: 0.176322, Regularization: 0.002513, Discriminator: 0.043381; Generator: 0.021640,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:55,400 root         INFO     Train Epoch: 94 [6656/8000 (83%)]\tTotal Loss: 0.267071\n",
      "Reconstruction: 0.198958, Regularization: 0.003112, Discriminator: 0.043350; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:55,498 root         INFO     Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 0.237366\n",
      "Reconstruction: 0.170136, Regularization: 0.002304, Discriminator: 0.043272; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:55,597 root         INFO     Train Epoch: 94 [7680/8000 (96%)]\tTotal Loss: 0.281074\n",
      "Reconstruction: 0.212828, Regularization: 0.003268, Discriminator: 0.043331; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:55,670 root         INFO     ====> Epoch: 94 Average loss: 0.2443\n",
      "2019-04-09 23:00:55,696 root         INFO     Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 0.228385\n",
      "Reconstruction: 0.161304, Regularization: 0.002069, Discriminator: 0.043351; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:55,798 root         INFO     Train Epoch: 95 [512/8000 (6%)]\tTotal Loss: 0.227305\n",
      "Reconstruction: 0.160350, Regularization: 0.002083, Discriminator: 0.043226; Generator: 0.021646,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 23:00:55,900 root         INFO     Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 0.204025\n",
      "Reconstruction: 0.137509, Regularization: 0.001485, Discriminator: 0.043376; Generator: 0.021655,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:00:56,001 root         INFO     Train Epoch: 95 [1536/8000 (19%)]\tTotal Loss: 0.265073\n",
      "Reconstruction: 0.197430, Regularization: 0.002669, Discriminator: 0.043327; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:56,101 root         INFO     Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 0.255901\n",
      "Reconstruction: 0.188170, Regularization: 0.002777, Discriminator: 0.043320; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:56,202 root         INFO     Train Epoch: 95 [2560/8000 (32%)]\tTotal Loss: 0.263988\n",
      "Reconstruction: 0.195909, Regularization: 0.003073, Discriminator: 0.043363; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:56,303 root         INFO     Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 0.246889\n",
      "Reconstruction: 0.179595, Regularization: 0.002299, Discriminator: 0.043338; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:56,402 root         INFO     Train Epoch: 95 [3584/8000 (45%)]\tTotal Loss: 0.203061\n",
      "Reconstruction: 0.136569, Regularization: 0.001508, Discriminator: 0.043325; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:56,502 root         INFO     Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 0.239314\n",
      "Reconstruction: 0.172120, Regularization: 0.002240, Discriminator: 0.043305; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:56,598 root         INFO     Train Epoch: 95 [4608/8000 (58%)]\tTotal Loss: 0.227978\n",
      "Reconstruction: 0.160864, Regularization: 0.002148, Discriminator: 0.043315; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:56,694 root         INFO     Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 0.225510\n",
      "Reconstruction: 0.158526, Regularization: 0.001990, Discriminator: 0.043334; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:56,790 root         INFO     Train Epoch: 95 [5632/8000 (70%)]\tTotal Loss: 0.226521\n",
      "Reconstruction: 0.159725, Regularization: 0.001796, Discriminator: 0.043343; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:56,887 root         INFO     Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 0.271459\n",
      "Reconstruction: 0.203332, Regularization: 0.003130, Discriminator: 0.043341; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:56,984 root         INFO     Train Epoch: 95 [6656/8000 (83%)]\tTotal Loss: 0.245551\n",
      "Reconstruction: 0.178650, Regularization: 0.001928, Discriminator: 0.043305; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:57,082 root         INFO     Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 0.237433\n",
      "Reconstruction: 0.170376, Regularization: 0.002066, Discriminator: 0.043331; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:57,179 root         INFO     Train Epoch: 95 [7680/8000 (96%)]\tTotal Loss: 0.271154\n",
      "Reconstruction: 0.203828, Regularization: 0.002338, Discriminator: 0.043336; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:57,252 root         INFO     ====> Epoch: 95 Average loss: 0.2447\n",
      "2019-04-09 23:00:57,278 root         INFO     Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 0.253174\n",
      "Reconstruction: 0.185607, Regularization: 0.002572, Discriminator: 0.043341; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:57,379 root         INFO     Train Epoch: 96 [512/8000 (6%)]\tTotal Loss: 0.279159\n",
      "Reconstruction: 0.211377, Regularization: 0.002794, Discriminator: 0.043328; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:57,478 root         INFO     Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 0.241126\n",
      "Reconstruction: 0.174066, Regularization: 0.002087, Discriminator: 0.043322; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:57,574 root         INFO     Train Epoch: 96 [1536/8000 (19%)]\tTotal Loss: 0.230398\n",
      "Reconstruction: 0.163749, Regularization: 0.001662, Discriminator: 0.043322; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:57,672 root         INFO     Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 0.240917\n",
      "Reconstruction: 0.173895, Regularization: 0.002040, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:57,770 root         INFO     Train Epoch: 96 [2560/8000 (32%)]\tTotal Loss: 0.236604\n",
      "Reconstruction: 0.169722, Regularization: 0.001905, Discriminator: 0.043320; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:57,868 root         INFO     Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 0.254174\n",
      "Reconstruction: 0.186819, Regularization: 0.002371, Discriminator: 0.043328; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:57,966 root         INFO     Train Epoch: 96 [3584/8000 (45%)]\tTotal Loss: 0.259035\n",
      "Reconstruction: 0.191535, Regularization: 0.002521, Discriminator: 0.043325; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:58,064 root         INFO     Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 0.218998\n",
      "Reconstruction: 0.152238, Regularization: 0.001783, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:58,161 root         INFO     Train Epoch: 96 [4608/8000 (58%)]\tTotal Loss: 0.218023\n",
      "Reconstruction: 0.151549, Regularization: 0.001500, Discriminator: 0.043321; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:58,260 root         INFO     Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 0.248753\n",
      "Reconstruction: 0.181604, Regularization: 0.002182, Discriminator: 0.043310; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:58,360 root         INFO     Train Epoch: 96 [5632/8000 (70%)]\tTotal Loss: 0.227539\n",
      "Reconstruction: 0.160817, Regularization: 0.001754, Discriminator: 0.043317; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:58,459 root         INFO     Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 0.202971\n",
      "Reconstruction: 0.136569, Regularization: 0.001419, Discriminator: 0.043325; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:58,559 root         INFO     Train Epoch: 96 [6656/8000 (83%)]\tTotal Loss: 0.270473\n",
      "Reconstruction: 0.202748, Regularization: 0.002713, Discriminator: 0.043353; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:58,658 root         INFO     Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 0.270155\n",
      "Reconstruction: 0.202444, Regularization: 0.002714, Discriminator: 0.043337; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:58,757 root         INFO     Train Epoch: 96 [7680/8000 (96%)]\tTotal Loss: 0.318531\n",
      "Reconstruction: 0.250018, Regularization: 0.003591, Discriminator: 0.043264; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:58,831 root         INFO     ====> Epoch: 96 Average loss: 0.2452\n",
      "2019-04-09 23:00:58,857 root         INFO     Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 0.243042\n",
      "Reconstruction: 0.175972, Regularization: 0.002085, Discriminator: 0.043326; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:58,959 root         INFO     Train Epoch: 97 [512/8000 (6%)]\tTotal Loss: 0.263019\n",
      "Reconstruction: 0.195558, Regularization: 0.002474, Discriminator: 0.043329; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:59,062 root         INFO     Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 0.275681\n",
      "Reconstruction: 0.208006, Regularization: 0.002732, Discriminator: 0.043280; Generator: 0.021663,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:59,164 root         INFO     Train Epoch: 97 [1536/8000 (19%)]\tTotal Loss: 0.244633\n",
      "Reconstruction: 0.177503, Regularization: 0.002145, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:59,265 root         INFO     Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 0.197179\n",
      "Reconstruction: 0.131164, Regularization: 0.001042, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:59,367 root         INFO     Train Epoch: 97 [2560/8000 (32%)]\tTotal Loss: 0.251442\n",
      "Reconstruction: 0.183896, Regularization: 0.002587, Discriminator: 0.043301; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:59,468 root         INFO     Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 0.246534\n",
      "Reconstruction: 0.179596, Regularization: 0.001961, Discriminator: 0.043311; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:59,567 root         INFO     Train Epoch: 97 [3584/8000 (45%)]\tTotal Loss: 0.272224\n",
      "Reconstruction: 0.204309, Regularization: 0.002952, Discriminator: 0.043308; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:59,666 root         INFO     Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 0.225233\n",
      "Reconstruction: 0.158435, Regularization: 0.001866, Discriminator: 0.043271; Generator: 0.021662,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:00:59,766 root         INFO     Train Epoch: 97 [4608/8000 (58%)]\tTotal Loss: 0.300218\n",
      "Reconstruction: 0.231802, Regularization: 0.003445, Discriminator: 0.043315; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:59,866 root         INFO     Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 0.231527\n",
      "Reconstruction: 0.164559, Regularization: 0.002002, Discriminator: 0.043305; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:00:59,965 root         INFO     Train Epoch: 97 [5632/8000 (70%)]\tTotal Loss: 0.231873\n",
      "Reconstruction: 0.165045, Regularization: 0.001868, Discriminator: 0.043301; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:00,064 root         INFO     Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 0.205813\n",
      "Reconstruction: 0.139431, Regularization: 0.001391, Discriminator: 0.043324; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:00,164 root         INFO     Train Epoch: 97 [6656/8000 (83%)]\tTotal Loss: 0.242925\n",
      "Reconstruction: 0.175780, Regularization: 0.002229, Discriminator: 0.043254; Generator: 0.021662,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:00,262 root         INFO     Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 0.221974\n",
      "Reconstruction: 0.155303, Regularization: 0.001653, Discriminator: 0.043356; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:00,361 root         INFO     Train Epoch: 97 [7680/8000 (96%)]\tTotal Loss: 0.236420\n",
      "Reconstruction: 0.169383, Regularization: 0.002054, Discriminator: 0.043318; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:00,434 root         INFO     ====> Epoch: 97 Average loss: 0.2447\n",
      "2019-04-09 23:01:00,461 root         INFO     Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 0.296767\n",
      "Reconstruction: 0.228646, Regularization: 0.003189, Discriminator: 0.043269; Generator: 0.021662,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:00,561 root         INFO     Train Epoch: 98 [512/8000 (6%)]\tTotal Loss: 0.290014\n",
      "Reconstruction: 0.221759, Regularization: 0.003258, Discriminator: 0.043337; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:00,662 root         INFO     Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 0.243544\n",
      "Reconstruction: 0.176502, Regularization: 0.002075, Discriminator: 0.043301; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:00,761 root         INFO     Train Epoch: 98 [1536/8000 (19%)]\tTotal Loss: 0.333953\n",
      "Reconstruction: 0.265081, Regularization: 0.003841, Discriminator: 0.043362; Generator: 0.021669,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:00,861 root         INFO     Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 0.252243\n",
      "Reconstruction: 0.184756, Regularization: 0.002473, Discriminator: 0.043352; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:00,961 root         INFO     Train Epoch: 98 [2560/8000 (32%)]\tTotal Loss: 0.224989\n",
      "Reconstruction: 0.158369, Regularization: 0.001659, Discriminator: 0.043300; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:01,061 root         INFO     Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 0.262589\n",
      "Reconstruction: 0.194855, Regularization: 0.002798, Discriminator: 0.043282; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:01,160 root         INFO     Train Epoch: 98 [3584/8000 (45%)]\tTotal Loss: 0.245167\n",
      "Reconstruction: 0.177967, Regularization: 0.002261, Discriminator: 0.043267; Generator: 0.021672,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:01,260 root         INFO     Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 0.226534\n",
      "Reconstruction: 0.159661, Regularization: 0.001915, Discriminator: 0.043300; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:01,360 root         INFO     Train Epoch: 98 [4608/8000 (58%)]\tTotal Loss: 0.263526\n",
      "Reconstruction: 0.195748, Regularization: 0.002789, Discriminator: 0.043332; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:01,459 root         INFO     Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 0.248721\n",
      "Reconstruction: 0.181508, Regularization: 0.002279, Discriminator: 0.043268; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:01,557 root         INFO     Train Epoch: 98 [5632/8000 (70%)]\tTotal Loss: 0.291797\n",
      "Reconstruction: 0.223495, Regularization: 0.003255, Discriminator: 0.043391; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:01,659 root         INFO     Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 0.259154\n",
      "Reconstruction: 0.191800, Regularization: 0.002408, Discriminator: 0.043274; Generator: 0.021671,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:01,761 root         INFO     Train Epoch: 98 [6656/8000 (83%)]\tTotal Loss: 0.266563\n",
      "Reconstruction: 0.198728, Regularization: 0.002846, Discriminator: 0.043331; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:01,865 root         INFO     Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 0.253116\n",
      "Reconstruction: 0.185864, Regularization: 0.002224, Discriminator: 0.043363; Generator: 0.021666,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:01,970 root         INFO     Train Epoch: 98 [7680/8000 (96%)]\tTotal Loss: 0.255986\n",
      "Reconstruction: 0.188783, Regularization: 0.002269, Discriminator: 0.043268; Generator: 0.021665,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:02,045 root         INFO     ====> Epoch: 98 Average loss: 0.2445\n",
      "2019-04-09 23:01:02,072 root         INFO     Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 0.235253\n",
      "Reconstruction: 0.168128, Regularization: 0.002194, Discriminator: 0.043275; Generator: 0.021656,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:02,173 root         INFO     Train Epoch: 99 [512/8000 (6%)]\tTotal Loss: 0.209576\n",
      "Reconstruction: 0.143023, Regularization: 0.001549, Discriminator: 0.043347; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:02,273 root         INFO     Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 0.241245\n",
      "Reconstruction: 0.173924, Regularization: 0.002268, Discriminator: 0.043396; Generator: 0.021657,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:02,373 root         INFO     Train Epoch: 99 [1536/8000 (19%)]\tTotal Loss: 0.227284\n",
      "Reconstruction: 0.160085, Regularization: 0.002141, Discriminator: 0.043397; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:02,472 root         INFO     Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 0.227468\n",
      "Reconstruction: 0.160582, Regularization: 0.001868, Discriminator: 0.043358; Generator: 0.021661,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:02,571 root         INFO     Train Epoch: 99 [2560/8000 (32%)]\tTotal Loss: 0.225004\n",
      "Reconstruction: 0.158033, Regularization: 0.001941, Discriminator: 0.043363; Generator: 0.021667,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:02,670 root         INFO     Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 0.237502\n",
      "Reconstruction: 0.170410, Regularization: 0.002106, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:02,769 root         INFO     Train Epoch: 99 [3584/8000 (45%)]\tTotal Loss: 0.218454\n",
      "Reconstruction: 0.151612, Regularization: 0.001845, Discriminator: 0.043334; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:02,868 root         INFO     Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 0.238026\n",
      "Reconstruction: 0.170927, Regularization: 0.002139, Discriminator: 0.043304; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:02,968 root         INFO     Train Epoch: 99 [4608/8000 (58%)]\tTotal Loss: 0.260303\n",
      "Reconstruction: 0.192494, Regularization: 0.002850, Discriminator: 0.043302; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:03,066 root         INFO     Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 0.257810\n",
      "Reconstruction: 0.190357, Regularization: 0.002429, Discriminator: 0.043361; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:03,165 root         INFO     Train Epoch: 99 [5632/8000 (70%)]\tTotal Loss: 0.208640\n",
      "Reconstruction: 0.142235, Regularization: 0.001376, Discriminator: 0.043365; Generator: 0.021664,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:03,264 root         INFO     Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 0.248824\n",
      "Reconstruction: 0.181645, Regularization: 0.002218, Discriminator: 0.043303; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:03,363 root         INFO     Train Epoch: 99 [6656/8000 (83%)]\tTotal Loss: 0.245727\n",
      "Reconstruction: 0.178548, Regularization: 0.002171, Discriminator: 0.043347; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:03,461 root         INFO     Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 0.217606\n",
      "Reconstruction: 0.150906, Regularization: 0.001699, Discriminator: 0.043342; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:03,562 root         INFO     Train Epoch: 99 [7680/8000 (96%)]\tTotal Loss: 0.257987\n",
      "Reconstruction: 0.190049, Regularization: 0.002974, Discriminator: 0.043298; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:03,636 root         INFO     ====> Epoch: 99 Average loss: 0.2443\n",
      "2019-04-09 23:01:03,662 root         INFO     Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 0.214306\n",
      "Reconstruction: 0.147389, Regularization: 0.001950, Discriminator: 0.043305; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:03,764 root         INFO     Train Epoch: 100 [512/8000 (6%)]\tTotal Loss: 0.264733\n",
      "Reconstruction: 0.196915, Regularization: 0.002807, Discriminator: 0.043350; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:03,869 root         INFO     Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 0.256830\n",
      "Reconstruction: 0.189013, Regularization: 0.002817, Discriminator: 0.043338; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:03,968 root         INFO     Train Epoch: 100 [1536/8000 (19%)]\tTotal Loss: 0.273146\n",
      "Reconstruction: 0.205199, Regularization: 0.002921, Discriminator: 0.043364; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:04,065 root         INFO     Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 0.233557\n",
      "Reconstruction: 0.166282, Regularization: 0.002301, Discriminator: 0.043309; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:04,163 root         INFO     Train Epoch: 100 [2560/8000 (32%)]\tTotal Loss: 0.229095\n",
      "Reconstruction: 0.162138, Regularization: 0.001975, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:04,260 root         INFO     Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 0.249715\n",
      "Reconstruction: 0.182085, Regularization: 0.002633, Discriminator: 0.043329; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:04,358 root         INFO     Train Epoch: 100 [3584/8000 (45%)]\tTotal Loss: 0.232981\n",
      "Reconstruction: 0.165937, Regularization: 0.002065, Discriminator: 0.043317; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:04,455 root         INFO     Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 0.254605\n",
      "Reconstruction: 0.186708, Regularization: 0.002907, Discriminator: 0.043323; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:04,552 root         INFO     Train Epoch: 100 [4608/8000 (58%)]\tTotal Loss: 0.254833\n",
      "Reconstruction: 0.186917, Regularization: 0.002928, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:04,650 root         INFO     Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 0.237608\n",
      "Reconstruction: 0.170283, Regularization: 0.002351, Discriminator: 0.043323; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:04,747 root         INFO     Train Epoch: 100 [5632/8000 (70%)]\tTotal Loss: 0.277631\n",
      "Reconstruction: 0.209226, Regularization: 0.003422, Discriminator: 0.043321; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:04,846 root         INFO     Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 0.256452\n",
      "Reconstruction: 0.188500, Regularization: 0.002973, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:04,946 root         INFO     Train Epoch: 100 [6656/8000 (83%)]\tTotal Loss: 0.258848\n",
      "Reconstruction: 0.190927, Regularization: 0.002936, Discriminator: 0.043323; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:05,044 root         INFO     Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 0.232044\n",
      "Reconstruction: 0.164786, Regularization: 0.002276, Discriminator: 0.043316; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:05,141 root         INFO     Train Epoch: 100 [7680/8000 (96%)]\tTotal Loss: 0.227202\n",
      "Reconstruction: 0.160064, Regularization: 0.002151, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:05,214 root         INFO     ====> Epoch: 100 Average loss: 0.2447\n",
      "2019-04-09 23:01:05,241 root         INFO     Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 0.245311\n",
      "Reconstruction: 0.177959, Regularization: 0.002369, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:05,341 root         INFO     Train Epoch: 101 [512/8000 (6%)]\tTotal Loss: 0.268178\n",
      "Reconstruction: 0.200044, Regularization: 0.003169, Discriminator: 0.043301; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:05,440 root         INFO     Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 0.225085\n",
      "Reconstruction: 0.158040, Regularization: 0.002044, Discriminator: 0.043324; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:05,540 root         INFO     Train Epoch: 101 [1536/8000 (19%)]\tTotal Loss: 0.209792\n",
      "Reconstruction: 0.142978, Regularization: 0.001828, Discriminator: 0.043319; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:05,637 root         INFO     Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 0.263313\n",
      "Reconstruction: 0.195192, Regularization: 0.003146, Discriminator: 0.043316; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:05,735 root         INFO     Train Epoch: 101 [2560/8000 (32%)]\tTotal Loss: 0.213206\n",
      "Reconstruction: 0.146311, Regularization: 0.001891, Discriminator: 0.043338; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:05,832 root         INFO     Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 0.206938\n",
      "Reconstruction: 0.140406, Regularization: 0.001539, Discriminator: 0.043332; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:05,928 root         INFO     Train Epoch: 101 [3584/8000 (45%)]\tTotal Loss: 0.226734\n",
      "Reconstruction: 0.159423, Regularization: 0.002338, Discriminator: 0.043310; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:06,025 root         INFO     Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 0.236652\n",
      "Reconstruction: 0.169272, Regularization: 0.002393, Discriminator: 0.043317; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:06,121 root         INFO     Train Epoch: 101 [4608/8000 (58%)]\tTotal Loss: 0.278852\n",
      "Reconstruction: 0.210317, Regularization: 0.003585, Discriminator: 0.043302; Generator: 0.021648,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:06,217 root         INFO     Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 0.231646\n",
      "Reconstruction: 0.164348, Regularization: 0.002313, Discriminator: 0.043309; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:06,313 root         INFO     Train Epoch: 101 [5632/8000 (70%)]\tTotal Loss: 0.235156\n",
      "Reconstruction: 0.167705, Regularization: 0.002423, Discriminator: 0.043365; Generator: 0.021664,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:06,409 root         INFO     Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 0.257198\n",
      "Reconstruction: 0.189336, Regularization: 0.002853, Discriminator: 0.043348; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:06,504 root         INFO     Train Epoch: 101 [6656/8000 (83%)]\tTotal Loss: 0.255673\n",
      "Reconstruction: 0.187970, Regularization: 0.002752, Discriminator: 0.043286; Generator: 0.021664,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:06,599 root         INFO     Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 0.236813\n",
      "Reconstruction: 0.169656, Regularization: 0.002153, Discriminator: 0.043347; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:06,694 root         INFO     Train Epoch: 101 [7680/8000 (96%)]\tTotal Loss: 0.240740\n",
      "Reconstruction: 0.173254, Regularization: 0.002481, Discriminator: 0.043352; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:06,766 root         INFO     ====> Epoch: 101 Average loss: 0.2444\n",
      "2019-04-09 23:01:06,792 root         INFO     Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 0.256513\n",
      "Reconstruction: 0.188601, Regularization: 0.002916, Discriminator: 0.043332; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:06,892 root         INFO     Train Epoch: 102 [512/8000 (6%)]\tTotal Loss: 0.221512\n",
      "Reconstruction: 0.154439, Regularization: 0.002132, Discriminator: 0.043289; Generator: 0.021652,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:06,991 root         INFO     Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 0.296139\n",
      "Reconstruction: 0.227299, Regularization: 0.003841, Discriminator: 0.043332; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:07,090 root         INFO     Train Epoch: 102 [1536/8000 (19%)]\tTotal Loss: 0.251211\n",
      "Reconstruction: 0.183875, Regularization: 0.002344, Discriminator: 0.043321; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:07,188 root         INFO     Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 0.258284\n",
      "Reconstruction: 0.190223, Regularization: 0.003058, Discriminator: 0.043346; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:07,287 root         INFO     Train Epoch: 102 [2560/8000 (32%)]\tTotal Loss: 0.204693\n",
      "Reconstruction: 0.138073, Regularization: 0.001654, Discriminator: 0.043310; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:07,386 root         INFO     Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 0.275568\n",
      "Reconstruction: 0.207282, Regularization: 0.003330, Discriminator: 0.043289; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:07,485 root         INFO     Train Epoch: 102 [3584/8000 (45%)]\tTotal Loss: 0.290727\n",
      "Reconstruction: 0.221836, Regularization: 0.003928, Discriminator: 0.043300; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:07,585 root         INFO     Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 0.277021\n",
      "Reconstruction: 0.208850, Regularization: 0.003225, Discriminator: 0.043301; Generator: 0.021645,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:07,686 root         INFO     Train Epoch: 102 [4608/8000 (58%)]\tTotal Loss: 0.258960\n",
      "Reconstruction: 0.191330, Regularization: 0.002647, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:07,789 root         INFO     Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 0.267123\n",
      "Reconstruction: 0.199148, Regularization: 0.003021, Discriminator: 0.043298; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:07,889 root         INFO     Train Epoch: 102 [5632/8000 (70%)]\tTotal Loss: 0.230697\n",
      "Reconstruction: 0.163624, Regularization: 0.002116, Discriminator: 0.043300; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:07,989 root         INFO     Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 0.230451\n",
      "Reconstruction: 0.163069, Regularization: 0.002365, Discriminator: 0.043355; Generator: 0.021661,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:08,089 root         INFO     Train Epoch: 102 [6656/8000 (83%)]\tTotal Loss: 0.286802\n",
      "Reconstruction: 0.218111, Regularization: 0.003717, Discriminator: 0.043319; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:08,186 root         INFO     Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 0.242067\n",
      "Reconstruction: 0.174556, Regularization: 0.002503, Discriminator: 0.043341; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:08,286 root         INFO     Train Epoch: 102 [7680/8000 (96%)]\tTotal Loss: 0.232312\n",
      "Reconstruction: 0.165136, Regularization: 0.002210, Discriminator: 0.043315; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:08,360 root         INFO     ====> Epoch: 102 Average loss: 0.2444\n",
      "2019-04-09 23:01:08,387 root         INFO     Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 0.228087\n",
      "Reconstruction: 0.160864, Regularization: 0.002214, Discriminator: 0.043343; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:08,488 root         INFO     Train Epoch: 103 [512/8000 (6%)]\tTotal Loss: 0.218335\n",
      "Reconstruction: 0.151785, Regularization: 0.001561, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:08,590 root         INFO     Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 0.292612\n",
      "Reconstruction: 0.223970, Regularization: 0.003625, Discriminator: 0.043371; Generator: 0.021646,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:08,689 root         INFO     Train Epoch: 103 [1536/8000 (19%)]\tTotal Loss: 0.216008\n",
      "Reconstruction: 0.149001, Regularization: 0.002002, Discriminator: 0.043340; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:08,787 root         INFO     Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 0.229633\n",
      "Reconstruction: 0.162428, Regularization: 0.002222, Discriminator: 0.043334; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:08,883 root         INFO     Train Epoch: 103 [2560/8000 (32%)]\tTotal Loss: 0.208670\n",
      "Reconstruction: 0.142076, Regularization: 0.001610, Discriminator: 0.043328; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:08,981 root         INFO     Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 0.272478\n",
      "Reconstruction: 0.204274, Regularization: 0.003200, Discriminator: 0.043339; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:09,078 root         INFO     Train Epoch: 103 [3584/8000 (45%)]\tTotal Loss: 0.247829\n",
      "Reconstruction: 0.180227, Regularization: 0.002630, Discriminator: 0.043315; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:09,176 root         INFO     Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 0.306757\n",
      "Reconstruction: 0.237864, Regularization: 0.003922, Discriminator: 0.043313; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:09,273 root         INFO     Train Epoch: 103 [4608/8000 (58%)]\tTotal Loss: 0.225762\n",
      "Reconstruction: 0.158617, Regularization: 0.002158, Discriminator: 0.043323; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:09,370 root         INFO     Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 0.266158\n",
      "Reconstruction: 0.198279, Regularization: 0.002905, Discriminator: 0.043320; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:09,470 root         INFO     Train Epoch: 103 [5632/8000 (70%)]\tTotal Loss: 0.280148\n",
      "Reconstruction: 0.211717, Regularization: 0.003454, Discriminator: 0.043313; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:09,569 root         INFO     Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 0.257286\n",
      "Reconstruction: 0.189381, Regularization: 0.002939, Discriminator: 0.043307; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:09,667 root         INFO     Train Epoch: 103 [6656/8000 (83%)]\tTotal Loss: 0.275241\n",
      "Reconstruction: 0.207038, Regularization: 0.003212, Discriminator: 0.043330; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:09,766 root         INFO     Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 0.247589\n",
      "Reconstruction: 0.180209, Regularization: 0.002413, Discriminator: 0.043301; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:09,866 root         INFO     Train Epoch: 103 [7680/8000 (96%)]\tTotal Loss: 0.264154\n",
      "Reconstruction: 0.196447, Regularization: 0.002717, Discriminator: 0.043340; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:09,942 root         INFO     ====> Epoch: 103 Average loss: 0.2443\n",
      "2019-04-09 23:01:09,968 root         INFO     Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 0.301144\n",
      "Reconstruction: 0.232426, Regularization: 0.003740, Discriminator: 0.043321; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:10,066 root         INFO     Train Epoch: 104 [512/8000 (6%)]\tTotal Loss: 0.240816\n",
      "Reconstruction: 0.173650, Regularization: 0.002195, Discriminator: 0.043312; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:10,163 root         INFO     Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 0.239281\n",
      "Reconstruction: 0.171914, Regularization: 0.002378, Discriminator: 0.043331; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:10,260 root         INFO     Train Epoch: 104 [1536/8000 (19%)]\tTotal Loss: 0.214534\n",
      "Reconstruction: 0.148064, Regularization: 0.001493, Discriminator: 0.043321; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:10,357 root         INFO     Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 0.219245\n",
      "Reconstruction: 0.152643, Regularization: 0.001619, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:10,456 root         INFO     Train Epoch: 104 [2560/8000 (32%)]\tTotal Loss: 0.286041\n",
      "Reconstruction: 0.217674, Regularization: 0.003380, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:10,553 root         INFO     Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 0.282642\n",
      "Reconstruction: 0.214542, Regularization: 0.003120, Discriminator: 0.043314; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:10,650 root         INFO     Train Epoch: 104 [3584/8000 (45%)]\tTotal Loss: 0.211044\n",
      "Reconstruction: 0.144492, Regularization: 0.001567, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:10,746 root         INFO     Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 0.245586\n",
      "Reconstruction: 0.178080, Regularization: 0.002525, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:10,843 root         INFO     Train Epoch: 104 [4608/8000 (58%)]\tTotal Loss: 0.250584\n",
      "Reconstruction: 0.182977, Regularization: 0.002631, Discriminator: 0.043322; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:10,942 root         INFO     Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 0.245845\n",
      "Reconstruction: 0.178429, Regularization: 0.002435, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:11,040 root         INFO     Train Epoch: 104 [5632/8000 (70%)]\tTotal Loss: 0.210761\n",
      "Reconstruction: 0.143933, Regularization: 0.001858, Discriminator: 0.043313; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:11,138 root         INFO     Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 0.231509\n",
      "Reconstruction: 0.164221, Regularization: 0.002331, Discriminator: 0.043297; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:11,234 root         INFO     Train Epoch: 104 [6656/8000 (83%)]\tTotal Loss: 0.262593\n",
      "Reconstruction: 0.194877, Regularization: 0.002742, Discriminator: 0.043314; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:11,330 root         INFO     Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 0.213140\n",
      "Reconstruction: 0.146570, Regularization: 0.001603, Discriminator: 0.043306; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:11,426 root         INFO     Train Epoch: 104 [7680/8000 (96%)]\tTotal Loss: 0.269432\n",
      "Reconstruction: 0.201411, Regularization: 0.003047, Discriminator: 0.043311; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:11,500 root         INFO     ====> Epoch: 104 Average loss: 0.2443\n",
      "2019-04-09 23:01:11,526 root         INFO     Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 0.240229\n",
      "Reconstruction: 0.172773, Regularization: 0.002477, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:11,624 root         INFO     Train Epoch: 105 [512/8000 (6%)]\tTotal Loss: 0.254994\n",
      "Reconstruction: 0.187303, Regularization: 0.002711, Discriminator: 0.043318; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:11,720 root         INFO     Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 0.262796\n",
      "Reconstruction: 0.195309, Regularization: 0.002516, Discriminator: 0.043310; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:11,817 root         INFO     Train Epoch: 105 [1536/8000 (19%)]\tTotal Loss: 0.232369\n",
      "Reconstruction: 0.165257, Regularization: 0.002131, Discriminator: 0.043319; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:11,913 root         INFO     Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 0.247921\n",
      "Reconstruction: 0.180552, Regularization: 0.002390, Discriminator: 0.043317; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:12,010 root         INFO     Train Epoch: 105 [2560/8000 (32%)]\tTotal Loss: 0.227896\n",
      "Reconstruction: 0.161041, Regularization: 0.001887, Discriminator: 0.043306; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:12,108 root         INFO     Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 0.213514\n",
      "Reconstruction: 0.146680, Regularization: 0.001845, Discriminator: 0.043331; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:12,205 root         INFO     Train Epoch: 105 [3584/8000 (45%)]\tTotal Loss: 0.280060\n",
      "Reconstruction: 0.211950, Regularization: 0.003112, Discriminator: 0.043337; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:12,301 root         INFO     Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 0.231605\n",
      "Reconstruction: 0.164372, Regularization: 0.002253, Discriminator: 0.043319; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:12,398 root         INFO     Train Epoch: 105 [4608/8000 (58%)]\tTotal Loss: 0.230054\n",
      "Reconstruction: 0.162956, Regularization: 0.002109, Discriminator: 0.043329; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:12,494 root         INFO     Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 0.307845\n",
      "Reconstruction: 0.239249, Regularization: 0.003606, Discriminator: 0.043329; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:12,591 root         INFO     Train Epoch: 105 [5632/8000 (70%)]\tTotal Loss: 0.234799\n",
      "Reconstruction: 0.167591, Regularization: 0.002233, Discriminator: 0.043311; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:12,688 root         INFO     Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 0.232686\n",
      "Reconstruction: 0.165450, Regularization: 0.002256, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:12,786 root         INFO     Train Epoch: 105 [6656/8000 (83%)]\tTotal Loss: 0.201883\n",
      "Reconstruction: 0.135576, Regularization: 0.001326, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:12,885 root         INFO     Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 0.262540\n",
      "Reconstruction: 0.194982, Regularization: 0.002567, Discriminator: 0.043327; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:12,984 root         INFO     Train Epoch: 105 [7680/8000 (96%)]\tTotal Loss: 0.232145\n",
      "Reconstruction: 0.164747, Regularization: 0.002431, Discriminator: 0.043306; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:13,059 root         INFO     ====> Epoch: 105 Average loss: 0.2444\n",
      "2019-04-09 23:01:13,085 root         INFO     Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 0.233714\n",
      "Reconstruction: 0.166910, Regularization: 0.001800, Discriminator: 0.043351; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:13,186 root         INFO     Train Epoch: 106 [512/8000 (6%)]\tTotal Loss: 0.276147\n",
      "Reconstruction: 0.207988, Regularization: 0.003197, Discriminator: 0.043302; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:13,287 root         INFO     Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 0.233463\n",
      "Reconstruction: 0.166529, Regularization: 0.001963, Discriminator: 0.043309; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:13,384 root         INFO     Train Epoch: 106 [1536/8000 (19%)]\tTotal Loss: 0.233349\n",
      "Reconstruction: 0.166491, Regularization: 0.001911, Discriminator: 0.043277; Generator: 0.021669,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:13,481 root         INFO     Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 0.233993\n",
      "Reconstruction: 0.166898, Regularization: 0.002168, Discriminator: 0.043261; Generator: 0.021665,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:13,580 root         INFO     Train Epoch: 106 [2560/8000 (32%)]\tTotal Loss: 0.260577\n",
      "Reconstruction: 0.192976, Regularization: 0.002647, Discriminator: 0.043297; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:13,677 root         INFO     Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 0.255507\n",
      "Reconstruction: 0.187962, Regularization: 0.002555, Discriminator: 0.043332; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:13,774 root         INFO     Train Epoch: 106 [3584/8000 (45%)]\tTotal Loss: 0.233272\n",
      "Reconstruction: 0.166172, Regularization: 0.002091, Discriminator: 0.043349; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:13,873 root         INFO     Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 0.234493\n",
      "Reconstruction: 0.167273, Regularization: 0.002237, Discriminator: 0.043318; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:13,970 root         INFO     Train Epoch: 106 [4608/8000 (58%)]\tTotal Loss: 0.240937\n",
      "Reconstruction: 0.173794, Regularization: 0.002182, Discriminator: 0.043304; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:14,066 root         INFO     Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 0.267949\n",
      "Reconstruction: 0.200063, Regularization: 0.002886, Discriminator: 0.043340; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:14,163 root         INFO     Train Epoch: 106 [5632/8000 (70%)]\tTotal Loss: 0.302547\n",
      "Reconstruction: 0.234073, Regularization: 0.003502, Discriminator: 0.043309; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:14,259 root         INFO     Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 0.243565\n",
      "Reconstruction: 0.176110, Regularization: 0.002486, Discriminator: 0.043307; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:14,356 root         INFO     Train Epoch: 106 [6656/8000 (83%)]\tTotal Loss: 0.260204\n",
      "Reconstruction: 0.192471, Regularization: 0.002750, Discriminator: 0.043326; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:14,452 root         INFO     Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 0.205932\n",
      "Reconstruction: 0.139571, Regularization: 0.001358, Discriminator: 0.043343; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:14,550 root         INFO     Train Epoch: 106 [7680/8000 (96%)]\tTotal Loss: 0.217024\n",
      "Reconstruction: 0.150158, Regularization: 0.001896, Discriminator: 0.043310; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:14,623 root         INFO     ====> Epoch: 106 Average loss: 0.2443\n",
      "2019-04-09 23:01:14,649 root         INFO     Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 0.247674\n",
      "Reconstruction: 0.180014, Regularization: 0.002662, Discriminator: 0.043340; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:14,749 root         INFO     Train Epoch: 107 [512/8000 (6%)]\tTotal Loss: 0.264762\n",
      "Reconstruction: 0.197080, Regularization: 0.002706, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:14,848 root         INFO     Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 0.279513\n",
      "Reconstruction: 0.211561, Regularization: 0.002988, Discriminator: 0.043307; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:14,946 root         INFO     Train Epoch: 107 [1536/8000 (19%)]\tTotal Loss: 0.231076\n",
      "Reconstruction: 0.163728, Regularization: 0.002370, Discriminator: 0.043320; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:15,042 root         INFO     Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 0.255093\n",
      "Reconstruction: 0.187443, Regularization: 0.002662, Discriminator: 0.043326; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:15,138 root         INFO     Train Epoch: 107 [2560/8000 (32%)]\tTotal Loss: 0.240024\n",
      "Reconstruction: 0.172870, Regularization: 0.002163, Discriminator: 0.043325; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:15,238 root         INFO     Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 0.233490\n",
      "Reconstruction: 0.166306, Regularization: 0.002201, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:15,337 root         INFO     Train Epoch: 107 [3584/8000 (45%)]\tTotal Loss: 0.229318\n",
      "Reconstruction: 0.162349, Regularization: 0.001987, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:15,436 root         INFO     Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 0.238298\n",
      "Reconstruction: 0.171199, Regularization: 0.002117, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:15,535 root         INFO     Train Epoch: 107 [4608/8000 (58%)]\tTotal Loss: 0.196726\n",
      "Reconstruction: 0.130181, Regularization: 0.001558, Discriminator: 0.043322; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:15,634 root         INFO     Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 0.196649\n",
      "Reconstruction: 0.130489, Regularization: 0.001180, Discriminator: 0.043319; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:15,732 root         INFO     Train Epoch: 107 [5632/8000 (70%)]\tTotal Loss: 0.218277\n",
      "Reconstruction: 0.151197, Regularization: 0.002100, Discriminator: 0.043323; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:15,831 root         INFO     Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 0.281033\n",
      "Reconstruction: 0.212422, Regularization: 0.003627, Discriminator: 0.043324; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:15,930 root         INFO     Train Epoch: 107 [6656/8000 (83%)]\tTotal Loss: 0.230661\n",
      "Reconstruction: 0.163562, Regularization: 0.002113, Discriminator: 0.043319; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:16,030 root         INFO     Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 0.274626\n",
      "Reconstruction: 0.206088, Regularization: 0.003568, Discriminator: 0.043312; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:16,129 root         INFO     Train Epoch: 107 [7680/8000 (96%)]\tTotal Loss: 0.215018\n",
      "Reconstruction: 0.148189, Regularization: 0.001862, Discriminator: 0.043320; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:16,204 root         INFO     ====> Epoch: 107 Average loss: 0.2445\n",
      "2019-04-09 23:01:16,231 root         INFO     Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 0.211312\n",
      "Reconstruction: 0.144402, Regularization: 0.001927, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:16,333 root         INFO     Train Epoch: 108 [512/8000 (6%)]\tTotal Loss: 0.216890\n",
      "Reconstruction: 0.149804, Regularization: 0.002094, Discriminator: 0.043328; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:16,434 root         INFO     Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 0.237607\n",
      "Reconstruction: 0.170087, Regularization: 0.002529, Discriminator: 0.043324; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:16,535 root         INFO     Train Epoch: 108 [1536/8000 (19%)]\tTotal Loss: 0.228825\n",
      "Reconstruction: 0.161652, Regularization: 0.002200, Discriminator: 0.043299; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:16,636 root         INFO     Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 0.244628\n",
      "Reconstruction: 0.177246, Regularization: 0.002395, Discriminator: 0.043314; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:16,737 root         INFO     Train Epoch: 108 [2560/8000 (32%)]\tTotal Loss: 0.266861\n",
      "Reconstruction: 0.198947, Regularization: 0.002908, Discriminator: 0.043333; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:16,838 root         INFO     Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 0.225475\n",
      "Reconstruction: 0.158389, Regularization: 0.002096, Discriminator: 0.043328; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:16,939 root         INFO     Train Epoch: 108 [3584/8000 (45%)]\tTotal Loss: 0.217133\n",
      "Reconstruction: 0.150075, Regularization: 0.002044, Discriminator: 0.043342; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:17,037 root         INFO     Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 0.286859\n",
      "Reconstruction: 0.218372, Regularization: 0.003505, Discriminator: 0.043313; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:17,133 root         INFO     Train Epoch: 108 [4608/8000 (58%)]\tTotal Loss: 0.241621\n",
      "Reconstruction: 0.173928, Regularization: 0.002712, Discriminator: 0.043317; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:17,230 root         INFO     Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 0.294593\n",
      "Reconstruction: 0.225961, Regularization: 0.003602, Discriminator: 0.043372; Generator: 0.021658,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:17,326 root         INFO     Train Epoch: 108 [5632/8000 (70%)]\tTotal Loss: 0.229197\n",
      "Reconstruction: 0.161937, Regularization: 0.002296, Discriminator: 0.043307; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:17,422 root         INFO     Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 0.267228\n",
      "Reconstruction: 0.198947, Regularization: 0.003288, Discriminator: 0.043322; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:17,518 root         INFO     Train Epoch: 108 [6656/8000 (83%)]\tTotal Loss: 0.264762\n",
      "Reconstruction: 0.196876, Regularization: 0.002920, Discriminator: 0.043313; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:17,614 root         INFO     Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 0.227931\n",
      "Reconstruction: 0.160754, Regularization: 0.002222, Discriminator: 0.043305; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:17,710 root         INFO     Train Epoch: 108 [7680/8000 (96%)]\tTotal Loss: 0.251907\n",
      "Reconstruction: 0.183897, Regularization: 0.003016, Discriminator: 0.043334; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:17,782 root         INFO     ====> Epoch: 108 Average loss: 0.2444\n",
      "2019-04-09 23:01:17,808 root         INFO     Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 0.236719\n",
      "Reconstruction: 0.169374, Regularization: 0.002379, Discriminator: 0.043313; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:17,909 root         INFO     Train Epoch: 109 [512/8000 (6%)]\tTotal Loss: 0.231411\n",
      "Reconstruction: 0.164357, Regularization: 0.002051, Discriminator: 0.043333; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:18,009 root         INFO     Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 0.232803\n",
      "Reconstruction: 0.165690, Regularization: 0.002103, Discriminator: 0.043344; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:18,109 root         INFO     Train Epoch: 109 [1536/8000 (19%)]\tTotal Loss: 0.254104\n",
      "Reconstruction: 0.186676, Regularization: 0.002435, Discriminator: 0.043341; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:18,208 root         INFO     Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 0.268543\n",
      "Reconstruction: 0.200865, Regularization: 0.002693, Discriminator: 0.043315; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:18,308 root         INFO     Train Epoch: 109 [2560/8000 (32%)]\tTotal Loss: 0.255479\n",
      "Reconstruction: 0.187838, Regularization: 0.002655, Discriminator: 0.043330; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:18,408 root         INFO     Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 0.245273\n",
      "Reconstruction: 0.177829, Regularization: 0.002443, Discriminator: 0.043348; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:18,508 root         INFO     Train Epoch: 109 [3584/8000 (45%)]\tTotal Loss: 0.237811\n",
      "Reconstruction: 0.170890, Regularization: 0.001937, Discriminator: 0.043326; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:18,608 root         INFO     Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 0.261265\n",
      "Reconstruction: 0.193220, Regularization: 0.003075, Discriminator: 0.043310; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:18,708 root         INFO     Train Epoch: 109 [4608/8000 (58%)]\tTotal Loss: 0.279917\n",
      "Reconstruction: 0.211677, Regularization: 0.003275, Discriminator: 0.043302; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:18,808 root         INFO     Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 0.204063\n",
      "Reconstruction: 0.137384, Regularization: 0.001710, Discriminator: 0.043304; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:18,908 root         INFO     Train Epoch: 109 [5632/8000 (70%)]\tTotal Loss: 0.187719\n",
      "Reconstruction: 0.121469, Regularization: 0.001268, Discriminator: 0.043327; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:19,008 root         INFO     Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 0.212531\n",
      "Reconstruction: 0.145806, Regularization: 0.001747, Discriminator: 0.043316; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:19,109 root         INFO     Train Epoch: 109 [6656/8000 (83%)]\tTotal Loss: 0.241661\n",
      "Reconstruction: 0.174275, Regularization: 0.002408, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:19,209 root         INFO     Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 0.229609\n",
      "Reconstruction: 0.162447, Regularization: 0.002178, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:19,309 root         INFO     Train Epoch: 109 [7680/8000 (96%)]\tTotal Loss: 0.227917\n",
      "Reconstruction: 0.160960, Regularization: 0.001978, Discriminator: 0.043325; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:19,384 root         INFO     ====> Epoch: 109 Average loss: 0.2445\n",
      "2019-04-09 23:01:19,410 root         INFO     Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 0.253812\n",
      "Reconstruction: 0.186048, Regularization: 0.002788, Discriminator: 0.043312; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:19,512 root         INFO     Train Epoch: 110 [512/8000 (6%)]\tTotal Loss: 0.215864\n",
      "Reconstruction: 0.149077, Regularization: 0.001814, Discriminator: 0.043316; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:19,612 root         INFO     Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 0.244809\n",
      "Reconstruction: 0.177284, Regularization: 0.002555, Discriminator: 0.043312; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:19,708 root         INFO     Train Epoch: 110 [1536/8000 (19%)]\tTotal Loss: 0.231829\n",
      "Reconstruction: 0.164749, Regularization: 0.002099, Discriminator: 0.043325; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:19,807 root         INFO     Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 0.253012\n",
      "Reconstruction: 0.185307, Regularization: 0.002711, Discriminator: 0.043328; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:19,907 root         INFO     Train Epoch: 110 [2560/8000 (32%)]\tTotal Loss: 0.272374\n",
      "Reconstruction: 0.204573, Regularization: 0.002822, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:20,006 root         INFO     Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 0.236099\n",
      "Reconstruction: 0.168711, Regularization: 0.002395, Discriminator: 0.043329; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:20,105 root         INFO     Train Epoch: 110 [3584/8000 (45%)]\tTotal Loss: 0.250345\n",
      "Reconstruction: 0.183296, Regularization: 0.002068, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:20,205 root         INFO     Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 0.246155\n",
      "Reconstruction: 0.178874, Regularization: 0.002298, Discriminator: 0.043317; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:20,304 root         INFO     Train Epoch: 110 [4608/8000 (58%)]\tTotal Loss: 0.212845\n",
      "Reconstruction: 0.146522, Regularization: 0.001335, Discriminator: 0.043328; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:20,403 root         INFO     Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 0.224676\n",
      "Reconstruction: 0.157911, Regularization: 0.001784, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:20,503 root         INFO     Train Epoch: 110 [5632/8000 (70%)]\tTotal Loss: 0.294164\n",
      "Reconstruction: 0.225718, Regularization: 0.003465, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:20,604 root         INFO     Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 0.265278\n",
      "Reconstruction: 0.197412, Regularization: 0.002881, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:20,705 root         INFO     Train Epoch: 110 [6656/8000 (83%)]\tTotal Loss: 0.261124\n",
      "Reconstruction: 0.193346, Regularization: 0.002790, Discriminator: 0.043321; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:20,807 root         INFO     Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 0.268031\n",
      "Reconstruction: 0.200177, Regularization: 0.002866, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:20,910 root         INFO     Train Epoch: 110 [7680/8000 (96%)]\tTotal Loss: 0.274906\n",
      "Reconstruction: 0.206784, Regularization: 0.003133, Discriminator: 0.043325; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:20,987 root         INFO     ====> Epoch: 110 Average loss: 0.2445\n",
      "2019-04-09 23:01:21,013 root         INFO     Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 0.230162\n",
      "Reconstruction: 0.163109, Regularization: 0.002071, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:21,114 root         INFO     Train Epoch: 111 [512/8000 (6%)]\tTotal Loss: 0.282656\n",
      "Reconstruction: 0.214508, Regularization: 0.003175, Discriminator: 0.043314; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:21,215 root         INFO     Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 0.232058\n",
      "Reconstruction: 0.165105, Regularization: 0.001973, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:21,316 root         INFO     Train Epoch: 111 [1536/8000 (19%)]\tTotal Loss: 0.244884\n",
      "Reconstruction: 0.177706, Regularization: 0.002192, Discriminator: 0.043327; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:21,418 root         INFO     Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 0.243194\n",
      "Reconstruction: 0.175924, Regularization: 0.002292, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:21,519 root         INFO     Train Epoch: 111 [2560/8000 (32%)]\tTotal Loss: 0.246255\n",
      "Reconstruction: 0.178639, Regularization: 0.002642, Discriminator: 0.043312; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:21,619 root         INFO     Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 0.235082\n",
      "Reconstruction: 0.168063, Regularization: 0.002037, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:21,719 root         INFO     Train Epoch: 111 [3584/8000 (45%)]\tTotal Loss: 0.254599\n",
      "Reconstruction: 0.186934, Regularization: 0.002680, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:21,820 root         INFO     Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 0.228368\n",
      "Reconstruction: 0.161653, Regularization: 0.001709, Discriminator: 0.043346; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:21,920 root         INFO     Train Epoch: 111 [4608/8000 (58%)]\tTotal Loss: 0.228513\n",
      "Reconstruction: 0.161242, Regularization: 0.002283, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:22,019 root         INFO     Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 0.213910\n",
      "Reconstruction: 0.147064, Regularization: 0.001865, Discriminator: 0.043316; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:22,116 root         INFO     Train Epoch: 111 [5632/8000 (70%)]\tTotal Loss: 0.214910\n",
      "Reconstruction: 0.148051, Regularization: 0.001860, Discriminator: 0.043337; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:22,214 root         INFO     Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 0.231580\n",
      "Reconstruction: 0.164325, Regularization: 0.002260, Discriminator: 0.043335; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:22,311 root         INFO     Train Epoch: 111 [6656/8000 (83%)]\tTotal Loss: 0.277248\n",
      "Reconstruction: 0.209334, Regularization: 0.002920, Discriminator: 0.043329; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:22,408 root         INFO     Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 0.215992\n",
      "Reconstruction: 0.149151, Regularization: 0.001872, Discriminator: 0.043309; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:22,505 root         INFO     Train Epoch: 111 [7680/8000 (96%)]\tTotal Loss: 0.229902\n",
      "Reconstruction: 0.162985, Regularization: 0.001923, Discriminator: 0.043332; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:22,580 root         INFO     ====> Epoch: 111 Average loss: 0.2444\n",
      "2019-04-09 23:01:22,606 root         INFO     Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 0.238119\n",
      "Reconstruction: 0.170877, Regularization: 0.002269, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:22,709 root         INFO     Train Epoch: 112 [512/8000 (6%)]\tTotal Loss: 0.218764\n",
      "Reconstruction: 0.151867, Regularization: 0.001913, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:22,809 root         INFO     Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 0.253295\n",
      "Reconstruction: 0.185524, Regularization: 0.002775, Discriminator: 0.043332; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:22,908 root         INFO     Train Epoch: 112 [1536/8000 (19%)]\tTotal Loss: 0.294808\n",
      "Reconstruction: 0.226382, Regularization: 0.003440, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:23,011 root         INFO     Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 0.277351\n",
      "Reconstruction: 0.209433, Regularization: 0.002911, Discriminator: 0.043346; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:23,112 root         INFO     Train Epoch: 112 [2560/8000 (32%)]\tTotal Loss: 0.251294\n",
      "Reconstruction: 0.183737, Regularization: 0.002557, Discriminator: 0.043338; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:23,213 root         INFO     Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 0.285539\n",
      "Reconstruction: 0.217306, Regularization: 0.003240, Discriminator: 0.043331; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:23,314 root         INFO     Train Epoch: 112 [3584/8000 (45%)]\tTotal Loss: 0.224375\n",
      "Reconstruction: 0.157241, Regularization: 0.002149, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:23,414 root         INFO     Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 0.255056\n",
      "Reconstruction: 0.187319, Regularization: 0.002747, Discriminator: 0.043327; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:23,515 root         INFO     Train Epoch: 112 [4608/8000 (58%)]\tTotal Loss: 0.231415\n",
      "Reconstruction: 0.164300, Regularization: 0.002138, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:23,616 root         INFO     Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 0.256195\n",
      "Reconstruction: 0.188551, Regularization: 0.002657, Discriminator: 0.043316; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:23,717 root         INFO     Train Epoch: 112 [5632/8000 (70%)]\tTotal Loss: 0.275348\n",
      "Reconstruction: 0.207473, Regularization: 0.002886, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:23,817 root         INFO     Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 0.243068\n",
      "Reconstruction: 0.175813, Regularization: 0.002282, Discriminator: 0.043311; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:23,917 root         INFO     Train Epoch: 112 [6656/8000 (83%)]\tTotal Loss: 0.228971\n",
      "Reconstruction: 0.162111, Regularization: 0.001853, Discriminator: 0.043346; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:24,017 root         INFO     Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 0.209817\n",
      "Reconstruction: 0.143433, Regularization: 0.001392, Discriminator: 0.043329; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:24,116 root         INFO     Train Epoch: 112 [7680/8000 (96%)]\tTotal Loss: 0.198803\n",
      "Reconstruction: 0.132383, Regularization: 0.001466, Discriminator: 0.043304; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:24,189 root         INFO     ====> Epoch: 112 Average loss: 0.2446\n",
      "2019-04-09 23:01:24,215 root         INFO     Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 0.292096\n",
      "Reconstruction: 0.223414, Regularization: 0.003699, Discriminator: 0.043330; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:24,316 root         INFO     Train Epoch: 113 [512/8000 (6%)]\tTotal Loss: 0.218402\n",
      "Reconstruction: 0.151699, Regularization: 0.001713, Discriminator: 0.043336; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:24,416 root         INFO     Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 0.195493\n",
      "Reconstruction: 0.129167, Regularization: 0.001329, Discriminator: 0.043340; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:24,516 root         INFO     Train Epoch: 113 [1536/8000 (19%)]\tTotal Loss: 0.231654\n",
      "Reconstruction: 0.164657, Regularization: 0.002027, Discriminator: 0.043318; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:24,617 root         INFO     Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 0.209452\n",
      "Reconstruction: 0.142633, Regularization: 0.001823, Discriminator: 0.043331; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:24,717 root         INFO     Train Epoch: 113 [2560/8000 (32%)]\tTotal Loss: 0.216852\n",
      "Reconstruction: 0.150028, Regularization: 0.001847, Discriminator: 0.043323; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:24,818 root         INFO     Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 0.243239\n",
      "Reconstruction: 0.175702, Regularization: 0.002561, Discriminator: 0.043319; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:24,919 root         INFO     Train Epoch: 113 [3584/8000 (45%)]\tTotal Loss: 0.203543\n",
      "Reconstruction: 0.137281, Regularization: 0.001285, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:25,019 root         INFO     Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 0.291971\n",
      "Reconstruction: 0.223011, Regularization: 0.003976, Discriminator: 0.043316; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:25,118 root         INFO     Train Epoch: 113 [4608/8000 (58%)]\tTotal Loss: 0.226900\n",
      "Reconstruction: 0.159730, Regularization: 0.002192, Discriminator: 0.043312; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:25,216 root         INFO     Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 0.220920\n",
      "Reconstruction: 0.153732, Regularization: 0.002208, Discriminator: 0.043317; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:25,314 root         INFO     Train Epoch: 113 [5632/8000 (70%)]\tTotal Loss: 0.265440\n",
      "Reconstruction: 0.197708, Regularization: 0.002740, Discriminator: 0.043328; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:25,412 root         INFO     Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 0.209658\n",
      "Reconstruction: 0.142914, Regularization: 0.001770, Discriminator: 0.043312; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:25,511 root         INFO     Train Epoch: 113 [6656/8000 (83%)]\tTotal Loss: 0.219136\n",
      "Reconstruction: 0.152312, Regularization: 0.001859, Discriminator: 0.043308; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:25,608 root         INFO     Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 0.261250\n",
      "Reconstruction: 0.193266, Regularization: 0.003012, Discriminator: 0.043318; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:25,707 root         INFO     Train Epoch: 113 [7680/8000 (96%)]\tTotal Loss: 0.238259\n",
      "Reconstruction: 0.170752, Regularization: 0.002539, Discriminator: 0.043311; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:25,781 root         INFO     ====> Epoch: 113 Average loss: 0.2441\n",
      "2019-04-09 23:01:25,807 root         INFO     Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 0.250018\n",
      "Reconstruction: 0.182510, Regularization: 0.002542, Discriminator: 0.043306; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:25,909 root         INFO     Train Epoch: 114 [512/8000 (6%)]\tTotal Loss: 0.243778\n",
      "Reconstruction: 0.176198, Regularization: 0.002594, Discriminator: 0.043327; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:26,010 root         INFO     Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 0.220630\n",
      "Reconstruction: 0.153615, Regularization: 0.002034, Discriminator: 0.043323; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:26,110 root         INFO     Train Epoch: 114 [1536/8000 (19%)]\tTotal Loss: 0.261458\n",
      "Reconstruction: 0.193602, Regularization: 0.002881, Discriminator: 0.043319; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:26,210 root         INFO     Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 0.207719\n",
      "Reconstruction: 0.141015, Regularization: 0.001714, Discriminator: 0.043329; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:26,310 root         INFO     Train Epoch: 114 [2560/8000 (32%)]\tTotal Loss: 0.225617\n",
      "Reconstruction: 0.158791, Regularization: 0.001836, Discriminator: 0.043331; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:26,410 root         INFO     Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 0.237747\n",
      "Reconstruction: 0.170375, Regularization: 0.002378, Discriminator: 0.043334; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:26,510 root         INFO     Train Epoch: 114 [3584/8000 (45%)]\tTotal Loss: 0.233811\n",
      "Reconstruction: 0.166534, Regularization: 0.002301, Discriminator: 0.043310; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:26,610 root         INFO     Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 0.228906\n",
      "Reconstruction: 0.162119, Regularization: 0.001794, Discriminator: 0.043327; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:26,710 root         INFO     Train Epoch: 114 [4608/8000 (58%)]\tTotal Loss: 0.274996\n",
      "Reconstruction: 0.206831, Regularization: 0.003195, Discriminator: 0.043302; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:26,810 root         INFO     Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 0.231070\n",
      "Reconstruction: 0.164223, Regularization: 0.001879, Discriminator: 0.043307; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:26,909 root         INFO     Train Epoch: 114 [5632/8000 (70%)]\tTotal Loss: 0.201302\n",
      "Reconstruction: 0.134922, Regularization: 0.001397, Discriminator: 0.043306; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:27,008 root         INFO     Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 0.228908\n",
      "Reconstruction: 0.161832, Regularization: 0.002063, Discriminator: 0.043350; Generator: 0.021665,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:27,109 root         INFO     Train Epoch: 114 [6656/8000 (83%)]\tTotal Loss: 0.257853\n",
      "Reconstruction: 0.190081, Regularization: 0.002794, Discriminator: 0.043320; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:27,210 root         INFO     Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 0.262428\n",
      "Reconstruction: 0.194580, Regularization: 0.002824, Discriminator: 0.043345; Generator: 0.021680,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:27,310 root         INFO     Train Epoch: 114 [7680/8000 (96%)]\tTotal Loss: 0.292009\n",
      "Reconstruction: 0.223675, Regularization: 0.003362, Discriminator: 0.043306; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:27,384 root         INFO     ====> Epoch: 114 Average loss: 0.2445\n",
      "2019-04-09 23:01:27,411 root         INFO     Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 0.198282\n",
      "Reconstruction: 0.131901, Regularization: 0.001451, Discriminator: 0.043278; Generator: 0.021652,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:27,513 root         INFO     Train Epoch: 115 [512/8000 (6%)]\tTotal Loss: 0.255158\n",
      "Reconstruction: 0.187415, Regularization: 0.002792, Discriminator: 0.043306; Generator: 0.021645,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:27,613 root         INFO     Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 0.311229\n",
      "Reconstruction: 0.242080, Regularization: 0.004205, Discriminator: 0.043306; Generator: 0.021639,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:27,714 root         INFO     Train Epoch: 115 [1536/8000 (19%)]\tTotal Loss: 0.282043\n",
      "Reconstruction: 0.213963, Regularization: 0.003101, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:27,814 root         INFO     Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 0.215537\n",
      "Reconstruction: 0.148905, Regularization: 0.001621, Discriminator: 0.043341; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:27,916 root         INFO     Train Epoch: 115 [2560/8000 (32%)]\tTotal Loss: 0.249523\n",
      "Reconstruction: 0.181623, Regularization: 0.002900, Discriminator: 0.043340; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:28,016 root         INFO     Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 0.224006\n",
      "Reconstruction: 0.157012, Regularization: 0.002016, Discriminator: 0.043306; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:28,116 root         INFO     Train Epoch: 115 [3584/8000 (45%)]\tTotal Loss: 0.251807\n",
      "Reconstruction: 0.184086, Regularization: 0.002735, Discriminator: 0.043330; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:28,216 root         INFO     Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 0.218662\n",
      "Reconstruction: 0.151786, Regularization: 0.001898, Discriminator: 0.043321; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:28,315 root         INFO     Train Epoch: 115 [4608/8000 (58%)]\tTotal Loss: 0.199029\n",
      "Reconstruction: 0.132811, Regularization: 0.001224, Discriminator: 0.043332; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:28,415 root         INFO     Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 0.226130\n",
      "Reconstruction: 0.159116, Regularization: 0.002030, Discriminator: 0.043332; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:28,514 root         INFO     Train Epoch: 115 [5632/8000 (70%)]\tTotal Loss: 0.275776\n",
      "Reconstruction: 0.207334, Regularization: 0.003457, Discriminator: 0.043324; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:28,614 root         INFO     Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 0.254058\n",
      "Reconstruction: 0.186183, Regularization: 0.002896, Discriminator: 0.043324; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:28,714 root         INFO     Train Epoch: 115 [6656/8000 (83%)]\tTotal Loss: 0.242218\n",
      "Reconstruction: 0.174681, Regularization: 0.002554, Discriminator: 0.043326; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:28,814 root         INFO     Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 0.247844\n",
      "Reconstruction: 0.180171, Regularization: 0.002708, Discriminator: 0.043307; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:28,913 root         INFO     Train Epoch: 115 [7680/8000 (96%)]\tTotal Loss: 0.274955\n",
      "Reconstruction: 0.206853, Regularization: 0.003118, Discriminator: 0.043326; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:28,987 root         INFO     ====> Epoch: 115 Average loss: 0.2445\n",
      "2019-04-09 23:01:29,013 root         INFO     Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 0.209897\n",
      "Reconstruction: 0.143332, Regularization: 0.001567, Discriminator: 0.043336; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:29,114 root         INFO     Train Epoch: 116 [512/8000 (6%)]\tTotal Loss: 0.255271\n",
      "Reconstruction: 0.187374, Regularization: 0.002911, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:29,213 root         INFO     Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 0.245379\n",
      "Reconstruction: 0.177974, Regularization: 0.002425, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:29,310 root         INFO     Train Epoch: 116 [1536/8000 (19%)]\tTotal Loss: 0.243723\n",
      "Reconstruction: 0.176332, Regularization: 0.002420, Discriminator: 0.043308; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:29,408 root         INFO     Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 0.243544\n",
      "Reconstruction: 0.176486, Regularization: 0.002103, Discriminator: 0.043295; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:29,507 root         INFO     Train Epoch: 116 [2560/8000 (32%)]\tTotal Loss: 0.250407\n",
      "Reconstruction: 0.182764, Regularization: 0.002664, Discriminator: 0.043316; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:29,605 root         INFO     Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 0.234491\n",
      "Reconstruction: 0.167272, Regularization: 0.002213, Discriminator: 0.043349; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:29,704 root         INFO     Train Epoch: 116 [3584/8000 (45%)]\tTotal Loss: 0.214772\n",
      "Reconstruction: 0.147970, Regularization: 0.001810, Discriminator: 0.043325; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:29,803 root         INFO     Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 0.247100\n",
      "Reconstruction: 0.179715, Regularization: 0.002439, Discriminator: 0.043288; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:29,902 root         INFO     Train Epoch: 116 [4608/8000 (58%)]\tTotal Loss: 0.254514\n",
      "Reconstruction: 0.186770, Regularization: 0.002744, Discriminator: 0.043343; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:30,001 root         INFO     Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 0.249371\n",
      "Reconstruction: 0.181715, Regularization: 0.002666, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:30,099 root         INFO     Train Epoch: 116 [5632/8000 (70%)]\tTotal Loss: 0.234114\n",
      "Reconstruction: 0.167006, Regularization: 0.002116, Discriminator: 0.043335; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:30,197 root         INFO     Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 0.195149\n",
      "Reconstruction: 0.128871, Regularization: 0.001299, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:30,293 root         INFO     Train Epoch: 116 [6656/8000 (83%)]\tTotal Loss: 0.273365\n",
      "Reconstruction: 0.205527, Regularization: 0.002839, Discriminator: 0.043340; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:30,389 root         INFO     Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 0.232482\n",
      "Reconstruction: 0.165250, Regularization: 0.002238, Discriminator: 0.043333; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:30,486 root         INFO     Train Epoch: 116 [7680/8000 (96%)]\tTotal Loss: 0.242722\n",
      "Reconstruction: 0.175505, Regularization: 0.002239, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:30,560 root         INFO     ====> Epoch: 116 Average loss: 0.2443\n",
      "2019-04-09 23:01:30,586 root         INFO     Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 0.284281\n",
      "Reconstruction: 0.216137, Regularization: 0.003168, Discriminator: 0.043310; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:30,686 root         INFO     Train Epoch: 117 [512/8000 (6%)]\tTotal Loss: 0.226407\n",
      "Reconstruction: 0.159624, Regularization: 0.001811, Discriminator: 0.043308; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:30,785 root         INFO     Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 0.206325\n",
      "Reconstruction: 0.140183, Regularization: 0.001171, Discriminator: 0.043303; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:30,884 root         INFO     Train Epoch: 117 [1536/8000 (19%)]\tTotal Loss: 0.248840\n",
      "Reconstruction: 0.181834, Regularization: 0.002048, Discriminator: 0.043293; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:30,982 root         INFO     Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 0.224255\n",
      "Reconstruction: 0.157512, Regularization: 0.001775, Discriminator: 0.043303; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:31,079 root         INFO     Train Epoch: 117 [2560/8000 (32%)]\tTotal Loss: 0.229835\n",
      "Reconstruction: 0.162936, Regularization: 0.001908, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:31,179 root         INFO     Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 0.226697\n",
      "Reconstruction: 0.159798, Regularization: 0.001914, Discriminator: 0.043311; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:31,278 root         INFO     Train Epoch: 117 [3584/8000 (45%)]\tTotal Loss: 0.256148\n",
      "Reconstruction: 0.188326, Regularization: 0.002852, Discriminator: 0.043318; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:31,378 root         INFO     Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 0.280933\n",
      "Reconstruction: 0.213047, Regularization: 0.002854, Discriminator: 0.043368; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:31,478 root         INFO     Train Epoch: 117 [4608/8000 (58%)]\tTotal Loss: 0.186103\n",
      "Reconstruction: 0.119957, Regularization: 0.001177, Discriminator: 0.043303; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:31,577 root         INFO     Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 0.225499\n",
      "Reconstruction: 0.158851, Regularization: 0.001695, Discriminator: 0.043300; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:31,676 root         INFO     Train Epoch: 117 [5632/8000 (70%)]\tTotal Loss: 0.245135\n",
      "Reconstruction: 0.177629, Regularization: 0.002534, Discriminator: 0.043326; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:31,775 root         INFO     Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 0.235342\n",
      "Reconstruction: 0.168165, Regularization: 0.002171, Discriminator: 0.043339; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:31,872 root         INFO     Train Epoch: 117 [6656/8000 (83%)]\tTotal Loss: 0.237289\n",
      "Reconstruction: 0.169994, Regularization: 0.002299, Discriminator: 0.043344; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:31,969 root         INFO     Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 0.228541\n",
      "Reconstruction: 0.161409, Regularization: 0.002155, Discriminator: 0.043322; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:32,066 root         INFO     Train Epoch: 117 [7680/8000 (96%)]\tTotal Loss: 0.240552\n",
      "Reconstruction: 0.172965, Regularization: 0.002625, Discriminator: 0.043301; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:32,140 root         INFO     ====> Epoch: 117 Average loss: 0.2443\n",
      "2019-04-09 23:01:32,166 root         INFO     Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 0.240074\n",
      "Reconstruction: 0.172902, Regularization: 0.002202, Discriminator: 0.043312; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:32,266 root         INFO     Train Epoch: 118 [512/8000 (6%)]\tTotal Loss: 0.233606\n",
      "Reconstruction: 0.166466, Regularization: 0.002177, Discriminator: 0.043314; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:32,366 root         INFO     Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 0.257422\n",
      "Reconstruction: 0.189363, Regularization: 0.003083, Discriminator: 0.043321; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:32,466 root         INFO     Train Epoch: 118 [1536/8000 (19%)]\tTotal Loss: 0.280995\n",
      "Reconstruction: 0.212641, Regularization: 0.003372, Discriminator: 0.043327; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:32,566 root         INFO     Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 0.275540\n",
      "Reconstruction: 0.207390, Regularization: 0.003180, Discriminator: 0.043310; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:32,665 root         INFO     Train Epoch: 118 [2560/8000 (32%)]\tTotal Loss: 0.264508\n",
      "Reconstruction: 0.196546, Regularization: 0.002981, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:32,765 root         INFO     Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 0.288658\n",
      "Reconstruction: 0.220277, Regularization: 0.003402, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:32,864 root         INFO     Train Epoch: 118 [3584/8000 (45%)]\tTotal Loss: 0.263893\n",
      "Reconstruction: 0.195749, Regularization: 0.003140, Discriminator: 0.043344; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:32,962 root         INFO     Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 0.233065\n",
      "Reconstruction: 0.165921, Regularization: 0.002179, Discriminator: 0.043301; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:33,060 root         INFO     Train Epoch: 118 [4608/8000 (58%)]\tTotal Loss: 0.238120\n",
      "Reconstruction: 0.170601, Regularization: 0.002552, Discriminator: 0.043307; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:33,158 root         INFO     Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 0.256434\n",
      "Reconstruction: 0.188504, Regularization: 0.002929, Discriminator: 0.043336; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:33,257 root         INFO     Train Epoch: 118 [5632/8000 (70%)]\tTotal Loss: 0.220342\n",
      "Reconstruction: 0.153741, Regularization: 0.001628, Discriminator: 0.043314; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:33,355 root         INFO     Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 0.248962\n",
      "Reconstruction: 0.181270, Regularization: 0.002678, Discriminator: 0.043358; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:33,454 root         INFO     Train Epoch: 118 [6656/8000 (83%)]\tTotal Loss: 0.267098\n",
      "Reconstruction: 0.198725, Regularization: 0.003408, Discriminator: 0.043303; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:33,553 root         INFO     Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 0.269626\n",
      "Reconstruction: 0.201297, Regularization: 0.003323, Discriminator: 0.043347; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:33,652 root         INFO     Train Epoch: 118 [7680/8000 (96%)]\tTotal Loss: 0.236551\n",
      "Reconstruction: 0.169142, Regularization: 0.002446, Discriminator: 0.043312; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:33,725 root         INFO     ====> Epoch: 118 Average loss: 0.2445\n",
      "2019-04-09 23:01:33,752 root         INFO     Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 0.212309\n",
      "Reconstruction: 0.145537, Regularization: 0.001793, Discriminator: 0.043316; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:33,853 root         INFO     Train Epoch: 119 [512/8000 (6%)]\tTotal Loss: 0.207916\n",
      "Reconstruction: 0.141264, Regularization: 0.001668, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:33,952 root         INFO     Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 0.289695\n",
      "Reconstruction: 0.221309, Regularization: 0.003372, Discriminator: 0.043353; Generator: 0.021661,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:34,052 root         INFO     Train Epoch: 119 [1536/8000 (19%)]\tTotal Loss: 0.212777\n",
      "Reconstruction: 0.145908, Regularization: 0.001907, Discriminator: 0.043304; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:34,152 root         INFO     Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 0.238770\n",
      "Reconstruction: 0.171331, Regularization: 0.002477, Discriminator: 0.043301; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:34,252 root         INFO     Train Epoch: 119 [2560/8000 (32%)]\tTotal Loss: 0.317223\n",
      "Reconstruction: 0.248049, Regularization: 0.004195, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:34,351 root         INFO     Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 0.216495\n",
      "Reconstruction: 0.149749, Regularization: 0.001758, Discriminator: 0.043326; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:34,451 root         INFO     Train Epoch: 119 [3584/8000 (45%)]\tTotal Loss: 0.226789\n",
      "Reconstruction: 0.159597, Regularization: 0.002216, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:34,551 root         INFO     Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 0.231082\n",
      "Reconstruction: 0.163895, Regularization: 0.002197, Discriminator: 0.043329; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:34,650 root         INFO     Train Epoch: 119 [4608/8000 (58%)]\tTotal Loss: 0.232110\n",
      "Reconstruction: 0.164855, Regularization: 0.002268, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:34,748 root         INFO     Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 0.205529\n",
      "Reconstruction: 0.139181, Regularization: 0.001357, Discriminator: 0.043323; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:34,847 root         INFO     Train Epoch: 119 [5632/8000 (70%)]\tTotal Loss: 0.234128\n",
      "Reconstruction: 0.166899, Regularization: 0.002219, Discriminator: 0.043344; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:34,945 root         INFO     Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 0.246679\n",
      "Reconstruction: 0.179173, Regularization: 0.002522, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:35,044 root         INFO     Train Epoch: 119 [6656/8000 (83%)]\tTotal Loss: 0.232141\n",
      "Reconstruction: 0.165177, Regularization: 0.001986, Discriminator: 0.043315; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:35,142 root         INFO     Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 0.224682\n",
      "Reconstruction: 0.157638, Regularization: 0.002073, Discriminator: 0.043315; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:35,240 root         INFO     Train Epoch: 119 [7680/8000 (96%)]\tTotal Loss: 0.247530\n",
      "Reconstruction: 0.179945, Regularization: 0.002624, Discriminator: 0.043306; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:35,314 root         INFO     ====> Epoch: 119 Average loss: 0.2444\n",
      "2019-04-09 23:01:35,340 root         INFO     Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 0.226471\n",
      "Reconstruction: 0.159311, Regularization: 0.002196, Discriminator: 0.043296; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:35,441 root         INFO     Train Epoch: 120 [512/8000 (6%)]\tTotal Loss: 0.248579\n",
      "Reconstruction: 0.181006, Regularization: 0.002600, Discriminator: 0.043315; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:35,541 root         INFO     Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 0.259331\n",
      "Reconstruction: 0.191376, Regularization: 0.002987, Discriminator: 0.043306; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:35,640 root         INFO     Train Epoch: 120 [1536/8000 (19%)]\tTotal Loss: 0.305856\n",
      "Reconstruction: 0.237177, Regularization: 0.003692, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:35,740 root         INFO     Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 0.256562\n",
      "Reconstruction: 0.188784, Regularization: 0.002781, Discriminator: 0.043326; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:35,841 root         INFO     Train Epoch: 120 [2560/8000 (32%)]\tTotal Loss: 0.242877\n",
      "Reconstruction: 0.175044, Regularization: 0.002853, Discriminator: 0.043316; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:35,941 root         INFO     Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 0.206557\n",
      "Reconstruction: 0.140134, Regularization: 0.001430, Discriminator: 0.043328; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:36,043 root         INFO     Train Epoch: 120 [3584/8000 (45%)]\tTotal Loss: 0.268202\n",
      "Reconstruction: 0.200255, Regularization: 0.002960, Discriminator: 0.043334; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:36,146 root         INFO     Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 0.282921\n",
      "Reconstruction: 0.214472, Regularization: 0.003457, Discriminator: 0.043333; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:36,245 root         INFO     Train Epoch: 120 [4608/8000 (58%)]\tTotal Loss: 0.269177\n",
      "Reconstruction: 0.201012, Regularization: 0.003189, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:36,344 root         INFO     Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 0.243348\n",
      "Reconstruction: 0.175819, Regularization: 0.002549, Discriminator: 0.043327; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:36,444 root         INFO     Train Epoch: 120 [5632/8000 (70%)]\tTotal Loss: 0.262383\n",
      "Reconstruction: 0.194244, Regularization: 0.003169, Discriminator: 0.043317; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:36,543 root         INFO     Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 0.245101\n",
      "Reconstruction: 0.177383, Regularization: 0.002724, Discriminator: 0.043325; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:36,643 root         INFO     Train Epoch: 120 [6656/8000 (83%)]\tTotal Loss: 0.219337\n",
      "Reconstruction: 0.152553, Regularization: 0.001809, Discriminator: 0.043318; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:36,742 root         INFO     Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 0.224297\n",
      "Reconstruction: 0.157153, Regularization: 0.002163, Discriminator: 0.043324; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:36,841 root         INFO     Train Epoch: 120 [7680/8000 (96%)]\tTotal Loss: 0.226732\n",
      "Reconstruction: 0.159851, Regularization: 0.001900, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:36,915 root         INFO     ====> Epoch: 120 Average loss: 0.2441\n",
      "2019-04-09 23:01:36,941 root         INFO     Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 0.260074\n",
      "Reconstruction: 0.192281, Regularization: 0.002822, Discriminator: 0.043313; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:37,042 root         INFO     Train Epoch: 121 [512/8000 (6%)]\tTotal Loss: 0.246378\n",
      "Reconstruction: 0.178866, Regularization: 0.002531, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:37,143 root         INFO     Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 0.265487\n",
      "Reconstruction: 0.197288, Regularization: 0.003223, Discriminator: 0.043316; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:37,243 root         INFO     Train Epoch: 121 [1536/8000 (19%)]\tTotal Loss: 0.272855\n",
      "Reconstruction: 0.204572, Regularization: 0.003298, Discriminator: 0.043327; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:37,343 root         INFO     Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 0.223125\n",
      "Reconstruction: 0.156057, Regularization: 0.002078, Discriminator: 0.043324; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:37,444 root         INFO     Train Epoch: 121 [2560/8000 (32%)]\tTotal Loss: 0.212631\n",
      "Reconstruction: 0.145840, Regularization: 0.001816, Discriminator: 0.043313; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:37,544 root         INFO     Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 0.232927\n",
      "Reconstruction: 0.165528, Regularization: 0.002408, Discriminator: 0.043332; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:37,642 root         INFO     Train Epoch: 121 [3584/8000 (45%)]\tTotal Loss: 0.228879\n",
      "Reconstruction: 0.161570, Regularization: 0.002330, Discriminator: 0.043309; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:37,742 root         INFO     Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 0.186713\n",
      "Reconstruction: 0.120571, Regularization: 0.001168, Discriminator: 0.043310; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:37,840 root         INFO     Train Epoch: 121 [4608/8000 (58%)]\tTotal Loss: 0.246985\n",
      "Reconstruction: 0.179214, Regularization: 0.002800, Discriminator: 0.043316; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:37,939 root         INFO     Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 0.246412\n",
      "Reconstruction: 0.178726, Regularization: 0.002705, Discriminator: 0.043328; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:38,037 root         INFO     Train Epoch: 121 [5632/8000 (70%)]\tTotal Loss: 0.231824\n",
      "Reconstruction: 0.164392, Regularization: 0.002424, Discriminator: 0.043346; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:38,135 root         INFO     Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 0.292340\n",
      "Reconstruction: 0.223660, Regularization: 0.003706, Discriminator: 0.043318; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:38,233 root         INFO     Train Epoch: 121 [6656/8000 (83%)]\tTotal Loss: 0.214227\n",
      "Reconstruction: 0.147347, Regularization: 0.001912, Discriminator: 0.043311; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:38,332 root         INFO     Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 0.231132\n",
      "Reconstruction: 0.163749, Regularization: 0.002392, Discriminator: 0.043330; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:38,430 root         INFO     Train Epoch: 121 [7680/8000 (96%)]\tTotal Loss: 0.197593\n",
      "Reconstruction: 0.131073, Regularization: 0.001545, Discriminator: 0.043323; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:38,503 root         INFO     ====> Epoch: 121 Average loss: 0.2443\n",
      "2019-04-09 23:01:38,530 root         INFO     Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 0.246244\n",
      "Reconstruction: 0.178794, Regularization: 0.002462, Discriminator: 0.043331; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:38,631 root         INFO     Train Epoch: 122 [512/8000 (6%)]\tTotal Loss: 0.218927\n",
      "Reconstruction: 0.151952, Regularization: 0.001995, Discriminator: 0.043317; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:38,732 root         INFO     Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 0.249915\n",
      "Reconstruction: 0.182099, Regularization: 0.002833, Discriminator: 0.043329; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:38,833 root         INFO     Train Epoch: 122 [1536/8000 (19%)]\tTotal Loss: 0.234241\n",
      "Reconstruction: 0.167065, Regularization: 0.002221, Discriminator: 0.043302; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:38,933 root         INFO     Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 0.226731\n",
      "Reconstruction: 0.159466, Regularization: 0.002269, Discriminator: 0.043336; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:39,034 root         INFO     Train Epoch: 122 [2560/8000 (32%)]\tTotal Loss: 0.231678\n",
      "Reconstruction: 0.164519, Regularization: 0.002178, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:39,134 root         INFO     Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 0.278325\n",
      "Reconstruction: 0.209792, Regularization: 0.003530, Discriminator: 0.043341; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:39,234 root         INFO     Train Epoch: 122 [3584/8000 (45%)]\tTotal Loss: 0.267277\n",
      "Reconstruction: 0.199334, Regularization: 0.002967, Discriminator: 0.043313; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:39,334 root         INFO     Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 0.253973\n",
      "Reconstruction: 0.186100, Regularization: 0.002867, Discriminator: 0.043341; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:39,434 root         INFO     Train Epoch: 122 [4608/8000 (58%)]\tTotal Loss: 0.284368\n",
      "Reconstruction: 0.216149, Regularization: 0.003245, Discriminator: 0.043312; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:39,534 root         INFO     Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 0.280026\n",
      "Reconstruction: 0.211883, Regularization: 0.003157, Discriminator: 0.043323; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:39,634 root         INFO     Train Epoch: 122 [5632/8000 (70%)]\tTotal Loss: 0.290442\n",
      "Reconstruction: 0.222080, Regularization: 0.003393, Discriminator: 0.043301; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:39,735 root         INFO     Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 0.270597\n",
      "Reconstruction: 0.202553, Regularization: 0.003053, Discriminator: 0.043325; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:39,836 root         INFO     Train Epoch: 122 [6656/8000 (83%)]\tTotal Loss: 0.225487\n",
      "Reconstruction: 0.158406, Regularization: 0.002079, Discriminator: 0.043335; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:39,937 root         INFO     Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 0.249179\n",
      "Reconstruction: 0.181741, Regularization: 0.002463, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:40,038 root         INFO     Train Epoch: 122 [7680/8000 (96%)]\tTotal Loss: 0.246526\n",
      "Reconstruction: 0.179134, Regularization: 0.002399, Discriminator: 0.043331; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:40,113 root         INFO     ====> Epoch: 122 Average loss: 0.2445\n",
      "2019-04-09 23:01:40,139 root         INFO     Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 0.247868\n",
      "Reconstruction: 0.180487, Regularization: 0.002431, Discriminator: 0.043291; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:40,241 root         INFO     Train Epoch: 123 [512/8000 (6%)]\tTotal Loss: 0.277240\n",
      "Reconstruction: 0.209050, Regularization: 0.003230, Discriminator: 0.043306; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:40,341 root         INFO     Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 0.234443\n",
      "Reconstruction: 0.167127, Regularization: 0.002335, Discriminator: 0.043319; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:40,442 root         INFO     Train Epoch: 123 [1536/8000 (19%)]\tTotal Loss: 0.231226\n",
      "Reconstruction: 0.163963, Regularization: 0.002290, Discriminator: 0.043318; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:40,542 root         INFO     Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 0.250640\n",
      "Reconstruction: 0.182974, Regularization: 0.002681, Discriminator: 0.043329; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:40,642 root         INFO     Train Epoch: 123 [2560/8000 (32%)]\tTotal Loss: 0.212859\n",
      "Reconstruction: 0.146181, Regularization: 0.001697, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:40,743 root         INFO     Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 0.222550\n",
      "Reconstruction: 0.155526, Regularization: 0.002042, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:40,843 root         INFO     Train Epoch: 123 [3584/8000 (45%)]\tTotal Loss: 0.207602\n",
      "Reconstruction: 0.141245, Regularization: 0.001380, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:40,944 root         INFO     Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 0.230355\n",
      "Reconstruction: 0.163274, Regularization: 0.002105, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:41,044 root         INFO     Train Epoch: 123 [4608/8000 (58%)]\tTotal Loss: 0.232712\n",
      "Reconstruction: 0.165439, Regularization: 0.002297, Discriminator: 0.043314; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:41,145 root         INFO     Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 0.221961\n",
      "Reconstruction: 0.154974, Regularization: 0.002009, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:41,245 root         INFO     Train Epoch: 123 [5632/8000 (70%)]\tTotal Loss: 0.250841\n",
      "Reconstruction: 0.183105, Regularization: 0.002754, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:41,346 root         INFO     Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 0.272373\n",
      "Reconstruction: 0.203981, Regularization: 0.003417, Discriminator: 0.043316; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:41,446 root         INFO     Train Epoch: 123 [6656/8000 (83%)]\tTotal Loss: 0.230321\n",
      "Reconstruction: 0.163073, Regularization: 0.002260, Discriminator: 0.043330; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:41,544 root         INFO     Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 0.235608\n",
      "Reconstruction: 0.168427, Regularization: 0.002205, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:41,644 root         INFO     Train Epoch: 123 [7680/8000 (96%)]\tTotal Loss: 0.233174\n",
      "Reconstruction: 0.165905, Regularization: 0.002288, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:41,716 root         INFO     ====> Epoch: 123 Average loss: 0.2443\n",
      "2019-04-09 23:01:41,742 root         INFO     Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 0.260982\n",
      "Reconstruction: 0.192996, Regularization: 0.003013, Discriminator: 0.043310; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:41,845 root         INFO     Train Epoch: 124 [512/8000 (6%)]\tTotal Loss: 0.215827\n",
      "Reconstruction: 0.149053, Regularization: 0.001793, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:41,942 root         INFO     Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 0.277835\n",
      "Reconstruction: 0.209970, Regularization: 0.002889, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:42,039 root         INFO     Train Epoch: 124 [1536/8000 (19%)]\tTotal Loss: 0.228802\n",
      "Reconstruction: 0.161888, Regularization: 0.001910, Discriminator: 0.043346; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:42,136 root         INFO     Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 0.256944\n",
      "Reconstruction: 0.189314, Regularization: 0.002653, Discriminator: 0.043316; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:42,234 root         INFO     Train Epoch: 124 [2560/8000 (32%)]\tTotal Loss: 0.229795\n",
      "Reconstruction: 0.162612, Regularization: 0.002204, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:42,330 root         INFO     Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 0.213885\n",
      "Reconstruction: 0.147393, Regularization: 0.001504, Discriminator: 0.043327; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:42,426 root         INFO     Train Epoch: 124 [3584/8000 (45%)]\tTotal Loss: 0.252645\n",
      "Reconstruction: 0.185116, Regularization: 0.002548, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:42,523 root         INFO     Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 0.231833\n",
      "Reconstruction: 0.164618, Regularization: 0.002234, Discriminator: 0.043316; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:42,620 root         INFO     Train Epoch: 124 [4608/8000 (58%)]\tTotal Loss: 0.239222\n",
      "Reconstruction: 0.171912, Regularization: 0.002321, Discriminator: 0.043329; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:42,717 root         INFO     Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 0.262483\n",
      "Reconstruction: 0.194607, Regularization: 0.002877, Discriminator: 0.043338; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:42,814 root         INFO     Train Epoch: 124 [5632/8000 (70%)]\tTotal Loss: 0.275453\n",
      "Reconstruction: 0.207633, Regularization: 0.002833, Discriminator: 0.043324; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:42,911 root         INFO     Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 0.234733\n",
      "Reconstruction: 0.167540, Regularization: 0.002213, Discriminator: 0.043312; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:43,008 root         INFO     Train Epoch: 124 [6656/8000 (83%)]\tTotal Loss: 0.258072\n",
      "Reconstruction: 0.190359, Regularization: 0.002733, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:43,105 root         INFO     Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 0.206641\n",
      "Reconstruction: 0.140145, Regularization: 0.001510, Discriminator: 0.043321; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:43,202 root         INFO     Train Epoch: 124 [7680/8000 (96%)]\tTotal Loss: 0.208447\n",
      "Reconstruction: 0.142018, Regularization: 0.001456, Discriminator: 0.043315; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:43,276 root         INFO     ====> Epoch: 124 Average loss: 0.2442\n",
      "2019-04-09 23:01:43,302 root         INFO     Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 0.263028\n",
      "Reconstruction: 0.195209, Regularization: 0.002844, Discriminator: 0.043312; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:43,405 root         INFO     Train Epoch: 125 [512/8000 (6%)]\tTotal Loss: 0.262197\n",
      "Reconstruction: 0.194301, Regularization: 0.002907, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:43,506 root         INFO     Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 0.228875\n",
      "Reconstruction: 0.161989, Regularization: 0.001916, Discriminator: 0.043303; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:43,607 root         INFO     Train Epoch: 125 [1536/8000 (19%)]\tTotal Loss: 0.247278\n",
      "Reconstruction: 0.179854, Regularization: 0.002419, Discriminator: 0.043342; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:43,708 root         INFO     Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 0.254713\n",
      "Reconstruction: 0.187063, Regularization: 0.002656, Discriminator: 0.043326; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:43,807 root         INFO     Train Epoch: 125 [2560/8000 (32%)]\tTotal Loss: 0.245497\n",
      "Reconstruction: 0.178237, Regularization: 0.002281, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:43,906 root         INFO     Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 0.240534\n",
      "Reconstruction: 0.173270, Regularization: 0.002308, Discriminator: 0.043301; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:44,003 root         INFO     Train Epoch: 125 [3584/8000 (45%)]\tTotal Loss: 0.206160\n",
      "Reconstruction: 0.139726, Regularization: 0.001452, Discriminator: 0.043314; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:44,100 root         INFO     Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 0.221256\n",
      "Reconstruction: 0.154290, Regularization: 0.001986, Discriminator: 0.043328; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:44,197 root         INFO     Train Epoch: 125 [4608/8000 (58%)]\tTotal Loss: 0.241275\n",
      "Reconstruction: 0.173687, Regularization: 0.002595, Discriminator: 0.043337; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:44,293 root         INFO     Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 0.266419\n",
      "Reconstruction: 0.198505, Regularization: 0.002926, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:44,389 root         INFO     Train Epoch: 125 [5632/8000 (70%)]\tTotal Loss: 0.286934\n",
      "Reconstruction: 0.218531, Regularization: 0.003414, Discriminator: 0.043330; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:44,486 root         INFO     Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 0.272144\n",
      "Reconstruction: 0.203723, Regularization: 0.003448, Discriminator: 0.043316; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:44,582 root         INFO     Train Epoch: 125 [6656/8000 (83%)]\tTotal Loss: 0.212174\n",
      "Reconstruction: 0.145379, Regularization: 0.001828, Discriminator: 0.043306; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:44,679 root         INFO     Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 0.216999\n",
      "Reconstruction: 0.150174, Regularization: 0.001858, Discriminator: 0.043306; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:44,776 root         INFO     Train Epoch: 125 [7680/8000 (96%)]\tTotal Loss: 0.228440\n",
      "Reconstruction: 0.161229, Regularization: 0.002234, Discriminator: 0.043315; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:44,850 root         INFO     ====> Epoch: 125 Average loss: 0.2447\n",
      "2019-04-09 23:01:44,876 root         INFO     Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 0.248806\n",
      "Reconstruction: 0.181074, Regularization: 0.002741, Discriminator: 0.043326; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:44,979 root         INFO     Train Epoch: 126 [512/8000 (6%)]\tTotal Loss: 0.240175\n",
      "Reconstruction: 0.172597, Regularization: 0.002602, Discriminator: 0.043314; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:45,080 root         INFO     Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 0.224378\n",
      "Reconstruction: 0.157429, Regularization: 0.001960, Discriminator: 0.043331; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:45,180 root         INFO     Train Epoch: 126 [1536/8000 (19%)]\tTotal Loss: 0.259318\n",
      "Reconstruction: 0.191349, Regularization: 0.002979, Discriminator: 0.043330; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:45,280 root         INFO     Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 0.210902\n",
      "Reconstruction: 0.144172, Regularization: 0.001751, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:45,378 root         INFO     Train Epoch: 126 [2560/8000 (32%)]\tTotal Loss: 0.221905\n",
      "Reconstruction: 0.154899, Regularization: 0.002038, Discriminator: 0.043306; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:45,477 root         INFO     Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 0.225357\n",
      "Reconstruction: 0.158238, Regularization: 0.002128, Discriminator: 0.043333; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:45,576 root         INFO     Train Epoch: 126 [3584/8000 (45%)]\tTotal Loss: 0.242216\n",
      "Reconstruction: 0.174895, Regularization: 0.002328, Discriminator: 0.043335; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:45,674 root         INFO     Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 0.223917\n",
      "Reconstruction: 0.156831, Regularization: 0.002067, Discriminator: 0.043356; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:45,773 root         INFO     Train Epoch: 126 [4608/8000 (58%)]\tTotal Loss: 0.223646\n",
      "Reconstruction: 0.156703, Regularization: 0.001971, Discriminator: 0.043314; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:45,872 root         INFO     Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 0.249157\n",
      "Reconstruction: 0.181301, Regularization: 0.002854, Discriminator: 0.043341; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:45,971 root         INFO     Train Epoch: 126 [5632/8000 (70%)]\tTotal Loss: 0.212111\n",
      "Reconstruction: 0.145484, Regularization: 0.001626, Discriminator: 0.043343; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:46,069 root         INFO     Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 0.194365\n",
      "Reconstruction: 0.128222, Regularization: 0.001165, Discriminator: 0.043318; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:46,167 root         INFO     Train Epoch: 126 [6656/8000 (83%)]\tTotal Loss: 0.250363\n",
      "Reconstruction: 0.182908, Regularization: 0.002464, Discriminator: 0.043327; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:46,266 root         INFO     Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 0.223568\n",
      "Reconstruction: 0.156805, Regularization: 0.001781, Discriminator: 0.043313; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:46,363 root         INFO     Train Epoch: 126 [7680/8000 (96%)]\tTotal Loss: 0.275332\n",
      "Reconstruction: 0.207474, Regularization: 0.002868, Discriminator: 0.043321; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:46,436 root         INFO     ====> Epoch: 126 Average loss: 0.2443\n",
      "2019-04-09 23:01:46,463 root         INFO     Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 0.228287\n",
      "Reconstruction: 0.161592, Regularization: 0.001722, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:46,563 root         INFO     Train Epoch: 127 [512/8000 (6%)]\tTotal Loss: 0.247701\n",
      "Reconstruction: 0.180394, Regularization: 0.002330, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:46,664 root         INFO     Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 0.244102\n",
      "Reconstruction: 0.176635, Regularization: 0.002493, Discriminator: 0.043316; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:46,764 root         INFO     Train Epoch: 127 [1536/8000 (19%)]\tTotal Loss: 0.201979\n",
      "Reconstruction: 0.135625, Regularization: 0.001371, Discriminator: 0.043314; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:46,864 root         INFO     Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 0.273445\n",
      "Reconstruction: 0.205212, Regularization: 0.003265, Discriminator: 0.043313; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:46,964 root         INFO     Train Epoch: 127 [2560/8000 (32%)]\tTotal Loss: 0.230664\n",
      "Reconstruction: 0.163552, Regularization: 0.002127, Discriminator: 0.043328; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:47,064 root         INFO     Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 0.288850\n",
      "Reconstruction: 0.220428, Regularization: 0.003455, Discriminator: 0.043295; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:47,164 root         INFO     Train Epoch: 127 [3584/8000 (45%)]\tTotal Loss: 0.232512\n",
      "Reconstruction: 0.165291, Regularization: 0.002230, Discriminator: 0.043324; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:47,264 root         INFO     Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 0.263167\n",
      "Reconstruction: 0.195449, Regularization: 0.002705, Discriminator: 0.043337; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:47,364 root         INFO     Train Epoch: 127 [4608/8000 (58%)]\tTotal Loss: 0.240661\n",
      "Reconstruction: 0.173591, Regularization: 0.002079, Discriminator: 0.043318; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:47,464 root         INFO     Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 0.271599\n",
      "Reconstruction: 0.203370, Regularization: 0.003214, Discriminator: 0.043363; Generator: 0.021652,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:47,564 root         INFO     Train Epoch: 127 [5632/8000 (70%)]\tTotal Loss: 0.216870\n",
      "Reconstruction: 0.150056, Regularization: 0.001796, Discriminator: 0.043375; Generator: 0.021643,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:01:47,663 root         INFO     Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 0.246215\n",
      "Reconstruction: 0.178767, Regularization: 0.002481, Discriminator: 0.043317; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:47,762 root         INFO     Train Epoch: 127 [6656/8000 (83%)]\tTotal Loss: 0.251015\n",
      "Reconstruction: 0.183365, Regularization: 0.002667, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:47,861 root         INFO     Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 0.272016\n",
      "Reconstruction: 0.203906, Regularization: 0.003116, Discriminator: 0.043340; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:47,962 root         INFO     Train Epoch: 127 [7680/8000 (96%)]\tTotal Loss: 0.301538\n",
      "Reconstruction: 0.232386, Regularization: 0.004181, Discriminator: 0.043320; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:48,037 root         INFO     ====> Epoch: 127 Average loss: 0.2444\n",
      "2019-04-09 23:01:48,065 root         INFO     Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 0.206335\n",
      "Reconstruction: 0.139662, Regularization: 0.001695, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:48,166 root         INFO     Train Epoch: 128 [512/8000 (6%)]\tTotal Loss: 0.218467\n",
      "Reconstruction: 0.151563, Regularization: 0.001925, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:48,266 root         INFO     Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 0.258867\n",
      "Reconstruction: 0.190926, Regularization: 0.002959, Discriminator: 0.043318; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:48,366 root         INFO     Train Epoch: 128 [1536/8000 (19%)]\tTotal Loss: 0.234881\n",
      "Reconstruction: 0.167272, Regularization: 0.002633, Discriminator: 0.043311; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:48,465 root         INFO     Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 0.241097\n",
      "Reconstruction: 0.173342, Regularization: 0.002768, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:48,564 root         INFO     Train Epoch: 128 [2560/8000 (32%)]\tTotal Loss: 0.233990\n",
      "Reconstruction: 0.166505, Regularization: 0.002487, Discriminator: 0.043338; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:48,664 root         INFO     Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 0.248333\n",
      "Reconstruction: 0.180736, Regularization: 0.002631, Discriminator: 0.043304; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:48,763 root         INFO     Train Epoch: 128 [3584/8000 (45%)]\tTotal Loss: 0.228056\n",
      "Reconstruction: 0.160863, Regularization: 0.002217, Discriminator: 0.043309; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:48,861 root         INFO     Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 0.262767\n",
      "Reconstruction: 0.194854, Regularization: 0.002928, Discriminator: 0.043317; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:48,960 root         INFO     Train Epoch: 128 [4608/8000 (58%)]\tTotal Loss: 0.238308\n",
      "Reconstruction: 0.171010, Regularization: 0.002312, Discriminator: 0.043327; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:49,060 root         INFO     Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 0.221686\n",
      "Reconstruction: 0.154680, Regularization: 0.002043, Discriminator: 0.043304; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:49,158 root         INFO     Train Epoch: 128 [5632/8000 (70%)]\tTotal Loss: 0.233445\n",
      "Reconstruction: 0.166313, Regularization: 0.002187, Discriminator: 0.043284; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:49,256 root         INFO     Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 0.286546\n",
      "Reconstruction: 0.218109, Regularization: 0.003444, Discriminator: 0.043329; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:49,352 root         INFO     Train Epoch: 128 [6656/8000 (83%)]\tTotal Loss: 0.227623\n",
      "Reconstruction: 0.160514, Regularization: 0.002117, Discriminator: 0.043330; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:49,450 root         INFO     Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 0.197470\n",
      "Reconstruction: 0.131464, Regularization: 0.001036, Discriminator: 0.043318; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:49,547 root         INFO     Train Epoch: 128 [7680/8000 (96%)]\tTotal Loss: 0.259928\n",
      "Reconstruction: 0.191898, Regularization: 0.003026, Discriminator: 0.043347; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:49,621 root         INFO     ====> Epoch: 128 Average loss: 0.2444\n",
      "2019-04-09 23:01:49,647 root         INFO     Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 0.232597\n",
      "Reconstruction: 0.165300, Regularization: 0.002302, Discriminator: 0.043337; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:49,747 root         INFO     Train Epoch: 129 [512/8000 (6%)]\tTotal Loss: 0.267614\n",
      "Reconstruction: 0.199646, Regularization: 0.002966, Discriminator: 0.043344; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:49,847 root         INFO     Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 0.232753\n",
      "Reconstruction: 0.165411, Regularization: 0.002355, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:49,945 root         INFO     Train Epoch: 129 [1536/8000 (19%)]\tTotal Loss: 0.237387\n",
      "Reconstruction: 0.170211, Regularization: 0.002192, Discriminator: 0.043326; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:50,044 root         INFO     Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 0.272990\n",
      "Reconstruction: 0.205034, Regularization: 0.002972, Discriminator: 0.043321; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:50,142 root         INFO     Train Epoch: 129 [2560/8000 (32%)]\tTotal Loss: 0.244910\n",
      "Reconstruction: 0.177557, Regularization: 0.002376, Discriminator: 0.043315; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:50,241 root         INFO     Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 0.288142\n",
      "Reconstruction: 0.220022, Regularization: 0.003143, Discriminator: 0.043309; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:50,339 root         INFO     Train Epoch: 129 [3584/8000 (45%)]\tTotal Loss: 0.233894\n",
      "Reconstruction: 0.166984, Regularization: 0.001923, Discriminator: 0.043319; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:50,437 root         INFO     Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 0.209027\n",
      "Reconstruction: 0.142435, Regularization: 0.001614, Discriminator: 0.043316; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:50,536 root         INFO     Train Epoch: 129 [4608/8000 (58%)]\tTotal Loss: 0.255489\n",
      "Reconstruction: 0.188004, Regularization: 0.002524, Discriminator: 0.043307; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:50,633 root         INFO     Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 0.246113\n",
      "Reconstruction: 0.178914, Regularization: 0.002212, Discriminator: 0.043330; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:50,734 root         INFO     Train Epoch: 129 [5632/8000 (70%)]\tTotal Loss: 0.234259\n",
      "Reconstruction: 0.167107, Regularization: 0.002163, Discriminator: 0.043326; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:50,831 root         INFO     Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 0.253212\n",
      "Reconstruction: 0.185637, Regularization: 0.002634, Discriminator: 0.043289; Generator: 0.021653,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:50,928 root         INFO     Train Epoch: 129 [6656/8000 (83%)]\tTotal Loss: 0.259163\n",
      "Reconstruction: 0.191384, Regularization: 0.002775, Discriminator: 0.043345; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:51,026 root         INFO     Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 0.227009\n",
      "Reconstruction: 0.159816, Regularization: 0.002219, Discriminator: 0.043316; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:51,122 root         INFO     Train Epoch: 129 [7680/8000 (96%)]\tTotal Loss: 0.261417\n",
      "Reconstruction: 0.193750, Regularization: 0.002670, Discriminator: 0.043327; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:51,195 root         INFO     ====> Epoch: 129 Average loss: 0.2444\n",
      "2019-04-09 23:01:51,221 root         INFO     Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 0.238442\n",
      "Reconstruction: 0.171295, Regularization: 0.002159, Discriminator: 0.043314; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:51,321 root         INFO     Train Epoch: 130 [512/8000 (6%)]\tTotal Loss: 0.278968\n",
      "Reconstruction: 0.210759, Regularization: 0.003207, Discriminator: 0.043324; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:51,421 root         INFO     Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 0.225120\n",
      "Reconstruction: 0.158470, Regularization: 0.001673, Discriminator: 0.043319; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:51,521 root         INFO     Train Epoch: 130 [1536/8000 (19%)]\tTotal Loss: 0.225717\n",
      "Reconstruction: 0.158568, Regularization: 0.002179, Discriminator: 0.043310; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:51,621 root         INFO     Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 0.248207\n",
      "Reconstruction: 0.180604, Regularization: 0.002604, Discriminator: 0.043350; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:51,720 root         INFO     Train Epoch: 130 [2560/8000 (32%)]\tTotal Loss: 0.280183\n",
      "Reconstruction: 0.212030, Regularization: 0.003156, Discriminator: 0.043337; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:51,817 root         INFO     Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 0.244552\n",
      "Reconstruction: 0.177200, Regularization: 0.002381, Discriminator: 0.043313; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:51,916 root         INFO     Train Epoch: 130 [3584/8000 (45%)]\tTotal Loss: 0.216844\n",
      "Reconstruction: 0.150143, Regularization: 0.001702, Discriminator: 0.043332; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:52,015 root         INFO     Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 0.299420\n",
      "Reconstruction: 0.230923, Regularization: 0.003524, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:52,113 root         INFO     Train Epoch: 130 [4608/8000 (58%)]\tTotal Loss: 0.214595\n",
      "Reconstruction: 0.147629, Regularization: 0.001974, Discriminator: 0.043340; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:52,212 root         INFO     Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 0.224039\n",
      "Reconstruction: 0.157183, Regularization: 0.001857, Discriminator: 0.043339; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:52,308 root         INFO     Train Epoch: 130 [5632/8000 (70%)]\tTotal Loss: 0.270521\n",
      "Reconstruction: 0.201969, Regularization: 0.003573, Discriminator: 0.043323; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:52,406 root         INFO     Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 0.234120\n",
      "Reconstruction: 0.166777, Regularization: 0.002361, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:52,502 root         INFO     Train Epoch: 130 [6656/8000 (83%)]\tTotal Loss: 0.212817\n",
      "Reconstruction: 0.146194, Regularization: 0.001643, Discriminator: 0.043316; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:52,599 root         INFO     Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 0.225737\n",
      "Reconstruction: 0.158722, Regularization: 0.002033, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:52,698 root         INFO     Train Epoch: 130 [7680/8000 (96%)]\tTotal Loss: 0.245892\n",
      "Reconstruction: 0.178108, Regularization: 0.002805, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:52,772 root         INFO     ====> Epoch: 130 Average loss: 0.2444\n",
      "2019-04-09 23:01:52,799 root         INFO     Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 0.225693\n",
      "Reconstruction: 0.158741, Regularization: 0.001973, Discriminator: 0.043317; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:52,899 root         INFO     Train Epoch: 131 [512/8000 (6%)]\tTotal Loss: 0.236522\n",
      "Reconstruction: 0.169243, Regularization: 0.002309, Discriminator: 0.043309; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:53,000 root         INFO     Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 0.227990\n",
      "Reconstruction: 0.160762, Regularization: 0.002244, Discriminator: 0.043329; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:53,100 root         INFO     Train Epoch: 131 [1536/8000 (19%)]\tTotal Loss: 0.282021\n",
      "Reconstruction: 0.213378, Regularization: 0.003669, Discriminator: 0.043308; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:53,200 root         INFO     Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 0.207157\n",
      "Reconstruction: 0.140454, Regularization: 0.001728, Discriminator: 0.043312; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:53,300 root         INFO     Train Epoch: 131 [2560/8000 (32%)]\tTotal Loss: 0.224125\n",
      "Reconstruction: 0.157191, Regularization: 0.001951, Discriminator: 0.043316; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:53,400 root         INFO     Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 0.214477\n",
      "Reconstruction: 0.147679, Regularization: 0.001828, Discriminator: 0.043311; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:53,501 root         INFO     Train Epoch: 131 [3584/8000 (45%)]\tTotal Loss: 0.273067\n",
      "Reconstruction: 0.205200, Regularization: 0.002893, Discriminator: 0.043314; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:53,601 root         INFO     Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 0.225904\n",
      "Reconstruction: 0.159047, Regularization: 0.001845, Discriminator: 0.043348; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:53,701 root         INFO     Train Epoch: 131 [4608/8000 (58%)]\tTotal Loss: 0.222938\n",
      "Reconstruction: 0.156129, Regularization: 0.001852, Discriminator: 0.043295; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:53,802 root         INFO     Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 0.240869\n",
      "Reconstruction: 0.173808, Regularization: 0.002093, Discriminator: 0.043306; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:53,900 root         INFO     Train Epoch: 131 [5632/8000 (70%)]\tTotal Loss: 0.253558\n",
      "Reconstruction: 0.186023, Regularization: 0.002549, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:54,000 root         INFO     Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 0.271696\n",
      "Reconstruction: 0.203872, Regularization: 0.002845, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:54,100 root         INFO     Train Epoch: 131 [6656/8000 (83%)]\tTotal Loss: 0.223311\n",
      "Reconstruction: 0.156408, Regularization: 0.001902, Discriminator: 0.043345; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:54,201 root         INFO     Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 0.197739\n",
      "Reconstruction: 0.131348, Regularization: 0.001392, Discriminator: 0.043342; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:54,301 root         INFO     Train Epoch: 131 [7680/8000 (96%)]\tTotal Loss: 0.255937\n",
      "Reconstruction: 0.188374, Regularization: 0.002574, Discriminator: 0.043327; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:54,376 root         INFO     ====> Epoch: 131 Average loss: 0.2446\n",
      "2019-04-09 23:01:54,402 root         INFO     Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 0.266825\n",
      "Reconstruction: 0.198825, Regularization: 0.003017, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:54,505 root         INFO     Train Epoch: 132 [512/8000 (6%)]\tTotal Loss: 0.250493\n",
      "Reconstruction: 0.183067, Regularization: 0.002443, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:54,607 root         INFO     Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 0.221708\n",
      "Reconstruction: 0.155065, Regularization: 0.001662, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:54,709 root         INFO     Train Epoch: 132 [1536/8000 (19%)]\tTotal Loss: 0.255012\n",
      "Reconstruction: 0.187597, Regularization: 0.002434, Discriminator: 0.043319; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:54,812 root         INFO     Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 0.225882\n",
      "Reconstruction: 0.158898, Regularization: 0.002000, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:54,914 root         INFO     Train Epoch: 132 [2560/8000 (32%)]\tTotal Loss: 0.242063\n",
      "Reconstruction: 0.174960, Regularization: 0.002134, Discriminator: 0.043311; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:55,016 root         INFO     Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 0.263893\n",
      "Reconstruction: 0.196037, Regularization: 0.002880, Discriminator: 0.043309; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:55,118 root         INFO     Train Epoch: 132 [3584/8000 (45%)]\tTotal Loss: 0.220533\n",
      "Reconstruction: 0.153587, Regularization: 0.001963, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:55,220 root         INFO     Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 0.250165\n",
      "Reconstruction: 0.182914, Regularization: 0.002291, Discriminator: 0.043295; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:55,322 root         INFO     Train Epoch: 132 [4608/8000 (58%)]\tTotal Loss: 0.253494\n",
      "Reconstruction: 0.185872, Regularization: 0.002628, Discriminator: 0.043326; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:55,420 root         INFO     Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 0.235673\n",
      "Reconstruction: 0.168605, Regularization: 0.002062, Discriminator: 0.043356; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:55,518 root         INFO     Train Epoch: 132 [5632/8000 (70%)]\tTotal Loss: 0.245756\n",
      "Reconstruction: 0.178343, Regularization: 0.002414, Discriminator: 0.043331; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:55,617 root         INFO     Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 0.236388\n",
      "Reconstruction: 0.169225, Regularization: 0.002211, Discriminator: 0.043294; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:55,714 root         INFO     Train Epoch: 132 [6656/8000 (83%)]\tTotal Loss: 0.234751\n",
      "Reconstruction: 0.167655, Regularization: 0.002119, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:55,812 root         INFO     Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 0.225617\n",
      "Reconstruction: 0.158737, Regularization: 0.001934, Discriminator: 0.043293; Generator: 0.021653,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:55,910 root         INFO     Train Epoch: 132 [7680/8000 (96%)]\tTotal Loss: 0.282011\n",
      "Reconstruction: 0.213610, Regularization: 0.003410, Discriminator: 0.043336; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:55,984 root         INFO     ====> Epoch: 132 Average loss: 0.2444\n",
      "2019-04-09 23:01:56,010 root         INFO     Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 0.273755\n",
      "Reconstruction: 0.205666, Regularization: 0.003116, Discriminator: 0.043325; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:56,111 root         INFO     Train Epoch: 133 [512/8000 (6%)]\tTotal Loss: 0.239489\n",
      "Reconstruction: 0.171905, Regularization: 0.002596, Discriminator: 0.043334; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:56,214 root         INFO     Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 0.228357\n",
      "Reconstruction: 0.161313, Regularization: 0.002055, Discriminator: 0.043332; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:56,316 root         INFO     Train Epoch: 133 [1536/8000 (19%)]\tTotal Loss: 0.264606\n",
      "Reconstruction: 0.196836, Regularization: 0.002804, Discriminator: 0.043311; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:56,418 root         INFO     Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 0.260118\n",
      "Reconstruction: 0.192142, Regularization: 0.002997, Discriminator: 0.043314; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:56,516 root         INFO     Train Epoch: 133 [2560/8000 (32%)]\tTotal Loss: 0.230800\n",
      "Reconstruction: 0.163634, Regularization: 0.002177, Discriminator: 0.043336; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:56,614 root         INFO     Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 0.223930\n",
      "Reconstruction: 0.157205, Regularization: 0.001757, Discriminator: 0.043310; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:56,712 root         INFO     Train Epoch: 133 [3584/8000 (45%)]\tTotal Loss: 0.275434\n",
      "Reconstruction: 0.206861, Regularization: 0.003596, Discriminator: 0.043325; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:56,811 root         INFO     Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 0.211737\n",
      "Reconstruction: 0.144948, Regularization: 0.001815, Discriminator: 0.043317; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:56,909 root         INFO     Train Epoch: 133 [4608/8000 (58%)]\tTotal Loss: 0.240266\n",
      "Reconstruction: 0.172515, Regularization: 0.002786, Discriminator: 0.043305; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:57,007 root         INFO     Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 0.236333\n",
      "Reconstruction: 0.168942, Regularization: 0.002422, Discriminator: 0.043309; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:57,105 root         INFO     Train Epoch: 133 [5632/8000 (70%)]\tTotal Loss: 0.224524\n",
      "Reconstruction: 0.157253, Regularization: 0.002312, Discriminator: 0.043304; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:57,204 root         INFO     Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 0.255482\n",
      "Reconstruction: 0.187603, Regularization: 0.002903, Discriminator: 0.043315; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:57,302 root         INFO     Train Epoch: 133 [6656/8000 (83%)]\tTotal Loss: 0.267081\n",
      "Reconstruction: 0.198690, Regularization: 0.003407, Discriminator: 0.043317; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:57,401 root         INFO     Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 0.219085\n",
      "Reconstruction: 0.152113, Regularization: 0.002023, Discriminator: 0.043290; Generator: 0.021660,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:01:57,498 root         INFO     Train Epoch: 133 [7680/8000 (96%)]\tTotal Loss: 0.228208\n",
      "Reconstruction: 0.161275, Regularization: 0.001939, Discriminator: 0.043336; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:57,572 root         INFO     ====> Epoch: 133 Average loss: 0.2445\n",
      "2019-04-09 23:01:57,599 root         INFO     Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 0.206695\n",
      "Reconstruction: 0.140094, Regularization: 0.001618, Discriminator: 0.043317; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:57,700 root         INFO     Train Epoch: 134 [512/8000 (6%)]\tTotal Loss: 0.230705\n",
      "Reconstruction: 0.163240, Regularization: 0.002491, Discriminator: 0.043316; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:57,799 root         INFO     Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 0.286840\n",
      "Reconstruction: 0.218313, Regularization: 0.003570, Discriminator: 0.043299; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:57,898 root         INFO     Train Epoch: 134 [1536/8000 (19%)]\tTotal Loss: 0.273858\n",
      "Reconstruction: 0.205662, Regularization: 0.003204, Discriminator: 0.043337; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:57,997 root         INFO     Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 0.294764\n",
      "Reconstruction: 0.225982, Regularization: 0.003794, Discriminator: 0.043321; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:58,096 root         INFO     Train Epoch: 134 [2560/8000 (32%)]\tTotal Loss: 0.224693\n",
      "Reconstruction: 0.157729, Regularization: 0.001953, Discriminator: 0.043349; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:58,195 root         INFO     Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 0.238185\n",
      "Reconstruction: 0.170868, Regularization: 0.002335, Discriminator: 0.043325; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:58,294 root         INFO     Train Epoch: 134 [3584/8000 (45%)]\tTotal Loss: 0.209445\n",
      "Reconstruction: 0.142660, Regularization: 0.001791, Discriminator: 0.043333; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:58,392 root         INFO     Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 0.258612\n",
      "Reconstruction: 0.190998, Regularization: 0.002631, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:58,491 root         INFO     Train Epoch: 134 [4608/8000 (58%)]\tTotal Loss: 0.229229\n",
      "Reconstruction: 0.161949, Regularization: 0.002290, Discriminator: 0.043328; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:58,591 root         INFO     Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 0.239181\n",
      "Reconstruction: 0.171906, Regularization: 0.002295, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:58,690 root         INFO     Train Epoch: 134 [5632/8000 (70%)]\tTotal Loss: 0.214361\n",
      "Reconstruction: 0.147975, Regularization: 0.001403, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:58,789 root         INFO     Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 0.231938\n",
      "Reconstruction: 0.164796, Regularization: 0.002161, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:58,888 root         INFO     Train Epoch: 134 [6656/8000 (83%)]\tTotal Loss: 0.247153\n",
      "Reconstruction: 0.179822, Regularization: 0.002353, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:58,988 root         INFO     Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 0.266878\n",
      "Reconstruction: 0.198927, Regularization: 0.002977, Discriminator: 0.043317; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:59,090 root         INFO     Train Epoch: 134 [7680/8000 (96%)]\tTotal Loss: 0.275222\n",
      "Reconstruction: 0.207129, Regularization: 0.003121, Discriminator: 0.043319; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:59,167 root         INFO     ====> Epoch: 134 Average loss: 0.2444\n",
      "2019-04-09 23:01:59,193 root         INFO     Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 0.230783\n",
      "Reconstruction: 0.163622, Regularization: 0.002174, Discriminator: 0.043325; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:59,294 root         INFO     Train Epoch: 135 [512/8000 (6%)]\tTotal Loss: 0.262021\n",
      "Reconstruction: 0.194491, Regularization: 0.002551, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:59,396 root         INFO     Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 0.216938\n",
      "Reconstruction: 0.150113, Regularization: 0.001841, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:59,497 root         INFO     Train Epoch: 135 [1536/8000 (19%)]\tTotal Loss: 0.238682\n",
      "Reconstruction: 0.171421, Regularization: 0.002274, Discriminator: 0.043323; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:59,598 root         INFO     Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 0.237181\n",
      "Reconstruction: 0.169701, Regularization: 0.002496, Discriminator: 0.043318; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:59,698 root         INFO     Train Epoch: 135 [2560/8000 (32%)]\tTotal Loss: 0.220346\n",
      "Reconstruction: 0.153416, Regularization: 0.001939, Discriminator: 0.043331; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:59,799 root         INFO     Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 0.251603\n",
      "Reconstruction: 0.183730, Regularization: 0.002900, Discriminator: 0.043315; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:59,899 root         INFO     Train Epoch: 135 [3584/8000 (45%)]\tTotal Loss: 0.237359\n",
      "Reconstruction: 0.170300, Regularization: 0.002077, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:01:59,997 root         INFO     Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 0.268253\n",
      "Reconstruction: 0.200229, Regularization: 0.003058, Discriminator: 0.043305; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:00,095 root         INFO     Train Epoch: 135 [4608/8000 (58%)]\tTotal Loss: 0.273594\n",
      "Reconstruction: 0.205494, Regularization: 0.003114, Discriminator: 0.043332; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:00,194 root         INFO     Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 0.269592\n",
      "Reconstruction: 0.201294, Regularization: 0.003331, Discriminator: 0.043311; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:00,292 root         INFO     Train Epoch: 135 [5632/8000 (70%)]\tTotal Loss: 0.239098\n",
      "Reconstruction: 0.171503, Regularization: 0.002607, Discriminator: 0.043323; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:00,391 root         INFO     Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 0.237678\n",
      "Reconstruction: 0.170475, Regularization: 0.002201, Discriminator: 0.043335; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:00,489 root         INFO     Train Epoch: 135 [6656/8000 (83%)]\tTotal Loss: 0.307535\n",
      "Reconstruction: 0.238675, Regularization: 0.003877, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:00,587 root         INFO     Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 0.299670\n",
      "Reconstruction: 0.231252, Regularization: 0.003439, Discriminator: 0.043328; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:00,685 root         INFO     Train Epoch: 135 [7680/8000 (96%)]\tTotal Loss: 0.213989\n",
      "Reconstruction: 0.147161, Regularization: 0.001871, Discriminator: 0.043306; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:00,759 root         INFO     ====> Epoch: 135 Average loss: 0.2441\n",
      "2019-04-09 23:02:00,785 root         INFO     Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 0.259182\n",
      "Reconstruction: 0.191451, Regularization: 0.002746, Discriminator: 0.043316; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:00,883 root         INFO     Train Epoch: 136 [512/8000 (6%)]\tTotal Loss: 0.277401\n",
      "Reconstruction: 0.209000, Regularization: 0.003418, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:00,980 root         INFO     Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 0.228260\n",
      "Reconstruction: 0.160929, Regularization: 0.002361, Discriminator: 0.043320; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:01,077 root         INFO     Train Epoch: 136 [1536/8000 (19%)]\tTotal Loss: 0.301138\n",
      "Reconstruction: 0.232090, Regularization: 0.004050, Discriminator: 0.043342; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:01,173 root         INFO     Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 0.295607\n",
      "Reconstruction: 0.227065, Regularization: 0.003566, Discriminator: 0.043313; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:01,269 root         INFO     Train Epoch: 136 [2560/8000 (32%)]\tTotal Loss: 0.248757\n",
      "Reconstruction: 0.180848, Regularization: 0.002924, Discriminator: 0.043320; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:01,366 root         INFO     Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 0.254905\n",
      "Reconstruction: 0.187281, Regularization: 0.002642, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:01,462 root         INFO     Train Epoch: 136 [3584/8000 (45%)]\tTotal Loss: 0.275326\n",
      "Reconstruction: 0.207011, Regularization: 0.003345, Discriminator: 0.043311; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:01,558 root         INFO     Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 0.274643\n",
      "Reconstruction: 0.206465, Regularization: 0.003194, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:01,654 root         INFO     Train Epoch: 136 [4608/8000 (58%)]\tTotal Loss: 0.237158\n",
      "Reconstruction: 0.169942, Regularization: 0.002233, Discriminator: 0.043321; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:01,750 root         INFO     Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 0.238234\n",
      "Reconstruction: 0.170954, Regularization: 0.002295, Discriminator: 0.043328; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:01,846 root         INFO     Train Epoch: 136 [5632/8000 (70%)]\tTotal Loss: 0.242045\n",
      "Reconstruction: 0.174470, Regularization: 0.002603, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:01,942 root         INFO     Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 0.278070\n",
      "Reconstruction: 0.209937, Regularization: 0.003131, Discriminator: 0.043339; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:02,038 root         INFO     Train Epoch: 136 [6656/8000 (83%)]\tTotal Loss: 0.263636\n",
      "Reconstruction: 0.195815, Regularization: 0.002859, Discriminator: 0.043308; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:02,135 root         INFO     Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 0.221306\n",
      "Reconstruction: 0.154286, Regularization: 0.002050, Discriminator: 0.043312; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:02,232 root         INFO     Train Epoch: 136 [7680/8000 (96%)]\tTotal Loss: 0.254794\n",
      "Reconstruction: 0.186966, Regularization: 0.002854, Discriminator: 0.043308; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:02,307 root         INFO     ====> Epoch: 136 Average loss: 0.2442\n",
      "2019-04-09 23:02:02,333 root         INFO     Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 0.245207\n",
      "Reconstruction: 0.177444, Regularization: 0.002783, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:02,433 root         INFO     Train Epoch: 137 [512/8000 (6%)]\tTotal Loss: 0.233050\n",
      "Reconstruction: 0.165889, Regularization: 0.002166, Discriminator: 0.043336; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:02,532 root         INFO     Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 0.209858\n",
      "Reconstruction: 0.143340, Regularization: 0.001544, Discriminator: 0.043315; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:02,628 root         INFO     Train Epoch: 137 [1536/8000 (19%)]\tTotal Loss: 0.224083\n",
      "Reconstruction: 0.157094, Regularization: 0.002010, Discriminator: 0.043315; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:02,726 root         INFO     Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 0.260458\n",
      "Reconstruction: 0.192590, Regularization: 0.002881, Discriminator: 0.043322; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:02,822 root         INFO     Train Epoch: 137 [2560/8000 (32%)]\tTotal Loss: 0.293140\n",
      "Reconstruction: 0.224286, Regularization: 0.003877, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:02,920 root         INFO     Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 0.280533\n",
      "Reconstruction: 0.212663, Regularization: 0.002880, Discriminator: 0.043331; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:03,018 root         INFO     Train Epoch: 137 [3584/8000 (45%)]\tTotal Loss: 0.255189\n",
      "Reconstruction: 0.187508, Regularization: 0.002691, Discriminator: 0.043328; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:03,114 root         INFO     Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 0.254631\n",
      "Reconstruction: 0.186926, Regularization: 0.002709, Discriminator: 0.043329; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:03,212 root         INFO     Train Epoch: 137 [4608/8000 (58%)]\tTotal Loss: 0.243042\n",
      "Reconstruction: 0.175628, Regularization: 0.002434, Discriminator: 0.043326; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:03,308 root         INFO     Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 0.219692\n",
      "Reconstruction: 0.152645, Regularization: 0.002070, Discriminator: 0.043321; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:03,406 root         INFO     Train Epoch: 137 [5632/8000 (70%)]\tTotal Loss: 0.254544\n",
      "Reconstruction: 0.186807, Regularization: 0.002759, Discriminator: 0.043317; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:03,504 root         INFO     Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 0.267903\n",
      "Reconstruction: 0.200113, Regularization: 0.002808, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:03,602 root         INFO     Train Epoch: 137 [6656/8000 (83%)]\tTotal Loss: 0.256239\n",
      "Reconstruction: 0.188583, Regularization: 0.002669, Discriminator: 0.043324; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:03,700 root         INFO     Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 0.235296\n",
      "Reconstruction: 0.168386, Regularization: 0.001932, Discriminator: 0.043320; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:03,796 root         INFO     Train Epoch: 137 [7680/8000 (96%)]\tTotal Loss: 0.245372\n",
      "Reconstruction: 0.178475, Regularization: 0.001915, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:03,871 root         INFO     ====> Epoch: 137 Average loss: 0.2445\n",
      "2019-04-09 23:02:03,898 root         INFO     Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 0.267381\n",
      "Reconstruction: 0.199646, Regularization: 0.002754, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:04,000 root         INFO     Train Epoch: 138 [512/8000 (6%)]\tTotal Loss: 0.223378\n",
      "Reconstruction: 0.156650, Regularization: 0.001753, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:04,101 root         INFO     Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 0.228244\n",
      "Reconstruction: 0.161307, Regularization: 0.001952, Discriminator: 0.043319; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:04,201 root         INFO     Train Epoch: 138 [1536/8000 (19%)]\tTotal Loss: 0.255018\n",
      "Reconstruction: 0.187607, Regularization: 0.002435, Discriminator: 0.043321; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:04,302 root         INFO     Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 0.227358\n",
      "Reconstruction: 0.160579, Regularization: 0.001798, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:04,402 root         INFO     Train Epoch: 138 [2560/8000 (32%)]\tTotal Loss: 0.263962\n",
      "Reconstruction: 0.196229, Regularization: 0.002755, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:04,504 root         INFO     Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 0.217080\n",
      "Reconstruction: 0.150368, Regularization: 0.001736, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:04,603 root         INFO     Train Epoch: 138 [3584/8000 (45%)]\tTotal Loss: 0.222024\n",
      "Reconstruction: 0.155104, Regularization: 0.001932, Discriminator: 0.043319; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:04,704 root         INFO     Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 0.233575\n",
      "Reconstruction: 0.166457, Regularization: 0.002118, Discriminator: 0.043330; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:04,804 root         INFO     Train Epoch: 138 [4608/8000 (58%)]\tTotal Loss: 0.196280\n",
      "Reconstruction: 0.130134, Regularization: 0.001150, Discriminator: 0.043338; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:04,905 root         INFO     Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 0.248939\n",
      "Reconstruction: 0.181719, Regularization: 0.002249, Discriminator: 0.043313; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:05,005 root         INFO     Train Epoch: 138 [5632/8000 (70%)]\tTotal Loss: 0.242118\n",
      "Reconstruction: 0.174829, Regularization: 0.002289, Discriminator: 0.043338; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:05,106 root         INFO     Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 0.236486\n",
      "Reconstruction: 0.169686, Regularization: 0.001806, Discriminator: 0.043329; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:05,206 root         INFO     Train Epoch: 138 [6656/8000 (83%)]\tTotal Loss: 0.252370\n",
      "Reconstruction: 0.184711, Regularization: 0.002666, Discriminator: 0.043325; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:05,304 root         INFO     Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 0.226303\n",
      "Reconstruction: 0.159350, Regularization: 0.001979, Discriminator: 0.043320; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:05,402 root         INFO     Train Epoch: 138 [7680/8000 (96%)]\tTotal Loss: 0.242180\n",
      "Reconstruction: 0.174876, Regularization: 0.002306, Discriminator: 0.043334; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:05,475 root         INFO     ====> Epoch: 138 Average loss: 0.2444\n",
      "2019-04-09 23:02:05,502 root         INFO     Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 0.233468\n",
      "Reconstruction: 0.166141, Regularization: 0.002344, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:05,601 root         INFO     Train Epoch: 139 [512/8000 (6%)]\tTotal Loss: 0.222269\n",
      "Reconstruction: 0.155263, Regularization: 0.002027, Discriminator: 0.043317; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:05,699 root         INFO     Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 0.251512\n",
      "Reconstruction: 0.183747, Regularization: 0.002783, Discriminator: 0.043319; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:05,797 root         INFO     Train Epoch: 139 [1536/8000 (19%)]\tTotal Loss: 0.223857\n",
      "Reconstruction: 0.157412, Regularization: 0.001465, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:05,896 root         INFO     Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 0.245969\n",
      "Reconstruction: 0.178363, Regularization: 0.002618, Discriminator: 0.043327; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:05,995 root         INFO     Train Epoch: 139 [2560/8000 (32%)]\tTotal Loss: 0.254010\n",
      "Reconstruction: 0.186373, Regularization: 0.002664, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:06,093 root         INFO     Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 0.249655\n",
      "Reconstruction: 0.182130, Regularization: 0.002538, Discriminator: 0.043328; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:06,191 root         INFO     Train Epoch: 139 [3584/8000 (45%)]\tTotal Loss: 0.262903\n",
      "Reconstruction: 0.195057, Regularization: 0.002865, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:06,290 root         INFO     Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 0.211510\n",
      "Reconstruction: 0.144892, Regularization: 0.001625, Discriminator: 0.043332; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:06,388 root         INFO     Train Epoch: 139 [4608/8000 (58%)]\tTotal Loss: 0.250921\n",
      "Reconstruction: 0.183383, Regularization: 0.002551, Discriminator: 0.043327; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:06,487 root         INFO     Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 0.289960\n",
      "Reconstruction: 0.221352, Regularization: 0.003635, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:06,585 root         INFO     Train Epoch: 139 [5632/8000 (70%)]\tTotal Loss: 0.241031\n",
      "Reconstruction: 0.173755, Regularization: 0.002301, Discriminator: 0.043316; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:06,683 root         INFO     Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 0.245688\n",
      "Reconstruction: 0.178184, Regularization: 0.002501, Discriminator: 0.043343; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:06,781 root         INFO     Train Epoch: 139 [6656/8000 (83%)]\tTotal Loss: 0.254210\n",
      "Reconstruction: 0.186394, Regularization: 0.002826, Discriminator: 0.043329; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:06,880 root         INFO     Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 0.277362\n",
      "Reconstruction: 0.209566, Regularization: 0.002825, Discriminator: 0.043309; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:06,980 root         INFO     Train Epoch: 139 [7680/8000 (96%)]\tTotal Loss: 0.281325\n",
      "Reconstruction: 0.213134, Regularization: 0.003203, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:07,054 root         INFO     ====> Epoch: 139 Average loss: 0.2445\n",
      "2019-04-09 23:02:07,080 root         INFO     Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 0.196493\n",
      "Reconstruction: 0.130156, Regularization: 0.001364, Discriminator: 0.043311; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:07,177 root         INFO     Train Epoch: 140 [512/8000 (6%)]\tTotal Loss: 0.272958\n",
      "Reconstruction: 0.205010, Regularization: 0.002977, Discriminator: 0.043307; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:07,274 root         INFO     Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 0.253156\n",
      "Reconstruction: 0.185466, Regularization: 0.002698, Discriminator: 0.043328; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:07,371 root         INFO     Train Epoch: 140 [1536/8000 (19%)]\tTotal Loss: 0.277575\n",
      "Reconstruction: 0.209429, Regularization: 0.003159, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:07,468 root         INFO     Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 0.243609\n",
      "Reconstruction: 0.176323, Regularization: 0.002300, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:07,566 root         INFO     Train Epoch: 140 [2560/8000 (32%)]\tTotal Loss: 0.226832\n",
      "Reconstruction: 0.160339, Regularization: 0.001486, Discriminator: 0.043347; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:07,663 root         INFO     Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 0.240132\n",
      "Reconstruction: 0.173043, Regularization: 0.002106, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:07,762 root         INFO     Train Epoch: 140 [3584/8000 (45%)]\tTotal Loss: 0.256376\n",
      "Reconstruction: 0.188892, Regularization: 0.002497, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:07,860 root         INFO     Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 0.252179\n",
      "Reconstruction: 0.184816, Regularization: 0.002380, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:07,957 root         INFO     Train Epoch: 140 [4608/8000 (58%)]\tTotal Loss: 0.249687\n",
      "Reconstruction: 0.182133, Regularization: 0.002567, Discriminator: 0.043321; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:08,054 root         INFO     Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 0.244085\n",
      "Reconstruction: 0.176740, Regularization: 0.002362, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:08,151 root         INFO     Train Epoch: 140 [5632/8000 (70%)]\tTotal Loss: 0.292724\n",
      "Reconstruction: 0.224348, Regularization: 0.003395, Discriminator: 0.043314; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:08,248 root         INFO     Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 0.253233\n",
      "Reconstruction: 0.185828, Regularization: 0.002429, Discriminator: 0.043320; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:08,345 root         INFO     Train Epoch: 140 [6656/8000 (83%)]\tTotal Loss: 0.241432\n",
      "Reconstruction: 0.174185, Regularization: 0.002252, Discriminator: 0.043326; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:08,442 root         INFO     Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 0.242691\n",
      "Reconstruction: 0.175241, Regularization: 0.002456, Discriminator: 0.043337; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:08,540 root         INFO     Train Epoch: 140 [7680/8000 (96%)]\tTotal Loss: 0.293942\n",
      "Reconstruction: 0.225463, Regularization: 0.003495, Discriminator: 0.043330; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:08,612 root         INFO     ====> Epoch: 140 Average loss: 0.2447\n",
      "2019-04-09 23:02:08,639 root         INFO     Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 0.264174\n",
      "Reconstruction: 0.196070, Regularization: 0.003127, Discriminator: 0.043311; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:08,736 root         INFO     Train Epoch: 141 [512/8000 (6%)]\tTotal Loss: 0.250522\n",
      "Reconstruction: 0.183035, Regularization: 0.002504, Discriminator: 0.043325; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:08,834 root         INFO     Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 0.206402\n",
      "Reconstruction: 0.139942, Regularization: 0.001463, Discriminator: 0.043332; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:08,929 root         INFO     Train Epoch: 141 [1536/8000 (19%)]\tTotal Loss: 0.246013\n",
      "Reconstruction: 0.178460, Regularization: 0.002578, Discriminator: 0.043319; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:09,024 root         INFO     Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 0.275135\n",
      "Reconstruction: 0.207051, Regularization: 0.003095, Discriminator: 0.043323; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:09,120 root         INFO     Train Epoch: 141 [2560/8000 (32%)]\tTotal Loss: 0.248720\n",
      "Reconstruction: 0.181150, Regularization: 0.002589, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:09,215 root         INFO     Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 0.263062\n",
      "Reconstruction: 0.195441, Regularization: 0.002644, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:09,310 root         INFO     Train Epoch: 141 [3584/8000 (45%)]\tTotal Loss: 0.226667\n",
      "Reconstruction: 0.159636, Regularization: 0.002048, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:09,405 root         INFO     Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 0.252717\n",
      "Reconstruction: 0.184986, Regularization: 0.002732, Discriminator: 0.043337; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:09,501 root         INFO     Train Epoch: 141 [4608/8000 (58%)]\tTotal Loss: 0.237167\n",
      "Reconstruction: 0.169859, Regularization: 0.002326, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:09,596 root         INFO     Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 0.231676\n",
      "Reconstruction: 0.164362, Regularization: 0.002327, Discriminator: 0.043325; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:09,692 root         INFO     Train Epoch: 141 [5632/8000 (70%)]\tTotal Loss: 0.241116\n",
      "Reconstruction: 0.174000, Regularization: 0.002143, Discriminator: 0.043314; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:09,788 root         INFO     Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 0.274023\n",
      "Reconstruction: 0.205793, Regularization: 0.003268, Discriminator: 0.043301; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:09,884 root         INFO     Train Epoch: 141 [6656/8000 (83%)]\tTotal Loss: 0.228547\n",
      "Reconstruction: 0.161716, Regularization: 0.001869, Discriminator: 0.043300; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:09,980 root         INFO     Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 0.214540\n",
      "Reconstruction: 0.147735, Regularization: 0.001808, Discriminator: 0.043336; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:10,076 root         INFO     Train Epoch: 141 [7680/8000 (96%)]\tTotal Loss: 0.272514\n",
      "Reconstruction: 0.204671, Regularization: 0.002863, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:10,148 root         INFO     ====> Epoch: 141 Average loss: 0.2443\n",
      "2019-04-09 23:02:10,174 root         INFO     Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 0.204488\n",
      "Reconstruction: 0.137933, Regularization: 0.001574, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:10,272 root         INFO     Train Epoch: 142 [512/8000 (6%)]\tTotal Loss: 0.239291\n",
      "Reconstruction: 0.172017, Regularization: 0.002307, Discriminator: 0.043309; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:10,370 root         INFO     Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 0.267156\n",
      "Reconstruction: 0.199252, Regularization: 0.002913, Discriminator: 0.043328; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:10,468 root         INFO     Train Epoch: 142 [1536/8000 (19%)]\tTotal Loss: 0.231679\n",
      "Reconstruction: 0.164457, Regularization: 0.002211, Discriminator: 0.043349; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:10,565 root         INFO     Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 0.254064\n",
      "Reconstruction: 0.186521, Regularization: 0.002563, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:10,663 root         INFO     Train Epoch: 142 [2560/8000 (32%)]\tTotal Loss: 0.229226\n",
      "Reconstruction: 0.162357, Regularization: 0.001887, Discriminator: 0.043319; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:10,760 root         INFO     Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 0.237062\n",
      "Reconstruction: 0.169800, Regularization: 0.002265, Discriminator: 0.043336; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:10,857 root         INFO     Train Epoch: 142 [3584/8000 (45%)]\tTotal Loss: 0.239334\n",
      "Reconstruction: 0.172017, Regularization: 0.002337, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:10,955 root         INFO     Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 0.214029\n",
      "Reconstruction: 0.147486, Regularization: 0.001563, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:11,052 root         INFO     Train Epoch: 142 [4608/8000 (58%)]\tTotal Loss: 0.258347\n",
      "Reconstruction: 0.190800, Regularization: 0.002567, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:11,149 root         INFO     Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 0.246981\n",
      "Reconstruction: 0.179623, Regularization: 0.002369, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:11,246 root         INFO     Train Epoch: 142 [5632/8000 (70%)]\tTotal Loss: 0.257668\n",
      "Reconstruction: 0.190358, Regularization: 0.002332, Discriminator: 0.043323; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:11,343 root         INFO     Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 0.233039\n",
      "Reconstruction: 0.166119, Regularization: 0.001941, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:11,438 root         INFO     Train Epoch: 142 [6656/8000 (83%)]\tTotal Loss: 0.236585\n",
      "Reconstruction: 0.169465, Regularization: 0.002135, Discriminator: 0.043330; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:11,534 root         INFO     Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 0.262201\n",
      "Reconstruction: 0.194706, Regularization: 0.002508, Discriminator: 0.043322; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:11,630 root         INFO     Train Epoch: 142 [7680/8000 (96%)]\tTotal Loss: 0.257178\n",
      "Reconstruction: 0.189691, Regularization: 0.002494, Discriminator: 0.043326; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:11,704 root         INFO     ====> Epoch: 142 Average loss: 0.2443\n",
      "2019-04-09 23:02:11,730 root         INFO     Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 0.223339\n",
      "Reconstruction: 0.156378, Regularization: 0.001978, Discriminator: 0.043334; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:11,829 root         INFO     Train Epoch: 143 [512/8000 (6%)]\tTotal Loss: 0.283694\n",
      "Reconstruction: 0.215364, Regularization: 0.003333, Discriminator: 0.043342; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:11,928 root         INFO     Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 0.268929\n",
      "Reconstruction: 0.200909, Regularization: 0.003027, Discriminator: 0.043327; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:12,027 root         INFO     Train Epoch: 143 [1536/8000 (19%)]\tTotal Loss: 0.250184\n",
      "Reconstruction: 0.182467, Regularization: 0.002745, Discriminator: 0.043310; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:12,125 root         INFO     Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 0.265003\n",
      "Reconstruction: 0.196972, Regularization: 0.003050, Discriminator: 0.043319; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:12,224 root         INFO     Train Epoch: 143 [2560/8000 (32%)]\tTotal Loss: 0.209769\n",
      "Reconstruction: 0.143233, Regularization: 0.001560, Discriminator: 0.043316; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:12,322 root         INFO     Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 0.271935\n",
      "Reconstruction: 0.203769, Regularization: 0.003177, Discriminator: 0.043329; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:12,421 root         INFO     Train Epoch: 143 [3584/8000 (45%)]\tTotal Loss: 0.241577\n",
      "Reconstruction: 0.174315, Regularization: 0.002271, Discriminator: 0.043332; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:12,519 root         INFO     Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 0.251436\n",
      "Reconstruction: 0.183641, Regularization: 0.002822, Discriminator: 0.043322; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:12,617 root         INFO     Train Epoch: 143 [4608/8000 (58%)]\tTotal Loss: 0.258387\n",
      "Reconstruction: 0.190589, Regularization: 0.002817, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:12,716 root         INFO     Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 0.258138\n",
      "Reconstruction: 0.190278, Regularization: 0.002880, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:12,814 root         INFO     Train Epoch: 143 [5632/8000 (70%)]\tTotal Loss: 0.260378\n",
      "Reconstruction: 0.192404, Regularization: 0.002991, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:12,912 root         INFO     Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 0.238001\n",
      "Reconstruction: 0.170638, Regularization: 0.002384, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:13,010 root         INFO     Train Epoch: 143 [6656/8000 (83%)]\tTotal Loss: 0.238529\n",
      "Reconstruction: 0.170967, Regularization: 0.002581, Discriminator: 0.043317; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:13,108 root         INFO     Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 0.191556\n",
      "Reconstruction: 0.125325, Regularization: 0.001254, Discriminator: 0.043321; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:13,207 root         INFO     Train Epoch: 143 [7680/8000 (96%)]\tTotal Loss: 0.290495\n",
      "Reconstruction: 0.222114, Regularization: 0.003393, Discriminator: 0.043325; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:13,283 root         INFO     ====> Epoch: 143 Average loss: 0.2444\n",
      "2019-04-09 23:02:13,310 root         INFO     Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 0.192904\n",
      "Reconstruction: 0.126720, Regularization: 0.001202, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:13,412 root         INFO     Train Epoch: 144 [512/8000 (6%)]\tTotal Loss: 0.245261\n",
      "Reconstruction: 0.177589, Regularization: 0.002687, Discriminator: 0.043326; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:13,513 root         INFO     Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 0.261070\n",
      "Reconstruction: 0.193637, Regularization: 0.002458, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:13,613 root         INFO     Train Epoch: 144 [1536/8000 (19%)]\tTotal Loss: 0.230101\n",
      "Reconstruction: 0.163044, Regularization: 0.002079, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:13,712 root         INFO     Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 0.285475\n",
      "Reconstruction: 0.216927, Regularization: 0.003570, Discriminator: 0.043325; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:13,812 root         INFO     Train Epoch: 144 [2560/8000 (32%)]\tTotal Loss: 0.255884\n",
      "Reconstruction: 0.188342, Regularization: 0.002558, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:13,911 root         INFO     Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 0.214889\n",
      "Reconstruction: 0.148244, Regularization: 0.001659, Discriminator: 0.043318; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:14,011 root         INFO     Train Epoch: 144 [3584/8000 (45%)]\tTotal Loss: 0.220252\n",
      "Reconstruction: 0.153420, Regularization: 0.001844, Discriminator: 0.043325; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:14,110 root         INFO     Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 0.224278\n",
      "Reconstruction: 0.157330, Regularization: 0.001953, Discriminator: 0.043329; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:14,209 root         INFO     Train Epoch: 144 [4608/8000 (58%)]\tTotal Loss: 0.237977\n",
      "Reconstruction: 0.170310, Regularization: 0.002680, Discriminator: 0.043321; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:14,308 root         INFO     Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 0.268839\n",
      "Reconstruction: 0.201168, Regularization: 0.002682, Discriminator: 0.043330; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:14,407 root         INFO     Train Epoch: 144 [5632/8000 (70%)]\tTotal Loss: 0.243442\n",
      "Reconstruction: 0.176091, Regularization: 0.002364, Discriminator: 0.043324; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:14,506 root         INFO     Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 0.279911\n",
      "Reconstruction: 0.211977, Regularization: 0.002954, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:14,604 root         INFO     Train Epoch: 144 [6656/8000 (83%)]\tTotal Loss: 0.252510\n",
      "Reconstruction: 0.184892, Regularization: 0.002624, Discriminator: 0.043329; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:14,703 root         INFO     Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 0.224746\n",
      "Reconstruction: 0.157653, Regularization: 0.002104, Discriminator: 0.043328; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:14,801 root         INFO     Train Epoch: 144 [7680/8000 (96%)]\tTotal Loss: 0.230464\n",
      "Reconstruction: 0.163317, Regularization: 0.002156, Discriminator: 0.043329; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:14,874 root         INFO     ====> Epoch: 144 Average loss: 0.2446\n",
      "2019-04-09 23:02:14,900 root         INFO     Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 0.215499\n",
      "Reconstruction: 0.148756, Regularization: 0.001765, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:15,000 root         INFO     Train Epoch: 145 [512/8000 (6%)]\tTotal Loss: 0.254232\n",
      "Reconstruction: 0.186739, Regularization: 0.002514, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:15,099 root         INFO     Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 0.232227\n",
      "Reconstruction: 0.164960, Regularization: 0.002295, Discriminator: 0.043320; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:15,197 root         INFO     Train Epoch: 145 [1536/8000 (19%)]\tTotal Loss: 0.313909\n",
      "Reconstruction: 0.245050, Regularization: 0.003879, Discriminator: 0.043316; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:15,294 root         INFO     Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 0.215625\n",
      "Reconstruction: 0.148792, Regularization: 0.001846, Discriminator: 0.043322; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:15,395 root         INFO     Train Epoch: 145 [2560/8000 (32%)]\tTotal Loss: 0.257692\n",
      "Reconstruction: 0.190362, Regularization: 0.002331, Discriminator: 0.043332; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:15,495 root         INFO     Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 0.204983\n",
      "Reconstruction: 0.138283, Regularization: 0.001719, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:15,594 root         INFO     Train Epoch: 145 [3584/8000 (45%)]\tTotal Loss: 0.240081\n",
      "Reconstruction: 0.173047, Regularization: 0.002058, Discriminator: 0.043314; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:15,694 root         INFO     Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 0.302240\n",
      "Reconstruction: 0.233636, Regularization: 0.003629, Discriminator: 0.043312; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:15,793 root         INFO     Train Epoch: 145 [4608/8000 (58%)]\tTotal Loss: 0.202410\n",
      "Reconstruction: 0.135699, Regularization: 0.001704, Discriminator: 0.043335; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:15,893 root         INFO     Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 0.242784\n",
      "Reconstruction: 0.175261, Regularization: 0.002549, Discriminator: 0.043316; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:15,992 root         INFO     Train Epoch: 145 [5632/8000 (70%)]\tTotal Loss: 0.254347\n",
      "Reconstruction: 0.186891, Regularization: 0.002472, Discriminator: 0.043328; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:16,093 root         INFO     Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 0.222038\n",
      "Reconstruction: 0.155170, Regularization: 0.001895, Discriminator: 0.043314; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:16,192 root         INFO     Train Epoch: 145 [6656/8000 (83%)]\tTotal Loss: 0.221386\n",
      "Reconstruction: 0.154512, Regularization: 0.001893, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:16,291 root         INFO     Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 0.210571\n",
      "Reconstruction: 0.144192, Regularization: 0.001396, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:16,390 root         INFO     Train Epoch: 145 [7680/8000 (96%)]\tTotal Loss: 0.243604\n",
      "Reconstruction: 0.176096, Regularization: 0.002529, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:16,464 root         INFO     ====> Epoch: 145 Average loss: 0.2444\n",
      "2019-04-09 23:02:16,491 root         INFO     Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 0.219882\n",
      "Reconstruction: 0.152863, Regularization: 0.002036, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:16,591 root         INFO     Train Epoch: 146 [512/8000 (6%)]\tTotal Loss: 0.209715\n",
      "Reconstruction: 0.143152, Regularization: 0.001577, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:16,691 root         INFO     Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 0.249089\n",
      "Reconstruction: 0.181608, Regularization: 0.002498, Discriminator: 0.043324; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:16,790 root         INFO     Train Epoch: 146 [1536/8000 (19%)]\tTotal Loss: 0.237495\n",
      "Reconstruction: 0.170210, Regularization: 0.002302, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:16,890 root         INFO     Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 0.228653\n",
      "Reconstruction: 0.161750, Regularization: 0.001920, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:16,990 root         INFO     Train Epoch: 146 [2560/8000 (32%)]\tTotal Loss: 0.278299\n",
      "Reconstruction: 0.209989, Regularization: 0.003327, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:17,090 root         INFO     Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 0.225454\n",
      "Reconstruction: 0.158376, Regularization: 0.002091, Discriminator: 0.043321; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:17,189 root         INFO     Train Epoch: 146 [3584/8000 (45%)]\tTotal Loss: 0.298493\n",
      "Reconstruction: 0.229997, Regularization: 0.003514, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:17,289 root         INFO     Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 0.220931\n",
      "Reconstruction: 0.154108, Regularization: 0.001842, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:17,388 root         INFO     Train Epoch: 146 [4608/8000 (58%)]\tTotal Loss: 0.264238\n",
      "Reconstruction: 0.196497, Regularization: 0.002765, Discriminator: 0.043314; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:17,488 root         INFO     Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 0.205537\n",
      "Reconstruction: 0.139023, Regularization: 0.001535, Discriminator: 0.043317; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:17,587 root         INFO     Train Epoch: 146 [5632/8000 (70%)]\tTotal Loss: 0.233707\n",
      "Reconstruction: 0.166556, Regularization: 0.002171, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:17,686 root         INFO     Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 0.272529\n",
      "Reconstruction: 0.204880, Regularization: 0.002676, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:17,785 root         INFO     Train Epoch: 146 [6656/8000 (83%)]\tTotal Loss: 0.251375\n",
      "Reconstruction: 0.183762, Regularization: 0.002631, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:17,885 root         INFO     Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 0.264008\n",
      "Reconstruction: 0.196286, Regularization: 0.002733, Discriminator: 0.043326; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:17,984 root         INFO     Train Epoch: 146 [7680/8000 (96%)]\tTotal Loss: 0.252706\n",
      "Reconstruction: 0.185103, Regularization: 0.002633, Discriminator: 0.043309; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:18,058 root         INFO     ====> Epoch: 146 Average loss: 0.2444\n",
      "2019-04-09 23:02:18,084 root         INFO     Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 0.259838\n",
      "Reconstruction: 0.192150, Regularization: 0.002695, Discriminator: 0.043331; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:18,186 root         INFO     Train Epoch: 147 [512/8000 (6%)]\tTotal Loss: 0.219272\n",
      "Reconstruction: 0.152623, Regularization: 0.001663, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:18,286 root         INFO     Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 0.247069\n",
      "Reconstruction: 0.179772, Regularization: 0.002319, Discriminator: 0.043315; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:18,387 root         INFO     Train Epoch: 147 [1536/8000 (19%)]\tTotal Loss: 0.241094\n",
      "Reconstruction: 0.173870, Regularization: 0.002240, Discriminator: 0.043324; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:18,488 root         INFO     Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 0.240148\n",
      "Reconstruction: 0.173008, Regularization: 0.002158, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:18,589 root         INFO     Train Epoch: 147 [2560/8000 (32%)]\tTotal Loss: 0.242448\n",
      "Reconstruction: 0.175447, Regularization: 0.002027, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:18,690 root         INFO     Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 0.227575\n",
      "Reconstruction: 0.160791, Regularization: 0.001802, Discriminator: 0.043318; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:18,791 root         INFO     Train Epoch: 147 [3584/8000 (45%)]\tTotal Loss: 0.246012\n",
      "Reconstruction: 0.178748, Regularization: 0.002292, Discriminator: 0.043311; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:18,893 root         INFO     Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 0.251309\n",
      "Reconstruction: 0.183776, Regularization: 0.002540, Discriminator: 0.043327; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:18,994 root         INFO     Train Epoch: 147 [4608/8000 (58%)]\tTotal Loss: 0.259635\n",
      "Reconstruction: 0.191838, Regularization: 0.002821, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:19,093 root         INFO     Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 0.213870\n",
      "Reconstruction: 0.147326, Regularization: 0.001559, Discriminator: 0.043328; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:19,192 root         INFO     Train Epoch: 147 [5632/8000 (70%)]\tTotal Loss: 0.245359\n",
      "Reconstruction: 0.178051, Regularization: 0.002339, Discriminator: 0.043313; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:19,292 root         INFO     Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 0.270664\n",
      "Reconstruction: 0.202614, Regularization: 0.003055, Discriminator: 0.043334; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:19,391 root         INFO     Train Epoch: 147 [6656/8000 (83%)]\tTotal Loss: 0.212672\n",
      "Reconstruction: 0.146017, Regularization: 0.001648, Discriminator: 0.043338; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:19,490 root         INFO     Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 0.260804\n",
      "Reconstruction: 0.193028, Regularization: 0.002788, Discriminator: 0.043324; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:19,588 root         INFO     Train Epoch: 147 [7680/8000 (96%)]\tTotal Loss: 0.231724\n",
      "Reconstruction: 0.164744, Regularization: 0.002014, Discriminator: 0.043310; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:19,662 root         INFO     ====> Epoch: 147 Average loss: 0.2444\n",
      "2019-04-09 23:02:19,689 root         INFO     Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 0.268837\n",
      "Reconstruction: 0.200825, Regularization: 0.003022, Discriminator: 0.043321; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:19,788 root         INFO     Train Epoch: 148 [512/8000 (6%)]\tTotal Loss: 0.265450\n",
      "Reconstruction: 0.197722, Regularization: 0.002739, Discriminator: 0.043331; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:19,888 root         INFO     Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 0.233600\n",
      "Reconstruction: 0.166495, Regularization: 0.002122, Discriminator: 0.043325; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:19,987 root         INFO     Train Epoch: 148 [1536/8000 (19%)]\tTotal Loss: 0.213587\n",
      "Reconstruction: 0.146933, Regularization: 0.001681, Discriminator: 0.043313; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:20,086 root         INFO     Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 0.226136\n",
      "Reconstruction: 0.159026, Regularization: 0.002129, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:20,185 root         INFO     Train Epoch: 148 [2560/8000 (32%)]\tTotal Loss: 0.266289\n",
      "Reconstruction: 0.198345, Regularization: 0.002967, Discriminator: 0.043314; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:20,284 root         INFO     Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 0.205007\n",
      "Reconstruction: 0.138424, Regularization: 0.001601, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:20,383 root         INFO     Train Epoch: 148 [3584/8000 (45%)]\tTotal Loss: 0.255570\n",
      "Reconstruction: 0.187814, Regularization: 0.002771, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:20,481 root         INFO     Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 0.222069\n",
      "Reconstruction: 0.155199, Regularization: 0.001886, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:20,580 root         INFO     Train Epoch: 148 [4608/8000 (58%)]\tTotal Loss: 0.239032\n",
      "Reconstruction: 0.171645, Regularization: 0.002411, Discriminator: 0.043312; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:20,679 root         INFO     Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 0.244012\n",
      "Reconstruction: 0.176429, Regularization: 0.002605, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:20,778 root         INFO     Train Epoch: 148 [5632/8000 (70%)]\tTotal Loss: 0.277573\n",
      "Reconstruction: 0.209442, Regularization: 0.003151, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:20,879 root         INFO     Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 0.221058\n",
      "Reconstruction: 0.154201, Regularization: 0.001873, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:20,979 root         INFO     Train Epoch: 148 [6656/8000 (83%)]\tTotal Loss: 0.208879\n",
      "Reconstruction: 0.142234, Regularization: 0.001667, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:21,080 root         INFO     Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 0.261475\n",
      "Reconstruction: 0.193790, Regularization: 0.002709, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:21,180 root         INFO     Train Epoch: 148 [7680/8000 (96%)]\tTotal Loss: 0.281093\n",
      "Reconstruction: 0.213029, Regularization: 0.003079, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:21,255 root         INFO     ====> Epoch: 148 Average loss: 0.2445\n",
      "2019-04-09 23:02:21,281 root         INFO     Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 0.231027\n",
      "Reconstruction: 0.163790, Regularization: 0.002257, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:21,382 root         INFO     Train Epoch: 149 [512/8000 (6%)]\tTotal Loss: 0.285361\n",
      "Reconstruction: 0.217067, Regularization: 0.003309, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:21,483 root         INFO     Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 0.214803\n",
      "Reconstruction: 0.147926, Regularization: 0.001896, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:21,581 root         INFO     Train Epoch: 149 [1536/8000 (19%)]\tTotal Loss: 0.225643\n",
      "Reconstruction: 0.158734, Regularization: 0.001929, Discriminator: 0.043317; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:21,679 root         INFO     Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 0.232327\n",
      "Reconstruction: 0.165284, Regularization: 0.002071, Discriminator: 0.043316; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:21,777 root         INFO     Train Epoch: 149 [2560/8000 (32%)]\tTotal Loss: 0.231221\n",
      "Reconstruction: 0.164256, Regularization: 0.001993, Discriminator: 0.043311; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:21,875 root         INFO     Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 0.263871\n",
      "Reconstruction: 0.196287, Regularization: 0.002585, Discriminator: 0.043337; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:21,973 root         INFO     Train Epoch: 149 [3584/8000 (45%)]\tTotal Loss: 0.219724\n",
      "Reconstruction: 0.152973, Regularization: 0.001778, Discriminator: 0.043320; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:22,071 root         INFO     Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 0.295832\n",
      "Reconstruction: 0.227525, Regularization: 0.003324, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:22,169 root         INFO     Train Epoch: 149 [4608/8000 (58%)]\tTotal Loss: 0.265071\n",
      "Reconstruction: 0.197199, Regularization: 0.002889, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:22,267 root         INFO     Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 0.239893\n",
      "Reconstruction: 0.172812, Regularization: 0.002098, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:22,365 root         INFO     Train Epoch: 149 [5632/8000 (70%)]\tTotal Loss: 0.261571\n",
      "Reconstruction: 0.193842, Regularization: 0.002749, Discriminator: 0.043318; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:22,463 root         INFO     Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 0.209084\n",
      "Reconstruction: 0.142505, Regularization: 0.001584, Discriminator: 0.043330; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:22,561 root         INFO     Train Epoch: 149 [6656/8000 (83%)]\tTotal Loss: 0.251061\n",
      "Reconstruction: 0.183691, Regularization: 0.002366, Discriminator: 0.043335; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:22,659 root         INFO     Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 0.283690\n",
      "Reconstruction: 0.215449, Regularization: 0.003269, Discriminator: 0.043318; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:22,759 root         INFO     Train Epoch: 149 [7680/8000 (96%)]\tTotal Loss: 0.250521\n",
      "Reconstruction: 0.182874, Regularization: 0.002668, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:22,833 root         INFO     ====> Epoch: 149 Average loss: 0.2445\n",
      "2019-04-09 23:02:22,860 root         INFO     Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 0.238717\n",
      "Reconstruction: 0.171494, Regularization: 0.002247, Discriminator: 0.043319; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:22,961 root         INFO     Train Epoch: 150 [512/8000 (6%)]\tTotal Loss: 0.297511\n",
      "Reconstruction: 0.228846, Regularization: 0.003690, Discriminator: 0.043314; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:23,062 root         INFO     Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 0.235923\n",
      "Reconstruction: 0.168789, Regularization: 0.002138, Discriminator: 0.043326; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:23,162 root         INFO     Train Epoch: 150 [1536/8000 (19%)]\tTotal Loss: 0.217639\n",
      "Reconstruction: 0.151108, Regularization: 0.001542, Discriminator: 0.043318; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:23,263 root         INFO     Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 0.255780\n",
      "Reconstruction: 0.188278, Regularization: 0.002521, Discriminator: 0.043313; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:23,363 root         INFO     Train Epoch: 150 [2560/8000 (32%)]\tTotal Loss: 0.240511\n",
      "Reconstruction: 0.173144, Regularization: 0.002410, Discriminator: 0.043305; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:23,464 root         INFO     Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 0.241012\n",
      "Reconstruction: 0.173477, Regularization: 0.002554, Discriminator: 0.043313; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:23,564 root         INFO     Train Epoch: 150 [3584/8000 (45%)]\tTotal Loss: 0.229978\n",
      "Reconstruction: 0.162899, Regularization: 0.002112, Discriminator: 0.043310; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:23,664 root         INFO     Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 0.262944\n",
      "Reconstruction: 0.195084, Regularization: 0.002871, Discriminator: 0.043331; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:23,765 root         INFO     Train Epoch: 150 [4608/8000 (58%)]\tTotal Loss: 0.229106\n",
      "Reconstruction: 0.161945, Regularization: 0.002193, Discriminator: 0.043313; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:23,865 root         INFO     Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 0.250445\n",
      "Reconstruction: 0.182976, Regularization: 0.002506, Discriminator: 0.043302; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:23,965 root         INFO     Train Epoch: 150 [5632/8000 (70%)]\tTotal Loss: 0.240835\n",
      "Reconstruction: 0.173420, Regularization: 0.002422, Discriminator: 0.043335; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:24,066 root         INFO     Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 0.263021\n",
      "Reconstruction: 0.195501, Regularization: 0.002549, Discriminator: 0.043313; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:24,166 root         INFO     Train Epoch: 150 [6656/8000 (83%)]\tTotal Loss: 0.212946\n",
      "Reconstruction: 0.146346, Regularization: 0.001603, Discriminator: 0.043339; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:24,267 root         INFO     Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 0.253751\n",
      "Reconstruction: 0.186146, Regularization: 0.002634, Discriminator: 0.043313; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:24,367 root         INFO     Train Epoch: 150 [7680/8000 (96%)]\tTotal Loss: 0.254939\n",
      "Reconstruction: 0.187361, Regularization: 0.002612, Discriminator: 0.043306; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:24,442 root         INFO     ====> Epoch: 150 Average loss: 0.2445\n",
      "2019-04-09 23:02:24,468 root         INFO     Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 0.233175\n",
      "Reconstruction: 0.166149, Regularization: 0.002041, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:24,568 root         INFO     Train Epoch: 151 [512/8000 (6%)]\tTotal Loss: 0.241974\n",
      "Reconstruction: 0.174988, Regularization: 0.001994, Discriminator: 0.043329; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:24,666 root         INFO     Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 0.253251\n",
      "Reconstruction: 0.185924, Regularization: 0.002347, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:24,765 root         INFO     Train Epoch: 151 [1536/8000 (19%)]\tTotal Loss: 0.232450\n",
      "Reconstruction: 0.165446, Regularization: 0.002023, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:24,864 root         INFO     Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 0.245570\n",
      "Reconstruction: 0.178356, Regularization: 0.002236, Discriminator: 0.043315; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:24,962 root         INFO     Train Epoch: 151 [2560/8000 (32%)]\tTotal Loss: 0.229794\n",
      "Reconstruction: 0.163018, Regularization: 0.001790, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:25,060 root         INFO     Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 0.250767\n",
      "Reconstruction: 0.183909, Regularization: 0.001862, Discriminator: 0.043327; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:25,158 root         INFO     Train Epoch: 151 [3584/8000 (45%)]\tTotal Loss: 0.212263\n",
      "Reconstruction: 0.146036, Regularization: 0.001228, Discriminator: 0.043332; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:25,256 root         INFO     Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 0.246965\n",
      "Reconstruction: 0.179611, Regularization: 0.002376, Discriminator: 0.043309; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:25,355 root         INFO     Train Epoch: 151 [4608/8000 (58%)]\tTotal Loss: 0.269229\n",
      "Reconstruction: 0.201558, Regularization: 0.002690, Discriminator: 0.043331; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:25,453 root         INFO     Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 0.229733\n",
      "Reconstruction: 0.162683, Regularization: 0.002097, Discriminator: 0.043307; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:25,552 root         INFO     Train Epoch: 151 [5632/8000 (70%)]\tTotal Loss: 0.246123\n",
      "Reconstruction: 0.178742, Regularization: 0.002431, Discriminator: 0.043302; Generator: 0.021647,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:02:25,650 root         INFO     Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 0.209986\n",
      "Reconstruction: 0.143494, Regularization: 0.001502, Discriminator: 0.043326; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:25,748 root         INFO     Train Epoch: 151 [6656/8000 (83%)]\tTotal Loss: 0.240033\n",
      "Reconstruction: 0.173079, Regularization: 0.001966, Discriminator: 0.043335; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:25,847 root         INFO     Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 0.267331\n",
      "Reconstruction: 0.199477, Regularization: 0.002869, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:25,945 root         INFO     Train Epoch: 151 [7680/8000 (96%)]\tTotal Loss: 0.271194\n",
      "Reconstruction: 0.203294, Regularization: 0.002914, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:26,021 root         INFO     ====> Epoch: 151 Average loss: 0.2448\n",
      "2019-04-09 23:02:26,047 root         INFO     Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 0.218523\n",
      "Reconstruction: 0.151834, Regularization: 0.001706, Discriminator: 0.043327; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:26,148 root         INFO     Train Epoch: 152 [512/8000 (6%)]\tTotal Loss: 0.271787\n",
      "Reconstruction: 0.203995, Regularization: 0.002813, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:26,245 root         INFO     Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 0.239886\n",
      "Reconstruction: 0.172819, Regularization: 0.002087, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:26,343 root         INFO     Train Epoch: 152 [1536/8000 (19%)]\tTotal Loss: 0.272589\n",
      "Reconstruction: 0.204775, Regularization: 0.002838, Discriminator: 0.043314; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:26,442 root         INFO     Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 0.221057\n",
      "Reconstruction: 0.154170, Regularization: 0.001918, Discriminator: 0.043309; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:26,540 root         INFO     Train Epoch: 152 [2560/8000 (32%)]\tTotal Loss: 0.232675\n",
      "Reconstruction: 0.165625, Regularization: 0.002066, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:26,638 root         INFO     Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 0.221014\n",
      "Reconstruction: 0.154222, Regularization: 0.001828, Discriminator: 0.043306; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:26,736 root         INFO     Train Epoch: 152 [3584/8000 (45%)]\tTotal Loss: 0.255080\n",
      "Reconstruction: 0.187649, Regularization: 0.002451, Discriminator: 0.043324; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:26,834 root         INFO     Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 0.249072\n",
      "Reconstruction: 0.181471, Regularization: 0.002626, Discriminator: 0.043316; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:26,932 root         INFO     Train Epoch: 152 [4608/8000 (58%)]\tTotal Loss: 0.244050\n",
      "Reconstruction: 0.176977, Regularization: 0.002090, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:27,030 root         INFO     Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 0.254393\n",
      "Reconstruction: 0.186965, Regularization: 0.002465, Discriminator: 0.043305; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:27,128 root         INFO     Train Epoch: 152 [5632/8000 (70%)]\tTotal Loss: 0.274569\n",
      "Reconstruction: 0.206915, Regularization: 0.002680, Discriminator: 0.043313; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:27,226 root         INFO     Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 0.231619\n",
      "Reconstruction: 0.164642, Regularization: 0.001981, Discriminator: 0.043333; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:27,324 root         INFO     Train Epoch: 152 [6656/8000 (83%)]\tTotal Loss: 0.272872\n",
      "Reconstruction: 0.205395, Regularization: 0.002519, Discriminator: 0.043307; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:27,422 root         INFO     Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 0.265719\n",
      "Reconstruction: 0.198185, Regularization: 0.002540, Discriminator: 0.043332; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:27,520 root         INFO     Train Epoch: 152 [7680/8000 (96%)]\tTotal Loss: 0.254326\n",
      "Reconstruction: 0.187265, Regularization: 0.002090, Discriminator: 0.043313; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:27,594 root         INFO     ====> Epoch: 152 Average loss: 0.2446\n",
      "2019-04-09 23:02:27,621 root         INFO     Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 0.215564\n",
      "Reconstruction: 0.148967, Regularization: 0.001622, Discriminator: 0.043316; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:27,722 root         INFO     Train Epoch: 153 [512/8000 (6%)]\tTotal Loss: 0.318275\n",
      "Reconstruction: 0.249593, Regularization: 0.003703, Discriminator: 0.043315; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:27,823 root         INFO     Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 0.189789\n",
      "Reconstruction: 0.123786, Regularization: 0.001019, Discriminator: 0.043326; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:27,924 root         INFO     Train Epoch: 153 [1536/8000 (19%)]\tTotal Loss: 0.238742\n",
      "Reconstruction: 0.172029, Regularization: 0.001733, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:28,025 root         INFO     Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 0.248553\n",
      "Reconstruction: 0.181467, Regularization: 0.002105, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:28,126 root         INFO     Train Epoch: 153 [2560/8000 (32%)]\tTotal Loss: 0.328677\n",
      "Reconstruction: 0.259985, Regularization: 0.003691, Discriminator: 0.043342; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:28,227 root         INFO     Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 0.265309\n",
      "Reconstruction: 0.197677, Regularization: 0.002636, Discriminator: 0.043338; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:28,327 root         INFO     Train Epoch: 153 [3584/8000 (45%)]\tTotal Loss: 0.205167\n",
      "Reconstruction: 0.138492, Regularization: 0.001693, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:28,428 root         INFO     Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 0.230797\n",
      "Reconstruction: 0.163921, Regularization: 0.001890, Discriminator: 0.043330; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:28,529 root         INFO     Train Epoch: 153 [4608/8000 (58%)]\tTotal Loss: 0.248751\n",
      "Reconstruction: 0.181218, Regularization: 0.002555, Discriminator: 0.043320; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:28,627 root         INFO     Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 0.258772\n",
      "Reconstruction: 0.191132, Regularization: 0.002657, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:28,724 root         INFO     Train Epoch: 153 [5632/8000 (70%)]\tTotal Loss: 0.260392\n",
      "Reconstruction: 0.192751, Regularization: 0.002681, Discriminator: 0.043304; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:28,821 root         INFO     Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 0.224307\n",
      "Reconstruction: 0.157282, Regularization: 0.002035, Discriminator: 0.043326; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:28,918 root         INFO     Train Epoch: 153 [6656/8000 (83%)]\tTotal Loss: 0.300211\n",
      "Reconstruction: 0.231714, Regularization: 0.003516, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:29,015 root         INFO     Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 0.242638\n",
      "Reconstruction: 0.175118, Regularization: 0.002542, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:29,112 root         INFO     Train Epoch: 153 [7680/8000 (96%)]\tTotal Loss: 0.252241\n",
      "Reconstruction: 0.184779, Regularization: 0.002479, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:29,185 root         INFO     ====> Epoch: 153 Average loss: 0.2447\n",
      "2019-04-09 23:02:29,211 root         INFO     Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 0.242760\n",
      "Reconstruction: 0.175365, Regularization: 0.002412, Discriminator: 0.043324; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:29,312 root         INFO     Train Epoch: 154 [512/8000 (6%)]\tTotal Loss: 0.256017\n",
      "Reconstruction: 0.188663, Regularization: 0.002378, Discriminator: 0.043315; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:29,413 root         INFO     Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 0.215165\n",
      "Reconstruction: 0.148379, Regularization: 0.001804, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:29,513 root         INFO     Train Epoch: 154 [1536/8000 (19%)]\tTotal Loss: 0.225207\n",
      "Reconstruction: 0.158210, Regularization: 0.002022, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:29,611 root         INFO     Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 0.280102\n",
      "Reconstruction: 0.212108, Regularization: 0.003009, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:29,709 root         INFO     Train Epoch: 154 [2560/8000 (32%)]\tTotal Loss: 0.228873\n",
      "Reconstruction: 0.162096, Regularization: 0.001799, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:29,808 root         INFO     Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 0.239026\n",
      "Reconstruction: 0.171886, Regularization: 0.002150, Discriminator: 0.043329; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:29,907 root         INFO     Train Epoch: 154 [3584/8000 (45%)]\tTotal Loss: 0.228598\n",
      "Reconstruction: 0.161612, Regularization: 0.002001, Discriminator: 0.043324; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:30,006 root         INFO     Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 0.217964\n",
      "Reconstruction: 0.151347, Regularization: 0.001635, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:30,103 root         INFO     Train Epoch: 154 [4608/8000 (58%)]\tTotal Loss: 0.200717\n",
      "Reconstruction: 0.134312, Regularization: 0.001439, Discriminator: 0.043307; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:30,202 root         INFO     Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 0.233455\n",
      "Reconstruction: 0.166317, Regularization: 0.002163, Discriminator: 0.043313; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:30,299 root         INFO     Train Epoch: 154 [5632/8000 (70%)]\tTotal Loss: 0.246833\n",
      "Reconstruction: 0.179690, Regularization: 0.002153, Discriminator: 0.043329; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:30,398 root         INFO     Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 0.237441\n",
      "Reconstruction: 0.170385, Regularization: 0.002049, Discriminator: 0.043347; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:30,497 root         INFO     Train Epoch: 154 [6656/8000 (83%)]\tTotal Loss: 0.266682\n",
      "Reconstruction: 0.198819, Regularization: 0.002870, Discriminator: 0.043332; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:30,595 root         INFO     Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 0.238554\n",
      "Reconstruction: 0.171467, Regularization: 0.002112, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:30,692 root         INFO     Train Epoch: 154 [7680/8000 (96%)]\tTotal Loss: 0.240744\n",
      "Reconstruction: 0.173605, Regularization: 0.002155, Discriminator: 0.043324; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:30,765 root         INFO     ====> Epoch: 154 Average loss: 0.2445\n",
      "2019-04-09 23:02:30,791 root         INFO     Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 0.319726\n",
      "Reconstruction: 0.250618, Regularization: 0.004126, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:30,889 root         INFO     Train Epoch: 155 [512/8000 (6%)]\tTotal Loss: 0.179688\n",
      "Reconstruction: 0.113811, Regularization: 0.000895, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:30,987 root         INFO     Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 0.231682\n",
      "Reconstruction: 0.164606, Regularization: 0.002094, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:31,083 root         INFO     Train Epoch: 155 [1536/8000 (19%)]\tTotal Loss: 0.246197\n",
      "Reconstruction: 0.178848, Regularization: 0.002381, Discriminator: 0.043310; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:31,181 root         INFO     Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 0.220028\n",
      "Reconstruction: 0.153349, Regularization: 0.001706, Discriminator: 0.043315; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:31,278 root         INFO     Train Epoch: 155 [2560/8000 (32%)]\tTotal Loss: 0.238922\n",
      "Reconstruction: 0.172004, Regularization: 0.001922, Discriminator: 0.043331; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:31,375 root         INFO     Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 0.215148\n",
      "Reconstruction: 0.148640, Regularization: 0.001538, Discriminator: 0.043310; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:31,472 root         INFO     Train Epoch: 155 [3584/8000 (45%)]\tTotal Loss: 0.264060\n",
      "Reconstruction: 0.196614, Regularization: 0.002476, Discriminator: 0.043315; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:31,570 root         INFO     Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 0.236669\n",
      "Reconstruction: 0.169640, Regularization: 0.002044, Discriminator: 0.043315; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:31,667 root         INFO     Train Epoch: 155 [4608/8000 (58%)]\tTotal Loss: 0.289787\n",
      "Reconstruction: 0.221746, Regularization: 0.003054, Discriminator: 0.043323; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:31,764 root         INFO     Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 0.264430\n",
      "Reconstruction: 0.196638, Regularization: 0.002806, Discriminator: 0.043321; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:31,862 root         INFO     Train Epoch: 155 [5632/8000 (70%)]\tTotal Loss: 0.301943\n",
      "Reconstruction: 0.233177, Regularization: 0.003788, Discriminator: 0.043310; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:31,959 root         INFO     Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 0.241950\n",
      "Reconstruction: 0.174769, Regularization: 0.002214, Discriminator: 0.043317; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:32,058 root         INFO     Train Epoch: 155 [6656/8000 (83%)]\tTotal Loss: 0.252994\n",
      "Reconstruction: 0.185421, Regularization: 0.002588, Discriminator: 0.043321; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:32,156 root         INFO     Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 0.258479\n",
      "Reconstruction: 0.190903, Regularization: 0.002590, Discriminator: 0.043335; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:32,254 root         INFO     Train Epoch: 155 [7680/8000 (96%)]\tTotal Loss: 0.240733\n",
      "Reconstruction: 0.173731, Regularization: 0.002010, Discriminator: 0.043336; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:32,327 root         INFO     ====> Epoch: 155 Average loss: 0.2444\n",
      "2019-04-09 23:02:32,355 root         INFO     Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 0.243932\n",
      "Reconstruction: 0.176433, Regularization: 0.002515, Discriminator: 0.043329; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:32,454 root         INFO     Train Epoch: 156 [512/8000 (6%)]\tTotal Loss: 0.256213\n",
      "Reconstruction: 0.188771, Regularization: 0.002455, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:32,552 root         INFO     Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 0.215686\n",
      "Reconstruction: 0.148926, Regularization: 0.001776, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:32,651 root         INFO     Train Epoch: 156 [1536/8000 (19%)]\tTotal Loss: 0.266605\n",
      "Reconstruction: 0.198894, Regularization: 0.002715, Discriminator: 0.043334; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:32,748 root         INFO     Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 0.250926\n",
      "Reconstruction: 0.183342, Regularization: 0.002599, Discriminator: 0.043330; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:32,847 root         INFO     Train Epoch: 156 [2560/8000 (32%)]\tTotal Loss: 0.236920\n",
      "Reconstruction: 0.169909, Regularization: 0.002028, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:32,945 root         INFO     Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 0.276851\n",
      "Reconstruction: 0.208603, Regularization: 0.003263, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:33,044 root         INFO     Train Epoch: 156 [3584/8000 (45%)]\tTotal Loss: 0.220811\n",
      "Reconstruction: 0.154014, Regularization: 0.001810, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:33,142 root         INFO     Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 0.272188\n",
      "Reconstruction: 0.203997, Regularization: 0.003217, Discriminator: 0.043319; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:33,240 root         INFO     Train Epoch: 156 [4608/8000 (58%)]\tTotal Loss: 0.251629\n",
      "Reconstruction: 0.184159, Regularization: 0.002487, Discriminator: 0.043316; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:33,339 root         INFO     Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 0.231790\n",
      "Reconstruction: 0.164840, Regularization: 0.001987, Discriminator: 0.043309; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:33,437 root         INFO     Train Epoch: 156 [5632/8000 (70%)]\tTotal Loss: 0.243178\n",
      "Reconstruction: 0.175719, Regularization: 0.002488, Discriminator: 0.043315; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:33,535 root         INFO     Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 0.213177\n",
      "Reconstruction: 0.146460, Regularization: 0.001731, Discriminator: 0.043327; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:33,633 root         INFO     Train Epoch: 156 [6656/8000 (83%)]\tTotal Loss: 0.296241\n",
      "Reconstruction: 0.227685, Regularization: 0.003567, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:33,731 root         INFO     Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 0.224529\n",
      "Reconstruction: 0.157732, Regularization: 0.001816, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:33,829 root         INFO     Train Epoch: 156 [7680/8000 (96%)]\tTotal Loss: 0.286953\n",
      "Reconstruction: 0.218756, Regularization: 0.003207, Discriminator: 0.043329; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:33,903 root         INFO     ====> Epoch: 156 Average loss: 0.2447\n",
      "2019-04-09 23:02:33,930 root         INFO     Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 0.261348\n",
      "Reconstruction: 0.193652, Regularization: 0.002713, Discriminator: 0.043319; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:34,029 root         INFO     Train Epoch: 157 [512/8000 (6%)]\tTotal Loss: 0.273923\n",
      "Reconstruction: 0.205932, Regularization: 0.002997, Discriminator: 0.043334; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:34,127 root         INFO     Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 0.239223\n",
      "Reconstruction: 0.172152, Regularization: 0.002078, Discriminator: 0.043333; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:34,225 root         INFO     Train Epoch: 157 [1536/8000 (19%)]\tTotal Loss: 0.232043\n",
      "Reconstruction: 0.165093, Regularization: 0.001972, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:34,324 root         INFO     Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 0.261930\n",
      "Reconstruction: 0.194211, Regularization: 0.002744, Discriminator: 0.043312; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:34,422 root         INFO     Train Epoch: 157 [2560/8000 (32%)]\tTotal Loss: 0.245556\n",
      "Reconstruction: 0.178256, Regularization: 0.002321, Discriminator: 0.043315; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:34,521 root         INFO     Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 0.228739\n",
      "Reconstruction: 0.161921, Regularization: 0.001827, Discriminator: 0.043331; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:34,619 root         INFO     Train Epoch: 157 [3584/8000 (45%)]\tTotal Loss: 0.201361\n",
      "Reconstruction: 0.135033, Regularization: 0.001356, Discriminator: 0.043313; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:34,717 root         INFO     Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 0.285210\n",
      "Reconstruction: 0.217056, Regularization: 0.003164, Discriminator: 0.043328; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:34,816 root         INFO     Train Epoch: 157 [4608/8000 (58%)]\tTotal Loss: 0.272370\n",
      "Reconstruction: 0.204940, Regularization: 0.002442, Discriminator: 0.043329; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:34,914 root         INFO     Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 0.224174\n",
      "Reconstruction: 0.157351, Regularization: 0.001815, Discriminator: 0.043342; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:35,012 root         INFO     Train Epoch: 157 [5632/8000 (70%)]\tTotal Loss: 0.236166\n",
      "Reconstruction: 0.169303, Regularization: 0.001892, Discriminator: 0.043313; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:35,111 root         INFO     Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 0.256963\n",
      "Reconstruction: 0.189440, Regularization: 0.002529, Discriminator: 0.043318; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:35,214 root         INFO     Train Epoch: 157 [6656/8000 (83%)]\tTotal Loss: 0.262361\n",
      "Reconstruction: 0.194898, Regularization: 0.002491, Discriminator: 0.043318; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:35,316 root         INFO     Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 0.260695\n",
      "Reconstruction: 0.193163, Regularization: 0.002571, Discriminator: 0.043306; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:35,418 root         INFO     Train Epoch: 157 [7680/8000 (96%)]\tTotal Loss: 0.268397\n",
      "Reconstruction: 0.200703, Regularization: 0.002714, Discriminator: 0.043326; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:35,494 root         INFO     ====> Epoch: 157 Average loss: 0.2444\n",
      "2019-04-09 23:02:35,520 root         INFO     Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 0.270288\n",
      "Reconstruction: 0.202600, Regularization: 0.002700, Discriminator: 0.043327; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:35,622 root         INFO     Train Epoch: 158 [512/8000 (6%)]\tTotal Loss: 0.226321\n",
      "Reconstruction: 0.159598, Regularization: 0.001742, Discriminator: 0.043325; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:35,723 root         INFO     Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 0.225131\n",
      "Reconstruction: 0.158328, Regularization: 0.001824, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:35,824 root         INFO     Train Epoch: 158 [1536/8000 (19%)]\tTotal Loss: 0.268738\n",
      "Reconstruction: 0.201046, Regularization: 0.002707, Discriminator: 0.043321; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:35,926 root         INFO     Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 0.293268\n",
      "Reconstruction: 0.225217, Regularization: 0.003067, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:36,027 root         INFO     Train Epoch: 158 [2560/8000 (32%)]\tTotal Loss: 0.283036\n",
      "Reconstruction: 0.215029, Regularization: 0.003025, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:36,128 root         INFO     Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 0.254769\n",
      "Reconstruction: 0.187163, Regularization: 0.002617, Discriminator: 0.043329; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:36,229 root         INFO     Train Epoch: 158 [3584/8000 (45%)]\tTotal Loss: 0.233572\n",
      "Reconstruction: 0.166684, Regularization: 0.001897, Discriminator: 0.043332; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:36,331 root         INFO     Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 0.223345\n",
      "Reconstruction: 0.156745, Regularization: 0.001629, Discriminator: 0.043310; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:36,432 root         INFO     Train Epoch: 158 [4608/8000 (58%)]\tTotal Loss: 0.227492\n",
      "Reconstruction: 0.160638, Regularization: 0.001877, Discriminator: 0.043317; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:36,533 root         INFO     Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 0.218493\n",
      "Reconstruction: 0.151712, Regularization: 0.001801, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:36,634 root         INFO     Train Epoch: 158 [5632/8000 (70%)]\tTotal Loss: 0.204181\n",
      "Reconstruction: 0.137869, Regularization: 0.001328, Discriminator: 0.043321; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:36,735 root         INFO     Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 0.215623\n",
      "Reconstruction: 0.149162, Regularization: 0.001466, Discriminator: 0.043332; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:36,833 root         INFO     Train Epoch: 158 [6656/8000 (83%)]\tTotal Loss: 0.244355\n",
      "Reconstruction: 0.177084, Regularization: 0.002299, Discriminator: 0.043312; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:36,931 root         INFO     Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 0.236919\n",
      "Reconstruction: 0.169920, Regularization: 0.002017, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:37,029 root         INFO     Train Epoch: 158 [7680/8000 (96%)]\tTotal Loss: 0.263843\n",
      "Reconstruction: 0.196335, Regularization: 0.002528, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:37,103 root         INFO     ====> Epoch: 158 Average loss: 0.2446\n",
      "2019-04-09 23:02:37,128 root         INFO     Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 0.240241\n",
      "Reconstruction: 0.172993, Regularization: 0.002272, Discriminator: 0.043316; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:37,229 root         INFO     Train Epoch: 159 [512/8000 (6%)]\tTotal Loss: 0.227342\n",
      "Reconstruction: 0.160424, Regularization: 0.001937, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:37,328 root         INFO     Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 0.230498\n",
      "Reconstruction: 0.163605, Regularization: 0.001904, Discriminator: 0.043330; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:37,428 root         INFO     Train Epoch: 159 [1536/8000 (19%)]\tTotal Loss: 0.255699\n",
      "Reconstruction: 0.188488, Regularization: 0.002229, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:37,527 root         INFO     Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 0.304546\n",
      "Reconstruction: 0.235888, Regularization: 0.003673, Discriminator: 0.043321; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:37,626 root         INFO     Train Epoch: 159 [2560/8000 (32%)]\tTotal Loss: 0.232450\n",
      "Reconstruction: 0.165289, Regularization: 0.002176, Discriminator: 0.043325; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:37,726 root         INFO     Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 0.265967\n",
      "Reconstruction: 0.198218, Regularization: 0.002758, Discriminator: 0.043330; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:37,825 root         INFO     Train Epoch: 159 [3584/8000 (45%)]\tTotal Loss: 0.296574\n",
      "Reconstruction: 0.228260, Regularization: 0.003318, Discriminator: 0.043323; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:37,923 root         INFO     Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 0.207864\n",
      "Reconstruction: 0.141585, Regularization: 0.001300, Discriminator: 0.043317; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:38,020 root         INFO     Train Epoch: 159 [4608/8000 (58%)]\tTotal Loss: 0.253681\n",
      "Reconstruction: 0.186294, Regularization: 0.002408, Discriminator: 0.043317; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:38,118 root         INFO     Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 0.261675\n",
      "Reconstruction: 0.194358, Regularization: 0.002323, Discriminator: 0.043333; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:38,214 root         INFO     Train Epoch: 159 [5632/8000 (70%)]\tTotal Loss: 0.243541\n",
      "Reconstruction: 0.176347, Regularization: 0.002202, Discriminator: 0.043332; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:38,311 root         INFO     Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 0.294429\n",
      "Reconstruction: 0.225984, Regularization: 0.003466, Discriminator: 0.043323; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:38,408 root         INFO     Train Epoch: 159 [6656/8000 (83%)]\tTotal Loss: 0.209369\n",
      "Reconstruction: 0.142866, Regularization: 0.001518, Discriminator: 0.043327; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:38,505 root         INFO     Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 0.278275\n",
      "Reconstruction: 0.210055, Regularization: 0.003239, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:38,602 root         INFO     Train Epoch: 159 [7680/8000 (96%)]\tTotal Loss: 0.285969\n",
      "Reconstruction: 0.217783, Regularization: 0.003203, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:38,675 root         INFO     ====> Epoch: 159 Average loss: 0.2449\n",
      "2019-04-09 23:02:38,702 root         INFO     Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 0.253384\n",
      "Reconstruction: 0.185833, Regularization: 0.002567, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:38,804 root         INFO     Train Epoch: 160 [512/8000 (6%)]\tTotal Loss: 0.235757\n",
      "Reconstruction: 0.168624, Regularization: 0.002148, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:38,904 root         INFO     Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 0.253850\n",
      "Reconstruction: 0.186483, Regularization: 0.002390, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:39,005 root         INFO     Train Epoch: 160 [1536/8000 (19%)]\tTotal Loss: 0.258055\n",
      "Reconstruction: 0.190460, Regularization: 0.002619, Discriminator: 0.043315; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:39,106 root         INFO     Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 0.227438\n",
      "Reconstruction: 0.160564, Regularization: 0.001891, Discriminator: 0.043324; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:39,204 root         INFO     Train Epoch: 160 [2560/8000 (32%)]\tTotal Loss: 0.283435\n",
      "Reconstruction: 0.215253, Regularization: 0.003207, Discriminator: 0.043316; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:39,302 root         INFO     Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 0.223920\n",
      "Reconstruction: 0.156876, Regularization: 0.002077, Discriminator: 0.043306; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:39,401 root         INFO     Train Epoch: 160 [3584/8000 (45%)]\tTotal Loss: 0.244474\n",
      "Reconstruction: 0.177042, Regularization: 0.002445, Discriminator: 0.043325; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:39,501 root         INFO     Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 0.255771\n",
      "Reconstruction: 0.188164, Regularization: 0.002642, Discriminator: 0.043304; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:39,600 root         INFO     Train Epoch: 160 [4608/8000 (58%)]\tTotal Loss: 0.255615\n",
      "Reconstruction: 0.188126, Regularization: 0.002515, Discriminator: 0.043318; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:39,698 root         INFO     Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 0.248000\n",
      "Reconstruction: 0.180998, Regularization: 0.002021, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:39,796 root         INFO     Train Epoch: 160 [5632/8000 (70%)]\tTotal Loss: 0.247702\n",
      "Reconstruction: 0.180262, Regularization: 0.002452, Discriminator: 0.043328; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:39,894 root         INFO     Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 0.221621\n",
      "Reconstruction: 0.154673, Regularization: 0.001966, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:39,992 root         INFO     Train Epoch: 160 [6656/8000 (83%)]\tTotal Loss: 0.219846\n",
      "Reconstruction: 0.153037, Regularization: 0.001825, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:40,090 root         INFO     Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 0.241171\n",
      "Reconstruction: 0.173941, Regularization: 0.002248, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:40,188 root         INFO     Train Epoch: 160 [7680/8000 (96%)]\tTotal Loss: 0.269850\n",
      "Reconstruction: 0.202166, Regularization: 0.002700, Discriminator: 0.043327; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:40,262 root         INFO     ====> Epoch: 160 Average loss: 0.2445\n",
      "2019-04-09 23:02:40,288 root         INFO     Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 0.285448\n",
      "Reconstruction: 0.217318, Regularization: 0.003147, Discriminator: 0.043325; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:40,387 root         INFO     Train Epoch: 161 [512/8000 (6%)]\tTotal Loss: 0.265165\n",
      "Reconstruction: 0.197563, Regularization: 0.002614, Discriminator: 0.043326; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:40,487 root         INFO     Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 0.233669\n",
      "Reconstruction: 0.166633, Regularization: 0.002050, Discriminator: 0.043323; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:40,585 root         INFO     Train Epoch: 161 [1536/8000 (19%)]\tTotal Loss: 0.265373\n",
      "Reconstruction: 0.197620, Regularization: 0.002768, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:40,684 root         INFO     Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 0.245205\n",
      "Reconstruction: 0.178026, Regularization: 0.002199, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:40,783 root         INFO     Train Epoch: 161 [2560/8000 (32%)]\tTotal Loss: 0.213386\n",
      "Reconstruction: 0.146730, Regularization: 0.001676, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:40,884 root         INFO     Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 0.256220\n",
      "Reconstruction: 0.188707, Regularization: 0.002515, Discriminator: 0.043325; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:40,984 root         INFO     Train Epoch: 161 [3584/8000 (45%)]\tTotal Loss: 0.239055\n",
      "Reconstruction: 0.171993, Regularization: 0.002094, Discriminator: 0.043304; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:41,084 root         INFO     Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 0.278158\n",
      "Reconstruction: 0.210187, Regularization: 0.003002, Discriminator: 0.043312; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:41,185 root         INFO     Train Epoch: 161 [4608/8000 (58%)]\tTotal Loss: 0.257481\n",
      "Reconstruction: 0.189843, Regularization: 0.002673, Discriminator: 0.043315; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:41,285 root         INFO     Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 0.253641\n",
      "Reconstruction: 0.186576, Regularization: 0.002084, Discriminator: 0.043327; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:41,386 root         INFO     Train Epoch: 161 [5632/8000 (70%)]\tTotal Loss: 0.221156\n",
      "Reconstruction: 0.154337, Regularization: 0.001841, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:41,487 root         INFO     Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 0.210852\n",
      "Reconstruction: 0.144294, Regularization: 0.001574, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:41,587 root         INFO     Train Epoch: 161 [6656/8000 (83%)]\tTotal Loss: 0.262688\n",
      "Reconstruction: 0.195096, Regularization: 0.002611, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:41,688 root         INFO     Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 0.209465\n",
      "Reconstruction: 0.142845, Regularization: 0.001639, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:41,789 root         INFO     Train Epoch: 161 [7680/8000 (96%)]\tTotal Loss: 0.245640\n",
      "Reconstruction: 0.178349, Regularization: 0.002310, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:41,863 root         INFO     ====> Epoch: 161 Average loss: 0.2446\n",
      "2019-04-09 23:02:41,891 root         INFO     Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 0.249546\n",
      "Reconstruction: 0.182154, Regularization: 0.002412, Discriminator: 0.043318; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:41,991 root         INFO     Train Epoch: 162 [512/8000 (6%)]\tTotal Loss: 0.270539\n",
      "Reconstruction: 0.202530, Regularization: 0.003027, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:42,091 root         INFO     Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 0.204578\n",
      "Reconstruction: 0.138234, Regularization: 0.001368, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:42,190 root         INFO     Train Epoch: 162 [1536/8000 (19%)]\tTotal Loss: 0.278839\n",
      "Reconstruction: 0.210612, Regularization: 0.003233, Discriminator: 0.043333; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:42,289 root         INFO     Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 0.253184\n",
      "Reconstruction: 0.185421, Regularization: 0.002768, Discriminator: 0.043331; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:42,388 root         INFO     Train Epoch: 162 [2560/8000 (32%)]\tTotal Loss: 0.224738\n",
      "Reconstruction: 0.157819, Regularization: 0.001966, Discriminator: 0.043302; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:42,488 root         INFO     Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 0.238870\n",
      "Reconstruction: 0.171342, Regularization: 0.002550, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:42,588 root         INFO     Train Epoch: 162 [3584/8000 (45%)]\tTotal Loss: 0.214479\n",
      "Reconstruction: 0.147896, Regularization: 0.001580, Discriminator: 0.043346; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:42,686 root         INFO     Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 0.263123\n",
      "Reconstruction: 0.195367, Regularization: 0.002791, Discriminator: 0.043311; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:42,784 root         INFO     Train Epoch: 162 [4608/8000 (58%)]\tTotal Loss: 0.270405\n",
      "Reconstruction: 0.202246, Regularization: 0.003193, Discriminator: 0.043310; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:42,882 root         INFO     Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 0.230662\n",
      "Reconstruction: 0.163632, Regularization: 0.002038, Discriminator: 0.043330; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:42,981 root         INFO     Train Epoch: 162 [5632/8000 (70%)]\tTotal Loss: 0.227327\n",
      "Reconstruction: 0.160478, Regularization: 0.001852, Discriminator: 0.043333; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:43,080 root         INFO     Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 0.243064\n",
      "Reconstruction: 0.175902, Regularization: 0.002179, Discriminator: 0.043325; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:43,180 root         INFO     Train Epoch: 162 [6656/8000 (83%)]\tTotal Loss: 0.259096\n",
      "Reconstruction: 0.191372, Regularization: 0.002757, Discriminator: 0.043313; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:43,280 root         INFO     Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 0.259242\n",
      "Reconstruction: 0.192298, Regularization: 0.001959, Discriminator: 0.043319; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:43,379 root         INFO     Train Epoch: 162 [7680/8000 (96%)]\tTotal Loss: 0.213154\n",
      "Reconstruction: 0.146496, Regularization: 0.001673, Discriminator: 0.043320; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:43,454 root         INFO     ====> Epoch: 162 Average loss: 0.2443\n",
      "2019-04-09 23:02:43,480 root         INFO     Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 0.242877\n",
      "Reconstruction: 0.175926, Regularization: 0.001971, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:43,581 root         INFO     Train Epoch: 163 [512/8000 (6%)]\tTotal Loss: 0.248803\n",
      "Reconstruction: 0.181300, Regularization: 0.002522, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:43,680 root         INFO     Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 0.257934\n",
      "Reconstruction: 0.190402, Regularization: 0.002571, Discriminator: 0.043299; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:43,779 root         INFO     Train Epoch: 163 [1536/8000 (19%)]\tTotal Loss: 0.251284\n",
      "Reconstruction: 0.183766, Regularization: 0.002513, Discriminator: 0.043336; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:43,878 root         INFO     Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 0.237893\n",
      "Reconstruction: 0.170677, Regularization: 0.002203, Discriminator: 0.043347; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:43,978 root         INFO     Train Epoch: 163 [2560/8000 (32%)]\tTotal Loss: 0.216518\n",
      "Reconstruction: 0.150002, Regularization: 0.001540, Discriminator: 0.043311; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:44,078 root         INFO     Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 0.231870\n",
      "Reconstruction: 0.164973, Regularization: 0.001917, Discriminator: 0.043328; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:44,177 root         INFO     Train Epoch: 163 [3584/8000 (45%)]\tTotal Loss: 0.278495\n",
      "Reconstruction: 0.210498, Regularization: 0.003014, Discriminator: 0.043329; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:44,275 root         INFO     Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 0.290514\n",
      "Reconstruction: 0.222217, Regularization: 0.003332, Discriminator: 0.043318; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:44,374 root         INFO     Train Epoch: 163 [4608/8000 (58%)]\tTotal Loss: 0.238005\n",
      "Reconstruction: 0.170698, Regularization: 0.002327, Discriminator: 0.043323; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:44,471 root         INFO     Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 0.196774\n",
      "Reconstruction: 0.130640, Regularization: 0.001137, Discriminator: 0.043330; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:44,568 root         INFO     Train Epoch: 163 [5632/8000 (70%)]\tTotal Loss: 0.238464\n",
      "Reconstruction: 0.171042, Regularization: 0.002433, Discriminator: 0.043331; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:44,664 root         INFO     Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 0.243899\n",
      "Reconstruction: 0.176517, Regularization: 0.002397, Discriminator: 0.043327; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:44,761 root         INFO     Train Epoch: 163 [6656/8000 (83%)]\tTotal Loss: 0.237701\n",
      "Reconstruction: 0.170666, Regularization: 0.002051, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:44,858 root         INFO     Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 0.251998\n",
      "Reconstruction: 0.184515, Regularization: 0.002506, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:44,954 root         INFO     Train Epoch: 163 [7680/8000 (96%)]\tTotal Loss: 0.267554\n",
      "Reconstruction: 0.199493, Regularization: 0.003070, Discriminator: 0.043332; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:45,027 root         INFO     ====> Epoch: 163 Average loss: 0.2447\n",
      "2019-04-09 23:02:45,054 root         INFO     Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 0.246805\n",
      "Reconstruction: 0.179256, Regularization: 0.002575, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:45,154 root         INFO     Train Epoch: 164 [512/8000 (6%)]\tTotal Loss: 0.234879\n",
      "Reconstruction: 0.167875, Regularization: 0.002028, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:45,254 root         INFO     Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 0.274893\n",
      "Reconstruction: 0.206719, Regularization: 0.003198, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:45,354 root         INFO     Train Epoch: 164 [1536/8000 (19%)]\tTotal Loss: 0.244088\n",
      "Reconstruction: 0.176804, Regularization: 0.002300, Discriminator: 0.043321; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:45,454 root         INFO     Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 0.228364\n",
      "Reconstruction: 0.161239, Regularization: 0.002139, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:45,555 root         INFO     Train Epoch: 164 [2560/8000 (32%)]\tTotal Loss: 0.285171\n",
      "Reconstruction: 0.216649, Regularization: 0.003496, Discriminator: 0.043367; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:02:45,655 root         INFO     Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 0.243648\n",
      "Reconstruction: 0.176307, Regularization: 0.002348, Discriminator: 0.043326; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:45,755 root         INFO     Train Epoch: 164 [3584/8000 (45%)]\tTotal Loss: 0.260345\n",
      "Reconstruction: 0.192732, Regularization: 0.002654, Discriminator: 0.043302; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:45,855 root         INFO     Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 0.243133\n",
      "Reconstruction: 0.175907, Regularization: 0.002234, Discriminator: 0.043334; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:45,956 root         INFO     Train Epoch: 164 [4608/8000 (58%)]\tTotal Loss: 0.224980\n",
      "Reconstruction: 0.158185, Regularization: 0.001814, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:46,059 root         INFO     Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 0.258433\n",
      "Reconstruction: 0.191102, Regularization: 0.002355, Discriminator: 0.043314; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:46,160 root         INFO     Train Epoch: 164 [5632/8000 (70%)]\tTotal Loss: 0.250887\n",
      "Reconstruction: 0.183582, Regularization: 0.002324, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:46,262 root         INFO     Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 0.225828\n",
      "Reconstruction: 0.159119, Regularization: 0.001731, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:46,364 root         INFO     Train Epoch: 164 [6656/8000 (83%)]\tTotal Loss: 0.236433\n",
      "Reconstruction: 0.169565, Regularization: 0.001889, Discriminator: 0.043314; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:46,465 root         INFO     Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 0.198331\n",
      "Reconstruction: 0.132132, Regularization: 0.001202, Discriminator: 0.043331; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:46,567 root         INFO     Train Epoch: 164 [7680/8000 (96%)]\tTotal Loss: 0.241230\n",
      "Reconstruction: 0.174033, Regularization: 0.002198, Discriminator: 0.043332; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:46,641 root         INFO     ====> Epoch: 164 Average loss: 0.2447\n",
      "2019-04-09 23:02:46,667 root         INFO     Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 0.237500\n",
      "Reconstruction: 0.170573, Regularization: 0.001954, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:46,768 root         INFO     Train Epoch: 165 [512/8000 (6%)]\tTotal Loss: 0.212568\n",
      "Reconstruction: 0.145990, Regularization: 0.001598, Discriminator: 0.043313; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:46,868 root         INFO     Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 0.250220\n",
      "Reconstruction: 0.182701, Regularization: 0.002546, Discriminator: 0.043303; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:46,968 root         INFO     Train Epoch: 165 [1536/8000 (19%)]\tTotal Loss: 0.221533\n",
      "Reconstruction: 0.154801, Regularization: 0.001751, Discriminator: 0.043312; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:47,068 root         INFO     Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 0.230474\n",
      "Reconstruction: 0.163453, Regularization: 0.002022, Discriminator: 0.043336; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:47,167 root         INFO     Train Epoch: 165 [2560/8000 (32%)]\tTotal Loss: 0.273928\n",
      "Reconstruction: 0.206234, Regularization: 0.002723, Discriminator: 0.043311; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:47,267 root         INFO     Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 0.218553\n",
      "Reconstruction: 0.152159, Regularization: 0.001425, Discriminator: 0.043310; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:47,367 root         INFO     Train Epoch: 165 [3584/8000 (45%)]\tTotal Loss: 0.214489\n",
      "Reconstruction: 0.147754, Regularization: 0.001765, Discriminator: 0.043320; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:47,466 root         INFO     Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 0.204471\n",
      "Reconstruction: 0.138198, Regularization: 0.001285, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:47,566 root         INFO     Train Epoch: 165 [4608/8000 (58%)]\tTotal Loss: 0.279698\n",
      "Reconstruction: 0.211554, Regularization: 0.003171, Discriminator: 0.043313; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:47,666 root         INFO     Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 0.247300\n",
      "Reconstruction: 0.179998, Regularization: 0.002310, Discriminator: 0.043334; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:47,766 root         INFO     Train Epoch: 165 [5632/8000 (70%)]\tTotal Loss: 0.241557\n",
      "Reconstruction: 0.174375, Regularization: 0.002198, Discriminator: 0.043325; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:47,866 root         INFO     Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 0.306768\n",
      "Reconstruction: 0.238032, Regularization: 0.003760, Discriminator: 0.043316; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:47,966 root         INFO     Train Epoch: 165 [6656/8000 (83%)]\tTotal Loss: 0.243872\n",
      "Reconstruction: 0.176654, Regularization: 0.002234, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:48,067 root         INFO     Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 0.210112\n",
      "Reconstruction: 0.143644, Regularization: 0.001485, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:48,166 root         INFO     Train Epoch: 165 [7680/8000 (96%)]\tTotal Loss: 0.210375\n",
      "Reconstruction: 0.143810, Regularization: 0.001584, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:48,241 root         INFO     ====> Epoch: 165 Average loss: 0.2445\n",
      "2019-04-09 23:02:48,267 root         INFO     Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 0.207394\n",
      "Reconstruction: 0.140786, Regularization: 0.001634, Discriminator: 0.043313; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:48,369 root         INFO     Train Epoch: 166 [512/8000 (6%)]\tTotal Loss: 0.241939\n",
      "Reconstruction: 0.174480, Regularization: 0.002464, Discriminator: 0.043332; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:48,470 root         INFO     Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 0.264904\n",
      "Reconstruction: 0.197238, Regularization: 0.002691, Discriminator: 0.043319; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:48,570 root         INFO     Train Epoch: 166 [1536/8000 (19%)]\tTotal Loss: 0.265270\n",
      "Reconstruction: 0.197306, Regularization: 0.002989, Discriminator: 0.043315; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:48,671 root         INFO     Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 0.307435\n",
      "Reconstruction: 0.238524, Regularization: 0.003914, Discriminator: 0.043335; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:48,772 root         INFO     Train Epoch: 166 [2560/8000 (32%)]\tTotal Loss: 0.253268\n",
      "Reconstruction: 0.185673, Regularization: 0.002611, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:48,872 root         INFO     Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 0.285974\n",
      "Reconstruction: 0.217942, Regularization: 0.003041, Discriminator: 0.043332; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:48,973 root         INFO     Train Epoch: 166 [3584/8000 (45%)]\tTotal Loss: 0.270738\n",
      "Reconstruction: 0.202854, Regularization: 0.002885, Discriminator: 0.043337; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:49,073 root         INFO     Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 0.237008\n",
      "Reconstruction: 0.170004, Regularization: 0.002009, Discriminator: 0.043333; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:49,173 root         INFO     Train Epoch: 166 [4608/8000 (58%)]\tTotal Loss: 0.233487\n",
      "Reconstruction: 0.166546, Regularization: 0.001949, Discriminator: 0.043332; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:49,273 root         INFO     Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 0.268739\n",
      "Reconstruction: 0.201123, Regularization: 0.002636, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:49,372 root         INFO     Train Epoch: 166 [5632/8000 (70%)]\tTotal Loss: 0.207859\n",
      "Reconstruction: 0.141224, Regularization: 0.001651, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:49,471 root         INFO     Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 0.240932\n",
      "Reconstruction: 0.173773, Regularization: 0.002175, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:49,570 root         INFO     Train Epoch: 166 [6656/8000 (83%)]\tTotal Loss: 0.222149\n",
      "Reconstruction: 0.155249, Regularization: 0.001914, Discriminator: 0.043320; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:49,670 root         INFO     Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 0.273417\n",
      "Reconstruction: 0.205575, Regularization: 0.002863, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:49,769 root         INFO     Train Epoch: 166 [7680/8000 (96%)]\tTotal Loss: 0.208870\n",
      "Reconstruction: 0.142466, Regularization: 0.001422, Discriminator: 0.043319; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:49,843 root         INFO     ====> Epoch: 166 Average loss: 0.2445\n",
      "2019-04-09 23:02:49,869 root         INFO     Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 0.270551\n",
      "Reconstruction: 0.202728, Regularization: 0.002839, Discriminator: 0.043321; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:49,970 root         INFO     Train Epoch: 167 [512/8000 (6%)]\tTotal Loss: 0.242246\n",
      "Reconstruction: 0.175254, Regularization: 0.002008, Discriminator: 0.043327; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:50,070 root         INFO     Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 0.249015\n",
      "Reconstruction: 0.181385, Regularization: 0.002648, Discriminator: 0.043317; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:50,170 root         INFO     Train Epoch: 167 [1536/8000 (19%)]\tTotal Loss: 0.288158\n",
      "Reconstruction: 0.219767, Regularization: 0.003416, Discriminator: 0.043316; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:50,270 root         INFO     Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 0.244063\n",
      "Reconstruction: 0.176649, Regularization: 0.002435, Discriminator: 0.043314; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:50,370 root         INFO     Train Epoch: 167 [2560/8000 (32%)]\tTotal Loss: 0.211365\n",
      "Reconstruction: 0.144800, Regularization: 0.001583, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:50,470 root         INFO     Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 0.294190\n",
      "Reconstruction: 0.225685, Regularization: 0.003517, Discriminator: 0.043332; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:50,570 root         INFO     Train Epoch: 167 [3584/8000 (45%)]\tTotal Loss: 0.284998\n",
      "Reconstruction: 0.217123, Regularization: 0.002904, Discriminator: 0.043312; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:50,670 root         INFO     Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 0.223141\n",
      "Reconstruction: 0.156474, Regularization: 0.001689, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:50,769 root         INFO     Train Epoch: 167 [4608/8000 (58%)]\tTotal Loss: 0.226981\n",
      "Reconstruction: 0.159945, Regularization: 0.002043, Discriminator: 0.043336; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:50,869 root         INFO     Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 0.238528\n",
      "Reconstruction: 0.171607, Regularization: 0.001940, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:50,968 root         INFO     Train Epoch: 167 [5632/8000 (70%)]\tTotal Loss: 0.243381\n",
      "Reconstruction: 0.176221, Regularization: 0.002178, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:51,067 root         INFO     Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 0.237565\n",
      "Reconstruction: 0.170244, Regularization: 0.002338, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:51,166 root         INFO     Train Epoch: 167 [6656/8000 (83%)]\tTotal Loss: 0.252943\n",
      "Reconstruction: 0.185286, Regularization: 0.002676, Discriminator: 0.043319; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:51,266 root         INFO     Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 0.201439\n",
      "Reconstruction: 0.134928, Regularization: 0.001529, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:51,365 root         INFO     Train Epoch: 167 [7680/8000 (96%)]\tTotal Loss: 0.270573\n",
      "Reconstruction: 0.202669, Regularization: 0.002914, Discriminator: 0.043324; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:51,439 root         INFO     ====> Epoch: 167 Average loss: 0.2444\n",
      "2019-04-09 23:02:51,465 root         INFO     Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 0.215654\n",
      "Reconstruction: 0.149069, Regularization: 0.001608, Discriminator: 0.043321; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:51,568 root         INFO     Train Epoch: 168 [512/8000 (6%)]\tTotal Loss: 0.243144\n",
      "Reconstruction: 0.175883, Regularization: 0.002286, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:51,667 root         INFO     Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 0.237714\n",
      "Reconstruction: 0.170573, Regularization: 0.002159, Discriminator: 0.043318; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:51,766 root         INFO     Train Epoch: 168 [1536/8000 (19%)]\tTotal Loss: 0.245760\n",
      "Reconstruction: 0.178591, Regularization: 0.002203, Discriminator: 0.043308; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:51,864 root         INFO     Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 0.220323\n",
      "Reconstruction: 0.153760, Regularization: 0.001579, Discriminator: 0.043324; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:51,963 root         INFO     Train Epoch: 168 [2560/8000 (32%)]\tTotal Loss: 0.235996\n",
      "Reconstruction: 0.168798, Regularization: 0.002213, Discriminator: 0.043327; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:52,061 root         INFO     Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 0.227630\n",
      "Reconstruction: 0.160644, Regularization: 0.002005, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:52,157 root         INFO     Train Epoch: 168 [3584/8000 (45%)]\tTotal Loss: 0.226890\n",
      "Reconstruction: 0.160174, Regularization: 0.001732, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:52,255 root         INFO     Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 0.238208\n",
      "Reconstruction: 0.171037, Regularization: 0.002196, Discriminator: 0.043316; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:52,352 root         INFO     Train Epoch: 168 [4608/8000 (58%)]\tTotal Loss: 0.244667\n",
      "Reconstruction: 0.177412, Regularization: 0.002287, Discriminator: 0.043305; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:52,449 root         INFO     Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 0.205706\n",
      "Reconstruction: 0.139249, Regularization: 0.001472, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:52,546 root         INFO     Train Epoch: 168 [5632/8000 (70%)]\tTotal Loss: 0.217622\n",
      "Reconstruction: 0.150998, Regularization: 0.001644, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:52,642 root         INFO     Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 0.268252\n",
      "Reconstruction: 0.200356, Regularization: 0.002921, Discriminator: 0.043318; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:52,740 root         INFO     Train Epoch: 168 [6656/8000 (83%)]\tTotal Loss: 0.289143\n",
      "Reconstruction: 0.220848, Regularization: 0.003302, Discriminator: 0.043332; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:52,835 root         INFO     Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 0.212398\n",
      "Reconstruction: 0.145898, Regularization: 0.001521, Discriminator: 0.043317; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:52,931 root         INFO     Train Epoch: 168 [7680/8000 (96%)]\tTotal Loss: 0.237395\n",
      "Reconstruction: 0.170310, Regularization: 0.002096, Discriminator: 0.043332; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:53,003 root         INFO     ====> Epoch: 168 Average loss: 0.2446\n",
      "2019-04-09 23:02:53,029 root         INFO     Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 0.266756\n",
      "Reconstruction: 0.199067, Regularization: 0.002699, Discriminator: 0.043327; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:53,124 root         INFO     Train Epoch: 169 [512/8000 (6%)]\tTotal Loss: 0.237424\n",
      "Reconstruction: 0.170310, Regularization: 0.002120, Discriminator: 0.043326; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:53,220 root         INFO     Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 0.213954\n",
      "Reconstruction: 0.147323, Regularization: 0.001645, Discriminator: 0.043327; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:53,315 root         INFO     Train Epoch: 169 [1536/8000 (19%)]\tTotal Loss: 0.258578\n",
      "Reconstruction: 0.191082, Regularization: 0.002517, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:53,411 root         INFO     Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 0.274717\n",
      "Reconstruction: 0.206716, Regularization: 0.003025, Discriminator: 0.043312; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:53,505 root         INFO     Train Epoch: 169 [2560/8000 (32%)]\tTotal Loss: 0.203610\n",
      "Reconstruction: 0.137318, Regularization: 0.001306, Discriminator: 0.043326; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:53,599 root         INFO     Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 0.253152\n",
      "Reconstruction: 0.185564, Regularization: 0.002606, Discriminator: 0.043325; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:53,693 root         INFO     Train Epoch: 169 [3584/8000 (45%)]\tTotal Loss: 0.285479\n",
      "Reconstruction: 0.217363, Regularization: 0.003136, Discriminator: 0.043324; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:53,788 root         INFO     Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 0.280378\n",
      "Reconstruction: 0.212386, Regularization: 0.002992, Discriminator: 0.043335; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:53,882 root         INFO     Train Epoch: 169 [4608/8000 (58%)]\tTotal Loss: 0.229342\n",
      "Reconstruction: 0.162507, Regularization: 0.001850, Discriminator: 0.043326; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:53,977 root         INFO     Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 0.252362\n",
      "Reconstruction: 0.185108, Regularization: 0.002273, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:54,071 root         INFO     Train Epoch: 169 [5632/8000 (70%)]\tTotal Loss: 0.217242\n",
      "Reconstruction: 0.150659, Regularization: 0.001606, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:54,165 root         INFO     Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 0.247522\n",
      "Reconstruction: 0.180021, Regularization: 0.002518, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:54,259 root         INFO     Train Epoch: 169 [6656/8000 (83%)]\tTotal Loss: 0.243306\n",
      "Reconstruction: 0.175886, Regularization: 0.002436, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:54,354 root         INFO     Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 0.212077\n",
      "Reconstruction: 0.145534, Regularization: 0.001557, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:54,448 root         INFO     Train Epoch: 169 [7680/8000 (96%)]\tTotal Loss: 0.258132\n",
      "Reconstruction: 0.190855, Regularization: 0.002295, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:54,520 root         INFO     ====> Epoch: 169 Average loss: 0.2445\n",
      "2019-04-09 23:02:54,546 root         INFO     Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 0.240283\n",
      "Reconstruction: 0.173164, Regularization: 0.002136, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:54,644 root         INFO     Train Epoch: 170 [512/8000 (6%)]\tTotal Loss: 0.271268\n",
      "Reconstruction: 0.203336, Regularization: 0.002951, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:54,741 root         INFO     Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 0.227656\n",
      "Reconstruction: 0.160733, Regularization: 0.001943, Discriminator: 0.043318; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:54,839 root         INFO     Train Epoch: 170 [1536/8000 (19%)]\tTotal Loss: 0.224358\n",
      "Reconstruction: 0.157564, Regularization: 0.001806, Discriminator: 0.043327; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:54,938 root         INFO     Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 0.266190\n",
      "Reconstruction: 0.198489, Regularization: 0.002723, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:55,036 root         INFO     Train Epoch: 170 [2560/8000 (32%)]\tTotal Loss: 0.282884\n",
      "Reconstruction: 0.214769, Regularization: 0.003132, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:55,134 root         INFO     Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 0.213931\n",
      "Reconstruction: 0.147211, Regularization: 0.001746, Discriminator: 0.043312; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:55,232 root         INFO     Train Epoch: 170 [3584/8000 (45%)]\tTotal Loss: 0.271712\n",
      "Reconstruction: 0.203823, Regularization: 0.002912, Discriminator: 0.043317; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:55,330 root         INFO     Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 0.236549\n",
      "Reconstruction: 0.169501, Regularization: 0.002059, Discriminator: 0.043330; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:55,428 root         INFO     Train Epoch: 170 [4608/8000 (58%)]\tTotal Loss: 0.189472\n",
      "Reconstruction: 0.123208, Regularization: 0.001268, Discriminator: 0.043332; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:55,526 root         INFO     Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 0.216333\n",
      "Reconstruction: 0.149633, Regularization: 0.001714, Discriminator: 0.043327; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:55,625 root         INFO     Train Epoch: 170 [5632/8000 (70%)]\tTotal Loss: 0.288656\n",
      "Reconstruction: 0.220410, Regularization: 0.003281, Discriminator: 0.043311; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:55,725 root         INFO     Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 0.277302\n",
      "Reconstruction: 0.209610, Regularization: 0.002705, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:55,825 root         INFO     Train Epoch: 170 [6656/8000 (83%)]\tTotal Loss: 0.204045\n",
      "Reconstruction: 0.137604, Regularization: 0.001457, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:55,925 root         INFO     Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 0.251858\n",
      "Reconstruction: 0.184782, Regularization: 0.002097, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:56,025 root         INFO     Train Epoch: 170 [7680/8000 (96%)]\tTotal Loss: 0.241405\n",
      "Reconstruction: 0.174354, Regularization: 0.002068, Discriminator: 0.043320; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:56,100 root         INFO     ====> Epoch: 170 Average loss: 0.2445\n",
      "2019-04-09 23:02:56,126 root         INFO     Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 0.262774\n",
      "Reconstruction: 0.195159, Regularization: 0.002640, Discriminator: 0.043312; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:56,226 root         INFO     Train Epoch: 171 [512/8000 (6%)]\tTotal Loss: 0.245861\n",
      "Reconstruction: 0.178805, Regularization: 0.002077, Discriminator: 0.043317; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:56,325 root         INFO     Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 0.221954\n",
      "Reconstruction: 0.155328, Regularization: 0.001652, Discriminator: 0.043308; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:56,423 root         INFO     Train Epoch: 171 [1536/8000 (19%)]\tTotal Loss: 0.318008\n",
      "Reconstruction: 0.249114, Regularization: 0.003909, Discriminator: 0.043319; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:56,521 root         INFO     Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 0.214214\n",
      "Reconstruction: 0.147410, Regularization: 0.001836, Discriminator: 0.043314; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:56,619 root         INFO     Train Epoch: 171 [2560/8000 (32%)]\tTotal Loss: 0.274681\n",
      "Reconstruction: 0.206942, Regularization: 0.002742, Discriminator: 0.043338; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:56,717 root         INFO     Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 0.236580\n",
      "Reconstruction: 0.169508, Regularization: 0.002092, Discriminator: 0.043311; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:56,815 root         INFO     Train Epoch: 171 [3584/8000 (45%)]\tTotal Loss: 0.279906\n",
      "Reconstruction: 0.212007, Regularization: 0.002919, Discriminator: 0.043317; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:56,912 root         INFO     Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 0.229565\n",
      "Reconstruction: 0.162758, Regularization: 0.001817, Discriminator: 0.043319; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:57,010 root         INFO     Train Epoch: 171 [4608/8000 (58%)]\tTotal Loss: 0.289104\n",
      "Reconstruction: 0.221088, Regularization: 0.003042, Discriminator: 0.043312; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:57,107 root         INFO     Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 0.246269\n",
      "Reconstruction: 0.178856, Regularization: 0.002424, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:57,204 root         INFO     Train Epoch: 171 [5632/8000 (70%)]\tTotal Loss: 0.263293\n",
      "Reconstruction: 0.195489, Regularization: 0.002820, Discriminator: 0.043326; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:57,302 root         INFO     Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 0.264339\n",
      "Reconstruction: 0.196554, Regularization: 0.002809, Discriminator: 0.043315; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:57,398 root         INFO     Train Epoch: 171 [6656/8000 (83%)]\tTotal Loss: 0.209944\n",
      "Reconstruction: 0.143632, Regularization: 0.001334, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:57,495 root         INFO     Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 0.233902\n",
      "Reconstruction: 0.166716, Regularization: 0.002210, Discriminator: 0.043316; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:57,592 root         INFO     Train Epoch: 171 [7680/8000 (96%)]\tTotal Loss: 0.268334\n",
      "Reconstruction: 0.200620, Regularization: 0.002744, Discriminator: 0.043310; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:57,665 root         INFO     ====> Epoch: 171 Average loss: 0.2444\n",
      "2019-04-09 23:02:57,692 root         INFO     Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 0.225782\n",
      "Reconstruction: 0.158917, Regularization: 0.001891, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:57,794 root         INFO     Train Epoch: 172 [512/8000 (6%)]\tTotal Loss: 0.232143\n",
      "Reconstruction: 0.165116, Regularization: 0.002033, Discriminator: 0.043332; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:57,895 root         INFO     Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 0.228750\n",
      "Reconstruction: 0.161788, Regularization: 0.001948, Discriminator: 0.043351; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:57,996 root         INFO     Train Epoch: 172 [1536/8000 (19%)]\tTotal Loss: 0.206333\n",
      "Reconstruction: 0.139746, Regularization: 0.001602, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:58,096 root         INFO     Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 0.284413\n",
      "Reconstruction: 0.216235, Regularization: 0.003238, Discriminator: 0.043281; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 23:02:58,196 root         INFO     Train Epoch: 172 [2560/8000 (32%)]\tTotal Loss: 0.231861\n",
      "Reconstruction: 0.164720, Regularization: 0.002135, Discriminator: 0.043345; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:58,296 root         INFO     Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 0.299537\n",
      "Reconstruction: 0.231052, Regularization: 0.003496, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:58,395 root         INFO     Train Epoch: 172 [3584/8000 (45%)]\tTotal Loss: 0.225652\n",
      "Reconstruction: 0.158775, Regularization: 0.001898, Discriminator: 0.043318; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:58,494 root         INFO     Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 0.254088\n",
      "Reconstruction: 0.186829, Regularization: 0.002269, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:58,593 root         INFO     Train Epoch: 172 [4608/8000 (58%)]\tTotal Loss: 0.239823\n",
      "Reconstruction: 0.172759, Regularization: 0.002078, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:58,691 root         INFO     Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 0.233070\n",
      "Reconstruction: 0.166157, Regularization: 0.001925, Discriminator: 0.043324; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:58,790 root         INFO     Train Epoch: 172 [5632/8000 (70%)]\tTotal Loss: 0.199751\n",
      "Reconstruction: 0.133480, Regularization: 0.001286, Discriminator: 0.043320; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:58,889 root         INFO     Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 0.234040\n",
      "Reconstruction: 0.166983, Regularization: 0.002079, Discriminator: 0.043315; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:58,988 root         INFO     Train Epoch: 172 [6656/8000 (83%)]\tTotal Loss: 0.262965\n",
      "Reconstruction: 0.195399, Regularization: 0.002582, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:59,089 root         INFO     Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 0.218572\n",
      "Reconstruction: 0.151989, Regularization: 0.001591, Discriminator: 0.043318; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:59,189 root         INFO     Train Epoch: 172 [7680/8000 (96%)]\tTotal Loss: 0.184001\n",
      "Reconstruction: 0.118064, Regularization: 0.000955, Discriminator: 0.043327; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:59,265 root         INFO     ====> Epoch: 172 Average loss: 0.2445\n",
      "2019-04-09 23:02:59,291 root         INFO     Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 0.234237\n",
      "Reconstruction: 0.166949, Regularization: 0.002295, Discriminator: 0.043327; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:59,392 root         INFO     Train Epoch: 173 [512/8000 (6%)]\tTotal Loss: 0.258657\n",
      "Reconstruction: 0.191221, Regularization: 0.002456, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:59,493 root         INFO     Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 0.234280\n",
      "Reconstruction: 0.167295, Regularization: 0.001986, Discriminator: 0.043339; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:59,593 root         INFO     Train Epoch: 173 [1536/8000 (19%)]\tTotal Loss: 0.232964\n",
      "Reconstruction: 0.165829, Regularization: 0.002143, Discriminator: 0.043325; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:59,693 root         INFO     Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 0.215874\n",
      "Reconstruction: 0.149331, Regularization: 0.001551, Discriminator: 0.043333; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:59,792 root         INFO     Train Epoch: 173 [2560/8000 (32%)]\tTotal Loss: 0.228371\n",
      "Reconstruction: 0.161505, Regularization: 0.001883, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:59,892 root         INFO     Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 0.237429\n",
      "Reconstruction: 0.170225, Regularization: 0.002219, Discriminator: 0.043327; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:02:59,991 root         INFO     Train Epoch: 173 [3584/8000 (45%)]\tTotal Loss: 0.205576\n",
      "Reconstruction: 0.139071, Regularization: 0.001533, Discriminator: 0.043309; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:00,091 root         INFO     Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 0.222341\n",
      "Reconstruction: 0.155394, Regularization: 0.001961, Discriminator: 0.043327; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:00,190 root         INFO     Train Epoch: 173 [4608/8000 (58%)]\tTotal Loss: 0.248768\n",
      "Reconstruction: 0.181191, Regularization: 0.002601, Discriminator: 0.043320; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:00,290 root         INFO     Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 0.261045\n",
      "Reconstruction: 0.192987, Regularization: 0.003072, Discriminator: 0.043324; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:00,389 root         INFO     Train Epoch: 173 [5632/8000 (70%)]\tTotal Loss: 0.228184\n",
      "Reconstruction: 0.160875, Regularization: 0.002327, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:00,489 root         INFO     Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 0.217582\n",
      "Reconstruction: 0.150801, Regularization: 0.001804, Discriminator: 0.043323; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:00,588 root         INFO     Train Epoch: 173 [6656/8000 (83%)]\tTotal Loss: 0.239332\n",
      "Reconstruction: 0.171974, Regularization: 0.002381, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:00,688 root         INFO     Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 0.268690\n",
      "Reconstruction: 0.200733, Regularization: 0.002966, Discriminator: 0.043324; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:00,787 root         INFO     Train Epoch: 173 [7680/8000 (96%)]\tTotal Loss: 0.271440\n",
      "Reconstruction: 0.203582, Regularization: 0.002879, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:00,862 root         INFO     ====> Epoch: 173 Average loss: 0.2445\n",
      "2019-04-09 23:03:00,889 root         INFO     Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 0.250821\n",
      "Reconstruction: 0.183384, Regularization: 0.002471, Discriminator: 0.043308; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:00,990 root         INFO     Train Epoch: 174 [512/8000 (6%)]\tTotal Loss: 0.230039\n",
      "Reconstruction: 0.162942, Regularization: 0.002110, Discriminator: 0.043319; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:01,089 root         INFO     Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 0.232082\n",
      "Reconstruction: 0.164896, Regularization: 0.002205, Discriminator: 0.043314; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:01,188 root         INFO     Train Epoch: 174 [1536/8000 (19%)]\tTotal Loss: 0.197426\n",
      "Reconstruction: 0.131108, Regularization: 0.001328, Discriminator: 0.043335; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:01,288 root         INFO     Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 0.236449\n",
      "Reconstruction: 0.169229, Regularization: 0.002219, Discriminator: 0.043335; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:01,387 root         INFO     Train Epoch: 174 [2560/8000 (32%)]\tTotal Loss: 0.206577\n",
      "Reconstruction: 0.140139, Regularization: 0.001444, Discriminator: 0.043334; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:01,487 root         INFO     Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 0.206002\n",
      "Reconstruction: 0.139671, Regularization: 0.001359, Discriminator: 0.043314; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:01,586 root         INFO     Train Epoch: 174 [3584/8000 (45%)]\tTotal Loss: 0.248521\n",
      "Reconstruction: 0.181317, Regularization: 0.002215, Discriminator: 0.043326; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:01,685 root         INFO     Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 0.225410\n",
      "Reconstruction: 0.158386, Regularization: 0.002047, Discriminator: 0.043317; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:01,785 root         INFO     Train Epoch: 174 [4608/8000 (58%)]\tTotal Loss: 0.250471\n",
      "Reconstruction: 0.183144, Regularization: 0.002341, Discriminator: 0.043320; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:01,884 root         INFO     Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 0.276672\n",
      "Reconstruction: 0.208744, Regularization: 0.002953, Discriminator: 0.043314; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:01,984 root         INFO     Train Epoch: 174 [5632/8000 (70%)]\tTotal Loss: 0.241593\n",
      "Reconstruction: 0.174411, Regularization: 0.002195, Discriminator: 0.043321; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:02,084 root         INFO     Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 0.246281\n",
      "Reconstruction: 0.178868, Regularization: 0.002424, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:02,183 root         INFO     Train Epoch: 174 [6656/8000 (83%)]\tTotal Loss: 0.219750\n",
      "Reconstruction: 0.153048, Regularization: 0.001731, Discriminator: 0.043316; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:02,283 root         INFO     Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 0.242537\n",
      "Reconstruction: 0.175163, Regularization: 0.002401, Discriminator: 0.043318; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:02,383 root         INFO     Train Epoch: 174 [7680/8000 (96%)]\tTotal Loss: 0.234858\n",
      "Reconstruction: 0.167786, Regularization: 0.002113, Discriminator: 0.043298; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:02,457 root         INFO     ====> Epoch: 174 Average loss: 0.2448\n",
      "2019-04-09 23:03:02,484 root         INFO     Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 0.218427\n",
      "Reconstruction: 0.151710, Regularization: 0.001763, Discriminator: 0.043298; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:02,585 root         INFO     Train Epoch: 175 [512/8000 (6%)]\tTotal Loss: 0.213809\n",
      "Reconstruction: 0.147313, Regularization: 0.001474, Discriminator: 0.043346; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:03:02,686 root         INFO     Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 0.298737\n",
      "Reconstruction: 0.230420, Regularization: 0.003334, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:02,786 root         INFO     Train Epoch: 175 [1536/8000 (19%)]\tTotal Loss: 0.221744\n",
      "Reconstruction: 0.155114, Regularization: 0.001674, Discriminator: 0.043307; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:02,886 root         INFO     Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 0.247271\n",
      "Reconstruction: 0.180000, Regularization: 0.002280, Discriminator: 0.043335; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:02,987 root         INFO     Train Epoch: 175 [2560/8000 (32%)]\tTotal Loss: 0.215991\n",
      "Reconstruction: 0.149480, Regularization: 0.001518, Discriminator: 0.043325; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:03,089 root         INFO     Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 0.297141\n",
      "Reconstruction: 0.228409, Regularization: 0.003748, Discriminator: 0.043318; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:03,190 root         INFO     Train Epoch: 175 [3584/8000 (45%)]\tTotal Loss: 0.219204\n",
      "Reconstruction: 0.152506, Regularization: 0.001714, Discriminator: 0.043321; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:03,293 root         INFO     Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 0.204758\n",
      "Reconstruction: 0.138183, Regularization: 0.001594, Discriminator: 0.043324; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:03,395 root         INFO     Train Epoch: 175 [4608/8000 (58%)]\tTotal Loss: 0.236262\n",
      "Reconstruction: 0.169295, Regularization: 0.001991, Discriminator: 0.043314; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:03,497 root         INFO     Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 0.223643\n",
      "Reconstruction: 0.156749, Regularization: 0.001912, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:03,598 root         INFO     Train Epoch: 175 [5632/8000 (70%)]\tTotal Loss: 0.266755\n",
      "Reconstruction: 0.198936, Regularization: 0.002842, Discriminator: 0.043315; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:03,699 root         INFO     Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 0.221975\n",
      "Reconstruction: 0.155163, Regularization: 0.001828, Discriminator: 0.043319; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:03,800 root         INFO     Train Epoch: 175 [6656/8000 (83%)]\tTotal Loss: 0.231372\n",
      "Reconstruction: 0.164335, Regularization: 0.002046, Discriminator: 0.043331; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:03,901 root         INFO     Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 0.245488\n",
      "Reconstruction: 0.178238, Regularization: 0.002278, Discriminator: 0.043314; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:04,002 root         INFO     Train Epoch: 175 [7680/8000 (96%)]\tTotal Loss: 0.218137\n",
      "Reconstruction: 0.151366, Regularization: 0.001796, Discriminator: 0.043317; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:04,077 root         INFO     ====> Epoch: 175 Average loss: 0.2445\n",
      "2019-04-09 23:03:04,104 root         INFO     Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 0.237103\n",
      "Reconstruction: 0.169848, Regularization: 0.002280, Discriminator: 0.043315; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:04,204 root         INFO     Train Epoch: 176 [512/8000 (6%)]\tTotal Loss: 0.231774\n",
      "Reconstruction: 0.164624, Regularization: 0.002163, Discriminator: 0.043325; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:04,304 root         INFO     Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 0.209362\n",
      "Reconstruction: 0.142898, Regularization: 0.001468, Discriminator: 0.043336; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:04,398 root         INFO     Train Epoch: 176 [1536/8000 (19%)]\tTotal Loss: 0.238389\n",
      "Reconstruction: 0.171432, Regularization: 0.001970, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:04,493 root         INFO     Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 0.231932\n",
      "Reconstruction: 0.165035, Regularization: 0.001904, Discriminator: 0.043331; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:04,587 root         INFO     Train Epoch: 176 [2560/8000 (32%)]\tTotal Loss: 0.228746\n",
      "Reconstruction: 0.161846, Regularization: 0.001931, Discriminator: 0.043309; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:04,683 root         INFO     Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 0.221062\n",
      "Reconstruction: 0.154107, Regularization: 0.001968, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:04,780 root         INFO     Train Epoch: 176 [3584/8000 (45%)]\tTotal Loss: 0.261463\n",
      "Reconstruction: 0.193750, Regularization: 0.002736, Discriminator: 0.043318; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:04,877 root         INFO     Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 0.237046\n",
      "Reconstruction: 0.169989, Regularization: 0.002075, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:04,974 root         INFO     Train Epoch: 176 [4608/8000 (58%)]\tTotal Loss: 0.201100\n",
      "Reconstruction: 0.134731, Regularization: 0.001388, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:05,071 root         INFO     Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 0.235155\n",
      "Reconstruction: 0.168173, Regularization: 0.002003, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:05,167 root         INFO     Train Epoch: 176 [5632/8000 (70%)]\tTotal Loss: 0.257298\n",
      "Reconstruction: 0.189903, Regularization: 0.002412, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:05,264 root         INFO     Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 0.231483\n",
      "Reconstruction: 0.164398, Regularization: 0.002101, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:05,361 root         INFO     Train Epoch: 176 [6656/8000 (83%)]\tTotal Loss: 0.228980\n",
      "Reconstruction: 0.162230, Regularization: 0.001774, Discriminator: 0.043319; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:05,458 root         INFO     Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 0.225012\n",
      "Reconstruction: 0.158290, Regularization: 0.001740, Discriminator: 0.043318; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:05,555 root         INFO     Train Epoch: 176 [7680/8000 (96%)]\tTotal Loss: 0.236115\n",
      "Reconstruction: 0.168793, Regularization: 0.002324, Discriminator: 0.043332; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:05,627 root         INFO     ====> Epoch: 176 Average loss: 0.2442\n",
      "2019-04-09 23:03:05,654 root         INFO     Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 0.263489\n",
      "Reconstruction: 0.195884, Regularization: 0.002638, Discriminator: 0.043313; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:05,753 root         INFO     Train Epoch: 177 [512/8000 (6%)]\tTotal Loss: 0.240279\n",
      "Reconstruction: 0.173330, Regularization: 0.001972, Discriminator: 0.043309; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:05,851 root         INFO     Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 0.232456\n",
      "Reconstruction: 0.165409, Regularization: 0.002060, Discriminator: 0.043330; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:05,953 root         INFO     Train Epoch: 177 [1536/8000 (19%)]\tTotal Loss: 0.235898\n",
      "Reconstruction: 0.168937, Regularization: 0.001975, Discriminator: 0.043323; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:06,055 root         INFO     Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 0.239787\n",
      "Reconstruction: 0.172873, Regularization: 0.001928, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:06,156 root         INFO     Train Epoch: 177 [2560/8000 (32%)]\tTotal Loss: 0.256247\n",
      "Reconstruction: 0.189007, Regularization: 0.002263, Discriminator: 0.043317; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:06,257 root         INFO     Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 0.226236\n",
      "Reconstruction: 0.159343, Regularization: 0.001916, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:06,358 root         INFO     Train Epoch: 177 [3584/8000 (45%)]\tTotal Loss: 0.214890\n",
      "Reconstruction: 0.148232, Regularization: 0.001693, Discriminator: 0.043315; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:06,458 root         INFO     Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 0.245870\n",
      "Reconstruction: 0.178617, Regularization: 0.002274, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:06,559 root         INFO     Train Epoch: 177 [4608/8000 (58%)]\tTotal Loss: 0.282629\n",
      "Reconstruction: 0.214317, Regularization: 0.003325, Discriminator: 0.043329; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:06,660 root         INFO     Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 0.267350\n",
      "Reconstruction: 0.199499, Regularization: 0.002870, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:06,760 root         INFO     Train Epoch: 177 [5632/8000 (70%)]\tTotal Loss: 0.216941\n",
      "Reconstruction: 0.150200, Regularization: 0.001763, Discriminator: 0.043318; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:06,860 root         INFO     Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 0.245388\n",
      "Reconstruction: 0.178126, Regularization: 0.002277, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:06,959 root         INFO     Train Epoch: 177 [6656/8000 (83%)]\tTotal Loss: 0.264501\n",
      "Reconstruction: 0.197051, Regularization: 0.002464, Discriminator: 0.043325; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:07,058 root         INFO     Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 0.236714\n",
      "Reconstruction: 0.169745, Regularization: 0.001987, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:07,158 root         INFO     Train Epoch: 177 [7680/8000 (96%)]\tTotal Loss: 0.231360\n",
      "Reconstruction: 0.164353, Regularization: 0.002021, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:07,233 root         INFO     ====> Epoch: 177 Average loss: 0.2445\n",
      "2019-04-09 23:03:07,259 root         INFO     Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 0.246913\n",
      "Reconstruction: 0.179527, Regularization: 0.002405, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:07,358 root         INFO     Train Epoch: 178 [512/8000 (6%)]\tTotal Loss: 0.280862\n",
      "Reconstruction: 0.212868, Regularization: 0.003000, Discriminator: 0.043334; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:07,456 root         INFO     Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 0.211763\n",
      "Reconstruction: 0.145016, Regularization: 0.001777, Discriminator: 0.043308; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:07,553 root         INFO     Train Epoch: 178 [1536/8000 (19%)]\tTotal Loss: 0.228337\n",
      "Reconstruction: 0.161603, Regularization: 0.001754, Discriminator: 0.043318; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:07,651 root         INFO     Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 0.215536\n",
      "Reconstruction: 0.148858, Regularization: 0.001705, Discriminator: 0.043316; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:07,751 root         INFO     Train Epoch: 178 [2560/8000 (32%)]\tTotal Loss: 0.287830\n",
      "Reconstruction: 0.219684, Regularization: 0.003174, Discriminator: 0.043315; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:07,849 root         INFO     Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 0.247446\n",
      "Reconstruction: 0.180094, Regularization: 0.002365, Discriminator: 0.043329; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:07,951 root         INFO     Train Epoch: 178 [3584/8000 (45%)]\tTotal Loss: 0.249140\n",
      "Reconstruction: 0.181845, Regularization: 0.002306, Discriminator: 0.043327; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:08,048 root         INFO     Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 0.294214\n",
      "Reconstruction: 0.226020, Regularization: 0.003223, Discriminator: 0.043311; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:08,146 root         INFO     Train Epoch: 178 [4608/8000 (58%)]\tTotal Loss: 0.213690\n",
      "Reconstruction: 0.146931, Regularization: 0.001777, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:08,244 root         INFO     Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 0.265479\n",
      "Reconstruction: 0.197818, Regularization: 0.002676, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:08,341 root         INFO     Train Epoch: 178 [5632/8000 (70%)]\tTotal Loss: 0.225187\n",
      "Reconstruction: 0.158399, Regularization: 0.001806, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:08,439 root         INFO     Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 0.255415\n",
      "Reconstruction: 0.188282, Regularization: 0.002154, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:08,536 root         INFO     Train Epoch: 178 [6656/8000 (83%)]\tTotal Loss: 0.261801\n",
      "Reconstruction: 0.194320, Regularization: 0.002498, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:08,634 root         INFO     Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 0.223531\n",
      "Reconstruction: 0.156903, Regularization: 0.001657, Discriminator: 0.043316; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:08,731 root         INFO     Train Epoch: 178 [7680/8000 (96%)]\tTotal Loss: 0.276950\n",
      "Reconstruction: 0.209042, Regularization: 0.002927, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:08,805 root         INFO     ====> Epoch: 178 Average loss: 0.2443\n",
      "2019-04-09 23:03:08,831 root         INFO     Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 0.210821\n",
      "Reconstruction: 0.144242, Regularization: 0.001603, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:08,929 root         INFO     Train Epoch: 179 [512/8000 (6%)]\tTotal Loss: 0.262410\n",
      "Reconstruction: 0.194576, Regularization: 0.002839, Discriminator: 0.043336; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:09,027 root         INFO     Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 0.248904\n",
      "Reconstruction: 0.181600, Regularization: 0.002323, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:09,124 root         INFO     Train Epoch: 179 [1536/8000 (19%)]\tTotal Loss: 0.237877\n",
      "Reconstruction: 0.170855, Regularization: 0.002034, Discriminator: 0.043325; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:09,220 root         INFO     Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 0.228460\n",
      "Reconstruction: 0.161595, Regularization: 0.001865, Discriminator: 0.043340; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:09,316 root         INFO     Train Epoch: 179 [2560/8000 (32%)]\tTotal Loss: 0.291887\n",
      "Reconstruction: 0.223570, Regularization: 0.003322, Discriminator: 0.043333; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:09,412 root         INFO     Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 0.215473\n",
      "Reconstruction: 0.148824, Regularization: 0.001675, Discriminator: 0.043314; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:09,509 root         INFO     Train Epoch: 179 [3584/8000 (45%)]\tTotal Loss: 0.265911\n",
      "Reconstruction: 0.198134, Regularization: 0.002799, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:09,604 root         INFO     Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 0.253441\n",
      "Reconstruction: 0.186054, Regularization: 0.002409, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:09,700 root         INFO     Train Epoch: 179 [4608/8000 (58%)]\tTotal Loss: 0.204527\n",
      "Reconstruction: 0.138106, Regularization: 0.001441, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:09,795 root         INFO     Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 0.279512\n",
      "Reconstruction: 0.211537, Regularization: 0.002994, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:09,891 root         INFO     Train Epoch: 179 [5632/8000 (70%)]\tTotal Loss: 0.268414\n",
      "Reconstruction: 0.200641, Regularization: 0.002791, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:09,987 root         INFO     Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 0.229517\n",
      "Reconstruction: 0.162690, Regularization: 0.001841, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:10,085 root         INFO     Train Epoch: 179 [6656/8000 (83%)]\tTotal Loss: 0.217819\n",
      "Reconstruction: 0.151127, Regularization: 0.001704, Discriminator: 0.043326; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:10,182 root         INFO     Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 0.228881\n",
      "Reconstruction: 0.161836, Regularization: 0.002062, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:10,280 root         INFO     Train Epoch: 179 [7680/8000 (96%)]\tTotal Loss: 0.217851\n",
      "Reconstruction: 0.151117, Regularization: 0.001753, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:10,353 root         INFO     ====> Epoch: 179 Average loss: 0.2446\n",
      "2019-04-09 23:03:10,380 root         INFO     Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 0.250958\n",
      "Reconstruction: 0.183472, Regularization: 0.002503, Discriminator: 0.043318; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:10,480 root         INFO     Train Epoch: 180 [512/8000 (6%)]\tTotal Loss: 0.225401\n",
      "Reconstruction: 0.158571, Regularization: 0.001856, Discriminator: 0.043317; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:10,578 root         INFO     Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 0.248294\n",
      "Reconstruction: 0.180816, Regularization: 0.002488, Discriminator: 0.043325; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:10,676 root         INFO     Train Epoch: 180 [1536/8000 (19%)]\tTotal Loss: 0.206373\n",
      "Reconstruction: 0.139900, Regularization: 0.001488, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:10,774 root         INFO     Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 0.244852\n",
      "Reconstruction: 0.177499, Regularization: 0.002365, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:10,873 root         INFO     Train Epoch: 180 [2560/8000 (32%)]\tTotal Loss: 0.194886\n",
      "Reconstruction: 0.128490, Regularization: 0.001420, Discriminator: 0.043316; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:10,972 root         INFO     Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 0.254937\n",
      "Reconstruction: 0.187241, Regularization: 0.002710, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:11,070 root         INFO     Train Epoch: 180 [3584/8000 (45%)]\tTotal Loss: 0.207682\n",
      "Reconstruction: 0.140975, Regularization: 0.001717, Discriminator: 0.043329; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:11,168 root         INFO     Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 0.221869\n",
      "Reconstruction: 0.154996, Regularization: 0.001891, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:11,267 root         INFO     Train Epoch: 180 [4608/8000 (58%)]\tTotal Loss: 0.238990\n",
      "Reconstruction: 0.171688, Regularization: 0.002324, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:11,366 root         INFO     Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 0.262712\n",
      "Reconstruction: 0.195195, Regularization: 0.002531, Discriminator: 0.043327; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:11,466 root         INFO     Train Epoch: 180 [5632/8000 (70%)]\tTotal Loss: 0.230806\n",
      "Reconstruction: 0.163813, Regularization: 0.002014, Discriminator: 0.043318; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:11,566 root         INFO     Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 0.232848\n",
      "Reconstruction: 0.165781, Regularization: 0.002078, Discriminator: 0.043327; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:11,665 root         INFO     Train Epoch: 180 [6656/8000 (83%)]\tTotal Loss: 0.295866\n",
      "Reconstruction: 0.227226, Regularization: 0.003657, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:11,764 root         INFO     Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 0.269203\n",
      "Reconstruction: 0.201288, Regularization: 0.002926, Discriminator: 0.043325; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:11,863 root         INFO     Train Epoch: 180 [7680/8000 (96%)]\tTotal Loss: 0.248721\n",
      "Reconstruction: 0.181391, Regularization: 0.002339, Discriminator: 0.043329; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:11,938 root         INFO     ====> Epoch: 180 Average loss: 0.2444\n",
      "2019-04-09 23:03:11,964 root         INFO     Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 0.250938\n",
      "Reconstruction: 0.183496, Regularization: 0.002466, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:12,066 root         INFO     Train Epoch: 181 [512/8000 (6%)]\tTotal Loss: 0.234065\n",
      "Reconstruction: 0.166947, Regularization: 0.002137, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:12,166 root         INFO     Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 0.231509\n",
      "Reconstruction: 0.164515, Regularization: 0.002014, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:12,267 root         INFO     Train Epoch: 181 [1536/8000 (19%)]\tTotal Loss: 0.259633\n",
      "Reconstruction: 0.191801, Regularization: 0.002854, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:12,367 root         INFO     Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 0.241670\n",
      "Reconstruction: 0.174449, Regularization: 0.002237, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:12,467 root         INFO     Train Epoch: 181 [2560/8000 (32%)]\tTotal Loss: 0.230390\n",
      "Reconstruction: 0.163313, Regularization: 0.002096, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:12,567 root         INFO     Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 0.242854\n",
      "Reconstruction: 0.175546, Regularization: 0.002326, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:12,667 root         INFO     Train Epoch: 181 [3584/8000 (45%)]\tTotal Loss: 0.248000\n",
      "Reconstruction: 0.180377, Regularization: 0.002646, Discriminator: 0.043317; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:12,768 root         INFO     Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 0.250746\n",
      "Reconstruction: 0.183268, Regularization: 0.002498, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:12,868 root         INFO     Train Epoch: 181 [4608/8000 (58%)]\tTotal Loss: 0.230150\n",
      "Reconstruction: 0.163132, Regularization: 0.002022, Discriminator: 0.043332; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:12,968 root         INFO     Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 0.271087\n",
      "Reconstruction: 0.202971, Regularization: 0.003143, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:13,069 root         INFO     Train Epoch: 181 [5632/8000 (70%)]\tTotal Loss: 0.254853\n",
      "Reconstruction: 0.187118, Regularization: 0.002743, Discriminator: 0.043321; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:13,169 root         INFO     Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 0.219946\n",
      "Reconstruction: 0.153058, Regularization: 0.001905, Discriminator: 0.043315; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:13,269 root         INFO     Train Epoch: 181 [6656/8000 (83%)]\tTotal Loss: 0.183188\n",
      "Reconstruction: 0.117214, Regularization: 0.000986, Discriminator: 0.043324; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:13,369 root         INFO     Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 0.216798\n",
      "Reconstruction: 0.150091, Regularization: 0.001728, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:13,469 root         INFO     Train Epoch: 181 [7680/8000 (96%)]\tTotal Loss: 0.260192\n",
      "Reconstruction: 0.192345, Regularization: 0.002870, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:13,544 root         INFO     ====> Epoch: 181 Average loss: 0.2443\n",
      "2019-04-09 23:03:13,570 root         INFO     Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 0.251060\n",
      "Reconstruction: 0.183583, Regularization: 0.002491, Discriminator: 0.043323; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:13,671 root         INFO     Train Epoch: 182 [512/8000 (6%)]\tTotal Loss: 0.267407\n",
      "Reconstruction: 0.199623, Regularization: 0.002799, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:13,771 root         INFO     Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 0.269296\n",
      "Reconstruction: 0.201348, Regularization: 0.002971, Discriminator: 0.043320; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:13,870 root         INFO     Train Epoch: 182 [1536/8000 (19%)]\tTotal Loss: 0.222096\n",
      "Reconstruction: 0.155176, Regularization: 0.001936, Discriminator: 0.043324; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:13,969 root         INFO     Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 0.244705\n",
      "Reconstruction: 0.177305, Regularization: 0.002424, Discriminator: 0.043312; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:14,067 root         INFO     Train Epoch: 182 [2560/8000 (32%)]\tTotal Loss: 0.269053\n",
      "Reconstruction: 0.201355, Regularization: 0.002723, Discriminator: 0.043312; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:14,165 root         INFO     Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 0.238030\n",
      "Reconstruction: 0.170979, Regularization: 0.002057, Discriminator: 0.043338; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:14,262 root         INFO     Train Epoch: 182 [3584/8000 (45%)]\tTotal Loss: 0.210385\n",
      "Reconstruction: 0.143837, Regularization: 0.001575, Discriminator: 0.043319; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:14,360 root         INFO     Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 0.247952\n",
      "Reconstruction: 0.180552, Regularization: 0.002412, Discriminator: 0.043329; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:14,460 root         INFO     Train Epoch: 182 [4608/8000 (58%)]\tTotal Loss: 0.231052\n",
      "Reconstruction: 0.164283, Regularization: 0.001795, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:14,560 root         INFO     Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 0.307431\n",
      "Reconstruction: 0.238633, Regularization: 0.003804, Discriminator: 0.043330; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:14,660 root         INFO     Train Epoch: 182 [5632/8000 (70%)]\tTotal Loss: 0.228389\n",
      "Reconstruction: 0.161422, Regularization: 0.001986, Discriminator: 0.043325; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:14,760 root         INFO     Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 0.233875\n",
      "Reconstruction: 0.166958, Regularization: 0.001932, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:14,860 root         INFO     Train Epoch: 182 [6656/8000 (83%)]\tTotal Loss: 0.256546\n",
      "Reconstruction: 0.189390, Regularization: 0.002167, Discriminator: 0.043323; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:14,960 root         INFO     Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 0.252841\n",
      "Reconstruction: 0.185338, Regularization: 0.002531, Discriminator: 0.043317; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:15,060 root         INFO     Train Epoch: 182 [7680/8000 (96%)]\tTotal Loss: 0.238643\n",
      "Reconstruction: 0.171736, Regularization: 0.001927, Discriminator: 0.043324; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:15,135 root         INFO     ====> Epoch: 182 Average loss: 0.2444\n",
      "2019-04-09 23:03:15,161 root         INFO     Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 0.223858\n",
      "Reconstruction: 0.157159, Regularization: 0.001712, Discriminator: 0.043320; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:15,262 root         INFO     Train Epoch: 183 [512/8000 (6%)]\tTotal Loss: 0.279255\n",
      "Reconstruction: 0.211419, Regularization: 0.002859, Discriminator: 0.043318; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:15,361 root         INFO     Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 0.224189\n",
      "Reconstruction: 0.157510, Regularization: 0.001675, Discriminator: 0.043342; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:15,461 root         INFO     Train Epoch: 183 [1536/8000 (19%)]\tTotal Loss: 0.264023\n",
      "Reconstruction: 0.196618, Regularization: 0.002405, Discriminator: 0.043338; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:15,560 root         INFO     Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 0.261128\n",
      "Reconstruction: 0.193854, Regularization: 0.002298, Discriminator: 0.043316; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:15,658 root         INFO     Train Epoch: 183 [2560/8000 (32%)]\tTotal Loss: 0.224323\n",
      "Reconstruction: 0.157615, Regularization: 0.001728, Discriminator: 0.043313; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:15,756 root         INFO     Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 0.246631\n",
      "Reconstruction: 0.179614, Regularization: 0.002031, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:15,854 root         INFO     Train Epoch: 183 [3584/8000 (45%)]\tTotal Loss: 0.281869\n",
      "Reconstruction: 0.214141, Regularization: 0.002745, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:15,953 root         INFO     Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 0.226047\n",
      "Reconstruction: 0.159404, Regularization: 0.001655, Discriminator: 0.043331; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:16,052 root         INFO     Train Epoch: 183 [4608/8000 (58%)]\tTotal Loss: 0.260371\n",
      "Reconstruction: 0.192856, Regularization: 0.002536, Discriminator: 0.043321; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:16,153 root         INFO     Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 0.250004\n",
      "Reconstruction: 0.182643, Regularization: 0.002380, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:16,252 root         INFO     Train Epoch: 183 [5632/8000 (70%)]\tTotal Loss: 0.248427\n",
      "Reconstruction: 0.181289, Regularization: 0.002153, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:16,352 root         INFO     Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 0.216605\n",
      "Reconstruction: 0.150106, Regularization: 0.001516, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:16,452 root         INFO     Train Epoch: 183 [6656/8000 (83%)]\tTotal Loss: 0.261250\n",
      "Reconstruction: 0.194050, Regularization: 0.002216, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:16,550 root         INFO     Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 0.216659\n",
      "Reconstruction: 0.150238, Regularization: 0.001442, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:16,649 root         INFO     Train Epoch: 183 [7680/8000 (96%)]\tTotal Loss: 0.243112\n",
      "Reconstruction: 0.175891, Regularization: 0.002240, Discriminator: 0.043319; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:16,724 root         INFO     ====> Epoch: 183 Average loss: 0.2447\n",
      "2019-04-09 23:03:16,750 root         INFO     Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 0.254832\n",
      "Reconstruction: 0.187589, Regularization: 0.002263, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:16,851 root         INFO     Train Epoch: 184 [512/8000 (6%)]\tTotal Loss: 0.245590\n",
      "Reconstruction: 0.178356, Regularization: 0.002251, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:16,953 root         INFO     Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 0.209471\n",
      "Reconstruction: 0.142937, Regularization: 0.001552, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:17,055 root         INFO     Train Epoch: 184 [1536/8000 (19%)]\tTotal Loss: 0.242469\n",
      "Reconstruction: 0.175414, Regularization: 0.002073, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:17,156 root         INFO     Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 0.261802\n",
      "Reconstruction: 0.194417, Regularization: 0.002400, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:17,257 root         INFO     Train Epoch: 184 [2560/8000 (32%)]\tTotal Loss: 0.285363\n",
      "Reconstruction: 0.217609, Regularization: 0.002769, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:17,359 root         INFO     Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 0.223278\n",
      "Reconstruction: 0.156666, Regularization: 0.001624, Discriminator: 0.043323; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:17,460 root         INFO     Train Epoch: 184 [3584/8000 (45%)]\tTotal Loss: 0.321982\n",
      "Reconstruction: 0.253304, Regularization: 0.003693, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:17,561 root         INFO     Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 0.237835\n",
      "Reconstruction: 0.170559, Regularization: 0.002292, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:17,663 root         INFO     Train Epoch: 184 [4608/8000 (58%)]\tTotal Loss: 0.253812\n",
      "Reconstruction: 0.186429, Regularization: 0.002404, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:17,764 root         INFO     Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 0.255899\n",
      "Reconstruction: 0.188690, Regularization: 0.002225, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:17,865 root         INFO     Train Epoch: 184 [5632/8000 (70%)]\tTotal Loss: 0.268499\n",
      "Reconstruction: 0.200765, Regularization: 0.002747, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:17,967 root         INFO     Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 0.243168\n",
      "Reconstruction: 0.176139, Regularization: 0.002037, Discriminator: 0.043331; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:18,069 root         INFO     Train Epoch: 184 [6656/8000 (83%)]\tTotal Loss: 0.232805\n",
      "Reconstruction: 0.165844, Regularization: 0.001983, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:18,170 root         INFO     Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 0.263010\n",
      "Reconstruction: 0.195628, Regularization: 0.002400, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:18,272 root         INFO     Train Epoch: 184 [7680/8000 (96%)]\tTotal Loss: 0.268357\n",
      "Reconstruction: 0.200937, Regularization: 0.002433, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:18,347 root         INFO     ====> Epoch: 184 Average loss: 0.2445\n",
      "2019-04-09 23:03:18,374 root         INFO     Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 0.260711\n",
      "Reconstruction: 0.193305, Regularization: 0.002426, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:18,475 root         INFO     Train Epoch: 185 [512/8000 (6%)]\tTotal Loss: 0.272965\n",
      "Reconstruction: 0.205401, Regularization: 0.002577, Discriminator: 0.043324; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:18,576 root         INFO     Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 0.254904\n",
      "Reconstruction: 0.187637, Regularization: 0.002285, Discriminator: 0.043316; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:18,678 root         INFO     Train Epoch: 185 [1536/8000 (19%)]\tTotal Loss: 0.280722\n",
      "Reconstruction: 0.213048, Regularization: 0.002682, Discriminator: 0.043327; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:18,779 root         INFO     Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 0.243818\n",
      "Reconstruction: 0.176813, Regularization: 0.002024, Discriminator: 0.043316; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:18,879 root         INFO     Train Epoch: 185 [2560/8000 (32%)]\tTotal Loss: 0.299997\n",
      "Reconstruction: 0.231710, Regularization: 0.003296, Discriminator: 0.043328; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:18,982 root         INFO     Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 0.281619\n",
      "Reconstruction: 0.213922, Regularization: 0.002727, Discriminator: 0.043305; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:19,084 root         INFO     Train Epoch: 185 [3584/8000 (45%)]\tTotal Loss: 0.245789\n",
      "Reconstruction: 0.178738, Regularization: 0.002097, Discriminator: 0.043294; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:19,186 root         INFO     Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 0.255079\n",
      "Reconstruction: 0.187960, Regularization: 0.002135, Discriminator: 0.043317; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:19,288 root         INFO     Train Epoch: 185 [4608/8000 (58%)]\tTotal Loss: 0.228250\n",
      "Reconstruction: 0.161370, Regularization: 0.001900, Discriminator: 0.043310; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:19,389 root         INFO     Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 0.229292\n",
      "Reconstruction: 0.162470, Regularization: 0.001854, Discriminator: 0.043315; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:19,491 root         INFO     Train Epoch: 185 [5632/8000 (70%)]\tTotal Loss: 0.202001\n",
      "Reconstruction: 0.135643, Regularization: 0.001342, Discriminator: 0.043350; Generator: 0.021666,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 23:03:19,593 root         INFO     Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 0.227441\n",
      "Reconstruction: 0.160734, Regularization: 0.001731, Discriminator: 0.043312; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:19,694 root         INFO     Train Epoch: 185 [6656/8000 (83%)]\tTotal Loss: 0.306697\n",
      "Reconstruction: 0.238362, Regularization: 0.003343, Discriminator: 0.043333; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:19,795 root         INFO     Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 0.277737\n",
      "Reconstruction: 0.210032, Regularization: 0.002707, Discriminator: 0.043339; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:19,897 root         INFO     Train Epoch: 185 [7680/8000 (96%)]\tTotal Loss: 0.222396\n",
      "Reconstruction: 0.155838, Regularization: 0.001581, Discriminator: 0.043321; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:19,972 root         INFO     ====> Epoch: 185 Average loss: 0.2446\n",
      "2019-04-09 23:03:19,999 root         INFO     Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 0.285131\n",
      "Reconstruction: 0.217266, Regularization: 0.002884, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:20,100 root         INFO     Train Epoch: 186 [512/8000 (6%)]\tTotal Loss: 0.221077\n",
      "Reconstruction: 0.154319, Regularization: 0.001760, Discriminator: 0.043337; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:20,201 root         INFO     Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 0.277965\n",
      "Reconstruction: 0.210124, Regularization: 0.002862, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:20,303 root         INFO     Train Epoch: 186 [1536/8000 (19%)]\tTotal Loss: 0.236335\n",
      "Reconstruction: 0.169204, Regularization: 0.002166, Discriminator: 0.043306; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:20,405 root         INFO     Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 0.232088\n",
      "Reconstruction: 0.165080, Regularization: 0.001997, Discriminator: 0.043349; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:20,506 root         INFO     Train Epoch: 186 [2560/8000 (32%)]\tTotal Loss: 0.246373\n",
      "Reconstruction: 0.179208, Regularization: 0.002194, Discriminator: 0.043305; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:20,607 root         INFO     Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 0.251414\n",
      "Reconstruction: 0.184048, Regularization: 0.002377, Discriminator: 0.043329; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:20,708 root         INFO     Train Epoch: 186 [3584/8000 (45%)]\tTotal Loss: 0.209148\n",
      "Reconstruction: 0.142769, Regularization: 0.001385, Discriminator: 0.043335; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:20,808 root         INFO     Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 0.232599\n",
      "Reconstruction: 0.165647, Regularization: 0.001966, Discriminator: 0.043327; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:20,909 root         INFO     Train Epoch: 186 [4608/8000 (58%)]\tTotal Loss: 0.208922\n",
      "Reconstruction: 0.142599, Regularization: 0.001331, Discriminator: 0.043334; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:21,011 root         INFO     Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 0.274904\n",
      "Reconstruction: 0.207089, Regularization: 0.002834, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:21,112 root         INFO     Train Epoch: 186 [5632/8000 (70%)]\tTotal Loss: 0.237283\n",
      "Reconstruction: 0.170210, Regularization: 0.002097, Discriminator: 0.043315; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:21,213 root         INFO     Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 0.235083\n",
      "Reconstruction: 0.168227, Regularization: 0.001882, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:21,314 root         INFO     Train Epoch: 186 [6656/8000 (83%)]\tTotal Loss: 0.248776\n",
      "Reconstruction: 0.181550, Regularization: 0.002245, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:21,414 root         INFO     Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 0.223187\n",
      "Reconstruction: 0.156346, Regularization: 0.001856, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:21,515 root         INFO     Train Epoch: 186 [7680/8000 (96%)]\tTotal Loss: 0.245796\n",
      "Reconstruction: 0.178593, Regularization: 0.002217, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:21,590 root         INFO     ====> Epoch: 186 Average loss: 0.2448\n",
      "2019-04-09 23:03:21,616 root         INFO     Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 0.210729\n",
      "Reconstruction: 0.144203, Regularization: 0.001547, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:21,716 root         INFO     Train Epoch: 187 [512/8000 (6%)]\tTotal Loss: 0.204272\n",
      "Reconstruction: 0.137903, Regularization: 0.001386, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:21,817 root         INFO     Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 0.221500\n",
      "Reconstruction: 0.154997, Regularization: 0.001521, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:21,918 root         INFO     Train Epoch: 187 [1536/8000 (19%)]\tTotal Loss: 0.246878\n",
      "Reconstruction: 0.179542, Regularization: 0.002351, Discriminator: 0.043321; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:22,018 root         INFO     Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 0.204227\n",
      "Reconstruction: 0.137849, Regularization: 0.001393, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:22,118 root         INFO     Train Epoch: 187 [2560/8000 (32%)]\tTotal Loss: 0.222039\n",
      "Reconstruction: 0.155271, Regularization: 0.001785, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:22,219 root         INFO     Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 0.266820\n",
      "Reconstruction: 0.199156, Regularization: 0.002676, Discriminator: 0.043323; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:22,316 root         INFO     Train Epoch: 187 [3584/8000 (45%)]\tTotal Loss: 0.272653\n",
      "Reconstruction: 0.204886, Regularization: 0.002786, Discriminator: 0.043316; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:22,412 root         INFO     Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 0.240738\n",
      "Reconstruction: 0.173358, Regularization: 0.002400, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:22,510 root         INFO     Train Epoch: 187 [4608/8000 (58%)]\tTotal Loss: 0.247655\n",
      "Reconstruction: 0.180389, Regularization: 0.002281, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:22,607 root         INFO     Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 0.196871\n",
      "Reconstruction: 0.130634, Regularization: 0.001249, Discriminator: 0.043325; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:22,705 root         INFO     Train Epoch: 187 [5632/8000 (70%)]\tTotal Loss: 0.215016\n",
      "Reconstruction: 0.148444, Regularization: 0.001593, Discriminator: 0.043315; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:22,804 root         INFO     Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 0.247865\n",
      "Reconstruction: 0.180330, Regularization: 0.002573, Discriminator: 0.043313; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:22,901 root         INFO     Train Epoch: 187 [6656/8000 (83%)]\tTotal Loss: 0.202893\n",
      "Reconstruction: 0.136646, Regularization: 0.001256, Discriminator: 0.043334; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:22,999 root         INFO     Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 0.282969\n",
      "Reconstruction: 0.214794, Regularization: 0.003193, Discriminator: 0.043316; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:23,096 root         INFO     Train Epoch: 187 [7680/8000 (96%)]\tTotal Loss: 0.286954\n",
      "Reconstruction: 0.218874, Regularization: 0.003088, Discriminator: 0.043321; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:23,170 root         INFO     ====> Epoch: 187 Average loss: 0.2443\n",
      "2019-04-09 23:03:23,196 root         INFO     Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 0.244977\n",
      "Reconstruction: 0.177684, Regularization: 0.002316, Discriminator: 0.043323; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:23,299 root         INFO     Train Epoch: 188 [512/8000 (6%)]\tTotal Loss: 0.204743\n",
      "Reconstruction: 0.138422, Regularization: 0.001331, Discriminator: 0.043321; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:23,400 root         INFO     Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 0.286102\n",
      "Reconstruction: 0.217753, Regularization: 0.003392, Discriminator: 0.043295; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:23,501 root         INFO     Train Epoch: 188 [1536/8000 (19%)]\tTotal Loss: 0.213805\n",
      "Reconstruction: 0.147373, Regularization: 0.001469, Discriminator: 0.043308; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:23,602 root         INFO     Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 0.251812\n",
      "Reconstruction: 0.184410, Regularization: 0.002428, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:23,703 root         INFO     Train Epoch: 188 [2560/8000 (32%)]\tTotal Loss: 0.259306\n",
      "Reconstruction: 0.191571, Regularization: 0.002735, Discriminator: 0.043334; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:23,803 root         INFO     Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 0.254840\n",
      "Reconstruction: 0.187323, Regularization: 0.002539, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:23,904 root         INFO     Train Epoch: 188 [3584/8000 (45%)]\tTotal Loss: 0.217282\n",
      "Reconstruction: 0.150645, Regularization: 0.001646, Discriminator: 0.043331; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:24,005 root         INFO     Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 0.242295\n",
      "Reconstruction: 0.175089, Regularization: 0.002234, Discriminator: 0.043313; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:24,106 root         INFO     Train Epoch: 188 [4608/8000 (58%)]\tTotal Loss: 0.183764\n",
      "Reconstruction: 0.117824, Regularization: 0.000959, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:24,207 root         INFO     Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 0.242678\n",
      "Reconstruction: 0.175411, Regularization: 0.002287, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:24,308 root         INFO     Train Epoch: 188 [5632/8000 (70%)]\tTotal Loss: 0.253656\n",
      "Reconstruction: 0.186157, Regularization: 0.002507, Discriminator: 0.043333; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:24,409 root         INFO     Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 0.219223\n",
      "Reconstruction: 0.152528, Regularization: 0.001696, Discriminator: 0.043335; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:24,509 root         INFO     Train Epoch: 188 [6656/8000 (83%)]\tTotal Loss: 0.237659\n",
      "Reconstruction: 0.170615, Regularization: 0.002059, Discriminator: 0.043328; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:24,608 root         INFO     Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 0.260277\n",
      "Reconstruction: 0.192984, Regularization: 0.002302, Discriminator: 0.043331; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:24,707 root         INFO     Train Epoch: 188 [7680/8000 (96%)]\tTotal Loss: 0.229933\n",
      "Reconstruction: 0.163069, Regularization: 0.001885, Discriminator: 0.043325; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:24,781 root         INFO     ====> Epoch: 188 Average loss: 0.2447\n",
      "2019-04-09 23:03:24,807 root         INFO     Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 0.195671\n",
      "Reconstruction: 0.129591, Regularization: 0.001110, Discriminator: 0.043310; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:24,910 root         INFO     Train Epoch: 189 [512/8000 (6%)]\tTotal Loss: 0.226649\n",
      "Reconstruction: 0.159853, Regularization: 0.001797, Discriminator: 0.043329; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:25,010 root         INFO     Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 0.236931\n",
      "Reconstruction: 0.170298, Regularization: 0.001643, Discriminator: 0.043329; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:25,110 root         INFO     Train Epoch: 189 [1536/8000 (19%)]\tTotal Loss: 0.217913\n",
      "Reconstruction: 0.151354, Regularization: 0.001589, Discriminator: 0.043321; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:25,210 root         INFO     Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 0.247446\n",
      "Reconstruction: 0.180528, Regularization: 0.001946, Discriminator: 0.043322; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:25,310 root         INFO     Train Epoch: 189 [2560/8000 (32%)]\tTotal Loss: 0.231964\n",
      "Reconstruction: 0.165331, Regularization: 0.001623, Discriminator: 0.043341; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:25,411 root         INFO     Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 0.180919\n",
      "Reconstruction: 0.115187, Regularization: 0.000752, Discriminator: 0.043327; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:25,511 root         INFO     Train Epoch: 189 [3584/8000 (45%)]\tTotal Loss: 0.239846\n",
      "Reconstruction: 0.172914, Regularization: 0.001944, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:25,611 root         INFO     Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 0.222475\n",
      "Reconstruction: 0.155591, Regularization: 0.001923, Discriminator: 0.043311; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:25,711 root         INFO     Train Epoch: 189 [4608/8000 (58%)]\tTotal Loss: 0.243367\n",
      "Reconstruction: 0.176325, Regularization: 0.002055, Discriminator: 0.043330; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:25,811 root         INFO     Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 0.233633\n",
      "Reconstruction: 0.166802, Regularization: 0.001863, Discriminator: 0.043314; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:25,910 root         INFO     Train Epoch: 189 [5632/8000 (70%)]\tTotal Loss: 0.256674\n",
      "Reconstruction: 0.189393, Regularization: 0.002291, Discriminator: 0.043331; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:26,009 root         INFO     Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 0.241501\n",
      "Reconstruction: 0.174356, Regularization: 0.002160, Discriminator: 0.043320; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:26,106 root         INFO     Train Epoch: 189 [6656/8000 (83%)]\tTotal Loss: 0.200221\n",
      "Reconstruction: 0.134141, Regularization: 0.001105, Discriminator: 0.043317; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:26,204 root         INFO     Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 0.218544\n",
      "Reconstruction: 0.151907, Regularization: 0.001648, Discriminator: 0.043329; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:26,303 root         INFO     Train Epoch: 189 [7680/8000 (96%)]\tTotal Loss: 0.251359\n",
      "Reconstruction: 0.184098, Regularization: 0.002277, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:26,377 root         INFO     ====> Epoch: 189 Average loss: 0.2446\n",
      "2019-04-09 23:03:26,403 root         INFO     Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 0.211214\n",
      "Reconstruction: 0.144779, Regularization: 0.001457, Discriminator: 0.043321; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:26,503 root         INFO     Train Epoch: 190 [512/8000 (6%)]\tTotal Loss: 0.239656\n",
      "Reconstruction: 0.172654, Regularization: 0.002020, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:26,602 root         INFO     Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 0.260200\n",
      "Reconstruction: 0.192816, Regularization: 0.002419, Discriminator: 0.043307; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:26,702 root         INFO     Train Epoch: 190 [1536/8000 (19%)]\tTotal Loss: 0.212268\n",
      "Reconstruction: 0.145768, Regularization: 0.001525, Discriminator: 0.043314; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:26,801 root         INFO     Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 0.195212\n",
      "Reconstruction: 0.129169, Regularization: 0.001062, Discriminator: 0.043325; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:26,900 root         INFO     Train Epoch: 190 [2560/8000 (32%)]\tTotal Loss: 0.238167\n",
      "Reconstruction: 0.171212, Regularization: 0.001971, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:26,999 root         INFO     Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 0.227332\n",
      "Reconstruction: 0.160630, Regularization: 0.001721, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:27,098 root         INFO     Train Epoch: 190 [3584/8000 (45%)]\tTotal Loss: 0.255781\n",
      "Reconstruction: 0.188322, Regularization: 0.002473, Discriminator: 0.043323; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:27,197 root         INFO     Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 0.241852\n",
      "Reconstruction: 0.174897, Regularization: 0.001982, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:27,296 root         INFO     Train Epoch: 190 [4608/8000 (58%)]\tTotal Loss: 0.261450\n",
      "Reconstruction: 0.194052, Regularization: 0.002419, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:27,395 root         INFO     Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 0.242778\n",
      "Reconstruction: 0.176021, Regularization: 0.001773, Discriminator: 0.043321; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:27,494 root         INFO     Train Epoch: 190 [5632/8000 (70%)]\tTotal Loss: 0.337519\n",
      "Reconstruction: 0.268713, Regularization: 0.003818, Discriminator: 0.043326; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:27,594 root         INFO     Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 0.247974\n",
      "Reconstruction: 0.180684, Regularization: 0.002294, Discriminator: 0.043334; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:27,693 root         INFO     Train Epoch: 190 [6656/8000 (83%)]\tTotal Loss: 0.227956\n",
      "Reconstruction: 0.161400, Regularization: 0.001574, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:27,791 root         INFO     Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 0.221914\n",
      "Reconstruction: 0.155315, Regularization: 0.001603, Discriminator: 0.043335; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:27,890 root         INFO     Train Epoch: 190 [7680/8000 (96%)]\tTotal Loss: 0.215144\n",
      "Reconstruction: 0.148717, Regularization: 0.001457, Discriminator: 0.043310; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:27,964 root         INFO     ====> Epoch: 190 Average loss: 0.2447\n",
      "2019-04-09 23:03:27,991 root         INFO     Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 0.221842\n",
      "Reconstruction: 0.155277, Regularization: 0.001583, Discriminator: 0.043319; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:28,091 root         INFO     Train Epoch: 191 [512/8000 (6%)]\tTotal Loss: 0.244713\n",
      "Reconstruction: 0.177863, Regularization: 0.001863, Discriminator: 0.043324; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:28,192 root         INFO     Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 0.281069\n",
      "Reconstruction: 0.213364, Regularization: 0.002725, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:28,293 root         INFO     Train Epoch: 191 [1536/8000 (19%)]\tTotal Loss: 0.235802\n",
      "Reconstruction: 0.168979, Regularization: 0.001835, Discriminator: 0.043319; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:28,392 root         INFO     Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 0.239891\n",
      "Reconstruction: 0.172780, Regularization: 0.002130, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:28,489 root         INFO     Train Epoch: 191 [2560/8000 (32%)]\tTotal Loss: 0.225328\n",
      "Reconstruction: 0.158824, Regularization: 0.001512, Discriminator: 0.043330; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:28,587 root         INFO     Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 0.226780\n",
      "Reconstruction: 0.160288, Regularization: 0.001505, Discriminator: 0.043322; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:28,686 root         INFO     Train Epoch: 191 [3584/8000 (45%)]\tTotal Loss: 0.246184\n",
      "Reconstruction: 0.179179, Regularization: 0.002012, Discriminator: 0.043334; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:28,784 root         INFO     Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 0.264277\n",
      "Reconstruction: 0.196664, Regularization: 0.002625, Discriminator: 0.043324; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:28,882 root         INFO     Train Epoch: 191 [4608/8000 (58%)]\tTotal Loss: 0.292225\n",
      "Reconstruction: 0.224119, Regularization: 0.003122, Discriminator: 0.043327; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:28,980 root         INFO     Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 0.234195\n",
      "Reconstruction: 0.167314, Regularization: 0.001915, Discriminator: 0.043305; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:29,079 root         INFO     Train Epoch: 191 [5632/8000 (70%)]\tTotal Loss: 0.238092\n",
      "Reconstruction: 0.171175, Regularization: 0.001937, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:29,177 root         INFO     Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 0.248615\n",
      "Reconstruction: 0.181368, Regularization: 0.002274, Discriminator: 0.043317; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:29,275 root         INFO     Train Epoch: 191 [6656/8000 (83%)]\tTotal Loss: 0.235454\n",
      "Reconstruction: 0.168428, Regularization: 0.002060, Discriminator: 0.043309; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:29,374 root         INFO     Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 0.232215\n",
      "Reconstruction: 0.165496, Regularization: 0.001752, Discriminator: 0.043307; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:29,472 root         INFO     Train Epoch: 191 [7680/8000 (96%)]\tTotal Loss: 0.275704\n",
      "Reconstruction: 0.207980, Regularization: 0.002757, Discriminator: 0.043309; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:29,547 root         INFO     ====> Epoch: 191 Average loss: 0.2447\n",
      "2019-04-09 23:03:29,573 root         INFO     Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 0.239513\n",
      "Reconstruction: 0.172500, Regularization: 0.002038, Discriminator: 0.043317; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:29,673 root         INFO     Train Epoch: 192 [512/8000 (6%)]\tTotal Loss: 0.253721\n",
      "Reconstruction: 0.186333, Regularization: 0.002401, Discriminator: 0.043316; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:29,771 root         INFO     Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 0.203029\n",
      "Reconstruction: 0.136936, Regularization: 0.001120, Discriminator: 0.043316; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:29,869 root         INFO     Train Epoch: 192 [1536/8000 (19%)]\tTotal Loss: 0.271481\n",
      "Reconstruction: 0.203717, Regularization: 0.002760, Discriminator: 0.043338; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:29,967 root         INFO     Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.208296\n",
      "Reconstruction: 0.141906, Regularization: 0.001400, Discriminator: 0.043332; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:30,065 root         INFO     Train Epoch: 192 [2560/8000 (32%)]\tTotal Loss: 0.210245\n",
      "Reconstruction: 0.143630, Regularization: 0.001629, Discriminator: 0.043321; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:30,163 root         INFO     Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 0.242681\n",
      "Reconstruction: 0.175587, Regularization: 0.002134, Discriminator: 0.043309; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:30,261 root         INFO     Train Epoch: 192 [3584/8000 (45%)]\tTotal Loss: 0.244757\n",
      "Reconstruction: 0.177683, Regularization: 0.002106, Discriminator: 0.043307; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:30,358 root         INFO     Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 0.207297\n",
      "Reconstruction: 0.140943, Regularization: 0.001353, Discriminator: 0.043336; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:30,456 root         INFO     Train Epoch: 192 [4608/8000 (58%)]\tTotal Loss: 0.239554\n",
      "Reconstruction: 0.172599, Regularization: 0.001968, Discriminator: 0.043320; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:30,554 root         INFO     Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 0.277377\n",
      "Reconstruction: 0.209482, Regularization: 0.002904, Discriminator: 0.043328; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:30,651 root         INFO     Train Epoch: 192 [5632/8000 (70%)]\tTotal Loss: 0.247942\n",
      "Reconstruction: 0.180761, Regularization: 0.002194, Discriminator: 0.043331; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:30,747 root         INFO     Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 0.236593\n",
      "Reconstruction: 0.169667, Regularization: 0.001927, Discriminator: 0.043337; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:30,844 root         INFO     Train Epoch: 192 [6656/8000 (83%)]\tTotal Loss: 0.281214\n",
      "Reconstruction: 0.213171, Regularization: 0.003038, Discriminator: 0.043342; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:30,940 root         INFO     Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 0.215354\n",
      "Reconstruction: 0.148696, Regularization: 0.001679, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:31,036 root         INFO     Train Epoch: 192 [7680/8000 (96%)]\tTotal Loss: 0.220654\n",
      "Reconstruction: 0.153912, Regularization: 0.001752, Discriminator: 0.043327; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:31,108 root         INFO     ====> Epoch: 192 Average loss: 0.2443\n",
      "2019-04-09 23:03:31,134 root         INFO     Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 0.269295\n",
      "Reconstruction: 0.201682, Regularization: 0.002634, Discriminator: 0.043315; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:31,236 root         INFO     Train Epoch: 193 [512/8000 (6%)]\tTotal Loss: 0.269049\n",
      "Reconstruction: 0.201199, Regularization: 0.002868, Discriminator: 0.043319; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:31,336 root         INFO     Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 0.256442\n",
      "Reconstruction: 0.189072, Regularization: 0.002383, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:31,436 root         INFO     Train Epoch: 193 [1536/8000 (19%)]\tTotal Loss: 0.262984\n",
      "Reconstruction: 0.195407, Regularization: 0.002599, Discriminator: 0.043320; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:31,536 root         INFO     Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 0.236425\n",
      "Reconstruction: 0.169358, Regularization: 0.002093, Discriminator: 0.043318; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:31,636 root         INFO     Train Epoch: 193 [2560/8000 (32%)]\tTotal Loss: 0.225593\n",
      "Reconstruction: 0.158811, Regularization: 0.001793, Discriminator: 0.043326; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:31,737 root         INFO     Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 0.211033\n",
      "Reconstruction: 0.144623, Regularization: 0.001458, Discriminator: 0.043301; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:31,837 root         INFO     Train Epoch: 193 [3584/8000 (45%)]\tTotal Loss: 0.222452\n",
      "Reconstruction: 0.155746, Regularization: 0.001742, Discriminator: 0.043309; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:31,937 root         INFO     Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 0.239653\n",
      "Reconstruction: 0.172647, Regularization: 0.002014, Discriminator: 0.043327; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:32,037 root         INFO     Train Epoch: 193 [4608/8000 (58%)]\tTotal Loss: 0.271819\n",
      "Reconstruction: 0.204210, Regularization: 0.002639, Discriminator: 0.043312; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:32,137 root         INFO     Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 0.221276\n",
      "Reconstruction: 0.154445, Regularization: 0.001846, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:32,235 root         INFO     Train Epoch: 193 [5632/8000 (70%)]\tTotal Loss: 0.260157\n",
      "Reconstruction: 0.192330, Regularization: 0.002847, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:32,332 root         INFO     Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 0.249062\n",
      "Reconstruction: 0.181910, Regularization: 0.002164, Discriminator: 0.043324; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:32,429 root         INFO     Train Epoch: 193 [6656/8000 (83%)]\tTotal Loss: 0.259294\n",
      "Reconstruction: 0.191695, Regularization: 0.002620, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:32,527 root         INFO     Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 0.201292\n",
      "Reconstruction: 0.134932, Regularization: 0.001377, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:32,625 root         INFO     Train Epoch: 193 [7680/8000 (96%)]\tTotal Loss: 0.242730\n",
      "Reconstruction: 0.175341, Regularization: 0.002408, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:32,701 root         INFO     ====> Epoch: 193 Average loss: 0.2444\n",
      "2019-04-09 23:03:32,727 root         INFO     Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 0.289332\n",
      "Reconstruction: 0.221035, Regularization: 0.003311, Discriminator: 0.043320; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:32,824 root         INFO     Train Epoch: 194 [512/8000 (6%)]\tTotal Loss: 0.219846\n",
      "Reconstruction: 0.153013, Regularization: 0.001849, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:32,919 root         INFO     Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 0.244025\n",
      "Reconstruction: 0.176671, Regularization: 0.002371, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:33,016 root         INFO     Train Epoch: 194 [1536/8000 (19%)]\tTotal Loss: 0.245574\n",
      "Reconstruction: 0.178129, Regularization: 0.002459, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:33,110 root         INFO     Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 0.242044\n",
      "Reconstruction: 0.174828, Regularization: 0.002233, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:33,203 root         INFO     Train Epoch: 194 [2560/8000 (32%)]\tTotal Loss: 0.297496\n",
      "Reconstruction: 0.229035, Regularization: 0.003478, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:33,298 root         INFO     Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 0.286787\n",
      "Reconstruction: 0.218470, Regularization: 0.003337, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:33,395 root         INFO     Train Epoch: 194 [3584/8000 (45%)]\tTotal Loss: 0.213582\n",
      "Reconstruction: 0.146801, Regularization: 0.001797, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:33,492 root         INFO     Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 0.251626\n",
      "Reconstruction: 0.183993, Regularization: 0.002649, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:33,590 root         INFO     Train Epoch: 194 [4608/8000 (58%)]\tTotal Loss: 0.231835\n",
      "Reconstruction: 0.164947, Regularization: 0.001909, Discriminator: 0.043316; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:33,687 root         INFO     Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 0.231066\n",
      "Reconstruction: 0.163972, Regularization: 0.002120, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:33,784 root         INFO     Train Epoch: 194 [5632/8000 (70%)]\tTotal Loss: 0.268375\n",
      "Reconstruction: 0.200476, Regularization: 0.002907, Discriminator: 0.043328; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:33,882 root         INFO     Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 0.220051\n",
      "Reconstruction: 0.153319, Regularization: 0.001746, Discriminator: 0.043319; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:33,979 root         INFO     Train Epoch: 194 [6656/8000 (83%)]\tTotal Loss: 0.258215\n",
      "Reconstruction: 0.190552, Regularization: 0.002704, Discriminator: 0.043304; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:34,076 root         INFO     Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 0.244802\n",
      "Reconstruction: 0.177321, Regularization: 0.002510, Discriminator: 0.043310; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:34,174 root         INFO     Train Epoch: 194 [7680/8000 (96%)]\tTotal Loss: 0.231701\n",
      "Reconstruction: 0.164908, Regularization: 0.001810, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:34,246 root         INFO     ====> Epoch: 194 Average loss: 0.2444\n",
      "2019-04-09 23:03:34,273 root         INFO     Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 0.211901\n",
      "Reconstruction: 0.145423, Regularization: 0.001480, Discriminator: 0.043336; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:34,372 root         INFO     Train Epoch: 195 [512/8000 (6%)]\tTotal Loss: 0.257739\n",
      "Reconstruction: 0.190165, Regularization: 0.002587, Discriminator: 0.043327; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:34,471 root         INFO     Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 0.238043\n",
      "Reconstruction: 0.170976, Regularization: 0.002084, Discriminator: 0.043315; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:34,569 root         INFO     Train Epoch: 195 [1536/8000 (19%)]\tTotal Loss: 0.285637\n",
      "Reconstruction: 0.217618, Regularization: 0.003030, Discriminator: 0.043319; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:34,667 root         INFO     Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 0.258739\n",
      "Reconstruction: 0.191203, Regularization: 0.002523, Discriminator: 0.043350; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:34,766 root         INFO     Train Epoch: 195 [2560/8000 (32%)]\tTotal Loss: 0.235557\n",
      "Reconstruction: 0.168345, Regularization: 0.002237, Discriminator: 0.043314; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:34,864 root         INFO     Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 0.249212\n",
      "Reconstruction: 0.181994, Regularization: 0.002217, Discriminator: 0.043338; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:34,963 root         INFO     Train Epoch: 195 [3584/8000 (45%)]\tTotal Loss: 0.252038\n",
      "Reconstruction: 0.184527, Regularization: 0.002526, Discriminator: 0.043316; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:35,061 root         INFO     Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 0.277939\n",
      "Reconstruction: 0.210129, Regularization: 0.002824, Discriminator: 0.043319; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:35,160 root         INFO     Train Epoch: 195 [4608/8000 (58%)]\tTotal Loss: 0.234496\n",
      "Reconstruction: 0.167548, Regularization: 0.001974, Discriminator: 0.043301; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:35,260 root         INFO     Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 0.245267\n",
      "Reconstruction: 0.177881, Regularization: 0.002431, Discriminator: 0.043291; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:35,360 root         INFO     Train Epoch: 195 [5632/8000 (70%)]\tTotal Loss: 0.270031\n",
      "Reconstruction: 0.202285, Regularization: 0.002754, Discriminator: 0.043340; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:35,459 root         INFO     Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 0.247361\n",
      "Reconstruction: 0.180249, Regularization: 0.002129, Discriminator: 0.043325; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:35,557 root         INFO     Train Epoch: 195 [6656/8000 (83%)]\tTotal Loss: 0.220124\n",
      "Reconstruction: 0.153342, Regularization: 0.001796, Discriminator: 0.043329; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:35,657 root         INFO     Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 0.240345\n",
      "Reconstruction: 0.173044, Regularization: 0.002343, Discriminator: 0.043298; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:35,756 root         INFO     Train Epoch: 195 [7680/8000 (96%)]\tTotal Loss: 0.272723\n",
      "Reconstruction: 0.204583, Regularization: 0.003154, Discriminator: 0.043339; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:35,829 root         INFO     ====> Epoch: 195 Average loss: 0.2446\n",
      "2019-04-09 23:03:35,856 root         INFO     Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 0.292755\n",
      "Reconstruction: 0.224494, Regularization: 0.003281, Discriminator: 0.043324; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:35,956 root         INFO     Train Epoch: 196 [512/8000 (6%)]\tTotal Loss: 0.274029\n",
      "Reconstruction: 0.206071, Regularization: 0.002959, Discriminator: 0.043329; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:36,055 root         INFO     Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 0.268126\n",
      "Reconstruction: 0.200380, Regularization: 0.002779, Discriminator: 0.043307; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:36,155 root         INFO     Train Epoch: 196 [1536/8000 (19%)]\tTotal Loss: 0.260141\n",
      "Reconstruction: 0.192412, Regularization: 0.002755, Discriminator: 0.043314; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:36,255 root         INFO     Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 0.310025\n",
      "Reconstruction: 0.241255, Regularization: 0.003784, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:36,354 root         INFO     Train Epoch: 196 [2560/8000 (32%)]\tTotal Loss: 0.267925\n",
      "Reconstruction: 0.200170, Regularization: 0.002773, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:36,454 root         INFO     Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 0.243369\n",
      "Reconstruction: 0.175849, Regularization: 0.002529, Discriminator: 0.043326; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:36,554 root         INFO     Train Epoch: 196 [3584/8000 (45%)]\tTotal Loss: 0.266207\n",
      "Reconstruction: 0.198568, Regularization: 0.002657, Discriminator: 0.043326; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:36,654 root         INFO     Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 0.249089\n",
      "Reconstruction: 0.181631, Regularization: 0.002486, Discriminator: 0.043316; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:36,754 root         INFO     Train Epoch: 196 [4608/8000 (58%)]\tTotal Loss: 0.245687\n",
      "Reconstruction: 0.178693, Regularization: 0.002006, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:36,854 root         INFO     Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 0.204080\n",
      "Reconstruction: 0.137773, Regularization: 0.001336, Discriminator: 0.043316; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:36,954 root         INFO     Train Epoch: 196 [5632/8000 (70%)]\tTotal Loss: 0.212091\n",
      "Reconstruction: 0.145540, Regularization: 0.001539, Discriminator: 0.043354; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:37,053 root         INFO     Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 0.272672\n",
      "Reconstruction: 0.204798, Regularization: 0.002889, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:37,153 root         INFO     Train Epoch: 196 [6656/8000 (83%)]\tTotal Loss: 0.270510\n",
      "Reconstruction: 0.202759, Regularization: 0.002752, Discriminator: 0.043335; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:37,253 root         INFO     Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 0.277060\n",
      "Reconstruction: 0.209228, Regularization: 0.002857, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:37,352 root         INFO     Train Epoch: 196 [7680/8000 (96%)]\tTotal Loss: 0.269941\n",
      "Reconstruction: 0.202600, Regularization: 0.002355, Discriminator: 0.043327; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:37,427 root         INFO     ====> Epoch: 196 Average loss: 0.2447\n",
      "2019-04-09 23:03:37,454 root         INFO     Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 0.274002\n",
      "Reconstruction: 0.206064, Regularization: 0.002957, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:37,554 root         INFO     Train Epoch: 197 [512/8000 (6%)]\tTotal Loss: 0.237997\n",
      "Reconstruction: 0.171189, Regularization: 0.001822, Discriminator: 0.043328; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:37,655 root         INFO     Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 0.246943\n",
      "Reconstruction: 0.179931, Regularization: 0.002024, Discriminator: 0.043322; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:37,756 root         INFO     Train Epoch: 197 [1536/8000 (19%)]\tTotal Loss: 0.296197\n",
      "Reconstruction: 0.228111, Regularization: 0.003102, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:37,855 root         INFO     Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 0.208754\n",
      "Reconstruction: 0.142367, Regularization: 0.001399, Discriminator: 0.043323; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:37,955 root         INFO     Train Epoch: 197 [2560/8000 (32%)]\tTotal Loss: 0.255425\n",
      "Reconstruction: 0.188072, Regularization: 0.002362, Discriminator: 0.043325; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:38,055 root         INFO     Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 0.238993\n",
      "Reconstruction: 0.171939, Regularization: 0.002071, Discriminator: 0.043318; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:38,154 root         INFO     Train Epoch: 197 [3584/8000 (45%)]\tTotal Loss: 0.240664\n",
      "Reconstruction: 0.173880, Regularization: 0.001814, Discriminator: 0.043312; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:38,254 root         INFO     Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 0.276145\n",
      "Reconstruction: 0.208466, Regularization: 0.002680, Discriminator: 0.043339; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:38,353 root         INFO     Train Epoch: 197 [4608/8000 (58%)]\tTotal Loss: 0.268306\n",
      "Reconstruction: 0.200762, Regularization: 0.002563, Discriminator: 0.043327; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:38,452 root         INFO     Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 0.275048\n",
      "Reconstruction: 0.207485, Regularization: 0.002567, Discriminator: 0.043331; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:38,551 root         INFO     Train Epoch: 197 [5632/8000 (70%)]\tTotal Loss: 0.232941\n",
      "Reconstruction: 0.165976, Regularization: 0.001959, Discriminator: 0.043335; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:38,650 root         INFO     Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 0.269581\n",
      "Reconstruction: 0.202051, Regularization: 0.002538, Discriminator: 0.043332; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:38,748 root         INFO     Train Epoch: 197 [6656/8000 (83%)]\tTotal Loss: 0.326121\n",
      "Reconstruction: 0.257425, Regularization: 0.003709, Discriminator: 0.043321; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:38,850 root         INFO     Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 0.244713\n",
      "Reconstruction: 0.177488, Regularization: 0.002242, Discriminator: 0.043324; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:38,951 root         INFO     Train Epoch: 197 [7680/8000 (96%)]\tTotal Loss: 0.223208\n",
      "Reconstruction: 0.156478, Regularization: 0.001745, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:39,026 root         INFO     ====> Epoch: 197 Average loss: 0.2447\n",
      "2019-04-09 23:03:39,053 root         INFO     Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 0.272323\n",
      "Reconstruction: 0.204714, Regularization: 0.002616, Discriminator: 0.043333; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:39,154 root         INFO     Train Epoch: 198 [512/8000 (6%)]\tTotal Loss: 0.214255\n",
      "Reconstruction: 0.147669, Regularization: 0.001616, Discriminator: 0.043317; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:39,254 root         INFO     Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.309990\n",
      "Reconstruction: 0.241579, Regularization: 0.003426, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:39,354 root         INFO     Train Epoch: 198 [1536/8000 (19%)]\tTotal Loss: 0.276148\n",
      "Reconstruction: 0.208184, Regularization: 0.002995, Discriminator: 0.043308; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:39,454 root         INFO     Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 0.241282\n",
      "Reconstruction: 0.174259, Regularization: 0.002036, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:39,554 root         INFO     Train Epoch: 198 [2560/8000 (32%)]\tTotal Loss: 0.241249\n",
      "Reconstruction: 0.174138, Regularization: 0.002141, Discriminator: 0.043311; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:39,655 root         INFO     Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 0.268895\n",
      "Reconstruction: 0.201197, Regularization: 0.002706, Discriminator: 0.043330; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:39,754 root         INFO     Train Epoch: 198 [3584/8000 (45%)]\tTotal Loss: 0.228707\n",
      "Reconstruction: 0.161917, Regularization: 0.001818, Discriminator: 0.043309; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:39,854 root         INFO     Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 0.281531\n",
      "Reconstruction: 0.213557, Regularization: 0.002985, Discriminator: 0.043331; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:39,954 root         INFO     Train Epoch: 198 [4608/8000 (58%)]\tTotal Loss: 0.219851\n",
      "Reconstruction: 0.153121, Regularization: 0.001750, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:40,054 root         INFO     Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 0.289319\n",
      "Reconstruction: 0.221247, Regularization: 0.003087, Discriminator: 0.043327; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:40,154 root         INFO     Train Epoch: 198 [5632/8000 (70%)]\tTotal Loss: 0.233868\n",
      "Reconstruction: 0.167041, Regularization: 0.001839, Discriminator: 0.043326; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:40,254 root         INFO     Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 0.251992\n",
      "Reconstruction: 0.184737, Regularization: 0.002289, Discriminator: 0.043304; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:40,354 root         INFO     Train Epoch: 198 [6656/8000 (83%)]\tTotal Loss: 0.235224\n",
      "Reconstruction: 0.168313, Regularization: 0.001916, Discriminator: 0.043336; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:40,454 root         INFO     Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 0.211768\n",
      "Reconstruction: 0.145355, Regularization: 0.001433, Discriminator: 0.043324; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:40,554 root         INFO     Train Epoch: 198 [7680/8000 (96%)]\tTotal Loss: 0.251132\n",
      "Reconstruction: 0.183956, Regularization: 0.002217, Discriminator: 0.043303; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:40,628 root         INFO     ====> Epoch: 198 Average loss: 0.2445\n",
      "2019-04-09 23:03:40,654 root         INFO     Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 0.240799\n",
      "Reconstruction: 0.173613, Regularization: 0.002212, Discriminator: 0.043310; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:40,755 root         INFO     Train Epoch: 199 [512/8000 (6%)]\tTotal Loss: 0.230664\n",
      "Reconstruction: 0.163666, Regularization: 0.002019, Discriminator: 0.043317; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:40,855 root         INFO     Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 0.202764\n",
      "Reconstruction: 0.136460, Regularization: 0.001312, Discriminator: 0.043329; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:40,956 root         INFO     Train Epoch: 199 [1536/8000 (19%)]\tTotal Loss: 0.207477\n",
      "Reconstruction: 0.141186, Regularization: 0.001298, Discriminator: 0.043334; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:41,056 root         INFO     Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 0.204286\n",
      "Reconstruction: 0.137939, Regularization: 0.001381, Discriminator: 0.043307; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:41,156 root         INFO     Train Epoch: 199 [2560/8000 (32%)]\tTotal Loss: 0.230982\n",
      "Reconstruction: 0.164094, Regularization: 0.001886, Discriminator: 0.043338; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:41,256 root         INFO     Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 0.216715\n",
      "Reconstruction: 0.150124, Regularization: 0.001585, Discriminator: 0.043345; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:41,357 root         INFO     Train Epoch: 199 [3584/8000 (45%)]\tTotal Loss: 0.236872\n",
      "Reconstruction: 0.169797, Regularization: 0.002078, Discriminator: 0.043342; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:41,457 root         INFO     Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 0.247689\n",
      "Reconstruction: 0.180352, Regularization: 0.002358, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:41,557 root         INFO     Train Epoch: 199 [4608/8000 (58%)]\tTotal Loss: 0.255825\n",
      "Reconstruction: 0.188478, Regularization: 0.002363, Discriminator: 0.043326; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:41,658 root         INFO     Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 0.231187\n",
      "Reconstruction: 0.164175, Regularization: 0.002027, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:41,756 root         INFO     Train Epoch: 199 [5632/8000 (70%)]\tTotal Loss: 0.301656\n",
      "Reconstruction: 0.233204, Regularization: 0.003487, Discriminator: 0.043309; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:41,853 root         INFO     Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.252517\n",
      "Reconstruction: 0.185201, Regularization: 0.002355, Discriminator: 0.043293; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:41,950 root         INFO     Train Epoch: 199 [6656/8000 (83%)]\tTotal Loss: 0.249622\n",
      "Reconstruction: 0.182297, Regularization: 0.002343, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:42,049 root         INFO     Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 0.238673\n",
      "Reconstruction: 0.171747, Regularization: 0.001939, Discriminator: 0.043331; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:42,149 root         INFO     Train Epoch: 199 [7680/8000 (96%)]\tTotal Loss: 0.221575\n",
      "Reconstruction: 0.154736, Regularization: 0.001831, Discriminator: 0.043341; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 23:03:42,224 root         INFO     ====> Epoch: 199 Average loss: 0.2444\n",
      "2019-04-09 23:03:42,237 luigi-interface INFO     [pid 11233] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=11233) done      TrainVEM()\n",
      "2019-04-09 23:03:42,237 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 23:03:42,238 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   DONE\n",
      "2019-04-09 23:03:42,238 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 23:03:42,238 luigi-interface DEBUG    Pending tasks: 1\n",
      "2019-04-09 23:03:42,238 luigi-interface INFO     [pid 11233] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=11233) running   RunAll()\n",
      "2019-04-09 23:03:42,239 luigi-interface INFO     [pid 11233] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=11233) done      RunAll()\n",
      "2019-04-09 23:03:42,239 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 23:03:42,239 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   DONE\n",
      "2019-04-09 23:03:42,239 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 23:03:42,240 luigi-interface DEBUG    Done\n",
      "2019-04-09 23:03:42,240 luigi-interface DEBUG    There are no more tasks to run at this time\n",
      "2019-04-09 23:03:42,240 luigi-interface INFO     Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=11233) was stopped. Shutting down Keep-Alive thread\n",
      "2019-04-09 23:03:42,241 luigi-interface INFO     \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 4 tasks of which:\n",
      "* 4 ran successfully:\n",
      "    - 1 MakeDataSet()\n",
      "    - 1 RunAll()\n",
      "    - 1 TrainVAE()\n",
      "    - 1 TrainVEM()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pattern = 'logs'\n",
    "logs = []\n",
    "for filename in os.listdir(OUTPUT):\n",
    "    if re.search(pattern, filename):\n",
    "        logs.append(filename)\n",
    "\n",
    "print('Found %d log files.' % len(logs))\n",
    "        \n",
    "for filename in logs:\n",
    "    path = os.path.join(OUTPUT, filename)\n",
    "    print('\\n-- Log file: %s\\n' % filename)\n",
    "    with open(path, 'r') as f:\n",
    "        message = f.read()\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
