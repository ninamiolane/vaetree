{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import importlib\n",
    "import toylosses\n",
    "importlib.reload(toylosses)\n",
    "import toynn\n",
    "importlib.reload(toynn)\n",
    "import toyvis\n",
    "importlib.reload(toyvis)\n",
    "\n",
    "import torch\n",
    "sns.set()\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "OUTPUT = '/scratch/users/nmiolane/toyoutput_180409a'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect generation of synthetic data from decoder_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_true = 2\n",
    "color_true = 'green'\n",
    "def generate_synthetic_1d(w=w_true, n=10):\n",
    "    z = np.random.normal(loc=0, scale=1, size=(n, 1))\n",
    "    eps = np.random.normal(loc=0, scale=1, size=(n, 1))\n",
    "\n",
    "    x = w * z + eps\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight tensor([[2.]], device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "assert decoder_true.layers[0].weight[0, 0] == w_true\n",
    "\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix from decoder:\n",
      "5.174616839917996\n",
      "Covariance matrix from synthetic:\n",
      "4.905543167070465\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "\n",
    "synthetic_x = generate_synthetic_1d(w=w_true, n=n_samples)\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = toyvis.plot_data(generated_true_x, color='green', label='from decoder true', ax=ax)\n",
    "ax = toyvis.plot_data(synthetic_x, color='green', label='from synthetic true', ax=ax)\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "print('Covariance matrix from decoder:')\n",
    "cov = np.cov(generated_true_x.T)\n",
    "print(cov)\n",
    "\n",
    "print('Covariance matrix from synthetic:')\n",
    "cov = np.cov(synthetic_x.T)\n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results from standard VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[2.]], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[1.0987]], device='cuda:0') \n",
      "\n",
      "Last losses:\n",
      "[0.04121307018399239, 0.04090024897456169, 0.04072944913804531, 0.04138818988204002, 0.04098958967626095]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "decoder_path = glob.glob(f'{OUTPUT}/train_vae/models/decoder.pth')[0]\n",
    "decoder = torch.load(decoder_path, map_location=DEVICE)\n",
    "\n",
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "losses_vae_path = glob.glob(f'{OUTPUT}/train_vae/train_losses.pkl')[0]\n",
    "train_losses_all_epochs = pickle.load(open(losses_vae_path, 'rb'))\n",
    "\n",
    "plt.figure()\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "plt.plot(range(n_epochs), train_losses_total)\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa4742a8b70>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 10000\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "\n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax, label='true')\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax, label='vae estimate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the inference on the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Optimal value for phi\n",
      "0.4\n",
      "\n",
      "-- Learnt values of parameters\n",
      "fc1.weight tensor([[0.4968]], device='cuda:0') \n",
      "\n",
      "0.49675614\n"
     ]
    }
   ],
   "source": [
    "encoder_path = glob.glob(f'{OUTPUT}/train_vae/models/encoder.pth')[0]\n",
    "encoder = torch.load(encoder_path, map_location=DEVICE)\n",
    "\n",
    "print('\\n-- Optimal value for phi')\n",
    "phi_opt = w_true / (w_true ** 2 + 1)\n",
    "print(phi_opt)\n",
    "\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in encoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "phi_encoder = encoder.fc1.weight.data.cpu().numpy()[0,0]\n",
    "print(phi_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa473d7f748>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_to_sample = 10000\n",
    "\n",
    "x = 3\n",
    "true_loc = w_true / (w_true ** 2 + 1) * x\n",
    "true_scale = 1/ np.sqrt((1 + w_true ** 2))\n",
    "z_true_posterior = np.random.normal(loc=true_loc, scale=true_scale, size=(n_to_sample, 1))\n",
    "z_opt_posterior = np.random.normal(loc=true_loc, scale=1, size=(n_to_sample, 1))\n",
    "z_encoder = np.random.normal(loc=phi_encoder*x, scale=1, size=(n_to_sample, 1)) \n",
    "                        \n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "ax = toyvis.plot_data(z_true_posterior, color='darkgreen', ax=ax)\n",
    "ax = toyvis.plot_data(z_opt_posterior, color='purple', ax=ax)\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(z_true_posterior, color='darkgreen', ax=ax)\n",
    "toyvis.plot_data(z_encoder, color='red', ax=ax)\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(z_opt_posterior, color='purple', ax=ax)\n",
    "toyvis.plot_data(z_encoder, color='red', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results from VEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[2.]], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[0.0350]], device='cuda:0') \n",
      "\n",
      "Last losses:\n",
      "[0.0851159046292305, 0.08510567712783813, 0.08511399310827256, 0.08511706686019897, 0.08512264275550842]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "decoder_path = glob.glob(f'{OUTPUT}/train_vem/models/decoder.pth')[0]\n",
    "decoder = torch.load(decoder_path, map_location=DEVICE)\n",
    "\n",
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "losses_vae_path = glob.glob(f'{OUTPUT}/train_vem/train_losses.pkl')[0]\n",
    "train_losses_all_epochs = pickle.load(open(losses_vae_path, 'rb'))\n",
    "\n",
    "plt.figure()\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "plt.plot(range(n_epochs), train_losses_total)\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa47400a588>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "\n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='orange', ax=ax)\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "toyvis.plot_data(generated_x, color='orange', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print pipeline logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Log file: logs2019-04-09 20:43:29.033664.txt\n",
      "\n",
      "2019-04-09 20:43:29,033 root         INFO     start\n",
      "2019-04-09 20:43:29,048 luigi        INFO     logging configured by default settings\n",
      "2019-04-09 20:43:29,071 luigi-interface DEBUG    Checking if RunAll() is complete\n",
      "2019-04-09 20:43:29,072 luigi-interface DEBUG    Checking if TrainVAE() is complete\n",
      "2019-04-09 20:43:29,072 luigi-interface DEBUG    Checking if TrainVEM() is complete\n",
      "2019-04-09 20:43:29,073 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   PENDING\n",
      "2019-04-09 20:43:29,073 luigi-interface DEBUG    Checking if MakeDataSet() is complete\n",
      "2019-04-09 20:43:29,074 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   PENDING\n",
      "2019-04-09 20:43:29,074 luigi-interface INFO     Informed scheduler that task   MakeDataSet__99914b932b   has status   PENDING\n",
      "2019-04-09 20:43:29,074 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   PENDING\n",
      "2019-04-09 20:43:29,074 luigi-interface INFO     Done scheduling tasks\n",
      "2019-04-09 20:43:29,074 luigi-interface INFO     Running Worker with 1 processes\n",
      "2019-04-09 20:43:29,074 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 20:43:29,075 luigi-interface DEBUG    Pending tasks: 4\n",
      "2019-04-09 20:43:29,075 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) running   MakeDataSet()\n",
      "2019-04-09 20:43:29,075 root         INFO     Configuration:\n",
      "2019-04-09 20:43:29,075 root         INFO     DATA_DIM = 1\n",
      "2019-04-09 20:43:29,075 root         INFO     LATENT_DIM = 1\n",
      "2019-04-09 20:43:29,075 root         INFO     N_DECODER_LAYERS = 1\n",
      "2019-04-09 20:43:29,075 root         INFO     NONLINEARITY=False\n",
      "2019-04-09 20:43:29,075 root         INFO     WITH_BIASX=False\n",
      "2019-04-09 20:43:29,075 root         INFO     WITH_LOGVARX=False\n",
      "2019-04-09 20:43:29,075 root         INFO     WITH_BIASZ=False\n",
      "2019-04-09 20:43:29,075 root         INFO     WITH_LOGVARZ=False\n",
      "2019-04-09 20:43:29,075 root         INFO     N_SAMPLES=10000\n",
      "2019-04-09 20:43:29,075 root         INFO     W_TRUE:\n",
      "2019-04-09 20:43:29,076 root         INFO     {0: [[2.0]]}\n",
      "2019-04-09 20:43:29,076 root         INFO     B_TRUE:\n",
      "2019-04-09 20:43:29,076 root         INFO     {}\n",
      "2019-04-09 20:43:32,927 root         INFO     Values of true 'decoder' parameters:\n",
      "2019-04-09 20:43:32,927 root         INFO     layers.0.weight\n",
      "2019-04-09 20:43:32,927 root         INFO     tensor([[2.]], device='cuda:0')\n",
      "2019-04-09 20:43:33,003 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) done      MakeDataSet()\n",
      "2019-04-09 20:43:33,003 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 20:43:33,004 luigi-interface INFO     Informed scheduler that task   MakeDataSet__99914b932b   has status   DONE\n",
      "2019-04-09 20:43:33,004 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 20:43:33,004 luigi-interface DEBUG    Pending tasks: 3\n",
      "2019-04-09 20:43:33,004 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) running   TrainVAE()\n",
      "2019-04-09 20:43:33,006 root         INFO     --Dataset tensor: (10000, 1)\n",
      "2019-04-09 20:43:33,006 root         INFO     -- Train tensor: (8000, 1)\n",
      "2019-04-09 20:43:33,007 root         INFO     Values of VAE's decoder parameters before training:\n",
      "2019-04-09 20:43:33,007 root         INFO     layers.0.weight\n",
      "2019-04-09 20:43:33,007 root         INFO     tensor([[0.9843]], device='cuda:0')\n",
      "2019-04-09 20:43:33,064 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 0.143113\n",
      "Reconstruction: 0.111874, Regularization: 0.031239\n",
      "2019-04-09 20:43:33,090 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 0.086073\n",
      "Reconstruction: 0.068759, Regularization: 0.017313\n",
      "2019-04-09 20:43:33,116 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 0.119782\n",
      "Reconstruction: 0.093426, Regularization: 0.026356\n",
      "2019-04-09 20:43:33,143 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 0.104063\n",
      "Reconstruction: 0.082816, Regularization: 0.021247\n",
      "2019-04-09 20:43:33,169 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 0.122470\n",
      "Reconstruction: 0.095654, Regularization: 0.026816\n",
      "2019-04-09 20:43:33,195 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 0.107716\n",
      "Reconstruction: 0.085178, Regularization: 0.022538\n",
      "2019-04-09 20:43:33,221 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 0.124466\n",
      "Reconstruction: 0.097871, Regularization: 0.026595\n",
      "2019-04-09 20:43:33,246 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 0.112226\n",
      "Reconstruction: 0.088852, Regularization: 0.023374\n",
      "2019-04-09 20:43:33,284 root         INFO     ====> Epoch: 0 Average loss: 0.1192\n",
      "2019-04-09 20:43:33,306 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 0.121119\n",
      "Reconstruction: 0.095526, Regularization: 0.025594\n",
      "2019-04-09 20:43:33,333 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 0.128738\n",
      "Reconstruction: 0.100717, Regularization: 0.028022\n",
      "2019-04-09 20:43:33,360 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 0.129123\n",
      "Reconstruction: 0.102360, Regularization: 0.026763\n",
      "2019-04-09 20:43:33,387 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 0.129338\n",
      "Reconstruction: 0.101829, Regularization: 0.027508\n",
      "2019-04-09 20:43:33,414 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 0.115296\n",
      "Reconstruction: 0.089340, Regularization: 0.025956\n",
      "2019-04-09 20:43:33,442 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 0.103050\n",
      "Reconstruction: 0.079963, Regularization: 0.023088\n",
      "2019-04-09 20:43:33,468 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 0.117097\n",
      "Reconstruction: 0.090895, Regularization: 0.026202\n",
      "2019-04-09 20:43:33,495 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 0.134582\n",
      "Reconstruction: 0.105552, Regularization: 0.029030\n",
      "2019-04-09 20:43:33,533 root         INFO     ====> Epoch: 1 Average loss: 0.1157\n",
      "2019-04-09 20:43:33,555 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 0.091388\n",
      "Reconstruction: 0.073079, Regularization: 0.018309\n",
      "2019-04-09 20:43:33,582 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 0.131784\n",
      "Reconstruction: 0.101614, Regularization: 0.030170\n",
      "2019-04-09 20:43:33,610 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 0.133483\n",
      "Reconstruction: 0.104337, Regularization: 0.029146\n",
      "2019-04-09 20:43:33,640 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 0.116499\n",
      "Reconstruction: 0.091024, Regularization: 0.025475\n",
      "2019-04-09 20:43:33,669 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 0.136757\n",
      "Reconstruction: 0.106304, Regularization: 0.030453\n",
      "2019-04-09 20:43:33,698 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 0.104426\n",
      "Reconstruction: 0.081701, Regularization: 0.022725\n",
      "2019-04-09 20:43:33,727 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 0.114189\n",
      "Reconstruction: 0.090864, Regularization: 0.023325\n",
      "2019-04-09 20:43:33,757 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 0.092408\n",
      "Reconstruction: 0.073768, Regularization: 0.018640\n",
      "2019-04-09 20:43:33,797 root         INFO     ====> Epoch: 2 Average loss: 0.1138\n",
      "2019-04-09 20:43:33,818 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 0.094357\n",
      "Reconstruction: 0.073235, Regularization: 0.021122\n",
      "2019-04-09 20:43:33,846 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 0.102295\n",
      "Reconstruction: 0.081409, Regularization: 0.020886\n",
      "2019-04-09 20:43:33,873 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 0.104147\n",
      "Reconstruction: 0.082682, Regularization: 0.021465\n",
      "2019-04-09 20:43:33,900 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 0.099068\n",
      "Reconstruction: 0.078090, Regularization: 0.020978\n",
      "2019-04-09 20:43:33,927 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 0.124678\n",
      "Reconstruction: 0.096491, Regularization: 0.028187\n",
      "2019-04-09 20:43:33,955 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 0.123925\n",
      "Reconstruction: 0.098221, Regularization: 0.025704\n",
      "2019-04-09 20:43:33,982 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 0.093572\n",
      "Reconstruction: 0.073734, Regularization: 0.019838\n",
      "2019-04-09 20:43:34,009 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 0.102098\n",
      "Reconstruction: 0.082144, Regularization: 0.019954\n",
      "2019-04-09 20:43:34,046 root         INFO     ====> Epoch: 3 Average loss: 0.1118\n",
      "2019-04-09 20:43:34,067 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 0.108173\n",
      "Reconstruction: 0.085282, Regularization: 0.022891\n",
      "2019-04-09 20:43:34,094 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 0.116430\n",
      "Reconstruction: 0.092072, Regularization: 0.024358\n",
      "2019-04-09 20:43:34,121 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 0.101917\n",
      "Reconstruction: 0.081432, Regularization: 0.020485\n",
      "2019-04-09 20:43:34,148 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 0.087024\n",
      "Reconstruction: 0.068988, Regularization: 0.018036\n",
      "2019-04-09 20:43:34,175 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 0.123969\n",
      "Reconstruction: 0.098118, Regularization: 0.025851\n",
      "2019-04-09 20:43:34,202 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 0.111509\n",
      "Reconstruction: 0.086611, Regularization: 0.024898\n",
      "2019-04-09 20:43:34,229 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 0.102699\n",
      "Reconstruction: 0.082108, Regularization: 0.020591\n",
      "2019-04-09 20:43:34,257 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 0.089395\n",
      "Reconstruction: 0.071534, Regularization: 0.017861\n",
      "2019-04-09 20:43:34,295 root         INFO     ====> Epoch: 4 Average loss: 0.1093\n",
      "2019-04-09 20:43:34,317 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 0.121246\n",
      "Reconstruction: 0.096093, Regularization: 0.025153\n",
      "2019-04-09 20:43:34,344 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 0.090817\n",
      "Reconstruction: 0.072246, Regularization: 0.018571\n",
      "2019-04-09 20:43:34,371 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 0.107512\n",
      "Reconstruction: 0.085399, Regularization: 0.022113\n",
      "2019-04-09 20:43:34,399 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 0.116574\n",
      "Reconstruction: 0.092925, Regularization: 0.023649\n",
      "2019-04-09 20:43:34,426 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 0.087916\n",
      "Reconstruction: 0.070981, Regularization: 0.016935\n",
      "2019-04-09 20:43:34,454 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 0.118471\n",
      "Reconstruction: 0.094306, Regularization: 0.024165\n",
      "2019-04-09 20:43:34,481 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 0.078050\n",
      "Reconstruction: 0.063052, Regularization: 0.014998\n",
      "2019-04-09 20:43:34,507 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 0.105228\n",
      "Reconstruction: 0.084380, Regularization: 0.020848\n",
      "2019-04-09 20:43:34,545 root         INFO     ====> Epoch: 5 Average loss: 0.1065\n",
      "2019-04-09 20:43:34,566 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 0.087810\n",
      "Reconstruction: 0.069627, Regularization: 0.018183\n",
      "2019-04-09 20:43:34,593 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 0.117592\n",
      "Reconstruction: 0.093556, Regularization: 0.024036\n",
      "2019-04-09 20:43:34,620 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 0.077602\n",
      "Reconstruction: 0.061684, Regularization: 0.015918\n",
      "2019-04-09 20:43:34,648 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 0.077849\n",
      "Reconstruction: 0.062272, Regularization: 0.015577\n",
      "2019-04-09 20:43:34,675 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 0.106479\n",
      "Reconstruction: 0.084898, Regularization: 0.021581\n",
      "2019-04-09 20:43:34,702 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 0.093098\n",
      "Reconstruction: 0.074561, Regularization: 0.018537\n",
      "2019-04-09 20:43:34,728 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 0.104046\n",
      "Reconstruction: 0.082784, Regularization: 0.021261\n",
      "2019-04-09 20:43:34,754 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 0.084027\n",
      "Reconstruction: 0.067921, Regularization: 0.016106\n",
      "2019-04-09 20:43:34,791 root         INFO     ====> Epoch: 6 Average loss: 0.1050\n",
      "2019-04-09 20:43:34,812 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 0.084186\n",
      "Reconstruction: 0.067248, Regularization: 0.016937\n",
      "2019-04-09 20:43:34,838 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 0.111053\n",
      "Reconstruction: 0.087495, Regularization: 0.023558\n",
      "2019-04-09 20:43:34,866 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 0.101025\n",
      "Reconstruction: 0.080713, Regularization: 0.020312\n",
      "2019-04-09 20:43:34,893 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 0.137743\n",
      "Reconstruction: 0.109308, Regularization: 0.028435\n",
      "2019-04-09 20:43:34,921 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 0.104566\n",
      "Reconstruction: 0.083250, Regularization: 0.021316\n",
      "2019-04-09 20:43:34,948 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 0.124386\n",
      "Reconstruction: 0.100268, Regularization: 0.024118\n",
      "2019-04-09 20:43:34,975 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 0.082989\n",
      "Reconstruction: 0.066022, Regularization: 0.016968\n",
      "2019-04-09 20:43:35,003 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 0.077630\n",
      "Reconstruction: 0.063224, Regularization: 0.014406\n",
      "2019-04-09 20:43:35,041 root         INFO     ====> Epoch: 7 Average loss: 0.1029\n",
      "2019-04-09 20:43:35,062 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 0.091930\n",
      "Reconstruction: 0.074055, Regularization: 0.017875\n",
      "2019-04-09 20:43:35,090 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 0.091458\n",
      "Reconstruction: 0.074267, Regularization: 0.017190\n",
      "2019-04-09 20:43:35,117 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 0.138804\n",
      "Reconstruction: 0.109707, Regularization: 0.029097\n",
      "2019-04-09 20:43:35,144 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 0.130547\n",
      "Reconstruction: 0.103344, Regularization: 0.027203\n",
      "2019-04-09 20:43:35,170 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 0.084247\n",
      "Reconstruction: 0.068224, Regularization: 0.016023\n",
      "2019-04-09 20:43:35,197 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 0.114507\n",
      "Reconstruction: 0.091597, Regularization: 0.022911\n",
      "2019-04-09 20:43:35,224 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 0.107422\n",
      "Reconstruction: 0.085236, Regularization: 0.022186\n",
      "2019-04-09 20:43:35,252 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 0.101115\n",
      "Reconstruction: 0.081371, Regularization: 0.019744\n",
      "2019-04-09 20:43:35,290 root         INFO     ====> Epoch: 8 Average loss: 0.1008\n",
      "2019-04-09 20:43:35,311 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 0.104324\n",
      "Reconstruction: 0.083577, Regularization: 0.020747\n",
      "2019-04-09 20:43:35,336 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 0.096223\n",
      "Reconstruction: 0.077114, Regularization: 0.019109\n",
      "2019-04-09 20:43:35,361 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 0.087821\n",
      "Reconstruction: 0.070621, Regularization: 0.017199\n",
      "2019-04-09 20:43:35,386 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 0.088269\n",
      "Reconstruction: 0.071339, Regularization: 0.016931\n",
      "2019-04-09 20:43:35,411 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 0.086726\n",
      "Reconstruction: 0.069221, Regularization: 0.017506\n",
      "2019-04-09 20:43:35,436 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 0.113033\n",
      "Reconstruction: 0.090742, Regularization: 0.022291\n",
      "2019-04-09 20:43:35,461 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 0.112149\n",
      "Reconstruction: 0.090107, Regularization: 0.022042\n",
      "2019-04-09 20:43:35,486 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 0.084682\n",
      "Reconstruction: 0.069031, Regularization: 0.015652\n",
      "2019-04-09 20:43:35,523 root         INFO     ====> Epoch: 9 Average loss: 0.0988\n",
      "2019-04-09 20:43:35,544 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 0.087294\n",
      "Reconstruction: 0.070752, Regularization: 0.016542\n",
      "2019-04-09 20:43:35,571 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 0.086872\n",
      "Reconstruction: 0.070351, Regularization: 0.016520\n",
      "2019-04-09 20:43:35,598 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 0.086476\n",
      "Reconstruction: 0.070368, Regularization: 0.016107\n",
      "2019-04-09 20:43:35,626 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 0.102736\n",
      "Reconstruction: 0.081979, Regularization: 0.020757\n",
      "2019-04-09 20:43:35,653 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 0.091722\n",
      "Reconstruction: 0.074691, Regularization: 0.017031\n",
      "2019-04-09 20:43:35,680 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 0.085702\n",
      "Reconstruction: 0.069538, Regularization: 0.016165\n",
      "2019-04-09 20:43:35,707 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 0.079470\n",
      "Reconstruction: 0.064884, Regularization: 0.014587\n",
      "2019-04-09 20:43:35,734 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 0.078421\n",
      "Reconstruction: 0.063657, Regularization: 0.014764\n",
      "2019-04-09 20:43:35,772 root         INFO     ====> Epoch: 10 Average loss: 0.0969\n",
      "2019-04-09 20:43:35,793 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.090095\n",
      "Reconstruction: 0.072507, Regularization: 0.017588\n",
      "2019-04-09 20:43:35,820 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 0.087805\n",
      "Reconstruction: 0.070823, Regularization: 0.016982\n",
      "2019-04-09 20:43:35,848 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.102506\n",
      "Reconstruction: 0.082202, Regularization: 0.020303\n",
      "2019-04-09 20:43:35,875 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 0.146445\n",
      "Reconstruction: 0.116475, Regularization: 0.029970\n",
      "2019-04-09 20:43:35,902 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 0.089261\n",
      "Reconstruction: 0.071845, Regularization: 0.017416\n",
      "2019-04-09 20:43:35,930 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 0.099277\n",
      "Reconstruction: 0.079760, Regularization: 0.019517\n",
      "2019-04-09 20:43:35,957 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.084531\n",
      "Reconstruction: 0.068625, Regularization: 0.015906\n",
      "2019-04-09 20:43:35,984 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 0.084892\n",
      "Reconstruction: 0.069328, Regularization: 0.015564\n",
      "2019-04-09 20:43:36,022 root         INFO     ====> Epoch: 11 Average loss: 0.0952\n",
      "2019-04-09 20:43:36,043 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 0.088853\n",
      "Reconstruction: 0.072176, Regularization: 0.016678\n",
      "2019-04-09 20:43:36,070 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 0.114926\n",
      "Reconstruction: 0.092408, Regularization: 0.022517\n",
      "2019-04-09 20:43:36,096 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 0.100323\n",
      "Reconstruction: 0.081616, Regularization: 0.018708\n",
      "2019-04-09 20:43:36,122 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 0.083775\n",
      "Reconstruction: 0.068622, Regularization: 0.015153\n",
      "2019-04-09 20:43:36,148 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 0.114519\n",
      "Reconstruction: 0.091961, Regularization: 0.022557\n",
      "2019-04-09 20:43:36,174 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.090872\n",
      "Reconstruction: 0.073714, Regularization: 0.017158\n",
      "2019-04-09 20:43:36,200 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.073561\n",
      "Reconstruction: 0.061296, Regularization: 0.012265\n",
      "2019-04-09 20:43:36,225 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 0.099856\n",
      "Reconstruction: 0.081273, Regularization: 0.018584\n",
      "2019-04-09 20:43:36,263 root         INFO     ====> Epoch: 12 Average loss: 0.0933\n",
      "2019-04-09 20:43:36,284 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 0.076596\n",
      "Reconstruction: 0.063413, Regularization: 0.013184\n",
      "2019-04-09 20:43:36,312 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 0.084473\n",
      "Reconstruction: 0.069197, Regularization: 0.015276\n",
      "2019-04-09 20:43:36,339 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 0.113973\n",
      "Reconstruction: 0.091801, Regularization: 0.022171\n",
      "2019-04-09 20:43:36,367 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 0.097616\n",
      "Reconstruction: 0.078827, Regularization: 0.018789\n",
      "2019-04-09 20:43:36,394 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 0.114320\n",
      "Reconstruction: 0.092423, Regularization: 0.021897\n",
      "2019-04-09 20:43:36,421 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 0.106722\n",
      "Reconstruction: 0.085788, Regularization: 0.020934\n",
      "2019-04-09 20:43:36,448 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 0.088348\n",
      "Reconstruction: 0.071363, Regularization: 0.016984\n",
      "2019-04-09 20:43:36,475 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 0.082466\n",
      "Reconstruction: 0.067096, Regularization: 0.015370\n",
      "2019-04-09 20:43:36,513 root         INFO     ====> Epoch: 13 Average loss: 0.0913\n",
      "2019-04-09 20:43:36,534 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.074063\n",
      "Reconstruction: 0.061542, Regularization: 0.012521\n",
      "2019-04-09 20:43:36,561 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.085444\n",
      "Reconstruction: 0.070799, Regularization: 0.014645\n",
      "2019-04-09 20:43:36,588 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 0.104169\n",
      "Reconstruction: 0.084607, Regularization: 0.019561\n",
      "2019-04-09 20:43:36,615 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.072497\n",
      "Reconstruction: 0.059965, Regularization: 0.012532\n",
      "2019-04-09 20:43:36,642 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.084897\n",
      "Reconstruction: 0.069490, Regularization: 0.015407\n",
      "2019-04-09 20:43:36,668 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 0.102656\n",
      "Reconstruction: 0.083405, Regularization: 0.019251\n",
      "2019-04-09 20:43:36,694 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.090474\n",
      "Reconstruction: 0.073891, Regularization: 0.016582\n",
      "2019-04-09 20:43:36,719 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.117014\n",
      "Reconstruction: 0.094383, Regularization: 0.022630\n",
      "2019-04-09 20:43:36,757 root         INFO     ====> Epoch: 14 Average loss: 0.0901\n",
      "2019-04-09 20:43:36,778 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 0.103261\n",
      "Reconstruction: 0.083932, Regularization: 0.019329\n",
      "2019-04-09 20:43:36,805 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 0.102733\n",
      "Reconstruction: 0.083671, Regularization: 0.019062\n",
      "2019-04-09 20:43:36,832 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.092465\n",
      "Reconstruction: 0.075777, Regularization: 0.016688\n",
      "2019-04-09 20:43:36,857 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.101808\n",
      "Reconstruction: 0.083017, Regularization: 0.018791\n",
      "2019-04-09 20:43:36,884 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.078647\n",
      "Reconstruction: 0.064993, Regularization: 0.013654\n",
      "2019-04-09 20:43:36,910 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.090887\n",
      "Reconstruction: 0.074479, Regularization: 0.016408\n",
      "2019-04-09 20:43:36,937 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.080443\n",
      "Reconstruction: 0.065503, Regularization: 0.014940\n",
      "2019-04-09 20:43:36,964 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 0.054522\n",
      "Reconstruction: 0.045737, Regularization: 0.008785\n",
      "2019-04-09 20:43:37,002 root         INFO     ====> Epoch: 15 Average loss: 0.0882\n",
      "2019-04-09 20:43:37,023 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 0.070046\n",
      "Reconstruction: 0.058126, Regularization: 0.011921\n",
      "2019-04-09 20:43:37,049 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 0.072569\n",
      "Reconstruction: 0.059962, Regularization: 0.012607\n",
      "2019-04-09 20:43:37,075 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.076244\n",
      "Reconstruction: 0.062893, Regularization: 0.013351\n",
      "2019-04-09 20:43:37,101 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 0.068663\n",
      "Reconstruction: 0.057019, Regularization: 0.011644\n",
      "2019-04-09 20:43:37,128 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 0.073743\n",
      "Reconstruction: 0.060790, Regularization: 0.012954\n",
      "2019-04-09 20:43:37,156 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 0.057911\n",
      "Reconstruction: 0.048428, Regularization: 0.009484\n",
      "2019-04-09 20:43:37,182 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 0.069919\n",
      "Reconstruction: 0.057406, Regularization: 0.012513\n",
      "2019-04-09 20:43:37,208 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.087642\n",
      "Reconstruction: 0.072011, Regularization: 0.015632\n",
      "2019-04-09 20:43:37,245 root         INFO     ====> Epoch: 16 Average loss: 0.0867\n",
      "2019-04-09 20:43:37,266 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.092886\n",
      "Reconstruction: 0.075983, Regularization: 0.016903\n",
      "2019-04-09 20:43:37,292 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 0.070512\n",
      "Reconstruction: 0.058203, Regularization: 0.012309\n",
      "2019-04-09 20:43:37,317 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.094380\n",
      "Reconstruction: 0.077890, Regularization: 0.016490\n",
      "2019-04-09 20:43:37,343 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 0.082515\n",
      "Reconstruction: 0.068470, Regularization: 0.014046\n",
      "2019-04-09 20:43:37,370 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.071002\n",
      "Reconstruction: 0.059440, Regularization: 0.011562\n",
      "2019-04-09 20:43:37,396 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 0.101649\n",
      "Reconstruction: 0.084338, Regularization: 0.017310\n",
      "2019-04-09 20:43:37,421 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 0.091980\n",
      "Reconstruction: 0.076105, Regularization: 0.015874\n",
      "2019-04-09 20:43:37,447 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 0.075350\n",
      "Reconstruction: 0.062296, Regularization: 0.013054\n",
      "2019-04-09 20:43:37,484 root         INFO     ====> Epoch: 17 Average loss: 0.0854\n",
      "2019-04-09 20:43:37,505 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 0.061680\n",
      "Reconstruction: 0.052227, Regularization: 0.009453\n",
      "2019-04-09 20:43:37,532 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.095234\n",
      "Reconstruction: 0.078458, Regularization: 0.016776\n",
      "2019-04-09 20:43:37,559 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 0.093446\n",
      "Reconstruction: 0.077172, Regularization: 0.016274\n",
      "2019-04-09 20:43:37,586 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.094657\n",
      "Reconstruction: 0.079060, Regularization: 0.015597\n",
      "2019-04-09 20:43:37,613 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 0.101334\n",
      "Reconstruction: 0.082657, Regularization: 0.018677\n",
      "2019-04-09 20:43:37,639 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.081240\n",
      "Reconstruction: 0.066804, Regularization: 0.014436\n",
      "2019-04-09 20:43:37,666 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 0.080795\n",
      "Reconstruction: 0.066572, Regularization: 0.014223\n",
      "2019-04-09 20:43:37,693 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 0.088018\n",
      "Reconstruction: 0.072165, Regularization: 0.015853\n",
      "2019-04-09 20:43:37,731 root         INFO     ====> Epoch: 18 Average loss: 0.0839\n",
      "2019-04-09 20:43:37,753 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 0.075797\n",
      "Reconstruction: 0.063262, Regularization: 0.012535\n",
      "2019-04-09 20:43:37,780 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 0.071749\n",
      "Reconstruction: 0.060298, Regularization: 0.011451\n",
      "2019-04-09 20:43:37,806 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 0.078067\n",
      "Reconstruction: 0.064933, Regularization: 0.013134\n",
      "2019-04-09 20:43:37,833 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 0.087170\n",
      "Reconstruction: 0.072094, Regularization: 0.015076\n",
      "2019-04-09 20:43:37,860 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 0.085230\n",
      "Reconstruction: 0.070839, Regularization: 0.014391\n",
      "2019-04-09 20:43:37,887 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 0.086966\n",
      "Reconstruction: 0.072285, Regularization: 0.014681\n",
      "2019-04-09 20:43:37,914 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 0.081238\n",
      "Reconstruction: 0.067166, Regularization: 0.014072\n",
      "2019-04-09 20:43:37,940 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.098832\n",
      "Reconstruction: 0.081317, Regularization: 0.017515\n",
      "2019-04-09 20:43:37,978 root         INFO     ====> Epoch: 19 Average loss: 0.0827\n",
      "2019-04-09 20:43:37,999 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 0.075317\n",
      "Reconstruction: 0.063001, Regularization: 0.012316\n",
      "2019-04-09 20:43:38,026 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 0.086279\n",
      "Reconstruction: 0.071863, Regularization: 0.014416\n",
      "2019-04-09 20:43:38,053 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 0.070771\n",
      "Reconstruction: 0.059860, Regularization: 0.010911\n",
      "2019-04-09 20:43:38,080 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 0.088181\n",
      "Reconstruction: 0.073115, Regularization: 0.015067\n",
      "2019-04-09 20:43:38,107 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 0.081508\n",
      "Reconstruction: 0.068158, Regularization: 0.013350\n",
      "2019-04-09 20:43:38,134 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 0.081416\n",
      "Reconstruction: 0.067427, Regularization: 0.013989\n",
      "2019-04-09 20:43:38,160 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 0.086913\n",
      "Reconstruction: 0.072281, Regularization: 0.014633\n",
      "2019-04-09 20:43:38,187 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 0.069705\n",
      "Reconstruction: 0.058505, Regularization: 0.011199\n",
      "2019-04-09 20:43:38,225 root         INFO     ====> Epoch: 20 Average loss: 0.0813\n",
      "2019-04-09 20:43:38,246 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.066612\n",
      "Reconstruction: 0.056279, Regularization: 0.010333\n",
      "2019-04-09 20:43:38,272 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 0.112903\n",
      "Reconstruction: 0.093163, Regularization: 0.019740\n",
      "2019-04-09 20:43:38,298 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 0.078872\n",
      "Reconstruction: 0.066133, Regularization: 0.012739\n",
      "2019-04-09 20:43:38,325 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 0.114042\n",
      "Reconstruction: 0.093947, Regularization: 0.020095\n",
      "2019-04-09 20:43:38,352 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.083688\n",
      "Reconstruction: 0.070097, Regularization: 0.013591\n",
      "2019-04-09 20:43:38,380 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 0.093261\n",
      "Reconstruction: 0.077363, Regularization: 0.015898\n",
      "2019-04-09 20:43:38,407 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 0.098732\n",
      "Reconstruction: 0.081870, Regularization: 0.016863\n",
      "2019-04-09 20:43:38,435 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.085565\n",
      "Reconstruction: 0.071360, Regularization: 0.014205\n",
      "2019-04-09 20:43:38,473 root         INFO     ====> Epoch: 21 Average loss: 0.0797\n",
      "2019-04-09 20:43:38,494 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 0.078047\n",
      "Reconstruction: 0.066166, Regularization: 0.011881\n",
      "2019-04-09 20:43:38,522 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 0.081577\n",
      "Reconstruction: 0.068189, Regularization: 0.013387\n",
      "2019-04-09 20:43:38,549 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 0.082650\n",
      "Reconstruction: 0.069633, Regularization: 0.013016\n",
      "2019-04-09 20:43:38,576 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 0.085678\n",
      "Reconstruction: 0.071259, Regularization: 0.014419\n",
      "2019-04-09 20:43:38,603 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.071681\n",
      "Reconstruction: 0.060336, Regularization: 0.011345\n",
      "2019-04-09 20:43:38,630 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 0.066190\n",
      "Reconstruction: 0.056000, Regularization: 0.010190\n",
      "2019-04-09 20:43:38,658 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 0.071060\n",
      "Reconstruction: 0.059682, Regularization: 0.011378\n",
      "2019-04-09 20:43:38,685 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 0.069309\n",
      "Reconstruction: 0.058892, Regularization: 0.010417\n",
      "2019-04-09 20:43:38,723 root         INFO     ====> Epoch: 22 Average loss: 0.0788\n",
      "2019-04-09 20:43:38,744 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 0.068900\n",
      "Reconstruction: 0.058262, Regularization: 0.010639\n",
      "2019-04-09 20:43:38,770 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 0.049807\n",
      "Reconstruction: 0.042996, Regularization: 0.006810\n",
      "2019-04-09 20:43:38,798 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 0.085919\n",
      "Reconstruction: 0.071283, Regularization: 0.014636\n",
      "2019-04-09 20:43:38,825 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 0.068543\n",
      "Reconstruction: 0.058435, Regularization: 0.010108\n",
      "2019-04-09 20:43:38,852 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 0.079541\n",
      "Reconstruction: 0.066690, Regularization: 0.012851\n",
      "2019-04-09 20:43:38,880 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 0.081710\n",
      "Reconstruction: 0.069070, Regularization: 0.012641\n",
      "2019-04-09 20:43:38,907 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 0.080158\n",
      "Reconstruction: 0.067526, Regularization: 0.012632\n",
      "2019-04-09 20:43:38,934 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 0.069336\n",
      "Reconstruction: 0.058948, Regularization: 0.010388\n",
      "2019-04-09 20:43:38,972 root         INFO     ====> Epoch: 23 Average loss: 0.0771\n",
      "2019-04-09 20:43:38,993 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.064238\n",
      "Reconstruction: 0.054679, Regularization: 0.009559\n",
      "2019-04-09 20:43:39,021 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 0.065220\n",
      "Reconstruction: 0.055234, Regularization: 0.009986\n",
      "2019-04-09 20:43:39,049 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 0.067647\n",
      "Reconstruction: 0.057425, Regularization: 0.010222\n",
      "2019-04-09 20:43:39,076 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 0.076995\n",
      "Reconstruction: 0.064799, Regularization: 0.012196\n",
      "2019-04-09 20:43:39,103 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 0.067878\n",
      "Reconstruction: 0.057417, Regularization: 0.010462\n",
      "2019-04-09 20:43:39,131 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 0.081014\n",
      "Reconstruction: 0.068582, Regularization: 0.012432\n",
      "2019-04-09 20:43:39,158 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 0.068459\n",
      "Reconstruction: 0.058428, Regularization: 0.010031\n",
      "2019-04-09 20:43:39,184 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 0.074672\n",
      "Reconstruction: 0.063328, Regularization: 0.011344\n",
      "2019-04-09 20:43:39,222 root         INFO     ====> Epoch: 24 Average loss: 0.0760\n",
      "2019-04-09 20:43:39,243 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 0.072635\n",
      "Reconstruction: 0.061639, Regularization: 0.010996\n",
      "2019-04-09 20:43:39,271 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 0.079124\n",
      "Reconstruction: 0.067225, Regularization: 0.011899\n",
      "2019-04-09 20:43:39,297 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 0.071802\n",
      "Reconstruction: 0.060991, Regularization: 0.010811\n",
      "2019-04-09 20:43:39,323 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 0.085594\n",
      "Reconstruction: 0.072222, Regularization: 0.013372\n",
      "2019-04-09 20:43:39,349 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 0.063830\n",
      "Reconstruction: 0.054806, Regularization: 0.009024\n",
      "2019-04-09 20:43:39,376 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 0.073275\n",
      "Reconstruction: 0.062397, Regularization: 0.010878\n",
      "2019-04-09 20:43:39,402 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.071487\n",
      "Reconstruction: 0.061110, Regularization: 0.010377\n",
      "2019-04-09 20:43:39,428 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 0.063799\n",
      "Reconstruction: 0.054879, Regularization: 0.008920\n",
      "2019-04-09 20:43:39,465 root         INFO     ====> Epoch: 25 Average loss: 0.0750\n",
      "2019-04-09 20:43:39,486 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 0.084621\n",
      "Reconstruction: 0.071613, Regularization: 0.013008\n",
      "2019-04-09 20:43:39,513 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 0.066701\n",
      "Reconstruction: 0.057082, Regularization: 0.009618\n",
      "2019-04-09 20:43:39,540 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 0.082649\n",
      "Reconstruction: 0.070110, Regularization: 0.012538\n",
      "2019-04-09 20:43:39,567 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 0.084155\n",
      "Reconstruction: 0.071403, Regularization: 0.012752\n",
      "2019-04-09 20:43:39,594 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.068733\n",
      "Reconstruction: 0.058840, Regularization: 0.009893\n",
      "2019-04-09 20:43:39,621 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 0.066031\n",
      "Reconstruction: 0.056590, Regularization: 0.009441\n",
      "2019-04-09 20:43:39,648 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 0.063497\n",
      "Reconstruction: 0.054433, Regularization: 0.009063\n",
      "2019-04-09 20:43:39,675 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 0.057039\n",
      "Reconstruction: 0.049005, Regularization: 0.008034\n",
      "2019-04-09 20:43:39,713 root         INFO     ====> Epoch: 26 Average loss: 0.0739\n",
      "2019-04-09 20:43:39,735 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 0.079334\n",
      "Reconstruction: 0.067595, Regularization: 0.011740\n",
      "2019-04-09 20:43:39,762 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.074280\n",
      "Reconstruction: 0.063705, Regularization: 0.010575\n",
      "2019-04-09 20:43:39,788 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 0.080647\n",
      "Reconstruction: 0.068835, Regularization: 0.011812\n",
      "2019-04-09 20:43:39,816 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.075224\n",
      "Reconstruction: 0.064372, Regularization: 0.010852\n",
      "2019-04-09 20:43:39,842 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 0.082353\n",
      "Reconstruction: 0.070289, Regularization: 0.012064\n",
      "2019-04-09 20:43:39,869 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.053894\n",
      "Reconstruction: 0.046602, Regularization: 0.007292\n",
      "2019-04-09 20:43:39,896 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.089844\n",
      "Reconstruction: 0.076355, Regularization: 0.013489\n",
      "2019-04-09 20:43:39,923 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 0.091804\n",
      "Reconstruction: 0.077396, Regularization: 0.014408\n",
      "2019-04-09 20:43:39,961 root         INFO     ====> Epoch: 27 Average loss: 0.0727\n",
      "2019-04-09 20:43:39,982 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.058917\n",
      "Reconstruction: 0.050973, Regularization: 0.007944\n",
      "2019-04-09 20:43:40,009 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.080638\n",
      "Reconstruction: 0.068719, Regularization: 0.011919\n",
      "2019-04-09 20:43:40,035 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 0.081879\n",
      "Reconstruction: 0.069808, Regularization: 0.012071\n",
      "2019-04-09 20:43:40,062 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.066482\n",
      "Reconstruction: 0.057311, Regularization: 0.009170\n",
      "2019-04-09 20:43:40,089 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.055385\n",
      "Reconstruction: 0.048185, Regularization: 0.007200\n",
      "2019-04-09 20:43:40,116 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.071395\n",
      "Reconstruction: 0.061331, Regularization: 0.010064\n",
      "2019-04-09 20:43:40,142 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.071969\n",
      "Reconstruction: 0.061777, Regularization: 0.010192\n",
      "2019-04-09 20:43:40,167 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.063867\n",
      "Reconstruction: 0.055113, Regularization: 0.008754\n",
      "2019-04-09 20:43:40,204 root         INFO     ====> Epoch: 28 Average loss: 0.0718\n",
      "2019-04-09 20:43:40,225 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 0.071794\n",
      "Reconstruction: 0.061488, Regularization: 0.010307\n",
      "2019-04-09 20:43:40,252 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 0.065204\n",
      "Reconstruction: 0.056413, Regularization: 0.008790\n",
      "2019-04-09 20:43:40,279 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 0.063980\n",
      "Reconstruction: 0.055508, Regularization: 0.008472\n",
      "2019-04-09 20:43:40,305 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 0.078192\n",
      "Reconstruction: 0.067342, Regularization: 0.010850\n",
      "2019-04-09 20:43:40,332 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.068613\n",
      "Reconstruction: 0.059224, Regularization: 0.009389\n",
      "2019-04-09 20:43:40,359 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 0.068598\n",
      "Reconstruction: 0.059171, Regularization: 0.009426\n",
      "2019-04-09 20:43:40,386 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 0.057373\n",
      "Reconstruction: 0.049958, Regularization: 0.007415\n",
      "2019-04-09 20:43:40,412 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.075203\n",
      "Reconstruction: 0.064657, Regularization: 0.010546\n",
      "2019-04-09 20:43:40,450 root         INFO     ====> Epoch: 29 Average loss: 0.0705\n",
      "2019-04-09 20:43:40,471 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.060234\n",
      "Reconstruction: 0.052478, Regularization: 0.007756\n",
      "2019-04-09 20:43:40,498 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.080096\n",
      "Reconstruction: 0.068927, Regularization: 0.011169\n",
      "2019-04-09 20:43:40,525 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.068557\n",
      "Reconstruction: 0.059059, Regularization: 0.009498\n",
      "2019-04-09 20:43:40,552 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.068209\n",
      "Reconstruction: 0.059145, Regularization: 0.009064\n",
      "2019-04-09 20:43:40,578 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.072987\n",
      "Reconstruction: 0.062996, Regularization: 0.009990\n",
      "2019-04-09 20:43:40,603 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.054521\n",
      "Reconstruction: 0.047597, Regularization: 0.006924\n",
      "2019-04-09 20:43:40,628 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.072696\n",
      "Reconstruction: 0.063221, Regularization: 0.009474\n",
      "2019-04-09 20:43:40,654 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 0.057621\n",
      "Reconstruction: 0.050192, Regularization: 0.007428\n",
      "2019-04-09 20:43:40,692 root         INFO     ====> Epoch: 30 Average loss: 0.0696\n",
      "2019-04-09 20:43:40,713 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.073049\n",
      "Reconstruction: 0.063172, Regularization: 0.009877\n",
      "2019-04-09 20:43:40,739 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.071313\n",
      "Reconstruction: 0.061955, Regularization: 0.009358\n",
      "2019-04-09 20:43:40,765 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 0.075825\n",
      "Reconstruction: 0.065729, Regularization: 0.010096\n",
      "2019-04-09 20:43:40,791 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.063698\n",
      "Reconstruction: 0.055397, Regularization: 0.008301\n",
      "2019-04-09 20:43:40,816 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.062717\n",
      "Reconstruction: 0.054745, Regularization: 0.007972\n",
      "2019-04-09 20:43:40,842 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.081076\n",
      "Reconstruction: 0.070083, Regularization: 0.010993\n",
      "2019-04-09 20:43:40,868 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 0.067297\n",
      "Reconstruction: 0.058739, Regularization: 0.008559\n",
      "2019-04-09 20:43:40,894 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 0.056071\n",
      "Reconstruction: 0.049212, Regularization: 0.006859\n",
      "2019-04-09 20:43:40,931 root         INFO     ====> Epoch: 31 Average loss: 0.0688\n",
      "2019-04-09 20:43:40,952 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.077322\n",
      "Reconstruction: 0.067110, Regularization: 0.010212\n",
      "2019-04-09 20:43:40,978 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.062801\n",
      "Reconstruction: 0.055003, Regularization: 0.007798\n",
      "2019-04-09 20:43:41,005 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.069763\n",
      "Reconstruction: 0.060834, Regularization: 0.008929\n",
      "2019-04-09 20:43:41,032 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.063801\n",
      "Reconstruction: 0.055742, Regularization: 0.008059\n",
      "2019-04-09 20:43:41,059 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.074912\n",
      "Reconstruction: 0.065119, Regularization: 0.009793\n",
      "2019-04-09 20:43:41,086 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 0.055881\n",
      "Reconstruction: 0.049186, Regularization: 0.006695\n",
      "2019-04-09 20:43:41,112 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.061226\n",
      "Reconstruction: 0.053876, Regularization: 0.007349\n",
      "2019-04-09 20:43:41,139 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.067866\n",
      "Reconstruction: 0.059143, Regularization: 0.008723\n",
      "2019-04-09 20:43:41,176 root         INFO     ====> Epoch: 32 Average loss: 0.0680\n",
      "2019-04-09 20:43:41,197 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.072690\n",
      "Reconstruction: 0.063409, Regularization: 0.009281\n",
      "2019-04-09 20:43:41,224 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.061879\n",
      "Reconstruction: 0.054378, Regularization: 0.007501\n",
      "2019-04-09 20:43:41,251 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.070509\n",
      "Reconstruction: 0.061657, Regularization: 0.008853\n",
      "2019-04-09 20:43:41,277 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.064355\n",
      "Reconstruction: 0.056333, Regularization: 0.008022\n",
      "2019-04-09 20:43:41,303 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 0.085023\n",
      "Reconstruction: 0.074206, Regularization: 0.010817\n",
      "2019-04-09 20:43:41,328 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.058561\n",
      "Reconstruction: 0.051766, Regularization: 0.006795\n",
      "2019-04-09 20:43:41,353 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 0.059689\n",
      "Reconstruction: 0.052583, Regularization: 0.007107\n",
      "2019-04-09 20:43:41,378 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.056491\n",
      "Reconstruction: 0.050088, Regularization: 0.006403\n",
      "2019-04-09 20:43:41,415 root         INFO     ====> Epoch: 33 Average loss: 0.0671\n",
      "2019-04-09 20:43:41,436 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.069377\n",
      "Reconstruction: 0.060671, Regularization: 0.008706\n",
      "2019-04-09 20:43:41,463 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.070567\n",
      "Reconstruction: 0.061809, Regularization: 0.008758\n",
      "2019-04-09 20:43:41,489 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.071972\n",
      "Reconstruction: 0.063024, Regularization: 0.008948\n",
      "2019-04-09 20:43:41,515 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.055206\n",
      "Reconstruction: 0.048964, Regularization: 0.006242\n",
      "2019-04-09 20:43:41,541 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.060902\n",
      "Reconstruction: 0.053791, Regularization: 0.007112\n",
      "2019-04-09 20:43:41,567 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.083648\n",
      "Reconstruction: 0.072792, Regularization: 0.010856\n",
      "2019-04-09 20:43:41,593 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.072025\n",
      "Reconstruction: 0.063364, Regularization: 0.008662\n",
      "2019-04-09 20:43:41,619 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 0.053616\n",
      "Reconstruction: 0.047664, Regularization: 0.005952\n",
      "2019-04-09 20:43:41,656 root         INFO     ====> Epoch: 34 Average loss: 0.0662\n",
      "2019-04-09 20:43:41,678 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.048494\n",
      "Reconstruction: 0.043235, Regularization: 0.005259\n",
      "2019-04-09 20:43:41,703 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.068727\n",
      "Reconstruction: 0.060382, Regularization: 0.008345\n",
      "2019-04-09 20:43:41,729 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.072756\n",
      "Reconstruction: 0.063919, Regularization: 0.008837\n",
      "2019-04-09 20:43:41,755 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.064751\n",
      "Reconstruction: 0.057271, Regularization: 0.007480\n",
      "2019-04-09 20:43:41,781 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.061942\n",
      "Reconstruction: 0.054844, Regularization: 0.007098\n",
      "2019-04-09 20:43:41,806 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.056294\n",
      "Reconstruction: 0.049868, Regularization: 0.006427\n",
      "2019-04-09 20:43:41,832 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.052961\n",
      "Reconstruction: 0.047135, Regularization: 0.005826\n",
      "2019-04-09 20:43:41,857 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.058542\n",
      "Reconstruction: 0.051900, Regularization: 0.006642\n",
      "2019-04-09 20:43:41,894 root         INFO     ====> Epoch: 35 Average loss: 0.0655\n",
      "2019-04-09 20:43:41,915 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 0.066353\n",
      "Reconstruction: 0.058684, Regularization: 0.007669\n",
      "2019-04-09 20:43:41,941 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.069297\n",
      "Reconstruction: 0.061162, Regularization: 0.008135\n",
      "2019-04-09 20:43:41,968 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.060746\n",
      "Reconstruction: 0.054017, Regularization: 0.006730\n",
      "2019-04-09 20:43:41,993 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.067819\n",
      "Reconstruction: 0.059983, Regularization: 0.007836\n",
      "2019-04-09 20:43:42,018 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.071285\n",
      "Reconstruction: 0.062965, Regularization: 0.008319\n",
      "2019-04-09 20:43:42,044 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.056232\n",
      "Reconstruction: 0.050158, Regularization: 0.006074\n",
      "2019-04-09 20:43:42,069 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 0.080474\n",
      "Reconstruction: 0.070954, Regularization: 0.009520\n",
      "2019-04-09 20:43:42,095 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.068006\n",
      "Reconstruction: 0.060163, Regularization: 0.007843\n",
      "2019-04-09 20:43:42,132 root         INFO     ====> Epoch: 36 Average loss: 0.0646\n",
      "2019-04-09 20:43:42,153 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.054346\n",
      "Reconstruction: 0.048527, Regularization: 0.005820\n",
      "2019-04-09 20:43:42,181 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.064852\n",
      "Reconstruction: 0.057690, Regularization: 0.007162\n",
      "2019-04-09 20:43:42,207 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.062529\n",
      "Reconstruction: 0.055703, Regularization: 0.006827\n",
      "2019-04-09 20:43:42,234 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 0.073943\n",
      "Reconstruction: 0.065486, Regularization: 0.008458\n",
      "2019-04-09 20:43:42,261 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.054787\n",
      "Reconstruction: 0.049085, Regularization: 0.005702\n",
      "2019-04-09 20:43:42,287 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.071641\n",
      "Reconstruction: 0.063521, Regularization: 0.008120\n",
      "2019-04-09 20:43:42,313 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.045466\n",
      "Reconstruction: 0.041137, Regularization: 0.004329\n",
      "2019-04-09 20:43:42,338 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.068670\n",
      "Reconstruction: 0.060959, Regularization: 0.007711\n",
      "2019-04-09 20:43:42,376 root         INFO     ====> Epoch: 37 Average loss: 0.0640\n",
      "2019-04-09 20:43:42,397 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.051011\n",
      "Reconstruction: 0.045944, Regularization: 0.005067\n",
      "2019-04-09 20:43:42,423 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.063762\n",
      "Reconstruction: 0.056818, Regularization: 0.006944\n",
      "2019-04-09 20:43:42,449 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.063897\n",
      "Reconstruction: 0.056896, Regularization: 0.007000\n",
      "2019-04-09 20:43:42,475 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 0.070673\n",
      "Reconstruction: 0.062928, Regularization: 0.007744\n",
      "2019-04-09 20:43:42,500 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.059932\n",
      "Reconstruction: 0.053633, Regularization: 0.006300\n",
      "2019-04-09 20:43:42,527 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.067339\n",
      "Reconstruction: 0.060006, Regularization: 0.007333\n",
      "2019-04-09 20:43:42,552 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.065198\n",
      "Reconstruction: 0.058232, Regularization: 0.006967\n",
      "2019-04-09 20:43:42,578 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.070051\n",
      "Reconstruction: 0.062498, Regularization: 0.007553\n",
      "2019-04-09 20:43:42,615 root         INFO     ====> Epoch: 38 Average loss: 0.0632\n",
      "2019-04-09 20:43:42,636 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 0.090452\n",
      "Reconstruction: 0.080105, Regularization: 0.010346\n",
      "2019-04-09 20:43:42,662 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.058973\n",
      "Reconstruction: 0.052927, Regularization: 0.006046\n",
      "2019-04-09 20:43:42,688 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.065589\n",
      "Reconstruction: 0.058735, Regularization: 0.006854\n",
      "2019-04-09 20:43:42,713 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.057128\n",
      "Reconstruction: 0.051332, Regularization: 0.005796\n",
      "2019-04-09 20:43:42,739 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.063295\n",
      "Reconstruction: 0.056741, Regularization: 0.006555\n",
      "2019-04-09 20:43:42,764 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.079683\n",
      "Reconstruction: 0.070751, Regularization: 0.008932\n",
      "2019-04-09 20:43:42,790 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.060244\n",
      "Reconstruction: 0.054092, Regularization: 0.006152\n",
      "2019-04-09 20:43:42,816 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.065968\n",
      "Reconstruction: 0.059082, Regularization: 0.006887\n",
      "2019-04-09 20:43:42,853 root         INFO     ====> Epoch: 39 Average loss: 0.0624\n",
      "2019-04-09 20:43:42,874 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.059678\n",
      "Reconstruction: 0.053709, Regularization: 0.005969\n",
      "2019-04-09 20:43:42,900 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.071823\n",
      "Reconstruction: 0.064337, Regularization: 0.007486\n",
      "2019-04-09 20:43:42,927 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.064177\n",
      "Reconstruction: 0.057710, Regularization: 0.006467\n",
      "2019-04-09 20:43:42,953 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.066140\n",
      "Reconstruction: 0.059295, Regularization: 0.006845\n",
      "2019-04-09 20:43:42,979 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.061348\n",
      "Reconstruction: 0.055147, Regularization: 0.006201\n",
      "2019-04-09 20:43:43,004 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 0.061322\n",
      "Reconstruction: 0.055279, Regularization: 0.006043\n",
      "2019-04-09 20:43:43,029 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.069433\n",
      "Reconstruction: 0.062284, Regularization: 0.007149\n",
      "2019-04-09 20:43:43,055 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.059969\n",
      "Reconstruction: 0.054143, Regularization: 0.005826\n",
      "2019-04-09 20:43:43,091 root         INFO     ====> Epoch: 40 Average loss: 0.0618\n",
      "2019-04-09 20:43:43,112 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 0.047497\n",
      "Reconstruction: 0.043262, Regularization: 0.004235\n",
      "2019-04-09 20:43:43,139 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.058776\n",
      "Reconstruction: 0.053119, Regularization: 0.005657\n",
      "2019-04-09 20:43:43,166 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 0.064783\n",
      "Reconstruction: 0.058232, Regularization: 0.006551\n",
      "2019-04-09 20:43:43,192 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.061309\n",
      "Reconstruction: 0.055412, Regularization: 0.005897\n",
      "2019-04-09 20:43:43,219 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.065847\n",
      "Reconstruction: 0.059309, Regularization: 0.006538\n",
      "2019-04-09 20:43:43,246 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 0.063735\n",
      "Reconstruction: 0.057548, Regularization: 0.006187\n",
      "2019-04-09 20:43:43,272 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.064547\n",
      "Reconstruction: 0.058266, Regularization: 0.006281\n",
      "2019-04-09 20:43:43,299 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.052329\n",
      "Reconstruction: 0.047571, Regularization: 0.004757\n",
      "2019-04-09 20:43:43,337 root         INFO     ====> Epoch: 41 Average loss: 0.0612\n",
      "2019-04-09 20:43:43,358 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.045960\n",
      "Reconstruction: 0.041991, Regularization: 0.003969\n",
      "2019-04-09 20:43:43,384 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.061534\n",
      "Reconstruction: 0.055727, Regularization: 0.005808\n",
      "2019-04-09 20:43:43,409 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.065140\n",
      "Reconstruction: 0.058867, Regularization: 0.006273\n",
      "2019-04-09 20:43:43,435 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 0.063920\n",
      "Reconstruction: 0.057837, Regularization: 0.006082\n",
      "2019-04-09 20:43:43,461 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.054961\n",
      "Reconstruction: 0.050072, Regularization: 0.004889\n",
      "2019-04-09 20:43:43,486 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.058104\n",
      "Reconstruction: 0.052753, Regularization: 0.005351\n",
      "2019-04-09 20:43:43,512 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.072500\n",
      "Reconstruction: 0.065451, Regularization: 0.007049\n",
      "2019-04-09 20:43:43,537 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.053045\n",
      "Reconstruction: 0.048386, Regularization: 0.004660\n",
      "2019-04-09 20:43:43,574 root         INFO     ====> Epoch: 42 Average loss: 0.0605\n",
      "2019-04-09 20:43:43,595 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.058221\n",
      "Reconstruction: 0.052922, Regularization: 0.005299\n",
      "2019-04-09 20:43:43,621 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.055681\n",
      "Reconstruction: 0.050761, Regularization: 0.004920\n",
      "2019-04-09 20:43:43,647 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.045420\n",
      "Reconstruction: 0.041728, Regularization: 0.003692\n",
      "2019-04-09 20:43:43,672 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.049860\n",
      "Reconstruction: 0.045660, Regularization: 0.004200\n",
      "2019-04-09 20:43:43,698 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.058389\n",
      "Reconstruction: 0.053179, Regularization: 0.005210\n",
      "2019-04-09 20:43:43,724 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.074865\n",
      "Reconstruction: 0.067758, Regularization: 0.007107\n",
      "2019-04-09 20:43:43,749 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.067882\n",
      "Reconstruction: 0.061602, Regularization: 0.006280\n",
      "2019-04-09 20:43:43,775 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.054528\n",
      "Reconstruction: 0.049824, Regularization: 0.004705\n",
      "2019-04-09 20:43:43,812 root         INFO     ====> Epoch: 43 Average loss: 0.0599\n",
      "2019-04-09 20:43:43,832 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.054426\n",
      "Reconstruction: 0.049784, Regularization: 0.004642\n",
      "2019-04-09 20:43:43,860 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.054018\n",
      "Reconstruction: 0.049470, Regularization: 0.004548\n",
      "2019-04-09 20:43:43,886 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.056417\n",
      "Reconstruction: 0.051582, Regularization: 0.004835\n",
      "2019-04-09 20:43:43,912 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.053614\n",
      "Reconstruction: 0.049151, Regularization: 0.004462\n",
      "2019-04-09 20:43:43,939 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.057950\n",
      "Reconstruction: 0.053024, Regularization: 0.004926\n",
      "2019-04-09 20:43:43,965 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.063119\n",
      "Reconstruction: 0.057595, Regularization: 0.005524\n",
      "2019-04-09 20:43:43,991 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.047027\n",
      "Reconstruction: 0.043364, Regularization: 0.003663\n",
      "2019-04-09 20:43:44,018 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.064757\n",
      "Reconstruction: 0.059040, Regularization: 0.005716\n",
      "2019-04-09 20:43:44,055 root         INFO     ====> Epoch: 44 Average loss: 0.0594\n",
      "2019-04-09 20:43:44,076 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.060616\n",
      "Reconstruction: 0.055475, Regularization: 0.005141\n",
      "2019-04-09 20:43:44,101 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 0.064123\n",
      "Reconstruction: 0.058580, Regularization: 0.005543\n",
      "2019-04-09 20:43:44,127 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.053456\n",
      "Reconstruction: 0.049108, Regularization: 0.004348\n",
      "2019-04-09 20:43:44,152 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.061925\n",
      "Reconstruction: 0.056703, Regularization: 0.005222\n",
      "2019-04-09 20:43:44,177 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.055988\n",
      "Reconstruction: 0.051420, Regularization: 0.004568\n",
      "2019-04-09 20:43:44,202 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.068401\n",
      "Reconstruction: 0.062514, Regularization: 0.005886\n",
      "2019-04-09 20:43:44,228 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.053559\n",
      "Reconstruction: 0.049279, Regularization: 0.004279\n",
      "2019-04-09 20:43:44,253 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.053427\n",
      "Reconstruction: 0.049194, Regularization: 0.004233\n",
      "2019-04-09 20:43:44,289 root         INFO     ====> Epoch: 45 Average loss: 0.0589\n",
      "2019-04-09 20:43:44,311 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.059880\n",
      "Reconstruction: 0.054916, Regularization: 0.004964\n",
      "2019-04-09 20:43:44,338 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.056919\n",
      "Reconstruction: 0.052352, Regularization: 0.004567\n",
      "2019-04-09 20:43:44,364 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.072458\n",
      "Reconstruction: 0.066235, Regularization: 0.006223\n",
      "2019-04-09 20:43:44,390 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.047709\n",
      "Reconstruction: 0.044167, Regularization: 0.003542\n",
      "2019-04-09 20:43:44,415 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.066003\n",
      "Reconstruction: 0.060533, Regularization: 0.005469\n",
      "2019-04-09 20:43:44,440 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.066694\n",
      "Reconstruction: 0.061149, Regularization: 0.005545\n",
      "2019-04-09 20:43:44,465 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.058899\n",
      "Reconstruction: 0.054217, Regularization: 0.004682\n",
      "2019-04-09 20:43:44,490 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.058710\n",
      "Reconstruction: 0.054059, Regularization: 0.004650\n",
      "2019-04-09 20:43:44,529 root         INFO     ====> Epoch: 46 Average loss: 0.0583\n",
      "2019-04-09 20:43:44,550 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.055349\n",
      "Reconstruction: 0.051087, Regularization: 0.004262\n",
      "2019-04-09 20:43:44,576 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.066683\n",
      "Reconstruction: 0.061253, Regularization: 0.005431\n",
      "2019-04-09 20:43:44,602 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.058080\n",
      "Reconstruction: 0.053559, Regularization: 0.004520\n",
      "2019-04-09 20:43:44,627 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.056644\n",
      "Reconstruction: 0.052305, Regularization: 0.004338\n",
      "2019-04-09 20:43:44,652 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.046933\n",
      "Reconstruction: 0.043614, Regularization: 0.003319\n",
      "2019-04-09 20:43:44,677 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.047859\n",
      "Reconstruction: 0.044443, Regularization: 0.003416\n",
      "2019-04-09 20:43:44,702 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.068787\n",
      "Reconstruction: 0.063293, Regularization: 0.005494\n",
      "2019-04-09 20:43:44,727 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.079344\n",
      "Reconstruction: 0.072788, Regularization: 0.006556\n",
      "2019-04-09 20:43:44,764 root         INFO     ====> Epoch: 47 Average loss: 0.0578\n",
      "2019-04-09 20:43:44,785 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.056035\n",
      "Reconstruction: 0.051855, Regularization: 0.004180\n",
      "2019-04-09 20:43:44,811 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.056302\n",
      "Reconstruction: 0.052113, Regularization: 0.004190\n",
      "2019-04-09 20:43:44,837 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.046374\n",
      "Reconstruction: 0.043180, Regularization: 0.003194\n",
      "2019-04-09 20:43:44,863 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.056586\n",
      "Reconstruction: 0.052427, Regularization: 0.004159\n",
      "2019-04-09 20:43:44,889 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.062084\n",
      "Reconstruction: 0.057394, Regularization: 0.004690\n",
      "2019-04-09 20:43:44,916 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.059610\n",
      "Reconstruction: 0.055176, Regularization: 0.004434\n",
      "2019-04-09 20:43:44,942 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.051389\n",
      "Reconstruction: 0.047771, Regularization: 0.003617\n",
      "2019-04-09 20:43:44,968 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.053138\n",
      "Reconstruction: 0.049385, Regularization: 0.003753\n",
      "2019-04-09 20:43:45,006 root         INFO     ====> Epoch: 48 Average loss: 0.0574\n",
      "2019-04-09 20:43:45,027 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.067138\n",
      "Reconstruction: 0.062039, Regularization: 0.005099\n",
      "2019-04-09 20:43:45,053 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.055498\n",
      "Reconstruction: 0.051548, Regularization: 0.003951\n",
      "2019-04-09 20:43:45,080 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.056766\n",
      "Reconstruction: 0.052710, Regularization: 0.004056\n",
      "2019-04-09 20:43:45,106 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.055617\n",
      "Reconstruction: 0.051690, Regularization: 0.003928\n",
      "2019-04-09 20:43:45,132 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.054334\n",
      "Reconstruction: 0.050554, Regularization: 0.003780\n",
      "2019-04-09 20:43:45,158 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.063206\n",
      "Reconstruction: 0.058607, Regularization: 0.004599\n",
      "2019-04-09 20:43:45,185 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.075141\n",
      "Reconstruction: 0.069453, Regularization: 0.005688\n",
      "2019-04-09 20:43:45,211 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.070191\n",
      "Reconstruction: 0.064984, Regularization: 0.005207\n",
      "2019-04-09 20:43:45,249 root         INFO     ====> Epoch: 49 Average loss: 0.0569\n",
      "2019-04-09 20:43:45,270 root         INFO     Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 0.050372\n",
      "Reconstruction: 0.047031, Regularization: 0.003341\n",
      "2019-04-09 20:43:45,296 root         INFO     Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 0.063141\n",
      "Reconstruction: 0.058640, Regularization: 0.004500\n",
      "2019-04-09 20:43:45,322 root         INFO     Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 0.049053\n",
      "Reconstruction: 0.045870, Regularization: 0.003183\n",
      "2019-04-09 20:43:45,349 root         INFO     Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 0.058644\n",
      "Reconstruction: 0.054600, Regularization: 0.004044\n",
      "2019-04-09 20:43:45,375 root         INFO     Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 0.051528\n",
      "Reconstruction: 0.048151, Regularization: 0.003377\n",
      "2019-04-09 20:43:45,401 root         INFO     Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 0.061450\n",
      "Reconstruction: 0.057194, Regularization: 0.004257\n",
      "2019-04-09 20:43:45,427 root         INFO     Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 0.048747\n",
      "Reconstruction: 0.045653, Regularization: 0.003093\n",
      "2019-04-09 20:43:45,453 root         INFO     Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 0.056794\n",
      "Reconstruction: 0.053000, Regularization: 0.003794\n",
      "2019-04-09 20:43:45,491 root         INFO     ====> Epoch: 50 Average loss: 0.0565\n",
      "2019-04-09 20:43:45,512 root         INFO     Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 0.048808\n",
      "Reconstruction: 0.045740, Regularization: 0.003067\n",
      "2019-04-09 20:43:45,538 root         INFO     Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 0.059365\n",
      "Reconstruction: 0.055374, Regularization: 0.003991\n",
      "2019-04-09 20:43:45,565 root         INFO     Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 0.055258\n",
      "Reconstruction: 0.051650, Regularization: 0.003608\n",
      "2019-04-09 20:43:45,590 root         INFO     Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 0.059693\n",
      "Reconstruction: 0.055709, Regularization: 0.003984\n",
      "2019-04-09 20:43:45,615 root         INFO     Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 0.053374\n",
      "Reconstruction: 0.049972, Regularization: 0.003402\n",
      "2019-04-09 20:43:45,640 root         INFO     Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 0.044619\n",
      "Reconstruction: 0.041995, Regularization: 0.002624\n",
      "2019-04-09 20:43:45,665 root         INFO     Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 0.054023\n",
      "Reconstruction: 0.050602, Regularization: 0.003421\n",
      "2019-04-09 20:43:45,691 root         INFO     Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 0.051018\n",
      "Reconstruction: 0.047868, Regularization: 0.003150\n",
      "2019-04-09 20:43:45,727 root         INFO     ====> Epoch: 51 Average loss: 0.0561\n",
      "2019-04-09 20:43:45,748 root         INFO     Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 0.049482\n",
      "Reconstruction: 0.046480, Regularization: 0.003002\n",
      "2019-04-09 20:43:45,775 root         INFO     Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 0.054399\n",
      "Reconstruction: 0.050997, Regularization: 0.003402\n",
      "2019-04-09 20:43:45,802 root         INFO     Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 0.052775\n",
      "Reconstruction: 0.049535, Regularization: 0.003240\n",
      "2019-04-09 20:43:45,829 root         INFO     Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 0.051920\n",
      "Reconstruction: 0.048759, Regularization: 0.003161\n",
      "2019-04-09 20:43:45,855 root         INFO     Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 0.057379\n",
      "Reconstruction: 0.053786, Regularization: 0.003593\n",
      "2019-04-09 20:43:45,882 root         INFO     Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 0.050311\n",
      "Reconstruction: 0.047316, Regularization: 0.002995\n",
      "2019-04-09 20:43:45,908 root         INFO     Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 0.061824\n",
      "Reconstruction: 0.057891, Regularization: 0.003932\n",
      "2019-04-09 20:43:45,935 root         INFO     Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 0.060706\n",
      "Reconstruction: 0.056891, Regularization: 0.003814\n",
      "2019-04-09 20:43:45,972 root         INFO     ====> Epoch: 52 Average loss: 0.0557\n",
      "2019-04-09 20:43:45,994 root         INFO     Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 0.049598\n",
      "Reconstruction: 0.046717, Regularization: 0.002880\n",
      "2019-04-09 20:43:46,020 root         INFO     Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 0.052218\n",
      "Reconstruction: 0.049139, Regularization: 0.003079\n",
      "2019-04-09 20:43:46,047 root         INFO     Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 0.071717\n",
      "Reconstruction: 0.067064, Regularization: 0.004653\n",
      "2019-04-09 20:43:46,074 root         INFO     Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 0.041941\n",
      "Reconstruction: 0.039723, Regularization: 0.002218\n",
      "2019-04-09 20:43:46,101 root         INFO     Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 0.072621\n",
      "Reconstruction: 0.067939, Regularization: 0.004682\n",
      "2019-04-09 20:43:46,128 root         INFO     Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 0.055380\n",
      "Reconstruction: 0.052123, Regularization: 0.003257\n",
      "2019-04-09 20:43:46,155 root         INFO     Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 0.055609\n",
      "Reconstruction: 0.052324, Regularization: 0.003285\n",
      "2019-04-09 20:43:46,181 root         INFO     Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 0.065454\n",
      "Reconstruction: 0.061427, Regularization: 0.004027\n",
      "2019-04-09 20:43:46,219 root         INFO     ====> Epoch: 53 Average loss: 0.0554\n",
      "2019-04-09 20:43:46,240 root         INFO     Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 0.055431\n",
      "Reconstruction: 0.052214, Regularization: 0.003217\n",
      "2019-04-09 20:43:46,266 root         INFO     Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 0.068052\n",
      "Reconstruction: 0.063869, Regularization: 0.004183\n",
      "2019-04-09 20:43:46,293 root         INFO     Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 0.061263\n",
      "Reconstruction: 0.057603, Regularization: 0.003660\n",
      "2019-04-09 20:43:46,320 root         INFO     Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 0.052028\n",
      "Reconstruction: 0.049131, Regularization: 0.002897\n",
      "2019-04-09 20:43:46,347 root         INFO     Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 0.052316\n",
      "Reconstruction: 0.049392, Regularization: 0.002925\n",
      "2019-04-09 20:43:46,373 root         INFO     Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 0.061854\n",
      "Reconstruction: 0.058234, Regularization: 0.003620\n",
      "2019-04-09 20:43:46,400 root         INFO     Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 0.051099\n",
      "Reconstruction: 0.048304, Regularization: 0.002795\n",
      "2019-04-09 20:43:46,427 root         INFO     Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 0.037729\n",
      "Reconstruction: 0.035963, Regularization: 0.001767\n",
      "2019-04-09 20:43:46,465 root         INFO     ====> Epoch: 54 Average loss: 0.0551\n",
      "2019-04-09 20:43:46,486 root         INFO     Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 0.051048\n",
      "Reconstruction: 0.048277, Regularization: 0.002771\n",
      "2019-04-09 20:43:46,513 root         INFO     Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 0.050785\n",
      "Reconstruction: 0.048059, Regularization: 0.002726\n",
      "2019-04-09 20:43:46,539 root         INFO     Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 0.051605\n",
      "Reconstruction: 0.048847, Regularization: 0.002758\n",
      "2019-04-09 20:43:46,566 root         INFO     Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 0.052298\n",
      "Reconstruction: 0.049462, Regularization: 0.002835\n",
      "2019-04-09 20:43:46,593 root         INFO     Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 0.051684\n",
      "Reconstruction: 0.048948, Regularization: 0.002736\n",
      "2019-04-09 20:43:46,620 root         INFO     Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 0.056778\n",
      "Reconstruction: 0.053666, Regularization: 0.003112\n",
      "2019-04-09 20:43:46,646 root         INFO     Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 0.046659\n",
      "Reconstruction: 0.044320, Regularization: 0.002339\n",
      "2019-04-09 20:43:46,671 root         INFO     Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 0.053732\n",
      "Reconstruction: 0.050887, Regularization: 0.002844\n",
      "2019-04-09 20:43:46,707 root         INFO     ====> Epoch: 55 Average loss: 0.0547\n",
      "2019-04-09 20:43:46,728 root         INFO     Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 0.054211\n",
      "Reconstruction: 0.051328, Regularization: 0.002883\n",
      "2019-04-09 20:43:46,756 root         INFO     Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 0.052805\n",
      "Reconstruction: 0.050053, Regularization: 0.002752\n",
      "2019-04-09 20:43:46,783 root         INFO     Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 0.050231\n",
      "Reconstruction: 0.047663, Regularization: 0.002568\n",
      "2019-04-09 20:43:46,809 root         INFO     Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 0.047105\n",
      "Reconstruction: 0.044805, Regularization: 0.002300\n",
      "2019-04-09 20:43:46,834 root         INFO     Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 0.062646\n",
      "Reconstruction: 0.059247, Regularization: 0.003399\n",
      "2019-04-09 20:43:46,860 root         INFO     Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 0.056431\n",
      "Reconstruction: 0.053482, Regularization: 0.002949\n",
      "2019-04-09 20:43:46,887 root         INFO     Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 0.051430\n",
      "Reconstruction: 0.048849, Regularization: 0.002581\n",
      "2019-04-09 20:43:46,913 root         INFO     Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 0.057904\n",
      "Reconstruction: 0.054912, Regularization: 0.002991\n",
      "2019-04-09 20:43:46,950 root         INFO     ====> Epoch: 56 Average loss: 0.0544\n",
      "2019-04-09 20:43:46,971 root         INFO     Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 0.046366\n",
      "Reconstruction: 0.044138, Regularization: 0.002228\n",
      "2019-04-09 20:43:46,999 root         INFO     Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 0.062828\n",
      "Reconstruction: 0.059507, Regularization: 0.003321\n",
      "2019-04-09 20:43:47,026 root         INFO     Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 0.058531\n",
      "Reconstruction: 0.055512, Regularization: 0.003019\n",
      "2019-04-09 20:43:47,053 root         INFO     Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 0.046734\n",
      "Reconstruction: 0.044547, Regularization: 0.002186\n",
      "2019-04-09 20:43:47,080 root         INFO     Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 0.045510\n",
      "Reconstruction: 0.043414, Regularization: 0.002095\n",
      "2019-04-09 20:43:47,106 root         INFO     Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 0.056996\n",
      "Reconstruction: 0.054125, Regularization: 0.002870\n",
      "2019-04-09 20:43:47,132 root         INFO     Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 0.052582\n",
      "Reconstruction: 0.050048, Regularization: 0.002534\n",
      "2019-04-09 20:43:47,158 root         INFO     Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 0.056697\n",
      "Reconstruction: 0.053889, Regularization: 0.002808\n",
      "2019-04-09 20:43:47,196 root         INFO     ====> Epoch: 57 Average loss: 0.0542\n",
      "2019-04-09 20:43:47,217 root         INFO     Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 0.054029\n",
      "Reconstruction: 0.051430, Regularization: 0.002599\n",
      "2019-04-09 20:43:47,243 root         INFO     Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 0.062129\n",
      "Reconstruction: 0.059033, Regularization: 0.003096\n",
      "2019-04-09 20:43:47,270 root         INFO     Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 0.056254\n",
      "Reconstruction: 0.053548, Regularization: 0.002706\n",
      "2019-04-09 20:43:47,296 root         INFO     Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 0.044978\n",
      "Reconstruction: 0.042982, Regularization: 0.001996\n",
      "2019-04-09 20:43:47,322 root         INFO     Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 0.048597\n",
      "Reconstruction: 0.046384, Regularization: 0.002213\n",
      "2019-04-09 20:43:47,348 root         INFO     Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 0.048673\n",
      "Reconstruction: 0.046483, Regularization: 0.002191\n",
      "2019-04-09 20:43:47,375 root         INFO     Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 0.069919\n",
      "Reconstruction: 0.066397, Regularization: 0.003522\n",
      "2019-04-09 20:43:47,402 root         INFO     Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 0.046433\n",
      "Reconstruction: 0.044417, Regularization: 0.002016\n",
      "2019-04-09 20:43:47,441 root         INFO     ====> Epoch: 58 Average loss: 0.0539\n",
      "2019-04-09 20:43:47,462 root         INFO     Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 0.063904\n",
      "Reconstruction: 0.060828, Regularization: 0.003076\n",
      "2019-04-09 20:43:47,489 root         INFO     Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 0.052466\n",
      "Reconstruction: 0.050101, Regularization: 0.002365\n",
      "2019-04-09 20:43:47,515 root         INFO     Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 0.046753\n",
      "Reconstruction: 0.044713, Regularization: 0.002040\n",
      "2019-04-09 20:43:47,542 root         INFO     Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 0.047720\n",
      "Reconstruction: 0.045646, Regularization: 0.002073\n",
      "2019-04-09 20:43:47,568 root         INFO     Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 0.049590\n",
      "Reconstruction: 0.047437, Regularization: 0.002153\n",
      "2019-04-09 20:43:47,594 root         INFO     Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 0.058887\n",
      "Reconstruction: 0.056146, Regularization: 0.002741\n",
      "2019-04-09 20:43:47,621 root         INFO     Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 0.062763\n",
      "Reconstruction: 0.059822, Regularization: 0.002942\n",
      "2019-04-09 20:43:47,647 root         INFO     Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 0.065065\n",
      "Reconstruction: 0.062020, Regularization: 0.003045\n",
      "2019-04-09 20:43:47,684 root         INFO     ====> Epoch: 59 Average loss: 0.0537\n",
      "2019-04-09 20:43:47,706 root         INFO     Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 0.048226\n",
      "Reconstruction: 0.046181, Regularization: 0.002044\n",
      "2019-04-09 20:43:47,733 root         INFO     Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 0.056016\n",
      "Reconstruction: 0.053485, Regularization: 0.002531\n",
      "2019-04-09 20:43:47,760 root         INFO     Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 0.053546\n",
      "Reconstruction: 0.051237, Regularization: 0.002309\n",
      "2019-04-09 20:43:47,787 root         INFO     Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 0.051969\n",
      "Reconstruction: 0.049722, Regularization: 0.002247\n",
      "2019-04-09 20:43:47,814 root         INFO     Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 0.054142\n",
      "Reconstruction: 0.051799, Regularization: 0.002343\n",
      "2019-04-09 20:43:47,840 root         INFO     Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 0.053508\n",
      "Reconstruction: 0.051230, Regularization: 0.002277\n",
      "2019-04-09 20:43:47,867 root         INFO     Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 0.052886\n",
      "Reconstruction: 0.050637, Regularization: 0.002248\n",
      "2019-04-09 20:43:47,894 root         INFO     Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 0.065839\n",
      "Reconstruction: 0.062872, Regularization: 0.002968\n",
      "2019-04-09 20:43:47,932 root         INFO     ====> Epoch: 60 Average loss: 0.0535\n",
      "2019-04-09 20:43:47,953 root         INFO     Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 0.056912\n",
      "Reconstruction: 0.054470, Regularization: 0.002441\n",
      "2019-04-09 20:43:47,980 root         INFO     Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 0.047319\n",
      "Reconstruction: 0.045399, Regularization: 0.001920\n",
      "2019-04-09 20:43:48,006 root         INFO     Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 0.047183\n",
      "Reconstruction: 0.045322, Regularization: 0.001861\n",
      "2019-04-09 20:43:48,032 root         INFO     Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 0.044753\n",
      "Reconstruction: 0.043029, Regularization: 0.001724\n",
      "2019-04-09 20:43:48,059 root         INFO     Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 0.048798\n",
      "Reconstruction: 0.046882, Regularization: 0.001915\n",
      "2019-04-09 20:43:48,086 root         INFO     Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 0.055763\n",
      "Reconstruction: 0.053434, Regularization: 0.002328\n",
      "2019-04-09 20:43:48,112 root         INFO     Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 0.048462\n",
      "Reconstruction: 0.046553, Regularization: 0.001909\n",
      "2019-04-09 20:43:48,139 root         INFO     Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 0.048263\n",
      "Reconstruction: 0.046383, Regularization: 0.001880\n",
      "2019-04-09 20:43:48,177 root         INFO     ====> Epoch: 61 Average loss: 0.0532\n",
      "2019-04-09 20:43:48,198 root         INFO     Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 0.055181\n",
      "Reconstruction: 0.052864, Regularization: 0.002316\n",
      "2019-04-09 20:43:48,225 root         INFO     Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 0.057458\n",
      "Reconstruction: 0.055150, Regularization: 0.002308\n",
      "2019-04-09 20:43:48,252 root         INFO     Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 0.059065\n",
      "Reconstruction: 0.056618, Regularization: 0.002447\n",
      "2019-04-09 20:43:48,279 root         INFO     Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 0.050519\n",
      "Reconstruction: 0.048565, Regularization: 0.001955\n",
      "2019-04-09 20:43:48,306 root         INFO     Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 0.057260\n",
      "Reconstruction: 0.054907, Regularization: 0.002353\n",
      "2019-04-09 20:43:48,333 root         INFO     Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 0.057065\n",
      "Reconstruction: 0.054727, Regularization: 0.002337\n",
      "2019-04-09 20:43:48,360 root         INFO     Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 0.056989\n",
      "Reconstruction: 0.054739, Regularization: 0.002250\n",
      "2019-04-09 20:43:48,387 root         INFO     Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 0.045803\n",
      "Reconstruction: 0.044101, Regularization: 0.001702\n",
      "2019-04-09 20:43:48,425 root         INFO     ====> Epoch: 62 Average loss: 0.0530\n",
      "2019-04-09 20:43:48,447 root         INFO     Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 0.043740\n",
      "Reconstruction: 0.042168, Regularization: 0.001573\n",
      "2019-04-09 20:43:48,473 root         INFO     Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 0.048997\n",
      "Reconstruction: 0.047157, Regularization: 0.001841\n",
      "2019-04-09 20:43:48,499 root         INFO     Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 0.052885\n",
      "Reconstruction: 0.050857, Regularization: 0.002028\n",
      "2019-04-09 20:43:48,526 root         INFO     Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 0.043053\n",
      "Reconstruction: 0.041543, Regularization: 0.001510\n",
      "2019-04-09 20:43:48,552 root         INFO     Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 0.049975\n",
      "Reconstruction: 0.048133, Regularization: 0.001842\n",
      "2019-04-09 20:43:48,578 root         INFO     Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 0.059731\n",
      "Reconstruction: 0.057410, Regularization: 0.002320\n",
      "2019-04-09 20:43:48,603 root         INFO     Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 0.042904\n",
      "Reconstruction: 0.041418, Regularization: 0.001486\n",
      "2019-04-09 20:43:48,629 root         INFO     Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 0.054529\n",
      "Reconstruction: 0.052490, Regularization: 0.002039\n",
      "2019-04-09 20:43:48,666 root         INFO     ====> Epoch: 63 Average loss: 0.0528\n",
      "2019-04-09 20:43:48,687 root         INFO     Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 0.047319\n",
      "Reconstruction: 0.045657, Regularization: 0.001662\n",
      "2019-04-09 20:43:48,713 root         INFO     Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 0.045828\n",
      "Reconstruction: 0.044263, Regularization: 0.001565\n",
      "2019-04-09 20:43:48,739 root         INFO     Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 0.046637\n",
      "Reconstruction: 0.044999, Regularization: 0.001639\n",
      "2019-04-09 20:43:48,765 root         INFO     Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 0.049720\n",
      "Reconstruction: 0.047962, Regularization: 0.001758\n",
      "2019-04-09 20:43:48,791 root         INFO     Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 0.058515\n",
      "Reconstruction: 0.056372, Regularization: 0.002143\n",
      "2019-04-09 20:43:48,817 root         INFO     Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 0.057418\n",
      "Reconstruction: 0.055277, Regularization: 0.002141\n",
      "2019-04-09 20:43:48,843 root         INFO     Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 0.043719\n",
      "Reconstruction: 0.042278, Regularization: 0.001441\n",
      "2019-04-09 20:43:48,869 root         INFO     Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 0.052562\n",
      "Reconstruction: 0.050711, Regularization: 0.001851\n",
      "2019-04-09 20:43:48,906 root         INFO     ====> Epoch: 64 Average loss: 0.0527\n",
      "2019-04-09 20:43:48,927 root         INFO     Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 0.051717\n",
      "Reconstruction: 0.049928, Regularization: 0.001789\n",
      "2019-04-09 20:43:48,953 root         INFO     Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 0.040297\n",
      "Reconstruction: 0.039023, Regularization: 0.001275\n",
      "2019-04-09 20:43:48,979 root         INFO     Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 0.047233\n",
      "Reconstruction: 0.045578, Regularization: 0.001655\n",
      "2019-04-09 20:43:49,007 root         INFO     Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 0.050118\n",
      "Reconstruction: 0.048356, Regularization: 0.001762\n",
      "2019-04-09 20:43:49,035 root         INFO     Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 0.045248\n",
      "Reconstruction: 0.043771, Regularization: 0.001477\n",
      "2019-04-09 20:43:49,062 root         INFO     Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 0.055999\n",
      "Reconstruction: 0.054079, Regularization: 0.001920\n",
      "2019-04-09 20:43:49,090 root         INFO     Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 0.051064\n",
      "Reconstruction: 0.049334, Regularization: 0.001731\n",
      "2019-04-09 20:43:49,118 root         INFO     Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 0.048251\n",
      "Reconstruction: 0.046634, Regularization: 0.001617\n",
      "2019-04-09 20:43:49,158 root         INFO     ====> Epoch: 65 Average loss: 0.0525\n",
      "2019-04-09 20:43:49,179 root         INFO     Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 0.041640\n",
      "Reconstruction: 0.040349, Regularization: 0.001291\n",
      "2019-04-09 20:43:49,207 root         INFO     Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 0.049019\n",
      "Reconstruction: 0.047369, Regularization: 0.001649\n",
      "2019-04-09 20:43:49,234 root         INFO     Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 0.051055\n",
      "Reconstruction: 0.049380, Regularization: 0.001676\n",
      "2019-04-09 20:43:49,262 root         INFO     Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 0.049837\n",
      "Reconstruction: 0.048222, Regularization: 0.001616\n",
      "2019-04-09 20:43:49,289 root         INFO     Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 0.049056\n",
      "Reconstruction: 0.047420, Regularization: 0.001636\n",
      "2019-04-09 20:43:49,316 root         INFO     Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 0.058221\n",
      "Reconstruction: 0.056234, Regularization: 0.001987\n",
      "2019-04-09 20:43:49,343 root         INFO     Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 0.052917\n",
      "Reconstruction: 0.051177, Regularization: 0.001740\n",
      "2019-04-09 20:43:49,370 root         INFO     Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 0.055097\n",
      "Reconstruction: 0.053199, Regularization: 0.001898\n",
      "2019-04-09 20:43:49,408 root         INFO     ====> Epoch: 66 Average loss: 0.0523\n",
      "2019-04-09 20:43:49,429 root         INFO     Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 0.046257\n",
      "Reconstruction: 0.044801, Regularization: 0.001456\n",
      "2019-04-09 20:43:49,457 root         INFO     Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 0.045589\n",
      "Reconstruction: 0.044191, Regularization: 0.001398\n",
      "2019-04-09 20:43:49,482 root         INFO     Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 0.040865\n",
      "Reconstruction: 0.039679, Regularization: 0.001186\n",
      "2019-04-09 20:43:49,509 root         INFO     Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 0.042005\n",
      "Reconstruction: 0.040790, Regularization: 0.001215\n",
      "2019-04-09 20:43:49,536 root         INFO     Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 0.057186\n",
      "Reconstruction: 0.055280, Regularization: 0.001906\n",
      "2019-04-09 20:43:49,563 root         INFO     Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 0.068225\n",
      "Reconstruction: 0.065869, Regularization: 0.002356\n",
      "2019-04-09 20:43:49,590 root         INFO     Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 0.056139\n",
      "Reconstruction: 0.054320, Regularization: 0.001819\n",
      "2019-04-09 20:43:49,617 root         INFO     Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 0.053658\n",
      "Reconstruction: 0.051963, Regularization: 0.001695\n",
      "2019-04-09 20:43:49,654 root         INFO     ====> Epoch: 67 Average loss: 0.0522\n",
      "2019-04-09 20:43:49,676 root         INFO     Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 0.056913\n",
      "Reconstruction: 0.055042, Regularization: 0.001871\n",
      "2019-04-09 20:43:49,703 root         INFO     Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 0.055225\n",
      "Reconstruction: 0.053478, Regularization: 0.001747\n",
      "2019-04-09 20:43:49,730 root         INFO     Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 0.046614\n",
      "Reconstruction: 0.045206, Regularization: 0.001408\n",
      "2019-04-09 20:43:49,757 root         INFO     Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 0.052850\n",
      "Reconstruction: 0.051120, Regularization: 0.001731\n",
      "2019-04-09 20:43:49,783 root         INFO     Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 0.052155\n",
      "Reconstruction: 0.050572, Regularization: 0.001583\n",
      "2019-04-09 20:43:49,810 root         INFO     Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 0.050291\n",
      "Reconstruction: 0.048735, Regularization: 0.001557\n",
      "2019-04-09 20:43:49,837 root         INFO     Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 0.053294\n",
      "Reconstruction: 0.051664, Regularization: 0.001630\n",
      "2019-04-09 20:43:49,864 root         INFO     Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 0.047607\n",
      "Reconstruction: 0.046171, Regularization: 0.001436\n",
      "2019-04-09 20:43:49,902 root         INFO     ====> Epoch: 68 Average loss: 0.0521\n",
      "2019-04-09 20:43:49,923 root         INFO     Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 0.046911\n",
      "Reconstruction: 0.045559, Regularization: 0.001352\n",
      "2019-04-09 20:43:49,950 root         INFO     Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 0.047134\n",
      "Reconstruction: 0.045741, Regularization: 0.001392\n",
      "2019-04-09 20:43:49,977 root         INFO     Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 0.048375\n",
      "Reconstruction: 0.046960, Regularization: 0.001415\n",
      "2019-04-09 20:43:50,005 root         INFO     Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 0.080016\n",
      "Reconstruction: 0.077318, Regularization: 0.002698\n",
      "2019-04-09 20:43:50,031 root         INFO     Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 0.054878\n",
      "Reconstruction: 0.053188, Regularization: 0.001690\n",
      "2019-04-09 20:43:50,058 root         INFO     Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 0.063727\n",
      "Reconstruction: 0.061693, Regularization: 0.002034\n",
      "2019-04-09 20:43:50,085 root         INFO     Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 0.051949\n",
      "Reconstruction: 0.050359, Regularization: 0.001590\n",
      "2019-04-09 20:43:50,112 root         INFO     Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 0.044288\n",
      "Reconstruction: 0.043088, Regularization: 0.001200\n",
      "2019-04-09 20:43:50,150 root         INFO     ====> Epoch: 69 Average loss: 0.0520\n",
      "2019-04-09 20:43:50,171 root         INFO     Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 0.041481\n",
      "Reconstruction: 0.040372, Regularization: 0.001108\n",
      "2019-04-09 20:43:50,198 root         INFO     Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 0.036645\n",
      "Reconstruction: 0.035683, Regularization: 0.000962\n",
      "2019-04-09 20:43:50,225 root         INFO     Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 0.052169\n",
      "Reconstruction: 0.050659, Regularization: 0.001510\n",
      "2019-04-09 20:43:50,252 root         INFO     Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 0.052174\n",
      "Reconstruction: 0.050615, Regularization: 0.001559\n",
      "2019-04-09 20:43:50,279 root         INFO     Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 0.048514\n",
      "Reconstruction: 0.047113, Regularization: 0.001400\n",
      "2019-04-09 20:43:50,306 root         INFO     Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 0.050829\n",
      "Reconstruction: 0.049292, Regularization: 0.001537\n",
      "2019-04-09 20:43:50,333 root         INFO     Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 0.051695\n",
      "Reconstruction: 0.050127, Regularization: 0.001568\n",
      "2019-04-09 20:43:50,361 root         INFO     Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 0.051118\n",
      "Reconstruction: 0.049652, Regularization: 0.001466\n",
      "2019-04-09 20:43:50,399 root         INFO     ====> Epoch: 70 Average loss: 0.0518\n",
      "2019-04-09 20:43:50,420 root         INFO     Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 0.049964\n",
      "Reconstruction: 0.048520, Regularization: 0.001444\n",
      "2019-04-09 20:43:50,447 root         INFO     Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 0.060135\n",
      "Reconstruction: 0.058279, Regularization: 0.001855\n",
      "2019-04-09 20:43:50,476 root         INFO     Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 0.041197\n",
      "Reconstruction: 0.040080, Regularization: 0.001117\n",
      "2019-04-09 20:43:50,504 root         INFO     Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 0.053195\n",
      "Reconstruction: 0.051659, Regularization: 0.001536\n",
      "2019-04-09 20:43:50,532 root         INFO     Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 0.049847\n",
      "Reconstruction: 0.048442, Regularization: 0.001405\n",
      "2019-04-09 20:43:50,561 root         INFO     Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 0.049055\n",
      "Reconstruction: 0.047628, Regularization: 0.001427\n",
      "2019-04-09 20:43:50,589 root         INFO     Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 0.051759\n",
      "Reconstruction: 0.050274, Regularization: 0.001485\n",
      "2019-04-09 20:43:50,618 root         INFO     Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 0.063184\n",
      "Reconstruction: 0.061221, Regularization: 0.001963\n",
      "2019-04-09 20:43:50,657 root         INFO     ====> Epoch: 71 Average loss: 0.0517\n",
      "2019-04-09 20:43:50,678 root         INFO     Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 0.051057\n",
      "Reconstruction: 0.049551, Regularization: 0.001506\n",
      "2019-04-09 20:43:50,706 root         INFO     Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 0.056067\n",
      "Reconstruction: 0.054383, Regularization: 0.001684\n",
      "2019-04-09 20:43:50,733 root         INFO     Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 0.054756\n",
      "Reconstruction: 0.053126, Regularization: 0.001631\n",
      "2019-04-09 20:43:50,760 root         INFO     Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 0.043100\n",
      "Reconstruction: 0.041950, Regularization: 0.001150\n",
      "2019-04-09 20:43:50,787 root         INFO     Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 0.055557\n",
      "Reconstruction: 0.053898, Regularization: 0.001660\n",
      "2019-04-09 20:43:50,813 root         INFO     Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 0.048518\n",
      "Reconstruction: 0.047149, Regularization: 0.001369\n",
      "2019-04-09 20:43:50,841 root         INFO     Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 0.047379\n",
      "Reconstruction: 0.046022, Regularization: 0.001357\n",
      "2019-04-09 20:43:50,867 root         INFO     Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 0.050984\n",
      "Reconstruction: 0.049531, Regularization: 0.001454\n",
      "2019-04-09 20:43:50,906 root         INFO     ====> Epoch: 72 Average loss: 0.0516\n",
      "2019-04-09 20:43:50,927 root         INFO     Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 0.046828\n",
      "Reconstruction: 0.045567, Regularization: 0.001261\n",
      "2019-04-09 20:43:50,954 root         INFO     Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 0.053907\n",
      "Reconstruction: 0.052345, Regularization: 0.001562\n",
      "2019-04-09 20:43:50,981 root         INFO     Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 0.048728\n",
      "Reconstruction: 0.047396, Regularization: 0.001332\n",
      "2019-04-09 20:43:51,008 root         INFO     Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 0.044381\n",
      "Reconstruction: 0.043188, Regularization: 0.001194\n",
      "2019-04-09 20:43:51,035 root         INFO     Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 0.056263\n",
      "Reconstruction: 0.054561, Regularization: 0.001701\n",
      "2019-04-09 20:43:51,063 root         INFO     Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 0.055982\n",
      "Reconstruction: 0.054327, Regularization: 0.001655\n",
      "2019-04-09 20:43:51,090 root         INFO     Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 0.048671\n",
      "Reconstruction: 0.047283, Regularization: 0.001388\n",
      "2019-04-09 20:43:51,116 root         INFO     Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 0.050509\n",
      "Reconstruction: 0.049093, Regularization: 0.001416\n",
      "2019-04-09 20:43:51,154 root         INFO     ====> Epoch: 73 Average loss: 0.0515\n",
      "2019-04-09 20:43:51,175 root         INFO     Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 0.050735\n",
      "Reconstruction: 0.049279, Regularization: 0.001456\n",
      "2019-04-09 20:43:51,202 root         INFO     Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 0.043165\n",
      "Reconstruction: 0.041958, Regularization: 0.001207\n",
      "2019-04-09 20:43:51,228 root         INFO     Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 0.050503\n",
      "Reconstruction: 0.049059, Regularization: 0.001443\n",
      "2019-04-09 20:43:51,254 root         INFO     Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 0.058147\n",
      "Reconstruction: 0.056401, Regularization: 0.001746\n",
      "2019-04-09 20:43:51,280 root         INFO     Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 0.046205\n",
      "Reconstruction: 0.044980, Regularization: 0.001225\n",
      "2019-04-09 20:43:51,307 root         INFO     Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 0.057906\n",
      "Reconstruction: 0.056196, Regularization: 0.001710\n",
      "2019-04-09 20:43:51,333 root         INFO     Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 0.049101\n",
      "Reconstruction: 0.047747, Regularization: 0.001354\n",
      "2019-04-09 20:43:51,359 root         INFO     Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 0.052734\n",
      "Reconstruction: 0.051187, Regularization: 0.001547\n",
      "2019-04-09 20:43:51,396 root         INFO     ====> Epoch: 74 Average loss: 0.0515\n",
      "2019-04-09 20:43:51,418 root         INFO     Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 0.041483\n",
      "Reconstruction: 0.040388, Regularization: 0.001095\n",
      "2019-04-09 20:43:51,444 root         INFO     Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 0.050850\n",
      "Reconstruction: 0.049349, Regularization: 0.001501\n",
      "2019-04-09 20:43:51,470 root         INFO     Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 0.054324\n",
      "Reconstruction: 0.052757, Regularization: 0.001567\n",
      "2019-04-09 20:43:51,497 root         INFO     Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 0.046361\n",
      "Reconstruction: 0.045090, Regularization: 0.001270\n",
      "2019-04-09 20:43:51,523 root         INFO     Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 0.058871\n",
      "Reconstruction: 0.057100, Regularization: 0.001771\n",
      "2019-04-09 20:43:51,549 root         INFO     Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 0.054656\n",
      "Reconstruction: 0.052991, Regularization: 0.001665\n",
      "2019-04-09 20:43:51,576 root         INFO     Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 0.056348\n",
      "Reconstruction: 0.054709, Regularization: 0.001639\n",
      "2019-04-09 20:43:51,604 root         INFO     Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 0.049378\n",
      "Reconstruction: 0.047992, Regularization: 0.001386\n",
      "2019-04-09 20:43:51,643 root         INFO     ====> Epoch: 75 Average loss: 0.0514\n",
      "2019-04-09 20:43:51,665 root         INFO     Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 0.047826\n",
      "Reconstruction: 0.046496, Regularization: 0.001330\n",
      "2019-04-09 20:43:51,692 root         INFO     Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 0.038376\n",
      "Reconstruction: 0.037418, Regularization: 0.000958\n",
      "2019-04-09 20:43:51,719 root         INFO     Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 0.043535\n",
      "Reconstruction: 0.042357, Regularization: 0.001177\n",
      "2019-04-09 20:43:51,746 root         INFO     Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 0.045646\n",
      "Reconstruction: 0.044382, Regularization: 0.001264\n",
      "2019-04-09 20:43:51,773 root         INFO     Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 0.046578\n",
      "Reconstruction: 0.045221, Regularization: 0.001358\n",
      "2019-04-09 20:43:51,799 root         INFO     Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 0.052596\n",
      "Reconstruction: 0.050993, Regularization: 0.001603\n",
      "2019-04-09 20:43:51,826 root         INFO     Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 0.052091\n",
      "Reconstruction: 0.050616, Regularization: 0.001475\n",
      "2019-04-09 20:43:51,853 root         INFO     Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 0.069482\n",
      "Reconstruction: 0.067179, Regularization: 0.002303\n",
      "2019-04-09 20:43:51,892 root         INFO     ====> Epoch: 76 Average loss: 0.0514\n",
      "2019-04-09 20:43:51,913 root         INFO     Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 0.057532\n",
      "Reconstruction: 0.055784, Regularization: 0.001747\n",
      "2019-04-09 20:43:51,940 root         INFO     Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 0.051642\n",
      "Reconstruction: 0.050228, Regularization: 0.001414\n",
      "2019-04-09 20:43:51,966 root         INFO     Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 0.043949\n",
      "Reconstruction: 0.042701, Regularization: 0.001248\n",
      "2019-04-09 20:43:51,993 root         INFO     Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 0.048253\n",
      "Reconstruction: 0.046826, Regularization: 0.001427\n",
      "2019-04-09 20:43:52,020 root         INFO     Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 0.062114\n",
      "Reconstruction: 0.060118, Regularization: 0.001996\n",
      "2019-04-09 20:43:52,046 root         INFO     Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 0.058986\n",
      "Reconstruction: 0.057065, Regularization: 0.001921\n",
      "2019-04-09 20:43:52,073 root         INFO     Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 0.041922\n",
      "Reconstruction: 0.040738, Regularization: 0.001183\n",
      "2019-04-09 20:43:52,099 root         INFO     Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 0.050468\n",
      "Reconstruction: 0.049017, Regularization: 0.001451\n",
      "2019-04-09 20:43:52,138 root         INFO     ====> Epoch: 77 Average loss: 0.0512\n",
      "2019-04-09 20:43:52,159 root         INFO     Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 0.053918\n",
      "Reconstruction: 0.052229, Regularization: 0.001689\n",
      "2019-04-09 20:43:52,186 root         INFO     Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 0.058143\n",
      "Reconstruction: 0.056304, Regularization: 0.001839\n",
      "2019-04-09 20:43:52,212 root         INFO     Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 0.059459\n",
      "Reconstruction: 0.057589, Regularization: 0.001870\n",
      "2019-04-09 20:43:52,239 root         INFO     Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 0.060323\n",
      "Reconstruction: 0.058393, Regularization: 0.001929\n",
      "2019-04-09 20:43:52,264 root         INFO     Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 0.033339\n",
      "Reconstruction: 0.032487, Regularization: 0.000851\n",
      "2019-04-09 20:43:52,288 root         INFO     Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 0.047883\n",
      "Reconstruction: 0.046456, Regularization: 0.001428\n",
      "2019-04-09 20:43:52,313 root         INFO     Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 0.050351\n",
      "Reconstruction: 0.048824, Regularization: 0.001527\n",
      "2019-04-09 20:43:52,337 root         INFO     Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 0.051774\n",
      "Reconstruction: 0.050226, Regularization: 0.001548\n",
      "2019-04-09 20:43:52,373 root         INFO     ====> Epoch: 78 Average loss: 0.0511\n",
      "2019-04-09 20:43:52,395 root         INFO     Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 0.057724\n",
      "Reconstruction: 0.055894, Regularization: 0.001830\n",
      "2019-04-09 20:43:52,423 root         INFO     Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 0.042929\n",
      "Reconstruction: 0.041760, Regularization: 0.001169\n",
      "2019-04-09 20:43:52,450 root         INFO     Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 0.066847\n",
      "Reconstruction: 0.064620, Regularization: 0.002227\n",
      "2019-04-09 20:43:52,475 root         INFO     Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 0.052103\n",
      "Reconstruction: 0.050425, Regularization: 0.001678\n",
      "2019-04-09 20:43:52,501 root         INFO     Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 0.041022\n",
      "Reconstruction: 0.039785, Regularization: 0.001236\n",
      "2019-04-09 20:43:52,527 root         INFO     Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 0.043441\n",
      "Reconstruction: 0.042198, Regularization: 0.001243\n",
      "2019-04-09 20:43:52,552 root         INFO     Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 0.055715\n",
      "Reconstruction: 0.053861, Regularization: 0.001853\n",
      "2019-04-09 20:43:52,578 root         INFO     Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 0.046689\n",
      "Reconstruction: 0.045219, Regularization: 0.001470\n",
      "2019-04-09 20:43:52,615 root         INFO     ====> Epoch: 79 Average loss: 0.0511\n",
      "2019-04-09 20:43:52,635 root         INFO     Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 0.051123\n",
      "Reconstruction: 0.049506, Regularization: 0.001617\n",
      "2019-04-09 20:43:52,662 root         INFO     Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 0.038828\n",
      "Reconstruction: 0.037731, Regularization: 0.001097\n",
      "2019-04-09 20:43:52,689 root         INFO     Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 0.046451\n",
      "Reconstruction: 0.045002, Regularization: 0.001449\n",
      "2019-04-09 20:43:52,715 root         INFO     Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 0.048157\n",
      "Reconstruction: 0.046619, Regularization: 0.001538\n",
      "2019-04-09 20:43:52,742 root         INFO     Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 0.054118\n",
      "Reconstruction: 0.052353, Regularization: 0.001765\n",
      "2019-04-09 20:43:52,767 root         INFO     Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 0.045862\n",
      "Reconstruction: 0.044513, Regularization: 0.001349\n",
      "2019-04-09 20:43:52,792 root         INFO     Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 0.047035\n",
      "Reconstruction: 0.045540, Regularization: 0.001495\n",
      "2019-04-09 20:43:52,818 root         INFO     Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 0.060872\n",
      "Reconstruction: 0.058702, Regularization: 0.002170\n",
      "2019-04-09 20:43:52,854 root         INFO     ====> Epoch: 80 Average loss: 0.0510\n",
      "2019-04-09 20:43:52,875 root         INFO     Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 0.051941\n",
      "Reconstruction: 0.050240, Regularization: 0.001700\n",
      "2019-04-09 20:43:52,903 root         INFO     Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 0.044136\n",
      "Reconstruction: 0.042705, Regularization: 0.001431\n",
      "2019-04-09 20:43:52,929 root         INFO     Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 0.045734\n",
      "Reconstruction: 0.044192, Regularization: 0.001542\n",
      "2019-04-09 20:43:52,956 root         INFO     Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 0.040449\n",
      "Reconstruction: 0.039230, Regularization: 0.001219\n",
      "2019-04-09 20:43:52,983 root         INFO     Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 0.058544\n",
      "Reconstruction: 0.056402, Regularization: 0.002143\n",
      "2019-04-09 20:43:53,009 root         INFO     Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 0.058180\n",
      "Reconstruction: 0.056103, Regularization: 0.002077\n",
      "2019-04-09 20:43:53,036 root         INFO     Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 0.051953\n",
      "Reconstruction: 0.050147, Regularization: 0.001806\n",
      "2019-04-09 20:43:53,063 root         INFO     Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 0.071947\n",
      "Reconstruction: 0.069166, Regularization: 0.002781\n",
      "2019-04-09 20:43:53,101 root         INFO     ====> Epoch: 81 Average loss: 0.0507\n",
      "2019-04-09 20:43:53,122 root         INFO     Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 0.051604\n",
      "Reconstruction: 0.049851, Regularization: 0.001753\n",
      "2019-04-09 20:43:53,148 root         INFO     Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 0.048663\n",
      "Reconstruction: 0.046995, Regularization: 0.001668\n",
      "2019-04-09 20:43:53,174 root         INFO     Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 0.037676\n",
      "Reconstruction: 0.036532, Regularization: 0.001144\n",
      "2019-04-09 20:43:53,201 root         INFO     Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 0.056446\n",
      "Reconstruction: 0.054271, Regularization: 0.002174\n",
      "2019-04-09 20:43:53,226 root         INFO     Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 0.051927\n",
      "Reconstruction: 0.049993, Regularization: 0.001934\n",
      "2019-04-09 20:43:53,252 root         INFO     Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 0.049488\n",
      "Reconstruction: 0.047577, Regularization: 0.001911\n",
      "2019-04-09 20:43:53,278 root         INFO     Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 0.052726\n",
      "Reconstruction: 0.050778, Regularization: 0.001947\n",
      "2019-04-09 20:43:53,304 root         INFO     Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 0.067424\n",
      "Reconstruction: 0.064705, Regularization: 0.002719\n",
      "2019-04-09 20:43:53,341 root         INFO     ====> Epoch: 82 Average loss: 0.0505\n",
      "2019-04-09 20:43:53,362 root         INFO     Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 0.042575\n",
      "Reconstruction: 0.041121, Regularization: 0.001453\n",
      "2019-04-09 20:43:53,389 root         INFO     Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 0.059511\n",
      "Reconstruction: 0.057106, Regularization: 0.002405\n",
      "2019-04-09 20:43:53,415 root         INFO     Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 0.060358\n",
      "Reconstruction: 0.057964, Regularization: 0.002394\n",
      "2019-04-09 20:43:53,440 root         INFO     Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 0.055139\n",
      "Reconstruction: 0.052997, Regularization: 0.002142\n",
      "2019-04-09 20:43:53,467 root         INFO     Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 0.054269\n",
      "Reconstruction: 0.052173, Regularization: 0.002096\n",
      "2019-04-09 20:43:53,493 root         INFO     Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 0.071122\n",
      "Reconstruction: 0.068035, Regularization: 0.003087\n",
      "2019-04-09 20:43:53,520 root         INFO     Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 0.050633\n",
      "Reconstruction: 0.048649, Regularization: 0.001984\n",
      "2019-04-09 20:43:53,547 root         INFO     Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 0.053157\n",
      "Reconstruction: 0.051028, Regularization: 0.002130\n",
      "2019-04-09 20:43:53,585 root         INFO     ====> Epoch: 83 Average loss: 0.0504\n",
      "2019-04-09 20:43:53,606 root         INFO     Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 0.046835\n",
      "Reconstruction: 0.045110, Regularization: 0.001725\n",
      "2019-04-09 20:43:53,633 root         INFO     Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 0.052668\n",
      "Reconstruction: 0.050601, Regularization: 0.002068\n",
      "2019-04-09 20:43:53,660 root         INFO     Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 0.051319\n",
      "Reconstruction: 0.049413, Regularization: 0.001906\n",
      "2019-04-09 20:43:53,686 root         INFO     Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 0.045870\n",
      "Reconstruction: 0.044105, Regularization: 0.001765\n",
      "2019-04-09 20:43:53,713 root         INFO     Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 0.041348\n",
      "Reconstruction: 0.039921, Regularization: 0.001426\n",
      "2019-04-09 20:43:53,740 root         INFO     Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 0.050880\n",
      "Reconstruction: 0.048803, Regularization: 0.002076\n",
      "2019-04-09 20:43:53,766 root         INFO     Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 0.042652\n",
      "Reconstruction: 0.041110, Regularization: 0.001542\n",
      "2019-04-09 20:43:53,793 root         INFO     Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 0.044313\n",
      "Reconstruction: 0.042624, Regularization: 0.001690\n",
      "2019-04-09 20:43:53,831 root         INFO     ====> Epoch: 84 Average loss: 0.0504\n",
      "2019-04-09 20:43:53,852 root         INFO     Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 0.049760\n",
      "Reconstruction: 0.047801, Regularization: 0.001958\n",
      "2019-04-09 20:43:53,879 root         INFO     Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 0.043956\n",
      "Reconstruction: 0.042178, Regularization: 0.001779\n",
      "2019-04-09 20:43:53,906 root         INFO     Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 0.039827\n",
      "Reconstruction: 0.038386, Regularization: 0.001441\n",
      "2019-04-09 20:43:53,933 root         INFO     Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 0.053261\n",
      "Reconstruction: 0.050910, Regularization: 0.002352\n",
      "2019-04-09 20:43:53,960 root         INFO     Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 0.047387\n",
      "Reconstruction: 0.045350, Regularization: 0.002037\n",
      "2019-04-09 20:43:53,987 root         INFO     Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 0.044005\n",
      "Reconstruction: 0.042200, Regularization: 0.001805\n",
      "2019-04-09 20:43:54,014 root         INFO     Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 0.044415\n",
      "Reconstruction: 0.042581, Regularization: 0.001834\n",
      "2019-04-09 20:43:54,040 root         INFO     Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 0.046441\n",
      "Reconstruction: 0.044450, Regularization: 0.001990\n",
      "2019-04-09 20:43:54,079 root         INFO     ====> Epoch: 85 Average loss: 0.0500\n",
      "2019-04-09 20:43:54,100 root         INFO     Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 0.056648\n",
      "Reconstruction: 0.054082, Regularization: 0.002566\n",
      "2019-04-09 20:43:54,128 root         INFO     Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 0.054514\n",
      "Reconstruction: 0.051984, Regularization: 0.002530\n",
      "2019-04-09 20:43:54,156 root         INFO     Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 0.065677\n",
      "Reconstruction: 0.062240, Regularization: 0.003436\n",
      "2019-04-09 20:43:54,184 root         INFO     Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 0.052476\n",
      "Reconstruction: 0.050221, Regularization: 0.002254\n",
      "2019-04-09 20:43:54,212 root         INFO     Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 0.060535\n",
      "Reconstruction: 0.057451, Regularization: 0.003083\n",
      "2019-04-09 20:43:54,240 root         INFO     Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 0.046624\n",
      "Reconstruction: 0.044454, Regularization: 0.002170\n",
      "2019-04-09 20:43:54,268 root         INFO     Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 0.047123\n",
      "Reconstruction: 0.044995, Regularization: 0.002128\n",
      "2019-04-09 20:43:54,296 root         INFO     Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 0.041866\n",
      "Reconstruction: 0.040117, Regularization: 0.001748\n",
      "2019-04-09 20:43:54,334 root         INFO     ====> Epoch: 86 Average loss: 0.0498\n",
      "2019-04-09 20:43:54,355 root         INFO     Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 0.038264\n",
      "Reconstruction: 0.036619, Regularization: 0.001645\n",
      "2019-04-09 20:43:54,382 root         INFO     Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 0.048210\n",
      "Reconstruction: 0.045927, Regularization: 0.002284\n",
      "2019-04-09 20:43:54,409 root         INFO     Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 0.044376\n",
      "Reconstruction: 0.042215, Regularization: 0.002161\n",
      "2019-04-09 20:43:54,436 root         INFO     Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 0.040520\n",
      "Reconstruction: 0.038748, Regularization: 0.001772\n",
      "2019-04-09 20:43:54,463 root         INFO     Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 0.049402\n",
      "Reconstruction: 0.046830, Regularization: 0.002572\n",
      "2019-04-09 20:43:54,490 root         INFO     Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 0.055822\n",
      "Reconstruction: 0.052809, Regularization: 0.003013\n",
      "2019-04-09 20:43:54,517 root         INFO     Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 0.040573\n",
      "Reconstruction: 0.038661, Regularization: 0.001911\n",
      "2019-04-09 20:43:54,544 root         INFO     Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 0.057472\n",
      "Reconstruction: 0.054499, Regularization: 0.002973\n",
      "2019-04-09 20:43:54,582 root         INFO     ====> Epoch: 87 Average loss: 0.0497\n",
      "2019-04-09 20:43:54,603 root         INFO     Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 0.047846\n",
      "Reconstruction: 0.045317, Regularization: 0.002528\n",
      "2019-04-09 20:43:54,630 root         INFO     Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 0.045275\n",
      "Reconstruction: 0.042971, Regularization: 0.002305\n",
      "2019-04-09 20:43:54,657 root         INFO     Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 0.041884\n",
      "Reconstruction: 0.039857, Regularization: 0.002027\n",
      "2019-04-09 20:43:54,684 root         INFO     Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 0.051139\n",
      "Reconstruction: 0.048430, Regularization: 0.002708\n",
      "2019-04-09 20:43:54,711 root         INFO     Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 0.049207\n",
      "Reconstruction: 0.046544, Regularization: 0.002662\n",
      "2019-04-09 20:43:54,738 root         INFO     Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 0.054706\n",
      "Reconstruction: 0.051835, Regularization: 0.002871\n",
      "2019-04-09 20:43:54,766 root         INFO     Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 0.049800\n",
      "Reconstruction: 0.047114, Regularization: 0.002686\n",
      "2019-04-09 20:43:54,793 root         INFO     Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 0.049736\n",
      "Reconstruction: 0.046895, Regularization: 0.002841\n",
      "2019-04-09 20:43:54,831 root         INFO     ====> Epoch: 88 Average loss: 0.0498\n",
      "2019-04-09 20:43:54,852 root         INFO     Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 0.062811\n",
      "Reconstruction: 0.058965, Regularization: 0.003846\n",
      "2019-04-09 20:43:54,879 root         INFO     Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 0.050579\n",
      "Reconstruction: 0.047869, Regularization: 0.002710\n",
      "2019-04-09 20:43:54,906 root         INFO     Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 0.055604\n",
      "Reconstruction: 0.052307, Regularization: 0.003296\n",
      "2019-04-09 20:43:54,933 root         INFO     Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 0.052449\n",
      "Reconstruction: 0.049327, Regularization: 0.003122\n",
      "2019-04-09 20:43:54,960 root         INFO     Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 0.041063\n",
      "Reconstruction: 0.038821, Regularization: 0.002242\n",
      "2019-04-09 20:43:54,987 root         INFO     Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 0.052376\n",
      "Reconstruction: 0.049153, Regularization: 0.003223\n",
      "2019-04-09 20:43:55,014 root         INFO     Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 0.045152\n",
      "Reconstruction: 0.042597, Regularization: 0.002555\n",
      "2019-04-09 20:43:55,040 root         INFO     Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 0.049894\n",
      "Reconstruction: 0.046998, Regularization: 0.002896\n",
      "2019-04-09 20:43:55,077 root         INFO     ====> Epoch: 89 Average loss: 0.0495\n",
      "2019-04-09 20:43:55,099 root         INFO     Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 0.060820\n",
      "Reconstruction: 0.056964, Regularization: 0.003856\n",
      "2019-04-09 20:43:55,125 root         INFO     Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 0.050421\n",
      "Reconstruction: 0.047217, Regularization: 0.003204\n",
      "2019-04-09 20:43:55,151 root         INFO     Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 0.044894\n",
      "Reconstruction: 0.042409, Regularization: 0.002485\n",
      "2019-04-09 20:43:55,177 root         INFO     Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 0.049791\n",
      "Reconstruction: 0.046711, Regularization: 0.003080\n",
      "2019-04-09 20:43:55,202 root         INFO     Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 0.048702\n",
      "Reconstruction: 0.045866, Regularization: 0.002836\n",
      "2019-04-09 20:43:55,228 root         INFO     Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 0.053091\n",
      "Reconstruction: 0.049696, Regularization: 0.003395\n",
      "2019-04-09 20:43:55,254 root         INFO     Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 0.045960\n",
      "Reconstruction: 0.043261, Regularization: 0.002700\n",
      "2019-04-09 20:43:55,281 root         INFO     Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 0.047681\n",
      "Reconstruction: 0.044757, Regularization: 0.002923\n",
      "2019-04-09 20:43:55,320 root         INFO     ====> Epoch: 90 Average loss: 0.0492\n",
      "2019-04-09 20:43:55,341 root         INFO     Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 0.061752\n",
      "Reconstruction: 0.057576, Regularization: 0.004176\n",
      "2019-04-09 20:43:55,368 root         INFO     Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 0.061362\n",
      "Reconstruction: 0.056964, Regularization: 0.004398\n",
      "2019-04-09 20:43:55,395 root         INFO     Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 0.056333\n",
      "Reconstruction: 0.052501, Regularization: 0.003831\n",
      "2019-04-09 20:43:55,422 root         INFO     Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 0.055414\n",
      "Reconstruction: 0.051705, Regularization: 0.003709\n",
      "2019-04-09 20:43:55,447 root         INFO     Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 0.055021\n",
      "Reconstruction: 0.051233, Regularization: 0.003789\n",
      "2019-04-09 20:43:55,472 root         INFO     Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 0.050755\n",
      "Reconstruction: 0.047383, Regularization: 0.003372\n",
      "2019-04-09 20:43:55,498 root         INFO     Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 0.050550\n",
      "Reconstruction: 0.046911, Regularization: 0.003639\n",
      "2019-04-09 20:43:55,524 root         INFO     Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 0.046020\n",
      "Reconstruction: 0.042743, Regularization: 0.003277\n",
      "2019-04-09 20:43:55,561 root         INFO     ====> Epoch: 91 Average loss: 0.0488\n",
      "2019-04-09 20:43:55,582 root         INFO     Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 0.043415\n",
      "Reconstruction: 0.040544, Regularization: 0.002871\n",
      "2019-04-09 20:43:55,609 root         INFO     Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 0.050659\n",
      "Reconstruction: 0.047274, Regularization: 0.003386\n",
      "2019-04-09 20:43:55,637 root         INFO     Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 0.037095\n",
      "Reconstruction: 0.034755, Regularization: 0.002339\n",
      "2019-04-09 20:43:55,664 root         INFO     Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 0.049691\n",
      "Reconstruction: 0.045980, Regularization: 0.003710\n",
      "2019-04-09 20:43:55,691 root         INFO     Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 0.044847\n",
      "Reconstruction: 0.041778, Regularization: 0.003069\n",
      "2019-04-09 20:43:55,718 root         INFO     Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 0.039119\n",
      "Reconstruction: 0.036627, Regularization: 0.002491\n",
      "2019-04-09 20:43:55,746 root         INFO     Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 0.048566\n",
      "Reconstruction: 0.045193, Regularization: 0.003374\n",
      "2019-04-09 20:43:55,773 root         INFO     Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 0.054167\n",
      "Reconstruction: 0.050257, Regularization: 0.003910\n",
      "2019-04-09 20:43:55,811 root         INFO     ====> Epoch: 92 Average loss: 0.0488\n",
      "2019-04-09 20:43:55,832 root         INFO     Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 0.056753\n",
      "Reconstruction: 0.052342, Regularization: 0.004412\n",
      "2019-04-09 20:43:55,859 root         INFO     Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 0.055313\n",
      "Reconstruction: 0.051259, Regularization: 0.004054\n",
      "2019-04-09 20:43:55,886 root         INFO     Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 0.044740\n",
      "Reconstruction: 0.041556, Regularization: 0.003184\n",
      "2019-04-09 20:43:55,913 root         INFO     Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 0.041185\n",
      "Reconstruction: 0.038418, Regularization: 0.002767\n",
      "2019-04-09 20:43:55,940 root         INFO     Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 0.046900\n",
      "Reconstruction: 0.043378, Regularization: 0.003522\n",
      "2019-04-09 20:43:55,966 root         INFO     Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 0.042365\n",
      "Reconstruction: 0.039325, Regularization: 0.003040\n",
      "2019-04-09 20:43:55,992 root         INFO     Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 0.054886\n",
      "Reconstruction: 0.050701, Regularization: 0.004185\n",
      "2019-04-09 20:43:56,019 root         INFO     Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 0.054817\n",
      "Reconstruction: 0.050207, Regularization: 0.004610\n",
      "2019-04-09 20:43:56,057 root         INFO     ====> Epoch: 93 Average loss: 0.0486\n",
      "2019-04-09 20:43:56,078 root         INFO     Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 0.049466\n",
      "Reconstruction: 0.045493, Regularization: 0.003973\n",
      "2019-04-09 20:43:56,105 root         INFO     Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 0.036971\n",
      "Reconstruction: 0.034168, Regularization: 0.002802\n",
      "2019-04-09 20:43:56,132 root         INFO     Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 0.046420\n",
      "Reconstruction: 0.042922, Regularization: 0.003498\n",
      "2019-04-09 20:43:56,159 root         INFO     Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 0.051300\n",
      "Reconstruction: 0.047080, Regularization: 0.004219\n",
      "2019-04-09 20:43:56,186 root         INFO     Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 0.051763\n",
      "Reconstruction: 0.047720, Regularization: 0.004043\n",
      "2019-04-09 20:43:56,213 root         INFO     Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 0.048745\n",
      "Reconstruction: 0.044871, Regularization: 0.003874\n",
      "2019-04-09 20:43:56,240 root         INFO     Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 0.041715\n",
      "Reconstruction: 0.038864, Regularization: 0.002851\n",
      "2019-04-09 20:43:56,267 root         INFO     Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 0.044533\n",
      "Reconstruction: 0.041566, Regularization: 0.002967\n",
      "2019-04-09 20:43:56,305 root         INFO     ====> Epoch: 94 Average loss: 0.0483\n",
      "2019-04-09 20:43:56,327 root         INFO     Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 0.047573\n",
      "Reconstruction: 0.043908, Regularization: 0.003665\n",
      "2019-04-09 20:43:56,353 root         INFO     Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 0.042368\n",
      "Reconstruction: 0.038998, Regularization: 0.003371\n",
      "2019-04-09 20:43:56,379 root         INFO     Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 0.038403\n",
      "Reconstruction: 0.035644, Regularization: 0.002760\n",
      "2019-04-09 20:43:56,405 root         INFO     Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 0.044600\n",
      "Reconstruction: 0.040732, Regularization: 0.003868\n",
      "2019-04-09 20:43:56,431 root         INFO     Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 0.054267\n",
      "Reconstruction: 0.049388, Regularization: 0.004878\n",
      "2019-04-09 20:43:56,458 root         INFO     Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 0.052398\n",
      "Reconstruction: 0.048141, Regularization: 0.004257\n",
      "2019-04-09 20:43:56,484 root         INFO     Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 0.043428\n",
      "Reconstruction: 0.039885, Regularization: 0.003544\n",
      "2019-04-09 20:43:56,510 root         INFO     Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 0.045467\n",
      "Reconstruction: 0.041339, Regularization: 0.004129\n",
      "2019-04-09 20:43:56,547 root         INFO     ====> Epoch: 95 Average loss: 0.0483\n",
      "2019-04-09 20:43:56,569 root         INFO     Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 0.047480\n",
      "Reconstruction: 0.043255, Regularization: 0.004225\n",
      "2019-04-09 20:43:56,595 root         INFO     Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 0.053312\n",
      "Reconstruction: 0.048284, Regularization: 0.005029\n",
      "2019-04-09 20:43:56,621 root         INFO     Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 0.051922\n",
      "Reconstruction: 0.047022, Regularization: 0.004900\n",
      "2019-04-09 20:43:56,647 root         INFO     Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 0.052727\n",
      "Reconstruction: 0.047461, Regularization: 0.005265\n",
      "2019-04-09 20:43:56,673 root         INFO     Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 0.053674\n",
      "Reconstruction: 0.048775, Regularization: 0.004900\n",
      "2019-04-09 20:43:56,698 root         INFO     Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 0.051245\n",
      "Reconstruction: 0.046570, Regularization: 0.004676\n",
      "2019-04-09 20:43:56,725 root         INFO     Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 0.046413\n",
      "Reconstruction: 0.041938, Regularization: 0.004475\n",
      "2019-04-09 20:43:56,751 root         INFO     Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 0.043610\n",
      "Reconstruction: 0.039595, Regularization: 0.004015\n",
      "2019-04-09 20:43:56,789 root         INFO     ====> Epoch: 96 Average loss: 0.0477\n",
      "2019-04-09 20:43:56,810 root         INFO     Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 0.045848\n",
      "Reconstruction: 0.041644, Regularization: 0.004204\n",
      "2019-04-09 20:43:56,837 root         INFO     Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 0.041260\n",
      "Reconstruction: 0.037595, Regularization: 0.003665\n",
      "2019-04-09 20:43:56,863 root         INFO     Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 0.058063\n",
      "Reconstruction: 0.052691, Regularization: 0.005372\n",
      "2019-04-09 20:43:56,889 root         INFO     Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 0.052465\n",
      "Reconstruction: 0.047236, Regularization: 0.005229\n",
      "2019-04-09 20:43:56,915 root         INFO     Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 0.043883\n",
      "Reconstruction: 0.040185, Regularization: 0.003698\n",
      "2019-04-09 20:43:56,940 root         INFO     Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 0.044058\n",
      "Reconstruction: 0.039787, Regularization: 0.004271\n",
      "2019-04-09 20:43:56,966 root         INFO     Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 0.052344\n",
      "Reconstruction: 0.047193, Regularization: 0.005151\n",
      "2019-04-09 20:43:56,992 root         INFO     Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 0.042830\n",
      "Reconstruction: 0.038990, Regularization: 0.003840\n",
      "2019-04-09 20:43:57,029 root         INFO     ====> Epoch: 97 Average loss: 0.0477\n",
      "2019-04-09 20:43:57,050 root         INFO     Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 0.050526\n",
      "Reconstruction: 0.045534, Regularization: 0.004992\n",
      "2019-04-09 20:43:57,077 root         INFO     Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 0.049311\n",
      "Reconstruction: 0.044331, Regularization: 0.004980\n",
      "2019-04-09 20:43:57,104 root         INFO     Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 0.044749\n",
      "Reconstruction: 0.040733, Regularization: 0.004016\n",
      "2019-04-09 20:43:57,131 root         INFO     Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 0.037827\n",
      "Reconstruction: 0.034262, Regularization: 0.003564\n",
      "2019-04-09 20:43:57,158 root         INFO     Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 0.051734\n",
      "Reconstruction: 0.045888, Regularization: 0.005846\n",
      "2019-04-09 20:43:57,185 root         INFO     Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 0.044642\n",
      "Reconstruction: 0.040035, Regularization: 0.004607\n",
      "2019-04-09 20:43:57,211 root         INFO     Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 0.054829\n",
      "Reconstruction: 0.048207, Regularization: 0.006622\n",
      "2019-04-09 20:43:57,238 root         INFO     Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 0.064829\n",
      "Reconstruction: 0.057452, Regularization: 0.007377\n",
      "2019-04-09 20:43:57,276 root         INFO     ====> Epoch: 98 Average loss: 0.0472\n",
      "2019-04-09 20:43:57,297 root         INFO     Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 0.036456\n",
      "Reconstruction: 0.032771, Regularization: 0.003685\n",
      "2019-04-09 20:43:57,324 root         INFO     Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 0.049526\n",
      "Reconstruction: 0.044768, Regularization: 0.004758\n",
      "2019-04-09 20:43:57,351 root         INFO     Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 0.046180\n",
      "Reconstruction: 0.041478, Regularization: 0.004702\n",
      "2019-04-09 20:43:57,378 root         INFO     Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 0.041743\n",
      "Reconstruction: 0.037517, Regularization: 0.004226\n",
      "2019-04-09 20:43:57,405 root         INFO     Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 0.044646\n",
      "Reconstruction: 0.040464, Regularization: 0.004181\n",
      "2019-04-09 20:43:57,432 root         INFO     Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 0.055597\n",
      "Reconstruction: 0.049585, Regularization: 0.006012\n",
      "2019-04-09 20:43:57,459 root         INFO     Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 0.047544\n",
      "Reconstruction: 0.042197, Regularization: 0.005346\n",
      "2019-04-09 20:43:57,485 root         INFO     Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 0.039124\n",
      "Reconstruction: 0.034972, Regularization: 0.004151\n",
      "2019-04-09 20:43:57,524 root         INFO     ====> Epoch: 99 Average loss: 0.0472\n",
      "2019-04-09 20:43:57,545 root         INFO     Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 0.050951\n",
      "Reconstruction: 0.044501, Regularization: 0.006450\n",
      "2019-04-09 20:43:57,573 root         INFO     Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 0.042151\n",
      "Reconstruction: 0.037612, Regularization: 0.004539\n",
      "2019-04-09 20:43:57,600 root         INFO     Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 0.051020\n",
      "Reconstruction: 0.045213, Regularization: 0.005807\n",
      "2019-04-09 20:43:57,626 root         INFO     Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 0.043174\n",
      "Reconstruction: 0.038296, Regularization: 0.004878\n",
      "2019-04-09 20:43:57,652 root         INFO     Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 0.048735\n",
      "Reconstruction: 0.043111, Regularization: 0.005624\n",
      "2019-04-09 20:43:57,677 root         INFO     Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 0.044490\n",
      "Reconstruction: 0.039449, Regularization: 0.005041\n",
      "2019-04-09 20:43:57,702 root         INFO     Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 0.041581\n",
      "Reconstruction: 0.037244, Regularization: 0.004337\n",
      "2019-04-09 20:43:57,727 root         INFO     Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 0.040279\n",
      "Reconstruction: 0.035698, Regularization: 0.004581\n",
      "2019-04-09 20:43:57,763 root         INFO     ====> Epoch: 100 Average loss: 0.0469\n",
      "2019-04-09 20:43:57,784 root         INFO     Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 0.042521\n",
      "Reconstruction: 0.037706, Regularization: 0.004815\n",
      "2019-04-09 20:43:57,812 root         INFO     Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 0.046824\n",
      "Reconstruction: 0.041413, Regularization: 0.005411\n",
      "2019-04-09 20:43:57,838 root         INFO     Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 0.054156\n",
      "Reconstruction: 0.047883, Regularization: 0.006273\n",
      "2019-04-09 20:43:57,865 root         INFO     Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 0.046953\n",
      "Reconstruction: 0.041543, Regularization: 0.005410\n",
      "2019-04-09 20:43:57,892 root         INFO     Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 0.047867\n",
      "Reconstruction: 0.042509, Regularization: 0.005358\n",
      "2019-04-09 20:43:57,919 root         INFO     Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 0.053072\n",
      "Reconstruction: 0.046890, Regularization: 0.006182\n",
      "2019-04-09 20:43:57,946 root         INFO     Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 0.048667\n",
      "Reconstruction: 0.042678, Regularization: 0.005989\n",
      "2019-04-09 20:43:57,973 root         INFO     Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 0.039571\n",
      "Reconstruction: 0.035172, Regularization: 0.004399\n",
      "2019-04-09 20:43:58,013 root         INFO     ====> Epoch: 101 Average loss: 0.0470\n",
      "2019-04-09 20:43:58,034 root         INFO     Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 0.053743\n",
      "Reconstruction: 0.047311, Regularization: 0.006432\n",
      "2019-04-09 20:43:58,062 root         INFO     Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 0.037574\n",
      "Reconstruction: 0.033156, Regularization: 0.004418\n",
      "2019-04-09 20:43:58,089 root         INFO     Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 0.040984\n",
      "Reconstruction: 0.036880, Regularization: 0.004104\n",
      "2019-04-09 20:43:58,114 root         INFO     Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 0.044060\n",
      "Reconstruction: 0.038843, Regularization: 0.005217\n",
      "2019-04-09 20:43:58,140 root         INFO     Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 0.049670\n",
      "Reconstruction: 0.042647, Regularization: 0.007022\n",
      "2019-04-09 20:43:58,165 root         INFO     Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 0.038046\n",
      "Reconstruction: 0.034157, Regularization: 0.003888\n",
      "2019-04-09 20:43:58,190 root         INFO     Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 0.039648\n",
      "Reconstruction: 0.034909, Regularization: 0.004739\n",
      "2019-04-09 20:43:58,216 root         INFO     Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 0.044542\n",
      "Reconstruction: 0.038792, Regularization: 0.005749\n",
      "2019-04-09 20:43:58,253 root         INFO     ====> Epoch: 102 Average loss: 0.0467\n",
      "2019-04-09 20:43:58,274 root         INFO     Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 0.044214\n",
      "Reconstruction: 0.038672, Regularization: 0.005541\n",
      "2019-04-09 20:43:58,301 root         INFO     Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 0.053243\n",
      "Reconstruction: 0.046420, Regularization: 0.006823\n",
      "2019-04-09 20:43:58,327 root         INFO     Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 0.052849\n",
      "Reconstruction: 0.046129, Regularization: 0.006719\n",
      "2019-04-09 20:43:58,354 root         INFO     Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 0.040585\n",
      "Reconstruction: 0.035500, Regularization: 0.005085\n",
      "2019-04-09 20:43:58,380 root         INFO     Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 0.051999\n",
      "Reconstruction: 0.044869, Regularization: 0.007130\n",
      "2019-04-09 20:43:58,406 root         INFO     Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 0.042460\n",
      "Reconstruction: 0.037565, Regularization: 0.004895\n",
      "2019-04-09 20:43:58,433 root         INFO     Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 0.045872\n",
      "Reconstruction: 0.039804, Regularization: 0.006068\n",
      "2019-04-09 20:43:58,459 root         INFO     Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 0.039114\n",
      "Reconstruction: 0.034409, Regularization: 0.004705\n",
      "2019-04-09 20:43:58,497 root         INFO     ====> Epoch: 103 Average loss: 0.0462\n",
      "2019-04-09 20:43:58,518 root         INFO     Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 0.033598\n",
      "Reconstruction: 0.029900, Regularization: 0.003698\n",
      "2019-04-09 20:43:58,546 root         INFO     Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 0.038730\n",
      "Reconstruction: 0.033188, Regularization: 0.005542\n",
      "2019-04-09 20:43:58,572 root         INFO     Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 0.049822\n",
      "Reconstruction: 0.043576, Regularization: 0.006246\n",
      "2019-04-09 20:43:58,598 root         INFO     Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 0.047429\n",
      "Reconstruction: 0.041269, Regularization: 0.006159\n",
      "2019-04-09 20:43:58,624 root         INFO     Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 0.038831\n",
      "Reconstruction: 0.033784, Regularization: 0.005047\n",
      "2019-04-09 20:43:58,650 root         INFO     Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 0.046254\n",
      "Reconstruction: 0.039808, Regularization: 0.006447\n",
      "2019-04-09 20:43:58,676 root         INFO     Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 0.045733\n",
      "Reconstruction: 0.039618, Regularization: 0.006115\n",
      "2019-04-09 20:43:58,702 root         INFO     Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 0.048216\n",
      "Reconstruction: 0.041943, Regularization: 0.006273\n",
      "2019-04-09 20:43:58,740 root         INFO     ====> Epoch: 104 Average loss: 0.0462\n",
      "2019-04-09 20:43:58,761 root         INFO     Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 0.044822\n",
      "Reconstruction: 0.039236, Regularization: 0.005586\n",
      "2019-04-09 20:43:58,787 root         INFO     Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 0.045415\n",
      "Reconstruction: 0.039078, Regularization: 0.006337\n",
      "2019-04-09 20:43:58,813 root         INFO     Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 0.040176\n",
      "Reconstruction: 0.034815, Regularization: 0.005361\n",
      "2019-04-09 20:43:58,838 root         INFO     Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 0.052901\n",
      "Reconstruction: 0.045083, Regularization: 0.007818\n",
      "2019-04-09 20:43:58,863 root         INFO     Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 0.038649\n",
      "Reconstruction: 0.033395, Regularization: 0.005255\n",
      "2019-04-09 20:43:58,888 root         INFO     Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 0.046873\n",
      "Reconstruction: 0.040544, Regularization: 0.006328\n",
      "2019-04-09 20:43:58,913 root         INFO     Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 0.050445\n",
      "Reconstruction: 0.042881, Regularization: 0.007563\n",
      "2019-04-09 20:43:58,938 root         INFO     Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 0.046049\n",
      "Reconstruction: 0.040072, Regularization: 0.005977\n",
      "2019-04-09 20:43:58,975 root         INFO     ====> Epoch: 105 Average loss: 0.0460\n",
      "2019-04-09 20:43:58,996 root         INFO     Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 0.050441\n",
      "Reconstruction: 0.042612, Regularization: 0.007830\n",
      "2019-04-09 20:43:59,023 root         INFO     Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 0.040107\n",
      "Reconstruction: 0.034716, Regularization: 0.005391\n",
      "2019-04-09 20:43:59,050 root         INFO     Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 0.046488\n",
      "Reconstruction: 0.039713, Regularization: 0.006775\n",
      "2019-04-09 20:43:59,077 root         INFO     Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 0.044770\n",
      "Reconstruction: 0.038320, Regularization: 0.006450\n",
      "2019-04-09 20:43:59,103 root         INFO     Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 0.045127\n",
      "Reconstruction: 0.038735, Regularization: 0.006392\n",
      "2019-04-09 20:43:59,130 root         INFO     Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 0.046862\n",
      "Reconstruction: 0.039923, Regularization: 0.006939\n",
      "2019-04-09 20:43:59,157 root         INFO     Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 0.044492\n",
      "Reconstruction: 0.038996, Regularization: 0.005496\n",
      "2019-04-09 20:43:59,184 root         INFO     Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 0.045784\n",
      "Reconstruction: 0.039068, Regularization: 0.006716\n",
      "2019-04-09 20:43:59,223 root         INFO     ====> Epoch: 106 Average loss: 0.0456\n",
      "2019-04-09 20:43:59,244 root         INFO     Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 0.036971\n",
      "Reconstruction: 0.031425, Regularization: 0.005547\n",
      "2019-04-09 20:43:59,271 root         INFO     Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 0.054018\n",
      "Reconstruction: 0.045655, Regularization: 0.008363\n",
      "2019-04-09 20:43:59,297 root         INFO     Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 0.040981\n",
      "Reconstruction: 0.035521, Regularization: 0.005461\n",
      "2019-04-09 20:43:59,324 root         INFO     Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 0.061441\n",
      "Reconstruction: 0.050676, Regularization: 0.010765\n",
      "2019-04-09 20:43:59,351 root         INFO     Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 0.053761\n",
      "Reconstruction: 0.044940, Regularization: 0.008821\n",
      "2019-04-09 20:43:59,378 root         INFO     Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 0.049123\n",
      "Reconstruction: 0.042151, Regularization: 0.006972\n",
      "2019-04-09 20:43:59,405 root         INFO     Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 0.051188\n",
      "Reconstruction: 0.043450, Regularization: 0.007737\n",
      "2019-04-09 20:43:59,431 root         INFO     Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 0.042553\n",
      "Reconstruction: 0.035911, Regularization: 0.006642\n",
      "2019-04-09 20:43:59,470 root         INFO     ====> Epoch: 107 Average loss: 0.0457\n",
      "2019-04-09 20:43:59,491 root         INFO     Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 0.047875\n",
      "Reconstruction: 0.040227, Regularization: 0.007648\n",
      "2019-04-09 20:43:59,517 root         INFO     Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 0.043881\n",
      "Reconstruction: 0.036750, Regularization: 0.007132\n",
      "2019-04-09 20:43:59,543 root         INFO     Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 0.044808\n",
      "Reconstruction: 0.038464, Regularization: 0.006344\n",
      "2019-04-09 20:43:59,569 root         INFO     Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 0.037192\n",
      "Reconstruction: 0.032519, Regularization: 0.004673\n",
      "2019-04-09 20:43:59,593 root         INFO     Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 0.043418\n",
      "Reconstruction: 0.036928, Regularization: 0.006490\n",
      "2019-04-09 20:43:59,618 root         INFO     Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 0.042692\n",
      "Reconstruction: 0.035352, Regularization: 0.007340\n",
      "2019-04-09 20:43:59,643 root         INFO     Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 0.057234\n",
      "Reconstruction: 0.047125, Regularization: 0.010109\n",
      "2019-04-09 20:43:59,669 root         INFO     Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 0.043431\n",
      "Reconstruction: 0.036407, Regularization: 0.007024\n",
      "2019-04-09 20:43:59,705 root         INFO     ====> Epoch: 108 Average loss: 0.0450\n",
      "2019-04-09 20:43:59,726 root         INFO     Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 0.040733\n",
      "Reconstruction: 0.034892, Regularization: 0.005840\n",
      "2019-04-09 20:43:59,754 root         INFO     Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 0.046976\n",
      "Reconstruction: 0.039327, Regularization: 0.007649\n",
      "2019-04-09 20:43:59,781 root         INFO     Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 0.041079\n",
      "Reconstruction: 0.035309, Regularization: 0.005770\n",
      "2019-04-09 20:43:59,807 root         INFO     Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 0.042366\n",
      "Reconstruction: 0.036123, Regularization: 0.006243\n",
      "2019-04-09 20:43:59,834 root         INFO     Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 0.043220\n",
      "Reconstruction: 0.035664, Regularization: 0.007556\n",
      "2019-04-09 20:43:59,861 root         INFO     Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 0.050901\n",
      "Reconstruction: 0.042163, Regularization: 0.008738\n",
      "2019-04-09 20:43:59,889 root         INFO     Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 0.040078\n",
      "Reconstruction: 0.034309, Regularization: 0.005769\n",
      "2019-04-09 20:43:59,916 root         INFO     Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 0.056532\n",
      "Reconstruction: 0.045471, Regularization: 0.011061\n",
      "2019-04-09 20:43:59,954 root         INFO     ====> Epoch: 109 Average loss: 0.0451\n",
      "2019-04-09 20:43:59,975 root         INFO     Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 0.044543\n",
      "Reconstruction: 0.037996, Regularization: 0.006547\n",
      "2019-04-09 20:44:00,003 root         INFO     Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 0.040855\n",
      "Reconstruction: 0.034286, Regularization: 0.006568\n",
      "2019-04-09 20:44:00,030 root         INFO     Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 0.040880\n",
      "Reconstruction: 0.034771, Regularization: 0.006110\n",
      "2019-04-09 20:44:00,056 root         INFO     Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 0.050213\n",
      "Reconstruction: 0.042489, Regularization: 0.007724\n",
      "2019-04-09 20:44:00,083 root         INFO     Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 0.050280\n",
      "Reconstruction: 0.042039, Regularization: 0.008241\n",
      "2019-04-09 20:44:00,109 root         INFO     Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 0.043727\n",
      "Reconstruction: 0.035982, Regularization: 0.007745\n",
      "2019-04-09 20:44:00,135 root         INFO     Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 0.053495\n",
      "Reconstruction: 0.043037, Regularization: 0.010458\n",
      "2019-04-09 20:44:00,162 root         INFO     Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 0.046376\n",
      "Reconstruction: 0.038632, Regularization: 0.007744\n",
      "2019-04-09 20:44:00,201 root         INFO     ====> Epoch: 110 Average loss: 0.0452\n",
      "2019-04-09 20:44:00,222 root         INFO     Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 0.042098\n",
      "Reconstruction: 0.036187, Regularization: 0.005910\n",
      "2019-04-09 20:44:00,249 root         INFO     Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 0.038247\n",
      "Reconstruction: 0.032904, Regularization: 0.005344\n",
      "2019-04-09 20:44:00,277 root         INFO     Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 0.045383\n",
      "Reconstruction: 0.037853, Regularization: 0.007529\n",
      "2019-04-09 20:44:00,303 root         INFO     Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 0.048658\n",
      "Reconstruction: 0.041423, Regularization: 0.007235\n",
      "2019-04-09 20:44:00,330 root         INFO     Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 0.041039\n",
      "Reconstruction: 0.034523, Regularization: 0.006516\n",
      "2019-04-09 20:44:00,356 root         INFO     Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 0.047692\n",
      "Reconstruction: 0.040215, Regularization: 0.007478\n",
      "2019-04-09 20:44:00,383 root         INFO     Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 0.048807\n",
      "Reconstruction: 0.040753, Regularization: 0.008055\n",
      "2019-04-09 20:44:00,409 root         INFO     Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 0.038709\n",
      "Reconstruction: 0.032859, Regularization: 0.005850\n",
      "2019-04-09 20:44:00,447 root         INFO     ====> Epoch: 111 Average loss: 0.0449\n",
      "2019-04-09 20:44:00,468 root         INFO     Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 0.050170\n",
      "Reconstruction: 0.041527, Regularization: 0.008643\n",
      "2019-04-09 20:44:00,495 root         INFO     Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 0.046458\n",
      "Reconstruction: 0.038404, Regularization: 0.008054\n",
      "2019-04-09 20:44:00,523 root         INFO     Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 0.050830\n",
      "Reconstruction: 0.041255, Regularization: 0.009575\n",
      "2019-04-09 20:44:00,552 root         INFO     Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 0.046483\n",
      "Reconstruction: 0.038494, Regularization: 0.007988\n",
      "2019-04-09 20:44:00,581 root         INFO     Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 0.044210\n",
      "Reconstruction: 0.036726, Regularization: 0.007484\n",
      "2019-04-09 20:44:00,610 root         INFO     Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 0.048660\n",
      "Reconstruction: 0.040210, Regularization: 0.008450\n",
      "2019-04-09 20:44:00,638 root         INFO     Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 0.043910\n",
      "Reconstruction: 0.036732, Regularization: 0.007178\n",
      "2019-04-09 20:44:00,667 root         INFO     Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 0.046792\n",
      "Reconstruction: 0.039039, Regularization: 0.007753\n",
      "2019-04-09 20:44:00,706 root         INFO     ====> Epoch: 112 Average loss: 0.0449\n",
      "2019-04-09 20:44:00,727 root         INFO     Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 0.053030\n",
      "Reconstruction: 0.043122, Regularization: 0.009909\n",
      "2019-04-09 20:44:00,754 root         INFO     Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 0.046174\n",
      "Reconstruction: 0.037316, Regularization: 0.008858\n",
      "2019-04-09 20:44:00,781 root         INFO     Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 0.048427\n",
      "Reconstruction: 0.041014, Regularization: 0.007413\n",
      "2019-04-09 20:44:00,808 root         INFO     Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 0.046501\n",
      "Reconstruction: 0.037821, Regularization: 0.008680\n",
      "2019-04-09 20:44:00,834 root         INFO     Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 0.039678\n",
      "Reconstruction: 0.033664, Regularization: 0.006013\n",
      "2019-04-09 20:44:00,861 root         INFO     Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 0.040055\n",
      "Reconstruction: 0.033809, Regularization: 0.006245\n",
      "2019-04-09 20:44:00,888 root         INFO     Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 0.048881\n",
      "Reconstruction: 0.038838, Regularization: 0.010043\n",
      "2019-04-09 20:44:00,914 root         INFO     Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 0.055662\n",
      "Reconstruction: 0.045801, Regularization: 0.009860\n",
      "2019-04-09 20:44:00,952 root         INFO     ====> Epoch: 113 Average loss: 0.0445\n",
      "2019-04-09 20:44:00,974 root         INFO     Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 0.057151\n",
      "Reconstruction: 0.045621, Regularization: 0.011530\n",
      "2019-04-09 20:44:01,000 root         INFO     Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 0.039242\n",
      "Reconstruction: 0.033303, Regularization: 0.005939\n",
      "2019-04-09 20:44:01,027 root         INFO     Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 0.044058\n",
      "Reconstruction: 0.036290, Regularization: 0.007768\n",
      "2019-04-09 20:44:01,054 root         INFO     Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 0.038255\n",
      "Reconstruction: 0.032497, Regularization: 0.005758\n",
      "2019-04-09 20:44:01,081 root         INFO     Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 0.048288\n",
      "Reconstruction: 0.039868, Regularization: 0.008420\n",
      "2019-04-09 20:44:01,107 root         INFO     Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 0.057731\n",
      "Reconstruction: 0.046653, Regularization: 0.011079\n",
      "2019-04-09 20:44:01,134 root         INFO     Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 0.051638\n",
      "Reconstruction: 0.042665, Regularization: 0.008973\n",
      "2019-04-09 20:44:01,160 root         INFO     Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 0.043973\n",
      "Reconstruction: 0.036313, Regularization: 0.007660\n",
      "2019-04-09 20:44:01,198 root         INFO     ====> Epoch: 114 Average loss: 0.0444\n",
      "2019-04-09 20:44:01,219 root         INFO     Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 0.039497\n",
      "Reconstruction: 0.032526, Regularization: 0.006971\n",
      "2019-04-09 20:44:01,246 root         INFO     Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 0.035525\n",
      "Reconstruction: 0.029097, Regularization: 0.006428\n",
      "2019-04-09 20:44:01,273 root         INFO     Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 0.044422\n",
      "Reconstruction: 0.036573, Regularization: 0.007848\n",
      "2019-04-09 20:44:01,300 root         INFO     Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 0.049066\n",
      "Reconstruction: 0.040381, Regularization: 0.008685\n",
      "2019-04-09 20:44:01,326 root         INFO     Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 0.045518\n",
      "Reconstruction: 0.036676, Regularization: 0.008842\n",
      "2019-04-09 20:44:01,352 root         INFO     Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 0.042946\n",
      "Reconstruction: 0.034735, Regularization: 0.008211\n",
      "2019-04-09 20:44:01,379 root         INFO     Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 0.040517\n",
      "Reconstruction: 0.033323, Regularization: 0.007194\n",
      "2019-04-09 20:44:01,405 root         INFO     Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 0.040808\n",
      "Reconstruction: 0.033910, Regularization: 0.006898\n",
      "2019-04-09 20:44:01,443 root         INFO     ====> Epoch: 115 Average loss: 0.0442\n",
      "2019-04-09 20:44:01,464 root         INFO     Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 0.042824\n",
      "Reconstruction: 0.035302, Regularization: 0.007522\n",
      "2019-04-09 20:44:01,492 root         INFO     Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 0.045123\n",
      "Reconstruction: 0.036650, Regularization: 0.008473\n",
      "2019-04-09 20:44:01,519 root         INFO     Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 0.049030\n",
      "Reconstruction: 0.040767, Regularization: 0.008263\n",
      "2019-04-09 20:44:01,547 root         INFO     Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 0.043439\n",
      "Reconstruction: 0.035467, Regularization: 0.007971\n",
      "2019-04-09 20:44:01,574 root         INFO     Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 0.050986\n",
      "Reconstruction: 0.042727, Regularization: 0.008259\n",
      "2019-04-09 20:44:01,601 root         INFO     Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 0.043162\n",
      "Reconstruction: 0.035640, Regularization: 0.007522\n",
      "2019-04-09 20:44:01,627 root         INFO     Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 0.057866\n",
      "Reconstruction: 0.046670, Regularization: 0.011196\n",
      "2019-04-09 20:44:01,654 root         INFO     Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 0.041678\n",
      "Reconstruction: 0.034695, Regularization: 0.006984\n",
      "2019-04-09 20:44:01,692 root         INFO     ====> Epoch: 116 Average loss: 0.0441\n",
      "2019-04-09 20:44:01,714 root         INFO     Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 0.034360\n",
      "Reconstruction: 0.028941, Regularization: 0.005419\n",
      "2019-04-09 20:44:01,740 root         INFO     Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 0.047492\n",
      "Reconstruction: 0.037875, Regularization: 0.009617\n",
      "2019-04-09 20:44:01,765 root         INFO     Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 0.048311\n",
      "Reconstruction: 0.037782, Regularization: 0.010530\n",
      "2019-04-09 20:44:01,792 root         INFO     Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 0.050365\n",
      "Reconstruction: 0.040718, Regularization: 0.009648\n",
      "2019-04-09 20:44:01,820 root         INFO     Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 0.038621\n",
      "Reconstruction: 0.031734, Regularization: 0.006887\n",
      "2019-04-09 20:44:01,847 root         INFO     Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 0.041157\n",
      "Reconstruction: 0.033551, Regularization: 0.007606\n",
      "2019-04-09 20:44:01,875 root         INFO     Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 0.037951\n",
      "Reconstruction: 0.031906, Regularization: 0.006045\n",
      "2019-04-09 20:44:01,901 root         INFO     Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 0.044812\n",
      "Reconstruction: 0.035837, Regularization: 0.008975\n",
      "2019-04-09 20:44:01,938 root         INFO     ====> Epoch: 117 Average loss: 0.0438\n",
      "2019-04-09 20:44:01,959 root         INFO     Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 0.042857\n",
      "Reconstruction: 0.034921, Regularization: 0.007937\n",
      "2019-04-09 20:44:01,986 root         INFO     Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 0.041714\n",
      "Reconstruction: 0.034049, Regularization: 0.007665\n",
      "2019-04-09 20:44:02,013 root         INFO     Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 0.045333\n",
      "Reconstruction: 0.035394, Regularization: 0.009940\n",
      "2019-04-09 20:44:02,040 root         INFO     Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 0.048220\n",
      "Reconstruction: 0.039605, Regularization: 0.008615\n",
      "2019-04-09 20:44:02,067 root         INFO     Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 0.045365\n",
      "Reconstruction: 0.035469, Regularization: 0.009896\n",
      "2019-04-09 20:44:02,094 root         INFO     Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 0.043659\n",
      "Reconstruction: 0.035942, Regularization: 0.007717\n",
      "2019-04-09 20:44:02,121 root         INFO     Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 0.036799\n",
      "Reconstruction: 0.030017, Regularization: 0.006782\n",
      "2019-04-09 20:44:02,148 root         INFO     Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 0.048982\n",
      "Reconstruction: 0.040365, Regularization: 0.008617\n",
      "2019-04-09 20:44:02,186 root         INFO     ====> Epoch: 118 Average loss: 0.0440\n",
      "2019-04-09 20:44:02,208 root         INFO     Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 0.045777\n",
      "Reconstruction: 0.036271, Regularization: 0.009506\n",
      "2019-04-09 20:44:02,236 root         INFO     Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 0.052032\n",
      "Reconstruction: 0.042505, Regularization: 0.009527\n",
      "2019-04-09 20:44:02,264 root         INFO     Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 0.052914\n",
      "Reconstruction: 0.041856, Regularization: 0.011058\n",
      "2019-04-09 20:44:02,292 root         INFO     Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 0.050998\n",
      "Reconstruction: 0.040606, Regularization: 0.010392\n",
      "2019-04-09 20:44:02,318 root         INFO     Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 0.045055\n",
      "Reconstruction: 0.037249, Regularization: 0.007806\n",
      "2019-04-09 20:44:02,344 root         INFO     Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 0.052415\n",
      "Reconstruction: 0.042485, Regularization: 0.009930\n",
      "2019-04-09 20:44:02,370 root         INFO     Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 0.039621\n",
      "Reconstruction: 0.031603, Regularization: 0.008018\n",
      "2019-04-09 20:44:02,396 root         INFO     Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 0.044931\n",
      "Reconstruction: 0.036094, Regularization: 0.008837\n",
      "2019-04-09 20:44:02,434 root         INFO     ====> Epoch: 119 Average loss: 0.0438\n",
      "2019-04-09 20:44:02,455 root         INFO     Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 0.046730\n",
      "Reconstruction: 0.038081, Regularization: 0.008649\n",
      "2019-04-09 20:44:02,483 root         INFO     Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 0.041779\n",
      "Reconstruction: 0.033525, Regularization: 0.008253\n",
      "2019-04-09 20:44:02,510 root         INFO     Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 0.043020\n",
      "Reconstruction: 0.034346, Regularization: 0.008674\n",
      "2019-04-09 20:44:02,537 root         INFO     Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 0.036468\n",
      "Reconstruction: 0.029693, Regularization: 0.006775\n",
      "2019-04-09 20:44:02,564 root         INFO     Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 0.049114\n",
      "Reconstruction: 0.039374, Regularization: 0.009739\n",
      "2019-04-09 20:44:02,591 root         INFO     Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 0.036046\n",
      "Reconstruction: 0.029446, Regularization: 0.006600\n",
      "2019-04-09 20:44:02,618 root         INFO     Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 0.043000\n",
      "Reconstruction: 0.035911, Regularization: 0.007089\n",
      "2019-04-09 20:44:02,645 root         INFO     Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 0.035859\n",
      "Reconstruction: 0.030296, Regularization: 0.005563\n",
      "2019-04-09 20:44:02,683 root         INFO     ====> Epoch: 120 Average loss: 0.0438\n",
      "2019-04-09 20:44:02,704 root         INFO     Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 0.041658\n",
      "Reconstruction: 0.034110, Regularization: 0.007549\n",
      "2019-04-09 20:44:02,732 root         INFO     Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 0.036202\n",
      "Reconstruction: 0.029264, Regularization: 0.006938\n",
      "2019-04-09 20:44:02,759 root         INFO     Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 0.038610\n",
      "Reconstruction: 0.030681, Regularization: 0.007929\n",
      "2019-04-09 20:44:02,787 root         INFO     Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 0.039218\n",
      "Reconstruction: 0.031412, Regularization: 0.007806\n",
      "2019-04-09 20:44:02,814 root         INFO     Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 0.044282\n",
      "Reconstruction: 0.034630, Regularization: 0.009652\n",
      "2019-04-09 20:44:02,841 root         INFO     Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 0.046314\n",
      "Reconstruction: 0.036974, Regularization: 0.009340\n",
      "2019-04-09 20:44:02,869 root         INFO     Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 0.043735\n",
      "Reconstruction: 0.035843, Regularization: 0.007893\n",
      "2019-04-09 20:44:02,896 root         INFO     Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 0.043566\n",
      "Reconstruction: 0.035218, Regularization: 0.008349\n",
      "2019-04-09 20:44:02,934 root         INFO     ====> Epoch: 121 Average loss: 0.0431\n",
      "2019-04-09 20:44:02,956 root         INFO     Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 0.048599\n",
      "Reconstruction: 0.039482, Regularization: 0.009117\n",
      "2019-04-09 20:44:02,981 root         INFO     Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 0.041383\n",
      "Reconstruction: 0.033072, Regularization: 0.008310\n",
      "2019-04-09 20:44:03,008 root         INFO     Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 0.043638\n",
      "Reconstruction: 0.034148, Regularization: 0.009490\n",
      "2019-04-09 20:44:03,035 root         INFO     Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 0.043956\n",
      "Reconstruction: 0.035984, Regularization: 0.007972\n",
      "2019-04-09 20:44:03,062 root         INFO     Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 0.046223\n",
      "Reconstruction: 0.036776, Regularization: 0.009447\n",
      "2019-04-09 20:44:03,090 root         INFO     Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 0.042082\n",
      "Reconstruction: 0.034705, Regularization: 0.007377\n",
      "2019-04-09 20:44:03,118 root         INFO     Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 0.040650\n",
      "Reconstruction: 0.032631, Regularization: 0.008018\n",
      "2019-04-09 20:44:03,147 root         INFO     Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 0.043408\n",
      "Reconstruction: 0.034615, Regularization: 0.008792\n",
      "2019-04-09 20:44:03,185 root         INFO     ====> Epoch: 122 Average loss: 0.0436\n",
      "2019-04-09 20:44:03,206 root         INFO     Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 0.037702\n",
      "Reconstruction: 0.030230, Regularization: 0.007473\n",
      "2019-04-09 20:44:03,233 root         INFO     Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 0.044225\n",
      "Reconstruction: 0.035468, Regularization: 0.008757\n",
      "2019-04-09 20:44:03,260 root         INFO     Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 0.049153\n",
      "Reconstruction: 0.037932, Regularization: 0.011220\n",
      "2019-04-09 20:44:03,286 root         INFO     Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 0.045962\n",
      "Reconstruction: 0.037134, Regularization: 0.008829\n",
      "2019-04-09 20:44:03,312 root         INFO     Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 0.041362\n",
      "Reconstruction: 0.032431, Regularization: 0.008930\n",
      "2019-04-09 20:44:03,338 root         INFO     Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 0.046502\n",
      "Reconstruction: 0.036746, Regularization: 0.009755\n",
      "2019-04-09 20:44:03,363 root         INFO     Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 0.035455\n",
      "Reconstruction: 0.029121, Regularization: 0.006334\n",
      "2019-04-09 20:44:03,389 root         INFO     Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 0.045714\n",
      "Reconstruction: 0.036048, Regularization: 0.009665\n",
      "2019-04-09 20:44:03,426 root         INFO     ====> Epoch: 123 Average loss: 0.0432\n",
      "2019-04-09 20:44:03,447 root         INFO     Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 0.047981\n",
      "Reconstruction: 0.038225, Regularization: 0.009756\n",
      "2019-04-09 20:44:03,474 root         INFO     Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 0.044281\n",
      "Reconstruction: 0.034403, Regularization: 0.009877\n",
      "2019-04-09 20:44:03,500 root         INFO     Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 0.048928\n",
      "Reconstruction: 0.037544, Regularization: 0.011384\n",
      "2019-04-09 20:44:03,526 root         INFO     Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 0.042606\n",
      "Reconstruction: 0.033032, Regularization: 0.009574\n",
      "2019-04-09 20:44:03,553 root         INFO     Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 0.041166\n",
      "Reconstruction: 0.032763, Regularization: 0.008403\n",
      "2019-04-09 20:44:03,580 root         INFO     Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 0.035931\n",
      "Reconstruction: 0.028765, Regularization: 0.007166\n",
      "2019-04-09 20:44:03,605 root         INFO     Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 0.036410\n",
      "Reconstruction: 0.028181, Regularization: 0.008229\n",
      "2019-04-09 20:44:03,631 root         INFO     Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 0.040337\n",
      "Reconstruction: 0.031998, Regularization: 0.008339\n",
      "2019-04-09 20:44:03,668 root         INFO     ====> Epoch: 124 Average loss: 0.0428\n",
      "2019-04-09 20:44:03,689 root         INFO     Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 0.046647\n",
      "Reconstruction: 0.036637, Regularization: 0.010010\n",
      "2019-04-09 20:44:03,716 root         INFO     Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 0.048789\n",
      "Reconstruction: 0.039018, Regularization: 0.009771\n",
      "2019-04-09 20:44:03,743 root         INFO     Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 0.036541\n",
      "Reconstruction: 0.030952, Regularization: 0.005589\n",
      "2019-04-09 20:44:03,770 root         INFO     Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 0.043407\n",
      "Reconstruction: 0.035215, Regularization: 0.008192\n",
      "2019-04-09 20:44:03,797 root         INFO     Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 0.043379\n",
      "Reconstruction: 0.035431, Regularization: 0.007948\n",
      "2019-04-09 20:44:03,824 root         INFO     Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 0.044702\n",
      "Reconstruction: 0.035503, Regularization: 0.009199\n",
      "2019-04-09 20:44:03,849 root         INFO     Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 0.043207\n",
      "Reconstruction: 0.033896, Regularization: 0.009311\n",
      "2019-04-09 20:44:03,875 root         INFO     Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 0.031301\n",
      "Reconstruction: 0.025074, Regularization: 0.006227\n",
      "2019-04-09 20:44:03,911 root         INFO     ====> Epoch: 125 Average loss: 0.0430\n",
      "2019-04-09 20:44:03,932 root         INFO     Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 0.039713\n",
      "Reconstruction: 0.032385, Regularization: 0.007328\n",
      "2019-04-09 20:44:03,959 root         INFO     Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 0.041930\n",
      "Reconstruction: 0.031526, Regularization: 0.010404\n",
      "2019-04-09 20:44:03,986 root         INFO     Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 0.047031\n",
      "Reconstruction: 0.036059, Regularization: 0.010973\n",
      "2019-04-09 20:44:04,013 root         INFO     Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 0.048620\n",
      "Reconstruction: 0.037624, Regularization: 0.010996\n",
      "2019-04-09 20:44:04,040 root         INFO     Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 0.046775\n",
      "Reconstruction: 0.037593, Regularization: 0.009182\n",
      "2019-04-09 20:44:04,067 root         INFO     Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 0.041676\n",
      "Reconstruction: 0.033820, Regularization: 0.007856\n",
      "2019-04-09 20:44:04,093 root         INFO     Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 0.039952\n",
      "Reconstruction: 0.031734, Regularization: 0.008218\n",
      "2019-04-09 20:44:04,121 root         INFO     Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 0.047715\n",
      "Reconstruction: 0.037038, Regularization: 0.010677\n",
      "2019-04-09 20:44:04,159 root         INFO     ====> Epoch: 126 Average loss: 0.0430\n",
      "2019-04-09 20:44:04,180 root         INFO     Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 0.040014\n",
      "Reconstruction: 0.031484, Regularization: 0.008530\n",
      "2019-04-09 20:44:04,207 root         INFO     Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 0.038471\n",
      "Reconstruction: 0.031516, Regularization: 0.006954\n",
      "2019-04-09 20:44:04,234 root         INFO     Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 0.039810\n",
      "Reconstruction: 0.030527, Regularization: 0.009283\n",
      "2019-04-09 20:44:04,259 root         INFO     Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 0.045150\n",
      "Reconstruction: 0.034246, Regularization: 0.010904\n",
      "2019-04-09 20:44:04,285 root         INFO     Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 0.049750\n",
      "Reconstruction: 0.038546, Regularization: 0.011204\n",
      "2019-04-09 20:44:04,310 root         INFO     Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 0.047057\n",
      "Reconstruction: 0.036592, Regularization: 0.010465\n",
      "2019-04-09 20:44:04,334 root         INFO     Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 0.040585\n",
      "Reconstruction: 0.033238, Regularization: 0.007347\n",
      "2019-04-09 20:44:04,359 root         INFO     Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 0.042326\n",
      "Reconstruction: 0.032279, Regularization: 0.010047\n",
      "2019-04-09 20:44:04,396 root         INFO     ====> Epoch: 127 Average loss: 0.0425\n",
      "2019-04-09 20:44:04,417 root         INFO     Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 0.042567\n",
      "Reconstruction: 0.033423, Regularization: 0.009144\n",
      "2019-04-09 20:44:04,444 root         INFO     Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 0.034905\n",
      "Reconstruction: 0.028563, Regularization: 0.006342\n",
      "2019-04-09 20:44:04,471 root         INFO     Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 0.046333\n",
      "Reconstruction: 0.035768, Regularization: 0.010565\n",
      "2019-04-09 20:44:04,498 root         INFO     Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 0.038143\n",
      "Reconstruction: 0.030737, Regularization: 0.007406\n",
      "2019-04-09 20:44:04,524 root         INFO     Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 0.036732\n",
      "Reconstruction: 0.028436, Regularization: 0.008296\n",
      "2019-04-09 20:44:04,551 root         INFO     Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 0.042819\n",
      "Reconstruction: 0.034044, Regularization: 0.008775\n",
      "2019-04-09 20:44:04,578 root         INFO     Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 0.044142\n",
      "Reconstruction: 0.033526, Regularization: 0.010617\n",
      "2019-04-09 20:44:04,605 root         INFO     Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 0.035029\n",
      "Reconstruction: 0.028535, Regularization: 0.006494\n",
      "2019-04-09 20:44:04,643 root         INFO     ====> Epoch: 128 Average loss: 0.0426\n",
      "2019-04-09 20:44:04,664 root         INFO     Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 0.042886\n",
      "Reconstruction: 0.033104, Regularization: 0.009783\n",
      "2019-04-09 20:44:04,691 root         INFO     Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 0.048345\n",
      "Reconstruction: 0.038657, Regularization: 0.009687\n",
      "2019-04-09 20:44:04,718 root         INFO     Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 0.036137\n",
      "Reconstruction: 0.028918, Regularization: 0.007219\n",
      "2019-04-09 20:44:04,744 root         INFO     Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 0.039977\n",
      "Reconstruction: 0.032300, Regularization: 0.007677\n",
      "2019-04-09 20:44:04,771 root         INFO     Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 0.037042\n",
      "Reconstruction: 0.028450, Regularization: 0.008592\n",
      "2019-04-09 20:44:04,798 root         INFO     Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 0.039709\n",
      "Reconstruction: 0.031024, Regularization: 0.008685\n",
      "2019-04-09 20:44:04,824 root         INFO     Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 0.041935\n",
      "Reconstruction: 0.031097, Regularization: 0.010838\n",
      "2019-04-09 20:44:04,851 root         INFO     Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 0.040046\n",
      "Reconstruction: 0.032173, Regularization: 0.007873\n",
      "2019-04-09 20:44:04,889 root         INFO     ====> Epoch: 129 Average loss: 0.0423\n",
      "2019-04-09 20:44:04,911 root         INFO     Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 0.042805\n",
      "Reconstruction: 0.033105, Regularization: 0.009700\n",
      "2019-04-09 20:44:04,937 root         INFO     Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 0.039330\n",
      "Reconstruction: 0.032206, Regularization: 0.007124\n",
      "2019-04-09 20:44:04,964 root         INFO     Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 0.042112\n",
      "Reconstruction: 0.033624, Regularization: 0.008488\n",
      "2019-04-09 20:44:04,989 root         INFO     Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 0.046686\n",
      "Reconstruction: 0.036399, Regularization: 0.010287\n",
      "2019-04-09 20:44:05,015 root         INFO     Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 0.041788\n",
      "Reconstruction: 0.032430, Regularization: 0.009358\n",
      "2019-04-09 20:44:05,041 root         INFO     Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 0.039854\n",
      "Reconstruction: 0.030577, Regularization: 0.009278\n",
      "2019-04-09 20:44:05,066 root         INFO     Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 0.043545\n",
      "Reconstruction: 0.034720, Regularization: 0.008825\n",
      "2019-04-09 20:44:05,092 root         INFO     Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 0.038475\n",
      "Reconstruction: 0.030738, Regularization: 0.007737\n",
      "2019-04-09 20:44:05,129 root         INFO     ====> Epoch: 130 Average loss: 0.0426\n",
      "2019-04-09 20:44:05,150 root         INFO     Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 0.040683\n",
      "Reconstruction: 0.032862, Regularization: 0.007821\n",
      "2019-04-09 20:44:05,176 root         INFO     Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 0.047157\n",
      "Reconstruction: 0.035695, Regularization: 0.011462\n",
      "2019-04-09 20:44:05,203 root         INFO     Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 0.044422\n",
      "Reconstruction: 0.034453, Regularization: 0.009969\n",
      "2019-04-09 20:44:05,229 root         INFO     Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 0.041419\n",
      "Reconstruction: 0.033122, Regularization: 0.008298\n",
      "2019-04-09 20:44:05,255 root         INFO     Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 0.035688\n",
      "Reconstruction: 0.028635, Regularization: 0.007053\n",
      "2019-04-09 20:44:05,281 root         INFO     Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 0.043687\n",
      "Reconstruction: 0.033943, Regularization: 0.009744\n",
      "2019-04-09 20:44:05,307 root         INFO     Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 0.046930\n",
      "Reconstruction: 0.036865, Regularization: 0.010065\n",
      "2019-04-09 20:44:05,333 root         INFO     Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 0.046706\n",
      "Reconstruction: 0.036562, Regularization: 0.010144\n",
      "2019-04-09 20:44:05,370 root         INFO     ====> Epoch: 131 Average loss: 0.0422\n",
      "2019-04-09 20:44:05,391 root         INFO     Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 0.040669\n",
      "Reconstruction: 0.032180, Regularization: 0.008488\n",
      "2019-04-09 20:44:05,418 root         INFO     Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 0.048257\n",
      "Reconstruction: 0.036926, Regularization: 0.011331\n",
      "2019-04-09 20:44:05,445 root         INFO     Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 0.035479\n",
      "Reconstruction: 0.027898, Regularization: 0.007581\n",
      "2019-04-09 20:44:05,472 root         INFO     Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 0.041690\n",
      "Reconstruction: 0.032332, Regularization: 0.009359\n",
      "2019-04-09 20:44:05,499 root         INFO     Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 0.038227\n",
      "Reconstruction: 0.029781, Regularization: 0.008446\n",
      "2019-04-09 20:44:05,526 root         INFO     Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 0.042397\n",
      "Reconstruction: 0.033665, Regularization: 0.008733\n",
      "2019-04-09 20:44:05,553 root         INFO     Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 0.039014\n",
      "Reconstruction: 0.030109, Regularization: 0.008905\n",
      "2019-04-09 20:44:05,580 root         INFO     Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 0.043131\n",
      "Reconstruction: 0.035507, Regularization: 0.007624\n",
      "2019-04-09 20:44:05,618 root         INFO     ====> Epoch: 132 Average loss: 0.0422\n",
      "2019-04-09 20:44:05,640 root         INFO     Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 0.057073\n",
      "Reconstruction: 0.044580, Regularization: 0.012493\n",
      "2019-04-09 20:44:05,667 root         INFO     Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 0.046164\n",
      "Reconstruction: 0.035249, Regularization: 0.010916\n",
      "2019-04-09 20:44:05,693 root         INFO     Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 0.046748\n",
      "Reconstruction: 0.035687, Regularization: 0.011061\n",
      "2019-04-09 20:44:05,720 root         INFO     Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 0.038246\n",
      "Reconstruction: 0.029733, Regularization: 0.008513\n",
      "2019-04-09 20:44:05,747 root         INFO     Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 0.039397\n",
      "Reconstruction: 0.031875, Regularization: 0.007522\n",
      "2019-04-09 20:44:05,774 root         INFO     Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 0.045448\n",
      "Reconstruction: 0.034360, Regularization: 0.011088\n",
      "2019-04-09 20:44:05,801 root         INFO     Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 0.044141\n",
      "Reconstruction: 0.034629, Regularization: 0.009512\n",
      "2019-04-09 20:44:05,828 root         INFO     Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 0.043408\n",
      "Reconstruction: 0.031516, Regularization: 0.011892\n",
      "2019-04-09 20:44:05,866 root         INFO     ====> Epoch: 133 Average loss: 0.0420\n",
      "2019-04-09 20:44:05,887 root         INFO     Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 0.043136\n",
      "Reconstruction: 0.033095, Regularization: 0.010041\n",
      "2019-04-09 20:44:05,914 root         INFO     Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 0.040774\n",
      "Reconstruction: 0.032569, Regularization: 0.008206\n",
      "2019-04-09 20:44:05,941 root         INFO     Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 0.038640\n",
      "Reconstruction: 0.030495, Regularization: 0.008145\n",
      "2019-04-09 20:44:05,967 root         INFO     Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 0.042214\n",
      "Reconstruction: 0.032822, Regularization: 0.009392\n",
      "2019-04-09 20:44:05,993 root         INFO     Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 0.048843\n",
      "Reconstruction: 0.037868, Regularization: 0.010975\n",
      "2019-04-09 20:44:06,019 root         INFO     Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 0.047802\n",
      "Reconstruction: 0.037758, Regularization: 0.010044\n",
      "2019-04-09 20:44:06,045 root         INFO     Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 0.041568\n",
      "Reconstruction: 0.031450, Regularization: 0.010119\n",
      "2019-04-09 20:44:06,072 root         INFO     Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 0.042095\n",
      "Reconstruction: 0.031395, Regularization: 0.010700\n",
      "2019-04-09 20:44:06,109 root         INFO     ====> Epoch: 134 Average loss: 0.0422\n",
      "2019-04-09 20:44:06,131 root         INFO     Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 0.035429\n",
      "Reconstruction: 0.028269, Regularization: 0.007160\n",
      "2019-04-09 20:44:06,158 root         INFO     Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 0.045310\n",
      "Reconstruction: 0.034840, Regularization: 0.010470\n",
      "2019-04-09 20:44:06,185 root         INFO     Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 0.050408\n",
      "Reconstruction: 0.040601, Regularization: 0.009808\n",
      "2019-04-09 20:44:06,212 root         INFO     Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 0.039081\n",
      "Reconstruction: 0.028016, Regularization: 0.011065\n",
      "2019-04-09 20:44:06,239 root         INFO     Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 0.044647\n",
      "Reconstruction: 0.034405, Regularization: 0.010242\n",
      "2019-04-09 20:44:06,266 root         INFO     Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 0.040719\n",
      "Reconstruction: 0.031921, Regularization: 0.008798\n",
      "2019-04-09 20:44:06,293 root         INFO     Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 0.042745\n",
      "Reconstruction: 0.032935, Regularization: 0.009809\n",
      "2019-04-09 20:44:06,320 root         INFO     Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 0.038176\n",
      "Reconstruction: 0.030165, Regularization: 0.008011\n",
      "2019-04-09 20:44:06,358 root         INFO     ====> Epoch: 135 Average loss: 0.0419\n",
      "2019-04-09 20:44:06,380 root         INFO     Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 0.040544\n",
      "Reconstruction: 0.031020, Regularization: 0.009524\n",
      "2019-04-09 20:44:06,406 root         INFO     Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 0.049440\n",
      "Reconstruction: 0.037314, Regularization: 0.012126\n",
      "2019-04-09 20:44:06,433 root         INFO     Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 0.039346\n",
      "Reconstruction: 0.030826, Regularization: 0.008520\n",
      "2019-04-09 20:44:06,460 root         INFO     Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 0.046301\n",
      "Reconstruction: 0.035940, Regularization: 0.010361\n",
      "2019-04-09 20:44:06,487 root         INFO     Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 0.044151\n",
      "Reconstruction: 0.031986, Regularization: 0.012166\n",
      "2019-04-09 20:44:06,514 root         INFO     Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 0.043592\n",
      "Reconstruction: 0.032160, Regularization: 0.011433\n",
      "2019-04-09 20:44:06,540 root         INFO     Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 0.042164\n",
      "Reconstruction: 0.034008, Regularization: 0.008156\n",
      "2019-04-09 20:44:06,565 root         INFO     Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 0.041868\n",
      "Reconstruction: 0.032365, Regularization: 0.009502\n",
      "2019-04-09 20:44:06,602 root         INFO     ====> Epoch: 136 Average loss: 0.0421\n",
      "2019-04-09 20:44:06,623 root         INFO     Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 0.047429\n",
      "Reconstruction: 0.037363, Regularization: 0.010066\n",
      "2019-04-09 20:44:06,650 root         INFO     Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 0.040102\n",
      "Reconstruction: 0.033444, Regularization: 0.006657\n",
      "2019-04-09 20:44:06,677 root         INFO     Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 0.039499\n",
      "Reconstruction: 0.031399, Regularization: 0.008101\n",
      "2019-04-09 20:44:06,704 root         INFO     Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 0.040124\n",
      "Reconstruction: 0.031419, Regularization: 0.008705\n",
      "2019-04-09 20:44:06,731 root         INFO     Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 0.035338\n",
      "Reconstruction: 0.029690, Regularization: 0.005648\n",
      "2019-04-09 20:44:06,758 root         INFO     Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 0.046265\n",
      "Reconstruction: 0.034877, Regularization: 0.011389\n",
      "2019-04-09 20:44:06,785 root         INFO     Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 0.046290\n",
      "Reconstruction: 0.033974, Regularization: 0.012316\n",
      "2019-04-09 20:44:06,812 root         INFO     Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 0.047996\n",
      "Reconstruction: 0.037813, Regularization: 0.010183\n",
      "2019-04-09 20:44:06,850 root         INFO     ====> Epoch: 137 Average loss: 0.0422\n",
      "2019-04-09 20:44:06,872 root         INFO     Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 0.039903\n",
      "Reconstruction: 0.030091, Regularization: 0.009812\n",
      "2019-04-09 20:44:06,899 root         INFO     Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 0.028842\n",
      "Reconstruction: 0.023985, Regularization: 0.004857\n",
      "2019-04-09 20:44:06,926 root         INFO     Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 0.042364\n",
      "Reconstruction: 0.032197, Regularization: 0.010167\n",
      "2019-04-09 20:44:06,952 root         INFO     Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 0.043163\n",
      "Reconstruction: 0.033891, Regularization: 0.009272\n",
      "2019-04-09 20:44:06,979 root         INFO     Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 0.042306\n",
      "Reconstruction: 0.031715, Regularization: 0.010591\n",
      "2019-04-09 20:44:07,006 root         INFO     Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 0.041631\n",
      "Reconstruction: 0.032746, Regularization: 0.008886\n",
      "2019-04-09 20:44:07,033 root         INFO     Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 0.037631\n",
      "Reconstruction: 0.029084, Regularization: 0.008547\n",
      "2019-04-09 20:44:07,059 root         INFO     Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 0.041397\n",
      "Reconstruction: 0.032616, Regularization: 0.008781\n",
      "2019-04-09 20:44:07,097 root         INFO     ====> Epoch: 138 Average loss: 0.0418\n",
      "2019-04-09 20:44:07,119 root         INFO     Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 0.050458\n",
      "Reconstruction: 0.038865, Regularization: 0.011594\n",
      "2019-04-09 20:44:07,144 root         INFO     Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 0.041942\n",
      "Reconstruction: 0.032819, Regularization: 0.009124\n",
      "2019-04-09 20:44:07,171 root         INFO     Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 0.034441\n",
      "Reconstruction: 0.027096, Regularization: 0.007345\n",
      "2019-04-09 20:44:07,197 root         INFO     Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 0.041106\n",
      "Reconstruction: 0.031519, Regularization: 0.009587\n",
      "2019-04-09 20:44:07,224 root         INFO     Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 0.039025\n",
      "Reconstruction: 0.031819, Regularization: 0.007206\n",
      "2019-04-09 20:44:07,251 root         INFO     Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 0.037202\n",
      "Reconstruction: 0.030076, Regularization: 0.007126\n",
      "2019-04-09 20:44:07,277 root         INFO     Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 0.049100\n",
      "Reconstruction: 0.038085, Regularization: 0.011015\n",
      "2019-04-09 20:44:07,304 root         INFO     Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 0.048229\n",
      "Reconstruction: 0.037128, Regularization: 0.011101\n",
      "2019-04-09 20:44:07,341 root         INFO     ====> Epoch: 139 Average loss: 0.0417\n",
      "2019-04-09 20:44:07,363 root         INFO     Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 0.044652\n",
      "Reconstruction: 0.033986, Regularization: 0.010666\n",
      "2019-04-09 20:44:07,389 root         INFO     Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 0.038308\n",
      "Reconstruction: 0.029880, Regularization: 0.008429\n",
      "2019-04-09 20:44:07,415 root         INFO     Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 0.048770\n",
      "Reconstruction: 0.035213, Regularization: 0.013557\n",
      "2019-04-09 20:44:07,442 root         INFO     Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 0.038527\n",
      "Reconstruction: 0.030826, Regularization: 0.007701\n",
      "2019-04-09 20:44:07,468 root         INFO     Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 0.036832\n",
      "Reconstruction: 0.028806, Regularization: 0.008026\n",
      "2019-04-09 20:44:07,495 root         INFO     Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 0.047096\n",
      "Reconstruction: 0.036069, Regularization: 0.011027\n",
      "2019-04-09 20:44:07,522 root         INFO     Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 0.041184\n",
      "Reconstruction: 0.033185, Regularization: 0.007999\n",
      "2019-04-09 20:44:07,549 root         INFO     Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 0.042807\n",
      "Reconstruction: 0.030729, Regularization: 0.012078\n",
      "2019-04-09 20:44:07,586 root         INFO     ====> Epoch: 140 Average loss: 0.0417\n",
      "2019-04-09 20:44:07,607 root         INFO     Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 0.036662\n",
      "Reconstruction: 0.030024, Regularization: 0.006638\n",
      "2019-04-09 20:44:07,635 root         INFO     Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 0.044323\n",
      "Reconstruction: 0.033394, Regularization: 0.010930\n",
      "2019-04-09 20:44:07,661 root         INFO     Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 0.040043\n",
      "Reconstruction: 0.031208, Regularization: 0.008836\n",
      "2019-04-09 20:44:07,686 root         INFO     Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 0.037390\n",
      "Reconstruction: 0.029160, Regularization: 0.008230\n",
      "2019-04-09 20:44:07,712 root         INFO     Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 0.042764\n",
      "Reconstruction: 0.031030, Regularization: 0.011733\n",
      "2019-04-09 20:44:07,738 root         INFO     Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 0.050182\n",
      "Reconstruction: 0.037840, Regularization: 0.012341\n",
      "2019-04-09 20:44:07,764 root         INFO     Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 0.044653\n",
      "Reconstruction: 0.032052, Regularization: 0.012601\n",
      "2019-04-09 20:44:07,790 root         INFO     Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 0.054186\n",
      "Reconstruction: 0.041837, Regularization: 0.012349\n",
      "2019-04-09 20:44:07,827 root         INFO     ====> Epoch: 141 Average loss: 0.0420\n",
      "2019-04-09 20:44:07,848 root         INFO     Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 0.034432\n",
      "Reconstruction: 0.027588, Regularization: 0.006843\n",
      "2019-04-09 20:44:07,874 root         INFO     Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 0.046410\n",
      "Reconstruction: 0.035118, Regularization: 0.011292\n",
      "2019-04-09 20:44:07,899 root         INFO     Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 0.037906\n",
      "Reconstruction: 0.031252, Regularization: 0.006654\n",
      "2019-04-09 20:44:07,924 root         INFO     Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 0.046528\n",
      "Reconstruction: 0.035485, Regularization: 0.011044\n",
      "2019-04-09 20:44:07,949 root         INFO     Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 0.037439\n",
      "Reconstruction: 0.030852, Regularization: 0.006587\n",
      "2019-04-09 20:44:07,974 root         INFO     Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 0.041994\n",
      "Reconstruction: 0.032479, Regularization: 0.009515\n",
      "2019-04-09 20:44:08,000 root         INFO     Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 0.049269\n",
      "Reconstruction: 0.037851, Regularization: 0.011418\n",
      "2019-04-09 20:44:08,025 root         INFO     Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 0.036071\n",
      "Reconstruction: 0.027078, Regularization: 0.008993\n",
      "2019-04-09 20:44:08,063 root         INFO     ====> Epoch: 142 Average loss: 0.0419\n",
      "2019-04-09 20:44:08,084 root         INFO     Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 0.039022\n",
      "Reconstruction: 0.031275, Regularization: 0.007747\n",
      "2019-04-09 20:44:08,110 root         INFO     Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 0.039937\n",
      "Reconstruction: 0.032087, Regularization: 0.007850\n",
      "2019-04-09 20:44:08,136 root         INFO     Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 0.034358\n",
      "Reconstruction: 0.026960, Regularization: 0.007398\n",
      "2019-04-09 20:44:08,163 root         INFO     Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 0.035560\n",
      "Reconstruction: 0.027810, Regularization: 0.007750\n",
      "2019-04-09 20:44:08,190 root         INFO     Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 0.041259\n",
      "Reconstruction: 0.032479, Regularization: 0.008780\n",
      "2019-04-09 20:44:08,217 root         INFO     Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 0.039171\n",
      "Reconstruction: 0.029747, Regularization: 0.009424\n",
      "2019-04-09 20:44:08,245 root         INFO     Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 0.047095\n",
      "Reconstruction: 0.035101, Regularization: 0.011994\n",
      "2019-04-09 20:44:08,271 root         INFO     Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 0.047019\n",
      "Reconstruction: 0.035052, Regularization: 0.011967\n",
      "2019-04-09 20:44:08,309 root         INFO     ====> Epoch: 143 Average loss: 0.0418\n",
      "2019-04-09 20:44:08,330 root         INFO     Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 0.037110\n",
      "Reconstruction: 0.027920, Regularization: 0.009190\n",
      "2019-04-09 20:44:08,357 root         INFO     Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 0.040329\n",
      "Reconstruction: 0.031091, Regularization: 0.009238\n",
      "2019-04-09 20:44:08,384 root         INFO     Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 0.039691\n",
      "Reconstruction: 0.031485, Regularization: 0.008206\n",
      "2019-04-09 20:44:08,411 root         INFO     Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 0.035159\n",
      "Reconstruction: 0.028543, Regularization: 0.006616\n",
      "2019-04-09 20:44:08,437 root         INFO     Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 0.042889\n",
      "Reconstruction: 0.033074, Regularization: 0.009815\n",
      "2019-04-09 20:44:08,464 root         INFO     Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 0.044909\n",
      "Reconstruction: 0.034150, Regularization: 0.010759\n",
      "2019-04-09 20:44:08,490 root         INFO     Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 0.035137\n",
      "Reconstruction: 0.028641, Regularization: 0.006497\n",
      "2019-04-09 20:44:08,517 root         INFO     Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 0.040894\n",
      "Reconstruction: 0.030698, Regularization: 0.010197\n",
      "2019-04-09 20:44:08,554 root         INFO     ====> Epoch: 144 Average loss: 0.0415\n",
      "2019-04-09 20:44:08,576 root         INFO     Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 0.041907\n",
      "Reconstruction: 0.030192, Regularization: 0.011715\n",
      "2019-04-09 20:44:08,603 root         INFO     Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 0.037623\n",
      "Reconstruction: 0.029736, Regularization: 0.007887\n",
      "2019-04-09 20:44:08,629 root         INFO     Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 0.044902\n",
      "Reconstruction: 0.033145, Regularization: 0.011758\n",
      "2019-04-09 20:44:08,656 root         INFO     Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 0.039906\n",
      "Reconstruction: 0.030741, Regularization: 0.009165\n",
      "2019-04-09 20:44:08,683 root         INFO     Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 0.040100\n",
      "Reconstruction: 0.031389, Regularization: 0.008711\n",
      "2019-04-09 20:44:08,710 root         INFO     Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 0.051822\n",
      "Reconstruction: 0.039952, Regularization: 0.011870\n",
      "2019-04-09 20:44:08,736 root         INFO     Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 0.035107\n",
      "Reconstruction: 0.027871, Regularization: 0.007237\n",
      "2019-04-09 20:44:08,763 root         INFO     Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 0.040762\n",
      "Reconstruction: 0.031584, Regularization: 0.009178\n",
      "2019-04-09 20:44:08,801 root         INFO     ====> Epoch: 145 Average loss: 0.0416\n",
      "2019-04-09 20:44:08,822 root         INFO     Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 0.048697\n",
      "Reconstruction: 0.036763, Regularization: 0.011934\n",
      "2019-04-09 20:44:08,849 root         INFO     Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 0.036445\n",
      "Reconstruction: 0.029067, Regularization: 0.007378\n",
      "2019-04-09 20:44:08,876 root         INFO     Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 0.040891\n",
      "Reconstruction: 0.032875, Regularization: 0.008016\n",
      "2019-04-09 20:44:08,903 root         INFO     Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 0.038922\n",
      "Reconstruction: 0.028827, Regularization: 0.010095\n",
      "2019-04-09 20:44:08,930 root         INFO     Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 0.048212\n",
      "Reconstruction: 0.035673, Regularization: 0.012539\n",
      "2019-04-09 20:44:08,956 root         INFO     Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 0.036605\n",
      "Reconstruction: 0.029710, Regularization: 0.006895\n",
      "2019-04-09 20:44:08,983 root         INFO     Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 0.047040\n",
      "Reconstruction: 0.035324, Regularization: 0.011717\n",
      "2019-04-09 20:44:09,009 root         INFO     Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 0.042919\n",
      "Reconstruction: 0.032304, Regularization: 0.010615\n",
      "2019-04-09 20:44:09,047 root         INFO     ====> Epoch: 146 Average loss: 0.0417\n",
      "2019-04-09 20:44:09,068 root         INFO     Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 0.045649\n",
      "Reconstruction: 0.035457, Regularization: 0.010192\n",
      "2019-04-09 20:44:09,096 root         INFO     Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 0.047870\n",
      "Reconstruction: 0.036286, Regularization: 0.011584\n",
      "2019-04-09 20:44:09,123 root         INFO     Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 0.046166\n",
      "Reconstruction: 0.036831, Regularization: 0.009335\n",
      "2019-04-09 20:44:09,149 root         INFO     Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 0.039384\n",
      "Reconstruction: 0.031464, Regularization: 0.007920\n",
      "2019-04-09 20:44:09,174 root         INFO     Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 0.044216\n",
      "Reconstruction: 0.032953, Regularization: 0.011263\n",
      "2019-04-09 20:44:09,200 root         INFO     Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 0.036251\n",
      "Reconstruction: 0.029052, Regularization: 0.007199\n",
      "2019-04-09 20:44:09,226 root         INFO     Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 0.041553\n",
      "Reconstruction: 0.031497, Regularization: 0.010056\n",
      "2019-04-09 20:44:09,253 root         INFO     Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 0.041175\n",
      "Reconstruction: 0.030458, Regularization: 0.010717\n",
      "2019-04-09 20:44:09,289 root         INFO     ====> Epoch: 147 Average loss: 0.0420\n",
      "2019-04-09 20:44:09,311 root         INFO     Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 0.040653\n",
      "Reconstruction: 0.030073, Regularization: 0.010579\n",
      "2019-04-09 20:44:09,338 root         INFO     Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 0.043591\n",
      "Reconstruction: 0.034186, Regularization: 0.009404\n",
      "2019-04-09 20:44:09,366 root         INFO     Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 0.033426\n",
      "Reconstruction: 0.027216, Regularization: 0.006210\n",
      "2019-04-09 20:44:09,393 root         INFO     Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 0.039310\n",
      "Reconstruction: 0.031700, Regularization: 0.007611\n",
      "2019-04-09 20:44:09,420 root         INFO     Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 0.035368\n",
      "Reconstruction: 0.027971, Regularization: 0.007398\n",
      "2019-04-09 20:44:09,448 root         INFO     Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 0.046029\n",
      "Reconstruction: 0.033955, Regularization: 0.012073\n",
      "2019-04-09 20:44:09,475 root         INFO     Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 0.043827\n",
      "Reconstruction: 0.033425, Regularization: 0.010401\n",
      "2019-04-09 20:44:09,503 root         INFO     Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 0.037898\n",
      "Reconstruction: 0.029054, Regularization: 0.008844\n",
      "2019-04-09 20:44:09,540 root         INFO     ====> Epoch: 148 Average loss: 0.0414\n",
      "2019-04-09 20:44:09,562 root         INFO     Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 0.038223\n",
      "Reconstruction: 0.028960, Regularization: 0.009263\n",
      "2019-04-09 20:44:09,589 root         INFO     Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 0.037218\n",
      "Reconstruction: 0.028855, Regularization: 0.008363\n",
      "2019-04-09 20:44:09,615 root         INFO     Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 0.039326\n",
      "Reconstruction: 0.029901, Regularization: 0.009425\n",
      "2019-04-09 20:44:09,642 root         INFO     Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 0.048040\n",
      "Reconstruction: 0.037091, Regularization: 0.010949\n",
      "2019-04-09 20:44:09,669 root         INFO     Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 0.038806\n",
      "Reconstruction: 0.028482, Regularization: 0.010324\n",
      "2019-04-09 20:44:09,696 root         INFO     Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 0.043039\n",
      "Reconstruction: 0.034416, Regularization: 0.008623\n",
      "2019-04-09 20:44:09,724 root         INFO     Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 0.046650\n",
      "Reconstruction: 0.033361, Regularization: 0.013289\n",
      "2019-04-09 20:44:09,751 root         INFO     Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 0.038134\n",
      "Reconstruction: 0.028985, Regularization: 0.009149\n",
      "2019-04-09 20:44:09,789 root         INFO     ====> Epoch: 149 Average loss: 0.0415\n",
      "2019-04-09 20:44:09,811 root         INFO     Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 0.038988\n",
      "Reconstruction: 0.030571, Regularization: 0.008417\n",
      "2019-04-09 20:44:09,839 root         INFO     Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 0.041438\n",
      "Reconstruction: 0.031484, Regularization: 0.009954\n",
      "2019-04-09 20:44:09,866 root         INFO     Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 0.043230\n",
      "Reconstruction: 0.031822, Regularization: 0.011408\n",
      "2019-04-09 20:44:09,894 root         INFO     Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 0.042989\n",
      "Reconstruction: 0.032893, Regularization: 0.010097\n",
      "2019-04-09 20:44:09,921 root         INFO     Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 0.035729\n",
      "Reconstruction: 0.027874, Regularization: 0.007855\n",
      "2019-04-09 20:44:09,949 root         INFO     Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 0.050521\n",
      "Reconstruction: 0.037985, Regularization: 0.012537\n",
      "2019-04-09 20:44:09,976 root         INFO     Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 0.036805\n",
      "Reconstruction: 0.028844, Regularization: 0.007961\n",
      "2019-04-09 20:44:10,003 root         INFO     Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 0.039327\n",
      "Reconstruction: 0.029628, Regularization: 0.009699\n",
      "2019-04-09 20:44:10,043 root         INFO     ====> Epoch: 150 Average loss: 0.0416\n",
      "2019-04-09 20:44:10,064 root         INFO     Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 0.037986\n",
      "Reconstruction: 0.029416, Regularization: 0.008570\n",
      "2019-04-09 20:44:10,091 root         INFO     Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 0.045360\n",
      "Reconstruction: 0.034467, Regularization: 0.010893\n",
      "2019-04-09 20:44:10,117 root         INFO     Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 0.042792\n",
      "Reconstruction: 0.032429, Regularization: 0.010362\n",
      "2019-04-09 20:44:10,144 root         INFO     Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 0.047880\n",
      "Reconstruction: 0.038105, Regularization: 0.009775\n",
      "2019-04-09 20:44:10,171 root         INFO     Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 0.045370\n",
      "Reconstruction: 0.035707, Regularization: 0.009662\n",
      "2019-04-09 20:44:10,197 root         INFO     Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 0.033033\n",
      "Reconstruction: 0.026587, Regularization: 0.006446\n",
      "2019-04-09 20:44:10,224 root         INFO     Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 0.042824\n",
      "Reconstruction: 0.032194, Regularization: 0.010630\n",
      "2019-04-09 20:44:10,250 root         INFO     Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 0.036330\n",
      "Reconstruction: 0.029808, Regularization: 0.006522\n",
      "2019-04-09 20:44:10,288 root         INFO     ====> Epoch: 151 Average loss: 0.0417\n",
      "2019-04-09 20:44:10,310 root         INFO     Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 0.048562\n",
      "Reconstruction: 0.037516, Regularization: 0.011046\n",
      "2019-04-09 20:44:10,336 root         INFO     Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 0.045234\n",
      "Reconstruction: 0.035391, Regularization: 0.009843\n",
      "2019-04-09 20:44:10,362 root         INFO     Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 0.044593\n",
      "Reconstruction: 0.033786, Regularization: 0.010808\n",
      "2019-04-09 20:44:10,388 root         INFO     Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 0.049749\n",
      "Reconstruction: 0.037578, Regularization: 0.012171\n",
      "2019-04-09 20:44:10,414 root         INFO     Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 0.036079\n",
      "Reconstruction: 0.026161, Regularization: 0.009919\n",
      "2019-04-09 20:44:10,440 root         INFO     Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 0.042463\n",
      "Reconstruction: 0.031984, Regularization: 0.010479\n",
      "2019-04-09 20:44:10,465 root         INFO     Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 0.038718\n",
      "Reconstruction: 0.030068, Regularization: 0.008650\n",
      "2019-04-09 20:44:10,491 root         INFO     Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 0.035818\n",
      "Reconstruction: 0.028202, Regularization: 0.007616\n",
      "2019-04-09 20:44:10,528 root         INFO     ====> Epoch: 152 Average loss: 0.0414\n",
      "2019-04-09 20:44:10,549 root         INFO     Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 0.044039\n",
      "Reconstruction: 0.033743, Regularization: 0.010295\n",
      "2019-04-09 20:44:10,577 root         INFO     Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 0.046014\n",
      "Reconstruction: 0.034605, Regularization: 0.011410\n",
      "2019-04-09 20:44:10,604 root         INFO     Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 0.053767\n",
      "Reconstruction: 0.041051, Regularization: 0.012716\n",
      "2019-04-09 20:44:10,631 root         INFO     Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 0.047258\n",
      "Reconstruction: 0.037267, Regularization: 0.009990\n",
      "2019-04-09 20:44:10,659 root         INFO     Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 0.033947\n",
      "Reconstruction: 0.026866, Regularization: 0.007081\n",
      "2019-04-09 20:44:10,686 root         INFO     Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 0.042640\n",
      "Reconstruction: 0.032529, Regularization: 0.010111\n",
      "2019-04-09 20:44:10,713 root         INFO     Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 0.041699\n",
      "Reconstruction: 0.031730, Regularization: 0.009968\n",
      "2019-04-09 20:44:10,740 root         INFO     Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 0.046464\n",
      "Reconstruction: 0.035349, Regularization: 0.011115\n",
      "2019-04-09 20:44:10,778 root         INFO     ====> Epoch: 153 Average loss: 0.0415\n",
      "2019-04-09 20:44:10,799 root         INFO     Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 0.039245\n",
      "Reconstruction: 0.030408, Regularization: 0.008837\n",
      "2019-04-09 20:44:10,827 root         INFO     Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 0.048873\n",
      "Reconstruction: 0.038174, Regularization: 0.010699\n",
      "2019-04-09 20:44:10,854 root         INFO     Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 0.047012\n",
      "Reconstruction: 0.036847, Regularization: 0.010165\n",
      "2019-04-09 20:44:10,879 root         INFO     Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 0.037955\n",
      "Reconstruction: 0.029544, Regularization: 0.008412\n",
      "2019-04-09 20:44:10,904 root         INFO     Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 0.043697\n",
      "Reconstruction: 0.033369, Regularization: 0.010328\n",
      "2019-04-09 20:44:10,930 root         INFO     Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 0.048103\n",
      "Reconstruction: 0.036954, Regularization: 0.011149\n",
      "2019-04-09 20:44:10,957 root         INFO     Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 0.035433\n",
      "Reconstruction: 0.028239, Regularization: 0.007194\n",
      "2019-04-09 20:44:10,983 root         INFO     Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 0.049005\n",
      "Reconstruction: 0.035853, Regularization: 0.013152\n",
      "2019-04-09 20:44:11,020 root         INFO     ====> Epoch: 154 Average loss: 0.0411\n",
      "2019-04-09 20:44:11,041 root         INFO     Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 0.040419\n",
      "Reconstruction: 0.030108, Regularization: 0.010312\n",
      "2019-04-09 20:44:11,068 root         INFO     Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 0.044470\n",
      "Reconstruction: 0.034237, Regularization: 0.010233\n",
      "2019-04-09 20:44:11,094 root         INFO     Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 0.040342\n",
      "Reconstruction: 0.031346, Regularization: 0.008997\n",
      "2019-04-09 20:44:11,119 root         INFO     Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 0.040637\n",
      "Reconstruction: 0.031611, Regularization: 0.009026\n",
      "2019-04-09 20:44:11,145 root         INFO     Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 0.046110\n",
      "Reconstruction: 0.033784, Regularization: 0.012326\n",
      "2019-04-09 20:44:11,172 root         INFO     Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 0.041782\n",
      "Reconstruction: 0.031804, Regularization: 0.009977\n",
      "2019-04-09 20:44:11,198 root         INFO     Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 0.037378\n",
      "Reconstruction: 0.028554, Regularization: 0.008824\n",
      "2019-04-09 20:44:11,225 root         INFO     Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 0.043675\n",
      "Reconstruction: 0.031955, Regularization: 0.011720\n",
      "2019-04-09 20:44:11,264 root         INFO     ====> Epoch: 155 Average loss: 0.0408\n",
      "2019-04-09 20:44:11,285 root         INFO     Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 0.040185\n",
      "Reconstruction: 0.031796, Regularization: 0.008389\n",
      "2019-04-09 20:44:11,312 root         INFO     Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 0.047699\n",
      "Reconstruction: 0.035173, Regularization: 0.012526\n",
      "2019-04-09 20:44:11,340 root         INFO     Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 0.040198\n",
      "Reconstruction: 0.031442, Regularization: 0.008756\n",
      "2019-04-09 20:44:11,367 root         INFO     Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 0.050562\n",
      "Reconstruction: 0.039245, Regularization: 0.011317\n",
      "2019-04-09 20:44:11,395 root         INFO     Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 0.043097\n",
      "Reconstruction: 0.034305, Regularization: 0.008792\n",
      "2019-04-09 20:44:11,421 root         INFO     Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 0.038869\n",
      "Reconstruction: 0.030135, Regularization: 0.008734\n",
      "2019-04-09 20:44:11,447 root         INFO     Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 0.042234\n",
      "Reconstruction: 0.031571, Regularization: 0.010664\n",
      "2019-04-09 20:44:11,473 root         INFO     Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 0.036302\n",
      "Reconstruction: 0.029418, Regularization: 0.006884\n",
      "2019-04-09 20:44:11,511 root         INFO     ====> Epoch: 156 Average loss: 0.0411\n",
      "2019-04-09 20:44:11,532 root         INFO     Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 0.041740\n",
      "Reconstruction: 0.034491, Regularization: 0.007249\n",
      "2019-04-09 20:44:11,558 root         INFO     Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 0.035778\n",
      "Reconstruction: 0.026993, Regularization: 0.008785\n",
      "2019-04-09 20:44:11,586 root         INFO     Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 0.038439\n",
      "Reconstruction: 0.029041, Regularization: 0.009398\n",
      "2019-04-09 20:44:11,614 root         INFO     Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 0.035651\n",
      "Reconstruction: 0.028224, Regularization: 0.007426\n",
      "2019-04-09 20:44:11,643 root         INFO     Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 0.045403\n",
      "Reconstruction: 0.034012, Regularization: 0.011391\n",
      "2019-04-09 20:44:11,671 root         INFO     Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 0.039025\n",
      "Reconstruction: 0.031242, Regularization: 0.007783\n",
      "2019-04-09 20:44:11,700 root         INFO     Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 0.027861\n",
      "Reconstruction: 0.023498, Regularization: 0.004363\n",
      "2019-04-09 20:44:11,727 root         INFO     Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 0.041791\n",
      "Reconstruction: 0.032298, Regularization: 0.009494\n",
      "2019-04-09 20:44:11,766 root         INFO     ====> Epoch: 157 Average loss: 0.0411\n",
      "2019-04-09 20:44:11,787 root         INFO     Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 0.045049\n",
      "Reconstruction: 0.034797, Regularization: 0.010253\n",
      "2019-04-09 20:44:11,815 root         INFO     Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 0.041893\n",
      "Reconstruction: 0.033664, Regularization: 0.008229\n",
      "2019-04-09 20:44:11,842 root         INFO     Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 0.040785\n",
      "Reconstruction: 0.031489, Regularization: 0.009295\n",
      "2019-04-09 20:44:11,870 root         INFO     Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 0.041371\n",
      "Reconstruction: 0.032915, Regularization: 0.008456\n",
      "2019-04-09 20:44:11,897 root         INFO     Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 0.038408\n",
      "Reconstruction: 0.028521, Regularization: 0.009888\n",
      "2019-04-09 20:44:11,924 root         INFO     Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 0.037321\n",
      "Reconstruction: 0.029726, Regularization: 0.007595\n",
      "2019-04-09 20:44:11,951 root         INFO     Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 0.040589\n",
      "Reconstruction: 0.030485, Regularization: 0.010104\n",
      "2019-04-09 20:44:11,979 root         INFO     Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 0.044128\n",
      "Reconstruction: 0.034530, Regularization: 0.009598\n",
      "2019-04-09 20:44:12,017 root         INFO     ====> Epoch: 158 Average loss: 0.0413\n",
      "2019-04-09 20:44:12,038 root         INFO     Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 0.042081\n",
      "Reconstruction: 0.032051, Regularization: 0.010030\n",
      "2019-04-09 20:44:12,066 root         INFO     Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 0.040803\n",
      "Reconstruction: 0.029837, Regularization: 0.010966\n",
      "2019-04-09 20:44:12,094 root         INFO     Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 0.037065\n",
      "Reconstruction: 0.029694, Regularization: 0.007371\n",
      "2019-04-09 20:44:12,121 root         INFO     Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 0.039717\n",
      "Reconstruction: 0.031093, Regularization: 0.008624\n",
      "2019-04-09 20:44:12,148 root         INFO     Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 0.038866\n",
      "Reconstruction: 0.030215, Regularization: 0.008652\n",
      "2019-04-09 20:44:12,175 root         INFO     Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 0.042288\n",
      "Reconstruction: 0.030847, Regularization: 0.011440\n",
      "2019-04-09 20:44:12,203 root         INFO     Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 0.044323\n",
      "Reconstruction: 0.034748, Regularization: 0.009575\n",
      "2019-04-09 20:44:12,231 root         INFO     Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 0.044004\n",
      "Reconstruction: 0.034669, Regularization: 0.009335\n",
      "2019-04-09 20:44:12,269 root         INFO     ====> Epoch: 159 Average loss: 0.0412\n",
      "2019-04-09 20:44:12,290 root         INFO     Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 0.038013\n",
      "Reconstruction: 0.031259, Regularization: 0.006754\n",
      "2019-04-09 20:44:12,318 root         INFO     Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 0.041107\n",
      "Reconstruction: 0.030321, Regularization: 0.010786\n",
      "2019-04-09 20:44:12,345 root         INFO     Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 0.038510\n",
      "Reconstruction: 0.029394, Regularization: 0.009116\n",
      "2019-04-09 20:44:12,372 root         INFO     Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 0.037726\n",
      "Reconstruction: 0.030076, Regularization: 0.007650\n",
      "2019-04-09 20:44:12,400 root         INFO     Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 0.038973\n",
      "Reconstruction: 0.030742, Regularization: 0.008231\n",
      "2019-04-09 20:44:12,426 root         INFO     Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 0.039013\n",
      "Reconstruction: 0.030120, Regularization: 0.008893\n",
      "2019-04-09 20:44:12,452 root         INFO     Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 0.039395\n",
      "Reconstruction: 0.029848, Regularization: 0.009547\n",
      "2019-04-09 20:44:12,477 root         INFO     Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 0.034898\n",
      "Reconstruction: 0.027441, Regularization: 0.007456\n",
      "2019-04-09 20:44:12,514 root         INFO     ====> Epoch: 160 Average loss: 0.0413\n",
      "2019-04-09 20:44:12,535 root         INFO     Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 0.040181\n",
      "Reconstruction: 0.032019, Regularization: 0.008162\n",
      "2019-04-09 20:44:12,562 root         INFO     Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 0.046044\n",
      "Reconstruction: 0.035003, Regularization: 0.011041\n",
      "2019-04-09 20:44:12,589 root         INFO     Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 0.041127\n",
      "Reconstruction: 0.033116, Regularization: 0.008011\n",
      "2019-04-09 20:44:12,616 root         INFO     Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 0.047873\n",
      "Reconstruction: 0.036496, Regularization: 0.011377\n",
      "2019-04-09 20:44:12,642 root         INFO     Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 0.043680\n",
      "Reconstruction: 0.033377, Regularization: 0.010304\n",
      "2019-04-09 20:44:12,669 root         INFO     Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 0.040226\n",
      "Reconstruction: 0.031427, Regularization: 0.008799\n",
      "2019-04-09 20:44:12,696 root         INFO     Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 0.037453\n",
      "Reconstruction: 0.029389, Regularization: 0.008065\n",
      "2019-04-09 20:44:12,723 root         INFO     Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 0.037687\n",
      "Reconstruction: 0.028964, Regularization: 0.008723\n",
      "2019-04-09 20:44:12,761 root         INFO     ====> Epoch: 161 Average loss: 0.0412\n",
      "2019-04-09 20:44:12,782 root         INFO     Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 0.044171\n",
      "Reconstruction: 0.035841, Regularization: 0.008330\n",
      "2019-04-09 20:44:12,808 root         INFO     Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 0.038853\n",
      "Reconstruction: 0.030203, Regularization: 0.008650\n",
      "2019-04-09 20:44:12,835 root         INFO     Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 0.040021\n",
      "Reconstruction: 0.030973, Regularization: 0.009047\n",
      "2019-04-09 20:44:12,861 root         INFO     Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 0.042077\n",
      "Reconstruction: 0.031723, Regularization: 0.010354\n",
      "2019-04-09 20:44:12,887 root         INFO     Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 0.044731\n",
      "Reconstruction: 0.030871, Regularization: 0.013860\n",
      "2019-04-09 20:44:12,914 root         INFO     Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 0.045703\n",
      "Reconstruction: 0.034831, Regularization: 0.010872\n",
      "2019-04-09 20:44:12,940 root         INFO     Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 0.043755\n",
      "Reconstruction: 0.033978, Regularization: 0.009776\n",
      "2019-04-09 20:44:12,967 root         INFO     Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 0.040560\n",
      "Reconstruction: 0.030762, Regularization: 0.009798\n",
      "2019-04-09 20:44:13,004 root         INFO     ====> Epoch: 162 Average loss: 0.0413\n",
      "2019-04-09 20:44:13,025 root         INFO     Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 0.041464\n",
      "Reconstruction: 0.031278, Regularization: 0.010186\n",
      "2019-04-09 20:44:13,052 root         INFO     Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 0.043721\n",
      "Reconstruction: 0.032414, Regularization: 0.011307\n",
      "2019-04-09 20:44:13,080 root         INFO     Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 0.042425\n",
      "Reconstruction: 0.031491, Regularization: 0.010934\n",
      "2019-04-09 20:44:13,107 root         INFO     Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 0.037051\n",
      "Reconstruction: 0.029824, Regularization: 0.007227\n",
      "2019-04-09 20:44:13,133 root         INFO     Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 0.042176\n",
      "Reconstruction: 0.032479, Regularization: 0.009697\n",
      "2019-04-09 20:44:13,159 root         INFO     Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 0.040468\n",
      "Reconstruction: 0.029691, Regularization: 0.010777\n",
      "2019-04-09 20:44:13,184 root         INFO     Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 0.036849\n",
      "Reconstruction: 0.027166, Regularization: 0.009683\n",
      "2019-04-09 20:44:13,210 root         INFO     Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 0.054506\n",
      "Reconstruction: 0.041452, Regularization: 0.013054\n",
      "2019-04-09 20:44:13,247 root         INFO     ====> Epoch: 163 Average loss: 0.0418\n",
      "2019-04-09 20:44:13,268 root         INFO     Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 0.048400\n",
      "Reconstruction: 0.037453, Regularization: 0.010947\n",
      "2019-04-09 20:44:13,295 root         INFO     Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 0.049547\n",
      "Reconstruction: 0.037866, Regularization: 0.011681\n",
      "2019-04-09 20:44:13,321 root         INFO     Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 0.041864\n",
      "Reconstruction: 0.032076, Regularization: 0.009788\n",
      "2019-04-09 20:44:13,347 root         INFO     Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 0.043545\n",
      "Reconstruction: 0.033551, Regularization: 0.009995\n",
      "2019-04-09 20:44:13,372 root         INFO     Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 0.037728\n",
      "Reconstruction: 0.028498, Regularization: 0.009230\n",
      "2019-04-09 20:44:13,398 root         INFO     Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 0.036860\n",
      "Reconstruction: 0.028564, Regularization: 0.008295\n",
      "2019-04-09 20:44:13,423 root         INFO     Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 0.034648\n",
      "Reconstruction: 0.028240, Regularization: 0.006408\n",
      "2019-04-09 20:44:13,449 root         INFO     Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 0.035265\n",
      "Reconstruction: 0.025862, Regularization: 0.009403\n",
      "2019-04-09 20:44:13,486 root         INFO     ====> Epoch: 164 Average loss: 0.0411\n",
      "2019-04-09 20:44:13,507 root         INFO     Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 0.033545\n",
      "Reconstruction: 0.026696, Regularization: 0.006848\n",
      "2019-04-09 20:44:13,534 root         INFO     Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 0.043728\n",
      "Reconstruction: 0.033178, Regularization: 0.010550\n",
      "2019-04-09 20:44:13,561 root         INFO     Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 0.036654\n",
      "Reconstruction: 0.029819, Regularization: 0.006835\n",
      "2019-04-09 20:44:13,588 root         INFO     Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 0.043669\n",
      "Reconstruction: 0.032711, Regularization: 0.010958\n",
      "2019-04-09 20:44:13,615 root         INFO     Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 0.038295\n",
      "Reconstruction: 0.029985, Regularization: 0.008310\n",
      "2019-04-09 20:44:13,642 root         INFO     Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 0.041090\n",
      "Reconstruction: 0.032154, Regularization: 0.008936\n",
      "2019-04-09 20:44:13,669 root         INFO     Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 0.040612\n",
      "Reconstruction: 0.031076, Regularization: 0.009537\n",
      "2019-04-09 20:44:13,696 root         INFO     Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 0.042232\n",
      "Reconstruction: 0.031525, Regularization: 0.010707\n",
      "2019-04-09 20:44:13,733 root         INFO     ====> Epoch: 165 Average loss: 0.0415\n",
      "2019-04-09 20:44:13,755 root         INFO     Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 0.042176\n",
      "Reconstruction: 0.030719, Regularization: 0.011457\n",
      "2019-04-09 20:44:13,781 root         INFO     Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 0.036744\n",
      "Reconstruction: 0.026988, Regularization: 0.009756\n",
      "2019-04-09 20:44:13,806 root         INFO     Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 0.038996\n",
      "Reconstruction: 0.028813, Regularization: 0.010183\n",
      "2019-04-09 20:44:13,831 root         INFO     Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 0.042047\n",
      "Reconstruction: 0.031335, Regularization: 0.010712\n",
      "2019-04-09 20:44:13,857 root         INFO     Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 0.037270\n",
      "Reconstruction: 0.028976, Regularization: 0.008295\n",
      "2019-04-09 20:44:13,883 root         INFO     Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 0.035434\n",
      "Reconstruction: 0.027416, Regularization: 0.008017\n",
      "2019-04-09 20:44:13,910 root         INFO     Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 0.040107\n",
      "Reconstruction: 0.030614, Regularization: 0.009494\n",
      "2019-04-09 20:44:13,936 root         INFO     Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 0.044404\n",
      "Reconstruction: 0.034733, Regularization: 0.009671\n",
      "2019-04-09 20:44:13,975 root         INFO     ====> Epoch: 166 Average loss: 0.0411\n",
      "2019-04-09 20:44:13,996 root         INFO     Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 0.038625\n",
      "Reconstruction: 0.028775, Regularization: 0.009851\n",
      "2019-04-09 20:44:14,023 root         INFO     Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 0.039452\n",
      "Reconstruction: 0.031195, Regularization: 0.008257\n",
      "2019-04-09 20:44:14,050 root         INFO     Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 0.044365\n",
      "Reconstruction: 0.034443, Regularization: 0.009922\n",
      "2019-04-09 20:44:14,076 root         INFO     Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 0.040669\n",
      "Reconstruction: 0.030989, Regularization: 0.009680\n",
      "2019-04-09 20:44:14,102 root         INFO     Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 0.043795\n",
      "Reconstruction: 0.031279, Regularization: 0.012516\n",
      "2019-04-09 20:44:14,128 root         INFO     Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 0.040343\n",
      "Reconstruction: 0.029939, Regularization: 0.010404\n",
      "2019-04-09 20:44:14,154 root         INFO     Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 0.044074\n",
      "Reconstruction: 0.034126, Regularization: 0.009947\n",
      "2019-04-09 20:44:14,180 root         INFO     Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 0.037168\n",
      "Reconstruction: 0.028408, Regularization: 0.008761\n",
      "2019-04-09 20:44:14,218 root         INFO     ====> Epoch: 167 Average loss: 0.0410\n",
      "2019-04-09 20:44:14,239 root         INFO     Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 0.039233\n",
      "Reconstruction: 0.030722, Regularization: 0.008511\n",
      "2019-04-09 20:44:14,265 root         INFO     Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 0.050548\n",
      "Reconstruction: 0.037063, Regularization: 0.013485\n",
      "2019-04-09 20:44:14,291 root         INFO     Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 0.038403\n",
      "Reconstruction: 0.030566, Regularization: 0.007837\n",
      "2019-04-09 20:44:14,317 root         INFO     Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 0.043673\n",
      "Reconstruction: 0.031994, Regularization: 0.011680\n",
      "2019-04-09 20:44:14,343 root         INFO     Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 0.046795\n",
      "Reconstruction: 0.037097, Regularization: 0.009698\n",
      "2019-04-09 20:44:14,369 root         INFO     Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 0.050076\n",
      "Reconstruction: 0.036357, Regularization: 0.013719\n",
      "2019-04-09 20:44:14,394 root         INFO     Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 0.036374\n",
      "Reconstruction: 0.027341, Regularization: 0.009034\n",
      "2019-04-09 20:44:14,420 root         INFO     Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 0.042638\n",
      "Reconstruction: 0.031586, Regularization: 0.011051\n",
      "2019-04-09 20:44:14,457 root         INFO     ====> Epoch: 168 Average loss: 0.0415\n",
      "2019-04-09 20:44:14,478 root         INFO     Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 0.047832\n",
      "Reconstruction: 0.037254, Regularization: 0.010578\n",
      "2019-04-09 20:44:14,506 root         INFO     Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 0.045435\n",
      "Reconstruction: 0.032918, Regularization: 0.012517\n",
      "2019-04-09 20:44:14,533 root         INFO     Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 0.043712\n",
      "Reconstruction: 0.032039, Regularization: 0.011674\n",
      "2019-04-09 20:44:14,560 root         INFO     Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 0.041664\n",
      "Reconstruction: 0.032603, Regularization: 0.009062\n",
      "2019-04-09 20:44:14,586 root         INFO     Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 0.037175\n",
      "Reconstruction: 0.027568, Regularization: 0.009607\n",
      "2019-04-09 20:44:14,613 root         INFO     Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 0.043489\n",
      "Reconstruction: 0.031033, Regularization: 0.012457\n",
      "2019-04-09 20:44:14,641 root         INFO     Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 0.034855\n",
      "Reconstruction: 0.029657, Regularization: 0.005198\n",
      "2019-04-09 20:44:14,668 root         INFO     Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 0.045528\n",
      "Reconstruction: 0.034945, Regularization: 0.010583\n",
      "2019-04-09 20:44:14,706 root         INFO     ====> Epoch: 169 Average loss: 0.0411\n",
      "2019-04-09 20:44:14,728 root         INFO     Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 0.042493\n",
      "Reconstruction: 0.032373, Regularization: 0.010120\n",
      "2019-04-09 20:44:14,754 root         INFO     Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 0.035361\n",
      "Reconstruction: 0.028597, Regularization: 0.006764\n",
      "2019-04-09 20:44:14,781 root         INFO     Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 0.040650\n",
      "Reconstruction: 0.030409, Regularization: 0.010241\n",
      "2019-04-09 20:44:14,807 root         INFO     Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 0.045827\n",
      "Reconstruction: 0.033470, Regularization: 0.012357\n",
      "2019-04-09 20:44:14,834 root         INFO     Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 0.036532\n",
      "Reconstruction: 0.028509, Regularization: 0.008023\n",
      "2019-04-09 20:44:14,861 root         INFO     Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 0.041133\n",
      "Reconstruction: 0.032756, Regularization: 0.008377\n",
      "2019-04-09 20:44:14,887 root         INFO     Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 0.040854\n",
      "Reconstruction: 0.032706, Regularization: 0.008148\n",
      "2019-04-09 20:44:14,914 root         INFO     Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 0.043752\n",
      "Reconstruction: 0.031560, Regularization: 0.012192\n",
      "2019-04-09 20:44:14,951 root         INFO     ====> Epoch: 170 Average loss: 0.0412\n",
      "2019-04-09 20:44:14,973 root         INFO     Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 0.047353\n",
      "Reconstruction: 0.036047, Regularization: 0.011306\n",
      "2019-04-09 20:44:15,000 root         INFO     Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 0.038600\n",
      "Reconstruction: 0.029486, Regularization: 0.009114\n",
      "2019-04-09 20:44:15,026 root         INFO     Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 0.050949\n",
      "Reconstruction: 0.038952, Regularization: 0.011998\n",
      "2019-04-09 20:44:15,052 root         INFO     Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 0.041686\n",
      "Reconstruction: 0.030079, Regularization: 0.011606\n",
      "2019-04-09 20:44:15,077 root         INFO     Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 0.035078\n",
      "Reconstruction: 0.027357, Regularization: 0.007721\n",
      "2019-04-09 20:44:15,103 root         INFO     Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 0.041778\n",
      "Reconstruction: 0.033309, Regularization: 0.008469\n",
      "2019-04-09 20:44:15,129 root         INFO     Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 0.037690\n",
      "Reconstruction: 0.029128, Regularization: 0.008562\n",
      "2019-04-09 20:44:15,155 root         INFO     Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 0.043333\n",
      "Reconstruction: 0.030505, Regularization: 0.012828\n",
      "2019-04-09 20:44:15,192 root         INFO     ====> Epoch: 171 Average loss: 0.0416\n",
      "2019-04-09 20:44:15,213 root         INFO     Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 0.045878\n",
      "Reconstruction: 0.035851, Regularization: 0.010027\n",
      "2019-04-09 20:44:15,241 root         INFO     Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 0.036968\n",
      "Reconstruction: 0.028979, Regularization: 0.007989\n",
      "2019-04-09 20:44:15,268 root         INFO     Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 0.040990\n",
      "Reconstruction: 0.031140, Regularization: 0.009850\n",
      "2019-04-09 20:44:15,294 root         INFO     Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 0.046920\n",
      "Reconstruction: 0.035507, Regularization: 0.011413\n",
      "2019-04-09 20:44:15,321 root         INFO     Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 0.037451\n",
      "Reconstruction: 0.028749, Regularization: 0.008702\n",
      "2019-04-09 20:44:15,348 root         INFO     Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 0.042095\n",
      "Reconstruction: 0.032902, Regularization: 0.009193\n",
      "2019-04-09 20:44:15,375 root         INFO     Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 0.050428\n",
      "Reconstruction: 0.038269, Regularization: 0.012158\n",
      "2019-04-09 20:44:15,402 root         INFO     Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 0.038106\n",
      "Reconstruction: 0.029476, Regularization: 0.008630\n",
      "2019-04-09 20:44:15,440 root         INFO     ====> Epoch: 172 Average loss: 0.0413\n",
      "2019-04-09 20:44:15,461 root         INFO     Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 0.036769\n",
      "Reconstruction: 0.028638, Regularization: 0.008131\n",
      "2019-04-09 20:44:15,488 root         INFO     Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 0.037926\n",
      "Reconstruction: 0.028482, Regularization: 0.009444\n",
      "2019-04-09 20:44:15,513 root         INFO     Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 0.037017\n",
      "Reconstruction: 0.028075, Regularization: 0.008942\n",
      "2019-04-09 20:44:15,539 root         INFO     Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 0.040640\n",
      "Reconstruction: 0.030608, Regularization: 0.010033\n",
      "2019-04-09 20:44:15,565 root         INFO     Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 0.033086\n",
      "Reconstruction: 0.025777, Regularization: 0.007309\n",
      "2019-04-09 20:44:15,590 root         INFO     Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 0.049584\n",
      "Reconstruction: 0.036937, Regularization: 0.012647\n",
      "2019-04-09 20:44:15,616 root         INFO     Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 0.038394\n",
      "Reconstruction: 0.030463, Regularization: 0.007931\n",
      "2019-04-09 20:44:15,642 root         INFO     Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 0.042665\n",
      "Reconstruction: 0.035015, Regularization: 0.007650\n",
      "2019-04-09 20:44:15,680 root         INFO     ====> Epoch: 173 Average loss: 0.0407\n",
      "2019-04-09 20:44:15,702 root         INFO     Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 0.036298\n",
      "Reconstruction: 0.027631, Regularization: 0.008666\n",
      "2019-04-09 20:44:15,729 root         INFO     Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 0.040382\n",
      "Reconstruction: 0.031247, Regularization: 0.009135\n",
      "2019-04-09 20:44:15,756 root         INFO     Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 0.048227\n",
      "Reconstruction: 0.036213, Regularization: 0.012013\n",
      "2019-04-09 20:44:15,782 root         INFO     Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 0.046149\n",
      "Reconstruction: 0.034913, Regularization: 0.011237\n",
      "2019-04-09 20:44:15,809 root         INFO     Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 0.038566\n",
      "Reconstruction: 0.030843, Regularization: 0.007724\n",
      "2019-04-09 20:44:15,835 root         INFO     Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 0.037296\n",
      "Reconstruction: 0.029155, Regularization: 0.008140\n",
      "2019-04-09 20:44:15,862 root         INFO     Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 0.042670\n",
      "Reconstruction: 0.032724, Regularization: 0.009947\n",
      "2019-04-09 20:44:15,889 root         INFO     Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 0.033384\n",
      "Reconstruction: 0.026814, Regularization: 0.006569\n",
      "2019-04-09 20:44:15,927 root         INFO     ====> Epoch: 174 Average loss: 0.0415\n",
      "2019-04-09 20:44:15,949 root         INFO     Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 0.043606\n",
      "Reconstruction: 0.033273, Regularization: 0.010333\n",
      "2019-04-09 20:44:15,977 root         INFO     Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 0.044772\n",
      "Reconstruction: 0.034223, Regularization: 0.010549\n",
      "2019-04-09 20:44:16,003 root         INFO     Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 0.040412\n",
      "Reconstruction: 0.032550, Regularization: 0.007862\n",
      "2019-04-09 20:44:16,030 root         INFO     Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 0.041533\n",
      "Reconstruction: 0.032104, Regularization: 0.009429\n",
      "2019-04-09 20:44:16,056 root         INFO     Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 0.040009\n",
      "Reconstruction: 0.030044, Regularization: 0.009965\n",
      "2019-04-09 20:44:16,082 root         INFO     Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 0.045481\n",
      "Reconstruction: 0.033369, Regularization: 0.012112\n",
      "2019-04-09 20:44:16,108 root         INFO     Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 0.037452\n",
      "Reconstruction: 0.029138, Regularization: 0.008314\n",
      "2019-04-09 20:44:16,134 root         INFO     Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 0.038428\n",
      "Reconstruction: 0.030419, Regularization: 0.008009\n",
      "2019-04-09 20:44:16,171 root         INFO     ====> Epoch: 175 Average loss: 0.0412\n",
      "2019-04-09 20:44:16,192 root         INFO     Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 0.040519\n",
      "Reconstruction: 0.032244, Regularization: 0.008276\n",
      "2019-04-09 20:44:16,220 root         INFO     Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 0.042155\n",
      "Reconstruction: 0.035005, Regularization: 0.007150\n",
      "2019-04-09 20:44:16,248 root         INFO     Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 0.044539\n",
      "Reconstruction: 0.034358, Regularization: 0.010181\n",
      "2019-04-09 20:44:16,276 root         INFO     Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 0.045002\n",
      "Reconstruction: 0.034633, Regularization: 0.010369\n",
      "2019-04-09 20:44:16,301 root         INFO     Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 0.041464\n",
      "Reconstruction: 0.033084, Regularization: 0.008380\n",
      "2019-04-09 20:44:16,326 root         INFO     Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 0.038894\n",
      "Reconstruction: 0.028682, Regularization: 0.010212\n",
      "2019-04-09 20:44:16,352 root         INFO     Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 0.040869\n",
      "Reconstruction: 0.030757, Regularization: 0.010112\n",
      "2019-04-09 20:44:16,377 root         INFO     Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 0.040435\n",
      "Reconstruction: 0.030330, Regularization: 0.010105\n",
      "2019-04-09 20:44:16,414 root         INFO     ====> Epoch: 176 Average loss: 0.0412\n",
      "2019-04-09 20:44:16,435 root         INFO     Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 0.041760\n",
      "Reconstruction: 0.032096, Regularization: 0.009664\n",
      "2019-04-09 20:44:16,462 root         INFO     Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 0.032439\n",
      "Reconstruction: 0.025274, Regularization: 0.007165\n",
      "2019-04-09 20:44:16,489 root         INFO     Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 0.034979\n",
      "Reconstruction: 0.026532, Regularization: 0.008447\n",
      "2019-04-09 20:44:16,516 root         INFO     Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 0.041516\n",
      "Reconstruction: 0.031445, Regularization: 0.010071\n",
      "2019-04-09 20:44:16,543 root         INFO     Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 0.037574\n",
      "Reconstruction: 0.028797, Regularization: 0.008776\n",
      "2019-04-09 20:44:16,569 root         INFO     Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 0.039692\n",
      "Reconstruction: 0.030641, Regularization: 0.009051\n",
      "2019-04-09 20:44:16,596 root         INFO     Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 0.036943\n",
      "Reconstruction: 0.025694, Regularization: 0.011249\n",
      "2019-04-09 20:44:16,622 root         INFO     Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 0.049137\n",
      "Reconstruction: 0.036727, Regularization: 0.012410\n",
      "2019-04-09 20:44:16,660 root         INFO     ====> Epoch: 177 Average loss: 0.0408\n",
      "2019-04-09 20:44:16,682 root         INFO     Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 0.039459\n",
      "Reconstruction: 0.030571, Regularization: 0.008888\n",
      "2019-04-09 20:44:16,709 root         INFO     Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 0.045550\n",
      "Reconstruction: 0.036521, Regularization: 0.009028\n",
      "2019-04-09 20:44:16,735 root         INFO     Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 0.044304\n",
      "Reconstruction: 0.032912, Regularization: 0.011392\n",
      "2019-04-09 20:44:16,761 root         INFO     Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 0.035460\n",
      "Reconstruction: 0.025685, Regularization: 0.009775\n",
      "2019-04-09 20:44:16,787 root         INFO     Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 0.041433\n",
      "Reconstruction: 0.032557, Regularization: 0.008876\n",
      "2019-04-09 20:44:16,813 root         INFO     Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 0.042151\n",
      "Reconstruction: 0.031739, Regularization: 0.010412\n",
      "2019-04-09 20:44:16,839 root         INFO     Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 0.040670\n",
      "Reconstruction: 0.030555, Regularization: 0.010114\n",
      "2019-04-09 20:44:16,865 root         INFO     Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 0.042401\n",
      "Reconstruction: 0.033965, Regularization: 0.008436\n",
      "2019-04-09 20:44:16,902 root         INFO     ====> Epoch: 178 Average loss: 0.0411\n",
      "2019-04-09 20:44:16,924 root         INFO     Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 0.042879\n",
      "Reconstruction: 0.031235, Regularization: 0.011644\n",
      "2019-04-09 20:44:16,950 root         INFO     Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 0.040002\n",
      "Reconstruction: 0.032446, Regularization: 0.007556\n",
      "2019-04-09 20:44:16,976 root         INFO     Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 0.035947\n",
      "Reconstruction: 0.029692, Regularization: 0.006254\n",
      "2019-04-09 20:44:17,002 root         INFO     Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 0.034266\n",
      "Reconstruction: 0.027223, Regularization: 0.007043\n",
      "2019-04-09 20:44:17,028 root         INFO     Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 0.038001\n",
      "Reconstruction: 0.030232, Regularization: 0.007769\n",
      "2019-04-09 20:44:17,055 root         INFO     Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 0.043235\n",
      "Reconstruction: 0.033136, Regularization: 0.010099\n",
      "2019-04-09 20:44:17,081 root         INFO     Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 0.034809\n",
      "Reconstruction: 0.026024, Regularization: 0.008785\n",
      "2019-04-09 20:44:17,108 root         INFO     Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 0.035928\n",
      "Reconstruction: 0.027259, Regularization: 0.008669\n",
      "2019-04-09 20:44:17,145 root         INFO     ====> Epoch: 179 Average loss: 0.0411\n",
      "2019-04-09 20:44:17,166 root         INFO     Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 0.044057\n",
      "Reconstruction: 0.032748, Regularization: 0.011309\n",
      "2019-04-09 20:44:17,193 root         INFO     Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 0.048418\n",
      "Reconstruction: 0.038445, Regularization: 0.009973\n",
      "2019-04-09 20:44:17,219 root         INFO     Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 0.042674\n",
      "Reconstruction: 0.035103, Regularization: 0.007571\n",
      "2019-04-09 20:44:17,246 root         INFO     Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 0.042652\n",
      "Reconstruction: 0.032620, Regularization: 0.010032\n",
      "2019-04-09 20:44:17,272 root         INFO     Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 0.036709\n",
      "Reconstruction: 0.028270, Regularization: 0.008439\n",
      "2019-04-09 20:44:17,298 root         INFO     Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 0.046132\n",
      "Reconstruction: 0.035428, Regularization: 0.010704\n",
      "2019-04-09 20:44:17,324 root         INFO     Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 0.047967\n",
      "Reconstruction: 0.036764, Regularization: 0.011203\n",
      "2019-04-09 20:44:17,350 root         INFO     Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 0.045808\n",
      "Reconstruction: 0.034242, Regularization: 0.011567\n",
      "2019-04-09 20:44:17,388 root         INFO     ====> Epoch: 180 Average loss: 0.0411\n",
      "2019-04-09 20:44:17,409 root         INFO     Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 0.033652\n",
      "Reconstruction: 0.026871, Regularization: 0.006781\n",
      "2019-04-09 20:44:17,436 root         INFO     Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 0.033827\n",
      "Reconstruction: 0.026289, Regularization: 0.007538\n",
      "2019-04-09 20:44:17,462 root         INFO     Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 0.040603\n",
      "Reconstruction: 0.031541, Regularization: 0.009062\n",
      "2019-04-09 20:44:17,489 root         INFO     Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 0.041509\n",
      "Reconstruction: 0.032130, Regularization: 0.009379\n",
      "2019-04-09 20:44:17,515 root         INFO     Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 0.047250\n",
      "Reconstruction: 0.035794, Regularization: 0.011456\n",
      "2019-04-09 20:44:17,542 root         INFO     Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 0.039664\n",
      "Reconstruction: 0.031908, Regularization: 0.007756\n",
      "2019-04-09 20:44:17,568 root         INFO     Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 0.039290\n",
      "Reconstruction: 0.030284, Regularization: 0.009006\n",
      "2019-04-09 20:44:17,594 root         INFO     Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 0.041582\n",
      "Reconstruction: 0.032301, Regularization: 0.009281\n",
      "2019-04-09 20:44:17,633 root         INFO     ====> Epoch: 181 Average loss: 0.0410\n",
      "2019-04-09 20:44:17,654 root         INFO     Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 0.047105\n",
      "Reconstruction: 0.037187, Regularization: 0.009918\n",
      "2019-04-09 20:44:17,681 root         INFO     Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 0.042867\n",
      "Reconstruction: 0.032822, Regularization: 0.010045\n",
      "2019-04-09 20:44:17,707 root         INFO     Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 0.036076\n",
      "Reconstruction: 0.028099, Regularization: 0.007977\n",
      "2019-04-09 20:44:17,733 root         INFO     Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 0.039943\n",
      "Reconstruction: 0.031540, Regularization: 0.008403\n",
      "2019-04-09 20:44:17,759 root         INFO     Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 0.038038\n",
      "Reconstruction: 0.028204, Regularization: 0.009834\n",
      "2019-04-09 20:44:17,785 root         INFO     Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 0.038748\n",
      "Reconstruction: 0.030420, Regularization: 0.008329\n",
      "2019-04-09 20:44:17,810 root         INFO     Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 0.038035\n",
      "Reconstruction: 0.030913, Regularization: 0.007121\n",
      "2019-04-09 20:44:17,836 root         INFO     Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 0.046590\n",
      "Reconstruction: 0.033189, Regularization: 0.013401\n",
      "2019-04-09 20:44:17,873 root         INFO     ====> Epoch: 182 Average loss: 0.0415\n",
      "2019-04-09 20:44:17,894 root         INFO     Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 0.044835\n",
      "Reconstruction: 0.034622, Regularization: 0.010213\n",
      "2019-04-09 20:44:17,920 root         INFO     Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 0.040480\n",
      "Reconstruction: 0.029148, Regularization: 0.011331\n",
      "2019-04-09 20:44:17,947 root         INFO     Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 0.032862\n",
      "Reconstruction: 0.024324, Regularization: 0.008538\n",
      "2019-04-09 20:44:17,973 root         INFO     Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 0.037205\n",
      "Reconstruction: 0.030643, Regularization: 0.006562\n",
      "2019-04-09 20:44:17,999 root         INFO     Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 0.042089\n",
      "Reconstruction: 0.034550, Regularization: 0.007539\n",
      "2019-04-09 20:44:18,024 root         INFO     Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 0.046987\n",
      "Reconstruction: 0.033078, Regularization: 0.013908\n",
      "2019-04-09 20:44:18,050 root         INFO     Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 0.045282\n",
      "Reconstruction: 0.034536, Regularization: 0.010747\n",
      "2019-04-09 20:44:18,075 root         INFO     Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 0.039928\n",
      "Reconstruction: 0.028772, Regularization: 0.011156\n",
      "2019-04-09 20:44:18,111 root         INFO     ====> Epoch: 183 Average loss: 0.0412\n",
      "2019-04-09 20:44:18,132 root         INFO     Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 0.039198\n",
      "Reconstruction: 0.030963, Regularization: 0.008236\n",
      "2019-04-09 20:44:18,159 root         INFO     Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 0.038726\n",
      "Reconstruction: 0.030935, Regularization: 0.007792\n",
      "2019-04-09 20:44:18,185 root         INFO     Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 0.041595\n",
      "Reconstruction: 0.032042, Regularization: 0.009553\n",
      "2019-04-09 20:44:18,211 root         INFO     Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 0.038495\n",
      "Reconstruction: 0.031989, Regularization: 0.006506\n",
      "2019-04-09 20:44:18,238 root         INFO     Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 0.047617\n",
      "Reconstruction: 0.037773, Regularization: 0.009843\n",
      "2019-04-09 20:44:18,264 root         INFO     Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 0.043300\n",
      "Reconstruction: 0.032246, Regularization: 0.011054\n",
      "2019-04-09 20:44:18,290 root         INFO     Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 0.048008\n",
      "Reconstruction: 0.035079, Regularization: 0.012929\n",
      "2019-04-09 20:44:18,316 root         INFO     Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 0.041367\n",
      "Reconstruction: 0.030875, Regularization: 0.010492\n",
      "2019-04-09 20:44:18,353 root         INFO     ====> Epoch: 184 Average loss: 0.0409\n",
      "2019-04-09 20:44:18,375 root         INFO     Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 0.049797\n",
      "Reconstruction: 0.036974, Regularization: 0.012823\n",
      "2019-04-09 20:44:18,401 root         INFO     Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 0.043469\n",
      "Reconstruction: 0.031269, Regularization: 0.012200\n",
      "2019-04-09 20:44:18,426 root         INFO     Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 0.038350\n",
      "Reconstruction: 0.030014, Regularization: 0.008336\n",
      "2019-04-09 20:44:18,452 root         INFO     Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 0.040505\n",
      "Reconstruction: 0.031694, Regularization: 0.008811\n",
      "2019-04-09 20:44:18,478 root         INFO     Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 0.041325\n",
      "Reconstruction: 0.032351, Regularization: 0.008974\n",
      "2019-04-09 20:44:18,503 root         INFO     Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 0.036269\n",
      "Reconstruction: 0.029232, Regularization: 0.007037\n",
      "2019-04-09 20:44:18,530 root         INFO     Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 0.043724\n",
      "Reconstruction: 0.034886, Regularization: 0.008838\n",
      "2019-04-09 20:44:18,556 root         INFO     Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 0.036795\n",
      "Reconstruction: 0.026760, Regularization: 0.010035\n",
      "2019-04-09 20:44:18,592 root         INFO     ====> Epoch: 185 Average loss: 0.0411\n",
      "2019-04-09 20:44:18,614 root         INFO     Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 0.046314\n",
      "Reconstruction: 0.034369, Regularization: 0.011945\n",
      "2019-04-09 20:44:18,640 root         INFO     Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 0.040903\n",
      "Reconstruction: 0.031548, Regularization: 0.009355\n",
      "2019-04-09 20:44:18,666 root         INFO     Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 0.048857\n",
      "Reconstruction: 0.038784, Regularization: 0.010074\n",
      "2019-04-09 20:44:18,692 root         INFO     Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 0.039019\n",
      "Reconstruction: 0.030595, Regularization: 0.008424\n",
      "2019-04-09 20:44:18,717 root         INFO     Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 0.033960\n",
      "Reconstruction: 0.027978, Regularization: 0.005982\n",
      "2019-04-09 20:44:18,743 root         INFO     Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 0.037956\n",
      "Reconstruction: 0.029016, Regularization: 0.008940\n",
      "2019-04-09 20:44:18,769 root         INFO     Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 0.042506\n",
      "Reconstruction: 0.032682, Regularization: 0.009824\n",
      "2019-04-09 20:44:18,794 root         INFO     Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 0.043804\n",
      "Reconstruction: 0.033013, Regularization: 0.010790\n",
      "2019-04-09 20:44:18,831 root         INFO     ====> Epoch: 186 Average loss: 0.0410\n",
      "2019-04-09 20:44:18,852 root         INFO     Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 0.034184\n",
      "Reconstruction: 0.025723, Regularization: 0.008461\n",
      "2019-04-09 20:44:18,879 root         INFO     Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 0.038937\n",
      "Reconstruction: 0.031350, Regularization: 0.007587\n",
      "2019-04-09 20:44:18,906 root         INFO     Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 0.048783\n",
      "Reconstruction: 0.035265, Regularization: 0.013518\n",
      "2019-04-09 20:44:18,932 root         INFO     Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 0.042768\n",
      "Reconstruction: 0.032817, Regularization: 0.009951\n",
      "2019-04-09 20:44:18,959 root         INFO     Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 0.053655\n",
      "Reconstruction: 0.040967, Regularization: 0.012688\n",
      "2019-04-09 20:44:18,985 root         INFO     Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 0.040852\n",
      "Reconstruction: 0.030484, Regularization: 0.010368\n",
      "2019-04-09 20:44:19,012 root         INFO     Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 0.039651\n",
      "Reconstruction: 0.031815, Regularization: 0.007836\n",
      "2019-04-09 20:44:19,039 root         INFO     Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 0.035343\n",
      "Reconstruction: 0.029138, Regularization: 0.006205\n",
      "2019-04-09 20:44:19,076 root         INFO     ====> Epoch: 187 Average loss: 0.0412\n",
      "2019-04-09 20:44:19,097 root         INFO     Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 0.039126\n",
      "Reconstruction: 0.029975, Regularization: 0.009152\n",
      "2019-04-09 20:44:19,124 root         INFO     Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 0.034223\n",
      "Reconstruction: 0.027151, Regularization: 0.007072\n",
      "2019-04-09 20:44:19,151 root         INFO     Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 0.041778\n",
      "Reconstruction: 0.033147, Regularization: 0.008631\n",
      "2019-04-09 20:44:19,178 root         INFO     Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 0.038108\n",
      "Reconstruction: 0.029704, Regularization: 0.008403\n",
      "2019-04-09 20:44:19,205 root         INFO     Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 0.044186\n",
      "Reconstruction: 0.033412, Regularization: 0.010775\n",
      "2019-04-09 20:44:19,232 root         INFO     Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 0.049317\n",
      "Reconstruction: 0.037905, Regularization: 0.011411\n",
      "2019-04-09 20:44:19,259 root         INFO     Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 0.043867\n",
      "Reconstruction: 0.033535, Regularization: 0.010333\n",
      "2019-04-09 20:44:19,285 root         INFO     Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 0.037959\n",
      "Reconstruction: 0.028499, Regularization: 0.009460\n",
      "2019-04-09 20:44:19,323 root         INFO     ====> Epoch: 188 Average loss: 0.0411\n",
      "2019-04-09 20:44:19,345 root         INFO     Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 0.043819\n",
      "Reconstruction: 0.031338, Regularization: 0.012481\n",
      "2019-04-09 20:44:19,372 root         INFO     Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 0.039974\n",
      "Reconstruction: 0.031431, Regularization: 0.008544\n",
      "2019-04-09 20:44:19,399 root         INFO     Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 0.035594\n",
      "Reconstruction: 0.027056, Regularization: 0.008538\n",
      "2019-04-09 20:44:19,425 root         INFO     Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 0.042597\n",
      "Reconstruction: 0.032206, Regularization: 0.010391\n",
      "2019-04-09 20:44:19,452 root         INFO     Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 0.034428\n",
      "Reconstruction: 0.028699, Regularization: 0.005729\n",
      "2019-04-09 20:44:19,478 root         INFO     Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 0.041649\n",
      "Reconstruction: 0.030331, Regularization: 0.011318\n",
      "2019-04-09 20:44:19,505 root         INFO     Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 0.036125\n",
      "Reconstruction: 0.027993, Regularization: 0.008132\n",
      "2019-04-09 20:44:19,531 root         INFO     Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 0.039200\n",
      "Reconstruction: 0.029035, Regularization: 0.010165\n",
      "2019-04-09 20:44:19,569 root         INFO     ====> Epoch: 189 Average loss: 0.0412\n",
      "2019-04-09 20:44:19,591 root         INFO     Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 0.034444\n",
      "Reconstruction: 0.027319, Regularization: 0.007126\n",
      "2019-04-09 20:44:19,617 root         INFO     Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 0.041417\n",
      "Reconstruction: 0.030592, Regularization: 0.010825\n",
      "2019-04-09 20:44:19,644 root         INFO     Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 0.041378\n",
      "Reconstruction: 0.032078, Regularization: 0.009300\n",
      "2019-04-09 20:44:19,671 root         INFO     Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 0.041293\n",
      "Reconstruction: 0.032310, Regularization: 0.008983\n",
      "2019-04-09 20:44:19,698 root         INFO     Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 0.046021\n",
      "Reconstruction: 0.034903, Regularization: 0.011117\n",
      "2019-04-09 20:44:19,725 root         INFO     Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 0.039702\n",
      "Reconstruction: 0.029184, Regularization: 0.010518\n",
      "2019-04-09 20:44:19,752 root         INFO     Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 0.038402\n",
      "Reconstruction: 0.029204, Regularization: 0.009198\n",
      "2019-04-09 20:44:19,779 root         INFO     Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 0.045637\n",
      "Reconstruction: 0.034234, Regularization: 0.011403\n",
      "2019-04-09 20:44:19,817 root         INFO     ====> Epoch: 190 Average loss: 0.0415\n",
      "2019-04-09 20:44:19,838 root         INFO     Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 0.037785\n",
      "Reconstruction: 0.027588, Regularization: 0.010197\n",
      "2019-04-09 20:44:19,864 root         INFO     Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 0.037496\n",
      "Reconstruction: 0.029850, Regularization: 0.007646\n",
      "2019-04-09 20:44:19,890 root         INFO     Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 0.040818\n",
      "Reconstruction: 0.031544, Regularization: 0.009275\n",
      "2019-04-09 20:44:19,915 root         INFO     Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 0.045786\n",
      "Reconstruction: 0.036311, Regularization: 0.009475\n",
      "2019-04-09 20:44:19,940 root         INFO     Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 0.040047\n",
      "Reconstruction: 0.030910, Regularization: 0.009137\n",
      "2019-04-09 20:44:19,966 root         INFO     Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 0.036770\n",
      "Reconstruction: 0.028701, Regularization: 0.008069\n",
      "2019-04-09 20:44:19,991 root         INFO     Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 0.049892\n",
      "Reconstruction: 0.038508, Regularization: 0.011384\n",
      "2019-04-09 20:44:20,017 root         INFO     Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 0.041172\n",
      "Reconstruction: 0.032917, Regularization: 0.008255\n",
      "2019-04-09 20:44:20,054 root         INFO     ====> Epoch: 191 Average loss: 0.0411\n",
      "2019-04-09 20:44:20,075 root         INFO     Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 0.040057\n",
      "Reconstruction: 0.029189, Regularization: 0.010868\n",
      "2019-04-09 20:44:20,102 root         INFO     Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 0.039231\n",
      "Reconstruction: 0.030447, Regularization: 0.008785\n",
      "2019-04-09 20:44:20,129 root         INFO     Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.034436\n",
      "Reconstruction: 0.026395, Regularization: 0.008041\n",
      "2019-04-09 20:44:20,156 root         INFO     Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 0.037029\n",
      "Reconstruction: 0.028424, Regularization: 0.008605\n",
      "2019-04-09 20:44:20,183 root         INFO     Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 0.038802\n",
      "Reconstruction: 0.029996, Regularization: 0.008806\n",
      "2019-04-09 20:44:20,210 root         INFO     Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 0.039305\n",
      "Reconstruction: 0.030660, Regularization: 0.008645\n",
      "2019-04-09 20:44:20,237 root         INFO     Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 0.036662\n",
      "Reconstruction: 0.029839, Regularization: 0.006822\n",
      "2019-04-09 20:44:20,263 root         INFO     Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 0.040553\n",
      "Reconstruction: 0.031091, Regularization: 0.009462\n",
      "2019-04-09 20:44:20,301 root         INFO     ====> Epoch: 192 Average loss: 0.0408\n",
      "2019-04-09 20:44:20,322 root         INFO     Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 0.037667\n",
      "Reconstruction: 0.030486, Regularization: 0.007180\n",
      "2019-04-09 20:44:20,349 root         INFO     Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 0.048525\n",
      "Reconstruction: 0.036146, Regularization: 0.012378\n",
      "2019-04-09 20:44:20,376 root         INFO     Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 0.041719\n",
      "Reconstruction: 0.033572, Regularization: 0.008147\n",
      "2019-04-09 20:44:20,404 root         INFO     Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 0.048098\n",
      "Reconstruction: 0.036508, Regularization: 0.011591\n",
      "2019-04-09 20:44:20,431 root         INFO     Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 0.039273\n",
      "Reconstruction: 0.031134, Regularization: 0.008139\n",
      "2019-04-09 20:44:20,458 root         INFO     Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 0.043047\n",
      "Reconstruction: 0.030485, Regularization: 0.012562\n",
      "2019-04-09 20:44:20,485 root         INFO     Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 0.040583\n",
      "Reconstruction: 0.029943, Regularization: 0.010640\n",
      "2019-04-09 20:44:20,512 root         INFO     Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 0.042477\n",
      "Reconstruction: 0.031648, Regularization: 0.010829\n",
      "2019-04-09 20:44:20,550 root         INFO     ====> Epoch: 193 Average loss: 0.0411\n",
      "2019-04-09 20:44:20,571 root         INFO     Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 0.035780\n",
      "Reconstruction: 0.028594, Regularization: 0.007186\n",
      "2019-04-09 20:44:20,598 root         INFO     Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 0.037953\n",
      "Reconstruction: 0.029410, Regularization: 0.008543\n",
      "2019-04-09 20:44:20,626 root         INFO     Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 0.045134\n",
      "Reconstruction: 0.036382, Regularization: 0.008752\n",
      "2019-04-09 20:44:20,652 root         INFO     Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 0.044606\n",
      "Reconstruction: 0.035445, Regularization: 0.009161\n",
      "2019-04-09 20:44:20,679 root         INFO     Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 0.044796\n",
      "Reconstruction: 0.031632, Regularization: 0.013164\n",
      "2019-04-09 20:44:20,707 root         INFO     Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 0.040452\n",
      "Reconstruction: 0.030929, Regularization: 0.009523\n",
      "2019-04-09 20:44:20,734 root         INFO     Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 0.050442\n",
      "Reconstruction: 0.038700, Regularization: 0.011742\n",
      "2019-04-09 20:44:20,761 root         INFO     Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 0.043151\n",
      "Reconstruction: 0.033294, Regularization: 0.009857\n",
      "2019-04-09 20:44:20,799 root         INFO     ====> Epoch: 194 Average loss: 0.0414\n",
      "2019-04-09 20:44:20,821 root         INFO     Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 0.042526\n",
      "Reconstruction: 0.032720, Regularization: 0.009805\n",
      "2019-04-09 20:44:20,848 root         INFO     Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 0.038337\n",
      "Reconstruction: 0.031571, Regularization: 0.006766\n",
      "2019-04-09 20:44:20,875 root         INFO     Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 0.037726\n",
      "Reconstruction: 0.030122, Regularization: 0.007605\n",
      "2019-04-09 20:44:20,901 root         INFO     Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 0.044918\n",
      "Reconstruction: 0.034098, Regularization: 0.010820\n",
      "2019-04-09 20:44:20,928 root         INFO     Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 0.041665\n",
      "Reconstruction: 0.031691, Regularization: 0.009975\n",
      "2019-04-09 20:44:20,955 root         INFO     Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 0.038171\n",
      "Reconstruction: 0.028464, Regularization: 0.009707\n",
      "2019-04-09 20:44:20,980 root         INFO     Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 0.037570\n",
      "Reconstruction: 0.029384, Regularization: 0.008186\n",
      "2019-04-09 20:44:21,006 root         INFO     Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 0.041284\n",
      "Reconstruction: 0.031782, Regularization: 0.009502\n",
      "2019-04-09 20:44:21,043 root         INFO     ====> Epoch: 195 Average loss: 0.0412\n",
      "2019-04-09 20:44:21,064 root         INFO     Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 0.034541\n",
      "Reconstruction: 0.025913, Regularization: 0.008628\n",
      "2019-04-09 20:44:21,091 root         INFO     Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 0.040918\n",
      "Reconstruction: 0.031511, Regularization: 0.009407\n",
      "2019-04-09 20:44:21,118 root         INFO     Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 0.040256\n",
      "Reconstruction: 0.031698, Regularization: 0.008558\n",
      "2019-04-09 20:44:21,146 root         INFO     Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 0.050096\n",
      "Reconstruction: 0.039677, Regularization: 0.010419\n",
      "2019-04-09 20:44:21,172 root         INFO     Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 0.041943\n",
      "Reconstruction: 0.033626, Regularization: 0.008317\n",
      "2019-04-09 20:44:21,199 root         INFO     Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 0.043124\n",
      "Reconstruction: 0.032965, Regularization: 0.010159\n",
      "2019-04-09 20:44:21,226 root         INFO     Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 0.035212\n",
      "Reconstruction: 0.026886, Regularization: 0.008325\n",
      "2019-04-09 20:44:21,253 root         INFO     Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 0.038551\n",
      "Reconstruction: 0.029362, Regularization: 0.009189\n",
      "2019-04-09 20:44:21,291 root         INFO     ====> Epoch: 196 Average loss: 0.0409\n",
      "2019-04-09 20:44:21,312 root         INFO     Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 0.037681\n",
      "Reconstruction: 0.029341, Regularization: 0.008340\n",
      "2019-04-09 20:44:21,339 root         INFO     Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 0.039381\n",
      "Reconstruction: 0.030710, Regularization: 0.008671\n",
      "2019-04-09 20:44:21,366 root         INFO     Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 0.041266\n",
      "Reconstruction: 0.032119, Regularization: 0.009147\n",
      "2019-04-09 20:44:21,393 root         INFO     Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 0.038516\n",
      "Reconstruction: 0.029190, Regularization: 0.009326\n",
      "2019-04-09 20:44:21,420 root         INFO     Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 0.037614\n",
      "Reconstruction: 0.028361, Regularization: 0.009253\n",
      "2019-04-09 20:44:21,448 root         INFO     Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 0.034846\n",
      "Reconstruction: 0.026970, Regularization: 0.007876\n",
      "2019-04-09 20:44:21,475 root         INFO     Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 0.034493\n",
      "Reconstruction: 0.027182, Regularization: 0.007311\n",
      "2019-04-09 20:44:21,503 root         INFO     Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 0.048578\n",
      "Reconstruction: 0.036771, Regularization: 0.011808\n",
      "2019-04-09 20:44:21,541 root         INFO     ====> Epoch: 197 Average loss: 0.0407\n",
      "2019-04-09 20:44:21,562 root         INFO     Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 0.046532\n",
      "Reconstruction: 0.035371, Regularization: 0.011161\n",
      "2019-04-09 20:44:21,589 root         INFO     Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.047631\n",
      "Reconstruction: 0.036405, Regularization: 0.011226\n",
      "2019-04-09 20:44:21,616 root         INFO     Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 0.044468\n",
      "Reconstruction: 0.032932, Regularization: 0.011536\n",
      "2019-04-09 20:44:21,643 root         INFO     Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 0.044762\n",
      "Reconstruction: 0.033137, Regularization: 0.011624\n",
      "2019-04-09 20:44:21,670 root         INFO     Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 0.040169\n",
      "Reconstruction: 0.030231, Regularization: 0.009938\n",
      "2019-04-09 20:44:21,697 root         INFO     Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 0.041736\n",
      "Reconstruction: 0.031540, Regularization: 0.010196\n",
      "2019-04-09 20:44:21,724 root         INFO     Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 0.041803\n",
      "Reconstruction: 0.034050, Regularization: 0.007754\n",
      "2019-04-09 20:44:21,750 root         INFO     Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 0.042530\n",
      "Reconstruction: 0.031247, Regularization: 0.011282\n",
      "2019-04-09 20:44:21,788 root         INFO     ====> Epoch: 198 Average loss: 0.0414\n",
      "2019-04-09 20:44:21,809 root         INFO     Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 0.044414\n",
      "Reconstruction: 0.033555, Regularization: 0.010858\n",
      "2019-04-09 20:44:21,837 root         INFO     Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 0.045664\n",
      "Reconstruction: 0.035276, Regularization: 0.010388\n",
      "2019-04-09 20:44:21,865 root         INFO     Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 0.039033\n",
      "Reconstruction: 0.031489, Regularization: 0.007544\n",
      "2019-04-09 20:44:21,892 root         INFO     Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 0.045498\n",
      "Reconstruction: 0.033685, Regularization: 0.011813\n",
      "2019-04-09 20:44:21,919 root         INFO     Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 0.038879\n",
      "Reconstruction: 0.029591, Regularization: 0.009288\n",
      "2019-04-09 20:44:21,946 root         INFO     Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 0.040728\n",
      "Reconstruction: 0.031150, Regularization: 0.009579\n",
      "2019-04-09 20:44:21,974 root         INFO     Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.042535\n",
      "Reconstruction: 0.032587, Regularization: 0.009948\n",
      "2019-04-09 20:44:22,001 root         INFO     Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 0.034320\n",
      "Reconstruction: 0.027919, Regularization: 0.006401\n",
      "2019-04-09 20:44:22,040 root         INFO     ====> Epoch: 199 Average loss: 0.0410\n",
      "2019-04-09 20:44:22,047 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) done      TrainVAE()\n",
      "2019-04-09 20:44:22,048 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 20:44:22,048 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   DONE\n",
      "2019-04-09 20:44:22,048 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 20:44:22,048 luigi-interface DEBUG    Pending tasks: 2\n",
      "2019-04-09 20:44:22,048 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) running   TrainVEM()\n",
      "2019-04-09 20:44:22,049 root         INFO     --Dataset tensor: (10000, 1)\n",
      "2019-04-09 20:44:22,049 root         INFO     -- Train tensor: (8000, 1)\n",
      "2019-04-09 20:44:22,050 root         INFO     Values of VEM's decoder parameters before training:\n",
      "2019-04-09 20:44:22,050 root         INFO     layers.0.weight\n",
      "2019-04-09 20:44:22,050 root         INFO     tensor([[0.5859]], device='cuda:0')\n",
      "2019-04-09 20:44:22,078 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 0.076626\n",
      "Reconstruction: 0.045808, Regularization: 0.000150, Discriminator: 0.022030; Generator: 0.008637,\n",
      "D(x): 0.575, D(G(z)): 0.575\n",
      "2019-04-09 20:44:22,144 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 0.082309\n",
      "Reconstruction: 0.051471, Regularization: 0.000168, Discriminator: 0.022018; Generator: 0.008652,\n",
      "D(x): 0.575, D(G(z)): 0.575\n",
      "2019-04-09 20:44:22,210 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 0.089495\n",
      "Reconstruction: 0.058692, Regularization: 0.000191, Discriminator: 0.021946; Generator: 0.008666,\n",
      "D(x): 0.577, D(G(z)): 0.574\n",
      "2019-04-09 20:44:22,276 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 0.093957\n",
      "Reconstruction: 0.063027, Regularization: 0.000203, Discriminator: 0.022048; Generator: 0.008680,\n",
      "D(x): 0.572, D(G(z)): 0.574\n",
      "2019-04-09 20:44:22,342 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 0.076134\n",
      "Reconstruction: 0.045266, Regularization: 0.000123, Discriminator: 0.022052; Generator: 0.008693,\n",
      "D(x): 0.571, D(G(z)): 0.573\n",
      "2019-04-09 20:44:22,408 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 0.081444\n",
      "Reconstruction: 0.050608, Regularization: 0.000141, Discriminator: 0.021987; Generator: 0.008708,\n",
      "D(x): 0.573, D(G(z)): 0.573\n",
      "2019-04-09 20:44:22,474 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 0.096468\n",
      "Reconstruction: 0.065506, Regularization: 0.000193, Discriminator: 0.022045; Generator: 0.008724,\n",
      "D(x): 0.570, D(G(z)): 0.572\n",
      "2019-04-09 20:44:22,539 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 0.076140\n",
      "Reconstruction: 0.045303, Regularization: 0.000112, Discriminator: 0.021987; Generator: 0.008738,\n",
      "D(x): 0.572, D(G(z)): 0.572\n",
      "2019-04-09 20:44:22,607 root         INFO     ====> Epoch: 0 Average loss: 0.0832\n",
      "2019-04-09 20:44:22,631 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 0.082681\n",
      "Reconstruction: 0.051779, Regularization: 0.000133, Discriminator: 0.022020; Generator: 0.008749,\n",
      "D(x): 0.570, D(G(z)): 0.571\n",
      "2019-04-09 20:44:22,698 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 0.082896\n",
      "Reconstruction: 0.051974, Regularization: 0.000130, Discriminator: 0.022028; Generator: 0.008764,\n",
      "D(x): 0.569, D(G(z)): 0.571\n",
      "2019-04-09 20:44:22,764 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 0.085940\n",
      "Reconstruction: 0.055002, Regularization: 0.000136, Discriminator: 0.022022; Generator: 0.008779,\n",
      "D(x): 0.568, D(G(z)): 0.570\n",
      "2019-04-09 20:44:22,830 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 0.086426\n",
      "Reconstruction: 0.055561, Regularization: 0.000137, Discriminator: 0.021935; Generator: 0.008793,\n",
      "D(x): 0.571, D(G(z)): 0.570\n",
      "2019-04-09 20:44:22,897 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 0.079359\n",
      "Reconstruction: 0.048508, Regularization: 0.000113, Discriminator: 0.021928; Generator: 0.008811,\n",
      "D(x): 0.570, D(G(z)): 0.569\n",
      "2019-04-09 20:44:22,963 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 0.078771\n",
      "Reconstruction: 0.047874, Regularization: 0.000108, Discriminator: 0.021965; Generator: 0.008824,\n",
      "D(x): 0.568, D(G(z)): 0.569\n",
      "2019-04-09 20:44:23,030 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 0.084035\n",
      "Reconstruction: 0.053046, Regularization: 0.000125, Discriminator: 0.022025; Generator: 0.008839,\n",
      "D(x): 0.565, D(G(z)): 0.568\n",
      "2019-04-09 20:44:23,096 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 0.079373\n",
      "Reconstruction: 0.048411, Regularization: 0.000107, Discriminator: 0.021999; Generator: 0.008856,\n",
      "D(x): 0.566, D(G(z)): 0.567\n",
      "2019-04-09 20:44:23,164 root         INFO     ====> Epoch: 1 Average loss: 0.0833\n",
      "2019-04-09 20:44:23,188 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 0.082304\n",
      "Reconstruction: 0.051435, Regularization: 0.000117, Discriminator: 0.021885; Generator: 0.008868,\n",
      "D(x): 0.569, D(G(z)): 0.567\n",
      "2019-04-09 20:44:23,252 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 0.075045\n",
      "Reconstruction: 0.044101, Regularization: 0.000092, Discriminator: 0.021968; Generator: 0.008884,\n",
      "D(x): 0.565, D(G(z)): 0.566\n",
      "2019-04-09 20:44:23,316 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 0.083584\n",
      "Reconstruction: 0.052597, Regularization: 0.000116, Discriminator: 0.021972; Generator: 0.008899,\n",
      "D(x): 0.565, D(G(z)): 0.566\n",
      "2019-04-09 20:44:23,380 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 0.081539\n",
      "Reconstruction: 0.050483, Regularization: 0.000110, Discriminator: 0.022029; Generator: 0.008918,\n",
      "D(x): 0.562, D(G(z)): 0.565\n",
      "2019-04-09 20:44:23,444 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 0.084066\n",
      "Reconstruction: 0.053144, Regularization: 0.000117, Discriminator: 0.021874; Generator: 0.008931,\n",
      "D(x): 0.567, D(G(z)): 0.565\n",
      "2019-04-09 20:44:23,508 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 0.084614\n",
      "Reconstruction: 0.053668, Regularization: 0.000117, Discriminator: 0.021883; Generator: 0.008946,\n",
      "D(x): 0.566, D(G(z)): 0.564\n",
      "2019-04-09 20:44:23,572 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 0.083321\n",
      "Reconstruction: 0.052280, Regularization: 0.000113, Discriminator: 0.021965; Generator: 0.008963,\n",
      "D(x): 0.562, D(G(z)): 0.563\n",
      "2019-04-09 20:44:23,636 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 0.079242\n",
      "Reconstruction: 0.048299, Regularization: 0.000099, Discriminator: 0.021869; Generator: 0.008974,\n",
      "D(x): 0.565, D(G(z)): 0.563\n",
      "2019-04-09 20:44:23,701 root         INFO     ====> Epoch: 2 Average loss: 0.0834\n",
      "2019-04-09 20:44:23,726 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 0.093606\n",
      "Reconstruction: 0.062522, Regularization: 0.000142, Discriminator: 0.021954; Generator: 0.008988,\n",
      "D(x): 0.561, D(G(z)): 0.563\n",
      "2019-04-09 20:44:23,789 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 0.082521\n",
      "Reconstruction: 0.051543, Regularization: 0.000111, Discriminator: 0.021860; Generator: 0.009007,\n",
      "D(x): 0.564, D(G(z)): 0.562\n",
      "2019-04-09 20:44:23,852 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 0.075356\n",
      "Reconstruction: 0.044352, Regularization: 0.000091, Discriminator: 0.021888; Generator: 0.009025,\n",
      "D(x): 0.562, D(G(z)): 0.561\n",
      "2019-04-09 20:44:23,916 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 0.094912\n",
      "Reconstruction: 0.063845, Regularization: 0.000150, Discriminator: 0.021877; Generator: 0.009040,\n",
      "D(x): 0.562, D(G(z)): 0.561\n",
      "2019-04-09 20:44:23,985 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 0.072805\n",
      "Reconstruction: 0.041649, Regularization: 0.000084, Discriminator: 0.022018; Generator: 0.009054,\n",
      "D(x): 0.556, D(G(z)): 0.560\n",
      "2019-04-09 20:44:24,053 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 0.088094\n",
      "Reconstruction: 0.057038, Regularization: 0.000131, Discriminator: 0.021851; Generator: 0.009073,\n",
      "D(x): 0.561, D(G(z)): 0.560\n",
      "2019-04-09 20:44:24,122 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 0.082469\n",
      "Reconstruction: 0.051435, Regularization: 0.000114, Discriminator: 0.021833; Generator: 0.009087,\n",
      "D(x): 0.561, D(G(z)): 0.559\n",
      "2019-04-09 20:44:24,191 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 0.089553\n",
      "Reconstruction: 0.058429, Regularization: 0.000135, Discriminator: 0.021887; Generator: 0.009101,\n",
      "D(x): 0.558, D(G(z)): 0.559\n",
      "2019-04-09 20:44:24,261 root         INFO     ====> Epoch: 3 Average loss: 0.0835\n",
      "2019-04-09 20:44:24,285 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 0.074027\n",
      "Reconstruction: 0.042926, Regularization: 0.000088, Discriminator: 0.021899; Generator: 0.009113,\n",
      "D(x): 0.557, D(G(z)): 0.558\n",
      "2019-04-09 20:44:24,353 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 0.081634\n",
      "Reconstruction: 0.050523, Regularization: 0.000111, Discriminator: 0.021874; Generator: 0.009127,\n",
      "D(x): 0.558, D(G(z)): 0.558\n",
      "2019-04-09 20:44:24,420 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 0.092651\n",
      "Reconstruction: 0.061588, Regularization: 0.000144, Discriminator: 0.021777; Generator: 0.009143,\n",
      "D(x): 0.561, D(G(z)): 0.557\n",
      "2019-04-09 20:44:24,487 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 0.082290\n",
      "Reconstruction: 0.051231, Regularization: 0.000112, Discriminator: 0.021789; Generator: 0.009158,\n",
      "D(x): 0.559, D(G(z)): 0.556\n",
      "2019-04-09 20:44:24,554 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 0.077156\n",
      "Reconstruction: 0.045957, Regularization: 0.000094, Discriminator: 0.021924; Generator: 0.009182,\n",
      "D(x): 0.554, D(G(z)): 0.556\n",
      "2019-04-09 20:44:24,621 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 0.096094\n",
      "Reconstruction: 0.065086, Regularization: 0.000147, Discriminator: 0.021669; Generator: 0.009192,\n",
      "D(x): 0.562, D(G(z)): 0.555\n",
      "2019-04-09 20:44:24,688 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 0.078629\n",
      "Reconstruction: 0.047577, Regularization: 0.000096, Discriminator: 0.021747; Generator: 0.009209,\n",
      "D(x): 0.559, D(G(z)): 0.555\n",
      "2019-04-09 20:44:24,756 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 0.085593\n",
      "Reconstruction: 0.054398, Regularization: 0.000114, Discriminator: 0.021854; Generator: 0.009226,\n",
      "D(x): 0.554, D(G(z)): 0.554\n",
      "2019-04-09 20:44:24,824 root         INFO     ====> Epoch: 4 Average loss: 0.0836\n",
      "2019-04-09 20:44:24,849 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 0.088211\n",
      "Reconstruction: 0.057094, Regularization: 0.000122, Discriminator: 0.021756; Generator: 0.009240,\n",
      "D(x): 0.557, D(G(z)): 0.554\n",
      "2019-04-09 20:44:24,916 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 0.076023\n",
      "Reconstruction: 0.044706, Regularization: 0.000085, Discriminator: 0.021973; Generator: 0.009259,\n",
      "D(x): 0.548, D(G(z)): 0.553\n",
      "2019-04-09 20:44:24,984 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 0.076183\n",
      "Reconstruction: 0.044988, Regularization: 0.000087, Discriminator: 0.021836; Generator: 0.009272,\n",
      "D(x): 0.553, D(G(z)): 0.552\n",
      "2019-04-09 20:44:25,050 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 0.093942\n",
      "Reconstruction: 0.062668, Regularization: 0.000138, Discriminator: 0.021844; Generator: 0.009292,\n",
      "D(x): 0.552, D(G(z)): 0.552\n",
      "2019-04-09 20:44:25,113 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 0.090520\n",
      "Reconstruction: 0.059211, Regularization: 0.000127, Discriminator: 0.021877; Generator: 0.009304,\n",
      "D(x): 0.550, D(G(z)): 0.551\n",
      "2019-04-09 20:44:25,178 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 0.083025\n",
      "Reconstruction: 0.051794, Regularization: 0.000107, Discriminator: 0.021801; Generator: 0.009323,\n",
      "D(x): 0.552, D(G(z)): 0.551\n",
      "2019-04-09 20:44:25,242 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 0.081607\n",
      "Reconstruction: 0.050353, Regularization: 0.000102, Discriminator: 0.021813; Generator: 0.009339,\n",
      "D(x): 0.551, D(G(z)): 0.550\n",
      "2019-04-09 20:44:25,306 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 0.082885\n",
      "Reconstruction: 0.051640, Regularization: 0.000106, Discriminator: 0.021784; Generator: 0.009356,\n",
      "D(x): 0.551, D(G(z)): 0.549\n",
      "2019-04-09 20:44:25,371 root         INFO     ====> Epoch: 5 Average loss: 0.0837\n",
      "2019-04-09 20:44:25,395 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 0.090661\n",
      "Reconstruction: 0.059413, Regularization: 0.000129, Discriminator: 0.021749; Generator: 0.009370,\n",
      "D(x): 0.552, D(G(z)): 0.549\n",
      "2019-04-09 20:44:25,464 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 0.082088\n",
      "Reconstruction: 0.050776, Regularization: 0.000104, Discriminator: 0.021822; Generator: 0.009385,\n",
      "D(x): 0.548, D(G(z)): 0.548\n",
      "2019-04-09 20:44:25,531 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 0.086798\n",
      "Reconstruction: 0.055469, Regularization: 0.000119, Discriminator: 0.021806; Generator: 0.009404,\n",
      "D(x): 0.548, D(G(z)): 0.548\n",
      "2019-04-09 20:44:25,599 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 0.084316\n",
      "Reconstruction: 0.053094, Regularization: 0.000111, Discriminator: 0.021690; Generator: 0.009420,\n",
      "D(x): 0.552, D(G(z)): 0.547\n",
      "2019-04-09 20:44:25,667 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 0.069299\n",
      "Reconstruction: 0.037899, Regularization: 0.000066, Discriminator: 0.021896; Generator: 0.009438,\n",
      "D(x): 0.543, D(G(z)): 0.547\n",
      "2019-04-09 20:44:25,735 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 0.077581\n",
      "Reconstruction: 0.046272, Regularization: 0.000090, Discriminator: 0.021770; Generator: 0.009449,\n",
      "D(x): 0.548, D(G(z)): 0.546\n",
      "2019-04-09 20:44:25,803 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 0.082623\n",
      "Reconstruction: 0.051150, Regularization: 0.000104, Discriminator: 0.021898; Generator: 0.009471,\n",
      "D(x): 0.542, D(G(z)): 0.545\n",
      "2019-04-09 20:44:25,871 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 0.092883\n",
      "Reconstruction: 0.061650, Regularization: 0.000130, Discriminator: 0.021620; Generator: 0.009483,\n",
      "D(x): 0.552, D(G(z)): 0.545\n",
      "2019-04-09 20:44:25,939 root         INFO     ====> Epoch: 6 Average loss: 0.0838\n",
      "2019-04-09 20:44:25,964 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 0.074933\n",
      "Reconstruction: 0.043507, Regularization: 0.000080, Discriminator: 0.021849; Generator: 0.009497,\n",
      "D(x): 0.543, D(G(z)): 0.545\n",
      "2019-04-09 20:44:26,032 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 0.087238\n",
      "Reconstruction: 0.055878, Regularization: 0.000114, Discriminator: 0.021736; Generator: 0.009511,\n",
      "D(x): 0.546, D(G(z)): 0.544\n",
      "2019-04-09 20:44:26,101 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 0.090159\n",
      "Reconstruction: 0.058862, Regularization: 0.000124, Discriminator: 0.021649; Generator: 0.009525,\n",
      "D(x): 0.549, D(G(z)): 0.544\n",
      "2019-04-09 20:44:26,169 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 0.076246\n",
      "Reconstruction: 0.044848, Regularization: 0.000083, Discriminator: 0.021771; Generator: 0.009544,\n",
      "D(x): 0.544, D(G(z)): 0.543\n",
      "2019-04-09 20:44:26,238 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 0.076058\n",
      "Reconstruction: 0.044651, Regularization: 0.000082, Discriminator: 0.021764; Generator: 0.009561,\n",
      "D(x): 0.543, D(G(z)): 0.542\n",
      "2019-04-09 20:44:26,306 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 0.088270\n",
      "Reconstruction: 0.056685, Regularization: 0.000116, Discriminator: 0.021893; Generator: 0.009576,\n",
      "D(x): 0.538, D(G(z)): 0.542\n",
      "2019-04-09 20:44:26,375 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 0.087700\n",
      "Reconstruction: 0.056180, Regularization: 0.000115, Discriminator: 0.021807; Generator: 0.009597,\n",
      "D(x): 0.540, D(G(z)): 0.541\n",
      "2019-04-09 20:44:26,443 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 0.074373\n",
      "Reconstruction: 0.042818, Regularization: 0.000079, Discriminator: 0.021868; Generator: 0.009609,\n",
      "D(x): 0.538, D(G(z)): 0.541\n",
      "2019-04-09 20:44:26,512 root         INFO     ====> Epoch: 7 Average loss: 0.0839\n",
      "2019-04-09 20:44:26,536 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 0.093544\n",
      "Reconstruction: 0.062034, Regularization: 0.000135, Discriminator: 0.021751; Generator: 0.009623,\n",
      "D(x): 0.541, D(G(z)): 0.540\n",
      "2019-04-09 20:44:26,604 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 0.080121\n",
      "Reconstruction: 0.048752, Regularization: 0.000098, Discriminator: 0.021635; Generator: 0.009635,\n",
      "D(x): 0.545, D(G(z)): 0.540\n",
      "2019-04-09 20:44:26,671 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 0.078516\n",
      "Reconstruction: 0.047077, Regularization: 0.000095, Discriminator: 0.021694; Generator: 0.009651,\n",
      "D(x): 0.542, D(G(z)): 0.539\n",
      "2019-04-09 20:44:26,738 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 0.078433\n",
      "Reconstruction: 0.047002, Regularization: 0.000094, Discriminator: 0.021672; Generator: 0.009664,\n",
      "D(x): 0.542, D(G(z)): 0.539\n",
      "2019-04-09 20:44:26,804 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 0.094054\n",
      "Reconstruction: 0.062557, Regularization: 0.000141, Discriminator: 0.021672; Generator: 0.009684,\n",
      "D(x): 0.542, D(G(z)): 0.538\n",
      "2019-04-09 20:44:26,871 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 0.086285\n",
      "Reconstruction: 0.054898, Regularization: 0.000120, Discriminator: 0.021564; Generator: 0.009702,\n",
      "D(x): 0.545, D(G(z)): 0.537\n",
      "2019-04-09 20:44:26,938 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 0.089475\n",
      "Reconstruction: 0.057789, Regularization: 0.000128, Discriminator: 0.021844; Generator: 0.009715,\n",
      "D(x): 0.535, D(G(z)): 0.537\n",
      "2019-04-09 20:44:27,006 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 0.091221\n",
      "Reconstruction: 0.059631, Regularization: 0.000133, Discriminator: 0.021731; Generator: 0.009727,\n",
      "D(x): 0.538, D(G(z)): 0.537\n",
      "2019-04-09 20:44:27,074 root         INFO     ====> Epoch: 8 Average loss: 0.0840\n",
      "2019-04-09 20:44:27,098 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 0.076289\n",
      "Reconstruction: 0.044733, Regularization: 0.000091, Discriminator: 0.021721; Generator: 0.009744,\n",
      "D(x): 0.537, D(G(z)): 0.536\n",
      "2019-04-09 20:44:27,166 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 0.089687\n",
      "Reconstruction: 0.057872, Regularization: 0.000129, Discriminator: 0.021929; Generator: 0.009758,\n",
      "D(x): 0.530, D(G(z)): 0.536\n",
      "2019-04-09 20:44:27,233 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 0.084529\n",
      "Reconstruction: 0.052881, Regularization: 0.000114, Discriminator: 0.021761; Generator: 0.009773,\n",
      "D(x): 0.535, D(G(z)): 0.535\n",
      "2019-04-09 20:44:27,301 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 0.077234\n",
      "Reconstruction: 0.045647, Regularization: 0.000092, Discriminator: 0.021711; Generator: 0.009784,\n",
      "D(x): 0.536, D(G(z)): 0.535\n",
      "2019-04-09 20:44:27,368 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 0.086649\n",
      "Reconstruction: 0.054846, Regularization: 0.000118, Discriminator: 0.021881; Generator: 0.009804,\n",
      "D(x): 0.530, D(G(z)): 0.534\n",
      "2019-04-09 20:44:27,435 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 0.078339\n",
      "Reconstruction: 0.046607, Regularization: 0.000093, Discriminator: 0.021827; Generator: 0.009812,\n",
      "D(x): 0.531, D(G(z)): 0.534\n",
      "2019-04-09 20:44:27,502 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 0.070463\n",
      "Reconstruction: 0.038850, Regularization: 0.000071, Discriminator: 0.021707; Generator: 0.009835,\n",
      "D(x): 0.534, D(G(z)): 0.533\n",
      "2019-04-09 20:44:27,568 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 0.080456\n",
      "Reconstruction: 0.048769, Regularization: 0.000099, Discriminator: 0.021740; Generator: 0.009847,\n",
      "D(x): 0.533, D(G(z)): 0.532\n",
      "2019-04-09 20:44:27,636 root         INFO     ====> Epoch: 9 Average loss: 0.0841\n",
      "2019-04-09 20:44:27,661 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 0.089358\n",
      "Reconstruction: 0.057747, Regularization: 0.000125, Discriminator: 0.021624; Generator: 0.009862,\n",
      "D(x): 0.536, D(G(z)): 0.532\n",
      "2019-04-09 20:44:27,733 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 0.088550\n",
      "Reconstruction: 0.056991, Regularization: 0.000122, Discriminator: 0.021560; Generator: 0.009877,\n",
      "D(x): 0.538, D(G(z)): 0.531\n",
      "2019-04-09 20:44:27,798 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 0.089209\n",
      "Reconstruction: 0.057176, Regularization: 0.000123, Discriminator: 0.022017; Generator: 0.009892,\n",
      "D(x): 0.522, D(G(z)): 0.531\n",
      "2019-04-09 20:44:27,864 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 0.080845\n",
      "Reconstruction: 0.049196, Regularization: 0.000100, Discriminator: 0.021645; Generator: 0.009904,\n",
      "D(x): 0.534, D(G(z)): 0.531\n",
      "2019-04-09 20:44:27,930 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 0.081240\n",
      "Reconstruction: 0.049457, Regularization: 0.000100, Discriminator: 0.021764; Generator: 0.009919,\n",
      "D(x): 0.529, D(G(z)): 0.530\n",
      "2019-04-09 20:44:27,996 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 0.094788\n",
      "Reconstruction: 0.062879, Regularization: 0.000138, Discriminator: 0.021829; Generator: 0.009942,\n",
      "D(x): 0.526, D(G(z)): 0.529\n",
      "2019-04-09 20:44:28,062 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 0.085419\n",
      "Reconstruction: 0.053592, Regularization: 0.000112, Discriminator: 0.021764; Generator: 0.009951,\n",
      "D(x): 0.528, D(G(z)): 0.529\n",
      "2019-04-09 20:44:28,128 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 0.089646\n",
      "Reconstruction: 0.057930, Regularization: 0.000125, Discriminator: 0.021626; Generator: 0.009966,\n",
      "D(x): 0.532, D(G(z)): 0.528\n",
      "2019-04-09 20:44:28,196 root         INFO     ====> Epoch: 10 Average loss: 0.0843\n",
      "2019-04-09 20:44:28,220 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.083179\n",
      "Reconstruction: 0.051467, Regularization: 0.000107, Discriminator: 0.021632; Generator: 0.009972,\n",
      "D(x): 0.532, D(G(z)): 0.528\n",
      "2019-04-09 20:44:28,286 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 0.097543\n",
      "Reconstruction: 0.065569, Regularization: 0.000147, Discriminator: 0.021838; Generator: 0.009989,\n",
      "D(x): 0.524, D(G(z)): 0.528\n",
      "2019-04-09 20:44:28,352 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.095241\n",
      "Reconstruction: 0.063485, Regularization: 0.000141, Discriminator: 0.021613; Generator: 0.010003,\n",
      "D(x): 0.531, D(G(z)): 0.527\n",
      "2019-04-09 20:44:28,418 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 0.076023\n",
      "Reconstruction: 0.044260, Regularization: 0.000086, Discriminator: 0.021659; Generator: 0.010019,\n",
      "D(x): 0.529, D(G(z)): 0.527\n",
      "2019-04-09 20:44:28,484 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 0.074659\n",
      "Reconstruction: 0.042699, Regularization: 0.000079, Discriminator: 0.021853; Generator: 0.010029,\n",
      "D(x): 0.522, D(G(z)): 0.526\n",
      "2019-04-09 20:44:28,549 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 0.089603\n",
      "Reconstruction: 0.057877, Regularization: 0.000122, Discriminator: 0.021563; Generator: 0.010041,\n",
      "D(x): 0.532, D(G(z)): 0.526\n",
      "2019-04-09 20:44:28,615 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.074310\n",
      "Reconstruction: 0.042638, Regularization: 0.000078, Discriminator: 0.021539; Generator: 0.010056,\n",
      "D(x): 0.532, D(G(z)): 0.525\n",
      "2019-04-09 20:44:28,680 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 0.073152\n",
      "Reconstruction: 0.041324, Regularization: 0.000072, Discriminator: 0.021692; Generator: 0.010063,\n",
      "D(x): 0.526, D(G(z)): 0.525\n",
      "2019-04-09 20:44:28,747 root         INFO     ====> Epoch: 11 Average loss: 0.0843\n",
      "2019-04-09 20:44:28,771 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 0.085357\n",
      "Reconstruction: 0.053443, Regularization: 0.000103, Discriminator: 0.021733; Generator: 0.010078,\n",
      "D(x): 0.524, D(G(z)): 0.525\n",
      "2019-04-09 20:44:28,834 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 0.078449\n",
      "Reconstruction: 0.046706, Regularization: 0.000086, Discriminator: 0.021568; Generator: 0.010090,\n",
      "D(x): 0.529, D(G(z)): 0.524\n",
      "2019-04-09 20:44:28,897 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 0.084860\n",
      "Reconstruction: 0.052994, Regularization: 0.000103, Discriminator: 0.021660; Generator: 0.010103,\n",
      "D(x): 0.526, D(G(z)): 0.524\n",
      "2019-04-09 20:44:28,960 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 0.093978\n",
      "Reconstruction: 0.062064, Regularization: 0.000130, Discriminator: 0.021668; Generator: 0.010116,\n",
      "D(x): 0.525, D(G(z)): 0.523\n",
      "2019-04-09 20:44:29,023 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 0.095831\n",
      "Reconstruction: 0.063719, Regularization: 0.000139, Discriminator: 0.021845; Generator: 0.010128,\n",
      "D(x): 0.519, D(G(z)): 0.523\n",
      "2019-04-09 20:44:29,086 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.080777\n",
      "Reconstruction: 0.048801, Regularization: 0.000097, Discriminator: 0.021727; Generator: 0.010153,\n",
      "D(x): 0.522, D(G(z)): 0.522\n",
      "2019-04-09 20:44:29,149 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.089762\n",
      "Reconstruction: 0.057663, Regularization: 0.000122, Discriminator: 0.021823; Generator: 0.010154,\n",
      "D(x): 0.519, D(G(z)): 0.522\n",
      "2019-04-09 20:44:29,212 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 0.079490\n",
      "Reconstruction: 0.047442, Regularization: 0.000092, Discriminator: 0.021797; Generator: 0.010159,\n",
      "D(x): 0.519, D(G(z)): 0.522\n",
      "2019-04-09 20:44:29,278 root         INFO     ====> Epoch: 12 Average loss: 0.0844\n",
      "2019-04-09 20:44:29,302 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 0.093303\n",
      "Reconstruction: 0.061342, Regularization: 0.000133, Discriminator: 0.021655; Generator: 0.010173,\n",
      "D(x): 0.524, D(G(z)): 0.521\n",
      "2019-04-09 20:44:29,369 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 0.082664\n",
      "Reconstruction: 0.050514, Regularization: 0.000104, Discriminator: 0.021869; Generator: 0.010177,\n",
      "D(x): 0.516, D(G(z)): 0.521\n",
      "2019-04-09 20:44:29,439 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 0.080112\n",
      "Reconstruction: 0.047889, Regularization: 0.000094, Discriminator: 0.021940; Generator: 0.010189,\n",
      "D(x): 0.513, D(G(z)): 0.521\n",
      "2019-04-09 20:44:29,508 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 0.086061\n",
      "Reconstruction: 0.054131, Regularization: 0.000109, Discriminator: 0.021622; Generator: 0.010200,\n",
      "D(x): 0.524, D(G(z)): 0.521\n",
      "2019-04-09 20:44:29,577 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 0.077004\n",
      "Reconstruction: 0.045032, Regularization: 0.000082, Discriminator: 0.021677; Generator: 0.010213,\n",
      "D(x): 0.521, D(G(z)): 0.520\n",
      "2019-04-09 20:44:29,647 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 0.076910\n",
      "Reconstruction: 0.044794, Regularization: 0.000081, Discriminator: 0.021818; Generator: 0.010218,\n",
      "D(x): 0.516, D(G(z)): 0.520\n",
      "2019-04-09 20:44:29,716 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 0.088464\n",
      "Reconstruction: 0.056459, Regularization: 0.000112, Discriminator: 0.021655; Generator: 0.010238,\n",
      "D(x): 0.521, D(G(z)): 0.519\n",
      "2019-04-09 20:44:29,786 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 0.069020\n",
      "Reconstruction: 0.037046, Regularization: 0.000060, Discriminator: 0.021661; Generator: 0.010252,\n",
      "D(x): 0.520, D(G(z)): 0.519\n",
      "2019-04-09 20:44:29,857 root         INFO     ====> Epoch: 13 Average loss: 0.0845\n",
      "2019-04-09 20:44:29,881 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.089351\n",
      "Reconstruction: 0.057412, Regularization: 0.000112, Discriminator: 0.021570; Generator: 0.010258,\n",
      "D(x): 0.523, D(G(z)): 0.519\n",
      "2019-04-09 20:44:29,948 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.081675\n",
      "Reconstruction: 0.049651, Regularization: 0.000089, Discriminator: 0.021664; Generator: 0.010270,\n",
      "D(x): 0.520, D(G(z)): 0.518\n",
      "2019-04-09 20:44:30,016 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 0.084994\n",
      "Reconstruction: 0.052854, Regularization: 0.000094, Discriminator: 0.021767; Generator: 0.010279,\n",
      "D(x): 0.516, D(G(z)): 0.518\n",
      "2019-04-09 20:44:30,083 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.091698\n",
      "Reconstruction: 0.059547, Regularization: 0.000112, Discriminator: 0.021753; Generator: 0.010286,\n",
      "D(x): 0.516, D(G(z)): 0.518\n",
      "2019-04-09 20:44:30,151 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.078872\n",
      "Reconstruction: 0.046865, Regularization: 0.000080, Discriminator: 0.021623; Generator: 0.010304,\n",
      "D(x): 0.520, D(G(z)): 0.517\n",
      "2019-04-09 20:44:30,218 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 0.084395\n",
      "Reconstruction: 0.052240, Regularization: 0.000093, Discriminator: 0.021757; Generator: 0.010305,\n",
      "D(x): 0.515, D(G(z)): 0.517\n",
      "2019-04-09 20:44:30,283 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.076046\n",
      "Reconstruction: 0.043743, Regularization: 0.000074, Discriminator: 0.021911; Generator: 0.010318,\n",
      "D(x): 0.510, D(G(z)): 0.517\n",
      "2019-04-09 20:44:30,348 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.078690\n",
      "Reconstruction: 0.046571, Regularization: 0.000081, Discriminator: 0.021714; Generator: 0.010325,\n",
      "D(x): 0.516, D(G(z)): 0.516\n",
      "2019-04-09 20:44:30,414 root         INFO     ====> Epoch: 14 Average loss: 0.0846\n",
      "2019-04-09 20:44:30,438 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 0.093106\n",
      "Reconstruction: 0.060801, Regularization: 0.000117, Discriminator: 0.021853; Generator: 0.010336,\n",
      "D(x): 0.511, D(G(z)): 0.516\n",
      "2019-04-09 20:44:30,507 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 0.092950\n",
      "Reconstruction: 0.060936, Regularization: 0.000116, Discriminator: 0.021551; Generator: 0.010347,\n",
      "D(x): 0.521, D(G(z)): 0.516\n",
      "2019-04-09 20:44:30,575 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.101549\n",
      "Reconstruction: 0.069177, Regularization: 0.000133, Discriminator: 0.021887; Generator: 0.010352,\n",
      "D(x): 0.510, D(G(z)): 0.516\n",
      "2019-04-09 20:44:30,643 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.079753\n",
      "Reconstruction: 0.047730, Regularization: 0.000081, Discriminator: 0.021585; Generator: 0.010357,\n",
      "D(x): 0.519, D(G(z)): 0.515\n",
      "2019-04-09 20:44:30,711 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.092237\n",
      "Reconstruction: 0.060179, Regularization: 0.000110, Discriminator: 0.021575; Generator: 0.010374,\n",
      "D(x): 0.519, D(G(z)): 0.515\n",
      "2019-04-09 20:44:30,778 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.096155\n",
      "Reconstruction: 0.063993, Regularization: 0.000118, Discriminator: 0.021659; Generator: 0.010385,\n",
      "D(x): 0.516, D(G(z)): 0.514\n",
      "2019-04-09 20:44:30,845 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.073681\n",
      "Reconstruction: 0.041533, Regularization: 0.000064, Discriminator: 0.021691; Generator: 0.010393,\n",
      "D(x): 0.514, D(G(z)): 0.514\n",
      "2019-04-09 20:44:30,912 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 0.090416\n",
      "Reconstruction: 0.058198, Regularization: 0.000104, Discriminator: 0.021715; Generator: 0.010399,\n",
      "D(x): 0.514, D(G(z)): 0.514\n",
      "2019-04-09 20:44:30,980 root         INFO     ====> Epoch: 15 Average loss: 0.0846\n",
      "2019-04-09 20:44:31,004 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 0.101962\n",
      "Reconstruction: 0.069588, Regularization: 0.000130, Discriminator: 0.021837; Generator: 0.010407,\n",
      "D(x): 0.510, D(G(z)): 0.514\n",
      "2019-04-09 20:44:31,071 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 0.073311\n",
      "Reconstruction: 0.041167, Regularization: 0.000063, Discriminator: 0.021672; Generator: 0.010409,\n",
      "D(x): 0.514, D(G(z)): 0.514\n",
      "2019-04-09 20:44:31,138 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.099511\n",
      "Reconstruction: 0.067108, Regularization: 0.000123, Discriminator: 0.021860; Generator: 0.010420,\n",
      "D(x): 0.508, D(G(z)): 0.513\n",
      "2019-04-09 20:44:31,206 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 0.088963\n",
      "Reconstruction: 0.056659, Regularization: 0.000099, Discriminator: 0.021773; Generator: 0.010432,\n",
      "D(x): 0.511, D(G(z)): 0.513\n",
      "2019-04-09 20:44:31,273 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 0.085943\n",
      "Reconstruction: 0.053817, Regularization: 0.000093, Discriminator: 0.021594; Generator: 0.010439,\n",
      "D(x): 0.516, D(G(z)): 0.513\n",
      "2019-04-09 20:44:31,341 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 0.076957\n",
      "Reconstruction: 0.044753, Regularization: 0.000071, Discriminator: 0.021683; Generator: 0.010449,\n",
      "D(x): 0.513, D(G(z)): 0.512\n",
      "2019-04-09 20:44:31,409 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 0.085184\n",
      "Reconstruction: 0.052892, Regularization: 0.000090, Discriminator: 0.021750; Generator: 0.010451,\n",
      "D(x): 0.511, D(G(z)): 0.512\n",
      "2019-04-09 20:44:31,476 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.097236\n",
      "Reconstruction: 0.065153, Regularization: 0.000120, Discriminator: 0.021506; Generator: 0.010457,\n",
      "D(x): 0.519, D(G(z)): 0.512\n",
      "2019-04-09 20:44:31,545 root         INFO     ====> Epoch: 16 Average loss: 0.0847\n",
      "2019-04-09 20:44:31,569 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.085334\n",
      "Reconstruction: 0.052994, Regularization: 0.000094, Discriminator: 0.021780; Generator: 0.010467,\n",
      "D(x): 0.509, D(G(z)): 0.512\n",
      "2019-04-09 20:44:31,635 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 0.090089\n",
      "Reconstruction: 0.057867, Regularization: 0.000105, Discriminator: 0.021646; Generator: 0.010471,\n",
      "D(x): 0.513, D(G(z)): 0.512\n",
      "2019-04-09 20:44:31,703 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.083657\n",
      "Reconstruction: 0.051538, Regularization: 0.000088, Discriminator: 0.021555; Generator: 0.010476,\n",
      "D(x): 0.516, D(G(z)): 0.511\n",
      "2019-04-09 20:44:31,770 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 0.083990\n",
      "Reconstruction: 0.051838, Regularization: 0.000089, Discriminator: 0.021586; Generator: 0.010477,\n",
      "D(x): 0.515, D(G(z)): 0.511\n",
      "2019-04-09 20:44:31,838 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.089660\n",
      "Reconstruction: 0.057101, Regularization: 0.000101, Discriminator: 0.021961; Generator: 0.010497,\n",
      "D(x): 0.502, D(G(z)): 0.511\n",
      "2019-04-09 20:44:31,905 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 0.084121\n",
      "Reconstruction: 0.051876, Regularization: 0.000088, Discriminator: 0.021655; Generator: 0.010501,\n",
      "D(x): 0.512, D(G(z)): 0.511\n",
      "2019-04-09 20:44:31,972 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 0.081799\n",
      "Reconstruction: 0.049711, Regularization: 0.000082, Discriminator: 0.021494; Generator: 0.010512,\n",
      "D(x): 0.517, D(G(z)): 0.510\n",
      "2019-04-09 20:44:32,040 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 0.088334\n",
      "Reconstruction: 0.055989, Regularization: 0.000096, Discriminator: 0.021734; Generator: 0.010515,\n",
      "D(x): 0.509, D(G(z)): 0.510\n",
      "2019-04-09 20:44:32,108 root         INFO     ====> Epoch: 17 Average loss: 0.0847\n",
      "2019-04-09 20:44:32,133 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 0.081978\n",
      "Reconstruction: 0.049542, Regularization: 0.000081, Discriminator: 0.021836; Generator: 0.010518,\n",
      "D(x): 0.505, D(G(z)): 0.510\n",
      "2019-04-09 20:44:32,201 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.096843\n",
      "Reconstruction: 0.064581, Regularization: 0.000117, Discriminator: 0.021621; Generator: 0.010523,\n",
      "D(x): 0.513, D(G(z)): 0.510\n",
      "2019-04-09 20:44:32,269 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 0.088635\n",
      "Reconstruction: 0.056181, Regularization: 0.000096, Discriminator: 0.021823; Generator: 0.010535,\n",
      "D(x): 0.505, D(G(z)): 0.510\n",
      "2019-04-09 20:44:32,337 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.086590\n",
      "Reconstruction: 0.054213, Regularization: 0.000092, Discriminator: 0.021744; Generator: 0.010541,\n",
      "D(x): 0.508, D(G(z)): 0.509\n",
      "2019-04-09 20:44:32,404 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 0.088364\n",
      "Reconstruction: 0.055899, Regularization: 0.000098, Discriminator: 0.021823; Generator: 0.010544,\n",
      "D(x): 0.505, D(G(z)): 0.509\n",
      "2019-04-09 20:44:32,472 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.091348\n",
      "Reconstruction: 0.059100, Regularization: 0.000107, Discriminator: 0.021591; Generator: 0.010550,\n",
      "D(x): 0.513, D(G(z)): 0.509\n",
      "2019-04-09 20:44:32,539 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 0.074225\n",
      "Reconstruction: 0.041756, Regularization: 0.000066, Discriminator: 0.021848; Generator: 0.010554,\n",
      "D(x): 0.504, D(G(z)): 0.509\n",
      "2019-04-09 20:44:32,607 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 0.078550\n",
      "Reconstruction: 0.046346, Regularization: 0.000078, Discriminator: 0.021568; Generator: 0.010558,\n",
      "D(x): 0.513, D(G(z)): 0.509\n",
      "2019-04-09 20:44:32,675 root         INFO     ====> Epoch: 18 Average loss: 0.0848\n",
      "2019-04-09 20:44:32,699 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 0.083825\n",
      "Reconstruction: 0.051361, Regularization: 0.000091, Discriminator: 0.021814; Generator: 0.010559,\n",
      "D(x): 0.505, D(G(z)): 0.509\n",
      "2019-04-09 20:44:32,766 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 0.079961\n",
      "Reconstruction: 0.047566, Regularization: 0.000081, Discriminator: 0.021749; Generator: 0.010565,\n",
      "D(x): 0.507, D(G(z)): 0.509\n",
      "2019-04-09 20:44:32,833 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 0.085083\n",
      "Reconstruction: 0.052917, Regularization: 0.000095, Discriminator: 0.021503; Generator: 0.010568,\n",
      "D(x): 0.515, D(G(z)): 0.508\n",
      "2019-04-09 20:44:32,899 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 0.080359\n",
      "Reconstruction: 0.048081, Regularization: 0.000083, Discriminator: 0.021618; Generator: 0.010577,\n",
      "D(x): 0.510, D(G(z)): 0.508\n",
      "2019-04-09 20:44:32,964 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 0.073275\n",
      "Reconstruction: 0.040936, Regularization: 0.000066, Discriminator: 0.021688; Generator: 0.010584,\n",
      "D(x): 0.508, D(G(z)): 0.508\n",
      "2019-04-09 20:44:33,030 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 0.085384\n",
      "Reconstruction: 0.053120, Regularization: 0.000093, Discriminator: 0.021584; Generator: 0.010586,\n",
      "D(x): 0.511, D(G(z)): 0.508\n",
      "2019-04-09 20:44:33,096 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 0.097880\n",
      "Reconstruction: 0.065335, Regularization: 0.000122, Discriminator: 0.021830; Generator: 0.010593,\n",
      "D(x): 0.503, D(G(z)): 0.508\n",
      "2019-04-09 20:44:33,162 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.093702\n",
      "Reconstruction: 0.061531, Regularization: 0.000111, Discriminator: 0.021463; Generator: 0.010596,\n",
      "D(x): 0.515, D(G(z)): 0.508\n",
      "2019-04-09 20:44:33,230 root         INFO     ====> Epoch: 19 Average loss: 0.0849\n",
      "2019-04-09 20:44:33,254 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 0.089499\n",
      "Reconstruction: 0.056854, Regularization: 0.000103, Discriminator: 0.021941; Generator: 0.010601,\n",
      "D(x): 0.499, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,318 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 0.090881\n",
      "Reconstruction: 0.058494, Regularization: 0.000106, Discriminator: 0.021679; Generator: 0.010600,\n",
      "D(x): 0.508, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,384 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 0.081347\n",
      "Reconstruction: 0.049173, Regularization: 0.000082, Discriminator: 0.021487; Generator: 0.010605,\n",
      "D(x): 0.514, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,450 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 0.094342\n",
      "Reconstruction: 0.061802, Regularization: 0.000112, Discriminator: 0.021811; Generator: 0.010617,\n",
      "D(x): 0.503, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,516 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 0.093774\n",
      "Reconstruction: 0.061428, Regularization: 0.000112, Discriminator: 0.021615; Generator: 0.010618,\n",
      "D(x): 0.509, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,582 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 0.093324\n",
      "Reconstruction: 0.061101, Regularization: 0.000113, Discriminator: 0.021487; Generator: 0.010624,\n",
      "D(x): 0.513, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,648 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 0.091283\n",
      "Reconstruction: 0.058724, Regularization: 0.000106, Discriminator: 0.021827; Generator: 0.010626,\n",
      "D(x): 0.502, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,714 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 0.077966\n",
      "Reconstruction: 0.045583, Regularization: 0.000074, Discriminator: 0.021681; Generator: 0.010629,\n",
      "D(x): 0.507, D(G(z)): 0.507\n",
      "2019-04-09 20:44:33,781 root         INFO     ====> Epoch: 20 Average loss: 0.0849\n",
      "2019-04-09 20:44:33,805 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.087743\n",
      "Reconstruction: 0.055340, Regularization: 0.000096, Discriminator: 0.021672; Generator: 0.010635,\n",
      "D(x): 0.507, D(G(z)): 0.506\n",
      "2019-04-09 20:44:33,871 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 0.071542\n",
      "Reconstruction: 0.039202, Regularization: 0.000058, Discriminator: 0.021646; Generator: 0.010636,\n",
      "D(x): 0.507, D(G(z)): 0.506\n",
      "2019-04-09 20:44:33,936 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 0.089217\n",
      "Reconstruction: 0.057042, Regularization: 0.000100, Discriminator: 0.021436; Generator: 0.010639,\n",
      "D(x): 0.514, D(G(z)): 0.506\n",
      "2019-04-09 20:44:34,002 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 0.079035\n",
      "Reconstruction: 0.046591, Regularization: 0.000075, Discriminator: 0.021723; Generator: 0.010646,\n",
      "D(x): 0.505, D(G(z)): 0.506\n",
      "2019-04-09 20:44:34,066 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.085205\n",
      "Reconstruction: 0.052964, Regularization: 0.000090, Discriminator: 0.021510; Generator: 0.010641,\n",
      "D(x): 0.512, D(G(z)): 0.506\n",
      "2019-04-09 20:44:34,132 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 0.081236\n",
      "Reconstruction: 0.048878, Regularization: 0.000079, Discriminator: 0.021632; Generator: 0.010647,\n",
      "D(x): 0.508, D(G(z)): 0.506\n",
      "2019-04-09 20:44:34,197 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 0.089798\n",
      "Reconstruction: 0.057229, Regularization: 0.000099, Discriminator: 0.021816; Generator: 0.010654,\n",
      "D(x): 0.502, D(G(z)): 0.506\n",
      "2019-04-09 20:44:34,260 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.082014\n",
      "Reconstruction: 0.049472, Regularization: 0.000081, Discriminator: 0.021808; Generator: 0.010653,\n",
      "D(x): 0.502, D(G(z)): 0.506\n",
      "2019-04-09 20:44:34,327 root         INFO     ====> Epoch: 21 Average loss: 0.0849\n",
      "2019-04-09 20:44:34,351 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 0.089645\n",
      "Reconstruction: 0.057140, Regularization: 0.000098, Discriminator: 0.021742; Generator: 0.010664,\n",
      "D(x): 0.504, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,418 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 0.087188\n",
      "Reconstruction: 0.054938, Regularization: 0.000092, Discriminator: 0.021489; Generator: 0.010670,\n",
      "D(x): 0.512, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,484 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 0.087721\n",
      "Reconstruction: 0.055163, Regularization: 0.000092, Discriminator: 0.021803; Generator: 0.010663,\n",
      "D(x): 0.502, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,550 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 0.088696\n",
      "Reconstruction: 0.056379, Regularization: 0.000095, Discriminator: 0.021554; Generator: 0.010668,\n",
      "D(x): 0.510, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,616 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.076161\n",
      "Reconstruction: 0.043834, Regularization: 0.000066, Discriminator: 0.021587; Generator: 0.010674,\n",
      "D(x): 0.508, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,680 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 0.083493\n",
      "Reconstruction: 0.051276, Regularization: 0.000082, Discriminator: 0.021462; Generator: 0.010674,\n",
      "D(x): 0.512, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,742 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 0.094870\n",
      "Reconstruction: 0.062367, Regularization: 0.000104, Discriminator: 0.021713; Generator: 0.010686,\n",
      "D(x): 0.504, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,805 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 0.093025\n",
      "Reconstruction: 0.060383, Regularization: 0.000099, Discriminator: 0.021856; Generator: 0.010687,\n",
      "D(x): 0.499, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,872 root         INFO     ====> Epoch: 22 Average loss: 0.0849\n",
      "2019-04-09 20:44:34,897 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 0.080576\n",
      "Reconstruction: 0.048252, Regularization: 0.000071, Discriminator: 0.021567; Generator: 0.010685,\n",
      "D(x): 0.508, D(G(z)): 0.505\n",
      "2019-04-09 20:44:34,963 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 0.076241\n",
      "Reconstruction: 0.043818, Regularization: 0.000063, Discriminator: 0.021671; Generator: 0.010689,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-09 20:44:35,029 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 0.095493\n",
      "Reconstruction: 0.062932, Regularization: 0.000103, Discriminator: 0.021760; Generator: 0.010698,\n",
      "D(x): 0.502, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,095 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 0.075033\n",
      "Reconstruction: 0.042704, Regularization: 0.000059, Discriminator: 0.021577; Generator: 0.010694,\n",
      "D(x): 0.508, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,161 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 0.088039\n",
      "Reconstruction: 0.055591, Regularization: 0.000085, Discriminator: 0.021665; Generator: 0.010698,\n",
      "D(x): 0.505, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,227 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 0.085437\n",
      "Reconstruction: 0.053112, Regularization: 0.000078, Discriminator: 0.021545; Generator: 0.010702,\n",
      "D(x): 0.509, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,293 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 0.092201\n",
      "Reconstruction: 0.059868, Regularization: 0.000090, Discriminator: 0.021541; Generator: 0.010702,\n",
      "D(x): 0.509, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,359 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 0.088205\n",
      "Reconstruction: 0.055588, Regularization: 0.000083, Discriminator: 0.021827; Generator: 0.010706,\n",
      "D(x): 0.499, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,427 root         INFO     ====> Epoch: 23 Average loss: 0.0850\n",
      "2019-04-09 20:44:35,451 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.082664\n",
      "Reconstruction: 0.050397, Regularization: 0.000075, Discriminator: 0.021487; Generator: 0.010705,\n",
      "D(x): 0.510, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,517 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 0.076918\n",
      "Reconstruction: 0.044360, Regularization: 0.000064, Discriminator: 0.021788; Generator: 0.010707,\n",
      "D(x): 0.500, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,584 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 0.102761\n",
      "Reconstruction: 0.070107, Regularization: 0.000120, Discriminator: 0.021821; Generator: 0.010712,\n",
      "D(x): 0.500, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,650 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 0.095542\n",
      "Reconstruction: 0.063206, Regularization: 0.000105, Discriminator: 0.021523; Generator: 0.010708,\n",
      "D(x): 0.509, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,716 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 0.087092\n",
      "Reconstruction: 0.054553, Regularization: 0.000086, Discriminator: 0.021737; Generator: 0.010716,\n",
      "D(x): 0.502, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,783 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 0.078982\n",
      "Reconstruction: 0.046548, Regularization: 0.000069, Discriminator: 0.021648; Generator: 0.010718,\n",
      "D(x): 0.505, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,848 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 0.080518\n",
      "Reconstruction: 0.048065, Regularization: 0.000071, Discriminator: 0.021661; Generator: 0.010720,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-09 20:44:35,913 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 0.082593\n",
      "Reconstruction: 0.050119, Regularization: 0.000075, Discriminator: 0.021675; Generator: 0.010725,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-09 20:44:35,980 root         INFO     ====> Epoch: 24 Average loss: 0.0850\n",
      "2019-04-09 20:44:36,004 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 0.088048\n",
      "Reconstruction: 0.055703, Regularization: 0.000087, Discriminator: 0.021533; Generator: 0.010725,\n",
      "D(x): 0.508, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,071 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 0.081564\n",
      "Reconstruction: 0.049009, Regularization: 0.000072, Discriminator: 0.021756; Generator: 0.010727,\n",
      "D(x): 0.501, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,137 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 0.081150\n",
      "Reconstruction: 0.048780, Regularization: 0.000071, Discriminator: 0.021575; Generator: 0.010724,\n",
      "D(x): 0.507, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,204 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 0.091249\n",
      "Reconstruction: 0.058693, Regularization: 0.000094, Discriminator: 0.021734; Generator: 0.010728,\n",
      "D(x): 0.502, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,270 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 0.088705\n",
      "Reconstruction: 0.056258, Regularization: 0.000086, Discriminator: 0.021628; Generator: 0.010733,\n",
      "D(x): 0.505, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,336 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 0.085529\n",
      "Reconstruction: 0.052977, Regularization: 0.000079, Discriminator: 0.021741; Generator: 0.010732,\n",
      "D(x): 0.501, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,402 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.072055\n",
      "Reconstruction: 0.039762, Regularization: 0.000050, Discriminator: 0.021511; Generator: 0.010732,\n",
      "D(x): 0.508, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,467 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 0.078220\n",
      "Reconstruction: 0.045862, Regularization: 0.000062, Discriminator: 0.021558; Generator: 0.010737,\n",
      "D(x): 0.507, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,533 root         INFO     ====> Epoch: 25 Average loss: 0.0850\n",
      "2019-04-09 20:44:36,557 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 0.089467\n",
      "Reconstruction: 0.056854, Regularization: 0.000086, Discriminator: 0.021789; Generator: 0.010739,\n",
      "D(x): 0.500, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,625 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 0.076597\n",
      "Reconstruction: 0.044201, Regularization: 0.000061, Discriminator: 0.021593; Generator: 0.010742,\n",
      "D(x): 0.506, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,692 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 0.087765\n",
      "Reconstruction: 0.055257, Regularization: 0.000084, Discriminator: 0.021681; Generator: 0.010743,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,759 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 0.093981\n",
      "Reconstruction: 0.061363, Regularization: 0.000096, Discriminator: 0.021775; Generator: 0.010747,\n",
      "D(x): 0.500, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,826 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.075146\n",
      "Reconstruction: 0.042566, Regularization: 0.000057, Discriminator: 0.021788; Generator: 0.010735,\n",
      "D(x): 0.499, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,893 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 0.089873\n",
      "Reconstruction: 0.057123, Regularization: 0.000085, Discriminator: 0.021926; Generator: 0.010740,\n",
      "D(x): 0.495, D(G(z)): 0.503\n",
      "2019-04-09 20:44:36,960 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 0.085150\n",
      "Reconstruction: 0.052701, Regularization: 0.000078, Discriminator: 0.021628; Generator: 0.010743,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-09 20:44:37,028 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 0.075688\n",
      "Reconstruction: 0.043201, Regularization: 0.000060, Discriminator: 0.021683; Generator: 0.010744,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-09 20:44:37,098 root         INFO     ====> Epoch: 26 Average loss: 0.0850\n",
      "2019-04-09 20:44:37,122 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 0.083360\n",
      "Reconstruction: 0.050890, Regularization: 0.000077, Discriminator: 0.021646; Generator: 0.010747,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-09 20:44:37,190 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.076182\n",
      "Reconstruction: 0.043663, Regularization: 0.000061, Discriminator: 0.021695; Generator: 0.010762,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,257 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 0.094527\n",
      "Reconstruction: 0.061810, Regularization: 0.000098, Discriminator: 0.021861; Generator: 0.010758,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,324 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.075028\n",
      "Reconstruction: 0.042498, Regularization: 0.000058, Discriminator: 0.021714; Generator: 0.010758,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,392 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 0.082405\n",
      "Reconstruction: 0.050095, Regularization: 0.000074, Discriminator: 0.021477; Generator: 0.010759,\n",
      "D(x): 0.509, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,457 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.078118\n",
      "Reconstruction: 0.045472, Regularization: 0.000065, Discriminator: 0.021816; Generator: 0.010765,\n",
      "D(x): 0.498, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,524 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.083613\n",
      "Reconstruction: 0.051091, Regularization: 0.000078, Discriminator: 0.021680; Generator: 0.010764,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,590 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 0.094066\n",
      "Reconstruction: 0.061638, Regularization: 0.000100, Discriminator: 0.021572; Generator: 0.010757,\n",
      "D(x): 0.506, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,658 root         INFO     ====> Epoch: 27 Average loss: 0.0850\n",
      "2019-04-09 20:44:37,682 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.082951\n",
      "Reconstruction: 0.050335, Regularization: 0.000075, Discriminator: 0.021782; Generator: 0.010758,\n",
      "D(x): 0.499, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,749 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.088770\n",
      "Reconstruction: 0.056064, Regularization: 0.000091, Discriminator: 0.021859; Generator: 0.010757,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,817 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 0.080446\n",
      "Reconstruction: 0.047927, Regularization: 0.000074, Discriminator: 0.021687; Generator: 0.010758,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,886 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.072479\n",
      "Reconstruction: 0.039919, Regularization: 0.000055, Discriminator: 0.021748; Generator: 0.010757,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 20:44:37,956 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.090068\n",
      "Reconstruction: 0.057366, Regularization: 0.000092, Discriminator: 0.021853; Generator: 0.010757,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,024 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.088279\n",
      "Reconstruction: 0.055684, Regularization: 0.000087, Discriminator: 0.021749; Generator: 0.010759,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,094 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.072977\n",
      "Reconstruction: 0.040368, Regularization: 0.000055, Discriminator: 0.021795; Generator: 0.010759,\n",
      "D(x): 0.498, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,163 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.092626\n",
      "Reconstruction: 0.060258, Regularization: 0.000097, Discriminator: 0.021511; Generator: 0.010761,\n",
      "D(x): 0.508, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,233 root         INFO     ====> Epoch: 28 Average loss: 0.0850\n",
      "2019-04-09 20:44:38,257 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 0.090939\n",
      "Reconstruction: 0.058433, Regularization: 0.000091, Discriminator: 0.021648; Generator: 0.010766,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,325 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 0.088645\n",
      "Reconstruction: 0.056119, Regularization: 0.000089, Discriminator: 0.021673; Generator: 0.010764,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,392 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 0.083245\n",
      "Reconstruction: 0.050796, Regularization: 0.000079, Discriminator: 0.021606; Generator: 0.010764,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,459 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 0.075001\n",
      "Reconstruction: 0.042558, Regularization: 0.000060, Discriminator: 0.021614; Generator: 0.010768,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,526 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.085939\n",
      "Reconstruction: 0.053249, Regularization: 0.000083, Discriminator: 0.021838; Generator: 0.010769,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,593 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 0.085457\n",
      "Reconstruction: 0.052858, Regularization: 0.000082, Discriminator: 0.021750; Generator: 0.010768,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,660 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 0.096107\n",
      "Reconstruction: 0.063626, Regularization: 0.000105, Discriminator: 0.021610; Generator: 0.010766,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,727 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.096086\n",
      "Reconstruction: 0.063567, Regularization: 0.000104, Discriminator: 0.021643; Generator: 0.010772,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,796 root         INFO     ====> Epoch: 29 Average loss: 0.0850\n",
      "2019-04-09 20:44:38,820 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.085444\n",
      "Reconstruction: 0.052969, Regularization: 0.000080, Discriminator: 0.021621; Generator: 0.010773,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,887 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.082730\n",
      "Reconstruction: 0.050215, Regularization: 0.000076, Discriminator: 0.021664; Generator: 0.010775,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 20:44:38,954 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.078044\n",
      "Reconstruction: 0.045472, Regularization: 0.000064, Discriminator: 0.021725; Generator: 0.010782,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,021 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.095493\n",
      "Reconstruction: 0.062942, Regularization: 0.000101, Discriminator: 0.021670; Generator: 0.010781,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,087 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.072612\n",
      "Reconstruction: 0.040055, Regularization: 0.000053, Discriminator: 0.021720; Generator: 0.010783,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,153 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.087372\n",
      "Reconstruction: 0.054791, Regularization: 0.000084, Discriminator: 0.021714; Generator: 0.010783,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,219 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.090142\n",
      "Reconstruction: 0.057640, Regularization: 0.000089, Discriminator: 0.021638; Generator: 0.010775,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,285 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 0.083845\n",
      "Reconstruction: 0.051308, Regularization: 0.000075, Discriminator: 0.021683; Generator: 0.010780,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,354 root         INFO     ====> Epoch: 30 Average loss: 0.0850\n",
      "2019-04-09 20:44:39,378 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.078607\n",
      "Reconstruction: 0.046171, Regularization: 0.000064, Discriminator: 0.021591; Generator: 0.010781,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,442 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.078166\n",
      "Reconstruction: 0.045789, Regularization: 0.000062, Discriminator: 0.021539; Generator: 0.010776,\n",
      "D(x): 0.506, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,508 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 0.092307\n",
      "Reconstruction: 0.059678, Regularization: 0.000091, Discriminator: 0.021762; Generator: 0.010776,\n",
      "D(x): 0.499, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,574 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.103323\n",
      "Reconstruction: 0.070705, Regularization: 0.000113, Discriminator: 0.021727; Generator: 0.010777,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,641 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.074243\n",
      "Reconstruction: 0.041824, Regularization: 0.000055, Discriminator: 0.021587; Generator: 0.010777,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,707 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.088031\n",
      "Reconstruction: 0.055580, Regularization: 0.000084, Discriminator: 0.021588; Generator: 0.010779,\n",
      "D(x): 0.505, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,773 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 0.074768\n",
      "Reconstruction: 0.042107, Regularization: 0.000056, Discriminator: 0.021827; Generator: 0.010777,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,839 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 0.084670\n",
      "Reconstruction: 0.052042, Regularization: 0.000077, Discriminator: 0.021770; Generator: 0.010781,\n",
      "D(x): 0.499, D(G(z)): 0.502\n",
      "2019-04-09 20:44:39,907 root         INFO     ====> Epoch: 31 Average loss: 0.0850\n",
      "2019-04-09 20:44:39,931 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.079269\n",
      "Reconstruction: 0.046673, Regularization: 0.000066, Discriminator: 0.021746; Generator: 0.010784,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:39,999 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.083252\n",
      "Reconstruction: 0.050633, Regularization: 0.000075, Discriminator: 0.021759; Generator: 0.010785,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,066 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.086036\n",
      "Reconstruction: 0.053535, Regularization: 0.000081, Discriminator: 0.021625; Generator: 0.010795,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,133 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.086214\n",
      "Reconstruction: 0.053683, Regularization: 0.000082, Discriminator: 0.021661; Generator: 0.010789,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,200 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.083363\n",
      "Reconstruction: 0.050880, Regularization: 0.000076, Discriminator: 0.021624; Generator: 0.010783,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-09 20:44:40,267 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 0.083105\n",
      "Reconstruction: 0.050632, Regularization: 0.000075, Discriminator: 0.021603; Generator: 0.010795,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,335 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.074416\n",
      "Reconstruction: 0.042074, Regularization: 0.000057, Discriminator: 0.021488; Generator: 0.010797,\n",
      "D(x): 0.507, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,403 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.089959\n",
      "Reconstruction: 0.057355, Regularization: 0.000089, Discriminator: 0.021721; Generator: 0.010794,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,471 root         INFO     ====> Epoch: 32 Average loss: 0.0850\n",
      "2019-04-09 20:44:40,495 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.091977\n",
      "Reconstruction: 0.059402, Regularization: 0.000091, Discriminator: 0.021692; Generator: 0.010793,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,563 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.087832\n",
      "Reconstruction: 0.055292, Regularization: 0.000082, Discriminator: 0.021667; Generator: 0.010790,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,630 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.083306\n",
      "Reconstruction: 0.050757, Regularization: 0.000072, Discriminator: 0.021685; Generator: 0.010792,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,698 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.075443\n",
      "Reconstruction: 0.042842, Regularization: 0.000058, Discriminator: 0.021751; Generator: 0.010792,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,765 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 0.084883\n",
      "Reconstruction: 0.052469, Regularization: 0.000077, Discriminator: 0.021554; Generator: 0.010783,\n",
      "D(x): 0.505, D(G(z)): 0.502\n",
      "2019-04-09 20:44:40,832 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.077169\n",
      "Reconstruction: 0.044700, Regularization: 0.000063, Discriminator: 0.021615; Generator: 0.010791,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,900 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 0.080678\n",
      "Reconstruction: 0.048200, Regularization: 0.000071, Discriminator: 0.021611; Generator: 0.010796,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:40,967 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.089491\n",
      "Reconstruction: 0.056784, Regularization: 0.000089, Discriminator: 0.021819; Generator: 0.010799,\n",
      "D(x): 0.496, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,034 root         INFO     ====> Epoch: 33 Average loss: 0.0850\n",
      "2019-04-09 20:44:41,059 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.079958\n",
      "Reconstruction: 0.047514, Regularization: 0.000068, Discriminator: 0.021582; Generator: 0.010794,\n",
      "D(x): 0.504, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,127 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.093208\n",
      "Reconstruction: 0.060577, Regularization: 0.000096, Discriminator: 0.021738; Generator: 0.010796,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,194 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.078486\n",
      "Reconstruction: 0.046028, Regularization: 0.000067, Discriminator: 0.021601; Generator: 0.010790,\n",
      "D(x): 0.504, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,261 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.080281\n",
      "Reconstruction: 0.047645, Regularization: 0.000068, Discriminator: 0.021772; Generator: 0.010796,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,329 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.084743\n",
      "Reconstruction: 0.052335, Regularization: 0.000080, Discriminator: 0.021532; Generator: 0.010796,\n",
      "D(x): 0.506, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,393 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.077630\n",
      "Reconstruction: 0.045098, Regularization: 0.000065, Discriminator: 0.021670; Generator: 0.010797,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,457 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.085131\n",
      "Reconstruction: 0.052571, Regularization: 0.000080, Discriminator: 0.021682; Generator: 0.010797,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,520 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 0.073488\n",
      "Reconstruction: 0.041062, Regularization: 0.000055, Discriminator: 0.021574; Generator: 0.010797,\n",
      "D(x): 0.504, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,586 root         INFO     ====> Epoch: 34 Average loss: 0.0851\n",
      "2019-04-09 20:44:41,610 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.084463\n",
      "Reconstruction: 0.051859, Regularization: 0.000078, Discriminator: 0.021730; Generator: 0.010796,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,677 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.093815\n",
      "Reconstruction: 0.061261, Regularization: 0.000098, Discriminator: 0.021658; Generator: 0.010799,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,744 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.083497\n",
      "Reconstruction: 0.051097, Regularization: 0.000076, Discriminator: 0.021522; Generator: 0.010801,\n",
      "D(x): 0.506, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,811 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.092841\n",
      "Reconstruction: 0.060202, Regularization: 0.000097, Discriminator: 0.021738; Generator: 0.010803,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,878 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.091658\n",
      "Reconstruction: 0.059029, Regularization: 0.000095, Discriminator: 0.021730; Generator: 0.010804,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:41,944 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.080402\n",
      "Reconstruction: 0.047789, Regularization: 0.000072, Discriminator: 0.021739; Generator: 0.010802,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,011 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.072960\n",
      "Reconstruction: 0.040415, Regularization: 0.000057, Discriminator: 0.021685; Generator: 0.010804,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,078 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.085715\n",
      "Reconstruction: 0.053230, Regularization: 0.000088, Discriminator: 0.021591; Generator: 0.010805,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,146 root         INFO     ====> Epoch: 35 Average loss: 0.0851\n",
      "2019-04-09 20:44:42,170 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 0.087398\n",
      "Reconstruction: 0.054904, Regularization: 0.000091, Discriminator: 0.021603; Generator: 0.010800,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,234 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.089576\n",
      "Reconstruction: 0.057026, Regularization: 0.000093, Discriminator: 0.021651; Generator: 0.010805,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,298 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.082868\n",
      "Reconstruction: 0.050270, Regularization: 0.000078, Discriminator: 0.021722; Generator: 0.010798,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,362 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.088380\n",
      "Reconstruction: 0.056088, Regularization: 0.000091, Discriminator: 0.021398; Generator: 0.010803,\n",
      "D(x): 0.510, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,425 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.083707\n",
      "Reconstruction: 0.051311, Regularization: 0.000078, Discriminator: 0.021516; Generator: 0.010802,\n",
      "D(x): 0.506, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,489 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.079141\n",
      "Reconstruction: 0.046610, Regularization: 0.000069, Discriminator: 0.021658; Generator: 0.010805,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,555 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 0.083702\n",
      "Reconstruction: 0.051033, Regularization: 0.000077, Discriminator: 0.021786; Generator: 0.010806,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,621 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.090585\n",
      "Reconstruction: 0.058013, Regularization: 0.000092, Discriminator: 0.021676; Generator: 0.010804,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,690 root         INFO     ====> Epoch: 36 Average loss: 0.0851\n",
      "2019-04-09 20:44:42,714 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.078976\n",
      "Reconstruction: 0.046457, Regularization: 0.000067, Discriminator: 0.021648; Generator: 0.010804,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,782 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.101304\n",
      "Reconstruction: 0.068614, Regularization: 0.000116, Discriminator: 0.021770; Generator: 0.010804,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,849 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.078165\n",
      "Reconstruction: 0.045798, Regularization: 0.000068, Discriminator: 0.021500; Generator: 0.010798,\n",
      "D(x): 0.506, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,916 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 0.091352\n",
      "Reconstruction: 0.058901, Regularization: 0.000097, Discriminator: 0.021552; Generator: 0.010802,\n",
      "D(x): 0.505, D(G(z)): 0.501\n",
      "2019-04-09 20:44:42,984 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.080902\n",
      "Reconstruction: 0.048217, Regularization: 0.000074, Discriminator: 0.021802; Generator: 0.010809,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,051 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.094846\n",
      "Reconstruction: 0.062171, Regularization: 0.000104, Discriminator: 0.021766; Generator: 0.010805,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,119 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.080374\n",
      "Reconstruction: 0.047842, Regularization: 0.000073, Discriminator: 0.021659; Generator: 0.010800,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,187 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.082691\n",
      "Reconstruction: 0.050290, Regularization: 0.000078, Discriminator: 0.021517; Generator: 0.010806,\n",
      "D(x): 0.506, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,255 root         INFO     ====> Epoch: 37 Average loss: 0.0851\n",
      "2019-04-09 20:44:43,279 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.092829\n",
      "Reconstruction: 0.060273, Regularization: 0.000100, Discriminator: 0.021646; Generator: 0.010810,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,348 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.081838\n",
      "Reconstruction: 0.049349, Regularization: 0.000077, Discriminator: 0.021606; Generator: 0.010806,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,415 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.074598\n",
      "Reconstruction: 0.042070, Regularization: 0.000061, Discriminator: 0.021661; Generator: 0.010806,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,483 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 0.093069\n",
      "Reconstruction: 0.060553, Regularization: 0.000102, Discriminator: 0.021610; Generator: 0.010803,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,550 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.082683\n",
      "Reconstruction: 0.050076, Regularization: 0.000078, Discriminator: 0.021723; Generator: 0.010805,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,618 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.088520\n",
      "Reconstruction: 0.055925, Regularization: 0.000092, Discriminator: 0.021696; Generator: 0.010807,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,684 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.086186\n",
      "Reconstruction: 0.053505, Regularization: 0.000087, Discriminator: 0.021790; Generator: 0.010805,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,752 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.083131\n",
      "Reconstruction: 0.050735, Regularization: 0.000080, Discriminator: 0.021508; Generator: 0.010808,\n",
      "D(x): 0.506, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,820 root         INFO     ====> Epoch: 38 Average loss: 0.0851\n",
      "2019-04-09 20:44:43,845 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 0.084875\n",
      "Reconstruction: 0.052198, Regularization: 0.000083, Discriminator: 0.021780; Generator: 0.010813,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,913 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.078089\n",
      "Reconstruction: 0.045559, Regularization: 0.000068, Discriminator: 0.021653; Generator: 0.010810,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:43,980 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.076929\n",
      "Reconstruction: 0.044351, Regularization: 0.000066, Discriminator: 0.021707; Generator: 0.010805,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 20:44:44,048 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.077774\n",
      "Reconstruction: 0.045255, Regularization: 0.000067, Discriminator: 0.021650; Generator: 0.010803,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:44,116 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.081327\n",
      "Reconstruction: 0.048809, Regularization: 0.000073, Discriminator: 0.021636; Generator: 0.010808,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:44,183 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.094427\n",
      "Reconstruction: 0.061910, Regularization: 0.000104, Discriminator: 0.021603; Generator: 0.010809,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:44,251 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.074415\n",
      "Reconstruction: 0.041844, Regularization: 0.000060, Discriminator: 0.021694; Generator: 0.010817,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,316 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.081287\n",
      "Reconstruction: 0.048813, Regularization: 0.000075, Discriminator: 0.021579; Generator: 0.010819,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,380 root         INFO     ====> Epoch: 39 Average loss: 0.0851\n",
      "2019-04-09 20:44:44,405 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.098537\n",
      "Reconstruction: 0.065987, Regularization: 0.000112, Discriminator: 0.021622; Generator: 0.010817,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,469 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.086183\n",
      "Reconstruction: 0.053663, Regularization: 0.000084, Discriminator: 0.021618; Generator: 0.010819,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,533 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.096879\n",
      "Reconstruction: 0.064397, Regularization: 0.000106, Discriminator: 0.021554; Generator: 0.010821,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,596 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.094810\n",
      "Reconstruction: 0.062270, Regularization: 0.000102, Discriminator: 0.021617; Generator: 0.010821,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,660 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.082545\n",
      "Reconstruction: 0.050005, Regularization: 0.000075, Discriminator: 0.021648; Generator: 0.010817,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,724 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 0.077122\n",
      "Reconstruction: 0.044618, Regularization: 0.000064, Discriminator: 0.021620; Generator: 0.010819,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,787 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.090303\n",
      "Reconstruction: 0.057803, Regularization: 0.000092, Discriminator: 0.021589; Generator: 0.010818,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,851 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.094798\n",
      "Reconstruction: 0.062200, Regularization: 0.000100, Discriminator: 0.021680; Generator: 0.010818,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:44,917 root         INFO     ====> Epoch: 40 Average loss: 0.0851\n",
      "2019-04-09 20:44:44,941 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 0.077658\n",
      "Reconstruction: 0.045178, Regularization: 0.000064, Discriminator: 0.021604; Generator: 0.010812,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,006 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.089071\n",
      "Reconstruction: 0.056471, Regularization: 0.000090, Discriminator: 0.021695; Generator: 0.010814,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,074 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 0.078564\n",
      "Reconstruction: 0.046122, Regularization: 0.000069, Discriminator: 0.021568; Generator: 0.010805,\n",
      "D(x): 0.504, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,143 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.091347\n",
      "Reconstruction: 0.058782, Regularization: 0.000098, Discriminator: 0.021652; Generator: 0.010815,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:45,211 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.091635\n",
      "Reconstruction: 0.059101, Regularization: 0.000101, Discriminator: 0.021610; Generator: 0.010823,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:45,279 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 0.087173\n",
      "Reconstruction: 0.054601, Regularization: 0.000090, Discriminator: 0.021665; Generator: 0.010818,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:45,347 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.088568\n",
      "Reconstruction: 0.055990, Regularization: 0.000093, Discriminator: 0.021672; Generator: 0.010812,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,416 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.080656\n",
      "Reconstruction: 0.048151, Regularization: 0.000076, Discriminator: 0.021617; Generator: 0.010811,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,485 root         INFO     ====> Epoch: 41 Average loss: 0.0851\n",
      "2019-04-09 20:44:45,509 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.075535\n",
      "Reconstruction: 0.043028, Regularization: 0.000066, Discriminator: 0.021625; Generator: 0.010817,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:45,575 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.079396\n",
      "Reconstruction: 0.046848, Regularization: 0.000075, Discriminator: 0.021655; Generator: 0.010817,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:45,640 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.078081\n",
      "Reconstruction: 0.045483, Regularization: 0.000073, Discriminator: 0.021714; Generator: 0.010811,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,704 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 0.101341\n",
      "Reconstruction: 0.068775, Regularization: 0.000127, Discriminator: 0.021630; Generator: 0.010808,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,768 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.083420\n",
      "Reconstruction: 0.050847, Regularization: 0.000085, Discriminator: 0.021677; Generator: 0.010811,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,831 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.092946\n",
      "Reconstruction: 0.060362, Regularization: 0.000107, Discriminator: 0.021670; Generator: 0.010807,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,895 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.083438\n",
      "Reconstruction: 0.050929, Regularization: 0.000086, Discriminator: 0.021613; Generator: 0.010810,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 20:44:45,958 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.074080\n",
      "Reconstruction: 0.041542, Regularization: 0.000064, Discriminator: 0.021658; Generator: 0.010817,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,025 root         INFO     ====> Epoch: 42 Average loss: 0.0851\n",
      "2019-04-09 20:44:46,049 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.079072\n",
      "Reconstruction: 0.046431, Regularization: 0.000075, Discriminator: 0.021746; Generator: 0.010821,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,115 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.094308\n",
      "Reconstruction: 0.061739, Regularization: 0.000107, Discriminator: 0.021644; Generator: 0.010817,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,179 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.071428\n",
      "Reconstruction: 0.038996, Regularization: 0.000057, Discriminator: 0.021559; Generator: 0.010817,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,243 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.082133\n",
      "Reconstruction: 0.049532, Regularization: 0.000080, Discriminator: 0.021704; Generator: 0.010818,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,307 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.076085\n",
      "Reconstruction: 0.043551, Regularization: 0.000065, Discriminator: 0.021654; Generator: 0.010816,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,371 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.078315\n",
      "Reconstruction: 0.045784, Regularization: 0.000071, Discriminator: 0.021642; Generator: 0.010818,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,435 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.084569\n",
      "Reconstruction: 0.052125, Regularization: 0.000084, Discriminator: 0.021545; Generator: 0.010816,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,498 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.097807\n",
      "Reconstruction: 0.065191, Regularization: 0.000113, Discriminator: 0.021680; Generator: 0.010823,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,564 root         INFO     ====> Epoch: 43 Average loss: 0.0851\n",
      "2019-04-09 20:44:46,588 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.092365\n",
      "Reconstruction: 0.059743, Regularization: 0.000100, Discriminator: 0.021701; Generator: 0.010821,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,655 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.080367\n",
      "Reconstruction: 0.047776, Regularization: 0.000076, Discriminator: 0.021688; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,720 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.078805\n",
      "Reconstruction: 0.046172, Regularization: 0.000072, Discriminator: 0.021738; Generator: 0.010822,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,786 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.075200\n",
      "Reconstruction: 0.042757, Regularization: 0.000064, Discriminator: 0.021562; Generator: 0.010817,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,852 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.088285\n",
      "Reconstruction: 0.055844, Regularization: 0.000091, Discriminator: 0.021532; Generator: 0.010818,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,918 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.079931\n",
      "Reconstruction: 0.047290, Regularization: 0.000070, Discriminator: 0.021751; Generator: 0.010820,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:46,984 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.095198\n",
      "Reconstruction: 0.062618, Regularization: 0.000103, Discriminator: 0.021659; Generator: 0.010818,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,049 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.073552\n",
      "Reconstruction: 0.040944, Regularization: 0.000058, Discriminator: 0.021728; Generator: 0.010822,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,117 root         INFO     ====> Epoch: 44 Average loss: 0.0851\n",
      "2019-04-09 20:44:47,140 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.076510\n",
      "Reconstruction: 0.043952, Regularization: 0.000065, Discriminator: 0.021668; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,207 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 0.081709\n",
      "Reconstruction: 0.049254, Regularization: 0.000076, Discriminator: 0.021551; Generator: 0.010828,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,274 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.083096\n",
      "Reconstruction: 0.050468, Regularization: 0.000079, Discriminator: 0.021716; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,341 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.090917\n",
      "Reconstruction: 0.058347, Regularization: 0.000095, Discriminator: 0.021651; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,407 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.101323\n",
      "Reconstruction: 0.068630, Regularization: 0.000115, Discriminator: 0.021753; Generator: 0.010826,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,473 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.077909\n",
      "Reconstruction: 0.045320, Regularization: 0.000066, Discriminator: 0.021702; Generator: 0.010820,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,540 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.081915\n",
      "Reconstruction: 0.049305, Regularization: 0.000075, Discriminator: 0.021714; Generator: 0.010821,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,607 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.086369\n",
      "Reconstruction: 0.053809, Regularization: 0.000084, Discriminator: 0.021653; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,675 root         INFO     ====> Epoch: 45 Average loss: 0.0851\n",
      "2019-04-09 20:44:47,699 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.084480\n",
      "Reconstruction: 0.051900, Regularization: 0.000079, Discriminator: 0.021679; Generator: 0.010822,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,767 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.093146\n",
      "Reconstruction: 0.060520, Regularization: 0.000095, Discriminator: 0.021713; Generator: 0.010819,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,832 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.087605\n",
      "Reconstruction: 0.055085, Regularization: 0.000084, Discriminator: 0.021617; Generator: 0.010818,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,894 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.078416\n",
      "Reconstruction: 0.045812, Regularization: 0.000064, Discriminator: 0.021721; Generator: 0.010819,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:47,956 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.088121\n",
      "Reconstruction: 0.055557, Regularization: 0.000083, Discriminator: 0.021665; Generator: 0.010817,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,020 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.088947\n",
      "Reconstruction: 0.056469, Regularization: 0.000083, Discriminator: 0.021579; Generator: 0.010816,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,085 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.085386\n",
      "Reconstruction: 0.052873, Regularization: 0.000076, Discriminator: 0.021620; Generator: 0.010817,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,150 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.078527\n",
      "Reconstruction: 0.046047, Regularization: 0.000064, Discriminator: 0.021600; Generator: 0.010816,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,216 root         INFO     ====> Epoch: 46 Average loss: 0.0851\n",
      "2019-04-09 20:44:48,241 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.080582\n",
      "Reconstruction: 0.048055, Regularization: 0.000067, Discriminator: 0.021634; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,307 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.086784\n",
      "Reconstruction: 0.054197, Regularization: 0.000082, Discriminator: 0.021681; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,376 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.093296\n",
      "Reconstruction: 0.060640, Regularization: 0.000097, Discriminator: 0.021736; Generator: 0.010823,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,445 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.086715\n",
      "Reconstruction: 0.054156, Regularization: 0.000083, Discriminator: 0.021651; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,514 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.089929\n",
      "Reconstruction: 0.057406, Regularization: 0.000088, Discriminator: 0.021613; Generator: 0.010821,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,583 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.090733\n",
      "Reconstruction: 0.058138, Regularization: 0.000088, Discriminator: 0.021683; Generator: 0.010823,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,653 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.093549\n",
      "Reconstruction: 0.061037, Regularization: 0.000093, Discriminator: 0.021592; Generator: 0.010827,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,722 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.087699\n",
      "Reconstruction: 0.055153, Regularization: 0.000081, Discriminator: 0.021635; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,792 root         INFO     ====> Epoch: 47 Average loss: 0.0851\n",
      "2019-04-09 20:44:48,817 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.091553\n",
      "Reconstruction: 0.058807, Regularization: 0.000088, Discriminator: 0.021833; Generator: 0.010824,\n",
      "D(x): 0.495, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,884 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.093638\n",
      "Reconstruction: 0.061197, Regularization: 0.000096, Discriminator: 0.021515; Generator: 0.010830,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 20:44:48,949 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.098920\n",
      "Reconstruction: 0.066317, Regularization: 0.000105, Discriminator: 0.021668; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,015 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.102148\n",
      "Reconstruction: 0.069576, Regularization: 0.000111, Discriminator: 0.021635; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,081 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.081643\n",
      "Reconstruction: 0.049039, Regularization: 0.000070, Discriminator: 0.021708; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,146 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.079501\n",
      "Reconstruction: 0.046997, Regularization: 0.000066, Discriminator: 0.021615; Generator: 0.010822,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,211 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.105338\n",
      "Reconstruction: 0.072752, Regularization: 0.000119, Discriminator: 0.021642; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,278 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.077126\n",
      "Reconstruction: 0.044534, Regularization: 0.000061, Discriminator: 0.021705; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,345 root         INFO     ====> Epoch: 48 Average loss: 0.0851\n",
      "2019-04-09 20:44:49,370 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.086595\n",
      "Reconstruction: 0.054096, Regularization: 0.000083, Discriminator: 0.021591; Generator: 0.010826,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,437 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.081257\n",
      "Reconstruction: 0.048718, Regularization: 0.000072, Discriminator: 0.021638; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,503 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.087248\n",
      "Reconstruction: 0.054646, Regularization: 0.000084, Discriminator: 0.021687; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,570 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.082405\n",
      "Reconstruction: 0.049916, Regularization: 0.000074, Discriminator: 0.021591; Generator: 0.010825,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,637 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.087066\n",
      "Reconstruction: 0.054439, Regularization: 0.000082, Discriminator: 0.021717; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,703 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.082468\n",
      "Reconstruction: 0.049867, Regularization: 0.000071, Discriminator: 0.021702; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,769 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.087183\n",
      "Reconstruction: 0.054512, Regularization: 0.000083, Discriminator: 0.021766; Generator: 0.010821,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,835 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.097398\n",
      "Reconstruction: 0.064883, Regularization: 0.000104, Discriminator: 0.021589; Generator: 0.010823,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,904 root         INFO     ====> Epoch: 49 Average loss: 0.0851\n",
      "2019-04-09 20:44:49,928 root         INFO     Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 0.094375\n",
      "Reconstruction: 0.061781, Regularization: 0.000100, Discriminator: 0.021670; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:49,996 root         INFO     Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 0.087888\n",
      "Reconstruction: 0.055349, Regularization: 0.000086, Discriminator: 0.021628; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,063 root         INFO     Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 0.079974\n",
      "Reconstruction: 0.047445, Regularization: 0.000069, Discriminator: 0.021633; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,130 root         INFO     Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 0.086012\n",
      "Reconstruction: 0.053501, Regularization: 0.000081, Discriminator: 0.021597; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,197 root         INFO     Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 0.080609\n",
      "Reconstruction: 0.048068, Regularization: 0.000071, Discriminator: 0.021643; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,263 root         INFO     Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 0.082422\n",
      "Reconstruction: 0.049922, Regularization: 0.000075, Discriminator: 0.021597; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,329 root         INFO     Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 0.090275\n",
      "Reconstruction: 0.057602, Regularization: 0.000092, Discriminator: 0.021753; Generator: 0.010828,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,395 root         INFO     Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 0.089500\n",
      "Reconstruction: 0.056954, Regularization: 0.000090, Discriminator: 0.021630; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,462 root         INFO     ====> Epoch: 50 Average loss: 0.0851\n",
      "2019-04-09 20:44:50,486 root         INFO     Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 0.087531\n",
      "Reconstruction: 0.054898, Regularization: 0.000085, Discriminator: 0.021723; Generator: 0.010824,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,553 root         INFO     Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 0.079471\n",
      "Reconstruction: 0.046910, Regularization: 0.000069, Discriminator: 0.021668; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,619 root         INFO     Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 0.076209\n",
      "Reconstruction: 0.043738, Regularization: 0.000062, Discriminator: 0.021590; Generator: 0.010820,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,685 root         INFO     Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 0.094056\n",
      "Reconstruction: 0.061479, Regularization: 0.000100, Discriminator: 0.021663; Generator: 0.010815,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,748 root         INFO     Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 0.087902\n",
      "Reconstruction: 0.055291, Regularization: 0.000086, Discriminator: 0.021710; Generator: 0.010816,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,811 root         INFO     Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 0.087052\n",
      "Reconstruction: 0.054531, Regularization: 0.000086, Discriminator: 0.021613; Generator: 0.010822,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,874 root         INFO     Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 0.090125\n",
      "Reconstruction: 0.057635, Regularization: 0.000094, Discriminator: 0.021568; Generator: 0.010828,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:50,937 root         INFO     Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 0.088851\n",
      "Reconstruction: 0.056314, Regularization: 0.000089, Discriminator: 0.021619; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,002 root         INFO     ====> Epoch: 51 Average loss: 0.0851\n",
      "2019-04-09 20:44:51,026 root         INFO     Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 0.088832\n",
      "Reconstruction: 0.056250, Regularization: 0.000090, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,089 root         INFO     Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 0.079785\n",
      "Reconstruction: 0.047210, Regularization: 0.000070, Discriminator: 0.021676; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,153 root         INFO     Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 0.083941\n",
      "Reconstruction: 0.051349, Regularization: 0.000077, Discriminator: 0.021692; Generator: 0.010823,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,216 root         INFO     Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 0.088577\n",
      "Reconstruction: 0.056134, Regularization: 0.000088, Discriminator: 0.021535; Generator: 0.010820,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,279 root         INFO     Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 0.081220\n",
      "Reconstruction: 0.048719, Regularization: 0.000074, Discriminator: 0.021595; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,342 root         INFO     Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 0.075087\n",
      "Reconstruction: 0.042532, Regularization: 0.000061, Discriminator: 0.021661; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,405 root         INFO     Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 0.076552\n",
      "Reconstruction: 0.044044, Regularization: 0.000066, Discriminator: 0.021610; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,467 root         INFO     Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 0.084850\n",
      "Reconstruction: 0.052275, Regularization: 0.000084, Discriminator: 0.021657; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,532 root         INFO     ====> Epoch: 52 Average loss: 0.0850\n",
      "2019-04-09 20:44:51,556 root         INFO     Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 0.079624\n",
      "Reconstruction: 0.047111, Regularization: 0.000072, Discriminator: 0.021608; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,623 root         INFO     Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 0.084809\n",
      "Reconstruction: 0.052296, Regularization: 0.000081, Discriminator: 0.021603; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,689 root         INFO     Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 0.085149\n",
      "Reconstruction: 0.052745, Regularization: 0.000081, Discriminator: 0.021499; Generator: 0.010824,\n",
      "D(x): 0.506, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,755 root         INFO     Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 0.086245\n",
      "Reconstruction: 0.053687, Regularization: 0.000086, Discriminator: 0.021647; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,821 root         INFO     Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 0.089020\n",
      "Reconstruction: 0.056481, Regularization: 0.000090, Discriminator: 0.021625; Generator: 0.010824,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,887 root         INFO     Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 0.083813\n",
      "Reconstruction: 0.051207, Regularization: 0.000082, Discriminator: 0.021693; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:51,953 root         INFO     Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 0.096731\n",
      "Reconstruction: 0.064042, Regularization: 0.000111, Discriminator: 0.021748; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,019 root         INFO     Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 0.081592\n",
      "Reconstruction: 0.049140, Regularization: 0.000079, Discriminator: 0.021553; Generator: 0.010820,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,088 root         INFO     ====> Epoch: 53 Average loss: 0.0851\n",
      "2019-04-09 20:44:52,112 root         INFO     Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 0.083482\n",
      "Reconstruction: 0.050941, Regularization: 0.000084, Discriminator: 0.021627; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,178 root         INFO     Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 0.082819\n",
      "Reconstruction: 0.050223, Regularization: 0.000084, Discriminator: 0.021689; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,245 root         INFO     Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 0.085654\n",
      "Reconstruction: 0.052996, Regularization: 0.000092, Discriminator: 0.021742; Generator: 0.010825,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,311 root         INFO     Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 0.090892\n",
      "Reconstruction: 0.058326, Regularization: 0.000105, Discriminator: 0.021634; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,377 root         INFO     Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 0.098967\n",
      "Reconstruction: 0.066532, Regularization: 0.000121, Discriminator: 0.021486; Generator: 0.010828,\n",
      "D(x): 0.506, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,444 root         INFO     Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 0.081576\n",
      "Reconstruction: 0.049011, Regularization: 0.000080, Discriminator: 0.021651; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,510 root         INFO     Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 0.080130\n",
      "Reconstruction: 0.047661, Regularization: 0.000076, Discriminator: 0.021561; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,576 root         INFO     Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 0.088367\n",
      "Reconstruction: 0.055648, Regularization: 0.000093, Discriminator: 0.021791; Generator: 0.010836,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,644 root         INFO     ====> Epoch: 54 Average loss: 0.0851\n",
      "2019-04-09 20:44:52,668 root         INFO     Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 0.078894\n",
      "Reconstruction: 0.046366, Regularization: 0.000071, Discriminator: 0.021624; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,732 root         INFO     Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 0.091368\n",
      "Reconstruction: 0.058839, Regularization: 0.000102, Discriminator: 0.021597; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,795 root         INFO     Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 0.078886\n",
      "Reconstruction: 0.046299, Regularization: 0.000072, Discriminator: 0.021682; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,857 root         INFO     Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 0.094425\n",
      "Reconstruction: 0.061858, Regularization: 0.000109, Discriminator: 0.021625; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,920 root         INFO     Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 0.078410\n",
      "Reconstruction: 0.045844, Regularization: 0.000071, Discriminator: 0.021664; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:52,984 root         INFO     Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 0.076713\n",
      "Reconstruction: 0.044106, Regularization: 0.000066, Discriminator: 0.021719; Generator: 0.010822,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,047 root         INFO     Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 0.101709\n",
      "Reconstruction: 0.069203, Regularization: 0.000123, Discriminator: 0.021553; Generator: 0.010830,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,109 root         INFO     Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 0.076724\n",
      "Reconstruction: 0.044182, Regularization: 0.000069, Discriminator: 0.021644; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,174 root         INFO     ====> Epoch: 55 Average loss: 0.0851\n",
      "2019-04-09 20:44:53,198 root         INFO     Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 0.083391\n",
      "Reconstruction: 0.050735, Regularization: 0.000084, Discriminator: 0.021742; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,261 root         INFO     Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 0.086705\n",
      "Reconstruction: 0.054042, Regularization: 0.000091, Discriminator: 0.021741; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,325 root         INFO     Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 0.085849\n",
      "Reconstruction: 0.053399, Regularization: 0.000089, Discriminator: 0.021528; Generator: 0.010832,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,388 root         INFO     Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 0.085192\n",
      "Reconstruction: 0.052602, Regularization: 0.000090, Discriminator: 0.021669; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,452 root         INFO     Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 0.084304\n",
      "Reconstruction: 0.051737, Regularization: 0.000086, Discriminator: 0.021653; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,516 root         INFO     Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 0.069596\n",
      "Reconstruction: 0.037035, Regularization: 0.000053, Discriminator: 0.021679; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,583 root         INFO     Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 0.075565\n",
      "Reconstruction: 0.043050, Regularization: 0.000066, Discriminator: 0.021620; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,650 root         INFO     Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 0.082459\n",
      "Reconstruction: 0.049796, Regularization: 0.000083, Discriminator: 0.021747; Generator: 0.010832,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,720 root         INFO     ====> Epoch: 56 Average loss: 0.0851\n",
      "2019-04-09 20:44:53,744 root         INFO     Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 0.089983\n",
      "Reconstruction: 0.057419, Regularization: 0.000103, Discriminator: 0.021631; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,810 root         INFO     Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 0.087687\n",
      "Reconstruction: 0.055100, Regularization: 0.000099, Discriminator: 0.021656; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,875 root         INFO     Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 0.076434\n",
      "Reconstruction: 0.043902, Regularization: 0.000072, Discriminator: 0.021632; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:53,940 root         INFO     Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 0.088595\n",
      "Reconstruction: 0.055979, Regularization: 0.000103, Discriminator: 0.021686; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,006 root         INFO     Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 0.085490\n",
      "Reconstruction: 0.052822, Regularization: 0.000093, Discriminator: 0.021743; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,070 root         INFO     Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 0.076770\n",
      "Reconstruction: 0.044226, Regularization: 0.000074, Discriminator: 0.021642; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,134 root         INFO     Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 0.083576\n",
      "Reconstruction: 0.050992, Regularization: 0.000093, Discriminator: 0.021664; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,198 root         INFO     Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 0.086435\n",
      "Reconstruction: 0.053864, Regularization: 0.000100, Discriminator: 0.021636; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,264 root         INFO     ====> Epoch: 57 Average loss: 0.0851\n",
      "2019-04-09 20:44:54,289 root         INFO     Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 0.089044\n",
      "Reconstruction: 0.056370, Regularization: 0.000108, Discriminator: 0.021736; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,356 root         INFO     Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 0.096228\n",
      "Reconstruction: 0.063569, Regularization: 0.000125, Discriminator: 0.021709; Generator: 0.010825,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,422 root         INFO     Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 0.073205\n",
      "Reconstruction: 0.040677, Regularization: 0.000067, Discriminator: 0.021635; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,488 root         INFO     Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 0.085731\n",
      "Reconstruction: 0.053250, Regularization: 0.000100, Discriminator: 0.021552; Generator: 0.010829,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,557 root         INFO     Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 0.084102\n",
      "Reconstruction: 0.051496, Regularization: 0.000092, Discriminator: 0.021678; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,626 root         INFO     Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 0.085964\n",
      "Reconstruction: 0.053320, Regularization: 0.000097, Discriminator: 0.021714; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,694 root         INFO     Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 0.083086\n",
      "Reconstruction: 0.050549, Regularization: 0.000092, Discriminator: 0.021618; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,763 root         INFO     Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 0.077611\n",
      "Reconstruction: 0.045068, Regularization: 0.000077, Discriminator: 0.021633; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,832 root         INFO     ====> Epoch: 58 Average loss: 0.0851\n",
      "2019-04-09 20:44:54,856 root         INFO     Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 0.081379\n",
      "Reconstruction: 0.048743, Regularization: 0.000083, Discriminator: 0.021720; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,921 root         INFO     Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 0.075567\n",
      "Reconstruction: 0.043062, Regularization: 0.000067, Discriminator: 0.021607; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:54,987 root         INFO     Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 0.084746\n",
      "Reconstruction: 0.052149, Regularization: 0.000088, Discriminator: 0.021670; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,052 root         INFO     Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 0.093259\n",
      "Reconstruction: 0.060706, Regularization: 0.000106, Discriminator: 0.021612; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,118 root         INFO     Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 0.076649\n",
      "Reconstruction: 0.044048, Regularization: 0.000068, Discriminator: 0.021702; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,184 root         INFO     Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 0.078385\n",
      "Reconstruction: 0.045754, Regularization: 0.000072, Discriminator: 0.021726; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,250 root         INFO     Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 0.097032\n",
      "Reconstruction: 0.064515, Regularization: 0.000113, Discriminator: 0.021577; Generator: 0.010827,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,316 root         INFO     Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 0.083699\n",
      "Reconstruction: 0.051272, Regularization: 0.000084, Discriminator: 0.021515; Generator: 0.010827,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,384 root         INFO     ====> Epoch: 59 Average loss: 0.0851\n",
      "2019-04-09 20:44:55,408 root         INFO     Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 0.082326\n",
      "Reconstruction: 0.049808, Regularization: 0.000081, Discriminator: 0.021604; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,474 root         INFO     Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 0.076254\n",
      "Reconstruction: 0.043675, Regularization: 0.000066, Discriminator: 0.021676; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,540 root         INFO     Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 0.082408\n",
      "Reconstruction: 0.049754, Regularization: 0.000080, Discriminator: 0.021747; Generator: 0.010827,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,605 root         INFO     Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 0.076643\n",
      "Reconstruction: 0.044103, Regularization: 0.000067, Discriminator: 0.021645; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,671 root         INFO     Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 0.077541\n",
      "Reconstruction: 0.044971, Regularization: 0.000068, Discriminator: 0.021675; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,739 root         INFO     Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 0.077700\n",
      "Reconstruction: 0.045187, Regularization: 0.000068, Discriminator: 0.021615; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,806 root         INFO     Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 0.074482\n",
      "Reconstruction: 0.041915, Regularization: 0.000062, Discriminator: 0.021669; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,874 root         INFO     Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 0.082687\n",
      "Reconstruction: 0.050129, Regularization: 0.000080, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:55,942 root         INFO     ====> Epoch: 60 Average loss: 0.0851\n",
      "2019-04-09 20:44:55,967 root         INFO     Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 0.094110\n",
      "Reconstruction: 0.061429, Regularization: 0.000106, Discriminator: 0.021745; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,033 root         INFO     Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 0.083699\n",
      "Reconstruction: 0.051064, Regularization: 0.000086, Discriminator: 0.021724; Generator: 0.010824,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,096 root         INFO     Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 0.092863\n",
      "Reconstruction: 0.060254, Regularization: 0.000109, Discriminator: 0.021678; Generator: 0.010823,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,159 root         INFO     Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 0.088988\n",
      "Reconstruction: 0.056489, Regularization: 0.000102, Discriminator: 0.021573; Generator: 0.010825,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,222 root         INFO     Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 0.078641\n",
      "Reconstruction: 0.046095, Regularization: 0.000077, Discriminator: 0.021645; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,288 root         INFO     Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 0.085763\n",
      "Reconstruction: 0.053184, Regularization: 0.000094, Discriminator: 0.021651; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,353 root         INFO     Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 0.084636\n",
      "Reconstruction: 0.052051, Regularization: 0.000092, Discriminator: 0.021666; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,418 root         INFO     Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 0.087768\n",
      "Reconstruction: 0.055175, Regularization: 0.000099, Discriminator: 0.021661; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,487 root         INFO     ====> Epoch: 61 Average loss: 0.0850\n",
      "2019-04-09 20:44:56,511 root         INFO     Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 0.094398\n",
      "Reconstruction: 0.061733, Regularization: 0.000116, Discriminator: 0.021711; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,576 root         INFO     Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 0.077789\n",
      "Reconstruction: 0.045206, Regularization: 0.000076, Discriminator: 0.021673; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,640 root         INFO     Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 0.083372\n",
      "Reconstruction: 0.050820, Regularization: 0.000086, Discriminator: 0.021634; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,707 root         INFO     Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 0.087713\n",
      "Reconstruction: 0.055127, Regularization: 0.000097, Discriminator: 0.021661; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,774 root         INFO     Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 0.093241\n",
      "Reconstruction: 0.060650, Regularization: 0.000111, Discriminator: 0.021656; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,840 root         INFO     Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 0.085097\n",
      "Reconstruction: 0.052459, Regularization: 0.000087, Discriminator: 0.021714; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,907 root         INFO     Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 0.079974\n",
      "Reconstruction: 0.047400, Regularization: 0.000075, Discriminator: 0.021664; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:56,974 root         INFO     Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 0.073024\n",
      "Reconstruction: 0.040443, Regularization: 0.000060, Discriminator: 0.021682; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,042 root         INFO     ====> Epoch: 62 Average loss: 0.0851\n",
      "2019-04-09 20:44:57,066 root         INFO     Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 0.081909\n",
      "Reconstruction: 0.049255, Regularization: 0.000080, Discriminator: 0.021737; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,131 root         INFO     Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 0.086778\n",
      "Reconstruction: 0.054270, Regularization: 0.000091, Discriminator: 0.021582; Generator: 0.010834,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,198 root         INFO     Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 0.091260\n",
      "Reconstruction: 0.058701, Regularization: 0.000101, Discriminator: 0.021624; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,265 root         INFO     Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 0.083821\n",
      "Reconstruction: 0.051236, Regularization: 0.000085, Discriminator: 0.021667; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,330 root         INFO     Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 0.071355\n",
      "Reconstruction: 0.038814, Regularization: 0.000056, Discriminator: 0.021654; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,395 root         INFO     Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 0.078985\n",
      "Reconstruction: 0.046433, Regularization: 0.000072, Discriminator: 0.021651; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,461 root         INFO     Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 0.094852\n",
      "Reconstruction: 0.062302, Regularization: 0.000106, Discriminator: 0.021612; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,527 root         INFO     Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 0.079499\n",
      "Reconstruction: 0.046982, Regularization: 0.000073, Discriminator: 0.021609; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,595 root         INFO     ====> Epoch: 63 Average loss: 0.0851\n",
      "2019-04-09 20:44:57,620 root         INFO     Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 0.086859\n",
      "Reconstruction: 0.054334, Regularization: 0.000089, Discriminator: 0.021602; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,689 root         INFO     Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 0.087245\n",
      "Reconstruction: 0.054692, Regularization: 0.000090, Discriminator: 0.021629; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,756 root         INFO     Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 0.086587\n",
      "Reconstruction: 0.053926, Regularization: 0.000088, Discriminator: 0.021745; Generator: 0.010827,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,824 root         INFO     Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 0.080352\n",
      "Reconstruction: 0.047733, Regularization: 0.000072, Discriminator: 0.021706; Generator: 0.010840,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,891 root         INFO     Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 0.097805\n",
      "Reconstruction: 0.065181, Regularization: 0.000113, Discriminator: 0.021668; Generator: 0.010843,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:57,956 root         INFO     Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 0.082401\n",
      "Reconstruction: 0.049800, Regularization: 0.000079, Discriminator: 0.021680; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,026 root         INFO     Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 0.078526\n",
      "Reconstruction: 0.045902, Regularization: 0.000071, Discriminator: 0.021709; Generator: 0.010844,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,096 root         INFO     Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 0.084280\n",
      "Reconstruction: 0.051594, Regularization: 0.000084, Discriminator: 0.021771; Generator: 0.010831,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,163 root         INFO     ====> Epoch: 64 Average loss: 0.0851\n",
      "2019-04-09 20:44:58,187 root         INFO     Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 0.089589\n",
      "Reconstruction: 0.056994, Regularization: 0.000096, Discriminator: 0.021672; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,255 root         INFO     Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 0.077304\n",
      "Reconstruction: 0.044715, Regularization: 0.000068, Discriminator: 0.021696; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,320 root         INFO     Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 0.081951\n",
      "Reconstruction: 0.049390, Regularization: 0.000077, Discriminator: 0.021658; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,383 root         INFO     Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 0.080684\n",
      "Reconstruction: 0.048097, Regularization: 0.000076, Discriminator: 0.021677; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,447 root         INFO     Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 0.095082\n",
      "Reconstruction: 0.062428, Regularization: 0.000107, Discriminator: 0.021715; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,512 root         INFO     Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 0.082539\n",
      "Reconstruction: 0.050038, Regularization: 0.000081, Discriminator: 0.021596; Generator: 0.010824,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,576 root         INFO     Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 0.083699\n",
      "Reconstruction: 0.051110, Regularization: 0.000082, Discriminator: 0.021679; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,640 root         INFO     Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 0.088358\n",
      "Reconstruction: 0.055843, Regularization: 0.000093, Discriminator: 0.021595; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,707 root         INFO     ====> Epoch: 65 Average loss: 0.0851\n",
      "2019-04-09 20:44:58,730 root         INFO     Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 0.084916\n",
      "Reconstruction: 0.052323, Regularization: 0.000084, Discriminator: 0.021675; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,796 root         INFO     Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 0.081444\n",
      "Reconstruction: 0.048880, Regularization: 0.000078, Discriminator: 0.021645; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,862 root         INFO     Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 0.083435\n",
      "Reconstruction: 0.050905, Regularization: 0.000083, Discriminator: 0.021614; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,927 root         INFO     Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 0.079584\n",
      "Reconstruction: 0.047061, Regularization: 0.000072, Discriminator: 0.021624; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:58,992 root         INFO     Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 0.096913\n",
      "Reconstruction: 0.064332, Regularization: 0.000111, Discriminator: 0.021647; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,057 root         INFO     Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 0.084164\n",
      "Reconstruction: 0.051594, Regularization: 0.000084, Discriminator: 0.021658; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,121 root         INFO     Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 0.080306\n",
      "Reconstruction: 0.047721, Regularization: 0.000075, Discriminator: 0.021677; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,186 root         INFO     Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 0.074733\n",
      "Reconstruction: 0.042163, Regularization: 0.000062, Discriminator: 0.021674; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,252 root         INFO     ====> Epoch: 66 Average loss: 0.0851\n",
      "2019-04-09 20:44:59,277 root         INFO     Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 0.071398\n",
      "Reconstruction: 0.038818, Regularization: 0.000055, Discriminator: 0.021688; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,343 root         INFO     Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 0.080938\n",
      "Reconstruction: 0.048400, Regularization: 0.000076, Discriminator: 0.021626; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,409 root         INFO     Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 0.083706\n",
      "Reconstruction: 0.051120, Regularization: 0.000083, Discriminator: 0.021657; Generator: 0.010847,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 20:44:59,475 root         INFO     Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 0.091205\n",
      "Reconstruction: 0.058606, Regularization: 0.000101, Discriminator: 0.021656; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,540 root         INFO     Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 0.091587\n",
      "Reconstruction: 0.058920, Regularization: 0.000102, Discriminator: 0.021723; Generator: 0.010842,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,602 root         INFO     Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 0.098882\n",
      "Reconstruction: 0.066339, Regularization: 0.000120, Discriminator: 0.021589; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,664 root         INFO     Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 0.086496\n",
      "Reconstruction: 0.053799, Regularization: 0.000091, Discriminator: 0.021769; Generator: 0.010837,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,726 root         INFO     Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 0.082954\n",
      "Reconstruction: 0.050437, Regularization: 0.000083, Discriminator: 0.021605; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,790 root         INFO     ====> Epoch: 67 Average loss: 0.0851\n",
      "2019-04-09 20:44:59,814 root         INFO     Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 0.090109\n",
      "Reconstruction: 0.057523, Regularization: 0.000099, Discriminator: 0.021662; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,879 root         INFO     Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 0.083517\n",
      "Reconstruction: 0.050974, Regularization: 0.000085, Discriminator: 0.021630; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:44:59,944 root         INFO     Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 0.075806\n",
      "Reconstruction: 0.043290, Regularization: 0.000069, Discriminator: 0.021621; Generator: 0.010826,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,009 root         INFO     Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 0.079538\n",
      "Reconstruction: 0.046965, Regularization: 0.000077, Discriminator: 0.021666; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,071 root         INFO     Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 0.090414\n",
      "Reconstruction: 0.057791, Regularization: 0.000105, Discriminator: 0.021690; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,134 root         INFO     Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 0.073727\n",
      "Reconstruction: 0.041192, Regularization: 0.000065, Discriminator: 0.021640; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,197 root         INFO     Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 0.079746\n",
      "Reconstruction: 0.047192, Regularization: 0.000080, Discriminator: 0.021639; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,261 root         INFO     Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 0.086349\n",
      "Reconstruction: 0.053703, Regularization: 0.000094, Discriminator: 0.021712; Generator: 0.010841,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,326 root         INFO     ====> Epoch: 68 Average loss: 0.0851\n",
      "2019-04-09 20:45:00,350 root         INFO     Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 0.091284\n",
      "Reconstruction: 0.058705, Regularization: 0.000109, Discriminator: 0.021638; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,413 root         INFO     Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 0.089293\n",
      "Reconstruction: 0.056664, Regularization: 0.000103, Discriminator: 0.021689; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,476 root         INFO     Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 0.072544\n",
      "Reconstruction: 0.040037, Regularization: 0.000063, Discriminator: 0.021613; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,539 root         INFO     Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 0.080203\n",
      "Reconstruction: 0.047662, Regularization: 0.000081, Discriminator: 0.021623; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,602 root         INFO     Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 0.092076\n",
      "Reconstruction: 0.059461, Regularization: 0.000111, Discriminator: 0.021664; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,664 root         INFO     Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 0.090477\n",
      "Reconstruction: 0.057865, Regularization: 0.000108, Discriminator: 0.021671; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,727 root         INFO     Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 0.091354\n",
      "Reconstruction: 0.058795, Regularization: 0.000109, Discriminator: 0.021620; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,790 root         INFO     Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 0.083359\n",
      "Reconstruction: 0.050756, Regularization: 0.000089, Discriminator: 0.021680; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,855 root         INFO     ====> Epoch: 69 Average loss: 0.0851\n",
      "2019-04-09 20:45:00,879 root         INFO     Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 0.083026\n",
      "Reconstruction: 0.050464, Regularization: 0.000088, Discriminator: 0.021646; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:00,945 root         INFO     Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 0.077118\n",
      "Reconstruction: 0.044576, Regularization: 0.000074, Discriminator: 0.021633; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,011 root         INFO     Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 0.093119\n",
      "Reconstruction: 0.060528, Regularization: 0.000112, Discriminator: 0.021643; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,078 root         INFO     Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 0.085102\n",
      "Reconstruction: 0.052605, Regularization: 0.000092, Discriminator: 0.021572; Generator: 0.010834,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,145 root         INFO     Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 0.072405\n",
      "Reconstruction: 0.039883, Regularization: 0.000062, Discriminator: 0.021629; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,213 root         INFO     Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 0.091391\n",
      "Reconstruction: 0.058741, Regularization: 0.000110, Discriminator: 0.021706; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,280 root         INFO     Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 0.096680\n",
      "Reconstruction: 0.064031, Regularization: 0.000121, Discriminator: 0.021698; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,346 root         INFO     Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 0.090271\n",
      "Reconstruction: 0.057774, Regularization: 0.000104, Discriminator: 0.021565; Generator: 0.010828,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,416 root         INFO     ====> Epoch: 70 Average loss: 0.0851\n",
      "2019-04-09 20:45:01,440 root         INFO     Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 0.082213\n",
      "Reconstruction: 0.049613, Regularization: 0.000084, Discriminator: 0.021688; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,506 root         INFO     Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 0.086336\n",
      "Reconstruction: 0.053774, Regularization: 0.000094, Discriminator: 0.021635; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,572 root         INFO     Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 0.094186\n",
      "Reconstruction: 0.061551, Regularization: 0.000114, Discriminator: 0.021690; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,638 root         INFO     Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 0.105443\n",
      "Reconstruction: 0.072890, Regularization: 0.000138, Discriminator: 0.021586; Generator: 0.010829,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,703 root         INFO     Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 0.094359\n",
      "Reconstruction: 0.061692, Regularization: 0.000111, Discriminator: 0.021722; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,769 root         INFO     Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 0.077272\n",
      "Reconstruction: 0.044773, Regularization: 0.000072, Discriminator: 0.021592; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,835 root         INFO     Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 0.084184\n",
      "Reconstruction: 0.051678, Regularization: 0.000089, Discriminator: 0.021582; Generator: 0.010834,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,901 root         INFO     Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 0.083219\n",
      "Reconstruction: 0.050639, Regularization: 0.000086, Discriminator: 0.021660; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:01,968 root         INFO     ====> Epoch: 71 Average loss: 0.0851\n",
      "2019-04-09 20:45:01,992 root         INFO     Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 0.069784\n",
      "Reconstruction: 0.037218, Regularization: 0.000054, Discriminator: 0.021682; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,056 root         INFO     Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 0.087726\n",
      "Reconstruction: 0.055126, Regularization: 0.000096, Discriminator: 0.021672; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,122 root         INFO     Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 0.084833\n",
      "Reconstruction: 0.052291, Regularization: 0.000091, Discriminator: 0.021620; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,188 root         INFO     Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 0.082719\n",
      "Reconstruction: 0.050131, Regularization: 0.000086, Discriminator: 0.021673; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,254 root         INFO     Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 0.090640\n",
      "Reconstruction: 0.058121, Regularization: 0.000107, Discriminator: 0.021587; Generator: 0.010826,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,320 root         INFO     Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 0.081094\n",
      "Reconstruction: 0.048548, Regularization: 0.000085, Discriminator: 0.021629; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,385 root         INFO     Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 0.083829\n",
      "Reconstruction: 0.051188, Regularization: 0.000091, Discriminator: 0.021719; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,450 root         INFO     Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 0.071899\n",
      "Reconstruction: 0.039383, Regularization: 0.000063, Discriminator: 0.021624; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,518 root         INFO     ====> Epoch: 72 Average loss: 0.0851\n",
      "2019-04-09 20:45:02,542 root         INFO     Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 0.082772\n",
      "Reconstruction: 0.050188, Regularization: 0.000088, Discriminator: 0.021658; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,606 root         INFO     Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 0.075698\n",
      "Reconstruction: 0.043078, Regularization: 0.000070, Discriminator: 0.021714; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,672 root         INFO     Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 0.087464\n",
      "Reconstruction: 0.054970, Regularization: 0.000099, Discriminator: 0.021562; Generator: 0.010833,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,741 root         INFO     Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 0.073151\n",
      "Reconstruction: 0.040585, Regularization: 0.000064, Discriminator: 0.021663; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,809 root         INFO     Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 0.081974\n",
      "Reconstruction: 0.049375, Regularization: 0.000087, Discriminator: 0.021677; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,878 root         INFO     Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 0.082887\n",
      "Reconstruction: 0.050351, Regularization: 0.000088, Discriminator: 0.021612; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:02,947 root         INFO     Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 0.077703\n",
      "Reconstruction: 0.045154, Regularization: 0.000076, Discriminator: 0.021643; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,015 root         INFO     Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 0.083710\n",
      "Reconstruction: 0.051094, Regularization: 0.000089, Discriminator: 0.021697; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,088 root         INFO     ====> Epoch: 73 Average loss: 0.0851\n",
      "2019-04-09 20:45:03,112 root         INFO     Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 0.074831\n",
      "Reconstruction: 0.042254, Regularization: 0.000068, Discriminator: 0.021676; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,179 root         INFO     Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 0.093641\n",
      "Reconstruction: 0.061091, Regularization: 0.000111, Discriminator: 0.021609; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,242 root         INFO     Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 0.093002\n",
      "Reconstruction: 0.060285, Regularization: 0.000110, Discriminator: 0.021779; Generator: 0.010827,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,308 root         INFO     Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 0.075896\n",
      "Reconstruction: 0.043363, Regularization: 0.000068, Discriminator: 0.021635; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,377 root         INFO     Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 0.073954\n",
      "Reconstruction: 0.041411, Regularization: 0.000064, Discriminator: 0.021644; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,446 root         INFO     Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 0.088534\n",
      "Reconstruction: 0.056002, Regularization: 0.000100, Discriminator: 0.021601; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,516 root         INFO     Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 0.084461\n",
      "Reconstruction: 0.051868, Regularization: 0.000090, Discriminator: 0.021668; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,584 root         INFO     Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 0.074997\n",
      "Reconstruction: 0.042477, Regularization: 0.000067, Discriminator: 0.021614; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,653 root         INFO     ====> Epoch: 74 Average loss: 0.0851\n",
      "2019-04-09 20:45:03,677 root         INFO     Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 0.090097\n",
      "Reconstruction: 0.057423, Regularization: 0.000103, Discriminator: 0.021734; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,750 root         INFO     Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 0.081407\n",
      "Reconstruction: 0.048907, Regularization: 0.000081, Discriminator: 0.021586; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,819 root         INFO     Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 0.080234\n",
      "Reconstruction: 0.047646, Regularization: 0.000080, Discriminator: 0.021678; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,887 root         INFO     Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 0.077616\n",
      "Reconstruction: 0.045117, Regularization: 0.000073, Discriminator: 0.021607; Generator: 0.010819,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:03,955 root         INFO     Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 0.083790\n",
      "Reconstruction: 0.051184, Regularization: 0.000086, Discriminator: 0.021689; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,021 root         INFO     Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 0.082258\n",
      "Reconstruction: 0.049694, Regularization: 0.000082, Discriminator: 0.021652; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,089 root         INFO     Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 0.075081\n",
      "Reconstruction: 0.042449, Regularization: 0.000064, Discriminator: 0.021733; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,157 root         INFO     Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 0.087768\n",
      "Reconstruction: 0.055056, Regularization: 0.000091, Discriminator: 0.021781; Generator: 0.010841,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,227 root         INFO     ====> Epoch: 75 Average loss: 0.0851\n",
      "2019-04-09 20:45:04,251 root         INFO     Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 0.079874\n",
      "Reconstruction: 0.047350, Regularization: 0.000075, Discriminator: 0.021609; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,319 root         INFO     Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 0.080699\n",
      "Reconstruction: 0.048124, Regularization: 0.000074, Discriminator: 0.021665; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,385 root         INFO     Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 0.092884\n",
      "Reconstruction: 0.060281, Regularization: 0.000101, Discriminator: 0.021664; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,453 root         INFO     Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 0.088858\n",
      "Reconstruction: 0.056310, Regularization: 0.000093, Discriminator: 0.021623; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,520 root         INFO     Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 0.088523\n",
      "Reconstruction: 0.055939, Regularization: 0.000091, Discriminator: 0.021661; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,588 root         INFO     Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 0.096125\n",
      "Reconstruction: 0.063573, Regularization: 0.000107, Discriminator: 0.021606; Generator: 0.010839,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,656 root         INFO     Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 0.093567\n",
      "Reconstruction: 0.060943, Regularization: 0.000104, Discriminator: 0.021681; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,733 root         INFO     Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 0.095115\n",
      "Reconstruction: 0.062576, Regularization: 0.000103, Discriminator: 0.021604; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,802 root         INFO     ====> Epoch: 76 Average loss: 0.0851\n",
      "2019-04-09 20:45:04,826 root         INFO     Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 0.085494\n",
      "Reconstruction: 0.052878, Regularization: 0.000080, Discriminator: 0.021705; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,892 root         INFO     Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 0.092564\n",
      "Reconstruction: 0.060007, Regularization: 0.000098, Discriminator: 0.021622; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:04,959 root         INFO     Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 0.087078\n",
      "Reconstruction: 0.054477, Regularization: 0.000086, Discriminator: 0.021685; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,024 root         INFO     Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 0.081598\n",
      "Reconstruction: 0.049074, Regularization: 0.000075, Discriminator: 0.021619; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,116 root         INFO     Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 0.089139\n",
      "Reconstruction: 0.056500, Regularization: 0.000095, Discriminator: 0.021712; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,218 root         INFO     Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 0.094494\n",
      "Reconstruction: 0.061918, Regularization: 0.000109, Discriminator: 0.021638; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,287 root         INFO     Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 0.091463\n",
      "Reconstruction: 0.058857, Regularization: 0.000103, Discriminator: 0.021665; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,354 root         INFO     Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 0.083545\n",
      "Reconstruction: 0.050895, Regularization: 0.000087, Discriminator: 0.021724; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,423 root         INFO     ====> Epoch: 77 Average loss: 0.0851\n",
      "2019-04-09 20:45:05,447 root         INFO     Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 0.090489\n",
      "Reconstruction: 0.057884, Regularization: 0.000102, Discriminator: 0.021667; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,513 root         INFO     Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 0.078655\n",
      "Reconstruction: 0.046099, Regularization: 0.000074, Discriminator: 0.021650; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,579 root         INFO     Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 0.088697\n",
      "Reconstruction: 0.056145, Regularization: 0.000098, Discriminator: 0.021620; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,644 root         INFO     Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 0.085193\n",
      "Reconstruction: 0.052643, Regularization: 0.000090, Discriminator: 0.021627; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,708 root         INFO     Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 0.088186\n",
      "Reconstruction: 0.055579, Regularization: 0.000098, Discriminator: 0.021673; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,774 root         INFO     Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 0.081478\n",
      "Reconstruction: 0.048785, Regularization: 0.000083, Discriminator: 0.021771; Generator: 0.010840,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,839 root         INFO     Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 0.084930\n",
      "Reconstruction: 0.052384, Regularization: 0.000092, Discriminator: 0.021626; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,903 root         INFO     Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 0.070665\n",
      "Reconstruction: 0.038133, Regularization: 0.000058, Discriminator: 0.021641; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:05,970 root         INFO     ====> Epoch: 78 Average loss: 0.0851\n",
      "2019-04-09 20:45:05,994 root         INFO     Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 0.075751\n",
      "Reconstruction: 0.043176, Regularization: 0.000070, Discriminator: 0.021668; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,061 root         INFO     Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 0.083818\n",
      "Reconstruction: 0.051259, Regularization: 0.000093, Discriminator: 0.021630; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,127 root         INFO     Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 0.076566\n",
      "Reconstruction: 0.043941, Regularization: 0.000073, Discriminator: 0.021705; Generator: 0.010847,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 20:45:06,192 root         INFO     Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 0.104468\n",
      "Reconstruction: 0.071771, Regularization: 0.000141, Discriminator: 0.021719; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,257 root         INFO     Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 0.097007\n",
      "Reconstruction: 0.064306, Regularization: 0.000129, Discriminator: 0.021735; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,320 root         INFO     Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 0.099788\n",
      "Reconstruction: 0.067162, Regularization: 0.000137, Discriminator: 0.021651; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,382 root         INFO     Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 0.094634\n",
      "Reconstruction: 0.062010, Regularization: 0.000124, Discriminator: 0.021665; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,445 root         INFO     Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 0.087887\n",
      "Reconstruction: 0.055252, Regularization: 0.000106, Discriminator: 0.021701; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,509 root         INFO     ====> Epoch: 79 Average loss: 0.0851\n",
      "2019-04-09 20:45:06,533 root         INFO     Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 0.089227\n",
      "Reconstruction: 0.056649, Regularization: 0.000108, Discriminator: 0.021640; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,597 root         INFO     Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 0.087806\n",
      "Reconstruction: 0.055219, Regularization: 0.000105, Discriminator: 0.021635; Generator: 0.010847,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 20:45:06,660 root         INFO     Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 0.088946\n",
      "Reconstruction: 0.056348, Regularization: 0.000104, Discriminator: 0.021659; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,724 root         INFO     Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 0.084281\n",
      "Reconstruction: 0.051775, Regularization: 0.000093, Discriminator: 0.021582; Generator: 0.010830,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,788 root         INFO     Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 0.078925\n",
      "Reconstruction: 0.046314, Regularization: 0.000078, Discriminator: 0.021695; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,852 root         INFO     Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 0.086849\n",
      "Reconstruction: 0.054263, Regularization: 0.000097, Discriminator: 0.021659; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,915 root         INFO     Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 0.080587\n",
      "Reconstruction: 0.047923, Regularization: 0.000086, Discriminator: 0.021750; Generator: 0.010827,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:06,979 root         INFO     Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 0.079181\n",
      "Reconstruction: 0.046626, Regularization: 0.000082, Discriminator: 0.021647; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,044 root         INFO     ====> Epoch: 80 Average loss: 0.0851\n",
      "2019-04-09 20:45:07,068 root         INFO     Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 0.087824\n",
      "Reconstruction: 0.055198, Regularization: 0.000104, Discriminator: 0.021688; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,134 root         INFO     Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 0.083843\n",
      "Reconstruction: 0.051303, Regularization: 0.000095, Discriminator: 0.021599; Generator: 0.010846,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 20:45:07,199 root         INFO     Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 0.079386\n",
      "Reconstruction: 0.046734, Regularization: 0.000084, Discriminator: 0.021720; Generator: 0.010848,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 20:45:07,266 root         INFO     Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 0.082997\n",
      "Reconstruction: 0.050383, Regularization: 0.000094, Discriminator: 0.021684; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,332 root         INFO     Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 0.083269\n",
      "Reconstruction: 0.050725, Regularization: 0.000095, Discriminator: 0.021616; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,398 root         INFO     Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 0.089884\n",
      "Reconstruction: 0.057256, Regularization: 0.000110, Discriminator: 0.021685; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,464 root         INFO     Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 0.081957\n",
      "Reconstruction: 0.049417, Regularization: 0.000090, Discriminator: 0.021622; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,529 root         INFO     Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 0.095069\n",
      "Reconstruction: 0.062455, Regularization: 0.000121, Discriminator: 0.021671; Generator: 0.010823,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,596 root         INFO     ====> Epoch: 81 Average loss: 0.0851\n",
      "2019-04-09 20:45:07,620 root         INFO     Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 0.096308\n",
      "Reconstruction: 0.063681, Regularization: 0.000128, Discriminator: 0.021670; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,684 root         INFO     Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 0.096914\n",
      "Reconstruction: 0.064335, Regularization: 0.000127, Discriminator: 0.021626; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,747 root         INFO     Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 0.080535\n",
      "Reconstruction: 0.047963, Regularization: 0.000088, Discriminator: 0.021652; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,810 root         INFO     Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 0.071145\n",
      "Reconstruction: 0.038653, Regularization: 0.000064, Discriminator: 0.021595; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,873 root         INFO     Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 0.082984\n",
      "Reconstruction: 0.050455, Regularization: 0.000096, Discriminator: 0.021607; Generator: 0.010826,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,936 root         INFO     Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 0.081302\n",
      "Reconstruction: 0.048725, Regularization: 0.000091, Discriminator: 0.021651; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:07,999 root         INFO     Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 0.079293\n",
      "Reconstruction: 0.046692, Regularization: 0.000086, Discriminator: 0.021678; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,062 root         INFO     Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 0.082137\n",
      "Reconstruction: 0.049586, Regularization: 0.000093, Discriminator: 0.021619; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,126 root         INFO     ====> Epoch: 82 Average loss: 0.0851\n",
      "2019-04-09 20:45:08,150 root         INFO     Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 0.081844\n",
      "Reconstruction: 0.049185, Regularization: 0.000092, Discriminator: 0.021730; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,213 root         INFO     Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 0.080854\n",
      "Reconstruction: 0.048273, Regularization: 0.000086, Discriminator: 0.021654; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,276 root         INFO     Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 0.070362\n",
      "Reconstruction: 0.037862, Regularization: 0.000060, Discriminator: 0.021597; Generator: 0.010843,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,342 root         INFO     Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 0.088073\n",
      "Reconstruction: 0.055531, Regularization: 0.000103, Discriminator: 0.021602; Generator: 0.010838,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,408 root         INFO     Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 0.094365\n",
      "Reconstruction: 0.061757, Regularization: 0.000122, Discriminator: 0.021642; Generator: 0.010844,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,474 root         INFO     Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 0.092472\n",
      "Reconstruction: 0.059781, Regularization: 0.000115, Discriminator: 0.021743; Generator: 0.010833,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,539 root         INFO     Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 0.087942\n",
      "Reconstruction: 0.055403, Regularization: 0.000103, Discriminator: 0.021605; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,605 root         INFO     Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 0.087486\n",
      "Reconstruction: 0.054874, Regularization: 0.000099, Discriminator: 0.021685; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,672 root         INFO     ====> Epoch: 83 Average loss: 0.0851\n",
      "2019-04-09 20:45:08,696 root         INFO     Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 0.089284\n",
      "Reconstruction: 0.056617, Regularization: 0.000104, Discriminator: 0.021737; Generator: 0.010825,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,759 root         INFO     Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 0.090990\n",
      "Reconstruction: 0.058423, Regularization: 0.000107, Discriminator: 0.021628; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,822 root         INFO     Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 0.087418\n",
      "Reconstruction: 0.054887, Regularization: 0.000099, Discriminator: 0.021603; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,886 root         INFO     Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 0.087611\n",
      "Reconstruction: 0.054959, Regularization: 0.000100, Discriminator: 0.021727; Generator: 0.010825,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:08,952 root         INFO     Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 0.088487\n",
      "Reconstruction: 0.055898, Regularization: 0.000103, Discriminator: 0.021661; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,018 root         INFO     Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 0.074982\n",
      "Reconstruction: 0.042470, Regularization: 0.000067, Discriminator: 0.021617; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,084 root         INFO     Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 0.087752\n",
      "Reconstruction: 0.055168, Regularization: 0.000100, Discriminator: 0.021643; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,150 root         INFO     Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 0.078791\n",
      "Reconstruction: 0.046292, Regularization: 0.000078, Discriminator: 0.021579; Generator: 0.010841,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,218 root         INFO     ====> Epoch: 84 Average loss: 0.0851\n",
      "2019-04-09 20:45:09,242 root         INFO     Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 0.087452\n",
      "Reconstruction: 0.054807, Regularization: 0.000101, Discriminator: 0.021707; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,307 root         INFO     Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 0.083943\n",
      "Reconstruction: 0.051291, Regularization: 0.000094, Discriminator: 0.021720; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,374 root         INFO     Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 0.091961\n",
      "Reconstruction: 0.059425, Regularization: 0.000113, Discriminator: 0.021587; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,439 root         INFO     Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 0.088122\n",
      "Reconstruction: 0.055458, Regularization: 0.000103, Discriminator: 0.021729; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,505 root         INFO     Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 0.081171\n",
      "Reconstruction: 0.048651, Regularization: 0.000088, Discriminator: 0.021602; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,572 root         INFO     Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 0.072544\n",
      "Reconstruction: 0.039901, Regularization: 0.000067, Discriminator: 0.021747; Generator: 0.010828,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,638 root         INFO     Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 0.081129\n",
      "Reconstruction: 0.048581, Regularization: 0.000089, Discriminator: 0.021628; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,705 root         INFO     Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 0.076682\n",
      "Reconstruction: 0.044065, Regularization: 0.000076, Discriminator: 0.021702; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,773 root         INFO     ====> Epoch: 85 Average loss: 0.0851\n",
      "2019-04-09 20:45:09,797 root         INFO     Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 0.081599\n",
      "Reconstruction: 0.049024, Regularization: 0.000089, Discriminator: 0.021654; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,864 root         INFO     Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 0.080174\n",
      "Reconstruction: 0.047678, Regularization: 0.000086, Discriminator: 0.021581; Generator: 0.010829,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:09,933 root         INFO     Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 0.083448\n",
      "Reconstruction: 0.050888, Regularization: 0.000095, Discriminator: 0.021636; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,001 root         INFO     Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 0.084674\n",
      "Reconstruction: 0.052047, Regularization: 0.000097, Discriminator: 0.021704; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,070 root         INFO     Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 0.079932\n",
      "Reconstruction: 0.047363, Regularization: 0.000083, Discriminator: 0.021654; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,139 root         INFO     Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 0.080889\n",
      "Reconstruction: 0.048287, Regularization: 0.000085, Discriminator: 0.021681; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,207 root         INFO     Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 0.081553\n",
      "Reconstruction: 0.049114, Regularization: 0.000086, Discriminator: 0.021522; Generator: 0.010831,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,276 root         INFO     Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 0.089489\n",
      "Reconstruction: 0.056920, Regularization: 0.000104, Discriminator: 0.021624; Generator: 0.010841,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,347 root         INFO     ====> Epoch: 86 Average loss: 0.0850\n",
      "2019-04-09 20:45:10,371 root         INFO     Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 0.086457\n",
      "Reconstruction: 0.053896, Regularization: 0.000096, Discriminator: 0.021627; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,438 root         INFO     Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 0.092219\n",
      "Reconstruction: 0.059620, Regularization: 0.000109, Discriminator: 0.021648; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,506 root         INFO     Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 0.078877\n",
      "Reconstruction: 0.046311, Regularization: 0.000077, Discriminator: 0.021656; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,572 root         INFO     Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 0.092819\n",
      "Reconstruction: 0.060229, Regularization: 0.000110, Discriminator: 0.021650; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,639 root         INFO     Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 0.091433\n",
      "Reconstruction: 0.058894, Regularization: 0.000107, Discriminator: 0.021604; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,707 root         INFO     Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 0.080352\n",
      "Reconstruction: 0.047769, Regularization: 0.000080, Discriminator: 0.021671; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,774 root         INFO     Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 0.081945\n",
      "Reconstruction: 0.049416, Regularization: 0.000084, Discriminator: 0.021611; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,842 root         INFO     Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 0.085812\n",
      "Reconstruction: 0.053308, Regularization: 0.000094, Discriminator: 0.021574; Generator: 0.010836,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:10,913 root         INFO     ====> Epoch: 87 Average loss: 0.0851\n",
      "2019-04-09 20:45:10,937 root         INFO     Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 0.087193\n",
      "Reconstruction: 0.054580, Regularization: 0.000095, Discriminator: 0.021683; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,006 root         INFO     Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 0.099324\n",
      "Reconstruction: 0.066818, Regularization: 0.000123, Discriminator: 0.021560; Generator: 0.010823,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,073 root         INFO     Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 0.090495\n",
      "Reconstruction: 0.057922, Regularization: 0.000103, Discriminator: 0.021646; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,141 root         INFO     Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 0.091619\n",
      "Reconstruction: 0.059018, Regularization: 0.000106, Discriminator: 0.021657; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,208 root         INFO     Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 0.073311\n",
      "Reconstruction: 0.040770, Regularization: 0.000063, Discriminator: 0.021636; Generator: 0.010842,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,276 root         INFO     Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 0.082795\n",
      "Reconstruction: 0.050231, Regularization: 0.000084, Discriminator: 0.021636; Generator: 0.010844,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,344 root         INFO     Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 0.082464\n",
      "Reconstruction: 0.049981, Regularization: 0.000085, Discriminator: 0.021560; Generator: 0.010837,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,411 root         INFO     Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 0.085196\n",
      "Reconstruction: 0.052631, Regularization: 0.000094, Discriminator: 0.021636; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,478 root         INFO     ====> Epoch: 88 Average loss: 0.0851\n",
      "2019-04-09 20:45:11,502 root         INFO     Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 0.078509\n",
      "Reconstruction: 0.045918, Regularization: 0.000077, Discriminator: 0.021683; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,570 root         INFO     Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 0.091653\n",
      "Reconstruction: 0.059132, Regularization: 0.000110, Discriminator: 0.021585; Generator: 0.010825,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,638 root         INFO     Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 0.087629\n",
      "Reconstruction: 0.055032, Regularization: 0.000099, Discriminator: 0.021665; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,705 root         INFO     Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 0.085720\n",
      "Reconstruction: 0.053110, Regularization: 0.000096, Discriminator: 0.021682; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,772 root         INFO     Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 0.086248\n",
      "Reconstruction: 0.053715, Regularization: 0.000097, Discriminator: 0.021611; Generator: 0.010825,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,840 root         INFO     Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 0.088313\n",
      "Reconstruction: 0.055650, Regularization: 0.000102, Discriminator: 0.021728; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,907 root         INFO     Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 0.085393\n",
      "Reconstruction: 0.052769, Regularization: 0.000094, Discriminator: 0.021696; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:11,975 root         INFO     Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 0.074568\n",
      "Reconstruction: 0.042007, Regularization: 0.000066, Discriminator: 0.021661; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,044 root         INFO     ====> Epoch: 89 Average loss: 0.0851\n",
      "2019-04-09 20:45:12,068 root         INFO     Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 0.086291\n",
      "Reconstruction: 0.053710, Regularization: 0.000095, Discriminator: 0.021646; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,135 root         INFO     Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 0.088142\n",
      "Reconstruction: 0.055570, Regularization: 0.000099, Discriminator: 0.021640; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,201 root         INFO     Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 0.088903\n",
      "Reconstruction: 0.056312, Regularization: 0.000098, Discriminator: 0.021658; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,268 root         INFO     Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 0.087067\n",
      "Reconstruction: 0.054439, Regularization: 0.000094, Discriminator: 0.021692; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,334 root         INFO     Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 0.086959\n",
      "Reconstruction: 0.054363, Regularization: 0.000093, Discriminator: 0.021667; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,401 root         INFO     Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 0.087634\n",
      "Reconstruction: 0.055107, Regularization: 0.000094, Discriminator: 0.021598; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,468 root         INFO     Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 0.089703\n",
      "Reconstruction: 0.057003, Regularization: 0.000098, Discriminator: 0.021761; Generator: 0.010841,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,535 root         INFO     Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 0.081396\n",
      "Reconstruction: 0.048805, Regularization: 0.000081, Discriminator: 0.021677; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,603 root         INFO     ====> Epoch: 90 Average loss: 0.0851\n",
      "2019-04-09 20:45:12,627 root         INFO     Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 0.089854\n",
      "Reconstruction: 0.057313, Regularization: 0.000102, Discriminator: 0.021610; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,694 root         INFO     Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 0.097007\n",
      "Reconstruction: 0.064405, Regularization: 0.000120, Discriminator: 0.021650; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,761 root         INFO     Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 0.070423\n",
      "Reconstruction: 0.037871, Regularization: 0.000056, Discriminator: 0.021662; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,830 root         INFO     Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 0.086859\n",
      "Reconstruction: 0.054132, Regularization: 0.000096, Discriminator: 0.021790; Generator: 0.010840,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,895 root         INFO     Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 0.076250\n",
      "Reconstruction: 0.043640, Regularization: 0.000071, Discriminator: 0.021704; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:12,960 root         INFO     Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 0.070943\n",
      "Reconstruction: 0.038411, Regularization: 0.000057, Discriminator: 0.021641; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,024 root         INFO     Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 0.099817\n",
      "Reconstruction: 0.067256, Regularization: 0.000124, Discriminator: 0.021605; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,086 root         INFO     Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 0.087505\n",
      "Reconstruction: 0.054916, Regularization: 0.000094, Discriminator: 0.021668; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,150 root         INFO     ====> Epoch: 91 Average loss: 0.0850\n",
      "2019-04-09 20:45:13,174 root         INFO     Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 0.081752\n",
      "Reconstruction: 0.049199, Regularization: 0.000082, Discriminator: 0.021639; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,238 root         INFO     Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 0.099963\n",
      "Reconstruction: 0.067292, Regularization: 0.000125, Discriminator: 0.021718; Generator: 0.010829,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,305 root         INFO     Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 0.096183\n",
      "Reconstruction: 0.063556, Regularization: 0.000117, Discriminator: 0.021681; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,371 root         INFO     Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 0.073829\n",
      "Reconstruction: 0.041289, Regularization: 0.000062, Discriminator: 0.021643; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,437 root         INFO     Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 0.082075\n",
      "Reconstruction: 0.049531, Regularization: 0.000081, Discriminator: 0.021624; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,503 root         INFO     Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 0.089599\n",
      "Reconstruction: 0.057024, Regularization: 0.000098, Discriminator: 0.021642; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,569 root         INFO     Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 0.085800\n",
      "Reconstruction: 0.053229, Regularization: 0.000090, Discriminator: 0.021652; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,636 root         INFO     Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 0.080524\n",
      "Reconstruction: 0.047935, Regularization: 0.000077, Discriminator: 0.021680; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,703 root         INFO     ====> Epoch: 92 Average loss: 0.0851\n",
      "2019-04-09 20:45:13,728 root         INFO     Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 0.089016\n",
      "Reconstruction: 0.056408, Regularization: 0.000097, Discriminator: 0.021671; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,795 root         INFO     Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 0.082454\n",
      "Reconstruction: 0.049890, Regularization: 0.000079, Discriminator: 0.021650; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,862 root         INFO     Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 0.084324\n",
      "Reconstruction: 0.051693, Regularization: 0.000085, Discriminator: 0.021716; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,927 root         INFO     Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 0.096079\n",
      "Reconstruction: 0.063455, Regularization: 0.000113, Discriminator: 0.021682; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:13,993 root         INFO     Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 0.083901\n",
      "Reconstruction: 0.051314, Regularization: 0.000084, Discriminator: 0.021677; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,058 root         INFO     Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 0.071868\n",
      "Reconstruction: 0.039402, Regularization: 0.000058, Discriminator: 0.021581; Generator: 0.010827,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,125 root         INFO     Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 0.076974\n",
      "Reconstruction: 0.044401, Regularization: 0.000069, Discriminator: 0.021678; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,191 root         INFO     Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 0.080026\n",
      "Reconstruction: 0.047475, Regularization: 0.000078, Discriminator: 0.021633; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,258 root         INFO     ====> Epoch: 93 Average loss: 0.0851\n",
      "2019-04-09 20:45:14,282 root         INFO     Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 0.082840\n",
      "Reconstruction: 0.050210, Regularization: 0.000082, Discriminator: 0.021701; Generator: 0.010847,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 20:45:14,349 root         INFO     Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 0.082858\n",
      "Reconstruction: 0.050360, Regularization: 0.000081, Discriminator: 0.021583; Generator: 0.010834,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,416 root         INFO     Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 0.088889\n",
      "Reconstruction: 0.056283, Regularization: 0.000094, Discriminator: 0.021675; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,483 root         INFO     Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 0.084385\n",
      "Reconstruction: 0.051744, Regularization: 0.000083, Discriminator: 0.021718; Generator: 0.010841,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,550 root         INFO     Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 0.086667\n",
      "Reconstruction: 0.054101, Regularization: 0.000087, Discriminator: 0.021646; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,616 root         INFO     Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 0.078159\n",
      "Reconstruction: 0.045601, Regularization: 0.000069, Discriminator: 0.021665; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,683 root         INFO     Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 0.094859\n",
      "Reconstruction: 0.062287, Regularization: 0.000106, Discriminator: 0.021643; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,748 root         INFO     Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 0.086398\n",
      "Reconstruction: 0.053767, Regularization: 0.000088, Discriminator: 0.021706; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,814 root         INFO     ====> Epoch: 94 Average loss: 0.0851\n",
      "2019-04-09 20:45:14,837 root         INFO     Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 0.087174\n",
      "Reconstruction: 0.054571, Regularization: 0.000090, Discriminator: 0.021670; Generator: 0.010843,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,906 root         INFO     Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 0.080850\n",
      "Reconstruction: 0.048258, Regularization: 0.000078, Discriminator: 0.021678; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:14,973 root         INFO     Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 0.085940\n",
      "Reconstruction: 0.053447, Regularization: 0.000090, Discriminator: 0.021568; Generator: 0.010835,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,040 root         INFO     Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 0.087874\n",
      "Reconstruction: 0.055297, Regularization: 0.000092, Discriminator: 0.021642; Generator: 0.010843,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,108 root         INFO     Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 0.082951\n",
      "Reconstruction: 0.050318, Regularization: 0.000082, Discriminator: 0.021708; Generator: 0.010843,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,175 root         INFO     Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 0.087796\n",
      "Reconstruction: 0.055213, Regularization: 0.000094, Discriminator: 0.021661; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,242 root         INFO     Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 0.085797\n",
      "Reconstruction: 0.053200, Regularization: 0.000091, Discriminator: 0.021674; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,311 root         INFO     Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 0.084791\n",
      "Reconstruction: 0.052137, Regularization: 0.000086, Discriminator: 0.021727; Generator: 0.010842,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,380 root         INFO     ====> Epoch: 95 Average loss: 0.0851\n",
      "2019-04-09 20:45:15,404 root         INFO     Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 0.086797\n",
      "Reconstruction: 0.054219, Regularization: 0.000093, Discriminator: 0.021655; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,471 root         INFO     Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 0.076934\n",
      "Reconstruction: 0.044359, Regularization: 0.000069, Discriminator: 0.021676; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,539 root         INFO     Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 0.072369\n",
      "Reconstruction: 0.039852, Regularization: 0.000058, Discriminator: 0.021627; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,607 root         INFO     Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 0.086519\n",
      "Reconstruction: 0.053921, Regularization: 0.000091, Discriminator: 0.021673; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,675 root         INFO     Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 0.082377\n",
      "Reconstruction: 0.049862, Regularization: 0.000084, Discriminator: 0.021604; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,741 root         INFO     Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 0.092025\n",
      "Reconstruction: 0.059519, Regularization: 0.000106, Discriminator: 0.021566; Generator: 0.010833,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,806 root         INFO     Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 0.092384\n",
      "Reconstruction: 0.059859, Regularization: 0.000106, Discriminator: 0.021581; Generator: 0.010838,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,871 root         INFO     Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 0.086302\n",
      "Reconstruction: 0.053764, Regularization: 0.000092, Discriminator: 0.021618; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:15,938 root         INFO     ====> Epoch: 96 Average loss: 0.0850\n",
      "2019-04-09 20:45:15,962 root         INFO     Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 0.078903\n",
      "Reconstruction: 0.046414, Regularization: 0.000075, Discriminator: 0.021578; Generator: 0.010836,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,029 root         INFO     Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 0.079089\n",
      "Reconstruction: 0.046485, Regularization: 0.000074, Discriminator: 0.021697; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,096 root         INFO     Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 0.084244\n",
      "Reconstruction: 0.051650, Regularization: 0.000085, Discriminator: 0.021676; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,163 root         INFO     Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 0.089045\n",
      "Reconstruction: 0.056369, Regularization: 0.000097, Discriminator: 0.021749; Generator: 0.010830,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,230 root         INFO     Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 0.084362\n",
      "Reconstruction: 0.051790, Regularization: 0.000088, Discriminator: 0.021657; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,297 root         INFO     Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 0.093603\n",
      "Reconstruction: 0.060982, Regularization: 0.000108, Discriminator: 0.021679; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,364 root         INFO     Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 0.082530\n",
      "Reconstruction: 0.049949, Regularization: 0.000080, Discriminator: 0.021657; Generator: 0.010845,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,431 root         INFO     Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 0.081147\n",
      "Reconstruction: 0.048548, Regularization: 0.000078, Discriminator: 0.021683; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,499 root         INFO     ====> Epoch: 97 Average loss: 0.0851\n",
      "2019-04-09 20:45:16,523 root         INFO     Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 0.082102\n",
      "Reconstruction: 0.049528, Regularization: 0.000079, Discriminator: 0.021655; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,590 root         INFO     Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 0.086069\n",
      "Reconstruction: 0.053448, Regularization: 0.000090, Discriminator: 0.021700; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,657 root         INFO     Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 0.078528\n",
      "Reconstruction: 0.046014, Regularization: 0.000072, Discriminator: 0.021616; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,724 root         INFO     Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 0.083585\n",
      "Reconstruction: 0.050970, Regularization: 0.000084, Discriminator: 0.021688; Generator: 0.010843,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,789 root         INFO     Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 0.083934\n",
      "Reconstruction: 0.051363, Regularization: 0.000083, Discriminator: 0.021644; Generator: 0.010845,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,854 root         INFO     Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 0.111452\n",
      "Reconstruction: 0.078978, Regularization: 0.000145, Discriminator: 0.021501; Generator: 0.010830,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,918 root         INFO     Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 0.091424\n",
      "Reconstruction: 0.058781, Regularization: 0.000101, Discriminator: 0.021707; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:16,982 root         INFO     Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 0.093671\n",
      "Reconstruction: 0.061157, Regularization: 0.000104, Discriminator: 0.021584; Generator: 0.010827,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,049 root         INFO     ====> Epoch: 98 Average loss: 0.0851\n",
      "2019-04-09 20:45:17,074 root         INFO     Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 0.087839\n",
      "Reconstruction: 0.055278, Regularization: 0.000089, Discriminator: 0.021637; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,140 root         INFO     Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 0.080910\n",
      "Reconstruction: 0.048301, Regularization: 0.000075, Discriminator: 0.021700; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,206 root         INFO     Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 0.082875\n",
      "Reconstruction: 0.050294, Regularization: 0.000082, Discriminator: 0.021669; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,272 root         INFO     Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 0.087913\n",
      "Reconstruction: 0.055289, Regularization: 0.000093, Discriminator: 0.021697; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,338 root         INFO     Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 0.088070\n",
      "Reconstruction: 0.055541, Regularization: 0.000092, Discriminator: 0.021608; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,404 root         INFO     Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 0.079786\n",
      "Reconstruction: 0.047195, Regularization: 0.000075, Discriminator: 0.021678; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,470 root         INFO     Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 0.083386\n",
      "Reconstruction: 0.050870, Regularization: 0.000083, Discriminator: 0.021601; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,536 root         INFO     Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 0.092528\n",
      "Reconstruction: 0.059956, Regularization: 0.000103, Discriminator: 0.021634; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,603 root         INFO     ====> Epoch: 99 Average loss: 0.0851\n",
      "2019-04-09 20:45:17,627 root         INFO     Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 0.086372\n",
      "Reconstruction: 0.053842, Regularization: 0.000090, Discriminator: 0.021605; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,692 root         INFO     Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 0.085913\n",
      "Reconstruction: 0.053345, Regularization: 0.000087, Discriminator: 0.021645; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,758 root         INFO     Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 0.086177\n",
      "Reconstruction: 0.053660, Regularization: 0.000088, Discriminator: 0.021602; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,824 root         INFO     Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 0.085697\n",
      "Reconstruction: 0.053165, Regularization: 0.000088, Discriminator: 0.021609; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,890 root         INFO     Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 0.083756\n",
      "Reconstruction: 0.051232, Regularization: 0.000086, Discriminator: 0.021607; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:17,955 root         INFO     Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 0.076963\n",
      "Reconstruction: 0.044373, Regularization: 0.000071, Discriminator: 0.021685; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,022 root         INFO     Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 0.081526\n",
      "Reconstruction: 0.049003, Regularization: 0.000082, Discriminator: 0.021612; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,087 root         INFO     Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 0.081164\n",
      "Reconstruction: 0.048561, Regularization: 0.000082, Discriminator: 0.021684; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,155 root         INFO     ====> Epoch: 100 Average loss: 0.0851\n",
      "2019-04-09 20:45:18,179 root         INFO     Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 0.088510\n",
      "Reconstruction: 0.055822, Regularization: 0.000100, Discriminator: 0.021752; Generator: 0.010836,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,246 root         INFO     Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 0.082842\n",
      "Reconstruction: 0.050159, Regularization: 0.000088, Discriminator: 0.021768; Generator: 0.010827,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,312 root         INFO     Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 0.079274\n",
      "Reconstruction: 0.046710, Regularization: 0.000077, Discriminator: 0.021662; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,379 root         INFO     Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 0.080977\n",
      "Reconstruction: 0.048425, Regularization: 0.000082, Discriminator: 0.021638; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,445 root         INFO     Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 0.083363\n",
      "Reconstruction: 0.050751, Regularization: 0.000090, Discriminator: 0.021687; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,512 root         INFO     Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 0.092114\n",
      "Reconstruction: 0.059597, Regularization: 0.000111, Discriminator: 0.021573; Generator: 0.010833,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,579 root         INFO     Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 0.079502\n",
      "Reconstruction: 0.046926, Regularization: 0.000079, Discriminator: 0.021663; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,646 root         INFO     Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 0.087532\n",
      "Reconstruction: 0.054980, Regularization: 0.000098, Discriminator: 0.021619; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,715 root         INFO     ====> Epoch: 101 Average loss: 0.0851\n",
      "2019-04-09 20:45:18,739 root         INFO     Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 0.095487\n",
      "Reconstruction: 0.062784, Regularization: 0.000117, Discriminator: 0.021745; Generator: 0.010841,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,807 root         INFO     Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 0.085317\n",
      "Reconstruction: 0.052700, Regularization: 0.000092, Discriminator: 0.021684; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,874 root         INFO     Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 0.087903\n",
      "Reconstruction: 0.055307, Regularization: 0.000099, Discriminator: 0.021669; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:18,940 root         INFO     Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 0.085173\n",
      "Reconstruction: 0.052634, Regularization: 0.000092, Discriminator: 0.021619; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,009 root         INFO     Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 0.083150\n",
      "Reconstruction: 0.050575, Regularization: 0.000087, Discriminator: 0.021654; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,076 root         INFO     Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 0.077226\n",
      "Reconstruction: 0.044660, Regularization: 0.000073, Discriminator: 0.021648; Generator: 0.010845,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,143 root         INFO     Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 0.088038\n",
      "Reconstruction: 0.055476, Regularization: 0.000101, Discriminator: 0.021619; Generator: 0.010842,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,209 root         INFO     Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 0.078873\n",
      "Reconstruction: 0.046274, Regularization: 0.000079, Discriminator: 0.021678; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,277 root         INFO     ====> Epoch: 102 Average loss: 0.0851\n",
      "2019-04-09 20:45:19,301 root         INFO     Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 0.081095\n",
      "Reconstruction: 0.048473, Regularization: 0.000084, Discriminator: 0.021705; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,369 root         INFO     Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 0.074831\n",
      "Reconstruction: 0.042274, Regularization: 0.000068, Discriminator: 0.021654; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,435 root         INFO     Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 0.085753\n",
      "Reconstruction: 0.053223, Regularization: 0.000095, Discriminator: 0.021594; Generator: 0.010841,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,501 root         INFO     Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 0.089931\n",
      "Reconstruction: 0.057307, Regularization: 0.000105, Discriminator: 0.021677; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,564 root         INFO     Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 0.079663\n",
      "Reconstruction: 0.047043, Regularization: 0.000079, Discriminator: 0.021702; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,628 root         INFO     Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 0.078900\n",
      "Reconstruction: 0.046346, Regularization: 0.000075, Discriminator: 0.021655; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,690 root         INFO     Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 0.078663\n",
      "Reconstruction: 0.046152, Regularization: 0.000075, Discriminator: 0.021614; Generator: 0.010823,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,754 root         INFO     Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 0.074072\n",
      "Reconstruction: 0.041528, Regularization: 0.000065, Discriminator: 0.021652; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,821 root         INFO     ====> Epoch: 103 Average loss: 0.0851\n",
      "2019-04-09 20:45:19,845 root         INFO     Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 0.095978\n",
      "Reconstruction: 0.063286, Regularization: 0.000116, Discriminator: 0.021738; Generator: 0.010837,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,912 root         INFO     Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 0.069134\n",
      "Reconstruction: 0.036648, Regularization: 0.000053, Discriminator: 0.021603; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:19,979 root         INFO     Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 0.094028\n",
      "Reconstruction: 0.061385, Regularization: 0.000110, Discriminator: 0.021703; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,045 root         INFO     Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 0.099713\n",
      "Reconstruction: 0.067091, Regularization: 0.000121, Discriminator: 0.021667; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,111 root         INFO     Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 0.090626\n",
      "Reconstruction: 0.058054, Regularization: 0.000101, Discriminator: 0.021630; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,178 root         INFO     Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 0.086210\n",
      "Reconstruction: 0.053650, Regularization: 0.000092, Discriminator: 0.021633; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,243 root         INFO     Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 0.086104\n",
      "Reconstruction: 0.053455, Regularization: 0.000090, Discriminator: 0.021720; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,309 root         INFO     Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 0.077228\n",
      "Reconstruction: 0.044706, Regularization: 0.000069, Discriminator: 0.021619; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,377 root         INFO     ====> Epoch: 104 Average loss: 0.0851\n",
      "2019-04-09 20:45:20,401 root         INFO     Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 0.100302\n",
      "Reconstruction: 0.067810, Regularization: 0.000121, Discriminator: 0.021539; Generator: 0.010833,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,469 root         INFO     Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 0.098546\n",
      "Reconstruction: 0.065934, Regularization: 0.000118, Discriminator: 0.021652; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,537 root         INFO     Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 0.081253\n",
      "Reconstruction: 0.048675, Regularization: 0.000079, Discriminator: 0.021666; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,602 root         INFO     Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 0.097659\n",
      "Reconstruction: 0.064998, Regularization: 0.000117, Discriminator: 0.021705; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,667 root         INFO     Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 0.085005\n",
      "Reconstruction: 0.052383, Regularization: 0.000089, Discriminator: 0.021703; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,733 root         INFO     Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 0.081107\n",
      "Reconstruction: 0.048604, Regularization: 0.000081, Discriminator: 0.021593; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,800 root         INFO     Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 0.075033\n",
      "Reconstruction: 0.042504, Regularization: 0.000067, Discriminator: 0.021624; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,866 root         INFO     Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 0.082625\n",
      "Reconstruction: 0.050021, Regularization: 0.000086, Discriminator: 0.021678; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:20,934 root         INFO     ====> Epoch: 105 Average loss: 0.0851\n",
      "2019-04-09 20:45:20,958 root         INFO     Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 0.080008\n",
      "Reconstruction: 0.047443, Regularization: 0.000078, Discriminator: 0.021653; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,026 root         INFO     Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 0.079161\n",
      "Reconstruction: 0.046574, Regularization: 0.000074, Discriminator: 0.021684; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,094 root         INFO     Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 0.072540\n",
      "Reconstruction: 0.040057, Regularization: 0.000060, Discriminator: 0.021594; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,162 root         INFO     Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 0.094740\n",
      "Reconstruction: 0.062143, Regularization: 0.000111, Discriminator: 0.021651; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,230 root         INFO     Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 0.086203\n",
      "Reconstruction: 0.053588, Regularization: 0.000093, Discriminator: 0.021692; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,297 root         INFO     Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 0.081431\n",
      "Reconstruction: 0.048898, Regularization: 0.000079, Discriminator: 0.021622; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,364 root         INFO     Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 0.077588\n",
      "Reconstruction: 0.045014, Regularization: 0.000070, Discriminator: 0.021664; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,431 root         INFO     Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 0.082461\n",
      "Reconstruction: 0.049813, Regularization: 0.000084, Discriminator: 0.021728; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,500 root         INFO     ====> Epoch: 106 Average loss: 0.0850\n",
      "2019-04-09 20:45:21,524 root         INFO     Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 0.102117\n",
      "Reconstruction: 0.069550, Regularization: 0.000132, Discriminator: 0.021599; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,591 root         INFO     Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 0.085021\n",
      "Reconstruction: 0.052434, Regularization: 0.000090, Discriminator: 0.021655; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,659 root         INFO     Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 0.092662\n",
      "Reconstruction: 0.060048, Regularization: 0.000106, Discriminator: 0.021669; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,726 root         INFO     Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 0.083131\n",
      "Reconstruction: 0.050576, Regularization: 0.000084, Discriminator: 0.021641; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,794 root         INFO     Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 0.082903\n",
      "Reconstruction: 0.050370, Regularization: 0.000081, Discriminator: 0.021615; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,861 root         INFO     Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 0.091002\n",
      "Reconstruction: 0.058335, Regularization: 0.000098, Discriminator: 0.021727; Generator: 0.010841,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,928 root         INFO     Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 0.076079\n",
      "Reconstruction: 0.043595, Regularization: 0.000065, Discriminator: 0.021587; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:21,995 root         INFO     Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 0.088954\n",
      "Reconstruction: 0.056295, Regularization: 0.000092, Discriminator: 0.021732; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,064 root         INFO     ====> Epoch: 107 Average loss: 0.0850\n",
      "2019-04-09 20:45:22,088 root         INFO     Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 0.089514\n",
      "Reconstruction: 0.056908, Regularization: 0.000093, Discriminator: 0.021684; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,155 root         INFO     Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 0.089215\n",
      "Reconstruction: 0.056584, Regularization: 0.000093, Discriminator: 0.021703; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,222 root         INFO     Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 0.092759\n",
      "Reconstruction: 0.060173, Regularization: 0.000102, Discriminator: 0.021651; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,288 root         INFO     Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 0.085531\n",
      "Reconstruction: 0.052929, Regularization: 0.000087, Discriminator: 0.021672; Generator: 0.010843,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,354 root         INFO     Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 0.085883\n",
      "Reconstruction: 0.053317, Regularization: 0.000090, Discriminator: 0.021642; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,420 root         INFO     Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 0.094505\n",
      "Reconstruction: 0.061955, Regularization: 0.000107, Discriminator: 0.021618; Generator: 0.010825,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,486 root         INFO     Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 0.075919\n",
      "Reconstruction: 0.043355, Regularization: 0.000065, Discriminator: 0.021668; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,551 root         INFO     Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 0.082911\n",
      "Reconstruction: 0.050411, Regularization: 0.000080, Discriminator: 0.021590; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,618 root         INFO     ====> Epoch: 108 Average loss: 0.0851\n",
      "2019-04-09 20:45:22,642 root         INFO     Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 0.082855\n",
      "Reconstruction: 0.050299, Regularization: 0.000079, Discriminator: 0.021644; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,710 root         INFO     Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 0.082654\n",
      "Reconstruction: 0.050161, Regularization: 0.000078, Discriminator: 0.021590; Generator: 0.010826,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,778 root         INFO     Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 0.090873\n",
      "Reconstruction: 0.058273, Regularization: 0.000094, Discriminator: 0.021674; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,846 root         INFO     Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 0.080787\n",
      "Reconstruction: 0.048184, Regularization: 0.000072, Discriminator: 0.021690; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,913 root         INFO     Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 0.081249\n",
      "Reconstruction: 0.048759, Regularization: 0.000075, Discriminator: 0.021584; Generator: 0.010830,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:22,980 root         INFO     Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 0.087717\n",
      "Reconstruction: 0.055065, Regularization: 0.000088, Discriminator: 0.021731; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,047 root         INFO     Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 0.090385\n",
      "Reconstruction: 0.057786, Regularization: 0.000094, Discriminator: 0.021672; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,115 root         INFO     Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 0.075868\n",
      "Reconstruction: 0.043294, Regularization: 0.000062, Discriminator: 0.021678; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,183 root         INFO     ====> Epoch: 109 Average loss: 0.0851\n",
      "2019-04-09 20:45:23,207 root         INFO     Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 0.080178\n",
      "Reconstruction: 0.047658, Regularization: 0.000072, Discriminator: 0.021614; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,275 root         INFO     Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 0.093085\n",
      "Reconstruction: 0.060546, Regularization: 0.000098, Discriminator: 0.021613; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,342 root         INFO     Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 0.097787\n",
      "Reconstruction: 0.065187, Regularization: 0.000109, Discriminator: 0.021666; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,410 root         INFO     Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 0.077228\n",
      "Reconstruction: 0.044633, Regularization: 0.000064, Discriminator: 0.021704; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,477 root         INFO     Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 0.076555\n",
      "Reconstruction: 0.044053, Regularization: 0.000063, Discriminator: 0.021605; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,544 root         INFO     Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 0.082795\n",
      "Reconstruction: 0.050265, Regularization: 0.000076, Discriminator: 0.021615; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,611 root         INFO     Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 0.074443\n",
      "Reconstruction: 0.041872, Regularization: 0.000057, Discriminator: 0.021667; Generator: 0.010847,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 20:45:23,679 root         INFO     Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 0.080476\n",
      "Reconstruction: 0.047932, Regularization: 0.000071, Discriminator: 0.021645; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,747 root         INFO     ====> Epoch: 110 Average loss: 0.0851\n",
      "2019-04-09 20:45:23,771 root         INFO     Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 0.086454\n",
      "Reconstruction: 0.053827, Regularization: 0.000084, Discriminator: 0.021705; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,836 root         INFO     Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 0.074254\n",
      "Reconstruction: 0.041698, Regularization: 0.000058, Discriminator: 0.021662; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,903 root         INFO     Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 0.097822\n",
      "Reconstruction: 0.065206, Regularization: 0.000106, Discriminator: 0.021673; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:23,972 root         INFO     Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 0.076932\n",
      "Reconstruction: 0.044401, Regularization: 0.000063, Discriminator: 0.021638; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,042 root         INFO     Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 0.076744\n",
      "Reconstruction: 0.044157, Regularization: 0.000061, Discriminator: 0.021690; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,110 root         INFO     Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 0.096091\n",
      "Reconstruction: 0.063559, Regularization: 0.000100, Discriminator: 0.021601; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,179 root         INFO     Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 0.090498\n",
      "Reconstruction: 0.057971, Regularization: 0.000090, Discriminator: 0.021602; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,248 root         INFO     Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 0.083044\n",
      "Reconstruction: 0.050475, Regularization: 0.000074, Discriminator: 0.021658; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,317 root         INFO     ====> Epoch: 111 Average loss: 0.0851\n",
      "2019-04-09 20:45:24,341 root         INFO     Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 0.073913\n",
      "Reconstruction: 0.041379, Regularization: 0.000056, Discriminator: 0.021639; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,410 root         INFO     Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 0.074738\n",
      "Reconstruction: 0.042192, Regularization: 0.000057, Discriminator: 0.021656; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,477 root         INFO     Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 0.084236\n",
      "Reconstruction: 0.051609, Regularization: 0.000077, Discriminator: 0.021716; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,544 root         INFO     Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 0.082808\n",
      "Reconstruction: 0.050245, Regularization: 0.000077, Discriminator: 0.021648; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,612 root         INFO     Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 0.086438\n",
      "Reconstruction: 0.053953, Regularization: 0.000082, Discriminator: 0.021574; Generator: 0.010828,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,679 root         INFO     Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 0.086997\n",
      "Reconstruction: 0.054436, Regularization: 0.000085, Discriminator: 0.021647; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,747 root         INFO     Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 0.078640\n",
      "Reconstruction: 0.046140, Regularization: 0.000068, Discriminator: 0.021599; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,814 root         INFO     Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 0.093897\n",
      "Reconstruction: 0.061251, Regularization: 0.000099, Discriminator: 0.021714; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,882 root         INFO     ====> Epoch: 112 Average loss: 0.0851\n",
      "2019-04-09 20:45:24,906 root         INFO     Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 0.088386\n",
      "Reconstruction: 0.055833, Regularization: 0.000087, Discriminator: 0.021629; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:24,973 root         INFO     Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 0.092648\n",
      "Reconstruction: 0.060061, Regularization: 0.000095, Discriminator: 0.021648; Generator: 0.010845,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,039 root         INFO     Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 0.094068\n",
      "Reconstruction: 0.061458, Regularization: 0.000101, Discriminator: 0.021663; Generator: 0.010847,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 20:45:25,103 root         INFO     Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 0.088837\n",
      "Reconstruction: 0.056183, Regularization: 0.000091, Discriminator: 0.021721; Generator: 0.010842,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,167 root         INFO     Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 0.083475\n",
      "Reconstruction: 0.050933, Regularization: 0.000079, Discriminator: 0.021629; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,231 root         INFO     Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 0.085300\n",
      "Reconstruction: 0.052791, Regularization: 0.000084, Discriminator: 0.021599; Generator: 0.010826,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,296 root         INFO     Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 0.079659\n",
      "Reconstruction: 0.047014, Regularization: 0.000071, Discriminator: 0.021743; Generator: 0.010831,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,363 root         INFO     Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 0.081897\n",
      "Reconstruction: 0.049325, Regularization: 0.000077, Discriminator: 0.021669; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,432 root         INFO     ====> Epoch: 113 Average loss: 0.0851\n",
      "2019-04-09 20:45:25,456 root         INFO     Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 0.081474\n",
      "Reconstruction: 0.048983, Regularization: 0.000076, Discriminator: 0.021586; Generator: 0.010829,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,525 root         INFO     Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 0.079564\n",
      "Reconstruction: 0.047055, Regularization: 0.000072, Discriminator: 0.021613; Generator: 0.010824,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,592 root         INFO     Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 0.093336\n",
      "Reconstruction: 0.060756, Regularization: 0.000104, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,660 root         INFO     Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 0.104657\n",
      "Reconstruction: 0.072043, Regularization: 0.000129, Discriminator: 0.021660; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,727 root         INFO     Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 0.090203\n",
      "Reconstruction: 0.057650, Regularization: 0.000096, Discriminator: 0.021632; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,793 root         INFO     Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 0.089419\n",
      "Reconstruction: 0.056882, Regularization: 0.000091, Discriminator: 0.021615; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,859 root         INFO     Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 0.089577\n",
      "Reconstruction: 0.057074, Regularization: 0.000093, Discriminator: 0.021575; Generator: 0.010835,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,924 root         INFO     Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 0.084971\n",
      "Reconstruction: 0.052400, Regularization: 0.000082, Discriminator: 0.021648; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:25,992 root         INFO     ====> Epoch: 114 Average loss: 0.0851\n",
      "2019-04-09 20:45:26,016 root         INFO     Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 0.095851\n",
      "Reconstruction: 0.063252, Regularization: 0.000108, Discriminator: 0.021652; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,083 root         INFO     Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 0.073683\n",
      "Reconstruction: 0.041134, Regularization: 0.000061, Discriminator: 0.021645; Generator: 0.010843,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,150 root         INFO     Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 0.091761\n",
      "Reconstruction: 0.059105, Regularization: 0.000097, Discriminator: 0.021720; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,216 root         INFO     Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 0.074420\n",
      "Reconstruction: 0.041830, Regularization: 0.000060, Discriminator: 0.021699; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,282 root         INFO     Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 0.089032\n",
      "Reconstruction: 0.056428, Regularization: 0.000090, Discriminator: 0.021688; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,348 root         INFO     Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 0.093184\n",
      "Reconstruction: 0.060615, Regularization: 0.000102, Discriminator: 0.021635; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,414 root         INFO     Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 0.086328\n",
      "Reconstruction: 0.053767, Regularization: 0.000084, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,480 root         INFO     Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 0.086285\n",
      "Reconstruction: 0.053698, Regularization: 0.000087, Discriminator: 0.021667; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,547 root         INFO     ====> Epoch: 115 Average loss: 0.0851\n",
      "2019-04-09 20:45:26,571 root         INFO     Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 0.084705\n",
      "Reconstruction: 0.052130, Regularization: 0.000084, Discriminator: 0.021654; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,637 root         INFO     Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 0.083999\n",
      "Reconstruction: 0.051447, Regularization: 0.000080, Discriminator: 0.021634; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,703 root         INFO     Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 0.084696\n",
      "Reconstruction: 0.052081, Regularization: 0.000081, Discriminator: 0.021700; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,769 root         INFO     Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 0.104161\n",
      "Reconstruction: 0.071453, Regularization: 0.000122, Discriminator: 0.021753; Generator: 0.010833,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,835 root         INFO     Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 0.082548\n",
      "Reconstruction: 0.049976, Regularization: 0.000074, Discriminator: 0.021678; Generator: 0.010820,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,901 root         INFO     Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 0.089526\n",
      "Reconstruction: 0.056969, Regularization: 0.000091, Discriminator: 0.021639; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:26,967 root         INFO     Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 0.081131\n",
      "Reconstruction: 0.048535, Regularization: 0.000073, Discriminator: 0.021687; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,033 root         INFO     Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 0.075035\n",
      "Reconstruction: 0.042459, Regularization: 0.000062, Discriminator: 0.021677; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,101 root         INFO     ====> Epoch: 116 Average loss: 0.0851\n",
      "2019-04-09 20:45:27,125 root         INFO     Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 0.085593\n",
      "Reconstruction: 0.053015, Regularization: 0.000085, Discriminator: 0.021651; Generator: 0.010843,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,189 root         INFO     Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 0.082401\n",
      "Reconstruction: 0.049796, Regularization: 0.000080, Discriminator: 0.021690; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,253 root         INFO     Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 0.086636\n",
      "Reconstruction: 0.054103, Regularization: 0.000088, Discriminator: 0.021610; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,316 root         INFO     Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 0.087764\n",
      "Reconstruction: 0.055212, Regularization: 0.000092, Discriminator: 0.021621; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,379 root         INFO     Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 0.101278\n",
      "Reconstruction: 0.068712, Regularization: 0.000120, Discriminator: 0.021606; Generator: 0.010841,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,444 root         INFO     Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 0.075344\n",
      "Reconstruction: 0.042819, Regularization: 0.000063, Discriminator: 0.021633; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,510 root         INFO     Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 0.087499\n",
      "Reconstruction: 0.054993, Regularization: 0.000091, Discriminator: 0.021584; Generator: 0.010830,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,576 root         INFO     Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 0.088304\n",
      "Reconstruction: 0.055778, Regularization: 0.000094, Discriminator: 0.021603; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,644 root         INFO     ====> Epoch: 117 Average loss: 0.0851\n",
      "2019-04-09 20:45:27,668 root         INFO     Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 0.076508\n",
      "Reconstruction: 0.043917, Regularization: 0.000065, Discriminator: 0.021690; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,735 root         INFO     Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 0.082556\n",
      "Reconstruction: 0.049989, Regularization: 0.000079, Discriminator: 0.021656; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,801 root         INFO     Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 0.080194\n",
      "Reconstruction: 0.047580, Regularization: 0.000073, Discriminator: 0.021705; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,868 root         INFO     Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 0.079842\n",
      "Reconstruction: 0.047325, Regularization: 0.000072, Discriminator: 0.021615; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:27,935 root         INFO     Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 0.095633\n",
      "Reconstruction: 0.062990, Regularization: 0.000107, Discriminator: 0.021713; Generator: 0.010824,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,003 root         INFO     Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 0.080691\n",
      "Reconstruction: 0.048135, Regularization: 0.000073, Discriminator: 0.021645; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,071 root         INFO     Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 0.080429\n",
      "Reconstruction: 0.047892, Regularization: 0.000074, Discriminator: 0.021627; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,136 root         INFO     Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 0.093963\n",
      "Reconstruction: 0.061417, Regularization: 0.000103, Discriminator: 0.021609; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,204 root         INFO     ====> Epoch: 118 Average loss: 0.0851\n",
      "2019-04-09 20:45:28,228 root         INFO     Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 0.073633\n",
      "Reconstruction: 0.041098, Regularization: 0.000058, Discriminator: 0.021636; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,295 root         INFO     Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 0.092397\n",
      "Reconstruction: 0.059781, Regularization: 0.000099, Discriminator: 0.021688; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,362 root         INFO     Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 0.081177\n",
      "Reconstruction: 0.048583, Regularization: 0.000076, Discriminator: 0.021685; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,429 root         INFO     Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 0.092522\n",
      "Reconstruction: 0.059914, Regularization: 0.000104, Discriminator: 0.021671; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,496 root         INFO     Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 0.083574\n",
      "Reconstruction: 0.050989, Regularization: 0.000085, Discriminator: 0.021668; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,563 root         INFO     Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 0.084156\n",
      "Reconstruction: 0.051458, Regularization: 0.000085, Discriminator: 0.021771; Generator: 0.010842,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,630 root         INFO     Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 0.076971\n",
      "Reconstruction: 0.044455, Regularization: 0.000067, Discriminator: 0.021617; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,695 root         INFO     Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 0.080169\n",
      "Reconstruction: 0.047656, Regularization: 0.000077, Discriminator: 0.021606; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,763 root         INFO     ====> Epoch: 119 Average loss: 0.0851\n",
      "2019-04-09 20:45:28,787 root         INFO     Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 0.085101\n",
      "Reconstruction: 0.052462, Regularization: 0.000088, Discriminator: 0.021710; Generator: 0.010841,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,855 root         INFO     Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 0.086335\n",
      "Reconstruction: 0.053732, Regularization: 0.000092, Discriminator: 0.021670; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,922 root         INFO     Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 0.093781\n",
      "Reconstruction: 0.061180, Regularization: 0.000109, Discriminator: 0.021646; Generator: 0.010845,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:28,988 root         INFO     Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 0.098536\n",
      "Reconstruction: 0.065824, Regularization: 0.000119, Discriminator: 0.021758; Generator: 0.010834,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,055 root         INFO     Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 0.105741\n",
      "Reconstruction: 0.073069, Regularization: 0.000137, Discriminator: 0.021703; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,123 root         INFO     Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 0.085542\n",
      "Reconstruction: 0.052951, Regularization: 0.000091, Discriminator: 0.021669; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,189 root         INFO     Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 0.079086\n",
      "Reconstruction: 0.046574, Regularization: 0.000076, Discriminator: 0.021610; Generator: 0.010825,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,252 root         INFO     Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 0.087194\n",
      "Reconstruction: 0.054611, Regularization: 0.000093, Discriminator: 0.021652; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,317 root         INFO     ====> Epoch: 120 Average loss: 0.0851\n",
      "2019-04-09 20:45:29,341 root         INFO     Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 0.079950\n",
      "Reconstruction: 0.047325, Regularization: 0.000076, Discriminator: 0.021715; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,407 root         INFO     Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 0.077707\n",
      "Reconstruction: 0.045185, Regularization: 0.000071, Discriminator: 0.021622; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,472 root         INFO     Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 0.077219\n",
      "Reconstruction: 0.044660, Regularization: 0.000069, Discriminator: 0.021652; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,537 root         INFO     Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 0.076212\n",
      "Reconstruction: 0.043637, Regularization: 0.000066, Discriminator: 0.021674; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,601 root         INFO     Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 0.082052\n",
      "Reconstruction: 0.049479, Regularization: 0.000081, Discriminator: 0.021662; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,665 root         INFO     Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 0.090452\n",
      "Reconstruction: 0.057856, Regularization: 0.000100, Discriminator: 0.021675; Generator: 0.010820,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,728 root         INFO     Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 0.086473\n",
      "Reconstruction: 0.053854, Regularization: 0.000091, Discriminator: 0.021687; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,792 root         INFO     Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 0.074593\n",
      "Reconstruction: 0.041961, Regularization: 0.000062, Discriminator: 0.021735; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,858 root         INFO     ====> Epoch: 121 Average loss: 0.0851\n",
      "2019-04-09 20:45:29,882 root         INFO     Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 0.077991\n",
      "Reconstruction: 0.045411, Regularization: 0.000070, Discriminator: 0.021668; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:29,948 root         INFO     Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 0.083540\n",
      "Reconstruction: 0.051027, Regularization: 0.000082, Discriminator: 0.021596; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,015 root         INFO     Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 0.085470\n",
      "Reconstruction: 0.052898, Regularization: 0.000085, Discriminator: 0.021645; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,082 root         INFO     Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 0.089385\n",
      "Reconstruction: 0.056871, Regularization: 0.000092, Discriminator: 0.021590; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,148 root         INFO     Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 0.070504\n",
      "Reconstruction: 0.037909, Regularization: 0.000051, Discriminator: 0.021702; Generator: 0.010842,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,215 root         INFO     Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 0.084566\n",
      "Reconstruction: 0.052054, Regularization: 0.000085, Discriminator: 0.021581; Generator: 0.010847,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 20:45:30,282 root         INFO     Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 0.086298\n",
      "Reconstruction: 0.053695, Regularization: 0.000088, Discriminator: 0.021682; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,349 root         INFO     Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 0.077893\n",
      "Reconstruction: 0.045289, Regularization: 0.000067, Discriminator: 0.021711; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,414 root         INFO     ====> Epoch: 122 Average loss: 0.0851\n",
      "2019-04-09 20:45:30,438 root         INFO     Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 0.069855\n",
      "Reconstruction: 0.037364, Regularization: 0.000050, Discriminator: 0.021617; Generator: 0.010825,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,506 root         INFO     Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 0.094588\n",
      "Reconstruction: 0.061997, Regularization: 0.000103, Discriminator: 0.021652; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,572 root         INFO     Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 0.096038\n",
      "Reconstruction: 0.063368, Regularization: 0.000105, Discriminator: 0.021735; Generator: 0.010829,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,639 root         INFO     Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 0.092427\n",
      "Reconstruction: 0.059874, Regularization: 0.000098, Discriminator: 0.021621; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,705 root         INFO     Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 0.077753\n",
      "Reconstruction: 0.045096, Regularization: 0.000068, Discriminator: 0.021742; Generator: 0.010848,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 20:45:30,772 root         INFO     Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 0.081433\n",
      "Reconstruction: 0.048896, Regularization: 0.000075, Discriminator: 0.021628; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,839 root         INFO     Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 0.075769\n",
      "Reconstruction: 0.043229, Regularization: 0.000063, Discriminator: 0.021649; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,905 root         INFO     Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 0.075875\n",
      "Reconstruction: 0.043277, Regularization: 0.000064, Discriminator: 0.021702; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:30,972 root         INFO     ====> Epoch: 123 Average loss: 0.0851\n",
      "2019-04-09 20:45:30,996 root         INFO     Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 0.091336\n",
      "Reconstruction: 0.058684, Regularization: 0.000098, Discriminator: 0.021726; Generator: 0.010828,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,061 root         INFO     Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 0.081767\n",
      "Reconstruction: 0.049187, Regularization: 0.000077, Discriminator: 0.021662; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,125 root         INFO     Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 0.106019\n",
      "Reconstruction: 0.073441, Regularization: 0.000129, Discriminator: 0.021615; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,188 root         INFO     Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 0.085717\n",
      "Reconstruction: 0.053117, Regularization: 0.000085, Discriminator: 0.021682; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,251 root         INFO     Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 0.098606\n",
      "Reconstruction: 0.066000, Regularization: 0.000114, Discriminator: 0.021667; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,315 root         INFO     Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 0.094963\n",
      "Reconstruction: 0.062369, Regularization: 0.000106, Discriminator: 0.021656; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,378 root         INFO     Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 0.078847\n",
      "Reconstruction: 0.046273, Regularization: 0.000071, Discriminator: 0.021665; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,443 root         INFO     Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 0.095151\n",
      "Reconstruction: 0.062558, Regularization: 0.000106, Discriminator: 0.021650; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,510 root         INFO     ====> Epoch: 124 Average loss: 0.0851\n",
      "2019-04-09 20:45:31,534 root         INFO     Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 0.084577\n",
      "Reconstruction: 0.052083, Regularization: 0.000081, Discriminator: 0.021575; Generator: 0.010837,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,602 root         INFO     Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 0.086856\n",
      "Reconstruction: 0.054314, Regularization: 0.000087, Discriminator: 0.021627; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,669 root         INFO     Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 0.098319\n",
      "Reconstruction: 0.065702, Regularization: 0.000110, Discriminator: 0.021672; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,736 root         INFO     Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 0.094921\n",
      "Reconstruction: 0.062346, Regularization: 0.000103, Discriminator: 0.021627; Generator: 0.010845,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,804 root         INFO     Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 0.101759\n",
      "Reconstruction: 0.069231, Regularization: 0.000120, Discriminator: 0.021567; Generator: 0.010841,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,871 root         INFO     Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 0.073297\n",
      "Reconstruction: 0.040740, Regularization: 0.000057, Discriminator: 0.021663; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:31,939 root         INFO     Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 0.101854\n",
      "Reconstruction: 0.069185, Regularization: 0.000116, Discriminator: 0.021722; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,004 root         INFO     Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 0.073807\n",
      "Reconstruction: 0.041285, Regularization: 0.000058, Discriminator: 0.021634; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,071 root         INFO     ====> Epoch: 125 Average loss: 0.0851\n",
      "2019-04-09 20:45:32,095 root         INFO     Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 0.082297\n",
      "Reconstruction: 0.049751, Regularization: 0.000076, Discriminator: 0.021644; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,162 root         INFO     Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 0.088459\n",
      "Reconstruction: 0.055949, Regularization: 0.000088, Discriminator: 0.021587; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,228 root         INFO     Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 0.087263\n",
      "Reconstruction: 0.054670, Regularization: 0.000086, Discriminator: 0.021661; Generator: 0.010847,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 20:45:32,295 root         INFO     Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 0.095133\n",
      "Reconstruction: 0.062531, Regularization: 0.000101, Discriminator: 0.021655; Generator: 0.010846,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 20:45:32,363 root         INFO     Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 0.077142\n",
      "Reconstruction: 0.044491, Regularization: 0.000062, Discriminator: 0.021752; Generator: 0.010837,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,431 root         INFO     Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 0.077453\n",
      "Reconstruction: 0.044850, Regularization: 0.000065, Discriminator: 0.021710; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,500 root         INFO     Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 0.089166\n",
      "Reconstruction: 0.056628, Regularization: 0.000090, Discriminator: 0.021628; Generator: 0.010819,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,569 root         INFO     Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 0.081687\n",
      "Reconstruction: 0.049150, Regularization: 0.000076, Discriminator: 0.021639; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,638 root         INFO     ====> Epoch: 126 Average loss: 0.0850\n",
      "2019-04-09 20:45:32,662 root         INFO     Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 0.082782\n",
      "Reconstruction: 0.050212, Regularization: 0.000077, Discriminator: 0.021658; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,730 root         INFO     Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 0.078655\n",
      "Reconstruction: 0.046062, Regularization: 0.000066, Discriminator: 0.021691; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,797 root         INFO     Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 0.086058\n",
      "Reconstruction: 0.053472, Regularization: 0.000080, Discriminator: 0.021670; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,863 root         INFO     Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 0.092481\n",
      "Reconstruction: 0.059877, Regularization: 0.000092, Discriminator: 0.021681; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,927 root         INFO     Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 0.074828\n",
      "Reconstruction: 0.042314, Regularization: 0.000057, Discriminator: 0.021628; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:32,994 root         INFO     Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 0.072543\n",
      "Reconstruction: 0.039947, Regularization: 0.000051, Discriminator: 0.021710; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,061 root         INFO     Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 0.084393\n",
      "Reconstruction: 0.051813, Regularization: 0.000076, Discriminator: 0.021670; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,126 root         INFO     Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 0.097719\n",
      "Reconstruction: 0.065156, Regularization: 0.000104, Discriminator: 0.021626; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,193 root         INFO     ====> Epoch: 127 Average loss: 0.0851\n",
      "2019-04-09 20:45:33,218 root         INFO     Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 0.085411\n",
      "Reconstruction: 0.052873, Regularization: 0.000081, Discriminator: 0.021625; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,285 root         INFO     Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 0.098766\n",
      "Reconstruction: 0.066137, Regularization: 0.000106, Discriminator: 0.021685; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,351 root         INFO     Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 0.079742\n",
      "Reconstruction: 0.047219, Regularization: 0.000068, Discriminator: 0.021627; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,416 root         INFO     Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 0.076771\n",
      "Reconstruction: 0.044289, Regularization: 0.000061, Discriminator: 0.021587; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,483 root         INFO     Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 0.082289\n",
      "Reconstruction: 0.049727, Regularization: 0.000070, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,548 root         INFO     Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 0.083444\n",
      "Reconstruction: 0.050907, Regularization: 0.000074, Discriminator: 0.021635; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,614 root         INFO     Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 0.090057\n",
      "Reconstruction: 0.057529, Regularization: 0.000086, Discriminator: 0.021607; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,681 root         INFO     Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 0.073669\n",
      "Reconstruction: 0.041066, Regularization: 0.000053, Discriminator: 0.021713; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,749 root         INFO     ====> Epoch: 128 Average loss: 0.0851\n",
      "2019-04-09 20:45:33,773 root         INFO     Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 0.084000\n",
      "Reconstruction: 0.051442, Regularization: 0.000073, Discriminator: 0.021650; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,841 root         INFO     Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 0.082122\n",
      "Reconstruction: 0.049511, Regularization: 0.000068, Discriminator: 0.021714; Generator: 0.010829,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,908 root         INFO     Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 0.081771\n",
      "Reconstruction: 0.049232, Regularization: 0.000071, Discriminator: 0.021635; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:33,975 root         INFO     Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 0.080350\n",
      "Reconstruction: 0.047825, Regularization: 0.000068, Discriminator: 0.021620; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,041 root         INFO     Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 0.074696\n",
      "Reconstruction: 0.042149, Regularization: 0.000056, Discriminator: 0.021660; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,108 root         INFO     Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 0.093945\n",
      "Reconstruction: 0.061406, Regularization: 0.000098, Discriminator: 0.021617; Generator: 0.010824,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,175 root         INFO     Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 0.086316\n",
      "Reconstruction: 0.053766, Regularization: 0.000080, Discriminator: 0.021633; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,242 root         INFO     Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 0.084218\n",
      "Reconstruction: 0.051684, Regularization: 0.000074, Discriminator: 0.021611; Generator: 0.010849,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 20:45:34,310 root         INFO     ====> Epoch: 129 Average loss: 0.0851\n",
      "2019-04-09 20:45:34,333 root         INFO     Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 0.083186\n",
      "Reconstruction: 0.050620, Regularization: 0.000072, Discriminator: 0.021659; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,400 root         INFO     Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 0.085193\n",
      "Reconstruction: 0.052613, Regularization: 0.000074, Discriminator: 0.021678; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,466 root         INFO     Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 0.095453\n",
      "Reconstruction: 0.062895, Regularization: 0.000093, Discriminator: 0.021625; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,532 root         INFO     Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 0.086832\n",
      "Reconstruction: 0.054238, Regularization: 0.000077, Discriminator: 0.021679; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,598 root         INFO     Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 0.092979\n",
      "Reconstruction: 0.060440, Regularization: 0.000091, Discriminator: 0.021617; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,664 root         INFO     Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 0.093424\n",
      "Reconstruction: 0.060806, Regularization: 0.000090, Discriminator: 0.021695; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,730 root         INFO     Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 0.081397\n",
      "Reconstruction: 0.048854, Regularization: 0.000068, Discriminator: 0.021645; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,796 root         INFO     Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 0.090584\n",
      "Reconstruction: 0.058019, Regularization: 0.000084, Discriminator: 0.021642; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,863 root         INFO     ====> Epoch: 130 Average loss: 0.0851\n",
      "2019-04-09 20:45:34,887 root         INFO     Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 0.086498\n",
      "Reconstruction: 0.053882, Regularization: 0.000076, Discriminator: 0.021705; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:34,950 root         INFO     Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 0.085597\n",
      "Reconstruction: 0.053031, Regularization: 0.000076, Discriminator: 0.021658; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,013 root         INFO     Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 0.085637\n",
      "Reconstruction: 0.053111, Regularization: 0.000075, Discriminator: 0.021621; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,076 root         INFO     Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 0.075163\n",
      "Reconstruction: 0.042623, Regularization: 0.000055, Discriminator: 0.021640; Generator: 0.010844,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,139 root         INFO     Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 0.078670\n",
      "Reconstruction: 0.046203, Regularization: 0.000061, Discriminator: 0.021569; Generator: 0.010837,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,202 root         INFO     Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 0.090987\n",
      "Reconstruction: 0.058391, Regularization: 0.000088, Discriminator: 0.021680; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,265 root         INFO     Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 0.080301\n",
      "Reconstruction: 0.047715, Regularization: 0.000067, Discriminator: 0.021688; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,328 root         INFO     Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 0.091659\n",
      "Reconstruction: 0.059068, Regularization: 0.000089, Discriminator: 0.021665; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,393 root         INFO     ====> Epoch: 131 Average loss: 0.0851\n",
      "2019-04-09 20:45:35,417 root         INFO     Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 0.089607\n",
      "Reconstruction: 0.057044, Regularization: 0.000085, Discriminator: 0.021645; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,483 root         INFO     Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 0.084208\n",
      "Reconstruction: 0.051581, Regularization: 0.000073, Discriminator: 0.021716; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,549 root         INFO     Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 0.080508\n",
      "Reconstruction: 0.047972, Regularization: 0.000066, Discriminator: 0.021637; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,615 root         INFO     Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 0.076197\n",
      "Reconstruction: 0.043629, Regularization: 0.000057, Discriminator: 0.021681; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,681 root         INFO     Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 0.081815\n",
      "Reconstruction: 0.049262, Regularization: 0.000070, Discriminator: 0.021658; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,748 root         INFO     Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 0.079610\n",
      "Reconstruction: 0.047088, Regularization: 0.000066, Discriminator: 0.021632; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,815 root         INFO     Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 0.092103\n",
      "Reconstruction: 0.059400, Regularization: 0.000091, Discriminator: 0.021775; Generator: 0.010837,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,880 root         INFO     Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 0.090378\n",
      "Reconstruction: 0.057781, Regularization: 0.000090, Discriminator: 0.021672; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:35,947 root         INFO     ====> Epoch: 132 Average loss: 0.0851\n",
      "2019-04-09 20:45:35,971 root         INFO     Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 0.078635\n",
      "Reconstruction: 0.046023, Regularization: 0.000065, Discriminator: 0.021707; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,035 root         INFO     Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 0.075107\n",
      "Reconstruction: 0.042587, Regularization: 0.000058, Discriminator: 0.021630; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,098 root         INFO     Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 0.095960\n",
      "Reconstruction: 0.063384, Regularization: 0.000102, Discriminator: 0.021641; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,161 root         INFO     Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 0.088319\n",
      "Reconstruction: 0.055717, Regularization: 0.000084, Discriminator: 0.021685; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,224 root         INFO     Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 0.076738\n",
      "Reconstruction: 0.044201, Regularization: 0.000061, Discriminator: 0.021638; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,286 root         INFO     Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 0.082278\n",
      "Reconstruction: 0.049806, Regularization: 0.000071, Discriminator: 0.021571; Generator: 0.010830,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,349 root         INFO     Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 0.090979\n",
      "Reconstruction: 0.058498, Regularization: 0.000090, Discriminator: 0.021563; Generator: 0.010827,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,412 root         INFO     Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 0.081215\n",
      "Reconstruction: 0.048601, Regularization: 0.000071, Discriminator: 0.021701; Generator: 0.010842,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,478 root         INFO     ====> Epoch: 133 Average loss: 0.0851\n",
      "2019-04-09 20:45:36,502 root         INFO     Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 0.078019\n",
      "Reconstruction: 0.045453, Regularization: 0.000062, Discriminator: 0.021667; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,565 root         INFO     Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 0.090460\n",
      "Reconstruction: 0.057837, Regularization: 0.000089, Discriminator: 0.021694; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,628 root         INFO     Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 0.084862\n",
      "Reconstruction: 0.052281, Regularization: 0.000078, Discriminator: 0.021669; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,691 root         INFO     Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 0.087005\n",
      "Reconstruction: 0.054484, Regularization: 0.000082, Discriminator: 0.021601; Generator: 0.010838,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,753 root         INFO     Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 0.090878\n",
      "Reconstruction: 0.058303, Regularization: 0.000087, Discriminator: 0.021658; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,816 root         INFO     Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 0.090921\n",
      "Reconstruction: 0.058337, Regularization: 0.000087, Discriminator: 0.021663; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,879 root         INFO     Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 0.081256\n",
      "Reconstruction: 0.048629, Regularization: 0.000068, Discriminator: 0.021725; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:36,942 root         INFO     Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 0.086964\n",
      "Reconstruction: 0.054468, Regularization: 0.000077, Discriminator: 0.021587; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,007 root         INFO     ====> Epoch: 134 Average loss: 0.0851\n",
      "2019-04-09 20:45:37,031 root         INFO     Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 0.084676\n",
      "Reconstruction: 0.052080, Regularization: 0.000071, Discriminator: 0.021686; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,097 root         INFO     Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 0.091805\n",
      "Reconstruction: 0.059183, Regularization: 0.000088, Discriminator: 0.021706; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,163 root         INFO     Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 0.091840\n",
      "Reconstruction: 0.059214, Regularization: 0.000085, Discriminator: 0.021702; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,226 root         INFO     Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 0.083093\n",
      "Reconstruction: 0.050451, Regularization: 0.000068, Discriminator: 0.021739; Generator: 0.010834,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,288 root         INFO     Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 0.080511\n",
      "Reconstruction: 0.047931, Regularization: 0.000061, Discriminator: 0.021687; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,351 root         INFO     Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 0.087687\n",
      "Reconstruction: 0.055185, Regularization: 0.000073, Discriminator: 0.021598; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,414 root         INFO     Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 0.083614\n",
      "Reconstruction: 0.050983, Regularization: 0.000067, Discriminator: 0.021718; Generator: 0.010847,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 20:45:37,477 root         INFO     Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 0.086037\n",
      "Reconstruction: 0.053530, Regularization: 0.000074, Discriminator: 0.021599; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,541 root         INFO     ====> Epoch: 135 Average loss: 0.0851\n",
      "2019-04-09 20:45:37,565 root         INFO     Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 0.084930\n",
      "Reconstruction: 0.052398, Regularization: 0.000071, Discriminator: 0.021626; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,629 root         INFO     Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 0.083961\n",
      "Reconstruction: 0.051438, Regularization: 0.000067, Discriminator: 0.021617; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,692 root         INFO     Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 0.082394\n",
      "Reconstruction: 0.049893, Regularization: 0.000063, Discriminator: 0.021605; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,756 root         INFO     Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 0.093949\n",
      "Reconstruction: 0.061341, Regularization: 0.000086, Discriminator: 0.021683; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,820 root         INFO     Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 0.092111\n",
      "Reconstruction: 0.059622, Regularization: 0.000084, Discriminator: 0.021572; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,883 root         INFO     Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 0.081860\n",
      "Reconstruction: 0.049336, Regularization: 0.000065, Discriminator: 0.021627; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:37,947 root         INFO     Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 0.084752\n",
      "Reconstruction: 0.052210, Regularization: 0.000070, Discriminator: 0.021639; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,011 root         INFO     Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 0.088378\n",
      "Reconstruction: 0.055785, Regularization: 0.000078, Discriminator: 0.021688; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,077 root         INFO     ====> Epoch: 136 Average loss: 0.0851\n",
      "2019-04-09 20:45:38,100 root         INFO     Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 0.089271\n",
      "Reconstruction: 0.056665, Regularization: 0.000078, Discriminator: 0.021697; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,167 root         INFO     Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 0.091188\n",
      "Reconstruction: 0.058604, Regularization: 0.000082, Discriminator: 0.021667; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,234 root         INFO     Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 0.086015\n",
      "Reconstruction: 0.053523, Regularization: 0.000072, Discriminator: 0.021576; Generator: 0.010844,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,300 root         INFO     Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 0.075211\n",
      "Reconstruction: 0.042712, Regularization: 0.000052, Discriminator: 0.021609; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,366 root         INFO     Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 0.088593\n",
      "Reconstruction: 0.056021, Regularization: 0.000076, Discriminator: 0.021662; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,432 root         INFO     Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 0.085937\n",
      "Reconstruction: 0.053404, Regularization: 0.000072, Discriminator: 0.021626; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,498 root         INFO     Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 0.091498\n",
      "Reconstruction: 0.058997, Regularization: 0.000082, Discriminator: 0.021582; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,564 root         INFO     Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 0.071646\n",
      "Reconstruction: 0.039085, Regularization: 0.000047, Discriminator: 0.021686; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,630 root         INFO     ====> Epoch: 137 Average loss: 0.0851\n",
      "2019-04-09 20:45:38,654 root         INFO     Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 0.086916\n",
      "Reconstruction: 0.054351, Regularization: 0.000074, Discriminator: 0.021667; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,720 root         INFO     Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 0.089448\n",
      "Reconstruction: 0.056934, Regularization: 0.000079, Discriminator: 0.021603; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,786 root         INFO     Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 0.090838\n",
      "Reconstruction: 0.058299, Regularization: 0.000082, Discriminator: 0.021622; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,852 root         INFO     Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 0.077320\n",
      "Reconstruction: 0.044786, Regularization: 0.000055, Discriminator: 0.021645; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,917 root         INFO     Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 0.088510\n",
      "Reconstruction: 0.055884, Regularization: 0.000074, Discriminator: 0.021721; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:38,982 root         INFO     Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 0.089837\n",
      "Reconstruction: 0.057233, Regularization: 0.000077, Discriminator: 0.021694; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,048 root         INFO     Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 0.096140\n",
      "Reconstruction: 0.063614, Regularization: 0.000087, Discriminator: 0.021606; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,113 root         INFO     Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 0.086006\n",
      "Reconstruction: 0.053502, Regularization: 0.000069, Discriminator: 0.021607; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,181 root         INFO     ====> Epoch: 138 Average loss: 0.0851\n",
      "2019-04-09 20:45:39,205 root         INFO     Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 0.088465\n",
      "Reconstruction: 0.055901, Regularization: 0.000072, Discriminator: 0.021656; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,271 root         INFO     Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 0.087874\n",
      "Reconstruction: 0.055288, Regularization: 0.000072, Discriminator: 0.021674; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,337 root         INFO     Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 0.081369\n",
      "Reconstruction: 0.048773, Regularization: 0.000060, Discriminator: 0.021693; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,403 root         INFO     Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 0.087824\n",
      "Reconstruction: 0.055311, Regularization: 0.000072, Discriminator: 0.021615; Generator: 0.010826,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,469 root         INFO     Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 0.080921\n",
      "Reconstruction: 0.048368, Regularization: 0.000060, Discriminator: 0.021651; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,535 root         INFO     Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 0.082827\n",
      "Reconstruction: 0.050327, Regularization: 0.000063, Discriminator: 0.021598; Generator: 0.010839,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,601 root         INFO     Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 0.088900\n",
      "Reconstruction: 0.056330, Regularization: 0.000076, Discriminator: 0.021665; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,667 root         INFO     Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 0.089702\n",
      "Reconstruction: 0.057039, Regularization: 0.000076, Discriminator: 0.021749; Generator: 0.010837,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,734 root         INFO     ====> Epoch: 139 Average loss: 0.0851\n",
      "2019-04-09 20:45:39,758 root         INFO     Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 0.081338\n",
      "Reconstruction: 0.048776, Regularization: 0.000060, Discriminator: 0.021680; Generator: 0.010823,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,824 root         INFO     Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 0.083556\n",
      "Reconstruction: 0.051030, Regularization: 0.000063, Discriminator: 0.021636; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,890 root         INFO     Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 0.082323\n",
      "Reconstruction: 0.049825, Regularization: 0.000061, Discriminator: 0.021604; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:39,956 root         INFO     Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 0.073824\n",
      "Reconstruction: 0.041230, Regularization: 0.000046, Discriminator: 0.021712; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,020 root         INFO     Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 0.083775\n",
      "Reconstruction: 0.051255, Regularization: 0.000063, Discriminator: 0.021631; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,084 root         INFO     Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 0.093313\n",
      "Reconstruction: 0.060731, Regularization: 0.000081, Discriminator: 0.021673; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,148 root         INFO     Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 0.084462\n",
      "Reconstruction: 0.051890, Regularization: 0.000064, Discriminator: 0.021681; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,212 root         INFO     Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 0.085756\n",
      "Reconstruction: 0.053218, Regularization: 0.000067, Discriminator: 0.021632; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,277 root         INFO     ====> Epoch: 140 Average loss: 0.0851\n",
      "2019-04-09 20:45:40,301 root         INFO     Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 0.088794\n",
      "Reconstruction: 0.056261, Regularization: 0.000072, Discriminator: 0.021622; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,368 root         INFO     Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 0.089567\n",
      "Reconstruction: 0.057023, Regularization: 0.000076, Discriminator: 0.021629; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,434 root         INFO     Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 0.081022\n",
      "Reconstruction: 0.048440, Regularization: 0.000063, Discriminator: 0.021688; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,500 root         INFO     Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 0.078848\n",
      "Reconstruction: 0.046271, Regularization: 0.000059, Discriminator: 0.021688; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,566 root         INFO     Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 0.084716\n",
      "Reconstruction: 0.052225, Regularization: 0.000070, Discriminator: 0.021591; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,632 root         INFO     Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 0.086632\n",
      "Reconstruction: 0.054067, Regularization: 0.000076, Discriminator: 0.021652; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,697 root         INFO     Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 0.084886\n",
      "Reconstruction: 0.052353, Regularization: 0.000073, Discriminator: 0.021622; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,763 root         INFO     Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 0.092137\n",
      "Reconstruction: 0.059527, Regularization: 0.000088, Discriminator: 0.021676; Generator: 0.010846,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,831 root         INFO     ====> Epoch: 141 Average loss: 0.0851\n",
      "2019-04-09 20:45:40,855 root         INFO     Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 0.089693\n",
      "Reconstruction: 0.057206, Regularization: 0.000084, Discriminator: 0.021571; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,925 root         INFO     Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 0.091422\n",
      "Reconstruction: 0.058854, Regularization: 0.000086, Discriminator: 0.021655; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:40,994 root         INFO     Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 0.086730\n",
      "Reconstruction: 0.054155, Regularization: 0.000078, Discriminator: 0.021664; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,063 root         INFO     Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 0.089171\n",
      "Reconstruction: 0.056565, Regularization: 0.000079, Discriminator: 0.021686; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,131 root         INFO     Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 0.086195\n",
      "Reconstruction: 0.053668, Regularization: 0.000072, Discriminator: 0.021615; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,200 root         INFO     Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 0.094986\n",
      "Reconstruction: 0.062417, Regularization: 0.000087, Discriminator: 0.021644; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,268 root         INFO     Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 0.107449\n",
      "Reconstruction: 0.074806, Regularization: 0.000106, Discriminator: 0.021706; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,336 root         INFO     Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 0.086526\n",
      "Reconstruction: 0.053960, Regularization: 0.000069, Discriminator: 0.021667; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,405 root         INFO     ====> Epoch: 142 Average loss: 0.0851\n",
      "2019-04-09 20:45:41,429 root         INFO     Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 0.093319\n",
      "Reconstruction: 0.060699, Regularization: 0.000084, Discriminator: 0.021704; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,497 root         INFO     Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 0.084797\n",
      "Reconstruction: 0.052166, Regularization: 0.000065, Discriminator: 0.021728; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,563 root         INFO     Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 0.091083\n",
      "Reconstruction: 0.058552, Regularization: 0.000076, Discriminator: 0.021629; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,629 root         INFO     Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 0.099203\n",
      "Reconstruction: 0.066727, Regularization: 0.000090, Discriminator: 0.021559; Generator: 0.010827,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,695 root         INFO     Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 0.081298\n",
      "Reconstruction: 0.048761, Regularization: 0.000060, Discriminator: 0.021639; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,762 root         INFO     Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 0.100148\n",
      "Reconstruction: 0.067587, Regularization: 0.000091, Discriminator: 0.021633; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,828 root         INFO     Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 0.079490\n",
      "Reconstruction: 0.046917, Regularization: 0.000054, Discriminator: 0.021676; Generator: 0.010843,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,894 root         INFO     Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 0.099575\n",
      "Reconstruction: 0.066945, Regularization: 0.000086, Discriminator: 0.021709; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:41,962 root         INFO     ====> Epoch: 143 Average loss: 0.0851\n",
      "2019-04-09 20:45:41,986 root         INFO     Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 0.102805\n",
      "Reconstruction: 0.070157, Regularization: 0.000092, Discriminator: 0.021726; Generator: 0.010829,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,054 root         INFO     Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 0.091351\n",
      "Reconstruction: 0.058725, Regularization: 0.000073, Discriminator: 0.021727; Generator: 0.010826,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,121 root         INFO     Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 0.098432\n",
      "Reconstruction: 0.065869, Regularization: 0.000087, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,187 root         INFO     Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 0.081161\n",
      "Reconstruction: 0.048637, Regularization: 0.000059, Discriminator: 0.021636; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,253 root         INFO     Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 0.083978\n",
      "Reconstruction: 0.051457, Regularization: 0.000066, Discriminator: 0.021637; Generator: 0.010819,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,318 root         INFO     Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 0.086992\n",
      "Reconstruction: 0.054466, Regularization: 0.000071, Discriminator: 0.021623; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,383 root         INFO     Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 0.077517\n",
      "Reconstruction: 0.044910, Regularization: 0.000054, Discriminator: 0.021714; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,449 root         INFO     Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 0.078171\n",
      "Reconstruction: 0.045657, Regularization: 0.000057, Discriminator: 0.021622; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,516 root         INFO     ====> Epoch: 144 Average loss: 0.0851\n",
      "2019-04-09 20:45:42,540 root         INFO     Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 0.078332\n",
      "Reconstruction: 0.045863, Regularization: 0.000056, Discriminator: 0.021571; Generator: 0.010842,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,609 root         INFO     Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 0.095756\n",
      "Reconstruction: 0.063256, Regularization: 0.000087, Discriminator: 0.021573; Generator: 0.010841,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,677 root         INFO     Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 0.082271\n",
      "Reconstruction: 0.049636, Regularization: 0.000060, Discriminator: 0.021733; Generator: 0.010843,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,746 root         INFO     Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 0.083599\n",
      "Reconstruction: 0.051130, Regularization: 0.000062, Discriminator: 0.021585; Generator: 0.010822,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,815 root         INFO     Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 0.080787\n",
      "Reconstruction: 0.048260, Regularization: 0.000056, Discriminator: 0.021640; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,884 root         INFO     Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 0.082378\n",
      "Reconstruction: 0.049832, Regularization: 0.000058, Discriminator: 0.021649; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:42,953 root         INFO     Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 0.077569\n",
      "Reconstruction: 0.044956, Regularization: 0.000050, Discriminator: 0.021719; Generator: 0.010844,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,022 root         INFO     Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 0.084742\n",
      "Reconstruction: 0.052181, Regularization: 0.000060, Discriminator: 0.021668; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,093 root         INFO     ====> Epoch: 145 Average loss: 0.0851\n",
      "2019-04-09 20:45:43,117 root         INFO     Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 0.079638\n",
      "Reconstruction: 0.047150, Regularization: 0.000052, Discriminator: 0.021610; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,183 root         INFO     Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 0.087664\n",
      "Reconstruction: 0.055122, Regularization: 0.000066, Discriminator: 0.021645; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,248 root         INFO     Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 0.083175\n",
      "Reconstruction: 0.050665, Regularization: 0.000061, Discriminator: 0.021626; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,312 root         INFO     Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 0.096120\n",
      "Reconstruction: 0.063596, Regularization: 0.000079, Discriminator: 0.021619; Generator: 0.010826,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,376 root         INFO     Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 0.084488\n",
      "Reconstruction: 0.051980, Regularization: 0.000062, Discriminator: 0.021618; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,440 root         INFO     Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 0.089985\n",
      "Reconstruction: 0.057497, Regularization: 0.000071, Discriminator: 0.021577; Generator: 0.010840,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,506 root         INFO     Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 0.081336\n",
      "Reconstruction: 0.048743, Regularization: 0.000057, Discriminator: 0.021698; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,570 root         INFO     Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 0.083799\n",
      "Reconstruction: 0.051212, Regularization: 0.000062, Discriminator: 0.021691; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,636 root         INFO     ====> Epoch: 146 Average loss: 0.0851\n",
      "2019-04-09 20:45:43,660 root         INFO     Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 0.080441\n",
      "Reconstruction: 0.047885, Regularization: 0.000056, Discriminator: 0.021663; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,727 root         INFO     Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 0.083600\n",
      "Reconstruction: 0.051090, Regularization: 0.000062, Discriminator: 0.021611; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,795 root         INFO     Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 0.090637\n",
      "Reconstruction: 0.058030, Regularization: 0.000076, Discriminator: 0.021693; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,862 root         INFO     Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 0.084506\n",
      "Reconstruction: 0.051987, Regularization: 0.000067, Discriminator: 0.021620; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,928 root         INFO     Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 0.089587\n",
      "Reconstruction: 0.057047, Regularization: 0.000075, Discriminator: 0.021637; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:43,995 root         INFO     Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 0.085419\n",
      "Reconstruction: 0.052809, Regularization: 0.000067, Discriminator: 0.021705; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,060 root         INFO     Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 0.085463\n",
      "Reconstruction: 0.052939, Regularization: 0.000066, Discriminator: 0.021620; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,124 root         INFO     Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 0.080671\n",
      "Reconstruction: 0.048157, Regularization: 0.000058, Discriminator: 0.021623; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,190 root         INFO     ====> Epoch: 147 Average loss: 0.0851\n",
      "2019-04-09 20:45:44,214 root         INFO     Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 0.082174\n",
      "Reconstruction: 0.049589, Regularization: 0.000062, Discriminator: 0.021686; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,280 root         INFO     Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 0.086347\n",
      "Reconstruction: 0.053795, Regularization: 0.000071, Discriminator: 0.021647; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,346 root         INFO     Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 0.080921\n",
      "Reconstruction: 0.048431, Regularization: 0.000060, Discriminator: 0.021586; Generator: 0.010844,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,412 root         INFO     Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 0.083506\n",
      "Reconstruction: 0.050984, Regularization: 0.000063, Discriminator: 0.021618; Generator: 0.010842,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,478 root         INFO     Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 0.092887\n",
      "Reconstruction: 0.060394, Regularization: 0.000080, Discriminator: 0.021581; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,543 root         INFO     Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 0.082787\n",
      "Reconstruction: 0.050218, Regularization: 0.000060, Discriminator: 0.021690; Generator: 0.010819,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,609 root         INFO     Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 0.083204\n",
      "Reconstruction: 0.050678, Regularization: 0.000059, Discriminator: 0.021641; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,674 root         INFO     Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 0.077842\n",
      "Reconstruction: 0.045269, Regularization: 0.000049, Discriminator: 0.021684; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,741 root         INFO     ====> Epoch: 148 Average loss: 0.0851\n",
      "2019-04-09 20:45:44,765 root         INFO     Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 0.083607\n",
      "Reconstruction: 0.051102, Regularization: 0.000060, Discriminator: 0.021604; Generator: 0.010841,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,832 root         INFO     Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 0.080099\n",
      "Reconstruction: 0.047536, Regularization: 0.000056, Discriminator: 0.021667; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,899 root         INFO     Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 0.088959\n",
      "Reconstruction: 0.056313, Regularization: 0.000069, Discriminator: 0.021735; Generator: 0.010842,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:44,966 root         INFO     Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 0.084656\n",
      "Reconstruction: 0.052072, Regularization: 0.000063, Discriminator: 0.021680; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,033 root         INFO     Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 0.089372\n",
      "Reconstruction: 0.056891, Regularization: 0.000071, Discriminator: 0.021571; Generator: 0.010838,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,100 root         INFO     Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 0.083990\n",
      "Reconstruction: 0.051472, Regularization: 0.000061, Discriminator: 0.021618; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,167 root         INFO     Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 0.075353\n",
      "Reconstruction: 0.042840, Regularization: 0.000047, Discriminator: 0.021629; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,234 root         INFO     Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 0.087149\n",
      "Reconstruction: 0.054581, Regularization: 0.000063, Discriminator: 0.021674; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,302 root         INFO     ====> Epoch: 149 Average loss: 0.0851\n",
      "2019-04-09 20:45:45,326 root         INFO     Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 0.082459\n",
      "Reconstruction: 0.049915, Regularization: 0.000055, Discriminator: 0.021670; Generator: 0.010819,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,392 root         INFO     Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 0.088249\n",
      "Reconstruction: 0.055736, Regularization: 0.000062, Discriminator: 0.021625; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,459 root         INFO     Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 0.087579\n",
      "Reconstruction: 0.055028, Regularization: 0.000060, Discriminator: 0.021650; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,525 root         INFO     Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 0.082958\n",
      "Reconstruction: 0.050408, Regularization: 0.000052, Discriminator: 0.021669; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,590 root         INFO     Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 0.088293\n",
      "Reconstruction: 0.055763, Regularization: 0.000061, Discriminator: 0.021631; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,655 root         INFO     Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 0.089823\n",
      "Reconstruction: 0.057304, Regularization: 0.000062, Discriminator: 0.021623; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,719 root         INFO     Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 0.086680\n",
      "Reconstruction: 0.054148, Regularization: 0.000056, Discriminator: 0.021638; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,783 root         INFO     Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 0.081719\n",
      "Reconstruction: 0.049164, Regularization: 0.000050, Discriminator: 0.021678; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,849 root         INFO     ====> Epoch: 150 Average loss: 0.0851\n",
      "2019-04-09 20:45:45,873 root         INFO     Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 0.088640\n",
      "Reconstruction: 0.056102, Regularization: 0.000061, Discriminator: 0.021651; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:45,939 root         INFO     Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 0.096122\n",
      "Reconstruction: 0.063492, Regularization: 0.000073, Discriminator: 0.021724; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,005 root         INFO     Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 0.082953\n",
      "Reconstruction: 0.050412, Regularization: 0.000054, Discriminator: 0.021659; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,071 root         INFO     Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 0.083469\n",
      "Reconstruction: 0.050945, Regularization: 0.000055, Discriminator: 0.021634; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,137 root         INFO     Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 0.085885\n",
      "Reconstruction: 0.053350, Regularization: 0.000060, Discriminator: 0.021640; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,204 root         INFO     Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 0.084439\n",
      "Reconstruction: 0.051983, Regularization: 0.000058, Discriminator: 0.021566; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,270 root         INFO     Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 0.083044\n",
      "Reconstruction: 0.050401, Regularization: 0.000059, Discriminator: 0.021750; Generator: 0.010834,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,337 root         INFO     Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 0.076797\n",
      "Reconstruction: 0.044332, Regularization: 0.000049, Discriminator: 0.021584; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,404 root         INFO     ====> Epoch: 151 Average loss: 0.0851\n",
      "2019-04-09 20:45:46,428 root         INFO     Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 0.076262\n",
      "Reconstruction: 0.043671, Regularization: 0.000047, Discriminator: 0.021712; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,495 root         INFO     Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 0.092892\n",
      "Reconstruction: 0.060421, Regularization: 0.000074, Discriminator: 0.021569; Generator: 0.010827,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,560 root         INFO     Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 0.088083\n",
      "Reconstruction: 0.055496, Regularization: 0.000068, Discriminator: 0.021684; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,626 root         INFO     Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 0.082945\n",
      "Reconstruction: 0.050415, Regularization: 0.000060, Discriminator: 0.021629; Generator: 0.010842,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,692 root         INFO     Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 0.084231\n",
      "Reconstruction: 0.051675, Regularization: 0.000062, Discriminator: 0.021651; Generator: 0.010843,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,758 root         INFO     Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 0.075474\n",
      "Reconstruction: 0.042936, Regularization: 0.000048, Discriminator: 0.021655; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,823 root         INFO     Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 0.081494\n",
      "Reconstruction: 0.048956, Regularization: 0.000056, Discriminator: 0.021647; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,889 root         INFO     Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 0.074254\n",
      "Reconstruction: 0.041727, Regularization: 0.000043, Discriminator: 0.021653; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:46,957 root         INFO     ====> Epoch: 152 Average loss: 0.0851\n",
      "2019-04-09 20:45:46,981 root         INFO     Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 0.095333\n",
      "Reconstruction: 0.062801, Regularization: 0.000078, Discriminator: 0.021625; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,047 root         INFO     Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 0.091917\n",
      "Reconstruction: 0.059395, Regularization: 0.000073, Discriminator: 0.021616; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,114 root         INFO     Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 0.091285\n",
      "Reconstruction: 0.058763, Regularization: 0.000074, Discriminator: 0.021613; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,180 root         INFO     Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 0.084970\n",
      "Reconstruction: 0.052436, Regularization: 0.000063, Discriminator: 0.021632; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,247 root         INFO     Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 0.088299\n",
      "Reconstruction: 0.055751, Regularization: 0.000067, Discriminator: 0.021649; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,313 root         INFO     Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 0.069324\n",
      "Reconstruction: 0.036771, Regularization: 0.000035, Discriminator: 0.021686; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,379 root         INFO     Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 0.089146\n",
      "Reconstruction: 0.056570, Regularization: 0.000069, Discriminator: 0.021683; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,445 root         INFO     Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 0.095810\n",
      "Reconstruction: 0.063251, Regularization: 0.000079, Discriminator: 0.021653; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,514 root         INFO     ====> Epoch: 153 Average loss: 0.0851\n",
      "2019-04-09 20:45:47,538 root         INFO     Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 0.071877\n",
      "Reconstruction: 0.039361, Regularization: 0.000041, Discriminator: 0.021636; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,601 root         INFO     Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 0.087920\n",
      "Reconstruction: 0.055298, Regularization: 0.000070, Discriminator: 0.021707; Generator: 0.010845,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,664 root         INFO     Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 0.089195\n",
      "Reconstruction: 0.056645, Regularization: 0.000072, Discriminator: 0.021633; Generator: 0.010845,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,728 root         INFO     Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 0.087173\n",
      "Reconstruction: 0.054592, Regularization: 0.000067, Discriminator: 0.021676; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,791 root         INFO     Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 0.076969\n",
      "Reconstruction: 0.044466, Regularization: 0.000050, Discriminator: 0.021617; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,855 root         INFO     Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 0.089914\n",
      "Reconstruction: 0.057319, Regularization: 0.000071, Discriminator: 0.021692; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,918 root         INFO     Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 0.079746\n",
      "Reconstruction: 0.047215, Regularization: 0.000053, Discriminator: 0.021653; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:47,982 root         INFO     Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 0.084945\n",
      "Reconstruction: 0.052443, Regularization: 0.000061, Discriminator: 0.021610; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,048 root         INFO     ====> Epoch: 154 Average loss: 0.0851\n",
      "2019-04-09 20:45:48,072 root         INFO     Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 0.088005\n",
      "Reconstruction: 0.055411, Regularization: 0.000069, Discriminator: 0.021697; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,136 root         INFO     Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 0.099973\n",
      "Reconstruction: 0.067282, Regularization: 0.000087, Discriminator: 0.021763; Generator: 0.010841,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,200 root         INFO     Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 0.087986\n",
      "Reconstruction: 0.055413, Regularization: 0.000069, Discriminator: 0.021675; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,264 root         INFO     Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 0.084906\n",
      "Reconstruction: 0.052358, Regularization: 0.000063, Discriminator: 0.021648; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,328 root         INFO     Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 0.086246\n",
      "Reconstruction: 0.053736, Regularization: 0.000065, Discriminator: 0.021609; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,392 root         INFO     Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 0.075109\n",
      "Reconstruction: 0.042551, Regularization: 0.000047, Discriminator: 0.021674; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,456 root         INFO     Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 0.070483\n",
      "Reconstruction: 0.037965, Regularization: 0.000041, Discriminator: 0.021649; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,520 root         INFO     Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 0.078870\n",
      "Reconstruction: 0.046288, Regularization: 0.000055, Discriminator: 0.021693; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,587 root         INFO     ====> Epoch: 155 Average loss: 0.0851\n",
      "2019-04-09 20:45:48,611 root         INFO     Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 0.078958\n",
      "Reconstruction: 0.046453, Regularization: 0.000056, Discriminator: 0.021618; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,675 root         INFO     Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 0.083820\n",
      "Reconstruction: 0.051214, Regularization: 0.000064, Discriminator: 0.021703; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,742 root         INFO     Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 0.079393\n",
      "Reconstruction: 0.046807, Regularization: 0.000056, Discriminator: 0.021704; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,809 root         INFO     Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 0.081571\n",
      "Reconstruction: 0.048997, Regularization: 0.000061, Discriminator: 0.021680; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,877 root         INFO     Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 0.079536\n",
      "Reconstruction: 0.046986, Regularization: 0.000057, Discriminator: 0.021658; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:48,945 root         INFO     Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 0.076385\n",
      "Reconstruction: 0.043916, Regularization: 0.000050, Discriminator: 0.021587; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,011 root         INFO     Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 0.087033\n",
      "Reconstruction: 0.054490, Regularization: 0.000067, Discriminator: 0.021640; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,077 root         INFO     Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 0.080683\n",
      "Reconstruction: 0.048129, Regularization: 0.000058, Discriminator: 0.021661; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,144 root         INFO     ====> Epoch: 156 Average loss: 0.0851\n",
      "2019-04-09 20:45:49,168 root         INFO     Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 0.090352\n",
      "Reconstruction: 0.057808, Regularization: 0.000074, Discriminator: 0.021634; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,235 root         INFO     Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 0.083557\n",
      "Reconstruction: 0.051114, Regularization: 0.000063, Discriminator: 0.021544; Generator: 0.010835,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,302 root         INFO     Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 0.083467\n",
      "Reconstruction: 0.050965, Regularization: 0.000060, Discriminator: 0.021616; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,368 root         INFO     Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 0.087466\n",
      "Reconstruction: 0.054947, Regularization: 0.000066, Discriminator: 0.021627; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,433 root         INFO     Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 0.081591\n",
      "Reconstruction: 0.049109, Regularization: 0.000057, Discriminator: 0.021589; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,499 root         INFO     Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 0.083281\n",
      "Reconstruction: 0.050671, Regularization: 0.000061, Discriminator: 0.021717; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,564 root         INFO     Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 0.084838\n",
      "Reconstruction: 0.052287, Regularization: 0.000065, Discriminator: 0.021651; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,630 root         INFO     Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 0.074358\n",
      "Reconstruction: 0.041764, Regularization: 0.000049, Discriminator: 0.021708; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,697 root         INFO     ====> Epoch: 157 Average loss: 0.0851\n",
      "2019-04-09 20:45:49,721 root         INFO     Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 0.082207\n",
      "Reconstruction: 0.049648, Regularization: 0.000063, Discriminator: 0.021654; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,785 root         INFO     Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 0.087039\n",
      "Reconstruction: 0.054427, Regularization: 0.000070, Discriminator: 0.021707; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,849 root         INFO     Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 0.080153\n",
      "Reconstruction: 0.047595, Regularization: 0.000060, Discriminator: 0.021669; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,912 root         INFO     Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 0.080204\n",
      "Reconstruction: 0.047676, Regularization: 0.000060, Discriminator: 0.021635; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:49,975 root         INFO     Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 0.086516\n",
      "Reconstruction: 0.054035, Regularization: 0.000073, Discriminator: 0.021573; Generator: 0.010836,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,041 root         INFO     Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 0.072188\n",
      "Reconstruction: 0.039679, Regularization: 0.000047, Discriminator: 0.021622; Generator: 0.010841,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,107 root         INFO     Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 0.082943\n",
      "Reconstruction: 0.050405, Regularization: 0.000067, Discriminator: 0.021636; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,174 root         INFO     Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 0.077318\n",
      "Reconstruction: 0.044763, Regularization: 0.000057, Discriminator: 0.021659; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,242 root         INFO     ====> Epoch: 158 Average loss: 0.0851\n",
      "2019-04-09 20:45:50,266 root         INFO     Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 0.092414\n",
      "Reconstruction: 0.059818, Regularization: 0.000083, Discriminator: 0.021680; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,331 root         INFO     Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 0.076329\n",
      "Reconstruction: 0.043787, Regularization: 0.000056, Discriminator: 0.021659; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,397 root         INFO     Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 0.083082\n",
      "Reconstruction: 0.050453, Regularization: 0.000068, Discriminator: 0.021733; Generator: 0.010828,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,463 root         INFO     Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 0.096098\n",
      "Reconstruction: 0.063465, Regularization: 0.000092, Discriminator: 0.021711; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,529 root         INFO     Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 0.081198\n",
      "Reconstruction: 0.048700, Regularization: 0.000065, Discriminator: 0.021600; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,595 root         INFO     Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 0.080628\n",
      "Reconstruction: 0.048049, Regularization: 0.000063, Discriminator: 0.021676; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,661 root         INFO     Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 0.087025\n",
      "Reconstruction: 0.054517, Regularization: 0.000077, Discriminator: 0.021593; Generator: 0.010839,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,727 root         INFO     Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 0.086244\n",
      "Reconstruction: 0.053748, Regularization: 0.000076, Discriminator: 0.021577; Generator: 0.010842,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,794 root         INFO     ====> Epoch: 159 Average loss: 0.0851\n",
      "2019-04-09 20:45:50,819 root         INFO     Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 0.080455\n",
      "Reconstruction: 0.047828, Regularization: 0.000066, Discriminator: 0.021721; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,886 root         INFO     Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 0.081763\n",
      "Reconstruction: 0.049186, Regularization: 0.000069, Discriminator: 0.021668; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:50,952 root         INFO     Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 0.079089\n",
      "Reconstruction: 0.046546, Regularization: 0.000064, Discriminator: 0.021640; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,018 root         INFO     Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 0.089679\n",
      "Reconstruction: 0.057108, Regularization: 0.000085, Discriminator: 0.021650; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,084 root         INFO     Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 0.083227\n",
      "Reconstruction: 0.050672, Regularization: 0.000073, Discriminator: 0.021647; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,149 root         INFO     Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 0.085221\n",
      "Reconstruction: 0.052745, Regularization: 0.000077, Discriminator: 0.021563; Generator: 0.010836,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,211 root         INFO     Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 0.081079\n",
      "Reconstruction: 0.048454, Regularization: 0.000068, Discriminator: 0.021721; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,273 root         INFO     Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 0.083725\n",
      "Reconstruction: 0.051180, Regularization: 0.000071, Discriminator: 0.021637; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,339 root         INFO     ====> Epoch: 160 Average loss: 0.0851\n",
      "2019-04-09 20:45:51,362 root         INFO     Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 0.086353\n",
      "Reconstruction: 0.053819, Regularization: 0.000074, Discriminator: 0.021634; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,428 root         INFO     Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 0.075763\n",
      "Reconstruction: 0.043185, Regularization: 0.000054, Discriminator: 0.021695; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,494 root         INFO     Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 0.077484\n",
      "Reconstruction: 0.044964, Regularization: 0.000059, Discriminator: 0.021636; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,560 root         INFO     Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 0.081748\n",
      "Reconstruction: 0.049140, Regularization: 0.000067, Discriminator: 0.021712; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,626 root         INFO     Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 0.089200\n",
      "Reconstruction: 0.056668, Regularization: 0.000080, Discriminator: 0.021628; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,691 root         INFO     Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 0.081049\n",
      "Reconstruction: 0.048522, Regularization: 0.000065, Discriminator: 0.021630; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,757 root         INFO     Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 0.089072\n",
      "Reconstruction: 0.056424, Regularization: 0.000080, Discriminator: 0.021729; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,823 root         INFO     Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 0.080962\n",
      "Reconstruction: 0.048368, Regularization: 0.000063, Discriminator: 0.021693; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,890 root         INFO     ====> Epoch: 161 Average loss: 0.0851\n",
      "2019-04-09 20:45:51,914 root         INFO     Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 0.089107\n",
      "Reconstruction: 0.056510, Regularization: 0.000078, Discriminator: 0.021683; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:51,980 root         INFO     Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 0.086339\n",
      "Reconstruction: 0.053823, Regularization: 0.000071, Discriminator: 0.021611; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,046 root         INFO     Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 0.092407\n",
      "Reconstruction: 0.059754, Regularization: 0.000081, Discriminator: 0.021736; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,112 root         INFO     Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 0.091019\n",
      "Reconstruction: 0.058380, Regularization: 0.000080, Discriminator: 0.021726; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,177 root         INFO     Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 0.100902\n",
      "Reconstruction: 0.068287, Regularization: 0.000098, Discriminator: 0.021684; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,242 root         INFO     Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 0.079476\n",
      "Reconstruction: 0.046855, Regularization: 0.000059, Discriminator: 0.021732; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,306 root         INFO     Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 0.084675\n",
      "Reconstruction: 0.052133, Regularization: 0.000069, Discriminator: 0.021634; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,371 root         INFO     Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 0.086931\n",
      "Reconstruction: 0.054351, Regularization: 0.000074, Discriminator: 0.021676; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,437 root         INFO     ====> Epoch: 162 Average loss: 0.0851\n",
      "2019-04-09 20:45:52,461 root         INFO     Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 0.085996\n",
      "Reconstruction: 0.053446, Regularization: 0.000075, Discriminator: 0.021632; Generator: 0.010843,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,525 root         INFO     Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 0.084396\n",
      "Reconstruction: 0.051766, Regularization: 0.000074, Discriminator: 0.021714; Generator: 0.010842,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,588 root         INFO     Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 0.080938\n",
      "Reconstruction: 0.048360, Regularization: 0.000066, Discriminator: 0.021678; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,652 root         INFO     Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 0.092092\n",
      "Reconstruction: 0.059535, Regularization: 0.000087, Discriminator: 0.021635; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,715 root         INFO     Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 0.079816\n",
      "Reconstruction: 0.047307, Regularization: 0.000065, Discriminator: 0.021614; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,777 root         INFO     Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 0.088209\n",
      "Reconstruction: 0.055664, Regularization: 0.000081, Discriminator: 0.021631; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,840 root         INFO     Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 0.095731\n",
      "Reconstruction: 0.063218, Regularization: 0.000095, Discriminator: 0.021581; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,904 root         INFO     Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 0.087850\n",
      "Reconstruction: 0.055218, Regularization: 0.000079, Discriminator: 0.021716; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:52,971 root         INFO     ====> Epoch: 163 Average loss: 0.0851\n",
      "2019-04-09 20:45:52,995 root         INFO     Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 0.085273\n",
      "Reconstruction: 0.052738, Regularization: 0.000071, Discriminator: 0.021630; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,058 root         INFO     Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 0.088052\n",
      "Reconstruction: 0.055481, Regularization: 0.000079, Discriminator: 0.021654; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,122 root         INFO     Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 0.088950\n",
      "Reconstruction: 0.056385, Regularization: 0.000080, Discriminator: 0.021651; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,185 root         INFO     Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 0.087891\n",
      "Reconstruction: 0.055345, Regularization: 0.000078, Discriminator: 0.021639; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,248 root         INFO     Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 0.074128\n",
      "Reconstruction: 0.041612, Regularization: 0.000053, Discriminator: 0.021639; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,312 root         INFO     Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 0.073283\n",
      "Reconstruction: 0.040729, Regularization: 0.000052, Discriminator: 0.021665; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,376 root         INFO     Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 0.091161\n",
      "Reconstruction: 0.058591, Regularization: 0.000086, Discriminator: 0.021646; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,440 root         INFO     Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 0.079992\n",
      "Reconstruction: 0.047402, Regularization: 0.000061, Discriminator: 0.021697; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,506 root         INFO     ====> Epoch: 164 Average loss: 0.0851\n",
      "2019-04-09 20:45:53,530 root         INFO     Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 0.082511\n",
      "Reconstruction: 0.049927, Regularization: 0.000067, Discriminator: 0.021684; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,594 root         INFO     Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 0.085230\n",
      "Reconstruction: 0.052649, Regularization: 0.000072, Discriminator: 0.021676; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,660 root         INFO     Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 0.082776\n",
      "Reconstruction: 0.050200, Regularization: 0.000069, Discriminator: 0.021673; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,725 root         INFO     Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 0.089029\n",
      "Reconstruction: 0.056441, Regularization: 0.000077, Discriminator: 0.021679; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,788 root         INFO     Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 0.087156\n",
      "Reconstruction: 0.054519, Regularization: 0.000076, Discriminator: 0.021727; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,851 root         INFO     Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 0.081462\n",
      "Reconstruction: 0.048895, Regularization: 0.000065, Discriminator: 0.021669; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,915 root         INFO     Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 0.080654\n",
      "Reconstruction: 0.048057, Regularization: 0.000065, Discriminator: 0.021691; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:53,979 root         INFO     Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 0.084218\n",
      "Reconstruction: 0.051620, Regularization: 0.000072, Discriminator: 0.021689; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,045 root         INFO     ====> Epoch: 165 Average loss: 0.0851\n",
      "2019-04-09 20:45:54,069 root         INFO     Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 0.075131\n",
      "Reconstruction: 0.042562, Regularization: 0.000056, Discriminator: 0.021680; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,135 root         INFO     Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 0.083676\n",
      "Reconstruction: 0.051142, Regularization: 0.000073, Discriminator: 0.021630; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,201 root         INFO     Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 0.073877\n",
      "Reconstruction: 0.041323, Regularization: 0.000052, Discriminator: 0.021669; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,268 root         INFO     Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 0.081175\n",
      "Reconstruction: 0.048595, Regularization: 0.000067, Discriminator: 0.021671; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,334 root         INFO     Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 0.082052\n",
      "Reconstruction: 0.049496, Regularization: 0.000068, Discriminator: 0.021652; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,400 root         INFO     Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 0.081371\n",
      "Reconstruction: 0.048801, Regularization: 0.000065, Discriminator: 0.021670; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,466 root         INFO     Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 0.099432\n",
      "Reconstruction: 0.066853, Regularization: 0.000099, Discriminator: 0.021652; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,531 root         INFO     Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 0.078869\n",
      "Reconstruction: 0.046266, Regularization: 0.000061, Discriminator: 0.021714; Generator: 0.010829,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,599 root         INFO     ====> Epoch: 166 Average loss: 0.0851\n",
      "2019-04-09 20:45:54,623 root         INFO     Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 0.090441\n",
      "Reconstruction: 0.057812, Regularization: 0.000083, Discriminator: 0.021708; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,687 root         INFO     Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 0.077786\n",
      "Reconstruction: 0.045208, Regularization: 0.000060, Discriminator: 0.021681; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,753 root         INFO     Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 0.081225\n",
      "Reconstruction: 0.048679, Regularization: 0.000067, Discriminator: 0.021632; Generator: 0.010846,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 20:45:54,819 root         INFO     Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 0.091933\n",
      "Reconstruction: 0.059327, Regularization: 0.000085, Discriminator: 0.021686; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,886 root         INFO     Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 0.086880\n",
      "Reconstruction: 0.054300, Regularization: 0.000075, Discriminator: 0.021669; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:54,952 root         INFO     Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 0.079999\n",
      "Reconstruction: 0.047485, Regularization: 0.000061, Discriminator: 0.021619; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,018 root         INFO     Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 0.087024\n",
      "Reconstruction: 0.054437, Regularization: 0.000073, Discriminator: 0.021682; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,084 root         INFO     Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 0.090390\n",
      "Reconstruction: 0.057784, Regularization: 0.000079, Discriminator: 0.021694; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,151 root         INFO     ====> Epoch: 167 Average loss: 0.0851\n",
      "2019-04-09 20:45:55,175 root         INFO     Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 0.091929\n",
      "Reconstruction: 0.059433, Regularization: 0.000083, Discriminator: 0.021585; Generator: 0.010827,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,242 root         INFO     Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 0.082110\n",
      "Reconstruction: 0.049521, Regularization: 0.000066, Discriminator: 0.021691; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,308 root         INFO     Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 0.077814\n",
      "Reconstruction: 0.045303, Regularization: 0.000058, Discriminator: 0.021628; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,374 root         INFO     Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 0.090418\n",
      "Reconstruction: 0.057824, Regularization: 0.000081, Discriminator: 0.021687; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,439 root         INFO     Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 0.086656\n",
      "Reconstruction: 0.054048, Regularization: 0.000075, Discriminator: 0.021696; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,506 root         INFO     Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 0.080060\n",
      "Reconstruction: 0.047505, Regularization: 0.000065, Discriminator: 0.021666; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,571 root         INFO     Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 0.078614\n",
      "Reconstruction: 0.046047, Regularization: 0.000062, Discriminator: 0.021674; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,638 root         INFO     Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 0.079882\n",
      "Reconstruction: 0.047371, Regularization: 0.000065, Discriminator: 0.021606; Generator: 0.010841,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,706 root         INFO     ====> Epoch: 168 Average loss: 0.0851\n",
      "2019-04-09 20:45:55,730 root         INFO     Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 0.080426\n",
      "Reconstruction: 0.047937, Regularization: 0.000064, Discriminator: 0.021583; Generator: 0.010842,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,796 root         INFO     Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 0.084658\n",
      "Reconstruction: 0.052069, Regularization: 0.000073, Discriminator: 0.021679; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,862 root         INFO     Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 0.081164\n",
      "Reconstruction: 0.048588, Regularization: 0.000067, Discriminator: 0.021673; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,927 root         INFO     Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 0.090386\n",
      "Reconstruction: 0.057803, Regularization: 0.000084, Discriminator: 0.021671; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:55,992 root         INFO     Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 0.084815\n",
      "Reconstruction: 0.052244, Regularization: 0.000072, Discriminator: 0.021671; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,058 root         INFO     Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 0.079871\n",
      "Reconstruction: 0.047363, Regularization: 0.000061, Discriminator: 0.021614; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,122 root         INFO     Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 0.091284\n",
      "Reconstruction: 0.058654, Regularization: 0.000081, Discriminator: 0.021710; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,187 root         INFO     Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 0.080773\n",
      "Reconstruction: 0.048225, Regularization: 0.000062, Discriminator: 0.021646; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,254 root         INFO     ====> Epoch: 169 Average loss: 0.0851\n",
      "2019-04-09 20:45:56,277 root         INFO     Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 0.080945\n",
      "Reconstruction: 0.048439, Regularization: 0.000062, Discriminator: 0.021604; Generator: 0.010840,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,344 root         INFO     Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 0.084319\n",
      "Reconstruction: 0.051817, Regularization: 0.000068, Discriminator: 0.021592; Generator: 0.010842,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,409 root         INFO     Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 0.072248\n",
      "Reconstruction: 0.039748, Regularization: 0.000044, Discriminator: 0.021616; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,475 root         INFO     Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 0.075201\n",
      "Reconstruction: 0.042605, Regularization: 0.000051, Discriminator: 0.021709; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,542 root         INFO     Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 0.083102\n",
      "Reconstruction: 0.050568, Regularization: 0.000066, Discriminator: 0.021632; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,610 root         INFO     Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 0.097082\n",
      "Reconstruction: 0.064479, Regularization: 0.000093, Discriminator: 0.021674; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,679 root         INFO     Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 0.085595\n",
      "Reconstruction: 0.053072, Regularization: 0.000072, Discriminator: 0.021620; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,746 root         INFO     Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 0.098077\n",
      "Reconstruction: 0.065455, Regularization: 0.000093, Discriminator: 0.021697; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,816 root         INFO     ====> Epoch: 170 Average loss: 0.0851\n",
      "2019-04-09 20:45:56,840 root         INFO     Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 0.084911\n",
      "Reconstruction: 0.052382, Regularization: 0.000069, Discriminator: 0.021626; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,909 root         INFO     Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 0.077192\n",
      "Reconstruction: 0.044642, Regularization: 0.000055, Discriminator: 0.021659; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:56,978 root         INFO     Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 0.074617\n",
      "Reconstruction: 0.042106, Regularization: 0.000050, Discriminator: 0.021623; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,046 root         INFO     Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 0.087810\n",
      "Reconstruction: 0.055179, Regularization: 0.000074, Discriminator: 0.021722; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,115 root         INFO     Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 0.081709\n",
      "Reconstruction: 0.049162, Regularization: 0.000064, Discriminator: 0.021657; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,182 root         INFO     Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 0.081651\n",
      "Reconstruction: 0.049107, Regularization: 0.000063, Discriminator: 0.021648; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,248 root         INFO     Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 0.081903\n",
      "Reconstruction: 0.049371, Regularization: 0.000062, Discriminator: 0.021647; Generator: 0.010822,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,314 root         INFO     Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 0.081060\n",
      "Reconstruction: 0.048513, Regularization: 0.000061, Discriminator: 0.021651; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,382 root         INFO     ====> Epoch: 171 Average loss: 0.0851\n",
      "2019-04-09 20:45:57,406 root         INFO     Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 0.084300\n",
      "Reconstruction: 0.051758, Regularization: 0.000067, Discriminator: 0.021639; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,473 root         INFO     Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 0.094272\n",
      "Reconstruction: 0.061718, Regularization: 0.000087, Discriminator: 0.021637; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,540 root         INFO     Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 0.076683\n",
      "Reconstruction: 0.044126, Regularization: 0.000054, Discriminator: 0.021670; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,607 root         INFO     Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 0.094701\n",
      "Reconstruction: 0.062081, Regularization: 0.000087, Discriminator: 0.021697; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,673 root         INFO     Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 0.089804\n",
      "Reconstruction: 0.057260, Regularization: 0.000080, Discriminator: 0.021630; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,738 root         INFO     Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 0.075097\n",
      "Reconstruction: 0.042662, Regularization: 0.000052, Discriminator: 0.021556; Generator: 0.010827,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,805 root         INFO     Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 0.086833\n",
      "Reconstruction: 0.054284, Regularization: 0.000074, Discriminator: 0.021638; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,873 root         INFO     Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 0.088053\n",
      "Reconstruction: 0.055471, Regularization: 0.000075, Discriminator: 0.021670; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:57,942 root         INFO     ====> Epoch: 172 Average loss: 0.0851\n",
      "2019-04-09 20:45:57,966 root         INFO     Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 0.072927\n",
      "Reconstruction: 0.040411, Regularization: 0.000047, Discriminator: 0.021631; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,031 root         INFO     Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 0.081045\n",
      "Reconstruction: 0.048445, Regularization: 0.000063, Discriminator: 0.021702; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,095 root         INFO     Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 0.075753\n",
      "Reconstruction: 0.043224, Regularization: 0.000053, Discriminator: 0.021639; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,159 root         INFO     Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 0.069943\n",
      "Reconstruction: 0.037373, Regularization: 0.000042, Discriminator: 0.021693; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,223 root         INFO     Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 0.082854\n",
      "Reconstruction: 0.050286, Regularization: 0.000064, Discriminator: 0.021676; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,287 root         INFO     Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 0.079159\n",
      "Reconstruction: 0.046573, Regularization: 0.000056, Discriminator: 0.021699; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,352 root         INFO     Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 0.080635\n",
      "Reconstruction: 0.048036, Regularization: 0.000063, Discriminator: 0.021704; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,418 root         INFO     Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 0.083951\n",
      "Reconstruction: 0.051420, Regularization: 0.000068, Discriminator: 0.021631; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,485 root         INFO     ====> Epoch: 173 Average loss: 0.0851\n",
      "2019-04-09 20:45:58,509 root         INFO     Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 0.095217\n",
      "Reconstruction: 0.062680, Regularization: 0.000087, Discriminator: 0.021611; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,576 root         INFO     Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 0.097177\n",
      "Reconstruction: 0.064599, Regularization: 0.000090, Discriminator: 0.021647; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,643 root         INFO     Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 0.084196\n",
      "Reconstruction: 0.051639, Regularization: 0.000065, Discriminator: 0.021653; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,710 root         INFO     Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 0.082149\n",
      "Reconstruction: 0.049602, Regularization: 0.000062, Discriminator: 0.021652; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,777 root         INFO     Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 0.089575\n",
      "Reconstruction: 0.056931, Regularization: 0.000074, Discriminator: 0.021740; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,844 root         INFO     Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 0.083725\n",
      "Reconstruction: 0.051205, Regularization: 0.000061, Discriminator: 0.021626; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,911 root         INFO     Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 0.083652\n",
      "Reconstruction: 0.051132, Regularization: 0.000061, Discriminator: 0.021632; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:58,976 root         INFO     Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 0.095792\n",
      "Reconstruction: 0.063212, Regularization: 0.000081, Discriminator: 0.021660; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,042 root         INFO     ====> Epoch: 174 Average loss: 0.0851\n",
      "2019-04-09 20:45:59,066 root         INFO     Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 0.095340\n",
      "Reconstruction: 0.062781, Regularization: 0.000079, Discriminator: 0.021647; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,134 root         INFO     Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 0.085892\n",
      "Reconstruction: 0.053350, Regularization: 0.000065, Discriminator: 0.021645; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,202 root         INFO     Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 0.074768\n",
      "Reconstruction: 0.042265, Regularization: 0.000047, Discriminator: 0.021633; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,269 root         INFO     Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 0.086377\n",
      "Reconstruction: 0.053847, Regularization: 0.000065, Discriminator: 0.021636; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,337 root         INFO     Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 0.075736\n",
      "Reconstruction: 0.043187, Regularization: 0.000047, Discriminator: 0.021662; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,404 root         INFO     Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 0.070794\n",
      "Reconstruction: 0.038266, Regularization: 0.000039, Discriminator: 0.021659; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,471 root         INFO     Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 0.080934\n",
      "Reconstruction: 0.048318, Regularization: 0.000053, Discriminator: 0.021727; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,539 root         INFO     Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 0.087681\n",
      "Reconstruction: 0.055130, Regularization: 0.000063, Discriminator: 0.021650; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,606 root         INFO     ====> Epoch: 175 Average loss: 0.0851\n",
      "2019-04-09 20:45:59,630 root         INFO     Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 0.085071\n",
      "Reconstruction: 0.052442, Regularization: 0.000060, Discriminator: 0.021731; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,698 root         INFO     Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 0.086628\n",
      "Reconstruction: 0.054024, Regularization: 0.000063, Discriminator: 0.021701; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,765 root         INFO     Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 0.082178\n",
      "Reconstruction: 0.049656, Regularization: 0.000057, Discriminator: 0.021627; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,833 root         INFO     Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 0.095577\n",
      "Reconstruction: 0.063020, Regularization: 0.000078, Discriminator: 0.021641; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,900 root         INFO     Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 0.085675\n",
      "Reconstruction: 0.053156, Regularization: 0.000062, Discriminator: 0.021630; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:45:59,967 root         INFO     Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 0.081269\n",
      "Reconstruction: 0.048755, Regularization: 0.000056, Discriminator: 0.021626; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,033 root         INFO     Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 0.087981\n",
      "Reconstruction: 0.055351, Regularization: 0.000066, Discriminator: 0.021735; Generator: 0.010829,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,099 root         INFO     Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 0.080954\n",
      "Reconstruction: 0.048375, Regularization: 0.000054, Discriminator: 0.021695; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,167 root         INFO     ====> Epoch: 176 Average loss: 0.0851\n",
      "2019-04-09 20:46:00,191 root         INFO     Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 0.077577\n",
      "Reconstruction: 0.045021, Regularization: 0.000048, Discriminator: 0.021671; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,260 root         INFO     Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 0.088028\n",
      "Reconstruction: 0.055441, Regularization: 0.000065, Discriminator: 0.021688; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,327 root         INFO     Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 0.088332\n",
      "Reconstruction: 0.055782, Regularization: 0.000065, Discriminator: 0.021653; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,395 root         INFO     Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 0.079877\n",
      "Reconstruction: 0.047286, Regularization: 0.000052, Discriminator: 0.021700; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,460 root         INFO     Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 0.080568\n",
      "Reconstruction: 0.048030, Regularization: 0.000052, Discriminator: 0.021648; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,525 root         INFO     Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 0.098247\n",
      "Reconstruction: 0.065649, Regularization: 0.000080, Discriminator: 0.021678; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,592 root         INFO     Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 0.085421\n",
      "Reconstruction: 0.052920, Regularization: 0.000060, Discriminator: 0.021609; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,659 root         INFO     Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 0.090806\n",
      "Reconstruction: 0.058230, Regularization: 0.000071, Discriminator: 0.021669; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,730 root         INFO     ====> Epoch: 177 Average loss: 0.0851\n",
      "2019-04-09 20:46:00,754 root         INFO     Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 0.078287\n",
      "Reconstruction: 0.045762, Regularization: 0.000049, Discriminator: 0.021646; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,819 root         INFO     Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 0.078629\n",
      "Reconstruction: 0.046105, Regularization: 0.000050, Discriminator: 0.021647; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,883 root         INFO     Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 0.081026\n",
      "Reconstruction: 0.048493, Regularization: 0.000052, Discriminator: 0.021649; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:00,950 root         INFO     Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 0.073760\n",
      "Reconstruction: 0.041216, Regularization: 0.000041, Discriminator: 0.021669; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,015 root         INFO     Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 0.079907\n",
      "Reconstruction: 0.047339, Regularization: 0.000050, Discriminator: 0.021683; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,080 root         INFO     Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 0.086452\n",
      "Reconstruction: 0.053918, Regularization: 0.000060, Discriminator: 0.021631; Generator: 0.010843,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,146 root         INFO     Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 0.090627\n",
      "Reconstruction: 0.058083, Regularization: 0.000068, Discriminator: 0.021638; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,211 root         INFO     Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 0.079474\n",
      "Reconstruction: 0.046903, Regularization: 0.000050, Discriminator: 0.021687; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,279 root         INFO     ====> Epoch: 178 Average loss: 0.0851\n",
      "2019-04-09 20:46:01,303 root         INFO     Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 0.085713\n",
      "Reconstruction: 0.053170, Regularization: 0.000061, Discriminator: 0.021652; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,371 root         INFO     Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 0.083126\n",
      "Reconstruction: 0.050633, Regularization: 0.000057, Discriminator: 0.021603; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,438 root         INFO     Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 0.088131\n",
      "Reconstruction: 0.055572, Regularization: 0.000065, Discriminator: 0.021659; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,505 root         INFO     Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 0.080029\n",
      "Reconstruction: 0.047458, Regularization: 0.000052, Discriminator: 0.021684; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,572 root         INFO     Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 0.100710\n",
      "Reconstruction: 0.068123, Regularization: 0.000082, Discriminator: 0.021670; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,639 root         INFO     Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 0.083250\n",
      "Reconstruction: 0.050650, Regularization: 0.000054, Discriminator: 0.021710; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,706 root         INFO     Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 0.076738\n",
      "Reconstruction: 0.044216, Regularization: 0.000045, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,773 root         INFO     Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 0.078159\n",
      "Reconstruction: 0.045547, Regularization: 0.000047, Discriminator: 0.021722; Generator: 0.010844,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,840 root         INFO     ====> Epoch: 179 Average loss: 0.0851\n",
      "2019-04-09 20:46:01,864 root         INFO     Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 0.085865\n",
      "Reconstruction: 0.053318, Regularization: 0.000059, Discriminator: 0.021663; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:01,933 root         INFO     Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 0.081142\n",
      "Reconstruction: 0.048590, Regularization: 0.000053, Discriminator: 0.021669; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,000 root         INFO     Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 0.097027\n",
      "Reconstruction: 0.064513, Regularization: 0.000079, Discriminator: 0.021602; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,067 root         INFO     Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 0.093454\n",
      "Reconstruction: 0.060875, Regularization: 0.000071, Discriminator: 0.021671; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,135 root         INFO     Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 0.079606\n",
      "Reconstruction: 0.047042, Regularization: 0.000050, Discriminator: 0.021682; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,202 root         INFO     Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 0.074823\n",
      "Reconstruction: 0.042183, Regularization: 0.000044, Discriminator: 0.021759; Generator: 0.010837,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,269 root         INFO     Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 0.088715\n",
      "Reconstruction: 0.056100, Regularization: 0.000066, Discriminator: 0.021711; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,335 root         INFO     Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 0.080575\n",
      "Reconstruction: 0.048098, Regularization: 0.000053, Discriminator: 0.021598; Generator: 0.010825,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,401 root         INFO     ====> Epoch: 180 Average loss: 0.0851\n",
      "2019-04-09 20:46:02,425 root         INFO     Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 0.078131\n",
      "Reconstruction: 0.045604, Regularization: 0.000051, Discriminator: 0.021644; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,493 root         INFO     Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 0.088564\n",
      "Reconstruction: 0.055970, Regularization: 0.000066, Discriminator: 0.021696; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,561 root         INFO     Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 0.081899\n",
      "Reconstruction: 0.049303, Regularization: 0.000056, Discriminator: 0.021713; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,628 root         INFO     Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 0.079004\n",
      "Reconstruction: 0.046492, Regularization: 0.000052, Discriminator: 0.021636; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,696 root         INFO     Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 0.088585\n",
      "Reconstruction: 0.056078, Regularization: 0.000067, Discriminator: 0.021606; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,763 root         INFO     Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 0.092753\n",
      "Reconstruction: 0.060229, Regularization: 0.000073, Discriminator: 0.021613; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,831 root         INFO     Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 0.087431\n",
      "Reconstruction: 0.054859, Regularization: 0.000063, Discriminator: 0.021672; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,898 root         INFO     Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 0.079216\n",
      "Reconstruction: 0.046638, Regularization: 0.000052, Discriminator: 0.021688; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:02,966 root         INFO     ====> Epoch: 181 Average loss: 0.0851\n",
      "2019-04-09 20:46:02,991 root         INFO     Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 0.082565\n",
      "Reconstruction: 0.050027, Regularization: 0.000058, Discriminator: 0.021644; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,059 root         INFO     Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 0.077900\n",
      "Reconstruction: 0.045290, Regularization: 0.000048, Discriminator: 0.021721; Generator: 0.010841,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,124 root         INFO     Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 0.094184\n",
      "Reconstruction: 0.061673, Regularization: 0.000076, Discriminator: 0.021608; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,188 root         INFO     Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 0.081600\n",
      "Reconstruction: 0.049032, Regularization: 0.000055, Discriminator: 0.021678; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,252 root         INFO     Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 0.093167\n",
      "Reconstruction: 0.060565, Regularization: 0.000074, Discriminator: 0.021689; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,317 root         INFO     Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 0.077990\n",
      "Reconstruction: 0.045467, Regularization: 0.000050, Discriminator: 0.021636; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,381 root         INFO     Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 0.094027\n",
      "Reconstruction: 0.061507, Regularization: 0.000078, Discriminator: 0.021611; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,445 root         INFO     Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 0.073205\n",
      "Reconstruction: 0.040687, Regularization: 0.000043, Discriminator: 0.021645; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,510 root         INFO     ====> Epoch: 182 Average loss: 0.0851\n",
      "2019-04-09 20:46:03,534 root         INFO     Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 0.084742\n",
      "Reconstruction: 0.052130, Regularization: 0.000061, Discriminator: 0.021720; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,602 root         INFO     Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 0.078878\n",
      "Reconstruction: 0.046326, Regularization: 0.000051, Discriminator: 0.021674; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,669 root         INFO     Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 0.080602\n",
      "Reconstruction: 0.048057, Regularization: 0.000054, Discriminator: 0.021662; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,735 root         INFO     Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 0.080963\n",
      "Reconstruction: 0.048428, Regularization: 0.000053, Discriminator: 0.021648; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,801 root         INFO     Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 0.082413\n",
      "Reconstruction: 0.049875, Regularization: 0.000056, Discriminator: 0.021647; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,867 root         INFO     Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 0.092150\n",
      "Reconstruction: 0.059604, Regularization: 0.000070, Discriminator: 0.021650; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:03,933 root         INFO     Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 0.072579\n",
      "Reconstruction: 0.040037, Regularization: 0.000040, Discriminator: 0.021668; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,000 root         INFO     Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 0.086424\n",
      "Reconstruction: 0.053827, Regularization: 0.000062, Discriminator: 0.021704; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,067 root         INFO     ====> Epoch: 183 Average loss: 0.0851\n",
      "2019-04-09 20:46:04,092 root         INFO     Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 0.084998\n",
      "Reconstruction: 0.052434, Regularization: 0.000060, Discriminator: 0.021659; Generator: 0.010845,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,158 root         INFO     Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 0.080358\n",
      "Reconstruction: 0.047827, Regularization: 0.000052, Discriminator: 0.021636; Generator: 0.010842,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,223 root         INFO     Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 0.082009\n",
      "Reconstruction: 0.049436, Regularization: 0.000053, Discriminator: 0.021679; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,290 root         INFO     Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 0.101144\n",
      "Reconstruction: 0.068578, Regularization: 0.000084, Discriminator: 0.021653; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,357 root         INFO     Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 0.077751\n",
      "Reconstruction: 0.045184, Regularization: 0.000048, Discriminator: 0.021680; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,423 root         INFO     Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 0.079594\n",
      "Reconstruction: 0.046991, Regularization: 0.000052, Discriminator: 0.021718; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,489 root         INFO     Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 0.091879\n",
      "Reconstruction: 0.059269, Regularization: 0.000069, Discriminator: 0.021706; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,556 root         INFO     Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 0.094020\n",
      "Reconstruction: 0.061416, Regularization: 0.000072, Discriminator: 0.021693; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,624 root         INFO     ====> Epoch: 184 Average loss: 0.0851\n",
      "2019-04-09 20:46:04,648 root         INFO     Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 0.082755\n",
      "Reconstruction: 0.050279, Regularization: 0.000054, Discriminator: 0.021590; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,716 root         INFO     Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 0.081065\n",
      "Reconstruction: 0.048513, Regularization: 0.000050, Discriminator: 0.021675; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,782 root         INFO     Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 0.085290\n",
      "Reconstruction: 0.052693, Regularization: 0.000056, Discriminator: 0.021707; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,848 root         INFO     Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 0.098897\n",
      "Reconstruction: 0.066313, Regularization: 0.000076, Discriminator: 0.021673; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,913 root         INFO     Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 0.081864\n",
      "Reconstruction: 0.049278, Regularization: 0.000052, Discriminator: 0.021700; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:04,979 root         INFO     Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 0.079978\n",
      "Reconstruction: 0.047418, Regularization: 0.000047, Discriminator: 0.021688; Generator: 0.010825,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,045 root         INFO     Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 0.087572\n",
      "Reconstruction: 0.055033, Regularization: 0.000058, Discriminator: 0.021657; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,112 root         INFO     Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 0.078212\n",
      "Reconstruction: 0.045655, Regularization: 0.000044, Discriminator: 0.021671; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,179 root         INFO     ====> Epoch: 185 Average loss: 0.0851\n",
      "2019-04-09 20:46:05,203 root         INFO     Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 0.071113\n",
      "Reconstruction: 0.038557, Regularization: 0.000034, Discriminator: 0.021676; Generator: 0.010845,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,266 root         INFO     Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 0.084339\n",
      "Reconstruction: 0.051761, Regularization: 0.000054, Discriminator: 0.021686; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,329 root         INFO     Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 0.077138\n",
      "Reconstruction: 0.044675, Regularization: 0.000042, Discriminator: 0.021591; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,392 root         INFO     Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 0.080135\n",
      "Reconstruction: 0.047601, Regularization: 0.000047, Discriminator: 0.021659; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,455 root         INFO     Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 0.077459\n",
      "Reconstruction: 0.044972, Regularization: 0.000043, Discriminator: 0.021615; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,518 root         INFO     Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 0.086715\n",
      "Reconstruction: 0.054158, Regularization: 0.000058, Discriminator: 0.021666; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,582 root         INFO     Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 0.078719\n",
      "Reconstruction: 0.046291, Regularization: 0.000045, Discriminator: 0.021553; Generator: 0.010829,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,645 root         INFO     Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 0.096361\n",
      "Reconstruction: 0.063857, Regularization: 0.000068, Discriminator: 0.021598; Generator: 0.010838,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,710 root         INFO     ====> Epoch: 186 Average loss: 0.0851\n",
      "2019-04-09 20:46:05,734 root         INFO     Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 0.084075\n",
      "Reconstruction: 0.051414, Regularization: 0.000051, Discriminator: 0.021770; Generator: 0.010841,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,799 root         INFO     Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 0.093969\n",
      "Reconstruction: 0.061392, Regularization: 0.000064, Discriminator: 0.021685; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,864 root         INFO     Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 0.099127\n",
      "Reconstruction: 0.066574, Regularization: 0.000071, Discriminator: 0.021646; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,928 root         INFO     Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 0.090884\n",
      "Reconstruction: 0.058342, Regularization: 0.000058, Discriminator: 0.021650; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:05,992 root         INFO     Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 0.089349\n",
      "Reconstruction: 0.056867, Regularization: 0.000056, Discriminator: 0.021589; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,058 root         INFO     Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 0.080417\n",
      "Reconstruction: 0.047768, Regularization: 0.000044, Discriminator: 0.021767; Generator: 0.010838,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,125 root         INFO     Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 0.094597\n",
      "Reconstruction: 0.062080, Regularization: 0.000063, Discriminator: 0.021621; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,191 root         INFO     Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 0.083968\n",
      "Reconstruction: 0.051492, Regularization: 0.000049, Discriminator: 0.021587; Generator: 0.010840,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,260 root         INFO     ====> Epoch: 187 Average loss: 0.0851\n",
      "2019-04-09 20:46:06,284 root         INFO     Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 0.085796\n",
      "Reconstruction: 0.053286, Regularization: 0.000052, Discriminator: 0.021622; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,350 root         INFO     Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 0.084169\n",
      "Reconstruction: 0.051617, Regularization: 0.000052, Discriminator: 0.021662; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,417 root         INFO     Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 0.086906\n",
      "Reconstruction: 0.054396, Regularization: 0.000053, Discriminator: 0.021625; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,483 root         INFO     Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 0.081925\n",
      "Reconstruction: 0.049378, Regularization: 0.000046, Discriminator: 0.021668; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,550 root         INFO     Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 0.091835\n",
      "Reconstruction: 0.059287, Regularization: 0.000056, Discriminator: 0.021657; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,616 root         INFO     Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 0.084980\n",
      "Reconstruction: 0.052463, Regularization: 0.000050, Discriminator: 0.021636; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,682 root         INFO     Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 0.094280\n",
      "Reconstruction: 0.061843, Regularization: 0.000061, Discriminator: 0.021548; Generator: 0.010829,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,748 root         INFO     Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 0.084521\n",
      "Reconstruction: 0.051993, Regularization: 0.000049, Discriminator: 0.021639; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,815 root         INFO     ====> Epoch: 188 Average loss: 0.0851\n",
      "2019-04-09 20:46:06,839 root         INFO     Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 0.087158\n",
      "Reconstruction: 0.054601, Regularization: 0.000050, Discriminator: 0.021672; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,906 root         INFO     Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 0.079385\n",
      "Reconstruction: 0.046838, Regularization: 0.000042, Discriminator: 0.021666; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:06,973 root         INFO     Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 0.084583\n",
      "Reconstruction: 0.052051, Regularization: 0.000048, Discriminator: 0.021645; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,039 root         INFO     Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 0.091257\n",
      "Reconstruction: 0.058680, Regularization: 0.000056, Discriminator: 0.021685; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,106 root         INFO     Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 0.087951\n",
      "Reconstruction: 0.055490, Regularization: 0.000050, Discriminator: 0.021571; Generator: 0.010841,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,172 root         INFO     Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 0.083964\n",
      "Reconstruction: 0.051458, Regularization: 0.000044, Discriminator: 0.021629; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,239 root         INFO     Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 0.092380\n",
      "Reconstruction: 0.059807, Regularization: 0.000054, Discriminator: 0.021688; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,305 root         INFO     Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 0.086248\n",
      "Reconstruction: 0.053729, Regularization: 0.000049, Discriminator: 0.021640; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,374 root         INFO     ====> Epoch: 189 Average loss: 0.0851\n",
      "2019-04-09 20:46:07,398 root         INFO     Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 0.082013\n",
      "Reconstruction: 0.049449, Regularization: 0.000042, Discriminator: 0.021692; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,465 root         INFO     Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 0.082158\n",
      "Reconstruction: 0.049621, Regularization: 0.000043, Discriminator: 0.021666; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,532 root         INFO     Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 0.077779\n",
      "Reconstruction: 0.045300, Regularization: 0.000037, Discriminator: 0.021605; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,598 root         INFO     Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 0.079979\n",
      "Reconstruction: 0.047402, Regularization: 0.000040, Discriminator: 0.021701; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,665 root         INFO     Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 0.087164\n",
      "Reconstruction: 0.054646, Regularization: 0.000051, Discriminator: 0.021642; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,731 root         INFO     Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 0.094117\n",
      "Reconstruction: 0.061609, Regularization: 0.000059, Discriminator: 0.021602; Generator: 0.010847,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 20:46:07,797 root         INFO     Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 0.105313\n",
      "Reconstruction: 0.072769, Regularization: 0.000071, Discriminator: 0.021638; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,864 root         INFO     Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 0.083051\n",
      "Reconstruction: 0.050456, Regularization: 0.000045, Discriminator: 0.021714; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:07,932 root         INFO     ====> Epoch: 190 Average loss: 0.0851\n",
      "2019-04-09 20:46:07,956 root         INFO     Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 0.090551\n",
      "Reconstruction: 0.058024, Regularization: 0.000054, Discriminator: 0.021642; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,023 root         INFO     Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 0.088653\n",
      "Reconstruction: 0.055976, Regularization: 0.000053, Discriminator: 0.021792; Generator: 0.010832,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,090 root         INFO     Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 0.076520\n",
      "Reconstruction: 0.043977, Regularization: 0.000038, Discriminator: 0.021686; Generator: 0.010818,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,157 root         INFO     Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 0.092403\n",
      "Reconstruction: 0.059905, Regularization: 0.000058, Discriminator: 0.021613; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,223 root         INFO     Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 0.098188\n",
      "Reconstruction: 0.065629, Regularization: 0.000064, Discriminator: 0.021662; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,291 root         INFO     Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 0.099067\n",
      "Reconstruction: 0.066488, Regularization: 0.000063, Discriminator: 0.021674; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,359 root         INFO     Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 0.080836\n",
      "Reconstruction: 0.048314, Regularization: 0.000041, Discriminator: 0.021643; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,427 root         INFO     Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 0.082957\n",
      "Reconstruction: 0.050426, Regularization: 0.000045, Discriminator: 0.021649; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,496 root         INFO     ====> Epoch: 191 Average loss: 0.0851\n",
      "2019-04-09 20:46:08,520 root         INFO     Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 0.080228\n",
      "Reconstruction: 0.047677, Regularization: 0.000042, Discriminator: 0.021671; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,588 root         INFO     Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 0.083430\n",
      "Reconstruction: 0.050908, Regularization: 0.000047, Discriminator: 0.021646; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,655 root         INFO     Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.092959\n",
      "Reconstruction: 0.060359, Regularization: 0.000057, Discriminator: 0.021711; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,721 root         INFO     Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 0.091347\n",
      "Reconstruction: 0.058851, Regularization: 0.000056, Discriminator: 0.021598; Generator: 0.010842,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,788 root         INFO     Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 0.079507\n",
      "Reconstruction: 0.046926, Regularization: 0.000040, Discriminator: 0.021700; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,855 root         INFO     Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 0.085982\n",
      "Reconstruction: 0.053474, Regularization: 0.000050, Discriminator: 0.021623; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,919 root         INFO     Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 0.084727\n",
      "Reconstruction: 0.052219, Regularization: 0.000047, Discriminator: 0.021619; Generator: 0.010843,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:08,983 root         INFO     Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 0.076747\n",
      "Reconstruction: 0.044191, Regularization: 0.000037, Discriminator: 0.021688; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,049 root         INFO     ====> Epoch: 192 Average loss: 0.0851\n",
      "2019-04-09 20:46:09,072 root         INFO     Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 0.091213\n",
      "Reconstruction: 0.058594, Regularization: 0.000055, Discriminator: 0.021737; Generator: 0.010827,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,139 root         INFO     Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 0.080673\n",
      "Reconstruction: 0.048101, Regularization: 0.000042, Discriminator: 0.021699; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,206 root         INFO     Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 0.077518\n",
      "Reconstruction: 0.045026, Regularization: 0.000037, Discriminator: 0.021626; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,272 root         INFO     Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 0.082535\n",
      "Reconstruction: 0.050009, Regularization: 0.000042, Discriminator: 0.021650; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,339 root         INFO     Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 0.076568\n",
      "Reconstruction: 0.044069, Regularization: 0.000035, Discriminator: 0.021637; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,406 root         INFO     Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 0.090691\n",
      "Reconstruction: 0.058138, Regularization: 0.000052, Discriminator: 0.021670; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,473 root         INFO     Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 0.087585\n",
      "Reconstruction: 0.055051, Regularization: 0.000048, Discriminator: 0.021647; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,539 root         INFO     Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 0.077403\n",
      "Reconstruction: 0.044828, Regularization: 0.000037, Discriminator: 0.021695; Generator: 0.010843,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,607 root         INFO     ====> Epoch: 193 Average loss: 0.0851\n",
      "2019-04-09 20:46:09,631 root         INFO     Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 0.085436\n",
      "Reconstruction: 0.052846, Regularization: 0.000047, Discriminator: 0.021710; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,699 root         INFO     Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 0.076557\n",
      "Reconstruction: 0.044088, Regularization: 0.000035, Discriminator: 0.021602; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,765 root         INFO     Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 0.094281\n",
      "Reconstruction: 0.061711, Regularization: 0.000055, Discriminator: 0.021672; Generator: 0.010843,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,832 root         INFO     Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 0.084972\n",
      "Reconstruction: 0.052505, Regularization: 0.000043, Discriminator: 0.021587; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,899 root         INFO     Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 0.085208\n",
      "Reconstruction: 0.052598, Regularization: 0.000042, Discriminator: 0.021728; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:09,965 root         INFO     Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 0.074716\n",
      "Reconstruction: 0.042132, Regularization: 0.000031, Discriminator: 0.021724; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,031 root         INFO     Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 0.106857\n",
      "Reconstruction: 0.074325, Regularization: 0.000068, Discriminator: 0.021640; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,097 root         INFO     Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 0.078308\n",
      "Reconstruction: 0.045763, Regularization: 0.000037, Discriminator: 0.021674; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,166 root         INFO     ====> Epoch: 194 Average loss: 0.0851\n",
      "2019-04-09 20:46:10,190 root         INFO     Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 0.096499\n",
      "Reconstruction: 0.063950, Regularization: 0.000058, Discriminator: 0.021658; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,256 root         INFO     Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 0.087113\n",
      "Reconstruction: 0.054540, Regularization: 0.000048, Discriminator: 0.021694; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,321 root         INFO     Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 0.079589\n",
      "Reconstruction: 0.047071, Regularization: 0.000038, Discriminator: 0.021656; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,388 root         INFO     Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 0.083695\n",
      "Reconstruction: 0.051230, Regularization: 0.000042, Discriminator: 0.021588; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,452 root         INFO     Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 0.079723\n",
      "Reconstruction: 0.047184, Regularization: 0.000037, Discriminator: 0.021662; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,515 root         INFO     Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 0.089952\n",
      "Reconstruction: 0.057362, Regularization: 0.000048, Discriminator: 0.021715; Generator: 0.010827,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,579 root         INFO     Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 0.093241\n",
      "Reconstruction: 0.060755, Regularization: 0.000052, Discriminator: 0.021597; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,642 root         INFO     Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 0.071966\n",
      "Reconstruction: 0.039404, Regularization: 0.000028, Discriminator: 0.021697; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,708 root         INFO     ====> Epoch: 195 Average loss: 0.0851\n",
      "2019-04-09 20:46:10,732 root         INFO     Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 0.087331\n",
      "Reconstruction: 0.054805, Regularization: 0.000046, Discriminator: 0.021645; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,799 root         INFO     Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 0.098495\n",
      "Reconstruction: 0.065839, Regularization: 0.000058, Discriminator: 0.021765; Generator: 0.010833,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,866 root         INFO     Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 0.096588\n",
      "Reconstruction: 0.064048, Regularization: 0.000055, Discriminator: 0.021657; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:10,933 root         INFO     Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 0.075133\n",
      "Reconstruction: 0.042618, Regularization: 0.000033, Discriminator: 0.021652; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,000 root         INFO     Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 0.092012\n",
      "Reconstruction: 0.059428, Regularization: 0.000054, Discriminator: 0.021690; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,067 root         INFO     Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 0.079682\n",
      "Reconstruction: 0.047129, Regularization: 0.000038, Discriminator: 0.021681; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,134 root         INFO     Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 0.081183\n",
      "Reconstruction: 0.048638, Regularization: 0.000039, Discriminator: 0.021676; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,204 root         INFO     Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 0.083140\n",
      "Reconstruction: 0.050651, Regularization: 0.000042, Discriminator: 0.021615; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,273 root         INFO     ====> Epoch: 196 Average loss: 0.0851\n",
      "2019-04-09 20:46:11,298 root         INFO     Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 0.073744\n",
      "Reconstruction: 0.041217, Regularization: 0.000029, Discriminator: 0.021657; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,364 root         INFO     Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 0.084057\n",
      "Reconstruction: 0.051506, Regularization: 0.000041, Discriminator: 0.021675; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,432 root         INFO     Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 0.095684\n",
      "Reconstruction: 0.063112, Regularization: 0.000055, Discriminator: 0.021684; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,499 root         INFO     Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 0.079876\n",
      "Reconstruction: 0.047337, Regularization: 0.000037, Discriminator: 0.021668; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,566 root         INFO     Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 0.097306\n",
      "Reconstruction: 0.064744, Regularization: 0.000056, Discriminator: 0.021670; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,634 root         INFO     Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 0.087011\n",
      "Reconstruction: 0.054345, Regularization: 0.000045, Discriminator: 0.021794; Generator: 0.010826,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,703 root         INFO     Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 0.081399\n",
      "Reconstruction: 0.048862, Regularization: 0.000041, Discriminator: 0.021664; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,771 root         INFO     Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 0.085223\n",
      "Reconstruction: 0.052605, Regularization: 0.000045, Discriminator: 0.021738; Generator: 0.010835,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,839 root         INFO     ====> Epoch: 197 Average loss: 0.0851\n",
      "2019-04-09 20:46:11,863 root         INFO     Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 0.100256\n",
      "Reconstruction: 0.067656, Regularization: 0.000061, Discriminator: 0.021700; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,931 root         INFO     Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.080639\n",
      "Reconstruction: 0.048200, Regularization: 0.000040, Discriminator: 0.021568; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 20:46:11,999 root         INFO     Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 0.089857\n",
      "Reconstruction: 0.057323, Regularization: 0.000050, Discriminator: 0.021649; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,062 root         INFO     Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 0.082129\n",
      "Reconstruction: 0.049546, Regularization: 0.000040, Discriminator: 0.021711; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,125 root         INFO     Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 0.088849\n",
      "Reconstruction: 0.056331, Regularization: 0.000050, Discriminator: 0.021638; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,192 root         INFO     Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 0.086933\n",
      "Reconstruction: 0.054424, Regularization: 0.000046, Discriminator: 0.021625; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,259 root         INFO     Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 0.091223\n",
      "Reconstruction: 0.058711, Regularization: 0.000053, Discriminator: 0.021622; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,326 root         INFO     Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 0.078295\n",
      "Reconstruction: 0.045749, Regularization: 0.000037, Discriminator: 0.021674; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,394 root         INFO     ====> Epoch: 198 Average loss: 0.0851\n",
      "2019-04-09 20:46:12,418 root         INFO     Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 0.084813\n",
      "Reconstruction: 0.052270, Regularization: 0.000045, Discriminator: 0.021663; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,485 root         INFO     Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 0.076462\n",
      "Reconstruction: 0.043859, Regularization: 0.000033, Discriminator: 0.021735; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,552 root         INFO     Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 0.094921\n",
      "Reconstruction: 0.062379, Regularization: 0.000056, Discriminator: 0.021655; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,619 root         INFO     Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 0.084170\n",
      "Reconstruction: 0.051614, Regularization: 0.000044, Discriminator: 0.021663; Generator: 0.010849,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 20:46:12,686 root         INFO     Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 0.078080\n",
      "Reconstruction: 0.045505, Regularization: 0.000037, Discriminator: 0.021702; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,751 root         INFO     Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 0.080512\n",
      "Reconstruction: 0.048049, Regularization: 0.000040, Discriminator: 0.021592; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,817 root         INFO     Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.083568\n",
      "Reconstruction: 0.051006, Regularization: 0.000044, Discriminator: 0.021691; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,883 root         INFO     Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 0.077778\n",
      "Reconstruction: 0.045282, Regularization: 0.000038, Discriminator: 0.021629; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 20:46:12,951 root         INFO     ====> Epoch: 199 Average loss: 0.0851\n",
      "2019-04-09 20:46:12,964 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) done      TrainVEM()\n",
      "2019-04-09 20:46:12,964 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 20:46:12,964 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   DONE\n",
      "2019-04-09 20:46:12,965 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 20:46:12,965 luigi-interface DEBUG    Pending tasks: 1\n",
      "2019-04-09 20:46:12,965 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) running   RunAll()\n",
      "2019-04-09 20:46:12,965 luigi-interface INFO     [pid 14447] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) done      RunAll()\n",
      "2019-04-09 20:46:12,966 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 20:46:12,966 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   DONE\n",
      "2019-04-09 20:46:12,966 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 20:46:12,966 luigi-interface DEBUG    Done\n",
      "2019-04-09 20:46:12,966 luigi-interface DEBUG    There are no more tasks to run at this time\n",
      "2019-04-09 20:46:12,966 luigi-interface INFO     Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=14447) was stopped. Shutting down Keep-Alive thread\n",
      "2019-04-09 20:46:12,967 luigi-interface INFO     \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 4 tasks of which:\n",
      "* 4 ran successfully:\n",
      "    - 1 MakeDataSet()\n",
      "    - 1 RunAll()\n",
      "    - 1 TrainVAE()\n",
      "    - 1 TrainVEM()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pattern = 'logs'\n",
    "logs = []\n",
    "for filename in os.listdir(OUTPUT):\n",
    "    if re.search(pattern, filename):\n",
    "        logs.append(filename)\n",
    "\n",
    "for filename in logs:\n",
    "    path = os.path.join(OUTPUT, filename)\n",
    "    print('\\n-- Log file: %s\\n' % filename)\n",
    "    with open(path, 'r') as f:\n",
    "        message = f.read()\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
