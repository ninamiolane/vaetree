{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import importlib\n",
    "import toylosses\n",
    "importlib.reload(toylosses)\n",
    "import toynn\n",
    "importlib.reload(toynn)\n",
    "import toyvis\n",
    "importlib.reload(toyvis)\n",
    "\n",
    "import torch\n",
    "sns.set()\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "OUTPUT = '/scratch/users/nmiolane/toyoutput'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide on experiment's configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight tensor([[ 0.6000],\n",
      "        [-0.7000]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0.0000, -0.1000], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.3.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.3.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.4.weight tensor([[200.,   0.],\n",
      "        [  0., -80.]], device='cuda:0') \n",
      "\n",
      "layers.4.bias tensor([2.0000, 2.4000], device='cuda:0') \n",
      "\n",
      "layers.5.weight tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0') \n",
      "\n",
      "layers.5.bias tensor([0., 0.], device='cuda:0') \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.589937409613567, 49.15128911130917, -5.1637784314807575, 12.825178651499087)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_DIM = 2\n",
    "LATENT_DIM = 1\n",
    "N_DECODER_LAYERS = 5\n",
    "NONLINEARITY = False\n",
    "N_SAMPLES = 10000\n",
    "WITH_BIASX = True\n",
    "WITH_LOGVARX = True\n",
    "\n",
    "W_TRUE = {}\n",
    "B_TRUE = {}\n",
    "\n",
    "W_TRUE[0] = [[0.6], [-0.7]]\n",
    "B_TRUE[0] = [0., -0.1]\n",
    "\n",
    "W_TRUE[1] = [[0.1, -0.1], [-0.1, .1]]\n",
    "B_TRUE[1] = [0.1, 0.]\n",
    "\n",
    "W_TRUE[2] = [[0.1, -0.1], [-0.1, .1]]\n",
    "B_TRUE[2] = [0.1, 0.]\n",
    "\n",
    "W_TRUE[3] = [[0.1, -0.1], [-0.1, .1]]\n",
    "B_TRUE[3] = [0.1, 0.]\n",
    "\n",
    "# For the reconstruction\n",
    "W_TRUE[4] = [[200., 0.], [0., -80.]]\n",
    "B_TRUE[4] = [2., 2.4]\n",
    "\n",
    "# For the logvarx\n",
    "W_TRUE[5] = [[0., 0.], [0., 0.]]\n",
    "B_TRUE[5] = [0., 0.]\n",
    "\n",
    "if WITH_LOGVARX:\n",
    "    assert len(W_TRUE) == N_DECODER_LAYERS + 1, len(W_TRUE)\n",
    "else:\n",
    "    assert len(W_TRUE) == N_DECODER_LAYERS\n",
    "\n",
    "WITH_BIASZ = True\n",
    "WITH_LOGVARZ = True\n",
    "\n",
    "decoder_true = toynn.make_decoder_true(\n",
    "    w_true=W_TRUE, b_true=B_TRUE, latent_dim=LATENT_DIM, \n",
    "    data_dim=DATA_DIM, n_layers=N_DECODER_LAYERS,\n",
    "    nonlinearity=NONLINEARITY, with_biasx=WITH_BIASX, with_logvarx=WITH_LOGVARX)\n",
    "\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, N_SAMPLES)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = toyvis.plot_data(generated_true_x, color='green', label='from decoder true', ax=ax)\n",
    "ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect generation of synthetic data from decoder_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight tensor([[ 0.6000],\n",
      "        [-0.7000]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0.0000, -0.1000], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.3.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.3.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.4.weight tensor([[200.,   0.],\n",
      "        [  0., -80.]], device='cuda:0') \n",
      "\n",
      "layers.4.bias tensor([2.0000, 2.4000], device='cuda:0') \n",
      "\n",
      "layers.5.weight tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0') \n",
      "\n",
      "layers.5.bias tensor([0., 0.], device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(nina): Add a comparison to a FA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results from standard VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[ 0.6000],\n",
      "        [-0.7000]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0.0000, -0.1000], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.3.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.3.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.4.weight tensor([[200.,   0.],\n",
      "        [  0., -80.]], device='cuda:0') \n",
      "\n",
      "layers.4.bias tensor([2.0000, 2.4000], device='cuda:0') \n",
      "\n",
      "layers.5.weight tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0') \n",
      "\n",
      "layers.5.bias tensor([0., 0.], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[0.9612],\n",
      "        [0.0397]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([-1.4925, -1.2341], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[-0.3266, -0.8483],\n",
      "        [ 0.2948,  0.8764]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([ 0.6886, -0.7158], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[-1.4020,  1.2327],\n",
      "        [ 0.6599, -1.1146]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([-1.4971,  0.6876], device='cuda:0') \n",
      "\n",
      "layers.3.weight tensor([[1.5803, 0.7515],\n",
      "        [0.5318, 1.1653]], device='cuda:0') \n",
      "\n",
      "layers.3.bias tensor([-0.3550,  0.0500], device='cuda:0') \n",
      "\n",
      "layers.4.weight tensor([[-2.2671,  1.3806],\n",
      "        [-0.2031,  0.4166]], device='cuda:0') \n",
      "\n",
      "layers.4.bias tensor([ 1.2910, -0.1538], device='cuda:0') \n",
      "\n",
      "layers.5.weight tensor([[ 0.5819,  1.4066],\n",
      "        [-0.1543,  0.2010]], device='cuda:0') \n",
      "\n",
      "layers.5.bias tensor([ 0.7268, -0.6223], device='cuda:0') \n",
      "\n",
      "Last losses:\n",
      "[0.1651371484398842, 0.16452492243051528, 0.1653072493672371, 0.16482117563486098, 0.1647257022857666]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "decoder_path = glob.glob(f'{OUTPUT}/train_vae/models/decoder.pth')[0]\n",
    "decoder = torch.load(decoder_path, map_location=DEVICE)\n",
    "\n",
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "losses_vae_path = glob.glob(f'{OUTPUT}/train_vae/train_losses.pkl')[0]\n",
    "train_losses_all_epochs = pickle.load(open(losses_vae_path, 'rb'))\n",
    "\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 4))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(range(n_epochs), train_losses_total)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(range(90, n_epochs), train_losses_total[90:])\n",
    "\n",
    "ax = axes[2]\n",
    "ax.plot(range(160, n_epochs), train_losses_total[160:])\n",
    "\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.932596425902527, 48.52487879272248, -5.322159156406135, 14.098331282448296)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "\n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "\n",
    "\n",
    "ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results from VEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[ 0.6000],\n",
      "        [-0.7000]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0.0000, -0.1000], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.3.weight tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0') \n",
      "\n",
      "layers.3.bias tensor([0.1000, 0.0000], device='cuda:0') \n",
      "\n",
      "layers.4.weight tensor([[200.,   0.],\n",
      "        [  0., -80.]], device='cuda:0') \n",
      "\n",
      "layers.4.bias tensor([2.0000, 2.4000], device='cuda:0') \n",
      "\n",
      "layers.5.weight tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0') \n",
      "\n",
      "layers.5.bias tensor([0., 0.], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[0.5482],\n",
      "        [0.4446]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 1.2498, -1.2086], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[-0.9312,  0.7286],\n",
      "        [ 1.0973, -1.4389]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([-0.9389,  0.1014], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 1.0707, -2.4687],\n",
      "        [-1.0423,  0.2618]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([-1.0260,  0.6529], device='cuda:0') \n",
      "\n",
      "layers.3.weight tensor([[ 1.2629,  0.6055],\n",
      "        [ 0.5306, -0.4852]], device='cuda:0') \n",
      "\n",
      "layers.3.bias tensor([0.5281, 0.0176], device='cuda:0') \n",
      "\n",
      "layers.4.weight tensor([[-1.8671,  0.2991],\n",
      "        [-1.0273, -1.8860]], device='cuda:0') \n",
      "\n",
      "layers.4.bias tensor([ 0.7741, -0.5696], device='cuda:0') \n",
      "\n",
      "layers.5.weight tensor([[-1.2318, -0.1295],\n",
      "        [-0.8036, -0.8898]], device='cuda:0') \n",
      "\n",
      "layers.5.bias tensor([0.2400, 0.1101], device='cuda:0') \n",
      "\n",
      "Last losses:\n",
      "[0.44372431313991545, 0.43401740276813505, 0.44335367715358737, 0.4390900332927704, 0.43741486537456514]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "decoder_path = glob.glob(f'{OUTPUT}/train_vem/models/decoder.pth')[0]\n",
    "decoder = torch.load(decoder_path, map_location=DEVICE)\n",
    "\n",
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "losses_vae_path = glob.glob(f'{OUTPUT}/train_vem/train_losses.pkl')[0]\n",
    "train_losses_all_epochs = pickle.load(open(losses_vae_path, 'rb'))\n",
    "\n",
    "plt.figure()\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "plt.plot(range(n_epochs), train_losses_total)\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4694.484628470988, 6473.78141599027, -62.99463872206656, 61.88333811686791)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "\n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='orange', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(generated_x, color='orange', ax=ax)\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "\n",
    "ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print pipeline logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 log files.\n",
      "\n",
      "-- Log file: logs2019-04-10 00:55:18.169271.txt\n",
      "\n",
      "2019-04-10 00:55:18,169 root         INFO     start\n",
      "2019-04-10 00:55:18,184 luigi        INFO     logging configured by default settings\n",
      "2019-04-10 00:55:18,188 luigi-interface DEBUG    Checking if RunAll() is complete\n",
      "2019-04-10 00:55:18,188 luigi-interface DEBUG    Checking if TrainVAE() is complete\n",
      "2019-04-10 00:55:18,189 luigi-interface DEBUG    Checking if TrainVEM() is complete\n",
      "2019-04-10 00:55:18,189 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   PENDING\n",
      "2019-04-10 00:55:18,190 luigi-interface DEBUG    Checking if MakeDataSet() is complete\n",
      "2019-04-10 00:55:18,190 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   PENDING\n",
      "2019-04-10 00:55:18,191 luigi-interface INFO     Informed scheduler that task   MakeDataSet__99914b932b   has status   PENDING\n",
      "2019-04-10 00:55:18,191 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   PENDING\n",
      "2019-04-10 00:55:18,191 luigi-interface INFO     Done scheduling tasks\n",
      "2019-04-10 00:55:18,191 luigi-interface INFO     Running Worker with 1 processes\n",
      "2019-04-10 00:55:18,192 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-10 00:55:18,192 luigi-interface DEBUG    Pending tasks: 4\n",
      "2019-04-10 00:55:18,192 luigi-interface INFO     [pid 1925] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=1925) running   MakeDataSet()\n",
      "2019-04-10 00:55:18,193 root         INFO     Configuration:\n",
      "2019-04-10 00:55:18,193 root         INFO     DATA_DIM = 2\n",
      "2019-04-10 00:55:18,193 root         INFO     LATENT_DIM = 1\n",
      "2019-04-10 00:55:18,193 root         INFO     N_DECODER_LAYERS = 5\n",
      "2019-04-10 00:55:18,193 root         INFO     NONLINEARITY=False\n",
      "2019-04-10 00:55:18,193 root         INFO     WITH_BIASX=True\n",
      "2019-04-10 00:55:18,193 root         INFO     WITH_LOGVARX=True\n",
      "2019-04-10 00:55:18,193 root         INFO     WITH_BIASZ=True\n",
      "2019-04-10 00:55:18,193 root         INFO     WITH_LOGVARZ=True\n",
      "2019-04-10 00:55:18,193 root         INFO     N_SAMPLES=10000\n",
      "2019-04-10 00:55:18,193 root         INFO     W_TRUE:\n",
      "2019-04-10 00:55:18,193 root         INFO     {0: [[0.6], [-0.7]], 1: [[0.1, -0.1], [-0.1, 0.1]], 2: [[0.1, -0.1], [-0.1, 0.1]], 3: [[0.1, -0.1], [-0.1, 0.1]], 4: [[200.0, 0.0], [0.0, -80.0]], 5: [[0.0, 0.0], [0.0, 0.0]]}\n",
      "2019-04-10 00:55:18,194 root         INFO     B_TRUE:\n",
      "2019-04-10 00:55:18,194 root         INFO     {0: [0.0, -0.1], 1: [0.1, 0.0], 2: [0.1, 0.0], 3: [0.1, 0.0], 4: [2.0, 2.4], 5: [0.0, 0.0]}\n",
      "2019-04-10 00:55:22,009 root         INFO     Values of true 'decoder' parameters:\n",
      "2019-04-10 00:55:22,009 root         INFO     layers.0.weight\n",
      "2019-04-10 00:55:22,009 root         INFO     tensor([[ 0.6000],\n",
      "        [-0.7000]], device='cuda:0')\n",
      "2019-04-10 00:55:22,030 root         INFO     layers.0.bias\n",
      "2019-04-10 00:55:22,030 root         INFO     tensor([ 0.0000, -0.1000], device='cuda:0')\n",
      "2019-04-10 00:55:22,031 root         INFO     layers.1.weight\n",
      "2019-04-10 00:55:22,031 root         INFO     tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0')\n",
      "2019-04-10 00:55:22,032 root         INFO     layers.1.bias\n",
      "2019-04-10 00:55:22,032 root         INFO     tensor([0.1000, 0.0000], device='cuda:0')\n",
      "2019-04-10 00:55:22,033 root         INFO     layers.2.weight\n",
      "2019-04-10 00:55:22,033 root         INFO     tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0')\n",
      "2019-04-10 00:55:22,034 root         INFO     layers.2.bias\n",
      "2019-04-10 00:55:22,034 root         INFO     tensor([0.1000, 0.0000], device='cuda:0')\n",
      "2019-04-10 00:55:22,035 root         INFO     layers.3.weight\n",
      "2019-04-10 00:55:22,035 root         INFO     tensor([[ 0.1000, -0.1000],\n",
      "        [-0.1000,  0.1000]], device='cuda:0')\n",
      "2019-04-10 00:55:22,037 root         INFO     layers.3.bias\n",
      "2019-04-10 00:55:22,037 root         INFO     tensor([0.1000, 0.0000], device='cuda:0')\n",
      "2019-04-10 00:55:22,038 root         INFO     layers.4.weight\n",
      "2019-04-10 00:55:22,038 root         INFO     tensor([[200.,   0.],\n",
      "        [  0., -80.]], device='cuda:0')\n",
      "2019-04-10 00:55:22,039 root         INFO     layers.4.bias\n",
      "2019-04-10 00:55:22,039 root         INFO     tensor([2.0000, 2.4000], device='cuda:0')\n",
      "2019-04-10 00:55:22,040 root         INFO     layers.5.weight\n",
      "2019-04-10 00:55:22,040 root         INFO     tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "2019-04-10 00:55:22,040 root         INFO     layers.5.bias\n",
      "2019-04-10 00:55:22,041 root         INFO     tensor([0., 0.], device='cuda:0')\n",
      "2019-04-10 00:55:22,149 luigi-interface INFO     [pid 1925] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=1925) done      MakeDataSet()\n",
      "2019-04-10 00:55:22,150 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-10 00:55:22,150 luigi-interface INFO     Informed scheduler that task   MakeDataSet__99914b932b   has status   DONE\n",
      "2019-04-10 00:55:22,150 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-10 00:55:22,150 luigi-interface DEBUG    Pending tasks: 3\n",
      "2019-04-10 00:55:22,151 luigi-interface INFO     [pid 1925] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=1925) running   TrainVEM()\n",
      "2019-04-10 00:55:22,152 root         INFO     --Dataset tensor: (10000, 2)\n",
      "2019-04-10 00:55:22,153 root         INFO     -- Train tensor: (8000, 2)\n",
      "2019-04-10 00:55:22,154 root         INFO     Values of VEM's decoder parameters before training:\n",
      "2019-04-10 00:55:22,154 root         INFO     layers.0.weight\n",
      "2019-04-10 00:55:22,154 root         INFO     tensor([[-0.0526],\n",
      "        [-0.2078]], device='cuda:0')\n",
      "2019-04-10 00:55:22,155 root         INFO     layers.0.bias\n",
      "2019-04-10 00:55:22,155 root         INFO     tensor([ 0.3363, -0.4224], device='cuda:0')\n",
      "2019-04-10 00:55:22,156 root         INFO     layers.1.weight\n",
      "2019-04-10 00:55:22,156 root         INFO     tensor([[ 0.2904, -0.4362],\n",
      "        [-0.2126,  0.5412]], device='cuda:0')\n",
      "2019-04-10 00:55:22,157 root         INFO     layers.1.bias\n",
      "2019-04-10 00:55:22,157 root         INFO     tensor([ 0.0693, -0.5593], device='cuda:0')\n",
      "2019-04-10 00:55:22,158 root         INFO     layers.2.weight\n",
      "2019-04-10 00:55:22,159 root         INFO     tensor([[ 0.4248, -0.4699],\n",
      "        [-0.0456, -0.0020]], device='cuda:0')\n",
      "2019-04-10 00:55:22,160 root         INFO     layers.2.bias\n",
      "2019-04-10 00:55:22,160 root         INFO     tensor([-0.3116,  0.3165], device='cuda:0')\n",
      "2019-04-10 00:55:22,161 root         INFO     layers.3.weight\n",
      "2019-04-10 00:55:22,161 root         INFO     tensor([[-0.0699,  0.3861],\n",
      "        [ 0.3593, -0.5530]], device='cuda:0')\n",
      "2019-04-10 00:55:22,162 root         INFO     layers.3.bias\n",
      "2019-04-10 00:55:22,162 root         INFO     tensor([0.5281, 0.0176], device='cuda:0')\n",
      "2019-04-10 00:55:22,163 root         INFO     layers.4.weight\n",
      "2019-04-10 00:55:22,163 root         INFO     tensor([[ 0.5583,  0.4401],\n",
      "        [-0.2079, -0.1400]], device='cuda:0')\n",
      "2019-04-10 00:55:22,164 root         INFO     layers.4.bias\n",
      "2019-04-10 00:55:22,164 root         INFO     tensor([-0.2586, -0.3348], device='cuda:0')\n",
      "2019-04-10 00:55:22,165 root         INFO     layers.5.weight\n",
      "2019-04-10 00:55:22,165 root         INFO     tensor([[0.5477, 0.6593],\n",
      "        [0.3130, 0.6352]], device='cuda:0')\n",
      "2019-04-10 00:55:22,166 root         INFO     layers.5.bias\n",
      "2019-04-10 00:55:22,166 root         INFO     tensor([0.2400, 0.1101], device='cuda:0')\n",
      "2019-04-10 00:55:22,240 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 18.402164\n",
      "Reconstruction: 16.903975, Regularization: 0.414003, Discriminator: 1.079039; Generator: 0.005147,\n",
      "D(x): 0.000, D(G(z)): 0.848\n",
      "2019-04-10 00:55:22,362 root         INFO     Train Epoch: 0 [512/8000 (6%)]\tTotal Loss: 14.873638\n",
      "Reconstruction: 13.554897, Regularization: 0.352149, Discriminator: 0.961879; Generator: 0.004713,\n",
      "D(x): 0.000, D(G(z)): 0.860\n",
      "2019-04-10 00:55:22,472 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 14.322220\n",
      "Reconstruction: 13.067829, Regularization: 0.335233, Discriminator: 0.914039; Generator: 0.005119,\n",
      "D(x): 0.000, D(G(z)): 0.849\n",
      "2019-04-10 00:55:22,581 root         INFO     Train Epoch: 0 [1536/8000 (19%)]\tTotal Loss: 16.720507\n",
      "Reconstruction: 15.390631, Regularization: 0.362313, Discriminator: 0.962442; Generator: 0.005121,\n",
      "D(x): 0.000, D(G(z)): 0.849\n",
      "2019-04-10 00:55:22,690 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 15.075704\n",
      "Reconstruction: 13.817432, Regularization: 0.334537, Discriminator: 0.918702; Generator: 0.005031,\n",
      "D(x): 0.000, D(G(z)): 0.852\n",
      "2019-04-10 00:55:22,799 root         INFO     Train Epoch: 0 [2560/8000 (32%)]\tTotal Loss: 17.618729\n",
      "Reconstruction: 16.275896, Regularization: 0.364545, Discriminator: 0.973155; Generator: 0.005133,\n",
      "D(x): 0.000, D(G(z)): 0.849\n",
      "2019-04-10 00:55:22,908 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 15.180911\n",
      "Reconstruction: 13.984457, Regularization: 0.320031, Discriminator: 0.871012; Generator: 0.005411,\n",
      "D(x): 0.000, D(G(z)): 0.841\n",
      "2019-04-10 00:55:23,017 root         INFO     Train Epoch: 0 [3584/8000 (45%)]\tTotal Loss: 15.312880\n",
      "Reconstruction: 14.124370, Regularization: 0.315860, Discriminator: 0.867180; Generator: 0.005470,\n",
      "D(x): 0.000, D(G(z)): 0.840\n",
      "2019-04-10 00:55:23,126 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 15.771794\n",
      "Reconstruction: 14.603186, Regularization: 0.313317, Discriminator: 0.849833; Generator: 0.005458,\n",
      "D(x): 0.000, D(G(z)): 0.840\n",
      "2019-04-10 00:55:23,235 root         INFO     Train Epoch: 0 [4608/8000 (58%)]\tTotal Loss: 18.249220\n",
      "Reconstruction: 16.995396, Regularization: 0.340847, Discriminator: 0.907654; Generator: 0.005322,\n",
      "D(x): 0.002, D(G(z)): 0.844\n",
      "2019-04-10 00:55:23,344 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 16.657240\n",
      "Reconstruction: 15.479665, Regularization: 0.315959, Discriminator: 0.856272; Generator: 0.005344,\n",
      "D(x): 0.000, D(G(z)): 0.843\n",
      "2019-04-10 00:55:23,453 root         INFO     Train Epoch: 0 [5632/8000 (70%)]\tTotal Loss: 17.197477\n",
      "Reconstruction: 16.003288, Regularization: 0.318439, Discriminator: 0.870241; Generator: 0.005508,\n",
      "D(x): 0.000, D(G(z)): 0.839\n",
      "2019-04-10 00:55:23,563 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 16.528212\n",
      "Reconstruction: 15.398626, Regularization: 0.301138, Discriminator: 0.823014; Generator: 0.005434,\n",
      "D(x): 0.000, D(G(z)): 0.841\n",
      "2019-04-10 00:55:23,672 root         INFO     Train Epoch: 0 [6656/8000 (83%)]\tTotal Loss: 17.035700\n",
      "Reconstruction: 15.887972, Regularization: 0.304038, Discriminator: 0.838222; Generator: 0.005467,\n",
      "D(x): 0.000, D(G(z)): 0.840\n",
      "2019-04-10 00:55:23,782 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 16.341021\n",
      "Reconstruction: 15.264828, Regularization: 0.287378, Discriminator: 0.783134; Generator: 0.005682,\n",
      "D(x): 0.000, D(G(z)): 0.834\n",
      "2019-04-10 00:55:23,893 root         INFO     Train Epoch: 0 [7680/8000 (96%)]\tTotal Loss: 14.913841\n",
      "Reconstruction: 13.900007, Regularization: 0.265170, Discriminator: 0.742872; Generator: 0.005793,\n",
      "D(x): 0.000, D(G(z)): 0.831\n",
      "2019-04-10 00:55:23,973 root         INFO     ====> Epoch: 0 Average loss: 16.4691\n",
      "2019-04-10 00:55:24,000 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 17.639872\n",
      "Reconstruction: 16.554617, Regularization: 0.289846, Discriminator: 0.789695; Generator: 0.005714,\n",
      "D(x): 0.000, D(G(z)): 0.833\n",
      "2019-04-10 00:55:24,113 root         INFO     Train Epoch: 1 [512/8000 (6%)]\tTotal Loss: 20.301348\n",
      "Reconstruction: 19.146629, Regularization: 0.311848, Discriminator: 0.837000; Generator: 0.005871,\n",
      "D(x): 0.000, D(G(z)): 0.829\n",
      "2019-04-10 00:55:24,225 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 19.879028\n",
      "Reconstruction: 18.768600, Regularization: 0.299008, Discriminator: 0.805544; Generator: 0.005877,\n",
      "D(x): 0.000, D(G(z)): 0.829\n",
      "2019-04-10 00:55:24,338 root         INFO     Train Epoch: 1 [1536/8000 (19%)]\tTotal Loss: 18.128071\n",
      "Reconstruction: 17.067663, Regularization: 0.279884, Discriminator: 0.774356; Generator: 0.006168,\n",
      "D(x): 0.000, D(G(z)): 0.821\n",
      "2019-04-10 00:55:24,450 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 17.082636\n",
      "Reconstruction: 16.096815, Regularization: 0.259742, Discriminator: 0.719990; Generator: 0.006089,\n",
      "D(x): 0.000, D(G(z)): 0.823\n",
      "2019-04-10 00:55:24,562 root         INFO     Train Epoch: 1 [2560/8000 (32%)]\tTotal Loss: 17.913795\n",
      "Reconstruction: 16.923403, Regularization: 0.261063, Discriminator: 0.723272; Generator: 0.006059,\n",
      "D(x): 0.000, D(G(z)): 0.824\n",
      "2019-04-10 00:55:24,674 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 16.868818\n",
      "Reconstruction: 15.937393, Regularization: 0.244577, Discriminator: 0.680843; Generator: 0.006005,\n",
      "D(x): 0.000, D(G(z)): 0.825\n",
      "2019-04-10 00:55:24,785 root         INFO     Train Epoch: 1 [3584/8000 (45%)]\tTotal Loss: 16.923950\n",
      "Reconstruction: 16.016457, Regularization: 0.239657, Discriminator: 0.661746; Generator: 0.006091,\n",
      "D(x): 0.000, D(G(z)): 0.823\n",
      "2019-04-10 00:55:24,896 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 16.208532\n",
      "Reconstruction: 15.340147, Regularization: 0.228529, Discriminator: 0.633631; Generator: 0.006225,\n",
      "D(x): 0.001, D(G(z)): 0.820\n",
      "2019-04-10 00:55:25,008 root         INFO     Train Epoch: 1 [4608/8000 (58%)]\tTotal Loss: 16.457336\n",
      "Reconstruction: 15.589820, Regularization: 0.227056, Discriminator: 0.633916; Generator: 0.006544,\n",
      "D(x): 0.001, D(G(z)): 0.811\n",
      "2019-04-10 00:55:25,120 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 19.993484\n",
      "Reconstruction: 19.058935, Regularization: 0.248178, Discriminator: 0.680345; Generator: 0.006026,\n",
      "D(x): 0.000, D(G(z)): 0.825\n",
      "2019-04-10 00:55:25,231 root         INFO     Train Epoch: 1 [5632/8000 (70%)]\tTotal Loss: 18.401117\n",
      "Reconstruction: 17.512749, Regularization: 0.231914, Discriminator: 0.650129; Generator: 0.006324,\n",
      "D(x): 0.000, D(G(z)): 0.817\n",
      "2019-04-10 00:55:25,342 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 20.485704\n",
      "Reconstruction: 19.565567, Regularization: 0.242499, Discriminator: 0.671170; Generator: 0.006468,\n",
      "D(x): 0.000, D(G(z)): 0.813\n",
      "2019-04-10 00:55:25,454 root         INFO     Train Epoch: 1 [6656/8000 (83%)]\tTotal Loss: 20.541687\n",
      "Reconstruction: 19.643541, Regularization: 0.235851, Discriminator: 0.655947; Generator: 0.006346,\n",
      "D(x): 0.000, D(G(z)): 0.817\n",
      "2019-04-10 00:55:25,566 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 19.182793\n",
      "Reconstruction: 18.340939, Regularization: 0.221490, Discriminator: 0.613664; Generator: 0.006701,\n",
      "D(x): 0.000, D(G(z)): 0.807\n",
      "2019-04-10 00:55:25,679 root         INFO     Train Epoch: 1 [7680/8000 (96%)]\tTotal Loss: 19.324099\n",
      "Reconstruction: 18.488651, Regularization: 0.217248, Discriminator: 0.611605; Generator: 0.006593,\n",
      "D(x): 0.000, D(G(z)): 0.810\n",
      "2019-04-10 00:55:25,762 root         INFO     ====> Epoch: 1 Average loss: 18.2893\n",
      "2019-04-10 00:55:25,788 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 19.666765\n",
      "Reconstruction: 18.830078, Regularization: 0.215563, Discriminator: 0.614536; Generator: 0.006590,\n",
      "D(x): 0.000, D(G(z)): 0.810\n",
      "2019-04-10 00:55:25,901 root         INFO     Train Epoch: 2 [512/8000 (6%)]\tTotal Loss: 17.600933\n",
      "Reconstruction: 16.834925, Regularization: 0.197688, Discriminator: 0.561360; Generator: 0.006961,\n",
      "D(x): 0.000, D(G(z)): 0.800\n",
      "2019-04-10 00:55:26,011 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 16.227280\n",
      "Reconstruction: 15.510183, Regularization: 0.184316, Discriminator: 0.525962; Generator: 0.006818,\n",
      "D(x): 0.000, D(G(z)): 0.804\n",
      "2019-04-10 00:55:26,121 root         INFO     Train Epoch: 2 [1536/8000 (19%)]\tTotal Loss: 20.461420\n",
      "Reconstruction: 19.666676, Regularization: 0.203760, Discriminator: 0.584000; Generator: 0.006985,\n",
      "D(x): 0.000, D(G(z)): 0.800\n",
      "2019-04-10 00:55:26,232 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 15.970567\n",
      "Reconstruction: 15.287148, Regularization: 0.175844, Discriminator: 0.500783; Generator: 0.006793,\n",
      "D(x): 0.000, D(G(z)): 0.805\n",
      "2019-04-10 00:55:26,342 root         INFO     Train Epoch: 2 [2560/8000 (32%)]\tTotal Loss: 20.671066\n",
      "Reconstruction: 19.900249, Regularization: 0.198085, Discriminator: 0.566167; Generator: 0.006566,\n",
      "D(x): 0.000, D(G(z)): 0.811\n",
      "2019-04-10 00:55:26,452 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 21.421160\n",
      "Reconstruction: 20.643324, Regularization: 0.197864, Discriminator: 0.573274; Generator: 0.006698,\n",
      "D(x): 0.000, D(G(z)): 0.807\n",
      "2019-04-10 00:55:26,562 root         INFO     Train Epoch: 2 [3584/8000 (45%)]\tTotal Loss: 23.362743\n",
      "Reconstruction: 22.578394, Regularization: 0.200240, Discriminator: 0.577024; Generator: 0.007084,\n",
      "D(x): 0.000, D(G(z)): 0.797\n",
      "2019-04-10 00:55:26,671 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 21.486658\n",
      "Reconstruction: 20.747307, Regularization: 0.187409, Discriminator: 0.545029; Generator: 0.006914,\n",
      "D(x): 0.000, D(G(z)): 0.802\n",
      "2019-04-10 00:55:26,782 root         INFO     Train Epoch: 2 [4608/8000 (58%)]\tTotal Loss: 20.764389\n",
      "Reconstruction: 20.048058, Regularization: 0.181016, Discriminator: 0.528348; Generator: 0.006967,\n",
      "D(x): 0.000, D(G(z)): 0.800\n",
      "2019-04-10 00:55:26,893 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 22.074812\n",
      "Reconstruction: 21.351057, Regularization: 0.182322, Discriminator: 0.534557; Generator: 0.006876,\n",
      "D(x): 0.000, D(G(z)): 0.803\n",
      "2019-04-10 00:55:27,003 root         INFO     Train Epoch: 2 [5632/8000 (70%)]\tTotal Loss: 18.152281\n",
      "Reconstruction: 17.531900, Regularization: 0.157831, Discriminator: 0.455327; Generator: 0.007221,\n",
      "D(x): 0.001, D(G(z)): 0.794\n",
      "2019-04-10 00:55:27,113 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 21.454725\n",
      "Reconstruction: 20.771627, Regularization: 0.172127, Discriminator: 0.504011; Generator: 0.006960,\n",
      "D(x): 0.000, D(G(z)): 0.800\n",
      "2019-04-10 00:55:27,224 root         INFO     Train Epoch: 2 [6656/8000 (83%)]\tTotal Loss: 20.241915\n",
      "Reconstruction: 19.603378, Regularization: 0.161022, Discriminator: 0.470343; Generator: 0.007172,\n",
      "D(x): 0.001, D(G(z)): 0.795\n",
      "2019-04-10 00:55:27,334 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 19.571575\n",
      "Reconstruction: 18.947136, Regularization: 0.156171, Discriminator: 0.461214; Generator: 0.007052,\n",
      "D(x): 0.000, D(G(z)): 0.798\n",
      "2019-04-10 00:55:27,445 root         INFO     Train Epoch: 2 [7680/8000 (96%)]\tTotal Loss: 23.448576\n",
      "Reconstruction: 22.777281, Regularization: 0.168455, Discriminator: 0.495824; Generator: 0.007016,\n",
      "D(x): 0.000, D(G(z)): 0.799\n",
      "2019-04-10 00:55:27,525 root         INFO     ====> Epoch: 2 Average loss: 20.2118\n",
      "2019-04-10 00:55:27,552 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 20.826836\n",
      "Reconstruction: 20.204277, Regularization: 0.154135, Discriminator: 0.461111; Generator: 0.007314,\n",
      "D(x): 0.000, D(G(z)): 0.791\n",
      "2019-04-10 00:55:27,664 root         INFO     Train Epoch: 3 [512/8000 (6%)]\tTotal Loss: 19.253181\n",
      "Reconstruction: 18.672741, Regularization: 0.145518, Discriminator: 0.427591; Generator: 0.007331,\n",
      "D(x): 0.000, D(G(z)): 0.791\n",
      "2019-04-10 00:55:27,774 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 19.042868\n",
      "Reconstruction: 18.474703, Regularization: 0.141386, Discriminator: 0.419476; Generator: 0.007304,\n",
      "D(x): 0.008, D(G(z)): 0.792\n",
      "2019-04-10 00:55:27,884 root         INFO     Train Epoch: 3 [1536/8000 (19%)]\tTotal Loss: 18.215254\n",
      "Reconstruction: 17.670681, Regularization: 0.138322, Discriminator: 0.398836; Generator: 0.007415,\n",
      "D(x): 0.000, D(G(z)): 0.789\n",
      "2019-04-10 00:55:27,996 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 23.586847\n",
      "Reconstruction: 22.967268, Regularization: 0.152801, Discriminator: 0.459236; Generator: 0.007543,\n",
      "D(x): 0.001, D(G(z)): 0.786\n",
      "2019-04-10 00:55:28,107 root         INFO     Train Epoch: 3 [2560/8000 (32%)]\tTotal Loss: 20.313669\n",
      "Reconstruction: 19.749735, Regularization: 0.140239, Discriminator: 0.416282; Generator: 0.007412,\n",
      "D(x): 0.000, D(G(z)): 0.789\n",
      "2019-04-10 00:55:28,218 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 19.546268\n",
      "Reconstruction: 19.008869, Regularization: 0.133317, Discriminator: 0.396720; Generator: 0.007362,\n",
      "D(x): 0.001, D(G(z)): 0.790\n",
      "2019-04-10 00:55:28,329 root         INFO     Train Epoch: 3 [3584/8000 (45%)]\tTotal Loss: 22.356133\n",
      "Reconstruction: 21.787560, Regularization: 0.139630, Discriminator: 0.421375; Generator: 0.007569,\n",
      "D(x): 0.000, D(G(z)): 0.785\n",
      "2019-04-10 00:55:28,441 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 23.565372\n",
      "Reconstruction: 22.995033, Regularization: 0.140479, Discriminator: 0.422374; Generator: 0.007485,\n",
      "D(x): 0.002, D(G(z)): 0.787\n",
      "2019-04-10 00:55:28,552 root         INFO     Train Epoch: 3 [4608/8000 (58%)]\tTotal Loss: 23.336950\n",
      "Reconstruction: 22.770576, Regularization: 0.139180, Discriminator: 0.419628; Generator: 0.007565,\n",
      "D(x): 0.000, D(G(z)): 0.785\n",
      "2019-04-10 00:55:28,662 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 23.048109\n",
      "Reconstruction: 22.498493, Regularization: 0.137229, Discriminator: 0.404893; Generator: 0.007494,\n",
      "D(x): 0.000, D(G(z)): 0.787\n",
      "2019-04-10 00:55:28,773 root         INFO     Train Epoch: 3 [5632/8000 (70%)]\tTotal Loss: 20.734251\n",
      "Reconstruction: 20.228111, Regularization: 0.126951, Discriminator: 0.371700; Generator: 0.007489,\n",
      "D(x): 0.000, D(G(z)): 0.787\n",
      "2019-04-10 00:55:28,884 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 20.344296\n",
      "Reconstruction: 19.847801, Regularization: 0.122274, Discriminator: 0.366531; Generator: 0.007689,\n",
      "D(x): 0.005, D(G(z)): 0.782\n",
      "2019-04-10 00:55:28,995 root         INFO     Train Epoch: 3 [6656/8000 (83%)]\tTotal Loss: 21.194555\n",
      "Reconstruction: 20.698305, Regularization: 0.123100, Discriminator: 0.365347; Generator: 0.007802,\n",
      "D(x): 0.001, D(G(z)): 0.779\n",
      "2019-04-10 00:55:29,106 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 23.656429\n",
      "Reconstruction: 23.137756, Regularization: 0.129318, Discriminator: 0.381499; Generator: 0.007856,\n",
      "D(x): 0.004, D(G(z)): 0.778\n",
      "2019-04-10 00:55:29,218 root         INFO     Train Epoch: 3 [7680/8000 (96%)]\tTotal Loss: 24.695330\n",
      "Reconstruction: 24.166061, Regularization: 0.131321, Discriminator: 0.390177; Generator: 0.007771,\n",
      "D(x): 0.000, D(G(z)): 0.780\n",
      "2019-04-10 00:55:29,299 root         INFO     ====> Epoch: 3 Average loss: 21.9532\n",
      "2019-04-10 00:55:29,326 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 26.408606\n",
      "Reconstruction: 25.868145, Regularization: 0.132459, Discriminator: 0.400052; Generator: 0.007949,\n",
      "D(x): 0.000, D(G(z)): 0.775\n",
      "2019-04-10 00:55:29,439 root         INFO     Train Epoch: 4 [512/8000 (6%)]\tTotal Loss: 23.186396\n",
      "Reconstruction: 22.686842, Regularization: 0.123101, Discriminator: 0.368639; Generator: 0.007814,\n",
      "D(x): 0.000, D(G(z)): 0.779\n",
      "2019-04-10 00:55:29,550 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 20.869234\n",
      "Reconstruction: 20.413330, Regularization: 0.114221, Discriminator: 0.333727; Generator: 0.007956,\n",
      "D(x): 0.003, D(G(z)): 0.775\n",
      "2019-04-10 00:55:29,662 root         INFO     Train Epoch: 4 [1536/8000 (19%)]\tTotal Loss: 24.539593\n",
      "Reconstruction: 24.044159, Regularization: 0.124559, Discriminator: 0.362966; Generator: 0.007908,\n",
      "D(x): 0.001, D(G(z)): 0.777\n",
      "2019-04-10 00:55:29,773 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 23.537672\n",
      "Reconstruction: 23.059324, Regularization: 0.119026, Discriminator: 0.351239; Generator: 0.008083,\n",
      "D(x): 0.005, D(G(z)): 0.772\n",
      "2019-04-10 00:55:29,883 root         INFO     Train Epoch: 4 [2560/8000 (32%)]\tTotal Loss: 24.460625\n",
      "Reconstruction: 23.980999, Regularization: 0.121391, Discriminator: 0.350273; Generator: 0.007961,\n",
      "D(x): 0.002, D(G(z)): 0.775\n",
      "2019-04-10 00:55:29,994 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 24.611168\n",
      "Reconstruction: 24.137440, Regularization: 0.123315, Discriminator: 0.342407; Generator: 0.008007,\n",
      "D(x): 0.002, D(G(z)): 0.774\n",
      "2019-04-10 00:55:30,104 root         INFO     Train Epoch: 4 [3584/8000 (45%)]\tTotal Loss: 23.377642\n",
      "Reconstruction: 22.918163, Regularization: 0.118335, Discriminator: 0.332918; Generator: 0.008226,\n",
      "D(x): 0.000, D(G(z)): 0.769\n",
      "2019-04-10 00:55:30,214 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 23.664799\n",
      "Reconstruction: 23.215080, Regularization: 0.117287, Discriminator: 0.324293; Generator: 0.008138,\n",
      "D(x): 0.004, D(G(z)): 0.771\n",
      "2019-04-10 00:55:30,324 root         INFO     Train Epoch: 4 [4608/8000 (58%)]\tTotal Loss: 23.403728\n",
      "Reconstruction: 22.959450, Regularization: 0.117230, Discriminator: 0.318686; Generator: 0.008363,\n",
      "D(x): 0.001, D(G(z)): 0.765\n",
      "2019-04-10 00:55:30,434 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 23.648233\n",
      "Reconstruction: 23.208935, Regularization: 0.115476, Discriminator: 0.315648; Generator: 0.008173,\n",
      "D(x): 0.006, D(G(z)): 0.770\n",
      "2019-04-10 00:55:30,544 root         INFO     Train Epoch: 4 [5632/8000 (70%)]\tTotal Loss: 25.745132\n",
      "Reconstruction: 25.287483, Regularization: 0.121867, Discriminator: 0.327269; Generator: 0.008514,\n",
      "D(x): 0.002, D(G(z)): 0.762\n",
      "2019-04-10 00:55:30,654 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 25.421745\n",
      "Reconstruction: 24.969738, Regularization: 0.121370, Discriminator: 0.322234; Generator: 0.008402,\n",
      "D(x): 0.001, D(G(z)): 0.764\n",
      "2019-04-10 00:55:30,763 root         INFO     Train Epoch: 4 [6656/8000 (83%)]\tTotal Loss: 21.673523\n",
      "Reconstruction: 21.266388, Regularization: 0.111916, Discriminator: 0.286688; Generator: 0.008531,\n",
      "D(x): 0.001, D(G(z)): 0.761\n",
      "2019-04-10 00:55:30,872 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 22.196751\n",
      "Reconstruction: 21.792242, Regularization: 0.111531, Discriminator: 0.284507; Generator: 0.008472,\n",
      "D(x): 0.004, D(G(z)): 0.763\n",
      "2019-04-10 00:55:30,981 root         INFO     Train Epoch: 4 [7680/8000 (96%)]\tTotal Loss: 22.107733\n",
      "Reconstruction: 21.707729, Regularization: 0.111048, Discriminator: 0.280258; Generator: 0.008698,\n",
      "D(x): 0.003, D(G(z)): 0.757\n",
      "2019-04-10 00:55:31,061 root         INFO     ====> Epoch: 4 Average loss: 23.2168\n",
      "2019-04-10 00:55:31,089 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 21.692648\n",
      "Reconstruction: 21.299965, Regularization: 0.109589, Discriminator: 0.274581; Generator: 0.008513,\n",
      "D(x): 0.003, D(G(z)): 0.762\n",
      "2019-04-10 00:55:31,200 root         INFO     Train Epoch: 5 [512/8000 (6%)]\tTotal Loss: 25.027571\n",
      "Reconstruction: 24.604523, Regularization: 0.121426, Discriminator: 0.292930; Generator: 0.008693,\n",
      "D(x): 0.009, D(G(z)): 0.757\n",
      "2019-04-10 00:55:31,311 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 23.602139\n",
      "Reconstruction: 23.198418, Regularization: 0.117066, Discriminator: 0.277925; Generator: 0.008730,\n",
      "D(x): 0.012, D(G(z)): 0.756\n",
      "2019-04-10 00:55:31,421 root         INFO     Train Epoch: 5 [1536/8000 (19%)]\tTotal Loss: 22.558289\n",
      "Reconstruction: 22.169945, Regularization: 0.115133, Discriminator: 0.264381; Generator: 0.008831,\n",
      "D(x): 0.009, D(G(z)): 0.754\n",
      "2019-04-10 00:55:31,532 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 25.580513\n",
      "Reconstruction: 25.163763, Regularization: 0.122791, Discriminator: 0.285227; Generator: 0.008731,\n",
      "D(x): 0.006, D(G(z)): 0.756\n",
      "2019-04-10 00:55:31,642 root         INFO     Train Epoch: 5 [2560/8000 (32%)]\tTotal Loss: 25.960676\n",
      "Reconstruction: 25.541510, Regularization: 0.127396, Discriminator: 0.282867; Generator: 0.008904,\n",
      "D(x): 0.004, D(G(z)): 0.752\n",
      "2019-04-10 00:55:31,753 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 23.218081\n",
      "Reconstruction: 22.830248, Regularization: 0.118619, Discriminator: 0.260068; Generator: 0.009146,\n",
      "D(x): 0.004, D(G(z)): 0.746\n",
      "2019-04-10 00:55:31,864 root         INFO     Train Epoch: 5 [3584/8000 (45%)]\tTotal Loss: 23.589108\n",
      "Reconstruction: 23.199785, Regularization: 0.119328, Discriminator: 0.261059; Generator: 0.008934,\n",
      "D(x): 0.006, D(G(z)): 0.751\n",
      "2019-04-10 00:55:31,975 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 24.473763\n",
      "Reconstruction: 24.077492, Regularization: 0.124785, Discriminator: 0.262441; Generator: 0.009045,\n",
      "D(x): 0.010, D(G(z)): 0.749\n",
      "2019-04-10 00:55:32,085 root         INFO     Train Epoch: 5 [4608/8000 (58%)]\tTotal Loss: 22.984442\n",
      "Reconstruction: 22.607922, Regularization: 0.121735, Discriminator: 0.245709; Generator: 0.009077,\n",
      "D(x): 0.005, D(G(z)): 0.748\n",
      "2019-04-10 00:55:32,195 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 24.563196\n",
      "Reconstruction: 24.171314, Regularization: 0.129697, Discriminator: 0.253110; Generator: 0.009074,\n",
      "D(x): 0.004, D(G(z)): 0.748\n",
      "2019-04-10 00:55:32,306 root         INFO     Train Epoch: 5 [5632/8000 (70%)]\tTotal Loss: 24.815165\n",
      "Reconstruction: 24.422480, Regularization: 0.130061, Discriminator: 0.253357; Generator: 0.009267,\n",
      "D(x): 0.006, D(G(z)): 0.743\n",
      "2019-04-10 00:55:32,416 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 23.921402\n",
      "Reconstruction: 23.541611, Regularization: 0.130451, Discriminator: 0.239958; Generator: 0.009383,\n",
      "D(x): 0.007, D(G(z)): 0.741\n",
      "2019-04-10 00:55:32,526 root         INFO     Train Epoch: 5 [6656/8000 (83%)]\tTotal Loss: 22.353798\n",
      "Reconstruction: 21.991718, Regularization: 0.122627, Discriminator: 0.230011; Generator: 0.009442,\n",
      "D(x): 0.008, D(G(z)): 0.739\n",
      "2019-04-10 00:55:32,636 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 23.733021\n",
      "Reconstruction: 23.358885, Regularization: 0.133730, Discriminator: 0.231114; Generator: 0.009293,\n",
      "D(x): 0.010, D(G(z)): 0.743\n",
      "2019-04-10 00:55:32,746 root         INFO     Train Epoch: 5 [7680/8000 (96%)]\tTotal Loss: 23.270369\n",
      "Reconstruction: 22.901421, Regularization: 0.131184, Discriminator: 0.228108; Generator: 0.009656,\n",
      "D(x): 0.007, D(G(z)): 0.734\n",
      "2019-04-10 00:55:32,827 root         INFO     ====> Epoch: 5 Average loss: 23.7927\n",
      "2019-04-10 00:55:32,854 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 23.604631\n",
      "Reconstruction: 23.233604, Regularization: 0.136097, Discriminator: 0.225440; Generator: 0.009490,\n",
      "D(x): 0.008, D(G(z)): 0.738\n",
      "2019-04-10 00:55:32,967 root         INFO     Train Epoch: 6 [512/8000 (6%)]\tTotal Loss: 23.074839\n",
      "Reconstruction: 22.711658, Regularization: 0.135761, Discriminator: 0.217900; Generator: 0.009520,\n",
      "D(x): 0.013, D(G(z)): 0.738\n",
      "2019-04-10 00:55:33,079 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 22.040806\n",
      "Reconstruction: 21.690687, Regularization: 0.132926, Discriminator: 0.207548; Generator: 0.009644,\n",
      "D(x): 0.015, D(G(z)): 0.735\n",
      "2019-04-10 00:55:33,191 root         INFO     Train Epoch: 6 [1536/8000 (19%)]\tTotal Loss: 21.866390\n",
      "Reconstruction: 21.519154, Regularization: 0.135385, Discriminator: 0.202191; Generator: 0.009661,\n",
      "D(x): 0.032, D(G(z)): 0.734\n",
      "2019-04-10 00:55:33,303 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 22.353344\n",
      "Reconstruction: 22.000315, Regularization: 0.139987, Discriminator: 0.203171; Generator: 0.009873,\n",
      "D(x): 0.023, D(G(z)): 0.729\n",
      "2019-04-10 00:55:33,415 root         INFO     Train Epoch: 6 [2560/8000 (32%)]\tTotal Loss: 23.759817\n",
      "Reconstruction: 23.388306, Regularization: 0.152513, Discriminator: 0.209143; Generator: 0.009855,\n",
      "D(x): 0.014, D(G(z)): 0.730\n",
      "2019-04-10 00:55:33,527 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 23.665167\n",
      "Reconstruction: 23.293175, Regularization: 0.152480, Discriminator: 0.209691; Generator: 0.009822,\n",
      "D(x): 0.010, D(G(z)): 0.730\n",
      "2019-04-10 00:55:33,639 root         INFO     Train Epoch: 6 [3584/8000 (45%)]\tTotal Loss: 23.171837\n",
      "Reconstruction: 22.807077, Regularization: 0.153647, Discriminator: 0.201144; Generator: 0.009970,\n",
      "D(x): 0.017, D(G(z)): 0.727\n",
      "2019-04-10 00:55:33,751 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 27.179281\n",
      "Reconstruction: 26.757893, Regularization: 0.187260, Discriminator: 0.224140; Generator: 0.009988,\n",
      "D(x): 0.006, D(G(z)): 0.727\n",
      "2019-04-10 00:55:33,863 root         INFO     Train Epoch: 6 [4608/8000 (58%)]\tTotal Loss: 23.128210\n",
      "Reconstruction: 22.762222, Regularization: 0.158795, Discriminator: 0.197079; Generator: 0.010114,\n",
      "D(x): 0.012, D(G(z)): 0.724\n",
      "2019-04-10 00:55:33,975 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 22.670650\n",
      "Reconstruction: 22.310740, Regularization: 0.159141, Discriminator: 0.190604; Generator: 0.010166,\n",
      "D(x): 0.019, D(G(z)): 0.722\n",
      "2019-04-10 00:55:34,086 root         INFO     Train Epoch: 6 [5632/8000 (70%)]\tTotal Loss: 21.727146\n",
      "Reconstruction: 21.377869, Regularization: 0.155037, Discriminator: 0.183900; Generator: 0.010340,\n",
      "D(x): 0.021, D(G(z)): 0.718\n",
      "2019-04-10 00:55:34,199 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 23.032276\n",
      "Reconstruction: 22.663158, Regularization: 0.169768, Discriminator: 0.188930; Generator: 0.010421,\n",
      "D(x): 0.017, D(G(z)): 0.716\n",
      "2019-04-10 00:55:34,311 root         INFO     Train Epoch: 6 [6656/8000 (83%)]\tTotal Loss: 23.803865\n",
      "Reconstruction: 23.424408, Regularization: 0.181016, Discriminator: 0.187966; Generator: 0.010476,\n",
      "D(x): 0.015, D(G(z)): 0.715\n",
      "2019-04-10 00:55:34,422 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 22.709124\n",
      "Reconstruction: 22.343407, Regularization: 0.175824, Discriminator: 0.179456; Generator: 0.010438,\n",
      "D(x): 0.024, D(G(z)): 0.716\n",
      "2019-04-10 00:55:34,532 root         INFO     Train Epoch: 6 [7680/8000 (96%)]\tTotal Loss: 23.541119\n",
      "Reconstruction: 23.160252, Regularization: 0.188568, Discriminator: 0.181563; Generator: 0.010736,\n",
      "D(x): 0.019, D(G(z)): 0.709\n",
      "2019-04-10 00:55:34,614 root         INFO     ====> Epoch: 6 Average loss: 23.4182\n",
      "2019-04-10 00:55:34,641 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 20.459616\n",
      "Reconstruction: 20.124775, Regularization: 0.159728, Discriminator: 0.164393; Generator: 0.010718,\n",
      "D(x): 0.030, D(G(z)): 0.710\n",
      "2019-04-10 00:55:34,754 root         INFO     Train Epoch: 7 [512/8000 (6%)]\tTotal Loss: 22.656368\n",
      "Reconstruction: 22.282288, Regularization: 0.188617, Discriminator: 0.174714; Generator: 0.010748,\n",
      "D(x): 0.029, D(G(z)): 0.709\n",
      "2019-04-10 00:55:34,866 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 21.903486\n",
      "Reconstruction: 21.539013, Regularization: 0.187582, Discriminator: 0.166127; Generator: 0.010764,\n",
      "D(x): 0.040, D(G(z)): 0.709\n",
      "2019-04-10 00:55:34,976 root         INFO     Train Epoch: 7 [1536/8000 (19%)]\tTotal Loss: 21.777584\n",
      "Reconstruction: 21.417599, Regularization: 0.187021, Discriminator: 0.162076; Generator: 0.010888,\n",
      "D(x): 0.034, D(G(z)): 0.706\n",
      "2019-04-10 00:55:35,086 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 21.197115\n",
      "Reconstruction: 20.843800, Regularization: 0.184926, Discriminator: 0.157454; Generator: 0.010937,\n",
      "D(x): 0.037, D(G(z)): 0.705\n",
      "2019-04-10 00:55:35,197 root         INFO     Train Epoch: 7 [2560/8000 (32%)]\tTotal Loss: 23.420673\n",
      "Reconstruction: 23.021069, Regularization: 0.222006, Discriminator: 0.166612; Generator: 0.010987,\n",
      "D(x): 0.044, D(G(z)): 0.704\n",
      "2019-04-10 00:55:35,307 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 23.570452\n",
      "Reconstruction: 23.167618, Regularization: 0.226456, Discriminator: 0.165233; Generator: 0.011145,\n",
      "D(x): 0.031, D(G(z)): 0.700\n",
      "2019-04-10 00:55:35,418 root         INFO     Train Epoch: 7 [3584/8000 (45%)]\tTotal Loss: 21.153460\n",
      "Reconstruction: 20.789219, Regularization: 0.200220, Discriminator: 0.152952; Generator: 0.011068,\n",
      "D(x): 0.054, D(G(z)): 0.702\n",
      "2019-04-10 00:55:35,529 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 22.674778\n",
      "Reconstruction: 22.282646, Regularization: 0.223787, Discriminator: 0.157154; Generator: 0.011191,\n",
      "D(x): 0.034, D(G(z)): 0.699\n",
      "2019-04-10 00:55:35,639 root         INFO     Train Epoch: 7 [4608/8000 (58%)]\tTotal Loss: 22.493206\n",
      "Reconstruction: 22.099627, Regularization: 0.226103, Discriminator: 0.156235; Generator: 0.011241,\n",
      "D(x): 0.034, D(G(z)): 0.698\n",
      "2019-04-10 00:55:35,748 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 22.249912\n",
      "Reconstruction: 21.856445, Regularization: 0.231255, Discriminator: 0.150782; Generator: 0.011431,\n",
      "D(x): 0.045, D(G(z)): 0.694\n",
      "2019-04-10 00:55:35,856 root         INFO     Train Epoch: 7 [5632/8000 (70%)]\tTotal Loss: 21.009497\n",
      "Reconstruction: 20.638367, Regularization: 0.216568, Discriminator: 0.143176; Generator: 0.011386,\n",
      "D(x): 0.056, D(G(z)): 0.695\n",
      "2019-04-10 00:55:35,966 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 23.469894\n",
      "Reconstruction: 23.041958, Regularization: 0.262237, Discriminator: 0.154154; Generator: 0.011544,\n",
      "D(x): 0.033, D(G(z)): 0.691\n",
      "2019-04-10 00:55:36,076 root         INFO     Train Epoch: 7 [6656/8000 (83%)]\tTotal Loss: 21.376419\n",
      "Reconstruction: 20.990974, Regularization: 0.233125, Discriminator: 0.140673; Generator: 0.011647,\n",
      "D(x): 0.048, D(G(z)): 0.689\n",
      "2019-04-10 00:55:36,187 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 22.301722\n",
      "Reconstruction: 21.880890, Regularization: 0.264066, Discriminator: 0.145053; Generator: 0.011713,\n",
      "D(x): 0.048, D(G(z)): 0.688\n",
      "2019-04-10 00:55:36,297 root         INFO     Train Epoch: 7 [7680/8000 (96%)]\tTotal Loss: 21.613543\n",
      "Reconstruction: 21.208258, Regularization: 0.253892, Discriminator: 0.139750; Generator: 0.011642,\n",
      "D(x): 0.055, D(G(z)): 0.689\n",
      "2019-04-10 00:55:36,377 root         INFO     ====> Epoch: 7 Average loss: 22.3043\n",
      "2019-04-10 00:55:36,405 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 19.947306\n",
      "Reconstruction: 19.574520, Regularization: 0.230385, Discriminator: 0.130540; Generator: 0.011861,\n",
      "D(x): 0.067, D(G(z)): 0.684\n",
      "2019-04-10 00:55:36,518 root         INFO     Train Epoch: 8 [512/8000 (6%)]\tTotal Loss: 22.300444\n",
      "Reconstruction: 21.860062, Regularization: 0.287500, Discriminator: 0.141024; Generator: 0.011858,\n",
      "D(x): 0.053, D(G(z)): 0.684\n",
      "2019-04-10 00:55:36,630 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 20.340219\n",
      "Reconstruction: 19.952969, Regularization: 0.246048, Discriminator: 0.129188; Generator: 0.012014,\n",
      "D(x): 0.063, D(G(z)): 0.681\n",
      "2019-04-10 00:55:36,742 root         INFO     Train Epoch: 8 [1536/8000 (19%)]\tTotal Loss: 20.065100\n",
      "Reconstruction: 19.675381, Regularization: 0.251193, Discriminator: 0.126478; Generator: 0.012046,\n",
      "D(x): 0.078, D(G(z)): 0.680\n",
      "2019-04-10 00:55:36,854 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 21.401358\n",
      "Reconstruction: 20.966557, Regularization: 0.291294, Discriminator: 0.131315; Generator: 0.012192,\n",
      "D(x): 0.069, D(G(z)): 0.677\n",
      "2019-04-10 00:55:36,967 root         INFO     Train Epoch: 8 [2560/8000 (32%)]\tTotal Loss: 20.370420\n",
      "Reconstruction: 19.960800, Regularization: 0.273042, Discriminator: 0.124403; Generator: 0.012175,\n",
      "D(x): 0.081, D(G(z)): 0.677\n",
      "2019-04-10 00:55:37,079 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 20.336308\n",
      "Reconstruction: 19.920807, Regularization: 0.279618, Discriminator: 0.123499; Generator: 0.012384,\n",
      "D(x): 0.074, D(G(z)): 0.673\n",
      "2019-04-10 00:55:37,191 root         INFO     Train Epoch: 8 [3584/8000 (45%)]\tTotal Loss: 22.029179\n",
      "Reconstruction: 21.549793, Regularization: 0.336517, Discriminator: 0.130423; Generator: 0.012446,\n",
      "D(x): 0.063, D(G(z)): 0.672\n",
      "2019-04-10 00:55:37,300 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 20.186022\n",
      "Reconstruction: 19.760834, Regularization: 0.293367, Discriminator: 0.119434; Generator: 0.012386,\n",
      "D(x): 0.088, D(G(z)): 0.673\n",
      "2019-04-10 00:55:37,410 root         INFO     Train Epoch: 8 [4608/8000 (58%)]\tTotal Loss: 22.019810\n",
      "Reconstruction: 21.509607, Regularization: 0.369014, Discriminator: 0.128646; Generator: 0.012542,\n",
      "D(x): 0.068, D(G(z)): 0.669\n",
      "2019-04-10 00:55:37,519 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 20.311163\n",
      "Reconstruction: 19.871424, Regularization: 0.309641, Discriminator: 0.117432; Generator: 0.012666,\n",
      "D(x): 0.084, D(G(z)): 0.667\n",
      "2019-04-10 00:55:37,629 root         INFO     Train Epoch: 8 [5632/8000 (70%)]\tTotal Loss: 19.090693\n",
      "Reconstruction: 18.683958, Regularization: 0.283792, Discriminator: 0.110210; Generator: 0.012731,\n",
      "D(x): 0.108, D(G(z)): 0.665\n",
      "2019-04-10 00:55:37,737 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 19.994785\n",
      "Reconstruction: 19.552666, Regularization: 0.316574, Discriminator: 0.112784; Generator: 0.012762,\n",
      "D(x): 0.096, D(G(z)): 0.665\n",
      "2019-04-10 00:55:37,846 root         INFO     Train Epoch: 8 [6656/8000 (83%)]\tTotal Loss: 20.505571\n",
      "Reconstruction: 20.036352, Regularization: 0.341911, Discriminator: 0.114397; Generator: 0.012911,\n",
      "D(x): 0.087, D(G(z)): 0.662\n",
      "2019-04-10 00:55:37,954 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 18.790684\n",
      "Reconstruction: 18.366148, Regularization: 0.304848, Discriminator: 0.106738; Generator: 0.012950,\n",
      "D(x): 0.119, D(G(z)): 0.661\n",
      "2019-04-10 00:55:38,061 root         INFO     Train Epoch: 8 [7680/8000 (96%)]\tTotal Loss: 20.356939\n",
      "Reconstruction: 19.871098, Regularization: 0.361347, Discriminator: 0.111435; Generator: 0.013059,\n",
      "D(x): 0.096, D(G(z)): 0.658\n",
      "2019-04-10 00:55:38,140 root         INFO     ====> Epoch: 8 Average loss: 20.5873\n",
      "2019-04-10 00:55:38,168 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 20.190731\n",
      "Reconstruction: 19.697004, Regularization: 0.370432, Discriminator: 0.110206; Generator: 0.013089,\n",
      "D(x): 0.103, D(G(z)): 0.658\n",
      "2019-04-10 00:55:38,277 root         INFO     Train Epoch: 9 [512/8000 (6%)]\tTotal Loss: 19.195910\n",
      "Reconstruction: 18.731236, Regularization: 0.346013, Discriminator: 0.105406; Generator: 0.013256,\n",
      "D(x): 0.114, D(G(z)): 0.654\n",
      "2019-04-10 00:55:38,385 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 19.073383\n",
      "Reconstruction: 18.601664, Regularization: 0.355327, Discriminator: 0.103144; Generator: 0.013249,\n",
      "D(x): 0.133, D(G(z)): 0.654\n",
      "2019-04-10 00:55:38,494 root         INFO     Train Epoch: 9 [1536/8000 (19%)]\tTotal Loss: 19.679415\n",
      "Reconstruction: 19.189554, Regularization: 0.372704, Discriminator: 0.103724; Generator: 0.013433,\n",
      "D(x): 0.116, D(G(z)): 0.651\n",
      "2019-04-10 00:55:38,603 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 20.408773\n",
      "Reconstruction: 19.853281, Regularization: 0.434775, Discriminator: 0.107206; Generator: 0.013511,\n",
      "D(x): 0.106, D(G(z)): 0.649\n",
      "2019-04-10 00:55:38,712 root         INFO     Train Epoch: 9 [2560/8000 (32%)]\tTotal Loss: 19.570587\n",
      "Reconstruction: 19.046043, Regularization: 0.407917, Discriminator: 0.103064; Generator: 0.013563,\n",
      "D(x): 0.119, D(G(z)): 0.648\n",
      "2019-04-10 00:55:38,820 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 18.654509\n",
      "Reconstruction: 18.145653, Regularization: 0.396966, Discriminator: 0.098172; Generator: 0.013717,\n",
      "D(x): 0.147, D(G(z)): 0.645\n",
      "2019-04-10 00:55:38,929 root         INFO     Train Epoch: 9 [3584/8000 (45%)]\tTotal Loss: 18.562891\n",
      "Reconstruction: 18.046618, Regularization: 0.404970, Discriminator: 0.097571; Generator: 0.013733,\n",
      "D(x): 0.144, D(G(z)): 0.644\n",
      "2019-04-10 00:55:39,038 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 18.082001\n",
      "Reconstruction: 17.604824, Regularization: 0.370106, Discriminator: 0.093277; Generator: 0.013793,\n",
      "D(x): 0.156, D(G(z)): 0.643\n",
      "2019-04-10 00:55:39,146 root         INFO     Train Epoch: 9 [4608/8000 (58%)]\tTotal Loss: 19.274828\n",
      "Reconstruction: 18.665960, Regularization: 0.494930, Discriminator: 0.100008; Generator: 0.013929,\n",
      "D(x): 0.138, D(G(z)): 0.640\n",
      "2019-04-10 00:55:39,255 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 18.327991\n",
      "Reconstruction: 17.792715, Regularization: 0.427770, Discriminator: 0.093348; Generator: 0.014157,\n",
      "D(x): 0.155, D(G(z)): 0.636\n",
      "2019-04-10 00:55:39,364 root         INFO     Train Epoch: 9 [5632/8000 (70%)]\tTotal Loss: 18.693520\n",
      "Reconstruction: 18.133858, Regularization: 0.452373, Discriminator: 0.093148; Generator: 0.014141,\n",
      "D(x): 0.153, D(G(z)): 0.636\n",
      "2019-04-10 00:55:39,472 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 17.714844\n",
      "Reconstruction: 17.190754, Regularization: 0.420305, Discriminator: 0.089618; Generator: 0.014166,\n",
      "D(x): 0.170, D(G(z)): 0.636\n",
      "2019-04-10 00:55:39,581 root         INFO     Train Epoch: 9 [6656/8000 (83%)]\tTotal Loss: 17.425301\n",
      "Reconstruction: 16.921757, Regularization: 0.402813, Discriminator: 0.086496; Generator: 0.014235,\n",
      "D(x): 0.186, D(G(z)): 0.634\n",
      "2019-04-10 00:55:39,690 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 18.294792\n",
      "Reconstruction: 17.710579, Regularization: 0.480298, Discriminator: 0.089578; Generator: 0.014339,\n",
      "D(x): 0.168, D(G(z)): 0.632\n",
      "2019-04-10 00:55:39,799 root         INFO     Train Epoch: 9 [7680/8000 (96%)]\tTotal Loss: 17.982918\n",
      "Reconstruction: 17.402081, Regularization: 0.478299, Discriminator: 0.088013; Generator: 0.014526,\n",
      "D(x): 0.173, D(G(z)): 0.628\n",
      "2019-04-10 00:55:39,878 root         INFO     ====> Epoch: 9 Average loss: 18.5956\n",
      "2019-04-10 00:55:39,905 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 17.103462\n",
      "Reconstruction: 16.578636, Regularization: 0.426349, Discriminator: 0.083963; Generator: 0.014514,\n",
      "D(x): 0.196, D(G(z)): 0.629\n",
      "2019-04-10 00:55:40,016 root         INFO     Train Epoch: 10 [512/8000 (6%)]\tTotal Loss: 16.958780\n",
      "Reconstruction: 16.417355, Regularization: 0.443275, Discriminator: 0.083582; Generator: 0.014568,\n",
      "D(x): 0.197, D(G(z)): 0.627\n",
      "2019-04-10 00:55:40,125 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 17.710512\n",
      "Reconstruction: 17.108719, Regularization: 0.502214, Discriminator: 0.084803; Generator: 0.014776,\n",
      "D(x): 0.187, D(G(z)): 0.623\n",
      "2019-04-10 00:55:40,234 root         INFO     Train Epoch: 10 [1536/8000 (19%)]\tTotal Loss: 17.554874\n",
      "Reconstruction: 16.917290, Regularization: 0.537953, Discriminator: 0.084804; Generator: 0.014829,\n",
      "D(x): 0.188, D(G(z)): 0.622\n",
      "2019-04-10 00:55:40,343 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 17.079975\n",
      "Reconstruction: 16.492231, Regularization: 0.491200, Discriminator: 0.081582; Generator: 0.014963,\n",
      "D(x): 0.200, D(G(z)): 0.620\n",
      "2019-04-10 00:55:40,452 root         INFO     Train Epoch: 10 [2560/8000 (32%)]\tTotal Loss: 17.292824\n",
      "Reconstruction: 16.705160, Regularization: 0.492614, Discriminator: 0.080069; Generator: 0.014981,\n",
      "D(x): 0.208, D(G(z)): 0.619\n",
      "2019-04-10 00:55:40,562 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 16.399250\n",
      "Reconstruction: 15.831583, Regularization: 0.474601, Discriminator: 0.077965; Generator: 0.015102,\n",
      "D(x): 0.224, D(G(z)): 0.617\n",
      "2019-04-10 00:55:40,670 root         INFO     Train Epoch: 10 [3584/8000 (45%)]\tTotal Loss: 16.449055\n",
      "Reconstruction: 15.839688, Regularization: 0.516122, Discriminator: 0.078053; Generator: 0.015191,\n",
      "D(x): 0.224, D(G(z)): 0.615\n",
      "2019-04-10 00:55:40,779 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 16.244555\n",
      "Reconstruction: 15.666451, Regularization: 0.487162, Discriminator: 0.075628; Generator: 0.015314,\n",
      "D(x): 0.237, D(G(z)): 0.613\n",
      "2019-04-10 00:55:40,889 root         INFO     Train Epoch: 10 [4608/8000 (58%)]\tTotal Loss: 16.621895\n",
      "Reconstruction: 15.980053, Regularization: 0.549686, Discriminator: 0.076860; Generator: 0.015296,\n",
      "D(x): 0.228, D(G(z)): 0.613\n",
      "2019-04-10 00:55:40,998 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 16.469568\n",
      "Reconstruction: 15.794535, Regularization: 0.583068, Discriminator: 0.076443; Generator: 0.015522,\n",
      "D(x): 0.229, D(G(z)): 0.609\n",
      "2019-04-10 00:55:41,107 root         INFO     Train Epoch: 10 [5632/8000 (70%)]\tTotal Loss: 15.569262\n",
      "Reconstruction: 14.999222, Regularization: 0.482496, Discriminator: 0.071974; Generator: 0.015569,\n",
      "D(x): 0.262, D(G(z)): 0.608\n",
      "2019-04-10 00:55:41,216 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 15.409785\n",
      "Reconstruction: 14.826946, Regularization: 0.496142, Discriminator: 0.071027; Generator: 0.015671,\n",
      "D(x): 0.270, D(G(z)): 0.606\n",
      "2019-04-10 00:55:41,325 root         INFO     Train Epoch: 10 [6656/8000 (83%)]\tTotal Loss: 15.648114\n",
      "Reconstruction: 14.937134, Regularization: 0.622039, Discriminator: 0.073134; Generator: 0.015808,\n",
      "D(x): 0.256, D(G(z)): 0.603\n",
      "2019-04-10 00:55:41,434 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 16.029694\n",
      "Reconstruction: 15.327967, Regularization: 0.613482, Discriminator: 0.072332; Generator: 0.015913,\n",
      "D(x): 0.253, D(G(z)): 0.601\n",
      "2019-04-10 00:55:41,543 root         INFO     Train Epoch: 10 [7680/8000 (96%)]\tTotal Loss: 15.428186\n",
      "Reconstruction: 14.824322, Regularization: 0.519091, Discriminator: 0.068841; Generator: 0.015932,\n",
      "D(x): 0.281, D(G(z)): 0.601\n",
      "2019-04-10 00:55:41,623 root         INFO     ====> Epoch: 10 Average loss: 16.4145\n",
      "2019-04-10 00:55:41,650 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 14.927077\n",
      "Reconstruction: 14.348022, Regularization: 0.495611, Discriminator: 0.067330; Generator: 0.016114,\n",
      "D(x): 0.293, D(G(z)): 0.597\n",
      "2019-04-10 00:55:41,759 root         INFO     Train Epoch: 11 [512/8000 (6%)]\tTotal Loss: 15.403107\n",
      "Reconstruction: 14.741829, Regularization: 0.576720, Discriminator: 0.068366; Generator: 0.016191,\n",
      "D(x): 0.283, D(G(z)): 0.596\n",
      "2019-04-10 00:55:41,868 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 15.656789\n",
      "Reconstruction: 14.910965, Regularization: 0.660292, Discriminator: 0.069292; Generator: 0.016240,\n",
      "D(x): 0.273, D(G(z)): 0.595\n",
      "2019-04-10 00:55:41,976 root         INFO     Train Epoch: 11 [1536/8000 (19%)]\tTotal Loss: 14.926915\n",
      "Reconstruction: 14.209921, Regularization: 0.633289, Discriminator: 0.067369; Generator: 0.016336,\n",
      "D(x): 0.292, D(G(z)): 0.593\n",
      "2019-04-10 00:55:42,084 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 14.634690\n",
      "Reconstruction: 13.982622, Regularization: 0.570329, Discriminator: 0.065274; Generator: 0.016465,\n",
      "D(x): 0.307, D(G(z)): 0.590\n",
      "2019-04-10 00:55:42,193 root         INFO     Train Epoch: 11 [2560/8000 (32%)]\tTotal Loss: 14.851189\n",
      "Reconstruction: 14.208054, Regularization: 0.562266, Discriminator: 0.064300; Generator: 0.016570,\n",
      "D(x): 0.314, D(G(z)): 0.588\n",
      "2019-04-10 00:55:42,301 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 15.181608\n",
      "Reconstruction: 14.401316, Regularization: 0.697899, Discriminator: 0.065714; Generator: 0.016680,\n",
      "D(x): 0.299, D(G(z)): 0.586\n",
      "2019-04-10 00:55:42,409 root         INFO     Train Epoch: 11 [3584/8000 (45%)]\tTotal Loss: 14.376367\n",
      "Reconstruction: 13.689514, Regularization: 0.606961, Discriminator: 0.063080; Generator: 0.016811,\n",
      "D(x): 0.324, D(G(z)): 0.584\n",
      "2019-04-10 00:55:42,517 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 14.213656\n",
      "Reconstruction: 13.483274, Regularization: 0.650596, Discriminator: 0.062922; Generator: 0.016864,\n",
      "D(x): 0.325, D(G(z)): 0.583\n",
      "2019-04-10 00:55:42,626 root         INFO     Train Epoch: 11 [4608/8000 (58%)]\tTotal Loss: 13.823803\n",
      "Reconstruction: 13.196796, Regularization: 0.549385, Discriminator: 0.060633; Generator: 0.016988,\n",
      "D(x): 0.346, D(G(z)): 0.581\n",
      "2019-04-10 00:55:42,734 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 14.095413\n",
      "Reconstruction: 13.397338, Regularization: 0.620069, Discriminator: 0.060910; Generator: 0.017096,\n",
      "D(x): 0.341, D(G(z)): 0.579\n",
      "2019-04-10 00:55:42,842 root         INFO     Train Epoch: 11 [5632/8000 (70%)]\tTotal Loss: 14.010506\n",
      "Reconstruction: 13.319530, Regularization: 0.613740, Discriminator: 0.060041; Generator: 0.017195,\n",
      "D(x): 0.348, D(G(z)): 0.577\n",
      "2019-04-10 00:55:42,951 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 13.735520\n",
      "Reconstruction: 13.062904, Regularization: 0.596352, Discriminator: 0.058929; Generator: 0.017334,\n",
      "D(x): 0.359, D(G(z)): 0.574\n",
      "2019-04-10 00:55:43,060 root         INFO     Train Epoch: 11 [6656/8000 (83%)]\tTotal Loss: 13.959442\n",
      "Reconstruction: 13.195082, Regularization: 0.687528, Discriminator: 0.059396; Generator: 0.017437,\n",
      "D(x): 0.351, D(G(z)): 0.572\n",
      "2019-04-10 00:55:43,168 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 13.634026\n",
      "Reconstruction: 12.956780, Regularization: 0.602055, Discriminator: 0.057631; Generator: 0.017558,\n",
      "D(x): 0.370, D(G(z)): 0.570\n",
      "2019-04-10 00:55:43,277 root         INFO     Train Epoch: 11 [7680/8000 (96%)]\tTotal Loss: 13.552413\n",
      "Reconstruction: 12.840930, Regularization: 0.636503, Discriminator: 0.057322; Generator: 0.017658,\n",
      "D(x): 0.371, D(G(z)): 0.568\n",
      "2019-04-10 00:55:43,358 root         INFO     ====> Epoch: 11 Average loss: 14.4387\n",
      "2019-04-10 00:55:43,384 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 13.674131\n",
      "Reconstruction: 12.875954, Regularization: 0.722886, Discriminator: 0.057559; Generator: 0.017732,\n",
      "D(x): 0.368, D(G(z)): 0.567\n",
      "2019-04-10 00:55:43,492 root         INFO     Train Epoch: 12 [512/8000 (6%)]\tTotal Loss: 13.670603\n",
      "Reconstruction: 12.895039, Regularization: 0.700922, Discriminator: 0.056793; Generator: 0.017849,\n",
      "D(x): 0.375, D(G(z)): 0.565\n",
      "2019-04-10 00:55:43,598 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 13.400497\n",
      "Reconstruction: 12.619572, Regularization: 0.706944, Discriminator: 0.056008; Generator: 0.017973,\n",
      "D(x): 0.382, D(G(z)): 0.563\n",
      "2019-04-10 00:55:43,704 root         INFO     Train Epoch: 12 [1536/8000 (19%)]\tTotal Loss: 13.292945\n",
      "Reconstruction: 12.531626, Regularization: 0.687967, Discriminator: 0.055273; Generator: 0.018080,\n",
      "D(x): 0.389, D(G(z)): 0.561\n",
      "2019-04-10 00:55:43,810 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 13.439750\n",
      "Reconstruction: 12.583115, Regularization: 0.783228, Discriminator: 0.055214; Generator: 0.018193,\n",
      "D(x): 0.388, D(G(z)): 0.559\n",
      "2019-04-10 00:55:43,917 root         INFO     Train Epoch: 12 [2560/8000 (32%)]\tTotal Loss: 13.006163\n",
      "Reconstruction: 12.224369, Regularization: 0.709564, Discriminator: 0.053917; Generator: 0.018312,\n",
      "D(x): 0.403, D(G(z)): 0.557\n",
      "2019-04-10 00:55:44,025 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 13.379152\n",
      "Reconstruction: 12.400064, Regularization: 0.906154, Discriminator: 0.054510; Generator: 0.018424,\n",
      "D(x): 0.393, D(G(z)): 0.555\n",
      "2019-04-10 00:55:44,133 root         INFO     Train Epoch: 12 [3584/8000 (45%)]\tTotal Loss: 13.392931\n",
      "Reconstruction: 12.495148, Regularization: 0.825713, Discriminator: 0.053526; Generator: 0.018544,\n",
      "D(x): 0.403, D(G(z)): 0.552\n",
      "2019-04-10 00:55:44,238 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 13.124681\n",
      "Reconstruction: 12.239673, Regularization: 0.813367, Discriminator: 0.052973; Generator: 0.018667,\n",
      "D(x): 0.409, D(G(z)): 0.550\n",
      "2019-04-10 00:55:44,343 root         INFO     Train Epoch: 12 [4608/8000 (58%)]\tTotal Loss: 12.903163\n",
      "Reconstruction: 11.985380, Regularization: 0.846789, Discriminator: 0.052218; Generator: 0.018775,\n",
      "D(x): 0.417, D(G(z)): 0.548\n",
      "2019-04-10 00:55:44,449 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 12.542150\n",
      "Reconstruction: 11.729564, Regularization: 0.742529, Discriminator: 0.051156; Generator: 0.018902,\n",
      "D(x): 0.429, D(G(z)): 0.546\n",
      "2019-04-10 00:55:44,555 root         INFO     Train Epoch: 12 [5632/8000 (70%)]\tTotal Loss: 12.931684\n",
      "Reconstruction: 12.031490, Regularization: 0.830220, Discriminator: 0.050940; Generator: 0.019036,\n",
      "D(x): 0.430, D(G(z)): 0.544\n",
      "2019-04-10 00:55:44,661 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 12.247618\n",
      "Reconstruction: 11.405599, Regularization: 0.772837, Discriminator: 0.050063; Generator: 0.019118,\n",
      "D(x): 0.441, D(G(z)): 0.542\n",
      "2019-04-10 00:55:44,767 root         INFO     Train Epoch: 12 [6656/8000 (83%)]\tTotal Loss: 12.427217\n",
      "Reconstruction: 11.534889, Regularization: 0.823269, Discriminator: 0.049808; Generator: 0.019251,\n",
      "D(x): 0.442, D(G(z)): 0.540\n",
      "2019-04-10 00:55:44,873 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 12.161916\n",
      "Reconstruction: 11.324258, Regularization: 0.769165, Discriminator: 0.049107; Generator: 0.019386,\n",
      "D(x): 0.450, D(G(z)): 0.538\n",
      "2019-04-10 00:55:44,979 root         INFO     Train Epoch: 12 [7680/8000 (96%)]\tTotal Loss: 12.149148\n",
      "Reconstruction: 11.333366, Regularization: 0.747642, Discriminator: 0.048638; Generator: 0.019501,\n",
      "D(x): 0.454, D(G(z)): 0.536\n",
      "2019-04-10 00:55:45,057 root         INFO     ====> Epoch: 12 Average loss: 12.7978\n",
      "2019-04-10 00:55:45,084 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 12.315528\n",
      "Reconstruction: 11.417385, Regularization: 0.830153, Discriminator: 0.048440; Generator: 0.019550,\n",
      "D(x): 0.457, D(G(z)): 0.535\n",
      "2019-04-10 00:55:45,194 root         INFO     Train Epoch: 13 [512/8000 (6%)]\tTotal Loss: 12.013599\n",
      "Reconstruction: 11.160071, Regularization: 0.786005, Discriminator: 0.047860; Generator: 0.019663,\n",
      "D(x): 0.463, D(G(z)): 0.533\n",
      "2019-04-10 00:55:45,303 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 11.860842\n",
      "Reconstruction: 11.081861, Regularization: 0.711944, Discriminator: 0.047229; Generator: 0.019809,\n",
      "D(x): 0.470, D(G(z)): 0.531\n",
      "2019-04-10 00:55:45,412 root         INFO     Train Epoch: 13 [1536/8000 (19%)]\tTotal Loss: 11.693398\n",
      "Reconstruction: 10.821837, Regularization: 0.805065, Discriminator: 0.046573; Generator: 0.019923,\n",
      "D(x): 0.478, D(G(z)): 0.529\n",
      "2019-04-10 00:55:45,521 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 11.932131\n",
      "Reconstruction: 11.024460, Regularization: 0.841444, Discriminator: 0.046140; Generator: 0.020086,\n",
      "D(x): 0.482, D(G(z)): 0.526\n",
      "2019-04-10 00:55:45,630 root         INFO     Train Epoch: 13 [2560/8000 (32%)]\tTotal Loss: 11.713670\n",
      "Reconstruction: 10.830822, Regularization: 0.816647, Discriminator: 0.046006; Generator: 0.020195,\n",
      "D(x): 0.482, D(G(z)): 0.524\n",
      "2019-04-10 00:55:45,738 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 11.759605\n",
      "Reconstruction: 10.607616, Regularization: 1.086252, Discriminator: 0.045432; Generator: 0.020305,\n",
      "D(x): 0.489, D(G(z)): 0.522\n",
      "2019-04-10 00:55:45,847 root         INFO     Train Epoch: 13 [3584/8000 (45%)]\tTotal Loss: 11.707765\n",
      "Reconstruction: 10.782348, Regularization: 0.860047, Discriminator: 0.044942; Generator: 0.020427,\n",
      "D(x): 0.495, D(G(z)): 0.520\n",
      "2019-04-10 00:55:45,955 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 11.585486\n",
      "Reconstruction: 10.618916, Regularization: 0.901549, Discriminator: 0.044497; Generator: 0.020525,\n",
      "D(x): 0.500, D(G(z)): 0.519\n",
      "2019-04-10 00:55:46,064 root         INFO     Train Epoch: 13 [4608/8000 (58%)]\tTotal Loss: 11.596655\n",
      "Reconstruction: 10.628178, Regularization: 0.903821, Discriminator: 0.044006; Generator: 0.020650,\n",
      "D(x): 0.506, D(G(z)): 0.516\n",
      "2019-04-10 00:55:46,172 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 11.677989\n",
      "Reconstruction: 10.605286, Regularization: 1.008366, Discriminator: 0.043567; Generator: 0.020770,\n",
      "D(x): 0.511, D(G(z)): 0.514\n",
      "2019-04-10 00:55:46,280 root         INFO     Train Epoch: 13 [5632/8000 (70%)]\tTotal Loss: 11.302940\n",
      "Reconstruction: 10.474097, Regularization: 0.764370, Discriminator: 0.043560; Generator: 0.020913,\n",
      "D(x): 0.509, D(G(z)): 0.512\n",
      "2019-04-10 00:55:46,389 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 11.488511\n",
      "Reconstruction: 10.402251, Regularization: 1.022575, Discriminator: 0.042696; Generator: 0.020988,\n",
      "D(x): 0.522, D(G(z)): 0.511\n",
      "2019-04-10 00:55:46,497 root         INFO     Train Epoch: 13 [6656/8000 (83%)]\tTotal Loss: 11.172525\n",
      "Reconstruction: 10.304673, Regularization: 0.803957, Discriminator: 0.042781; Generator: 0.021114,\n",
      "D(x): 0.518, D(G(z)): 0.509\n",
      "2019-04-10 00:55:46,605 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 11.141961\n",
      "Reconstruction: 10.171885, Regularization: 0.906777, Discriminator: 0.042053; Generator: 0.021248,\n",
      "D(x): 0.528, D(G(z)): 0.507\n",
      "2019-04-10 00:55:46,714 root         INFO     Train Epoch: 13 [7680/8000 (96%)]\tTotal Loss: 11.150840\n",
      "Reconstruction: 10.269711, Regularization: 0.817631, Discriminator: 0.042122; Generator: 0.021377,\n",
      "D(x): 0.525, D(G(z)): 0.505\n",
      "2019-04-10 00:55:46,793 root         INFO     ====> Epoch: 13 Average loss: 11.6083\n",
      "2019-04-10 00:55:46,821 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 10.819774\n",
      "Reconstruction: 9.985849, Regularization: 0.770867, Discriminator: 0.041668; Generator: 0.021389,\n",
      "D(x): 0.532, D(G(z)): 0.504\n",
      "2019-04-10 00:55:46,930 root         INFO     Train Epoch: 14 [512/8000 (6%)]\tTotal Loss: 11.146255\n",
      "Reconstruction: 10.193553, Regularization: 0.889903, Discriminator: 0.041269; Generator: 0.021531,\n",
      "D(x): 0.537, D(G(z)): 0.502\n",
      "2019-04-10 00:55:47,039 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 10.935161\n",
      "Reconstruction: 10.034725, Regularization: 0.838016, Discriminator: 0.040703; Generator: 0.021716,\n",
      "D(x): 0.543, D(G(z)): 0.499\n",
      "2019-04-10 00:55:47,149 root         INFO     Train Epoch: 14 [1536/8000 (19%)]\tTotal Loss: 10.978194\n",
      "Reconstruction: 10.033878, Regularization: 0.882217, Discriminator: 0.040304; Generator: 0.021795,\n",
      "D(x): 0.549, D(G(z)): 0.498\n",
      "2019-04-10 00:55:47,257 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 11.222855\n",
      "Reconstruction: 10.090746, Regularization: 1.070836, Discriminator: 0.039302; Generator: 0.021972,\n",
      "D(x): 0.564, D(G(z)): 0.495\n",
      "2019-04-10 00:55:47,366 root         INFO     Train Epoch: 14 [2560/8000 (32%)]\tTotal Loss: 11.267599\n",
      "Reconstruction: 10.160416, Regularization: 1.045852, Discriminator: 0.039300; Generator: 0.022032,\n",
      "D(x): 0.563, D(G(z)): 0.494\n",
      "2019-04-10 00:55:47,475 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 10.687463\n",
      "Reconstruction: 9.627571, Regularization: 0.998495, Discriminator: 0.039109; Generator: 0.022288,\n",
      "D(x): 0.562, D(G(z)): 0.490\n",
      "2019-04-10 00:55:47,584 root         INFO     Train Epoch: 14 [3584/8000 (45%)]\tTotal Loss: 11.033722\n",
      "Reconstruction: 10.047341, Regularization: 0.924999, Discriminator: 0.039064; Generator: 0.022318,\n",
      "D(x): 0.562, D(G(z)): 0.490\n",
      "2019-04-10 00:55:47,692 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 10.679327\n",
      "Reconstruction: 9.661858, Regularization: 0.956277, Discriminator: 0.038744; Generator: 0.022448,\n",
      "D(x): 0.566, D(G(z)): 0.488\n",
      "2019-04-10 00:55:47,798 root         INFO     Train Epoch: 14 [4608/8000 (58%)]\tTotal Loss: 10.788875\n",
      "Reconstruction: 9.714176, Regularization: 1.014430, Discriminator: 0.037788; Generator: 0.022481,\n",
      "D(x): 0.583, D(G(z)): 0.487\n",
      "2019-04-10 00:55:47,904 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 11.289041\n",
      "Reconstruction: 10.120483, Regularization: 1.108557, Discriminator: 0.037374; Generator: 0.022626,\n",
      "D(x): 0.588, D(G(z)): 0.485\n",
      "2019-04-10 00:55:48,009 root         INFO     Train Epoch: 14 [5632/8000 (70%)]\tTotal Loss: 10.743349\n",
      "Reconstruction: 9.717529, Regularization: 0.965397, Discriminator: 0.037639; Generator: 0.022783,\n",
      "D(x): 0.581, D(G(z)): 0.482\n",
      "2019-04-10 00:55:48,115 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 10.955278\n",
      "Reconstruction: 9.989551, Regularization: 0.905360, Discriminator: 0.037510; Generator: 0.022858,\n",
      "D(x): 0.581, D(G(z)): 0.481\n",
      "2019-04-10 00:55:48,222 root         INFO     Train Epoch: 14 [6656/8000 (83%)]\tTotal Loss: 10.834062\n",
      "Reconstruction: 9.812922, Regularization: 0.961372, Discriminator: 0.036747; Generator: 0.023020,\n",
      "D(x): 0.593, D(G(z)): 0.479\n",
      "2019-04-10 00:55:48,328 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 11.270953\n",
      "Reconstruction: 10.115683, Regularization: 1.096121, Discriminator: 0.036037; Generator: 0.023113,\n",
      "D(x): 0.605, D(G(z)): 0.477\n",
      "2019-04-10 00:55:48,434 root         INFO     Train Epoch: 14 [7680/8000 (96%)]\tTotal Loss: 11.485295\n",
      "Reconstruction: 10.166622, Regularization: 1.260384, Discriminator: 0.035139; Generator: 0.023151,\n",
      "D(x): 0.622, D(G(z)): 0.477\n",
      "2019-04-10 00:55:48,513 root         INFO     ====> Epoch: 14 Average loss: 10.9688\n",
      "2019-04-10 00:55:48,540 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 11.306636\n",
      "Reconstruction: 10.182686, Regularization: 1.064357, Discriminator: 0.036329; Generator: 0.023264,\n",
      "D(x): 0.597, D(G(z)): 0.475\n",
      "2019-04-10 00:55:48,648 root         INFO     Train Epoch: 15 [512/8000 (6%)]\tTotal Loss: 10.365807\n",
      "Reconstruction: 9.376842, Regularization: 0.929132, Discriminator: 0.036432; Generator: 0.023399,\n",
      "D(x): 0.594, D(G(z)): 0.473\n",
      "2019-04-10 00:55:48,753 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 10.782516\n",
      "Reconstruction: 9.669476, Regularization: 1.054205, Discriminator: 0.035317; Generator: 0.023518,\n",
      "D(x): 0.613, D(G(z)): 0.471\n",
      "2019-04-10 00:55:48,859 root         INFO     Train Epoch: 15 [1536/8000 (19%)]\tTotal Loss: 10.417523\n",
      "Reconstruction: 9.403872, Regularization: 0.954439, Discriminator: 0.035530; Generator: 0.023682,\n",
      "D(x): 0.605, D(G(z)): 0.469\n",
      "2019-04-10 00:55:48,966 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 10.307969\n",
      "Reconstruction: 9.322668, Regularization: 0.926199, Discriminator: 0.035390; Generator: 0.023712,\n",
      "D(x): 0.608, D(G(z)): 0.468\n",
      "2019-04-10 00:55:49,073 root         INFO     Train Epoch: 15 [2560/8000 (32%)]\tTotal Loss: 11.046239\n",
      "Reconstruction: 9.875545, Regularization: 1.112383, Discriminator: 0.034426; Generator: 0.023886,\n",
      "D(x): 0.624, D(G(z)): 0.466\n",
      "2019-04-10 00:55:49,179 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 10.558803\n",
      "Reconstruction: 9.569269, Regularization: 0.931066, Discriminator: 0.034485; Generator: 0.023982,\n",
      "D(x): 0.620, D(G(z)): 0.464\n",
      "2019-04-10 00:55:49,286 root         INFO     Train Epoch: 15 [3584/8000 (45%)]\tTotal Loss: 10.557793\n",
      "Reconstruction: 9.547530, Regularization: 0.951601, Discriminator: 0.034629; Generator: 0.024032,\n",
      "D(x): 0.618, D(G(z)): 0.464\n",
      "2019-04-10 00:55:49,392 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 11.194419\n",
      "Reconstruction: 9.926546, Regularization: 1.210485, Discriminator: 0.033205; Generator: 0.024183,\n",
      "D(x): 0.643, D(G(z)): 0.461\n",
      "2019-04-10 00:55:49,499 root         INFO     Train Epoch: 15 [4608/8000 (58%)]\tTotal Loss: 10.143989\n",
      "Reconstruction: 9.136719, Regularization: 0.948549, Discriminator: 0.034374; Generator: 0.024346,\n",
      "D(x): 0.618, D(G(z)): 0.459\n",
      "2019-04-10 00:55:49,606 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 10.582614\n",
      "Reconstruction: 9.489325, Regularization: 1.035691, Discriminator: 0.033234; Generator: 0.024364,\n",
      "D(x): 0.640, D(G(z)): 0.459\n",
      "2019-04-10 00:55:49,713 root         INFO     Train Epoch: 15 [5632/8000 (70%)]\tTotal Loss: 10.702805\n",
      "Reconstruction: 9.527033, Regularization: 1.118691, Discriminator: 0.032524; Generator: 0.024557,\n",
      "D(x): 0.652, D(G(z)): 0.456\n",
      "2019-04-10 00:55:49,821 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 10.026256\n",
      "Reconstruction: 9.054340, Regularization: 0.913079, Discriminator: 0.034303; Generator: 0.024534,\n",
      "D(x): 0.618, D(G(z)): 0.456\n",
      "2019-04-10 00:55:49,929 root         INFO     Train Epoch: 15 [6656/8000 (83%)]\tTotal Loss: 11.093073\n",
      "Reconstruction: 9.866834, Regularization: 1.169484, Discriminator: 0.032091; Generator: 0.024664,\n",
      "D(x): 0.659, D(G(z)): 0.454\n",
      "2019-04-10 00:55:50,039 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 10.623861\n",
      "Reconstruction: 9.465403, Regularization: 1.101110, Discriminator: 0.032638; Generator: 0.024710,\n",
      "D(x): 0.648, D(G(z)): 0.454\n",
      "2019-04-10 00:55:50,147 root         INFO     Train Epoch: 15 [7680/8000 (96%)]\tTotal Loss: 11.014719\n",
      "Reconstruction: 9.692224, Regularization: 1.266177, Discriminator: 0.031389; Generator: 0.024930,\n",
      "D(x): 0.670, D(G(z)): 0.450\n",
      "2019-04-10 00:55:50,227 root         INFO     ====> Epoch: 15 Average loss: 10.7410\n",
      "2019-04-10 00:55:50,254 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 10.541103\n",
      "Reconstruction: 9.359297, Regularization: 1.125007, Discriminator: 0.031910; Generator: 0.024889,\n",
      "D(x): 0.659, D(G(z)): 0.451\n",
      "2019-04-10 00:55:50,364 root         INFO     Train Epoch: 16 [512/8000 (6%)]\tTotal Loss: 10.271174\n",
      "Reconstruction: 9.219515, Regularization: 0.993814, Discriminator: 0.032636; Generator: 0.025210,\n",
      "D(x): 0.640, D(G(z)): 0.446\n",
      "2019-04-10 00:55:50,473 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 10.911324\n",
      "Reconstruction: 9.619874, Regularization: 1.235550, Discriminator: 0.030781; Generator: 0.025118,\n",
      "D(x): 0.678, D(G(z)): 0.448\n",
      "2019-04-10 00:55:50,583 root         INFO     Train Epoch: 16 [1536/8000 (19%)]\tTotal Loss: 9.667801\n",
      "Reconstruction: 8.669312, Regularization: 0.941252, Discriminator: 0.031835; Generator: 0.025402,\n",
      "D(x): 0.653, D(G(z)): 0.444\n",
      "2019-04-10 00:55:50,692 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 10.498780\n",
      "Reconstruction: 9.239525, Regularization: 1.203449, Discriminator: 0.030547; Generator: 0.025260,\n",
      "D(x): 0.683, D(G(z)): 0.446\n",
      "2019-04-10 00:55:50,800 root         INFO     Train Epoch: 16 [2560/8000 (32%)]\tTotal Loss: 10.476863\n",
      "Reconstruction: 9.242815, Regularization: 1.177605, Discriminator: 0.031117; Generator: 0.025326,\n",
      "D(x): 0.671, D(G(z)): 0.445\n",
      "2019-04-10 00:55:50,909 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 10.710165\n",
      "Reconstruction: 9.401812, Regularization: 1.252243, Discriminator: 0.030596; Generator: 0.025515,\n",
      "D(x): 0.679, D(G(z)): 0.442\n",
      "2019-04-10 00:55:51,018 root         INFO     Train Epoch: 16 [3584/8000 (45%)]\tTotal Loss: 10.257706\n",
      "Reconstruction: 9.063648, Regularization: 1.137768, Discriminator: 0.030678; Generator: 0.025612,\n",
      "D(x): 0.675, D(G(z)): 0.441\n",
      "2019-04-10 00:55:51,127 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 9.183309\n",
      "Reconstruction: 8.232264, Regularization: 0.893527, Discriminator: 0.031969; Generator: 0.025549,\n",
      "D(x): 0.649, D(G(z)): 0.442\n",
      "2019-04-10 00:55:51,235 root         INFO     Train Epoch: 16 [4608/8000 (58%)]\tTotal Loss: 9.405194\n",
      "Reconstruction: 8.413948, Regularization: 0.934044, Discriminator: 0.031403; Generator: 0.025798,\n",
      "D(x): 0.656, D(G(z)): 0.438\n",
      "2019-04-10 00:55:51,342 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 10.358417\n",
      "Reconstruction: 9.201780, Regularization: 1.100418, Discriminator: 0.030361; Generator: 0.025857,\n",
      "D(x): 0.676, D(G(z)): 0.437\n",
      "2019-04-10 00:55:51,449 root         INFO     Train Epoch: 16 [5632/8000 (70%)]\tTotal Loss: 9.856994\n",
      "Reconstruction: 8.731364, Regularization: 1.069160, Discriminator: 0.030466; Generator: 0.026004,\n",
      "D(x): 0.674, D(G(z)): 0.435\n",
      "2019-04-10 00:55:51,555 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 10.816317\n",
      "Reconstruction: 9.468097, Regularization: 1.293379, Discriminator: 0.028770; Generator: 0.026071,\n",
      "D(x): 0.707, D(G(z)): 0.434\n",
      "2019-04-10 00:55:51,662 root         INFO     Train Epoch: 16 [6656/8000 (83%)]\tTotal Loss: 10.319368\n",
      "Reconstruction: 9.089057, Regularization: 1.175182, Discriminator: 0.028895; Generator: 0.026235,\n",
      "D(x): 0.702, D(G(z)): 0.432\n",
      "2019-04-10 00:55:51,769 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 9.732991\n",
      "Reconstruction: 8.656542, Regularization: 1.020511, Discriminator: 0.029705; Generator: 0.026233,\n",
      "D(x): 0.684, D(G(z)): 0.432\n",
      "2019-04-10 00:55:51,875 root         INFO     Train Epoch: 16 [7680/8000 (96%)]\tTotal Loss: 10.417162\n",
      "Reconstruction: 9.110995, Regularization: 1.251275, Discriminator: 0.028590; Generator: 0.026301,\n",
      "D(x): 0.709, D(G(z)): 0.431\n",
      "2019-04-10 00:55:51,953 root         INFO     ====> Epoch: 16 Average loss: 10.3778\n",
      "2019-04-10 00:55:51,980 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 9.838724\n",
      "Reconstruction: 8.674088, Regularization: 1.109340, Discriminator: 0.028936; Generator: 0.026359,\n",
      "D(x): 0.701, D(G(z)): 0.430\n",
      "2019-04-10 00:55:52,089 root         INFO     Train Epoch: 17 [512/8000 (6%)]\tTotal Loss: 10.615492\n",
      "Reconstruction: 9.256413, Regularization: 1.304732, Discriminator: 0.027887; Generator: 0.026459,\n",
      "D(x): 0.721, D(G(z)): 0.429\n",
      "2019-04-10 00:55:52,198 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 10.099142\n",
      "Reconstruction: 8.751236, Regularization: 1.292715, Discriminator: 0.028557; Generator: 0.026634,\n",
      "D(x): 0.711, D(G(z)): 0.426\n",
      "2019-04-10 00:55:52,308 root         INFO     Train Epoch: 17 [1536/8000 (19%)]\tTotal Loss: 10.055817\n",
      "Reconstruction: 8.842695, Regularization: 1.158182, Discriminator: 0.028325; Generator: 0.026614,\n",
      "D(x): 0.710, D(G(z)): 0.427\n",
      "2019-04-10 00:55:52,417 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 10.858622\n",
      "Reconstruction: 9.514187, Regularization: 1.290641, Discriminator: 0.027114; Generator: 0.026680,\n",
      "D(x): 0.735, D(G(z)): 0.426\n",
      "2019-04-10 00:55:52,526 root         INFO     Train Epoch: 17 [2560/8000 (32%)]\tTotal Loss: 10.623804\n",
      "Reconstruction: 9.305122, Regularization: 1.264412, Discriminator: 0.027568; Generator: 0.026701,\n",
      "D(x): 0.727, D(G(z)): 0.426\n",
      "2019-04-10 00:55:52,635 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 10.122412\n",
      "Reconstruction: 8.877348, Regularization: 1.190442, Discriminator: 0.027870; Generator: 0.026753,\n",
      "D(x): 0.719, D(G(z)): 0.425\n",
      "2019-04-10 00:55:52,744 root         INFO     Train Epoch: 17 [3584/8000 (45%)]\tTotal Loss: 10.654292\n",
      "Reconstruction: 9.337208, Regularization: 1.263554, Discriminator: 0.026602; Generator: 0.026928,\n",
      "D(x): 0.742, D(G(z)): 0.422\n",
      "2019-04-10 00:55:52,853 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 9.644846\n",
      "Reconstruction: 8.516862, Regularization: 1.072852, Discriminator: 0.028167; Generator: 0.026965,\n",
      "D(x): 0.708, D(G(z)): 0.422\n",
      "2019-04-10 00:55:52,962 root         INFO     Train Epoch: 17 [4608/8000 (58%)]\tTotal Loss: 10.586317\n",
      "Reconstruction: 9.279225, Regularization: 1.253531, Discriminator: 0.026440; Generator: 0.027121,\n",
      "D(x): 0.743, D(G(z)): 0.420\n",
      "2019-04-10 00:55:53,071 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 11.253935\n",
      "Reconstruction: 9.771444, Regularization: 1.429328, Discriminator: 0.026020; Generator: 0.027143,\n",
      "D(x): 0.756, D(G(z)): 0.420\n",
      "2019-04-10 00:55:53,181 root         INFO     Train Epoch: 17 [5632/8000 (70%)]\tTotal Loss: 9.806041\n",
      "Reconstruction: 8.660788, Regularization: 1.090335, Discriminator: 0.027720; Generator: 0.027198,\n",
      "D(x): 0.715, D(G(z)): 0.419\n",
      "2019-04-10 00:55:53,289 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 10.283448\n",
      "Reconstruction: 9.077834, Regularization: 1.151415, Discriminator: 0.026954; Generator: 0.027244,\n",
      "D(x): 0.730, D(G(z)): 0.418\n",
      "2019-04-10 00:55:53,399 root         INFO     Train Epoch: 17 [6656/8000 (83%)]\tTotal Loss: 11.694304\n",
      "Reconstruction: 10.182734, Regularization: 1.459382, Discriminator: 0.024808; Generator: 0.027379,\n",
      "D(x): 0.778, D(G(z)): 0.416\n",
      "2019-04-10 00:55:53,508 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 10.282840\n",
      "Reconstruction: 9.114609, Regularization: 1.113820, Discriminator: 0.026980; Generator: 0.027430,\n",
      "D(x): 0.727, D(G(z)): 0.416\n",
      "2019-04-10 00:55:53,617 root         INFO     Train Epoch: 17 [7680/8000 (96%)]\tTotal Loss: 11.542135\n",
      "Reconstruction: 10.097668, Regularization: 1.391273, Discriminator: 0.025784; Generator: 0.027410,\n",
      "D(x): 0.755, D(G(z)): 0.416\n",
      "2019-04-10 00:55:53,697 root         INFO     ====> Epoch: 17 Average loss: 10.4807\n",
      "2019-04-10 00:55:53,725 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 10.604265\n",
      "Reconstruction: 9.381599, Regularization: 1.169130, Discriminator: 0.026042; Generator: 0.027494,\n",
      "D(x): 0.746, D(G(z)): 0.415\n",
      "2019-04-10 00:55:53,835 root         INFO     Train Epoch: 18 [512/8000 (6%)]\tTotal Loss: 11.056128\n",
      "Reconstruction: 9.689533, Regularization: 1.312663, Discriminator: 0.026407; Generator: 0.027524,\n",
      "D(x): 0.743, D(G(z)): 0.414\n",
      "2019-04-10 00:55:53,946 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 10.437351\n",
      "Reconstruction: 9.173109, Regularization: 1.210870, Discriminator: 0.025697; Generator: 0.027674,\n",
      "D(x): 0.754, D(G(z)): 0.412\n",
      "2019-04-10 00:55:54,056 root         INFO     Train Epoch: 18 [1536/8000 (19%)]\tTotal Loss: 10.732108\n",
      "Reconstruction: 9.445237, Regularization: 1.233120, Discriminator: 0.026030; Generator: 0.027721,\n",
      "D(x): 0.748, D(G(z)): 0.412\n",
      "2019-04-10 00:55:54,166 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 10.422514\n",
      "Reconstruction: 9.209751, Regularization: 1.159260, Discriminator: 0.025666; Generator: 0.027837,\n",
      "D(x): 0.751, D(G(z)): 0.410\n",
      "2019-04-10 00:55:54,277 root         INFO     Train Epoch: 18 [2560/8000 (32%)]\tTotal Loss: 11.674793\n",
      "Reconstruction: 10.250784, Regularization: 1.371883, Discriminator: 0.024331; Generator: 0.027795,\n",
      "D(x): 0.784, D(G(z)): 0.411\n",
      "2019-04-10 00:55:54,388 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 11.185751\n",
      "Reconstruction: 9.800468, Regularization: 1.332329, Discriminator: 0.024994; Generator: 0.027960,\n",
      "D(x): 0.768, D(G(z)): 0.409\n",
      "2019-04-10 00:55:54,498 root         INFO     Train Epoch: 18 [3584/8000 (45%)]\tTotal Loss: 9.824634\n",
      "Reconstruction: 8.731030, Regularization: 1.039218, Discriminator: 0.026414; Generator: 0.027972,\n",
      "D(x): 0.732, D(G(z)): 0.409\n",
      "2019-04-10 00:55:54,609 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 10.352077\n",
      "Reconstruction: 9.156301, Regularization: 1.141562, Discriminator: 0.026162; Generator: 0.028052,\n",
      "D(x): 0.738, D(G(z)): 0.408\n",
      "2019-04-10 00:55:54,719 root         INFO     Train Epoch: 18 [4608/8000 (58%)]\tTotal Loss: 11.314969\n",
      "Reconstruction: 9.954151, Regularization: 1.308298, Discriminator: 0.024426; Generator: 0.028094,\n",
      "D(x): 0.778, D(G(z)): 0.407\n",
      "2019-04-10 00:55:54,829 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 10.744425\n",
      "Reconstruction: 9.503914, Regularization: 1.187225, Discriminator: 0.025110; Generator: 0.028176,\n",
      "D(x): 0.759, D(G(z)): 0.406\n",
      "2019-04-10 00:55:54,940 root         INFO     Train Epoch: 18 [5632/8000 (70%)]\tTotal Loss: 10.672112\n",
      "Reconstruction: 9.444732, Regularization: 1.174261, Discriminator: 0.024946; Generator: 0.028175,\n",
      "D(x): 0.764, D(G(z)): 0.406\n",
      "2019-04-10 00:55:55,050 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 10.289575\n",
      "Reconstruction: 9.103279, Regularization: 1.133524, Discriminator: 0.024540; Generator: 0.028232,\n",
      "D(x): 0.770, D(G(z)): 0.405\n",
      "2019-04-10 00:55:55,160 root         INFO     Train Epoch: 18 [6656/8000 (83%)]\tTotal Loss: 11.693369\n",
      "Reconstruction: 10.236857, Regularization: 1.404180, Discriminator: 0.024007; Generator: 0.028325,\n",
      "D(x): 0.787, D(G(z)): 0.404\n",
      "2019-04-10 00:55:55,270 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 10.512078\n",
      "Reconstruction: 9.266031, Regularization: 1.192520, Discriminator: 0.025157; Generator: 0.028371,\n",
      "D(x): 0.759, D(G(z)): 0.403\n",
      "2019-04-10 00:55:55,381 root         INFO     Train Epoch: 18 [7680/8000 (96%)]\tTotal Loss: 10.789911\n",
      "Reconstruction: 9.516027, Regularization: 1.221619, Discriminator: 0.023870; Generator: 0.028394,\n",
      "D(x): 0.786, D(G(z)): 0.403\n",
      "2019-04-10 00:55:55,461 root         INFO     ====> Epoch: 18 Average loss: 11.0432\n",
      "2019-04-10 00:55:55,488 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 12.180853\n",
      "Reconstruction: 10.687173, Regularization: 1.442746, Discriminator: 0.022501; Generator: 0.028432,\n",
      "D(x): 0.819, D(G(z)): 0.403\n",
      "2019-04-10 00:55:55,596 root         INFO     Train Epoch: 19 [512/8000 (6%)]\tTotal Loss: 10.875748\n",
      "Reconstruction: 9.600191, Regularization: 1.223340, Discriminator: 0.023721; Generator: 0.028496,\n",
      "D(x): 0.787, D(G(z)): 0.402\n",
      "2019-04-10 00:55:55,705 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 12.166670\n",
      "Reconstruction: 10.722393, Regularization: 1.392959, Discriminator: 0.022787; Generator: 0.028532,\n",
      "D(x): 0.813, D(G(z)): 0.401\n",
      "2019-04-10 00:55:55,812 root         INFO     Train Epoch: 19 [1536/8000 (19%)]\tTotal Loss: 10.618987\n",
      "Reconstruction: 9.342374, Regularization: 1.222925, Discriminator: 0.025108; Generator: 0.028580,\n",
      "D(x): 0.756, D(G(z)): 0.401\n",
      "2019-04-10 00:55:55,920 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 10.741363\n",
      "Reconstruction: 9.495914, Regularization: 1.192575, Discriminator: 0.024230; Generator: 0.028642,\n",
      "D(x): 0.777, D(G(z)): 0.400\n",
      "2019-04-10 00:55:56,028 root         INFO     Train Epoch: 19 [2560/8000 (32%)]\tTotal Loss: 11.858562\n",
      "Reconstruction: 10.486462, Regularization: 1.319223, Discriminator: 0.024198; Generator: 0.028679,\n",
      "D(x): 0.782, D(G(z)): 0.399\n",
      "2019-04-10 00:55:56,137 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 10.605149\n",
      "Reconstruction: 9.393120, Regularization: 1.158920, Discriminator: 0.024381; Generator: 0.028729,\n",
      "D(x): 0.774, D(G(z)): 0.399\n",
      "2019-04-10 00:55:56,245 root         INFO     Train Epoch: 19 [3584/8000 (45%)]\tTotal Loss: 12.581161\n",
      "Reconstruction: 11.125726, Regularization: 1.404664, Discriminator: 0.021996; Generator: 0.028775,\n",
      "D(x): 0.825, D(G(z)): 0.398\n",
      "2019-04-10 00:55:56,352 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 12.146233\n",
      "Reconstruction: 10.717422, Regularization: 1.376789, Discriminator: 0.023198; Generator: 0.028823,\n",
      "D(x): 0.799, D(G(z)): 0.398\n",
      "2019-04-10 00:55:56,460 root         INFO     Train Epoch: 19 [4608/8000 (58%)]\tTotal Loss: 10.067615\n",
      "Reconstruction: 8.913520, Regularization: 1.101698, Discriminator: 0.023549; Generator: 0.028848,\n",
      "D(x): 0.788, D(G(z)): 0.397\n",
      "2019-04-10 00:55:56,568 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 11.441824\n",
      "Reconstruction: 10.121704, Regularization: 1.268789, Discriminator: 0.022433; Generator: 0.028898,\n",
      "D(x): 0.814, D(G(z)): 0.397\n",
      "2019-04-10 00:55:56,676 root         INFO     Train Epoch: 19 [5632/8000 (70%)]\tTotal Loss: 10.921810\n",
      "Reconstruction: 9.676899, Regularization: 1.192393, Discriminator: 0.023576; Generator: 0.028942,\n",
      "D(x): 0.786, D(G(z)): 0.396\n",
      "2019-04-10 00:55:56,781 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 13.165399\n",
      "Reconstruction: 11.609643, Regularization: 1.505993, Discriminator: 0.020779; Generator: 0.028984,\n",
      "D(x): 0.854, D(G(z)): 0.396\n",
      "2019-04-10 00:55:56,888 root         INFO     Train Epoch: 19 [6656/8000 (83%)]\tTotal Loss: 10.148805\n",
      "Reconstruction: 8.960351, Regularization: 1.136065, Discriminator: 0.023358; Generator: 0.029031,\n",
      "D(x): 0.790, D(G(z)): 0.395\n",
      "2019-04-10 00:55:56,994 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 9.365902\n",
      "Reconstruction: 8.277653, Regularization: 1.035373, Discriminator: 0.023812; Generator: 0.029064,\n",
      "D(x): 0.783, D(G(z)): 0.395\n",
      "2019-04-10 00:55:57,099 root         INFO     Train Epoch: 19 [7680/8000 (96%)]\tTotal Loss: 11.477691\n",
      "Reconstruction: 10.148589, Regularization: 1.277507, Discriminator: 0.022491; Generator: 0.029104,\n",
      "D(x): 0.812, D(G(z)): 0.394\n",
      "2019-04-10 00:55:57,177 root         INFO     ====> Epoch: 19 Average loss: 11.3414\n",
      "2019-04-10 00:55:57,204 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 11.560186\n",
      "Reconstruction: 10.211643, Regularization: 1.297801, Discriminator: 0.021601; Generator: 0.029142,\n",
      "D(x): 0.831, D(G(z)): 0.394\n",
      "2019-04-10 00:55:57,313 root         INFO     Train Epoch: 20 [512/8000 (6%)]\tTotal Loss: 10.668427\n",
      "Reconstruction: 9.428722, Regularization: 1.188254, Discriminator: 0.022268; Generator: 0.029181,\n",
      "D(x): 0.815, D(G(z)): 0.393\n",
      "2019-04-10 00:55:57,421 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 10.259554\n",
      "Reconstruction: 9.074637, Regularization: 1.133271, Discriminator: 0.022430; Generator: 0.029215,\n",
      "D(x): 0.807, D(G(z)): 0.393\n",
      "2019-04-10 00:55:57,530 root         INFO     Train Epoch: 20 [1536/8000 (19%)]\tTotal Loss: 10.648081\n",
      "Reconstruction: 9.402507, Regularization: 1.193481, Discriminator: 0.022859; Generator: 0.029233,\n",
      "D(x): 0.800, D(G(z)): 0.392\n",
      "2019-04-10 00:55:57,638 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 10.131065\n",
      "Reconstruction: 8.932712, Regularization: 1.146682, Discriminator: 0.022396; Generator: 0.029276,\n",
      "D(x): 0.810, D(G(z)): 0.392\n",
      "2019-04-10 00:55:57,747 root         INFO     Train Epoch: 20 [2560/8000 (32%)]\tTotal Loss: 11.548193\n",
      "Reconstruction: 10.212652, Regularization: 1.284080, Discriminator: 0.022118; Generator: 0.029343,\n",
      "D(x): 0.819, D(G(z)): 0.391\n",
      "2019-04-10 00:55:57,856 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 10.487329\n",
      "Reconstruction: 9.276896, Regularization: 1.159206, Discriminator: 0.021859; Generator: 0.029367,\n",
      "D(x): 0.822, D(G(z)): 0.391\n",
      "2019-04-10 00:55:57,964 root         INFO     Train Epoch: 20 [3584/8000 (45%)]\tTotal Loss: 11.057918\n",
      "Reconstruction: 9.778081, Regularization: 1.228888, Discriminator: 0.021572; Generator: 0.029377,\n",
      "D(x): 0.830, D(G(z)): 0.391\n",
      "2019-04-10 00:55:58,072 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 11.483554\n",
      "Reconstruction: 10.152086, Regularization: 1.280641, Discriminator: 0.021444; Generator: 0.029382,\n",
      "D(x): 0.833, D(G(z)): 0.391\n",
      "2019-04-10 00:55:58,179 root         INFO     Train Epoch: 20 [4608/8000 (58%)]\tTotal Loss: 11.340602\n",
      "Reconstruction: 10.019173, Regularization: 1.271196, Discriminator: 0.020794; Generator: 0.029439,\n",
      "D(x): 0.847, D(G(z)): 0.390\n",
      "2019-04-10 00:55:58,287 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 10.698549\n",
      "Reconstruction: 9.444971, Regularization: 1.202736, Discriminator: 0.021445; Generator: 0.029398,\n",
      "D(x): 0.833, D(G(z)): 0.390\n",
      "2019-04-10 00:55:58,395 root         INFO     Train Epoch: 20 [5632/8000 (70%)]\tTotal Loss: 10.110891\n",
      "Reconstruction: 8.944741, Regularization: 1.114919, Discriminator: 0.021701; Generator: 0.029531,\n",
      "D(x): 0.826, D(G(z)): 0.389\n",
      "2019-04-10 00:55:58,503 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 11.772483\n",
      "Reconstruction: 10.427454, Regularization: 1.292706, Discriminator: 0.022754; Generator: 0.029568,\n",
      "D(x): 0.813, D(G(z)): 0.388\n",
      "2019-04-10 00:55:58,611 root         INFO     Train Epoch: 20 [6656/8000 (83%)]\tTotal Loss: 9.465110\n",
      "Reconstruction: 8.363209, Regularization: 1.050507, Discriminator: 0.021789; Generator: 0.029604,\n",
      "D(x): 0.818, D(G(z)): 0.388\n",
      "2019-04-10 00:55:58,719 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 10.164701\n",
      "Reconstruction: 8.987859, Regularization: 1.125588, Discriminator: 0.021609; Generator: 0.029645,\n",
      "D(x): 0.824, D(G(z)): 0.387\n",
      "2019-04-10 00:55:58,828 root         INFO     Train Epoch: 20 [7680/8000 (96%)]\tTotal Loss: 12.210551\n",
      "Reconstruction: 10.800715, Regularization: 1.360438, Discriminator: 0.019770; Generator: 0.029627,\n",
      "D(x): 0.871, D(G(z)): 0.387\n",
      "2019-04-10 00:55:58,908 root         INFO     ====> Epoch: 20 Average loss: 10.9650\n",
      "2019-04-10 00:55:58,935 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 11.039198\n",
      "Reconstruction: 9.762689, Regularization: 1.225846, Discriminator: 0.021017; Generator: 0.029646,\n",
      "D(x): 0.842, D(G(z)): 0.387\n",
      "2019-04-10 00:55:59,045 root         INFO     Train Epoch: 21 [512/8000 (6%)]\tTotal Loss: 10.628945\n",
      "Reconstruction: 9.373828, Regularization: 1.204840, Discriminator: 0.020647; Generator: 0.029630,\n",
      "D(x): 0.852, D(G(z)): 0.387\n",
      "2019-04-10 00:55:59,156 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 9.651212\n",
      "Reconstruction: 8.539145, Regularization: 1.061258, Discriminator: 0.021076; Generator: 0.029734,\n",
      "D(x): 0.835, D(G(z)): 0.386\n",
      "2019-04-10 00:55:59,264 root         INFO     Train Epoch: 21 [1536/8000 (19%)]\tTotal Loss: 10.087270\n",
      "Reconstruction: 8.949573, Regularization: 1.086609, Discriminator: 0.021382; Generator: 0.029706,\n",
      "D(x): 0.830, D(G(z)): 0.387\n",
      "2019-04-10 00:55:59,371 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 11.002236\n",
      "Reconstruction: 9.741433, Regularization: 1.211283, Discriminator: 0.019761; Generator: 0.029758,\n",
      "D(x): 0.870, D(G(z)): 0.386\n",
      "2019-04-10 00:55:59,480 root         INFO     Train Epoch: 21 [2560/8000 (32%)]\tTotal Loss: 9.368333\n",
      "Reconstruction: 8.324582, Regularization: 0.991669, Discriminator: 0.022258; Generator: 0.029825,\n",
      "D(x): 0.808, D(G(z)): 0.385\n",
      "2019-04-10 00:55:59,588 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 10.760287\n",
      "Reconstruction: 9.554729, Regularization: 1.156044, Discriminator: 0.019744; Generator: 0.029770,\n",
      "D(x): 0.868, D(G(z)): 0.386\n",
      "2019-04-10 00:55:59,696 root         INFO     Train Epoch: 21 [3584/8000 (45%)]\tTotal Loss: 11.729835\n",
      "Reconstruction: 10.425013, Regularization: 1.255257, Discriminator: 0.019764; Generator: 0.029801,\n",
      "D(x): 0.869, D(G(z)): 0.385\n",
      "2019-04-10 00:55:59,804 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 10.276360\n",
      "Reconstruction: 9.117088, Regularization: 1.109019, Discriminator: 0.020480; Generator: 0.029773,\n",
      "D(x): 0.852, D(G(z)): 0.386\n",
      "2019-04-10 00:55:59,913 root         INFO     Train Epoch: 21 [4608/8000 (58%)]\tTotal Loss: 10.816037\n",
      "Reconstruction: 9.603963, Regularization: 1.162593, Discriminator: 0.019590; Generator: 0.029892,\n",
      "D(x): 0.872, D(G(z)): 0.384\n",
      "2019-04-10 00:56:00,021 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 10.787313\n",
      "Reconstruction: 9.588947, Regularization: 1.148630, Discriminator: 0.019860; Generator: 0.029876,\n",
      "D(x): 0.865, D(G(z)): 0.384\n",
      "2019-04-10 00:56:00,129 root         INFO     Train Epoch: 21 [5632/8000 (70%)]\tTotal Loss: 11.187887\n",
      "Reconstruction: 9.936769, Regularization: 1.201810, Discriminator: 0.019438; Generator: 0.029869,\n",
      "D(x): 0.876, D(G(z)): 0.385\n",
      "2019-04-10 00:56:00,237 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 12.789725\n",
      "Reconstruction: 11.370346, Regularization: 1.370795, Discriminator: 0.018686; Generator: 0.029898,\n",
      "D(x): 0.901, D(G(z)): 0.384\n",
      "2019-04-10 00:56:00,344 root         INFO     Train Epoch: 21 [6656/8000 (83%)]\tTotal Loss: 11.166059\n",
      "Reconstruction: 9.917593, Regularization: 1.199227, Discriminator: 0.019219; Generator: 0.030021,\n",
      "D(x): 0.879, D(G(z)): 0.383\n",
      "2019-04-10 00:56:00,450 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 9.062257\n",
      "Reconstruction: 8.006584, Regularization: 1.005921, Discriminator: 0.019751; Generator: 0.030001,\n",
      "D(x): 0.864, D(G(z)): 0.383\n",
      "2019-04-10 00:56:00,558 root         INFO     Train Epoch: 21 [7680/8000 (96%)]\tTotal Loss: 8.743512\n",
      "Reconstruction: 7.734617, Regularization: 0.958280, Discriminator: 0.020733; Generator: 0.029882,\n",
      "D(x): 0.844, D(G(z)): 0.384\n",
      "2019-04-10 00:56:00,636 root         INFO     ====> Epoch: 21 Average loss: 10.4526\n",
      "2019-04-10 00:56:00,663 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 9.294789\n",
      "Reconstruction: 8.227951, Regularization: 1.016912, Discriminator: 0.019978; Generator: 0.029947,\n",
      "D(x): 0.864, D(G(z)): 0.384\n",
      "2019-04-10 00:56:00,773 root         INFO     Train Epoch: 22 [512/8000 (6%)]\tTotal Loss: 10.681782\n",
      "Reconstruction: 9.512769, Regularization: 1.119455, Discriminator: 0.019515; Generator: 0.030043,\n",
      "D(x): 0.874, D(G(z)): 0.382\n",
      "2019-04-10 00:56:00,881 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 8.792122\n",
      "Reconstruction: 7.788338, Regularization: 0.953473, Discriminator: 0.020191; Generator: 0.030120,\n",
      "D(x): 0.855, D(G(z)): 0.381\n",
      "2019-04-10 00:56:00,990 root         INFO     Train Epoch: 22 [1536/8000 (19%)]\tTotal Loss: 8.926098\n",
      "Reconstruction: 7.897985, Regularization: 0.978708, Discriminator: 0.019355; Generator: 0.030050,\n",
      "D(x): 0.875, D(G(z)): 0.382\n",
      "2019-04-10 00:56:01,098 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 8.425866\n",
      "Reconstruction: 7.459742, Regularization: 0.915525, Discriminator: 0.020559; Generator: 0.030040,\n",
      "D(x): 0.847, D(G(z)): 0.382\n",
      "2019-04-10 00:56:01,207 root         INFO     Train Epoch: 22 [2560/8000 (32%)]\tTotal Loss: 11.547269\n",
      "Reconstruction: 10.315489, Regularization: 1.182628, Discriminator: 0.019191; Generator: 0.029961,\n",
      "D(x): 0.884, D(G(z)): 0.383\n",
      "2019-04-10 00:56:01,316 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 11.315036\n",
      "Reconstruction: 10.087801, Regularization: 1.178407, Discriminator: 0.018732; Generator: 0.030095,\n",
      "D(x): 0.895, D(G(z)): 0.382\n",
      "2019-04-10 00:56:01,425 root         INFO     Train Epoch: 22 [3584/8000 (45%)]\tTotal Loss: 9.600751\n",
      "Reconstruction: 8.531606, Regularization: 1.019999, Discriminator: 0.019093; Generator: 0.030053,\n",
      "D(x): 0.884, D(G(z)): 0.382\n",
      "2019-04-10 00:56:01,533 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 9.650208\n",
      "Reconstruction: 8.570459, Regularization: 1.030469, Discriminator: 0.019095; Generator: 0.030184,\n",
      "D(x): 0.881, D(G(z)): 0.381\n",
      "2019-04-10 00:56:01,642 root         INFO     Train Epoch: 22 [4608/8000 (58%)]\tTotal Loss: 9.995842\n",
      "Reconstruction: 8.900813, Regularization: 1.046139, Discriminator: 0.018904; Generator: 0.029986,\n",
      "D(x): 0.890, D(G(z)): 0.383\n",
      "2019-04-10 00:56:01,751 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 8.185465\n",
      "Reconstruction: 7.260102, Regularization: 0.874358, Discriminator: 0.020963; Generator: 0.030042,\n",
      "D(x): 0.839, D(G(z)): 0.382\n",
      "2019-04-10 00:56:01,859 root         INFO     Train Epoch: 22 [5632/8000 (70%)]\tTotal Loss: 8.823509\n",
      "Reconstruction: 7.820905, Regularization: 0.953164, Discriminator: 0.019337; Generator: 0.030104,\n",
      "D(x): 0.876, D(G(z)): 0.382\n",
      "2019-04-10 00:56:01,968 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 8.200886\n",
      "Reconstruction: 7.251376, Regularization: 0.900087, Discriminator: 0.019337; Generator: 0.030086,\n",
      "D(x): 0.879, D(G(z)): 0.382\n",
      "2019-04-10 00:56:02,076 root         INFO     Train Epoch: 22 [6656/8000 (83%)]\tTotal Loss: 9.009712\n",
      "Reconstruction: 7.951147, Regularization: 1.010172, Discriminator: 0.018374; Generator: 0.030019,\n",
      "D(x): 0.904, D(G(z)): 0.383\n",
      "2019-04-10 00:56:02,185 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 7.887390\n",
      "Reconstruction: 6.967196, Regularization: 0.870208, Discriminator: 0.019831; Generator: 0.030154,\n",
      "D(x): 0.866, D(G(z)): 0.381\n",
      "2019-04-10 00:56:02,293 root         INFO     Train Epoch: 22 [7680/8000 (96%)]\tTotal Loss: 8.580185\n",
      "Reconstruction: 7.604731, Regularization: 0.926141, Discriminator: 0.019242; Generator: 0.030071,\n",
      "D(x): 0.879, D(G(z)): 0.382\n",
      "2019-04-10 00:56:02,374 root         INFO     ====> Epoch: 22 Average loss: 9.3724\n",
      "2019-04-10 00:56:02,401 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 9.239624\n",
      "Reconstruction: 8.213153, Regularization: 0.977303, Discriminator: 0.019111; Generator: 0.030057,\n",
      "D(x): 0.886, D(G(z)): 0.382\n",
      "2019-04-10 00:56:02,511 root         INFO     Train Epoch: 23 [512/8000 (6%)]\tTotal Loss: 8.193470\n",
      "Reconstruction: 7.256813, Regularization: 0.887128, Discriminator: 0.019338; Generator: 0.030191,\n",
      "D(x): 0.875, D(G(z)): 0.381\n",
      "2019-04-10 00:56:02,622 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 9.227649\n",
      "Reconstruction: 8.205413, Regularization: 0.972253, Discriminator: 0.019931; Generator: 0.030052,\n",
      "D(x): 0.869, D(G(z)): 0.382\n",
      "2019-04-10 00:56:02,733 root         INFO     Train Epoch: 23 [1536/8000 (19%)]\tTotal Loss: 8.673560\n",
      "Reconstruction: 7.693672, Regularization: 0.931359, Discriminator: 0.018480; Generator: 0.030049,\n",
      "D(x): 0.900, D(G(z)): 0.382\n",
      "2019-04-10 00:56:02,844 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 7.517411\n",
      "Reconstruction: 6.626324, Regularization: 0.842075, Discriminator: 0.018819; Generator: 0.030194,\n",
      "D(x): 0.887, D(G(z)): 0.381\n",
      "2019-04-10 00:56:02,954 root         INFO     Train Epoch: 23 [2560/8000 (32%)]\tTotal Loss: 8.599797\n",
      "Reconstruction: 7.614170, Regularization: 0.936993, Discriminator: 0.018382; Generator: 0.030251,\n",
      "D(x): 0.900, D(G(z)): 0.380\n",
      "2019-04-10 00:56:03,065 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 8.104529\n",
      "Reconstruction: 7.166130, Regularization: 0.889298, Discriminator: 0.018895; Generator: 0.030206,\n",
      "D(x): 0.888, D(G(z)): 0.380\n",
      "2019-04-10 00:56:03,175 root         INFO     Train Epoch: 23 [3584/8000 (45%)]\tTotal Loss: 7.717506\n",
      "Reconstruction: 6.803133, Regularization: 0.865202, Discriminator: 0.019018; Generator: 0.030153,\n",
      "D(x): 0.888, D(G(z)): 0.381\n",
      "2019-04-10 00:56:03,286 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 7.479242\n",
      "Reconstruction: 6.586501, Regularization: 0.844319, Discriminator: 0.018208; Generator: 0.030215,\n",
      "D(x): 0.904, D(G(z)): 0.380\n",
      "2019-04-10 00:56:03,396 root         INFO     Train Epoch: 23 [4608/8000 (58%)]\tTotal Loss: 7.298406\n",
      "Reconstruction: 6.434642, Regularization: 0.815073, Discriminator: 0.018497; Generator: 0.030195,\n",
      "D(x): 0.897, D(G(z)): 0.381\n",
      "2019-04-10 00:56:03,507 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 7.327638\n",
      "Reconstruction: 6.482356, Regularization: 0.795345, Discriminator: 0.019625; Generator: 0.030312,\n",
      "D(x): 0.872, D(G(z)): 0.379\n",
      "2019-04-10 00:56:03,618 root         INFO     Train Epoch: 23 [5632/8000 (70%)]\tTotal Loss: 7.680209\n",
      "Reconstruction: 6.796609, Regularization: 0.834411, Discriminator: 0.018955; Generator: 0.030235,\n",
      "D(x): 0.887, D(G(z)): 0.380\n",
      "2019-04-10 00:56:03,727 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 7.432920\n",
      "Reconstruction: 6.569922, Regularization: 0.813895, Discriminator: 0.018790; Generator: 0.030312,\n",
      "D(x): 0.891, D(G(z)): 0.379\n",
      "2019-04-10 00:56:03,836 root         INFO     Train Epoch: 23 [6656/8000 (83%)]\tTotal Loss: 8.737126\n",
      "Reconstruction: 7.752552, Regularization: 0.936593, Discriminator: 0.017456; Generator: 0.030525,\n",
      "D(x): 0.920, D(G(z)): 0.377\n",
      "2019-04-10 00:56:03,945 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 7.617158\n",
      "Reconstruction: 6.742805, Regularization: 0.825963, Discriminator: 0.017958; Generator: 0.030433,\n",
      "D(x): 0.907, D(G(z)): 0.378\n",
      "2019-04-10 00:56:04,052 root         INFO     Train Epoch: 23 [7680/8000 (96%)]\tTotal Loss: 7.440086\n",
      "Reconstruction: 6.559703, Regularization: 0.832446, Discriminator: 0.017309; Generator: 0.030628,\n",
      "D(x): 0.922, D(G(z)): 0.375\n",
      "2019-04-10 00:56:04,132 root         INFO     ====> Epoch: 23 Average loss: 7.7767\n",
      "2019-04-10 00:56:04,159 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 6.329896\n",
      "Reconstruction: 5.581537, Regularization: 0.698633, Discriminator: 0.019411; Generator: 0.030314,\n",
      "D(x): 0.873, D(G(z)): 0.379\n",
      "2019-04-10 00:56:04,271 root         INFO     Train Epoch: 24 [512/8000 (6%)]\tTotal Loss: 7.647749\n",
      "Reconstruction: 6.784037, Regularization: 0.815062, Discriminator: 0.018397; Generator: 0.030253,\n",
      "D(x): 0.902, D(G(z)): 0.380\n",
      "2019-04-10 00:56:04,382 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 7.414011\n",
      "Reconstruction: 6.562187, Regularization: 0.803343, Discriminator: 0.017935; Generator: 0.030546,\n",
      "D(x): 0.907, D(G(z)): 0.376\n",
      "2019-04-10 00:56:04,492 root         INFO     Train Epoch: 24 [1536/8000 (19%)]\tTotal Loss: 7.359939\n",
      "Reconstruction: 6.591247, Regularization: 0.718648, Discriminator: 0.019492; Generator: 0.030552,\n",
      "D(x): 0.870, D(G(z)): 0.376\n",
      "2019-04-10 00:56:04,602 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 7.461722\n",
      "Reconstruction: 6.601018, Regularization: 0.812727, Discriminator: 0.017325; Generator: 0.030652,\n",
      "D(x): 0.925, D(G(z)): 0.375\n",
      "2019-04-10 00:56:04,711 root         INFO     Train Epoch: 24 [2560/8000 (32%)]\tTotal Loss: 8.100662\n",
      "Reconstruction: 7.201382, Regularization: 0.850973, Discriminator: 0.017717; Generator: 0.030591,\n",
      "D(x): 0.914, D(G(z)): 0.376\n",
      "2019-04-10 00:56:04,820 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 6.524470\n",
      "Reconstruction: 5.747097, Regularization: 0.728567, Discriminator: 0.018128; Generator: 0.030679,\n",
      "D(x): 0.901, D(G(z)): 0.375\n",
      "2019-04-10 00:56:04,929 root         INFO     Train Epoch: 24 [3584/8000 (45%)]\tTotal Loss: 6.664235\n",
      "Reconstruction: 5.889407, Regularization: 0.725509, Discriminator: 0.018521; Generator: 0.030797,\n",
      "D(x): 0.890, D(G(z)): 0.373\n",
      "2019-04-10 00:56:05,039 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 7.548241\n",
      "Reconstruction: 6.701179, Regularization: 0.798959, Discriminator: 0.017409; Generator: 0.030695,\n",
      "D(x): 0.920, D(G(z)): 0.375\n",
      "2019-04-10 00:56:05,148 root         INFO     Train Epoch: 24 [4608/8000 (58%)]\tTotal Loss: 5.658801\n",
      "Reconstruction: 4.942408, Regularization: 0.667978, Discriminator: 0.017523; Generator: 0.030892,\n",
      "D(x): 0.911, D(G(z)): 0.372\n",
      "2019-04-10 00:56:05,258 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 5.204479\n",
      "Reconstruction: 4.521449, Regularization: 0.634709, Discriminator: 0.017350; Generator: 0.030971,\n",
      "D(x): 0.915, D(G(z)): 0.371\n",
      "2019-04-10 00:56:05,367 root         INFO     Train Epoch: 24 [5632/8000 (70%)]\tTotal Loss: 4.777027\n",
      "Reconstruction: 4.152865, Regularization: 0.573863, Discriminator: 0.019017; Generator: 0.031281,\n",
      "D(x): 0.873, D(G(z)): 0.368\n",
      "2019-04-10 00:56:05,476 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 6.091756\n",
      "Reconstruction: 5.331097, Regularization: 0.712370, Discriminator: 0.016989; Generator: 0.031300,\n",
      "D(x): 0.921, D(G(z)): 0.367\n",
      "2019-04-10 00:56:05,586 root         INFO     Train Epoch: 24 [6656/8000 (83%)]\tTotal Loss: 5.862623\n",
      "Reconstruction: 5.135287, Regularization: 0.678807, Discriminator: 0.017046; Generator: 0.031482,\n",
      "D(x): 0.916, D(G(z)): 0.365\n",
      "2019-04-10 00:56:05,694 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 5.668803\n",
      "Reconstruction: 4.950433, Regularization: 0.669635, Discriminator: 0.017514; Generator: 0.031221,\n",
      "D(x): 0.909, D(G(z)): 0.368\n",
      "2019-04-10 00:56:05,803 root         INFO     Train Epoch: 24 [7680/8000 (96%)]\tTotal Loss: 5.288312\n",
      "Reconstruction: 4.593190, Regularization: 0.646582, Discriminator: 0.017116; Generator: 0.031423,\n",
      "D(x): 0.914, D(G(z)): 0.366\n",
      "2019-04-10 00:56:05,882 root         INFO     ====> Epoch: 24 Average loss: 6.2961\n",
      "2019-04-10 00:56:05,910 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 5.749629\n",
      "Reconstruction: 4.987687, Regularization: 0.714140, Discriminator: 0.016043; Generator: 0.031759,\n",
      "D(x): 0.939, D(G(z)): 0.362\n",
      "2019-04-10 00:56:06,022 root         INFO     Train Epoch: 25 [512/8000 (6%)]\tTotal Loss: 5.321002\n",
      "Reconstruction: 4.605362, Regularization: 0.666937, Discriminator: 0.016735; Generator: 0.031967,\n",
      "D(x): 0.917, D(G(z)): 0.360\n",
      "2019-04-10 00:56:06,132 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 4.690787\n",
      "Reconstruction: 4.047657, Regularization: 0.594453, Discriminator: 0.016728; Generator: 0.031949,\n",
      "D(x): 0.916, D(G(z)): 0.360\n",
      "2019-04-10 00:56:06,242 root         INFO     Train Epoch: 25 [1536/8000 (19%)]\tTotal Loss: 5.242977\n",
      "Reconstruction: 4.541203, Regularization: 0.653389, Discriminator: 0.016510; Generator: 0.031875,\n",
      "D(x): 0.925, D(G(z)): 0.361\n",
      "2019-04-10 00:56:06,352 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 5.292949\n",
      "Reconstruction: 4.583989, Regularization: 0.660638, Discriminator: 0.016277; Generator: 0.032045,\n",
      "D(x): 0.928, D(G(z)): 0.359\n",
      "2019-04-10 00:56:06,462 root         INFO     Train Epoch: 25 [2560/8000 (32%)]\tTotal Loss: 4.478037\n",
      "Reconstruction: 3.852045, Regularization: 0.576860, Discriminator: 0.016954; Generator: 0.032179,\n",
      "D(x): 0.908, D(G(z)): 0.357\n",
      "2019-04-10 00:56:06,572 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 4.869043\n",
      "Reconstruction: 4.212008, Regularization: 0.608109, Discriminator: 0.016359; Generator: 0.032566,\n",
      "D(x): 0.918, D(G(z)): 0.353\n",
      "2019-04-10 00:56:06,683 root         INFO     Train Epoch: 25 [3584/8000 (45%)]\tTotal Loss: 4.819259\n",
      "Reconstruction: 4.154475, Regularization: 0.615644, Discriminator: 0.016621; Generator: 0.032519,\n",
      "D(x): 0.916, D(G(z)): 0.353\n",
      "2019-04-10 00:56:06,793 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 4.874907\n",
      "Reconstruction: 4.219647, Regularization: 0.606243, Discriminator: 0.016164; Generator: 0.032853,\n",
      "D(x): 0.919, D(G(z)): 0.350\n",
      "2019-04-10 00:56:06,903 root         INFO     Train Epoch: 25 [4608/8000 (58%)]\tTotal Loss: 4.030258\n",
      "Reconstruction: 3.455048, Regularization: 0.524900, Discriminator: 0.017067; Generator: 0.033242,\n",
      "D(x): 0.895, D(G(z)): 0.345\n",
      "2019-04-10 00:56:07,013 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 3.491222\n",
      "Reconstruction: 2.952852, Regularization: 0.488240, Discriminator: 0.016932; Generator: 0.033199,\n",
      "D(x): 0.895, D(G(z)): 0.346\n",
      "2019-04-10 00:56:07,123 root         INFO     Train Epoch: 25 [5632/8000 (70%)]\tTotal Loss: 4.173939\n",
      "Reconstruction: 3.551652, Regularization: 0.573330, Discriminator: 0.015720; Generator: 0.033237,\n",
      "D(x): 0.926, D(G(z)): 0.345\n",
      "2019-04-10 00:56:07,233 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 5.260338\n",
      "Reconstruction: 4.523664, Regularization: 0.688256, Discriminator: 0.014984; Generator: 0.033434,\n",
      "D(x): 0.945, D(G(z)): 0.343\n",
      "2019-04-10 00:56:07,343 root         INFO     Train Epoch: 25 [6656/8000 (83%)]\tTotal Loss: 3.592643\n",
      "Reconstruction: 3.041076, Regularization: 0.501549, Discriminator: 0.016264; Generator: 0.033755,\n",
      "D(x): 0.903, D(G(z)): 0.340\n",
      "2019-04-10 00:56:07,453 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 3.956803\n",
      "Reconstruction: 3.378132, Regularization: 0.528839, Discriminator: 0.016002; Generator: 0.033830,\n",
      "D(x): 0.910, D(G(z)): 0.339\n",
      "2019-04-10 00:56:07,564 root         INFO     Train Epoch: 25 [7680/8000 (96%)]\tTotal Loss: 5.039092\n",
      "Reconstruction: 4.342199, Regularization: 0.647735, Discriminator: 0.015006; Generator: 0.034151,\n",
      "D(x): 0.933, D(G(z)): 0.335\n",
      "2019-04-10 00:56:07,644 root         INFO     ====> Epoch: 25 Average loss: 4.6085\n",
      "2019-04-10 00:56:07,671 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 4.210301\n",
      "Reconstruction: 3.592725, Regularization: 0.568323, Discriminator: 0.014787; Generator: 0.034466,\n",
      "D(x): 0.934, D(G(z)): 0.332\n",
      "2019-04-10 00:56:07,780 root         INFO     Train Epoch: 26 [512/8000 (6%)]\tTotal Loss: 4.291739\n",
      "Reconstruction: 3.665479, Regularization: 0.576767, Discriminator: 0.014690; Generator: 0.034803,\n",
      "D(x): 0.932, D(G(z)): 0.328\n",
      "2019-04-10 00:56:07,890 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 3.865022\n",
      "Reconstruction: 3.283908, Regularization: 0.531460, Discriminator: 0.014780; Generator: 0.034875,\n",
      "D(x): 0.929, D(G(z)): 0.328\n",
      "2019-04-10 00:56:08,000 root         INFO     Train Epoch: 26 [1536/8000 (19%)]\tTotal Loss: 3.844629\n",
      "Reconstruction: 3.260774, Regularization: 0.534323, Discriminator: 0.014452; Generator: 0.035079,\n",
      "D(x): 0.935, D(G(z)): 0.326\n",
      "2019-04-10 00:56:08,111 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 3.899887\n",
      "Reconstruction: 3.318486, Regularization: 0.531342, Discriminator: 0.014647; Generator: 0.035412,\n",
      "D(x): 0.926, D(G(z)): 0.322\n",
      "2019-04-10 00:56:08,223 root         INFO     Train Epoch: 26 [2560/8000 (32%)]\tTotal Loss: 4.558446\n",
      "Reconstruction: 3.904676, Regularization: 0.604399, Discriminator: 0.013413; Generator: 0.035958,\n",
      "D(x): 0.953, D(G(z)): 0.316\n",
      "2019-04-10 00:56:08,335 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 3.816552\n",
      "Reconstruction: 3.239073, Regularization: 0.527223, Discriminator: 0.014221; Generator: 0.036036,\n",
      "D(x): 0.930, D(G(z)): 0.316\n",
      "2019-04-10 00:56:08,447 root         INFO     Train Epoch: 26 [3584/8000 (45%)]\tTotal Loss: 3.295818\n",
      "Reconstruction: 2.782086, Regularization: 0.462647, Discriminator: 0.014468; Generator: 0.036617,\n",
      "D(x): 0.916, D(G(z)): 0.310\n",
      "2019-04-10 00:56:08,559 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 3.548419\n",
      "Reconstruction: 2.993540, Regularization: 0.504143, Discriminator: 0.013885; Generator: 0.036851,\n",
      "D(x): 0.929, D(G(z)): 0.308\n",
      "2019-04-10 00:56:08,671 root         INFO     Train Epoch: 26 [4608/8000 (58%)]\tTotal Loss: 2.509184\n",
      "Reconstruction: 2.078663, Regularization: 0.378649, Discriminator: 0.014713; Generator: 0.037159,\n",
      "D(x): 0.901, D(G(z)): 0.305\n",
      "2019-04-10 00:56:08,781 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 3.780048\n",
      "Reconstruction: 3.208114, Regularization: 0.520347, Discriminator: 0.014399; Generator: 0.037189,\n",
      "D(x): 0.915, D(G(z)): 0.304\n",
      "2019-04-10 00:56:08,892 root         INFO     Train Epoch: 26 [5632/8000 (70%)]\tTotal Loss: 3.437830\n",
      "Reconstruction: 2.893259, Regularization: 0.493774, Discriminator: 0.012914; Generator: 0.037883,\n",
      "D(x): 0.943, D(G(z)): 0.298\n",
      "2019-04-10 00:56:09,003 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 2.644349\n",
      "Reconstruction: 2.195053, Regularization: 0.397487, Discriminator: 0.013671; Generator: 0.038138,\n",
      "D(x): 0.918, D(G(z)): 0.295\n",
      "2019-04-10 00:56:09,113 root         INFO     Train Epoch: 26 [6656/8000 (83%)]\tTotal Loss: 3.033315\n",
      "Reconstruction: 2.536933, Regularization: 0.445266, Discriminator: 0.012899; Generator: 0.038216,\n",
      "D(x): 0.939, D(G(z)): 0.294\n",
      "2019-04-10 00:56:09,224 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 2.920959\n",
      "Reconstruction: 2.438893, Regularization: 0.430392, Discriminator: 0.012803; Generator: 0.038871,\n",
      "D(x): 0.934, D(G(z)): 0.288\n",
      "2019-04-10 00:56:09,334 root         INFO     Train Epoch: 26 [7680/8000 (96%)]\tTotal Loss: 3.264723\n",
      "Reconstruction: 2.750608, Regularization: 0.461697, Discriminator: 0.013244; Generator: 0.039174,\n",
      "D(x): 0.921, D(G(z)): 0.286\n",
      "2019-04-10 00:56:09,416 root         INFO     ====> Epoch: 26 Average loss: 3.6187\n",
      "2019-04-10 00:56:09,443 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 3.100604\n",
      "Reconstruction: 2.592962, Regularization: 0.455862, Discriminator: 0.012222; Generator: 0.039558,\n",
      "D(x): 0.943, D(G(z)): 0.282\n",
      "2019-04-10 00:56:09,554 root         INFO     Train Epoch: 27 [512/8000 (6%)]\tTotal Loss: 3.322973\n",
      "Reconstruction: 2.782205, Regularization: 0.489147, Discriminator: 0.011817; Generator: 0.039805,\n",
      "D(x): 0.952, D(G(z)): 0.280\n",
      "2019-04-10 00:56:09,663 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 2.843936\n",
      "Reconstruction: 2.380531, Regularization: 0.410168, Discriminator: 0.012990; Generator: 0.040247,\n",
      "D(x): 0.915, D(G(z)): 0.276\n",
      "2019-04-10 00:56:09,772 root         INFO     Train Epoch: 27 [1536/8000 (19%)]\tTotal Loss: 2.805399\n",
      "Reconstruction: 2.327420, Regularization: 0.425227, Discriminator: 0.012084; Generator: 0.040668,\n",
      "D(x): 0.935, D(G(z)): 0.272\n",
      "2019-04-10 00:56:09,881 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 3.105614\n",
      "Reconstruction: 2.597878, Regularization: 0.454936, Discriminator: 0.011799; Generator: 0.041001,\n",
      "D(x): 0.940, D(G(z)): 0.269\n",
      "2019-04-10 00:56:09,990 root         INFO     Train Epoch: 27 [2560/8000 (32%)]\tTotal Loss: 2.843093\n",
      "Reconstruction: 2.378098, Regularization: 0.411405, Discriminator: 0.012048; Generator: 0.041542,\n",
      "D(x): 0.928, D(G(z)): 0.265\n",
      "2019-04-10 00:56:10,099 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 2.398000\n",
      "Reconstruction: 1.988355, Regularization: 0.355223, Discriminator: 0.012500; Generator: 0.041921,\n",
      "D(x): 0.913, D(G(z)): 0.261\n",
      "2019-04-10 00:56:10,208 root         INFO     Train Epoch: 27 [3584/8000 (45%)]\tTotal Loss: 2.817948\n",
      "Reconstruction: 2.355793, Regularization: 0.408252, Discriminator: 0.011499; Generator: 0.042404,\n",
      "D(x): 0.935, D(G(z)): 0.257\n",
      "2019-04-10 00:56:10,318 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 2.587473\n",
      "Reconstruction: 2.153310, Regularization: 0.380107, Discriminator: 0.011158; Generator: 0.042899,\n",
      "D(x): 0.939, D(G(z)): 0.253\n",
      "2019-04-10 00:56:10,427 root         INFO     Train Epoch: 27 [4608/8000 (58%)]\tTotal Loss: 2.715865\n",
      "Reconstruction: 2.264473, Regularization: 0.397159, Discriminator: 0.010960; Generator: 0.043273,\n",
      "D(x): 0.941, D(G(z)): 0.250\n",
      "2019-04-10 00:56:10,536 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 3.102308\n",
      "Reconstruction: 2.585335, Regularization: 0.463079, Discriminator: 0.010147; Generator: 0.043748,\n",
      "D(x): 0.960, D(G(z)): 0.247\n",
      "2019-04-10 00:56:10,646 root         INFO     Train Epoch: 27 [5632/8000 (70%)]\tTotal Loss: 2.538739\n",
      "Reconstruction: 2.113915, Regularization: 0.369738, Discriminator: 0.010923; Generator: 0.044164,\n",
      "D(x): 0.934, D(G(z)): 0.243\n",
      "2019-04-10 00:56:10,755 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 2.264752\n",
      "Reconstruction: 1.870754, Regularization: 0.338756, Discriminator: 0.010518; Generator: 0.044725,\n",
      "D(x): 0.940, D(G(z)): 0.239\n",
      "2019-04-10 00:56:10,864 root         INFO     Train Epoch: 27 [6656/8000 (83%)]\tTotal Loss: 2.574342\n",
      "Reconstruction: 2.171240, Regularization: 0.346918, Discriminator: 0.011021; Generator: 0.045163,\n",
      "D(x): 0.923, D(G(z)): 0.236\n",
      "2019-04-10 00:56:10,973 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 2.834406\n",
      "Reconstruction: 2.394146, Regularization: 0.383662, Discriminator: 0.010924; Generator: 0.045673,\n",
      "D(x): 0.924, D(G(z)): 0.232\n",
      "2019-04-10 00:56:11,082 root         INFO     Train Epoch: 27 [7680/8000 (96%)]\tTotal Loss: 2.625340\n",
      "Reconstruction: 2.184280, Regularization: 0.385007, Discriminator: 0.009912; Generator: 0.046141,\n",
      "D(x): 0.945, D(G(z)): 0.228\n",
      "2019-04-10 00:56:11,162 root         INFO     ====> Epoch: 27 Average loss: 2.9178\n",
      "2019-04-10 00:56:11,190 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 2.502206\n",
      "Reconstruction: 2.081628, Regularization: 0.364165, Discriminator: 0.009953; Generator: 0.046460,\n",
      "D(x): 0.942, D(G(z)): 0.226\n",
      "2019-04-10 00:56:11,303 root         INFO     Train Epoch: 28 [512/8000 (6%)]\tTotal Loss: 2.352833\n",
      "Reconstruction: 1.950633, Regularization: 0.345673, Discriminator: 0.009589; Generator: 0.046938,\n",
      "D(x): 0.947, D(G(z)): 0.223\n",
      "2019-04-10 00:56:11,411 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 2.740700\n",
      "Reconstruction: 2.289567, Regularization: 0.394336, Discriminator: 0.009397; Generator: 0.047400,\n",
      "D(x): 0.949, D(G(z)): 0.219\n",
      "2019-04-10 00:56:11,521 root         INFO     Train Epoch: 28 [1536/8000 (19%)]\tTotal Loss: 2.425025\n",
      "Reconstruction: 2.023672, Regularization: 0.344252, Discriminator: 0.009276; Generator: 0.047825,\n",
      "D(x): 0.949, D(G(z)): 0.216\n",
      "2019-04-10 00:56:11,629 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 2.686773\n",
      "Reconstruction: 2.246764, Regularization: 0.382695, Discriminator: 0.008948; Generator: 0.048366,\n",
      "D(x): 0.956, D(G(z)): 0.213\n",
      "2019-04-10 00:56:11,739 root         INFO     Train Epoch: 28 [2560/8000 (32%)]\tTotal Loss: 2.832167\n",
      "Reconstruction: 2.402711, Regularization: 0.371372, Discriminator: 0.009291; Generator: 0.048792,\n",
      "D(x): 0.942, D(G(z)): 0.210\n",
      "2019-04-10 00:56:11,848 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 2.415521\n",
      "Reconstruction: 2.019676, Regularization: 0.337789, Discriminator: 0.008787; Generator: 0.049269,\n",
      "D(x): 0.952, D(G(z)): 0.207\n",
      "2019-04-10 00:56:11,957 root         INFO     Train Epoch: 28 [3584/8000 (45%)]\tTotal Loss: 2.649925\n",
      "Reconstruction: 2.227485, Regularization: 0.364282, Discriminator: 0.008415; Generator: 0.049743,\n",
      "D(x): 0.960, D(G(z)): 0.204\n",
      "2019-04-10 00:56:12,066 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 2.880988\n",
      "Reconstruction: 2.434187, Regularization: 0.388528, Discriminator: 0.008083; Generator: 0.050190,\n",
      "D(x): 0.966, D(G(z)): 0.201\n",
      "2019-04-10 00:56:12,174 root         INFO     Train Epoch: 28 [4608/8000 (58%)]\tTotal Loss: 2.580286\n",
      "Reconstruction: 2.165709, Regularization: 0.355685, Discriminator: 0.008245; Generator: 0.050647,\n",
      "D(x): 0.958, D(G(z)): 0.198\n",
      "2019-04-10 00:56:12,285 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 2.395153\n",
      "Reconstruction: 1.999841, Regularization: 0.336076, Discriminator: 0.008142; Generator: 0.051094,\n",
      "D(x): 0.958, D(G(z)): 0.195\n",
      "2019-04-10 00:56:12,397 root         INFO     Train Epoch: 28 [5632/8000 (70%)]\tTotal Loss: 2.561085\n",
      "Reconstruction: 2.156969, Regularization: 0.344627, Discriminator: 0.007960; Generator: 0.051529,\n",
      "D(x): 0.961, D(G(z)): 0.192\n",
      "2019-04-10 00:56:12,509 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 2.684472\n",
      "Reconstruction: 2.269280, Regularization: 0.355335, Discriminator: 0.007895; Generator: 0.051963,\n",
      "D(x): 0.959, D(G(z)): 0.190\n",
      "2019-04-10 00:56:12,622 root         INFO     Train Epoch: 28 [6656/8000 (83%)]\tTotal Loss: 2.313429\n",
      "Reconstruction: 1.935473, Regularization: 0.317852, Discriminator: 0.007700; Generator: 0.052404,\n",
      "D(x): 0.962, D(G(z)): 0.187\n",
      "2019-04-10 00:56:12,734 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 2.144293\n",
      "Reconstruction: 1.787193, Regularization: 0.296183, Discriminator: 0.008110; Generator: 0.052808,\n",
      "D(x): 0.949, D(G(z)): 0.185\n",
      "2019-04-10 00:56:12,845 root         INFO     Train Epoch: 28 [7680/8000 (96%)]\tTotal Loss: 2.046083\n",
      "Reconstruction: 1.709019, Regularization: 0.275913, Discriminator: 0.007938; Generator: 0.053213,\n",
      "D(x): 0.949, D(G(z)): 0.182\n",
      "2019-04-10 00:56:12,926 root         INFO     ====> Epoch: 28 Average loss: 2.4997\n",
      "2019-04-10 00:56:12,953 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 2.465785\n",
      "Reconstruction: 2.080096, Regularization: 0.324823, Discriminator: 0.007341; Generator: 0.053526,\n",
      "D(x): 0.965, D(G(z)): 0.180\n",
      "2019-04-10 00:56:13,065 root         INFO     Train Epoch: 29 [512/8000 (6%)]\tTotal Loss: 2.337616\n",
      "Reconstruction: 1.966472, Regularization: 0.309748, Discriminator: 0.007472; Generator: 0.053925,\n",
      "D(x): 0.959, D(G(z)): 0.178\n",
      "2019-04-10 00:56:13,177 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 2.191988\n",
      "Reconstruction: 1.842873, Regularization: 0.287372, Discriminator: 0.007457; Generator: 0.054285,\n",
      "D(x): 0.957, D(G(z)): 0.176\n",
      "2019-04-10 00:56:13,290 root         INFO     Train Epoch: 29 [1536/8000 (19%)]\tTotal Loss: 2.644645\n",
      "Reconstruction: 2.258922, Regularization: 0.323968, Discriminator: 0.007079; Generator: 0.054677,\n",
      "D(x): 0.966, D(G(z)): 0.174\n",
      "2019-04-10 00:56:13,403 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 2.447041\n",
      "Reconstruction: 2.070489, Regularization: 0.314521, Discriminator: 0.006928; Generator: 0.055103,\n",
      "D(x): 0.967, D(G(z)): 0.171\n",
      "2019-04-10 00:56:13,515 root         INFO     Train Epoch: 29 [2560/8000 (32%)]\tTotal Loss: 2.186018\n",
      "Reconstruction: 1.842193, Regularization: 0.281313, Discriminator: 0.007081; Generator: 0.055430,\n",
      "D(x): 0.961, D(G(z)): 0.170\n",
      "2019-04-10 00:56:13,625 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 2.054440\n",
      "Reconstruction: 1.725621, Regularization: 0.266035, Discriminator: 0.006974; Generator: 0.055810,\n",
      "D(x): 0.961, D(G(z)): 0.168\n",
      "2019-04-10 00:56:13,736 root         INFO     Train Epoch: 29 [3584/8000 (45%)]\tTotal Loss: 2.637277\n",
      "Reconstruction: 2.262500, Regularization: 0.311687, Discriminator: 0.006876; Generator: 0.056214,\n",
      "D(x): 0.963, D(G(z)): 0.165\n",
      "2019-04-10 00:56:13,847 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 1.813727\n",
      "Reconstruction: 1.517821, Regularization: 0.232403, Discriminator: 0.006973; Generator: 0.056530,\n",
      "D(x): 0.957, D(G(z)): 0.164\n",
      "2019-04-10 00:56:13,958 root         INFO     Train Epoch: 29 [4608/8000 (58%)]\tTotal Loss: 2.448982\n",
      "Reconstruction: 2.080447, Regularization: 0.305119, Discriminator: 0.006600; Generator: 0.056816,\n",
      "D(x): 0.967, D(G(z)): 0.162\n",
      "2019-04-10 00:56:14,070 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 2.308293\n",
      "Reconstruction: 1.964091, Regularization: 0.280428, Discriminator: 0.006540; Generator: 0.057234,\n",
      "D(x): 0.966, D(G(z)): 0.160\n",
      "2019-04-10 00:56:14,182 root         INFO     Train Epoch: 29 [5632/8000 (70%)]\tTotal Loss: 2.055128\n",
      "Reconstruction: 1.736296, Regularization: 0.254958, Discriminator: 0.006470; Generator: 0.057403,\n",
      "D(x): 0.967, D(G(z)): 0.159\n",
      "2019-04-10 00:56:14,294 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 2.007918\n",
      "Reconstruction: 1.696853, Regularization: 0.246901, Discriminator: 0.006334; Generator: 0.057830,\n",
      "D(x): 0.969, D(G(z)): 0.157\n",
      "2019-04-10 00:56:14,404 root         INFO     Train Epoch: 29 [6656/8000 (83%)]\tTotal Loss: 2.168753\n",
      "Reconstruction: 1.840358, Regularization: 0.263852, Discriminator: 0.006406; Generator: 0.058137,\n",
      "D(x): 0.966, D(G(z)): 0.156\n",
      "2019-04-10 00:56:14,516 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 2.273653\n",
      "Reconstruction: 1.952025, Regularization: 0.257006, Discriminator: 0.006215; Generator: 0.058407,\n",
      "D(x): 0.969, D(G(z)): 0.154\n",
      "2019-04-10 00:56:14,627 root         INFO     Train Epoch: 29 [7680/8000 (96%)]\tTotal Loss: 1.754753\n",
      "Reconstruction: 1.475954, Regularization: 0.213781, Discriminator: 0.006311; Generator: 0.058708,\n",
      "D(x): 0.965, D(G(z)): 0.153\n",
      "2019-04-10 00:56:14,708 root         INFO     ====> Epoch: 29 Average loss: 2.2968\n",
      "2019-04-10 00:56:14,736 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 1.835581\n",
      "Reconstruction: 1.551393, Regularization: 0.218960, Discriminator: 0.006273; Generator: 0.058955,\n",
      "D(x): 0.965, D(G(z)): 0.152\n",
      "2019-04-10 00:56:14,849 root         INFO     Train Epoch: 30 [512/8000 (6%)]\tTotal Loss: 2.728952\n",
      "Reconstruction: 2.357100, Regularization: 0.306778, Discriminator: 0.005860; Generator: 0.059214,\n",
      "D(x): 0.976, D(G(z)): 0.150\n",
      "2019-04-10 00:56:14,961 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 2.547894\n",
      "Reconstruction: 2.198905, Regularization: 0.283754, Discriminator: 0.005896; Generator: 0.059339,\n",
      "D(x): 0.974, D(G(z)): 0.150\n",
      "2019-04-10 00:56:15,072 root         INFO     Train Epoch: 30 [1536/8000 (19%)]\tTotal Loss: 1.950237\n",
      "Reconstruction: 1.663899, Regularization: 0.220244, Discriminator: 0.006385; Generator: 0.059709,\n",
      "D(x): 0.958, D(G(z)): 0.148\n",
      "2019-04-10 00:56:15,185 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 2.670004\n",
      "Reconstruction: 2.323059, Regularization: 0.281283, Discriminator: 0.005773; Generator: 0.059890,\n",
      "D(x): 0.975, D(G(z)): 0.147\n",
      "2019-04-10 00:56:15,297 root         INFO     Train Epoch: 30 [2560/8000 (32%)]\tTotal Loss: 2.151678\n",
      "Reconstruction: 1.857363, Regularization: 0.228201, Discriminator: 0.005965; Generator: 0.060148,\n",
      "D(x): 0.968, D(G(z)): 0.146\n",
      "2019-04-10 00:56:15,409 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 2.496409\n",
      "Reconstruction: 2.171176, Regularization: 0.259242, Discriminator: 0.005666; Generator: 0.060325,\n",
      "D(x): 0.976, D(G(z)): 0.145\n",
      "2019-04-10 00:56:15,521 root         INFO     Train Epoch: 30 [3584/8000 (45%)]\tTotal Loss: 1.926851\n",
      "Reconstruction: 1.661097, Regularization: 0.199255, Discriminator: 0.005880; Generator: 0.060619,\n",
      "D(x): 0.968, D(G(z)): 0.144\n",
      "2019-04-10 00:56:15,632 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 2.224339\n",
      "Reconstruction: 1.933734, Regularization: 0.223985, Discriminator: 0.005746; Generator: 0.060874,\n",
      "D(x): 0.971, D(G(z)): 0.143\n",
      "2019-04-10 00:56:15,741 root         INFO     Train Epoch: 30 [4608/8000 (58%)]\tTotal Loss: 1.971005\n",
      "Reconstruction: 1.703097, Regularization: 0.201157, Discriminator: 0.005656; Generator: 0.061094,\n",
      "D(x): 0.972, D(G(z)): 0.142\n",
      "2019-04-10 00:56:15,851 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 2.242278\n",
      "Reconstruction: 1.958838, Regularization: 0.216673, Discriminator: 0.005652; Generator: 0.061114,\n",
      "D(x): 0.972, D(G(z)): 0.141\n",
      "2019-04-10 00:56:15,961 root         INFO     Train Epoch: 30 [5632/8000 (70%)]\tTotal Loss: 2.432997\n",
      "Reconstruction: 2.136236, Regularization: 0.229764, Discriminator: 0.005454; Generator: 0.061543,\n",
      "D(x): 0.976, D(G(z)): 0.140\n",
      "2019-04-10 00:56:16,070 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 2.711105\n",
      "Reconstruction: 2.393744, Regularization: 0.250292, Discriminator: 0.005443; Generator: 0.061626,\n",
      "D(x): 0.976, D(G(z)): 0.139\n",
      "2019-04-10 00:56:16,180 root         INFO     Train Epoch: 30 [6656/8000 (83%)]\tTotal Loss: 2.500954\n",
      "Reconstruction: 2.203903, Regularization: 0.229827, Discriminator: 0.005424; Generator: 0.061801,\n",
      "D(x): 0.976, D(G(z)): 0.138\n",
      "2019-04-10 00:56:16,289 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 2.420740\n",
      "Reconstruction: 2.137830, Regularization: 0.215329, Discriminator: 0.005572; Generator: 0.062009,\n",
      "D(x): 0.971, D(G(z)): 0.137\n",
      "2019-04-10 00:56:16,399 root         INFO     Train Epoch: 30 [7680/8000 (96%)]\tTotal Loss: 2.143611\n",
      "Reconstruction: 1.875862, Regularization: 0.200229, Discriminator: 0.005326; Generator: 0.062194,\n",
      "D(x): 0.977, D(G(z)): 0.137\n",
      "2019-04-10 00:56:16,480 root         INFO     ====> Epoch: 30 Average loss: 2.2611\n",
      "2019-04-10 00:56:16,507 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 2.392722\n",
      "Reconstruction: 2.114627, Regularization: 0.210602, Discriminator: 0.005249; Generator: 0.062243,\n",
      "D(x): 0.979, D(G(z)): 0.136\n",
      "2019-04-10 00:56:16,619 root         INFO     Train Epoch: 31 [512/8000 (6%)]\tTotal Loss: 2.540454\n",
      "Reconstruction: 2.257755, Regularization: 0.214975, Discriminator: 0.005280; Generator: 0.062443,\n",
      "D(x): 0.977, D(G(z)): 0.136\n",
      "2019-04-10 00:56:16,730 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 2.125549\n",
      "Reconstruction: 1.875996, Regularization: 0.181746, Discriminator: 0.005323; Generator: 0.062484,\n",
      "D(x): 0.976, D(G(z)): 0.135\n",
      "2019-04-10 00:56:16,839 root         INFO     Train Epoch: 31 [1536/8000 (19%)]\tTotal Loss: 2.186754\n",
      "Reconstruction: 1.933317, Regularization: 0.185426, Discriminator: 0.005305; Generator: 0.062706,\n",
      "D(x): 0.975, D(G(z)): 0.134\n",
      "2019-04-10 00:56:16,947 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 2.820635\n",
      "Reconstruction: 2.524563, Regularization: 0.228122, Discriminator: 0.005117; Generator: 0.062833,\n",
      "D(x): 0.981, D(G(z)): 0.134\n",
      "2019-04-10 00:56:17,055 root         INFO     Train Epoch: 31 [2560/8000 (32%)]\tTotal Loss: 2.591163\n",
      "Reconstruction: 2.318839, Regularization: 0.204157, Discriminator: 0.005106; Generator: 0.063062,\n",
      "D(x): 0.980, D(G(z)): 0.133\n",
      "2019-04-10 00:56:17,164 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 2.201041\n",
      "Reconstruction: 1.957210, Regularization: 0.175453, Discriminator: 0.005197; Generator: 0.063182,\n",
      "D(x): 0.977, D(G(z)): 0.132\n",
      "2019-04-10 00:56:17,272 root         INFO     Train Epoch: 31 [3584/8000 (45%)]\tTotal Loss: 2.193452\n",
      "Reconstruction: 1.958787, Regularization: 0.166079, Discriminator: 0.005325; Generator: 0.063261,\n",
      "D(x): 0.972, D(G(z)): 0.132\n",
      "2019-04-10 00:56:17,379 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 2.904840\n",
      "Reconstruction: 2.625858, Regularization: 0.210674, Discriminator: 0.004962; Generator: 0.063345,\n",
      "D(x): 0.983, D(G(z)): 0.132\n",
      "2019-04-10 00:56:17,488 root         INFO     Train Epoch: 31 [4608/8000 (58%)]\tTotal Loss: 2.131787\n",
      "Reconstruction: 1.906307, Regularization: 0.156531, Discriminator: 0.005456; Generator: 0.063494,\n",
      "D(x): 0.967, D(G(z)): 0.131\n",
      "2019-04-10 00:56:17,596 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 2.530393\n",
      "Reconstruction: 2.283373, Regularization: 0.178592, Discriminator: 0.004922; Generator: 0.063505,\n",
      "D(x): 0.983, D(G(z)): 0.131\n",
      "2019-04-10 00:56:17,704 root         INFO     Train Epoch: 31 [5632/8000 (70%)]\tTotal Loss: 2.701067\n",
      "Reconstruction: 2.446305, Regularization: 0.186151, Discriminator: 0.004855; Generator: 0.063756,\n",
      "D(x): 0.984, D(G(z)): 0.130\n",
      "2019-04-10 00:56:17,813 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 2.455461\n",
      "Reconstruction: 2.219447, Regularization: 0.167330, Discriminator: 0.004828; Generator: 0.063856,\n",
      "D(x): 0.984, D(G(z)): 0.130\n",
      "2019-04-10 00:56:17,921 root         INFO     Train Epoch: 31 [6656/8000 (83%)]\tTotal Loss: 2.444478\n",
      "Reconstruction: 2.215961, Regularization: 0.159483, Discriminator: 0.005007; Generator: 0.064028,\n",
      "D(x): 0.978, D(G(z)): 0.129\n",
      "2019-04-10 00:56:18,029 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 2.998775\n",
      "Reconstruction: 2.745844, Regularization: 0.184022, Discriminator: 0.004770; Generator: 0.064139,\n",
      "D(x): 0.985, D(G(z)): 0.128\n",
      "2019-04-10 00:56:18,138 root         INFO     Train Epoch: 31 [7680/8000 (96%)]\tTotal Loss: 2.488254\n",
      "Reconstruction: 2.262953, Regularization: 0.156151, Discriminator: 0.004944; Generator: 0.064205,\n",
      "D(x): 0.979, D(G(z)): 0.128\n",
      "2019-04-10 00:56:18,217 root         INFO     ====> Epoch: 31 Average loss: 2.4346\n",
      "2019-04-10 00:56:18,245 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 2.792152\n",
      "Reconstruction: 2.551364, Regularization: 0.171894, Discriminator: 0.004698; Generator: 0.064196,\n",
      "D(x): 0.987, D(G(z)): 0.128\n",
      "2019-04-10 00:56:18,357 root         INFO     Train Epoch: 32 [512/8000 (6%)]\tTotal Loss: 2.648772\n",
      "Reconstruction: 2.419719, Regularization: 0.160007, Discriminator: 0.004717; Generator: 0.064329,\n",
      "D(x): 0.986, D(G(z)): 0.128\n",
      "2019-04-10 00:56:18,468 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 2.767724\n",
      "Reconstruction: 2.534859, Regularization: 0.163698, Discriminator: 0.004688; Generator: 0.064478,\n",
      "D(x): 0.986, D(G(z)): 0.127\n",
      "2019-04-10 00:56:18,580 root         INFO     Train Epoch: 32 [1536/8000 (19%)]\tTotal Loss: 2.453698\n",
      "Reconstruction: 2.248670, Regularization: 0.135462, Discriminator: 0.004994; Generator: 0.064571,\n",
      "D(x): 0.976, D(G(z)): 0.127\n",
      "2019-04-10 00:56:18,692 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 2.838884\n",
      "Reconstruction: 2.611587, Regularization: 0.157946, Discriminator: 0.004752; Generator: 0.064600,\n",
      "D(x): 0.984, D(G(z)): 0.127\n",
      "2019-04-10 00:56:18,803 root         INFO     Train Epoch: 32 [2560/8000 (32%)]\tTotal Loss: 2.899166\n",
      "Reconstruction: 2.674941, Regularization: 0.154837, Discriminator: 0.004674; Generator: 0.064715,\n",
      "D(x): 0.985, D(G(z)): 0.126\n",
      "2019-04-10 00:56:18,914 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 2.549798\n",
      "Reconstruction: 2.344517, Regularization: 0.135753, Discriminator: 0.004703; Generator: 0.064825,\n",
      "D(x): 0.984, D(G(z)): 0.126\n",
      "2019-04-10 00:56:19,026 root         INFO     Train Epoch: 32 [3584/8000 (45%)]\tTotal Loss: 2.576360\n",
      "Reconstruction: 2.375168, Regularization: 0.131607, Discriminator: 0.004723; Generator: 0.064861,\n",
      "D(x): 0.983, D(G(z)): 0.125\n",
      "2019-04-10 00:56:19,137 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 2.798285\n",
      "Reconstruction: 2.590129, Regularization: 0.138489, Discriminator: 0.004619; Generator: 0.065048,\n",
      "D(x): 0.986, D(G(z)): 0.125\n",
      "2019-04-10 00:56:19,248 root         INFO     Train Epoch: 32 [4608/8000 (58%)]\tTotal Loss: 2.530038\n",
      "Reconstruction: 2.334209, Regularization: 0.126107, Discriminator: 0.004668; Generator: 0.065053,\n",
      "D(x): 0.984, D(G(z)): 0.125\n",
      "2019-04-10 00:56:19,359 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 2.953952\n",
      "Reconstruction: 2.742320, Regularization: 0.141838, Discriminator: 0.004658; Generator: 0.065137,\n",
      "D(x): 0.984, D(G(z)): 0.124\n",
      "2019-04-10 00:56:19,471 root         INFO     Train Epoch: 32 [5632/8000 (70%)]\tTotal Loss: 2.961066\n",
      "Reconstruction: 2.757078, Regularization: 0.134154, Discriminator: 0.004623; Generator: 0.065211,\n",
      "D(x): 0.985, D(G(z)): 0.124\n",
      "2019-04-10 00:56:19,583 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 2.678488\n",
      "Reconstruction: 2.489455, Regularization: 0.119070, Discriminator: 0.004680; Generator: 0.065284,\n",
      "D(x): 0.983, D(G(z)): 0.124\n",
      "2019-04-10 00:56:19,694 root         INFO     Train Epoch: 32 [6656/8000 (83%)]\tTotal Loss: 2.838346\n",
      "Reconstruction: 2.644054, Regularization: 0.124418, Discriminator: 0.004524; Generator: 0.065351,\n",
      "D(x): 0.987, D(G(z)): 0.124\n",
      "2019-04-10 00:56:19,805 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 2.824184\n",
      "Reconstruction: 2.634804, Regularization: 0.119309, Discriminator: 0.004611; Generator: 0.065460,\n",
      "D(x): 0.984, D(G(z)): 0.123\n",
      "2019-04-10 00:56:19,915 root         INFO     Train Epoch: 32 [7680/8000 (96%)]\tTotal Loss: 2.795926\n",
      "Reconstruction: 2.611173, Regularization: 0.114413, Discriminator: 0.004835; Generator: 0.065505,\n",
      "D(x): 0.977, D(G(z)): 0.123\n",
      "2019-04-10 00:56:19,996 root         INFO     ====> Epoch: 32 Average loss: 2.7330\n",
      "2019-04-10 00:56:20,023 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 3.205499\n",
      "Reconstruction: 3.002140, Regularization: 0.133313, Discriminator: 0.004504; Generator: 0.065542,\n",
      "D(x): 0.987, D(G(z)): 0.123\n",
      "2019-04-10 00:56:20,136 root         INFO     Train Epoch: 33 [512/8000 (6%)]\tTotal Loss: 2.960148\n",
      "Reconstruction: 2.771486, Regularization: 0.118531, Discriminator: 0.004522; Generator: 0.065610,\n",
      "D(x): 0.986, D(G(z)): 0.123\n",
      "2019-04-10 00:56:20,246 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 2.811936\n",
      "Reconstruction: 2.630412, Regularization: 0.111392, Discriminator: 0.004451; Generator: 0.065682,\n",
      "D(x): 0.988, D(G(z)): 0.122\n",
      "2019-04-10 00:56:20,355 root         INFO     Train Epoch: 33 [1536/8000 (19%)]\tTotal Loss: 3.228702\n",
      "Reconstruction: 3.036225, Regularization: 0.122217, Discriminator: 0.004517; Generator: 0.065744,\n",
      "D(x): 0.986, D(G(z)): 0.122\n",
      "2019-04-10 00:56:20,464 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 2.821381\n",
      "Reconstruction: 2.645597, Regularization: 0.105443, Discriminator: 0.004535; Generator: 0.065805,\n",
      "D(x): 0.985, D(G(z)): 0.122\n",
      "2019-04-10 00:56:20,574 root         INFO     Train Epoch: 33 [2560/8000 (32%)]\tTotal Loss: 2.897346\n",
      "Reconstruction: 2.722065, Regularization: 0.104894, Discriminator: 0.004526; Generator: 0.065861,\n",
      "D(x): 0.985, D(G(z)): 0.122\n",
      "2019-04-10 00:56:20,683 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 3.203012\n",
      "Reconstruction: 3.020495, Regularization: 0.112174, Discriminator: 0.004419; Generator: 0.065924,\n",
      "D(x): 0.988, D(G(z)): 0.121\n",
      "2019-04-10 00:56:20,792 root         INFO     Train Epoch: 33 [3584/8000 (45%)]\tTotal Loss: 2.678667\n",
      "Reconstruction: 2.515478, Regularization: 0.092665, Discriminator: 0.004502; Generator: 0.066021,\n",
      "D(x): 0.985, D(G(z)): 0.121\n",
      "2019-04-10 00:56:20,902 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 3.107474\n",
      "Reconstruction: 2.933114, Regularization: 0.103924, Discriminator: 0.004388; Generator: 0.066049,\n",
      "D(x): 0.988, D(G(z)): 0.121\n",
      "2019-04-10 00:56:21,012 root         INFO     Train Epoch: 33 [4608/8000 (58%)]\tTotal Loss: 3.017105\n",
      "Reconstruction: 2.848242, Regularization: 0.098328, Discriminator: 0.004411; Generator: 0.066124,\n",
      "D(x): 0.987, D(G(z)): 0.121\n",
      "2019-04-10 00:56:21,121 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 2.911181\n",
      "Reconstruction: 2.748352, Regularization: 0.092262, Discriminator: 0.004357; Generator: 0.066211,\n",
      "D(x): 0.989, D(G(z)): 0.120\n",
      "2019-04-10 00:56:21,231 root         INFO     Train Epoch: 33 [5632/8000 (70%)]\tTotal Loss: 3.068334\n",
      "Reconstruction: 2.903758, Regularization: 0.093918, Discriminator: 0.004382; Generator: 0.066277,\n",
      "D(x): 0.988, D(G(z)): 0.120\n",
      "2019-04-10 00:56:21,340 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 2.957916\n",
      "Reconstruction: 2.798871, Regularization: 0.088327, Discriminator: 0.004419; Generator: 0.066298,\n",
      "D(x): 0.986, D(G(z)): 0.120\n",
      "2019-04-10 00:56:21,450 root         INFO     Train Epoch: 33 [6656/8000 (83%)]\tTotal Loss: 3.322559\n",
      "Reconstruction: 3.154899, Regularization: 0.097039, Discriminator: 0.004262; Generator: 0.066360,\n",
      "D(x): 0.991, D(G(z)): 0.120\n",
      "2019-04-10 00:56:21,560 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 3.499171\n",
      "Reconstruction: 3.328794, Regularization: 0.099593, Discriminator: 0.004293; Generator: 0.066490,\n",
      "D(x): 0.990, D(G(z)): 0.119\n",
      "2019-04-10 00:56:21,672 root         INFO     Train Epoch: 33 [7680/8000 (96%)]\tTotal Loss: 3.235152\n",
      "Reconstruction: 3.075706, Regularization: 0.088426, Discriminator: 0.004511; Generator: 0.066509,\n",
      "D(x): 0.983, D(G(z)): 0.119\n",
      "2019-04-10 00:56:21,752 root         INFO     ====> Epoch: 33 Average loss: 3.0534\n",
      "2019-04-10 00:56:21,780 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 3.294729\n",
      "Reconstruction: 3.135675, Regularization: 0.088116, Discriminator: 0.004389; Generator: 0.066549,\n",
      "D(x): 0.986, D(G(z)): 0.119\n",
      "2019-04-10 00:56:21,892 root         INFO     Train Epoch: 34 [512/8000 (6%)]\tTotal Loss: 3.011081\n",
      "Reconstruction: 2.861572, Regularization: 0.078596, Discriminator: 0.004281; Generator: 0.066632,\n",
      "D(x): 0.989, D(G(z)): 0.119\n",
      "2019-04-10 00:56:22,003 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 3.378971\n",
      "Reconstruction: 3.223147, Regularization: 0.084711, Discriminator: 0.004489; Generator: 0.066623,\n",
      "D(x): 0.983, D(G(z)): 0.119\n",
      "2019-04-10 00:56:22,115 root         INFO     Train Epoch: 34 [1536/8000 (19%)]\tTotal Loss: 3.738968\n",
      "Reconstruction: 3.575540, Regularization: 0.092548, Discriminator: 0.004241; Generator: 0.066638,\n",
      "D(x): 0.991, D(G(z)): 0.119\n",
      "2019-04-10 00:56:22,226 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 3.614149\n",
      "Reconstruction: 3.456186, Regularization: 0.087069, Discriminator: 0.004203; Generator: 0.066691,\n",
      "D(x): 0.992, D(G(z)): 0.118\n",
      "2019-04-10 00:56:22,338 root         INFO     Train Epoch: 34 [2560/8000 (32%)]\tTotal Loss: 3.434153\n",
      "Reconstruction: 3.282618, Regularization: 0.080460, Discriminator: 0.004243; Generator: 0.066832,\n",
      "D(x): 0.990, D(G(z)): 0.118\n",
      "2019-04-10 00:56:22,449 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 3.513176\n",
      "Reconstruction: 3.360419, Regularization: 0.081407, Discriminator: 0.004262; Generator: 0.067088,\n",
      "D(x): 0.988, D(G(z)): 0.117\n",
      "2019-04-10 00:56:22,561 root         INFO     Train Epoch: 34 [3584/8000 (45%)]\tTotal Loss: 3.529074\n",
      "Reconstruction: 3.379756, Regularization: 0.078093, Discriminator: 0.004206; Generator: 0.067019,\n",
      "D(x): 0.990, D(G(z)): 0.117\n",
      "2019-04-10 00:56:22,674 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 3.494310\n",
      "Reconstruction: 3.347564, Regularization: 0.075333, Discriminator: 0.004187; Generator: 0.067226,\n",
      "D(x): 0.990, D(G(z)): 0.116\n",
      "2019-04-10 00:56:22,786 root         INFO     Train Epoch: 34 [4608/8000 (58%)]\tTotal Loss: 3.545555\n",
      "Reconstruction: 3.399385, Regularization: 0.074876, Discriminator: 0.004251; Generator: 0.067043,\n",
      "D(x): 0.989, D(G(z)): 0.117\n",
      "2019-04-10 00:56:22,899 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 3.698925\n",
      "Reconstruction: 3.549374, Regularization: 0.077937, Discriminator: 0.004092; Generator: 0.067523,\n",
      "D(x): 0.992, D(G(z)): 0.115\n",
      "2019-04-10 00:56:23,013 root         INFO     Train Epoch: 34 [5632/8000 (70%)]\tTotal Loss: 3.906603\n",
      "Reconstruction: 3.756829, Regularization: 0.078239, Discriminator: 0.004000; Generator: 0.067536,\n",
      "D(x): 0.994, D(G(z)): 0.115\n",
      "2019-04-10 00:56:23,125 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 3.521121\n",
      "Reconstruction: 3.381539, Regularization: 0.068056, Discriminator: 0.004128; Generator: 0.067398,\n",
      "D(x): 0.991, D(G(z)): 0.116\n",
      "2019-04-10 00:56:23,238 root         INFO     Train Epoch: 34 [6656/8000 (83%)]\tTotal Loss: 3.158023\n",
      "Reconstruction: 3.026502, Regularization: 0.059652, Discriminator: 0.004323; Generator: 0.067546,\n",
      "D(x): 0.984, D(G(z)): 0.115\n",
      "2019-04-10 00:56:23,351 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 3.673711\n",
      "Reconstruction: 3.533919, Regularization: 0.068090, Discriminator: 0.004110; Generator: 0.067591,\n",
      "D(x): 0.991, D(G(z)): 0.115\n",
      "2019-04-10 00:56:23,464 root         INFO     Train Epoch: 34 [7680/8000 (96%)]\tTotal Loss: 3.682148\n",
      "Reconstruction: 3.543849, Regularization: 0.066374, Discriminator: 0.004131; Generator: 0.067794,\n",
      "D(x): 0.989, D(G(z)): 0.114\n",
      "2019-04-10 00:56:23,546 root         INFO     ====> Epoch: 34 Average loss: 3.4861\n",
      "2019-04-10 00:56:23,573 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 3.599991\n",
      "Reconstruction: 3.464339, Regularization: 0.063654, Discriminator: 0.004073; Generator: 0.067925,\n",
      "D(x): 0.991, D(G(z)): 0.114\n",
      "2019-04-10 00:56:23,684 root         INFO     Train Epoch: 35 [512/8000 (6%)]\tTotal Loss: 3.843556\n",
      "Reconstruction: 3.705126, Regularization: 0.066403, Discriminator: 0.004041; Generator: 0.067987,\n",
      "D(x): 0.991, D(G(z)): 0.114\n",
      "2019-04-10 00:56:23,795 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 3.719793\n",
      "Reconstruction: 3.586107, Regularization: 0.061430, Discriminator: 0.004162; Generator: 0.068094,\n",
      "D(x): 0.987, D(G(z)): 0.113\n",
      "2019-04-10 00:56:23,906 root         INFO     Train Epoch: 35 [1536/8000 (19%)]\tTotal Loss: 3.689172\n",
      "Reconstruction: 3.557006, Regularization: 0.059882, Discriminator: 0.004021; Generator: 0.068262,\n",
      "D(x): 0.991, D(G(z)): 0.113\n",
      "2019-04-10 00:56:24,017 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 3.565825\n",
      "Reconstruction: 3.438222, Regularization: 0.055309, Discriminator: 0.004008; Generator: 0.068285,\n",
      "D(x): 0.991, D(G(z)): 0.113\n",
      "2019-04-10 00:56:24,128 root         INFO     Train Epoch: 35 [2560/8000 (32%)]\tTotal Loss: 3.800227\n",
      "Reconstruction: 3.669602, Regularization: 0.058289, Discriminator: 0.003920; Generator: 0.068416,\n",
      "D(x): 0.993, D(G(z)): 0.112\n",
      "2019-04-10 00:56:24,239 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 3.738332\n",
      "Reconstruction: 3.610219, Regularization: 0.055598, Discriminator: 0.003966; Generator: 0.068549,\n",
      "D(x): 0.991, D(G(z)): 0.112\n",
      "2019-04-10 00:56:24,348 root         INFO     Train Epoch: 35 [3584/8000 (45%)]\tTotal Loss: 3.975499\n",
      "Reconstruction: 3.843486, Regularization: 0.059085, Discriminator: 0.004008; Generator: 0.068920,\n",
      "D(x): 0.989, D(G(z)): 0.110\n",
      "2019-04-10 00:56:24,459 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 4.226278\n",
      "Reconstruction: 4.092432, Regularization: 0.060896, Discriminator: 0.003906; Generator: 0.069043,\n",
      "D(x): 0.991, D(G(z)): 0.110\n",
      "2019-04-10 00:56:24,569 root         INFO     Train Epoch: 35 [4608/8000 (58%)]\tTotal Loss: 3.966596\n",
      "Reconstruction: 3.838678, Regularization: 0.055253, Discriminator: 0.004091; Generator: 0.068574,\n",
      "D(x): 0.988, D(G(z)): 0.111\n",
      "2019-04-10 00:56:24,680 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 4.091503\n",
      "Reconstruction: 3.961632, Regularization: 0.056730, Discriminator: 0.003938; Generator: 0.069204,\n",
      "D(x): 0.990, D(G(z)): 0.109\n",
      "2019-04-10 00:56:24,792 root         INFO     Train Epoch: 35 [5632/8000 (70%)]\tTotal Loss: 4.436427\n",
      "Reconstruction: 4.302605, Regularization: 0.060757, Discriminator: 0.003788; Generator: 0.069276,\n",
      "D(x): 0.994, D(G(z)): 0.109\n",
      "2019-04-10 00:56:24,902 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 4.007117\n",
      "Reconstruction: 3.881991, Regularization: 0.051371, Discriminator: 0.003812; Generator: 0.069943,\n",
      "D(x): 0.991, D(G(z)): 0.107\n",
      "2019-04-10 00:56:25,012 root         INFO     Train Epoch: 35 [6656/8000 (83%)]\tTotal Loss: 3.994648\n",
      "Reconstruction: 3.870392, Regularization: 0.050888, Discriminator: 0.003775; Generator: 0.069593,\n",
      "D(x): 0.993, D(G(z)): 0.108\n",
      "2019-04-10 00:56:25,123 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 4.463316\n",
      "Reconstruction: 4.334076, Regularization: 0.055424, Discriminator: 0.004029; Generator: 0.069788,\n",
      "D(x): 0.986, D(G(z)): 0.107\n",
      "2019-04-10 00:56:25,234 root         INFO     Train Epoch: 35 [7680/8000 (96%)]\tTotal Loss: 4.276431\n",
      "Reconstruction: 4.150446, Regularization: 0.051995, Discriminator: 0.003709; Generator: 0.070281,\n",
      "D(x): 0.993, D(G(z)): 0.106\n",
      "2019-04-10 00:56:25,314 root         INFO     ====> Epoch: 35 Average loss: 3.9751\n",
      "2019-04-10 00:56:25,341 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 4.911242\n",
      "Reconstruction: 4.778729, Regularization: 0.058595, Discriminator: 0.003646; Generator: 0.070272,\n",
      "D(x): 0.995, D(G(z)): 0.106\n",
      "2019-04-10 00:56:25,454 root         INFO     Train Epoch: 36 [512/8000 (6%)]\tTotal Loss: 4.017025\n",
      "Reconstruction: 3.897411, Regularization: 0.045503, Discriminator: 0.003714; Generator: 0.070397,\n",
      "D(x): 0.992, D(G(z)): 0.105\n",
      "2019-04-10 00:56:25,567 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 4.334722\n",
      "Reconstruction: 4.211667, Regularization: 0.048819, Discriminator: 0.003604; Generator: 0.070632,\n",
      "D(x): 0.995, D(G(z)): 0.104\n",
      "2019-04-10 00:56:25,680 root         INFO     Train Epoch: 36 [1536/8000 (19%)]\tTotal Loss: 4.106432\n",
      "Reconstruction: 3.986166, Regularization: 0.045639, Discriminator: 0.003706; Generator: 0.070921,\n",
      "D(x): 0.991, D(G(z)): 0.103\n",
      "2019-04-10 00:56:25,792 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 4.320260\n",
      "Reconstruction: 4.198354, Regularization: 0.047096, Discriminator: 0.003771; Generator: 0.071038,\n",
      "D(x): 0.988, D(G(z)): 0.103\n",
      "2019-04-10 00:56:25,905 root         INFO     Train Epoch: 36 [2560/8000 (32%)]\tTotal Loss: 5.155642\n",
      "Reconstruction: 5.023866, Regularization: 0.056832, Discriminator: 0.003485; Generator: 0.071459,\n",
      "D(x): 0.996, D(G(z)): 0.102\n",
      "2019-04-10 00:56:26,017 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 4.217706\n",
      "Reconstruction: 4.098378, Regularization: 0.044064, Discriminator: 0.003507; Generator: 0.071758,\n",
      "D(x): 0.994, D(G(z)): 0.101\n",
      "2019-04-10 00:56:26,129 root         INFO     Train Epoch: 36 [3584/8000 (45%)]\tTotal Loss: 4.259050\n",
      "Reconstruction: 4.140065, Regularization: 0.043190, Discriminator: 0.003873; Generator: 0.071922,\n",
      "D(x): 0.983, D(G(z)): 0.100\n",
      "2019-04-10 00:56:26,241 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 4.439920\n",
      "Reconstruction: 4.320960, Regularization: 0.043181, Discriminator: 0.003455; Generator: 0.072324,\n",
      "D(x): 0.994, D(G(z)): 0.099\n",
      "2019-04-10 00:56:26,354 root         INFO     Train Epoch: 36 [4608/8000 (58%)]\tTotal Loss: 3.980131\n",
      "Reconstruction: 3.865700, Regularization: 0.038336, Discriminator: 0.003481; Generator: 0.072614,\n",
      "D(x): 0.992, D(G(z)): 0.098\n",
      "2019-04-10 00:56:26,466 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 4.437674\n",
      "Reconstruction: 4.319245, Regularization: 0.042358, Discriminator: 0.003396; Generator: 0.072675,\n",
      "D(x): 0.994, D(G(z)): 0.098\n",
      "2019-04-10 00:56:26,578 root         INFO     Train Epoch: 36 [5632/8000 (70%)]\tTotal Loss: 4.401498\n",
      "Reconstruction: 4.283877, Regularization: 0.041241, Discriminator: 0.003432; Generator: 0.072947,\n",
      "D(x): 0.992, D(G(z)): 0.097\n",
      "2019-04-10 00:56:26,691 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 4.681550\n",
      "Reconstruction: 4.561536, Regularization: 0.043293, Discriminator: 0.003279; Generator: 0.073442,\n",
      "D(x): 0.995, D(G(z)): 0.095\n",
      "2019-04-10 00:56:26,804 root         INFO     Train Epoch: 36 [6656/8000 (83%)]\tTotal Loss: 5.370732\n",
      "Reconstruction: 5.245928, Regularization: 0.048162, Discriminator: 0.003235; Generator: 0.073407,\n",
      "D(x): 0.997, D(G(z)): 0.096\n",
      "2019-04-10 00:56:26,916 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 4.762434\n",
      "Reconstruction: 4.643367, Regularization: 0.042376, Discriminator: 0.003324; Generator: 0.073367,\n",
      "D(x): 0.994, D(G(z)): 0.096\n",
      "2019-04-10 00:56:27,029 root         INFO     Train Epoch: 36 [7680/8000 (96%)]\tTotal Loss: 4.649828\n",
      "Reconstruction: 4.532249, Regularization: 0.040131, Discriminator: 0.003290; Generator: 0.074158,\n",
      "D(x): 0.993, D(G(z)): 0.093\n",
      "2019-04-10 00:56:27,110 root         INFO     ====> Epoch: 36 Average loss: 4.4395\n",
      "2019-04-10 00:56:27,138 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 3.720942\n",
      "Reconstruction: 3.611744, Regularization: 0.031410, Discriminator: 0.003344; Generator: 0.074444,\n",
      "D(x): 0.990, D(G(z)): 0.092\n",
      "2019-04-10 00:56:27,251 root         INFO     Train Epoch: 37 [512/8000 (6%)]\tTotal Loss: 4.451229\n",
      "Reconstruction: 4.336581, Regularization: 0.036922, Discriminator: 0.003204; Generator: 0.074521,\n",
      "D(x): 0.994, D(G(z)): 0.092\n",
      "2019-04-10 00:56:27,363 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 4.242425\n",
      "Reconstruction: 4.129397, Regularization: 0.034930, Discriminator: 0.003086; Generator: 0.075013,\n",
      "D(x): 0.996, D(G(z)): 0.091\n",
      "2019-04-10 00:56:27,475 root         INFO     Train Epoch: 37 [1536/8000 (19%)]\tTotal Loss: 4.827755\n",
      "Reconstruction: 4.709893, Regularization: 0.039252, Discriminator: 0.003124; Generator: 0.075486,\n",
      "D(x): 0.994, D(G(z)): 0.089\n",
      "2019-04-10 00:56:27,587 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 4.956317\n",
      "Reconstruction: 4.837963, Regularization: 0.039424, Discriminator: 0.003136; Generator: 0.075794,\n",
      "D(x): 0.993, D(G(z)): 0.089\n",
      "2019-04-10 00:56:27,700 root         INFO     Train Epoch: 37 [2560/8000 (32%)]\tTotal Loss: 4.025681\n",
      "Reconstruction: 3.914060, Regularization: 0.032597, Discriminator: 0.003049; Generator: 0.075976,\n",
      "D(x): 0.995, D(G(z)): 0.088\n",
      "2019-04-10 00:56:27,812 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 4.616326\n",
      "Reconstruction: 4.501181, Regularization: 0.035511, Discriminator: 0.003032; Generator: 0.076603,\n",
      "D(x): 0.993, D(G(z)): 0.086\n",
      "2019-04-10 00:56:27,924 root         INFO     Train Epoch: 37 [3584/8000 (45%)]\tTotal Loss: 4.586791\n",
      "Reconstruction: 4.472778, Regularization: 0.034380, Discriminator: 0.002993; Generator: 0.076640,\n",
      "D(x): 0.994, D(G(z)): 0.086\n",
      "2019-04-10 00:56:28,035 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 4.396820\n",
      "Reconstruction: 4.283899, Regularization: 0.032948, Discriminator: 0.002905; Generator: 0.077068,\n",
      "D(x): 0.996, D(G(z)): 0.085\n",
      "2019-04-10 00:56:28,145 root         INFO     Train Epoch: 37 [4608/8000 (58%)]\tTotal Loss: 4.159216\n",
      "Reconstruction: 4.048575, Regularization: 0.030741, Discriminator: 0.002943; Generator: 0.076956,\n",
      "D(x): 0.995, D(G(z)): 0.085\n",
      "2019-04-10 00:56:28,254 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 5.111768\n",
      "Reconstruction: 4.992937, Regularization: 0.038056, Discriminator: 0.002884; Generator: 0.077891,\n",
      "D(x): 0.994, D(G(z)): 0.083\n",
      "2019-04-10 00:56:28,365 root         INFO     Train Epoch: 37 [5632/8000 (70%)]\tTotal Loss: 4.302647\n",
      "Reconstruction: 4.190930, Regularization: 0.030932, Discriminator: 0.002904; Generator: 0.077879,\n",
      "D(x): 0.994, D(G(z)): 0.083\n",
      "2019-04-10 00:56:28,476 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 5.093184\n",
      "Reconstruction: 4.974904, Regularization: 0.037098, Discriminator: 0.002833; Generator: 0.078349,\n",
      "D(x): 0.995, D(G(z)): 0.082\n",
      "2019-04-10 00:56:28,586 root         INFO     Train Epoch: 37 [6656/8000 (83%)]\tTotal Loss: 4.093338\n",
      "Reconstruction: 3.981705, Regularization: 0.029793, Discriminator: 0.002839; Generator: 0.079001,\n",
      "D(x): 0.993, D(G(z)): 0.080\n",
      "2019-04-10 00:56:28,696 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 4.137822\n",
      "Reconstruction: 4.028064, Regularization: 0.027996, Discriminator: 0.002856; Generator: 0.078906,\n",
      "D(x): 0.992, D(G(z)): 0.080\n",
      "2019-04-10 00:56:28,807 root         INFO     Train Epoch: 37 [7680/8000 (96%)]\tTotal Loss: 3.929260\n",
      "Reconstruction: 3.819889, Regularization: 0.027269, Discriminator: 0.002673; Generator: 0.079430,\n",
      "D(x): 0.997, D(G(z)): 0.079\n",
      "2019-04-10 00:56:28,888 root         INFO     ====> Epoch: 37 Average loss: 4.5517\n",
      "2019-04-10 00:56:28,916 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 4.966405\n",
      "Reconstruction: 4.848826, Regularization: 0.034974, Discriminator: 0.002619; Generator: 0.079986,\n",
      "D(x): 0.997, D(G(z)): 0.077\n",
      "2019-04-10 00:56:29,027 root         INFO     Train Epoch: 38 [512/8000 (6%)]\tTotal Loss: 4.492909\n",
      "Reconstruction: 4.380859, Regularization: 0.029306, Discriminator: 0.002671; Generator: 0.080073,\n",
      "D(x): 0.995, D(G(z)): 0.077\n",
      "2019-04-10 00:56:29,142 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 4.664603\n",
      "Reconstruction: 4.550421, Regularization: 0.030797, Discriminator: 0.002528; Generator: 0.080857,\n",
      "D(x): 0.997, D(G(z)): 0.075\n",
      "2019-04-10 00:56:29,254 root         INFO     Train Epoch: 38 [1536/8000 (19%)]\tTotal Loss: 4.536564\n",
      "Reconstruction: 4.423392, Regularization: 0.029637, Discriminator: 0.002536; Generator: 0.081000,\n",
      "D(x): 0.997, D(G(z)): 0.075\n",
      "2019-04-10 00:56:29,366 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 4.215173\n",
      "Reconstruction: 4.104082, Regularization: 0.027082, Discriminator: 0.002590; Generator: 0.081420,\n",
      "D(x): 0.994, D(G(z)): 0.074\n",
      "2019-04-10 00:56:29,477 root         INFO     Train Epoch: 38 [2560/8000 (32%)]\tTotal Loss: 4.034816\n",
      "Reconstruction: 3.924881, Regularization: 0.025736, Discriminator: 0.002453; Generator: 0.081746,\n",
      "D(x): 0.997, D(G(z)): 0.073\n",
      "2019-04-10 00:56:29,588 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 4.545074\n",
      "Reconstruction: 4.431458, Regularization: 0.028786, Discriminator: 0.002690; Generator: 0.082139,\n",
      "D(x): 0.990, D(G(z)): 0.072\n",
      "2019-04-10 00:56:29,699 root         INFO     Train Epoch: 38 [3584/8000 (45%)]\tTotal Loss: 3.973087\n",
      "Reconstruction: 3.862837, Regularization: 0.024706, Discriminator: 0.002506; Generator: 0.083038,\n",
      "D(x): 0.993, D(G(z)): 0.070\n",
      "2019-04-10 00:56:29,809 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 3.801920\n",
      "Reconstruction: 3.693624, Regularization: 0.023146, Discriminator: 0.002502; Generator: 0.082649,\n",
      "D(x): 0.994, D(G(z)): 0.071\n",
      "2019-04-10 00:56:29,921 root         INFO     Train Epoch: 38 [4608/8000 (58%)]\tTotal Loss: 3.756813\n",
      "Reconstruction: 3.647027, Regularization: 0.024210, Discriminator: 0.002390; Generator: 0.083186,\n",
      "D(x): 0.996, D(G(z)): 0.070\n",
      "2019-04-10 00:56:30,033 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 3.846335\n",
      "Reconstruction: 3.736960, Regularization: 0.023568, Discriminator: 0.002361; Generator: 0.083446,\n",
      "D(x): 0.996, D(G(z)): 0.069\n",
      "2019-04-10 00:56:30,145 root         INFO     Train Epoch: 38 [5632/8000 (70%)]\tTotal Loss: 3.665213\n",
      "Reconstruction: 3.556579, Regularization: 0.022699, Discriminator: 0.002360; Generator: 0.083576,\n",
      "D(x): 0.996, D(G(z)): 0.069\n",
      "2019-04-10 00:56:30,257 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 3.936462\n",
      "Reconstruction: 3.826458, Regularization: 0.023280, Discriminator: 0.002575; Generator: 0.084150,\n",
      "D(x): 0.989, D(G(z)): 0.068\n",
      "2019-04-10 00:56:30,368 root         INFO     Train Epoch: 38 [6656/8000 (83%)]\tTotal Loss: 3.743938\n",
      "Reconstruction: 3.634661, Regularization: 0.022762, Discriminator: 0.002357; Generator: 0.084158,\n",
      "D(x): 0.995, D(G(z)): 0.068\n",
      "2019-04-10 00:56:30,478 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 3.559790\n",
      "Reconstruction: 3.450478, Regularization: 0.021993, Discriminator: 0.002319; Generator: 0.085000,\n",
      "D(x): 0.994, D(G(z)): 0.066\n",
      "2019-04-10 00:56:30,587 root         INFO     Train Epoch: 38 [7680/8000 (96%)]\tTotal Loss: 3.448253\n",
      "Reconstruction: 3.340861, Regularization: 0.019974, Discriminator: 0.002313; Generator: 0.085105,\n",
      "D(x): 0.994, D(G(z)): 0.066\n",
      "2019-04-10 00:56:30,667 root         INFO     ====> Epoch: 38 Average loss: 4.0522\n",
      "2019-04-10 00:56:30,694 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 4.215939\n",
      "Reconstruction: 4.104291, Regularization: 0.023868, Discriminator: 0.002190; Generator: 0.085591,\n",
      "D(x): 0.997, D(G(z)): 0.065\n",
      "2019-04-10 00:56:30,804 root         INFO     Train Epoch: 39 [512/8000 (6%)]\tTotal Loss: 3.415266\n",
      "Reconstruction: 3.307868, Regularization: 0.019175, Discriminator: 0.002294; Generator: 0.085929,\n",
      "D(x): 0.993, D(G(z)): 0.064\n",
      "2019-04-10 00:56:30,913 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 3.611300\n",
      "Reconstruction: 3.502709, Regularization: 0.020375, Discriminator: 0.002178; Generator: 0.086038,\n",
      "D(x): 0.996, D(G(z)): 0.064\n",
      "2019-04-10 00:56:31,021 root         INFO     Train Epoch: 39 [1536/8000 (19%)]\tTotal Loss: 3.465332\n",
      "Reconstruction: 3.358378, Regularization: 0.018860, Discriminator: 0.002245; Generator: 0.085848,\n",
      "D(x): 0.995, D(G(z)): 0.064\n",
      "2019-04-10 00:56:31,130 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 3.668875\n",
      "Reconstruction: 3.561421, Regularization: 0.018917, Discriminator: 0.002111; Generator: 0.086426,\n",
      "D(x): 0.998, D(G(z)): 0.063\n",
      "2019-04-10 00:56:31,238 root         INFO     Train Epoch: 39 [2560/8000 (32%)]\tTotal Loss: 3.032233\n",
      "Reconstruction: 2.927607, Regularization: 0.015465, Discriminator: 0.002065; Generator: 0.087095,\n",
      "D(x): 0.998, D(G(z)): 0.062\n",
      "2019-04-10 00:56:31,347 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 2.820203\n",
      "Reconstruction: 2.716316, Regularization: 0.014635, Discriminator: 0.002196; Generator: 0.087056,\n",
      "D(x): 0.994, D(G(z)): 0.062\n",
      "2019-04-10 00:56:31,456 root         INFO     Train Epoch: 39 [3584/8000 (45%)]\tTotal Loss: 3.134867\n",
      "Reconstruction: 3.030359, Regularization: 0.015431, Discriminator: 0.002116; Generator: 0.086961,\n",
      "D(x): 0.996, D(G(z)): 0.062\n",
      "2019-04-10 00:56:31,565 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 3.175772\n",
      "Reconstruction: 3.070987, Regularization: 0.015448, Discriminator: 0.002170; Generator: 0.087168,\n",
      "D(x): 0.994, D(G(z)): 0.061\n",
      "2019-04-10 00:56:31,673 root         INFO     Train Epoch: 39 [4608/8000 (58%)]\tTotal Loss: 2.911788\n",
      "Reconstruction: 2.808071, Regularization: 0.014444, Discriminator: 0.002121; Generator: 0.087152,\n",
      "D(x): 0.996, D(G(z)): 0.062\n",
      "2019-04-10 00:56:31,782 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 2.719664\n",
      "Reconstruction: 2.617498, Regularization: 0.012380, Discriminator: 0.002038; Generator: 0.087748,\n",
      "D(x): 0.997, D(G(z)): 0.060\n",
      "2019-04-10 00:56:31,890 root         INFO     Train Epoch: 39 [5632/8000 (70%)]\tTotal Loss: 3.241239\n",
      "Reconstruction: 3.137402, Regularization: 0.014063, Discriminator: 0.001984; Generator: 0.087790,\n",
      "D(x): 0.999, D(G(z)): 0.060\n",
      "2019-04-10 00:56:31,999 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 2.473568\n",
      "Reconstruction: 2.371145, Regularization: 0.012003, Discriminator: 0.002094; Generator: 0.088327,\n",
      "D(x): 0.994, D(G(z)): 0.059\n",
      "2019-04-10 00:56:32,108 root         INFO     Train Epoch: 39 [6656/8000 (83%)]\tTotal Loss: 2.647160\n",
      "Reconstruction: 2.545838, Regularization: 0.010614, Discriminator: 0.002176; Generator: 0.088532,\n",
      "D(x): 0.992, D(G(z)): 0.059\n",
      "2019-04-10 00:56:32,216 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 2.696903\n",
      "Reconstruction: 2.594892, Regularization: 0.010994, Discriminator: 0.001984; Generator: 0.089033,\n",
      "D(x): 0.996, D(G(z)): 0.058\n",
      "2019-04-10 00:56:32,324 root         INFO     Train Epoch: 39 [7680/8000 (96%)]\tTotal Loss: 2.680940\n",
      "Reconstruction: 2.579534, Regularization: 0.010485, Discriminator: 0.001974; Generator: 0.088946,\n",
      "D(x): 0.997, D(G(z)): 0.058\n",
      "2019-04-10 00:56:32,403 root         INFO     ====> Epoch: 39 Average loss: 3.0386\n",
      "2019-04-10 00:56:32,430 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 2.370187\n",
      "Reconstruction: 2.269997, Regularization: 0.009755, Discriminator: 0.002037; Generator: 0.088397,\n",
      "D(x): 0.996, D(G(z)): 0.059\n",
      "2019-04-10 00:56:32,542 root         INFO     Train Epoch: 40 [512/8000 (6%)]\tTotal Loss: 2.522660\n",
      "Reconstruction: 2.422775, Regularization: 0.008788, Discriminator: 0.001938; Generator: 0.089159,\n",
      "D(x): 0.997, D(G(z)): 0.058\n",
      "2019-04-10 00:56:32,653 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 2.139882\n",
      "Reconstruction: 2.038686, Regularization: 0.009430, Discriminator: 0.002038; Generator: 0.089727,\n",
      "D(x): 0.993, D(G(z)): 0.057\n",
      "2019-04-10 00:56:32,763 root         INFO     Train Epoch: 40 [1536/8000 (19%)]\tTotal Loss: 2.278811\n",
      "Reconstruction: 2.178306, Regularization: 0.009477, Discriminator: 0.001954; Generator: 0.089074,\n",
      "D(x): 0.997, D(G(z)): 0.058\n",
      "2019-04-10 00:56:32,874 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 2.302252\n",
      "Reconstruction: 2.201928, Regularization: 0.009141, Discriminator: 0.001985; Generator: 0.089198,\n",
      "D(x): 0.996, D(G(z)): 0.058\n",
      "2019-04-10 00:56:32,985 root         INFO     Train Epoch: 40 [2560/8000 (32%)]\tTotal Loss: 1.993562\n",
      "Reconstruction: 1.894963, Regularization: 0.006823, Discriminator: 0.002111; Generator: 0.089665,\n",
      "D(x): 0.991, D(G(z)): 0.057\n",
      "2019-04-10 00:56:33,096 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 1.956291\n",
      "Reconstruction: 1.856420, Regularization: 0.007938, Discriminator: 0.002090; Generator: 0.089843,\n",
      "D(x): 0.992, D(G(z)): 0.056\n",
      "2019-04-10 00:56:33,206 root         INFO     Train Epoch: 40 [3584/8000 (45%)]\tTotal Loss: 1.893299\n",
      "Reconstruction: 1.795655, Regularization: 0.005736, Discriminator: 0.001891; Generator: 0.090017,\n",
      "D(x): 0.997, D(G(z)): 0.056\n",
      "2019-04-10 00:56:33,317 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 1.841226\n",
      "Reconstruction: 1.742573, Regularization: 0.006943, Discriminator: 0.002223; Generator: 0.089487,\n",
      "D(x): 0.989, D(G(z)): 0.057\n",
      "2019-04-10 00:56:33,428 root         INFO     Train Epoch: 40 [4608/8000 (58%)]\tTotal Loss: 2.027914\n",
      "Reconstruction: 1.930354, Regularization: 0.005699, Discriminator: 0.002165; Generator: 0.089695,\n",
      "D(x): 0.990, D(G(z)): 0.057\n",
      "2019-04-10 00:56:33,539 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 1.663903\n",
      "Reconstruction: 1.565820, Regularization: 0.006302, Discriminator: 0.002221; Generator: 0.089560,\n",
      "D(x): 0.988, D(G(z)): 0.057\n",
      "2019-04-10 00:56:33,650 root         INFO     Train Epoch: 40 [5632/8000 (70%)]\tTotal Loss: 1.731923\n",
      "Reconstruction: 1.635070, Regularization: 0.005037, Discriminator: 0.001913; Generator: 0.089904,\n",
      "D(x): 0.997, D(G(z)): 0.056\n",
      "2019-04-10 00:56:33,760 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 1.667457\n",
      "Reconstruction: 1.571029, Regularization: 0.004926, Discriminator: 0.002265; Generator: 0.089238,\n",
      "D(x): 0.989, D(G(z)): 0.058\n",
      "2019-04-10 00:56:33,872 root         INFO     Train Epoch: 40 [6656/8000 (83%)]\tTotal Loss: 1.581872\n",
      "Reconstruction: 1.484704, Regularization: 0.004708, Discriminator: 0.002041; Generator: 0.090420,\n",
      "D(x): 0.992, D(G(z)): 0.056\n",
      "2019-04-10 00:56:33,982 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 1.780905\n",
      "Reconstruction: 1.683519, Regularization: 0.005369, Discriminator: 0.001814; Generator: 0.090202,\n",
      "D(x): 0.999, D(G(z)): 0.056\n",
      "2019-04-10 00:56:34,092 root         INFO     Train Epoch: 40 [7680/8000 (96%)]\tTotal Loss: 1.544785\n",
      "Reconstruction: 1.447608, Regularization: 0.004646, Discriminator: 0.001842; Generator: 0.090690,\n",
      "D(x): 0.998, D(G(z)): 0.055\n",
      "2019-04-10 00:56:34,172 root         INFO     ====> Epoch: 40 Average loss: 1.9336\n",
      "2019-04-10 00:56:34,199 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 1.439436\n",
      "Reconstruction: 1.341534, Regularization: 0.005136, Discriminator: 0.002144; Generator: 0.090622,\n",
      "D(x): 0.989, D(G(z)): 0.055\n",
      "2019-04-10 00:56:34,311 root         INFO     Train Epoch: 41 [512/8000 (6%)]\tTotal Loss: 1.380589\n",
      "Reconstruction: 1.285092, Regularization: 0.003703, Discriminator: 0.002086; Generator: 0.089707,\n",
      "D(x): 0.992, D(G(z)): 0.057\n",
      "2019-04-10 00:56:34,422 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 1.317771\n",
      "Reconstruction: 1.221622, Regularization: 0.004213, Discriminator: 0.002021; Generator: 0.089915,\n",
      "D(x): 0.994, D(G(z)): 0.056\n",
      "2019-04-10 00:56:34,532 root         INFO     Train Epoch: 41 [1536/8000 (19%)]\tTotal Loss: 1.362123\n",
      "Reconstruction: 1.266135, Regularization: 0.004073, Discriminator: 0.001963; Generator: 0.089951,\n",
      "D(x): 0.995, D(G(z)): 0.056\n",
      "2019-04-10 00:56:34,643 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 1.244714\n",
      "Reconstruction: 1.147502, Regularization: 0.004405, Discriminator: 0.002140; Generator: 0.090667,\n",
      "D(x): 0.989, D(G(z)): 0.055\n",
      "2019-04-10 00:56:34,753 root         INFO     Train Epoch: 41 [2560/8000 (32%)]\tTotal Loss: 1.212071\n",
      "Reconstruction: 1.116663, Regularization: 0.003449, Discriminator: 0.001960; Generator: 0.089998,\n",
      "D(x): 0.995, D(G(z)): 0.056\n",
      "2019-04-10 00:56:34,862 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 1.083897\n",
      "Reconstruction: 0.987018, Regularization: 0.004722, Discriminator: 0.002061; Generator: 0.090096,\n",
      "D(x): 0.992, D(G(z)): 0.056\n",
      "2019-04-10 00:56:34,971 root         INFO     Train Epoch: 41 [3584/8000 (45%)]\tTotal Loss: 1.065092\n",
      "Reconstruction: 0.966432, Regularization: 0.005979, Discriminator: 0.002638; Generator: 0.090043,\n",
      "D(x): 0.978, D(G(z)): 0.056\n",
      "2019-04-10 00:56:35,079 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 1.169409\n",
      "Reconstruction: 1.073340, Regularization: 0.004385, Discriminator: 0.002107; Generator: 0.089577,\n",
      "D(x): 0.992, D(G(z)): 0.057\n",
      "2019-04-10 00:56:35,188 root         INFO     Train Epoch: 41 [4608/8000 (58%)]\tTotal Loss: 1.083231\n",
      "Reconstruction: 0.985921, Regularization: 0.004595, Discriminator: 0.001874; Generator: 0.090841,\n",
      "D(x): 0.996, D(G(z)): 0.055\n",
      "2019-04-10 00:56:35,296 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 1.078655\n",
      "Reconstruction: 0.980389, Regularization: 0.005693, Discriminator: 0.001870; Generator: 0.090703,\n",
      "D(x): 0.997, D(G(z)): 0.055\n",
      "2019-04-10 00:56:35,404 root         INFO     Train Epoch: 41 [5632/8000 (70%)]\tTotal Loss: 1.104517\n",
      "Reconstruction: 1.006831, Regularization: 0.005664, Discriminator: 0.001978; Generator: 0.090044,\n",
      "D(x): 0.995, D(G(z)): 0.056\n",
      "2019-04-10 00:56:35,514 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.939871\n",
      "Reconstruction: 0.842992, Regularization: 0.004460, Discriminator: 0.002514; Generator: 0.089905,\n",
      "D(x): 0.983, D(G(z)): 0.056\n",
      "2019-04-10 00:56:35,624 root         INFO     Train Epoch: 41 [6656/8000 (83%)]\tTotal Loss: 1.017574\n",
      "Reconstruction: 0.921360, Regularization: 0.004245, Discriminator: 0.001865; Generator: 0.090105,\n",
      "D(x): 0.998, D(G(z)): 0.056\n",
      "2019-04-10 00:56:35,733 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.919884\n",
      "Reconstruction: 0.822917, Regularization: 0.005182, Discriminator: 0.001890; Generator: 0.089895,\n",
      "D(x): 0.998, D(G(z)): 0.057\n",
      "2019-04-10 00:56:35,844 root         INFO     Train Epoch: 41 [7680/8000 (96%)]\tTotal Loss: 0.916215\n",
      "Reconstruction: 0.817466, Regularization: 0.005636, Discriminator: 0.002064; Generator: 0.091048,\n",
      "D(x): 0.991, D(G(z)): 0.054\n",
      "2019-04-10 00:56:35,924 root         INFO     ====> Epoch: 41 Average loss: 1.1367\n",
      "2019-04-10 00:56:35,952 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.878356\n",
      "Reconstruction: 0.781435, Regularization: 0.005050, Discriminator: 0.001961; Generator: 0.089909,\n",
      "D(x): 0.996, D(G(z)): 0.057\n",
      "2019-04-10 00:56:36,063 root         INFO     Train Epoch: 42 [512/8000 (6%)]\tTotal Loss: 0.812614\n",
      "Reconstruction: 0.714830, Regularization: 0.005885, Discriminator: 0.002776; Generator: 0.089124,\n",
      "D(x): 0.978, D(G(z)): 0.058\n",
      "2019-04-10 00:56:36,174 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.789356\n",
      "Reconstruction: 0.690312, Regularization: 0.006243, Discriminator: 0.001847; Generator: 0.090954,\n",
      "D(x): 0.997, D(G(z)): 0.055\n",
      "2019-04-10 00:56:36,285 root         INFO     Train Epoch: 42 [1536/8000 (19%)]\tTotal Loss: 0.808876\n",
      "Reconstruction: 0.711128, Regularization: 0.006058, Discriminator: 0.001965; Generator: 0.089725,\n",
      "D(x): 0.996, D(G(z)): 0.057\n",
      "2019-04-10 00:56:36,395 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.733568\n",
      "Reconstruction: 0.634328, Regularization: 0.007103, Discriminator: 0.002018; Generator: 0.090119,\n",
      "D(x): 0.993, D(G(z)): 0.056\n",
      "2019-04-10 00:56:36,504 root         INFO     Train Epoch: 42 [2560/8000 (32%)]\tTotal Loss: 0.760392\n",
      "Reconstruction: 0.660695, Regularization: 0.006477, Discriminator: 0.002539; Generator: 0.090681,\n",
      "D(x): 0.979, D(G(z)): 0.055\n",
      "2019-04-10 00:56:36,615 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 0.796915\n",
      "Reconstruction: 0.696944, Regularization: 0.007909, Discriminator: 0.001997; Generator: 0.090064,\n",
      "D(x): 0.994, D(G(z)): 0.056\n",
      "2019-04-10 00:56:36,724 root         INFO     Train Epoch: 42 [3584/8000 (45%)]\tTotal Loss: 0.768801\n",
      "Reconstruction: 0.669365, Regularization: 0.006382, Discriminator: 0.002430; Generator: 0.090624,\n",
      "D(x): 0.984, D(G(z)): 0.055\n",
      "2019-04-10 00:56:36,834 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.763004\n",
      "Reconstruction: 0.665810, Regularization: 0.006578, Discriminator: 0.001989; Generator: 0.088627,\n",
      "D(x): 0.997, D(G(z)): 0.059\n",
      "2019-04-10 00:56:36,944 root         INFO     Train Epoch: 42 [4608/8000 (58%)]\tTotal Loss: 0.632516\n",
      "Reconstruction: 0.534348, Regularization: 0.006835, Discriminator: 0.001948; Generator: 0.089385,\n",
      "D(x): 0.997, D(G(z)): 0.058\n",
      "2019-04-10 00:56:37,055 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.569130\n",
      "Reconstruction: 0.469986, Regularization: 0.008275, Discriminator: 0.001989; Generator: 0.088881,\n",
      "D(x): 0.997, D(G(z)): 0.059\n",
      "2019-04-10 00:56:37,165 root         INFO     Train Epoch: 42 [5632/8000 (70%)]\tTotal Loss: 0.584912\n",
      "Reconstruction: 0.484070, Regularization: 0.008272, Discriminator: 0.002387; Generator: 0.090183,\n",
      "D(x): 0.983, D(G(z)): 0.056\n",
      "2019-04-10 00:56:37,275 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.589172\n",
      "Reconstruction: 0.490395, Regularization: 0.008013, Discriminator: 0.002101; Generator: 0.088663,\n",
      "D(x): 0.994, D(G(z)): 0.059\n",
      "2019-04-10 00:56:37,386 root         INFO     Train Epoch: 42 [6656/8000 (83%)]\tTotal Loss: 0.562173\n",
      "Reconstruction: 0.460232, Regularization: 0.008933, Discriminator: 0.002198; Generator: 0.090810,\n",
      "D(x): 0.987, D(G(z)): 0.055\n",
      "2019-04-10 00:56:37,496 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.606949\n",
      "Reconstruction: 0.507537, Regularization: 0.008473, Discriminator: 0.002059; Generator: 0.088881,\n",
      "D(x): 0.994, D(G(z)): 0.058\n",
      "2019-04-10 00:56:37,606 root         INFO     Train Epoch: 42 [7680/8000 (96%)]\tTotal Loss: 0.545560\n",
      "Reconstruction: 0.444068, Regularization: 0.008766, Discriminator: 0.001938; Generator: 0.090789,\n",
      "D(x): 0.995, D(G(z)): 0.055\n",
      "2019-04-10 00:56:37,686 root         INFO     ====> Epoch: 42 Average loss: 0.6952\n",
      "2019-04-10 00:56:37,714 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.594526\n",
      "Reconstruction: 0.493254, Regularization: 0.008571, Discriminator: 0.001936; Generator: 0.090765,\n",
      "D(x): 0.995, D(G(z)): 0.055\n",
      "2019-04-10 00:56:37,825 root         INFO     Train Epoch: 43 [512/8000 (6%)]\tTotal Loss: 0.528174\n",
      "Reconstruction: 0.427663, Regularization: 0.009407, Discriminator: 0.001995; Generator: 0.089109,\n",
      "D(x): 0.996, D(G(z)): 0.058\n",
      "2019-04-10 00:56:37,936 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.557344\n",
      "Reconstruction: 0.457185, Regularization: 0.007953, Discriminator: 0.001911; Generator: 0.090294,\n",
      "D(x): 0.997, D(G(z)): 0.056\n",
      "2019-04-10 00:56:38,046 root         INFO     Train Epoch: 43 [1536/8000 (19%)]\tTotal Loss: 0.596415\n",
      "Reconstruction: 0.495014, Regularization: 0.009323, Discriminator: 0.002061; Generator: 0.090016,\n",
      "D(x): 0.993, D(G(z)): 0.056\n",
      "2019-04-10 00:56:38,157 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.467721\n",
      "Reconstruction: 0.366607, Regularization: 0.008101, Discriminator: 0.001891; Generator: 0.091122,\n",
      "D(x): 0.996, D(G(z)): 0.055\n",
      "2019-04-10 00:56:38,268 root         INFO     Train Epoch: 43 [2560/8000 (32%)]\tTotal Loss: 0.518440\n",
      "Reconstruction: 0.417305, Regularization: 0.009415, Discriminator: 0.002272; Generator: 0.089449,\n",
      "D(x): 0.987, D(G(z)): 0.057\n",
      "2019-04-10 00:56:38,379 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.483828\n",
      "Reconstruction: 0.380808, Regularization: 0.010538, Discriminator: 0.001918; Generator: 0.090565,\n",
      "D(x): 0.996, D(G(z)): 0.056\n",
      "2019-04-10 00:56:38,489 root         INFO     Train Epoch: 43 [3584/8000 (45%)]\tTotal Loss: 0.486830\n",
      "Reconstruction: 0.382668, Regularization: 0.010427, Discriminator: 0.002202; Generator: 0.091533,\n",
      "D(x): 0.987, D(G(z)): 0.054\n",
      "2019-04-10 00:56:38,600 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.492670\n",
      "Reconstruction: 0.389143, Regularization: 0.009482, Discriminator: 0.002359; Generator: 0.091688,\n",
      "D(x): 0.984, D(G(z)): 0.054\n",
      "2019-04-10 00:56:38,710 root         INFO     Train Epoch: 43 [4608/8000 (58%)]\tTotal Loss: 0.467531\n",
      "Reconstruction: 0.365984, Regularization: 0.009055, Discriminator: 0.001925; Generator: 0.090567,\n",
      "D(x): 0.996, D(G(z)): 0.056\n",
      "2019-04-10 00:56:38,821 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.465510\n",
      "Reconstruction: 0.361895, Regularization: 0.010198, Discriminator: 0.002769; Generator: 0.090648,\n",
      "D(x): 0.974, D(G(z)): 0.055\n",
      "2019-04-10 00:56:38,931 root         INFO     Train Epoch: 43 [5632/8000 (70%)]\tTotal Loss: 0.427756\n",
      "Reconstruction: 0.325534, Regularization: 0.009530, Discriminator: 0.001906; Generator: 0.090786,\n",
      "D(x): 0.996, D(G(z)): 0.055\n",
      "2019-04-10 00:56:39,041 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.485626\n",
      "Reconstruction: 0.383570, Regularization: 0.010408, Discriminator: 0.001912; Generator: 0.089736,\n",
      "D(x): 0.998, D(G(z)): 0.057\n",
      "2019-04-10 00:56:39,150 root         INFO     Train Epoch: 43 [6656/8000 (83%)]\tTotal Loss: 0.427855\n",
      "Reconstruction: 0.323852, Regularization: 0.010254, Discriminator: 0.001934; Generator: 0.091817,\n",
      "D(x): 0.993, D(G(z)): 0.053\n",
      "2019-04-10 00:56:39,259 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.450233\n",
      "Reconstruction: 0.348447, Regularization: 0.009520, Discriminator: 0.002014; Generator: 0.090251,\n",
      "D(x): 0.994, D(G(z)): 0.056\n",
      "2019-04-10 00:56:39,368 root         INFO     Train Epoch: 43 [7680/8000 (96%)]\tTotal Loss: 0.422323\n",
      "Reconstruction: 0.318309, Regularization: 0.009911, Discriminator: 0.001855; Generator: 0.092247,\n",
      "D(x): 0.995, D(G(z)): 0.053\n",
      "2019-04-10 00:56:39,448 root         INFO     ====> Epoch: 43 Average loss: 0.4861\n",
      "2019-04-10 00:56:39,476 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.389338\n",
      "Reconstruction: 0.284624, Regularization: 0.010872, Discriminator: 0.002308; Generator: 0.091534,\n",
      "D(x): 0.983, D(G(z)): 0.054\n",
      "2019-04-10 00:56:39,588 root         INFO     Train Epoch: 44 [512/8000 (6%)]\tTotal Loss: 0.423458\n",
      "Reconstruction: 0.320240, Regularization: 0.010305, Discriminator: 0.001991; Generator: 0.090922,\n",
      "D(x): 0.993, D(G(z)): 0.055\n",
      "2019-04-10 00:56:39,698 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.415450\n",
      "Reconstruction: 0.311661, Regularization: 0.010835, Discriminator: 0.001979; Generator: 0.090975,\n",
      "D(x): 0.993, D(G(z)): 0.055\n",
      "2019-04-10 00:56:39,807 root         INFO     Train Epoch: 44 [1536/8000 (19%)]\tTotal Loss: 0.404497\n",
      "Reconstruction: 0.301898, Regularization: 0.009852, Discriminator: 0.002304; Generator: 0.090443,\n",
      "D(x): 0.985, D(G(z)): 0.056\n",
      "2019-04-10 00:56:39,915 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.419037\n",
      "Reconstruction: 0.315814, Regularization: 0.009940, Discriminator: 0.002665; Generator: 0.090619,\n",
      "D(x): 0.978, D(G(z)): 0.056\n",
      "2019-04-10 00:56:40,024 root         INFO     Train Epoch: 44 [2560/8000 (32%)]\tTotal Loss: 0.396035\n",
      "Reconstruction: 0.291225, Regularization: 0.011101, Discriminator: 0.001918; Generator: 0.091791,\n",
      "D(x): 0.994, D(G(z)): 0.053\n",
      "2019-04-10 00:56:40,133 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.382727\n",
      "Reconstruction: 0.278922, Regularization: 0.010114, Discriminator: 0.002600; Generator: 0.091092,\n",
      "D(x): 0.976, D(G(z)): 0.055\n",
      "2019-04-10 00:56:40,243 root         INFO     Train Epoch: 44 [3584/8000 (45%)]\tTotal Loss: 0.399454\n",
      "Reconstruction: 0.295115, Regularization: 0.011682, Discriminator: 0.001930; Generator: 0.090727,\n",
      "D(x): 0.995, D(G(z)): 0.056\n",
      "2019-04-10 00:56:40,351 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.391603\n",
      "Reconstruction: 0.287665, Regularization: 0.010219, Discriminator: 0.001860; Generator: 0.091858,\n",
      "D(x): 0.996, D(G(z)): 0.054\n",
      "2019-04-10 00:56:40,459 root         INFO     Train Epoch: 44 [4608/8000 (58%)]\tTotal Loss: 0.395440\n",
      "Reconstruction: 0.290506, Regularization: 0.010451, Discriminator: 0.002625; Generator: 0.091858,\n",
      "D(x): 0.975, D(G(z)): 0.054\n",
      "2019-04-10 00:56:40,568 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.391539\n",
      "Reconstruction: 0.287874, Regularization: 0.010703, Discriminator: 0.002182; Generator: 0.090781,\n",
      "D(x): 0.988, D(G(z)): 0.056\n",
      "2019-04-10 00:56:40,676 root         INFO     Train Epoch: 44 [5632/8000 (70%)]\tTotal Loss: 0.381489\n",
      "Reconstruction: 0.278720, Regularization: 0.010082, Discriminator: 0.001978; Generator: 0.090709,\n",
      "D(x): 0.994, D(G(z)): 0.056\n",
      "2019-04-10 00:56:40,785 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.353433\n",
      "Reconstruction: 0.249395, Regularization: 0.010087, Discriminator: 0.001918; Generator: 0.092032,\n",
      "D(x): 0.994, D(G(z)): 0.053\n",
      "2019-04-10 00:56:40,895 root         INFO     Train Epoch: 44 [6656/8000 (83%)]\tTotal Loss: 0.368057\n",
      "Reconstruction: 0.263864, Regularization: 0.010266, Discriminator: 0.002496; Generator: 0.091431,\n",
      "D(x): 0.978, D(G(z)): 0.054\n",
      "2019-04-10 00:56:41,004 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.379076\n",
      "Reconstruction: 0.276124, Regularization: 0.010050, Discriminator: 0.002029; Generator: 0.090873,\n",
      "D(x): 0.992, D(G(z)): 0.055\n",
      "2019-04-10 00:56:41,113 root         INFO     Train Epoch: 44 [7680/8000 (96%)]\tTotal Loss: 0.370290\n",
      "Reconstruction: 0.268523, Regularization: 0.010124, Discriminator: 0.002160; Generator: 0.089482,\n",
      "D(x): 0.991, D(G(z)): 0.058\n",
      "2019-04-10 00:56:41,193 root         INFO     ====> Epoch: 44 Average loss: 0.3933\n",
      "2019-04-10 00:56:41,221 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.364141\n",
      "Reconstruction: 0.259170, Regularization: 0.010420, Discriminator: 0.002695; Generator: 0.091857,\n",
      "D(x): 0.976, D(G(z)): 0.054\n",
      "2019-04-10 00:56:41,331 root         INFO     Train Epoch: 45 [512/8000 (6%)]\tTotal Loss: 0.358383\n",
      "Reconstruction: 0.256926, Regularization: 0.009600, Discriminator: 0.002054; Generator: 0.089802,\n",
      "D(x): 0.994, D(G(z)): 0.058\n",
      "2019-04-10 00:56:41,441 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 0.374548\n",
      "Reconstruction: 0.270204, Regularization: 0.011236, Discriminator: 0.002942; Generator: 0.090166,\n",
      "D(x): 0.970, D(G(z)): 0.056\n",
      "2019-04-10 00:56:41,550 root         INFO     Train Epoch: 45 [1536/8000 (19%)]\tTotal Loss: 0.335848\n",
      "Reconstruction: 0.232178, Regularization: 0.010584, Discriminator: 0.002149; Generator: 0.090936,\n",
      "D(x): 0.989, D(G(z)): 0.056\n",
      "2019-04-10 00:56:41,661 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.365260\n",
      "Reconstruction: 0.259618, Regularization: 0.010782, Discriminator: 0.002489; Generator: 0.092371,\n",
      "D(x): 0.978, D(G(z)): 0.053\n",
      "2019-04-10 00:56:41,771 root         INFO     Train Epoch: 45 [2560/8000 (32%)]\tTotal Loss: 0.352544\n",
      "Reconstruction: 0.250143, Regularization: 0.009275, Discriminator: 0.002142; Generator: 0.090984,\n",
      "D(x): 0.989, D(G(z)): 0.055\n",
      "2019-04-10 00:56:41,881 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.362500\n",
      "Reconstruction: 0.261616, Regularization: 0.009473, Discriminator: 0.002238; Generator: 0.089172,\n",
      "D(x): 0.989, D(G(z)): 0.058\n",
      "2019-04-10 00:56:41,992 root         INFO     Train Epoch: 45 [3584/8000 (45%)]\tTotal Loss: 0.340926\n",
      "Reconstruction: 0.237456, Regularization: 0.010300, Discriminator: 0.002276; Generator: 0.090893,\n",
      "D(x): 0.984, D(G(z)): 0.055\n",
      "2019-04-10 00:56:42,102 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.352913\n",
      "Reconstruction: 0.249438, Regularization: 0.009458, Discriminator: 0.002039; Generator: 0.091979,\n",
      "D(x): 0.991, D(G(z)): 0.054\n",
      "2019-04-10 00:56:42,213 root         INFO     Train Epoch: 45 [4608/8000 (58%)]\tTotal Loss: 0.358114\n",
      "Reconstruction: 0.255894, Regularization: 0.009511, Discriminator: 0.002254; Generator: 0.090455,\n",
      "D(x): 0.987, D(G(z)): 0.057\n",
      "2019-04-10 00:56:42,323 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.347258\n",
      "Reconstruction: 0.245270, Regularization: 0.009403, Discriminator: 0.002314; Generator: 0.090271,\n",
      "D(x): 0.985, D(G(z)): 0.057\n",
      "2019-04-10 00:56:42,434 root         INFO     Train Epoch: 45 [5632/8000 (70%)]\tTotal Loss: 0.342085\n",
      "Reconstruction: 0.240303, Regularization: 0.008837, Discriminator: 0.002152; Generator: 0.090793,\n",
      "D(x): 0.989, D(G(z)): 0.056\n",
      "2019-04-10 00:56:42,544 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.331570\n",
      "Reconstruction: 0.231583, Regularization: 0.009162, Discriminator: 0.002229; Generator: 0.088596,\n",
      "D(x): 0.990, D(G(z)): 0.060\n",
      "2019-04-10 00:56:42,655 root         INFO     Train Epoch: 45 [6656/8000 (83%)]\tTotal Loss: 0.330949\n",
      "Reconstruction: 0.228578, Regularization: 0.009186, Discriminator: 0.002517; Generator: 0.090668,\n",
      "D(x): 0.979, D(G(z)): 0.056\n",
      "2019-04-10 00:56:42,766 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.345711\n",
      "Reconstruction: 0.242827, Regularization: 0.010227, Discriminator: 0.002028; Generator: 0.090629,\n",
      "D(x): 0.993, D(G(z)): 0.056\n",
      "2019-04-10 00:56:42,876 root         INFO     Train Epoch: 45 [7680/8000 (96%)]\tTotal Loss: 0.338101\n",
      "Reconstruction: 0.236086, Regularization: 0.009137, Discriminator: 0.002377; Generator: 0.090502,\n",
      "D(x): 0.983, D(G(z)): 0.056\n",
      "2019-04-10 00:56:42,957 root         INFO     ====> Epoch: 45 Average loss: 0.3524\n",
      "2019-04-10 00:56:42,984 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.350483\n",
      "Reconstruction: 0.248663, Regularization: 0.010017, Discriminator: 0.002711; Generator: 0.089093,\n",
      "D(x): 0.977, D(G(z)): 0.059\n",
      "2019-04-10 00:56:43,096 root         INFO     Train Epoch: 46 [512/8000 (6%)]\tTotal Loss: 0.355361\n",
      "Reconstruction: 0.252660, Regularization: 0.009196, Discriminator: 0.001971; Generator: 0.091535,\n",
      "D(x): 0.993, D(G(z)): 0.055\n",
      "2019-04-10 00:56:43,207 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.337956\n",
      "Reconstruction: 0.235031, Regularization: 0.009382, Discriminator: 0.002756; Generator: 0.090786,\n",
      "D(x): 0.974, D(G(z)): 0.056\n",
      "2019-04-10 00:56:43,319 root         INFO     Train Epoch: 46 [1536/8000 (19%)]\tTotal Loss: 0.346978\n",
      "Reconstruction: 0.243975, Regularization: 0.009501, Discriminator: 0.002122; Generator: 0.091380,\n",
      "D(x): 0.989, D(G(z)): 0.055\n",
      "2019-04-10 00:56:43,431 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.335161\n",
      "Reconstruction: 0.232632, Regularization: 0.008480, Discriminator: 0.002494; Generator: 0.091556,\n",
      "D(x): 0.978, D(G(z)): 0.055\n",
      "2019-04-10 00:56:43,542 root         INFO     Train Epoch: 46 [2560/8000 (32%)]\tTotal Loss: 0.339985\n",
      "Reconstruction: 0.236453, Regularization: 0.009004, Discriminator: 0.002611; Generator: 0.091917,\n",
      "D(x): 0.974, D(G(z)): 0.054\n",
      "2019-04-10 00:56:43,653 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.338513\n",
      "Reconstruction: 0.237786, Regularization: 0.009249, Discriminator: 0.003161; Generator: 0.088317,\n",
      "D(x): 0.966, D(G(z)): 0.060\n",
      "2019-04-10 00:56:43,765 root         INFO     Train Epoch: 46 [3584/8000 (45%)]\tTotal Loss: 0.339070\n",
      "Reconstruction: 0.237768, Regularization: 0.009754, Discriminator: 0.002201; Generator: 0.089346,\n",
      "D(x): 0.991, D(G(z)): 0.059\n",
      "2019-04-10 00:56:43,874 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.329110\n",
      "Reconstruction: 0.229967, Regularization: 0.008322, Discriminator: 0.002242; Generator: 0.088578,\n",
      "D(x): 0.991, D(G(z)): 0.060\n",
      "2019-04-10 00:56:43,983 root         INFO     Train Epoch: 46 [4608/8000 (58%)]\tTotal Loss: 0.323063\n",
      "Reconstruction: 0.223776, Regularization: 0.007948, Discriminator: 0.002592; Generator: 0.088747,\n",
      "D(x): 0.980, D(G(z)): 0.060\n",
      "2019-04-10 00:56:44,092 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.334776\n",
      "Reconstruction: 0.233864, Regularization: 0.008588, Discriminator: 0.002566; Generator: 0.089757,\n",
      "D(x): 0.979, D(G(z)): 0.057\n",
      "2019-04-10 00:56:44,201 root         INFO     Train Epoch: 46 [5632/8000 (70%)]\tTotal Loss: 0.338445\n",
      "Reconstruction: 0.237511, Regularization: 0.007985, Discriminator: 0.001940; Generator: 0.091009,\n",
      "D(x): 0.995, D(G(z)): 0.056\n",
      "2019-04-10 00:56:44,309 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.344852\n",
      "Reconstruction: 0.246102, Regularization: 0.008379, Discriminator: 0.002974; Generator: 0.087398,\n",
      "D(x): 0.976, D(G(z)): 0.064\n",
      "2019-04-10 00:56:44,417 root         INFO     Train Epoch: 46 [6656/8000 (83%)]\tTotal Loss: 0.349059\n",
      "Reconstruction: 0.251934, Regularization: 0.007727, Discriminator: 0.002598; Generator: 0.086800,\n",
      "D(x): 0.985, D(G(z)): 0.064\n",
      "2019-04-10 00:56:44,527 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.323904\n",
      "Reconstruction: 0.221563, Regularization: 0.007731, Discriminator: 0.002604; Generator: 0.092007,\n",
      "D(x): 0.975, D(G(z)): 0.054\n",
      "2019-04-10 00:56:44,638 root         INFO     Train Epoch: 46 [7680/8000 (96%)]\tTotal Loss: 0.332747\n",
      "Reconstruction: 0.234092, Regularization: 0.007483, Discriminator: 0.003758; Generator: 0.087415,\n",
      "D(x): 0.960, D(G(z)): 0.063\n",
      "2019-04-10 00:56:44,719 root         INFO     ====> Epoch: 46 Average loss: 0.3349\n",
      "2019-04-10 00:56:44,746 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.336073\n",
      "Reconstruction: 0.235719, Regularization: 0.007442, Discriminator: 0.003883; Generator: 0.089029,\n",
      "D(x): 0.966, D(G(z)): 0.059\n",
      "2019-04-10 00:56:44,859 root         INFO     Train Epoch: 47 [512/8000 (6%)]\tTotal Loss: 0.340537\n",
      "Reconstruction: 0.241314, Regularization: 0.008568, Discriminator: 0.002145; Generator: 0.088510,\n",
      "D(x): 0.994, D(G(z)): 0.060\n",
      "2019-04-10 00:56:44,970 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.331830\n",
      "Reconstruction: 0.232944, Regularization: 0.007541, Discriminator: 0.002754; Generator: 0.088592,\n",
      "D(x): 0.977, D(G(z)): 0.060\n",
      "2019-04-10 00:56:45,082 root         INFO     Train Epoch: 47 [1536/8000 (19%)]\tTotal Loss: 0.327715\n",
      "Reconstruction: 0.228195, Regularization: 0.007194, Discriminator: 0.003272; Generator: 0.089054,\n",
      "D(x): 0.967, D(G(z)): 0.060\n",
      "2019-04-10 00:56:45,193 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.333338\n",
      "Reconstruction: 0.233431, Regularization: 0.007928, Discriminator: 0.004153; Generator: 0.087827,\n",
      "D(x): 0.949, D(G(z)): 0.062\n",
      "2019-04-10 00:56:45,305 root         INFO     Train Epoch: 47 [2560/8000 (32%)]\tTotal Loss: 0.328559\n",
      "Reconstruction: 0.228729, Regularization: 0.007700, Discriminator: 0.005450; Generator: 0.086680,\n",
      "D(x): 0.929, D(G(z)): 0.064\n",
      "2019-04-10 00:56:45,417 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.326255\n",
      "Reconstruction: 0.228346, Regularization: 0.007751, Discriminator: 0.004990; Generator: 0.085168,\n",
      "D(x): 0.935, D(G(z)): 0.067\n",
      "2019-04-10 00:56:45,528 root         INFO     Train Epoch: 47 [3584/8000 (45%)]\tTotal Loss: 0.317622\n",
      "Reconstruction: 0.222366, Regularization: 0.006269, Discriminator: 0.003855; Generator: 0.085132,\n",
      "D(x): 0.959, D(G(z)): 0.068\n",
      "2019-04-10 00:56:45,640 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.318277\n",
      "Reconstruction: 0.221818, Regularization: 0.006042, Discriminator: 0.004456; Generator: 0.085961,\n",
      "D(x): 0.950, D(G(z)): 0.065\n",
      "2019-04-10 00:56:45,752 root         INFO     Train Epoch: 47 [4608/8000 (58%)]\tTotal Loss: 0.324977\n",
      "Reconstruction: 0.227574, Regularization: 0.007762, Discriminator: 0.004131; Generator: 0.085509,\n",
      "D(x): 0.957, D(G(z)): 0.067\n",
      "2019-04-10 00:56:45,863 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.327153\n",
      "Reconstruction: 0.228865, Regularization: 0.007232, Discriminator: 0.004017; Generator: 0.087039,\n",
      "D(x): 0.956, D(G(z)): 0.063\n",
      "2019-04-10 00:56:45,975 root         INFO     Train Epoch: 47 [5632/8000 (70%)]\tTotal Loss: 0.334416\n",
      "Reconstruction: 0.237902, Regularization: 0.007822, Discriminator: 0.002404; Generator: 0.086289,\n",
      "D(x): 0.991, D(G(z)): 0.065\n",
      "2019-04-10 00:56:46,087 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.328846\n",
      "Reconstruction: 0.228643, Regularization: 0.005931, Discriminator: 0.005809; Generator: 0.088464,\n",
      "D(x): 0.927, D(G(z)): 0.061\n",
      "2019-04-10 00:56:46,198 root         INFO     Train Epoch: 47 [6656/8000 (83%)]\tTotal Loss: 0.320261\n",
      "Reconstruction: 0.222069, Regularization: 0.006655, Discriminator: 0.002788; Generator: 0.088749,\n",
      "D(x): 0.975, D(G(z)): 0.060\n",
      "2019-04-10 00:56:46,310 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.321981\n",
      "Reconstruction: 0.226269, Regularization: 0.005481, Discriminator: 0.003530; Generator: 0.086701,\n",
      "D(x): 0.962, D(G(z)): 0.064\n",
      "2019-04-10 00:56:46,422 root         INFO     Train Epoch: 47 [7680/8000 (96%)]\tTotal Loss: 0.318338\n",
      "Reconstruction: 0.217613, Regularization: 0.005253, Discriminator: 0.004458; Generator: 0.091014,\n",
      "D(x): 0.958, D(G(z)): 0.056\n",
      "2019-04-10 00:56:46,503 root         INFO     ====> Epoch: 47 Average loss: 0.3267\n",
      "2019-04-10 00:56:46,530 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.322107\n",
      "Reconstruction: 0.225306, Regularization: 0.006362, Discriminator: 0.002555; Generator: 0.087884,\n",
      "D(x): 0.983, D(G(z)): 0.062\n",
      "2019-04-10 00:56:46,643 root         INFO     Train Epoch: 48 [512/8000 (6%)]\tTotal Loss: 0.330950\n",
      "Reconstruction: 0.231538, Regularization: 0.006716, Discriminator: 0.006283; Generator: 0.086412,\n",
      "D(x): 0.949, D(G(z)): 0.066\n",
      "2019-04-10 00:56:46,754 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.323226\n",
      "Reconstruction: 0.226439, Regularization: 0.005771, Discriminator: 0.004308; Generator: 0.086708,\n",
      "D(x): 0.944, D(G(z)): 0.064\n",
      "2019-04-10 00:56:46,866 root         INFO     Train Epoch: 48 [1536/8000 (19%)]\tTotal Loss: 0.319375\n",
      "Reconstruction: 0.226381, Regularization: 0.006440, Discriminator: 0.002783; Generator: 0.083771,\n",
      "D(x): 0.985, D(G(z)): 0.071\n",
      "2019-04-10 00:56:46,977 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.333349\n",
      "Reconstruction: 0.238524, Regularization: 0.004994, Discriminator: 0.002499; Generator: 0.087332,\n",
      "D(x): 0.986, D(G(z)): 0.063\n",
      "2019-04-10 00:56:47,089 root         INFO     Train Epoch: 48 [2560/8000 (32%)]\tTotal Loss: 0.324554\n",
      "Reconstruction: 0.228341, Regularization: 0.004829, Discriminator: 0.003739; Generator: 0.087646,\n",
      "D(x): 0.965, D(G(z)): 0.062\n",
      "2019-04-10 00:56:47,200 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.321415\n",
      "Reconstruction: 0.228792, Regularization: 0.004431, Discriminator: 0.002956; Generator: 0.085236,\n",
      "D(x): 0.979, D(G(z)): 0.068\n",
      "2019-04-10 00:56:47,312 root         INFO     Train Epoch: 48 [3584/8000 (45%)]\tTotal Loss: 0.317202\n",
      "Reconstruction: 0.224457, Regularization: 0.003986, Discriminator: 0.003774; Generator: 0.084985,\n",
      "D(x): 0.962, D(G(z)): 0.067\n",
      "2019-04-10 00:56:47,423 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.321265\n",
      "Reconstruction: 0.229773, Regularization: 0.004419, Discriminator: 0.005190; Generator: 0.081882,\n",
      "D(x): 0.931, D(G(z)): 0.075\n",
      "2019-04-10 00:56:47,535 root         INFO     Train Epoch: 48 [4608/8000 (58%)]\tTotal Loss: 0.328532\n",
      "Reconstruction: 0.238068, Regularization: 0.004884, Discriminator: 0.002799; Generator: 0.082782,\n",
      "D(x): 0.987, D(G(z)): 0.073\n",
      "2019-04-10 00:56:47,646 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.323957\n",
      "Reconstruction: 0.231555, Regularization: 0.004755, Discriminator: 0.003420; Generator: 0.084227,\n",
      "D(x): 0.974, D(G(z)): 0.072\n",
      "2019-04-10 00:56:47,758 root         INFO     Train Epoch: 48 [5632/8000 (70%)]\tTotal Loss: 0.319818\n",
      "Reconstruction: 0.229922, Regularization: 0.004816, Discriminator: 0.004225; Generator: 0.080856,\n",
      "D(x): 0.956, D(G(z)): 0.079\n",
      "2019-04-10 00:56:47,869 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.322526\n",
      "Reconstruction: 0.230639, Regularization: 0.004519, Discriminator: 0.004802; Generator: 0.082566,\n",
      "D(x): 0.946, D(G(z)): 0.074\n",
      "2019-04-10 00:56:47,981 root         INFO     Train Epoch: 48 [6656/8000 (83%)]\tTotal Loss: 0.328004\n",
      "Reconstruction: 0.233687, Regularization: 0.004908, Discriminator: 0.008395; Generator: 0.081014,\n",
      "D(x): 0.902, D(G(z)): 0.076\n",
      "2019-04-10 00:56:48,092 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.334368\n",
      "Reconstruction: 0.238784, Regularization: 0.005355, Discriminator: 0.005765; Generator: 0.084465,\n",
      "D(x): 0.928, D(G(z)): 0.070\n",
      "2019-04-10 00:56:48,203 root         INFO     Train Epoch: 48 [7680/8000 (96%)]\tTotal Loss: 0.327066\n",
      "Reconstruction: 0.236364, Regularization: 0.005226, Discriminator: 0.003523; Generator: 0.081953,\n",
      "D(x): 0.969, D(G(z)): 0.076\n",
      "2019-04-10 00:56:48,285 root         INFO     ====> Epoch: 48 Average loss: 0.3245\n",
      "2019-04-10 00:56:48,312 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.333216\n",
      "Reconstruction: 0.240268, Regularization: 0.005122, Discriminator: 0.003014; Generator: 0.084813,\n",
      "D(x): 0.977, D(G(z)): 0.069\n",
      "2019-04-10 00:56:48,423 root         INFO     Train Epoch: 49 [512/8000 (6%)]\tTotal Loss: 0.320690\n",
      "Reconstruction: 0.230445, Regularization: 0.004364, Discriminator: 0.006837; Generator: 0.079043,\n",
      "D(x): 0.913, D(G(z)): 0.084\n",
      "2019-04-10 00:56:48,535 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.322966\n",
      "Reconstruction: 0.235253, Regularization: 0.003669, Discriminator: 0.003713; Generator: 0.080331,\n",
      "D(x): 0.967, D(G(z)): 0.079\n",
      "2019-04-10 00:56:48,646 root         INFO     Train Epoch: 49 [1536/8000 (19%)]\tTotal Loss: 0.321791\n",
      "Reconstruction: 0.235679, Regularization: 0.003605, Discriminator: 0.003976; Generator: 0.078532,\n",
      "D(x): 0.964, D(G(z)): 0.084\n",
      "2019-04-10 00:56:48,757 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.325626\n",
      "Reconstruction: 0.234878, Regularization: 0.003477, Discriminator: 0.005754; Generator: 0.081517,\n",
      "D(x): 0.940, D(G(z)): 0.078\n",
      "2019-04-10 00:56:48,867 root         INFO     Train Epoch: 49 [2560/8000 (32%)]\tTotal Loss: 0.329161\n",
      "Reconstruction: 0.237320, Regularization: 0.004392, Discriminator: 0.005128; Generator: 0.082321,\n",
      "D(x): 0.949, D(G(z)): 0.075\n",
      "2019-04-10 00:56:48,977 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.325071\n",
      "Reconstruction: 0.236192, Regularization: 0.003264, Discriminator: 0.004137; Generator: 0.081478,\n",
      "D(x): 0.956, D(G(z)): 0.079\n",
      "2019-04-10 00:56:49,087 root         INFO     Train Epoch: 49 [3584/8000 (45%)]\tTotal Loss: 0.333086\n",
      "Reconstruction: 0.240413, Regularization: 0.004079, Discriminator: 0.007243; Generator: 0.081350,\n",
      "D(x): 0.926, D(G(z)): 0.077\n",
      "2019-04-10 00:56:49,196 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.331185\n",
      "Reconstruction: 0.242876, Regularization: 0.004608, Discriminator: 0.003395; Generator: 0.080306,\n",
      "D(x): 0.977, D(G(z)): 0.081\n",
      "2019-04-10 00:56:49,306 root         INFO     Train Epoch: 49 [4608/8000 (58%)]\tTotal Loss: 0.335277\n",
      "Reconstruction: 0.243844, Regularization: 0.005132, Discriminator: 0.007248; Generator: 0.079053,\n",
      "D(x): 0.914, D(G(z)): 0.083\n",
      "2019-04-10 00:56:49,416 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.330446\n",
      "Reconstruction: 0.240754, Regularization: 0.003272, Discriminator: 0.006037; Generator: 0.080382,\n",
      "D(x): 0.923, D(G(z)): 0.081\n",
      "2019-04-10 00:56:49,526 root         INFO     Train Epoch: 49 [5632/8000 (70%)]\tTotal Loss: 0.329471\n",
      "Reconstruction: 0.242569, Regularization: 0.003063, Discriminator: 0.005093; Generator: 0.078745,\n",
      "D(x): 0.938, D(G(z)): 0.085\n",
      "2019-04-10 00:56:49,636 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.327535\n",
      "Reconstruction: 0.240963, Regularization: 0.003244, Discriminator: 0.004722; Generator: 0.078607,\n",
      "D(x): 0.946, D(G(z)): 0.084\n",
      "2019-04-10 00:56:49,746 root         INFO     Train Epoch: 49 [6656/8000 (83%)]\tTotal Loss: 0.332156\n",
      "Reconstruction: 0.244302, Regularization: 0.004181, Discriminator: 0.005380; Generator: 0.078293,\n",
      "D(x): 0.927, D(G(z)): 0.084\n",
      "2019-04-10 00:56:49,856 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.337231\n",
      "Reconstruction: 0.246513, Regularization: 0.003600, Discriminator: 0.008864; Generator: 0.078254,\n",
      "D(x): 0.909, D(G(z)): 0.086\n",
      "2019-04-10 00:56:49,967 root         INFO     Train Epoch: 49 [7680/8000 (96%)]\tTotal Loss: 0.330045\n",
      "Reconstruction: 0.243534, Regularization: 0.002714, Discriminator: 0.004307; Generator: 0.079490,\n",
      "D(x): 0.963, D(G(z)): 0.084\n",
      "2019-04-10 00:56:50,047 root         INFO     ====> Epoch: 49 Average loss: 0.3288\n",
      "2019-04-10 00:56:50,074 root         INFO     Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 0.330782\n",
      "Reconstruction: 0.242185, Regularization: 0.003470, Discriminator: 0.004466; Generator: 0.080662,\n",
      "D(x): 0.943, D(G(z)): 0.078\n",
      "2019-04-10 00:56:50,186 root         INFO     Train Epoch: 50 [512/8000 (6%)]\tTotal Loss: 0.334166\n",
      "Reconstruction: 0.250553, Regularization: 0.002654, Discriminator: 0.005144; Generator: 0.075816,\n",
      "D(x): 0.963, D(G(z)): 0.091\n",
      "2019-04-10 00:56:50,298 root         INFO     Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 0.331535\n",
      "Reconstruction: 0.247189, Regularization: 0.002263, Discriminator: 0.007546; Generator: 0.074537,\n",
      "D(x): 0.926, D(G(z)): 0.099\n",
      "2019-04-10 00:56:50,409 root         INFO     Train Epoch: 50 [1536/8000 (19%)]\tTotal Loss: 0.331257\n",
      "Reconstruction: 0.246728, Regularization: 0.003071, Discriminator: 0.006166; Generator: 0.075292,\n",
      "D(x): 0.924, D(G(z)): 0.094\n",
      "2019-04-10 00:56:50,520 root         INFO     Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 0.337312\n",
      "Reconstruction: 0.251297, Regularization: 0.003386, Discriminator: 0.009665; Generator: 0.072964,\n",
      "D(x): 0.911, D(G(z)): 0.104\n",
      "2019-04-10 00:56:50,631 root         INFO     Train Epoch: 50 [2560/8000 (32%)]\tTotal Loss: 0.339083\n",
      "Reconstruction: 0.254752, Regularization: 0.003204, Discriminator: 0.004494; Generator: 0.076634,\n",
      "D(x): 0.960, D(G(z)): 0.090\n",
      "2019-04-10 00:56:50,742 root         INFO     Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 0.334889\n",
      "Reconstruction: 0.251748, Regularization: 0.003447, Discriminator: 0.004782; Generator: 0.074912,\n",
      "D(x): 0.953, D(G(z)): 0.094\n",
      "2019-04-10 00:56:50,853 root         INFO     Train Epoch: 50 [3584/8000 (45%)]\tTotal Loss: 0.333939\n",
      "Reconstruction: 0.253133, Regularization: 0.004044, Discriminator: 0.006177; Generator: 0.070584,\n",
      "D(x): 0.940, D(G(z)): 0.112\n",
      "2019-04-10 00:56:50,965 root         INFO     Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 0.343618\n",
      "Reconstruction: 0.255484, Regularization: 0.003072, Discriminator: 0.010042; Generator: 0.075021,\n",
      "D(x): 0.882, D(G(z)): 0.095\n",
      "2019-04-10 00:56:51,076 root         INFO     Train Epoch: 50 [4608/8000 (58%)]\tTotal Loss: 0.344206\n",
      "Reconstruction: 0.254338, Regularization: 0.003038, Discriminator: 0.011337; Generator: 0.075493,\n",
      "D(x): 0.847, D(G(z)): 0.094\n",
      "2019-04-10 00:56:51,187 root         INFO     Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 0.336049\n",
      "Reconstruction: 0.255089, Regularization: 0.002838, Discriminator: 0.007524; Generator: 0.070598,\n",
      "D(x): 0.918, D(G(z)): 0.109\n",
      "2019-04-10 00:56:51,298 root         INFO     Train Epoch: 50 [5632/8000 (70%)]\tTotal Loss: 0.343568\n",
      "Reconstruction: 0.253351, Regularization: 0.002642, Discriminator: 0.011903; Generator: 0.075672,\n",
      "D(x): 0.848, D(G(z)): 0.093\n",
      "2019-04-10 00:56:51,410 root         INFO     Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 0.343179\n",
      "Reconstruction: 0.258289, Regularization: 0.002087, Discriminator: 0.007978; Generator: 0.074825,\n",
      "D(x): 0.923, D(G(z)): 0.095\n",
      "2019-04-10 00:56:51,521 root         INFO     Train Epoch: 50 [6656/8000 (83%)]\tTotal Loss: 0.344419\n",
      "Reconstruction: 0.259656, Regularization: 0.003282, Discriminator: 0.005734; Generator: 0.075747,\n",
      "D(x): 0.948, D(G(z)): 0.092\n",
      "2019-04-10 00:56:51,632 root         INFO     Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 0.342013\n",
      "Reconstruction: 0.261787, Regularization: 0.002035, Discriminator: 0.008123; Generator: 0.070068,\n",
      "D(x): 0.935, D(G(z)): 0.111\n",
      "2019-04-10 00:56:51,744 root         INFO     Train Epoch: 50 [7680/8000 (96%)]\tTotal Loss: 0.340170\n",
      "Reconstruction: 0.257679, Regularization: 0.002039, Discriminator: 0.011948; Generator: 0.068504,\n",
      "D(x): 0.903, D(G(z)): 0.115\n",
      "2019-04-10 00:56:51,825 root         INFO     ====> Epoch: 50 Average loss: 0.3374\n",
      "2019-04-10 00:56:51,852 root         INFO     Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 0.345986\n",
      "Reconstruction: 0.259050, Regularization: 0.002225, Discriminator: 0.014945; Generator: 0.069767,\n",
      "D(x): 0.876, D(G(z)): 0.115\n",
      "2019-04-10 00:56:51,963 root         INFO     Train Epoch: 51 [512/8000 (6%)]\tTotal Loss: 0.346316\n",
      "Reconstruction: 0.261460, Regularization: 0.003669, Discriminator: 0.013935; Generator: 0.067252,\n",
      "D(x): 0.853, D(G(z)): 0.126\n",
      "2019-04-10 00:56:52,073 root         INFO     Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 0.340226\n",
      "Reconstruction: 0.259414, Regularization: 0.002802, Discriminator: 0.008934; Generator: 0.069076,\n",
      "D(x): 0.914, D(G(z)): 0.117\n",
      "2019-04-10 00:56:52,184 root         INFO     Train Epoch: 51 [1536/8000 (19%)]\tTotal Loss: 0.341280\n",
      "Reconstruction: 0.262755, Regularization: 0.002227, Discriminator: 0.010754; Generator: 0.065544,\n",
      "D(x): 0.881, D(G(z)): 0.128\n",
      "2019-04-10 00:56:52,295 root         INFO     Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 0.341307\n",
      "Reconstruction: 0.262508, Regularization: 0.002094, Discriminator: 0.008040; Generator: 0.068664,\n",
      "D(x): 0.912, D(G(z)): 0.116\n",
      "2019-04-10 00:56:52,406 root         INFO     Train Epoch: 51 [2560/8000 (32%)]\tTotal Loss: 0.345375\n",
      "Reconstruction: 0.264539, Regularization: 0.002538, Discriminator: 0.010511; Generator: 0.067786,\n",
      "D(x): 0.891, D(G(z)): 0.120\n",
      "2019-04-10 00:56:52,516 root         INFO     Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 0.345417\n",
      "Reconstruction: 0.267419, Regularization: 0.002432, Discriminator: 0.007847; Generator: 0.067720,\n",
      "D(x): 0.926, D(G(z)): 0.121\n",
      "2019-04-10 00:56:52,626 root         INFO     Train Epoch: 51 [3584/8000 (45%)]\tTotal Loss: 0.352756\n",
      "Reconstruction: 0.271146, Regularization: 0.002657, Discriminator: 0.010289; Generator: 0.068664,\n",
      "D(x): 0.891, D(G(z)): 0.116\n",
      "2019-04-10 00:56:52,737 root         INFO     Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 0.346740\n",
      "Reconstruction: 0.266241, Regularization: 0.001681, Discriminator: 0.006717; Generator: 0.072101,\n",
      "D(x): 0.926, D(G(z)): 0.103\n",
      "2019-04-10 00:56:52,846 root         INFO     Train Epoch: 51 [4608/8000 (58%)]\tTotal Loss: 0.343507\n",
      "Reconstruction: 0.268755, Regularization: 0.001505, Discriminator: 0.006824; Generator: 0.066422,\n",
      "D(x): 0.934, D(G(z)): 0.124\n",
      "2019-04-10 00:56:52,956 root         INFO     Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 0.346243\n",
      "Reconstruction: 0.268897, Regularization: 0.002842, Discriminator: 0.008543; Generator: 0.065961,\n",
      "D(x): 0.914, D(G(z)): 0.126\n",
      "2019-04-10 00:56:53,065 root         INFO     Train Epoch: 51 [5632/8000 (70%)]\tTotal Loss: 0.356408\n",
      "Reconstruction: 0.272479, Regularization: 0.002439, Discriminator: 0.015539; Generator: 0.065952,\n",
      "D(x): 0.830, D(G(z)): 0.126\n",
      "2019-04-10 00:56:53,174 root         INFO     Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 0.355457\n",
      "Reconstruction: 0.270837, Regularization: 0.003344, Discriminator: 0.016689; Generator: 0.064587,\n",
      "D(x): 0.842, D(G(z)): 0.132\n",
      "2019-04-10 00:56:53,286 root         INFO     Train Epoch: 51 [6656/8000 (83%)]\tTotal Loss: 0.347171\n",
      "Reconstruction: 0.274410, Regularization: 0.001568, Discriminator: 0.006746; Generator: 0.064447,\n",
      "D(x): 0.938, D(G(z)): 0.133\n",
      "2019-04-10 00:56:53,399 root         INFO     Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 0.351478\n",
      "Reconstruction: 0.272642, Regularization: 0.001873, Discriminator: 0.014393; Generator: 0.062569,\n",
      "D(x): 0.862, D(G(z)): 0.140\n",
      "2019-04-10 00:56:53,512 root         INFO     Train Epoch: 51 [7680/8000 (96%)]\tTotal Loss: 0.360083\n",
      "Reconstruction: 0.277445, Regularization: 0.002463, Discriminator: 0.015811; Generator: 0.064364,\n",
      "D(x): 0.823, D(G(z)): 0.132\n",
      "2019-04-10 00:56:53,594 root         INFO     ====> Epoch: 51 Average loss: 0.3477\n",
      "2019-04-10 00:56:53,621 root         INFO     Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 0.350595\n",
      "Reconstruction: 0.276557, Regularization: 0.001929, Discriminator: 0.009134; Generator: 0.062975,\n",
      "D(x): 0.905, D(G(z)): 0.138\n",
      "2019-04-10 00:56:53,732 root         INFO     Train Epoch: 52 [512/8000 (6%)]\tTotal Loss: 0.359811\n",
      "Reconstruction: 0.277620, Regularization: 0.001279, Discriminator: 0.015429; Generator: 0.065483,\n",
      "D(x): 0.874, D(G(z)): 0.127\n",
      "2019-04-10 00:56:53,843 root         INFO     Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 0.349781\n",
      "Reconstruction: 0.278398, Regularization: 0.002016, Discriminator: 0.005856; Generator: 0.063512,\n",
      "D(x): 0.965, D(G(z)): 0.137\n",
      "2019-04-10 00:56:53,954 root         INFO     Train Epoch: 52 [1536/8000 (19%)]\tTotal Loss: 0.354662\n",
      "Reconstruction: 0.280111, Regularization: 0.001612, Discriminator: 0.009103; Generator: 0.063836,\n",
      "D(x): 0.901, D(G(z)): 0.134\n",
      "2019-04-10 00:56:54,065 root         INFO     Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 0.353715\n",
      "Reconstruction: 0.281513, Regularization: 0.001233, Discriminator: 0.012114; Generator: 0.058855,\n",
      "D(x): 0.885, D(G(z)): 0.157\n",
      "2019-04-10 00:56:54,174 root         INFO     Train Epoch: 52 [2560/8000 (32%)]\tTotal Loss: 0.360630\n",
      "Reconstruction: 0.281882, Regularization: 0.002979, Discriminator: 0.016369; Generator: 0.059399,\n",
      "D(x): 0.836, D(G(z)): 0.156\n",
      "2019-04-10 00:56:54,284 root         INFO     Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 0.354740\n",
      "Reconstruction: 0.282016, Regularization: 0.001618, Discriminator: 0.010071; Generator: 0.061035,\n",
      "D(x): 0.893, D(G(z)): 0.147\n",
      "2019-04-10 00:56:54,395 root         INFO     Train Epoch: 52 [3584/8000 (45%)]\tTotal Loss: 0.371310\n",
      "Reconstruction: 0.286547, Regularization: 0.002705, Discriminator: 0.020294; Generator: 0.061764,\n",
      "D(x): 0.810, D(G(z)): 0.143\n",
      "2019-04-10 00:56:54,507 root         INFO     Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 0.359028\n",
      "Reconstruction: 0.285196, Regularization: 0.001988, Discriminator: 0.016462; Generator: 0.055381,\n",
      "D(x): 0.852, D(G(z)): 0.174\n",
      "2019-04-10 00:56:54,617 root         INFO     Train Epoch: 52 [4608/8000 (58%)]\tTotal Loss: 0.364113\n",
      "Reconstruction: 0.284654, Regularization: 0.001608, Discriminator: 0.015728; Generator: 0.062124,\n",
      "D(x): 0.841, D(G(z)): 0.142\n",
      "2019-04-10 00:56:54,727 root         INFO     Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 0.366798\n",
      "Reconstruction: 0.288608, Regularization: 0.002155, Discriminator: 0.017152; Generator: 0.058883,\n",
      "D(x): 0.815, D(G(z)): 0.156\n",
      "2019-04-10 00:56:54,838 root         INFO     Train Epoch: 52 [5632/8000 (70%)]\tTotal Loss: 0.354452\n",
      "Reconstruction: 0.287125, Regularization: 0.001297, Discriminator: 0.008044; Generator: 0.057986,\n",
      "D(x): 0.929, D(G(z)): 0.161\n",
      "2019-04-10 00:56:54,948 root         INFO     Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 0.358943\n",
      "Reconstruction: 0.290406, Regularization: 0.001510, Discriminator: 0.011509; Generator: 0.055518,\n",
      "D(x): 0.866, D(G(z)): 0.174\n",
      "2019-04-10 00:56:55,058 root         INFO     Train Epoch: 52 [6656/8000 (83%)]\tTotal Loss: 0.359985\n",
      "Reconstruction: 0.291252, Regularization: 0.001379, Discriminator: 0.012213; Generator: 0.055141,\n",
      "D(x): 0.890, D(G(z)): 0.179\n",
      "2019-04-10 00:56:55,168 root         INFO     Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 0.366145\n",
      "Reconstruction: 0.291837, Regularization: 0.002228, Discriminator: 0.013352; Generator: 0.058728,\n",
      "D(x): 0.867, D(G(z)): 0.157\n",
      "2019-04-10 00:56:55,278 root         INFO     Train Epoch: 52 [7680/8000 (96%)]\tTotal Loss: 0.365096\n",
      "Reconstruction: 0.291140, Regularization: 0.001818, Discriminator: 0.016462; Generator: 0.055676,\n",
      "D(x): 0.829, D(G(z)): 0.173\n",
      "2019-04-10 00:56:55,358 root         INFO     ====> Epoch: 52 Average loss: 0.3603\n",
      "2019-04-10 00:56:55,385 root         INFO     Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 0.375584\n",
      "Reconstruction: 0.293755, Regularization: 0.002479, Discriminator: 0.021761; Generator: 0.057589,\n",
      "D(x): 0.782, D(G(z)): 0.164\n",
      "2019-04-10 00:56:55,494 root         INFO     Train Epoch: 53 [512/8000 (6%)]\tTotal Loss: 0.367493\n",
      "Reconstruction: 0.294115, Regularization: 0.002202, Discriminator: 0.017583; Generator: 0.053594,\n",
      "D(x): 0.841, D(G(z)): 0.187\n",
      "2019-04-10 00:56:55,605 root         INFO     Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 0.380644\n",
      "Reconstruction: 0.297574, Regularization: 0.003492, Discriminator: 0.022606; Generator: 0.056973,\n",
      "D(x): 0.791, D(G(z)): 0.168\n",
      "2019-04-10 00:56:55,715 root         INFO     Train Epoch: 53 [1536/8000 (19%)]\tTotal Loss: 0.377713\n",
      "Reconstruction: 0.296560, Regularization: 0.002139, Discriminator: 0.020891; Generator: 0.058122,\n",
      "D(x): 0.730, D(G(z)): 0.159\n",
      "2019-04-10 00:56:55,825 root         INFO     Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 0.375195\n",
      "Reconstruction: 0.298844, Regularization: 0.002696, Discriminator: 0.018218; Generator: 0.055437,\n",
      "D(x): 0.821, D(G(z)): 0.174\n",
      "2019-04-10 00:56:55,935 root         INFO     Train Epoch: 53 [2560/8000 (32%)]\tTotal Loss: 0.368299\n",
      "Reconstruction: 0.299418, Regularization: 0.001561, Discriminator: 0.015615; Generator: 0.051704,\n",
      "D(x): 0.843, D(G(z)): 0.195\n",
      "2019-04-10 00:56:56,045 root         INFO     Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 0.368553\n",
      "Reconstruction: 0.301661, Regularization: 0.001603, Discriminator: 0.011373; Generator: 0.053916,\n",
      "D(x): 0.893, D(G(z)): 0.183\n",
      "2019-04-10 00:56:56,153 root         INFO     Train Epoch: 53 [3584/8000 (45%)]\tTotal Loss: 0.378011\n",
      "Reconstruction: 0.301398, Regularization: 0.001821, Discriminator: 0.021038; Generator: 0.053753,\n",
      "D(x): 0.764, D(G(z)): 0.182\n",
      "2019-04-10 00:56:56,262 root         INFO     Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 0.365751\n",
      "Reconstruction: 0.302279, Regularization: 0.001557, Discriminator: 0.010314; Generator: 0.051600,\n",
      "D(x): 0.920, D(G(z)): 0.196\n",
      "2019-04-10 00:56:56,372 root         INFO     Train Epoch: 53 [4608/8000 (58%)]\tTotal Loss: 0.365799\n",
      "Reconstruction: 0.303144, Regularization: 0.001370, Discriminator: 0.011143; Generator: 0.050142,\n",
      "D(x): 0.917, D(G(z)): 0.206\n",
      "2019-04-10 00:56:56,481 root         INFO     Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 0.374233\n",
      "Reconstruction: 0.304286, Regularization: 0.000947, Discriminator: 0.016479; Generator: 0.052521,\n",
      "D(x): 0.823, D(G(z)): 0.189\n",
      "2019-04-10 00:56:56,590 root         INFO     Train Epoch: 53 [5632/8000 (70%)]\tTotal Loss: 0.377239\n",
      "Reconstruction: 0.307000, Regularization: 0.001728, Discriminator: 0.019254; Generator: 0.049257,\n",
      "D(x): 0.854, D(G(z)): 0.210\n",
      "2019-04-10 00:56:56,700 root         INFO     Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 0.380044\n",
      "Reconstruction: 0.307040, Regularization: 0.001491, Discriminator: 0.019314; Generator: 0.052198,\n",
      "D(x): 0.781, D(G(z)): 0.190\n",
      "2019-04-10 00:56:56,811 root         INFO     Train Epoch: 53 [6656/8000 (83%)]\tTotal Loss: 0.380064\n",
      "Reconstruction: 0.308020, Regularization: 0.001949, Discriminator: 0.022519; Generator: 0.047576,\n",
      "D(x): 0.768, D(G(z)): 0.222\n",
      "2019-04-10 00:56:56,923 root         INFO     Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 0.375496\n",
      "Reconstruction: 0.309603, Regularization: 0.001910, Discriminator: 0.015819; Generator: 0.048164,\n",
      "D(x): 0.845, D(G(z)): 0.218\n",
      "2019-04-10 00:56:57,032 root         INFO     Train Epoch: 53 [7680/8000 (96%)]\tTotal Loss: 0.388726\n",
      "Reconstruction: 0.311028, Regularization: 0.002416, Discriminator: 0.025253; Generator: 0.050028,\n",
      "D(x): 0.736, D(G(z)): 0.206\n",
      "2019-04-10 00:56:57,112 root         INFO     ====> Epoch: 53 Average loss: 0.3748\n",
      "2019-04-10 00:56:57,139 root         INFO     Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 0.379578\n",
      "Reconstruction: 0.311889, Regularization: 0.001665, Discriminator: 0.014249; Generator: 0.051774,\n",
      "D(x): 0.847, D(G(z)): 0.194\n",
      "2019-04-10 00:56:57,250 root         INFO     Train Epoch: 54 [512/8000 (6%)]\tTotal Loss: 0.389565\n",
      "Reconstruction: 0.312477, Regularization: 0.002293, Discriminator: 0.024938; Generator: 0.049857,\n",
      "D(x): 0.759, D(G(z)): 0.206\n",
      "2019-04-10 00:56:57,361 root         INFO     Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 0.394847\n",
      "Reconstruction: 0.313090, Regularization: 0.002072, Discriminator: 0.033448; Generator: 0.046238,\n",
      "D(x): 0.790, D(G(z)): 0.232\n",
      "2019-04-10 00:56:57,472 root         INFO     Train Epoch: 54 [1536/8000 (19%)]\tTotal Loss: 0.387383\n",
      "Reconstruction: 0.315417, Regularization: 0.002487, Discriminator: 0.021303; Generator: 0.048176,\n",
      "D(x): 0.804, D(G(z)): 0.220\n",
      "2019-04-10 00:56:57,583 root         INFO     Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 0.392534\n",
      "Reconstruction: 0.317007, Regularization: 0.002396, Discriminator: 0.029814; Generator: 0.043317,\n",
      "D(x): 0.759, D(G(z)): 0.253\n",
      "2019-04-10 00:56:57,695 root         INFO     Train Epoch: 54 [2560/8000 (32%)]\tTotal Loss: 0.384324\n",
      "Reconstruction: 0.316401, Regularization: 0.002218, Discriminator: 0.022582; Generator: 0.043124,\n",
      "D(x): 0.783, D(G(z)): 0.259\n",
      "2019-04-10 00:56:57,807 root         INFO     Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 0.395916\n",
      "Reconstruction: 0.317851, Regularization: 0.001559, Discriminator: 0.030460; Generator: 0.046046,\n",
      "D(x): 0.704, D(G(z)): 0.233\n",
      "2019-04-10 00:56:57,919 root         INFO     Train Epoch: 54 [3584/8000 (45%)]\tTotal Loss: 0.386362\n",
      "Reconstruction: 0.319315, Regularization: 0.001921, Discriminator: 0.021596; Generator: 0.043530,\n",
      "D(x): 0.783, D(G(z)): 0.253\n",
      "2019-04-10 00:56:58,031 root         INFO     Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 0.386329\n",
      "Reconstruction: 0.319906, Regularization: 0.001401, Discriminator: 0.020886; Generator: 0.044135,\n",
      "D(x): 0.807, D(G(z)): 0.248\n",
      "2019-04-10 00:56:58,143 root         INFO     Train Epoch: 54 [4608/8000 (58%)]\tTotal Loss: 0.394358\n",
      "Reconstruction: 0.319136, Regularization: 0.001661, Discriminator: 0.026984; Generator: 0.046577,\n",
      "D(x): 0.723, D(G(z)): 0.228\n",
      "2019-04-10 00:56:58,255 root         INFO     Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 0.387169\n",
      "Reconstruction: 0.321092, Regularization: 0.001761, Discriminator: 0.020622; Generator: 0.043694,\n",
      "D(x): 0.800, D(G(z)): 0.249\n",
      "2019-04-10 00:56:58,367 root         INFO     Train Epoch: 54 [5632/8000 (70%)]\tTotal Loss: 0.391186\n",
      "Reconstruction: 0.323149, Regularization: 0.001468, Discriminator: 0.024097; Generator: 0.042471,\n",
      "D(x): 0.740, D(G(z)): 0.261\n",
      "2019-04-10 00:56:58,479 root         INFO     Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 0.390647\n",
      "Reconstruction: 0.323638, Regularization: 0.001306, Discriminator: 0.022121; Generator: 0.043582,\n",
      "D(x): 0.744, D(G(z)): 0.250\n",
      "2019-04-10 00:56:58,587 root         INFO     Train Epoch: 54 [6656/8000 (83%)]\tTotal Loss: 0.393612\n",
      "Reconstruction: 0.325163, Regularization: 0.001322, Discriminator: 0.025814; Generator: 0.041312,\n",
      "D(x): 0.745, D(G(z)): 0.269\n",
      "2019-04-10 00:56:58,697 root         INFO     Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 0.396226\n",
      "Reconstruction: 0.327123, Regularization: 0.001929, Discriminator: 0.024287; Generator: 0.042887,\n",
      "D(x): 0.750, D(G(z)): 0.256\n",
      "2019-04-10 00:56:58,807 root         INFO     Train Epoch: 54 [7680/8000 (96%)]\tTotal Loss: 0.412553\n",
      "Reconstruction: 0.328846, Regularization: 0.002274, Discriminator: 0.038730; Generator: 0.042704,\n",
      "D(x): 0.618, D(G(z)): 0.258\n",
      "2019-04-10 00:56:58,886 root         INFO     ====> Epoch: 54 Average loss: 0.3913\n",
      "2019-04-10 00:56:58,914 root         INFO     Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 0.393683\n",
      "Reconstruction: 0.328744, Regularization: 0.001363, Discriminator: 0.021435; Generator: 0.042140,\n",
      "D(x): 0.780, D(G(z)): 0.261\n",
      "2019-04-10 00:56:59,027 root         INFO     Train Epoch: 55 [512/8000 (6%)]\tTotal Loss: 0.405743\n",
      "Reconstruction: 0.329842, Regularization: 0.001407, Discriminator: 0.036093; Generator: 0.038402,\n",
      "D(x): 0.668, D(G(z)): 0.294\n",
      "2019-04-10 00:56:59,141 root         INFO     Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 0.404111\n",
      "Reconstruction: 0.331848, Regularization: 0.002421, Discriminator: 0.030842; Generator: 0.039000,\n",
      "D(x): 0.749, D(G(z)): 0.290\n",
      "2019-04-10 00:56:59,254 root         INFO     Train Epoch: 55 [1536/8000 (19%)]\tTotal Loss: 0.406087\n",
      "Reconstruction: 0.332273, Regularization: 0.002054, Discriminator: 0.032883; Generator: 0.038877,\n",
      "D(x): 0.693, D(G(z)): 0.290\n",
      "2019-04-10 00:56:59,366 root         INFO     Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 0.410719\n",
      "Reconstruction: 0.333208, Regularization: 0.001717, Discriminator: 0.035594; Generator: 0.040200,\n",
      "D(x): 0.656, D(G(z)): 0.278\n",
      "2019-04-10 00:56:59,478 root         INFO     Train Epoch: 55 [2560/8000 (32%)]\tTotal Loss: 0.409249\n",
      "Reconstruction: 0.334614, Regularization: 0.001486, Discriminator: 0.035580; Generator: 0.037569,\n",
      "D(x): 0.677, D(G(z)): 0.304\n",
      "2019-04-10 00:56:59,591 root         INFO     Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 0.399714\n",
      "Reconstruction: 0.334794, Regularization: 0.001879, Discriminator: 0.024253; Generator: 0.038788,\n",
      "D(x): 0.767, D(G(z)): 0.292\n",
      "2019-04-10 00:56:59,703 root         INFO     Train Epoch: 55 [3584/8000 (45%)]\tTotal Loss: 0.406810\n",
      "Reconstruction: 0.335697, Regularization: 0.001376, Discriminator: 0.031521; Generator: 0.038216,\n",
      "D(x): 0.706, D(G(z)): 0.296\n",
      "2019-04-10 00:56:59,815 root         INFO     Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 0.413375\n",
      "Reconstruction: 0.336367, Regularization: 0.002873, Discriminator: 0.037228; Generator: 0.036907,\n",
      "D(x): 0.618, D(G(z)): 0.308\n",
      "2019-04-10 00:56:59,928 root         INFO     Train Epoch: 55 [4608/8000 (58%)]\tTotal Loss: 0.409018\n",
      "Reconstruction: 0.336871, Regularization: 0.001907, Discriminator: 0.032219; Generator: 0.038021,\n",
      "D(x): 0.681, D(G(z)): 0.298\n",
      "2019-04-10 00:57:00,040 root         INFO     Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 0.399834\n",
      "Reconstruction: 0.337756, Regularization: 0.001580, Discriminator: 0.026829; Generator: 0.033670,\n",
      "D(x): 0.790, D(G(z)): 0.342\n",
      "2019-04-10 00:57:00,153 root         INFO     Train Epoch: 55 [5632/8000 (70%)]\tTotal Loss: 0.412075\n",
      "Reconstruction: 0.339551, Regularization: 0.001755, Discriminator: 0.035108; Generator: 0.035661,\n",
      "D(x): 0.652, D(G(z)): 0.321\n",
      "2019-04-10 00:57:00,265 root         INFO     Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 0.421101\n",
      "Reconstruction: 0.340518, Regularization: 0.001592, Discriminator: 0.042793; Generator: 0.036198,\n",
      "D(x): 0.554, D(G(z)): 0.316\n",
      "2019-04-10 00:57:00,377 root         INFO     Train Epoch: 55 [6656/8000 (83%)]\tTotal Loss: 0.406060\n",
      "Reconstruction: 0.340824, Regularization: 0.001363, Discriminator: 0.028563; Generator: 0.035310,\n",
      "D(x): 0.695, D(G(z)): 0.325\n",
      "2019-04-10 00:57:00,489 root         INFO     Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 0.414850\n",
      "Reconstruction: 0.342043, Regularization: 0.001647, Discriminator: 0.034849; Generator: 0.036311,\n",
      "D(x): 0.710, D(G(z)): 0.315\n",
      "2019-04-10 00:57:00,601 root         INFO     Train Epoch: 55 [7680/8000 (96%)]\tTotal Loss: 0.412549\n",
      "Reconstruction: 0.342507, Regularization: 0.001656, Discriminator: 0.034812; Generator: 0.033573,\n",
      "D(x): 0.662, D(G(z)): 0.343\n",
      "2019-04-10 00:57:00,681 root         INFO     ====> Epoch: 55 Average loss: 0.4087\n",
      "2019-04-10 00:57:00,708 root         INFO     Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 0.423266\n",
      "Reconstruction: 0.343374, Regularization: 0.001299, Discriminator: 0.043388; Generator: 0.035205,\n",
      "D(x): 0.603, D(G(z)): 0.326\n",
      "2019-04-10 00:57:00,820 root         INFO     Train Epoch: 56 [512/8000 (6%)]\tTotal Loss: 0.420923\n",
      "Reconstruction: 0.345218, Regularization: 0.001804, Discriminator: 0.041419; Generator: 0.032482,\n",
      "D(x): 0.620, D(G(z)): 0.355\n",
      "2019-04-10 00:57:00,933 root         INFO     Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 0.428107\n",
      "Reconstruction: 0.345097, Regularization: 0.001317, Discriminator: 0.047268; Generator: 0.034424,\n",
      "D(x): 0.603, D(G(z)): 0.334\n",
      "2019-04-10 00:57:01,046 root         INFO     Train Epoch: 56 [1536/8000 (19%)]\tTotal Loss: 0.421656\n",
      "Reconstruction: 0.347595, Regularization: 0.001955, Discriminator: 0.038526; Generator: 0.033580,\n",
      "D(x): 0.684, D(G(z)): 0.343\n",
      "2019-04-10 00:57:01,158 root         INFO     Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 0.420398\n",
      "Reconstruction: 0.348048, Regularization: 0.001475, Discriminator: 0.036436; Generator: 0.034439,\n",
      "D(x): 0.617, D(G(z)): 0.333\n",
      "2019-04-10 00:57:01,271 root         INFO     Train Epoch: 56 [2560/8000 (32%)]\tTotal Loss: 0.420223\n",
      "Reconstruction: 0.349696, Regularization: 0.001890, Discriminator: 0.035993; Generator: 0.032644,\n",
      "D(x): 0.706, D(G(z)): 0.353\n",
      "2019-04-10 00:57:01,384 root         INFO     Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 0.423730\n",
      "Reconstruction: 0.349668, Regularization: 0.001663, Discriminator: 0.040863; Generator: 0.031535,\n",
      "D(x): 0.566, D(G(z)): 0.365\n",
      "2019-04-10 00:57:01,496 root         INFO     Train Epoch: 56 [3584/8000 (45%)]\tTotal Loss: 0.416404\n",
      "Reconstruction: 0.350669, Regularization: 0.002073, Discriminator: 0.031755; Generator: 0.031907,\n",
      "D(x): 0.656, D(G(z)): 0.361\n",
      "2019-04-10 00:57:01,609 root         INFO     Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 0.429532\n",
      "Reconstruction: 0.352272, Regularization: 0.001662, Discriminator: 0.043373; Generator: 0.032225,\n",
      "D(x): 0.596, D(G(z)): 0.358\n",
      "2019-04-10 00:57:01,721 root         INFO     Train Epoch: 56 [4608/8000 (58%)]\tTotal Loss: 0.424773\n",
      "Reconstruction: 0.352383, Regularization: 0.001196, Discriminator: 0.039605; Generator: 0.031589,\n",
      "D(x): 0.600, D(G(z)): 0.365\n",
      "2019-04-10 00:57:01,833 root         INFO     Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 0.433983\n",
      "Reconstruction: 0.353662, Regularization: 0.001362, Discriminator: 0.046577; Generator: 0.032381,\n",
      "D(x): 0.511, D(G(z)): 0.356\n",
      "2019-04-10 00:57:01,946 root         INFO     Train Epoch: 56 [5632/8000 (70%)]\tTotal Loss: 0.431208\n",
      "Reconstruction: 0.354258, Regularization: 0.001344, Discriminator: 0.045430; Generator: 0.030176,\n",
      "D(x): 0.584, D(G(z)): 0.381\n",
      "2019-04-10 00:57:02,058 root         INFO     Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 0.423961\n",
      "Reconstruction: 0.355014, Regularization: 0.001466, Discriminator: 0.036639; Generator: 0.030842,\n",
      "D(x): 0.616, D(G(z)): 0.373\n",
      "2019-04-10 00:57:02,171 root         INFO     Train Epoch: 56 [6656/8000 (83%)]\tTotal Loss: 0.436196\n",
      "Reconstruction: 0.355973, Regularization: 0.001446, Discriminator: 0.048244; Generator: 0.030533,\n",
      "D(x): 0.530, D(G(z)): 0.377\n",
      "2019-04-10 00:57:02,282 root         INFO     Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 0.445513\n",
      "Reconstruction: 0.356802, Regularization: 0.001405, Discriminator: 0.057519; Generator: 0.029786,\n",
      "D(x): 0.528, D(G(z)): 0.387\n",
      "2019-04-10 00:57:02,394 root         INFO     Train Epoch: 56 [7680/8000 (96%)]\tTotal Loss: 0.416276\n",
      "Reconstruction: 0.357540, Regularization: 0.001477, Discriminator: 0.028924; Generator: 0.028335,\n",
      "D(x): 0.751, D(G(z)): 0.405\n",
      "2019-04-10 00:57:02,475 root         INFO     ====> Epoch: 56 Average loss: 0.4258\n",
      "2019-04-10 00:57:02,503 root         INFO     Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 0.439361\n",
      "Reconstruction: 0.357991, Regularization: 0.001267, Discriminator: 0.050603; Generator: 0.029500,\n",
      "D(x): 0.606, D(G(z)): 0.390\n",
      "2019-04-10 00:57:02,615 root         INFO     Train Epoch: 57 [512/8000 (6%)]\tTotal Loss: 0.434981\n",
      "Reconstruction: 0.358712, Regularization: 0.001897, Discriminator: 0.044991; Generator: 0.029382,\n",
      "D(x): 0.597, D(G(z)): 0.392\n",
      "2019-04-10 00:57:02,725 root         INFO     Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 0.439955\n",
      "Reconstruction: 0.359294, Regularization: 0.002179, Discriminator: 0.049943; Generator: 0.028540,\n",
      "D(x): 0.519, D(G(z)): 0.402\n",
      "2019-04-10 00:57:02,835 root         INFO     Train Epoch: 57 [1536/8000 (19%)]\tTotal Loss: 0.449588\n",
      "Reconstruction: 0.359979, Regularization: 0.001410, Discriminator: 0.060326; Generator: 0.027873,\n",
      "D(x): 0.476, D(G(z)): 0.410\n",
      "2019-04-10 00:57:02,944 root         INFO     Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 0.440447\n",
      "Reconstruction: 0.360636, Regularization: 0.001163, Discriminator: 0.049851; Generator: 0.028797,\n",
      "D(x): 0.475, D(G(z)): 0.399\n",
      "2019-04-10 00:57:03,055 root         INFO     Train Epoch: 57 [2560/8000 (32%)]\tTotal Loss: 0.431908\n",
      "Reconstruction: 0.361518, Regularization: 0.001542, Discriminator: 0.041248; Generator: 0.027600,\n",
      "D(x): 0.600, D(G(z)): 0.414\n",
      "2019-04-10 00:57:03,165 root         INFO     Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 0.438673\n",
      "Reconstruction: 0.362596, Regularization: 0.001753, Discriminator: 0.045483; Generator: 0.028841,\n",
      "D(x): 0.511, D(G(z)): 0.398\n",
      "2019-04-10 00:57:03,275 root         INFO     Train Epoch: 57 [3584/8000 (45%)]\tTotal Loss: 0.438588\n",
      "Reconstruction: 0.363309, Regularization: 0.001378, Discriminator: 0.046360; Generator: 0.027541,\n",
      "D(x): 0.566, D(G(z)): 0.415\n",
      "2019-04-10 00:57:03,384 root         INFO     Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 0.441230\n",
      "Reconstruction: 0.363969, Regularization: 0.001191, Discriminator: 0.047515; Generator: 0.028555,\n",
      "D(x): 0.555, D(G(z)): 0.401\n",
      "2019-04-10 00:57:03,494 root         INFO     Train Epoch: 57 [4608/8000 (58%)]\tTotal Loss: 0.437184\n",
      "Reconstruction: 0.364949, Regularization: 0.001617, Discriminator: 0.042410; Generator: 0.028207,\n",
      "D(x): 0.547, D(G(z)): 0.406\n",
      "2019-04-10 00:57:03,603 root         INFO     Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 0.440545\n",
      "Reconstruction: 0.365924, Regularization: 0.002104, Discriminator: 0.045453; Generator: 0.027063,\n",
      "D(x): 0.587, D(G(z)): 0.421\n",
      "2019-04-10 00:57:03,714 root         INFO     Train Epoch: 57 [5632/8000 (70%)]\tTotal Loss: 0.450892\n",
      "Reconstruction: 0.366706, Regularization: 0.001216, Discriminator: 0.056516; Generator: 0.026454,\n",
      "D(x): 0.436, D(G(z)): 0.429\n",
      "2019-04-10 00:57:03,823 root         INFO     Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 0.441835\n",
      "Reconstruction: 0.368013, Regularization: 0.001434, Discriminator: 0.045633; Generator: 0.026755,\n",
      "D(x): 0.587, D(G(z)): 0.425\n",
      "2019-04-10 00:57:03,933 root         INFO     Train Epoch: 57 [6656/8000 (83%)]\tTotal Loss: 0.447891\n",
      "Reconstruction: 0.368986, Regularization: 0.001795, Discriminator: 0.049193; Generator: 0.027918,\n",
      "D(x): 0.523, D(G(z)): 0.410\n",
      "2019-04-10 00:57:04,043 root         INFO     Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 0.440271\n",
      "Reconstruction: 0.369911, Regularization: 0.001377, Discriminator: 0.042155; Generator: 0.026828,\n",
      "D(x): 0.583, D(G(z)): 0.424\n",
      "2019-04-10 00:57:04,153 root         INFO     Train Epoch: 57 [7680/8000 (96%)]\tTotal Loss: 0.446181\n",
      "Reconstruction: 0.370569, Regularization: 0.001358, Discriminator: 0.047682; Generator: 0.026572,\n",
      "D(x): 0.536, D(G(z)): 0.428\n",
      "2019-04-10 00:57:04,233 root         INFO     ====> Epoch: 57 Average loss: 0.4407\n",
      "2019-04-10 00:57:04,260 root         INFO     Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 0.445927\n",
      "Reconstruction: 0.371128, Regularization: 0.001134, Discriminator: 0.047377; Generator: 0.026288,\n",
      "D(x): 0.536, D(G(z)): 0.432\n",
      "2019-04-10 00:57:04,370 root         INFO     Train Epoch: 58 [512/8000 (6%)]\tTotal Loss: 0.456877\n",
      "Reconstruction: 0.371756, Regularization: 0.001526, Discriminator: 0.058472; Generator: 0.025123,\n",
      "D(x): 0.440, D(G(z)): 0.448\n",
      "2019-04-10 00:57:04,480 root         INFO     Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 0.446605\n",
      "Reconstruction: 0.372698, Regularization: 0.001137, Discriminator: 0.046823; Generator: 0.025947,\n",
      "D(x): 0.537, D(G(z)): 0.436\n",
      "2019-04-10 00:57:04,589 root         INFO     Train Epoch: 58 [1536/8000 (19%)]\tTotal Loss: 0.453479\n",
      "Reconstruction: 0.373149, Regularization: 0.001253, Discriminator: 0.054847; Generator: 0.024230,\n",
      "D(x): 0.452, D(G(z)): 0.461\n",
      "2019-04-10 00:57:04,698 root         INFO     Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 0.447143\n",
      "Reconstruction: 0.373718, Regularization: 0.001511, Discriminator: 0.047133; Generator: 0.024781,\n",
      "D(x): 0.567, D(G(z)): 0.453\n",
      "2019-04-10 00:57:04,808 root         INFO     Train Epoch: 58 [2560/8000 (32%)]\tTotal Loss: 0.454535\n",
      "Reconstruction: 0.374318, Regularization: 0.001813, Discriminator: 0.052994; Generator: 0.025410,\n",
      "D(x): 0.526, D(G(z)): 0.444\n",
      "2019-04-10 00:57:04,917 root         INFO     Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 0.448912\n",
      "Reconstruction: 0.374815, Regularization: 0.001109, Discriminator: 0.048004; Generator: 0.024984,\n",
      "D(x): 0.567, D(G(z)): 0.450\n",
      "2019-04-10 00:57:05,026 root         INFO     Train Epoch: 58 [3584/8000 (45%)]\tTotal Loss: 0.447959\n",
      "Reconstruction: 0.375266, Regularization: 0.001295, Discriminator: 0.046604; Generator: 0.024793,\n",
      "D(x): 0.537, D(G(z)): 0.453\n",
      "2019-04-10 00:57:05,136 root         INFO     Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 0.448010\n",
      "Reconstruction: 0.375884, Regularization: 0.000973, Discriminator: 0.046585; Generator: 0.024568,\n",
      "D(x): 0.565, D(G(z)): 0.456\n",
      "2019-04-10 00:57:05,245 root         INFO     Train Epoch: 58 [4608/8000 (58%)]\tTotal Loss: 0.459326\n",
      "Reconstruction: 0.376447, Regularization: 0.001522, Discriminator: 0.056661; Generator: 0.024696,\n",
      "D(x): 0.449, D(G(z)): 0.454\n",
      "2019-04-10 00:57:05,354 root         INFO     Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 0.462645\n",
      "Reconstruction: 0.377052, Regularization: 0.001686, Discriminator: 0.059912; Generator: 0.023995,\n",
      "D(x): 0.420, D(G(z)): 0.464\n",
      "2019-04-10 00:57:05,463 root         INFO     Train Epoch: 58 [5632/8000 (70%)]\tTotal Loss: 0.464149\n",
      "Reconstruction: 0.377877, Regularization: 0.001745, Discriminator: 0.060594; Generator: 0.023934,\n",
      "D(x): 0.480, D(G(z)): 0.465\n",
      "2019-04-10 00:57:05,572 root         INFO     Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 0.459651\n",
      "Reconstruction: 0.378304, Regularization: 0.001448, Discriminator: 0.056350; Generator: 0.023550,\n",
      "D(x): 0.444, D(G(z)): 0.471\n",
      "2019-04-10 00:57:05,683 root         INFO     Train Epoch: 58 [6656/8000 (83%)]\tTotal Loss: 0.457928\n",
      "Reconstruction: 0.379057, Regularization: 0.001719, Discriminator: 0.053489; Generator: 0.023663,\n",
      "D(x): 0.481, D(G(z)): 0.469\n",
      "2019-04-10 00:57:05,793 root         INFO     Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 0.455885\n",
      "Reconstruction: 0.379703, Regularization: 0.001362, Discriminator: 0.050197; Generator: 0.024622,\n",
      "D(x): 0.497, D(G(z)): 0.455\n",
      "2019-04-10 00:57:05,903 root         INFO     Train Epoch: 58 [7680/8000 (96%)]\tTotal Loss: 0.460800\n",
      "Reconstruction: 0.380474, Regularization: 0.001476, Discriminator: 0.054250; Generator: 0.024600,\n",
      "D(x): 0.459, D(G(z)): 0.455\n",
      "2019-04-10 00:57:05,984 root         INFO     ====> Epoch: 58 Average loss: 0.4539\n",
      "2019-04-10 00:57:06,011 root         INFO     Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 0.456073\n",
      "Reconstruction: 0.380965, Regularization: 0.000965, Discriminator: 0.050078; Generator: 0.024065,\n",
      "D(x): 0.539, D(G(z)): 0.463\n",
      "2019-04-10 00:57:06,124 root         INFO     Train Epoch: 59 [512/8000 (6%)]\tTotal Loss: 0.459909\n",
      "Reconstruction: 0.381756, Regularization: 0.000997, Discriminator: 0.053325; Generator: 0.023831,\n",
      "D(x): 0.457, D(G(z)): 0.467\n",
      "2019-04-10 00:57:06,235 root         INFO     Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 0.466635\n",
      "Reconstruction: 0.382596, Regularization: 0.001290, Discriminator: 0.059208; Generator: 0.023540,\n",
      "D(x): 0.458, D(G(z)): 0.471\n",
      "2019-04-10 00:57:06,347 root         INFO     Train Epoch: 59 [1536/8000 (19%)]\tTotal Loss: 0.464349\n",
      "Reconstruction: 0.383358, Regularization: 0.001116, Discriminator: 0.055374; Generator: 0.024501,\n",
      "D(x): 0.464, D(G(z)): 0.457\n",
      "2019-04-10 00:57:06,458 root         INFO     Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 0.478618\n",
      "Reconstruction: 0.384013, Regularization: 0.001231, Discriminator: 0.069541; Generator: 0.023833,\n",
      "D(x): 0.321, D(G(z)): 0.467\n",
      "2019-04-10 00:57:06,570 root         INFO     Train Epoch: 59 [2560/8000 (32%)]\tTotal Loss: 0.461473\n",
      "Reconstruction: 0.384952, Regularization: 0.001280, Discriminator: 0.051686; Generator: 0.023555,\n",
      "D(x): 0.514, D(G(z)): 0.471\n",
      "2019-04-10 00:57:06,681 root         INFO     Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 0.465140\n",
      "Reconstruction: 0.385506, Regularization: 0.001166, Discriminator: 0.055519; Generator: 0.022948,\n",
      "D(x): 0.429, D(G(z)): 0.480\n",
      "2019-04-10 00:57:06,793 root         INFO     Train Epoch: 59 [3584/8000 (45%)]\tTotal Loss: 0.463341\n",
      "Reconstruction: 0.386279, Regularization: 0.001212, Discriminator: 0.052936; Generator: 0.022914,\n",
      "D(x): 0.492, D(G(z)): 0.481\n",
      "2019-04-10 00:57:06,904 root         INFO     Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 0.463203\n",
      "Reconstruction: 0.386980, Regularization: 0.001303, Discriminator: 0.052289; Generator: 0.022631,\n",
      "D(x): 0.480, D(G(z)): 0.485\n",
      "2019-04-10 00:57:07,015 root         INFO     Train Epoch: 59 [4608/8000 (58%)]\tTotal Loss: 0.474846\n",
      "Reconstruction: 0.387416, Regularization: 0.001193, Discriminator: 0.062947; Generator: 0.023290,\n",
      "D(x): 0.391, D(G(z)): 0.475\n",
      "2019-04-10 00:57:07,127 root         INFO     Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 0.468670\n",
      "Reconstruction: 0.388218, Regularization: 0.001056, Discriminator: 0.056855; Generator: 0.022541,\n",
      "D(x): 0.473, D(G(z)): 0.486\n",
      "2019-04-10 00:57:07,238 root         INFO     Train Epoch: 59 [5632/8000 (70%)]\tTotal Loss: 0.475498\n",
      "Reconstruction: 0.388667, Regularization: 0.000883, Discriminator: 0.063392; Generator: 0.022556,\n",
      "D(x): 0.371, D(G(z)): 0.486\n",
      "2019-04-10 00:57:07,349 root         INFO     Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 0.466855\n",
      "Reconstruction: 0.388961, Regularization: 0.000894, Discriminator: 0.054658; Generator: 0.022342,\n",
      "D(x): 0.450, D(G(z)): 0.489\n",
      "2019-04-10 00:57:07,461 root         INFO     Train Epoch: 59 [6656/8000 (83%)]\tTotal Loss: 0.466588\n",
      "Reconstruction: 0.389686, Regularization: 0.001088, Discriminator: 0.053384; Generator: 0.022430,\n",
      "D(x): 0.460, D(G(z)): 0.488\n",
      "2019-04-10 00:57:07,573 root         INFO     Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 0.469536\n",
      "Reconstruction: 0.390376, Regularization: 0.001252, Discriminator: 0.055942; Generator: 0.021966,\n",
      "D(x): 0.432, D(G(z)): 0.495\n",
      "2019-04-10 00:57:07,684 root         INFO     Train Epoch: 59 [7680/8000 (96%)]\tTotal Loss: 0.475795\n",
      "Reconstruction: 0.390536, Regularization: 0.001374, Discriminator: 0.061792; Generator: 0.022093,\n",
      "D(x): 0.367, D(G(z)): 0.493\n",
      "2019-04-10 00:57:07,765 root         INFO     ====> Epoch: 59 Average loss: 0.4657\n",
      "2019-04-10 00:57:07,792 root         INFO     Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 0.463687\n",
      "Reconstruction: 0.390975, Regularization: 0.001055, Discriminator: 0.049330; Generator: 0.022328,\n",
      "D(x): 0.508, D(G(z)): 0.490\n",
      "2019-04-10 00:57:07,904 root         INFO     Train Epoch: 60 [512/8000 (6%)]\tTotal Loss: 0.461822\n",
      "Reconstruction: 0.391537, Regularization: 0.001260, Discriminator: 0.046960; Generator: 0.022065,\n",
      "D(x): 0.505, D(G(z)): 0.494\n",
      "2019-04-10 00:57:08,016 root         INFO     Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 0.476901\n",
      "Reconstruction: 0.392049, Regularization: 0.001060, Discriminator: 0.061889; Generator: 0.021904,\n",
      "D(x): 0.360, D(G(z)): 0.496\n",
      "2019-04-10 00:57:08,127 root         INFO     Train Epoch: 60 [1536/8000 (19%)]\tTotal Loss: 0.462688\n",
      "Reconstruction: 0.392547, Regularization: 0.001512, Discriminator: 0.046763; Generator: 0.021866,\n",
      "D(x): 0.530, D(G(z)): 0.497\n",
      "2019-04-10 00:57:08,239 root         INFO     Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 0.467129\n",
      "Reconstruction: 0.393052, Regularization: 0.001189, Discriminator: 0.050478; Generator: 0.022410,\n",
      "D(x): 0.489, D(G(z)): 0.488\n",
      "2019-04-10 00:57:08,350 root         INFO     Train Epoch: 60 [2560/8000 (32%)]\tTotal Loss: 0.466409\n",
      "Reconstruction: 0.393563, Regularization: 0.000784, Discriminator: 0.050193; Generator: 0.021869,\n",
      "D(x): 0.477, D(G(z)): 0.497\n",
      "2019-04-10 00:57:08,462 root         INFO     Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 0.477609\n",
      "Reconstruction: 0.394320, Regularization: 0.001183, Discriminator: 0.060091; Generator: 0.022016,\n",
      "D(x): 0.401, D(G(z)): 0.494\n",
      "2019-04-10 00:57:08,573 root         INFO     Train Epoch: 60 [3584/8000 (45%)]\tTotal Loss: 0.479401\n",
      "Reconstruction: 0.394506, Regularization: 0.000807, Discriminator: 0.062152; Generator: 0.021936,\n",
      "D(x): 0.348, D(G(z)): 0.496\n",
      "2019-04-10 00:57:08,685 root         INFO     Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 0.466867\n",
      "Reconstruction: 0.395467, Regularization: 0.001074, Discriminator: 0.048704; Generator: 0.021622,\n",
      "D(x): 0.507, D(G(z)): 0.501\n",
      "2019-04-10 00:57:08,796 root         INFO     Train Epoch: 60 [4608/8000 (58%)]\tTotal Loss: 0.476846\n",
      "Reconstruction: 0.395666, Regularization: 0.001126, Discriminator: 0.058680; Generator: 0.021373,\n",
      "D(x): 0.386, D(G(z)): 0.505\n",
      "2019-04-10 00:57:08,908 root         INFO     Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 0.479181\n",
      "Reconstruction: 0.396623, Regularization: 0.001237, Discriminator: 0.059906; Generator: 0.021414,\n",
      "D(x): 0.390, D(G(z)): 0.504\n",
      "2019-04-10 00:57:09,019 root         INFO     Train Epoch: 60 [5632/8000 (70%)]\tTotal Loss: 0.475812\n",
      "Reconstruction: 0.397120, Regularization: 0.001489, Discriminator: 0.055462; Generator: 0.021741,\n",
      "D(x): 0.434, D(G(z)): 0.499\n",
      "2019-04-10 00:57:09,131 root         INFO     Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 0.479046\n",
      "Reconstruction: 0.397734, Regularization: 0.001039, Discriminator: 0.058743; Generator: 0.021531,\n",
      "D(x): 0.384, D(G(z)): 0.502\n",
      "2019-04-10 00:57:09,242 root         INFO     Train Epoch: 60 [6656/8000 (83%)]\tTotal Loss: 0.477001\n",
      "Reconstruction: 0.398417, Regularization: 0.001226, Discriminator: 0.055730; Generator: 0.021629,\n",
      "D(x): 0.416, D(G(z)): 0.501\n",
      "2019-04-10 00:57:09,353 root         INFO     Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 0.482824\n",
      "Reconstruction: 0.399070, Regularization: 0.001046, Discriminator: 0.061166; Generator: 0.021541,\n",
      "D(x): 0.379, D(G(z)): 0.502\n",
      "2019-04-10 00:57:09,465 root         INFO     Train Epoch: 60 [7680/8000 (96%)]\tTotal Loss: 0.478341\n",
      "Reconstruction: 0.399687, Regularization: 0.001489, Discriminator: 0.055494; Generator: 0.021670,\n",
      "D(x): 0.420, D(G(z)): 0.500\n",
      "2019-04-10 00:57:09,548 root         INFO     ====> Epoch: 60 Average loss: 0.4751\n",
      "2019-04-10 00:57:09,576 root         INFO     Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 0.479760\n",
      "Reconstruction: 0.400286, Regularization: 0.001206, Discriminator: 0.056759; Generator: 0.021509,\n",
      "D(x): 0.401, D(G(z)): 0.502\n",
      "2019-04-10 00:57:09,687 root         INFO     Train Epoch: 61 [512/8000 (6%)]\tTotal Loss: 0.481349\n",
      "Reconstruction: 0.400803, Regularization: 0.001193, Discriminator: 0.058188; Generator: 0.021165,\n",
      "D(x): 0.418, D(G(z)): 0.508\n",
      "2019-04-10 00:57:09,799 root         INFO     Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 0.496098\n",
      "Reconstruction: 0.401353, Regularization: 0.001217, Discriminator: 0.071705; Generator: 0.021823,\n",
      "D(x): 0.277, D(G(z)): 0.497\n",
      "2019-04-10 00:57:09,911 root         INFO     Train Epoch: 61 [1536/8000 (19%)]\tTotal Loss: 0.485465\n",
      "Reconstruction: 0.401828, Regularization: 0.000813, Discriminator: 0.061254; Generator: 0.021570,\n",
      "D(x): 0.361, D(G(z)): 0.502\n",
      "2019-04-10 00:57:10,023 root         INFO     Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 0.487406\n",
      "Reconstruction: 0.402673, Regularization: 0.001094, Discriminator: 0.062462; Generator: 0.021176,\n",
      "D(x): 0.351, D(G(z)): 0.508\n",
      "2019-04-10 00:57:10,134 root         INFO     Train Epoch: 61 [2560/8000 (32%)]\tTotal Loss: 0.481890\n",
      "Reconstruction: 0.403050, Regularization: 0.000837, Discriminator: 0.056772; Generator: 0.021231,\n",
      "D(x): 0.396, D(G(z)): 0.507\n",
      "2019-04-10 00:57:10,245 root         INFO     Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 0.483186\n",
      "Reconstruction: 0.403796, Regularization: 0.000913, Discriminator: 0.057321; Generator: 0.021156,\n",
      "D(x): 0.418, D(G(z)): 0.508\n",
      "2019-04-10 00:57:10,353 root         INFO     Train Epoch: 61 [3584/8000 (45%)]\tTotal Loss: 0.485698\n",
      "Reconstruction: 0.404379, Regularization: 0.001090, Discriminator: 0.059117; Generator: 0.021111,\n",
      "D(x): 0.395, D(G(z)): 0.509\n",
      "2019-04-10 00:57:10,461 root         INFO     Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 0.480977\n",
      "Reconstruction: 0.404740, Regularization: 0.000894, Discriminator: 0.054149; Generator: 0.021194,\n",
      "D(x): 0.425, D(G(z)): 0.508\n",
      "2019-04-10 00:57:10,570 root         INFO     Train Epoch: 61 [4608/8000 (58%)]\tTotal Loss: 0.488367\n",
      "Reconstruction: 0.405223, Regularization: 0.001022, Discriminator: 0.060956; Generator: 0.021166,\n",
      "D(x): 0.380, D(G(z)): 0.508\n",
      "2019-04-10 00:57:10,678 root         INFO     Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 0.482841\n",
      "Reconstruction: 0.405754, Regularization: 0.001223, Discriminator: 0.055032; Generator: 0.020832,\n",
      "D(x): 0.412, D(G(z)): 0.513\n",
      "2019-04-10 00:57:10,786 root         INFO     Train Epoch: 61 [5632/8000 (70%)]\tTotal Loss: 0.485560\n",
      "Reconstruction: 0.406286, Regularization: 0.001169, Discriminator: 0.057099; Generator: 0.021006,\n",
      "D(x): 0.398, D(G(z)): 0.511\n",
      "2019-04-10 00:57:10,895 root         INFO     Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 0.487829\n",
      "Reconstruction: 0.406364, Regularization: 0.000954, Discriminator: 0.059411; Generator: 0.021100,\n",
      "D(x): 0.357, D(G(z)): 0.509\n",
      "2019-04-10 00:57:11,004 root         INFO     Train Epoch: 61 [6656/8000 (83%)]\tTotal Loss: 0.485305\n",
      "Reconstruction: 0.407163, Regularization: 0.000761, Discriminator: 0.056499; Generator: 0.020882,\n",
      "D(x): 0.410, D(G(z)): 0.513\n",
      "2019-04-10 00:57:11,112 root         INFO     Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 0.489854\n",
      "Reconstruction: 0.407416, Regularization: 0.000743, Discriminator: 0.060890; Generator: 0.020805,\n",
      "D(x): 0.358, D(G(z)): 0.514\n",
      "2019-04-10 00:57:11,221 root         INFO     Train Epoch: 61 [7680/8000 (96%)]\tTotal Loss: 0.482563\n",
      "Reconstruction: 0.407880, Regularization: 0.001172, Discriminator: 0.052653; Generator: 0.020858,\n",
      "D(x): 0.426, D(G(z)): 0.513\n",
      "2019-04-10 00:57:11,300 root         INFO     ====> Epoch: 61 Average loss: 0.4846\n",
      "2019-04-10 00:57:11,327 root         INFO     Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 0.489193\n",
      "Reconstruction: 0.408415, Regularization: 0.000550, Discriminator: 0.059167; Generator: 0.021060,\n",
      "D(x): 0.380, D(G(z)): 0.510\n",
      "2019-04-10 00:57:11,437 root         INFO     Train Epoch: 62 [512/8000 (6%)]\tTotal Loss: 0.492682\n",
      "Reconstruction: 0.408657, Regularization: 0.000762, Discriminator: 0.062391; Generator: 0.020873,\n",
      "D(x): 0.338, D(G(z)): 0.513\n",
      "2019-04-10 00:57:11,547 root         INFO     Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 0.493539\n",
      "Reconstruction: 0.409464, Regularization: 0.000898, Discriminator: 0.062560; Generator: 0.020616,\n",
      "D(x): 0.335, D(G(z)): 0.517\n",
      "2019-04-10 00:57:11,656 root         INFO     Train Epoch: 62 [1536/8000 (19%)]\tTotal Loss: 0.492751\n",
      "Reconstruction: 0.409637, Regularization: 0.001206, Discriminator: 0.060885; Generator: 0.021023,\n",
      "D(x): 0.383, D(G(z)): 0.510\n",
      "2019-04-10 00:57:11,765 root         INFO     Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 0.491657\n",
      "Reconstruction: 0.410337, Regularization: 0.000899, Discriminator: 0.059426; Generator: 0.020995,\n",
      "D(x): 0.358, D(G(z)): 0.511\n",
      "2019-04-10 00:57:11,874 root         INFO     Train Epoch: 62 [2560/8000 (32%)]\tTotal Loss: 0.487041\n",
      "Reconstruction: 0.410889, Regularization: 0.000909, Discriminator: 0.054399; Generator: 0.020844,\n",
      "D(x): 0.427, D(G(z)): 0.513\n",
      "2019-04-10 00:57:11,984 root         INFO     Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 0.489507\n",
      "Reconstruction: 0.411361, Regularization: 0.000637, Discriminator: 0.056493; Generator: 0.021016,\n",
      "D(x): 0.416, D(G(z)): 0.510\n",
      "2019-04-10 00:57:12,093 root         INFO     Train Epoch: 62 [3584/8000 (45%)]\tTotal Loss: 0.487954\n",
      "Reconstruction: 0.411892, Regularization: 0.000994, Discriminator: 0.054020; Generator: 0.021048,\n",
      "D(x): 0.391, D(G(z)): 0.510\n",
      "2019-04-10 00:57:12,202 root         INFO     Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 0.490399\n",
      "Reconstruction: 0.412819, Regularization: 0.000957, Discriminator: 0.055463; Generator: 0.021160,\n",
      "D(x): 0.400, D(G(z)): 0.508\n",
      "2019-04-10 00:57:12,312 root         INFO     Train Epoch: 62 [4608/8000 (58%)]\tTotal Loss: 0.496131\n",
      "Reconstruction: 0.413364, Regularization: 0.000636, Discriminator: 0.061067; Generator: 0.021064,\n",
      "D(x): 0.372, D(G(z)): 0.510\n",
      "2019-04-10 00:57:12,421 root         INFO     Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 0.496303\n",
      "Reconstruction: 0.413465, Regularization: 0.001026, Discriminator: 0.060743; Generator: 0.021069,\n",
      "D(x): 0.344, D(G(z)): 0.510\n",
      "2019-04-10 00:57:12,531 root         INFO     Train Epoch: 62 [5632/8000 (70%)]\tTotal Loss: 0.497265\n",
      "Reconstruction: 0.414399, Regularization: 0.001261, Discriminator: 0.060762; Generator: 0.020843,\n",
      "D(x): 0.346, D(G(z)): 0.513\n",
      "2019-04-10 00:57:12,640 root         INFO     Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 0.494703\n",
      "Reconstruction: 0.414707, Regularization: 0.000824, Discriminator: 0.058109; Generator: 0.021062,\n",
      "D(x): 0.367, D(G(z)): 0.510\n",
      "2019-04-10 00:57:12,750 root         INFO     Train Epoch: 62 [6656/8000 (83%)]\tTotal Loss: 0.495850\n",
      "Reconstruction: 0.415200, Regularization: 0.001096, Discriminator: 0.058866; Generator: 0.020688,\n",
      "D(x): 0.398, D(G(z)): 0.516\n",
      "2019-04-10 00:57:12,859 root         INFO     Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 0.492097\n",
      "Reconstruction: 0.415499, Regularization: 0.000701, Discriminator: 0.055005; Generator: 0.020893,\n",
      "D(x): 0.398, D(G(z)): 0.512\n",
      "2019-04-10 00:57:12,968 root         INFO     Train Epoch: 62 [7680/8000 (96%)]\tTotal Loss: 0.497075\n",
      "Reconstruction: 0.416067, Regularization: 0.000667, Discriminator: 0.059164; Generator: 0.021177,\n",
      "D(x): 0.338, D(G(z)): 0.508\n",
      "2019-04-10 00:57:13,047 root         INFO     ====> Epoch: 62 Average loss: 0.4926\n",
      "2019-04-10 00:57:13,074 root         INFO     Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 0.496226\n",
      "Reconstruction: 0.416235, Regularization: 0.000703, Discriminator: 0.058190; Generator: 0.021096,\n",
      "D(x): 0.373, D(G(z)): 0.509\n",
      "2019-04-10 00:57:13,182 root         INFO     Train Epoch: 63 [512/8000 (6%)]\tTotal Loss: 0.495026\n",
      "Reconstruction: 0.416870, Regularization: 0.000927, Discriminator: 0.056344; Generator: 0.020886,\n",
      "D(x): 0.380, D(G(z)): 0.513\n",
      "2019-04-10 00:57:13,289 root         INFO     Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 0.496711\n",
      "Reconstruction: 0.417429, Regularization: 0.000897, Discriminator: 0.057405; Generator: 0.020980,\n",
      "D(x): 0.360, D(G(z)): 0.511\n",
      "2019-04-10 00:57:13,396 root         INFO     Train Epoch: 63 [1536/8000 (19%)]\tTotal Loss: 0.490066\n",
      "Reconstruction: 0.417495, Regularization: 0.000693, Discriminator: 0.050966; Generator: 0.020912,\n",
      "D(x): 0.436, D(G(z)): 0.512\n",
      "2019-04-10 00:57:13,503 root         INFO     Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 0.495458\n",
      "Reconstruction: 0.418247, Regularization: 0.000749, Discriminator: 0.055702; Generator: 0.020760,\n",
      "D(x): 0.384, D(G(z)): 0.515\n",
      "2019-04-10 00:57:13,610 root         INFO     Train Epoch: 63 [2560/8000 (32%)]\tTotal Loss: 0.499016\n",
      "Reconstruction: 0.418888, Regularization: 0.000716, Discriminator: 0.058518; Generator: 0.020894,\n",
      "D(x): 0.354, D(G(z)): 0.512\n",
      "2019-04-10 00:57:13,717 root         INFO     Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 0.494876\n",
      "Reconstruction: 0.419155, Regularization: 0.000775, Discriminator: 0.054328; Generator: 0.020618,\n",
      "D(x): 0.407, D(G(z)): 0.517\n",
      "2019-04-10 00:57:13,826 root         INFO     Train Epoch: 63 [3584/8000 (45%)]\tTotal Loss: 0.498521\n",
      "Reconstruction: 0.419664, Regularization: 0.000995, Discriminator: 0.056906; Generator: 0.020955,\n",
      "D(x): 0.359, D(G(z)): 0.511\n",
      "2019-04-10 00:57:13,937 root         INFO     Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 0.500294\n",
      "Reconstruction: 0.419979, Regularization: 0.000903, Discriminator: 0.058745; Generator: 0.020667,\n",
      "D(x): 0.359, D(G(z)): 0.516\n",
      "2019-04-10 00:57:14,047 root         INFO     Train Epoch: 63 [4608/8000 (58%)]\tTotal Loss: 0.501516\n",
      "Reconstruction: 0.420542, Regularization: 0.000968, Discriminator: 0.059005; Generator: 0.021001,\n",
      "D(x): 0.342, D(G(z)): 0.511\n",
      "2019-04-10 00:57:14,160 root         INFO     Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 0.492190\n",
      "Reconstruction: 0.420913, Regularization: 0.000526, Discriminator: 0.049921; Generator: 0.020830,\n",
      "D(x): 0.438, D(G(z)): 0.513\n",
      "2019-04-10 00:57:14,271 root         INFO     Train Epoch: 63 [5632/8000 (70%)]\tTotal Loss: 0.504550\n",
      "Reconstruction: 0.421300, Regularization: 0.000896, Discriminator: 0.061559; Generator: 0.020795,\n",
      "D(x): 0.320, D(G(z)): 0.514\n",
      "2019-04-10 00:57:14,383 root         INFO     Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 0.503685\n",
      "Reconstruction: 0.421970, Regularization: 0.000934, Discriminator: 0.059836; Generator: 0.020945,\n",
      "D(x): 0.350, D(G(z)): 0.512\n",
      "2019-04-10 00:57:14,494 root         INFO     Train Epoch: 63 [6656/8000 (83%)]\tTotal Loss: 0.503548\n",
      "Reconstruction: 0.422210, Regularization: 0.000730, Discriminator: 0.059520; Generator: 0.021088,\n",
      "D(x): 0.335, D(G(z)): 0.509\n",
      "2019-04-10 00:57:14,605 root         INFO     Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 0.502667\n",
      "Reconstruction: 0.422821, Regularization: 0.000851, Discriminator: 0.057830; Generator: 0.021165,\n",
      "D(x): 0.353, D(G(z)): 0.508\n",
      "2019-04-10 00:57:14,717 root         INFO     Train Epoch: 63 [7680/8000 (96%)]\tTotal Loss: 0.504428\n",
      "Reconstruction: 0.423683, Regularization: 0.001475, Discriminator: 0.058110; Generator: 0.021160,\n",
      "D(x): 0.349, D(G(z)): 0.508\n",
      "2019-04-10 00:57:14,798 root         INFO     ====> Epoch: 63 Average loss: 0.4999\n",
      "2019-04-10 00:57:14,826 root         INFO     Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 0.497561\n",
      "Reconstruction: 0.423719, Regularization: 0.000613, Discriminator: 0.052166; Generator: 0.021064,\n",
      "D(x): 0.409, D(G(z)): 0.510\n",
      "2019-04-10 00:57:14,937 root         INFO     Train Epoch: 64 [512/8000 (6%)]\tTotal Loss: 0.506447\n",
      "Reconstruction: 0.424673, Regularization: 0.000889, Discriminator: 0.059814; Generator: 0.021071,\n",
      "D(x): 0.336, D(G(z)): 0.510\n",
      "2019-04-10 00:57:15,047 root         INFO     Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 0.502559\n",
      "Reconstruction: 0.424911, Regularization: 0.000654, Discriminator: 0.055668; Generator: 0.021326,\n",
      "D(x): 0.373, D(G(z)): 0.505\n",
      "2019-04-10 00:57:15,157 root         INFO     Train Epoch: 64 [1536/8000 (19%)]\tTotal Loss: 0.504886\n",
      "Reconstruction: 0.425718, Regularization: 0.000843, Discriminator: 0.057058; Generator: 0.021267,\n",
      "D(x): 0.367, D(G(z)): 0.506\n",
      "2019-04-10 00:57:15,267 root         INFO     Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 0.503260\n",
      "Reconstruction: 0.426136, Regularization: 0.001169, Discriminator: 0.054820; Generator: 0.021135,\n",
      "D(x): 0.384, D(G(z)): 0.508\n",
      "2019-04-10 00:57:15,377 root         INFO     Train Epoch: 64 [2560/8000 (32%)]\tTotal Loss: 0.508751\n",
      "Reconstruction: 0.426592, Regularization: 0.000849, Discriminator: 0.060087; Generator: 0.021224,\n",
      "D(x): 0.326, D(G(z)): 0.507\n",
      "2019-04-10 00:57:15,487 root         INFO     Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 0.510058\n",
      "Reconstruction: 0.427153, Regularization: 0.000675, Discriminator: 0.060932; Generator: 0.021297,\n",
      "D(x): 0.308, D(G(z)): 0.506\n",
      "2019-04-10 00:57:15,597 root         INFO     Train Epoch: 64 [3584/8000 (45%)]\tTotal Loss: 0.509826\n",
      "Reconstruction: 0.427426, Regularization: 0.001173, Discriminator: 0.059880; Generator: 0.021347,\n",
      "D(x): 0.336, D(G(z)): 0.505\n",
      "2019-04-10 00:57:15,708 root         INFO     Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 0.504422\n",
      "Reconstruction: 0.427985, Regularization: 0.000606, Discriminator: 0.054591; Generator: 0.021241,\n",
      "D(x): 0.376, D(G(z)): 0.507\n",
      "2019-04-10 00:57:15,817 root         INFO     Train Epoch: 64 [4608/8000 (58%)]\tTotal Loss: 0.508176\n",
      "Reconstruction: 0.428372, Regularization: 0.000497, Discriminator: 0.058138; Generator: 0.021170,\n",
      "D(x): 0.338, D(G(z)): 0.508\n",
      "2019-04-10 00:57:15,927 root         INFO     Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 0.508234\n",
      "Reconstruction: 0.428959, Regularization: 0.000769, Discriminator: 0.057384; Generator: 0.021123,\n",
      "D(x): 0.348, D(G(z)): 0.509\n",
      "2019-04-10 00:57:16,037 root         INFO     Train Epoch: 64 [5632/8000 (70%)]\tTotal Loss: 0.509542\n",
      "Reconstruction: 0.429796, Regularization: 0.000885, Discriminator: 0.057662; Generator: 0.021199,\n",
      "D(x): 0.354, D(G(z)): 0.507\n",
      "2019-04-10 00:57:16,147 root         INFO     Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 0.513777\n",
      "Reconstruction: 0.429932, Regularization: 0.000749, Discriminator: 0.061764; Generator: 0.021333,\n",
      "D(x): 0.311, D(G(z)): 0.505\n",
      "2019-04-10 00:57:16,258 root         INFO     Train Epoch: 64 [6656/8000 (83%)]\tTotal Loss: 0.505062\n",
      "Reconstruction: 0.430282, Regularization: 0.000595, Discriminator: 0.052904; Generator: 0.021281,\n",
      "D(x): 0.392, D(G(z)): 0.506\n",
      "2019-04-10 00:57:16,368 root         INFO     Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 0.508229\n",
      "Reconstruction: 0.430811, Regularization: 0.000499, Discriminator: 0.055571; Generator: 0.021348,\n",
      "D(x): 0.355, D(G(z)): 0.505\n",
      "2019-04-10 00:57:16,477 root         INFO     Train Epoch: 64 [7680/8000 (96%)]\tTotal Loss: 0.508561\n",
      "Reconstruction: 0.431096, Regularization: 0.000615, Discriminator: 0.055545; Generator: 0.021304,\n",
      "D(x): 0.361, D(G(z)): 0.506\n",
      "2019-04-10 00:57:16,558 root         INFO     ====> Epoch: 64 Average loss: 0.5076\n",
      "2019-04-10 00:57:16,585 root         INFO     Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 0.513764\n",
      "Reconstruction: 0.431365, Regularization: 0.000641, Discriminator: 0.060376; Generator: 0.021382,\n",
      "D(x): 0.322, D(G(z)): 0.505\n",
      "2019-04-10 00:57:16,697 root         INFO     Train Epoch: 65 [512/8000 (6%)]\tTotal Loss: 0.508306\n",
      "Reconstruction: 0.431690, Regularization: 0.000626, Discriminator: 0.054542; Generator: 0.021448,\n",
      "D(x): 0.370, D(G(z)): 0.503\n",
      "2019-04-10 00:57:16,808 root         INFO     Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 0.511155\n",
      "Reconstruction: 0.431998, Regularization: 0.000537, Discriminator: 0.057259; Generator: 0.021360,\n",
      "D(x): 0.348, D(G(z)): 0.505\n",
      "2019-04-10 00:57:16,918 root         INFO     Train Epoch: 65 [1536/8000 (19%)]\tTotal Loss: 0.509271\n",
      "Reconstruction: 0.432230, Regularization: 0.000545, Discriminator: 0.055019; Generator: 0.021477,\n",
      "D(x): 0.360, D(G(z)): 0.503\n",
      "2019-04-10 00:57:17,028 root         INFO     Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 0.510832\n",
      "Reconstruction: 0.432740, Regularization: 0.000536, Discriminator: 0.056108; Generator: 0.021448,\n",
      "D(x): 0.363, D(G(z)): 0.503\n",
      "2019-04-10 00:57:17,138 root         INFO     Train Epoch: 65 [2560/8000 (32%)]\tTotal Loss: 0.513664\n",
      "Reconstruction: 0.433289, Regularization: 0.000519, Discriminator: 0.058397; Generator: 0.021459,\n",
      "D(x): 0.328, D(G(z)): 0.503\n",
      "2019-04-10 00:57:17,248 root         INFO     Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 0.515718\n",
      "Reconstruction: 0.433462, Regularization: 0.000662, Discriminator: 0.060139; Generator: 0.021456,\n",
      "D(x): 0.326, D(G(z)): 0.503\n",
      "2019-04-10 00:57:17,359 root         INFO     Train Epoch: 65 [3584/8000 (45%)]\tTotal Loss: 0.508574\n",
      "Reconstruction: 0.434160, Regularization: 0.000478, Discriminator: 0.052374; Generator: 0.021561,\n",
      "D(x): 0.401, D(G(z)): 0.502\n",
      "2019-04-10 00:57:17,469 root         INFO     Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 0.513940\n",
      "Reconstruction: 0.434458, Regularization: 0.000640, Discriminator: 0.057251; Generator: 0.021591,\n",
      "D(x): 0.341, D(G(z)): 0.501\n",
      "2019-04-10 00:57:17,580 root         INFO     Train Epoch: 65 [4608/8000 (58%)]\tTotal Loss: 0.513077\n",
      "Reconstruction: 0.434757, Regularization: 0.000612, Discriminator: 0.056193; Generator: 0.021515,\n",
      "D(x): 0.360, D(G(z)): 0.502\n",
      "2019-04-10 00:57:17,691 root         INFO     Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 0.512972\n",
      "Reconstruction: 0.435189, Regularization: 0.000645, Discriminator: 0.055405; Generator: 0.021733,\n",
      "D(x): 0.361, D(G(z)): 0.499\n",
      "2019-04-10 00:57:17,802 root         INFO     Train Epoch: 65 [5632/8000 (70%)]\tTotal Loss: 0.513011\n",
      "Reconstruction: 0.435644, Regularization: 0.000624, Discriminator: 0.055096; Generator: 0.021647,\n",
      "D(x): 0.363, D(G(z)): 0.500\n",
      "2019-04-10 00:57:17,914 root         INFO     Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 0.519309\n",
      "Reconstruction: 0.436186, Regularization: 0.000923, Discriminator: 0.060641; Generator: 0.021558,\n",
      "D(x): 0.305, D(G(z)): 0.502\n",
      "2019-04-10 00:57:18,026 root         INFO     Train Epoch: 65 [6656/8000 (83%)]\tTotal Loss: 0.516198\n",
      "Reconstruction: 0.436720, Regularization: 0.000720, Discriminator: 0.057022; Generator: 0.021736,\n",
      "D(x): 0.339, D(G(z)): 0.499\n",
      "2019-04-10 00:57:18,138 root         INFO     Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 0.515703\n",
      "Reconstruction: 0.437151, Regularization: 0.000623, Discriminator: 0.056104; Generator: 0.021825,\n",
      "D(x): 0.356, D(G(z)): 0.497\n",
      "2019-04-10 00:57:18,250 root         INFO     Train Epoch: 65 [7680/8000 (96%)]\tTotal Loss: 0.518492\n",
      "Reconstruction: 0.437738, Regularization: 0.000549, Discriminator: 0.058400; Generator: 0.021805,\n",
      "D(x): 0.327, D(G(z)): 0.498\n",
      "2019-04-10 00:57:18,333 root         INFO     ====> Epoch: 65 Average loss: 0.5138\n",
      "2019-04-10 00:57:18,360 root         INFO     Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 0.517500\n",
      "Reconstruction: 0.438070, Regularization: 0.000643, Discriminator: 0.056927; Generator: 0.021861,\n",
      "D(x): 0.342, D(G(z)): 0.497\n",
      "2019-04-10 00:57:18,472 root         INFO     Train Epoch: 66 [512/8000 (6%)]\tTotal Loss: 0.516420\n",
      "Reconstruction: 0.438442, Regularization: 0.000590, Discriminator: 0.055463; Generator: 0.021924,\n",
      "D(x): 0.359, D(G(z)): 0.496\n",
      "2019-04-10 00:57:18,584 root         INFO     Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 0.521152\n",
      "Reconstruction: 0.439001, Regularization: 0.000754, Discriminator: 0.059466; Generator: 0.021931,\n",
      "D(x): 0.320, D(G(z)): 0.496\n",
      "2019-04-10 00:57:18,695 root         INFO     Train Epoch: 66 [1536/8000 (19%)]\tTotal Loss: 0.519072\n",
      "Reconstruction: 0.439714, Regularization: 0.000683, Discriminator: 0.056722; Generator: 0.021953,\n",
      "D(x): 0.340, D(G(z)): 0.495\n",
      "2019-04-10 00:57:18,806 root         INFO     Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 0.518883\n",
      "Reconstruction: 0.440121, Regularization: 0.000614, Discriminator: 0.056236; Generator: 0.021912,\n",
      "D(x): 0.345, D(G(z)): 0.496\n",
      "2019-04-10 00:57:18,917 root         INFO     Train Epoch: 66 [2560/8000 (32%)]\tTotal Loss: 0.516825\n",
      "Reconstruction: 0.440588, Regularization: 0.000439, Discriminator: 0.053889; Generator: 0.021909,\n",
      "D(x): 0.369, D(G(z)): 0.496\n",
      "2019-04-10 00:57:19,028 root         INFO     Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 0.520601\n",
      "Reconstruction: 0.441010, Regularization: 0.000530, Discriminator: 0.057020; Generator: 0.022041,\n",
      "D(x): 0.332, D(G(z)): 0.494\n",
      "2019-04-10 00:57:19,139 root         INFO     Train Epoch: 66 [3584/8000 (45%)]\tTotal Loss: 0.517776\n",
      "Reconstruction: 0.441505, Regularization: 0.000625, Discriminator: 0.053591; Generator: 0.022056,\n",
      "D(x): 0.372, D(G(z)): 0.494\n",
      "2019-04-10 00:57:19,249 root         INFO     Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 0.523689\n",
      "Reconstruction: 0.442185, Regularization: 0.000478, Discriminator: 0.058858; Generator: 0.022168,\n",
      "D(x): 0.320, D(G(z)): 0.492\n",
      "2019-04-10 00:57:19,359 root         INFO     Train Epoch: 66 [4608/8000 (58%)]\tTotal Loss: 0.523590\n",
      "Reconstruction: 0.442766, Regularization: 0.000549, Discriminator: 0.058041; Generator: 0.022234,\n",
      "D(x): 0.338, D(G(z)): 0.491\n",
      "2019-04-10 00:57:19,468 root         INFO     Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 0.521946\n",
      "Reconstruction: 0.442960, Regularization: 0.000726, Discriminator: 0.055979; Generator: 0.022282,\n",
      "D(x): 0.340, D(G(z)): 0.490\n",
      "2019-04-10 00:57:19,577 root         INFO     Train Epoch: 66 [5632/8000 (70%)]\tTotal Loss: 0.521727\n",
      "Reconstruction: 0.443330, Regularization: 0.000407, Discriminator: 0.055736; Generator: 0.022254,\n",
      "D(x): 0.349, D(G(z)): 0.491\n",
      "2019-04-10 00:57:19,686 root         INFO     Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 0.521974\n",
      "Reconstruction: 0.443720, Regularization: 0.000667, Discriminator: 0.055235; Generator: 0.022352,\n",
      "D(x): 0.348, D(G(z)): 0.489\n",
      "2019-04-10 00:57:19,796 root         INFO     Train Epoch: 66 [6656/8000 (83%)]\tTotal Loss: 0.524128\n",
      "Reconstruction: 0.444314, Regularization: 0.000600, Discriminator: 0.056922; Generator: 0.022291,\n",
      "D(x): 0.328, D(G(z)): 0.490\n",
      "2019-04-10 00:57:19,905 root         INFO     Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 0.526610\n",
      "Reconstruction: 0.444794, Regularization: 0.000590, Discriminator: 0.058935; Generator: 0.022291,\n",
      "D(x): 0.313, D(G(z)): 0.490\n",
      "2019-04-10 00:57:20,014 root         INFO     Train Epoch: 66 [7680/8000 (96%)]\tTotal Loss: 0.524352\n",
      "Reconstruction: 0.445083, Regularization: 0.000449, Discriminator: 0.056437; Generator: 0.022384,\n",
      "D(x): 0.334, D(G(z)): 0.489\n",
      "2019-04-10 00:57:20,095 root         INFO     ====> Epoch: 66 Average loss: 0.5210\n",
      "2019-04-10 00:57:20,122 root         INFO     Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 0.523175\n",
      "Reconstruction: 0.445377, Regularization: 0.000446, Discriminator: 0.054952; Generator: 0.022401,\n",
      "D(x): 0.351, D(G(z)): 0.488\n",
      "2019-04-10 00:57:20,235 root         INFO     Train Epoch: 67 [512/8000 (6%)]\tTotal Loss: 0.526394\n",
      "Reconstruction: 0.445773, Regularization: 0.000662, Discriminator: 0.057521; Generator: 0.022438,\n",
      "D(x): 0.320, D(G(z)): 0.488\n",
      "2019-04-10 00:57:20,343 root         INFO     Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 0.523351\n",
      "Reconstruction: 0.446048, Regularization: 0.000563, Discriminator: 0.054261; Generator: 0.022479,\n",
      "D(x): 0.354, D(G(z)): 0.487\n",
      "2019-04-10 00:57:20,451 root         INFO     Train Epoch: 67 [1536/8000 (19%)]\tTotal Loss: 0.527815\n",
      "Reconstruction: 0.446574, Regularization: 0.000558, Discriminator: 0.058240; Generator: 0.022443,\n",
      "D(x): 0.318, D(G(z)): 0.488\n",
      "2019-04-10 00:57:20,560 root         INFO     Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 0.524515\n",
      "Reconstruction: 0.446984, Regularization: 0.000524, Discriminator: 0.054346; Generator: 0.022662,\n",
      "D(x): 0.351, D(G(z)): 0.484\n",
      "2019-04-10 00:57:20,671 root         INFO     Train Epoch: 67 [2560/8000 (32%)]\tTotal Loss: 0.524948\n",
      "Reconstruction: 0.447351, Regularization: 0.000539, Discriminator: 0.054501; Generator: 0.022557,\n",
      "D(x): 0.354, D(G(z)): 0.486\n",
      "2019-04-10 00:57:20,781 root         INFO     Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 0.525804\n",
      "Reconstruction: 0.447686, Regularization: 0.000510, Discriminator: 0.054900; Generator: 0.022708,\n",
      "D(x): 0.344, D(G(z)): 0.484\n",
      "2019-04-10 00:57:20,890 root         INFO     Train Epoch: 67 [3584/8000 (45%)]\tTotal Loss: 0.527538\n",
      "Reconstruction: 0.448044, Regularization: 0.000597, Discriminator: 0.056217; Generator: 0.022680,\n",
      "D(x): 0.337, D(G(z)): 0.484\n",
      "2019-04-10 00:57:20,999 root         INFO     Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 0.527517\n",
      "Reconstruction: 0.448446, Regularization: 0.000699, Discriminator: 0.055634; Generator: 0.022738,\n",
      "D(x): 0.341, D(G(z)): 0.483\n",
      "2019-04-10 00:57:21,106 root         INFO     Train Epoch: 67 [4608/8000 (58%)]\tTotal Loss: 0.526423\n",
      "Reconstruction: 0.448763, Regularization: 0.000476, Discriminator: 0.054366; Generator: 0.022817,\n",
      "D(x): 0.348, D(G(z)): 0.482\n",
      "2019-04-10 00:57:21,213 root         INFO     Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 0.529139\n",
      "Reconstruction: 0.449143, Regularization: 0.000520, Discriminator: 0.056561; Generator: 0.022915,\n",
      "D(x): 0.331, D(G(z)): 0.480\n",
      "2019-04-10 00:57:21,321 root         INFO     Train Epoch: 67 [5632/8000 (70%)]\tTotal Loss: 0.529180\n",
      "Reconstruction: 0.449525, Regularization: 0.000485, Discriminator: 0.056223; Generator: 0.022948,\n",
      "D(x): 0.328, D(G(z)): 0.480\n",
      "2019-04-10 00:57:21,430 root         INFO     Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 0.529521\n",
      "Reconstruction: 0.449848, Regularization: 0.000662, Discriminator: 0.056108; Generator: 0.022903,\n",
      "D(x): 0.327, D(G(z)): 0.481\n",
      "2019-04-10 00:57:21,542 root         INFO     Train Epoch: 67 [6656/8000 (83%)]\tTotal Loss: 0.529606\n",
      "Reconstruction: 0.450273, Regularization: 0.000528, Discriminator: 0.055924; Generator: 0.022882,\n",
      "D(x): 0.332, D(G(z)): 0.481\n",
      "2019-04-10 00:57:21,653 root         INFO     Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 0.526663\n",
      "Reconstruction: 0.450579, Regularization: 0.000478, Discriminator: 0.052624; Generator: 0.022982,\n",
      "D(x): 0.365, D(G(z)): 0.479\n",
      "2019-04-10 00:57:21,763 root         INFO     Train Epoch: 67 [7680/8000 (96%)]\tTotal Loss: 0.529078\n",
      "Reconstruction: 0.450939, Regularization: 0.000516, Discriminator: 0.054585; Generator: 0.023038,\n",
      "D(x): 0.344, D(G(z)): 0.478\n",
      "2019-04-10 00:57:21,844 root         INFO     ====> Epoch: 67 Average loss: 0.5271\n",
      "2019-04-10 00:57:21,872 root         INFO     Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 0.529157\n",
      "Reconstruction: 0.451333, Regularization: 0.000576, Discriminator: 0.054145; Generator: 0.023103,\n",
      "D(x): 0.347, D(G(z)): 0.477\n",
      "2019-04-10 00:57:21,988 root         INFO     Train Epoch: 68 [512/8000 (6%)]\tTotal Loss: 0.529224\n",
      "Reconstruction: 0.451725, Regularization: 0.000459, Discriminator: 0.053926; Generator: 0.023114,\n",
      "D(x): 0.350, D(G(z)): 0.477\n",
      "2019-04-10 00:57:22,102 root         INFO     Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 0.532518\n",
      "Reconstruction: 0.452165, Regularization: 0.000423, Discriminator: 0.056828; Generator: 0.023102,\n",
      "D(x): 0.323, D(G(z)): 0.477\n",
      "2019-04-10 00:57:22,215 root         INFO     Train Epoch: 68 [1536/8000 (19%)]\tTotal Loss: 0.530705\n",
      "Reconstruction: 0.452643, Regularization: 0.000532, Discriminator: 0.054265; Generator: 0.023265,\n",
      "D(x): 0.343, D(G(z)): 0.475\n",
      "2019-04-10 00:57:22,330 root         INFO     Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 0.531449\n",
      "Reconstruction: 0.453161, Regularization: 0.000346, Discriminator: 0.054654; Generator: 0.023288,\n",
      "D(x): 0.342, D(G(z)): 0.475\n",
      "2019-04-10 00:57:22,443 root         INFO     Train Epoch: 68 [2560/8000 (32%)]\tTotal Loss: 0.533788\n",
      "Reconstruction: 0.453537, Regularization: 0.000462, Discriminator: 0.056515; Generator: 0.023274,\n",
      "D(x): 0.324, D(G(z)): 0.475\n",
      "2019-04-10 00:57:22,558 root         INFO     Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 0.531033\n",
      "Reconstruction: 0.454067, Regularization: 0.000375, Discriminator: 0.053258; Generator: 0.023333,\n",
      "D(x): 0.353, D(G(z)): 0.474\n",
      "2019-04-10 00:57:22,681 root         INFO     Train Epoch: 68 [3584/8000 (45%)]\tTotal Loss: 0.531754\n",
      "Reconstruction: 0.454531, Regularization: 0.000348, Discriminator: 0.053541; Generator: 0.023335,\n",
      "D(x): 0.352, D(G(z)): 0.474\n",
      "2019-04-10 00:57:22,795 root         INFO     Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 0.533331\n",
      "Reconstruction: 0.454988, Regularization: 0.000596, Discriminator: 0.054387; Generator: 0.023360,\n",
      "D(x): 0.340, D(G(z)): 0.474\n",
      "2019-04-10 00:57:22,908 root         INFO     Train Epoch: 68 [4608/8000 (58%)]\tTotal Loss: 0.534320\n",
      "Reconstruction: 0.455355, Regularization: 0.000357, Discriminator: 0.054993; Generator: 0.023616,\n",
      "D(x): 0.331, D(G(z)): 0.470\n",
      "2019-04-10 00:57:23,021 root         INFO     Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 0.534344\n",
      "Reconstruction: 0.455944, Regularization: 0.000360, Discriminator: 0.054496; Generator: 0.023545,\n",
      "D(x): 0.339, D(G(z)): 0.471\n",
      "2019-04-10 00:57:23,132 root         INFO     Train Epoch: 68 [5632/8000 (70%)]\tTotal Loss: 0.533676\n",
      "Reconstruction: 0.456396, Regularization: 0.000360, Discriminator: 0.053385; Generator: 0.023535,\n",
      "D(x): 0.351, D(G(z)): 0.471\n",
      "2019-04-10 00:57:23,243 root         INFO     Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 0.536454\n",
      "Reconstruction: 0.456894, Regularization: 0.000534, Discriminator: 0.055481; Generator: 0.023546,\n",
      "D(x): 0.330, D(G(z)): 0.471\n",
      "2019-04-10 00:57:23,354 root         INFO     Train Epoch: 68 [6656/8000 (83%)]\tTotal Loss: 0.535401\n",
      "Reconstruction: 0.457281, Regularization: 0.000628, Discriminator: 0.053712; Generator: 0.023779,\n",
      "D(x): 0.343, D(G(z)): 0.467\n",
      "2019-04-10 00:57:23,466 root         INFO     Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 0.535777\n",
      "Reconstruction: 0.457703, Regularization: 0.000379, Discriminator: 0.053893; Generator: 0.023802,\n",
      "D(x): 0.347, D(G(z)): 0.467\n",
      "2019-04-10 00:57:23,578 root         INFO     Train Epoch: 68 [7680/8000 (96%)]\tTotal Loss: 0.535475\n",
      "Reconstruction: 0.457974, Regularization: 0.000450, Discriminator: 0.053185; Generator: 0.023865,\n",
      "D(x): 0.346, D(G(z)): 0.466\n",
      "2019-04-10 00:57:23,659 root         INFO     ====> Epoch: 68 Average loss: 0.5333\n",
      "2019-04-10 00:57:23,686 root         INFO     Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 0.537736\n",
      "Reconstruction: 0.458380, Regularization: 0.000393, Discriminator: 0.055079; Generator: 0.023884,\n",
      "D(x): 0.326, D(G(z)): 0.466\n",
      "2019-04-10 00:57:23,797 root         INFO     Train Epoch: 69 [512/8000 (6%)]\tTotal Loss: 0.539101\n",
      "Reconstruction: 0.458693, Regularization: 0.000384, Discriminator: 0.056048; Generator: 0.023977,\n",
      "D(x): 0.317, D(G(z)): 0.464\n",
      "2019-04-10 00:57:23,907 root         INFO     Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 0.536657\n",
      "Reconstruction: 0.459135, Regularization: 0.000432, Discriminator: 0.053034; Generator: 0.024056,\n",
      "D(x): 0.346, D(G(z)): 0.463\n",
      "2019-04-10 00:57:24,017 root         INFO     Train Epoch: 69 [1536/8000 (19%)]\tTotal Loss: 0.537127\n",
      "Reconstruction: 0.459514, Regularization: 0.000505, Discriminator: 0.053061; Generator: 0.024047,\n",
      "D(x): 0.347, D(G(z)): 0.463\n",
      "2019-04-10 00:57:24,127 root         INFO     Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 0.537797\n",
      "Reconstruction: 0.459718, Regularization: 0.000274, Discriminator: 0.053766; Generator: 0.024039,\n",
      "D(x): 0.339, D(G(z)): 0.463\n",
      "2019-04-10 00:57:24,238 root         INFO     Train Epoch: 69 [2560/8000 (32%)]\tTotal Loss: 0.538211\n",
      "Reconstruction: 0.460206, Regularization: 0.000598, Discriminator: 0.053261; Generator: 0.024146,\n",
      "D(x): 0.345, D(G(z)): 0.462\n",
      "2019-04-10 00:57:24,348 root         INFO     Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 0.539117\n",
      "Reconstruction: 0.460433, Regularization: 0.000623, Discriminator: 0.053997; Generator: 0.024064,\n",
      "D(x): 0.337, D(G(z)): 0.463\n",
      "2019-04-10 00:57:24,458 root         INFO     Train Epoch: 69 [3584/8000 (45%)]\tTotal Loss: 0.538648\n",
      "Reconstruction: 0.460873, Regularization: 0.000365, Discriminator: 0.053309; Generator: 0.024101,\n",
      "D(x): 0.344, D(G(z)): 0.462\n",
      "2019-04-10 00:57:24,568 root         INFO     Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 0.540084\n",
      "Reconstruction: 0.461213, Regularization: 0.000525, Discriminator: 0.054083; Generator: 0.024262,\n",
      "D(x): 0.334, D(G(z)): 0.460\n",
      "2019-04-10 00:57:24,678 root         INFO     Train Epoch: 69 [4608/8000 (58%)]\tTotal Loss: 0.541977\n",
      "Reconstruction: 0.461747, Regularization: 0.000516, Discriminator: 0.055524; Generator: 0.024190,\n",
      "D(x): 0.319, D(G(z)): 0.461\n",
      "2019-04-10 00:57:24,789 root         INFO     Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 0.539169\n",
      "Reconstruction: 0.462010, Regularization: 0.000290, Discriminator: 0.052597; Generator: 0.024272,\n",
      "D(x): 0.348, D(G(z)): 0.460\n",
      "2019-04-10 00:57:24,899 root         INFO     Train Epoch: 69 [5632/8000 (70%)]\tTotal Loss: 0.539570\n",
      "Reconstruction: 0.462268, Regularization: 0.000457, Discriminator: 0.052509; Generator: 0.024336,\n",
      "D(x): 0.348, D(G(z)): 0.459\n",
      "2019-04-10 00:57:25,009 root         INFO     Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 0.539489\n",
      "Reconstruction: 0.462590, Regularization: 0.000507, Discriminator: 0.052060; Generator: 0.024333,\n",
      "D(x): 0.355, D(G(z)): 0.459\n",
      "2019-04-10 00:57:25,119 root         INFO     Train Epoch: 69 [6656/8000 (83%)]\tTotal Loss: 0.542015\n",
      "Reconstruction: 0.462978, Regularization: 0.000432, Discriminator: 0.054252; Generator: 0.024353,\n",
      "D(x): 0.330, D(G(z)): 0.459\n",
      "2019-04-10 00:57:25,229 root         INFO     Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 0.542020\n",
      "Reconstruction: 0.463414, Regularization: 0.000259, Discriminator: 0.053976; Generator: 0.024371,\n",
      "D(x): 0.334, D(G(z)): 0.458\n",
      "2019-04-10 00:57:25,339 root         INFO     Train Epoch: 69 [7680/8000 (96%)]\tTotal Loss: 0.543455\n",
      "Reconstruction: 0.463835, Regularization: 0.000399, Discriminator: 0.054690; Generator: 0.024531,\n",
      "D(x): 0.323, D(G(z)): 0.456\n",
      "2019-04-10 00:57:25,419 root         INFO     ====> Epoch: 69 Average loss: 0.5394\n",
      "2019-04-10 00:57:25,446 root         INFO     Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 0.542308\n",
      "Reconstruction: 0.464030, Regularization: 0.000492, Discriminator: 0.053246; Generator: 0.024539,\n",
      "D(x): 0.338, D(G(z)): 0.456\n",
      "2019-04-10 00:57:25,555 root         INFO     Train Epoch: 70 [512/8000 (6%)]\tTotal Loss: 0.542082\n",
      "Reconstruction: 0.464197, Regularization: 0.000449, Discriminator: 0.052811; Generator: 0.024625,\n",
      "D(x): 0.343, D(G(z)): 0.455\n",
      "2019-04-10 00:57:25,666 root         INFO     Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 0.542119\n",
      "Reconstruction: 0.464852, Regularization: 0.000285, Discriminator: 0.052327; Generator: 0.024655,\n",
      "D(x): 0.349, D(G(z)): 0.454\n",
      "2019-04-10 00:57:25,776 root         INFO     Train Epoch: 70 [1536/8000 (19%)]\tTotal Loss: 0.543418\n",
      "Reconstruction: 0.465033, Regularization: 0.000392, Discriminator: 0.053304; Generator: 0.024689,\n",
      "D(x): 0.335, D(G(z)): 0.454\n",
      "2019-04-10 00:57:25,885 root         INFO     Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 0.542318\n",
      "Reconstruction: 0.465550, Regularization: 0.000416, Discriminator: 0.051669; Generator: 0.024683,\n",
      "D(x): 0.354, D(G(z)): 0.454\n",
      "2019-04-10 00:57:25,996 root         INFO     Train Epoch: 70 [2560/8000 (32%)]\tTotal Loss: 0.543814\n",
      "Reconstruction: 0.465758, Regularization: 0.000265, Discriminator: 0.053033; Generator: 0.024758,\n",
      "D(x): 0.338, D(G(z)): 0.453\n",
      "2019-04-10 00:57:26,105 root         INFO     Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 0.542282\n",
      "Reconstruction: 0.466284, Regularization: 0.000339, Discriminator: 0.050834; Generator: 0.024824,\n",
      "D(x): 0.362, D(G(z)): 0.452\n",
      "2019-04-10 00:57:26,216 root         INFO     Train Epoch: 70 [3584/8000 (45%)]\tTotal Loss: 0.545017\n",
      "Reconstruction: 0.466447, Regularization: 0.000386, Discriminator: 0.053243; Generator: 0.024941,\n",
      "D(x): 0.335, D(G(z)): 0.450\n",
      "2019-04-10 00:57:26,325 root         INFO     Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 0.544799\n",
      "Reconstruction: 0.466816, Regularization: 0.000526, Discriminator: 0.052338; Generator: 0.025119,\n",
      "D(x): 0.341, D(G(z)): 0.448\n",
      "2019-04-10 00:57:26,434 root         INFO     Train Epoch: 70 [4608/8000 (58%)]\tTotal Loss: 0.543897\n",
      "Reconstruction: 0.467342, Regularization: 0.000343, Discriminator: 0.051164; Generator: 0.025047,\n",
      "D(x): 0.357, D(G(z)): 0.449\n",
      "2019-04-10 00:57:26,545 root         INFO     Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 0.545621\n",
      "Reconstruction: 0.467954, Regularization: 0.000393, Discriminator: 0.052215; Generator: 0.025059,\n",
      "D(x): 0.344, D(G(z)): 0.448\n",
      "2019-04-10 00:57:26,654 root         INFO     Train Epoch: 70 [5632/8000 (70%)]\tTotal Loss: 0.546869\n",
      "Reconstruction: 0.468225, Regularization: 0.000560, Discriminator: 0.052953; Generator: 0.025131,\n",
      "D(x): 0.338, D(G(z)): 0.447\n",
      "2019-04-10 00:57:26,762 root         INFO     Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 0.546446\n",
      "Reconstruction: 0.468668, Regularization: 0.000398, Discriminator: 0.052132; Generator: 0.025248,\n",
      "D(x): 0.344, D(G(z)): 0.446\n",
      "2019-04-10 00:57:26,870 root         INFO     Train Epoch: 70 [6656/8000 (83%)]\tTotal Loss: 0.546170\n",
      "Reconstruction: 0.468946, Regularization: 0.000431, Discriminator: 0.051532; Generator: 0.025262,\n",
      "D(x): 0.349, D(G(z)): 0.446\n",
      "2019-04-10 00:57:26,977 root         INFO     Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 0.547417\n",
      "Reconstruction: 0.469282, Regularization: 0.000321, Discriminator: 0.052528; Generator: 0.025286,\n",
      "D(x): 0.340, D(G(z)): 0.445\n",
      "2019-04-10 00:57:27,085 root         INFO     Train Epoch: 70 [7680/8000 (96%)]\tTotal Loss: 0.547193\n",
      "Reconstruction: 0.469837, Regularization: 0.000486, Discriminator: 0.051620; Generator: 0.025250,\n",
      "D(x): 0.349, D(G(z)): 0.446\n",
      "2019-04-10 00:57:27,164 root         INFO     ====> Epoch: 70 Average loss: 0.5448\n",
      "2019-04-10 00:57:27,191 root         INFO     Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 0.547230\n",
      "Reconstruction: 0.469874, Regularization: 0.000313, Discriminator: 0.051766; Generator: 0.025277,\n",
      "D(x): 0.348, D(G(z)): 0.445\n",
      "2019-04-10 00:57:27,303 root         INFO     Train Epoch: 71 [512/8000 (6%)]\tTotal Loss: 0.549377\n",
      "Reconstruction: 0.470553, Regularization: 0.000233, Discriminator: 0.053251; Generator: 0.025340,\n",
      "D(x): 0.329, D(G(z)): 0.444\n",
      "2019-04-10 00:57:27,413 root         INFO     Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 0.547349\n",
      "Reconstruction: 0.470838, Regularization: 0.000339, Discriminator: 0.050699; Generator: 0.025473,\n",
      "D(x): 0.358, D(G(z)): 0.443\n",
      "2019-04-10 00:57:27,524 root         INFO     Train Epoch: 71 [1536/8000 (19%)]\tTotal Loss: 0.548958\n",
      "Reconstruction: 0.471185, Regularization: 0.000262, Discriminator: 0.051893; Generator: 0.025617,\n",
      "D(x): 0.342, D(G(z)): 0.441\n",
      "2019-04-10 00:57:27,634 root         INFO     Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 0.548569\n",
      "Reconstruction: 0.471575, Regularization: 0.000316, Discriminator: 0.051074; Generator: 0.025603,\n",
      "D(x): 0.351, D(G(z)): 0.441\n",
      "2019-04-10 00:57:27,744 root         INFO     Train Epoch: 71 [2560/8000 (32%)]\tTotal Loss: 0.549920\n",
      "Reconstruction: 0.471960, Regularization: 0.000302, Discriminator: 0.052045; Generator: 0.025614,\n",
      "D(x): 0.341, D(G(z)): 0.441\n",
      "2019-04-10 00:57:27,855 root         INFO     Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 0.549108\n",
      "Reconstruction: 0.472519, Regularization: 0.000263, Discriminator: 0.050671; Generator: 0.025654,\n",
      "D(x): 0.355, D(G(z)): 0.440\n",
      "2019-04-10 00:57:27,965 root         INFO     Train Epoch: 71 [3584/8000 (45%)]\tTotal Loss: 0.551884\n",
      "Reconstruction: 0.472661, Regularization: 0.000372, Discriminator: 0.053095; Generator: 0.025757,\n",
      "D(x): 0.329, D(G(z)): 0.439\n",
      "2019-04-10 00:57:28,076 root         INFO     Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 0.550382\n",
      "Reconstruction: 0.473183, Regularization: 0.000255, Discriminator: 0.051081; Generator: 0.025863,\n",
      "D(x): 0.349, D(G(z)): 0.437\n",
      "2019-04-10 00:57:28,184 root         INFO     Train Epoch: 71 [4608/8000 (58%)]\tTotal Loss: 0.551558\n",
      "Reconstruction: 0.473540, Regularization: 0.000413, Discriminator: 0.051667; Generator: 0.025939,\n",
      "D(x): 0.342, D(G(z)): 0.436\n",
      "2019-04-10 00:57:28,292 root         INFO     Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 0.550780\n",
      "Reconstruction: 0.473861, Regularization: 0.000441, Discriminator: 0.050551; Generator: 0.025927,\n",
      "D(x): 0.354, D(G(z)): 0.436\n",
      "2019-04-10 00:57:28,400 root         INFO     Train Epoch: 71 [5632/8000 (70%)]\tTotal Loss: 0.550793\n",
      "Reconstruction: 0.474273, Regularization: 0.000311, Discriminator: 0.050302; Generator: 0.025907,\n",
      "D(x): 0.357, D(G(z)): 0.436\n",
      "2019-04-10 00:57:28,508 root         INFO     Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 0.551605\n",
      "Reconstruction: 0.474672, Regularization: 0.000290, Discriminator: 0.050648; Generator: 0.025995,\n",
      "D(x): 0.353, D(G(z)): 0.435\n",
      "2019-04-10 00:57:28,615 root         INFO     Train Epoch: 71 [6656/8000 (83%)]\tTotal Loss: 0.553264\n",
      "Reconstruction: 0.475024, Regularization: 0.000427, Discriminator: 0.051740; Generator: 0.026073,\n",
      "D(x): 0.341, D(G(z)): 0.434\n",
      "2019-04-10 00:57:28,722 root         INFO     Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 0.553012\n",
      "Reconstruction: 0.475190, Regularization: 0.000346, Discriminator: 0.051378; Generator: 0.026099,\n",
      "D(x): 0.343, D(G(z)): 0.434\n",
      "2019-04-10 00:57:28,829 root         INFO     Train Epoch: 71 [7680/8000 (96%)]\tTotal Loss: 0.552891\n",
      "Reconstruction: 0.475696, Regularization: 0.000408, Discriminator: 0.050685; Generator: 0.026102,\n",
      "D(x): 0.350, D(G(z)): 0.434\n",
      "2019-04-10 00:57:28,909 root         INFO     ====> Epoch: 71 Average loss: 0.5507\n",
      "2019-04-10 00:57:28,936 root         INFO     Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 0.553436\n",
      "Reconstruction: 0.475664, Regularization: 0.000380, Discriminator: 0.051186; Generator: 0.026207,\n",
      "D(x): 0.344, D(G(z)): 0.432\n",
      "2019-04-10 00:57:29,049 root         INFO     Train Epoch: 72 [512/8000 (6%)]\tTotal Loss: 0.554046\n",
      "Reconstruction: 0.476155, Regularization: 0.000365, Discriminator: 0.051249; Generator: 0.026278,\n",
      "D(x): 0.343, D(G(z)): 0.431\n",
      "2019-04-10 00:57:29,161 root         INFO     Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 0.553337\n",
      "Reconstruction: 0.476368, Regularization: 0.000327, Discriminator: 0.050235; Generator: 0.026407,\n",
      "D(x): 0.353, D(G(z)): 0.430\n",
      "2019-04-10 00:57:29,272 root         INFO     Train Epoch: 72 [1536/8000 (19%)]\tTotal Loss: 0.555253\n",
      "Reconstruction: 0.476680, Regularization: 0.000461, Discriminator: 0.051685; Generator: 0.026427,\n",
      "D(x): 0.337, D(G(z)): 0.429\n",
      "2019-04-10 00:57:29,383 root         INFO     Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 0.554632\n",
      "Reconstruction: 0.477089, Regularization: 0.000371, Discriminator: 0.050815; Generator: 0.026358,\n",
      "D(x): 0.347, D(G(z)): 0.430\n",
      "2019-04-10 00:57:29,494 root         INFO     Train Epoch: 72 [2560/8000 (32%)]\tTotal Loss: 0.554513\n",
      "Reconstruction: 0.477249, Regularization: 0.000339, Discriminator: 0.050445; Generator: 0.026481,\n",
      "D(x): 0.350, D(G(z)): 0.429\n",
      "2019-04-10 00:57:29,606 root         INFO     Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 0.554212\n",
      "Reconstruction: 0.477536, Regularization: 0.000338, Discriminator: 0.049753; Generator: 0.026585,\n",
      "D(x): 0.356, D(G(z)): 0.427\n",
      "2019-04-10 00:57:29,717 root         INFO     Train Epoch: 72 [3584/8000 (45%)]\tTotal Loss: 0.555392\n",
      "Reconstruction: 0.477810, Regularization: 0.000310, Discriminator: 0.050575; Generator: 0.026697,\n",
      "D(x): 0.346, D(G(z)): 0.426\n",
      "2019-04-10 00:57:29,828 root         INFO     Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 0.554953\n",
      "Reconstruction: 0.478179, Regularization: 0.000252, Discriminator: 0.049840; Generator: 0.026682,\n",
      "D(x): 0.355, D(G(z)): 0.426\n",
      "2019-04-10 00:57:29,939 root         INFO     Train Epoch: 72 [4608/8000 (58%)]\tTotal Loss: 0.555629\n",
      "Reconstruction: 0.478600, Regularization: 0.000378, Discriminator: 0.049943; Generator: 0.026709,\n",
      "D(x): 0.354, D(G(z)): 0.425\n",
      "2019-04-10 00:57:30,049 root         INFO     Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 0.556595\n",
      "Reconstruction: 0.478929, Regularization: 0.000289, Discriminator: 0.050572; Generator: 0.026805,\n",
      "D(x): 0.345, D(G(z)): 0.424\n",
      "2019-04-10 00:57:30,160 root         INFO     Train Epoch: 72 [5632/8000 (70%)]\tTotal Loss: 0.556655\n",
      "Reconstruction: 0.479098, Regularization: 0.000219, Discriminator: 0.050464; Generator: 0.026875,\n",
      "D(x): 0.346, D(G(z)): 0.423\n",
      "2019-04-10 00:57:30,270 root         INFO     Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 0.557387\n",
      "Reconstruction: 0.479371, Regularization: 0.000348, Discriminator: 0.050752; Generator: 0.026916,\n",
      "D(x): 0.343, D(G(z)): 0.423\n",
      "2019-04-10 00:57:30,381 root         INFO     Train Epoch: 72 [6656/8000 (83%)]\tTotal Loss: 0.555948\n",
      "Reconstruction: 0.479601, Regularization: 0.000280, Discriminator: 0.048987; Generator: 0.027080,\n",
      "D(x): 0.361, D(G(z)): 0.420\n",
      "2019-04-10 00:57:30,492 root         INFO     Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 0.556168\n",
      "Reconstruction: 0.479931, Regularization: 0.000282, Discriminator: 0.048850; Generator: 0.027105,\n",
      "D(x): 0.362, D(G(z)): 0.420\n",
      "2019-04-10 00:57:30,602 root         INFO     Train Epoch: 72 [7680/8000 (96%)]\tTotal Loss: 0.556955\n",
      "Reconstruction: 0.480245, Regularization: 0.000280, Discriminator: 0.049324; Generator: 0.027106,\n",
      "D(x): 0.357, D(G(z)): 0.420\n",
      "2019-04-10 00:57:30,684 root         INFO     ====> Epoch: 72 Average loss: 0.5557\n",
      "2019-04-10 00:57:30,711 root         INFO     Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 0.557614\n",
      "Reconstruction: 0.480359, Regularization: 0.000327, Discriminator: 0.049816; Generator: 0.027112,\n",
      "D(x): 0.351, D(G(z)): 0.420\n",
      "2019-04-10 00:57:30,823 root         INFO     Train Epoch: 73 [512/8000 (6%)]\tTotal Loss: 0.558323\n",
      "Reconstruction: 0.480816, Regularization: 0.000346, Discriminator: 0.049953; Generator: 0.027208,\n",
      "D(x): 0.349, D(G(z)): 0.419\n",
      "2019-04-10 00:57:30,935 root         INFO     Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 0.558683\n",
      "Reconstruction: 0.481085, Regularization: 0.000530, Discriminator: 0.049819; Generator: 0.027249,\n",
      "D(x): 0.350, D(G(z)): 0.418\n",
      "2019-04-10 00:57:31,047 root         INFO     Train Epoch: 73 [1536/8000 (19%)]\tTotal Loss: 0.559261\n",
      "Reconstruction: 0.481351, Regularization: 0.000265, Discriminator: 0.050270; Generator: 0.027375,\n",
      "D(x): 0.345, D(G(z)): 0.416\n",
      "2019-04-10 00:57:31,158 root         INFO     Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 0.558553\n",
      "Reconstruction: 0.481615, Regularization: 0.000276, Discriminator: 0.049243; Generator: 0.027420,\n",
      "D(x): 0.356, D(G(z)): 0.416\n",
      "2019-04-10 00:57:31,269 root         INFO     Train Epoch: 73 [2560/8000 (32%)]\tTotal Loss: 0.559642\n",
      "Reconstruction: 0.481927, Regularization: 0.000367, Discriminator: 0.049833; Generator: 0.027516,\n",
      "D(x): 0.347, D(G(z)): 0.415\n",
      "2019-04-10 00:57:31,379 root         INFO     Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 0.559617\n",
      "Reconstruction: 0.482281, Regularization: 0.000364, Discriminator: 0.049369; Generator: 0.027604,\n",
      "D(x): 0.352, D(G(z)): 0.413\n",
      "2019-04-10 00:57:31,490 root         INFO     Train Epoch: 73 [3584/8000 (45%)]\tTotal Loss: 0.560097\n",
      "Reconstruction: 0.482457, Regularization: 0.000348, Discriminator: 0.049646; Generator: 0.027646,\n",
      "D(x): 0.349, D(G(z)): 0.413\n",
      "2019-04-10 00:57:31,600 root         INFO     Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 0.561266\n",
      "Reconstruction: 0.482920, Regularization: 0.000342, Discriminator: 0.050315; Generator: 0.027689,\n",
      "D(x): 0.341, D(G(z)): 0.412\n",
      "2019-04-10 00:57:31,711 root         INFO     Train Epoch: 73 [4608/8000 (58%)]\tTotal Loss: 0.560740\n",
      "Reconstruction: 0.482946, Regularization: 0.000326, Discriminator: 0.049678; Generator: 0.027789,\n",
      "D(x): 0.347, D(G(z)): 0.411\n",
      "2019-04-10 00:57:31,821 root         INFO     Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 0.560599\n",
      "Reconstruction: 0.483596, Regularization: 0.000225, Discriminator: 0.048869; Generator: 0.027909,\n",
      "D(x): 0.355, D(G(z)): 0.409\n",
      "2019-04-10 00:57:31,930 root         INFO     Train Epoch: 73 [5632/8000 (70%)]\tTotal Loss: 0.562370\n",
      "Reconstruction: 0.483877, Regularization: 0.000308, Discriminator: 0.050171; Generator: 0.028014,\n",
      "D(x): 0.340, D(G(z)): 0.408\n",
      "2019-04-10 00:57:32,039 root         INFO     Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 0.561651\n",
      "Reconstruction: 0.484053, Regularization: 0.000347, Discriminator: 0.049138; Generator: 0.028113,\n",
      "D(x): 0.350, D(G(z)): 0.407\n",
      "2019-04-10 00:57:32,148 root         INFO     Train Epoch: 73 [6656/8000 (83%)]\tTotal Loss: 0.562016\n",
      "Reconstruction: 0.484367, Regularization: 0.000303, Discriminator: 0.049173; Generator: 0.028174,\n",
      "D(x): 0.350, D(G(z)): 0.406\n",
      "2019-04-10 00:57:32,258 root         INFO     Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 0.562511\n",
      "Reconstruction: 0.484754, Regularization: 0.000322, Discriminator: 0.049183; Generator: 0.028252,\n",
      "D(x): 0.349, D(G(z)): 0.405\n",
      "2019-04-10 00:57:32,367 root         INFO     Train Epoch: 73 [7680/8000 (96%)]\tTotal Loss: 0.562257\n",
      "Reconstruction: 0.485008, Regularization: 0.000340, Discriminator: 0.048588; Generator: 0.028321,\n",
      "D(x): 0.355, D(G(z)): 0.404\n",
      "2019-04-10 00:57:32,450 root         INFO     ====> Epoch: 73 Average loss: 0.5603\n",
      "2019-04-10 00:57:32,477 root         INFO     Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 0.563082\n",
      "Reconstruction: 0.485306, Regularization: 0.000445, Discriminator: 0.048972; Generator: 0.028358,\n",
      "D(x): 0.350, D(G(z)): 0.404\n",
      "2019-04-10 00:57:32,588 root         INFO     Train Epoch: 74 [512/8000 (6%)]\tTotal Loss: 0.562817\n",
      "Reconstruction: 0.485437, Regularization: 0.000243, Discriminator: 0.048671; Generator: 0.028466,\n",
      "D(x): 0.353, D(G(z)): 0.402\n",
      "2019-04-10 00:57:32,698 root         INFO     Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 0.563270\n",
      "Reconstruction: 0.485722, Regularization: 0.000264, Discriminator: 0.048720; Generator: 0.028564,\n",
      "D(x): 0.352, D(G(z)): 0.401\n",
      "2019-04-10 00:57:32,808 root         INFO     Train Epoch: 74 [1536/8000 (19%)]\tTotal Loss: 0.563589\n",
      "Reconstruction: 0.486019, Regularization: 0.000260, Discriminator: 0.048668; Generator: 0.028642,\n",
      "D(x): 0.351, D(G(z)): 0.400\n",
      "2019-04-10 00:57:32,916 root         INFO     Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 0.564459\n",
      "Reconstruction: 0.486473, Regularization: 0.000384, Discriminator: 0.048868; Generator: 0.028734,\n",
      "D(x): 0.349, D(G(z)): 0.399\n",
      "2019-04-10 00:57:33,024 root         INFO     Train Epoch: 74 [2560/8000 (32%)]\tTotal Loss: 0.564602\n",
      "Reconstruction: 0.486725, Regularization: 0.000259, Discriminator: 0.048807; Generator: 0.028811,\n",
      "D(x): 0.349, D(G(z)): 0.398\n",
      "2019-04-10 00:57:33,133 root         INFO     Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 0.564129\n",
      "Reconstruction: 0.486894, Regularization: 0.000246, Discriminator: 0.048030; Generator: 0.028959,\n",
      "D(x): 0.356, D(G(z)): 0.396\n",
      "2019-04-10 00:57:33,241 root         INFO     Train Epoch: 74 [3584/8000 (45%)]\tTotal Loss: 0.565505\n",
      "Reconstruction: 0.487386, Regularization: 0.000288, Discriminator: 0.048752; Generator: 0.029078,\n",
      "D(x): 0.347, D(G(z)): 0.394\n",
      "2019-04-10 00:57:33,349 root         INFO     Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 0.565862\n",
      "Reconstruction: 0.487488, Regularization: 0.000544, Discriminator: 0.048661; Generator: 0.029168,\n",
      "D(x): 0.348, D(G(z)): 0.393\n",
      "2019-04-10 00:57:33,457 root         INFO     Train Epoch: 74 [4608/8000 (58%)]\tTotal Loss: 0.566036\n",
      "Reconstruction: 0.488044, Regularization: 0.000189, Discriminator: 0.048565; Generator: 0.029239,\n",
      "D(x): 0.348, D(G(z)): 0.392\n",
      "2019-04-10 00:57:33,565 root         INFO     Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 0.565586\n",
      "Reconstruction: 0.488000, Regularization: 0.000251, Discriminator: 0.048013; Generator: 0.029322,\n",
      "D(x): 0.354, D(G(z)): 0.391\n",
      "2019-04-10 00:57:33,672 root         INFO     Train Epoch: 74 [5632/8000 (70%)]\tTotal Loss: 0.566412\n",
      "Reconstruction: 0.488450, Regularization: 0.000283, Discriminator: 0.048261; Generator: 0.029418,\n",
      "D(x): 0.350, D(G(z)): 0.390\n",
      "2019-04-10 00:57:33,780 root         INFO     Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 0.566880\n",
      "Reconstruction: 0.488521, Regularization: 0.000423, Discriminator: 0.048391; Generator: 0.029544,\n",
      "D(x): 0.348, D(G(z)): 0.389\n",
      "2019-04-10 00:57:33,888 root         INFO     Train Epoch: 74 [6656/8000 (83%)]\tTotal Loss: 0.566507\n",
      "Reconstruction: 0.488785, Regularization: 0.000215, Discriminator: 0.047823; Generator: 0.029684,\n",
      "D(x): 0.353, D(G(z)): 0.387\n",
      "2019-04-10 00:57:33,997 root         INFO     Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 0.567263\n",
      "Reconstruction: 0.489064, Regularization: 0.000233, Discriminator: 0.048158; Generator: 0.029807,\n",
      "D(x): 0.349, D(G(z)): 0.385\n",
      "2019-04-10 00:57:34,105 root         INFO     Train Epoch: 74 [7680/8000 (96%)]\tTotal Loss: 0.567849\n",
      "Reconstruction: 0.489338, Regularization: 0.000287, Discriminator: 0.048312; Generator: 0.029912,\n",
      "D(x): 0.346, D(G(z)): 0.384\n",
      "2019-04-10 00:57:34,185 root         INFO     ====> Epoch: 74 Average loss: 0.5653\n",
      "2019-04-10 00:57:34,212 root         INFO     Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 0.567286\n",
      "Reconstruction: 0.489362, Regularization: 0.000164, Discriminator: 0.047781; Generator: 0.029980,\n",
      "D(x): 0.352, D(G(z)): 0.383\n",
      "2019-04-10 00:57:34,324 root         INFO     Train Epoch: 75 [512/8000 (6%)]\tTotal Loss: 0.568174\n",
      "Reconstruction: 0.489747, Regularization: 0.000271, Discriminator: 0.048097; Generator: 0.030059,\n",
      "D(x): 0.348, D(G(z)): 0.382\n",
      "2019-04-10 00:57:34,434 root         INFO     Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 0.568134\n",
      "Reconstruction: 0.489873, Regularization: 0.000339, Discriminator: 0.047744; Generator: 0.030178,\n",
      "D(x): 0.351, D(G(z)): 0.381\n",
      "2019-04-10 00:57:34,545 root         INFO     Train Epoch: 75 [1536/8000 (19%)]\tTotal Loss: 0.568496\n",
      "Reconstruction: 0.489957, Regularization: 0.000395, Discriminator: 0.047839; Generator: 0.030305,\n",
      "D(x): 0.349, D(G(z)): 0.379\n",
      "2019-04-10 00:57:34,656 root         INFO     Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 0.568648\n",
      "Reconstruction: 0.490257, Regularization: 0.000308, Discriminator: 0.047647; Generator: 0.030436,\n",
      "D(x): 0.350, D(G(z)): 0.378\n",
      "2019-04-10 00:57:34,768 root         INFO     Train Epoch: 75 [2560/8000 (32%)]\tTotal Loss: 0.568614\n",
      "Reconstruction: 0.490491, Regularization: 0.000181, Discriminator: 0.047406; Generator: 0.030536,\n",
      "D(x): 0.352, D(G(z)): 0.376\n",
      "2019-04-10 00:57:34,879 root         INFO     Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 0.569319\n",
      "Reconstruction: 0.490671, Regularization: 0.000293, Discriminator: 0.047725; Generator: 0.030630,\n",
      "D(x): 0.348, D(G(z)): 0.375\n",
      "2019-04-10 00:57:34,989 root         INFO     Train Epoch: 75 [3584/8000 (45%)]\tTotal Loss: 0.569341\n",
      "Reconstruction: 0.490805, Regularization: 0.000201, Discriminator: 0.047586; Generator: 0.030748,\n",
      "D(x): 0.348, D(G(z)): 0.374\n",
      "2019-04-10 00:57:35,100 root         INFO     Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 0.569596\n",
      "Reconstruction: 0.490885, Regularization: 0.000215, Discriminator: 0.047626; Generator: 0.030870,\n",
      "D(x): 0.347, D(G(z)): 0.372\n",
      "2019-04-10 00:57:35,211 root         INFO     Train Epoch: 75 [4608/8000 (58%)]\tTotal Loss: 0.569630\n",
      "Reconstruction: 0.490971, Regularization: 0.000241, Discriminator: 0.047408; Generator: 0.031011,\n",
      "D(x): 0.349, D(G(z)): 0.371\n",
      "2019-04-10 00:57:35,321 root         INFO     Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 0.570167\n",
      "Reconstruction: 0.491238, Regularization: 0.000304, Discriminator: 0.047544; Generator: 0.031082,\n",
      "D(x): 0.347, D(G(z)): 0.370\n",
      "2019-04-10 00:57:35,432 root         INFO     Train Epoch: 75 [5632/8000 (70%)]\tTotal Loss: 0.570101\n",
      "Reconstruction: 0.491273, Regularization: 0.000193, Discriminator: 0.047439; Generator: 0.031197,\n",
      "D(x): 0.347, D(G(z)): 0.369\n",
      "2019-04-10 00:57:35,543 root         INFO     Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 0.570323\n",
      "Reconstruction: 0.491375, Regularization: 0.000336, Discriminator: 0.047310; Generator: 0.031302,\n",
      "D(x): 0.348, D(G(z)): 0.367\n",
      "2019-04-10 00:57:35,655 root         INFO     Train Epoch: 75 [6656/8000 (83%)]\tTotal Loss: 0.570512\n",
      "Reconstruction: 0.491477, Regularization: 0.000333, Discriminator: 0.047288; Generator: 0.031413,\n",
      "D(x): 0.347, D(G(z)): 0.366\n",
      "2019-04-10 00:57:35,766 root         INFO     Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 0.570526\n",
      "Reconstruction: 0.491549, Regularization: 0.000314, Discriminator: 0.047139; Generator: 0.031524,\n",
      "D(x): 0.348, D(G(z)): 0.365\n",
      "2019-04-10 00:57:35,877 root         INFO     Train Epoch: 75 [7680/8000 (96%)]\tTotal Loss: 0.570726\n",
      "Reconstruction: 0.491622, Regularization: 0.000271, Discriminator: 0.047214; Generator: 0.031619,\n",
      "D(x): 0.347, D(G(z)): 0.364\n",
      "2019-04-10 00:57:35,957 root         INFO     ====> Epoch: 75 Average loss: 0.5694\n",
      "2019-04-10 00:57:35,985 root         INFO     Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 0.570879\n",
      "Reconstruction: 0.491670, Regularization: 0.000289, Discriminator: 0.047225; Generator: 0.031695,\n",
      "D(x): 0.346, D(G(z)): 0.363\n",
      "2019-04-10 00:57:36,096 root         INFO     Train Epoch: 76 [512/8000 (6%)]\tTotal Loss: 0.570628\n",
      "Reconstruction: 0.491571, Regularization: 0.000139, Discriminator: 0.047061; Generator: 0.031856,\n",
      "D(x): 0.347, D(G(z)): 0.361\n",
      "2019-04-10 00:57:36,208 root         INFO     Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 0.570851\n",
      "Reconstruction: 0.491667, Regularization: 0.000216, Discriminator: 0.047015; Generator: 0.031953,\n",
      "D(x): 0.347, D(G(z)): 0.360\n",
      "2019-04-10 00:57:36,320 root         INFO     Train Epoch: 76 [1536/8000 (19%)]\tTotal Loss: 0.570981\n",
      "Reconstruction: 0.491712, Regularization: 0.000240, Discriminator: 0.047013; Generator: 0.032016,\n",
      "D(x): 0.347, D(G(z)): 0.359\n",
      "2019-04-10 00:57:36,431 root         INFO     Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 0.570920\n",
      "Reconstruction: 0.491861, Regularization: 0.000172, Discriminator: 0.046853; Generator: 0.032034,\n",
      "D(x): 0.348, D(G(z)): 0.359\n",
      "2019-04-10 00:57:36,543 root         INFO     Train Epoch: 76 [2560/8000 (32%)]\tTotal Loss: 0.570826\n",
      "Reconstruction: 0.491628, Regularization: 0.000271, Discriminator: 0.046848; Generator: 0.032079,\n",
      "D(x): 0.348, D(G(z)): 0.358\n",
      "2019-04-10 00:57:36,654 root         INFO     Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 0.571017\n",
      "Reconstruction: 0.491869, Regularization: 0.000247, Discriminator: 0.046754; Generator: 0.032146,\n",
      "D(x): 0.349, D(G(z)): 0.357\n",
      "2019-04-10 00:57:36,765 root         INFO     Train Epoch: 76 [3584/8000 (45%)]\tTotal Loss: 0.570874\n",
      "Reconstruction: 0.491698, Regularization: 0.000171, Discriminator: 0.046760; Generator: 0.032245,\n",
      "D(x): 0.348, D(G(z)): 0.356\n",
      "2019-04-10 00:57:36,877 root         INFO     Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 0.570831\n",
      "Reconstruction: 0.491687, Regularization: 0.000203, Discriminator: 0.046675; Generator: 0.032265,\n",
      "D(x): 0.349, D(G(z)): 0.356\n",
      "2019-04-10 00:57:36,988 root         INFO     Train Epoch: 76 [4608/8000 (58%)]\tTotal Loss: 0.570978\n",
      "Reconstruction: 0.491752, Regularization: 0.000207, Discriminator: 0.046698; Generator: 0.032321,\n",
      "D(x): 0.348, D(G(z)): 0.355\n",
      "2019-04-10 00:57:37,099 root         INFO     Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 0.571118\n",
      "Reconstruction: 0.491793, Regularization: 0.000302, Discriminator: 0.046638; Generator: 0.032385,\n",
      "D(x): 0.348, D(G(z)): 0.355\n",
      "2019-04-10 00:57:37,211 root         INFO     Train Epoch: 76 [5632/8000 (70%)]\tTotal Loss: 0.571089\n",
      "Reconstruction: 0.491714, Regularization: 0.000275, Discriminator: 0.046652; Generator: 0.032448,\n",
      "D(x): 0.348, D(G(z)): 0.354\n",
      "2019-04-10 00:57:37,322 root         INFO     Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 0.571089\n",
      "Reconstruction: 0.491730, Regularization: 0.000268, Discriminator: 0.046523; Generator: 0.032568,\n",
      "D(x): 0.349, D(G(z)): 0.353\n",
      "2019-04-10 00:57:37,433 root         INFO     Train Epoch: 76 [6656/8000 (83%)]\tTotal Loss: 0.571002\n",
      "Reconstruction: 0.491561, Regularization: 0.000303, Discriminator: 0.046511; Generator: 0.032627,\n",
      "D(x): 0.348, D(G(z)): 0.352\n",
      "2019-04-10 00:57:37,545 root         INFO     Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 0.571198\n",
      "Reconstruction: 0.491660, Regularization: 0.000351, Discriminator: 0.046474; Generator: 0.032712,\n",
      "D(x): 0.348, D(G(z)): 0.351\n",
      "2019-04-10 00:57:37,657 root         INFO     Train Epoch: 76 [7680/8000 (96%)]\tTotal Loss: 0.571303\n",
      "Reconstruction: 0.491760, Regularization: 0.000330, Discriminator: 0.046415; Generator: 0.032797,\n",
      "D(x): 0.348, D(G(z)): 0.350\n",
      "2019-04-10 00:57:37,738 root         INFO     ====> Epoch: 76 Average loss: 0.5710\n",
      "2019-04-10 00:57:37,765 root         INFO     Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 0.571264\n",
      "Reconstruction: 0.491585, Regularization: 0.000450, Discriminator: 0.046403; Generator: 0.032826,\n",
      "D(x): 0.348, D(G(z)): 0.350\n",
      "2019-04-10 00:57:37,876 root         INFO     Train Epoch: 77 [512/8000 (6%)]\tTotal Loss: 0.571064\n",
      "Reconstruction: 0.491607, Regularization: 0.000225, Discriminator: 0.046360; Generator: 0.032873,\n",
      "D(x): 0.349, D(G(z)): 0.349\n",
      "2019-04-10 00:57:37,987 root         INFO     Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 0.571100\n",
      "Reconstruction: 0.491578, Regularization: 0.000318, Discriminator: 0.046305; Generator: 0.032899,\n",
      "D(x): 0.349, D(G(z)): 0.349\n",
      "2019-04-10 00:57:38,098 root         INFO     Train Epoch: 77 [1536/8000 (19%)]\tTotal Loss: 0.570882\n",
      "Reconstruction: 0.491489, Regularization: 0.000198, Discriminator: 0.046259; Generator: 0.032936,\n",
      "D(x): 0.349, D(G(z)): 0.349\n",
      "2019-04-10 00:57:38,207 root         INFO     Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 0.570887\n",
      "Reconstruction: 0.491439, Regularization: 0.000239, Discriminator: 0.046231; Generator: 0.032977,\n",
      "D(x): 0.349, D(G(z)): 0.348\n",
      "2019-04-10 00:57:38,317 root         INFO     Train Epoch: 77 [2560/8000 (32%)]\tTotal Loss: 0.570909\n",
      "Reconstruction: 0.491452, Regularization: 0.000246, Discriminator: 0.046199; Generator: 0.033013,\n",
      "D(x): 0.350, D(G(z)): 0.348\n",
      "2019-04-10 00:57:38,426 root         INFO     Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 0.570908\n",
      "Reconstruction: 0.491488, Regularization: 0.000241, Discriminator: 0.046115; Generator: 0.033064,\n",
      "D(x): 0.350, D(G(z)): 0.347\n",
      "2019-04-10 00:57:38,535 root         INFO     Train Epoch: 77 [3584/8000 (45%)]\tTotal Loss: 0.570965\n",
      "Reconstruction: 0.491378, Regularization: 0.000376, Discriminator: 0.046076; Generator: 0.033135,\n",
      "D(x): 0.350, D(G(z)): 0.346\n",
      "2019-04-10 00:57:38,645 root         INFO     Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 0.570977\n",
      "Reconstruction: 0.491437, Regularization: 0.000284, Discriminator: 0.046034; Generator: 0.033222,\n",
      "D(x): 0.350, D(G(z)): 0.345\n",
      "2019-04-10 00:57:38,754 root         INFO     Train Epoch: 77 [4608/8000 (58%)]\tTotal Loss: 0.570702\n",
      "Reconstruction: 0.491237, Regularization: 0.000186, Discriminator: 0.046038; Generator: 0.033242,\n",
      "D(x): 0.350, D(G(z)): 0.345\n",
      "2019-04-10 00:57:38,864 root         INFO     Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 0.570976\n",
      "Reconstruction: 0.491303, Regularization: 0.000370, Discriminator: 0.046009; Generator: 0.033294,\n",
      "D(x): 0.350, D(G(z)): 0.345\n",
      "2019-04-10 00:57:38,973 root         INFO     Train Epoch: 77 [5632/8000 (70%)]\tTotal Loss: 0.570890\n",
      "Reconstruction: 0.491437, Regularization: 0.000202, Discriminator: 0.045922; Generator: 0.033328,\n",
      "D(x): 0.351, D(G(z)): 0.344\n",
      "2019-04-10 00:57:39,082 root         INFO     Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 0.570890\n",
      "Reconstruction: 0.491447, Regularization: 0.000265, Discriminator: 0.045831; Generator: 0.033347,\n",
      "D(x): 0.352, D(G(z)): 0.344\n",
      "2019-04-10 00:57:39,191 root         INFO     Train Epoch: 77 [6656/8000 (83%)]\tTotal Loss: 0.570726\n",
      "Reconstruction: 0.491230, Regularization: 0.000300, Discriminator: 0.045831; Generator: 0.033365,\n",
      "D(x): 0.352, D(G(z)): 0.344\n",
      "2019-04-10 00:57:39,301 root         INFO     Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 0.570899\n",
      "Reconstruction: 0.491468, Regularization: 0.000237, Discriminator: 0.045823; Generator: 0.033370,\n",
      "D(x): 0.352, D(G(z)): 0.344\n",
      "2019-04-10 00:57:39,410 root         INFO     Train Epoch: 77 [7680/8000 (96%)]\tTotal Loss: 0.570776\n",
      "Reconstruction: 0.491283, Regularization: 0.000286, Discriminator: 0.045770; Generator: 0.033437,\n",
      "D(x): 0.352, D(G(z)): 0.343\n",
      "2019-04-10 00:57:39,490 root         INFO     ====> Epoch: 77 Average loss: 0.5709\n",
      "2019-04-10 00:57:39,517 root         INFO     Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 0.570713\n",
      "Reconstruction: 0.491221, Regularization: 0.000290, Discriminator: 0.045785; Generator: 0.033417,\n",
      "D(x): 0.352, D(G(z)): 0.343\n",
      "2019-04-10 00:57:39,630 root         INFO     Train Epoch: 78 [512/8000 (6%)]\tTotal Loss: 0.570840\n",
      "Reconstruction: 0.491242, Regularization: 0.000321, Discriminator: 0.045765; Generator: 0.033513,\n",
      "D(x): 0.351, D(G(z)): 0.342\n",
      "2019-04-10 00:57:39,743 root         INFO     Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 0.570698\n",
      "Reconstruction: 0.491272, Regularization: 0.000308, Discriminator: 0.045592; Generator: 0.033527,\n",
      "D(x): 0.353, D(G(z)): 0.342\n",
      "2019-04-10 00:57:39,855 root         INFO     Train Epoch: 78 [1536/8000 (19%)]\tTotal Loss: 0.570572\n",
      "Reconstruction: 0.491165, Regularization: 0.000294, Discriminator: 0.045602; Generator: 0.033511,\n",
      "D(x): 0.353, D(G(z)): 0.342\n",
      "2019-04-10 00:57:39,967 root         INFO     Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 0.570598\n",
      "Reconstruction: 0.491230, Regularization: 0.000248, Discriminator: 0.045560; Generator: 0.033560,\n",
      "D(x): 0.354, D(G(z)): 0.342\n",
      "2019-04-10 00:57:40,077 root         INFO     Train Epoch: 78 [2560/8000 (32%)]\tTotal Loss: 0.570281\n",
      "Reconstruction: 0.491023, Regularization: 0.000200, Discriminator: 0.045492; Generator: 0.033566,\n",
      "D(x): 0.354, D(G(z)): 0.342\n",
      "2019-04-10 00:57:40,187 root         INFO     Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 0.570353\n",
      "Reconstruction: 0.490959, Regularization: 0.000302, Discriminator: 0.045537; Generator: 0.033554,\n",
      "D(x): 0.354, D(G(z)): 0.342\n",
      "2019-04-10 00:57:40,298 root         INFO     Train Epoch: 78 [3584/8000 (45%)]\tTotal Loss: 0.570224\n",
      "Reconstruction: 0.490821, Regularization: 0.000218, Discriminator: 0.045618; Generator: 0.033568,\n",
      "D(x): 0.353, D(G(z)): 0.342\n",
      "2019-04-10 00:57:40,408 root         INFO     Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 0.570164\n",
      "Reconstruction: 0.490809, Regularization: 0.000395, Discriminator: 0.045352; Generator: 0.033608,\n",
      "D(x): 0.356, D(G(z)): 0.341\n",
      "2019-04-10 00:57:40,519 root         INFO     Train Epoch: 78 [4608/8000 (58%)]\tTotal Loss: 0.569971\n",
      "Reconstruction: 0.490908, Regularization: 0.000225, Discriminator: 0.045266; Generator: 0.033572,\n",
      "D(x): 0.357, D(G(z)): 0.342\n",
      "2019-04-10 00:57:40,629 root         INFO     Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 0.569841\n",
      "Reconstruction: 0.490634, Regularization: 0.000381, Discriminator: 0.045171; Generator: 0.033655,\n",
      "D(x): 0.357, D(G(z)): 0.341\n",
      "2019-04-10 00:57:40,739 root         INFO     Train Epoch: 78 [5632/8000 (70%)]\tTotal Loss: 0.569894\n",
      "Reconstruction: 0.490512, Regularization: 0.000322, Discriminator: 0.045374; Generator: 0.033687,\n",
      "D(x): 0.355, D(G(z)): 0.340\n",
      "2019-04-10 00:57:40,849 root         INFO     Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 0.569663\n",
      "Reconstruction: 0.490502, Regularization: 0.000251, Discriminator: 0.045129; Generator: 0.033781,\n",
      "D(x): 0.357, D(G(z)): 0.339\n",
      "2019-04-10 00:57:40,960 root         INFO     Train Epoch: 78 [6656/8000 (83%)]\tTotal Loss: 0.569402\n",
      "Reconstruction: 0.490262, Regularization: 0.000202, Discriminator: 0.045151; Generator: 0.033787,\n",
      "D(x): 0.357, D(G(z)): 0.339\n",
      "2019-04-10 00:57:41,070 root         INFO     Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 0.569640\n",
      "Reconstruction: 0.490298, Regularization: 0.000342, Discriminator: 0.045173; Generator: 0.033826,\n",
      "D(x): 0.356, D(G(z)): 0.339\n",
      "2019-04-10 00:57:41,180 root         INFO     Train Epoch: 78 [7680/8000 (96%)]\tTotal Loss: 0.569183\n",
      "Reconstruction: 0.490163, Regularization: 0.000195, Discriminator: 0.044994; Generator: 0.033831,\n",
      "D(x): 0.358, D(G(z)): 0.339\n",
      "2019-04-10 00:57:41,261 root         INFO     ====> Epoch: 78 Average loss: 0.5701\n",
      "2019-04-10 00:57:41,288 root         INFO     Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 0.568726\n",
      "Reconstruction: 0.489876, Regularization: 0.000159, Discriminator: 0.044860; Generator: 0.033831,\n",
      "D(x): 0.360, D(G(z)): 0.339\n",
      "2019-04-10 00:57:41,401 root         INFO     Train Epoch: 79 [512/8000 (6%)]\tTotal Loss: 0.568638\n",
      "Reconstruction: 0.489787, Regularization: 0.000288, Discriminator: 0.044685; Generator: 0.033878,\n",
      "D(x): 0.362, D(G(z)): 0.338\n",
      "2019-04-10 00:57:41,513 root         INFO     Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 0.568839\n",
      "Reconstruction: 0.489495, Regularization: 0.000238, Discriminator: 0.045251; Generator: 0.033855,\n",
      "D(x): 0.355, D(G(z)): 0.338\n",
      "2019-04-10 00:57:41,625 root         INFO     Train Epoch: 79 [1536/8000 (19%)]\tTotal Loss: 0.568019\n",
      "Reconstruction: 0.489112, Regularization: 0.000220, Discriminator: 0.044896; Generator: 0.033789,\n",
      "D(x): 0.360, D(G(z)): 0.339\n",
      "2019-04-10 00:57:41,737 root         INFO     Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 0.567785\n",
      "Reconstruction: 0.489123, Regularization: 0.000154, Discriminator: 0.044687; Generator: 0.033821,\n",
      "D(x): 0.362, D(G(z)): 0.339\n",
      "2019-04-10 00:57:41,850 root         INFO     Train Epoch: 79 [2560/8000 (32%)]\tTotal Loss: 0.567637\n",
      "Reconstruction: 0.488808, Regularization: 0.000350, Discriminator: 0.044642; Generator: 0.033836,\n",
      "D(x): 0.363, D(G(z)): 0.339\n",
      "2019-04-10 00:57:41,961 root         INFO     Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 0.567198\n",
      "Reconstruction: 0.488554, Regularization: 0.000269, Discriminator: 0.044577; Generator: 0.033797,\n",
      "D(x): 0.363, D(G(z)): 0.339\n",
      "2019-04-10 00:57:42,073 root         INFO     Train Epoch: 79 [3584/8000 (45%)]\tTotal Loss: 0.567055\n",
      "Reconstruction: 0.488474, Regularization: 0.000419, Discriminator: 0.044387; Generator: 0.033774,\n",
      "D(x): 0.366, D(G(z)): 0.339\n",
      "2019-04-10 00:57:42,185 root         INFO     Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 0.566319\n",
      "Reconstruction: 0.488063, Regularization: 0.000244, Discriminator: 0.044308; Generator: 0.033705,\n",
      "D(x): 0.367, D(G(z)): 0.340\n",
      "2019-04-10 00:57:42,297 root         INFO     Train Epoch: 79 [4608/8000 (58%)]\tTotal Loss: 0.565936\n",
      "Reconstruction: 0.487567, Regularization: 0.000259, Discriminator: 0.044502; Generator: 0.033609,\n",
      "D(x): 0.366, D(G(z)): 0.341\n",
      "2019-04-10 00:57:42,407 root         INFO     Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 0.565629\n",
      "Reconstruction: 0.487406, Regularization: 0.000303, Discriminator: 0.044403; Generator: 0.033517,\n",
      "D(x): 0.367, D(G(z)): 0.342\n",
      "2019-04-10 00:57:42,517 root         INFO     Train Epoch: 79 [5632/8000 (70%)]\tTotal Loss: 0.565306\n",
      "Reconstruction: 0.487234, Regularization: 0.000251, Discriminator: 0.044391; Generator: 0.033430,\n",
      "D(x): 0.368, D(G(z)): 0.343\n",
      "2019-04-10 00:57:42,627 root         INFO     Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 0.564960\n",
      "Reconstruction: 0.486866, Regularization: 0.000205, Discriminator: 0.044561; Generator: 0.033327,\n",
      "D(x): 0.366, D(G(z)): 0.344\n",
      "2019-04-10 00:57:42,737 root         INFO     Train Epoch: 79 [6656/8000 (83%)]\tTotal Loss: 0.564003\n",
      "Reconstruction: 0.486527, Regularization: 0.000184, Discriminator: 0.044140; Generator: 0.033151,\n",
      "D(x): 0.373, D(G(z)): 0.346\n",
      "2019-04-10 00:57:42,848 root         INFO     Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 0.563162\n",
      "Reconstruction: 0.486069, Regularization: 0.000226, Discriminator: 0.043875; Generator: 0.032991,\n",
      "D(x): 0.377, D(G(z)): 0.348\n",
      "2019-04-10 00:57:42,958 root         INFO     Train Epoch: 79 [7680/8000 (96%)]\tTotal Loss: 0.562701\n",
      "Reconstruction: 0.485862, Regularization: 0.000256, Discriminator: 0.043789; Generator: 0.032795,\n",
      "D(x): 0.379, D(G(z)): 0.350\n",
      "2019-04-10 00:57:43,039 root         INFO     ====> Epoch: 79 Average loss: 0.5662\n",
      "2019-04-10 00:57:43,067 root         INFO     Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 0.562259\n",
      "Reconstruction: 0.485543, Regularization: 0.000203, Discriminator: 0.043859; Generator: 0.032654,\n",
      "D(x): 0.379, D(G(z)): 0.352\n",
      "2019-04-10 00:57:43,179 root         INFO     Train Epoch: 80 [512/8000 (6%)]\tTotal Loss: 0.561558\n",
      "Reconstruction: 0.485282, Regularization: 0.000186, Discriminator: 0.043721; Generator: 0.032369,\n",
      "D(x): 0.383, D(G(z)): 0.355\n",
      "2019-04-10 00:57:43,291 root         INFO     Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 0.560864\n",
      "Reconstruction: 0.484996, Regularization: 0.000326, Discriminator: 0.043405; Generator: 0.032138,\n",
      "D(x): 0.388, D(G(z)): 0.358\n",
      "2019-04-10 00:57:43,403 root         INFO     Train Epoch: 80 [1536/8000 (19%)]\tTotal Loss: 0.560275\n",
      "Reconstruction: 0.484792, Regularization: 0.000193, Discriminator: 0.043446; Generator: 0.031845,\n",
      "D(x): 0.390, D(G(z)): 0.361\n",
      "2019-04-10 00:57:43,515 root         INFO     Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 0.559839\n",
      "Reconstruction: 0.484601, Regularization: 0.000278, Discriminator: 0.043365; Generator: 0.031595,\n",
      "D(x): 0.393, D(G(z)): 0.364\n",
      "2019-04-10 00:57:43,626 root         INFO     Train Epoch: 80 [2560/8000 (32%)]\tTotal Loss: 0.559187\n",
      "Reconstruction: 0.484292, Regularization: 0.000247, Discriminator: 0.043260; Generator: 0.031388,\n",
      "D(x): 0.395, D(G(z)): 0.366\n",
      "2019-04-10 00:57:43,738 root         INFO     Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 0.558173\n",
      "Reconstruction: 0.484097, Regularization: 0.000208, Discriminator: 0.042823; Generator: 0.031044,\n",
      "D(x): 0.404, D(G(z)): 0.370\n",
      "2019-04-10 00:57:43,849 root         INFO     Train Epoch: 80 [3584/8000 (45%)]\tTotal Loss: 0.557735\n",
      "Reconstruction: 0.483777, Regularization: 0.000313, Discriminator: 0.042889; Generator: 0.030756,\n",
      "D(x): 0.405, D(G(z)): 0.374\n",
      "2019-04-10 00:57:43,961 root         INFO     Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 0.557221\n",
      "Reconstruction: 0.483355, Regularization: 0.000148, Discriminator: 0.043182; Generator: 0.030537,\n",
      "D(x): 0.403, D(G(z)): 0.376\n",
      "2019-04-10 00:57:44,073 root         INFO     Train Epoch: 80 [4608/8000 (58%)]\tTotal Loss: 0.556436\n",
      "Reconstruction: 0.482903, Regularization: 0.000322, Discriminator: 0.042856; Generator: 0.030355,\n",
      "D(x): 0.409, D(G(z)): 0.379\n",
      "2019-04-10 00:57:44,183 root         INFO     Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 0.555964\n",
      "Reconstruction: 0.482717, Regularization: 0.000382, Discriminator: 0.042690; Generator: 0.030175,\n",
      "D(x): 0.412, D(G(z)): 0.381\n",
      "2019-04-10 00:57:44,292 root         INFO     Train Epoch: 80 [5632/8000 (70%)]\tTotal Loss: 0.555107\n",
      "Reconstruction: 0.482319, Regularization: 0.000205, Discriminator: 0.042547; Generator: 0.030036,\n",
      "D(x): 0.415, D(G(z)): 0.382\n",
      "2019-04-10 00:57:44,402 root         INFO     Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 0.554462\n",
      "Reconstruction: 0.481713, Regularization: 0.000235, Discriminator: 0.042517; Generator: 0.029997,\n",
      "D(x): 0.416, D(G(z)): 0.383\n",
      "2019-04-10 00:57:44,511 root         INFO     Train Epoch: 80 [6656/8000 (83%)]\tTotal Loss: 0.553534\n",
      "Reconstruction: 0.481144, Regularization: 0.000233, Discriminator: 0.042179; Generator: 0.029979,\n",
      "D(x): 0.421, D(G(z)): 0.383\n",
      "2019-04-10 00:57:44,621 root         INFO     Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 0.553146\n",
      "Reconstruction: 0.480628, Regularization: 0.000208, Discriminator: 0.042359; Generator: 0.029950,\n",
      "D(x): 0.419, D(G(z)): 0.384\n",
      "2019-04-10 00:57:44,731 root         INFO     Train Epoch: 80 [7680/8000 (96%)]\tTotal Loss: 0.552080\n",
      "Reconstruction: 0.479899, Regularization: 0.000247, Discriminator: 0.041952; Generator: 0.029982,\n",
      "D(x): 0.424, D(G(z)): 0.383\n",
      "2019-04-10 00:57:44,812 root         INFO     ====> Epoch: 80 Average loss: 0.5571\n",
      "2019-04-10 00:57:44,839 root         INFO     Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 0.551755\n",
      "Reconstruction: 0.479390, Regularization: 0.000171, Discriminator: 0.042228; Generator: 0.029966,\n",
      "D(x): 0.420, D(G(z)): 0.383\n",
      "2019-04-10 00:57:44,952 root         INFO     Train Epoch: 81 [512/8000 (6%)]\tTotal Loss: 0.550990\n",
      "Reconstruction: 0.478683, Regularization: 0.000256, Discriminator: 0.042229; Generator: 0.029822,\n",
      "D(x): 0.421, D(G(z)): 0.385\n",
      "2019-04-10 00:57:45,064 root         INFO     Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 0.549458\n",
      "Reconstruction: 0.477807, Regularization: 0.000261, Discriminator: 0.041675; Generator: 0.029714,\n",
      "D(x): 0.430, D(G(z)): 0.386\n",
      "2019-04-10 00:57:45,176 root         INFO     Train Epoch: 81 [1536/8000 (19%)]\tTotal Loss: 0.549086\n",
      "Reconstruction: 0.477538, Regularization: 0.000265, Discriminator: 0.041626; Generator: 0.029657,\n",
      "D(x): 0.431, D(G(z)): 0.387\n",
      "2019-04-10 00:57:45,288 root         INFO     Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 0.548390\n",
      "Reconstruction: 0.477018, Regularization: 0.000257, Discriminator: 0.041347; Generator: 0.029769,\n",
      "D(x): 0.434, D(G(z)): 0.386\n",
      "2019-04-10 00:57:45,399 root         INFO     Train Epoch: 81 [2560/8000 (32%)]\tTotal Loss: 0.548519\n",
      "Reconstruction: 0.476756, Regularization: 0.000293, Discriminator: 0.041670; Generator: 0.029799,\n",
      "D(x): 0.429, D(G(z)): 0.385\n",
      "2019-04-10 00:57:45,510 root         INFO     Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 0.547455\n",
      "Reconstruction: 0.476302, Regularization: 0.000281, Discriminator: 0.041095; Generator: 0.029778,\n",
      "D(x): 0.437, D(G(z)): 0.386\n",
      "2019-04-10 00:57:45,622 root         INFO     Train Epoch: 81 [3584/8000 (45%)]\tTotal Loss: 0.547346\n",
      "Reconstruction: 0.475923, Regularization: 0.000148, Discriminator: 0.041455; Generator: 0.029821,\n",
      "D(x): 0.432, D(G(z)): 0.385\n",
      "2019-04-10 00:57:45,733 root         INFO     Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 0.546381\n",
      "Reconstruction: 0.475440, Regularization: 0.000343, Discriminator: 0.040900; Generator: 0.029697,\n",
      "D(x): 0.441, D(G(z)): 0.387\n",
      "2019-04-10 00:57:45,845 root         INFO     Train Epoch: 81 [4608/8000 (58%)]\tTotal Loss: 0.546445\n",
      "Reconstruction: 0.474752, Regularization: 0.000256, Discriminator: 0.041590; Generator: 0.029847,\n",
      "D(x): 0.430, D(G(z)): 0.385\n",
      "2019-04-10 00:57:45,956 root         INFO     Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 0.545159\n",
      "Reconstruction: 0.474340, Regularization: 0.000246, Discriminator: 0.040698; Generator: 0.029875,\n",
      "D(x): 0.442, D(G(z)): 0.384\n",
      "2019-04-10 00:57:46,067 root         INFO     Train Epoch: 81 [5632/8000 (70%)]\tTotal Loss: 0.544949\n",
      "Reconstruction: 0.473405, Regularization: 0.000410, Discriminator: 0.041229; Generator: 0.029905,\n",
      "D(x): 0.435, D(G(z)): 0.384\n",
      "2019-04-10 00:57:46,178 root         INFO     Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 0.543623\n",
      "Reconstruction: 0.472438, Regularization: 0.000228, Discriminator: 0.041097; Generator: 0.029860,\n",
      "D(x): 0.437, D(G(z)): 0.385\n",
      "2019-04-10 00:57:46,289 root         INFO     Train Epoch: 81 [6656/8000 (83%)]\tTotal Loss: 0.542305\n",
      "Reconstruction: 0.471841, Regularization: 0.000295, Discriminator: 0.040683; Generator: 0.029487,\n",
      "D(x): 0.446, D(G(z)): 0.389\n",
      "2019-04-10 00:57:46,400 root         INFO     Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 0.541438\n",
      "Reconstruction: 0.470906, Regularization: 0.000220, Discriminator: 0.040604; Generator: 0.029709,\n",
      "D(x): 0.445, D(G(z)): 0.386\n",
      "2019-04-10 00:57:46,510 root         INFO     Train Epoch: 81 [7680/8000 (96%)]\tTotal Loss: 0.541170\n",
      "Reconstruction: 0.470075, Regularization: 0.000291, Discriminator: 0.041232; Generator: 0.029571,\n",
      "D(x): 0.438, D(G(z)): 0.388\n",
      "2019-04-10 00:57:46,592 root         INFO     ====> Epoch: 81 Average loss: 0.5462\n",
      "2019-04-10 00:57:46,619 root         INFO     Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 0.539903\n",
      "Reconstruction: 0.469451, Regularization: 0.000180, Discriminator: 0.040480; Generator: 0.029792,\n",
      "D(x): 0.446, D(G(z)): 0.385\n",
      "2019-04-10 00:57:46,731 root         INFO     Train Epoch: 82 [512/8000 (6%)]\tTotal Loss: 0.539149\n",
      "Reconstruction: 0.468484, Regularization: 0.000251, Discriminator: 0.040501; Generator: 0.029913,\n",
      "D(x): 0.445, D(G(z)): 0.384\n",
      "2019-04-10 00:57:46,843 root         INFO     Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 0.538467\n",
      "Reconstruction: 0.467538, Regularization: 0.000136, Discriminator: 0.040841; Generator: 0.029952,\n",
      "D(x): 0.440, D(G(z)): 0.383\n",
      "2019-04-10 00:57:46,954 root         INFO     Train Epoch: 82 [1536/8000 (19%)]\tTotal Loss: 0.536545\n",
      "Reconstruction: 0.466492, Regularization: 0.000126, Discriminator: 0.040433; Generator: 0.029494,\n",
      "D(x): 0.450, D(G(z)): 0.389\n",
      "2019-04-10 00:57:47,065 root         INFO     Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 0.534882\n",
      "Reconstruction: 0.465745, Regularization: 0.000210, Discriminator: 0.039668; Generator: 0.029259,\n",
      "D(x): 0.463, D(G(z)): 0.392\n",
      "2019-04-10 00:57:47,177 root         INFO     Train Epoch: 82 [2560/8000 (32%)]\tTotal Loss: 0.533771\n",
      "Reconstruction: 0.464914, Regularization: 0.000248, Discriminator: 0.039350; Generator: 0.029259,\n",
      "D(x): 0.468, D(G(z)): 0.392\n",
      "2019-04-10 00:57:47,288 root         INFO     Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 0.534014\n",
      "Reconstruction: 0.464128, Regularization: 0.000242, Discriminator: 0.040038; Generator: 0.029606,\n",
      "D(x): 0.454, D(G(z)): 0.388\n",
      "2019-04-10 00:57:47,399 root         INFO     Train Epoch: 82 [3584/8000 (45%)]\tTotal Loss: 0.533374\n",
      "Reconstruction: 0.463539, Regularization: 0.000253, Discriminator: 0.040420; Generator: 0.029162,\n",
      "D(x): 0.453, D(G(z)): 0.393\n",
      "2019-04-10 00:57:47,510 root         INFO     Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 0.532149\n",
      "Reconstruction: 0.462831, Regularization: 0.000116, Discriminator: 0.039929; Generator: 0.029273,\n",
      "D(x): 0.459, D(G(z)): 0.392\n",
      "2019-04-10 00:57:47,622 root         INFO     Train Epoch: 82 [4608/8000 (58%)]\tTotal Loss: 0.531245\n",
      "Reconstruction: 0.461722, Regularization: 0.000348, Discriminator: 0.039450; Generator: 0.029725,\n",
      "D(x): 0.463, D(G(z)): 0.386\n",
      "2019-04-10 00:57:47,733 root         INFO     Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 0.529878\n",
      "Reconstruction: 0.460304, Regularization: 0.000238, Discriminator: 0.040190; Generator: 0.029147,\n",
      "D(x): 0.457, D(G(z)): 0.393\n",
      "2019-04-10 00:57:47,844 root         INFO     Train Epoch: 82 [5632/8000 (70%)]\tTotal Loss: 0.528521\n",
      "Reconstruction: 0.459561, Regularization: 0.000328, Discriminator: 0.039572; Generator: 0.029059,\n",
      "D(x): 0.468, D(G(z)): 0.395\n",
      "2019-04-10 00:57:47,955 root         INFO     Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 0.526968\n",
      "Reconstruction: 0.458015, Regularization: 0.000271, Discriminator: 0.039655; Generator: 0.029027,\n",
      "D(x): 0.466, D(G(z)): 0.395\n",
      "2019-04-10 00:57:48,066 root         INFO     Train Epoch: 82 [6656/8000 (83%)]\tTotal Loss: 0.526905\n",
      "Reconstruction: 0.457035, Regularization: 0.000238, Discriminator: 0.040084; Generator: 0.029548,\n",
      "D(x): 0.455, D(G(z)): 0.388\n",
      "2019-04-10 00:57:48,177 root         INFO     Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 0.524141\n",
      "Reconstruction: 0.455081, Regularization: 0.000165, Discriminator: 0.040146; Generator: 0.028749,\n",
      "D(x): 0.461, D(G(z)): 0.399\n",
      "2019-04-10 00:57:48,288 root         INFO     Train Epoch: 82 [7680/8000 (96%)]\tTotal Loss: 0.521894\n",
      "Reconstruction: 0.453622, Regularization: 0.000339, Discriminator: 0.039282; Generator: 0.028651,\n",
      "D(x): 0.477, D(G(z)): 0.400\n",
      "2019-04-10 00:57:48,369 root         INFO     ====> Epoch: 82 Average loss: 0.5317\n",
      "2019-04-10 00:57:48,397 root         INFO     Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 0.521195\n",
      "Reconstruction: 0.453317, Regularization: 0.000153, Discriminator: 0.038829; Generator: 0.028895,\n",
      "D(x): 0.479, D(G(z)): 0.397\n",
      "2019-04-10 00:57:48,508 root         INFO     Train Epoch: 83 [512/8000 (6%)]\tTotal Loss: 0.520007\n",
      "Reconstruction: 0.451497, Regularization: 0.000215, Discriminator: 0.039667; Generator: 0.028628,\n",
      "D(x): 0.470, D(G(z)): 0.400\n",
      "2019-04-10 00:57:48,619 root         INFO     Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 0.519209\n",
      "Reconstruction: 0.450366, Regularization: 0.000228, Discriminator: 0.039959; Generator: 0.028656,\n",
      "D(x): 0.465, D(G(z)): 0.400\n",
      "2019-04-10 00:57:48,729 root         INFO     Train Epoch: 83 [1536/8000 (19%)]\tTotal Loss: 0.518707\n",
      "Reconstruction: 0.449812, Regularization: 0.000347, Discriminator: 0.040023; Generator: 0.028525,\n",
      "D(x): 0.467, D(G(z)): 0.401\n",
      "2019-04-10 00:57:48,840 root         INFO     Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 0.517563\n",
      "Reconstruction: 0.448334, Regularization: 0.000218, Discriminator: 0.040240; Generator: 0.028771,\n",
      "D(x): 0.461, D(G(z)): 0.398\n",
      "2019-04-10 00:57:48,950 root         INFO     Train Epoch: 83 [2560/8000 (32%)]\tTotal Loss: 0.516273\n",
      "Reconstruction: 0.447997, Regularization: 0.000149, Discriminator: 0.039559; Generator: 0.028568,\n",
      "D(x): 0.472, D(G(z)): 0.401\n",
      "2019-04-10 00:57:49,061 root         INFO     Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 0.514821\n",
      "Reconstruction: 0.446487, Regularization: 0.000167, Discriminator: 0.039416; Generator: 0.028751,\n",
      "D(x): 0.474, D(G(z)): 0.399\n",
      "2019-04-10 00:57:49,171 root         INFO     Train Epoch: 83 [3584/8000 (45%)]\tTotal Loss: 0.512523\n",
      "Reconstruction: 0.445191, Regularization: 0.000265, Discriminator: 0.038889; Generator: 0.028178,\n",
      "D(x): 0.488, D(G(z)): 0.406\n",
      "2019-04-10 00:57:49,281 root         INFO     Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 0.511130\n",
      "Reconstruction: 0.443393, Regularization: 0.000302, Discriminator: 0.039353; Generator: 0.028083,\n",
      "D(x): 0.481, D(G(z)): 0.407\n",
      "2019-04-10 00:57:49,392 root         INFO     Train Epoch: 83 [4608/8000 (58%)]\tTotal Loss: 0.509506\n",
      "Reconstruction: 0.441688, Regularization: 0.000291, Discriminator: 0.039644; Generator: 0.027884,\n",
      "D(x): 0.480, D(G(z)): 0.410\n",
      "2019-04-10 00:57:49,502 root         INFO     Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 0.508886\n",
      "Reconstruction: 0.440647, Regularization: 0.000195, Discriminator: 0.040487; Generator: 0.027558,\n",
      "D(x): 0.469, D(G(z)): 0.414\n",
      "2019-04-10 00:57:49,612 root         INFO     Train Epoch: 83 [5632/8000 (70%)]\tTotal Loss: 0.506049\n",
      "Reconstruction: 0.438921, Regularization: 0.000268, Discriminator: 0.038892; Generator: 0.027968,\n",
      "D(x): 0.488, D(G(z)): 0.409\n",
      "2019-04-10 00:57:49,723 root         INFO     Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 0.505115\n",
      "Reconstruction: 0.438060, Regularization: 0.000318, Discriminator: 0.039013; Generator: 0.027724,\n",
      "D(x): 0.491, D(G(z)): 0.412\n",
      "2019-04-10 00:57:49,833 root         INFO     Train Epoch: 83 [6656/8000 (83%)]\tTotal Loss: 0.503505\n",
      "Reconstruction: 0.436619, Regularization: 0.000228, Discriminator: 0.038909; Generator: 0.027749,\n",
      "D(x): 0.492, D(G(z)): 0.411\n",
      "2019-04-10 00:57:49,943 root         INFO     Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 0.503017\n",
      "Reconstruction: 0.435271, Regularization: 0.000195, Discriminator: 0.039926; Generator: 0.027625,\n",
      "D(x): 0.478, D(G(z)): 0.413\n",
      "2019-04-10 00:57:50,053 root         INFO     Train Epoch: 83 [7680/8000 (96%)]\tTotal Loss: 0.500490\n",
      "Reconstruction: 0.434126, Regularization: 0.000228, Discriminator: 0.038962; Generator: 0.027173,\n",
      "D(x): 0.497, D(G(z)): 0.419\n",
      "2019-04-10 00:57:50,134 root         INFO     ====> Epoch: 83 Average loss: 0.5115\n",
      "2019-04-10 00:57:50,161 root         INFO     Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 0.500292\n",
      "Reconstruction: 0.433656, Regularization: 0.000274, Discriminator: 0.038784; Generator: 0.027579,\n",
      "D(x): 0.496, D(G(z)): 0.414\n",
      "2019-04-10 00:57:50,273 root         INFO     Train Epoch: 84 [512/8000 (6%)]\tTotal Loss: 0.500090\n",
      "Reconstruction: 0.432301, Regularization: 0.000186, Discriminator: 0.040899; Generator: 0.026703,\n",
      "D(x): 0.473, D(G(z)): 0.425\n",
      "2019-04-10 00:57:50,384 root         INFO     Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 0.497622\n",
      "Reconstruction: 0.431179, Regularization: 0.000313, Discriminator: 0.039370; Generator: 0.026760,\n",
      "D(x): 0.497, D(G(z)): 0.425\n",
      "2019-04-10 00:57:50,495 root         INFO     Train Epoch: 84 [1536/8000 (19%)]\tTotal Loss: 0.495954\n",
      "Reconstruction: 0.429178, Regularization: 0.000298, Discriminator: 0.039528; Generator: 0.026949,\n",
      "D(x): 0.493, D(G(z)): 0.422\n",
      "2019-04-10 00:57:50,606 root         INFO     Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 0.494521\n",
      "Reconstruction: 0.427812, Regularization: 0.000302, Discriminator: 0.039654; Generator: 0.026753,\n",
      "D(x): 0.494, D(G(z)): 0.425\n",
      "2019-04-10 00:57:50,717 root         INFO     Train Epoch: 84 [2560/8000 (32%)]\tTotal Loss: 0.492293\n",
      "Reconstruction: 0.426010, Regularization: 0.000268, Discriminator: 0.039852; Generator: 0.026164,\n",
      "D(x): 0.496, D(G(z)): 0.433\n",
      "2019-04-10 00:57:50,828 root         INFO     Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 0.490254\n",
      "Reconstruction: 0.424781, Regularization: 0.000152, Discriminator: 0.038689; Generator: 0.026633,\n",
      "D(x): 0.509, D(G(z)): 0.426\n",
      "2019-04-10 00:57:50,939 root         INFO     Train Epoch: 84 [3584/8000 (45%)]\tTotal Loss: 0.489698\n",
      "Reconstruction: 0.422280, Regularization: 0.000197, Discriminator: 0.040600; Generator: 0.026621,\n",
      "D(x): 0.480, D(G(z)): 0.427\n",
      "2019-04-10 00:57:51,050 root         INFO     Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 0.487225\n",
      "Reconstruction: 0.420830, Regularization: 0.000342, Discriminator: 0.039729; Generator: 0.026324,\n",
      "D(x): 0.497, D(G(z)): 0.431\n",
      "2019-04-10 00:57:51,161 root         INFO     Train Epoch: 84 [4608/8000 (58%)]\tTotal Loss: 0.484840\n",
      "Reconstruction: 0.418858, Regularization: 0.000333, Discriminator: 0.039327; Generator: 0.026322,\n",
      "D(x): 0.505, D(G(z)): 0.431\n",
      "2019-04-10 00:57:51,272 root         INFO     Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 0.482956\n",
      "Reconstruction: 0.417845, Regularization: 0.000266, Discriminator: 0.039540; Generator: 0.025305,\n",
      "D(x): 0.512, D(G(z)): 0.445\n",
      "2019-04-10 00:57:51,384 root         INFO     Train Epoch: 84 [5632/8000 (70%)]\tTotal Loss: 0.482105\n",
      "Reconstruction: 0.416371, Regularization: 0.000155, Discriminator: 0.040198; Generator: 0.025381,\n",
      "D(x): 0.500, D(G(z)): 0.444\n",
      "2019-04-10 00:57:51,495 root         INFO     Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 0.482055\n",
      "Reconstruction: 0.415106, Regularization: 0.000209, Discriminator: 0.040995; Generator: 0.025745,\n",
      "D(x): 0.483, D(G(z)): 0.439\n",
      "2019-04-10 00:57:51,606 root         INFO     Train Epoch: 84 [6656/8000 (83%)]\tTotal Loss: 0.480982\n",
      "Reconstruction: 0.414604, Regularization: 0.000248, Discriminator: 0.040552; Generator: 0.025579,\n",
      "D(x): 0.491, D(G(z)): 0.441\n",
      "2019-04-10 00:57:51,717 root         INFO     Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 0.479523\n",
      "Reconstruction: 0.413828, Regularization: 0.000279, Discriminator: 0.039597; Generator: 0.025818,\n",
      "D(x): 0.505, D(G(z)): 0.438\n",
      "2019-04-10 00:57:51,828 root         INFO     Train Epoch: 84 [7680/8000 (96%)]\tTotal Loss: 0.478770\n",
      "Reconstruction: 0.412203, Regularization: 0.000227, Discriminator: 0.040931; Generator: 0.025409,\n",
      "D(x): 0.489, D(G(z)): 0.443\n",
      "2019-04-10 00:57:51,909 root         INFO     ====> Epoch: 84 Average loss: 0.4884\n",
      "2019-04-10 00:57:51,937 root         INFO     Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 0.477117\n",
      "Reconstruction: 0.411493, Regularization: 0.000188, Discriminator: 0.040481; Generator: 0.024955,\n",
      "D(x): 0.502, D(G(z)): 0.450\n",
      "2019-04-10 00:57:52,048 root         INFO     Train Epoch: 85 [512/8000 (6%)]\tTotal Loss: 0.476917\n",
      "Reconstruction: 0.410210, Regularization: 0.000198, Discriminator: 0.041377; Generator: 0.025133,\n",
      "D(x): 0.487, D(G(z)): 0.447\n",
      "2019-04-10 00:57:52,160 root         INFO     Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 0.473738\n",
      "Reconstruction: 0.408545, Regularization: 0.000214, Discriminator: 0.040512; Generator: 0.024468,\n",
      "D(x): 0.511, D(G(z)): 0.457\n",
      "2019-04-10 00:57:52,271 root         INFO     Train Epoch: 85 [1536/8000 (19%)]\tTotal Loss: 0.472633\n",
      "Reconstruction: 0.406585, Regularization: 0.000184, Discriminator: 0.041191; Generator: 0.024673,\n",
      "D(x): 0.494, D(G(z)): 0.454\n",
      "2019-04-10 00:57:52,383 root         INFO     Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 0.470992\n",
      "Reconstruction: 0.404979, Regularization: 0.000220, Discriminator: 0.041229; Generator: 0.024563,\n",
      "D(x): 0.497, D(G(z)): 0.456\n",
      "2019-04-10 00:57:52,494 root         INFO     Train Epoch: 85 [2560/8000 (32%)]\tTotal Loss: 0.469024\n",
      "Reconstruction: 0.402996, Regularization: 0.000208, Discriminator: 0.041678; Generator: 0.024142,\n",
      "D(x): 0.497, D(G(z)): 0.462\n",
      "2019-04-10 00:57:52,606 root         INFO     Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 0.467751\n",
      "Reconstruction: 0.401548, Regularization: 0.000230, Discriminator: 0.041844; Generator: 0.024129,\n",
      "D(x): 0.494, D(G(z)): 0.462\n",
      "2019-04-10 00:57:52,717 root         INFO     Train Epoch: 85 [3584/8000 (45%)]\tTotal Loss: 0.464895\n",
      "Reconstruction: 0.399689, Regularization: 0.000248, Discriminator: 0.041042; Generator: 0.023917,\n",
      "D(x): 0.509, D(G(z)): 0.465\n",
      "2019-04-10 00:57:52,829 root         INFO     Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 0.464083\n",
      "Reconstruction: 0.398120, Regularization: 0.000185, Discriminator: 0.042026; Generator: 0.023752,\n",
      "D(x): 0.496, D(G(z)): 0.468\n",
      "2019-04-10 00:57:52,940 root         INFO     Train Epoch: 85 [4608/8000 (58%)]\tTotal Loss: 0.463980\n",
      "Reconstruction: 0.397315, Regularization: 0.000261, Discriminator: 0.042985; Generator: 0.023419,\n",
      "D(x): 0.486, D(G(z)): 0.473\n",
      "2019-04-10 00:57:53,051 root         INFO     Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 0.462733\n",
      "Reconstruction: 0.396463, Regularization: 0.000179, Discriminator: 0.042267; Generator: 0.023824,\n",
      "D(x): 0.489, D(G(z)): 0.467\n",
      "2019-04-10 00:57:53,163 root         INFO     Train Epoch: 85 [5632/8000 (70%)]\tTotal Loss: 0.462119\n",
      "Reconstruction: 0.395632, Regularization: 0.000204, Discriminator: 0.042898; Generator: 0.023385,\n",
      "D(x): 0.486, D(G(z)): 0.473\n",
      "2019-04-10 00:57:53,274 root         INFO     Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 0.461429\n",
      "Reconstruction: 0.394310, Regularization: 0.000206, Discriminator: 0.043322; Generator: 0.023590,\n",
      "D(x): 0.477, D(G(z)): 0.470\n",
      "2019-04-10 00:57:53,386 root         INFO     Train Epoch: 85 [6656/8000 (83%)]\tTotal Loss: 0.457880\n",
      "Reconstruction: 0.393200, Regularization: 0.000265, Discriminator: 0.041462; Generator: 0.022953,\n",
      "D(x): 0.515, D(G(z)): 0.480\n",
      "2019-04-10 00:57:53,497 root         INFO     Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 0.456786\n",
      "Reconstruction: 0.392054, Regularization: 0.000202, Discriminator: 0.041581; Generator: 0.022949,\n",
      "D(x): 0.512, D(G(z)): 0.480\n",
      "2019-04-10 00:57:53,608 root         INFO     Train Epoch: 85 [7680/8000 (96%)]\tTotal Loss: 0.456038\n",
      "Reconstruction: 0.390356, Regularization: 0.000179, Discriminator: 0.042549; Generator: 0.022953,\n",
      "D(x): 0.499, D(G(z)): 0.480\n",
      "2019-04-10 00:57:53,689 root         INFO     ====> Epoch: 85 Average loss: 0.4654\n",
      "2019-04-10 00:57:53,717 root         INFO     Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 0.453928\n",
      "Reconstruction: 0.389424, Regularization: 0.000236, Discriminator: 0.041607; Generator: 0.022661,\n",
      "D(x): 0.518, D(G(z)): 0.484\n",
      "2019-04-10 00:57:53,828 root         INFO     Train Epoch: 86 [512/8000 (6%)]\tTotal Loss: 0.453085\n",
      "Reconstruction: 0.388159, Regularization: 0.000294, Discriminator: 0.041956; Generator: 0.022677,\n",
      "D(x): 0.513, D(G(z)): 0.484\n",
      "2019-04-10 00:57:53,938 root         INFO     Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 0.451245\n",
      "Reconstruction: 0.386426, Regularization: 0.000273, Discriminator: 0.042112; Generator: 0.022435,\n",
      "D(x): 0.513, D(G(z)): 0.488\n",
      "2019-04-10 00:57:54,050 root         INFO     Train Epoch: 86 [1536/8000 (19%)]\tTotal Loss: 0.452674\n",
      "Reconstruction: 0.385499, Regularization: 0.000258, Discriminator: 0.044350; Generator: 0.022567,\n",
      "D(x): 0.478, D(G(z)): 0.486\n",
      "2019-04-10 00:57:54,161 root         INFO     Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 0.448909\n",
      "Reconstruction: 0.383825, Regularization: 0.000279, Discriminator: 0.042493; Generator: 0.022311,\n",
      "D(x): 0.512, D(G(z)): 0.490\n",
      "2019-04-10 00:57:54,273 root         INFO     Train Epoch: 86 [2560/8000 (32%)]\tTotal Loss: 0.448439\n",
      "Reconstruction: 0.382108, Regularization: 0.000233, Discriminator: 0.043918; Generator: 0.022181,\n",
      "D(x): 0.489, D(G(z)): 0.492\n",
      "2019-04-10 00:57:54,384 root         INFO     Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 0.446004\n",
      "Reconstruction: 0.380626, Regularization: 0.000191, Discriminator: 0.043085; Generator: 0.022102,\n",
      "D(x): 0.502, D(G(z)): 0.493\n",
      "2019-04-10 00:57:54,496 root         INFO     Train Epoch: 86 [3584/8000 (45%)]\tTotal Loss: 0.446063\n",
      "Reconstruction: 0.379509, Regularization: 0.000326, Discriminator: 0.044609; Generator: 0.021620,\n",
      "D(x): 0.489, D(G(z)): 0.501\n",
      "2019-04-10 00:57:54,608 root         INFO     Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 0.443992\n",
      "Reconstruction: 0.378551, Regularization: 0.000251, Discriminator: 0.043638; Generator: 0.021552,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-10 00:57:54,719 root         INFO     Train Epoch: 86 [4608/8000 (58%)]\tTotal Loss: 0.442211\n",
      "Reconstruction: 0.377382, Regularization: 0.000273, Discriminator: 0.043330; Generator: 0.021227,\n",
      "D(x): 0.511, D(G(z)): 0.507\n",
      "2019-04-10 00:57:54,830 root         INFO     Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 0.441491\n",
      "Reconstruction: 0.375906, Regularization: 0.000275, Discriminator: 0.044212; Generator: 0.021098,\n",
      "D(x): 0.502, D(G(z)): 0.509\n",
      "2019-04-10 00:57:54,942 root         INFO     Train Epoch: 86 [5632/8000 (70%)]\tTotal Loss: 0.440119\n",
      "Reconstruction: 0.375747, Regularization: 0.000289, Discriminator: 0.043016; Generator: 0.021067,\n",
      "D(x): 0.519, D(G(z)): 0.510\n",
      "2019-04-10 00:57:55,053 root         INFO     Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 0.439318\n",
      "Reconstruction: 0.374487, Regularization: 0.000263, Discriminator: 0.043329; Generator: 0.021240,\n",
      "D(x): 0.511, D(G(z)): 0.507\n",
      "2019-04-10 00:57:55,165 root         INFO     Train Epoch: 86 [6656/8000 (83%)]\tTotal Loss: 0.440502\n",
      "Reconstruction: 0.374466, Regularization: 0.000281, Discriminator: 0.044453; Generator: 0.021303,\n",
      "D(x): 0.493, D(G(z)): 0.506\n",
      "2019-04-10 00:57:55,276 root         INFO     Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 0.438006\n",
      "Reconstruction: 0.373064, Regularization: 0.000252, Discriminator: 0.043745; Generator: 0.020945,\n",
      "D(x): 0.509, D(G(z)): 0.512\n",
      "2019-04-10 00:57:55,388 root         INFO     Train Epoch: 86 [7680/8000 (96%)]\tTotal Loss: 0.437233\n",
      "Reconstruction: 0.372043, Regularization: 0.000287, Discriminator: 0.044156; Generator: 0.020747,\n",
      "D(x): 0.506, D(G(z)): 0.515\n",
      "2019-04-10 00:57:55,469 root         INFO     ====> Epoch: 86 Average loss: 0.4447\n",
      "2019-04-10 00:57:55,497 root         INFO     Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 0.436046\n",
      "Reconstruction: 0.371737, Regularization: 0.000235, Discriminator: 0.043366; Generator: 0.020708,\n",
      "D(x): 0.519, D(G(z)): 0.515\n",
      "2019-04-10 00:57:55,609 root         INFO     Train Epoch: 87 [512/8000 (6%)]\tTotal Loss: 0.435927\n",
      "Reconstruction: 0.370155, Regularization: 0.000223, Discriminator: 0.044871; Generator: 0.020679,\n",
      "D(x): 0.501, D(G(z)): 0.516\n",
      "2019-04-10 00:57:55,720 root         INFO     Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 0.434614\n",
      "Reconstruction: 0.369611, Regularization: 0.000282, Discriminator: 0.044358; Generator: 0.020363,\n",
      "D(x): 0.513, D(G(z)): 0.521\n",
      "2019-04-10 00:57:55,832 root         INFO     Train Epoch: 87 [1536/8000 (19%)]\tTotal Loss: 0.433264\n",
      "Reconstruction: 0.368213, Regularization: 0.000156, Discriminator: 0.044475; Generator: 0.020419,\n",
      "D(x): 0.510, D(G(z)): 0.520\n",
      "2019-04-10 00:57:55,943 root         INFO     Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 0.431738\n",
      "Reconstruction: 0.366660, Regularization: 0.000162, Discriminator: 0.044787; Generator: 0.020129,\n",
      "D(x): 0.507, D(G(z)): 0.525\n",
      "2019-04-10 00:57:56,055 root         INFO     Train Epoch: 87 [2560/8000 (32%)]\tTotal Loss: 0.430260\n",
      "Reconstruction: 0.365712, Regularization: 0.000239, Discriminator: 0.044220; Generator: 0.020090,\n",
      "D(x): 0.514, D(G(z)): 0.526\n",
      "2019-04-10 00:57:56,166 root         INFO     Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 0.428570\n",
      "Reconstruction: 0.364730, Regularization: 0.000242, Discriminator: 0.043416; Generator: 0.020182,\n",
      "D(x): 0.527, D(G(z)): 0.524\n",
      "2019-04-10 00:57:56,276 root         INFO     Train Epoch: 87 [3584/8000 (45%)]\tTotal Loss: 0.428742\n",
      "Reconstruction: 0.363409, Regularization: 0.000269, Discriminator: 0.045143; Generator: 0.019921,\n",
      "D(x): 0.506, D(G(z)): 0.529\n",
      "2019-04-10 00:57:56,386 root         INFO     Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 0.425634\n",
      "Reconstruction: 0.362345, Regularization: 0.000254, Discriminator: 0.043091; Generator: 0.019943,\n",
      "D(x): 0.539, D(G(z)): 0.528\n",
      "2019-04-10 00:57:56,495 root         INFO     Train Epoch: 87 [4608/8000 (58%)]\tTotal Loss: 0.425253\n",
      "Reconstruction: 0.361104, Regularization: 0.000280, Discriminator: 0.044039; Generator: 0.019830,\n",
      "D(x): 0.525, D(G(z)): 0.530\n",
      "2019-04-10 00:57:56,604 root         INFO     Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 0.424521\n",
      "Reconstruction: 0.360044, Regularization: 0.000279, Discriminator: 0.044374; Generator: 0.019823,\n",
      "D(x): 0.522, D(G(z)): 0.530\n",
      "2019-04-10 00:57:56,714 root         INFO     Train Epoch: 87 [5632/8000 (70%)]\tTotal Loss: 0.423715\n",
      "Reconstruction: 0.359350, Regularization: 0.000298, Discriminator: 0.044452; Generator: 0.019615,\n",
      "D(x): 0.520, D(G(z)): 0.534\n",
      "2019-04-10 00:57:56,823 root         INFO     Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 0.423336\n",
      "Reconstruction: 0.358548, Regularization: 0.000278, Discriminator: 0.044836; Generator: 0.019675,\n",
      "D(x): 0.514, D(G(z)): 0.533\n",
      "2019-04-10 00:57:56,932 root         INFO     Train Epoch: 87 [6656/8000 (83%)]\tTotal Loss: 0.421348\n",
      "Reconstruction: 0.357331, Regularization: 0.000273, Discriminator: 0.044159; Generator: 0.019585,\n",
      "D(x): 0.525, D(G(z)): 0.534\n",
      "2019-04-10 00:57:57,043 root         INFO     Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 0.421610\n",
      "Reconstruction: 0.357086, Regularization: 0.000303, Discriminator: 0.044614; Generator: 0.019608,\n",
      "D(x): 0.518, D(G(z)): 0.534\n",
      "2019-04-10 00:57:57,152 root         INFO     Train Epoch: 87 [7680/8000 (96%)]\tTotal Loss: 0.420894\n",
      "Reconstruction: 0.356006, Regularization: 0.000245, Discriminator: 0.045063; Generator: 0.019580,\n",
      "D(x): 0.510, D(G(z)): 0.534\n",
      "2019-04-10 00:57:57,232 root         INFO     ====> Epoch: 87 Average loss: 0.4279\n",
      "2019-04-10 00:57:57,260 root         INFO     Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 0.421278\n",
      "Reconstruction: 0.356674, Regularization: 0.000223, Discriminator: 0.045118; Generator: 0.019262,\n",
      "D(x): 0.516, D(G(z)): 0.540\n",
      "2019-04-10 00:57:57,372 root         INFO     Train Epoch: 88 [512/8000 (6%)]\tTotal Loss: 0.419766\n",
      "Reconstruction: 0.355447, Regularization: 0.000173, Discriminator: 0.044859; Generator: 0.019287,\n",
      "D(x): 0.519, D(G(z)): 0.539\n",
      "2019-04-10 00:57:57,483 root         INFO     Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 0.420120\n",
      "Reconstruction: 0.355390, Regularization: 0.000287, Discriminator: 0.045250; Generator: 0.019193,\n",
      "D(x): 0.518, D(G(z)): 0.541\n",
      "2019-04-10 00:57:57,594 root         INFO     Train Epoch: 88 [1536/8000 (19%)]\tTotal Loss: 0.419123\n",
      "Reconstruction: 0.353922, Regularization: 0.000281, Discriminator: 0.045419; Generator: 0.019500,\n",
      "D(x): 0.508, D(G(z)): 0.536\n",
      "2019-04-10 00:57:57,705 root         INFO     Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 0.418427\n",
      "Reconstruction: 0.353628, Regularization: 0.000253, Discriminator: 0.045055; Generator: 0.019492,\n",
      "D(x): 0.513, D(G(z)): 0.536\n",
      "2019-04-10 00:57:57,816 root         INFO     Train Epoch: 88 [2560/8000 (32%)]\tTotal Loss: 0.417452\n",
      "Reconstruction: 0.352924, Regularization: 0.000241, Discriminator: 0.044945; Generator: 0.019342,\n",
      "D(x): 0.517, D(G(z)): 0.539\n",
      "2019-04-10 00:57:57,927 root         INFO     Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 0.416034\n",
      "Reconstruction: 0.352102, Regularization: 0.000262, Discriminator: 0.044077; Generator: 0.019593,\n",
      "D(x): 0.527, D(G(z)): 0.534\n",
      "2019-04-10 00:57:58,036 root         INFO     Train Epoch: 88 [3584/8000 (45%)]\tTotal Loss: 0.414409\n",
      "Reconstruction: 0.350640, Regularization: 0.000278, Discriminator: 0.044241; Generator: 0.019249,\n",
      "D(x): 0.531, D(G(z)): 0.540\n",
      "2019-04-10 00:57:58,146 root         INFO     Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 0.415324\n",
      "Reconstruction: 0.350575, Regularization: 0.000343, Discriminator: 0.045314; Generator: 0.019091,\n",
      "D(x): 0.517, D(G(z)): 0.543\n",
      "2019-04-10 00:57:58,256 root         INFO     Train Epoch: 88 [4608/8000 (58%)]\tTotal Loss: 0.413169\n",
      "Reconstruction: 0.348797, Regularization: 0.000276, Discriminator: 0.045134; Generator: 0.018962,\n",
      "D(x): 0.522, D(G(z)): 0.545\n",
      "2019-04-10 00:57:58,366 root         INFO     Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 0.412744\n",
      "Reconstruction: 0.348365, Regularization: 0.000255, Discriminator: 0.045533; Generator: 0.018591,\n",
      "D(x): 0.521, D(G(z)): 0.552\n",
      "2019-04-10 00:57:58,475 root         INFO     Train Epoch: 88 [5632/8000 (70%)]\tTotal Loss: 0.410907\n",
      "Reconstruction: 0.347497, Regularization: 0.000382, Discriminator: 0.044529; Generator: 0.018499,\n",
      "D(x): 0.541, D(G(z)): 0.553\n",
      "2019-04-10 00:57:58,585 root         INFO     Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 0.411575\n",
      "Reconstruction: 0.346928, Regularization: 0.000336, Discriminator: 0.045568; Generator: 0.018743,\n",
      "D(x): 0.519, D(G(z)): 0.549\n",
      "2019-04-10 00:57:58,695 root         INFO     Train Epoch: 88 [6656/8000 (83%)]\tTotal Loss: 0.409733\n",
      "Reconstruction: 0.344860, Regularization: 0.000289, Discriminator: 0.045796; Generator: 0.018788,\n",
      "D(x): 0.513, D(G(z)): 0.548\n",
      "2019-04-10 00:57:58,805 root         INFO     Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 0.410161\n",
      "Reconstruction: 0.345489, Regularization: 0.000335, Discriminator: 0.045487; Generator: 0.018849,\n",
      "D(x): 0.517, D(G(z)): 0.547\n",
      "2019-04-10 00:57:58,913 root         INFO     Train Epoch: 88 [7680/8000 (96%)]\tTotal Loss: 0.409545\n",
      "Reconstruction: 0.345168, Regularization: 0.000208, Discriminator: 0.045371; Generator: 0.018798,\n",
      "D(x): 0.520, D(G(z)): 0.548\n",
      "2019-04-10 00:57:58,992 root         INFO     ====> Epoch: 88 Average loss: 0.4150\n",
      "2019-04-10 00:57:59,020 root         INFO     Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 0.409383\n",
      "Reconstruction: 0.344359, Regularization: 0.000255, Discriminator: 0.045886; Generator: 0.018883,\n",
      "D(x): 0.510, D(G(z)): 0.546\n",
      "2019-04-10 00:57:59,132 root         INFO     Train Epoch: 89 [512/8000 (6%)]\tTotal Loss: 0.408329\n",
      "Reconstruction: 0.344438, Regularization: 0.000314, Discriminator: 0.044860; Generator: 0.018716,\n",
      "D(x): 0.530, D(G(z)): 0.549\n",
      "2019-04-10 00:57:59,242 root         INFO     Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 0.407642\n",
      "Reconstruction: 0.343908, Regularization: 0.000245, Discriminator: 0.044755; Generator: 0.018734,\n",
      "D(x): 0.531, D(G(z)): 0.549\n",
      "2019-04-10 00:57:59,353 root         INFO     Train Epoch: 89 [1536/8000 (19%)]\tTotal Loss: 0.407593\n",
      "Reconstruction: 0.343896, Regularization: 0.000257, Discriminator: 0.044765; Generator: 0.018674,\n",
      "D(x): 0.532, D(G(z)): 0.550\n",
      "2019-04-10 00:57:59,463 root         INFO     Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 0.406869\n",
      "Reconstruction: 0.342671, Regularization: 0.000227, Discriminator: 0.045300; Generator: 0.018671,\n",
      "D(x): 0.523, D(G(z)): 0.550\n",
      "2019-04-10 00:57:59,574 root         INFO     Train Epoch: 89 [2560/8000 (32%)]\tTotal Loss: 0.406456\n",
      "Reconstruction: 0.342185, Regularization: 0.000253, Discriminator: 0.045307; Generator: 0.018712,\n",
      "D(x): 0.522, D(G(z)): 0.549\n",
      "2019-04-10 00:57:59,684 root         INFO     Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 0.406588\n",
      "Reconstruction: 0.342582, Regularization: 0.000287, Discriminator: 0.045036; Generator: 0.018684,\n",
      "D(x): 0.527, D(G(z)): 0.550\n",
      "2019-04-10 00:57:59,795 root         INFO     Train Epoch: 89 [3584/8000 (45%)]\tTotal Loss: 0.405666\n",
      "Reconstruction: 0.341384, Regularization: 0.000249, Discriminator: 0.045243; Generator: 0.018789,\n",
      "D(x): 0.521, D(G(z)): 0.548\n",
      "2019-04-10 00:57:59,905 root         INFO     Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 0.405750\n",
      "Reconstruction: 0.341448, Regularization: 0.000219, Discriminator: 0.045288; Generator: 0.018795,\n",
      "D(x): 0.520, D(G(z)): 0.548\n",
      "2019-04-10 00:58:00,016 root         INFO     Train Epoch: 89 [4608/8000 (58%)]\tTotal Loss: 0.406328\n",
      "Reconstruction: 0.341956, Regularization: 0.000305, Discriminator: 0.045144; Generator: 0.018924,\n",
      "D(x): 0.520, D(G(z)): 0.546\n",
      "2019-04-10 00:58:00,126 root         INFO     Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 0.404016\n",
      "Reconstruction: 0.340137, Regularization: 0.000274, Discriminator: 0.044702; Generator: 0.018903,\n",
      "D(x): 0.528, D(G(z)): 0.546\n",
      "2019-04-10 00:58:00,237 root         INFO     Train Epoch: 89 [5632/8000 (70%)]\tTotal Loss: 0.404784\n",
      "Reconstruction: 0.340793, Regularization: 0.000476, Discriminator: 0.044588; Generator: 0.018928,\n",
      "D(x): 0.529, D(G(z)): 0.546\n",
      "2019-04-10 00:58:00,348 root         INFO     Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 0.403094\n",
      "Reconstruction: 0.339479, Regularization: 0.000206, Discriminator: 0.044570; Generator: 0.018838,\n",
      "D(x): 0.531, D(G(z)): 0.547\n",
      "2019-04-10 00:58:00,458 root         INFO     Train Epoch: 89 [6656/8000 (83%)]\tTotal Loss: 0.404113\n",
      "Reconstruction: 0.340300, Regularization: 0.000310, Discriminator: 0.044615; Generator: 0.018888,\n",
      "D(x): 0.530, D(G(z)): 0.546\n",
      "2019-04-10 00:58:00,568 root         INFO     Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 0.402165\n",
      "Reconstruction: 0.338575, Regularization: 0.000280, Discriminator: 0.044413; Generator: 0.018897,\n",
      "D(x): 0.533, D(G(z)): 0.546\n",
      "2019-04-10 00:58:00,677 root         INFO     Train Epoch: 89 [7680/8000 (96%)]\tTotal Loss: 0.403260\n",
      "Reconstruction: 0.338970, Regularization: 0.000442, Discriminator: 0.044855; Generator: 0.018994,\n",
      "D(x): 0.524, D(G(z)): 0.545\n",
      "2019-04-10 00:58:00,757 root         INFO     ====> Epoch: 89 Average loss: 0.4056\n",
      "2019-04-10 00:58:00,785 root         INFO     Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 0.400956\n",
      "Reconstruction: 0.337266, Regularization: 0.000268, Discriminator: 0.044485; Generator: 0.018938,\n",
      "D(x): 0.531, D(G(z)): 0.546\n",
      "2019-04-10 00:58:00,897 root         INFO     Train Epoch: 90 [512/8000 (6%)]\tTotal Loss: 0.400791\n",
      "Reconstruction: 0.337574, Regularization: 0.000349, Discriminator: 0.044051; Generator: 0.018818,\n",
      "D(x): 0.540, D(G(z)): 0.548\n",
      "2019-04-10 00:58:01,008 root         INFO     Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 0.401393\n",
      "Reconstruction: 0.337741, Regularization: 0.000234, Discriminator: 0.044535; Generator: 0.018881,\n",
      "D(x): 0.531, D(G(z)): 0.547\n",
      "2019-04-10 00:58:01,119 root         INFO     Train Epoch: 90 [1536/8000 (19%)]\tTotal Loss: 0.400818\n",
      "Reconstruction: 0.336642, Regularization: 0.000237, Discriminator: 0.044981; Generator: 0.018957,\n",
      "D(x): 0.522, D(G(z)): 0.545\n",
      "2019-04-10 00:58:01,230 root         INFO     Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 0.399804\n",
      "Reconstruction: 0.336003, Regularization: 0.000382, Discriminator: 0.044483; Generator: 0.018936,\n",
      "D(x): 0.531, D(G(z)): 0.546\n",
      "2019-04-10 00:58:01,341 root         INFO     Train Epoch: 90 [2560/8000 (32%)]\tTotal Loss: 0.399778\n",
      "Reconstruction: 0.336166, Regularization: 0.000271, Discriminator: 0.044463; Generator: 0.018879,\n",
      "D(x): 0.532, D(G(z)): 0.547\n",
      "2019-04-10 00:58:01,452 root         INFO     Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 0.399737\n",
      "Reconstruction: 0.335987, Regularization: 0.000333, Discriminator: 0.044594; Generator: 0.018822,\n",
      "D(x): 0.531, D(G(z)): 0.548\n",
      "2019-04-10 00:58:01,563 root         INFO     Train Epoch: 90 [3584/8000 (45%)]\tTotal Loss: 0.398619\n",
      "Reconstruction: 0.335166, Regularization: 0.000325, Discriminator: 0.044321; Generator: 0.018807,\n",
      "D(x): 0.536, D(G(z)): 0.548\n",
      "2019-04-10 00:58:01,674 root         INFO     Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 0.398382\n",
      "Reconstruction: 0.334760, Regularization: 0.000302, Discriminator: 0.044407; Generator: 0.018913,\n",
      "D(x): 0.532, D(G(z)): 0.546\n",
      "2019-04-10 00:58:01,785 root         INFO     Train Epoch: 90 [4608/8000 (58%)]\tTotal Loss: 0.398016\n",
      "Reconstruction: 0.334567, Regularization: 0.000329, Discriminator: 0.044133; Generator: 0.018987,\n",
      "D(x): 0.535, D(G(z)): 0.545\n",
      "2019-04-10 00:58:01,896 root         INFO     Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 0.397802\n",
      "Reconstruction: 0.334254, Regularization: 0.000369, Discriminator: 0.044183; Generator: 0.018996,\n",
      "D(x): 0.534, D(G(z)): 0.545\n",
      "2019-04-10 00:58:02,007 root         INFO     Train Epoch: 90 [5632/8000 (70%)]\tTotal Loss: 0.397972\n",
      "Reconstruction: 0.334469, Regularization: 0.000248, Discriminator: 0.044239; Generator: 0.019016,\n",
      "D(x): 0.533, D(G(z)): 0.544\n",
      "2019-04-10 00:58:02,118 root         INFO     Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 0.397035\n",
      "Reconstruction: 0.333594, Regularization: 0.000259, Discriminator: 0.044183; Generator: 0.018999,\n",
      "D(x): 0.534, D(G(z)): 0.544\n",
      "2019-04-10 00:58:02,229 root         INFO     Train Epoch: 90 [6656/8000 (83%)]\tTotal Loss: 0.397894\n",
      "Reconstruction: 0.334539, Regularization: 0.000290, Discriminator: 0.044039; Generator: 0.019027,\n",
      "D(x): 0.536, D(G(z)): 0.544\n",
      "2019-04-10 00:58:02,339 root         INFO     Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 0.397777\n",
      "Reconstruction: 0.334287, Regularization: 0.000294, Discriminator: 0.044139; Generator: 0.019058,\n",
      "D(x): 0.533, D(G(z)): 0.543\n",
      "2019-04-10 00:58:02,449 root         INFO     Train Epoch: 90 [7680/8000 (96%)]\tTotal Loss: 0.397356\n",
      "Reconstruction: 0.333892, Regularization: 0.000267, Discriminator: 0.044045; Generator: 0.019153,\n",
      "D(x): 0.533, D(G(z)): 0.542\n",
      "2019-04-10 00:58:02,529 root         INFO     ====> Epoch: 90 Average loss: 0.3988\n",
      "2019-04-10 00:58:02,556 root         INFO     Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 0.397349\n",
      "Reconstruction: 0.333802, Regularization: 0.000271, Discriminator: 0.044087; Generator: 0.019188,\n",
      "D(x): 0.532, D(G(z)): 0.541\n",
      "2019-04-10 00:58:02,668 root         INFO     Train Epoch: 91 [512/8000 (6%)]\tTotal Loss: 0.397457\n",
      "Reconstruction: 0.334081, Regularization: 0.000220, Discriminator: 0.043925; Generator: 0.019231,\n",
      "D(x): 0.534, D(G(z)): 0.540\n",
      "2019-04-10 00:58:02,779 root         INFO     Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 0.397203\n",
      "Reconstruction: 0.333747, Regularization: 0.000267, Discriminator: 0.043947; Generator: 0.019243,\n",
      "D(x): 0.533, D(G(z)): 0.540\n",
      "2019-04-10 00:58:02,890 root         INFO     Train Epoch: 91 [1536/8000 (19%)]\tTotal Loss: 0.397210\n",
      "Reconstruction: 0.333744, Regularization: 0.000397, Discriminator: 0.043838; Generator: 0.019231,\n",
      "D(x): 0.535, D(G(z)): 0.540\n",
      "2019-04-10 00:58:03,002 root         INFO     Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 0.397492\n",
      "Reconstruction: 0.334115, Regularization: 0.000277, Discriminator: 0.043838; Generator: 0.019261,\n",
      "D(x): 0.534, D(G(z)): 0.540\n",
      "2019-04-10 00:58:03,113 root         INFO     Train Epoch: 91 [2560/8000 (32%)]\tTotal Loss: 0.396899\n",
      "Reconstruction: 0.333501, Regularization: 0.000293, Discriminator: 0.043835; Generator: 0.019270,\n",
      "D(x): 0.534, D(G(z)): 0.540\n",
      "2019-04-10 00:58:03,224 root         INFO     Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 0.397053\n",
      "Reconstruction: 0.333613, Regularization: 0.000347, Discriminator: 0.043750; Generator: 0.019343,\n",
      "D(x): 0.534, D(G(z)): 0.539\n",
      "2019-04-10 00:58:03,335 root         INFO     Train Epoch: 91 [3584/8000 (45%)]\tTotal Loss: 0.398301\n",
      "Reconstruction: 0.334911, Regularization: 0.000247, Discriminator: 0.043704; Generator: 0.019439,\n",
      "D(x): 0.533, D(G(z)): 0.537\n",
      "2019-04-10 00:58:03,446 root         INFO     Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 0.397415\n",
      "Reconstruction: 0.333976, Regularization: 0.000274, Discriminator: 0.043678; Generator: 0.019487,\n",
      "D(x): 0.533, D(G(z)): 0.536\n",
      "2019-04-10 00:58:03,557 root         INFO     Train Epoch: 91 [4608/8000 (58%)]\tTotal Loss: 0.397569\n",
      "Reconstruction: 0.334211, Regularization: 0.000258, Discriminator: 0.043594; Generator: 0.019506,\n",
      "D(x): 0.534, D(G(z)): 0.536\n",
      "2019-04-10 00:58:03,668 root         INFO     Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 0.396463\n",
      "Reconstruction: 0.332890, Regularization: 0.000382, Discriminator: 0.043605; Generator: 0.019585,\n",
      "D(x): 0.532, D(G(z)): 0.534\n",
      "2019-04-10 00:58:03,779 root         INFO     Train Epoch: 91 [5632/8000 (70%)]\tTotal Loss: 0.396701\n",
      "Reconstruction: 0.333311, Regularization: 0.000321, Discriminator: 0.043528; Generator: 0.019541,\n",
      "D(x): 0.534, D(G(z)): 0.535\n",
      "2019-04-10 00:58:03,891 root         INFO     Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 0.397320\n",
      "Reconstruction: 0.333976, Regularization: 0.000302, Discriminator: 0.043475; Generator: 0.019567,\n",
      "D(x): 0.535, D(G(z)): 0.535\n",
      "2019-04-10 00:58:04,002 root         INFO     Train Epoch: 91 [6656/8000 (83%)]\tTotal Loss: 0.396738\n",
      "Reconstruction: 0.333357, Regularization: 0.000312, Discriminator: 0.043494; Generator: 0.019575,\n",
      "D(x): 0.534, D(G(z)): 0.535\n",
      "2019-04-10 00:58:04,113 root         INFO     Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 0.397293\n",
      "Reconstruction: 0.334081, Regularization: 0.000252, Discriminator: 0.043396; Generator: 0.019564,\n",
      "D(x): 0.536, D(G(z)): 0.535\n",
      "2019-04-10 00:58:04,224 root         INFO     Train Epoch: 91 [7680/8000 (96%)]\tTotal Loss: 0.396220\n",
      "Reconstruction: 0.332929, Regularization: 0.000283, Discriminator: 0.043382; Generator: 0.019626,\n",
      "D(x): 0.535, D(G(z)): 0.534\n",
      "2019-04-10 00:58:04,305 root         INFO     ====> Epoch: 91 Average loss: 0.3971\n",
      "2019-04-10 00:58:04,332 root         INFO     Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 0.395802\n",
      "Reconstruction: 0.332517, Regularization: 0.000257, Discriminator: 0.043372; Generator: 0.019655,\n",
      "D(x): 0.535, D(G(z)): 0.533\n",
      "2019-04-10 00:58:04,444 root         INFO     Train Epoch: 92 [512/8000 (6%)]\tTotal Loss: 0.395409\n",
      "Reconstruction: 0.332223, Regularization: 0.000205, Discriminator: 0.043305; Generator: 0.019676,\n",
      "D(x): 0.535, D(G(z)): 0.533\n",
      "2019-04-10 00:58:04,555 root         INFO     Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 0.396360\n",
      "Reconstruction: 0.333064, Regularization: 0.000247, Discriminator: 0.043298; Generator: 0.019751,\n",
      "D(x): 0.534, D(G(z)): 0.532\n",
      "2019-04-10 00:58:04,667 root         INFO     Train Epoch: 92 [1536/8000 (19%)]\tTotal Loss: 0.395563\n",
      "Reconstruction: 0.332289, Regularization: 0.000316, Discriminator: 0.043249; Generator: 0.019709,\n",
      "D(x): 0.536, D(G(z)): 0.532\n",
      "2019-04-10 00:58:04,778 root         INFO     Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 0.396046\n",
      "Reconstruction: 0.332761, Regularization: 0.000335, Discriminator: 0.043235; Generator: 0.019716,\n",
      "D(x): 0.536, D(G(z)): 0.532\n",
      "2019-04-10 00:58:04,890 root         INFO     Train Epoch: 92 [2560/8000 (32%)]\tTotal Loss: 0.395919\n",
      "Reconstruction: 0.332718, Regularization: 0.000280, Discriminator: 0.043164; Generator: 0.019757,\n",
      "D(x): 0.536, D(G(z)): 0.531\n",
      "2019-04-10 00:58:05,003 root         INFO     Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 0.395610\n",
      "Reconstruction: 0.332272, Regularization: 0.000308, Discriminator: 0.043267; Generator: 0.019763,\n",
      "D(x): 0.534, D(G(z)): 0.531\n",
      "2019-04-10 00:58:05,115 root         INFO     Train Epoch: 92 [3584/8000 (45%)]\tTotal Loss: 0.397063\n",
      "Reconstruction: 0.333739, Regularization: 0.000298, Discriminator: 0.043185; Generator: 0.019841,\n",
      "D(x): 0.534, D(G(z)): 0.530\n",
      "2019-04-10 00:58:05,227 root         INFO     Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 0.395629\n",
      "Reconstruction: 0.332416, Regularization: 0.000245, Discriminator: 0.043073; Generator: 0.019896,\n",
      "D(x): 0.535, D(G(z)): 0.529\n",
      "2019-04-10 00:58:05,339 root         INFO     Train Epoch: 92 [4608/8000 (58%)]\tTotal Loss: 0.396367\n",
      "Reconstruction: 0.333082, Regularization: 0.000195, Discriminator: 0.043140; Generator: 0.019950,\n",
      "D(x): 0.533, D(G(z)): 0.528\n",
      "2019-04-10 00:58:05,452 root         INFO     Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 0.396602\n",
      "Reconstruction: 0.333173, Regularization: 0.000247, Discriminator: 0.043151; Generator: 0.020031,\n",
      "D(x): 0.531, D(G(z)): 0.527\n",
      "2019-04-10 00:58:05,564 root         INFO     Train Epoch: 92 [5632/8000 (70%)]\tTotal Loss: 0.395828\n",
      "Reconstruction: 0.332315, Regularization: 0.000292, Discriminator: 0.043162; Generator: 0.020059,\n",
      "D(x): 0.530, D(G(z)): 0.526\n",
      "2019-04-10 00:58:05,676 root         INFO     Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 0.397067\n",
      "Reconstruction: 0.333874, Regularization: 0.000270, Discriminator: 0.042858; Generator: 0.020064,\n",
      "D(x): 0.536, D(G(z)): 0.526\n",
      "2019-04-10 00:58:05,788 root         INFO     Train Epoch: 92 [6656/8000 (83%)]\tTotal Loss: 0.396604\n",
      "Reconstruction: 0.333401, Regularization: 0.000233, Discriminator: 0.042905; Generator: 0.020065,\n",
      "D(x): 0.535, D(G(z)): 0.526\n",
      "2019-04-10 00:58:05,900 root         INFO     Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 0.397430\n",
      "Reconstruction: 0.334017, Regularization: 0.000276, Discriminator: 0.043021; Generator: 0.020115,\n",
      "D(x): 0.532, D(G(z)): 0.525\n",
      "2019-04-10 00:58:06,012 root         INFO     Train Epoch: 92 [7680/8000 (96%)]\tTotal Loss: 0.397649\n",
      "Reconstruction: 0.334075, Regularization: 0.000249, Discriminator: 0.043131; Generator: 0.020194,\n",
      "D(x): 0.529, D(G(z)): 0.524\n",
      "2019-04-10 00:58:06,094 root         INFO     ====> Epoch: 92 Average loss: 0.3966\n",
      "2019-04-10 00:58:06,121 root         INFO     Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 0.396622\n",
      "Reconstruction: 0.333249, Regularization: 0.000307, Discriminator: 0.042859; Generator: 0.020206,\n",
      "D(x): 0.533, D(G(z)): 0.524\n",
      "2019-04-10 00:58:06,233 root         INFO     Train Epoch: 93 [512/8000 (6%)]\tTotal Loss: 0.398559\n",
      "Reconstruction: 0.335183, Regularization: 0.000266, Discriminator: 0.042872; Generator: 0.020238,\n",
      "D(x): 0.532, D(G(z)): 0.523\n",
      "2019-04-10 00:58:06,342 root         INFO     Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 0.398199\n",
      "Reconstruction: 0.334574, Regularization: 0.000294, Discriminator: 0.043056; Generator: 0.020275,\n",
      "D(x): 0.528, D(G(z)): 0.523\n",
      "2019-04-10 00:58:06,455 root         INFO     Train Epoch: 93 [1536/8000 (19%)]\tTotal Loss: 0.398642\n",
      "Reconstruction: 0.335286, Regularization: 0.000309, Discriminator: 0.042747; Generator: 0.020300,\n",
      "D(x): 0.533, D(G(z)): 0.522\n",
      "2019-04-10 00:58:06,567 root         INFO     Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 0.399075\n",
      "Reconstruction: 0.335627, Regularization: 0.000319, Discriminator: 0.042864; Generator: 0.020266,\n",
      "D(x): 0.532, D(G(z)): 0.523\n",
      "2019-04-10 00:58:06,680 root         INFO     Train Epoch: 93 [2560/8000 (32%)]\tTotal Loss: 0.398809\n",
      "Reconstruction: 0.335540, Regularization: 0.000243, Discriminator: 0.042713; Generator: 0.020313,\n",
      "D(x): 0.533, D(G(z)): 0.522\n",
      "2019-04-10 00:58:06,792 root         INFO     Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 0.399863\n",
      "Reconstruction: 0.336509, Regularization: 0.000263, Discriminator: 0.042708; Generator: 0.020384,\n",
      "D(x): 0.532, D(G(z)): 0.521\n",
      "2019-04-10 00:58:06,904 root         INFO     Train Epoch: 93 [3584/8000 (45%)]\tTotal Loss: 0.399793\n",
      "Reconstruction: 0.336554, Regularization: 0.000198, Discriminator: 0.042651; Generator: 0.020390,\n",
      "D(x): 0.533, D(G(z)): 0.521\n",
      "2019-04-10 00:58:07,016 root         INFO     Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 0.400056\n",
      "Reconstruction: 0.336294, Regularization: 0.000300, Discriminator: 0.043077; Generator: 0.020384,\n",
      "D(x): 0.526, D(G(z)): 0.521\n",
      "2019-04-10 00:58:07,129 root         INFO     Train Epoch: 93 [4608/8000 (58%)]\tTotal Loss: 0.400881\n",
      "Reconstruction: 0.337441, Regularization: 0.000282, Discriminator: 0.042733; Generator: 0.020425,\n",
      "D(x): 0.531, D(G(z)): 0.520\n",
      "2019-04-10 00:58:07,239 root         INFO     Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 0.400718\n",
      "Reconstruction: 0.337166, Regularization: 0.000215, Discriminator: 0.042927; Generator: 0.020410,\n",
      "D(x): 0.528, D(G(z)): 0.520\n",
      "2019-04-10 00:58:07,348 root         INFO     Train Epoch: 93 [5632/8000 (70%)]\tTotal Loss: 0.401351\n",
      "Reconstruction: 0.337829, Regularization: 0.000239, Discriminator: 0.042827; Generator: 0.020456,\n",
      "D(x): 0.529, D(G(z)): 0.520\n",
      "2019-04-10 00:58:07,456 root         INFO     Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 0.402815\n",
      "Reconstruction: 0.339024, Regularization: 0.000266, Discriminator: 0.043053; Generator: 0.020471,\n",
      "D(x): 0.525, D(G(z)): 0.519\n",
      "2019-04-10 00:58:07,566 root         INFO     Train Epoch: 93 [6656/8000 (83%)]\tTotal Loss: 0.403154\n",
      "Reconstruction: 0.339371, Regularization: 0.000377, Discriminator: 0.042877; Generator: 0.020528,\n",
      "D(x): 0.527, D(G(z)): 0.518\n",
      "2019-04-10 00:58:07,677 root         INFO     Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 0.402784\n",
      "Reconstruction: 0.339023, Regularization: 0.000265, Discriminator: 0.042937; Generator: 0.020559,\n",
      "D(x): 0.525, D(G(z)): 0.518\n",
      "2019-04-10 00:58:07,788 root         INFO     Train Epoch: 93 [7680/8000 (96%)]\tTotal Loss: 0.402569\n",
      "Reconstruction: 0.339158, Regularization: 0.000235, Discriminator: 0.042597; Generator: 0.020579,\n",
      "D(x): 0.531, D(G(z)): 0.518\n",
      "2019-04-10 00:58:07,869 root         INFO     ====> Epoch: 93 Average loss: 0.4004\n",
      "2019-04-10 00:58:07,897 root         INFO     Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 0.403575\n",
      "Reconstruction: 0.340027, Regularization: 0.000313, Discriminator: 0.042669; Generator: 0.020565,\n",
      "D(x): 0.530, D(G(z)): 0.518\n",
      "2019-04-10 00:58:08,011 root         INFO     Train Epoch: 94 [512/8000 (6%)]\tTotal Loss: 0.403245\n",
      "Reconstruction: 0.340000, Regularization: 0.000191, Discriminator: 0.042507; Generator: 0.020547,\n",
      "D(x): 0.533, D(G(z)): 0.518\n",
      "2019-04-10 00:58:08,124 root         INFO     Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 0.403526\n",
      "Reconstruction: 0.339785, Regularization: 0.000280, Discriminator: 0.042884; Generator: 0.020577,\n",
      "D(x): 0.526, D(G(z)): 0.518\n",
      "2019-04-10 00:58:08,236 root         INFO     Train Epoch: 94 [1536/8000 (19%)]\tTotal Loss: 0.403567\n",
      "Reconstruction: 0.340335, Regularization: 0.000225, Discriminator: 0.042413; Generator: 0.020593,\n",
      "D(x): 0.533, D(G(z)): 0.517\n",
      "2019-04-10 00:58:08,348 root         INFO     Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 0.404462\n",
      "Reconstruction: 0.340904, Regularization: 0.000261, Discriminator: 0.042710; Generator: 0.020586,\n",
      "D(x): 0.529, D(G(z)): 0.517\n",
      "2019-04-10 00:58:08,461 root         INFO     Train Epoch: 94 [2560/8000 (32%)]\tTotal Loss: 0.404751\n",
      "Reconstruction: 0.341058, Regularization: 0.000309, Discriminator: 0.042737; Generator: 0.020648,\n",
      "D(x): 0.527, D(G(z)): 0.516\n",
      "2019-04-10 00:58:08,573 root         INFO     Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 0.404846\n",
      "Reconstruction: 0.340839, Regularization: 0.000347, Discriminator: 0.042965; Generator: 0.020695,\n",
      "D(x): 0.522, D(G(z)): 0.516\n",
      "2019-04-10 00:58:08,685 root         INFO     Train Epoch: 94 [3584/8000 (45%)]\tTotal Loss: 0.405548\n",
      "Reconstruction: 0.341688, Regularization: 0.000325, Discriminator: 0.042814; Generator: 0.020721,\n",
      "D(x): 0.524, D(G(z)): 0.515\n",
      "2019-04-10 00:58:08,797 root         INFO     Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 0.406651\n",
      "Reconstruction: 0.342823, Regularization: 0.000285, Discriminator: 0.042808; Generator: 0.020735,\n",
      "D(x): 0.524, D(G(z)): 0.515\n",
      "2019-04-10 00:58:08,908 root         INFO     Train Epoch: 94 [4608/8000 (58%)]\tTotal Loss: 0.406346\n",
      "Reconstruction: 0.342618, Regularization: 0.000294, Discriminator: 0.042673; Generator: 0.020761,\n",
      "D(x): 0.526, D(G(z)): 0.515\n",
      "2019-04-10 00:58:09,019 root         INFO     Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 0.407191\n",
      "Reconstruction: 0.343481, Regularization: 0.000316, Discriminator: 0.042645; Generator: 0.020749,\n",
      "D(x): 0.527, D(G(z)): 0.515\n",
      "2019-04-10 00:58:09,131 root         INFO     Train Epoch: 94 [5632/8000 (70%)]\tTotal Loss: 0.406576\n",
      "Reconstruction: 0.342607, Regularization: 0.000277, Discriminator: 0.042985; Generator: 0.020707,\n",
      "D(x): 0.522, D(G(z)): 0.516\n",
      "2019-04-10 00:58:09,242 root         INFO     Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 0.406741\n",
      "Reconstruction: 0.343001, Regularization: 0.000194, Discriminator: 0.042813; Generator: 0.020732,\n",
      "D(x): 0.524, D(G(z)): 0.515\n",
      "2019-04-10 00:58:09,353 root         INFO     Train Epoch: 94 [6656/8000 (83%)]\tTotal Loss: 0.408223\n",
      "Reconstruction: 0.344561, Regularization: 0.000301, Discriminator: 0.042615; Generator: 0.020747,\n",
      "D(x): 0.527, D(G(z)): 0.515\n",
      "2019-04-10 00:58:09,464 root         INFO     Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 0.408294\n",
      "Reconstruction: 0.344380, Regularization: 0.000345, Discriminator: 0.042757; Generator: 0.020812,\n",
      "D(x): 0.524, D(G(z)): 0.514\n",
      "2019-04-10 00:58:09,575 root         INFO     Train Epoch: 94 [7680/8000 (96%)]\tTotal Loss: 0.408558\n",
      "Reconstruction: 0.344854, Regularization: 0.000244, Discriminator: 0.042662; Generator: 0.020798,\n",
      "D(x): 0.526, D(G(z)): 0.514\n",
      "2019-04-10 00:58:09,656 root         INFO     ====> Epoch: 94 Average loss: 0.4059\n",
      "2019-04-10 00:58:09,684 root         INFO     Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 0.408093\n",
      "Reconstruction: 0.344479, Regularization: 0.000210, Discriminator: 0.042612; Generator: 0.020791,\n",
      "D(x): 0.526, D(G(z)): 0.514\n",
      "2019-04-10 00:58:09,797 root         INFO     Train Epoch: 95 [512/8000 (6%)]\tTotal Loss: 0.409382\n",
      "Reconstruction: 0.345349, Regularization: 0.000306, Discriminator: 0.042968; Generator: 0.020760,\n",
      "D(x): 0.521, D(G(z)): 0.515\n",
      "2019-04-10 00:58:09,910 root         INFO     Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 0.409906\n",
      "Reconstruction: 0.346189, Regularization: 0.000270, Discriminator: 0.042702; Generator: 0.020745,\n",
      "D(x): 0.526, D(G(z)): 0.515\n",
      "2019-04-10 00:58:10,022 root         INFO     Train Epoch: 95 [1536/8000 (19%)]\tTotal Loss: 0.410988\n",
      "Reconstruction: 0.347373, Regularization: 0.000259, Discriminator: 0.042540; Generator: 0.020816,\n",
      "D(x): 0.527, D(G(z)): 0.514\n",
      "2019-04-10 00:58:10,135 root         INFO     Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 0.411140\n",
      "Reconstruction: 0.347101, Regularization: 0.000277, Discriminator: 0.042887; Generator: 0.020875,\n",
      "D(x): 0.521, D(G(z)): 0.513\n",
      "2019-04-10 00:58:10,247 root         INFO     Train Epoch: 95 [2560/8000 (32%)]\tTotal Loss: 0.411428\n",
      "Reconstruction: 0.347328, Regularization: 0.000282, Discriminator: 0.042900; Generator: 0.020917,\n",
      "D(x): 0.520, D(G(z)): 0.512\n",
      "2019-04-10 00:58:10,357 root         INFO     Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 0.411860\n",
      "Reconstruction: 0.347668, Regularization: 0.000285, Discriminator: 0.042976; Generator: 0.020930,\n",
      "D(x): 0.518, D(G(z)): 0.512\n",
      "2019-04-10 00:58:10,466 root         INFO     Train Epoch: 95 [3584/8000 (45%)]\tTotal Loss: 0.412020\n",
      "Reconstruction: 0.348436, Regularization: 0.000193, Discriminator: 0.042441; Generator: 0.020951,\n",
      "D(x): 0.527, D(G(z)): 0.511\n",
      "2019-04-10 00:58:10,576 root         INFO     Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 0.412512\n",
      "Reconstruction: 0.348372, Regularization: 0.000301, Discriminator: 0.042940; Generator: 0.020899,\n",
      "D(x): 0.519, D(G(z)): 0.512\n",
      "2019-04-10 00:58:10,686 root         INFO     Train Epoch: 95 [4608/8000 (58%)]\tTotal Loss: 0.414171\n",
      "Reconstruction: 0.349783, Regularization: 0.000431, Discriminator: 0.043038; Generator: 0.020919,\n",
      "D(x): 0.517, D(G(z)): 0.512\n",
      "2019-04-10 00:58:10,795 root         INFO     Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 0.414379\n",
      "Reconstruction: 0.350034, Regularization: 0.000297, Discriminator: 0.043085; Generator: 0.020962,\n",
      "D(x): 0.516, D(G(z)): 0.511\n",
      "2019-04-10 00:58:10,904 root         INFO     Train Epoch: 95 [5632/8000 (70%)]\tTotal Loss: 0.414825\n",
      "Reconstruction: 0.350529, Regularization: 0.000304, Discriminator: 0.042973; Generator: 0.021019,\n",
      "D(x): 0.517, D(G(z)): 0.510\n",
      "2019-04-10 00:58:11,013 root         INFO     Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 0.416303\n",
      "Reconstruction: 0.351813, Regularization: 0.000295, Discriminator: 0.043126; Generator: 0.021068,\n",
      "D(x): 0.513, D(G(z)): 0.510\n",
      "2019-04-10 00:58:11,122 root         INFO     Train Epoch: 95 [6656/8000 (83%)]\tTotal Loss: 0.416759\n",
      "Reconstruction: 0.352752, Regularization: 0.000245, Discriminator: 0.042718; Generator: 0.021044,\n",
      "D(x): 0.521, D(G(z)): 0.510\n",
      "2019-04-10 00:58:11,233 root         INFO     Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 0.416475\n",
      "Reconstruction: 0.352228, Regularization: 0.000254, Discriminator: 0.042906; Generator: 0.021088,\n",
      "D(x): 0.516, D(G(z)): 0.509\n",
      "2019-04-10 00:58:11,344 root         INFO     Train Epoch: 95 [7680/8000 (96%)]\tTotal Loss: 0.418046\n",
      "Reconstruction: 0.353739, Regularization: 0.000269, Discriminator: 0.042930; Generator: 0.021108,\n",
      "D(x): 0.516, D(G(z)): 0.509\n",
      "2019-04-10 00:58:11,425 root         INFO     ====> Epoch: 95 Average loss: 0.4133\n",
      "2019-04-10 00:58:11,452 root         INFO     Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 0.418924\n",
      "Reconstruction: 0.354705, Regularization: 0.000273, Discriminator: 0.042857; Generator: 0.021089,\n",
      "D(x): 0.517, D(G(z)): 0.509\n",
      "2019-04-10 00:58:11,562 root         INFO     Train Epoch: 96 [512/8000 (6%)]\tTotal Loss: 0.418661\n",
      "Reconstruction: 0.354538, Regularization: 0.000272, Discriminator: 0.042704; Generator: 0.021146,\n",
      "D(x): 0.519, D(G(z)): 0.508\n",
      "2019-04-10 00:58:11,672 root         INFO     Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 0.419874\n",
      "Reconstruction: 0.355399, Regularization: 0.000273, Discriminator: 0.043051; Generator: 0.021151,\n",
      "D(x): 0.513, D(G(z)): 0.508\n",
      "2019-04-10 00:58:11,783 root         INFO     Train Epoch: 96 [1536/8000 (19%)]\tTotal Loss: 0.421052\n",
      "Reconstruction: 0.356425, Regularization: 0.000280, Discriminator: 0.043151; Generator: 0.021197,\n",
      "D(x): 0.511, D(G(z)): 0.507\n",
      "2019-04-10 00:58:11,893 root         INFO     Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 0.421246\n",
      "Reconstruction: 0.356851, Regularization: 0.000372, Discriminator: 0.042783; Generator: 0.021240,\n",
      "D(x): 0.516, D(G(z)): 0.507\n",
      "2019-04-10 00:58:12,003 root         INFO     Train Epoch: 96 [2560/8000 (32%)]\tTotal Loss: 0.422464\n",
      "Reconstruction: 0.358115, Regularization: 0.000329, Discriminator: 0.042847; Generator: 0.021172,\n",
      "D(x): 0.516, D(G(z)): 0.508\n",
      "2019-04-10 00:58:12,113 root         INFO     Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 0.422826\n",
      "Reconstruction: 0.358359, Regularization: 0.000288, Discriminator: 0.042941; Generator: 0.021237,\n",
      "D(x): 0.513, D(G(z)): 0.507\n",
      "2019-04-10 00:58:12,223 root         INFO     Train Epoch: 96 [3584/8000 (45%)]\tTotal Loss: 0.423378\n",
      "Reconstruction: 0.359121, Regularization: 0.000296, Discriminator: 0.042726; Generator: 0.021235,\n",
      "D(x): 0.517, D(G(z)): 0.507\n",
      "2019-04-10 00:58:12,333 root         INFO     Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 0.424539\n",
      "Reconstruction: 0.360484, Regularization: 0.000208, Discriminator: 0.042650; Generator: 0.021197,\n",
      "D(x): 0.519, D(G(z)): 0.507\n",
      "2019-04-10 00:58:12,443 root         INFO     Train Epoch: 96 [4608/8000 (58%)]\tTotal Loss: 0.425528\n",
      "Reconstruction: 0.360893, Regularization: 0.000259, Discriminator: 0.043108; Generator: 0.021268,\n",
      "D(x): 0.510, D(G(z)): 0.506\n",
      "2019-04-10 00:58:12,553 root         INFO     Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 0.426165\n",
      "Reconstruction: 0.361409, Regularization: 0.000288, Discriminator: 0.043197; Generator: 0.021270,\n",
      "D(x): 0.509, D(G(z)): 0.506\n",
      "2019-04-10 00:58:12,663 root         INFO     Train Epoch: 96 [5632/8000 (70%)]\tTotal Loss: 0.426189\n",
      "Reconstruction: 0.361144, Regularization: 0.000342, Discriminator: 0.043403; Generator: 0.021300,\n",
      "D(x): 0.505, D(G(z)): 0.506\n",
      "2019-04-10 00:58:12,773 root         INFO     Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 0.426450\n",
      "Reconstruction: 0.361842, Regularization: 0.000315, Discriminator: 0.042953; Generator: 0.021339,\n",
      "D(x): 0.512, D(G(z)): 0.505\n",
      "2019-04-10 00:58:12,884 root         INFO     Train Epoch: 96 [6656/8000 (83%)]\tTotal Loss: 0.427394\n",
      "Reconstruction: 0.362653, Regularization: 0.000274, Discriminator: 0.043145; Generator: 0.021323,\n",
      "D(x): 0.509, D(G(z)): 0.505\n",
      "2019-04-10 00:58:12,995 root         INFO     Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 0.427108\n",
      "Reconstruction: 0.362967, Regularization: 0.000193, Discriminator: 0.042635; Generator: 0.021313,\n",
      "D(x): 0.517, D(G(z)): 0.506\n",
      "2019-04-10 00:58:13,107 root         INFO     Train Epoch: 96 [7680/8000 (96%)]\tTotal Loss: 0.428753\n",
      "Reconstruction: 0.364459, Regularization: 0.000248, Discriminator: 0.042769; Generator: 0.021277,\n",
      "D(x): 0.516, D(G(z)): 0.506\n",
      "2019-04-10 00:58:13,187 root         INFO     ====> Epoch: 96 Average loss: 0.4239\n",
      "2019-04-10 00:58:13,215 root         INFO     Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 0.429042\n",
      "Reconstruction: 0.363961, Regularization: 0.000355, Discriminator: 0.043417; Generator: 0.021310,\n",
      "D(x): 0.505, D(G(z)): 0.506\n",
      "2019-04-10 00:58:13,327 root         INFO     Train Epoch: 97 [512/8000 (6%)]\tTotal Loss: 0.429738\n",
      "Reconstruction: 0.364719, Regularization: 0.000276, Discriminator: 0.043385; Generator: 0.021357,\n",
      "D(x): 0.504, D(G(z)): 0.505\n",
      "2019-04-10 00:58:13,438 root         INFO     Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 0.429300\n",
      "Reconstruction: 0.364325, Regularization: 0.000251, Discriminator: 0.043300; Generator: 0.021423,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-10 00:58:13,550 root         INFO     Train Epoch: 97 [1536/8000 (19%)]\tTotal Loss: 0.430539\n",
      "Reconstruction: 0.365998, Regularization: 0.000291, Discriminator: 0.042802; Generator: 0.021447,\n",
      "D(x): 0.512, D(G(z)): 0.503\n",
      "2019-04-10 00:58:13,661 root         INFO     Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 0.431911\n",
      "Reconstruction: 0.366957, Regularization: 0.000215, Discriminator: 0.043236; Generator: 0.021503,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-10 00:58:13,772 root         INFO     Train Epoch: 97 [2560/8000 (32%)]\tTotal Loss: 0.431267\n",
      "Reconstruction: 0.366675, Regularization: 0.000268, Discriminator: 0.042854; Generator: 0.021470,\n",
      "D(x): 0.511, D(G(z)): 0.503\n",
      "2019-04-10 00:58:13,882 root         INFO     Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 0.433864\n",
      "Reconstruction: 0.369105, Regularization: 0.000275, Discriminator: 0.043030; Generator: 0.021454,\n",
      "D(x): 0.509, D(G(z)): 0.503\n",
      "2019-04-10 00:58:13,993 root         INFO     Train Epoch: 97 [3584/8000 (45%)]\tTotal Loss: 0.433829\n",
      "Reconstruction: 0.368895, Regularization: 0.000309, Discriminator: 0.043135; Generator: 0.021489,\n",
      "D(x): 0.506, D(G(z)): 0.503\n",
      "2019-04-10 00:58:14,108 root         INFO     Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 0.434212\n",
      "Reconstruction: 0.369078, Regularization: 0.000272, Discriminator: 0.043288; Generator: 0.021574,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:58:14,219 root         INFO     Train Epoch: 97 [4608/8000 (58%)]\tTotal Loss: 0.436049\n",
      "Reconstruction: 0.370700, Regularization: 0.000289, Discriminator: 0.043477; Generator: 0.021582,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-10 00:58:14,329 root         INFO     Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 0.436234\n",
      "Reconstruction: 0.371425, Regularization: 0.000259, Discriminator: 0.042990; Generator: 0.021559,\n",
      "D(x): 0.507, D(G(z)): 0.502\n",
      "2019-04-10 00:58:14,440 root         INFO     Train Epoch: 97 [5632/8000 (70%)]\tTotal Loss: 0.437168\n",
      "Reconstruction: 0.371846, Regularization: 0.000266, Discriminator: 0.043476; Generator: 0.021580,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-10 00:58:14,550 root         INFO     Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 0.437217\n",
      "Reconstruction: 0.372289, Regularization: 0.000207, Discriminator: 0.043176; Generator: 0.021546,\n",
      "D(x): 0.505, D(G(z)): 0.502\n",
      "2019-04-10 00:58:14,660 root         INFO     Train Epoch: 97 [6656/8000 (83%)]\tTotal Loss: 0.439299\n",
      "Reconstruction: 0.374176, Regularization: 0.000319, Discriminator: 0.043202; Generator: 0.021602,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-10 00:58:14,770 root         INFO     Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 0.440142\n",
      "Reconstruction: 0.374900, Regularization: 0.000201, Discriminator: 0.043338; Generator: 0.021704,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:14,884 root         INFO     Train Epoch: 97 [7680/8000 (96%)]\tTotal Loss: 0.441958\n",
      "Reconstruction: 0.376686, Regularization: 0.000230, Discriminator: 0.043317; Generator: 0.021724,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:14,966 root         INFO     ====> Epoch: 97 Average loss: 0.4347\n",
      "2019-04-10 00:58:14,993 root         INFO     Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 0.442590\n",
      "Reconstruction: 0.376755, Regularization: 0.000281, Discriminator: 0.043784; Generator: 0.021770,\n",
      "D(x): 0.491, D(G(z)): 0.498\n",
      "2019-04-10 00:58:15,106 root         INFO     Train Epoch: 98 [512/8000 (6%)]\tTotal Loss: 0.442904\n",
      "Reconstruction: 0.377091, Regularization: 0.000327, Discriminator: 0.043671; Generator: 0.021815,\n",
      "D(x): 0.493, D(G(z)): 0.498\n",
      "2019-04-10 00:58:15,218 root         INFO     Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 0.442679\n",
      "Reconstruction: 0.377241, Regularization: 0.000211, Discriminator: 0.043449; Generator: 0.021778,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-10 00:58:15,331 root         INFO     Train Epoch: 98 [1536/8000 (19%)]\tTotal Loss: 0.444720\n",
      "Reconstruction: 0.379086, Regularization: 0.000302, Discriminator: 0.043481; Generator: 0.021850,\n",
      "D(x): 0.495, D(G(z)): 0.497\n",
      "2019-04-10 00:58:15,443 root         INFO     Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 0.444278\n",
      "Reconstruction: 0.379000, Regularization: 0.000232, Discriminator: 0.043190; Generator: 0.021856,\n",
      "D(x): 0.499, D(G(z)): 0.497\n",
      "2019-04-10 00:58:15,554 root         INFO     Train Epoch: 98 [2560/8000 (32%)]\tTotal Loss: 0.445289\n",
      "Reconstruction: 0.379814, Regularization: 0.000241, Discriminator: 0.043329; Generator: 0.021905,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-04-10 00:58:15,666 root         INFO     Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 0.446398\n",
      "Reconstruction: 0.381005, Regularization: 0.000203, Discriminator: 0.043304; Generator: 0.021886,\n",
      "D(x): 0.497, D(G(z)): 0.496\n",
      "2019-04-10 00:58:15,776 root         INFO     Train Epoch: 98 [3584/8000 (45%)]\tTotal Loss: 0.447146\n",
      "Reconstruction: 0.381241, Regularization: 0.000325, Discriminator: 0.043659; Generator: 0.021920,\n",
      "D(x): 0.491, D(G(z)): 0.496\n",
      "2019-04-10 00:58:15,887 root         INFO     Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 0.447693\n",
      "Reconstruction: 0.382383, Regularization: 0.000259, Discriminator: 0.043199; Generator: 0.021852,\n",
      "D(x): 0.499, D(G(z)): 0.497\n",
      "2019-04-10 00:58:15,998 root         INFO     Train Epoch: 98 [4608/8000 (58%)]\tTotal Loss: 0.448819\n",
      "Reconstruction: 0.383205, Regularization: 0.000293, Discriminator: 0.043450; Generator: 0.021871,\n",
      "D(x): 0.495, D(G(z)): 0.497\n",
      "2019-04-10 00:58:16,109 root         INFO     Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 0.449065\n",
      "Reconstruction: 0.383445, Regularization: 0.000223, Discriminator: 0.043459; Generator: 0.021939,\n",
      "D(x): 0.494, D(G(z)): 0.496\n",
      "2019-04-10 00:58:16,220 root         INFO     Train Epoch: 98 [5632/8000 (70%)]\tTotal Loss: 0.449865\n",
      "Reconstruction: 0.384373, Regularization: 0.000260, Discriminator: 0.043263; Generator: 0.021969,\n",
      "D(x): 0.496, D(G(z)): 0.495\n",
      "2019-04-10 00:58:16,332 root         INFO     Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 0.449169\n",
      "Reconstruction: 0.383896, Regularization: 0.000172, Discriminator: 0.043105; Generator: 0.021997,\n",
      "D(x): 0.498, D(G(z)): 0.495\n",
      "2019-04-10 00:58:16,443 root         INFO     Train Epoch: 98 [6656/8000 (83%)]\tTotal Loss: 0.450971\n",
      "Reconstruction: 0.384636, Regularization: 0.000421, Discriminator: 0.043882; Generator: 0.022032,\n",
      "D(x): 0.486, D(G(z)): 0.494\n",
      "2019-04-10 00:58:16,554 root         INFO     Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 0.451334\n",
      "Reconstruction: 0.385514, Regularization: 0.000260, Discriminator: 0.043517; Generator: 0.022044,\n",
      "D(x): 0.491, D(G(z)): 0.494\n",
      "2019-04-10 00:58:16,664 root         INFO     Train Epoch: 98 [7680/8000 (96%)]\tTotal Loss: 0.452476\n",
      "Reconstruction: 0.386785, Regularization: 0.000186, Discriminator: 0.043427; Generator: 0.022079,\n",
      "D(x): 0.492, D(G(z)): 0.493\n",
      "2019-04-10 00:58:16,746 root         INFO     ====> Epoch: 98 Average loss: 0.4474\n",
      "2019-04-10 00:58:16,773 root         INFO     Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 0.453350\n",
      "Reconstruction: 0.387043, Regularization: 0.000329, Discriminator: 0.043922; Generator: 0.022056,\n",
      "D(x): 0.485, D(G(z)): 0.494\n",
      "2019-04-10 00:58:16,885 root         INFO     Train Epoch: 99 [512/8000 (6%)]\tTotal Loss: 0.454334\n",
      "Reconstruction: 0.388095, Regularization: 0.000261, Discriminator: 0.043873; Generator: 0.022106,\n",
      "D(x): 0.485, D(G(z)): 0.493\n",
      "2019-04-10 00:58:16,997 root         INFO     Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 0.455823\n",
      "Reconstruction: 0.389722, Regularization: 0.000266, Discriminator: 0.043748; Generator: 0.022086,\n",
      "D(x): 0.487, D(G(z)): 0.493\n",
      "2019-04-10 00:58:17,109 root         INFO     Train Epoch: 99 [1536/8000 (19%)]\tTotal Loss: 0.456566\n",
      "Reconstruction: 0.390908, Regularization: 0.000225, Discriminator: 0.043285; Generator: 0.022146,\n",
      "D(x): 0.493, D(G(z)): 0.492\n",
      "2019-04-10 00:58:17,221 root         INFO     Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 0.456128\n",
      "Reconstruction: 0.390227, Regularization: 0.000184, Discriminator: 0.043555; Generator: 0.022162,\n",
      "D(x): 0.489, D(G(z)): 0.492\n",
      "2019-04-10 00:58:17,334 root         INFO     Train Epoch: 99 [2560/8000 (32%)]\tTotal Loss: 0.456970\n",
      "Reconstruction: 0.390817, Regularization: 0.000281, Discriminator: 0.043708; Generator: 0.022164,\n",
      "D(x): 0.486, D(G(z)): 0.492\n",
      "2019-04-10 00:58:17,446 root         INFO     Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 0.457998\n",
      "Reconstruction: 0.391781, Regularization: 0.000261, Discriminator: 0.043740; Generator: 0.022215,\n",
      "D(x): 0.485, D(G(z)): 0.491\n",
      "2019-04-10 00:58:17,558 root         INFO     Train Epoch: 99 [3584/8000 (45%)]\tTotal Loss: 0.459086\n",
      "Reconstruction: 0.393042, Regularization: 0.000237, Discriminator: 0.043539; Generator: 0.022268,\n",
      "D(x): 0.487, D(G(z)): 0.490\n",
      "2019-04-10 00:58:17,667 root         INFO     Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 0.460618\n",
      "Reconstruction: 0.394546, Regularization: 0.000213, Discriminator: 0.043638; Generator: 0.022221,\n",
      "D(x): 0.487, D(G(z)): 0.491\n",
      "2019-04-10 00:58:17,776 root         INFO     Train Epoch: 99 [4608/8000 (58%)]\tTotal Loss: 0.459918\n",
      "Reconstruction: 0.393723, Regularization: 0.000209, Discriminator: 0.043717; Generator: 0.022270,\n",
      "D(x): 0.485, D(G(z)): 0.490\n",
      "2019-04-10 00:58:17,885 root         INFO     Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 0.462202\n",
      "Reconstruction: 0.395791, Regularization: 0.000287, Discriminator: 0.043796; Generator: 0.022328,\n",
      "D(x): 0.482, D(G(z)): 0.489\n",
      "2019-04-10 00:58:17,993 root         INFO     Train Epoch: 99 [5632/8000 (70%)]\tTotal Loss: 0.462460\n",
      "Reconstruction: 0.396158, Regularization: 0.000254, Discriminator: 0.043651; Generator: 0.022397,\n",
      "D(x): 0.484, D(G(z)): 0.488\n",
      "2019-04-10 00:58:18,102 root         INFO     Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 0.462312\n",
      "Reconstruction: 0.396338, Regularization: 0.000173, Discriminator: 0.043278; Generator: 0.022524,\n",
      "D(x): 0.488, D(G(z)): 0.486\n",
      "2019-04-10 00:58:18,211 root         INFO     Train Epoch: 99 [6656/8000 (83%)]\tTotal Loss: 0.463134\n",
      "Reconstruction: 0.396805, Regularization: 0.000165, Discriminator: 0.043741; Generator: 0.022423,\n",
      "D(x): 0.482, D(G(z)): 0.488\n",
      "2019-04-10 00:58:18,320 root         INFO     Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 0.463596\n",
      "Reconstruction: 0.397344, Regularization: 0.000208, Discriminator: 0.043729; Generator: 0.022314,\n",
      "D(x): 0.484, D(G(z)): 0.490\n",
      "2019-04-10 00:58:18,429 root         INFO     Train Epoch: 99 [7680/8000 (96%)]\tTotal Loss: 0.465298\n",
      "Reconstruction: 0.398982, Regularization: 0.000270, Discriminator: 0.043664; Generator: 0.022382,\n",
      "D(x): 0.484, D(G(z)): 0.489\n",
      "2019-04-10 00:58:18,509 root         INFO     ====> Epoch: 99 Average loss: 0.4595\n",
      "2019-04-10 00:58:18,536 root         INFO     Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 0.464938\n",
      "Reconstruction: 0.398945, Regularization: 0.000199, Discriminator: 0.043433; Generator: 0.022362,\n",
      "D(x): 0.488, D(G(z)): 0.489\n",
      "2019-04-10 00:58:18,647 root         INFO     Train Epoch: 100 [512/8000 (6%)]\tTotal Loss: 0.465956\n",
      "Reconstruction: 0.399934, Regularization: 0.000148, Discriminator: 0.043451; Generator: 0.022424,\n",
      "D(x): 0.486, D(G(z)): 0.488\n",
      "2019-04-10 00:58:18,757 root         INFO     Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 0.465567\n",
      "Reconstruction: 0.399414, Regularization: 0.000160, Discriminator: 0.043619; Generator: 0.022374,\n",
      "D(x): 0.484, D(G(z)): 0.489\n",
      "2019-04-10 00:58:18,868 root         INFO     Train Epoch: 100 [1536/8000 (19%)]\tTotal Loss: 0.467376\n",
      "Reconstruction: 0.401007, Regularization: 0.000185, Discriminator: 0.043746; Generator: 0.022438,\n",
      "D(x): 0.482, D(G(z)): 0.488\n",
      "2019-04-10 00:58:18,979 root         INFO     Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 0.467467\n",
      "Reconstruction: 0.400955, Regularization: 0.000291, Discriminator: 0.043774; Generator: 0.022447,\n",
      "D(x): 0.481, D(G(z)): 0.488\n",
      "2019-04-10 00:58:19,090 root         INFO     Train Epoch: 100 [2560/8000 (32%)]\tTotal Loss: 0.468937\n",
      "Reconstruction: 0.402172, Regularization: 0.000294, Discriminator: 0.043938; Generator: 0.022533,\n",
      "D(x): 0.477, D(G(z)): 0.486\n",
      "2019-04-10 00:58:19,201 root         INFO     Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 0.469139\n",
      "Reconstruction: 0.402656, Regularization: 0.000181, Discriminator: 0.043773; Generator: 0.022530,\n",
      "D(x): 0.480, D(G(z)): 0.486\n",
      "2019-04-10 00:58:19,312 root         INFO     Train Epoch: 100 [3584/8000 (45%)]\tTotal Loss: 0.470042\n",
      "Reconstruction: 0.403492, Regularization: 0.000213, Discriminator: 0.043717; Generator: 0.022620,\n",
      "D(x): 0.479, D(G(z)): 0.485\n",
      "2019-04-10 00:58:19,423 root         INFO     Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 0.470065\n",
      "Reconstruction: 0.403659, Regularization: 0.000224, Discriminator: 0.043621; Generator: 0.022560,\n",
      "D(x): 0.482, D(G(z)): 0.486\n",
      "2019-04-10 00:58:19,534 root         INFO     Train Epoch: 100 [4608/8000 (58%)]\tTotal Loss: 0.471084\n",
      "Reconstruction: 0.404786, Regularization: 0.000138, Discriminator: 0.043592; Generator: 0.022568,\n",
      "D(x): 0.482, D(G(z)): 0.486\n",
      "2019-04-10 00:58:19,645 root         INFO     Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 0.471817\n",
      "Reconstruction: 0.405277, Regularization: 0.000220, Discriminator: 0.043724; Generator: 0.022595,\n",
      "D(x): 0.480, D(G(z)): 0.485\n",
      "2019-04-10 00:58:19,755 root         INFO     Train Epoch: 100 [5632/8000 (70%)]\tTotal Loss: 0.472681\n",
      "Reconstruction: 0.406255, Regularization: 0.000195, Discriminator: 0.043635; Generator: 0.022596,\n",
      "D(x): 0.481, D(G(z)): 0.485\n",
      "2019-04-10 00:58:19,866 root         INFO     Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 0.473040\n",
      "Reconstruction: 0.406459, Regularization: 0.000172, Discriminator: 0.043722; Generator: 0.022687,\n",
      "D(x): 0.478, D(G(z)): 0.484\n",
      "2019-04-10 00:58:19,977 root         INFO     Train Epoch: 100 [6656/8000 (83%)]\tTotal Loss: 0.473338\n",
      "Reconstruction: 0.406720, Regularization: 0.000217, Discriminator: 0.043683; Generator: 0.022719,\n",
      "D(x): 0.478, D(G(z)): 0.483\n",
      "2019-04-10 00:58:20,087 root         INFO     Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 0.473389\n",
      "Reconstruction: 0.406918, Regularization: 0.000160, Discriminator: 0.043606; Generator: 0.022705,\n",
      "D(x): 0.480, D(G(z)): 0.484\n",
      "2019-04-10 00:58:20,196 root         INFO     Train Epoch: 100 [7680/8000 (96%)]\tTotal Loss: 0.474060\n",
      "Reconstruction: 0.407547, Regularization: 0.000156, Discriminator: 0.043696; Generator: 0.022661,\n",
      "D(x): 0.479, D(G(z)): 0.484\n",
      "2019-04-10 00:58:20,278 root         INFO     ====> Epoch: 100 Average loss: 0.4703\n",
      "2019-04-10 00:58:20,305 root         INFO     Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 0.474467\n",
      "Reconstruction: 0.407861, Regularization: 0.000207, Discriminator: 0.043664; Generator: 0.022735,\n",
      "D(x): 0.478, D(G(z)): 0.483\n",
      "2019-04-10 00:58:20,416 root         INFO     Train Epoch: 101 [512/8000 (6%)]\tTotal Loss: 0.474183\n",
      "Reconstruction: 0.407640, Regularization: 0.000170, Discriminator: 0.043650; Generator: 0.022723,\n",
      "D(x): 0.479, D(G(z)): 0.483\n",
      "2019-04-10 00:58:20,526 root         INFO     Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 0.475366\n",
      "Reconstruction: 0.408848, Regularization: 0.000264, Discriminator: 0.043477; Generator: 0.022776,\n",
      "D(x): 0.481, D(G(z)): 0.482\n",
      "2019-04-10 00:58:20,637 root         INFO     Train Epoch: 101 [1536/8000 (19%)]\tTotal Loss: 0.475723\n",
      "Reconstruction: 0.409086, Regularization: 0.000163, Discriminator: 0.043636; Generator: 0.022838,\n",
      "D(x): 0.477, D(G(z)): 0.482\n",
      "2019-04-10 00:58:20,746 root         INFO     Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 0.476197\n",
      "Reconstruction: 0.409586, Regularization: 0.000173, Discriminator: 0.043566; Generator: 0.022872,\n",
      "D(x): 0.478, D(G(z)): 0.481\n",
      "2019-04-10 00:58:20,855 root         INFO     Train Epoch: 101 [2560/8000 (32%)]\tTotal Loss: 0.476084\n",
      "Reconstruction: 0.409336, Regularization: 0.000302, Discriminator: 0.043571; Generator: 0.022875,\n",
      "D(x): 0.478, D(G(z)): 0.481\n",
      "2019-04-10 00:58:20,965 root         INFO     Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 0.476558\n",
      "Reconstruction: 0.409995, Regularization: 0.000151, Discriminator: 0.043468; Generator: 0.022944,\n",
      "D(x): 0.478, D(G(z)): 0.480\n",
      "2019-04-10 00:58:21,074 root         INFO     Train Epoch: 101 [3584/8000 (45%)]\tTotal Loss: 0.477477\n",
      "Reconstruction: 0.410848, Regularization: 0.000182, Discriminator: 0.043447; Generator: 0.022999,\n",
      "D(x): 0.478, D(G(z)): 0.479\n",
      "2019-04-10 00:58:21,183 root         INFO     Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 0.477286\n",
      "Reconstruction: 0.410665, Regularization: 0.000214, Discriminator: 0.043436; Generator: 0.022971,\n",
      "D(x): 0.479, D(G(z)): 0.479\n",
      "2019-04-10 00:58:21,292 root         INFO     Train Epoch: 101 [4608/8000 (58%)]\tTotal Loss: 0.477737\n",
      "Reconstruction: 0.410989, Regularization: 0.000214, Discriminator: 0.043392; Generator: 0.023143,\n",
      "D(x): 0.477, D(G(z)): 0.477\n",
      "2019-04-10 00:58:21,401 root         INFO     Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 0.477214\n",
      "Reconstruction: 0.410411, Regularization: 0.000231, Discriminator: 0.043352; Generator: 0.023220,\n",
      "D(x): 0.476, D(G(z)): 0.476\n",
      "2019-04-10 00:58:21,510 root         INFO     Train Epoch: 101 [5632/8000 (70%)]\tTotal Loss: 0.477218\n",
      "Reconstruction: 0.410548, Regularization: 0.000211, Discriminator: 0.043249; Generator: 0.023210,\n",
      "D(x): 0.478, D(G(z)): 0.476\n",
      "2019-04-10 00:58:21,619 root         INFO     Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 0.476527\n",
      "Reconstruction: 0.409790, Regularization: 0.000263, Discriminator: 0.043240; Generator: 0.023234,\n",
      "D(x): 0.478, D(G(z)): 0.475\n",
      "2019-04-10 00:58:21,728 root         INFO     Train Epoch: 101 [6656/8000 (83%)]\tTotal Loss: 0.475945\n",
      "Reconstruction: 0.409203, Regularization: 0.000184, Discriminator: 0.043227; Generator: 0.023330,\n",
      "D(x): 0.477, D(G(z)): 0.474\n",
      "2019-04-10 00:58:21,839 root         INFO     Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 0.475385\n",
      "Reconstruction: 0.408691, Regularization: 0.000195, Discriminator: 0.043171; Generator: 0.023328,\n",
      "D(x): 0.478, D(G(z)): 0.474\n",
      "2019-04-10 00:58:21,950 root         INFO     Train Epoch: 101 [7680/8000 (96%)]\tTotal Loss: 0.475291\n",
      "Reconstruction: 0.408521, Regularization: 0.000153, Discriminator: 0.043133; Generator: 0.023483,\n",
      "D(x): 0.476, D(G(z)): 0.472\n",
      "2019-04-10 00:58:22,031 root         INFO     ====> Epoch: 101 Average loss: 0.4761\n",
      "2019-04-10 00:58:22,059 root         INFO     Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 0.473887\n",
      "Reconstruction: 0.407219, Regularization: 0.000247, Discriminator: 0.043037; Generator: 0.023384,\n",
      "D(x): 0.479, D(G(z)): 0.473\n",
      "2019-04-10 00:58:22,170 root         INFO     Train Epoch: 102 [512/8000 (6%)]\tTotal Loss: 0.474181\n",
      "Reconstruction: 0.407447, Regularization: 0.000236, Discriminator: 0.042966; Generator: 0.023531,\n",
      "D(x): 0.478, D(G(z)): 0.471\n",
      "2019-04-10 00:58:22,280 root         INFO     Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 0.474487\n",
      "Reconstruction: 0.407664, Regularization: 0.000280, Discriminator: 0.042960; Generator: 0.023583,\n",
      "D(x): 0.477, D(G(z)): 0.470\n",
      "2019-04-10 00:58:22,391 root         INFO     Train Epoch: 102 [1536/8000 (19%)]\tTotal Loss: 0.473046\n",
      "Reconstruction: 0.406117, Regularization: 0.000189, Discriminator: 0.043038; Generator: 0.023701,\n",
      "D(x): 0.475, D(G(z)): 0.468\n",
      "2019-04-10 00:58:22,501 root         INFO     Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 0.472890\n",
      "Reconstruction: 0.406299, Regularization: 0.000248, Discriminator: 0.042722; Generator: 0.023621,\n",
      "D(x): 0.481, D(G(z)): 0.470\n",
      "2019-04-10 00:58:22,611 root         INFO     Train Epoch: 102 [2560/8000 (32%)]\tTotal Loss: 0.472084\n",
      "Reconstruction: 0.405637, Regularization: 0.000232, Discriminator: 0.042732; Generator: 0.023482,\n",
      "D(x): 0.482, D(G(z)): 0.472\n",
      "2019-04-10 00:58:22,722 root         INFO     Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 0.470812\n",
      "Reconstruction: 0.404353, Regularization: 0.000171, Discriminator: 0.042698; Generator: 0.023589,\n",
      "D(x): 0.481, D(G(z)): 0.470\n",
      "2019-04-10 00:58:22,832 root         INFO     Train Epoch: 102 [3584/8000 (45%)]\tTotal Loss: 0.469698\n",
      "Reconstruction: 0.402872, Regularization: 0.000234, Discriminator: 0.043125; Generator: 0.023466,\n",
      "D(x): 0.477, D(G(z)): 0.472\n",
      "2019-04-10 00:58:22,943 root         INFO     Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 0.468218\n",
      "Reconstruction: 0.401576, Regularization: 0.000170, Discriminator: 0.043210; Generator: 0.023262,\n",
      "D(x): 0.478, D(G(z)): 0.475\n",
      "2019-04-10 00:58:23,054 root         INFO     Train Epoch: 102 [4608/8000 (58%)]\tTotal Loss: 0.466700\n",
      "Reconstruction: 0.400521, Regularization: 0.000247, Discriminator: 0.042728; Generator: 0.023204,\n",
      "D(x): 0.486, D(G(z)): 0.476\n",
      "2019-04-10 00:58:23,164 root         INFO     Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 0.464951\n",
      "Reconstruction: 0.398629, Regularization: 0.000242, Discriminator: 0.042772; Generator: 0.023307,\n",
      "D(x): 0.484, D(G(z)): 0.474\n",
      "2019-04-10 00:58:23,275 root         INFO     Train Epoch: 102 [5632/8000 (70%)]\tTotal Loss: 0.464055\n",
      "Reconstruction: 0.398126, Regularization: 0.000282, Discriminator: 0.042540; Generator: 0.023107,\n",
      "D(x): 0.491, D(G(z)): 0.477\n",
      "2019-04-10 00:58:23,385 root         INFO     Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 0.462466\n",
      "Reconstruction: 0.396399, Regularization: 0.000215, Discriminator: 0.042865; Generator: 0.022986,\n",
      "D(x): 0.487, D(G(z)): 0.479\n",
      "2019-04-10 00:58:23,497 root         INFO     Train Epoch: 102 [6656/8000 (83%)]\tTotal Loss: 0.461833\n",
      "Reconstruction: 0.395726, Regularization: 0.000259, Discriminator: 0.042708; Generator: 0.023139,\n",
      "D(x): 0.488, D(G(z)): 0.477\n",
      "2019-04-10 00:58:23,608 root         INFO     Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 0.460412\n",
      "Reconstruction: 0.393579, Regularization: 0.000215, Discriminator: 0.043564; Generator: 0.023054,\n",
      "D(x): 0.476, D(G(z)): 0.478\n",
      "2019-04-10 00:58:23,719 root         INFO     Train Epoch: 102 [7680/8000 (96%)]\tTotal Loss: 0.457394\n",
      "Reconstruction: 0.391830, Regularization: 0.000208, Discriminator: 0.042791; Generator: 0.022565,\n",
      "D(x): 0.495, D(G(z)): 0.486\n",
      "2019-04-10 00:58:23,800 root         INFO     ====> Epoch: 102 Average loss: 0.4677\n",
      "2019-04-10 00:58:23,827 root         INFO     Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 0.456899\n",
      "Reconstruction: 0.391195, Regularization: 0.000238, Discriminator: 0.042766; Generator: 0.022700,\n",
      "D(x): 0.493, D(G(z)): 0.484\n",
      "2019-04-10 00:58:23,940 root         INFO     Train Epoch: 103 [512/8000 (6%)]\tTotal Loss: 0.456707\n",
      "Reconstruction: 0.390756, Regularization: 0.000371, Discriminator: 0.043044; Generator: 0.022537,\n",
      "D(x): 0.491, D(G(z)): 0.486\n",
      "2019-04-10 00:58:24,051 root         INFO     Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 0.454341\n",
      "Reconstruction: 0.388549, Regularization: 0.000227, Discriminator: 0.043019; Generator: 0.022547,\n",
      "D(x): 0.492, D(G(z)): 0.486\n",
      "2019-04-10 00:58:24,163 root         INFO     Train Epoch: 103 [1536/8000 (19%)]\tTotal Loss: 0.452263\n",
      "Reconstruction: 0.386670, Regularization: 0.000236, Discriminator: 0.042937; Generator: 0.022419,\n",
      "D(x): 0.495, D(G(z)): 0.488\n",
      "2019-04-10 00:58:24,275 root         INFO     Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 0.451253\n",
      "Reconstruction: 0.385265, Regularization: 0.000228, Discriminator: 0.043169; Generator: 0.022591,\n",
      "D(x): 0.489, D(G(z)): 0.485\n",
      "2019-04-10 00:58:24,387 root         INFO     Train Epoch: 103 [2560/8000 (32%)]\tTotal Loss: 0.448913\n",
      "Reconstruction: 0.383311, Regularization: 0.000274, Discriminator: 0.043118; Generator: 0.022210,\n",
      "D(x): 0.495, D(G(z)): 0.491\n",
      "2019-04-10 00:58:24,499 root         INFO     Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 0.448391\n",
      "Reconstruction: 0.382811, Regularization: 0.000295, Discriminator: 0.043271; Generator: 0.022013,\n",
      "D(x): 0.496, D(G(z)): 0.494\n",
      "2019-04-10 00:58:24,610 root         INFO     Train Epoch: 103 [3584/8000 (45%)]\tTotal Loss: 0.446936\n",
      "Reconstruction: 0.381562, Regularization: 0.000274, Discriminator: 0.042926; Generator: 0.022175,\n",
      "D(x): 0.499, D(G(z)): 0.492\n",
      "2019-04-10 00:58:24,720 root         INFO     Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 0.445488\n",
      "Reconstruction: 0.380256, Regularization: 0.000208, Discriminator: 0.042960; Generator: 0.022063,\n",
      "D(x): 0.500, D(G(z)): 0.494\n",
      "2019-04-10 00:58:24,830 root         INFO     Train Epoch: 103 [4608/8000 (58%)]\tTotal Loss: 0.444126\n",
      "Reconstruction: 0.379018, Regularization: 0.000244, Discriminator: 0.042942; Generator: 0.021921,\n",
      "D(x): 0.503, D(G(z)): 0.496\n",
      "2019-04-10 00:58:24,939 root         INFO     Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 0.442703\n",
      "Reconstruction: 0.376818, Regularization: 0.000232, Discriminator: 0.043666; Generator: 0.021988,\n",
      "D(x): 0.490, D(G(z)): 0.495\n",
      "2019-04-10 00:58:25,048 root         INFO     Train Epoch: 103 [5632/8000 (70%)]\tTotal Loss: 0.440383\n",
      "Reconstruction: 0.375195, Regularization: 0.000295, Discriminator: 0.043357; Generator: 0.021536,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:58:25,157 root         INFO     Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 0.438265\n",
      "Reconstruction: 0.373725, Regularization: 0.000252, Discriminator: 0.043078; Generator: 0.021210,\n",
      "D(x): 0.512, D(G(z)): 0.507\n",
      "2019-04-10 00:58:25,267 root         INFO     Train Epoch: 103 [6656/8000 (83%)]\tTotal Loss: 0.437959\n",
      "Reconstruction: 0.372684, Regularization: 0.000254, Discriminator: 0.043632; Generator: 0.021389,\n",
      "D(x): 0.500, D(G(z)): 0.504\n",
      "2019-04-10 00:58:25,376 root         INFO     Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 0.436708\n",
      "Reconstruction: 0.371647, Regularization: 0.000173, Discriminator: 0.043567; Generator: 0.021320,\n",
      "D(x): 0.502, D(G(z)): 0.505\n",
      "2019-04-10 00:58:25,485 root         INFO     Train Epoch: 103 [7680/8000 (96%)]\tTotal Loss: 0.436047\n",
      "Reconstruction: 0.371197, Regularization: 0.000293, Discriminator: 0.043244; Generator: 0.021314,\n",
      "D(x): 0.508, D(G(z)): 0.506\n",
      "2019-04-10 00:58:25,565 root         INFO     ====> Epoch: 103 Average loss: 0.4456\n",
      "2019-04-10 00:58:25,592 root         INFO     Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 0.435582\n",
      "Reconstruction: 0.370128, Regularization: 0.000197, Discriminator: 0.043901; Generator: 0.021356,\n",
      "D(x): 0.496, D(G(z)): 0.505\n",
      "2019-04-10 00:58:25,701 root         INFO     Train Epoch: 104 [512/8000 (6%)]\tTotal Loss: 0.434000\n",
      "Reconstruction: 0.368356, Regularization: 0.000188, Discriminator: 0.044093; Generator: 0.021363,\n",
      "D(x): 0.493, D(G(z)): 0.505\n",
      "2019-04-10 00:58:25,810 root         INFO     Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 0.432267\n",
      "Reconstruction: 0.367675, Regularization: 0.000239, Discriminator: 0.043210; Generator: 0.021142,\n",
      "D(x): 0.511, D(G(z)): 0.508\n",
      "2019-04-10 00:58:25,918 root         INFO     Train Epoch: 104 [1536/8000 (19%)]\tTotal Loss: 0.431699\n",
      "Reconstruction: 0.367027, Regularization: 0.000192, Discriminator: 0.043480; Generator: 0.020999,\n",
      "D(x): 0.509, D(G(z)): 0.511\n",
      "2019-04-10 00:58:26,027 root         INFO     Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 0.429619\n",
      "Reconstruction: 0.364825, Regularization: 0.000196, Discriminator: 0.043675; Generator: 0.020924,\n",
      "D(x): 0.507, D(G(z)): 0.512\n",
      "2019-04-10 00:58:26,135 root         INFO     Train Epoch: 104 [2560/8000 (32%)]\tTotal Loss: 0.429101\n",
      "Reconstruction: 0.364432, Regularization: 0.000235, Discriminator: 0.043596; Generator: 0.020837,\n",
      "D(x): 0.510, D(G(z)): 0.513\n",
      "2019-04-10 00:58:26,242 root         INFO     Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 0.428658\n",
      "Reconstruction: 0.363958, Regularization: 0.000259, Discriminator: 0.043506; Generator: 0.020935,\n",
      "D(x): 0.509, D(G(z)): 0.512\n",
      "2019-04-10 00:58:26,351 root         INFO     Train Epoch: 104 [3584/8000 (45%)]\tTotal Loss: 0.427396\n",
      "Reconstruction: 0.362707, Regularization: 0.000279, Discriminator: 0.043635; Generator: 0.020775,\n",
      "D(x): 0.510, D(G(z)): 0.514\n",
      "2019-04-10 00:58:26,459 root         INFO     Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 0.425949\n",
      "Reconstruction: 0.361037, Regularization: 0.000188, Discriminator: 0.043893; Generator: 0.020832,\n",
      "D(x): 0.505, D(G(z)): 0.513\n",
      "2019-04-10 00:58:26,567 root         INFO     Train Epoch: 104 [4608/8000 (58%)]\tTotal Loss: 0.425878\n",
      "Reconstruction: 0.361433, Regularization: 0.000214, Discriminator: 0.043572; Generator: 0.020659,\n",
      "D(x): 0.513, D(G(z)): 0.516\n",
      "2019-04-10 00:58:26,674 root         INFO     Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 0.426670\n",
      "Reconstruction: 0.361929, Regularization: 0.000214, Discriminator: 0.043749; Generator: 0.020779,\n",
      "D(x): 0.508, D(G(z)): 0.514\n",
      "2019-04-10 00:58:26,781 root         INFO     Train Epoch: 104 [5632/8000 (70%)]\tTotal Loss: 0.425220\n",
      "Reconstruction: 0.360418, Regularization: 0.000282, Discriminator: 0.043737; Generator: 0.020784,\n",
      "D(x): 0.508, D(G(z)): 0.514\n",
      "2019-04-10 00:58:26,888 root         INFO     Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 0.423981\n",
      "Reconstruction: 0.359295, Regularization: 0.000251, Discriminator: 0.043705; Generator: 0.020730,\n",
      "D(x): 0.510, D(G(z)): 0.515\n",
      "2019-04-10 00:58:26,995 root         INFO     Train Epoch: 104 [6656/8000 (83%)]\tTotal Loss: 0.423008\n",
      "Reconstruction: 0.358320, Regularization: 0.000251, Discriminator: 0.043641; Generator: 0.020796,\n",
      "D(x): 0.509, D(G(z)): 0.514\n",
      "2019-04-10 00:58:27,102 root         INFO     Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 0.422386\n",
      "Reconstruction: 0.357988, Regularization: 0.000282, Discriminator: 0.043530; Generator: 0.020587,\n",
      "D(x): 0.515, D(G(z)): 0.517\n",
      "2019-04-10 00:58:27,209 root         INFO     Train Epoch: 104 [7680/8000 (96%)]\tTotal Loss: 0.423062\n",
      "Reconstruction: 0.358568, Regularization: 0.000242, Discriminator: 0.043600; Generator: 0.020651,\n",
      "D(x): 0.513, D(G(z)): 0.516\n",
      "2019-04-10 00:58:27,288 root         INFO     ====> Epoch: 104 Average loss: 0.4271\n",
      "2019-04-10 00:58:27,315 root         INFO     Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 0.421830\n",
      "Reconstruction: 0.357293, Regularization: 0.000212, Discriminator: 0.043550; Generator: 0.020774,\n",
      "D(x): 0.511, D(G(z)): 0.514\n",
      "2019-04-10 00:58:27,422 root         INFO     Train Epoch: 105 [512/8000 (6%)]\tTotal Loss: 0.421394\n",
      "Reconstruction: 0.356866, Regularization: 0.000256, Discriminator: 0.043524; Generator: 0.020748,\n",
      "D(x): 0.512, D(G(z)): 0.515\n",
      "2019-04-10 00:58:27,529 root         INFO     Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 0.420459\n",
      "Reconstruction: 0.355995, Regularization: 0.000259, Discriminator: 0.043492; Generator: 0.020713,\n",
      "D(x): 0.513, D(G(z)): 0.515\n",
      "2019-04-10 00:58:27,636 root         INFO     Train Epoch: 105 [1536/8000 (19%)]\tTotal Loss: 0.418797\n",
      "Reconstruction: 0.354405, Regularization: 0.000298, Discriminator: 0.043308; Generator: 0.020787,\n",
      "D(x): 0.515, D(G(z)): 0.514\n",
      "2019-04-10 00:58:27,742 root         INFO     Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 0.420185\n",
      "Reconstruction: 0.355666, Regularization: 0.000236, Discriminator: 0.043468; Generator: 0.020815,\n",
      "D(x): 0.512, D(G(z)): 0.514\n",
      "2019-04-10 00:58:27,852 root         INFO     Train Epoch: 105 [2560/8000 (32%)]\tTotal Loss: 0.420016\n",
      "Reconstruction: 0.355611, Regularization: 0.000264, Discriminator: 0.043477; Generator: 0.020664,\n",
      "D(x): 0.514, D(G(z)): 0.516\n",
      "2019-04-10 00:58:27,961 root         INFO     Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 0.419003\n",
      "Reconstruction: 0.354815, Regularization: 0.000228, Discriminator: 0.043403; Generator: 0.020557,\n",
      "D(x): 0.517, D(G(z)): 0.518\n",
      "2019-04-10 00:58:28,070 root         INFO     Train Epoch: 105 [3584/8000 (45%)]\tTotal Loss: 0.418779\n",
      "Reconstruction: 0.354500, Regularization: 0.000262, Discriminator: 0.043386; Generator: 0.020631,\n",
      "D(x): 0.516, D(G(z)): 0.517\n",
      "2019-04-10 00:58:28,180 root         INFO     Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 0.418920\n",
      "Reconstruction: 0.354498, Regularization: 0.000241, Discriminator: 0.043399; Generator: 0.020782,\n",
      "D(x): 0.513, D(G(z)): 0.514\n",
      "2019-04-10 00:58:28,289 root         INFO     Train Epoch: 105 [4608/8000 (58%)]\tTotal Loss: 0.418952\n",
      "Reconstruction: 0.354451, Regularization: 0.000244, Discriminator: 0.043390; Generator: 0.020867,\n",
      "D(x): 0.512, D(G(z)): 0.513\n",
      "2019-04-10 00:58:28,398 root         INFO     Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 0.420513\n",
      "Reconstruction: 0.356108, Regularization: 0.000238, Discriminator: 0.043359; Generator: 0.020808,\n",
      "D(x): 0.514, D(G(z)): 0.514\n",
      "2019-04-10 00:58:28,507 root         INFO     Train Epoch: 105 [5632/8000 (70%)]\tTotal Loss: 0.419147\n",
      "Reconstruction: 0.354814, Regularization: 0.000178, Discriminator: 0.043338; Generator: 0.020817,\n",
      "D(x): 0.514, D(G(z)): 0.514\n",
      "2019-04-10 00:58:28,616 root         INFO     Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 0.417866\n",
      "Reconstruction: 0.353464, Regularization: 0.000311, Discriminator: 0.043339; Generator: 0.020752,\n",
      "D(x): 0.515, D(G(z)): 0.515\n",
      "2019-04-10 00:58:28,725 root         INFO     Train Epoch: 105 [6656/8000 (83%)]\tTotal Loss: 0.418330\n",
      "Reconstruction: 0.353894, Regularization: 0.000289, Discriminator: 0.043322; Generator: 0.020824,\n",
      "D(x): 0.514, D(G(z)): 0.514\n",
      "2019-04-10 00:58:28,835 root         INFO     Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 0.419281\n",
      "Reconstruction: 0.354865, Regularization: 0.000248, Discriminator: 0.043265; Generator: 0.020902,\n",
      "D(x): 0.514, D(G(z)): 0.512\n",
      "2019-04-10 00:58:28,944 root         INFO     Train Epoch: 105 [7680/8000 (96%)]\tTotal Loss: 0.420133\n",
      "Reconstruction: 0.355750, Regularization: 0.000222, Discriminator: 0.043277; Generator: 0.020884,\n",
      "D(x): 0.514, D(G(z)): 0.513\n",
      "2019-04-10 00:58:29,024 root         INFO     ====> Epoch: 105 Average loss: 0.4196\n",
      "2019-04-10 00:58:29,051 root         INFO     Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 0.420145\n",
      "Reconstruction: 0.355794, Regularization: 0.000219, Discriminator: 0.043219; Generator: 0.020914,\n",
      "D(x): 0.514, D(G(z)): 0.512\n",
      "2019-04-10 00:58:29,160 root         INFO     Train Epoch: 106 [512/8000 (6%)]\tTotal Loss: 0.418828\n",
      "Reconstruction: 0.354404, Regularization: 0.000206, Discriminator: 0.043243; Generator: 0.020975,\n",
      "D(x): 0.513, D(G(z)): 0.511\n",
      "2019-04-10 00:58:29,269 root         INFO     Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 0.420318\n",
      "Reconstruction: 0.355685, Regularization: 0.000308, Discriminator: 0.043318; Generator: 0.021007,\n",
      "D(x): 0.511, D(G(z)): 0.511\n",
      "2019-04-10 00:58:29,377 root         INFO     Train Epoch: 106 [1536/8000 (19%)]\tTotal Loss: 0.420908\n",
      "Reconstruction: 0.356379, Regularization: 0.000265, Discriminator: 0.043281; Generator: 0.020984,\n",
      "D(x): 0.512, D(G(z)): 0.511\n",
      "2019-04-10 00:58:29,486 root         INFO     Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 0.419654\n",
      "Reconstruction: 0.355250, Regularization: 0.000193, Discriminator: 0.043197; Generator: 0.021013,\n",
      "D(x): 0.513, D(G(z)): 0.510\n",
      "2019-04-10 00:58:29,596 root         INFO     Train Epoch: 106 [2560/8000 (32%)]\tTotal Loss: 0.420727\n",
      "Reconstruction: 0.356263, Regularization: 0.000262, Discriminator: 0.043220; Generator: 0.020983,\n",
      "D(x): 0.513, D(G(z)): 0.511\n",
      "2019-04-10 00:58:29,705 root         INFO     Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 0.421301\n",
      "Reconstruction: 0.356898, Regularization: 0.000264, Discriminator: 0.043124; Generator: 0.021015,\n",
      "D(x): 0.514, D(G(z)): 0.510\n",
      "2019-04-10 00:58:29,815 root         INFO     Train Epoch: 106 [3584/8000 (45%)]\tTotal Loss: 0.421151\n",
      "Reconstruction: 0.356607, Regularization: 0.000229, Discriminator: 0.043223; Generator: 0.021091,\n",
      "D(x): 0.511, D(G(z)): 0.509\n",
      "2019-04-10 00:58:29,924 root         INFO     Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 0.422136\n",
      "Reconstruction: 0.357598, Regularization: 0.000263, Discriminator: 0.043143; Generator: 0.021132,\n",
      "D(x): 0.512, D(G(z)): 0.509\n",
      "2019-04-10 00:58:30,033 root         INFO     Train Epoch: 106 [4608/8000 (58%)]\tTotal Loss: 0.422389\n",
      "Reconstruction: 0.357692, Regularization: 0.000271, Discriminator: 0.043282; Generator: 0.021145,\n",
      "D(x): 0.509, D(G(z)): 0.508\n",
      "2019-04-10 00:58:30,142 root         INFO     Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 0.421762\n",
      "Reconstruction: 0.357168, Regularization: 0.000248, Discriminator: 0.043247; Generator: 0.021099,\n",
      "D(x): 0.511, D(G(z)): 0.509\n",
      "2019-04-10 00:58:30,251 root         INFO     Train Epoch: 106 [5632/8000 (70%)]\tTotal Loss: 0.423121\n",
      "Reconstruction: 0.358676, Regularization: 0.000250, Discriminator: 0.043102; Generator: 0.021093,\n",
      "D(x): 0.513, D(G(z)): 0.509\n",
      "2019-04-10 00:58:30,360 root         INFO     Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 0.424106\n",
      "Reconstruction: 0.359622, Regularization: 0.000241, Discriminator: 0.043062; Generator: 0.021180,\n",
      "D(x): 0.512, D(G(z)): 0.508\n",
      "2019-04-10 00:58:30,469 root         INFO     Train Epoch: 106 [6656/8000 (83%)]\tTotal Loss: 0.425595\n",
      "Reconstruction: 0.360868, Regularization: 0.000291, Discriminator: 0.043223; Generator: 0.021213,\n",
      "D(x): 0.509, D(G(z)): 0.507\n",
      "2019-04-10 00:58:30,579 root         INFO     Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 0.425897\n",
      "Reconstruction: 0.361334, Regularization: 0.000227, Discriminator: 0.043076; Generator: 0.021261,\n",
      "D(x): 0.511, D(G(z)): 0.506\n",
      "2019-04-10 00:58:30,688 root         INFO     Train Epoch: 106 [7680/8000 (96%)]\tTotal Loss: 0.427118\n",
      "Reconstruction: 0.362469, Regularization: 0.000252, Discriminator: 0.043112; Generator: 0.021285,\n",
      "D(x): 0.510, D(G(z)): 0.506\n",
      "2019-04-10 00:58:30,768 root         INFO     ====> Epoch: 106 Average loss: 0.4222\n",
      "2019-04-10 00:58:30,795 root         INFO     Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 0.425577\n",
      "Reconstruction: 0.360877, Regularization: 0.000262, Discriminator: 0.043136; Generator: 0.021302,\n",
      "D(x): 0.509, D(G(z)): 0.506\n",
      "2019-04-10 00:58:30,905 root         INFO     Train Epoch: 107 [512/8000 (6%)]\tTotal Loss: 0.427785\n",
      "Reconstruction: 0.363168, Regularization: 0.000209, Discriminator: 0.043175; Generator: 0.021232,\n",
      "D(x): 0.509, D(G(z)): 0.507\n",
      "2019-04-10 00:58:31,013 root         INFO     Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 0.427852\n",
      "Reconstruction: 0.363230, Regularization: 0.000216, Discriminator: 0.043144; Generator: 0.021262,\n",
      "D(x): 0.509, D(G(z)): 0.506\n",
      "2019-04-10 00:58:31,122 root         INFO     Train Epoch: 107 [1536/8000 (19%)]\tTotal Loss: 0.427763\n",
      "Reconstruction: 0.363086, Regularization: 0.000250, Discriminator: 0.043104; Generator: 0.021322,\n",
      "D(x): 0.509, D(G(z)): 0.505\n",
      "2019-04-10 00:58:31,230 root         INFO     Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 0.428571\n",
      "Reconstruction: 0.363903, Regularization: 0.000214, Discriminator: 0.043087; Generator: 0.021368,\n",
      "D(x): 0.509, D(G(z)): 0.505\n",
      "2019-04-10 00:58:31,338 root         INFO     Train Epoch: 107 [2560/8000 (32%)]\tTotal Loss: 0.430430\n",
      "Reconstruction: 0.365565, Regularization: 0.000231, Discriminator: 0.043197; Generator: 0.021437,\n",
      "D(x): 0.506, D(G(z)): 0.504\n",
      "2019-04-10 00:58:31,447 root         INFO     Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 0.430462\n",
      "Reconstruction: 0.365541, Regularization: 0.000241, Discriminator: 0.043238; Generator: 0.021441,\n",
      "D(x): 0.505, D(G(z)): 0.504\n",
      "2019-04-10 00:58:31,555 root         INFO     Train Epoch: 107 [3584/8000 (45%)]\tTotal Loss: 0.430162\n",
      "Reconstruction: 0.365442, Regularization: 0.000240, Discriminator: 0.043059; Generator: 0.021420,\n",
      "D(x): 0.508, D(G(z)): 0.504\n",
      "2019-04-10 00:58:31,664 root         INFO     Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 0.431269\n",
      "Reconstruction: 0.366338, Regularization: 0.000273, Discriminator: 0.043221; Generator: 0.021437,\n",
      "D(x): 0.505, D(G(z)): 0.504\n",
      "2019-04-10 00:58:31,772 root         INFO     Train Epoch: 107 [4608/8000 (58%)]\tTotal Loss: 0.432188\n",
      "Reconstruction: 0.367274, Regularization: 0.000194, Discriminator: 0.043276; Generator: 0.021443,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-10 00:58:31,881 root         INFO     Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 0.431930\n",
      "Reconstruction: 0.366936, Regularization: 0.000223, Discriminator: 0.043249; Generator: 0.021522,\n",
      "D(x): 0.504, D(G(z)): 0.502\n",
      "2019-04-10 00:58:31,989 root         INFO     Train Epoch: 107 [5632/8000 (70%)]\tTotal Loss: 0.433634\n",
      "Reconstruction: 0.368598, Regularization: 0.000248, Discriminator: 0.043307; Generator: 0.021480,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-10 00:58:32,098 root         INFO     Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 0.435772\n",
      "Reconstruction: 0.370704, Regularization: 0.000211, Discriminator: 0.043324; Generator: 0.021532,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:58:32,206 root         INFO     Train Epoch: 107 [6656/8000 (83%)]\tTotal Loss: 0.435962\n",
      "Reconstruction: 0.370931, Regularization: 0.000255, Discriminator: 0.043272; Generator: 0.021504,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-10 00:58:32,314 root         INFO     Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 0.436027\n",
      "Reconstruction: 0.370755, Regularization: 0.000236, Discriminator: 0.043441; Generator: 0.021595,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-10 00:58:32,423 root         INFO     Train Epoch: 107 [7680/8000 (96%)]\tTotal Loss: 0.437597\n",
      "Reconstruction: 0.372573, Regularization: 0.000245, Discriminator: 0.043231; Generator: 0.021549,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-10 00:58:32,502 root         INFO     ====> Epoch: 107 Average loss: 0.4316\n",
      "2019-04-10 00:58:32,529 root         INFO     Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 0.438252\n",
      "Reconstruction: 0.373211, Regularization: 0.000223, Discriminator: 0.043275; Generator: 0.021543,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-10 00:58:32,638 root         INFO     Train Epoch: 108 [512/8000 (6%)]\tTotal Loss: 0.439145\n",
      "Reconstruction: 0.373938, Regularization: 0.000254, Discriminator: 0.043267; Generator: 0.021686,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:58:32,747 root         INFO     Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 0.440615\n",
      "Reconstruction: 0.375173, Regularization: 0.000281, Discriminator: 0.043423; Generator: 0.021738,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-10 00:58:32,855 root         INFO     Train Epoch: 108 [1536/8000 (19%)]\tTotal Loss: 0.441045\n",
      "Reconstruction: 0.375817, Regularization: 0.000228, Discriminator: 0.043335; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:58:32,964 root         INFO     Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 0.442580\n",
      "Reconstruction: 0.377004, Regularization: 0.000250, Discriminator: 0.043582; Generator: 0.021744,\n",
      "D(x): 0.495, D(G(z)): 0.499\n",
      "2019-04-10 00:58:33,072 root         INFO     Train Epoch: 108 [2560/8000 (32%)]\tTotal Loss: 0.442165\n",
      "Reconstruction: 0.376967, Regularization: 0.000221, Discriminator: 0.043258; Generator: 0.021719,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:58:33,179 root         INFO     Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 0.442737\n",
      "Reconstruction: 0.377439, Regularization: 0.000231, Discriminator: 0.043351; Generator: 0.021717,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:33,288 root         INFO     Train Epoch: 108 [3584/8000 (45%)]\tTotal Loss: 0.444612\n",
      "Reconstruction: 0.379243, Regularization: 0.000265, Discriminator: 0.043428; Generator: 0.021676,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 00:58:33,396 root         INFO     Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 0.443826\n",
      "Reconstruction: 0.378354, Regularization: 0.000294, Discriminator: 0.043440; Generator: 0.021739,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-10 00:58:33,504 root         INFO     Train Epoch: 108 [4608/8000 (58%)]\tTotal Loss: 0.443384\n",
      "Reconstruction: 0.378161, Regularization: 0.000279, Discriminator: 0.043179; Generator: 0.021765,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-10 00:58:33,611 root         INFO     Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 0.444564\n",
      "Reconstruction: 0.378985, Regularization: 0.000259, Discriminator: 0.043490; Generator: 0.021831,\n",
      "D(x): 0.495, D(G(z)): 0.497\n",
      "2019-04-10 00:58:33,719 root         INFO     Train Epoch: 108 [5632/8000 (70%)]\tTotal Loss: 0.445917\n",
      "Reconstruction: 0.380465, Regularization: 0.000204, Discriminator: 0.043437; Generator: 0.021812,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-10 00:58:33,827 root         INFO     Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 0.447080\n",
      "Reconstruction: 0.381718, Regularization: 0.000263, Discriminator: 0.043280; Generator: 0.021819,\n",
      "D(x): 0.498, D(G(z)): 0.497\n",
      "2019-04-10 00:58:33,934 root         INFO     Train Epoch: 108 [6656/8000 (83%)]\tTotal Loss: 0.448599\n",
      "Reconstruction: 0.383108, Regularization: 0.000196, Discriminator: 0.043474; Generator: 0.021822,\n",
      "D(x): 0.495, D(G(z)): 0.497\n",
      "2019-04-10 00:58:34,041 root         INFO     Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 0.448816\n",
      "Reconstruction: 0.383144, Regularization: 0.000241, Discriminator: 0.043539; Generator: 0.021892,\n",
      "D(x): 0.493, D(G(z)): 0.496\n",
      "2019-04-10 00:58:34,148 root         INFO     Train Epoch: 108 [7680/8000 (96%)]\tTotal Loss: 0.450484\n",
      "Reconstruction: 0.384894, Regularization: 0.000290, Discriminator: 0.043348; Generator: 0.021952,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-04-10 00:58:34,228 root         INFO     ====> Epoch: 108 Average loss: 0.4440\n",
      "2019-04-10 00:58:34,256 root         INFO     Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 0.450014\n",
      "Reconstruction: 0.384435, Regularization: 0.000244, Discriminator: 0.043363; Generator: 0.021972,\n",
      "D(x): 0.494, D(G(z)): 0.495\n",
      "2019-04-10 00:58:34,368 root         INFO     Train Epoch: 109 [512/8000 (6%)]\tTotal Loss: 0.450753\n",
      "Reconstruction: 0.385258, Regularization: 0.000213, Discriminator: 0.043361; Generator: 0.021921,\n",
      "D(x): 0.495, D(G(z)): 0.496\n",
      "2019-04-10 00:58:34,480 root         INFO     Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 0.452500\n",
      "Reconstruction: 0.386880, Regularization: 0.000210, Discriminator: 0.043438; Generator: 0.021972,\n",
      "D(x): 0.493, D(G(z)): 0.495\n",
      "2019-04-10 00:58:34,591 root         INFO     Train Epoch: 109 [1536/8000 (19%)]\tTotal Loss: 0.452422\n",
      "Reconstruction: 0.386750, Regularization: 0.000238, Discriminator: 0.043420; Generator: 0.022015,\n",
      "D(x): 0.493, D(G(z)): 0.494\n",
      "2019-04-10 00:58:34,703 root         INFO     Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 0.453664\n",
      "Reconstruction: 0.387921, Regularization: 0.000208, Discriminator: 0.043478; Generator: 0.022056,\n",
      "D(x): 0.491, D(G(z)): 0.494\n",
      "2019-04-10 00:58:34,814 root         INFO     Train Epoch: 109 [2560/8000 (32%)]\tTotal Loss: 0.452697\n",
      "Reconstruction: 0.387028, Regularization: 0.000230, Discriminator: 0.043410; Generator: 0.022029,\n",
      "D(x): 0.493, D(G(z)): 0.494\n",
      "2019-04-10 00:58:34,924 root         INFO     Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 0.454388\n",
      "Reconstruction: 0.388760, Regularization: 0.000203, Discriminator: 0.043346; Generator: 0.022080,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "2019-04-10 00:58:35,030 root         INFO     Train Epoch: 109 [3584/8000 (45%)]\tTotal Loss: 0.453587\n",
      "Reconstruction: 0.387845, Regularization: 0.000282, Discriminator: 0.043394; Generator: 0.022066,\n",
      "D(x): 0.493, D(G(z)): 0.494\n",
      "2019-04-10 00:58:35,136 root         INFO     Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 0.453884\n",
      "Reconstruction: 0.388040, Regularization: 0.000246, Discriminator: 0.043483; Generator: 0.022115,\n",
      "D(x): 0.490, D(G(z)): 0.493\n",
      "2019-04-10 00:58:35,242 root         INFO     Train Epoch: 109 [4608/8000 (58%)]\tTotal Loss: 0.455053\n",
      "Reconstruction: 0.389329, Regularization: 0.000218, Discriminator: 0.043352; Generator: 0.022154,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-04-10 00:58:35,350 root         INFO     Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 0.455300\n",
      "Reconstruction: 0.389535, Regularization: 0.000222, Discriminator: 0.043399; Generator: 0.022143,\n",
      "D(x): 0.491, D(G(z)): 0.492\n",
      "2019-04-10 00:58:35,460 root         INFO     Train Epoch: 109 [5632/8000 (70%)]\tTotal Loss: 0.455257\n",
      "Reconstruction: 0.389375, Regularization: 0.000278, Discriminator: 0.043453; Generator: 0.022150,\n",
      "D(x): 0.490, D(G(z)): 0.492\n",
      "2019-04-10 00:58:35,570 root         INFO     Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 0.455436\n",
      "Reconstruction: 0.389626, Regularization: 0.000270, Discriminator: 0.043359; Generator: 0.022180,\n",
      "D(x): 0.491, D(G(z)): 0.492\n",
      "2019-04-10 00:58:35,679 root         INFO     Train Epoch: 109 [6656/8000 (83%)]\tTotal Loss: 0.455920\n",
      "Reconstruction: 0.390145, Regularization: 0.000277, Discriminator: 0.043358; Generator: 0.022139,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-04-10 00:58:35,788 root         INFO     Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 0.457297\n",
      "Reconstruction: 0.391343, Regularization: 0.000233, Discriminator: 0.043407; Generator: 0.022314,\n",
      "D(x): 0.489, D(G(z)): 0.490\n",
      "2019-04-10 00:58:35,898 root         INFO     Train Epoch: 109 [7680/8000 (96%)]\tTotal Loss: 0.457386\n",
      "Reconstruction: 0.391487, Regularization: 0.000249, Discriminator: 0.043348; Generator: 0.022303,\n",
      "D(x): 0.490, D(G(z)): 0.490\n",
      "2019-04-10 00:58:35,977 root         INFO     ====> Epoch: 109 Average loss: 0.4544\n",
      "2019-04-10 00:58:36,004 root         INFO     Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 0.458102\n",
      "Reconstruction: 0.392215, Regularization: 0.000232, Discriminator: 0.043360; Generator: 0.022294,\n",
      "D(x): 0.490, D(G(z)): 0.490\n",
      "2019-04-10 00:58:36,112 root         INFO     Train Epoch: 110 [512/8000 (6%)]\tTotal Loss: 0.459118\n",
      "Reconstruction: 0.393180, Regularization: 0.000253, Discriminator: 0.043321; Generator: 0.022363,\n",
      "D(x): 0.489, D(G(z)): 0.489\n",
      "2019-04-10 00:58:36,219 root         INFO     Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 0.458486\n",
      "Reconstruction: 0.392570, Regularization: 0.000238, Discriminator: 0.043282; Generator: 0.022397,\n",
      "D(x): 0.489, D(G(z)): 0.488\n",
      "2019-04-10 00:58:36,325 root         INFO     Train Epoch: 110 [1536/8000 (19%)]\tTotal Loss: 0.457479\n",
      "Reconstruction: 0.391627, Regularization: 0.000175, Discriminator: 0.043310; Generator: 0.022367,\n",
      "D(x): 0.489, D(G(z)): 0.489\n",
      "2019-04-10 00:58:36,437 root         INFO     Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 0.456355\n",
      "Reconstruction: 0.390447, Regularization: 0.000246, Discriminator: 0.043319; Generator: 0.022343,\n",
      "D(x): 0.489, D(G(z)): 0.489\n",
      "2019-04-10 00:58:36,547 root         INFO     Train Epoch: 110 [2560/8000 (32%)]\tTotal Loss: 0.455934\n",
      "Reconstruction: 0.390008, Regularization: 0.000263, Discriminator: 0.043285; Generator: 0.022377,\n",
      "D(x): 0.490, D(G(z)): 0.489\n",
      "2019-04-10 00:58:36,658 root         INFO     Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 0.454489\n",
      "Reconstruction: 0.388576, Regularization: 0.000246, Discriminator: 0.043208; Generator: 0.022459,\n",
      "D(x): 0.490, D(G(z)): 0.487\n",
      "2019-04-10 00:58:36,767 root         INFO     Train Epoch: 110 [3584/8000 (45%)]\tTotal Loss: 0.453886\n",
      "Reconstruction: 0.387916, Regularization: 0.000279, Discriminator: 0.043301; Generator: 0.022391,\n",
      "D(x): 0.489, D(G(z)): 0.488\n",
      "2019-04-10 00:58:36,878 root         INFO     Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 0.453079\n",
      "Reconstruction: 0.387372, Regularization: 0.000279, Discriminator: 0.043137; Generator: 0.022291,\n",
      "D(x): 0.493, D(G(z)): 0.490\n",
      "2019-04-10 00:58:36,988 root         INFO     Train Epoch: 110 [4608/8000 (58%)]\tTotal Loss: 0.452536\n",
      "Reconstruction: 0.386726, Regularization: 0.000214, Discriminator: 0.043289; Generator: 0.022307,\n",
      "D(x): 0.491, D(G(z)): 0.490\n",
      "2019-04-10 00:58:37,098 root         INFO     Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 0.453053\n",
      "Reconstruction: 0.387367, Regularization: 0.000188, Discriminator: 0.043321; Generator: 0.022176,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-04-10 00:58:37,208 root         INFO     Train Epoch: 110 [5632/8000 (70%)]\tTotal Loss: 0.451924\n",
      "Reconstruction: 0.386156, Regularization: 0.000218, Discriminator: 0.043207; Generator: 0.022342,\n",
      "D(x): 0.491, D(G(z)): 0.489\n",
      "2019-04-10 00:58:37,316 root         INFO     Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 0.451656\n",
      "Reconstruction: 0.386010, Regularization: 0.000281, Discriminator: 0.043181; Generator: 0.022183,\n",
      "D(x): 0.494, D(G(z)): 0.492\n",
      "2019-04-10 00:58:37,423 root         INFO     Train Epoch: 110 [6656/8000 (83%)]\tTotal Loss: 0.451984\n",
      "Reconstruction: 0.386355, Regularization: 0.000280, Discriminator: 0.043154; Generator: 0.022195,\n",
      "D(x): 0.494, D(G(z)): 0.492\n",
      "2019-04-10 00:58:37,531 root         INFO     Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 0.450457\n",
      "Reconstruction: 0.384831, Regularization: 0.000253, Discriminator: 0.043159; Generator: 0.022214,\n",
      "D(x): 0.494, D(G(z)): 0.491\n",
      "2019-04-10 00:58:37,638 root         INFO     Train Epoch: 110 [7680/8000 (96%)]\tTotal Loss: 0.448806\n",
      "Reconstruction: 0.383403, Regularization: 0.000228, Discriminator: 0.043200; Generator: 0.021975,\n",
      "D(x): 0.497, D(G(z)): 0.495\n",
      "2019-04-10 00:58:37,716 root         INFO     ====> Epoch: 110 Average loss: 0.4542\n",
      "2019-04-10 00:58:37,744 root         INFO     Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 0.448390\n",
      "Reconstruction: 0.382884, Regularization: 0.000238, Discriminator: 0.043292; Generator: 0.021976,\n",
      "D(x): 0.496, D(G(z)): 0.495\n",
      "2019-04-10 00:58:37,854 root         INFO     Train Epoch: 111 [512/8000 (6%)]\tTotal Loss: 0.446745\n",
      "Reconstruction: 0.381016, Regularization: 0.000216, Discriminator: 0.043452; Generator: 0.022061,\n",
      "D(x): 0.492, D(G(z)): 0.494\n",
      "2019-04-10 00:58:37,964 root         INFO     Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 0.444483\n",
      "Reconstruction: 0.378981, Regularization: 0.000222, Discriminator: 0.043423; Generator: 0.021857,\n",
      "D(x): 0.495, D(G(z)): 0.497\n",
      "2019-04-10 00:58:38,073 root         INFO     Train Epoch: 111 [1536/8000 (19%)]\tTotal Loss: 0.442237\n",
      "Reconstruction: 0.376896, Regularization: 0.000274, Discriminator: 0.043310; Generator: 0.021757,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 00:58:38,183 root         INFO     Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 0.442163\n",
      "Reconstruction: 0.376909, Regularization: 0.000204, Discriminator: 0.043217; Generator: 0.021833,\n",
      "D(x): 0.499, D(G(z)): 0.497\n",
      "2019-04-10 00:58:38,293 root         INFO     Train Epoch: 111 [2560/8000 (32%)]\tTotal Loss: 0.441180\n",
      "Reconstruction: 0.375847, Regularization: 0.000231, Discriminator: 0.043424; Generator: 0.021677,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 00:58:38,403 root         INFO     Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 0.438104\n",
      "Reconstruction: 0.373052, Regularization: 0.000193, Discriminator: 0.043287; Generator: 0.021572,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:58:38,513 root         INFO     Train Epoch: 111 [3584/8000 (45%)]\tTotal Loss: 0.438972\n",
      "Reconstruction: 0.373599, Regularization: 0.000231, Discriminator: 0.043344; Generator: 0.021798,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:38,623 root         INFO     Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 0.437960\n",
      "Reconstruction: 0.372574, Regularization: 0.000229, Discriminator: 0.043443; Generator: 0.021714,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-10 00:58:38,733 root         INFO     Train Epoch: 111 [4608/8000 (58%)]\tTotal Loss: 0.436531\n",
      "Reconstruction: 0.371439, Regularization: 0.000225, Discriminator: 0.043323; Generator: 0.021545,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:58:38,844 root         INFO     Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 0.436484\n",
      "Reconstruction: 0.371561, Regularization: 0.000224, Discriminator: 0.043330; Generator: 0.021369,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-10 00:58:38,954 root         INFO     Train Epoch: 111 [5632/8000 (70%)]\tTotal Loss: 0.435837\n",
      "Reconstruction: 0.370475, Regularization: 0.000286, Discriminator: 0.043410; Generator: 0.021666,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:58:39,066 root         INFO     Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 0.435534\n",
      "Reconstruction: 0.370512, Regularization: 0.000212, Discriminator: 0.043412; Generator: 0.021398,\n",
      "D(x): 0.503, D(G(z)): 0.504\n",
      "2019-04-10 00:58:39,177 root         INFO     Train Epoch: 111 [6656/8000 (83%)]\tTotal Loss: 0.433712\n",
      "Reconstruction: 0.368716, Regularization: 0.000253, Discriminator: 0.043402; Generator: 0.021341,\n",
      "D(x): 0.504, D(G(z)): 0.505\n",
      "2019-04-10 00:58:39,290 root         INFO     Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 0.433729\n",
      "Reconstruction: 0.368695, Regularization: 0.000178, Discriminator: 0.043476; Generator: 0.021380,\n",
      "D(x): 0.502, D(G(z)): 0.505\n",
      "2019-04-10 00:58:39,403 root         INFO     Train Epoch: 111 [7680/8000 (96%)]\tTotal Loss: 0.430953\n",
      "Reconstruction: 0.366115, Regularization: 0.000239, Discriminator: 0.043334; Generator: 0.021265,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-10 00:58:39,484 root         INFO     ====> Epoch: 111 Average loss: 0.4388\n",
      "2019-04-10 00:58:39,512 root         INFO     Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 0.432025\n",
      "Reconstruction: 0.367277, Regularization: 0.000207, Discriminator: 0.043281; Generator: 0.021260,\n",
      "D(x): 0.507, D(G(z)): 0.506\n",
      "2019-04-10 00:58:39,624 root         INFO     Train Epoch: 112 [512/8000 (6%)]\tTotal Loss: 0.430730\n",
      "Reconstruction: 0.365903, Regularization: 0.000216, Discriminator: 0.043288; Generator: 0.021323,\n",
      "D(x): 0.506, D(G(z)): 0.505\n",
      "2019-04-10 00:58:39,734 root         INFO     Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 0.428918\n",
      "Reconstruction: 0.364249, Regularization: 0.000232, Discriminator: 0.043280; Generator: 0.021157,\n",
      "D(x): 0.509, D(G(z)): 0.508\n",
      "2019-04-10 00:58:39,844 root         INFO     Train Epoch: 112 [1536/8000 (19%)]\tTotal Loss: 0.427487\n",
      "Reconstruction: 0.362592, Regularization: 0.000226, Discriminator: 0.043482; Generator: 0.021187,\n",
      "D(x): 0.505, D(G(z)): 0.508\n",
      "2019-04-10 00:58:39,955 root         INFO     Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 0.429246\n",
      "Reconstruction: 0.364364, Regularization: 0.000288, Discriminator: 0.043433; Generator: 0.021161,\n",
      "D(x): 0.506, D(G(z)): 0.508\n",
      "2019-04-10 00:58:40,066 root         INFO     Train Epoch: 112 [2560/8000 (32%)]\tTotal Loss: 0.426975\n",
      "Reconstruction: 0.362182, Regularization: 0.000222, Discriminator: 0.043367; Generator: 0.021204,\n",
      "D(x): 0.507, D(G(z)): 0.507\n",
      "2019-04-10 00:58:40,177 root         INFO     Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 0.427133\n",
      "Reconstruction: 0.362418, Regularization: 0.000236, Discriminator: 0.043366; Generator: 0.021113,\n",
      "D(x): 0.508, D(G(z)): 0.509\n",
      "2019-04-10 00:58:40,288 root         INFO     Train Epoch: 112 [3584/8000 (45%)]\tTotal Loss: 0.426091\n",
      "Reconstruction: 0.361333, Regularization: 0.000230, Discriminator: 0.043342; Generator: 0.021185,\n",
      "D(x): 0.507, D(G(z)): 0.508\n",
      "2019-04-10 00:58:40,399 root         INFO     Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 0.427450\n",
      "Reconstruction: 0.362644, Regularization: 0.000254, Discriminator: 0.043324; Generator: 0.021228,\n",
      "D(x): 0.507, D(G(z)): 0.507\n",
      "2019-04-10 00:58:40,506 root         INFO     Train Epoch: 112 [4608/8000 (58%)]\tTotal Loss: 0.426698\n",
      "Reconstruction: 0.361910, Regularization: 0.000206, Discriminator: 0.043315; Generator: 0.021266,\n",
      "D(x): 0.507, D(G(z)): 0.506\n",
      "2019-04-10 00:58:40,617 root         INFO     Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 0.427974\n",
      "Reconstruction: 0.363160, Regularization: 0.000222, Discriminator: 0.043358; Generator: 0.021233,\n",
      "D(x): 0.506, D(G(z)): 0.507\n",
      "2019-04-10 00:58:40,727 root         INFO     Train Epoch: 112 [5632/8000 (70%)]\tTotal Loss: 0.427751\n",
      "Reconstruction: 0.362913, Regularization: 0.000218, Discriminator: 0.043300; Generator: 0.021320,\n",
      "D(x): 0.506, D(G(z)): 0.505\n",
      "2019-04-10 00:58:40,837 root         INFO     Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 0.427762\n",
      "Reconstruction: 0.362925, Regularization: 0.000206, Discriminator: 0.043304; Generator: 0.021327,\n",
      "D(x): 0.506, D(G(z)): 0.505\n",
      "2019-04-10 00:58:40,948 root         INFO     Train Epoch: 112 [6656/8000 (83%)]\tTotal Loss: 0.428161\n",
      "Reconstruction: 0.363276, Regularization: 0.000231, Discriminator: 0.043332; Generator: 0.021322,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-10 00:58:41,059 root         INFO     Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 0.428293\n",
      "Reconstruction: 0.363385, Regularization: 0.000320, Discriminator: 0.043312; Generator: 0.021276,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-10 00:58:41,169 root         INFO     Train Epoch: 112 [7680/8000 (96%)]\tTotal Loss: 0.427605\n",
      "Reconstruction: 0.362727, Regularization: 0.000248, Discriminator: 0.043265; Generator: 0.021365,\n",
      "D(x): 0.506, D(G(z)): 0.505\n",
      "2019-04-10 00:58:41,249 root         INFO     ====> Epoch: 112 Average loss: 0.4282\n",
      "2019-04-10 00:58:41,276 root         INFO     Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 0.428680\n",
      "Reconstruction: 0.363808, Regularization: 0.000211, Discriminator: 0.043262; Generator: 0.021399,\n",
      "D(x): 0.505, D(G(z)): 0.504\n",
      "2019-04-10 00:58:41,387 root         INFO     Train Epoch: 113 [512/8000 (6%)]\tTotal Loss: 0.428708\n",
      "Reconstruction: 0.363715, Regularization: 0.000238, Discriminator: 0.043290; Generator: 0.021465,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-10 00:58:41,497 root         INFO     Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 0.429520\n",
      "Reconstruction: 0.364544, Regularization: 0.000261, Discriminator: 0.043287; Generator: 0.021428,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-10 00:58:41,607 root         INFO     Train Epoch: 113 [1536/8000 (19%)]\tTotal Loss: 0.429092\n",
      "Reconstruction: 0.364242, Regularization: 0.000234, Discriminator: 0.043258; Generator: 0.021358,\n",
      "D(x): 0.506, D(G(z)): 0.505\n",
      "2019-04-10 00:58:41,718 root         INFO     Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 0.428295\n",
      "Reconstruction: 0.363411, Regularization: 0.000244, Discriminator: 0.043285; Generator: 0.021354,\n",
      "D(x): 0.506, D(G(z)): 0.505\n",
      "2019-04-10 00:58:41,828 root         INFO     Train Epoch: 113 [2560/8000 (32%)]\tTotal Loss: 0.429059\n",
      "Reconstruction: 0.364157, Regularization: 0.000218, Discriminator: 0.043292; Generator: 0.021391,\n",
      "D(x): 0.505, D(G(z)): 0.504\n",
      "2019-04-10 00:58:41,938 root         INFO     Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 0.429169\n",
      "Reconstruction: 0.364274, Regularization: 0.000242, Discriminator: 0.043240; Generator: 0.021412,\n",
      "D(x): 0.505, D(G(z)): 0.504\n",
      "2019-04-10 00:58:42,048 root         INFO     Train Epoch: 113 [3584/8000 (45%)]\tTotal Loss: 0.430515\n",
      "Reconstruction: 0.365500, Regularization: 0.000230, Discriminator: 0.043434; Generator: 0.021352,\n",
      "D(x): 0.503, D(G(z)): 0.505\n",
      "2019-04-10 00:58:42,158 root         INFO     Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 0.431251\n",
      "Reconstruction: 0.366257, Regularization: 0.000264, Discriminator: 0.043256; Generator: 0.021475,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-10 00:58:42,269 root         INFO     Train Epoch: 113 [4608/8000 (58%)]\tTotal Loss: 0.430679\n",
      "Reconstruction: 0.365881, Regularization: 0.000215, Discriminator: 0.043119; Generator: 0.021464,\n",
      "D(x): 0.506, D(G(z)): 0.503\n",
      "2019-04-10 00:58:42,379 root         INFO     Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 0.432941\n",
      "Reconstruction: 0.367902, Regularization: 0.000255, Discriminator: 0.043314; Generator: 0.021469,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-10 00:58:42,490 root         INFO     Train Epoch: 113 [5632/8000 (70%)]\tTotal Loss: 0.433941\n",
      "Reconstruction: 0.368854, Regularization: 0.000207, Discriminator: 0.043386; Generator: 0.021494,\n",
      "D(x): 0.502, D(G(z)): 0.503\n",
      "2019-04-10 00:58:42,600 root         INFO     Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 0.434832\n",
      "Reconstruction: 0.369840, Regularization: 0.000188, Discriminator: 0.043299; Generator: 0.021505,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-10 00:58:42,711 root         INFO     Train Epoch: 113 [6656/8000 (83%)]\tTotal Loss: 0.436022\n",
      "Reconstruction: 0.371028, Regularization: 0.000209, Discriminator: 0.043294; Generator: 0.021491,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-10 00:58:42,821 root         INFO     Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 0.437346\n",
      "Reconstruction: 0.372347, Regularization: 0.000241, Discriminator: 0.043284; Generator: 0.021473,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-10 00:58:42,934 root         INFO     Train Epoch: 113 [7680/8000 (96%)]\tTotal Loss: 0.438181\n",
      "Reconstruction: 0.372966, Regularization: 0.000191, Discriminator: 0.043412; Generator: 0.021612,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-10 00:58:43,015 root         INFO     ====> Epoch: 113 Average loss: 0.4318\n",
      "2019-04-10 00:58:43,042 root         INFO     Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 0.439279\n",
      "Reconstruction: 0.374016, Regularization: 0.000266, Discriminator: 0.043300; Generator: 0.021698,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:58:43,154 root         INFO     Train Epoch: 114 [512/8000 (6%)]\tTotal Loss: 0.439273\n",
      "Reconstruction: 0.374034, Regularization: 0.000245, Discriminator: 0.043327; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:58:43,264 root         INFO     Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 0.441016\n",
      "Reconstruction: 0.375837, Regularization: 0.000219, Discriminator: 0.043278; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:58:43,374 root         INFO     Train Epoch: 114 [1536/8000 (19%)]\tTotal Loss: 0.441068\n",
      "Reconstruction: 0.375876, Regularization: 0.000208, Discriminator: 0.043293; Generator: 0.021692,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:58:43,484 root         INFO     Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 0.440050\n",
      "Reconstruction: 0.374835, Regularization: 0.000230, Discriminator: 0.043259; Generator: 0.021725,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:58:43,595 root         INFO     Train Epoch: 114 [2560/8000 (32%)]\tTotal Loss: 0.441572\n",
      "Reconstruction: 0.376296, Regularization: 0.000232, Discriminator: 0.043347; Generator: 0.021696,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:43,705 root         INFO     Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 0.441099\n",
      "Reconstruction: 0.375836, Regularization: 0.000243, Discriminator: 0.043349; Generator: 0.021670,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:58:43,815 root         INFO     Train Epoch: 114 [3584/8000 (45%)]\tTotal Loss: 0.442599\n",
      "Reconstruction: 0.377380, Regularization: 0.000191, Discriminator: 0.043385; Generator: 0.021643,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:58:43,925 root         INFO     Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 0.442593\n",
      "Reconstruction: 0.377242, Regularization: 0.000212, Discriminator: 0.043340; Generator: 0.021799,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:44,035 root         INFO     Train Epoch: 114 [4608/8000 (58%)]\tTotal Loss: 0.442790\n",
      "Reconstruction: 0.377424, Regularization: 0.000206, Discriminator: 0.043360; Generator: 0.021801,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-10 00:58:44,146 root         INFO     Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 0.443784\n",
      "Reconstruction: 0.378334, Regularization: 0.000213, Discriminator: 0.043458; Generator: 0.021779,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-10 00:58:44,257 root         INFO     Train Epoch: 114 [5632/8000 (70%)]\tTotal Loss: 0.444126\n",
      "Reconstruction: 0.378732, Regularization: 0.000232, Discriminator: 0.043408; Generator: 0.021754,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-10 00:58:44,368 root         INFO     Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 0.445324\n",
      "Reconstruction: 0.379902, Regularization: 0.000227, Discriminator: 0.043425; Generator: 0.021770,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-10 00:58:44,478 root         INFO     Train Epoch: 114 [6656/8000 (83%)]\tTotal Loss: 0.445059\n",
      "Reconstruction: 0.379704, Regularization: 0.000216, Discriminator: 0.043317; Generator: 0.021822,\n",
      "D(x): 0.498, D(G(z)): 0.497\n",
      "2019-04-10 00:58:44,589 root         INFO     Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 0.447143\n",
      "Reconstruction: 0.381705, Regularization: 0.000214, Discriminator: 0.043373; Generator: 0.021852,\n",
      "D(x): 0.496, D(G(z)): 0.497\n",
      "2019-04-10 00:58:44,699 root         INFO     Train Epoch: 114 [7680/8000 (96%)]\tTotal Loss: 0.447675\n",
      "Reconstruction: 0.382133, Regularization: 0.000186, Discriminator: 0.043403; Generator: 0.021953,\n",
      "D(x): 0.494, D(G(z)): 0.495\n",
      "2019-04-10 00:58:44,780 root         INFO     ====> Epoch: 114 Average loss: 0.4429\n",
      "2019-04-10 00:58:44,807 root         INFO     Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 0.448344\n",
      "Reconstruction: 0.382749, Regularization: 0.000221, Discriminator: 0.043412; Generator: 0.021962,\n",
      "D(x): 0.494, D(G(z)): 0.495\n",
      "2019-04-10 00:58:44,915 root         INFO     Train Epoch: 115 [512/8000 (6%)]\tTotal Loss: 0.449165\n",
      "Reconstruction: 0.383607, Regularization: 0.000220, Discriminator: 0.043388; Generator: 0.021950,\n",
      "D(x): 0.494, D(G(z)): 0.495\n",
      "2019-04-10 00:58:45,022 root         INFO     Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 0.450318\n",
      "Reconstruction: 0.384823, Regularization: 0.000222, Discriminator: 0.043362; Generator: 0.021911,\n",
      "D(x): 0.495, D(G(z)): 0.496\n",
      "2019-04-10 00:58:45,131 root         INFO     Train Epoch: 115 [1536/8000 (19%)]\tTotal Loss: 0.450579\n",
      "Reconstruction: 0.385155, Regularization: 0.000207, Discriminator: 0.043346; Generator: 0.021871,\n",
      "D(x): 0.496, D(G(z)): 0.497\n",
      "2019-04-10 00:58:45,238 root         INFO     Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 0.450569\n",
      "Reconstruction: 0.384995, Regularization: 0.000195, Discriminator: 0.043342; Generator: 0.022037,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-04-10 00:58:45,346 root         INFO     Train Epoch: 115 [2560/8000 (32%)]\tTotal Loss: 0.451510\n",
      "Reconstruction: 0.386030, Regularization: 0.000174, Discriminator: 0.043326; Generator: 0.021980,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-04-10 00:58:45,454 root         INFO     Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 0.451668\n",
      "Reconstruction: 0.386178, Regularization: 0.000180, Discriminator: 0.043310; Generator: 0.022000,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-04-10 00:58:45,564 root         INFO     Train Epoch: 115 [3584/8000 (45%)]\tTotal Loss: 0.450287\n",
      "Reconstruction: 0.384752, Regularization: 0.000218, Discriminator: 0.043300; Generator: 0.022017,\n",
      "D(x): 0.495, D(G(z)): 0.494\n",
      "2019-04-10 00:58:45,676 root         INFO     Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 0.450652\n",
      "Reconstruction: 0.385123, Regularization: 0.000214, Discriminator: 0.043315; Generator: 0.021999,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-04-10 00:58:45,789 root         INFO     Train Epoch: 115 [4608/8000 (58%)]\tTotal Loss: 0.448386\n",
      "Reconstruction: 0.382905, Regularization: 0.000194, Discriminator: 0.043313; Generator: 0.021975,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-04-10 00:58:45,901 root         INFO     Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 0.448447\n",
      "Reconstruction: 0.382985, Regularization: 0.000189, Discriminator: 0.043295; Generator: 0.021978,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-04-10 00:58:46,013 root         INFO     Train Epoch: 115 [5632/8000 (70%)]\tTotal Loss: 0.447190\n",
      "Reconstruction: 0.381671, Regularization: 0.000201, Discriminator: 0.043336; Generator: 0.021983,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-04-10 00:58:46,125 root         INFO     Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 0.446354\n",
      "Reconstruction: 0.381028, Regularization: 0.000203, Discriminator: 0.043260; Generator: 0.021863,\n",
      "D(x): 0.498, D(G(z)): 0.497\n",
      "2019-04-10 00:58:46,238 root         INFO     Train Epoch: 115 [6656/8000 (83%)]\tTotal Loss: 0.445085\n",
      "Reconstruction: 0.379723, Regularization: 0.000193, Discriminator: 0.043294; Generator: 0.021876,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-10 00:58:46,351 root         INFO     Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 0.444511\n",
      "Reconstruction: 0.379205, Regularization: 0.000180, Discriminator: 0.043286; Generator: 0.021840,\n",
      "D(x): 0.498, D(G(z)): 0.497\n",
      "2019-04-10 00:58:46,464 root         INFO     Train Epoch: 115 [7680/8000 (96%)]\tTotal Loss: 0.444842\n",
      "Reconstruction: 0.379509, Regularization: 0.000224, Discriminator: 0.043204; Generator: 0.021905,\n",
      "D(x): 0.498, D(G(z)): 0.496\n",
      "2019-04-10 00:58:46,546 root         INFO     ====> Epoch: 115 Average loss: 0.4486\n",
      "2019-04-10 00:58:46,573 root         INFO     Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 0.445525\n",
      "Reconstruction: 0.379986, Regularization: 0.000227, Discriminator: 0.043327; Generator: 0.021985,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-04-10 00:58:46,686 root         INFO     Train Epoch: 116 [512/8000 (6%)]\tTotal Loss: 0.444101\n",
      "Reconstruction: 0.378612, Regularization: 0.000247, Discriminator: 0.043310; Generator: 0.021932,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-04-10 00:58:46,798 root         INFO     Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 0.444402\n",
      "Reconstruction: 0.379129, Regularization: 0.000227, Discriminator: 0.043245; Generator: 0.021801,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 00:58:46,910 root         INFO     Train Epoch: 116 [1536/8000 (19%)]\tTotal Loss: 0.443620\n",
      "Reconstruction: 0.378335, Regularization: 0.000221, Discriminator: 0.043274; Generator: 0.021790,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 00:58:47,021 root         INFO     Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 0.443256\n",
      "Reconstruction: 0.377851, Regularization: 0.000212, Discriminator: 0.043358; Generator: 0.021835,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-10 00:58:47,132 root         INFO     Train Epoch: 116 [2560/8000 (32%)]\tTotal Loss: 0.441645\n",
      "Reconstruction: 0.376278, Regularization: 0.000215, Discriminator: 0.043344; Generator: 0.021809,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-10 00:58:47,243 root         INFO     Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 0.440330\n",
      "Reconstruction: 0.375156, Regularization: 0.000217, Discriminator: 0.043374; Generator: 0.021583,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:58:47,354 root         INFO     Train Epoch: 116 [3584/8000 (45%)]\tTotal Loss: 0.438218\n",
      "Reconstruction: 0.373308, Regularization: 0.000226, Discriminator: 0.043090; Generator: 0.021594,\n",
      "D(x): 0.505, D(G(z)): 0.501\n",
      "2019-04-10 00:58:47,466 root         INFO     Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 0.437720\n",
      "Reconstruction: 0.372679, Regularization: 0.000200, Discriminator: 0.043277; Generator: 0.021564,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:58:47,578 root         INFO     Train Epoch: 116 [4608/8000 (58%)]\tTotal Loss: 0.437419\n",
      "Reconstruction: 0.372276, Regularization: 0.000194, Discriminator: 0.043378; Generator: 0.021571,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:58:47,689 root         INFO     Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 0.435225\n",
      "Reconstruction: 0.370347, Regularization: 0.000199, Discriminator: 0.043347; Generator: 0.021332,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-10 00:58:47,800 root         INFO     Train Epoch: 116 [5632/8000 (70%)]\tTotal Loss: 0.434023\n",
      "Reconstruction: 0.368918, Regularization: 0.000185, Discriminator: 0.043423; Generator: 0.021496,\n",
      "D(x): 0.501, D(G(z)): 0.503\n",
      "2019-04-10 00:58:47,911 root         INFO     Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 0.433433\n",
      "Reconstruction: 0.368422, Regularization: 0.000179, Discriminator: 0.043284; Generator: 0.021548,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:58:48,020 root         INFO     Train Epoch: 116 [6656/8000 (83%)]\tTotal Loss: 0.432800\n",
      "Reconstruction: 0.367675, Regularization: 0.000230, Discriminator: 0.043409; Generator: 0.021485,\n",
      "D(x): 0.501, D(G(z)): 0.503\n",
      "2019-04-10 00:58:48,130 root         INFO     Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 0.431537\n",
      "Reconstruction: 0.366536, Regularization: 0.000189, Discriminator: 0.043375; Generator: 0.021437,\n",
      "D(x): 0.503, D(G(z)): 0.504\n",
      "2019-04-10 00:58:48,242 root         INFO     Train Epoch: 116 [7680/8000 (96%)]\tTotal Loss: 0.431411\n",
      "Reconstruction: 0.366405, Regularization: 0.000221, Discriminator: 0.043338; Generator: 0.021447,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-10 00:58:48,322 root         INFO     ====> Epoch: 116 Average loss: 0.4383\n",
      "2019-04-10 00:58:48,350 root         INFO     Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 0.432025\n",
      "Reconstruction: 0.367088, Regularization: 0.000223, Discriminator: 0.043335; Generator: 0.021379,\n",
      "D(x): 0.504, D(G(z)): 0.505\n",
      "2019-04-10 00:58:48,464 root         INFO     Train Epoch: 117 [512/8000 (6%)]\tTotal Loss: 0.431150\n",
      "Reconstruction: 0.366146, Regularization: 0.000184, Discriminator: 0.043350; Generator: 0.021470,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-10 00:58:48,577 root         INFO     Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 0.431871\n",
      "Reconstruction: 0.366974, Regularization: 0.000218, Discriminator: 0.043314; Generator: 0.021365,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-10 00:58:48,689 root         INFO     Train Epoch: 117 [1536/8000 (19%)]\tTotal Loss: 0.432392\n",
      "Reconstruction: 0.367429, Regularization: 0.000270, Discriminator: 0.043318; Generator: 0.021374,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-10 00:58:48,800 root         INFO     Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 0.432595\n",
      "Reconstruction: 0.367671, Regularization: 0.000198, Discriminator: 0.043319; Generator: 0.021407,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-10 00:58:48,911 root         INFO     Train Epoch: 117 [2560/8000 (32%)]\tTotal Loss: 0.432196\n",
      "Reconstruction: 0.367253, Regularization: 0.000220, Discriminator: 0.043335; Generator: 0.021389,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-10 00:58:49,022 root         INFO     Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 0.433213\n",
      "Reconstruction: 0.368200, Regularization: 0.000228, Discriminator: 0.043313; Generator: 0.021473,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-10 00:58:49,133 root         INFO     Train Epoch: 117 [3584/8000 (45%)]\tTotal Loss: 0.432619\n",
      "Reconstruction: 0.367569, Regularization: 0.000203, Discriminator: 0.043305; Generator: 0.021542,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:58:49,243 root         INFO     Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 0.433879\n",
      "Reconstruction: 0.368853, Regularization: 0.000211, Discriminator: 0.043311; Generator: 0.021504,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-10 00:58:49,351 root         INFO     Train Epoch: 117 [4608/8000 (58%)]\tTotal Loss: 0.433232\n",
      "Reconstruction: 0.368197, Regularization: 0.000230, Discriminator: 0.043303; Generator: 0.021503,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-10 00:58:49,461 root         INFO     Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 0.433953\n",
      "Reconstruction: 0.368930, Regularization: 0.000213, Discriminator: 0.043303; Generator: 0.021507,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-10 00:58:49,569 root         INFO     Train Epoch: 117 [5632/8000 (70%)]\tTotal Loss: 0.432942\n",
      "Reconstruction: 0.367905, Regularization: 0.000219, Discriminator: 0.043304; Generator: 0.021513,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-10 00:58:49,677 root         INFO     Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 0.432327\n",
      "Reconstruction: 0.367254, Regularization: 0.000198, Discriminator: 0.043321; Generator: 0.021553,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:58:49,787 root         INFO     Train Epoch: 117 [6656/8000 (83%)]\tTotal Loss: 0.432819\n",
      "Reconstruction: 0.367852, Regularization: 0.000198, Discriminator: 0.043306; Generator: 0.021464,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-10 00:58:49,895 root         INFO     Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 0.433159\n",
      "Reconstruction: 0.368163, Regularization: 0.000192, Discriminator: 0.043311; Generator: 0.021493,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-10 00:58:50,004 root         INFO     Train Epoch: 117 [7680/8000 (96%)]\tTotal Loss: 0.432710\n",
      "Reconstruction: 0.367745, Regularization: 0.000199, Discriminator: 0.043283; Generator: 0.021483,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-10 00:58:50,084 root         INFO     ====> Epoch: 117 Average loss: 0.4328\n",
      "2019-04-10 00:58:50,112 root         INFO     Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 0.434589\n",
      "Reconstruction: 0.369477, Regularization: 0.000217, Discriminator: 0.043261; Generator: 0.021634,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:58:50,224 root         INFO     Train Epoch: 118 [512/8000 (6%)]\tTotal Loss: 0.434675\n",
      "Reconstruction: 0.369539, Regularization: 0.000192, Discriminator: 0.043329; Generator: 0.021616,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:58:50,335 root         INFO     Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 0.435197\n",
      "Reconstruction: 0.370153, Regularization: 0.000222, Discriminator: 0.043246; Generator: 0.021576,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-10 00:58:50,447 root         INFO     Train Epoch: 118 [1536/8000 (19%)]\tTotal Loss: 0.435913\n",
      "Reconstruction: 0.370910, Regularization: 0.000216, Discriminator: 0.043252; Generator: 0.021536,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-10 00:58:50,558 root         INFO     Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 0.437647\n",
      "Reconstruction: 0.372408, Regularization: 0.000272, Discriminator: 0.043409; Generator: 0.021558,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-10 00:58:50,668 root         INFO     Train Epoch: 118 [2560/8000 (32%)]\tTotal Loss: 0.438724\n",
      "Reconstruction: 0.373437, Regularization: 0.000233, Discriminator: 0.043379; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:58:50,780 root         INFO     Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 0.440115\n",
      "Reconstruction: 0.374873, Regularization: 0.000202, Discriminator: 0.043272; Generator: 0.021769,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 00:58:50,891 root         INFO     Train Epoch: 118 [3584/8000 (45%)]\tTotal Loss: 0.441799\n",
      "Reconstruction: 0.376546, Regularization: 0.000190, Discriminator: 0.043360; Generator: 0.021704,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:51,002 root         INFO     Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 0.442552\n",
      "Reconstruction: 0.377351, Regularization: 0.000167, Discriminator: 0.043308; Generator: 0.021725,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:51,112 root         INFO     Train Epoch: 118 [4608/8000 (58%)]\tTotal Loss: 0.443361\n",
      "Reconstruction: 0.377991, Regularization: 0.000230, Discriminator: 0.043353; Generator: 0.021786,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:51,222 root         INFO     Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 0.443299\n",
      "Reconstruction: 0.377977, Regularization: 0.000219, Discriminator: 0.043343; Generator: 0.021761,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:51,333 root         INFO     Train Epoch: 118 [5632/8000 (70%)]\tTotal Loss: 0.442660\n",
      "Reconstruction: 0.377403, Regularization: 0.000186, Discriminator: 0.043322; Generator: 0.021749,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:51,444 root         INFO     Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 0.444553\n",
      "Reconstruction: 0.379270, Regularization: 0.000180, Discriminator: 0.043339; Generator: 0.021765,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:51,555 root         INFO     Train Epoch: 118 [6656/8000 (83%)]\tTotal Loss: 0.443895\n",
      "Reconstruction: 0.378637, Regularization: 0.000157, Discriminator: 0.043331; Generator: 0.021771,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:51,665 root         INFO     Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 0.444604\n",
      "Reconstruction: 0.379349, Regularization: 0.000162, Discriminator: 0.043318; Generator: 0.021775,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:51,776 root         INFO     Train Epoch: 118 [7680/8000 (96%)]\tTotal Loss: 0.444773\n",
      "Reconstruction: 0.379435, Regularization: 0.000169, Discriminator: 0.043328; Generator: 0.021842,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-10 00:58:51,856 root         INFO     ====> Epoch: 118 Average loss: 0.4410\n",
      "2019-04-10 00:58:51,883 root         INFO     Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 0.444220\n",
      "Reconstruction: 0.378915, Regularization: 0.000180, Discriminator: 0.043336; Generator: 0.021788,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:51,996 root         INFO     Train Epoch: 119 [512/8000 (6%)]\tTotal Loss: 0.445596\n",
      "Reconstruction: 0.380282, Regularization: 0.000190, Discriminator: 0.043337; Generator: 0.021787,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:52,106 root         INFO     Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 0.444415\n",
      "Reconstruction: 0.379146, Regularization: 0.000164, Discriminator: 0.043336; Generator: 0.021770,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:52,216 root         INFO     Train Epoch: 119 [1536/8000 (19%)]\tTotal Loss: 0.445836\n",
      "Reconstruction: 0.380538, Regularization: 0.000137, Discriminator: 0.043326; Generator: 0.021834,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-10 00:58:52,325 root         INFO     Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 0.445659\n",
      "Reconstruction: 0.380378, Regularization: 0.000140, Discriminator: 0.043326; Generator: 0.021815,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-10 00:58:52,435 root         INFO     Train Epoch: 119 [2560/8000 (32%)]\tTotal Loss: 0.444693\n",
      "Reconstruction: 0.379381, Regularization: 0.000155, Discriminator: 0.043320; Generator: 0.021838,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-10 00:58:52,545 root         INFO     Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 0.445910\n",
      "Reconstruction: 0.380671, Regularization: 0.000140, Discriminator: 0.043323; Generator: 0.021775,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:52,655 root         INFO     Train Epoch: 119 [3584/8000 (45%)]\tTotal Loss: 0.445559\n",
      "Reconstruction: 0.380167, Regularization: 0.000198, Discriminator: 0.043304; Generator: 0.021890,\n",
      "D(x): 0.497, D(G(z)): 0.496\n",
      "2019-04-10 00:58:52,765 root         INFO     Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 0.445229\n",
      "Reconstruction: 0.379898, Regularization: 0.000166, Discriminator: 0.043299; Generator: 0.021866,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-10 00:58:52,875 root         INFO     Train Epoch: 119 [4608/8000 (58%)]\tTotal Loss: 0.444256\n",
      "Reconstruction: 0.378917, Regularization: 0.000152, Discriminator: 0.043300; Generator: 0.021887,\n",
      "D(x): 0.497, D(G(z)): 0.496\n",
      "2019-04-10 00:58:52,986 root         INFO     Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 0.444609\n",
      "Reconstruction: 0.379376, Regularization: 0.000163, Discriminator: 0.043277; Generator: 0.021792,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 00:58:53,095 root         INFO     Train Epoch: 119 [5632/8000 (70%)]\tTotal Loss: 0.443381\n",
      "Reconstruction: 0.377972, Regularization: 0.000187, Discriminator: 0.043321; Generator: 0.021902,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-04-10 00:58:53,205 root         INFO     Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 0.443380\n",
      "Reconstruction: 0.378215, Regularization: 0.000153, Discriminator: 0.043261; Generator: 0.021751,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:58:53,314 root         INFO     Train Epoch: 119 [6656/8000 (83%)]\tTotal Loss: 0.443147\n",
      "Reconstruction: 0.377930, Regularization: 0.000201, Discriminator: 0.043299; Generator: 0.021718,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:53,425 root         INFO     Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 0.441819\n",
      "Reconstruction: 0.376544, Regularization: 0.000151, Discriminator: 0.043345; Generator: 0.021779,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:53,535 root         INFO     Train Epoch: 119 [7680/8000 (96%)]\tTotal Loss: 0.441318\n",
      "Reconstruction: 0.376172, Regularization: 0.000166, Discriminator: 0.043252; Generator: 0.021727,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:58:53,615 root         INFO     ====> Epoch: 119 Average loss: 0.4443\n",
      "2019-04-10 00:58:53,642 root         INFO     Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 0.440945\n",
      "Reconstruction: 0.375734, Regularization: 0.000164, Discriminator: 0.043347; Generator: 0.021700,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:53,754 root         INFO     Train Epoch: 120 [512/8000 (6%)]\tTotal Loss: 0.438475\n",
      "Reconstruction: 0.373387, Regularization: 0.000149, Discriminator: 0.043243; Generator: 0.021696,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-10 00:58:53,865 root         INFO     Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 0.437752\n",
      "Reconstruction: 0.372504, Regularization: 0.000162, Discriminator: 0.043388; Generator: 0.021699,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:58:53,976 root         INFO     Train Epoch: 120 [1536/8000 (19%)]\tTotal Loss: 0.436747\n",
      "Reconstruction: 0.371616, Regularization: 0.000151, Discriminator: 0.043386; Generator: 0.021594,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:58:54,086 root         INFO     Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 0.436235\n",
      "Reconstruction: 0.371178, Regularization: 0.000160, Discriminator: 0.043342; Generator: 0.021554,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-10 00:58:54,196 root         INFO     Train Epoch: 120 [2560/8000 (32%)]\tTotal Loss: 0.435172\n",
      "Reconstruction: 0.370048, Regularization: 0.000180, Discriminator: 0.043344; Generator: 0.021599,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:58:54,306 root         INFO     Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 0.435041\n",
      "Reconstruction: 0.369972, Regularization: 0.000168, Discriminator: 0.043355; Generator: 0.021546,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-10 00:58:54,416 root         INFO     Train Epoch: 120 [3584/8000 (45%)]\tTotal Loss: 0.434589\n",
      "Reconstruction: 0.369619, Regularization: 0.000173, Discriminator: 0.043348; Generator: 0.021449,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-10 00:58:54,525 root         INFO     Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 0.433832\n",
      "Reconstruction: 0.368754, Regularization: 0.000199, Discriminator: 0.043347; Generator: 0.021533,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:58:54,634 root         INFO     Train Epoch: 120 [4608/8000 (58%)]\tTotal Loss: 0.434131\n",
      "Reconstruction: 0.369136, Regularization: 0.000161, Discriminator: 0.043329; Generator: 0.021505,\n",
      "D(x): 0.502, D(G(z)): 0.503\n",
      "2019-04-10 00:58:54,743 root         INFO     Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 0.433837\n",
      "Reconstruction: 0.368784, Regularization: 0.000156, Discriminator: 0.043324; Generator: 0.021573,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:58:54,851 root         INFO     Train Epoch: 120 [5632/8000 (70%)]\tTotal Loss: 0.434322\n",
      "Reconstruction: 0.369292, Regularization: 0.000193, Discriminator: 0.043327; Generator: 0.021511,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:58:54,959 root         INFO     Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 0.433913\n",
      "Reconstruction: 0.368885, Regularization: 0.000171, Discriminator: 0.043321; Generator: 0.021535,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:58:55,066 root         INFO     Train Epoch: 120 [6656/8000 (83%)]\tTotal Loss: 0.434189\n",
      "Reconstruction: 0.369093, Regularization: 0.000203, Discriminator: 0.043322; Generator: 0.021571,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:58:55,175 root         INFO     Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 0.434772\n",
      "Reconstruction: 0.369697, Regularization: 0.000177, Discriminator: 0.043302; Generator: 0.021596,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:58:55,283 root         INFO     Train Epoch: 120 [7680/8000 (96%)]\tTotal Loss: 0.434352\n",
      "Reconstruction: 0.369336, Regularization: 0.000178, Discriminator: 0.043314; Generator: 0.021523,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:58:55,362 root         INFO     ====> Epoch: 120 Average loss: 0.4354\n",
      "2019-04-10 00:58:55,391 root         INFO     Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 0.433981\n",
      "Reconstruction: 0.369000, Regularization: 0.000158, Discriminator: 0.043326; Generator: 0.021496,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-10 00:58:55,504 root         INFO     Train Epoch: 121 [512/8000 (6%)]\tTotal Loss: 0.434674\n",
      "Reconstruction: 0.369734, Regularization: 0.000180, Discriminator: 0.043279; Generator: 0.021480,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-10 00:58:55,616 root         INFO     Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 0.434979\n",
      "Reconstruction: 0.369978, Regularization: 0.000181, Discriminator: 0.043291; Generator: 0.021528,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-10 00:58:55,727 root         INFO     Train Epoch: 121 [1536/8000 (19%)]\tTotal Loss: 0.435590\n",
      "Reconstruction: 0.370560, Regularization: 0.000176, Discriminator: 0.043351; Generator: 0.021504,\n",
      "D(x): 0.502, D(G(z)): 0.503\n",
      "2019-04-10 00:58:55,838 root         INFO     Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 0.435807\n",
      "Reconstruction: 0.370662, Regularization: 0.000200, Discriminator: 0.043343; Generator: 0.021602,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:58:55,950 root         INFO     Train Epoch: 121 [2560/8000 (32%)]\tTotal Loss: 0.436700\n",
      "Reconstruction: 0.371497, Regularization: 0.000174, Discriminator: 0.043362; Generator: 0.021667,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:58:56,061 root         INFO     Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 0.437212\n",
      "Reconstruction: 0.372210, Regularization: 0.000158, Discriminator: 0.043264; Generator: 0.021580,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:58:56,172 root         INFO     Train Epoch: 121 [3584/8000 (45%)]\tTotal Loss: 0.438764\n",
      "Reconstruction: 0.373644, Regularization: 0.000166, Discriminator: 0.043296; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:58:56,282 root         INFO     Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 0.439774\n",
      "Reconstruction: 0.374672, Regularization: 0.000177, Discriminator: 0.043332; Generator: 0.021593,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:58:56,392 root         INFO     Train Epoch: 121 [4608/8000 (58%)]\tTotal Loss: 0.441044\n",
      "Reconstruction: 0.375900, Regularization: 0.000160, Discriminator: 0.043296; Generator: 0.021688,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:58:56,503 root         INFO     Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 0.441911\n",
      "Reconstruction: 0.376668, Regularization: 0.000173, Discriminator: 0.043371; Generator: 0.021700,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:56,613 root         INFO     Train Epoch: 121 [5632/8000 (70%)]\tTotal Loss: 0.442894\n",
      "Reconstruction: 0.377615, Regularization: 0.000173, Discriminator: 0.043347; Generator: 0.021758,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:56,723 root         INFO     Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 0.443531\n",
      "Reconstruction: 0.378217, Regularization: 0.000173, Discriminator: 0.043313; Generator: 0.021829,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-10 00:58:56,833 root         INFO     Train Epoch: 121 [6656/8000 (83%)]\tTotal Loss: 0.442652\n",
      "Reconstruction: 0.377298, Regularization: 0.000182, Discriminator: 0.043332; Generator: 0.021840,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-10 00:58:56,943 root         INFO     Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 0.442897\n",
      "Reconstruction: 0.377687, Regularization: 0.000159, Discriminator: 0.043328; Generator: 0.021723,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:57,053 root         INFO     Train Epoch: 121 [7680/8000 (96%)]\tTotal Loss: 0.443143\n",
      "Reconstruction: 0.377957, Regularization: 0.000157, Discriminator: 0.043324; Generator: 0.021704,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:57,134 root         INFO     ====> Epoch: 121 Average loss: 0.4393\n",
      "2019-04-10 00:58:57,162 root         INFO     Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 0.443020\n",
      "Reconstruction: 0.377715, Regularization: 0.000169, Discriminator: 0.043331; Generator: 0.021805,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:57,271 root         INFO     Train Epoch: 122 [512/8000 (6%)]\tTotal Loss: 0.442849\n",
      "Reconstruction: 0.377591, Regularization: 0.000170, Discriminator: 0.043336; Generator: 0.021752,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:58:57,380 root         INFO     Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 0.443553\n",
      "Reconstruction: 0.378341, Regularization: 0.000168, Discriminator: 0.043324; Generator: 0.021719,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:57,489 root         INFO     Train Epoch: 122 [1536/8000 (19%)]\tTotal Loss: 0.443489\n",
      "Reconstruction: 0.378200, Regularization: 0.000178, Discriminator: 0.043318; Generator: 0.021793,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:57,598 root         INFO     Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 0.442893\n",
      "Reconstruction: 0.377604, Regularization: 0.000188, Discriminator: 0.043324; Generator: 0.021777,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:57,706 root         INFO     Train Epoch: 122 [2560/8000 (32%)]\tTotal Loss: 0.443263\n",
      "Reconstruction: 0.378014, Regularization: 0.000158, Discriminator: 0.043315; Generator: 0.021775,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:57,813 root         INFO     Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 0.443567\n",
      "Reconstruction: 0.378349, Regularization: 0.000151, Discriminator: 0.043312; Generator: 0.021755,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 00:58:57,921 root         INFO     Train Epoch: 122 [3584/8000 (45%)]\tTotal Loss: 0.443966\n",
      "Reconstruction: 0.378676, Regularization: 0.000184, Discriminator: 0.043320; Generator: 0.021786,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:58,030 root         INFO     Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 0.443288\n",
      "Reconstruction: 0.378053, Regularization: 0.000200, Discriminator: 0.043332; Generator: 0.021703,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:58,139 root         INFO     Train Epoch: 122 [4608/8000 (58%)]\tTotal Loss: 0.443463\n",
      "Reconstruction: 0.378224, Regularization: 0.000191, Discriminator: 0.043328; Generator: 0.021718,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:58,248 root         INFO     Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 0.442610\n",
      "Reconstruction: 0.377368, Regularization: 0.000191, Discriminator: 0.043278; Generator: 0.021773,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 00:58:58,357 root         INFO     Train Epoch: 122 [5632/8000 (70%)]\tTotal Loss: 0.443025\n",
      "Reconstruction: 0.377729, Regularization: 0.000202, Discriminator: 0.043322; Generator: 0.021772,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:58:58,466 root         INFO     Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 0.441617\n",
      "Reconstruction: 0.376416, Regularization: 0.000164, Discriminator: 0.043343; Generator: 0.021693,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:58:58,575 root         INFO     Train Epoch: 122 [6656/8000 (83%)]\tTotal Loss: 0.440100\n",
      "Reconstruction: 0.375003, Regularization: 0.000188, Discriminator: 0.043290; Generator: 0.021619,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:58:58,684 root         INFO     Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 0.438218\n",
      "Reconstruction: 0.373138, Regularization: 0.000154, Discriminator: 0.043327; Generator: 0.021599,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:58:58,795 root         INFO     Train Epoch: 122 [7680/8000 (96%)]\tTotal Loss: 0.438696\n",
      "Reconstruction: 0.373565, Regularization: 0.000222, Discriminator: 0.043234; Generator: 0.021675,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:58:58,875 root         INFO     ====> Epoch: 122 Average loss: 0.4424\n",
      "2019-04-10 00:58:58,903 root         INFO     Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 0.436954\n",
      "Reconstruction: 0.371766, Regularization: 0.000182, Discriminator: 0.043340; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:58:59,016 root         INFO     Train Epoch: 123 [512/8000 (6%)]\tTotal Loss: 0.435585\n",
      "Reconstruction: 0.370478, Regularization: 0.000199, Discriminator: 0.043281; Generator: 0.021626,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:58:59,129 root         INFO     Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 0.435570\n",
      "Reconstruction: 0.370549, Regularization: 0.000190, Discriminator: 0.043302; Generator: 0.021529,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:58:59,240 root         INFO     Train Epoch: 123 [1536/8000 (19%)]\tTotal Loss: 0.434710\n",
      "Reconstruction: 0.369626, Regularization: 0.000184, Discriminator: 0.043304; Generator: 0.021595,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:58:59,350 root         INFO     Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 0.435887\n",
      "Reconstruction: 0.370852, Regularization: 0.000204, Discriminator: 0.043327; Generator: 0.021504,\n",
      "D(x): 0.502, D(G(z)): 0.503\n",
      "2019-04-10 00:58:59,461 root         INFO     Train Epoch: 123 [2560/8000 (32%)]\tTotal Loss: 0.434978\n",
      "Reconstruction: 0.369893, Regularization: 0.000177, Discriminator: 0.043334; Generator: 0.021574,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:58:59,570 root         INFO     Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 0.435383\n",
      "Reconstruction: 0.370296, Regularization: 0.000175, Discriminator: 0.043315; Generator: 0.021598,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:58:59,679 root         INFO     Train Epoch: 123 [3584/8000 (45%)]\tTotal Loss: 0.435655\n",
      "Reconstruction: 0.370538, Regularization: 0.000181, Discriminator: 0.043338; Generator: 0.021598,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:58:59,788 root         INFO     Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 0.436316\n",
      "Reconstruction: 0.371245, Regularization: 0.000180, Discriminator: 0.043325; Generator: 0.021565,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-10 00:58:59,896 root         INFO     Train Epoch: 123 [4608/8000 (58%)]\tTotal Loss: 0.436332\n",
      "Reconstruction: 0.371256, Regularization: 0.000192, Discriminator: 0.043316; Generator: 0.021567,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:59:00,002 root         INFO     Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 0.435610\n",
      "Reconstruction: 0.370555, Regularization: 0.000156, Discriminator: 0.043319; Generator: 0.021580,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:00,108 root         INFO     Train Epoch: 123 [5632/8000 (70%)]\tTotal Loss: 0.436410\n",
      "Reconstruction: 0.371303, Regularization: 0.000183, Discriminator: 0.043315; Generator: 0.021610,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:00,214 root         INFO     Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 0.435970\n",
      "Reconstruction: 0.370880, Regularization: 0.000185, Discriminator: 0.043319; Generator: 0.021586,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:00,319 root         INFO     Train Epoch: 123 [6656/8000 (83%)]\tTotal Loss: 0.436574\n",
      "Reconstruction: 0.371481, Regularization: 0.000190, Discriminator: 0.043315; Generator: 0.021588,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:00,425 root         INFO     Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 0.436574\n",
      "Reconstruction: 0.371407, Regularization: 0.000212, Discriminator: 0.043319; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:00,531 root         INFO     Train Epoch: 123 [7680/8000 (96%)]\tTotal Loss: 0.435284\n",
      "Reconstruction: 0.370134, Regularization: 0.000186, Discriminator: 0.043307; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:00,609 root         INFO     ====> Epoch: 123 Average loss: 0.4360\n",
      "2019-04-10 00:59:00,637 root         INFO     Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 0.435782\n",
      "Reconstruction: 0.370628, Regularization: 0.000176, Discriminator: 0.043340; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:00,748 root         INFO     Train Epoch: 124 [512/8000 (6%)]\tTotal Loss: 0.436953\n",
      "Reconstruction: 0.371920, Regularization: 0.000186, Discriminator: 0.043312; Generator: 0.021534,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:59:00,859 root         INFO     Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 0.437791\n",
      "Reconstruction: 0.372604, Regularization: 0.000152, Discriminator: 0.043326; Generator: 0.021708,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:00,969 root         INFO     Train Epoch: 124 [1536/8000 (19%)]\tTotal Loss: 0.438995\n",
      "Reconstruction: 0.373833, Regularization: 0.000171, Discriminator: 0.043277; Generator: 0.021714,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:01,080 root         INFO     Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 0.439318\n",
      "Reconstruction: 0.374185, Regularization: 0.000157, Discriminator: 0.043338; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:01,190 root         INFO     Train Epoch: 124 [2560/8000 (32%)]\tTotal Loss: 0.440161\n",
      "Reconstruction: 0.374939, Regularization: 0.000163, Discriminator: 0.043319; Generator: 0.021740,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:01,301 root         INFO     Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 0.442621\n",
      "Reconstruction: 0.377406, Regularization: 0.000150, Discriminator: 0.043305; Generator: 0.021759,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 00:59:01,412 root         INFO     Train Epoch: 124 [3584/8000 (45%)]\tTotal Loss: 0.443035\n",
      "Reconstruction: 0.377845, Regularization: 0.000151, Discriminator: 0.043340; Generator: 0.021699,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:01,523 root         INFO     Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 0.442464\n",
      "Reconstruction: 0.377283, Regularization: 0.000171, Discriminator: 0.043326; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:01,634 root         INFO     Train Epoch: 124 [4608/8000 (58%)]\tTotal Loss: 0.443147\n",
      "Reconstruction: 0.377987, Regularization: 0.000148, Discriminator: 0.043331; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:01,745 root         INFO     Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 0.444060\n",
      "Reconstruction: 0.378860, Regularization: 0.000152, Discriminator: 0.043323; Generator: 0.021725,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:01,856 root         INFO     Train Epoch: 124 [5632/8000 (70%)]\tTotal Loss: 0.443788\n",
      "Reconstruction: 0.378524, Regularization: 0.000179, Discriminator: 0.043313; Generator: 0.021773,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:59:01,967 root         INFO     Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 0.441508\n",
      "Reconstruction: 0.376298, Regularization: 0.000157, Discriminator: 0.043338; Generator: 0.021714,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:02,078 root         INFO     Train Epoch: 124 [6656/8000 (83%)]\tTotal Loss: 0.442607\n",
      "Reconstruction: 0.377365, Regularization: 0.000163, Discriminator: 0.043319; Generator: 0.021760,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:59:02,189 root         INFO     Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 0.441750\n",
      "Reconstruction: 0.376594, Regularization: 0.000170, Discriminator: 0.043314; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:02,300 root         INFO     Train Epoch: 124 [7680/8000 (96%)]\tTotal Loss: 0.441889\n",
      "Reconstruction: 0.376698, Regularization: 0.000157, Discriminator: 0.043320; Generator: 0.021714,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:02,380 root         INFO     ====> Epoch: 124 Average loss: 0.4412\n",
      "2019-04-10 00:59:02,408 root         INFO     Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 0.440883\n",
      "Reconstruction: 0.375733, Regularization: 0.000159, Discriminator: 0.043326; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:02,520 root         INFO     Train Epoch: 125 [512/8000 (6%)]\tTotal Loss: 0.440548\n",
      "Reconstruction: 0.375499, Regularization: 0.000150, Discriminator: 0.043302; Generator: 0.021598,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:02,632 root         INFO     Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 0.441923\n",
      "Reconstruction: 0.376756, Regularization: 0.000162, Discriminator: 0.043264; Generator: 0.021740,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:02,744 root         INFO     Train Epoch: 125 [1536/8000 (19%)]\tTotal Loss: 0.442354\n",
      "Reconstruction: 0.377130, Regularization: 0.000164, Discriminator: 0.043361; Generator: 0.021699,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:02,855 root         INFO     Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 0.442841\n",
      "Reconstruction: 0.377623, Regularization: 0.000162, Discriminator: 0.043334; Generator: 0.021722,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:02,965 root         INFO     Train Epoch: 125 [2560/8000 (32%)]\tTotal Loss: 0.442088\n",
      "Reconstruction: 0.376908, Regularization: 0.000175, Discriminator: 0.043284; Generator: 0.021720,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:03,075 root         INFO     Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 0.440991\n",
      "Reconstruction: 0.375900, Regularization: 0.000160, Discriminator: 0.043284; Generator: 0.021647,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:03,185 root         INFO     Train Epoch: 125 [3584/8000 (45%)]\tTotal Loss: 0.440616\n",
      "Reconstruction: 0.375524, Regularization: 0.000151, Discriminator: 0.043329; Generator: 0.021612,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:03,296 root         INFO     Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 0.439507\n",
      "Reconstruction: 0.374451, Regularization: 0.000164, Discriminator: 0.043324; Generator: 0.021567,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-10 00:59:03,405 root         INFO     Train Epoch: 125 [4608/8000 (58%)]\tTotal Loss: 0.438329\n",
      "Reconstruction: 0.373343, Regularization: 0.000172, Discriminator: 0.043303; Generator: 0.021510,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-10 00:59:03,514 root         INFO     Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 0.437001\n",
      "Reconstruction: 0.371906, Regularization: 0.000147, Discriminator: 0.043311; Generator: 0.021636,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:03,624 root         INFO     Train Epoch: 125 [5632/8000 (70%)]\tTotal Loss: 0.437769\n",
      "Reconstruction: 0.372670, Regularization: 0.000178, Discriminator: 0.043306; Generator: 0.021614,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:03,737 root         INFO     Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 0.435847\n",
      "Reconstruction: 0.370701, Regularization: 0.000173, Discriminator: 0.043316; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:03,849 root         INFO     Train Epoch: 125 [6656/8000 (83%)]\tTotal Loss: 0.435532\n",
      "Reconstruction: 0.370402, Regularization: 0.000146, Discriminator: 0.043313; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:03,961 root         INFO     Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 0.435268\n",
      "Reconstruction: 0.370176, Regularization: 0.000144, Discriminator: 0.043330; Generator: 0.021617,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:04,072 root         INFO     Train Epoch: 125 [7680/8000 (96%)]\tTotal Loss: 0.434849\n",
      "Reconstruction: 0.369724, Regularization: 0.000210, Discriminator: 0.043321; Generator: 0.021594,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:04,152 root         INFO     ====> Epoch: 125 Average loss: 0.4388\n",
      "2019-04-10 00:59:04,179 root         INFO     Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 0.435109\n",
      "Reconstruction: 0.370078, Regularization: 0.000180, Discriminator: 0.043315; Generator: 0.021537,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:59:04,291 root         INFO     Train Epoch: 126 [512/8000 (6%)]\tTotal Loss: 0.435771\n",
      "Reconstruction: 0.370680, Regularization: 0.000158, Discriminator: 0.043323; Generator: 0.021610,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:04,401 root         INFO     Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 0.436742\n",
      "Reconstruction: 0.371621, Regularization: 0.000164, Discriminator: 0.043324; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:04,512 root         INFO     Train Epoch: 126 [1536/8000 (19%)]\tTotal Loss: 0.437151\n",
      "Reconstruction: 0.372017, Regularization: 0.000151, Discriminator: 0.043308; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:04,623 root         INFO     Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 0.437155\n",
      "Reconstruction: 0.372022, Regularization: 0.000195, Discriminator: 0.043345; Generator: 0.021593,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:04,734 root         INFO     Train Epoch: 126 [2560/8000 (32%)]\tTotal Loss: 0.438181\n",
      "Reconstruction: 0.373073, Regularization: 0.000145, Discriminator: 0.043311; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:04,846 root         INFO     Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 0.438563\n",
      "Reconstruction: 0.373406, Regularization: 0.000160, Discriminator: 0.043315; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:04,959 root         INFO     Train Epoch: 126 [3584/8000 (45%)]\tTotal Loss: 0.438263\n",
      "Reconstruction: 0.373215, Regularization: 0.000149, Discriminator: 0.043323; Generator: 0.021576,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:05,073 root         INFO     Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 0.438517\n",
      "Reconstruction: 0.373408, Regularization: 0.000185, Discriminator: 0.043317; Generator: 0.021608,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:05,186 root         INFO     Train Epoch: 126 [4608/8000 (58%)]\tTotal Loss: 0.438321\n",
      "Reconstruction: 0.373139, Regularization: 0.000168, Discriminator: 0.043330; Generator: 0.021684,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:05,300 root         INFO     Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 0.438997\n",
      "Reconstruction: 0.373816, Regularization: 0.000161, Discriminator: 0.043329; Generator: 0.021691,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:05,412 root         INFO     Train Epoch: 126 [5632/8000 (70%)]\tTotal Loss: 0.438713\n",
      "Reconstruction: 0.373619, Regularization: 0.000152, Discriminator: 0.043341; Generator: 0.021601,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:05,525 root         INFO     Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 0.440587\n",
      "Reconstruction: 0.375433, Regularization: 0.000159, Discriminator: 0.043340; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:05,638 root         INFO     Train Epoch: 126 [6656/8000 (83%)]\tTotal Loss: 0.440525\n",
      "Reconstruction: 0.375304, Regularization: 0.000167, Discriminator: 0.043326; Generator: 0.021727,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:05,750 root         INFO     Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 0.441681\n",
      "Reconstruction: 0.376450, Regularization: 0.000166, Discriminator: 0.043353; Generator: 0.021712,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:05,863 root         INFO     Train Epoch: 126 [7680/8000 (96%)]\tTotal Loss: 0.443033\n",
      "Reconstruction: 0.377786, Regularization: 0.000170, Discriminator: 0.043336; Generator: 0.021741,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:05,944 root         INFO     ====> Epoch: 126 Average loss: 0.4389\n",
      "2019-04-10 00:59:05,971 root         INFO     Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 0.443051\n",
      "Reconstruction: 0.377894, Regularization: 0.000177, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:06,086 root         INFO     Train Epoch: 127 [512/8000 (6%)]\tTotal Loss: 0.442886\n",
      "Reconstruction: 0.377743, Regularization: 0.000153, Discriminator: 0.043322; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:06,198 root         INFO     Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 0.443883\n",
      "Reconstruction: 0.378735, Regularization: 0.000159, Discriminator: 0.043316; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:06,311 root         INFO     Train Epoch: 127 [1536/8000 (19%)]\tTotal Loss: 0.444116\n",
      "Reconstruction: 0.378968, Regularization: 0.000138, Discriminator: 0.043321; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:06,424 root         INFO     Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 0.444562\n",
      "Reconstruction: 0.379340, Regularization: 0.000179, Discriminator: 0.043318; Generator: 0.021725,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:06,536 root         INFO     Train Epoch: 127 [2560/8000 (32%)]\tTotal Loss: 0.443858\n",
      "Reconstruction: 0.378707, Regularization: 0.000142, Discriminator: 0.043286; Generator: 0.021723,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:06,649 root         INFO     Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 0.443964\n",
      "Reconstruction: 0.378771, Regularization: 0.000151, Discriminator: 0.043344; Generator: 0.021698,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:06,761 root         INFO     Train Epoch: 127 [3584/8000 (45%)]\tTotal Loss: 0.441962\n",
      "Reconstruction: 0.376784, Regularization: 0.000166, Discriminator: 0.043298; Generator: 0.021715,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:06,874 root         INFO     Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 0.442030\n",
      "Reconstruction: 0.376878, Regularization: 0.000170, Discriminator: 0.043292; Generator: 0.021691,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:06,986 root         INFO     Train Epoch: 127 [4608/8000 (58%)]\tTotal Loss: 0.440047\n",
      "Reconstruction: 0.374898, Regularization: 0.000191, Discriminator: 0.043289; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:07,099 root         INFO     Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 0.438733\n",
      "Reconstruction: 0.373552, Regularization: 0.000182, Discriminator: 0.043328; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:07,212 root         INFO     Train Epoch: 127 [5632/8000 (70%)]\tTotal Loss: 0.438013\n",
      "Reconstruction: 0.372831, Regularization: 0.000188, Discriminator: 0.043324; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:07,325 root         INFO     Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 0.436933\n",
      "Reconstruction: 0.371787, Regularization: 0.000170, Discriminator: 0.043310; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:07,437 root         INFO     Train Epoch: 127 [6656/8000 (83%)]\tTotal Loss: 0.436951\n",
      "Reconstruction: 0.371772, Regularization: 0.000161, Discriminator: 0.043304; Generator: 0.021715,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:07,550 root         INFO     Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 0.436081\n",
      "Reconstruction: 0.370911, Regularization: 0.000172, Discriminator: 0.043350; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:07,662 root         INFO     Train Epoch: 127 [7680/8000 (96%)]\tTotal Loss: 0.436440\n",
      "Reconstruction: 0.371398, Regularization: 0.000157, Discriminator: 0.043329; Generator: 0.021557,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:59:07,743 root         INFO     ====> Epoch: 127 Average loss: 0.4406\n",
      "2019-04-10 00:59:07,771 root         INFO     Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 0.436685\n",
      "Reconstruction: 0.371534, Regularization: 0.000164, Discriminator: 0.043327; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:07,883 root         INFO     Train Epoch: 128 [512/8000 (6%)]\tTotal Loss: 0.436119\n",
      "Reconstruction: 0.370986, Regularization: 0.000176, Discriminator: 0.043317; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:07,995 root         INFO     Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 0.436401\n",
      "Reconstruction: 0.371272, Regularization: 0.000196, Discriminator: 0.043307; Generator: 0.021625,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:08,107 root         INFO     Train Epoch: 128 [1536/8000 (19%)]\tTotal Loss: 0.434933\n",
      "Reconstruction: 0.369873, Regularization: 0.000171, Discriminator: 0.043318; Generator: 0.021572,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:08,220 root         INFO     Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 0.435447\n",
      "Reconstruction: 0.370361, Regularization: 0.000164, Discriminator: 0.043325; Generator: 0.021596,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:08,332 root         INFO     Train Epoch: 128 [2560/8000 (32%)]\tTotal Loss: 0.433802\n",
      "Reconstruction: 0.368772, Regularization: 0.000160, Discriminator: 0.043314; Generator: 0.021557,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:59:08,445 root         INFO     Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 0.434080\n",
      "Reconstruction: 0.369075, Regularization: 0.000156, Discriminator: 0.043302; Generator: 0.021547,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:59:08,557 root         INFO     Train Epoch: 128 [3584/8000 (45%)]\tTotal Loss: 0.435327\n",
      "Reconstruction: 0.370233, Regularization: 0.000152, Discriminator: 0.043309; Generator: 0.021632,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:08,670 root         INFO     Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 0.436824\n",
      "Reconstruction: 0.371745, Regularization: 0.000145, Discriminator: 0.043329; Generator: 0.021605,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:08,782 root         INFO     Train Epoch: 128 [4608/8000 (58%)]\tTotal Loss: 0.437540\n",
      "Reconstruction: 0.372474, Regularization: 0.000152, Discriminator: 0.043328; Generator: 0.021587,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:08,895 root         INFO     Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 0.438763\n",
      "Reconstruction: 0.373589, Regularization: 0.000146, Discriminator: 0.043344; Generator: 0.021684,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:09,007 root         INFO     Train Epoch: 128 [5632/8000 (70%)]\tTotal Loss: 0.440495\n",
      "Reconstruction: 0.375317, Regularization: 0.000137, Discriminator: 0.043328; Generator: 0.021713,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:09,119 root         INFO     Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 0.442003\n",
      "Reconstruction: 0.376874, Regularization: 0.000141, Discriminator: 0.043341; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:09,231 root         INFO     Train Epoch: 128 [6656/8000 (83%)]\tTotal Loss: 0.442775\n",
      "Reconstruction: 0.377607, Regularization: 0.000129, Discriminator: 0.043319; Generator: 0.021720,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:09,344 root         INFO     Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 0.444573\n",
      "Reconstruction: 0.379361, Regularization: 0.000161, Discriminator: 0.043327; Generator: 0.021723,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:09,456 root         INFO     Train Epoch: 128 [7680/8000 (96%)]\tTotal Loss: 0.443763\n",
      "Reconstruction: 0.378507, Regularization: 0.000146, Discriminator: 0.043330; Generator: 0.021781,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:59:09,540 root         INFO     ====> Epoch: 128 Average loss: 0.4385\n",
      "2019-04-10 00:59:09,567 root         INFO     Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 0.444656\n",
      "Reconstruction: 0.379418, Regularization: 0.000142, Discriminator: 0.043319; Generator: 0.021778,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:59:09,680 root         INFO     Train Epoch: 129 [512/8000 (6%)]\tTotal Loss: 0.443497\n",
      "Reconstruction: 0.378276, Regularization: 0.000125, Discriminator: 0.043328; Generator: 0.021768,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:59:09,791 root         INFO     Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 0.441391\n",
      "Reconstruction: 0.376253, Regularization: 0.000144, Discriminator: 0.043302; Generator: 0.021693,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:09,904 root         INFO     Train Epoch: 129 [1536/8000 (19%)]\tTotal Loss: 0.440863\n",
      "Reconstruction: 0.375670, Regularization: 0.000142, Discriminator: 0.043325; Generator: 0.021726,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:10,016 root         INFO     Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 0.440265\n",
      "Reconstruction: 0.375143, Regularization: 0.000141, Discriminator: 0.043308; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:10,128 root         INFO     Train Epoch: 129 [2560/8000 (32%)]\tTotal Loss: 0.440737\n",
      "Reconstruction: 0.375668, Regularization: 0.000133, Discriminator: 0.043311; Generator: 0.021626,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:10,241 root         INFO     Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 0.441121\n",
      "Reconstruction: 0.376155, Regularization: 0.000125, Discriminator: 0.043281; Generator: 0.021560,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:59:10,353 root         INFO     Train Epoch: 129 [3584/8000 (45%)]\tTotal Loss: 0.442453\n",
      "Reconstruction: 0.377229, Regularization: 0.000137, Discriminator: 0.043344; Generator: 0.021744,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:10,465 root         INFO     Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 0.441466\n",
      "Reconstruction: 0.376277, Regularization: 0.000147, Discriminator: 0.043347; Generator: 0.021695,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:10,578 root         INFO     Train Epoch: 129 [4608/8000 (58%)]\tTotal Loss: 0.442118\n",
      "Reconstruction: 0.376956, Regularization: 0.000147, Discriminator: 0.043360; Generator: 0.021655,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:10,690 root         INFO     Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 0.440629\n",
      "Reconstruction: 0.375508, Regularization: 0.000142, Discriminator: 0.043276; Generator: 0.021703,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:10,802 root         INFO     Train Epoch: 129 [5632/8000 (70%)]\tTotal Loss: 0.438273\n",
      "Reconstruction: 0.373193, Regularization: 0.000165, Discriminator: 0.043282; Generator: 0.021633,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:10,916 root         INFO     Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 0.436807\n",
      "Reconstruction: 0.371665, Regularization: 0.000154, Discriminator: 0.043352; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:11,028 root         INFO     Train Epoch: 129 [6656/8000 (83%)]\tTotal Loss: 0.434775\n",
      "Reconstruction: 0.369467, Regularization: 0.000157, Discriminator: 0.043476; Generator: 0.021675,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-10 00:59:11,138 root         INFO     Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 0.432838\n",
      "Reconstruction: 0.367670, Regularization: 0.000156, Discriminator: 0.043371; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:11,249 root         INFO     Train Epoch: 129 [7680/8000 (96%)]\tTotal Loss: 0.431560\n",
      "Reconstruction: 0.366502, Regularization: 0.000152, Discriminator: 0.043327; Generator: 0.021579,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:11,330 root         INFO     ====> Epoch: 129 Average loss: 0.4394\n",
      "2019-04-10 00:59:11,357 root         INFO     Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 0.432450\n",
      "Reconstruction: 0.367366, Regularization: 0.000157, Discriminator: 0.043327; Generator: 0.021600,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:11,468 root         INFO     Train Epoch: 130 [512/8000 (6%)]\tTotal Loss: 0.433218\n",
      "Reconstruction: 0.368195, Regularization: 0.000139, Discriminator: 0.043317; Generator: 0.021567,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:59:11,577 root         INFO     Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 0.433760\n",
      "Reconstruction: 0.368713, Regularization: 0.000151, Discriminator: 0.043303; Generator: 0.021593,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:11,685 root         INFO     Train Epoch: 130 [1536/8000 (19%)]\tTotal Loss: 0.435551\n",
      "Reconstruction: 0.370576, Regularization: 0.000128, Discriminator: 0.043248; Generator: 0.021599,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:59:11,793 root         INFO     Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 0.437637\n",
      "Reconstruction: 0.372448, Regularization: 0.000125, Discriminator: 0.043354; Generator: 0.021710,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:11,901 root         INFO     Train Epoch: 130 [2560/8000 (32%)]\tTotal Loss: 0.438828\n",
      "Reconstruction: 0.373803, Regularization: 0.000126, Discriminator: 0.043301; Generator: 0.021598,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:12,010 root         INFO     Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 0.442116\n",
      "Reconstruction: 0.377050, Regularization: 0.000121, Discriminator: 0.043281; Generator: 0.021664,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:12,118 root         INFO     Train Epoch: 130 [3584/8000 (45%)]\tTotal Loss: 0.443149\n",
      "Reconstruction: 0.377925, Regularization: 0.000134, Discriminator: 0.043363; Generator: 0.021727,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:12,227 root         INFO     Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 0.444603\n",
      "Reconstruction: 0.379505, Regularization: 0.000098, Discriminator: 0.043296; Generator: 0.021705,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:12,335 root         INFO     Train Epoch: 130 [4608/8000 (58%)]\tTotal Loss: 0.443950\n",
      "Reconstruction: 0.378866, Regularization: 0.000095, Discriminator: 0.043315; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:12,443 root         INFO     Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 0.444071\n",
      "Reconstruction: 0.378989, Regularization: 0.000111, Discriminator: 0.043333; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:12,552 root         INFO     Train Epoch: 130 [5632/8000 (70%)]\tTotal Loss: 0.442914\n",
      "Reconstruction: 0.377788, Regularization: 0.000095, Discriminator: 0.043286; Generator: 0.021745,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:12,660 root         INFO     Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 0.441740\n",
      "Reconstruction: 0.376565, Regularization: 0.000109, Discriminator: 0.043338; Generator: 0.021729,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:12,769 root         INFO     Train Epoch: 130 [6656/8000 (83%)]\tTotal Loss: 0.439823\n",
      "Reconstruction: 0.374696, Regularization: 0.000087, Discriminator: 0.043315; Generator: 0.021725,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:12,878 root         INFO     Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 0.438982\n",
      "Reconstruction: 0.373769, Regularization: 0.000108, Discriminator: 0.043391; Generator: 0.021714,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:12,986 root         INFO     Train Epoch: 130 [7680/8000 (96%)]\tTotal Loss: 0.438594\n",
      "Reconstruction: 0.373461, Regularization: 0.000136, Discriminator: 0.043331; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:13,065 root         INFO     ====> Epoch: 130 Average loss: 0.4396\n",
      "2019-04-10 00:59:13,092 root         INFO     Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 0.437252\n",
      "Reconstruction: 0.372200, Regularization: 0.000114, Discriminator: 0.043318; Generator: 0.021620,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:13,205 root         INFO     Train Epoch: 131 [512/8000 (6%)]\tTotal Loss: 0.437768\n",
      "Reconstruction: 0.372696, Regularization: 0.000113, Discriminator: 0.043309; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:13,318 root         INFO     Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 0.437845\n",
      "Reconstruction: 0.372769, Regularization: 0.000083, Discriminator: 0.043295; Generator: 0.021698,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:13,430 root         INFO     Train Epoch: 131 [1536/8000 (19%)]\tTotal Loss: 0.440184\n",
      "Reconstruction: 0.375106, Regularization: 0.000093, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:13,543 root         INFO     Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 0.440885\n",
      "Reconstruction: 0.375720, Regularization: 0.000093, Discriminator: 0.043356; Generator: 0.021716,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:13,655 root         INFO     Train Epoch: 131 [2560/8000 (32%)]\tTotal Loss: 0.440992\n",
      "Reconstruction: 0.375806, Regularization: 0.000111, Discriminator: 0.043368; Generator: 0.021706,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:13,768 root         INFO     Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 0.441870\n",
      "Reconstruction: 0.376788, Regularization: 0.000103, Discriminator: 0.043335; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:13,880 root         INFO     Train Epoch: 131 [3584/8000 (45%)]\tTotal Loss: 0.441266\n",
      "Reconstruction: 0.376117, Regularization: 0.000097, Discriminator: 0.043348; Generator: 0.021705,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:13,990 root         INFO     Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 0.440509\n",
      "Reconstruction: 0.375414, Regularization: 0.000093, Discriminator: 0.043304; Generator: 0.021698,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:14,101 root         INFO     Train Epoch: 131 [4608/8000 (58%)]\tTotal Loss: 0.439315\n",
      "Reconstruction: 0.374327, Regularization: 0.000090, Discriminator: 0.043271; Generator: 0.021628,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:14,210 root         INFO     Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 0.436343\n",
      "Reconstruction: 0.371344, Regularization: 0.000100, Discriminator: 0.043333; Generator: 0.021565,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-10 00:59:14,318 root         INFO     Train Epoch: 131 [5632/8000 (70%)]\tTotal Loss: 0.435546\n",
      "Reconstruction: 0.370518, Regularization: 0.000109, Discriminator: 0.043316; Generator: 0.021604,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:14,426 root         INFO     Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 0.433484\n",
      "Reconstruction: 0.368460, Regularization: 0.000111, Discriminator: 0.043340; Generator: 0.021572,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:14,535 root         INFO     Train Epoch: 131 [6656/8000 (83%)]\tTotal Loss: 0.432622\n",
      "Reconstruction: 0.367597, Regularization: 0.000121, Discriminator: 0.043315; Generator: 0.021589,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:14,644 root         INFO     Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 0.432956\n",
      "Reconstruction: 0.367929, Regularization: 0.000131, Discriminator: 0.043319; Generator: 0.021577,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:14,752 root         INFO     Train Epoch: 131 [7680/8000 (96%)]\tTotal Loss: 0.433437\n",
      "Reconstruction: 0.368427, Regularization: 0.000106, Discriminator: 0.043282; Generator: 0.021622,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:14,831 root         INFO     ====> Epoch: 131 Average loss: 0.4377\n",
      "2019-04-10 00:59:14,858 root         INFO     Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 0.434024\n",
      "Reconstruction: 0.368971, Regularization: 0.000094, Discriminator: 0.043353; Generator: 0.021606,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:14,969 root         INFO     Train Epoch: 132 [512/8000 (6%)]\tTotal Loss: 0.435953\n",
      "Reconstruction: 0.370871, Regularization: 0.000097, Discriminator: 0.043295; Generator: 0.021689,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:15,079 root         INFO     Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 0.437840\n",
      "Reconstruction: 0.372797, Regularization: 0.000121, Discriminator: 0.043276; Generator: 0.021647,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:15,188 root         INFO     Train Epoch: 132 [1536/8000 (19%)]\tTotal Loss: 0.439481\n",
      "Reconstruction: 0.374405, Regularization: 0.000092, Discriminator: 0.043305; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:15,297 root         INFO     Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 0.440824\n",
      "Reconstruction: 0.375747, Regularization: 0.000092, Discriminator: 0.043328; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:15,406 root         INFO     Train Epoch: 132 [2560/8000 (32%)]\tTotal Loss: 0.443010\n",
      "Reconstruction: 0.377967, Regularization: 0.000095, Discriminator: 0.043318; Generator: 0.021629,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:15,516 root         INFO     Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 0.444168\n",
      "Reconstruction: 0.378942, Regularization: 0.000120, Discriminator: 0.043323; Generator: 0.021782,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:59:15,625 root         INFO     Train Epoch: 132 [3584/8000 (45%)]\tTotal Loss: 0.445400\n",
      "Reconstruction: 0.380219, Regularization: 0.000109, Discriminator: 0.043326; Generator: 0.021746,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:15,733 root         INFO     Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 0.445738\n",
      "Reconstruction: 0.380562, Regularization: 0.000096, Discriminator: 0.043326; Generator: 0.021755,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:59:15,840 root         INFO     Train Epoch: 132 [4608/8000 (58%)]\tTotal Loss: 0.445405\n",
      "Reconstruction: 0.380254, Regularization: 0.000106, Discriminator: 0.043318; Generator: 0.021727,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:15,947 root         INFO     Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 0.444655\n",
      "Reconstruction: 0.379516, Regularization: 0.000119, Discriminator: 0.043347; Generator: 0.021673,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:16,055 root         INFO     Train Epoch: 132 [5632/8000 (70%)]\tTotal Loss: 0.443890\n",
      "Reconstruction: 0.378715, Regularization: 0.000101, Discriminator: 0.043297; Generator: 0.021777,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 00:59:16,162 root         INFO     Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 0.441607\n",
      "Reconstruction: 0.376523, Regularization: 0.000112, Discriminator: 0.043258; Generator: 0.021714,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:16,269 root         INFO     Train Epoch: 132 [6656/8000 (83%)]\tTotal Loss: 0.440140\n",
      "Reconstruction: 0.375008, Regularization: 0.000082, Discriminator: 0.043368; Generator: 0.021682,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:16,377 root         INFO     Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 0.438816\n",
      "Reconstruction: 0.373781, Regularization: 0.000091, Discriminator: 0.043290; Generator: 0.021653,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:16,484 root         INFO     Train Epoch: 132 [7680/8000 (96%)]\tTotal Loss: 0.437655\n",
      "Reconstruction: 0.372613, Regularization: 0.000098, Discriminator: 0.043312; Generator: 0.021632,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:16,564 root         INFO     ====> Epoch: 132 Average loss: 0.4414\n",
      "2019-04-10 00:59:16,592 root         INFO     Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 0.438032\n",
      "Reconstruction: 0.372991, Regularization: 0.000076, Discriminator: 0.043311; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:16,704 root         INFO     Train Epoch: 133 [512/8000 (6%)]\tTotal Loss: 0.437765\n",
      "Reconstruction: 0.372807, Regularization: 0.000073, Discriminator: 0.043290; Generator: 0.021596,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:59:16,815 root         INFO     Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 0.438565\n",
      "Reconstruction: 0.373581, Regularization: 0.000103, Discriminator: 0.043303; Generator: 0.021577,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:59:16,926 root         INFO     Train Epoch: 133 [1536/8000 (19%)]\tTotal Loss: 0.440331\n",
      "Reconstruction: 0.375297, Regularization: 0.000077, Discriminator: 0.043318; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:17,037 root         INFO     Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 0.441185\n",
      "Reconstruction: 0.376014, Regularization: 0.000089, Discriminator: 0.043339; Generator: 0.021743,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:17,148 root         INFO     Train Epoch: 133 [2560/8000 (32%)]\tTotal Loss: 0.441677\n",
      "Reconstruction: 0.376577, Regularization: 0.000088, Discriminator: 0.043349; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:17,259 root         INFO     Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 0.442139\n",
      "Reconstruction: 0.376988, Regularization: 0.000097, Discriminator: 0.043346; Generator: 0.021708,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:17,371 root         INFO     Train Epoch: 133 [3584/8000 (45%)]\tTotal Loss: 0.442152\n",
      "Reconstruction: 0.377085, Regularization: 0.000086, Discriminator: 0.043315; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:17,483 root         INFO     Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 0.441104\n",
      "Reconstruction: 0.376114, Regularization: 0.000091, Discriminator: 0.043319; Generator: 0.021580,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:17,593 root         INFO     Train Epoch: 133 [4608/8000 (58%)]\tTotal Loss: 0.439266\n",
      "Reconstruction: 0.374299, Regularization: 0.000098, Discriminator: 0.043228; Generator: 0.021640,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-10 00:59:17,703 root         INFO     Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 0.436595\n",
      "Reconstruction: 0.371682, Regularization: 0.000085, Discriminator: 0.043202; Generator: 0.021625,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-10 00:59:17,813 root         INFO     Train Epoch: 133 [5632/8000 (70%)]\tTotal Loss: 0.434413\n",
      "Reconstruction: 0.369414, Regularization: 0.000107, Discriminator: 0.043284; Generator: 0.021608,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:17,923 root         INFO     Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 0.432870\n",
      "Reconstruction: 0.367777, Regularization: 0.000092, Discriminator: 0.043362; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:18,032 root         INFO     Train Epoch: 133 [6656/8000 (83%)]\tTotal Loss: 0.431714\n",
      "Reconstruction: 0.366661, Regularization: 0.000098, Discriminator: 0.043356; Generator: 0.021599,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:18,142 root         INFO     Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 0.431746\n",
      "Reconstruction: 0.366675, Regularization: 0.000114, Discriminator: 0.043337; Generator: 0.021620,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:18,251 root         INFO     Train Epoch: 133 [7680/8000 (96%)]\tTotal Loss: 0.432343\n",
      "Reconstruction: 0.367302, Regularization: 0.000103, Discriminator: 0.043307; Generator: 0.021631,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:18,331 root         INFO     ====> Epoch: 133 Average loss: 0.4376\n",
      "2019-04-10 00:59:18,359 root         INFO     Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 0.432223\n",
      "Reconstruction: 0.367238, Regularization: 0.000101, Discriminator: 0.043317; Generator: 0.021568,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:59:18,471 root         INFO     Train Epoch: 134 [512/8000 (6%)]\tTotal Loss: 0.433904\n",
      "Reconstruction: 0.368903, Regularization: 0.000108, Discriminator: 0.043292; Generator: 0.021601,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:18,582 root         INFO     Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 0.436083\n",
      "Reconstruction: 0.371046, Regularization: 0.000102, Discriminator: 0.043351; Generator: 0.021584,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:18,694 root         INFO     Train Epoch: 134 [1536/8000 (19%)]\tTotal Loss: 0.438435\n",
      "Reconstruction: 0.373472, Regularization: 0.000107, Discriminator: 0.043233; Generator: 0.021624,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:59:18,806 root         INFO     Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 0.441540\n",
      "Reconstruction: 0.376514, Regularization: 0.000097, Discriminator: 0.043280; Generator: 0.021649,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:18,917 root         INFO     Train Epoch: 134 [2560/8000 (32%)]\tTotal Loss: 0.443737\n",
      "Reconstruction: 0.378621, Regularization: 0.000095, Discriminator: 0.043290; Generator: 0.021732,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:19,029 root         INFO     Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 0.446095\n",
      "Reconstruction: 0.380847, Regularization: 0.000088, Discriminator: 0.043364; Generator: 0.021796,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-10 00:59:19,140 root         INFO     Train Epoch: 134 [3584/8000 (45%)]\tTotal Loss: 0.447503\n",
      "Reconstruction: 0.382280, Regularization: 0.000074, Discriminator: 0.043372; Generator: 0.021777,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-10 00:59:19,250 root         INFO     Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 0.447956\n",
      "Reconstruction: 0.382814, Regularization: 0.000096, Discriminator: 0.043321; Generator: 0.021724,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:19,360 root         INFO     Train Epoch: 134 [4608/8000 (58%)]\tTotal Loss: 0.447776\n",
      "Reconstruction: 0.382678, Regularization: 0.000088, Discriminator: 0.043331; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:19,470 root         INFO     Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 0.446424\n",
      "Reconstruction: 0.381378, Regularization: 0.000096, Discriminator: 0.043243; Generator: 0.021707,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-10 00:59:19,579 root         INFO     Train Epoch: 134 [5632/8000 (70%)]\tTotal Loss: 0.444351\n",
      "Reconstruction: 0.379320, Regularization: 0.000107, Discriminator: 0.043247; Generator: 0.021676,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:19,688 root         INFO     Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 0.441498\n",
      "Reconstruction: 0.376449, Regularization: 0.000081, Discriminator: 0.043300; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:19,798 root         INFO     Train Epoch: 134 [6656/8000 (83%)]\tTotal Loss: 0.439377\n",
      "Reconstruction: 0.374192, Regularization: 0.000087, Discriminator: 0.043377; Generator: 0.021720,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:19,907 root         INFO     Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 0.436516\n",
      "Reconstruction: 0.371447, Regularization: 0.000085, Discriminator: 0.043329; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:20,017 root         INFO     Train Epoch: 134 [7680/8000 (96%)]\tTotal Loss: 0.434844\n",
      "Reconstruction: 0.369754, Regularization: 0.000086, Discriminator: 0.043378; Generator: 0.021625,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:20,098 root         INFO     ====> Epoch: 134 Average loss: 0.4415\n",
      "2019-04-10 00:59:20,125 root         INFO     Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 0.433490\n",
      "Reconstruction: 0.368422, Regularization: 0.000106, Discriminator: 0.043296; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:20,237 root         INFO     Train Epoch: 135 [512/8000 (6%)]\tTotal Loss: 0.433246\n",
      "Reconstruction: 0.368163, Regularization: 0.000088, Discriminator: 0.043342; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:20,348 root         INFO     Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 0.432950\n",
      "Reconstruction: 0.367947, Regularization: 0.000098, Discriminator: 0.043294; Generator: 0.021612,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:20,459 root         INFO     Train Epoch: 135 [1536/8000 (19%)]\tTotal Loss: 0.433519\n",
      "Reconstruction: 0.368563, Regularization: 0.000084, Discriminator: 0.043256; Generator: 0.021617,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:59:20,570 root         INFO     Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 0.434146\n",
      "Reconstruction: 0.369194, Regularization: 0.000080, Discriminator: 0.043325; Generator: 0.021547,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 00:59:20,679 root         INFO     Train Epoch: 135 [2560/8000 (32%)]\tTotal Loss: 0.436516\n",
      "Reconstruction: 0.371560, Regularization: 0.000089, Discriminator: 0.043238; Generator: 0.021630,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-10 00:59:20,790 root         INFO     Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 0.437249\n",
      "Reconstruction: 0.372213, Regularization: 0.000085, Discriminator: 0.043360; Generator: 0.021592,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:20,901 root         INFO     Train Epoch: 135 [3584/8000 (45%)]\tTotal Loss: 0.439197\n",
      "Reconstruction: 0.374038, Regularization: 0.000086, Discriminator: 0.043450; Generator: 0.021622,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-10 00:59:21,012 root         INFO     Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 0.441650\n",
      "Reconstruction: 0.376493, Regularization: 0.000093, Discriminator: 0.043393; Generator: 0.021671,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:21,123 root         INFO     Train Epoch: 135 [4608/8000 (58%)]\tTotal Loss: 0.442685\n",
      "Reconstruction: 0.377505, Regularization: 0.000080, Discriminator: 0.043358; Generator: 0.021743,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:21,235 root         INFO     Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 0.444135\n",
      "Reconstruction: 0.379016, Regularization: 0.000073, Discriminator: 0.043341; Generator: 0.021706,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:21,346 root         INFO     Train Epoch: 135 [5632/8000 (70%)]\tTotal Loss: 0.444056\n",
      "Reconstruction: 0.378992, Regularization: 0.000084, Discriminator: 0.043315; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:21,457 root         INFO     Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 0.443463\n",
      "Reconstruction: 0.378483, Regularization: 0.000081, Discriminator: 0.043284; Generator: 0.021615,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:21,568 root         INFO     Train Epoch: 135 [6656/8000 (83%)]\tTotal Loss: 0.442930\n",
      "Reconstruction: 0.377939, Regularization: 0.000089, Discriminator: 0.043267; Generator: 0.021635,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:21,680 root         INFO     Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 0.442347\n",
      "Reconstruction: 0.377337, Regularization: 0.000093, Discriminator: 0.043287; Generator: 0.021629,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:21,791 root         INFO     Train Epoch: 135 [7680/8000 (96%)]\tTotal Loss: 0.441166\n",
      "Reconstruction: 0.376064, Regularization: 0.000110, Discriminator: 0.043324; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:21,872 root         INFO     ====> Epoch: 135 Average loss: 0.4390\n",
      "2019-04-10 00:59:21,900 root         INFO     Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 0.439670\n",
      "Reconstruction: 0.374630, Regularization: 0.000096, Discriminator: 0.043247; Generator: 0.021698,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-10 00:59:22,011 root         INFO     Train Epoch: 136 [512/8000 (6%)]\tTotal Loss: 0.438620\n",
      "Reconstruction: 0.373405, Regularization: 0.000109, Discriminator: 0.043395; Generator: 0.021711,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:22,124 root         INFO     Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 0.436372\n",
      "Reconstruction: 0.371147, Regularization: 0.000076, Discriminator: 0.043473; Generator: 0.021676,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-10 00:59:22,236 root         INFO     Train Epoch: 136 [1536/8000 (19%)]\tTotal Loss: 0.435800\n",
      "Reconstruction: 0.370642, Regularization: 0.000093, Discriminator: 0.043369; Generator: 0.021696,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:22,349 root         INFO     Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 0.434191\n",
      "Reconstruction: 0.369064, Regularization: 0.000087, Discriminator: 0.043356; Generator: 0.021684,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:22,461 root         INFO     Train Epoch: 136 [2560/8000 (32%)]\tTotal Loss: 0.435505\n",
      "Reconstruction: 0.370375, Regularization: 0.000099, Discriminator: 0.043340; Generator: 0.021691,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:22,574 root         INFO     Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 0.435441\n",
      "Reconstruction: 0.370250, Regularization: 0.000107, Discriminator: 0.043319; Generator: 0.021766,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:59:22,686 root         INFO     Train Epoch: 136 [3584/8000 (45%)]\tTotal Loss: 0.435375\n",
      "Reconstruction: 0.370300, Regularization: 0.000093, Discriminator: 0.043298; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:22,799 root         INFO     Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 0.436509\n",
      "Reconstruction: 0.371494, Regularization: 0.000086, Discriminator: 0.043270; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:22,912 root         INFO     Train Epoch: 136 [4608/8000 (58%)]\tTotal Loss: 0.437118\n",
      "Reconstruction: 0.372018, Regularization: 0.000103, Discriminator: 0.043287; Generator: 0.021709,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:23,024 root         INFO     Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 0.438348\n",
      "Reconstruction: 0.373282, Regularization: 0.000090, Discriminator: 0.043281; Generator: 0.021696,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:23,136 root         INFO     Train Epoch: 136 [5632/8000 (70%)]\tTotal Loss: 0.439371\n",
      "Reconstruction: 0.374304, Regularization: 0.000093, Discriminator: 0.043304; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:23,248 root         INFO     Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 0.440311\n",
      "Reconstruction: 0.375244, Regularization: 0.000099, Discriminator: 0.043352; Generator: 0.021616,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:23,358 root         INFO     Train Epoch: 136 [6656/8000 (83%)]\tTotal Loss: 0.442059\n",
      "Reconstruction: 0.376923, Regularization: 0.000091, Discriminator: 0.043358; Generator: 0.021687,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:23,465 root         INFO     Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 0.442798\n",
      "Reconstruction: 0.377675, Regularization: 0.000082, Discriminator: 0.043350; Generator: 0.021691,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:23,572 root         INFO     Train Epoch: 136 [7680/8000 (96%)]\tTotal Loss: 0.444707\n",
      "Reconstruction: 0.379502, Regularization: 0.000101, Discriminator: 0.043394; Generator: 0.021709,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:23,651 root         INFO     ====> Epoch: 136 Average loss: 0.4384\n",
      "2019-04-10 00:59:23,678 root         INFO     Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 0.444662\n",
      "Reconstruction: 0.379502, Regularization: 0.000091, Discriminator: 0.043401; Generator: 0.021668,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:23,790 root         INFO     Train Epoch: 137 [512/8000 (6%)]\tTotal Loss: 0.445440\n",
      "Reconstruction: 0.380307, Regularization: 0.000083, Discriminator: 0.043356; Generator: 0.021694,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:23,902 root         INFO     Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 0.444802\n",
      "Reconstruction: 0.379722, Regularization: 0.000098, Discriminator: 0.043309; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:24,013 root         INFO     Train Epoch: 137 [1536/8000 (19%)]\tTotal Loss: 0.443592\n",
      "Reconstruction: 0.378688, Regularization: 0.000092, Discriminator: 0.043218; Generator: 0.021594,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-10 00:59:24,125 root         INFO     Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 0.442803\n",
      "Reconstruction: 0.377826, Regularization: 0.000116, Discriminator: 0.043244; Generator: 0.021617,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:59:24,236 root         INFO     Train Epoch: 137 [2560/8000 (32%)]\tTotal Loss: 0.441440\n",
      "Reconstruction: 0.376411, Regularization: 0.000105, Discriminator: 0.043225; Generator: 0.021699,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-10 00:59:24,348 root         INFO     Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 0.438709\n",
      "Reconstruction: 0.373595, Regularization: 0.000151, Discriminator: 0.043315; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:24,459 root         INFO     Train Epoch: 137 [3584/8000 (45%)]\tTotal Loss: 0.436336\n",
      "Reconstruction: 0.371375, Regularization: 0.000137, Discriminator: 0.043227; Generator: 0.021596,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-10 00:59:24,570 root         INFO     Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 0.434162\n",
      "Reconstruction: 0.369030, Regularization: 0.000158, Discriminator: 0.043390; Generator: 0.021584,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:24,679 root         INFO     Train Epoch: 137 [4608/8000 (58%)]\tTotal Loss: 0.431336\n",
      "Reconstruction: 0.366209, Regularization: 0.000159, Discriminator: 0.043394; Generator: 0.021573,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:24,789 root         INFO     Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 0.430920\n",
      "Reconstruction: 0.365845, Regularization: 0.000148, Discriminator: 0.043338; Generator: 0.021589,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:24,898 root         INFO     Train Epoch: 137 [5632/8000 (70%)]\tTotal Loss: 0.430480\n",
      "Reconstruction: 0.365393, Regularization: 0.000155, Discriminator: 0.043309; Generator: 0.021623,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:25,006 root         INFO     Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 0.430017\n",
      "Reconstruction: 0.364903, Regularization: 0.000171, Discriminator: 0.043305; Generator: 0.021637,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:25,115 root         INFO     Train Epoch: 137 [6656/8000 (83%)]\tTotal Loss: 0.431122\n",
      "Reconstruction: 0.366027, Regularization: 0.000154, Discriminator: 0.043324; Generator: 0.021617,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:25,225 root         INFO     Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 0.432090\n",
      "Reconstruction: 0.367026, Regularization: 0.000154, Discriminator: 0.043293; Generator: 0.021617,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:25,335 root         INFO     Train Epoch: 137 [7680/8000 (96%)]\tTotal Loss: 0.434127\n",
      "Reconstruction: 0.369140, Regularization: 0.000169, Discriminator: 0.043149; Generator: 0.021669,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-10 00:59:25,415 root         INFO     ====> Epoch: 137 Average loss: 0.4367\n",
      "2019-04-10 00:59:25,442 root         INFO     Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 0.435249\n",
      "Reconstruction: 0.370144, Regularization: 0.000162, Discriminator: 0.043262; Generator: 0.021682,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:25,555 root         INFO     Train Epoch: 138 [512/8000 (6%)]\tTotal Loss: 0.437328\n",
      "Reconstruction: 0.372233, Regularization: 0.000161, Discriminator: 0.043292; Generator: 0.021642,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:25,667 root         INFO     Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 0.440482\n",
      "Reconstruction: 0.375275, Regularization: 0.000195, Discriminator: 0.043211; Generator: 0.021802,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-10 00:59:25,779 root         INFO     Train Epoch: 138 [1536/8000 (19%)]\tTotal Loss: 0.442347\n",
      "Reconstruction: 0.377060, Regularization: 0.000176, Discriminator: 0.043415; Generator: 0.021696,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:25,892 root         INFO     Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 0.445211\n",
      "Reconstruction: 0.379919, Regularization: 0.000194, Discriminator: 0.043374; Generator: 0.021724,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:26,004 root         INFO     Train Epoch: 138 [2560/8000 (32%)]\tTotal Loss: 0.446314\n",
      "Reconstruction: 0.380903, Regularization: 0.000188, Discriminator: 0.043470; Generator: 0.021754,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-10 00:59:26,116 root         INFO     Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 0.447132\n",
      "Reconstruction: 0.381905, Regularization: 0.000178, Discriminator: 0.043360; Generator: 0.021688,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:26,228 root         INFO     Train Epoch: 138 [3584/8000 (45%)]\tTotal Loss: 0.449570\n",
      "Reconstruction: 0.384265, Regularization: 0.000167, Discriminator: 0.043271; Generator: 0.021867,\n",
      "D(x): 0.498, D(G(z)): 0.497\n",
      "2019-04-10 00:59:26,340 root         INFO     Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 0.450104\n",
      "Reconstruction: 0.384767, Regularization: 0.000185, Discriminator: 0.043362; Generator: 0.021791,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-10 00:59:26,452 root         INFO     Train Epoch: 138 [4608/8000 (58%)]\tTotal Loss: 0.449962\n",
      "Reconstruction: 0.384708, Regularization: 0.000165, Discriminator: 0.043294; Generator: 0.021795,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:59:26,565 root         INFO     Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 0.447771\n",
      "Reconstruction: 0.382632, Regularization: 0.000193, Discriminator: 0.043251; Generator: 0.021695,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-10 00:59:26,676 root         INFO     Train Epoch: 138 [5632/8000 (70%)]\tTotal Loss: 0.445935\n",
      "Reconstruction: 0.380765, Regularization: 0.000218, Discriminator: 0.043314; Generator: 0.021638,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:26,789 root         INFO     Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 0.445936\n",
      "Reconstruction: 0.380831, Regularization: 0.000217, Discriminator: 0.043182; Generator: 0.021705,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-10 00:59:26,901 root         INFO     Train Epoch: 138 [6656/8000 (83%)]\tTotal Loss: 0.442080\n",
      "Reconstruction: 0.376963, Regularization: 0.000225, Discriminator: 0.043259; Generator: 0.021633,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:27,011 root         INFO     Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 0.439350\n",
      "Reconstruction: 0.374277, Regularization: 0.000220, Discriminator: 0.043245; Generator: 0.021607,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:59:27,122 root         INFO     Train Epoch: 138 [7680/8000 (96%)]\tTotal Loss: 0.439285\n",
      "Reconstruction: 0.373984, Regularization: 0.000220, Discriminator: 0.043452; Generator: 0.021630,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-10 00:59:27,203 root         INFO     ====> Epoch: 138 Average loss: 0.4440\n",
      "2019-04-10 00:59:27,230 root         INFO     Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 0.437349\n",
      "Reconstruction: 0.372131, Regularization: 0.000218, Discriminator: 0.043353; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:27,343 root         INFO     Train Epoch: 139 [512/8000 (6%)]\tTotal Loss: 0.434781\n",
      "Reconstruction: 0.369566, Regularization: 0.000209, Discriminator: 0.043392; Generator: 0.021614,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:27,453 root         INFO     Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 0.432919\n",
      "Reconstruction: 0.367780, Regularization: 0.000199, Discriminator: 0.043328; Generator: 0.021612,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:27,565 root         INFO     Train Epoch: 139 [1536/8000 (19%)]\tTotal Loss: 0.432010\n",
      "Reconstruction: 0.366782, Regularization: 0.000219, Discriminator: 0.043394; Generator: 0.021615,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:27,675 root         INFO     Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 0.430302\n",
      "Reconstruction: 0.365148, Regularization: 0.000232, Discriminator: 0.043342; Generator: 0.021581,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:27,786 root         INFO     Train Epoch: 139 [2560/8000 (32%)]\tTotal Loss: 0.430790\n",
      "Reconstruction: 0.365639, Regularization: 0.000220, Discriminator: 0.043324; Generator: 0.021607,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:27,897 root         INFO     Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 0.431121\n",
      "Reconstruction: 0.365930, Regularization: 0.000219, Discriminator: 0.043321; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:28,008 root         INFO     Train Epoch: 139 [3584/8000 (45%)]\tTotal Loss: 0.430923\n",
      "Reconstruction: 0.365848, Regularization: 0.000210, Discriminator: 0.043278; Generator: 0.021587,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:59:28,119 root         INFO     Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 0.432541\n",
      "Reconstruction: 0.367461, Regularization: 0.000243, Discriminator: 0.043255; Generator: 0.021581,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:59:28,230 root         INFO     Train Epoch: 139 [4608/8000 (58%)]\tTotal Loss: 0.432769\n",
      "Reconstruction: 0.367680, Regularization: 0.000244, Discriminator: 0.043227; Generator: 0.021618,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:59:28,341 root         INFO     Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 0.434543\n",
      "Reconstruction: 0.369377, Regularization: 0.000218, Discriminator: 0.043334; Generator: 0.021614,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:28,452 root         INFO     Train Epoch: 139 [5632/8000 (70%)]\tTotal Loss: 0.435386\n",
      "Reconstruction: 0.370224, Regularization: 0.000222, Discriminator: 0.043325; Generator: 0.021614,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:28,562 root         INFO     Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 0.436461\n",
      "Reconstruction: 0.371341, Regularization: 0.000196, Discriminator: 0.043341; Generator: 0.021583,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:28,671 root         INFO     Train Epoch: 139 [6656/8000 (83%)]\tTotal Loss: 0.439752\n",
      "Reconstruction: 0.374581, Regularization: 0.000192, Discriminator: 0.043279; Generator: 0.021700,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:28,780 root         INFO     Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 0.440825\n",
      "Reconstruction: 0.375516, Regularization: 0.000218, Discriminator: 0.043392; Generator: 0.021700,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:28,888 root         INFO     Train Epoch: 139 [7680/8000 (96%)]\tTotal Loss: 0.443356\n",
      "Reconstruction: 0.378115, Regularization: 0.000216, Discriminator: 0.043348; Generator: 0.021678,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:28,969 root         INFO     ====> Epoch: 139 Average loss: 0.4348\n",
      "2019-04-10 00:59:28,997 root         INFO     Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 0.443613\n",
      "Reconstruction: 0.378323, Regularization: 0.000194, Discriminator: 0.043385; Generator: 0.021710,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:29,110 root         INFO     Train Epoch: 140 [512/8000 (6%)]\tTotal Loss: 0.445612\n",
      "Reconstruction: 0.380287, Regularization: 0.000195, Discriminator: 0.043417; Generator: 0.021712,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:29,223 root         INFO     Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 0.446477\n",
      "Reconstruction: 0.381281, Regularization: 0.000194, Discriminator: 0.043358; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:29,334 root         INFO     Train Epoch: 140 [1536/8000 (19%)]\tTotal Loss: 0.446748\n",
      "Reconstruction: 0.381498, Regularization: 0.000194, Discriminator: 0.043305; Generator: 0.021751,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:29,446 root         INFO     Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 0.446277\n",
      "Reconstruction: 0.381077, Regularization: 0.000199, Discriminator: 0.043306; Generator: 0.021695,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:29,558 root         INFO     Train Epoch: 140 [2560/8000 (32%)]\tTotal Loss: 0.446478\n",
      "Reconstruction: 0.381235, Regularization: 0.000204, Discriminator: 0.043249; Generator: 0.021789,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 00:59:29,670 root         INFO     Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 0.445481\n",
      "Reconstruction: 0.380286, Regularization: 0.000195, Discriminator: 0.043298; Generator: 0.021702,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:29,782 root         INFO     Train Epoch: 140 [3584/8000 (45%)]\tTotal Loss: 0.443804\n",
      "Reconstruction: 0.378523, Regularization: 0.000202, Discriminator: 0.043401; Generator: 0.021678,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 00:59:29,894 root         INFO     Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 0.442383\n",
      "Reconstruction: 0.377109, Regularization: 0.000205, Discriminator: 0.043342; Generator: 0.021727,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:30,006 root         INFO     Train Epoch: 140 [4608/8000 (58%)]\tTotal Loss: 0.441305\n",
      "Reconstruction: 0.376011, Regularization: 0.000214, Discriminator: 0.043357; Generator: 0.021723,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:30,117 root         INFO     Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 0.439392\n",
      "Reconstruction: 0.374216, Regularization: 0.000226, Discriminator: 0.043277; Generator: 0.021673,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:30,229 root         INFO     Train Epoch: 140 [5632/8000 (70%)]\tTotal Loss: 0.437339\n",
      "Reconstruction: 0.372064, Regularization: 0.000263, Discriminator: 0.043321; Generator: 0.021692,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:30,341 root         INFO     Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 0.437238\n",
      "Reconstruction: 0.371940, Regularization: 0.000265, Discriminator: 0.043323; Generator: 0.021710,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:30,453 root         INFO     Train Epoch: 140 [6656/8000 (83%)]\tTotal Loss: 0.436684\n",
      "Reconstruction: 0.371445, Regularization: 0.000269, Discriminator: 0.043325; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:30,565 root         INFO     Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 0.435385\n",
      "Reconstruction: 0.370137, Regularization: 0.000265, Discriminator: 0.043324; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:30,677 root         INFO     Train Epoch: 140 [7680/8000 (96%)]\tTotal Loss: 0.436072\n",
      "Reconstruction: 0.370829, Regularization: 0.000259, Discriminator: 0.043298; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:30,758 root         INFO     ====> Epoch: 140 Average loss: 0.4417\n",
      "2019-04-10 00:59:30,785 root         INFO     Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 0.436038\n",
      "Reconstruction: 0.370806, Regularization: 0.000265, Discriminator: 0.043301; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:30,899 root         INFO     Train Epoch: 141 [512/8000 (6%)]\tTotal Loss: 0.434349\n",
      "Reconstruction: 0.369169, Regularization: 0.000274, Discriminator: 0.043332; Generator: 0.021574,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:31,012 root         INFO     Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 0.435693\n",
      "Reconstruction: 0.370510, Regularization: 0.000280, Discriminator: 0.043298; Generator: 0.021605,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:31,124 root         INFO     Train Epoch: 141 [1536/8000 (19%)]\tTotal Loss: 0.435679\n",
      "Reconstruction: 0.370475, Regularization: 0.000273, Discriminator: 0.043304; Generator: 0.021627,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:31,237 root         INFO     Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 0.436872\n",
      "Reconstruction: 0.371596, Regularization: 0.000263, Discriminator: 0.043327; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:31,349 root         INFO     Train Epoch: 141 [2560/8000 (32%)]\tTotal Loss: 0.439476\n",
      "Reconstruction: 0.374178, Regularization: 0.000272, Discriminator: 0.043349; Generator: 0.021678,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:31,462 root         INFO     Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 0.439467\n",
      "Reconstruction: 0.374247, Regularization: 0.000262, Discriminator: 0.043320; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:31,575 root         INFO     Train Epoch: 141 [3584/8000 (45%)]\tTotal Loss: 0.440048\n",
      "Reconstruction: 0.374750, Regularization: 0.000255, Discriminator: 0.043364; Generator: 0.021679,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:31,687 root         INFO     Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 0.441564\n",
      "Reconstruction: 0.376295, Regularization: 0.000276, Discriminator: 0.043328; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:31,800 root         INFO     Train Epoch: 141 [4608/8000 (58%)]\tTotal Loss: 0.440528\n",
      "Reconstruction: 0.375265, Regularization: 0.000293, Discriminator: 0.043317; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:31,912 root         INFO     Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 0.440455\n",
      "Reconstruction: 0.375209, Regularization: 0.000268, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:32,025 root         INFO     Train Epoch: 141 [5632/8000 (70%)]\tTotal Loss: 0.440876\n",
      "Reconstruction: 0.375665, Regularization: 0.000279, Discriminator: 0.043314; Generator: 0.021618,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:32,138 root         INFO     Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 0.438674\n",
      "Reconstruction: 0.373525, Regularization: 0.000254, Discriminator: 0.043283; Generator: 0.021611,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:32,250 root         INFO     Train Epoch: 141 [6656/8000 (83%)]\tTotal Loss: 0.439140\n",
      "Reconstruction: 0.373944, Regularization: 0.000242, Discriminator: 0.043354; Generator: 0.021601,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:32,363 root         INFO     Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 0.438157\n",
      "Reconstruction: 0.372937, Regularization: 0.000265, Discriminator: 0.043321; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:32,475 root         INFO     Train Epoch: 141 [7680/8000 (96%)]\tTotal Loss: 0.437735\n",
      "Reconstruction: 0.372488, Regularization: 0.000282, Discriminator: 0.043316; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:32,557 root         INFO     ====> Epoch: 141 Average loss: 0.4385\n",
      "2019-04-10 00:59:32,584 root         INFO     Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 0.437705\n",
      "Reconstruction: 0.372412, Regularization: 0.000266, Discriminator: 0.043358; Generator: 0.021669,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:32,696 root         INFO     Train Epoch: 142 [512/8000 (6%)]\tTotal Loss: 0.437340\n",
      "Reconstruction: 0.372128, Regularization: 0.000280, Discriminator: 0.043298; Generator: 0.021634,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:32,807 root         INFO     Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 0.435985\n",
      "Reconstruction: 0.370718, Regularization: 0.000268, Discriminator: 0.043331; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:32,918 root         INFO     Train Epoch: 142 [1536/8000 (19%)]\tTotal Loss: 0.435782\n",
      "Reconstruction: 0.370498, Regularization: 0.000266, Discriminator: 0.043333; Generator: 0.021685,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:33,029 root         INFO     Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 0.436648\n",
      "Reconstruction: 0.371310, Regularization: 0.000273, Discriminator: 0.043350; Generator: 0.021715,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:33,140 root         INFO     Train Epoch: 142 [2560/8000 (32%)]\tTotal Loss: 0.436487\n",
      "Reconstruction: 0.371248, Regularization: 0.000249, Discriminator: 0.043325; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:33,252 root         INFO     Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 0.438438\n",
      "Reconstruction: 0.373223, Regularization: 0.000254, Discriminator: 0.043303; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:33,363 root         INFO     Train Epoch: 142 [3584/8000 (45%)]\tTotal Loss: 0.439471\n",
      "Reconstruction: 0.374136, Regularization: 0.000269, Discriminator: 0.043333; Generator: 0.021733,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:33,475 root         INFO     Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 0.440682\n",
      "Reconstruction: 0.375450, Regularization: 0.000280, Discriminator: 0.043266; Generator: 0.021685,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:33,587 root         INFO     Train Epoch: 142 [4608/8000 (58%)]\tTotal Loss: 0.441263\n",
      "Reconstruction: 0.375993, Regularization: 0.000269, Discriminator: 0.043309; Generator: 0.021691,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:33,698 root         INFO     Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 0.441415\n",
      "Reconstruction: 0.376114, Regularization: 0.000306, Discriminator: 0.043302; Generator: 0.021693,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:33,809 root         INFO     Train Epoch: 142 [5632/8000 (70%)]\tTotal Loss: 0.442790\n",
      "Reconstruction: 0.377485, Regularization: 0.000286, Discriminator: 0.043330; Generator: 0.021689,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:33,921 root         INFO     Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 0.444207\n",
      "Reconstruction: 0.378914, Regularization: 0.000294, Discriminator: 0.043302; Generator: 0.021696,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:34,032 root         INFO     Train Epoch: 142 [6656/8000 (83%)]\tTotal Loss: 0.446030\n",
      "Reconstruction: 0.380621, Regularization: 0.000300, Discriminator: 0.043370; Generator: 0.021739,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:34,143 root         INFO     Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 0.445050\n",
      "Reconstruction: 0.379663, Regularization: 0.000285, Discriminator: 0.043337; Generator: 0.021765,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:59:34,255 root         INFO     Train Epoch: 142 [7680/8000 (96%)]\tTotal Loss: 0.444904\n",
      "Reconstruction: 0.379512, Regularization: 0.000305, Discriminator: 0.043354; Generator: 0.021733,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:34,336 root         INFO     ====> Epoch: 142 Average loss: 0.4403\n",
      "2019-04-10 00:59:34,363 root         INFO     Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 0.443332\n",
      "Reconstruction: 0.377998, Regularization: 0.000287, Discriminator: 0.043330; Generator: 0.021718,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:34,477 root         INFO     Train Epoch: 143 [512/8000 (6%)]\tTotal Loss: 0.444017\n",
      "Reconstruction: 0.378761, Regularization: 0.000257, Discriminator: 0.043349; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:34,589 root         INFO     Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 0.442004\n",
      "Reconstruction: 0.376742, Regularization: 0.000242, Discriminator: 0.043346; Generator: 0.021673,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:34,702 root         INFO     Train Epoch: 143 [1536/8000 (19%)]\tTotal Loss: 0.440764\n",
      "Reconstruction: 0.375529, Regularization: 0.000254, Discriminator: 0.043345; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:34,813 root         INFO     Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 0.439344\n",
      "Reconstruction: 0.374096, Regularization: 0.000268, Discriminator: 0.043363; Generator: 0.021618,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:34,923 root         INFO     Train Epoch: 143 [2560/8000 (32%)]\tTotal Loss: 0.437991\n",
      "Reconstruction: 0.372740, Regularization: 0.000273, Discriminator: 0.043303; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:35,034 root         INFO     Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 0.435749\n",
      "Reconstruction: 0.370482, Regularization: 0.000276, Discriminator: 0.043406; Generator: 0.021585,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:35,145 root         INFO     Train Epoch: 143 [3584/8000 (45%)]\tTotal Loss: 0.434510\n",
      "Reconstruction: 0.369403, Regularization: 0.000268, Discriminator: 0.043266; Generator: 0.021573,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:59:35,255 root         INFO     Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 0.434087\n",
      "Reconstruction: 0.368844, Regularization: 0.000255, Discriminator: 0.043332; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:35,366 root         INFO     Train Epoch: 143 [4608/8000 (58%)]\tTotal Loss: 0.432510\n",
      "Reconstruction: 0.367313, Regularization: 0.000251, Discriminator: 0.043331; Generator: 0.021615,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:35,477 root         INFO     Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 0.432708\n",
      "Reconstruction: 0.367528, Regularization: 0.000257, Discriminator: 0.043316; Generator: 0.021607,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:35,587 root         INFO     Train Epoch: 143 [5632/8000 (70%)]\tTotal Loss: 0.431772\n",
      "Reconstruction: 0.366563, Regularization: 0.000252, Discriminator: 0.043331; Generator: 0.021626,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:35,698 root         INFO     Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 0.432815\n",
      "Reconstruction: 0.367601, Regularization: 0.000264, Discriminator: 0.043361; Generator: 0.021589,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:35,808 root         INFO     Train Epoch: 143 [6656/8000 (83%)]\tTotal Loss: 0.432552\n",
      "Reconstruction: 0.367279, Regularization: 0.000248, Discriminator: 0.043365; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:35,918 root         INFO     Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 0.433263\n",
      "Reconstruction: 0.368117, Regularization: 0.000226, Discriminator: 0.043294; Generator: 0.021626,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:36,028 root         INFO     Train Epoch: 143 [7680/8000 (96%)]\tTotal Loss: 0.435147\n",
      "Reconstruction: 0.369881, Regularization: 0.000237, Discriminator: 0.043355; Generator: 0.021673,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:36,107 root         INFO     ====> Epoch: 143 Average loss: 0.4362\n",
      "2019-04-10 00:59:36,135 root         INFO     Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 0.436901\n",
      "Reconstruction: 0.371692, Regularization: 0.000223, Discriminator: 0.043279; Generator: 0.021708,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:36,247 root         INFO     Train Epoch: 144 [512/8000 (6%)]\tTotal Loss: 0.437159\n",
      "Reconstruction: 0.371967, Regularization: 0.000242, Discriminator: 0.043319; Generator: 0.021630,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:36,358 root         INFO     Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 0.438622\n",
      "Reconstruction: 0.373408, Regularization: 0.000237, Discriminator: 0.043302; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:36,468 root         INFO     Train Epoch: 144 [1536/8000 (19%)]\tTotal Loss: 0.441323\n",
      "Reconstruction: 0.376050, Regularization: 0.000255, Discriminator: 0.043352; Generator: 0.021667,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:36,579 root         INFO     Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 0.442188\n",
      "Reconstruction: 0.376911, Regularization: 0.000239, Discriminator: 0.043346; Generator: 0.021692,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:36,690 root         INFO     Train Epoch: 144 [2560/8000 (32%)]\tTotal Loss: 0.443937\n",
      "Reconstruction: 0.378775, Regularization: 0.000231, Discriminator: 0.043287; Generator: 0.021644,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:36,800 root         INFO     Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 0.444792\n",
      "Reconstruction: 0.379522, Regularization: 0.000234, Discriminator: 0.043349; Generator: 0.021687,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:36,911 root         INFO     Train Epoch: 144 [3584/8000 (45%)]\tTotal Loss: 0.445706\n",
      "Reconstruction: 0.380457, Regularization: 0.000223, Discriminator: 0.043336; Generator: 0.021690,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:37,023 root         INFO     Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 0.446736\n",
      "Reconstruction: 0.381387, Regularization: 0.000252, Discriminator: 0.043363; Generator: 0.021734,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:37,133 root         INFO     Train Epoch: 144 [4608/8000 (58%)]\tTotal Loss: 0.447881\n",
      "Reconstruction: 0.382621, Regularization: 0.000226, Discriminator: 0.043327; Generator: 0.021706,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:37,240 root         INFO     Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 0.446781\n",
      "Reconstruction: 0.381535, Regularization: 0.000231, Discriminator: 0.043292; Generator: 0.021723,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:37,348 root         INFO     Train Epoch: 144 [5632/8000 (70%)]\tTotal Loss: 0.446144\n",
      "Reconstruction: 0.380939, Regularization: 0.000225, Discriminator: 0.043293; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:37,455 root         INFO     Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 0.443337\n",
      "Reconstruction: 0.378093, Regularization: 0.000205, Discriminator: 0.043308; Generator: 0.021731,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:37,563 root         INFO     Train Epoch: 144 [6656/8000 (83%)]\tTotal Loss: 0.441576\n",
      "Reconstruction: 0.376446, Regularization: 0.000213, Discriminator: 0.043218; Generator: 0.021699,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-10 00:59:37,670 root         INFO     Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 0.438459\n",
      "Reconstruction: 0.373397, Regularization: 0.000176, Discriminator: 0.043224; Generator: 0.021661,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-10 00:59:37,778 root         INFO     Train Epoch: 144 [7680/8000 (96%)]\tTotal Loss: 0.437679\n",
      "Reconstruction: 0.372368, Regularization: 0.000189, Discriminator: 0.043470; Generator: 0.021651,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 00:59:37,857 root         INFO     ====> Epoch: 144 Average loss: 0.4427\n",
      "2019-04-10 00:59:37,884 root         INFO     Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 0.435868\n",
      "Reconstruction: 0.370677, Regularization: 0.000201, Discriminator: 0.043340; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:37,995 root         INFO     Train Epoch: 145 [512/8000 (6%)]\tTotal Loss: 0.434429\n",
      "Reconstruction: 0.369237, Regularization: 0.000200, Discriminator: 0.043356; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:38,107 root         INFO     Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 0.431739\n",
      "Reconstruction: 0.366600, Regularization: 0.000177, Discriminator: 0.043340; Generator: 0.021620,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:38,217 root         INFO     Train Epoch: 145 [1536/8000 (19%)]\tTotal Loss: 0.432946\n",
      "Reconstruction: 0.367841, Regularization: 0.000166, Discriminator: 0.043327; Generator: 0.021612,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:38,328 root         INFO     Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 0.432142\n",
      "Reconstruction: 0.367002, Regularization: 0.000178, Discriminator: 0.043343; Generator: 0.021619,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:38,439 root         INFO     Train Epoch: 145 [2560/8000 (32%)]\tTotal Loss: 0.432672\n",
      "Reconstruction: 0.367563, Regularization: 0.000161, Discriminator: 0.043296; Generator: 0.021651,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:38,549 root         INFO     Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 0.433030\n",
      "Reconstruction: 0.367968, Regularization: 0.000169, Discriminator: 0.043295; Generator: 0.021598,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:38,656 root         INFO     Train Epoch: 145 [3584/8000 (45%)]\tTotal Loss: 0.433414\n",
      "Reconstruction: 0.368242, Regularization: 0.000177, Discriminator: 0.043358; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:38,764 root         INFO     Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 0.434694\n",
      "Reconstruction: 0.369631, Regularization: 0.000169, Discriminator: 0.043342; Generator: 0.021552,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-10 00:59:38,873 root         INFO     Train Epoch: 145 [4608/8000 (58%)]\tTotal Loss: 0.437166\n",
      "Reconstruction: 0.372059, Regularization: 0.000175, Discriminator: 0.043299; Generator: 0.021633,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:38,982 root         INFO     Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 0.437068\n",
      "Reconstruction: 0.371895, Regularization: 0.000184, Discriminator: 0.043390; Generator: 0.021600,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:39,091 root         INFO     Train Epoch: 145 [5632/8000 (70%)]\tTotal Loss: 0.439144\n",
      "Reconstruction: 0.373920, Regularization: 0.000187, Discriminator: 0.043413; Generator: 0.021624,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-10 00:59:39,200 root         INFO     Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 0.439625\n",
      "Reconstruction: 0.374511, Regularization: 0.000195, Discriminator: 0.043296; Generator: 0.021622,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:39,308 root         INFO     Train Epoch: 145 [6656/8000 (83%)]\tTotal Loss: 0.441010\n",
      "Reconstruction: 0.375875, Regularization: 0.000180, Discriminator: 0.043298; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:39,417 root         INFO     Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 0.442387\n",
      "Reconstruction: 0.377206, Regularization: 0.000174, Discriminator: 0.043360; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:39,526 root         INFO     Train Epoch: 145 [7680/8000 (96%)]\tTotal Loss: 0.443773\n",
      "Reconstruction: 0.378590, Regularization: 0.000175, Discriminator: 0.043331; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:39,605 root         INFO     ====> Epoch: 145 Average loss: 0.4361\n",
      "2019-04-10 00:59:39,632 root         INFO     Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 0.443038\n",
      "Reconstruction: 0.377863, Regularization: 0.000173, Discriminator: 0.043314; Generator: 0.021688,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:39,746 root         INFO     Train Epoch: 146 [512/8000 (6%)]\tTotal Loss: 0.441842\n",
      "Reconstruction: 0.376681, Regularization: 0.000181, Discriminator: 0.043290; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:39,859 root         INFO     Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 0.442731\n",
      "Reconstruction: 0.377523, Regularization: 0.000171, Discriminator: 0.043317; Generator: 0.021720,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:39,971 root         INFO     Train Epoch: 146 [1536/8000 (19%)]\tTotal Loss: 0.442264\n",
      "Reconstruction: 0.377087, Regularization: 0.000180, Discriminator: 0.043321; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:40,084 root         INFO     Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 0.440940\n",
      "Reconstruction: 0.375720, Regularization: 0.000173, Discriminator: 0.043338; Generator: 0.021709,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:40,196 root         INFO     Train Epoch: 146 [2560/8000 (32%)]\tTotal Loss: 0.440039\n",
      "Reconstruction: 0.374816, Regularization: 0.000180, Discriminator: 0.043384; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:40,308 root         INFO     Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 0.438855\n",
      "Reconstruction: 0.373648, Regularization: 0.000177, Discriminator: 0.043332; Generator: 0.021698,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:40,418 root         INFO     Train Epoch: 146 [3584/8000 (45%)]\tTotal Loss: 0.438308\n",
      "Reconstruction: 0.373057, Regularization: 0.000186, Discriminator: 0.043337; Generator: 0.021727,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:40,529 root         INFO     Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 0.438897\n",
      "Reconstruction: 0.373717, Regularization: 0.000199, Discriminator: 0.043333; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:40,640 root         INFO     Train Epoch: 146 [4608/8000 (58%)]\tTotal Loss: 0.441032\n",
      "Reconstruction: 0.375896, Regularization: 0.000183, Discriminator: 0.043307; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:40,751 root         INFO     Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 0.439727\n",
      "Reconstruction: 0.374532, Regularization: 0.000183, Discriminator: 0.043317; Generator: 0.021695,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:40,861 root         INFO     Train Epoch: 146 [5632/8000 (70%)]\tTotal Loss: 0.438700\n",
      "Reconstruction: 0.373547, Regularization: 0.000174, Discriminator: 0.043287; Generator: 0.021691,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:40,971 root         INFO     Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 0.441286\n",
      "Reconstruction: 0.376156, Regularization: 0.000182, Discriminator: 0.043268; Generator: 0.021680,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:41,082 root         INFO     Train Epoch: 146 [6656/8000 (83%)]\tTotal Loss: 0.441630\n",
      "Reconstruction: 0.376498, Regularization: 0.000170, Discriminator: 0.043287; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:41,193 root         INFO     Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 0.442586\n",
      "Reconstruction: 0.377464, Regularization: 0.000193, Discriminator: 0.043261; Generator: 0.021668,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:41,303 root         INFO     Train Epoch: 146 [7680/8000 (96%)]\tTotal Loss: 0.443619\n",
      "Reconstruction: 0.378452, Regularization: 0.000173, Discriminator: 0.043288; Generator: 0.021706,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:41,384 root         INFO     ====> Epoch: 146 Average loss: 0.4409\n",
      "2019-04-10 00:59:41,411 root         INFO     Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 0.441853\n",
      "Reconstruction: 0.376605, Regularization: 0.000180, Discriminator: 0.043314; Generator: 0.021754,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:41,523 root         INFO     Train Epoch: 147 [512/8000 (6%)]\tTotal Loss: 0.442174\n",
      "Reconstruction: 0.376968, Regularization: 0.000181, Discriminator: 0.043351; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:41,635 root         INFO     Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 0.442254\n",
      "Reconstruction: 0.377099, Regularization: 0.000171, Discriminator: 0.043338; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:41,747 root         INFO     Train Epoch: 147 [1536/8000 (19%)]\tTotal Loss: 0.442339\n",
      "Reconstruction: 0.377172, Regularization: 0.000162, Discriminator: 0.043360; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:41,858 root         INFO     Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 0.440174\n",
      "Reconstruction: 0.375020, Regularization: 0.000190, Discriminator: 0.043305; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:41,966 root         INFO     Train Epoch: 147 [2560/8000 (32%)]\tTotal Loss: 0.438862\n",
      "Reconstruction: 0.373742, Regularization: 0.000182, Discriminator: 0.043312; Generator: 0.021626,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:42,075 root         INFO     Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 0.437797\n",
      "Reconstruction: 0.372688, Regularization: 0.000215, Discriminator: 0.043259; Generator: 0.021635,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:42,184 root         INFO     Train Epoch: 147 [3584/8000 (45%)]\tTotal Loss: 0.436736\n",
      "Reconstruction: 0.371589, Regularization: 0.000215, Discriminator: 0.043320; Generator: 0.021612,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:42,293 root         INFO     Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 0.435090\n",
      "Reconstruction: 0.369864, Regularization: 0.000217, Discriminator: 0.043418; Generator: 0.021591,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:42,403 root         INFO     Train Epoch: 147 [4608/8000 (58%)]\tTotal Loss: 0.432833\n",
      "Reconstruction: 0.367608, Regularization: 0.000231, Discriminator: 0.043352; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:42,513 root         INFO     Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 0.430390\n",
      "Reconstruction: 0.365207, Regularization: 0.000228, Discriminator: 0.043322; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:42,623 root         INFO     Train Epoch: 147 [5632/8000 (70%)]\tTotal Loss: 0.431735\n",
      "Reconstruction: 0.366495, Regularization: 0.000227, Discriminator: 0.043370; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:42,734 root         INFO     Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 0.430690\n",
      "Reconstruction: 0.365570, Regularization: 0.000219, Discriminator: 0.043319; Generator: 0.021583,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:42,845 root         INFO     Train Epoch: 147 [6656/8000 (83%)]\tTotal Loss: 0.431296\n",
      "Reconstruction: 0.366153, Regularization: 0.000210, Discriminator: 0.043324; Generator: 0.021609,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:42,956 root         INFO     Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 0.432020\n",
      "Reconstruction: 0.366941, Regularization: 0.000218, Discriminator: 0.043261; Generator: 0.021601,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 00:59:43,067 root         INFO     Train Epoch: 147 [7680/8000 (96%)]\tTotal Loss: 0.433852\n",
      "Reconstruction: 0.368586, Regularization: 0.000210, Discriminator: 0.043372; Generator: 0.021684,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:43,148 root         INFO     ====> Epoch: 147 Average loss: 0.4363\n",
      "2019-04-10 00:59:43,175 root         INFO     Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 0.434651\n",
      "Reconstruction: 0.369405, Regularization: 0.000224, Discriminator: 0.043345; Generator: 0.021676,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:43,289 root         INFO     Train Epoch: 148 [512/8000 (6%)]\tTotal Loss: 0.435406\n",
      "Reconstruction: 0.370263, Regularization: 0.000211, Discriminator: 0.043308; Generator: 0.021624,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:43,402 root         INFO     Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 0.436404\n",
      "Reconstruction: 0.371250, Regularization: 0.000231, Discriminator: 0.043273; Generator: 0.021650,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:43,516 root         INFO     Train Epoch: 148 [1536/8000 (19%)]\tTotal Loss: 0.439179\n",
      "Reconstruction: 0.373993, Regularization: 0.000198, Discriminator: 0.043342; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:43,628 root         INFO     Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 0.442078\n",
      "Reconstruction: 0.376756, Regularization: 0.000209, Discriminator: 0.043396; Generator: 0.021718,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:43,740 root         INFO     Train Epoch: 148 [2560/8000 (32%)]\tTotal Loss: 0.442483\n",
      "Reconstruction: 0.377198, Regularization: 0.000177, Discriminator: 0.043352; Generator: 0.021755,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 00:59:43,852 root         INFO     Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 0.445353\n",
      "Reconstruction: 0.380127, Regularization: 0.000182, Discriminator: 0.043356; Generator: 0.021689,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:43,965 root         INFO     Train Epoch: 148 [3584/8000 (45%)]\tTotal Loss: 0.445258\n",
      "Reconstruction: 0.379967, Regularization: 0.000186, Discriminator: 0.043366; Generator: 0.021739,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:44,078 root         INFO     Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 0.445546\n",
      "Reconstruction: 0.380332, Regularization: 0.000182, Discriminator: 0.043320; Generator: 0.021712,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:44,188 root         INFO     Train Epoch: 148 [4608/8000 (58%)]\tTotal Loss: 0.446016\n",
      "Reconstruction: 0.380823, Regularization: 0.000179, Discriminator: 0.043330; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:44,297 root         INFO     Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 0.447020\n",
      "Reconstruction: 0.381833, Regularization: 0.000182, Discriminator: 0.043320; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:44,407 root         INFO     Train Epoch: 148 [5632/8000 (70%)]\tTotal Loss: 0.446846\n",
      "Reconstruction: 0.381605, Regularization: 0.000195, Discriminator: 0.043301; Generator: 0.021744,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:44,517 root         INFO     Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 0.446879\n",
      "Reconstruction: 0.381670, Regularization: 0.000191, Discriminator: 0.043304; Generator: 0.021714,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:44,627 root         INFO     Train Epoch: 148 [6656/8000 (83%)]\tTotal Loss: 0.444369\n",
      "Reconstruction: 0.379168, Regularization: 0.000189, Discriminator: 0.043313; Generator: 0.021699,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:44,736 root         INFO     Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 0.443176\n",
      "Reconstruction: 0.377864, Regularization: 0.000166, Discriminator: 0.043468; Generator: 0.021678,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-10 00:59:44,845 root         INFO     Train Epoch: 148 [7680/8000 (96%)]\tTotal Loss: 0.441478\n",
      "Reconstruction: 0.376389, Regularization: 0.000159, Discriminator: 0.043269; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:44,926 root         INFO     ====> Epoch: 148 Average loss: 0.4427\n",
      "2019-04-10 00:59:44,953 root         INFO     Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 0.440653\n",
      "Reconstruction: 0.375492, Regularization: 0.000153, Discriminator: 0.043336; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:45,064 root         INFO     Train Epoch: 149 [512/8000 (6%)]\tTotal Loss: 0.438128\n",
      "Reconstruction: 0.373025, Regularization: 0.000143, Discriminator: 0.043289; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:45,174 root         INFO     Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 0.437910\n",
      "Reconstruction: 0.372791, Regularization: 0.000139, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:45,284 root         INFO     Train Epoch: 149 [1536/8000 (19%)]\tTotal Loss: 0.438078\n",
      "Reconstruction: 0.372969, Regularization: 0.000149, Discriminator: 0.043310; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:45,395 root         INFO     Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 0.436504\n",
      "Reconstruction: 0.371351, Regularization: 0.000146, Discriminator: 0.043354; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:45,505 root         INFO     Train Epoch: 149 [2560/8000 (32%)]\tTotal Loss: 0.435927\n",
      "Reconstruction: 0.370826, Regularization: 0.000142, Discriminator: 0.043331; Generator: 0.021628,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:45,615 root         INFO     Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 0.435499\n",
      "Reconstruction: 0.370442, Regularization: 0.000133, Discriminator: 0.043310; Generator: 0.021613,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:45,726 root         INFO     Train Epoch: 149 [3584/8000 (45%)]\tTotal Loss: 0.434810\n",
      "Reconstruction: 0.369703, Regularization: 0.000144, Discriminator: 0.043336; Generator: 0.021628,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:45,838 root         INFO     Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 0.436092\n",
      "Reconstruction: 0.370970, Regularization: 0.000136, Discriminator: 0.043309; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:45,948 root         INFO     Train Epoch: 149 [4608/8000 (58%)]\tTotal Loss: 0.436392\n",
      "Reconstruction: 0.371237, Regularization: 0.000142, Discriminator: 0.043326; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:46,059 root         INFO     Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 0.437455\n",
      "Reconstruction: 0.372382, Regularization: 0.000137, Discriminator: 0.043334; Generator: 0.021601,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:46,170 root         INFO     Train Epoch: 149 [5632/8000 (70%)]\tTotal Loss: 0.436993\n",
      "Reconstruction: 0.371895, Regularization: 0.000137, Discriminator: 0.043330; Generator: 0.021631,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:46,281 root         INFO     Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 0.437011\n",
      "Reconstruction: 0.371904, Regularization: 0.000143, Discriminator: 0.043320; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:46,392 root         INFO     Train Epoch: 149 [6656/8000 (83%)]\tTotal Loss: 0.437515\n",
      "Reconstruction: 0.372443, Regularization: 0.000144, Discriminator: 0.043321; Generator: 0.021607,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:46,503 root         INFO     Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 0.437026\n",
      "Reconstruction: 0.371919, Regularization: 0.000142, Discriminator: 0.043303; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:46,614 root         INFO     Train Epoch: 149 [7680/8000 (96%)]\tTotal Loss: 0.437003\n",
      "Reconstruction: 0.371948, Regularization: 0.000140, Discriminator: 0.043285; Generator: 0.021630,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:46,695 root         INFO     ====> Epoch: 149 Average loss: 0.4371\n",
      "2019-04-10 00:59:46,723 root         INFO     Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 0.436769\n",
      "Reconstruction: 0.371630, Regularization: 0.000140, Discriminator: 0.043322; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:46,834 root         INFO     Train Epoch: 150 [512/8000 (6%)]\tTotal Loss: 0.437630\n",
      "Reconstruction: 0.372509, Regularization: 0.000130, Discriminator: 0.043338; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:46,945 root         INFO     Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 0.436905\n",
      "Reconstruction: 0.371824, Regularization: 0.000137, Discriminator: 0.043325; Generator: 0.021619,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:47,056 root         INFO     Train Epoch: 150 [1536/8000 (19%)]\tTotal Loss: 0.437576\n",
      "Reconstruction: 0.372428, Regularization: 0.000141, Discriminator: 0.043336; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:47,166 root         INFO     Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 0.437294\n",
      "Reconstruction: 0.372194, Regularization: 0.000138, Discriminator: 0.043330; Generator: 0.021632,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:47,277 root         INFO     Train Epoch: 150 [2560/8000 (32%)]\tTotal Loss: 0.437856\n",
      "Reconstruction: 0.372765, Regularization: 0.000143, Discriminator: 0.043324; Generator: 0.021624,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:47,389 root         INFO     Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 0.437154\n",
      "Reconstruction: 0.372003, Regularization: 0.000139, Discriminator: 0.043345; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:47,499 root         INFO     Train Epoch: 150 [3584/8000 (45%)]\tTotal Loss: 0.437456\n",
      "Reconstruction: 0.372259, Regularization: 0.000145, Discriminator: 0.043317; Generator: 0.021735,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:47,610 root         INFO     Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 0.438160\n",
      "Reconstruction: 0.372972, Regularization: 0.000143, Discriminator: 0.043356; Generator: 0.021689,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:47,720 root         INFO     Train Epoch: 150 [4608/8000 (58%)]\tTotal Loss: 0.439499\n",
      "Reconstruction: 0.374348, Regularization: 0.000137, Discriminator: 0.043318; Generator: 0.021695,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:47,832 root         INFO     Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 0.440313\n",
      "Reconstruction: 0.375269, Regularization: 0.000132, Discriminator: 0.043254; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:47,940 root         INFO     Train Epoch: 150 [5632/8000 (70%)]\tTotal Loss: 0.441990\n",
      "Reconstruction: 0.376818, Regularization: 0.000145, Discriminator: 0.043331; Generator: 0.021696,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:48,049 root         INFO     Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 0.442762\n",
      "Reconstruction: 0.377628, Regularization: 0.000137, Discriminator: 0.043294; Generator: 0.021703,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:48,158 root         INFO     Train Epoch: 150 [6656/8000 (83%)]\tTotal Loss: 0.445111\n",
      "Reconstruction: 0.379903, Regularization: 0.000139, Discriminator: 0.043345; Generator: 0.021724,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:48,268 root         INFO     Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 0.445242\n",
      "Reconstruction: 0.380142, Regularization: 0.000134, Discriminator: 0.043321; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:48,377 root         INFO     Train Epoch: 150 [7680/8000 (96%)]\tTotal Loss: 0.445289\n",
      "Reconstruction: 0.380153, Regularization: 0.000132, Discriminator: 0.043326; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:48,458 root         INFO     ====> Epoch: 150 Average loss: 0.4399\n",
      "2019-04-10 00:59:48,485 root         INFO     Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 0.445511\n",
      "Reconstruction: 0.380371, Regularization: 0.000151, Discriminator: 0.043332; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:48,597 root         INFO     Train Epoch: 151 [512/8000 (6%)]\tTotal Loss: 0.445680\n",
      "Reconstruction: 0.380474, Regularization: 0.000136, Discriminator: 0.043348; Generator: 0.021722,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:48,708 root         INFO     Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 0.443866\n",
      "Reconstruction: 0.378745, Regularization: 0.000139, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:48,820 root         INFO     Train Epoch: 151 [1536/8000 (19%)]\tTotal Loss: 0.443350\n",
      "Reconstruction: 0.378224, Regularization: 0.000143, Discriminator: 0.043314; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:48,931 root         INFO     Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 0.442241\n",
      "Reconstruction: 0.377176, Regularization: 0.000149, Discriminator: 0.043262; Generator: 0.021655,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:49,041 root         INFO     Train Epoch: 151 [2560/8000 (32%)]\tTotal Loss: 0.439436\n",
      "Reconstruction: 0.374421, Regularization: 0.000155, Discriminator: 0.043223; Generator: 0.021637,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-10 00:59:49,152 root         INFO     Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 0.437832\n",
      "Reconstruction: 0.372722, Regularization: 0.000136, Discriminator: 0.043329; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:49,263 root         INFO     Train Epoch: 151 [3584/8000 (45%)]\tTotal Loss: 0.436447\n",
      "Reconstruction: 0.371337, Regularization: 0.000121, Discriminator: 0.043349; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:49,373 root         INFO     Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 0.434158\n",
      "Reconstruction: 0.368994, Regularization: 0.000162, Discriminator: 0.043319; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:49,483 root         INFO     Train Epoch: 151 [4608/8000 (58%)]\tTotal Loss: 0.433255\n",
      "Reconstruction: 0.368164, Regularization: 0.000151, Discriminator: 0.043344; Generator: 0.021597,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:49,592 root         INFO     Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 0.433447\n",
      "Reconstruction: 0.368328, Regularization: 0.000141, Discriminator: 0.043324; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:49,704 root         INFO     Train Epoch: 151 [5632/8000 (70%)]\tTotal Loss: 0.431911\n",
      "Reconstruction: 0.366817, Regularization: 0.000133, Discriminator: 0.043322; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:49,814 root         INFO     Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 0.432515\n",
      "Reconstruction: 0.367406, Regularization: 0.000133, Discriminator: 0.043306; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:49,924 root         INFO     Train Epoch: 151 [6656/8000 (83%)]\tTotal Loss: 0.433059\n",
      "Reconstruction: 0.367989, Regularization: 0.000144, Discriminator: 0.043297; Generator: 0.021630,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:50,034 root         INFO     Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 0.434841\n",
      "Reconstruction: 0.369767, Regularization: 0.000132, Discriminator: 0.043277; Generator: 0.021665,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:50,144 root         INFO     Train Epoch: 151 [7680/8000 (96%)]\tTotal Loss: 0.435951\n",
      "Reconstruction: 0.370861, Regularization: 0.000147, Discriminator: 0.043346; Generator: 0.021597,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:50,225 root         INFO     ====> Epoch: 151 Average loss: 0.4373\n",
      "2019-04-10 00:59:50,252 root         INFO     Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 0.436982\n",
      "Reconstruction: 0.371827, Regularization: 0.000146, Discriminator: 0.043411; Generator: 0.021598,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:50,364 root         INFO     Train Epoch: 152 [512/8000 (6%)]\tTotal Loss: 0.438827\n",
      "Reconstruction: 0.373801, Regularization: 0.000130, Discriminator: 0.043284; Generator: 0.021614,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:50,478 root         INFO     Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 0.440677\n",
      "Reconstruction: 0.375631, Regularization: 0.000131, Discriminator: 0.043334; Generator: 0.021582,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:50,591 root         INFO     Train Epoch: 152 [1536/8000 (19%)]\tTotal Loss: 0.442624\n",
      "Reconstruction: 0.377430, Regularization: 0.000135, Discriminator: 0.043361; Generator: 0.021698,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:50,704 root         INFO     Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 0.444785\n",
      "Reconstruction: 0.379632, Regularization: 0.000131, Discriminator: 0.043347; Generator: 0.021676,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:50,816 root         INFO     Train Epoch: 152 [2560/8000 (32%)]\tTotal Loss: 0.445229\n",
      "Reconstruction: 0.380069, Regularization: 0.000118, Discriminator: 0.043356; Generator: 0.021686,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:50,928 root         INFO     Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 0.446383\n",
      "Reconstruction: 0.381225, Regularization: 0.000123, Discriminator: 0.043313; Generator: 0.021723,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:51,040 root         INFO     Train Epoch: 152 [3584/8000 (45%)]\tTotal Loss: 0.445006\n",
      "Reconstruction: 0.379883, Regularization: 0.000118, Discriminator: 0.043301; Generator: 0.021704,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:51,153 root         INFO     Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 0.443702\n",
      "Reconstruction: 0.378794, Regularization: 0.000118, Discriminator: 0.043139; Generator: 0.021651,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-10 00:59:51,265 root         INFO     Train Epoch: 152 [4608/8000 (58%)]\tTotal Loss: 0.442916\n",
      "Reconstruction: 0.377911, Regularization: 0.000129, Discriminator: 0.043208; Generator: 0.021669,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-10 00:59:51,377 root         INFO     Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 0.440461\n",
      "Reconstruction: 0.375315, Regularization: 0.000138, Discriminator: 0.043309; Generator: 0.021699,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:51,489 root         INFO     Train Epoch: 152 [5632/8000 (70%)]\tTotal Loss: 0.437357\n",
      "Reconstruction: 0.372152, Regularization: 0.000118, Discriminator: 0.043426; Generator: 0.021661,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 00:59:51,602 root         INFO     Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 0.436167\n",
      "Reconstruction: 0.371132, Regularization: 0.000106, Discriminator: 0.043268; Generator: 0.021662,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:51,714 root         INFO     Train Epoch: 152 [6656/8000 (83%)]\tTotal Loss: 0.434557\n",
      "Reconstruction: 0.369399, Regularization: 0.000112, Discriminator: 0.043356; Generator: 0.021690,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:51,825 root         INFO     Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 0.435003\n",
      "Reconstruction: 0.369895, Regularization: 0.000120, Discriminator: 0.043319; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:51,934 root         INFO     Train Epoch: 152 [7680/8000 (96%)]\tTotal Loss: 0.434896\n",
      "Reconstruction: 0.369814, Regularization: 0.000122, Discriminator: 0.043297; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:52,015 root         INFO     ====> Epoch: 152 Average loss: 0.4404\n",
      "2019-04-10 00:59:52,042 root         INFO     Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 0.434276\n",
      "Reconstruction: 0.369213, Regularization: 0.000112, Discriminator: 0.043317; Generator: 0.021633,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:52,154 root         INFO     Train Epoch: 153 [512/8000 (6%)]\tTotal Loss: 0.436709\n",
      "Reconstruction: 0.371678, Regularization: 0.000112, Discriminator: 0.043270; Generator: 0.021649,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:52,266 root         INFO     Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 0.437549\n",
      "Reconstruction: 0.372464, Regularization: 0.000121, Discriminator: 0.043357; Generator: 0.021608,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:52,378 root         INFO     Train Epoch: 153 [1536/8000 (19%)]\tTotal Loss: 0.438787\n",
      "Reconstruction: 0.373692, Regularization: 0.000111, Discriminator: 0.043328; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:52,490 root         INFO     Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 0.440111\n",
      "Reconstruction: 0.374934, Regularization: 0.000109, Discriminator: 0.043379; Generator: 0.021689,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:52,602 root         INFO     Train Epoch: 153 [2560/8000 (32%)]\tTotal Loss: 0.441941\n",
      "Reconstruction: 0.376818, Regularization: 0.000103, Discriminator: 0.043382; Generator: 0.021638,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:52,715 root         INFO     Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 0.442552\n",
      "Reconstruction: 0.377400, Regularization: 0.000102, Discriminator: 0.043359; Generator: 0.021691,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:52,826 root         INFO     Train Epoch: 153 [3584/8000 (45%)]\tTotal Loss: 0.443206\n",
      "Reconstruction: 0.378058, Regularization: 0.000097, Discriminator: 0.043351; Generator: 0.021700,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:52,938 root         INFO     Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 0.444286\n",
      "Reconstruction: 0.379198, Regularization: 0.000103, Discriminator: 0.043342; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:53,050 root         INFO     Train Epoch: 153 [4608/8000 (58%)]\tTotal Loss: 0.444006\n",
      "Reconstruction: 0.378924, Regularization: 0.000089, Discriminator: 0.043323; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:53,161 root         INFO     Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 0.443919\n",
      "Reconstruction: 0.378802, Regularization: 0.000098, Discriminator: 0.043297; Generator: 0.021722,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:53,273 root         INFO     Train Epoch: 153 [5632/8000 (70%)]\tTotal Loss: 0.442090\n",
      "Reconstruction: 0.377103, Regularization: 0.000093, Discriminator: 0.043260; Generator: 0.021634,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:53,385 root         INFO     Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 0.440812\n",
      "Reconstruction: 0.375665, Regularization: 0.000096, Discriminator: 0.043424; Generator: 0.021629,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-10 00:59:53,496 root         INFO     Train Epoch: 153 [6656/8000 (83%)]\tTotal Loss: 0.439567\n",
      "Reconstruction: 0.374579, Regularization: 0.000112, Discriminator: 0.043243; Generator: 0.021634,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-10 00:59:53,605 root         INFO     Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 0.436588\n",
      "Reconstruction: 0.371495, Regularization: 0.000108, Discriminator: 0.043349; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:53,716 root         INFO     Train Epoch: 153 [7680/8000 (96%)]\tTotal Loss: 0.435993\n",
      "Reconstruction: 0.370871, Regularization: 0.000116, Discriminator: 0.043336; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:53,796 root         INFO     ====> Epoch: 153 Average loss: 0.4402\n",
      "2019-04-10 00:59:53,823 root         INFO     Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 0.433706\n",
      "Reconstruction: 0.368672, Regularization: 0.000115, Discriminator: 0.043310; Generator: 0.021609,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:53,935 root         INFO     Train Epoch: 154 [512/8000 (6%)]\tTotal Loss: 0.433750\n",
      "Reconstruction: 0.368585, Regularization: 0.000110, Discriminator: 0.043392; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:54,048 root         INFO     Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 0.432997\n",
      "Reconstruction: 0.367932, Regularization: 0.000110, Discriminator: 0.043318; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:54,160 root         INFO     Train Epoch: 154 [1536/8000 (19%)]\tTotal Loss: 0.432421\n",
      "Reconstruction: 0.367340, Regularization: 0.000116, Discriminator: 0.043328; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:54,272 root         INFO     Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 0.434088\n",
      "Reconstruction: 0.368940, Regularization: 0.000124, Discriminator: 0.043338; Generator: 0.021686,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:54,384 root         INFO     Train Epoch: 154 [2560/8000 (32%)]\tTotal Loss: 0.434938\n",
      "Reconstruction: 0.369824, Regularization: 0.000113, Discriminator: 0.043334; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:54,496 root         INFO     Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 0.434588\n",
      "Reconstruction: 0.369542, Regularization: 0.000109, Discriminator: 0.043303; Generator: 0.021634,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:54,608 root         INFO     Train Epoch: 154 [3584/8000 (45%)]\tTotal Loss: 0.437264\n",
      "Reconstruction: 0.372286, Regularization: 0.000104, Discriminator: 0.043205; Generator: 0.021668,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-10 00:59:54,720 root         INFO     Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 0.439829\n",
      "Reconstruction: 0.374733, Regularization: 0.000115, Discriminator: 0.043358; Generator: 0.021623,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:54,833 root         INFO     Train Epoch: 154 [4608/8000 (58%)]\tTotal Loss: 0.441532\n",
      "Reconstruction: 0.376358, Regularization: 0.000138, Discriminator: 0.043328; Generator: 0.021708,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:54,945 root         INFO     Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 0.443070\n",
      "Reconstruction: 0.377966, Regularization: 0.000127, Discriminator: 0.043343; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:55,057 root         INFO     Train Epoch: 154 [5632/8000 (70%)]\tTotal Loss: 0.445433\n",
      "Reconstruction: 0.380297, Regularization: 0.000132, Discriminator: 0.043300; Generator: 0.021705,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:55,169 root         INFO     Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 0.446334\n",
      "Reconstruction: 0.381107, Regularization: 0.000139, Discriminator: 0.043371; Generator: 0.021717,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 00:59:55,281 root         INFO     Train Epoch: 154 [6656/8000 (83%)]\tTotal Loss: 0.447154\n",
      "Reconstruction: 0.381958, Regularization: 0.000131, Discriminator: 0.043373; Generator: 0.021693,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:55,393 root         INFO     Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 0.447034\n",
      "Reconstruction: 0.381898, Regularization: 0.000133, Discriminator: 0.043317; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:55,505 root         INFO     Train Epoch: 154 [7680/8000 (96%)]\tTotal Loss: 0.447819\n",
      "Reconstruction: 0.382681, Regularization: 0.000145, Discriminator: 0.043301; Generator: 0.021692,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:55,586 root         INFO     ====> Epoch: 154 Average loss: 0.4398\n",
      "2019-04-10 00:59:55,613 root         INFO     Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 0.446044\n",
      "Reconstruction: 0.380951, Regularization: 0.000138, Discriminator: 0.043244; Generator: 0.021710,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:55,726 root         INFO     Train Epoch: 155 [512/8000 (6%)]\tTotal Loss: 0.444392\n",
      "Reconstruction: 0.379416, Regularization: 0.000135, Discriminator: 0.043173; Generator: 0.021668,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-10 00:59:55,839 root         INFO     Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 0.442793\n",
      "Reconstruction: 0.377723, Regularization: 0.000124, Discriminator: 0.043279; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:55,951 root         INFO     Train Epoch: 155 [1536/8000 (19%)]\tTotal Loss: 0.439701\n",
      "Reconstruction: 0.374663, Regularization: 0.000120, Discriminator: 0.043280; Generator: 0.021638,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:56,063 root         INFO     Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 0.437679\n",
      "Reconstruction: 0.372607, Regularization: 0.000139, Discriminator: 0.043275; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:56,175 root         INFO     Train Epoch: 155 [2560/8000 (32%)]\tTotal Loss: 0.435519\n",
      "Reconstruction: 0.370391, Regularization: 0.000144, Discriminator: 0.043340; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:56,287 root         INFO     Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 0.434252\n",
      "Reconstruction: 0.369081, Regularization: 0.000141, Discriminator: 0.043371; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:56,398 root         INFO     Train Epoch: 155 [3584/8000 (45%)]\tTotal Loss: 0.432626\n",
      "Reconstruction: 0.367549, Regularization: 0.000144, Discriminator: 0.043335; Generator: 0.021598,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:56,511 root         INFO     Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 0.431888\n",
      "Reconstruction: 0.366777, Regularization: 0.000154, Discriminator: 0.043323; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:56,623 root         INFO     Train Epoch: 155 [4608/8000 (58%)]\tTotal Loss: 0.431686\n",
      "Reconstruction: 0.366606, Regularization: 0.000139, Discriminator: 0.043325; Generator: 0.021616,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:56,733 root         INFO     Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 0.432128\n",
      "Reconstruction: 0.367055, Regularization: 0.000140, Discriminator: 0.043319; Generator: 0.021613,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:56,845 root         INFO     Train Epoch: 155 [5632/8000 (70%)]\tTotal Loss: 0.431760\n",
      "Reconstruction: 0.366705, Regularization: 0.000128, Discriminator: 0.043307; Generator: 0.021620,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:56,956 root         INFO     Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 0.435125\n",
      "Reconstruction: 0.370091, Regularization: 0.000134, Discriminator: 0.043293; Generator: 0.021607,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 00:59:57,066 root         INFO     Train Epoch: 155 [6656/8000 (83%)]\tTotal Loss: 0.435828\n",
      "Reconstruction: 0.370657, Regularization: 0.000157, Discriminator: 0.043398; Generator: 0.021615,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:57,177 root         INFO     Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 0.437207\n",
      "Reconstruction: 0.372044, Regularization: 0.000149, Discriminator: 0.043320; Generator: 0.021694,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:57,287 root         INFO     Train Epoch: 155 [7680/8000 (96%)]\tTotal Loss: 0.438595\n",
      "Reconstruction: 0.373477, Regularization: 0.000133, Discriminator: 0.043314; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:57,368 root         INFO     ====> Epoch: 155 Average loss: 0.4366\n",
      "2019-04-10 00:59:57,395 root         INFO     Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 0.438799\n",
      "Reconstruction: 0.373623, Regularization: 0.000127, Discriminator: 0.043374; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:57,508 root         INFO     Train Epoch: 156 [512/8000 (6%)]\tTotal Loss: 0.440550\n",
      "Reconstruction: 0.375493, Regularization: 0.000132, Discriminator: 0.043282; Generator: 0.021643,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:57,620 root         INFO     Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 0.442814\n",
      "Reconstruction: 0.377729, Regularization: 0.000124, Discriminator: 0.043284; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:57,731 root         INFO     Train Epoch: 156 [1536/8000 (19%)]\tTotal Loss: 0.443468\n",
      "Reconstruction: 0.378302, Regularization: 0.000108, Discriminator: 0.043353; Generator: 0.021705,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:57,841 root         INFO     Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 0.444500\n",
      "Reconstruction: 0.379382, Regularization: 0.000112, Discriminator: 0.043318; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:57,952 root         INFO     Train Epoch: 156 [2560/8000 (32%)]\tTotal Loss: 0.444904\n",
      "Reconstruction: 0.379790, Regularization: 0.000110, Discriminator: 0.043316; Generator: 0.021688,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:58,063 root         INFO     Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 0.445178\n",
      "Reconstruction: 0.380040, Regularization: 0.000111, Discriminator: 0.043327; Generator: 0.021700,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 00:59:58,175 root         INFO     Train Epoch: 156 [3584/8000 (45%)]\tTotal Loss: 0.444462\n",
      "Reconstruction: 0.379396, Regularization: 0.000105, Discriminator: 0.043277; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:58,288 root         INFO     Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 0.443494\n",
      "Reconstruction: 0.378413, Regularization: 0.000100, Discriminator: 0.043288; Generator: 0.021693,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:58,401 root         INFO     Train Epoch: 156 [4608/8000 (58%)]\tTotal Loss: 0.441508\n",
      "Reconstruction: 0.376417, Regularization: 0.000098, Discriminator: 0.043285; Generator: 0.021707,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:58,514 root         INFO     Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 0.439679\n",
      "Reconstruction: 0.374568, Regularization: 0.000101, Discriminator: 0.043338; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:58,627 root         INFO     Train Epoch: 156 [5632/8000 (70%)]\tTotal Loss: 0.438725\n",
      "Reconstruction: 0.373658, Regularization: 0.000110, Discriminator: 0.043289; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:58,740 root         INFO     Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 0.436442\n",
      "Reconstruction: 0.371295, Regularization: 0.000117, Discriminator: 0.043350; Generator: 0.021680,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:58,852 root         INFO     Train Epoch: 156 [6656/8000 (83%)]\tTotal Loss: 0.435810\n",
      "Reconstruction: 0.370671, Regularization: 0.000119, Discriminator: 0.043345; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 00:59:58,965 root         INFO     Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 0.435969\n",
      "Reconstruction: 0.370893, Regularization: 0.000118, Discriminator: 0.043326; Generator: 0.021632,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:59,079 root         INFO     Train Epoch: 156 [7680/8000 (96%)]\tTotal Loss: 0.435613\n",
      "Reconstruction: 0.370531, Regularization: 0.000110, Discriminator: 0.043318; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:59,160 root         INFO     ====> Epoch: 156 Average loss: 0.4409\n",
      "2019-04-10 00:59:59,188 root         INFO     Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 0.435352\n",
      "Reconstruction: 0.370281, Regularization: 0.000115, Discriminator: 0.043318; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:59,299 root         INFO     Train Epoch: 157 [512/8000 (6%)]\tTotal Loss: 0.436263\n",
      "Reconstruction: 0.371154, Regularization: 0.000114, Discriminator: 0.043299; Generator: 0.021696,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 00:59:59,409 root         INFO     Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 0.436866\n",
      "Reconstruction: 0.371758, Regularization: 0.000121, Discriminator: 0.043335; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:59,519 root         INFO     Train Epoch: 157 [1536/8000 (19%)]\tTotal Loss: 0.435193\n",
      "Reconstruction: 0.370146, Regularization: 0.000113, Discriminator: 0.043296; Generator: 0.021637,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 00:59:59,628 root         INFO     Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 0.437297\n",
      "Reconstruction: 0.372217, Regularization: 0.000118, Discriminator: 0.043297; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:59,738 root         INFO     Train Epoch: 157 [2560/8000 (32%)]\tTotal Loss: 0.437127\n",
      "Reconstruction: 0.371996, Regularization: 0.000126, Discriminator: 0.043365; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 00:59:59,847 root         INFO     Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 0.438296\n",
      "Reconstruction: 0.373197, Regularization: 0.000115, Discriminator: 0.043363; Generator: 0.021622,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 00:59:59,958 root         INFO     Train Epoch: 157 [3584/8000 (45%)]\tTotal Loss: 0.438943\n",
      "Reconstruction: 0.373831, Regularization: 0.000120, Discriminator: 0.043357; Generator: 0.021635,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:00,069 root         INFO     Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 0.439388\n",
      "Reconstruction: 0.374347, Regularization: 0.000112, Discriminator: 0.043299; Generator: 0.021630,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:00,180 root         INFO     Train Epoch: 157 [4608/8000 (58%)]\tTotal Loss: 0.439992\n",
      "Reconstruction: 0.374894, Regularization: 0.000117, Discriminator: 0.043348; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:00,291 root         INFO     Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 0.439746\n",
      "Reconstruction: 0.374677, Regularization: 0.000124, Discriminator: 0.043308; Generator: 0.021637,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:00,402 root         INFO     Train Epoch: 157 [5632/8000 (70%)]\tTotal Loss: 0.440713\n",
      "Reconstruction: 0.375646, Regularization: 0.000118, Discriminator: 0.043299; Generator: 0.021650,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:00,514 root         INFO     Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 0.440481\n",
      "Reconstruction: 0.375441, Regularization: 0.000124, Discriminator: 0.043307; Generator: 0.021609,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:00,625 root         INFO     Train Epoch: 157 [6656/8000 (83%)]\tTotal Loss: 0.440204\n",
      "Reconstruction: 0.375101, Regularization: 0.000126, Discriminator: 0.043321; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:00,736 root         INFO     Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 0.442062\n",
      "Reconstruction: 0.376976, Regularization: 0.000123, Discriminator: 0.043308; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:00,847 root         INFO     Train Epoch: 157 [7680/8000 (96%)]\tTotal Loss: 0.442414\n",
      "Reconstruction: 0.377288, Regularization: 0.000127, Discriminator: 0.043295; Generator: 0.021705,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:00,927 root         INFO     ====> Epoch: 157 Average loss: 0.4388\n",
      "2019-04-10 01:00:00,955 root         INFO     Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 0.441688\n",
      "Reconstruction: 0.376571, Regularization: 0.000123, Discriminator: 0.043325; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:01,066 root         INFO     Train Epoch: 158 [512/8000 (6%)]\tTotal Loss: 0.440921\n",
      "Reconstruction: 0.375812, Regularization: 0.000135, Discriminator: 0.043335; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:01,177 root         INFO     Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 0.441112\n",
      "Reconstruction: 0.375977, Regularization: 0.000126, Discriminator: 0.043335; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:01,288 root         INFO     Train Epoch: 158 [1536/8000 (19%)]\tTotal Loss: 0.440551\n",
      "Reconstruction: 0.375370, Regularization: 0.000133, Discriminator: 0.043342; Generator: 0.021706,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:01,400 root         INFO     Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 0.441087\n",
      "Reconstruction: 0.375927, Regularization: 0.000122, Discriminator: 0.043333; Generator: 0.021706,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:01,512 root         INFO     Train Epoch: 158 [2560/8000 (32%)]\tTotal Loss: 0.440331\n",
      "Reconstruction: 0.375160, Regularization: 0.000127, Discriminator: 0.043330; Generator: 0.021713,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:01,623 root         INFO     Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 0.439160\n",
      "Reconstruction: 0.374025, Regularization: 0.000115, Discriminator: 0.043363; Generator: 0.021657,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:01,734 root         INFO     Train Epoch: 158 [3584/8000 (45%)]\tTotal Loss: 0.439183\n",
      "Reconstruction: 0.374028, Regularization: 0.000120, Discriminator: 0.043309; Generator: 0.021726,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:01,846 root         INFO     Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 0.439368\n",
      "Reconstruction: 0.374275, Regularization: 0.000117, Discriminator: 0.043313; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:01,961 root         INFO     Train Epoch: 158 [4608/8000 (58%)]\tTotal Loss: 0.438322\n",
      "Reconstruction: 0.373223, Regularization: 0.000117, Discriminator: 0.043311; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:02,076 root         INFO     Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 0.439585\n",
      "Reconstruction: 0.374507, Regularization: 0.000111, Discriminator: 0.043276; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:02,187 root         INFO     Train Epoch: 158 [5632/8000 (70%)]\tTotal Loss: 0.440537\n",
      "Reconstruction: 0.375486, Regularization: 0.000121, Discriminator: 0.043289; Generator: 0.021641,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:02,302 root         INFO     Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 0.441493\n",
      "Reconstruction: 0.376369, Regularization: 0.000114, Discriminator: 0.043301; Generator: 0.021709,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:02,415 root         INFO     Train Epoch: 158 [6656/8000 (83%)]\tTotal Loss: 0.440852\n",
      "Reconstruction: 0.375732, Regularization: 0.000113, Discriminator: 0.043340; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:02,525 root         INFO     Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 0.440893\n",
      "Reconstruction: 0.375760, Regularization: 0.000125, Discriminator: 0.043338; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:02,635 root         INFO     Train Epoch: 158 [7680/8000 (96%)]\tTotal Loss: 0.440643\n",
      "Reconstruction: 0.375559, Regularization: 0.000124, Discriminator: 0.043341; Generator: 0.021618,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:02,715 root         INFO     ====> Epoch: 158 Average loss: 0.4403\n",
      "2019-04-10 01:00:02,743 root         INFO     Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 0.440763\n",
      "Reconstruction: 0.375622, Regularization: 0.000120, Discriminator: 0.043335; Generator: 0.021687,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:02,856 root         INFO     Train Epoch: 159 [512/8000 (6%)]\tTotal Loss: 0.440467\n",
      "Reconstruction: 0.375395, Regularization: 0.000119, Discriminator: 0.043315; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:02,969 root         INFO     Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 0.439771\n",
      "Reconstruction: 0.374711, Regularization: 0.000115, Discriminator: 0.043318; Generator: 0.021628,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:03,082 root         INFO     Train Epoch: 159 [1536/8000 (19%)]\tTotal Loss: 0.439190\n",
      "Reconstruction: 0.374155, Regularization: 0.000130, Discriminator: 0.043304; Generator: 0.021601,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:03,195 root         INFO     Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 0.437800\n",
      "Reconstruction: 0.372755, Regularization: 0.000132, Discriminator: 0.043307; Generator: 0.021606,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:03,306 root         INFO     Train Epoch: 159 [2560/8000 (32%)]\tTotal Loss: 0.436930\n",
      "Reconstruction: 0.371904, Regularization: 0.000122, Discriminator: 0.043278; Generator: 0.021626,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:03,419 root         INFO     Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 0.435628\n",
      "Reconstruction: 0.370555, Regularization: 0.000115, Discriminator: 0.043329; Generator: 0.021629,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:03,534 root         INFO     Train Epoch: 159 [3584/8000 (45%)]\tTotal Loss: 0.435139\n",
      "Reconstruction: 0.370078, Regularization: 0.000104, Discriminator: 0.043296; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:03,646 root         INFO     Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 0.433857\n",
      "Reconstruction: 0.368744, Regularization: 0.000110, Discriminator: 0.043379; Generator: 0.021623,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:03,762 root         INFO     Train Epoch: 159 [4608/8000 (58%)]\tTotal Loss: 0.432178\n",
      "Reconstruction: 0.367109, Regularization: 0.000110, Discriminator: 0.043332; Generator: 0.021628,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:03,874 root         INFO     Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 0.432872\n",
      "Reconstruction: 0.367738, Regularization: 0.000116, Discriminator: 0.043339; Generator: 0.021679,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:03,989 root         INFO     Train Epoch: 159 [5632/8000 (70%)]\tTotal Loss: 0.432840\n",
      "Reconstruction: 0.367805, Regularization: 0.000112, Discriminator: 0.043307; Generator: 0.021616,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:04,106 root         INFO     Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 0.433759\n",
      "Reconstruction: 0.368726, Regularization: 0.000108, Discriminator: 0.043279; Generator: 0.021646,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:04,220 root         INFO     Train Epoch: 159 [6656/8000 (83%)]\tTotal Loss: 0.435257\n",
      "Reconstruction: 0.370123, Regularization: 0.000129, Discriminator: 0.043351; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:04,333 root         INFO     Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 0.437412\n",
      "Reconstruction: 0.372321, Regularization: 0.000143, Discriminator: 0.043267; Generator: 0.021681,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:04,445 root         INFO     Train Epoch: 159 [7680/8000 (96%)]\tTotal Loss: 0.438851\n",
      "Reconstruction: 0.373856, Regularization: 0.000112, Discriminator: 0.043213; Generator: 0.021669,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-10 01:00:04,527 root         INFO     ====> Epoch: 159 Average loss: 0.4362\n",
      "2019-04-10 01:00:04,553 root         INFO     Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 0.441364\n",
      "Reconstruction: 0.376129, Regularization: 0.000131, Discriminator: 0.043421; Generator: 0.021683,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 01:00:04,667 root         INFO     Train Epoch: 160 [512/8000 (6%)]\tTotal Loss: 0.443045\n",
      "Reconstruction: 0.377890, Regularization: 0.000088, Discriminator: 0.043362; Generator: 0.021705,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:04,780 root         INFO     Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 0.444727\n",
      "Reconstruction: 0.379575, Regularization: 0.000068, Discriminator: 0.043361; Generator: 0.021722,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:04,893 root         INFO     Train Epoch: 160 [1536/8000 (19%)]\tTotal Loss: 0.447157\n",
      "Reconstruction: 0.382008, Regularization: 0.000077, Discriminator: 0.043330; Generator: 0.021743,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:05,006 root         INFO     Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 0.447811\n",
      "Reconstruction: 0.382727, Regularization: 0.000066, Discriminator: 0.043344; Generator: 0.021674,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:05,120 root         INFO     Train Epoch: 160 [2560/8000 (32%)]\tTotal Loss: 0.448897\n",
      "Reconstruction: 0.383766, Regularization: 0.000060, Discriminator: 0.043344; Generator: 0.021727,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:05,235 root         INFO     Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 0.449313\n",
      "Reconstruction: 0.384236, Regularization: 0.000062, Discriminator: 0.043314; Generator: 0.021701,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:05,349 root         INFO     Train Epoch: 160 [3584/8000 (45%)]\tTotal Loss: 0.448201\n",
      "Reconstruction: 0.383134, Regularization: 0.000057, Discriminator: 0.043306; Generator: 0.021703,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:05,463 root         INFO     Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 0.447699\n",
      "Reconstruction: 0.382661, Regularization: 0.000058, Discriminator: 0.043284; Generator: 0.021695,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:05,578 root         INFO     Train Epoch: 160 [4608/8000 (58%)]\tTotal Loss: 0.445560\n",
      "Reconstruction: 0.380479, Regularization: 0.000059, Discriminator: 0.043341; Generator: 0.021681,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:05,692 root         INFO     Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 0.444096\n",
      "Reconstruction: 0.378988, Regularization: 0.000045, Discriminator: 0.043387; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:05,811 root         INFO     Train Epoch: 160 [5632/8000 (70%)]\tTotal Loss: 0.441211\n",
      "Reconstruction: 0.376193, Regularization: 0.000051, Discriminator: 0.043316; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:05,935 root         INFO     Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 0.439012\n",
      "Reconstruction: 0.373934, Regularization: 0.000033, Discriminator: 0.043378; Generator: 0.021666,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:06,050 root         INFO     Train Epoch: 160 [6656/8000 (83%)]\tTotal Loss: 0.436312\n",
      "Reconstruction: 0.371227, Regularization: 0.000024, Discriminator: 0.043398; Generator: 0.021664,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:06,164 root         INFO     Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 0.433916\n",
      "Reconstruction: 0.368760, Regularization: 0.000019, Discriminator: 0.043451; Generator: 0.021686,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 01:00:06,278 root         INFO     Train Epoch: 160 [7680/8000 (96%)]\tTotal Loss: 0.431991\n",
      "Reconstruction: 0.366930, Regularization: 0.000024, Discriminator: 0.043398; Generator: 0.021639,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:06,360 root         INFO     ====> Epoch: 160 Average loss: 0.4432\n",
      "2019-04-10 01:00:06,388 root         INFO     Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 0.431396\n",
      "Reconstruction: 0.366329, Regularization: 0.000019, Discriminator: 0.043388; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:06,506 root         INFO     Train Epoch: 161 [512/8000 (6%)]\tTotal Loss: 0.430493\n",
      "Reconstruction: 0.365530, Regularization: 0.000028, Discriminator: 0.043311; Generator: 0.021623,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:06,623 root         INFO     Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 0.430146\n",
      "Reconstruction: 0.365131, Regularization: 0.000022, Discriminator: 0.043318; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:06,741 root         INFO     Train Epoch: 161 [1536/8000 (19%)]\tTotal Loss: 0.430521\n",
      "Reconstruction: 0.365590, Regularization: 0.000020, Discriminator: 0.043303; Generator: 0.021608,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:06,859 root         INFO     Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 0.431591\n",
      "Reconstruction: 0.366653, Regularization: 0.000015, Discriminator: 0.043286; Generator: 0.021637,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:06,973 root         INFO     Train Epoch: 161 [2560/8000 (32%)]\tTotal Loss: 0.432723\n",
      "Reconstruction: 0.367746, Regularization: 0.000021, Discriminator: 0.043343; Generator: 0.021613,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:07,087 root         INFO     Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 0.434620\n",
      "Reconstruction: 0.369704, Regularization: 0.000018, Discriminator: 0.043291; Generator: 0.021607,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:07,202 root         INFO     Train Epoch: 161 [3584/8000 (45%)]\tTotal Loss: 0.436348\n",
      "Reconstruction: 0.371470, Regularization: 0.000014, Discriminator: 0.043282; Generator: 0.021581,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:07,313 root         INFO     Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 0.438336\n",
      "Reconstruction: 0.373405, Regularization: 0.000017, Discriminator: 0.043268; Generator: 0.021645,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:07,422 root         INFO     Train Epoch: 161 [4608/8000 (58%)]\tTotal Loss: 0.440334\n",
      "Reconstruction: 0.375260, Regularization: 0.000012, Discriminator: 0.043405; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:07,531 root         INFO     Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 0.442153\n",
      "Reconstruction: 0.377123, Regularization: 0.000012, Discriminator: 0.043390; Generator: 0.021629,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-10 01:00:07,640 root         INFO     Train Epoch: 161 [5632/8000 (70%)]\tTotal Loss: 0.443494\n",
      "Reconstruction: 0.378487, Regularization: 0.000014, Discriminator: 0.043353; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:07,748 root         INFO     Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 0.444616\n",
      "Reconstruction: 0.379588, Regularization: 0.000012, Discriminator: 0.043355; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:07,857 root         INFO     Train Epoch: 161 [6656/8000 (83%)]\tTotal Loss: 0.445186\n",
      "Reconstruction: 0.380209, Regularization: 0.000015, Discriminator: 0.043326; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:07,966 root         INFO     Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 0.445674\n",
      "Reconstruction: 0.380715, Regularization: 0.000015, Discriminator: 0.043275; Generator: 0.021669,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:08,075 root         INFO     Train Epoch: 161 [7680/8000 (96%)]\tTotal Loss: 0.445036\n",
      "Reconstruction: 0.380046, Regularization: 0.000013, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:08,155 root         INFO     ====> Epoch: 161 Average loss: 0.4379\n",
      "2019-04-10 01:00:08,183 root         INFO     Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 0.444665\n",
      "Reconstruction: 0.379612, Regularization: 0.000012, Discriminator: 0.043356; Generator: 0.021684,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:08,295 root         INFO     Train Epoch: 162 [512/8000 (6%)]\tTotal Loss: 0.443532\n",
      "Reconstruction: 0.378350, Regularization: 0.000020, Discriminator: 0.043448; Generator: 0.021714,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-10 01:00:08,405 root         INFO     Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 0.442136\n",
      "Reconstruction: 0.377046, Regularization: 0.000016, Discriminator: 0.043355; Generator: 0.021719,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:08,514 root         INFO     Train Epoch: 162 [1536/8000 (19%)]\tTotal Loss: 0.440820\n",
      "Reconstruction: 0.375668, Regularization: 0.000016, Discriminator: 0.043401; Generator: 0.021735,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:08,621 root         INFO     Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 0.439494\n",
      "Reconstruction: 0.374432, Regularization: 0.000023, Discriminator: 0.043305; Generator: 0.021734,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:08,728 root         INFO     Train Epoch: 162 [2560/8000 (32%)]\tTotal Loss: 0.438412\n",
      "Reconstruction: 0.373245, Regularization: 0.000022, Discriminator: 0.043420; Generator: 0.021724,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-10 01:00:08,836 root         INFO     Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 0.437016\n",
      "Reconstruction: 0.371984, Regularization: 0.000019, Discriminator: 0.043317; Generator: 0.021696,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:08,945 root         INFO     Train Epoch: 162 [3584/8000 (45%)]\tTotal Loss: 0.436584\n",
      "Reconstruction: 0.371502, Regularization: 0.000013, Discriminator: 0.043323; Generator: 0.021747,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:09,052 root         INFO     Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 0.436391\n",
      "Reconstruction: 0.371426, Regularization: 0.000015, Discriminator: 0.043278; Generator: 0.021671,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:09,160 root         INFO     Train Epoch: 162 [4608/8000 (58%)]\tTotal Loss: 0.436188\n",
      "Reconstruction: 0.371331, Regularization: 0.000019, Discriminator: 0.043216; Generator: 0.021622,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:09,268 root         INFO     Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 0.436784\n",
      "Reconstruction: 0.371860, Regularization: 0.000015, Discriminator: 0.043297; Generator: 0.021612,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:09,376 root         INFO     Train Epoch: 162 [5632/8000 (70%)]\tTotal Loss: 0.437708\n",
      "Reconstruction: 0.372827, Regularization: 0.000014, Discriminator: 0.043166; Generator: 0.021701,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-10 01:00:09,484 root         INFO     Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 0.438955\n",
      "Reconstruction: 0.373961, Regularization: 0.000014, Discriminator: 0.043330; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:09,592 root         INFO     Train Epoch: 162 [6656/8000 (83%)]\tTotal Loss: 0.440419\n",
      "Reconstruction: 0.375389, Regularization: 0.000017, Discriminator: 0.043316; Generator: 0.021697,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:09,701 root         INFO     Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 0.441459\n",
      "Reconstruction: 0.376324, Regularization: 0.000013, Discriminator: 0.043442; Generator: 0.021680,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 01:00:09,809 root         INFO     Train Epoch: 162 [7680/8000 (96%)]\tTotal Loss: 0.442684\n",
      "Reconstruction: 0.377645, Regularization: 0.000011, Discriminator: 0.043334; Generator: 0.021694,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:09,889 root         INFO     ====> Epoch: 162 Average loss: 0.4394\n",
      "2019-04-10 01:00:09,916 root         INFO     Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 0.443178\n",
      "Reconstruction: 0.378038, Regularization: 0.000013, Discriminator: 0.043408; Generator: 0.021720,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:10,028 root         INFO     Train Epoch: 163 [512/8000 (6%)]\tTotal Loss: 0.443582\n",
      "Reconstruction: 0.378469, Regularization: 0.000014, Discriminator: 0.043381; Generator: 0.021718,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:10,139 root         INFO     Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 0.443566\n",
      "Reconstruction: 0.378551, Regularization: 0.000010, Discriminator: 0.043345; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:10,250 root         INFO     Train Epoch: 163 [1536/8000 (19%)]\tTotal Loss: 0.443222\n",
      "Reconstruction: 0.378199, Regularization: 0.000011, Discriminator: 0.043338; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:10,360 root         INFO     Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 0.441924\n",
      "Reconstruction: 0.377000, Regularization: 0.000017, Discriminator: 0.043267; Generator: 0.021640,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:10,471 root         INFO     Train Epoch: 163 [2560/8000 (32%)]\tTotal Loss: 0.440305\n",
      "Reconstruction: 0.375437, Regularization: 0.000017, Discriminator: 0.043259; Generator: 0.021593,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:10,581 root         INFO     Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 0.438354\n",
      "Reconstruction: 0.373446, Regularization: 0.000016, Discriminator: 0.043268; Generator: 0.021625,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:10,691 root         INFO     Train Epoch: 163 [3584/8000 (45%)]\tTotal Loss: 0.436273\n",
      "Reconstruction: 0.371236, Regularization: 0.000027, Discriminator: 0.043396; Generator: 0.021615,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:10,802 root         INFO     Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 0.434480\n",
      "Reconstruction: 0.369576, Regularization: 0.000026, Discriminator: 0.043310; Generator: 0.021567,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:10,912 root         INFO     Train Epoch: 163 [4608/8000 (58%)]\tTotal Loss: 0.432725\n",
      "Reconstruction: 0.367713, Regularization: 0.000027, Discriminator: 0.043365; Generator: 0.021620,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:11,024 root         INFO     Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 0.431899\n",
      "Reconstruction: 0.366867, Regularization: 0.000023, Discriminator: 0.043374; Generator: 0.021635,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:11,136 root         INFO     Train Epoch: 163 [5632/8000 (70%)]\tTotal Loss: 0.431515\n",
      "Reconstruction: 0.366542, Regularization: 0.000026, Discriminator: 0.043316; Generator: 0.021632,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:11,248 root         INFO     Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 0.431780\n",
      "Reconstruction: 0.366772, Regularization: 0.000035, Discriminator: 0.043365; Generator: 0.021609,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:11,359 root         INFO     Train Epoch: 163 [6656/8000 (83%)]\tTotal Loss: 0.432196\n",
      "Reconstruction: 0.367250, Regularization: 0.000029, Discriminator: 0.043284; Generator: 0.021632,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:11,471 root         INFO     Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 0.433122\n",
      "Reconstruction: 0.368100, Regularization: 0.000022, Discriminator: 0.043314; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:11,583 root         INFO     Train Epoch: 163 [7680/8000 (96%)]\tTotal Loss: 0.434417\n",
      "Reconstruction: 0.369397, Regularization: 0.000028, Discriminator: 0.043337; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:11,664 root         INFO     ====> Epoch: 163 Average loss: 0.4368\n",
      "2019-04-10 01:00:11,691 root         INFO     Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 0.435181\n",
      "Reconstruction: 0.370193, Regularization: 0.000029, Discriminator: 0.043294; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:11,803 root         INFO     Train Epoch: 164 [512/8000 (6%)]\tTotal Loss: 0.436878\n",
      "Reconstruction: 0.371921, Regularization: 0.000033, Discriminator: 0.043277; Generator: 0.021647,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:11,914 root         INFO     Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 0.438727\n",
      "Reconstruction: 0.373674, Regularization: 0.000053, Discriminator: 0.043346; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:12,027 root         INFO     Train Epoch: 164 [1536/8000 (19%)]\tTotal Loss: 0.440945\n",
      "Reconstruction: 0.375825, Regularization: 0.000055, Discriminator: 0.043350; Generator: 0.021715,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:12,137 root         INFO     Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 0.442738\n",
      "Reconstruction: 0.377659, Regularization: 0.000061, Discriminator: 0.043353; Generator: 0.021666,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:12,248 root         INFO     Train Epoch: 164 [2560/8000 (32%)]\tTotal Loss: 0.444275\n",
      "Reconstruction: 0.379165, Regularization: 0.000049, Discriminator: 0.043322; Generator: 0.021738,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:12,359 root         INFO     Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 0.446438\n",
      "Reconstruction: 0.381318, Regularization: 0.000048, Discriminator: 0.043361; Generator: 0.021710,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:12,469 root         INFO     Train Epoch: 164 [3584/8000 (45%)]\tTotal Loss: 0.448696\n",
      "Reconstruction: 0.383489, Regularization: 0.000034, Discriminator: 0.043441; Generator: 0.021732,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-10 01:00:12,580 root         INFO     Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 0.449315\n",
      "Reconstruction: 0.384199, Regularization: 0.000031, Discriminator: 0.043315; Generator: 0.021771,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 01:00:12,691 root         INFO     Train Epoch: 164 [4608/8000 (58%)]\tTotal Loss: 0.450207\n",
      "Reconstruction: 0.385069, Regularization: 0.000033, Discriminator: 0.043342; Generator: 0.021762,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 01:00:12,801 root         INFO     Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 0.450442\n",
      "Reconstruction: 0.385368, Regularization: 0.000031, Discriminator: 0.043312; Generator: 0.021731,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:12,911 root         INFO     Train Epoch: 164 [5632/8000 (70%)]\tTotal Loss: 0.450349\n",
      "Reconstruction: 0.385298, Regularization: 0.000033, Discriminator: 0.043267; Generator: 0.021751,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:13,022 root         INFO     Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 0.449033\n",
      "Reconstruction: 0.384018, Regularization: 0.000029, Discriminator: 0.043263; Generator: 0.021723,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:13,131 root         INFO     Train Epoch: 164 [6656/8000 (83%)]\tTotal Loss: 0.447091\n",
      "Reconstruction: 0.382037, Regularization: 0.000020, Discriminator: 0.043322; Generator: 0.021711,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:13,241 root         INFO     Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 0.445418\n",
      "Reconstruction: 0.380382, Regularization: 0.000031, Discriminator: 0.043343; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:13,351 root         INFO     Train Epoch: 164 [7680/8000 (96%)]\tTotal Loss: 0.443134\n",
      "Reconstruction: 0.378121, Regularization: 0.000041, Discriminator: 0.043269; Generator: 0.021702,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:13,432 root         INFO     ====> Epoch: 164 Average loss: 0.4452\n",
      "2019-04-10 01:00:13,459 root         INFO     Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 0.442005\n",
      "Reconstruction: 0.376989, Regularization: 0.000037, Discriminator: 0.043310; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:13,570 root         INFO     Train Epoch: 165 [512/8000 (6%)]\tTotal Loss: 0.439241\n",
      "Reconstruction: 0.374332, Regularization: 0.000028, Discriminator: 0.043261; Generator: 0.021620,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:13,681 root         INFO     Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 0.436595\n",
      "Reconstruction: 0.371652, Regularization: 0.000023, Discriminator: 0.043249; Generator: 0.021670,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:13,791 root         INFO     Train Epoch: 165 [1536/8000 (19%)]\tTotal Loss: 0.434190\n",
      "Reconstruction: 0.369144, Regularization: 0.000020, Discriminator: 0.043395; Generator: 0.021632,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:13,901 root         INFO     Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 0.432115\n",
      "Reconstruction: 0.367108, Regularization: 0.000030, Discriminator: 0.043355; Generator: 0.021622,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:14,011 root         INFO     Train Epoch: 165 [2560/8000 (32%)]\tTotal Loss: 0.430663\n",
      "Reconstruction: 0.365585, Regularization: 0.000026, Discriminator: 0.043422; Generator: 0.021630,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:14,122 root         INFO     Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 0.429405\n",
      "Reconstruction: 0.364512, Regularization: 0.000031, Discriminator: 0.043277; Generator: 0.021584,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:14,232 root         INFO     Train Epoch: 165 [3584/8000 (45%)]\tTotal Loss: 0.428798\n",
      "Reconstruction: 0.363813, Regularization: 0.000024, Discriminator: 0.043354; Generator: 0.021606,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:14,343 root         INFO     Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 0.428274\n",
      "Reconstruction: 0.363331, Regularization: 0.000026, Discriminator: 0.043319; Generator: 0.021598,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:14,452 root         INFO     Train Epoch: 165 [4608/8000 (58%)]\tTotal Loss: 0.427995\n",
      "Reconstruction: 0.363089, Regularization: 0.000027, Discriminator: 0.043309; Generator: 0.021570,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:14,562 root         INFO     Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 0.429496\n",
      "Reconstruction: 0.364558, Regularization: 0.000026, Discriminator: 0.043334; Generator: 0.021578,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:14,671 root         INFO     Train Epoch: 165 [5632/8000 (70%)]\tTotal Loss: 0.430453\n",
      "Reconstruction: 0.365578, Regularization: 0.000023, Discriminator: 0.043263; Generator: 0.021589,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:14,779 root         INFO     Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 0.431998\n",
      "Reconstruction: 0.367009, Regularization: 0.000020, Discriminator: 0.043354; Generator: 0.021615,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:14,887 root         INFO     Train Epoch: 165 [6656/8000 (83%)]\tTotal Loss: 0.433087\n",
      "Reconstruction: 0.368212, Regularization: 0.000022, Discriminator: 0.043278; Generator: 0.021575,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:14,995 root         INFO     Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 0.434914\n",
      "Reconstruction: 0.369990, Regularization: 0.000024, Discriminator: 0.043310; Generator: 0.021591,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:15,105 root         INFO     Train Epoch: 165 [7680/8000 (96%)]\tTotal Loss: 0.436713\n",
      "Reconstruction: 0.371763, Regularization: 0.000026, Discriminator: 0.043335; Generator: 0.021588,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:15,186 root         INFO     ====> Epoch: 165 Average loss: 0.4326\n",
      "2019-04-10 01:00:15,213 root         INFO     Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 0.437888\n",
      "Reconstruction: 0.372920, Regularization: 0.000023, Discriminator: 0.043357; Generator: 0.021589,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:15,324 root         INFO     Train Epoch: 166 [512/8000 (6%)]\tTotal Loss: 0.439590\n",
      "Reconstruction: 0.374601, Regularization: 0.000021, Discriminator: 0.043337; Generator: 0.021631,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:15,436 root         INFO     Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 0.441258\n",
      "Reconstruction: 0.376352, Regularization: 0.000012, Discriminator: 0.043255; Generator: 0.021639,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:15,546 root         INFO     Train Epoch: 166 [1536/8000 (19%)]\tTotal Loss: 0.443259\n",
      "Reconstruction: 0.378077, Regularization: 0.000014, Discriminator: 0.043450; Generator: 0.021719,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-10 01:00:15,658 root         INFO     Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 0.444043\n",
      "Reconstruction: 0.379106, Regularization: 0.000017, Discriminator: 0.043310; Generator: 0.021611,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:15,769 root         INFO     Train Epoch: 166 [2560/8000 (32%)]\tTotal Loss: 0.445187\n",
      "Reconstruction: 0.380197, Regularization: 0.000010, Discriminator: 0.043298; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:15,879 root         INFO     Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 0.445811\n",
      "Reconstruction: 0.380820, Regularization: 0.000017, Discriminator: 0.043293; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:15,991 root         INFO     Train Epoch: 166 [3584/8000 (45%)]\tTotal Loss: 0.446090\n",
      "Reconstruction: 0.381082, Regularization: 0.000010, Discriminator: 0.043307; Generator: 0.021692,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:16,102 root         INFO     Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 0.446074\n",
      "Reconstruction: 0.381043, Regularization: 0.000011, Discriminator: 0.043303; Generator: 0.021717,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:16,213 root         INFO     Train Epoch: 166 [4608/8000 (58%)]\tTotal Loss: 0.445772\n",
      "Reconstruction: 0.380705, Regularization: 0.000008, Discriminator: 0.043340; Generator: 0.021719,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:16,324 root         INFO     Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 0.445174\n",
      "Reconstruction: 0.380087, Regularization: 0.000011, Discriminator: 0.043347; Generator: 0.021729,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:16,436 root         INFO     Train Epoch: 166 [5632/8000 (70%)]\tTotal Loss: 0.444656\n",
      "Reconstruction: 0.379631, Regularization: 0.000014, Discriminator: 0.043281; Generator: 0.021730,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:16,547 root         INFO     Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 0.443688\n",
      "Reconstruction: 0.378619, Regularization: 0.000011, Discriminator: 0.043361; Generator: 0.021698,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:16,659 root         INFO     Train Epoch: 166 [6656/8000 (83%)]\tTotal Loss: 0.442713\n",
      "Reconstruction: 0.377646, Regularization: 0.000018, Discriminator: 0.043319; Generator: 0.021731,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:16,771 root         INFO     Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 0.441965\n",
      "Reconstruction: 0.376908, Regularization: 0.000015, Discriminator: 0.043341; Generator: 0.021701,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:16,882 root         INFO     Train Epoch: 166 [7680/8000 (96%)]\tTotal Loss: 0.441200\n",
      "Reconstruction: 0.376083, Regularization: 0.000012, Discriminator: 0.043344; Generator: 0.021762,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 01:00:16,961 root         INFO     ====> Epoch: 166 Average loss: 0.4436\n",
      "2019-04-10 01:00:16,989 root         INFO     Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 0.440803\n",
      "Reconstruction: 0.375771, Regularization: 0.000016, Discriminator: 0.043304; Generator: 0.021712,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:17,099 root         INFO     Train Epoch: 167 [512/8000 (6%)]\tTotal Loss: 0.440156\n",
      "Reconstruction: 0.375101, Regularization: 0.000011, Discriminator: 0.043308; Generator: 0.021737,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:17,208 root         INFO     Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 0.439791\n",
      "Reconstruction: 0.374754, Regularization: 0.000010, Discriminator: 0.043307; Generator: 0.021721,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:17,319 root         INFO     Train Epoch: 167 [1536/8000 (19%)]\tTotal Loss: 0.439647\n",
      "Reconstruction: 0.374717, Regularization: 0.000014, Discriminator: 0.043269; Generator: 0.021647,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:17,427 root         INFO     Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 0.439725\n",
      "Reconstruction: 0.374766, Regularization: 0.000010, Discriminator: 0.043282; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:17,535 root         INFO     Train Epoch: 167 [2560/8000 (32%)]\tTotal Loss: 0.440100\n",
      "Reconstruction: 0.375205, Regularization: 0.000008, Discriminator: 0.043237; Generator: 0.021650,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-10 01:00:17,643 root         INFO     Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 0.440522\n",
      "Reconstruction: 0.375474, Regularization: 0.000012, Discriminator: 0.043336; Generator: 0.021699,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:17,751 root         INFO     Train Epoch: 167 [3584/8000 (45%)]\tTotal Loss: 0.440667\n",
      "Reconstruction: 0.375611, Regularization: 0.000007, Discriminator: 0.043338; Generator: 0.021710,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:17,859 root         INFO     Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 0.440852\n",
      "Reconstruction: 0.375810, Regularization: 0.000011, Discriminator: 0.043335; Generator: 0.021696,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:17,967 root         INFO     Train Epoch: 167 [4608/8000 (58%)]\tTotal Loss: 0.440476\n",
      "Reconstruction: 0.375474, Regularization: 0.000011, Discriminator: 0.043325; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:18,075 root         INFO     Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 0.440285\n",
      "Reconstruction: 0.375274, Regularization: 0.000011, Discriminator: 0.043353; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:18,182 root         INFO     Train Epoch: 167 [5632/8000 (70%)]\tTotal Loss: 0.439685\n",
      "Reconstruction: 0.374651, Regularization: 0.000012, Discriminator: 0.043359; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:18,290 root         INFO     Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 0.438422\n",
      "Reconstruction: 0.373441, Regularization: 0.000008, Discriminator: 0.043341; Generator: 0.021632,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:18,397 root         INFO     Train Epoch: 167 [6656/8000 (83%)]\tTotal Loss: 0.437011\n",
      "Reconstruction: 0.372084, Regularization: 0.000010, Discriminator: 0.043319; Generator: 0.021598,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:18,506 root         INFO     Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 0.435858\n",
      "Reconstruction: 0.370954, Regularization: 0.000005, Discriminator: 0.043303; Generator: 0.021596,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:18,612 root         INFO     Train Epoch: 167 [7680/8000 (96%)]\tTotal Loss: 0.434697\n",
      "Reconstruction: 0.369719, Regularization: 0.000008, Discriminator: 0.043383; Generator: 0.021586,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:18,691 root         INFO     ====> Epoch: 167 Average loss: 0.4392\n",
      "2019-04-10 01:00:18,718 root         INFO     Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 0.433946\n",
      "Reconstruction: 0.369048, Regularization: 0.000013, Discriminator: 0.043299; Generator: 0.021586,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:18,827 root         INFO     Train Epoch: 168 [512/8000 (6%)]\tTotal Loss: 0.433321\n",
      "Reconstruction: 0.368409, Regularization: 0.000012, Discriminator: 0.043357; Generator: 0.021543,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-10 01:00:18,935 root         INFO     Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 0.433124\n",
      "Reconstruction: 0.368216, Regularization: 0.000013, Discriminator: 0.043280; Generator: 0.021615,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:19,043 root         INFO     Train Epoch: 168 [1536/8000 (19%)]\tTotal Loss: 0.432535\n",
      "Reconstruction: 0.367588, Regularization: 0.000008, Discriminator: 0.043310; Generator: 0.021629,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:19,151 root         INFO     Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 0.432475\n",
      "Reconstruction: 0.367578, Regularization: 0.000012, Discriminator: 0.043306; Generator: 0.021579,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:19,259 root         INFO     Train Epoch: 168 [2560/8000 (32%)]\tTotal Loss: 0.432703\n",
      "Reconstruction: 0.367789, Regularization: 0.000010, Discriminator: 0.043323; Generator: 0.021581,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:19,366 root         INFO     Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 0.432999\n",
      "Reconstruction: 0.368061, Regularization: 0.000011, Discriminator: 0.043314; Generator: 0.021612,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:19,475 root         INFO     Train Epoch: 168 [3584/8000 (45%)]\tTotal Loss: 0.433856\n",
      "Reconstruction: 0.368815, Regularization: 0.000010, Discriminator: 0.043351; Generator: 0.021680,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:19,583 root         INFO     Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 0.434433\n",
      "Reconstruction: 0.369550, Regularization: 0.000010, Discriminator: 0.043275; Generator: 0.021598,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:19,691 root         INFO     Train Epoch: 168 [4608/8000 (58%)]\tTotal Loss: 0.435542\n",
      "Reconstruction: 0.370522, Regularization: 0.000008, Discriminator: 0.043357; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:19,799 root         INFO     Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 0.436790\n",
      "Reconstruction: 0.371780, Regularization: 0.000009, Discriminator: 0.043322; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:19,908 root         INFO     Train Epoch: 168 [5632/8000 (70%)]\tTotal Loss: 0.438121\n",
      "Reconstruction: 0.373022, Regularization: 0.000008, Discriminator: 0.043393; Generator: 0.021698,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:20,016 root         INFO     Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 0.439360\n",
      "Reconstruction: 0.374338, Regularization: 0.000009, Discriminator: 0.043344; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:20,124 root         INFO     Train Epoch: 168 [6656/8000 (83%)]\tTotal Loss: 0.440953\n",
      "Reconstruction: 0.375917, Regularization: 0.000011, Discriminator: 0.043331; Generator: 0.021694,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:20,232 root         INFO     Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 0.442164\n",
      "Reconstruction: 0.377133, Regularization: 0.000009, Discriminator: 0.043271; Generator: 0.021751,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:20,338 root         INFO     Train Epoch: 168 [7680/8000 (96%)]\tTotal Loss: 0.443267\n",
      "Reconstruction: 0.378237, Regularization: 0.000008, Discriminator: 0.043358; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:20,418 root         INFO     ====> Epoch: 168 Average loss: 0.4361\n",
      "2019-04-10 01:00:20,445 root         INFO     Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 0.444159\n",
      "Reconstruction: 0.379065, Regularization: 0.000010, Discriminator: 0.043329; Generator: 0.021754,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:20,553 root         INFO     Train Epoch: 169 [512/8000 (6%)]\tTotal Loss: 0.445337\n",
      "Reconstruction: 0.380256, Regularization: 0.000009, Discriminator: 0.043342; Generator: 0.021730,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:20,659 root         INFO     Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 0.446480\n",
      "Reconstruction: 0.381357, Regularization: 0.000005, Discriminator: 0.043349; Generator: 0.021769,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 01:00:20,766 root         INFO     Train Epoch: 169 [1536/8000 (19%)]\tTotal Loss: 0.447104\n",
      "Reconstruction: 0.382045, Regularization: 0.000006, Discriminator: 0.043338; Generator: 0.021715,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:20,873 root         INFO     Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 0.447595\n",
      "Reconstruction: 0.382532, Regularization: 0.000007, Discriminator: 0.043319; Generator: 0.021736,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:20,980 root         INFO     Train Epoch: 169 [2560/8000 (32%)]\tTotal Loss: 0.447717\n",
      "Reconstruction: 0.382635, Regularization: 0.000009, Discriminator: 0.043322; Generator: 0.021751,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:21,086 root         INFO     Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 0.447535\n",
      "Reconstruction: 0.382511, Regularization: 0.000007, Discriminator: 0.043319; Generator: 0.021697,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:21,193 root         INFO     Train Epoch: 169 [3584/8000 (45%)]\tTotal Loss: 0.446997\n",
      "Reconstruction: 0.381998, Regularization: 0.000006, Discriminator: 0.043313; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:21,299 root         INFO     Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 0.446399\n",
      "Reconstruction: 0.381352, Regularization: 0.000010, Discriminator: 0.043343; Generator: 0.021694,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:21,406 root         INFO     Train Epoch: 169 [4608/8000 (58%)]\tTotal Loss: 0.445394\n",
      "Reconstruction: 0.380349, Regularization: 0.000008, Discriminator: 0.043296; Generator: 0.021742,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:21,513 root         INFO     Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 0.444095\n",
      "Reconstruction: 0.379073, Regularization: 0.000009, Discriminator: 0.043304; Generator: 0.021710,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:21,619 root         INFO     Train Epoch: 169 [5632/8000 (70%)]\tTotal Loss: 0.442323\n",
      "Reconstruction: 0.377277, Regularization: 0.000011, Discriminator: 0.043313; Generator: 0.021722,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:21,726 root         INFO     Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 0.440172\n",
      "Reconstruction: 0.375135, Regularization: 0.000006, Discriminator: 0.043385; Generator: 0.021645,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:21,832 root         INFO     Train Epoch: 169 [6656/8000 (83%)]\tTotal Loss: 0.437937\n",
      "Reconstruction: 0.372998, Regularization: 0.000012, Discriminator: 0.043271; Generator: 0.021656,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:21,939 root         INFO     Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 0.436173\n",
      "Reconstruction: 0.371120, Regularization: 0.000007, Discriminator: 0.043374; Generator: 0.021673,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:22,047 root         INFO     Train Epoch: 169 [7680/8000 (96%)]\tTotal Loss: 0.434146\n",
      "Reconstruction: 0.369237, Regularization: 0.000004, Discriminator: 0.043311; Generator: 0.021593,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:22,127 root         INFO     ====> Epoch: 169 Average loss: 0.4436\n",
      "2019-04-10 01:00:22,154 root         INFO     Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 0.433445\n",
      "Reconstruction: 0.368477, Regularization: 0.000007, Discriminator: 0.043353; Generator: 0.021609,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:22,264 root         INFO     Train Epoch: 170 [512/8000 (6%)]\tTotal Loss: 0.432291\n",
      "Reconstruction: 0.367337, Regularization: 0.000006, Discriminator: 0.043332; Generator: 0.021616,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:22,373 root         INFO     Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 0.431579\n",
      "Reconstruction: 0.366630, Regularization: 0.000008, Discriminator: 0.043331; Generator: 0.021610,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:22,483 root         INFO     Train Epoch: 170 [1536/8000 (19%)]\tTotal Loss: 0.431461\n",
      "Reconstruction: 0.366501, Regularization: 0.000005, Discriminator: 0.043320; Generator: 0.021635,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:22,593 root         INFO     Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 0.431522\n",
      "Reconstruction: 0.366577, Regularization: 0.000009, Discriminator: 0.043323; Generator: 0.021614,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:22,703 root         INFO     Train Epoch: 170 [2560/8000 (32%)]\tTotal Loss: 0.431462\n",
      "Reconstruction: 0.366513, Regularization: 0.000008, Discriminator: 0.043313; Generator: 0.021629,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:22,812 root         INFO     Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 0.432203\n",
      "Reconstruction: 0.367271, Regularization: 0.000008, Discriminator: 0.043323; Generator: 0.021600,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:22,920 root         INFO     Train Epoch: 170 [3584/8000 (45%)]\tTotal Loss: 0.432623\n",
      "Reconstruction: 0.367700, Regularization: 0.000009, Discriminator: 0.043316; Generator: 0.021598,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:23,028 root         INFO     Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 0.433761\n",
      "Reconstruction: 0.368896, Regularization: 0.000007, Discriminator: 0.043260; Generator: 0.021599,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:23,136 root         INFO     Train Epoch: 170 [4608/8000 (58%)]\tTotal Loss: 0.434978\n",
      "Reconstruction: 0.370042, Regularization: 0.000007, Discriminator: 0.043344; Generator: 0.021585,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:23,244 root         INFO     Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 0.436425\n",
      "Reconstruction: 0.371509, Regularization: 0.000007, Discriminator: 0.043276; Generator: 0.021633,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:23,352 root         INFO     Train Epoch: 170 [5632/8000 (70%)]\tTotal Loss: 0.437848\n",
      "Reconstruction: 0.372894, Regularization: 0.000010, Discriminator: 0.043283; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:23,460 root         INFO     Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 0.439061\n",
      "Reconstruction: 0.374151, Regularization: 0.000015, Discriminator: 0.043266; Generator: 0.021629,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:23,569 root         INFO     Train Epoch: 170 [6656/8000 (83%)]\tTotal Loss: 0.440473\n",
      "Reconstruction: 0.375503, Regularization: 0.000016, Discriminator: 0.043319; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:23,677 root         INFO     Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 0.441316\n",
      "Reconstruction: 0.376295, Regularization: 0.000013, Discriminator: 0.043327; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:23,785 root         INFO     Train Epoch: 170 [7680/8000 (96%)]\tTotal Loss: 0.441854\n",
      "Reconstruction: 0.376841, Regularization: 0.000013, Discriminator: 0.043320; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:23,865 root         INFO     ====> Epoch: 170 Average loss: 0.4353\n",
      "2019-04-10 01:00:23,892 root         INFO     Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 0.442069\n",
      "Reconstruction: 0.377115, Regularization: 0.000015, Discriminator: 0.043260; Generator: 0.021678,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:24,001 root         INFO     Train Epoch: 171 [512/8000 (6%)]\tTotal Loss: 0.442469\n",
      "Reconstruction: 0.377415, Regularization: 0.000013, Discriminator: 0.043299; Generator: 0.021742,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:24,110 root         INFO     Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 0.441639\n",
      "Reconstruction: 0.376686, Regularization: 0.000012, Discriminator: 0.043287; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:24,219 root         INFO     Train Epoch: 171 [1536/8000 (19%)]\tTotal Loss: 0.441435\n",
      "Reconstruction: 0.376448, Regularization: 0.000012, Discriminator: 0.043314; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:24,328 root         INFO     Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 0.440867\n",
      "Reconstruction: 0.375734, Regularization: 0.000013, Discriminator: 0.043390; Generator: 0.021729,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:24,437 root         INFO     Train Epoch: 171 [2560/8000 (32%)]\tTotal Loss: 0.440636\n",
      "Reconstruction: 0.375569, Regularization: 0.000009, Discriminator: 0.043357; Generator: 0.021701,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:24,546 root         INFO     Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 0.440384\n",
      "Reconstruction: 0.375313, Regularization: 0.000012, Discriminator: 0.043333; Generator: 0.021726,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:24,656 root         INFO     Train Epoch: 171 [3584/8000 (45%)]\tTotal Loss: 0.440273\n",
      "Reconstruction: 0.375203, Regularization: 0.000011, Discriminator: 0.043329; Generator: 0.021730,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:24,765 root         INFO     Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 0.440155\n",
      "Reconstruction: 0.375103, Regularization: 0.000015, Discriminator: 0.043326; Generator: 0.021710,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:24,874 root         INFO     Train Epoch: 171 [4608/8000 (58%)]\tTotal Loss: 0.440048\n",
      "Reconstruction: 0.375043, Regularization: 0.000014, Discriminator: 0.043306; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:24,983 root         INFO     Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 0.440658\n",
      "Reconstruction: 0.375611, Regularization: 0.000010, Discriminator: 0.043312; Generator: 0.021725,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:25,091 root         INFO     Train Epoch: 171 [5632/8000 (70%)]\tTotal Loss: 0.440947\n",
      "Reconstruction: 0.375904, Regularization: 0.000012, Discriminator: 0.043328; Generator: 0.021704,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:25,200 root         INFO     Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 0.441577\n",
      "Reconstruction: 0.376624, Regularization: 0.000011, Discriminator: 0.043277; Generator: 0.021665,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:25,309 root         INFO     Train Epoch: 171 [6656/8000 (83%)]\tTotal Loss: 0.442219\n",
      "Reconstruction: 0.377205, Regularization: 0.000015, Discriminator: 0.043309; Generator: 0.021689,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:25,418 root         INFO     Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 0.442678\n",
      "Reconstruction: 0.377673, Regularization: 0.000014, Discriminator: 0.043315; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:25,527 root         INFO     Train Epoch: 171 [7680/8000 (96%)]\tTotal Loss: 0.443151\n",
      "Reconstruction: 0.378147, Regularization: 0.000015, Discriminator: 0.043305; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:25,608 root         INFO     ====> Epoch: 171 Average loss: 0.4413\n",
      "2019-04-10 01:00:25,635 root         INFO     Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 0.443259\n",
      "Reconstruction: 0.378279, Regularization: 0.000015, Discriminator: 0.043344; Generator: 0.021621,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:25,746 root         INFO     Train Epoch: 172 [512/8000 (6%)]\tTotal Loss: 0.444098\n",
      "Reconstruction: 0.379051, Regularization: 0.000012, Discriminator: 0.043350; Generator: 0.021685,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:25,856 root         INFO     Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 0.444154\n",
      "Reconstruction: 0.379128, Regularization: 0.000015, Discriminator: 0.043326; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:25,966 root         INFO     Train Epoch: 172 [1536/8000 (19%)]\tTotal Loss: 0.443653\n",
      "Reconstruction: 0.378579, Regularization: 0.000016, Discriminator: 0.043371; Generator: 0.021687,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:26,077 root         INFO     Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 0.442739\n",
      "Reconstruction: 0.377773, Regularization: 0.000014, Discriminator: 0.043337; Generator: 0.021616,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:26,187 root         INFO     Train Epoch: 172 [2560/8000 (32%)]\tTotal Loss: 0.441645\n",
      "Reconstruction: 0.376635, Regularization: 0.000014, Discriminator: 0.043327; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:26,297 root         INFO     Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 0.440454\n",
      "Reconstruction: 0.375514, Regularization: 0.000022, Discriminator: 0.043313; Generator: 0.021605,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:26,408 root         INFO     Train Epoch: 172 [3584/8000 (45%)]\tTotal Loss: 0.438509\n",
      "Reconstruction: 0.373592, Regularization: 0.000017, Discriminator: 0.043288; Generator: 0.021612,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:26,518 root         INFO     Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 0.436926\n",
      "Reconstruction: 0.371895, Regularization: 0.000014, Discriminator: 0.043399; Generator: 0.021617,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-10 01:00:26,629 root         INFO     Train Epoch: 172 [4608/8000 (58%)]\tTotal Loss: 0.434956\n",
      "Reconstruction: 0.370047, Regularization: 0.000018, Discriminator: 0.043285; Generator: 0.021606,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:26,739 root         INFO     Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 0.433448\n",
      "Reconstruction: 0.368422, Regularization: 0.000017, Discriminator: 0.043371; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:26,849 root         INFO     Train Epoch: 172 [5632/8000 (70%)]\tTotal Loss: 0.432323\n",
      "Reconstruction: 0.367232, Regularization: 0.000017, Discriminator: 0.043415; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:26,959 root         INFO     Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 0.431074\n",
      "Reconstruction: 0.366078, Regularization: 0.000013, Discriminator: 0.043331; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:27,069 root         INFO     Train Epoch: 172 [6656/8000 (83%)]\tTotal Loss: 0.430928\n",
      "Reconstruction: 0.365904, Regularization: 0.000016, Discriminator: 0.043326; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:27,179 root         INFO     Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 0.431174\n",
      "Reconstruction: 0.366197, Regularization: 0.000017, Discriminator: 0.043301; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:27,290 root         INFO     Train Epoch: 172 [7680/8000 (96%)]\tTotal Loss: 0.431709\n",
      "Reconstruction: 0.366752, Regularization: 0.000014, Discriminator: 0.043316; Generator: 0.021628,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:27,370 root         INFO     ====> Epoch: 172 Average loss: 0.4373\n",
      "2019-04-10 01:00:27,397 root         INFO     Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 0.432608\n",
      "Reconstruction: 0.367540, Regularization: 0.000012, Discriminator: 0.043403; Generator: 0.021653,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:27,510 root         INFO     Train Epoch: 173 [512/8000 (6%)]\tTotal Loss: 0.433746\n",
      "Reconstruction: 0.368883, Regularization: 0.000022, Discriminator: 0.043242; Generator: 0.021599,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:27,622 root         INFO     Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 0.435183\n",
      "Reconstruction: 0.370319, Regularization: 0.000020, Discriminator: 0.043196; Generator: 0.021647,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-10 01:00:27,734 root         INFO     Train Epoch: 173 [1536/8000 (19%)]\tTotal Loss: 0.437758\n",
      "Reconstruction: 0.372734, Regularization: 0.000019, Discriminator: 0.043357; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:27,845 root         INFO     Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 0.439932\n",
      "Reconstruction: 0.374834, Regularization: 0.000017, Discriminator: 0.043369; Generator: 0.021713,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:27,957 root         INFO     Train Epoch: 173 [2560/8000 (32%)]\tTotal Loss: 0.441549\n",
      "Reconstruction: 0.376548, Regularization: 0.000016, Discriminator: 0.043279; Generator: 0.021706,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:28,069 root         INFO     Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 0.443455\n",
      "Reconstruction: 0.378382, Regularization: 0.000017, Discriminator: 0.043367; Generator: 0.021688,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:28,180 root         INFO     Train Epoch: 173 [3584/8000 (45%)]\tTotal Loss: 0.444597\n",
      "Reconstruction: 0.379589, Regularization: 0.000014, Discriminator: 0.043325; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:28,292 root         INFO     Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 0.445808\n",
      "Reconstruction: 0.380816, Regularization: 0.000015, Discriminator: 0.043306; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:28,404 root         INFO     Train Epoch: 173 [4608/8000 (58%)]\tTotal Loss: 0.446771\n",
      "Reconstruction: 0.381712, Regularization: 0.000016, Discriminator: 0.043349; Generator: 0.021694,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:28,516 root         INFO     Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 0.447106\n",
      "Reconstruction: 0.382082, Regularization: 0.000018, Discriminator: 0.043320; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:28,627 root         INFO     Train Epoch: 173 [5632/8000 (70%)]\tTotal Loss: 0.446385\n",
      "Reconstruction: 0.381431, Regularization: 0.000017, Discriminator: 0.043292; Generator: 0.021645,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:28,739 root         INFO     Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 0.445719\n",
      "Reconstruction: 0.380751, Regularization: 0.000016, Discriminator: 0.043285; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:28,851 root         INFO     Train Epoch: 173 [6656/8000 (83%)]\tTotal Loss: 0.444523\n",
      "Reconstruction: 0.379552, Regularization: 0.000017, Discriminator: 0.043276; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:28,963 root         INFO     Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 0.443005\n",
      "Reconstruction: 0.377905, Regularization: 0.000018, Discriminator: 0.043372; Generator: 0.021711,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:29,074 root         INFO     Train Epoch: 173 [7680/8000 (96%)]\tTotal Loss: 0.441250\n",
      "Reconstruction: 0.376235, Regularization: 0.000029, Discriminator: 0.043269; Generator: 0.021718,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:29,154 root         INFO     ====> Epoch: 173 Average loss: 0.4421\n",
      "2019-04-10 01:00:29,182 root         INFO     Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 0.439703\n",
      "Reconstruction: 0.374689, Regularization: 0.000025, Discriminator: 0.043316; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:29,294 root         INFO     Train Epoch: 174 [512/8000 (6%)]\tTotal Loss: 0.438318\n",
      "Reconstruction: 0.373213, Regularization: 0.000025, Discriminator: 0.043331; Generator: 0.021750,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:29,405 root         INFO     Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 0.436598\n",
      "Reconstruction: 0.371580, Regularization: 0.000020, Discriminator: 0.043293; Generator: 0.021704,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:29,516 root         INFO     Train Epoch: 174 [1536/8000 (19%)]\tTotal Loss: 0.435584\n",
      "Reconstruction: 0.370396, Regularization: 0.000023, Discriminator: 0.043459; Generator: 0.021706,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-10 01:00:29,627 root         INFO     Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 0.434510\n",
      "Reconstruction: 0.369527, Regularization: 0.000017, Discriminator: 0.043289; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:29,738 root         INFO     Train Epoch: 174 [2560/8000 (32%)]\tTotal Loss: 0.434480\n",
      "Reconstruction: 0.369519, Regularization: 0.000018, Discriminator: 0.043329; Generator: 0.021614,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:29,849 root         INFO     Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 0.434521\n",
      "Reconstruction: 0.369555, Regularization: 0.000018, Discriminator: 0.043333; Generator: 0.021615,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:29,960 root         INFO     Train Epoch: 174 [3584/8000 (45%)]\tTotal Loss: 0.435059\n",
      "Reconstruction: 0.370055, Regularization: 0.000016, Discriminator: 0.043320; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:30,071 root         INFO     Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 0.435865\n",
      "Reconstruction: 0.370901, Regularization: 0.000021, Discriminator: 0.043311; Generator: 0.021632,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:30,181 root         INFO     Train Epoch: 174 [4608/8000 (58%)]\tTotal Loss: 0.436976\n",
      "Reconstruction: 0.371992, Regularization: 0.000019, Discriminator: 0.043321; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:30,292 root         INFO     Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 0.438178\n",
      "Reconstruction: 0.373193, Regularization: 0.000020, Discriminator: 0.043388; Generator: 0.021576,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:30,403 root         INFO     Train Epoch: 174 [5632/8000 (70%)]\tTotal Loss: 0.440009\n",
      "Reconstruction: 0.375013, Regularization: 0.000021, Discriminator: 0.043325; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:30,513 root         INFO     Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 0.441475\n",
      "Reconstruction: 0.376362, Regularization: 0.000025, Discriminator: 0.043406; Generator: 0.021683,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 01:00:30,623 root         INFO     Train Epoch: 174 [6656/8000 (83%)]\tTotal Loss: 0.442383\n",
      "Reconstruction: 0.377341, Regularization: 0.000032, Discriminator: 0.043342; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:30,732 root         INFO     Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 0.443452\n",
      "Reconstruction: 0.378387, Regularization: 0.000033, Discriminator: 0.043346; Generator: 0.021686,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:30,842 root         INFO     Train Epoch: 174 [7680/8000 (96%)]\tTotal Loss: 0.443644\n",
      "Reconstruction: 0.378669, Regularization: 0.000033, Discriminator: 0.043321; Generator: 0.021621,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:30,922 root         INFO     ====> Epoch: 174 Average loss: 0.4380\n",
      "2019-04-10 01:00:30,949 root         INFO     Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 0.443463\n",
      "Reconstruction: 0.378448, Regularization: 0.000034, Discriminator: 0.043281; Generator: 0.021701,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:31,061 root         INFO     Train Epoch: 175 [512/8000 (6%)]\tTotal Loss: 0.442592\n",
      "Reconstruction: 0.377666, Regularization: 0.000034, Discriminator: 0.043293; Generator: 0.021599,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:31,173 root         INFO     Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 0.441410\n",
      "Reconstruction: 0.376460, Regularization: 0.000028, Discriminator: 0.043309; Generator: 0.021614,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:31,284 root         INFO     Train Epoch: 175 [1536/8000 (19%)]\tTotal Loss: 0.438927\n",
      "Reconstruction: 0.374034, Regularization: 0.000033, Discriminator: 0.043260; Generator: 0.021600,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:31,395 root         INFO     Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 0.438056\n",
      "Reconstruction: 0.373106, Regularization: 0.000030, Discriminator: 0.043279; Generator: 0.021642,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:31,506 root         INFO     Train Epoch: 175 [2560/8000 (32%)]\tTotal Loss: 0.435864\n",
      "Reconstruction: 0.370920, Regularization: 0.000029, Discriminator: 0.043284; Generator: 0.021631,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:31,617 root         INFO     Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 0.434348\n",
      "Reconstruction: 0.369312, Regularization: 0.000026, Discriminator: 0.043322; Generator: 0.021689,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:31,726 root         INFO     Train Epoch: 175 [3584/8000 (45%)]\tTotal Loss: 0.433750\n",
      "Reconstruction: 0.368612, Regularization: 0.000031, Discriminator: 0.043419; Generator: 0.021688,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 01:00:31,836 root         INFO     Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 0.432860\n",
      "Reconstruction: 0.367795, Regularization: 0.000028, Discriminator: 0.043364; Generator: 0.021673,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:31,946 root         INFO     Train Epoch: 175 [4608/8000 (58%)]\tTotal Loss: 0.432471\n",
      "Reconstruction: 0.367394, Regularization: 0.000027, Discriminator: 0.043349; Generator: 0.021702,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:32,056 root         INFO     Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 0.432319\n",
      "Reconstruction: 0.367329, Regularization: 0.000029, Discriminator: 0.043291; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:32,165 root         INFO     Train Epoch: 175 [5632/8000 (70%)]\tTotal Loss: 0.433881\n",
      "Reconstruction: 0.368895, Regularization: 0.000026, Discriminator: 0.043280; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:32,275 root         INFO     Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 0.435250\n",
      "Reconstruction: 0.370383, Regularization: 0.000032, Discriminator: 0.043211; Generator: 0.021624,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:32,385 root         INFO     Train Epoch: 175 [6656/8000 (83%)]\tTotal Loss: 0.436991\n",
      "Reconstruction: 0.371957, Regularization: 0.000035, Discriminator: 0.043333; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:32,494 root         INFO     Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 0.439130\n",
      "Reconstruction: 0.374077, Regularization: 0.000031, Discriminator: 0.043371; Generator: 0.021652,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:32,604 root         INFO     Train Epoch: 175 [7680/8000 (96%)]\tTotal Loss: 0.441155\n",
      "Reconstruction: 0.376059, Regularization: 0.000030, Discriminator: 0.043368; Generator: 0.021697,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:32,684 root         INFO     ====> Epoch: 175 Average loss: 0.4367\n",
      "2019-04-10 01:00:32,712 root         INFO     Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 0.442268\n",
      "Reconstruction: 0.377168, Regularization: 0.000029, Discriminator: 0.043367; Generator: 0.021704,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:32,823 root         INFO     Train Epoch: 176 [512/8000 (6%)]\tTotal Loss: 0.444187\n",
      "Reconstruction: 0.379175, Regularization: 0.000022, Discriminator: 0.043355; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:32,934 root         INFO     Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 0.445662\n",
      "Reconstruction: 0.380556, Regularization: 0.000018, Discriminator: 0.043334; Generator: 0.021754,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:33,043 root         INFO     Train Epoch: 176 [1536/8000 (19%)]\tTotal Loss: 0.446862\n",
      "Reconstruction: 0.381701, Regularization: 0.000020, Discriminator: 0.043421; Generator: 0.021720,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-10 01:00:33,153 root         INFO     Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 0.448060\n",
      "Reconstruction: 0.382952, Regularization: 0.000020, Discriminator: 0.043384; Generator: 0.021705,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:33,263 root         INFO     Train Epoch: 176 [2560/8000 (32%)]\tTotal Loss: 0.448379\n",
      "Reconstruction: 0.383298, Regularization: 0.000021, Discriminator: 0.043349; Generator: 0.021711,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:33,373 root         INFO     Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 0.448139\n",
      "Reconstruction: 0.383116, Regularization: 0.000021, Discriminator: 0.043330; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:33,483 root         INFO     Train Epoch: 176 [3584/8000 (45%)]\tTotal Loss: 0.447176\n",
      "Reconstruction: 0.382197, Regularization: 0.000021, Discriminator: 0.043272; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:33,593 root         INFO     Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 0.445743\n",
      "Reconstruction: 0.380799, Regularization: 0.000018, Discriminator: 0.043233; Generator: 0.021693,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-10 01:00:33,703 root         INFO     Train Epoch: 176 [4608/8000 (58%)]\tTotal Loss: 0.443614\n",
      "Reconstruction: 0.378646, Regularization: 0.000014, Discriminator: 0.043277; Generator: 0.021677,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:33,813 root         INFO     Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 0.440688\n",
      "Reconstruction: 0.375870, Regularization: 0.000014, Discriminator: 0.043198; Generator: 0.021606,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-10 01:00:33,923 root         INFO     Train Epoch: 176 [5632/8000 (70%)]\tTotal Loss: 0.438212\n",
      "Reconstruction: 0.373050, Regularization: 0.000028, Discriminator: 0.043494; Generator: 0.021640,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 01:00:34,033 root         INFO     Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 0.435305\n",
      "Reconstruction: 0.370407, Regularization: 0.000019, Discriminator: 0.043217; Generator: 0.021662,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-10 01:00:34,144 root         INFO     Train Epoch: 176 [6656/8000 (83%)]\tTotal Loss: 0.433660\n",
      "Reconstruction: 0.368535, Regularization: 0.000020, Discriminator: 0.043450; Generator: 0.021654,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 01:00:34,255 root         INFO     Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 0.432126\n",
      "Reconstruction: 0.366993, Regularization: 0.000024, Discriminator: 0.043474; Generator: 0.021635,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 01:00:34,366 root         INFO     Train Epoch: 176 [7680/8000 (96%)]\tTotal Loss: 0.431343\n",
      "Reconstruction: 0.366266, Regularization: 0.000027, Discriminator: 0.043391; Generator: 0.021658,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:34,447 root         INFO     ====> Epoch: 176 Average loss: 0.4419\n",
      "2019-04-10 01:00:34,474 root         INFO     Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 0.430699\n",
      "Reconstruction: 0.365674, Regularization: 0.000026, Discriminator: 0.043356; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:34,587 root         INFO     Train Epoch: 177 [512/8000 (6%)]\tTotal Loss: 0.430361\n",
      "Reconstruction: 0.365393, Regularization: 0.000024, Discriminator: 0.043319; Generator: 0.021625,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:34,698 root         INFO     Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 0.430634\n",
      "Reconstruction: 0.365710, Regularization: 0.000024, Discriminator: 0.043282; Generator: 0.021618,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:34,809 root         INFO     Train Epoch: 177 [1536/8000 (19%)]\tTotal Loss: 0.431522\n",
      "Reconstruction: 0.366575, Regularization: 0.000028, Discriminator: 0.043273; Generator: 0.021645,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:34,919 root         INFO     Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 0.432366\n",
      "Reconstruction: 0.367440, Regularization: 0.000025, Discriminator: 0.043282; Generator: 0.021620,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:35,029 root         INFO     Train Epoch: 177 [2560/8000 (32%)]\tTotal Loss: 0.433662\n",
      "Reconstruction: 0.368645, Regularization: 0.000019, Discriminator: 0.043371; Generator: 0.021627,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:35,139 root         INFO     Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 0.435321\n",
      "Reconstruction: 0.370343, Regularization: 0.000016, Discriminator: 0.043311; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:35,250 root         INFO     Train Epoch: 177 [3584/8000 (45%)]\tTotal Loss: 0.436864\n",
      "Reconstruction: 0.371921, Regularization: 0.000017, Discriminator: 0.043265; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:35,358 root         INFO     Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 0.438606\n",
      "Reconstruction: 0.373654, Regularization: 0.000012, Discriminator: 0.043253; Generator: 0.021687,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:35,466 root         INFO     Train Epoch: 177 [4608/8000 (58%)]\tTotal Loss: 0.440166\n",
      "Reconstruction: 0.375269, Regularization: 0.000010, Discriminator: 0.043292; Generator: 0.021595,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:35,575 root         INFO     Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 0.441668\n",
      "Reconstruction: 0.376692, Regularization: 0.000009, Discriminator: 0.043282; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:35,685 root         INFO     Train Epoch: 177 [5632/8000 (70%)]\tTotal Loss: 0.443394\n",
      "Reconstruction: 0.378339, Regularization: 0.000007, Discriminator: 0.043326; Generator: 0.021723,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:35,795 root         INFO     Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 0.444774\n",
      "Reconstruction: 0.379682, Regularization: 0.000012, Discriminator: 0.043358; Generator: 0.021722,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:35,904 root         INFO     Train Epoch: 177 [6656/8000 (83%)]\tTotal Loss: 0.445507\n",
      "Reconstruction: 0.380471, Regularization: 0.000011, Discriminator: 0.043360; Generator: 0.021665,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:36,013 root         INFO     Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 0.446481\n",
      "Reconstruction: 0.381432, Regularization: 0.000012, Discriminator: 0.043322; Generator: 0.021716,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:36,123 root         INFO     Train Epoch: 177 [7680/8000 (96%)]\tTotal Loss: 0.446726\n",
      "Reconstruction: 0.381714, Regularization: 0.000011, Discriminator: 0.043323; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:36,204 root         INFO     ====> Epoch: 177 Average loss: 0.4383\n",
      "2019-04-10 01:00:36,231 root         INFO     Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 0.446886\n",
      "Reconstruction: 0.381883, Regularization: 0.000010, Discriminator: 0.043303; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:36,345 root         INFO     Train Epoch: 178 [512/8000 (6%)]\tTotal Loss: 0.446320\n",
      "Reconstruction: 0.381375, Regularization: 0.000010, Discriminator: 0.043291; Generator: 0.021644,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:36,457 root         INFO     Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 0.445586\n",
      "Reconstruction: 0.380604, Regularization: 0.000012, Discriminator: 0.043327; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:36,570 root         INFO     Train Epoch: 178 [1536/8000 (19%)]\tTotal Loss: 0.444799\n",
      "Reconstruction: 0.379763, Regularization: 0.000013, Discriminator: 0.043349; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:36,683 root         INFO     Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 0.443416\n",
      "Reconstruction: 0.378428, Regularization: 0.000010, Discriminator: 0.043256; Generator: 0.021723,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:36,795 root         INFO     Train Epoch: 178 [2560/8000 (32%)]\tTotal Loss: 0.441868\n",
      "Reconstruction: 0.376761, Regularization: 0.000008, Discriminator: 0.043412; Generator: 0.021687,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 01:00:36,908 root         INFO     Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 0.440164\n",
      "Reconstruction: 0.375129, Regularization: 0.000011, Discriminator: 0.043373; Generator: 0.021651,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:37,021 root         INFO     Train Epoch: 178 [3584/8000 (45%)]\tTotal Loss: 0.438998\n",
      "Reconstruction: 0.373881, Regularization: 0.000009, Discriminator: 0.043400; Generator: 0.021708,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:37,133 root         INFO     Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 0.437455\n",
      "Reconstruction: 0.372525, Regularization: 0.000008, Discriminator: 0.043261; Generator: 0.021660,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:37,244 root         INFO     Train Epoch: 178 [4608/8000 (58%)]\tTotal Loss: 0.436548\n",
      "Reconstruction: 0.371560, Regularization: 0.000007, Discriminator: 0.043317; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:37,356 root         INFO     Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 0.435905\n",
      "Reconstruction: 0.370913, Regularization: 0.000009, Discriminator: 0.043301; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:37,467 root         INFO     Train Epoch: 178 [5632/8000 (70%)]\tTotal Loss: 0.435414\n",
      "Reconstruction: 0.370400, Regularization: 0.000009, Discriminator: 0.043319; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:37,578 root         INFO     Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 0.434809\n",
      "Reconstruction: 0.369853, Regularization: 0.000007, Discriminator: 0.043304; Generator: 0.021645,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:37,690 root         INFO     Train Epoch: 178 [6656/8000 (83%)]\tTotal Loss: 0.434927\n",
      "Reconstruction: 0.369958, Regularization: 0.000010, Discriminator: 0.043283; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:37,801 root         INFO     Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 0.435188\n",
      "Reconstruction: 0.370172, Regularization: 0.000007, Discriminator: 0.043345; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:37,912 root         INFO     Train Epoch: 178 [7680/8000 (96%)]\tTotal Loss: 0.435676\n",
      "Reconstruction: 0.370651, Regularization: 0.000010, Discriminator: 0.043336; Generator: 0.021679,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:37,993 root         INFO     ====> Epoch: 178 Average loss: 0.4394\n",
      "2019-04-10 01:00:38,020 root         INFO     Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 0.435704\n",
      "Reconstruction: 0.370710, Regularization: 0.000007, Discriminator: 0.043313; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:38,131 root         INFO     Train Epoch: 179 [512/8000 (6%)]\tTotal Loss: 0.436004\n",
      "Reconstruction: 0.371061, Regularization: 0.000008, Discriminator: 0.043335; Generator: 0.021600,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:38,241 root         INFO     Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 0.436669\n",
      "Reconstruction: 0.371668, Regularization: 0.000008, Discriminator: 0.043354; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:38,352 root         INFO     Train Epoch: 179 [1536/8000 (19%)]\tTotal Loss: 0.437607\n",
      "Reconstruction: 0.372623, Regularization: 0.000007, Discriminator: 0.043353; Generator: 0.021624,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:38,462 root         INFO     Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 0.438459\n",
      "Reconstruction: 0.373455, Regularization: 0.000008, Discriminator: 0.043342; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:38,573 root         INFO     Train Epoch: 179 [2560/8000 (32%)]\tTotal Loss: 0.439180\n",
      "Reconstruction: 0.374136, Regularization: 0.000007, Discriminator: 0.043386; Generator: 0.021652,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:38,683 root         INFO     Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 0.440096\n",
      "Reconstruction: 0.375115, Regularization: 0.000009, Discriminator: 0.043363; Generator: 0.021609,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:38,793 root         INFO     Train Epoch: 179 [3584/8000 (45%)]\tTotal Loss: 0.440634\n",
      "Reconstruction: 0.375620, Regularization: 0.000010, Discriminator: 0.043341; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:38,903 root         INFO     Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 0.441232\n",
      "Reconstruction: 0.376230, Regularization: 0.000011, Discriminator: 0.043333; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:39,014 root         INFO     Train Epoch: 179 [4608/8000 (58%)]\tTotal Loss: 0.441458\n",
      "Reconstruction: 0.376462, Regularization: 0.000012, Discriminator: 0.043315; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:39,124 root         INFO     Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 0.441609\n",
      "Reconstruction: 0.376659, Regularization: 0.000013, Discriminator: 0.043300; Generator: 0.021637,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:39,234 root         INFO     Train Epoch: 179 [5632/8000 (70%)]\tTotal Loss: 0.441218\n",
      "Reconstruction: 0.376278, Regularization: 0.000011, Discriminator: 0.043322; Generator: 0.021606,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:39,344 root         INFO     Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 0.440910\n",
      "Reconstruction: 0.375936, Regularization: 0.000011, Discriminator: 0.043340; Generator: 0.021623,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:39,454 root         INFO     Train Epoch: 179 [6656/8000 (83%)]\tTotal Loss: 0.440124\n",
      "Reconstruction: 0.375174, Regularization: 0.000013, Discriminator: 0.043303; Generator: 0.021635,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:39,564 root         INFO     Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 0.439623\n",
      "Reconstruction: 0.374637, Regularization: 0.000010, Discriminator: 0.043312; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:39,673 root         INFO     Train Epoch: 179 [7680/8000 (96%)]\tTotal Loss: 0.438816\n",
      "Reconstruction: 0.373780, Regularization: 0.000010, Discriminator: 0.043348; Generator: 0.021678,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:39,754 root         INFO     ====> Epoch: 179 Average loss: 0.4394\n",
      "2019-04-10 01:00:39,781 root         INFO     Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 0.438080\n",
      "Reconstruction: 0.373103, Regularization: 0.000011, Discriminator: 0.043325; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:39,894 root         INFO     Train Epoch: 180 [512/8000 (6%)]\tTotal Loss: 0.436883\n",
      "Reconstruction: 0.371885, Regularization: 0.000010, Discriminator: 0.043318; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:40,006 root         INFO     Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 0.437020\n",
      "Reconstruction: 0.371939, Regularization: 0.000011, Discriminator: 0.043362; Generator: 0.021709,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:40,118 root         INFO     Train Epoch: 180 [1536/8000 (19%)]\tTotal Loss: 0.436927\n",
      "Reconstruction: 0.371898, Regularization: 0.000011, Discriminator: 0.043333; Generator: 0.021684,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:40,229 root         INFO     Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 0.436527\n",
      "Reconstruction: 0.371464, Regularization: 0.000011, Discriminator: 0.043365; Generator: 0.021687,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:40,340 root         INFO     Train Epoch: 180 [2560/8000 (32%)]\tTotal Loss: 0.437572\n",
      "Reconstruction: 0.372557, Regularization: 0.000012, Discriminator: 0.043329; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:40,451 root         INFO     Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 0.437593\n",
      "Reconstruction: 0.372536, Regularization: 0.000012, Discriminator: 0.043321; Generator: 0.021724,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:40,561 root         INFO     Train Epoch: 180 [3584/8000 (45%)]\tTotal Loss: 0.438245\n",
      "Reconstruction: 0.373238, Regularization: 0.000009, Discriminator: 0.043308; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:40,670 root         INFO     Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 0.439023\n",
      "Reconstruction: 0.374040, Regularization: 0.000010, Discriminator: 0.043285; Generator: 0.021688,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:40,778 root         INFO     Train Epoch: 180 [4608/8000 (58%)]\tTotal Loss: 0.439992\n",
      "Reconstruction: 0.375000, Regularization: 0.000011, Discriminator: 0.043280; Generator: 0.021700,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:40,886 root         INFO     Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 0.440677\n",
      "Reconstruction: 0.375686, Regularization: 0.000011, Discriminator: 0.043315; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:40,993 root         INFO     Train Epoch: 180 [5632/8000 (70%)]\tTotal Loss: 0.441447\n",
      "Reconstruction: 0.376405, Regularization: 0.000009, Discriminator: 0.043303; Generator: 0.021731,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:41,100 root         INFO     Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 0.442085\n",
      "Reconstruction: 0.377074, Regularization: 0.000012, Discriminator: 0.043301; Generator: 0.021697,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:41,207 root         INFO     Train Epoch: 180 [6656/8000 (83%)]\tTotal Loss: 0.442694\n",
      "Reconstruction: 0.377676, Regularization: 0.000011, Discriminator: 0.043306; Generator: 0.021701,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:41,314 root         INFO     Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 0.443167\n",
      "Reconstruction: 0.378124, Regularization: 0.000010, Discriminator: 0.043356; Generator: 0.021677,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:41,421 root         INFO     Train Epoch: 180 [7680/8000 (96%)]\tTotal Loss: 0.443455\n",
      "Reconstruction: 0.378436, Regularization: 0.000011, Discriminator: 0.043339; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:41,501 root         INFO     ====> Epoch: 180 Average loss: 0.4395\n",
      "2019-04-10 01:00:41,528 root         INFO     Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 0.443153\n",
      "Reconstruction: 0.378129, Regularization: 0.000010, Discriminator: 0.043342; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:41,639 root         INFO     Train Epoch: 181 [512/8000 (6%)]\tTotal Loss: 0.442745\n",
      "Reconstruction: 0.377733, Regularization: 0.000009, Discriminator: 0.043323; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:41,748 root         INFO     Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 0.441858\n",
      "Reconstruction: 0.376839, Regularization: 0.000011, Discriminator: 0.043370; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:41,857 root         INFO     Train Epoch: 181 [1536/8000 (19%)]\tTotal Loss: 0.440381\n",
      "Reconstruction: 0.375376, Regularization: 0.000014, Discriminator: 0.043355; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:41,966 root         INFO     Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 0.438939\n",
      "Reconstruction: 0.373937, Regularization: 0.000017, Discriminator: 0.043332; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:42,075 root         INFO     Train Epoch: 181 [2560/8000 (32%)]\tTotal Loss: 0.437786\n",
      "Reconstruction: 0.372813, Regularization: 0.000012, Discriminator: 0.043344; Generator: 0.021617,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:42,184 root         INFO     Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 0.436122\n",
      "Reconstruction: 0.371203, Regularization: 0.000008, Discriminator: 0.043313; Generator: 0.021598,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:42,291 root         INFO     Train Epoch: 181 [3584/8000 (45%)]\tTotal Loss: 0.434968\n",
      "Reconstruction: 0.370002, Regularization: 0.000011, Discriminator: 0.043359; Generator: 0.021596,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:42,398 root         INFO     Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 0.433967\n",
      "Reconstruction: 0.369050, Regularization: 0.000012, Discriminator: 0.043306; Generator: 0.021599,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:42,507 root         INFO     Train Epoch: 181 [4608/8000 (58%)]\tTotal Loss: 0.433032\n",
      "Reconstruction: 0.367991, Regularization: 0.000012, Discriminator: 0.043380; Generator: 0.021649,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:42,616 root         INFO     Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 0.432610\n",
      "Reconstruction: 0.367666, Regularization: 0.000012, Discriminator: 0.043314; Generator: 0.021619,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:42,723 root         INFO     Train Epoch: 181 [5632/8000 (70%)]\tTotal Loss: 0.432408\n",
      "Reconstruction: 0.367424, Regularization: 0.000011, Discriminator: 0.043314; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:42,831 root         INFO     Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 0.432641\n",
      "Reconstruction: 0.367724, Regularization: 0.000009, Discriminator: 0.043325; Generator: 0.021583,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:42,940 root         INFO     Train Epoch: 181 [6656/8000 (83%)]\tTotal Loss: 0.433374\n",
      "Reconstruction: 0.368384, Regularization: 0.000009, Discriminator: 0.043328; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:43,047 root         INFO     Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 0.434363\n",
      "Reconstruction: 0.369409, Regularization: 0.000007, Discriminator: 0.043302; Generator: 0.021645,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:43,153 root         INFO     Train Epoch: 181 [7680/8000 (96%)]\tTotal Loss: 0.435312\n",
      "Reconstruction: 0.370350, Regularization: 0.000008, Discriminator: 0.043317; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:43,233 root         INFO     ====> Epoch: 181 Average loss: 0.4363\n",
      "2019-04-10 01:00:43,261 root         INFO     Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 0.436137\n",
      "Reconstruction: 0.371124, Regularization: 0.000005, Discriminator: 0.043367; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:43,373 root         INFO     Train Epoch: 182 [512/8000 (6%)]\tTotal Loss: 0.437691\n",
      "Reconstruction: 0.372740, Regularization: 0.000004, Discriminator: 0.043297; Generator: 0.021650,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:43,484 root         INFO     Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 0.439514\n",
      "Reconstruction: 0.374496, Regularization: 0.000005, Discriminator: 0.043371; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:43,594 root         INFO     Train Epoch: 182 [1536/8000 (19%)]\tTotal Loss: 0.441276\n",
      "Reconstruction: 0.376306, Regularization: 0.000004, Discriminator: 0.043283; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:43,705 root         INFO     Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 0.443136\n",
      "Reconstruction: 0.378063, Regularization: 0.000003, Discriminator: 0.043332; Generator: 0.021738,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:43,815 root         INFO     Train Epoch: 182 [2560/8000 (32%)]\tTotal Loss: 0.444638\n",
      "Reconstruction: 0.379570, Regularization: 0.000006, Discriminator: 0.043307; Generator: 0.021756,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 01:00:43,926 root         INFO     Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 0.445799\n",
      "Reconstruction: 0.380807, Regularization: 0.000008, Discriminator: 0.043298; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:44,037 root         INFO     Train Epoch: 182 [3584/8000 (45%)]\tTotal Loss: 0.446869\n",
      "Reconstruction: 0.381774, Regularization: 0.000009, Discriminator: 0.043344; Generator: 0.021741,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:44,148 root         INFO     Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 0.447171\n",
      "Reconstruction: 0.382114, Regularization: 0.000009, Discriminator: 0.043322; Generator: 0.021725,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:44,259 root         INFO     Train Epoch: 182 [4608/8000 (58%)]\tTotal Loss: 0.447089\n",
      "Reconstruction: 0.382081, Regularization: 0.000012, Discriminator: 0.043327; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:44,370 root         INFO     Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 0.446565\n",
      "Reconstruction: 0.381570, Regularization: 0.000010, Discriminator: 0.043307; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:44,480 root         INFO     Train Epoch: 182 [5632/8000 (70%)]\tTotal Loss: 0.446330\n",
      "Reconstruction: 0.381302, Regularization: 0.000012, Discriminator: 0.043305; Generator: 0.021711,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:44,591 root         INFO     Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 0.444519\n",
      "Reconstruction: 0.379591, Regularization: 0.000006, Discriminator: 0.043259; Generator: 0.021663,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:44,701 root         INFO     Train Epoch: 182 [6656/8000 (83%)]\tTotal Loss: 0.443199\n",
      "Reconstruction: 0.378186, Regularization: 0.000004, Discriminator: 0.043316; Generator: 0.021693,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:44,811 root         INFO     Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 0.441489\n",
      "Reconstruction: 0.376379, Regularization: 0.000004, Discriminator: 0.043404; Generator: 0.021702,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:44,922 root         INFO     Train Epoch: 182 [7680/8000 (96%)]\tTotal Loss: 0.439342\n",
      "Reconstruction: 0.374424, Regularization: 0.000003, Discriminator: 0.043267; Generator: 0.021648,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:45,002 root         INFO     ====> Epoch: 182 Average loss: 0.4433\n",
      "2019-04-10 01:00:45,029 root         INFO     Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 0.438283\n",
      "Reconstruction: 0.373317, Regularization: 0.000003, Discriminator: 0.043308; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:45,141 root         INFO     Train Epoch: 183 [512/8000 (6%)]\tTotal Loss: 0.436726\n",
      "Reconstruction: 0.371790, Regularization: 0.000002, Discriminator: 0.043278; Generator: 0.021655,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:45,253 root         INFO     Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 0.435363\n",
      "Reconstruction: 0.370305, Regularization: 0.000003, Discriminator: 0.043384; Generator: 0.021671,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:45,364 root         INFO     Train Epoch: 183 [1536/8000 (19%)]\tTotal Loss: 0.433672\n",
      "Reconstruction: 0.368725, Regularization: 0.000005, Discriminator: 0.043318; Generator: 0.021624,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:45,475 root         INFO     Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 0.432708\n",
      "Reconstruction: 0.367745, Regularization: 0.000006, Discriminator: 0.043308; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:45,586 root         INFO     Train Epoch: 183 [2560/8000 (32%)]\tTotal Loss: 0.431945\n",
      "Reconstruction: 0.366962, Regularization: 0.000006, Discriminator: 0.043330; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:45,697 root         INFO     Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 0.431547\n",
      "Reconstruction: 0.366595, Regularization: 0.000007, Discriminator: 0.043332; Generator: 0.021614,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:45,807 root         INFO     Train Epoch: 183 [3584/8000 (45%)]\tTotal Loss: 0.431904\n",
      "Reconstruction: 0.366923, Regularization: 0.000005, Discriminator: 0.043352; Generator: 0.021624,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:45,918 root         INFO     Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 0.432637\n",
      "Reconstruction: 0.367667, Regularization: 0.000008, Discriminator: 0.043321; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:46,029 root         INFO     Train Epoch: 183 [4608/8000 (58%)]\tTotal Loss: 0.433362\n",
      "Reconstruction: 0.368437, Regularization: 0.000009, Discriminator: 0.043312; Generator: 0.021604,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:46,140 root         INFO     Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 0.434360\n",
      "Reconstruction: 0.369508, Regularization: 0.000010, Discriminator: 0.043279; Generator: 0.021563,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 01:00:46,251 root         INFO     Train Epoch: 183 [5632/8000 (70%)]\tTotal Loss: 0.435714\n",
      "Reconstruction: 0.370733, Regularization: 0.000012, Discriminator: 0.043312; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:46,362 root         INFO     Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 0.437010\n",
      "Reconstruction: 0.372096, Regularization: 0.000012, Discriminator: 0.043306; Generator: 0.021596,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:46,473 root         INFO     Train Epoch: 183 [6656/8000 (83%)]\tTotal Loss: 0.438676\n",
      "Reconstruction: 0.373735, Regularization: 0.000013, Discriminator: 0.043288; Generator: 0.021641,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:46,585 root         INFO     Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 0.439690\n",
      "Reconstruction: 0.374718, Regularization: 0.000013, Discriminator: 0.043309; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:46,695 root         INFO     Train Epoch: 183 [7680/8000 (96%)]\tTotal Loss: 0.440759\n",
      "Reconstruction: 0.375746, Regularization: 0.000017, Discriminator: 0.043343; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:46,776 root         INFO     ====> Epoch: 183 Average loss: 0.4352\n",
      "2019-04-10 01:00:46,803 root         INFO     Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 0.441090\n",
      "Reconstruction: 0.376155, Regularization: 0.000020, Discriminator: 0.043330; Generator: 0.021584,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:46,914 root         INFO     Train Epoch: 184 [512/8000 (6%)]\tTotal Loss: 0.441874\n",
      "Reconstruction: 0.376888, Regularization: 0.000024, Discriminator: 0.043312; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:47,025 root         INFO     Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 0.442377\n",
      "Reconstruction: 0.377434, Regularization: 0.000023, Discriminator: 0.043300; Generator: 0.021619,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:47,136 root         INFO     Train Epoch: 184 [1536/8000 (19%)]\tTotal Loss: 0.443406\n",
      "Reconstruction: 0.378382, Regularization: 0.000022, Discriminator: 0.043314; Generator: 0.021688,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:47,247 root         INFO     Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 0.443540\n",
      "Reconstruction: 0.378533, Regularization: 0.000024, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:47,357 root         INFO     Train Epoch: 184 [2560/8000 (32%)]\tTotal Loss: 0.443645\n",
      "Reconstruction: 0.378601, Regularization: 0.000027, Discriminator: 0.043327; Generator: 0.021690,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:47,468 root         INFO     Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 0.444351\n",
      "Reconstruction: 0.379245, Regularization: 0.000029, Discriminator: 0.043338; Generator: 0.021739,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:47,580 root         INFO     Train Epoch: 184 [3584/8000 (45%)]\tTotal Loss: 0.443503\n",
      "Reconstruction: 0.378458, Regularization: 0.000030, Discriminator: 0.043308; Generator: 0.021707,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:47,691 root         INFO     Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 0.443258\n",
      "Reconstruction: 0.378157, Regularization: 0.000030, Discriminator: 0.043342; Generator: 0.021729,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:47,802 root         INFO     Train Epoch: 184 [4608/8000 (58%)]\tTotal Loss: 0.442962\n",
      "Reconstruction: 0.377873, Regularization: 0.000030, Discriminator: 0.043340; Generator: 0.021718,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:47,913 root         INFO     Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 0.443586\n",
      "Reconstruction: 0.378512, Regularization: 0.000029, Discriminator: 0.043321; Generator: 0.021724,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:48,024 root         INFO     Train Epoch: 184 [5632/8000 (70%)]\tTotal Loss: 0.442758\n",
      "Reconstruction: 0.377688, Regularization: 0.000031, Discriminator: 0.043310; Generator: 0.021728,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:48,136 root         INFO     Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 0.442626\n",
      "Reconstruction: 0.377570, Regularization: 0.000031, Discriminator: 0.043308; Generator: 0.021717,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:48,247 root         INFO     Train Epoch: 184 [6656/8000 (83%)]\tTotal Loss: 0.442269\n",
      "Reconstruction: 0.377252, Regularization: 0.000028, Discriminator: 0.043278; Generator: 0.021711,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:48,358 root         INFO     Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 0.441483\n",
      "Reconstruction: 0.376484, Regularization: 0.000033, Discriminator: 0.043288; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:48,469 root         INFO     Train Epoch: 184 [7680/8000 (96%)]\tTotal Loss: 0.441976\n",
      "Reconstruction: 0.376962, Regularization: 0.000037, Discriminator: 0.043310; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:48,549 root         INFO     ====> Epoch: 184 Average loss: 0.4428\n",
      "2019-04-10 01:00:48,577 root         INFO     Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 0.441024\n",
      "Reconstruction: 0.375964, Regularization: 0.000038, Discriminator: 0.043308; Generator: 0.021713,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:48,689 root         INFO     Train Epoch: 185 [512/8000 (6%)]\tTotal Loss: 0.440882\n",
      "Reconstruction: 0.375881, Regularization: 0.000042, Discriminator: 0.043284; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:48,801 root         INFO     Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 0.439180\n",
      "Reconstruction: 0.374119, Regularization: 0.000042, Discriminator: 0.043323; Generator: 0.021695,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:48,913 root         INFO     Train Epoch: 185 [1536/8000 (19%)]\tTotal Loss: 0.438849\n",
      "Reconstruction: 0.373816, Regularization: 0.000038, Discriminator: 0.043364; Generator: 0.021631,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:49,025 root         INFO     Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 0.437364\n",
      "Reconstruction: 0.372361, Regularization: 0.000041, Discriminator: 0.043320; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:49,137 root         INFO     Train Epoch: 185 [2560/8000 (32%)]\tTotal Loss: 0.436521\n",
      "Reconstruction: 0.371498, Regularization: 0.000036, Discriminator: 0.043310; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:49,249 root         INFO     Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 0.435082\n",
      "Reconstruction: 0.370128, Regularization: 0.000034, Discriminator: 0.043261; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:49,361 root         INFO     Train Epoch: 185 [3584/8000 (45%)]\tTotal Loss: 0.434046\n",
      "Reconstruction: 0.369099, Regularization: 0.000030, Discriminator: 0.043312; Generator: 0.021605,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:49,473 root         INFO     Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 0.432292\n",
      "Reconstruction: 0.367373, Regularization: 0.000026, Discriminator: 0.043298; Generator: 0.021595,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:49,585 root         INFO     Train Epoch: 185 [4608/8000 (58%)]\tTotal Loss: 0.431268\n",
      "Reconstruction: 0.366365, Regularization: 0.000023, Discriminator: 0.043308; Generator: 0.021572,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:49,697 root         INFO     Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 0.429829\n",
      "Reconstruction: 0.364873, Regularization: 0.000022, Discriminator: 0.043347; Generator: 0.021587,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:49,808 root         INFO     Train Epoch: 185 [5632/8000 (70%)]\tTotal Loss: 0.429250\n",
      "Reconstruction: 0.364349, Regularization: 0.000022, Discriminator: 0.043300; Generator: 0.021579,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:49,921 root         INFO     Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 0.429750\n",
      "Reconstruction: 0.364861, Regularization: 0.000021, Discriminator: 0.043316; Generator: 0.021552,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 01:00:50,031 root         INFO     Train Epoch: 185 [6656/8000 (83%)]\tTotal Loss: 0.430361\n",
      "Reconstruction: 0.365468, Regularization: 0.000028, Discriminator: 0.043318; Generator: 0.021546,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 01:00:50,141 root         INFO     Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 0.431389\n",
      "Reconstruction: 0.366479, Regularization: 0.000032, Discriminator: 0.043257; Generator: 0.021620,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:50,251 root         INFO     Train Epoch: 185 [7680/8000 (96%)]\tTotal Loss: 0.432511\n",
      "Reconstruction: 0.367558, Regularization: 0.000039, Discriminator: 0.043295; Generator: 0.021620,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:50,331 root         INFO     ====> Epoch: 185 Average loss: 0.4341\n",
      "2019-04-10 01:00:50,358 root         INFO     Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 0.433966\n",
      "Reconstruction: 0.369026, Regularization: 0.000039, Discriminator: 0.043247; Generator: 0.021653,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:50,470 root         INFO     Train Epoch: 186 [512/8000 (6%)]\tTotal Loss: 0.434713\n",
      "Reconstruction: 0.369659, Regularization: 0.000039, Discriminator: 0.043358; Generator: 0.021657,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:50,582 root         INFO     Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 0.436289\n",
      "Reconstruction: 0.371273, Regularization: 0.000038, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:50,692 root         INFO     Train Epoch: 186 [1536/8000 (19%)]\tTotal Loss: 0.438349\n",
      "Reconstruction: 0.373343, Regularization: 0.000046, Discriminator: 0.043352; Generator: 0.021609,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:50,802 root         INFO     Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 0.440331\n",
      "Reconstruction: 0.375388, Regularization: 0.000049, Discriminator: 0.043220; Generator: 0.021674,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:50,912 root         INFO     Train Epoch: 186 [2560/8000 (32%)]\tTotal Loss: 0.442191\n",
      "Reconstruction: 0.377111, Regularization: 0.000037, Discriminator: 0.043329; Generator: 0.021714,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:51,023 root         INFO     Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 0.443381\n",
      "Reconstruction: 0.378404, Regularization: 0.000032, Discriminator: 0.043242; Generator: 0.021703,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-10 01:00:51,134 root         INFO     Train Epoch: 186 [3584/8000 (45%)]\tTotal Loss: 0.445485\n",
      "Reconstruction: 0.380356, Regularization: 0.000027, Discriminator: 0.043325; Generator: 0.021776,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 01:00:51,246 root         INFO     Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 0.447453\n",
      "Reconstruction: 0.382375, Regularization: 0.000032, Discriminator: 0.043325; Generator: 0.021721,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:51,358 root         INFO     Train Epoch: 186 [4608/8000 (58%)]\tTotal Loss: 0.449143\n",
      "Reconstruction: 0.383951, Regularization: 0.000038, Discriminator: 0.043399; Generator: 0.021755,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-10 01:00:51,470 root         INFO     Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 0.450048\n",
      "Reconstruction: 0.384907, Regularization: 0.000041, Discriminator: 0.043357; Generator: 0.021744,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:51,582 root         INFO     Train Epoch: 186 [5632/8000 (70%)]\tTotal Loss: 0.450737\n",
      "Reconstruction: 0.385640, Regularization: 0.000036, Discriminator: 0.043342; Generator: 0.021719,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:51,694 root         INFO     Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 0.451849\n",
      "Reconstruction: 0.386694, Regularization: 0.000036, Discriminator: 0.043353; Generator: 0.021766,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 01:00:51,807 root         INFO     Train Epoch: 186 [6656/8000 (83%)]\tTotal Loss: 0.451772\n",
      "Reconstruction: 0.386688, Regularization: 0.000036, Discriminator: 0.043308; Generator: 0.021739,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:51,919 root         INFO     Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 0.450885\n",
      "Reconstruction: 0.385764, Regularization: 0.000039, Discriminator: 0.043308; Generator: 0.021774,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 01:00:52,032 root         INFO     Train Epoch: 186 [7680/8000 (96%)]\tTotal Loss: 0.449223\n",
      "Reconstruction: 0.384156, Regularization: 0.000041, Discriminator: 0.043257; Generator: 0.021769,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 01:00:52,113 root         INFO     ====> Epoch: 186 Average loss: 0.4450\n",
      "2019-04-10 01:00:52,140 root         INFO     Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 0.447538\n",
      "Reconstruction: 0.382322, Regularization: 0.000036, Discriminator: 0.043399; Generator: 0.021782,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-10 01:00:52,252 root         INFO     Train Epoch: 187 [512/8000 (6%)]\tTotal Loss: 0.444511\n",
      "Reconstruction: 0.379500, Regularization: 0.000029, Discriminator: 0.043269; Generator: 0.021712,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:52,363 root         INFO     Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 0.441724\n",
      "Reconstruction: 0.376578, Regularization: 0.000027, Discriminator: 0.043384; Generator: 0.021735,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:52,475 root         INFO     Train Epoch: 187 [1536/8000 (19%)]\tTotal Loss: 0.439021\n",
      "Reconstruction: 0.373950, Regularization: 0.000026, Discriminator: 0.043337; Generator: 0.021708,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:52,585 root         INFO     Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 0.436638\n",
      "Reconstruction: 0.371519, Regularization: 0.000019, Discriminator: 0.043394; Generator: 0.021705,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:52,694 root         INFO     Train Epoch: 187 [2560/8000 (32%)]\tTotal Loss: 0.435024\n",
      "Reconstruction: 0.370039, Regularization: 0.000018, Discriminator: 0.043331; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:52,802 root         INFO     Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 0.434093\n",
      "Reconstruction: 0.369237, Regularization: 0.000015, Discriminator: 0.043289; Generator: 0.021551,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 01:00:52,910 root         INFO     Train Epoch: 187 [3584/8000 (45%)]\tTotal Loss: 0.433722\n",
      "Reconstruction: 0.368785, Regularization: 0.000013, Discriminator: 0.043343; Generator: 0.021581,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:53,018 root         INFO     Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 0.434081\n",
      "Reconstruction: 0.368994, Regularization: 0.000014, Discriminator: 0.043436; Generator: 0.021637,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:53,126 root         INFO     Train Epoch: 187 [4608/8000 (58%)]\tTotal Loss: 0.434596\n",
      "Reconstruction: 0.369537, Regularization: 0.000015, Discriminator: 0.043401; Generator: 0.021643,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:53,234 root         INFO     Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 0.434939\n",
      "Reconstruction: 0.369941, Regularization: 0.000013, Discriminator: 0.043368; Generator: 0.021618,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:53,341 root         INFO     Train Epoch: 187 [5632/8000 (70%)]\tTotal Loss: 0.435398\n",
      "Reconstruction: 0.370355, Regularization: 0.000015, Discriminator: 0.043379; Generator: 0.021649,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:53,449 root         INFO     Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 0.435220\n",
      "Reconstruction: 0.370213, Regularization: 0.000014, Discriminator: 0.043341; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:53,557 root         INFO     Train Epoch: 187 [6656/8000 (83%)]\tTotal Loss: 0.435809\n",
      "Reconstruction: 0.370845, Regularization: 0.000014, Discriminator: 0.043327; Generator: 0.021623,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:53,665 root         INFO     Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 0.434761\n",
      "Reconstruction: 0.369844, Regularization: 0.000014, Discriminator: 0.043286; Generator: 0.021617,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:53,774 root         INFO     Train Epoch: 187 [7680/8000 (96%)]\tTotal Loss: 0.434306\n",
      "Reconstruction: 0.369406, Regularization: 0.000012, Discriminator: 0.043305; Generator: 0.021583,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:53,855 root         INFO     ====> Epoch: 187 Average loss: 0.4366\n",
      "2019-04-10 01:00:53,882 root         INFO     Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 0.433885\n",
      "Reconstruction: 0.368975, Regularization: 0.000013, Discriminator: 0.043311; Generator: 0.021587,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:53,994 root         INFO     Train Epoch: 188 [512/8000 (6%)]\tTotal Loss: 0.432964\n",
      "Reconstruction: 0.368084, Regularization: 0.000012, Discriminator: 0.043319; Generator: 0.021549,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 01:00:54,105 root         INFO     Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 0.431972\n",
      "Reconstruction: 0.367142, Regularization: 0.000011, Discriminator: 0.043237; Generator: 0.021583,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-10 01:00:54,216 root         INFO     Train Epoch: 188 [1536/8000 (19%)]\tTotal Loss: 0.431299\n",
      "Reconstruction: 0.366427, Regularization: 0.000013, Discriminator: 0.043300; Generator: 0.021559,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-10 01:00:54,327 root         INFO     Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 0.430323\n",
      "Reconstruction: 0.365345, Regularization: 0.000012, Discriminator: 0.043358; Generator: 0.021608,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:54,438 root         INFO     Train Epoch: 188 [2560/8000 (32%)]\tTotal Loss: 0.429402\n",
      "Reconstruction: 0.364407, Regularization: 0.000010, Discriminator: 0.043316; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:54,549 root         INFO     Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 0.429387\n",
      "Reconstruction: 0.364408, Regularization: 0.000010, Discriminator: 0.043350; Generator: 0.021620,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:54,657 root         INFO     Train Epoch: 188 [3584/8000 (45%)]\tTotal Loss: 0.429483\n",
      "Reconstruction: 0.364505, Regularization: 0.000008, Discriminator: 0.043363; Generator: 0.021607,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:54,764 root         INFO     Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 0.430487\n",
      "Reconstruction: 0.365529, Regularization: 0.000008, Discriminator: 0.043328; Generator: 0.021621,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:54,870 root         INFO     Train Epoch: 188 [4608/8000 (58%)]\tTotal Loss: 0.431511\n",
      "Reconstruction: 0.366559, Regularization: 0.000008, Discriminator: 0.043356; Generator: 0.021588,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:54,977 root         INFO     Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 0.433301\n",
      "Reconstruction: 0.368428, Regularization: 0.000007, Discriminator: 0.043260; Generator: 0.021606,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:55,083 root         INFO     Train Epoch: 188 [5632/8000 (70%)]\tTotal Loss: 0.435282\n",
      "Reconstruction: 0.370282, Regularization: 0.000007, Discriminator: 0.043326; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:55,189 root         INFO     Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 0.437689\n",
      "Reconstruction: 0.372662, Regularization: 0.000007, Discriminator: 0.043311; Generator: 0.021709,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:55,296 root         INFO     Train Epoch: 188 [6656/8000 (83%)]\tTotal Loss: 0.440194\n",
      "Reconstruction: 0.375272, Regularization: 0.000008, Discriminator: 0.043288; Generator: 0.021626,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:55,402 root         INFO     Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 0.443095\n",
      "Reconstruction: 0.378152, Regularization: 0.000010, Discriminator: 0.043245; Generator: 0.021689,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:55,508 root         INFO     Train Epoch: 188 [7680/8000 (96%)]\tTotal Loss: 0.445421\n",
      "Reconstruction: 0.380308, Regularization: 0.000011, Discriminator: 0.043305; Generator: 0.021797,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 01:00:55,586 root         INFO     ====> Epoch: 188 Average loss: 0.4342\n",
      "2019-04-10 01:00:55,613 root         INFO     Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 0.447137\n",
      "Reconstruction: 0.381954, Regularization: 0.000009, Discriminator: 0.043435; Generator: 0.021739,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-10 01:00:55,720 root         INFO     Train Epoch: 189 [512/8000 (6%)]\tTotal Loss: 0.449428\n",
      "Reconstruction: 0.384339, Regularization: 0.000009, Discriminator: 0.043292; Generator: 0.021788,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 01:00:55,828 root         INFO     Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 0.451148\n",
      "Reconstruction: 0.385961, Regularization: 0.000011, Discriminator: 0.043407; Generator: 0.021769,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-10 01:00:55,935 root         INFO     Train Epoch: 189 [1536/8000 (19%)]\tTotal Loss: 0.452444\n",
      "Reconstruction: 0.387332, Regularization: 0.000014, Discriminator: 0.043334; Generator: 0.021763,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 01:00:56,042 root         INFO     Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 0.453795\n",
      "Reconstruction: 0.388697, Regularization: 0.000014, Discriminator: 0.043317; Generator: 0.021767,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 01:00:56,149 root         INFO     Train Epoch: 189 [2560/8000 (32%)]\tTotal Loss: 0.454665\n",
      "Reconstruction: 0.389577, Regularization: 0.000013, Discriminator: 0.043304; Generator: 0.021771,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 01:00:56,256 root         INFO     Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 0.454666\n",
      "Reconstruction: 0.389579, Regularization: 0.000014, Discriminator: 0.043318; Generator: 0.021755,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 01:00:56,362 root         INFO     Train Epoch: 189 [3584/8000 (45%)]\tTotal Loss: 0.454844\n",
      "Reconstruction: 0.389773, Regularization: 0.000013, Discriminator: 0.043278; Generator: 0.021780,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 01:00:56,469 root         INFO     Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 0.453079\n",
      "Reconstruction: 0.387989, Regularization: 0.000011, Discriminator: 0.043317; Generator: 0.021761,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 01:00:56,576 root         INFO     Train Epoch: 189 [4608/8000 (58%)]\tTotal Loss: 0.451032\n",
      "Reconstruction: 0.386034, Regularization: 0.000010, Discriminator: 0.043251; Generator: 0.021736,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:00:56,682 root         INFO     Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 0.448710\n",
      "Reconstruction: 0.383592, Regularization: 0.000006, Discriminator: 0.043377; Generator: 0.021735,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:56,789 root         INFO     Train Epoch: 189 [5632/8000 (70%)]\tTotal Loss: 0.445921\n",
      "Reconstruction: 0.380892, Regularization: 0.000004, Discriminator: 0.043304; Generator: 0.021721,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:00:56,896 root         INFO     Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 0.443070\n",
      "Reconstruction: 0.377956, Regularization: 0.000003, Discriminator: 0.043351; Generator: 0.021760,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 01:00:57,003 root         INFO     Train Epoch: 189 [6656/8000 (83%)]\tTotal Loss: 0.440115\n",
      "Reconstruction: 0.375005, Regularization: 0.000002, Discriminator: 0.043370; Generator: 0.021738,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:00:57,110 root         INFO     Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 0.437540\n",
      "Reconstruction: 0.372438, Regularization: 0.000004, Discriminator: 0.043406; Generator: 0.021691,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 01:00:57,219 root         INFO     Train Epoch: 189 [7680/8000 (96%)]\tTotal Loss: 0.435077\n",
      "Reconstruction: 0.370220, Regularization: 0.000002, Discriminator: 0.043222; Generator: 0.021634,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-10 01:00:57,298 root         INFO     ====> Epoch: 189 Average loss: 0.4482\n",
      "2019-04-10 01:00:57,325 root         INFO     Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 0.434054\n",
      "Reconstruction: 0.369105, Regularization: 0.000002, Discriminator: 0.043323; Generator: 0.021624,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:57,434 root         INFO     Train Epoch: 190 [512/8000 (6%)]\tTotal Loss: 0.432883\n",
      "Reconstruction: 0.367993, Regularization: 0.000002, Discriminator: 0.043314; Generator: 0.021573,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:57,542 root         INFO     Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 0.432314\n",
      "Reconstruction: 0.367348, Regularization: 0.000002, Discriminator: 0.043342; Generator: 0.021623,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:57,651 root         INFO     Train Epoch: 190 [1536/8000 (19%)]\tTotal Loss: 0.432437\n",
      "Reconstruction: 0.367475, Regularization: 0.000005, Discriminator: 0.043355; Generator: 0.021603,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:57,759 root         INFO     Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 0.432177\n",
      "Reconstruction: 0.367201, Regularization: 0.000004, Discriminator: 0.043366; Generator: 0.021606,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:57,867 root         INFO     Train Epoch: 190 [2560/8000 (32%)]\tTotal Loss: 0.432412\n",
      "Reconstruction: 0.367426, Regularization: 0.000003, Discriminator: 0.043379; Generator: 0.021603,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:57,976 root         INFO     Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 0.432829\n",
      "Reconstruction: 0.367892, Regularization: 0.000003, Discriminator: 0.043349; Generator: 0.021585,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:58,083 root         INFO     Train Epoch: 190 [3584/8000 (45%)]\tTotal Loss: 0.433180\n",
      "Reconstruction: 0.368236, Regularization: 0.000003, Discriminator: 0.043356; Generator: 0.021586,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:58,190 root         INFO     Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 0.434112\n",
      "Reconstruction: 0.369163, Regularization: 0.000003, Discriminator: 0.043314; Generator: 0.021632,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:00:58,299 root         INFO     Train Epoch: 190 [4608/8000 (58%)]\tTotal Loss: 0.434818\n",
      "Reconstruction: 0.369789, Regularization: 0.000003, Discriminator: 0.043335; Generator: 0.021692,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:58,409 root         INFO     Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 0.435229\n",
      "Reconstruction: 0.370183, Regularization: 0.000003, Discriminator: 0.043367; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:58,519 root         INFO     Train Epoch: 190 [5632/8000 (70%)]\tTotal Loss: 0.435517\n",
      "Reconstruction: 0.370556, Regularization: 0.000004, Discriminator: 0.043329; Generator: 0.021628,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:58,629 root         INFO     Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 0.435304\n",
      "Reconstruction: 0.370423, Regularization: 0.000003, Discriminator: 0.043301; Generator: 0.021578,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:58,738 root         INFO     Train Epoch: 190 [6656/8000 (83%)]\tTotal Loss: 0.435205\n",
      "Reconstruction: 0.370325, Regularization: 0.000003, Discriminator: 0.043274; Generator: 0.021603,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:58,848 root         INFO     Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 0.434987\n",
      "Reconstruction: 0.370151, Regularization: 0.000003, Discriminator: 0.043261; Generator: 0.021573,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:58,957 root         INFO     Train Epoch: 190 [7680/8000 (96%)]\tTotal Loss: 0.434840\n",
      "Reconstruction: 0.370023, Regularization: 0.000002, Discriminator: 0.043279; Generator: 0.021535,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-10 01:00:59,036 root         INFO     ====> Epoch: 190 Average loss: 0.4339\n",
      "2019-04-10 01:00:59,064 root         INFO     Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 0.434555\n",
      "Reconstruction: 0.369740, Regularization: 0.000003, Discriminator: 0.043256; Generator: 0.021556,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-10 01:00:59,173 root         INFO     Train Epoch: 191 [512/8000 (6%)]\tTotal Loss: 0.434613\n",
      "Reconstruction: 0.369738, Regularization: 0.000003, Discriminator: 0.043303; Generator: 0.021569,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:00:59,280 root         INFO     Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 0.434771\n",
      "Reconstruction: 0.369855, Regularization: 0.000003, Discriminator: 0.043320; Generator: 0.021593,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:59,388 root         INFO     Train Epoch: 191 [1536/8000 (19%)]\tTotal Loss: 0.434752\n",
      "Reconstruction: 0.369813, Regularization: 0.000003, Discriminator: 0.043342; Generator: 0.021594,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:00:59,496 root         INFO     Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 0.434996\n",
      "Reconstruction: 0.370004, Regularization: 0.000003, Discriminator: 0.043365; Generator: 0.021624,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:00:59,602 root         INFO     Train Epoch: 191 [2560/8000 (32%)]\tTotal Loss: 0.434871\n",
      "Reconstruction: 0.369836, Regularization: 0.000003, Discriminator: 0.043376; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:59,710 root         INFO     Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 0.435078\n",
      "Reconstruction: 0.370103, Regularization: 0.000006, Discriminator: 0.043304; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:00:59,817 root         INFO     Train Epoch: 191 [3584/8000 (45%)]\tTotal Loss: 0.435737\n",
      "Reconstruction: 0.370696, Regularization: 0.000005, Discriminator: 0.043365; Generator: 0.021671,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:00:59,924 root         INFO     Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 0.436233\n",
      "Reconstruction: 0.371241, Regularization: 0.000004, Discriminator: 0.043340; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:00,032 root         INFO     Train Epoch: 191 [4608/8000 (58%)]\tTotal Loss: 0.437394\n",
      "Reconstruction: 0.372457, Regularization: 0.000003, Discriminator: 0.043293; Generator: 0.021640,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:01:00,139 root         INFO     Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 0.438951\n",
      "Reconstruction: 0.373955, Regularization: 0.000007, Discriminator: 0.043310; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:00,246 root         INFO     Train Epoch: 191 [5632/8000 (70%)]\tTotal Loss: 0.440566\n",
      "Reconstruction: 0.375470, Regularization: 0.000006, Discriminator: 0.043415; Generator: 0.021675,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 01:01:00,354 root         INFO     Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 0.442133\n",
      "Reconstruction: 0.377051, Regularization: 0.000003, Discriminator: 0.043351; Generator: 0.021727,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:01:00,464 root         INFO     Train Epoch: 191 [6656/8000 (83%)]\tTotal Loss: 0.443667\n",
      "Reconstruction: 0.378537, Regularization: 0.000004, Discriminator: 0.043362; Generator: 0.021765,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 01:01:00,574 root         INFO     Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 0.445291\n",
      "Reconstruction: 0.380284, Regularization: 0.000003, Discriminator: 0.043316; Generator: 0.021688,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:00,683 root         INFO     Train Epoch: 191 [7680/8000 (96%)]\tTotal Loss: 0.446908\n",
      "Reconstruction: 0.381800, Regularization: 0.000002, Discriminator: 0.043399; Generator: 0.021706,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:01:00,763 root         INFO     ====> Epoch: 191 Average loss: 0.4383\n",
      "2019-04-10 01:01:00,790 root         INFO     Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 0.447842\n",
      "Reconstruction: 0.382801, Regularization: 0.000002, Discriminator: 0.043281; Generator: 0.021758,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-10 01:01:00,896 root         INFO     Train Epoch: 192 [512/8000 (6%)]\tTotal Loss: 0.449407\n",
      "Reconstruction: 0.384261, Regularization: 0.000002, Discriminator: 0.043352; Generator: 0.021791,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-10 01:01:01,002 root         INFO     Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 0.450385\n",
      "Reconstruction: 0.385299, Regularization: 0.000003, Discriminator: 0.043335; Generator: 0.021748,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:01:01,109 root         INFO     Train Epoch: 192 [1536/8000 (19%)]\tTotal Loss: 0.451535\n",
      "Reconstruction: 0.386441, Regularization: 0.000002, Discriminator: 0.043339; Generator: 0.021753,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:01:01,216 root         INFO     Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.452335\n",
      "Reconstruction: 0.387189, Regularization: 0.000002, Discriminator: 0.043343; Generator: 0.021801,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-10 01:01:01,322 root         INFO     Train Epoch: 192 [2560/8000 (32%)]\tTotal Loss: 0.452229\n",
      "Reconstruction: 0.387143, Regularization: 0.000003, Discriminator: 0.043320; Generator: 0.021764,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-10 01:01:01,429 root         INFO     Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 0.451992\n",
      "Reconstruction: 0.386843, Regularization: 0.000002, Discriminator: 0.043335; Generator: 0.021811,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-10 01:01:01,537 root         INFO     Train Epoch: 192 [3584/8000 (45%)]\tTotal Loss: 0.451073\n",
      "Reconstruction: 0.386066, Regularization: 0.000003, Discriminator: 0.043271; Generator: 0.021733,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:01:01,644 root         INFO     Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 0.449904\n",
      "Reconstruction: 0.384828, Regularization: 0.000004, Discriminator: 0.043340; Generator: 0.021732,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:01,751 root         INFO     Train Epoch: 192 [4608/8000 (58%)]\tTotal Loss: 0.448123\n",
      "Reconstruction: 0.383186, Regularization: 0.000003, Discriminator: 0.043195; Generator: 0.021738,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-10 01:01:01,857 root         INFO     Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 0.446019\n",
      "Reconstruction: 0.381074, Regularization: 0.000002, Discriminator: 0.043206; Generator: 0.021737,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-10 01:01:01,963 root         INFO     Train Epoch: 192 [5632/8000 (70%)]\tTotal Loss: 0.443630\n",
      "Reconstruction: 0.378618, Regularization: 0.000001, Discriminator: 0.043259; Generator: 0.021752,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:01:02,070 root         INFO     Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 0.440826\n",
      "Reconstruction: 0.375820, Regularization: 0.000001, Discriminator: 0.043362; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:02,177 root         INFO     Train Epoch: 192 [6656/8000 (83%)]\tTotal Loss: 0.438443\n",
      "Reconstruction: 0.373402, Regularization: 0.000001, Discriminator: 0.043406; Generator: 0.021634,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:01:02,284 root         INFO     Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 0.436296\n",
      "Reconstruction: 0.371425, Regularization: 0.000001, Discriminator: 0.043255; Generator: 0.021615,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:01:02,390 root         INFO     Train Epoch: 192 [7680/8000 (96%)]\tTotal Loss: 0.434752\n",
      "Reconstruction: 0.369822, Regularization: 0.000001, Discriminator: 0.043304; Generator: 0.021625,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:02,469 root         INFO     ====> Epoch: 192 Average loss: 0.4465\n",
      "2019-04-10 01:01:02,496 root         INFO     Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 0.434086\n",
      "Reconstruction: 0.369153, Regularization: 0.000001, Discriminator: 0.043325; Generator: 0.021608,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:02,605 root         INFO     Train Epoch: 193 [512/8000 (6%)]\tTotal Loss: 0.432979\n",
      "Reconstruction: 0.368047, Regularization: 0.000001, Discriminator: 0.043305; Generator: 0.021626,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:02,714 root         INFO     Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 0.432413\n",
      "Reconstruction: 0.367469, Regularization: 0.000001, Discriminator: 0.043293; Generator: 0.021650,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:01:02,822 root         INFO     Train Epoch: 193 [1536/8000 (19%)]\tTotal Loss: 0.431703\n",
      "Reconstruction: 0.366793, Regularization: 0.000001, Discriminator: 0.043335; Generator: 0.021573,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:02,931 root         INFO     Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 0.431421\n",
      "Reconstruction: 0.366465, Regularization: 0.000001, Discriminator: 0.043345; Generator: 0.021610,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:01:03,040 root         INFO     Train Epoch: 193 [2560/8000 (32%)]\tTotal Loss: 0.431369\n",
      "Reconstruction: 0.366482, Regularization: 0.000001, Discriminator: 0.043305; Generator: 0.021581,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:01:03,149 root         INFO     Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 0.431771\n",
      "Reconstruction: 0.366860, Regularization: 0.000001, Discriminator: 0.043344; Generator: 0.021567,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-10 01:01:03,258 root         INFO     Train Epoch: 193 [3584/8000 (45%)]\tTotal Loss: 0.432209\n",
      "Reconstruction: 0.367251, Regularization: 0.000001, Discriminator: 0.043341; Generator: 0.021617,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:01:03,367 root         INFO     Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 0.432736\n",
      "Reconstruction: 0.367850, Regularization: 0.000000, Discriminator: 0.043316; Generator: 0.021569,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:01:03,476 root         INFO     Train Epoch: 193 [4608/8000 (58%)]\tTotal Loss: 0.433619\n",
      "Reconstruction: 0.368661, Regularization: 0.000001, Discriminator: 0.043364; Generator: 0.021593,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:01:03,585 root         INFO     Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 0.434129\n",
      "Reconstruction: 0.369224, Regularization: 0.000001, Discriminator: 0.043314; Generator: 0.021591,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:03,694 root         INFO     Train Epoch: 193 [5632/8000 (70%)]\tTotal Loss: 0.434999\n",
      "Reconstruction: 0.370022, Regularization: 0.000000, Discriminator: 0.043335; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:03,803 root         INFO     Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 0.435633\n",
      "Reconstruction: 0.370660, Regularization: 0.000001, Discriminator: 0.043317; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:03,912 root         INFO     Train Epoch: 193 [6656/8000 (83%)]\tTotal Loss: 0.436193\n",
      "Reconstruction: 0.371286, Regularization: 0.000001, Discriminator: 0.043304; Generator: 0.021602,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:04,021 root         INFO     Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 0.436530\n",
      "Reconstruction: 0.371600, Regularization: 0.000001, Discriminator: 0.043303; Generator: 0.021625,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:04,130 root         INFO     Train Epoch: 193 [7680/8000 (96%)]\tTotal Loss: 0.436732\n",
      "Reconstruction: 0.371842, Regularization: 0.000001, Discriminator: 0.043292; Generator: 0.021598,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:04,210 root         INFO     ====> Epoch: 193 Average loss: 0.4336\n",
      "2019-04-10 01:01:04,237 root         INFO     Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 0.436976\n",
      "Reconstruction: 0.372041, Regularization: 0.000001, Discriminator: 0.043323; Generator: 0.021611,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:04,347 root         INFO     Train Epoch: 194 [512/8000 (6%)]\tTotal Loss: 0.437202\n",
      "Reconstruction: 0.372342, Regularization: 0.000001, Discriminator: 0.043280; Generator: 0.021579,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:01:04,456 root         INFO     Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 0.437484\n",
      "Reconstruction: 0.372528, Regularization: 0.000001, Discriminator: 0.043308; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:04,566 root         INFO     Train Epoch: 194 [1536/8000 (19%)]\tTotal Loss: 0.437921\n",
      "Reconstruction: 0.372968, Regularization: 0.000002, Discriminator: 0.043281; Generator: 0.021670,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:01:04,676 root         INFO     Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 0.438217\n",
      "Reconstruction: 0.373220, Regularization: 0.000002, Discriminator: 0.043362; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:04,785 root         INFO     Train Epoch: 194 [2560/8000 (32%)]\tTotal Loss: 0.438808\n",
      "Reconstruction: 0.373853, Regularization: 0.000003, Discriminator: 0.043304; Generator: 0.021646,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:01:04,897 root         INFO     Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 0.439287\n",
      "Reconstruction: 0.374294, Regularization: 0.000002, Discriminator: 0.043349; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:05,008 root         INFO     Train Epoch: 194 [3584/8000 (45%)]\tTotal Loss: 0.440024\n",
      "Reconstruction: 0.375005, Regularization: 0.000004, Discriminator: 0.043328; Generator: 0.021687,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:01:05,119 root         INFO     Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 0.441079\n",
      "Reconstruction: 0.375997, Regularization: 0.000003, Discriminator: 0.043330; Generator: 0.021748,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:01:05,231 root         INFO     Train Epoch: 194 [4608/8000 (58%)]\tTotal Loss: 0.441842\n",
      "Reconstruction: 0.376753, Regularization: 0.000003, Discriminator: 0.043397; Generator: 0.021688,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 01:01:05,341 root         INFO     Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 0.442678\n",
      "Reconstruction: 0.377638, Regularization: 0.000002, Discriminator: 0.043329; Generator: 0.021709,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:05,452 root         INFO     Train Epoch: 194 [5632/8000 (70%)]\tTotal Loss: 0.443755\n",
      "Reconstruction: 0.378663, Regularization: 0.000002, Discriminator: 0.043340; Generator: 0.021750,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:01:05,562 root         INFO     Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 0.444727\n",
      "Reconstruction: 0.379643, Regularization: 0.000001, Discriminator: 0.043370; Generator: 0.021713,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:01:05,673 root         INFO     Train Epoch: 194 [6656/8000 (83%)]\tTotal Loss: 0.445482\n",
      "Reconstruction: 0.380443, Regularization: 0.000002, Discriminator: 0.043342; Generator: 0.021696,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:05,783 root         INFO     Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 0.446475\n",
      "Reconstruction: 0.381411, Regularization: 0.000002, Discriminator: 0.043317; Generator: 0.021745,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:05,893 root         INFO     Train Epoch: 194 [7680/8000 (96%)]\tTotal Loss: 0.447275\n",
      "Reconstruction: 0.382283, Regularization: 0.000003, Discriminator: 0.043321; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:05,973 root         INFO     ====> Epoch: 194 Average loss: 0.4414\n",
      "2019-04-10 01:01:06,001 root         INFO     Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 0.447920\n",
      "Reconstruction: 0.382884, Regularization: 0.000004, Discriminator: 0.043346; Generator: 0.021687,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:01:06,114 root         INFO     Train Epoch: 195 [512/8000 (6%)]\tTotal Loss: 0.448516\n",
      "Reconstruction: 0.383467, Regularization: 0.000003, Discriminator: 0.043342; Generator: 0.021704,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:06,227 root         INFO     Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 0.448970\n",
      "Reconstruction: 0.383925, Regularization: 0.000004, Discriminator: 0.043297; Generator: 0.021745,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:06,340 root         INFO     Train Epoch: 195 [1536/8000 (19%)]\tTotal Loss: 0.449336\n",
      "Reconstruction: 0.384316, Regularization: 0.000003, Discriminator: 0.043303; Generator: 0.021714,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:06,452 root         INFO     Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 0.449282\n",
      "Reconstruction: 0.384247, Regularization: 0.000004, Discriminator: 0.043314; Generator: 0.021717,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:06,564 root         INFO     Train Epoch: 195 [2560/8000 (32%)]\tTotal Loss: 0.448932\n",
      "Reconstruction: 0.383947, Regularization: 0.000004, Discriminator: 0.043309; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:06,677 root         INFO     Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 0.448396\n",
      "Reconstruction: 0.383359, Regularization: 0.000004, Discriminator: 0.043332; Generator: 0.021700,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:06,789 root         INFO     Train Epoch: 195 [3584/8000 (45%)]\tTotal Loss: 0.447724\n",
      "Reconstruction: 0.382684, Regularization: 0.000004, Discriminator: 0.043317; Generator: 0.021720,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:06,902 root         INFO     Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 0.446453\n",
      "Reconstruction: 0.381393, Regularization: 0.000002, Discriminator: 0.043328; Generator: 0.021730,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:07,013 root         INFO     Train Epoch: 195 [4608/8000 (58%)]\tTotal Loss: 0.444440\n",
      "Reconstruction: 0.379498, Regularization: 0.000002, Discriminator: 0.043253; Generator: 0.021687,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:01:07,124 root         INFO     Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 0.442216\n",
      "Reconstruction: 0.377260, Regularization: 0.000001, Discriminator: 0.043282; Generator: 0.021673,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:01:07,235 root         INFO     Train Epoch: 195 [5632/8000 (70%)]\tTotal Loss: 0.439746\n",
      "Reconstruction: 0.374799, Regularization: 0.000000, Discriminator: 0.043287; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:01:07,347 root         INFO     Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 0.437712\n",
      "Reconstruction: 0.372683, Regularization: 0.000001, Discriminator: 0.043390; Generator: 0.021639,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:01:07,458 root         INFO     Train Epoch: 195 [6656/8000 (83%)]\tTotal Loss: 0.435880\n",
      "Reconstruction: 0.370984, Regularization: 0.000000, Discriminator: 0.043228; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:01:07,570 root         INFO     Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 0.434269\n",
      "Reconstruction: 0.369281, Regularization: 0.000000, Discriminator: 0.043301; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:07,681 root         INFO     Train Epoch: 195 [7680/8000 (96%)]\tTotal Loss: 0.432721\n",
      "Reconstruction: 0.367643, Regularization: 0.000003, Discriminator: 0.043413; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:01:07,763 root         INFO     ====> Epoch: 195 Average loss: 0.4437\n",
      "2019-04-10 01:01:07,790 root         INFO     Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 0.431738\n",
      "Reconstruction: 0.366772, Regularization: 0.000003, Discriminator: 0.043354; Generator: 0.021609,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:01:07,901 root         INFO     Train Epoch: 196 [512/8000 (6%)]\tTotal Loss: 0.430930\n",
      "Reconstruction: 0.365987, Regularization: 0.000003, Discriminator: 0.043369; Generator: 0.021571,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:08,011 root         INFO     Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 0.430432\n",
      "Reconstruction: 0.365504, Regularization: 0.000003, Discriminator: 0.043333; Generator: 0.021592,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:08,122 root         INFO     Train Epoch: 196 [1536/8000 (19%)]\tTotal Loss: 0.430158\n",
      "Reconstruction: 0.365268, Regularization: 0.000002, Discriminator: 0.043316; Generator: 0.021572,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:01:08,232 root         INFO     Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 0.430674\n",
      "Reconstruction: 0.365722, Regularization: 0.000003, Discriminator: 0.043346; Generator: 0.021603,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:08,342 root         INFO     Train Epoch: 196 [2560/8000 (32%)]\tTotal Loss: 0.431333\n",
      "Reconstruction: 0.366342, Regularization: 0.000002, Discriminator: 0.043332; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:08,452 root         INFO     Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 0.431877\n",
      "Reconstruction: 0.366913, Regularization: 0.000002, Discriminator: 0.043320; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:08,563 root         INFO     Train Epoch: 196 [3584/8000 (45%)]\tTotal Loss: 0.432800\n",
      "Reconstruction: 0.367926, Regularization: 0.000002, Discriminator: 0.043304; Generator: 0.021568,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:01:08,673 root         INFO     Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 0.433695\n",
      "Reconstruction: 0.368777, Regularization: 0.000002, Discriminator: 0.043317; Generator: 0.021599,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:08,781 root         INFO     Train Epoch: 196 [4608/8000 (58%)]\tTotal Loss: 0.434533\n",
      "Reconstruction: 0.369615, Regularization: 0.000003, Discriminator: 0.043344; Generator: 0.021571,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:08,889 root         INFO     Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 0.435563\n",
      "Reconstruction: 0.370609, Regularization: 0.000005, Discriminator: 0.043292; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:01:08,998 root         INFO     Train Epoch: 196 [5632/8000 (70%)]\tTotal Loss: 0.436582\n",
      "Reconstruction: 0.371642, Regularization: 0.000005, Discriminator: 0.043331; Generator: 0.021603,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:09,106 root         INFO     Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 0.437460\n",
      "Reconstruction: 0.372548, Regularization: 0.000004, Discriminator: 0.043286; Generator: 0.021622,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:09,214 root         INFO     Train Epoch: 196 [6656/8000 (83%)]\tTotal Loss: 0.437836\n",
      "Reconstruction: 0.372944, Regularization: 0.000003, Discriminator: 0.043309; Generator: 0.021580,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-10 01:01:09,323 root         INFO     Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 0.438407\n",
      "Reconstruction: 0.373472, Regularization: 0.000003, Discriminator: 0.043282; Generator: 0.021650,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:01:09,431 root         INFO     Train Epoch: 196 [7680/8000 (96%)]\tTotal Loss: 0.438825\n",
      "Reconstruction: 0.373878, Regularization: 0.000003, Discriminator: 0.043327; Generator: 0.021618,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:09,511 root         INFO     ====> Epoch: 196 Average loss: 0.4340\n",
      "2019-04-10 01:01:09,539 root         INFO     Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 0.439032\n",
      "Reconstruction: 0.374107, Regularization: 0.000003, Discriminator: 0.043275; Generator: 0.021647,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:01:09,647 root         INFO     Train Epoch: 197 [512/8000 (6%)]\tTotal Loss: 0.439702\n",
      "Reconstruction: 0.374705, Regularization: 0.000004, Discriminator: 0.043330; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:09,755 root         INFO     Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 0.439960\n",
      "Reconstruction: 0.374962, Regularization: 0.000004, Discriminator: 0.043283; Generator: 0.021711,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:01:09,862 root         INFO     Train Epoch: 197 [1536/8000 (19%)]\tTotal Loss: 0.440286\n",
      "Reconstruction: 0.375264, Regularization: 0.000004, Discriminator: 0.043328; Generator: 0.021690,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:01:09,970 root         INFO     Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 0.440411\n",
      "Reconstruction: 0.375403, Regularization: 0.000003, Discriminator: 0.043325; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:10,078 root         INFO     Train Epoch: 197 [2560/8000 (32%)]\tTotal Loss: 0.440730\n",
      "Reconstruction: 0.375705, Regularization: 0.000003, Discriminator: 0.043342; Generator: 0.021680,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:01:10,186 root         INFO     Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 0.440882\n",
      "Reconstruction: 0.375823, Regularization: 0.000003, Discriminator: 0.043342; Generator: 0.021714,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:10,294 root         INFO     Train Epoch: 197 [3584/8000 (45%)]\tTotal Loss: 0.441399\n",
      "Reconstruction: 0.376355, Regularization: 0.000003, Discriminator: 0.043368; Generator: 0.021673,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:01:10,402 root         INFO     Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 0.442279\n",
      "Reconstruction: 0.377189, Regularization: 0.000003, Discriminator: 0.043371; Generator: 0.021715,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:01:10,510 root         INFO     Train Epoch: 197 [4608/8000 (58%)]\tTotal Loss: 0.443314\n",
      "Reconstruction: 0.378236, Regularization: 0.000003, Discriminator: 0.043346; Generator: 0.021730,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:10,618 root         INFO     Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 0.444383\n",
      "Reconstruction: 0.379307, Regularization: 0.000003, Discriminator: 0.043350; Generator: 0.021722,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:10,727 root         INFO     Train Epoch: 197 [5632/8000 (70%)]\tTotal Loss: 0.445294\n",
      "Reconstruction: 0.380308, Regularization: 0.000002, Discriminator: 0.043338; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:10,835 root         INFO     Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 0.446723\n",
      "Reconstruction: 0.381709, Regularization: 0.000003, Discriminator: 0.043268; Generator: 0.021743,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:01:10,943 root         INFO     Train Epoch: 197 [6656/8000 (83%)]\tTotal Loss: 0.448045\n",
      "Reconstruction: 0.382890, Regularization: 0.000003, Discriminator: 0.043404; Generator: 0.021748,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-10 01:01:11,051 root         INFO     Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 0.448896\n",
      "Reconstruction: 0.383798, Regularization: 0.000004, Discriminator: 0.043354; Generator: 0.021740,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-10 01:01:11,158 root         INFO     Train Epoch: 197 [7680/8000 (96%)]\tTotal Loss: 0.449274\n",
      "Reconstruction: 0.384262, Regularization: 0.000004, Discriminator: 0.043324; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:11,237 root         INFO     ====> Epoch: 197 Average loss: 0.4434\n",
      "2019-04-10 01:01:11,265 root         INFO     Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 0.449607\n",
      "Reconstruction: 0.384559, Regularization: 0.000005, Discriminator: 0.043319; Generator: 0.021725,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:11,375 root         INFO     Train Epoch: 198 [512/8000 (6%)]\tTotal Loss: 0.449600\n",
      "Reconstruction: 0.384544, Regularization: 0.000005, Discriminator: 0.043315; Generator: 0.021736,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:11,486 root         INFO     Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.449344\n",
      "Reconstruction: 0.384298, Regularization: 0.000004, Discriminator: 0.043328; Generator: 0.021713,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-10 01:01:11,596 root         INFO     Train Epoch: 198 [1536/8000 (19%)]\tTotal Loss: 0.448452\n",
      "Reconstruction: 0.383438, Regularization: 0.000003, Discriminator: 0.043314; Generator: 0.021697,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:01:11,706 root         INFO     Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 0.447096\n",
      "Reconstruction: 0.382198, Regularization: 0.000002, Discriminator: 0.043201; Generator: 0.021695,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-10 01:01:11,817 root         INFO     Train Epoch: 198 [2560/8000 (32%)]\tTotal Loss: 0.445211\n",
      "Reconstruction: 0.380230, Regularization: 0.000001, Discriminator: 0.043271; Generator: 0.021709,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-10 01:01:11,927 root         INFO     Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 0.442597\n",
      "Reconstruction: 0.377679, Regularization: 0.000001, Discriminator: 0.043237; Generator: 0.021681,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-10 01:01:12,037 root         INFO     Train Epoch: 198 [3584/8000 (45%)]\tTotal Loss: 0.439952\n",
      "Reconstruction: 0.374870, Regularization: 0.000002, Discriminator: 0.043421; Generator: 0.021660,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 01:01:12,148 root         INFO     Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 0.436953\n",
      "Reconstruction: 0.372131, Regularization: 0.000001, Discriminator: 0.043198; Generator: 0.021623,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-10 01:01:12,258 root         INFO     Train Epoch: 198 [4608/8000 (58%)]\tTotal Loss: 0.435075\n",
      "Reconstruction: 0.369934, Regularization: 0.000001, Discriminator: 0.043503; Generator: 0.021637,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-10 01:01:12,369 root         INFO     Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 0.433052\n",
      "Reconstruction: 0.368093, Regularization: 0.000000, Discriminator: 0.043335; Generator: 0.021623,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:01:12,479 root         INFO     Train Epoch: 198 [5632/8000 (70%)]\tTotal Loss: 0.431863\n",
      "Reconstruction: 0.366837, Regularization: 0.000001, Discriminator: 0.043408; Generator: 0.021617,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-10 01:01:12,589 root         INFO     Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 0.430648\n",
      "Reconstruction: 0.365710, Regularization: 0.000000, Discriminator: 0.043354; Generator: 0.021584,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:12,699 root         INFO     Train Epoch: 198 [6656/8000 (83%)]\tTotal Loss: 0.430455\n",
      "Reconstruction: 0.365486, Regularization: 0.000001, Discriminator: 0.043332; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:12,809 root         INFO     Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 0.430420\n",
      "Reconstruction: 0.365486, Regularization: 0.000001, Discriminator: 0.043346; Generator: 0.021588,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:12,919 root         INFO     Train Epoch: 198 [7680/8000 (96%)]\tTotal Loss: 0.430942\n",
      "Reconstruction: 0.365988, Regularization: 0.000000, Discriminator: 0.043328; Generator: 0.021626,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:01:12,999 root         INFO     ====> Epoch: 198 Average loss: 0.4391\n",
      "2019-04-10 01:01:13,026 root         INFO     Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 0.431222\n",
      "Reconstruction: 0.366319, Regularization: 0.000000, Discriminator: 0.043315; Generator: 0.021588,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:13,137 root         INFO     Train Epoch: 199 [512/8000 (6%)]\tTotal Loss: 0.431944\n",
      "Reconstruction: 0.367015, Regularization: 0.000000, Discriminator: 0.043330; Generator: 0.021599,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:13,248 root         INFO     Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 0.432971\n",
      "Reconstruction: 0.368017, Regularization: 0.000000, Discriminator: 0.043324; Generator: 0.021630,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-10 01:01:13,358 root         INFO     Train Epoch: 199 [1536/8000 (19%)]\tTotal Loss: 0.434140\n",
      "Reconstruction: 0.369118, Regularization: 0.000000, Discriminator: 0.043379; Generator: 0.021643,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:01:13,468 root         INFO     Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 0.434846\n",
      "Reconstruction: 0.370025, Regularization: 0.000001, Discriminator: 0.043258; Generator: 0.021563,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-10 01:01:13,579 root         INFO     Train Epoch: 199 [2560/8000 (32%)]\tTotal Loss: 0.436167\n",
      "Reconstruction: 0.371258, Regularization: 0.000000, Discriminator: 0.043317; Generator: 0.021592,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:13,689 root         INFO     Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 0.437095\n",
      "Reconstruction: 0.372114, Regularization: 0.000001, Discriminator: 0.043347; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:13,800 root         INFO     Train Epoch: 199 [3584/8000 (45%)]\tTotal Loss: 0.437812\n",
      "Reconstruction: 0.372840, Regularization: 0.000000, Discriminator: 0.043324; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:13,911 root         INFO     Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 0.438313\n",
      "Reconstruction: 0.373418, Regularization: 0.000002, Discriminator: 0.043297; Generator: 0.021596,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:14,021 root         INFO     Train Epoch: 199 [4608/8000 (58%)]\tTotal Loss: 0.438847\n",
      "Reconstruction: 0.373950, Regularization: 0.000001, Discriminator: 0.043265; Generator: 0.021629,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-10 01:01:14,133 root         INFO     Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 0.439491\n",
      "Reconstruction: 0.374537, Regularization: 0.000002, Discriminator: 0.043315; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:14,244 root         INFO     Train Epoch: 199 [5632/8000 (70%)]\tTotal Loss: 0.439884\n",
      "Reconstruction: 0.374929, Regularization: 0.000003, Discriminator: 0.043287; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:14,354 root         INFO     Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.440328\n",
      "Reconstruction: 0.375333, Regularization: 0.000003, Discriminator: 0.043344; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:14,464 root         INFO     Train Epoch: 199 [6656/8000 (83%)]\tTotal Loss: 0.440367\n",
      "Reconstruction: 0.375361, Regularization: 0.000002, Discriminator: 0.043333; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:14,574 root         INFO     Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 0.440543\n",
      "Reconstruction: 0.375567, Regularization: 0.000002, Discriminator: 0.043292; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-10 01:01:14,685 root         INFO     Train Epoch: 199 [7680/8000 (96%)]\tTotal Loss: 0.441097\n",
      "Reconstruction: 0.376066, Regularization: 0.000004, Discriminator: 0.043353; Generator: 0.021674,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-10 01:01:14,764 root         INFO     ====> Epoch: 199 Average loss: 0.4374\n",
      "2019-04-10 01:01:14,778 luigi-interface INFO     [pid 1925] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=1925) done      TrainVEM()\n",
      "2019-04-10 01:01:14,778 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-10 01:01:14,778 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   DONE\n",
      "2019-04-10 01:01:14,779 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-10 01:01:14,779 luigi-interface DEBUG    Pending tasks: 2\n",
      "2019-04-10 01:01:14,779 luigi-interface INFO     [pid 1925] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=1925) running   TrainVAE()\n",
      "2019-04-10 01:01:14,780 root         INFO     --Dataset tensor: (10000, 2)\n",
      "2019-04-10 01:01:14,780 root         INFO     -- Train tensor: (8000, 2)\n",
      "2019-04-10 01:01:14,781 root         INFO     Values of VAE's decoder parameters before training:\n",
      "2019-04-10 01:01:14,781 root         INFO     layers.0.weight\n",
      "2019-04-10 01:01:14,781 root         INFO     tensor([[-0.6497],\n",
      "        [ 0.9626]], device='cuda:0')\n",
      "2019-04-10 01:01:14,782 root         INFO     layers.0.bias\n",
      "2019-04-10 01:01:14,782 root         INFO     tensor([-0.9750, -0.2332], device='cuda:0')\n",
      "2019-04-10 01:01:14,783 root         INFO     layers.1.weight\n",
      "2019-04-10 01:01:14,784 root         INFO     tensor([[-0.1379, -0.5922],\n",
      "        [-0.2357,  0.5636]], device='cuda:0')\n",
      "2019-04-10 01:01:14,785 root         INFO     layers.1.bias\n",
      "2019-04-10 01:01:14,785 root         INFO     tensor([-0.1943,  0.0769], device='cuda:0')\n",
      "2019-04-10 01:01:14,786 root         INFO     layers.2.weight\n",
      "2019-04-10 01:01:14,786 root         INFO     tensor([[ 0.6644, -0.5124],\n",
      "        [-0.4031, -0.4051]], device='cuda:0')\n",
      "2019-04-10 01:01:14,787 root         INFO     layers.2.bias\n",
      "2019-04-10 01:01:14,787 root         INFO     tensor([-0.5565,  0.1725], device='cuda:0')\n",
      "2019-04-10 01:01:14,788 root         INFO     layers.3.weight\n",
      "2019-04-10 01:01:14,788 root         INFO     tensor([[-0.3523, -0.6266],\n",
      "        [-0.3515, -0.2904]], device='cuda:0')\n",
      "2019-04-10 01:01:14,789 root         INFO     layers.3.bias\n",
      "2019-04-10 01:01:14,789 root         INFO     tensor([-0.3550,  0.0500], device='cuda:0')\n",
      "2019-04-10 01:01:14,790 root         INFO     layers.4.weight\n",
      "2019-04-10 01:01:14,790 root         INFO     tensor([[ 0.2561, -0.3836],\n",
      "        [ 0.3839,  0.2321]], device='cuda:0')\n",
      "2019-04-10 01:01:14,791 root         INFO     layers.4.bias\n",
      "2019-04-10 01:01:14,791 root         INFO     tensor([-0.6679, -0.5838], device='cuda:0')\n",
      "2019-04-10 01:01:14,792 root         INFO     layers.5.weight\n",
      "2019-04-10 01:01:14,792 root         INFO     tensor([[-0.1573,  0.5253],\n",
      "        [ 0.6630,  0.1170]], device='cuda:0')\n",
      "2019-04-10 01:01:14,793 root         INFO     layers.5.bias\n",
      "2019-04-10 01:01:14,793 root         INFO     tensor([ 0.4975, -0.3834], device='cuda:0')\n",
      "2019-04-10 01:01:14,818 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 7.846128\n",
      "Reconstruction: 5.822622, Regularization: 2.023506\n",
      "2019-04-10 01:01:14,883 root         INFO     Train Epoch: 0 [512/8000 (6%)]\tTotal Loss: 8.413287\n",
      "Reconstruction: 6.277318, Regularization: 2.135969\n",
      "2019-04-10 01:01:14,946 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 9.838552\n",
      "Reconstruction: 7.612849, Regularization: 2.225703\n",
      "2019-04-10 01:01:15,009 root         INFO     Train Epoch: 0 [1536/8000 (19%)]\tTotal Loss: 8.005777\n",
      "Reconstruction: 5.963937, Regularization: 2.041841\n",
      "2019-04-10 01:01:15,072 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 8.195824\n",
      "Reconstruction: 5.900893, Regularization: 2.294930\n",
      "2019-04-10 01:01:15,135 root         INFO     Train Epoch: 0 [2560/8000 (32%)]\tTotal Loss: 6.514953\n",
      "Reconstruction: 4.443342, Regularization: 2.071611\n",
      "2019-04-10 01:01:15,198 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 7.841286\n",
      "Reconstruction: 5.773916, Regularization: 2.067370\n",
      "2019-04-10 01:01:15,261 root         INFO     Train Epoch: 0 [3584/8000 (45%)]\tTotal Loss: 5.635639\n",
      "Reconstruction: 3.713039, Regularization: 1.922601\n",
      "2019-04-10 01:01:15,323 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 5.959963\n",
      "Reconstruction: 3.839532, Regularization: 2.120431\n",
      "2019-04-10 01:01:15,385 root         INFO     Train Epoch: 0 [4608/8000 (58%)]\tTotal Loss: 6.695278\n",
      "Reconstruction: 4.656024, Regularization: 2.039254\n",
      "2019-04-10 01:01:15,447 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 5.305213\n",
      "Reconstruction: 3.289725, Regularization: 2.015488\n",
      "2019-04-10 01:01:15,511 root         INFO     Train Epoch: 0 [5632/8000 (70%)]\tTotal Loss: 4.243719\n",
      "Reconstruction: 2.559018, Regularization: 1.684701\n",
      "2019-04-10 01:01:15,575 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 4.396250\n",
      "Reconstruction: 2.560688, Regularization: 1.835562\n",
      "2019-04-10 01:01:15,638 root         INFO     Train Epoch: 0 [6656/8000 (83%)]\tTotal Loss: 3.436491\n",
      "Reconstruction: 1.844266, Regularization: 1.592225\n",
      "2019-04-10 01:01:15,702 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 4.057766\n",
      "Reconstruction: 2.367594, Regularization: 1.690172\n",
      "2019-04-10 01:01:15,765 root         INFO     Train Epoch: 0 [7680/8000 (96%)]\tTotal Loss: 4.591332\n",
      "Reconstruction: 2.648365, Regularization: 1.942967\n",
      "2019-04-10 01:01:15,820 root         INFO     ====> Epoch: 0 Average loss: 5.9170\n",
      "2019-04-10 01:01:15,843 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 4.516862\n",
      "Reconstruction: 2.647501, Regularization: 1.869361\n",
      "2019-04-10 01:01:15,907 root         INFO     Train Epoch: 1 [512/8000 (6%)]\tTotal Loss: 4.078029\n",
      "Reconstruction: 2.211078, Regularization: 1.866951\n",
      "2019-04-10 01:01:15,971 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 4.302875\n",
      "Reconstruction: 2.348512, Regularization: 1.954363\n",
      "2019-04-10 01:01:16,035 root         INFO     Train Epoch: 1 [1536/8000 (19%)]\tTotal Loss: 4.783562\n",
      "Reconstruction: 2.696194, Regularization: 2.087368\n",
      "2019-04-10 01:01:16,098 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 3.796474\n",
      "Reconstruction: 2.057569, Regularization: 1.738905\n",
      "2019-04-10 01:01:16,162 root         INFO     Train Epoch: 1 [2560/8000 (32%)]\tTotal Loss: 4.193924\n",
      "Reconstruction: 2.346587, Regularization: 1.847337\n",
      "2019-04-10 01:01:16,226 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 3.769621\n",
      "Reconstruction: 1.991831, Regularization: 1.777790\n",
      "2019-04-10 01:01:16,290 root         INFO     Train Epoch: 1 [3584/8000 (45%)]\tTotal Loss: 4.118927\n",
      "Reconstruction: 2.314456, Regularization: 1.804471\n",
      "2019-04-10 01:01:16,354 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 3.339290\n",
      "Reconstruction: 1.657040, Regularization: 1.682250\n",
      "2019-04-10 01:01:16,418 root         INFO     Train Epoch: 1 [4608/8000 (58%)]\tTotal Loss: 3.663706\n",
      "Reconstruction: 1.797652, Regularization: 1.866054\n",
      "2019-04-10 01:01:16,482 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 3.613206\n",
      "Reconstruction: 1.778797, Regularization: 1.834409\n",
      "2019-04-10 01:01:16,546 root         INFO     Train Epoch: 1 [5632/8000 (70%)]\tTotal Loss: 3.790715\n",
      "Reconstruction: 1.860723, Regularization: 1.929992\n",
      "2019-04-10 01:01:16,610 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 3.275140\n",
      "Reconstruction: 1.521680, Regularization: 1.753460\n",
      "2019-04-10 01:01:16,674 root         INFO     Train Epoch: 1 [6656/8000 (83%)]\tTotal Loss: 2.949405\n",
      "Reconstruction: 1.331964, Regularization: 1.617441\n",
      "2019-04-10 01:01:16,737 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 3.229370\n",
      "Reconstruction: 1.440584, Regularization: 1.788786\n",
      "2019-04-10 01:01:16,801 root         INFO     Train Epoch: 1 [7680/8000 (96%)]\tTotal Loss: 3.297959\n",
      "Reconstruction: 1.549875, Regularization: 1.748084\n",
      "2019-04-10 01:01:16,855 root         INFO     ====> Epoch: 1 Average loss: 3.6930\n",
      "2019-04-10 01:01:16,879 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 3.226807\n",
      "Reconstruction: 1.474194, Regularization: 1.752613\n",
      "2019-04-10 01:01:16,943 root         INFO     Train Epoch: 2 [512/8000 (6%)]\tTotal Loss: 2.941768\n",
      "Reconstruction: 1.319247, Regularization: 1.622521\n",
      "2019-04-10 01:01:17,007 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 2.984887\n",
      "Reconstruction: 1.211312, Regularization: 1.773575\n",
      "2019-04-10 01:01:17,071 root         INFO     Train Epoch: 2 [1536/8000 (19%)]\tTotal Loss: 2.971921\n",
      "Reconstruction: 1.231864, Regularization: 1.740058\n",
      "2019-04-10 01:01:17,134 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 3.007573\n",
      "Reconstruction: 1.354121, Regularization: 1.653452\n",
      "2019-04-10 01:01:17,198 root         INFO     Train Epoch: 2 [2560/8000 (32%)]\tTotal Loss: 2.706620\n",
      "Reconstruction: 1.090011, Regularization: 1.616609\n",
      "2019-04-10 01:01:17,261 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 3.123540\n",
      "Reconstruction: 1.304878, Regularization: 1.818663\n",
      "2019-04-10 01:01:17,322 root         INFO     Train Epoch: 2 [3584/8000 (45%)]\tTotal Loss: 2.989657\n",
      "Reconstruction: 1.305538, Regularization: 1.684119\n",
      "2019-04-10 01:01:17,383 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 2.922275\n",
      "Reconstruction: 1.213032, Regularization: 1.709242\n",
      "2019-04-10 01:01:17,445 root         INFO     Train Epoch: 2 [4608/8000 (58%)]\tTotal Loss: 2.581858\n",
      "Reconstruction: 1.026107, Regularization: 1.555750\n",
      "2019-04-10 01:01:17,506 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 2.807855\n",
      "Reconstruction: 1.098133, Regularization: 1.709722\n",
      "2019-04-10 01:01:17,569 root         INFO     Train Epoch: 2 [5632/8000 (70%)]\tTotal Loss: 2.739797\n",
      "Reconstruction: 1.066094, Regularization: 1.673703\n",
      "2019-04-10 01:01:17,632 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 2.576900\n",
      "Reconstruction: 1.015538, Regularization: 1.561362\n",
      "2019-04-10 01:01:17,695 root         INFO     Train Epoch: 2 [6656/8000 (83%)]\tTotal Loss: 2.576222\n",
      "Reconstruction: 0.904626, Regularization: 1.671596\n",
      "2019-04-10 01:01:17,759 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 2.720789\n",
      "Reconstruction: 1.121733, Regularization: 1.599056\n",
      "2019-04-10 01:01:17,822 root         INFO     Train Epoch: 2 [7680/8000 (96%)]\tTotal Loss: 2.186319\n",
      "Reconstruction: 0.825734, Regularization: 1.360585\n",
      "2019-04-10 01:01:17,876 root         INFO     ====> Epoch: 2 Average loss: 2.8377\n",
      "2019-04-10 01:01:17,900 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 2.821987\n",
      "Reconstruction: 1.082294, Regularization: 1.739693\n",
      "2019-04-10 01:01:17,964 root         INFO     Train Epoch: 3 [512/8000 (6%)]\tTotal Loss: 2.776740\n",
      "Reconstruction: 1.042758, Regularization: 1.733982\n",
      "2019-04-10 01:01:18,028 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 2.432557\n",
      "Reconstruction: 0.905513, Regularization: 1.527044\n",
      "2019-04-10 01:01:18,091 root         INFO     Train Epoch: 3 [1536/8000 (19%)]\tTotal Loss: 2.565416\n",
      "Reconstruction: 0.985581, Regularization: 1.579835\n",
      "2019-04-10 01:01:18,154 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 2.613748\n",
      "Reconstruction: 0.944351, Regularization: 1.669397\n",
      "2019-04-10 01:01:18,218 root         INFO     Train Epoch: 3 [2560/8000 (32%)]\tTotal Loss: 2.127670\n",
      "Reconstruction: 0.735927, Regularization: 1.391743\n",
      "2019-04-10 01:01:18,281 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 2.555143\n",
      "Reconstruction: 0.943851, Regularization: 1.611292\n",
      "2019-04-10 01:01:18,344 root         INFO     Train Epoch: 3 [3584/8000 (45%)]\tTotal Loss: 2.521966\n",
      "Reconstruction: 0.903550, Regularization: 1.618416\n",
      "2019-04-10 01:01:18,407 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 2.340497\n",
      "Reconstruction: 0.832395, Regularization: 1.508101\n",
      "2019-04-10 01:01:18,470 root         INFO     Train Epoch: 3 [4608/8000 (58%)]\tTotal Loss: 2.351327\n",
      "Reconstruction: 0.799344, Regularization: 1.551983\n",
      "2019-04-10 01:01:18,533 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 2.513913\n",
      "Reconstruction: 0.877846, Regularization: 1.636068\n",
      "2019-04-10 01:01:18,596 root         INFO     Train Epoch: 3 [5632/8000 (70%)]\tTotal Loss: 2.224570\n",
      "Reconstruction: 0.722848, Regularization: 1.501722\n",
      "2019-04-10 01:01:18,659 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 2.081425\n",
      "Reconstruction: 0.685854, Regularization: 1.395571\n",
      "2019-04-10 01:01:18,722 root         INFO     Train Epoch: 3 [6656/8000 (83%)]\tTotal Loss: 2.457030\n",
      "Reconstruction: 0.860777, Regularization: 1.596253\n",
      "2019-04-10 01:01:18,785 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 2.238989\n",
      "Reconstruction: 0.756335, Regularization: 1.482655\n",
      "2019-04-10 01:01:18,848 root         INFO     Train Epoch: 3 [7680/8000 (96%)]\tTotal Loss: 2.201826\n",
      "Reconstruction: 0.725753, Regularization: 1.476073\n",
      "2019-04-10 01:01:18,903 root         INFO     ====> Epoch: 3 Average loss: 2.3662\n",
      "2019-04-10 01:01:18,926 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 2.476554\n",
      "Reconstruction: 0.881592, Regularization: 1.594962\n",
      "2019-04-10 01:01:18,990 root         INFO     Train Epoch: 4 [512/8000 (6%)]\tTotal Loss: 1.919015\n",
      "Reconstruction: 0.609200, Regularization: 1.309815\n",
      "2019-04-10 01:01:19,053 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 2.129502\n",
      "Reconstruction: 0.707603, Regularization: 1.421899\n",
      "2019-04-10 01:01:19,116 root         INFO     Train Epoch: 4 [1536/8000 (19%)]\tTotal Loss: 2.099548\n",
      "Reconstruction: 0.688904, Regularization: 1.410644\n",
      "2019-04-10 01:01:19,180 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 2.221757\n",
      "Reconstruction: 0.730815, Regularization: 1.490942\n",
      "2019-04-10 01:01:19,243 root         INFO     Train Epoch: 4 [2560/8000 (32%)]\tTotal Loss: 2.043515\n",
      "Reconstruction: 0.654012, Regularization: 1.389503\n",
      "2019-04-10 01:01:19,306 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 1.934004\n",
      "Reconstruction: 0.615341, Regularization: 1.318663\n",
      "2019-04-10 01:01:19,369 root         INFO     Train Epoch: 4 [3584/8000 (45%)]\tTotal Loss: 1.959178\n",
      "Reconstruction: 0.621513, Regularization: 1.337665\n",
      "2019-04-10 01:01:19,433 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 2.066052\n",
      "Reconstruction: 0.646848, Regularization: 1.419205\n",
      "2019-04-10 01:01:19,496 root         INFO     Train Epoch: 4 [4608/8000 (58%)]\tTotal Loss: 1.918634\n",
      "Reconstruction: 0.632365, Regularization: 1.286269\n",
      "2019-04-10 01:01:19,560 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 1.816303\n",
      "Reconstruction: 0.552644, Regularization: 1.263659\n",
      "2019-04-10 01:01:19,624 root         INFO     Train Epoch: 4 [5632/8000 (70%)]\tTotal Loss: 2.074056\n",
      "Reconstruction: 0.653444, Regularization: 1.420612\n",
      "2019-04-10 01:01:19,687 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 1.964914\n",
      "Reconstruction: 0.615631, Regularization: 1.349283\n",
      "2019-04-10 01:01:19,751 root         INFO     Train Epoch: 4 [6656/8000 (83%)]\tTotal Loss: 1.863555\n",
      "Reconstruction: 0.574770, Regularization: 1.288785\n",
      "2019-04-10 01:01:19,815 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 2.010751\n",
      "Reconstruction: 0.605424, Regularization: 1.405326\n",
      "2019-04-10 01:01:19,879 root         INFO     Train Epoch: 4 [7680/8000 (96%)]\tTotal Loss: 1.956338\n",
      "Reconstruction: 0.632066, Regularization: 1.324272\n",
      "2019-04-10 01:01:19,933 root         INFO     ====> Epoch: 4 Average loss: 2.0464\n",
      "2019-04-10 01:01:19,957 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 1.922698\n",
      "Reconstruction: 0.595462, Regularization: 1.327236\n",
      "2019-04-10 01:01:20,021 root         INFO     Train Epoch: 5 [512/8000 (6%)]\tTotal Loss: 1.835512\n",
      "Reconstruction: 0.546823, Regularization: 1.288689\n",
      "2019-04-10 01:01:20,084 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 1.851112\n",
      "Reconstruction: 0.543433, Regularization: 1.307678\n",
      "2019-04-10 01:01:20,147 root         INFO     Train Epoch: 5 [1536/8000 (19%)]\tTotal Loss: 1.848418\n",
      "Reconstruction: 0.550852, Regularization: 1.297566\n",
      "2019-04-10 01:01:20,210 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 1.910086\n",
      "Reconstruction: 0.569079, Regularization: 1.341006\n",
      "2019-04-10 01:01:20,273 root         INFO     Train Epoch: 5 [2560/8000 (32%)]\tTotal Loss: 1.813897\n",
      "Reconstruction: 0.557353, Regularization: 1.256544\n",
      "2019-04-10 01:01:20,335 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 1.854205\n",
      "Reconstruction: 0.565644, Regularization: 1.288562\n",
      "2019-04-10 01:01:20,397 root         INFO     Train Epoch: 5 [3584/8000 (45%)]\tTotal Loss: 1.828524\n",
      "Reconstruction: 0.559240, Regularization: 1.269285\n",
      "2019-04-10 01:01:20,459 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 1.849199\n",
      "Reconstruction: 0.555731, Regularization: 1.293468\n",
      "2019-04-10 01:01:20,522 root         INFO     Train Epoch: 5 [4608/8000 (58%)]\tTotal Loss: 1.680243\n",
      "Reconstruction: 0.492978, Regularization: 1.187265\n",
      "2019-04-10 01:01:20,584 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 1.767912\n",
      "Reconstruction: 0.540259, Regularization: 1.227652\n",
      "2019-04-10 01:01:20,647 root         INFO     Train Epoch: 5 [5632/8000 (70%)]\tTotal Loss: 1.692923\n",
      "Reconstruction: 0.511615, Regularization: 1.181308\n",
      "2019-04-10 01:01:20,709 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 1.575253\n",
      "Reconstruction: 0.492866, Regularization: 1.082387\n",
      "2019-04-10 01:01:20,771 root         INFO     Train Epoch: 5 [6656/8000 (83%)]\tTotal Loss: 1.696414\n",
      "Reconstruction: 0.502907, Regularization: 1.193507\n",
      "2019-04-10 01:01:20,833 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 1.636989\n",
      "Reconstruction: 0.517247, Regularization: 1.119742\n",
      "2019-04-10 01:01:20,896 root         INFO     Train Epoch: 5 [7680/8000 (96%)]\tTotal Loss: 1.840420\n",
      "Reconstruction: 0.526426, Regularization: 1.313994\n",
      "2019-04-10 01:01:20,949 root         INFO     ====> Epoch: 5 Average loss: 1.8028\n",
      "2019-04-10 01:01:20,973 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 1.600116\n",
      "Reconstruction: 0.458291, Regularization: 1.141826\n",
      "2019-04-10 01:01:21,036 root         INFO     Train Epoch: 6 [512/8000 (6%)]\tTotal Loss: 1.696499\n",
      "Reconstruction: 0.506814, Regularization: 1.189685\n",
      "2019-04-10 01:01:21,098 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 1.788874\n",
      "Reconstruction: 0.514238, Regularization: 1.274635\n",
      "2019-04-10 01:01:21,160 root         INFO     Train Epoch: 6 [1536/8000 (19%)]\tTotal Loss: 1.611800\n",
      "Reconstruction: 0.509035, Regularization: 1.102765\n",
      "2019-04-10 01:01:21,223 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 1.778802\n",
      "Reconstruction: 0.528565, Regularization: 1.250237\n",
      "2019-04-10 01:01:21,286 root         INFO     Train Epoch: 6 [2560/8000 (32%)]\tTotal Loss: 1.586181\n",
      "Reconstruction: 0.468215, Regularization: 1.117966\n",
      "2019-04-10 01:01:21,348 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 1.635080\n",
      "Reconstruction: 0.482514, Regularization: 1.152565\n",
      "2019-04-10 01:01:21,411 root         INFO     Train Epoch: 6 [3584/8000 (45%)]\tTotal Loss: 1.639012\n",
      "Reconstruction: 0.459979, Regularization: 1.179033\n",
      "2019-04-10 01:01:21,474 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 1.540697\n",
      "Reconstruction: 0.457471, Regularization: 1.083225\n",
      "2019-04-10 01:01:21,536 root         INFO     Train Epoch: 6 [4608/8000 (58%)]\tTotal Loss: 1.566013\n",
      "Reconstruction: 0.474497, Regularization: 1.091516\n",
      "2019-04-10 01:01:21,599 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 1.671371\n",
      "Reconstruction: 0.506879, Regularization: 1.164493\n",
      "2019-04-10 01:01:21,662 root         INFO     Train Epoch: 6 [5632/8000 (70%)]\tTotal Loss: 1.571970\n",
      "Reconstruction: 0.456164, Regularization: 1.115806\n",
      "2019-04-10 01:01:21,724 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 1.542897\n",
      "Reconstruction: 0.468690, Regularization: 1.074206\n",
      "2019-04-10 01:01:21,786 root         INFO     Train Epoch: 6 [6656/8000 (83%)]\tTotal Loss: 1.420987\n",
      "Reconstruction: 0.447331, Regularization: 0.973656\n",
      "2019-04-10 01:01:21,848 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 1.612988\n",
      "Reconstruction: 0.480425, Regularization: 1.132563\n",
      "2019-04-10 01:01:21,910 root         INFO     Train Epoch: 6 [7680/8000 (96%)]\tTotal Loss: 1.457762\n",
      "Reconstruction: 0.419363, Regularization: 1.038399\n",
      "2019-04-10 01:01:21,964 root         INFO     ====> Epoch: 6 Average loss: 1.6013\n",
      "2019-04-10 01:01:21,988 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 1.462578\n",
      "Reconstruction: 0.465566, Regularization: 0.997012\n",
      "2019-04-10 01:01:22,052 root         INFO     Train Epoch: 7 [512/8000 (6%)]\tTotal Loss: 1.487853\n",
      "Reconstruction: 0.423421, Regularization: 1.064432\n",
      "2019-04-10 01:01:22,115 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 1.534561\n",
      "Reconstruction: 0.457309, Regularization: 1.077252\n",
      "2019-04-10 01:01:22,179 root         INFO     Train Epoch: 7 [1536/8000 (19%)]\tTotal Loss: 1.423517\n",
      "Reconstruction: 0.414401, Regularization: 1.009116\n",
      "2019-04-10 01:01:22,243 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 1.358875\n",
      "Reconstruction: 0.388098, Regularization: 0.970777\n",
      "2019-04-10 01:01:22,307 root         INFO     Train Epoch: 7 [2560/8000 (32%)]\tTotal Loss: 1.519001\n",
      "Reconstruction: 0.472933, Regularization: 1.046068\n",
      "2019-04-10 01:01:22,371 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 1.404087\n",
      "Reconstruction: 0.400501, Regularization: 1.003586\n",
      "2019-04-10 01:01:22,433 root         INFO     Train Epoch: 7 [3584/8000 (45%)]\tTotal Loss: 1.414639\n",
      "Reconstruction: 0.440700, Regularization: 0.973940\n",
      "2019-04-10 01:01:22,496 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 1.363746\n",
      "Reconstruction: 0.480237, Regularization: 0.883508\n",
      "2019-04-10 01:01:22,559 root         INFO     Train Epoch: 7 [4608/8000 (58%)]\tTotal Loss: 1.340477\n",
      "Reconstruction: 0.424058, Regularization: 0.916419\n",
      "2019-04-10 01:01:22,622 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 1.491851\n",
      "Reconstruction: 0.428463, Regularization: 1.063389\n",
      "2019-04-10 01:01:22,685 root         INFO     Train Epoch: 7 [5632/8000 (70%)]\tTotal Loss: 1.344443\n",
      "Reconstruction: 0.389289, Regularization: 0.955154\n",
      "2019-04-10 01:01:22,748 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 1.399423\n",
      "Reconstruction: 0.411240, Regularization: 0.988183\n",
      "2019-04-10 01:01:22,811 root         INFO     Train Epoch: 7 [6656/8000 (83%)]\tTotal Loss: 1.434729\n",
      "Reconstruction: 0.451657, Regularization: 0.983071\n",
      "2019-04-10 01:01:22,874 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 1.377908\n",
      "Reconstruction: 0.423335, Regularization: 0.954573\n",
      "2019-04-10 01:01:22,936 root         INFO     Train Epoch: 7 [7680/8000 (96%)]\tTotal Loss: 1.329967\n",
      "Reconstruction: 0.422410, Regularization: 0.907557\n",
      "2019-04-10 01:01:22,990 root         INFO     ====> Epoch: 7 Average loss: 1.4279\n",
      "2019-04-10 01:01:23,014 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 1.390210\n",
      "Reconstruction: 0.426824, Regularization: 0.963386\n",
      "2019-04-10 01:01:23,077 root         INFO     Train Epoch: 8 [512/8000 (6%)]\tTotal Loss: 1.284202\n",
      "Reconstruction: 0.415125, Regularization: 0.869077\n",
      "2019-04-10 01:01:23,140 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 1.473703\n",
      "Reconstruction: 0.455692, Regularization: 1.018012\n",
      "2019-04-10 01:01:23,202 root         INFO     Train Epoch: 8 [1536/8000 (19%)]\tTotal Loss: 1.351769\n",
      "Reconstruction: 0.413499, Regularization: 0.938271\n",
      "2019-04-10 01:01:23,265 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 1.342056\n",
      "Reconstruction: 0.398231, Regularization: 0.943825\n",
      "2019-04-10 01:01:23,327 root         INFO     Train Epoch: 8 [2560/8000 (32%)]\tTotal Loss: 1.362267\n",
      "Reconstruction: 0.416649, Regularization: 0.945618\n",
      "2019-04-10 01:01:23,391 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 1.241802\n",
      "Reconstruction: 0.382589, Regularization: 0.859212\n",
      "2019-04-10 01:01:23,454 root         INFO     Train Epoch: 8 [3584/8000 (45%)]\tTotal Loss: 1.264105\n",
      "Reconstruction: 0.357906, Regularization: 0.906199\n",
      "2019-04-10 01:01:23,516 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 1.233891\n",
      "Reconstruction: 0.378202, Regularization: 0.855689\n",
      "2019-04-10 01:01:23,579 root         INFO     Train Epoch: 8 [4608/8000 (58%)]\tTotal Loss: 1.348638\n",
      "Reconstruction: 0.411751, Regularization: 0.936887\n",
      "2019-04-10 01:01:23,642 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 1.210118\n",
      "Reconstruction: 0.397266, Regularization: 0.812853\n",
      "2019-04-10 01:01:23,705 root         INFO     Train Epoch: 8 [5632/8000 (70%)]\tTotal Loss: 1.237819\n",
      "Reconstruction: 0.392562, Regularization: 0.845257\n",
      "2019-04-10 01:01:23,768 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 1.246199\n",
      "Reconstruction: 0.435637, Regularization: 0.810562\n",
      "2019-04-10 01:01:23,830 root         INFO     Train Epoch: 8 [6656/8000 (83%)]\tTotal Loss: 1.241125\n",
      "Reconstruction: 0.395424, Regularization: 0.845701\n",
      "2019-04-10 01:01:23,893 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 1.208348\n",
      "Reconstruction: 0.401624, Regularization: 0.806724\n",
      "2019-04-10 01:01:23,955 root         INFO     Train Epoch: 8 [7680/8000 (96%)]\tTotal Loss: 1.201014\n",
      "Reconstruction: 0.384724, Regularization: 0.816289\n",
      "2019-04-10 01:01:24,010 root         INFO     ====> Epoch: 8 Average loss: 1.2773\n",
      "2019-04-10 01:01:24,034 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 1.253175\n",
      "Reconstruction: 0.374871, Regularization: 0.878304\n",
      "2019-04-10 01:01:24,097 root         INFO     Train Epoch: 9 [512/8000 (6%)]\tTotal Loss: 1.173441\n",
      "Reconstruction: 0.382797, Regularization: 0.790645\n",
      "2019-04-10 01:01:24,161 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 1.215706\n",
      "Reconstruction: 0.393697, Regularization: 0.822009\n",
      "2019-04-10 01:01:24,224 root         INFO     Train Epoch: 9 [1536/8000 (19%)]\tTotal Loss: 1.231090\n",
      "Reconstruction: 0.386680, Regularization: 0.844410\n",
      "2019-04-10 01:01:24,287 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 1.162501\n",
      "Reconstruction: 0.358910, Regularization: 0.803591\n",
      "2019-04-10 01:01:24,350 root         INFO     Train Epoch: 9 [2560/8000 (32%)]\tTotal Loss: 1.171539\n",
      "Reconstruction: 0.366260, Regularization: 0.805279\n",
      "2019-04-10 01:01:24,412 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 1.198310\n",
      "Reconstruction: 0.385332, Regularization: 0.812978\n",
      "2019-04-10 01:01:24,474 root         INFO     Train Epoch: 9 [3584/8000 (45%)]\tTotal Loss: 1.091739\n",
      "Reconstruction: 0.378981, Regularization: 0.712758\n",
      "2019-04-10 01:01:24,537 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 1.107637\n",
      "Reconstruction: 0.381163, Regularization: 0.726474\n",
      "2019-04-10 01:01:24,599 root         INFO     Train Epoch: 9 [4608/8000 (58%)]\tTotal Loss: 1.024752\n",
      "Reconstruction: 0.377354, Regularization: 0.647398\n",
      "2019-04-10 01:01:24,661 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 1.153732\n",
      "Reconstruction: 0.378296, Regularization: 0.775436\n",
      "2019-04-10 01:01:24,723 root         INFO     Train Epoch: 9 [5632/8000 (70%)]\tTotal Loss: 1.155998\n",
      "Reconstruction: 0.365784, Regularization: 0.790214\n",
      "2019-04-10 01:01:24,786 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 1.111475\n",
      "Reconstruction: 0.352466, Regularization: 0.759008\n",
      "2019-04-10 01:01:24,847 root         INFO     Train Epoch: 9 [6656/8000 (83%)]\tTotal Loss: 1.088873\n",
      "Reconstruction: 0.372441, Regularization: 0.716432\n",
      "2019-04-10 01:01:24,909 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 1.075254\n",
      "Reconstruction: 0.336297, Regularization: 0.738957\n",
      "2019-04-10 01:01:24,971 root         INFO     Train Epoch: 9 [7680/8000 (96%)]\tTotal Loss: 1.001275\n",
      "Reconstruction: 0.314167, Regularization: 0.687107\n",
      "2019-04-10 01:01:25,025 root         INFO     ====> Epoch: 9 Average loss: 1.1428\n",
      "2019-04-10 01:01:25,049 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 1.193306\n",
      "Reconstruction: 0.396505, Regularization: 0.796801\n",
      "2019-04-10 01:01:25,114 root         INFO     Train Epoch: 10 [512/8000 (6%)]\tTotal Loss: 1.082314\n",
      "Reconstruction: 0.383829, Regularization: 0.698485\n",
      "2019-04-10 01:01:25,179 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 1.018243\n",
      "Reconstruction: 0.334177, Regularization: 0.684065\n",
      "2019-04-10 01:01:25,243 root         INFO     Train Epoch: 10 [1536/8000 (19%)]\tTotal Loss: 1.047440\n",
      "Reconstruction: 0.354980, Regularization: 0.692460\n",
      "2019-04-10 01:01:25,307 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 1.005459\n",
      "Reconstruction: 0.342817, Regularization: 0.662642\n",
      "2019-04-10 01:01:25,371 root         INFO     Train Epoch: 10 [2560/8000 (32%)]\tTotal Loss: 1.087358\n",
      "Reconstruction: 0.387364, Regularization: 0.699994\n",
      "2019-04-10 01:01:25,435 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 1.012845\n",
      "Reconstruction: 0.346551, Regularization: 0.666294\n",
      "2019-04-10 01:01:25,499 root         INFO     Train Epoch: 10 [3584/8000 (45%)]\tTotal Loss: 1.041589\n",
      "Reconstruction: 0.360636, Regularization: 0.680953\n",
      "2019-04-10 01:01:25,563 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 1.034604\n",
      "Reconstruction: 0.344720, Regularization: 0.689884\n",
      "2019-04-10 01:01:25,628 root         INFO     Train Epoch: 10 [4608/8000 (58%)]\tTotal Loss: 0.978929\n",
      "Reconstruction: 0.361295, Regularization: 0.617634\n",
      "2019-04-10 01:01:25,691 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 0.964647\n",
      "Reconstruction: 0.342595, Regularization: 0.622052\n",
      "2019-04-10 01:01:25,755 root         INFO     Train Epoch: 10 [5632/8000 (70%)]\tTotal Loss: 0.948693\n",
      "Reconstruction: 0.316404, Regularization: 0.632288\n",
      "2019-04-10 01:01:25,819 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 1.063827\n",
      "Reconstruction: 0.385688, Regularization: 0.678139\n",
      "2019-04-10 01:01:25,883 root         INFO     Train Epoch: 10 [6656/8000 (83%)]\tTotal Loss: 0.977522\n",
      "Reconstruction: 0.347652, Regularization: 0.629870\n",
      "2019-04-10 01:01:25,947 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 0.905294\n",
      "Reconstruction: 0.331843, Regularization: 0.573452\n",
      "2019-04-10 01:01:26,011 root         INFO     Train Epoch: 10 [7680/8000 (96%)]\tTotal Loss: 0.984313\n",
      "Reconstruction: 0.356294, Regularization: 0.628019\n",
      "2019-04-10 01:01:26,066 root         INFO     ====> Epoch: 10 Average loss: 1.0246\n",
      "2019-04-10 01:01:26,090 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.953933\n",
      "Reconstruction: 0.356507, Regularization: 0.597427\n",
      "2019-04-10 01:01:26,154 root         INFO     Train Epoch: 11 [512/8000 (6%)]\tTotal Loss: 0.884042\n",
      "Reconstruction: 0.325655, Regularization: 0.558387\n",
      "2019-04-10 01:01:26,219 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 0.949521\n",
      "Reconstruction: 0.357082, Regularization: 0.592438\n",
      "2019-04-10 01:01:26,283 root         INFO     Train Epoch: 11 [1536/8000 (19%)]\tTotal Loss: 0.903901\n",
      "Reconstruction: 0.329432, Regularization: 0.574468\n",
      "2019-04-10 01:01:26,347 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.970224\n",
      "Reconstruction: 0.362396, Regularization: 0.607829\n",
      "2019-04-10 01:01:26,412 root         INFO     Train Epoch: 11 [2560/8000 (32%)]\tTotal Loss: 0.901441\n",
      "Reconstruction: 0.334455, Regularization: 0.566986\n",
      "2019-04-10 01:01:26,476 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 0.900118\n",
      "Reconstruction: 0.347469, Regularization: 0.552648\n",
      "2019-04-10 01:01:26,539 root         INFO     Train Epoch: 11 [3584/8000 (45%)]\tTotal Loss: 0.925671\n",
      "Reconstruction: 0.347361, Regularization: 0.578310\n",
      "2019-04-10 01:01:26,604 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 0.949275\n",
      "Reconstruction: 0.343785, Regularization: 0.605490\n",
      "2019-04-10 01:01:26,667 root         INFO     Train Epoch: 11 [4608/8000 (58%)]\tTotal Loss: 0.835256\n",
      "Reconstruction: 0.343310, Regularization: 0.491947\n",
      "2019-04-10 01:01:26,731 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 0.970853\n",
      "Reconstruction: 0.342213, Regularization: 0.628640\n",
      "2019-04-10 01:01:26,795 root         INFO     Train Epoch: 11 [5632/8000 (70%)]\tTotal Loss: 0.815772\n",
      "Reconstruction: 0.309439, Regularization: 0.506334\n",
      "2019-04-10 01:01:26,859 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.943139\n",
      "Reconstruction: 0.348140, Regularization: 0.594999\n",
      "2019-04-10 01:01:26,923 root         INFO     Train Epoch: 11 [6656/8000 (83%)]\tTotal Loss: 0.870215\n",
      "Reconstruction: 0.347480, Regularization: 0.522735\n",
      "2019-04-10 01:01:26,987 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 0.854424\n",
      "Reconstruction: 0.335960, Regularization: 0.518464\n",
      "2019-04-10 01:01:27,053 root         INFO     Train Epoch: 11 [7680/8000 (96%)]\tTotal Loss: 0.931558\n",
      "Reconstruction: 0.348217, Regularization: 0.583341\n",
      "2019-04-10 01:01:27,109 root         INFO     ====> Epoch: 11 Average loss: 0.9191\n",
      "2019-04-10 01:01:27,133 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 0.855540\n",
      "Reconstruction: 0.324071, Regularization: 0.531468\n",
      "2019-04-10 01:01:27,196 root         INFO     Train Epoch: 12 [512/8000 (6%)]\tTotal Loss: 0.830416\n",
      "Reconstruction: 0.337765, Regularization: 0.492651\n",
      "2019-04-10 01:01:27,260 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 0.832666\n",
      "Reconstruction: 0.334676, Regularization: 0.497989\n",
      "2019-04-10 01:01:27,323 root         INFO     Train Epoch: 12 [1536/8000 (19%)]\tTotal Loss: 0.812345\n",
      "Reconstruction: 0.323432, Regularization: 0.488913\n",
      "2019-04-10 01:01:27,387 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 0.839184\n",
      "Reconstruction: 0.325348, Regularization: 0.513836\n",
      "2019-04-10 01:01:27,451 root         INFO     Train Epoch: 12 [2560/8000 (32%)]\tTotal Loss: 0.886643\n",
      "Reconstruction: 0.318255, Regularization: 0.568388\n",
      "2019-04-10 01:01:27,515 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 0.871581\n",
      "Reconstruction: 0.323704, Regularization: 0.547877\n",
      "2019-04-10 01:01:27,579 root         INFO     Train Epoch: 12 [3584/8000 (45%)]\tTotal Loss: 0.809503\n",
      "Reconstruction: 0.309660, Regularization: 0.499843\n",
      "2019-04-10 01:01:27,642 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 0.813009\n",
      "Reconstruction: 0.343569, Regularization: 0.469440\n",
      "2019-04-10 01:01:27,705 root         INFO     Train Epoch: 12 [4608/8000 (58%)]\tTotal Loss: 0.831166\n",
      "Reconstruction: 0.328733, Regularization: 0.502433\n",
      "2019-04-10 01:01:27,769 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.823875\n",
      "Reconstruction: 0.336847, Regularization: 0.487028\n",
      "2019-04-10 01:01:27,832 root         INFO     Train Epoch: 12 [5632/8000 (70%)]\tTotal Loss: 0.799680\n",
      "Reconstruction: 0.304179, Regularization: 0.495501\n",
      "2019-04-10 01:01:27,895 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.747780\n",
      "Reconstruction: 0.323358, Regularization: 0.424422\n",
      "2019-04-10 01:01:27,958 root         INFO     Train Epoch: 12 [6656/8000 (83%)]\tTotal Loss: 0.756641\n",
      "Reconstruction: 0.322772, Regularization: 0.433869\n",
      "2019-04-10 01:01:28,022 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 0.757275\n",
      "Reconstruction: 0.323442, Regularization: 0.433833\n",
      "2019-04-10 01:01:28,085 root         INFO     Train Epoch: 12 [7680/8000 (96%)]\tTotal Loss: 0.777470\n",
      "Reconstruction: 0.321634, Regularization: 0.455836\n",
      "2019-04-10 01:01:28,139 root         INFO     ====> Epoch: 12 Average loss: 0.8283\n",
      "2019-04-10 01:01:28,162 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 0.778964\n",
      "Reconstruction: 0.335823, Regularization: 0.443141\n",
      "2019-04-10 01:01:28,226 root         INFO     Train Epoch: 13 [512/8000 (6%)]\tTotal Loss: 0.773460\n",
      "Reconstruction: 0.316567, Regularization: 0.456893\n",
      "2019-04-10 01:01:28,290 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 0.758471\n",
      "Reconstruction: 0.315427, Regularization: 0.443044\n",
      "2019-04-10 01:01:28,353 root         INFO     Train Epoch: 13 [1536/8000 (19%)]\tTotal Loss: 0.766109\n",
      "Reconstruction: 0.321076, Regularization: 0.445033\n",
      "2019-04-10 01:01:28,417 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 0.796266\n",
      "Reconstruction: 0.333214, Regularization: 0.463052\n",
      "2019-04-10 01:01:28,481 root         INFO     Train Epoch: 13 [2560/8000 (32%)]\tTotal Loss: 0.778770\n",
      "Reconstruction: 0.337321, Regularization: 0.441449\n",
      "2019-04-10 01:01:28,545 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 0.768412\n",
      "Reconstruction: 0.344734, Regularization: 0.423678\n",
      "2019-04-10 01:01:28,609 root         INFO     Train Epoch: 13 [3584/8000 (45%)]\tTotal Loss: 0.728568\n",
      "Reconstruction: 0.322433, Regularization: 0.406135\n",
      "2019-04-10 01:01:28,672 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 0.749715\n",
      "Reconstruction: 0.322460, Regularization: 0.427255\n",
      "2019-04-10 01:01:28,735 root         INFO     Train Epoch: 13 [4608/8000 (58%)]\tTotal Loss: 0.741719\n",
      "Reconstruction: 0.317185, Regularization: 0.424534\n",
      "2019-04-10 01:01:28,798 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 0.738126\n",
      "Reconstruction: 0.325393, Regularization: 0.412733\n",
      "2019-04-10 01:01:28,860 root         INFO     Train Epoch: 13 [5632/8000 (70%)]\tTotal Loss: 0.719985\n",
      "Reconstruction: 0.312883, Regularization: 0.407103\n",
      "2019-04-10 01:01:28,922 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 0.733047\n",
      "Reconstruction: 0.314724, Regularization: 0.418322\n",
      "2019-04-10 01:01:28,984 root         INFO     Train Epoch: 13 [6656/8000 (83%)]\tTotal Loss: 0.708386\n",
      "Reconstruction: 0.310024, Regularization: 0.398361\n",
      "2019-04-10 01:01:29,045 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 0.714265\n",
      "Reconstruction: 0.325706, Regularization: 0.388559\n",
      "2019-04-10 01:01:29,110 root         INFO     Train Epoch: 13 [7680/8000 (96%)]\tTotal Loss: 0.723016\n",
      "Reconstruction: 0.329076, Regularization: 0.393940\n",
      "2019-04-10 01:01:29,162 root         INFO     ====> Epoch: 13 Average loss: 0.7467\n",
      "2019-04-10 01:01:29,186 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.690325\n",
      "Reconstruction: 0.307916, Regularization: 0.382408\n",
      "2019-04-10 01:01:29,250 root         INFO     Train Epoch: 14 [512/8000 (6%)]\tTotal Loss: 0.669669\n",
      "Reconstruction: 0.302144, Regularization: 0.367525\n",
      "2019-04-10 01:01:29,314 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.659161\n",
      "Reconstruction: 0.299027, Regularization: 0.360134\n",
      "2019-04-10 01:01:29,377 root         INFO     Train Epoch: 14 [1536/8000 (19%)]\tTotal Loss: 0.646772\n",
      "Reconstruction: 0.309194, Regularization: 0.337578\n",
      "2019-04-10 01:01:29,441 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 0.687428\n",
      "Reconstruction: 0.315805, Regularization: 0.371623\n",
      "2019-04-10 01:01:29,505 root         INFO     Train Epoch: 14 [2560/8000 (32%)]\tTotal Loss: 0.677699\n",
      "Reconstruction: 0.331456, Regularization: 0.346243\n",
      "2019-04-10 01:01:29,569 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.692221\n",
      "Reconstruction: 0.324820, Regularization: 0.367400\n",
      "2019-04-10 01:01:29,632 root         INFO     Train Epoch: 14 [3584/8000 (45%)]\tTotal Loss: 0.690241\n",
      "Reconstruction: 0.323864, Regularization: 0.366377\n",
      "2019-04-10 01:01:29,694 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.684658\n",
      "Reconstruction: 0.322217, Regularization: 0.362441\n",
      "2019-04-10 01:01:29,757 root         INFO     Train Epoch: 14 [4608/8000 (58%)]\tTotal Loss: 0.639784\n",
      "Reconstruction: 0.303461, Regularization: 0.336323\n",
      "2019-04-10 01:01:29,819 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 0.707595\n",
      "Reconstruction: 0.327057, Regularization: 0.380538\n",
      "2019-04-10 01:01:29,881 root         INFO     Train Epoch: 14 [5632/8000 (70%)]\tTotal Loss: 0.659049\n",
      "Reconstruction: 0.293571, Regularization: 0.365479\n",
      "2019-04-10 01:01:29,944 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.692757\n",
      "Reconstruction: 0.330038, Regularization: 0.362718\n",
      "2019-04-10 01:01:30,007 root         INFO     Train Epoch: 14 [6656/8000 (83%)]\tTotal Loss: 0.668424\n",
      "Reconstruction: 0.300936, Regularization: 0.367487\n",
      "2019-04-10 01:01:30,069 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.628401\n",
      "Reconstruction: 0.302614, Regularization: 0.325787\n",
      "2019-04-10 01:01:30,131 root         INFO     Train Epoch: 14 [7680/8000 (96%)]\tTotal Loss: 0.621474\n",
      "Reconstruction: 0.306688, Regularization: 0.314785\n",
      "2019-04-10 01:01:30,185 root         INFO     ====> Epoch: 14 Average loss: 0.6776\n",
      "2019-04-10 01:01:30,209 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 0.693713\n",
      "Reconstruction: 0.325783, Regularization: 0.367930\n",
      "2019-04-10 01:01:30,273 root         INFO     Train Epoch: 15 [512/8000 (6%)]\tTotal Loss: 0.642200\n",
      "Reconstruction: 0.329704, Regularization: 0.312496\n",
      "2019-04-10 01:01:30,336 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 0.673455\n",
      "Reconstruction: 0.317585, Regularization: 0.355870\n",
      "2019-04-10 01:01:30,400 root         INFO     Train Epoch: 15 [1536/8000 (19%)]\tTotal Loss: 0.614568\n",
      "Reconstruction: 0.288842, Regularization: 0.325726\n",
      "2019-04-10 01:01:30,465 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.636739\n",
      "Reconstruction: 0.321038, Regularization: 0.315700\n",
      "2019-04-10 01:01:30,528 root         INFO     Train Epoch: 15 [2560/8000 (32%)]\tTotal Loss: 0.567084\n",
      "Reconstruction: 0.305739, Regularization: 0.261346\n",
      "2019-04-10 01:01:30,592 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.578489\n",
      "Reconstruction: 0.287320, Regularization: 0.291169\n",
      "2019-04-10 01:01:30,656 root         INFO     Train Epoch: 15 [3584/8000 (45%)]\tTotal Loss: 0.565775\n",
      "Reconstruction: 0.289002, Regularization: 0.276773\n",
      "2019-04-10 01:01:30,719 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.615201\n",
      "Reconstruction: 0.313257, Regularization: 0.301944\n",
      "2019-04-10 01:01:30,782 root         INFO     Train Epoch: 15 [4608/8000 (58%)]\tTotal Loss: 0.610595\n",
      "Reconstruction: 0.320228, Regularization: 0.290367\n",
      "2019-04-10 01:01:30,847 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.636445\n",
      "Reconstruction: 0.333807, Regularization: 0.302638\n",
      "2019-04-10 01:01:30,911 root         INFO     Train Epoch: 15 [5632/8000 (70%)]\tTotal Loss: 0.569710\n",
      "Reconstruction: 0.304269, Regularization: 0.265441\n",
      "2019-04-10 01:01:30,975 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.599280\n",
      "Reconstruction: 0.319818, Regularization: 0.279463\n",
      "2019-04-10 01:01:31,039 root         INFO     Train Epoch: 15 [6656/8000 (83%)]\tTotal Loss: 0.625932\n",
      "Reconstruction: 0.305143, Regularization: 0.320788\n",
      "2019-04-10 01:01:31,103 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 0.580597\n",
      "Reconstruction: 0.306815, Regularization: 0.273782\n",
      "2019-04-10 01:01:31,167 root         INFO     Train Epoch: 15 [7680/8000 (96%)]\tTotal Loss: 0.597014\n",
      "Reconstruction: 0.295999, Regularization: 0.301015\n",
      "2019-04-10 01:01:31,221 root         INFO     ====> Epoch: 15 Average loss: 0.6167\n",
      "2019-04-10 01:01:31,245 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 0.587154\n",
      "Reconstruction: 0.303801, Regularization: 0.283353\n",
      "2019-04-10 01:01:31,308 root         INFO     Train Epoch: 16 [512/8000 (6%)]\tTotal Loss: 0.583435\n",
      "Reconstruction: 0.309557, Regularization: 0.273878\n",
      "2019-04-10 01:01:31,371 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 0.608624\n",
      "Reconstruction: 0.337843, Regularization: 0.270781\n",
      "2019-04-10 01:01:31,433 root         INFO     Train Epoch: 16 [1536/8000 (19%)]\tTotal Loss: 0.588761\n",
      "Reconstruction: 0.302482, Regularization: 0.286279\n",
      "2019-04-10 01:01:31,496 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.588637\n",
      "Reconstruction: 0.311875, Regularization: 0.276762\n",
      "2019-04-10 01:01:31,558 root         INFO     Train Epoch: 16 [2560/8000 (32%)]\tTotal Loss: 0.600152\n",
      "Reconstruction: 0.316231, Regularization: 0.283921\n",
      "2019-04-10 01:01:31,620 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 0.607760\n",
      "Reconstruction: 0.316701, Regularization: 0.291059\n",
      "2019-04-10 01:01:31,683 root         INFO     Train Epoch: 16 [3584/8000 (45%)]\tTotal Loss: 0.582758\n",
      "Reconstruction: 0.295700, Regularization: 0.287058\n",
      "2019-04-10 01:01:31,744 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 0.609291\n",
      "Reconstruction: 0.332149, Regularization: 0.277142\n",
      "2019-04-10 01:01:31,806 root         INFO     Train Epoch: 16 [4608/8000 (58%)]\tTotal Loss: 0.516646\n",
      "Reconstruction: 0.294636, Regularization: 0.222010\n",
      "2019-04-10 01:01:31,869 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 0.554759\n",
      "Reconstruction: 0.301500, Regularization: 0.253259\n",
      "2019-04-10 01:01:31,931 root         INFO     Train Epoch: 16 [5632/8000 (70%)]\tTotal Loss: 0.555393\n",
      "Reconstruction: 0.316765, Regularization: 0.238628\n",
      "2019-04-10 01:01:31,993 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 0.563208\n",
      "Reconstruction: 0.307012, Regularization: 0.256196\n",
      "2019-04-10 01:01:32,055 root         INFO     Train Epoch: 16 [6656/8000 (83%)]\tTotal Loss: 0.573109\n",
      "Reconstruction: 0.334074, Regularization: 0.239035\n",
      "2019-04-10 01:01:32,117 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.542575\n",
      "Reconstruction: 0.318426, Regularization: 0.224149\n",
      "2019-04-10 01:01:32,180 root         INFO     Train Epoch: 16 [7680/8000 (96%)]\tTotal Loss: 0.553036\n",
      "Reconstruction: 0.285517, Regularization: 0.267520\n",
      "2019-04-10 01:01:32,235 root         INFO     ====> Epoch: 16 Average loss: 0.5665\n",
      "2019-04-10 01:01:32,259 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.522262\n",
      "Reconstruction: 0.289945, Regularization: 0.232317\n",
      "2019-04-10 01:01:32,323 root         INFO     Train Epoch: 17 [512/8000 (6%)]\tTotal Loss: 0.515174\n",
      "Reconstruction: 0.294651, Regularization: 0.220524\n",
      "2019-04-10 01:01:32,386 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 0.523396\n",
      "Reconstruction: 0.298892, Regularization: 0.224504\n",
      "2019-04-10 01:01:32,449 root         INFO     Train Epoch: 17 [1536/8000 (19%)]\tTotal Loss: 0.529022\n",
      "Reconstruction: 0.294564, Regularization: 0.234458\n",
      "2019-04-10 01:01:32,512 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.489679\n",
      "Reconstruction: 0.263743, Regularization: 0.225936\n",
      "2019-04-10 01:01:32,575 root         INFO     Train Epoch: 17 [2560/8000 (32%)]\tTotal Loss: 0.529035\n",
      "Reconstruction: 0.270463, Regularization: 0.258572\n",
      "2019-04-10 01:01:32,638 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 0.529302\n",
      "Reconstruction: 0.301435, Regularization: 0.227867\n",
      "2019-04-10 01:01:32,700 root         INFO     Train Epoch: 17 [3584/8000 (45%)]\tTotal Loss: 0.548150\n",
      "Reconstruction: 0.320013, Regularization: 0.228137\n",
      "2019-04-10 01:01:32,763 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.513510\n",
      "Reconstruction: 0.302178, Regularization: 0.211332\n",
      "2019-04-10 01:01:32,825 root         INFO     Train Epoch: 17 [4608/8000 (58%)]\tTotal Loss: 0.519948\n",
      "Reconstruction: 0.293029, Regularization: 0.226919\n",
      "2019-04-10 01:01:32,887 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 0.527106\n",
      "Reconstruction: 0.284474, Regularization: 0.242631\n",
      "2019-04-10 01:01:32,949 root         INFO     Train Epoch: 17 [5632/8000 (70%)]\tTotal Loss: 0.510082\n",
      "Reconstruction: 0.298076, Regularization: 0.212005\n",
      "2019-04-10 01:01:33,011 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 0.484995\n",
      "Reconstruction: 0.279780, Regularization: 0.205215\n",
      "2019-04-10 01:01:33,073 root         INFO     Train Epoch: 17 [6656/8000 (83%)]\tTotal Loss: 0.485613\n",
      "Reconstruction: 0.275009, Regularization: 0.210604\n",
      "2019-04-10 01:01:33,135 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 0.505472\n",
      "Reconstruction: 0.300168, Regularization: 0.205304\n",
      "2019-04-10 01:01:33,197 root         INFO     Train Epoch: 17 [7680/8000 (96%)]\tTotal Loss: 0.496544\n",
      "Reconstruction: 0.297264, Regularization: 0.199279\n",
      "2019-04-10 01:01:33,250 root         INFO     ====> Epoch: 17 Average loss: 0.5220\n",
      "2019-04-10 01:01:33,275 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 0.494140\n",
      "Reconstruction: 0.293618, Regularization: 0.200522\n",
      "2019-04-10 01:01:33,338 root         INFO     Train Epoch: 18 [512/8000 (6%)]\tTotal Loss: 0.493674\n",
      "Reconstruction: 0.282045, Regularization: 0.211629\n",
      "2019-04-10 01:01:33,401 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.525905\n",
      "Reconstruction: 0.329618, Regularization: 0.196287\n",
      "2019-04-10 01:01:33,464 root         INFO     Train Epoch: 18 [1536/8000 (19%)]\tTotal Loss: 0.501097\n",
      "Reconstruction: 0.295428, Regularization: 0.205669\n",
      "2019-04-10 01:01:33,527 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 0.480932\n",
      "Reconstruction: 0.284466, Regularization: 0.196466\n",
      "2019-04-10 01:01:33,590 root         INFO     Train Epoch: 18 [2560/8000 (32%)]\tTotal Loss: 0.486963\n",
      "Reconstruction: 0.284468, Regularization: 0.202494\n",
      "2019-04-10 01:01:33,653 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.485638\n",
      "Reconstruction: 0.290137, Regularization: 0.195501\n",
      "2019-04-10 01:01:33,715 root         INFO     Train Epoch: 18 [3584/8000 (45%)]\tTotal Loss: 0.472692\n",
      "Reconstruction: 0.291386, Regularization: 0.181305\n",
      "2019-04-10 01:01:33,777 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 0.489846\n",
      "Reconstruction: 0.302246, Regularization: 0.187600\n",
      "2019-04-10 01:01:33,839 root         INFO     Train Epoch: 18 [4608/8000 (58%)]\tTotal Loss: 0.487990\n",
      "Reconstruction: 0.312214, Regularization: 0.175775\n",
      "2019-04-10 01:01:33,901 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.485102\n",
      "Reconstruction: 0.301510, Regularization: 0.183592\n",
      "2019-04-10 01:01:33,963 root         INFO     Train Epoch: 18 [5632/8000 (70%)]\tTotal Loss: 0.491839\n",
      "Reconstruction: 0.292485, Regularization: 0.199353\n",
      "2019-04-10 01:01:34,025 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 0.473141\n",
      "Reconstruction: 0.280696, Regularization: 0.192445\n",
      "2019-04-10 01:01:34,087 root         INFO     Train Epoch: 18 [6656/8000 (83%)]\tTotal Loss: 0.468744\n",
      "Reconstruction: 0.289777, Regularization: 0.178966\n",
      "2019-04-10 01:01:34,149 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 0.478368\n",
      "Reconstruction: 0.308381, Regularization: 0.169987\n",
      "2019-04-10 01:01:34,211 root         INFO     Train Epoch: 18 [7680/8000 (96%)]\tTotal Loss: 0.462800\n",
      "Reconstruction: 0.297467, Regularization: 0.165333\n",
      "2019-04-10 01:01:34,264 root         INFO     ====> Epoch: 18 Average loss: 0.4846\n",
      "2019-04-10 01:01:34,288 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 0.468660\n",
      "Reconstruction: 0.301230, Regularization: 0.167430\n",
      "2019-04-10 01:01:34,352 root         INFO     Train Epoch: 19 [512/8000 (6%)]\tTotal Loss: 0.454908\n",
      "Reconstruction: 0.260487, Regularization: 0.194421\n",
      "2019-04-10 01:01:34,415 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 0.468884\n",
      "Reconstruction: 0.279361, Regularization: 0.189523\n",
      "2019-04-10 01:01:34,478 root         INFO     Train Epoch: 19 [1536/8000 (19%)]\tTotal Loss: 0.438928\n",
      "Reconstruction: 0.285109, Regularization: 0.153819\n",
      "2019-04-10 01:01:34,541 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 0.462491\n",
      "Reconstruction: 0.303093, Regularization: 0.159398\n",
      "2019-04-10 01:01:34,605 root         INFO     Train Epoch: 19 [2560/8000 (32%)]\tTotal Loss: 0.448891\n",
      "Reconstruction: 0.269273, Regularization: 0.179618\n",
      "2019-04-10 01:01:34,668 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 0.442092\n",
      "Reconstruction: 0.283084, Regularization: 0.159008\n",
      "2019-04-10 01:01:34,731 root         INFO     Train Epoch: 19 [3584/8000 (45%)]\tTotal Loss: 0.475105\n",
      "Reconstruction: 0.295820, Regularization: 0.179285\n",
      "2019-04-10 01:01:34,795 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 0.432127\n",
      "Reconstruction: 0.278943, Regularization: 0.153184\n",
      "2019-04-10 01:01:34,858 root         INFO     Train Epoch: 19 [4608/8000 (58%)]\tTotal Loss: 0.439260\n",
      "Reconstruction: 0.282938, Regularization: 0.156322\n",
      "2019-04-10 01:01:34,921 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 0.472469\n",
      "Reconstruction: 0.282143, Regularization: 0.190326\n",
      "2019-04-10 01:01:34,984 root         INFO     Train Epoch: 19 [5632/8000 (70%)]\tTotal Loss: 0.453805\n",
      "Reconstruction: 0.292069, Regularization: 0.161736\n",
      "2019-04-10 01:01:35,048 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 0.445642\n",
      "Reconstruction: 0.296012, Regularization: 0.149630\n",
      "2019-04-10 01:01:35,111 root         INFO     Train Epoch: 19 [6656/8000 (83%)]\tTotal Loss: 0.439079\n",
      "Reconstruction: 0.284470, Regularization: 0.154609\n",
      "2019-04-10 01:01:35,173 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.445098\n",
      "Reconstruction: 0.297915, Regularization: 0.147183\n",
      "2019-04-10 01:01:35,236 root         INFO     Train Epoch: 19 [7680/8000 (96%)]\tTotal Loss: 0.426863\n",
      "Reconstruction: 0.301258, Regularization: 0.125605\n",
      "2019-04-10 01:01:35,290 root         INFO     ====> Epoch: 19 Average loss: 0.4525\n",
      "2019-04-10 01:01:35,314 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 0.447174\n",
      "Reconstruction: 0.284010, Regularization: 0.163164\n",
      "2019-04-10 01:01:35,377 root         INFO     Train Epoch: 20 [512/8000 (6%)]\tTotal Loss: 0.447679\n",
      "Reconstruction: 0.306282, Regularization: 0.141396\n",
      "2019-04-10 01:01:35,440 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 0.461206\n",
      "Reconstruction: 0.317880, Regularization: 0.143325\n",
      "2019-04-10 01:01:35,504 root         INFO     Train Epoch: 20 [1536/8000 (19%)]\tTotal Loss: 0.456031\n",
      "Reconstruction: 0.291700, Regularization: 0.164331\n",
      "2019-04-10 01:01:35,567 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 0.402170\n",
      "Reconstruction: 0.276818, Regularization: 0.125352\n",
      "2019-04-10 01:01:35,630 root         INFO     Train Epoch: 20 [2560/8000 (32%)]\tTotal Loss: 0.442239\n",
      "Reconstruction: 0.317269, Regularization: 0.124970\n",
      "2019-04-10 01:01:35,693 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 0.429103\n",
      "Reconstruction: 0.277484, Regularization: 0.151620\n",
      "2019-04-10 01:01:35,757 root         INFO     Train Epoch: 20 [3584/8000 (45%)]\tTotal Loss: 0.439030\n",
      "Reconstruction: 0.290385, Regularization: 0.148645\n",
      "2019-04-10 01:01:35,820 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 0.445782\n",
      "Reconstruction: 0.289105, Regularization: 0.156677\n",
      "2019-04-10 01:01:35,883 root         INFO     Train Epoch: 20 [4608/8000 (58%)]\tTotal Loss: 0.434036\n",
      "Reconstruction: 0.294596, Regularization: 0.139440\n",
      "2019-04-10 01:01:35,946 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 0.417046\n",
      "Reconstruction: 0.289060, Regularization: 0.127986\n",
      "2019-04-10 01:01:36,009 root         INFO     Train Epoch: 20 [5632/8000 (70%)]\tTotal Loss: 0.443902\n",
      "Reconstruction: 0.328312, Regularization: 0.115590\n",
      "2019-04-10 01:01:36,072 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 0.410145\n",
      "Reconstruction: 0.282239, Regularization: 0.127907\n",
      "2019-04-10 01:01:36,136 root         INFO     Train Epoch: 20 [6656/8000 (83%)]\tTotal Loss: 0.445093\n",
      "Reconstruction: 0.297876, Regularization: 0.147217\n",
      "2019-04-10 01:01:36,199 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 0.407380\n",
      "Reconstruction: 0.274094, Regularization: 0.133285\n",
      "2019-04-10 01:01:36,262 root         INFO     Train Epoch: 20 [7680/8000 (96%)]\tTotal Loss: 0.405838\n",
      "Reconstruction: 0.283719, Regularization: 0.122119\n",
      "2019-04-10 01:01:36,316 root         INFO     ====> Epoch: 20 Average loss: 0.4261\n",
      "2019-04-10 01:01:36,340 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.426183\n",
      "Reconstruction: 0.282525, Regularization: 0.143658\n",
      "2019-04-10 01:01:36,404 root         INFO     Train Epoch: 21 [512/8000 (6%)]\tTotal Loss: 0.451528\n",
      "Reconstruction: 0.315925, Regularization: 0.135603\n",
      "2019-04-10 01:01:36,467 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 0.383411\n",
      "Reconstruction: 0.251725, Regularization: 0.131686\n",
      "2019-04-10 01:01:36,530 root         INFO     Train Epoch: 21 [1536/8000 (19%)]\tTotal Loss: 0.405010\n",
      "Reconstruction: 0.270780, Regularization: 0.134230\n",
      "2019-04-10 01:01:36,593 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 0.404658\n",
      "Reconstruction: 0.282926, Regularization: 0.121731\n",
      "2019-04-10 01:01:36,656 root         INFO     Train Epoch: 21 [2560/8000 (32%)]\tTotal Loss: 0.438183\n",
      "Reconstruction: 0.313832, Regularization: 0.124350\n",
      "2019-04-10 01:01:36,720 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 0.414327\n",
      "Reconstruction: 0.287648, Regularization: 0.126678\n",
      "2019-04-10 01:01:36,783 root         INFO     Train Epoch: 21 [3584/8000 (45%)]\tTotal Loss: 0.429760\n",
      "Reconstruction: 0.302236, Regularization: 0.127524\n",
      "2019-04-10 01:01:36,846 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.436837\n",
      "Reconstruction: 0.303094, Regularization: 0.133744\n",
      "2019-04-10 01:01:36,909 root         INFO     Train Epoch: 21 [4608/8000 (58%)]\tTotal Loss: 0.437823\n",
      "Reconstruction: 0.307003, Regularization: 0.130820\n",
      "2019-04-10 01:01:36,973 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 0.422832\n",
      "Reconstruction: 0.308754, Regularization: 0.114078\n",
      "2019-04-10 01:01:37,036 root         INFO     Train Epoch: 21 [5632/8000 (70%)]\tTotal Loss: 0.378501\n",
      "Reconstruction: 0.266202, Regularization: 0.112299\n",
      "2019-04-10 01:01:37,099 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 0.386225\n",
      "Reconstruction: 0.263975, Regularization: 0.122250\n",
      "2019-04-10 01:01:37,162 root         INFO     Train Epoch: 21 [6656/8000 (83%)]\tTotal Loss: 0.408136\n",
      "Reconstruction: 0.283608, Regularization: 0.124528\n",
      "2019-04-10 01:01:37,225 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.379375\n",
      "Reconstruction: 0.269955, Regularization: 0.109419\n",
      "2019-04-10 01:01:37,289 root         INFO     Train Epoch: 21 [7680/8000 (96%)]\tTotal Loss: 0.401935\n",
      "Reconstruction: 0.281381, Regularization: 0.120553\n",
      "2019-04-10 01:01:37,343 root         INFO     ====> Epoch: 21 Average loss: 0.4033\n",
      "2019-04-10 01:01:37,367 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 0.378533\n",
      "Reconstruction: 0.265168, Regularization: 0.113365\n",
      "2019-04-10 01:01:37,429 root         INFO     Train Epoch: 22 [512/8000 (6%)]\tTotal Loss: 0.384555\n",
      "Reconstruction: 0.278462, Regularization: 0.106093\n",
      "2019-04-10 01:01:37,491 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 0.416013\n",
      "Reconstruction: 0.305605, Regularization: 0.110408\n",
      "2019-04-10 01:01:37,553 root         INFO     Train Epoch: 22 [1536/8000 (19%)]\tTotal Loss: 0.386673\n",
      "Reconstruction: 0.274040, Regularization: 0.112633\n",
      "2019-04-10 01:01:37,615 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 0.389108\n",
      "Reconstruction: 0.265882, Regularization: 0.123226\n",
      "2019-04-10 01:01:37,676 root         INFO     Train Epoch: 22 [2560/8000 (32%)]\tTotal Loss: 0.427645\n",
      "Reconstruction: 0.313746, Regularization: 0.113899\n",
      "2019-04-10 01:01:37,738 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 0.393202\n",
      "Reconstruction: 0.286981, Regularization: 0.106221\n",
      "2019-04-10 01:01:37,799 root         INFO     Train Epoch: 22 [3584/8000 (45%)]\tTotal Loss: 0.375765\n",
      "Reconstruction: 0.253599, Regularization: 0.122166\n",
      "2019-04-10 01:01:37,860 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.381704\n",
      "Reconstruction: 0.272051, Regularization: 0.109653\n",
      "2019-04-10 01:01:37,922 root         INFO     Train Epoch: 22 [4608/8000 (58%)]\tTotal Loss: 0.365908\n",
      "Reconstruction: 0.259301, Regularization: 0.106607\n",
      "2019-04-10 01:01:37,983 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 0.384869\n",
      "Reconstruction: 0.287511, Regularization: 0.097358\n",
      "2019-04-10 01:01:38,045 root         INFO     Train Epoch: 22 [5632/8000 (70%)]\tTotal Loss: 0.408453\n",
      "Reconstruction: 0.296686, Regularization: 0.111767\n",
      "2019-04-10 01:01:38,106 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 0.361718\n",
      "Reconstruction: 0.267659, Regularization: 0.094060\n",
      "2019-04-10 01:01:38,168 root         INFO     Train Epoch: 22 [6656/8000 (83%)]\tTotal Loss: 0.371947\n",
      "Reconstruction: 0.265503, Regularization: 0.106444\n",
      "2019-04-10 01:01:38,229 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 0.372236\n",
      "Reconstruction: 0.273923, Regularization: 0.098312\n",
      "2019-04-10 01:01:38,291 root         INFO     Train Epoch: 22 [7680/8000 (96%)]\tTotal Loss: 0.367553\n",
      "Reconstruction: 0.273111, Regularization: 0.094442\n",
      "2019-04-10 01:01:38,344 root         INFO     ====> Epoch: 22 Average loss: 0.3844\n",
      "2019-04-10 01:01:38,369 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 0.383269\n",
      "Reconstruction: 0.272154, Regularization: 0.111115\n",
      "2019-04-10 01:01:38,433 root         INFO     Train Epoch: 23 [512/8000 (6%)]\tTotal Loss: 0.384294\n",
      "Reconstruction: 0.287472, Regularization: 0.096822\n",
      "2019-04-10 01:01:38,496 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 0.376871\n",
      "Reconstruction: 0.264874, Regularization: 0.111997\n",
      "2019-04-10 01:01:38,560 root         INFO     Train Epoch: 23 [1536/8000 (19%)]\tTotal Loss: 0.367216\n",
      "Reconstruction: 0.264547, Regularization: 0.102668\n",
      "2019-04-10 01:01:38,623 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 0.407684\n",
      "Reconstruction: 0.318026, Regularization: 0.089658\n",
      "2019-04-10 01:01:38,686 root         INFO     Train Epoch: 23 [2560/8000 (32%)]\tTotal Loss: 0.361666\n",
      "Reconstruction: 0.276167, Regularization: 0.085499\n",
      "2019-04-10 01:01:38,748 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 0.360469\n",
      "Reconstruction: 0.250365, Regularization: 0.110105\n",
      "2019-04-10 01:01:38,810 root         INFO     Train Epoch: 23 [3584/8000 (45%)]\tTotal Loss: 0.365658\n",
      "Reconstruction: 0.279008, Regularization: 0.086650\n",
      "2019-04-10 01:01:38,873 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 0.353526\n",
      "Reconstruction: 0.273778, Regularization: 0.079748\n",
      "2019-04-10 01:01:38,935 root         INFO     Train Epoch: 23 [4608/8000 (58%)]\tTotal Loss: 0.341614\n",
      "Reconstruction: 0.250342, Regularization: 0.091272\n",
      "2019-04-10 01:01:38,998 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 0.365923\n",
      "Reconstruction: 0.268539, Regularization: 0.097384\n",
      "2019-04-10 01:01:39,061 root         INFO     Train Epoch: 23 [5632/8000 (70%)]\tTotal Loss: 0.359091\n",
      "Reconstruction: 0.262773, Regularization: 0.096318\n",
      "2019-04-10 01:01:39,123 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 0.372690\n",
      "Reconstruction: 0.279889, Regularization: 0.092801\n",
      "2019-04-10 01:01:39,185 root         INFO     Train Epoch: 23 [6656/8000 (83%)]\tTotal Loss: 0.351428\n",
      "Reconstruction: 0.265793, Regularization: 0.085635\n",
      "2019-04-10 01:01:39,246 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 0.366561\n",
      "Reconstruction: 0.271264, Regularization: 0.095297\n",
      "2019-04-10 01:01:39,308 root         INFO     Train Epoch: 23 [7680/8000 (96%)]\tTotal Loss: 0.380414\n",
      "Reconstruction: 0.288448, Regularization: 0.091965\n",
      "2019-04-10 01:01:39,361 root         INFO     ====> Epoch: 23 Average loss: 0.3672\n",
      "2019-04-10 01:01:39,385 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.349522\n",
      "Reconstruction: 0.264901, Regularization: 0.084621\n",
      "2019-04-10 01:01:39,448 root         INFO     Train Epoch: 24 [512/8000 (6%)]\tTotal Loss: 0.350476\n",
      "Reconstruction: 0.257048, Regularization: 0.093428\n",
      "2019-04-10 01:01:39,511 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 0.348029\n",
      "Reconstruction: 0.260269, Regularization: 0.087761\n",
      "2019-04-10 01:01:39,574 root         INFO     Train Epoch: 24 [1536/8000 (19%)]\tTotal Loss: 0.364587\n",
      "Reconstruction: 0.280961, Regularization: 0.083626\n",
      "2019-04-10 01:01:39,637 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 0.338561\n",
      "Reconstruction: 0.257917, Regularization: 0.080645\n",
      "2019-04-10 01:01:39,700 root         INFO     Train Epoch: 24 [2560/8000 (32%)]\tTotal Loss: 0.364748\n",
      "Reconstruction: 0.280710, Regularization: 0.084038\n",
      "2019-04-10 01:01:39,763 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 0.354566\n",
      "Reconstruction: 0.263015, Regularization: 0.091551\n",
      "2019-04-10 01:01:39,825 root         INFO     Train Epoch: 24 [3584/8000 (45%)]\tTotal Loss: 0.342571\n",
      "Reconstruction: 0.258737, Regularization: 0.083835\n",
      "2019-04-10 01:01:39,888 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 0.340058\n",
      "Reconstruction: 0.269893, Regularization: 0.070165\n",
      "2019-04-10 01:01:39,953 root         INFO     Train Epoch: 24 [4608/8000 (58%)]\tTotal Loss: 0.357706\n",
      "Reconstruction: 0.271310, Regularization: 0.086396\n",
      "2019-04-10 01:01:40,016 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 0.354789\n",
      "Reconstruction: 0.275886, Regularization: 0.078903\n",
      "2019-04-10 01:01:40,080 root         INFO     Train Epoch: 24 [5632/8000 (70%)]\tTotal Loss: 0.353659\n",
      "Reconstruction: 0.262193, Regularization: 0.091467\n",
      "2019-04-10 01:01:40,144 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 0.365572\n",
      "Reconstruction: 0.275621, Regularization: 0.089951\n",
      "2019-04-10 01:01:40,208 root         INFO     Train Epoch: 24 [6656/8000 (83%)]\tTotal Loss: 0.359018\n",
      "Reconstruction: 0.285430, Regularization: 0.073588\n",
      "2019-04-10 01:01:40,272 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 0.339069\n",
      "Reconstruction: 0.261973, Regularization: 0.077096\n",
      "2019-04-10 01:01:40,336 root         INFO     Train Epoch: 24 [7680/8000 (96%)]\tTotal Loss: 0.339154\n",
      "Reconstruction: 0.261044, Regularization: 0.078110\n",
      "2019-04-10 01:01:40,390 root         INFO     ====> Epoch: 24 Average loss: 0.3524\n",
      "2019-04-10 01:01:40,414 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 0.362423\n",
      "Reconstruction: 0.272673, Regularization: 0.089750\n",
      "2019-04-10 01:01:40,478 root         INFO     Train Epoch: 25 [512/8000 (6%)]\tTotal Loss: 0.364681\n",
      "Reconstruction: 0.286401, Regularization: 0.078280\n",
      "2019-04-10 01:01:40,542 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 0.339468\n",
      "Reconstruction: 0.270340, Regularization: 0.069128\n",
      "2019-04-10 01:01:40,606 root         INFO     Train Epoch: 25 [1536/8000 (19%)]\tTotal Loss: 0.334963\n",
      "Reconstruction: 0.258583, Regularization: 0.076381\n",
      "2019-04-10 01:01:40,670 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 0.351284\n",
      "Reconstruction: 0.275567, Regularization: 0.075718\n",
      "2019-04-10 01:01:40,734 root         INFO     Train Epoch: 25 [2560/8000 (32%)]\tTotal Loss: 0.350350\n",
      "Reconstruction: 0.282804, Regularization: 0.067546\n",
      "2019-04-10 01:01:40,797 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 0.371085\n",
      "Reconstruction: 0.301220, Regularization: 0.069865\n",
      "2019-04-10 01:01:40,861 root         INFO     Train Epoch: 25 [3584/8000 (45%)]\tTotal Loss: 0.341859\n",
      "Reconstruction: 0.265000, Regularization: 0.076859\n",
      "2019-04-10 01:01:40,924 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 0.335687\n",
      "Reconstruction: 0.263695, Regularization: 0.071991\n",
      "2019-04-10 01:01:40,987 root         INFO     Train Epoch: 25 [4608/8000 (58%)]\tTotal Loss: 0.353099\n",
      "Reconstruction: 0.285102, Regularization: 0.067997\n",
      "2019-04-10 01:01:41,051 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 0.348880\n",
      "Reconstruction: 0.273791, Regularization: 0.075089\n",
      "2019-04-10 01:01:41,114 root         INFO     Train Epoch: 25 [5632/8000 (70%)]\tTotal Loss: 0.339552\n",
      "Reconstruction: 0.268900, Regularization: 0.070652\n",
      "2019-04-10 01:01:41,177 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.330280\n",
      "Reconstruction: 0.258656, Regularization: 0.071624\n",
      "2019-04-10 01:01:41,239 root         INFO     Train Epoch: 25 [6656/8000 (83%)]\tTotal Loss: 0.336987\n",
      "Reconstruction: 0.264819, Regularization: 0.072168\n",
      "2019-04-10 01:01:41,302 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 0.321907\n",
      "Reconstruction: 0.251256, Regularization: 0.070651\n",
      "2019-04-10 01:01:41,364 root         INFO     Train Epoch: 25 [7680/8000 (96%)]\tTotal Loss: 0.319769\n",
      "Reconstruction: 0.247881, Regularization: 0.071889\n",
      "2019-04-10 01:01:41,418 root         INFO     ====> Epoch: 25 Average loss: 0.3400\n",
      "2019-04-10 01:01:41,442 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 0.329181\n",
      "Reconstruction: 0.259752, Regularization: 0.069429\n",
      "2019-04-10 01:01:41,505 root         INFO     Train Epoch: 26 [512/8000 (6%)]\tTotal Loss: 0.339074\n",
      "Reconstruction: 0.265452, Regularization: 0.073622\n",
      "2019-04-10 01:01:41,568 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 0.338006\n",
      "Reconstruction: 0.262895, Regularization: 0.075111\n",
      "2019-04-10 01:01:41,629 root         INFO     Train Epoch: 26 [1536/8000 (19%)]\tTotal Loss: 0.338833\n",
      "Reconstruction: 0.280938, Regularization: 0.057895\n",
      "2019-04-10 01:01:41,690 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 0.339896\n",
      "Reconstruction: 0.271879, Regularization: 0.068017\n",
      "2019-04-10 01:01:41,751 root         INFO     Train Epoch: 26 [2560/8000 (32%)]\tTotal Loss: 0.320275\n",
      "Reconstruction: 0.253662, Regularization: 0.066613\n",
      "2019-04-10 01:01:41,813 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 0.331047\n",
      "Reconstruction: 0.265145, Regularization: 0.065902\n",
      "2019-04-10 01:01:41,875 root         INFO     Train Epoch: 26 [3584/8000 (45%)]\tTotal Loss: 0.312071\n",
      "Reconstruction: 0.251672, Regularization: 0.060398\n",
      "2019-04-10 01:01:41,938 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.318539\n",
      "Reconstruction: 0.256186, Regularization: 0.062353\n",
      "2019-04-10 01:01:42,000 root         INFO     Train Epoch: 26 [4608/8000 (58%)]\tTotal Loss: 0.325810\n",
      "Reconstruction: 0.266585, Regularization: 0.059225\n",
      "2019-04-10 01:01:42,063 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 0.320724\n",
      "Reconstruction: 0.255028, Regularization: 0.065696\n",
      "2019-04-10 01:01:42,126 root         INFO     Train Epoch: 26 [5632/8000 (70%)]\tTotal Loss: 0.328843\n",
      "Reconstruction: 0.266066, Regularization: 0.062776\n",
      "2019-04-10 01:01:42,189 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 0.337799\n",
      "Reconstruction: 0.275140, Regularization: 0.062659\n",
      "2019-04-10 01:01:42,251 root         INFO     Train Epoch: 26 [6656/8000 (83%)]\tTotal Loss: 0.334435\n",
      "Reconstruction: 0.278524, Regularization: 0.055912\n",
      "2019-04-10 01:01:42,314 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 0.333735\n",
      "Reconstruction: 0.265304, Regularization: 0.068431\n",
      "2019-04-10 01:01:42,377 root         INFO     Train Epoch: 26 [7680/8000 (96%)]\tTotal Loss: 0.314461\n",
      "Reconstruction: 0.247704, Regularization: 0.066757\n",
      "2019-04-10 01:01:42,432 root         INFO     ====> Epoch: 26 Average loss: 0.3289\n",
      "2019-04-10 01:01:42,455 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 0.327677\n",
      "Reconstruction: 0.268641, Regularization: 0.059036\n",
      "2019-04-10 01:01:42,519 root         INFO     Train Epoch: 27 [512/8000 (6%)]\tTotal Loss: 0.320490\n",
      "Reconstruction: 0.261906, Regularization: 0.058584\n",
      "2019-04-10 01:01:42,582 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.323241\n",
      "Reconstruction: 0.262126, Regularization: 0.061115\n",
      "2019-04-10 01:01:42,645 root         INFO     Train Epoch: 27 [1536/8000 (19%)]\tTotal Loss: 0.315691\n",
      "Reconstruction: 0.257178, Regularization: 0.058513\n",
      "2019-04-10 01:01:42,708 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 0.318949\n",
      "Reconstruction: 0.258294, Regularization: 0.060655\n",
      "2019-04-10 01:01:42,771 root         INFO     Train Epoch: 27 [2560/8000 (32%)]\tTotal Loss: 0.307532\n",
      "Reconstruction: 0.251265, Regularization: 0.056267\n",
      "2019-04-10 01:01:42,834 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.330075\n",
      "Reconstruction: 0.264695, Regularization: 0.065380\n",
      "2019-04-10 01:01:42,897 root         INFO     Train Epoch: 27 [3584/8000 (45%)]\tTotal Loss: 0.336645\n",
      "Reconstruction: 0.281316, Regularization: 0.055329\n",
      "2019-04-10 01:01:42,960 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 0.343316\n",
      "Reconstruction: 0.290505, Regularization: 0.052812\n",
      "2019-04-10 01:01:43,024 root         INFO     Train Epoch: 27 [4608/8000 (58%)]\tTotal Loss: 0.304666\n",
      "Reconstruction: 0.250747, Regularization: 0.053919\n",
      "2019-04-10 01:01:43,087 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.316608\n",
      "Reconstruction: 0.271431, Regularization: 0.045177\n",
      "2019-04-10 01:01:43,150 root         INFO     Train Epoch: 27 [5632/8000 (70%)]\tTotal Loss: 0.320483\n",
      "Reconstruction: 0.263576, Regularization: 0.056907\n",
      "2019-04-10 01:01:43,212 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.323176\n",
      "Reconstruction: 0.263577, Regularization: 0.059598\n",
      "2019-04-10 01:01:43,274 root         INFO     Train Epoch: 27 [6656/8000 (83%)]\tTotal Loss: 0.317511\n",
      "Reconstruction: 0.255587, Regularization: 0.061924\n",
      "2019-04-10 01:01:43,336 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 0.318561\n",
      "Reconstruction: 0.258260, Regularization: 0.060302\n",
      "2019-04-10 01:01:43,397 root         INFO     Train Epoch: 27 [7680/8000 (96%)]\tTotal Loss: 0.331354\n",
      "Reconstruction: 0.278357, Regularization: 0.052997\n",
      "2019-04-10 01:01:43,450 root         INFO     ====> Epoch: 27 Average loss: 0.3195\n",
      "2019-04-10 01:01:43,474 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.301487\n",
      "Reconstruction: 0.252134, Regularization: 0.049353\n",
      "2019-04-10 01:01:43,538 root         INFO     Train Epoch: 28 [512/8000 (6%)]\tTotal Loss: 0.301927\n",
      "Reconstruction: 0.252686, Regularization: 0.049240\n",
      "2019-04-10 01:01:43,601 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.296091\n",
      "Reconstruction: 0.244346, Regularization: 0.051745\n",
      "2019-04-10 01:01:43,664 root         INFO     Train Epoch: 28 [1536/8000 (19%)]\tTotal Loss: 0.310200\n",
      "Reconstruction: 0.259185, Regularization: 0.051015\n",
      "2019-04-10 01:01:43,727 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 0.298138\n",
      "Reconstruction: 0.247375, Regularization: 0.050763\n",
      "2019-04-10 01:01:43,789 root         INFO     Train Epoch: 28 [2560/8000 (32%)]\tTotal Loss: 0.307150\n",
      "Reconstruction: 0.263705, Regularization: 0.043445\n",
      "2019-04-10 01:01:43,853 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.311655\n",
      "Reconstruction: 0.267565, Regularization: 0.044090\n",
      "2019-04-10 01:01:43,915 root         INFO     Train Epoch: 28 [3584/8000 (45%)]\tTotal Loss: 0.297251\n",
      "Reconstruction: 0.250893, Regularization: 0.046358\n",
      "2019-04-10 01:01:43,978 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.331146\n",
      "Reconstruction: 0.277898, Regularization: 0.053248\n",
      "2019-04-10 01:01:44,040 root         INFO     Train Epoch: 28 [4608/8000 (58%)]\tTotal Loss: 0.309454\n",
      "Reconstruction: 0.259111, Regularization: 0.050343\n",
      "2019-04-10 01:01:44,105 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.325261\n",
      "Reconstruction: 0.278131, Regularization: 0.047130\n",
      "2019-04-10 01:01:44,170 root         INFO     Train Epoch: 28 [5632/8000 (70%)]\tTotal Loss: 0.316934\n",
      "Reconstruction: 0.268030, Regularization: 0.048904\n",
      "2019-04-10 01:01:44,234 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.329153\n",
      "Reconstruction: 0.284643, Regularization: 0.044510\n",
      "2019-04-10 01:01:44,299 root         INFO     Train Epoch: 28 [6656/8000 (83%)]\tTotal Loss: 0.312197\n",
      "Reconstruction: 0.261945, Regularization: 0.050253\n",
      "2019-04-10 01:01:44,363 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.301205\n",
      "Reconstruction: 0.253165, Regularization: 0.048041\n",
      "2019-04-10 01:01:44,427 root         INFO     Train Epoch: 28 [7680/8000 (96%)]\tTotal Loss: 0.297278\n",
      "Reconstruction: 0.252257, Regularization: 0.045022\n",
      "2019-04-10 01:01:44,482 root         INFO     ====> Epoch: 28 Average loss: 0.3098\n",
      "2019-04-10 01:01:44,506 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 0.305661\n",
      "Reconstruction: 0.260580, Regularization: 0.045082\n",
      "2019-04-10 01:01:44,567 root         INFO     Train Epoch: 29 [512/8000 (6%)]\tTotal Loss: 0.320858\n",
      "Reconstruction: 0.275519, Regularization: 0.045339\n",
      "2019-04-10 01:01:44,629 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 0.310593\n",
      "Reconstruction: 0.263996, Regularization: 0.046597\n",
      "2019-04-10 01:01:44,690 root         INFO     Train Epoch: 29 [1536/8000 (19%)]\tTotal Loss: 0.306390\n",
      "Reconstruction: 0.263679, Regularization: 0.042711\n",
      "2019-04-10 01:01:44,752 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 0.300899\n",
      "Reconstruction: 0.257846, Regularization: 0.043052\n",
      "2019-04-10 01:01:44,814 root         INFO     Train Epoch: 29 [2560/8000 (32%)]\tTotal Loss: 0.305329\n",
      "Reconstruction: 0.258126, Regularization: 0.047203\n",
      "2019-04-10 01:01:44,875 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 0.301786\n",
      "Reconstruction: 0.260750, Regularization: 0.041036\n",
      "2019-04-10 01:01:44,937 root         INFO     Train Epoch: 29 [3584/8000 (45%)]\tTotal Loss: 0.300217\n",
      "Reconstruction: 0.261663, Regularization: 0.038554\n",
      "2019-04-10 01:01:44,999 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.303270\n",
      "Reconstruction: 0.254366, Regularization: 0.048904\n",
      "2019-04-10 01:01:45,060 root         INFO     Train Epoch: 29 [4608/8000 (58%)]\tTotal Loss: 0.305639\n",
      "Reconstruction: 0.251698, Regularization: 0.053942\n",
      "2019-04-10 01:01:45,123 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 0.297975\n",
      "Reconstruction: 0.255089, Regularization: 0.042886\n",
      "2019-04-10 01:01:45,185 root         INFO     Train Epoch: 29 [5632/8000 (70%)]\tTotal Loss: 0.289382\n",
      "Reconstruction: 0.245201, Regularization: 0.044181\n",
      "2019-04-10 01:01:45,248 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 0.284777\n",
      "Reconstruction: 0.242105, Regularization: 0.042672\n",
      "2019-04-10 01:01:45,310 root         INFO     Train Epoch: 29 [6656/8000 (83%)]\tTotal Loss: 0.305632\n",
      "Reconstruction: 0.263487, Regularization: 0.042145\n",
      "2019-04-10 01:01:45,373 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.296280\n",
      "Reconstruction: 0.252698, Regularization: 0.043582\n",
      "2019-04-10 01:01:45,435 root         INFO     Train Epoch: 29 [7680/8000 (96%)]\tTotal Loss: 0.298536\n",
      "Reconstruction: 0.257867, Regularization: 0.040669\n",
      "2019-04-10 01:01:45,488 root         INFO     ====> Epoch: 29 Average loss: 0.3035\n",
      "2019-04-10 01:01:45,512 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.306805\n",
      "Reconstruction: 0.261933, Regularization: 0.044872\n",
      "2019-04-10 01:01:45,575 root         INFO     Train Epoch: 30 [512/8000 (6%)]\tTotal Loss: 0.291609\n",
      "Reconstruction: 0.247039, Regularization: 0.044570\n",
      "2019-04-10 01:01:45,638 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.297330\n",
      "Reconstruction: 0.253535, Regularization: 0.043794\n",
      "2019-04-10 01:01:45,700 root         INFO     Train Epoch: 30 [1536/8000 (19%)]\tTotal Loss: 0.306112\n",
      "Reconstruction: 0.266974, Regularization: 0.039138\n",
      "2019-04-10 01:01:45,763 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.301290\n",
      "Reconstruction: 0.254765, Regularization: 0.046525\n",
      "2019-04-10 01:01:45,825 root         INFO     Train Epoch: 30 [2560/8000 (32%)]\tTotal Loss: 0.305068\n",
      "Reconstruction: 0.259291, Regularization: 0.045777\n",
      "2019-04-10 01:01:45,888 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.283929\n",
      "Reconstruction: 0.240564, Regularization: 0.043365\n",
      "2019-04-10 01:01:45,951 root         INFO     Train Epoch: 30 [3584/8000 (45%)]\tTotal Loss: 0.293952\n",
      "Reconstruction: 0.255597, Regularization: 0.038355\n",
      "2019-04-10 01:01:46,014 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.285836\n",
      "Reconstruction: 0.241968, Regularization: 0.043868\n",
      "2019-04-10 01:01:46,077 root         INFO     Train Epoch: 30 [4608/8000 (58%)]\tTotal Loss: 0.291069\n",
      "Reconstruction: 0.251603, Regularization: 0.039467\n",
      "2019-04-10 01:01:46,140 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.296693\n",
      "Reconstruction: 0.256742, Regularization: 0.039951\n",
      "2019-04-10 01:01:46,203 root         INFO     Train Epoch: 30 [5632/8000 (70%)]\tTotal Loss: 0.292653\n",
      "Reconstruction: 0.254431, Regularization: 0.038222\n",
      "2019-04-10 01:01:46,265 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.296176\n",
      "Reconstruction: 0.258793, Regularization: 0.037383\n",
      "2019-04-10 01:01:46,327 root         INFO     Train Epoch: 30 [6656/8000 (83%)]\tTotal Loss: 0.301981\n",
      "Reconstruction: 0.256680, Regularization: 0.045301\n",
      "2019-04-10 01:01:46,389 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 0.303932\n",
      "Reconstruction: 0.269185, Regularization: 0.034747\n",
      "2019-04-10 01:01:46,451 root         INFO     Train Epoch: 30 [7680/8000 (96%)]\tTotal Loss: 0.296192\n",
      "Reconstruction: 0.254350, Regularization: 0.041842\n",
      "2019-04-10 01:01:46,504 root         INFO     ====> Epoch: 30 Average loss: 0.2971\n",
      "2019-04-10 01:01:46,528 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.287581\n",
      "Reconstruction: 0.256013, Regularization: 0.031568\n",
      "2019-04-10 01:01:46,592 root         INFO     Train Epoch: 31 [512/8000 (6%)]\tTotal Loss: 0.278502\n",
      "Reconstruction: 0.245338, Regularization: 0.033165\n",
      "2019-04-10 01:01:46,655 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.291381\n",
      "Reconstruction: 0.254876, Regularization: 0.036505\n",
      "2019-04-10 01:01:46,718 root         INFO     Train Epoch: 31 [1536/8000 (19%)]\tTotal Loss: 0.284452\n",
      "Reconstruction: 0.249550, Regularization: 0.034902\n",
      "2019-04-10 01:01:46,781 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 0.289093\n",
      "Reconstruction: 0.250113, Regularization: 0.038980\n",
      "2019-04-10 01:01:46,845 root         INFO     Train Epoch: 31 [2560/8000 (32%)]\tTotal Loss: 0.281423\n",
      "Reconstruction: 0.246142, Regularization: 0.035282\n",
      "2019-04-10 01:01:46,908 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.285098\n",
      "Reconstruction: 0.245809, Regularization: 0.039288\n",
      "2019-04-10 01:01:46,972 root         INFO     Train Epoch: 31 [3584/8000 (45%)]\tTotal Loss: 0.285563\n",
      "Reconstruction: 0.256334, Regularization: 0.029229\n",
      "2019-04-10 01:01:47,034 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.288585\n",
      "Reconstruction: 0.252365, Regularization: 0.036220\n",
      "2019-04-10 01:01:47,097 root         INFO     Train Epoch: 31 [4608/8000 (58%)]\tTotal Loss: 0.286104\n",
      "Reconstruction: 0.252222, Regularization: 0.033882\n",
      "2019-04-10 01:01:47,160 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.296261\n",
      "Reconstruction: 0.262792, Regularization: 0.033469\n",
      "2019-04-10 01:01:47,223 root         INFO     Train Epoch: 31 [5632/8000 (70%)]\tTotal Loss: 0.304206\n",
      "Reconstruction: 0.263789, Regularization: 0.040417\n",
      "2019-04-10 01:01:47,286 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 0.292192\n",
      "Reconstruction: 0.258365, Regularization: 0.033828\n",
      "2019-04-10 01:01:47,349 root         INFO     Train Epoch: 31 [6656/8000 (83%)]\tTotal Loss: 0.302483\n",
      "Reconstruction: 0.268862, Regularization: 0.033621\n",
      "2019-04-10 01:01:47,412 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 0.283476\n",
      "Reconstruction: 0.252682, Regularization: 0.030794\n",
      "2019-04-10 01:01:47,475 root         INFO     Train Epoch: 31 [7680/8000 (96%)]\tTotal Loss: 0.284986\n",
      "Reconstruction: 0.254883, Regularization: 0.030103\n",
      "2019-04-10 01:01:47,529 root         INFO     ====> Epoch: 31 Average loss: 0.2907\n",
      "2019-04-10 01:01:47,553 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.266579\n",
      "Reconstruction: 0.236695, Regularization: 0.029884\n",
      "2019-04-10 01:01:47,617 root         INFO     Train Epoch: 32 [512/8000 (6%)]\tTotal Loss: 0.292350\n",
      "Reconstruction: 0.258108, Regularization: 0.034242\n",
      "2019-04-10 01:01:47,681 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.286928\n",
      "Reconstruction: 0.251245, Regularization: 0.035683\n",
      "2019-04-10 01:01:47,745 root         INFO     Train Epoch: 32 [1536/8000 (19%)]\tTotal Loss: 0.284245\n",
      "Reconstruction: 0.247104, Regularization: 0.037141\n",
      "2019-04-10 01:01:47,809 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.281492\n",
      "Reconstruction: 0.251120, Regularization: 0.030372\n",
      "2019-04-10 01:01:47,874 root         INFO     Train Epoch: 32 [2560/8000 (32%)]\tTotal Loss: 0.277745\n",
      "Reconstruction: 0.245980, Regularization: 0.031765\n",
      "2019-04-10 01:01:47,938 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.279782\n",
      "Reconstruction: 0.249221, Regularization: 0.030561\n",
      "2019-04-10 01:01:48,002 root         INFO     Train Epoch: 32 [3584/8000 (45%)]\tTotal Loss: 0.277346\n",
      "Reconstruction: 0.248504, Regularization: 0.028842\n",
      "2019-04-10 01:01:48,066 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.287337\n",
      "Reconstruction: 0.256734, Regularization: 0.030603\n",
      "2019-04-10 01:01:48,130 root         INFO     Train Epoch: 32 [4608/8000 (58%)]\tTotal Loss: 0.279494\n",
      "Reconstruction: 0.251160, Regularization: 0.028335\n",
      "2019-04-10 01:01:48,194 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 0.275257\n",
      "Reconstruction: 0.246199, Regularization: 0.029058\n",
      "2019-04-10 01:01:48,257 root         INFO     Train Epoch: 32 [5632/8000 (70%)]\tTotal Loss: 0.289963\n",
      "Reconstruction: 0.263301, Regularization: 0.026662\n",
      "2019-04-10 01:01:48,321 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.275334\n",
      "Reconstruction: 0.249342, Regularization: 0.025992\n",
      "2019-04-10 01:01:48,383 root         INFO     Train Epoch: 32 [6656/8000 (83%)]\tTotal Loss: 0.283515\n",
      "Reconstruction: 0.249903, Regularization: 0.033612\n",
      "2019-04-10 01:01:48,444 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.278800\n",
      "Reconstruction: 0.250954, Regularization: 0.027846\n",
      "2019-04-10 01:01:48,505 root         INFO     Train Epoch: 32 [7680/8000 (96%)]\tTotal Loss: 0.296337\n",
      "Reconstruction: 0.266293, Regularization: 0.030044\n",
      "2019-04-10 01:01:48,560 root         INFO     ====> Epoch: 32 Average loss: 0.2849\n",
      "2019-04-10 01:01:48,584 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.284285\n",
      "Reconstruction: 0.256289, Regularization: 0.027996\n",
      "2019-04-10 01:01:48,648 root         INFO     Train Epoch: 33 [512/8000 (6%)]\tTotal Loss: 0.293407\n",
      "Reconstruction: 0.266278, Regularization: 0.027129\n",
      "2019-04-10 01:01:48,711 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.276274\n",
      "Reconstruction: 0.251725, Regularization: 0.024549\n",
      "2019-04-10 01:01:48,775 root         INFO     Train Epoch: 33 [1536/8000 (19%)]\tTotal Loss: 0.279991\n",
      "Reconstruction: 0.252120, Regularization: 0.027870\n",
      "2019-04-10 01:01:48,839 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.280830\n",
      "Reconstruction: 0.249299, Regularization: 0.031532\n",
      "2019-04-10 01:01:48,903 root         INFO     Train Epoch: 33 [2560/8000 (32%)]\tTotal Loss: 0.282414\n",
      "Reconstruction: 0.254647, Regularization: 0.027766\n",
      "2019-04-10 01:01:48,968 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.266068\n",
      "Reconstruction: 0.243266, Regularization: 0.022802\n",
      "2019-04-10 01:01:49,033 root         INFO     Train Epoch: 33 [3584/8000 (45%)]\tTotal Loss: 0.278576\n",
      "Reconstruction: 0.251385, Regularization: 0.027191\n",
      "2019-04-10 01:01:49,098 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 0.278781\n",
      "Reconstruction: 0.254775, Regularization: 0.024006\n",
      "2019-04-10 01:01:49,162 root         INFO     Train Epoch: 33 [4608/8000 (58%)]\tTotal Loss: 0.285338\n",
      "Reconstruction: 0.260451, Regularization: 0.024887\n",
      "2019-04-10 01:01:49,227 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.266721\n",
      "Reconstruction: 0.244498, Regularization: 0.022223\n",
      "2019-04-10 01:01:49,291 root         INFO     Train Epoch: 33 [5632/8000 (70%)]\tTotal Loss: 0.288558\n",
      "Reconstruction: 0.261788, Regularization: 0.026771\n",
      "2019-04-10 01:01:49,356 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 0.279738\n",
      "Reconstruction: 0.255775, Regularization: 0.023963\n",
      "2019-04-10 01:01:49,421 root         INFO     Train Epoch: 33 [6656/8000 (83%)]\tTotal Loss: 0.289422\n",
      "Reconstruction: 0.262356, Regularization: 0.027067\n",
      "2019-04-10 01:01:49,485 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.271427\n",
      "Reconstruction: 0.246308, Regularization: 0.025118\n",
      "2019-04-10 01:01:49,549 root         INFO     Train Epoch: 33 [7680/8000 (96%)]\tTotal Loss: 0.268308\n",
      "Reconstruction: 0.248254, Regularization: 0.020053\n",
      "2019-04-10 01:01:49,605 root         INFO     ====> Epoch: 33 Average loss: 0.2798\n",
      "2019-04-10 01:01:49,628 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.276434\n",
      "Reconstruction: 0.251009, Regularization: 0.025424\n",
      "2019-04-10 01:01:49,692 root         INFO     Train Epoch: 34 [512/8000 (6%)]\tTotal Loss: 0.289074\n",
      "Reconstruction: 0.263521, Regularization: 0.025553\n",
      "2019-04-10 01:01:49,756 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.270299\n",
      "Reconstruction: 0.250285, Regularization: 0.020013\n",
      "2019-04-10 01:01:49,819 root         INFO     Train Epoch: 34 [1536/8000 (19%)]\tTotal Loss: 0.271561\n",
      "Reconstruction: 0.248780, Regularization: 0.022781\n",
      "2019-04-10 01:01:49,882 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.271473\n",
      "Reconstruction: 0.245136, Regularization: 0.026337\n",
      "2019-04-10 01:01:49,945 root         INFO     Train Epoch: 34 [2560/8000 (32%)]\tTotal Loss: 0.265586\n",
      "Reconstruction: 0.245789, Regularization: 0.019796\n",
      "2019-04-10 01:01:50,008 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.278894\n",
      "Reconstruction: 0.252797, Regularization: 0.026097\n",
      "2019-04-10 01:01:50,071 root         INFO     Train Epoch: 34 [3584/8000 (45%)]\tTotal Loss: 0.270795\n",
      "Reconstruction: 0.250185, Regularization: 0.020610\n",
      "2019-04-10 01:01:50,133 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.268778\n",
      "Reconstruction: 0.247357, Regularization: 0.021421\n",
      "2019-04-10 01:01:50,196 root         INFO     Train Epoch: 34 [4608/8000 (58%)]\tTotal Loss: 0.271909\n",
      "Reconstruction: 0.251290, Regularization: 0.020619\n",
      "2019-04-10 01:01:50,258 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.268736\n",
      "Reconstruction: 0.245547, Regularization: 0.023189\n",
      "2019-04-10 01:01:50,321 root         INFO     Train Epoch: 34 [5632/8000 (70%)]\tTotal Loss: 0.277827\n",
      "Reconstruction: 0.256115, Regularization: 0.021712\n",
      "2019-04-10 01:01:50,383 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.278557\n",
      "Reconstruction: 0.257501, Regularization: 0.021056\n",
      "2019-04-10 01:01:50,445 root         INFO     Train Epoch: 34 [6656/8000 (83%)]\tTotal Loss: 0.271688\n",
      "Reconstruction: 0.251243, Regularization: 0.020445\n",
      "2019-04-10 01:01:50,508 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 0.270023\n",
      "Reconstruction: 0.252338, Regularization: 0.017684\n",
      "2019-04-10 01:01:50,570 root         INFO     Train Epoch: 34 [7680/8000 (96%)]\tTotal Loss: 0.273769\n",
      "Reconstruction: 0.248971, Regularization: 0.024798\n",
      "2019-04-10 01:01:50,623 root         INFO     ====> Epoch: 34 Average loss: 0.2752\n",
      "2019-04-10 01:01:50,647 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.269769\n",
      "Reconstruction: 0.242628, Regularization: 0.027141\n",
      "2019-04-10 01:01:50,709 root         INFO     Train Epoch: 35 [512/8000 (6%)]\tTotal Loss: 0.276078\n",
      "Reconstruction: 0.251176, Regularization: 0.024903\n",
      "2019-04-10 01:01:50,770 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.280650\n",
      "Reconstruction: 0.260153, Regularization: 0.020497\n",
      "2019-04-10 01:01:50,832 root         INFO     Train Epoch: 35 [1536/8000 (19%)]\tTotal Loss: 0.275051\n",
      "Reconstruction: 0.249613, Regularization: 0.025438\n",
      "2019-04-10 01:01:50,893 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.269315\n",
      "Reconstruction: 0.249968, Regularization: 0.019347\n",
      "2019-04-10 01:01:50,955 root         INFO     Train Epoch: 35 [2560/8000 (32%)]\tTotal Loss: 0.264745\n",
      "Reconstruction: 0.247196, Regularization: 0.017548\n",
      "2019-04-10 01:01:51,017 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.269590\n",
      "Reconstruction: 0.249240, Regularization: 0.020351\n",
      "2019-04-10 01:01:51,078 root         INFO     Train Epoch: 35 [3584/8000 (45%)]\tTotal Loss: 0.273931\n",
      "Reconstruction: 0.253291, Regularization: 0.020641\n",
      "2019-04-10 01:01:51,140 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.268691\n",
      "Reconstruction: 0.247418, Regularization: 0.021273\n",
      "2019-04-10 01:01:51,202 root         INFO     Train Epoch: 35 [4608/8000 (58%)]\tTotal Loss: 0.272800\n",
      "Reconstruction: 0.251411, Regularization: 0.021389\n",
      "2019-04-10 01:01:51,263 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.273007\n",
      "Reconstruction: 0.252715, Regularization: 0.020292\n",
      "2019-04-10 01:01:51,324 root         INFO     Train Epoch: 35 [5632/8000 (70%)]\tTotal Loss: 0.261441\n",
      "Reconstruction: 0.243743, Regularization: 0.017698\n",
      "2019-04-10 01:01:51,386 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.260889\n",
      "Reconstruction: 0.238936, Regularization: 0.021954\n",
      "2019-04-10 01:01:51,449 root         INFO     Train Epoch: 35 [6656/8000 (83%)]\tTotal Loss: 0.273278\n",
      "Reconstruction: 0.252631, Regularization: 0.020646\n",
      "2019-04-10 01:01:51,513 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.266999\n",
      "Reconstruction: 0.246787, Regularization: 0.020212\n",
      "2019-04-10 01:01:51,578 root         INFO     Train Epoch: 35 [7680/8000 (96%)]\tTotal Loss: 0.282428\n",
      "Reconstruction: 0.259840, Regularization: 0.022588\n",
      "2019-04-10 01:01:51,631 root         INFO     ====> Epoch: 35 Average loss: 0.2712\n",
      "2019-04-10 01:01:51,655 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 0.281872\n",
      "Reconstruction: 0.259634, Regularization: 0.022238\n",
      "2019-04-10 01:01:51,718 root         INFO     Train Epoch: 36 [512/8000 (6%)]\tTotal Loss: 0.261717\n",
      "Reconstruction: 0.239956, Regularization: 0.021760\n",
      "2019-04-10 01:01:51,781 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.286613\n",
      "Reconstruction: 0.266477, Regularization: 0.020136\n",
      "2019-04-10 01:01:51,843 root         INFO     Train Epoch: 36 [1536/8000 (19%)]\tTotal Loss: 0.267439\n",
      "Reconstruction: 0.248418, Regularization: 0.019021\n",
      "2019-04-10 01:01:51,906 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.275316\n",
      "Reconstruction: 0.256534, Regularization: 0.018782\n",
      "2019-04-10 01:01:51,969 root         INFO     Train Epoch: 36 [2560/8000 (32%)]\tTotal Loss: 0.258124\n",
      "Reconstruction: 0.239378, Regularization: 0.018747\n",
      "2019-04-10 01:01:52,032 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.266716\n",
      "Reconstruction: 0.249733, Regularization: 0.016983\n",
      "2019-04-10 01:01:52,094 root         INFO     Train Epoch: 36 [3584/8000 (45%)]\tTotal Loss: 0.272148\n",
      "Reconstruction: 0.251651, Regularization: 0.020498\n",
      "2019-04-10 01:01:52,157 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.262007\n",
      "Reconstruction: 0.245078, Regularization: 0.016929\n",
      "2019-04-10 01:01:52,221 root         INFO     Train Epoch: 36 [4608/8000 (58%)]\tTotal Loss: 0.250698\n",
      "Reconstruction: 0.234942, Regularization: 0.015756\n",
      "2019-04-10 01:01:52,283 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.267691\n",
      "Reconstruction: 0.251033, Regularization: 0.016658\n",
      "2019-04-10 01:01:52,346 root         INFO     Train Epoch: 36 [5632/8000 (70%)]\tTotal Loss: 0.267102\n",
      "Reconstruction: 0.248137, Regularization: 0.018965\n",
      "2019-04-10 01:01:52,409 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 0.269510\n",
      "Reconstruction: 0.252184, Regularization: 0.017326\n",
      "2019-04-10 01:01:52,472 root         INFO     Train Epoch: 36 [6656/8000 (83%)]\tTotal Loss: 0.276654\n",
      "Reconstruction: 0.260946, Regularization: 0.015708\n",
      "2019-04-10 01:01:52,535 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.269926\n",
      "Reconstruction: 0.248431, Regularization: 0.021495\n",
      "2019-04-10 01:01:52,598 root         INFO     Train Epoch: 36 [7680/8000 (96%)]\tTotal Loss: 0.265395\n",
      "Reconstruction: 0.247325, Regularization: 0.018070\n",
      "2019-04-10 01:01:52,651 root         INFO     ====> Epoch: 36 Average loss: 0.2672\n",
      "2019-04-10 01:01:52,675 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.266170\n",
      "Reconstruction: 0.248590, Regularization: 0.017580\n",
      "2019-04-10 01:01:52,738 root         INFO     Train Epoch: 37 [512/8000 (6%)]\tTotal Loss: 0.263224\n",
      "Reconstruction: 0.245681, Regularization: 0.017542\n",
      "2019-04-10 01:01:52,801 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.260181\n",
      "Reconstruction: 0.245764, Regularization: 0.014417\n",
      "2019-04-10 01:01:52,864 root         INFO     Train Epoch: 37 [1536/8000 (19%)]\tTotal Loss: 0.265516\n",
      "Reconstruction: 0.249077, Regularization: 0.016439\n",
      "2019-04-10 01:01:52,927 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.271900\n",
      "Reconstruction: 0.254696, Regularization: 0.017204\n",
      "2019-04-10 01:01:52,990 root         INFO     Train Epoch: 37 [2560/8000 (32%)]\tTotal Loss: 0.262282\n",
      "Reconstruction: 0.245732, Regularization: 0.016550\n",
      "2019-04-10 01:01:53,053 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 0.271633\n",
      "Reconstruction: 0.256263, Regularization: 0.015370\n",
      "2019-04-10 01:01:53,116 root         INFO     Train Epoch: 37 [3584/8000 (45%)]\tTotal Loss: 0.258508\n",
      "Reconstruction: 0.242961, Regularization: 0.015546\n",
      "2019-04-10 01:01:53,180 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.270700\n",
      "Reconstruction: 0.255768, Regularization: 0.014932\n",
      "2019-04-10 01:01:53,243 root         INFO     Train Epoch: 37 [4608/8000 (58%)]\tTotal Loss: 0.257869\n",
      "Reconstruction: 0.239733, Regularization: 0.018135\n",
      "2019-04-10 01:01:53,306 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.263460\n",
      "Reconstruction: 0.247328, Regularization: 0.016133\n",
      "2019-04-10 01:01:53,369 root         INFO     Train Epoch: 37 [5632/8000 (70%)]\tTotal Loss: 0.257241\n",
      "Reconstruction: 0.242676, Regularization: 0.014565\n",
      "2019-04-10 01:01:53,431 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.269197\n",
      "Reconstruction: 0.255105, Regularization: 0.014093\n",
      "2019-04-10 01:01:53,493 root         INFO     Train Epoch: 37 [6656/8000 (83%)]\tTotal Loss: 0.268889\n",
      "Reconstruction: 0.251879, Regularization: 0.017010\n",
      "2019-04-10 01:01:53,555 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.269961\n",
      "Reconstruction: 0.255135, Regularization: 0.014826\n",
      "2019-04-10 01:01:53,618 root         INFO     Train Epoch: 37 [7680/8000 (96%)]\tTotal Loss: 0.264713\n",
      "Reconstruction: 0.249544, Regularization: 0.015169\n",
      "2019-04-10 01:01:53,672 root         INFO     ====> Epoch: 37 Average loss: 0.2634\n",
      "2019-04-10 01:01:53,696 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.259124\n",
      "Reconstruction: 0.244078, Regularization: 0.015046\n",
      "2019-04-10 01:01:53,759 root         INFO     Train Epoch: 38 [512/8000 (6%)]\tTotal Loss: 0.264850\n",
      "Reconstruction: 0.250500, Regularization: 0.014349\n",
      "2019-04-10 01:01:53,821 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.255630\n",
      "Reconstruction: 0.242000, Regularization: 0.013629\n",
      "2019-04-10 01:01:53,883 root         INFO     Train Epoch: 38 [1536/8000 (19%)]\tTotal Loss: 0.264839\n",
      "Reconstruction: 0.250121, Regularization: 0.014717\n",
      "2019-04-10 01:01:53,946 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.262686\n",
      "Reconstruction: 0.249204, Regularization: 0.013482\n",
      "2019-04-10 01:01:54,009 root         INFO     Train Epoch: 38 [2560/8000 (32%)]\tTotal Loss: 0.255965\n",
      "Reconstruction: 0.242610, Regularization: 0.013355\n",
      "2019-04-10 01:01:54,071 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 0.262183\n",
      "Reconstruction: 0.249699, Regularization: 0.012483\n",
      "2019-04-10 01:01:54,134 root         INFO     Train Epoch: 38 [3584/8000 (45%)]\tTotal Loss: 0.267860\n",
      "Reconstruction: 0.250770, Regularization: 0.017090\n",
      "2019-04-10 01:01:54,196 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.256172\n",
      "Reconstruction: 0.240835, Regularization: 0.015338\n",
      "2019-04-10 01:01:54,259 root         INFO     Train Epoch: 38 [4608/8000 (58%)]\tTotal Loss: 0.266094\n",
      "Reconstruction: 0.252655, Regularization: 0.013439\n",
      "2019-04-10 01:01:54,322 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.255313\n",
      "Reconstruction: 0.241104, Regularization: 0.014209\n",
      "2019-04-10 01:01:54,384 root         INFO     Train Epoch: 38 [5632/8000 (70%)]\tTotal Loss: 0.264576\n",
      "Reconstruction: 0.251314, Regularization: 0.013261\n",
      "2019-04-10 01:01:54,447 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.253799\n",
      "Reconstruction: 0.241681, Regularization: 0.012118\n",
      "2019-04-10 01:01:54,510 root         INFO     Train Epoch: 38 [6656/8000 (83%)]\tTotal Loss: 0.258790\n",
      "Reconstruction: 0.245094, Regularization: 0.013696\n",
      "2019-04-10 01:01:54,572 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.257864\n",
      "Reconstruction: 0.245716, Regularization: 0.012149\n",
      "2019-04-10 01:01:54,634 root         INFO     Train Epoch: 38 [7680/8000 (96%)]\tTotal Loss: 0.264625\n",
      "Reconstruction: 0.251390, Regularization: 0.013236\n",
      "2019-04-10 01:01:54,688 root         INFO     ====> Epoch: 38 Average loss: 0.2603\n",
      "2019-04-10 01:01:54,712 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 0.260523\n",
      "Reconstruction: 0.247334, Regularization: 0.013189\n",
      "2019-04-10 01:01:54,775 root         INFO     Train Epoch: 39 [512/8000 (6%)]\tTotal Loss: 0.255236\n",
      "Reconstruction: 0.241537, Regularization: 0.013699\n",
      "2019-04-10 01:01:54,838 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.268528\n",
      "Reconstruction: 0.254165, Regularization: 0.014363\n",
      "2019-04-10 01:01:54,901 root         INFO     Train Epoch: 39 [1536/8000 (19%)]\tTotal Loss: 0.266237\n",
      "Reconstruction: 0.254316, Regularization: 0.011921\n",
      "2019-04-10 01:01:54,964 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.252779\n",
      "Reconstruction: 0.241922, Regularization: 0.010857\n",
      "2019-04-10 01:01:55,026 root         INFO     Train Epoch: 39 [2560/8000 (32%)]\tTotal Loss: 0.258798\n",
      "Reconstruction: 0.245565, Regularization: 0.013233\n",
      "2019-04-10 01:01:55,089 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.258131\n",
      "Reconstruction: 0.246401, Regularization: 0.011730\n",
      "2019-04-10 01:01:55,152 root         INFO     Train Epoch: 39 [3584/8000 (45%)]\tTotal Loss: 0.262903\n",
      "Reconstruction: 0.250953, Regularization: 0.011950\n",
      "2019-04-10 01:01:55,214 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.263305\n",
      "Reconstruction: 0.250676, Regularization: 0.012629\n",
      "2019-04-10 01:01:55,276 root         INFO     Train Epoch: 39 [4608/8000 (58%)]\tTotal Loss: 0.256144\n",
      "Reconstruction: 0.244738, Regularization: 0.011406\n",
      "2019-04-10 01:01:55,337 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.255170\n",
      "Reconstruction: 0.242792, Regularization: 0.012378\n",
      "2019-04-10 01:01:55,398 root         INFO     Train Epoch: 39 [5632/8000 (70%)]\tTotal Loss: 0.272045\n",
      "Reconstruction: 0.260114, Regularization: 0.011931\n",
      "2019-04-10 01:01:55,460 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.262695\n",
      "Reconstruction: 0.250637, Regularization: 0.012058\n",
      "2019-04-10 01:01:55,522 root         INFO     Train Epoch: 39 [6656/8000 (83%)]\tTotal Loss: 0.259913\n",
      "Reconstruction: 0.247869, Regularization: 0.012044\n",
      "2019-04-10 01:01:55,584 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.249808\n",
      "Reconstruction: 0.239312, Regularization: 0.010496\n",
      "2019-04-10 01:01:55,645 root         INFO     Train Epoch: 39 [7680/8000 (96%)]\tTotal Loss: 0.255199\n",
      "Reconstruction: 0.242608, Regularization: 0.012591\n",
      "2019-04-10 01:01:55,698 root         INFO     ====> Epoch: 39 Average loss: 0.2575\n",
      "2019-04-10 01:01:55,722 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.255190\n",
      "Reconstruction: 0.244075, Regularization: 0.011115\n",
      "2019-04-10 01:01:55,785 root         INFO     Train Epoch: 40 [512/8000 (6%)]\tTotal Loss: 0.253966\n",
      "Reconstruction: 0.241326, Regularization: 0.012640\n",
      "2019-04-10 01:01:55,849 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.249510\n",
      "Reconstruction: 0.238206, Regularization: 0.011304\n",
      "2019-04-10 01:01:55,911 root         INFO     Train Epoch: 40 [1536/8000 (19%)]\tTotal Loss: 0.255623\n",
      "Reconstruction: 0.245494, Regularization: 0.010129\n",
      "2019-04-10 01:01:55,975 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.245352\n",
      "Reconstruction: 0.235444, Regularization: 0.009908\n",
      "2019-04-10 01:01:56,038 root         INFO     Train Epoch: 40 [2560/8000 (32%)]\tTotal Loss: 0.254676\n",
      "Reconstruction: 0.244015, Regularization: 0.010661\n",
      "2019-04-10 01:01:56,100 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.260132\n",
      "Reconstruction: 0.247872, Regularization: 0.012260\n",
      "2019-04-10 01:01:56,163 root         INFO     Train Epoch: 40 [3584/8000 (45%)]\tTotal Loss: 0.264862\n",
      "Reconstruction: 0.253518, Regularization: 0.011344\n",
      "2019-04-10 01:01:56,226 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.249826\n",
      "Reconstruction: 0.238650, Regularization: 0.011176\n",
      "2019-04-10 01:01:56,290 root         INFO     Train Epoch: 40 [4608/8000 (58%)]\tTotal Loss: 0.258050\n",
      "Reconstruction: 0.246782, Regularization: 0.011268\n",
      "2019-04-10 01:01:56,353 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 0.256560\n",
      "Reconstruction: 0.245841, Regularization: 0.010719\n",
      "2019-04-10 01:01:56,416 root         INFO     Train Epoch: 40 [5632/8000 (70%)]\tTotal Loss: 0.252732\n",
      "Reconstruction: 0.242314, Regularization: 0.010418\n",
      "2019-04-10 01:01:56,479 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.249722\n",
      "Reconstruction: 0.239148, Regularization: 0.010574\n",
      "2019-04-10 01:01:56,542 root         INFO     Train Epoch: 40 [6656/8000 (83%)]\tTotal Loss: 0.247986\n",
      "Reconstruction: 0.236958, Regularization: 0.011028\n",
      "2019-04-10 01:01:56,605 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.259353\n",
      "Reconstruction: 0.248871, Regularization: 0.010482\n",
      "2019-04-10 01:01:56,668 root         INFO     Train Epoch: 40 [7680/8000 (96%)]\tTotal Loss: 0.259222\n",
      "Reconstruction: 0.247829, Regularization: 0.011393\n",
      "2019-04-10 01:01:56,722 root         INFO     ====> Epoch: 40 Average loss: 0.2545\n",
      "2019-04-10 01:01:56,746 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 0.256488\n",
      "Reconstruction: 0.247464, Regularization: 0.009024\n",
      "2019-04-10 01:01:56,808 root         INFO     Train Epoch: 41 [512/8000 (6%)]\tTotal Loss: 0.253895\n",
      "Reconstruction: 0.245017, Regularization: 0.008877\n",
      "2019-04-10 01:01:56,869 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.262355\n",
      "Reconstruction: 0.252930, Regularization: 0.009425\n",
      "2019-04-10 01:01:56,931 root         INFO     Train Epoch: 41 [1536/8000 (19%)]\tTotal Loss: 0.249435\n",
      "Reconstruction: 0.240696, Regularization: 0.008739\n",
      "2019-04-10 01:01:56,993 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 0.249666\n",
      "Reconstruction: 0.240441, Regularization: 0.009225\n",
      "2019-04-10 01:01:57,056 root         INFO     Train Epoch: 41 [2560/8000 (32%)]\tTotal Loss: 0.247734\n",
      "Reconstruction: 0.238755, Regularization: 0.008979\n",
      "2019-04-10 01:01:57,118 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.255015\n",
      "Reconstruction: 0.244653, Regularization: 0.010362\n",
      "2019-04-10 01:01:57,181 root         INFO     Train Epoch: 41 [3584/8000 (45%)]\tTotal Loss: 0.255180\n",
      "Reconstruction: 0.246096, Regularization: 0.009085\n",
      "2019-04-10 01:01:57,243 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.249844\n",
      "Reconstruction: 0.240972, Regularization: 0.008873\n",
      "2019-04-10 01:01:57,306 root         INFO     Train Epoch: 41 [4608/8000 (58%)]\tTotal Loss: 0.248082\n",
      "Reconstruction: 0.240803, Regularization: 0.007279\n",
      "2019-04-10 01:01:57,368 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 0.255439\n",
      "Reconstruction: 0.246668, Regularization: 0.008772\n",
      "2019-04-10 01:01:57,430 root         INFO     Train Epoch: 41 [5632/8000 (70%)]\tTotal Loss: 0.250731\n",
      "Reconstruction: 0.242276, Regularization: 0.008455\n",
      "2019-04-10 01:01:57,492 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.243497\n",
      "Reconstruction: 0.236100, Regularization: 0.007397\n",
      "2019-04-10 01:01:57,555 root         INFO     Train Epoch: 41 [6656/8000 (83%)]\tTotal Loss: 0.247911\n",
      "Reconstruction: 0.239974, Regularization: 0.007937\n",
      "2019-04-10 01:01:57,617 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.263153\n",
      "Reconstruction: 0.255086, Regularization: 0.008068\n",
      "2019-04-10 01:01:57,680 root         INFO     Train Epoch: 41 [7680/8000 (96%)]\tTotal Loss: 0.243949\n",
      "Reconstruction: 0.237049, Regularization: 0.006900\n",
      "2019-04-10 01:01:57,733 root         INFO     ====> Epoch: 41 Average loss: 0.2515\n",
      "2019-04-10 01:01:57,757 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.255725\n",
      "Reconstruction: 0.247103, Regularization: 0.008622\n",
      "2019-04-10 01:01:57,821 root         INFO     Train Epoch: 42 [512/8000 (6%)]\tTotal Loss: 0.257551\n",
      "Reconstruction: 0.248411, Regularization: 0.009139\n",
      "2019-04-10 01:01:57,884 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.255035\n",
      "Reconstruction: 0.246805, Regularization: 0.008230\n",
      "2019-04-10 01:01:57,946 root         INFO     Train Epoch: 42 [1536/8000 (19%)]\tTotal Loss: 0.248955\n",
      "Reconstruction: 0.240268, Regularization: 0.008687\n",
      "2019-04-10 01:01:58,010 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.249822\n",
      "Reconstruction: 0.241429, Regularization: 0.008393\n",
      "2019-04-10 01:01:58,074 root         INFO     Train Epoch: 42 [2560/8000 (32%)]\tTotal Loss: 0.247010\n",
      "Reconstruction: 0.239718, Regularization: 0.007292\n",
      "2019-04-10 01:01:58,137 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 0.253261\n",
      "Reconstruction: 0.245030, Regularization: 0.008230\n",
      "2019-04-10 01:01:58,201 root         INFO     Train Epoch: 42 [3584/8000 (45%)]\tTotal Loss: 0.250950\n",
      "Reconstruction: 0.242923, Regularization: 0.008028\n",
      "2019-04-10 01:01:58,264 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.256346\n",
      "Reconstruction: 0.247886, Regularization: 0.008459\n",
      "2019-04-10 01:01:58,327 root         INFO     Train Epoch: 42 [4608/8000 (58%)]\tTotal Loss: 0.256450\n",
      "Reconstruction: 0.248207, Regularization: 0.008243\n",
      "2019-04-10 01:01:58,389 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.253219\n",
      "Reconstruction: 0.245561, Regularization: 0.007658\n",
      "2019-04-10 01:01:58,451 root         INFO     Train Epoch: 42 [5632/8000 (70%)]\tTotal Loss: 0.249157\n",
      "Reconstruction: 0.241802, Regularization: 0.007355\n",
      "2019-04-10 01:01:58,512 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.247304\n",
      "Reconstruction: 0.240846, Regularization: 0.006458\n",
      "2019-04-10 01:01:58,574 root         INFO     Train Epoch: 42 [6656/8000 (83%)]\tTotal Loss: 0.243527\n",
      "Reconstruction: 0.236060, Regularization: 0.007468\n",
      "2019-04-10 01:01:58,636 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.248360\n",
      "Reconstruction: 0.240911, Regularization: 0.007449\n",
      "2019-04-10 01:01:58,698 root         INFO     Train Epoch: 42 [7680/8000 (96%)]\tTotal Loss: 0.244442\n",
      "Reconstruction: 0.236453, Regularization: 0.007990\n",
      "2019-04-10 01:01:58,752 root         INFO     ====> Epoch: 42 Average loss: 0.2488\n",
      "2019-04-10 01:01:58,776 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.244367\n",
      "Reconstruction: 0.236665, Regularization: 0.007702\n",
      "2019-04-10 01:01:58,840 root         INFO     Train Epoch: 43 [512/8000 (6%)]\tTotal Loss: 0.241970\n",
      "Reconstruction: 0.236218, Regularization: 0.005752\n",
      "2019-04-10 01:01:58,904 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.255301\n",
      "Reconstruction: 0.247989, Regularization: 0.007311\n",
      "2019-04-10 01:01:58,967 root         INFO     Train Epoch: 43 [1536/8000 (19%)]\tTotal Loss: 0.250560\n",
      "Reconstruction: 0.244213, Regularization: 0.006347\n",
      "2019-04-10 01:01:59,030 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.247893\n",
      "Reconstruction: 0.241032, Regularization: 0.006861\n",
      "2019-04-10 01:01:59,095 root         INFO     Train Epoch: 43 [2560/8000 (32%)]\tTotal Loss: 0.254892\n",
      "Reconstruction: 0.248439, Regularization: 0.006453\n",
      "2019-04-10 01:01:59,157 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.242193\n",
      "Reconstruction: 0.236889, Regularization: 0.005305\n",
      "2019-04-10 01:01:59,220 root         INFO     Train Epoch: 43 [3584/8000 (45%)]\tTotal Loss: 0.245155\n",
      "Reconstruction: 0.238799, Regularization: 0.006356\n",
      "2019-04-10 01:01:59,282 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.265107\n",
      "Reconstruction: 0.257795, Regularization: 0.007312\n",
      "2019-04-10 01:01:59,344 root         INFO     Train Epoch: 43 [4608/8000 (58%)]\tTotal Loss: 0.252712\n",
      "Reconstruction: 0.245087, Regularization: 0.007625\n",
      "2019-04-10 01:01:59,407 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.250275\n",
      "Reconstruction: 0.242852, Regularization: 0.007423\n",
      "2019-04-10 01:01:59,470 root         INFO     Train Epoch: 43 [5632/8000 (70%)]\tTotal Loss: 0.242902\n",
      "Reconstruction: 0.236374, Regularization: 0.006528\n",
      "2019-04-10 01:01:59,533 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.251526\n",
      "Reconstruction: 0.245472, Regularization: 0.006054\n",
      "2019-04-10 01:01:59,596 root         INFO     Train Epoch: 43 [6656/8000 (83%)]\tTotal Loss: 0.240391\n",
      "Reconstruction: 0.234698, Regularization: 0.005694\n",
      "2019-04-10 01:01:59,659 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.240462\n",
      "Reconstruction: 0.234185, Regularization: 0.006277\n",
      "2019-04-10 01:01:59,722 root         INFO     Train Epoch: 43 [7680/8000 (96%)]\tTotal Loss: 0.240075\n",
      "Reconstruction: 0.233638, Regularization: 0.006437\n",
      "2019-04-10 01:01:59,776 root         INFO     ====> Epoch: 43 Average loss: 0.2462\n",
      "2019-04-10 01:01:59,800 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.233698\n",
      "Reconstruction: 0.228763, Regularization: 0.004935\n",
      "2019-04-10 01:01:59,863 root         INFO     Train Epoch: 44 [512/8000 (6%)]\tTotal Loss: 0.241620\n",
      "Reconstruction: 0.236103, Regularization: 0.005516\n",
      "2019-04-10 01:01:59,927 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.249113\n",
      "Reconstruction: 0.243133, Regularization: 0.005980\n",
      "2019-04-10 01:01:59,990 root         INFO     Train Epoch: 44 [1536/8000 (19%)]\tTotal Loss: 0.238875\n",
      "Reconstruction: 0.232867, Regularization: 0.006009\n",
      "2019-04-10 01:02:00,053 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.242241\n",
      "Reconstruction: 0.235983, Regularization: 0.006257\n",
      "2019-04-10 01:02:00,116 root         INFO     Train Epoch: 44 [2560/8000 (32%)]\tTotal Loss: 0.248785\n",
      "Reconstruction: 0.242227, Regularization: 0.006558\n",
      "2019-04-10 01:02:00,179 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.247895\n",
      "Reconstruction: 0.242151, Regularization: 0.005744\n",
      "2019-04-10 01:02:00,242 root         INFO     Train Epoch: 44 [3584/8000 (45%)]\tTotal Loss: 0.246302\n",
      "Reconstruction: 0.240528, Regularization: 0.005774\n",
      "2019-04-10 01:02:00,304 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.243787\n",
      "Reconstruction: 0.238303, Regularization: 0.005484\n",
      "2019-04-10 01:02:00,365 root         INFO     Train Epoch: 44 [4608/8000 (58%)]\tTotal Loss: 0.244223\n",
      "Reconstruction: 0.238816, Regularization: 0.005408\n",
      "2019-04-10 01:02:00,427 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.249136\n",
      "Reconstruction: 0.243195, Regularization: 0.005941\n",
      "2019-04-10 01:02:00,491 root         INFO     Train Epoch: 44 [5632/8000 (70%)]\tTotal Loss: 0.249059\n",
      "Reconstruction: 0.243268, Regularization: 0.005791\n",
      "2019-04-10 01:02:00,552 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.243646\n",
      "Reconstruction: 0.237724, Regularization: 0.005922\n",
      "2019-04-10 01:02:00,614 root         INFO     Train Epoch: 44 [6656/8000 (83%)]\tTotal Loss: 0.240220\n",
      "Reconstruction: 0.235733, Regularization: 0.004486\n",
      "2019-04-10 01:02:00,677 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.248164\n",
      "Reconstruction: 0.242483, Regularization: 0.005681\n",
      "2019-04-10 01:02:00,740 root         INFO     Train Epoch: 44 [7680/8000 (96%)]\tTotal Loss: 0.241389\n",
      "Reconstruction: 0.236741, Regularization: 0.004648\n",
      "2019-04-10 01:02:00,794 root         INFO     ====> Epoch: 44 Average loss: 0.2432\n",
      "2019-04-10 01:02:00,818 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.251141\n",
      "Reconstruction: 0.245646, Regularization: 0.005494\n",
      "2019-04-10 01:02:00,881 root         INFO     Train Epoch: 45 [512/8000 (6%)]\tTotal Loss: 0.244734\n",
      "Reconstruction: 0.239515, Regularization: 0.005219\n",
      "2019-04-10 01:02:00,945 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 0.246245\n",
      "Reconstruction: 0.241066, Regularization: 0.005179\n",
      "2019-04-10 01:02:01,008 root         INFO     Train Epoch: 45 [1536/8000 (19%)]\tTotal Loss: 0.252612\n",
      "Reconstruction: 0.246854, Regularization: 0.005758\n",
      "2019-04-10 01:02:01,072 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.240680\n",
      "Reconstruction: 0.236102, Regularization: 0.004578\n",
      "2019-04-10 01:02:01,135 root         INFO     Train Epoch: 45 [2560/8000 (32%)]\tTotal Loss: 0.253000\n",
      "Reconstruction: 0.247246, Regularization: 0.005754\n",
      "2019-04-10 01:02:01,198 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.244877\n",
      "Reconstruction: 0.239995, Regularization: 0.004882\n",
      "2019-04-10 01:02:01,262 root         INFO     Train Epoch: 45 [3584/8000 (45%)]\tTotal Loss: 0.244735\n",
      "Reconstruction: 0.240002, Regularization: 0.004733\n",
      "2019-04-10 01:02:01,326 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.233266\n",
      "Reconstruction: 0.228908, Regularization: 0.004359\n",
      "2019-04-10 01:02:01,390 root         INFO     Train Epoch: 45 [4608/8000 (58%)]\tTotal Loss: 0.246454\n",
      "Reconstruction: 0.241139, Regularization: 0.005315\n",
      "2019-04-10 01:02:01,453 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.238073\n",
      "Reconstruction: 0.233919, Regularization: 0.004154\n",
      "2019-04-10 01:02:01,517 root         INFO     Train Epoch: 45 [5632/8000 (70%)]\tTotal Loss: 0.233324\n",
      "Reconstruction: 0.229719, Regularization: 0.003605\n",
      "2019-04-10 01:02:01,580 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.234226\n",
      "Reconstruction: 0.230201, Regularization: 0.004024\n",
      "2019-04-10 01:02:01,643 root         INFO     Train Epoch: 45 [6656/8000 (83%)]\tTotal Loss: 0.232822\n",
      "Reconstruction: 0.228859, Regularization: 0.003963\n",
      "2019-04-10 01:02:01,706 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.239992\n",
      "Reconstruction: 0.235808, Regularization: 0.004185\n",
      "2019-04-10 01:02:01,769 root         INFO     Train Epoch: 45 [7680/8000 (96%)]\tTotal Loss: 0.237402\n",
      "Reconstruction: 0.233384, Regularization: 0.004018\n",
      "2019-04-10 01:02:01,823 root         INFO     ====> Epoch: 45 Average loss: 0.2409\n",
      "2019-04-10 01:02:01,848 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.239180\n",
      "Reconstruction: 0.235424, Regularization: 0.003755\n",
      "2019-04-10 01:02:01,912 root         INFO     Train Epoch: 46 [512/8000 (6%)]\tTotal Loss: 0.236454\n",
      "Reconstruction: 0.232962, Regularization: 0.003492\n",
      "2019-04-10 01:02:01,975 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.250512\n",
      "Reconstruction: 0.245904, Regularization: 0.004609\n",
      "2019-04-10 01:02:02,039 root         INFO     Train Epoch: 46 [1536/8000 (19%)]\tTotal Loss: 0.231164\n",
      "Reconstruction: 0.227569, Regularization: 0.003595\n",
      "2019-04-10 01:02:02,102 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.238044\n",
      "Reconstruction: 0.233602, Regularization: 0.004442\n",
      "2019-04-10 01:02:02,166 root         INFO     Train Epoch: 46 [2560/8000 (32%)]\tTotal Loss: 0.237679\n",
      "Reconstruction: 0.233671, Regularization: 0.004008\n",
      "2019-04-10 01:02:02,230 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.243089\n",
      "Reconstruction: 0.238570, Regularization: 0.004519\n",
      "2019-04-10 01:02:02,293 root         INFO     Train Epoch: 46 [3584/8000 (45%)]\tTotal Loss: 0.244415\n",
      "Reconstruction: 0.239582, Regularization: 0.004833\n",
      "2019-04-10 01:02:02,356 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.248121\n",
      "Reconstruction: 0.243484, Regularization: 0.004637\n",
      "2019-04-10 01:02:02,419 root         INFO     Train Epoch: 46 [4608/8000 (58%)]\tTotal Loss: 0.237704\n",
      "Reconstruction: 0.233869, Regularization: 0.003835\n",
      "2019-04-10 01:02:02,483 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.238896\n",
      "Reconstruction: 0.235021, Regularization: 0.003876\n",
      "2019-04-10 01:02:02,547 root         INFO     Train Epoch: 46 [5632/8000 (70%)]\tTotal Loss: 0.239798\n",
      "Reconstruction: 0.235922, Regularization: 0.003876\n",
      "2019-04-10 01:02:02,610 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.237841\n",
      "Reconstruction: 0.234288, Regularization: 0.003553\n",
      "2019-04-10 01:02:02,674 root         INFO     Train Epoch: 46 [6656/8000 (83%)]\tTotal Loss: 0.238833\n",
      "Reconstruction: 0.234621, Regularization: 0.004212\n",
      "2019-04-10 01:02:02,737 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.241573\n",
      "Reconstruction: 0.237669, Regularization: 0.003904\n",
      "2019-04-10 01:02:02,800 root         INFO     Train Epoch: 46 [7680/8000 (96%)]\tTotal Loss: 0.234916\n",
      "Reconstruction: 0.231433, Regularization: 0.003483\n",
      "2019-04-10 01:02:02,855 root         INFO     ====> Epoch: 46 Average loss: 0.2388\n",
      "2019-04-10 01:02:02,879 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.236824\n",
      "Reconstruction: 0.232513, Regularization: 0.004311\n",
      "2019-04-10 01:02:02,942 root         INFO     Train Epoch: 47 [512/8000 (6%)]\tTotal Loss: 0.242658\n",
      "Reconstruction: 0.239094, Regularization: 0.003564\n",
      "2019-04-10 01:02:03,005 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.236225\n",
      "Reconstruction: 0.232515, Regularization: 0.003710\n",
      "2019-04-10 01:02:03,069 root         INFO     Train Epoch: 47 [1536/8000 (19%)]\tTotal Loss: 0.229869\n",
      "Reconstruction: 0.227083, Regularization: 0.002786\n",
      "2019-04-10 01:02:03,132 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.233726\n",
      "Reconstruction: 0.230332, Regularization: 0.003394\n",
      "2019-04-10 01:02:03,195 root         INFO     Train Epoch: 47 [2560/8000 (32%)]\tTotal Loss: 0.236610\n",
      "Reconstruction: 0.232933, Regularization: 0.003677\n",
      "2019-04-10 01:02:03,258 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.238837\n",
      "Reconstruction: 0.235263, Regularization: 0.003574\n",
      "2019-04-10 01:02:03,321 root         INFO     Train Epoch: 47 [3584/8000 (45%)]\tTotal Loss: 0.234106\n",
      "Reconstruction: 0.230995, Regularization: 0.003111\n",
      "2019-04-10 01:02:03,384 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.233044\n",
      "Reconstruction: 0.230261, Regularization: 0.002783\n",
      "2019-04-10 01:02:03,446 root         INFO     Train Epoch: 47 [4608/8000 (58%)]\tTotal Loss: 0.242700\n",
      "Reconstruction: 0.239212, Regularization: 0.003488\n",
      "2019-04-10 01:02:03,509 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.233803\n",
      "Reconstruction: 0.230849, Regularization: 0.002953\n",
      "2019-04-10 01:02:03,572 root         INFO     Train Epoch: 47 [5632/8000 (70%)]\tTotal Loss: 0.243297\n",
      "Reconstruction: 0.240093, Regularization: 0.003204\n",
      "2019-04-10 01:02:03,634 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.233283\n",
      "Reconstruction: 0.230231, Regularization: 0.003051\n",
      "2019-04-10 01:02:03,696 root         INFO     Train Epoch: 47 [6656/8000 (83%)]\tTotal Loss: 0.231729\n",
      "Reconstruction: 0.228708, Regularization: 0.003022\n",
      "2019-04-10 01:02:03,759 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.233222\n",
      "Reconstruction: 0.230204, Regularization: 0.003018\n",
      "2019-04-10 01:02:03,819 root         INFO     Train Epoch: 47 [7680/8000 (96%)]\tTotal Loss: 0.231181\n",
      "Reconstruction: 0.228470, Regularization: 0.002711\n",
      "2019-04-10 01:02:03,872 root         INFO     ====> Epoch: 47 Average loss: 0.2359\n",
      "2019-04-10 01:02:03,895 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.238054\n",
      "Reconstruction: 0.235710, Regularization: 0.002343\n",
      "2019-04-10 01:02:03,957 root         INFO     Train Epoch: 48 [512/8000 (6%)]\tTotal Loss: 0.241053\n",
      "Reconstruction: 0.238295, Regularization: 0.002758\n",
      "2019-04-10 01:02:04,019 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.233769\n",
      "Reconstruction: 0.230882, Regularization: 0.002887\n",
      "2019-04-10 01:02:04,081 root         INFO     Train Epoch: 48 [1536/8000 (19%)]\tTotal Loss: 0.228433\n",
      "Reconstruction: 0.225687, Regularization: 0.002746\n",
      "2019-04-10 01:02:04,144 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.231921\n",
      "Reconstruction: 0.229144, Regularization: 0.002778\n",
      "2019-04-10 01:02:04,206 root         INFO     Train Epoch: 48 [2560/8000 (32%)]\tTotal Loss: 0.234450\n",
      "Reconstruction: 0.232090, Regularization: 0.002359\n",
      "2019-04-10 01:02:04,268 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.229726\n",
      "Reconstruction: 0.227397, Regularization: 0.002330\n",
      "2019-04-10 01:02:04,331 root         INFO     Train Epoch: 48 [3584/8000 (45%)]\tTotal Loss: 0.229598\n",
      "Reconstruction: 0.227167, Regularization: 0.002431\n",
      "2019-04-10 01:02:04,393 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.230113\n",
      "Reconstruction: 0.227865, Regularization: 0.002248\n",
      "2019-04-10 01:02:04,455 root         INFO     Train Epoch: 48 [4608/8000 (58%)]\tTotal Loss: 0.233300\n",
      "Reconstruction: 0.231169, Regularization: 0.002131\n",
      "2019-04-10 01:02:04,518 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.237208\n",
      "Reconstruction: 0.234285, Regularization: 0.002924\n",
      "2019-04-10 01:02:04,580 root         INFO     Train Epoch: 48 [5632/8000 (70%)]\tTotal Loss: 0.233455\n",
      "Reconstruction: 0.231296, Regularization: 0.002159\n",
      "2019-04-10 01:02:04,643 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.251628\n",
      "Reconstruction: 0.248556, Regularization: 0.003072\n",
      "2019-04-10 01:02:04,706 root         INFO     Train Epoch: 48 [6656/8000 (83%)]\tTotal Loss: 0.231230\n",
      "Reconstruction: 0.229068, Regularization: 0.002161\n",
      "2019-04-10 01:02:04,769 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.231602\n",
      "Reconstruction: 0.229336, Regularization: 0.002266\n",
      "2019-04-10 01:02:04,831 root         INFO     Train Epoch: 48 [7680/8000 (96%)]\tTotal Loss: 0.228330\n",
      "Reconstruction: 0.226239, Regularization: 0.002091\n",
      "2019-04-10 01:02:04,885 root         INFO     ====> Epoch: 48 Average loss: 0.2337\n",
      "2019-04-10 01:02:04,909 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.228270\n",
      "Reconstruction: 0.225908, Regularization: 0.002362\n",
      "2019-04-10 01:02:04,973 root         INFO     Train Epoch: 49 [512/8000 (6%)]\tTotal Loss: 0.230940\n",
      "Reconstruction: 0.228856, Regularization: 0.002084\n",
      "2019-04-10 01:02:05,036 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.221634\n",
      "Reconstruction: 0.219359, Regularization: 0.002275\n",
      "2019-04-10 01:02:05,098 root         INFO     Train Epoch: 49 [1536/8000 (19%)]\tTotal Loss: 0.238614\n",
      "Reconstruction: 0.235894, Regularization: 0.002721\n",
      "2019-04-10 01:02:05,160 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.227733\n",
      "Reconstruction: 0.226108, Regularization: 0.001625\n",
      "2019-04-10 01:02:05,223 root         INFO     Train Epoch: 49 [2560/8000 (32%)]\tTotal Loss: 0.232567\n",
      "Reconstruction: 0.230534, Regularization: 0.002033\n",
      "2019-04-10 01:02:05,286 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.224947\n",
      "Reconstruction: 0.223019, Regularization: 0.001928\n",
      "2019-04-10 01:02:05,348 root         INFO     Train Epoch: 49 [3584/8000 (45%)]\tTotal Loss: 0.233994\n",
      "Reconstruction: 0.231550, Regularization: 0.002444\n",
      "2019-04-10 01:02:05,410 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.228335\n",
      "Reconstruction: 0.226451, Regularization: 0.001883\n",
      "2019-04-10 01:02:05,474 root         INFO     Train Epoch: 49 [4608/8000 (58%)]\tTotal Loss: 0.228076\n",
      "Reconstruction: 0.226034, Regularization: 0.002042\n",
      "2019-04-10 01:02:05,536 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.232050\n",
      "Reconstruction: 0.230280, Regularization: 0.001770\n",
      "2019-04-10 01:02:05,599 root         INFO     Train Epoch: 49 [5632/8000 (70%)]\tTotal Loss: 0.227261\n",
      "Reconstruction: 0.225534, Regularization: 0.001727\n",
      "2019-04-10 01:02:05,661 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.230615\n",
      "Reconstruction: 0.229064, Regularization: 0.001551\n",
      "2019-04-10 01:02:05,723 root         INFO     Train Epoch: 49 [6656/8000 (83%)]\tTotal Loss: 0.224387\n",
      "Reconstruction: 0.223113, Regularization: 0.001274\n",
      "2019-04-10 01:02:05,785 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.227675\n",
      "Reconstruction: 0.226047, Regularization: 0.001628\n",
      "2019-04-10 01:02:05,848 root         INFO     Train Epoch: 49 [7680/8000 (96%)]\tTotal Loss: 0.230587\n",
      "Reconstruction: 0.228752, Regularization: 0.001836\n",
      "2019-04-10 01:02:05,901 root         INFO     ====> Epoch: 49 Average loss: 0.2314\n",
      "2019-04-10 01:02:05,925 root         INFO     Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 0.227442\n",
      "Reconstruction: 0.225472, Regularization: 0.001970\n",
      "2019-04-10 01:02:05,989 root         INFO     Train Epoch: 50 [512/8000 (6%)]\tTotal Loss: 0.233031\n",
      "Reconstruction: 0.231239, Regularization: 0.001791\n",
      "2019-04-10 01:02:06,051 root         INFO     Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 0.227964\n",
      "Reconstruction: 0.226207, Regularization: 0.001757\n",
      "2019-04-10 01:02:06,115 root         INFO     Train Epoch: 50 [1536/8000 (19%)]\tTotal Loss: 0.231692\n",
      "Reconstruction: 0.230026, Regularization: 0.001665\n",
      "2019-04-10 01:02:06,177 root         INFO     Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 0.232760\n",
      "Reconstruction: 0.231201, Regularization: 0.001559\n",
      "2019-04-10 01:02:06,239 root         INFO     Train Epoch: 50 [2560/8000 (32%)]\tTotal Loss: 0.227578\n",
      "Reconstruction: 0.226060, Regularization: 0.001518\n",
      "2019-04-10 01:02:06,300 root         INFO     Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 0.227769\n",
      "Reconstruction: 0.226267, Regularization: 0.001502\n",
      "2019-04-10 01:02:06,361 root         INFO     Train Epoch: 50 [3584/8000 (45%)]\tTotal Loss: 0.223627\n",
      "Reconstruction: 0.222178, Regularization: 0.001448\n",
      "2019-04-10 01:02:06,423 root         INFO     Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 0.233839\n",
      "Reconstruction: 0.232464, Regularization: 0.001375\n",
      "2019-04-10 01:02:06,484 root         INFO     Train Epoch: 50 [4608/8000 (58%)]\tTotal Loss: 0.229700\n",
      "Reconstruction: 0.228052, Regularization: 0.001648\n",
      "2019-04-10 01:02:06,546 root         INFO     Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 0.227945\n",
      "Reconstruction: 0.226328, Regularization: 0.001617\n",
      "2019-04-10 01:02:06,608 root         INFO     Train Epoch: 50 [5632/8000 (70%)]\tTotal Loss: 0.228728\n",
      "Reconstruction: 0.227088, Regularization: 0.001640\n",
      "2019-04-10 01:02:06,669 root         INFO     Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 0.239318\n",
      "Reconstruction: 0.237619, Regularization: 0.001698\n",
      "2019-04-10 01:02:06,730 root         INFO     Train Epoch: 50 [6656/8000 (83%)]\tTotal Loss: 0.227753\n",
      "Reconstruction: 0.226164, Regularization: 0.001589\n",
      "2019-04-10 01:02:06,792 root         INFO     Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 0.234567\n",
      "Reconstruction: 0.232959, Regularization: 0.001608\n",
      "2019-04-10 01:02:06,853 root         INFO     Train Epoch: 50 [7680/8000 (96%)]\tTotal Loss: 0.226963\n",
      "Reconstruction: 0.225592, Regularization: 0.001371\n",
      "2019-04-10 01:02:06,905 root         INFO     ====> Epoch: 50 Average loss: 0.2293\n",
      "2019-04-10 01:02:06,929 root         INFO     Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 0.226892\n",
      "Reconstruction: 0.225652, Regularization: 0.001240\n",
      "2019-04-10 01:02:06,992 root         INFO     Train Epoch: 51 [512/8000 (6%)]\tTotal Loss: 0.220669\n",
      "Reconstruction: 0.219641, Regularization: 0.001028\n",
      "2019-04-10 01:02:07,054 root         INFO     Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 0.230581\n",
      "Reconstruction: 0.228924, Regularization: 0.001656\n",
      "2019-04-10 01:02:07,117 root         INFO     Train Epoch: 51 [1536/8000 (19%)]\tTotal Loss: 0.229381\n",
      "Reconstruction: 0.227839, Regularization: 0.001542\n",
      "2019-04-10 01:02:07,180 root         INFO     Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 0.229707\n",
      "Reconstruction: 0.228506, Regularization: 0.001202\n",
      "2019-04-10 01:02:07,242 root         INFO     Train Epoch: 51 [2560/8000 (32%)]\tTotal Loss: 0.222334\n",
      "Reconstruction: 0.221316, Regularization: 0.001019\n",
      "2019-04-10 01:02:07,305 root         INFO     Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 0.231977\n",
      "Reconstruction: 0.230408, Regularization: 0.001570\n",
      "2019-04-10 01:02:07,368 root         INFO     Train Epoch: 51 [3584/8000 (45%)]\tTotal Loss: 0.225058\n",
      "Reconstruction: 0.223640, Regularization: 0.001418\n",
      "2019-04-10 01:02:07,430 root         INFO     Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 0.224355\n",
      "Reconstruction: 0.223323, Regularization: 0.001032\n",
      "2019-04-10 01:02:07,493 root         INFO     Train Epoch: 51 [4608/8000 (58%)]\tTotal Loss: 0.221928\n",
      "Reconstruction: 0.220690, Regularization: 0.001238\n",
      "2019-04-10 01:02:07,556 root         INFO     Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 0.233214\n",
      "Reconstruction: 0.231622, Regularization: 0.001592\n",
      "2019-04-10 01:02:07,620 root         INFO     Train Epoch: 51 [5632/8000 (70%)]\tTotal Loss: 0.231163\n",
      "Reconstruction: 0.230159, Regularization: 0.001004\n",
      "2019-04-10 01:02:07,684 root         INFO     Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 0.224180\n",
      "Reconstruction: 0.222997, Regularization: 0.001183\n",
      "2019-04-10 01:02:07,748 root         INFO     Train Epoch: 51 [6656/8000 (83%)]\tTotal Loss: 0.231770\n",
      "Reconstruction: 0.230683, Regularization: 0.001086\n",
      "2019-04-10 01:02:07,812 root         INFO     Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 0.226325\n",
      "Reconstruction: 0.225206, Regularization: 0.001120\n",
      "2019-04-10 01:02:07,876 root         INFO     Train Epoch: 51 [7680/8000 (96%)]\tTotal Loss: 0.219959\n",
      "Reconstruction: 0.219104, Regularization: 0.000855\n",
      "2019-04-10 01:02:07,930 root         INFO     ====> Epoch: 51 Average loss: 0.2273\n",
      "2019-04-10 01:02:07,954 root         INFO     Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 0.221730\n",
      "Reconstruction: 0.220527, Regularization: 0.001203\n",
      "2019-04-10 01:02:08,019 root         INFO     Train Epoch: 52 [512/8000 (6%)]\tTotal Loss: 0.220573\n",
      "Reconstruction: 0.219372, Regularization: 0.001201\n",
      "2019-04-10 01:02:08,082 root         INFO     Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 0.231944\n",
      "Reconstruction: 0.230821, Regularization: 0.001123\n",
      "2019-04-10 01:02:08,145 root         INFO     Train Epoch: 52 [1536/8000 (19%)]\tTotal Loss: 0.225398\n",
      "Reconstruction: 0.224005, Regularization: 0.001393\n",
      "2019-04-10 01:02:08,208 root         INFO     Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 0.223354\n",
      "Reconstruction: 0.222508, Regularization: 0.000845\n",
      "2019-04-10 01:02:08,272 root         INFO     Train Epoch: 52 [2560/8000 (32%)]\tTotal Loss: 0.230270\n",
      "Reconstruction: 0.229192, Regularization: 0.001078\n",
      "2019-04-10 01:02:08,336 root         INFO     Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 0.226825\n",
      "Reconstruction: 0.225992, Regularization: 0.000832\n",
      "2019-04-10 01:02:08,399 root         INFO     Train Epoch: 52 [3584/8000 (45%)]\tTotal Loss: 0.228932\n",
      "Reconstruction: 0.227850, Regularization: 0.001082\n",
      "2019-04-10 01:02:08,461 root         INFO     Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 0.229310\n",
      "Reconstruction: 0.228324, Regularization: 0.000986\n",
      "2019-04-10 01:02:08,524 root         INFO     Train Epoch: 52 [4608/8000 (58%)]\tTotal Loss: 0.218736\n",
      "Reconstruction: 0.217754, Regularization: 0.000982\n",
      "2019-04-10 01:02:08,586 root         INFO     Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 0.230488\n",
      "Reconstruction: 0.229133, Regularization: 0.001355\n",
      "2019-04-10 01:02:08,649 root         INFO     Train Epoch: 52 [5632/8000 (70%)]\tTotal Loss: 0.225749\n",
      "Reconstruction: 0.224657, Regularization: 0.001092\n",
      "2019-04-10 01:02:08,712 root         INFO     Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 0.220883\n",
      "Reconstruction: 0.219693, Regularization: 0.001190\n",
      "2019-04-10 01:02:08,774 root         INFO     Train Epoch: 52 [6656/8000 (83%)]\tTotal Loss: 0.223527\n",
      "Reconstruction: 0.222553, Regularization: 0.000974\n",
      "2019-04-10 01:02:08,836 root         INFO     Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 0.222509\n",
      "Reconstruction: 0.221708, Regularization: 0.000801\n",
      "2019-04-10 01:02:08,899 root         INFO     Train Epoch: 52 [7680/8000 (96%)]\tTotal Loss: 0.224171\n",
      "Reconstruction: 0.223168, Regularization: 0.001003\n",
      "2019-04-10 01:02:08,952 root         INFO     ====> Epoch: 52 Average loss: 0.2254\n",
      "2019-04-10 01:02:08,977 root         INFO     Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 0.227468\n",
      "Reconstruction: 0.226350, Regularization: 0.001118\n",
      "2019-04-10 01:02:09,041 root         INFO     Train Epoch: 53 [512/8000 (6%)]\tTotal Loss: 0.228224\n",
      "Reconstruction: 0.227347, Regularization: 0.000877\n",
      "2019-04-10 01:02:09,104 root         INFO     Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 0.225148\n",
      "Reconstruction: 0.224461, Regularization: 0.000688\n",
      "2019-04-10 01:02:09,167 root         INFO     Train Epoch: 53 [1536/8000 (19%)]\tTotal Loss: 0.222490\n",
      "Reconstruction: 0.221377, Regularization: 0.001113\n",
      "2019-04-10 01:02:09,229 root         INFO     Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 0.231207\n",
      "Reconstruction: 0.230495, Regularization: 0.000713\n",
      "2019-04-10 01:02:09,291 root         INFO     Train Epoch: 53 [2560/8000 (32%)]\tTotal Loss: 0.216469\n",
      "Reconstruction: 0.215503, Regularization: 0.000967\n",
      "2019-04-10 01:02:09,353 root         INFO     Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 0.221155\n",
      "Reconstruction: 0.220551, Regularization: 0.000604\n",
      "2019-04-10 01:02:09,415 root         INFO     Train Epoch: 53 [3584/8000 (45%)]\tTotal Loss: 0.222659\n",
      "Reconstruction: 0.221549, Regularization: 0.001110\n",
      "2019-04-10 01:02:09,477 root         INFO     Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 0.222733\n",
      "Reconstruction: 0.222050, Regularization: 0.000683\n",
      "2019-04-10 01:02:09,539 root         INFO     Train Epoch: 53 [4608/8000 (58%)]\tTotal Loss: 0.227575\n",
      "Reconstruction: 0.226786, Regularization: 0.000789\n",
      "2019-04-10 01:02:09,601 root         INFO     Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 0.221137\n",
      "Reconstruction: 0.220283, Regularization: 0.000854\n",
      "2019-04-10 01:02:09,663 root         INFO     Train Epoch: 53 [5632/8000 (70%)]\tTotal Loss: 0.216508\n",
      "Reconstruction: 0.215865, Regularization: 0.000643\n",
      "2019-04-10 01:02:09,725 root         INFO     Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 0.218249\n",
      "Reconstruction: 0.217558, Regularization: 0.000691\n",
      "2019-04-10 01:02:09,787 root         INFO     Train Epoch: 53 [6656/8000 (83%)]\tTotal Loss: 0.225390\n",
      "Reconstruction: 0.224555, Regularization: 0.000835\n",
      "2019-04-10 01:02:09,849 root         INFO     Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 0.220221\n",
      "Reconstruction: 0.219367, Regularization: 0.000855\n",
      "2019-04-10 01:02:09,911 root         INFO     Train Epoch: 53 [7680/8000 (96%)]\tTotal Loss: 0.224668\n",
      "Reconstruction: 0.223810, Regularization: 0.000858\n",
      "2019-04-10 01:02:09,964 root         INFO     ====> Epoch: 53 Average loss: 0.2237\n",
      "2019-04-10 01:02:09,988 root         INFO     Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 0.220988\n",
      "Reconstruction: 0.220038, Regularization: 0.000950\n",
      "2019-04-10 01:02:10,052 root         INFO     Train Epoch: 54 [512/8000 (6%)]\tTotal Loss: 0.224918\n",
      "Reconstruction: 0.223856, Regularization: 0.001062\n",
      "2019-04-10 01:02:10,115 root         INFO     Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 0.224491\n",
      "Reconstruction: 0.223648, Regularization: 0.000843\n",
      "2019-04-10 01:02:10,178 root         INFO     Train Epoch: 54 [1536/8000 (19%)]\tTotal Loss: 0.223177\n",
      "Reconstruction: 0.222569, Regularization: 0.000608\n",
      "2019-04-10 01:02:10,241 root         INFO     Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 0.225555\n",
      "Reconstruction: 0.224453, Regularization: 0.001103\n",
      "2019-04-10 01:02:10,304 root         INFO     Train Epoch: 54 [2560/8000 (32%)]\tTotal Loss: 0.225176\n",
      "Reconstruction: 0.224511, Regularization: 0.000665\n",
      "2019-04-10 01:02:10,366 root         INFO     Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 0.223712\n",
      "Reconstruction: 0.222718, Regularization: 0.000994\n",
      "2019-04-10 01:02:10,428 root         INFO     Train Epoch: 54 [3584/8000 (45%)]\tTotal Loss: 0.221855\n",
      "Reconstruction: 0.221304, Regularization: 0.000551\n",
      "2019-04-10 01:02:10,489 root         INFO     Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 0.219314\n",
      "Reconstruction: 0.218580, Regularization: 0.000733\n",
      "2019-04-10 01:02:10,551 root         INFO     Train Epoch: 54 [4608/8000 (58%)]\tTotal Loss: 0.220758\n",
      "Reconstruction: 0.219822, Regularization: 0.000936\n",
      "2019-04-10 01:02:10,613 root         INFO     Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 0.217077\n",
      "Reconstruction: 0.216671, Regularization: 0.000406\n",
      "2019-04-10 01:02:10,674 root         INFO     Train Epoch: 54 [5632/8000 (70%)]\tTotal Loss: 0.220455\n",
      "Reconstruction: 0.219972, Regularization: 0.000483\n",
      "2019-04-10 01:02:10,736 root         INFO     Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 0.227085\n",
      "Reconstruction: 0.226465, Regularization: 0.000620\n",
      "2019-04-10 01:02:10,798 root         INFO     Train Epoch: 54 [6656/8000 (83%)]\tTotal Loss: 0.224308\n",
      "Reconstruction: 0.223398, Regularization: 0.000910\n",
      "2019-04-10 01:02:10,860 root         INFO     Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 0.222586\n",
      "Reconstruction: 0.221925, Regularization: 0.000660\n",
      "2019-04-10 01:02:10,922 root         INFO     Train Epoch: 54 [7680/8000 (96%)]\tTotal Loss: 0.224074\n",
      "Reconstruction: 0.223601, Regularization: 0.000473\n",
      "2019-04-10 01:02:10,975 root         INFO     ====> Epoch: 54 Average loss: 0.2221\n",
      "2019-04-10 01:02:10,999 root         INFO     Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 0.220195\n",
      "Reconstruction: 0.219355, Regularization: 0.000840\n",
      "2019-04-10 01:02:11,063 root         INFO     Train Epoch: 55 [512/8000 (6%)]\tTotal Loss: 0.225987\n",
      "Reconstruction: 0.225279, Regularization: 0.000707\n",
      "2019-04-10 01:02:11,126 root         INFO     Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 0.216690\n",
      "Reconstruction: 0.216059, Regularization: 0.000631\n",
      "2019-04-10 01:02:11,190 root         INFO     Train Epoch: 55 [1536/8000 (19%)]\tTotal Loss: 0.217851\n",
      "Reconstruction: 0.217194, Regularization: 0.000656\n",
      "2019-04-10 01:02:11,253 root         INFO     Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 0.221629\n",
      "Reconstruction: 0.221060, Regularization: 0.000569\n",
      "2019-04-10 01:02:11,317 root         INFO     Train Epoch: 55 [2560/8000 (32%)]\tTotal Loss: 0.223953\n",
      "Reconstruction: 0.223293, Regularization: 0.000660\n",
      "2019-04-10 01:02:11,381 root         INFO     Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 0.218233\n",
      "Reconstruction: 0.217515, Regularization: 0.000718\n",
      "2019-04-10 01:02:11,445 root         INFO     Train Epoch: 55 [3584/8000 (45%)]\tTotal Loss: 0.219111\n",
      "Reconstruction: 0.218466, Regularization: 0.000645\n",
      "2019-04-10 01:02:11,509 root         INFO     Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 0.224211\n",
      "Reconstruction: 0.223630, Regularization: 0.000580\n",
      "2019-04-10 01:02:11,573 root         INFO     Train Epoch: 55 [4608/8000 (58%)]\tTotal Loss: 0.225356\n",
      "Reconstruction: 0.224683, Regularization: 0.000673\n",
      "2019-04-10 01:02:11,637 root         INFO     Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 0.219181\n",
      "Reconstruction: 0.218737, Regularization: 0.000444\n",
      "2019-04-10 01:02:11,702 root         INFO     Train Epoch: 55 [5632/8000 (70%)]\tTotal Loss: 0.225413\n",
      "Reconstruction: 0.224735, Regularization: 0.000677\n",
      "2019-04-10 01:02:11,765 root         INFO     Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 0.218784\n",
      "Reconstruction: 0.218341, Regularization: 0.000443\n",
      "2019-04-10 01:02:11,829 root         INFO     Train Epoch: 55 [6656/8000 (83%)]\tTotal Loss: 0.216162\n",
      "Reconstruction: 0.215649, Regularization: 0.000513\n",
      "2019-04-10 01:02:11,893 root         INFO     Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 0.227506\n",
      "Reconstruction: 0.226720, Regularization: 0.000786\n",
      "2019-04-10 01:02:11,956 root         INFO     Train Epoch: 55 [7680/8000 (96%)]\tTotal Loss: 0.226073\n",
      "Reconstruction: 0.225317, Regularization: 0.000755\n",
      "2019-04-10 01:02:12,011 root         INFO     ====> Epoch: 55 Average loss: 0.2207\n",
      "2019-04-10 01:02:12,035 root         INFO     Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 0.219442\n",
      "Reconstruction: 0.218755, Regularization: 0.000687\n",
      "2019-04-10 01:02:12,099 root         INFO     Train Epoch: 56 [512/8000 (6%)]\tTotal Loss: 0.219503\n",
      "Reconstruction: 0.218761, Regularization: 0.000742\n",
      "2019-04-10 01:02:12,162 root         INFO     Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 0.217766\n",
      "Reconstruction: 0.217066, Regularization: 0.000700\n",
      "2019-04-10 01:02:12,226 root         INFO     Train Epoch: 56 [1536/8000 (19%)]\tTotal Loss: 0.217969\n",
      "Reconstruction: 0.217477, Regularization: 0.000492\n",
      "2019-04-10 01:02:12,289 root         INFO     Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 0.222196\n",
      "Reconstruction: 0.221672, Regularization: 0.000524\n",
      "2019-04-10 01:02:12,353 root         INFO     Train Epoch: 56 [2560/8000 (32%)]\tTotal Loss: 0.216181\n",
      "Reconstruction: 0.215659, Regularization: 0.000522\n",
      "2019-04-10 01:02:12,417 root         INFO     Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 0.221114\n",
      "Reconstruction: 0.220494, Regularization: 0.000620\n",
      "2019-04-10 01:02:12,479 root         INFO     Train Epoch: 56 [3584/8000 (45%)]\tTotal Loss: 0.215921\n",
      "Reconstruction: 0.215382, Regularization: 0.000539\n",
      "2019-04-10 01:02:12,542 root         INFO     Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 0.219594\n",
      "Reconstruction: 0.218929, Regularization: 0.000665\n",
      "2019-04-10 01:02:12,605 root         INFO     Train Epoch: 56 [4608/8000 (58%)]\tTotal Loss: 0.218364\n",
      "Reconstruction: 0.217871, Regularization: 0.000493\n",
      "2019-04-10 01:02:12,668 root         INFO     Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 0.225994\n",
      "Reconstruction: 0.225303, Regularization: 0.000690\n",
      "2019-04-10 01:02:12,731 root         INFO     Train Epoch: 56 [5632/8000 (70%)]\tTotal Loss: 0.213754\n",
      "Reconstruction: 0.213156, Regularization: 0.000598\n",
      "2019-04-10 01:02:12,794 root         INFO     Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 0.212996\n",
      "Reconstruction: 0.212484, Regularization: 0.000512\n",
      "2019-04-10 01:02:12,857 root         INFO     Train Epoch: 56 [6656/8000 (83%)]\tTotal Loss: 0.220257\n",
      "Reconstruction: 0.219688, Regularization: 0.000569\n",
      "2019-04-10 01:02:12,920 root         INFO     Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 0.218062\n",
      "Reconstruction: 0.217557, Regularization: 0.000505\n",
      "2019-04-10 01:02:12,982 root         INFO     Train Epoch: 56 [7680/8000 (96%)]\tTotal Loss: 0.213644\n",
      "Reconstruction: 0.213167, Regularization: 0.000477\n",
      "2019-04-10 01:02:13,037 root         INFO     ====> Epoch: 56 Average loss: 0.2193\n",
      "2019-04-10 01:02:13,061 root         INFO     Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 0.219470\n",
      "Reconstruction: 0.218874, Regularization: 0.000596\n",
      "2019-04-10 01:02:13,125 root         INFO     Train Epoch: 57 [512/8000 (6%)]\tTotal Loss: 0.216137\n",
      "Reconstruction: 0.215543, Regularization: 0.000594\n",
      "2019-04-10 01:02:13,188 root         INFO     Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 0.221107\n",
      "Reconstruction: 0.220378, Regularization: 0.000729\n",
      "2019-04-10 01:02:13,251 root         INFO     Train Epoch: 57 [1536/8000 (19%)]\tTotal Loss: 0.216571\n",
      "Reconstruction: 0.215819, Regularization: 0.000751\n",
      "2019-04-10 01:02:13,314 root         INFO     Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 0.223492\n",
      "Reconstruction: 0.222999, Regularization: 0.000493\n",
      "2019-04-10 01:02:13,377 root         INFO     Train Epoch: 57 [2560/8000 (32%)]\tTotal Loss: 0.216211\n",
      "Reconstruction: 0.215772, Regularization: 0.000439\n",
      "2019-04-10 01:02:13,440 root         INFO     Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 0.216535\n",
      "Reconstruction: 0.215866, Regularization: 0.000669\n",
      "2019-04-10 01:02:13,503 root         INFO     Train Epoch: 57 [3584/8000 (45%)]\tTotal Loss: 0.219824\n",
      "Reconstruction: 0.219180, Regularization: 0.000643\n",
      "2019-04-10 01:02:13,567 root         INFO     Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 0.220006\n",
      "Reconstruction: 0.219392, Regularization: 0.000614\n",
      "2019-04-10 01:02:13,631 root         INFO     Train Epoch: 57 [4608/8000 (58%)]\tTotal Loss: 0.218521\n",
      "Reconstruction: 0.218050, Regularization: 0.000471\n",
      "2019-04-10 01:02:13,693 root         INFO     Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 0.211444\n",
      "Reconstruction: 0.210898, Regularization: 0.000546\n",
      "2019-04-10 01:02:13,756 root         INFO     Train Epoch: 57 [5632/8000 (70%)]\tTotal Loss: 0.213279\n",
      "Reconstruction: 0.212765, Regularization: 0.000514\n",
      "2019-04-10 01:02:13,819 root         INFO     Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 0.212373\n",
      "Reconstruction: 0.211683, Regularization: 0.000690\n",
      "2019-04-10 01:02:13,882 root         INFO     Train Epoch: 57 [6656/8000 (83%)]\tTotal Loss: 0.214993\n",
      "Reconstruction: 0.214442, Regularization: 0.000550\n",
      "2019-04-10 01:02:13,945 root         INFO     Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 0.218689\n",
      "Reconstruction: 0.218318, Regularization: 0.000371\n",
      "2019-04-10 01:02:14,007 root         INFO     Train Epoch: 57 [7680/8000 (96%)]\tTotal Loss: 0.218989\n",
      "Reconstruction: 0.218252, Regularization: 0.000737\n",
      "2019-04-10 01:02:14,063 root         INFO     ====> Epoch: 57 Average loss: 0.2181\n",
      "2019-04-10 01:02:14,087 root         INFO     Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 0.217424\n",
      "Reconstruction: 0.216847, Regularization: 0.000576\n",
      "2019-04-10 01:02:14,151 root         INFO     Train Epoch: 58 [512/8000 (6%)]\tTotal Loss: 0.215764\n",
      "Reconstruction: 0.215280, Regularization: 0.000484\n",
      "2019-04-10 01:02:14,214 root         INFO     Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 0.221073\n",
      "Reconstruction: 0.220444, Regularization: 0.000629\n",
      "2019-04-10 01:02:14,277 root         INFO     Train Epoch: 58 [1536/8000 (19%)]\tTotal Loss: 0.208546\n",
      "Reconstruction: 0.207989, Regularization: 0.000557\n",
      "2019-04-10 01:02:14,340 root         INFO     Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 0.210741\n",
      "Reconstruction: 0.210172, Regularization: 0.000569\n",
      "2019-04-10 01:02:14,404 root         INFO     Train Epoch: 58 [2560/8000 (32%)]\tTotal Loss: 0.216195\n",
      "Reconstruction: 0.215787, Regularization: 0.000408\n",
      "2019-04-10 01:02:14,467 root         INFO     Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 0.217249\n",
      "Reconstruction: 0.216705, Regularization: 0.000544\n",
      "2019-04-10 01:02:14,531 root         INFO     Train Epoch: 58 [3584/8000 (45%)]\tTotal Loss: 0.216629\n",
      "Reconstruction: 0.216060, Regularization: 0.000570\n",
      "2019-04-10 01:02:14,594 root         INFO     Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 0.218005\n",
      "Reconstruction: 0.217289, Regularization: 0.000716\n",
      "2019-04-10 01:02:14,657 root         INFO     Train Epoch: 58 [4608/8000 (58%)]\tTotal Loss: 0.219827\n",
      "Reconstruction: 0.219201, Regularization: 0.000626\n",
      "2019-04-10 01:02:14,720 root         INFO     Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 0.215987\n",
      "Reconstruction: 0.215599, Regularization: 0.000389\n",
      "2019-04-10 01:02:14,781 root         INFO     Train Epoch: 58 [5632/8000 (70%)]\tTotal Loss: 0.214537\n",
      "Reconstruction: 0.214068, Regularization: 0.000468\n",
      "2019-04-10 01:02:14,843 root         INFO     Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 0.222399\n",
      "Reconstruction: 0.221841, Regularization: 0.000559\n",
      "2019-04-10 01:02:14,905 root         INFO     Train Epoch: 58 [6656/8000 (83%)]\tTotal Loss: 0.211410\n",
      "Reconstruction: 0.211150, Regularization: 0.000260\n",
      "2019-04-10 01:02:14,966 root         INFO     Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 0.217979\n",
      "Reconstruction: 0.217498, Regularization: 0.000481\n",
      "2019-04-10 01:02:15,027 root         INFO     Train Epoch: 58 [7680/8000 (96%)]\tTotal Loss: 0.209679\n",
      "Reconstruction: 0.209407, Regularization: 0.000272\n",
      "2019-04-10 01:02:15,080 root         INFO     ====> Epoch: 58 Average loss: 0.2169\n",
      "2019-04-10 01:02:15,104 root         INFO     Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 0.218669\n",
      "Reconstruction: 0.218006, Regularization: 0.000663\n",
      "2019-04-10 01:02:15,168 root         INFO     Train Epoch: 59 [512/8000 (6%)]\tTotal Loss: 0.220617\n",
      "Reconstruction: 0.220057, Regularization: 0.000560\n",
      "2019-04-10 01:02:15,231 root         INFO     Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 0.210129\n",
      "Reconstruction: 0.209816, Regularization: 0.000314\n",
      "2019-04-10 01:02:15,294 root         INFO     Train Epoch: 59 [1536/8000 (19%)]\tTotal Loss: 0.217216\n",
      "Reconstruction: 0.216740, Regularization: 0.000476\n",
      "2019-04-10 01:02:15,358 root         INFO     Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 0.213737\n",
      "Reconstruction: 0.213115, Regularization: 0.000623\n",
      "2019-04-10 01:02:15,421 root         INFO     Train Epoch: 59 [2560/8000 (32%)]\tTotal Loss: 0.214725\n",
      "Reconstruction: 0.214310, Regularization: 0.000415\n",
      "2019-04-10 01:02:15,484 root         INFO     Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 0.214624\n",
      "Reconstruction: 0.214185, Regularization: 0.000439\n",
      "2019-04-10 01:02:15,548 root         INFO     Train Epoch: 59 [3584/8000 (45%)]\tTotal Loss: 0.215477\n",
      "Reconstruction: 0.214908, Regularization: 0.000568\n",
      "2019-04-10 01:02:15,611 root         INFO     Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 0.212265\n",
      "Reconstruction: 0.211833, Regularization: 0.000432\n",
      "2019-04-10 01:02:15,675 root         INFO     Train Epoch: 59 [4608/8000 (58%)]\tTotal Loss: 0.210843\n",
      "Reconstruction: 0.210301, Regularization: 0.000542\n",
      "2019-04-10 01:02:15,738 root         INFO     Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 0.217098\n",
      "Reconstruction: 0.216738, Regularization: 0.000361\n",
      "2019-04-10 01:02:15,801 root         INFO     Train Epoch: 59 [5632/8000 (70%)]\tTotal Loss: 0.216398\n",
      "Reconstruction: 0.215978, Regularization: 0.000420\n",
      "2019-04-10 01:02:15,865 root         INFO     Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 0.215265\n",
      "Reconstruction: 0.214878, Regularization: 0.000387\n",
      "2019-04-10 01:02:15,928 root         INFO     Train Epoch: 59 [6656/8000 (83%)]\tTotal Loss: 0.211715\n",
      "Reconstruction: 0.210862, Regularization: 0.000853\n",
      "2019-04-10 01:02:15,991 root         INFO     Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 0.216260\n",
      "Reconstruction: 0.215887, Regularization: 0.000373\n",
      "2019-04-10 01:02:16,055 root         INFO     Train Epoch: 59 [7680/8000 (96%)]\tTotal Loss: 0.209742\n",
      "Reconstruction: 0.209099, Regularization: 0.000643\n",
      "2019-04-10 01:02:16,109 root         INFO     ====> Epoch: 59 Average loss: 0.2158\n",
      "2019-04-10 01:02:16,133 root         INFO     Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 0.223350\n",
      "Reconstruction: 0.222806, Regularization: 0.000544\n",
      "2019-04-10 01:02:16,197 root         INFO     Train Epoch: 60 [512/8000 (6%)]\tTotal Loss: 0.215704\n",
      "Reconstruction: 0.215269, Regularization: 0.000435\n",
      "2019-04-10 01:02:16,262 root         INFO     Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 0.224595\n",
      "Reconstruction: 0.224232, Regularization: 0.000363\n",
      "2019-04-10 01:02:16,327 root         INFO     Train Epoch: 60 [1536/8000 (19%)]\tTotal Loss: 0.214169\n",
      "Reconstruction: 0.213707, Regularization: 0.000462\n",
      "2019-04-10 01:02:16,392 root         INFO     Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 0.212637\n",
      "Reconstruction: 0.212230, Regularization: 0.000407\n",
      "2019-04-10 01:02:16,456 root         INFO     Train Epoch: 60 [2560/8000 (32%)]\tTotal Loss: 0.216007\n",
      "Reconstruction: 0.215462, Regularization: 0.000545\n",
      "2019-04-10 01:02:16,519 root         INFO     Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 0.213529\n",
      "Reconstruction: 0.213163, Regularization: 0.000367\n",
      "2019-04-10 01:02:16,583 root         INFO     Train Epoch: 60 [3584/8000 (45%)]\tTotal Loss: 0.209741\n",
      "Reconstruction: 0.208872, Regularization: 0.000869\n",
      "2019-04-10 01:02:16,646 root         INFO     Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 0.211366\n",
      "Reconstruction: 0.210920, Regularization: 0.000446\n",
      "2019-04-10 01:02:16,709 root         INFO     Train Epoch: 60 [4608/8000 (58%)]\tTotal Loss: 0.212900\n",
      "Reconstruction: 0.212534, Regularization: 0.000366\n",
      "2019-04-10 01:02:16,772 root         INFO     Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 0.213479\n",
      "Reconstruction: 0.212952, Regularization: 0.000528\n",
      "2019-04-10 01:02:16,835 root         INFO     Train Epoch: 60 [5632/8000 (70%)]\tTotal Loss: 0.215908\n",
      "Reconstruction: 0.215334, Regularization: 0.000574\n",
      "2019-04-10 01:02:16,898 root         INFO     Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 0.210236\n",
      "Reconstruction: 0.209765, Regularization: 0.000471\n",
      "2019-04-10 01:02:16,962 root         INFO     Train Epoch: 60 [6656/8000 (83%)]\tTotal Loss: 0.212502\n",
      "Reconstruction: 0.212111, Regularization: 0.000391\n",
      "2019-04-10 01:02:17,026 root         INFO     Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 0.212399\n",
      "Reconstruction: 0.212068, Regularization: 0.000331\n",
      "2019-04-10 01:02:17,090 root         INFO     Train Epoch: 60 [7680/8000 (96%)]\tTotal Loss: 0.211972\n",
      "Reconstruction: 0.211446, Regularization: 0.000526\n",
      "2019-04-10 01:02:17,145 root         INFO     ====> Epoch: 60 Average loss: 0.2147\n",
      "2019-04-10 01:02:17,169 root         INFO     Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 0.221882\n",
      "Reconstruction: 0.221305, Regularization: 0.000577\n",
      "2019-04-10 01:02:17,233 root         INFO     Train Epoch: 61 [512/8000 (6%)]\tTotal Loss: 0.213404\n",
      "Reconstruction: 0.212994, Regularization: 0.000411\n",
      "2019-04-10 01:02:17,297 root         INFO     Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 0.209963\n",
      "Reconstruction: 0.209589, Regularization: 0.000373\n",
      "2019-04-10 01:02:17,361 root         INFO     Train Epoch: 61 [1536/8000 (19%)]\tTotal Loss: 0.220844\n",
      "Reconstruction: 0.220217, Regularization: 0.000627\n",
      "2019-04-10 01:02:17,425 root         INFO     Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 0.206903\n",
      "Reconstruction: 0.206410, Regularization: 0.000493\n",
      "2019-04-10 01:02:17,488 root         INFO     Train Epoch: 61 [2560/8000 (32%)]\tTotal Loss: 0.216769\n",
      "Reconstruction: 0.216388, Regularization: 0.000381\n",
      "2019-04-10 01:02:17,552 root         INFO     Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 0.209973\n",
      "Reconstruction: 0.209491, Regularization: 0.000483\n",
      "2019-04-10 01:02:17,615 root         INFO     Train Epoch: 61 [3584/8000 (45%)]\tTotal Loss: 0.210185\n",
      "Reconstruction: 0.209694, Regularization: 0.000491\n",
      "2019-04-10 01:02:17,678 root         INFO     Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 0.211642\n",
      "Reconstruction: 0.211122, Regularization: 0.000520\n",
      "2019-04-10 01:02:17,741 root         INFO     Train Epoch: 61 [4608/8000 (58%)]\tTotal Loss: 0.213494\n",
      "Reconstruction: 0.212733, Regularization: 0.000760\n",
      "2019-04-10 01:02:17,805 root         INFO     Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 0.215214\n",
      "Reconstruction: 0.214906, Regularization: 0.000309\n",
      "2019-04-10 01:02:17,868 root         INFO     Train Epoch: 61 [5632/8000 (70%)]\tTotal Loss: 0.212332\n",
      "Reconstruction: 0.211826, Regularization: 0.000506\n",
      "2019-04-10 01:02:17,931 root         INFO     Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 0.210368\n",
      "Reconstruction: 0.209847, Regularization: 0.000520\n",
      "2019-04-10 01:02:17,995 root         INFO     Train Epoch: 61 [6656/8000 (83%)]\tTotal Loss: 0.208589\n",
      "Reconstruction: 0.208156, Regularization: 0.000434\n",
      "2019-04-10 01:02:18,057 root         INFO     Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 0.216275\n",
      "Reconstruction: 0.215972, Regularization: 0.000303\n",
      "2019-04-10 01:02:18,121 root         INFO     Train Epoch: 61 [7680/8000 (96%)]\tTotal Loss: 0.212755\n",
      "Reconstruction: 0.212396, Regularization: 0.000359\n",
      "2019-04-10 01:02:18,174 root         INFO     ====> Epoch: 61 Average loss: 0.2137\n",
      "2019-04-10 01:02:18,198 root         INFO     Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 0.208807\n",
      "Reconstruction: 0.208138, Regularization: 0.000669\n",
      "2019-04-10 01:02:18,263 root         INFO     Train Epoch: 62 [512/8000 (6%)]\tTotal Loss: 0.207246\n",
      "Reconstruction: 0.206658, Regularization: 0.000588\n",
      "2019-04-10 01:02:18,327 root         INFO     Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 0.218294\n",
      "Reconstruction: 0.217894, Regularization: 0.000399\n",
      "2019-04-10 01:02:18,390 root         INFO     Train Epoch: 62 [1536/8000 (19%)]\tTotal Loss: 0.212638\n",
      "Reconstruction: 0.212064, Regularization: 0.000574\n",
      "2019-04-10 01:02:18,454 root         INFO     Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 0.211302\n",
      "Reconstruction: 0.210797, Regularization: 0.000504\n",
      "2019-04-10 01:02:18,518 root         INFO     Train Epoch: 62 [2560/8000 (32%)]\tTotal Loss: 0.212764\n",
      "Reconstruction: 0.212390, Regularization: 0.000374\n",
      "2019-04-10 01:02:18,582 root         INFO     Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 0.213049\n",
      "Reconstruction: 0.212712, Regularization: 0.000337\n",
      "2019-04-10 01:02:18,645 root         INFO     Train Epoch: 62 [3584/8000 (45%)]\tTotal Loss: 0.205968\n",
      "Reconstruction: 0.205491, Regularization: 0.000477\n",
      "2019-04-10 01:02:18,708 root         INFO     Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 0.210914\n",
      "Reconstruction: 0.210478, Regularization: 0.000437\n",
      "2019-04-10 01:02:18,772 root         INFO     Train Epoch: 62 [4608/8000 (58%)]\tTotal Loss: 0.209987\n",
      "Reconstruction: 0.209455, Regularization: 0.000532\n",
      "2019-04-10 01:02:18,836 root         INFO     Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 0.215037\n",
      "Reconstruction: 0.214668, Regularization: 0.000368\n",
      "2019-04-10 01:02:18,899 root         INFO     Train Epoch: 62 [5632/8000 (70%)]\tTotal Loss: 0.210972\n",
      "Reconstruction: 0.210646, Regularization: 0.000326\n",
      "2019-04-10 01:02:18,962 root         INFO     Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 0.213351\n",
      "Reconstruction: 0.212771, Regularization: 0.000580\n",
      "2019-04-10 01:02:19,026 root         INFO     Train Epoch: 62 [6656/8000 (83%)]\tTotal Loss: 0.216865\n",
      "Reconstruction: 0.216285, Regularization: 0.000580\n",
      "2019-04-10 01:02:19,090 root         INFO     Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 0.214584\n",
      "Reconstruction: 0.214161, Regularization: 0.000423\n",
      "2019-04-10 01:02:19,153 root         INFO     Train Epoch: 62 [7680/8000 (96%)]\tTotal Loss: 0.219956\n",
      "Reconstruction: 0.219394, Regularization: 0.000562\n",
      "2019-04-10 01:02:19,207 root         INFO     ====> Epoch: 62 Average loss: 0.2127\n",
      "2019-04-10 01:02:19,231 root         INFO     Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 0.212625\n",
      "Reconstruction: 0.211976, Regularization: 0.000649\n",
      "2019-04-10 01:02:19,295 root         INFO     Train Epoch: 63 [512/8000 (6%)]\tTotal Loss: 0.220205\n",
      "Reconstruction: 0.219485, Regularization: 0.000720\n",
      "2019-04-10 01:02:19,359 root         INFO     Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 0.215156\n",
      "Reconstruction: 0.214827, Regularization: 0.000329\n",
      "2019-04-10 01:02:19,422 root         INFO     Train Epoch: 63 [1536/8000 (19%)]\tTotal Loss: 0.212736\n",
      "Reconstruction: 0.212007, Regularization: 0.000729\n",
      "2019-04-10 01:02:19,485 root         INFO     Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 0.211414\n",
      "Reconstruction: 0.211032, Regularization: 0.000382\n",
      "2019-04-10 01:02:19,548 root         INFO     Train Epoch: 63 [2560/8000 (32%)]\tTotal Loss: 0.214610\n",
      "Reconstruction: 0.214258, Regularization: 0.000352\n",
      "2019-04-10 01:02:19,610 root         INFO     Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 0.210798\n",
      "Reconstruction: 0.210290, Regularization: 0.000507\n",
      "2019-04-10 01:02:19,672 root         INFO     Train Epoch: 63 [3584/8000 (45%)]\tTotal Loss: 0.212497\n",
      "Reconstruction: 0.212062, Regularization: 0.000434\n",
      "2019-04-10 01:02:19,733 root         INFO     Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 0.218500\n",
      "Reconstruction: 0.218022, Regularization: 0.000478\n",
      "2019-04-10 01:02:19,797 root         INFO     Train Epoch: 63 [4608/8000 (58%)]\tTotal Loss: 0.211698\n",
      "Reconstruction: 0.211350, Regularization: 0.000349\n",
      "2019-04-10 01:02:19,860 root         INFO     Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 0.212726\n",
      "Reconstruction: 0.212321, Regularization: 0.000406\n",
      "2019-04-10 01:02:19,924 root         INFO     Train Epoch: 63 [5632/8000 (70%)]\tTotal Loss: 0.206487\n",
      "Reconstruction: 0.205997, Regularization: 0.000490\n",
      "2019-04-10 01:02:19,987 root         INFO     Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 0.210200\n",
      "Reconstruction: 0.209752, Regularization: 0.000448\n",
      "2019-04-10 01:02:20,050 root         INFO     Train Epoch: 63 [6656/8000 (83%)]\tTotal Loss: 0.213582\n",
      "Reconstruction: 0.213013, Regularization: 0.000569\n",
      "2019-04-10 01:02:20,113 root         INFO     Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 0.212397\n",
      "Reconstruction: 0.211957, Regularization: 0.000440\n",
      "2019-04-10 01:02:20,176 root         INFO     Train Epoch: 63 [7680/8000 (96%)]\tTotal Loss: 0.209845\n",
      "Reconstruction: 0.209525, Regularization: 0.000321\n",
      "2019-04-10 01:02:20,230 root         INFO     ====> Epoch: 63 Average loss: 0.2118\n",
      "2019-04-10 01:02:20,255 root         INFO     Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 0.219473\n",
      "Reconstruction: 0.219066, Regularization: 0.000407\n",
      "2019-04-10 01:02:20,319 root         INFO     Train Epoch: 64 [512/8000 (6%)]\tTotal Loss: 0.206762\n",
      "Reconstruction: 0.206388, Regularization: 0.000374\n",
      "2019-04-10 01:02:20,382 root         INFO     Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 0.225354\n",
      "Reconstruction: 0.224887, Regularization: 0.000467\n",
      "2019-04-10 01:02:20,445 root         INFO     Train Epoch: 64 [1536/8000 (19%)]\tTotal Loss: 0.208936\n",
      "Reconstruction: 0.208459, Regularization: 0.000477\n",
      "2019-04-10 01:02:20,508 root         INFO     Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 0.208041\n",
      "Reconstruction: 0.207550, Regularization: 0.000491\n",
      "2019-04-10 01:02:20,571 root         INFO     Train Epoch: 64 [2560/8000 (32%)]\tTotal Loss: 0.208088\n",
      "Reconstruction: 0.207373, Regularization: 0.000716\n",
      "2019-04-10 01:02:20,634 root         INFO     Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 0.213416\n",
      "Reconstruction: 0.212878, Regularization: 0.000538\n",
      "2019-04-10 01:02:20,698 root         INFO     Train Epoch: 64 [3584/8000 (45%)]\tTotal Loss: 0.211207\n",
      "Reconstruction: 0.210772, Regularization: 0.000435\n",
      "2019-04-10 01:02:20,760 root         INFO     Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 0.218635\n",
      "Reconstruction: 0.218227, Regularization: 0.000408\n",
      "2019-04-10 01:02:20,823 root         INFO     Train Epoch: 64 [4608/8000 (58%)]\tTotal Loss: 0.203818\n",
      "Reconstruction: 0.203262, Regularization: 0.000556\n",
      "2019-04-10 01:02:20,885 root         INFO     Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 0.210833\n",
      "Reconstruction: 0.210349, Regularization: 0.000484\n",
      "2019-04-10 01:02:20,948 root         INFO     Train Epoch: 64 [5632/8000 (70%)]\tTotal Loss: 0.218221\n",
      "Reconstruction: 0.217749, Regularization: 0.000472\n",
      "2019-04-10 01:02:21,011 root         INFO     Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 0.210118\n",
      "Reconstruction: 0.209770, Regularization: 0.000348\n",
      "2019-04-10 01:02:21,074 root         INFO     Train Epoch: 64 [6656/8000 (83%)]\tTotal Loss: 0.215117\n",
      "Reconstruction: 0.214570, Regularization: 0.000546\n",
      "2019-04-10 01:02:21,137 root         INFO     Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 0.212971\n",
      "Reconstruction: 0.212510, Regularization: 0.000461\n",
      "2019-04-10 01:02:21,200 root         INFO     Train Epoch: 64 [7680/8000 (96%)]\tTotal Loss: 0.208550\n",
      "Reconstruction: 0.208126, Regularization: 0.000424\n",
      "2019-04-10 01:02:21,254 root         INFO     ====> Epoch: 64 Average loss: 0.2111\n",
      "2019-04-10 01:02:21,279 root         INFO     Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 0.216204\n",
      "Reconstruction: 0.215621, Regularization: 0.000583\n",
      "2019-04-10 01:02:21,343 root         INFO     Train Epoch: 65 [512/8000 (6%)]\tTotal Loss: 0.212854\n",
      "Reconstruction: 0.212458, Regularization: 0.000397\n",
      "2019-04-10 01:02:21,407 root         INFO     Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 0.212463\n",
      "Reconstruction: 0.212104, Regularization: 0.000359\n",
      "2019-04-10 01:02:21,471 root         INFO     Train Epoch: 65 [1536/8000 (19%)]\tTotal Loss: 0.209596\n",
      "Reconstruction: 0.209103, Regularization: 0.000492\n",
      "2019-04-10 01:02:21,534 root         INFO     Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 0.216978\n",
      "Reconstruction: 0.216650, Regularization: 0.000328\n",
      "2019-04-10 01:02:21,597 root         INFO     Train Epoch: 65 [2560/8000 (32%)]\tTotal Loss: 0.209202\n",
      "Reconstruction: 0.208715, Regularization: 0.000487\n",
      "2019-04-10 01:02:21,660 root         INFO     Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 0.210079\n",
      "Reconstruction: 0.209549, Regularization: 0.000530\n",
      "2019-04-10 01:02:21,723 root         INFO     Train Epoch: 65 [3584/8000 (45%)]\tTotal Loss: 0.208506\n",
      "Reconstruction: 0.208039, Regularization: 0.000466\n",
      "2019-04-10 01:02:21,786 root         INFO     Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 0.215353\n",
      "Reconstruction: 0.214857, Regularization: 0.000495\n",
      "2019-04-10 01:02:21,850 root         INFO     Train Epoch: 65 [4608/8000 (58%)]\tTotal Loss: 0.208998\n",
      "Reconstruction: 0.208460, Regularization: 0.000538\n",
      "2019-04-10 01:02:21,913 root         INFO     Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 0.214027\n",
      "Reconstruction: 0.213609, Regularization: 0.000418\n",
      "2019-04-10 01:02:21,977 root         INFO     Train Epoch: 65 [5632/8000 (70%)]\tTotal Loss: 0.217772\n",
      "Reconstruction: 0.217484, Regularization: 0.000289\n",
      "2019-04-10 01:02:22,040 root         INFO     Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 0.207707\n",
      "Reconstruction: 0.207284, Regularization: 0.000423\n",
      "2019-04-10 01:02:22,103 root         INFO     Train Epoch: 65 [6656/8000 (83%)]\tTotal Loss: 0.210189\n",
      "Reconstruction: 0.209569, Regularization: 0.000620\n",
      "2019-04-10 01:02:22,166 root         INFO     Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 0.212311\n",
      "Reconstruction: 0.211875, Regularization: 0.000436\n",
      "2019-04-10 01:02:22,230 root         INFO     Train Epoch: 65 [7680/8000 (96%)]\tTotal Loss: 0.214852\n",
      "Reconstruction: 0.214485, Regularization: 0.000367\n",
      "2019-04-10 01:02:22,284 root         INFO     ====> Epoch: 65 Average loss: 0.2104\n",
      "2019-04-10 01:02:22,308 root         INFO     Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 0.211884\n",
      "Reconstruction: 0.211260, Regularization: 0.000624\n",
      "2019-04-10 01:02:22,372 root         INFO     Train Epoch: 66 [512/8000 (6%)]\tTotal Loss: 0.216293\n",
      "Reconstruction: 0.216065, Regularization: 0.000228\n",
      "2019-04-10 01:02:22,436 root         INFO     Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 0.207702\n",
      "Reconstruction: 0.207041, Regularization: 0.000661\n",
      "2019-04-10 01:02:22,498 root         INFO     Train Epoch: 66 [1536/8000 (19%)]\tTotal Loss: 0.206311\n",
      "Reconstruction: 0.205978, Regularization: 0.000332\n",
      "2019-04-10 01:02:22,561 root         INFO     Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 0.207836\n",
      "Reconstruction: 0.207382, Regularization: 0.000453\n",
      "2019-04-10 01:02:22,623 root         INFO     Train Epoch: 66 [2560/8000 (32%)]\tTotal Loss: 0.210233\n",
      "Reconstruction: 0.209952, Regularization: 0.000281\n",
      "2019-04-10 01:02:22,685 root         INFO     Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 0.211677\n",
      "Reconstruction: 0.211209, Regularization: 0.000468\n",
      "2019-04-10 01:02:22,748 root         INFO     Train Epoch: 66 [3584/8000 (45%)]\tTotal Loss: 0.205823\n",
      "Reconstruction: 0.205336, Regularization: 0.000487\n",
      "2019-04-10 01:02:22,811 root         INFO     Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 0.202277\n",
      "Reconstruction: 0.201862, Regularization: 0.000415\n",
      "2019-04-10 01:02:22,874 root         INFO     Train Epoch: 66 [4608/8000 (58%)]\tTotal Loss: 0.216283\n",
      "Reconstruction: 0.215910, Regularization: 0.000374\n",
      "2019-04-10 01:02:22,936 root         INFO     Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 0.211435\n",
      "Reconstruction: 0.211078, Regularization: 0.000357\n",
      "2019-04-10 01:02:22,999 root         INFO     Train Epoch: 66 [5632/8000 (70%)]\tTotal Loss: 0.204458\n",
      "Reconstruction: 0.204055, Regularization: 0.000403\n",
      "2019-04-10 01:02:23,061 root         INFO     Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 0.208477\n",
      "Reconstruction: 0.207923, Regularization: 0.000553\n",
      "2019-04-10 01:02:23,123 root         INFO     Train Epoch: 66 [6656/8000 (83%)]\tTotal Loss: 0.212814\n",
      "Reconstruction: 0.212486, Regularization: 0.000329\n",
      "2019-04-10 01:02:23,185 root         INFO     Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 0.204297\n",
      "Reconstruction: 0.203809, Regularization: 0.000488\n",
      "2019-04-10 01:02:23,247 root         INFO     Train Epoch: 66 [7680/8000 (96%)]\tTotal Loss: 0.218511\n",
      "Reconstruction: 0.218143, Regularization: 0.000368\n",
      "2019-04-10 01:02:23,301 root         INFO     ====> Epoch: 66 Average loss: 0.2097\n",
      "2019-04-10 01:02:23,325 root         INFO     Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 0.206823\n",
      "Reconstruction: 0.206328, Regularization: 0.000495\n",
      "2019-04-10 01:02:23,388 root         INFO     Train Epoch: 67 [512/8000 (6%)]\tTotal Loss: 0.214218\n",
      "Reconstruction: 0.213853, Regularization: 0.000365\n",
      "2019-04-10 01:02:23,451 root         INFO     Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 0.212011\n",
      "Reconstruction: 0.211613, Regularization: 0.000398\n",
      "2019-04-10 01:02:23,514 root         INFO     Train Epoch: 67 [1536/8000 (19%)]\tTotal Loss: 0.216706\n",
      "Reconstruction: 0.216271, Regularization: 0.000435\n",
      "2019-04-10 01:02:23,577 root         INFO     Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 0.207853\n",
      "Reconstruction: 0.207471, Regularization: 0.000383\n",
      "2019-04-10 01:02:23,640 root         INFO     Train Epoch: 67 [2560/8000 (32%)]\tTotal Loss: 0.215041\n",
      "Reconstruction: 0.214635, Regularization: 0.000406\n",
      "2019-04-10 01:02:23,702 root         INFO     Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 0.210320\n",
      "Reconstruction: 0.209996, Regularization: 0.000323\n",
      "2019-04-10 01:02:23,766 root         INFO     Train Epoch: 67 [3584/8000 (45%)]\tTotal Loss: 0.205335\n",
      "Reconstruction: 0.204940, Regularization: 0.000394\n",
      "2019-04-10 01:02:23,829 root         INFO     Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 0.212243\n",
      "Reconstruction: 0.211666, Regularization: 0.000577\n",
      "2019-04-10 01:02:23,891 root         INFO     Train Epoch: 67 [4608/8000 (58%)]\tTotal Loss: 0.208951\n",
      "Reconstruction: 0.208596, Regularization: 0.000354\n",
      "2019-04-10 01:02:23,954 root         INFO     Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 0.209884\n",
      "Reconstruction: 0.209363, Regularization: 0.000521\n",
      "2019-04-10 01:02:24,016 root         INFO     Train Epoch: 67 [5632/8000 (70%)]\tTotal Loss: 0.215289\n",
      "Reconstruction: 0.214479, Regularization: 0.000810\n",
      "2019-04-10 01:02:24,079 root         INFO     Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 0.206183\n",
      "Reconstruction: 0.205882, Regularization: 0.000301\n",
      "2019-04-10 01:02:24,141 root         INFO     Train Epoch: 67 [6656/8000 (83%)]\tTotal Loss: 0.209763\n",
      "Reconstruction: 0.209555, Regularization: 0.000208\n",
      "2019-04-10 01:02:24,203 root         INFO     Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 0.213303\n",
      "Reconstruction: 0.212872, Regularization: 0.000430\n",
      "2019-04-10 01:02:24,265 root         INFO     Train Epoch: 67 [7680/8000 (96%)]\tTotal Loss: 0.217672\n",
      "Reconstruction: 0.217253, Regularization: 0.000419\n",
      "2019-04-10 01:02:24,319 root         INFO     ====> Epoch: 67 Average loss: 0.2092\n",
      "2019-04-10 01:02:24,342 root         INFO     Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 0.206535\n",
      "Reconstruction: 0.206103, Regularization: 0.000433\n",
      "2019-04-10 01:02:24,406 root         INFO     Train Epoch: 68 [512/8000 (6%)]\tTotal Loss: 0.204276\n",
      "Reconstruction: 0.203780, Regularization: 0.000497\n",
      "2019-04-10 01:02:24,470 root         INFO     Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 0.211978\n",
      "Reconstruction: 0.211533, Regularization: 0.000445\n",
      "2019-04-10 01:02:24,533 root         INFO     Train Epoch: 68 [1536/8000 (19%)]\tTotal Loss: 0.203824\n",
      "Reconstruction: 0.203451, Regularization: 0.000373\n",
      "2019-04-10 01:02:24,597 root         INFO     Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 0.208991\n",
      "Reconstruction: 0.208482, Regularization: 0.000509\n",
      "2019-04-10 01:02:24,660 root         INFO     Train Epoch: 68 [2560/8000 (32%)]\tTotal Loss: 0.206401\n",
      "Reconstruction: 0.206014, Regularization: 0.000387\n",
      "2019-04-10 01:02:24,724 root         INFO     Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 0.205125\n",
      "Reconstruction: 0.204763, Regularization: 0.000362\n",
      "2019-04-10 01:02:24,788 root         INFO     Train Epoch: 68 [3584/8000 (45%)]\tTotal Loss: 0.205116\n",
      "Reconstruction: 0.204768, Regularization: 0.000348\n",
      "2019-04-10 01:02:24,852 root         INFO     Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 0.205423\n",
      "Reconstruction: 0.204990, Regularization: 0.000433\n",
      "2019-04-10 01:02:24,915 root         INFO     Train Epoch: 68 [4608/8000 (58%)]\tTotal Loss: 0.209762\n",
      "Reconstruction: 0.209386, Regularization: 0.000377\n",
      "2019-04-10 01:02:24,979 root         INFO     Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 0.210071\n",
      "Reconstruction: 0.209840, Regularization: 0.000231\n",
      "2019-04-10 01:02:25,044 root         INFO     Train Epoch: 68 [5632/8000 (70%)]\tTotal Loss: 0.208574\n",
      "Reconstruction: 0.208170, Regularization: 0.000403\n",
      "2019-04-10 01:02:25,108 root         INFO     Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 0.204216\n",
      "Reconstruction: 0.203595, Regularization: 0.000621\n",
      "2019-04-10 01:02:25,172 root         INFO     Train Epoch: 68 [6656/8000 (83%)]\tTotal Loss: 0.207044\n",
      "Reconstruction: 0.206646, Regularization: 0.000398\n",
      "2019-04-10 01:02:25,235 root         INFO     Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 0.207666\n",
      "Reconstruction: 0.207195, Regularization: 0.000472\n",
      "2019-04-10 01:02:25,299 root         INFO     Train Epoch: 68 [7680/8000 (96%)]\tTotal Loss: 0.208482\n",
      "Reconstruction: 0.208078, Regularization: 0.000404\n",
      "2019-04-10 01:02:25,354 root         INFO     ====> Epoch: 68 Average loss: 0.2088\n",
      "2019-04-10 01:02:25,378 root         INFO     Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 0.203241\n",
      "Reconstruction: 0.202511, Regularization: 0.000730\n",
      "2019-04-10 01:02:25,440 root         INFO     Train Epoch: 69 [512/8000 (6%)]\tTotal Loss: 0.205015\n",
      "Reconstruction: 0.204638, Regularization: 0.000377\n",
      "2019-04-10 01:02:25,504 root         INFO     Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 0.203789\n",
      "Reconstruction: 0.203409, Regularization: 0.000380\n",
      "2019-04-10 01:02:25,567 root         INFO     Train Epoch: 69 [1536/8000 (19%)]\tTotal Loss: 0.204809\n",
      "Reconstruction: 0.204366, Regularization: 0.000443\n",
      "2019-04-10 01:02:25,630 root         INFO     Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 0.204558\n",
      "Reconstruction: 0.204209, Regularization: 0.000349\n",
      "2019-04-10 01:02:25,693 root         INFO     Train Epoch: 69 [2560/8000 (32%)]\tTotal Loss: 0.212464\n",
      "Reconstruction: 0.212159, Regularization: 0.000305\n",
      "2019-04-10 01:02:25,756 root         INFO     Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 0.205984\n",
      "Reconstruction: 0.205474, Regularization: 0.000509\n",
      "2019-04-10 01:02:25,819 root         INFO     Train Epoch: 69 [3584/8000 (45%)]\tTotal Loss: 0.211205\n",
      "Reconstruction: 0.210968, Regularization: 0.000237\n",
      "2019-04-10 01:02:25,882 root         INFO     Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 0.207107\n",
      "Reconstruction: 0.206652, Regularization: 0.000455\n",
      "2019-04-10 01:02:25,945 root         INFO     Train Epoch: 69 [4608/8000 (58%)]\tTotal Loss: 0.212175\n",
      "Reconstruction: 0.211742, Regularization: 0.000433\n",
      "2019-04-10 01:02:26,009 root         INFO     Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 0.208687\n",
      "Reconstruction: 0.208396, Regularization: 0.000291\n",
      "2019-04-10 01:02:26,072 root         INFO     Train Epoch: 69 [5632/8000 (70%)]\tTotal Loss: 0.216977\n",
      "Reconstruction: 0.216251, Regularization: 0.000725\n",
      "2019-04-10 01:02:26,134 root         INFO     Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 0.213686\n",
      "Reconstruction: 0.213172, Regularization: 0.000515\n",
      "2019-04-10 01:02:26,197 root         INFO     Train Epoch: 69 [6656/8000 (83%)]\tTotal Loss: 0.207122\n",
      "Reconstruction: 0.206771, Regularization: 0.000351\n",
      "2019-04-10 01:02:26,260 root         INFO     Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 0.207251\n",
      "Reconstruction: 0.206821, Regularization: 0.000430\n",
      "2019-04-10 01:02:26,322 root         INFO     Train Epoch: 69 [7680/8000 (96%)]\tTotal Loss: 0.206116\n",
      "Reconstruction: 0.205604, Regularization: 0.000512\n",
      "2019-04-10 01:02:26,377 root         INFO     ====> Epoch: 69 Average loss: 0.2083\n",
      "2019-04-10 01:02:26,401 root         INFO     Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 0.213314\n",
      "Reconstruction: 0.212656, Regularization: 0.000658\n",
      "2019-04-10 01:02:26,465 root         INFO     Train Epoch: 70 [512/8000 (6%)]\tTotal Loss: 0.209076\n",
      "Reconstruction: 0.208677, Regularization: 0.000398\n",
      "2019-04-10 01:02:26,529 root         INFO     Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 0.203763\n",
      "Reconstruction: 0.203193, Regularization: 0.000571\n",
      "2019-04-10 01:02:26,593 root         INFO     Train Epoch: 70 [1536/8000 (19%)]\tTotal Loss: 0.208203\n",
      "Reconstruction: 0.207900, Regularization: 0.000303\n",
      "2019-04-10 01:02:26,659 root         INFO     Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 0.204443\n",
      "Reconstruction: 0.203724, Regularization: 0.000718\n",
      "2019-04-10 01:02:26,723 root         INFO     Train Epoch: 70 [2560/8000 (32%)]\tTotal Loss: 0.210547\n",
      "Reconstruction: 0.210191, Regularization: 0.000356\n",
      "2019-04-10 01:02:26,786 root         INFO     Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 0.209417\n",
      "Reconstruction: 0.209143, Regularization: 0.000274\n",
      "2019-04-10 01:02:26,848 root         INFO     Train Epoch: 70 [3584/8000 (45%)]\tTotal Loss: 0.210230\n",
      "Reconstruction: 0.209750, Regularization: 0.000481\n",
      "2019-04-10 01:02:26,909 root         INFO     Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 0.208009\n",
      "Reconstruction: 0.207394, Regularization: 0.000614\n",
      "2019-04-10 01:02:26,971 root         INFO     Train Epoch: 70 [4608/8000 (58%)]\tTotal Loss: 0.209370\n",
      "Reconstruction: 0.208747, Regularization: 0.000622\n",
      "2019-04-10 01:02:27,033 root         INFO     Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 0.207184\n",
      "Reconstruction: 0.206791, Regularization: 0.000393\n",
      "2019-04-10 01:02:27,094 root         INFO     Train Epoch: 70 [5632/8000 (70%)]\tTotal Loss: 0.204084\n",
      "Reconstruction: 0.203663, Regularization: 0.000420\n",
      "2019-04-10 01:02:27,155 root         INFO     Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 0.205162\n",
      "Reconstruction: 0.204743, Regularization: 0.000420\n",
      "2019-04-10 01:02:27,216 root         INFO     Train Epoch: 70 [6656/8000 (83%)]\tTotal Loss: 0.207112\n",
      "Reconstruction: 0.206653, Regularization: 0.000460\n",
      "2019-04-10 01:02:27,277 root         INFO     Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 0.213687\n",
      "Reconstruction: 0.213146, Regularization: 0.000541\n",
      "2019-04-10 01:02:27,339 root         INFO     Train Epoch: 70 [7680/8000 (96%)]\tTotal Loss: 0.210257\n",
      "Reconstruction: 0.209880, Regularization: 0.000376\n",
      "2019-04-10 01:02:27,392 root         INFO     ====> Epoch: 70 Average loss: 0.2079\n",
      "2019-04-10 01:02:27,416 root         INFO     Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 0.204775\n",
      "Reconstruction: 0.204217, Regularization: 0.000558\n",
      "2019-04-10 01:02:27,481 root         INFO     Train Epoch: 71 [512/8000 (6%)]\tTotal Loss: 0.204872\n",
      "Reconstruction: 0.204424, Regularization: 0.000448\n",
      "2019-04-10 01:02:27,544 root         INFO     Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 0.200865\n",
      "Reconstruction: 0.200339, Regularization: 0.000526\n",
      "2019-04-10 01:02:27,606 root         INFO     Train Epoch: 71 [1536/8000 (19%)]\tTotal Loss: 0.203163\n",
      "Reconstruction: 0.202810, Regularization: 0.000353\n",
      "2019-04-10 01:02:27,668 root         INFO     Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 0.202993\n",
      "Reconstruction: 0.202577, Regularization: 0.000416\n",
      "2019-04-10 01:02:27,730 root         INFO     Train Epoch: 71 [2560/8000 (32%)]\tTotal Loss: 0.209779\n",
      "Reconstruction: 0.209358, Regularization: 0.000421\n",
      "2019-04-10 01:02:27,792 root         INFO     Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 0.222432\n",
      "Reconstruction: 0.221955, Regularization: 0.000477\n",
      "2019-04-10 01:02:27,854 root         INFO     Train Epoch: 71 [3584/8000 (45%)]\tTotal Loss: 0.207937\n",
      "Reconstruction: 0.207692, Regularization: 0.000245\n",
      "2019-04-10 01:02:27,917 root         INFO     Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 0.206980\n",
      "Reconstruction: 0.206530, Regularization: 0.000450\n",
      "2019-04-10 01:02:27,979 root         INFO     Train Epoch: 71 [4608/8000 (58%)]\tTotal Loss: 0.205189\n",
      "Reconstruction: 0.204821, Regularization: 0.000368\n",
      "2019-04-10 01:02:28,040 root         INFO     Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 0.208962\n",
      "Reconstruction: 0.208494, Regularization: 0.000467\n",
      "2019-04-10 01:02:28,102 root         INFO     Train Epoch: 71 [5632/8000 (70%)]\tTotal Loss: 0.204578\n",
      "Reconstruction: 0.204167, Regularization: 0.000411\n",
      "2019-04-10 01:02:28,163 root         INFO     Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 0.203720\n",
      "Reconstruction: 0.203247, Regularization: 0.000473\n",
      "2019-04-10 01:02:28,225 root         INFO     Train Epoch: 71 [6656/8000 (83%)]\tTotal Loss: 0.199353\n",
      "Reconstruction: 0.199037, Regularization: 0.000316\n",
      "2019-04-10 01:02:28,287 root         INFO     Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 0.202434\n",
      "Reconstruction: 0.202102, Regularization: 0.000332\n",
      "2019-04-10 01:02:28,349 root         INFO     Train Epoch: 71 [7680/8000 (96%)]\tTotal Loss: 0.202217\n",
      "Reconstruction: 0.201767, Regularization: 0.000450\n",
      "2019-04-10 01:02:28,402 root         INFO     ====> Epoch: 71 Average loss: 0.2074\n",
      "2019-04-10 01:02:28,426 root         INFO     Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 0.200687\n",
      "Reconstruction: 0.200463, Regularization: 0.000224\n",
      "2019-04-10 01:02:28,491 root         INFO     Train Epoch: 72 [512/8000 (6%)]\tTotal Loss: 0.207195\n",
      "Reconstruction: 0.206838, Regularization: 0.000357\n",
      "2019-04-10 01:02:28,555 root         INFO     Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 0.200835\n",
      "Reconstruction: 0.200482, Regularization: 0.000353\n",
      "2019-04-10 01:02:28,619 root         INFO     Train Epoch: 72 [1536/8000 (19%)]\tTotal Loss: 0.216045\n",
      "Reconstruction: 0.215552, Regularization: 0.000493\n",
      "2019-04-10 01:02:28,683 root         INFO     Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 0.208504\n",
      "Reconstruction: 0.208167, Regularization: 0.000337\n",
      "2019-04-10 01:02:28,747 root         INFO     Train Epoch: 72 [2560/8000 (32%)]\tTotal Loss: 0.209380\n",
      "Reconstruction: 0.208797, Regularization: 0.000583\n",
      "2019-04-10 01:02:28,809 root         INFO     Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 0.205656\n",
      "Reconstruction: 0.205191, Regularization: 0.000465\n",
      "2019-04-10 01:02:28,872 root         INFO     Train Epoch: 72 [3584/8000 (45%)]\tTotal Loss: 0.205708\n",
      "Reconstruction: 0.205409, Regularization: 0.000300\n",
      "2019-04-10 01:02:28,936 root         INFO     Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 0.202059\n",
      "Reconstruction: 0.201589, Regularization: 0.000469\n",
      "2019-04-10 01:02:28,999 root         INFO     Train Epoch: 72 [4608/8000 (58%)]\tTotal Loss: 0.207942\n",
      "Reconstruction: 0.207632, Regularization: 0.000310\n",
      "2019-04-10 01:02:29,063 root         INFO     Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 0.211517\n",
      "Reconstruction: 0.211194, Regularization: 0.000323\n",
      "2019-04-10 01:02:29,126 root         INFO     Train Epoch: 72 [5632/8000 (70%)]\tTotal Loss: 0.214135\n",
      "Reconstruction: 0.213736, Regularization: 0.000398\n",
      "2019-04-10 01:02:29,189 root         INFO     Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 0.201288\n",
      "Reconstruction: 0.200895, Regularization: 0.000393\n",
      "2019-04-10 01:02:29,252 root         INFO     Train Epoch: 72 [6656/8000 (83%)]\tTotal Loss: 0.210219\n",
      "Reconstruction: 0.209818, Regularization: 0.000401\n",
      "2019-04-10 01:02:29,314 root         INFO     Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 0.203659\n",
      "Reconstruction: 0.203350, Regularization: 0.000309\n",
      "2019-04-10 01:02:29,377 root         INFO     Train Epoch: 72 [7680/8000 (96%)]\tTotal Loss: 0.204738\n",
      "Reconstruction: 0.204348, Regularization: 0.000390\n",
      "2019-04-10 01:02:29,431 root         INFO     ====> Epoch: 72 Average loss: 0.2069\n",
      "2019-04-10 01:02:29,455 root         INFO     Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 0.196356\n",
      "Reconstruction: 0.195939, Regularization: 0.000417\n",
      "2019-04-10 01:02:29,520 root         INFO     Train Epoch: 73 [512/8000 (6%)]\tTotal Loss: 0.207562\n",
      "Reconstruction: 0.207235, Regularization: 0.000327\n",
      "2019-04-10 01:02:29,584 root         INFO     Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 0.207903\n",
      "Reconstruction: 0.207590, Regularization: 0.000313\n",
      "2019-04-10 01:02:29,647 root         INFO     Train Epoch: 73 [1536/8000 (19%)]\tTotal Loss: 0.205839\n",
      "Reconstruction: 0.205344, Regularization: 0.000495\n",
      "2019-04-10 01:02:29,711 root         INFO     Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 0.210203\n",
      "Reconstruction: 0.209912, Regularization: 0.000291\n",
      "2019-04-10 01:02:29,775 root         INFO     Train Epoch: 73 [2560/8000 (32%)]\tTotal Loss: 0.208663\n",
      "Reconstruction: 0.208262, Regularization: 0.000402\n",
      "2019-04-10 01:02:29,840 root         INFO     Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 0.205229\n",
      "Reconstruction: 0.204648, Regularization: 0.000581\n",
      "2019-04-10 01:02:29,904 root         INFO     Train Epoch: 73 [3584/8000 (45%)]\tTotal Loss: 0.208094\n",
      "Reconstruction: 0.207852, Regularization: 0.000242\n",
      "2019-04-10 01:02:29,968 root         INFO     Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 0.204782\n",
      "Reconstruction: 0.204229, Regularization: 0.000552\n",
      "2019-04-10 01:02:30,032 root         INFO     Train Epoch: 73 [4608/8000 (58%)]\tTotal Loss: 0.200954\n",
      "Reconstruction: 0.200609, Regularization: 0.000345\n",
      "2019-04-10 01:02:30,096 root         INFO     Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 0.204824\n",
      "Reconstruction: 0.204452, Regularization: 0.000372\n",
      "2019-04-10 01:02:30,160 root         INFO     Train Epoch: 73 [5632/8000 (70%)]\tTotal Loss: 0.208556\n",
      "Reconstruction: 0.208227, Regularization: 0.000329\n",
      "2019-04-10 01:02:30,224 root         INFO     Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 0.206834\n",
      "Reconstruction: 0.206501, Regularization: 0.000333\n",
      "2019-04-10 01:02:30,288 root         INFO     Train Epoch: 73 [6656/8000 (83%)]\tTotal Loss: 0.203295\n",
      "Reconstruction: 0.202965, Regularization: 0.000331\n",
      "2019-04-10 01:02:30,352 root         INFO     Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 0.204370\n",
      "Reconstruction: 0.203894, Regularization: 0.000476\n",
      "2019-04-10 01:02:30,415 root         INFO     Train Epoch: 73 [7680/8000 (96%)]\tTotal Loss: 0.207859\n",
      "Reconstruction: 0.207537, Regularization: 0.000322\n",
      "2019-04-10 01:02:30,469 root         INFO     ====> Epoch: 73 Average loss: 0.2065\n",
      "2019-04-10 01:02:30,493 root         INFO     Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 0.211515\n",
      "Reconstruction: 0.211209, Regularization: 0.000306\n",
      "2019-04-10 01:02:30,558 root         INFO     Train Epoch: 74 [512/8000 (6%)]\tTotal Loss: 0.200426\n",
      "Reconstruction: 0.200134, Regularization: 0.000292\n",
      "2019-04-10 01:02:30,623 root         INFO     Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 0.210631\n",
      "Reconstruction: 0.210213, Regularization: 0.000418\n",
      "2019-04-10 01:02:30,687 root         INFO     Train Epoch: 74 [1536/8000 (19%)]\tTotal Loss: 0.206034\n",
      "Reconstruction: 0.205569, Regularization: 0.000465\n",
      "2019-04-10 01:02:30,751 root         INFO     Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 0.206179\n",
      "Reconstruction: 0.205902, Regularization: 0.000277\n",
      "2019-04-10 01:02:30,816 root         INFO     Train Epoch: 74 [2560/8000 (32%)]\tTotal Loss: 0.206317\n",
      "Reconstruction: 0.206022, Regularization: 0.000295\n",
      "2019-04-10 01:02:30,879 root         INFO     Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 0.200809\n",
      "Reconstruction: 0.200202, Regularization: 0.000608\n",
      "2019-04-10 01:02:30,943 root         INFO     Train Epoch: 74 [3584/8000 (45%)]\tTotal Loss: 0.204431\n",
      "Reconstruction: 0.204060, Regularization: 0.000371\n",
      "2019-04-10 01:02:31,007 root         INFO     Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 0.201952\n",
      "Reconstruction: 0.201696, Regularization: 0.000256\n",
      "2019-04-10 01:02:31,071 root         INFO     Train Epoch: 74 [4608/8000 (58%)]\tTotal Loss: 0.198049\n",
      "Reconstruction: 0.197761, Regularization: 0.000288\n",
      "2019-04-10 01:02:31,135 root         INFO     Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 0.208842\n",
      "Reconstruction: 0.208367, Regularization: 0.000475\n",
      "2019-04-10 01:02:31,199 root         INFO     Train Epoch: 74 [5632/8000 (70%)]\tTotal Loss: 0.204863\n",
      "Reconstruction: 0.204436, Regularization: 0.000427\n",
      "2019-04-10 01:02:31,263 root         INFO     Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 0.210947\n",
      "Reconstruction: 0.210641, Regularization: 0.000306\n",
      "2019-04-10 01:02:31,327 root         INFO     Train Epoch: 74 [6656/8000 (83%)]\tTotal Loss: 0.203739\n",
      "Reconstruction: 0.203317, Regularization: 0.000422\n",
      "2019-04-10 01:02:31,391 root         INFO     Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 0.208811\n",
      "Reconstruction: 0.208500, Regularization: 0.000311\n",
      "2019-04-10 01:02:31,455 root         INFO     Train Epoch: 74 [7680/8000 (96%)]\tTotal Loss: 0.204079\n",
      "Reconstruction: 0.203829, Regularization: 0.000250\n",
      "2019-04-10 01:02:31,510 root         INFO     ====> Epoch: 74 Average loss: 0.2060\n",
      "2019-04-10 01:02:31,534 root         INFO     Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 0.202653\n",
      "Reconstruction: 0.202242, Regularization: 0.000412\n",
      "2019-04-10 01:02:31,597 root         INFO     Train Epoch: 75 [512/8000 (6%)]\tTotal Loss: 0.205690\n",
      "Reconstruction: 0.205397, Regularization: 0.000293\n",
      "2019-04-10 01:02:31,661 root         INFO     Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 0.205740\n",
      "Reconstruction: 0.205317, Regularization: 0.000424\n",
      "2019-04-10 01:02:31,725 root         INFO     Train Epoch: 75 [1536/8000 (19%)]\tTotal Loss: 0.206196\n",
      "Reconstruction: 0.205844, Regularization: 0.000351\n",
      "2019-04-10 01:02:31,789 root         INFO     Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 0.200016\n",
      "Reconstruction: 0.199594, Regularization: 0.000422\n",
      "2019-04-10 01:02:31,852 root         INFO     Train Epoch: 75 [2560/8000 (32%)]\tTotal Loss: 0.217387\n",
      "Reconstruction: 0.217083, Regularization: 0.000304\n",
      "2019-04-10 01:02:31,916 root         INFO     Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 0.212032\n",
      "Reconstruction: 0.211618, Regularization: 0.000414\n",
      "2019-04-10 01:02:31,979 root         INFO     Train Epoch: 75 [3584/8000 (45%)]\tTotal Loss: 0.203977\n",
      "Reconstruction: 0.203575, Regularization: 0.000402\n",
      "2019-04-10 01:02:32,043 root         INFO     Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 0.200514\n",
      "Reconstruction: 0.200233, Regularization: 0.000280\n",
      "2019-04-10 01:02:32,106 root         INFO     Train Epoch: 75 [4608/8000 (58%)]\tTotal Loss: 0.208396\n",
      "Reconstruction: 0.208107, Regularization: 0.000289\n",
      "2019-04-10 01:02:32,169 root         INFO     Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 0.197717\n",
      "Reconstruction: 0.197354, Regularization: 0.000363\n",
      "2019-04-10 01:02:32,231 root         INFO     Train Epoch: 75 [5632/8000 (70%)]\tTotal Loss: 0.199071\n",
      "Reconstruction: 0.198695, Regularization: 0.000376\n",
      "2019-04-10 01:02:32,294 root         INFO     Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 0.210287\n",
      "Reconstruction: 0.210005, Regularization: 0.000282\n",
      "2019-04-10 01:02:32,357 root         INFO     Train Epoch: 75 [6656/8000 (83%)]\tTotal Loss: 0.204712\n",
      "Reconstruction: 0.204132, Regularization: 0.000581\n",
      "2019-04-10 01:02:32,420 root         INFO     Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 0.206223\n",
      "Reconstruction: 0.205851, Regularization: 0.000371\n",
      "2019-04-10 01:02:32,483 root         INFO     Train Epoch: 75 [7680/8000 (96%)]\tTotal Loss: 0.205517\n",
      "Reconstruction: 0.205211, Regularization: 0.000306\n",
      "2019-04-10 01:02:32,537 root         INFO     ====> Epoch: 75 Average loss: 0.2054\n",
      "2019-04-10 01:02:32,561 root         INFO     Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 0.207271\n",
      "Reconstruction: 0.206994, Regularization: 0.000276\n",
      "2019-04-10 01:02:32,625 root         INFO     Train Epoch: 76 [512/8000 (6%)]\tTotal Loss: 0.205840\n",
      "Reconstruction: 0.205581, Regularization: 0.000259\n",
      "2019-04-10 01:02:32,688 root         INFO     Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 0.206596\n",
      "Reconstruction: 0.206053, Regularization: 0.000543\n",
      "2019-04-10 01:02:32,752 root         INFO     Train Epoch: 76 [1536/8000 (19%)]\tTotal Loss: 0.206050\n",
      "Reconstruction: 0.205734, Regularization: 0.000316\n",
      "2019-04-10 01:02:32,815 root         INFO     Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 0.200457\n",
      "Reconstruction: 0.200231, Regularization: 0.000226\n",
      "2019-04-10 01:02:32,879 root         INFO     Train Epoch: 76 [2560/8000 (32%)]\tTotal Loss: 0.201267\n",
      "Reconstruction: 0.200931, Regularization: 0.000336\n",
      "2019-04-10 01:02:32,942 root         INFO     Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 0.204867\n",
      "Reconstruction: 0.204564, Regularization: 0.000303\n",
      "2019-04-10 01:02:33,005 root         INFO     Train Epoch: 76 [3584/8000 (45%)]\tTotal Loss: 0.209233\n",
      "Reconstruction: 0.208886, Regularization: 0.000348\n",
      "2019-04-10 01:02:33,068 root         INFO     Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 0.213943\n",
      "Reconstruction: 0.213624, Regularization: 0.000319\n",
      "2019-04-10 01:02:33,131 root         INFO     Train Epoch: 76 [4608/8000 (58%)]\tTotal Loss: 0.206814\n",
      "Reconstruction: 0.206442, Regularization: 0.000372\n",
      "2019-04-10 01:02:33,194 root         INFO     Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 0.200304\n",
      "Reconstruction: 0.199887, Regularization: 0.000416\n",
      "2019-04-10 01:02:33,257 root         INFO     Train Epoch: 76 [5632/8000 (70%)]\tTotal Loss: 0.205396\n",
      "Reconstruction: 0.204942, Regularization: 0.000454\n",
      "2019-04-10 01:02:33,320 root         INFO     Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 0.203045\n",
      "Reconstruction: 0.202711, Regularization: 0.000334\n",
      "2019-04-10 01:02:33,383 root         INFO     Train Epoch: 76 [6656/8000 (83%)]\tTotal Loss: 0.201349\n",
      "Reconstruction: 0.200986, Regularization: 0.000363\n",
      "2019-04-10 01:02:33,446 root         INFO     Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 0.200760\n",
      "Reconstruction: 0.200284, Regularization: 0.000476\n",
      "2019-04-10 01:02:33,509 root         INFO     Train Epoch: 76 [7680/8000 (96%)]\tTotal Loss: 0.204608\n",
      "Reconstruction: 0.204315, Regularization: 0.000293\n",
      "2019-04-10 01:02:33,564 root         INFO     ====> Epoch: 76 Average loss: 0.2048\n",
      "2019-04-10 01:02:33,589 root         INFO     Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 0.206624\n",
      "Reconstruction: 0.206333, Regularization: 0.000291\n",
      "2019-04-10 01:02:33,653 root         INFO     Train Epoch: 77 [512/8000 (6%)]\tTotal Loss: 0.203661\n",
      "Reconstruction: 0.203364, Regularization: 0.000297\n",
      "2019-04-10 01:02:33,716 root         INFO     Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 0.207075\n",
      "Reconstruction: 0.206616, Regularization: 0.000459\n",
      "2019-04-10 01:02:33,780 root         INFO     Train Epoch: 77 [1536/8000 (19%)]\tTotal Loss: 0.215408\n",
      "Reconstruction: 0.215056, Regularization: 0.000351\n",
      "2019-04-10 01:02:33,843 root         INFO     Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 0.209005\n",
      "Reconstruction: 0.208704, Regularization: 0.000301\n",
      "2019-04-10 01:02:33,905 root         INFO     Train Epoch: 77 [2560/8000 (32%)]\tTotal Loss: 0.207092\n",
      "Reconstruction: 0.206795, Regularization: 0.000298\n",
      "2019-04-10 01:02:33,967 root         INFO     Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 0.200915\n",
      "Reconstruction: 0.200638, Regularization: 0.000276\n",
      "2019-04-10 01:02:34,029 root         INFO     Train Epoch: 77 [3584/8000 (45%)]\tTotal Loss: 0.209439\n",
      "Reconstruction: 0.209157, Regularization: 0.000282\n",
      "2019-04-10 01:02:34,091 root         INFO     Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 0.201265\n",
      "Reconstruction: 0.200964, Regularization: 0.000301\n",
      "2019-04-10 01:02:34,153 root         INFO     Train Epoch: 77 [4608/8000 (58%)]\tTotal Loss: 0.197817\n",
      "Reconstruction: 0.197543, Regularization: 0.000275\n",
      "2019-04-10 01:02:34,215 root         INFO     Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 0.215501\n",
      "Reconstruction: 0.215152, Regularization: 0.000350\n",
      "2019-04-10 01:02:34,278 root         INFO     Train Epoch: 77 [5632/8000 (70%)]\tTotal Loss: 0.201980\n",
      "Reconstruction: 0.201489, Regularization: 0.000492\n",
      "2019-04-10 01:02:34,342 root         INFO     Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 0.200333\n",
      "Reconstruction: 0.199941, Regularization: 0.000392\n",
      "2019-04-10 01:02:34,405 root         INFO     Train Epoch: 77 [6656/8000 (83%)]\tTotal Loss: 0.201906\n",
      "Reconstruction: 0.201476, Regularization: 0.000431\n",
      "2019-04-10 01:02:34,467 root         INFO     Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 0.202030\n",
      "Reconstruction: 0.201672, Regularization: 0.000358\n",
      "2019-04-10 01:02:34,530 root         INFO     Train Epoch: 77 [7680/8000 (96%)]\tTotal Loss: 0.201145\n",
      "Reconstruction: 0.200822, Regularization: 0.000323\n",
      "2019-04-10 01:02:34,584 root         INFO     ====> Epoch: 77 Average loss: 0.2042\n",
      "2019-04-10 01:02:34,608 root         INFO     Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 0.195118\n",
      "Reconstruction: 0.194646, Regularization: 0.000472\n",
      "2019-04-10 01:02:34,671 root         INFO     Train Epoch: 78 [512/8000 (6%)]\tTotal Loss: 0.204146\n",
      "Reconstruction: 0.203833, Regularization: 0.000313\n",
      "2019-04-10 01:02:34,732 root         INFO     Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 0.205071\n",
      "Reconstruction: 0.204819, Regularization: 0.000252\n",
      "2019-04-10 01:02:34,794 root         INFO     Train Epoch: 78 [1536/8000 (19%)]\tTotal Loss: 0.198763\n",
      "Reconstruction: 0.198506, Regularization: 0.000257\n",
      "2019-04-10 01:02:34,855 root         INFO     Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 0.212069\n",
      "Reconstruction: 0.211782, Regularization: 0.000286\n",
      "2019-04-10 01:02:34,916 root         INFO     Train Epoch: 78 [2560/8000 (32%)]\tTotal Loss: 0.204450\n",
      "Reconstruction: 0.204216, Regularization: 0.000234\n",
      "2019-04-10 01:02:34,978 root         INFO     Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 0.204980\n",
      "Reconstruction: 0.204530, Regularization: 0.000450\n",
      "2019-04-10 01:02:35,040 root         INFO     Train Epoch: 78 [3584/8000 (45%)]\tTotal Loss: 0.199635\n",
      "Reconstruction: 0.199263, Regularization: 0.000372\n",
      "2019-04-10 01:02:35,101 root         INFO     Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 0.203586\n",
      "Reconstruction: 0.203167, Regularization: 0.000419\n",
      "2019-04-10 01:02:35,162 root         INFO     Train Epoch: 78 [4608/8000 (58%)]\tTotal Loss: 0.195148\n",
      "Reconstruction: 0.194919, Regularization: 0.000229\n",
      "2019-04-10 01:02:35,223 root         INFO     Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 0.207083\n",
      "Reconstruction: 0.206857, Regularization: 0.000227\n",
      "2019-04-10 01:02:35,284 root         INFO     Train Epoch: 78 [5632/8000 (70%)]\tTotal Loss: 0.207108\n",
      "Reconstruction: 0.206691, Regularization: 0.000417\n",
      "2019-04-10 01:02:35,345 root         INFO     Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 0.201403\n",
      "Reconstruction: 0.201101, Regularization: 0.000302\n",
      "2019-04-10 01:02:35,407 root         INFO     Train Epoch: 78 [6656/8000 (83%)]\tTotal Loss: 0.211553\n",
      "Reconstruction: 0.211223, Regularization: 0.000330\n",
      "2019-04-10 01:02:35,468 root         INFO     Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 0.202699\n",
      "Reconstruction: 0.202376, Regularization: 0.000323\n",
      "2019-04-10 01:02:35,529 root         INFO     Train Epoch: 78 [7680/8000 (96%)]\tTotal Loss: 0.202339\n",
      "Reconstruction: 0.202059, Regularization: 0.000280\n",
      "2019-04-10 01:02:35,582 root         INFO     ====> Epoch: 78 Average loss: 0.2035\n",
      "2019-04-10 01:02:35,606 root         INFO     Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 0.203521\n",
      "Reconstruction: 0.203275, Regularization: 0.000246\n",
      "2019-04-10 01:02:35,668 root         INFO     Train Epoch: 79 [512/8000 (6%)]\tTotal Loss: 0.203764\n",
      "Reconstruction: 0.203558, Regularization: 0.000205\n",
      "2019-04-10 01:02:35,730 root         INFO     Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 0.203884\n",
      "Reconstruction: 0.203671, Regularization: 0.000213\n",
      "2019-04-10 01:02:35,791 root         INFO     Train Epoch: 79 [1536/8000 (19%)]\tTotal Loss: 0.198631\n",
      "Reconstruction: 0.198235, Regularization: 0.000396\n",
      "2019-04-10 01:02:35,853 root         INFO     Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 0.203483\n",
      "Reconstruction: 0.203219, Regularization: 0.000264\n",
      "2019-04-10 01:02:35,915 root         INFO     Train Epoch: 79 [2560/8000 (32%)]\tTotal Loss: 0.197725\n",
      "Reconstruction: 0.197418, Regularization: 0.000306\n",
      "2019-04-10 01:02:35,976 root         INFO     Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 0.204761\n",
      "Reconstruction: 0.204469, Regularization: 0.000292\n",
      "2019-04-10 01:02:36,038 root         INFO     Train Epoch: 79 [3584/8000 (45%)]\tTotal Loss: 0.207221\n",
      "Reconstruction: 0.206901, Regularization: 0.000320\n",
      "2019-04-10 01:02:36,100 root         INFO     Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 0.198647\n",
      "Reconstruction: 0.198107, Regularization: 0.000540\n",
      "2019-04-10 01:02:36,161 root         INFO     Train Epoch: 79 [4608/8000 (58%)]\tTotal Loss: 0.200493\n",
      "Reconstruction: 0.200245, Regularization: 0.000248\n",
      "2019-04-10 01:02:36,223 root         INFO     Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 0.199384\n",
      "Reconstruction: 0.198998, Regularization: 0.000386\n",
      "2019-04-10 01:02:36,285 root         INFO     Train Epoch: 79 [5632/8000 (70%)]\tTotal Loss: 0.205414\n",
      "Reconstruction: 0.205121, Regularization: 0.000293\n",
      "2019-04-10 01:02:36,347 root         INFO     Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 0.211844\n",
      "Reconstruction: 0.211545, Regularization: 0.000298\n",
      "2019-04-10 01:02:36,409 root         INFO     Train Epoch: 79 [6656/8000 (83%)]\tTotal Loss: 0.197779\n",
      "Reconstruction: 0.197365, Regularization: 0.000415\n",
      "2019-04-10 01:02:36,471 root         INFO     Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 0.201598\n",
      "Reconstruction: 0.201335, Regularization: 0.000263\n",
      "2019-04-10 01:02:36,534 root         INFO     Train Epoch: 79 [7680/8000 (96%)]\tTotal Loss: 0.199948\n",
      "Reconstruction: 0.199487, Regularization: 0.000461\n",
      "2019-04-10 01:02:36,588 root         INFO     ====> Epoch: 79 Average loss: 0.2027\n",
      "2019-04-10 01:02:36,611 root         INFO     Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 0.201530\n",
      "Reconstruction: 0.201214, Regularization: 0.000316\n",
      "2019-04-10 01:02:36,674 root         INFO     Train Epoch: 80 [512/8000 (6%)]\tTotal Loss: 0.202970\n",
      "Reconstruction: 0.202786, Regularization: 0.000184\n",
      "2019-04-10 01:02:36,737 root         INFO     Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 0.211559\n",
      "Reconstruction: 0.211158, Regularization: 0.000400\n",
      "2019-04-10 01:02:36,800 root         INFO     Train Epoch: 80 [1536/8000 (19%)]\tTotal Loss: 0.201576\n",
      "Reconstruction: 0.201186, Regularization: 0.000389\n",
      "2019-04-10 01:02:36,863 root         INFO     Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 0.207426\n",
      "Reconstruction: 0.207072, Regularization: 0.000354\n",
      "2019-04-10 01:02:36,926 root         INFO     Train Epoch: 80 [2560/8000 (32%)]\tTotal Loss: 0.204444\n",
      "Reconstruction: 0.204167, Regularization: 0.000277\n",
      "2019-04-10 01:02:36,989 root         INFO     Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 0.206774\n",
      "Reconstruction: 0.206461, Regularization: 0.000312\n",
      "2019-04-10 01:02:37,051 root         INFO     Train Epoch: 80 [3584/8000 (45%)]\tTotal Loss: 0.209119\n",
      "Reconstruction: 0.208780, Regularization: 0.000339\n",
      "2019-04-10 01:02:37,114 root         INFO     Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 0.196622\n",
      "Reconstruction: 0.196269, Regularization: 0.000353\n",
      "2019-04-10 01:02:37,177 root         INFO     Train Epoch: 80 [4608/8000 (58%)]\tTotal Loss: 0.197192\n",
      "Reconstruction: 0.196687, Regularization: 0.000505\n",
      "2019-04-10 01:02:37,240 root         INFO     Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 0.199828\n",
      "Reconstruction: 0.199512, Regularization: 0.000315\n",
      "2019-04-10 01:02:37,303 root         INFO     Train Epoch: 80 [5632/8000 (70%)]\tTotal Loss: 0.197416\n",
      "Reconstruction: 0.196976, Regularization: 0.000441\n",
      "2019-04-10 01:02:37,366 root         INFO     Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 0.201117\n",
      "Reconstruction: 0.200910, Regularization: 0.000207\n",
      "2019-04-10 01:02:37,428 root         INFO     Train Epoch: 80 [6656/8000 (83%)]\tTotal Loss: 0.209250\n",
      "Reconstruction: 0.208896, Regularization: 0.000354\n",
      "2019-04-10 01:02:37,491 root         INFO     Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 0.203845\n",
      "Reconstruction: 0.203251, Regularization: 0.000594\n",
      "2019-04-10 01:02:37,555 root         INFO     Train Epoch: 80 [7680/8000 (96%)]\tTotal Loss: 0.199037\n",
      "Reconstruction: 0.198750, Regularization: 0.000287\n",
      "2019-04-10 01:02:37,609 root         INFO     ====> Epoch: 80 Average loss: 0.2019\n",
      "2019-04-10 01:02:37,634 root         INFO     Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 0.198133\n",
      "Reconstruction: 0.197720, Regularization: 0.000413\n",
      "2019-04-10 01:02:37,698 root         INFO     Train Epoch: 81 [512/8000 (6%)]\tTotal Loss: 0.198635\n",
      "Reconstruction: 0.198348, Regularization: 0.000287\n",
      "2019-04-10 01:02:37,762 root         INFO     Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 0.198051\n",
      "Reconstruction: 0.197855, Regularization: 0.000195\n",
      "2019-04-10 01:02:37,826 root         INFO     Train Epoch: 81 [1536/8000 (19%)]\tTotal Loss: 0.200728\n",
      "Reconstruction: 0.200499, Regularization: 0.000228\n",
      "2019-04-10 01:02:37,891 root         INFO     Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 0.201661\n",
      "Reconstruction: 0.201387, Regularization: 0.000275\n",
      "2019-04-10 01:02:37,955 root         INFO     Train Epoch: 81 [2560/8000 (32%)]\tTotal Loss: 0.201198\n",
      "Reconstruction: 0.200728, Regularization: 0.000470\n",
      "2019-04-10 01:02:38,019 root         INFO     Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 0.201415\n",
      "Reconstruction: 0.201049, Regularization: 0.000366\n",
      "2019-04-10 01:02:38,083 root         INFO     Train Epoch: 81 [3584/8000 (45%)]\tTotal Loss: 0.200265\n",
      "Reconstruction: 0.200049, Regularization: 0.000215\n",
      "2019-04-10 01:02:38,147 root         INFO     Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 0.205168\n",
      "Reconstruction: 0.204807, Regularization: 0.000362\n",
      "2019-04-10 01:02:38,211 root         INFO     Train Epoch: 81 [4608/8000 (58%)]\tTotal Loss: 0.198758\n",
      "Reconstruction: 0.198374, Regularization: 0.000384\n",
      "2019-04-10 01:02:38,275 root         INFO     Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 0.199917\n",
      "Reconstruction: 0.199435, Regularization: 0.000482\n",
      "2019-04-10 01:02:38,338 root         INFO     Train Epoch: 81 [5632/8000 (70%)]\tTotal Loss: 0.201487\n",
      "Reconstruction: 0.201229, Regularization: 0.000259\n",
      "2019-04-10 01:02:38,402 root         INFO     Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 0.204694\n",
      "Reconstruction: 0.204382, Regularization: 0.000312\n",
      "2019-04-10 01:02:38,466 root         INFO     Train Epoch: 81 [6656/8000 (83%)]\tTotal Loss: 0.201343\n",
      "Reconstruction: 0.201154, Regularization: 0.000189\n",
      "2019-04-10 01:02:38,530 root         INFO     Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 0.202137\n",
      "Reconstruction: 0.201964, Regularization: 0.000173\n",
      "2019-04-10 01:02:38,594 root         INFO     Train Epoch: 81 [7680/8000 (96%)]\tTotal Loss: 0.202519\n",
      "Reconstruction: 0.202197, Regularization: 0.000322\n",
      "2019-04-10 01:02:38,649 root         INFO     ====> Epoch: 81 Average loss: 0.2010\n",
      "2019-04-10 01:02:38,673 root         INFO     Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 0.196358\n",
      "Reconstruction: 0.196063, Regularization: 0.000296\n",
      "2019-04-10 01:02:38,737 root         INFO     Train Epoch: 82 [512/8000 (6%)]\tTotal Loss: 0.197540\n",
      "Reconstruction: 0.197038, Regularization: 0.000502\n",
      "2019-04-10 01:02:38,801 root         INFO     Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 0.200767\n",
      "Reconstruction: 0.200442, Regularization: 0.000325\n",
      "2019-04-10 01:02:38,865 root         INFO     Train Epoch: 82 [1536/8000 (19%)]\tTotal Loss: 0.197182\n",
      "Reconstruction: 0.196952, Regularization: 0.000230\n",
      "2019-04-10 01:02:38,929 root         INFO     Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 0.200230\n",
      "Reconstruction: 0.199947, Regularization: 0.000283\n",
      "2019-04-10 01:02:38,993 root         INFO     Train Epoch: 82 [2560/8000 (32%)]\tTotal Loss: 0.199946\n",
      "Reconstruction: 0.199633, Regularization: 0.000313\n",
      "2019-04-10 01:02:39,057 root         INFO     Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 0.202269\n",
      "Reconstruction: 0.202065, Regularization: 0.000205\n",
      "2019-04-10 01:02:39,121 root         INFO     Train Epoch: 82 [3584/8000 (45%)]\tTotal Loss: 0.194451\n",
      "Reconstruction: 0.194101, Regularization: 0.000349\n",
      "2019-04-10 01:02:39,185 root         INFO     Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 0.194079\n",
      "Reconstruction: 0.193660, Regularization: 0.000419\n",
      "2019-04-10 01:02:39,249 root         INFO     Train Epoch: 82 [4608/8000 (58%)]\tTotal Loss: 0.200570\n",
      "Reconstruction: 0.200148, Regularization: 0.000422\n",
      "2019-04-10 01:02:39,313 root         INFO     Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 0.206099\n",
      "Reconstruction: 0.205942, Regularization: 0.000156\n",
      "2019-04-10 01:02:39,377 root         INFO     Train Epoch: 82 [5632/8000 (70%)]\tTotal Loss: 0.197148\n",
      "Reconstruction: 0.196792, Regularization: 0.000356\n",
      "2019-04-10 01:02:39,440 root         INFO     Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 0.193955\n",
      "Reconstruction: 0.193742, Regularization: 0.000213\n",
      "2019-04-10 01:02:39,503 root         INFO     Train Epoch: 82 [6656/8000 (83%)]\tTotal Loss: 0.200757\n",
      "Reconstruction: 0.200395, Regularization: 0.000362\n",
      "2019-04-10 01:02:39,567 root         INFO     Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 0.195560\n",
      "Reconstruction: 0.195185, Regularization: 0.000376\n",
      "2019-04-10 01:02:39,631 root         INFO     Train Epoch: 82 [7680/8000 (96%)]\tTotal Loss: 0.195680\n",
      "Reconstruction: 0.195392, Regularization: 0.000288\n",
      "2019-04-10 01:02:39,685 root         INFO     ====> Epoch: 82 Average loss: 0.2000\n",
      "2019-04-10 01:02:39,709 root         INFO     Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 0.201618\n",
      "Reconstruction: 0.201422, Regularization: 0.000196\n",
      "2019-04-10 01:02:39,772 root         INFO     Train Epoch: 83 [512/8000 (6%)]\tTotal Loss: 0.196023\n",
      "Reconstruction: 0.195821, Regularization: 0.000202\n",
      "2019-04-10 01:02:39,836 root         INFO     Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 0.199399\n",
      "Reconstruction: 0.199080, Regularization: 0.000319\n",
      "2019-04-10 01:02:39,899 root         INFO     Train Epoch: 83 [1536/8000 (19%)]\tTotal Loss: 0.193918\n",
      "Reconstruction: 0.193632, Regularization: 0.000287\n",
      "2019-04-10 01:02:39,963 root         INFO     Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 0.193257\n",
      "Reconstruction: 0.192970, Regularization: 0.000286\n",
      "2019-04-10 01:02:40,027 root         INFO     Train Epoch: 83 [2560/8000 (32%)]\tTotal Loss: 0.195873\n",
      "Reconstruction: 0.195564, Regularization: 0.000308\n",
      "2019-04-10 01:02:40,091 root         INFO     Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 0.199254\n",
      "Reconstruction: 0.198929, Regularization: 0.000325\n",
      "2019-04-10 01:02:40,155 root         INFO     Train Epoch: 83 [3584/8000 (45%)]\tTotal Loss: 0.210218\n",
      "Reconstruction: 0.209878, Regularization: 0.000340\n",
      "2019-04-10 01:02:40,218 root         INFO     Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 0.198495\n",
      "Reconstruction: 0.198142, Regularization: 0.000353\n",
      "2019-04-10 01:02:40,281 root         INFO     Train Epoch: 83 [4608/8000 (58%)]\tTotal Loss: 0.197118\n",
      "Reconstruction: 0.196819, Regularization: 0.000299\n",
      "2019-04-10 01:02:40,344 root         INFO     Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 0.201197\n",
      "Reconstruction: 0.200975, Regularization: 0.000222\n",
      "2019-04-10 01:02:40,407 root         INFO     Train Epoch: 83 [5632/8000 (70%)]\tTotal Loss: 0.194219\n",
      "Reconstruction: 0.193906, Regularization: 0.000313\n",
      "2019-04-10 01:02:40,469 root         INFO     Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 0.198319\n",
      "Reconstruction: 0.198169, Regularization: 0.000150\n",
      "2019-04-10 01:02:40,532 root         INFO     Train Epoch: 83 [6656/8000 (83%)]\tTotal Loss: 0.200034\n",
      "Reconstruction: 0.199728, Regularization: 0.000307\n",
      "2019-04-10 01:02:40,595 root         INFO     Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 0.219785\n",
      "Reconstruction: 0.219465, Regularization: 0.000320\n",
      "2019-04-10 01:02:40,658 root         INFO     Train Epoch: 83 [7680/8000 (96%)]\tTotal Loss: 0.200378\n",
      "Reconstruction: 0.200176, Regularization: 0.000202\n",
      "2019-04-10 01:02:40,711 root         INFO     ====> Epoch: 83 Average loss: 0.1989\n",
      "2019-04-10 01:02:40,736 root         INFO     Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 0.202972\n",
      "Reconstruction: 0.202757, Regularization: 0.000214\n",
      "2019-04-10 01:02:40,800 root         INFO     Train Epoch: 84 [512/8000 (6%)]\tTotal Loss: 0.196571\n",
      "Reconstruction: 0.196264, Regularization: 0.000308\n",
      "2019-04-10 01:02:40,864 root         INFO     Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 0.194094\n",
      "Reconstruction: 0.193813, Regularization: 0.000282\n",
      "2019-04-10 01:02:40,928 root         INFO     Train Epoch: 84 [1536/8000 (19%)]\tTotal Loss: 0.198797\n",
      "Reconstruction: 0.198345, Regularization: 0.000452\n",
      "2019-04-10 01:02:40,991 root         INFO     Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 0.197791\n",
      "Reconstruction: 0.197474, Regularization: 0.000317\n",
      "2019-04-10 01:02:41,055 root         INFO     Train Epoch: 84 [2560/8000 (32%)]\tTotal Loss: 0.194686\n",
      "Reconstruction: 0.194347, Regularization: 0.000339\n",
      "2019-04-10 01:02:41,119 root         INFO     Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 0.194317\n",
      "Reconstruction: 0.193948, Regularization: 0.000369\n",
      "2019-04-10 01:02:41,183 root         INFO     Train Epoch: 84 [3584/8000 (45%)]\tTotal Loss: 0.201969\n",
      "Reconstruction: 0.201567, Regularization: 0.000402\n",
      "2019-04-10 01:02:41,247 root         INFO     Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 0.201778\n",
      "Reconstruction: 0.201519, Regularization: 0.000259\n",
      "2019-04-10 01:02:41,311 root         INFO     Train Epoch: 84 [4608/8000 (58%)]\tTotal Loss: 0.193665\n",
      "Reconstruction: 0.193456, Regularization: 0.000209\n",
      "2019-04-10 01:02:41,375 root         INFO     Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 0.204198\n",
      "Reconstruction: 0.203715, Regularization: 0.000483\n",
      "2019-04-10 01:02:41,440 root         INFO     Train Epoch: 84 [5632/8000 (70%)]\tTotal Loss: 0.192239\n",
      "Reconstruction: 0.192003, Regularization: 0.000236\n",
      "2019-04-10 01:02:41,503 root         INFO     Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 0.195013\n",
      "Reconstruction: 0.194713, Regularization: 0.000300\n",
      "2019-04-10 01:02:41,567 root         INFO     Train Epoch: 84 [6656/8000 (83%)]\tTotal Loss: 0.191442\n",
      "Reconstruction: 0.191064, Regularization: 0.000378\n",
      "2019-04-10 01:02:41,631 root         INFO     Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 0.197087\n",
      "Reconstruction: 0.196797, Regularization: 0.000290\n",
      "2019-04-10 01:02:41,695 root         INFO     Train Epoch: 84 [7680/8000 (96%)]\tTotal Loss: 0.194811\n",
      "Reconstruction: 0.194637, Regularization: 0.000174\n",
      "2019-04-10 01:02:41,749 root         INFO     ====> Epoch: 84 Average loss: 0.1977\n",
      "2019-04-10 01:02:41,773 root         INFO     Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 0.193323\n",
      "Reconstruction: 0.193083, Regularization: 0.000240\n",
      "2019-04-10 01:02:41,837 root         INFO     Train Epoch: 85 [512/8000 (6%)]\tTotal Loss: 0.198617\n",
      "Reconstruction: 0.198252, Regularization: 0.000364\n",
      "2019-04-10 01:02:41,901 root         INFO     Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 0.201597\n",
      "Reconstruction: 0.201053, Regularization: 0.000544\n",
      "2019-04-10 01:02:41,964 root         INFO     Train Epoch: 85 [1536/8000 (19%)]\tTotal Loss: 0.198444\n",
      "Reconstruction: 0.198005, Regularization: 0.000439\n",
      "2019-04-10 01:02:42,026 root         INFO     Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 0.194167\n",
      "Reconstruction: 0.193888, Regularization: 0.000279\n",
      "2019-04-10 01:02:42,090 root         INFO     Train Epoch: 85 [2560/8000 (32%)]\tTotal Loss: 0.195816\n",
      "Reconstruction: 0.195539, Regularization: 0.000277\n",
      "2019-04-10 01:02:42,153 root         INFO     Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 0.192525\n",
      "Reconstruction: 0.192295, Regularization: 0.000230\n",
      "2019-04-10 01:02:42,216 root         INFO     Train Epoch: 85 [3584/8000 (45%)]\tTotal Loss: 0.197863\n",
      "Reconstruction: 0.197635, Regularization: 0.000228\n",
      "2019-04-10 01:02:42,279 root         INFO     Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 0.196047\n",
      "Reconstruction: 0.195747, Regularization: 0.000300\n",
      "2019-04-10 01:02:42,343 root         INFO     Train Epoch: 85 [4608/8000 (58%)]\tTotal Loss: 0.195861\n",
      "Reconstruction: 0.195637, Regularization: 0.000224\n",
      "2019-04-10 01:02:42,405 root         INFO     Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 0.193133\n",
      "Reconstruction: 0.192758, Regularization: 0.000375\n",
      "2019-04-10 01:02:42,469 root         INFO     Train Epoch: 85 [5632/8000 (70%)]\tTotal Loss: 0.202139\n",
      "Reconstruction: 0.201719, Regularization: 0.000420\n",
      "2019-04-10 01:02:42,532 root         INFO     Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 0.193676\n",
      "Reconstruction: 0.193446, Regularization: 0.000229\n",
      "2019-04-10 01:02:42,595 root         INFO     Train Epoch: 85 [6656/8000 (83%)]\tTotal Loss: 0.191938\n",
      "Reconstruction: 0.191543, Regularization: 0.000395\n",
      "2019-04-10 01:02:42,659 root         INFO     Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 0.191429\n",
      "Reconstruction: 0.191073, Regularization: 0.000356\n",
      "2019-04-10 01:02:42,722 root         INFO     Train Epoch: 85 [7680/8000 (96%)]\tTotal Loss: 0.200737\n",
      "Reconstruction: 0.200305, Regularization: 0.000432\n",
      "2019-04-10 01:02:42,776 root         INFO     ====> Epoch: 85 Average loss: 0.1963\n",
      "2019-04-10 01:02:42,799 root         INFO     Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 0.196218\n",
      "Reconstruction: 0.195955, Regularization: 0.000263\n",
      "2019-04-10 01:02:42,864 root         INFO     Train Epoch: 86 [512/8000 (6%)]\tTotal Loss: 0.194683\n",
      "Reconstruction: 0.194384, Regularization: 0.000299\n",
      "2019-04-10 01:02:42,927 root         INFO     Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 0.199677\n",
      "Reconstruction: 0.199197, Regularization: 0.000480\n",
      "2019-04-10 01:02:42,991 root         INFO     Train Epoch: 86 [1536/8000 (19%)]\tTotal Loss: 0.198688\n",
      "Reconstruction: 0.198426, Regularization: 0.000263\n",
      "2019-04-10 01:02:43,055 root         INFO     Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 0.190601\n",
      "Reconstruction: 0.190380, Regularization: 0.000221\n",
      "2019-04-10 01:02:43,118 root         INFO     Train Epoch: 86 [2560/8000 (32%)]\tTotal Loss: 0.190066\n",
      "Reconstruction: 0.189774, Regularization: 0.000291\n",
      "2019-04-10 01:02:43,182 root         INFO     Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 0.196344\n",
      "Reconstruction: 0.196120, Regularization: 0.000224\n",
      "2019-04-10 01:02:43,246 root         INFO     Train Epoch: 86 [3584/8000 (45%)]\tTotal Loss: 0.200458\n",
      "Reconstruction: 0.200087, Regularization: 0.000371\n",
      "2019-04-10 01:02:43,310 root         INFO     Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 0.193911\n",
      "Reconstruction: 0.193657, Regularization: 0.000253\n",
      "2019-04-10 01:02:43,374 root         INFO     Train Epoch: 86 [4608/8000 (58%)]\tTotal Loss: 0.191953\n",
      "Reconstruction: 0.191772, Regularization: 0.000181\n",
      "2019-04-10 01:02:43,438 root         INFO     Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 0.193872\n",
      "Reconstruction: 0.193572, Regularization: 0.000300\n",
      "2019-04-10 01:02:43,502 root         INFO     Train Epoch: 86 [5632/8000 (70%)]\tTotal Loss: 0.194198\n",
      "Reconstruction: 0.193776, Regularization: 0.000422\n",
      "2019-04-10 01:02:43,566 root         INFO     Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 0.194602\n",
      "Reconstruction: 0.194333, Regularization: 0.000268\n",
      "2019-04-10 01:02:43,630 root         INFO     Train Epoch: 86 [6656/8000 (83%)]\tTotal Loss: 0.201498\n",
      "Reconstruction: 0.201179, Regularization: 0.000319\n",
      "2019-04-10 01:02:43,693 root         INFO     Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 0.191770\n",
      "Reconstruction: 0.191412, Regularization: 0.000359\n",
      "2019-04-10 01:02:43,757 root         INFO     Train Epoch: 86 [7680/8000 (96%)]\tTotal Loss: 0.197587\n",
      "Reconstruction: 0.197278, Regularization: 0.000309\n",
      "2019-04-10 01:02:43,811 root         INFO     ====> Epoch: 86 Average loss: 0.1947\n",
      "2019-04-10 01:02:43,835 root         INFO     Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 0.189630\n",
      "Reconstruction: 0.189356, Regularization: 0.000274\n",
      "2019-04-10 01:02:43,899 root         INFO     Train Epoch: 87 [512/8000 (6%)]\tTotal Loss: 0.189336\n",
      "Reconstruction: 0.189092, Regularization: 0.000244\n",
      "2019-04-10 01:02:43,961 root         INFO     Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 0.191056\n",
      "Reconstruction: 0.190777, Regularization: 0.000278\n",
      "2019-04-10 01:02:44,024 root         INFO     Train Epoch: 87 [1536/8000 (19%)]\tTotal Loss: 0.190836\n",
      "Reconstruction: 0.190514, Regularization: 0.000322\n",
      "2019-04-10 01:02:44,089 root         INFO     Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 0.203017\n",
      "Reconstruction: 0.202733, Regularization: 0.000284\n",
      "2019-04-10 01:02:44,152 root         INFO     Train Epoch: 87 [2560/8000 (32%)]\tTotal Loss: 0.190301\n",
      "Reconstruction: 0.190073, Regularization: 0.000227\n",
      "2019-04-10 01:02:44,216 root         INFO     Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 0.188560\n",
      "Reconstruction: 0.188258, Regularization: 0.000301\n",
      "2019-04-10 01:02:44,279 root         INFO     Train Epoch: 87 [3584/8000 (45%)]\tTotal Loss: 0.195476\n",
      "Reconstruction: 0.195207, Regularization: 0.000269\n",
      "2019-04-10 01:02:44,342 root         INFO     Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 0.194198\n",
      "Reconstruction: 0.193936, Regularization: 0.000262\n",
      "2019-04-10 01:02:44,405 root         INFO     Train Epoch: 87 [4608/8000 (58%)]\tTotal Loss: 0.193462\n",
      "Reconstruction: 0.193158, Regularization: 0.000303\n",
      "2019-04-10 01:02:44,467 root         INFO     Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 0.189002\n",
      "Reconstruction: 0.188781, Regularization: 0.000221\n",
      "2019-04-10 01:02:44,530 root         INFO     Train Epoch: 87 [5632/8000 (70%)]\tTotal Loss: 0.190186\n",
      "Reconstruction: 0.189897, Regularization: 0.000289\n",
      "2019-04-10 01:02:44,593 root         INFO     Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 0.191673\n",
      "Reconstruction: 0.191296, Regularization: 0.000377\n",
      "2019-04-10 01:02:44,656 root         INFO     Train Epoch: 87 [6656/8000 (83%)]\tTotal Loss: 0.186802\n",
      "Reconstruction: 0.186589, Regularization: 0.000213\n",
      "2019-04-10 01:02:44,719 root         INFO     Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 0.192040\n",
      "Reconstruction: 0.191735, Regularization: 0.000305\n",
      "2019-04-10 01:02:44,782 root         INFO     Train Epoch: 87 [7680/8000 (96%)]\tTotal Loss: 0.191628\n",
      "Reconstruction: 0.191425, Regularization: 0.000203\n",
      "2019-04-10 01:02:44,836 root         INFO     ====> Epoch: 87 Average loss: 0.1929\n",
      "2019-04-10 01:02:44,859 root         INFO     Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 0.193594\n",
      "Reconstruction: 0.193352, Regularization: 0.000241\n",
      "2019-04-10 01:02:44,924 root         INFO     Train Epoch: 88 [512/8000 (6%)]\tTotal Loss: 0.189647\n",
      "Reconstruction: 0.189270, Regularization: 0.000377\n",
      "2019-04-10 01:02:44,987 root         INFO     Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 0.184571\n",
      "Reconstruction: 0.184300, Regularization: 0.000271\n",
      "2019-04-10 01:02:45,051 root         INFO     Train Epoch: 88 [1536/8000 (19%)]\tTotal Loss: 0.197885\n",
      "Reconstruction: 0.197589, Regularization: 0.000296\n",
      "2019-04-10 01:02:45,115 root         INFO     Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 0.187926\n",
      "Reconstruction: 0.187762, Regularization: 0.000164\n",
      "2019-04-10 01:02:45,179 root         INFO     Train Epoch: 88 [2560/8000 (32%)]\tTotal Loss: 0.185160\n",
      "Reconstruction: 0.184817, Regularization: 0.000343\n",
      "2019-04-10 01:02:45,243 root         INFO     Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 0.186863\n",
      "Reconstruction: 0.186659, Regularization: 0.000204\n",
      "2019-04-10 01:02:45,307 root         INFO     Train Epoch: 88 [3584/8000 (45%)]\tTotal Loss: 0.188358\n",
      "Reconstruction: 0.188189, Regularization: 0.000169\n",
      "2019-04-10 01:02:45,371 root         INFO     Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 0.206218\n",
      "Reconstruction: 0.205844, Regularization: 0.000374\n",
      "2019-04-10 01:02:45,435 root         INFO     Train Epoch: 88 [4608/8000 (58%)]\tTotal Loss: 0.186161\n",
      "Reconstruction: 0.185974, Regularization: 0.000187\n",
      "2019-04-10 01:02:45,499 root         INFO     Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 0.189091\n",
      "Reconstruction: 0.188848, Regularization: 0.000243\n",
      "2019-04-10 01:02:45,563 root         INFO     Train Epoch: 88 [5632/8000 (70%)]\tTotal Loss: 0.192056\n",
      "Reconstruction: 0.191679, Regularization: 0.000377\n",
      "2019-04-10 01:02:45,626 root         INFO     Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 0.189445\n",
      "Reconstruction: 0.189249, Regularization: 0.000195\n",
      "2019-04-10 01:02:45,689 root         INFO     Train Epoch: 88 [6656/8000 (83%)]\tTotal Loss: 0.187058\n",
      "Reconstruction: 0.186856, Regularization: 0.000202\n",
      "2019-04-10 01:02:45,751 root         INFO     Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 0.187409\n",
      "Reconstruction: 0.187120, Regularization: 0.000289\n",
      "2019-04-10 01:02:45,815 root         INFO     Train Epoch: 88 [7680/8000 (96%)]\tTotal Loss: 0.191292\n",
      "Reconstruction: 0.190968, Regularization: 0.000323\n",
      "2019-04-10 01:02:45,868 root         INFO     ====> Epoch: 88 Average loss: 0.1908\n",
      "2019-04-10 01:02:45,892 root         INFO     Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 0.183726\n",
      "Reconstruction: 0.183383, Regularization: 0.000343\n",
      "2019-04-10 01:02:45,955 root         INFO     Train Epoch: 89 [512/8000 (6%)]\tTotal Loss: 0.201801\n",
      "Reconstruction: 0.201356, Regularization: 0.000445\n",
      "2019-04-10 01:02:46,017 root         INFO     Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 0.189718\n",
      "Reconstruction: 0.189475, Regularization: 0.000243\n",
      "2019-04-10 01:02:46,080 root         INFO     Train Epoch: 89 [1536/8000 (19%)]\tTotal Loss: 0.195939\n",
      "Reconstruction: 0.195656, Regularization: 0.000283\n",
      "2019-04-10 01:02:46,144 root         INFO     Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 0.188067\n",
      "Reconstruction: 0.187687, Regularization: 0.000380\n",
      "2019-04-10 01:02:46,206 root         INFO     Train Epoch: 89 [2560/8000 (32%)]\tTotal Loss: 0.186867\n",
      "Reconstruction: 0.186536, Regularization: 0.000330\n",
      "2019-04-10 01:02:46,270 root         INFO     Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 0.194614\n",
      "Reconstruction: 0.194283, Regularization: 0.000331\n",
      "2019-04-10 01:02:46,333 root         INFO     Train Epoch: 89 [3584/8000 (45%)]\tTotal Loss: 0.191084\n",
      "Reconstruction: 0.190795, Regularization: 0.000289\n",
      "2019-04-10 01:02:46,396 root         INFO     Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 0.187922\n",
      "Reconstruction: 0.187643, Regularization: 0.000279\n",
      "2019-04-10 01:02:46,459 root         INFO     Train Epoch: 89 [4608/8000 (58%)]\tTotal Loss: 0.186194\n",
      "Reconstruction: 0.185889, Regularization: 0.000305\n",
      "2019-04-10 01:02:46,522 root         INFO     Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 0.184587\n",
      "Reconstruction: 0.184280, Regularization: 0.000306\n",
      "2019-04-10 01:02:46,586 root         INFO     Train Epoch: 89 [5632/8000 (70%)]\tTotal Loss: 0.184310\n",
      "Reconstruction: 0.184049, Regularization: 0.000261\n",
      "2019-04-10 01:02:46,649 root         INFO     Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 0.196010\n",
      "Reconstruction: 0.195731, Regularization: 0.000280\n",
      "2019-04-10 01:02:46,713 root         INFO     Train Epoch: 89 [6656/8000 (83%)]\tTotal Loss: 0.183605\n",
      "Reconstruction: 0.183425, Regularization: 0.000180\n",
      "2019-04-10 01:02:46,775 root         INFO     Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 0.190443\n",
      "Reconstruction: 0.190222, Regularization: 0.000221\n",
      "2019-04-10 01:02:46,838 root         INFO     Train Epoch: 89 [7680/8000 (96%)]\tTotal Loss: 0.182111\n",
      "Reconstruction: 0.181787, Regularization: 0.000323\n",
      "2019-04-10 01:02:46,892 root         INFO     ====> Epoch: 89 Average loss: 0.1884\n",
      "2019-04-10 01:02:46,916 root         INFO     Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 0.185905\n",
      "Reconstruction: 0.185628, Regularization: 0.000277\n",
      "2019-04-10 01:02:46,979 root         INFO     Train Epoch: 90 [512/8000 (6%)]\tTotal Loss: 0.184226\n",
      "Reconstruction: 0.183834, Regularization: 0.000391\n",
      "2019-04-10 01:02:47,042 root         INFO     Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 0.186843\n",
      "Reconstruction: 0.186584, Regularization: 0.000259\n",
      "2019-04-10 01:02:47,105 root         INFO     Train Epoch: 90 [1536/8000 (19%)]\tTotal Loss: 0.188393\n",
      "Reconstruction: 0.188114, Regularization: 0.000279\n",
      "2019-04-10 01:02:47,167 root         INFO     Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 0.183622\n",
      "Reconstruction: 0.183317, Regularization: 0.000305\n",
      "2019-04-10 01:02:47,229 root         INFO     Train Epoch: 90 [2560/8000 (32%)]\tTotal Loss: 0.184437\n",
      "Reconstruction: 0.184216, Regularization: 0.000220\n",
      "2019-04-10 01:02:47,291 root         INFO     Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 0.192269\n",
      "Reconstruction: 0.191749, Regularization: 0.000520\n",
      "2019-04-10 01:02:47,353 root         INFO     Train Epoch: 90 [3584/8000 (45%)]\tTotal Loss: 0.181997\n",
      "Reconstruction: 0.181679, Regularization: 0.000318\n",
      "2019-04-10 01:02:47,414 root         INFO     Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 0.185504\n",
      "Reconstruction: 0.185056, Regularization: 0.000448\n",
      "2019-04-10 01:02:47,476 root         INFO     Train Epoch: 90 [4608/8000 (58%)]\tTotal Loss: 0.180128\n",
      "Reconstruction: 0.179918, Regularization: 0.000209\n",
      "2019-04-10 01:02:47,537 root         INFO     Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 0.187871\n",
      "Reconstruction: 0.187629, Regularization: 0.000242\n",
      "2019-04-10 01:02:47,599 root         INFO     Train Epoch: 90 [5632/8000 (70%)]\tTotal Loss: 0.190242\n",
      "Reconstruction: 0.189812, Regularization: 0.000429\n",
      "2019-04-10 01:02:47,660 root         INFO     Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 0.181702\n",
      "Reconstruction: 0.181386, Regularization: 0.000316\n",
      "2019-04-10 01:02:47,721 root         INFO     Train Epoch: 90 [6656/8000 (83%)]\tTotal Loss: 0.187765\n",
      "Reconstruction: 0.187536, Regularization: 0.000229\n",
      "2019-04-10 01:02:47,783 root         INFO     Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 0.177590\n",
      "Reconstruction: 0.177355, Regularization: 0.000235\n",
      "2019-04-10 01:02:47,844 root         INFO     Train Epoch: 90 [7680/8000 (96%)]\tTotal Loss: 0.178892\n",
      "Reconstruction: 0.178629, Regularization: 0.000262\n",
      "2019-04-10 01:02:47,898 root         INFO     ====> Epoch: 90 Average loss: 0.1855\n",
      "2019-04-10 01:02:47,922 root         INFO     Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 0.182066\n",
      "Reconstruction: 0.181926, Regularization: 0.000141\n",
      "2019-04-10 01:02:47,985 root         INFO     Train Epoch: 91 [512/8000 (6%)]\tTotal Loss: 0.184897\n",
      "Reconstruction: 0.184628, Regularization: 0.000269\n",
      "2019-04-10 01:02:48,047 root         INFO     Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 0.184103\n",
      "Reconstruction: 0.183834, Regularization: 0.000268\n",
      "2019-04-10 01:02:48,110 root         INFO     Train Epoch: 91 [1536/8000 (19%)]\tTotal Loss: 0.181509\n",
      "Reconstruction: 0.181175, Regularization: 0.000334\n",
      "2019-04-10 01:02:48,173 root         INFO     Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 0.180746\n",
      "Reconstruction: 0.180488, Regularization: 0.000258\n",
      "2019-04-10 01:02:48,235 root         INFO     Train Epoch: 91 [2560/8000 (32%)]\tTotal Loss: 0.182127\n",
      "Reconstruction: 0.181829, Regularization: 0.000298\n",
      "2019-04-10 01:02:48,298 root         INFO     Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 0.180164\n",
      "Reconstruction: 0.179859, Regularization: 0.000305\n",
      "2019-04-10 01:02:48,361 root         INFO     Train Epoch: 91 [3584/8000 (45%)]\tTotal Loss: 0.176677\n",
      "Reconstruction: 0.176477, Regularization: 0.000199\n",
      "2019-04-10 01:02:48,423 root         INFO     Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 0.174394\n",
      "Reconstruction: 0.174177, Regularization: 0.000216\n",
      "2019-04-10 01:02:48,486 root         INFO     Train Epoch: 91 [4608/8000 (58%)]\tTotal Loss: 0.181177\n",
      "Reconstruction: 0.180834, Regularization: 0.000343\n",
      "2019-04-10 01:02:48,549 root         INFO     Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 0.183703\n",
      "Reconstruction: 0.183315, Regularization: 0.000387\n",
      "2019-04-10 01:02:48,612 root         INFO     Train Epoch: 91 [5632/8000 (70%)]\tTotal Loss: 0.178511\n",
      "Reconstruction: 0.178279, Regularization: 0.000232\n",
      "2019-04-10 01:02:48,675 root         INFO     Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 0.181041\n",
      "Reconstruction: 0.180697, Regularization: 0.000344\n",
      "2019-04-10 01:02:48,737 root         INFO     Train Epoch: 91 [6656/8000 (83%)]\tTotal Loss: 0.179103\n",
      "Reconstruction: 0.178754, Regularization: 0.000349\n",
      "2019-04-10 01:02:48,800 root         INFO     Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 0.175393\n",
      "Reconstruction: 0.175233, Regularization: 0.000160\n",
      "2019-04-10 01:02:48,862 root         INFO     Train Epoch: 91 [7680/8000 (96%)]\tTotal Loss: 0.185090\n",
      "Reconstruction: 0.184874, Regularization: 0.000216\n",
      "2019-04-10 01:02:48,916 root         INFO     ====> Epoch: 91 Average loss: 0.1821\n",
      "2019-04-10 01:02:48,940 root         INFO     Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 0.179154\n",
      "Reconstruction: 0.178779, Regularization: 0.000375\n",
      "2019-04-10 01:02:49,003 root         INFO     Train Epoch: 92 [512/8000 (6%)]\tTotal Loss: 0.170994\n",
      "Reconstruction: 0.170660, Regularization: 0.000334\n",
      "2019-04-10 01:02:49,067 root         INFO     Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 0.174009\n",
      "Reconstruction: 0.173686, Regularization: 0.000323\n",
      "2019-04-10 01:02:49,130 root         INFO     Train Epoch: 92 [1536/8000 (19%)]\tTotal Loss: 0.183785\n",
      "Reconstruction: 0.183421, Regularization: 0.000364\n",
      "2019-04-10 01:02:49,193 root         INFO     Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 0.178085\n",
      "Reconstruction: 0.177732, Regularization: 0.000353\n",
      "2019-04-10 01:02:49,256 root         INFO     Train Epoch: 92 [2560/8000 (32%)]\tTotal Loss: 0.178674\n",
      "Reconstruction: 0.178421, Regularization: 0.000253\n",
      "2019-04-10 01:02:49,320 root         INFO     Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 0.175923\n",
      "Reconstruction: 0.175718, Regularization: 0.000205\n",
      "2019-04-10 01:02:49,383 root         INFO     Train Epoch: 92 [3584/8000 (45%)]\tTotal Loss: 0.172950\n",
      "Reconstruction: 0.172688, Regularization: 0.000262\n",
      "2019-04-10 01:02:49,446 root         INFO     Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 0.179665\n",
      "Reconstruction: 0.179338, Regularization: 0.000327\n",
      "2019-04-10 01:02:49,510 root         INFO     Train Epoch: 92 [4608/8000 (58%)]\tTotal Loss: 0.182245\n",
      "Reconstruction: 0.181988, Regularization: 0.000257\n",
      "2019-04-10 01:02:49,573 root         INFO     Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 0.181032\n",
      "Reconstruction: 0.180659, Regularization: 0.000372\n",
      "2019-04-10 01:02:49,636 root         INFO     Train Epoch: 92 [5632/8000 (70%)]\tTotal Loss: 0.174527\n",
      "Reconstruction: 0.174293, Regularization: 0.000234\n",
      "2019-04-10 01:02:49,699 root         INFO     Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 0.182356\n",
      "Reconstruction: 0.181907, Regularization: 0.000449\n",
      "2019-04-10 01:02:49,762 root         INFO     Train Epoch: 92 [6656/8000 (83%)]\tTotal Loss: 0.185451\n",
      "Reconstruction: 0.185093, Regularization: 0.000358\n",
      "2019-04-10 01:02:49,826 root         INFO     Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 0.169329\n",
      "Reconstruction: 0.169135, Regularization: 0.000194\n",
      "2019-04-10 01:02:49,889 root         INFO     Train Epoch: 92 [7680/8000 (96%)]\tTotal Loss: 0.192107\n",
      "Reconstruction: 0.191708, Regularization: 0.000400\n",
      "2019-04-10 01:02:49,943 root         INFO     ====> Epoch: 92 Average loss: 0.1783\n",
      "2019-04-10 01:02:49,967 root         INFO     Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 0.178166\n",
      "Reconstruction: 0.177825, Regularization: 0.000342\n",
      "2019-04-10 01:02:50,031 root         INFO     Train Epoch: 93 [512/8000 (6%)]\tTotal Loss: 0.170501\n",
      "Reconstruction: 0.170159, Regularization: 0.000342\n",
      "2019-04-10 01:02:50,095 root         INFO     Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 0.174025\n",
      "Reconstruction: 0.173733, Regularization: 0.000292\n",
      "2019-04-10 01:02:50,159 root         INFO     Train Epoch: 93 [1536/8000 (19%)]\tTotal Loss: 0.170203\n",
      "Reconstruction: 0.169886, Regularization: 0.000317\n",
      "2019-04-10 01:02:50,222 root         INFO     Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 0.179451\n",
      "Reconstruction: 0.179085, Regularization: 0.000366\n",
      "2019-04-10 01:02:50,286 root         INFO     Train Epoch: 93 [2560/8000 (32%)]\tTotal Loss: 0.180834\n",
      "Reconstruction: 0.180547, Regularization: 0.000287\n",
      "2019-04-10 01:02:50,350 root         INFO     Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 0.168139\n",
      "Reconstruction: 0.167880, Regularization: 0.000259\n",
      "2019-04-10 01:02:50,414 root         INFO     Train Epoch: 93 [3584/8000 (45%)]\tTotal Loss: 0.172997\n",
      "Reconstruction: 0.172664, Regularization: 0.000333\n",
      "2019-04-10 01:02:50,478 root         INFO     Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 0.172035\n",
      "Reconstruction: 0.171689, Regularization: 0.000345\n",
      "2019-04-10 01:02:50,542 root         INFO     Train Epoch: 93 [4608/8000 (58%)]\tTotal Loss: 0.182384\n",
      "Reconstruction: 0.182066, Regularization: 0.000318\n",
      "2019-04-10 01:02:50,606 root         INFO     Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 0.173383\n",
      "Reconstruction: 0.173111, Regularization: 0.000273\n",
      "2019-04-10 01:02:50,670 root         INFO     Train Epoch: 93 [5632/8000 (70%)]\tTotal Loss: 0.180760\n",
      "Reconstruction: 0.180350, Regularization: 0.000410\n",
      "2019-04-10 01:02:50,733 root         INFO     Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 0.163541\n",
      "Reconstruction: 0.163191, Regularization: 0.000350\n",
      "2019-04-10 01:02:50,797 root         INFO     Train Epoch: 93 [6656/8000 (83%)]\tTotal Loss: 0.175864\n",
      "Reconstruction: 0.175445, Regularization: 0.000419\n",
      "2019-04-10 01:02:50,861 root         INFO     Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 0.162951\n",
      "Reconstruction: 0.162727, Regularization: 0.000224\n",
      "2019-04-10 01:02:50,924 root         INFO     Train Epoch: 93 [7680/8000 (96%)]\tTotal Loss: 0.166102\n",
      "Reconstruction: 0.165808, Regularization: 0.000294\n",
      "2019-04-10 01:02:50,978 root         INFO     ====> Epoch: 93 Average loss: 0.1743\n",
      "2019-04-10 01:02:51,002 root         INFO     Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 0.170259\n",
      "Reconstruction: 0.170008, Regularization: 0.000251\n",
      "2019-04-10 01:02:51,065 root         INFO     Train Epoch: 94 [512/8000 (6%)]\tTotal Loss: 0.168029\n",
      "Reconstruction: 0.167679, Regularization: 0.000351\n",
      "2019-04-10 01:02:51,128 root         INFO     Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 0.181436\n",
      "Reconstruction: 0.180840, Regularization: 0.000596\n",
      "2019-04-10 01:02:51,192 root         INFO     Train Epoch: 94 [1536/8000 (19%)]\tTotal Loss: 0.169029\n",
      "Reconstruction: 0.168696, Regularization: 0.000333\n",
      "2019-04-10 01:02:51,254 root         INFO     Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 0.183309\n",
      "Reconstruction: 0.182978, Regularization: 0.000331\n",
      "2019-04-10 01:02:51,318 root         INFO     Train Epoch: 94 [2560/8000 (32%)]\tTotal Loss: 0.178228\n",
      "Reconstruction: 0.177768, Regularization: 0.000460\n",
      "2019-04-10 01:02:51,380 root         INFO     Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 0.172008\n",
      "Reconstruction: 0.171652, Regularization: 0.000356\n",
      "2019-04-10 01:02:51,443 root         INFO     Train Epoch: 94 [3584/8000 (45%)]\tTotal Loss: 0.172834\n",
      "Reconstruction: 0.172458, Regularization: 0.000376\n",
      "2019-04-10 01:02:51,506 root         INFO     Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 0.159547\n",
      "Reconstruction: 0.159295, Regularization: 0.000251\n",
      "2019-04-10 01:02:51,570 root         INFO     Train Epoch: 94 [4608/8000 (58%)]\tTotal Loss: 0.176954\n",
      "Reconstruction: 0.176512, Regularization: 0.000441\n",
      "2019-04-10 01:02:51,633 root         INFO     Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 0.165769\n",
      "Reconstruction: 0.165385, Regularization: 0.000384\n",
      "2019-04-10 01:02:51,695 root         INFO     Train Epoch: 94 [5632/8000 (70%)]\tTotal Loss: 0.161802\n",
      "Reconstruction: 0.161444, Regularization: 0.000359\n",
      "2019-04-10 01:02:51,758 root         INFO     Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 0.174507\n",
      "Reconstruction: 0.174116, Regularization: 0.000391\n",
      "2019-04-10 01:02:51,821 root         INFO     Train Epoch: 94 [6656/8000 (83%)]\tTotal Loss: 0.169669\n",
      "Reconstruction: 0.169309, Regularization: 0.000360\n",
      "2019-04-10 01:02:51,884 root         INFO     Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 0.177440\n",
      "Reconstruction: 0.177088, Regularization: 0.000352\n",
      "2019-04-10 01:02:51,947 root         INFO     Train Epoch: 94 [7680/8000 (96%)]\tTotal Loss: 0.180378\n",
      "Reconstruction: 0.179818, Regularization: 0.000559\n",
      "2019-04-10 01:02:52,001 root         INFO     ====> Epoch: 94 Average loss: 0.1707\n",
      "2019-04-10 01:02:52,025 root         INFO     Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 0.168910\n",
      "Reconstruction: 0.168617, Regularization: 0.000293\n",
      "2019-04-10 01:02:52,088 root         INFO     Train Epoch: 95 [512/8000 (6%)]\tTotal Loss: 0.171733\n",
      "Reconstruction: 0.171393, Regularization: 0.000340\n",
      "2019-04-10 01:02:52,152 root         INFO     Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 0.172661\n",
      "Reconstruction: 0.172104, Regularization: 0.000556\n",
      "2019-04-10 01:02:52,215 root         INFO     Train Epoch: 95 [1536/8000 (19%)]\tTotal Loss: 0.174690\n",
      "Reconstruction: 0.174326, Regularization: 0.000364\n",
      "2019-04-10 01:02:52,278 root         INFO     Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 0.155242\n",
      "Reconstruction: 0.155025, Regularization: 0.000218\n",
      "2019-04-10 01:02:52,342 root         INFO     Train Epoch: 95 [2560/8000 (32%)]\tTotal Loss: 0.174956\n",
      "Reconstruction: 0.174585, Regularization: 0.000371\n",
      "2019-04-10 01:02:52,405 root         INFO     Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 0.159322\n",
      "Reconstruction: 0.159067, Regularization: 0.000254\n",
      "2019-04-10 01:02:52,469 root         INFO     Train Epoch: 95 [3584/8000 (45%)]\tTotal Loss: 0.172349\n",
      "Reconstruction: 0.171955, Regularization: 0.000395\n",
      "2019-04-10 01:02:52,533 root         INFO     Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 0.168479\n",
      "Reconstruction: 0.168052, Regularization: 0.000427\n",
      "2019-04-10 01:02:52,597 root         INFO     Train Epoch: 95 [4608/8000 (58%)]\tTotal Loss: 0.182011\n",
      "Reconstruction: 0.181569, Regularization: 0.000442\n",
      "2019-04-10 01:02:52,660 root         INFO     Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 0.158721\n",
      "Reconstruction: 0.158440, Regularization: 0.000281\n",
      "2019-04-10 01:02:52,723 root         INFO     Train Epoch: 95 [5632/8000 (70%)]\tTotal Loss: 0.161296\n",
      "Reconstruction: 0.161026, Regularization: 0.000270\n",
      "2019-04-10 01:02:52,786 root         INFO     Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 0.170610\n",
      "Reconstruction: 0.170212, Regularization: 0.000398\n",
      "2019-04-10 01:02:52,849 root         INFO     Train Epoch: 95 [6656/8000 (83%)]\tTotal Loss: 0.173195\n",
      "Reconstruction: 0.172709, Regularization: 0.000486\n",
      "2019-04-10 01:02:52,913 root         INFO     Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 0.161405\n",
      "Reconstruction: 0.161094, Regularization: 0.000311\n",
      "2019-04-10 01:02:52,977 root         INFO     Train Epoch: 95 [7680/8000 (96%)]\tTotal Loss: 0.170163\n",
      "Reconstruction: 0.169677, Regularization: 0.000486\n",
      "2019-04-10 01:02:53,030 root         INFO     ====> Epoch: 95 Average loss: 0.1681\n",
      "2019-04-10 01:02:53,054 root         INFO     Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 0.160402\n",
      "Reconstruction: 0.160139, Regularization: 0.000263\n",
      "2019-04-10 01:02:53,119 root         INFO     Train Epoch: 96 [512/8000 (6%)]\tTotal Loss: 0.169825\n",
      "Reconstruction: 0.169413, Regularization: 0.000412\n",
      "2019-04-10 01:02:53,182 root         INFO     Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 0.161632\n",
      "Reconstruction: 0.161392, Regularization: 0.000240\n",
      "2019-04-10 01:02:53,244 root         INFO     Train Epoch: 96 [1536/8000 (19%)]\tTotal Loss: 0.170123\n",
      "Reconstruction: 0.169815, Regularization: 0.000308\n",
      "2019-04-10 01:02:53,307 root         INFO     Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 0.162451\n",
      "Reconstruction: 0.162191, Regularization: 0.000260\n",
      "2019-04-10 01:02:53,370 root         INFO     Train Epoch: 96 [2560/8000 (32%)]\tTotal Loss: 0.175805\n",
      "Reconstruction: 0.175399, Regularization: 0.000406\n",
      "2019-04-10 01:02:53,432 root         INFO     Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 0.164823\n",
      "Reconstruction: 0.164474, Regularization: 0.000349\n",
      "2019-04-10 01:02:53,495 root         INFO     Train Epoch: 96 [3584/8000 (45%)]\tTotal Loss: 0.172586\n",
      "Reconstruction: 0.172224, Regularization: 0.000362\n",
      "2019-04-10 01:02:53,557 root         INFO     Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 0.155268\n",
      "Reconstruction: 0.155062, Regularization: 0.000205\n",
      "2019-04-10 01:02:53,620 root         INFO     Train Epoch: 96 [4608/8000 (58%)]\tTotal Loss: 0.168509\n",
      "Reconstruction: 0.168192, Regularization: 0.000317\n",
      "2019-04-10 01:02:53,682 root         INFO     Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 0.158101\n",
      "Reconstruction: 0.157750, Regularization: 0.000351\n",
      "2019-04-10 01:02:53,744 root         INFO     Train Epoch: 96 [5632/8000 (70%)]\tTotal Loss: 0.173043\n",
      "Reconstruction: 0.172480, Regularization: 0.000563\n",
      "2019-04-10 01:02:53,806 root         INFO     Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 0.160644\n",
      "Reconstruction: 0.160297, Regularization: 0.000347\n",
      "2019-04-10 01:02:53,867 root         INFO     Train Epoch: 96 [6656/8000 (83%)]\tTotal Loss: 0.175240\n",
      "Reconstruction: 0.174773, Regularization: 0.000467\n",
      "2019-04-10 01:02:53,929 root         INFO     Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 0.163122\n",
      "Reconstruction: 0.162785, Regularization: 0.000337\n",
      "2019-04-10 01:02:53,990 root         INFO     Train Epoch: 96 [7680/8000 (96%)]\tTotal Loss: 0.167731\n",
      "Reconstruction: 0.167434, Regularization: 0.000298\n",
      "2019-04-10 01:02:54,043 root         INFO     ====> Epoch: 96 Average loss: 0.1669\n",
      "2019-04-10 01:02:54,067 root         INFO     Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 0.163604\n",
      "Reconstruction: 0.163254, Regularization: 0.000350\n",
      "2019-04-10 01:02:54,130 root         INFO     Train Epoch: 97 [512/8000 (6%)]\tTotal Loss: 0.175447\n",
      "Reconstruction: 0.175042, Regularization: 0.000405\n",
      "2019-04-10 01:02:54,193 root         INFO     Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 0.159013\n",
      "Reconstruction: 0.158747, Regularization: 0.000265\n",
      "2019-04-10 01:02:54,257 root         INFO     Train Epoch: 97 [1536/8000 (19%)]\tTotal Loss: 0.164686\n",
      "Reconstruction: 0.164321, Regularization: 0.000365\n",
      "2019-04-10 01:02:54,320 root         INFO     Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 0.156234\n",
      "Reconstruction: 0.155986, Regularization: 0.000248\n",
      "2019-04-10 01:02:54,382 root         INFO     Train Epoch: 97 [2560/8000 (32%)]\tTotal Loss: 0.172931\n",
      "Reconstruction: 0.172575, Regularization: 0.000356\n",
      "2019-04-10 01:02:54,445 root         INFO     Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 0.156894\n",
      "Reconstruction: 0.156584, Regularization: 0.000310\n",
      "2019-04-10 01:02:54,509 root         INFO     Train Epoch: 97 [3584/8000 (45%)]\tTotal Loss: 0.162325\n",
      "Reconstruction: 0.162072, Regularization: 0.000253\n",
      "2019-04-10 01:02:54,571 root         INFO     Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 0.174083\n",
      "Reconstruction: 0.173760, Regularization: 0.000323\n",
      "2019-04-10 01:02:54,633 root         INFO     Train Epoch: 97 [4608/8000 (58%)]\tTotal Loss: 0.165198\n",
      "Reconstruction: 0.164748, Regularization: 0.000450\n",
      "2019-04-10 01:02:54,695 root         INFO     Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 0.156206\n",
      "Reconstruction: 0.155947, Regularization: 0.000259\n",
      "2019-04-10 01:02:54,757 root         INFO     Train Epoch: 97 [5632/8000 (70%)]\tTotal Loss: 0.163719\n",
      "Reconstruction: 0.163415, Regularization: 0.000303\n",
      "2019-04-10 01:02:54,819 root         INFO     Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 0.176972\n",
      "Reconstruction: 0.176581, Regularization: 0.000391\n",
      "2019-04-10 01:02:54,881 root         INFO     Train Epoch: 97 [6656/8000 (83%)]\tTotal Loss: 0.166089\n",
      "Reconstruction: 0.165709, Regularization: 0.000380\n",
      "2019-04-10 01:02:54,943 root         INFO     Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 0.166850\n",
      "Reconstruction: 0.166505, Regularization: 0.000344\n",
      "2019-04-10 01:02:55,005 root         INFO     Train Epoch: 97 [7680/8000 (96%)]\tTotal Loss: 0.153875\n",
      "Reconstruction: 0.153591, Regularization: 0.000284\n",
      "2019-04-10 01:02:55,058 root         INFO     ====> Epoch: 97 Average loss: 0.1665\n",
      "2019-04-10 01:02:55,082 root         INFO     Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 0.161823\n",
      "Reconstruction: 0.161413, Regularization: 0.000410\n",
      "2019-04-10 01:02:55,146 root         INFO     Train Epoch: 98 [512/8000 (6%)]\tTotal Loss: 0.164129\n",
      "Reconstruction: 0.163671, Regularization: 0.000459\n",
      "2019-04-10 01:02:55,209 root         INFO     Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 0.170398\n",
      "Reconstruction: 0.169895, Regularization: 0.000502\n",
      "2019-04-10 01:02:55,272 root         INFO     Train Epoch: 98 [1536/8000 (19%)]\tTotal Loss: 0.162672\n",
      "Reconstruction: 0.162270, Regularization: 0.000402\n",
      "2019-04-10 01:02:55,335 root         INFO     Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 0.169773\n",
      "Reconstruction: 0.169345, Regularization: 0.000428\n",
      "2019-04-10 01:02:55,398 root         INFO     Train Epoch: 98 [2560/8000 (32%)]\tTotal Loss: 0.155486\n",
      "Reconstruction: 0.155233, Regularization: 0.000253\n",
      "2019-04-10 01:02:55,461 root         INFO     Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 0.164045\n",
      "Reconstruction: 0.163709, Regularization: 0.000337\n",
      "2019-04-10 01:02:55,524 root         INFO     Train Epoch: 98 [3584/8000 (45%)]\tTotal Loss: 0.164688\n",
      "Reconstruction: 0.164299, Regularization: 0.000389\n",
      "2019-04-10 01:02:55,586 root         INFO     Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 0.179911\n",
      "Reconstruction: 0.179490, Regularization: 0.000421\n",
      "2019-04-10 01:02:55,649 root         INFO     Train Epoch: 98 [4608/8000 (58%)]\tTotal Loss: 0.171204\n",
      "Reconstruction: 0.170710, Regularization: 0.000494\n",
      "2019-04-10 01:02:55,711 root         INFO     Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 0.155962\n",
      "Reconstruction: 0.155669, Regularization: 0.000293\n",
      "2019-04-10 01:02:55,773 root         INFO     Train Epoch: 98 [5632/8000 (70%)]\tTotal Loss: 0.156098\n",
      "Reconstruction: 0.155787, Regularization: 0.000311\n",
      "2019-04-10 01:02:55,834 root         INFO     Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 0.160597\n",
      "Reconstruction: 0.160298, Regularization: 0.000299\n",
      "2019-04-10 01:02:55,896 root         INFO     Train Epoch: 98 [6656/8000 (83%)]\tTotal Loss: 0.163097\n",
      "Reconstruction: 0.162713, Regularization: 0.000384\n",
      "2019-04-10 01:02:55,957 root         INFO     Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 0.163077\n",
      "Reconstruction: 0.162633, Regularization: 0.000444\n",
      "2019-04-10 01:02:56,018 root         INFO     Train Epoch: 98 [7680/8000 (96%)]\tTotal Loss: 0.161608\n",
      "Reconstruction: 0.161261, Regularization: 0.000347\n",
      "2019-04-10 01:02:56,070 root         INFO     ====> Epoch: 98 Average loss: 0.1665\n",
      "2019-04-10 01:02:56,094 root         INFO     Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 0.157115\n",
      "Reconstruction: 0.156790, Regularization: 0.000325\n",
      "2019-04-10 01:02:56,159 root         INFO     Train Epoch: 99 [512/8000 (6%)]\tTotal Loss: 0.172789\n",
      "Reconstruction: 0.172268, Regularization: 0.000520\n",
      "2019-04-10 01:02:56,223 root         INFO     Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 0.158476\n",
      "Reconstruction: 0.158149, Regularization: 0.000327\n",
      "2019-04-10 01:02:56,287 root         INFO     Train Epoch: 99 [1536/8000 (19%)]\tTotal Loss: 0.166852\n",
      "Reconstruction: 0.166433, Regularization: 0.000419\n",
      "2019-04-10 01:02:56,351 root         INFO     Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 0.162260\n",
      "Reconstruction: 0.161950, Regularization: 0.000310\n",
      "2019-04-10 01:02:56,415 root         INFO     Train Epoch: 99 [2560/8000 (32%)]\tTotal Loss: 0.171101\n",
      "Reconstruction: 0.170708, Regularization: 0.000393\n",
      "2019-04-10 01:02:56,478 root         INFO     Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 0.159687\n",
      "Reconstruction: 0.159341, Regularization: 0.000346\n",
      "2019-04-10 01:02:56,542 root         INFO     Train Epoch: 99 [3584/8000 (45%)]\tTotal Loss: 0.180526\n",
      "Reconstruction: 0.179999, Regularization: 0.000527\n",
      "2019-04-10 01:02:56,604 root         INFO     Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 0.156691\n",
      "Reconstruction: 0.156426, Regularization: 0.000265\n",
      "2019-04-10 01:02:56,667 root         INFO     Train Epoch: 99 [4608/8000 (58%)]\tTotal Loss: 0.170223\n",
      "Reconstruction: 0.169738, Regularization: 0.000484\n",
      "2019-04-10 01:02:56,729 root         INFO     Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 0.163795\n",
      "Reconstruction: 0.163441, Regularization: 0.000355\n",
      "2019-04-10 01:02:56,791 root         INFO     Train Epoch: 99 [5632/8000 (70%)]\tTotal Loss: 0.157808\n",
      "Reconstruction: 0.157502, Regularization: 0.000306\n",
      "2019-04-10 01:02:56,854 root         INFO     Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 0.174395\n",
      "Reconstruction: 0.173807, Regularization: 0.000588\n",
      "2019-04-10 01:02:56,915 root         INFO     Train Epoch: 99 [6656/8000 (83%)]\tTotal Loss: 0.168405\n",
      "Reconstruction: 0.168059, Regularization: 0.000346\n",
      "2019-04-10 01:02:56,976 root         INFO     Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 0.159714\n",
      "Reconstruction: 0.159404, Regularization: 0.000310\n",
      "2019-04-10 01:02:57,038 root         INFO     Train Epoch: 99 [7680/8000 (96%)]\tTotal Loss: 0.167814\n",
      "Reconstruction: 0.167401, Regularization: 0.000412\n",
      "2019-04-10 01:02:57,091 root         INFO     ====> Epoch: 99 Average loss: 0.1663\n",
      "2019-04-10 01:02:57,114 root         INFO     Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 0.164670\n",
      "Reconstruction: 0.164286, Regularization: 0.000384\n",
      "2019-04-10 01:02:57,178 root         INFO     Train Epoch: 100 [512/8000 (6%)]\tTotal Loss: 0.155844\n",
      "Reconstruction: 0.155610, Regularization: 0.000235\n",
      "2019-04-10 01:02:57,242 root         INFO     Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 0.174114\n",
      "Reconstruction: 0.173649, Regularization: 0.000465\n",
      "2019-04-10 01:02:57,305 root         INFO     Train Epoch: 100 [1536/8000 (19%)]\tTotal Loss: 0.164238\n",
      "Reconstruction: 0.163897, Regularization: 0.000342\n",
      "2019-04-10 01:02:57,367 root         INFO     Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 0.159120\n",
      "Reconstruction: 0.158818, Regularization: 0.000302\n",
      "2019-04-10 01:02:57,430 root         INFO     Train Epoch: 100 [2560/8000 (32%)]\tTotal Loss: 0.174008\n",
      "Reconstruction: 0.173457, Regularization: 0.000551\n",
      "2019-04-10 01:02:57,493 root         INFO     Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 0.154304\n",
      "Reconstruction: 0.153948, Regularization: 0.000356\n",
      "2019-04-10 01:02:57,557 root         INFO     Train Epoch: 100 [3584/8000 (45%)]\tTotal Loss: 0.164833\n",
      "Reconstruction: 0.164425, Regularization: 0.000408\n",
      "2019-04-10 01:02:57,619 root         INFO     Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 0.161032\n",
      "Reconstruction: 0.160659, Regularization: 0.000373\n",
      "2019-04-10 01:02:57,682 root         INFO     Train Epoch: 100 [4608/8000 (58%)]\tTotal Loss: 0.174309\n",
      "Reconstruction: 0.173884, Regularization: 0.000425\n",
      "2019-04-10 01:02:57,745 root         INFO     Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 0.179784\n",
      "Reconstruction: 0.179237, Regularization: 0.000548\n",
      "2019-04-10 01:02:57,807 root         INFO     Train Epoch: 100 [5632/8000 (70%)]\tTotal Loss: 0.169185\n",
      "Reconstruction: 0.168757, Regularization: 0.000427\n",
      "2019-04-10 01:02:57,870 root         INFO     Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 0.160209\n",
      "Reconstruction: 0.159854, Regularization: 0.000355\n",
      "2019-04-10 01:02:57,933 root         INFO     Train Epoch: 100 [6656/8000 (83%)]\tTotal Loss: 0.156835\n",
      "Reconstruction: 0.156548, Regularization: 0.000287\n",
      "2019-04-10 01:02:57,996 root         INFO     Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 0.172523\n",
      "Reconstruction: 0.172053, Regularization: 0.000470\n",
      "2019-04-10 01:02:58,059 root         INFO     Train Epoch: 100 [7680/8000 (96%)]\tTotal Loss: 0.162880\n",
      "Reconstruction: 0.162562, Regularization: 0.000318\n",
      "2019-04-10 01:02:58,113 root         INFO     ====> Epoch: 100 Average loss: 0.1662\n",
      "2019-04-10 01:02:58,137 root         INFO     Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 0.164547\n",
      "Reconstruction: 0.164143, Regularization: 0.000404\n",
      "2019-04-10 01:02:58,200 root         INFO     Train Epoch: 101 [512/8000 (6%)]\tTotal Loss: 0.173026\n",
      "Reconstruction: 0.172669, Regularization: 0.000357\n",
      "2019-04-10 01:02:58,263 root         INFO     Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 0.171220\n",
      "Reconstruction: 0.170734, Regularization: 0.000487\n",
      "2019-04-10 01:02:58,327 root         INFO     Train Epoch: 101 [1536/8000 (19%)]\tTotal Loss: 0.175698\n",
      "Reconstruction: 0.175309, Regularization: 0.000389\n",
      "2019-04-10 01:02:58,389 root         INFO     Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 0.170936\n",
      "Reconstruction: 0.170538, Regularization: 0.000398\n",
      "2019-04-10 01:02:58,453 root         INFO     Train Epoch: 101 [2560/8000 (32%)]\tTotal Loss: 0.152098\n",
      "Reconstruction: 0.151866, Regularization: 0.000233\n",
      "2019-04-10 01:02:58,516 root         INFO     Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 0.175608\n",
      "Reconstruction: 0.175096, Regularization: 0.000512\n",
      "2019-04-10 01:02:58,579 root         INFO     Train Epoch: 101 [3584/8000 (45%)]\tTotal Loss: 0.149306\n",
      "Reconstruction: 0.149086, Regularization: 0.000220\n",
      "2019-04-10 01:02:58,642 root         INFO     Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 0.160010\n",
      "Reconstruction: 0.159705, Regularization: 0.000305\n",
      "2019-04-10 01:02:58,706 root         INFO     Train Epoch: 101 [4608/8000 (58%)]\tTotal Loss: 0.164138\n",
      "Reconstruction: 0.163750, Regularization: 0.000388\n",
      "2019-04-10 01:02:58,770 root         INFO     Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 0.161985\n",
      "Reconstruction: 0.161673, Regularization: 0.000313\n",
      "2019-04-10 01:02:58,833 root         INFO     Train Epoch: 101 [5632/8000 (70%)]\tTotal Loss: 0.165986\n",
      "Reconstruction: 0.165587, Regularization: 0.000399\n",
      "2019-04-10 01:02:58,897 root         INFO     Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 0.162278\n",
      "Reconstruction: 0.161984, Regularization: 0.000294\n",
      "2019-04-10 01:02:58,961 root         INFO     Train Epoch: 101 [6656/8000 (83%)]\tTotal Loss: 0.176461\n",
      "Reconstruction: 0.175965, Regularization: 0.000496\n",
      "2019-04-10 01:02:59,024 root         INFO     Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 0.157234\n",
      "Reconstruction: 0.156889, Regularization: 0.000345\n",
      "2019-04-10 01:02:59,087 root         INFO     Train Epoch: 101 [7680/8000 (96%)]\tTotal Loss: 0.164931\n",
      "Reconstruction: 0.164543, Regularization: 0.000388\n",
      "2019-04-10 01:02:59,141 root         INFO     ====> Epoch: 101 Average loss: 0.1664\n",
      "2019-04-10 01:02:59,165 root         INFO     Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 0.170001\n",
      "Reconstruction: 0.169515, Regularization: 0.000486\n",
      "2019-04-10 01:02:59,229 root         INFO     Train Epoch: 102 [512/8000 (6%)]\tTotal Loss: 0.181070\n",
      "Reconstruction: 0.180542, Regularization: 0.000528\n",
      "2019-04-10 01:02:59,292 root         INFO     Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 0.168826\n",
      "Reconstruction: 0.168394, Regularization: 0.000432\n",
      "2019-04-10 01:02:59,356 root         INFO     Train Epoch: 102 [1536/8000 (19%)]\tTotal Loss: 0.168315\n",
      "Reconstruction: 0.167862, Regularization: 0.000453\n",
      "2019-04-10 01:02:59,419 root         INFO     Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 0.165210\n",
      "Reconstruction: 0.164889, Regularization: 0.000321\n",
      "2019-04-10 01:02:59,483 root         INFO     Train Epoch: 102 [2560/8000 (32%)]\tTotal Loss: 0.169417\n",
      "Reconstruction: 0.168984, Regularization: 0.000433\n",
      "2019-04-10 01:02:59,547 root         INFO     Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 0.167438\n",
      "Reconstruction: 0.167118, Regularization: 0.000320\n",
      "2019-04-10 01:02:59,611 root         INFO     Train Epoch: 102 [3584/8000 (45%)]\tTotal Loss: 0.157640\n",
      "Reconstruction: 0.157275, Regularization: 0.000364\n",
      "2019-04-10 01:02:59,675 root         INFO     Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 0.164690\n",
      "Reconstruction: 0.164337, Regularization: 0.000353\n",
      "2019-04-10 01:02:59,740 root         INFO     Train Epoch: 102 [4608/8000 (58%)]\tTotal Loss: 0.172378\n",
      "Reconstruction: 0.171878, Regularization: 0.000500\n",
      "2019-04-10 01:02:59,804 root         INFO     Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 0.157669\n",
      "Reconstruction: 0.157411, Regularization: 0.000259\n",
      "2019-04-10 01:02:59,867 root         INFO     Train Epoch: 102 [5632/8000 (70%)]\tTotal Loss: 0.159745\n",
      "Reconstruction: 0.159485, Regularization: 0.000260\n",
      "2019-04-10 01:02:59,928 root         INFO     Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 0.158785\n",
      "Reconstruction: 0.158397, Regularization: 0.000387\n",
      "2019-04-10 01:02:59,991 root         INFO     Train Epoch: 102 [6656/8000 (83%)]\tTotal Loss: 0.167633\n",
      "Reconstruction: 0.167211, Regularization: 0.000422\n",
      "2019-04-10 01:03:00,053 root         INFO     Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 0.165936\n",
      "Reconstruction: 0.165507, Regularization: 0.000429\n",
      "2019-04-10 01:03:00,116 root         INFO     Train Epoch: 102 [7680/8000 (96%)]\tTotal Loss: 0.169039\n",
      "Reconstruction: 0.168546, Regularization: 0.000493\n",
      "2019-04-10 01:03:00,170 root         INFO     ====> Epoch: 102 Average loss: 0.1664\n",
      "2019-04-10 01:03:00,194 root         INFO     Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 0.158516\n",
      "Reconstruction: 0.158149, Regularization: 0.000367\n",
      "2019-04-10 01:03:00,258 root         INFO     Train Epoch: 103 [512/8000 (6%)]\tTotal Loss: 0.172043\n",
      "Reconstruction: 0.171616, Regularization: 0.000427\n",
      "2019-04-10 01:03:00,322 root         INFO     Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 0.169831\n",
      "Reconstruction: 0.169360, Regularization: 0.000471\n",
      "2019-04-10 01:03:00,385 root         INFO     Train Epoch: 103 [1536/8000 (19%)]\tTotal Loss: 0.157635\n",
      "Reconstruction: 0.157345, Regularization: 0.000290\n",
      "2019-04-10 01:03:00,449 root         INFO     Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 0.163536\n",
      "Reconstruction: 0.163159, Regularization: 0.000378\n",
      "2019-04-10 01:03:00,511 root         INFO     Train Epoch: 103 [2560/8000 (32%)]\tTotal Loss: 0.169585\n",
      "Reconstruction: 0.169073, Regularization: 0.000511\n",
      "2019-04-10 01:03:00,573 root         INFO     Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 0.154700\n",
      "Reconstruction: 0.154439, Regularization: 0.000261\n",
      "2019-04-10 01:03:00,634 root         INFO     Train Epoch: 103 [3584/8000 (45%)]\tTotal Loss: 0.171041\n",
      "Reconstruction: 0.170498, Regularization: 0.000543\n",
      "2019-04-10 01:03:00,696 root         INFO     Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 0.177718\n",
      "Reconstruction: 0.177188, Regularization: 0.000530\n",
      "2019-04-10 01:03:00,757 root         INFO     Train Epoch: 103 [4608/8000 (58%)]\tTotal Loss: 0.185130\n",
      "Reconstruction: 0.184434, Regularization: 0.000696\n",
      "2019-04-10 01:03:00,819 root         INFO     Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 0.168754\n",
      "Reconstruction: 0.168184, Regularization: 0.000570\n",
      "2019-04-10 01:03:00,880 root         INFO     Train Epoch: 103 [5632/8000 (70%)]\tTotal Loss: 0.180022\n",
      "Reconstruction: 0.179564, Regularization: 0.000458\n",
      "2019-04-10 01:03:00,941 root         INFO     Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 0.169439\n",
      "Reconstruction: 0.169051, Regularization: 0.000388\n",
      "2019-04-10 01:03:01,002 root         INFO     Train Epoch: 103 [6656/8000 (83%)]\tTotal Loss: 0.182997\n",
      "Reconstruction: 0.182385, Regularization: 0.000612\n",
      "2019-04-10 01:03:01,066 root         INFO     Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 0.185528\n",
      "Reconstruction: 0.184978, Regularization: 0.000550\n",
      "2019-04-10 01:03:01,127 root         INFO     Train Epoch: 103 [7680/8000 (96%)]\tTotal Loss: 0.164343\n",
      "Reconstruction: 0.164016, Regularization: 0.000328\n",
      "2019-04-10 01:03:01,180 root         INFO     ====> Epoch: 103 Average loss: 0.1663\n",
      "2019-04-10 01:03:01,204 root         INFO     Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 0.163548\n",
      "Reconstruction: 0.163174, Regularization: 0.000374\n",
      "2019-04-10 01:03:01,268 root         INFO     Train Epoch: 104 [512/8000 (6%)]\tTotal Loss: 0.165959\n",
      "Reconstruction: 0.165527, Regularization: 0.000432\n",
      "2019-04-10 01:03:01,333 root         INFO     Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 0.158683\n",
      "Reconstruction: 0.158348, Regularization: 0.000335\n",
      "2019-04-10 01:03:01,397 root         INFO     Train Epoch: 104 [1536/8000 (19%)]\tTotal Loss: 0.159970\n",
      "Reconstruction: 0.159702, Regularization: 0.000267\n",
      "2019-04-10 01:03:01,462 root         INFO     Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 0.161467\n",
      "Reconstruction: 0.161081, Regularization: 0.000386\n",
      "2019-04-10 01:03:01,526 root         INFO     Train Epoch: 104 [2560/8000 (32%)]\tTotal Loss: 0.170664\n",
      "Reconstruction: 0.170086, Regularization: 0.000578\n",
      "2019-04-10 01:03:01,591 root         INFO     Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 0.159255\n",
      "Reconstruction: 0.158933, Regularization: 0.000322\n",
      "2019-04-10 01:03:01,655 root         INFO     Train Epoch: 104 [3584/8000 (45%)]\tTotal Loss: 0.172952\n",
      "Reconstruction: 0.172491, Regularization: 0.000460\n",
      "2019-04-10 01:03:01,719 root         INFO     Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 0.170065\n",
      "Reconstruction: 0.169458, Regularization: 0.000607\n",
      "2019-04-10 01:03:01,784 root         INFO     Train Epoch: 104 [4608/8000 (58%)]\tTotal Loss: 0.178793\n",
      "Reconstruction: 0.178284, Regularization: 0.000509\n",
      "2019-04-10 01:03:01,847 root         INFO     Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 0.154112\n",
      "Reconstruction: 0.153777, Regularization: 0.000335\n",
      "2019-04-10 01:03:01,912 root         INFO     Train Epoch: 104 [5632/8000 (70%)]\tTotal Loss: 0.170277\n",
      "Reconstruction: 0.169694, Regularization: 0.000583\n",
      "2019-04-10 01:03:01,976 root         INFO     Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 0.171787\n",
      "Reconstruction: 0.171359, Regularization: 0.000428\n",
      "2019-04-10 01:03:02,040 root         INFO     Train Epoch: 104 [6656/8000 (83%)]\tTotal Loss: 0.171979\n",
      "Reconstruction: 0.171527, Regularization: 0.000453\n",
      "2019-04-10 01:03:02,103 root         INFO     Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 0.173200\n",
      "Reconstruction: 0.172741, Regularization: 0.000460\n",
      "2019-04-10 01:03:02,166 root         INFO     Train Epoch: 104 [7680/8000 (96%)]\tTotal Loss: 0.164888\n",
      "Reconstruction: 0.164413, Regularization: 0.000475\n",
      "2019-04-10 01:03:02,219 root         INFO     ====> Epoch: 104 Average loss: 0.1663\n",
      "2019-04-10 01:03:02,244 root         INFO     Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 0.161544\n",
      "Reconstruction: 0.161208, Regularization: 0.000336\n",
      "2019-04-10 01:03:02,308 root         INFO     Train Epoch: 105 [512/8000 (6%)]\tTotal Loss: 0.162419\n",
      "Reconstruction: 0.162085, Regularization: 0.000334\n",
      "2019-04-10 01:03:02,371 root         INFO     Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 0.181222\n",
      "Reconstruction: 0.180596, Regularization: 0.000626\n",
      "2019-04-10 01:03:02,434 root         INFO     Train Epoch: 105 [1536/8000 (19%)]\tTotal Loss: 0.170668\n",
      "Reconstruction: 0.170237, Regularization: 0.000431\n",
      "2019-04-10 01:03:02,497 root         INFO     Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 0.158467\n",
      "Reconstruction: 0.158126, Regularization: 0.000340\n",
      "2019-04-10 01:03:02,560 root         INFO     Train Epoch: 105 [2560/8000 (32%)]\tTotal Loss: 0.183779\n",
      "Reconstruction: 0.183156, Regularization: 0.000623\n",
      "2019-04-10 01:03:02,622 root         INFO     Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 0.171231\n",
      "Reconstruction: 0.170743, Regularization: 0.000488\n",
      "2019-04-10 01:03:02,685 root         INFO     Train Epoch: 105 [3584/8000 (45%)]\tTotal Loss: 0.156896\n",
      "Reconstruction: 0.156594, Regularization: 0.000301\n",
      "2019-04-10 01:03:02,749 root         INFO     Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 0.173572\n",
      "Reconstruction: 0.173072, Regularization: 0.000500\n",
      "2019-04-10 01:03:02,812 root         INFO     Train Epoch: 105 [4608/8000 (58%)]\tTotal Loss: 0.164354\n",
      "Reconstruction: 0.163952, Regularization: 0.000402\n",
      "2019-04-10 01:03:02,876 root         INFO     Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 0.169776\n",
      "Reconstruction: 0.169297, Regularization: 0.000479\n",
      "2019-04-10 01:03:02,940 root         INFO     Train Epoch: 105 [5632/8000 (70%)]\tTotal Loss: 0.170844\n",
      "Reconstruction: 0.170349, Regularization: 0.000495\n",
      "2019-04-10 01:03:03,004 root         INFO     Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 0.181636\n",
      "Reconstruction: 0.181144, Regularization: 0.000492\n",
      "2019-04-10 01:03:03,069 root         INFO     Train Epoch: 105 [6656/8000 (83%)]\tTotal Loss: 0.161931\n",
      "Reconstruction: 0.161509, Regularization: 0.000422\n",
      "2019-04-10 01:03:03,133 root         INFO     Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 0.174969\n",
      "Reconstruction: 0.174444, Regularization: 0.000526\n",
      "2019-04-10 01:03:03,197 root         INFO     Train Epoch: 105 [7680/8000 (96%)]\tTotal Loss: 0.175829\n",
      "Reconstruction: 0.175216, Regularization: 0.000614\n",
      "2019-04-10 01:03:03,251 root         INFO     ====> Epoch: 105 Average loss: 0.1664\n",
      "2019-04-10 01:03:03,276 root         INFO     Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 0.161811\n",
      "Reconstruction: 0.161513, Regularization: 0.000298\n",
      "2019-04-10 01:03:03,340 root         INFO     Train Epoch: 106 [512/8000 (6%)]\tTotal Loss: 0.177994\n",
      "Reconstruction: 0.177466, Regularization: 0.000528\n",
      "2019-04-10 01:03:03,404 root         INFO     Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 0.165034\n",
      "Reconstruction: 0.164620, Regularization: 0.000414\n",
      "2019-04-10 01:03:03,467 root         INFO     Train Epoch: 106 [1536/8000 (19%)]\tTotal Loss: 0.157679\n",
      "Reconstruction: 0.157321, Regularization: 0.000357\n",
      "2019-04-10 01:03:03,529 root         INFO     Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 0.170695\n",
      "Reconstruction: 0.170270, Regularization: 0.000425\n",
      "2019-04-10 01:03:03,592 root         INFO     Train Epoch: 106 [2560/8000 (32%)]\tTotal Loss: 0.185545\n",
      "Reconstruction: 0.184903, Regularization: 0.000642\n",
      "2019-04-10 01:03:03,655 root         INFO     Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 0.176980\n",
      "Reconstruction: 0.176391, Regularization: 0.000589\n",
      "2019-04-10 01:03:03,717 root         INFO     Train Epoch: 106 [3584/8000 (45%)]\tTotal Loss: 0.170147\n",
      "Reconstruction: 0.169696, Regularization: 0.000451\n",
      "2019-04-10 01:03:03,780 root         INFO     Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 0.169051\n",
      "Reconstruction: 0.168564, Regularization: 0.000487\n",
      "2019-04-10 01:03:03,842 root         INFO     Train Epoch: 106 [4608/8000 (58%)]\tTotal Loss: 0.160894\n",
      "Reconstruction: 0.160539, Regularization: 0.000356\n",
      "2019-04-10 01:03:03,905 root         INFO     Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 0.173513\n",
      "Reconstruction: 0.173063, Regularization: 0.000450\n",
      "2019-04-10 01:03:03,968 root         INFO     Train Epoch: 106 [5632/8000 (70%)]\tTotal Loss: 0.160545\n",
      "Reconstruction: 0.160288, Regularization: 0.000257\n",
      "2019-04-10 01:03:04,030 root         INFO     Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 0.159813\n",
      "Reconstruction: 0.159501, Regularization: 0.000312\n",
      "2019-04-10 01:03:04,093 root         INFO     Train Epoch: 106 [6656/8000 (83%)]\tTotal Loss: 0.159926\n",
      "Reconstruction: 0.159596, Regularization: 0.000330\n",
      "2019-04-10 01:03:04,155 root         INFO     Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 0.151777\n",
      "Reconstruction: 0.151540, Regularization: 0.000237\n",
      "2019-04-10 01:03:04,218 root         INFO     Train Epoch: 106 [7680/8000 (96%)]\tTotal Loss: 0.163850\n",
      "Reconstruction: 0.163491, Regularization: 0.000358\n",
      "2019-04-10 01:03:04,273 root         INFO     ====> Epoch: 106 Average loss: 0.1664\n",
      "2019-04-10 01:03:04,297 root         INFO     Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 0.166916\n",
      "Reconstruction: 0.166451, Regularization: 0.000465\n",
      "2019-04-10 01:03:04,361 root         INFO     Train Epoch: 107 [512/8000 (6%)]\tTotal Loss: 0.187682\n",
      "Reconstruction: 0.186946, Regularization: 0.000737\n",
      "2019-04-10 01:03:04,425 root         INFO     Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 0.175776\n",
      "Reconstruction: 0.175234, Regularization: 0.000542\n",
      "2019-04-10 01:03:04,489 root         INFO     Train Epoch: 107 [1536/8000 (19%)]\tTotal Loss: 0.160666\n",
      "Reconstruction: 0.160290, Regularization: 0.000376\n",
      "2019-04-10 01:03:04,553 root         INFO     Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 0.173815\n",
      "Reconstruction: 0.173275, Regularization: 0.000539\n",
      "2019-04-10 01:03:04,617 root         INFO     Train Epoch: 107 [2560/8000 (32%)]\tTotal Loss: 0.157561\n",
      "Reconstruction: 0.157247, Regularization: 0.000314\n",
      "2019-04-10 01:03:04,681 root         INFO     Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 0.155111\n",
      "Reconstruction: 0.154808, Regularization: 0.000303\n",
      "2019-04-10 01:03:04,745 root         INFO     Train Epoch: 107 [3584/8000 (45%)]\tTotal Loss: 0.162887\n",
      "Reconstruction: 0.162534, Regularization: 0.000353\n",
      "2019-04-10 01:03:04,810 root         INFO     Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 0.175302\n",
      "Reconstruction: 0.174684, Regularization: 0.000618\n",
      "2019-04-10 01:03:04,874 root         INFO     Train Epoch: 107 [4608/8000 (58%)]\tTotal Loss: 0.161231\n",
      "Reconstruction: 0.160775, Regularization: 0.000455\n",
      "2019-04-10 01:03:04,938 root         INFO     Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 0.165526\n",
      "Reconstruction: 0.165135, Regularization: 0.000392\n",
      "2019-04-10 01:03:05,003 root         INFO     Train Epoch: 107 [5632/8000 (70%)]\tTotal Loss: 0.178119\n",
      "Reconstruction: 0.177695, Regularization: 0.000424\n",
      "2019-04-10 01:03:05,066 root         INFO     Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 0.163612\n",
      "Reconstruction: 0.163272, Regularization: 0.000340\n",
      "2019-04-10 01:03:05,129 root         INFO     Train Epoch: 107 [6656/8000 (83%)]\tTotal Loss: 0.174697\n",
      "Reconstruction: 0.174112, Regularization: 0.000585\n",
      "2019-04-10 01:03:05,191 root         INFO     Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 0.160345\n",
      "Reconstruction: 0.160008, Regularization: 0.000337\n",
      "2019-04-10 01:03:05,254 root         INFO     Train Epoch: 107 [7680/8000 (96%)]\tTotal Loss: 0.175533\n",
      "Reconstruction: 0.174965, Regularization: 0.000568\n",
      "2019-04-10 01:03:05,307 root         INFO     ====> Epoch: 107 Average loss: 0.1663\n",
      "2019-04-10 01:03:05,331 root         INFO     Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 0.160709\n",
      "Reconstruction: 0.160282, Regularization: 0.000426\n",
      "2019-04-10 01:03:05,394 root         INFO     Train Epoch: 108 [512/8000 (6%)]\tTotal Loss: 0.172926\n",
      "Reconstruction: 0.172359, Regularization: 0.000568\n",
      "2019-04-10 01:03:05,457 root         INFO     Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 0.178734\n",
      "Reconstruction: 0.178129, Regularization: 0.000605\n",
      "2019-04-10 01:03:05,521 root         INFO     Train Epoch: 108 [1536/8000 (19%)]\tTotal Loss: 0.172935\n",
      "Reconstruction: 0.172344, Regularization: 0.000591\n",
      "2019-04-10 01:03:05,584 root         INFO     Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 0.169632\n",
      "Reconstruction: 0.169208, Regularization: 0.000424\n",
      "2019-04-10 01:03:05,647 root         INFO     Train Epoch: 108 [2560/8000 (32%)]\tTotal Loss: 0.152765\n",
      "Reconstruction: 0.152522, Regularization: 0.000244\n",
      "2019-04-10 01:03:05,709 root         INFO     Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 0.169798\n",
      "Reconstruction: 0.169371, Regularization: 0.000427\n",
      "2019-04-10 01:03:05,773 root         INFO     Train Epoch: 108 [3584/8000 (45%)]\tTotal Loss: 0.166241\n",
      "Reconstruction: 0.165809, Regularization: 0.000432\n",
      "2019-04-10 01:03:05,835 root         INFO     Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 0.171933\n",
      "Reconstruction: 0.171451, Regularization: 0.000482\n",
      "2019-04-10 01:03:05,898 root         INFO     Train Epoch: 108 [4608/8000 (58%)]\tTotal Loss: 0.162348\n",
      "Reconstruction: 0.161973, Regularization: 0.000375\n",
      "2019-04-10 01:03:05,961 root         INFO     Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 0.165441\n",
      "Reconstruction: 0.164983, Regularization: 0.000458\n",
      "2019-04-10 01:03:06,023 root         INFO     Train Epoch: 108 [5632/8000 (70%)]\tTotal Loss: 0.167713\n",
      "Reconstruction: 0.167204, Regularization: 0.000509\n",
      "2019-04-10 01:03:06,086 root         INFO     Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 0.172168\n",
      "Reconstruction: 0.171698, Regularization: 0.000470\n",
      "2019-04-10 01:03:06,149 root         INFO     Train Epoch: 108 [6656/8000 (83%)]\tTotal Loss: 0.161562\n",
      "Reconstruction: 0.161180, Regularization: 0.000382\n",
      "2019-04-10 01:03:06,212 root         INFO     Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 0.164057\n",
      "Reconstruction: 0.163698, Regularization: 0.000359\n",
      "2019-04-10 01:03:06,274 root         INFO     Train Epoch: 108 [7680/8000 (96%)]\tTotal Loss: 0.167640\n",
      "Reconstruction: 0.167179, Regularization: 0.000461\n",
      "2019-04-10 01:03:06,328 root         INFO     ====> Epoch: 108 Average loss: 0.1663\n",
      "2019-04-10 01:03:06,352 root         INFO     Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 0.174123\n",
      "Reconstruction: 0.173503, Regularization: 0.000621\n",
      "2019-04-10 01:03:06,415 root         INFO     Train Epoch: 109 [512/8000 (6%)]\tTotal Loss: 0.179080\n",
      "Reconstruction: 0.178471, Regularization: 0.000609\n",
      "2019-04-10 01:03:06,478 root         INFO     Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 0.169089\n",
      "Reconstruction: 0.168653, Regularization: 0.000436\n",
      "2019-04-10 01:03:06,541 root         INFO     Train Epoch: 109 [1536/8000 (19%)]\tTotal Loss: 0.184875\n",
      "Reconstruction: 0.184166, Regularization: 0.000709\n",
      "2019-04-10 01:03:06,604 root         INFO     Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 0.170621\n",
      "Reconstruction: 0.170169, Regularization: 0.000452\n",
      "2019-04-10 01:03:06,668 root         INFO     Train Epoch: 109 [2560/8000 (32%)]\tTotal Loss: 0.171019\n",
      "Reconstruction: 0.170483, Regularization: 0.000536\n",
      "2019-04-10 01:03:06,731 root         INFO     Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 0.167987\n",
      "Reconstruction: 0.167565, Regularization: 0.000422\n",
      "2019-04-10 01:03:06,794 root         INFO     Train Epoch: 109 [3584/8000 (45%)]\tTotal Loss: 0.183102\n",
      "Reconstruction: 0.182368, Regularization: 0.000735\n",
      "2019-04-10 01:03:06,856 root         INFO     Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 0.157338\n",
      "Reconstruction: 0.157000, Regularization: 0.000338\n",
      "2019-04-10 01:03:06,918 root         INFO     Train Epoch: 109 [4608/8000 (58%)]\tTotal Loss: 0.161645\n",
      "Reconstruction: 0.161267, Regularization: 0.000378\n",
      "2019-04-10 01:03:06,980 root         INFO     Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 0.165765\n",
      "Reconstruction: 0.165378, Regularization: 0.000387\n",
      "2019-04-10 01:03:07,042 root         INFO     Train Epoch: 109 [5632/8000 (70%)]\tTotal Loss: 0.166902\n",
      "Reconstruction: 0.166459, Regularization: 0.000444\n",
      "2019-04-10 01:03:07,104 root         INFO     Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 0.160426\n",
      "Reconstruction: 0.160026, Regularization: 0.000400\n",
      "2019-04-10 01:03:07,166 root         INFO     Train Epoch: 109 [6656/8000 (83%)]\tTotal Loss: 0.156011\n",
      "Reconstruction: 0.155748, Regularization: 0.000263\n",
      "2019-04-10 01:03:07,228 root         INFO     Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 0.168467\n",
      "Reconstruction: 0.168014, Regularization: 0.000453\n",
      "2019-04-10 01:03:07,291 root         INFO     Train Epoch: 109 [7680/8000 (96%)]\tTotal Loss: 0.180364\n",
      "Reconstruction: 0.179834, Regularization: 0.000530\n",
      "2019-04-10 01:03:07,344 root         INFO     ====> Epoch: 109 Average loss: 0.1662\n",
      "2019-04-10 01:03:07,367 root         INFO     Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 0.158041\n",
      "Reconstruction: 0.157695, Regularization: 0.000346\n",
      "2019-04-10 01:03:07,431 root         INFO     Train Epoch: 110 [512/8000 (6%)]\tTotal Loss: 0.164473\n",
      "Reconstruction: 0.164081, Regularization: 0.000393\n",
      "2019-04-10 01:03:07,494 root         INFO     Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 0.162838\n",
      "Reconstruction: 0.162392, Regularization: 0.000446\n",
      "2019-04-10 01:03:07,557 root         INFO     Train Epoch: 110 [1536/8000 (19%)]\tTotal Loss: 0.160040\n",
      "Reconstruction: 0.159658, Regularization: 0.000381\n",
      "2019-04-10 01:03:07,619 root         INFO     Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 0.166375\n",
      "Reconstruction: 0.165859, Regularization: 0.000516\n",
      "2019-04-10 01:03:07,682 root         INFO     Train Epoch: 110 [2560/8000 (32%)]\tTotal Loss: 0.148042\n",
      "Reconstruction: 0.147815, Regularization: 0.000227\n",
      "2019-04-10 01:03:07,744 root         INFO     Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 0.178356\n",
      "Reconstruction: 0.177830, Regularization: 0.000527\n",
      "2019-04-10 01:03:07,807 root         INFO     Train Epoch: 110 [3584/8000 (45%)]\tTotal Loss: 0.163233\n",
      "Reconstruction: 0.162752, Regularization: 0.000481\n",
      "2019-04-10 01:03:07,869 root         INFO     Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 0.160753\n",
      "Reconstruction: 0.160444, Regularization: 0.000309\n",
      "2019-04-10 01:03:07,932 root         INFO     Train Epoch: 110 [4608/8000 (58%)]\tTotal Loss: 0.167251\n",
      "Reconstruction: 0.166808, Regularization: 0.000443\n",
      "2019-04-10 01:03:07,995 root         INFO     Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 0.178533\n",
      "Reconstruction: 0.177967, Regularization: 0.000566\n",
      "2019-04-10 01:03:08,057 root         INFO     Train Epoch: 110 [5632/8000 (70%)]\tTotal Loss: 0.159235\n",
      "Reconstruction: 0.158836, Regularization: 0.000399\n",
      "2019-04-10 01:03:08,120 root         INFO     Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 0.158791\n",
      "Reconstruction: 0.158452, Regularization: 0.000340\n",
      "2019-04-10 01:03:08,183 root         INFO     Train Epoch: 110 [6656/8000 (83%)]\tTotal Loss: 0.173399\n",
      "Reconstruction: 0.172808, Regularization: 0.000591\n",
      "2019-04-10 01:03:08,246 root         INFO     Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 0.167651\n",
      "Reconstruction: 0.167110, Regularization: 0.000541\n",
      "2019-04-10 01:03:08,308 root         INFO     Train Epoch: 110 [7680/8000 (96%)]\tTotal Loss: 0.155633\n",
      "Reconstruction: 0.155335, Regularization: 0.000298\n",
      "2019-04-10 01:03:08,362 root         INFO     ====> Epoch: 110 Average loss: 0.1662\n",
      "2019-04-10 01:03:08,386 root         INFO     Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 0.167667\n",
      "Reconstruction: 0.167198, Regularization: 0.000469\n",
      "2019-04-10 01:03:08,449 root         INFO     Train Epoch: 111 [512/8000 (6%)]\tTotal Loss: 0.173397\n",
      "Reconstruction: 0.172855, Regularization: 0.000542\n",
      "2019-04-10 01:03:08,512 root         INFO     Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 0.171603\n",
      "Reconstruction: 0.171033, Regularization: 0.000570\n",
      "2019-04-10 01:03:08,575 root         INFO     Train Epoch: 111 [1536/8000 (19%)]\tTotal Loss: 0.172947\n",
      "Reconstruction: 0.172303, Regularization: 0.000644\n",
      "2019-04-10 01:03:08,638 root         INFO     Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 0.153747\n",
      "Reconstruction: 0.153505, Regularization: 0.000243\n",
      "2019-04-10 01:03:08,699 root         INFO     Train Epoch: 111 [2560/8000 (32%)]\tTotal Loss: 0.167517\n",
      "Reconstruction: 0.166916, Regularization: 0.000601\n",
      "2019-04-10 01:03:08,761 root         INFO     Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 0.164208\n",
      "Reconstruction: 0.163747, Regularization: 0.000461\n",
      "2019-04-10 01:03:08,823 root         INFO     Train Epoch: 111 [3584/8000 (45%)]\tTotal Loss: 0.165933\n",
      "Reconstruction: 0.165453, Regularization: 0.000480\n",
      "2019-04-10 01:03:08,884 root         INFO     Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 0.168747\n",
      "Reconstruction: 0.168230, Regularization: 0.000517\n",
      "2019-04-10 01:03:08,946 root         INFO     Train Epoch: 111 [4608/8000 (58%)]\tTotal Loss: 0.162623\n",
      "Reconstruction: 0.162266, Regularization: 0.000356\n",
      "2019-04-10 01:03:09,007 root         INFO     Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 0.172623\n",
      "Reconstruction: 0.172081, Regularization: 0.000541\n",
      "2019-04-10 01:03:09,069 root         INFO     Train Epoch: 111 [5632/8000 (70%)]\tTotal Loss: 0.160541\n",
      "Reconstruction: 0.160202, Regularization: 0.000339\n",
      "2019-04-10 01:03:09,130 root         INFO     Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 0.159649\n",
      "Reconstruction: 0.159308, Regularization: 0.000341\n",
      "2019-04-10 01:03:09,192 root         INFO     Train Epoch: 111 [6656/8000 (83%)]\tTotal Loss: 0.159785\n",
      "Reconstruction: 0.159441, Regularization: 0.000345\n",
      "2019-04-10 01:03:09,253 root         INFO     Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 0.155148\n",
      "Reconstruction: 0.154813, Regularization: 0.000335\n",
      "2019-04-10 01:03:09,315 root         INFO     Train Epoch: 111 [7680/8000 (96%)]\tTotal Loss: 0.166747\n",
      "Reconstruction: 0.166276, Regularization: 0.000471\n",
      "2019-04-10 01:03:09,369 root         INFO     ====> Epoch: 111 Average loss: 0.1663\n",
      "2019-04-10 01:03:09,393 root         INFO     Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 0.163442\n",
      "Reconstruction: 0.163056, Regularization: 0.000387\n",
      "2019-04-10 01:03:09,455 root         INFO     Train Epoch: 112 [512/8000 (6%)]\tTotal Loss: 0.175664\n",
      "Reconstruction: 0.175022, Regularization: 0.000641\n",
      "2019-04-10 01:03:09,519 root         INFO     Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 0.181056\n",
      "Reconstruction: 0.180229, Regularization: 0.000827\n",
      "2019-04-10 01:03:09,582 root         INFO     Train Epoch: 112 [1536/8000 (19%)]\tTotal Loss: 0.155269\n",
      "Reconstruction: 0.154923, Regularization: 0.000346\n",
      "2019-04-10 01:03:09,646 root         INFO     Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 0.165976\n",
      "Reconstruction: 0.165474, Regularization: 0.000502\n",
      "2019-04-10 01:03:09,709 root         INFO     Train Epoch: 112 [2560/8000 (32%)]\tTotal Loss: 0.165574\n",
      "Reconstruction: 0.165072, Regularization: 0.000502\n",
      "2019-04-10 01:03:09,773 root         INFO     Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 0.163004\n",
      "Reconstruction: 0.162547, Regularization: 0.000456\n",
      "2019-04-10 01:03:09,836 root         INFO     Train Epoch: 112 [3584/8000 (45%)]\tTotal Loss: 0.159708\n",
      "Reconstruction: 0.159293, Regularization: 0.000415\n",
      "2019-04-10 01:03:09,899 root         INFO     Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 0.163372\n",
      "Reconstruction: 0.162883, Regularization: 0.000489\n",
      "2019-04-10 01:03:09,964 root         INFO     Train Epoch: 112 [4608/8000 (58%)]\tTotal Loss: 0.165184\n",
      "Reconstruction: 0.164718, Regularization: 0.000466\n",
      "2019-04-10 01:03:10,028 root         INFO     Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 0.187387\n",
      "Reconstruction: 0.186549, Regularization: 0.000838\n",
      "2019-04-10 01:03:10,090 root         INFO     Train Epoch: 112 [5632/8000 (70%)]\tTotal Loss: 0.179232\n",
      "Reconstruction: 0.178539, Regularization: 0.000693\n",
      "2019-04-10 01:03:10,152 root         INFO     Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 0.172676\n",
      "Reconstruction: 0.172027, Regularization: 0.000649\n",
      "2019-04-10 01:03:10,214 root         INFO     Train Epoch: 112 [6656/8000 (83%)]\tTotal Loss: 0.168319\n",
      "Reconstruction: 0.167826, Regularization: 0.000492\n",
      "2019-04-10 01:03:10,276 root         INFO     Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 0.176004\n",
      "Reconstruction: 0.175282, Regularization: 0.000723\n",
      "2019-04-10 01:03:10,339 root         INFO     Train Epoch: 112 [7680/8000 (96%)]\tTotal Loss: 0.157767\n",
      "Reconstruction: 0.157351, Regularization: 0.000416\n",
      "2019-04-10 01:03:10,393 root         INFO     ====> Epoch: 112 Average loss: 0.1663\n",
      "2019-04-10 01:03:10,417 root         INFO     Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 0.157905\n",
      "Reconstruction: 0.157581, Regularization: 0.000324\n",
      "2019-04-10 01:03:10,480 root         INFO     Train Epoch: 113 [512/8000 (6%)]\tTotal Loss: 0.167154\n",
      "Reconstruction: 0.166645, Regularization: 0.000509\n",
      "2019-04-10 01:03:10,544 root         INFO     Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 0.162389\n",
      "Reconstruction: 0.161988, Regularization: 0.000401\n",
      "2019-04-10 01:03:10,608 root         INFO     Train Epoch: 113 [1536/8000 (19%)]\tTotal Loss: 0.166842\n",
      "Reconstruction: 0.166311, Regularization: 0.000531\n",
      "2019-04-10 01:03:10,670 root         INFO     Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 0.168770\n",
      "Reconstruction: 0.168172, Regularization: 0.000598\n",
      "2019-04-10 01:03:10,733 root         INFO     Train Epoch: 113 [2560/8000 (32%)]\tTotal Loss: 0.173741\n",
      "Reconstruction: 0.173128, Regularization: 0.000613\n",
      "2019-04-10 01:03:10,795 root         INFO     Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 0.162028\n",
      "Reconstruction: 0.161635, Regularization: 0.000393\n",
      "2019-04-10 01:03:10,859 root         INFO     Train Epoch: 113 [3584/8000 (45%)]\tTotal Loss: 0.158353\n",
      "Reconstruction: 0.158030, Regularization: 0.000323\n",
      "2019-04-10 01:03:10,923 root         INFO     Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 0.173013\n",
      "Reconstruction: 0.172368, Regularization: 0.000645\n",
      "2019-04-10 01:03:10,987 root         INFO     Train Epoch: 113 [4608/8000 (58%)]\tTotal Loss: 0.163273\n",
      "Reconstruction: 0.162768, Regularization: 0.000505\n",
      "2019-04-10 01:03:11,051 root         INFO     Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 0.163627\n",
      "Reconstruction: 0.163223, Regularization: 0.000404\n",
      "2019-04-10 01:03:11,115 root         INFO     Train Epoch: 113 [5632/8000 (70%)]\tTotal Loss: 0.160010\n",
      "Reconstruction: 0.159671, Regularization: 0.000339\n",
      "2019-04-10 01:03:11,179 root         INFO     Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 0.166328\n",
      "Reconstruction: 0.165843, Regularization: 0.000485\n",
      "2019-04-10 01:03:11,243 root         INFO     Train Epoch: 113 [6656/8000 (83%)]\tTotal Loss: 0.165552\n",
      "Reconstruction: 0.164979, Regularization: 0.000573\n",
      "2019-04-10 01:03:11,307 root         INFO     Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 0.177135\n",
      "Reconstruction: 0.176425, Regularization: 0.000710\n",
      "2019-04-10 01:03:11,371 root         INFO     Train Epoch: 113 [7680/8000 (96%)]\tTotal Loss: 0.159671\n",
      "Reconstruction: 0.159250, Regularization: 0.000421\n",
      "2019-04-10 01:03:11,425 root         INFO     ====> Epoch: 113 Average loss: 0.1662\n",
      "2019-04-10 01:03:11,449 root         INFO     Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 0.165270\n",
      "Reconstruction: 0.164797, Regularization: 0.000473\n",
      "2019-04-10 01:03:11,515 root         INFO     Train Epoch: 114 [512/8000 (6%)]\tTotal Loss: 0.163766\n",
      "Reconstruction: 0.163257, Regularization: 0.000509\n",
      "2019-04-10 01:03:11,579 root         INFO     Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 0.175112\n",
      "Reconstruction: 0.174460, Regularization: 0.000652\n",
      "2019-04-10 01:03:11,643 root         INFO     Train Epoch: 114 [1536/8000 (19%)]\tTotal Loss: 0.152625\n",
      "Reconstruction: 0.152346, Regularization: 0.000279\n",
      "2019-04-10 01:03:11,707 root         INFO     Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 0.162811\n",
      "Reconstruction: 0.162378, Regularization: 0.000432\n",
      "2019-04-10 01:03:11,771 root         INFO     Train Epoch: 114 [2560/8000 (32%)]\tTotal Loss: 0.177167\n",
      "Reconstruction: 0.176561, Regularization: 0.000606\n",
      "2019-04-10 01:03:11,835 root         INFO     Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 0.163201\n",
      "Reconstruction: 0.162763, Regularization: 0.000438\n",
      "2019-04-10 01:03:11,898 root         INFO     Train Epoch: 114 [3584/8000 (45%)]\tTotal Loss: 0.167643\n",
      "Reconstruction: 0.167079, Regularization: 0.000564\n",
      "2019-04-10 01:03:11,963 root         INFO     Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 0.160627\n",
      "Reconstruction: 0.160218, Regularization: 0.000409\n",
      "2019-04-10 01:03:12,027 root         INFO     Train Epoch: 114 [4608/8000 (58%)]\tTotal Loss: 0.170886\n",
      "Reconstruction: 0.170266, Regularization: 0.000620\n",
      "2019-04-10 01:03:12,090 root         INFO     Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 0.171025\n",
      "Reconstruction: 0.170430, Regularization: 0.000595\n",
      "2019-04-10 01:03:12,155 root         INFO     Train Epoch: 114 [5632/8000 (70%)]\tTotal Loss: 0.174037\n",
      "Reconstruction: 0.173341, Regularization: 0.000695\n",
      "2019-04-10 01:03:12,219 root         INFO     Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 0.164231\n",
      "Reconstruction: 0.163646, Regularization: 0.000586\n",
      "2019-04-10 01:03:12,283 root         INFO     Train Epoch: 114 [6656/8000 (83%)]\tTotal Loss: 0.165377\n",
      "Reconstruction: 0.164967, Regularization: 0.000411\n",
      "2019-04-10 01:03:12,346 root         INFO     Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 0.159946\n",
      "Reconstruction: 0.159529, Regularization: 0.000417\n",
      "2019-04-10 01:03:12,410 root         INFO     Train Epoch: 114 [7680/8000 (96%)]\tTotal Loss: 0.170273\n",
      "Reconstruction: 0.169774, Regularization: 0.000499\n",
      "2019-04-10 01:03:12,463 root         INFO     ====> Epoch: 114 Average loss: 0.1662\n",
      "2019-04-10 01:03:12,487 root         INFO     Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 0.155075\n",
      "Reconstruction: 0.154645, Regularization: 0.000431\n",
      "2019-04-10 01:03:12,551 root         INFO     Train Epoch: 115 [512/8000 (6%)]\tTotal Loss: 0.178446\n",
      "Reconstruction: 0.177727, Regularization: 0.000719\n",
      "2019-04-10 01:03:12,615 root         INFO     Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 0.175749\n",
      "Reconstruction: 0.175097, Regularization: 0.000652\n",
      "2019-04-10 01:03:12,679 root         INFO     Train Epoch: 115 [1536/8000 (19%)]\tTotal Loss: 0.159776\n",
      "Reconstruction: 0.159354, Regularization: 0.000422\n",
      "2019-04-10 01:03:12,743 root         INFO     Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 0.183660\n",
      "Reconstruction: 0.182928, Regularization: 0.000732\n",
      "2019-04-10 01:03:12,807 root         INFO     Train Epoch: 115 [2560/8000 (32%)]\tTotal Loss: 0.169510\n",
      "Reconstruction: 0.168916, Regularization: 0.000594\n",
      "2019-04-10 01:03:12,870 root         INFO     Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 0.178823\n",
      "Reconstruction: 0.178154, Regularization: 0.000669\n",
      "2019-04-10 01:03:12,933 root         INFO     Train Epoch: 115 [3584/8000 (45%)]\tTotal Loss: 0.162366\n",
      "Reconstruction: 0.161908, Regularization: 0.000459\n",
      "2019-04-10 01:03:12,997 root         INFO     Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 0.169526\n",
      "Reconstruction: 0.169062, Regularization: 0.000464\n",
      "2019-04-10 01:03:13,061 root         INFO     Train Epoch: 115 [4608/8000 (58%)]\tTotal Loss: 0.176594\n",
      "Reconstruction: 0.175944, Regularization: 0.000650\n",
      "2019-04-10 01:03:13,124 root         INFO     Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 0.169786\n",
      "Reconstruction: 0.169176, Regularization: 0.000610\n",
      "2019-04-10 01:03:13,188 root         INFO     Train Epoch: 115 [5632/8000 (70%)]\tTotal Loss: 0.168943\n",
      "Reconstruction: 0.168383, Regularization: 0.000560\n",
      "2019-04-10 01:03:13,251 root         INFO     Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 0.165706\n",
      "Reconstruction: 0.165182, Regularization: 0.000524\n",
      "2019-04-10 01:03:13,314 root         INFO     Train Epoch: 115 [6656/8000 (83%)]\tTotal Loss: 0.164598\n",
      "Reconstruction: 0.164168, Regularization: 0.000431\n",
      "2019-04-10 01:03:13,377 root         INFO     Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 0.168152\n",
      "Reconstruction: 0.167494, Regularization: 0.000658\n",
      "2019-04-10 01:03:13,441 root         INFO     Train Epoch: 115 [7680/8000 (96%)]\tTotal Loss: 0.177339\n",
      "Reconstruction: 0.176683, Regularization: 0.000656\n",
      "2019-04-10 01:03:13,494 root         INFO     ====> Epoch: 115 Average loss: 0.1662\n",
      "2019-04-10 01:03:13,519 root         INFO     Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 0.177438\n",
      "Reconstruction: 0.176735, Regularization: 0.000703\n",
      "2019-04-10 01:03:13,582 root         INFO     Train Epoch: 116 [512/8000 (6%)]\tTotal Loss: 0.174344\n",
      "Reconstruction: 0.173758, Regularization: 0.000586\n",
      "2019-04-10 01:03:13,645 root         INFO     Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 0.183299\n",
      "Reconstruction: 0.182378, Regularization: 0.000920\n",
      "2019-04-10 01:03:13,708 root         INFO     Train Epoch: 116 [1536/8000 (19%)]\tTotal Loss: 0.164865\n",
      "Reconstruction: 0.164270, Regularization: 0.000595\n",
      "2019-04-10 01:03:13,771 root         INFO     Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 0.163335\n",
      "Reconstruction: 0.162837, Regularization: 0.000498\n",
      "2019-04-10 01:03:13,834 root         INFO     Train Epoch: 116 [2560/8000 (32%)]\tTotal Loss: 0.163108\n",
      "Reconstruction: 0.162672, Regularization: 0.000437\n",
      "2019-04-10 01:03:13,897 root         INFO     Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 0.171412\n",
      "Reconstruction: 0.170731, Regularization: 0.000681\n",
      "2019-04-10 01:03:13,960 root         INFO     Train Epoch: 116 [3584/8000 (45%)]\tTotal Loss: 0.172743\n",
      "Reconstruction: 0.172143, Regularization: 0.000600\n",
      "2019-04-10 01:03:14,023 root         INFO     Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 0.160473\n",
      "Reconstruction: 0.159975, Regularization: 0.000498\n",
      "2019-04-10 01:03:14,087 root         INFO     Train Epoch: 116 [4608/8000 (58%)]\tTotal Loss: 0.158365\n",
      "Reconstruction: 0.157984, Regularization: 0.000380\n",
      "2019-04-10 01:03:14,148 root         INFO     Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 0.186550\n",
      "Reconstruction: 0.185637, Regularization: 0.000914\n",
      "2019-04-10 01:03:14,209 root         INFO     Train Epoch: 116 [5632/8000 (70%)]\tTotal Loss: 0.166361\n",
      "Reconstruction: 0.165800, Regularization: 0.000562\n",
      "2019-04-10 01:03:14,271 root         INFO     Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 0.160705\n",
      "Reconstruction: 0.160237, Regularization: 0.000469\n",
      "2019-04-10 01:03:14,333 root         INFO     Train Epoch: 116 [6656/8000 (83%)]\tTotal Loss: 0.170408\n",
      "Reconstruction: 0.169802, Regularization: 0.000606\n",
      "2019-04-10 01:03:14,395 root         INFO     Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 0.164815\n",
      "Reconstruction: 0.164339, Regularization: 0.000476\n",
      "2019-04-10 01:03:14,457 root         INFO     Train Epoch: 116 [7680/8000 (96%)]\tTotal Loss: 0.164762\n",
      "Reconstruction: 0.164202, Regularization: 0.000559\n",
      "2019-04-10 01:03:14,510 root         INFO     ====> Epoch: 116 Average loss: 0.1662\n",
      "2019-04-10 01:03:14,534 root         INFO     Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 0.171901\n",
      "Reconstruction: 0.171156, Regularization: 0.000746\n",
      "2019-04-10 01:03:14,597 root         INFO     Train Epoch: 117 [512/8000 (6%)]\tTotal Loss: 0.170962\n",
      "Reconstruction: 0.170243, Regularization: 0.000719\n",
      "2019-04-10 01:03:14,659 root         INFO     Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 0.170335\n",
      "Reconstruction: 0.169697, Regularization: 0.000638\n",
      "2019-04-10 01:03:14,722 root         INFO     Train Epoch: 117 [1536/8000 (19%)]\tTotal Loss: 0.162311\n",
      "Reconstruction: 0.161828, Regularization: 0.000483\n",
      "2019-04-10 01:03:14,784 root         INFO     Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 0.157088\n",
      "Reconstruction: 0.156662, Regularization: 0.000426\n",
      "2019-04-10 01:03:14,847 root         INFO     Train Epoch: 117 [2560/8000 (32%)]\tTotal Loss: 0.168399\n",
      "Reconstruction: 0.167766, Regularization: 0.000634\n",
      "2019-04-10 01:03:14,910 root         INFO     Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 0.156641\n",
      "Reconstruction: 0.156262, Regularization: 0.000379\n",
      "2019-04-10 01:03:14,972 root         INFO     Train Epoch: 117 [3584/8000 (45%)]\tTotal Loss: 0.177405\n",
      "Reconstruction: 0.176711, Regularization: 0.000694\n",
      "2019-04-10 01:03:15,034 root         INFO     Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 0.164373\n",
      "Reconstruction: 0.163800, Regularization: 0.000573\n",
      "2019-04-10 01:03:15,097 root         INFO     Train Epoch: 117 [4608/8000 (58%)]\tTotal Loss: 0.161592\n",
      "Reconstruction: 0.161065, Regularization: 0.000526\n",
      "2019-04-10 01:03:15,159 root         INFO     Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 0.176265\n",
      "Reconstruction: 0.175527, Regularization: 0.000737\n",
      "2019-04-10 01:03:15,222 root         INFO     Train Epoch: 117 [5632/8000 (70%)]\tTotal Loss: 0.166515\n",
      "Reconstruction: 0.165861, Regularization: 0.000653\n",
      "2019-04-10 01:03:15,284 root         INFO     Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 0.155948\n",
      "Reconstruction: 0.155508, Regularization: 0.000440\n",
      "2019-04-10 01:03:15,346 root         INFO     Train Epoch: 117 [6656/8000 (83%)]\tTotal Loss: 0.173862\n",
      "Reconstruction: 0.173085, Regularization: 0.000778\n",
      "2019-04-10 01:03:15,409 root         INFO     Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 0.152899\n",
      "Reconstruction: 0.152556, Regularization: 0.000343\n",
      "2019-04-10 01:03:15,472 root         INFO     Train Epoch: 117 [7680/8000 (96%)]\tTotal Loss: 0.155382\n",
      "Reconstruction: 0.154962, Regularization: 0.000420\n",
      "2019-04-10 01:03:15,525 root         INFO     ====> Epoch: 117 Average loss: 0.1663\n",
      "2019-04-10 01:03:15,549 root         INFO     Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 0.168668\n",
      "Reconstruction: 0.168022, Regularization: 0.000646\n",
      "2019-04-10 01:03:15,613 root         INFO     Train Epoch: 118 [512/8000 (6%)]\tTotal Loss: 0.163078\n",
      "Reconstruction: 0.162535, Regularization: 0.000543\n",
      "2019-04-10 01:03:15,675 root         INFO     Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 0.170415\n",
      "Reconstruction: 0.169780, Regularization: 0.000635\n",
      "2019-04-10 01:03:15,738 root         INFO     Train Epoch: 118 [1536/8000 (19%)]\tTotal Loss: 0.172545\n",
      "Reconstruction: 0.171762, Regularization: 0.000783\n",
      "2019-04-10 01:03:15,800 root         INFO     Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 0.163792\n",
      "Reconstruction: 0.163243, Regularization: 0.000549\n",
      "2019-04-10 01:03:15,863 root         INFO     Train Epoch: 118 [2560/8000 (32%)]\tTotal Loss: 0.166920\n",
      "Reconstruction: 0.166332, Regularization: 0.000588\n",
      "2019-04-10 01:03:15,925 root         INFO     Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 0.151636\n",
      "Reconstruction: 0.151341, Regularization: 0.000295\n",
      "2019-04-10 01:03:15,988 root         INFO     Train Epoch: 118 [3584/8000 (45%)]\tTotal Loss: 0.190971\n",
      "Reconstruction: 0.189899, Regularization: 0.001071\n",
      "2019-04-10 01:03:16,050 root         INFO     Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 0.170440\n",
      "Reconstruction: 0.169793, Regularization: 0.000647\n",
      "2019-04-10 01:03:16,113 root         INFO     Train Epoch: 118 [4608/8000 (58%)]\tTotal Loss: 0.160421\n",
      "Reconstruction: 0.159975, Regularization: 0.000446\n",
      "2019-04-10 01:03:16,175 root         INFO     Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 0.167093\n",
      "Reconstruction: 0.166446, Regularization: 0.000647\n",
      "2019-04-10 01:03:16,238 root         INFO     Train Epoch: 118 [5632/8000 (70%)]\tTotal Loss: 0.164862\n",
      "Reconstruction: 0.164249, Regularization: 0.000613\n",
      "2019-04-10 01:03:16,301 root         INFO     Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 0.168633\n",
      "Reconstruction: 0.167982, Regularization: 0.000651\n",
      "2019-04-10 01:03:16,364 root         INFO     Train Epoch: 118 [6656/8000 (83%)]\tTotal Loss: 0.162245\n",
      "Reconstruction: 0.161739, Regularization: 0.000506\n",
      "2019-04-10 01:03:16,427 root         INFO     Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 0.175533\n",
      "Reconstruction: 0.174775, Regularization: 0.000758\n",
      "2019-04-10 01:03:16,489 root         INFO     Train Epoch: 118 [7680/8000 (96%)]\tTotal Loss: 0.157248\n",
      "Reconstruction: 0.156801, Regularization: 0.000447\n",
      "2019-04-10 01:03:16,543 root         INFO     ====> Epoch: 118 Average loss: 0.1664\n",
      "2019-04-10 01:03:16,568 root         INFO     Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 0.166836\n",
      "Reconstruction: 0.166285, Regularization: 0.000552\n",
      "2019-04-10 01:03:16,631 root         INFO     Train Epoch: 119 [512/8000 (6%)]\tTotal Loss: 0.158924\n",
      "Reconstruction: 0.158443, Regularization: 0.000480\n",
      "2019-04-10 01:03:16,695 root         INFO     Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 0.158187\n",
      "Reconstruction: 0.157716, Regularization: 0.000472\n",
      "2019-04-10 01:03:16,758 root         INFO     Train Epoch: 119 [1536/8000 (19%)]\tTotal Loss: 0.164139\n",
      "Reconstruction: 0.163565, Regularization: 0.000575\n",
      "2019-04-10 01:03:16,822 root         INFO     Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 0.163573\n",
      "Reconstruction: 0.163068, Regularization: 0.000504\n",
      "2019-04-10 01:03:16,886 root         INFO     Train Epoch: 119 [2560/8000 (32%)]\tTotal Loss: 0.167511\n",
      "Reconstruction: 0.166927, Regularization: 0.000584\n",
      "2019-04-10 01:03:16,949 root         INFO     Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 0.161481\n",
      "Reconstruction: 0.160976, Regularization: 0.000504\n",
      "2019-04-10 01:03:17,012 root         INFO     Train Epoch: 119 [3584/8000 (45%)]\tTotal Loss: 0.167942\n",
      "Reconstruction: 0.167401, Regularization: 0.000541\n",
      "2019-04-10 01:03:17,075 root         INFO     Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 0.172135\n",
      "Reconstruction: 0.171431, Regularization: 0.000704\n",
      "2019-04-10 01:03:17,139 root         INFO     Train Epoch: 119 [4608/8000 (58%)]\tTotal Loss: 0.175520\n",
      "Reconstruction: 0.174647, Regularization: 0.000872\n",
      "2019-04-10 01:03:17,202 root         INFO     Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 0.163961\n",
      "Reconstruction: 0.163427, Regularization: 0.000535\n",
      "2019-04-10 01:03:17,264 root         INFO     Train Epoch: 119 [5632/8000 (70%)]\tTotal Loss: 0.155876\n",
      "Reconstruction: 0.155462, Regularization: 0.000414\n",
      "2019-04-10 01:03:17,327 root         INFO     Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 0.165942\n",
      "Reconstruction: 0.165316, Regularization: 0.000626\n",
      "2019-04-10 01:03:17,390 root         INFO     Train Epoch: 119 [6656/8000 (83%)]\tTotal Loss: 0.158323\n",
      "Reconstruction: 0.157849, Regularization: 0.000474\n",
      "2019-04-10 01:03:17,453 root         INFO     Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 0.161764\n",
      "Reconstruction: 0.161284, Regularization: 0.000480\n",
      "2019-04-10 01:03:17,515 root         INFO     Train Epoch: 119 [7680/8000 (96%)]\tTotal Loss: 0.157743\n",
      "Reconstruction: 0.157293, Regularization: 0.000450\n",
      "2019-04-10 01:03:17,569 root         INFO     ====> Epoch: 119 Average loss: 0.1662\n",
      "2019-04-10 01:03:17,594 root         INFO     Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 0.167829\n",
      "Reconstruction: 0.167192, Regularization: 0.000637\n",
      "2019-04-10 01:03:17,656 root         INFO     Train Epoch: 120 [512/8000 (6%)]\tTotal Loss: 0.164022\n",
      "Reconstruction: 0.163518, Regularization: 0.000504\n",
      "2019-04-10 01:03:17,719 root         INFO     Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 0.162189\n",
      "Reconstruction: 0.161715, Regularization: 0.000474\n",
      "2019-04-10 01:03:17,781 root         INFO     Train Epoch: 120 [1536/8000 (19%)]\tTotal Loss: 0.168191\n",
      "Reconstruction: 0.167538, Regularization: 0.000653\n",
      "2019-04-10 01:03:17,843 root         INFO     Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 0.151547\n",
      "Reconstruction: 0.151207, Regularization: 0.000339\n",
      "2019-04-10 01:03:17,905 root         INFO     Train Epoch: 120 [2560/8000 (32%)]\tTotal Loss: 0.177945\n",
      "Reconstruction: 0.177225, Regularization: 0.000720\n",
      "2019-04-10 01:03:17,967 root         INFO     Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 0.181647\n",
      "Reconstruction: 0.180758, Regularization: 0.000889\n",
      "2019-04-10 01:03:18,030 root         INFO     Train Epoch: 120 [3584/8000 (45%)]\tTotal Loss: 0.170195\n",
      "Reconstruction: 0.169531, Regularization: 0.000664\n",
      "2019-04-10 01:03:18,092 root         INFO     Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 0.169601\n",
      "Reconstruction: 0.169004, Regularization: 0.000597\n",
      "2019-04-10 01:03:18,154 root         INFO     Train Epoch: 120 [4608/8000 (58%)]\tTotal Loss: 0.158436\n",
      "Reconstruction: 0.158011, Regularization: 0.000425\n",
      "2019-04-10 01:03:18,216 root         INFO     Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 0.158450\n",
      "Reconstruction: 0.157991, Regularization: 0.000459\n",
      "2019-04-10 01:03:18,278 root         INFO     Train Epoch: 120 [5632/8000 (70%)]\tTotal Loss: 0.163493\n",
      "Reconstruction: 0.162933, Regularization: 0.000560\n",
      "2019-04-10 01:03:18,340 root         INFO     Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 0.157097\n",
      "Reconstruction: 0.156648, Regularization: 0.000449\n",
      "2019-04-10 01:03:18,402 root         INFO     Train Epoch: 120 [6656/8000 (83%)]\tTotal Loss: 0.158960\n",
      "Reconstruction: 0.158506, Regularization: 0.000454\n",
      "2019-04-10 01:03:18,464 root         INFO     Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 0.169286\n",
      "Reconstruction: 0.168607, Regularization: 0.000678\n",
      "2019-04-10 01:03:18,527 root         INFO     Train Epoch: 120 [7680/8000 (96%)]\tTotal Loss: 0.150397\n",
      "Reconstruction: 0.150138, Regularization: 0.000260\n",
      "2019-04-10 01:03:18,581 root         INFO     ====> Epoch: 120 Average loss: 0.1661\n",
      "2019-04-10 01:03:18,605 root         INFO     Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 0.159802\n",
      "Reconstruction: 0.159291, Regularization: 0.000512\n",
      "2019-04-10 01:03:18,668 root         INFO     Train Epoch: 121 [512/8000 (6%)]\tTotal Loss: 0.158695\n",
      "Reconstruction: 0.158195, Regularization: 0.000500\n",
      "2019-04-10 01:03:18,732 root         INFO     Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 0.171277\n",
      "Reconstruction: 0.170571, Regularization: 0.000706\n",
      "2019-04-10 01:03:18,795 root         INFO     Train Epoch: 121 [1536/8000 (19%)]\tTotal Loss: 0.158531\n",
      "Reconstruction: 0.158114, Regularization: 0.000417\n",
      "2019-04-10 01:03:18,858 root         INFO     Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 0.165791\n",
      "Reconstruction: 0.165237, Regularization: 0.000555\n",
      "2019-04-10 01:03:18,921 root         INFO     Train Epoch: 121 [2560/8000 (32%)]\tTotal Loss: 0.171470\n",
      "Reconstruction: 0.170696, Regularization: 0.000774\n",
      "2019-04-10 01:03:18,984 root         INFO     Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 0.172421\n",
      "Reconstruction: 0.171815, Regularization: 0.000605\n",
      "2019-04-10 01:03:19,046 root         INFO     Train Epoch: 121 [3584/8000 (45%)]\tTotal Loss: 0.172710\n",
      "Reconstruction: 0.172005, Regularization: 0.000705\n",
      "2019-04-10 01:03:19,108 root         INFO     Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 0.167723\n",
      "Reconstruction: 0.167078, Regularization: 0.000646\n",
      "2019-04-10 01:03:19,169 root         INFO     Train Epoch: 121 [4608/8000 (58%)]\tTotal Loss: 0.169034\n",
      "Reconstruction: 0.168271, Regularization: 0.000764\n",
      "2019-04-10 01:03:19,231 root         INFO     Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 0.162710\n",
      "Reconstruction: 0.162174, Regularization: 0.000536\n",
      "2019-04-10 01:03:19,293 root         INFO     Train Epoch: 121 [5632/8000 (70%)]\tTotal Loss: 0.169910\n",
      "Reconstruction: 0.169133, Regularization: 0.000776\n",
      "2019-04-10 01:03:19,356 root         INFO     Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 0.173506\n",
      "Reconstruction: 0.172616, Regularization: 0.000891\n",
      "2019-04-10 01:03:19,418 root         INFO     Train Epoch: 121 [6656/8000 (83%)]\tTotal Loss: 0.157689\n",
      "Reconstruction: 0.157290, Regularization: 0.000398\n",
      "2019-04-10 01:03:19,480 root         INFO     Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 0.165685\n",
      "Reconstruction: 0.165059, Regularization: 0.000626\n",
      "2019-04-10 01:03:19,542 root         INFO     Train Epoch: 121 [7680/8000 (96%)]\tTotal Loss: 0.169444\n",
      "Reconstruction: 0.168815, Regularization: 0.000629\n",
      "2019-04-10 01:03:19,595 root         INFO     ====> Epoch: 121 Average loss: 0.1663\n",
      "2019-04-10 01:03:19,619 root         INFO     Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 0.159354\n",
      "Reconstruction: 0.158846, Regularization: 0.000508\n",
      "2019-04-10 01:03:19,681 root         INFO     Train Epoch: 122 [512/8000 (6%)]\tTotal Loss: 0.167065\n",
      "Reconstruction: 0.166492, Regularization: 0.000573\n",
      "2019-04-10 01:03:19,742 root         INFO     Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 0.164423\n",
      "Reconstruction: 0.163826, Regularization: 0.000597\n",
      "2019-04-10 01:03:19,804 root         INFO     Train Epoch: 122 [1536/8000 (19%)]\tTotal Loss: 0.202439\n",
      "Reconstruction: 0.200987, Regularization: 0.001453\n",
      "2019-04-10 01:03:19,865 root         INFO     Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 0.168650\n",
      "Reconstruction: 0.167977, Regularization: 0.000674\n",
      "2019-04-10 01:03:19,927 root         INFO     Train Epoch: 122 [2560/8000 (32%)]\tTotal Loss: 0.165490\n",
      "Reconstruction: 0.164915, Regularization: 0.000575\n",
      "2019-04-10 01:03:19,989 root         INFO     Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 0.158328\n",
      "Reconstruction: 0.157854, Regularization: 0.000474\n",
      "2019-04-10 01:03:20,050 root         INFO     Train Epoch: 122 [3584/8000 (45%)]\tTotal Loss: 0.173936\n",
      "Reconstruction: 0.173165, Regularization: 0.000770\n",
      "2019-04-10 01:03:20,112 root         INFO     Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 0.181842\n",
      "Reconstruction: 0.181020, Regularization: 0.000821\n",
      "2019-04-10 01:03:20,174 root         INFO     Train Epoch: 122 [4608/8000 (58%)]\tTotal Loss: 0.170695\n",
      "Reconstruction: 0.169981, Regularization: 0.000715\n",
      "2019-04-10 01:03:20,236 root         INFO     Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 0.168817\n",
      "Reconstruction: 0.168224, Regularization: 0.000593\n",
      "2019-04-10 01:03:20,297 root         INFO     Train Epoch: 122 [5632/8000 (70%)]\tTotal Loss: 0.155797\n",
      "Reconstruction: 0.155399, Regularization: 0.000399\n",
      "2019-04-10 01:03:20,359 root         INFO     Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 0.165903\n",
      "Reconstruction: 0.165238, Regularization: 0.000665\n",
      "2019-04-10 01:03:20,421 root         INFO     Train Epoch: 122 [6656/8000 (83%)]\tTotal Loss: 0.156543\n",
      "Reconstruction: 0.156085, Regularization: 0.000457\n",
      "2019-04-10 01:03:20,482 root         INFO     Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 0.171426\n",
      "Reconstruction: 0.170630, Regularization: 0.000796\n",
      "2019-04-10 01:03:20,543 root         INFO     Train Epoch: 122 [7680/8000 (96%)]\tTotal Loss: 0.163177\n",
      "Reconstruction: 0.162636, Regularization: 0.000540\n",
      "2019-04-10 01:03:20,597 root         INFO     ====> Epoch: 122 Average loss: 0.1662\n",
      "2019-04-10 01:03:20,621 root         INFO     Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 0.175128\n",
      "Reconstruction: 0.174360, Regularization: 0.000768\n",
      "2019-04-10 01:03:20,685 root         INFO     Train Epoch: 123 [512/8000 (6%)]\tTotal Loss: 0.168264\n",
      "Reconstruction: 0.167552, Regularization: 0.000712\n",
      "2019-04-10 01:03:20,748 root         INFO     Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 0.168962\n",
      "Reconstruction: 0.168207, Regularization: 0.000756\n",
      "2019-04-10 01:03:20,811 root         INFO     Train Epoch: 123 [1536/8000 (19%)]\tTotal Loss: 0.158286\n",
      "Reconstruction: 0.157797, Regularization: 0.000489\n",
      "2019-04-10 01:03:20,874 root         INFO     Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 0.175117\n",
      "Reconstruction: 0.174424, Regularization: 0.000693\n",
      "2019-04-10 01:03:20,937 root         INFO     Train Epoch: 123 [2560/8000 (32%)]\tTotal Loss: 0.154308\n",
      "Reconstruction: 0.153945, Regularization: 0.000364\n",
      "2019-04-10 01:03:21,000 root         INFO     Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 0.166351\n",
      "Reconstruction: 0.165689, Regularization: 0.000663\n",
      "2019-04-10 01:03:21,063 root         INFO     Train Epoch: 123 [3584/8000 (45%)]\tTotal Loss: 0.165547\n",
      "Reconstruction: 0.164996, Regularization: 0.000551\n",
      "2019-04-10 01:03:21,126 root         INFO     Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 0.156230\n",
      "Reconstruction: 0.155772, Regularization: 0.000458\n",
      "2019-04-10 01:03:21,189 root         INFO     Train Epoch: 123 [4608/8000 (58%)]\tTotal Loss: 0.175133\n",
      "Reconstruction: 0.174326, Regularization: 0.000807\n",
      "2019-04-10 01:03:21,252 root         INFO     Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 0.172573\n",
      "Reconstruction: 0.171864, Regularization: 0.000709\n",
      "2019-04-10 01:03:21,314 root         INFO     Train Epoch: 123 [5632/8000 (70%)]\tTotal Loss: 0.173424\n",
      "Reconstruction: 0.172635, Regularization: 0.000789\n",
      "2019-04-10 01:03:21,377 root         INFO     Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 0.172057\n",
      "Reconstruction: 0.171393, Regularization: 0.000664\n",
      "2019-04-10 01:03:21,440 root         INFO     Train Epoch: 123 [6656/8000 (83%)]\tTotal Loss: 0.155828\n",
      "Reconstruction: 0.155424, Regularization: 0.000404\n",
      "2019-04-10 01:03:21,502 root         INFO     Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 0.168009\n",
      "Reconstruction: 0.167339, Regularization: 0.000670\n",
      "2019-04-10 01:03:21,566 root         INFO     Train Epoch: 123 [7680/8000 (96%)]\tTotal Loss: 0.158571\n",
      "Reconstruction: 0.158085, Regularization: 0.000486\n",
      "2019-04-10 01:03:21,619 root         INFO     ====> Epoch: 123 Average loss: 0.1661\n",
      "2019-04-10 01:03:21,643 root         INFO     Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 0.170218\n",
      "Reconstruction: 0.169532, Regularization: 0.000686\n",
      "2019-04-10 01:03:21,706 root         INFO     Train Epoch: 124 [512/8000 (6%)]\tTotal Loss: 0.171684\n",
      "Reconstruction: 0.170995, Regularization: 0.000689\n",
      "2019-04-10 01:03:21,769 root         INFO     Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 0.155008\n",
      "Reconstruction: 0.154560, Regularization: 0.000448\n",
      "2019-04-10 01:03:21,832 root         INFO     Train Epoch: 124 [1536/8000 (19%)]\tTotal Loss: 0.169156\n",
      "Reconstruction: 0.168454, Regularization: 0.000702\n",
      "2019-04-10 01:03:21,895 root         INFO     Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 0.162713\n",
      "Reconstruction: 0.162175, Regularization: 0.000539\n",
      "2019-04-10 01:03:21,958 root         INFO     Train Epoch: 124 [2560/8000 (32%)]\tTotal Loss: 0.162675\n",
      "Reconstruction: 0.162121, Regularization: 0.000554\n",
      "2019-04-10 01:03:22,021 root         INFO     Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 0.173406\n",
      "Reconstruction: 0.172611, Regularization: 0.000794\n",
      "2019-04-10 01:03:22,083 root         INFO     Train Epoch: 124 [3584/8000 (45%)]\tTotal Loss: 0.158840\n",
      "Reconstruction: 0.158373, Regularization: 0.000468\n",
      "2019-04-10 01:03:22,146 root         INFO     Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 0.158877\n",
      "Reconstruction: 0.158364, Regularization: 0.000513\n",
      "2019-04-10 01:03:22,208 root         INFO     Train Epoch: 124 [4608/8000 (58%)]\tTotal Loss: 0.166217\n",
      "Reconstruction: 0.165611, Regularization: 0.000606\n",
      "2019-04-10 01:03:22,271 root         INFO     Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 0.163893\n",
      "Reconstruction: 0.163224, Regularization: 0.000669\n",
      "2019-04-10 01:03:22,334 root         INFO     Train Epoch: 124 [5632/8000 (70%)]\tTotal Loss: 0.147686\n",
      "Reconstruction: 0.147423, Regularization: 0.000263\n",
      "2019-04-10 01:03:22,396 root         INFO     Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 0.165809\n",
      "Reconstruction: 0.165180, Regularization: 0.000629\n",
      "2019-04-10 01:03:22,459 root         INFO     Train Epoch: 124 [6656/8000 (83%)]\tTotal Loss: 0.171499\n",
      "Reconstruction: 0.170631, Regularization: 0.000869\n",
      "2019-04-10 01:03:22,522 root         INFO     Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 0.161816\n",
      "Reconstruction: 0.161244, Regularization: 0.000572\n",
      "2019-04-10 01:03:22,585 root         INFO     Train Epoch: 124 [7680/8000 (96%)]\tTotal Loss: 0.156246\n",
      "Reconstruction: 0.155753, Regularization: 0.000493\n",
      "2019-04-10 01:03:22,638 root         INFO     ====> Epoch: 124 Average loss: 0.1661\n",
      "2019-04-10 01:03:22,663 root         INFO     Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 0.176425\n",
      "Reconstruction: 0.175548, Regularization: 0.000878\n",
      "2019-04-10 01:03:22,727 root         INFO     Train Epoch: 125 [512/8000 (6%)]\tTotal Loss: 0.157798\n",
      "Reconstruction: 0.157297, Regularization: 0.000502\n",
      "2019-04-10 01:03:22,790 root         INFO     Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 0.168090\n",
      "Reconstruction: 0.167308, Regularization: 0.000782\n",
      "2019-04-10 01:03:22,853 root         INFO     Train Epoch: 125 [1536/8000 (19%)]\tTotal Loss: 0.182971\n",
      "Reconstruction: 0.181921, Regularization: 0.001050\n",
      "2019-04-10 01:03:22,917 root         INFO     Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 0.165777\n",
      "Reconstruction: 0.165091, Regularization: 0.000686\n",
      "2019-04-10 01:03:22,980 root         INFO     Train Epoch: 125 [2560/8000 (32%)]\tTotal Loss: 0.170009\n",
      "Reconstruction: 0.169230, Regularization: 0.000779\n",
      "2019-04-10 01:03:23,042 root         INFO     Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 0.175378\n",
      "Reconstruction: 0.174430, Regularization: 0.000947\n",
      "2019-04-10 01:03:23,105 root         INFO     Train Epoch: 125 [3584/8000 (45%)]\tTotal Loss: 0.163074\n",
      "Reconstruction: 0.162444, Regularization: 0.000630\n",
      "2019-04-10 01:03:23,167 root         INFO     Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 0.169254\n",
      "Reconstruction: 0.168521, Regularization: 0.000733\n",
      "2019-04-10 01:03:23,230 root         INFO     Train Epoch: 125 [4608/8000 (58%)]\tTotal Loss: 0.158318\n",
      "Reconstruction: 0.157875, Regularization: 0.000443\n",
      "2019-04-10 01:03:23,294 root         INFO     Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 0.170205\n",
      "Reconstruction: 0.169476, Regularization: 0.000730\n",
      "2019-04-10 01:03:23,357 root         INFO     Train Epoch: 125 [5632/8000 (70%)]\tTotal Loss: 0.162296\n",
      "Reconstruction: 0.161721, Regularization: 0.000575\n",
      "2019-04-10 01:03:23,421 root         INFO     Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 0.151613\n",
      "Reconstruction: 0.151283, Regularization: 0.000330\n",
      "2019-04-10 01:03:23,484 root         INFO     Train Epoch: 125 [6656/8000 (83%)]\tTotal Loss: 0.171257\n",
      "Reconstruction: 0.170508, Regularization: 0.000749\n",
      "2019-04-10 01:03:23,546 root         INFO     Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 0.167881\n",
      "Reconstruction: 0.167041, Regularization: 0.000840\n",
      "2019-04-10 01:03:23,610 root         INFO     Train Epoch: 125 [7680/8000 (96%)]\tTotal Loss: 0.170938\n",
      "Reconstruction: 0.170031, Regularization: 0.000906\n",
      "2019-04-10 01:03:23,664 root         INFO     ====> Epoch: 125 Average loss: 0.1661\n",
      "2019-04-10 01:03:23,688 root         INFO     Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 0.172834\n",
      "Reconstruction: 0.171918, Regularization: 0.000915\n",
      "2019-04-10 01:03:23,751 root         INFO     Train Epoch: 126 [512/8000 (6%)]\tTotal Loss: 0.155799\n",
      "Reconstruction: 0.155339, Regularization: 0.000460\n",
      "2019-04-10 01:03:23,814 root         INFO     Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 0.161343\n",
      "Reconstruction: 0.160706, Regularization: 0.000637\n",
      "2019-04-10 01:03:23,878 root         INFO     Train Epoch: 126 [1536/8000 (19%)]\tTotal Loss: 0.169115\n",
      "Reconstruction: 0.168296, Regularization: 0.000819\n",
      "2019-04-10 01:03:23,941 root         INFO     Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 0.161146\n",
      "Reconstruction: 0.160481, Regularization: 0.000665\n",
      "2019-04-10 01:03:24,005 root         INFO     Train Epoch: 126 [2560/8000 (32%)]\tTotal Loss: 0.168095\n",
      "Reconstruction: 0.167385, Regularization: 0.000710\n",
      "2019-04-10 01:03:24,068 root         INFO     Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 0.156476\n",
      "Reconstruction: 0.155925, Regularization: 0.000551\n",
      "2019-04-10 01:03:24,132 root         INFO     Train Epoch: 126 [3584/8000 (45%)]\tTotal Loss: 0.163272\n",
      "Reconstruction: 0.162614, Regularization: 0.000657\n",
      "2019-04-10 01:03:24,196 root         INFO     Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 0.176974\n",
      "Reconstruction: 0.175996, Regularization: 0.000979\n",
      "2019-04-10 01:03:24,260 root         INFO     Train Epoch: 126 [4608/8000 (58%)]\tTotal Loss: 0.166271\n",
      "Reconstruction: 0.165612, Regularization: 0.000659\n",
      "2019-04-10 01:03:24,324 root         INFO     Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 0.170027\n",
      "Reconstruction: 0.169267, Regularization: 0.000760\n",
      "2019-04-10 01:03:24,389 root         INFO     Train Epoch: 126 [5632/8000 (70%)]\tTotal Loss: 0.157819\n",
      "Reconstruction: 0.157291, Regularization: 0.000528\n",
      "2019-04-10 01:03:24,453 root         INFO     Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 0.166839\n",
      "Reconstruction: 0.166040, Regularization: 0.000800\n",
      "2019-04-10 01:03:24,517 root         INFO     Train Epoch: 126 [6656/8000 (83%)]\tTotal Loss: 0.167740\n",
      "Reconstruction: 0.166993, Regularization: 0.000747\n",
      "2019-04-10 01:03:24,582 root         INFO     Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 0.186047\n",
      "Reconstruction: 0.184810, Regularization: 0.001237\n",
      "2019-04-10 01:03:24,646 root         INFO     Train Epoch: 126 [7680/8000 (96%)]\tTotal Loss: 0.172261\n",
      "Reconstruction: 0.171366, Regularization: 0.000895\n",
      "2019-04-10 01:03:24,701 root         INFO     ====> Epoch: 126 Average loss: 0.1663\n",
      "2019-04-10 01:03:24,725 root         INFO     Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 0.157189\n",
      "Reconstruction: 0.156677, Regularization: 0.000512\n",
      "2019-04-10 01:03:24,790 root         INFO     Train Epoch: 127 [512/8000 (6%)]\tTotal Loss: 0.178327\n",
      "Reconstruction: 0.177434, Regularization: 0.000893\n",
      "2019-04-10 01:03:24,854 root         INFO     Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 0.178636\n",
      "Reconstruction: 0.177584, Regularization: 0.001052\n",
      "2019-04-10 01:03:24,919 root         INFO     Train Epoch: 127 [1536/8000 (19%)]\tTotal Loss: 0.168161\n",
      "Reconstruction: 0.167480, Regularization: 0.000681\n",
      "2019-04-10 01:03:24,983 root         INFO     Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 0.169348\n",
      "Reconstruction: 0.168488, Regularization: 0.000860\n",
      "2019-04-10 01:03:25,048 root         INFO     Train Epoch: 127 [2560/8000 (32%)]\tTotal Loss: 0.166600\n",
      "Reconstruction: 0.165858, Regularization: 0.000742\n",
      "2019-04-10 01:03:25,112 root         INFO     Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 0.172807\n",
      "Reconstruction: 0.171967, Regularization: 0.000840\n",
      "2019-04-10 01:03:25,177 root         INFO     Train Epoch: 127 [3584/8000 (45%)]\tTotal Loss: 0.160072\n",
      "Reconstruction: 0.159535, Regularization: 0.000537\n",
      "2019-04-10 01:03:25,241 root         INFO     Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 0.172493\n",
      "Reconstruction: 0.171610, Regularization: 0.000883\n",
      "2019-04-10 01:03:25,305 root         INFO     Train Epoch: 127 [4608/8000 (58%)]\tTotal Loss: 0.168718\n",
      "Reconstruction: 0.167904, Regularization: 0.000815\n",
      "2019-04-10 01:03:25,370 root         INFO     Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 0.162995\n",
      "Reconstruction: 0.162357, Regularization: 0.000638\n",
      "2019-04-10 01:03:25,434 root         INFO     Train Epoch: 127 [5632/8000 (70%)]\tTotal Loss: 0.175845\n",
      "Reconstruction: 0.174844, Regularization: 0.001001\n",
      "2019-04-10 01:03:25,497 root         INFO     Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 0.164035\n",
      "Reconstruction: 0.163372, Regularization: 0.000663\n",
      "2019-04-10 01:03:25,561 root         INFO     Train Epoch: 127 [6656/8000 (83%)]\tTotal Loss: 0.164566\n",
      "Reconstruction: 0.163891, Regularization: 0.000676\n",
      "2019-04-10 01:03:25,625 root         INFO     Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 0.159561\n",
      "Reconstruction: 0.158939, Regularization: 0.000622\n",
      "2019-04-10 01:03:25,689 root         INFO     Train Epoch: 127 [7680/8000 (96%)]\tTotal Loss: 0.167854\n",
      "Reconstruction: 0.167102, Regularization: 0.000752\n",
      "2019-04-10 01:03:25,743 root         INFO     ====> Epoch: 127 Average loss: 0.1661\n",
      "2019-04-10 01:03:25,767 root         INFO     Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 0.170261\n",
      "Reconstruction: 0.169469, Regularization: 0.000792\n",
      "2019-04-10 01:03:25,832 root         INFO     Train Epoch: 128 [512/8000 (6%)]\tTotal Loss: 0.165127\n",
      "Reconstruction: 0.164381, Regularization: 0.000746\n",
      "2019-04-10 01:03:25,896 root         INFO     Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 0.166206\n",
      "Reconstruction: 0.165448, Regularization: 0.000758\n",
      "2019-04-10 01:03:25,959 root         INFO     Train Epoch: 128 [1536/8000 (19%)]\tTotal Loss: 0.165312\n",
      "Reconstruction: 0.164618, Regularization: 0.000695\n",
      "2019-04-10 01:03:26,023 root         INFO     Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 0.178366\n",
      "Reconstruction: 0.177416, Regularization: 0.000950\n",
      "2019-04-10 01:03:26,087 root         INFO     Train Epoch: 128 [2560/8000 (32%)]\tTotal Loss: 0.162078\n",
      "Reconstruction: 0.161485, Regularization: 0.000593\n",
      "2019-04-10 01:03:26,151 root         INFO     Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 0.159270\n",
      "Reconstruction: 0.158564, Regularization: 0.000706\n",
      "2019-04-10 01:03:26,216 root         INFO     Train Epoch: 128 [3584/8000 (45%)]\tTotal Loss: 0.172902\n",
      "Reconstruction: 0.171911, Regularization: 0.000991\n",
      "2019-04-10 01:03:26,279 root         INFO     Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 0.164579\n",
      "Reconstruction: 0.163761, Regularization: 0.000818\n",
      "2019-04-10 01:03:26,343 root         INFO     Train Epoch: 128 [4608/8000 (58%)]\tTotal Loss: 0.161126\n",
      "Reconstruction: 0.160447, Regularization: 0.000679\n",
      "2019-04-10 01:03:26,407 root         INFO     Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 0.149955\n",
      "Reconstruction: 0.149553, Regularization: 0.000403\n",
      "2019-04-10 01:03:26,471 root         INFO     Train Epoch: 128 [5632/8000 (70%)]\tTotal Loss: 0.157605\n",
      "Reconstruction: 0.157085, Regularization: 0.000520\n",
      "2019-04-10 01:03:26,536 root         INFO     Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 0.161554\n",
      "Reconstruction: 0.160917, Regularization: 0.000637\n",
      "2019-04-10 01:03:26,600 root         INFO     Train Epoch: 128 [6656/8000 (83%)]\tTotal Loss: 0.154195\n",
      "Reconstruction: 0.153683, Regularization: 0.000511\n",
      "2019-04-10 01:03:26,663 root         INFO     Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 0.161454\n",
      "Reconstruction: 0.160869, Regularization: 0.000584\n",
      "2019-04-10 01:03:26,727 root         INFO     Train Epoch: 128 [7680/8000 (96%)]\tTotal Loss: 0.168095\n",
      "Reconstruction: 0.167300, Regularization: 0.000795\n",
      "2019-04-10 01:03:26,782 root         INFO     ====> Epoch: 128 Average loss: 0.1663\n",
      "2019-04-10 01:03:26,806 root         INFO     Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 0.178314\n",
      "Reconstruction: 0.177360, Regularization: 0.000954\n",
      "2019-04-10 01:03:26,869 root         INFO     Train Epoch: 129 [512/8000 (6%)]\tTotal Loss: 0.165428\n",
      "Reconstruction: 0.164669, Regularization: 0.000759\n",
      "2019-04-10 01:03:26,933 root         INFO     Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 0.165433\n",
      "Reconstruction: 0.164643, Regularization: 0.000790\n",
      "2019-04-10 01:03:26,997 root         INFO     Train Epoch: 129 [1536/8000 (19%)]\tTotal Loss: 0.168817\n",
      "Reconstruction: 0.167916, Regularization: 0.000901\n",
      "2019-04-10 01:03:27,060 root         INFO     Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 0.158942\n",
      "Reconstruction: 0.158359, Regularization: 0.000582\n",
      "2019-04-10 01:03:27,124 root         INFO     Train Epoch: 129 [2560/8000 (32%)]\tTotal Loss: 0.164846\n",
      "Reconstruction: 0.164072, Regularization: 0.000773\n",
      "2019-04-10 01:03:27,187 root         INFO     Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 0.167619\n",
      "Reconstruction: 0.166789, Regularization: 0.000830\n",
      "2019-04-10 01:03:27,251 root         INFO     Train Epoch: 129 [3584/8000 (45%)]\tTotal Loss: 0.162692\n",
      "Reconstruction: 0.162028, Regularization: 0.000664\n",
      "2019-04-10 01:03:27,314 root         INFO     Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 0.158516\n",
      "Reconstruction: 0.157822, Regularization: 0.000694\n",
      "2019-04-10 01:03:27,378 root         INFO     Train Epoch: 129 [4608/8000 (58%)]\tTotal Loss: 0.163943\n",
      "Reconstruction: 0.163184, Regularization: 0.000760\n",
      "2019-04-10 01:03:27,442 root         INFO     Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 0.166419\n",
      "Reconstruction: 0.165690, Regularization: 0.000729\n",
      "2019-04-10 01:03:27,506 root         INFO     Train Epoch: 129 [5632/8000 (70%)]\tTotal Loss: 0.163834\n",
      "Reconstruction: 0.163094, Regularization: 0.000740\n",
      "2019-04-10 01:03:27,569 root         INFO     Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 0.161863\n",
      "Reconstruction: 0.161208, Regularization: 0.000655\n",
      "2019-04-10 01:03:27,633 root         INFO     Train Epoch: 129 [6656/8000 (83%)]\tTotal Loss: 0.163245\n",
      "Reconstruction: 0.162537, Regularization: 0.000708\n",
      "2019-04-10 01:03:27,698 root         INFO     Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 0.160030\n",
      "Reconstruction: 0.159320, Regularization: 0.000711\n",
      "2019-04-10 01:03:27,762 root         INFO     Train Epoch: 129 [7680/8000 (96%)]\tTotal Loss: 0.167139\n",
      "Reconstruction: 0.166252, Regularization: 0.000887\n",
      "2019-04-10 01:03:27,816 root         INFO     ====> Epoch: 129 Average loss: 0.1661\n",
      "2019-04-10 01:03:27,840 root         INFO     Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 0.164914\n",
      "Reconstruction: 0.164128, Regularization: 0.000786\n",
      "2019-04-10 01:03:27,905 root         INFO     Train Epoch: 130 [512/8000 (6%)]\tTotal Loss: 0.154134\n",
      "Reconstruction: 0.153681, Regularization: 0.000453\n",
      "2019-04-10 01:03:27,968 root         INFO     Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 0.158151\n",
      "Reconstruction: 0.157558, Regularization: 0.000593\n",
      "2019-04-10 01:03:28,031 root         INFO     Train Epoch: 130 [1536/8000 (19%)]\tTotal Loss: 0.165886\n",
      "Reconstruction: 0.165160, Regularization: 0.000726\n",
      "2019-04-10 01:03:28,093 root         INFO     Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 0.178566\n",
      "Reconstruction: 0.177468, Regularization: 0.001097\n",
      "2019-04-10 01:03:28,157 root         INFO     Train Epoch: 130 [2560/8000 (32%)]\tTotal Loss: 0.171114\n",
      "Reconstruction: 0.170085, Regularization: 0.001029\n",
      "2019-04-10 01:03:28,220 root         INFO     Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 0.156205\n",
      "Reconstruction: 0.155623, Regularization: 0.000581\n",
      "2019-04-10 01:03:28,282 root         INFO     Train Epoch: 130 [3584/8000 (45%)]\tTotal Loss: 0.165163\n",
      "Reconstruction: 0.164451, Regularization: 0.000713\n",
      "2019-04-10 01:03:28,346 root         INFO     Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 0.169159\n",
      "Reconstruction: 0.168204, Regularization: 0.000955\n",
      "2019-04-10 01:03:28,409 root         INFO     Train Epoch: 130 [4608/8000 (58%)]\tTotal Loss: 0.160703\n",
      "Reconstruction: 0.160038, Regularization: 0.000665\n",
      "2019-04-10 01:03:28,473 root         INFO     Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 0.162556\n",
      "Reconstruction: 0.161793, Regularization: 0.000763\n",
      "2019-04-10 01:03:28,536 root         INFO     Train Epoch: 130 [5632/8000 (70%)]\tTotal Loss: 0.169691\n",
      "Reconstruction: 0.168687, Regularization: 0.001004\n",
      "2019-04-10 01:03:28,598 root         INFO     Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 0.171131\n",
      "Reconstruction: 0.170294, Regularization: 0.000837\n",
      "2019-04-10 01:03:28,661 root         INFO     Train Epoch: 130 [6656/8000 (83%)]\tTotal Loss: 0.158187\n",
      "Reconstruction: 0.157628, Regularization: 0.000559\n",
      "2019-04-10 01:03:28,724 root         INFO     Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 0.168491\n",
      "Reconstruction: 0.167709, Regularization: 0.000782\n",
      "2019-04-10 01:03:28,787 root         INFO     Train Epoch: 130 [7680/8000 (96%)]\tTotal Loss: 0.164874\n",
      "Reconstruction: 0.164135, Regularization: 0.000739\n",
      "2019-04-10 01:03:28,841 root         INFO     ====> Epoch: 130 Average loss: 0.1661\n",
      "2019-04-10 01:03:28,865 root         INFO     Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 0.174238\n",
      "Reconstruction: 0.173166, Regularization: 0.001072\n",
      "2019-04-10 01:03:28,930 root         INFO     Train Epoch: 131 [512/8000 (6%)]\tTotal Loss: 0.160835\n",
      "Reconstruction: 0.160126, Regularization: 0.000708\n",
      "2019-04-10 01:03:28,994 root         INFO     Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 0.155136\n",
      "Reconstruction: 0.154566, Regularization: 0.000569\n",
      "2019-04-10 01:03:29,059 root         INFO     Train Epoch: 131 [1536/8000 (19%)]\tTotal Loss: 0.168814\n",
      "Reconstruction: 0.168037, Regularization: 0.000777\n",
      "2019-04-10 01:03:29,122 root         INFO     Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 0.153136\n",
      "Reconstruction: 0.152625, Regularization: 0.000511\n",
      "2019-04-10 01:03:29,185 root         INFO     Train Epoch: 131 [2560/8000 (32%)]\tTotal Loss: 0.169956\n",
      "Reconstruction: 0.169085, Regularization: 0.000871\n",
      "2019-04-10 01:03:29,247 root         INFO     Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 0.161625\n",
      "Reconstruction: 0.160968, Regularization: 0.000658\n",
      "2019-04-10 01:03:29,311 root         INFO     Train Epoch: 131 [3584/8000 (45%)]\tTotal Loss: 0.158747\n",
      "Reconstruction: 0.158130, Regularization: 0.000617\n",
      "2019-04-10 01:03:29,374 root         INFO     Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 0.155133\n",
      "Reconstruction: 0.154561, Regularization: 0.000572\n",
      "2019-04-10 01:03:29,437 root         INFO     Train Epoch: 131 [4608/8000 (58%)]\tTotal Loss: 0.152765\n",
      "Reconstruction: 0.152325, Regularization: 0.000441\n",
      "2019-04-10 01:03:29,501 root         INFO     Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 0.159710\n",
      "Reconstruction: 0.159001, Regularization: 0.000709\n",
      "2019-04-10 01:03:29,565 root         INFO     Train Epoch: 131 [5632/8000 (70%)]\tTotal Loss: 0.171029\n",
      "Reconstruction: 0.170001, Regularization: 0.001027\n",
      "2019-04-10 01:03:29,628 root         INFO     Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 0.167976\n",
      "Reconstruction: 0.167131, Regularization: 0.000845\n",
      "2019-04-10 01:03:29,691 root         INFO     Train Epoch: 131 [6656/8000 (83%)]\tTotal Loss: 0.154124\n",
      "Reconstruction: 0.153566, Regularization: 0.000558\n",
      "2019-04-10 01:03:29,754 root         INFO     Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 0.162732\n",
      "Reconstruction: 0.162084, Regularization: 0.000648\n",
      "2019-04-10 01:03:29,816 root         INFO     Train Epoch: 131 [7680/8000 (96%)]\tTotal Loss: 0.164128\n",
      "Reconstruction: 0.163322, Regularization: 0.000806\n",
      "2019-04-10 01:03:29,869 root         INFO     ====> Epoch: 131 Average loss: 0.1661\n",
      "2019-04-10 01:03:29,894 root         INFO     Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 0.157175\n",
      "Reconstruction: 0.156622, Regularization: 0.000552\n",
      "2019-04-10 01:03:29,958 root         INFO     Train Epoch: 132 [512/8000 (6%)]\tTotal Loss: 0.163948\n",
      "Reconstruction: 0.163257, Regularization: 0.000691\n",
      "2019-04-10 01:03:30,023 root         INFO     Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 0.155384\n",
      "Reconstruction: 0.154831, Regularization: 0.000553\n",
      "2019-04-10 01:03:30,087 root         INFO     Train Epoch: 132 [1536/8000 (19%)]\tTotal Loss: 0.164796\n",
      "Reconstruction: 0.163984, Regularization: 0.000812\n",
      "2019-04-10 01:03:30,150 root         INFO     Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 0.156582\n",
      "Reconstruction: 0.155933, Regularization: 0.000649\n",
      "2019-04-10 01:03:30,214 root         INFO     Train Epoch: 132 [2560/8000 (32%)]\tTotal Loss: 0.162320\n",
      "Reconstruction: 0.161555, Regularization: 0.000765\n",
      "2019-04-10 01:03:30,278 root         INFO     Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 0.161212\n",
      "Reconstruction: 0.160420, Regularization: 0.000791\n",
      "2019-04-10 01:03:30,341 root         INFO     Train Epoch: 132 [3584/8000 (45%)]\tTotal Loss: 0.157594\n",
      "Reconstruction: 0.156977, Regularization: 0.000618\n",
      "2019-04-10 01:03:30,405 root         INFO     Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 0.160370\n",
      "Reconstruction: 0.159630, Regularization: 0.000740\n",
      "2019-04-10 01:03:30,468 root         INFO     Train Epoch: 132 [4608/8000 (58%)]\tTotal Loss: 0.156342\n",
      "Reconstruction: 0.155754, Regularization: 0.000588\n",
      "2019-04-10 01:03:30,531 root         INFO     Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 0.155450\n",
      "Reconstruction: 0.154894, Regularization: 0.000556\n",
      "2019-04-10 01:03:30,595 root         INFO     Train Epoch: 132 [5632/8000 (70%)]\tTotal Loss: 0.168429\n",
      "Reconstruction: 0.167531, Regularization: 0.000898\n",
      "2019-04-10 01:03:30,659 root         INFO     Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 0.170690\n",
      "Reconstruction: 0.169711, Regularization: 0.000979\n",
      "2019-04-10 01:03:30,722 root         INFO     Train Epoch: 132 [6656/8000 (83%)]\tTotal Loss: 0.165798\n",
      "Reconstruction: 0.164898, Regularization: 0.000900\n",
      "2019-04-10 01:03:30,786 root         INFO     Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 0.160618\n",
      "Reconstruction: 0.159863, Regularization: 0.000756\n",
      "2019-04-10 01:03:30,849 root         INFO     Train Epoch: 132 [7680/8000 (96%)]\tTotal Loss: 0.163533\n",
      "Reconstruction: 0.162771, Regularization: 0.000762\n",
      "2019-04-10 01:03:30,903 root         INFO     ====> Epoch: 132 Average loss: 0.1663\n",
      "2019-04-10 01:03:30,926 root         INFO     Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 0.165035\n",
      "Reconstruction: 0.164123, Regularization: 0.000912\n",
      "2019-04-10 01:03:30,990 root         INFO     Train Epoch: 133 [512/8000 (6%)]\tTotal Loss: 0.173946\n",
      "Reconstruction: 0.172929, Regularization: 0.001017\n",
      "2019-04-10 01:03:31,053 root         INFO     Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 0.169088\n",
      "Reconstruction: 0.168115, Regularization: 0.000973\n",
      "2019-04-10 01:03:31,117 root         INFO     Train Epoch: 133 [1536/8000 (19%)]\tTotal Loss: 0.168539\n",
      "Reconstruction: 0.167640, Regularization: 0.000899\n",
      "2019-04-10 01:03:31,180 root         INFO     Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 0.167304\n",
      "Reconstruction: 0.166384, Regularization: 0.000920\n",
      "2019-04-10 01:03:31,244 root         INFO     Train Epoch: 133 [2560/8000 (32%)]\tTotal Loss: 0.180228\n",
      "Reconstruction: 0.178954, Regularization: 0.001274\n",
      "2019-04-10 01:03:31,307 root         INFO     Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 0.158078\n",
      "Reconstruction: 0.157444, Regularization: 0.000634\n",
      "2019-04-10 01:03:31,370 root         INFO     Train Epoch: 133 [3584/8000 (45%)]\tTotal Loss: 0.164905\n",
      "Reconstruction: 0.164032, Regularization: 0.000873\n",
      "2019-04-10 01:03:31,434 root         INFO     Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 0.160279\n",
      "Reconstruction: 0.159495, Regularization: 0.000784\n",
      "2019-04-10 01:03:31,497 root         INFO     Train Epoch: 133 [4608/8000 (58%)]\tTotal Loss: 0.164904\n",
      "Reconstruction: 0.164038, Regularization: 0.000866\n",
      "2019-04-10 01:03:31,561 root         INFO     Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 0.170324\n",
      "Reconstruction: 0.169307, Regularization: 0.001017\n",
      "2019-04-10 01:03:31,624 root         INFO     Train Epoch: 133 [5632/8000 (70%)]\tTotal Loss: 0.181481\n",
      "Reconstruction: 0.180315, Regularization: 0.001166\n",
      "2019-04-10 01:03:31,687 root         INFO     Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 0.157044\n",
      "Reconstruction: 0.156449, Regularization: 0.000595\n",
      "2019-04-10 01:03:31,750 root         INFO     Train Epoch: 133 [6656/8000 (83%)]\tTotal Loss: 0.168229\n",
      "Reconstruction: 0.167356, Regularization: 0.000872\n",
      "2019-04-10 01:03:31,814 root         INFO     Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 0.159202\n",
      "Reconstruction: 0.158649, Regularization: 0.000552\n",
      "2019-04-10 01:03:31,877 root         INFO     Train Epoch: 133 [7680/8000 (96%)]\tTotal Loss: 0.175014\n",
      "Reconstruction: 0.173944, Regularization: 0.001070\n",
      "2019-04-10 01:03:31,930 root         INFO     ====> Epoch: 133 Average loss: 0.1661\n",
      "2019-04-10 01:03:31,955 root         INFO     Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 0.159651\n",
      "Reconstruction: 0.158958, Regularization: 0.000693\n",
      "2019-04-10 01:03:32,019 root         INFO     Train Epoch: 134 [512/8000 (6%)]\tTotal Loss: 0.166523\n",
      "Reconstruction: 0.165636, Regularization: 0.000887\n",
      "2019-04-10 01:03:32,082 root         INFO     Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 0.185328\n",
      "Reconstruction: 0.184074, Regularization: 0.001254\n",
      "2019-04-10 01:03:32,145 root         INFO     Train Epoch: 134 [1536/8000 (19%)]\tTotal Loss: 0.160367\n",
      "Reconstruction: 0.159617, Regularization: 0.000750\n",
      "2019-04-10 01:03:32,208 root         INFO     Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 0.171442\n",
      "Reconstruction: 0.170432, Regularization: 0.001010\n",
      "2019-04-10 01:03:32,272 root         INFO     Train Epoch: 134 [2560/8000 (32%)]\tTotal Loss: 0.168937\n",
      "Reconstruction: 0.168112, Regularization: 0.000824\n",
      "2019-04-10 01:03:32,335 root         INFO     Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 0.167436\n",
      "Reconstruction: 0.166522, Regularization: 0.000914\n",
      "2019-04-10 01:03:32,399 root         INFO     Train Epoch: 134 [3584/8000 (45%)]\tTotal Loss: 0.158954\n",
      "Reconstruction: 0.158215, Regularization: 0.000738\n",
      "2019-04-10 01:03:32,462 root         INFO     Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 0.160248\n",
      "Reconstruction: 0.159554, Regularization: 0.000694\n",
      "2019-04-10 01:03:32,526 root         INFO     Train Epoch: 134 [4608/8000 (58%)]\tTotal Loss: 0.180140\n",
      "Reconstruction: 0.178852, Regularization: 0.001288\n",
      "2019-04-10 01:03:32,590 root         INFO     Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 0.160963\n",
      "Reconstruction: 0.160269, Regularization: 0.000694\n",
      "2019-04-10 01:03:32,653 root         INFO     Train Epoch: 134 [5632/8000 (70%)]\tTotal Loss: 0.166988\n",
      "Reconstruction: 0.166126, Regularization: 0.000862\n",
      "2019-04-10 01:03:32,717 root         INFO     Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 0.160569\n",
      "Reconstruction: 0.159820, Regularization: 0.000749\n",
      "2019-04-10 01:03:32,779 root         INFO     Train Epoch: 134 [6656/8000 (83%)]\tTotal Loss: 0.156003\n",
      "Reconstruction: 0.155344, Regularization: 0.000659\n",
      "2019-04-10 01:03:32,842 root         INFO     Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 0.162576\n",
      "Reconstruction: 0.161835, Regularization: 0.000741\n",
      "2019-04-10 01:03:32,905 root         INFO     Train Epoch: 134 [7680/8000 (96%)]\tTotal Loss: 0.164180\n",
      "Reconstruction: 0.163255, Regularization: 0.000925\n",
      "2019-04-10 01:03:32,959 root         INFO     ====> Epoch: 134 Average loss: 0.1661\n",
      "2019-04-10 01:03:32,983 root         INFO     Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 0.166373\n",
      "Reconstruction: 0.165500, Regularization: 0.000874\n",
      "2019-04-10 01:03:33,047 root         INFO     Train Epoch: 135 [512/8000 (6%)]\tTotal Loss: 0.171747\n",
      "Reconstruction: 0.170712, Regularization: 0.001035\n",
      "2019-04-10 01:03:33,112 root         INFO     Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 0.171575\n",
      "Reconstruction: 0.170526, Regularization: 0.001048\n",
      "2019-04-10 01:03:33,176 root         INFO     Train Epoch: 135 [1536/8000 (19%)]\tTotal Loss: 0.165898\n",
      "Reconstruction: 0.164835, Regularization: 0.001063\n",
      "2019-04-10 01:03:33,239 root         INFO     Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 0.171078\n",
      "Reconstruction: 0.169906, Regularization: 0.001172\n",
      "2019-04-10 01:03:33,303 root         INFO     Train Epoch: 135 [2560/8000 (32%)]\tTotal Loss: 0.167814\n",
      "Reconstruction: 0.166859, Regularization: 0.000954\n",
      "2019-04-10 01:03:33,367 root         INFO     Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 0.159141\n",
      "Reconstruction: 0.158456, Regularization: 0.000685\n",
      "2019-04-10 01:03:33,431 root         INFO     Train Epoch: 135 [3584/8000 (45%)]\tTotal Loss: 0.167988\n",
      "Reconstruction: 0.166956, Regularization: 0.001032\n",
      "2019-04-10 01:03:33,494 root         INFO     Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 0.163554\n",
      "Reconstruction: 0.162647, Regularization: 0.000907\n",
      "2019-04-10 01:03:33,557 root         INFO     Train Epoch: 135 [4608/8000 (58%)]\tTotal Loss: 0.173928\n",
      "Reconstruction: 0.172836, Regularization: 0.001092\n",
      "2019-04-10 01:03:33,621 root         INFO     Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 0.166853\n",
      "Reconstruction: 0.165921, Regularization: 0.000933\n",
      "2019-04-10 01:03:33,684 root         INFO     Train Epoch: 135 [5632/8000 (70%)]\tTotal Loss: 0.165251\n",
      "Reconstruction: 0.164354, Regularization: 0.000896\n",
      "2019-04-10 01:03:33,748 root         INFO     Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 0.162458\n",
      "Reconstruction: 0.161609, Regularization: 0.000849\n",
      "2019-04-10 01:03:33,812 root         INFO     Train Epoch: 135 [6656/8000 (83%)]\tTotal Loss: 0.149889\n",
      "Reconstruction: 0.149424, Regularization: 0.000466\n",
      "2019-04-10 01:03:33,876 root         INFO     Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 0.166755\n",
      "Reconstruction: 0.165925, Regularization: 0.000830\n",
      "2019-04-10 01:03:33,939 root         INFO     Train Epoch: 135 [7680/8000 (96%)]\tTotal Loss: 0.162873\n",
      "Reconstruction: 0.162101, Regularization: 0.000772\n",
      "2019-04-10 01:03:33,993 root         INFO     ====> Epoch: 135 Average loss: 0.1661\n",
      "2019-04-10 01:03:34,017 root         INFO     Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 0.169341\n",
      "Reconstruction: 0.168314, Regularization: 0.001028\n",
      "2019-04-10 01:03:34,081 root         INFO     Train Epoch: 136 [512/8000 (6%)]\tTotal Loss: 0.166025\n",
      "Reconstruction: 0.165008, Regularization: 0.001017\n",
      "2019-04-10 01:03:34,145 root         INFO     Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 0.160237\n",
      "Reconstruction: 0.159432, Regularization: 0.000805\n",
      "2019-04-10 01:03:34,208 root         INFO     Train Epoch: 136 [1536/8000 (19%)]\tTotal Loss: 0.156176\n",
      "Reconstruction: 0.155587, Regularization: 0.000589\n",
      "2019-04-10 01:03:34,272 root         INFO     Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 0.162812\n",
      "Reconstruction: 0.161986, Regularization: 0.000826\n",
      "2019-04-10 01:03:34,335 root         INFO     Train Epoch: 136 [2560/8000 (32%)]\tTotal Loss: 0.187366\n",
      "Reconstruction: 0.185766, Regularization: 0.001600\n",
      "2019-04-10 01:03:34,398 root         INFO     Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 0.149288\n",
      "Reconstruction: 0.148747, Regularization: 0.000541\n",
      "2019-04-10 01:03:34,462 root         INFO     Train Epoch: 136 [3584/8000 (45%)]\tTotal Loss: 0.167606\n",
      "Reconstruction: 0.166654, Regularization: 0.000952\n",
      "2019-04-10 01:03:34,525 root         INFO     Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 0.168476\n",
      "Reconstruction: 0.167579, Regularization: 0.000896\n",
      "2019-04-10 01:03:34,589 root         INFO     Train Epoch: 136 [4608/8000 (58%)]\tTotal Loss: 0.169454\n",
      "Reconstruction: 0.168442, Regularization: 0.001012\n",
      "2019-04-10 01:03:34,653 root         INFO     Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 0.173213\n",
      "Reconstruction: 0.171876, Regularization: 0.001338\n",
      "2019-04-10 01:03:34,717 root         INFO     Train Epoch: 136 [5632/8000 (70%)]\tTotal Loss: 0.169596\n",
      "Reconstruction: 0.168616, Regularization: 0.000980\n",
      "2019-04-10 01:03:34,780 root         INFO     Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 0.170795\n",
      "Reconstruction: 0.169772, Regularization: 0.001022\n",
      "2019-04-10 01:03:34,844 root         INFO     Train Epoch: 136 [6656/8000 (83%)]\tTotal Loss: 0.165753\n",
      "Reconstruction: 0.164786, Regularization: 0.000967\n",
      "2019-04-10 01:03:34,907 root         INFO     Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 0.181370\n",
      "Reconstruction: 0.179972, Regularization: 0.001398\n",
      "2019-04-10 01:03:34,971 root         INFO     Train Epoch: 136 [7680/8000 (96%)]\tTotal Loss: 0.157704\n",
      "Reconstruction: 0.156962, Regularization: 0.000742\n",
      "2019-04-10 01:03:35,025 root         INFO     ====> Epoch: 136 Average loss: 0.1659\n",
      "2019-04-10 01:03:35,049 root         INFO     Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 0.153803\n",
      "Reconstruction: 0.153144, Regularization: 0.000659\n",
      "2019-04-10 01:03:35,113 root         INFO     Train Epoch: 137 [512/8000 (6%)]\tTotal Loss: 0.163668\n",
      "Reconstruction: 0.162797, Regularization: 0.000871\n",
      "2019-04-10 01:03:35,176 root         INFO     Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 0.170105\n",
      "Reconstruction: 0.169126, Regularization: 0.000979\n",
      "2019-04-10 01:03:35,240 root         INFO     Train Epoch: 137 [1536/8000 (19%)]\tTotal Loss: 0.165549\n",
      "Reconstruction: 0.164579, Regularization: 0.000970\n",
      "2019-04-10 01:03:35,304 root         INFO     Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 0.163808\n",
      "Reconstruction: 0.162962, Regularization: 0.000846\n",
      "2019-04-10 01:03:35,368 root         INFO     Train Epoch: 137 [2560/8000 (32%)]\tTotal Loss: 0.176798\n",
      "Reconstruction: 0.175535, Regularization: 0.001263\n",
      "2019-04-10 01:03:35,432 root         INFO     Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 0.173785\n",
      "Reconstruction: 0.172599, Regularization: 0.001186\n",
      "2019-04-10 01:03:35,495 root         INFO     Train Epoch: 137 [3584/8000 (45%)]\tTotal Loss: 0.170464\n",
      "Reconstruction: 0.169370, Regularization: 0.001094\n",
      "2019-04-10 01:03:35,558 root         INFO     Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 0.152503\n",
      "Reconstruction: 0.151977, Regularization: 0.000526\n",
      "2019-04-10 01:03:35,620 root         INFO     Train Epoch: 137 [4608/8000 (58%)]\tTotal Loss: 0.171309\n",
      "Reconstruction: 0.170249, Regularization: 0.001060\n",
      "2019-04-10 01:03:35,683 root         INFO     Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 0.172246\n",
      "Reconstruction: 0.171073, Regularization: 0.001173\n",
      "2019-04-10 01:03:35,745 root         INFO     Train Epoch: 137 [5632/8000 (70%)]\tTotal Loss: 0.160636\n",
      "Reconstruction: 0.159781, Regularization: 0.000855\n",
      "2019-04-10 01:03:35,807 root         INFO     Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 0.171351\n",
      "Reconstruction: 0.170217, Regularization: 0.001134\n",
      "2019-04-10 01:03:35,870 root         INFO     Train Epoch: 137 [6656/8000 (83%)]\tTotal Loss: 0.161445\n",
      "Reconstruction: 0.160566, Regularization: 0.000880\n",
      "2019-04-10 01:03:35,933 root         INFO     Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 0.172729\n",
      "Reconstruction: 0.171530, Regularization: 0.001199\n",
      "2019-04-10 01:03:35,995 root         INFO     Train Epoch: 137 [7680/8000 (96%)]\tTotal Loss: 0.159005\n",
      "Reconstruction: 0.158037, Regularization: 0.000968\n",
      "2019-04-10 01:03:36,048 root         INFO     ====> Epoch: 137 Average loss: 0.1658\n",
      "2019-04-10 01:03:36,072 root         INFO     Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 0.156060\n",
      "Reconstruction: 0.155383, Regularization: 0.000678\n",
      "2019-04-10 01:03:36,136 root         INFO     Train Epoch: 138 [512/8000 (6%)]\tTotal Loss: 0.185531\n",
      "Reconstruction: 0.183877, Regularization: 0.001654\n",
      "2019-04-10 01:03:36,199 root         INFO     Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 0.162763\n",
      "Reconstruction: 0.161920, Regularization: 0.000843\n",
      "2019-04-10 01:03:36,262 root         INFO     Train Epoch: 138 [1536/8000 (19%)]\tTotal Loss: 0.170282\n",
      "Reconstruction: 0.169185, Regularization: 0.001096\n",
      "2019-04-10 01:03:36,326 root         INFO     Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 0.180701\n",
      "Reconstruction: 0.179013, Regularization: 0.001687\n",
      "2019-04-10 01:03:36,389 root         INFO     Train Epoch: 138 [2560/8000 (32%)]\tTotal Loss: 0.166246\n",
      "Reconstruction: 0.165223, Regularization: 0.001024\n",
      "2019-04-10 01:03:36,453 root         INFO     Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 0.174898\n",
      "Reconstruction: 0.173681, Regularization: 0.001217\n",
      "2019-04-10 01:03:36,517 root         INFO     Train Epoch: 138 [3584/8000 (45%)]\tTotal Loss: 0.173396\n",
      "Reconstruction: 0.172110, Regularization: 0.001286\n",
      "2019-04-10 01:03:36,580 root         INFO     Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 0.161745\n",
      "Reconstruction: 0.160778, Regularization: 0.000967\n",
      "2019-04-10 01:03:36,644 root         INFO     Train Epoch: 138 [4608/8000 (58%)]\tTotal Loss: 0.165814\n",
      "Reconstruction: 0.164707, Regularization: 0.001107\n",
      "2019-04-10 01:03:36,707 root         INFO     Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 0.153967\n",
      "Reconstruction: 0.153405, Regularization: 0.000562\n",
      "2019-04-10 01:03:36,771 root         INFO     Train Epoch: 138 [5632/8000 (70%)]\tTotal Loss: 0.170419\n",
      "Reconstruction: 0.169243, Regularization: 0.001177\n",
      "2019-04-10 01:03:36,834 root         INFO     Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 0.170990\n",
      "Reconstruction: 0.169912, Regularization: 0.001078\n",
      "2019-04-10 01:03:36,898 root         INFO     Train Epoch: 138 [6656/8000 (83%)]\tTotal Loss: 0.165163\n",
      "Reconstruction: 0.164208, Regularization: 0.000954\n",
      "2019-04-10 01:03:36,961 root         INFO     Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 0.187990\n",
      "Reconstruction: 0.186069, Regularization: 0.001922\n",
      "2019-04-10 01:03:37,025 root         INFO     Train Epoch: 138 [7680/8000 (96%)]\tTotal Loss: 0.158260\n",
      "Reconstruction: 0.157362, Regularization: 0.000898\n",
      "2019-04-10 01:03:37,079 root         INFO     ====> Epoch: 138 Average loss: 0.1660\n",
      "2019-04-10 01:03:37,103 root         INFO     Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 0.172007\n",
      "Reconstruction: 0.170717, Regularization: 0.001290\n",
      "2019-04-10 01:03:37,167 root         INFO     Train Epoch: 139 [512/8000 (6%)]\tTotal Loss: 0.163855\n",
      "Reconstruction: 0.162861, Regularization: 0.000994\n",
      "2019-04-10 01:03:37,230 root         INFO     Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 0.162074\n",
      "Reconstruction: 0.161237, Regularization: 0.000837\n",
      "2019-04-10 01:03:37,294 root         INFO     Train Epoch: 139 [1536/8000 (19%)]\tTotal Loss: 0.160317\n",
      "Reconstruction: 0.159412, Regularization: 0.000905\n",
      "2019-04-10 01:03:37,359 root         INFO     Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 0.165809\n",
      "Reconstruction: 0.164819, Regularization: 0.000991\n",
      "2019-04-10 01:03:37,423 root         INFO     Train Epoch: 139 [2560/8000 (32%)]\tTotal Loss: 0.164227\n",
      "Reconstruction: 0.163162, Regularization: 0.001064\n",
      "2019-04-10 01:03:37,487 root         INFO     Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 0.170120\n",
      "Reconstruction: 0.168995, Regularization: 0.001124\n",
      "2019-04-10 01:03:37,550 root         INFO     Train Epoch: 139 [3584/8000 (45%)]\tTotal Loss: 0.160067\n",
      "Reconstruction: 0.159191, Regularization: 0.000876\n",
      "2019-04-10 01:03:37,613 root         INFO     Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 0.164335\n",
      "Reconstruction: 0.163290, Regularization: 0.001045\n",
      "2019-04-10 01:03:37,676 root         INFO     Train Epoch: 139 [4608/8000 (58%)]\tTotal Loss: 0.166728\n",
      "Reconstruction: 0.165562, Regularization: 0.001166\n",
      "2019-04-10 01:03:37,739 root         INFO     Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 0.178586\n",
      "Reconstruction: 0.177062, Regularization: 0.001524\n",
      "2019-04-10 01:03:37,803 root         INFO     Train Epoch: 139 [5632/8000 (70%)]\tTotal Loss: 0.167467\n",
      "Reconstruction: 0.166159, Regularization: 0.001308\n",
      "2019-04-10 01:03:37,866 root         INFO     Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 0.162427\n",
      "Reconstruction: 0.161346, Regularization: 0.001081\n",
      "2019-04-10 01:03:37,930 root         INFO     Train Epoch: 139 [6656/8000 (83%)]\tTotal Loss: 0.154979\n",
      "Reconstruction: 0.154236, Regularization: 0.000743\n",
      "2019-04-10 01:03:37,994 root         INFO     Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 0.166805\n",
      "Reconstruction: 0.165654, Regularization: 0.001151\n",
      "2019-04-10 01:03:38,057 root         INFO     Train Epoch: 139 [7680/8000 (96%)]\tTotal Loss: 0.171611\n",
      "Reconstruction: 0.170330, Regularization: 0.001280\n",
      "2019-04-10 01:03:38,111 root         INFO     ====> Epoch: 139 Average loss: 0.1662\n",
      "2019-04-10 01:03:38,135 root         INFO     Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 0.184229\n",
      "Reconstruction: 0.182554, Regularization: 0.001674\n",
      "2019-04-10 01:03:38,199 root         INFO     Train Epoch: 140 [512/8000 (6%)]\tTotal Loss: 0.170527\n",
      "Reconstruction: 0.169347, Regularization: 0.001180\n",
      "2019-04-10 01:03:38,263 root         INFO     Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 0.169417\n",
      "Reconstruction: 0.168193, Regularization: 0.001224\n",
      "2019-04-10 01:03:38,326 root         INFO     Train Epoch: 140 [1536/8000 (19%)]\tTotal Loss: 0.161411\n",
      "Reconstruction: 0.160551, Regularization: 0.000860\n",
      "2019-04-10 01:03:38,389 root         INFO     Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 0.196436\n",
      "Reconstruction: 0.194021, Regularization: 0.002415\n",
      "2019-04-10 01:03:38,452 root         INFO     Train Epoch: 140 [2560/8000 (32%)]\tTotal Loss: 0.157284\n",
      "Reconstruction: 0.156584, Regularization: 0.000700\n",
      "2019-04-10 01:03:38,515 root         INFO     Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 0.175191\n",
      "Reconstruction: 0.173803, Regularization: 0.001388\n",
      "2019-04-10 01:03:38,579 root         INFO     Train Epoch: 140 [3584/8000 (45%)]\tTotal Loss: 0.167774\n",
      "Reconstruction: 0.166585, Regularization: 0.001189\n",
      "2019-04-10 01:03:38,642 root         INFO     Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 0.160645\n",
      "Reconstruction: 0.159765, Regularization: 0.000881\n",
      "2019-04-10 01:03:38,705 root         INFO     Train Epoch: 140 [4608/8000 (58%)]\tTotal Loss: 0.169944\n",
      "Reconstruction: 0.168784, Regularization: 0.001161\n",
      "2019-04-10 01:03:38,768 root         INFO     Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 0.159991\n",
      "Reconstruction: 0.159132, Regularization: 0.000859\n",
      "2019-04-10 01:03:38,831 root         INFO     Train Epoch: 140 [5632/8000 (70%)]\tTotal Loss: 0.161506\n",
      "Reconstruction: 0.160419, Regularization: 0.001087\n",
      "2019-04-10 01:03:38,893 root         INFO     Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 0.155636\n",
      "Reconstruction: 0.154948, Regularization: 0.000689\n",
      "2019-04-10 01:03:38,956 root         INFO     Train Epoch: 140 [6656/8000 (83%)]\tTotal Loss: 0.170979\n",
      "Reconstruction: 0.169539, Regularization: 0.001440\n",
      "2019-04-10 01:03:39,019 root         INFO     Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 0.163219\n",
      "Reconstruction: 0.162163, Regularization: 0.001056\n",
      "2019-04-10 01:03:39,081 root         INFO     Train Epoch: 140 [7680/8000 (96%)]\tTotal Loss: 0.153961\n",
      "Reconstruction: 0.153282, Regularization: 0.000678\n",
      "2019-04-10 01:03:39,135 root         INFO     ====> Epoch: 140 Average loss: 0.1660\n",
      "2019-04-10 01:03:39,159 root         INFO     Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 0.175482\n",
      "Reconstruction: 0.174186, Regularization: 0.001296\n",
      "2019-04-10 01:03:39,223 root         INFO     Train Epoch: 141 [512/8000 (6%)]\tTotal Loss: 0.162933\n",
      "Reconstruction: 0.161960, Regularization: 0.000973\n",
      "2019-04-10 01:03:39,286 root         INFO     Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 0.175619\n",
      "Reconstruction: 0.174108, Regularization: 0.001512\n",
      "2019-04-10 01:03:39,350 root         INFO     Train Epoch: 141 [1536/8000 (19%)]\tTotal Loss: 0.177104\n",
      "Reconstruction: 0.175543, Regularization: 0.001561\n",
      "2019-04-10 01:03:39,413 root         INFO     Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 0.161581\n",
      "Reconstruction: 0.160629, Regularization: 0.000951\n",
      "2019-04-10 01:03:39,477 root         INFO     Train Epoch: 141 [2560/8000 (32%)]\tTotal Loss: 0.162906\n",
      "Reconstruction: 0.161860, Regularization: 0.001046\n",
      "2019-04-10 01:03:39,540 root         INFO     Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 0.186125\n",
      "Reconstruction: 0.184184, Regularization: 0.001941\n",
      "2019-04-10 01:03:39,602 root         INFO     Train Epoch: 141 [3584/8000 (45%)]\tTotal Loss: 0.175761\n",
      "Reconstruction: 0.174464, Regularization: 0.001298\n",
      "2019-04-10 01:03:39,666 root         INFO     Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 0.178701\n",
      "Reconstruction: 0.177077, Regularization: 0.001623\n",
      "2019-04-10 01:03:39,729 root         INFO     Train Epoch: 141 [4608/8000 (58%)]\tTotal Loss: 0.175497\n",
      "Reconstruction: 0.173974, Regularization: 0.001523\n",
      "2019-04-10 01:03:39,791 root         INFO     Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 0.163453\n",
      "Reconstruction: 0.162448, Regularization: 0.001005\n",
      "2019-04-10 01:03:39,854 root         INFO     Train Epoch: 141 [5632/8000 (70%)]\tTotal Loss: 0.173871\n",
      "Reconstruction: 0.172514, Regularization: 0.001356\n",
      "2019-04-10 01:03:39,916 root         INFO     Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 0.169268\n",
      "Reconstruction: 0.168017, Regularization: 0.001251\n",
      "2019-04-10 01:03:39,979 root         INFO     Train Epoch: 141 [6656/8000 (83%)]\tTotal Loss: 0.163858\n",
      "Reconstruction: 0.162851, Regularization: 0.001006\n",
      "2019-04-10 01:03:40,042 root         INFO     Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 0.169655\n",
      "Reconstruction: 0.168292, Regularization: 0.001363\n",
      "2019-04-10 01:03:40,105 root         INFO     Train Epoch: 141 [7680/8000 (96%)]\tTotal Loss: 0.167633\n",
      "Reconstruction: 0.166399, Regularization: 0.001234\n",
      "2019-04-10 01:03:40,160 root         INFO     ====> Epoch: 141 Average loss: 0.1662\n",
      "2019-04-10 01:03:40,184 root         INFO     Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 0.169117\n",
      "Reconstruction: 0.167940, Regularization: 0.001177\n",
      "2019-04-10 01:03:40,249 root         INFO     Train Epoch: 142 [512/8000 (6%)]\tTotal Loss: 0.174599\n",
      "Reconstruction: 0.173101, Regularization: 0.001499\n",
      "2019-04-10 01:03:40,313 root         INFO     Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 0.167346\n",
      "Reconstruction: 0.166051, Regularization: 0.001295\n",
      "2019-04-10 01:03:40,377 root         INFO     Train Epoch: 142 [1536/8000 (19%)]\tTotal Loss: 0.171282\n",
      "Reconstruction: 0.169977, Regularization: 0.001306\n",
      "2019-04-10 01:03:40,441 root         INFO     Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 0.172146\n",
      "Reconstruction: 0.170762, Regularization: 0.001384\n",
      "2019-04-10 01:03:40,504 root         INFO     Train Epoch: 142 [2560/8000 (32%)]\tTotal Loss: 0.168349\n",
      "Reconstruction: 0.167052, Regularization: 0.001297\n",
      "2019-04-10 01:03:40,568 root         INFO     Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 0.163420\n",
      "Reconstruction: 0.162171, Regularization: 0.001249\n",
      "2019-04-10 01:03:40,633 root         INFO     Train Epoch: 142 [3584/8000 (45%)]\tTotal Loss: 0.158074\n",
      "Reconstruction: 0.157271, Regularization: 0.000803\n",
      "2019-04-10 01:03:40,696 root         INFO     Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 0.168677\n",
      "Reconstruction: 0.167351, Regularization: 0.001326\n",
      "2019-04-10 01:03:40,760 root         INFO     Train Epoch: 142 [4608/8000 (58%)]\tTotal Loss: 0.166177\n",
      "Reconstruction: 0.165099, Regularization: 0.001078\n",
      "2019-04-10 01:03:40,825 root         INFO     Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 0.165008\n",
      "Reconstruction: 0.163672, Regularization: 0.001337\n",
      "2019-04-10 01:03:40,889 root         INFO     Train Epoch: 142 [5632/8000 (70%)]\tTotal Loss: 0.167468\n",
      "Reconstruction: 0.166156, Regularization: 0.001312\n",
      "2019-04-10 01:03:40,952 root         INFO     Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 0.161383\n",
      "Reconstruction: 0.160323, Regularization: 0.001060\n",
      "2019-04-10 01:03:41,016 root         INFO     Train Epoch: 142 [6656/8000 (83%)]\tTotal Loss: 0.156836\n",
      "Reconstruction: 0.155838, Regularization: 0.000999\n",
      "2019-04-10 01:03:41,080 root         INFO     Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 0.156469\n",
      "Reconstruction: 0.155622, Regularization: 0.000847\n",
      "2019-04-10 01:03:41,144 root         INFO     Train Epoch: 142 [7680/8000 (96%)]\tTotal Loss: 0.166747\n",
      "Reconstruction: 0.165440, Regularization: 0.001307\n",
      "2019-04-10 01:03:41,198 root         INFO     ====> Epoch: 142 Average loss: 0.1660\n",
      "2019-04-10 01:03:41,222 root         INFO     Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 0.169385\n",
      "Reconstruction: 0.167895, Regularization: 0.001490\n",
      "2019-04-10 01:03:41,287 root         INFO     Train Epoch: 143 [512/8000 (6%)]\tTotal Loss: 0.165677\n",
      "Reconstruction: 0.164491, Regularization: 0.001186\n",
      "2019-04-10 01:03:41,351 root         INFO     Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 0.162195\n",
      "Reconstruction: 0.160946, Regularization: 0.001250\n",
      "2019-04-10 01:03:41,415 root         INFO     Train Epoch: 143 [1536/8000 (19%)]\tTotal Loss: 0.166542\n",
      "Reconstruction: 0.165385, Regularization: 0.001157\n",
      "2019-04-10 01:03:41,479 root         INFO     Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 0.171840\n",
      "Reconstruction: 0.170578, Regularization: 0.001261\n",
      "2019-04-10 01:03:41,544 root         INFO     Train Epoch: 143 [2560/8000 (32%)]\tTotal Loss: 0.174071\n",
      "Reconstruction: 0.172583, Regularization: 0.001487\n",
      "2019-04-10 01:03:41,608 root         INFO     Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 0.161906\n",
      "Reconstruction: 0.160854, Regularization: 0.001052\n",
      "2019-04-10 01:03:41,671 root         INFO     Train Epoch: 143 [3584/8000 (45%)]\tTotal Loss: 0.166537\n",
      "Reconstruction: 0.165329, Regularization: 0.001208\n",
      "2019-04-10 01:03:41,735 root         INFO     Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 0.163615\n",
      "Reconstruction: 0.162441, Regularization: 0.001174\n",
      "2019-04-10 01:03:41,799 root         INFO     Train Epoch: 143 [4608/8000 (58%)]\tTotal Loss: 0.155598\n",
      "Reconstruction: 0.154726, Regularization: 0.000873\n",
      "2019-04-10 01:03:41,863 root         INFO     Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 0.177390\n",
      "Reconstruction: 0.175601, Regularization: 0.001789\n",
      "2019-04-10 01:03:41,927 root         INFO     Train Epoch: 143 [5632/8000 (70%)]\tTotal Loss: 0.156577\n",
      "Reconstruction: 0.155697, Regularization: 0.000880\n",
      "2019-04-10 01:03:41,992 root         INFO     Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 0.165967\n",
      "Reconstruction: 0.164706, Regularization: 0.001261\n",
      "2019-04-10 01:03:42,056 root         INFO     Train Epoch: 143 [6656/8000 (83%)]\tTotal Loss: 0.164725\n",
      "Reconstruction: 0.163588, Regularization: 0.001137\n",
      "2019-04-10 01:03:42,120 root         INFO     Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 0.165650\n",
      "Reconstruction: 0.164409, Regularization: 0.001240\n",
      "2019-04-10 01:03:42,184 root         INFO     Train Epoch: 143 [7680/8000 (96%)]\tTotal Loss: 0.156865\n",
      "Reconstruction: 0.155888, Regularization: 0.000977\n",
      "2019-04-10 01:03:42,238 root         INFO     ====> Epoch: 143 Average loss: 0.1662\n",
      "2019-04-10 01:03:42,262 root         INFO     Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 0.160890\n",
      "Reconstruction: 0.159730, Regularization: 0.001161\n",
      "2019-04-10 01:03:42,324 root         INFO     Train Epoch: 144 [512/8000 (6%)]\tTotal Loss: 0.168915\n",
      "Reconstruction: 0.167494, Regularization: 0.001422\n",
      "2019-04-10 01:03:42,387 root         INFO     Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 0.156148\n",
      "Reconstruction: 0.155277, Regularization: 0.000871\n",
      "2019-04-10 01:03:42,450 root         INFO     Train Epoch: 144 [1536/8000 (19%)]\tTotal Loss: 0.175117\n",
      "Reconstruction: 0.173466, Regularization: 0.001651\n",
      "2019-04-10 01:03:42,513 root         INFO     Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 0.165927\n",
      "Reconstruction: 0.164811, Regularization: 0.001116\n",
      "2019-04-10 01:03:42,577 root         INFO     Train Epoch: 144 [2560/8000 (32%)]\tTotal Loss: 0.171447\n",
      "Reconstruction: 0.170135, Regularization: 0.001312\n",
      "2019-04-10 01:03:42,642 root         INFO     Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 0.167810\n",
      "Reconstruction: 0.166466, Regularization: 0.001343\n",
      "2019-04-10 01:03:42,705 root         INFO     Train Epoch: 144 [3584/8000 (45%)]\tTotal Loss: 0.155379\n",
      "Reconstruction: 0.154571, Regularization: 0.000808\n",
      "2019-04-10 01:03:42,769 root         INFO     Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 0.157981\n",
      "Reconstruction: 0.157084, Regularization: 0.000896\n",
      "2019-04-10 01:03:42,833 root         INFO     Train Epoch: 144 [4608/8000 (58%)]\tTotal Loss: 0.153438\n",
      "Reconstruction: 0.152660, Regularization: 0.000777\n",
      "2019-04-10 01:03:42,897 root         INFO     Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 0.176380\n",
      "Reconstruction: 0.174813, Regularization: 0.001567\n",
      "2019-04-10 01:03:42,961 root         INFO     Train Epoch: 144 [5632/8000 (70%)]\tTotal Loss: 0.150540\n",
      "Reconstruction: 0.149784, Regularization: 0.000756\n",
      "2019-04-10 01:03:43,025 root         INFO     Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 0.173729\n",
      "Reconstruction: 0.172187, Regularization: 0.001542\n",
      "2019-04-10 01:03:43,089 root         INFO     Train Epoch: 144 [6656/8000 (83%)]\tTotal Loss: 0.174924\n",
      "Reconstruction: 0.173071, Regularization: 0.001853\n",
      "2019-04-10 01:03:43,152 root         INFO     Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 0.166211\n",
      "Reconstruction: 0.164797, Regularization: 0.001415\n",
      "2019-04-10 01:03:43,216 root         INFO     Train Epoch: 144 [7680/8000 (96%)]\tTotal Loss: 0.169963\n",
      "Reconstruction: 0.168558, Regularization: 0.001405\n",
      "2019-04-10 01:03:43,270 root         INFO     ====> Epoch: 144 Average loss: 0.1660\n",
      "2019-04-10 01:03:43,294 root         INFO     Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 0.169883\n",
      "Reconstruction: 0.168407, Regularization: 0.001476\n",
      "2019-04-10 01:03:43,358 root         INFO     Train Epoch: 145 [512/8000 (6%)]\tTotal Loss: 0.170878\n",
      "Reconstruction: 0.169399, Regularization: 0.001479\n",
      "2019-04-10 01:03:43,420 root         INFO     Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 0.163649\n",
      "Reconstruction: 0.162372, Regularization: 0.001276\n",
      "2019-04-10 01:03:43,482 root         INFO     Train Epoch: 145 [1536/8000 (19%)]\tTotal Loss: 0.182467\n",
      "Reconstruction: 0.180681, Regularization: 0.001785\n",
      "2019-04-10 01:03:43,544 root         INFO     Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 0.164917\n",
      "Reconstruction: 0.163609, Regularization: 0.001308\n",
      "2019-04-10 01:03:43,607 root         INFO     Train Epoch: 145 [2560/8000 (32%)]\tTotal Loss: 0.152586\n",
      "Reconstruction: 0.151777, Regularization: 0.000809\n",
      "2019-04-10 01:03:43,669 root         INFO     Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 0.164858\n",
      "Reconstruction: 0.163582, Regularization: 0.001276\n",
      "2019-04-10 01:03:43,731 root         INFO     Train Epoch: 145 [3584/8000 (45%)]\tTotal Loss: 0.158615\n",
      "Reconstruction: 0.157578, Regularization: 0.001037\n",
      "2019-04-10 01:03:43,793 root         INFO     Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 0.168081\n",
      "Reconstruction: 0.166667, Regularization: 0.001414\n",
      "2019-04-10 01:03:43,855 root         INFO     Train Epoch: 145 [4608/8000 (58%)]\tTotal Loss: 0.175347\n",
      "Reconstruction: 0.173729, Regularization: 0.001617\n",
      "2019-04-10 01:03:43,916 root         INFO     Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 0.174798\n",
      "Reconstruction: 0.173300, Regularization: 0.001498\n",
      "2019-04-10 01:03:43,978 root         INFO     Train Epoch: 145 [5632/8000 (70%)]\tTotal Loss: 0.177645\n",
      "Reconstruction: 0.175930, Regularization: 0.001714\n",
      "2019-04-10 01:03:44,040 root         INFO     Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 0.156331\n",
      "Reconstruction: 0.155439, Regularization: 0.000892\n",
      "2019-04-10 01:03:44,103 root         INFO     Train Epoch: 145 [6656/8000 (83%)]\tTotal Loss: 0.168289\n",
      "Reconstruction: 0.166992, Regularization: 0.001297\n",
      "2019-04-10 01:03:44,165 root         INFO     Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 0.169222\n",
      "Reconstruction: 0.167973, Regularization: 0.001249\n",
      "2019-04-10 01:03:44,226 root         INFO     Train Epoch: 145 [7680/8000 (96%)]\tTotal Loss: 0.161526\n",
      "Reconstruction: 0.160473, Regularization: 0.001053\n",
      "2019-04-10 01:03:44,279 root         INFO     ====> Epoch: 145 Average loss: 0.1661\n",
      "2019-04-10 01:03:44,303 root         INFO     Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 0.166299\n",
      "Reconstruction: 0.164814, Regularization: 0.001485\n",
      "2019-04-10 01:03:44,366 root         INFO     Train Epoch: 146 [512/8000 (6%)]\tTotal Loss: 0.163397\n",
      "Reconstruction: 0.162109, Regularization: 0.001288\n",
      "2019-04-10 01:03:44,429 root         INFO     Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 0.164793\n",
      "Reconstruction: 0.163370, Regularization: 0.001424\n",
      "2019-04-10 01:03:44,492 root         INFO     Train Epoch: 146 [1536/8000 (19%)]\tTotal Loss: 0.152127\n",
      "Reconstruction: 0.151319, Regularization: 0.000807\n",
      "2019-04-10 01:03:44,554 root         INFO     Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 0.162760\n",
      "Reconstruction: 0.161568, Regularization: 0.001192\n",
      "2019-04-10 01:03:44,615 root         INFO     Train Epoch: 146 [2560/8000 (32%)]\tTotal Loss: 0.167366\n",
      "Reconstruction: 0.165945, Regularization: 0.001421\n",
      "2019-04-10 01:03:44,678 root         INFO     Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 0.174631\n",
      "Reconstruction: 0.172670, Regularization: 0.001960\n",
      "2019-04-10 01:03:44,739 root         INFO     Train Epoch: 146 [3584/8000 (45%)]\tTotal Loss: 0.170626\n",
      "Reconstruction: 0.169005, Regularization: 0.001621\n",
      "2019-04-10 01:03:44,801 root         INFO     Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 0.172934\n",
      "Reconstruction: 0.171468, Regularization: 0.001467\n",
      "2019-04-10 01:03:44,863 root         INFO     Train Epoch: 146 [4608/8000 (58%)]\tTotal Loss: 0.167754\n",
      "Reconstruction: 0.166391, Regularization: 0.001363\n",
      "2019-04-10 01:03:44,925 root         INFO     Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 0.165648\n",
      "Reconstruction: 0.164363, Regularization: 0.001285\n",
      "2019-04-10 01:03:44,987 root         INFO     Train Epoch: 146 [5632/8000 (70%)]\tTotal Loss: 0.169414\n",
      "Reconstruction: 0.167849, Regularization: 0.001565\n",
      "2019-04-10 01:03:45,049 root         INFO     Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 0.165689\n",
      "Reconstruction: 0.164401, Regularization: 0.001288\n",
      "2019-04-10 01:03:45,111 root         INFO     Train Epoch: 146 [6656/8000 (83%)]\tTotal Loss: 0.156806\n",
      "Reconstruction: 0.155739, Regularization: 0.001068\n",
      "2019-04-10 01:03:45,174 root         INFO     Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 0.155670\n",
      "Reconstruction: 0.154650, Regularization: 0.001020\n",
      "2019-04-10 01:03:45,237 root         INFO     Train Epoch: 146 [7680/8000 (96%)]\tTotal Loss: 0.163498\n",
      "Reconstruction: 0.162196, Regularization: 0.001303\n",
      "2019-04-10 01:03:45,291 root         INFO     ====> Epoch: 146 Average loss: 0.1661\n",
      "2019-04-10 01:03:45,315 root         INFO     Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 0.167917\n",
      "Reconstruction: 0.166469, Regularization: 0.001447\n",
      "2019-04-10 01:03:45,379 root         INFO     Train Epoch: 147 [512/8000 (6%)]\tTotal Loss: 0.165615\n",
      "Reconstruction: 0.164127, Regularization: 0.001488\n",
      "2019-04-10 01:03:45,442 root         INFO     Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 0.152577\n",
      "Reconstruction: 0.151804, Regularization: 0.000773\n",
      "2019-04-10 01:03:45,504 root         INFO     Train Epoch: 147 [1536/8000 (19%)]\tTotal Loss: 0.171579\n",
      "Reconstruction: 0.169751, Regularization: 0.001828\n",
      "2019-04-10 01:03:45,567 root         INFO     Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 0.166983\n",
      "Reconstruction: 0.165645, Regularization: 0.001338\n",
      "2019-04-10 01:03:45,630 root         INFO     Train Epoch: 147 [2560/8000 (32%)]\tTotal Loss: 0.160417\n",
      "Reconstruction: 0.159319, Regularization: 0.001098\n",
      "2019-04-10 01:03:45,693 root         INFO     Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 0.152067\n",
      "Reconstruction: 0.151139, Regularization: 0.000928\n",
      "2019-04-10 01:03:45,755 root         INFO     Train Epoch: 147 [3584/8000 (45%)]\tTotal Loss: 0.169706\n",
      "Reconstruction: 0.168253, Regularization: 0.001453\n",
      "2019-04-10 01:03:45,819 root         INFO     Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 0.164038\n",
      "Reconstruction: 0.162710, Regularization: 0.001328\n",
      "2019-04-10 01:03:45,882 root         INFO     Train Epoch: 147 [4608/8000 (58%)]\tTotal Loss: 0.161171\n",
      "Reconstruction: 0.160004, Regularization: 0.001167\n",
      "2019-04-10 01:03:45,945 root         INFO     Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 0.166087\n",
      "Reconstruction: 0.164675, Regularization: 0.001412\n",
      "2019-04-10 01:03:46,008 root         INFO     Train Epoch: 147 [5632/8000 (70%)]\tTotal Loss: 0.152951\n",
      "Reconstruction: 0.152064, Regularization: 0.000887\n",
      "2019-04-10 01:03:46,071 root         INFO     Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 0.164168\n",
      "Reconstruction: 0.162839, Regularization: 0.001328\n",
      "2019-04-10 01:03:46,134 root         INFO     Train Epoch: 147 [6656/8000 (83%)]\tTotal Loss: 0.174206\n",
      "Reconstruction: 0.172520, Regularization: 0.001685\n",
      "2019-04-10 01:03:46,197 root         INFO     Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 0.163074\n",
      "Reconstruction: 0.161850, Regularization: 0.001224\n",
      "2019-04-10 01:03:46,260 root         INFO     Train Epoch: 147 [7680/8000 (96%)]\tTotal Loss: 0.159413\n",
      "Reconstruction: 0.158273, Regularization: 0.001140\n",
      "2019-04-10 01:03:46,314 root         INFO     ====> Epoch: 147 Average loss: 0.1662\n",
      "2019-04-10 01:03:46,338 root         INFO     Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 0.163427\n",
      "Reconstruction: 0.162080, Regularization: 0.001347\n",
      "2019-04-10 01:03:46,401 root         INFO     Train Epoch: 148 [512/8000 (6%)]\tTotal Loss: 0.171089\n",
      "Reconstruction: 0.169572, Regularization: 0.001517\n",
      "2019-04-10 01:03:46,463 root         INFO     Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 0.170620\n",
      "Reconstruction: 0.169089, Regularization: 0.001531\n",
      "2019-04-10 01:03:46,526 root         INFO     Train Epoch: 148 [1536/8000 (19%)]\tTotal Loss: 0.165612\n",
      "Reconstruction: 0.164237, Regularization: 0.001375\n",
      "2019-04-10 01:03:46,589 root         INFO     Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 0.159289\n",
      "Reconstruction: 0.158296, Regularization: 0.000992\n",
      "2019-04-10 01:03:46,653 root         INFO     Train Epoch: 148 [2560/8000 (32%)]\tTotal Loss: 0.153653\n",
      "Reconstruction: 0.152673, Regularization: 0.000980\n",
      "2019-04-10 01:03:46,717 root         INFO     Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 0.169905\n",
      "Reconstruction: 0.168226, Regularization: 0.001679\n",
      "2019-04-10 01:03:46,778 root         INFO     Train Epoch: 148 [3584/8000 (45%)]\tTotal Loss: 0.159010\n",
      "Reconstruction: 0.157917, Regularization: 0.001093\n",
      "2019-04-10 01:03:46,839 root         INFO     Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 0.173267\n",
      "Reconstruction: 0.171528, Regularization: 0.001739\n",
      "2019-04-10 01:03:46,900 root         INFO     Train Epoch: 148 [4608/8000 (58%)]\tTotal Loss: 0.160895\n",
      "Reconstruction: 0.159748, Regularization: 0.001146\n",
      "2019-04-10 01:03:46,962 root         INFO     Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 0.163123\n",
      "Reconstruction: 0.161764, Regularization: 0.001360\n",
      "2019-04-10 01:03:47,023 root         INFO     Train Epoch: 148 [5632/8000 (70%)]\tTotal Loss: 0.170431\n",
      "Reconstruction: 0.168763, Regularization: 0.001668\n",
      "2019-04-10 01:03:47,084 root         INFO     Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 0.175579\n",
      "Reconstruction: 0.173877, Regularization: 0.001702\n",
      "2019-04-10 01:03:47,145 root         INFO     Train Epoch: 148 [6656/8000 (83%)]\tTotal Loss: 0.176715\n",
      "Reconstruction: 0.174788, Regularization: 0.001928\n",
      "2019-04-10 01:03:47,206 root         INFO     Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 0.166595\n",
      "Reconstruction: 0.165119, Regularization: 0.001477\n",
      "2019-04-10 01:03:47,268 root         INFO     Train Epoch: 148 [7680/8000 (96%)]\tTotal Loss: 0.170678\n",
      "Reconstruction: 0.168808, Regularization: 0.001870\n",
      "2019-04-10 01:03:47,321 root         INFO     ====> Epoch: 148 Average loss: 0.1658\n",
      "2019-04-10 01:03:47,345 root         INFO     Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 0.167926\n",
      "Reconstruction: 0.166520, Regularization: 0.001406\n",
      "2019-04-10 01:03:47,409 root         INFO     Train Epoch: 149 [512/8000 (6%)]\tTotal Loss: 0.155826\n",
      "Reconstruction: 0.154785, Regularization: 0.001040\n",
      "2019-04-10 01:03:47,471 root         INFO     Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 0.161195\n",
      "Reconstruction: 0.160042, Regularization: 0.001154\n",
      "2019-04-10 01:03:47,535 root         INFO     Train Epoch: 149 [1536/8000 (19%)]\tTotal Loss: 0.157582\n",
      "Reconstruction: 0.156778, Regularization: 0.000804\n",
      "2019-04-10 01:03:47,597 root         INFO     Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 0.155981\n",
      "Reconstruction: 0.155029, Regularization: 0.000952\n",
      "2019-04-10 01:03:47,658 root         INFO     Train Epoch: 149 [2560/8000 (32%)]\tTotal Loss: 0.175494\n",
      "Reconstruction: 0.173728, Regularization: 0.001767\n",
      "2019-04-10 01:03:47,721 root         INFO     Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 0.167877\n",
      "Reconstruction: 0.166157, Regularization: 0.001720\n",
      "2019-04-10 01:03:47,784 root         INFO     Train Epoch: 149 [3584/8000 (45%)]\tTotal Loss: 0.158702\n",
      "Reconstruction: 0.157528, Regularization: 0.001174\n",
      "2019-04-10 01:03:47,847 root         INFO     Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 0.157018\n",
      "Reconstruction: 0.155899, Regularization: 0.001119\n",
      "2019-04-10 01:03:47,910 root         INFO     Train Epoch: 149 [4608/8000 (58%)]\tTotal Loss: 0.164261\n",
      "Reconstruction: 0.162633, Regularization: 0.001627\n",
      "2019-04-10 01:03:47,974 root         INFO     Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 0.173171\n",
      "Reconstruction: 0.171354, Regularization: 0.001817\n",
      "2019-04-10 01:03:48,037 root         INFO     Train Epoch: 149 [5632/8000 (70%)]\tTotal Loss: 0.174288\n",
      "Reconstruction: 0.172463, Regularization: 0.001826\n",
      "2019-04-10 01:03:48,100 root         INFO     Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 0.163688\n",
      "Reconstruction: 0.162285, Regularization: 0.001404\n",
      "2019-04-10 01:03:48,162 root         INFO     Train Epoch: 149 [6656/8000 (83%)]\tTotal Loss: 0.174409\n",
      "Reconstruction: 0.172507, Regularization: 0.001902\n",
      "2019-04-10 01:03:48,223 root         INFO     Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 0.166740\n",
      "Reconstruction: 0.165367, Regularization: 0.001374\n",
      "2019-04-10 01:03:48,284 root         INFO     Train Epoch: 149 [7680/8000 (96%)]\tTotal Loss: 0.168229\n",
      "Reconstruction: 0.166648, Regularization: 0.001581\n",
      "2019-04-10 01:03:48,337 root         INFO     ====> Epoch: 149 Average loss: 0.1659\n",
      "2019-04-10 01:03:48,361 root         INFO     Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 0.165154\n",
      "Reconstruction: 0.163634, Regularization: 0.001520\n",
      "2019-04-10 01:03:48,425 root         INFO     Train Epoch: 150 [512/8000 (6%)]\tTotal Loss: 0.160563\n",
      "Reconstruction: 0.159124, Regularization: 0.001439\n",
      "2019-04-10 01:03:48,488 root         INFO     Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 0.165887\n",
      "Reconstruction: 0.164297, Regularization: 0.001590\n",
      "2019-04-10 01:03:48,551 root         INFO     Train Epoch: 150 [1536/8000 (19%)]\tTotal Loss: 0.169015\n",
      "Reconstruction: 0.167292, Regularization: 0.001723\n",
      "2019-04-10 01:03:48,614 root         INFO     Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 0.172986\n",
      "Reconstruction: 0.171169, Regularization: 0.001817\n",
      "2019-04-10 01:03:48,677 root         INFO     Train Epoch: 150 [2560/8000 (32%)]\tTotal Loss: 0.174479\n",
      "Reconstruction: 0.172740, Regularization: 0.001739\n",
      "2019-04-10 01:03:48,740 root         INFO     Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 0.157258\n",
      "Reconstruction: 0.156178, Regularization: 0.001080\n",
      "2019-04-10 01:03:48,803 root         INFO     Train Epoch: 150 [3584/8000 (45%)]\tTotal Loss: 0.158485\n",
      "Reconstruction: 0.157345, Regularization: 0.001140\n",
      "2019-04-10 01:03:48,866 root         INFO     Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 0.180329\n",
      "Reconstruction: 0.178187, Regularization: 0.002142\n",
      "2019-04-10 01:03:48,929 root         INFO     Train Epoch: 150 [4608/8000 (58%)]\tTotal Loss: 0.171292\n",
      "Reconstruction: 0.169500, Regularization: 0.001792\n",
      "2019-04-10 01:03:48,992 root         INFO     Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 0.150889\n",
      "Reconstruction: 0.149914, Regularization: 0.000975\n",
      "2019-04-10 01:03:49,055 root         INFO     Train Epoch: 150 [5632/8000 (70%)]\tTotal Loss: 0.165318\n",
      "Reconstruction: 0.163782, Regularization: 0.001536\n",
      "2019-04-10 01:03:49,117 root         INFO     Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 0.165763\n",
      "Reconstruction: 0.164199, Regularization: 0.001564\n",
      "2019-04-10 01:03:49,180 root         INFO     Train Epoch: 150 [6656/8000 (83%)]\tTotal Loss: 0.167324\n",
      "Reconstruction: 0.165622, Regularization: 0.001702\n",
      "2019-04-10 01:03:49,243 root         INFO     Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 0.165338\n",
      "Reconstruction: 0.163773, Regularization: 0.001565\n",
      "2019-04-10 01:03:49,306 root         INFO     Train Epoch: 150 [7680/8000 (96%)]\tTotal Loss: 0.157658\n",
      "Reconstruction: 0.156518, Regularization: 0.001140\n",
      "2019-04-10 01:03:49,360 root         INFO     ====> Epoch: 150 Average loss: 0.1661\n",
      "2019-04-10 01:03:49,384 root         INFO     Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 0.156643\n",
      "Reconstruction: 0.155524, Regularization: 0.001119\n",
      "2019-04-10 01:03:49,447 root         INFO     Train Epoch: 151 [512/8000 (6%)]\tTotal Loss: 0.160972\n",
      "Reconstruction: 0.159578, Regularization: 0.001393\n",
      "2019-04-10 01:03:49,510 root         INFO     Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 0.165288\n",
      "Reconstruction: 0.163558, Regularization: 0.001730\n",
      "2019-04-10 01:03:49,574 root         INFO     Train Epoch: 151 [1536/8000 (19%)]\tTotal Loss: 0.174244\n",
      "Reconstruction: 0.172332, Regularization: 0.001912\n",
      "2019-04-10 01:03:49,637 root         INFO     Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 0.160088\n",
      "Reconstruction: 0.158912, Regularization: 0.001176\n",
      "2019-04-10 01:03:49,700 root         INFO     Train Epoch: 151 [2560/8000 (32%)]\tTotal Loss: 0.158759\n",
      "Reconstruction: 0.157537, Regularization: 0.001222\n",
      "2019-04-10 01:03:49,762 root         INFO     Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 0.174446\n",
      "Reconstruction: 0.172752, Regularization: 0.001694\n",
      "2019-04-10 01:03:49,824 root         INFO     Train Epoch: 151 [3584/8000 (45%)]\tTotal Loss: 0.166461\n",
      "Reconstruction: 0.164981, Regularization: 0.001480\n",
      "2019-04-10 01:03:49,886 root         INFO     Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 0.167288\n",
      "Reconstruction: 0.165757, Regularization: 0.001531\n",
      "2019-04-10 01:03:49,949 root         INFO     Train Epoch: 151 [4608/8000 (58%)]\tTotal Loss: 0.160139\n",
      "Reconstruction: 0.158942, Regularization: 0.001197\n",
      "2019-04-10 01:03:50,011 root         INFO     Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 0.167811\n",
      "Reconstruction: 0.166093, Regularization: 0.001717\n",
      "2019-04-10 01:03:50,073 root         INFO     Train Epoch: 151 [5632/8000 (70%)]\tTotal Loss: 0.164606\n",
      "Reconstruction: 0.163274, Regularization: 0.001332\n",
      "2019-04-10 01:03:50,134 root         INFO     Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 0.170517\n",
      "Reconstruction: 0.168593, Regularization: 0.001923\n",
      "2019-04-10 01:03:50,195 root         INFO     Train Epoch: 151 [6656/8000 (83%)]\tTotal Loss: 0.160503\n",
      "Reconstruction: 0.159213, Regularization: 0.001290\n",
      "2019-04-10 01:03:50,257 root         INFO     Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 0.163417\n",
      "Reconstruction: 0.162159, Regularization: 0.001259\n",
      "2019-04-10 01:03:50,319 root         INFO     Train Epoch: 151 [7680/8000 (96%)]\tTotal Loss: 0.161341\n",
      "Reconstruction: 0.159921, Regularization: 0.001420\n",
      "2019-04-10 01:03:50,373 root         INFO     ====> Epoch: 151 Average loss: 0.1660\n",
      "2019-04-10 01:03:50,398 root         INFO     Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 0.173090\n",
      "Reconstruction: 0.171278, Regularization: 0.001812\n",
      "2019-04-10 01:03:50,460 root         INFO     Train Epoch: 152 [512/8000 (6%)]\tTotal Loss: 0.172809\n",
      "Reconstruction: 0.170765, Regularization: 0.002043\n",
      "2019-04-10 01:03:50,522 root         INFO     Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 0.164840\n",
      "Reconstruction: 0.163055, Regularization: 0.001785\n",
      "2019-04-10 01:03:50,584 root         INFO     Train Epoch: 152 [1536/8000 (19%)]\tTotal Loss: 0.165614\n",
      "Reconstruction: 0.164221, Regularization: 0.001393\n",
      "2019-04-10 01:03:50,645 root         INFO     Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 0.153691\n",
      "Reconstruction: 0.152786, Regularization: 0.000905\n",
      "2019-04-10 01:03:50,706 root         INFO     Train Epoch: 152 [2560/8000 (32%)]\tTotal Loss: 0.178935\n",
      "Reconstruction: 0.176926, Regularization: 0.002010\n",
      "2019-04-10 01:03:50,768 root         INFO     Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 0.157156\n",
      "Reconstruction: 0.155933, Regularization: 0.001223\n",
      "2019-04-10 01:03:50,829 root         INFO     Train Epoch: 152 [3584/8000 (45%)]\tTotal Loss: 0.164774\n",
      "Reconstruction: 0.163343, Regularization: 0.001431\n",
      "2019-04-10 01:03:50,890 root         INFO     Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 0.172788\n",
      "Reconstruction: 0.171039, Regularization: 0.001750\n",
      "2019-04-10 01:03:50,951 root         INFO     Train Epoch: 152 [4608/8000 (58%)]\tTotal Loss: 0.166216\n",
      "Reconstruction: 0.164594, Regularization: 0.001622\n",
      "2019-04-10 01:03:51,012 root         INFO     Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 0.167233\n",
      "Reconstruction: 0.165343, Regularization: 0.001891\n",
      "2019-04-10 01:03:51,074 root         INFO     Train Epoch: 152 [5632/8000 (70%)]\tTotal Loss: 0.164281\n",
      "Reconstruction: 0.162889, Regularization: 0.001392\n",
      "2019-04-10 01:03:51,135 root         INFO     Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 0.171581\n",
      "Reconstruction: 0.169789, Regularization: 0.001792\n",
      "2019-04-10 01:03:51,196 root         INFO     Train Epoch: 152 [6656/8000 (83%)]\tTotal Loss: 0.162776\n",
      "Reconstruction: 0.161207, Regularization: 0.001569\n",
      "2019-04-10 01:03:51,258 root         INFO     Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 0.163525\n",
      "Reconstruction: 0.162095, Regularization: 0.001430\n",
      "2019-04-10 01:03:51,319 root         INFO     Train Epoch: 152 [7680/8000 (96%)]\tTotal Loss: 0.163618\n",
      "Reconstruction: 0.162180, Regularization: 0.001438\n",
      "2019-04-10 01:03:51,372 root         INFO     ====> Epoch: 152 Average loss: 0.1660\n",
      "2019-04-10 01:03:51,396 root         INFO     Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 0.174211\n",
      "Reconstruction: 0.172179, Regularization: 0.002032\n",
      "2019-04-10 01:03:51,460 root         INFO     Train Epoch: 153 [512/8000 (6%)]\tTotal Loss: 0.168606\n",
      "Reconstruction: 0.166605, Regularization: 0.002002\n",
      "2019-04-10 01:03:51,523 root         INFO     Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 0.162852\n",
      "Reconstruction: 0.161433, Regularization: 0.001419\n",
      "2019-04-10 01:03:51,586 root         INFO     Train Epoch: 153 [1536/8000 (19%)]\tTotal Loss: 0.155128\n",
      "Reconstruction: 0.153876, Regularization: 0.001252\n",
      "2019-04-10 01:03:51,649 root         INFO     Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 0.168369\n",
      "Reconstruction: 0.166695, Regularization: 0.001674\n",
      "2019-04-10 01:03:51,713 root         INFO     Train Epoch: 153 [2560/8000 (32%)]\tTotal Loss: 0.169365\n",
      "Reconstruction: 0.167639, Regularization: 0.001725\n",
      "2019-04-10 01:03:51,776 root         INFO     Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 0.190033\n",
      "Reconstruction: 0.187482, Regularization: 0.002552\n",
      "2019-04-10 01:03:51,839 root         INFO     Train Epoch: 153 [3584/8000 (45%)]\tTotal Loss: 0.161096\n",
      "Reconstruction: 0.159935, Regularization: 0.001160\n",
      "2019-04-10 01:03:51,902 root         INFO     Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 0.168924\n",
      "Reconstruction: 0.166721, Regularization: 0.002203\n",
      "2019-04-10 01:03:51,965 root         INFO     Train Epoch: 153 [4608/8000 (58%)]\tTotal Loss: 0.161002\n",
      "Reconstruction: 0.159664, Regularization: 0.001338\n",
      "2019-04-10 01:03:52,028 root         INFO     Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 0.161533\n",
      "Reconstruction: 0.160024, Regularization: 0.001509\n",
      "2019-04-10 01:03:52,091 root         INFO     Train Epoch: 153 [5632/8000 (70%)]\tTotal Loss: 0.170818\n",
      "Reconstruction: 0.168941, Regularization: 0.001878\n",
      "2019-04-10 01:03:52,154 root         INFO     Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 0.164880\n",
      "Reconstruction: 0.163442, Regularization: 0.001438\n",
      "2019-04-10 01:03:52,217 root         INFO     Train Epoch: 153 [6656/8000 (83%)]\tTotal Loss: 0.168834\n",
      "Reconstruction: 0.167081, Regularization: 0.001753\n",
      "2019-04-10 01:03:52,280 root         INFO     Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 0.164601\n",
      "Reconstruction: 0.163049, Regularization: 0.001551\n",
      "2019-04-10 01:03:52,343 root         INFO     Train Epoch: 153 [7680/8000 (96%)]\tTotal Loss: 0.173358\n",
      "Reconstruction: 0.171255, Regularization: 0.002103\n",
      "2019-04-10 01:03:52,396 root         INFO     ====> Epoch: 153 Average loss: 0.1660\n",
      "2019-04-10 01:03:52,421 root         INFO     Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 0.170576\n",
      "Reconstruction: 0.168928, Regularization: 0.001647\n",
      "2019-04-10 01:03:52,485 root         INFO     Train Epoch: 154 [512/8000 (6%)]\tTotal Loss: 0.178304\n",
      "Reconstruction: 0.176104, Regularization: 0.002200\n",
      "2019-04-10 01:03:52,549 root         INFO     Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 0.177471\n",
      "Reconstruction: 0.175307, Regularization: 0.002165\n",
      "2019-04-10 01:03:52,613 root         INFO     Train Epoch: 154 [1536/8000 (19%)]\tTotal Loss: 0.161376\n",
      "Reconstruction: 0.160074, Regularization: 0.001302\n",
      "2019-04-10 01:03:52,677 root         INFO     Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 0.166542\n",
      "Reconstruction: 0.164840, Regularization: 0.001702\n",
      "2019-04-10 01:03:52,741 root         INFO     Train Epoch: 154 [2560/8000 (32%)]\tTotal Loss: 0.170264\n",
      "Reconstruction: 0.168224, Regularization: 0.002040\n",
      "2019-04-10 01:03:52,805 root         INFO     Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 0.172913\n",
      "Reconstruction: 0.170888, Regularization: 0.002025\n",
      "2019-04-10 01:03:52,869 root         INFO     Train Epoch: 154 [3584/8000 (45%)]\tTotal Loss: 0.159233\n",
      "Reconstruction: 0.157827, Regularization: 0.001406\n",
      "2019-04-10 01:03:52,933 root         INFO     Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 0.169684\n",
      "Reconstruction: 0.167963, Regularization: 0.001720\n",
      "2019-04-10 01:03:52,996 root         INFO     Train Epoch: 154 [4608/8000 (58%)]\tTotal Loss: 0.163766\n",
      "Reconstruction: 0.162231, Regularization: 0.001535\n",
      "2019-04-10 01:03:53,059 root         INFO     Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 0.156392\n",
      "Reconstruction: 0.155260, Regularization: 0.001132\n",
      "2019-04-10 01:03:53,122 root         INFO     Train Epoch: 154 [5632/8000 (70%)]\tTotal Loss: 0.164364\n",
      "Reconstruction: 0.162683, Regularization: 0.001681\n",
      "2019-04-10 01:03:53,185 root         INFO     Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 0.167556\n",
      "Reconstruction: 0.165804, Regularization: 0.001753\n",
      "2019-04-10 01:03:53,247 root         INFO     Train Epoch: 154 [6656/8000 (83%)]\tTotal Loss: 0.161923\n",
      "Reconstruction: 0.160332, Regularization: 0.001592\n",
      "2019-04-10 01:03:53,308 root         INFO     Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 0.173586\n",
      "Reconstruction: 0.171331, Regularization: 0.002255\n",
      "2019-04-10 01:03:53,369 root         INFO     Train Epoch: 154 [7680/8000 (96%)]\tTotal Loss: 0.169546\n",
      "Reconstruction: 0.167746, Regularization: 0.001800\n",
      "2019-04-10 01:03:53,423 root         INFO     ====> Epoch: 154 Average loss: 0.1661\n",
      "2019-04-10 01:03:53,448 root         INFO     Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 0.163872\n",
      "Reconstruction: 0.162278, Regularization: 0.001595\n",
      "2019-04-10 01:03:53,512 root         INFO     Train Epoch: 155 [512/8000 (6%)]\tTotal Loss: 0.160944\n",
      "Reconstruction: 0.159718, Regularization: 0.001226\n",
      "2019-04-10 01:03:53,575 root         INFO     Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 0.168897\n",
      "Reconstruction: 0.167208, Regularization: 0.001689\n",
      "2019-04-10 01:03:53,638 root         INFO     Train Epoch: 155 [1536/8000 (19%)]\tTotal Loss: 0.153212\n",
      "Reconstruction: 0.152034, Regularization: 0.001178\n",
      "2019-04-10 01:03:53,702 root         INFO     Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 0.169461\n",
      "Reconstruction: 0.167539, Regularization: 0.001922\n",
      "2019-04-10 01:03:53,766 root         INFO     Train Epoch: 155 [2560/8000 (32%)]\tTotal Loss: 0.164330\n",
      "Reconstruction: 0.162850, Regularization: 0.001480\n",
      "2019-04-10 01:03:53,829 root         INFO     Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 0.171860\n",
      "Reconstruction: 0.169779, Regularization: 0.002081\n",
      "2019-04-10 01:03:53,892 root         INFO     Train Epoch: 155 [3584/8000 (45%)]\tTotal Loss: 0.176909\n",
      "Reconstruction: 0.174617, Regularization: 0.002292\n",
      "2019-04-10 01:03:53,955 root         INFO     Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 0.162150\n",
      "Reconstruction: 0.160423, Regularization: 0.001727\n",
      "2019-04-10 01:03:54,018 root         INFO     Train Epoch: 155 [4608/8000 (58%)]\tTotal Loss: 0.180578\n",
      "Reconstruction: 0.177955, Regularization: 0.002624\n",
      "2019-04-10 01:03:54,081 root         INFO     Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 0.178984\n",
      "Reconstruction: 0.176488, Regularization: 0.002496\n",
      "2019-04-10 01:03:54,145 root         INFO     Train Epoch: 155 [5632/8000 (70%)]\tTotal Loss: 0.175821\n",
      "Reconstruction: 0.173417, Regularization: 0.002404\n",
      "2019-04-10 01:03:54,209 root         INFO     Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 0.175802\n",
      "Reconstruction: 0.173546, Regularization: 0.002256\n",
      "2019-04-10 01:03:54,272 root         INFO     Train Epoch: 155 [6656/8000 (83%)]\tTotal Loss: 0.157577\n",
      "Reconstruction: 0.156372, Regularization: 0.001206\n",
      "2019-04-10 01:03:54,335 root         INFO     Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 0.169288\n",
      "Reconstruction: 0.167217, Regularization: 0.002071\n",
      "2019-04-10 01:03:54,398 root         INFO     Train Epoch: 155 [7680/8000 (96%)]\tTotal Loss: 0.164765\n",
      "Reconstruction: 0.162841, Regularization: 0.001924\n",
      "2019-04-10 01:03:54,452 root         INFO     ====> Epoch: 155 Average loss: 0.1660\n",
      "2019-04-10 01:03:54,476 root         INFO     Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 0.168494\n",
      "Reconstruction: 0.166422, Regularization: 0.002071\n",
      "2019-04-10 01:03:54,540 root         INFO     Train Epoch: 156 [512/8000 (6%)]\tTotal Loss: 0.175198\n",
      "Reconstruction: 0.173313, Regularization: 0.001885\n",
      "2019-04-10 01:03:54,603 root         INFO     Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 0.168834\n",
      "Reconstruction: 0.166847, Regularization: 0.001987\n",
      "2019-04-10 01:03:54,668 root         INFO     Train Epoch: 156 [1536/8000 (19%)]\tTotal Loss: 0.167038\n",
      "Reconstruction: 0.165323, Regularization: 0.001714\n",
      "2019-04-10 01:03:54,732 root         INFO     Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 0.162385\n",
      "Reconstruction: 0.160727, Regularization: 0.001658\n",
      "2019-04-10 01:03:54,795 root         INFO     Train Epoch: 156 [2560/8000 (32%)]\tTotal Loss: 0.159537\n",
      "Reconstruction: 0.158255, Regularization: 0.001282\n",
      "2019-04-10 01:03:54,859 root         INFO     Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 0.161332\n",
      "Reconstruction: 0.159868, Regularization: 0.001464\n",
      "2019-04-10 01:03:54,924 root         INFO     Train Epoch: 156 [3584/8000 (45%)]\tTotal Loss: 0.152623\n",
      "Reconstruction: 0.151583, Regularization: 0.001040\n",
      "2019-04-10 01:03:54,988 root         INFO     Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 0.166068\n",
      "Reconstruction: 0.163943, Regularization: 0.002125\n",
      "2019-04-10 01:03:55,051 root         INFO     Train Epoch: 156 [4608/8000 (58%)]\tTotal Loss: 0.161371\n",
      "Reconstruction: 0.159652, Regularization: 0.001720\n",
      "2019-04-10 01:03:55,115 root         INFO     Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 0.174293\n",
      "Reconstruction: 0.172029, Regularization: 0.002264\n",
      "2019-04-10 01:03:55,180 root         INFO     Train Epoch: 156 [5632/8000 (70%)]\tTotal Loss: 0.160161\n",
      "Reconstruction: 0.158632, Regularization: 0.001529\n",
      "2019-04-10 01:03:55,243 root         INFO     Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 0.168257\n",
      "Reconstruction: 0.165658, Regularization: 0.002599\n",
      "2019-04-10 01:03:55,307 root         INFO     Train Epoch: 156 [6656/8000 (83%)]\tTotal Loss: 0.157886\n",
      "Reconstruction: 0.156624, Regularization: 0.001262\n",
      "2019-04-10 01:03:55,371 root         INFO     Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 0.198364\n",
      "Reconstruction: 0.194982, Regularization: 0.003382\n",
      "2019-04-10 01:03:55,435 root         INFO     Train Epoch: 156 [7680/8000 (96%)]\tTotal Loss: 0.178465\n",
      "Reconstruction: 0.176026, Regularization: 0.002440\n",
      "2019-04-10 01:03:55,488 root         INFO     ====> Epoch: 156 Average loss: 0.1658\n",
      "2019-04-10 01:03:55,513 root         INFO     Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 0.159915\n",
      "Reconstruction: 0.158240, Regularization: 0.001675\n",
      "2019-04-10 01:03:55,578 root         INFO     Train Epoch: 157 [512/8000 (6%)]\tTotal Loss: 0.165612\n",
      "Reconstruction: 0.163718, Regularization: 0.001894\n",
      "2019-04-10 01:03:55,641 root         INFO     Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 0.163238\n",
      "Reconstruction: 0.161872, Regularization: 0.001367\n",
      "2019-04-10 01:03:55,705 root         INFO     Train Epoch: 157 [1536/8000 (19%)]\tTotal Loss: 0.170178\n",
      "Reconstruction: 0.168068, Regularization: 0.002110\n",
      "2019-04-10 01:03:55,769 root         INFO     Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 0.166469\n",
      "Reconstruction: 0.164514, Regularization: 0.001956\n",
      "2019-04-10 01:03:55,832 root         INFO     Train Epoch: 157 [2560/8000 (32%)]\tTotal Loss: 0.176672\n",
      "Reconstruction: 0.174136, Regularization: 0.002536\n",
      "2019-04-10 01:03:55,896 root         INFO     Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 0.171028\n",
      "Reconstruction: 0.169061, Regularization: 0.001967\n",
      "2019-04-10 01:03:55,959 root         INFO     Train Epoch: 157 [3584/8000 (45%)]\tTotal Loss: 0.186478\n",
      "Reconstruction: 0.183488, Regularization: 0.002990\n",
      "2019-04-10 01:03:56,022 root         INFO     Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 0.156891\n",
      "Reconstruction: 0.155631, Regularization: 0.001260\n",
      "2019-04-10 01:03:56,085 root         INFO     Train Epoch: 157 [4608/8000 (58%)]\tTotal Loss: 0.173759\n",
      "Reconstruction: 0.171414, Regularization: 0.002345\n",
      "2019-04-10 01:03:56,148 root         INFO     Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 0.164644\n",
      "Reconstruction: 0.162543, Regularization: 0.002100\n",
      "2019-04-10 01:03:56,211 root         INFO     Train Epoch: 157 [5632/8000 (70%)]\tTotal Loss: 0.174714\n",
      "Reconstruction: 0.172522, Regularization: 0.002192\n",
      "2019-04-10 01:03:56,274 root         INFO     Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 0.166182\n",
      "Reconstruction: 0.164333, Regularization: 0.001850\n",
      "2019-04-10 01:03:56,336 root         INFO     Train Epoch: 157 [6656/8000 (83%)]\tTotal Loss: 0.163868\n",
      "Reconstruction: 0.162075, Regularization: 0.001793\n",
      "2019-04-10 01:03:56,398 root         INFO     Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 0.178743\n",
      "Reconstruction: 0.175788, Regularization: 0.002955\n",
      "2019-04-10 01:03:56,460 root         INFO     Train Epoch: 157 [7680/8000 (96%)]\tTotal Loss: 0.169669\n",
      "Reconstruction: 0.167656, Regularization: 0.002013\n",
      "2019-04-10 01:03:56,513 root         INFO     ====> Epoch: 157 Average loss: 0.1659\n",
      "2019-04-10 01:03:56,537 root         INFO     Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 0.164273\n",
      "Reconstruction: 0.162516, Regularization: 0.001757\n",
      "2019-04-10 01:03:56,601 root         INFO     Train Epoch: 158 [512/8000 (6%)]\tTotal Loss: 0.163715\n",
      "Reconstruction: 0.161868, Regularization: 0.001847\n",
      "2019-04-10 01:03:56,666 root         INFO     Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 0.170854\n",
      "Reconstruction: 0.168595, Regularization: 0.002259\n",
      "2019-04-10 01:03:56,730 root         INFO     Train Epoch: 158 [1536/8000 (19%)]\tTotal Loss: 0.163835\n",
      "Reconstruction: 0.161896, Regularization: 0.001939\n",
      "2019-04-10 01:03:56,793 root         INFO     Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 0.166938\n",
      "Reconstruction: 0.165044, Regularization: 0.001894\n",
      "2019-04-10 01:03:56,857 root         INFO     Train Epoch: 158 [2560/8000 (32%)]\tTotal Loss: 0.164785\n",
      "Reconstruction: 0.162929, Regularization: 0.001856\n",
      "2019-04-10 01:03:56,921 root         INFO     Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 0.163314\n",
      "Reconstruction: 0.161276, Regularization: 0.002038\n",
      "2019-04-10 01:03:56,984 root         INFO     Train Epoch: 158 [3584/8000 (45%)]\tTotal Loss: 0.171970\n",
      "Reconstruction: 0.169614, Regularization: 0.002356\n",
      "2019-04-10 01:03:57,047 root         INFO     Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 0.167323\n",
      "Reconstruction: 0.165268, Regularization: 0.002054\n",
      "2019-04-10 01:03:57,111 root         INFO     Train Epoch: 158 [4608/8000 (58%)]\tTotal Loss: 0.173060\n",
      "Reconstruction: 0.170787, Regularization: 0.002273\n",
      "2019-04-10 01:03:57,175 root         INFO     Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 0.165777\n",
      "Reconstruction: 0.163780, Regularization: 0.001998\n",
      "2019-04-10 01:03:57,239 root         INFO     Train Epoch: 158 [5632/8000 (70%)]\tTotal Loss: 0.164436\n",
      "Reconstruction: 0.162289, Regularization: 0.002147\n",
      "2019-04-10 01:03:57,303 root         INFO     Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 0.154460\n",
      "Reconstruction: 0.153417, Regularization: 0.001043\n",
      "2019-04-10 01:03:57,367 root         INFO     Train Epoch: 158 [6656/8000 (83%)]\tTotal Loss: 0.163471\n",
      "Reconstruction: 0.161705, Regularization: 0.001765\n",
      "2019-04-10 01:03:57,431 root         INFO     Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 0.168898\n",
      "Reconstruction: 0.166633, Regularization: 0.002266\n",
      "2019-04-10 01:03:57,495 root         INFO     Train Epoch: 158 [7680/8000 (96%)]\tTotal Loss: 0.159968\n",
      "Reconstruction: 0.158226, Regularization: 0.001742\n",
      "2019-04-10 01:03:57,549 root         INFO     ====> Epoch: 158 Average loss: 0.1659\n",
      "2019-04-10 01:03:57,573 root         INFO     Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 0.170350\n",
      "Reconstruction: 0.168167, Regularization: 0.002183\n",
      "2019-04-10 01:03:57,636 root         INFO     Train Epoch: 159 [512/8000 (6%)]\tTotal Loss: 0.160172\n",
      "Reconstruction: 0.158461, Regularization: 0.001712\n",
      "2019-04-10 01:03:57,699 root         INFO     Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 0.166172\n",
      "Reconstruction: 0.164285, Regularization: 0.001887\n",
      "2019-04-10 01:03:57,763 root         INFO     Train Epoch: 159 [1536/8000 (19%)]\tTotal Loss: 0.164334\n",
      "Reconstruction: 0.162491, Regularization: 0.001842\n",
      "2019-04-10 01:03:57,826 root         INFO     Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 0.172979\n",
      "Reconstruction: 0.170503, Regularization: 0.002476\n",
      "2019-04-10 01:03:57,890 root         INFO     Train Epoch: 159 [2560/8000 (32%)]\tTotal Loss: 0.164332\n",
      "Reconstruction: 0.162498, Regularization: 0.001834\n",
      "2019-04-10 01:03:57,954 root         INFO     Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 0.162742\n",
      "Reconstruction: 0.160637, Regularization: 0.002106\n",
      "2019-04-10 01:03:58,017 root         INFO     Train Epoch: 159 [3584/8000 (45%)]\tTotal Loss: 0.167019\n",
      "Reconstruction: 0.165096, Regularization: 0.001923\n",
      "2019-04-10 01:03:58,081 root         INFO     Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 0.166342\n",
      "Reconstruction: 0.164398, Regularization: 0.001944\n",
      "2019-04-10 01:03:58,144 root         INFO     Train Epoch: 159 [4608/8000 (58%)]\tTotal Loss: 0.168805\n",
      "Reconstruction: 0.166595, Regularization: 0.002210\n",
      "2019-04-10 01:03:58,207 root         INFO     Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 0.164231\n",
      "Reconstruction: 0.162303, Regularization: 0.001929\n",
      "2019-04-10 01:03:58,270 root         INFO     Train Epoch: 159 [5632/8000 (70%)]\tTotal Loss: 0.172610\n",
      "Reconstruction: 0.170108, Regularization: 0.002502\n",
      "2019-04-10 01:03:58,332 root         INFO     Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 0.153951\n",
      "Reconstruction: 0.152726, Regularization: 0.001225\n",
      "2019-04-10 01:03:58,394 root         INFO     Train Epoch: 159 [6656/8000 (83%)]\tTotal Loss: 0.168226\n",
      "Reconstruction: 0.165998, Regularization: 0.002228\n",
      "2019-04-10 01:03:58,456 root         INFO     Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 0.156317\n",
      "Reconstruction: 0.154717, Regularization: 0.001599\n",
      "2019-04-10 01:03:58,519 root         INFO     Train Epoch: 159 [7680/8000 (96%)]\tTotal Loss: 0.163742\n",
      "Reconstruction: 0.161788, Regularization: 0.001954\n",
      "2019-04-10 01:03:58,573 root         INFO     ====> Epoch: 159 Average loss: 0.1657\n",
      "2019-04-10 01:03:58,596 root         INFO     Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 0.171013\n",
      "Reconstruction: 0.168712, Regularization: 0.002301\n",
      "2019-04-10 01:03:58,661 root         INFO     Train Epoch: 160 [512/8000 (6%)]\tTotal Loss: 0.159582\n",
      "Reconstruction: 0.157883, Regularization: 0.001699\n",
      "2019-04-10 01:03:58,724 root         INFO     Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 0.184997\n",
      "Reconstruction: 0.181471, Regularization: 0.003526\n",
      "2019-04-10 01:03:58,787 root         INFO     Train Epoch: 160 [1536/8000 (19%)]\tTotal Loss: 0.172269\n",
      "Reconstruction: 0.169945, Regularization: 0.002324\n",
      "2019-04-10 01:03:58,850 root         INFO     Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 0.162285\n",
      "Reconstruction: 0.160630, Regularization: 0.001656\n",
      "2019-04-10 01:03:58,913 root         INFO     Train Epoch: 160 [2560/8000 (32%)]\tTotal Loss: 0.177490\n",
      "Reconstruction: 0.174710, Regularization: 0.002779\n",
      "2019-04-10 01:03:58,977 root         INFO     Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 0.166627\n",
      "Reconstruction: 0.164461, Regularization: 0.002166\n",
      "2019-04-10 01:03:59,040 root         INFO     Train Epoch: 160 [3584/8000 (45%)]\tTotal Loss: 0.157735\n",
      "Reconstruction: 0.156367, Regularization: 0.001368\n",
      "2019-04-10 01:03:59,103 root         INFO     Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 0.162021\n",
      "Reconstruction: 0.159844, Regularization: 0.002177\n",
      "2019-04-10 01:03:59,167 root         INFO     Train Epoch: 160 [4608/8000 (58%)]\tTotal Loss: 0.173002\n",
      "Reconstruction: 0.170619, Regularization: 0.002383\n",
      "2019-04-10 01:03:59,230 root         INFO     Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 0.176731\n",
      "Reconstruction: 0.174133, Regularization: 0.002598\n",
      "2019-04-10 01:03:59,293 root         INFO     Train Epoch: 160 [5632/8000 (70%)]\tTotal Loss: 0.161938\n",
      "Reconstruction: 0.159656, Regularization: 0.002282\n",
      "2019-04-10 01:03:59,356 root         INFO     Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 0.162389\n",
      "Reconstruction: 0.160485, Regularization: 0.001904\n",
      "2019-04-10 01:03:59,420 root         INFO     Train Epoch: 160 [6656/8000 (83%)]\tTotal Loss: 0.162328\n",
      "Reconstruction: 0.160430, Regularization: 0.001898\n",
      "2019-04-10 01:03:59,483 root         INFO     Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 0.156201\n",
      "Reconstruction: 0.154797, Regularization: 0.001404\n",
      "2019-04-10 01:03:59,546 root         INFO     Train Epoch: 160 [7680/8000 (96%)]\tTotal Loss: 0.160440\n",
      "Reconstruction: 0.158415, Regularization: 0.002024\n",
      "2019-04-10 01:03:59,600 root         INFO     ====> Epoch: 160 Average loss: 0.1657\n",
      "2019-04-10 01:03:59,624 root         INFO     Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 0.174690\n",
      "Reconstruction: 0.172198, Regularization: 0.002492\n",
      "2019-04-10 01:03:59,688 root         INFO     Train Epoch: 161 [512/8000 (6%)]\tTotal Loss: 0.159763\n",
      "Reconstruction: 0.158214, Regularization: 0.001550\n",
      "2019-04-10 01:03:59,752 root         INFO     Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 0.160899\n",
      "Reconstruction: 0.159126, Regularization: 0.001773\n",
      "2019-04-10 01:03:59,815 root         INFO     Train Epoch: 161 [1536/8000 (19%)]\tTotal Loss: 0.156639\n",
      "Reconstruction: 0.155053, Regularization: 0.001586\n",
      "2019-04-10 01:03:59,879 root         INFO     Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 0.159745\n",
      "Reconstruction: 0.157853, Regularization: 0.001892\n",
      "2019-04-10 01:03:59,942 root         INFO     Train Epoch: 161 [2560/8000 (32%)]\tTotal Loss: 0.165711\n",
      "Reconstruction: 0.163484, Regularization: 0.002228\n",
      "2019-04-10 01:04:00,006 root         INFO     Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 0.165738\n",
      "Reconstruction: 0.163615, Regularization: 0.002122\n",
      "2019-04-10 01:04:00,069 root         INFO     Train Epoch: 161 [3584/8000 (45%)]\tTotal Loss: 0.179658\n",
      "Reconstruction: 0.176503, Regularization: 0.003154\n",
      "2019-04-10 01:04:00,133 root         INFO     Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 0.168764\n",
      "Reconstruction: 0.166159, Regularization: 0.002605\n",
      "2019-04-10 01:04:00,197 root         INFO     Train Epoch: 161 [4608/8000 (58%)]\tTotal Loss: 0.156052\n",
      "Reconstruction: 0.154185, Regularization: 0.001867\n",
      "2019-04-10 01:04:00,261 root         INFO     Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 0.183277\n",
      "Reconstruction: 0.179836, Regularization: 0.003442\n",
      "2019-04-10 01:04:00,324 root         INFO     Train Epoch: 161 [5632/8000 (70%)]\tTotal Loss: 0.163020\n",
      "Reconstruction: 0.160840, Regularization: 0.002180\n",
      "2019-04-10 01:04:00,388 root         INFO     Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 0.166148\n",
      "Reconstruction: 0.163914, Regularization: 0.002234\n",
      "2019-04-10 01:04:00,451 root         INFO     Train Epoch: 161 [6656/8000 (83%)]\tTotal Loss: 0.162821\n",
      "Reconstruction: 0.160999, Regularization: 0.001823\n",
      "2019-04-10 01:04:00,515 root         INFO     Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 0.161727\n",
      "Reconstruction: 0.159887, Regularization: 0.001840\n",
      "2019-04-10 01:04:00,578 root         INFO     Train Epoch: 161 [7680/8000 (96%)]\tTotal Loss: 0.147064\n",
      "Reconstruction: 0.145995, Regularization: 0.001069\n",
      "2019-04-10 01:04:00,632 root         INFO     ====> Epoch: 161 Average loss: 0.1660\n",
      "2019-04-10 01:04:00,656 root         INFO     Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 0.164562\n",
      "Reconstruction: 0.162643, Regularization: 0.001919\n",
      "2019-04-10 01:04:00,720 root         INFO     Train Epoch: 162 [512/8000 (6%)]\tTotal Loss: 0.156480\n",
      "Reconstruction: 0.154986, Regularization: 0.001494\n",
      "2019-04-10 01:04:00,783 root         INFO     Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 0.167774\n",
      "Reconstruction: 0.165524, Regularization: 0.002250\n",
      "2019-04-10 01:04:00,845 root         INFO     Train Epoch: 162 [1536/8000 (19%)]\tTotal Loss: 0.166064\n",
      "Reconstruction: 0.163605, Regularization: 0.002459\n",
      "2019-04-10 01:04:00,906 root         INFO     Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 0.160434\n",
      "Reconstruction: 0.158613, Regularization: 0.001821\n",
      "2019-04-10 01:04:00,968 root         INFO     Train Epoch: 162 [2560/8000 (32%)]\tTotal Loss: 0.168781\n",
      "Reconstruction: 0.166311, Regularization: 0.002470\n",
      "2019-04-10 01:04:01,030 root         INFO     Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 0.169998\n",
      "Reconstruction: 0.167414, Regularization: 0.002584\n",
      "2019-04-10 01:04:01,091 root         INFO     Train Epoch: 162 [3584/8000 (45%)]\tTotal Loss: 0.175299\n",
      "Reconstruction: 0.172569, Regularization: 0.002730\n",
      "2019-04-10 01:04:01,153 root         INFO     Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 0.158605\n",
      "Reconstruction: 0.156662, Regularization: 0.001943\n",
      "2019-04-10 01:04:01,215 root         INFO     Train Epoch: 162 [4608/8000 (58%)]\tTotal Loss: 0.173645\n",
      "Reconstruction: 0.170748, Regularization: 0.002897\n",
      "2019-04-10 01:04:01,276 root         INFO     Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 0.161493\n",
      "Reconstruction: 0.159645, Regularization: 0.001849\n",
      "2019-04-10 01:04:01,340 root         INFO     Train Epoch: 162 [5632/8000 (70%)]\tTotal Loss: 0.157790\n",
      "Reconstruction: 0.156054, Regularization: 0.001737\n",
      "2019-04-10 01:04:01,403 root         INFO     Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 0.165572\n",
      "Reconstruction: 0.163337, Regularization: 0.002235\n",
      "2019-04-10 01:04:01,466 root         INFO     Train Epoch: 162 [6656/8000 (83%)]\tTotal Loss: 0.169063\n",
      "Reconstruction: 0.166734, Regularization: 0.002329\n",
      "2019-04-10 01:04:01,529 root         INFO     Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 0.173610\n",
      "Reconstruction: 0.170893, Regularization: 0.002717\n",
      "2019-04-10 01:04:01,593 root         INFO     Train Epoch: 162 [7680/8000 (96%)]\tTotal Loss: 0.167364\n",
      "Reconstruction: 0.164885, Regularization: 0.002480\n",
      "2019-04-10 01:04:01,646 root         INFO     ====> Epoch: 162 Average loss: 0.1656\n",
      "2019-04-10 01:04:01,670 root         INFO     Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 0.182052\n",
      "Reconstruction: 0.178964, Regularization: 0.003088\n",
      "2019-04-10 01:04:01,733 root         INFO     Train Epoch: 163 [512/8000 (6%)]\tTotal Loss: 0.162006\n",
      "Reconstruction: 0.159945, Regularization: 0.002060\n",
      "2019-04-10 01:04:01,796 root         INFO     Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 0.163130\n",
      "Reconstruction: 0.160825, Regularization: 0.002304\n",
      "2019-04-10 01:04:01,858 root         INFO     Train Epoch: 163 [1536/8000 (19%)]\tTotal Loss: 0.174858\n",
      "Reconstruction: 0.172108, Regularization: 0.002750\n",
      "2019-04-10 01:04:01,921 root         INFO     Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 0.165227\n",
      "Reconstruction: 0.162993, Regularization: 0.002233\n",
      "2019-04-10 01:04:01,984 root         INFO     Train Epoch: 163 [2560/8000 (32%)]\tTotal Loss: 0.171508\n",
      "Reconstruction: 0.168626, Regularization: 0.002882\n",
      "2019-04-10 01:04:02,047 root         INFO     Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 0.172774\n",
      "Reconstruction: 0.170284, Regularization: 0.002490\n",
      "2019-04-10 01:04:02,109 root         INFO     Train Epoch: 163 [3584/8000 (45%)]\tTotal Loss: 0.161171\n",
      "Reconstruction: 0.159249, Regularization: 0.001922\n",
      "2019-04-10 01:04:02,172 root         INFO     Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 0.171741\n",
      "Reconstruction: 0.168847, Regularization: 0.002894\n",
      "2019-04-10 01:04:02,234 root         INFO     Train Epoch: 163 [4608/8000 (58%)]\tTotal Loss: 0.177818\n",
      "Reconstruction: 0.175147, Regularization: 0.002671\n",
      "2019-04-10 01:04:02,297 root         INFO     Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 0.174275\n",
      "Reconstruction: 0.171503, Regularization: 0.002773\n",
      "2019-04-10 01:04:02,361 root         INFO     Train Epoch: 163 [5632/8000 (70%)]\tTotal Loss: 0.173121\n",
      "Reconstruction: 0.170408, Regularization: 0.002713\n",
      "2019-04-10 01:04:02,424 root         INFO     Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 0.163390\n",
      "Reconstruction: 0.161063, Regularization: 0.002327\n",
      "2019-04-10 01:04:02,486 root         INFO     Train Epoch: 163 [6656/8000 (83%)]\tTotal Loss: 0.159462\n",
      "Reconstruction: 0.157702, Regularization: 0.001760\n",
      "2019-04-10 01:04:02,549 root         INFO     Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 0.164867\n",
      "Reconstruction: 0.162826, Regularization: 0.002041\n",
      "2019-04-10 01:04:02,612 root         INFO     Train Epoch: 163 [7680/8000 (96%)]\tTotal Loss: 0.150672\n",
      "Reconstruction: 0.149363, Regularization: 0.001310\n",
      "2019-04-10 01:04:02,666 root         INFO     ====> Epoch: 163 Average loss: 0.1659\n",
      "2019-04-10 01:04:02,689 root         INFO     Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 0.173706\n",
      "Reconstruction: 0.170904, Regularization: 0.002803\n",
      "2019-04-10 01:04:02,753 root         INFO     Train Epoch: 164 [512/8000 (6%)]\tTotal Loss: 0.168399\n",
      "Reconstruction: 0.165956, Regularization: 0.002443\n",
      "2019-04-10 01:04:02,817 root         INFO     Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 0.159905\n",
      "Reconstruction: 0.157840, Regularization: 0.002065\n",
      "2019-04-10 01:04:02,880 root         INFO     Train Epoch: 164 [1536/8000 (19%)]\tTotal Loss: 0.169549\n",
      "Reconstruction: 0.166744, Regularization: 0.002805\n",
      "2019-04-10 01:04:02,942 root         INFO     Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 0.152999\n",
      "Reconstruction: 0.151495, Regularization: 0.001504\n",
      "2019-04-10 01:04:03,006 root         INFO     Train Epoch: 164 [2560/8000 (32%)]\tTotal Loss: 0.156528\n",
      "Reconstruction: 0.155012, Regularization: 0.001516\n",
      "2019-04-10 01:04:03,069 root         INFO     Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 0.157292\n",
      "Reconstruction: 0.155127, Regularization: 0.002166\n",
      "2019-04-10 01:04:03,133 root         INFO     Train Epoch: 164 [3584/8000 (45%)]\tTotal Loss: 0.171607\n",
      "Reconstruction: 0.168524, Regularization: 0.003083\n",
      "2019-04-10 01:04:03,196 root         INFO     Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 0.158571\n",
      "Reconstruction: 0.156548, Regularization: 0.002024\n",
      "2019-04-10 01:04:03,259 root         INFO     Train Epoch: 164 [4608/8000 (58%)]\tTotal Loss: 0.176362\n",
      "Reconstruction: 0.173412, Regularization: 0.002950\n",
      "2019-04-10 01:04:03,323 root         INFO     Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 0.156958\n",
      "Reconstruction: 0.155118, Regularization: 0.001840\n",
      "2019-04-10 01:04:03,387 root         INFO     Train Epoch: 164 [5632/8000 (70%)]\tTotal Loss: 0.165560\n",
      "Reconstruction: 0.163051, Regularization: 0.002509\n",
      "2019-04-10 01:04:03,451 root         INFO     Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 0.161463\n",
      "Reconstruction: 0.159183, Regularization: 0.002281\n",
      "2019-04-10 01:04:03,513 root         INFO     Train Epoch: 164 [6656/8000 (83%)]\tTotal Loss: 0.167794\n",
      "Reconstruction: 0.165038, Regularization: 0.002756\n",
      "2019-04-10 01:04:03,576 root         INFO     Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 0.162410\n",
      "Reconstruction: 0.159991, Regularization: 0.002420\n",
      "2019-04-10 01:04:03,638 root         INFO     Train Epoch: 164 [7680/8000 (96%)]\tTotal Loss: 0.158868\n",
      "Reconstruction: 0.157121, Regularization: 0.001747\n",
      "2019-04-10 01:04:03,692 root         INFO     ====> Epoch: 164 Average loss: 0.1656\n",
      "2019-04-10 01:04:03,716 root         INFO     Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 0.159981\n",
      "Reconstruction: 0.157903, Regularization: 0.002078\n",
      "2019-04-10 01:04:03,780 root         INFO     Train Epoch: 165 [512/8000 (6%)]\tTotal Loss: 0.167831\n",
      "Reconstruction: 0.164959, Regularization: 0.002873\n",
      "2019-04-10 01:04:03,844 root         INFO     Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 0.169178\n",
      "Reconstruction: 0.167062, Regularization: 0.002116\n",
      "2019-04-10 01:04:03,907 root         INFO     Train Epoch: 165 [1536/8000 (19%)]\tTotal Loss: 0.166808\n",
      "Reconstruction: 0.164472, Regularization: 0.002336\n",
      "2019-04-10 01:04:03,971 root         INFO     Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 0.159280\n",
      "Reconstruction: 0.156987, Regularization: 0.002293\n",
      "2019-04-10 01:04:04,035 root         INFO     Train Epoch: 165 [2560/8000 (32%)]\tTotal Loss: 0.174939\n",
      "Reconstruction: 0.171615, Regularization: 0.003325\n",
      "2019-04-10 01:04:04,098 root         INFO     Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 0.169184\n",
      "Reconstruction: 0.166521, Regularization: 0.002663\n",
      "2019-04-10 01:04:04,160 root         INFO     Train Epoch: 165 [3584/8000 (45%)]\tTotal Loss: 0.153517\n",
      "Reconstruction: 0.151943, Regularization: 0.001575\n",
      "2019-04-10 01:04:04,223 root         INFO     Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 0.162658\n",
      "Reconstruction: 0.160382, Regularization: 0.002275\n",
      "2019-04-10 01:04:04,286 root         INFO     Train Epoch: 165 [4608/8000 (58%)]\tTotal Loss: 0.179979\n",
      "Reconstruction: 0.176425, Regularization: 0.003555\n",
      "2019-04-10 01:04:04,349 root         INFO     Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 0.159709\n",
      "Reconstruction: 0.157702, Regularization: 0.002007\n",
      "2019-04-10 01:04:04,412 root         INFO     Train Epoch: 165 [5632/8000 (70%)]\tTotal Loss: 0.156959\n",
      "Reconstruction: 0.155185, Regularization: 0.001774\n",
      "2019-04-10 01:04:04,475 root         INFO     Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 0.187940\n",
      "Reconstruction: 0.184001, Regularization: 0.003938\n",
      "2019-04-10 01:04:04,538 root         INFO     Train Epoch: 165 [6656/8000 (83%)]\tTotal Loss: 0.157811\n",
      "Reconstruction: 0.156033, Regularization: 0.001779\n",
      "2019-04-10 01:04:04,601 root         INFO     Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 0.158009\n",
      "Reconstruction: 0.155820, Regularization: 0.002189\n",
      "2019-04-10 01:04:04,664 root         INFO     Train Epoch: 165 [7680/8000 (96%)]\tTotal Loss: 0.178619\n",
      "Reconstruction: 0.175159, Regularization: 0.003460\n",
      "2019-04-10 01:04:04,719 root         INFO     ====> Epoch: 165 Average loss: 0.1657\n",
      "2019-04-10 01:04:04,743 root         INFO     Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 0.166726\n",
      "Reconstruction: 0.164505, Regularization: 0.002221\n",
      "2019-04-10 01:04:04,807 root         INFO     Train Epoch: 166 [512/8000 (6%)]\tTotal Loss: 0.165179\n",
      "Reconstruction: 0.162557, Regularization: 0.002622\n",
      "2019-04-10 01:04:04,870 root         INFO     Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 0.159431\n",
      "Reconstruction: 0.157197, Regularization: 0.002234\n",
      "2019-04-10 01:04:04,934 root         INFO     Train Epoch: 166 [1536/8000 (19%)]\tTotal Loss: 0.152059\n",
      "Reconstruction: 0.150642, Regularization: 0.001416\n",
      "2019-04-10 01:04:04,998 root         INFO     Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 0.167499\n",
      "Reconstruction: 0.164641, Regularization: 0.002858\n",
      "2019-04-10 01:04:05,062 root         INFO     Train Epoch: 166 [2560/8000 (32%)]\tTotal Loss: 0.169478\n",
      "Reconstruction: 0.166872, Regularization: 0.002606\n",
      "2019-04-10 01:04:05,125 root         INFO     Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 0.165064\n",
      "Reconstruction: 0.162985, Regularization: 0.002080\n",
      "2019-04-10 01:04:05,189 root         INFO     Train Epoch: 166 [3584/8000 (45%)]\tTotal Loss: 0.170995\n",
      "Reconstruction: 0.168013, Regularization: 0.002982\n",
      "2019-04-10 01:04:05,253 root         INFO     Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 0.174991\n",
      "Reconstruction: 0.171715, Regularization: 0.003276\n",
      "2019-04-10 01:04:05,317 root         INFO     Train Epoch: 166 [4608/8000 (58%)]\tTotal Loss: 0.160785\n",
      "Reconstruction: 0.158725, Regularization: 0.002060\n",
      "2019-04-10 01:04:05,381 root         INFO     Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 0.178034\n",
      "Reconstruction: 0.174860, Regularization: 0.003174\n",
      "2019-04-10 01:04:05,443 root         INFO     Train Epoch: 166 [5632/8000 (70%)]\tTotal Loss: 0.152994\n",
      "Reconstruction: 0.151394, Regularization: 0.001600\n",
      "2019-04-10 01:04:05,506 root         INFO     Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 0.162003\n",
      "Reconstruction: 0.159811, Regularization: 0.002193\n",
      "2019-04-10 01:04:05,569 root         INFO     Train Epoch: 166 [6656/8000 (83%)]\tTotal Loss: 0.177123\n",
      "Reconstruction: 0.173791, Regularization: 0.003332\n",
      "2019-04-10 01:04:05,631 root         INFO     Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 0.160154\n",
      "Reconstruction: 0.158077, Regularization: 0.002076\n",
      "2019-04-10 01:04:05,694 root         INFO     Train Epoch: 166 [7680/8000 (96%)]\tTotal Loss: 0.164467\n",
      "Reconstruction: 0.162040, Regularization: 0.002428\n",
      "2019-04-10 01:04:05,748 root         INFO     ====> Epoch: 166 Average loss: 0.1658\n",
      "2019-04-10 01:04:05,773 root         INFO     Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 0.160755\n",
      "Reconstruction: 0.158566, Regularization: 0.002189\n",
      "2019-04-10 01:04:05,836 root         INFO     Train Epoch: 167 [512/8000 (6%)]\tTotal Loss: 0.165430\n",
      "Reconstruction: 0.162682, Regularization: 0.002748\n",
      "2019-04-10 01:04:05,899 root         INFO     Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 0.168572\n",
      "Reconstruction: 0.165901, Regularization: 0.002670\n",
      "2019-04-10 01:04:05,963 root         INFO     Train Epoch: 167 [1536/8000 (19%)]\tTotal Loss: 0.168347\n",
      "Reconstruction: 0.165770, Regularization: 0.002577\n",
      "2019-04-10 01:04:06,026 root         INFO     Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 0.177913\n",
      "Reconstruction: 0.174644, Regularization: 0.003269\n",
      "2019-04-10 01:04:06,089 root         INFO     Train Epoch: 167 [2560/8000 (32%)]\tTotal Loss: 0.184420\n",
      "Reconstruction: 0.179877, Regularization: 0.004543\n",
      "2019-04-10 01:04:06,152 root         INFO     Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 0.171102\n",
      "Reconstruction: 0.168345, Regularization: 0.002757\n",
      "2019-04-10 01:04:06,216 root         INFO     Train Epoch: 167 [3584/8000 (45%)]\tTotal Loss: 0.178200\n",
      "Reconstruction: 0.174690, Regularization: 0.003510\n",
      "2019-04-10 01:04:06,279 root         INFO     Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 0.169512\n",
      "Reconstruction: 0.166518, Regularization: 0.002994\n",
      "2019-04-10 01:04:06,342 root         INFO     Train Epoch: 167 [4608/8000 (58%)]\tTotal Loss: 0.171424\n",
      "Reconstruction: 0.168404, Regularization: 0.003020\n",
      "2019-04-10 01:04:06,405 root         INFO     Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 0.178782\n",
      "Reconstruction: 0.175740, Regularization: 0.003043\n",
      "2019-04-10 01:04:06,469 root         INFO     Train Epoch: 167 [5632/8000 (70%)]\tTotal Loss: 0.153168\n",
      "Reconstruction: 0.151224, Regularization: 0.001944\n",
      "2019-04-10 01:04:06,532 root         INFO     Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 0.184625\n",
      "Reconstruction: 0.181155, Regularization: 0.003470\n",
      "2019-04-10 01:04:06,595 root         INFO     Train Epoch: 167 [6656/8000 (83%)]\tTotal Loss: 0.168534\n",
      "Reconstruction: 0.165655, Regularization: 0.002879\n",
      "2019-04-10 01:04:06,658 root         INFO     Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 0.165233\n",
      "Reconstruction: 0.162272, Regularization: 0.002961\n",
      "2019-04-10 01:04:06,722 root         INFO     Train Epoch: 167 [7680/8000 (96%)]\tTotal Loss: 0.169848\n",
      "Reconstruction: 0.167006, Regularization: 0.002842\n",
      "2019-04-10 01:04:06,775 root         INFO     ====> Epoch: 167 Average loss: 0.1657\n",
      "2019-04-10 01:04:06,799 root         INFO     Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 0.151005\n",
      "Reconstruction: 0.149538, Regularization: 0.001467\n",
      "2019-04-10 01:04:06,862 root         INFO     Train Epoch: 168 [512/8000 (6%)]\tTotal Loss: 0.166670\n",
      "Reconstruction: 0.163729, Regularization: 0.002942\n",
      "2019-04-10 01:04:06,926 root         INFO     Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 0.161999\n",
      "Reconstruction: 0.159773, Regularization: 0.002226\n",
      "2019-04-10 01:04:06,989 root         INFO     Train Epoch: 168 [1536/8000 (19%)]\tTotal Loss: 0.177874\n",
      "Reconstruction: 0.174735, Regularization: 0.003138\n",
      "2019-04-10 01:04:07,052 root         INFO     Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 0.160654\n",
      "Reconstruction: 0.158235, Regularization: 0.002420\n",
      "2019-04-10 01:04:07,115 root         INFO     Train Epoch: 168 [2560/8000 (32%)]\tTotal Loss: 0.168257\n",
      "Reconstruction: 0.165518, Regularization: 0.002739\n",
      "2019-04-10 01:04:07,178 root         INFO     Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 0.189942\n",
      "Reconstruction: 0.185985, Regularization: 0.003958\n",
      "2019-04-10 01:04:07,241 root         INFO     Train Epoch: 168 [3584/8000 (45%)]\tTotal Loss: 0.177254\n",
      "Reconstruction: 0.174159, Regularization: 0.003095\n",
      "2019-04-10 01:04:07,303 root         INFO     Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 0.158711\n",
      "Reconstruction: 0.156611, Regularization: 0.002100\n",
      "2019-04-10 01:04:07,366 root         INFO     Train Epoch: 168 [4608/8000 (58%)]\tTotal Loss: 0.174995\n",
      "Reconstruction: 0.171685, Regularization: 0.003310\n",
      "2019-04-10 01:04:07,429 root         INFO     Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 0.154491\n",
      "Reconstruction: 0.152774, Regularization: 0.001716\n",
      "2019-04-10 01:04:07,492 root         INFO     Train Epoch: 168 [5632/8000 (70%)]\tTotal Loss: 0.152026\n",
      "Reconstruction: 0.150331, Regularization: 0.001695\n",
      "2019-04-10 01:04:07,555 root         INFO     Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 0.162623\n",
      "Reconstruction: 0.159747, Regularization: 0.002876\n",
      "2019-04-10 01:04:07,618 root         INFO     Train Epoch: 168 [6656/8000 (83%)]\tTotal Loss: 0.172773\n",
      "Reconstruction: 0.169315, Regularization: 0.003457\n",
      "2019-04-10 01:04:07,681 root         INFO     Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 0.179630\n",
      "Reconstruction: 0.175763, Regularization: 0.003868\n",
      "2019-04-10 01:04:07,744 root         INFO     Train Epoch: 168 [7680/8000 (96%)]\tTotal Loss: 0.158545\n",
      "Reconstruction: 0.156751, Regularization: 0.001795\n",
      "2019-04-10 01:04:07,797 root         INFO     ====> Epoch: 168 Average loss: 0.1655\n",
      "2019-04-10 01:04:07,821 root         INFO     Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 0.173879\n",
      "Reconstruction: 0.170087, Regularization: 0.003792\n",
      "2019-04-10 01:04:07,885 root         INFO     Train Epoch: 169 [512/8000 (6%)]\tTotal Loss: 0.178261\n",
      "Reconstruction: 0.174766, Regularization: 0.003495\n",
      "2019-04-10 01:04:07,948 root         INFO     Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 0.176559\n",
      "Reconstruction: 0.173194, Regularization: 0.003365\n",
      "2019-04-10 01:04:08,012 root         INFO     Train Epoch: 169 [1536/8000 (19%)]\tTotal Loss: 0.175662\n",
      "Reconstruction: 0.172222, Regularization: 0.003440\n",
      "2019-04-10 01:04:08,074 root         INFO     Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 0.160346\n",
      "Reconstruction: 0.157912, Regularization: 0.002434\n",
      "2019-04-10 01:04:08,137 root         INFO     Train Epoch: 169 [2560/8000 (32%)]\tTotal Loss: 0.155122\n",
      "Reconstruction: 0.153419, Regularization: 0.001703\n",
      "2019-04-10 01:04:08,200 root         INFO     Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 0.166629\n",
      "Reconstruction: 0.163632, Regularization: 0.002997\n",
      "2019-04-10 01:04:08,263 root         INFO     Train Epoch: 169 [3584/8000 (45%)]\tTotal Loss: 0.154118\n",
      "Reconstruction: 0.152078, Regularization: 0.002040\n",
      "2019-04-10 01:04:08,326 root         INFO     Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 0.168162\n",
      "Reconstruction: 0.164976, Regularization: 0.003185\n",
      "2019-04-10 01:04:08,389 root         INFO     Train Epoch: 169 [4608/8000 (58%)]\tTotal Loss: 0.157711\n",
      "Reconstruction: 0.155563, Regularization: 0.002148\n",
      "2019-04-10 01:04:08,452 root         INFO     Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 0.167631\n",
      "Reconstruction: 0.164849, Regularization: 0.002782\n",
      "2019-04-10 01:04:08,514 root         INFO     Train Epoch: 169 [5632/8000 (70%)]\tTotal Loss: 0.171983\n",
      "Reconstruction: 0.168616, Regularization: 0.003367\n",
      "2019-04-10 01:04:08,577 root         INFO     Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 0.169133\n",
      "Reconstruction: 0.165956, Regularization: 0.003177\n",
      "2019-04-10 01:04:08,640 root         INFO     Train Epoch: 169 [6656/8000 (83%)]\tTotal Loss: 0.172558\n",
      "Reconstruction: 0.169496, Regularization: 0.003062\n",
      "2019-04-10 01:04:08,702 root         INFO     Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 0.179936\n",
      "Reconstruction: 0.176609, Regularization: 0.003327\n",
      "2019-04-10 01:04:08,765 root         INFO     Train Epoch: 169 [7680/8000 (96%)]\tTotal Loss: 0.161856\n",
      "Reconstruction: 0.159369, Regularization: 0.002488\n",
      "2019-04-10 01:04:08,819 root         INFO     ====> Epoch: 169 Average loss: 0.1656\n",
      "2019-04-10 01:04:08,843 root         INFO     Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 0.168035\n",
      "Reconstruction: 0.165213, Regularization: 0.002822\n",
      "2019-04-10 01:04:08,906 root         INFO     Train Epoch: 170 [512/8000 (6%)]\tTotal Loss: 0.164780\n",
      "Reconstruction: 0.161850, Regularization: 0.002930\n",
      "2019-04-10 01:04:08,969 root         INFO     Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 0.166850\n",
      "Reconstruction: 0.163545, Regularization: 0.003305\n",
      "2019-04-10 01:04:09,032 root         INFO     Train Epoch: 170 [1536/8000 (19%)]\tTotal Loss: 0.165830\n",
      "Reconstruction: 0.162919, Regularization: 0.002911\n",
      "2019-04-10 01:04:09,095 root         INFO     Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 0.165962\n",
      "Reconstruction: 0.163023, Regularization: 0.002939\n",
      "2019-04-10 01:04:09,158 root         INFO     Train Epoch: 170 [2560/8000 (32%)]\tTotal Loss: 0.153523\n",
      "Reconstruction: 0.151055, Regularization: 0.002468\n",
      "2019-04-10 01:04:09,221 root         INFO     Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 0.165075\n",
      "Reconstruction: 0.161869, Regularization: 0.003206\n",
      "2019-04-10 01:04:09,284 root         INFO     Train Epoch: 170 [3584/8000 (45%)]\tTotal Loss: 0.156362\n",
      "Reconstruction: 0.153978, Regularization: 0.002383\n",
      "2019-04-10 01:04:09,348 root         INFO     Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 0.158631\n",
      "Reconstruction: 0.156402, Regularization: 0.002229\n",
      "2019-04-10 01:04:09,411 root         INFO     Train Epoch: 170 [4608/8000 (58%)]\tTotal Loss: 0.167714\n",
      "Reconstruction: 0.164559, Regularization: 0.003155\n",
      "2019-04-10 01:04:09,474 root         INFO     Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 0.165785\n",
      "Reconstruction: 0.161990, Regularization: 0.003795\n",
      "2019-04-10 01:04:09,537 root         INFO     Train Epoch: 170 [5632/8000 (70%)]\tTotal Loss: 0.170212\n",
      "Reconstruction: 0.166619, Regularization: 0.003593\n",
      "2019-04-10 01:04:09,600 root         INFO     Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 0.159897\n",
      "Reconstruction: 0.157018, Regularization: 0.002879\n",
      "2019-04-10 01:04:09,664 root         INFO     Train Epoch: 170 [6656/8000 (83%)]\tTotal Loss: 0.165235\n",
      "Reconstruction: 0.162943, Regularization: 0.002292\n",
      "2019-04-10 01:04:09,727 root         INFO     Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 0.158606\n",
      "Reconstruction: 0.155910, Regularization: 0.002696\n",
      "2019-04-10 01:04:09,790 root         INFO     Train Epoch: 170 [7680/8000 (96%)]\tTotal Loss: 0.165814\n",
      "Reconstruction: 0.162739, Regularization: 0.003076\n",
      "2019-04-10 01:04:09,844 root         INFO     ====> Epoch: 170 Average loss: 0.1655\n",
      "2019-04-10 01:04:09,868 root         INFO     Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 0.170682\n",
      "Reconstruction: 0.167545, Regularization: 0.003137\n",
      "2019-04-10 01:04:09,931 root         INFO     Train Epoch: 171 [512/8000 (6%)]\tTotal Loss: 0.158572\n",
      "Reconstruction: 0.155985, Regularization: 0.002587\n",
      "2019-04-10 01:04:09,995 root         INFO     Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 0.164359\n",
      "Reconstruction: 0.161602, Regularization: 0.002757\n",
      "2019-04-10 01:04:10,058 root         INFO     Train Epoch: 171 [1536/8000 (19%)]\tTotal Loss: 0.160071\n",
      "Reconstruction: 0.157627, Regularization: 0.002444\n",
      "2019-04-10 01:04:10,121 root         INFO     Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 0.163866\n",
      "Reconstruction: 0.161153, Regularization: 0.002713\n",
      "2019-04-10 01:04:10,184 root         INFO     Train Epoch: 171 [2560/8000 (32%)]\tTotal Loss: 0.169629\n",
      "Reconstruction: 0.165896, Regularization: 0.003733\n",
      "2019-04-10 01:04:10,247 root         INFO     Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 0.194822\n",
      "Reconstruction: 0.189404, Regularization: 0.005418\n",
      "2019-04-10 01:04:10,310 root         INFO     Train Epoch: 171 [3584/8000 (45%)]\tTotal Loss: 0.176598\n",
      "Reconstruction: 0.172660, Regularization: 0.003938\n",
      "2019-04-10 01:04:10,373 root         INFO     Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 0.168939\n",
      "Reconstruction: 0.165048, Regularization: 0.003891\n",
      "2019-04-10 01:04:10,436 root         INFO     Train Epoch: 171 [4608/8000 (58%)]\tTotal Loss: 0.164703\n",
      "Reconstruction: 0.161939, Regularization: 0.002764\n",
      "2019-04-10 01:04:10,499 root         INFO     Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 0.162156\n",
      "Reconstruction: 0.159003, Regularization: 0.003153\n",
      "2019-04-10 01:04:10,562 root         INFO     Train Epoch: 171 [5632/8000 (70%)]\tTotal Loss: 0.158239\n",
      "Reconstruction: 0.156049, Regularization: 0.002189\n",
      "2019-04-10 01:04:10,625 root         INFO     Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 0.161002\n",
      "Reconstruction: 0.157916, Regularization: 0.003087\n",
      "2019-04-10 01:04:10,688 root         INFO     Train Epoch: 171 [6656/8000 (83%)]\tTotal Loss: 0.160195\n",
      "Reconstruction: 0.157690, Regularization: 0.002506\n",
      "2019-04-10 01:04:10,751 root         INFO     Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 0.165411\n",
      "Reconstruction: 0.162032, Regularization: 0.003379\n",
      "2019-04-10 01:04:10,814 root         INFO     Train Epoch: 171 [7680/8000 (96%)]\tTotal Loss: 0.175896\n",
      "Reconstruction: 0.172110, Regularization: 0.003786\n",
      "2019-04-10 01:04:10,867 root         INFO     ====> Epoch: 171 Average loss: 0.1661\n",
      "2019-04-10 01:04:10,891 root         INFO     Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 0.168567\n",
      "Reconstruction: 0.165661, Regularization: 0.002906\n",
      "2019-04-10 01:04:10,955 root         INFO     Train Epoch: 172 [512/8000 (6%)]\tTotal Loss: 0.169946\n",
      "Reconstruction: 0.167137, Regularization: 0.002809\n",
      "2019-04-10 01:04:11,018 root         INFO     Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 0.165027\n",
      "Reconstruction: 0.162024, Regularization: 0.003003\n",
      "2019-04-10 01:04:11,082 root         INFO     Train Epoch: 172 [1536/8000 (19%)]\tTotal Loss: 0.162520\n",
      "Reconstruction: 0.159628, Regularization: 0.002892\n",
      "2019-04-10 01:04:11,146 root         INFO     Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 0.160380\n",
      "Reconstruction: 0.157891, Regularization: 0.002489\n",
      "2019-04-10 01:04:11,210 root         INFO     Train Epoch: 172 [2560/8000 (32%)]\tTotal Loss: 0.173554\n",
      "Reconstruction: 0.169896, Regularization: 0.003658\n",
      "2019-04-10 01:04:11,273 root         INFO     Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 0.160907\n",
      "Reconstruction: 0.157940, Regularization: 0.002967\n",
      "2019-04-10 01:04:11,337 root         INFO     Train Epoch: 172 [3584/8000 (45%)]\tTotal Loss: 0.175106\n",
      "Reconstruction: 0.171227, Regularization: 0.003879\n",
      "2019-04-10 01:04:11,401 root         INFO     Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 0.156488\n",
      "Reconstruction: 0.154393, Regularization: 0.002095\n",
      "2019-04-10 01:04:11,464 root         INFO     Train Epoch: 172 [4608/8000 (58%)]\tTotal Loss: 0.158211\n",
      "Reconstruction: 0.155760, Regularization: 0.002451\n",
      "2019-04-10 01:04:11,527 root         INFO     Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 0.164664\n",
      "Reconstruction: 0.161529, Regularization: 0.003135\n",
      "2019-04-10 01:04:11,590 root         INFO     Train Epoch: 172 [5632/8000 (70%)]\tTotal Loss: 0.171970\n",
      "Reconstruction: 0.168395, Regularization: 0.003575\n",
      "2019-04-10 01:04:11,651 root         INFO     Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 0.162450\n",
      "Reconstruction: 0.159553, Regularization: 0.002897\n",
      "2019-04-10 01:04:11,713 root         INFO     Train Epoch: 172 [6656/8000 (83%)]\tTotal Loss: 0.168623\n",
      "Reconstruction: 0.165123, Regularization: 0.003500\n",
      "2019-04-10 01:04:11,775 root         INFO     Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 0.162709\n",
      "Reconstruction: 0.160001, Regularization: 0.002709\n",
      "2019-04-10 01:04:11,837 root         INFO     Train Epoch: 172 [7680/8000 (96%)]\tTotal Loss: 0.161817\n",
      "Reconstruction: 0.158862, Regularization: 0.002955\n",
      "2019-04-10 01:04:11,891 root         INFO     ====> Epoch: 172 Average loss: 0.1658\n",
      "2019-04-10 01:04:11,914 root         INFO     Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 0.175158\n",
      "Reconstruction: 0.170932, Regularization: 0.004226\n",
      "2019-04-10 01:04:11,978 root         INFO     Train Epoch: 173 [512/8000 (6%)]\tTotal Loss: 0.158472\n",
      "Reconstruction: 0.155718, Regularization: 0.002754\n",
      "2019-04-10 01:04:12,041 root         INFO     Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 0.165221\n",
      "Reconstruction: 0.162637, Regularization: 0.002584\n",
      "2019-04-10 01:04:12,104 root         INFO     Train Epoch: 173 [1536/8000 (19%)]\tTotal Loss: 0.176562\n",
      "Reconstruction: 0.171916, Regularization: 0.004646\n",
      "2019-04-10 01:04:12,167 root         INFO     Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 0.170512\n",
      "Reconstruction: 0.166990, Regularization: 0.003522\n",
      "2019-04-10 01:04:12,230 root         INFO     Train Epoch: 173 [2560/8000 (32%)]\tTotal Loss: 0.155375\n",
      "Reconstruction: 0.153422, Regularization: 0.001952\n",
      "2019-04-10 01:04:12,294 root         INFO     Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 0.174355\n",
      "Reconstruction: 0.170486, Regularization: 0.003869\n",
      "2019-04-10 01:04:12,357 root         INFO     Train Epoch: 173 [3584/8000 (45%)]\tTotal Loss: 0.174461\n",
      "Reconstruction: 0.170119, Regularization: 0.004342\n",
      "2019-04-10 01:04:12,420 root         INFO     Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 0.161835\n",
      "Reconstruction: 0.158767, Regularization: 0.003069\n",
      "2019-04-10 01:04:12,482 root         INFO     Train Epoch: 173 [4608/8000 (58%)]\tTotal Loss: 0.182334\n",
      "Reconstruction: 0.177372, Regularization: 0.004962\n",
      "2019-04-10 01:04:12,545 root         INFO     Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 0.172933\n",
      "Reconstruction: 0.168627, Regularization: 0.004306\n",
      "2019-04-10 01:04:12,608 root         INFO     Train Epoch: 173 [5632/8000 (70%)]\tTotal Loss: 0.166851\n",
      "Reconstruction: 0.164016, Regularization: 0.002835\n",
      "2019-04-10 01:04:12,671 root         INFO     Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 0.176074\n",
      "Reconstruction: 0.171908, Regularization: 0.004166\n",
      "2019-04-10 01:04:12,733 root         INFO     Train Epoch: 173 [6656/8000 (83%)]\tTotal Loss: 0.166019\n",
      "Reconstruction: 0.162958, Regularization: 0.003061\n",
      "2019-04-10 01:04:12,796 root         INFO     Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 0.161839\n",
      "Reconstruction: 0.159136, Regularization: 0.002703\n",
      "2019-04-10 01:04:12,859 root         INFO     Train Epoch: 173 [7680/8000 (96%)]\tTotal Loss: 0.158172\n",
      "Reconstruction: 0.155421, Regularization: 0.002751\n",
      "2019-04-10 01:04:12,913 root         INFO     ====> Epoch: 173 Average loss: 0.1658\n",
      "2019-04-10 01:04:12,937 root         INFO     Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 0.168471\n",
      "Reconstruction: 0.165013, Regularization: 0.003459\n",
      "2019-04-10 01:04:13,000 root         INFO     Train Epoch: 174 [512/8000 (6%)]\tTotal Loss: 0.161559\n",
      "Reconstruction: 0.158459, Regularization: 0.003100\n",
      "2019-04-10 01:04:13,063 root         INFO     Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 0.161043\n",
      "Reconstruction: 0.158143, Regularization: 0.002900\n",
      "2019-04-10 01:04:13,126 root         INFO     Train Epoch: 174 [1536/8000 (19%)]\tTotal Loss: 0.156387\n",
      "Reconstruction: 0.154419, Regularization: 0.001968\n",
      "2019-04-10 01:04:13,189 root         INFO     Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 0.158915\n",
      "Reconstruction: 0.156454, Regularization: 0.002461\n",
      "2019-04-10 01:04:13,253 root         INFO     Train Epoch: 174 [2560/8000 (32%)]\tTotal Loss: 0.163253\n",
      "Reconstruction: 0.160170, Regularization: 0.003083\n",
      "2019-04-10 01:04:13,315 root         INFO     Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 0.174315\n",
      "Reconstruction: 0.169916, Regularization: 0.004399\n",
      "2019-04-10 01:04:13,377 root         INFO     Train Epoch: 174 [3584/8000 (45%)]\tTotal Loss: 0.179101\n",
      "Reconstruction: 0.174880, Regularization: 0.004221\n",
      "2019-04-10 01:04:13,439 root         INFO     Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 0.160411\n",
      "Reconstruction: 0.157815, Regularization: 0.002595\n",
      "2019-04-10 01:04:13,501 root         INFO     Train Epoch: 174 [4608/8000 (58%)]\tTotal Loss: 0.179291\n",
      "Reconstruction: 0.174670, Regularization: 0.004621\n",
      "2019-04-10 01:04:13,563 root         INFO     Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 0.176542\n",
      "Reconstruction: 0.172858, Regularization: 0.003685\n",
      "2019-04-10 01:04:13,625 root         INFO     Train Epoch: 174 [5632/8000 (70%)]\tTotal Loss: 0.166372\n",
      "Reconstruction: 0.162832, Regularization: 0.003539\n",
      "2019-04-10 01:04:13,688 root         INFO     Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 0.153698\n",
      "Reconstruction: 0.150927, Regularization: 0.002771\n",
      "2019-04-10 01:04:13,750 root         INFO     Train Epoch: 174 [6656/8000 (83%)]\tTotal Loss: 0.191818\n",
      "Reconstruction: 0.185606, Regularization: 0.006212\n",
      "2019-04-10 01:04:13,813 root         INFO     Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 0.158502\n",
      "Reconstruction: 0.155947, Regularization: 0.002554\n",
      "2019-04-10 01:04:13,875 root         INFO     Train Epoch: 174 [7680/8000 (96%)]\tTotal Loss: 0.175424\n",
      "Reconstruction: 0.171939, Regularization: 0.003485\n",
      "2019-04-10 01:04:13,929 root         INFO     ====> Epoch: 174 Average loss: 0.1656\n",
      "2019-04-10 01:04:13,953 root         INFO     Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 0.162145\n",
      "Reconstruction: 0.159107, Regularization: 0.003037\n",
      "2019-04-10 01:04:14,014 root         INFO     Train Epoch: 175 [512/8000 (6%)]\tTotal Loss: 0.173557\n",
      "Reconstruction: 0.169470, Regularization: 0.004087\n",
      "2019-04-10 01:04:14,077 root         INFO     Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 0.164040\n",
      "Reconstruction: 0.161152, Regularization: 0.002888\n",
      "2019-04-10 01:04:14,140 root         INFO     Train Epoch: 175 [1536/8000 (19%)]\tTotal Loss: 0.177337\n",
      "Reconstruction: 0.173417, Regularization: 0.003920\n",
      "2019-04-10 01:04:14,201 root         INFO     Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 0.160948\n",
      "Reconstruction: 0.157965, Regularization: 0.002983\n",
      "2019-04-10 01:04:14,262 root         INFO     Train Epoch: 175 [2560/8000 (32%)]\tTotal Loss: 0.170808\n",
      "Reconstruction: 0.167378, Regularization: 0.003430\n",
      "2019-04-10 01:04:14,324 root         INFO     Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 0.165605\n",
      "Reconstruction: 0.161875, Regularization: 0.003730\n",
      "2019-04-10 01:04:14,386 root         INFO     Train Epoch: 175 [3584/8000 (45%)]\tTotal Loss: 0.156846\n",
      "Reconstruction: 0.154129, Regularization: 0.002717\n",
      "2019-04-10 01:04:14,447 root         INFO     Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 0.156400\n",
      "Reconstruction: 0.153880, Regularization: 0.002520\n",
      "2019-04-10 01:04:14,508 root         INFO     Train Epoch: 175 [4608/8000 (58%)]\tTotal Loss: 0.164900\n",
      "Reconstruction: 0.162200, Regularization: 0.002700\n",
      "2019-04-10 01:04:14,569 root         INFO     Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 0.176695\n",
      "Reconstruction: 0.172486, Regularization: 0.004209\n",
      "2019-04-10 01:04:14,630 root         INFO     Train Epoch: 175 [5632/8000 (70%)]\tTotal Loss: 0.169541\n",
      "Reconstruction: 0.165298, Regularization: 0.004243\n",
      "2019-04-10 01:04:14,691 root         INFO     Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 0.159971\n",
      "Reconstruction: 0.157330, Regularization: 0.002642\n",
      "2019-04-10 01:04:14,752 root         INFO     Train Epoch: 175 [6656/8000 (83%)]\tTotal Loss: 0.173764\n",
      "Reconstruction: 0.169581, Regularization: 0.004183\n",
      "2019-04-10 01:04:14,812 root         INFO     Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 0.159819\n",
      "Reconstruction: 0.156923, Regularization: 0.002897\n",
      "2019-04-10 01:04:14,873 root         INFO     Train Epoch: 175 [7680/8000 (96%)]\tTotal Loss: 0.156153\n",
      "Reconstruction: 0.153371, Regularization: 0.002781\n",
      "2019-04-10 01:04:14,926 root         INFO     ====> Epoch: 175 Average loss: 0.1656\n",
      "2019-04-10 01:04:14,950 root         INFO     Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 0.179544\n",
      "Reconstruction: 0.175042, Regularization: 0.004502\n",
      "2019-04-10 01:04:15,013 root         INFO     Train Epoch: 176 [512/8000 (6%)]\tTotal Loss: 0.153489\n",
      "Reconstruction: 0.151038, Regularization: 0.002451\n",
      "2019-04-10 01:04:15,076 root         INFO     Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 0.157489\n",
      "Reconstruction: 0.154959, Regularization: 0.002529\n",
      "2019-04-10 01:04:15,139 root         INFO     Train Epoch: 176 [1536/8000 (19%)]\tTotal Loss: 0.164844\n",
      "Reconstruction: 0.161381, Regularization: 0.003463\n",
      "2019-04-10 01:04:15,201 root         INFO     Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 0.175921\n",
      "Reconstruction: 0.171407, Regularization: 0.004515\n",
      "2019-04-10 01:04:15,263 root         INFO     Train Epoch: 176 [2560/8000 (32%)]\tTotal Loss: 0.165803\n",
      "Reconstruction: 0.162511, Regularization: 0.003291\n",
      "2019-04-10 01:04:15,326 root         INFO     Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 0.163728\n",
      "Reconstruction: 0.160385, Regularization: 0.003343\n",
      "2019-04-10 01:04:15,388 root         INFO     Train Epoch: 176 [3584/8000 (45%)]\tTotal Loss: 0.170138\n",
      "Reconstruction: 0.166190, Regularization: 0.003948\n",
      "2019-04-10 01:04:15,449 root         INFO     Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 0.180828\n",
      "Reconstruction: 0.176120, Regularization: 0.004708\n",
      "2019-04-10 01:04:15,510 root         INFO     Train Epoch: 176 [4608/8000 (58%)]\tTotal Loss: 0.155072\n",
      "Reconstruction: 0.152228, Regularization: 0.002844\n",
      "2019-04-10 01:04:15,572 root         INFO     Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 0.152323\n",
      "Reconstruction: 0.150058, Regularization: 0.002265\n",
      "2019-04-10 01:04:15,635 root         INFO     Train Epoch: 176 [5632/8000 (70%)]\tTotal Loss: 0.163968\n",
      "Reconstruction: 0.160348, Regularization: 0.003619\n",
      "2019-04-10 01:04:15,698 root         INFO     Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 0.172665\n",
      "Reconstruction: 0.168812, Regularization: 0.003854\n",
      "2019-04-10 01:04:15,761 root         INFO     Train Epoch: 176 [6656/8000 (83%)]\tTotal Loss: 0.163903\n",
      "Reconstruction: 0.160188, Regularization: 0.003715\n",
      "2019-04-10 01:04:15,823 root         INFO     Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 0.157010\n",
      "Reconstruction: 0.154056, Regularization: 0.002954\n",
      "2019-04-10 01:04:15,886 root         INFO     Train Epoch: 176 [7680/8000 (96%)]\tTotal Loss: 0.157168\n",
      "Reconstruction: 0.154802, Regularization: 0.002366\n",
      "2019-04-10 01:04:15,940 root         INFO     ====> Epoch: 176 Average loss: 0.1658\n",
      "2019-04-10 01:04:15,963 root         INFO     Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 0.170725\n",
      "Reconstruction: 0.166478, Regularization: 0.004247\n",
      "2019-04-10 01:04:16,026 root         INFO     Train Epoch: 177 [512/8000 (6%)]\tTotal Loss: 0.182186\n",
      "Reconstruction: 0.177546, Regularization: 0.004640\n",
      "2019-04-10 01:04:16,088 root         INFO     Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 0.168066\n",
      "Reconstruction: 0.164028, Regularization: 0.004038\n",
      "2019-04-10 01:04:16,150 root         INFO     Train Epoch: 177 [1536/8000 (19%)]\tTotal Loss: 0.160008\n",
      "Reconstruction: 0.157312, Regularization: 0.002696\n",
      "2019-04-10 01:04:16,213 root         INFO     Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 0.178152\n",
      "Reconstruction: 0.173331, Regularization: 0.004821\n",
      "2019-04-10 01:04:16,275 root         INFO     Train Epoch: 177 [2560/8000 (32%)]\tTotal Loss: 0.162593\n",
      "Reconstruction: 0.159572, Regularization: 0.003021\n",
      "2019-04-10 01:04:16,336 root         INFO     Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 0.174473\n",
      "Reconstruction: 0.170213, Regularization: 0.004260\n",
      "2019-04-10 01:04:16,397 root         INFO     Train Epoch: 177 [3584/8000 (45%)]\tTotal Loss: 0.166575\n",
      "Reconstruction: 0.163692, Regularization: 0.002883\n",
      "2019-04-10 01:04:16,457 root         INFO     Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 0.173478\n",
      "Reconstruction: 0.169116, Regularization: 0.004362\n",
      "2019-04-10 01:04:16,518 root         INFO     Train Epoch: 177 [4608/8000 (58%)]\tTotal Loss: 0.162057\n",
      "Reconstruction: 0.158874, Regularization: 0.003183\n",
      "2019-04-10 01:04:16,579 root         INFO     Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 0.166358\n",
      "Reconstruction: 0.162480, Regularization: 0.003878\n",
      "2019-04-10 01:04:16,640 root         INFO     Train Epoch: 177 [5632/8000 (70%)]\tTotal Loss: 0.165046\n",
      "Reconstruction: 0.161921, Regularization: 0.003125\n",
      "2019-04-10 01:04:16,701 root         INFO     Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 0.157009\n",
      "Reconstruction: 0.154674, Regularization: 0.002335\n",
      "2019-04-10 01:04:16,761 root         INFO     Train Epoch: 177 [6656/8000 (83%)]\tTotal Loss: 0.157496\n",
      "Reconstruction: 0.155048, Regularization: 0.002448\n",
      "2019-04-10 01:04:16,822 root         INFO     Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 0.167848\n",
      "Reconstruction: 0.164362, Regularization: 0.003486\n",
      "2019-04-10 01:04:16,883 root         INFO     Train Epoch: 177 [7680/8000 (96%)]\tTotal Loss: 0.166139\n",
      "Reconstruction: 0.162874, Regularization: 0.003265\n",
      "2019-04-10 01:04:16,935 root         INFO     ====> Epoch: 177 Average loss: 0.1654\n",
      "2019-04-10 01:04:16,959 root         INFO     Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 0.165361\n",
      "Reconstruction: 0.161967, Regularization: 0.003394\n",
      "2019-04-10 01:04:17,022 root         INFO     Train Epoch: 178 [512/8000 (6%)]\tTotal Loss: 0.178417\n",
      "Reconstruction: 0.174294, Regularization: 0.004123\n",
      "2019-04-10 01:04:17,084 root         INFO     Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 0.161724\n",
      "Reconstruction: 0.158097, Regularization: 0.003627\n",
      "2019-04-10 01:04:17,146 root         INFO     Train Epoch: 178 [1536/8000 (19%)]\tTotal Loss: 0.162072\n",
      "Reconstruction: 0.158570, Regularization: 0.003501\n",
      "2019-04-10 01:04:17,208 root         INFO     Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 0.180301\n",
      "Reconstruction: 0.175978, Regularization: 0.004323\n",
      "2019-04-10 01:04:17,270 root         INFO     Train Epoch: 178 [2560/8000 (32%)]\tTotal Loss: 0.162840\n",
      "Reconstruction: 0.159649, Regularization: 0.003191\n",
      "2019-04-10 01:04:17,333 root         INFO     Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 0.156865\n",
      "Reconstruction: 0.154254, Regularization: 0.002611\n",
      "2019-04-10 01:04:17,395 root         INFO     Train Epoch: 178 [3584/8000 (45%)]\tTotal Loss: 0.164104\n",
      "Reconstruction: 0.161082, Regularization: 0.003022\n",
      "2019-04-10 01:04:17,457 root         INFO     Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 0.162050\n",
      "Reconstruction: 0.158808, Regularization: 0.003241\n",
      "2019-04-10 01:04:17,520 root         INFO     Train Epoch: 178 [4608/8000 (58%)]\tTotal Loss: 0.167555\n",
      "Reconstruction: 0.163771, Regularization: 0.003784\n",
      "2019-04-10 01:04:17,582 root         INFO     Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 0.170012\n",
      "Reconstruction: 0.165980, Regularization: 0.004032\n",
      "2019-04-10 01:04:17,644 root         INFO     Train Epoch: 178 [5632/8000 (70%)]\tTotal Loss: 0.160275\n",
      "Reconstruction: 0.157142, Regularization: 0.003133\n",
      "2019-04-10 01:04:17,706 root         INFO     Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 0.178574\n",
      "Reconstruction: 0.173558, Regularization: 0.005016\n",
      "2019-04-10 01:04:17,769 root         INFO     Train Epoch: 178 [6656/8000 (83%)]\tTotal Loss: 0.165042\n",
      "Reconstruction: 0.161440, Regularization: 0.003602\n",
      "2019-04-10 01:04:17,831 root         INFO     Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 0.173393\n",
      "Reconstruction: 0.169590, Regularization: 0.003804\n",
      "2019-04-10 01:04:17,893 root         INFO     Train Epoch: 178 [7680/8000 (96%)]\tTotal Loss: 0.166912\n",
      "Reconstruction: 0.163768, Regularization: 0.003144\n",
      "2019-04-10 01:04:17,947 root         INFO     ====> Epoch: 178 Average loss: 0.1659\n",
      "2019-04-10 01:04:17,970 root         INFO     Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 0.172733\n",
      "Reconstruction: 0.168851, Regularization: 0.003882\n",
      "2019-04-10 01:04:18,033 root         INFO     Train Epoch: 179 [512/8000 (6%)]\tTotal Loss: 0.164280\n",
      "Reconstruction: 0.160425, Regularization: 0.003855\n",
      "2019-04-10 01:04:18,096 root         INFO     Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 0.148067\n",
      "Reconstruction: 0.146524, Regularization: 0.001543\n",
      "2019-04-10 01:04:18,159 root         INFO     Train Epoch: 179 [1536/8000 (19%)]\tTotal Loss: 0.172393\n",
      "Reconstruction: 0.167541, Regularization: 0.004851\n",
      "2019-04-10 01:04:18,222 root         INFO     Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 0.165345\n",
      "Reconstruction: 0.161640, Regularization: 0.003705\n",
      "2019-04-10 01:04:18,284 root         INFO     Train Epoch: 179 [2560/8000 (32%)]\tTotal Loss: 0.171207\n",
      "Reconstruction: 0.166571, Regularization: 0.004636\n",
      "2019-04-10 01:04:18,346 root         INFO     Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 0.159593\n",
      "Reconstruction: 0.156777, Regularization: 0.002816\n",
      "2019-04-10 01:04:18,409 root         INFO     Train Epoch: 179 [3584/8000 (45%)]\tTotal Loss: 0.161167\n",
      "Reconstruction: 0.158536, Regularization: 0.002631\n",
      "2019-04-10 01:04:18,471 root         INFO     Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 0.177955\n",
      "Reconstruction: 0.173177, Regularization: 0.004778\n",
      "2019-04-10 01:04:18,533 root         INFO     Train Epoch: 179 [4608/8000 (58%)]\tTotal Loss: 0.166249\n",
      "Reconstruction: 0.162430, Regularization: 0.003818\n",
      "2019-04-10 01:04:18,596 root         INFO     Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 0.167704\n",
      "Reconstruction: 0.163791, Regularization: 0.003913\n",
      "2019-04-10 01:04:18,659 root         INFO     Train Epoch: 179 [5632/8000 (70%)]\tTotal Loss: 0.167480\n",
      "Reconstruction: 0.164299, Regularization: 0.003181\n",
      "2019-04-10 01:04:18,721 root         INFO     Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 0.176349\n",
      "Reconstruction: 0.172022, Regularization: 0.004327\n",
      "2019-04-10 01:04:18,784 root         INFO     Train Epoch: 179 [6656/8000 (83%)]\tTotal Loss: 0.168508\n",
      "Reconstruction: 0.164997, Regularization: 0.003511\n",
      "2019-04-10 01:04:18,846 root         INFO     Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 0.162803\n",
      "Reconstruction: 0.159615, Regularization: 0.003188\n",
      "2019-04-10 01:04:18,909 root         INFO     Train Epoch: 179 [7680/8000 (96%)]\tTotal Loss: 0.173869\n",
      "Reconstruction: 0.169833, Regularization: 0.004037\n",
      "2019-04-10 01:04:18,962 root         INFO     ====> Epoch: 179 Average loss: 0.1656\n",
      "2019-04-10 01:04:18,986 root         INFO     Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 0.166744\n",
      "Reconstruction: 0.162718, Regularization: 0.004026\n",
      "2019-04-10 01:04:19,048 root         INFO     Train Epoch: 180 [512/8000 (6%)]\tTotal Loss: 0.161323\n",
      "Reconstruction: 0.157932, Regularization: 0.003391\n",
      "2019-04-10 01:04:19,110 root         INFO     Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 0.169270\n",
      "Reconstruction: 0.165687, Regularization: 0.003582\n",
      "2019-04-10 01:04:19,171 root         INFO     Train Epoch: 180 [1536/8000 (19%)]\tTotal Loss: 0.183737\n",
      "Reconstruction: 0.177406, Regularization: 0.006332\n",
      "2019-04-10 01:04:19,232 root         INFO     Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 0.169249\n",
      "Reconstruction: 0.165515, Regularization: 0.003733\n",
      "2019-04-10 01:04:19,294 root         INFO     Train Epoch: 180 [2560/8000 (32%)]\tTotal Loss: 0.172084\n",
      "Reconstruction: 0.167428, Regularization: 0.004655\n",
      "2019-04-10 01:04:19,355 root         INFO     Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 0.164681\n",
      "Reconstruction: 0.161433, Regularization: 0.003248\n",
      "2019-04-10 01:04:19,417 root         INFO     Train Epoch: 180 [3584/8000 (45%)]\tTotal Loss: 0.160503\n",
      "Reconstruction: 0.157275, Regularization: 0.003228\n",
      "2019-04-10 01:04:19,478 root         INFO     Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 0.163893\n",
      "Reconstruction: 0.160758, Regularization: 0.003135\n",
      "2019-04-10 01:04:19,540 root         INFO     Train Epoch: 180 [4608/8000 (58%)]\tTotal Loss: 0.168523\n",
      "Reconstruction: 0.164238, Regularization: 0.004285\n",
      "2019-04-10 01:04:19,601 root         INFO     Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 0.164475\n",
      "Reconstruction: 0.161508, Regularization: 0.002967\n",
      "2019-04-10 01:04:19,663 root         INFO     Train Epoch: 180 [5632/8000 (70%)]\tTotal Loss: 0.159662\n",
      "Reconstruction: 0.156401, Regularization: 0.003261\n",
      "2019-04-10 01:04:19,724 root         INFO     Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 0.152733\n",
      "Reconstruction: 0.150679, Regularization: 0.002054\n",
      "2019-04-10 01:04:19,786 root         INFO     Train Epoch: 180 [6656/8000 (83%)]\tTotal Loss: 0.163429\n",
      "Reconstruction: 0.160027, Regularization: 0.003403\n",
      "2019-04-10 01:04:19,846 root         INFO     Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 0.154995\n",
      "Reconstruction: 0.151946, Regularization: 0.003049\n",
      "2019-04-10 01:04:19,907 root         INFO     Train Epoch: 180 [7680/8000 (96%)]\tTotal Loss: 0.153838\n",
      "Reconstruction: 0.150622, Regularization: 0.003217\n",
      "2019-04-10 01:04:19,960 root         INFO     ====> Epoch: 180 Average loss: 0.1653\n",
      "2019-04-10 01:04:19,984 root         INFO     Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 0.158477\n",
      "Reconstruction: 0.155320, Regularization: 0.003158\n",
      "2019-04-10 01:04:20,046 root         INFO     Train Epoch: 181 [512/8000 (6%)]\tTotal Loss: 0.172953\n",
      "Reconstruction: 0.168294, Regularization: 0.004660\n",
      "2019-04-10 01:04:20,108 root         INFO     Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 0.158154\n",
      "Reconstruction: 0.154609, Regularization: 0.003545\n",
      "2019-04-10 01:04:20,170 root         INFO     Train Epoch: 181 [1536/8000 (19%)]\tTotal Loss: 0.168432\n",
      "Reconstruction: 0.164347, Regularization: 0.004086\n",
      "2019-04-10 01:04:20,233 root         INFO     Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 0.163101\n",
      "Reconstruction: 0.159870, Regularization: 0.003231\n",
      "2019-04-10 01:04:20,295 root         INFO     Train Epoch: 181 [2560/8000 (32%)]\tTotal Loss: 0.163418\n",
      "Reconstruction: 0.160266, Regularization: 0.003152\n",
      "2019-04-10 01:04:20,358 root         INFO     Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 0.167350\n",
      "Reconstruction: 0.163883, Regularization: 0.003467\n",
      "2019-04-10 01:04:20,420 root         INFO     Train Epoch: 181 [3584/8000 (45%)]\tTotal Loss: 0.162099\n",
      "Reconstruction: 0.159152, Regularization: 0.002947\n",
      "2019-04-10 01:04:20,482 root         INFO     Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 0.163065\n",
      "Reconstruction: 0.159965, Regularization: 0.003100\n",
      "2019-04-10 01:04:20,544 root         INFO     Train Epoch: 181 [4608/8000 (58%)]\tTotal Loss: 0.161903\n",
      "Reconstruction: 0.158459, Regularization: 0.003443\n",
      "2019-04-10 01:04:20,606 root         INFO     Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 0.168336\n",
      "Reconstruction: 0.164613, Regularization: 0.003723\n",
      "2019-04-10 01:04:20,668 root         INFO     Train Epoch: 181 [5632/8000 (70%)]\tTotal Loss: 0.175230\n",
      "Reconstruction: 0.170428, Regularization: 0.004801\n",
      "2019-04-10 01:04:20,731 root         INFO     Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 0.162718\n",
      "Reconstruction: 0.159224, Regularization: 0.003494\n",
      "2019-04-10 01:04:20,794 root         INFO     Train Epoch: 181 [6656/8000 (83%)]\tTotal Loss: 0.168194\n",
      "Reconstruction: 0.163707, Regularization: 0.004486\n",
      "2019-04-10 01:04:20,855 root         INFO     Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 0.163025\n",
      "Reconstruction: 0.159215, Regularization: 0.003810\n",
      "2019-04-10 01:04:20,917 root         INFO     Train Epoch: 181 [7680/8000 (96%)]\tTotal Loss: 0.159274\n",
      "Reconstruction: 0.155682, Regularization: 0.003593\n",
      "2019-04-10 01:04:20,970 root         INFO     ====> Epoch: 181 Average loss: 0.1657\n",
      "2019-04-10 01:04:20,994 root         INFO     Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 0.164188\n",
      "Reconstruction: 0.160628, Regularization: 0.003561\n",
      "2019-04-10 01:04:21,057 root         INFO     Train Epoch: 182 [512/8000 (6%)]\tTotal Loss: 0.174331\n",
      "Reconstruction: 0.169807, Regularization: 0.004524\n",
      "2019-04-10 01:04:21,121 root         INFO     Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 0.179135\n",
      "Reconstruction: 0.173701, Regularization: 0.005434\n",
      "2019-04-10 01:04:21,184 root         INFO     Train Epoch: 182 [1536/8000 (19%)]\tTotal Loss: 0.154201\n",
      "Reconstruction: 0.150781, Regularization: 0.003420\n",
      "2019-04-10 01:04:21,247 root         INFO     Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 0.163745\n",
      "Reconstruction: 0.160473, Regularization: 0.003272\n",
      "2019-04-10 01:04:21,311 root         INFO     Train Epoch: 182 [2560/8000 (32%)]\tTotal Loss: 0.159186\n",
      "Reconstruction: 0.156047, Regularization: 0.003139\n",
      "2019-04-10 01:04:21,375 root         INFO     Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 0.162669\n",
      "Reconstruction: 0.159016, Regularization: 0.003653\n",
      "2019-04-10 01:04:21,438 root         INFO     Train Epoch: 182 [3584/8000 (45%)]\tTotal Loss: 0.162123\n",
      "Reconstruction: 0.158471, Regularization: 0.003652\n",
      "2019-04-10 01:04:21,501 root         INFO     Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 0.153568\n",
      "Reconstruction: 0.150867, Regularization: 0.002701\n",
      "2019-04-10 01:04:21,565 root         INFO     Train Epoch: 182 [4608/8000 (58%)]\tTotal Loss: 0.169623\n",
      "Reconstruction: 0.164654, Regularization: 0.004970\n",
      "2019-04-10 01:04:21,628 root         INFO     Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 0.165007\n",
      "Reconstruction: 0.161319, Regularization: 0.003688\n",
      "2019-04-10 01:04:21,692 root         INFO     Train Epoch: 182 [5632/8000 (70%)]\tTotal Loss: 0.170399\n",
      "Reconstruction: 0.166055, Regularization: 0.004344\n",
      "2019-04-10 01:04:21,755 root         INFO     Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 0.162403\n",
      "Reconstruction: 0.159245, Regularization: 0.003159\n",
      "2019-04-10 01:04:21,819 root         INFO     Train Epoch: 182 [6656/8000 (83%)]\tTotal Loss: 0.150984\n",
      "Reconstruction: 0.148531, Regularization: 0.002452\n",
      "2019-04-10 01:04:21,882 root         INFO     Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 0.169341\n",
      "Reconstruction: 0.164699, Regularization: 0.004643\n",
      "2019-04-10 01:04:21,945 root         INFO     Train Epoch: 182 [7680/8000 (96%)]\tTotal Loss: 0.171884\n",
      "Reconstruction: 0.166633, Regularization: 0.005251\n",
      "2019-04-10 01:04:21,999 root         INFO     ====> Epoch: 182 Average loss: 0.1656\n",
      "2019-04-10 01:04:22,023 root         INFO     Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 0.162173\n",
      "Reconstruction: 0.159044, Regularization: 0.003129\n",
      "2019-04-10 01:04:22,087 root         INFO     Train Epoch: 183 [512/8000 (6%)]\tTotal Loss: 0.182728\n",
      "Reconstruction: 0.175546, Regularization: 0.007182\n",
      "2019-04-10 01:04:22,151 root         INFO     Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 0.165456\n",
      "Reconstruction: 0.161633, Regularization: 0.003824\n",
      "2019-04-10 01:04:22,214 root         INFO     Train Epoch: 183 [1536/8000 (19%)]\tTotal Loss: 0.159622\n",
      "Reconstruction: 0.156295, Regularization: 0.003327\n",
      "2019-04-10 01:04:22,278 root         INFO     Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 0.153067\n",
      "Reconstruction: 0.150284, Regularization: 0.002782\n",
      "2019-04-10 01:04:22,341 root         INFO     Train Epoch: 183 [2560/8000 (32%)]\tTotal Loss: 0.170127\n",
      "Reconstruction: 0.166081, Regularization: 0.004046\n",
      "2019-04-10 01:04:22,404 root         INFO     Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 0.155804\n",
      "Reconstruction: 0.152976, Regularization: 0.002828\n",
      "2019-04-10 01:04:22,468 root         INFO     Train Epoch: 183 [3584/8000 (45%)]\tTotal Loss: 0.166068\n",
      "Reconstruction: 0.161482, Regularization: 0.004586\n",
      "2019-04-10 01:04:22,531 root         INFO     Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 0.166565\n",
      "Reconstruction: 0.162687, Regularization: 0.003878\n",
      "2019-04-10 01:04:22,593 root         INFO     Train Epoch: 183 [4608/8000 (58%)]\tTotal Loss: 0.157665\n",
      "Reconstruction: 0.154496, Regularization: 0.003170\n",
      "2019-04-10 01:04:22,656 root         INFO     Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 0.154991\n",
      "Reconstruction: 0.152167, Regularization: 0.002824\n",
      "2019-04-10 01:04:22,719 root         INFO     Train Epoch: 183 [5632/8000 (70%)]\tTotal Loss: 0.168588\n",
      "Reconstruction: 0.164550, Regularization: 0.004038\n",
      "2019-04-10 01:04:22,781 root         INFO     Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 0.160705\n",
      "Reconstruction: 0.157420, Regularization: 0.003285\n",
      "2019-04-10 01:04:22,844 root         INFO     Train Epoch: 183 [6656/8000 (83%)]\tTotal Loss: 0.160292\n",
      "Reconstruction: 0.156693, Regularization: 0.003599\n",
      "2019-04-10 01:04:22,907 root         INFO     Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 0.159899\n",
      "Reconstruction: 0.156369, Regularization: 0.003530\n",
      "2019-04-10 01:04:22,970 root         INFO     Train Epoch: 183 [7680/8000 (96%)]\tTotal Loss: 0.157843\n",
      "Reconstruction: 0.154061, Regularization: 0.003782\n",
      "2019-04-10 01:04:23,024 root         INFO     ====> Epoch: 183 Average loss: 0.1654\n",
      "2019-04-10 01:04:23,048 root         INFO     Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 0.177439\n",
      "Reconstruction: 0.172521, Regularization: 0.004918\n",
      "2019-04-10 01:04:23,112 root         INFO     Train Epoch: 184 [512/8000 (6%)]\tTotal Loss: 0.158425\n",
      "Reconstruction: 0.154919, Regularization: 0.003506\n",
      "2019-04-10 01:04:23,175 root         INFO     Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 0.164011\n",
      "Reconstruction: 0.160099, Regularization: 0.003912\n",
      "2019-04-10 01:04:23,238 root         INFO     Train Epoch: 184 [1536/8000 (19%)]\tTotal Loss: 0.169109\n",
      "Reconstruction: 0.165749, Regularization: 0.003359\n",
      "2019-04-10 01:04:23,302 root         INFO     Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 0.159389\n",
      "Reconstruction: 0.156487, Regularization: 0.002902\n",
      "2019-04-10 01:04:23,366 root         INFO     Train Epoch: 184 [2560/8000 (32%)]\tTotal Loss: 0.170719\n",
      "Reconstruction: 0.166871, Regularization: 0.003849\n",
      "2019-04-10 01:04:23,429 root         INFO     Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 0.171230\n",
      "Reconstruction: 0.166068, Regularization: 0.005162\n",
      "2019-04-10 01:04:23,492 root         INFO     Train Epoch: 184 [3584/8000 (45%)]\tTotal Loss: 0.172242\n",
      "Reconstruction: 0.167088, Regularization: 0.005154\n",
      "2019-04-10 01:04:23,555 root         INFO     Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 0.163124\n",
      "Reconstruction: 0.159011, Regularization: 0.004112\n",
      "2019-04-10 01:04:23,619 root         INFO     Train Epoch: 184 [4608/8000 (58%)]\tTotal Loss: 0.191681\n",
      "Reconstruction: 0.184037, Regularization: 0.007644\n",
      "2019-04-10 01:04:23,682 root         INFO     Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 0.173239\n",
      "Reconstruction: 0.168602, Regularization: 0.004637\n",
      "2019-04-10 01:04:23,746 root         INFO     Train Epoch: 184 [5632/8000 (70%)]\tTotal Loss: 0.173048\n",
      "Reconstruction: 0.168190, Regularization: 0.004858\n",
      "2019-04-10 01:04:23,809 root         INFO     Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 0.161062\n",
      "Reconstruction: 0.157409, Regularization: 0.003653\n",
      "2019-04-10 01:04:23,873 root         INFO     Train Epoch: 184 [6656/8000 (83%)]\tTotal Loss: 0.157764\n",
      "Reconstruction: 0.154611, Regularization: 0.003153\n",
      "2019-04-10 01:04:23,936 root         INFO     Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 0.169226\n",
      "Reconstruction: 0.165487, Regularization: 0.003739\n",
      "2019-04-10 01:04:24,000 root         INFO     Train Epoch: 184 [7680/8000 (96%)]\tTotal Loss: 0.157371\n",
      "Reconstruction: 0.153924, Regularization: 0.003447\n",
      "2019-04-10 01:04:24,054 root         INFO     ====> Epoch: 184 Average loss: 0.1651\n",
      "2019-04-10 01:04:24,078 root         INFO     Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 0.165670\n",
      "Reconstruction: 0.161719, Regularization: 0.003952\n",
      "2019-04-10 01:04:24,142 root         INFO     Train Epoch: 185 [512/8000 (6%)]\tTotal Loss: 0.162593\n",
      "Reconstruction: 0.159334, Regularization: 0.003260\n",
      "2019-04-10 01:04:24,207 root         INFO     Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 0.155263\n",
      "Reconstruction: 0.152151, Regularization: 0.003112\n",
      "2019-04-10 01:04:24,271 root         INFO     Train Epoch: 185 [1536/8000 (19%)]\tTotal Loss: 0.165725\n",
      "Reconstruction: 0.161151, Regularization: 0.004574\n",
      "2019-04-10 01:04:24,334 root         INFO     Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 0.165384\n",
      "Reconstruction: 0.161182, Regularization: 0.004202\n",
      "2019-04-10 01:04:24,399 root         INFO     Train Epoch: 185 [2560/8000 (32%)]\tTotal Loss: 0.162415\n",
      "Reconstruction: 0.158989, Regularization: 0.003426\n",
      "2019-04-10 01:04:24,463 root         INFO     Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 0.159813\n",
      "Reconstruction: 0.156396, Regularization: 0.003417\n",
      "2019-04-10 01:04:24,527 root         INFO     Train Epoch: 185 [3584/8000 (45%)]\tTotal Loss: 0.172649\n",
      "Reconstruction: 0.166934, Regularization: 0.005715\n",
      "2019-04-10 01:04:24,590 root         INFO     Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 0.159457\n",
      "Reconstruction: 0.156376, Regularization: 0.003080\n",
      "2019-04-10 01:04:24,655 root         INFO     Train Epoch: 185 [4608/8000 (58%)]\tTotal Loss: 0.162149\n",
      "Reconstruction: 0.158341, Regularization: 0.003808\n",
      "2019-04-10 01:04:24,719 root         INFO     Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 0.171704\n",
      "Reconstruction: 0.165687, Regularization: 0.006016\n",
      "2019-04-10 01:04:24,783 root         INFO     Train Epoch: 185 [5632/8000 (70%)]\tTotal Loss: 0.148542\n",
      "Reconstruction: 0.146026, Regularization: 0.002515\n",
      "2019-04-10 01:04:24,846 root         INFO     Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 0.161897\n",
      "Reconstruction: 0.157701, Regularization: 0.004195\n",
      "2019-04-10 01:04:24,910 root         INFO     Train Epoch: 185 [6656/8000 (83%)]\tTotal Loss: 0.165665\n",
      "Reconstruction: 0.160795, Regularization: 0.004870\n",
      "2019-04-10 01:04:24,972 root         INFO     Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 0.163869\n",
      "Reconstruction: 0.159672, Regularization: 0.004197\n",
      "2019-04-10 01:04:25,034 root         INFO     Train Epoch: 185 [7680/8000 (96%)]\tTotal Loss: 0.169257\n",
      "Reconstruction: 0.165519, Regularization: 0.003738\n",
      "2019-04-10 01:04:25,087 root         INFO     ====> Epoch: 185 Average loss: 0.1653\n",
      "2019-04-10 01:04:25,110 root         INFO     Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 0.170325\n",
      "Reconstruction: 0.165858, Regularization: 0.004467\n",
      "2019-04-10 01:04:25,173 root         INFO     Train Epoch: 186 [512/8000 (6%)]\tTotal Loss: 0.174945\n",
      "Reconstruction: 0.168704, Regularization: 0.006240\n",
      "2019-04-10 01:04:25,237 root         INFO     Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 0.170319\n",
      "Reconstruction: 0.165454, Regularization: 0.004865\n",
      "2019-04-10 01:04:25,300 root         INFO     Train Epoch: 186 [1536/8000 (19%)]\tTotal Loss: 0.175702\n",
      "Reconstruction: 0.169675, Regularization: 0.006026\n",
      "2019-04-10 01:04:25,364 root         INFO     Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 0.155171\n",
      "Reconstruction: 0.151838, Regularization: 0.003334\n",
      "2019-04-10 01:04:25,427 root         INFO     Train Epoch: 186 [2560/8000 (32%)]\tTotal Loss: 0.169333\n",
      "Reconstruction: 0.164545, Regularization: 0.004788\n",
      "2019-04-10 01:04:25,488 root         INFO     Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 0.179468\n",
      "Reconstruction: 0.174064, Regularization: 0.005404\n",
      "2019-04-10 01:04:25,552 root         INFO     Train Epoch: 186 [3584/8000 (45%)]\tTotal Loss: 0.174777\n",
      "Reconstruction: 0.168940, Regularization: 0.005838\n",
      "2019-04-10 01:04:25,615 root         INFO     Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 0.159141\n",
      "Reconstruction: 0.155472, Regularization: 0.003669\n",
      "2019-04-10 01:04:25,678 root         INFO     Train Epoch: 186 [4608/8000 (58%)]\tTotal Loss: 0.163485\n",
      "Reconstruction: 0.159838, Regularization: 0.003647\n",
      "2019-04-10 01:04:25,741 root         INFO     Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 0.167083\n",
      "Reconstruction: 0.162959, Regularization: 0.004124\n",
      "2019-04-10 01:04:25,805 root         INFO     Train Epoch: 186 [5632/8000 (70%)]\tTotal Loss: 0.149309\n",
      "Reconstruction: 0.146772, Regularization: 0.002537\n",
      "2019-04-10 01:04:25,868 root         INFO     Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 0.158365\n",
      "Reconstruction: 0.154772, Regularization: 0.003593\n",
      "2019-04-10 01:04:25,932 root         INFO     Train Epoch: 186 [6656/8000 (83%)]\tTotal Loss: 0.160938\n",
      "Reconstruction: 0.156822, Regularization: 0.004116\n",
      "2019-04-10 01:04:25,995 root         INFO     Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 0.167086\n",
      "Reconstruction: 0.163325, Regularization: 0.003761\n",
      "2019-04-10 01:04:26,058 root         INFO     Train Epoch: 186 [7680/8000 (96%)]\tTotal Loss: 0.161211\n",
      "Reconstruction: 0.157346, Regularization: 0.003865\n",
      "2019-04-10 01:04:26,112 root         INFO     ====> Epoch: 186 Average loss: 0.1653\n",
      "2019-04-10 01:04:26,135 root         INFO     Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 0.176074\n",
      "Reconstruction: 0.170541, Regularization: 0.005534\n",
      "2019-04-10 01:04:26,199 root         INFO     Train Epoch: 187 [512/8000 (6%)]\tTotal Loss: 0.152781\n",
      "Reconstruction: 0.150059, Regularization: 0.002722\n",
      "2019-04-10 01:04:26,263 root         INFO     Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 0.181599\n",
      "Reconstruction: 0.175745, Regularization: 0.005853\n",
      "2019-04-10 01:04:26,327 root         INFO     Train Epoch: 187 [1536/8000 (19%)]\tTotal Loss: 0.164467\n",
      "Reconstruction: 0.159972, Regularization: 0.004495\n",
      "2019-04-10 01:04:26,391 root         INFO     Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 0.157161\n",
      "Reconstruction: 0.153434, Regularization: 0.003727\n",
      "2019-04-10 01:04:26,455 root         INFO     Train Epoch: 187 [2560/8000 (32%)]\tTotal Loss: 0.154245\n",
      "Reconstruction: 0.150941, Regularization: 0.003304\n",
      "2019-04-10 01:04:26,519 root         INFO     Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 0.165972\n",
      "Reconstruction: 0.161987, Regularization: 0.003985\n",
      "2019-04-10 01:04:26,582 root         INFO     Train Epoch: 187 [3584/8000 (45%)]\tTotal Loss: 0.183053\n",
      "Reconstruction: 0.176787, Regularization: 0.006266\n",
      "2019-04-10 01:04:26,647 root         INFO     Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 0.161959\n",
      "Reconstruction: 0.157766, Regularization: 0.004193\n",
      "2019-04-10 01:04:26,711 root         INFO     Train Epoch: 187 [4608/8000 (58%)]\tTotal Loss: 0.160687\n",
      "Reconstruction: 0.157058, Regularization: 0.003628\n",
      "2019-04-10 01:04:26,775 root         INFO     Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 0.167655\n",
      "Reconstruction: 0.163172, Regularization: 0.004483\n",
      "2019-04-10 01:04:26,839 root         INFO     Train Epoch: 187 [5632/8000 (70%)]\tTotal Loss: 0.165028\n",
      "Reconstruction: 0.160550, Regularization: 0.004477\n",
      "2019-04-10 01:04:26,902 root         INFO     Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 0.172463\n",
      "Reconstruction: 0.167593, Regularization: 0.004870\n",
      "2019-04-10 01:04:26,966 root         INFO     Train Epoch: 187 [6656/8000 (83%)]\tTotal Loss: 0.173577\n",
      "Reconstruction: 0.168265, Regularization: 0.005312\n",
      "2019-04-10 01:04:27,030 root         INFO     Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 0.165970\n",
      "Reconstruction: 0.161010, Regularization: 0.004960\n",
      "2019-04-10 01:04:27,094 root         INFO     Train Epoch: 187 [7680/8000 (96%)]\tTotal Loss: 0.169484\n",
      "Reconstruction: 0.164321, Regularization: 0.005163\n",
      "2019-04-10 01:04:27,148 root         INFO     ====> Epoch: 187 Average loss: 0.1652\n",
      "2019-04-10 01:04:27,172 root         INFO     Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 0.161920\n",
      "Reconstruction: 0.157999, Regularization: 0.003921\n",
      "2019-04-10 01:04:27,236 root         INFO     Train Epoch: 188 [512/8000 (6%)]\tTotal Loss: 0.161872\n",
      "Reconstruction: 0.157840, Regularization: 0.004033\n",
      "2019-04-10 01:04:27,299 root         INFO     Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 0.155891\n",
      "Reconstruction: 0.152644, Regularization: 0.003247\n",
      "2019-04-10 01:04:27,362 root         INFO     Train Epoch: 188 [1536/8000 (19%)]\tTotal Loss: 0.164889\n",
      "Reconstruction: 0.160309, Regularization: 0.004580\n",
      "2019-04-10 01:04:27,426 root         INFO     Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 0.163693\n",
      "Reconstruction: 0.159529, Regularization: 0.004164\n",
      "2019-04-10 01:04:27,489 root         INFO     Train Epoch: 188 [2560/8000 (32%)]\tTotal Loss: 0.161818\n",
      "Reconstruction: 0.156513, Regularization: 0.005305\n",
      "2019-04-10 01:04:27,552 root         INFO     Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 0.185806\n",
      "Reconstruction: 0.179872, Regularization: 0.005934\n",
      "2019-04-10 01:04:27,616 root         INFO     Train Epoch: 188 [3584/8000 (45%)]\tTotal Loss: 0.152865\n",
      "Reconstruction: 0.149877, Regularization: 0.002988\n",
      "2019-04-10 01:04:27,679 root         INFO     Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 0.178072\n",
      "Reconstruction: 0.173220, Regularization: 0.004851\n",
      "2019-04-10 01:04:27,742 root         INFO     Train Epoch: 188 [4608/8000 (58%)]\tTotal Loss: 0.150242\n",
      "Reconstruction: 0.146932, Regularization: 0.003310\n",
      "2019-04-10 01:04:27,806 root         INFO     Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 0.159235\n",
      "Reconstruction: 0.155753, Regularization: 0.003482\n",
      "2019-04-10 01:04:27,869 root         INFO     Train Epoch: 188 [5632/8000 (70%)]\tTotal Loss: 0.173724\n",
      "Reconstruction: 0.168987, Regularization: 0.004736\n",
      "2019-04-10 01:04:27,933 root         INFO     Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 0.175978\n",
      "Reconstruction: 0.170917, Regularization: 0.005061\n",
      "2019-04-10 01:04:27,996 root         INFO     Train Epoch: 188 [6656/8000 (83%)]\tTotal Loss: 0.165436\n",
      "Reconstruction: 0.160823, Regularization: 0.004613\n",
      "2019-04-10 01:04:28,059 root         INFO     Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 0.172104\n",
      "Reconstruction: 0.166487, Regularization: 0.005617\n",
      "2019-04-10 01:04:28,123 root         INFO     Train Epoch: 188 [7680/8000 (96%)]\tTotal Loss: 0.172094\n",
      "Reconstruction: 0.167521, Regularization: 0.004573\n",
      "2019-04-10 01:04:28,177 root         INFO     ====> Epoch: 188 Average loss: 0.1651\n",
      "2019-04-10 01:04:28,200 root         INFO     Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 0.160426\n",
      "Reconstruction: 0.156340, Regularization: 0.004087\n",
      "2019-04-10 01:04:28,266 root         INFO     Train Epoch: 189 [512/8000 (6%)]\tTotal Loss: 0.160142\n",
      "Reconstruction: 0.156680, Regularization: 0.003462\n",
      "2019-04-10 01:04:28,329 root         INFO     Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 0.177171\n",
      "Reconstruction: 0.172400, Regularization: 0.004771\n",
      "2019-04-10 01:04:28,393 root         INFO     Train Epoch: 189 [1536/8000 (19%)]\tTotal Loss: 0.161152\n",
      "Reconstruction: 0.157650, Regularization: 0.003502\n",
      "2019-04-10 01:04:28,457 root         INFO     Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 0.161003\n",
      "Reconstruction: 0.156944, Regularization: 0.004059\n",
      "2019-04-10 01:04:28,521 root         INFO     Train Epoch: 189 [2560/8000 (32%)]\tTotal Loss: 0.169322\n",
      "Reconstruction: 0.164185, Regularization: 0.005138\n",
      "2019-04-10 01:04:28,585 root         INFO     Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 0.170110\n",
      "Reconstruction: 0.165096, Regularization: 0.005014\n",
      "2019-04-10 01:04:28,649 root         INFO     Train Epoch: 189 [3584/8000 (45%)]\tTotal Loss: 0.178837\n",
      "Reconstruction: 0.172233, Regularization: 0.006604\n",
      "2019-04-10 01:04:28,713 root         INFO     Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 0.157169\n",
      "Reconstruction: 0.153111, Regularization: 0.004058\n",
      "2019-04-10 01:04:28,777 root         INFO     Train Epoch: 189 [4608/8000 (58%)]\tTotal Loss: 0.161219\n",
      "Reconstruction: 0.157068, Regularization: 0.004151\n",
      "2019-04-10 01:04:28,841 root         INFO     Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 0.167980\n",
      "Reconstruction: 0.162785, Regularization: 0.005194\n",
      "2019-04-10 01:04:28,905 root         INFO     Train Epoch: 189 [5632/8000 (70%)]\tTotal Loss: 0.152820\n",
      "Reconstruction: 0.149641, Regularization: 0.003179\n",
      "2019-04-10 01:04:28,969 root         INFO     Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 0.162947\n",
      "Reconstruction: 0.158162, Regularization: 0.004786\n",
      "2019-04-10 01:04:29,033 root         INFO     Train Epoch: 189 [6656/8000 (83%)]\tTotal Loss: 0.163825\n",
      "Reconstruction: 0.159785, Regularization: 0.004040\n",
      "2019-04-10 01:04:29,097 root         INFO     Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 0.164480\n",
      "Reconstruction: 0.159913, Regularization: 0.004567\n",
      "2019-04-10 01:04:29,160 root         INFO     Train Epoch: 189 [7680/8000 (96%)]\tTotal Loss: 0.163525\n",
      "Reconstruction: 0.159225, Regularization: 0.004300\n",
      "2019-04-10 01:04:29,214 root         INFO     ====> Epoch: 189 Average loss: 0.1651\n",
      "2019-04-10 01:04:29,239 root         INFO     Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 0.174129\n",
      "Reconstruction: 0.169256, Regularization: 0.004873\n",
      "2019-04-10 01:04:29,303 root         INFO     Train Epoch: 190 [512/8000 (6%)]\tTotal Loss: 0.170550\n",
      "Reconstruction: 0.164853, Regularization: 0.005697\n",
      "2019-04-10 01:04:29,367 root         INFO     Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 0.168508\n",
      "Reconstruction: 0.162948, Regularization: 0.005560\n",
      "2019-04-10 01:04:29,430 root         INFO     Train Epoch: 190 [1536/8000 (19%)]\tTotal Loss: 0.178498\n",
      "Reconstruction: 0.171955, Regularization: 0.006543\n",
      "2019-04-10 01:04:29,494 root         INFO     Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 0.167311\n",
      "Reconstruction: 0.162514, Regularization: 0.004797\n",
      "2019-04-10 01:04:29,556 root         INFO     Train Epoch: 190 [2560/8000 (32%)]\tTotal Loss: 0.169990\n",
      "Reconstruction: 0.164569, Regularization: 0.005422\n",
      "2019-04-10 01:04:29,618 root         INFO     Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 0.177720\n",
      "Reconstruction: 0.171680, Regularization: 0.006040\n",
      "2019-04-10 01:04:29,680 root         INFO     Train Epoch: 190 [3584/8000 (45%)]\tTotal Loss: 0.174332\n",
      "Reconstruction: 0.169408, Regularization: 0.004923\n",
      "2019-04-10 01:04:29,743 root         INFO     Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 0.153633\n",
      "Reconstruction: 0.150771, Regularization: 0.002862\n",
      "2019-04-10 01:04:29,805 root         INFO     Train Epoch: 190 [4608/8000 (58%)]\tTotal Loss: 0.155046\n",
      "Reconstruction: 0.152059, Regularization: 0.002987\n",
      "2019-04-10 01:04:29,867 root         INFO     Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 0.159288\n",
      "Reconstruction: 0.154369, Regularization: 0.004919\n",
      "2019-04-10 01:04:29,930 root         INFO     Train Epoch: 190 [5632/8000 (70%)]\tTotal Loss: 0.153089\n",
      "Reconstruction: 0.149849, Regularization: 0.003240\n",
      "2019-04-10 01:04:29,993 root         INFO     Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 0.163417\n",
      "Reconstruction: 0.158491, Regularization: 0.004926\n",
      "2019-04-10 01:04:30,055 root         INFO     Train Epoch: 190 [6656/8000 (83%)]\tTotal Loss: 0.177181\n",
      "Reconstruction: 0.171468, Regularization: 0.005713\n",
      "2019-04-10 01:04:30,117 root         INFO     Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 0.159722\n",
      "Reconstruction: 0.156675, Regularization: 0.003047\n",
      "2019-04-10 01:04:30,178 root         INFO     Train Epoch: 190 [7680/8000 (96%)]\tTotal Loss: 0.166173\n",
      "Reconstruction: 0.161241, Regularization: 0.004932\n",
      "2019-04-10 01:04:30,231 root         INFO     ====> Epoch: 190 Average loss: 0.1655\n",
      "2019-04-10 01:04:30,255 root         INFO     Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 0.156454\n",
      "Reconstruction: 0.152606, Regularization: 0.003849\n",
      "2019-04-10 01:04:30,317 root         INFO     Train Epoch: 191 [512/8000 (6%)]\tTotal Loss: 0.159585\n",
      "Reconstruction: 0.155589, Regularization: 0.003996\n",
      "2019-04-10 01:04:30,379 root         INFO     Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 0.169503\n",
      "Reconstruction: 0.164241, Regularization: 0.005262\n",
      "2019-04-10 01:04:30,441 root         INFO     Train Epoch: 191 [1536/8000 (19%)]\tTotal Loss: 0.170233\n",
      "Reconstruction: 0.164881, Regularization: 0.005352\n",
      "2019-04-10 01:04:30,502 root         INFO     Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 0.164289\n",
      "Reconstruction: 0.159890, Regularization: 0.004399\n",
      "2019-04-10 01:04:30,563 root         INFO     Train Epoch: 191 [2560/8000 (32%)]\tTotal Loss: 0.152492\n",
      "Reconstruction: 0.149253, Regularization: 0.003239\n",
      "2019-04-10 01:04:30,624 root         INFO     Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 0.161260\n",
      "Reconstruction: 0.156608, Regularization: 0.004652\n",
      "2019-04-10 01:04:30,686 root         INFO     Train Epoch: 191 [3584/8000 (45%)]\tTotal Loss: 0.163198\n",
      "Reconstruction: 0.159314, Regularization: 0.003884\n",
      "2019-04-10 01:04:30,747 root         INFO     Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 0.150305\n",
      "Reconstruction: 0.147314, Regularization: 0.002990\n",
      "2019-04-10 01:04:30,808 root         INFO     Train Epoch: 191 [4608/8000 (58%)]\tTotal Loss: 0.167258\n",
      "Reconstruction: 0.161815, Regularization: 0.005443\n",
      "2019-04-10 01:04:30,869 root         INFO     Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 0.160378\n",
      "Reconstruction: 0.156175, Regularization: 0.004203\n",
      "2019-04-10 01:04:30,931 root         INFO     Train Epoch: 191 [5632/8000 (70%)]\tTotal Loss: 0.167182\n",
      "Reconstruction: 0.162069, Regularization: 0.005113\n",
      "2019-04-10 01:04:30,993 root         INFO     Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 0.146180\n",
      "Reconstruction: 0.143184, Regularization: 0.002997\n",
      "2019-04-10 01:04:31,055 root         INFO     Train Epoch: 191 [6656/8000 (83%)]\tTotal Loss: 0.170458\n",
      "Reconstruction: 0.165013, Regularization: 0.005445\n",
      "2019-04-10 01:04:31,118 root         INFO     Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 0.187967\n",
      "Reconstruction: 0.179950, Regularization: 0.008017\n",
      "2019-04-10 01:04:31,179 root         INFO     Train Epoch: 191 [7680/8000 (96%)]\tTotal Loss: 0.160180\n",
      "Reconstruction: 0.156043, Regularization: 0.004136\n",
      "2019-04-10 01:04:31,233 root         INFO     ====> Epoch: 191 Average loss: 0.1654\n",
      "2019-04-10 01:04:31,256 root         INFO     Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 0.162171\n",
      "Reconstruction: 0.157622, Regularization: 0.004549\n",
      "2019-04-10 01:04:31,319 root         INFO     Train Epoch: 192 [512/8000 (6%)]\tTotal Loss: 0.164322\n",
      "Reconstruction: 0.159036, Regularization: 0.005286\n",
      "2019-04-10 01:04:31,381 root         INFO     Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 0.160085\n",
      "Reconstruction: 0.155583, Regularization: 0.004502\n",
      "2019-04-10 01:04:31,444 root         INFO     Train Epoch: 192 [1536/8000 (19%)]\tTotal Loss: 0.160692\n",
      "Reconstruction: 0.156192, Regularization: 0.004500\n",
      "2019-04-10 01:04:31,506 root         INFO     Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.155572\n",
      "Reconstruction: 0.152166, Regularization: 0.003407\n",
      "2019-04-10 01:04:31,568 root         INFO     Train Epoch: 192 [2560/8000 (32%)]\tTotal Loss: 0.168059\n",
      "Reconstruction: 0.162782, Regularization: 0.005277\n",
      "2019-04-10 01:04:31,630 root         INFO     Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 0.162441\n",
      "Reconstruction: 0.157405, Regularization: 0.005036\n",
      "2019-04-10 01:04:31,693 root         INFO     Train Epoch: 192 [3584/8000 (45%)]\tTotal Loss: 0.165047\n",
      "Reconstruction: 0.161403, Regularization: 0.003644\n",
      "2019-04-10 01:04:31,755 root         INFO     Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 0.163600\n",
      "Reconstruction: 0.158927, Regularization: 0.004673\n",
      "2019-04-10 01:04:31,818 root         INFO     Train Epoch: 192 [4608/8000 (58%)]\tTotal Loss: 0.159300\n",
      "Reconstruction: 0.154260, Regularization: 0.005041\n",
      "2019-04-10 01:04:31,880 root         INFO     Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 0.166616\n",
      "Reconstruction: 0.163020, Regularization: 0.003596\n",
      "2019-04-10 01:04:31,942 root         INFO     Train Epoch: 192 [5632/8000 (70%)]\tTotal Loss: 0.148817\n",
      "Reconstruction: 0.146131, Regularization: 0.002686\n",
      "2019-04-10 01:04:32,005 root         INFO     Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 0.163044\n",
      "Reconstruction: 0.157576, Regularization: 0.005469\n",
      "2019-04-10 01:04:32,067 root         INFO     Train Epoch: 192 [6656/8000 (83%)]\tTotal Loss: 0.148268\n",
      "Reconstruction: 0.145633, Regularization: 0.002635\n",
      "2019-04-10 01:04:32,129 root         INFO     Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 0.159865\n",
      "Reconstruction: 0.154848, Regularization: 0.005017\n",
      "2019-04-10 01:04:32,192 root         INFO     Train Epoch: 192 [7680/8000 (96%)]\tTotal Loss: 0.168712\n",
      "Reconstruction: 0.162545, Regularization: 0.006168\n",
      "2019-04-10 01:04:32,245 root         INFO     ====> Epoch: 192 Average loss: 0.1653\n",
      "2019-04-10 01:04:32,269 root         INFO     Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 0.161865\n",
      "Reconstruction: 0.156806, Regularization: 0.005059\n",
      "2019-04-10 01:04:32,331 root         INFO     Train Epoch: 193 [512/8000 (6%)]\tTotal Loss: 0.167060\n",
      "Reconstruction: 0.162136, Regularization: 0.004923\n",
      "2019-04-10 01:04:32,393 root         INFO     Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 0.157258\n",
      "Reconstruction: 0.153895, Regularization: 0.003363\n",
      "2019-04-10 01:04:32,455 root         INFO     Train Epoch: 193 [1536/8000 (19%)]\tTotal Loss: 0.169826\n",
      "Reconstruction: 0.165115, Regularization: 0.004711\n",
      "2019-04-10 01:04:32,516 root         INFO     Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 0.167323\n",
      "Reconstruction: 0.161871, Regularization: 0.005453\n",
      "2019-04-10 01:04:32,579 root         INFO     Train Epoch: 193 [2560/8000 (32%)]\tTotal Loss: 0.151363\n",
      "Reconstruction: 0.148062, Regularization: 0.003301\n",
      "2019-04-10 01:04:32,641 root         INFO     Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 0.170216\n",
      "Reconstruction: 0.165228, Regularization: 0.004988\n",
      "2019-04-10 01:04:32,703 root         INFO     Train Epoch: 193 [3584/8000 (45%)]\tTotal Loss: 0.156993\n",
      "Reconstruction: 0.152583, Regularization: 0.004411\n",
      "2019-04-10 01:04:32,765 root         INFO     Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 0.164955\n",
      "Reconstruction: 0.160010, Regularization: 0.004946\n",
      "2019-04-10 01:04:32,826 root         INFO     Train Epoch: 193 [4608/8000 (58%)]\tTotal Loss: 0.164589\n",
      "Reconstruction: 0.158817, Regularization: 0.005772\n",
      "2019-04-10 01:04:32,888 root         INFO     Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 0.159651\n",
      "Reconstruction: 0.155015, Regularization: 0.004636\n",
      "2019-04-10 01:04:32,950 root         INFO     Train Epoch: 193 [5632/8000 (70%)]\tTotal Loss: 0.179201\n",
      "Reconstruction: 0.172017, Regularization: 0.007184\n",
      "2019-04-10 01:04:33,012 root         INFO     Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 0.159937\n",
      "Reconstruction: 0.155019, Regularization: 0.004919\n",
      "2019-04-10 01:04:33,073 root         INFO     Train Epoch: 193 [6656/8000 (83%)]\tTotal Loss: 0.164437\n",
      "Reconstruction: 0.159976, Regularization: 0.004460\n",
      "2019-04-10 01:04:33,135 root         INFO     Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 0.164456\n",
      "Reconstruction: 0.160353, Regularization: 0.004103\n",
      "2019-04-10 01:04:33,197 root         INFO     Train Epoch: 193 [7680/8000 (96%)]\tTotal Loss: 0.164743\n",
      "Reconstruction: 0.158827, Regularization: 0.005917\n",
      "2019-04-10 01:04:33,250 root         INFO     ====> Epoch: 193 Average loss: 0.1651\n",
      "2019-04-10 01:04:33,274 root         INFO     Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 0.164222\n",
      "Reconstruction: 0.160126, Regularization: 0.004097\n",
      "2019-04-10 01:04:33,339 root         INFO     Train Epoch: 194 [512/8000 (6%)]\tTotal Loss: 0.169188\n",
      "Reconstruction: 0.164455, Regularization: 0.004733\n",
      "2019-04-10 01:04:33,403 root         INFO     Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 0.159910\n",
      "Reconstruction: 0.154638, Regularization: 0.005272\n",
      "2019-04-10 01:04:33,465 root         INFO     Train Epoch: 194 [1536/8000 (19%)]\tTotal Loss: 0.170057\n",
      "Reconstruction: 0.164912, Regularization: 0.005145\n",
      "2019-04-10 01:04:33,528 root         INFO     Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 0.168549\n",
      "Reconstruction: 0.162026, Regularization: 0.006522\n",
      "2019-04-10 01:04:33,591 root         INFO     Train Epoch: 194 [2560/8000 (32%)]\tTotal Loss: 0.153159\n",
      "Reconstruction: 0.149143, Regularization: 0.004017\n",
      "2019-04-10 01:04:33,653 root         INFO     Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 0.161840\n",
      "Reconstruction: 0.157484, Regularization: 0.004355\n",
      "2019-04-10 01:04:33,716 root         INFO     Train Epoch: 194 [3584/8000 (45%)]\tTotal Loss: 0.166098\n",
      "Reconstruction: 0.161352, Regularization: 0.004747\n",
      "2019-04-10 01:04:33,778 root         INFO     Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 0.175576\n",
      "Reconstruction: 0.169217, Regularization: 0.006359\n",
      "2019-04-10 01:04:33,841 root         INFO     Train Epoch: 194 [4608/8000 (58%)]\tTotal Loss: 0.175094\n",
      "Reconstruction: 0.169625, Regularization: 0.005469\n",
      "2019-04-10 01:04:33,905 root         INFO     Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 0.162748\n",
      "Reconstruction: 0.159002, Regularization: 0.003746\n",
      "2019-04-10 01:04:33,969 root         INFO     Train Epoch: 194 [5632/8000 (70%)]\tTotal Loss: 0.169408\n",
      "Reconstruction: 0.163692, Regularization: 0.005716\n",
      "2019-04-10 01:04:34,033 root         INFO     Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 0.166466\n",
      "Reconstruction: 0.160341, Regularization: 0.006126\n",
      "2019-04-10 01:04:34,097 root         INFO     Train Epoch: 194 [6656/8000 (83%)]\tTotal Loss: 0.171390\n",
      "Reconstruction: 0.165001, Regularization: 0.006388\n",
      "2019-04-10 01:04:34,159 root         INFO     Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 0.165365\n",
      "Reconstruction: 0.161315, Regularization: 0.004049\n",
      "2019-04-10 01:04:34,222 root         INFO     Train Epoch: 194 [7680/8000 (96%)]\tTotal Loss: 0.170794\n",
      "Reconstruction: 0.165144, Regularization: 0.005650\n",
      "2019-04-10 01:04:34,275 root         INFO     ====> Epoch: 194 Average loss: 0.1651\n",
      "2019-04-10 01:04:34,299 root         INFO     Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 0.158780\n",
      "Reconstruction: 0.153895, Regularization: 0.004885\n",
      "2019-04-10 01:04:34,363 root         INFO     Train Epoch: 195 [512/8000 (6%)]\tTotal Loss: 0.150742\n",
      "Reconstruction: 0.147745, Regularization: 0.002997\n",
      "2019-04-10 01:04:34,427 root         INFO     Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 0.153857\n",
      "Reconstruction: 0.150665, Regularization: 0.003192\n",
      "2019-04-10 01:04:34,491 root         INFO     Train Epoch: 195 [1536/8000 (19%)]\tTotal Loss: 0.164963\n",
      "Reconstruction: 0.159871, Regularization: 0.005092\n",
      "2019-04-10 01:04:34,554 root         INFO     Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 0.165204\n",
      "Reconstruction: 0.160087, Regularization: 0.005117\n",
      "2019-04-10 01:04:34,616 root         INFO     Train Epoch: 195 [2560/8000 (32%)]\tTotal Loss: 0.185296\n",
      "Reconstruction: 0.176942, Regularization: 0.008353\n",
      "2019-04-10 01:04:34,678 root         INFO     Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 0.181849\n",
      "Reconstruction: 0.175040, Regularization: 0.006810\n",
      "2019-04-10 01:04:34,741 root         INFO     Train Epoch: 195 [3584/8000 (45%)]\tTotal Loss: 0.160213\n",
      "Reconstruction: 0.155700, Regularization: 0.004513\n",
      "2019-04-10 01:04:34,803 root         INFO     Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 0.164597\n",
      "Reconstruction: 0.159253, Regularization: 0.005344\n",
      "2019-04-10 01:04:34,865 root         INFO     Train Epoch: 195 [4608/8000 (58%)]\tTotal Loss: 0.157532\n",
      "Reconstruction: 0.153429, Regularization: 0.004104\n",
      "2019-04-10 01:04:34,928 root         INFO     Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 0.164498\n",
      "Reconstruction: 0.159518, Regularization: 0.004980\n",
      "2019-04-10 01:04:34,990 root         INFO     Train Epoch: 195 [5632/8000 (70%)]\tTotal Loss: 0.178387\n",
      "Reconstruction: 0.171510, Regularization: 0.006878\n",
      "2019-04-10 01:04:35,053 root         INFO     Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 0.177821\n",
      "Reconstruction: 0.171114, Regularization: 0.006707\n",
      "2019-04-10 01:04:35,115 root         INFO     Train Epoch: 195 [6656/8000 (83%)]\tTotal Loss: 0.160022\n",
      "Reconstruction: 0.155350, Regularization: 0.004672\n",
      "2019-04-10 01:04:35,177 root         INFO     Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 0.164380\n",
      "Reconstruction: 0.159079, Regularization: 0.005301\n",
      "2019-04-10 01:04:35,239 root         INFO     Train Epoch: 195 [7680/8000 (96%)]\tTotal Loss: 0.152942\n",
      "Reconstruction: 0.148906, Regularization: 0.004035\n",
      "2019-04-10 01:04:35,294 root         INFO     ====> Epoch: 195 Average loss: 0.1651\n",
      "2019-04-10 01:04:35,318 root         INFO     Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 0.164924\n",
      "Reconstruction: 0.159593, Regularization: 0.005331\n",
      "2019-04-10 01:04:35,381 root         INFO     Train Epoch: 196 [512/8000 (6%)]\tTotal Loss: 0.167195\n",
      "Reconstruction: 0.161291, Regularization: 0.005904\n",
      "2019-04-10 01:04:35,444 root         INFO     Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 0.159439\n",
      "Reconstruction: 0.155230, Regularization: 0.004209\n",
      "2019-04-10 01:04:35,507 root         INFO     Train Epoch: 196 [1536/8000 (19%)]\tTotal Loss: 0.151834\n",
      "Reconstruction: 0.148208, Regularization: 0.003626\n",
      "2019-04-10 01:04:35,568 root         INFO     Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 0.172270\n",
      "Reconstruction: 0.166097, Regularization: 0.006173\n",
      "2019-04-10 01:04:35,629 root         INFO     Train Epoch: 196 [2560/8000 (32%)]\tTotal Loss: 0.166176\n",
      "Reconstruction: 0.160043, Regularization: 0.006133\n",
      "2019-04-10 01:04:35,690 root         INFO     Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 0.160342\n",
      "Reconstruction: 0.155892, Regularization: 0.004450\n",
      "2019-04-10 01:04:35,752 root         INFO     Train Epoch: 196 [3584/8000 (45%)]\tTotal Loss: 0.163155\n",
      "Reconstruction: 0.157458, Regularization: 0.005697\n",
      "2019-04-10 01:04:35,813 root         INFO     Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 0.173632\n",
      "Reconstruction: 0.167695, Regularization: 0.005937\n",
      "2019-04-10 01:04:35,874 root         INFO     Train Epoch: 196 [4608/8000 (58%)]\tTotal Loss: 0.162955\n",
      "Reconstruction: 0.157675, Regularization: 0.005280\n",
      "2019-04-10 01:04:35,935 root         INFO     Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 0.175552\n",
      "Reconstruction: 0.170447, Regularization: 0.005105\n",
      "2019-04-10 01:04:35,996 root         INFO     Train Epoch: 196 [5632/8000 (70%)]\tTotal Loss: 0.162099\n",
      "Reconstruction: 0.158360, Regularization: 0.003739\n",
      "2019-04-10 01:04:36,057 root         INFO     Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 0.167176\n",
      "Reconstruction: 0.161676, Regularization: 0.005500\n",
      "2019-04-10 01:04:36,118 root         INFO     Train Epoch: 196 [6656/8000 (83%)]\tTotal Loss: 0.170026\n",
      "Reconstruction: 0.164887, Regularization: 0.005140\n",
      "2019-04-10 01:04:36,179 root         INFO     Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 0.162749\n",
      "Reconstruction: 0.158049, Regularization: 0.004701\n",
      "2019-04-10 01:04:36,239 root         INFO     Train Epoch: 196 [7680/8000 (96%)]\tTotal Loss: 0.163577\n",
      "Reconstruction: 0.158371, Regularization: 0.005206\n",
      "2019-04-10 01:04:36,293 root         INFO     ====> Epoch: 196 Average loss: 0.1645\n",
      "2019-04-10 01:04:36,317 root         INFO     Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 0.155766\n",
      "Reconstruction: 0.151480, Regularization: 0.004286\n",
      "2019-04-10 01:04:36,379 root         INFO     Train Epoch: 197 [512/8000 (6%)]\tTotal Loss: 0.165139\n",
      "Reconstruction: 0.160654, Regularization: 0.004485\n",
      "2019-04-10 01:04:36,440 root         INFO     Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 0.154451\n",
      "Reconstruction: 0.150284, Regularization: 0.004167\n",
      "2019-04-10 01:04:36,501 root         INFO     Train Epoch: 197 [1536/8000 (19%)]\tTotal Loss: 0.171838\n",
      "Reconstruction: 0.165302, Regularization: 0.006536\n",
      "2019-04-10 01:04:36,562 root         INFO     Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 0.189948\n",
      "Reconstruction: 0.182750, Regularization: 0.007198\n",
      "2019-04-10 01:04:36,623 root         INFO     Train Epoch: 197 [2560/8000 (32%)]\tTotal Loss: 0.163480\n",
      "Reconstruction: 0.158144, Regularization: 0.005336\n",
      "2019-04-10 01:04:36,683 root         INFO     Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 0.160743\n",
      "Reconstruction: 0.155936, Regularization: 0.004807\n",
      "2019-04-10 01:04:36,744 root         INFO     Train Epoch: 197 [3584/8000 (45%)]\tTotal Loss: 0.152999\n",
      "Reconstruction: 0.148984, Regularization: 0.004015\n",
      "2019-04-10 01:04:36,805 root         INFO     Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 0.163837\n",
      "Reconstruction: 0.157294, Regularization: 0.006543\n",
      "2019-04-10 01:04:36,866 root         INFO     Train Epoch: 197 [4608/8000 (58%)]\tTotal Loss: 0.178404\n",
      "Reconstruction: 0.171986, Regularization: 0.006418\n",
      "2019-04-10 01:04:36,927 root         INFO     Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 0.174585\n",
      "Reconstruction: 0.168406, Regularization: 0.006179\n",
      "2019-04-10 01:04:36,988 root         INFO     Train Epoch: 197 [5632/8000 (70%)]\tTotal Loss: 0.169957\n",
      "Reconstruction: 0.164840, Regularization: 0.005117\n",
      "2019-04-10 01:04:37,049 root         INFO     Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 0.174026\n",
      "Reconstruction: 0.167706, Regularization: 0.006320\n",
      "2019-04-10 01:04:37,110 root         INFO     Train Epoch: 197 [6656/8000 (83%)]\tTotal Loss: 0.168827\n",
      "Reconstruction: 0.162699, Regularization: 0.006128\n",
      "2019-04-10 01:04:37,171 root         INFO     Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 0.159146\n",
      "Reconstruction: 0.153649, Regularization: 0.005497\n",
      "2019-04-10 01:04:37,232 root         INFO     Train Epoch: 197 [7680/8000 (96%)]\tTotal Loss: 0.161565\n",
      "Reconstruction: 0.156454, Regularization: 0.005111\n",
      "2019-04-10 01:04:37,284 root         INFO     ====> Epoch: 197 Average loss: 0.1653\n",
      "2019-04-10 01:04:37,308 root         INFO     Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 0.155163\n",
      "Reconstruction: 0.151329, Regularization: 0.003834\n",
      "2019-04-10 01:04:37,371 root         INFO     Train Epoch: 198 [512/8000 (6%)]\tTotal Loss: 0.178288\n",
      "Reconstruction: 0.170497, Regularization: 0.007792\n",
      "2019-04-10 01:04:37,433 root         INFO     Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.165098\n",
      "Reconstruction: 0.158832, Regularization: 0.006266\n",
      "2019-04-10 01:04:37,495 root         INFO     Train Epoch: 198 [1536/8000 (19%)]\tTotal Loss: 0.179100\n",
      "Reconstruction: 0.170744, Regularization: 0.008356\n",
      "2019-04-10 01:04:37,558 root         INFO     Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 0.162743\n",
      "Reconstruction: 0.157717, Regularization: 0.005026\n",
      "2019-04-10 01:04:37,620 root         INFO     Train Epoch: 198 [2560/8000 (32%)]\tTotal Loss: 0.155373\n",
      "Reconstruction: 0.151289, Regularization: 0.004084\n",
      "2019-04-10 01:04:37,682 root         INFO     Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 0.160195\n",
      "Reconstruction: 0.155535, Regularization: 0.004661\n",
      "2019-04-10 01:04:37,744 root         INFO     Train Epoch: 198 [3584/8000 (45%)]\tTotal Loss: 0.151595\n",
      "Reconstruction: 0.148472, Regularization: 0.003123\n",
      "2019-04-10 01:04:37,806 root         INFO     Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 0.158357\n",
      "Reconstruction: 0.153980, Regularization: 0.004377\n",
      "2019-04-10 01:04:37,868 root         INFO     Train Epoch: 198 [4608/8000 (58%)]\tTotal Loss: 0.169071\n",
      "Reconstruction: 0.164171, Regularization: 0.004899\n",
      "2019-04-10 01:04:37,930 root         INFO     Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 0.160791\n",
      "Reconstruction: 0.155397, Regularization: 0.005394\n",
      "2019-04-10 01:04:37,992 root         INFO     Train Epoch: 198 [5632/8000 (70%)]\tTotal Loss: 0.163805\n",
      "Reconstruction: 0.158171, Regularization: 0.005634\n",
      "2019-04-10 01:04:38,054 root         INFO     Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 0.165662\n",
      "Reconstruction: 0.159411, Regularization: 0.006251\n",
      "2019-04-10 01:04:38,116 root         INFO     Train Epoch: 198 [6656/8000 (83%)]\tTotal Loss: 0.163834\n",
      "Reconstruction: 0.158267, Regularization: 0.005567\n",
      "2019-04-10 01:04:38,178 root         INFO     Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 0.159562\n",
      "Reconstruction: 0.154366, Regularization: 0.005196\n",
      "2019-04-10 01:04:38,240 root         INFO     Train Epoch: 198 [7680/8000 (96%)]\tTotal Loss: 0.168909\n",
      "Reconstruction: 0.163588, Regularization: 0.005321\n",
      "2019-04-10 01:04:38,294 root         INFO     ====> Epoch: 198 Average loss: 0.1648\n",
      "2019-04-10 01:04:38,318 root         INFO     Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 0.161376\n",
      "Reconstruction: 0.156285, Regularization: 0.005091\n",
      "2019-04-10 01:04:38,382 root         INFO     Train Epoch: 199 [512/8000 (6%)]\tTotal Loss: 0.155582\n",
      "Reconstruction: 0.151259, Regularization: 0.004323\n",
      "2019-04-10 01:04:38,444 root         INFO     Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 0.168156\n",
      "Reconstruction: 0.163479, Regularization: 0.004677\n",
      "2019-04-10 01:04:38,506 root         INFO     Train Epoch: 199 [1536/8000 (19%)]\tTotal Loss: 0.156807\n",
      "Reconstruction: 0.150862, Regularization: 0.005945\n",
      "2019-04-10 01:04:38,568 root         INFO     Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 0.172182\n",
      "Reconstruction: 0.166232, Regularization: 0.005950\n",
      "2019-04-10 01:04:38,631 root         INFO     Train Epoch: 199 [2560/8000 (32%)]\tTotal Loss: 0.160439\n",
      "Reconstruction: 0.154446, Regularization: 0.005993\n",
      "2019-04-10 01:04:38,693 root         INFO     Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 0.166677\n",
      "Reconstruction: 0.160925, Regularization: 0.005752\n",
      "2019-04-10 01:04:38,756 root         INFO     Train Epoch: 199 [3584/8000 (45%)]\tTotal Loss: 0.168685\n",
      "Reconstruction: 0.163071, Regularization: 0.005614\n",
      "2019-04-10 01:04:38,818 root         INFO     Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 0.171150\n",
      "Reconstruction: 0.164361, Regularization: 0.006789\n",
      "2019-04-10 01:04:38,881 root         INFO     Train Epoch: 199 [4608/8000 (58%)]\tTotal Loss: 0.172771\n",
      "Reconstruction: 0.167208, Regularization: 0.005563\n",
      "2019-04-10 01:04:38,944 root         INFO     Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 0.166585\n",
      "Reconstruction: 0.160556, Regularization: 0.006029\n",
      "2019-04-10 01:04:39,007 root         INFO     Train Epoch: 199 [5632/8000 (70%)]\tTotal Loss: 0.160459\n",
      "Reconstruction: 0.155750, Regularization: 0.004708\n",
      "2019-04-10 01:04:39,069 root         INFO     Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.166241\n",
      "Reconstruction: 0.160561, Regularization: 0.005680\n",
      "2019-04-10 01:04:39,132 root         INFO     Train Epoch: 199 [6656/8000 (83%)]\tTotal Loss: 0.158760\n",
      "Reconstruction: 0.154381, Regularization: 0.004379\n",
      "2019-04-10 01:04:39,195 root         INFO     Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 0.157624\n",
      "Reconstruction: 0.152652, Regularization: 0.004973\n",
      "2019-04-10 01:04:39,257 root         INFO     Train Epoch: 199 [7680/8000 (96%)]\tTotal Loss: 0.171986\n",
      "Reconstruction: 0.166482, Regularization: 0.005504\n",
      "2019-04-10 01:04:39,311 root         INFO     ====> Epoch: 199 Average loss: 0.1647\n",
      "2019-04-10 01:04:39,319 luigi-interface INFO     [pid 1925] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=1925) done      TrainVAE()\n",
      "2019-04-10 01:04:39,320 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-10 01:04:39,320 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   DONE\n",
      "2019-04-10 01:04:39,320 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-10 01:04:39,320 luigi-interface DEBUG    Pending tasks: 1\n",
      "2019-04-10 01:04:39,321 luigi-interface INFO     [pid 1925] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=1925) running   RunAll()\n",
      "2019-04-10 01:04:39,321 luigi-interface INFO     [pid 1925] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=1925) done      RunAll()\n",
      "2019-04-10 01:04:39,321 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-10 01:04:39,322 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   DONE\n",
      "2019-04-10 01:04:39,322 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-10 01:04:39,322 luigi-interface DEBUG    Done\n",
      "2019-04-10 01:04:39,322 luigi-interface DEBUG    There are no more tasks to run at this time\n",
      "2019-04-10 01:04:39,322 luigi-interface INFO     Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=1925) was stopped. Shutting down Keep-Alive thread\n",
      "2019-04-10 01:04:39,323 luigi-interface INFO     \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 4 tasks of which:\n",
      "* 4 ran successfully:\n",
      "    - 1 MakeDataSet()\n",
      "    - 1 RunAll()\n",
      "    - 1 TrainVAE()\n",
      "    - 1 TrainVEM()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pattern = 'logs'\n",
    "logs = []\n",
    "for filename in os.listdir(OUTPUT):\n",
    "    if re.search(pattern, filename):\n",
    "        logs.append(filename)\n",
    "\n",
    "print('Found %d log files.' % len(logs))\n",
    "        \n",
    "for filename in logs:\n",
    "    path = os.path.join(OUTPUT, filename)\n",
    "    print('\\n-- Log file: %s\\n' % filename)\n",
    "    with open(path, 'r') as f:\n",
    "        message = f.read()\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
