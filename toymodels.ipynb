{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "import sympy as sp\n",
    "\n",
    "import importlib\n",
    "import toylosses\n",
    "importlib.reload(toylosses)\n",
    "import toynn\n",
    "importlib.reload(toynn)\n",
    "import toyvis\n",
    "importlib.reload(toyvis)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as tnn\n",
    "from torch.nn import functional as F\n",
    "sns.set()\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mixture of FA / PPCA\n",
    "# Models parameters\n",
    "\n",
    "W = np.array([\n",
    "    [[2], [3]],  # W1\n",
    "    [[-1], [1]],  # W2\n",
    "    [[2], [1]]  # W3\n",
    "])\n",
    "\n",
    "mu = np.array([\n",
    "    [2, 3],  # mu1\n",
    "    [-1, 1],  # mu2\n",
    "    [2, 1]  # mu3\n",
    "])\n",
    "\n",
    "probabilities = np.array([0.1, 0.6, 0.3])\n",
    "# Sample latent variable, noise -> generate data\n",
    "n = 1000\n",
    "z = np.random.normal(size=(n, 1))\n",
    "s = 0.1\n",
    "eps = np.random.normal(loc=0, scale=s**2, size=(n, 2))  # PPCA because it is isotropic\n",
    "\n",
    "# Generative model\n",
    "c = np.random.choice([0, 1, 2], n, p=probabilities)\n",
    "\n",
    "mask = np.zeros((n, 3))\n",
    "for i in range(n): \n",
    "    mask[i] = c[i] == range(3)\n",
    "ws = np.einsum('nm, mij->nij', mask, W)\n",
    "mus = np.einsum('nm, mi->ni', mask, mu)\n",
    "x = np.einsum('nij,nj->ni', ws, z) \n",
    "x = x + mus + eps\n",
    "\n",
    "# Plot data\n",
    "plt.scatter(x[:, 0], x[:, 1])\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating synthetic data from 2D model: x = W^T z + mu + eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models parameters\n",
    "w1 = 2\n",
    "w2 = 3\n",
    "W = np.array([[w1], [w2]])\n",
    "mu1 = -1\n",
    "mu2 = 1\n",
    "mu = np.array([mu1, mu2])\n",
    "print(mu.shape)\n",
    "\n",
    "# Sample latent variable, noise -> generate data\n",
    "n = 100\n",
    "z = np.random.normal(size=(n, 1))\n",
    "print(z.shape)\n",
    "s = 0.1\n",
    "eps = np.random.normal(loc=0, scale=s**2, size=(n, 2))  # PPCA because it is isotropic\n",
    "print(eps.shape)\n",
    "\n",
    "# Generative model\n",
    "x = np.einsum('ij,nj->ni', W, z) + mu + eps\n",
    "x = np.maximum(x, 0)  # ReLu \n",
    "print(x.shape)\n",
    "# Plot data\n",
    "plt.scatter(x[:, 0], x[:, 1])\n",
    "plt.axis('equal')\n",
    "\n",
    "# Adding a second layer\n",
    "v1 = -4\n",
    "v2 = 7\n",
    "V = np.array([[v1], [v2]])\n",
    "m1 = 3\n",
    "m2 = 5\n",
    "m = np.array([m1, m2])\n",
    "print(mu.shape)\n",
    "\n",
    "# Generative model\n",
    "h = np.einsum('ij,nj->ni', W, z) + mu\n",
    "h = np.maximum(h, 0)  # ReLu \n",
    "eps = np.random.normal(loc=0, scale=s**2, size=(n, 2))  # PPCA because it is isotropic\n",
    "x = np.einsum('ij,nj->ni', V, h) + m + eps\n",
    "x = np.maximum(x, 0)  # ReLu \n",
    "print(x.shape)\n",
    "# Plot data\n",
    "plt.figure()\n",
    "plt.scatter(x[:, 0], x[:, 1])\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate synthetic data from a VAE's decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of parameters for the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_true = {}\n",
    "b_true = {}\n",
    "\n",
    "w_true[0] = [[1.], [1.]]\n",
    "b_true[0] = [0., -1.]\n",
    "\n",
    "# For the reconstruction\n",
    "w_true[1] = [[2., 1.], [-1., 2.]]\n",
    "b_true[1] = [0., 0.]\n",
    "\n",
    "# For the scale\n",
    "w_true[2] = [[1., -1.], [0., 1.]]\n",
    "b_true[2] = [0., 0.]\n",
    "\n",
    "\n",
    "## Parameters 1\n",
    "\n",
    "w_true = {}\n",
    "b_true = {}\n",
    "\n",
    "# For the reconstruction\n",
    "w_true[0] = [[4.], [4.]]\n",
    "b_true[0] = [0., -0.]\n",
    "\n",
    "# For the scale\n",
    "w_true[1] = [[-0.], [-0.]]\n",
    "b_true[1] = [0., -0.]\n",
    "\n",
    "\n",
    "## Parameters 2\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "data_dim = 1\n",
    "latent_dim = 1\n",
    "n_layers = 1\n",
    "nonlinearity = False\n",
    "n_samples = 10000\n",
    "with_biasx = False\n",
    "with_logvarx = False\n",
    "\n",
    "w_true = {}\n",
    "b_true = {}\n",
    "\n",
    "# For the reconstruction\n",
    "w_true[0] = [[2.]]\n",
    "if with_biasx:\n",
    "    b_true[0] = [[0.]]\n",
    "\n",
    "if with_logvarx:\n",
    "    # For the scale\n",
    "    w_true[1] = [[0.]]\n",
    "    b_true[1] = [[0.]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight tensor([[2.]], device='cuda:0') \n",
      "\n",
      "Covariance matrix from decoder:\n",
      "4.925015160331548\n",
      "Covariance matrix from synthetic:\n",
      "5.016637077188237\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DEVICE = 'cuda'\n",
    "\n",
    "data_dim = 1\n",
    "latent_dim = 1\n",
    "n_layers = 1\n",
    "nonlinearity = False\n",
    "n_samples = 10000\n",
    "with_biasx = False\n",
    "with_logvarx = False\n",
    "\n",
    "w_true = {}\n",
    "b_true = {}\n",
    "\n",
    "# For the reconstruction\n",
    "w_true[0] = [[2.]]\n",
    "if with_biasx:\n",
    "    b_true[0] = [[0.]]\n",
    "\n",
    "if with_logvarx:\n",
    "    # For the scale\n",
    "    w_true[1] = [[0.]]\n",
    "    b_true[1] = [[0.]]\n",
    "\n",
    "decoder_true = toynn.make_decoder_true(\n",
    "    w_true, b_true, latent_dim, data_dim, n_layers,\n",
    "    nonlinearity, with_biasx, with_logvarx)\n",
    "\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "\n",
    "w_true = 2\n",
    "color_true = 'green'\n",
    "def generate_synthetic_1d(w=w_true, n=10):\n",
    "    z = np.random.normal(loc=0, scale=1, size=(n, 1))\n",
    "    eps = np.random.normal(loc=0, scale=1, size=(n, 1))\n",
    "\n",
    "    x = w * z + eps\n",
    "    return z, x\n",
    "\n",
    "generated_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "_, synthetic_x = generate_synthetic_1d(w=w_true, n=n_samples)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = toyvis.plot_data(generated_x, color='green', label='from decoder true', ax=ax)\n",
    "ax = toyvis.plot_data(synthetic_x, color='green', label='from synthetic true', ax=ax)\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "print('Covariance matrix from decoder:')\n",
    "cov = np.cov(generated_x.T)\n",
    "print(cov)\n",
    "\n",
    "print('Covariance matrix from synthetic:')\n",
    "cov = np.cov(synthetic_x.T)\n",
    "print(cov)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a VAE to learn the decoder's distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAC_TEST = 0.2\n",
    "n_train = int((1 - FRAC_TEST) * n_samples)\n",
    "BATCH_SIZE = 64\n",
    "CUDA = torch.cuda.is_available()\n",
    "KWARGS = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n",
    "\n",
    "train = torch.Tensor(generated_x[:n_train, :])\n",
    "test = torch.Tensor(generated_x[n_train: , :])\n",
    "\n",
    "logging.info('-- Train tensor: (%d, %d)' % train.shape)\n",
    "train_dataset = torch.utils.data.TensorDataset(train)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, **KWARGS)\n",
    "\n",
    "logging.info('-- Test tensor: (%d, %d)' % test.shape)\n",
    "test_dataset = torch.utils.data.TensorDataset(test)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, **KWARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the unregularized VAE:\n",
    "\n",
    "\\begin{align*}\n",
    "    L_{ELBO} \n",
    "  = L_{UVAE} - KL_{prior}(\\phi) \n",
    "  = \\mathbb{E}_{p_{data}(x)}\\left[ \\mathbb{E}_{q_\\phi(z|x)} \\left[\\log p_\\theta(x|z)\\right] - KL\\left(q_\\phi(z|x) || p(z)\\right) \\right] \n",
    "\\end{align*}\n",
    "\n",
    "Where the $\\mathbb{E}$ is taken over the batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111 tensor(9.6517, device='cuda:0')\n",
      "2222 tensor(9.6517, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "b_data = torch.Tensor(np.array([[0., 0., 0.], [0., 0., 0.]])).to(DEVICE)\n",
    "b_recon = torch.Tensor(np.array([[2., 2., 2.], [3., 3., 3.]])).to(DEVICE)\n",
    "\n",
    "b_logvarx = torch.Tensor(np.array([[np.log(1.)], [np.log(2.)]])).to(DEVICE)\n",
    "print('1111', toylosses.reconstruction_loss(b_data, b_recon, b_logvarx))\n",
    "\n",
    "#expected_ssd = tensor([12., 27.])\n",
    "#expected_ssd_term = tensor([-6.0000, -6.7500])\n",
    "\n",
    "b_data = torch.Tensor(np.array([[0., 0., 0.], [0., 0., 0.]])).to(DEVICE)\n",
    "b_recon = torch.Tensor(np.array([[2., 2., 2.], [3., 3., 3.]])).to(DEVICE)\n",
    "\n",
    "b_logvarx = torch.Tensor(\n",
    "    np.array(\n",
    "        [[np.log(1.), np.log(1.), np.log(1.)], \n",
    "         [np.log(2.), np.log(2.), np.log(2.)]])).to(DEVICE)\n",
    "print('2222', toylosses.reconstruction_loss(b_data, b_recon, b_logvarx))\n",
    "#1111 tensor(9.6517, device='cuda:0')\n",
    "#2222 tensor(9.6517, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "PRINT_INTERVAL = 16\n",
    "\n",
    "def toytrain_vae(epoch, train_loader, modules, optimizers):\n",
    "    for module in modules.values():\n",
    "        module.train()\n",
    "    total_loss_reconstruction = 0\n",
    "    total_loss_regularization = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    n_data = len(train_loader.dataset)\n",
    "    n_batches = len(train_loader)\n",
    "    \n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        if DEBUG:\n",
    "            if batch_idx > 3:\n",
    "                continue\n",
    "        \n",
    "        batch_data = batch_data[0].to(DEVICE)\n",
    "        n_batch_data = len(batch_data)\n",
    "        \n",
    "        for optimizer in optimizers.values():\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        encoder = modules['encoder']\n",
    "        decoder = modules['decoder']\n",
    "        \n",
    "        mu, logvar = encoder(batch_data)\n",
    "        \n",
    "        z = toynn.sample_from_q(mu, logvar).to(DEVICE)\n",
    "        batch_recon, batch_logvarx = decoder(z)\n",
    "        \n",
    "        z_from_prior = toynn.sample_from_prior(\n",
    "                latent_dim, n_samples=n_batch_data).to(DEVICE)\n",
    "        batch_from_prior, scale_b_from_prior = decoder(\n",
    "                z_from_prior)\n",
    "        \n",
    "        loss_reconstruction = toylosses.reconstruction_loss(batch_data, batch_recon, batch_logvarx)\n",
    "        loss_reconstruction.backward(retain_graph=True)\n",
    "        loss_regularization = toylosses.regularization_loss(mu, logvar)  # kld\n",
    "        loss_regularization.backward()\n",
    "           \n",
    "        optimizers['encoder'].step()\n",
    "        optimizers['decoder'].step()            \n",
    "        \n",
    "        loss = loss_reconstruction + loss_regularization\n",
    "        \n",
    "        if batch_idx % PRINT_INTERVAL == 0:\n",
    "            logloss = loss / n_batch_data\n",
    "            logloss_reconstruction = loss_reconstruction / n_batch_data\n",
    "            logloss_regularization = loss_regularization / n_batch_data\n",
    "            \n",
    "            string_base = ('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTotal Loss: {:.6f}'\n",
    "                       + '\\nReconstruction: {:.6f}, Regularization: {:.6f}')\n",
    "            print(\n",
    "                string_base.format(\n",
    "                    epoch, batch_idx * n_batch_data, n_data,\n",
    "                    100. * batch_idx / n_batches,\n",
    "                    logloss, logloss_reconstruction, logloss_regularization))\n",
    "            \n",
    "        total_loss_reconstruction += loss_reconstruction.item()\n",
    "        total_loss_regularization += loss_regularization.item()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    \n",
    "    average_loss_reconstruction = total_loss_reconstruction / n_data\n",
    "    average_loss_regularization = total_loss_regularization / n_data\n",
    "    average_loss = total_loss / n_data\n",
    "    \n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "            epoch, average_loss))\n",
    "    train_losses = {}\n",
    "    train_losses['reconstruction'] = average_loss_reconstruction\n",
    "    train_losses['regularization'] = average_loss_regularization\n",
    "    train_losses['total'] = average_loss\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by modifying the VAE criterion and integrating GANs, we can provide a NN implementation of the variational EM.\n",
    "\n",
    "- Send a batch through the VAE\n",
    "- Compute the VAE loss: the reconstruction error and the regularization\n",
    "- back propagate through the entire VAE\n",
    "- update only the encoder: this will update it wrt to the -KL( || posterior), this is the E step of the variational EM.\n",
    "- Generate N data Z from the prior\n",
    "- Propagate through the decoder\n",
    "- Use a GAN to distinguish the distribution in $\\tilde x$ from N data from the true distribution: generate ONE sample Z, and ask the discriminator.\n",
    "- back propagate this through the decoder\n",
    "- update the decoder w.r.t. only this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toytrain_vem(epoch, train_loader, modules, optimizers):\n",
    "    for module in modules.values():\n",
    "        module.train()\n",
    "    total_loss_reconstruction = 0\n",
    "    total_loss_regularization = 0\n",
    "    total_loss_discriminator = 0\n",
    "    total_loss_generator = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    n_data = len(train_loader.dataset)\n",
    "    n_batches = len(train_loader)\n",
    "    \n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        if DEBUG:\n",
    "            if batch_idx > 3:\n",
    "                continue\n",
    "        \n",
    "        batch_data = batch_data[0].to(DEVICE)\n",
    "        n_batch_data = len(batch_data)\n",
    "        \n",
    "        for optimizer in optimizers.values():\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        encoder = modules['encoder']\n",
    "        decoder = modules['decoder']\n",
    "        \n",
    "        mu, logvar = encoder(batch_data)\n",
    "        \n",
    "        z = toynn.sample_from_q(\n",
    "                mu, logvar).to(DEVICE)\n",
    "        batch_recon, batch_logvarx = decoder(z)\n",
    "        \n",
    "        z_from_prior = toynn.sample_from_prior(\n",
    "                latent_dim, n_samples=n_batch_data).to(DEVICE)\n",
    "        batch_from_prior, batch_logvarx_from_prior = decoder(\n",
    "                z_from_prior)\n",
    "        \n",
    "        loss_reconstruction = toylosses.reconstruction_loss(batch_data, batch_recon, batch_logvarx)\n",
    "        loss_reconstruction.backward(retain_graph=True)\n",
    "        loss_regularization = toylosses.regularization_loss(mu, logvar)  # kld\n",
    "        loss_regularization.backward()\n",
    "        \n",
    "        ## - ENCODER STEP -\n",
    "        optimizers['encoder'].step()\n",
    "        ## - - - - - - - - -\n",
    "        \n",
    "        n_from_prior = int(np.random.uniform(\n",
    "            low=n_batch_data - n_batch_data / 4, \n",
    "            high=n_batch_data + n_batch_data / 4))\n",
    "        z_from_prior = toynn.sample_from_prior(latent_dim, n_samples=n_from_prior)\n",
    "        batch_recon_from_prior, batch_logvarx_from_prior = decoder(z_from_prior)\n",
    "            \n",
    "        discriminator = modules['discriminator']\n",
    "        \n",
    "        real_labels = torch.full((n_batch_data, 1), 1, device=DEVICE)\n",
    "        fake_labels = torch.full((n_batch_data, 1), 0, device=DEVICE)\n",
    "        \n",
    "        # -- Update Discriminator\n",
    "        labels_data = discriminator(batch_data)\n",
    "        labels_from_prior = discriminator(batch_from_prior)  #.detach())\n",
    "\n",
    "        loss_dis_data = F.binary_cross_entropy(\n",
    "                    labels_data,\n",
    "                    real_labels)\n",
    "        loss_dis_from_prior = F.binary_cross_entropy(\n",
    "                    labels_from_prior,\n",
    "                    fake_labels)\n",
    "\n",
    "        loss_discriminator = (\n",
    "                loss_dis_data + loss_dis_from_prior)\n",
    "\n",
    "        # Fill gradients on discriminator only\n",
    "        loss_discriminator.backward(retain_graph=True)\n",
    "        \n",
    "        ## - DISCRIMINATOR STEP -\n",
    "        # Before filing with gradient of loss_generator\n",
    "        optimizers['discriminator'].step()\n",
    "        ## - - - - - - - - -\n",
    "\n",
    "        # -- Update Generator/Decoder\n",
    "        loss_generator = F.binary_cross_entropy(\n",
    "                labels_from_prior,\n",
    "                real_labels)\n",
    "\n",
    "        # Fill gradients on generator only\n",
    "        # FREE THE DECODER:\n",
    "        optimizers['decoder'].zero_grad()\n",
    "        # Only back propagate the loss of the generator through the deocder\n",
    "        loss_generator.backward()       \n",
    "            \n",
    "        ## - DECODER STEP -\n",
    "        optimizers['decoder'].step()\n",
    "        ## - - - - - - - - -\n",
    "\n",
    "        loss = loss_reconstruction + loss_regularization\n",
    "        loss += loss_discriminator + loss_generator     \n",
    "        \n",
    "        if batch_idx % PRINT_INTERVAL == 0:\n",
    "            average_batch_loss = loss / n_batch_data\n",
    "            average_batch_loss_reconstruction = loss_reconstruction / n_batch_data\n",
    "            average_batch_loss_regularization = loss_regularization / n_batch_data\n",
    "            average_batch_loss_discriminator = loss_discriminator / n_batch_data\n",
    "            average_batch_loss_generator = loss_generator / n_batch_data\n",
    "            \n",
    "            dx = labels_data.mean()\n",
    "            dgz = labels_from_prior.mean()\n",
    "            \n",
    "            string_base = ('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTotal Loss: {:.6f}'\n",
    "                       + '\\nReconstruction: {:.6f}, Regularization: {:.6f}')\n",
    "            string_base += (\n",
    "                ', Discriminator: {:.6f}; Generator: {:.6f},'\n",
    "                '\\nD(x): {:.3f}, D(G(z)): {:.3f}')\n",
    "            print(\n",
    "                string_base.format(\n",
    "                    epoch, batch_idx * n_batch_data, n_data,\n",
    "                    100. * batch_idx / n_batches,\n",
    "                    average_batch_loss,\n",
    "                    average_batch_loss_reconstruction, \n",
    "                    average_batch_loss_regularization,\n",
    "                    average_batch_loss_discriminator,\n",
    "                    average_batch_loss_generator,\n",
    "                    dx, dgz))\n",
    "            \n",
    "        total_loss_reconstruction += loss_reconstruction.item()\n",
    "        total_loss_regularization += loss_regularization.item()\n",
    "        total_loss_discriminator += loss_discriminator.item()\n",
    "        total_loss_generator += loss_generator.item()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    average_loss_reconstruction = total_loss_reconstruction / n_data\n",
    "    average_loss_regularization = total_loss_regularization / n_data\n",
    "    average_loss = total_loss / n_data\n",
    "    \n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "            epoch, average_loss))\n",
    "    train_losses = {}\n",
    "    train_losses['reconstruction'] = average_loss_reconstruction\n",
    "    train_losses['regularization'] = average_loss_regularization\n",
    "    train_losses['total'] = average_loss\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Values of parameters before learning\n",
      "layers.0.weight tensor([[-0.7359]], device='cuda:0') \n",
      "\n",
      "Error of layer type. <class 'toynn.Encoder'>\n",
      "Error of layer type. <class 'torch.nn.modules.activation.ReLU'>\n",
      "Error of layer type. <class 'torch.nn.modules.container.ModuleList'>\n",
      "Error of layer type. <class 'toynn.Decoder'>\n",
      "Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 0.088081\n",
      "Reconstruction: 0.030505, Regularization: 0.057577\n",
      "Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 0.093865\n",
      "Reconstruction: 0.030928, Regularization: 0.062937\n",
      "Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 0.124084\n",
      "Reconstruction: 0.037811, Regularization: 0.086272\n",
      "Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 0.145185\n",
      "Reconstruction: 0.041680, Regularization: 0.103505\n",
      "Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 0.093742\n",
      "Reconstruction: 0.031520, Regularization: 0.062222\n",
      "Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 0.100848\n",
      "Reconstruction: 0.032520, Regularization: 0.068328\n",
      "Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 0.077221\n",
      "Reconstruction: 0.028146, Regularization: 0.049075\n",
      "Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 0.097113\n",
      "Reconstruction: 0.031269, Regularization: 0.065844\n",
      "====> Epoch: 0 Average loss: 0.1070\n",
      "Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 0.121762\n",
      "Reconstruction: 0.036198, Regularization: 0.085564\n",
      "Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 0.086862\n",
      "Reconstruction: 0.029396, Regularization: 0.057467\n",
      "Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 0.110288\n",
      "Reconstruction: 0.034719, Regularization: 0.075569\n",
      "Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 0.074128\n",
      "Reconstruction: 0.027513, Regularization: 0.046615\n",
      "Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 0.128923\n",
      "Reconstruction: 0.038320, Regularization: 0.090604\n",
      "Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 0.100341\n",
      "Reconstruction: 0.032934, Regularization: 0.067407\n",
      "Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 0.088264\n",
      "Reconstruction: 0.029838, Regularization: 0.058426\n",
      "Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 0.107042\n",
      "Reconstruction: 0.033752, Regularization: 0.073290\n",
      "====> Epoch: 1 Average loss: 0.1050\n",
      "Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 0.084574\n",
      "Reconstruction: 0.029256, Regularization: 0.055318\n",
      "Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 0.075837\n",
      "Reconstruction: 0.027514, Regularization: 0.048323\n",
      "Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 0.108159\n",
      "Reconstruction: 0.033945, Regularization: 0.074214\n",
      "Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 0.101986\n",
      "Reconstruction: 0.033884, Regularization: 0.068102\n",
      "Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 0.110169\n",
      "Reconstruction: 0.034531, Regularization: 0.075638\n",
      "Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 0.140510\n",
      "Reconstruction: 0.039793, Regularization: 0.100717\n",
      "Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 0.082714\n",
      "Reconstruction: 0.028416, Regularization: 0.054298\n",
      "Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 0.121530\n",
      "Reconstruction: 0.036666, Regularization: 0.084865\n",
      "====> Epoch: 2 Average loss: 0.1030\n",
      "Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 0.109988\n",
      "Reconstruction: 0.033971, Regularization: 0.076017\n",
      "Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 0.093498\n",
      "Reconstruction: 0.031591, Regularization: 0.061908\n",
      "Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 0.102888\n",
      "Reconstruction: 0.031987, Regularization: 0.070901\n",
      "Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 0.086885\n",
      "Reconstruction: 0.029406, Regularization: 0.057479\n",
      "Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 0.100192\n",
      "Reconstruction: 0.032576, Regularization: 0.067616\n",
      "Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 0.114277\n",
      "Reconstruction: 0.034264, Regularization: 0.080013\n",
      "Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 0.109433\n",
      "Reconstruction: 0.034154, Regularization: 0.075280\n",
      "Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 0.092723\n",
      "Reconstruction: 0.030787, Regularization: 0.061936\n",
      "====> Epoch: 3 Average loss: 0.1012\n",
      "Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 0.099030\n",
      "Reconstruction: 0.030674, Regularization: 0.068356\n",
      "Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 0.091673\n",
      "Reconstruction: 0.029565, Regularization: 0.062107\n",
      "Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 0.103557\n",
      "Reconstruction: 0.032950, Regularization: 0.070607\n",
      "Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 0.118419\n",
      "Reconstruction: 0.035623, Regularization: 0.082796\n",
      "Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 0.073757\n",
      "Reconstruction: 0.026915, Regularization: 0.046841\n",
      "Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 0.119832\n",
      "Reconstruction: 0.035490, Regularization: 0.084341\n",
      "Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 0.105426\n",
      "Reconstruction: 0.031829, Regularization: 0.073597\n",
      "Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 0.102470\n",
      "Reconstruction: 0.031764, Regularization: 0.070706\n",
      "====> Epoch: 4 Average loss: 0.0993\n",
      "Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 0.092673\n",
      "Reconstruction: 0.031023, Regularization: 0.061650\n",
      "Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 0.102868\n",
      "Reconstruction: 0.031904, Regularization: 0.070963\n",
      "Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 0.097880\n",
      "Reconstruction: 0.030984, Regularization: 0.066896\n",
      "Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 0.089482\n",
      "Reconstruction: 0.030262, Regularization: 0.059220\n",
      "Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 0.087561\n",
      "Reconstruction: 0.030233, Regularization: 0.057327\n",
      "Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 0.071919\n",
      "Reconstruction: 0.026405, Regularization: 0.045514\n",
      "Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 0.097893\n",
      "Reconstruction: 0.031716, Regularization: 0.066177\n",
      "Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 0.090996\n",
      "Reconstruction: 0.029193, Regularization: 0.061803\n",
      "====> Epoch: 5 Average loss: 0.0976\n",
      "Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 0.090007\n",
      "Reconstruction: 0.029728, Regularization: 0.060279\n",
      "Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 0.093296\n",
      "Reconstruction: 0.029506, Regularization: 0.063790\n",
      "Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 0.121564\n",
      "Reconstruction: 0.035927, Regularization: 0.085637\n",
      "Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 0.096707\n",
      "Reconstruction: 0.030088, Regularization: 0.066619\n",
      "Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 0.081455\n",
      "Reconstruction: 0.027920, Regularization: 0.053534\n",
      "Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 0.101885\n",
      "Reconstruction: 0.031762, Regularization: 0.070122\n",
      "Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 0.097679\n",
      "Reconstruction: 0.031734, Regularization: 0.065945\n",
      "Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 0.132615\n",
      "Reconstruction: 0.037045, Regularization: 0.095570\n",
      "====> Epoch: 6 Average loss: 0.0958\n",
      "Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 0.067358\n",
      "Reconstruction: 0.024586, Regularization: 0.042772\n",
      "Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 0.108834\n",
      "Reconstruction: 0.033921, Regularization: 0.074913\n",
      "Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 0.109185\n",
      "Reconstruction: 0.032325, Regularization: 0.076860\n",
      "Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 0.093196\n",
      "Reconstruction: 0.029661, Regularization: 0.063535\n",
      "Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 0.088262\n",
      "Reconstruction: 0.028576, Regularization: 0.059686\n",
      "Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 0.093157\n",
      "Reconstruction: 0.028972, Regularization: 0.064185\n",
      "Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 0.094353\n",
      "Reconstruction: 0.028881, Regularization: 0.065472\n",
      "Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 0.091767\n",
      "Reconstruction: 0.029174, Regularization: 0.062594\n",
      "====> Epoch: 7 Average loss: 0.0943\n",
      "Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 0.103005\n",
      "Reconstruction: 0.031234, Regularization: 0.071771\n",
      "Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 0.074408\n",
      "Reconstruction: 0.024995, Regularization: 0.049414\n",
      "Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 0.094321\n",
      "Reconstruction: 0.028710, Regularization: 0.065611\n",
      "Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 0.112741\n",
      "Reconstruction: 0.034029, Regularization: 0.078712\n",
      "Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 0.105152\n",
      "Reconstruction: 0.031880, Regularization: 0.073272\n",
      "Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 0.095347\n",
      "Reconstruction: 0.029384, Regularization: 0.065963\n",
      "Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 0.087966\n",
      "Reconstruction: 0.029219, Regularization: 0.058747\n",
      "Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 0.103668\n",
      "Reconstruction: 0.030592, Regularization: 0.073075\n",
      "====> Epoch: 8 Average loss: 0.0925\n",
      "Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 0.104732\n",
      "Reconstruction: 0.031202, Regularization: 0.073530\n",
      "Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 0.073499\n",
      "Reconstruction: 0.026071, Regularization: 0.047428\n",
      "Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 0.095448\n",
      "Reconstruction: 0.030767, Regularization: 0.064682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 0.074821\n",
      "Reconstruction: 0.026554, Regularization: 0.048267\n",
      "Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 0.080178\n",
      "Reconstruction: 0.026933, Regularization: 0.053245\n",
      "Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 0.100750\n",
      "Reconstruction: 0.029573, Regularization: 0.071178\n",
      "Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 0.079217\n",
      "Reconstruction: 0.027061, Regularization: 0.052156\n",
      "Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 0.100073\n",
      "Reconstruction: 0.030267, Regularization: 0.069807\n",
      "====> Epoch: 9 Average loss: 0.0910\n",
      "Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 0.081390\n",
      "Reconstruction: 0.028136, Regularization: 0.053254\n",
      "Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 0.077678\n",
      "Reconstruction: 0.026771, Regularization: 0.050907\n",
      "Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 0.061873\n",
      "Reconstruction: 0.023421, Regularization: 0.038452\n",
      "Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 0.083352\n",
      "Reconstruction: 0.026726, Regularization: 0.056626\n",
      "Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 0.087070\n",
      "Reconstruction: 0.028321, Regularization: 0.058750\n",
      "Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 0.071968\n",
      "Reconstruction: 0.025236, Regularization: 0.046732\n",
      "Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 0.078740\n",
      "Reconstruction: 0.027524, Regularization: 0.051216\n",
      "Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 0.077896\n",
      "Reconstruction: 0.026118, Regularization: 0.051777\n",
      "====> Epoch: 10 Average loss: 0.0895\n",
      "Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.075219\n",
      "Reconstruction: 0.025884, Regularization: 0.049335\n",
      "Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 0.101658\n",
      "Reconstruction: 0.030344, Regularization: 0.071314\n",
      "Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.109787\n",
      "Reconstruction: 0.032101, Regularization: 0.077685\n",
      "Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 0.095264\n",
      "Reconstruction: 0.029702, Regularization: 0.065561\n",
      "Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 0.073058\n",
      "Reconstruction: 0.024960, Regularization: 0.048098\n",
      "Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 0.086076\n",
      "Reconstruction: 0.026460, Regularization: 0.059616\n",
      "Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.084338\n",
      "Reconstruction: 0.028727, Regularization: 0.055611\n",
      "Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 0.076224\n",
      "Reconstruction: 0.025455, Regularization: 0.050769\n",
      "====> Epoch: 11 Average loss: 0.0880\n",
      "Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 0.072481\n",
      "Reconstruction: 0.025326, Regularization: 0.047155\n",
      "Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 0.104829\n",
      "Reconstruction: 0.030190, Regularization: 0.074639\n",
      "Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 0.086248\n",
      "Reconstruction: 0.027329, Regularization: 0.058919\n",
      "Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 0.068842\n",
      "Reconstruction: 0.024927, Regularization: 0.043915\n",
      "Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 0.077681\n",
      "Reconstruction: 0.026846, Regularization: 0.050835\n",
      "Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.098992\n",
      "Reconstruction: 0.031263, Regularization: 0.067729\n",
      "Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.092347\n",
      "Reconstruction: 0.029038, Regularization: 0.063309\n",
      "Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 0.091621\n",
      "Reconstruction: 0.029441, Regularization: 0.062180\n",
      "====> Epoch: 12 Average loss: 0.0866\n",
      "Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 0.113540\n",
      "Reconstruction: 0.033080, Regularization: 0.080461\n",
      "Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 0.080488\n",
      "Reconstruction: 0.026797, Regularization: 0.053691\n",
      "Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 0.110083\n",
      "Reconstruction: 0.032194, Regularization: 0.077889\n",
      "Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 0.075045\n",
      "Reconstruction: 0.025792, Regularization: 0.049253\n",
      "Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 0.084800\n",
      "Reconstruction: 0.027917, Regularization: 0.056883\n",
      "Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 0.095961\n",
      "Reconstruction: 0.030430, Regularization: 0.065531\n",
      "Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 0.078510\n",
      "Reconstruction: 0.026924, Regularization: 0.051586\n",
      "Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 0.068351\n",
      "Reconstruction: 0.024528, Regularization: 0.043823\n",
      "====> Epoch: 13 Average loss: 0.0850\n",
      "Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.082900\n",
      "Reconstruction: 0.025917, Regularization: 0.056983\n",
      "Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.076012\n",
      "Reconstruction: 0.026816, Regularization: 0.049196\n",
      "Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 0.083972\n",
      "Reconstruction: 0.028052, Regularization: 0.055920\n",
      "Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.075124\n",
      "Reconstruction: 0.025416, Regularization: 0.049708\n",
      "Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.096648\n",
      "Reconstruction: 0.028912, Regularization: 0.067736\n",
      "Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 0.086078\n",
      "Reconstruction: 0.027354, Regularization: 0.058724\n",
      "Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.095439\n",
      "Reconstruction: 0.030247, Regularization: 0.065191\n",
      "Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.071602\n",
      "Reconstruction: 0.024543, Regularization: 0.047059\n",
      "====> Epoch: 14 Average loss: 0.0836\n",
      "Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 0.101397\n",
      "Reconstruction: 0.029162, Regularization: 0.072235\n",
      "Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 0.090027\n",
      "Reconstruction: 0.028278, Regularization: 0.061749\n",
      "Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.084439\n",
      "Reconstruction: 0.027716, Regularization: 0.056723\n",
      "Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.076851\n",
      "Reconstruction: 0.026546, Regularization: 0.050305\n",
      "Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.083717\n",
      "Reconstruction: 0.026549, Regularization: 0.057168\n",
      "Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.075017\n",
      "Reconstruction: 0.025635, Regularization: 0.049382\n",
      "Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.072774\n",
      "Reconstruction: 0.025097, Regularization: 0.047677\n",
      "Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 0.079529\n",
      "Reconstruction: 0.025191, Regularization: 0.054338\n",
      "====> Epoch: 15 Average loss: 0.0823\n",
      "Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 0.104105\n",
      "Reconstruction: 0.031109, Regularization: 0.072995\n",
      "Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 0.072545\n",
      "Reconstruction: 0.024612, Regularization: 0.047933\n",
      "Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.081646\n",
      "Reconstruction: 0.028424, Regularization: 0.053222\n",
      "Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 0.072629\n",
      "Reconstruction: 0.025905, Regularization: 0.046724\n",
      "Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 0.077426\n",
      "Reconstruction: 0.025766, Regularization: 0.051660\n",
      "Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 0.073309\n",
      "Reconstruction: 0.024693, Regularization: 0.048616\n",
      "Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 0.062369\n",
      "Reconstruction: 0.024091, Regularization: 0.038278\n",
      "Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.083136\n",
      "Reconstruction: 0.026973, Regularization: 0.056163\n",
      "====> Epoch: 16 Average loss: 0.0811\n",
      "Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.069543\n",
      "Reconstruction: 0.024537, Regularization: 0.045006\n",
      "Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 0.088647\n",
      "Reconstruction: 0.028811, Regularization: 0.059836\n",
      "Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.069839\n",
      "Reconstruction: 0.024636, Regularization: 0.045203\n",
      "Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 0.083587\n",
      "Reconstruction: 0.028057, Regularization: 0.055530\n",
      "Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.083219\n",
      "Reconstruction: 0.026233, Regularization: 0.056986\n",
      "Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 0.067397\n",
      "Reconstruction: 0.024136, Regularization: 0.043261\n",
      "Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 0.088525\n",
      "Reconstruction: 0.027084, Regularization: 0.061441\n",
      "Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 0.070816\n",
      "Reconstruction: 0.025841, Regularization: 0.044975\n",
      "====> Epoch: 17 Average loss: 0.0799\n",
      "Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 0.077585\n",
      "Reconstruction: 0.026426, Regularization: 0.051159\n",
      "Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.082469\n",
      "Reconstruction: 0.026108, Regularization: 0.056360\n",
      "Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 0.092612\n",
      "Reconstruction: 0.028465, Regularization: 0.064147\n",
      "Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.092502\n",
      "Reconstruction: 0.029769, Regularization: 0.062733\n",
      "Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 0.088663\n",
      "Reconstruction: 0.027868, Regularization: 0.060795\n",
      "Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.091728\n",
      "Reconstruction: 0.029423, Regularization: 0.062305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 0.076106\n",
      "Reconstruction: 0.027591, Regularization: 0.048515\n",
      "Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 0.061618\n",
      "Reconstruction: 0.023265, Regularization: 0.038353\n",
      "====> Epoch: 18 Average loss: 0.0785\n",
      "Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 0.079067\n",
      "Reconstruction: 0.027272, Regularization: 0.051795\n",
      "Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 0.082122\n",
      "Reconstruction: 0.027528, Regularization: 0.054594\n",
      "Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 0.086734\n",
      "Reconstruction: 0.027033, Regularization: 0.059701\n",
      "Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 0.076808\n",
      "Reconstruction: 0.026808, Regularization: 0.050000\n",
      "Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 0.084286\n",
      "Reconstruction: 0.026184, Regularization: 0.058103\n",
      "Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 0.091728\n",
      "Reconstruction: 0.028993, Regularization: 0.062736\n",
      "Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 0.057395\n",
      "Reconstruction: 0.022774, Regularization: 0.034621\n",
      "Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.078560\n",
      "Reconstruction: 0.027285, Regularization: 0.051275\n",
      "====> Epoch: 19 Average loss: 0.0773\n",
      "Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 0.088058\n",
      "Reconstruction: 0.025998, Regularization: 0.062060\n",
      "Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 0.062311\n",
      "Reconstruction: 0.023647, Regularization: 0.038664\n",
      "Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 0.078386\n",
      "Reconstruction: 0.026455, Regularization: 0.051931\n",
      "Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 0.075545\n",
      "Reconstruction: 0.026471, Regularization: 0.049074\n",
      "Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 0.066556\n",
      "Reconstruction: 0.024593, Regularization: 0.041963\n",
      "Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 0.085795\n",
      "Reconstruction: 0.027591, Regularization: 0.058204\n",
      "Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 0.075109\n",
      "Reconstruction: 0.026119, Regularization: 0.048990\n",
      "Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 0.065224\n",
      "Reconstruction: 0.023163, Regularization: 0.042061\n",
      "====> Epoch: 20 Average loss: 0.0762\n",
      "Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.071146\n",
      "Reconstruction: 0.025158, Regularization: 0.045988\n",
      "Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 0.078999\n",
      "Reconstruction: 0.028347, Regularization: 0.050652\n",
      "Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 0.057895\n",
      "Reconstruction: 0.023682, Regularization: 0.034213\n",
      "Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 0.078098\n",
      "Reconstruction: 0.026263, Regularization: 0.051835\n",
      "Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.066980\n",
      "Reconstruction: 0.024940, Regularization: 0.042040\n",
      "Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 0.070644\n",
      "Reconstruction: 0.025191, Regularization: 0.045453\n",
      "Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 0.080112\n",
      "Reconstruction: 0.025880, Regularization: 0.054232\n",
      "Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.063162\n",
      "Reconstruction: 0.024025, Regularization: 0.039137\n",
      "====> Epoch: 21 Average loss: 0.0751\n",
      "Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 0.063667\n",
      "Reconstruction: 0.024095, Regularization: 0.039572\n",
      "Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 0.087133\n",
      "Reconstruction: 0.026540, Regularization: 0.060593\n",
      "Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 0.073092\n",
      "Reconstruction: 0.026222, Regularization: 0.046870\n",
      "Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 0.080812\n",
      "Reconstruction: 0.026864, Regularization: 0.053948\n",
      "Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.069562\n",
      "Reconstruction: 0.025191, Regularization: 0.044372\n",
      "Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 0.085819\n",
      "Reconstruction: 0.027271, Regularization: 0.058548\n",
      "Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 0.082839\n",
      "Reconstruction: 0.026329, Regularization: 0.056510\n",
      "Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 0.061120\n",
      "Reconstruction: 0.024273, Regularization: 0.036847\n",
      "====> Epoch: 22 Average loss: 0.0737\n",
      "Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 0.096764\n",
      "Reconstruction: 0.028489, Regularization: 0.068275\n",
      "Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 0.084048\n",
      "Reconstruction: 0.029356, Regularization: 0.054691\n",
      "Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 0.073764\n",
      "Reconstruction: 0.025503, Regularization: 0.048261\n",
      "Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 0.071407\n",
      "Reconstruction: 0.024304, Regularization: 0.047104\n",
      "Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 0.065902\n",
      "Reconstruction: 0.025011, Regularization: 0.040891\n",
      "Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 0.077747\n",
      "Reconstruction: 0.026015, Regularization: 0.051732\n",
      "Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 0.070345\n",
      "Reconstruction: 0.025885, Regularization: 0.044459\n",
      "Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 0.070056\n",
      "Reconstruction: 0.026031, Regularization: 0.044025\n",
      "====> Epoch: 23 Average loss: 0.0727\n",
      "Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.056209\n",
      "Reconstruction: 0.023139, Regularization: 0.033071\n",
      "Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 0.073947\n",
      "Reconstruction: 0.024351, Regularization: 0.049596\n",
      "Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 0.061525\n",
      "Reconstruction: 0.023248, Regularization: 0.038276\n",
      "Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 0.075719\n",
      "Reconstruction: 0.027089, Regularization: 0.048630\n",
      "Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 0.048303\n",
      "Reconstruction: 0.021023, Regularization: 0.027280\n",
      "Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 0.083455\n",
      "Reconstruction: 0.028337, Regularization: 0.055119\n",
      "Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 0.077872\n",
      "Reconstruction: 0.026446, Regularization: 0.051426\n",
      "Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 0.078927\n",
      "Reconstruction: 0.026965, Regularization: 0.051962\n",
      "====> Epoch: 24 Average loss: 0.0717\n",
      "Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 0.078369\n",
      "Reconstruction: 0.026941, Regularization: 0.051427\n",
      "Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 0.065039\n",
      "Reconstruction: 0.025073, Regularization: 0.039966\n",
      "Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 0.065917\n",
      "Reconstruction: 0.025480, Regularization: 0.040437\n",
      "Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 0.078235\n",
      "Reconstruction: 0.026806, Regularization: 0.051429\n",
      "Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 0.059527\n",
      "Reconstruction: 0.021905, Regularization: 0.037622\n",
      "Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 0.063414\n",
      "Reconstruction: 0.024955, Regularization: 0.038458\n",
      "Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.054914\n",
      "Reconstruction: 0.023084, Regularization: 0.031830\n",
      "Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 0.069435\n",
      "Reconstruction: 0.024716, Regularization: 0.044719\n",
      "====> Epoch: 25 Average loss: 0.0706\n",
      "Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 0.078170\n",
      "Reconstruction: 0.025438, Regularization: 0.052732\n",
      "Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 0.053961\n",
      "Reconstruction: 0.022635, Regularization: 0.031325\n",
      "Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 0.079337\n",
      "Reconstruction: 0.025764, Regularization: 0.053572\n",
      "Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 0.063637\n",
      "Reconstruction: 0.023718, Regularization: 0.039919\n",
      "Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.078800\n",
      "Reconstruction: 0.027892, Regularization: 0.050908\n",
      "Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 0.069565\n",
      "Reconstruction: 0.024716, Regularization: 0.044849\n",
      "Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 0.073592\n",
      "Reconstruction: 0.027949, Regularization: 0.045643\n",
      "Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 0.067931\n",
      "Reconstruction: 0.024762, Regularization: 0.043170\n",
      "====> Epoch: 26 Average loss: 0.0697\n",
      "Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 0.072989\n",
      "Reconstruction: 0.024953, Regularization: 0.048037\n",
      "Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.076251\n",
      "Reconstruction: 0.026319, Regularization: 0.049931\n",
      "Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 0.057447\n",
      "Reconstruction: 0.023359, Regularization: 0.034088\n",
      "Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.066300\n",
      "Reconstruction: 0.025352, Regularization: 0.040948\n",
      "Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 0.065801\n",
      "Reconstruction: 0.024276, Regularization: 0.041525\n",
      "Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.057075\n",
      "Reconstruction: 0.024227, Regularization: 0.032849\n",
      "Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.062028\n",
      "Reconstruction: 0.023258, Regularization: 0.038769\n",
      "Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 0.046929\n",
      "Reconstruction: 0.020902, Regularization: 0.026027\n",
      "====> Epoch: 27 Average loss: 0.0686\n",
      "Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.062541\n",
      "Reconstruction: 0.024494, Regularization: 0.038048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.063582\n",
      "Reconstruction: 0.023887, Regularization: 0.039695\n",
      "Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 0.061159\n",
      "Reconstruction: 0.023228, Regularization: 0.037931\n",
      "Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.081036\n",
      "Reconstruction: 0.028129, Regularization: 0.052907\n",
      "Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.057570\n",
      "Reconstruction: 0.023019, Regularization: 0.034551\n",
      "Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.067263\n",
      "Reconstruction: 0.025793, Regularization: 0.041470\n",
      "Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.062636\n",
      "Reconstruction: 0.023716, Regularization: 0.038920\n",
      "Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.062185\n",
      "Reconstruction: 0.023970, Regularization: 0.038215\n",
      "====> Epoch: 28 Average loss: 0.0676\n",
      "Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 0.068720\n",
      "Reconstruction: 0.025048, Regularization: 0.043672\n",
      "Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 0.056107\n",
      "Reconstruction: 0.025265, Regularization: 0.030842\n",
      "Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 0.060764\n",
      "Reconstruction: 0.023660, Regularization: 0.037104\n",
      "Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 0.065851\n",
      "Reconstruction: 0.024661, Regularization: 0.041190\n",
      "Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.066232\n",
      "Reconstruction: 0.023766, Regularization: 0.042466\n",
      "Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 0.054972\n",
      "Reconstruction: 0.022050, Regularization: 0.032922\n",
      "Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 0.046235\n",
      "Reconstruction: 0.020933, Regularization: 0.025302\n",
      "Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.056466\n",
      "Reconstruction: 0.022849, Regularization: 0.033617\n",
      "====> Epoch: 29 Average loss: 0.0666\n",
      "Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.066680\n",
      "Reconstruction: 0.024063, Regularization: 0.042618\n",
      "Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.059194\n",
      "Reconstruction: 0.023140, Regularization: 0.036053\n",
      "Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.054634\n",
      "Reconstruction: 0.023289, Regularization: 0.031345\n",
      "Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.060200\n",
      "Reconstruction: 0.022974, Regularization: 0.037226\n",
      "Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.058645\n",
      "Reconstruction: 0.024063, Regularization: 0.034582\n",
      "Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.065603\n",
      "Reconstruction: 0.023836, Regularization: 0.041768\n",
      "Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.046583\n",
      "Reconstruction: 0.021651, Regularization: 0.024932\n",
      "Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 0.067429\n",
      "Reconstruction: 0.023912, Regularization: 0.043517\n",
      "====> Epoch: 30 Average loss: 0.0657\n",
      "Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.049470\n",
      "Reconstruction: 0.020957, Regularization: 0.028514\n",
      "Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.063778\n",
      "Reconstruction: 0.023408, Regularization: 0.040371\n",
      "Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 0.069529\n",
      "Reconstruction: 0.025540, Regularization: 0.043989\n",
      "Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.056040\n",
      "Reconstruction: 0.021477, Regularization: 0.034563\n",
      "Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.057409\n",
      "Reconstruction: 0.024243, Regularization: 0.033166\n",
      "Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.061603\n",
      "Reconstruction: 0.024334, Regularization: 0.037269\n",
      "Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 0.066774\n",
      "Reconstruction: 0.024484, Regularization: 0.042290\n",
      "Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 0.067519\n",
      "Reconstruction: 0.026592, Regularization: 0.040927\n",
      "====> Epoch: 31 Average loss: 0.0648\n",
      "Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.057571\n",
      "Reconstruction: 0.023454, Regularization: 0.034117\n",
      "Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.083856\n",
      "Reconstruction: 0.026837, Regularization: 0.057020\n",
      "Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.061726\n",
      "Reconstruction: 0.024770, Regularization: 0.036956\n",
      "Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.055012\n",
      "Reconstruction: 0.026044, Regularization: 0.028969\n",
      "Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.061115\n",
      "Reconstruction: 0.024454, Regularization: 0.036661\n",
      "Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 0.064866\n",
      "Reconstruction: 0.025710, Regularization: 0.039156\n",
      "Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.061272\n",
      "Reconstruction: 0.024256, Regularization: 0.037016\n",
      "Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.060267\n",
      "Reconstruction: 0.023213, Regularization: 0.037054\n",
      "====> Epoch: 32 Average loss: 0.0639\n",
      "Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.066512\n",
      "Reconstruction: 0.024526, Regularization: 0.041986\n",
      "Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.058045\n",
      "Reconstruction: 0.023379, Regularization: 0.034666\n",
      "Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.073503\n",
      "Reconstruction: 0.026464, Regularization: 0.047039\n",
      "Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.051083\n",
      "Reconstruction: 0.023400, Regularization: 0.027683\n",
      "Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 0.066748\n",
      "Reconstruction: 0.024460, Regularization: 0.042288\n",
      "Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.059849\n",
      "Reconstruction: 0.023206, Regularization: 0.036643\n",
      "Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 0.074669\n",
      "Reconstruction: 0.026415, Regularization: 0.048254\n",
      "Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.049742\n",
      "Reconstruction: 0.020902, Regularization: 0.028840\n",
      "====> Epoch: 33 Average loss: 0.0629\n",
      "Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.054627\n",
      "Reconstruction: 0.023556, Regularization: 0.031071\n",
      "Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.056764\n",
      "Reconstruction: 0.024536, Regularization: 0.032228\n",
      "Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.046171\n",
      "Reconstruction: 0.021705, Regularization: 0.024466\n",
      "Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.057388\n",
      "Reconstruction: 0.022601, Regularization: 0.034788\n",
      "Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.067188\n",
      "Reconstruction: 0.025433, Regularization: 0.041755\n",
      "Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.061690\n",
      "Reconstruction: 0.024367, Regularization: 0.037323\n",
      "Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.055022\n",
      "Reconstruction: 0.024099, Regularization: 0.030923\n",
      "Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 0.050388\n",
      "Reconstruction: 0.022707, Regularization: 0.027681\n",
      "====> Epoch: 34 Average loss: 0.0621\n",
      "Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.062257\n",
      "Reconstruction: 0.023818, Regularization: 0.038439\n",
      "Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.057935\n",
      "Reconstruction: 0.022803, Regularization: 0.035132\n",
      "Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.063811\n",
      "Reconstruction: 0.024751, Regularization: 0.039060\n",
      "Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.054690\n",
      "Reconstruction: 0.024974, Regularization: 0.029716\n",
      "Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.069283\n",
      "Reconstruction: 0.025865, Regularization: 0.043418\n",
      "Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.053066\n",
      "Reconstruction: 0.021452, Regularization: 0.031613\n",
      "Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.052808\n",
      "Reconstruction: 0.022530, Regularization: 0.030278\n",
      "Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.055538\n",
      "Reconstruction: 0.022890, Regularization: 0.032648\n",
      "====> Epoch: 35 Average loss: 0.0612\n",
      "Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 0.055464\n",
      "Reconstruction: 0.021638, Regularization: 0.033826\n",
      "Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.045722\n",
      "Reconstruction: 0.021629, Regularization: 0.024093\n",
      "Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.064804\n",
      "Reconstruction: 0.023700, Regularization: 0.041104\n",
      "Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.068655\n",
      "Reconstruction: 0.026053, Regularization: 0.042602\n",
      "Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.060524\n",
      "Reconstruction: 0.023962, Regularization: 0.036561\n",
      "Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.052979\n",
      "Reconstruction: 0.023339, Regularization: 0.029640\n",
      "Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 0.047839\n",
      "Reconstruction: 0.023933, Regularization: 0.023906\n",
      "Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.072449\n",
      "Reconstruction: 0.026570, Regularization: 0.045879\n",
      "====> Epoch: 36 Average loss: 0.0604\n",
      "Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.074989\n",
      "Reconstruction: 0.028853, Regularization: 0.046137\n",
      "Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.054456\n",
      "Reconstruction: 0.021814, Regularization: 0.032642\n",
      "Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.050063\n",
      "Reconstruction: 0.022387, Regularization: 0.027676\n",
      "Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 0.062052\n",
      "Reconstruction: 0.024580, Regularization: 0.037471\n",
      "Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.064421\n",
      "Reconstruction: 0.025672, Regularization: 0.038749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.054625\n",
      "Reconstruction: 0.026016, Regularization: 0.028609\n",
      "Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.059106\n",
      "Reconstruction: 0.024082, Regularization: 0.035024\n",
      "Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.050744\n",
      "Reconstruction: 0.022656, Regularization: 0.028089\n",
      "====> Epoch: 37 Average loss: 0.0596\n",
      "Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.060270\n",
      "Reconstruction: 0.023674, Regularization: 0.036597\n",
      "Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.070063\n",
      "Reconstruction: 0.028913, Regularization: 0.041150\n",
      "Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.067194\n",
      "Reconstruction: 0.026215, Regularization: 0.040979\n",
      "Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 0.053648\n",
      "Reconstruction: 0.022753, Regularization: 0.030895\n",
      "Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.054889\n",
      "Reconstruction: 0.024135, Regularization: 0.030754\n",
      "Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.063656\n",
      "Reconstruction: 0.026378, Regularization: 0.037278\n",
      "Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.053978\n",
      "Reconstruction: 0.023599, Regularization: 0.030379\n",
      "Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.066557\n",
      "Reconstruction: 0.026984, Regularization: 0.039573\n",
      "====> Epoch: 38 Average loss: 0.0591\n",
      "Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 0.055558\n",
      "Reconstruction: 0.025232, Regularization: 0.030325\n",
      "Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.062137\n",
      "Reconstruction: 0.026359, Regularization: 0.035778\n",
      "Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.060891\n",
      "Reconstruction: 0.024516, Regularization: 0.036375\n",
      "Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.048926\n",
      "Reconstruction: 0.022073, Regularization: 0.026853\n",
      "Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.073647\n",
      "Reconstruction: 0.025340, Regularization: 0.048307\n",
      "Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.059622\n",
      "Reconstruction: 0.025619, Regularization: 0.034002\n",
      "Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.048244\n",
      "Reconstruction: 0.021635, Regularization: 0.026609\n",
      "Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.051228\n",
      "Reconstruction: 0.022897, Regularization: 0.028331\n",
      "====> Epoch: 39 Average loss: 0.0581\n",
      "Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.052742\n",
      "Reconstruction: 0.021852, Regularization: 0.030890\n",
      "Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.048537\n",
      "Reconstruction: 0.023424, Regularization: 0.025113\n",
      "Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.061484\n",
      "Reconstruction: 0.024516, Regularization: 0.036968\n",
      "Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.061644\n",
      "Reconstruction: 0.023849, Regularization: 0.037795\n",
      "Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.062368\n",
      "Reconstruction: 0.026238, Regularization: 0.036130\n",
      "Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 0.055661\n",
      "Reconstruction: 0.023036, Regularization: 0.032625\n",
      "Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.054128\n",
      "Reconstruction: 0.024581, Regularization: 0.029546\n",
      "Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.047755\n",
      "Reconstruction: 0.022965, Regularization: 0.024790\n",
      "====> Epoch: 40 Average loss: 0.0573\n",
      "Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 0.064204\n",
      "Reconstruction: 0.029222, Regularization: 0.034983\n",
      "Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.057555\n",
      "Reconstruction: 0.024594, Regularization: 0.032961\n",
      "Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 0.057013\n",
      "Reconstruction: 0.025749, Regularization: 0.031263\n",
      "Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.069136\n",
      "Reconstruction: 0.027216, Regularization: 0.041920\n",
      "Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.048032\n",
      "Reconstruction: 0.022305, Regularization: 0.025728\n",
      "Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 0.061003\n",
      "Reconstruction: 0.028077, Regularization: 0.032926\n",
      "Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.058843\n",
      "Reconstruction: 0.025459, Regularization: 0.033385\n",
      "Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.062052\n",
      "Reconstruction: 0.025379, Regularization: 0.036673\n",
      "====> Epoch: 41 Average loss: 0.0569\n",
      "Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.059365\n",
      "Reconstruction: 0.023217, Regularization: 0.036148\n",
      "Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.051960\n",
      "Reconstruction: 0.023907, Regularization: 0.028053\n",
      "Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.050841\n",
      "Reconstruction: 0.022977, Regularization: 0.027864\n",
      "Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 0.058005\n",
      "Reconstruction: 0.024643, Regularization: 0.033362\n",
      "Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.052826\n",
      "Reconstruction: 0.021904, Regularization: 0.030922\n",
      "Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.052431\n",
      "Reconstruction: 0.022735, Regularization: 0.029696\n",
      "Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.062844\n",
      "Reconstruction: 0.027286, Regularization: 0.035557\n",
      "Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.052100\n",
      "Reconstruction: 0.023370, Regularization: 0.028730\n",
      "====> Epoch: 42 Average loss: 0.0560\n",
      "Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.061090\n",
      "Reconstruction: 0.028487, Regularization: 0.032603\n",
      "Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.069039\n",
      "Reconstruction: 0.027573, Regularization: 0.041466\n",
      "Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.054075\n",
      "Reconstruction: 0.023358, Regularization: 0.030717\n",
      "Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.059302\n",
      "Reconstruction: 0.025515, Regularization: 0.033787\n",
      "Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.060907\n",
      "Reconstruction: 0.025561, Regularization: 0.035346\n",
      "Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.049155\n",
      "Reconstruction: 0.023337, Regularization: 0.025818\n",
      "Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.051083\n",
      "Reconstruction: 0.025630, Regularization: 0.025453\n",
      "Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.060528\n",
      "Reconstruction: 0.026750, Regularization: 0.033778\n",
      "====> Epoch: 43 Average loss: 0.0554\n",
      "Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.056793\n",
      "Reconstruction: 0.024250, Regularization: 0.032543\n",
      "Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.048765\n",
      "Reconstruction: 0.023897, Regularization: 0.024868\n",
      "Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.053469\n",
      "Reconstruction: 0.023606, Regularization: 0.029864\n",
      "Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.047541\n",
      "Reconstruction: 0.024759, Regularization: 0.022781\n",
      "Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.053031\n",
      "Reconstruction: 0.024901, Regularization: 0.028130\n",
      "Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.045418\n",
      "Reconstruction: 0.023062, Regularization: 0.022356\n",
      "Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.058061\n",
      "Reconstruction: 0.027463, Regularization: 0.030598\n",
      "Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.054459\n",
      "Reconstruction: 0.024990, Regularization: 0.029469\n",
      "====> Epoch: 44 Average loss: 0.0549\n",
      "Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.068550\n",
      "Reconstruction: 0.026889, Regularization: 0.041661\n",
      "Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 0.051999\n",
      "Reconstruction: 0.023650, Regularization: 0.028348\n",
      "Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.053282\n",
      "Reconstruction: 0.025463, Regularization: 0.027820\n",
      "Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.043342\n",
      "Reconstruction: 0.021659, Regularization: 0.021683\n",
      "Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.055031\n",
      "Reconstruction: 0.025219, Regularization: 0.029812\n",
      "Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.050221\n",
      "Reconstruction: 0.022747, Regularization: 0.027474\n",
      "Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.056808\n",
      "Reconstruction: 0.023794, Regularization: 0.033014\n",
      "Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.051266\n",
      "Reconstruction: 0.023604, Regularization: 0.027662\n",
      "====> Epoch: 45 Average loss: 0.0540\n",
      "Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.046321\n",
      "Reconstruction: 0.022218, Regularization: 0.024103\n",
      "Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.049083\n",
      "Reconstruction: 0.022813, Regularization: 0.026270\n",
      "Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.059920\n",
      "Reconstruction: 0.025425, Regularization: 0.034496\n",
      "Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.045676\n",
      "Reconstruction: 0.022072, Regularization: 0.023605\n",
      "Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.043510\n",
      "Reconstruction: 0.022390, Regularization: 0.021121\n",
      "Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.048440\n",
      "Reconstruction: 0.025249, Regularization: 0.023191\n",
      "Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.053752\n",
      "Reconstruction: 0.024076, Regularization: 0.029676\n",
      "Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.045764\n",
      "Reconstruction: 0.024362, Regularization: 0.021402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 46 Average loss: 0.0533\n",
      "Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.057373\n",
      "Reconstruction: 0.027825, Regularization: 0.029549\n",
      "Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.055442\n",
      "Reconstruction: 0.027417, Regularization: 0.028025\n",
      "Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.045150\n",
      "Reconstruction: 0.024960, Regularization: 0.020190\n",
      "Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.059065\n",
      "Reconstruction: 0.027760, Regularization: 0.031306\n",
      "Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.051714\n",
      "Reconstruction: 0.025191, Regularization: 0.026523\n",
      "Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.049570\n",
      "Reconstruction: 0.025333, Regularization: 0.024237\n",
      "Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.045914\n",
      "Reconstruction: 0.022699, Regularization: 0.023215\n",
      "Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.047220\n",
      "Reconstruction: 0.023794, Regularization: 0.023426\n",
      "====> Epoch: 47 Average loss: 0.0527\n",
      "Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.055015\n",
      "Reconstruction: 0.025447, Regularization: 0.029569\n",
      "Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.043677\n",
      "Reconstruction: 0.022691, Regularization: 0.020986\n",
      "Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.052168\n",
      "Reconstruction: 0.026202, Regularization: 0.025965\n",
      "Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.071075\n",
      "Reconstruction: 0.031770, Regularization: 0.039305\n",
      "Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.051049\n",
      "Reconstruction: 0.024258, Regularization: 0.026790\n",
      "Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.057224\n",
      "Reconstruction: 0.025938, Regularization: 0.031287\n",
      "Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.056431\n",
      "Reconstruction: 0.026254, Regularization: 0.030177\n",
      "Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.043717\n",
      "Reconstruction: 0.024273, Regularization: 0.019443\n",
      "====> Epoch: 48 Average loss: 0.0521\n",
      "Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.041490\n",
      "Reconstruction: 0.021563, Regularization: 0.019927\n",
      "Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.047129\n",
      "Reconstruction: 0.024027, Regularization: 0.023102\n",
      "Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.045834\n",
      "Reconstruction: 0.021983, Regularization: 0.023851\n",
      "Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.052599\n",
      "Reconstruction: 0.026443, Regularization: 0.026155\n",
      "Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.057744\n",
      "Reconstruction: 0.028141, Regularization: 0.029604\n",
      "Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.040669\n",
      "Reconstruction: 0.021479, Regularization: 0.019190\n",
      "Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.064849\n",
      "Reconstruction: 0.027962, Regularization: 0.036888\n",
      "Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.048528\n",
      "Reconstruction: 0.023432, Regularization: 0.025097\n",
      "====> Epoch: 49 Average loss: 0.0515\n",
      "Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 0.056469\n",
      "Reconstruction: 0.028216, Regularization: 0.028253\n",
      "Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 0.051355\n",
      "Reconstruction: 0.023084, Regularization: 0.028271\n",
      "Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 0.054839\n",
      "Reconstruction: 0.027181, Regularization: 0.027658\n",
      "Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 0.048815\n",
      "Reconstruction: 0.024238, Regularization: 0.024577\n",
      "Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 0.055242\n",
      "Reconstruction: 0.027888, Regularization: 0.027354\n",
      "Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 0.049437\n",
      "Reconstruction: 0.024994, Regularization: 0.024443\n",
      "Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 0.059472\n",
      "Reconstruction: 0.028473, Regularization: 0.030999\n",
      "Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 0.051810\n",
      "Reconstruction: 0.025166, Regularization: 0.026644\n",
      "====> Epoch: 50 Average loss: 0.0510\n",
      "Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 0.048491\n",
      "Reconstruction: 0.024407, Regularization: 0.024083\n",
      "Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 0.051414\n",
      "Reconstruction: 0.025212, Regularization: 0.026202\n",
      "Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 0.048797\n",
      "Reconstruction: 0.024644, Regularization: 0.024154\n",
      "Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 0.064894\n",
      "Reconstruction: 0.028836, Regularization: 0.036059\n",
      "Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 0.045784\n",
      "Reconstruction: 0.023758, Regularization: 0.022025\n",
      "Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 0.051404\n",
      "Reconstruction: 0.024377, Regularization: 0.027027\n",
      "Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 0.054414\n",
      "Reconstruction: 0.026429, Regularization: 0.027985\n",
      "Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 0.039364\n",
      "Reconstruction: 0.021590, Regularization: 0.017774\n",
      "====> Epoch: 51 Average loss: 0.0505\n",
      "Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 0.043671\n",
      "Reconstruction: 0.022114, Regularization: 0.021558\n",
      "Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 0.043140\n",
      "Reconstruction: 0.022480, Regularization: 0.020660\n",
      "Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 0.050750\n",
      "Reconstruction: 0.024979, Regularization: 0.025771\n",
      "Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 0.046362\n",
      "Reconstruction: 0.025860, Regularization: 0.020502\n",
      "Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 0.047849\n",
      "Reconstruction: 0.023265, Regularization: 0.024583\n",
      "Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 0.050015\n",
      "Reconstruction: 0.025263, Regularization: 0.024753\n",
      "Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 0.049543\n",
      "Reconstruction: 0.026763, Regularization: 0.022780\n",
      "Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 0.050714\n",
      "Reconstruction: 0.024973, Regularization: 0.025741\n",
      "====> Epoch: 52 Average loss: 0.0500\n",
      "Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 0.050912\n",
      "Reconstruction: 0.025102, Regularization: 0.025810\n",
      "Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 0.043338\n",
      "Reconstruction: 0.021958, Regularization: 0.021380\n",
      "Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 0.043371\n",
      "Reconstruction: 0.025540, Regularization: 0.017831\n",
      "Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 0.043737\n",
      "Reconstruction: 0.024509, Regularization: 0.019228\n",
      "Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 0.048511\n",
      "Reconstruction: 0.025965, Regularization: 0.022545\n",
      "Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 0.057828\n",
      "Reconstruction: 0.026509, Regularization: 0.031320\n",
      "Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 0.047262\n",
      "Reconstruction: 0.025697, Regularization: 0.021565\n",
      "Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 0.049972\n",
      "Reconstruction: 0.025148, Regularization: 0.024824\n",
      "====> Epoch: 53 Average loss: 0.0497\n",
      "Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 0.054612\n",
      "Reconstruction: 0.027694, Regularization: 0.026918\n",
      "Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 0.055553\n",
      "Reconstruction: 0.027365, Regularization: 0.028188\n",
      "Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 0.049375\n",
      "Reconstruction: 0.027039, Regularization: 0.022335\n",
      "Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 0.058444\n",
      "Reconstruction: 0.025781, Regularization: 0.032663\n",
      "Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 0.047010\n",
      "Reconstruction: 0.025831, Regularization: 0.021178\n",
      "Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 0.060317\n",
      "Reconstruction: 0.029171, Regularization: 0.031147\n",
      "Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 0.045695\n",
      "Reconstruction: 0.024514, Regularization: 0.021181\n",
      "Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 0.041181\n",
      "Reconstruction: 0.022754, Regularization: 0.018428\n",
      "====> Epoch: 54 Average loss: 0.0490\n",
      "Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 0.053067\n",
      "Reconstruction: 0.025338, Regularization: 0.027729\n",
      "Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 0.054288\n",
      "Reconstruction: 0.025719, Regularization: 0.028569\n",
      "Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 0.047160\n",
      "Reconstruction: 0.024369, Regularization: 0.022790\n",
      "Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 0.043648\n",
      "Reconstruction: 0.023346, Regularization: 0.020302\n",
      "Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 0.055972\n",
      "Reconstruction: 0.028356, Regularization: 0.027617\n",
      "Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 0.055514\n",
      "Reconstruction: 0.030709, Regularization: 0.024805\n",
      "Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 0.045742\n",
      "Reconstruction: 0.024521, Regularization: 0.021222\n",
      "Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 0.050384\n",
      "Reconstruction: 0.026000, Regularization: 0.024384\n",
      "====> Epoch: 55 Average loss: 0.0487\n",
      "Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 0.048085\n",
      "Reconstruction: 0.025317, Regularization: 0.022768\n",
      "Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 0.052334\n",
      "Reconstruction: 0.026895, Regularization: 0.025439\n",
      "Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 0.049844\n",
      "Reconstruction: 0.028392, Regularization: 0.021452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 0.048338\n",
      "Reconstruction: 0.026624, Regularization: 0.021714\n",
      "Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 0.047213\n",
      "Reconstruction: 0.026179, Regularization: 0.021034\n",
      "Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 0.055534\n",
      "Reconstruction: 0.028948, Regularization: 0.026587\n",
      "Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 0.044216\n",
      "Reconstruction: 0.025438, Regularization: 0.018778\n",
      "Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 0.042184\n",
      "Reconstruction: 0.024405, Regularization: 0.017780\n",
      "====> Epoch: 56 Average loss: 0.0481\n",
      "Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 0.050819\n",
      "Reconstruction: 0.029861, Regularization: 0.020958\n",
      "Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 0.048841\n",
      "Reconstruction: 0.023377, Regularization: 0.025464\n",
      "Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 0.048749\n",
      "Reconstruction: 0.027429, Regularization: 0.021320\n",
      "Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 0.062604\n",
      "Reconstruction: 0.029159, Regularization: 0.033445\n",
      "Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 0.046707\n",
      "Reconstruction: 0.028031, Regularization: 0.018676\n",
      "Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 0.047100\n",
      "Reconstruction: 0.026886, Regularization: 0.020214\n",
      "Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 0.058445\n",
      "Reconstruction: 0.028972, Regularization: 0.029473\n",
      "Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 0.042753\n",
      "Reconstruction: 0.024707, Regularization: 0.018046\n",
      "====> Epoch: 57 Average loss: 0.0476\n",
      "Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 0.041614\n",
      "Reconstruction: 0.025674, Regularization: 0.015940\n",
      "Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 0.054129\n",
      "Reconstruction: 0.030153, Regularization: 0.023976\n",
      "Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 0.055084\n",
      "Reconstruction: 0.026618, Regularization: 0.028466\n",
      "Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 0.045561\n",
      "Reconstruction: 0.024145, Regularization: 0.021416\n",
      "Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 0.048597\n",
      "Reconstruction: 0.025725, Regularization: 0.022873\n",
      "Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 0.037515\n",
      "Reconstruction: 0.024362, Regularization: 0.013152\n",
      "Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 0.042132\n",
      "Reconstruction: 0.023673, Regularization: 0.018458\n",
      "Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 0.052085\n",
      "Reconstruction: 0.027171, Regularization: 0.024914\n",
      "====> Epoch: 58 Average loss: 0.0471\n",
      "Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 0.042314\n",
      "Reconstruction: 0.024033, Regularization: 0.018282\n",
      "Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 0.047095\n",
      "Reconstruction: 0.025424, Regularization: 0.021672\n",
      "Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 0.045616\n",
      "Reconstruction: 0.025667, Regularization: 0.019950\n",
      "Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 0.048718\n",
      "Reconstruction: 0.029048, Regularization: 0.019670\n",
      "Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 0.046989\n",
      "Reconstruction: 0.029453, Regularization: 0.017536\n",
      "Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 0.043456\n",
      "Reconstruction: 0.024353, Regularization: 0.019103\n",
      "Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 0.039781\n",
      "Reconstruction: 0.024213, Regularization: 0.015568\n",
      "Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 0.042560\n",
      "Reconstruction: 0.023814, Regularization: 0.018746\n",
      "====> Epoch: 59 Average loss: 0.0469\n",
      "Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 0.042225\n",
      "Reconstruction: 0.023559, Regularization: 0.018667\n",
      "Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 0.053627\n",
      "Reconstruction: 0.026172, Regularization: 0.027455\n",
      "Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 0.048697\n",
      "Reconstruction: 0.027791, Regularization: 0.020907\n",
      "Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 0.047850\n",
      "Reconstruction: 0.027729, Regularization: 0.020121\n",
      "Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 0.042887\n",
      "Reconstruction: 0.025418, Regularization: 0.017469\n",
      "Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 0.046234\n",
      "Reconstruction: 0.024977, Regularization: 0.021257\n",
      "Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 0.044734\n",
      "Reconstruction: 0.026595, Regularization: 0.018139\n",
      "Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 0.045861\n",
      "Reconstruction: 0.026950, Regularization: 0.018911\n",
      "====> Epoch: 60 Average loss: 0.0464\n",
      "Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 0.041581\n",
      "Reconstruction: 0.024982, Regularization: 0.016600\n",
      "Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 0.050881\n",
      "Reconstruction: 0.028072, Regularization: 0.022809\n",
      "Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 0.043214\n",
      "Reconstruction: 0.025176, Regularization: 0.018038\n",
      "Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 0.044166\n",
      "Reconstruction: 0.027483, Regularization: 0.016683\n",
      "Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 0.038775\n",
      "Reconstruction: 0.024078, Regularization: 0.014697\n",
      "Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 0.046763\n",
      "Reconstruction: 0.028110, Regularization: 0.018653\n",
      "Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 0.044730\n",
      "Reconstruction: 0.026651, Regularization: 0.018078\n",
      "Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 0.049220\n",
      "Reconstruction: 0.027029, Regularization: 0.022191\n",
      "====> Epoch: 61 Average loss: 0.0462\n",
      "Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 0.049661\n",
      "Reconstruction: 0.027430, Regularization: 0.022231\n",
      "Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 0.041870\n",
      "Reconstruction: 0.025565, Regularization: 0.016305\n",
      "Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 0.048496\n",
      "Reconstruction: 0.029078, Regularization: 0.019418\n",
      "Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 0.048198\n",
      "Reconstruction: 0.028359, Regularization: 0.019839\n",
      "Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 0.051880\n",
      "Reconstruction: 0.029283, Regularization: 0.022597\n",
      "Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 0.043225\n",
      "Reconstruction: 0.025227, Regularization: 0.017998\n",
      "Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 0.041247\n",
      "Reconstruction: 0.025634, Regularization: 0.015613\n",
      "Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 0.045183\n",
      "Reconstruction: 0.026327, Regularization: 0.018857\n",
      "====> Epoch: 62 Average loss: 0.0458\n",
      "Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 0.043006\n",
      "Reconstruction: 0.025905, Regularization: 0.017101\n",
      "Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 0.044939\n",
      "Reconstruction: 0.028004, Regularization: 0.016935\n",
      "Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 0.043068\n",
      "Reconstruction: 0.025684, Regularization: 0.017384\n",
      "Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 0.046471\n",
      "Reconstruction: 0.026035, Regularization: 0.020436\n",
      "Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 0.047499\n",
      "Reconstruction: 0.026501, Regularization: 0.020998\n",
      "Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 0.052096\n",
      "Reconstruction: 0.030701, Regularization: 0.021394\n",
      "Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 0.052989\n",
      "Reconstruction: 0.028574, Regularization: 0.024414\n",
      "Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 0.041747\n",
      "Reconstruction: 0.027595, Regularization: 0.014152\n",
      "====> Epoch: 63 Average loss: 0.0450\n",
      "Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 0.048198\n",
      "Reconstruction: 0.029238, Regularization: 0.018960\n",
      "Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 0.040016\n",
      "Reconstruction: 0.026129, Regularization: 0.013886\n",
      "Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 0.035930\n",
      "Reconstruction: 0.022561, Regularization: 0.013369\n",
      "Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 0.045708\n",
      "Reconstruction: 0.027503, Regularization: 0.018205\n",
      "Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 0.036024\n",
      "Reconstruction: 0.023372, Regularization: 0.012652\n",
      "Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 0.040992\n",
      "Reconstruction: 0.025223, Regularization: 0.015769\n",
      "Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 0.045534\n",
      "Reconstruction: 0.026809, Regularization: 0.018725\n",
      "Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 0.046215\n",
      "Reconstruction: 0.026700, Regularization: 0.019515\n",
      "====> Epoch: 64 Average loss: 0.0450\n",
      "Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 0.042463\n",
      "Reconstruction: 0.023749, Regularization: 0.018714\n",
      "Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 0.045422\n",
      "Reconstruction: 0.022548, Regularization: 0.022874\n",
      "Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 0.044802\n",
      "Reconstruction: 0.027945, Regularization: 0.016857\n",
      "Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 0.050273\n",
      "Reconstruction: 0.028165, Regularization: 0.022109\n",
      "Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 0.051377\n",
      "Reconstruction: 0.028014, Regularization: 0.023362\n",
      "Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 0.049053\n",
      "Reconstruction: 0.031230, Regularization: 0.017823\n",
      "Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 0.047973\n",
      "Reconstruction: 0.028282, Regularization: 0.019691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 0.038985\n",
      "Reconstruction: 0.027129, Regularization: 0.011856\n",
      "====> Epoch: 65 Average loss: 0.0448\n",
      "Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 0.037812\n",
      "Reconstruction: 0.023443, Regularization: 0.014369\n",
      "Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 0.043406\n",
      "Reconstruction: 0.026424, Regularization: 0.016982\n",
      "Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 0.049122\n",
      "Reconstruction: 0.031412, Regularization: 0.017710\n",
      "Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 0.050106\n",
      "Reconstruction: 0.028227, Regularization: 0.021880\n",
      "Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 0.047739\n",
      "Reconstruction: 0.028544, Regularization: 0.019196\n",
      "Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 0.038311\n",
      "Reconstruction: 0.026028, Regularization: 0.012282\n",
      "Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 0.039622\n",
      "Reconstruction: 0.025871, Regularization: 0.013751\n",
      "Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 0.043796\n",
      "Reconstruction: 0.026749, Regularization: 0.017047\n",
      "====> Epoch: 66 Average loss: 0.0446\n",
      "Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 0.046895\n",
      "Reconstruction: 0.031035, Regularization: 0.015860\n",
      "Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 0.043596\n",
      "Reconstruction: 0.027417, Regularization: 0.016178\n",
      "Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 0.050607\n",
      "Reconstruction: 0.028318, Regularization: 0.022289\n",
      "Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 0.048158\n",
      "Reconstruction: 0.029455, Regularization: 0.018703\n",
      "Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 0.043455\n",
      "Reconstruction: 0.028423, Regularization: 0.015032\n",
      "Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 0.045049\n",
      "Reconstruction: 0.027327, Regularization: 0.017723\n",
      "Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 0.049505\n",
      "Reconstruction: 0.027072, Regularization: 0.022433\n",
      "Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 0.037091\n",
      "Reconstruction: 0.024042, Regularization: 0.013049\n",
      "====> Epoch: 67 Average loss: 0.0445\n",
      "Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 0.048908\n",
      "Reconstruction: 0.028801, Regularization: 0.020108\n",
      "Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 0.039860\n",
      "Reconstruction: 0.025054, Regularization: 0.014805\n",
      "Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 0.044429\n",
      "Reconstruction: 0.025741, Regularization: 0.018689\n",
      "Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 0.041702\n",
      "Reconstruction: 0.027211, Regularization: 0.014491\n",
      "Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 0.038856\n",
      "Reconstruction: 0.026797, Regularization: 0.012059\n",
      "Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 0.036377\n",
      "Reconstruction: 0.022060, Regularization: 0.014317\n",
      "Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 0.043790\n",
      "Reconstruction: 0.029055, Regularization: 0.014735\n",
      "Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 0.041060\n",
      "Reconstruction: 0.025426, Regularization: 0.015634\n",
      "====> Epoch: 68 Average loss: 0.0439\n",
      "Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 0.040958\n",
      "Reconstruction: 0.027197, Regularization: 0.013761\n",
      "Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 0.035942\n",
      "Reconstruction: 0.025300, Regularization: 0.010642\n",
      "Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 0.041166\n",
      "Reconstruction: 0.027282, Regularization: 0.013884\n",
      "Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 0.043785\n",
      "Reconstruction: 0.031309, Regularization: 0.012476\n",
      "Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 0.039509\n",
      "Reconstruction: 0.027108, Regularization: 0.012401\n",
      "Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 0.041933\n",
      "Reconstruction: 0.026435, Regularization: 0.015498\n",
      "Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 0.039287\n",
      "Reconstruction: 0.024901, Regularization: 0.014386\n",
      "Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 0.046586\n",
      "Reconstruction: 0.030464, Regularization: 0.016122\n",
      "====> Epoch: 69 Average loss: 0.0436\n",
      "Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 0.056736\n",
      "Reconstruction: 0.033271, Regularization: 0.023466\n",
      "Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 0.042823\n",
      "Reconstruction: 0.026484, Regularization: 0.016339\n",
      "Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 0.051267\n",
      "Reconstruction: 0.031265, Regularization: 0.020002\n",
      "Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 0.043668\n",
      "Reconstruction: 0.027263, Regularization: 0.016406\n",
      "Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 0.042879\n",
      "Reconstruction: 0.029162, Regularization: 0.013717\n",
      "Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 0.037632\n",
      "Reconstruction: 0.025523, Regularization: 0.012109\n",
      "Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 0.040632\n",
      "Reconstruction: 0.026883, Regularization: 0.013749\n",
      "Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 0.045156\n",
      "Reconstruction: 0.029238, Regularization: 0.015918\n",
      "====> Epoch: 70 Average loss: 0.0436\n",
      "Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 0.051470\n",
      "Reconstruction: 0.032527, Regularization: 0.018943\n",
      "Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 0.041420\n",
      "Reconstruction: 0.026422, Regularization: 0.014998\n",
      "Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 0.043345\n",
      "Reconstruction: 0.029095, Regularization: 0.014249\n",
      "Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 0.035994\n",
      "Reconstruction: 0.025031, Regularization: 0.010963\n",
      "Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 0.045697\n",
      "Reconstruction: 0.029618, Regularization: 0.016079\n",
      "Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 0.035338\n",
      "Reconstruction: 0.024964, Regularization: 0.010374\n",
      "Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 0.049073\n",
      "Reconstruction: 0.029047, Regularization: 0.020026\n",
      "Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 0.034243\n",
      "Reconstruction: 0.024182, Regularization: 0.010061\n",
      "====> Epoch: 71 Average loss: 0.0428\n",
      "Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 0.050795\n",
      "Reconstruction: 0.031618, Regularization: 0.019177\n",
      "Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 0.049448\n",
      "Reconstruction: 0.031201, Regularization: 0.018247\n",
      "Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 0.038786\n",
      "Reconstruction: 0.026554, Regularization: 0.012232\n",
      "Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 0.047978\n",
      "Reconstruction: 0.029530, Regularization: 0.018448\n",
      "Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 0.041763\n",
      "Reconstruction: 0.027414, Regularization: 0.014349\n",
      "Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 0.039716\n",
      "Reconstruction: 0.026173, Regularization: 0.013543\n",
      "Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 0.043576\n",
      "Reconstruction: 0.026259, Regularization: 0.017317\n",
      "Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 0.050058\n",
      "Reconstruction: 0.031341, Regularization: 0.018716\n",
      "====> Epoch: 72 Average loss: 0.0428\n",
      "Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 0.036545\n",
      "Reconstruction: 0.024731, Regularization: 0.011814\n",
      "Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 0.056050\n",
      "Reconstruction: 0.036780, Regularization: 0.019270\n",
      "Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 0.043586\n",
      "Reconstruction: 0.028686, Regularization: 0.014900\n",
      "Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 0.043170\n",
      "Reconstruction: 0.026309, Regularization: 0.016861\n",
      "Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 0.037711\n",
      "Reconstruction: 0.024390, Regularization: 0.013321\n",
      "Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 0.050017\n",
      "Reconstruction: 0.032048, Regularization: 0.017969\n",
      "Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 0.038496\n",
      "Reconstruction: 0.026318, Regularization: 0.012179\n",
      "Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 0.039675\n",
      "Reconstruction: 0.026323, Regularization: 0.013351\n",
      "====> Epoch: 73 Average loss: 0.0428\n",
      "Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 0.040135\n",
      "Reconstruction: 0.026303, Regularization: 0.013832\n",
      "Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 0.044523\n",
      "Reconstruction: 0.029102, Regularization: 0.015422\n",
      "Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 0.038035\n",
      "Reconstruction: 0.025570, Regularization: 0.012464\n",
      "Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 0.037472\n",
      "Reconstruction: 0.027080, Regularization: 0.010392\n",
      "Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 0.035011\n",
      "Reconstruction: 0.026049, Regularization: 0.008962\n",
      "Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 0.049987\n",
      "Reconstruction: 0.032996, Regularization: 0.016992\n",
      "Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 0.038202\n",
      "Reconstruction: 0.025951, Regularization: 0.012252\n",
      "Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 0.044288\n",
      "Reconstruction: 0.029830, Regularization: 0.014458\n",
      "====> Epoch: 74 Average loss: 0.0425\n",
      "Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 0.043632\n",
      "Reconstruction: 0.029519, Regularization: 0.014113\n",
      "Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 0.037399\n",
      "Reconstruction: 0.026513, Regularization: 0.010886\n",
      "Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 0.048121\n",
      "Reconstruction: 0.030424, Regularization: 0.017697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 0.042521\n",
      "Reconstruction: 0.030286, Regularization: 0.012235\n",
      "Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 0.047204\n",
      "Reconstruction: 0.032038, Regularization: 0.015166\n",
      "Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 0.041959\n",
      "Reconstruction: 0.026960, Regularization: 0.014999\n",
      "Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 0.060044\n",
      "Reconstruction: 0.039562, Regularization: 0.020482\n",
      "Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 0.039161\n",
      "Reconstruction: 0.025795, Regularization: 0.013365\n",
      "====> Epoch: 75 Average loss: 0.0429\n",
      "Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 0.040343\n",
      "Reconstruction: 0.027833, Regularization: 0.012510\n",
      "Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 0.047348\n",
      "Reconstruction: 0.030785, Regularization: 0.016563\n",
      "Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 0.038438\n",
      "Reconstruction: 0.027237, Regularization: 0.011201\n",
      "Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 0.043319\n",
      "Reconstruction: 0.028534, Regularization: 0.014784\n",
      "Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 0.039264\n",
      "Reconstruction: 0.026728, Regularization: 0.012536\n",
      "Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 0.042569\n",
      "Reconstruction: 0.030451, Regularization: 0.012118\n",
      "Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 0.046459\n",
      "Reconstruction: 0.031665, Regularization: 0.014795\n",
      "Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 0.045486\n",
      "Reconstruction: 0.030738, Regularization: 0.014748\n",
      "====> Epoch: 76 Average loss: 0.0424\n",
      "Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 0.046787\n",
      "Reconstruction: 0.030381, Regularization: 0.016406\n",
      "Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 0.055576\n",
      "Reconstruction: 0.033260, Regularization: 0.022316\n",
      "Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 0.043657\n",
      "Reconstruction: 0.028686, Regularization: 0.014971\n",
      "Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 0.048320\n",
      "Reconstruction: 0.031625, Regularization: 0.016695\n",
      "Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 0.044024\n",
      "Reconstruction: 0.029645, Regularization: 0.014379\n",
      "Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 0.044699\n",
      "Reconstruction: 0.029143, Regularization: 0.015556\n",
      "Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 0.035815\n",
      "Reconstruction: 0.024955, Regularization: 0.010860\n",
      "Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 0.040791\n",
      "Reconstruction: 0.026335, Regularization: 0.014456\n",
      "====> Epoch: 77 Average loss: 0.0426\n",
      "Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 0.046300\n",
      "Reconstruction: 0.031169, Regularization: 0.015131\n",
      "Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 0.031102\n",
      "Reconstruction: 0.023720, Regularization: 0.007383\n",
      "Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 0.046380\n",
      "Reconstruction: 0.032379, Regularization: 0.014001\n",
      "Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 0.039294\n",
      "Reconstruction: 0.028472, Regularization: 0.010823\n",
      "Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 0.049956\n",
      "Reconstruction: 0.031285, Regularization: 0.018671\n",
      "Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 0.037705\n",
      "Reconstruction: 0.025763, Regularization: 0.011942\n",
      "Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 0.040128\n",
      "Reconstruction: 0.027535, Regularization: 0.012594\n",
      "Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 0.046406\n",
      "Reconstruction: 0.033693, Regularization: 0.012713\n",
      "====> Epoch: 78 Average loss: 0.0423\n",
      "Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 0.046871\n",
      "Reconstruction: 0.030433, Regularization: 0.016438\n",
      "Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 0.039376\n",
      "Reconstruction: 0.027414, Regularization: 0.011962\n",
      "Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 0.050353\n",
      "Reconstruction: 0.034559, Regularization: 0.015793\n",
      "Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 0.039305\n",
      "Reconstruction: 0.028295, Regularization: 0.011010\n",
      "Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 0.045577\n",
      "Reconstruction: 0.031210, Regularization: 0.014367\n",
      "Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 0.039602\n",
      "Reconstruction: 0.027911, Regularization: 0.011691\n",
      "Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 0.039460\n",
      "Reconstruction: 0.028378, Regularization: 0.011081\n",
      "Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 0.041960\n",
      "Reconstruction: 0.030363, Regularization: 0.011597\n",
      "====> Epoch: 79 Average loss: 0.0421\n",
      "Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 0.041909\n",
      "Reconstruction: 0.027848, Regularization: 0.014061\n",
      "Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 0.042120\n",
      "Reconstruction: 0.031788, Regularization: 0.010333\n",
      "Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 0.047384\n",
      "Reconstruction: 0.032720, Regularization: 0.014664\n",
      "Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 0.041613\n",
      "Reconstruction: 0.028629, Regularization: 0.012984\n",
      "Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 0.050511\n",
      "Reconstruction: 0.035066, Regularization: 0.015445\n",
      "Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 0.042977\n",
      "Reconstruction: 0.032324, Regularization: 0.010653\n",
      "Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 0.045566\n",
      "Reconstruction: 0.031098, Regularization: 0.014467\n",
      "Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 0.043779\n",
      "Reconstruction: 0.031347, Regularization: 0.012432\n",
      "====> Epoch: 80 Average loss: 0.0415\n",
      "Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 0.040669\n",
      "Reconstruction: 0.029008, Regularization: 0.011661\n",
      "Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 0.039663\n",
      "Reconstruction: 0.028466, Regularization: 0.011197\n",
      "Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 0.044061\n",
      "Reconstruction: 0.032104, Regularization: 0.011956\n",
      "Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 0.035761\n",
      "Reconstruction: 0.026379, Regularization: 0.009382\n",
      "Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 0.043793\n",
      "Reconstruction: 0.032841, Regularization: 0.010952\n",
      "Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 0.032530\n",
      "Reconstruction: 0.023186, Regularization: 0.009344\n",
      "Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 0.037665\n",
      "Reconstruction: 0.026060, Regularization: 0.011604\n",
      "Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 0.049588\n",
      "Reconstruction: 0.034850, Regularization: 0.014737\n",
      "====> Epoch: 81 Average loss: 0.0421\n",
      "Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 0.043226\n",
      "Reconstruction: 0.030864, Regularization: 0.012362\n",
      "Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 0.043959\n",
      "Reconstruction: 0.030479, Regularization: 0.013480\n",
      "Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 0.044492\n",
      "Reconstruction: 0.032897, Regularization: 0.011594\n",
      "Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 0.051152\n",
      "Reconstruction: 0.036302, Regularization: 0.014850\n",
      "Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 0.034872\n",
      "Reconstruction: 0.026561, Regularization: 0.008310\n",
      "Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 0.046124\n",
      "Reconstruction: 0.032657, Regularization: 0.013467\n",
      "Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 0.038092\n",
      "Reconstruction: 0.027049, Regularization: 0.011044\n",
      "Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 0.039278\n",
      "Reconstruction: 0.028499, Regularization: 0.010779\n",
      "====> Epoch: 82 Average loss: 0.0419\n",
      "Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 0.039333\n",
      "Reconstruction: 0.030260, Regularization: 0.009073\n",
      "Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 0.050396\n",
      "Reconstruction: 0.036283, Regularization: 0.014113\n",
      "Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 0.038512\n",
      "Reconstruction: 0.030104, Regularization: 0.008408\n",
      "Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 0.036856\n",
      "Reconstruction: 0.027112, Regularization: 0.009744\n",
      "Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 0.032418\n",
      "Reconstruction: 0.024200, Regularization: 0.008219\n",
      "Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 0.044527\n",
      "Reconstruction: 0.032332, Regularization: 0.012194\n",
      "Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 0.038231\n",
      "Reconstruction: 0.027922, Regularization: 0.010308\n",
      "Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 0.041378\n",
      "Reconstruction: 0.032187, Regularization: 0.009191\n",
      "====> Epoch: 83 Average loss: 0.0423\n",
      "Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 0.045507\n",
      "Reconstruction: 0.031661, Regularization: 0.013846\n",
      "Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 0.045958\n",
      "Reconstruction: 0.032248, Regularization: 0.013709\n",
      "Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 0.046241\n",
      "Reconstruction: 0.034122, Regularization: 0.012120\n",
      "Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 0.045644\n",
      "Reconstruction: 0.031876, Regularization: 0.013769\n",
      "Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 0.036347\n",
      "Reconstruction: 0.028700, Regularization: 0.007647\n",
      "Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 0.046936\n",
      "Reconstruction: 0.034377, Regularization: 0.012559\n",
      "Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 0.042138\n",
      "Reconstruction: 0.030086, Regularization: 0.012051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 0.043194\n",
      "Reconstruction: 0.032973, Regularization: 0.010222\n",
      "====> Epoch: 84 Average loss: 0.0420\n",
      "Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 0.038698\n",
      "Reconstruction: 0.028407, Regularization: 0.010291\n",
      "Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 0.048737\n",
      "Reconstruction: 0.035845, Regularization: 0.012891\n",
      "Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 0.038712\n",
      "Reconstruction: 0.027931, Regularization: 0.010781\n",
      "Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 0.040001\n",
      "Reconstruction: 0.029537, Regularization: 0.010464\n",
      "Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 0.044660\n",
      "Reconstruction: 0.031610, Regularization: 0.013050\n",
      "Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 0.038604\n",
      "Reconstruction: 0.028996, Regularization: 0.009608\n",
      "Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 0.042741\n",
      "Reconstruction: 0.029843, Regularization: 0.012899\n",
      "Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 0.043077\n",
      "Reconstruction: 0.031869, Regularization: 0.011209\n",
      "====> Epoch: 85 Average loss: 0.0415\n",
      "Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 0.038974\n",
      "Reconstruction: 0.028938, Regularization: 0.010036\n",
      "Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 0.049186\n",
      "Reconstruction: 0.038241, Regularization: 0.010945\n",
      "Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 0.037011\n",
      "Reconstruction: 0.025789, Regularization: 0.011222\n",
      "Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 0.042058\n",
      "Reconstruction: 0.031024, Regularization: 0.011034\n",
      "Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 0.046567\n",
      "Reconstruction: 0.032208, Regularization: 0.014359\n",
      "Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 0.042963\n",
      "Reconstruction: 0.031147, Regularization: 0.011816\n",
      "Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 0.044117\n",
      "Reconstruction: 0.031417, Regularization: 0.012700\n",
      "Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 0.041171\n",
      "Reconstruction: 0.030297, Regularization: 0.010874\n",
      "====> Epoch: 86 Average loss: 0.0415\n",
      "Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 0.034204\n",
      "Reconstruction: 0.026499, Regularization: 0.007706\n",
      "Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 0.040307\n",
      "Reconstruction: 0.028562, Regularization: 0.011745\n",
      "Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 0.038460\n",
      "Reconstruction: 0.028968, Regularization: 0.009492\n",
      "Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 0.044012\n",
      "Reconstruction: 0.034235, Regularization: 0.009777\n",
      "Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 0.043308\n",
      "Reconstruction: 0.031801, Regularization: 0.011507\n",
      "Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 0.044418\n",
      "Reconstruction: 0.031977, Regularization: 0.012441\n",
      "Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 0.037582\n",
      "Reconstruction: 0.029147, Regularization: 0.008435\n",
      "Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 0.036614\n",
      "Reconstruction: 0.026975, Regularization: 0.009639\n",
      "====> Epoch: 87 Average loss: 0.0416\n",
      "Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 0.040679\n",
      "Reconstruction: 0.031269, Regularization: 0.009410\n",
      "Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 0.044797\n",
      "Reconstruction: 0.034999, Regularization: 0.009798\n",
      "Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 0.043821\n",
      "Reconstruction: 0.032343, Regularization: 0.011478\n",
      "Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 0.043203\n",
      "Reconstruction: 0.031798, Regularization: 0.011405\n",
      "Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 0.045051\n",
      "Reconstruction: 0.033790, Regularization: 0.011261\n",
      "Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 0.049830\n",
      "Reconstruction: 0.035907, Regularization: 0.013922\n",
      "Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 0.036263\n",
      "Reconstruction: 0.027846, Regularization: 0.008418\n",
      "Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 0.040939\n",
      "Reconstruction: 0.032095, Regularization: 0.008844\n",
      "====> Epoch: 88 Average loss: 0.0411\n",
      "Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 0.042201\n",
      "Reconstruction: 0.030316, Regularization: 0.011886\n",
      "Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 0.043592\n",
      "Reconstruction: 0.031314, Regularization: 0.012278\n",
      "Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 0.041943\n",
      "Reconstruction: 0.031970, Regularization: 0.009973\n",
      "Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 0.040648\n",
      "Reconstruction: 0.030030, Regularization: 0.010618\n",
      "Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 0.035299\n",
      "Reconstruction: 0.026732, Regularization: 0.008567\n",
      "Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 0.035186\n",
      "Reconstruction: 0.027063, Regularization: 0.008124\n",
      "Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 0.038262\n",
      "Reconstruction: 0.027318, Regularization: 0.010944\n",
      "Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 0.042080\n",
      "Reconstruction: 0.032392, Regularization: 0.009689\n",
      "====> Epoch: 89 Average loss: 0.0412\n",
      "Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 0.044843\n",
      "Reconstruction: 0.032707, Regularization: 0.012135\n",
      "Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 0.037740\n",
      "Reconstruction: 0.029732, Regularization: 0.008008\n",
      "Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 0.054467\n",
      "Reconstruction: 0.040943, Regularization: 0.013524\n",
      "Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 0.042261\n",
      "Reconstruction: 0.031355, Regularization: 0.010906\n",
      "Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 0.046409\n",
      "Reconstruction: 0.035614, Regularization: 0.010795\n",
      "Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 0.040915\n",
      "Reconstruction: 0.032239, Regularization: 0.008676\n",
      "Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 0.039939\n",
      "Reconstruction: 0.031570, Regularization: 0.008369\n",
      "Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 0.045434\n",
      "Reconstruction: 0.033797, Regularization: 0.011637\n",
      "====> Epoch: 90 Average loss: 0.0415\n",
      "Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 0.049937\n",
      "Reconstruction: 0.037450, Regularization: 0.012487\n",
      "Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 0.042666\n",
      "Reconstruction: 0.032324, Regularization: 0.010342\n",
      "Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 0.035685\n",
      "Reconstruction: 0.027316, Regularization: 0.008369\n",
      "Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 0.046939\n",
      "Reconstruction: 0.034661, Regularization: 0.012278\n",
      "Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 0.040583\n",
      "Reconstruction: 0.030432, Regularization: 0.010151\n",
      "Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 0.043618\n",
      "Reconstruction: 0.031294, Regularization: 0.012324\n",
      "Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 0.046076\n",
      "Reconstruction: 0.034581, Regularization: 0.011495\n",
      "Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 0.037732\n",
      "Reconstruction: 0.029626, Regularization: 0.008106\n",
      "====> Epoch: 91 Average loss: 0.0415\n",
      "Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 0.039884\n",
      "Reconstruction: 0.030578, Regularization: 0.009306\n",
      "Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 0.041140\n",
      "Reconstruction: 0.030251, Regularization: 0.010889\n",
      "Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 0.041950\n",
      "Reconstruction: 0.030811, Regularization: 0.011139\n",
      "Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 0.041916\n",
      "Reconstruction: 0.033266, Regularization: 0.008650\n",
      "Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 0.045784\n",
      "Reconstruction: 0.035042, Regularization: 0.010741\n",
      "Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 0.036917\n",
      "Reconstruction: 0.028307, Regularization: 0.008611\n",
      "Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 0.040137\n",
      "Reconstruction: 0.030926, Regularization: 0.009210\n",
      "Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 0.042321\n",
      "Reconstruction: 0.030808, Regularization: 0.011514\n",
      "====> Epoch: 92 Average loss: 0.0417\n",
      "Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 0.039493\n",
      "Reconstruction: 0.029331, Regularization: 0.010162\n",
      "Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 0.041129\n",
      "Reconstruction: 0.031343, Regularization: 0.009786\n",
      "Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 0.050001\n",
      "Reconstruction: 0.037800, Regularization: 0.012202\n",
      "Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 0.042901\n",
      "Reconstruction: 0.033142, Regularization: 0.009759\n",
      "Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 0.048283\n",
      "Reconstruction: 0.033726, Regularization: 0.014557\n",
      "Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 0.037083\n",
      "Reconstruction: 0.028393, Regularization: 0.008690\n",
      "Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 0.042533\n",
      "Reconstruction: 0.032490, Regularization: 0.010043\n",
      "Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 0.039799\n",
      "Reconstruction: 0.030803, Regularization: 0.008996\n",
      "====> Epoch: 93 Average loss: 0.0412\n",
      "Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 0.047734\n",
      "Reconstruction: 0.036836, Regularization: 0.010898\n",
      "Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 0.038783\n",
      "Reconstruction: 0.029663, Regularization: 0.009120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 0.048475\n",
      "Reconstruction: 0.037410, Regularization: 0.011065\n",
      "Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 0.036627\n",
      "Reconstruction: 0.028852, Regularization: 0.007775\n",
      "Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 0.044308\n",
      "Reconstruction: 0.034788, Regularization: 0.009520\n",
      "Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 0.046273\n",
      "Reconstruction: 0.032563, Regularization: 0.013710\n",
      "Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 0.037475\n",
      "Reconstruction: 0.028851, Regularization: 0.008624\n",
      "Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 0.038509\n",
      "Reconstruction: 0.028316, Regularization: 0.010193\n",
      "====> Epoch: 94 Average loss: 0.0410\n",
      "Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 0.039944\n",
      "Reconstruction: 0.031577, Regularization: 0.008367\n",
      "Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 0.045133\n",
      "Reconstruction: 0.033373, Regularization: 0.011761\n",
      "Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 0.038593\n",
      "Reconstruction: 0.030324, Regularization: 0.008269\n",
      "Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 0.042563\n",
      "Reconstruction: 0.031783, Regularization: 0.010780\n",
      "Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 0.047777\n",
      "Reconstruction: 0.034671, Regularization: 0.013107\n",
      "Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 0.041675\n",
      "Reconstruction: 0.031819, Regularization: 0.009856\n",
      "Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 0.044336\n",
      "Reconstruction: 0.032760, Regularization: 0.011576\n",
      "Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 0.036063\n",
      "Reconstruction: 0.028465, Regularization: 0.007598\n",
      "====> Epoch: 95 Average loss: 0.0412\n",
      "Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 0.044225\n",
      "Reconstruction: 0.032685, Regularization: 0.011540\n",
      "Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 0.046369\n",
      "Reconstruction: 0.035997, Regularization: 0.010372\n",
      "Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 0.040080\n",
      "Reconstruction: 0.031966, Regularization: 0.008114\n",
      "Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 0.035725\n",
      "Reconstruction: 0.028654, Regularization: 0.007071\n",
      "Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 0.034336\n",
      "Reconstruction: 0.026025, Regularization: 0.008310\n",
      "Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 0.038418\n",
      "Reconstruction: 0.029793, Regularization: 0.008625\n",
      "Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 0.038837\n",
      "Reconstruction: 0.030546, Regularization: 0.008291\n",
      "Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 0.037570\n",
      "Reconstruction: 0.030399, Regularization: 0.007171\n",
      "====> Epoch: 96 Average loss: 0.0414\n",
      "Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 0.040965\n",
      "Reconstruction: 0.031744, Regularization: 0.009222\n",
      "Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 0.042824\n",
      "Reconstruction: 0.031101, Regularization: 0.011723\n",
      "Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 0.049317\n",
      "Reconstruction: 0.036224, Regularization: 0.013093\n",
      "Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 0.036196\n",
      "Reconstruction: 0.028914, Regularization: 0.007282\n",
      "Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 0.040391\n",
      "Reconstruction: 0.030507, Regularization: 0.009884\n",
      "Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 0.039083\n",
      "Reconstruction: 0.029747, Regularization: 0.009336\n",
      "Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 0.040539\n",
      "Reconstruction: 0.031490, Regularization: 0.009050\n",
      "Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 0.044442\n",
      "Reconstruction: 0.033979, Regularization: 0.010463\n",
      "====> Epoch: 97 Average loss: 0.0412\n",
      "Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 0.045254\n",
      "Reconstruction: 0.031391, Regularization: 0.013863\n",
      "Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 0.043264\n",
      "Reconstruction: 0.033266, Regularization: 0.009997\n",
      "Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 0.040150\n",
      "Reconstruction: 0.029507, Regularization: 0.010643\n",
      "Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 0.038624\n",
      "Reconstruction: 0.031672, Regularization: 0.006951\n",
      "Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 0.045499\n",
      "Reconstruction: 0.033719, Regularization: 0.011780\n",
      "Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 0.039463\n",
      "Reconstruction: 0.029676, Regularization: 0.009787\n",
      "Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 0.038202\n",
      "Reconstruction: 0.029043, Regularization: 0.009159\n",
      "Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 0.040056\n",
      "Reconstruction: 0.030142, Regularization: 0.009914\n",
      "====> Epoch: 98 Average loss: 0.0416\n",
      "Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 0.034498\n",
      "Reconstruction: 0.025923, Regularization: 0.008576\n",
      "Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 0.050991\n",
      "Reconstruction: 0.036353, Regularization: 0.014638\n",
      "Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 0.041654\n",
      "Reconstruction: 0.032037, Regularization: 0.009617\n",
      "Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 0.042772\n",
      "Reconstruction: 0.032055, Regularization: 0.010717\n",
      "Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 0.037974\n",
      "Reconstruction: 0.029014, Regularization: 0.008960\n",
      "Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 0.040310\n",
      "Reconstruction: 0.028407, Regularization: 0.011904\n",
      "Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 0.049766\n",
      "Reconstruction: 0.035436, Regularization: 0.014331\n",
      "Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 0.041001\n",
      "Reconstruction: 0.030316, Regularization: 0.010685\n",
      "====> Epoch: 99 Average loss: 0.0410\n",
      "Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 0.038469\n",
      "Reconstruction: 0.028667, Regularization: 0.009802\n",
      "Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 0.046525\n",
      "Reconstruction: 0.036061, Regularization: 0.010464\n",
      "Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 0.042123\n",
      "Reconstruction: 0.032298, Regularization: 0.009826\n",
      "Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 0.042757\n",
      "Reconstruction: 0.033085, Regularization: 0.009672\n",
      "Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 0.038668\n",
      "Reconstruction: 0.029671, Regularization: 0.008997\n",
      "Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 0.037677\n",
      "Reconstruction: 0.030569, Regularization: 0.007108\n",
      "Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 0.049215\n",
      "Reconstruction: 0.037490, Regularization: 0.011725\n",
      "Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 0.043828\n",
      "Reconstruction: 0.034262, Regularization: 0.009566\n",
      "====> Epoch: 100 Average loss: 0.0410\n",
      "Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 0.044002\n",
      "Reconstruction: 0.033416, Regularization: 0.010586\n",
      "Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 0.044009\n",
      "Reconstruction: 0.032568, Regularization: 0.011441\n",
      "Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 0.040433\n",
      "Reconstruction: 0.031124, Regularization: 0.009310\n",
      "Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 0.041139\n",
      "Reconstruction: 0.033122, Regularization: 0.008017\n",
      "Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 0.045000\n",
      "Reconstruction: 0.034443, Regularization: 0.010557\n",
      "Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 0.038117\n",
      "Reconstruction: 0.029973, Regularization: 0.008143\n",
      "Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 0.038909\n",
      "Reconstruction: 0.029487, Regularization: 0.009422\n",
      "Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 0.042369\n",
      "Reconstruction: 0.033060, Regularization: 0.009309\n",
      "====> Epoch: 101 Average loss: 0.0413\n",
      "Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 0.048193\n",
      "Reconstruction: 0.037557, Regularization: 0.010637\n",
      "Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 0.035598\n",
      "Reconstruction: 0.029497, Regularization: 0.006102\n",
      "Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 0.038132\n",
      "Reconstruction: 0.031090, Regularization: 0.007043\n",
      "Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 0.043341\n",
      "Reconstruction: 0.034745, Regularization: 0.008596\n",
      "Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 0.042147\n",
      "Reconstruction: 0.032951, Regularization: 0.009197\n",
      "Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 0.052808\n",
      "Reconstruction: 0.038082, Regularization: 0.014726\n",
      "Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 0.038471\n",
      "Reconstruction: 0.030776, Regularization: 0.007695\n",
      "Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 0.044776\n",
      "Reconstruction: 0.033585, Regularization: 0.011191\n",
      "====> Epoch: 102 Average loss: 0.0411\n",
      "Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 0.038361\n",
      "Reconstruction: 0.028419, Regularization: 0.009942\n",
      "Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 0.048910\n",
      "Reconstruction: 0.036473, Regularization: 0.012438\n",
      "Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 0.040967\n",
      "Reconstruction: 0.032189, Regularization: 0.008778\n",
      "Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 0.035742\n",
      "Reconstruction: 0.026809, Regularization: 0.008933\n",
      "Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 0.044667\n",
      "Reconstruction: 0.033132, Regularization: 0.011535\n",
      "Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 0.047218\n",
      "Reconstruction: 0.033126, Regularization: 0.014092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 0.040473\n",
      "Reconstruction: 0.030199, Regularization: 0.010273\n",
      "Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 0.037540\n",
      "Reconstruction: 0.028688, Regularization: 0.008852\n",
      "====> Epoch: 103 Average loss: 0.0414\n",
      "Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 0.038322\n",
      "Reconstruction: 0.029560, Regularization: 0.008763\n",
      "Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 0.043086\n",
      "Reconstruction: 0.032830, Regularization: 0.010257\n",
      "Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 0.043353\n",
      "Reconstruction: 0.034110, Regularization: 0.009244\n",
      "Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 0.048023\n",
      "Reconstruction: 0.037572, Regularization: 0.010451\n",
      "Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 0.037167\n",
      "Reconstruction: 0.028713, Regularization: 0.008455\n",
      "Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 0.030788\n",
      "Reconstruction: 0.023940, Regularization: 0.006849\n",
      "Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 0.039468\n",
      "Reconstruction: 0.030006, Regularization: 0.009462\n",
      "Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 0.044546\n",
      "Reconstruction: 0.033693, Regularization: 0.010853\n",
      "====> Epoch: 104 Average loss: 0.0413\n",
      "Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 0.038751\n",
      "Reconstruction: 0.027976, Regularization: 0.010775\n",
      "Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 0.036719\n",
      "Reconstruction: 0.028409, Regularization: 0.008311\n",
      "Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 0.042957\n",
      "Reconstruction: 0.032994, Regularization: 0.009963\n",
      "Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 0.037676\n",
      "Reconstruction: 0.027884, Regularization: 0.009792\n",
      "Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 0.038235\n",
      "Reconstruction: 0.030216, Regularization: 0.008019\n",
      "Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 0.041739\n",
      "Reconstruction: 0.030992, Regularization: 0.010747\n",
      "Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 0.040218\n",
      "Reconstruction: 0.029992, Regularization: 0.010227\n",
      "Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 0.044936\n",
      "Reconstruction: 0.035447, Regularization: 0.009489\n",
      "====> Epoch: 105 Average loss: 0.0410\n",
      "Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 0.043693\n",
      "Reconstruction: 0.033464, Regularization: 0.010229\n",
      "Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 0.039331\n",
      "Reconstruction: 0.030700, Regularization: 0.008631\n",
      "Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 0.038509\n",
      "Reconstruction: 0.029368, Regularization: 0.009142\n",
      "Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 0.039691\n",
      "Reconstruction: 0.032058, Regularization: 0.007633\n",
      "Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 0.037108\n",
      "Reconstruction: 0.027846, Regularization: 0.009262\n",
      "Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 0.035561\n",
      "Reconstruction: 0.029722, Regularization: 0.005839\n",
      "Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 0.039314\n",
      "Reconstruction: 0.030035, Regularization: 0.009278\n",
      "Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 0.037336\n",
      "Reconstruction: 0.028041, Regularization: 0.009295\n",
      "====> Epoch: 106 Average loss: 0.0412\n",
      "Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 0.045779\n",
      "Reconstruction: 0.036782, Regularization: 0.008998\n",
      "Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 0.039121\n",
      "Reconstruction: 0.030261, Regularization: 0.008860\n",
      "Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 0.036700\n",
      "Reconstruction: 0.027529, Regularization: 0.009170\n",
      "Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 0.043524\n",
      "Reconstruction: 0.033681, Regularization: 0.009843\n",
      "Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 0.042062\n",
      "Reconstruction: 0.031504, Regularization: 0.010558\n",
      "Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 0.042387\n",
      "Reconstruction: 0.032907, Regularization: 0.009480\n",
      "Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 0.042876\n",
      "Reconstruction: 0.031745, Regularization: 0.011131\n",
      "Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 0.042213\n",
      "Reconstruction: 0.031481, Regularization: 0.010731\n",
      "====> Epoch: 107 Average loss: 0.0415\n",
      "Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 0.042052\n",
      "Reconstruction: 0.032635, Regularization: 0.009417\n",
      "Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 0.042385\n",
      "Reconstruction: 0.033674, Regularization: 0.008710\n",
      "Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 0.038276\n",
      "Reconstruction: 0.031304, Regularization: 0.006972\n",
      "Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 0.034376\n",
      "Reconstruction: 0.026944, Regularization: 0.007432\n",
      "Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 0.040945\n",
      "Reconstruction: 0.032424, Regularization: 0.008521\n",
      "Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 0.039539\n",
      "Reconstruction: 0.029363, Regularization: 0.010175\n",
      "Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 0.038281\n",
      "Reconstruction: 0.027587, Regularization: 0.010694\n",
      "Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 0.038246\n",
      "Reconstruction: 0.029839, Regularization: 0.008407\n",
      "====> Epoch: 108 Average loss: 0.0413\n",
      "Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 0.047321\n",
      "Reconstruction: 0.035691, Regularization: 0.011630\n",
      "Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 0.043727\n",
      "Reconstruction: 0.035028, Regularization: 0.008699\n",
      "Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 0.040719\n",
      "Reconstruction: 0.030844, Regularization: 0.009875\n",
      "Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 0.039177\n",
      "Reconstruction: 0.029700, Regularization: 0.009477\n",
      "Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 0.044285\n",
      "Reconstruction: 0.034329, Regularization: 0.009955\n",
      "Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 0.047705\n",
      "Reconstruction: 0.035697, Regularization: 0.012008\n",
      "Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 0.040167\n",
      "Reconstruction: 0.028341, Regularization: 0.011826\n",
      "Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 0.039347\n",
      "Reconstruction: 0.031386, Regularization: 0.007962\n",
      "====> Epoch: 109 Average loss: 0.0413\n",
      "Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 0.043709\n",
      "Reconstruction: 0.035051, Regularization: 0.008658\n",
      "Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 0.036986\n",
      "Reconstruction: 0.027342, Regularization: 0.009644\n",
      "Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 0.037602\n",
      "Reconstruction: 0.028014, Regularization: 0.009589\n",
      "Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 0.041611\n",
      "Reconstruction: 0.030467, Regularization: 0.011144\n",
      "Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 0.041779\n",
      "Reconstruction: 0.033337, Regularization: 0.008443\n",
      "Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 0.039790\n",
      "Reconstruction: 0.029416, Regularization: 0.010373\n",
      "Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 0.046353\n",
      "Reconstruction: 0.033460, Regularization: 0.012893\n",
      "Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 0.042321\n",
      "Reconstruction: 0.033486, Regularization: 0.008834\n",
      "====> Epoch: 110 Average loss: 0.0411\n",
      "Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 0.053761\n",
      "Reconstruction: 0.039912, Regularization: 0.013849\n",
      "Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 0.039448\n",
      "Reconstruction: 0.031260, Regularization: 0.008188\n",
      "Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 0.039654\n",
      "Reconstruction: 0.030629, Regularization: 0.009025\n",
      "Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 0.045562\n",
      "Reconstruction: 0.034603, Regularization: 0.010959\n",
      "Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 0.045075\n",
      "Reconstruction: 0.035821, Regularization: 0.009254\n",
      "Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 0.043380\n",
      "Reconstruction: 0.032388, Regularization: 0.010992\n",
      "Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 0.040979\n",
      "Reconstruction: 0.030245, Regularization: 0.010734\n",
      "Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 0.046540\n",
      "Reconstruction: 0.032891, Regularization: 0.013649\n",
      "====> Epoch: 111 Average loss: 0.0413\n",
      "Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 0.034387\n",
      "Reconstruction: 0.024795, Regularization: 0.009592\n",
      "Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 0.049106\n",
      "Reconstruction: 0.037563, Regularization: 0.011543\n",
      "Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 0.042384\n",
      "Reconstruction: 0.031944, Regularization: 0.010440\n",
      "Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 0.051054\n",
      "Reconstruction: 0.035873, Regularization: 0.015181\n",
      "Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 0.042865\n",
      "Reconstruction: 0.035186, Regularization: 0.007678\n",
      "Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 0.042494\n",
      "Reconstruction: 0.031774, Regularization: 0.010720\n",
      "Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 0.036880\n",
      "Reconstruction: 0.030713, Regularization: 0.006167\n",
      "Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 0.043126\n",
      "Reconstruction: 0.033044, Regularization: 0.010082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 112 Average loss: 0.0408\n",
      "Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 0.039638\n",
      "Reconstruction: 0.030018, Regularization: 0.009620\n",
      "Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 0.035976\n",
      "Reconstruction: 0.028467, Regularization: 0.007509\n",
      "Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 0.037668\n",
      "Reconstruction: 0.027989, Regularization: 0.009679\n",
      "Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 0.036466\n",
      "Reconstruction: 0.029699, Regularization: 0.006767\n",
      "Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 0.041307\n",
      "Reconstruction: 0.030597, Regularization: 0.010710\n",
      "Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 0.037849\n",
      "Reconstruction: 0.030916, Regularization: 0.006932\n",
      "Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 0.042680\n",
      "Reconstruction: 0.031877, Regularization: 0.010803\n",
      "Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 0.040821\n",
      "Reconstruction: 0.032273, Regularization: 0.008548\n",
      "====> Epoch: 113 Average loss: 0.0411\n",
      "Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 0.036460\n",
      "Reconstruction: 0.028253, Regularization: 0.008207\n",
      "Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 0.041175\n",
      "Reconstruction: 0.031554, Regularization: 0.009621\n",
      "Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 0.042489\n",
      "Reconstruction: 0.032354, Regularization: 0.010135\n",
      "Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 0.035258\n",
      "Reconstruction: 0.027318, Regularization: 0.007940\n",
      "Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 0.046129\n",
      "Reconstruction: 0.034552, Regularization: 0.011577\n",
      "Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 0.036601\n",
      "Reconstruction: 0.029531, Regularization: 0.007070\n",
      "Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 0.044368\n",
      "Reconstruction: 0.033864, Regularization: 0.010504\n",
      "Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 0.050102\n",
      "Reconstruction: 0.037991, Regularization: 0.012111\n",
      "====> Epoch: 114 Average loss: 0.0413\n",
      "Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 0.037015\n",
      "Reconstruction: 0.029395, Regularization: 0.007621\n",
      "Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 0.038356\n",
      "Reconstruction: 0.030320, Regularization: 0.008036\n",
      "Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 0.042554\n",
      "Reconstruction: 0.034423, Regularization: 0.008131\n",
      "Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 0.042923\n",
      "Reconstruction: 0.034039, Regularization: 0.008883\n",
      "Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 0.043564\n",
      "Reconstruction: 0.035294, Regularization: 0.008270\n",
      "Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 0.039756\n",
      "Reconstruction: 0.030236, Regularization: 0.009520\n",
      "Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 0.042024\n",
      "Reconstruction: 0.031690, Regularization: 0.010333\n",
      "Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 0.041801\n",
      "Reconstruction: 0.030398, Regularization: 0.011403\n",
      "====> Epoch: 115 Average loss: 0.0415\n",
      "Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 0.035126\n",
      "Reconstruction: 0.026877, Regularization: 0.008248\n",
      "Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 0.048327\n",
      "Reconstruction: 0.035534, Regularization: 0.012793\n",
      "Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 0.036373\n",
      "Reconstruction: 0.029247, Regularization: 0.007126\n",
      "Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 0.042896\n",
      "Reconstruction: 0.034762, Regularization: 0.008134\n",
      "Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 0.030657\n",
      "Reconstruction: 0.025018, Regularization: 0.005638\n",
      "Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 0.034778\n",
      "Reconstruction: 0.027417, Regularization: 0.007361\n",
      "Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 0.039117\n",
      "Reconstruction: 0.029719, Regularization: 0.009399\n",
      "Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 0.040272\n",
      "Reconstruction: 0.032340, Regularization: 0.007932\n",
      "====> Epoch: 116 Average loss: 0.0412\n",
      "Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 0.038120\n",
      "Reconstruction: 0.029158, Regularization: 0.008961\n",
      "Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 0.032777\n",
      "Reconstruction: 0.025840, Regularization: 0.006937\n",
      "Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 0.041830\n",
      "Reconstruction: 0.030177, Regularization: 0.011653\n",
      "Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 0.038785\n",
      "Reconstruction: 0.029977, Regularization: 0.008808\n",
      "Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 0.047736\n",
      "Reconstruction: 0.035132, Regularization: 0.012604\n",
      "Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 0.039305\n",
      "Reconstruction: 0.033009, Regularization: 0.006295\n",
      "Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 0.040736\n",
      "Reconstruction: 0.031819, Regularization: 0.008917\n",
      "Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 0.036448\n",
      "Reconstruction: 0.027570, Regularization: 0.008878\n",
      "====> Epoch: 117 Average loss: 0.0404\n",
      "Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 0.042310\n",
      "Reconstruction: 0.031164, Regularization: 0.011146\n",
      "Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 0.036675\n",
      "Reconstruction: 0.027542, Regularization: 0.009134\n",
      "Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 0.046850\n",
      "Reconstruction: 0.036170, Regularization: 0.010680\n",
      "Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 0.038581\n",
      "Reconstruction: 0.029940, Regularization: 0.008640\n",
      "Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 0.044301\n",
      "Reconstruction: 0.034635, Regularization: 0.009666\n",
      "Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 0.044122\n",
      "Reconstruction: 0.035083, Regularization: 0.009039\n",
      "Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 0.041257\n",
      "Reconstruction: 0.031503, Regularization: 0.009754\n",
      "Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 0.045021\n",
      "Reconstruction: 0.035831, Regularization: 0.009190\n",
      "====> Epoch: 118 Average loss: 0.0413\n",
      "Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 0.035726\n",
      "Reconstruction: 0.028580, Regularization: 0.007146\n",
      "Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 0.040291\n",
      "Reconstruction: 0.030314, Regularization: 0.009977\n",
      "Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 0.044618\n",
      "Reconstruction: 0.032321, Regularization: 0.012296\n",
      "Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 0.038157\n",
      "Reconstruction: 0.029581, Regularization: 0.008576\n",
      "Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 0.038620\n",
      "Reconstruction: 0.029010, Regularization: 0.009609\n",
      "Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 0.042327\n",
      "Reconstruction: 0.033527, Regularization: 0.008800\n",
      "Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 0.041175\n",
      "Reconstruction: 0.031444, Regularization: 0.009730\n",
      "Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 0.048360\n",
      "Reconstruction: 0.036449, Regularization: 0.011911\n",
      "====> Epoch: 119 Average loss: 0.0410\n",
      "Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 0.039634\n",
      "Reconstruction: 0.030303, Regularization: 0.009332\n",
      "Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 0.050273\n",
      "Reconstruction: 0.040836, Regularization: 0.009436\n",
      "Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 0.039472\n",
      "Reconstruction: 0.031030, Regularization: 0.008443\n",
      "Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 0.038900\n",
      "Reconstruction: 0.030385, Regularization: 0.008515\n",
      "Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 0.031131\n",
      "Reconstruction: 0.024435, Regularization: 0.006695\n",
      "Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 0.030890\n",
      "Reconstruction: 0.023829, Regularization: 0.007061\n",
      "Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 0.046746\n",
      "Reconstruction: 0.039297, Regularization: 0.007449\n",
      "Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 0.038531\n",
      "Reconstruction: 0.031328, Regularization: 0.007203\n",
      "====> Epoch: 120 Average loss: 0.0417\n",
      "Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 0.044063\n",
      "Reconstruction: 0.034098, Regularization: 0.009966\n",
      "Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 0.040833\n",
      "Reconstruction: 0.031042, Regularization: 0.009791\n",
      "Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 0.040195\n",
      "Reconstruction: 0.030818, Regularization: 0.009378\n",
      "Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 0.038589\n",
      "Reconstruction: 0.030980, Regularization: 0.007609\n",
      "Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 0.038947\n",
      "Reconstruction: 0.030846, Regularization: 0.008101\n",
      "Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 0.045136\n",
      "Reconstruction: 0.034471, Regularization: 0.010665\n",
      "Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 0.044351\n",
      "Reconstruction: 0.033921, Regularization: 0.010431\n",
      "Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 0.046429\n",
      "Reconstruction: 0.033642, Regularization: 0.012787\n",
      "====> Epoch: 121 Average loss: 0.0409\n",
      "Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 0.041385\n",
      "Reconstruction: 0.031895, Regularization: 0.009490\n",
      "Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 0.038987\n",
      "Reconstruction: 0.030006, Regularization: 0.008981\n",
      "Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 0.039865\n",
      "Reconstruction: 0.032301, Regularization: 0.007564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 0.043469\n",
      "Reconstruction: 0.035201, Regularization: 0.008268\n",
      "Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 0.038519\n",
      "Reconstruction: 0.029688, Regularization: 0.008831\n",
      "Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 0.047689\n",
      "Reconstruction: 0.037280, Regularization: 0.010409\n",
      "Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 0.044957\n",
      "Reconstruction: 0.035002, Regularization: 0.009955\n",
      "Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 0.054967\n",
      "Reconstruction: 0.041564, Regularization: 0.013403\n",
      "====> Epoch: 122 Average loss: 0.0417\n",
      "Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 0.044040\n",
      "Reconstruction: 0.032426, Regularization: 0.011613\n",
      "Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 0.040276\n",
      "Reconstruction: 0.032539, Regularization: 0.007737\n",
      "Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 0.036354\n",
      "Reconstruction: 0.027064, Regularization: 0.009290\n",
      "Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 0.043139\n",
      "Reconstruction: 0.033018, Regularization: 0.010121\n",
      "Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 0.033825\n",
      "Reconstruction: 0.026815, Regularization: 0.007010\n",
      "Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 0.042852\n",
      "Reconstruction: 0.031439, Regularization: 0.011414\n",
      "Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 0.037003\n",
      "Reconstruction: 0.028778, Regularization: 0.008226\n",
      "Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 0.043340\n",
      "Reconstruction: 0.033547, Regularization: 0.009793\n",
      "====> Epoch: 123 Average loss: 0.0413\n",
      "Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 0.038027\n",
      "Reconstruction: 0.028817, Regularization: 0.009210\n",
      "Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 0.054805\n",
      "Reconstruction: 0.038608, Regularization: 0.016197\n",
      "Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 0.040918\n",
      "Reconstruction: 0.030474, Regularization: 0.010444\n",
      "Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 0.039946\n",
      "Reconstruction: 0.031444, Regularization: 0.008502\n",
      "Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 0.045261\n",
      "Reconstruction: 0.032660, Regularization: 0.012601\n",
      "Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 0.039332\n",
      "Reconstruction: 0.031414, Regularization: 0.007918\n",
      "Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 0.040747\n",
      "Reconstruction: 0.030703, Regularization: 0.010044\n",
      "Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 0.042796\n",
      "Reconstruction: 0.032369, Regularization: 0.010428\n",
      "====> Epoch: 124 Average loss: 0.0413\n",
      "Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 0.037493\n",
      "Reconstruction: 0.028215, Regularization: 0.009279\n",
      "Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 0.038297\n",
      "Reconstruction: 0.030025, Regularization: 0.008272\n",
      "Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 0.050137\n",
      "Reconstruction: 0.039805, Regularization: 0.010332\n",
      "Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 0.037298\n",
      "Reconstruction: 0.027789, Regularization: 0.009509\n",
      "Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 0.042899\n",
      "Reconstruction: 0.032682, Regularization: 0.010217\n",
      "Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 0.042051\n",
      "Reconstruction: 0.032533, Regularization: 0.009518\n",
      "Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 0.036683\n",
      "Reconstruction: 0.027594, Regularization: 0.009089\n",
      "Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 0.040972\n",
      "Reconstruction: 0.030621, Regularization: 0.010351\n",
      "====> Epoch: 125 Average loss: 0.0411\n",
      "Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 0.041738\n",
      "Reconstruction: 0.029814, Regularization: 0.011924\n",
      "Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 0.042206\n",
      "Reconstruction: 0.030993, Regularization: 0.011213\n",
      "Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 0.047663\n",
      "Reconstruction: 0.036918, Regularization: 0.010746\n",
      "Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 0.043155\n",
      "Reconstruction: 0.032753, Regularization: 0.010402\n",
      "Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 0.040686\n",
      "Reconstruction: 0.031896, Regularization: 0.008791\n",
      "Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 0.037217\n",
      "Reconstruction: 0.028987, Regularization: 0.008230\n",
      "Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 0.043232\n",
      "Reconstruction: 0.031806, Regularization: 0.011426\n",
      "Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 0.042053\n",
      "Reconstruction: 0.030075, Regularization: 0.011978\n",
      "====> Epoch: 126 Average loss: 0.0413\n",
      "Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 0.041357\n",
      "Reconstruction: 0.031611, Regularization: 0.009746\n",
      "Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 0.043530\n",
      "Reconstruction: 0.032277, Regularization: 0.011253\n",
      "Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 0.038156\n",
      "Reconstruction: 0.032073, Regularization: 0.006084\n",
      "Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 0.037394\n",
      "Reconstruction: 0.031170, Regularization: 0.006223\n",
      "Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 0.043150\n",
      "Reconstruction: 0.033544, Regularization: 0.009606\n",
      "Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 0.035965\n",
      "Reconstruction: 0.028231, Regularization: 0.007734\n",
      "Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 0.043846\n",
      "Reconstruction: 0.033779, Regularization: 0.010067\n",
      "Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 0.045017\n",
      "Reconstruction: 0.032474, Regularization: 0.012544\n",
      "====> Epoch: 127 Average loss: 0.0413\n",
      "Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 0.042429\n",
      "Reconstruction: 0.030791, Regularization: 0.011638\n",
      "Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 0.040437\n",
      "Reconstruction: 0.031472, Regularization: 0.008965\n",
      "Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 0.039660\n",
      "Reconstruction: 0.030254, Regularization: 0.009406\n",
      "Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 0.040244\n",
      "Reconstruction: 0.031349, Regularization: 0.008895\n",
      "Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 0.042994\n",
      "Reconstruction: 0.032782, Regularization: 0.010212\n",
      "Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 0.039455\n",
      "Reconstruction: 0.030006, Regularization: 0.009449\n",
      "Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 0.046041\n",
      "Reconstruction: 0.034216, Regularization: 0.011825\n",
      "Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 0.041129\n",
      "Reconstruction: 0.030400, Regularization: 0.010729\n",
      "====> Epoch: 128 Average loss: 0.0410\n",
      "Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 0.043534\n",
      "Reconstruction: 0.033956, Regularization: 0.009578\n",
      "Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 0.041049\n",
      "Reconstruction: 0.032580, Regularization: 0.008469\n",
      "Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 0.041235\n",
      "Reconstruction: 0.032129, Regularization: 0.009106\n",
      "Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 0.042715\n",
      "Reconstruction: 0.032700, Regularization: 0.010015\n",
      "Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 0.043618\n",
      "Reconstruction: 0.035511, Regularization: 0.008107\n",
      "Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 0.041605\n",
      "Reconstruction: 0.032029, Regularization: 0.009576\n",
      "Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 0.043535\n",
      "Reconstruction: 0.032537, Regularization: 0.010997\n",
      "Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 0.038603\n",
      "Reconstruction: 0.029185, Regularization: 0.009418\n",
      "====> Epoch: 129 Average loss: 0.0410\n",
      "Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 0.048139\n",
      "Reconstruction: 0.039187, Regularization: 0.008951\n",
      "Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 0.043207\n",
      "Reconstruction: 0.031642, Regularization: 0.011564\n",
      "Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 0.040779\n",
      "Reconstruction: 0.030078, Regularization: 0.010701\n",
      "Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 0.044668\n",
      "Reconstruction: 0.034038, Regularization: 0.010629\n",
      "Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 0.045955\n",
      "Reconstruction: 0.036197, Regularization: 0.009758\n",
      "Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 0.040117\n",
      "Reconstruction: 0.029862, Regularization: 0.010255\n",
      "Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 0.039947\n",
      "Reconstruction: 0.032292, Regularization: 0.007654\n",
      "Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 0.040332\n",
      "Reconstruction: 0.030540, Regularization: 0.009792\n",
      "====> Epoch: 130 Average loss: 0.0416\n",
      "Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 0.041231\n",
      "Reconstruction: 0.033054, Regularization: 0.008178\n",
      "Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 0.040938\n",
      "Reconstruction: 0.028979, Regularization: 0.011959\n",
      "Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 0.040522\n",
      "Reconstruction: 0.031520, Regularization: 0.009002\n",
      "Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 0.041264\n",
      "Reconstruction: 0.033637, Regularization: 0.007626\n",
      "Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 0.037601\n",
      "Reconstruction: 0.030419, Regularization: 0.007182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 0.036840\n",
      "Reconstruction: 0.027771, Regularization: 0.009069\n",
      "Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 0.037640\n",
      "Reconstruction: 0.028161, Regularization: 0.009479\n",
      "Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 0.041717\n",
      "Reconstruction: 0.029969, Regularization: 0.011748\n",
      "====> Epoch: 131 Average loss: 0.0414\n",
      "Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 0.041758\n",
      "Reconstruction: 0.032366, Regularization: 0.009392\n",
      "Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 0.043180\n",
      "Reconstruction: 0.031907, Regularization: 0.011273\n",
      "Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 0.038178\n",
      "Reconstruction: 0.029207, Regularization: 0.008971\n",
      "Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 0.044565\n",
      "Reconstruction: 0.035019, Regularization: 0.009546\n",
      "Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 0.031191\n",
      "Reconstruction: 0.026928, Regularization: 0.004263\n",
      "Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 0.042504\n",
      "Reconstruction: 0.032269, Regularization: 0.010235\n",
      "Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 0.037910\n",
      "Reconstruction: 0.028382, Regularization: 0.009528\n",
      "Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 0.041758\n",
      "Reconstruction: 0.031210, Regularization: 0.010548\n",
      "====> Epoch: 132 Average loss: 0.0412\n",
      "Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 0.035900\n",
      "Reconstruction: 0.027007, Regularization: 0.008893\n",
      "Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 0.044296\n",
      "Reconstruction: 0.035679, Regularization: 0.008617\n",
      "Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 0.037397\n",
      "Reconstruction: 0.027075, Regularization: 0.010322\n",
      "Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 0.046568\n",
      "Reconstruction: 0.036420, Regularization: 0.010148\n",
      "Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 0.041573\n",
      "Reconstruction: 0.030648, Regularization: 0.010925\n",
      "Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 0.034425\n",
      "Reconstruction: 0.026874, Regularization: 0.007551\n",
      "Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 0.049286\n",
      "Reconstruction: 0.035040, Regularization: 0.014246\n",
      "Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 0.037285\n",
      "Reconstruction: 0.028268, Regularization: 0.009017\n",
      "====> Epoch: 133 Average loss: 0.0412\n",
      "Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 0.047161\n",
      "Reconstruction: 0.032914, Regularization: 0.014247\n",
      "Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 0.036547\n",
      "Reconstruction: 0.030389, Regularization: 0.006158\n",
      "Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 0.053940\n",
      "Reconstruction: 0.038998, Regularization: 0.014942\n",
      "Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 0.036383\n",
      "Reconstruction: 0.028215, Regularization: 0.008167\n",
      "Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 0.045640\n",
      "Reconstruction: 0.034436, Regularization: 0.011204\n",
      "Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 0.037275\n",
      "Reconstruction: 0.029915, Regularization: 0.007360\n",
      "Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 0.044114\n",
      "Reconstruction: 0.032615, Regularization: 0.011499\n",
      "Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 0.036642\n",
      "Reconstruction: 0.028125, Regularization: 0.008517\n",
      "====> Epoch: 134 Average loss: 0.0411\n",
      "Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 0.035790\n",
      "Reconstruction: 0.027012, Regularization: 0.008778\n",
      "Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 0.040946\n",
      "Reconstruction: 0.032244, Regularization: 0.008702\n",
      "Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 0.054301\n",
      "Reconstruction: 0.041675, Regularization: 0.012626\n",
      "Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 0.043835\n",
      "Reconstruction: 0.032613, Regularization: 0.011222\n",
      "Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 0.040746\n",
      "Reconstruction: 0.030427, Regularization: 0.010319\n",
      "Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 0.048686\n",
      "Reconstruction: 0.034260, Regularization: 0.014425\n",
      "Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 0.038196\n",
      "Reconstruction: 0.029785, Regularization: 0.008411\n",
      "Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 0.041858\n",
      "Reconstruction: 0.030452, Regularization: 0.011406\n",
      "====> Epoch: 135 Average loss: 0.0414\n",
      "Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 0.042844\n",
      "Reconstruction: 0.033210, Regularization: 0.009634\n",
      "Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 0.034956\n",
      "Reconstruction: 0.027809, Regularization: 0.007147\n",
      "Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 0.052332\n",
      "Reconstruction: 0.039322, Regularization: 0.013011\n",
      "Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 0.045573\n",
      "Reconstruction: 0.034097, Regularization: 0.011477\n",
      "Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 0.040321\n",
      "Reconstruction: 0.030519, Regularization: 0.009802\n",
      "Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 0.041504\n",
      "Reconstruction: 0.032048, Regularization: 0.009456\n",
      "Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 0.036880\n",
      "Reconstruction: 0.028901, Regularization: 0.007979\n",
      "Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 0.044384\n",
      "Reconstruction: 0.033655, Regularization: 0.010729\n",
      "====> Epoch: 136 Average loss: 0.0411\n",
      "Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 0.045722\n",
      "Reconstruction: 0.032774, Regularization: 0.012948\n",
      "Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 0.039914\n",
      "Reconstruction: 0.031033, Regularization: 0.008881\n",
      "Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 0.041301\n",
      "Reconstruction: 0.031736, Regularization: 0.009565\n",
      "Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 0.040238\n",
      "Reconstruction: 0.031105, Regularization: 0.009133\n",
      "Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 0.039104\n",
      "Reconstruction: 0.032829, Regularization: 0.006274\n",
      "Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 0.038269\n",
      "Reconstruction: 0.027401, Regularization: 0.010868\n",
      "Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 0.047437\n",
      "Reconstruction: 0.037241, Regularization: 0.010196\n",
      "Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 0.041462\n",
      "Reconstruction: 0.030285, Regularization: 0.011177\n",
      "====> Epoch: 137 Average loss: 0.0410\n",
      "Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 0.043294\n",
      "Reconstruction: 0.033141, Regularization: 0.010154\n",
      "Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 0.046186\n",
      "Reconstruction: 0.036180, Regularization: 0.010005\n",
      "Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 0.047913\n",
      "Reconstruction: 0.037557, Regularization: 0.010356\n",
      "Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 0.040537\n",
      "Reconstruction: 0.031499, Regularization: 0.009038\n",
      "Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 0.040455\n",
      "Reconstruction: 0.030922, Regularization: 0.009533\n",
      "Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 0.044736\n",
      "Reconstruction: 0.035034, Regularization: 0.009702\n",
      "Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 0.045919\n",
      "Reconstruction: 0.034808, Regularization: 0.011111\n",
      "Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 0.049976\n",
      "Reconstruction: 0.036475, Regularization: 0.013501\n",
      "====> Epoch: 138 Average loss: 0.0418\n",
      "Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 0.038816\n",
      "Reconstruction: 0.030727, Regularization: 0.008089\n",
      "Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 0.040168\n",
      "Reconstruction: 0.031499, Regularization: 0.008669\n",
      "Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 0.039577\n",
      "Reconstruction: 0.030032, Regularization: 0.009545\n",
      "Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 0.039630\n",
      "Reconstruction: 0.029109, Regularization: 0.010521\n",
      "Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 0.044220\n",
      "Reconstruction: 0.033642, Regularization: 0.010578\n",
      "Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 0.034089\n",
      "Reconstruction: 0.027804, Regularization: 0.006285\n",
      "Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 0.040269\n",
      "Reconstruction: 0.032366, Regularization: 0.007903\n",
      "Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 0.043809\n",
      "Reconstruction: 0.034159, Regularization: 0.009650\n",
      "====> Epoch: 139 Average loss: 0.0409\n",
      "Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 0.042609\n",
      "Reconstruction: 0.035969, Regularization: 0.006641\n",
      "Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 0.040503\n",
      "Reconstruction: 0.031924, Regularization: 0.008579\n",
      "Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 0.045717\n",
      "Reconstruction: 0.035186, Regularization: 0.010531\n",
      "Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 0.036320\n",
      "Reconstruction: 0.027037, Regularization: 0.009282\n",
      "Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 0.038276\n",
      "Reconstruction: 0.030560, Regularization: 0.007716\n",
      "Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 0.048194\n",
      "Reconstruction: 0.036088, Regularization: 0.012107\n",
      "Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 0.041342\n",
      "Reconstruction: 0.032961, Regularization: 0.008381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 0.037885\n",
      "Reconstruction: 0.028841, Regularization: 0.009044\n",
      "====> Epoch: 140 Average loss: 0.0414\n",
      "Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 0.045142\n",
      "Reconstruction: 0.034901, Regularization: 0.010241\n",
      "Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 0.040446\n",
      "Reconstruction: 0.031317, Regularization: 0.009129\n",
      "Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 0.046289\n",
      "Reconstruction: 0.034803, Regularization: 0.011485\n",
      "Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 0.036118\n",
      "Reconstruction: 0.027123, Regularization: 0.008995\n",
      "Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 0.045176\n",
      "Reconstruction: 0.033245, Regularization: 0.011931\n",
      "Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 0.039444\n",
      "Reconstruction: 0.030911, Regularization: 0.008532\n",
      "Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 0.038348\n",
      "Reconstruction: 0.030184, Regularization: 0.008164\n",
      "Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 0.037656\n",
      "Reconstruction: 0.027618, Regularization: 0.010038\n",
      "====> Epoch: 141 Average loss: 0.0405\n",
      "Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 0.033265\n",
      "Reconstruction: 0.025331, Regularization: 0.007934\n",
      "Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 0.041122\n",
      "Reconstruction: 0.032316, Regularization: 0.008805\n",
      "Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 0.041803\n",
      "Reconstruction: 0.030979, Regularization: 0.010824\n",
      "Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 0.044641\n",
      "Reconstruction: 0.032647, Regularization: 0.011994\n",
      "Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 0.041359\n",
      "Reconstruction: 0.031388, Regularization: 0.009971\n",
      "Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 0.046474\n",
      "Reconstruction: 0.035207, Regularization: 0.011267\n",
      "Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 0.034180\n",
      "Reconstruction: 0.027590, Regularization: 0.006590\n",
      "Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 0.040670\n",
      "Reconstruction: 0.030982, Regularization: 0.009688\n",
      "====> Epoch: 142 Average loss: 0.0412\n",
      "Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 0.040632\n",
      "Reconstruction: 0.031291, Regularization: 0.009341\n",
      "Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 0.034288\n",
      "Reconstruction: 0.027066, Regularization: 0.007222\n",
      "Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 0.041849\n",
      "Reconstruction: 0.031415, Regularization: 0.010434\n",
      "Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 0.036593\n",
      "Reconstruction: 0.028464, Regularization: 0.008129\n",
      "Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 0.033078\n",
      "Reconstruction: 0.024234, Regularization: 0.008844\n",
      "Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 0.041519\n",
      "Reconstruction: 0.031499, Regularization: 0.010019\n",
      "Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 0.043831\n",
      "Reconstruction: 0.033842, Regularization: 0.009989\n",
      "Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 0.039269\n",
      "Reconstruction: 0.031704, Regularization: 0.007565\n",
      "====> Epoch: 143 Average loss: 0.0413\n",
      "Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 0.051567\n",
      "Reconstruction: 0.039174, Regularization: 0.012393\n",
      "Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 0.048025\n",
      "Reconstruction: 0.037811, Regularization: 0.010213\n",
      "Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 0.038633\n",
      "Reconstruction: 0.030789, Regularization: 0.007844\n",
      "Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 0.042153\n",
      "Reconstruction: 0.032985, Regularization: 0.009168\n",
      "Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 0.044723\n",
      "Reconstruction: 0.032648, Regularization: 0.012076\n",
      "Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 0.041341\n",
      "Reconstruction: 0.032264, Regularization: 0.009077\n",
      "Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 0.041502\n",
      "Reconstruction: 0.032289, Regularization: 0.009213\n",
      "Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 0.042680\n",
      "Reconstruction: 0.032071, Regularization: 0.010609\n",
      "====> Epoch: 144 Average loss: 0.0412\n",
      "Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 0.043413\n",
      "Reconstruction: 0.033019, Regularization: 0.010394\n",
      "Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 0.040753\n",
      "Reconstruction: 0.030058, Regularization: 0.010695\n",
      "Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 0.051238\n",
      "Reconstruction: 0.037334, Regularization: 0.013904\n",
      "Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 0.043696\n",
      "Reconstruction: 0.035243, Regularization: 0.008453\n",
      "Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 0.040194\n",
      "Reconstruction: 0.031053, Regularization: 0.009141\n",
      "Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 0.038674\n",
      "Reconstruction: 0.030783, Regularization: 0.007891\n",
      "Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 0.044999\n",
      "Reconstruction: 0.035264, Regularization: 0.009735\n",
      "Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 0.037456\n",
      "Reconstruction: 0.028571, Regularization: 0.008885\n",
      "====> Epoch: 145 Average loss: 0.0413\n",
      "Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 0.040207\n",
      "Reconstruction: 0.030821, Regularization: 0.009386\n",
      "Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 0.039038\n",
      "Reconstruction: 0.028606, Regularization: 0.010432\n",
      "Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 0.042829\n",
      "Reconstruction: 0.032844, Regularization: 0.009985\n",
      "Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 0.043219\n",
      "Reconstruction: 0.035314, Regularization: 0.007905\n",
      "Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 0.046117\n",
      "Reconstruction: 0.035575, Regularization: 0.010542\n",
      "Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 0.044483\n",
      "Reconstruction: 0.033816, Regularization: 0.010667\n",
      "Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 0.046095\n",
      "Reconstruction: 0.038067, Regularization: 0.008028\n",
      "Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 0.039176\n",
      "Reconstruction: 0.031327, Regularization: 0.007849\n",
      "====> Epoch: 146 Average loss: 0.0416\n",
      "Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 0.041029\n",
      "Reconstruction: 0.032291, Regularization: 0.008738\n",
      "Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 0.039865\n",
      "Reconstruction: 0.029008, Regularization: 0.010857\n",
      "Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 0.036624\n",
      "Reconstruction: 0.030250, Regularization: 0.006374\n",
      "Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 0.035968\n",
      "Reconstruction: 0.028539, Regularization: 0.007429\n",
      "Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 0.044281\n",
      "Reconstruction: 0.033339, Regularization: 0.010942\n",
      "Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 0.040287\n",
      "Reconstruction: 0.031718, Regularization: 0.008570\n",
      "Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 0.042341\n",
      "Reconstruction: 0.035323, Regularization: 0.007018\n",
      "Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 0.051105\n",
      "Reconstruction: 0.036987, Regularization: 0.014117\n",
      "====> Epoch: 147 Average loss: 0.0414\n",
      "Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 0.039285\n",
      "Reconstruction: 0.030092, Regularization: 0.009192\n",
      "Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 0.032735\n",
      "Reconstruction: 0.026121, Regularization: 0.006614\n",
      "Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 0.039945\n",
      "Reconstruction: 0.028663, Regularization: 0.011283\n",
      "Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 0.036794\n",
      "Reconstruction: 0.026518, Regularization: 0.010276\n",
      "Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 0.037110\n",
      "Reconstruction: 0.030653, Regularization: 0.006458\n",
      "Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 0.044696\n",
      "Reconstruction: 0.036692, Regularization: 0.008004\n",
      "Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 0.047722\n",
      "Reconstruction: 0.037114, Regularization: 0.010608\n",
      "Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 0.048366\n",
      "Reconstruction: 0.038815, Regularization: 0.009551\n",
      "====> Epoch: 148 Average loss: 0.0413\n",
      "Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 0.040176\n",
      "Reconstruction: 0.031958, Regularization: 0.008218\n",
      "Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 0.038232\n",
      "Reconstruction: 0.028696, Regularization: 0.009536\n",
      "Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 0.037843\n",
      "Reconstruction: 0.028972, Regularization: 0.008871\n",
      "Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 0.046366\n",
      "Reconstruction: 0.036003, Regularization: 0.010363\n",
      "Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 0.043711\n",
      "Reconstruction: 0.033594, Regularization: 0.010117\n",
      "Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 0.049302\n",
      "Reconstruction: 0.037291, Regularization: 0.012010\n",
      "Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 0.041627\n",
      "Reconstruction: 0.032030, Regularization: 0.009597\n",
      "Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 0.037412\n",
      "Reconstruction: 0.028906, Regularization: 0.008506\n",
      "====> Epoch: 149 Average loss: 0.0411\n",
      "Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 0.047185\n",
      "Reconstruction: 0.034600, Regularization: 0.012585\n",
      "Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 0.035585\n",
      "Reconstruction: 0.028170, Regularization: 0.007415\n",
      "Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 0.035984\n",
      "Reconstruction: 0.028258, Regularization: 0.007726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 0.033994\n",
      "Reconstruction: 0.027239, Regularization: 0.006755\n",
      "Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 0.034111\n",
      "Reconstruction: 0.025860, Regularization: 0.008252\n",
      "Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 0.043109\n",
      "Reconstruction: 0.030606, Regularization: 0.012502\n",
      "Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 0.039005\n",
      "Reconstruction: 0.030342, Regularization: 0.008662\n",
      "Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 0.049931\n",
      "Reconstruction: 0.037254, Regularization: 0.012677\n",
      "====> Epoch: 150 Average loss: 0.0410\n",
      "Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 0.036486\n",
      "Reconstruction: 0.029388, Regularization: 0.007098\n",
      "Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 0.040560\n",
      "Reconstruction: 0.033168, Regularization: 0.007392\n",
      "Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 0.041198\n",
      "Reconstruction: 0.031623, Regularization: 0.009575\n",
      "Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 0.038905\n",
      "Reconstruction: 0.030405, Regularization: 0.008500\n",
      "Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 0.039605\n",
      "Reconstruction: 0.028960, Regularization: 0.010645\n",
      "Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 0.037528\n",
      "Reconstruction: 0.030901, Regularization: 0.006627\n",
      "Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 0.038518\n",
      "Reconstruction: 0.029583, Regularization: 0.008935\n",
      "Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 0.043828\n",
      "Reconstruction: 0.034749, Regularization: 0.009079\n",
      "====> Epoch: 151 Average loss: 0.0415\n",
      "Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 0.044946\n",
      "Reconstruction: 0.034238, Regularization: 0.010708\n",
      "Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 0.039875\n",
      "Reconstruction: 0.027451, Regularization: 0.012424\n",
      "Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 0.042185\n",
      "Reconstruction: 0.032907, Regularization: 0.009278\n",
      "Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 0.038370\n",
      "Reconstruction: 0.030604, Regularization: 0.007766\n",
      "Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 0.042536\n",
      "Reconstruction: 0.033308, Regularization: 0.009227\n",
      "Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 0.039214\n",
      "Reconstruction: 0.030576, Regularization: 0.008638\n",
      "Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 0.038835\n",
      "Reconstruction: 0.030838, Regularization: 0.007996\n",
      "Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 0.039109\n",
      "Reconstruction: 0.031176, Regularization: 0.007932\n",
      "====> Epoch: 152 Average loss: 0.0416\n",
      "Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 0.042434\n",
      "Reconstruction: 0.030960, Regularization: 0.011474\n",
      "Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 0.040548\n",
      "Reconstruction: 0.030202, Regularization: 0.010347\n",
      "Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 0.044483\n",
      "Reconstruction: 0.035242, Regularization: 0.009240\n",
      "Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 0.040917\n",
      "Reconstruction: 0.032795, Regularization: 0.008121\n",
      "Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 0.050937\n",
      "Reconstruction: 0.039019, Regularization: 0.011918\n",
      "Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 0.041520\n",
      "Reconstruction: 0.030529, Regularization: 0.010991\n",
      "Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 0.042770\n",
      "Reconstruction: 0.033517, Regularization: 0.009254\n",
      "Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 0.035787\n",
      "Reconstruction: 0.029270, Regularization: 0.006517\n",
      "====> Epoch: 153 Average loss: 0.0415\n",
      "Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 0.046786\n",
      "Reconstruction: 0.034970, Regularization: 0.011816\n",
      "Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 0.041244\n",
      "Reconstruction: 0.031465, Regularization: 0.009779\n",
      "Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 0.042182\n",
      "Reconstruction: 0.034023, Regularization: 0.008159\n",
      "Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 0.045820\n",
      "Reconstruction: 0.034974, Regularization: 0.010847\n",
      "Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 0.041229\n",
      "Reconstruction: 0.031831, Regularization: 0.009398\n",
      "Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 0.038663\n",
      "Reconstruction: 0.029651, Regularization: 0.009013\n",
      "Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 0.036884\n",
      "Reconstruction: 0.030241, Regularization: 0.006643\n",
      "Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 0.043809\n",
      "Reconstruction: 0.033321, Regularization: 0.010488\n",
      "====> Epoch: 154 Average loss: 0.0414\n",
      "Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 0.043186\n",
      "Reconstruction: 0.033131, Regularization: 0.010055\n",
      "Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 0.047896\n",
      "Reconstruction: 0.036203, Regularization: 0.011693\n",
      "Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 0.045010\n",
      "Reconstruction: 0.034287, Regularization: 0.010723\n",
      "Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 0.039222\n",
      "Reconstruction: 0.031583, Regularization: 0.007639\n",
      "Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 0.042500\n",
      "Reconstruction: 0.033243, Regularization: 0.009256\n",
      "Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 0.042235\n",
      "Reconstruction: 0.033054, Regularization: 0.009181\n",
      "Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 0.034351\n",
      "Reconstruction: 0.026741, Regularization: 0.007611\n",
      "Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 0.034061\n",
      "Reconstruction: 0.026950, Regularization: 0.007111\n",
      "====> Epoch: 155 Average loss: 0.0415\n",
      "Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 0.040228\n",
      "Reconstruction: 0.030075, Regularization: 0.010153\n",
      "Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 0.042286\n",
      "Reconstruction: 0.030557, Regularization: 0.011729\n",
      "Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 0.042047\n",
      "Reconstruction: 0.033910, Regularization: 0.008137\n",
      "Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 0.044093\n",
      "Reconstruction: 0.032867, Regularization: 0.011227\n",
      "Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 0.042020\n",
      "Reconstruction: 0.032959, Regularization: 0.009062\n",
      "Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 0.039808\n",
      "Reconstruction: 0.030140, Regularization: 0.009668\n",
      "Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 0.036247\n",
      "Reconstruction: 0.027694, Regularization: 0.008553\n",
      "Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 0.036678\n",
      "Reconstruction: 0.028876, Regularization: 0.007802\n",
      "====> Epoch: 156 Average loss: 0.0413\n",
      "Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 0.046718\n",
      "Reconstruction: 0.035331, Regularization: 0.011387\n",
      "Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 0.044561\n",
      "Reconstruction: 0.033841, Regularization: 0.010720\n",
      "Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 0.038866\n",
      "Reconstruction: 0.030851, Regularization: 0.008014\n",
      "Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 0.039177\n",
      "Reconstruction: 0.031364, Regularization: 0.007814\n",
      "Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 0.037732\n",
      "Reconstruction: 0.028229, Regularization: 0.009503\n",
      "Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 0.044306\n",
      "Reconstruction: 0.034647, Regularization: 0.009659\n",
      "Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 0.037575\n",
      "Reconstruction: 0.028757, Regularization: 0.008818\n",
      "Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 0.038059\n",
      "Reconstruction: 0.028529, Regularization: 0.009531\n",
      "====> Epoch: 157 Average loss: 0.0418\n",
      "Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 0.045997\n",
      "Reconstruction: 0.034480, Regularization: 0.011517\n",
      "Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 0.041134\n",
      "Reconstruction: 0.030630, Regularization: 0.010504\n",
      "Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 0.039450\n",
      "Reconstruction: 0.032005, Regularization: 0.007446\n",
      "Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 0.045487\n",
      "Reconstruction: 0.036167, Regularization: 0.009320\n",
      "Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 0.046552\n",
      "Reconstruction: 0.034600, Regularization: 0.011952\n",
      "Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 0.044560\n",
      "Reconstruction: 0.032121, Regularization: 0.012439\n",
      "Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 0.047944\n",
      "Reconstruction: 0.037038, Regularization: 0.010906\n",
      "Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 0.042136\n",
      "Reconstruction: 0.033560, Regularization: 0.008577\n",
      "====> Epoch: 158 Average loss: 0.0415\n",
      "Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 0.040723\n",
      "Reconstruction: 0.032923, Regularization: 0.007799\n",
      "Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 0.038551\n",
      "Reconstruction: 0.029351, Regularization: 0.009200\n",
      "Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 0.038190\n",
      "Reconstruction: 0.027939, Regularization: 0.010251\n",
      "Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 0.042637\n",
      "Reconstruction: 0.032206, Regularization: 0.010431\n",
      "Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 0.046227\n",
      "Reconstruction: 0.033890, Regularization: 0.012337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 0.039083\n",
      "Reconstruction: 0.030694, Regularization: 0.008389\n",
      "Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 0.034624\n",
      "Reconstruction: 0.027407, Regularization: 0.007217\n",
      "Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 0.035680\n",
      "Reconstruction: 0.027548, Regularization: 0.008132\n",
      "====> Epoch: 159 Average loss: 0.0408\n",
      "Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 0.036781\n",
      "Reconstruction: 0.029207, Regularization: 0.007574\n",
      "Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 0.035918\n",
      "Reconstruction: 0.029221, Regularization: 0.006698\n",
      "Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 0.038435\n",
      "Reconstruction: 0.030038, Regularization: 0.008397\n",
      "Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 0.043382\n",
      "Reconstruction: 0.032539, Regularization: 0.010843\n",
      "Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 0.037262\n",
      "Reconstruction: 0.028010, Regularization: 0.009252\n",
      "Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 0.040791\n",
      "Reconstruction: 0.030966, Regularization: 0.009824\n",
      "Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 0.040934\n",
      "Reconstruction: 0.031055, Regularization: 0.009879\n",
      "Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 0.035783\n",
      "Reconstruction: 0.028576, Regularization: 0.007207\n",
      "====> Epoch: 160 Average loss: 0.0409\n",
      "Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 0.040883\n",
      "Reconstruction: 0.033408, Regularization: 0.007475\n",
      "Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 0.039205\n",
      "Reconstruction: 0.029940, Regularization: 0.009266\n",
      "Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 0.038208\n",
      "Reconstruction: 0.028956, Regularization: 0.009253\n",
      "Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 0.046232\n",
      "Reconstruction: 0.035572, Regularization: 0.010660\n",
      "Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 0.038705\n",
      "Reconstruction: 0.030943, Regularization: 0.007762\n",
      "Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 0.037252\n",
      "Reconstruction: 0.028887, Regularization: 0.008365\n",
      "Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 0.042853\n",
      "Reconstruction: 0.031504, Regularization: 0.011349\n",
      "Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 0.036756\n",
      "Reconstruction: 0.027505, Regularization: 0.009251\n",
      "====> Epoch: 161 Average loss: 0.0411\n",
      "Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 0.038935\n",
      "Reconstruction: 0.030316, Regularization: 0.008619\n",
      "Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 0.045504\n",
      "Reconstruction: 0.035386, Regularization: 0.010118\n",
      "Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 0.036905\n",
      "Reconstruction: 0.029425, Regularization: 0.007480\n",
      "Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 0.039239\n",
      "Reconstruction: 0.029222, Regularization: 0.010017\n",
      "Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 0.041122\n",
      "Reconstruction: 0.030296, Regularization: 0.010826\n",
      "Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 0.041946\n",
      "Reconstruction: 0.031805, Regularization: 0.010141\n",
      "Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 0.041343\n",
      "Reconstruction: 0.030703, Regularization: 0.010640\n",
      "Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 0.037247\n",
      "Reconstruction: 0.030047, Regularization: 0.007200\n",
      "====> Epoch: 162 Average loss: 0.0412\n",
      "Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 0.047519\n",
      "Reconstruction: 0.036377, Regularization: 0.011141\n",
      "Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 0.039576\n",
      "Reconstruction: 0.031382, Regularization: 0.008194\n",
      "Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 0.045284\n",
      "Reconstruction: 0.033048, Regularization: 0.012236\n",
      "Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 0.040818\n",
      "Reconstruction: 0.032708, Regularization: 0.008111\n",
      "Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 0.036907\n",
      "Reconstruction: 0.029012, Regularization: 0.007895\n",
      "Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 0.040874\n",
      "Reconstruction: 0.031817, Regularization: 0.009057\n",
      "Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 0.040241\n",
      "Reconstruction: 0.031118, Regularization: 0.009123\n",
      "Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 0.036928\n",
      "Reconstruction: 0.028161, Regularization: 0.008767\n",
      "====> Epoch: 163 Average loss: 0.0413\n",
      "Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 0.043652\n",
      "Reconstruction: 0.033374, Regularization: 0.010278\n",
      "Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 0.040236\n",
      "Reconstruction: 0.029579, Regularization: 0.010657\n",
      "Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 0.037597\n",
      "Reconstruction: 0.029360, Regularization: 0.008237\n",
      "Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 0.038322\n",
      "Reconstruction: 0.030610, Regularization: 0.007713\n",
      "Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 0.037578\n",
      "Reconstruction: 0.028574, Regularization: 0.009004\n",
      "Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 0.036027\n",
      "Reconstruction: 0.029190, Regularization: 0.006837\n",
      "Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 0.035255\n",
      "Reconstruction: 0.027782, Regularization: 0.007473\n",
      "Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 0.040790\n",
      "Reconstruction: 0.033199, Regularization: 0.007592\n",
      "====> Epoch: 164 Average loss: 0.0415\n",
      "Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 0.041061\n",
      "Reconstruction: 0.032442, Regularization: 0.008620\n",
      "Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 0.041625\n",
      "Reconstruction: 0.030890, Regularization: 0.010736\n",
      "Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 0.044784\n",
      "Reconstruction: 0.033667, Regularization: 0.011117\n",
      "Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 0.038081\n",
      "Reconstruction: 0.032158, Regularization: 0.005924\n",
      "Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 0.048723\n",
      "Reconstruction: 0.038699, Regularization: 0.010024\n",
      "Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 0.041657\n",
      "Reconstruction: 0.031030, Regularization: 0.010627\n",
      "Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 0.041332\n",
      "Reconstruction: 0.032207, Regularization: 0.009125\n",
      "Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 0.043604\n",
      "Reconstruction: 0.032343, Regularization: 0.011261\n",
      "====> Epoch: 165 Average loss: 0.0413\n",
      "Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 0.043416\n",
      "Reconstruction: 0.032387, Regularization: 0.011028\n",
      "Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 0.041558\n",
      "Reconstruction: 0.032159, Regularization: 0.009399\n",
      "Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 0.042313\n",
      "Reconstruction: 0.032341, Regularization: 0.009973\n",
      "Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 0.037859\n",
      "Reconstruction: 0.030606, Regularization: 0.007253\n",
      "Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 0.038154\n",
      "Reconstruction: 0.028864, Regularization: 0.009290\n",
      "Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 0.040600\n",
      "Reconstruction: 0.033058, Regularization: 0.007542\n",
      "Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 0.037704\n",
      "Reconstruction: 0.029211, Regularization: 0.008493\n",
      "Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 0.039509\n",
      "Reconstruction: 0.029714, Regularization: 0.009795\n",
      "====> Epoch: 166 Average loss: 0.0415\n",
      "Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 0.042204\n",
      "Reconstruction: 0.031984, Regularization: 0.010220\n",
      "Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 0.039598\n",
      "Reconstruction: 0.030088, Regularization: 0.009510\n",
      "Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 0.035212\n",
      "Reconstruction: 0.027163, Regularization: 0.008049\n",
      "Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 0.043595\n",
      "Reconstruction: 0.033619, Regularization: 0.009976\n",
      "Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 0.046269\n",
      "Reconstruction: 0.036534, Regularization: 0.009735\n",
      "Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 0.041223\n",
      "Reconstruction: 0.031897, Regularization: 0.009326\n",
      "Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 0.044543\n",
      "Reconstruction: 0.035717, Regularization: 0.008826\n",
      "Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 0.034847\n",
      "Reconstruction: 0.027353, Regularization: 0.007494\n",
      "====> Epoch: 167 Average loss: 0.0408\n",
      "Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 0.039558\n",
      "Reconstruction: 0.030402, Regularization: 0.009157\n",
      "Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 0.042720\n",
      "Reconstruction: 0.032597, Regularization: 0.010123\n",
      "Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 0.043830\n",
      "Reconstruction: 0.030885, Regularization: 0.012944\n",
      "Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 0.040457\n",
      "Reconstruction: 0.029905, Regularization: 0.010553\n",
      "Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 0.044194\n",
      "Reconstruction: 0.031900, Regularization: 0.012294\n",
      "Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 0.042195\n",
      "Reconstruction: 0.031520, Regularization: 0.010674\n",
      "Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 0.042381\n",
      "Reconstruction: 0.032663, Regularization: 0.009719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 0.038603\n",
      "Reconstruction: 0.029431, Regularization: 0.009172\n",
      "====> Epoch: 168 Average loss: 0.0409\n",
      "Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 0.042688\n",
      "Reconstruction: 0.031977, Regularization: 0.010710\n",
      "Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 0.037795\n",
      "Reconstruction: 0.027024, Regularization: 0.010771\n",
      "Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 0.037391\n",
      "Reconstruction: 0.029071, Regularization: 0.008321\n",
      "Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 0.039082\n",
      "Reconstruction: 0.030030, Regularization: 0.009051\n",
      "Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 0.041065\n",
      "Reconstruction: 0.032425, Regularization: 0.008640\n",
      "Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 0.046920\n",
      "Reconstruction: 0.034018, Regularization: 0.012902\n",
      "Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 0.042114\n",
      "Reconstruction: 0.033198, Regularization: 0.008916\n",
      "Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 0.041172\n",
      "Reconstruction: 0.030233, Regularization: 0.010939\n",
      "====> Epoch: 169 Average loss: 0.0414\n",
      "Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 0.037640\n",
      "Reconstruction: 0.029129, Regularization: 0.008511\n",
      "Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 0.041128\n",
      "Reconstruction: 0.030734, Regularization: 0.010393\n",
      "Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 0.047307\n",
      "Reconstruction: 0.036279, Regularization: 0.011028\n",
      "Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 0.042532\n",
      "Reconstruction: 0.033013, Regularization: 0.009519\n",
      "Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 0.041934\n",
      "Reconstruction: 0.032707, Regularization: 0.009227\n",
      "Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 0.038910\n",
      "Reconstruction: 0.031385, Regularization: 0.007525\n",
      "Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 0.044016\n",
      "Reconstruction: 0.033143, Regularization: 0.010872\n",
      "Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 0.039889\n",
      "Reconstruction: 0.030154, Regularization: 0.009735\n",
      "====> Epoch: 170 Average loss: 0.0411\n",
      "Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 0.041295\n",
      "Reconstruction: 0.033089, Regularization: 0.008206\n",
      "Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 0.037691\n",
      "Reconstruction: 0.029776, Regularization: 0.007915\n",
      "Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 0.040399\n",
      "Reconstruction: 0.031968, Regularization: 0.008430\n",
      "Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 0.042259\n",
      "Reconstruction: 0.030795, Regularization: 0.011464\n",
      "Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 0.049768\n",
      "Reconstruction: 0.038160, Regularization: 0.011608\n",
      "Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 0.043495\n",
      "Reconstruction: 0.034272, Regularization: 0.009222\n",
      "Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 0.045494\n",
      "Reconstruction: 0.034438, Regularization: 0.011056\n",
      "Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 0.042236\n",
      "Reconstruction: 0.032514, Regularization: 0.009722\n",
      "====> Epoch: 171 Average loss: 0.0411\n",
      "Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 0.040474\n",
      "Reconstruction: 0.031695, Regularization: 0.008778\n",
      "Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 0.036062\n",
      "Reconstruction: 0.027502, Regularization: 0.008561\n",
      "Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 0.036858\n",
      "Reconstruction: 0.027692, Regularization: 0.009166\n",
      "Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 0.039119\n",
      "Reconstruction: 0.028687, Regularization: 0.010433\n",
      "Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 0.044145\n",
      "Reconstruction: 0.033873, Regularization: 0.010272\n",
      "Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 0.040892\n",
      "Reconstruction: 0.031673, Regularization: 0.009219\n",
      "Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 0.044545\n",
      "Reconstruction: 0.033190, Regularization: 0.011355\n",
      "Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 0.040269\n",
      "Reconstruction: 0.031831, Regularization: 0.008438\n",
      "====> Epoch: 172 Average loss: 0.0411\n",
      "Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 0.043019\n",
      "Reconstruction: 0.034800, Regularization: 0.008219\n",
      "Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 0.040075\n",
      "Reconstruction: 0.030672, Regularization: 0.009403\n",
      "Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 0.040204\n",
      "Reconstruction: 0.028899, Regularization: 0.011306\n",
      "Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 0.039874\n",
      "Reconstruction: 0.030641, Regularization: 0.009233\n",
      "Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 0.036899\n",
      "Reconstruction: 0.028184, Regularization: 0.008715\n",
      "Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 0.041596\n",
      "Reconstruction: 0.031865, Regularization: 0.009731\n",
      "Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 0.040064\n",
      "Reconstruction: 0.030308, Regularization: 0.009756\n",
      "Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 0.034433\n",
      "Reconstruction: 0.023856, Regularization: 0.010577\n",
      "====> Epoch: 173 Average loss: 0.0411\n",
      "Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 0.035410\n",
      "Reconstruction: 0.027314, Regularization: 0.008096\n",
      "Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 0.041653\n",
      "Reconstruction: 0.031107, Regularization: 0.010546\n",
      "Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 0.042740\n",
      "Reconstruction: 0.033493, Regularization: 0.009246\n",
      "Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 0.038702\n",
      "Reconstruction: 0.031857, Regularization: 0.006845\n",
      "Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 0.043005\n",
      "Reconstruction: 0.033024, Regularization: 0.009981\n",
      "Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 0.043811\n",
      "Reconstruction: 0.035282, Regularization: 0.008529\n",
      "Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 0.043190\n",
      "Reconstruction: 0.032962, Regularization: 0.010229\n",
      "Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 0.040400\n",
      "Reconstruction: 0.030984, Regularization: 0.009416\n",
      "====> Epoch: 174 Average loss: 0.0412\n",
      "Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 0.035427\n",
      "Reconstruction: 0.028916, Regularization: 0.006511\n",
      "Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 0.045887\n",
      "Reconstruction: 0.035507, Regularization: 0.010379\n",
      "Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 0.041705\n",
      "Reconstruction: 0.031543, Regularization: 0.010162\n",
      "Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 0.040315\n",
      "Reconstruction: 0.029409, Regularization: 0.010906\n",
      "Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 0.038352\n",
      "Reconstruction: 0.030056, Regularization: 0.008296\n",
      "Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 0.037782\n",
      "Reconstruction: 0.031498, Regularization: 0.006285\n",
      "Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 0.035133\n",
      "Reconstruction: 0.027835, Regularization: 0.007298\n",
      "Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 0.044709\n",
      "Reconstruction: 0.035687, Regularization: 0.009023\n",
      "====> Epoch: 175 Average loss: 0.0411\n",
      "Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 0.045872\n",
      "Reconstruction: 0.033105, Regularization: 0.012767\n",
      "Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 0.037838\n",
      "Reconstruction: 0.031387, Regularization: 0.006451\n",
      "Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 0.036155\n",
      "Reconstruction: 0.027359, Regularization: 0.008796\n",
      "Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 0.035054\n",
      "Reconstruction: 0.028351, Regularization: 0.006703\n",
      "Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 0.039948\n",
      "Reconstruction: 0.029294, Regularization: 0.010654\n",
      "Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 0.044470\n",
      "Reconstruction: 0.036096, Regularization: 0.008375\n",
      "Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 0.038634\n",
      "Reconstruction: 0.028803, Regularization: 0.009831\n",
      "Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 0.034383\n",
      "Reconstruction: 0.026869, Regularization: 0.007514\n",
      "====> Epoch: 176 Average loss: 0.0413\n",
      "Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 0.033967\n",
      "Reconstruction: 0.027789, Regularization: 0.006178\n",
      "Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 0.039512\n",
      "Reconstruction: 0.031455, Regularization: 0.008057\n",
      "Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 0.041864\n",
      "Reconstruction: 0.033036, Regularization: 0.008828\n",
      "Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 0.039726\n",
      "Reconstruction: 0.029688, Regularization: 0.010038\n",
      "Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 0.045472\n",
      "Reconstruction: 0.035900, Regularization: 0.009572\n",
      "Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 0.043304\n",
      "Reconstruction: 0.032701, Regularization: 0.010603\n",
      "Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 0.038632\n",
      "Reconstruction: 0.028806, Regularization: 0.009826\n",
      "Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 0.038860\n",
      "Reconstruction: 0.029715, Regularization: 0.009146\n",
      "====> Epoch: 177 Average loss: 0.0412\n",
      "Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 0.035218\n",
      "Reconstruction: 0.029332, Regularization: 0.005886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 0.042181\n",
      "Reconstruction: 0.032171, Regularization: 0.010010\n",
      "Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 0.038918\n",
      "Reconstruction: 0.027405, Regularization: 0.011513\n",
      "Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 0.034495\n",
      "Reconstruction: 0.025543, Regularization: 0.008952\n",
      "Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 0.043816\n",
      "Reconstruction: 0.032929, Regularization: 0.010887\n",
      "Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 0.040615\n",
      "Reconstruction: 0.030716, Regularization: 0.009899\n",
      "Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 0.035387\n",
      "Reconstruction: 0.026998, Regularization: 0.008389\n",
      "Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 0.033542\n",
      "Reconstruction: 0.024599, Regularization: 0.008943\n",
      "====> Epoch: 178 Average loss: 0.0409\n",
      "Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 0.042569\n",
      "Reconstruction: 0.032044, Regularization: 0.010525\n",
      "Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 0.040163\n",
      "Reconstruction: 0.030619, Regularization: 0.009544\n",
      "Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 0.044417\n",
      "Reconstruction: 0.035302, Regularization: 0.009115\n",
      "Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 0.044329\n",
      "Reconstruction: 0.035252, Regularization: 0.009078\n",
      "Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 0.034201\n",
      "Reconstruction: 0.029100, Regularization: 0.005101\n",
      "Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 0.048043\n",
      "Reconstruction: 0.037153, Regularization: 0.010890\n",
      "Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 0.040457\n",
      "Reconstruction: 0.029905, Regularization: 0.010551\n",
      "Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 0.037986\n",
      "Reconstruction: 0.030875, Regularization: 0.007111\n",
      "====> Epoch: 179 Average loss: 0.0418\n",
      "Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 0.038406\n",
      "Reconstruction: 0.029082, Regularization: 0.009324\n",
      "Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 0.039003\n",
      "Reconstruction: 0.030520, Regularization: 0.008483\n",
      "Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 0.045366\n",
      "Reconstruction: 0.036556, Regularization: 0.008810\n",
      "Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 0.045503\n",
      "Reconstruction: 0.034096, Regularization: 0.011408\n",
      "Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 0.037765\n",
      "Reconstruction: 0.029684, Regularization: 0.008080\n",
      "Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 0.049661\n",
      "Reconstruction: 0.037855, Regularization: 0.011807\n",
      "Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 0.042225\n",
      "Reconstruction: 0.033298, Regularization: 0.008927\n",
      "Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 0.046654\n",
      "Reconstruction: 0.035394, Regularization: 0.011259\n",
      "====> Epoch: 180 Average loss: 0.0414\n",
      "Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 0.039967\n",
      "Reconstruction: 0.030673, Regularization: 0.009294\n",
      "Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 0.046006\n",
      "Reconstruction: 0.035354, Regularization: 0.010652\n",
      "Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 0.043454\n",
      "Reconstruction: 0.033452, Regularization: 0.010002\n",
      "Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 0.039112\n",
      "Reconstruction: 0.030253, Regularization: 0.008859\n",
      "Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 0.043431\n",
      "Reconstruction: 0.030992, Regularization: 0.012439\n",
      "Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 0.038045\n",
      "Reconstruction: 0.030639, Regularization: 0.007406\n",
      "Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 0.036513\n",
      "Reconstruction: 0.027810, Regularization: 0.008703\n",
      "Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 0.046704\n",
      "Reconstruction: 0.034353, Regularization: 0.012351\n",
      "====> Epoch: 181 Average loss: 0.0414\n",
      "Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 0.035103\n",
      "Reconstruction: 0.026566, Regularization: 0.008537\n",
      "Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 0.040393\n",
      "Reconstruction: 0.030053, Regularization: 0.010340\n",
      "Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 0.040364\n",
      "Reconstruction: 0.030359, Regularization: 0.010005\n",
      "Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 0.045016\n",
      "Reconstruction: 0.033636, Regularization: 0.011381\n",
      "Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 0.045222\n",
      "Reconstruction: 0.033842, Regularization: 0.011380\n",
      "Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 0.037087\n",
      "Reconstruction: 0.028699, Regularization: 0.008387\n",
      "Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 0.041867\n",
      "Reconstruction: 0.033776, Regularization: 0.008091\n",
      "Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 0.037862\n",
      "Reconstruction: 0.028749, Regularization: 0.009112\n",
      "====> Epoch: 182 Average loss: 0.0413\n",
      "Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 0.036995\n",
      "Reconstruction: 0.028811, Regularization: 0.008184\n",
      "Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 0.051120\n",
      "Reconstruction: 0.039589, Regularization: 0.011532\n",
      "Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 0.044862\n",
      "Reconstruction: 0.034058, Regularization: 0.010804\n",
      "Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 0.041686\n",
      "Reconstruction: 0.031341, Regularization: 0.010345\n",
      "Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 0.036201\n",
      "Reconstruction: 0.028577, Regularization: 0.007624\n",
      "Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 0.042276\n",
      "Reconstruction: 0.032346, Regularization: 0.009930\n",
      "Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 0.036242\n",
      "Reconstruction: 0.028758, Regularization: 0.007484\n",
      "Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 0.041294\n",
      "Reconstruction: 0.033174, Regularization: 0.008120\n",
      "====> Epoch: 183 Average loss: 0.0415\n",
      "Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 0.046705\n",
      "Reconstruction: 0.034323, Regularization: 0.012382\n",
      "Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 0.040943\n",
      "Reconstruction: 0.032115, Regularization: 0.008828\n",
      "Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 0.037672\n",
      "Reconstruction: 0.028028, Regularization: 0.009644\n",
      "Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 0.044091\n",
      "Reconstruction: 0.033086, Regularization: 0.011004\n",
      "Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 0.038784\n",
      "Reconstruction: 0.029423, Regularization: 0.009361\n",
      "Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 0.038244\n",
      "Reconstruction: 0.029977, Regularization: 0.008268\n",
      "Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 0.038763\n",
      "Reconstruction: 0.030347, Regularization: 0.008416\n",
      "Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 0.039465\n",
      "Reconstruction: 0.029663, Regularization: 0.009802\n",
      "====> Epoch: 184 Average loss: 0.0414\n",
      "Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 0.043719\n",
      "Reconstruction: 0.031735, Regularization: 0.011984\n",
      "Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 0.033651\n",
      "Reconstruction: 0.026190, Regularization: 0.007461\n",
      "Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 0.039681\n",
      "Reconstruction: 0.029738, Regularization: 0.009942\n",
      "Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 0.037506\n",
      "Reconstruction: 0.027041, Regularization: 0.010465\n",
      "Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 0.043668\n",
      "Reconstruction: 0.032427, Regularization: 0.011241\n",
      "Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 0.044875\n",
      "Reconstruction: 0.034613, Regularization: 0.010262\n",
      "Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 0.037927\n",
      "Reconstruction: 0.030698, Regularization: 0.007230\n",
      "Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 0.040825\n",
      "Reconstruction: 0.032330, Regularization: 0.008495\n",
      "====> Epoch: 185 Average loss: 0.0417\n",
      "Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 0.051145\n",
      "Reconstruction: 0.038506, Regularization: 0.012639\n",
      "Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 0.042247\n",
      "Reconstruction: 0.033916, Regularization: 0.008330\n",
      "Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 0.045275\n",
      "Reconstruction: 0.033643, Regularization: 0.011632\n",
      "Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 0.033086\n",
      "Reconstruction: 0.026080, Regularization: 0.007006\n",
      "Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 0.036116\n",
      "Reconstruction: 0.027083, Regularization: 0.009034\n",
      "Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 0.033090\n",
      "Reconstruction: 0.025722, Regularization: 0.007367\n",
      "Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 0.042994\n",
      "Reconstruction: 0.033028, Regularization: 0.009966\n",
      "Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 0.042113\n",
      "Reconstruction: 0.032325, Regularization: 0.009789\n",
      "====> Epoch: 186 Average loss: 0.0412\n",
      "Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 0.054387\n",
      "Reconstruction: 0.040039, Regularization: 0.014347\n",
      "Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 0.044429\n",
      "Reconstruction: 0.034598, Regularization: 0.009831\n",
      "Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 0.050378\n",
      "Reconstruction: 0.037864, Regularization: 0.012514\n",
      "Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 0.046479\n",
      "Reconstruction: 0.035829, Regularization: 0.010650\n",
      "Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 0.040790\n",
      "Reconstruction: 0.031734, Regularization: 0.009056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 0.039991\n",
      "Reconstruction: 0.028335, Regularization: 0.011656\n",
      "Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 0.039600\n",
      "Reconstruction: 0.030170, Regularization: 0.009429\n",
      "Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 0.036922\n",
      "Reconstruction: 0.026447, Regularization: 0.010475\n",
      "====> Epoch: 187 Average loss: 0.0408\n",
      "Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 0.042377\n",
      "Reconstruction: 0.033622, Regularization: 0.008756\n",
      "Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 0.042909\n",
      "Reconstruction: 0.032245, Regularization: 0.010664\n",
      "Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 0.039366\n",
      "Reconstruction: 0.031180, Regularization: 0.008186\n",
      "Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 0.035118\n",
      "Reconstruction: 0.028297, Regularization: 0.006821\n",
      "Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 0.039430\n",
      "Reconstruction: 0.028960, Regularization: 0.010470\n",
      "Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 0.041464\n",
      "Reconstruction: 0.030754, Regularization: 0.010709\n",
      "Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 0.046405\n",
      "Reconstruction: 0.035759, Regularization: 0.010646\n",
      "Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 0.036410\n",
      "Reconstruction: 0.028597, Regularization: 0.007813\n",
      "====> Epoch: 188 Average loss: 0.0416\n",
      "Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 0.038878\n",
      "Reconstruction: 0.030538, Regularization: 0.008340\n",
      "Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 0.038152\n",
      "Reconstruction: 0.030511, Regularization: 0.007641\n",
      "Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 0.045700\n",
      "Reconstruction: 0.035444, Regularization: 0.010256\n",
      "Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 0.035636\n",
      "Reconstruction: 0.025709, Regularization: 0.009926\n",
      "Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 0.044758\n",
      "Reconstruction: 0.034871, Regularization: 0.009887\n",
      "Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 0.040810\n",
      "Reconstruction: 0.032015, Regularization: 0.008796\n",
      "Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 0.042042\n",
      "Reconstruction: 0.032343, Regularization: 0.009699\n",
      "Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 0.039800\n",
      "Reconstruction: 0.031523, Regularization: 0.008277\n",
      "====> Epoch: 189 Average loss: 0.0416\n",
      "Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 0.043395\n",
      "Reconstruction: 0.031848, Regularization: 0.011547\n",
      "Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 0.038603\n",
      "Reconstruction: 0.031147, Regularization: 0.007456\n",
      "Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 0.049503\n",
      "Reconstruction: 0.037038, Regularization: 0.012465\n",
      "Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 0.039130\n",
      "Reconstruction: 0.030762, Regularization: 0.008367\n",
      "Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 0.036566\n",
      "Reconstruction: 0.028839, Regularization: 0.007727\n",
      "Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 0.040888\n",
      "Reconstruction: 0.031803, Regularization: 0.009085\n",
      "Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 0.043289\n",
      "Reconstruction: 0.032565, Regularization: 0.010724\n",
      "Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 0.042855\n",
      "Reconstruction: 0.032366, Regularization: 0.010489\n",
      "====> Epoch: 190 Average loss: 0.0412\n",
      "Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 0.053545\n",
      "Reconstruction: 0.039260, Regularization: 0.014285\n",
      "Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 0.038204\n",
      "Reconstruction: 0.028621, Regularization: 0.009582\n",
      "Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 0.045454\n",
      "Reconstruction: 0.033396, Regularization: 0.012059\n",
      "Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 0.039407\n",
      "Reconstruction: 0.029268, Regularization: 0.010138\n",
      "Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 0.040227\n",
      "Reconstruction: 0.030112, Regularization: 0.010115\n",
      "Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 0.038871\n",
      "Reconstruction: 0.029391, Regularization: 0.009480\n",
      "Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 0.034271\n",
      "Reconstruction: 0.026567, Regularization: 0.007704\n",
      "Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 0.045944\n",
      "Reconstruction: 0.036940, Regularization: 0.009004\n",
      "====> Epoch: 191 Average loss: 0.0412\n",
      "Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 0.049705\n",
      "Reconstruction: 0.038787, Regularization: 0.010919\n",
      "Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 0.042067\n",
      "Reconstruction: 0.031548, Regularization: 0.010518\n",
      "Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.037960\n",
      "Reconstruction: 0.030567, Regularization: 0.007393\n",
      "Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 0.039039\n",
      "Reconstruction: 0.030756, Regularization: 0.008283\n",
      "Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 0.036555\n",
      "Reconstruction: 0.029423, Regularization: 0.007132\n",
      "Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 0.039940\n",
      "Reconstruction: 0.031341, Regularization: 0.008599\n",
      "Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 0.039134\n",
      "Reconstruction: 0.029900, Regularization: 0.009235\n",
      "Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 0.043721\n",
      "Reconstruction: 0.033237, Regularization: 0.010485\n",
      "====> Epoch: 192 Average loss: 0.0420\n",
      "Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 0.050130\n",
      "Reconstruction: 0.036211, Regularization: 0.013919\n",
      "Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 0.037702\n",
      "Reconstruction: 0.028042, Regularization: 0.009660\n",
      "Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 0.038665\n",
      "Reconstruction: 0.030444, Regularization: 0.008221\n",
      "Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 0.037741\n",
      "Reconstruction: 0.027813, Regularization: 0.009928\n",
      "Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 0.038693\n",
      "Reconstruction: 0.029271, Regularization: 0.009422\n",
      "Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 0.036416\n",
      "Reconstruction: 0.028455, Regularization: 0.007961\n",
      "Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 0.035695\n",
      "Reconstruction: 0.027718, Regularization: 0.007977\n",
      "Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 0.042945\n",
      "Reconstruction: 0.031328, Regularization: 0.011617\n",
      "====> Epoch: 193 Average loss: 0.0413\n",
      "Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 0.038041\n",
      "Reconstruction: 0.031621, Regularization: 0.006420\n",
      "Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 0.047009\n",
      "Reconstruction: 0.034889, Regularization: 0.012120\n",
      "Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 0.037194\n",
      "Reconstruction: 0.026897, Regularization: 0.010297\n",
      "Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 0.049667\n",
      "Reconstruction: 0.037824, Regularization: 0.011844\n",
      "Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 0.043093\n",
      "Reconstruction: 0.032816, Regularization: 0.010278\n",
      "Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 0.038971\n",
      "Reconstruction: 0.029243, Regularization: 0.009727\n",
      "Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 0.042020\n",
      "Reconstruction: 0.031753, Regularization: 0.010267\n",
      "Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 0.044463\n",
      "Reconstruction: 0.034222, Regularization: 0.010241\n",
      "====> Epoch: 194 Average loss: 0.0413\n",
      "Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 0.047953\n",
      "Reconstruction: 0.034252, Regularization: 0.013701\n",
      "Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 0.045776\n",
      "Reconstruction: 0.035602, Regularization: 0.010174\n",
      "Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 0.040331\n",
      "Reconstruction: 0.030114, Regularization: 0.010218\n",
      "Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 0.040745\n",
      "Reconstruction: 0.031844, Regularization: 0.008902\n",
      "Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 0.041024\n",
      "Reconstruction: 0.031333, Regularization: 0.009691\n",
      "Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 0.037871\n",
      "Reconstruction: 0.029784, Regularization: 0.008087\n",
      "Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 0.038443\n",
      "Reconstruction: 0.030067, Regularization: 0.008377\n",
      "Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 0.043911\n",
      "Reconstruction: 0.032931, Regularization: 0.010980\n",
      "====> Epoch: 195 Average loss: 0.0415\n",
      "Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 0.043024\n",
      "Reconstruction: 0.033480, Regularization: 0.009544\n",
      "Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 0.036803\n",
      "Reconstruction: 0.027484, Regularization: 0.009319\n",
      "Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 0.039741\n",
      "Reconstruction: 0.030102, Regularization: 0.009640\n",
      "Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 0.047943\n",
      "Reconstruction: 0.035362, Regularization: 0.012581\n",
      "Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 0.034285\n",
      "Reconstruction: 0.026122, Regularization: 0.008163\n",
      "Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 0.041502\n",
      "Reconstruction: 0.030840, Regularization: 0.010662\n",
      "Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 0.032693\n",
      "Reconstruction: 0.025978, Regularization: 0.006715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 0.039880\n",
      "Reconstruction: 0.030558, Regularization: 0.009322\n",
      "====> Epoch: 196 Average loss: 0.0409\n",
      "Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 0.045595\n",
      "Reconstruction: 0.036734, Regularization: 0.008861\n",
      "Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 0.035093\n",
      "Reconstruction: 0.028379, Regularization: 0.006714\n",
      "Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 0.048133\n",
      "Reconstruction: 0.038062, Regularization: 0.010071\n",
      "Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 0.040900\n",
      "Reconstruction: 0.029268, Regularization: 0.011632\n",
      "Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 0.037316\n",
      "Reconstruction: 0.028688, Regularization: 0.008629\n",
      "Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 0.043290\n",
      "Reconstruction: 0.032750, Regularization: 0.010539\n",
      "Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 0.038686\n",
      "Reconstruction: 0.028866, Regularization: 0.009820\n",
      "Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 0.050645\n",
      "Reconstruction: 0.037474, Regularization: 0.013171\n",
      "====> Epoch: 197 Average loss: 0.0411\n",
      "Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 0.040312\n",
      "Reconstruction: 0.029485, Regularization: 0.010827\n",
      "Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.046963\n",
      "Reconstruction: 0.037527, Regularization: 0.009436\n",
      "Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 0.041797\n",
      "Reconstruction: 0.033049, Regularization: 0.008749\n",
      "Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 0.038112\n",
      "Reconstruction: 0.028599, Regularization: 0.009513\n",
      "Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 0.044515\n",
      "Reconstruction: 0.036356, Regularization: 0.008159\n",
      "Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 0.036248\n",
      "Reconstruction: 0.028497, Regularization: 0.007751\n",
      "Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 0.041620\n",
      "Reconstruction: 0.030966, Regularization: 0.010654\n",
      "Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 0.039444\n",
      "Reconstruction: 0.030337, Regularization: 0.009107\n",
      "====> Epoch: 198 Average loss: 0.0409\n",
      "Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 0.042502\n",
      "Reconstruction: 0.032934, Regularization: 0.009568\n",
      "Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 0.041849\n",
      "Reconstruction: 0.030357, Regularization: 0.011492\n",
      "Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 0.037612\n",
      "Reconstruction: 0.029701, Regularization: 0.007911\n",
      "Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 0.037246\n",
      "Reconstruction: 0.029464, Regularization: 0.007782\n",
      "Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 0.041496\n",
      "Reconstruction: 0.031789, Regularization: 0.009707\n",
      "Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 0.045284\n",
      "Reconstruction: 0.034096, Regularization: 0.011188\n",
      "Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.045092\n",
      "Reconstruction: 0.036130, Regularization: 0.008962\n",
      "Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 0.043270\n",
      "Reconstruction: 0.032842, Regularization: 0.010429\n",
      "====> Epoch: 199 Average loss: 0.0414\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 200\n",
    "LR = 1e-4  # TODO: increase LR\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.999\n",
    "\n",
    "PRINT_INTERVAL = 16\n",
    "N_FROM_PRIOR = 1000\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "vae = toynn.VAE(\n",
    "    latent_dim=latent_dim, data_dim=data_dim, \n",
    "    n_layers=n_layers, nonlinearity=nonlinearity,\n",
    "    with_biasx=False,\n",
    "    with_logvarx=False,\n",
    "    with_biasz=False,\n",
    "    with_logvarz=False)\n",
    "vae.to(DEVICE)\n",
    "\n",
    "modules = {}\n",
    "modules['encoder'] = vae.encoder\n",
    "modules['decoder'] = vae.decoder\n",
    "\n",
    "print('\\n-- Values of parameters before learning')\n",
    "decoder = modules['decoder']\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "optimizers = {}\n",
    "optimizers['encoder'] = torch.optim.Adam(\n",
    "    modules['encoder'].parameters(), lr=LR, betas=(BETA1, BETA2))\n",
    "optimizers['decoder'] = torch.optim.Adam(\n",
    "    modules['decoder'].parameters(), lr=LR, betas=(BETA1, BETA2))\n",
    "\n",
    "def init_xavier_normal(m):\n",
    "    if type(m) == tnn.Linear:\n",
    "        tnn.init.xavier_normal_(m.weight)\n",
    "    else:\n",
    "        print('Error of layer type.', type(m))\n",
    "        \n",
    "for module in modules.values():\n",
    "    module.apply(init_xavier_normal)\n",
    "\n",
    "\n",
    "train_losses_all_epochs = []\n",
    "test_losses_all_epochs = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_losses = toytrain_vae(\n",
    "        epoch, train_loader, modules, optimizers)\n",
    "    \n",
    "    train_losses_all_epochs.append(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last losses:\n",
      "[0.041480558067560194, 0.04088488367199898, 0.04108098813891411, 0.04094149371981621, 0.041356930136680604]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "plt.plot(range(N_EPOCHS), train_losses_total)\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate estimates from standard VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[2.]], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[-1.1069]], device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "decoder = modules['decoder']\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "generated_true_x = generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = generate_from_decoder(decoder, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f63480b02b0>"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'hist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-241-50e69de03614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_true_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_side\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis_side\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'darkgreen'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-215-75645f1c76f5>\u001b[0m in \u001b[0;36mplot_data\u001b[0;34m(x_data, color, axis_side, ax)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_dim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBINS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mALPHA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'from decoder true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'hist'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For 2D\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(12, 12))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0, 0]\n",
    "plot_data(generated_true_x, color='darkgreen')\n",
    "\n",
    "ax = axes[0, 1]\n",
    "plot_data(generated_x, color='red')\n",
    "\n",
    "ax = axes[1, 0]\n",
    "plot_kde(generated_true_x, ax, 'Greens', axis_side)\n",
    "\n",
    "ax = axes[1, 1]\n",
    "plot_kde(generated_x, ax, 'Reds', axis_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk(theta):\n",
    "    #loglikelihood_i = ... theta ...\n",
    "\n",
    "    n_samples = 1000\n",
    "    generated_true_x = generate_from_decoder(decoder_true, n_samples)\n",
    "    risk = - np.mean([loglikelihood_i.subs({x_i: sp.Matrix(x_elt)}) for x_elt in generated_true_x])\n",
    "    return risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Encoder(\n",
       "    (fc1): Linear(in_features=2, out_features=1, bias=True)\n",
       "    (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (relu): ReLU()\n",
       "    (sigmoid): Sigmoid()\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=1, out_features=2, bias=True)\n",
       "      (1): Linear(in_features=2, out_features=2, bias=True)\n",
       "      (2): Linear(in_features=2, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = toynn.VAE(\n",
    "    latent_dim=latent_dim, data_dim=data_dim, \n",
    "    n_layers=n_layers, nonlinearity=nonlinearity)\n",
    "vae.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "-- Values of parameters before learning\n",
      "layers.0.weight tensor([[-0.7359]], device='cuda:0') \n",
      "\n",
      "tensor(0.3179, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3187, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 0.153956\n",
      "Reconstruction: 0.035497, Regularization: 0.076676, Discriminator: 0.023915; Generator: 0.017868,\n",
      "D(x): 0.318, D(G(z)): 0.319\n",
      "tensor(0.3183, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3197, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 0.142510\n",
      "Reconstruction: 0.032403, Regularization: 0.068371, Discriminator: 0.023916; Generator: 0.017819,\n",
      "D(x): 0.318, D(G(z)): 0.320\n",
      "tensor(0.3223, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3210, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 0.134124\n",
      "Reconstruction: 0.031645, Regularization: 0.060972, Discriminator: 0.023754; Generator: 0.017753,\n",
      "D(x): 0.322, D(G(z)): 0.321\n",
      "tensor(0.3194, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3219, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 0.170759\n",
      "Reconstruction: 0.039298, Regularization: 0.089828, Discriminator: 0.023921; Generator: 0.017711,\n",
      "D(x): 0.319, D(G(z)): 0.322\n",
      "tensor(0.3259, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3227, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 0.147654\n",
      "Reconstruction: 0.035623, Regularization: 0.070738, Discriminator: 0.023619; Generator: 0.017675,\n",
      "D(x): 0.326, D(G(z)): 0.323\n",
      "tensor(0.3238, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3240, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 0.142626\n",
      "Reconstruction: 0.033134, Regularization: 0.068131, Discriminator: 0.023752; Generator: 0.017609,\n",
      "D(x): 0.324, D(G(z)): 0.324\n",
      "tensor(0.3279, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3249, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 0.149602\n",
      "Reconstruction: 0.034731, Regularization: 0.073730, Discriminator: 0.023577; Generator: 0.017564,\n",
      "D(x): 0.328, D(G(z)): 0.325\n",
      "tensor(0.3253, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3260, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 0.137019\n",
      "Reconstruction: 0.032810, Regularization: 0.062975, Discriminator: 0.023721; Generator: 0.017514,\n",
      "D(x): 0.325, D(G(z)): 0.326\n",
      "====> Epoch: 0 Average loss: 0.1490\n",
      "tensor(0.3261, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3268, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 0.120378\n",
      "Reconstruction: 0.029003, Regularization: 0.050199, Discriminator: 0.023703; Generator: 0.017473,\n",
      "D(x): 0.326, D(G(z)): 0.327\n",
      "tensor(0.3252, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3278, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 0.163924\n",
      "Reconstruction: 0.037732, Regularization: 0.084989, Discriminator: 0.023775; Generator: 0.017428,\n",
      "D(x): 0.325, D(G(z)): 0.328\n",
      "tensor(0.3299, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3286, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 0.122789\n",
      "Reconstruction: 0.030415, Regularization: 0.051422, Discriminator: 0.023562; Generator: 0.017389,\n",
      "D(x): 0.330, D(G(z)): 0.329\n",
      "tensor(0.3318, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3298, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 0.167560\n",
      "Reconstruction: 0.039467, Regularization: 0.087254, Discriminator: 0.023508; Generator: 0.017331,\n",
      "D(x): 0.332, D(G(z)): 0.330\n",
      "tensor(0.3312, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3310, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 0.155732\n",
      "Reconstruction: 0.036422, Regularization: 0.078475, Discriminator: 0.023559; Generator: 0.017276,\n",
      "D(x): 0.331, D(G(z)): 0.331\n",
      "tensor(0.3323, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3317, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 0.128574\n",
      "Reconstruction: 0.031008, Regularization: 0.056801, Discriminator: 0.023524; Generator: 0.017242,\n",
      "D(x): 0.332, D(G(z)): 0.332\n",
      "tensor(0.3310, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3330, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 0.126783\n",
      "Reconstruction: 0.030960, Regularization: 0.055029, Discriminator: 0.023614; Generator: 0.017181,\n",
      "D(x): 0.331, D(G(z)): 0.333\n",
      "tensor(0.3349, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3342, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 0.146378\n",
      "Reconstruction: 0.034585, Regularization: 0.071204, Discriminator: 0.023461; Generator: 0.017127,\n",
      "D(x): 0.335, D(G(z)): 0.334\n",
      "====> Epoch: 1 Average loss: 0.1473\n",
      "tensor(0.3347, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3349, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 0.165097\n",
      "Reconstruction: 0.038942, Regularization: 0.085573, Discriminator: 0.023491; Generator: 0.017092,\n",
      "D(x): 0.335, D(G(z)): 0.335\n",
      "tensor(0.3342, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3358, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 0.162254\n",
      "Reconstruction: 0.037562, Regularization: 0.084109, Discriminator: 0.023535; Generator: 0.017048,\n",
      "D(x): 0.334, D(G(z)): 0.336\n",
      "tensor(0.3409, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3368, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 0.170670\n",
      "Reconstruction: 0.040062, Regularization: 0.090358, Discriminator: 0.023246; Generator: 0.017004,\n",
      "D(x): 0.341, D(G(z)): 0.337\n",
      "tensor(0.3358, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3379, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 0.136663\n",
      "Reconstruction: 0.033181, Regularization: 0.063026, Discriminator: 0.023504; Generator: 0.016951,\n",
      "D(x): 0.336, D(G(z)): 0.338\n",
      "tensor(0.3418, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3391, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 0.119100\n",
      "Reconstruction: 0.029401, Regularization: 0.049548, Discriminator: 0.023252; Generator: 0.016899,\n",
      "D(x): 0.342, D(G(z)): 0.339\n",
      "tensor(0.3392, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3401, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 0.148689\n",
      "Reconstruction: 0.035675, Regularization: 0.072761, Discriminator: 0.023401; Generator: 0.016852,\n",
      "D(x): 0.339, D(G(z)): 0.340\n",
      "tensor(0.3415, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3410, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 0.136796\n",
      "Reconstruction: 0.033187, Regularization: 0.063483, Discriminator: 0.023317; Generator: 0.016810,\n",
      "D(x): 0.341, D(G(z)): 0.341\n",
      "tensor(0.3417, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3421, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 0.144246\n",
      "Reconstruction: 0.035153, Regularization: 0.069003, Discriminator: 0.023330; Generator: 0.016760,\n",
      "D(x): 0.342, D(G(z)): 0.342\n",
      "====> Epoch: 2 Average loss: 0.1456\n",
      "tensor(0.3416, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3431, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 0.133086\n",
      "Reconstruction: 0.032051, Regularization: 0.060963, Discriminator: 0.023357; Generator: 0.016715,\n",
      "D(x): 0.342, D(G(z)): 0.343\n",
      "tensor(0.3414, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3441, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 0.143648\n",
      "Reconstruction: 0.035183, Regularization: 0.068405, Discriminator: 0.023391; Generator: 0.016669,\n",
      "D(x): 0.341, D(G(z)): 0.344\n",
      "tensor(0.3475, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3449, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 0.131153\n",
      "Reconstruction: 0.032233, Regularization: 0.059154, Discriminator: 0.023132; Generator: 0.016635,\n",
      "D(x): 0.348, D(G(z)): 0.345\n",
      "tensor(0.3482, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3459, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 0.134705\n",
      "Reconstruction: 0.033007, Regularization: 0.061982, Discriminator: 0.023129; Generator: 0.016587,\n",
      "D(x): 0.348, D(G(z)): 0.346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3492, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3471, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 0.149177\n",
      "Reconstruction: 0.035759, Regularization: 0.073773, Discriminator: 0.023111; Generator: 0.016534,\n",
      "D(x): 0.349, D(G(z)): 0.347\n",
      "tensor(0.3473, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3482, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 0.160767\n",
      "Reconstruction: 0.039610, Regularization: 0.081449, Discriminator: 0.023223; Generator: 0.016485,\n",
      "D(x): 0.347, D(G(z)): 0.348\n",
      "tensor(0.3490, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3490, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 0.157587\n",
      "Reconstruction: 0.039010, Regularization: 0.078962, Discriminator: 0.023167; Generator: 0.016447,\n",
      "D(x): 0.349, D(G(z)): 0.349\n",
      "tensor(0.3527, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3503, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 0.155781\n",
      "Reconstruction: 0.038478, Regularization: 0.077879, Discriminator: 0.023032; Generator: 0.016391,\n",
      "D(x): 0.353, D(G(z)): 0.350\n",
      "====> Epoch: 3 Average loss: 0.1440\n",
      "tensor(0.3497, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3509, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 0.151167\n",
      "Reconstruction: 0.036835, Regularization: 0.074790, Discriminator: 0.023180; Generator: 0.016362,\n",
      "D(x): 0.350, D(G(z)): 0.351\n",
      "tensor(0.3507, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3519, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 0.168622\n",
      "Reconstruction: 0.041971, Regularization: 0.087172, Discriminator: 0.023160; Generator: 0.016319,\n",
      "D(x): 0.351, D(G(z)): 0.352\n",
      "tensor(0.3534, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3530, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 0.106650\n",
      "Reconstruction: 0.027659, Regularization: 0.039659, Discriminator: 0.023060; Generator: 0.016272,\n",
      "D(x): 0.353, D(G(z)): 0.353\n",
      "tensor(0.3524, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3538, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 0.127910\n",
      "Reconstruction: 0.032072, Regularization: 0.056479, Discriminator: 0.023126; Generator: 0.016233,\n",
      "D(x): 0.352, D(G(z)): 0.354\n",
      "tensor(0.3581, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3553, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 0.161633\n",
      "Reconstruction: 0.040462, Regularization: 0.082087, Discriminator: 0.022916; Generator: 0.016167,\n",
      "D(x): 0.358, D(G(z)): 0.355\n",
      "tensor(0.3547, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3563, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 0.141496\n",
      "Reconstruction: 0.035515, Regularization: 0.066768, Discriminator: 0.023090; Generator: 0.016123,\n",
      "D(x): 0.355, D(G(z)): 0.356\n",
      "tensor(0.3570, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3572, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 0.138197\n",
      "Reconstruction: 0.034493, Regularization: 0.064613, Discriminator: 0.023007; Generator: 0.016084,\n",
      "D(x): 0.357, D(G(z)): 0.357\n",
      "tensor(0.3580, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3585, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 0.128840\n",
      "Reconstruction: 0.032654, Regularization: 0.057162, Discriminator: 0.022995; Generator: 0.016029,\n",
      "D(x): 0.358, D(G(z)): 0.358\n",
      "====> Epoch: 4 Average loss: 0.1424\n",
      "tensor(0.3612, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3590, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 0.113552\n",
      "Reconstruction: 0.028436, Regularization: 0.046242, Discriminator: 0.022866; Generator: 0.016008,\n",
      "D(x): 0.361, D(G(z)): 0.359\n",
      "tensor(0.3607, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3600, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 0.142690\n",
      "Reconstruction: 0.036250, Regularization: 0.067563, Discriminator: 0.022915; Generator: 0.015961,\n",
      "D(x): 0.361, D(G(z)): 0.360\n",
      "tensor(0.3599, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3615, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 0.152296\n",
      "Reconstruction: 0.038635, Regularization: 0.074774, Discriminator: 0.022989; Generator: 0.015898,\n",
      "D(x): 0.360, D(G(z)): 0.362\n",
      "tensor(0.3615, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3623, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 0.135732\n",
      "Reconstruction: 0.034772, Regularization: 0.062160, Discriminator: 0.022936; Generator: 0.015864,\n",
      "D(x): 0.362, D(G(z)): 0.362\n",
      "tensor(0.3629, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3635, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 0.110803\n",
      "Reconstruction: 0.028422, Regularization: 0.043667, Discriminator: 0.022900; Generator: 0.015814,\n",
      "D(x): 0.363, D(G(z)): 0.363\n",
      "tensor(0.3659, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3644, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 0.145764\n",
      "Reconstruction: 0.036696, Regularization: 0.070497, Discriminator: 0.022800; Generator: 0.015771,\n",
      "D(x): 0.366, D(G(z)): 0.364\n",
      "tensor(0.3630, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3657, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 0.143394\n",
      "Reconstruction: 0.036151, Regularization: 0.068570, Discriminator: 0.022954; Generator: 0.015719,\n",
      "D(x): 0.363, D(G(z)): 0.366\n",
      "tensor(0.3642, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3665, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 0.123642\n",
      "Reconstruction: 0.030989, Regularization: 0.054049, Discriminator: 0.022922; Generator: 0.015682,\n",
      "D(x): 0.364, D(G(z)): 0.367\n",
      "====> Epoch: 5 Average loss: 0.1409\n",
      "tensor(0.3653, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3677, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 0.123314\n",
      "Reconstruction: 0.032430, Regularization: 0.052346, Discriminator: 0.022903; Generator: 0.015634,\n",
      "D(x): 0.365, D(G(z)): 0.368\n",
      "tensor(0.3697, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3685, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 0.130217\n",
      "Reconstruction: 0.032939, Regularization: 0.058942, Discriminator: 0.022737; Generator: 0.015600,\n",
      "D(x): 0.370, D(G(z)): 0.368\n",
      "tensor(0.3698, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3698, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 0.105028\n",
      "Reconstruction: 0.026369, Regularization: 0.040353, Discriminator: 0.022761; Generator: 0.015545,\n",
      "D(x): 0.370, D(G(z)): 0.370\n",
      "tensor(0.3697, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3710, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 0.140903\n",
      "Reconstruction: 0.035447, Regularization: 0.067164, Discriminator: 0.022800; Generator: 0.015492,\n",
      "D(x): 0.370, D(G(z)): 0.371\n",
      "tensor(0.3719, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3721, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 0.123050\n",
      "Reconstruction: 0.031969, Regularization: 0.052901, Discriminator: 0.022734; Generator: 0.015445,\n",
      "D(x): 0.372, D(G(z)): 0.372\n",
      "tensor(0.3737, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3731, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 0.141680\n",
      "Reconstruction: 0.035793, Regularization: 0.067797, Discriminator: 0.022683; Generator: 0.015406,\n",
      "D(x): 0.374, D(G(z)): 0.373\n",
      "tensor(0.3733, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3741, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 0.133748\n",
      "Reconstruction: 0.034428, Regularization: 0.061230, Discriminator: 0.022726; Generator: 0.015364,\n",
      "D(x): 0.373, D(G(z)): 0.374\n",
      "tensor(0.3738, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3751, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 0.146021\n",
      "Reconstruction: 0.038076, Regularization: 0.069890, Discriminator: 0.022733; Generator: 0.015321,\n",
      "D(x): 0.374, D(G(z)): 0.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 6 Average loss: 0.1393\n",
      "tensor(0.3746, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3762, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 0.153691\n",
      "Reconstruction: 0.039247, Regularization: 0.076442, Discriminator: 0.022725; Generator: 0.015277,\n",
      "D(x): 0.375, D(G(z)): 0.376\n",
      "tensor(0.3762, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3773, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 0.142123\n",
      "Reconstruction: 0.036661, Regularization: 0.067545, Discriminator: 0.022688; Generator: 0.015230,\n",
      "D(x): 0.376, D(G(z)): 0.377\n",
      "tensor(0.3812, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3786, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 0.148094\n",
      "Reconstruction: 0.038858, Regularization: 0.071549, Discriminator: 0.022511; Generator: 0.015176,\n",
      "D(x): 0.381, D(G(z)): 0.379\n",
      "tensor(0.3829, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3796, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 0.147267\n",
      "Reconstruction: 0.037580, Regularization: 0.072086, Discriminator: 0.022466; Generator: 0.015135,\n",
      "D(x): 0.383, D(G(z)): 0.380\n",
      "tensor(0.3804, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3807, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 0.133562\n",
      "Reconstruction: 0.035204, Regularization: 0.060670, Discriminator: 0.022597; Generator: 0.015091,\n",
      "D(x): 0.380, D(G(z)): 0.381\n",
      "tensor(0.3838, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3820, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 0.136504\n",
      "Reconstruction: 0.035885, Regularization: 0.063091, Discriminator: 0.022494; Generator: 0.015035,\n",
      "D(x): 0.384, D(G(z)): 0.382\n",
      "tensor(0.3857, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3833, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 0.130925\n",
      "Reconstruction: 0.034755, Regularization: 0.058740, Discriminator: 0.022445; Generator: 0.014985,\n",
      "D(x): 0.386, D(G(z)): 0.383\n",
      "tensor(0.3857, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3844, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 0.152644\n",
      "Reconstruction: 0.040895, Regularization: 0.074333, Discriminator: 0.022476; Generator: 0.014940,\n",
      "D(x): 0.386, D(G(z)): 0.384\n",
      "====> Epoch: 7 Average loss: 0.1376\n",
      "tensor(0.3851, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3853, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 0.135690\n",
      "Reconstruction: 0.036280, Regularization: 0.061988, Discriminator: 0.022520; Generator: 0.014903,\n",
      "D(x): 0.385, D(G(z)): 0.385\n",
      "tensor(0.3850, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3866, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 0.132949\n",
      "Reconstruction: 0.034855, Regularization: 0.060685, Discriminator: 0.022560; Generator: 0.014849,\n",
      "D(x): 0.385, D(G(z)): 0.387\n",
      "tensor(0.3878, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3877, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 0.157580\n",
      "Reconstruction: 0.041190, Regularization: 0.079109, Discriminator: 0.022475; Generator: 0.014805,\n",
      "D(x): 0.388, D(G(z)): 0.388\n",
      "tensor(0.3894, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3887, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 0.134575\n",
      "Reconstruction: 0.036371, Regularization: 0.061007, Discriminator: 0.022434; Generator: 0.014763,\n",
      "D(x): 0.389, D(G(z)): 0.389\n",
      "tensor(0.3886, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3901, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 0.139514\n",
      "Reconstruction: 0.036706, Regularization: 0.065597, Discriminator: 0.022502; Generator: 0.014709,\n",
      "D(x): 0.389, D(G(z)): 0.390\n",
      "tensor(0.3914, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3914, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 0.145759\n",
      "Reconstruction: 0.039551, Regularization: 0.069130, Discriminator: 0.022423; Generator: 0.014656,\n",
      "D(x): 0.391, D(G(z)): 0.391\n",
      "tensor(0.3915, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3926, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 0.139698\n",
      "Reconstruction: 0.036616, Regularization: 0.066022, Discriminator: 0.022452; Generator: 0.014609,\n",
      "D(x): 0.391, D(G(z)): 0.393\n",
      "tensor(0.3954, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3937, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 0.105879\n",
      "Reconstruction: 0.028260, Regularization: 0.040732, Discriminator: 0.022323; Generator: 0.014563,\n",
      "D(x): 0.395, D(G(z)): 0.394\n",
      "====> Epoch: 8 Average loss: 0.1362\n",
      "tensor(0.3941, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3950, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 0.149361\n",
      "Reconstruction: 0.039859, Regularization: 0.072577, Discriminator: 0.022411; Generator: 0.014514,\n",
      "D(x): 0.394, D(G(z)): 0.395\n",
      "tensor(0.3943, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3960, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 0.138068\n",
      "Reconstruction: 0.036656, Regularization: 0.064512, Discriminator: 0.022426; Generator: 0.014473,\n",
      "D(x): 0.394, D(G(z)): 0.396\n",
      "tensor(0.3947, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3974, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 0.131066\n",
      "Reconstruction: 0.035394, Regularization: 0.058807, Discriminator: 0.022448; Generator: 0.014418,\n",
      "D(x): 0.395, D(G(z)): 0.397\n",
      "tensor(0.4006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.3989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 0.150269\n",
      "Reconstruction: 0.039866, Regularization: 0.073790, Discriminator: 0.022254; Generator: 0.014359,\n",
      "D(x): 0.401, D(G(z)): 0.399\n",
      "tensor(0.3986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 0.129762\n",
      "Reconstruction: 0.034790, Regularization: 0.058295, Discriminator: 0.022364; Generator: 0.014312,\n",
      "D(x): 0.399, D(G(z)): 0.400\n",
      "tensor(0.4005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 0.137949\n",
      "Reconstruction: 0.036728, Regularization: 0.064632, Discriminator: 0.022319; Generator: 0.014270,\n",
      "D(x): 0.400, D(G(z)): 0.401\n",
      "tensor(0.4041, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4026, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 0.157805\n",
      "Reconstruction: 0.042259, Regularization: 0.079114, Discriminator: 0.022214; Generator: 0.014217,\n",
      "D(x): 0.404, D(G(z)): 0.403\n",
      "tensor(0.4023, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4037, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 0.154233\n",
      "Reconstruction: 0.041409, Regularization: 0.076339, Discriminator: 0.022312; Generator: 0.014173,\n",
      "D(x): 0.402, D(G(z)): 0.404\n",
      "====> Epoch: 9 Average loss: 0.1346\n",
      "tensor(0.4075, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4050, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 0.130885\n",
      "Reconstruction: 0.034318, Regularization: 0.060297, Discriminator: 0.022146; Generator: 0.014124,\n",
      "D(x): 0.407, D(G(z)): 0.405\n",
      "tensor(0.4042, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4060, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 0.141676\n",
      "Reconstruction: 0.037668, Regularization: 0.067624, Discriminator: 0.022298; Generator: 0.014085,\n",
      "D(x): 0.404, D(G(z)): 0.406\n",
      "tensor(0.4087, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4073, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 0.148481\n",
      "Reconstruction: 0.039674, Regularization: 0.072613, Discriminator: 0.022160; Generator: 0.014034,\n",
      "D(x): 0.409, D(G(z)): 0.407\n",
      "tensor(0.4092, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4086, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 0.117544\n",
      "Reconstruction: 0.032499, Regularization: 0.048886, Discriminator: 0.022173; Generator: 0.013986,\n",
      "D(x): 0.409, D(G(z)): 0.409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4112, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4102, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 0.127426\n",
      "Reconstruction: 0.034664, Regularization: 0.056696, Discriminator: 0.022142; Generator: 0.013924,\n",
      "D(x): 0.411, D(G(z)): 0.410\n",
      "tensor(0.4108, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4112, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 0.151043\n",
      "Reconstruction: 0.041335, Regularization: 0.073640, Discriminator: 0.022185; Generator: 0.013884,\n",
      "D(x): 0.411, D(G(z)): 0.411\n",
      "tensor(0.4126, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4125, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 0.123645\n",
      "Reconstruction: 0.033797, Regularization: 0.053864, Discriminator: 0.022147; Generator: 0.013837,\n",
      "D(x): 0.413, D(G(z)): 0.412\n",
      "tensor(0.4147, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4142, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 0.123944\n",
      "Reconstruction: 0.034162, Regularization: 0.053897, Discriminator: 0.022113; Generator: 0.013772,\n",
      "D(x): 0.415, D(G(z)): 0.414\n",
      "====> Epoch: 10 Average loss: 0.1332\n",
      "tensor(0.4160, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4150, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.115660\n",
      "Reconstruction: 0.032228, Regularization: 0.047605, Discriminator: 0.022087; Generator: 0.013741,\n",
      "D(x): 0.416, D(G(z)): 0.415\n",
      "tensor(0.4185, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4161, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 0.150946\n",
      "Reconstruction: 0.041714, Regularization: 0.073509, Discriminator: 0.022024; Generator: 0.013699,\n",
      "D(x): 0.419, D(G(z)): 0.416\n",
      "tensor(0.4154, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4174, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.152027\n",
      "Reconstruction: 0.042027, Regularization: 0.074172, Discriminator: 0.022176; Generator: 0.013653,\n",
      "D(x): 0.415, D(G(z)): 0.417\n",
      "tensor(0.4152, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4190, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 0.131269\n",
      "Reconstruction: 0.036020, Regularization: 0.059432, Discriminator: 0.022225; Generator: 0.013592,\n",
      "D(x): 0.415, D(G(z)): 0.419\n",
      "tensor(0.4192, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4197, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 0.122630\n",
      "Reconstruction: 0.033921, Regularization: 0.053050, Discriminator: 0.022093; Generator: 0.013567,\n",
      "D(x): 0.419, D(G(z)): 0.420\n",
      "tensor(0.4232, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4213, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 0.120071\n",
      "Reconstruction: 0.034183, Regularization: 0.050395, Discriminator: 0.021988; Generator: 0.013505,\n",
      "D(x): 0.423, D(G(z)): 0.421\n",
      "tensor(0.4234, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4226, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.128954\n",
      "Reconstruction: 0.036178, Regularization: 0.057304, Discriminator: 0.022013; Generator: 0.013459,\n",
      "D(x): 0.423, D(G(z)): 0.423\n",
      "tensor(0.4238, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4241, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 0.138215\n",
      "Reconstruction: 0.038419, Regularization: 0.064352, Discriminator: 0.022041; Generator: 0.013403,\n",
      "D(x): 0.424, D(G(z)): 0.424\n",
      "====> Epoch: 11 Average loss: 0.1319\n",
      "tensor(0.4226, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4251, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 0.148345\n",
      "Reconstruction: 0.041078, Regularization: 0.071785, Discriminator: 0.022114; Generator: 0.013368,\n",
      "D(x): 0.423, D(G(z)): 0.425\n",
      "tensor(0.4261, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4263, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 0.130788\n",
      "Reconstruction: 0.036833, Regularization: 0.058618, Discriminator: 0.022015; Generator: 0.013323,\n",
      "D(x): 0.426, D(G(z)): 0.426\n",
      "tensor(0.4269, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4274, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 0.143731\n",
      "Reconstruction: 0.040745, Regularization: 0.067686, Discriminator: 0.022019; Generator: 0.013281,\n",
      "D(x): 0.427, D(G(z)): 0.427\n",
      "tensor(0.4296, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4286, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 0.125128\n",
      "Reconstruction: 0.036166, Regularization: 0.053774, Discriminator: 0.021952; Generator: 0.013236,\n",
      "D(x): 0.430, D(G(z)): 0.429\n",
      "tensor(0.4288, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4299, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 0.129649\n",
      "Reconstruction: 0.036508, Regularization: 0.057935, Discriminator: 0.022014; Generator: 0.013192,\n",
      "D(x): 0.429, D(G(z)): 0.430\n",
      "tensor(0.4326, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4315, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.117180\n",
      "Reconstruction: 0.033916, Regularization: 0.048210, Discriminator: 0.021921; Generator: 0.013132,\n",
      "D(x): 0.433, D(G(z)): 0.432\n",
      "tensor(0.4329, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4327, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.129105\n",
      "Reconstruction: 0.036751, Regularization: 0.057320, Discriminator: 0.021945; Generator: 0.013089,\n",
      "D(x): 0.433, D(G(z)): 0.433\n",
      "tensor(0.4328, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4337, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 0.126562\n",
      "Reconstruction: 0.035795, Regularization: 0.055740, Discriminator: 0.021973; Generator: 0.013053,\n",
      "D(x): 0.433, D(G(z)): 0.434\n",
      "====> Epoch: 12 Average loss: 0.1306\n",
      "tensor(0.4354, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4349, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 0.131392\n",
      "Reconstruction: 0.037624, Regularization: 0.058844, Discriminator: 0.021913; Generator: 0.013011,\n",
      "D(x): 0.435, D(G(z)): 0.435\n",
      "tensor(0.4344, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4360, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 0.122741\n",
      "Reconstruction: 0.035491, Regularization: 0.052298, Discriminator: 0.021983; Generator: 0.012969,\n",
      "D(x): 0.434, D(G(z)): 0.436\n",
      "tensor(0.4358, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4374, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 0.130778\n",
      "Reconstruction: 0.036978, Regularization: 0.058910, Discriminator: 0.021971; Generator: 0.012921,\n",
      "D(x): 0.436, D(G(z)): 0.437\n",
      "tensor(0.4382, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4387, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 0.128723\n",
      "Reconstruction: 0.036220, Regularization: 0.057709, Discriminator: 0.021919; Generator: 0.012874,\n",
      "D(x): 0.438, D(G(z)): 0.439\n",
      "tensor(0.4413, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4400, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 0.135772\n",
      "Reconstruction: 0.038344, Regularization: 0.062754, Discriminator: 0.021847; Generator: 0.012827,\n",
      "D(x): 0.441, D(G(z)): 0.440\n",
      "tensor(0.4415, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4412, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 0.139013\n",
      "Reconstruction: 0.040468, Regularization: 0.063887, Discriminator: 0.021873; Generator: 0.012786,\n",
      "D(x): 0.441, D(G(z)): 0.441\n",
      "tensor(0.4418, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4422, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 0.149849\n",
      "Reconstruction: 0.044334, Regularization: 0.070874, Discriminator: 0.021889; Generator: 0.012752,\n",
      "D(x): 0.442, D(G(z)): 0.442\n",
      "tensor(0.4436, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4434, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 0.128667\n",
      "Reconstruction: 0.037881, Regularization: 0.056220, Discriminator: 0.021858; Generator: 0.012709,\n",
      "D(x): 0.444, D(G(z)): 0.443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 13 Average loss: 0.1292\n",
      "tensor(0.4443, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4445, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.135377\n",
      "Reconstruction: 0.039480, Regularization: 0.061360, Discriminator: 0.021867; Generator: 0.012669,\n",
      "D(x): 0.444, D(G(z)): 0.444\n",
      "tensor(0.4473, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4456, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.125867\n",
      "Reconstruction: 0.036865, Regularization: 0.054581, Discriminator: 0.021789; Generator: 0.012631,\n",
      "D(x): 0.447, D(G(z)): 0.446\n",
      "tensor(0.4478, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4468, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 0.124590\n",
      "Reconstruction: 0.036685, Regularization: 0.053511, Discriminator: 0.021806; Generator: 0.012588,\n",
      "D(x): 0.448, D(G(z)): 0.447\n",
      "tensor(0.4493, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4482, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.098230\n",
      "Reconstruction: 0.028508, Regularization: 0.035389, Discriminator: 0.021794; Generator: 0.012539,\n",
      "D(x): 0.449, D(G(z)): 0.448\n",
      "tensor(0.4491, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4492, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.098113\n",
      "Reconstruction: 0.028255, Regularization: 0.035525, Discriminator: 0.021828; Generator: 0.012505,\n",
      "D(x): 0.449, D(G(z)): 0.449\n",
      "tensor(0.4490, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4505, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 0.114803\n",
      "Reconstruction: 0.033638, Regularization: 0.046836, Discriminator: 0.021868; Generator: 0.012461,\n",
      "D(x): 0.449, D(G(z)): 0.450\n",
      "tensor(0.4505, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4515, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.133700\n",
      "Reconstruction: 0.039601, Regularization: 0.059828, Discriminator: 0.021846; Generator: 0.012424,\n",
      "D(x): 0.451, D(G(z)): 0.452\n",
      "tensor(0.4529, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4527, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.147296\n",
      "Reconstruction: 0.042023, Regularization: 0.071091, Discriminator: 0.021799; Generator: 0.012383,\n",
      "D(x): 0.453, D(G(z)): 0.453\n",
      "====> Epoch: 14 Average loss: 0.1278\n",
      "tensor(0.4530, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4537, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 0.100310\n",
      "Reconstruction: 0.029425, Regularization: 0.036715, Discriminator: 0.021820; Generator: 0.012350,\n",
      "D(x): 0.453, D(G(z)): 0.454\n",
      "tensor(0.4556, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4547, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 0.125697\n",
      "Reconstruction: 0.037301, Regularization: 0.054319, Discriminator: 0.021763; Generator: 0.012313,\n",
      "D(x): 0.456, D(G(z)): 0.455\n",
      "tensor(0.4545, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4557, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.119570\n",
      "Reconstruction: 0.035239, Regularization: 0.050224, Discriminator: 0.021826; Generator: 0.012280,\n",
      "D(x): 0.455, D(G(z)): 0.456\n",
      "tensor(0.4577, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4569, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.165155\n",
      "Reconstruction: 0.048494, Regularization: 0.082666, Discriminator: 0.021757; Generator: 0.012238,\n",
      "D(x): 0.458, D(G(z)): 0.457\n",
      "tensor(0.4578, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4579, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.110553\n",
      "Reconstruction: 0.032191, Regularization: 0.044380, Discriminator: 0.021778; Generator: 0.012203,\n",
      "D(x): 0.458, D(G(z)): 0.458\n",
      "tensor(0.4603, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4592, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.133381\n",
      "Reconstruction: 0.039914, Regularization: 0.059577, Discriminator: 0.021728; Generator: 0.012162,\n",
      "D(x): 0.460, D(G(z)): 0.459\n",
      "tensor(0.4606, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4601, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.102396\n",
      "Reconstruction: 0.030969, Regularization: 0.037550, Discriminator: 0.021745; Generator: 0.012131,\n",
      "D(x): 0.461, D(G(z)): 0.460\n",
      "tensor(0.4627, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4611, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 0.115530\n",
      "Reconstruction: 0.035109, Regularization: 0.046621, Discriminator: 0.021703; Generator: 0.012097,\n",
      "D(x): 0.463, D(G(z)): 0.461\n",
      "====> Epoch: 15 Average loss: 0.1266\n",
      "tensor(0.4620, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4620, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 0.119043\n",
      "Reconstruction: 0.035599, Regularization: 0.049623, Discriminator: 0.021754; Generator: 0.012067,\n",
      "D(x): 0.462, D(G(z)): 0.462\n",
      "tensor(0.4628, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4631, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 0.119725\n",
      "Reconstruction: 0.036463, Regularization: 0.049475, Discriminator: 0.021758; Generator: 0.012030,\n",
      "D(x): 0.463, D(G(z)): 0.463\n",
      "tensor(0.4630, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4640, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.121946\n",
      "Reconstruction: 0.036713, Regularization: 0.051456, Discriminator: 0.021778; Generator: 0.011999,\n",
      "D(x): 0.463, D(G(z)): 0.464\n",
      "tensor(0.4662, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4651, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 0.126773\n",
      "Reconstruction: 0.038709, Regularization: 0.054400, Discriminator: 0.021702; Generator: 0.011962,\n",
      "D(x): 0.466, D(G(z)): 0.465\n",
      "tensor(0.4666, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4659, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 0.100354\n",
      "Reconstruction: 0.030405, Regularization: 0.036303, Discriminator: 0.021712; Generator: 0.011934,\n",
      "D(x): 0.467, D(G(z)): 0.466\n",
      "tensor(0.4681, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4668, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 0.127265\n",
      "Reconstruction: 0.037623, Regularization: 0.056050, Discriminator: 0.021688; Generator: 0.011904,\n",
      "D(x): 0.468, D(G(z)): 0.467\n",
      "tensor(0.4672, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4679, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 0.123847\n",
      "Reconstruction: 0.036806, Regularization: 0.053423, Discriminator: 0.021749; Generator: 0.011869,\n",
      "D(x): 0.467, D(G(z)): 0.468\n",
      "tensor(0.4695, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4688, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.120302\n",
      "Reconstruction: 0.036710, Regularization: 0.050056, Discriminator: 0.021698; Generator: 0.011839,\n",
      "D(x): 0.470, D(G(z)): 0.469\n",
      "====> Epoch: 16 Average loss: 0.1252\n",
      "tensor(0.4686, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4693, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.162028\n",
      "Reconstruction: 0.049369, Regularization: 0.079094, Discriminator: 0.021746; Generator: 0.011819,\n",
      "D(x): 0.469, D(G(z)): 0.469\n",
      "tensor(0.4718, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4704, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 0.126173\n",
      "Reconstruction: 0.038134, Regularization: 0.054585, Discriminator: 0.021671; Generator: 0.011783,\n",
      "D(x): 0.472, D(G(z)): 0.470\n",
      "tensor(0.4713, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4713, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.104102\n",
      "Reconstruction: 0.031610, Regularization: 0.039024, Discriminator: 0.021715; Generator: 0.011753,\n",
      "D(x): 0.471, D(G(z)): 0.471\n",
      "tensor(0.4728, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4723, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 0.098414\n",
      "Reconstruction: 0.030036, Regularization: 0.034964, Discriminator: 0.021692; Generator: 0.011723,\n",
      "D(x): 0.473, D(G(z)): 0.472\n",
      "tensor(0.4724, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4731, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.125256\n",
      "Reconstruction: 0.038511, Regularization: 0.053320, Discriminator: 0.021730; Generator: 0.011695,\n",
      "D(x): 0.472, D(G(z)): 0.473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4746, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4739, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 0.098375\n",
      "Reconstruction: 0.030096, Regularization: 0.034929, Discriminator: 0.021684; Generator: 0.011667,\n",
      "D(x): 0.475, D(G(z)): 0.474\n",
      "tensor(0.4756, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4749, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 0.104648\n",
      "Reconstruction: 0.032226, Regularization: 0.039107, Discriminator: 0.021678; Generator: 0.011637,\n",
      "D(x): 0.476, D(G(z)): 0.475\n",
      "tensor(0.4755, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4755, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 0.107396\n",
      "Reconstruction: 0.032873, Regularization: 0.041209, Discriminator: 0.021699; Generator: 0.011615,\n",
      "D(x): 0.476, D(G(z)): 0.476\n",
      "====> Epoch: 17 Average loss: 0.1241\n",
      "tensor(0.4765, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4762, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 0.136374\n",
      "Reconstruction: 0.041578, Regularization: 0.061516, Discriminator: 0.021686; Generator: 0.011593,\n",
      "D(x): 0.477, D(G(z)): 0.476\n",
      "tensor(0.4777, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4770, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.114185\n",
      "Reconstruction: 0.034922, Regularization: 0.046026, Discriminator: 0.021673; Generator: 0.011565,\n",
      "D(x): 0.478, D(G(z)): 0.477\n",
      "tensor(0.4773, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4778, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 0.101321\n",
      "Reconstruction: 0.030619, Regularization: 0.037454, Discriminator: 0.021707; Generator: 0.011541,\n",
      "D(x): 0.477, D(G(z)): 0.478\n",
      "tensor(0.4770, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4786, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.124924\n",
      "Reconstruction: 0.038464, Regularization: 0.053204, Discriminator: 0.021742; Generator: 0.011513,\n",
      "D(x): 0.477, D(G(z)): 0.479\n",
      "tensor(0.4792, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4793, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 0.111198\n",
      "Reconstruction: 0.033500, Regularization: 0.044514, Discriminator: 0.021693; Generator: 0.011491,\n",
      "D(x): 0.479, D(G(z)): 0.479\n",
      "tensor(0.4781, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4800, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.136189\n",
      "Reconstruction: 0.041606, Regularization: 0.061365, Discriminator: 0.021748; Generator: 0.011469,\n",
      "D(x): 0.478, D(G(z)): 0.480\n",
      "tensor(0.4791, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4806, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 0.120739\n",
      "Reconstruction: 0.037486, Regularization: 0.050070, Discriminator: 0.021735; Generator: 0.011448,\n",
      "D(x): 0.479, D(G(z)): 0.481\n",
      "tensor(0.4814, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4814, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 0.103490\n",
      "Reconstruction: 0.031861, Regularization: 0.038522, Discriminator: 0.021684; Generator: 0.011423,\n",
      "D(x): 0.481, D(G(z)): 0.481\n",
      "====> Epoch: 18 Average loss: 0.1232\n",
      "tensor(0.4832, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4818, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 0.110846\n",
      "Reconstruction: 0.034613, Regularization: 0.043184, Discriminator: 0.021640; Generator: 0.011409,\n",
      "D(x): 0.483, D(G(z)): 0.482\n",
      "tensor(0.4827, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4827, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 0.143525\n",
      "Reconstruction: 0.045281, Regularization: 0.065183, Discriminator: 0.021679; Generator: 0.011381,\n",
      "D(x): 0.483, D(G(z)): 0.483\n",
      "tensor(0.4830, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4831, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 0.108429\n",
      "Reconstruction: 0.033999, Regularization: 0.041380, Discriminator: 0.021684; Generator: 0.011366,\n",
      "D(x): 0.483, D(G(z)): 0.483\n",
      "tensor(0.4830, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4836, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 0.130080\n",
      "Reconstruction: 0.040693, Regularization: 0.056336, Discriminator: 0.021700; Generator: 0.011350,\n",
      "D(x): 0.483, D(G(z)): 0.484\n",
      "tensor(0.4852, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4844, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 0.113040\n",
      "Reconstruction: 0.034751, Regularization: 0.045312, Discriminator: 0.021651; Generator: 0.011325,\n",
      "D(x): 0.485, D(G(z)): 0.484\n",
      "tensor(0.4853, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4851, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 0.105311\n",
      "Reconstruction: 0.032605, Regularization: 0.039735, Discriminator: 0.021667; Generator: 0.011304,\n",
      "D(x): 0.485, D(G(z)): 0.485\n",
      "tensor(0.4842, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4856, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 0.145943\n",
      "Reconstruction: 0.046152, Regularization: 0.066784, Discriminator: 0.021719; Generator: 0.011287,\n",
      "D(x): 0.484, D(G(z)): 0.486\n",
      "tensor(0.4857, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4861, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.105731\n",
      "Reconstruction: 0.032977, Regularization: 0.039798, Discriminator: 0.021686; Generator: 0.011270,\n",
      "D(x): 0.486, D(G(z)): 0.486\n",
      "====> Epoch: 19 Average loss: 0.1220\n",
      "tensor(0.4862, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4866, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 0.116820\n",
      "Reconstruction: 0.036455, Regularization: 0.047424, Discriminator: 0.021687; Generator: 0.011254,\n",
      "D(x): 0.486, D(G(z)): 0.487\n",
      "tensor(0.4864, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4872, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 0.134162\n",
      "Reconstruction: 0.043028, Regularization: 0.058200, Discriminator: 0.021698; Generator: 0.011236,\n",
      "D(x): 0.486, D(G(z)): 0.487\n",
      "tensor(0.4878, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4877, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 0.123211\n",
      "Reconstruction: 0.039030, Regularization: 0.051293, Discriminator: 0.021669; Generator: 0.011220,\n",
      "D(x): 0.488, D(G(z)): 0.488\n",
      "tensor(0.4880, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4882, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 0.114618\n",
      "Reconstruction: 0.035667, Regularization: 0.046070, Discriminator: 0.021678; Generator: 0.011203,\n",
      "D(x): 0.488, D(G(z)): 0.488\n",
      "tensor(0.4889, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4886, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 0.132590\n",
      "Reconstruction: 0.042044, Regularization: 0.057694, Discriminator: 0.021662; Generator: 0.011190,\n",
      "D(x): 0.489, D(G(z)): 0.489\n",
      "tensor(0.4896, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4891, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 0.112132\n",
      "Reconstruction: 0.035396, Regularization: 0.043908, Discriminator: 0.021653; Generator: 0.011175,\n",
      "D(x): 0.490, D(G(z)): 0.489\n",
      "tensor(0.4899, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4896, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 0.104440\n",
      "Reconstruction: 0.032362, Regularization: 0.039262, Discriminator: 0.021658; Generator: 0.011159,\n",
      "D(x): 0.490, D(G(z)): 0.490\n",
      "tensor(0.4903, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4900, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 0.113155\n",
      "Reconstruction: 0.035187, Regularization: 0.045164, Discriminator: 0.021659; Generator: 0.011145,\n",
      "D(x): 0.490, D(G(z)): 0.490\n",
      "====> Epoch: 20 Average loss: 0.1210\n",
      "tensor(0.4904, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4903, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.143896\n",
      "Reconstruction: 0.045261, Regularization: 0.065833, Discriminator: 0.021666; Generator: 0.011136,\n",
      "D(x): 0.490, D(G(z)): 0.490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4907, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4907, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 0.126819\n",
      "Reconstruction: 0.040421, Regularization: 0.053608, Discriminator: 0.021667; Generator: 0.011123,\n",
      "D(x): 0.491, D(G(z)): 0.491\n",
      "tensor(0.4915, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4912, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 0.097545\n",
      "Reconstruction: 0.031222, Regularization: 0.033560, Discriminator: 0.021656; Generator: 0.011107,\n",
      "D(x): 0.492, D(G(z)): 0.491\n",
      "tensor(0.4919, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4915, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 0.115387\n",
      "Reconstruction: 0.037013, Regularization: 0.045622, Discriminator: 0.021654; Generator: 0.011099,\n",
      "D(x): 0.492, D(G(z)): 0.491\n",
      "tensor(0.4921, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4920, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.097132\n",
      "Reconstruction: 0.030377, Regularization: 0.034011, Discriminator: 0.021660; Generator: 0.011084,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "tensor(0.4920, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4923, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 0.120524\n",
      "Reconstruction: 0.038571, Regularization: 0.049205, Discriminator: 0.021676; Generator: 0.011071,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "tensor(0.4927, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4928, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 0.119232\n",
      "Reconstruction: 0.038274, Regularization: 0.048234, Discriminator: 0.021667; Generator: 0.011057,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "tensor(0.4923, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4930, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.133528\n",
      "Reconstruction: 0.042582, Regularization: 0.058209, Discriminator: 0.021685; Generator: 0.011051,\n",
      "D(x): 0.492, D(G(z)): 0.493\n",
      "====> Epoch: 21 Average loss: 0.1200\n",
      "tensor(0.4930, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4933, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 0.108274\n",
      "Reconstruction: 0.035143, Regularization: 0.040416, Discriminator: 0.021676; Generator: 0.011040,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "tensor(0.4936, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4936, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 0.121069\n",
      "Reconstruction: 0.039451, Regularization: 0.048921, Discriminator: 0.021665; Generator: 0.011031,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "tensor(0.4930, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4939, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 0.110926\n",
      "Reconstruction: 0.036135, Regularization: 0.042076, Discriminator: 0.021693; Generator: 0.011022,\n",
      "D(x): 0.493, D(G(z)): 0.494\n",
      "tensor(0.4937, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4942, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 0.108436\n",
      "Reconstruction: 0.034723, Regularization: 0.041022, Discriminator: 0.021678; Generator: 0.011013,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "tensor(0.4949, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4945, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.132453\n",
      "Reconstruction: 0.042176, Regularization: 0.057622, Discriminator: 0.021652; Generator: 0.011004,\n",
      "D(x): 0.495, D(G(z)): 0.494\n",
      "tensor(0.4948, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4947, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 0.123376\n",
      "Reconstruction: 0.040178, Regularization: 0.050541, Discriminator: 0.021661; Generator: 0.010996,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "tensor(0.4951, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4951, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 0.115224\n",
      "Reconstruction: 0.037014, Regularization: 0.045564, Discriminator: 0.021662; Generator: 0.010984,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "tensor(0.4949, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4953, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 0.119302\n",
      "Reconstruction: 0.039304, Regularization: 0.047345, Discriminator: 0.021674; Generator: 0.010979,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "====> Epoch: 22 Average loss: 0.1190\n",
      "tensor(0.4956, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4954, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 0.118345\n",
      "Reconstruction: 0.038341, Regularization: 0.047374, Discriminator: 0.021655; Generator: 0.010974,\n",
      "D(x): 0.496, D(G(z)): 0.495\n",
      "tensor(0.4955, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4957, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 0.108083\n",
      "Reconstruction: 0.035031, Regularization: 0.040420, Discriminator: 0.021667; Generator: 0.010966,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "tensor(0.4956, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4960, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 0.097788\n",
      "Reconstruction: 0.031338, Regularization: 0.033820, Discriminator: 0.021674; Generator: 0.010956,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "tensor(0.4961, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4961, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 0.140317\n",
      "Reconstruction: 0.045429, Regularization: 0.062274, Discriminator: 0.021660; Generator: 0.010954,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "tensor(0.4967, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4964, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 0.122443\n",
      "Reconstruction: 0.040709, Regularization: 0.049139, Discriminator: 0.021650; Generator: 0.010945,\n",
      "D(x): 0.497, D(G(z)): 0.496\n",
      "tensor(0.4977, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4965, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 0.128238\n",
      "Reconstruction: 0.041073, Regularization: 0.054600, Discriminator: 0.021626; Generator: 0.010939,\n",
      "D(x): 0.498, D(G(z)): 0.497\n",
      "tensor(0.4967, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4967, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 0.126242\n",
      "Reconstruction: 0.042140, Regularization: 0.051505, Discriminator: 0.021663; Generator: 0.010934,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "tensor(0.4967, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4969, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 0.122235\n",
      "Reconstruction: 0.040503, Regularization: 0.049136, Discriminator: 0.021669; Generator: 0.010926,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "====> Epoch: 23 Average loss: 0.1182\n",
      "tensor(0.4968, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4971, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.124861\n",
      "Reconstruction: 0.041143, Regularization: 0.051127, Discriminator: 0.021669; Generator: 0.010922,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "tensor(0.4969, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4972, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 0.116482\n",
      "Reconstruction: 0.037501, Regularization: 0.046390, Discriminator: 0.021672; Generator: 0.010919,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "tensor(0.4973, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4974, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 0.107730\n",
      "Reconstruction: 0.035813, Regularization: 0.039341, Discriminator: 0.021662; Generator: 0.010913,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "tensor(0.4979, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4975, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 0.129514\n",
      "Reconstruction: 0.042695, Regularization: 0.054261, Discriminator: 0.021649; Generator: 0.010909,\n",
      "D(x): 0.498, D(G(z)): 0.497\n",
      "tensor(0.4975, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4977, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 0.122779\n",
      "Reconstruction: 0.040694, Regularization: 0.049514, Discriminator: 0.021667; Generator: 0.010904,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "tensor(0.4975, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4978, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 0.119275\n",
      "Reconstruction: 0.038756, Regularization: 0.047949, Discriminator: 0.021670; Generator: 0.010901,\n",
      "D(x): 0.497, D(G(z)): 0.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4979, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 0.122423\n",
      "Reconstruction: 0.040887, Regularization: 0.048981, Discriminator: 0.021661; Generator: 0.010895,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 0.104762\n",
      "Reconstruction: 0.034507, Regularization: 0.037700, Discriminator: 0.021664; Generator: 0.010891,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "====> Epoch: 24 Average loss: 0.1173\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 0.112398\n",
      "Reconstruction: 0.037550, Regularization: 0.042296, Discriminator: 0.021664; Generator: 0.010889,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 0.127365\n",
      "Reconstruction: 0.042667, Regularization: 0.052153, Discriminator: 0.021661; Generator: 0.010885,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 0.129513\n",
      "Reconstruction: 0.042159, Regularization: 0.054809, Discriminator: 0.021664; Generator: 0.010882,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 0.117382\n",
      "Reconstruction: 0.039808, Regularization: 0.045035, Discriminator: 0.021661; Generator: 0.010879,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 0.112812\n",
      "Reconstruction: 0.037930, Regularization: 0.042343, Discriminator: 0.021662; Generator: 0.010876,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 0.108512\n",
      "Reconstruction: 0.035612, Regularization: 0.040357, Discriminator: 0.021669; Generator: 0.010873,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.101569\n",
      "Reconstruction: 0.033269, Regularization: 0.035777, Discriminator: 0.021654; Generator: 0.010869,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 0.120229\n",
      "Reconstruction: 0.039734, Regularization: 0.047967, Discriminator: 0.021660; Generator: 0.010867,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "====> Epoch: 25 Average loss: 0.1165\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 0.114637\n",
      "Reconstruction: 0.038953, Regularization: 0.043149, Discriminator: 0.021671; Generator: 0.010865,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 0.137909\n",
      "Reconstruction: 0.046651, Regularization: 0.058722, Discriminator: 0.021673; Generator: 0.010863,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 0.113956\n",
      "Reconstruction: 0.038629, Regularization: 0.042807, Discriminator: 0.021659; Generator: 0.010861,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 0.125781\n",
      "Reconstruction: 0.042707, Regularization: 0.050555, Discriminator: 0.021660; Generator: 0.010859,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.119058\n",
      "Reconstruction: 0.040107, Regularization: 0.046434, Discriminator: 0.021661; Generator: 0.010856,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 0.129735\n",
      "Reconstruction: 0.043855, Regularization: 0.053369, Discriminator: 0.021656; Generator: 0.010855,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 0.102131\n",
      "Reconstruction: 0.034449, Regularization: 0.035168, Discriminator: 0.021661; Generator: 0.010853,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 0.117738\n",
      "Reconstruction: 0.039427, Regularization: 0.045801, Discriminator: 0.021659; Generator: 0.010851,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "====> Epoch: 26 Average loss: 0.1156\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 0.114260\n",
      "Reconstruction: 0.038495, Regularization: 0.043256, Discriminator: 0.021659; Generator: 0.010850,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.145823\n",
      "Reconstruction: 0.051161, Regularization: 0.062153, Discriminator: 0.021661; Generator: 0.010848,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 0.113725\n",
      "Reconstruction: 0.039041, Regularization: 0.042175, Discriminator: 0.021661; Generator: 0.010847,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.105083\n",
      "Reconstruction: 0.036165, Regularization: 0.036413, Discriminator: 0.021660; Generator: 0.010846,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 0.115430\n",
      "Reconstruction: 0.039415, Regularization: 0.043509, Discriminator: 0.021661; Generator: 0.010845,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.130916\n",
      "Reconstruction: 0.044769, Regularization: 0.053643, Discriminator: 0.021661; Generator: 0.010843,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.092217\n",
      "Reconstruction: 0.031417, Regularization: 0.028296, Discriminator: 0.021661; Generator: 0.010843,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 0.108679\n",
      "Reconstruction: 0.037441, Regularization: 0.038735, Discriminator: 0.021661; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 27 Average loss: 0.1149\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.106007\n",
      "Reconstruction: 0.036118, Regularization: 0.037387, Discriminator: 0.021661; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.111241\n",
      "Reconstruction: 0.037982, Regularization: 0.040758, Discriminator: 0.021661; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 0.098599\n",
      "Reconstruction: 0.033676, Regularization: 0.032423, Discriminator: 0.021661; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.118604\n",
      "Reconstruction: 0.040693, Regularization: 0.045412, Discriminator: 0.021660; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.131902\n",
      "Reconstruction: 0.045555, Regularization: 0.053849, Discriminator: 0.021661; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.125534\n",
      "Reconstruction: 0.042984, Regularization: 0.050053, Discriminator: 0.021660; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.128465\n",
      "Reconstruction: 0.044754, Regularization: 0.051216, Discriminator: 0.021660; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.122575\n",
      "Reconstruction: 0.043036, Regularization: 0.047044, Discriminator: 0.021659; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 28 Average loss: 0.1140\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 0.102603\n",
      "Reconstruction: 0.035574, Regularization: 0.034532, Discriminator: 0.021662; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 0.127763\n",
      "Reconstruction: 0.043803, Regularization: 0.051464, Discriminator: 0.021660; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 0.109857\n",
      "Reconstruction: 0.038063, Regularization: 0.039296, Discriminator: 0.021664; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 0.126546\n",
      "Reconstruction: 0.044318, Regularization: 0.049738, Discriminator: 0.021656; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.124942\n",
      "Reconstruction: 0.043453, Regularization: 0.048992, Discriminator: 0.021663; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 0.101940\n",
      "Reconstruction: 0.034888, Regularization: 0.034567, Discriminator: 0.021652; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 0.118490\n",
      "Reconstruction: 0.041509, Regularization: 0.044484, Discriminator: 0.021665; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.131903\n",
      "Reconstruction: 0.045570, Regularization: 0.053842, Discriminator: 0.021659; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 29 Average loss: 0.1132\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.104263\n",
      "Reconstruction: 0.036078, Regularization: 0.035691, Discriminator: 0.021662; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.125663\n",
      "Reconstruction: 0.044267, Regularization: 0.048907, Discriminator: 0.021657; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.095614\n",
      "Reconstruction: 0.032794, Regularization: 0.030329, Discriminator: 0.021659; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.127738\n",
      "Reconstruction: 0.045882, Regularization: 0.049363, Discriminator: 0.021662; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.116310\n",
      "Reconstruction: 0.040456, Regularization: 0.043361, Discriminator: 0.021660; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.099814\n",
      "Reconstruction: 0.034557, Regularization: 0.032772, Discriminator: 0.021654; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.110733\n",
      "Reconstruction: 0.039322, Regularization: 0.038919, Discriminator: 0.021660; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 0.112211\n",
      "Reconstruction: 0.039609, Regularization: 0.040115, Discriminator: 0.021656; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 30 Average loss: 0.1125\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.095404\n",
      "Reconstruction: 0.033807, Regularization: 0.029101, Discriminator: 0.021666; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.097326\n",
      "Reconstruction: 0.033894, Regularization: 0.030943, Discriminator: 0.021659; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 0.112835\n",
      "Reconstruction: 0.039961, Regularization: 0.040380, Discriminator: 0.021663; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.096907\n",
      "Reconstruction: 0.033732, Regularization: 0.030689, Discriminator: 0.021657; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.110067\n",
      "Reconstruction: 0.039724, Regularization: 0.037848, Discriminator: 0.021665; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.112068\n",
      "Reconstruction: 0.039939, Regularization: 0.039648, Discriminator: 0.021653; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 0.125808\n",
      "Reconstruction: 0.044865, Regularization: 0.048451, Discriminator: 0.021663; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 0.108383\n",
      "Reconstruction: 0.038879, Regularization: 0.037015, Discriminator: 0.021659; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 31 Average loss: 0.1117\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.112961\n",
      "Reconstruction: 0.040200, Regularization: 0.040273, Discriminator: 0.021658; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.113222\n",
      "Reconstruction: 0.040132, Regularization: 0.040596, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.099135\n",
      "Reconstruction: 0.034904, Regularization: 0.031735, Discriminator: 0.021667; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.107404\n",
      "Reconstruction: 0.038127, Regularization: 0.036786, Discriminator: 0.021663; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.102529\n",
      "Reconstruction: 0.036291, Regularization: 0.033753, Discriminator: 0.021656; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 0.119645\n",
      "Reconstruction: 0.043212, Regularization: 0.043935, Discriminator: 0.021669; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.144137\n",
      "Reconstruction: 0.053744, Regularization: 0.057921, Discriminator: 0.021642; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.097171\n",
      "Reconstruction: 0.033972, Regularization: 0.030719, Discriminator: 0.021651; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 32 Average loss: 0.1110\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.132615\n",
      "Reconstruction: 0.047794, Regularization: 0.052322, Discriminator: 0.021669; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.125482\n",
      "Reconstruction: 0.046463, Regularization: 0.046539, Discriminator: 0.021651; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.114211\n",
      "Reconstruction: 0.040454, Regularization: 0.041258, Discriminator: 0.021671; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.115885\n",
      "Reconstruction: 0.042070, Regularization: 0.041323, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 0.106979\n",
      "Reconstruction: 0.038393, Regularization: 0.036103, Discriminator: 0.021654; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.094784\n",
      "Reconstruction: 0.033779, Regularization: 0.028534, Discriminator: 0.021640; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 0.124931\n",
      "Reconstruction: 0.046014, Regularization: 0.046429, Discriminator: 0.021660; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.113566\n",
      "Reconstruction: 0.040639, Regularization: 0.040438, Discriminator: 0.021661; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 33 Average loss: 0.1103\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.126497\n",
      "Reconstruction: 0.046504, Regularization: 0.047509, Discriminator: 0.021655; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.106517\n",
      "Reconstruction: 0.038172, Regularization: 0.035861, Discriminator: 0.021655; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.102372\n",
      "Reconstruction: 0.036775, Regularization: 0.033097, Discriminator: 0.021671; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.119682\n",
      "Reconstruction: 0.044340, Regularization: 0.042845, Discriminator: 0.021669; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.100984\n",
      "Reconstruction: 0.036420, Regularization: 0.032079, Discriminator: 0.021656; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.091619\n",
      "Reconstruction: 0.032293, Regularization: 0.026835, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.112541\n",
      "Reconstruction: 0.041879, Regularization: 0.038183, Discriminator: 0.021650; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 0.115376\n",
      "Reconstruction: 0.042025, Regularization: 0.040859, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 34 Average loss: 0.1097\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.095521\n",
      "Reconstruction: 0.034695, Regularization: 0.028339, Discriminator: 0.021658; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.104272\n",
      "Reconstruction: 0.037695, Regularization: 0.034075, Discriminator: 0.021674; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.104616\n",
      "Reconstruction: 0.037930, Regularization: 0.034196, Discriminator: 0.021660; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.102461\n",
      "Reconstruction: 0.037461, Regularization: 0.032534, Discriminator: 0.021635; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.088139\n",
      "Reconstruction: 0.032252, Regularization: 0.023403, Discriminator: 0.021656; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.100038\n",
      "Reconstruction: 0.035654, Regularization: 0.031874, Discriminator: 0.021682; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.125628\n",
      "Reconstruction: 0.047667, Regularization: 0.045469, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.109498\n",
      "Reconstruction: 0.040637, Regularization: 0.036371, Discriminator: 0.021659; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 35 Average loss: 0.1088\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 0.112017\n",
      "Reconstruction: 0.041671, Regularization: 0.037837, Discriminator: 0.021680; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.098011\n",
      "Reconstruction: 0.036066, Regularization: 0.029481, Discriminator: 0.021635; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.105389\n",
      "Reconstruction: 0.038747, Regularization: 0.034135, Discriminator: 0.021677; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.091673\n",
      "Reconstruction: 0.033249, Regularization: 0.025947, Discriminator: 0.021647; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.109585\n",
      "Reconstruction: 0.040334, Regularization: 0.036780, Discriminator: 0.021642; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.122135\n",
      "Reconstruction: 0.046241, Regularization: 0.043401, Discriminator: 0.021662; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 0.119240\n",
      "Reconstruction: 0.045141, Regularization: 0.041618, Discriminator: 0.021651; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.107951\n",
      "Reconstruction: 0.040278, Regularization: 0.035207, Discriminator: 0.021637; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 36 Average loss: 0.1081\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.103479\n",
      "Reconstruction: 0.038799, Regularization: 0.032192, Discriminator: 0.021661; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.107664\n",
      "Reconstruction: 0.040895, Regularization: 0.034287, Discriminator: 0.021652; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.100189\n",
      "Reconstruction: 0.037306, Regularization: 0.030399, Discriminator: 0.021653; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 0.102970\n",
      "Reconstruction: 0.038040, Regularization: 0.032433, Discriminator: 0.021670; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.111934\n",
      "Reconstruction: 0.043241, Regularization: 0.036197, Discriminator: 0.021666; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.108353\n",
      "Reconstruction: 0.041023, Regularization: 0.034862, Discriminator: 0.021639; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.117373\n",
      "Reconstruction: 0.045036, Regularization: 0.039843, Discriminator: 0.021667; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.106711\n",
      "Reconstruction: 0.040493, Regularization: 0.033727, Discriminator: 0.021663; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 37 Average loss: 0.1076\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.135074\n",
      "Reconstruction: 0.053496, Regularization: 0.049074, Discriminator: 0.021674; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.108351\n",
      "Reconstruction: 0.041483, Regularization: 0.034366, Discriminator: 0.021675; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.093604\n",
      "Reconstruction: 0.035755, Regularization: 0.025374, Discriminator: 0.021646; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 0.107197\n",
      "Reconstruction: 0.041043, Regularization: 0.033679, Discriminator: 0.021646; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.097976\n",
      "Reconstruction: 0.036769, Regularization: 0.028709, Discriminator: 0.021668; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.127458\n",
      "Reconstruction: 0.049896, Regularization: 0.045069, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.099196\n",
      "Reconstruction: 0.038031, Regularization: 0.028669, Discriminator: 0.021667; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.115410\n",
      "Reconstruction: 0.044837, Regularization: 0.038115, Discriminator: 0.021630; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 38 Average loss: 0.1070\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 0.091335\n",
      "Reconstruction: 0.033692, Regularization: 0.025161, Discriminator: 0.021653; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.103272\n",
      "Reconstruction: 0.038840, Regularization: 0.031946, Discriminator: 0.021659; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.107055\n",
      "Reconstruction: 0.040601, Regularization: 0.033966, Discriminator: 0.021659; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.118057\n",
      "Reconstruction: 0.045920, Regularization: 0.039640, Discriminator: 0.021661; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.104644\n",
      "Reconstruction: 0.040014, Regularization: 0.032141, Discriminator: 0.021662; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.108575\n",
      "Reconstruction: 0.042087, Regularization: 0.033995, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.114553\n",
      "Reconstruction: 0.044656, Regularization: 0.037426, Discriminator: 0.021640; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.104307\n",
      "Reconstruction: 0.039983, Regularization: 0.031840, Discriminator: 0.021656; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 39 Average loss: 0.1063\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.107281\n",
      "Reconstruction: 0.040923, Regularization: 0.033826, Discriminator: 0.021703; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.117178\n",
      "Reconstruction: 0.045787, Regularization: 0.038891, Discriminator: 0.021667; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.102110\n",
      "Reconstruction: 0.039060, Regularization: 0.030572, Discriminator: 0.021650; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.127130\n",
      "Reconstruction: 0.050636, Regularization: 0.043999, Discriminator: 0.021666; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.091727\n",
      "Reconstruction: 0.034133, Regularization: 0.025097, Discriminator: 0.021669; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 0.128603\n",
      "Reconstruction: 0.051126, Regularization: 0.044988, Discriminator: 0.021658; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.108836\n",
      "Reconstruction: 0.042930, Regularization: 0.033397, Discriminator: 0.021678; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.088445\n",
      "Reconstruction: 0.033887, Regularization: 0.022082, Discriminator: 0.021644; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 40 Average loss: 0.1057\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 0.102992\n",
      "Reconstruction: 0.039535, Regularization: 0.030953, Discriminator: 0.021674; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.121506\n",
      "Reconstruction: 0.048492, Regularization: 0.040514, Discriminator: 0.021666; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 0.114751\n",
      "Reconstruction: 0.045785, Regularization: 0.036502, Discriminator: 0.021634; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.100239\n",
      "Reconstruction: 0.038727, Regularization: 0.029023, Discriminator: 0.021659; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.139124\n",
      "Reconstruction: 0.057256, Regularization: 0.049353, Discriminator: 0.021683; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 0.103262\n",
      "Reconstruction: 0.040463, Regularization: 0.030299, Discriminator: 0.021669; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.106710\n",
      "Reconstruction: 0.042227, Regularization: 0.032000, Discriminator: 0.021651; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.107865\n",
      "Reconstruction: 0.042194, Regularization: 0.033208, Discriminator: 0.021632; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 41 Average loss: 0.1052\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.095129\n",
      "Reconstruction: 0.036957, Regularization: 0.025668, Discriminator: 0.021675; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.110798\n",
      "Reconstruction: 0.044194, Regularization: 0.034118, Discriminator: 0.021652; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.093793\n",
      "Reconstruction: 0.035966, Regularization: 0.025337, Discriminator: 0.021657; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 0.105797\n",
      "Reconstruction: 0.042497, Regularization: 0.030791, Discriminator: 0.021682; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.105994\n",
      "Reconstruction: 0.041971, Regularization: 0.031560, Discriminator: 0.021631; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.098269\n",
      "Reconstruction: 0.038664, Regularization: 0.027075, Discriminator: 0.021699; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.100958\n",
      "Reconstruction: 0.040366, Regularization: 0.028100, Discriminator: 0.021659; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.110188\n",
      "Reconstruction: 0.043902, Regularization: 0.033795, Discriminator: 0.021665; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 42 Average loss: 0.1046\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.114572\n",
      "Reconstruction: 0.046579, Regularization: 0.035525, Discriminator: 0.021639; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5020, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.102163\n",
      "Reconstruction: 0.040276, Regularization: 0.029456, Discriminator: 0.021601; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.097319\n",
      "Reconstruction: 0.038564, Regularization: 0.026265, Discriminator: 0.021663; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.100165\n",
      "Reconstruction: 0.039444, Regularization: 0.028234, Discriminator: 0.021655; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.100905\n",
      "Reconstruction: 0.040306, Regularization: 0.028104, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.084573\n",
      "Reconstruction: 0.031964, Regularization: 0.020131, Discriminator: 0.021648; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.098306\n",
      "Reconstruction: 0.038727, Regularization: 0.027093, Discriminator: 0.021654; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.094334\n",
      "Reconstruction: 0.036980, Regularization: 0.024887, Discriminator: 0.021638; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 43 Average loss: 0.1040\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.104289\n",
      "Reconstruction: 0.041874, Regularization: 0.029934, Discriminator: 0.021650; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.098909\n",
      "Reconstruction: 0.039584, Regularization: 0.026864, Discriminator: 0.021631; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.090892\n",
      "Reconstruction: 0.034963, Regularization: 0.023428, Discriminator: 0.021671; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.092589\n",
      "Reconstruction: 0.036753, Regularization: 0.023344, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.093252\n",
      "Reconstruction: 0.037036, Regularization: 0.023715, Discriminator: 0.021670; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.121834\n",
      "Reconstruction: 0.050488, Regularization: 0.038866, Discriminator: 0.021651; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.105295\n",
      "Reconstruction: 0.042468, Regularization: 0.030363, Discriminator: 0.021636; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.112982\n",
      "Reconstruction: 0.046657, Regularization: 0.033828, Discriminator: 0.021664; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 44 Average loss: 0.1033\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.105985\n",
      "Reconstruction: 0.042420, Regularization: 0.031050, Discriminator: 0.021687; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4979, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 0.102334\n",
      "Reconstruction: 0.041393, Regularization: 0.028383, Discriminator: 0.021726; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.106667\n",
      "Reconstruction: 0.043565, Regularization: 0.030629, Discriminator: 0.021640; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.108199\n",
      "Reconstruction: 0.044388, Regularization: 0.031308, Discriminator: 0.021670; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.103966\n",
      "Reconstruction: 0.042719, Regularization: 0.028733, Discriminator: 0.021683; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.100494\n",
      "Reconstruction: 0.040665, Regularization: 0.027353, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.117321\n",
      "Reconstruction: 0.048929, Regularization: 0.035882, Discriminator: 0.021677; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.115865\n",
      "Reconstruction: 0.048846, Regularization: 0.034549, Discriminator: 0.021637; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 45 Average loss: 0.1028\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.115304\n",
      "Reconstruction: 0.048335, Regularization: 0.034466, Discriminator: 0.021676; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.093299\n",
      "Reconstruction: 0.037006, Regularization: 0.023824, Discriminator: 0.021638; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.091457\n",
      "Reconstruction: 0.036394, Regularization: 0.022552, Discriminator: 0.021676; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.099644\n",
      "Reconstruction: 0.040762, Regularization: 0.026425, Discriminator: 0.021627; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.097092\n",
      "Reconstruction: 0.039290, Regularization: 0.025311, Discriminator: 0.021660; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.097241\n",
      "Reconstruction: 0.039724, Regularization: 0.024976, Discriminator: 0.021712; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.099850\n",
      "Reconstruction: 0.040948, Regularization: 0.026395, Discriminator: 0.021675; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.109324\n",
      "Reconstruction: 0.046336, Regularization: 0.030500, Discriminator: 0.021659; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 46 Average loss: 0.1022\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.107540\n",
      "Reconstruction: 0.044916, Regularization: 0.030130, Discriminator: 0.021661; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.102676\n",
      "Reconstruction: 0.042007, Regularization: 0.028177, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.096955\n",
      "Reconstruction: 0.039445, Regularization: 0.025046, Discriminator: 0.021635; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.101644\n",
      "Reconstruction: 0.041602, Regularization: 0.027509, Discriminator: 0.021702; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.089096\n",
      "Reconstruction: 0.036132, Regularization: 0.020475, Discriminator: 0.021661; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.110114\n",
      "Reconstruction: 0.046943, Regularization: 0.030628, Discriminator: 0.021717; Generator: 0.010827,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.106244\n",
      "Reconstruction: 0.044726, Regularization: 0.029034, Discriminator: 0.021654; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.095186\n",
      "Reconstruction: 0.038753, Regularization: 0.023943, Discriminator: 0.021658; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 47 Average loss: 0.1016\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.095106\n",
      "Reconstruction: 0.039273, Regularization: 0.023352, Discriminator: 0.021647; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.105642\n",
      "Reconstruction: 0.043671, Regularization: 0.029471, Discriminator: 0.021668; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.114111\n",
      "Reconstruction: 0.048784, Regularization: 0.032820, Discriminator: 0.021673; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.107778\n",
      "Reconstruction: 0.045689, Regularization: 0.029650, Discriminator: 0.021604; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.113191\n",
      "Reconstruction: 0.048048, Regularization: 0.032707, Discriminator: 0.021607; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.112268\n",
      "Reconstruction: 0.047765, Regularization: 0.032013, Discriminator: 0.021665; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.109336\n",
      "Reconstruction: 0.046568, Regularization: 0.030256, Discriminator: 0.021684; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.089304\n",
      "Reconstruction: 0.036013, Regularization: 0.020822, Discriminator: 0.021639; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 48 Average loss: 0.1010\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.095148\n",
      "Reconstruction: 0.038964, Regularization: 0.023743, Discriminator: 0.021613; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.102658\n",
      "Reconstruction: 0.043465, Regularization: 0.026717, Discriminator: 0.021644; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.092224\n",
      "Reconstruction: 0.037764, Regularization: 0.021968, Discriminator: 0.021659; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.090596\n",
      "Reconstruction: 0.036583, Regularization: 0.021500, Discriminator: 0.021680; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.114515\n",
      "Reconstruction: 0.049258, Regularization: 0.032756, Discriminator: 0.021666; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.084192\n",
      "Reconstruction: 0.033727, Regularization: 0.017974, Discriminator: 0.021663; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.093132\n",
      "Reconstruction: 0.038420, Regularization: 0.022219, Discriminator: 0.021662; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.102573\n",
      "Reconstruction: 0.043479, Regularization: 0.026628, Discriminator: 0.021639; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 49 Average loss: 0.1004\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 0.103431\n",
      "Reconstruction: 0.043996, Regularization: 0.026944, Discriminator: 0.021664; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 0.116348\n",
      "Reconstruction: 0.051532, Regularization: 0.032391, Discriminator: 0.021593; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 0.092199\n",
      "Reconstruction: 0.038438, Regularization: 0.021291, Discriminator: 0.021639; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 0.097722\n",
      "Reconstruction: 0.040362, Regularization: 0.024841, Discriminator: 0.021693; Generator: 0.010825,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 0.102348\n",
      "Reconstruction: 0.044042, Regularization: 0.025831, Discriminator: 0.021641; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 0.093824\n",
      "Reconstruction: 0.038799, Regularization: 0.022532, Discriminator: 0.021661; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 0.101704\n",
      "Reconstruction: 0.043102, Regularization: 0.026124, Discriminator: 0.021648; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 0.087766\n",
      "Reconstruction: 0.035582, Regularization: 0.019717, Discriminator: 0.021636; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 50 Average loss: 0.1001\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 0.116904\n",
      "Reconstruction: 0.051909, Regularization: 0.032504, Discriminator: 0.021660; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 0.106382\n",
      "Reconstruction: 0.046859, Regularization: 0.027027, Discriminator: 0.021667; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 0.101405\n",
      "Reconstruction: 0.043611, Regularization: 0.025343, Discriminator: 0.021622; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 0.103908\n",
      "Reconstruction: 0.044375, Regularization: 0.027064, Discriminator: 0.021636; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 0.077728\n",
      "Reconstruction: 0.031049, Regularization: 0.014207, Discriminator: 0.021639; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 0.099153\n",
      "Reconstruction: 0.042622, Regularization: 0.024011, Discriminator: 0.021687; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 0.088122\n",
      "Reconstruction: 0.037004, Regularization: 0.018607, Discriminator: 0.021673; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 0.114926\n",
      "Reconstruction: 0.051629, Regularization: 0.030848, Discriminator: 0.021622; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 51 Average loss: 0.0996\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 0.088749\n",
      "Reconstruction: 0.037287, Regularization: 0.018934, Discriminator: 0.021696; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 0.095384\n",
      "Reconstruction: 0.040773, Regularization: 0.022147, Discriminator: 0.021634; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 0.093370\n",
      "Reconstruction: 0.040144, Regularization: 0.020739, Discriminator: 0.021656; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 0.108417\n",
      "Reconstruction: 0.047733, Regularization: 0.028162, Discriminator: 0.021691; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 0.082897\n",
      "Reconstruction: 0.033995, Regularization: 0.016413, Discriminator: 0.021658; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 0.096119\n",
      "Reconstruction: 0.041322, Regularization: 0.022305, Discriminator: 0.021665; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 0.103181\n",
      "Reconstruction: 0.045064, Regularization: 0.025654, Discriminator: 0.021636; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 0.099134\n",
      "Reconstruction: 0.043398, Regularization: 0.023269, Discriminator: 0.021634; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 52 Average loss: 0.0992\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 0.089873\n",
      "Reconstruction: 0.037570, Regularization: 0.019806, Discriminator: 0.021662; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 0.107242\n",
      "Reconstruction: 0.047898, Regularization: 0.026835, Discriminator: 0.021673; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 0.094751\n",
      "Reconstruction: 0.040995, Regularization: 0.021237, Discriminator: 0.021690; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 0.103995\n",
      "Reconstruction: 0.046355, Regularization: 0.025197, Discriminator: 0.021614; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 0.082609\n",
      "Reconstruction: 0.033964, Regularization: 0.016170, Discriminator: 0.021640; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 0.091744\n",
      "Reconstruction: 0.039466, Regularization: 0.019786, Discriminator: 0.021656; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 0.106829\n",
      "Reconstruction: 0.048183, Regularization: 0.026127, Discriminator: 0.021694; Generator: 0.010824,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 0.103914\n",
      "Reconstruction: 0.046194, Regularization: 0.025220, Discriminator: 0.021666; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 53 Average loss: 0.0986\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 0.083434\n",
      "Reconstruction: 0.035001, Regularization: 0.015979, Discriminator: 0.021619; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 0.097767\n",
      "Reconstruction: 0.042997, Regularization: 0.022301, Discriminator: 0.021635; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 0.092373\n",
      "Reconstruction: 0.040340, Regularization: 0.019541, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 0.104113\n",
      "Reconstruction: 0.046602, Regularization: 0.024974, Discriminator: 0.021708; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 0.093157\n",
      "Reconstruction: 0.040362, Regularization: 0.020316, Discriminator: 0.021646; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 0.099358\n",
      "Reconstruction: 0.043661, Regularization: 0.023204, Discriminator: 0.021658; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 0.093792\n",
      "Reconstruction: 0.040675, Regularization: 0.020678, Discriminator: 0.021608; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 0.101080\n",
      "Reconstruction: 0.045312, Regularization: 0.023242, Discriminator: 0.021695; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 54 Average loss: 0.0982\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 0.098290\n",
      "Reconstruction: 0.043581, Regularization: 0.022211, Discriminator: 0.021673; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 0.105685\n",
      "Reconstruction: 0.047519, Regularization: 0.025637, Discriminator: 0.021696; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 0.086403\n",
      "Reconstruction: 0.036740, Regularization: 0.017154, Discriminator: 0.021675; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 0.094635\n",
      "Reconstruction: 0.041476, Regularization: 0.020612, Discriminator: 0.021713; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 0.110098\n",
      "Reconstruction: 0.050843, Regularization: 0.026739, Discriminator: 0.021684; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 0.110355\n",
      "Reconstruction: 0.051401, Regularization: 0.026467, Discriminator: 0.021653; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 0.084538\n",
      "Reconstruction: 0.035908, Regularization: 0.016157, Discriminator: 0.021640; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 0.099253\n",
      "Reconstruction: 0.044723, Regularization: 0.022085, Discriminator: 0.021613; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 55 Average loss: 0.0977\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 0.085872\n",
      "Reconstruction: 0.036531, Regularization: 0.016898, Discriminator: 0.021608; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 0.091312\n",
      "Reconstruction: 0.039956, Regularization: 0.018858, Discriminator: 0.021670; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 0.089446\n",
      "Reconstruction: 0.039070, Regularization: 0.017909, Discriminator: 0.021631; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 0.101487\n",
      "Reconstruction: 0.045706, Regularization: 0.023275, Discriminator: 0.021668; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 0.094338\n",
      "Reconstruction: 0.042203, Regularization: 0.019653, Discriminator: 0.021654; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 0.086399\n",
      "Reconstruction: 0.037157, Regularization: 0.016735, Discriminator: 0.021676; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 0.091599\n",
      "Reconstruction: 0.040525, Regularization: 0.018630, Discriminator: 0.021606; Generator: 0.010838,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 0.091651\n",
      "Reconstruction: 0.040853, Regularization: 0.018281, Discriminator: 0.021684; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 56 Average loss: 0.0972\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 0.116806\n",
      "Reconstruction: 0.055306, Regularization: 0.029025, Discriminator: 0.021645; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 0.084151\n",
      "Reconstruction: 0.036017, Regularization: 0.015607, Discriminator: 0.021702; Generator: 0.010825,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 0.097163\n",
      "Reconstruction: 0.043807, Regularization: 0.020875, Discriminator: 0.021648; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 0.085667\n",
      "Reconstruction: 0.036773, Regularization: 0.016434, Discriminator: 0.021623; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 0.089289\n",
      "Reconstruction: 0.038826, Regularization: 0.017994, Discriminator: 0.021640; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 0.100767\n",
      "Reconstruction: 0.046717, Regularization: 0.021617, Discriminator: 0.021601; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 0.085928\n",
      "Reconstruction: 0.037652, Regularization: 0.015751, Discriminator: 0.021694; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4979, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 0.106372\n",
      "Reconstruction: 0.049165, Regularization: 0.024648, Discriminator: 0.021731; Generator: 0.010828,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "====> Epoch: 57 Average loss: 0.0967\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 0.105689\n",
      "Reconstruction: 0.049196, Regularization: 0.024003, Discriminator: 0.021659; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 0.088049\n",
      "Reconstruction: 0.038395, Regularization: 0.017106, Discriminator: 0.021717; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 0.096813\n",
      "Reconstruction: 0.043796, Regularization: 0.020559, Discriminator: 0.021625; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 0.089256\n",
      "Reconstruction: 0.039589, Regularization: 0.017198, Discriminator: 0.021640; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 0.110218\n",
      "Reconstruction: 0.052415, Regularization: 0.025305, Discriminator: 0.021667; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 0.101517\n",
      "Reconstruction: 0.047010, Regularization: 0.022068, Discriminator: 0.021607; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 0.088760\n",
      "Reconstruction: 0.039687, Regularization: 0.016585, Discriminator: 0.021658; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 0.095373\n",
      "Reconstruction: 0.043128, Regularization: 0.019740, Discriminator: 0.021673; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 58 Average loss: 0.0962\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 0.092427\n",
      "Reconstruction: 0.040959, Regularization: 0.018978, Discriminator: 0.021660; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5033, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 0.108717\n",
      "Reconstruction: 0.051420, Regularization: 0.024906, Discriminator: 0.021560; Generator: 0.010831,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 0.107039\n",
      "Reconstruction: 0.050555, Regularization: 0.024015, Discriminator: 0.021638; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 0.101768\n",
      "Reconstruction: 0.046877, Regularization: 0.022398, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 0.100698\n",
      "Reconstruction: 0.047066, Regularization: 0.021084, Discriminator: 0.021716; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 0.090042\n",
      "Reconstruction: 0.040383, Regularization: 0.017174, Discriminator: 0.021653; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 0.082749\n",
      "Reconstruction: 0.035966, Regularization: 0.014314, Discriminator: 0.021631; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 0.082081\n",
      "Reconstruction: 0.035791, Regularization: 0.013817, Discriminator: 0.021636; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 59 Average loss: 0.0958\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 0.090142\n",
      "Reconstruction: 0.040645, Regularization: 0.017013, Discriminator: 0.021649; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 0.089695\n",
      "Reconstruction: 0.040236, Regularization: 0.016934, Discriminator: 0.021692; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 0.092301\n",
      "Reconstruction: 0.042320, Regularization: 0.017475, Discriminator: 0.021678; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 0.088531\n",
      "Reconstruction: 0.039633, Regularization: 0.016415, Discriminator: 0.021648; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 0.086382\n",
      "Reconstruction: 0.038793, Regularization: 0.015058, Discriminator: 0.021692; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 0.083060\n",
      "Reconstruction: 0.036886, Regularization: 0.013668, Discriminator: 0.021671; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 0.085244\n",
      "Reconstruction: 0.037870, Regularization: 0.014886, Discriminator: 0.021656; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 0.095535\n",
      "Reconstruction: 0.044664, Regularization: 0.018392, Discriminator: 0.021644; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 60 Average loss: 0.0954\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 0.097582\n",
      "Reconstruction: 0.045534, Regularization: 0.019605, Discriminator: 0.021612; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 0.085282\n",
      "Reconstruction: 0.038285, Regularization: 0.014483, Discriminator: 0.021679; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 0.104621\n",
      "Reconstruction: 0.050248, Regularization: 0.021884, Discriminator: 0.021658; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 0.100854\n",
      "Reconstruction: 0.048551, Regularization: 0.019823, Discriminator: 0.021644; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4974, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 0.102794\n",
      "Reconstruction: 0.049551, Regularization: 0.020666, Discriminator: 0.021745; Generator: 0.010832,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "tensor(0.5026, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 0.101281\n",
      "Reconstruction: 0.048494, Regularization: 0.020376, Discriminator: 0.021583; Generator: 0.010829,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 0.103795\n",
      "Reconstruction: 0.049396, Regularization: 0.021949, Discriminator: 0.021619; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 0.091155\n",
      "Reconstruction: 0.041665, Regularization: 0.016974, Discriminator: 0.021685; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 61 Average loss: 0.0952\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 0.107050\n",
      "Reconstruction: 0.051205, Regularization: 0.023411, Discriminator: 0.021601; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 0.110530\n",
      "Reconstruction: 0.054021, Regularization: 0.023984, Discriminator: 0.021700; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 0.086641\n",
      "Reconstruction: 0.039097, Regularization: 0.015033, Discriminator: 0.021677; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 0.080898\n",
      "Reconstruction: 0.035421, Regularization: 0.013016, Discriminator: 0.021626; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 0.097966\n",
      "Reconstruction: 0.046393, Regularization: 0.019110, Discriminator: 0.021630; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 0.081927\n",
      "Reconstruction: 0.036433, Regularization: 0.013025, Discriminator: 0.021643; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 0.114066\n",
      "Reconstruction: 0.056713, Regularization: 0.024806, Discriminator: 0.021717; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 0.092232\n",
      "Reconstruction: 0.043095, Regularization: 0.016638, Discriminator: 0.021664; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 62 Average loss: 0.0945\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 0.100474\n",
      "Reconstruction: 0.048075, Regularization: 0.019892, Discriminator: 0.021666; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 0.080772\n",
      "Reconstruction: 0.035816, Regularization: 0.012454, Discriminator: 0.021668; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 0.095162\n",
      "Reconstruction: 0.044891, Regularization: 0.017744, Discriminator: 0.021697; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 0.098643\n",
      "Reconstruction: 0.047062, Regularization: 0.019130, Discriminator: 0.021618; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 0.095769\n",
      "Reconstruction: 0.045840, Regularization: 0.017468, Discriminator: 0.021631; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 0.114212\n",
      "Reconstruction: 0.057098, Regularization: 0.024612, Discriminator: 0.021665; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 0.089510\n",
      "Reconstruction: 0.041774, Regularization: 0.015230, Discriminator: 0.021677; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 0.105069\n",
      "Reconstruction: 0.051764, Regularization: 0.020774, Discriminator: 0.021692; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 63 Average loss: 0.0941\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 0.083830\n",
      "Reconstruction: 0.038036, Regularization: 0.013327, Discriminator: 0.021638; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 0.095345\n",
      "Reconstruction: 0.045683, Regularization: 0.017216, Discriminator: 0.021614; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 0.096644\n",
      "Reconstruction: 0.046336, Regularization: 0.017881, Discriminator: 0.021597; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 0.091928\n",
      "Reconstruction: 0.043319, Regularization: 0.016122, Discriminator: 0.021649; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 0.103437\n",
      "Reconstruction: 0.050736, Regularization: 0.020199, Discriminator: 0.021672; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 0.092305\n",
      "Reconstruction: 0.043768, Regularization: 0.016070, Discriminator: 0.021634; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 0.100541\n",
      "Reconstruction: 0.049024, Regularization: 0.018984, Discriminator: 0.021703; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 0.103038\n",
      "Reconstruction: 0.051334, Regularization: 0.019209, Discriminator: 0.021664; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 64 Average loss: 0.0938\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 0.086686\n",
      "Reconstruction: 0.040351, Regularization: 0.013860, Discriminator: 0.021643; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 0.107939\n",
      "Reconstruction: 0.054247, Regularization: 0.021217, Discriminator: 0.021646; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 0.084170\n",
      "Reconstruction: 0.037919, Regularization: 0.013756, Discriminator: 0.021659; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 0.090406\n",
      "Reconstruction: 0.042933, Regularization: 0.014989, Discriminator: 0.021646; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 0.110853\n",
      "Reconstruction: 0.055957, Regularization: 0.022411, Discriminator: 0.021650; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 0.083881\n",
      "Reconstruction: 0.038282, Regularization: 0.013069, Discriminator: 0.021694; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 0.099749\n",
      "Reconstruction: 0.049461, Regularization: 0.017835, Discriminator: 0.021624; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 0.099668\n",
      "Reconstruction: 0.049216, Regularization: 0.017923, Discriminator: 0.021696; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 65 Average loss: 0.0933\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 0.091144\n",
      "Reconstruction: 0.043343, Regularization: 0.015261, Discriminator: 0.021709; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 0.092084\n",
      "Reconstruction: 0.044385, Regularization: 0.015228, Discriminator: 0.021642; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 0.098450\n",
      "Reconstruction: 0.048983, Regularization: 0.016925, Discriminator: 0.021704; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 0.088291\n",
      "Reconstruction: 0.041359, Regularization: 0.014432, Discriminator: 0.021669; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 0.090166\n",
      "Reconstruction: 0.042738, Regularization: 0.014898, Discriminator: 0.021695; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5029, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 0.089916\n",
      "Reconstruction: 0.043407, Regularization: 0.014106, Discriminator: 0.021571; Generator: 0.010831,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 0.094929\n",
      "Reconstruction: 0.046105, Regularization: 0.016318, Discriminator: 0.021671; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 0.076940\n",
      "Reconstruction: 0.034211, Regularization: 0.010294, Discriminator: 0.021599; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 66 Average loss: 0.0930\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 0.097247\n",
      "Reconstruction: 0.047650, Regularization: 0.017071, Discriminator: 0.021693; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 0.095318\n",
      "Reconstruction: 0.046535, Regularization: 0.016318, Discriminator: 0.021635; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 0.088792\n",
      "Reconstruction: 0.042586, Regularization: 0.013658, Discriminator: 0.021717; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 0.078499\n",
      "Reconstruction: 0.035606, Regularization: 0.010455, Discriminator: 0.021606; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 0.093854\n",
      "Reconstruction: 0.046208, Regularization: 0.015195, Discriminator: 0.021613; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 0.095896\n",
      "Reconstruction: 0.047363, Regularization: 0.016021, Discriminator: 0.021683; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 0.090762\n",
      "Reconstruction: 0.043497, Regularization: 0.014811, Discriminator: 0.021620; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 0.098071\n",
      "Reconstruction: 0.049015, Regularization: 0.016617, Discriminator: 0.021606; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 67 Average loss: 0.0927\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 0.086060\n",
      "Reconstruction: 0.040909, Regularization: 0.012674, Discriminator: 0.021645; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 0.096346\n",
      "Reconstruction: 0.048021, Regularization: 0.015873, Discriminator: 0.021622; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 0.106644\n",
      "Reconstruction: 0.054872, Regularization: 0.019262, Discriminator: 0.021681; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 0.098173\n",
      "Reconstruction: 0.049531, Regularization: 0.016139, Discriminator: 0.021677; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5020, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 0.104497\n",
      "Reconstruction: 0.053935, Regularization: 0.018131, Discriminator: 0.021600; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 0.086876\n",
      "Reconstruction: 0.041641, Regularization: 0.012712, Discriminator: 0.021689; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 0.079142\n",
      "Reconstruction: 0.036427, Regularization: 0.010278, Discriminator: 0.021605; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 0.087493\n",
      "Reconstruction: 0.041784, Regularization: 0.013195, Discriminator: 0.021677; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 68 Average loss: 0.0925\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 0.102248\n",
      "Reconstruction: 0.052074, Regularization: 0.017672, Discriminator: 0.021670; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 0.103513\n",
      "Reconstruction: 0.053042, Regularization: 0.017992, Discriminator: 0.021647; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 0.088224\n",
      "Reconstruction: 0.042594, Regularization: 0.013124, Discriminator: 0.021672; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5029, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 0.085274\n",
      "Reconstruction: 0.040560, Regularization: 0.012311, Discriminator: 0.021571; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 0.093307\n",
      "Reconstruction: 0.046141, Regularization: 0.014662, Discriminator: 0.021673; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 0.090487\n",
      "Reconstruction: 0.044431, Regularization: 0.013525, Discriminator: 0.021694; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 0.089609\n",
      "Reconstruction: 0.043826, Regularization: 0.013256, Discriminator: 0.021692; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 0.093458\n",
      "Reconstruction: 0.046524, Regularization: 0.014409, Discriminator: 0.021687; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 69 Average loss: 0.0920\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 0.093505\n",
      "Reconstruction: 0.046636, Regularization: 0.014371, Discriminator: 0.021663; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 0.087601\n",
      "Reconstruction: 0.042493, Regularization: 0.012619, Discriminator: 0.021655; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 0.103662\n",
      "Reconstruction: 0.053766, Regularization: 0.017417, Discriminator: 0.021650; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 0.094334\n",
      "Reconstruction: 0.047443, Regularization: 0.014384, Discriminator: 0.021679; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 0.090050\n",
      "Reconstruction: 0.044563, Regularization: 0.012957, Discriminator: 0.021695; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 0.086469\n",
      "Reconstruction: 0.041873, Regularization: 0.012085, Discriminator: 0.021675; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 0.084292\n",
      "Reconstruction: 0.040557, Regularization: 0.011290, Discriminator: 0.021612; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 0.087785\n",
      "Reconstruction: 0.043029, Regularization: 0.012319, Discriminator: 0.021610; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 70 Average loss: 0.0917\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 0.092662\n",
      "Reconstruction: 0.046308, Regularization: 0.013910, Discriminator: 0.021616; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 0.087727\n",
      "Reconstruction: 0.042926, Regularization: 0.012275, Discriminator: 0.021695; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 0.100729\n",
      "Reconstruction: 0.051758, Regularization: 0.016589, Discriminator: 0.021547; Generator: 0.010835,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "tensor(0.5020, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 0.084940\n",
      "Reconstruction: 0.041179, Regularization: 0.011329, Discriminator: 0.021597; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 0.088786\n",
      "Reconstruction: 0.044319, Regularization: 0.011985, Discriminator: 0.021650; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 0.095008\n",
      "Reconstruction: 0.048442, Regularization: 0.014059, Discriminator: 0.021672; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 0.088040\n",
      "Reconstruction: 0.043527, Regularization: 0.012026, Discriminator: 0.021649; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 0.089668\n",
      "Reconstruction: 0.045038, Regularization: 0.012170, Discriminator: 0.021630; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 71 Average loss: 0.0914\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 0.110600\n",
      "Reconstruction: 0.059951, Regularization: 0.018147, Discriminator: 0.021670; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 0.087253\n",
      "Reconstruction: 0.043125, Regularization: 0.011625, Discriminator: 0.021671; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 0.079722\n",
      "Reconstruction: 0.037533, Regularization: 0.009667, Discriminator: 0.021692; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 0.086538\n",
      "Reconstruction: 0.042793, Regularization: 0.011308, Discriminator: 0.021602; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 0.084227\n",
      "Reconstruction: 0.040956, Regularization: 0.010730, Discriminator: 0.021710; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5027, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 0.098936\n",
      "Reconstruction: 0.051598, Regularization: 0.014927, Discriminator: 0.021576; Generator: 0.010835,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 0.095598\n",
      "Reconstruction: 0.049192, Regularization: 0.013968, Discriminator: 0.021610; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 0.087982\n",
      "Reconstruction: 0.043815, Regularization: 0.011663, Discriminator: 0.021672; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 72 Average loss: 0.0910\n",
      "tensor(0.5033, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 0.082627\n",
      "Reconstruction: 0.040055, Regularization: 0.010183, Discriminator: 0.021558; Generator: 0.010831,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 0.103277\n",
      "Reconstruction: 0.055389, Regularization: 0.015403, Discriminator: 0.021654; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 0.087259\n",
      "Reconstruction: 0.043190, Regularization: 0.011619, Discriminator: 0.021615; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 0.097805\n",
      "Reconstruction: 0.051379, Regularization: 0.013985, Discriminator: 0.021603; Generator: 0.010838,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 0.092273\n",
      "Reconstruction: 0.046877, Regularization: 0.012859, Discriminator: 0.021706; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 0.087810\n",
      "Reconstruction: 0.043712, Regularization: 0.011611, Discriminator: 0.021656; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 0.090348\n",
      "Reconstruction: 0.045395, Regularization: 0.012413, Discriminator: 0.021705; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 0.090471\n",
      "Reconstruction: 0.046053, Regularization: 0.011866, Discriminator: 0.021720; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 73 Average loss: 0.0907\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 0.094855\n",
      "Reconstruction: 0.049297, Regularization: 0.013040, Discriminator: 0.021685; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 0.083101\n",
      "Reconstruction: 0.040653, Regularization: 0.009970, Discriminator: 0.021647; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 0.100336\n",
      "Reconstruction: 0.052734, Regularization: 0.015149, Discriminator: 0.021620; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 0.093064\n",
      "Reconstruction: 0.048458, Regularization: 0.012146, Discriminator: 0.021624; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 0.076901\n",
      "Reconstruction: 0.036083, Regularization: 0.008346, Discriminator: 0.021639; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 0.097601\n",
      "Reconstruction: 0.051283, Regularization: 0.013880, Discriminator: 0.021605; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 0.086203\n",
      "Reconstruction: 0.043190, Regularization: 0.010485, Discriminator: 0.021697; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 0.091031\n",
      "Reconstruction: 0.046549, Regularization: 0.011975, Discriminator: 0.021672; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 74 Average loss: 0.0906\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 0.087247\n",
      "Reconstruction: 0.044029, Regularization: 0.010723, Discriminator: 0.021659; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 0.113009\n",
      "Reconstruction: 0.062854, Regularization: 0.017641, Discriminator: 0.021679; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5026, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 0.105478\n",
      "Reconstruction: 0.057387, Regularization: 0.015678, Discriminator: 0.021582; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 0.085085\n",
      "Reconstruction: 0.042622, Regularization: 0.009950, Discriminator: 0.021680; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 0.101021\n",
      "Reconstruction: 0.054269, Regularization: 0.014199, Discriminator: 0.021718; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 0.086092\n",
      "Reconstruction: 0.043280, Regularization: 0.010269, Discriminator: 0.021712; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 0.090340\n",
      "Reconstruction: 0.046476, Regularization: 0.011448, Discriminator: 0.021587; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 0.083196\n",
      "Reconstruction: 0.041192, Regularization: 0.009448, Discriminator: 0.021725; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "====> Epoch: 75 Average loss: 0.0902\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 0.086911\n",
      "Reconstruction: 0.043986, Regularization: 0.010405, Discriminator: 0.021694; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 0.080138\n",
      "Reconstruction: 0.039164, Regularization: 0.008476, Discriminator: 0.021661; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 0.099688\n",
      "Reconstruction: 0.053453, Regularization: 0.013778, Discriminator: 0.021620; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 0.082208\n",
      "Reconstruction: 0.040549, Regularization: 0.009128, Discriminator: 0.021697; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 0.094860\n",
      "Reconstruction: 0.050507, Regularization: 0.011890, Discriminator: 0.021628; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 0.100437\n",
      "Reconstruction: 0.054125, Regularization: 0.013835, Discriminator: 0.021638; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 0.104468\n",
      "Reconstruction: 0.057498, Regularization: 0.014434, Discriminator: 0.021703; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 0.081347\n",
      "Reconstruction: 0.040177, Regularization: 0.008750, Discriminator: 0.021581; Generator: 0.010839,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 76 Average loss: 0.0899\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 0.105424\n",
      "Reconstruction: 0.058469, Regularization: 0.014497, Discriminator: 0.021624; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 0.093905\n",
      "Reconstruction: 0.049487, Regularization: 0.011899, Discriminator: 0.021685; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 0.084599\n",
      "Reconstruction: 0.042814, Regularization: 0.009300, Discriminator: 0.021652; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 0.091212\n",
      "Reconstruction: 0.047608, Regularization: 0.011135, Discriminator: 0.021641; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5030, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 0.099307\n",
      "Reconstruction: 0.054157, Regularization: 0.012748, Discriminator: 0.021570; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 0.087256\n",
      "Reconstruction: 0.044727, Regularization: 0.010012, Discriminator: 0.021686; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4979, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 0.083668\n",
      "Reconstruction: 0.042021, Regularization: 0.009087, Discriminator: 0.021731; Generator: 0.010829,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 0.089860\n",
      "Reconstruction: 0.046651, Regularization: 0.010759, Discriminator: 0.021611; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 77 Average loss: 0.0898\n",
      "tensor(0.4970, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 0.093617\n",
      "Reconstruction: 0.049539, Regularization: 0.011489, Discriminator: 0.021756; Generator: 0.010832,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 0.087772\n",
      "Reconstruction: 0.045496, Regularization: 0.009822, Discriminator: 0.021618; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 0.086020\n",
      "Reconstruction: 0.044245, Regularization: 0.009313, Discriminator: 0.021622; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 0.106575\n",
      "Reconstruction: 0.059778, Regularization: 0.014350, Discriminator: 0.021616; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 0.088628\n",
      "Reconstruction: 0.046026, Regularization: 0.010118, Discriminator: 0.021650; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 0.083091\n",
      "Reconstruction: 0.042020, Regularization: 0.008621, Discriminator: 0.021628; Generator: 0.010821,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 0.099510\n",
      "Reconstruction: 0.054399, Regularization: 0.012558, Discriminator: 0.021719; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 0.097596\n",
      "Reconstruction: 0.053247, Regularization: 0.011853, Discriminator: 0.021661; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 78 Average loss: 0.0895\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 0.100224\n",
      "Reconstruction: 0.055018, Regularization: 0.012686, Discriminator: 0.021687; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 0.092248\n",
      "Reconstruction: 0.049172, Regularization: 0.010657, Discriminator: 0.021584; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 0.081162\n",
      "Reconstruction: 0.040440, Regularization: 0.008224, Discriminator: 0.021660; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 0.093919\n",
      "Reconstruction: 0.050487, Regularization: 0.010922, Discriminator: 0.021677; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 0.103595\n",
      "Reconstruction: 0.057527, Regularization: 0.013564, Discriminator: 0.021667; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 0.092981\n",
      "Reconstruction: 0.049828, Regularization: 0.010640, Discriminator: 0.021678; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 0.084453\n",
      "Reconstruction: 0.043296, Regularization: 0.008693, Discriminator: 0.021631; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 0.083482\n",
      "Reconstruction: 0.042446, Regularization: 0.008522, Discriminator: 0.021679; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 79 Average loss: 0.0890\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 0.079740\n",
      "Reconstruction: 0.039761, Regularization: 0.007520, Discriminator: 0.021625; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 0.086099\n",
      "Reconstruction: 0.044612, Regularization: 0.009028, Discriminator: 0.021629; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 0.089166\n",
      "Reconstruction: 0.047249, Regularization: 0.009391, Discriminator: 0.021693; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 0.085765\n",
      "Reconstruction: 0.044554, Regularization: 0.008725, Discriminator: 0.021649; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5030, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 0.106403\n",
      "Reconstruction: 0.060480, Regularization: 0.013520, Discriminator: 0.021575; Generator: 0.010828,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 0.090212\n",
      "Reconstruction: 0.048229, Regularization: 0.009546, Discriminator: 0.021604; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 0.079672\n",
      "Reconstruction: 0.039795, Regularization: 0.007433, Discriminator: 0.021614; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 0.080958\n",
      "Reconstruction: 0.040632, Regularization: 0.007802, Discriminator: 0.021685; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 80 Average loss: 0.0888\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 0.084474\n",
      "Reconstruction: 0.043420, Regularization: 0.008516, Discriminator: 0.021700; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 0.095734\n",
      "Reconstruction: 0.052442, Regularization: 0.010774, Discriminator: 0.021686; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 0.087475\n",
      "Reconstruction: 0.046120, Regularization: 0.008857, Discriminator: 0.021665; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 0.085187\n",
      "Reconstruction: 0.044333, Regularization: 0.008392, Discriminator: 0.021630; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 0.083967\n",
      "Reconstruction: 0.043431, Regularization: 0.008048, Discriminator: 0.021652; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 0.086024\n",
      "Reconstruction: 0.044988, Regularization: 0.008516, Discriminator: 0.021681; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 0.075953\n",
      "Reconstruction: 0.037138, Regularization: 0.006380, Discriminator: 0.021605; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 0.081510\n",
      "Reconstruction: 0.041905, Regularization: 0.007116, Discriminator: 0.021652; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 81 Average loss: 0.0887\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 0.087782\n",
      "Reconstruction: 0.046267, Regularization: 0.009081, Discriminator: 0.021604; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 0.090552\n",
      "Reconstruction: 0.048781, Regularization: 0.009350, Discriminator: 0.021591; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 0.078341\n",
      "Reconstruction: 0.039218, Regularization: 0.006644, Discriminator: 0.021643; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 0.068548\n",
      "Reconstruction: 0.031344, Regularization: 0.004729, Discriminator: 0.021640; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 0.094784\n",
      "Reconstruction: 0.052082, Regularization: 0.010210, Discriminator: 0.021660; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 0.088845\n",
      "Reconstruction: 0.047692, Regularization: 0.008683, Discriminator: 0.021639; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 0.080911\n",
      "Reconstruction: 0.041240, Regularization: 0.007194, Discriminator: 0.021645; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 0.091006\n",
      "Reconstruction: 0.049461, Regularization: 0.009084, Discriminator: 0.021624; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 82 Average loss: 0.0883\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 0.091644\n",
      "Reconstruction: 0.049838, Regularization: 0.009295, Discriminator: 0.021676; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 0.085697\n",
      "Reconstruction: 0.045017, Regularization: 0.008227, Discriminator: 0.021619; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 0.086760\n",
      "Reconstruction: 0.046050, Regularization: 0.008283, Discriminator: 0.021593; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 0.100283\n",
      "Reconstruction: 0.057039, Regularization: 0.010715, Discriminator: 0.021697; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 0.084543\n",
      "Reconstruction: 0.044495, Regularization: 0.007521, Discriminator: 0.021692; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 0.079340\n",
      "Reconstruction: 0.040296, Regularization: 0.006534, Discriminator: 0.021677; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 0.092922\n",
      "Reconstruction: 0.051340, Regularization: 0.009094, Discriminator: 0.021650; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 0.092976\n",
      "Reconstruction: 0.051143, Regularization: 0.009335, Discriminator: 0.021666; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 83 Average loss: 0.0881\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 0.092824\n",
      "Reconstruction: 0.051345, Regularization: 0.008930, Discriminator: 0.021715; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 0.084449\n",
      "Reconstruction: 0.044549, Regularization: 0.007415, Discriminator: 0.021654; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5034, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 0.088344\n",
      "Reconstruction: 0.047828, Regularization: 0.008127, Discriminator: 0.021553; Generator: 0.010836,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5029, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 0.099045\n",
      "Reconstruction: 0.056684, Regularization: 0.009957, Discriminator: 0.021565; Generator: 0.010839,\n",
      "D(x): 0.503, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 0.088194\n",
      "Reconstruction: 0.047632, Regularization: 0.008031, Discriminator: 0.021699; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 0.080756\n",
      "Reconstruction: 0.041587, Regularization: 0.006652, Discriminator: 0.021680; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 0.087236\n",
      "Reconstruction: 0.047015, Regularization: 0.007758, Discriminator: 0.021633; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5020, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 0.107820\n",
      "Reconstruction: 0.063827, Regularization: 0.011560, Discriminator: 0.021600; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 84 Average loss: 0.0879\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 0.089528\n",
      "Reconstruction: 0.048795, Regularization: 0.008223, Discriminator: 0.021683; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 0.100487\n",
      "Reconstruction: 0.057689, Regularization: 0.010296, Discriminator: 0.021668; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 0.079958\n",
      "Reconstruction: 0.041094, Regularization: 0.006363, Discriminator: 0.021666; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 0.087627\n",
      "Reconstruction: 0.047509, Regularization: 0.007693, Discriminator: 0.021588; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 0.087449\n",
      "Reconstruction: 0.047381, Regularization: 0.007631, Discriminator: 0.021606; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 0.093551\n",
      "Reconstruction: 0.052259, Regularization: 0.008823, Discriminator: 0.021630; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 0.080709\n",
      "Reconstruction: 0.041844, Regularization: 0.006366, Discriminator: 0.021661; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 0.082423\n",
      "Reconstruction: 0.043547, Regularization: 0.006364, Discriminator: 0.021679; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 85 Average loss: 0.0877\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 0.106238\n",
      "Reconstruction: 0.062991, Regularization: 0.010764, Discriminator: 0.021649; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5028, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 0.087516\n",
      "Reconstruction: 0.047746, Regularization: 0.007362, Discriminator: 0.021573; Generator: 0.010835,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 0.092943\n",
      "Reconstruction: 0.052017, Regularization: 0.008478, Discriminator: 0.021618; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 0.083444\n",
      "Reconstruction: 0.044278, Regularization: 0.006725, Discriminator: 0.021606; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 0.084856\n",
      "Reconstruction: 0.045445, Regularization: 0.006882, Discriminator: 0.021698; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 0.083952\n",
      "Reconstruction: 0.044694, Regularization: 0.006727, Discriminator: 0.021696; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 0.091764\n",
      "Reconstruction: 0.050947, Regularization: 0.008388, Discriminator: 0.021592; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 0.094236\n",
      "Reconstruction: 0.053532, Regularization: 0.008216, Discriminator: 0.021654; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 86 Average loss: 0.0875\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 0.082997\n",
      "Reconstruction: 0.043955, Regularization: 0.006575, Discriminator: 0.021630; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 0.099145\n",
      "Reconstruction: 0.057415, Regularization: 0.009264, Discriminator: 0.021629; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 0.087574\n",
      "Reconstruction: 0.047906, Regularization: 0.007176, Discriminator: 0.021663; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 0.087680\n",
      "Reconstruction: 0.047991, Regularization: 0.007174, Discriminator: 0.021678; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 0.086946\n",
      "Reconstruction: 0.047341, Regularization: 0.007084, Discriminator: 0.021690; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 0.081382\n",
      "Reconstruction: 0.043033, Regularization: 0.005859, Discriminator: 0.021659; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 0.101505\n",
      "Reconstruction: 0.059682, Regularization: 0.009325, Discriminator: 0.021663; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 0.094130\n",
      "Reconstruction: 0.053432, Regularization: 0.008179, Discriminator: 0.021688; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 87 Average loss: 0.0873\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 0.096270\n",
      "Reconstruction: 0.055204, Regularization: 0.008615, Discriminator: 0.021611; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 0.086998\n",
      "Reconstruction: 0.047681, Regularization: 0.006823, Discriminator: 0.021659; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 0.097806\n",
      "Reconstruction: 0.056727, Regularization: 0.008574, Discriminator: 0.021671; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 0.073784\n",
      "Reconstruction: 0.036786, Regularization: 0.004536, Discriminator: 0.021622; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 0.084096\n",
      "Reconstruction: 0.045489, Regularization: 0.006139, Discriminator: 0.021639; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 0.089970\n",
      "Reconstruction: 0.050385, Regularization: 0.007061, Discriminator: 0.021690; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 0.082089\n",
      "Reconstruction: 0.043619, Regularization: 0.005972, Discriminator: 0.021656; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 0.085836\n",
      "Reconstruction: 0.046925, Regularization: 0.006439, Discriminator: 0.021639; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 88 Average loss: 0.0871\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 0.089742\n",
      "Reconstruction: 0.050363, Regularization: 0.006875, Discriminator: 0.021670; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 0.075365\n",
      "Reconstruction: 0.038128, Regularization: 0.004696, Discriminator: 0.021706; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 0.100903\n",
      "Reconstruction: 0.059762, Regularization: 0.008657, Discriminator: 0.021651; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 0.080507\n",
      "Reconstruction: 0.042602, Regularization: 0.005385, Discriminator: 0.021688; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 0.101436\n",
      "Reconstruction: 0.059908, Regularization: 0.008978, Discriminator: 0.021717; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 0.089062\n",
      "Reconstruction: 0.049704, Regularization: 0.006851, Discriminator: 0.021671; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 0.093589\n",
      "Reconstruction: 0.053653, Regularization: 0.007439, Discriminator: 0.021664; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 0.080577\n",
      "Reconstruction: 0.042753, Regularization: 0.005272, Discriminator: 0.021720; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "====> Epoch: 89 Average loss: 0.0870\n",
      "tensor(0.4972, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 0.097423\n",
      "Reconstruction: 0.056866, Regularization: 0.007974, Discriminator: 0.021752; Generator: 0.010832,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "tensor(0.4975, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 0.085904\n",
      "Reconstruction: 0.047116, Regularization: 0.006215, Discriminator: 0.021734; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 0.082356\n",
      "Reconstruction: 0.044299, Regularization: 0.005565, Discriminator: 0.021656; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 0.104895\n",
      "Reconstruction: 0.063514, Regularization: 0.008872, Discriminator: 0.021672; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 0.089281\n",
      "Reconstruction: 0.050203, Regularization: 0.006562, Discriminator: 0.021682; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 0.080843\n",
      "Reconstruction: 0.043262, Regularization: 0.005139, Discriminator: 0.021610; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 0.104431\n",
      "Reconstruction: 0.063220, Regularization: 0.008769, Discriminator: 0.021605; Generator: 0.010838,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 0.079234\n",
      "Reconstruction: 0.041649, Regularization: 0.005068, Discriminator: 0.021682; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 90 Average loss: 0.0868\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 0.086271\n",
      "Reconstruction: 0.047815, Regularization: 0.005926, Discriminator: 0.021696; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 0.073003\n",
      "Reconstruction: 0.036508, Regularization: 0.004017, Discriminator: 0.021642; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 0.079491\n",
      "Reconstruction: 0.042086, Regularization: 0.004941, Discriminator: 0.021631; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 0.079717\n",
      "Reconstruction: 0.042306, Regularization: 0.004908, Discriminator: 0.021665; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 0.079679\n",
      "Reconstruction: 0.042162, Regularization: 0.005002, Discriminator: 0.021682; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 0.087226\n",
      "Reconstruction: 0.048961, Regularization: 0.005812, Discriminator: 0.021613; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 0.088020\n",
      "Reconstruction: 0.049644, Regularization: 0.005898, Discriminator: 0.021641; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 0.089555\n",
      "Reconstruction: 0.050936, Regularization: 0.006098, Discriminator: 0.021686; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 91 Average loss: 0.0867\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 0.088140\n",
      "Reconstruction: 0.049574, Regularization: 0.006052, Discriminator: 0.021682; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5027, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 0.089279\n",
      "Reconstruction: 0.050757, Regularization: 0.006111, Discriminator: 0.021575; Generator: 0.010835,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 0.080260\n",
      "Reconstruction: 0.042963, Regularization: 0.004812, Discriminator: 0.021655; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 0.094168\n",
      "Reconstruction: 0.054662, Regularization: 0.006977, Discriminator: 0.021691; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 0.086624\n",
      "Reconstruction: 0.048420, Regularization: 0.005685, Discriminator: 0.021687; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 0.080466\n",
      "Reconstruction: 0.043112, Regularization: 0.004819, Discriminator: 0.021705; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 0.088849\n",
      "Reconstruction: 0.050392, Regularization: 0.005980, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 0.094064\n",
      "Reconstruction: 0.055086, Regularization: 0.006502, Discriminator: 0.021641; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 92 Average loss: 0.0865\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 0.089261\n",
      "Reconstruction: 0.050943, Regularization: 0.005826, Discriminator: 0.021648; Generator: 0.010843,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 0.085440\n",
      "Reconstruction: 0.047648, Regularization: 0.005364, Discriminator: 0.021594; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 0.079986\n",
      "Reconstruction: 0.042999, Regularization: 0.004495, Discriminator: 0.021659; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 0.079826\n",
      "Reconstruction: 0.042615, Regularization: 0.004711, Discriminator: 0.021665; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 0.106215\n",
      "Reconstruction: 0.065552, Regularization: 0.008191, Discriminator: 0.021639; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 0.086428\n",
      "Reconstruction: 0.048591, Regularization: 0.005360, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 0.091865\n",
      "Reconstruction: 0.053280, Regularization: 0.006065, Discriminator: 0.021687; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4976, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 0.089859\n",
      "Reconstruction: 0.051624, Regularization: 0.005665, Discriminator: 0.021735; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "====> Epoch: 93 Average loss: 0.0863\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 0.088790\n",
      "Reconstruction: 0.050795, Regularization: 0.005528, Discriminator: 0.021639; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 0.092121\n",
      "Reconstruction: 0.053602, Regularization: 0.006040, Discriminator: 0.021637; Generator: 0.010841,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 0.075253\n",
      "Reconstruction: 0.038961, Regularization: 0.003816, Discriminator: 0.021644; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 0.095435\n",
      "Reconstruction: 0.056543, Regularization: 0.006340, Discriminator: 0.021716; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4978, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 0.091217\n",
      "Reconstruction: 0.052872, Regularization: 0.005781, Discriminator: 0.021730; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 0.084918\n",
      "Reconstruction: 0.047341, Regularization: 0.005098, Discriminator: 0.021648; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 0.080580\n",
      "Reconstruction: 0.043643, Regularization: 0.004397, Discriminator: 0.021706; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 0.076799\n",
      "Reconstruction: 0.040481, Regularization: 0.003845, Discriminator: 0.021642; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 94 Average loss: 0.0860\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 0.075393\n",
      "Reconstruction: 0.039238, Regularization: 0.003657, Discriminator: 0.021669; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 0.084853\n",
      "Reconstruction: 0.047673, Regularization: 0.004713, Discriminator: 0.021636; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 0.094005\n",
      "Reconstruction: 0.055697, Regularization: 0.005851, Discriminator: 0.021622; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5020, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 0.087492\n",
      "Reconstruction: 0.049911, Regularization: 0.005149, Discriminator: 0.021602; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 0.081200\n",
      "Reconstruction: 0.044395, Regularization: 0.004318, Discriminator: 0.021654; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 0.094915\n",
      "Reconstruction: 0.056562, Regularization: 0.005885, Discriminator: 0.021632; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 0.074987\n",
      "Reconstruction: 0.039041, Regularization: 0.003502, Discriminator: 0.021612; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 0.081476\n",
      "Reconstruction: 0.044671, Regularization: 0.004348, Discriminator: 0.021620; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 95 Average loss: 0.0861\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 0.083555\n",
      "Reconstruction: 0.046878, Regularization: 0.004222, Discriminator: 0.021624; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 0.085266\n",
      "Reconstruction: 0.048127, Regularization: 0.004665, Discriminator: 0.021640; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 0.079182\n",
      "Reconstruction: 0.042870, Regularization: 0.003775, Discriminator: 0.021703; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 0.094656\n",
      "Reconstruction: 0.056475, Regularization: 0.005717, Discriminator: 0.021629; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 0.084227\n",
      "Reconstruction: 0.047269, Regularization: 0.004442, Discriminator: 0.021683; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 0.071153\n",
      "Reconstruction: 0.035775, Regularization: 0.002850, Discriminator: 0.021693; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 0.085985\n",
      "Reconstruction: 0.048935, Regularization: 0.004566, Discriminator: 0.021652; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 0.084608\n",
      "Reconstruction: 0.047656, Regularization: 0.004414, Discriminator: 0.021707; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 96 Average loss: 0.0860\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 0.080500\n",
      "Reconstruction: 0.043974, Regularization: 0.004019, Discriminator: 0.021672; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4964, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 0.087223\n",
      "Reconstruction: 0.049902, Regularization: 0.004715, Discriminator: 0.021776; Generator: 0.010830,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 0.084723\n",
      "Reconstruction: 0.047735, Regularization: 0.004462, Discriminator: 0.021696; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4976, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 0.082416\n",
      "Reconstruction: 0.045840, Regularization: 0.004007, Discriminator: 0.021739; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 0.093337\n",
      "Reconstruction: 0.055491, Regularization: 0.005337, Discriminator: 0.021675; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 0.074627\n",
      "Reconstruction: 0.039009, Regularization: 0.003147, Discriminator: 0.021640; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 0.093943\n",
      "Reconstruction: 0.056072, Regularization: 0.005327, Discriminator: 0.021704; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 0.086479\n",
      "Reconstruction: 0.049516, Regularization: 0.004468, Discriminator: 0.021660; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 97 Average loss: 0.0858\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 0.079784\n",
      "Reconstruction: 0.043679, Regularization: 0.003651, Discriminator: 0.021621; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 0.088025\n",
      "Reconstruction: 0.050962, Regularization: 0.004633, Discriminator: 0.021591; Generator: 0.010839,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4979, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 0.094920\n",
      "Reconstruction: 0.057032, Regularization: 0.005327, Discriminator: 0.021727; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 0.082875\n",
      "Reconstruction: 0.046393, Regularization: 0.003986, Discriminator: 0.021662; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 0.094518\n",
      "Reconstruction: 0.056837, Regularization: 0.005224, Discriminator: 0.021627; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 0.081186\n",
      "Reconstruction: 0.044865, Regularization: 0.003831, Discriminator: 0.021656; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 0.088197\n",
      "Reconstruction: 0.051236, Regularization: 0.004451, Discriminator: 0.021680; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 0.073566\n",
      "Reconstruction: 0.038125, Regularization: 0.002946, Discriminator: 0.021664; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 98 Average loss: 0.0857\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 0.086456\n",
      "Reconstruction: 0.049907, Regularization: 0.004115, Discriminator: 0.021601; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 0.075142\n",
      "Reconstruction: 0.039619, Regularization: 0.003070, Discriminator: 0.021618; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 0.086524\n",
      "Reconstruction: 0.049871, Regularization: 0.004162, Discriminator: 0.021660; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 0.080909\n",
      "Reconstruction: 0.044863, Regularization: 0.003518, Discriminator: 0.021691; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5030, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 0.105635\n",
      "Reconstruction: 0.066992, Regularization: 0.006239, Discriminator: 0.021571; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 0.081465\n",
      "Reconstruction: 0.045386, Regularization: 0.003593, Discriminator: 0.021650; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 0.077194\n",
      "Reconstruction: 0.041529, Regularization: 0.003166, Discriminator: 0.021668; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 0.082168\n",
      "Reconstruction: 0.046079, Regularization: 0.003594, Discriminator: 0.021664; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 99 Average loss: 0.0855\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 0.078533\n",
      "Reconstruction: 0.042767, Regularization: 0.003229, Discriminator: 0.021703; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 0.076554\n",
      "Reconstruction: 0.041150, Regularization: 0.002900, Discriminator: 0.021666; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 0.085011\n",
      "Reconstruction: 0.048731, Regularization: 0.003804, Discriminator: 0.021644; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 0.079690\n",
      "Reconstruction: 0.043848, Regularization: 0.003337, Discriminator: 0.021669; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 0.090871\n",
      "Reconstruction: 0.053931, Regularization: 0.004485, Discriminator: 0.021623; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 0.083073\n",
      "Reconstruction: 0.046954, Regularization: 0.003619, Discriminator: 0.021663; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 0.079344\n",
      "Reconstruction: 0.043713, Regularization: 0.003188, Discriminator: 0.021610; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 0.083104\n",
      "Reconstruction: 0.047116, Regularization: 0.003510, Discriminator: 0.021639; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 100 Average loss: 0.0854\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 0.090897\n",
      "Reconstruction: 0.053995, Regularization: 0.004383, Discriminator: 0.021681; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 0.079429\n",
      "Reconstruction: 0.043806, Regularization: 0.003119, Discriminator: 0.021669; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 0.088974\n",
      "Reconstruction: 0.052538, Regularization: 0.004017, Discriminator: 0.021590; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 0.079064\n",
      "Reconstruction: 0.043511, Regularization: 0.003103, Discriminator: 0.021619; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 0.093655\n",
      "Reconstruction: 0.056804, Regularization: 0.004410, Discriminator: 0.021612; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 0.090196\n",
      "Reconstruction: 0.053700, Regularization: 0.004016, Discriminator: 0.021645; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 0.088413\n",
      "Reconstruction: 0.052050, Regularization: 0.003915, Discriminator: 0.021613; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 0.085376\n",
      "Reconstruction: 0.049466, Regularization: 0.003417, Discriminator: 0.021659; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 101 Average loss: 0.0854\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 0.083127\n",
      "Reconstruction: 0.047170, Regularization: 0.003450, Discriminator: 0.021669; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 0.092960\n",
      "Reconstruction: 0.056237, Regularization: 0.004210, Discriminator: 0.021683; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 0.075686\n",
      "Reconstruction: 0.040537, Regularization: 0.002645, Discriminator: 0.021673; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 0.083587\n",
      "Reconstruction: 0.047987, Regularization: 0.003157, Discriminator: 0.021605; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 0.082070\n",
      "Reconstruction: 0.046398, Regularization: 0.003205, Discriminator: 0.021631; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 0.086782\n",
      "Reconstruction: 0.050556, Regularization: 0.003743, Discriminator: 0.021650; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 0.089428\n",
      "Reconstruction: 0.053077, Regularization: 0.003839, Discriminator: 0.021682; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 0.083895\n",
      "Reconstruction: 0.048140, Regularization: 0.003334, Discriminator: 0.021587; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 102 Average loss: 0.0852\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 0.088144\n",
      "Reconstruction: 0.052118, Regularization: 0.003577, Discriminator: 0.021611; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 0.095649\n",
      "Reconstruction: 0.059051, Regularization: 0.004172, Discriminator: 0.021584; Generator: 0.010843,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 0.085491\n",
      "Reconstruction: 0.049683, Regularization: 0.003250, Discriminator: 0.021732; Generator: 0.010826,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5046, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 0.096827\n",
      "Reconstruction: 0.060258, Regularization: 0.004216, Discriminator: 0.021522; Generator: 0.010831,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 0.098312\n",
      "Reconstruction: 0.061401, Regularization: 0.004380, Discriminator: 0.021700; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 0.086964\n",
      "Reconstruction: 0.051111, Regularization: 0.003371, Discriminator: 0.021647; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 0.085696\n",
      "Reconstruction: 0.049987, Regularization: 0.003266, Discriminator: 0.021612; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 0.083484\n",
      "Reconstruction: 0.047892, Regularization: 0.003120, Discriminator: 0.021638; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 103 Average loss: 0.0852\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 0.085837\n",
      "Reconstruction: 0.050018, Regularization: 0.003326, Discriminator: 0.021666; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 0.095798\n",
      "Reconstruction: 0.059276, Regularization: 0.004043, Discriminator: 0.021651; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 0.099424\n",
      "Reconstruction: 0.062650, Regularization: 0.004297, Discriminator: 0.021637; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 0.075147\n",
      "Reconstruction: 0.040267, Regularization: 0.002384, Discriminator: 0.021661; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 0.086297\n",
      "Reconstruction: 0.050587, Regularization: 0.003164, Discriminator: 0.021714; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 0.093596\n",
      "Reconstruction: 0.057368, Regularization: 0.003739, Discriminator: 0.021664; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 0.089043\n",
      "Reconstruction: 0.053140, Regularization: 0.003380, Discriminator: 0.021689; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 0.085997\n",
      "Reconstruction: 0.050419, Regularization: 0.003080, Discriminator: 0.021667; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 104 Average loss: 0.0852\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 0.082154\n",
      "Reconstruction: 0.046914, Regularization: 0.002742, Discriminator: 0.021660; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 0.082083\n",
      "Reconstruction: 0.046792, Regularization: 0.002822, Discriminator: 0.021634; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 0.091004\n",
      "Reconstruction: 0.054993, Regularization: 0.003514, Discriminator: 0.021661; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4969, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 0.076868\n",
      "Reconstruction: 0.041954, Regularization: 0.002324, Discriminator: 0.021753; Generator: 0.010837,\n",
      "D(x): 0.497, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 0.078550\n",
      "Reconstruction: 0.043617, Regularization: 0.002459, Discriminator: 0.021639; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 0.083833\n",
      "Reconstruction: 0.048395, Regularization: 0.002911, Discriminator: 0.021698; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 0.083726\n",
      "Reconstruction: 0.048320, Regularization: 0.002914, Discriminator: 0.021664; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 0.083840\n",
      "Reconstruction: 0.048519, Regularization: 0.002838, Discriminator: 0.021647; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 105 Average loss: 0.0850\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 0.077193\n",
      "Reconstruction: 0.042485, Regularization: 0.002246, Discriminator: 0.021626; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 0.080596\n",
      "Reconstruction: 0.045585, Regularization: 0.002539, Discriminator: 0.021628; Generator: 0.010844,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 0.101060\n",
      "Reconstruction: 0.064651, Regularization: 0.003899, Discriminator: 0.021681; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 0.084474\n",
      "Reconstruction: 0.049169, Regularization: 0.002865, Discriminator: 0.021604; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 0.079272\n",
      "Reconstruction: 0.044327, Regularization: 0.002452, Discriminator: 0.021663; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 0.088498\n",
      "Reconstruction: 0.052895, Regularization: 0.003087, Discriminator: 0.021680; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5020, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 0.078398\n",
      "Reconstruction: 0.043597, Regularization: 0.002370, Discriminator: 0.021589; Generator: 0.010842,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 0.079212\n",
      "Reconstruction: 0.044319, Regularization: 0.002384, Discriminator: 0.021677; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 106 Average loss: 0.0850\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 0.075416\n",
      "Reconstruction: 0.040887, Regularization: 0.002034, Discriminator: 0.021664; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 0.096031\n",
      "Reconstruction: 0.060012, Regularization: 0.003522, Discriminator: 0.021665; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 0.077146\n",
      "Reconstruction: 0.042580, Regularization: 0.002137, Discriminator: 0.021598; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 0.082758\n",
      "Reconstruction: 0.047749, Regularization: 0.002500, Discriminator: 0.021675; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 0.081966\n",
      "Reconstruction: 0.046924, Regularization: 0.002511, Discriminator: 0.021695; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5027, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 0.086728\n",
      "Reconstruction: 0.051468, Regularization: 0.002850, Discriminator: 0.021572; Generator: 0.010839,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 0.079106\n",
      "Reconstruction: 0.044325, Regularization: 0.002290, Discriminator: 0.021660; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 0.089739\n",
      "Reconstruction: 0.054192, Regularization: 0.003019, Discriminator: 0.021698; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 107 Average loss: 0.0849\n",
      "tensor(0.5025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 0.085425\n",
      "Reconstruction: 0.050313, Regularization: 0.002696, Discriminator: 0.021584; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 0.088017\n",
      "Reconstruction: 0.052668, Regularization: 0.002809, Discriminator: 0.021706; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 0.084669\n",
      "Reconstruction: 0.049656, Regularization: 0.002560, Discriminator: 0.021622; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 0.086571\n",
      "Reconstruction: 0.051435, Regularization: 0.002684, Discriminator: 0.021615; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5023, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 0.080594\n",
      "Reconstruction: 0.045890, Regularization: 0.002283, Discriminator: 0.021583; Generator: 0.010838,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 0.085862\n",
      "Reconstruction: 0.050730, Regularization: 0.002697, Discriminator: 0.021596; Generator: 0.010839,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 0.083724\n",
      "Reconstruction: 0.048653, Regularization: 0.002568, Discriminator: 0.021667; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 0.074228\n",
      "Reconstruction: 0.039839, Regularization: 0.001940, Discriminator: 0.021619; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 108 Average loss: 0.0848\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 0.087928\n",
      "Reconstruction: 0.052760, Regularization: 0.002720, Discriminator: 0.021612; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 0.081305\n",
      "Reconstruction: 0.046463, Regularization: 0.002299, Discriminator: 0.021704; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 0.088122\n",
      "Reconstruction: 0.052970, Regularization: 0.002638, Discriminator: 0.021684; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 0.087914\n",
      "Reconstruction: 0.052891, Regularization: 0.002531, Discriminator: 0.021658; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 0.073901\n",
      "Reconstruction: 0.039704, Regularization: 0.001738, Discriminator: 0.021628; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 0.078687\n",
      "Reconstruction: 0.044206, Regularization: 0.001987, Discriminator: 0.021658; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 0.082792\n",
      "Reconstruction: 0.048094, Regularization: 0.002215, Discriminator: 0.021644; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 0.091952\n",
      "Reconstruction: 0.056588, Regularization: 0.002834, Discriminator: 0.021694; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 109 Average loss: 0.0849\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 0.076595\n",
      "Reconstruction: 0.042283, Regularization: 0.001877, Discriminator: 0.021601; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 0.078012\n",
      "Reconstruction: 0.043544, Regularization: 0.001928, Discriminator: 0.021704; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 0.085105\n",
      "Reconstruction: 0.050228, Regularization: 0.002402, Discriminator: 0.021640; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 0.088451\n",
      "Reconstruction: 0.053495, Regularization: 0.002473, Discriminator: 0.021649; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 0.082595\n",
      "Reconstruction: 0.047843, Regularization: 0.002267, Discriminator: 0.021654; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 0.081385\n",
      "Reconstruction: 0.046893, Regularization: 0.002039, Discriminator: 0.021621; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 0.082300\n",
      "Reconstruction: 0.047726, Regularization: 0.002079, Discriminator: 0.021659; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 0.074846\n",
      "Reconstruction: 0.040661, Regularization: 0.001699, Discriminator: 0.021647; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 110 Average loss: 0.0847\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 0.087073\n",
      "Reconstruction: 0.052114, Regularization: 0.002466, Discriminator: 0.021660; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 0.085477\n",
      "Reconstruction: 0.050666, Regularization: 0.002309, Discriminator: 0.021670; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 0.096602\n",
      "Reconstruction: 0.061237, Regularization: 0.002910, Discriminator: 0.021620; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 0.094508\n",
      "Reconstruction: 0.059281, Regularization: 0.002789, Discriminator: 0.021607; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 0.087448\n",
      "Reconstruction: 0.052668, Regularization: 0.002297, Discriminator: 0.021648; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4978, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 0.080286\n",
      "Reconstruction: 0.045860, Regularization: 0.001864, Discriminator: 0.021733; Generator: 0.010829,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 0.094705\n",
      "Reconstruction: 0.059463, Regularization: 0.002697, Discriminator: 0.021705; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 0.072154\n",
      "Reconstruction: 0.038216, Regularization: 0.001430, Discriminator: 0.021677; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 111 Average loss: 0.0848\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 0.077049\n",
      "Reconstruction: 0.042856, Regularization: 0.001683, Discriminator: 0.021673; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 0.088798\n",
      "Reconstruction: 0.053835, Regularization: 0.002419, Discriminator: 0.021711; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 0.092941\n",
      "Reconstruction: 0.057874, Regularization: 0.002576, Discriminator: 0.021666; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 0.073735\n",
      "Reconstruction: 0.039718, Regularization: 0.001473, Discriminator: 0.021712; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 0.077847\n",
      "Reconstruction: 0.043614, Regularization: 0.001758, Discriminator: 0.021638; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5030, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 0.089457\n",
      "Reconstruction: 0.054679, Regularization: 0.002379, Discriminator: 0.021563; Generator: 0.010836,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 0.096679\n",
      "Reconstruction: 0.061473, Regularization: 0.002747, Discriminator: 0.021628; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 0.084187\n",
      "Reconstruction: 0.049640, Regularization: 0.002049, Discriminator: 0.021670; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 112 Average loss: 0.0846\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 0.078671\n",
      "Reconstruction: 0.044425, Regularization: 0.001717, Discriminator: 0.021693; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 0.089827\n",
      "Reconstruction: 0.055003, Regularization: 0.002330, Discriminator: 0.021663; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 0.090744\n",
      "Reconstruction: 0.055928, Regularization: 0.002346, Discriminator: 0.021636; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 0.083878\n",
      "Reconstruction: 0.049511, Regularization: 0.001915, Discriminator: 0.021621; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 0.084229\n",
      "Reconstruction: 0.049738, Regularization: 0.002011, Discriminator: 0.021646; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 0.086519\n",
      "Reconstruction: 0.051990, Regularization: 0.002079, Discriminator: 0.021614; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 0.079632\n",
      "Reconstruction: 0.045401, Regularization: 0.001711, Discriminator: 0.021682; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 0.065298\n",
      "Reconstruction: 0.031839, Regularization: 0.000974, Discriminator: 0.021654; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 113 Average loss: 0.0848\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 0.077384\n",
      "Reconstruction: 0.043267, Regularization: 0.001587, Discriminator: 0.021697; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 0.090966\n",
      "Reconstruction: 0.056116, Regularization: 0.002328, Discriminator: 0.021688; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 0.079632\n",
      "Reconstruction: 0.045471, Regularization: 0.001637, Discriminator: 0.021695; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 0.077768\n",
      "Reconstruction: 0.043631, Regularization: 0.001611, Discriminator: 0.021690; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 0.087068\n",
      "Reconstruction: 0.052547, Regularization: 0.001991, Discriminator: 0.021691; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 0.082067\n",
      "Reconstruction: 0.047784, Regularization: 0.001741, Discriminator: 0.021704; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 0.083327\n",
      "Reconstruction: 0.048987, Regularization: 0.001838, Discriminator: 0.021662; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 0.077583\n",
      "Reconstruction: 0.043505, Regularization: 0.001533, Discriminator: 0.021713; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "====> Epoch: 114 Average loss: 0.0847\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 0.087443\n",
      "Reconstruction: 0.052928, Regularization: 0.001986, Discriminator: 0.021696; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 0.078995\n",
      "Reconstruction: 0.044922, Regularization: 0.001553, Discriminator: 0.021683; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 0.081602\n",
      "Reconstruction: 0.047262, Regularization: 0.001805, Discriminator: 0.021701; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 0.088978\n",
      "Reconstruction: 0.054464, Regularization: 0.002026, Discriminator: 0.021656; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 0.088795\n",
      "Reconstruction: 0.054301, Regularization: 0.002034, Discriminator: 0.021626; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 0.083605\n",
      "Reconstruction: 0.049356, Regularization: 0.001805, Discriminator: 0.021609; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 0.080055\n",
      "Reconstruction: 0.046020, Regularization: 0.001569, Discriminator: 0.021631; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 0.091231\n",
      "Reconstruction: 0.056629, Regularization: 0.002167, Discriminator: 0.021596; Generator: 0.010840,\n",
      "D(x): 0.502, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 115 Average loss: 0.0846\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 0.087810\n",
      "Reconstruction: 0.053347, Regularization: 0.001964, Discriminator: 0.021665; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 0.085445\n",
      "Reconstruction: 0.051159, Regularization: 0.001827, Discriminator: 0.021630; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 0.089847\n",
      "Reconstruction: 0.055271, Regularization: 0.002074, Discriminator: 0.021671; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 0.078992\n",
      "Reconstruction: 0.044986, Regularization: 0.001528, Discriminator: 0.021647; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 0.077727\n",
      "Reconstruction: 0.043764, Regularization: 0.001447, Discriminator: 0.021684; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 0.078141\n",
      "Reconstruction: 0.044163, Regularization: 0.001496, Discriminator: 0.021650; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4978, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 0.084562\n",
      "Reconstruction: 0.050301, Regularization: 0.001698, Discriminator: 0.021730; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5027, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 0.086263\n",
      "Reconstruction: 0.052111, Regularization: 0.001742, Discriminator: 0.021583; Generator: 0.010827,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "====> Epoch: 116 Average loss: 0.0846\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 0.084844\n",
      "Reconstruction: 0.050689, Regularization: 0.001674, Discriminator: 0.021642; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 0.086048\n",
      "Reconstruction: 0.051780, Regularization: 0.001805, Discriminator: 0.021626; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 0.081605\n",
      "Reconstruction: 0.047530, Regularization: 0.001579, Discriminator: 0.021665; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 0.068676\n",
      "Reconstruction: 0.035233, Regularization: 0.000972, Discriminator: 0.021637; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 0.075431\n",
      "Reconstruction: 0.041651, Regularization: 0.001255, Discriminator: 0.021696; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5023, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 0.082002\n",
      "Reconstruction: 0.047934, Regularization: 0.001644, Discriminator: 0.021592; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 0.083565\n",
      "Reconstruction: 0.049488, Regularization: 0.001581, Discriminator: 0.021667; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 0.077219\n",
      "Reconstruction: 0.043352, Regularization: 0.001376, Discriminator: 0.021656; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 117 Average loss: 0.0847\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 0.092048\n",
      "Reconstruction: 0.057675, Regularization: 0.001910, Discriminator: 0.021624; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 0.083990\n",
      "Reconstruction: 0.049863, Regularization: 0.001624, Discriminator: 0.021678; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4973, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 0.073695\n",
      "Reconstruction: 0.039999, Regularization: 0.001119, Discriminator: 0.021738; Generator: 0.010839,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 0.079796\n",
      "Reconstruction: 0.045840, Regularization: 0.001406, Discriminator: 0.021715; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 0.086995\n",
      "Reconstruction: 0.052812, Regularization: 0.001687, Discriminator: 0.021658; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 0.090113\n",
      "Reconstruction: 0.055719, Regularization: 0.001869, Discriminator: 0.021690; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 0.090638\n",
      "Reconstruction: 0.056332, Regularization: 0.001811, Discriminator: 0.021665; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 0.082412\n",
      "Reconstruction: 0.048473, Regularization: 0.001482, Discriminator: 0.021626; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 118 Average loss: 0.0846\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 0.088986\n",
      "Reconstruction: 0.054762, Regularization: 0.001733, Discriminator: 0.021655; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 0.078935\n",
      "Reconstruction: 0.045155, Regularization: 0.001290, Discriminator: 0.021656; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 0.084719\n",
      "Reconstruction: 0.050759, Regularization: 0.001517, Discriminator: 0.021611; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 0.077107\n",
      "Reconstruction: 0.043429, Regularization: 0.001248, Discriminator: 0.021600; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 0.088294\n",
      "Reconstruction: 0.054132, Regularization: 0.001650, Discriminator: 0.021678; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 0.084710\n",
      "Reconstruction: 0.050711, Regularization: 0.001530, Discriminator: 0.021633; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 0.108194\n",
      "Reconstruction: 0.073306, Regularization: 0.002411, Discriminator: 0.021645; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 0.083099\n",
      "Reconstruction: 0.049168, Regularization: 0.001515, Discriminator: 0.021583; Generator: 0.010833,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "====> Epoch: 119 Average loss: 0.0847\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 0.084182\n",
      "Reconstruction: 0.050240, Regularization: 0.001469, Discriminator: 0.021638; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 0.078641\n",
      "Reconstruction: 0.044971, Regularization: 0.001251, Discriminator: 0.021588; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 0.078960\n",
      "Reconstruction: 0.045195, Regularization: 0.001279, Discriminator: 0.021650; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 0.081600\n",
      "Reconstruction: 0.047806, Regularization: 0.001321, Discriminator: 0.021643; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4963, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 0.090699\n",
      "Reconstruction: 0.056351, Regularization: 0.001738, Discriminator: 0.021782; Generator: 0.010828,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 0.086324\n",
      "Reconstruction: 0.052259, Regularization: 0.001567, Discriminator: 0.021663; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 0.083332\n",
      "Reconstruction: 0.049384, Regularization: 0.001418, Discriminator: 0.021692; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 0.084531\n",
      "Reconstruction: 0.050654, Regularization: 0.001430, Discriminator: 0.021612; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 120 Average loss: 0.0846\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 0.088091\n",
      "Reconstruction: 0.054035, Regularization: 0.001560, Discriminator: 0.021666; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 0.083304\n",
      "Reconstruction: 0.049379, Regularization: 0.001397, Discriminator: 0.021696; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 0.083609\n",
      "Reconstruction: 0.049732, Regularization: 0.001409, Discriminator: 0.021633; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 0.078251\n",
      "Reconstruction: 0.044595, Regularization: 0.001190, Discriminator: 0.021636; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 0.079975\n",
      "Reconstruction: 0.046295, Regularization: 0.001263, Discriminator: 0.021578; Generator: 0.010839,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 0.069932\n",
      "Reconstruction: 0.036558, Regularization: 0.000844, Discriminator: 0.021700; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 0.079724\n",
      "Reconstruction: 0.046106, Regularization: 0.001158, Discriminator: 0.021624; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 0.093139\n",
      "Reconstruction: 0.058876, Regularization: 0.001713, Discriminator: 0.021725; Generator: 0.010825,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "====> Epoch: 121 Average loss: 0.0847\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 0.086439\n",
      "Reconstruction: 0.052425, Regularization: 0.001490, Discriminator: 0.021695; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 0.085687\n",
      "Reconstruction: 0.051821, Regularization: 0.001385, Discriminator: 0.021645; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 0.084029\n",
      "Reconstruction: 0.050169, Regularization: 0.001351, Discriminator: 0.021680; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 0.083856\n",
      "Reconstruction: 0.050100, Regularization: 0.001292, Discriminator: 0.021629; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 0.087631\n",
      "Reconstruction: 0.053611, Regularization: 0.001513, Discriminator: 0.021669; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 0.075629\n",
      "Reconstruction: 0.042097, Regularization: 0.001047, Discriminator: 0.021651; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 0.079256\n",
      "Reconstruction: 0.045610, Regularization: 0.001112, Discriminator: 0.021699; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 0.084846\n",
      "Reconstruction: 0.050951, Regularization: 0.001356, Discriminator: 0.021700; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 122 Average loss: 0.0846\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 0.084261\n",
      "Reconstruction: 0.050491, Regularization: 0.001312, Discriminator: 0.021625; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 0.081215\n",
      "Reconstruction: 0.047479, Regularization: 0.001232, Discriminator: 0.021666; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 0.083974\n",
      "Reconstruction: 0.050101, Regularization: 0.001369, Discriminator: 0.021669; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 0.088076\n",
      "Reconstruction: 0.054181, Regularization: 0.001440, Discriminator: 0.021618; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 0.093935\n",
      "Reconstruction: 0.059762, Regularization: 0.001664, Discriminator: 0.021672; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 0.092922\n",
      "Reconstruction: 0.058804, Regularization: 0.001626, Discriminator: 0.021657; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 0.084977\n",
      "Reconstruction: 0.051206, Regularization: 0.001294, Discriminator: 0.021640; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 0.078098\n",
      "Reconstruction: 0.044481, Regularization: 0.001087, Discriminator: 0.021697; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 123 Average loss: 0.0846\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 0.084547\n",
      "Reconstruction: 0.050729, Regularization: 0.001312, Discriminator: 0.021677; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 0.085903\n",
      "Reconstruction: 0.052027, Regularization: 0.001320, Discriminator: 0.021719; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 0.084222\n",
      "Reconstruction: 0.050423, Regularization: 0.001286, Discriminator: 0.021677; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 0.085415\n",
      "Reconstruction: 0.051590, Regularization: 0.001297, Discriminator: 0.021696; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 0.080310\n",
      "Reconstruction: 0.046674, Regularization: 0.001137, Discriminator: 0.021663; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 0.080130\n",
      "Reconstruction: 0.046473, Regularization: 0.001141, Discriminator: 0.021685; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 0.083454\n",
      "Reconstruction: 0.049701, Regularization: 0.001257, Discriminator: 0.021663; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 0.085128\n",
      "Reconstruction: 0.051279, Regularization: 0.001290, Discriminator: 0.021724; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "====> Epoch: 124 Average loss: 0.0846\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 0.092489\n",
      "Reconstruction: 0.058508, Regularization: 0.001528, Discriminator: 0.021614; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 0.088239\n",
      "Reconstruction: 0.054400, Regularization: 0.001422, Discriminator: 0.021581; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 0.086542\n",
      "Reconstruction: 0.052729, Regularization: 0.001363, Discriminator: 0.021612; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 0.096521\n",
      "Reconstruction: 0.062295, Regularization: 0.001675, Discriminator: 0.021712; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 0.074953\n",
      "Reconstruction: 0.041596, Regularization: 0.000913, Discriminator: 0.021609; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 0.080229\n",
      "Reconstruction: 0.046589, Regularization: 0.001093, Discriminator: 0.021710; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 0.083651\n",
      "Reconstruction: 0.049913, Regularization: 0.001197, Discriminator: 0.021705; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5038, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 0.079900\n",
      "Reconstruction: 0.046413, Regularization: 0.001112, Discriminator: 0.021547; Generator: 0.010828,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "====> Epoch: 125 Average loss: 0.0846\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 0.090864\n",
      "Reconstruction: 0.056911, Regularization: 0.001485, Discriminator: 0.021634; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 0.082248\n",
      "Reconstruction: 0.048619, Regularization: 0.001176, Discriminator: 0.021620; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 0.082306\n",
      "Reconstruction: 0.048645, Regularization: 0.001143, Discriminator: 0.021683; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 0.083229\n",
      "Reconstruction: 0.049582, Regularization: 0.001177, Discriminator: 0.021639; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 0.082273\n",
      "Reconstruction: 0.048608, Regularization: 0.001159, Discriminator: 0.021671; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 0.079076\n",
      "Reconstruction: 0.045541, Regularization: 0.001047, Discriminator: 0.021652; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 0.077467\n",
      "Reconstruction: 0.043930, Regularization: 0.001012, Discriminator: 0.021690; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4974, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 0.079943\n",
      "Reconstruction: 0.046290, Regularization: 0.001076, Discriminator: 0.021741; Generator: 0.010835,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "====> Epoch: 126 Average loss: 0.0846\n",
      "tensor(0.5025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 0.093662\n",
      "Reconstruction: 0.059767, Regularization: 0.001477, Discriminator: 0.021583; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 0.077200\n",
      "Reconstruction: 0.043764, Regularization: 0.001002, Discriminator: 0.021598; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 0.078390\n",
      "Reconstruction: 0.044893, Regularization: 0.001001, Discriminator: 0.021657; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 0.082137\n",
      "Reconstruction: 0.048532, Regularization: 0.001135, Discriminator: 0.021635; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 0.083840\n",
      "Reconstruction: 0.050103, Regularization: 0.001183, Discriminator: 0.021724; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 0.092161\n",
      "Reconstruction: 0.058288, Regularization: 0.001437, Discriminator: 0.021607; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 0.078217\n",
      "Reconstruction: 0.044613, Regularization: 0.001050, Discriminator: 0.021712; Generator: 0.010842,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 0.078054\n",
      "Reconstruction: 0.044591, Regularization: 0.001000, Discriminator: 0.021626; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 127 Average loss: 0.0846\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 0.084616\n",
      "Reconstruction: 0.050964, Regularization: 0.001197, Discriminator: 0.021631; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 0.076234\n",
      "Reconstruction: 0.042747, Regularization: 0.000937, Discriminator: 0.021714; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 0.083446\n",
      "Reconstruction: 0.049867, Regularization: 0.001143, Discriminator: 0.021607; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 0.082564\n",
      "Reconstruction: 0.048959, Regularization: 0.001099, Discriminator: 0.021671; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5043, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 0.085754\n",
      "Reconstruction: 0.052139, Regularization: 0.001254, Discriminator: 0.021530; Generator: 0.010831,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 0.083720\n",
      "Reconstruction: 0.050097, Regularization: 0.001150, Discriminator: 0.021638; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 0.086557\n",
      "Reconstruction: 0.052832, Regularization: 0.001212, Discriminator: 0.021676; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 0.088698\n",
      "Reconstruction: 0.054951, Regularization: 0.001287, Discriminator: 0.021623; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 128 Average loss: 0.0845\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 0.086876\n",
      "Reconstruction: 0.053135, Regularization: 0.001258, Discriminator: 0.021658; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 0.085164\n",
      "Reconstruction: 0.051526, Regularization: 0.001197, Discriminator: 0.021605; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 0.073920\n",
      "Reconstruction: 0.040593, Regularization: 0.000798, Discriminator: 0.021696; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 0.086283\n",
      "Reconstruction: 0.052575, Regularization: 0.001226, Discriminator: 0.021649; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5030, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 0.090157\n",
      "Reconstruction: 0.056406, Regularization: 0.001349, Discriminator: 0.021566; Generator: 0.010836,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 0.090048\n",
      "Reconstruction: 0.056198, Regularization: 0.001341, Discriminator: 0.021676; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 0.088223\n",
      "Reconstruction: 0.054421, Regularization: 0.001260, Discriminator: 0.021708; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 0.079651\n",
      "Reconstruction: 0.046186, Regularization: 0.000982, Discriminator: 0.021645; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 129 Average loss: 0.0847\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 0.091015\n",
      "Reconstruction: 0.057121, Regularization: 0.001412, Discriminator: 0.021645; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 0.083875\n",
      "Reconstruction: 0.050251, Regularization: 0.001127, Discriminator: 0.021659; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 0.081601\n",
      "Reconstruction: 0.047992, Regularization: 0.001071, Discriminator: 0.021706; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 0.075448\n",
      "Reconstruction: 0.042035, Regularization: 0.000896, Discriminator: 0.021678; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 0.087199\n",
      "Reconstruction: 0.053491, Regularization: 0.001250, Discriminator: 0.021625; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 0.074639\n",
      "Reconstruction: 0.041324, Regularization: 0.000831, Discriminator: 0.021652; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 0.082734\n",
      "Reconstruction: 0.049133, Regularization: 0.001094, Discriminator: 0.021670; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 0.078120\n",
      "Reconstruction: 0.044620, Regularization: 0.000968, Discriminator: 0.021697; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 130 Average loss: 0.0845\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 0.094681\n",
      "Reconstruction: 0.060747, Regularization: 0.001456, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 0.080073\n",
      "Reconstruction: 0.046550, Regularization: 0.001012, Discriminator: 0.021678; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 0.082268\n",
      "Reconstruction: 0.048783, Regularization: 0.001047, Discriminator: 0.021599; Generator: 0.010839,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 0.099656\n",
      "Reconstruction: 0.065521, Regularization: 0.001590, Discriminator: 0.021716; Generator: 0.010829,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5026, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 0.076955\n",
      "Reconstruction: 0.043623, Regularization: 0.000919, Discriminator: 0.021578; Generator: 0.010834,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 0.084040\n",
      "Reconstruction: 0.050415, Regularization: 0.001129, Discriminator: 0.021662; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 0.068351\n",
      "Reconstruction: 0.035229, Regularization: 0.000665, Discriminator: 0.021623; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 0.092772\n",
      "Reconstruction: 0.058956, Regularization: 0.001389, Discriminator: 0.021595; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 131 Average loss: 0.0845\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 0.084889\n",
      "Reconstruction: 0.051262, Regularization: 0.001143, Discriminator: 0.021648; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 0.081340\n",
      "Reconstruction: 0.047789, Regularization: 0.001044, Discriminator: 0.021679; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 0.073919\n",
      "Reconstruction: 0.040586, Regularization: 0.000865, Discriminator: 0.021633; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 0.080308\n",
      "Reconstruction: 0.046774, Regularization: 0.001019, Discriminator: 0.021680; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 0.087971\n",
      "Reconstruction: 0.054297, Regularization: 0.001192, Discriminator: 0.021646; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 0.077439\n",
      "Reconstruction: 0.044024, Regularization: 0.000929, Discriminator: 0.021654; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 0.082100\n",
      "Reconstruction: 0.048608, Regularization: 0.001065, Discriminator: 0.021586; Generator: 0.010841,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 0.083318\n",
      "Reconstruction: 0.049731, Regularization: 0.001116, Discriminator: 0.021639; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 132 Average loss: 0.0846\n",
      "tensor(0.5039, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 0.096449\n",
      "Reconstruction: 0.062567, Regularization: 0.001508, Discriminator: 0.021534; Generator: 0.010839,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 0.087617\n",
      "Reconstruction: 0.053923, Regularization: 0.001252, Discriminator: 0.021606; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 0.087873\n",
      "Reconstruction: 0.054094, Regularization: 0.001224, Discriminator: 0.021723; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5023, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 0.085241\n",
      "Reconstruction: 0.051652, Regularization: 0.001166, Discriminator: 0.021591; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 0.095315\n",
      "Reconstruction: 0.061370, Regularization: 0.001445, Discriminator: 0.021667; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 0.085813\n",
      "Reconstruction: 0.052177, Regularization: 0.001164, Discriminator: 0.021639; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5030, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 0.095637\n",
      "Reconstruction: 0.061761, Regularization: 0.001476, Discriminator: 0.021561; Generator: 0.010840,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 0.083806\n",
      "Reconstruction: 0.050253, Regularization: 0.001080, Discriminator: 0.021636; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 133 Average loss: 0.0845\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 0.089094\n",
      "Reconstruction: 0.055335, Regularization: 0.001269, Discriminator: 0.021662; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 0.089748\n",
      "Reconstruction: 0.055960, Regularization: 0.001342, Discriminator: 0.021616; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 0.083429\n",
      "Reconstruction: 0.049830, Regularization: 0.001081, Discriminator: 0.021684; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 0.082616\n",
      "Reconstruction: 0.049068, Regularization: 0.001069, Discriminator: 0.021645; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4976, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 0.090468\n",
      "Reconstruction: 0.056606, Regularization: 0.001291, Discriminator: 0.021736; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 0.082014\n",
      "Reconstruction: 0.048455, Regularization: 0.001051, Discriminator: 0.021676; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5028, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 0.078193\n",
      "Reconstruction: 0.044829, Regularization: 0.000956, Discriminator: 0.021576; Generator: 0.010832,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 0.084892\n",
      "Reconstruction: 0.051352, Regularization: 0.001106, Discriminator: 0.021601; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 134 Average loss: 0.0845\n",
      "tensor(0.5030, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 0.093598\n",
      "Reconstruction: 0.059783, Regularization: 0.001413, Discriminator: 0.021566; Generator: 0.010836,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 0.077666\n",
      "Reconstruction: 0.044239, Regularization: 0.000936, Discriminator: 0.021657; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 0.088852\n",
      "Reconstruction: 0.055120, Regularization: 0.001259, Discriminator: 0.021637; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 0.079557\n",
      "Reconstruction: 0.046125, Regularization: 0.000965, Discriminator: 0.021641; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 0.086477\n",
      "Reconstruction: 0.052859, Regularization: 0.001177, Discriminator: 0.021614; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 0.086721\n",
      "Reconstruction: 0.053094, Regularization: 0.001160, Discriminator: 0.021637; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 0.076386\n",
      "Reconstruction: 0.043091, Regularization: 0.000878, Discriminator: 0.021581; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 0.086446\n",
      "Reconstruction: 0.052763, Regularization: 0.001196, Discriminator: 0.021648; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 135 Average loss: 0.0845\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 0.080884\n",
      "Reconstruction: 0.047366, Regularization: 0.001034, Discriminator: 0.021657; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 0.086546\n",
      "Reconstruction: 0.052841, Regularization: 0.001164, Discriminator: 0.021708; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5042, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 0.089644\n",
      "Reconstruction: 0.055981, Regularization: 0.001299, Discriminator: 0.021523; Generator: 0.010841,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 0.086661\n",
      "Reconstruction: 0.052984, Regularization: 0.001193, Discriminator: 0.021643; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 0.076927\n",
      "Reconstruction: 0.043572, Regularization: 0.000911, Discriminator: 0.021607; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 0.087755\n",
      "Reconstruction: 0.054063, Regularization: 0.001223, Discriminator: 0.021640; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 0.076136\n",
      "Reconstruction: 0.042717, Regularization: 0.000885, Discriminator: 0.021701; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 0.097548\n",
      "Reconstruction: 0.063574, Regularization: 0.001514, Discriminator: 0.021628; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 136 Average loss: 0.0846\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 0.082144\n",
      "Reconstruction: 0.048593, Regularization: 0.001043, Discriminator: 0.021674; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 0.090861\n",
      "Reconstruction: 0.057089, Regularization: 0.001321, Discriminator: 0.021617; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 0.090939\n",
      "Reconstruction: 0.057165, Regularization: 0.001322, Discriminator: 0.021623; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 0.080339\n",
      "Reconstruction: 0.046859, Regularization: 0.000985, Discriminator: 0.021659; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 0.095682\n",
      "Reconstruction: 0.061666, Regularization: 0.001508, Discriminator: 0.021673; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 0.088079\n",
      "Reconstruction: 0.054361, Regularization: 0.001249, Discriminator: 0.021631; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 0.071338\n",
      "Reconstruction: 0.038081, Regularization: 0.000772, Discriminator: 0.021649; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 0.090176\n",
      "Reconstruction: 0.056397, Regularization: 0.001279, Discriminator: 0.021667; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 137 Average loss: 0.0846\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 0.072132\n",
      "Reconstruction: 0.038882, Regularization: 0.000765, Discriminator: 0.021651; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 0.073472\n",
      "Reconstruction: 0.040145, Regularization: 0.000779, Discriminator: 0.021716; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 0.083411\n",
      "Reconstruction: 0.049864, Regularization: 0.001104, Discriminator: 0.021602; Generator: 0.010840,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 0.082026\n",
      "Reconstruction: 0.048558, Regularization: 0.001018, Discriminator: 0.021610; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 0.094807\n",
      "Reconstruction: 0.060881, Regularization: 0.001397, Discriminator: 0.021692; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 0.068581\n",
      "Reconstruction: 0.035399, Regularization: 0.000669, Discriminator: 0.021678; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 0.086895\n",
      "Reconstruction: 0.053157, Regularization: 0.001222, Discriminator: 0.021687; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 0.092542\n",
      "Reconstruction: 0.058759, Regularization: 0.001348, Discriminator: 0.021603; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 138 Average loss: 0.0846\n",
      "tensor(0.4979, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 0.079434\n",
      "Reconstruction: 0.045888, Regularization: 0.000985, Discriminator: 0.021726; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 0.084490\n",
      "Reconstruction: 0.050890, Regularization: 0.001134, Discriminator: 0.021634; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 0.094187\n",
      "Reconstruction: 0.060298, Regularization: 0.001417, Discriminator: 0.021639; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 0.082568\n",
      "Reconstruction: 0.049033, Regularization: 0.001072, Discriminator: 0.021632; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 0.080881\n",
      "Reconstruction: 0.047399, Regularization: 0.001008, Discriminator: 0.021645; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 0.082191\n",
      "Reconstruction: 0.048715, Regularization: 0.001030, Discriminator: 0.021609; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 0.082311\n",
      "Reconstruction: 0.048739, Regularization: 0.001085, Discriminator: 0.021657; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 0.076417\n",
      "Reconstruction: 0.042981, Regularization: 0.000890, Discriminator: 0.021714; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "====> Epoch: 139 Average loss: 0.0845\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 0.078645\n",
      "Reconstruction: 0.045207, Regularization: 0.000958, Discriminator: 0.021642; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4970, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 0.076746\n",
      "Reconstruction: 0.043265, Regularization: 0.000893, Discriminator: 0.021756; Generator: 0.010833,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 0.082561\n",
      "Reconstruction: 0.049015, Regularization: 0.001035, Discriminator: 0.021678; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 0.086273\n",
      "Reconstruction: 0.052586, Regularization: 0.001214, Discriminator: 0.021644; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 0.092252\n",
      "Reconstruction: 0.058424, Regularization: 0.001349, Discriminator: 0.021646; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 0.081646\n",
      "Reconstruction: 0.048174, Regularization: 0.001034, Discriminator: 0.021603; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 0.082565\n",
      "Reconstruction: 0.048959, Regularization: 0.001072, Discriminator: 0.021701; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 0.075015\n",
      "Reconstruction: 0.041709, Regularization: 0.000860, Discriminator: 0.021613; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 140 Average loss: 0.0845\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 0.082443\n",
      "Reconstruction: 0.048886, Regularization: 0.001063, Discriminator: 0.021666; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 0.084829\n",
      "Reconstruction: 0.051149, Regularization: 0.001152, Discriminator: 0.021698; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 0.080907\n",
      "Reconstruction: 0.047421, Regularization: 0.001039, Discriminator: 0.021612; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 0.083160\n",
      "Reconstruction: 0.049597, Regularization: 0.001109, Discriminator: 0.021621; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 0.081996\n",
      "Reconstruction: 0.048438, Regularization: 0.001032, Discriminator: 0.021688; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 0.098390\n",
      "Reconstruction: 0.064316, Regularization: 0.001533, Discriminator: 0.021703; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5035, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 0.089460\n",
      "Reconstruction: 0.055801, Regularization: 0.001273, Discriminator: 0.021553; Generator: 0.010833,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 0.079242\n",
      "Reconstruction: 0.045803, Regularization: 0.000978, Discriminator: 0.021631; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 141 Average loss: 0.0846\n",
      "tensor(0.5037, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 0.087616\n",
      "Reconstruction: 0.053936, Regularization: 0.001299, Discriminator: 0.021538; Generator: 0.010843,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 0.078335\n",
      "Reconstruction: 0.044886, Regularization: 0.000941, Discriminator: 0.021673; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 0.081534\n",
      "Reconstruction: 0.048008, Regularization: 0.001014, Discriminator: 0.021672; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 0.086957\n",
      "Reconstruction: 0.053205, Regularization: 0.001231, Discriminator: 0.021688; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 0.083408\n",
      "Reconstruction: 0.049829, Regularization: 0.001061, Discriminator: 0.021677; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 0.086027\n",
      "Reconstruction: 0.052297, Regularization: 0.001215, Discriminator: 0.021679; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 0.091959\n",
      "Reconstruction: 0.058181, Regularization: 0.001317, Discriminator: 0.021628; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 0.073685\n",
      "Reconstruction: 0.040360, Regularization: 0.000816, Discriminator: 0.021676; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 142 Average loss: 0.0846\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 0.084065\n",
      "Reconstruction: 0.050459, Regularization: 0.001170, Discriminator: 0.021602; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 0.079750\n",
      "Reconstruction: 0.046239, Regularization: 0.000966, Discriminator: 0.021713; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 0.098333\n",
      "Reconstruction: 0.064332, Regularization: 0.001571, Discriminator: 0.021597; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 0.087820\n",
      "Reconstruction: 0.054104, Regularization: 0.001241, Discriminator: 0.021642; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 0.084100\n",
      "Reconstruction: 0.050451, Regularization: 0.001115, Discriminator: 0.021697; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 0.083114\n",
      "Reconstruction: 0.049531, Regularization: 0.001112, Discriminator: 0.021637; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 0.088941\n",
      "Reconstruction: 0.055136, Regularization: 0.001323, Discriminator: 0.021643; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 0.083654\n",
      "Reconstruction: 0.050063, Regularization: 0.001109, Discriminator: 0.021646; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 143 Average loss: 0.0846\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 0.088620\n",
      "Reconstruction: 0.054887, Regularization: 0.001267, Discriminator: 0.021636; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 0.094213\n",
      "Reconstruction: 0.060308, Regularization: 0.001449, Discriminator: 0.021616; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 0.087774\n",
      "Reconstruction: 0.053990, Regularization: 0.001293, Discriminator: 0.021655; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 0.085526\n",
      "Reconstruction: 0.051824, Regularization: 0.001183, Discriminator: 0.021683; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 0.073723\n",
      "Reconstruction: 0.040421, Regularization: 0.000819, Discriminator: 0.021651; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 0.092900\n",
      "Reconstruction: 0.059050, Regularization: 0.001410, Discriminator: 0.021609; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 0.088806\n",
      "Reconstruction: 0.055024, Regularization: 0.001280, Discriminator: 0.021670; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 0.085373\n",
      "Reconstruction: 0.051680, Regularization: 0.001190, Discriminator: 0.021665; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 144 Average loss: 0.0845\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 0.091451\n",
      "Reconstruction: 0.057511, Regularization: 0.001382, Discriminator: 0.021731; Generator: 0.010826,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 0.091889\n",
      "Reconstruction: 0.057980, Regularization: 0.001370, Discriminator: 0.021707; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 0.087921\n",
      "Reconstruction: 0.054202, Regularization: 0.001236, Discriminator: 0.021648; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 0.078716\n",
      "Reconstruction: 0.045281, Regularization: 0.000960, Discriminator: 0.021641; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 0.077641\n",
      "Reconstruction: 0.044129, Regularization: 0.000973, Discriminator: 0.021708; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 0.083406\n",
      "Reconstruction: 0.049789, Regularization: 0.001138, Discriminator: 0.021640; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 0.097629\n",
      "Reconstruction: 0.063566, Regularization: 0.001517, Discriminator: 0.021712; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 0.090783\n",
      "Reconstruction: 0.056884, Regularization: 0.001361, Discriminator: 0.021704; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 145 Average loss: 0.0846\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 0.093490\n",
      "Reconstruction: 0.059576, Regularization: 0.001440, Discriminator: 0.021639; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 0.096916\n",
      "Reconstruction: 0.062837, Regularization: 0.001552, Discriminator: 0.021696; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 0.074555\n",
      "Reconstruction: 0.041252, Regularization: 0.000803, Discriminator: 0.021669; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 0.083190\n",
      "Reconstruction: 0.049549, Regularization: 0.001137, Discriminator: 0.021659; Generator: 0.010845,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 0.076651\n",
      "Reconstruction: 0.043259, Regularization: 0.000894, Discriminator: 0.021663; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 0.093427\n",
      "Reconstruction: 0.059567, Regularization: 0.001390, Discriminator: 0.021636; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 0.072712\n",
      "Reconstruction: 0.039462, Regularization: 0.000759, Discriminator: 0.021663; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 0.091142\n",
      "Reconstruction: 0.057300, Regularization: 0.001352, Discriminator: 0.021659; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 146 Average loss: 0.0845\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 0.079117\n",
      "Reconstruction: 0.045714, Regularization: 0.000952, Discriminator: 0.021618; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 0.091348\n",
      "Reconstruction: 0.057445, Regularization: 0.001373, Discriminator: 0.021693; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 0.077069\n",
      "Reconstruction: 0.043713, Regularization: 0.000937, Discriminator: 0.021584; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 0.092439\n",
      "Reconstruction: 0.058578, Regularization: 0.001384, Discriminator: 0.021645; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 0.096136\n",
      "Reconstruction: 0.062174, Regularization: 0.001463, Discriminator: 0.021663; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4972, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 0.082462\n",
      "Reconstruction: 0.048819, Regularization: 0.001060, Discriminator: 0.021745; Generator: 0.010838,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "tensor(0.4973, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 0.082501\n",
      "Reconstruction: 0.048826, Regularization: 0.001096, Discriminator: 0.021742; Generator: 0.010837,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 0.072172\n",
      "Reconstruction: 0.038865, Regularization: 0.000788, Discriminator: 0.021689; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 147 Average loss: 0.0846\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 0.087592\n",
      "Reconstruction: 0.053810, Regularization: 0.001237, Discriminator: 0.021713; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5023, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 0.089041\n",
      "Reconstruction: 0.055339, Regularization: 0.001279, Discriminator: 0.021594; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 0.080422\n",
      "Reconstruction: 0.046947, Regularization: 0.000986, Discriminator: 0.021651; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 0.083944\n",
      "Reconstruction: 0.050297, Regularization: 0.001116, Discriminator: 0.021701; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 0.081208\n",
      "Reconstruction: 0.047730, Regularization: 0.001016, Discriminator: 0.021624; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 0.083592\n",
      "Reconstruction: 0.049968, Regularization: 0.001138, Discriminator: 0.021649; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 0.078820\n",
      "Reconstruction: 0.045321, Regularization: 0.000965, Discriminator: 0.021699; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 0.075531\n",
      "Reconstruction: 0.042185, Regularization: 0.000868, Discriminator: 0.021642; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 148 Average loss: 0.0846\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 0.087323\n",
      "Reconstruction: 0.053692, Regularization: 0.001185, Discriminator: 0.021614; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 0.081974\n",
      "Reconstruction: 0.048483, Regularization: 0.001062, Discriminator: 0.021592; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 0.081335\n",
      "Reconstruction: 0.047826, Regularization: 0.001035, Discriminator: 0.021643; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 0.078385\n",
      "Reconstruction: 0.044952, Regularization: 0.000938, Discriminator: 0.021662; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 0.084478\n",
      "Reconstruction: 0.050827, Regularization: 0.001157, Discriminator: 0.021659; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 0.076938\n",
      "Reconstruction: 0.043529, Regularization: 0.000906, Discriminator: 0.021664; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 0.077752\n",
      "Reconstruction: 0.044343, Regularization: 0.000924, Discriminator: 0.021653; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 0.095126\n",
      "Reconstruction: 0.061130, Regularization: 0.001462, Discriminator: 0.021702; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 149 Average loss: 0.0846\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 0.082312\n",
      "Reconstruction: 0.048751, Regularization: 0.001065, Discriminator: 0.021656; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 0.081600\n",
      "Reconstruction: 0.048077, Regularization: 0.001056, Discriminator: 0.021632; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 0.088005\n",
      "Reconstruction: 0.054245, Regularization: 0.001241, Discriminator: 0.021694; Generator: 0.010825,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4975, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 0.080394\n",
      "Reconstruction: 0.046850, Regularization: 0.000971, Discriminator: 0.021740; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 0.092413\n",
      "Reconstruction: 0.058565, Regularization: 0.001382, Discriminator: 0.021634; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 0.082516\n",
      "Reconstruction: 0.048953, Regularization: 0.001100, Discriminator: 0.021630; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 0.083353\n",
      "Reconstruction: 0.049740, Regularization: 0.001110, Discriminator: 0.021667; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 0.086362\n",
      "Reconstruction: 0.052645, Regularization: 0.001225, Discriminator: 0.021660; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 150 Average loss: 0.0845\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 0.083532\n",
      "Reconstruction: 0.049876, Regularization: 0.001108, Discriminator: 0.021711; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 0.084694\n",
      "Reconstruction: 0.051090, Regularization: 0.001115, Discriminator: 0.021652; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 0.084550\n",
      "Reconstruction: 0.050910, Regularization: 0.001180, Discriminator: 0.021625; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 0.081970\n",
      "Reconstruction: 0.048383, Regularization: 0.001060, Discriminator: 0.021697; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 0.087093\n",
      "Reconstruction: 0.053452, Regularization: 0.001205, Discriminator: 0.021603; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 0.082886\n",
      "Reconstruction: 0.049357, Regularization: 0.001078, Discriminator: 0.021615; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 0.081461\n",
      "Reconstruction: 0.047907, Regularization: 0.001054, Discriminator: 0.021661; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 0.085220\n",
      "Reconstruction: 0.051525, Regularization: 0.001182, Discriminator: 0.021679; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 151 Average loss: 0.0846\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 0.090049\n",
      "Reconstruction: 0.056321, Regularization: 0.001284, Discriminator: 0.021611; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 0.079415\n",
      "Reconstruction: 0.045863, Regularization: 0.000996, Discriminator: 0.021719; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 0.081209\n",
      "Reconstruction: 0.047716, Regularization: 0.001059, Discriminator: 0.021600; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 0.088515\n",
      "Reconstruction: 0.054781, Regularization: 0.001265, Discriminator: 0.021636; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 0.089790\n",
      "Reconstruction: 0.056003, Regularization: 0.001265, Discriminator: 0.021692; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 0.076135\n",
      "Reconstruction: 0.042735, Regularization: 0.000889, Discriminator: 0.021677; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 0.090103\n",
      "Reconstruction: 0.056326, Regularization: 0.001307, Discriminator: 0.021634; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 0.081055\n",
      "Reconstruction: 0.047535, Regularization: 0.001056, Discriminator: 0.021636; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 152 Average loss: 0.0845\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 0.082809\n",
      "Reconstruction: 0.049258, Regularization: 0.001107, Discriminator: 0.021612; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 0.083393\n",
      "Reconstruction: 0.049839, Regularization: 0.001117, Discriminator: 0.021610; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 0.078699\n",
      "Reconstruction: 0.045256, Regularization: 0.000980, Discriminator: 0.021631; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 0.095687\n",
      "Reconstruction: 0.061688, Regularization: 0.001481, Discriminator: 0.021681; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 0.091442\n",
      "Reconstruction: 0.057633, Regularization: 0.001364, Discriminator: 0.021609; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 0.081076\n",
      "Reconstruction: 0.047503, Regularization: 0.001042, Discriminator: 0.021696; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 0.083248\n",
      "Reconstruction: 0.049640, Regularization: 0.001133, Discriminator: 0.021638; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 0.079102\n",
      "Reconstruction: 0.045621, Regularization: 0.000984, Discriminator: 0.021666; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 153 Average loss: 0.0846\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 0.086795\n",
      "Reconstruction: 0.053065, Regularization: 0.001215, Discriminator: 0.021680; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 0.079144\n",
      "Reconstruction: 0.045653, Regularization: 0.000977, Discriminator: 0.021679; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 0.084129\n",
      "Reconstruction: 0.050503, Regularization: 0.001125, Discriminator: 0.021669; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 0.079004\n",
      "Reconstruction: 0.045550, Regularization: 0.000999, Discriminator: 0.021621; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 0.080784\n",
      "Reconstruction: 0.047254, Regularization: 0.001065, Discriminator: 0.021634; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 0.081851\n",
      "Reconstruction: 0.048285, Regularization: 0.001079, Discriminator: 0.021653; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 0.086935\n",
      "Reconstruction: 0.053127, Regularization: 0.001255, Discriminator: 0.021720; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 0.078309\n",
      "Reconstruction: 0.044868, Regularization: 0.000931, Discriminator: 0.021669; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 154 Average loss: 0.0847\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 0.080221\n",
      "Reconstruction: 0.046675, Regularization: 0.001068, Discriminator: 0.021639; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 0.084333\n",
      "Reconstruction: 0.050634, Regularization: 0.001173, Discriminator: 0.021691; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 0.083552\n",
      "Reconstruction: 0.049945, Regularization: 0.001109, Discriminator: 0.021666; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 0.087628\n",
      "Reconstruction: 0.053860, Regularization: 0.001232, Discriminator: 0.021698; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 0.078873\n",
      "Reconstruction: 0.045352, Regularization: 0.001023, Discriminator: 0.021665; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 0.080784\n",
      "Reconstruction: 0.047213, Regularization: 0.001037, Discriminator: 0.021703; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 0.079481\n",
      "Reconstruction: 0.046076, Regularization: 0.000980, Discriminator: 0.021594; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 0.076584\n",
      "Reconstruction: 0.043195, Regularization: 0.000930, Discriminator: 0.021618; Generator: 0.010842,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 155 Average loss: 0.0846\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 0.089090\n",
      "Reconstruction: 0.055294, Regularization: 0.001304, Discriminator: 0.021660; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 0.083983\n",
      "Reconstruction: 0.050393, Regularization: 0.001092, Discriminator: 0.021657; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 0.088518\n",
      "Reconstruction: 0.054688, Regularization: 0.001301, Discriminator: 0.021694; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 0.087301\n",
      "Reconstruction: 0.053496, Regularization: 0.001299, Discriminator: 0.021670; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 0.091275\n",
      "Reconstruction: 0.057372, Regularization: 0.001428, Discriminator: 0.021643; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 0.085166\n",
      "Reconstruction: 0.051506, Regularization: 0.001132, Discriminator: 0.021692; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 0.081578\n",
      "Reconstruction: 0.048028, Regularization: 0.001072, Discriminator: 0.021645; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 0.101501\n",
      "Reconstruction: 0.067368, Regularization: 0.001683, Discriminator: 0.021618; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 156 Average loss: 0.0845\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 0.092858\n",
      "Reconstruction: 0.059012, Regularization: 0.001384, Discriminator: 0.021631; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 0.080149\n",
      "Reconstruction: 0.046638, Regularization: 0.001000, Discriminator: 0.021676; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 0.084533\n",
      "Reconstruction: 0.050882, Regularization: 0.001146, Discriminator: 0.021666; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 0.084711\n",
      "Reconstruction: 0.051052, Regularization: 0.001128, Discriminator: 0.021689; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 0.080447\n",
      "Reconstruction: 0.046895, Regularization: 0.001009, Discriminator: 0.021708; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 0.090208\n",
      "Reconstruction: 0.056368, Regularization: 0.001337, Discriminator: 0.021670; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 0.098716\n",
      "Reconstruction: 0.064525, Regularization: 0.001664, Discriminator: 0.021687; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4974, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 0.082047\n",
      "Reconstruction: 0.048416, Regularization: 0.001057, Discriminator: 0.021743; Generator: 0.010832,\n",
      "D(x): 0.497, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 157 Average loss: 0.0846\n",
      "tensor(0.5023, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 0.084679\n",
      "Reconstruction: 0.051076, Regularization: 0.001180, Discriminator: 0.021586; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 0.077531\n",
      "Reconstruction: 0.044052, Regularization: 0.000986, Discriminator: 0.021658; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4978, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 0.082076\n",
      "Reconstruction: 0.048449, Regularization: 0.001062, Discriminator: 0.021730; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 0.089790\n",
      "Reconstruction: 0.055919, Regularization: 0.001367, Discriminator: 0.021671; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 0.100820\n",
      "Reconstruction: 0.066621, Regularization: 0.001699, Discriminator: 0.021668; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 0.076114\n",
      "Reconstruction: 0.042763, Regularization: 0.000930, Discriminator: 0.021588; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 0.090567\n",
      "Reconstruction: 0.056698, Regularization: 0.001380, Discriminator: 0.021655; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 0.087197\n",
      "Reconstruction: 0.053427, Regularization: 0.001297, Discriminator: 0.021639; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 158 Average loss: 0.0845\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 0.085612\n",
      "Reconstruction: 0.051897, Regularization: 0.001232, Discriminator: 0.021643; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 0.082375\n",
      "Reconstruction: 0.048750, Regularization: 0.001121, Discriminator: 0.021669; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 0.075427\n",
      "Reconstruction: 0.042076, Regularization: 0.000884, Discriminator: 0.021636; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 0.082293\n",
      "Reconstruction: 0.048691, Regularization: 0.001095, Discriminator: 0.021672; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 0.085877\n",
      "Reconstruction: 0.052091, Regularization: 0.001238, Discriminator: 0.021715; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 0.077708\n",
      "Reconstruction: 0.044267, Regularization: 0.000948, Discriminator: 0.021655; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 0.081985\n",
      "Reconstruction: 0.048435, Regularization: 0.001084, Discriminator: 0.021635; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 0.073726\n",
      "Reconstruction: 0.040388, Regularization: 0.000831, Discriminator: 0.021678; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 159 Average loss: 0.0844\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 0.101342\n",
      "Reconstruction: 0.067126, Regularization: 0.001665, Discriminator: 0.021714; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5023, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 0.082309\n",
      "Reconstruction: 0.048808, Regularization: 0.001079, Discriminator: 0.021589; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 0.083296\n",
      "Reconstruction: 0.049660, Regularization: 0.001122, Discriminator: 0.021674; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5020, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 0.089573\n",
      "Reconstruction: 0.055806, Regularization: 0.001334, Discriminator: 0.021599; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 0.073265\n",
      "Reconstruction: 0.039878, Regularization: 0.000863, Discriminator: 0.021692; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 0.085269\n",
      "Reconstruction: 0.051580, Regularization: 0.001184, Discriminator: 0.021671; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 0.090656\n",
      "Reconstruction: 0.056862, Regularization: 0.001301, Discriminator: 0.021650; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 0.089266\n",
      "Reconstruction: 0.055544, Regularization: 0.001284, Discriminator: 0.021609; Generator: 0.010830,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 160 Average loss: 0.0848\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 0.086074\n",
      "Reconstruction: 0.052391, Regularization: 0.001188, Discriminator: 0.021659; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 0.084211\n",
      "Reconstruction: 0.050556, Regularization: 0.001162, Discriminator: 0.021664; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 0.084172\n",
      "Reconstruction: 0.050549, Regularization: 0.001148, Discriminator: 0.021638; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 0.077227\n",
      "Reconstruction: 0.043803, Regularization: 0.000935, Discriminator: 0.021654; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 0.086252\n",
      "Reconstruction: 0.052542, Regularization: 0.001230, Discriminator: 0.021647; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 0.074548\n",
      "Reconstruction: 0.041272, Regularization: 0.000850, Discriminator: 0.021593; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 0.072417\n",
      "Reconstruction: 0.039083, Regularization: 0.000804, Discriminator: 0.021696; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 0.093173\n",
      "Reconstruction: 0.059268, Regularization: 0.001394, Discriminator: 0.021675; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 161 Average loss: 0.0845\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 0.087182\n",
      "Reconstruction: 0.053494, Regularization: 0.001225, Discriminator: 0.021633; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 0.090399\n",
      "Reconstruction: 0.056548, Regularization: 0.001317, Discriminator: 0.021707; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 0.085582\n",
      "Reconstruction: 0.051912, Regularization: 0.001175, Discriminator: 0.021656; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 0.081083\n",
      "Reconstruction: 0.047532, Regularization: 0.001075, Discriminator: 0.021640; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 0.082233\n",
      "Reconstruction: 0.048602, Regularization: 0.001077, Discriminator: 0.021715; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 0.079254\n",
      "Reconstruction: 0.045743, Regularization: 0.000994, Discriminator: 0.021680; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 0.092369\n",
      "Reconstruction: 0.058523, Regularization: 0.001416, Discriminator: 0.021597; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 0.097566\n",
      "Reconstruction: 0.063493, Regularization: 0.001562, Discriminator: 0.021679; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 162 Average loss: 0.0847\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 0.096792\n",
      "Reconstruction: 0.062759, Regularization: 0.001558, Discriminator: 0.021637; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 0.075184\n",
      "Reconstruction: 0.041836, Regularization: 0.000844, Discriminator: 0.021673; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 0.086410\n",
      "Reconstruction: 0.052656, Regularization: 0.001255, Discriminator: 0.021666; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 0.072548\n",
      "Reconstruction: 0.039272, Regularization: 0.000798, Discriminator: 0.021649; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 0.091673\n",
      "Reconstruction: 0.057827, Regularization: 0.001382, Discriminator: 0.021625; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 0.090188\n",
      "Reconstruction: 0.056329, Regularization: 0.001375, Discriminator: 0.021650; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 0.094133\n",
      "Reconstruction: 0.060148, Regularization: 0.001465, Discriminator: 0.021687; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 0.095345\n",
      "Reconstruction: 0.061348, Regularization: 0.001557, Discriminator: 0.021603; Generator: 0.010838,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 163 Average loss: 0.0846\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 0.088732\n",
      "Reconstruction: 0.054919, Regularization: 0.001316, Discriminator: 0.021671; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 0.078668\n",
      "Reconstruction: 0.045189, Regularization: 0.000997, Discriminator: 0.021655; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 0.077872\n",
      "Reconstruction: 0.044446, Regularization: 0.000970, Discriminator: 0.021619; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 0.078479\n",
      "Reconstruction: 0.044979, Regularization: 0.000989, Discriminator: 0.021683; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 0.079586\n",
      "Reconstruction: 0.046063, Regularization: 0.001057, Discriminator: 0.021636; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4978, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 0.089159\n",
      "Reconstruction: 0.055262, Regularization: 0.001335, Discriminator: 0.021725; Generator: 0.010838,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 0.091696\n",
      "Reconstruction: 0.057815, Regularization: 0.001406, Discriminator: 0.021645; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4975, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 0.092329\n",
      "Reconstruction: 0.058273, Regularization: 0.001481, Discriminator: 0.021739; Generator: 0.010836,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "====> Epoch: 164 Average loss: 0.0845\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 0.075857\n",
      "Reconstruction: 0.042411, Regularization: 0.000902, Discriminator: 0.021707; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 0.077024\n",
      "Reconstruction: 0.043602, Regularization: 0.000957, Discriminator: 0.021622; Generator: 0.010843,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4974, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 0.102623\n",
      "Reconstruction: 0.068294, Regularization: 0.001750, Discriminator: 0.021743; Generator: 0.010835,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 0.086844\n",
      "Reconstruction: 0.053045, Regularization: 0.001285, Discriminator: 0.021683; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 0.087037\n",
      "Reconstruction: 0.053236, Regularization: 0.001245, Discriminator: 0.021722; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 0.079463\n",
      "Reconstruction: 0.045917, Regularization: 0.001057, Discriminator: 0.021653; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 0.078937\n",
      "Reconstruction: 0.045474, Regularization: 0.001003, Discriminator: 0.021621; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 0.075767\n",
      "Reconstruction: 0.042312, Regularization: 0.000926, Discriminator: 0.021686; Generator: 0.010843,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 165 Average loss: 0.0846\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 0.069352\n",
      "Reconstruction: 0.036185, Regularization: 0.000709, Discriminator: 0.021621; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 0.071979\n",
      "Reconstruction: 0.038696, Regularization: 0.000793, Discriminator: 0.021656; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 0.094899\n",
      "Reconstruction: 0.060926, Regularization: 0.001484, Discriminator: 0.021652; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 0.083403\n",
      "Reconstruction: 0.049796, Regularization: 0.001143, Discriminator: 0.021625; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 0.091129\n",
      "Reconstruction: 0.057259, Regularization: 0.001394, Discriminator: 0.021643; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 0.083028\n",
      "Reconstruction: 0.049398, Regularization: 0.001129, Discriminator: 0.021671; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 0.075756\n",
      "Reconstruction: 0.042339, Regularization: 0.000898, Discriminator: 0.021688; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 0.102348\n",
      "Reconstruction: 0.068112, Regularization: 0.001711, Discriminator: 0.021692; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 166 Average loss: 0.0846\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 0.084995\n",
      "Reconstruction: 0.051334, Regularization: 0.001182, Discriminator: 0.021643; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 0.081751\n",
      "Reconstruction: 0.048152, Regularization: 0.001112, Discriminator: 0.021647; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 0.082348\n",
      "Reconstruction: 0.048752, Regularization: 0.001116, Discriminator: 0.021640; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 0.084880\n",
      "Reconstruction: 0.051227, Regularization: 0.001162, Discriminator: 0.021655; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 0.086128\n",
      "Reconstruction: 0.052432, Regularization: 0.001185, Discriminator: 0.021679; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 0.087089\n",
      "Reconstruction: 0.053378, Regularization: 0.001257, Discriminator: 0.021618; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 0.091441\n",
      "Reconstruction: 0.057558, Regularization: 0.001383, Discriminator: 0.021666; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 0.076077\n",
      "Reconstruction: 0.042674, Regularization: 0.000924, Discriminator: 0.021641; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 167 Average loss: 0.0846\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 0.082047\n",
      "Reconstruction: 0.048509, Regularization: 0.001077, Discriminator: 0.021626; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 0.084854\n",
      "Reconstruction: 0.051148, Regularization: 0.001203, Discriminator: 0.021665; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 0.080609\n",
      "Reconstruction: 0.047126, Regularization: 0.001034, Discriminator: 0.021612; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 0.077564\n",
      "Reconstruction: 0.044038, Regularization: 0.000996, Discriminator: 0.021695; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 0.091588\n",
      "Reconstruction: 0.057707, Regularization: 0.001416, Discriminator: 0.021633; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 0.080700\n",
      "Reconstruction: 0.047129, Regularization: 0.001066, Discriminator: 0.021672; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 0.080530\n",
      "Reconstruction: 0.046969, Regularization: 0.001046, Discriminator: 0.021681; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 0.093716\n",
      "Reconstruction: 0.059776, Regularization: 0.001430, Discriminator: 0.021676; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 168 Average loss: 0.0845\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 0.078630\n",
      "Reconstruction: 0.045127, Regularization: 0.000978, Discriminator: 0.021691; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 0.089511\n",
      "Reconstruction: 0.055650, Regularization: 0.001323, Discriminator: 0.021702; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 0.085512\n",
      "Reconstruction: 0.051864, Regularization: 0.001177, Discriminator: 0.021636; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 0.084641\n",
      "Reconstruction: 0.050993, Regularization: 0.001160, Discriminator: 0.021659; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 0.084965\n",
      "Reconstruction: 0.051313, Regularization: 0.001166, Discriminator: 0.021647; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 0.079118\n",
      "Reconstruction: 0.045600, Regularization: 0.000976, Discriminator: 0.021710; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 0.089575\n",
      "Reconstruction: 0.055801, Regularization: 0.001296, Discriminator: 0.021647; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 0.082112\n",
      "Reconstruction: 0.048591, Regularization: 0.001096, Discriminator: 0.021597; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 169 Average loss: 0.0845\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 0.082401\n",
      "Reconstruction: 0.048858, Regularization: 0.001077, Discriminator: 0.021637; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 0.081922\n",
      "Reconstruction: 0.048378, Regularization: 0.001056, Discriminator: 0.021657; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 0.095172\n",
      "Reconstruction: 0.061218, Regularization: 0.001421, Discriminator: 0.021697; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 0.094780\n",
      "Reconstruction: 0.060884, Regularization: 0.001447, Discriminator: 0.021607; Generator: 0.010842,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 0.086824\n",
      "Reconstruction: 0.053132, Regularization: 0.001184, Discriminator: 0.021677; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 0.088637\n",
      "Reconstruction: 0.054813, Regularization: 0.001291, Discriminator: 0.021698; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 0.084669\n",
      "Reconstruction: 0.050991, Regularization: 0.001163, Discriminator: 0.021687; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5040, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 0.094111\n",
      "Reconstruction: 0.060347, Regularization: 0.001394, Discriminator: 0.021536; Generator: 0.010833,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "====> Epoch: 170 Average loss: 0.0846\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 0.066136\n",
      "Reconstruction: 0.033039, Regularization: 0.000603, Discriminator: 0.021658; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 0.084125\n",
      "Reconstruction: 0.050474, Regularization: 0.001162, Discriminator: 0.021655; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 0.095762\n",
      "Reconstruction: 0.061739, Regularization: 0.001477, Discriminator: 0.021711; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 0.079736\n",
      "Reconstruction: 0.046251, Regularization: 0.001020, Discriminator: 0.021633; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 0.081547\n",
      "Reconstruction: 0.048055, Regularization: 0.001073, Discriminator: 0.021584; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 0.086591\n",
      "Reconstruction: 0.052938, Regularization: 0.001226, Discriminator: 0.021591; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 0.087291\n",
      "Reconstruction: 0.053596, Regularization: 0.001212, Discriminator: 0.021645; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 0.083599\n",
      "Reconstruction: 0.050046, Regularization: 0.001114, Discriminator: 0.021605; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 171 Average loss: 0.0846\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 0.087210\n",
      "Reconstruction: 0.053475, Regularization: 0.001280, Discriminator: 0.021625; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 0.081807\n",
      "Reconstruction: 0.048229, Regularization: 0.001050, Discriminator: 0.021694; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 0.085965\n",
      "Reconstruction: 0.052293, Regularization: 0.001173, Discriminator: 0.021668; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 0.093781\n",
      "Reconstruction: 0.059836, Regularization: 0.001423, Discriminator: 0.021683; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 0.087976\n",
      "Reconstruction: 0.054233, Regularization: 0.001238, Discriminator: 0.021675; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 0.089146\n",
      "Reconstruction: 0.055383, Regularization: 0.001280, Discriminator: 0.021644; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 0.077689\n",
      "Reconstruction: 0.044233, Regularization: 0.000962, Discriminator: 0.021662; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 0.081935\n",
      "Reconstruction: 0.048324, Regularization: 0.001055, Discriminator: 0.021724; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "====> Epoch: 172 Average loss: 0.0847\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 0.081885\n",
      "Reconstruction: 0.048298, Regularization: 0.001067, Discriminator: 0.021690; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 0.091602\n",
      "Reconstruction: 0.057645, Regularization: 0.001423, Discriminator: 0.021703; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 0.077947\n",
      "Reconstruction: 0.044554, Regularization: 0.000956, Discriminator: 0.021603; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 0.080030\n",
      "Reconstruction: 0.046539, Regularization: 0.001051, Discriminator: 0.021605; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 0.083292\n",
      "Reconstruction: 0.049776, Regularization: 0.001135, Discriminator: 0.021544; Generator: 0.010837,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 0.076539\n",
      "Reconstruction: 0.043191, Regularization: 0.000886, Discriminator: 0.021635; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4974, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 0.085409\n",
      "Reconstruction: 0.051641, Regularization: 0.001190, Discriminator: 0.021749; Generator: 0.010828,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 0.072527\n",
      "Reconstruction: 0.039232, Regularization: 0.000795, Discriminator: 0.021664; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 173 Average loss: 0.0846\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 0.093908\n",
      "Reconstruction: 0.059930, Regularization: 0.001444, Discriminator: 0.021701; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 0.079390\n",
      "Reconstruction: 0.045947, Regularization: 0.000951, Discriminator: 0.021659; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 0.081897\n",
      "Reconstruction: 0.048355, Regularization: 0.001095, Discriminator: 0.021619; Generator: 0.010827,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 0.081919\n",
      "Reconstruction: 0.048335, Regularization: 0.001083, Discriminator: 0.021660; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 0.080702\n",
      "Reconstruction: 0.047201, Regularization: 0.001017, Discriminator: 0.021654; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 0.080677\n",
      "Reconstruction: 0.047136, Regularization: 0.001014, Discriminator: 0.021698; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4979, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 0.085754\n",
      "Reconstruction: 0.051952, Regularization: 0.001241, Discriminator: 0.021722; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 0.084361\n",
      "Reconstruction: 0.050720, Regularization: 0.001200, Discriminator: 0.021605; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 174 Average loss: 0.0845\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 0.081833\n",
      "Reconstruction: 0.048216, Regularization: 0.001094, Discriminator: 0.021691; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 0.089407\n",
      "Reconstruction: 0.055563, Regularization: 0.001348, Discriminator: 0.021656; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 0.105173\n",
      "Reconstruction: 0.070850, Regularization: 0.001819, Discriminator: 0.021667; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 0.091785\n",
      "Reconstruction: 0.057935, Regularization: 0.001404, Discriminator: 0.021611; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4978, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 0.090235\n",
      "Reconstruction: 0.056302, Regularization: 0.001368, Discriminator: 0.021732; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 0.069996\n",
      "Reconstruction: 0.036802, Regularization: 0.000693, Discriminator: 0.021671; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 0.084195\n",
      "Reconstruction: 0.050491, Regularization: 0.001153, Discriminator: 0.021720; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 0.085573\n",
      "Reconstruction: 0.051853, Regularization: 0.001215, Discriminator: 0.021672; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 175 Average loss: 0.0845\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 0.070541\n",
      "Reconstruction: 0.037330, Regularization: 0.000746, Discriminator: 0.021627; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 0.090488\n",
      "Reconstruction: 0.056632, Regularization: 0.001334, Discriminator: 0.021691; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 0.080283\n",
      "Reconstruction: 0.046727, Regularization: 0.001058, Discriminator: 0.021668; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 0.103251\n",
      "Reconstruction: 0.069133, Regularization: 0.001691, Discriminator: 0.021592; Generator: 0.010835,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 0.082276\n",
      "Reconstruction: 0.048708, Regularization: 0.001093, Discriminator: 0.021640; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 0.081132\n",
      "Reconstruction: 0.047521, Regularization: 0.001061, Discriminator: 0.021709; Generator: 0.010841,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 0.084595\n",
      "Reconstruction: 0.050990, Regularization: 0.001132, Discriminator: 0.021634; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5030, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 0.088868\n",
      "Reconstruction: 0.055168, Regularization: 0.001298, Discriminator: 0.021568; Generator: 0.010833,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "====> Epoch: 176 Average loss: 0.0847\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 0.091472\n",
      "Reconstruction: 0.057654, Regularization: 0.001309, Discriminator: 0.021673; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 0.079372\n",
      "Reconstruction: 0.045915, Regularization: 0.001001, Discriminator: 0.021622; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 0.095650\n",
      "Reconstruction: 0.061660, Regularization: 0.001462, Discriminator: 0.021692; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 0.087266\n",
      "Reconstruction: 0.053618, Regularization: 0.001181, Discriminator: 0.021631; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 0.072219\n",
      "Reconstruction: 0.038942, Regularization: 0.000780, Discriminator: 0.021664; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 0.080235\n",
      "Reconstruction: 0.046780, Regularization: 0.000993, Discriminator: 0.021629; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 0.088541\n",
      "Reconstruction: 0.054778, Regularization: 0.001266, Discriminator: 0.021665; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 0.081725\n",
      "Reconstruction: 0.048210, Regularization: 0.001028, Discriminator: 0.021651; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 177 Average loss: 0.0846\n",
      "tensor(0.4979, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 0.069631\n",
      "Reconstruction: 0.036403, Regularization: 0.000670, Discriminator: 0.021725; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 0.105754\n",
      "Reconstruction: 0.071497, Regularization: 0.001702, Discriminator: 0.021723; Generator: 0.010831,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 0.077728\n",
      "Reconstruction: 0.044357, Regularization: 0.000873, Discriminator: 0.021663; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 0.080073\n",
      "Reconstruction: 0.046663, Regularization: 0.000942, Discriminator: 0.021631; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 0.090048\n",
      "Reconstruction: 0.056286, Regularization: 0.001276, Discriminator: 0.021650; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 0.088915\n",
      "Reconstruction: 0.055220, Regularization: 0.001213, Discriminator: 0.021650; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 0.080053\n",
      "Reconstruction: 0.046669, Regularization: 0.000956, Discriminator: 0.021591; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 0.090086\n",
      "Reconstruction: 0.056383, Regularization: 0.001242, Discriminator: 0.021624; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 178 Average loss: 0.0846\n",
      "tensor(0.5025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 0.092638\n",
      "Reconstruction: 0.058864, Regularization: 0.001356, Discriminator: 0.021587; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 0.079200\n",
      "Reconstruction: 0.045843, Regularization: 0.000938, Discriminator: 0.021585; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 0.078209\n",
      "Reconstruction: 0.044792, Regularization: 0.000917, Discriminator: 0.021667; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 0.080611\n",
      "Reconstruction: 0.047182, Regularization: 0.000969, Discriminator: 0.021629; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 0.084504\n",
      "Reconstruction: 0.050958, Regularization: 0.001086, Discriminator: 0.021627; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 0.075502\n",
      "Reconstruction: 0.042157, Regularization: 0.000843, Discriminator: 0.021667; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 0.078031\n",
      "Reconstruction: 0.044585, Regularization: 0.000902, Discriminator: 0.021714; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 0.083547\n",
      "Reconstruction: 0.049979, Regularization: 0.001078, Discriminator: 0.021657; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 179 Average loss: 0.0846\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 0.079648\n",
      "Reconstruction: 0.046195, Regularization: 0.000949, Discriminator: 0.021671; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 0.078804\n",
      "Reconstruction: 0.045329, Regularization: 0.000935, Discriminator: 0.021712; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 0.081311\n",
      "Reconstruction: 0.047832, Regularization: 0.001010, Discriminator: 0.021631; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 0.096825\n",
      "Reconstruction: 0.062853, Regularization: 0.001495, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 0.085373\n",
      "Reconstruction: 0.051762, Regularization: 0.001143, Discriminator: 0.021636; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 0.081803\n",
      "Reconstruction: 0.048311, Regularization: 0.001041, Discriminator: 0.021621; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 0.086234\n",
      "Reconstruction: 0.052612, Regularization: 0.001153, Discriminator: 0.021642; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 0.089081\n",
      "Reconstruction: 0.055270, Regularization: 0.001258, Discriminator: 0.021720; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "====> Epoch: 180 Average loss: 0.0845\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 0.088317\n",
      "Reconstruction: 0.054594, Regularization: 0.001194, Discriminator: 0.021697; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 0.084701\n",
      "Reconstruction: 0.051084, Regularization: 0.001114, Discriminator: 0.021667; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4974, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 0.087877\n",
      "Reconstruction: 0.054065, Regularization: 0.001233, Discriminator: 0.021735; Generator: 0.010843,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 0.087349\n",
      "Reconstruction: 0.053671, Regularization: 0.001205, Discriminator: 0.021640; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 0.086392\n",
      "Reconstruction: 0.052680, Regularization: 0.001190, Discriminator: 0.021687; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 0.091791\n",
      "Reconstruction: 0.058058, Regularization: 0.001298, Discriminator: 0.021601; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5028, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 0.087501\n",
      "Reconstruction: 0.053838, Regularization: 0.001256, Discriminator: 0.021574; Generator: 0.010834,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 0.077700\n",
      "Reconstruction: 0.044298, Regularization: 0.000920, Discriminator: 0.021648; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 181 Average loss: 0.0846\n",
      "tensor(0.4974, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 0.098528\n",
      "Reconstruction: 0.064377, Regularization: 0.001574, Discriminator: 0.021746; Generator: 0.010831,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 0.088160\n",
      "Reconstruction: 0.054488, Regularization: 0.001177, Discriminator: 0.021662; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 0.079311\n",
      "Reconstruction: 0.045869, Regularization: 0.000951, Discriminator: 0.021659; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 0.091081\n",
      "Reconstruction: 0.057328, Regularization: 0.001275, Discriminator: 0.021649; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 0.085699\n",
      "Reconstruction: 0.052044, Regularization: 0.001139, Discriminator: 0.021682; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 0.087456\n",
      "Reconstruction: 0.053804, Regularization: 0.001180, Discriminator: 0.021637; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 0.076657\n",
      "Reconstruction: 0.043342, Regularization: 0.000855, Discriminator: 0.021632; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 0.090912\n",
      "Reconstruction: 0.057134, Regularization: 0.001296, Discriminator: 0.021644; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 182 Average loss: 0.0847\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 0.093231\n",
      "Reconstruction: 0.059399, Regularization: 0.001317, Discriminator: 0.021681; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 0.076483\n",
      "Reconstruction: 0.043106, Regularization: 0.000851, Discriminator: 0.021691; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 0.088001\n",
      "Reconstruction: 0.054311, Regularization: 0.001177, Discriminator: 0.021677; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5035, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 0.091898\n",
      "Reconstruction: 0.058211, Regularization: 0.001301, Discriminator: 0.021550; Generator: 0.010836,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "tensor(0.4978, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 0.084180\n",
      "Reconstruction: 0.050528, Regularization: 0.001087, Discriminator: 0.021730; Generator: 0.010835,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 0.091198\n",
      "Reconstruction: 0.057517, Regularization: 0.001264, Discriminator: 0.021579; Generator: 0.010838,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 0.083134\n",
      "Reconstruction: 0.049625, Regularization: 0.001016, Discriminator: 0.021655; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 0.084881\n",
      "Reconstruction: 0.051312, Regularization: 0.001064, Discriminator: 0.021669; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 183 Average loss: 0.0846\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 0.083611\n",
      "Reconstruction: 0.050116, Regularization: 0.001012, Discriminator: 0.021652; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 0.076288\n",
      "Reconstruction: 0.042985, Regularization: 0.000843, Discriminator: 0.021627; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 0.097122\n",
      "Reconstruction: 0.063258, Regularization: 0.001416, Discriminator: 0.021615; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 0.084658\n",
      "Reconstruction: 0.051046, Regularization: 0.001075, Discriminator: 0.021696; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 0.086451\n",
      "Reconstruction: 0.052870, Regularization: 0.001094, Discriminator: 0.021652; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 0.095583\n",
      "Reconstruction: 0.061710, Regularization: 0.001393, Discriminator: 0.021644; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 0.090764\n",
      "Reconstruction: 0.057088, Regularization: 0.001246, Discriminator: 0.021594; Generator: 0.010836,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 0.078842\n",
      "Reconstruction: 0.045393, Regularization: 0.000929, Discriminator: 0.021689; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 184 Average loss: 0.0847\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 0.083458\n",
      "Reconstruction: 0.049922, Regularization: 0.001054, Discriminator: 0.021653; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 0.076546\n",
      "Reconstruction: 0.043273, Regularization: 0.000847, Discriminator: 0.021585; Generator: 0.010841,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 0.083215\n",
      "Reconstruction: 0.049699, Regularization: 0.001035, Discriminator: 0.021638; Generator: 0.010844,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 0.084573\n",
      "Reconstruction: 0.051046, Regularization: 0.001070, Discriminator: 0.021615; Generator: 0.010842,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 0.093893\n",
      "Reconstruction: 0.060070, Regularization: 0.001379, Discriminator: 0.021625; Generator: 0.010819,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 0.080785\n",
      "Reconstruction: 0.047308, Regularization: 0.000989, Discriminator: 0.021654; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 0.093764\n",
      "Reconstruction: 0.059899, Regularization: 0.001358, Discriminator: 0.021676; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 0.093746\n",
      "Reconstruction: 0.059854, Regularization: 0.001393, Discriminator: 0.021665; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 185 Average loss: 0.0846\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 0.080539\n",
      "Reconstruction: 0.047079, Regularization: 0.000977, Discriminator: 0.021657; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 0.086051\n",
      "Reconstruction: 0.052443, Regularization: 0.001143, Discriminator: 0.021633; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 0.086858\n",
      "Reconstruction: 0.053203, Regularization: 0.001166, Discriminator: 0.021655; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 0.091370\n",
      "Reconstruction: 0.057615, Regularization: 0.001315, Discriminator: 0.021603; Generator: 0.010837,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 0.079578\n",
      "Reconstruction: 0.046160, Regularization: 0.000974, Discriminator: 0.021612; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 0.092379\n",
      "Reconstruction: 0.058509, Regularization: 0.001314, Discriminator: 0.021725; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 0.077171\n",
      "Reconstruction: 0.043814, Regularization: 0.000899, Discriminator: 0.021624; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 0.086542\n",
      "Reconstruction: 0.052908, Regularization: 0.001156, Discriminator: 0.021645; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 186 Average loss: 0.0845\n",
      "tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 0.080411\n",
      "Reconstruction: 0.046873, Regularization: 0.000984, Discriminator: 0.021719; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 0.090938\n",
      "Reconstruction: 0.057154, Regularization: 0.001307, Discriminator: 0.021649; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 0.083811\n",
      "Reconstruction: 0.050294, Regularization: 0.001096, Discriminator: 0.021590; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 0.085260\n",
      "Reconstruction: 0.051593, Regularization: 0.001147, Discriminator: 0.021687; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 0.080305\n",
      "Reconstruction: 0.046843, Regularization: 0.001015, Discriminator: 0.021615; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 0.084233\n",
      "Reconstruction: 0.050610, Regularization: 0.001096, Discriminator: 0.021688; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 0.101523\n",
      "Reconstruction: 0.067410, Regularization: 0.001638, Discriminator: 0.021644; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 0.088589\n",
      "Reconstruction: 0.054846, Regularization: 0.001223, Discriminator: 0.021687; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "====> Epoch: 187 Average loss: 0.0847\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 0.090873\n",
      "Reconstruction: 0.057079, Regularization: 0.001326, Discriminator: 0.021635; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 0.079899\n",
      "Reconstruction: 0.046454, Regularization: 0.000947, Discriminator: 0.021661; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 0.087053\n",
      "Reconstruction: 0.053356, Regularization: 0.001205, Discriminator: 0.021657; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 0.072898\n",
      "Reconstruction: 0.039620, Regularization: 0.000771, Discriminator: 0.021671; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 0.074682\n",
      "Reconstruction: 0.041323, Regularization: 0.000834, Discriminator: 0.021691; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 0.069213\n",
      "Reconstruction: 0.036060, Regularization: 0.000663, Discriminator: 0.021658; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 0.083572\n",
      "Reconstruction: 0.049976, Regularization: 0.001095, Discriminator: 0.021666; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 0.088065\n",
      "Reconstruction: 0.054443, Regularization: 0.001194, Discriminator: 0.021599; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 188 Average loss: 0.0846\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 0.079473\n",
      "Reconstruction: 0.046056, Regularization: 0.000965, Discriminator: 0.021615; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 0.090625\n",
      "Reconstruction: 0.056819, Regularization: 0.001328, Discriminator: 0.021646; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 0.086901\n",
      "Reconstruction: 0.053203, Regularization: 0.001232, Discriminator: 0.021632; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 0.082590\n",
      "Reconstruction: 0.049087, Regularization: 0.001036, Discriminator: 0.021631; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 0.074619\n",
      "Reconstruction: 0.041308, Regularization: 0.000837, Discriminator: 0.021639; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 0.091821\n",
      "Reconstruction: 0.058000, Regularization: 0.001315, Discriminator: 0.021666; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 0.078913\n",
      "Reconstruction: 0.045376, Regularization: 0.000980, Discriminator: 0.021725; Generator: 0.010832,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 0.087234\n",
      "Reconstruction: 0.053489, Regularization: 0.001191, Discriminator: 0.021720; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "====> Epoch: 189 Average loss: 0.0847\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 0.086055\n",
      "Reconstruction: 0.052363, Regularization: 0.001179, Discriminator: 0.021683; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 0.098175\n",
      "Reconstruction: 0.064159, Regularization: 0.001516, Discriminator: 0.021669; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 0.079523\n",
      "Reconstruction: 0.046028, Regularization: 0.000967, Discriminator: 0.021689; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 0.084815\n",
      "Reconstruction: 0.051212, Regularization: 0.001125, Discriminator: 0.021650; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4969, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 0.090926\n",
      "Reconstruction: 0.057011, Regularization: 0.001323, Discriminator: 0.021756; Generator: 0.010836,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 0.068850\n",
      "Reconstruction: 0.035644, Regularization: 0.000675, Discriminator: 0.021702; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 0.093709\n",
      "Reconstruction: 0.059753, Regularization: 0.001430, Discriminator: 0.021690; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 0.073864\n",
      "Reconstruction: 0.040576, Regularization: 0.000813, Discriminator: 0.021648; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 190 Average loss: 0.0846\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 0.086456\n",
      "Reconstruction: 0.052740, Regularization: 0.001237, Discriminator: 0.021647; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 0.088419\n",
      "Reconstruction: 0.054649, Regularization: 0.001293, Discriminator: 0.021646; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 0.092346\n",
      "Reconstruction: 0.058450, Regularization: 0.001389, Discriminator: 0.021672; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 0.078271\n",
      "Reconstruction: 0.044791, Regularization: 0.000987, Discriminator: 0.021659; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 0.081706\n",
      "Reconstruction: 0.048161, Regularization: 0.001056, Discriminator: 0.021662; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 0.081920\n",
      "Reconstruction: 0.048341, Regularization: 0.001035, Discriminator: 0.021712; Generator: 0.010833,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 0.080321\n",
      "Reconstruction: 0.046776, Regularization: 0.001010, Discriminator: 0.021691; Generator: 0.010844,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 0.089966\n",
      "Reconstruction: 0.056247, Regularization: 0.001260, Discriminator: 0.021626; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 191 Average loss: 0.0845\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 0.075340\n",
      "Reconstruction: 0.042040, Regularization: 0.000836, Discriminator: 0.021633; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 0.090137\n",
      "Reconstruction: 0.056303, Regularization: 0.001326, Discriminator: 0.021674; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.102948\n",
      "Reconstruction: 0.068781, Regularization: 0.001646, Discriminator: 0.021693; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 0.081312\n",
      "Reconstruction: 0.047768, Regularization: 0.001036, Discriminator: 0.021674; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 0.085244\n",
      "Reconstruction: 0.051634, Regularization: 0.001155, Discriminator: 0.021624; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 0.087965\n",
      "Reconstruction: 0.054237, Regularization: 0.001224, Discriminator: 0.021672; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 0.086874\n",
      "Reconstruction: 0.053196, Regularization: 0.001192, Discriminator: 0.021654; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 0.088408\n",
      "Reconstruction: 0.054687, Regularization: 0.001245, Discriminator: 0.021642; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 192 Average loss: 0.0846\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 0.100841\n",
      "Reconstruction: 0.066664, Regularization: 0.001633, Discriminator: 0.021705; Generator: 0.010839,\n",
      "D(x): 0.498, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 0.080386\n",
      "Reconstruction: 0.046933, Regularization: 0.000987, Discriminator: 0.021635; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 0.094228\n",
      "Reconstruction: 0.060341, Regularization: 0.001424, Discriminator: 0.021632; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 0.084955\n",
      "Reconstruction: 0.051310, Regularization: 0.001119, Discriminator: 0.021694; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 0.080752\n",
      "Reconstruction: 0.047239, Regularization: 0.001060, Discriminator: 0.021616; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 0.088260\n",
      "Reconstruction: 0.054575, Regularization: 0.001238, Discriminator: 0.021606; Generator: 0.010842,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 0.088843\n",
      "Reconstruction: 0.055132, Regularization: 0.001265, Discriminator: 0.021613; Generator: 0.010833,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 0.085325\n",
      "Reconstruction: 0.051677, Regularization: 0.001171, Discriminator: 0.021643; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 193 Average loss: 0.0845\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 0.083580\n",
      "Reconstruction: 0.049917, Regularization: 0.001128, Discriminator: 0.021701; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 0.084275\n",
      "Reconstruction: 0.050667, Regularization: 0.001120, Discriminator: 0.021658; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 0.086298\n",
      "Reconstruction: 0.052598, Regularization: 0.001211, Discriminator: 0.021650; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4974, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 0.093257\n",
      "Reconstruction: 0.059274, Regularization: 0.001406, Discriminator: 0.021744; Generator: 0.010832,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 0.079699\n",
      "Reconstruction: 0.046158, Regularization: 0.001040, Discriminator: 0.021667; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 0.085643\n",
      "Reconstruction: 0.051928, Regularization: 0.001195, Discriminator: 0.021685; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 0.075861\n",
      "Reconstruction: 0.042463, Regularization: 0.000928, Discriminator: 0.021639; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 0.091802\n",
      "Reconstruction: 0.057973, Regularization: 0.001355, Discriminator: 0.021635; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 194 Average loss: 0.0846\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 0.085461\n",
      "Reconstruction: 0.051755, Regularization: 0.001236, Discriminator: 0.021643; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 0.075357\n",
      "Reconstruction: 0.041983, Regularization: 0.000916, Discriminator: 0.021627; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 0.081272\n",
      "Reconstruction: 0.047708, Regularization: 0.001109, Discriminator: 0.021621; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 0.082072\n",
      "Reconstruction: 0.048465, Regularization: 0.001109, Discriminator: 0.021662; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 0.075474\n",
      "Reconstruction: 0.042039, Regularization: 0.000898, Discriminator: 0.021703; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 0.100642\n",
      "Reconstruction: 0.066433, Regularization: 0.001681, Discriminator: 0.021693; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 0.087509\n",
      "Reconstruction: 0.053784, Regularization: 0.001228, Discriminator: 0.021663; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 0.081265\n",
      "Reconstruction: 0.047695, Regularization: 0.001067, Discriminator: 0.021673; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 195 Average loss: 0.0845\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 0.077704\n",
      "Reconstruction: 0.044260, Regularization: 0.000960, Discriminator: 0.021655; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 0.081026\n",
      "Reconstruction: 0.047438, Regularization: 0.001066, Discriminator: 0.021691; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5020, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 0.082524\n",
      "Reconstruction: 0.048969, Regularization: 0.001124, Discriminator: 0.021597; Generator: 0.010834,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 0.077464\n",
      "Reconstruction: 0.043977, Regularization: 0.000955, Discriminator: 0.021703; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 0.088037\n",
      "Reconstruction: 0.054270, Regularization: 0.001279, Discriminator: 0.021654; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 0.097387\n",
      "Reconstruction: 0.063311, Regularization: 0.001557, Discriminator: 0.021684; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 0.083131\n",
      "Reconstruction: 0.049488, Regularization: 0.001163, Discriminator: 0.021646; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5030, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 0.081659\n",
      "Reconstruction: 0.048138, Regularization: 0.001119, Discriminator: 0.021572; Generator: 0.010829,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "====> Epoch: 196 Average loss: 0.0845\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 0.090100\n",
      "Reconstruction: 0.056216, Regularization: 0.001342, Discriminator: 0.021704; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 0.078428\n",
      "Reconstruction: 0.044946, Regularization: 0.000977, Discriminator: 0.021666; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 0.089207\n",
      "Reconstruction: 0.055387, Regularization: 0.001299, Discriminator: 0.021682; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 0.105654\n",
      "Reconstruction: 0.071340, Regularization: 0.001811, Discriminator: 0.021666; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 0.075328\n",
      "Reconstruction: 0.041887, Regularization: 0.000928, Discriminator: 0.021672; Generator: 0.010842,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 0.081865\n",
      "Reconstruction: 0.048308, Regularization: 0.001070, Discriminator: 0.021653; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 0.082122\n",
      "Reconstruction: 0.048587, Regularization: 0.001073, Discriminator: 0.021624; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 0.095040\n",
      "Reconstruction: 0.061030, Regularization: 0.001519, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "====> Epoch: 197 Average loss: 0.0846\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 0.086013\n",
      "Reconstruction: 0.052298, Regularization: 0.001209, Discriminator: 0.021675; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.075220\n",
      "Reconstruction: 0.041788, Regularization: 0.000908, Discriminator: 0.021693; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 0.079577\n",
      "Reconstruction: 0.046054, Regularization: 0.001012, Discriminator: 0.021685; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4965, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 0.079811\n",
      "Reconstruction: 0.046199, Regularization: 0.001007, Discriminator: 0.021762; Generator: 0.010842,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 0.068859\n",
      "Reconstruction: 0.035664, Regularization: 0.000739, Discriminator: 0.021626; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 0.069544\n",
      "Reconstruction: 0.036299, Regularization: 0.000735, Discriminator: 0.021678; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 0.078161\n",
      "Reconstruction: 0.044644, Regularization: 0.000985, Discriminator: 0.021692; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 0.093436\n",
      "Reconstruction: 0.059487, Regularization: 0.001503, Discriminator: 0.021618; Generator: 0.010828,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "====> Epoch: 198 Average loss: 0.0844\n",
      "tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 0.079618\n",
      "Reconstruction: 0.046095, Regularization: 0.001065, Discriminator: 0.021618; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 0.088165\n",
      "Reconstruction: 0.054345, Regularization: 0.001301, Discriminator: 0.021684; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 0.078520\n",
      "Reconstruction: 0.045004, Regularization: 0.001003, Discriminator: 0.021678; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 0.082767\n",
      "Reconstruction: 0.049148, Regularization: 0.001148, Discriminator: 0.021634; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 0.085174\n",
      "Reconstruction: 0.051480, Regularization: 0.001199, Discriminator: 0.021656; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 0.089910\n",
      "Reconstruction: 0.056127, Regularization: 0.001355, Discriminator: 0.021599; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.080098\n",
      "Reconstruction: 0.046502, Regularization: 0.001076, Discriminator: 0.021687; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 0.074166\n",
      "Reconstruction: 0.040817, Regularization: 0.000875, Discriminator: 0.021639; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "====> Epoch: 199 Average loss: 0.0845\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 200\n",
    "LR = 1e-4  # TODO: increase LR\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.999\n",
    "\n",
    "PRINT_INTERVAL = 16\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "vae = toynn.VAE(\n",
    "    latent_dim=latent_dim, data_dim=data_dim, \n",
    "    n_layers=n_layers, nonlinearity=nonlinearity,\n",
    "    with_biasx=False,\n",
    "    with_logvarx=False,\n",
    "    with_biasz=False,\n",
    "    with_logvarz=False)\n",
    "vae.to(DEVICE)\n",
    "\n",
    "discriminator = toynn.Discriminator(data_dim=data_dim).to(DEVICE)\n",
    "\n",
    "modules = {}\n",
    "modules['encoder'] = vae.encoder\n",
    "modules['decoder'] = vae.decoder\n",
    "\n",
    "modules['discriminator'] = discriminator\n",
    "\n",
    "print('\\n-- Values of parameters before learning')\n",
    "decoder = modules['decoder']\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "optimizers = {}\n",
    "optimizers['encoder'] = torch.optim.Adam(\n",
    "    modules['encoder'].parameters(), lr=LR, betas=(BETA1, BETA2))\n",
    "optimizers['decoder'] = torch.optim.Adam(\n",
    "    modules['decoder'].parameters(), lr=LR, betas=(BETA1, BETA2))\n",
    "\n",
    "optimizers['discriminator'] = torch.optim.Adam(\n",
    "    modules['discriminator'].parameters(), lr=LR, betas=(BETA1, BETA2))\n",
    "\n",
    "def init_xavier_normal(m):\n",
    "    if type(m) == tnn.Linear:\n",
    "        tnn.init.xavier_normal_(m.weight)\n",
    "        \n",
    "for module in modules.values():\n",
    "    module.apply(init_xavier_normal)\n",
    "\n",
    "train_losses_all_epochs = []\n",
    "test_losses_all_epochs = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_losses = toytrain_vem(\n",
    "        epoch, train_loader, modules, optimizers)\n",
    "    \n",
    "    train_losses_all_epochs.append(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6348b095f8>]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "plt.plot(range(N_EPOCHS), train_losses_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[2.]], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[-0.1827]], device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "decoder = modules['decoder']\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "generated_true_x = generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = generate_from_decoder(decoder, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6348958d68>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "plot_data(generated_true_x, axis_side=axis_side, color='darkgreen', ax=ax)\n",
    "\n",
    "ax = axes[1]\n",
    "plot_data(generated_x, axis_side=axis_side, color='orange', ax=ax)\n",
    "\n",
    "ax = axes[2]\n",
    "plot_data(generated_true_x, axis_side=axis_side, color='darkgreen', ax=ax)\n",
    "plot_data(generated_x, axis_side=axis_side, color='orange', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
