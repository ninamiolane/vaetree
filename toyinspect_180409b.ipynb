{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import importlib\n",
    "import toylosses\n",
    "importlib.reload(toylosses)\n",
    "import toynn\n",
    "importlib.reload(toynn)\n",
    "import toyvis\n",
    "importlib.reload(toyvis)\n",
    "\n",
    "import torch\n",
    "sns.set()\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "OUTPUT = '/scratch/users/nmiolane/toyoutput_180409b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide on experiment's configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEBCAYAAAB7Wx7VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXt4VNW5/z9zTzKThAQShosEBDJKq4dzetpoUUBBAaMmoBDlNkT0nCOa2jzYphSliFLEyxMxJW0fDoRBoOWWEGuAKGhQqNDj75Sj1TrhZpBLCOSeSTKZ2++PcW9nMntCgECArM8/4mTvtfeay7vWfi/fV+Xz+RAIBALBjY+6u29AIBAIBFcHYfAFAoGghyAMvkAgEPQQhMEXCASCHoIw+AKBQNBDEAZfIBAIegjC4AsEAkEPQRh8gUAg6CEIgy8QCAQ9BGHwBQKBoIcgDL5AIBD0ELTdfQOAAfgxcAbwdPO9CAQCwfWCBugH/A/g7MwJ14LB/zHwSXffhEAgEFyn3A3s68yB14LBPwNQW+vA671xlTt79zZRXd3U3bdxVRFz7jn0xHl395zVahVxcUb4zoZ2hmvB4HsAvF7fDW3wgRt+fkqIOfcceuK8r5E5d9oVLoK2AoFA0EMQBl8gEAh6CMLgCwQCQQ9BGHyBQCDoIVwLQVuBQCDoUWg0Khyqely+NnQqPUZfLB7PlQ8Aix2+QCAQXEU0GhUnnEe42zaKoXk3c7dtFCecR9BoVFf82sLgCwQCwVXEoaonfVM6FfUVAFTUV5C+KR2Hqv6KX7vLXDoWi+VB4GVAhX8hWWy32wu7anyBQCC4EXD52mRjL1FRX4Hb57ri1+6SHb7FYlEB7wCz7Hb7SGAmYLNYLOIJQiAQCALQqfQkxSYFvZYUm4RWpbvi1+5Kg+wFYr/7dy/gjN1u93bh+AKBQHDdY/TFsj1ju2z0k2KT2J6xHaMv9gJnXj5d4tKx2+0+i8UyDSi2WCwOIBpI7YqxBQKB4EbC4/ExyDCMT6z7cftcaFW6q5alo/L5Lv8iFotFC+wCfmO32/dbLJZRwJ+AEXa7/ULqQoOB45d9EwKBQNAzGQJ805kDuypoOxLob7fb9wN8Z/QdwK34tZovSHV107UiRHRFSEiI5ty5xu6+jauKmHPPoSfOu7vnrFar6N3bdHHndNG1TwIDLRaLBcBisdwKmIGjXTS+QCAQCC6TrvLhV1oslqeBrRaLRQrUZtrt9pquGF8gEAgEl0+X5eHb7fYNwIauGk8gEAgEXYvIkxcIBIIegjD4AoFA0EMQBl8gEAh6CMLgCwQCQQ9BGHyBQCDoIQiDLxAIBD0EYfAFAoGghyAMvkAgEPQQhMEXCASCHoIw+AKBQNBDEAZfIBAIegjC4AsEAkEPQRh8gUAg6CEIgy8QCAQ9BGHwBQKBoIcgDL5AIBD0EITBFwgEgh6CMPgCgUDQQxAGXyAQCHoIXdbT1mKxRAC5wHigFfjUbrf/R1eNLxAIBILLo8sMPvAafkOfbLfbfRaLpW8Xji0QCASCy6RLDL7FYjEBs4GBdrvdB2C32892xdgCgUAg6Bq6aoc/FKgGfmOxWO4BmoAX7Hb7vi4aXyAQCASXicrn8132IBaL5UfAZ8AMu92+0WKxpAB/AYbZ7faGC5w+GDh+2TchEAgEPZMhwDedObCrdvgVgBv4E4Ddbj9osVjOA8n4F4ILUl3dhNd7+YvPtUpCQjTnzjV2921cVcScew49cd7dPWe1WkXv3qaLO6crLmy3288DHwH3AVgslmQgETjSFeMLBAKB4PLpyiyd/wLWWCyWNwEXMMtut9d14fgCgUAguAy6zODb7fZjwNiuGk8gEAgEXYuotBUIBIIegjD4AoFA0EMQBl8gEAh6CMLgCwQCQQ9BGHyBQCDoIQiDLxAIBD2ErszDFwgEgusCjUaFQ1WPy9eGTqXH6IvF47lxK/0lxA5fIBD0KDQaFSecR7jbNoqheTdzt20UJ5xH0GhU3X1rVxxh8AUCQY/CoaonfVM6FfUVAFTUV5C+KR2Hqr6b7+zKIwy+QCDoUbh8bbKxl6ior8Dtc3XTHV09hMEXCATdgkajolXbQKPmPK3ahqvmUtGp9CTFJgW9lhSbhFaluyrX706EwRcIBFed7vSjG32xbM/YLhv9pNgktmdsx+iLveLX7m5Elo5AILjqhPOjf2LdTwQxV/TaHo+PQYZhfGLdj9vnQqvS9ZgsHWHwBQJBCFc6bbG7/egejy9oYfFw4xt7EC4dgUDQjo7cLV3ld+/JfvTuRBh8gUAQRDh3S7O6vsv87p31o3dXYPdGRbh0BAJBEOHcLW1eZ1i/ezwX11u1M3506UlDuqa0KAwyDOsR/vYrgdjhCwSCIMK5W9RqTZf63T0eHxHuGEye3kS4Y0KM+KUWSImngvAIgy8QCIII524xqCIuye9+qQb4UgK7PVk2oTN0ucG3WCy/sVgsPovF8sOuHlsgEFx5At0tx7KO84l1P4MMwzB4jBedv345BvhSArs9WTahM3SpD99isfwbcAdwoivHFQgEV4Zw6Zfh0hYvNn/9cvLtpSeN9j58oy82bBpld6d7Xut0mcG3WCwGYCUwHfioq8YVCARXhksJil5s/vrlGOBLKZCSngoCrynSPb+nK106S4D1drv9eBeOKRAIrhBXw/1xufn2FwrstqcnyyZ0hi7Z4VssljuBHwO/utQxeve+uLSu65GEhOjuvoWrjpjztUtFXY3i7turcl/SHJTO8fqMFD9eTNqf0uSniOLHixnQqx9q1ZXJGenlu50DTx7A6XZi0BpINCZesWtdL5+1hMrnu/x8VovF8ivgZ0Dbdy8NBM4CmXa7/f0LnD4YOF5d3YTXe+Pm1iYkRHPuXGN338ZVRcz52kTy27f5nNirv2bJ3iUcPHUQ8O+IP7HuJ8J9cXo2Hc1but6NplvT3Z+1Wq2SNspDgG86c06X7PDtdvurwKvS/1sslm+AB+12+z+6YnyBQNA1KPntC9IKWLBnAZVNlRcMil4KSn7/67nFoHTvFXU1qLXa6+reRaWtQNCDUPLbZxZnsnfOXtS+q2O8rucK2uv53uEKFV7Z7fbBYncvEFx7hMua8Xp9nQqKdgXXc6789XzvICptBYIexbWgUtkVufIXqt7VaFS49c04dDU0aM7h1HWNxML1nucvDL5A0IO4lLTFrtamab/opAxIoWR6CV68nRr/QtW7Go2KKs9Jvq75irFrxzAsbyh3re0aiYVrYcG8HLokS+cyGYzI0rkhEXO+NrmYrJnO+qwvZt6BY5pNZpaNW0ZmcWanfeKt2gbuto0KKa6SsotatQ18cf7/mFcyL+wx4d6TCwWRryUffrdl6QgEguuHi6mWvRhphM4azcAKWq/KzZi1Yy5KeuFCbhWXrw2jzthp18vFGPH29361At1dhXDpCASCsHTWZ+31eS9KJE2qoPV4vRftEw/nVonQRNKqbcCHj0RjYqddLxcbiJXuPalX0lULdHcVwuALBIKwdNZnXeWo6tBohosDXIpPXCkOsWvGLs42n+Fu2yiG5Q1lwe4FbJ22tVOxis4uau3n4PV5w97jtYpw6QgEgrB0VrHS6XaGNZpKLpNdM3Zh0kXj9rrYM3sP80vnU1xe3ClFTCVRNZUKJm6YKN9DcXkxAHvn7MXj9aBXG4jyKrteOiO4pjSH4seLuUk39Lra4QuDLxDcQHR1BWtnFSsNWkNYo+kg2GViNpk503SGzOKJsvEsyijidw+sxOelU/fcPg7RqDkfsuAUlxeTO+Etoj0J4Akfq+jMoqbk9kn7U1qnZJ6vJYTBFwhuEK5UBolkXDUaFQ7qqeMcOm3wYpJoTAxrNOs4F2SMc0blyFk54DeekzdN5hPrfoy+WP+Cpbm4BStSE0XJ9BKMOiM1LTUs37+cyqbKENdQuAXxQova9Z5/LyEMvkBwndLeeGnV2otuNtJV6YhqlTqs0dRpg10m8ZHxysYT1yUtWBqNilPNZ+Q0TEkfqJ+pX9Au/UJz6Chz6UbR2RdBW4HgOkSp+Kiy+TRmkznouI52oRfTflDJpbG4bDFN6hoaNeepbKoEUNSuDwyypgxICZtB4/V5WFy2uNPZMlIQtUFdragPZNJFBy0U4bJxmtX1FywsUwoUFz9efN3p7AuDLxBchygZr8mbJrNozKKg4wJ3oe2zTJrVnU9HbO/SSBmQQlZKFqPXjmZo3s3c8d93hF0sJJfJp5kH+X3q71mwewGrH14dZDxXP7ya+aXzsY60Bp17odz5u22jqKj7RvGJweUNPi+cW6bF03zBRU+pz+9tibddVwFbEAZfILguCWe8hscPV0xFVNrNt3iaO+2Xbp8+mTMqh7nvzr2o3HW3183kTZMpLi9m4YcLyZ2Qy77MfeyYsYONX2zEOtLKiIQRFE4rJGVAijyHC+XO17TUdCq1M1wK6OGaw52aR/vuW1eqqcqVRPjwBYLrkHA+5UhNlKIf3a1v5nTTaWzpNjmoebjmMEmxSZhNZnJG5RAfGY/D5SBCEwme4Ou1z2RJNCZ2uFgoxQYCF6mDpw4yZfMUAD576jOm3zZdXkCSYpOwpdvI/TSXxWMXK6ZoBo61fP9yVj+8Ouh8pdROpWycoowini55Ouw8bjSEwRcIriMkQ4raR1FGEZM3TQ4ycu1zzaVmIyebTwcFNVc/vJqNX2xk14xd36VIdqxl0z6TRaNWhw1ihguO9o3qp7xI6SJ5ZPMjQbts63YrH8/5BJM3Lug+pPn7fD5KppfI3boWfriQ/NR8bul9CzqVQTH4rJSNo1Vr5fhD+3nciFx/zyQCQQ8l0C0z6K2beKnsJfbM3iP7lMNlszhU9fLCAH6DOvfduTwy4hGidMaQFMnOuDRM3viwqpvhgqMenzvknC1Tt6BVa5WfFryuEGMvzX9Y3lDmlcxj2bhlpAxIobKpkv6m/vQisUO5g/ZuGYPH2KOanosdvkBwndDekBaXF3Po7CFZATJcYZGSv99sMjOizwhc3kvLL2+/W47UR6BvM+Hx+HBplMd0eV1B56jUKh7bmkHOqBzFnb9GrQlyLYXr1lVmLUOr0oWtpL2YedxIPXeVEDt8geAapX1WDWrfRRtnjUaFVq1hX+Y+ORiaMiCFZeOWMdY2ls/Pfn7J+u6Bu2WzySwbyY7EzSS/vlalw6CKoLKpUvbBB+6yC9IK0KsigsYIF6g+1XgKn49LNtLtd/1daey7upfA5SJ2+ALBNYiSH7woo4i05DRZJwaC/ebN6nqcXicatQaDKoJITHzTfDhojNUPr8agNTCzcCYV9RW8V/4eW6ZuYeqWqZhNZhaNWcTw+OGoVP57uFDBk2TAPU0O9Br/Dj9a3Ytt07bJfvmk2CR2zthJZfPpkJjDrhm7mLhhouyDHxo3lMqmShKiEojEhAuvfC1p4apyVLF8/3IOnjpIUmwSVY4q+psGXPHP5GK5lrTzJbqkAYrFYukNvAMMBZzAEeA/7Xb7uU6cPhjRAOWG5EaZ88Xo01zsnAMNtVatQa/W4/Z58Pm8jF47OsTNsWf2HsatGxdkQAZHDQ8x7AVpBQzuNZh7bPeEjFE2p4whK4aQMiCFpfcuJe9gHs/d8RwxhpggI12UUYQ5qj8GjzFkvu2NWVpyGm9OeBM1GjRqNXkH8/jpoJ8SHxlPm6eNIXFDGL9ufMi97JvzVzy4cHqc6NQ6Wlwt2Kvt2A7ZyJu4kgh3jKLhXP3wavIO5pGVkkXewTz52KvJhT7rCzVquVwupQFKV7l0fMBrdrvdYrfbbweOAq920dgCQbdxMdWolzr2XWv9Qcgxa8fwdfXXnGk8zVnHWUX3hRpNUPHP4KjhNPiqcbgc5E7IJWVAiuzbdnqUFSy9Xi9JsUlyLn1xeTF1rXUhmTKTN03m71X/T3G+gf50qQhr3Lpx3Jw3hNFrRzNx+ESW71/OWNtYmtqaONukPB+nt4Xndj6H5XcW7rHdw5mmMyzfv5zi8mLZVaXku5/77lx+O/635B3Mk1M327+3Tl0DDZpzOHQ1uPXNV92dci3q73SJwbfb7TV2u70s4KUDQFKYwwWC64aLbY5xuWNnFmdyvuU8Rr0xrG89wh1DLH3QqrUcby5n9NrR3FVwF9ml2Sy9d6ls9NUqdUjv2DJrGT58lFnL+Ld+/8a4IeMonFbIiIQRisbJqDOGzFejUdHm+34xUSrCmvvuXHJG5QB+7ZxmV7PifOzVdrJSsuR7ls7zB2395imc4TRoDORNXBniImm/kI5dO4ava76iynPyqhr9a7H/bZcHbS0Wixp4Gni3q8cWCK42V3KXFm5so85Ii6slJJDZvmr271X/TzHdUjKYVY4qijKKZA2b1+97Het2K8PyhjHWNpYqRxXz75yPQWvA6/NSMr1ErnCVrlnTUhNSUHXCeQR79dfyvSmJoZlNZn6Y+EPKrGX0j+5P/+j+FKQVhMgpLNm7JGhxqKiv4NaEW9k1c5d8vXCGU6dWzqgJt5AeqzvWJQt1Z7mUhvFXmisRtM0DmoDfXcxJ3/mibmgSEqK7+xauOtf7nD1NDuViIX0ECSbluXV2zuHGdrgc1LTUYDtk45PMT/D6vBi0BhKNiahVaiqbKklfl44t3aa4YAyMGUhBWgEJxgSGxg3lwJMHaHW3Mnbt2CAj6PQ4aWprClGZXLBnAZVNlax+eDULP1wYNN/KpkoWly7mmZ88w66ZuzhWewyvzxs0DykL6L537gsad/3n63l/1vucaTxDTUsNCz9cyMFTBwH/oiHN/1jtMVI3psoCZT9I+AHFjxeT9qc0ebwtU7dQ01KDy+AiOjIaL175/amoqwm7kHpV7i79Tl5orF6+2znw5AGcbmfQZ9hddEnQVsJisbwB3A48ZLfbnZ08bTAiaHtDciPM+WIzLS5mzkpjF6QVYNQZ+e0nv+XV8a9i0kXT5g0OFjdqzjM072YKpxWSXZqtGNjtZYhD5dQDcMJ5BIfLwV0FdwVd3/6snfvfuT80qGst46vzX7Fk7xIqmyopyiiiT1QCeFVotRq+OvdlkIzBtmnbMOqMcsepkukl8iISOG5BWgF9TX15YMMDIX/LnZBLdmm2vOBIC4EU5DT6YmlS13DWcZYYQww5H+TIHbK2TN3C5n9s5r9+/F+o0RChNVBeUw4QpI2fn5rPbX3+JWzA9GKbx3T39/tSgrZdtsO3WCxLgR8BqRdh7AWCa5pwhTngz8LorHHoqPHGvjn7afsunVKv1uPxefn9A3/kbPMZ2YgGLjSSi2P5/uVySmVg9sr80vm8OeFN9BoDPp+X9E3prHpoVcjThNen3EC81dNKjCEGW7oNjVpDo7ORQW/dRFpyGm9NeivEX//I5kfY98Q+9szeQ2VTZVgXT7Qhml/v/nWI7k1RRhEJUYmUzSnjsa2PycZeGt/t81fcuvFwsuFk0CJXUV/B0o+XsnD0QuaXzueZnzzDoNhBOFwOecEqSCvApDcRrY8O2zrxQgu70ud3PdIlzxYWi+UHwK+B/sBfLRbLIYvFUtQVYwsE3U37whzgojJ3Osr08Xh8GFwxRHsSiHLFo3WaMLTF4Pa6wwaLJd9wZVMlapWa3Am5lFnLyJ2Qy8IPF1JcXkxlUyWfnf4fvm34lor6CrRqLe9Mfkf2Jz9/x/NEaiMVfePHao/hdDvJ+SCH47XHaXA2yJk4pxpOKS4SbZ42xq0bx10Fd/H1+a9Dxl00ZhGPbn5UUSnzpbKXONdcRUVdRYe6NjqVXlG0zTrSytKPl5KVksVTf3mKW1bewrySeSy9dylmk5nM4kz6Gs0kagaGXZQ7Cs6H+/x6bBNzu93+JdC9JWQCwVUinHH4xLqfeEJjUR0dH64TVbiArsvnf3iWnjq8KndQOiUgB2zjI+OpclSRFJtEX2NfNGoNu2fvxqAx0Ohs5Lmdz4XstiW/fWVTJbkTconSRVHlqJIzcXIn5CrLIKg08mtK6pVD44bKfw9UyiyzllHpqKTB2cCQuCEUZhQyZdOUoN2/tCs3+mIxm8wh1080JmIdaVXMFMqdkMuUzVPweD0dPoF1FJwP9/kdePIAGoxhx7wWEZW2AsFFcrGZOxd7fEdVpaebTuMz+VCjQYuOWFWfENXM1Q+vZtfhXWT+WyYGrYEDcw9wuuk0UzZ+b0gL0gqodFSy8MOFYQOpA2MGEmOIYc3f15BzVw62dBtenxdbug3rdmuQUdZr9PL9vlf+HmqVmj2z9wDgw4fH61FcKIx6I7974Hc8uvlRuYCrdGYpGrUGn89HrD4OT6vfUHs8PnrrzSHz7RPVR35P27/H8ZHxnUqF7KiFYbjPz+l2EiUMvkBwY9ORcfD6vCG+/Yvph9pRVemv7/41Le6WkErboTHJlM0pw+l24vF52H1kNxm3ZfDAhgcwm8ysn7Je3jXD92mK0u73y6ovFYO/cZFxxBpi+eWoX9Lc1kyCMQFHm4M+UX3YMGUDAH1NfTFoDByrPUaVowrbIRsvjHmBTV9sYuLwifKuOy05ja3TtsqGXQq2JhoT+UfVPxg3ZBwPJj9IfGQ8R2uPEmOIocHZgNlkpp+xH1GqGBrcdTR62kiITOTTzIO0elrQqNVo1Vo0ak3YjKfAp4RwKGnlB6p/Ko1t0BrgOpPN79IsnUtkMCJL54bkRp1zuADf4KjhVLQeCUof3J6xnf6mgZxq+jZER0YpIKhVaxQlFUpnlgIwYf2EoL89f8fzTL99etDYRRlFvFT2EsXlxRROKyTRmBiSoQN+d8pY21hSBqSQNykvJPibdzCPNye8yfzS+bKEwXN3PMfAmIGoVCq0Ki0Ol4PUjamyUV9+33IanA30ieoTIuuQlpzG6/e/jtfnRaPW8Hzp8xSXF5OWnMYLY14IWgy2TtuKChWPbH6E9VPWE6mNDJJ9kN7vBl813zZ8i16jR6PWBLmDtk7bSqu7lWG9hqNxRnXqc3Wo6kNUM8N93rebb6f6vONyvkqXRbdm6QgEPYVwmTuN3jrZ2MP3vt781HyW7F1Cfmo+w+OHE6mJkqV82xuTv//H38mdkEt8ZLycUii5WM43nw8yoCkDUnjyR08GLQIV9X5JhNwJuRSXFwf58ZV2v4BfrMyYEHRdybXz6n2vsvy+5ejUOn477recdZwNyq9/Z/I7mE1mzCYzWSlZ8r3sy9wX4gapdFRS76ynylEVlLZpHWmVjb00h0c3P8qOGTuoqPd31wpMH5Xe1/a6Qrtn7abMWobT43/SKfjfAmbcPgO929jh7j7wcw2MqUjnhPu8RYtDgeAa5GLzqzuDknEIpwNv1Bk5eOqgXEz0iXU/4E/rbPM5Od10mnFDxjHz9pl48crulcCd9tHaozjdziDDnTMqJ2QRkK6ZaEwEkAu42rtTJH/84azDtHnaONVwStGtIxVBlUwvAQgy1BX1FcwqmkXuhFwA2X2TMiCFuMi4kBiElKnTvmBMKY2zor6CBmcDSbFJeLwexb9XNlXKr5tNZr5t+Daoc1dRRhGDo4bjarv8bJpwi8H1hjD4ghuaqylRG85XX9NSI/+/FKxtrzT5wpgXqHJUkbkpuPvU3Hfnsnv2bmYWzgQIyn5JNCaG3b0PjBnIJ5mfEKOPYdHYRTS7mslPzceoM1LTUkPO7hw5E2fK5imkDEhh86Ob/To+OiMOl4OEqASydmYBYNQZ5XsKpKK+glv63EKzq1k29kvvXSoXV6Ulp2FLt9HgbCAhKgGzySw3HZfGav//ge/b1mlbZU0gpUwkiZxROSGduyZvmtxhJlQ4rsQG4Vrh+nsmEQguAqWUusVli2lS13R5UwqjL5bix4uDtFMK0gpYvn+5fIwkCra4bLGcP//b8b/llb2vYNQZFQ2qx+uhsqlS7t0q5bAPjBmI7ZAtRHNny9QtVDmqMGgMVLdU0+xqBr5LX9xuZcrmKVQ2VbJl6page3N6nMwrmcdY21jmlcyTzwO/UXa4HIp5+8frjuP1eXn+judZk7aGCG0EuRNyeWLkE7Kb5yf//RPG2saybNwy3it/L+iebYdsbJu2LWgOhRmFxBhieHbHs+R8kBPy96KMImyHbPJ9hHtKuFjNo8Cc++mFj/PF+f+j2ncGp677m5d0BWKHL7ihaZ9SJxUQSYHRrtrxS7vCfsZ+fJz5MS6PC7VKjUqlwmw0A9+LZ+k0erJSskLy39tr0kjn1LXWyTv7g6cOkl2azeqHV1PvrOeFMS/wyt5XyJ2QS6IxkT5Rfdjy5RZm3j6TVk8r55rPsf7z9Uy/bTpv7H9DPi7BmIBGpZELnRaNWcSsollBC6N1u5VVD62iqa2JftH96GvsyzuT35GPC8zbNxvNLBq7SN7ZS4Hm9vGFzOJM8lPzgxqe6DQ6/vbt3yidWcr55vPERcbx692/pri8mJQBKVhHWtGoNOydsxePz4NapSFCHcGr41/l0NlDVNRXyItRZzKhOkLaIJhNZpbeuzToM+ru5iVdgcjSuUrcqBkrHXEtzLl9E4pw+jOX05RCo1FR5TmJw+Wgr7EvVc1VIdkiWpWW+Mh4TN54mtQ1ipk4qx5ahVqlDtGpSTQmYtAaaHG1cKbpDC2uFtxeNwNjBmLQGPi24VvAvwt/r/w9Zt4+M8iXvfnRzbi8LuIj4/3yDRo9j219DLPRzIpJKzjZcJLeUb25deWtIXP7+pmvZaOdFJtEyfQSjHojFXUVQUFlpfd1X+Y+xeygw1mH0ag08v9n78rGOtJKdmk2ZpOZdZPXcabxDG2eNmINsUzbOi2ofkASd9ueUUxfYyLN7maitFGcdVSRvintgga6I5fNhXSKAr8n3f397s4GKALBNUl7iVql0nylR/+L6UXq1DhobGukwdnA51Wfh+S8P7r5UfRaPS6vv2rTE0bD5ua4m+ln6scHsz6g/Nly8lPzeWbHM9xdcDcnG06iU+vY9uU2vD4vT/3lKUbkj+Dedfdi1Bt5z/4eAL+661dBvmyzyYzD5WBG4QxG5I/g/nfu55zD34iuuLyY2pZaWt2tHKs9puiuOVp7NGguqRtTcbqdsmtIyiBSel+l+EL7Mcury6ltreWVj1/hRP0JOZtI2lXf/879jLWN5am/PIXD5cBsMsvXzyzOJGdUzneZOmn8/ezfGZY3jDvX3EmE1sC+Od83hwmVRyOqAAAgAElEQVRn7DuSxZDiMF3lIrrWEAZfcEMTmFJ3LOs4N8XcFGKE0pLT0KjVsnHX6dWyUVj6ySs0uRuooZIWXS06vTpkMWjz+V0nmcWZYf3wtS21DMsbxt22UahVKkVD6Pa6/d2hvkt9TN2YysFTB6mor2DKpikcOnuI//zxf4ZICDy6+VH+68f/RXZpNg3OBjk2UDitkJfveTkkmDl1y1TWpK0hLTmN43XHWfjhQiK1kWydtjXIT75t2jaW7F0SMpemtqaQuEFfU9+QOdkO2dgydUvQcZIG/pRNU3hkxCNywLampYZFYxaFzE0y8IHXl6SUpQwo6d8TN0zE56PDZuQXamgjbRDCxSu6s3lJVyB8+IIbnsCUOg2qoIrKtOQ0XhzzYpBPXypcGjdkHE//+GkmbZgU5GLpa+zLF1WfY9QZ0ag1DIoZxNC4oeROyA3rh08wJvD+zPeJ1kej1+hDNGNWP7yanA9y+I9//w+SeydjNplD8vH7Gvvi9rqVA7s+D6seWkWENiIorXPXzF1hF6AXx7zI/or95IzKQa1S0+hsxJZuY2DMQOzVdlwel6KY2Yn6Eyzfv5z81HxujruZY7XHiNJGhejnZKVk8YfP/iDPo190P5bvW86yccsYEDMAjUrD+ebzlEwvYeGehbx2/2uK9yoZeOn6UtZTuAyojriQzIW0Qegb1S9EwkGqvL1eUzJBGHxBD6N9EY1KTUhjEKlwydLHEqTdXlFfwct7X2bR2EXMK5mH2WRm2bhlQYvFhikb+Mj6EacbT8tSA8/d8Ryzi2bLUr0erwc1asVCp+w7szHqjKybvI5zjnPyGK/f9zqxEbG4PC7FBUWSRyhIK8BsMlNRX0FFfQX1rcqyANK4i8YuClp4tk3bRqu7lSV7l/D2xLcpSCsIigcE+tANGgNzts/h4KmDHM46TK+IXuycsRO9Ro+92i7Pac2hNXKMIvuObFrcLXIhlZSR8/sHfy+3QWx/r1KBWOD1A/8deKxOraNVFV62uiOZiyDfvlfPkKjkkGKrCwVsr/WUThG0vUp0d4CnO7jW59yqbeBE4zeKgcXjzx0H6DA4GS6wl5+aT+rGVNKS03hjwhvUt9bLu+LKpkrK5pTx9zN/Vzx3/ZT1GHXGEDG0L89+yV2D72JJ2RI5w8dsMrNozCJujruZb+u/5cWPXgzJrV/98Gp/fn+A0bal28jZnUPOqBzFe9g7Zy/NrmZqWmrQqDT0MfbhbNNZml3NROoi6Wvsi0qlYtkny2RjXjqzlMqmSmpaavi3fv/GkZojQbv9rdO2olFpiNJFhchDJMUmUTanjJ/v/HlI9lJRRhFmo5lWtxOdWodGpaXV04JOraPJ1RjSLyBCGyG/lpacxpsT3vQLzal0RKt70eSro8XTzOGaw7JeviTT8E3z4Q7rNdob8wG9+gVJK1zNmg8Q0goCQViUdl4uX5ti4VJachrnHOdkbRmpeKi2tZbekb3lHXS4wJ5RZ5TTP8evGx+SwtjiasF2yBaiOintzqVzpPHmvjuXvXP2MmbtGCrqK6h0+J8UYgwxQfoy0viSC+Tle14mdWMqZpOZVQ+tYmDMQLRqrSwJkGhMVHQdubwujtcdD2ogsv7z9TyY/CB6jZ7DNYeJMcQw/bbpVDdX8+KYF4M6UO2ZvYe8g3lB45p0JiJ0EWH19J1up1/H31EZdF6viF48XfI0i8culg2niSjwQJQmNmgHrlVrubMgRS4Ay0rJCpJe2DZtGy/vfVm+z6KMIsxR/TF4jDR66zqUsFYy5sWPF3OTbqhszC9FBvtqI3b4V4lrfbd7JbhSc+7osTlQAEujVqNSqVH5VIq7QbOxH/aar+lr6sux2mOygfvI+hH/PP9P4iPjiYuIw+11ywJhkn6M2+tmQMwAxRaBktRAuN2/Tq1DrVKTdzCPtya9RYurBY1aw6mGU0TqIrlz9Z3yOSkDUsgZlcNtfW/ji7Nf8F75ezyY/CA/SPyB4rXzU/MBSN2Yyj+f+Se3rrxVrn4N3DkXpBUwNH4oR2uOhrhsADKLM4O08aWceumpYlj8MGpbarkp5iZONZ7iZMNJ+SkoLTmNhaMXsvTjpVhHWhnSawhxkf730elxKrY43DFjh+LrO2fsxKAx4Pa5v1usNBhUERg8/mBt4PfA7XNxc94QIHz6rfT0I/2/lGYppWO251jWcUye3iHpve3PBy44Rlcj0jIFNzwdpdUF/u3mvCGMXjua8mo7z+58hjNNZ4LS+xaXLeaM4zTW7VZuXXkr80rmkZ+aLzfHnlcyjztX38mE9ROoclQFnTuraBYt7hZmF82mIK1AsbI23O4/uXcyf/7Hn1n44UKsI62oUDFpwyQsv7OwYM8CYgwx8niSoc4uzWZ43nCyS7N5+sdPYztk40zjmbDj/zDhhxzOOkykNpK05DS5eUn77Jc2T1tIBk9mcaYcGM47mMeatDXY0m1o1Vr+/MifWZu+FoDZRbPJ2JqBvdpO1s4sskuzWXrvUp4Y+QTWkVbMJjO/GfsbbIds1DvrGbN2DMPyhvHr3b8OyQYqzCikobWBkuklQa9vnbaVNf+7huN1x7n/nfsZ+vZQxq4dw5G6cpo1dVT7zvDF+f9jeuHj3G0bhRcPaclpFE4rZETCiAsGgAODtZJvX3rfC6cVsi9zHxq1PyurMz0NAseQuNYye4TBF1xXdJRWp/S3ue/OxTrSGpLeZx1plf3k0rFTNk3BpDcFdZAKlxooCaIt2LOA/NR8vpr3FaseWoVJb5J92Uo/fhUqFty9gLcmvoVBa6C+tZ5t07aRlpzG0nuXyj1fk2KTFA31o5sfxTrSGnZ8gNFrRzM8bzhj1o7hhTEvMKTXEEVjFfjfwNf1Gr3sEnlgwwOMtY1l3LpxtLhbmLN9Tkj7QCkvfu67c/nlqF+SXZrNZ6c/Y/KmyTzzk2dktxX4c/9f2fsKZXPK+Ocz/+Qj60es/NtKHtv2GG2eNrZN20aZtYwdM3bwyt5X+Omgn4a8B7OKZvF51eck/y456F7+8D9/4MUxL5Jdms1X575SfH+8Pi+F0wops5ZRMr2ECE0k8H06pvQ5ZJdmc1fBXYxeO5oTziNEaqIuaMzb13wEZvZcKwiDL7gukHLf23ytYXda4XZh0m47cHcn+a+lH3/htELMJjM6ja7DnWHKgBRKppeQaEykcFoh4HefVDmqeOovTwHw4ewPGWkeGZKDvmHKBmpaahi/bjx3rr6TeSXz0Kg1uL1u3pjwBlq1lufueA6j3kjpzFJ+1P9HYe/lvfL3FPPm//g/fwxZIGIjYpWNlVpLUmySvKOVjKBBY2BN2hrFp4KX73lZNu5r0tZgNpmD8uIl9U7pPR8YMzBkDsXlxbS4Wpi4fiKnG0/z5bkv5eyo2IhYcj/N5ZzjnFyQFS5OIv177rtzyRmVw08H/VRerKU2i4Hvz47pO9CqtWSXZst6QWebz8i9hQcZhvH2pLdD5p2+KR2Pzx1izIsfLw4y5u1rPsIVf3UnXRa0tVgsyYAN6A1UA7Ptdvvhrhpf0HMJDJiF66kq7bSU/tYvuh8l00u4KeYmUgakUNlUyaDYQSwbtyzEfx2piQybGpgyICXknM2PbqbF3cKAmAHsmLGDwq8K5YKiNk8bqx5ahV6jlytGpSAiwLgh42h2NZOxNUMODi+/bzm1rbUcrT3K4NjBpCWnUVxeHHQvNS01PJj8oKyhIwU4X977MtaRVjjw/XtXUV+B2+tWzPtfeXAlJdNLQrJ4tk3bhqPNoWhoB8UOImVACgdPHaS2pZZl45bJzbyldE/4XgEzXCcqjdrfA3dG4QzZry7d65sT3pTrGcIpaSYYEyizlsmB5vjIeLRqrXxcoNDc7X1vR6+KQKVS8cDGB0KMuRRU9Xh8uFGWYnZ5XSGa+O2zdODal1Huyh3+H4CVdrs9GVgJ/LELxxb0YAJdNUo7N+mxWemRuiCtgNlFs5lXMo9TjadYm7aWTzMPovJpFP3XXrwhO2dbuo0YQwx/euRPirIF1u1WhucN54ENDzBx+EQW7F7AXQV3kVmcSa+IXqz7v3WkbkxFrVLLVbAfzv6QnLty5EwgyYUyYf0Eefd/1nGW/NR8SqaXyLvvkukl2A7ZiI+Mp7i8mCmbpzDWNpYpm6dQXF4s6+BLJMUmoVapidZHy9fOnZDLwg8X8saBN4jWR4e8D49sfgSj3qj4VHC09ig5o3JIS04jLjIOvUZP/+j+cgtDScFS+pyqHFWKcY5TDafk60lPCEmxfv392tZaXt33KoUZhYpqoFunbeXXu3/NWNtYskuzWTZuGRq1Rm5wLiEJzelVEUS4Y2jzOi/LD+/x+Ihwx8iVvNdjA5QuydKxWCyJQDnQ2263eywWiwb/Ln+43W4/d4HTByOydG5ILmbOnRG0kpAyV6Sdm1KWjsvn5Ovqr1myd4ms9yJlffQy9KLV7ZQzOgI5knWE+aXzsY600i+6H/1M/ahtqeV43XFGJIzglpW3yMd2NhOkdGYppYdLSbWkUtlUSZWjSt6RSjUASmOlJafxm7G/CcrJL8wopNnVHNIFSrrW7tm7g1JBt03bRj9TP1xeF16fF5fXxamGUyzYswCz0cxr97+G5XeWkPfhs6c+w4cvqGmKlLXzh9Q/4Pa5Q/rTxhhigjKa0pLTePuBt3G0OThed1zW2e8T2Yef7fqZ3Jg9d0KurAAqZQXlp+bzg4Qf8L9n/pd/6fsveHwePD4PEdoIfr7z5yFPPR/P+YQYVXyHufThMm3K5uxF49PK7pn26ZdFGUX0iUoAryrou9bdv+nuzMO/CThlt9s9AN8Z/dPfvX4hgy/oAVwolbKjghW9Org6Utq5SSlxHoL7wurQo0JN6sbUoHuoqPcXUTW7momPjFd0FfjwUVxeLBuUl8e+zGO3PUaiMRGjzuhXi/yuicig2EGdygQ533yeh299mLqWOnlXHBcZxxdnv5DvQclXHS6wnDshl+fff16xKfgf/+ePim6e7NJstkzdgk6to390f1Y/vBqD1kB5dbni+3Ci/gS9InoFNU2RjHFsRGxQv9qKer8+jy3dhlFv5P1Z73Om8QwOl4OjNUeJ1PoDowNiBgDwfOnzsrEvyijC6/PKTx3S4jw0bihen7/717Zp26hrrWPuu3OxpduCjL10fbfXhZfgKmqpUKvOcw6dVk+0uldIo/KCtAIe25ohF2ANMgwLGsOLh/ml8+Xc/etdIvmaKbz6bqW6oUlIiO7uW7jqJCRE4/V5+aLqi6Dm3sWPF3Nb4m2oVWoqmypJX6dQsJL5CQa9AZerjdKZpRytPSrnyhc/VsyAXv1Qq9SK4++ZvUfRkFU5qsguzWb9lPUh2i9bpm6htqWWkuklxEfGkxCVQL2znvHrxmM2mVn5wEq5xZ+025Z87NJTR6IxkbjIONnPLV1Tr9HT4GyQK2TfmfyO7K6Y++5cRV91OGXP+Mh4Dp46SKOzMcggq1Vq3jjwRpAPHyD7zmzZKEu76cKMQiK0ESzZuyTkfZCaj6hQUddaF1TctXXa1rBtFQfEDECFCqfHSe6nuWSlZMnSB29PfBun28n55vMsG7+M1+9/Ha1aS4urJcivLn1OOo1O7tLVO7K3fA/hfPpfV3/NgJhGbku8jXiVKex37od9f8iBJw/Q7Grm6/Nfs2DPAnmRSd+UzoEnD/gD0fizre747ztCvpfSMdL3+3qiqwz+t8AAi8WiCXDp9P/u9U4hXDo3HtKcW7UNIc290/6UJu/QmzUtigakurkal9cl+7klg9PqbiUx0iwHzALHlwKrPnzsmb2Hkw0n5XZ+ksugot7fRerTbz/lI+tHeHweNCoNRr2Rb+u/lY16yfQS+d+rHloVlK5pNpmpbKrkzQlv8vr9r9PgbAgyjLZ0m2z0dh3exbyfzKPN08afH/kzfYx90Kl1PHfHc6w4sILcCbkM6TUkJLCaYExQNG6SYNiCPQt4/b7X5YYkUh57uOMr6v3tCG3pNiqbKjHqjFQ2VcrBzfjIeL/LJaoPbZ42KpsqafO0YUu30T+6P6cbT/P7//k98386X/E65dXlct/ewoxC/vT5n2Rj6vV5Q4LDUvFX+6YqW6dtJVIbSaTaSGxCL5wBvncpNtC+eYz09CF9p8J958rmlKFFh8qn/ATY0tYq/07DfS+lY7r7Nx3g0un8OV1xYbvdXgUcAh7/7qXHgb93wn8v6AFcqGglXKBMr9XLxl4659HNjxIfGU+zpwmnrgG3vllO1UwZkMLbE98GYPy68QzLG4Z1u5WVD6ykIK1AdhkkxSYRY4hh4vCJ3GO7h+F5w/0uijq/OJqUrikpYD4x8gmSen1v4KSCqHkl8xiWN4z73rmPBmdDUHGWdbuV5fctZ9fhXWTclsE9tnuY//58WtwtjF83nm/qvmHBngVYR1qJj4zneN1xVv5tJXvn7GVf5j5yJ+SyfF9ogHrbtG1yYNRs9KdE5qfmU2YtI8YQE9IKcPXDq+U2hkmx/naEUkqix+th27RtVDZVMmXzFKzbrSQaE/F4PZRXlzP//flyIdYv3v8FNS01rDm0hsKvCkOus3XaVrZ9tU2e/5RNU3j6J0/LhVB9TX0Vg+RtnjZ+8cEvyE/N53DWYVY9tIpX9r6C2+1F2xaFwRWDXmWQryVl30i1D4GuoMDvVLjvXEVdBXet9RdpXSiv/noopLpYukxawWKx3II/LTMOqMWflmnvxKmDEUHbG5LAHX5HZelKPvzVD6/GqDcGyQxISJ2UpDRGgKO1fl9xi7tF3pUHXuuDWR/wj6p/YDtkY/5P53NT7E2ySmagO6ZPVB/qW+uDuixtmbqFXhG9uO+d+6ioDy+aFhisBX8AWK1Sc4/tHswmM2vS1lDbUkuVo4peEb2CDKA0xs4ZOxmRP0J+Tbq3HyT+gC+rvuSvJ/7Kkz96Eo1ag06tk/V1JJ6/43meTXkWp8eJXqNn5cGVvHHgDXlHHejC8Ac7P8bhctDU1kSMISZIEydw55w7IZdbE27l9f2v88tRvyTngxx5sappqcF2yMZvx/+WJ4qfkMcvf7Yct9fNpA2TQuYl8dW8r+TXy6xlWLdbFUXLlAKpL5W9FBK8DdzhK33npM9IKSDemesGHtPdv+luFU+z2+1fAyldNZ7gxkFKl2z/w5G0xdtLFmvUan6282dYR1rD+uED0xgDM1IidZGKO7vTjadl3/WO8h1M++E02dgr6cwESgxP3TKVsjllsishXDFQe912jVpDfWu93MkpsN+rLd3G5kc3hyws7cXcpAD1lqlbsPSxMCJhBF6fl176XtS11gXdR8qAFCYOnygvApJrJfNfM4nSR/HY1sdkYyzds8vr7717suFk0CJWUe8vaJIM5JBeQ/D5fCy4ewFurzsosC3xi1G/YOm9S+VFwocPlUpF7oTcsL73kw0n5X8nxfrVQvtG9cPT9v3mT/p+7JuznzavE7VaQ5TGyOKxi+Wetu2/U4HfufaqoikDUiguL+Z3D6zsUP64/feysxLJ1zLXXyKp4Lqkb1Q/yubs5WjWUfbNCa1A9Hj8P1KtSofH6+XNCW/y1xN/VeyYtHz/ckXZgUc2P0KsQbmqtKalRnY1TP3BVHw+H0mxyvIF7aUUzCYzPp+PGEMMpTNLGdxrsOI12uu2n2w4SbQhWrGTk3W7lXpnvezKsKXbiNJFEWuIDclb3zN7D31NfdFr9HJPWqfHSVxkXNB9BM4lZUAKuRNyaXG1EKmLDGpYHnjPXp+XCG1EhwHitOQ0vHiZtGESw/OGh22HWOWoYu67c1k0ZhFbp23ll+//kltX3kp2qV/jvzCjMMQ99ed//FleAFf+bSUJUQk0exyKbSXPt5zj3nX3MmTFYH6y+t+J0EaEbWkoGetPn/iU/NR85pXM49aVt/LUX55i6b1LSUtOw+clKK9eyZC3z72/no09CLXMq0Z3P/51BwkJ0dTUNHVKIzzcY7vZZObAyQNyz1PJ5VBmLWOsbWzINY8/d5zjtcfJLM6Ud3ZD44ai1+jx+Dy4PC4itBHoNXrOOs7S4mpR1MOXxleqrt2esR0v3qAAa2FGIfGR8TjdTrw+LzqNjvOO80QbotGqtUH5+xL7MvcRpYuin6kf9c563F43ALWttSQaE/H5fETro6l31lPZVBl0D+9MfoeEqAS8Pq+c5SK5upSeWooyitBr9EGqn5Iy5rD4YUFNSSSSYv3qm8m9k4Mkm5Xek6KMIuIi43C6nUTpojhWe4yc3f5FU3KXJcUm0eppxeVxcbLhJCv/tpLX7n+NIzVHSIhKkLOYlL4nnVGrVMKpa+CutaHn7Zm9hzj6XpYB7+7ftFDLFFwTSLo3FXUVNKlrWFy2OCS1TeohKqEkfDZ502TwgUFrwKQ34fa6ee6O5+Qdu9Iu83C1X81j75y98s7Out3KN3XfMH7deEbkj+Ae2z2UV5ez8m8r5Xz89uMkGhMps5ZRkFbAigMrQu4/LiKO3bN2czjrMB9ZP6JPVB9+vvPn3LLyFiZtmMSphlO8uu9VqhxVnG8+r3iNuMg4Xip7iS/PfUnOBzk0u5pZuGchdxfcjeV3Fk7Un+BwzWGO1x0PCXjOKprFsbpjnGs+R+6EXD576jMGxgwM+9QyedNkDFoD66esp8xaJqdzrjiwAq/PS6whVlHF8l8S/4X61voggymJxr0/633+9uTf2D17Ny+VvcSQFUOYsH4C5dXl5H6ay/Lxy3l74tuyENldBXdRUVfBgt0L/Om4jkrONJ4hdWMqsRGxsoa+VA28uGyx/D3pjFqlEm1e5fPUaLp9t96+N3L7J5orgTD4gi4lUKJ48IrBjF47mqyULFIGfB/eUfqhKv2gzSYz9c56jDoj8ZHxpG5MZcGeBeROyGVQ7CBFd8+LH73Ivevupby6XN6B54zKUcwQeTD5QTKLM0NcKNumbWPB7gWMtY1l0oZJivff2NZIRX0F49eN5+a3b2Z0wffzlFw2kkpnm6ctJNtmw5QNPFH8BMXlxcx9dy6/Hf9bWT8e/Lvom2JvAgjbGF0SEFu+fzl1rXUU/7OYooyisO6Zs01nuSnmJvpH92dwr8Fs+XILL4x5gW8bvsXr88qLnORimlcyj1EFo4g2RIcsWJVNleg1evpE9WH8uvGyP1/y/VtHWrFut3K+5XzQ+y79be67c/1PKcYE0pLT0Kq0ZKVkycJm2aXZZKVkIakXXEi+OPD7F2hEO6Ny2R10JPN9JREGX9ClhJMoDvSJK/3glH7QtnQbarWa3E9zOVF/gor6Cg6eOsiUzVP491X/TtbOLN6f9T5fzfuK/NR8OT0vZUBKUBVsR0FWabf6wawPKLOWsXPGTrkrktL9S2qZRp0Rp8cZlIoZeFxFfQX9ovv5d5MqNQs/XMiqh1bJksCBRqii3t9UPCsliyG9/HIPOaNyOFZ7DIfLgcPlUDRaGrWGftH9WD9lPUPihnDfsPt4qeylEN++dHyVo4pWdyuzimbxwIYHmPOvc+gT1QeTzl9kNLpgNEPeHsL4deNl91JFfQW/fP+XFGUUBS1Y/grVxzjdeDrsexu4KCn97XTjaR7Y8AAvjHkBj88T8lQy9925eH0e4MLyxe37IUhG9GzzGXbN2BV079szthOt7nXVd9eBdCTzfSURBl/QpYR79JZEvQKzKQJR+kHfsvIW7n/nfrJSsojSRckiYoXTCmXVyyM1R8gszsSgMWA2+vPn16avldUWgbDun0Gxg3hi5BNUNlXyj6p/MNY2lipHlWLpfqIxkSdGPkHepDw5/35eyTzyJuXx2VOfyfLKgUJgcRFxpCWnoVFrePmelxkUO4hjtcd4fNvj3FVwl9wwpMxaRl9TXwbFDqJ/dH8OzD3AbX1vQ6fWMShmEAlRCSFPIYUZhUTporj/nfsZnjece233UtlUSaWjkieKn1B8+rEdssniZ2aTmSpHFT/f+XP0Wn2IhEPg4lVcXoxBY2DHjB0czjpMfmq+nN4pZRW1l1iW3n8pkB24K5d29W2eNrm2Qq1SK35vPF6/EqfH42Nw1HBWTFqhKF8crh9C+qZ0TLroIMliqX/t1d5dB3KpLqrLRRh8QZcSrljlppibOtQID6dHbjaZ0aq1xEb4F4ic3f7G23mT8vjI+hHJvZMxG81s/GIjC0cvxHbIxj/P/RMVKvbM3sO+zH2Y9CZFA5i9y99B6r3H35OLkwIXh0AjNSBmAAtHLwwpBJu6ZSon6k/Iqo2Sods6bSvnms/x+wd/T6Q2kpV/W8lX574i1hCLLd3GuCHjyDuYx9M/fprcT3P54uwX1LXW0exuxqQ38cXZL1j5t5VUt1QDMCRuCGXWMo5kHeFD64f0juwtu6yke5Gyiw6eOsgfPvsDpTNL5SKuvIN5ZKVksWTvEuIj48kZlcOKAyvISsmitqW2wzTTpNgk7NV2nih+Ap/Ph1FnJGdUDikDUli+fzmbH93MsnHLgnTmtWot26Zto09kn5Bd+QMbHmDRWH+bRMkF5vEpF0Lp1P4nQY1GxTfNhznZcDKsoXT7XIp/c3ldQZk24frXXunddSDdVdQlsnSuEt0d0b9adFSsAt/3II3UROHxuWnzBoupNWmqZRVLpWyTwGKg92e9z5GaI9zc62aidFH8bOfPyErJko1b4Hlbp21FhQqT3sSJ+hO8+NGLctVt2Zwy/n7m78RHxuP1edGqtbz51zflsawj/RWoA6IH8Ni24Fx2gE/nfsqZxjMkGhMZGDMQgCpHFc2uZvpH96empQYVqpCc+6a2JtnoBt6rpLHf19SXs01n8fq8ZBZnynIFT/7oSc43n+8wuwj8aptvTXzLLx2h1qBWqTlRfwKXx597X9NSQ3ZpNgVpBbS4W2RNnuX7l8vFVlLtQkJUAt82fMv0bdNDPovl45cHdbUCv/H6yPoRXp8XjVojF7kF/j0/NR+DxkDewTyeu+M5vD5v0Puw8ZGNxEfEk6gZiENVz922UfI9KWXr+FQeRq8dHTBY9bcAACAASURBVPK3j+d8TKQrTn6tq3rPXs5v+kJFXZ1BZOkIup3AYpVvnvtG3tEDsn91euHjfF3zFXetDX6k1unVcsl7yoAUxa5Lkquhor6CM41nmFcyjzNNZ2hxt8jBQOm/gec9uvlRTtSfYML6CTS1NclG22wyy4ZvrG0smcWZxEfGs2LSCnnhkHamY21jWTZuWVAAV3LdSMeMWTuGb+q+AcC63Ury75LJ2JohN0CR7mfqlqkMjBkYcq+BGvu3rrwV63YrsRGxlM0pIy4ijjcOvEFta63sSgmkfS3Ai2NepNnVzLh14xiyYgijC0Zj0Bi4KfYmzCYzP0z8IeOGjEOtUjOvZF6QvnzJ9BKG9BpC6cxSVv5tJV9UfSEb+8DPYtGYRXKsIpCK+graPG3+hi91FWGDznPfncvy+5azYM8CWdPn62e+Jj81n36mfvxq96/8O2+1j9wJufSL7kfpzFLSktPkeUouQpVKHRIc3zJ1CyqVKshPfy1IJnRXd6xrRi1TcOMgdf2RdkAe/HnUi8sWkzshl1v63MLxuuNyNavZZOZ002miDdGcbDjJe4+/x7nmc2G7LkmplFIxVWZxJnvn7JWzUzoK0ga6KgAWjVkU4hpJ3ZjKntl7FBeOzOJM8lPzZZGwLVO3kPNBTtAx1u1W8lPzQ84LlF6oqK8gQhvBDxN/iC3dJu+spYwis8ksC5pVNlXSO7I3ze5mkmKTONN4JkhpU9ohbpu2jQRjAkeyjqBV+3/az+18Th7H6/PS6m4N0svfMnULSz9eSkX99xITeo0erVrL3Hfnyjt9KVNIOkaSVLil9y2caz6nWEV7tPYoFfXhFS6lz0+tUrNs3DLcXjdRuig8Pg9L9i7hD6l/YPl9y3HhxOfxYTtkk2UftkzdwuKxi4mPjMfkjfcbSpVKTu3sF92PuIg4/vv//Tc/HfRTuaVlb70Zjafjyu+rRXd0xxIGX3BFkXTqUXuDfOCSS2DjFxuZftv0IMP1/qz3ySzOZMeMHYqGon90f0pnlvLa/teA77Nc+kT1CcrRVzIw7XfBw+KHKS4OPnxh0xuH9BrCp3M/JS4ijhZXi2KQN1x2ikRachrnm88HablI+kGSFEN7yeJ93+xj67StvLL3FdndlDshl0RjIn1NfTFoDFQ5qjhRf4J/7fevVDdXB7mLAtU/pXuSJJMrHZVh3WeScU9LTgtxPxVmFBKtj2bL1C0hqqbP7ngW6FjhMik2iepmf5ziqb88Jf/9ncnvoNPogqQzVj+8mkpHJQdPHWTqlqnsmb2HGFVvGlV1uDRtRKqjWDx2Memb0ln10Cpe/eTVkPvdNWMXJl00sYZefDznY9QqDT4v171kQmcRBr+H01Fjkss5R6dXc6bxDHWeOo7XHWdIryGcaz4XpFEz99257Mvcx+dVn/PnR/9MjCGGFlcLXp+XivoKWlwt2NJtsn9Y2tk1OBs46zjLf/7oP/ny3JdUNlVyvO4475W/J+9Y2xsYSVa5+LFizCYz9mfteLwedGqdYt9YFSr6mvoqLhwAP9/1c8xGM29NekvxGGlRUXotKTaJ5fctJ+eDnKBmJXkH83jt/tcUpRimbJrCjhk7UKNmxaQVqFVqfv/g73F6nDjdTgCydmTJO+CijKIgHXkIn8+faExULNaa++5c8lPz5acPW7pNNsCB95U7IRfbIRu7Z+/G4/VwtPYojc5GWcpBUriUZJYP1xyW4zAFaQX0MfYJquStqPcXlrV/SgrU9qmor8CgiaDaUyl3EbMdsvHq+Fc58MRBGl0Niu6yM01nyCyeeMl+8+sdYfB7MJcSOOrMOTq9mqOOr2lxt+DyuIKahkg7u4OnDvpTA5urgv5uS7cRFxHHvsx9ROoiUavU5KfmMzRuKECQmmNBWgEbp2ykzdvGt/Xf8uW5L8namUXOqBySeyfz8ZyPcXqcHK45zLM7nqWyqZId03dwsuFkSFMPIEglsq61Dq/PG7JzXf3wahbsXkB+aj7NrmZe3vtyiJ77hikb6BXRS87Xd7gc9DX2pcHZQJm1jH7R/Wh1t4bsPlc/vBqjzsjQuKGKhlmFijnFc6hsquTTJz7ldOPpoHkE7oAnb5pM6czSoHHCPfn0ieojX6P9NYfGDcW63UplUyUqlSqsq6y4vJhDZw9hS7dh0BhYcWBF0KJb2VSJ1+eVd/PLxy+npqWGBXsW8Ob9b4b18StdC/xPSOeaq0KekH61+1e8PeltDtccDnlCUyrAC2xi3hMQBr8HEy5vuaMfQGfOafBV88jmR3h/1vtB+iztd2lK/nPJ/y35yHfO2IlOrUOv0Ye01csszuSDWR9w68pbgxYT2yEbP0j8AXq1nl+8/wusI62ygalprWFm4cyQgO6OGTvIvjMbr8+LWqUmShdFlaOKQTGD2DljJzUtNVQ5quTF6tDZQ+yYsQMAg8YgSxVIwdm61rqQhWzBngWyT3xEwgjZJRO4w182fhlatVbRMB+vOy6rUbZ523h578sh5798z8s0tTURHxmPQWMIGmf5/uUUpBUEaeBsmbqF1/a/xvyfzictOS1E8tigNcjvXUVdRVhXGfh30Em9kvB4PeROzMXldVFmLaPSUUmj05/NEhcZx51rgiWv2yuESuMqPSVJi9abE970B4QVvlsur4sle5dgS7cFjRsutnOlc9+vJYTB78FcqPhDyXXTmYIRl9efD+3xehSPva3vbfJOt6OdndRV6qm/PIUt3aZ83YCK0LnvzqUoo4hoQzRnm87Sz9RPMT1TcisFjuNoc+D1eYkxxATtmosyioiNiA1JgZTiBr8c9csgNweg6CuXFrJIbSTrP1/Pv/b7V8Udvs/nk3PY2+/eJTfIzhk7UalUiuffHHezvDCmJacFjSN1uVr10Cr0Gr3cFnHNoTUAvDDmhaAeuVunbaW5rVlO80wZkBLWFy8Jqknpl9Lf1Co1Kw6skBcSKd8+8P2yHbKFPEkVZhQSpY2Sj5UWpz5Rffh4zidhv1uJxkR0ah2VTZW8tv+1oHGliuX2C8vFZudIv4uKuhrUWu115f8XBr8HI6Wntf8BRGgicWuaOdl8OqRBRN+ofhf80ejUOpJi/VrnSsd+cfYLskuz+WDWBx3uGAMfwaWd3f9v793jo6jP9v/3nrJJNuczx4AI66Fa2sdKqyAoKIdUA0FJBUwIHn4tiJYHnvIFlGrU8sTqkyKSHijGIKAgBNLKIZiURKEaa1uqgmxAMEhgSSDnzWZPs78/lhl3dmc5Q0Dmer18YfYw85nZmXs+n+u+7utOi0qTVCI2l03irwFJ9ijywXtn7FWUZ4orCP99xkfE09jZGLTkn7B2QsjkcYOtQfqcP0Jx5dfFX4fb42buHXPxer2KnHn1tGpau1p5ofoFduTu4HDrYamBuCglbbI3Ea4PV/z+1ilbpdfEvET51HJ0Wh21J2t5attTsgYoRRlFAEy8aaIU7P3P1dYpW6VjqKmvYWnNUqqmVSF4BQSvIDUk3zx5c9C5e/Qvj1KVW8XiUYsZu3qs4kMoPTadZ4Y/g06j44O8D3B5fM3HY3WJNLkaqMipwC240Wq0NNgacLgdpOiSsWlaFX+TtKg0YjSJkgpnT+MeijKKGJgwkGhDzAWrcy6Gfr47oerwr0GIBlNur4vKnEqZpnnblG0c7zzGvxv+GVRuP37teDxeN5uyN0la+Q/zPmRX3i48GhdtukY8xk50Gj3bH9lOhCGCtye+LdNFl4wv4b3a9ygcXYjNaQvySC/OLOa92vconVTKTck3UdfqkwJGhUWx/ZHtlIwvoWR3iVTR6fa6JV38ouGLZGNudbQqBt4B8QNk+yzNLmVu+dyQgdotuIOcJNdPWs97te/R6eoM0nSH8r75pvUbmruaGbt6rOQNFLivBlsDTsGJ1eZLeOZuyiVrXZYsSDfYGnALbsXv67V6yXoCfEH/ROcJmu3N9IjqISVSxdVLqimVvTP2MihxkOL2DDqD7LhnDZnFL7f+kiZ7E4s/XMwTtz3B/ln76R/XX/H79e31dDg7GNl/pDSeF6pfYOuUreybuU9qaahBQ5QngRhPChGueNrcLdy98m6mlk7ly8YvOdZ+jDZHG7Fh8VLvBPE69D+eRF0aLqcgadzfznqHW5K+T6KmBzpH5AVr37vLA+diQZ3hX2MI5Tv/+rhleAXQaGDM6jEhKRSX4KKv8Xo+efRTbO52XIKLDlcHf/7nnxk3aFwQJbJl8hbWPriWuPA4jDojRr2RmbfPlLj7zEGZVORU0GxvpqWrhT6xfZh661RJt64kBfRPTj647kGp+jJQYnms/ZjiLPBE5wm2TNmCTqPD4/WQakql4N4CjHqjIo8dExbDsk+Wyb5T/K9ipt46laiwqCBePD3WVyXqX5Uqulje+cadshVL4NjEzlNFGUXYXXYqcio43nFcUqE8M/wZfv+P3/ODHj8I+n7moExcgosUUwqrslbhdDv5uvVr+sX1o/ZkLQMTBkq5hmRTMhUHKhg5YCSHWg5xfcL1iuMxaA0hcxhipWyHoyOkFr/B1sDs8tlU5FTws+/9TKKSIgwRGLVGro8fyNIxy4JoEZE6rGutI2tdlqT/7/R0EKZ3Y/LGKnajcjm/9d4x6WIlStKmacWki71g7Xt3eeBcLKgz/GsE4qy+TXtS0Xde7P4j+oeHMhwT8KDVaajv+Ia7S+7G/LqZ0atGk31LNgadQQr2Ysclm8tGssnX3GJEyQg+PvIxWWuzpEbhs38ym9qTtSRFJvH4Xx/HI3ik4Fmwq4CCewtCVtuK+7g19VaqplVhMphkYxaTlP6zwLcmvIVBa2Dc6nHcsOwGFlQsoK61jnnvz6O+rZ6X73sZo97Iyv+sxKg3Sn//1PxT6TvjVo9jzMAxXJ9wPQ+9+5Bk2Sz6zDd3NaPX6KmeVk3tk7VU5VaRFJlEl7tLlkANrAoVu3nVtdYxKHGQ1PB8aPFQZpfPZtGIRfy97u/kfD8HnUYn+37moEyeGf4M41aPY2jxUEatHEWXp4sdB3dwrOMYSz5eQmNnIxv2bmBEyQjaHG3cknYLDTafSipnY07QuVrxwAo0Gg0NtgaGFg+VrTTqWuu4IfEG9Fo90cZobky6kbcmvBXyeDyCh8f/+rhUzdtsb0anMRBLEiavLzD7O1cGuqeKXjzXL71eqsyG0B2rLpX98JVQpXshUL10LhO600vHf1ZfMr5EsVOU6CMidhZSKv5Z8cAKltYsZcnY1xiu4Fmy/ZHtmF83h+wTO79yPgWjClj5n5X8/LafByXp0kxpuL1u0n/37Q310aMfKTYy/+jRj7A5bbJ9vDXhLRIjEqUOUKLKx+VxYdQbCdeHo9Fo+KLhCzbs3cBPB/2Um1Nu5lfbfyVbRYjBU+S0A5Ow4vFW5VbR/7X+QWMTm3FXTaviZOdJ6SEYuJ0hvYZIvVa/bPySgl0Fkr/Prum7+M/x/wT525RPLeer5q8wJ5p9lhIuO31j++LxeqSeuf5jLJ9azrz35/GbUb+h2d5Mz+ie/O3Q37in/z14vB5qT9aSX50v2UovGr6IQYmD+Pz455TsLmHxqMUcajkUdPyZgzKDCuk2T96MUWfkuM23IvE/HqW8SVFGEdfFXUeXuyuIExcdLcevHX9a/xzxYSH2QtZotCBo0GhQ7HR1pg5ZZ8KVxOF3i5eO2WxeZjab95nN5v+YzeZdZrP5tgvdpoqLC3/eMdTMXZyhiNyotcPKwr8tpCijSOJaF/5tIWW1ZbhCdBESnSJP1ydW8Ar86s5fBblOZq3Nwuay4fK4+NcT/2L64Ok+K93IZDZP3hzkXxNjjAnaxyMbH6Hd2c6WKVv49PFP2TJlC13uLpJNydhcNoa/OZz036Xzp0//xC9+9Atml8/mWPsxWYHOkF5D+M2o38gSmKG4/S5Pl+K5TDYlUzK+BAC72y4lk/Or82WzaGuHlbjwOLxeL7PLZ0vBcd2D62jt+pYTNuqNvDbmNdKi0iTfm+uXXs/U0qnotXoOtx4O6XjpxcvTP36aZnuzb6WwbTaD0wZzd8ndDFw6kBmbZ/DSPS8xpNcQaupryFiTgcvjklYUTfYmbky6Mcht9NXRrwb9hhlrMjDoDITrw2XHs37SevKr84PGlhCRgBevIifeLrRIlM2tqbdKv41owVw4uhCDXi/N4q9b2p+73ryL2pMWZm2bid3TeUmol1BeUVdDwhYuDoe/FfilxWJxmc3mnwJrgQEXYbsqLhL8eUelMvdN2ZvQa/W0605g0ITRL3IgH+buwuV1sO/kPnI35cqShi6PS5Gv1aChOLOYMF2Y4s2WEJGA0+PkROcJxfePth8ld1MuW6ds5cnbn5QphIozi1n12Som3jSRm5NvRoOG8qnlaDQa6tvqJX/2+Ih43B43Rp3Rp983huH0OHn7s7clzXqyKVmicgSvwI3JN0oB5aV7XgoKnqH49m9av1Gs6F1QsUBWHPbamNckdcz8yvlU5FSgQYNGo2Hyhsn86f4/yfT0glfguO24TMdfnFnM2gfX0unqlFUr55XlUTWtCrfgVhzjweaDUtEXQO7gXFn1rUiRibUR6bHpRBoiWZW1Cq/Xy5TSKbJci1aj5ZvWb2jsbFT8DY+0HSEuPE6We+hydyk2UI8Pjw95LTi9XaDxTUDQoJjLqcypVGy2Uzi6kP1N+y+KBFMJSl5RVwsueIZvsVjes1gs4mPzI6C32WxWcwOXCWfTFzOQd9RqtLz/yPscmHWAndP+Trg+nJ8UD5G4zq8792PyxhJHSpCyY/2k9WzYuyFoxic2yZ5fOZ+e0T0VZ742l40wXVhIp0fRTOtQy6EghVBeWR7zh81nx8EddLm7aLI34fF6aO1qpU9sHzZM2sDHj36MSW8iKTIJh8fBvW/dy8ClA3l669Nk35ItOWKOWz2OWUNmMX3wdLQaLQebD8pWJoHjU8oFlGaXsuyTZVInq30z97F1ylZerH5R1i0rryyPE/YTUjMRa4dVauLd0tXCsD7DiDRESmPLWpdFQmSCYktGh8fB2NVjeW3Ma2yful2a6Z7sPMniDxcHdaVa8cAK8qvzmbhuolSvcDpjufTYdMp+VkaXu4vEiESO245Lq5Oy2jJGrRyFw+1gRMkI2h3tir9hg62BjDUZhOnCSI1KJcWUgsvjkoqg/K+jee/PC3kteLwePj/xHxo8R4jWxvHq6FeDVnTWDmvIY8mvzg86H0qNd0KhO/rNXg5cbJXOk8Bmi8UinOsXT3FR32kkJ0df1O0JXoHPGz4n8+1MadZT9nAZt6TcgvZUM1DBK3C8o4PKnEr0Wj2NnY2y4pqN2Rt5vup5aYY77855PuWNtgm9Vk+qPpXl9y8nISJBKmsfO3CsVOWZYkohxZSC0+PkyxNfkmZKQ6PRsH7Setl+SrNLSY1Mxe11857lPUXLgoV/WwjIKRR/d0aD1kD2LdnMe39e0Gzv3YfeZfGHi/n1iF+TakqVzWJzB+cGacwf/cujbJmyhXGrx5EWlcaKB1YQrg+XksVivkL0wu8T24fVWatxC27fw0bw8PSPnyavLI/7Vt1H5qBMXhn9iqKRWkJEAg63QzrOcH04glcga20Wnzz2CZ3uTipyKnB5XLzy91ckL6HA7XgEj2Sf7G809u5D73Ky8yS9ontRlVslUXf+2v1oYzSlk0pJMaWwefJmibcHXzAcED+AipwKvF4v+5v2k1+dj7XDyvpJ62l3tEsrqFaHj2pSMkwrGV+C4BV8/woCXa4u3IJbcv8U9fBif4Cy2jKsNmvQKqk4s5icjTlYO6xsmLQBe3gbEZqIoHMSqkK3yd6EtcNKWlQaHz/2MQ63A6PeSIopRbovLvS+EnGx7+lLjTMmbc1m87+AviHeTrVYLJ5Tn/sZ8Dxwl8ViOX4OY+iHmrQ9L4gJ1sALfue0XXi94Pa6EPAwp3wOZbVlIZOPhaMLKdhVIEu0Zg7K5OX7XpY6HB23HWfiuoksv3+5FGzEYCw2/gjThXGs4xhZa7MY2X8k84bOQ6vRSoGs8lAlFY9UgAY6HB2E6X02vAeaDsgCkDjOwMSx+HqoJJ74etW0Kvov+TaZ6t8UxB8HnzrIbutuiWq6Lv46qVx/+uDpQYllMfEsJjjFSlKtRovgFTDqjNyz8p6gcW2dshWdVseehj2U7C5h5u0zSY1KxeF2oNVoZTLWDZM2kBCRILORAB+lUXBvAYJX4FDLoaCAXZFTwdzyucy8fab0+/iPoXxqucx5UjwWa4eVzZM309LVItE3/g9ga4dV1qjkidueIL86nzfHv8lvd/2WZ+56hqPtR+l0dRJrjJU1eVk/aT2R+kg0Gg06rY5wXQThugg+tX7CoMRBUoGceB3dmHwjB5sPBh2b6I3/fNXzsgdq5qBMfj3i10F+OmIfg6U1S3luxHPnzLGHuq8CE77d3dTofJK2Z5zhWyyWH57pM2azeQLwEjDyHIO9igtAKE2w3dPJvW/dK7sJrDZryORj/7j+vJH5hqTyGNJrCLOGzJJ8cPwfFGJzcCUljuhUmRaVxuRbJnPfW/eRFpXGouGLeHb4s+Tfnc9x23FJlrlo+CIGxA9gUOIghvUZJj08+sT24e2Jb9Pc1SxbxovjP5PffWCOQYmDzxyUSUtXi/TgEINt1bQq6tvqiY+Il6leRFpFVJsM6zOMcH24zKlx8ajFbH9kO422Rum1hXctJFwfzsMbHsbaYfUVnlne4+FbHyYqLEqqQBX3MXHdRCpzKtmYvVEKZKJqKNAqeM3na5h661R6xfQCYObtM3nni3eCZswbszcGefbnleWxI3cHu627Odp+VPaQCOT1TQYTuZtyqcipoKmziUXDF3Gw+SCVhyrpH9efcYPG0epolYK9uA3/GomN2RuJMcXS7mrF4XbQbG+W6hdq6mukymt/JY+4HZPBxIS1E6jMqWT38d3ScT034jkp3+TGhVajQfAK/GbUb3j1769Khm7nao52tWvtT4cLpnROJWr/D7jXYrF8fcEjUnHWCGWNsL9pv+LN6x/4xFlV75jevtmmx8GO3B0AOD1Ovmr+irSoNNKi0rg+4XqpSYdRb1RU4qRFpdHY2cjiUYvx4mVBxQJphi7OuBweh+LMXQy2L1S/IGtwEegaKY7/TH73Go1GVr5fsrskiGJ6ZfQrQZa8E9dNlAL6zrydije9OdHMoacP0WxvllYDIp3R4eyQrQg2Zm/E0mghxhhDwagCekb3pKWrhZlDZjLizRFBbpbiPjxeD0adUSpIS4pMCjKOe/Qvj7Ijdwdft3wtPZjFWfW2/dtYfv9y+sX1Y3/TfgSvoEg1ebweZpfPDllkF9hoRoOGVkcrNybdyMMbHmbdg+uwuWzkV+WzeNTi0z6En696nsWjFtNga8CoNxJpiOQPn/5BlqzWaXSkxwbbZ4gUlxadYqGVSRcbJJVc8cAK9jTuoaa+5pwDdaj76mrR2p8OF4PDLwacwHqz2Sy+NtJisZy8CNtWcRpEa+OCfElKs0uZsXmG7HPijTevYh7FmcWyPqoj+4/kFz/6hdRUQ6m3qn9AqZpWRcn4EvRavYxnV9Lsi8ZZ/hrwutY6CkcXBiXgJq6bSOHoQspqy6hrreOlD16icEyh7MYTk6eB1rv+S/kVD6xgbvlcCu4tkIJJelw6eo1eUo44Pc6Q5luicVsofviz459h1BtDmqP5vzZh7QQqcipwup3YXDaOtB3xqWpO8eyikVhggDMZTBztOgr4Hr6hOH2RHw+cVZdPLaexs5F737qXtKg03sh8g515O4O08QatgY+mf4SAIFk5+2v+bS6brFHJZ8c/k3rcppnSaHW0SiuD3MG5IR/C4opRXM2IlFLeD/KYu32udOwApdmltHa1yiqXS8aXkDkoE73GINfQ63z0i0fjDqnWmV0+Wxaoz6aXgyhN7u6OWJcCFxzwLRZL8sUYiAplnO4CbRdagixyO12dQRK4zEGZJJuSefW+V0mNSuX3Gb/nJ2/8hLrWOubcMYdxq8cpBuET9hNBge1I2xGSIpMwGUxSEIkLj1M0zqqeVs3CuxZK1MjmyZtJj00/LSUDSAFi9rbZQcnTvrF9eW3cawhegepp1bgEF06PE7vL19NWTFQW3FsgyQzLp5bzwq4XmD9sPnO2z+Gle17iq+avQgYoOH2XpoJRBad9WPi/JkoTxZl0WtSp4rLYdEr3lrJl8haO247LAlxpding8+TpGd0TDRrFgO3xKj+02hxt9I7uLa2kxPMfyHE/vfVpnh3+LBqNJkgCmhaVRpe7ixOdJ3j1vldJikzi5V0vU9fqq5mozKmUqWSUzpfY9cp/NejfRrF3TG+Wjl0qWxXtyN2haJldmVMpC7iBxYRK5+HmlJupzKkkWhuHC+Gsi6b8tfb+q4mrRWt/OqheOlcwznSBurxOymrLZMv1Ib2GyOiLzEGZPDv8WdlNX5pdKmm5dRqdIi8+pNcQRUMsvUZPg61BFqBEy2H/maqoZPEvzhELj0LZ1Pq7ZIoBIjEyMaiic8OkDbQ52ogwRHCs/ZhiAlen1UkBbt7783jitifQa/QsGr6IpTVLefrHTwfRPGIiUzpWrW9VoNPo+LrlaylhG4pSUvJvb7A10CO6B4WjC9Fr9aycsJLWrlbWT1pPg62Bdmd70MMya20WFTkVAHzd8rXsXIsBW3SYVBqHKcyEU3BKnbP8++PaXDZeHf0qU0qnUFNfwxO3PRH0UM8ry2PX9F10ubtkaiB/mkTcl//KYM3nayjKKKJ/XH8OtRyiy91FTX2N1IgkVAW2f13B0fajisFbi04WcJWKCQPPw56GPcwuny3dMw6djaMdR2U9hEP1f+iOfrOXA6pe/grGmZz5lHw9rB2+ZhOFowv59PFPKRxTGFRok7XW13wEkGgF/wpc8cY81HIoaPuJkYmKNELBqALJ70T0S2lxtEg6bhFuwc33Ur4XpJFeP2k9Jbt91an+nYp+OuinQRWdE9dNxO62Ex8eT8nukiCNMM3dGwAAIABJREFUd3FmMW6Pm+LMYqk6+MakG6V9zxoyi7yyPJ7c8qRUSbwjdwdRYVFYO6ySt3vuplwGLh3I3SV3y45BSZcvHk+gDr5kt6+D1+zy2QwtHsp9b91Hl7uLtZ+vZVDiIJm/jghxZeD1ehVXTkvGLmHb/m3otXpFPx6n24nX6+W6+OukWb74u8zYPIPmrmZpX6ES+Z2uzqBaCNHDKD02nXB9OI2djczYPEP6vafeOpWkiCTmV8wnOiwal8fFzrydUl1GqArsF+5+QaqgjY+Il9xbRSjx50rFhIHnQfTxGb92PA6dDWvnUdl4X7rnpVMrrqs/GXu2UL10LhPOR8LVrjvBgKXXBb0u+t4orQDEJtdWm5XFIxcTpgsLat4BUPtkLfe+dS8j+4/kv3/y3zR3NROuD5cpK5SSqxU5FQxcOjBoe/tn7ZclQeFbSV3GmgyZzDEtKo1X7nuFXtG9cHgcHO84ToophUhDJM32ZuIi4uhyd6HVaPF6vdyw7Iag/VXlVlH4USEL71qIw+OgzdGm6Duj0Wjwer3otDr++I8/MuP2GRxtPxpEj1RPq8YtuPHiRafRBckiRXllXlme1IRElKvGGGMI04VR9EkRj/3XY5zoPCGpdBaNWER+VX5Qz9zC0YXcnHIzB5oOKEplizOL6RXTC/PrZgLx5UyfXXCYLozf7vptkLtnwb0FdDg7aLI34RJcIaW4WeuyQkp1t07Zyk1FNwXte2feTpweJ27BrSj/rMypxIuXcF04ne5O3IKb0r2l/KTPTwjXhyteiwefOsiXJ76UOob1i+3Hgspvq5WVaJdA6WSgD5D424r4+umvGf7mcMXr85ak75+Xv853UpapovtwNmqBnlG9pWCl1+qxu+z8ZtRvCNOFMWrlKApHFypuw6Dz2d6G6cJoc7QxtXSqVBwjeqPXtdax8G8LKRxdKGmkW7paFLcHyj1RzYlm5v54Lo/912OMXjVaeoiIbQZFisYUZsIjeHB73bKuSeVTy0PSP2W1ZTw34jniI+IZVjxM8RyKCWdR2igGcn9Ovqa+Bpfgkh5YoRQ6TfYmijKKpFzDU1ufYtaQWcRHxFP0SZFUFCbmG14Z/Qpuj1tRIXNj8o1EGaLoH9dfsQhNq9FyoOmA4rF/0/oNj//1cXbl7WLRiG/bRIrqpj//88/k/TCPd/7xDr+681ch8yXpsen0i+0nk4CK+w+VtO4Z3ZMXP3iRGT+aIcsdiQFW8AqSRYb/9tZ8voY5d8xRlMee6DwRlEP4fcbvKRz9OwxaAzqNnhZPIwb9tzkskzdWNm5rhxWjzsg3rd8oUnzuEEn6gQkDvxPJ2LOFSulcwfBv8jCk1xA2T97M+4+8j0ajwWPspAkrNnc71g6rb3bq9RIZFolRZwR8F7TScleszDzUcginxylV2ormWbUna6XP19TXULCrAA0a8qvzEQQhyAZ3w6QNEp/sj/TYdCwnLUy+dTJtjjbqWusUl/UT103ki4Yv2G3dHVQRO+/9eUE2DiseWMF7te9RlVtFtDEag9agSAMIXkGilEJV24oURe3JWum9UOX+DbYGstZm8e9j/2bEmyOk4h4NGu7oewcvVr9I4Rhf9XGDrYFmezNevNLvJ9IWmydv5kTnCfY37ScqLAqTwURlTiU783ZSOLqQpTVLSYtKI786P+i32zBpA8/ueJa61jrsHjtvf/Y25VPLpe++9MFLjBk4hgUVC5h661RJRht4LGJeYUHlAjRoqMipkO0/LjxO0aph9rbZ5Hw/RzJI86dHMgdlYtAZyN2UK9lfl4wvweFxMPXWqSyoWBC0TSUTtryyPJyCk1iSOGFvlNl+iBbHHo+XtMieFGUUsXfGXooyilj4t4XMr5wfdM42Zm/EqA1XPA8RusjvRDL2bKFSOpcJ4vLvTLKwwPejtXHY6cAa0G5QNBMTm4UEJvX8mzz7V8T2jO7J7G2zZeZeAKs+W8WcO+ag0+gA8Hq9jFk9hrpWn7oGIMYY41OAxPQmxhiD0+PkQNMBNuzdwM9v+zkdzo4gOd3K/6xk4k0TuTHpRu4uuTukPXNVbhWA4nufPv6pVA37VfNXbNi7gWmDp/HIxkeCqCzxuPzVKKKyRmnbO/N2EmGIYMbmGRIFEEpmKq4GxMrd9Nh0lt+/nP7x/TnecZyhxUOZPng6v/jRL3hw3YOkRaWxdOxSAMVzU/hRIYtHLeZo+1H6xfXjs+OfSSspg9bA4399PEiyGaGP4J6V90iB7OuWr+kb25eEiARFquqDvA840nZE1ozF/1jEc1/4USEv3/cyeq0evUZPp6uTFf9aEZICU7I7Lp9ajt1l5+ebf65YZ+ERPPSNTcfldkvqF5fXwYClwV6LX836CoPGeNqKV5HSfK7quSB761dGv0KzvZkjbUco2V3C/476X0Ub5gtxurwaKR014F8mJCdH09TUcVrVTahuVGmmNElGKSI9Nl3yglHiZ0X+2H+5L/rmlNWWyR4C/eL6Ye2wBjXvTo5MpsvThcvjYsPeDTx8y8OyytLZP5mN4BXoFdNLqqr1D04J4b5/RaXI4pGLsbvtITllQHE5XpRRxI1JNzJ722xyB+fyvZTv8T/b/0firp0eJxGGCNKi0oIUNWfa9tYpWzGFmbirWO7vnzkok8IxhYrBTuS/wcenr/inLzCKdNH0wdOZc8ccjDojxzqOkWZKY9RbwfmNwtGF9Ijuwc/W/4zqadWSv31ceBzPVz0fVBfhb4dQnFnMoMRBzNw8k7LaMnbm7WRo8VCZ91CTvYm+sX2ZuWUmi4YvwpxoxnLSEmRdIPbOTY5MpldEOq2ek9z15l2SV5IS765kV/HRox9xrP1YUJ2CuJ+S8SX0julNPKlSkHUY2hR963dO24VTcJ42hwXfTpA0WhC8HjyCgE6r5amtTwXlTT7Kq8EtuC+a1PJqDPgqpXMZcSbVjdL7E9ZOoMPVocg/ipLKwNcTIhKw2qykmlKpmlbFgVkH+CDvA+LC46RgLyo3hhYP5T/H/xOk5JmwdgIerwcNGow6I2MHjmXkypFS96WXRr5Ez+ie9IzuKRUx1dTXkLUuixElI8hYk0GSKYlwfbgUcOdXzifGGCP1sRVpqvKp5USFRfFe7XtBvWOLM4tJjkymtauVJ257gltSb0Gv1ft0+qcohcf/+jguj4uppVO5u+RuBK8QdD5KdpewYdKGIIoiryyPp7Y8FdRbd9GIRYTrwyUnSzHYi+oP8XMR+gjGDBwj1Qykx6bzxm6fTYXH62FY8TDq2+sVf6cUUwrH2o9R11pHh7NDSsTGhcfx7PBniQuPY8uULdQ+Wcvy+5cTFRbFygkr2TplK27BTaOtkYV3LeTTxz+V1C2BSinxXGSsycDhdgS5n4o0Tb+4fvSKSKfN3YJLcEnnLRS9pSRBPdZ+jJLdJUGtJsXjTYtKY075HDq133r9RwrBvWk3ZW8iShOHXqtjZ95OWY/ewByWx+Ml3B2D0RlDhCueKE8ibsGjmDfp8thDdsg6V+h0Gp8i7ipz01STtpcRZ/LoCPl+CK9z8d/A150eJ0vHLpU6JtlcNtKi0kg1pbIzb2eQT0woad6RtiPM2T6H4sxiutxdkskaINPiiwVVgeOob6unyd4k9Vh1uB0cbT9Kj6geVOZU4nA7ZN2pVjywgr/X/Z0duTtweHzGYg22BsBXcZpfnc+ycctIiEhQlPeJM+9Af/ce0T144rYn6B3TW5rNOj1OtBotBaMKfGOMTJFp1TtdndhcNtZ8tobyqeW0OdqIMcYw7/15UvDfmL0RwStIY7HarNKsuHdMb75u+VpKMCudn6TIJOZsn0PmoEwcHofM12dj9kY0aLCcsJAQkcCyT5Yxa8gsWXJX9C7KHZzLe7XvKdpFPPTuQ5LqynLSwoCEASy/fzm9Y3qj0+qob6vHarMiCF4O2b/tMCWOu2R3iaI3j9jsJpBKfPrHT9PmaFM83sOthymrLeO39/2WyFP9ZZWKnKK1cVK3q8DtPzfiuTMmWS+1NYK0El/Z/V2vzhUqpXOZkJwczTfN9czaNlMmo/v74b8za8gs3IIHvVbHXQqtA1dnrSZMFxZ0s2s1WtocbUFFUIkRiTg9Tua9P4+y2jKJ09SgwS24iTREcrD5oKSumHfnPEW6ozizWBbQ/BUk/vpwUbceWC0aY4yRXDEdbgfRxmjmls+V5Q9E6gW+pVG8eHG4HXS6OjnceliSWRZlFNEvrh92l53blgc3VvOnGcQ2g2KgeHb4s6SaUml3tjO/Yn4QXSJaUqSZ0ii4twCNRsOx9mNEGiKl5uonOk9gd9mJNESSGpVKTFgMrY5WBr0+KGgstU/W8sjGR2ReQoFGc3/49A9UHqqUOVn6n38xUG+evJkwXZhkiBf4mR7RPbC77ESFRXH7n28PGsvOvJ10ubtY+LeFLB65GED2W4lJ8dv/fLuU8/Eft3+ls+jyKSa8e8f0JsWUgkFrQBC8dLjaOWE/gcvjCsot+btvnk4KGcqt8oNpHxAlJJwxqF7qNoRn66Z5qaFy+FcwkpOjaWm1cbDTIuPVS7NLJZ22WBXrz6Wvn7SecF04JbtLyPthHnqtnnB9OE6Pk1ErR0m8eY/oHsSHx0tB3l8ON/mWySG54HUPriNcH45LcPFC9QuyG7ulq0WmbAF571p/iCoUh8ch0Qh/+McfGDNwjMThi/1bv2n9hmd3PIu1wyrNxM+UKAXYN3MfHsGDXqeX5Jb+4/Kf1YtdpQxaA07BiQYNTfYmIg2RGPVGxZqBnXk7aehskP0+gaZupdmlON1OdFqdbPaslBsYu3qs9Pv0je1LpCESnVaHUWfkYPNBtBotTfYmekT3UOzb658crsyp5Pql1wd9ZmfeTnrH9Gb4m8NDjmX7I9vJ2ZhDTX0N26duD6mfF6tvxd9z3p3zuK3nbXQ4O2h1tNJkbwqpkU9IiJJECc00MKV0Mi/c/QJ9Y/vyVfNXkr+++Ju+nfWOxMMH4kz1J2cDkdu/FNYIF2N8FwMqh3+Zca5dcTq8LUE+IVlrsyi4t8A3Ix2cy666XTKJ3ovVL9Lc1cxDNz/EuNXjyNmYwxcNXxCmC/NRLKN8FIvdZWf0qtGybkuP/uVR5twxJ2R/WbGZRpvT1/5u0YhFEq8/auUoYowxilSPuJz3x7A+wzjWcYy7S+7m+qXXM3LlSB77r8ekYP/SPS8xY/MMblx2I4//9XGpylHUtCvJNcVZJPiCkrXDikFn4FfbfxUkvSvOLKZgV4H0oFj84WIOtx7mrjfvYuDSgYxcORKdVsf/ffR/Ic3I7G570O8zcd1Ecgfnyn6vmPAYabWlJHstzS6ly91FaXYp1g4rWeuymLhuItYOK61drdSerCWvLE/qcHWs/ZgiTy5aTdS11klWEYGfSYpMotXRGnIs7z70LjqNjjSTT54aaYhUPHZrh1WqvgYky+KDzQexdlhJjEjEnGjG4XGwdNxSDs46JOvnKngFuvRttNCIQasnzZTGfavuI3dTLg63g1fve5UtU7ZIs/zT0StKFeTnSsmI3P7F4Osvxfi6C2rAP0+Iy8ZhJXcGaYRDwSE4FG82L15GlIygZHcJ999wP032JlJNqfyo5494ZfQrpEWlEWOMYfn9y3lz/JvEGGMkpYzIkfeJ7cPI/iODtm3QGkImdufdOY8lHy8hXB8u+dT7Bzux8Mcf6bHp6DS6IDuDGbfPCEr8iv1KQwXzRcMXSck/fzuFwHGKAT3aGI1G4+uUJBaEVeVW8c7EdxiQMIBVWavYOmUraz5fw8SbJip61Ey8aSJ7GvYoHpdWo1Ucw03JN0mJw8BzWlNfI41l38x9UmHW1y1fs+yTZbz/yPt8OfNLtj+ynf7x/Zm1dRbP7nhWFphDJZT9k8OAYjB/eZdPSpkem05NfQ1rPl/DlilbsDxpYUfuDtZ9sY7DrYcpyiiS8jdKx95ga2BA/ICgh+jK/6xE8Arc+9a9XL/0eiasncCBpgO+ZianAqlOp+Hzhs+le+GuN+/i2eHPkjkoU3pwOD1OppdNx9phPWOrQf/6E3Es59Ke8FLjSh/f6aAmbc8ToRQ3oZotCF6fXEwxmaTVSw6R/pWg/tTLhkkbWPbJMqlz1Su7XlHkhf3NrTIHZaLVKO+zyd5EQkSCVJCk5DiYX51PaXapjOJYP2k9R9qOkBiZSNW0KlweF/ub9kvKDn+ICo9Q7pgDEwZy3HZc8lBRGmd6nI+SCNeH09bVhl6jlzlHAiweuViSVYoz7PjweMV9DogfwLz35yk6Ox5pO6I4hr2Ne5ld/q1zpxhg/YP+7PLZFGUUkWJK4ZdbfylRHv/9k/+WukkVji6UHCbFh0SKKYVeMb1YVrOMwtGFfC/lewheQZYcLs4s5lDzIek7t6beilajpdPVycnOk0SFRUnU4ORbJge5Yy75eAlLxi7BZDCxoGKBYmXv0pqlzLx9prR9wSvwyMZHQvrfVE+rRk+kdC+I7QDFz0xcN5EPpn0gq5Z9O+udIHolVF3KlexWKY7v48c+xu7suuLGdzqoHP554lx4PJ1Og03XjBYttU21smRWcWYxfWP7Sl7joXjpzEGZ/GbUb2i0NZJiSmHfiX0hNesZazJIj/UVwoTq/zpr6ywKRhWg1+oZWjyU0kmlittblbVK2mdqVCp//Mcf+fCbD6UkrcjN35x8c5BXSeagTBbetVAy2QrcdvW0avot6QcoFzutn7Se3//j91QeqmRH7g6OdRwLKiDSa/VSGb//tkPVKJRPLedo+1FijDEkRiZK3vjzK+ZjtVlPm0cQvx9piKSxszEoF5McmYxBa8DmssnqFRYMW0BseCx2lx2X4JIF2/WT1qPT6IiPiEen0WFz2mh3ttPY2SgprFJNqczcMlNW9JRfnc/6h9ZjtVmlIq/izGJZBy3/a+j7qd8njhRsmlYMej02V4dsjGKBmrXDykd5NXR6Ohi5cmTIQrmvZn1FtCf5nO+FwPviUiZXLzWuRh2+GvDPE2ebqfe/qMVqwxP2E9LNnBSRhE6ro8PZEbICdV7FvKDerrHGWMWCmL0z9tJga0DwCvSJ7UN9Wz2CV8AtuAnThdFkb2Jw2mCa7E2E68OlBKaSUVrJ+BJ0Wh1JkUkYdUaKPinijr538MMeP2RP4x6ZWdmwPsP42S0/C2rGEhUWhUFroLmrOWil4PV6ZWX1ogGWOcmMFi3tznaf/35EEna3XTGwhzJz++SxT2hztCk2SfFXnpTsLuHV0a9KCVExWXlT8k3sbdwbZML1yWOfkBqVKlWjerwePF4Pxf8q5rH/egydVqeYEF6VtYpwfTgvVr8oJcaTIpP48z//zJRbp9DXeD02TSvDSu4MKmCLMcYwrHhYkLJpz4w9sodaqN69O/N2kh7TD6NLfl12aluxezplTcvFgKvVaTjUWcuxjmOKD+ud03ZJ2ztf1Yo7rJN/N/wzyPTucqtdzhdXY8BXKZ3T4HQ2CGfbFcef+jncepiS3SXkDs7FZDDhcDv4zYe/4YnbnsDhdoSkXgKX1fnV+RKHHvh5scH14pGLmVs+VwouPaN78vKul6XZcqQhUtKHi0v8hX9byKqsVfSK7oXH66G+rR6jzoggCLS723nsvx4jTBfGSftJmdmVOAv++Y9+TvW0ahweB2HaMF744AXe2P0GANMHT6d8ajl6rR6Hx8Grf3+VPY17ZNSKtcNKhD4Cg9Ygo2hKxpdg1BtPm0AOPA8JEQms+2IdO3J3SNWy4kx99/Hd0upn0YhFMipHLB7bPHmz4oonxugLRL0KewVdLz//0c9DNiVJjEjklb+/Iv0evWN6o9Poeer2X0rXlUvnq8Ooa62TKnnBN5s+OOsQGq2Gn63Plh5Aoj+RiFB6/7SoNCIF+XXp8XgxemKI1MUSnhQZRLd4PF7SjQNJi+wZZK62KXuTbHsmbyxlD5dJtE6oe8EfOp2GI6fsigOvo2vJrvhyQ53hh0Aom4OkyGT0GPB43Xg1XrxeAY8ghOTx/Je7SrRFyfgSBK9AfHg8XryKfjn/b+j/42j7UZkr4fTB05l5+0zZrHnz5M1EGiIRvALHOo6hQcOU0ikyiaFRZ6TV0Sq9vnnyZv706Z/IHZxL39i+CF4hqNlI0T+KqDxU6fOZD2GLW5RRBCAVRx23HZf61/rPVs2JZsnjRzwni4Yvon9cf/ad2EfBrgJeve9V2erFX+YYuN9QtQK9onvR7mzH6XEqroQOzDqA4BVo6Wqhw9lBjDFGtjrZPHkzTfamIL+e3//j9ywYtgDLSUvQzLQoowiH23FGaiwtKo1EXRoupyAb05lmyoHvB9JwSvUQ7z70Lukx/dF0Gc/h6pfDEKalzXsSl+DCoDUQo0kMGntikon6lmNnzbmHOtZVWavoG9MXt+AJ2YLwSsHVOMO/JgP+2fS1DHVBLr9/OXqtXnZTBfKO/jeIXqvn9ZrXeeXjVwDfTVkwqoAe0T040HRAWkq/+9C7RBoiOdF5grSoNCIMvpnu0fajQbr8dkc7Sz5ewsK7FhIfES/1adVr9VKAEguPlCgQf8rBP0iE0nEvv3859626Twq8Sj7p+2ftR4sWnVYnqV3iw+ODumOtmbiG+PB4WX/TQJ7c36tGxMGnDnKk7YgsAIsaeavNJykcED+Aw62HeXbHs6ycsJL73rrvtNr0FnsLT217ipr6Gob0GsLKCStpsjeRGJFIdFg0glfA5rLhFtwcaTsi1Q5sf2S7rM9vcWYxqaZUpv9lOkDQQ700uxQNmqBZciBXHdJLKbInRo+vfaL/+5mDMhXtkeMj4jnReYImexPXxV1Hiq73GZOkp7tXzoZnP9fgp8T7D+k1hKKMItnxnA+nf67HeL64pgO+2WweAVQCT1ssltfP4av9uIwB/2wuYJ1OQ5v2JHUtX8tm1eDjyJVmmuIszBCm5SvbPlmQ3jJ5C+3OdrrcXdhcNq6Luw634OZw22FMBhM6rY7eMb1ptDVKlYwajQaXx6W4L1EN4hE8ZK/Ppq61Lmi2t3fGXsXAfGDWgaACniG9hrAqaxWAIh++b+Y+cjflUlNfg+VJC7/a/qugphsv3/cyORtzWDR8EX/69E/MGjIrZEL1g2kfYHfbZXYFoqpFtAsINL76IO8DtGhxe90+xZNGh0ajwelxcrzjOMmmZKm4yP/4lVZVG7M3AvCLzb+QmYiJDwfxAQSwbNyyoLyEUkOT8qnlUqMWMQ9wa+qt6LV6NGi5681hZ8Vxn4lbB2QFRdHaODq8LTgFh6+oSxuO1wtdHruiIuZck6Rny8+fbfATg7HT68Bycp/MyC1UMxb/fMHZbP9yJYKvxoB/UTh8s9kcDRQAWy/G9i4lziSnVLpg/MvCdVplwzKRd2zznpTp0dOi0oKaVG/M3siaz9aQ98M8nG6n1PRDdJQUPxuqEYfJYOLBdQ9SkVMhvR8ofRQLdQJvHiWZprXDik6jw+lxKn7nq+avmHfnPEp2lxChj1CsBl7+6XLeyHwDnUZH7uBc1ny+hrl3zA1xrtxEhUVh1Bvxer38buzvePm+l9nTsIc/fPoHZg2Zxe7ju2UzaGu779zftvw2LE9auOete6hrlVs/+zdvF3l5f518iimFFFMKLV0taDQamYmY6F1TOLpQttroEdWTqmlVeAQPBq1BqgMIPKY2R5v0tyjT/DB3F+GuGNp1J057zfjD4/Hi1RBkoyBdo+4YmezXhYCRGIwAnm+3E3VKMhkqnySOYfza8eyctguvBsUZ8Zn8n8QAXtfShFavP+1sWune8pceD0wYqLgvu6dT8t45E85VLn2t4WIVXv0f8FvgxEXa3iXDmS5gpQtGLBJa8cAK6tvqSY8NXWUXqEefd+e8oAKgCWsn8OSQJ/EIHuIj4nmx+kXqWuuCPhvKqbDJ3kRda52kB4dvE3Yi6tvqg/quFmcWc7zjeFBDkeLMYh7e8DDz3p8X5Bq54oEV5Ffn0zumN88Mf4bPGz4PKrB6cN2D3NH3Dprtzdyw7AZml89m8i2TpaAbOH7x4fLLrb/kYPNB9jbu5UDTAWaXz+aN3W9IAXpn3k62TNnC/Mr5TFo/iQhDhPR9cf9ikvWRjY/IipeWfbJM+lsMwKK2/PY/3y71sz0w6wDV06rpFdUH0MicMTdlbyLSG0OLvYWRK0eSviSdzxs+VzwmsUBM/Nu/EOdcKzPPdI2eL0Jt1+7pDFlAeLqx+xcf9lvS74zFh0r3Vl5ZHmsfXMuHubuI0EUq7mt/037JUfZ8j1FNBPtwwTN8s9k8FoizWCzrzWbzT893O6eWJpccng6b4iw2Iiyc5Kho6lqaFC8Yc6KZOeVzsNp8XuT+M/ayh8voFdfDVwzTIldKhCo6OtJ2hKHFQ6WgarVZgz4rlsoHJnnnVfi6NHkEjzQWsbG2OK4lHy/hpZEvUZRRJElATQYTT217imXjfEU+NyTdwKGWQzIDs7l3zpW+02RvklY2KaYUhr85XLFAq661TuryJP796F8epTizOOhcrc5aTYOtgXVfrOOZ4c/wYvWLPP3jp0k1pUqfFQP0igdWML1sujQ2m9NGaXYpJzpPKK5SEiISWJ21msTIRIw6I+H6cFZnrQagT2wfOp2d0qxebIk3p3wOf7j/D6REJZEUlcDHj32Mw+3AqDdKx+QfpPKr8xV///S49KDvajW++ZTgNQWpWPyvmdNdo/4rGL1OR2K8SfE7Z4NQ1/7+pv1BM+KPH/uYtKi00469wdYgOUYqfTcQoe4tgD7xvRC8gmK7xYV/W8jaB9eSnBx93sco3t8XG2czpisJZwz4ZrP5X0DfUG8D/wvce6EDuVwcfpguSlFOGeb0mT9p9XrFC8agNbBk7BKfekBr4OPpNdjd3/KkJ0/4LAIiwk2sn7ReMh2zuZQvwMDgWDi6MEhWV1Nfw9KapWyZsoVGWyM2lw3BK2DtsLJ58masHVZijDFsnbIVo94IXtiRuwOX4OJA0wH+76P/Y+JNE0mLSuNw62FKAqVXAAATUklEQVSe2vYU4PNTSTGlAMi6FgHM3T6X18e9Lo1fpGya7c3Utdad0epXRF1rHb1ielHfVk/J+BJ6RvdEr9XzdcvXvPHvN1g0fBFPb32a3MG5aDVajHoj/eP7Sy0ca0/WyozT0mPTMYWZsLvsPL3tacVq0dnbZvO7sb8DLxxpP8Lc7XMl/jvKk4AmTCvrwypuv9D5O4mL1WEiEhO44KTdRqfOLjvWmvoa5lfOp3paNYLglX7/5pN2dJhIT06jsbGdk3a5X3wfw4CgylHxmgl1jQZ2crpQPlrp2t+YvZFfbP6F7HN1rXXYnV3SOQk19sBzo/Rdf4S6t7RevfR5sW1h4ITD/zPneoz+9/fFxBXE4Z81LihpazabhwKlQOepl5IAB7DEYrHkn+Vm+tFNKh0lCZkSz/jWhLcw6oxMWj/pjCqLTm0rDqELvVaPFy96jZ7DbYdP22IOfMUxc7bPCZLVBX72wKwDgG+GGii5FF0dRTtkj+DB2mElKTKJjDUZQTmCUEmy4sxiWrpaZG31WrpamF0+m5H9R0ot/AJzEqISSdyOqMk36oySUknc/oCEAaT/7tvl+5BeQ3hz/JvcuOzGkM6ZYrFU1rosPn38Uw63Hg5qon1w1iFiSVL8fc+nQOhcv3OxgoBOp6FD26Rolx0q2Xs2ypTAa1+v1fOT4iHndE5EnOu5OVvBxIUmXS+lU6Y/rqCA3z2yTLPZ/Cbw6ZWs0jkbfHvzONh3ch8R+ggZtw7BF7bShSo29/755p9LWvRkUzILKhYEqTyqplXR5e6SdPQewaPYjq56WjV7GveEbBMoyhlFCebU0qm88+A7OD1ODFqD5NUDyrrtQDtgUXu+p3EPL93zEg6PQ9Lt+3v6T/repCD9vkajIVwXLtnp+o9VSR66csJKGm2NNNgaeK/2PX466KekmFKIj4hnQcUCqfy/pr4m5MPqdIHqfILJuX7nYgaBs7UsuJAgebG/u23KNqIM0TiF0/dsPl0wvlwB+0KhBvzvSMAXId5woUrW/W+8UL05q6dVyzxmlILsxuyNuAW31L1IrIxtsjfJ1DBvTXiLHtE98AgeSQLoj8BxHv7lYQ40HZCpfgKLkIb0GsI7E9/B7rZLdQCib3t9Wz1LPl4izaozB2XKbAj84T/jFlcFeWV5Ia0PLE9a6HB2kLU2K2jl4T+j//WIX5McmYLD08Wc8jnSg2jblG3n1ZT6fILJuXznYgaBs51BX2hDjgsJsOJ3BY2bME04xzuPXbXeOOeKqzHgX1RrBYvFMu1ibq+7ISoUQvHWospCp9Ng93Qq8pnN9mY2TNogBW5rhxWTwcTy+5dL3jZJkUnM2jIriK/dOmUrFY9U4PF6+Kr5K9yCm1ErR7H8/uWK4xH908W/Ba+gqPoJTHZqNBrmV8znmeHPyKga/2Ryemw6vx7xa6wdVsV9H7cdl5qPrHhgBfMr51PXWocGjeLnw3XhpET24qO8GpzeLo60HZFaKNbU1/DoXx6laloVcZpkXE6BSF0sS8cso3D076SghI5zdlT0eLwyed7pWuVdyHcuBs7WvuNClSkXcnzid8WObqok8sqG6od/Gog3nNjXM1B2F62No0vfRpv2JPub9itKyiIMEbzz+Tt8mPchB2cd4qPpH2F326Vg/17tez5jsMG5LK1ZKnm8F44uZH7FfGqbarG5bORX50sVrIF+6iKFUrK7RPp7xQMraLA1SDff9MHTuSn5JipyKtg7Yy/TB0+XVhdlX5bxyuhXZN2t/OWofWP7UpFTQaopld/u+m3Qvjdmb+SGxBukpi3+OvaDzQcVz12UkIDg8XK88xjD3xz+bXP0e16SfOcFQaDJ00CX3qdxD2xocSmbXFwJ8LcJDmw44o8rpSGHy+skLSqN0kmlVOVWUTqplLSoNFUSeQXhmrRWOBeIS1aNFgSvR/LN8W+0LEollex9X6x+kZm3z2RQ4iBiNUkc6qyVyc7efehdHB4HUYYoTtpPBiUq48LjmLhuYpBPy5BeQ2Qt5Dbs3cDEmybK7AXEXrVKidYNkzYgeAUMWgMuwUWYLozBfxwcdPyWJy0U7Cyg8lAlH+R9wInOE+RX5ctaIZoMJiasnaBoKZBflS9ZHwxMGEiELtJnvHWaJKpY8epv9Xy1UAPdscy/EmyGk5OjOdZ6nH1Ne4Psv29IuAm9M/KyjONy4mqkdK7pgH8hnhsiZ58WlUbJ+BJGrxodZBQWoY/gnpX3sG/mPpIjk2nuapYZh8G3XjXXJ1wvS6iK722ZsoWbi26m9sla/mf7/8hoHzFxGWq/c388l8m3TiZcH65o0bB1ylbJVz+Uf7zoowM+JZHT4wxS8FwXfx3D3xweNI5bU27ls4bPpDqAQF+XUElJcT/+9QHnwkl3J7orCHR3ojM5OZojLfWKeaxzsUa4mnA1BvxrltI5nxaF4vcchja6BDvFmcUsG7eMNkebr/z/VP/S3E25pJpSWfXZKtJjfdYEYlMMJa5VtCpWeq/N0UZ6bDoajYbcwbnEhcexZcoWPnr0I/rH9Zd87GeXz2ZEyQhmbJ5BtDGauT+eS/Yt2Txf9TwGnXKbQ4POQMGuAp922mUPqsxd8cAKnt3xrPR3alQqSz5eIh2jUWdkycdLCNOEsyl7k+z4e0T14MktT5KxJoMRJSPIWJPBmNVjZBWToaiI3jG9ZcFeHK9KDYTGlUBvOQXlXIJLUH+3KwXX7Az/bJQNgSsAfxpHnGEDirPsGGMMbY42jDojC/+2kNVZq0N2tSqfWs5XzV8pygyLMoow6oxoNdogaaj//gO/98G0DyQNd2CjDPEzO3J3sNu6mxRTCgkRCYTrwjFow3AJLgQ8MlXMxuyNDIgZRKPDKuuU9NyI5xRNvdB66fu7PkHn3V/ZFIqKSI3scd7a8O5Gd8/6ugti0vZC1EJXG7r7t+52lc6VDv8A7vV6T6tsUApGlTmVMhWCyWCSvlfXKm9aUZVbRf+4/uSV5Umma2LyN5DnLt9fToY5I6h/bGl2KV6vl5lbZpJmSpOpfdJjfY0tosOiFY/Df7b16t9flVX/psf6/N6Pth+VHkCBvK9OpwlSxTg6BeJ1qYRFh9Mzqhe3jbldRh34KzG69G2nVTaBPCnpT0Xg4azUKSquLJytqkhF9+GaCfiBAXzz5M0hA5JY5Sh+VvQzcQtumXSwyd6EUW9U3I7NZWPfiX1YO6yseGAFy2qW8esRv+b5qucl58ZkUzJajZZ7r78Xy0kLvWN6syN3Byc6T3Ck7Qj5Vfn8esSvefehd/EIHlZ9tkpmDTBj8wzWPbhOcf8uj0t6Xew6tXXKVgw6AwatAa1GS8aajJASulBSvbOV8J1tF6RQ27uSm1irUMaV3nxcxTVE6QRSOEoFUJuyN9EvciBfd+7H5rIxtHhoyDJ/0S996dildDg7ZNt5a8JbJEQk0OXu4nDrYekB8c0vjyB4PXzT9g0NtgYKdhWweORigJB2CiI980XjF4rUzUd5NUHFLhuzN/L6J68z+ZbJQauJHpG9MHpMtNB4Xo2nzwXn2gXpu4DuXuZ3F67F4+7uY1YpndMgsDgllAlWu9DC+LXjKRxdSHpselA/WVGfLkoHo8Oi6RHVg4qcCgA0aAjThfHax6/JulxtnrzZ5yujNZIYkciU0imkRaXRL66fTJ3jv/2sdT56xyMIXBd3XZBL46bsTRg9JtmsSqfVotPqqTxUyZ7GPdKKwOay0SOyF3pnJB68GPRhZ6RcLhRajVbG3arLehUquhfXTMAXFSGBVaZar55Ijy8oefi2kXTBrgLefehdnB5l5cFNyTdROLqQcEM4Q4uHBgXOypxK3v3yXUXbgE3Zm/jk0U+p7/gGh8ehuP2EiARpW3qNgVhdErEJ8VRPq8YjeAjTGiU9O4BJFytRVmlRadLDQax+FR8O/o2nVb5VhRIuV4tAFZcf10zAP9sAJz4Yaupr0Gq0xEfEK86E9zbuZXb5bLZO2aoYsLXo+DB3F4LGLfPSEbnyD6Z9yIS1E05rkyAbo8eL3hOJ/lQnIzyhuxnVtdYxv3I+RRlF3JB4AwaNMeimVflWFUq4Eoq4VFw6XDM6/LMtUxcfDOmx6RxuPcyCigVB1gDvPvSupLgJ1dVJrzH49NCCoPhAcHi6SItK49kdz1IyvkS2/fWT1vP91O9TlFFEuD78rI5PibLKWJOBBm1IXfaVoN1WcWUhVIvAs+04peLKxjUzw4fQihD/JWyELpKkiBQqc/5GhD6cfnH9ZMqatKg0IvQRzL1zLnaXneTI5CA5pf/KQYlKSo/1dRlaNHwRGWsymFcxT9p+QkQC7Y52JpdOlpK2Z2M+FWo/l9tPRcXVDbVF4HcbV+0MX6fT0KVvo113gi592xkrZE+3HbHidnLpw+xr2svQN+/g+qUDuOONO4jQR/D62GUMTv0BfaP7EU8qkd5YTAYTj//1cX7wpx+QX5VPZU6l4srB5I1lY/bGoArW/Op8BiYMlOij2eWziTBEYO2w8tS2p6Qq07O92fxXJuJ+/PuqqlBxNrhSjNhUXBpclbLMi8kz+ss1SyeVKlbCXqj/uDusk383/FNq21awqwBrh5Wd03bh9XJRug+J5+VKahzR3bK17sDVfszne29d7cd9PujuY75mZJmheMbz8d12e13SdkI1HA+cYZ/rstfoMdErpldQEZK/ygZ8N9uFKGe6y7ddxXcHajL/u42rMuBfCM8YKDkL131bKXumRicizpUv93i83JJyyxlvIvVmU3ElQJ04fHdxVXL458szKjlkWm1WyZ6gYFdBkGPkxuyNQTz4+fDlYhHSmRQxqnJGhQoVlwrXFIcfinsvGV9Ck72JhIgEBK+AVqMlNSoVg9ZAoi4Nl1NQHMO58OXdzfd1B9RjvnZwLR53dx9zt3H4ZrN5FjATcAFui8Xyg4ux3VA4X+ojFBXUM7onuZtyZV40sYZ4jB6TYrAXx6Aue1WoUHE14YIDvtlszgIeAn5ksVjazWZz2oUP68w4n4AbinuP0EUGPzycXjWIq1Ch4juFi8HhzwGes1gs7QAWi8V6EbZ5SRCKe48UYlXeXIUKFd95XDCHbzabm4HfAj8FwoA/WiyW5eewiX7AoQsaxDlA8Ao02BpwuB0Y9UZSTCloNVdl7lqFChUq4GJy+Gaz+V9A3xBvpwI6oA8wFEgCdpnNZovFYvngrIZ6CpezxaEOE5GYwAUn7bbLss/uTvB0B9RjvnZwLR53dx+zX9L2rHHGgG+xWH54uvfNZvNh4G2LxSIADWaz+X3gduCcAr4KFSpUqLi0uBhcxhpgDIDZbDYBw4D/XITtqlChQoWKi4iLEfALgT5ms3kP8AmwymKxvH8RtqtChQoVKi4iLliWabFY7MAjF2EsKlSoUKHiEuJK8NLRgS8B8V3HtXCMgVCP+drBtXjc3XnMfvvWne13rgRrhaHAh909CBUqVKi4SjEM2Hk2H7wSAr4R+BFwDPB081hUqFCh4mqBDugB/ANwnM0XroSAr0KFChUqLgPUElMVKlSouEagBnwVKlSouEagBnwVKlSouEagBnwVKlSouEagBnwVKlSouEagBnwVKlSouEagBnwVKlSouEZwJVgrfGdhNpunAr8CbgJ+abFYXvd7LxIoBv4LcANzLRbLe90y0EsIs9n8JjAKOHHqpXctFstL3TeiSwOz2TwIKAESgZNAjsVi2d+9o7r0MJvNXwNdp/4DmGexWMq7bUCXAGaz+RVgIr5mTbdYLJYvTr1+1f3m6gz/0mI38DN8FtKBmAu0WyyW64H7gT+bzeZz62Zw9eB/LRbL4FP/feeC/Sn8AVhmsVgGAcuAP3bzeC4nHvT7fb9Twf4UNgF3AXUBr191v7ka8C8hLBbLFxaLZS8gKLydje+C4dSs4FNg7GUcnoqLBLPZnAL8EHj71EtvAz80m83J3TcqFRcLFotlp8Vi+cb/tav1N1cDfvehL/IZw2F8rSK/i/hvs9n8udls3mQ2m2/s7sFcAvQB6i0Wiwfg1L9H+e7+noFYbTabPzObzUVmszmuuwdzmXBV/uYqh38BOFO/X/Fi+C7jLHoeLwSOWSwWwWw25wDbzGbzddfCublGMMxisXxjNpuNwO+A14Gp3TwmFSGgBvwLwJn6/Z4Bh4F0oPHU332BHRc8qMuMszgH9X6fXWk2mwuB3gTzoVczvgF6mc1mncVi8ZjNZh3Q89Tr32mIVIfFYnGYzeYi4C/dPKTLhavyN1cpne7Du8D/B2A2mwfis4je1q0jugQwm829/P5/ND4L7PrQ37j6YLFYGvAl6B8+9dLDwL8tFktj6G9d/TCbzSaz2Rx76v81+AQKu7t3VJcHV+tvrtojX0KYzeaHgd8C8YATsAH3WSyWvacavr8J/ABfEPyVxWIp666xXiqYzeYKfNSOALQB/2OxWD7u3lFdfJjN5hvwSfTigWZ8Ej1L947q0sJsNl8HbMDny64D9gJPWSyWY906sIsMs9n8GpAFpOGTF5+0WCw3X42/uRrwVahQoeIagUrpqFChQsU1AjXgq1ChQsU1AjXgq1ChQsU1AjXgq1ChQsU1AjXgq1ChQsU1AjXgq1ChQsU1AjXgq1ChQsU1AjXgq1ChQsU1gv8fEPSuK1PwW8sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_DIM = 2\n",
    "LATENT_DIM = 1\n",
    "N_DECODER_LAYERS = 2\n",
    "NONLINEARITY = False\n",
    "N_SAMPLES = 10000\n",
    "WITH_BIASX = True\n",
    "WITH_LOGVARX = True\n",
    "\n",
    "W_TRUE = {}\n",
    "B_TRUE = {}\n",
    "\n",
    "W_TRUE[0] = [[1.], [1.]]\n",
    "B_TRUE[0] = [0., -1.]\n",
    "\n",
    "# For the reconstruction\n",
    "W_TRUE[1] = [[2., 1.], [-1., 2.]]\n",
    "B_TRUE[1] = [0., 0.]\n",
    "\n",
    "# For the logvarx\n",
    "W_TRUE[2] = [[1., -1.], [0., 1.]]\n",
    "B_TRUE[2] = [0., 0.]\n",
    "\n",
    "if WITH_LOGVARX:\n",
    "    assert len(W_TRUE) == N_DECODER_LAYERS + 1\n",
    "else:\n",
    "    assert len(W_TRUE) == N_DECODER_LAYERS\n",
    "\n",
    "WITH_BIASZ = True\n",
    "WITH_LOGVARZ = True\n",
    "\n",
    "decoder_true = toynn.make_decoder_true(\n",
    "    w_true=W_TRUE, b_true=B_TRUE, latent_dim=LATENT_DIM, \n",
    "    data_dim=DATA_DIM, n_layers=N_DECODER_LAYERS,\n",
    "    nonlinearity=NONLINEARITY, with_biasx=WITH_BIASX, with_logvarx=WITH_LOGVARX)\n",
    "\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, N_SAMPLES)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = toyvis.plot_data(generated_true_x, color='green', label='from decoder true', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect generation of synthetic data from decoder_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight tensor([[1.],\n",
      "        [1.]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0., -1.], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 2.,  1.],\n",
      "        [-1.,  2.]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([0., 0.], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 1., -1.],\n",
      "        [ 0.,  1.]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0., 0.], device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(nina): Add a comparison to a FA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results from standard VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[1.],\n",
      "        [1.]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0., -1.], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 2.,  1.],\n",
      "        [-1.,  2.]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([0., 0.], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 1., -1.],\n",
      "        [ 0.,  1.]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0., 0.], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[ 0.9520],\n",
      "        [-0.8405]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([0.1646, 0.9808], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[-0.5298,  0.3283],\n",
      "        [-1.2349, -0.3692]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([ 0.6727, -0.2406], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 1.1437,  0.8916],\n",
      "        [-0.1093,  0.0673]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([ 0.5147, -0.6609], device='cuda:0') \n",
      "\n",
      "Last losses:\n",
      "[0.08472455477714538, 0.08383438789844513, 0.08322126817703247, 0.08241943776607513, 0.08201259326934815]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "decoder_path = glob.glob(f'{OUTPUT}/train_vae/models/decoder.pth')[0]\n",
    "decoder = torch.load(decoder_path, map_location=DEVICE)\n",
    "\n",
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "losses_vae_path = glob.glob(f'{OUTPUT}/train_vae/train_losses.pkl')[0]\n",
    "train_losses_all_epochs = pickle.load(open(losses_vae_path, 'rb'))\n",
    "\n",
    "plt.figure()\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "plt.plot(range(n_epochs), train_losses_total)\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb29a57d68>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "\n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results from VEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[1.],\n",
      "        [1.]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0., -1.], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 2.,  1.],\n",
      "        [-1.,  2.]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([0., 0.], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 1., -1.],\n",
      "        [ 0.,  1.]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0., 0.], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[0.1005],\n",
      "        [0.2445]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0.1762, -1.1042], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 0.3307,  0.3261],\n",
      "        [-1.0173,  1.1383]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([-0.6204, -0.5296], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[-0.4501,  0.1227],\n",
      "        [ 1.0479, -0.2198]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([-0.1202, -0.0849], device='cuda:0') \n",
      "\n",
      "Last losses:\n",
      "[0.19339379155635833, 0.19265535390377045, 0.1927059817314148, 0.1934036124944687, 0.19326992774009705]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "decoder_path = glob.glob(f'{OUTPUT}/train_vem/models/decoder.pth')[0]\n",
    "decoder = torch.load(decoder_path, map_location=DEVICE)\n",
    "\n",
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "losses_vae_path = glob.glob(f'{OUTPUT}/train_vem/train_losses.pkl')[0]\n",
    "train_losses_all_epochs = pickle.load(open(losses_vae_path, 'rb'))\n",
    "\n",
    "plt.figure()\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "plt.plot(range(n_epochs), train_losses_total)\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb2993c048>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "\n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='orange', ax=ax)\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "toyvis.plot_data(generated_x, color='orange', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print pipeline logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 log files.\n",
      "\n",
      "-- Log file: logs2019-04-09 21:37:19.781589.txt\n",
      "\n",
      "2019-04-09 21:37:19,781 root         INFO     start\n",
      "2019-04-09 21:37:19,800 luigi        INFO     logging configured by default settings\n",
      "2019-04-09 21:37:19,805 luigi-interface DEBUG    Checking if RunAll() is complete\n",
      "2019-04-09 21:37:19,806 luigi-interface DEBUG    Checking if TrainVAE() is complete\n",
      "2019-04-09 21:37:19,806 luigi-interface DEBUG    Checking if TrainVEM() is complete\n",
      "2019-04-09 21:37:19,807 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   PENDING\n",
      "2019-04-09 21:37:19,807 luigi-interface DEBUG    Checking if MakeDataSet() is complete\n",
      "2019-04-09 21:37:19,807 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   PENDING\n",
      "2019-04-09 21:37:19,808 luigi-interface INFO     Informed scheduler that task   MakeDataSet__99914b932b   has status   DONE\n",
      "2019-04-09 21:37:19,808 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   PENDING\n",
      "2019-04-09 21:37:19,808 luigi-interface INFO     Done scheduling tasks\n",
      "2019-04-09 21:37:19,808 luigi-interface INFO     Running Worker with 1 processes\n",
      "2019-04-09 21:37:19,808 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 21:37:19,809 luigi-interface DEBUG    Pending tasks: 3\n",
      "2019-04-09 21:37:19,809 luigi-interface INFO     [pid 25020] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=25020) running   TrainVEM()\n",
      "2019-04-09 21:37:19,825 root         INFO     --Dataset tensor: (10000, 2)\n",
      "2019-04-09 21:37:19,825 root         INFO     -- Train tensor: (8000, 2)\n",
      "2019-04-09 21:37:23,642 root         INFO     Values of VEM's decoder parameters before training:\n",
      "2019-04-09 21:37:23,642 root         INFO     layers.0.weight\n",
      "2019-04-09 21:37:23,643 root         INFO     tensor([[-0.2651],\n",
      "        [ 0.1353]], device='cuda:0')\n",
      "2019-04-09 21:37:23,662 root         INFO     layers.0.bias\n",
      "2019-04-09 21:37:23,662 root         INFO     tensor([-0.3248, -0.5761], device='cuda:0')\n",
      "2019-04-09 21:37:23,663 root         INFO     layers.1.weight\n",
      "2019-04-09 21:37:23,663 root         INFO     tensor([[-0.0574,  0.4460],\n",
      "        [ 0.5879, -0.3491]], device='cuda:0')\n",
      "2019-04-09 21:37:23,664 root         INFO     layers.1.bias\n",
      "2019-04-09 21:37:23,664 root         INFO     tensor([-0.4054, -0.0326], device='cuda:0')\n",
      "2019-04-09 21:37:23,665 root         INFO     layers.2.weight\n",
      "2019-04-09 21:37:23,665 root         INFO     tensor([[ 0.3113,  0.3165],\n",
      "        [-0.2632,  0.2449]], device='cuda:0')\n",
      "2019-04-09 21:37:23,666 root         INFO     layers.2.bias\n",
      "2019-04-09 21:37:23,666 root         INFO     tensor([-0.1202, -0.0849], device='cuda:0')\n",
      "2019-04-09 21:37:23,734 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 0.242362\n",
      "Reconstruction: 0.168921, Regularization: 0.039611, Discriminator: 0.023392; Generator: 0.010437,\n",
      "D(x): 0.469, D(G(z)): 0.513\n",
      "2019-04-09 21:37:23,823 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 0.212732\n",
      "Reconstruction: 0.143841, Regularization: 0.034747, Discriminator: 0.023659; Generator: 0.010484,\n",
      "D(x): 0.458, D(G(z)): 0.511\n",
      "2019-04-09 21:37:23,911 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 0.802628\n",
      "Reconstruction: 0.724597, Regularization: 0.043705, Discriminator: 0.023949; Generator: 0.010376,\n",
      "D(x): 0.454, D(G(z)): 0.515\n",
      "2019-04-09 21:37:23,999 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 0.284865\n",
      "Reconstruction: 0.202784, Regularization: 0.048119, Discriminator: 0.023650; Generator: 0.010312,\n",
      "D(x): 0.464, D(G(z)): 0.517\n",
      "2019-04-09 21:37:24,087 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 0.289496\n",
      "Reconstruction: 0.207452, Regularization: 0.048601, Discriminator: 0.023117; Generator: 0.010326,\n",
      "D(x): 0.479, D(G(z)): 0.517\n",
      "2019-04-09 21:37:24,175 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 0.233865\n",
      "Reconstruction: 0.162069, Regularization: 0.038097, Discriminator: 0.023473; Generator: 0.010225,\n",
      "D(x): 0.470, D(G(z)): 0.520\n",
      "2019-04-09 21:37:24,263 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 0.316112\n",
      "Reconstruction: 0.226903, Regularization: 0.055228, Discriminator: 0.023751; Generator: 0.010230,\n",
      "D(x): 0.462, D(G(z)): 0.520\n",
      "2019-04-09 21:37:24,352 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 0.312658\n",
      "Reconstruction: 0.224810, Regularization: 0.054352, Discriminator: 0.023364; Generator: 0.010132,\n",
      "D(x): 0.477, D(G(z)): 0.523\n",
      "2019-04-09 21:37:24,436 root         INFO     ====> Epoch: 0 Average loss: 0.3458\n",
      "2019-04-09 21:37:24,461 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 0.336333\n",
      "Reconstruction: 0.246684, Regularization: 0.056191, Discriminator: 0.023296; Generator: 0.010162,\n",
      "D(x): 0.478, D(G(z)): 0.522\n",
      "2019-04-09 21:37:24,553 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 0.385729\n",
      "Reconstruction: 0.288363, Regularization: 0.064143, Discriminator: 0.023097; Generator: 0.010127,\n",
      "D(x): 0.486, D(G(z)): 0.523\n",
      "2019-04-09 21:37:24,647 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 0.269918\n",
      "Reconstruction: 0.193135, Regularization: 0.043405, Discriminator: 0.023272; Generator: 0.010106,\n",
      "D(x): 0.478, D(G(z)): 0.524\n",
      "2019-04-09 21:37:24,740 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 0.454605\n",
      "Reconstruction: 0.361571, Regularization: 0.059609, Discriminator: 0.023365; Generator: 0.010061,\n",
      "D(x): 0.477, D(G(z)): 0.525\n",
      "2019-04-09 21:37:24,832 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 0.390884\n",
      "Reconstruction: 0.286395, Regularization: 0.070795, Discriminator: 0.023603; Generator: 0.010090,\n",
      "D(x): 0.469, D(G(z)): 0.524\n",
      "2019-04-09 21:37:24,922 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 0.324191\n",
      "Reconstruction: 0.245420, Regularization: 0.045505, Discriminator: 0.023172; Generator: 0.010095,\n",
      "D(x): 0.480, D(G(z)): 0.524\n",
      "2019-04-09 21:37:25,013 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 0.284148\n",
      "Reconstruction: 0.201510, Regularization: 0.049493, Discriminator: 0.023029; Generator: 0.010116,\n",
      "D(x): 0.484, D(G(z)): 0.523\n",
      "2019-04-09 21:37:25,103 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 0.362896\n",
      "Reconstruction: 0.272371, Regularization: 0.057666, Discriminator: 0.022750; Generator: 0.010110,\n",
      "D(x): 0.493, D(G(z)): 0.524\n",
      "2019-04-09 21:37:25,189 root         INFO     ====> Epoch: 1 Average loss: 0.3383\n",
      "2019-04-09 21:37:25,215 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 0.492834\n",
      "Reconstruction: 0.403971, Regularization: 0.056185, Discriminator: 0.022601; Generator: 0.010077,\n",
      "D(x): 0.498, D(G(z)): 0.525\n",
      "2019-04-09 21:37:25,306 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 0.345747\n",
      "Reconstruction: 0.254618, Regularization: 0.057927, Discriminator: 0.023148; Generator: 0.010053,\n",
      "D(x): 0.482, D(G(z)): 0.526\n",
      "2019-04-09 21:37:25,398 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 0.658427\n",
      "Reconstruction: 0.562367, Regularization: 0.063078, Discriminator: 0.022944; Generator: 0.010038,\n",
      "D(x): 0.489, D(G(z)): 0.526\n",
      "2019-04-09 21:37:25,489 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 0.289857\n",
      "Reconstruction: 0.209155, Regularization: 0.047928, Discriminator: 0.022647; Generator: 0.010127,\n",
      "D(x): 0.494, D(G(z)): 0.523\n",
      "2019-04-09 21:37:25,580 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 0.296112\n",
      "Reconstruction: 0.217236, Regularization: 0.046184, Discriminator: 0.022604; Generator: 0.010088,\n",
      "D(x): 0.497, D(G(z)): 0.524\n",
      "2019-04-09 21:37:25,670 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 0.304538\n",
      "Reconstruction: 0.221838, Regularization: 0.050062, Discriminator: 0.022547; Generator: 0.010090,\n",
      "D(x): 0.498, D(G(z)): 0.524\n",
      "2019-04-09 21:37:25,759 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 0.338273\n",
      "Reconstruction: 0.255502, Regularization: 0.050209, Discriminator: 0.022466; Generator: 0.010096,\n",
      "D(x): 0.500, D(G(z)): 0.524\n",
      "2019-04-09 21:37:25,848 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 0.297823\n",
      "Reconstruction: 0.221085, Regularization: 0.044098, Discriminator: 0.022557; Generator: 0.010082,\n",
      "D(x): 0.498, D(G(z)): 0.525\n",
      "2019-04-09 21:37:25,934 root         INFO     ====> Epoch: 2 Average loss: 0.3311\n",
      "2019-04-09 21:37:25,959 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 0.369929\n",
      "Reconstruction: 0.276876, Regularization: 0.060610, Discriminator: 0.022315; Generator: 0.010127,\n",
      "D(x): 0.504, D(G(z)): 0.523\n",
      "2019-04-09 21:37:26,048 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 0.265282\n",
      "Reconstruction: 0.189925, Regularization: 0.042938, Discriminator: 0.022260; Generator: 0.010159,\n",
      "D(x): 0.504, D(G(z)): 0.522\n",
      "2019-04-09 21:37:26,137 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 0.301559\n",
      "Reconstruction: 0.225747, Regularization: 0.043330, Discriminator: 0.022335; Generator: 0.010147,\n",
      "D(x): 0.502, D(G(z)): 0.522\n",
      "2019-04-09 21:37:26,228 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 0.239862\n",
      "Reconstruction: 0.171225, Regularization: 0.036262, Discriminator: 0.022239; Generator: 0.010136,\n",
      "D(x): 0.505, D(G(z)): 0.523\n",
      "2019-04-09 21:37:26,318 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 0.380182\n",
      "Reconstruction: 0.287466, Regularization: 0.060243, Discriminator: 0.022309; Generator: 0.010163,\n",
      "D(x): 0.502, D(G(z)): 0.522\n",
      "2019-04-09 21:37:26,406 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 0.276221\n",
      "Reconstruction: 0.201940, Regularization: 0.041858, Discriminator: 0.022255; Generator: 0.010167,\n",
      "D(x): 0.504, D(G(z)): 0.522\n",
      "2019-04-09 21:37:26,494 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 0.249528\n",
      "Reconstruction: 0.178830, Regularization: 0.038503, Discriminator: 0.022009; Generator: 0.010186,\n",
      "D(x): 0.511, D(G(z)): 0.521\n",
      "2019-04-09 21:37:26,582 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 0.270709\n",
      "Reconstruction: 0.194540, Regularization: 0.044002, Discriminator: 0.021979; Generator: 0.010188,\n",
      "D(x): 0.512, D(G(z)): 0.521\n",
      "2019-04-09 21:37:26,667 root         INFO     ====> Epoch: 3 Average loss: 0.3178\n",
      "2019-04-09 21:37:26,693 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 0.320090\n",
      "Reconstruction: 0.252687, Regularization: 0.035238, Discriminator: 0.021970; Generator: 0.010194,\n",
      "D(x): 0.512, D(G(z)): 0.521\n",
      "2019-04-09 21:37:26,783 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 0.305374\n",
      "Reconstruction: 0.226692, Regularization: 0.046475, Discriminator: 0.021983; Generator: 0.010223,\n",
      "D(x): 0.510, D(G(z)): 0.520\n",
      "2019-04-09 21:37:26,874 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 0.413612\n",
      "Reconstruction: 0.317215, Regularization: 0.064235, Discriminator: 0.021941; Generator: 0.010220,\n",
      "D(x): 0.512, D(G(z)): 0.520\n",
      "2019-04-09 21:37:26,964 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 0.271170\n",
      "Reconstruction: 0.194733, Regularization: 0.044271, Discriminator: 0.021940; Generator: 0.010227,\n",
      "D(x): 0.511, D(G(z)): 0.520\n",
      "2019-04-09 21:37:27,054 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 0.355065\n",
      "Reconstruction: 0.254714, Regularization: 0.068292, Discriminator: 0.021819; Generator: 0.010239,\n",
      "D(x): 0.515, D(G(z)): 0.519\n",
      "2019-04-09 21:37:27,145 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 0.294488\n",
      "Reconstruction: 0.217170, Regularization: 0.045177, Discriminator: 0.021879; Generator: 0.010262,\n",
      "D(x): 0.512, D(G(z)): 0.519\n",
      "2019-04-09 21:37:27,236 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 0.258063\n",
      "Reconstruction: 0.184974, Regularization: 0.041053, Discriminator: 0.021770; Generator: 0.010266,\n",
      "D(x): 0.516, D(G(z)): 0.518\n",
      "2019-04-09 21:37:27,325 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 0.372322\n",
      "Reconstruction: 0.288424, Regularization: 0.051854, Discriminator: 0.021767; Generator: 0.010277,\n",
      "D(x): 0.515, D(G(z)): 0.518\n",
      "2019-04-09 21:37:27,412 root         INFO     ====> Epoch: 4 Average loss: 0.3405\n",
      "2019-04-09 21:37:27,437 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 0.482182\n",
      "Reconstruction: 0.394672, Regularization: 0.055486, Discriminator: 0.021742; Generator: 0.010283,\n",
      "D(x): 0.516, D(G(z)): 0.518\n",
      "2019-04-09 21:37:27,527 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 0.372579\n",
      "Reconstruction: 0.283857, Regularization: 0.056740, Discriminator: 0.021689; Generator: 0.010293,\n",
      "D(x): 0.517, D(G(z)): 0.517\n",
      "2019-04-09 21:37:27,619 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 0.318950\n",
      "Reconstruction: 0.234719, Regularization: 0.052237, Discriminator: 0.021692; Generator: 0.010303,\n",
      "D(x): 0.517, D(G(z)): 0.517\n",
      "2019-04-09 21:37:27,709 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 0.317358\n",
      "Reconstruction: 0.240499, Regularization: 0.044908, Discriminator: 0.021641; Generator: 0.010311,\n",
      "D(x): 0.518, D(G(z)): 0.517\n",
      "2019-04-09 21:37:27,798 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 0.282249\n",
      "Reconstruction: 0.213569, Regularization: 0.036744, Discriminator: 0.021613; Generator: 0.010322,\n",
      "D(x): 0.519, D(G(z)): 0.517\n",
      "2019-04-09 21:37:27,887 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 0.349860\n",
      "Reconstruction: 0.269562, Regularization: 0.048376, Discriminator: 0.021596; Generator: 0.010325,\n",
      "D(x): 0.519, D(G(z)): 0.516\n",
      "2019-04-09 21:37:27,975 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 0.230123\n",
      "Reconstruction: 0.161426, Regularization: 0.036791, Discriminator: 0.021567; Generator: 0.010338,\n",
      "D(x): 0.520, D(G(z)): 0.516\n",
      "2019-04-09 21:37:28,064 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 0.234259\n",
      "Reconstruction: 0.173972, Regularization: 0.028377, Discriminator: 0.021565; Generator: 0.010345,\n",
      "D(x): 0.520, D(G(z)): 0.516\n",
      "2019-04-09 21:37:28,147 root         INFO     ====> Epoch: 5 Average loss: 0.3256\n",
      "2019-04-09 21:37:28,173 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 0.238982\n",
      "Reconstruction: 0.172463, Regularization: 0.034662, Discriminator: 0.021497; Generator: 0.010360,\n",
      "D(x): 0.521, D(G(z)): 0.515\n",
      "2019-04-09 21:37:28,258 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 0.260605\n",
      "Reconstruction: 0.188412, Regularization: 0.040343, Discriminator: 0.021478; Generator: 0.010372,\n",
      "D(x): 0.521, D(G(z)): 0.515\n",
      "2019-04-09 21:37:28,343 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 0.251066\n",
      "Reconstruction: 0.178786, Regularization: 0.040456, Discriminator: 0.021457; Generator: 0.010368,\n",
      "D(x): 0.522, D(G(z)): 0.515\n",
      "2019-04-09 21:37:28,432 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 0.375788\n",
      "Reconstruction: 0.288618, Regularization: 0.055387, Discriminator: 0.021393; Generator: 0.010389,\n",
      "D(x): 0.524, D(G(z)): 0.514\n",
      "2019-04-09 21:37:28,520 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 0.332962\n",
      "Reconstruction: 0.251559, Regularization: 0.049594, Discriminator: 0.021410; Generator: 0.010398,\n",
      "D(x): 0.523, D(G(z)): 0.514\n",
      "2019-04-09 21:37:28,608 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 0.311557\n",
      "Reconstruction: 0.233522, Regularization: 0.046315, Discriminator: 0.021333; Generator: 0.010387,\n",
      "D(x): 0.526, D(G(z)): 0.514\n",
      "2019-04-09 21:37:28,693 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 0.383639\n",
      "Reconstruction: 0.296805, Regularization: 0.055198, Discriminator: 0.021237; Generator: 0.010399,\n",
      "D(x): 0.529, D(G(z)): 0.514\n",
      "2019-04-09 21:37:28,778 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 0.288923\n",
      "Reconstruction: 0.211807, Regularization: 0.045336, Discriminator: 0.021368; Generator: 0.010412,\n",
      "D(x): 0.524, D(G(z)): 0.514\n",
      "2019-04-09 21:37:28,860 root         INFO     ====> Epoch: 6 Average loss: 0.3176\n",
      "2019-04-09 21:37:28,885 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 0.322679\n",
      "Reconstruction: 0.239292, Regularization: 0.051605, Discriminator: 0.021356; Generator: 0.010426,\n",
      "D(x): 0.524, D(G(z)): 0.513\n",
      "2019-04-09 21:37:28,975 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 0.267419\n",
      "Reconstruction: 0.192865, Regularization: 0.042701, Discriminator: 0.021440; Generator: 0.010414,\n",
      "D(x): 0.522, D(G(z)): 0.514\n",
      "2019-04-09 21:37:29,064 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 0.266706\n",
      "Reconstruction: 0.194293, Regularization: 0.040748, Discriminator: 0.021222; Generator: 0.010442,\n",
      "D(x): 0.528, D(G(z)): 0.513\n",
      "2019-04-09 21:37:29,153 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 0.290678\n",
      "Reconstruction: 0.218764, Regularization: 0.040184, Discriminator: 0.021286; Generator: 0.010444,\n",
      "D(x): 0.526, D(G(z)): 0.513\n",
      "2019-04-09 21:37:29,242 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 0.287098\n",
      "Reconstruction: 0.213562, Regularization: 0.041925, Discriminator: 0.021149; Generator: 0.010462,\n",
      "D(x): 0.530, D(G(z)): 0.512\n",
      "2019-04-09 21:37:29,332 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 0.215923\n",
      "Reconstruction: 0.153920, Regularization: 0.030405, Discriminator: 0.021144; Generator: 0.010454,\n",
      "D(x): 0.530, D(G(z)): 0.512\n",
      "2019-04-09 21:37:29,418 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 0.284518\n",
      "Reconstruction: 0.202233, Regularization: 0.050628, Discriminator: 0.021163; Generator: 0.010494,\n",
      "D(x): 0.528, D(G(z)): 0.511\n",
      "2019-04-09 21:37:29,503 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 0.306142\n",
      "Reconstruction: 0.229314, Regularization: 0.045277, Discriminator: 0.021052; Generator: 0.010499,\n",
      "D(x): 0.532, D(G(z)): 0.511\n",
      "2019-04-09 21:37:29,586 root         INFO     ====> Epoch: 7 Average loss: 0.3069\n",
      "2019-04-09 21:37:29,611 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 0.257264\n",
      "Reconstruction: 0.186045, Regularization: 0.039540, Discriminator: 0.021189; Generator: 0.010491,\n",
      "D(x): 0.528, D(G(z)): 0.511\n",
      "2019-04-09 21:37:29,701 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 0.347796\n",
      "Reconstruction: 0.264027, Regularization: 0.052115, Discriminator: 0.021161; Generator: 0.010492,\n",
      "D(x): 0.529, D(G(z)): 0.511\n",
      "2019-04-09 21:37:29,790 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 0.367436\n",
      "Reconstruction: 0.281007, Regularization: 0.054884, Discriminator: 0.021046; Generator: 0.010500,\n",
      "D(x): 0.533, D(G(z)): 0.511\n",
      "2019-04-09 21:37:29,880 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 0.299466\n",
      "Reconstruction: 0.223324, Regularization: 0.044743, Discriminator: 0.020875; Generator: 0.010524,\n",
      "D(x): 0.537, D(G(z)): 0.510\n",
      "2019-04-09 21:37:29,969 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 0.285668\n",
      "Reconstruction: 0.214237, Regularization: 0.040007, Discriminator: 0.020940; Generator: 0.010484,\n",
      "D(x): 0.537, D(G(z)): 0.511\n",
      "2019-04-09 21:37:30,059 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 0.256757\n",
      "Reconstruction: 0.186357, Regularization: 0.039112, Discriminator: 0.020798; Generator: 0.010491,\n",
      "D(x): 0.541, D(G(z)): 0.511\n",
      "2019-04-09 21:37:30,148 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 0.332205\n",
      "Reconstruction: 0.253220, Regularization: 0.047244, Discriminator: 0.021196; Generator: 0.010544,\n",
      "D(x): 0.526, D(G(z)): 0.509\n",
      "2019-04-09 21:37:30,237 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 0.261211\n",
      "Reconstruction: 0.189569, Regularization: 0.040248, Discriminator: 0.020884; Generator: 0.010510,\n",
      "D(x): 0.538, D(G(z)): 0.510\n",
      "2019-04-09 21:37:30,322 root         INFO     ====> Epoch: 8 Average loss: 0.2975\n",
      "2019-04-09 21:37:30,347 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 0.248919\n",
      "Reconstruction: 0.185530, Regularization: 0.032109, Discriminator: 0.020749; Generator: 0.010531,\n",
      "D(x): 0.542, D(G(z)): 0.510\n",
      "2019-04-09 21:37:30,439 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 0.381013\n",
      "Reconstruction: 0.296898, Regularization: 0.052642, Discriminator: 0.020934; Generator: 0.010539,\n",
      "D(x): 0.536, D(G(z)): 0.509\n",
      "2019-04-09 21:37:30,531 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 0.313597\n",
      "Reconstruction: 0.245932, Regularization: 0.035842, Discriminator: 0.021337; Generator: 0.010486,\n",
      "D(x): 0.524, D(G(z)): 0.511\n",
      "2019-04-09 21:37:30,621 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 0.323165\n",
      "Reconstruction: 0.253088, Regularization: 0.038536, Discriminator: 0.021007; Generator: 0.010534,\n",
      "D(x): 0.533, D(G(z)): 0.510\n",
      "2019-04-09 21:37:30,710 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 0.260031\n",
      "Reconstruction: 0.191172, Regularization: 0.037411, Discriminator: 0.020915; Generator: 0.010533,\n",
      "D(x): 0.537, D(G(z)): 0.510\n",
      "2019-04-09 21:37:30,799 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 0.239402\n",
      "Reconstruction: 0.172462, Regularization: 0.035959, Discriminator: 0.020431; Generator: 0.010550,\n",
      "D(x): 0.552, D(G(z)): 0.509\n",
      "2019-04-09 21:37:30,888 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 0.333613\n",
      "Reconstruction: 0.256037, Regularization: 0.046327, Discriminator: 0.020656; Generator: 0.010592,\n",
      "D(x): 0.544, D(G(z)): 0.508\n",
      "2019-04-09 21:37:30,977 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 0.286653\n",
      "Reconstruction: 0.211904, Regularization: 0.043315, Discriminator: 0.020855; Generator: 0.010578,\n",
      "D(x): 0.538, D(G(z)): 0.508\n",
      "2019-04-09 21:37:31,062 root         INFO     ====> Epoch: 9 Average loss: 0.2996\n",
      "2019-04-09 21:37:31,087 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 0.342589\n",
      "Reconstruction: 0.262240, Regularization: 0.049165, Discriminator: 0.020567; Generator: 0.010617,\n",
      "D(x): 0.547, D(G(z)): 0.507\n",
      "2019-04-09 21:37:31,177 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 0.285861\n",
      "Reconstruction: 0.212158, Regularization: 0.042430, Discriminator: 0.020690; Generator: 0.010584,\n",
      "D(x): 0.544, D(G(z)): 0.508\n",
      "2019-04-09 21:37:31,267 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 0.271069\n",
      "Reconstruction: 0.195456, Regularization: 0.043805, Discriminator: 0.021143; Generator: 0.010666,\n",
      "D(x): 0.526, D(G(z)): 0.505\n",
      "2019-04-09 21:37:31,357 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 0.317903\n",
      "Reconstruction: 0.242292, Regularization: 0.044324, Discriminator: 0.020728; Generator: 0.010559,\n",
      "D(x): 0.544, D(G(z)): 0.509\n",
      "2019-04-09 21:37:31,447 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 0.256706\n",
      "Reconstruction: 0.183625, Regularization: 0.041455, Discriminator: 0.020966; Generator: 0.010660,\n",
      "D(x): 0.533, D(G(z)): 0.506\n",
      "2019-04-09 21:37:31,537 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 0.368550\n",
      "Reconstruction: 0.286252, Regularization: 0.051536, Discriminator: 0.020192; Generator: 0.010569,\n",
      "D(x): 0.563, D(G(z)): 0.509\n",
      "2019-04-09 21:37:31,627 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 0.229310\n",
      "Reconstruction: 0.158727, Regularization: 0.038914, Discriminator: 0.020992; Generator: 0.010677,\n",
      "D(x): 0.532, D(G(z)): 0.505\n",
      "2019-04-09 21:37:31,716 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 0.286243\n",
      "Reconstruction: 0.213391, Regularization: 0.041921, Discriminator: 0.020286; Generator: 0.010645,\n",
      "D(x): 0.556, D(G(z)): 0.506\n",
      "2019-04-09 21:37:31,799 root         INFO     ====> Epoch: 10 Average loss: 0.2822\n",
      "2019-04-09 21:37:31,825 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.312887\n",
      "Reconstruction: 0.242940, Regularization: 0.038882, Discriminator: 0.020470; Generator: 0.010595,\n",
      "D(x): 0.552, D(G(z)): 0.508\n",
      "2019-04-09 21:37:31,915 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 0.241694\n",
      "Reconstruction: 0.175723, Regularization: 0.034628, Discriminator: 0.020679; Generator: 0.010664,\n",
      "D(x): 0.543, D(G(z)): 0.506\n",
      "2019-04-09 21:37:32,006 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.261958\n",
      "Reconstruction: 0.194827, Regularization: 0.035918, Discriminator: 0.020582; Generator: 0.010632,\n",
      "D(x): 0.547, D(G(z)): 0.507\n",
      "2019-04-09 21:37:32,096 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 0.275593\n",
      "Reconstruction: 0.201431, Regularization: 0.043628, Discriminator: 0.019867; Generator: 0.010666,\n",
      "D(x): 0.571, D(G(z)): 0.505\n",
      "2019-04-09 21:37:32,185 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 0.302404\n",
      "Reconstruction: 0.226458, Regularization: 0.045066, Discriminator: 0.020197; Generator: 0.010683,\n",
      "D(x): 0.560, D(G(z)): 0.505\n",
      "2019-04-09 21:37:32,277 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 0.317288\n",
      "Reconstruction: 0.237087, Regularization: 0.049280, Discriminator: 0.020309; Generator: 0.010612,\n",
      "D(x): 0.561, D(G(z)): 0.507\n",
      "2019-04-09 21:37:32,367 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.235964\n",
      "Reconstruction: 0.161610, Regularization: 0.043097, Discriminator: 0.020539; Generator: 0.010718,\n",
      "D(x): 0.550, D(G(z)): 0.504\n",
      "2019-04-09 21:37:32,459 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 0.376162\n",
      "Reconstruction: 0.291945, Regularization: 0.053775, Discriminator: 0.019656; Generator: 0.010785,\n",
      "D(x): 0.577, D(G(z)): 0.502\n",
      "2019-04-09 21:37:32,546 root         INFO     ====> Epoch: 11 Average loss: 0.2756\n",
      "2019-04-09 21:37:32,571 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 0.372437\n",
      "Reconstruction: 0.290064, Regularization: 0.051597, Discriminator: 0.020112; Generator: 0.010664,\n",
      "D(x): 0.566, D(G(z)): 0.506\n",
      "2019-04-09 21:37:32,662 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 0.261070\n",
      "Reconstruction: 0.185876, Regularization: 0.043511, Discriminator: 0.020948; Generator: 0.010736,\n",
      "D(x): 0.537, D(G(z)): 0.503\n",
      "2019-04-09 21:37:32,753 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 0.244642\n",
      "Reconstruction: 0.178907, Regularization: 0.034635, Discriminator: 0.020378; Generator: 0.010722,\n",
      "D(x): 0.553, D(G(z)): 0.504\n",
      "2019-04-09 21:37:32,843 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 0.244392\n",
      "Reconstruction: 0.173662, Regularization: 0.038889, Discriminator: 0.021221; Generator: 0.010620,\n",
      "D(x): 0.531, D(G(z)): 0.507\n",
      "2019-04-09 21:37:32,933 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 0.283059\n",
      "Reconstruction: 0.212352, Regularization: 0.039573, Discriminator: 0.020361; Generator: 0.010774,\n",
      "D(x): 0.554, D(G(z)): 0.502\n",
      "2019-04-09 21:37:33,024 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.308633\n",
      "Reconstruction: 0.224375, Regularization: 0.052884, Discriminator: 0.020559; Generator: 0.010815,\n",
      "D(x): 0.550, D(G(z)): 0.501\n",
      "2019-04-09 21:37:33,114 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.246175\n",
      "Reconstruction: 0.180580, Regularization: 0.034010, Discriminator: 0.020784; Generator: 0.010801,\n",
      "D(x): 0.540, D(G(z)): 0.501\n",
      "2019-04-09 21:37:33,204 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 0.261531\n",
      "Reconstruction: 0.192063, Regularization: 0.038702, Discriminator: 0.020058; Generator: 0.010707,\n",
      "D(x): 0.568, D(G(z)): 0.504\n",
      "2019-04-09 21:37:33,290 root         INFO     ====> Epoch: 12 Average loss: 0.2631\n",
      "2019-04-09 21:37:33,315 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 0.238312\n",
      "Reconstruction: 0.180402, Regularization: 0.027007, Discriminator: 0.020272; Generator: 0.010632,\n",
      "D(x): 0.561, D(G(z)): 0.507\n",
      "2019-04-09 21:37:33,404 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 0.422401\n",
      "Reconstruction: 0.346318, Regularization: 0.045421, Discriminator: 0.019845; Generator: 0.010818,\n",
      "D(x): 0.573, D(G(z)): 0.501\n",
      "2019-04-09 21:37:33,493 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 0.252136\n",
      "Reconstruction: 0.184695, Regularization: 0.036547, Discriminator: 0.020126; Generator: 0.010767,\n",
      "D(x): 0.564, D(G(z)): 0.502\n",
      "2019-04-09 21:37:33,585 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 0.281070\n",
      "Reconstruction: 0.208890, Regularization: 0.041267, Discriminator: 0.020185; Generator: 0.010727,\n",
      "D(x): 0.565, D(G(z)): 0.504\n",
      "2019-04-09 21:37:33,678 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 0.294050\n",
      "Reconstruction: 0.223737, Regularization: 0.038904, Discriminator: 0.020616; Generator: 0.010793,\n",
      "D(x): 0.548, D(G(z)): 0.502\n",
      "2019-04-09 21:37:33,768 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 0.263327\n",
      "Reconstruction: 0.193218, Regularization: 0.039314, Discriminator: 0.019927; Generator: 0.010868,\n",
      "D(x): 0.570, D(G(z)): 0.499\n",
      "2019-04-09 21:37:33,858 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 0.273075\n",
      "Reconstruction: 0.202845, Regularization: 0.039825, Discriminator: 0.019674; Generator: 0.010732,\n",
      "D(x): 0.583, D(G(z)): 0.504\n",
      "2019-04-09 21:37:33,949 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 0.239088\n",
      "Reconstruction: 0.175389, Regularization: 0.033226, Discriminator: 0.019744; Generator: 0.010729,\n",
      "D(x): 0.579, D(G(z)): 0.504\n",
      "2019-04-09 21:37:34,035 root         INFO     ====> Epoch: 13 Average loss: 0.2591\n",
      "2019-04-09 21:37:34,060 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.306264\n",
      "Reconstruction: 0.231092, Regularization: 0.044238, Discriminator: 0.019946; Generator: 0.010988,\n",
      "D(x): 0.568, D(G(z)): 0.496\n",
      "2019-04-09 21:37:34,151 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.358420\n",
      "Reconstruction: 0.269255, Regularization: 0.058015, Discriminator: 0.020130; Generator: 0.011019,\n",
      "D(x): 0.569, D(G(z)): 0.495\n",
      "2019-04-09 21:37:34,242 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 0.238539\n",
      "Reconstruction: 0.172941, Regularization: 0.034987, Discriminator: 0.019802; Generator: 0.010809,\n",
      "D(x): 0.578, D(G(z)): 0.501\n",
      "2019-04-09 21:37:34,332 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.171484\n",
      "Reconstruction: 0.117488, Regularization: 0.022883, Discriminator: 0.020390; Generator: 0.010722,\n",
      "D(x): 0.557, D(G(z)): 0.504\n",
      "2019-04-09 21:37:34,423 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.214220\n",
      "Reconstruction: 0.150332, Regularization: 0.032670, Discriminator: 0.020239; Generator: 0.010979,\n",
      "D(x): 0.559, D(G(z)): 0.496\n",
      "2019-04-09 21:37:34,513 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 0.336348\n",
      "Reconstruction: 0.261501, Regularization: 0.043497, Discriminator: 0.020475; Generator: 0.010875,\n",
      "D(x): 0.560, D(G(z)): 0.499\n",
      "2019-04-09 21:37:34,603 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.237039\n",
      "Reconstruction: 0.171958, Regularization: 0.033665, Discriminator: 0.020701; Generator: 0.010715,\n",
      "D(x): 0.551, D(G(z)): 0.504\n",
      "2019-04-09 21:37:34,690 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.262740\n",
      "Reconstruction: 0.197332, Regularization: 0.033811, Discriminator: 0.020643; Generator: 0.010954,\n",
      "D(x): 0.547, D(G(z)): 0.497\n",
      "2019-04-09 21:37:34,774 root         INFO     ====> Epoch: 14 Average loss: 0.2473\n",
      "2019-04-09 21:37:34,800 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 0.276708\n",
      "Reconstruction: 0.198952, Regularization: 0.047073, Discriminator: 0.019806; Generator: 0.010877,\n",
      "D(x): 0.583, D(G(z)): 0.499\n",
      "2019-04-09 21:37:34,890 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 0.325990\n",
      "Reconstruction: 0.244616, Regularization: 0.050044, Discriminator: 0.020425; Generator: 0.010904,\n",
      "D(x): 0.563, D(G(z)): 0.498\n",
      "2019-04-09 21:37:34,982 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.243927\n",
      "Reconstruction: 0.174514, Regularization: 0.038831, Discriminator: 0.019844; Generator: 0.010737,\n",
      "D(x): 0.585, D(G(z)): 0.504\n",
      "2019-04-09 21:37:35,072 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.223252\n",
      "Reconstruction: 0.165029, Regularization: 0.027945, Discriminator: 0.019336; Generator: 0.010942,\n",
      "D(x): 0.589, D(G(z)): 0.497\n",
      "2019-04-09 21:37:35,161 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.253532\n",
      "Reconstruction: 0.187115, Regularization: 0.035872, Discriminator: 0.019735; Generator: 0.010810,\n",
      "D(x): 0.584, D(G(z)): 0.501\n",
      "2019-04-09 21:37:35,252 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.184461\n",
      "Reconstruction: 0.126995, Regularization: 0.026246, Discriminator: 0.020212; Generator: 0.011008,\n",
      "D(x): 0.559, D(G(z)): 0.495\n",
      "2019-04-09 21:37:35,344 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.191564\n",
      "Reconstruction: 0.137139, Regularization: 0.022985, Discriminator: 0.020389; Generator: 0.011051,\n",
      "D(x): 0.549, D(G(z)): 0.494\n",
      "2019-04-09 21:37:35,433 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 0.265830\n",
      "Reconstruction: 0.198093, Regularization: 0.036161, Discriminator: 0.020581; Generator: 0.010996,\n",
      "D(x): 0.553, D(G(z)): 0.496\n",
      "2019-04-09 21:37:35,519 root         INFO     ====> Epoch: 15 Average loss: 0.2397\n",
      "2019-04-09 21:37:35,545 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 0.226727\n",
      "Reconstruction: 0.163650, Regularization: 0.031811, Discriminator: 0.020614; Generator: 0.010653,\n",
      "D(x): 0.559, D(G(z)): 0.507\n",
      "2019-04-09 21:37:35,634 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 0.266367\n",
      "Reconstruction: 0.191593, Regularization: 0.043592, Discriminator: 0.020274; Generator: 0.010907,\n",
      "D(x): 0.573, D(G(z)): 0.498\n",
      "2019-04-09 21:37:35,721 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.227109\n",
      "Reconstruction: 0.162838, Regularization: 0.032896, Discriminator: 0.020438; Generator: 0.010937,\n",
      "D(x): 0.560, D(G(z)): 0.498\n",
      "2019-04-09 21:37:35,808 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 0.206971\n",
      "Reconstruction: 0.145525, Regularization: 0.030641, Discriminator: 0.019829; Generator: 0.010976,\n",
      "D(x): 0.577, D(G(z)): 0.497\n",
      "2019-04-09 21:37:35,895 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 0.253513\n",
      "Reconstruction: 0.184488, Regularization: 0.038520, Discriminator: 0.019283; Generator: 0.011221,\n",
      "D(x): 0.593, D(G(z)): 0.488\n",
      "2019-04-09 21:37:35,982 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 0.235869\n",
      "Reconstruction: 0.164118, Regularization: 0.040315, Discriminator: 0.020410; Generator: 0.011026,\n",
      "D(x): 0.565, D(G(z)): 0.495\n",
      "2019-04-09 21:37:36,069 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 0.223201\n",
      "Reconstruction: 0.158816, Regularization: 0.032938, Discriminator: 0.020454; Generator: 0.010994,\n",
      "D(x): 0.560, D(G(z)): 0.496\n",
      "2019-04-09 21:37:36,156 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.211692\n",
      "Reconstruction: 0.150860, Regularization: 0.029566, Discriminator: 0.020031; Generator: 0.011235,\n",
      "D(x): 0.561, D(G(z)): 0.489\n",
      "2019-04-09 21:37:36,239 root         INFO     ====> Epoch: 16 Average loss: 0.2344\n",
      "2019-04-09 21:37:36,265 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.179718\n",
      "Reconstruction: 0.124605, Regularization: 0.024280, Discriminator: 0.019664; Generator: 0.011169,\n",
      "D(x): 0.573, D(G(z)): 0.490\n",
      "2019-04-09 21:37:36,350 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 0.184365\n",
      "Reconstruction: 0.128690, Regularization: 0.024496, Discriminator: 0.020091; Generator: 0.011087,\n",
      "D(x): 0.563, D(G(z)): 0.493\n",
      "2019-04-09 21:37:36,436 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.216019\n",
      "Reconstruction: 0.155157, Regularization: 0.030009, Discriminator: 0.019654; Generator: 0.011198,\n",
      "D(x): 0.576, D(G(z)): 0.489\n",
      "2019-04-09 21:37:36,520 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 0.164994\n",
      "Reconstruction: 0.111836, Regularization: 0.022289, Discriminator: 0.019696; Generator: 0.011173,\n",
      "D(x): 0.573, D(G(z)): 0.490\n",
      "2019-04-09 21:37:36,605 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.219128\n",
      "Reconstruction: 0.158874, Regularization: 0.029240, Discriminator: 0.019959; Generator: 0.011056,\n",
      "D(x): 0.571, D(G(z)): 0.494\n",
      "2019-04-09 21:37:36,689 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 0.178522\n",
      "Reconstruction: 0.122807, Regularization: 0.024919, Discriminator: 0.019701; Generator: 0.011096,\n",
      "D(x): 0.578, D(G(z)): 0.493\n",
      "2019-04-09 21:37:36,774 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 0.303178\n",
      "Reconstruction: 0.221762, Regularization: 0.050062, Discriminator: 0.020462; Generator: 0.010892,\n",
      "D(x): 0.592, D(G(z)): 0.500\n",
      "2019-04-09 21:37:36,861 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 0.268817\n",
      "Reconstruction: 0.199244, Regularization: 0.038695, Discriminator: 0.019903; Generator: 0.010974,\n",
      "D(x): 0.582, D(G(z)): 0.496\n",
      "2019-04-09 21:37:36,944 root         INFO     ====> Epoch: 17 Average loss: 0.2254\n",
      "2019-04-09 21:37:36,970 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 0.245719\n",
      "Reconstruction: 0.180242, Regularization: 0.033527, Discriminator: 0.020535; Generator: 0.011415,\n",
      "D(x): 0.545, D(G(z)): 0.483\n",
      "2019-04-09 21:37:37,055 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.199711\n",
      "Reconstruction: 0.142304, Regularization: 0.026396, Discriminator: 0.020057; Generator: 0.010953,\n",
      "D(x): 0.571, D(G(z)): 0.497\n",
      "2019-04-09 21:37:37,140 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 0.229829\n",
      "Reconstruction: 0.168298, Regularization: 0.030593, Discriminator: 0.019585; Generator: 0.011352,\n",
      "D(x): 0.576, D(G(z)): 0.485\n",
      "2019-04-09 21:37:37,225 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.257502\n",
      "Reconstruction: 0.189929, Regularization: 0.037079, Discriminator: 0.019144; Generator: 0.011350,\n",
      "D(x): 0.594, D(G(z)): 0.485\n",
      "2019-04-09 21:37:37,309 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 0.213538\n",
      "Reconstruction: 0.152998, Regularization: 0.029059, Discriminator: 0.020269; Generator: 0.011211,\n",
      "D(x): 0.558, D(G(z)): 0.489\n",
      "2019-04-09 21:37:37,393 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.207145\n",
      "Reconstruction: 0.143443, Regularization: 0.031752, Discriminator: 0.020794; Generator: 0.011156,\n",
      "D(x): 0.548, D(G(z)): 0.491\n",
      "2019-04-09 21:37:37,477 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 0.247011\n",
      "Reconstruction: 0.184532, Regularization: 0.032038, Discriminator: 0.019144; Generator: 0.011297,\n",
      "D(x): 0.588, D(G(z)): 0.486\n",
      "2019-04-09 21:37:37,561 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 0.182319\n",
      "Reconstruction: 0.126136, Regularization: 0.024606, Discriminator: 0.020299; Generator: 0.011278,\n",
      "D(x): 0.555, D(G(z)): 0.487\n",
      "2019-04-09 21:37:37,642 root         INFO     ====> Epoch: 18 Average loss: 0.2201\n",
      "2019-04-09 21:37:37,667 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 0.227607\n",
      "Reconstruction: 0.162299, Regularization: 0.034427, Discriminator: 0.019605; Generator: 0.011275,\n",
      "D(x): 0.582, D(G(z)): 0.488\n",
      "2019-04-09 21:37:37,752 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 0.238501\n",
      "Reconstruction: 0.173308, Regularization: 0.033969, Discriminator: 0.019982; Generator: 0.011242,\n",
      "D(x): 0.570, D(G(z)): 0.489\n",
      "2019-04-09 21:37:37,836 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 0.271126\n",
      "Reconstruction: 0.198907, Regularization: 0.040198, Discriminator: 0.020601; Generator: 0.011419,\n",
      "D(x): 0.553, D(G(z)): 0.483\n",
      "2019-04-09 21:37:37,921 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 0.183569\n",
      "Reconstruction: 0.130675, Regularization: 0.022256, Discriminator: 0.019452; Generator: 0.011186,\n",
      "D(x): 0.582, D(G(z)): 0.491\n",
      "2019-04-09 21:37:38,005 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 0.228854\n",
      "Reconstruction: 0.164722, Regularization: 0.032881, Discriminator: 0.019797; Generator: 0.011453,\n",
      "D(x): 0.573, D(G(z)): 0.482\n",
      "2019-04-09 21:37:38,090 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 0.213452\n",
      "Reconstruction: 0.150510, Regularization: 0.031810, Discriminator: 0.019750; Generator: 0.011382,\n",
      "D(x): 0.574, D(G(z)): 0.484\n",
      "2019-04-09 21:37:38,173 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 0.211912\n",
      "Reconstruction: 0.150312, Regularization: 0.031321, Discriminator: 0.018820; Generator: 0.011458,\n",
      "D(x): 0.599, D(G(z)): 0.481\n",
      "2019-04-09 21:37:38,257 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.213619\n",
      "Reconstruction: 0.153487, Regularization: 0.029861, Discriminator: 0.018902; Generator: 0.011368,\n",
      "D(x): 0.599, D(G(z)): 0.485\n",
      "2019-04-09 21:37:38,338 root         INFO     ====> Epoch: 19 Average loss: 0.2147\n",
      "2019-04-09 21:37:38,363 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 0.271651\n",
      "Reconstruction: 0.194017, Regularization: 0.044621, Discriminator: 0.021621; Generator: 0.011392,\n",
      "D(x): 0.544, D(G(z)): 0.484\n",
      "2019-04-09 21:37:38,448 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 0.223632\n",
      "Reconstruction: 0.162620, Regularization: 0.030949, Discriminator: 0.018617; Generator: 0.011446,\n",
      "D(x): 0.604, D(G(z)): 0.482\n",
      "2019-04-09 21:37:38,533 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 0.179660\n",
      "Reconstruction: 0.127171, Regularization: 0.021327, Discriminator: 0.019686; Generator: 0.011476,\n",
      "D(x): 0.562, D(G(z)): 0.481\n",
      "2019-04-09 21:37:38,618 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 0.216903\n",
      "Reconstruction: 0.154041, Regularization: 0.031818, Discriminator: 0.019501; Generator: 0.011543,\n",
      "D(x): 0.576, D(G(z)): 0.479\n",
      "2019-04-09 21:37:38,704 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 0.218488\n",
      "Reconstruction: 0.153284, Regularization: 0.033872, Discriminator: 0.019884; Generator: 0.011448,\n",
      "D(x): 0.576, D(G(z)): 0.482\n",
      "2019-04-09 21:37:38,792 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 0.278683\n",
      "Reconstruction: 0.206945, Regularization: 0.040044, Discriminator: 0.020390; Generator: 0.011304,\n",
      "D(x): 0.559, D(G(z)): 0.486\n",
      "2019-04-09 21:37:38,880 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 0.246214\n",
      "Reconstruction: 0.180277, Regularization: 0.034206, Discriminator: 0.020142; Generator: 0.011590,\n",
      "D(x): 0.560, D(G(z)): 0.478\n",
      "2019-04-09 21:37:38,968 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 0.182488\n",
      "Reconstruction: 0.127271, Regularization: 0.024313, Discriminator: 0.019111; Generator: 0.011793,\n",
      "D(x): 0.578, D(G(z)): 0.472\n",
      "2019-04-09 21:37:39,051 root         INFO     ====> Epoch: 20 Average loss: 0.2110\n",
      "2019-04-09 21:37:39,076 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.173615\n",
      "Reconstruction: 0.118561, Regularization: 0.023282, Discriminator: 0.020509; Generator: 0.011263,\n",
      "D(x): 0.552, D(G(z)): 0.488\n",
      "2019-04-09 21:37:39,160 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 0.223900\n",
      "Reconstruction: 0.160752, Regularization: 0.032752, Discriminator: 0.018665; Generator: 0.011731,\n",
      "D(x): 0.600, D(G(z)): 0.473\n",
      "2019-04-09 21:37:39,245 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 0.235836\n",
      "Reconstruction: 0.165558, Regularization: 0.037529, Discriminator: 0.021423; Generator: 0.011327,\n",
      "D(x): 0.549, D(G(z)): 0.486\n",
      "2019-04-09 21:37:39,329 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 0.297152\n",
      "Reconstruction: 0.219486, Regularization: 0.047332, Discriminator: 0.019130; Generator: 0.011203,\n",
      "D(x): 0.604, D(G(z)): 0.491\n",
      "2019-04-09 21:37:39,413 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.260761\n",
      "Reconstruction: 0.193839, Regularization: 0.035292, Discriminator: 0.020032; Generator: 0.011598,\n",
      "D(x): 0.559, D(G(z)): 0.478\n",
      "2019-04-09 21:37:39,497 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 0.206414\n",
      "Reconstruction: 0.147664, Regularization: 0.026106, Discriminator: 0.021072; Generator: 0.011573,\n",
      "D(x): 0.524, D(G(z)): 0.478\n",
      "2019-04-09 21:37:39,581 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 0.187864\n",
      "Reconstruction: 0.132533, Regularization: 0.023322, Discriminator: 0.020334; Generator: 0.011675,\n",
      "D(x): 0.545, D(G(z)): 0.476\n",
      "2019-04-09 21:37:39,666 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.199833\n",
      "Reconstruction: 0.141745, Regularization: 0.027900, Discriminator: 0.018746; Generator: 0.011443,\n",
      "D(x): 0.599, D(G(z)): 0.482\n",
      "2019-04-09 21:37:39,747 root         INFO     ====> Epoch: 21 Average loss: 0.2079\n",
      "2019-04-09 21:37:39,772 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 0.188384\n",
      "Reconstruction: 0.132686, Regularization: 0.025099, Discriminator: 0.018961; Generator: 0.011638,\n",
      "D(x): 0.586, D(G(z)): 0.476\n",
      "2019-04-09 21:37:39,860 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 0.245288\n",
      "Reconstruction: 0.175571, Regularization: 0.036845, Discriminator: 0.021289; Generator: 0.011583,\n",
      "D(x): 0.533, D(G(z)): 0.479\n",
      "2019-04-09 21:37:39,948 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 0.220308\n",
      "Reconstruction: 0.156497, Regularization: 0.032598, Discriminator: 0.019098; Generator: 0.012115,\n",
      "D(x): 0.573, D(G(z)): 0.462\n",
      "2019-04-09 21:37:40,035 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 0.224892\n",
      "Reconstruction: 0.162508, Regularization: 0.031266, Discriminator: 0.019537; Generator: 0.011582,\n",
      "D(x): 0.570, D(G(z)): 0.478\n",
      "2019-04-09 21:37:40,123 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.180547\n",
      "Reconstruction: 0.124066, Regularization: 0.024043, Discriminator: 0.020523; Generator: 0.011916,\n",
      "D(x): 0.534, D(G(z)): 0.468\n",
      "2019-04-09 21:37:40,213 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 0.186232\n",
      "Reconstruction: 0.128093, Regularization: 0.025904, Discriminator: 0.020470; Generator: 0.011764,\n",
      "D(x): 0.540, D(G(z)): 0.473\n",
      "2019-04-09 21:37:40,300 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 0.201632\n",
      "Reconstruction: 0.142815, Regularization: 0.026065, Discriminator: 0.021217; Generator: 0.011535,\n",
      "D(x): 0.523, D(G(z)): 0.480\n",
      "2019-04-09 21:37:40,385 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 0.194953\n",
      "Reconstruction: 0.136143, Regularization: 0.027379, Discriminator: 0.019638; Generator: 0.011793,\n",
      "D(x): 0.565, D(G(z)): 0.472\n",
      "2019-04-09 21:37:40,468 root         INFO     ====> Epoch: 22 Average loss: 0.2053\n",
      "2019-04-09 21:37:40,494 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 0.195562\n",
      "Reconstruction: 0.137355, Regularization: 0.026010, Discriminator: 0.020554; Generator: 0.011643,\n",
      "D(x): 0.545, D(G(z)): 0.477\n",
      "2019-04-09 21:37:40,584 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 0.174082\n",
      "Reconstruction: 0.120241, Regularization: 0.022886, Discriminator: 0.019037; Generator: 0.011919,\n",
      "D(x): 0.574, D(G(z)): 0.468\n",
      "2019-04-09 21:37:40,671 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 0.186618\n",
      "Reconstruction: 0.130559, Regularization: 0.024476, Discriminator: 0.019517; Generator: 0.012065,\n",
      "D(x): 0.557, D(G(z)): 0.463\n",
      "2019-04-09 21:37:40,760 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 0.219992\n",
      "Reconstruction: 0.158566, Regularization: 0.028318, Discriminator: 0.021246; Generator: 0.011862,\n",
      "D(x): 0.512, D(G(z)): 0.470\n",
      "2019-04-09 21:37:40,849 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 0.225593\n",
      "Reconstruction: 0.161822, Regularization: 0.032294, Discriminator: 0.019311; Generator: 0.012166,\n",
      "D(x): 0.568, D(G(z)): 0.461\n",
      "2019-04-09 21:37:40,938 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 0.191636\n",
      "Reconstruction: 0.136478, Regularization: 0.023867, Discriminator: 0.019546; Generator: 0.011745,\n",
      "D(x): 0.559, D(G(z)): 0.473\n",
      "2019-04-09 21:37:41,027 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 0.204085\n",
      "Reconstruction: 0.146026, Regularization: 0.025956, Discriminator: 0.019904; Generator: 0.012200,\n",
      "D(x): 0.548, D(G(z)): 0.460\n",
      "2019-04-09 21:37:41,117 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 0.191855\n",
      "Reconstruction: 0.134267, Regularization: 0.025916, Discriminator: 0.019829; Generator: 0.011843,\n",
      "D(x): 0.553, D(G(z)): 0.471\n",
      "2019-04-09 21:37:41,202 root         INFO     ====> Epoch: 23 Average loss: 0.2036\n",
      "2019-04-09 21:37:41,227 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.214832\n",
      "Reconstruction: 0.153233, Regularization: 0.028151, Discriminator: 0.021573; Generator: 0.011876,\n",
      "D(x): 0.502, D(G(z)): 0.469\n",
      "2019-04-09 21:37:41,316 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 0.162458\n",
      "Reconstruction: 0.110816, Regularization: 0.020408, Discriminator: 0.019541; Generator: 0.011692,\n",
      "D(x): 0.565, D(G(z)): 0.475\n",
      "2019-04-09 21:37:41,405 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 0.184655\n",
      "Reconstruction: 0.128053, Regularization: 0.024519, Discriminator: 0.020019; Generator: 0.012064,\n",
      "D(x): 0.542, D(G(z)): 0.464\n",
      "2019-04-09 21:37:41,495 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 0.185600\n",
      "Reconstruction: 0.129291, Regularization: 0.024952, Discriminator: 0.019216; Generator: 0.012140,\n",
      "D(x): 0.563, D(G(z)): 0.462\n",
      "2019-04-09 21:37:41,584 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 0.207324\n",
      "Reconstruction: 0.148568, Regularization: 0.027309, Discriminator: 0.019677; Generator: 0.011771,\n",
      "D(x): 0.560, D(G(z)): 0.473\n",
      "2019-04-09 21:37:41,673 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 0.184163\n",
      "Reconstruction: 0.127842, Regularization: 0.023519, Discriminator: 0.020968; Generator: 0.011834,\n",
      "D(x): 0.524, D(G(z)): 0.471\n",
      "2019-04-09 21:37:41,762 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 0.191025\n",
      "Reconstruction: 0.134771, Regularization: 0.024726, Discriminator: 0.019890; Generator: 0.011639,\n",
      "D(x): 0.558, D(G(z)): 0.477\n",
      "2019-04-09 21:37:41,849 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 0.206042\n",
      "Reconstruction: 0.149059, Regularization: 0.025679, Discriminator: 0.019249; Generator: 0.012053,\n",
      "D(x): 0.565, D(G(z)): 0.464\n",
      "2019-04-09 21:37:41,932 root         INFO     ====> Epoch: 24 Average loss: 0.2018\n",
      "2019-04-09 21:37:41,958 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 0.227780\n",
      "Reconstruction: 0.164527, Regularization: 0.030613, Discriminator: 0.020467; Generator: 0.012173,\n",
      "D(x): 0.531, D(G(z)): 0.460\n",
      "2019-04-09 21:37:42,046 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 0.167470\n",
      "Reconstruction: 0.114273, Regularization: 0.020890, Discriminator: 0.020407; Generator: 0.011901,\n",
      "D(x): 0.530, D(G(z)): 0.469\n",
      "2019-04-09 21:37:42,133 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 0.192425\n",
      "Reconstruction: 0.134453, Regularization: 0.025182, Discriminator: 0.020614; Generator: 0.012176,\n",
      "D(x): 0.523, D(G(z)): 0.460\n",
      "2019-04-09 21:37:42,220 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 0.197751\n",
      "Reconstruction: 0.140673, Regularization: 0.025108, Discriminator: 0.020134; Generator: 0.011836,\n",
      "D(x): 0.543, D(G(z)): 0.471\n",
      "2019-04-09 21:37:42,307 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 0.174694\n",
      "Reconstruction: 0.121886, Regularization: 0.020234, Discriminator: 0.020326; Generator: 0.012248,\n",
      "D(x): 0.523, D(G(z)): 0.459\n",
      "2019-04-09 21:37:42,394 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 0.218899\n",
      "Reconstruction: 0.154604, Regularization: 0.031414, Discriminator: 0.021061; Generator: 0.011819,\n",
      "D(x): 0.527, D(G(z)): 0.472\n",
      "2019-04-09 21:37:42,482 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.186435\n",
      "Reconstruction: 0.129692, Regularization: 0.024437, Discriminator: 0.020394; Generator: 0.011912,\n",
      "D(x): 0.539, D(G(z)): 0.468\n",
      "2019-04-09 21:37:42,569 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 0.163420\n",
      "Reconstruction: 0.111251, Regularization: 0.020606, Discriminator: 0.019574; Generator: 0.011989,\n",
      "D(x): 0.555, D(G(z)): 0.466\n",
      "2019-04-09 21:37:42,652 root         INFO     ====> Epoch: 25 Average loss: 0.1996\n",
      "2019-04-09 21:37:42,677 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 0.192436\n",
      "Reconstruction: 0.137342, Regularization: 0.023585, Discriminator: 0.019455; Generator: 0.012054,\n",
      "D(x): 0.554, D(G(z)): 0.465\n",
      "2019-04-09 21:37:42,765 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 0.213142\n",
      "Reconstruction: 0.154137, Regularization: 0.027093, Discriminator: 0.019866; Generator: 0.012046,\n",
      "D(x): 0.551, D(G(z)): 0.465\n",
      "2019-04-09 21:37:42,853 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 0.228122\n",
      "Reconstruction: 0.165324, Regularization: 0.030481, Discriminator: 0.020152; Generator: 0.012165,\n",
      "D(x): 0.536, D(G(z)): 0.461\n",
      "2019-04-09 21:37:42,940 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 0.204146\n",
      "Reconstruction: 0.145634, Regularization: 0.026427, Discriminator: 0.020020; Generator: 0.012066,\n",
      "D(x): 0.537, D(G(z)): 0.465\n",
      "2019-04-09 21:37:43,028 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.171022\n",
      "Reconstruction: 0.119027, Regularization: 0.020267, Discriminator: 0.019647; Generator: 0.012081,\n",
      "D(x): 0.544, D(G(z)): 0.464\n",
      "2019-04-09 21:37:43,115 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 0.210033\n",
      "Reconstruction: 0.149824, Regularization: 0.027479, Discriminator: 0.020206; Generator: 0.012524,\n",
      "D(x): 0.524, D(G(z)): 0.451\n",
      "2019-04-09 21:37:43,202 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 0.223795\n",
      "Reconstruction: 0.160524, Regularization: 0.030910, Discriminator: 0.020311; Generator: 0.012049,\n",
      "D(x): 0.544, D(G(z)): 0.464\n",
      "2019-04-09 21:37:43,289 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 0.225263\n",
      "Reconstruction: 0.166172, Regularization: 0.027577, Discriminator: 0.019315; Generator: 0.012199,\n",
      "D(x): 0.558, D(G(z)): 0.460\n",
      "2019-04-09 21:37:43,373 root         INFO     ====> Epoch: 26 Average loss: 0.1985\n",
      "2019-04-09 21:37:43,398 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 0.185157\n",
      "Reconstruction: 0.131819, Regularization: 0.020960, Discriminator: 0.020345; Generator: 0.012032,\n",
      "D(x): 0.526, D(G(z)): 0.465\n",
      "2019-04-09 21:37:43,484 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.190084\n",
      "Reconstruction: 0.135098, Regularization: 0.022657, Discriminator: 0.020327; Generator: 0.012003,\n",
      "D(x): 0.530, D(G(z)): 0.466\n",
      "2019-04-09 21:37:43,569 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 0.159618\n",
      "Reconstruction: 0.110517, Regularization: 0.016832, Discriminator: 0.020135; Generator: 0.012134,\n",
      "D(x): 0.527, D(G(z)): 0.462\n",
      "2019-04-09 21:37:43,654 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.183235\n",
      "Reconstruction: 0.129774, Regularization: 0.021086, Discriminator: 0.020391; Generator: 0.011983,\n",
      "D(x): 0.526, D(G(z)): 0.466\n",
      "2019-04-09 21:37:43,740 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 0.170475\n",
      "Reconstruction: 0.119056, Regularization: 0.018930, Discriminator: 0.020677; Generator: 0.011811,\n",
      "D(x): 0.526, D(G(z)): 0.471\n",
      "2019-04-09 21:37:43,826 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.194012\n",
      "Reconstruction: 0.139493, Regularization: 0.023174, Discriminator: 0.019127; Generator: 0.012218,\n",
      "D(x): 0.558, D(G(z)): 0.460\n",
      "2019-04-09 21:37:43,912 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.198625\n",
      "Reconstruction: 0.142573, Regularization: 0.023531, Discriminator: 0.020424; Generator: 0.012097,\n",
      "D(x): 0.521, D(G(z)): 0.463\n",
      "2019-04-09 21:37:43,997 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 0.167792\n",
      "Reconstruction: 0.117610, Regularization: 0.018505, Discriminator: 0.019554; Generator: 0.012123,\n",
      "D(x): 0.546, D(G(z)): 0.463\n",
      "2019-04-09 21:37:44,078 root         INFO     ====> Epoch: 27 Average loss: 0.1976\n",
      "2019-04-09 21:37:44,104 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.201575\n",
      "Reconstruction: 0.143942, Regularization: 0.024689, Discriminator: 0.020938; Generator: 0.012006,\n",
      "D(x): 0.519, D(G(z)): 0.465\n",
      "2019-04-09 21:37:44,192 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.197904\n",
      "Reconstruction: 0.142295, Regularization: 0.023847, Discriminator: 0.019929; Generator: 0.011833,\n",
      "D(x): 0.546, D(G(z)): 0.471\n",
      "2019-04-09 21:37:44,279 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 0.250029\n",
      "Reconstruction: 0.184425, Regularization: 0.033153, Discriminator: 0.020334; Generator: 0.012116,\n",
      "D(x): 0.532, D(G(z)): 0.462\n",
      "2019-04-09 21:37:44,366 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.195343\n",
      "Reconstruction: 0.137842, Regularization: 0.023847, Discriminator: 0.021678; Generator: 0.011976,\n",
      "D(x): 0.494, D(G(z)): 0.467\n",
      "2019-04-09 21:37:44,455 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.229705\n",
      "Reconstruction: 0.168411, Regularization: 0.028710, Discriminator: 0.020566; Generator: 0.012018,\n",
      "D(x): 0.528, D(G(z)): 0.466\n",
      "2019-04-09 21:37:44,544 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.185928\n",
      "Reconstruction: 0.131613, Regularization: 0.021885, Discriminator: 0.020557; Generator: 0.011873,\n",
      "D(x): 0.534, D(G(z)): 0.470\n",
      "2019-04-09 21:37:44,633 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.240413\n",
      "Reconstruction: 0.178952, Regularization: 0.029131, Discriminator: 0.020317; Generator: 0.012013,\n",
      "D(x): 0.527, D(G(z)): 0.466\n",
      "2019-04-09 21:37:44,721 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.215330\n",
      "Reconstruction: 0.156944, Regularization: 0.025836, Discriminator: 0.020764; Generator: 0.011785,\n",
      "D(x): 0.524, D(G(z)): 0.472\n",
      "2019-04-09 21:37:44,806 root         INFO     ====> Epoch: 28 Average loss: 0.1973\n",
      "2019-04-09 21:37:44,832 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 0.198307\n",
      "Reconstruction: 0.142587, Regularization: 0.023025, Discriminator: 0.021017; Generator: 0.011679,\n",
      "D(x): 0.515, D(G(z)): 0.475\n",
      "2019-04-09 21:37:44,918 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 0.169351\n",
      "Reconstruction: 0.119701, Regularization: 0.017274, Discriminator: 0.020292; Generator: 0.012084,\n",
      "D(x): 0.523, D(G(z)): 0.464\n",
      "2019-04-09 21:37:45,005 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 0.173732\n",
      "Reconstruction: 0.122951, Regularization: 0.019363, Discriminator: 0.019145; Generator: 0.012273,\n",
      "D(x): 0.554, D(G(z)): 0.458\n",
      "2019-04-09 21:37:45,092 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 0.220781\n",
      "Reconstruction: 0.161796, Regularization: 0.027183, Discriminator: 0.019964; Generator: 0.011839,\n",
      "D(x): 0.542, D(G(z)): 0.471\n",
      "2019-04-09 21:37:45,179 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.145985\n",
      "Reconstruction: 0.099672, Regularization: 0.014662, Discriminator: 0.019846; Generator: 0.011805,\n",
      "D(x): 0.543, D(G(z)): 0.472\n",
      "2019-04-09 21:37:45,265 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 0.174389\n",
      "Reconstruction: 0.122974, Regularization: 0.019565, Discriminator: 0.019897; Generator: 0.011953,\n",
      "D(x): 0.546, D(G(z)): 0.467\n",
      "2019-04-09 21:37:45,352 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 0.182473\n",
      "Reconstruction: 0.128993, Regularization: 0.021081, Discriminator: 0.020626; Generator: 0.011773,\n",
      "D(x): 0.536, D(G(z)): 0.472\n",
      "2019-04-09 21:37:45,438 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.195054\n",
      "Reconstruction: 0.140959, Regularization: 0.021592, Discriminator: 0.020974; Generator: 0.011530,\n",
      "D(x): 0.521, D(G(z)): 0.480\n",
      "2019-04-09 21:37:45,522 root         INFO     ====> Epoch: 29 Average loss: 0.1972\n",
      "2019-04-09 21:37:45,547 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.179037\n",
      "Reconstruction: 0.126661, Regularization: 0.019745, Discriminator: 0.020401; Generator: 0.012230,\n",
      "D(x): 0.517, D(G(z)): 0.459\n",
      "2019-04-09 21:37:45,633 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.207551\n",
      "Reconstruction: 0.150169, Regularization: 0.025321, Discriminator: 0.019990; Generator: 0.012070,\n",
      "D(x): 0.539, D(G(z)): 0.464\n",
      "2019-04-09 21:37:45,718 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.194036\n",
      "Reconstruction: 0.139672, Regularization: 0.021937, Discriminator: 0.020768; Generator: 0.011659,\n",
      "D(x): 0.525, D(G(z)): 0.476\n",
      "2019-04-09 21:37:45,802 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.217967\n",
      "Reconstruction: 0.161045, Regularization: 0.024982, Discriminator: 0.020108; Generator: 0.011831,\n",
      "D(x): 0.539, D(G(z)): 0.471\n",
      "2019-04-09 21:37:45,889 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.154340\n",
      "Reconstruction: 0.107127, Regularization: 0.014807, Discriminator: 0.020637; Generator: 0.011768,\n",
      "D(x): 0.522, D(G(z)): 0.473\n",
      "2019-04-09 21:37:45,976 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.222192\n",
      "Reconstruction: 0.165412, Regularization: 0.024990, Discriminator: 0.019888; Generator: 0.011901,\n",
      "D(x): 0.539, D(G(z)): 0.469\n",
      "2019-04-09 21:37:46,063 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.222523\n",
      "Reconstruction: 0.164041, Regularization: 0.025720, Discriminator: 0.021102; Generator: 0.011659,\n",
      "D(x): 0.516, D(G(z)): 0.476\n",
      "2019-04-09 21:37:46,149 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 0.189292\n",
      "Reconstruction: 0.136500, Regularization: 0.020514, Discriminator: 0.020744; Generator: 0.011534,\n",
      "D(x): 0.529, D(G(z)): 0.480\n",
      "2019-04-09 21:37:46,233 root         INFO     ====> Epoch: 30 Average loss: 0.1976\n",
      "2019-04-09 21:37:46,258 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.220895\n",
      "Reconstruction: 0.162996, Regularization: 0.025608, Discriminator: 0.020557; Generator: 0.011734,\n",
      "D(x): 0.530, D(G(z)): 0.474\n",
      "2019-04-09 21:37:46,346 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.199412\n",
      "Reconstruction: 0.145194, Regularization: 0.022115, Discriminator: 0.020675; Generator: 0.011428,\n",
      "D(x): 0.530, D(G(z)): 0.483\n",
      "2019-04-09 21:37:46,433 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 0.222992\n",
      "Reconstruction: 0.164400, Regularization: 0.026406, Discriminator: 0.020785; Generator: 0.011400,\n",
      "D(x): 0.529, D(G(z)): 0.484\n",
      "2019-04-09 21:37:46,520 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.217471\n",
      "Reconstruction: 0.160447, Regularization: 0.024742, Discriminator: 0.020847; Generator: 0.011435,\n",
      "D(x): 0.524, D(G(z)): 0.482\n",
      "2019-04-09 21:37:46,607 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.175486\n",
      "Reconstruction: 0.123932, Regularization: 0.018008, Discriminator: 0.021973; Generator: 0.011573,\n",
      "D(x): 0.491, D(G(z)): 0.479\n",
      "2019-04-09 21:37:46,694 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.217750\n",
      "Reconstruction: 0.161847, Regularization: 0.023702, Discriminator: 0.020621; Generator: 0.011581,\n",
      "D(x): 0.523, D(G(z)): 0.478\n",
      "2019-04-09 21:37:46,784 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 0.220543\n",
      "Reconstruction: 0.163936, Regularization: 0.024398, Discriminator: 0.020712; Generator: 0.011496,\n",
      "D(x): 0.527, D(G(z)): 0.481\n",
      "2019-04-09 21:37:46,875 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 0.157928\n",
      "Reconstruction: 0.110284, Regularization: 0.015296, Discriminator: 0.020913; Generator: 0.011435,\n",
      "D(x): 0.526, D(G(z)): 0.483\n",
      "2019-04-09 21:37:46,961 root         INFO     ====> Epoch: 31 Average loss: 0.1978\n",
      "2019-04-09 21:37:46,986 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.247885\n",
      "Reconstruction: 0.187343, Regularization: 0.028467, Discriminator: 0.020556; Generator: 0.011519,\n",
      "D(x): 0.535, D(G(z)): 0.480\n",
      "2019-04-09 21:37:47,077 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.205663\n",
      "Reconstruction: 0.152062, Regularization: 0.021313, Discriminator: 0.020786; Generator: 0.011502,\n",
      "D(x): 0.522, D(G(z)): 0.481\n",
      "2019-04-09 21:37:47,167 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.198766\n",
      "Reconstruction: 0.144797, Regularization: 0.021442, Discriminator: 0.020980; Generator: 0.011547,\n",
      "D(x): 0.519, D(G(z)): 0.479\n",
      "2019-04-09 21:37:47,257 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.196908\n",
      "Reconstruction: 0.143042, Regularization: 0.021135, Discriminator: 0.021306; Generator: 0.011425,\n",
      "D(x): 0.511, D(G(z)): 0.483\n",
      "2019-04-09 21:37:47,347 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.185812\n",
      "Reconstruction: 0.135081, Regularization: 0.018232, Discriminator: 0.020944; Generator: 0.011555,\n",
      "D(x): 0.518, D(G(z)): 0.480\n",
      "2019-04-09 21:37:47,437 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 0.252806\n",
      "Reconstruction: 0.191000, Regularization: 0.028466, Discriminator: 0.021953; Generator: 0.011387,\n",
      "D(x): 0.500, D(G(z)): 0.484\n",
      "2019-04-09 21:37:47,527 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.230334\n",
      "Reconstruction: 0.172727, Regularization: 0.024838, Discriminator: 0.021384; Generator: 0.011386,\n",
      "D(x): 0.513, D(G(z)): 0.484\n",
      "2019-04-09 21:37:47,616 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.194706\n",
      "Reconstruction: 0.141561, Regularization: 0.019524, Discriminator: 0.022046; Generator: 0.011575,\n",
      "D(x): 0.483, D(G(z)): 0.478\n",
      "2019-04-09 21:37:47,703 root         INFO     ====> Epoch: 32 Average loss: 0.1992\n",
      "2019-04-09 21:37:47,728 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.249127\n",
      "Reconstruction: 0.190799, Regularization: 0.025905, Discriminator: 0.020925; Generator: 0.011497,\n",
      "D(x): 0.519, D(G(z)): 0.481\n",
      "2019-04-09 21:37:47,820 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.176734\n",
      "Reconstruction: 0.127086, Regularization: 0.017142, Discriminator: 0.021163; Generator: 0.011342,\n",
      "D(x): 0.518, D(G(z)): 0.485\n",
      "2019-04-09 21:37:47,910 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.203554\n",
      "Reconstruction: 0.150094, Regularization: 0.021199, Discriminator: 0.020874; Generator: 0.011387,\n",
      "D(x): 0.528, D(G(z)): 0.484\n",
      "2019-04-09 21:37:48,000 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.230644\n",
      "Reconstruction: 0.173525, Regularization: 0.023893, Discriminator: 0.021664; Generator: 0.011562,\n",
      "D(x): 0.498, D(G(z)): 0.479\n",
      "2019-04-09 21:37:48,089 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 0.208878\n",
      "Reconstruction: 0.152562, Regularization: 0.022800, Discriminator: 0.022138; Generator: 0.011379,\n",
      "D(x): 0.495, D(G(z)): 0.484\n",
      "2019-04-09 21:37:48,178 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.153835\n",
      "Reconstruction: 0.108875, Regularization: 0.012768, Discriminator: 0.020876; Generator: 0.011316,\n",
      "D(x): 0.522, D(G(z)): 0.486\n",
      "2019-04-09 21:37:48,268 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 0.190618\n",
      "Reconstruction: 0.138268, Regularization: 0.018724, Discriminator: 0.022408; Generator: 0.011218,\n",
      "D(x): 0.481, D(G(z)): 0.489\n",
      "2019-04-09 21:37:48,356 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.176145\n",
      "Reconstruction: 0.126090, Regularization: 0.016795, Discriminator: 0.021694; Generator: 0.011566,\n",
      "D(x): 0.500, D(G(z)): 0.479\n",
      "2019-04-09 21:37:48,440 root         INFO     ====> Epoch: 33 Average loss: 0.1998\n",
      "2019-04-09 21:37:48,466 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.178125\n",
      "Reconstruction: 0.129067, Regularization: 0.016560, Discriminator: 0.020806; Generator: 0.011691,\n",
      "D(x): 0.517, D(G(z)): 0.475\n",
      "2019-04-09 21:37:48,556 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.215239\n",
      "Reconstruction: 0.161646, Regularization: 0.021554, Discriminator: 0.020724; Generator: 0.011315,\n",
      "D(x): 0.534, D(G(z)): 0.486\n",
      "2019-04-09 21:37:48,646 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.202318\n",
      "Reconstruction: 0.150042, Regularization: 0.019836, Discriminator: 0.021378; Generator: 0.011061,\n",
      "D(x): 0.516, D(G(z)): 0.494\n",
      "2019-04-09 21:37:48,736 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.191517\n",
      "Reconstruction: 0.141073, Regularization: 0.017382, Discriminator: 0.021950; Generator: 0.011113,\n",
      "D(x): 0.500, D(G(z)): 0.492\n",
      "2019-04-09 21:37:48,826 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.200008\n",
      "Reconstruction: 0.147928, Regularization: 0.019611, Discriminator: 0.021123; Generator: 0.011346,\n",
      "D(x): 0.514, D(G(z)): 0.485\n",
      "2019-04-09 21:37:48,912 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.201425\n",
      "Reconstruction: 0.149475, Regularization: 0.018931, Discriminator: 0.021776; Generator: 0.011242,\n",
      "D(x): 0.500, D(G(z)): 0.489\n",
      "2019-04-09 21:37:48,997 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.189694\n",
      "Reconstruction: 0.138935, Regularization: 0.017546, Discriminator: 0.021916; Generator: 0.011297,\n",
      "D(x): 0.489, D(G(z)): 0.486\n",
      "2019-04-09 21:37:49,083 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 0.215575\n",
      "Reconstruction: 0.162501, Regularization: 0.020765, Discriminator: 0.021034; Generator: 0.011275,\n",
      "D(x): 0.516, D(G(z)): 0.487\n",
      "2019-04-09 21:37:49,167 root         INFO     ====> Epoch: 34 Average loss: 0.2008\n",
      "2019-04-09 21:37:49,192 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.236466\n",
      "Reconstruction: 0.179826, Regularization: 0.024169, Discriminator: 0.021269; Generator: 0.011201,\n",
      "D(x): 0.517, D(G(z)): 0.489\n",
      "2019-04-09 21:37:49,280 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.185120\n",
      "Reconstruction: 0.134984, Regularization: 0.016934, Discriminator: 0.022152; Generator: 0.011050,\n",
      "D(x): 0.491, D(G(z)): 0.494\n",
      "2019-04-09 21:37:49,367 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.195985\n",
      "Reconstruction: 0.144712, Regularization: 0.017982, Discriminator: 0.022134; Generator: 0.011158,\n",
      "D(x): 0.487, D(G(z)): 0.491\n",
      "2019-04-09 21:37:49,454 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.180608\n",
      "Reconstruction: 0.131833, Regularization: 0.016000, Discriminator: 0.021614; Generator: 0.011161,\n",
      "D(x): 0.500, D(G(z)): 0.491\n",
      "2019-04-09 21:37:49,541 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.220675\n",
      "Reconstruction: 0.166444, Regularization: 0.021061, Discriminator: 0.022148; Generator: 0.011022,\n",
      "D(x): 0.492, D(G(z)): 0.495\n",
      "2019-04-09 21:37:49,627 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.200226\n",
      "Reconstruction: 0.147742, Regularization: 0.019693, Discriminator: 0.021547; Generator: 0.011244,\n",
      "D(x): 0.506, D(G(z)): 0.488\n",
      "2019-04-09 21:37:49,713 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.152730\n",
      "Reconstruction: 0.108067, Regularization: 0.011854, Discriminator: 0.021762; Generator: 0.011047,\n",
      "D(x): 0.499, D(G(z)): 0.494\n",
      "2019-04-09 21:37:49,800 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.201696\n",
      "Reconstruction: 0.150703, Regularization: 0.018349, Discriminator: 0.021448; Generator: 0.011195,\n",
      "D(x): 0.504, D(G(z)): 0.489\n",
      "2019-04-09 21:37:49,884 root         INFO     ====> Epoch: 35 Average loss: 0.2015\n",
      "2019-04-09 21:37:49,909 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 0.192333\n",
      "Reconstruction: 0.142603, Regularization: 0.016418, Discriminator: 0.022083; Generator: 0.011229,\n",
      "D(x): 0.486, D(G(z)): 0.489\n",
      "2019-04-09 21:37:49,996 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.201069\n",
      "Reconstruction: 0.150292, Regularization: 0.017831, Discriminator: 0.021981; Generator: 0.010965,\n",
      "D(x): 0.496, D(G(z)): 0.497\n",
      "2019-04-09 21:37:50,081 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.184288\n",
      "Reconstruction: 0.135962, Regularization: 0.015989, Discriminator: 0.021363; Generator: 0.010974,\n",
      "D(x): 0.516, D(G(z)): 0.497\n",
      "2019-04-09 21:37:50,167 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.180739\n",
      "Reconstruction: 0.130913, Regularization: 0.015857, Discriminator: 0.023006; Generator: 0.010964,\n",
      "D(x): 0.466, D(G(z)): 0.497\n",
      "2019-04-09 21:37:50,253 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.181170\n",
      "Reconstruction: 0.132889, Regularization: 0.015486, Discriminator: 0.021907; Generator: 0.010887,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 21:37:50,339 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.161490\n",
      "Reconstruction: 0.116516, Regularization: 0.012399, Discriminator: 0.021371; Generator: 0.011205,\n",
      "D(x): 0.507, D(G(z)): 0.489\n",
      "2019-04-09 21:37:50,425 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 0.216355\n",
      "Reconstruction: 0.165125, Regularization: 0.018333, Discriminator: 0.022042; Generator: 0.010854,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 21:37:50,511 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.268116\n",
      "Reconstruction: 0.207724, Regularization: 0.026986, Discriminator: 0.022563; Generator: 0.010843,\n",
      "D(x): 0.483, D(G(z)): 0.500\n",
      "2019-04-09 21:37:50,594 root         INFO     ====> Epoch: 36 Average loss: 0.2026\n",
      "2019-04-09 21:37:50,619 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.201808\n",
      "Reconstruction: 0.150558, Regularization: 0.017875, Discriminator: 0.022567; Generator: 0.010808,\n",
      "D(x): 0.483, D(G(z)): 0.502\n",
      "2019-04-09 21:37:50,705 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.207456\n",
      "Reconstruction: 0.156173, Regularization: 0.018280, Discriminator: 0.021987; Generator: 0.011016,\n",
      "D(x): 0.493, D(G(z)): 0.495\n",
      "2019-04-09 21:37:50,791 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.197849\n",
      "Reconstruction: 0.147823, Regularization: 0.016846, Discriminator: 0.022292; Generator: 0.010888,\n",
      "D(x): 0.486, D(G(z)): 0.499\n",
      "2019-04-09 21:37:50,879 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 0.164508\n",
      "Reconstruction: 0.118762, Regularization: 0.013026, Discriminator: 0.021719; Generator: 0.011001,\n",
      "D(x): 0.501, D(G(z)): 0.495\n",
      "2019-04-09 21:37:50,967 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.189227\n",
      "Reconstruction: 0.140181, Regularization: 0.015998, Discriminator: 0.022126; Generator: 0.010923,\n",
      "D(x): 0.491, D(G(z)): 0.498\n",
      "2019-04-09 21:37:51,055 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.263389\n",
      "Reconstruction: 0.205527, Regularization: 0.024942, Discriminator: 0.021967; Generator: 0.010953,\n",
      "D(x): 0.496, D(G(z)): 0.497\n",
      "2019-04-09 21:37:51,143 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.154535\n",
      "Reconstruction: 0.110378, Regularization: 0.011424, Discriminator: 0.021857; Generator: 0.010876,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 21:37:51,232 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.197624\n",
      "Reconstruction: 0.148828, Regularization: 0.015636, Discriminator: 0.022188; Generator: 0.010972,\n",
      "D(x): 0.486, D(G(z)): 0.496\n",
      "2019-04-09 21:37:51,319 root         INFO     ====> Epoch: 37 Average loss: 0.2034\n",
      "2019-04-09 21:37:51,344 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.183673\n",
      "Reconstruction: 0.136549, Regularization: 0.014668, Discriminator: 0.021543; Generator: 0.010912,\n",
      "D(x): 0.507, D(G(z)): 0.498\n",
      "2019-04-09 21:37:51,432 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.167657\n",
      "Reconstruction: 0.121527, Regularization: 0.012595, Discriminator: 0.022739; Generator: 0.010796,\n",
      "D(x): 0.475, D(G(z)): 0.502\n",
      "2019-04-09 21:37:51,520 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.198447\n",
      "Reconstruction: 0.148176, Regularization: 0.017142, Discriminator: 0.022193; Generator: 0.010937,\n",
      "D(x): 0.490, D(G(z)): 0.497\n",
      "2019-04-09 21:37:51,608 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 0.219574\n",
      "Reconstruction: 0.167843, Regularization: 0.019006, Discriminator: 0.021514; Generator: 0.011210,\n",
      "D(x): 0.501, D(G(z)): 0.488\n",
      "2019-04-09 21:37:51,696 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.235679\n",
      "Reconstruction: 0.182590, Regularization: 0.020098, Discriminator: 0.022058; Generator: 0.010933,\n",
      "D(x): 0.493, D(G(z)): 0.497\n",
      "2019-04-09 21:37:51,784 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.179272\n",
      "Reconstruction: 0.131961, Regularization: 0.013992, Discriminator: 0.022428; Generator: 0.010891,\n",
      "D(x): 0.482, D(G(z)): 0.499\n",
      "2019-04-09 21:37:51,870 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.214432\n",
      "Reconstruction: 0.163691, Regularization: 0.017480, Discriminator: 0.022454; Generator: 0.010806,\n",
      "D(x): 0.482, D(G(z)): 0.501\n",
      "2019-04-09 21:37:51,955 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.199989\n",
      "Reconstruction: 0.150902, Regularization: 0.015757, Discriminator: 0.022372; Generator: 0.010958,\n",
      "D(x): 0.480, D(G(z)): 0.496\n",
      "2019-04-09 21:37:52,038 root         INFO     ====> Epoch: 38 Average loss: 0.2041\n",
      "2019-04-09 21:37:52,063 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 0.221069\n",
      "Reconstruction: 0.170116, Regularization: 0.018314, Discriminator: 0.021675; Generator: 0.010965,\n",
      "D(x): 0.500, D(G(z)): 0.496\n",
      "2019-04-09 21:37:52,152 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.187797\n",
      "Reconstruction: 0.139005, Regularization: 0.015109, Discriminator: 0.022667; Generator: 0.011016,\n",
      "D(x): 0.471, D(G(z)): 0.495\n",
      "2019-04-09 21:37:52,240 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.252135\n",
      "Reconstruction: 0.198011, Regularization: 0.021624, Discriminator: 0.021555; Generator: 0.010945,\n",
      "D(x): 0.505, D(G(z)): 0.497\n",
      "2019-04-09 21:37:52,328 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.223148\n",
      "Reconstruction: 0.172302, Regularization: 0.017863, Discriminator: 0.022058; Generator: 0.010924,\n",
      "D(x): 0.490, D(G(z)): 0.497\n",
      "2019-04-09 21:37:52,415 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.166288\n",
      "Reconstruction: 0.121280, Regularization: 0.012134, Discriminator: 0.022134; Generator: 0.010739,\n",
      "D(x): 0.492, D(G(z)): 0.503\n",
      "2019-04-09 21:37:52,503 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.222282\n",
      "Reconstruction: 0.171305, Regularization: 0.017722, Discriminator: 0.022407; Generator: 0.010849,\n",
      "D(x): 0.482, D(G(z)): 0.500\n",
      "2019-04-09 21:37:52,592 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.233164\n",
      "Reconstruction: 0.181128, Regularization: 0.018957, Discriminator: 0.022257; Generator: 0.010822,\n",
      "D(x): 0.487, D(G(z)): 0.501\n",
      "2019-04-09 21:37:52,680 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.219847\n",
      "Reconstruction: 0.170281, Regularization: 0.016982, Discriminator: 0.021730; Generator: 0.010853,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:37:52,763 root         INFO     ====> Epoch: 39 Average loss: 0.2048\n",
      "2019-04-09 21:37:52,789 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.203154\n",
      "Reconstruction: 0.154064, Regularization: 0.016007, Discriminator: 0.022256; Generator: 0.010827,\n",
      "D(x): 0.486, D(G(z)): 0.500\n",
      "2019-04-09 21:37:52,877 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.174062\n",
      "Reconstruction: 0.129029, Regularization: 0.011784, Discriminator: 0.022455; Generator: 0.010794,\n",
      "D(x): 0.480, D(G(z)): 0.502\n",
      "2019-04-09 21:37:52,966 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.269022\n",
      "Reconstruction: 0.213171, Regularization: 0.022456, Discriminator: 0.022645; Generator: 0.010749,\n",
      "D(x): 0.477, D(G(z)): 0.503\n",
      "2019-04-09 21:37:53,054 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.195808\n",
      "Reconstruction: 0.148837, Regularization: 0.014193, Discriminator: 0.021921; Generator: 0.010857,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 21:37:53,142 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.177608\n",
      "Reconstruction: 0.132580, Regularization: 0.011837, Discriminator: 0.022455; Generator: 0.010736,\n",
      "D(x): 0.482, D(G(z)): 0.503\n",
      "2019-04-09 21:37:53,230 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 0.204618\n",
      "Reconstruction: 0.155311, Regularization: 0.015797, Discriminator: 0.022602; Generator: 0.010908,\n",
      "D(x): 0.474, D(G(z)): 0.498\n",
      "2019-04-09 21:37:53,316 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.223584\n",
      "Reconstruction: 0.172026, Regularization: 0.018174, Discriminator: 0.022599; Generator: 0.010784,\n",
      "D(x): 0.479, D(G(z)): 0.502\n",
      "2019-04-09 21:37:53,403 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.201042\n",
      "Reconstruction: 0.152299, Regularization: 0.015465, Discriminator: 0.022472; Generator: 0.010805,\n",
      "D(x): 0.478, D(G(z)): 0.501\n",
      "2019-04-09 21:37:53,485 root         INFO     ====> Epoch: 40 Average loss: 0.2056\n",
      "2019-04-09 21:37:53,511 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 0.160494\n",
      "Reconstruction: 0.116827, Regularization: 0.010831, Discriminator: 0.021933; Generator: 0.010903,\n",
      "D(x): 0.493, D(G(z)): 0.498\n",
      "2019-04-09 21:37:53,599 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.168128\n",
      "Reconstruction: 0.123966, Regularization: 0.010876, Discriminator: 0.022455; Generator: 0.010831,\n",
      "D(x): 0.479, D(G(z)): 0.500\n",
      "2019-04-09 21:37:53,686 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 0.277886\n",
      "Reconstruction: 0.222637, Regularization: 0.022050, Discriminator: 0.022258; Generator: 0.010940,\n",
      "D(x): 0.481, D(G(z)): 0.497\n",
      "2019-04-09 21:37:53,772 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.162446\n",
      "Reconstruction: 0.119448, Regularization: 0.009993, Discriminator: 0.022147; Generator: 0.010859,\n",
      "D(x): 0.486, D(G(z)): 0.499\n",
      "2019-04-09 21:37:53,857 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.172155\n",
      "Reconstruction: 0.126410, Regularization: 0.012123, Discriminator: 0.022796; Generator: 0.010825,\n",
      "D(x): 0.469, D(G(z)): 0.500\n",
      "2019-04-09 21:37:53,943 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 0.224411\n",
      "Reconstruction: 0.174170, Regularization: 0.016832, Discriminator: 0.022494; Generator: 0.010915,\n",
      "D(x): 0.476, D(G(z)): 0.497\n",
      "2019-04-09 21:37:54,029 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.190593\n",
      "Reconstruction: 0.142983, Regularization: 0.014283, Discriminator: 0.022423; Generator: 0.010904,\n",
      "D(x): 0.478, D(G(z)): 0.498\n",
      "2019-04-09 21:37:54,115 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.183422\n",
      "Reconstruction: 0.137545, Regularization: 0.012766, Discriminator: 0.022106; Generator: 0.011005,\n",
      "D(x): 0.485, D(G(z)): 0.495\n",
      "2019-04-09 21:37:54,197 root         INFO     ====> Epoch: 41 Average loss: 0.2060\n",
      "2019-04-09 21:37:54,223 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.225310\n",
      "Reconstruction: 0.175290, Regularization: 0.017118, Discriminator: 0.021997; Generator: 0.010904,\n",
      "D(x): 0.490, D(G(z)): 0.498\n",
      "2019-04-09 21:37:54,311 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.163455\n",
      "Reconstruction: 0.119775, Regularization: 0.010476, Discriminator: 0.022282; Generator: 0.010922,\n",
      "D(x): 0.481, D(G(z)): 0.497\n",
      "2019-04-09 21:37:54,398 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.184231\n",
      "Reconstruction: 0.139547, Regularization: 0.011767, Discriminator: 0.022090; Generator: 0.010827,\n",
      "D(x): 0.489, D(G(z)): 0.500\n",
      "2019-04-09 21:37:54,484 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 0.203718\n",
      "Reconstruction: 0.156650, Regularization: 0.013934, Discriminator: 0.022216; Generator: 0.010918,\n",
      "D(x): 0.483, D(G(z)): 0.497\n",
      "2019-04-09 21:37:54,570 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.244900\n",
      "Reconstruction: 0.193988, Regularization: 0.017519, Discriminator: 0.022532; Generator: 0.010860,\n",
      "D(x): 0.475, D(G(z)): 0.499\n",
      "2019-04-09 21:37:54,656 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.191396\n",
      "Reconstruction: 0.144843, Regularization: 0.013571, Discriminator: 0.022072; Generator: 0.010910,\n",
      "D(x): 0.487, D(G(z)): 0.498\n",
      "2019-04-09 21:37:54,741 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.158746\n",
      "Reconstruction: 0.116883, Regularization: 0.008932, Discriminator: 0.022043; Generator: 0.010889,\n",
      "D(x): 0.488, D(G(z)): 0.498\n",
      "2019-04-09 21:37:54,827 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.186017\n",
      "Reconstruction: 0.140641, Regularization: 0.012064, Discriminator: 0.022524; Generator: 0.010788,\n",
      "D(x): 0.477, D(G(z)): 0.501\n",
      "2019-04-09 21:37:54,910 root         INFO     ====> Epoch: 42 Average loss: 0.2064\n",
      "2019-04-09 21:37:54,936 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.184242\n",
      "Reconstruction: 0.139438, Regularization: 0.011962, Discriminator: 0.021903; Generator: 0.010939,\n",
      "D(x): 0.491, D(G(z)): 0.497\n",
      "2019-04-09 21:37:55,023 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.195167\n",
      "Reconstruction: 0.149438, Regularization: 0.012746, Discriminator: 0.022177; Generator: 0.010807,\n",
      "D(x): 0.486, D(G(z)): 0.501\n",
      "2019-04-09 21:37:55,112 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.188604\n",
      "Reconstruction: 0.143539, Regularization: 0.011998, Discriminator: 0.022222; Generator: 0.010845,\n",
      "D(x): 0.484, D(G(z)): 0.500\n",
      "2019-04-09 21:37:55,200 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.194822\n",
      "Reconstruction: 0.149710, Regularization: 0.011943, Discriminator: 0.022247; Generator: 0.010922,\n",
      "D(x): 0.481, D(G(z)): 0.497\n",
      "2019-04-09 21:37:55,289 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.227097\n",
      "Reconstruction: 0.179378, Regularization: 0.014997, Discriminator: 0.021819; Generator: 0.010904,\n",
      "D(x): 0.494, D(G(z)): 0.498\n",
      "2019-04-09 21:37:55,377 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.208363\n",
      "Reconstruction: 0.161513, Regularization: 0.013646, Discriminator: 0.022313; Generator: 0.010891,\n",
      "D(x): 0.479, D(G(z)): 0.498\n",
      "2019-04-09 21:37:55,466 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.185440\n",
      "Reconstruction: 0.140662, Regularization: 0.012056, Discriminator: 0.021855; Generator: 0.010867,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 21:37:55,554 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.209416\n",
      "Reconstruction: 0.162653, Regularization: 0.013807, Discriminator: 0.022070; Generator: 0.010887,\n",
      "D(x): 0.486, D(G(z)): 0.498\n",
      "2019-04-09 21:37:55,639 root         INFO     ====> Epoch: 43 Average loss: 0.2065\n",
      "2019-04-09 21:37:55,665 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.189548\n",
      "Reconstruction: 0.144721, Regularization: 0.011754, Discriminator: 0.022215; Generator: 0.010859,\n",
      "D(x): 0.483, D(G(z)): 0.499\n",
      "2019-04-09 21:37:55,755 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.195334\n",
      "Reconstruction: 0.150324, Regularization: 0.011959, Discriminator: 0.022180; Generator: 0.010871,\n",
      "D(x): 0.484, D(G(z)): 0.499\n",
      "2019-04-09 21:37:55,844 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.212210\n",
      "Reconstruction: 0.166319, Regularization: 0.012781, Discriminator: 0.022199; Generator: 0.010911,\n",
      "D(x): 0.482, D(G(z)): 0.497\n",
      "2019-04-09 21:37:55,933 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.227812\n",
      "Reconstruction: 0.179788, Regularization: 0.014995, Discriminator: 0.022181; Generator: 0.010847,\n",
      "D(x): 0.484, D(G(z)): 0.500\n",
      "2019-04-09 21:37:56,021 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.237658\n",
      "Reconstruction: 0.188325, Regularization: 0.016493, Discriminator: 0.022008; Generator: 0.010832,\n",
      "D(x): 0.491, D(G(z)): 0.500\n",
      "2019-04-09 21:37:56,110 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.196939\n",
      "Reconstruction: 0.151599, Regularization: 0.012562, Discriminator: 0.021844; Generator: 0.010933,\n",
      "D(x): 0.492, D(G(z)): 0.497\n",
      "2019-04-09 21:37:56,198 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.225216\n",
      "Reconstruction: 0.176742, Regularization: 0.015293, Discriminator: 0.022232; Generator: 0.010949,\n",
      "D(x): 0.480, D(G(z)): 0.496\n",
      "2019-04-09 21:37:56,287 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.178888\n",
      "Reconstruction: 0.135459, Regularization: 0.010486, Discriminator: 0.022078; Generator: 0.010864,\n",
      "D(x): 0.487, D(G(z)): 0.499\n",
      "2019-04-09 21:37:56,372 root         INFO     ====> Epoch: 44 Average loss: 0.2072\n",
      "2019-04-09 21:37:56,398 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.217125\n",
      "Reconstruction: 0.170949, Regularization: 0.013103, Discriminator: 0.022189; Generator: 0.010883,\n",
      "D(x): 0.483, D(G(z)): 0.498\n",
      "2019-04-09 21:37:56,488 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 0.212097\n",
      "Reconstruction: 0.165162, Regularization: 0.014034, Discriminator: 0.021966; Generator: 0.010935,\n",
      "D(x): 0.488, D(G(z)): 0.497\n",
      "2019-04-09 21:37:56,577 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.163981\n",
      "Reconstruction: 0.121517, Regularization: 0.009537, Discriminator: 0.022023; Generator: 0.010904,\n",
      "D(x): 0.487, D(G(z)): 0.498\n",
      "2019-04-09 21:37:56,667 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.204709\n",
      "Reconstruction: 0.158047, Regularization: 0.013724, Discriminator: 0.022052; Generator: 0.010886,\n",
      "D(x): 0.487, D(G(z)): 0.498\n",
      "2019-04-09 21:37:56,757 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.244710\n",
      "Reconstruction: 0.195113, Regularization: 0.016560, Discriminator: 0.022163; Generator: 0.010874,\n",
      "D(x): 0.484, D(G(z)): 0.499\n",
      "2019-04-09 21:37:56,846 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.217371\n",
      "Reconstruction: 0.169838, Regularization: 0.014539, Discriminator: 0.022063; Generator: 0.010932,\n",
      "D(x): 0.486, D(G(z)): 0.497\n",
      "2019-04-09 21:37:56,936 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.223149\n",
      "Reconstruction: 0.175803, Regularization: 0.014351, Discriminator: 0.022139; Generator: 0.010857,\n",
      "D(x): 0.486, D(G(z)): 0.499\n",
      "2019-04-09 21:37:57,026 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.211168\n",
      "Reconstruction: 0.165223, Regularization: 0.013023, Discriminator: 0.022058; Generator: 0.010865,\n",
      "D(x): 0.487, D(G(z)): 0.499\n",
      "2019-04-09 21:37:57,112 root         INFO     ====> Epoch: 45 Average loss: 0.2073\n",
      "2019-04-09 21:37:57,137 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.189649\n",
      "Reconstruction: 0.146528, Regularization: 0.010449, Discriminator: 0.021777; Generator: 0.010895,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 21:37:57,229 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.203628\n",
      "Reconstruction: 0.157757, Regularization: 0.012989, Discriminator: 0.021973; Generator: 0.010909,\n",
      "D(x): 0.489, D(G(z)): 0.498\n",
      "2019-04-09 21:37:57,315 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.194180\n",
      "Reconstruction: 0.149067, Regularization: 0.012167, Discriminator: 0.022043; Generator: 0.010904,\n",
      "D(x): 0.486, D(G(z)): 0.498\n",
      "2019-04-09 21:37:57,403 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.196957\n",
      "Reconstruction: 0.153691, Regularization: 0.010444, Discriminator: 0.021911; Generator: 0.010910,\n",
      "D(x): 0.490, D(G(z)): 0.497\n",
      "2019-04-09 21:37:57,490 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.212068\n",
      "Reconstruction: 0.165485, Regularization: 0.013570, Discriminator: 0.022036; Generator: 0.010978,\n",
      "D(x): 0.484, D(G(z)): 0.495\n",
      "2019-04-09 21:37:57,577 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.221732\n",
      "Reconstruction: 0.175868, Regularization: 0.013045, Discriminator: 0.021904; Generator: 0.010915,\n",
      "D(x): 0.490, D(G(z)): 0.497\n",
      "2019-04-09 21:37:57,664 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.209128\n",
      "Reconstruction: 0.165926, Regularization: 0.010361, Discriminator: 0.021912; Generator: 0.010929,\n",
      "D(x): 0.489, D(G(z)): 0.497\n",
      "2019-04-09 21:37:57,751 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.211671\n",
      "Reconstruction: 0.167761, Regularization: 0.011140, Discriminator: 0.021880; Generator: 0.010891,\n",
      "D(x): 0.492, D(G(z)): 0.498\n",
      "2019-04-09 21:37:57,835 root         INFO     ====> Epoch: 46 Average loss: 0.2076\n",
      "2019-04-09 21:37:57,860 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.205886\n",
      "Reconstruction: 0.161468, Regularization: 0.011484, Discriminator: 0.022035; Generator: 0.010899,\n",
      "D(x): 0.487, D(G(z)): 0.498\n",
      "2019-04-09 21:37:57,948 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.247430\n",
      "Reconstruction: 0.199836, Regularization: 0.014839, Discriminator: 0.021834; Generator: 0.010921,\n",
      "D(x): 0.492, D(G(z)): 0.497\n",
      "2019-04-09 21:37:58,035 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.248334\n",
      "Reconstruction: 0.200119, Regularization: 0.015326, Discriminator: 0.021954; Generator: 0.010935,\n",
      "D(x): 0.488, D(G(z)): 0.497\n",
      "2019-04-09 21:37:58,122 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.176103\n",
      "Reconstruction: 0.133989, Regularization: 0.009259, Discriminator: 0.021987; Generator: 0.010868,\n",
      "D(x): 0.489, D(G(z)): 0.499\n",
      "2019-04-09 21:37:58,210 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.184410\n",
      "Reconstruction: 0.142785, Regularization: 0.008910, Discriminator: 0.021826; Generator: 0.010889,\n",
      "D(x): 0.493, D(G(z)): 0.498\n",
      "2019-04-09 21:37:58,297 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.211687\n",
      "Reconstruction: 0.167048, Regularization: 0.011912, Discriminator: 0.021827; Generator: 0.010900,\n",
      "D(x): 0.493, D(G(z)): 0.498\n",
      "2019-04-09 21:37:58,385 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.225853\n",
      "Reconstruction: 0.179823, Regularization: 0.013143, Discriminator: 0.022013; Generator: 0.010874,\n",
      "D(x): 0.488, D(G(z)): 0.499\n",
      "2019-04-09 21:37:58,472 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.213603\n",
      "Reconstruction: 0.169848, Regularization: 0.011010, Discriminator: 0.021862; Generator: 0.010883,\n",
      "D(x): 0.492, D(G(z)): 0.498\n",
      "2019-04-09 21:37:58,555 root         INFO     ====> Epoch: 47 Average loss: 0.2076\n",
      "2019-04-09 21:37:58,580 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.233087\n",
      "Reconstruction: 0.187560, Regularization: 0.012767, Discriminator: 0.021856; Generator: 0.010904,\n",
      "D(x): 0.492, D(G(z)): 0.498\n",
      "2019-04-09 21:37:58,670 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.203641\n",
      "Reconstruction: 0.159948, Regularization: 0.010993, Discriminator: 0.021807; Generator: 0.010893,\n",
      "D(x): 0.494, D(G(z)): 0.498\n",
      "2019-04-09 21:37:58,757 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.220299\n",
      "Reconstruction: 0.175539, Regularization: 0.011969, Discriminator: 0.021914; Generator: 0.010877,\n",
      "D(x): 0.491, D(G(z)): 0.499\n",
      "2019-04-09 21:37:58,844 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.251890\n",
      "Reconstruction: 0.204152, Regularization: 0.014959, Discriminator: 0.021896; Generator: 0.010883,\n",
      "D(x): 0.491, D(G(z)): 0.498\n",
      "2019-04-09 21:37:58,931 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.181643\n",
      "Reconstruction: 0.139838, Regularization: 0.009111, Discriminator: 0.021818; Generator: 0.010877,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 21:37:59,018 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.168834\n",
      "Reconstruction: 0.128665, Regularization: 0.007500, Discriminator: 0.021801; Generator: 0.010867,\n",
      "D(x): 0.495, D(G(z)): 0.499\n",
      "2019-04-09 21:37:59,105 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.197939\n",
      "Reconstruction: 0.154436, Regularization: 0.010658, Discriminator: 0.021988; Generator: 0.010856,\n",
      "D(x): 0.489, D(G(z)): 0.499\n",
      "2019-04-09 21:37:59,192 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.228798\n",
      "Reconstruction: 0.183222, Regularization: 0.012854, Discriminator: 0.021862; Generator: 0.010860,\n",
      "D(x): 0.493, D(G(z)): 0.499\n",
      "2019-04-09 21:37:59,275 root         INFO     ====> Epoch: 48 Average loss: 0.2077\n",
      "2019-04-09 21:37:59,300 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.186930\n",
      "Reconstruction: 0.144642, Regularization: 0.009625, Discriminator: 0.021793; Generator: 0.010870,\n",
      "D(x): 0.495, D(G(z)): 0.499\n",
      "2019-04-09 21:37:59,386 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.201392\n",
      "Reconstruction: 0.158964, Regularization: 0.009729, Discriminator: 0.021848; Generator: 0.010852,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 21:37:59,474 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.153091\n",
      "Reconstruction: 0.113691, Regularization: 0.006725, Discriminator: 0.021815; Generator: 0.010859,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 21:37:59,561 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.248742\n",
      "Reconstruction: 0.201468, Regularization: 0.014582, Discriminator: 0.021856; Generator: 0.010836,\n",
      "D(x): 0.494, D(G(z)): 0.500\n",
      "2019-04-09 21:37:59,652 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.232202\n",
      "Reconstruction: 0.188751, Regularization: 0.010912, Discriminator: 0.021658; Generator: 0.010881,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 21:37:59,742 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.181838\n",
      "Reconstruction: 0.140495, Regularization: 0.008682, Discriminator: 0.021795; Generator: 0.010866,\n",
      "D(x): 0.495, D(G(z)): 0.499\n",
      "2019-04-09 21:37:59,832 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.186536\n",
      "Reconstruction: 0.144661, Regularization: 0.009166, Discriminator: 0.021884; Generator: 0.010826,\n",
      "D(x): 0.493, D(G(z)): 0.500\n",
      "2019-04-09 21:37:59,922 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.185883\n",
      "Reconstruction: 0.143808, Regularization: 0.009413, Discriminator: 0.021800; Generator: 0.010862,\n",
      "D(x): 0.495, D(G(z)): 0.499\n",
      "2019-04-09 21:38:00,007 root         INFO     ====> Epoch: 49 Average loss: 0.2079\n",
      "2019-04-09 21:38:00,032 root         INFO     Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 0.200426\n",
      "Reconstruction: 0.156721, Regularization: 0.011019, Discriminator: 0.021838; Generator: 0.010848,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 21:38:00,123 root         INFO     Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 0.171157\n",
      "Reconstruction: 0.130379, Regularization: 0.008149, Discriminator: 0.021757; Generator: 0.010873,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 21:38:00,210 root         INFO     Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 0.185026\n",
      "Reconstruction: 0.144085, Regularization: 0.008337, Discriminator: 0.021732; Generator: 0.010872,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 21:38:00,297 root         INFO     Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 0.168689\n",
      "Reconstruction: 0.128834, Regularization: 0.007295, Discriminator: 0.021709; Generator: 0.010851,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 21:38:00,384 root         INFO     Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 0.203682\n",
      "Reconstruction: 0.160558, Regularization: 0.010475, Discriminator: 0.021763; Generator: 0.010886,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 21:38:00,470 root         INFO     Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 0.198658\n",
      "Reconstruction: 0.155866, Regularization: 0.010092, Discriminator: 0.021829; Generator: 0.010870,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 21:38:00,556 root         INFO     Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 0.160620\n",
      "Reconstruction: 0.121840, Regularization: 0.006220, Discriminator: 0.021698; Generator: 0.010862,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 21:38:00,641 root         INFO     Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 0.215811\n",
      "Reconstruction: 0.172655, Regularization: 0.010531, Discriminator: 0.021747; Generator: 0.010879,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 21:38:00,724 root         INFO     ====> Epoch: 50 Average loss: 0.2076\n",
      "2019-04-09 21:38:00,749 root         INFO     Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 0.205297\n",
      "Reconstruction: 0.162096, Regularization: 0.010561, Discriminator: 0.021775; Generator: 0.010865,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 21:38:00,836 root         INFO     Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 0.177070\n",
      "Reconstruction: 0.135742, Regularization: 0.008645, Discriminator: 0.021800; Generator: 0.010884,\n",
      "D(x): 0.494, D(G(z)): 0.498\n",
      "2019-04-09 21:38:00,923 root         INFO     Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 0.208675\n",
      "Reconstruction: 0.164721, Regularization: 0.011299, Discriminator: 0.021793; Generator: 0.010862,\n",
      "D(x): 0.495, D(G(z)): 0.499\n",
      "2019-04-09 21:38:01,010 root         INFO     Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 0.204219\n",
      "Reconstruction: 0.160850, Regularization: 0.010703, Discriminator: 0.021785; Generator: 0.010882,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 21:38:01,098 root         INFO     Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 0.194242\n",
      "Reconstruction: 0.152869, Regularization: 0.008803, Discriminator: 0.021689; Generator: 0.010882,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 21:38:01,185 root         INFO     Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 0.224840\n",
      "Reconstruction: 0.180753, Regularization: 0.011473, Discriminator: 0.021733; Generator: 0.010881,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 21:38:01,272 root         INFO     Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 0.182872\n",
      "Reconstruction: 0.141628, Regularization: 0.008611, Discriminator: 0.021750; Generator: 0.010883,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 21:38:01,359 root         INFO     Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 0.159825\n",
      "Reconstruction: 0.119543, Regularization: 0.007652, Discriminator: 0.021756; Generator: 0.010874,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 21:38:01,443 root         INFO     ====> Epoch: 51 Average loss: 0.2074\n",
      "2019-04-09 21:38:01,468 root         INFO     Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 0.179574\n",
      "Reconstruction: 0.138506, Regularization: 0.008433, Discriminator: 0.021759; Generator: 0.010875,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 21:38:01,553 root         INFO     Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 0.168582\n",
      "Reconstruction: 0.128254, Regularization: 0.007731, Discriminator: 0.021730; Generator: 0.010867,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 21:38:01,638 root         INFO     Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 0.198868\n",
      "Reconstruction: 0.156801, Regularization: 0.009493, Discriminator: 0.021695; Generator: 0.010879,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 21:38:01,731 root         INFO     Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 0.166127\n",
      "Reconstruction: 0.126479, Regularization: 0.007093, Discriminator: 0.021659; Generator: 0.010897,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 21:38:01,824 root         INFO     Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 0.194472\n",
      "Reconstruction: 0.152729, Regularization: 0.009125, Discriminator: 0.021720; Generator: 0.010898,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 21:38:01,917 root         INFO     Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 0.194642\n",
      "Reconstruction: 0.153603, Regularization: 0.008501, Discriminator: 0.021635; Generator: 0.010903,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 21:38:02,009 root         INFO     Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 0.175000\n",
      "Reconstruction: 0.134354, Regularization: 0.008030, Discriminator: 0.021703; Generator: 0.010912,\n",
      "D(x): 0.496, D(G(z)): 0.497\n",
      "2019-04-09 21:38:02,096 root         INFO     Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 0.215512\n",
      "Reconstruction: 0.173361, Regularization: 0.009629, Discriminator: 0.021593; Generator: 0.010929,\n",
      "D(x): 0.499, D(G(z)): 0.497\n",
      "2019-04-09 21:38:02,180 root         INFO     ====> Epoch: 52 Average loss: 0.2069\n",
      "2019-04-09 21:38:02,205 root         INFO     Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 0.186835\n",
      "Reconstruction: 0.146542, Regularization: 0.007799, Discriminator: 0.021576; Generator: 0.010917,\n",
      "D(x): 0.500, D(G(z)): 0.497\n",
      "2019-04-09 21:38:02,293 root         INFO     Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 0.190891\n",
      "Reconstruction: 0.149931, Regularization: 0.008417, Discriminator: 0.021623; Generator: 0.010920,\n",
      "D(x): 0.499, D(G(z)): 0.497\n",
      "2019-04-09 21:38:02,381 root         INFO     Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 0.222262\n",
      "Reconstruction: 0.178648, Regularization: 0.011010, Discriminator: 0.021688; Generator: 0.010915,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-09 21:38:02,469 root         INFO     Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 0.223269\n",
      "Reconstruction: 0.180175, Regularization: 0.010518, Discriminator: 0.021646; Generator: 0.010929,\n",
      "D(x): 0.498, D(G(z)): 0.497\n",
      "2019-04-09 21:38:02,557 root         INFO     Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 0.200561\n",
      "Reconstruction: 0.159292, Regularization: 0.008739, Discriminator: 0.021587; Generator: 0.010943,\n",
      "D(x): 0.499, D(G(z)): 0.496\n",
      "2019-04-09 21:38:02,644 root         INFO     Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 0.194966\n",
      "Reconstruction: 0.152514, Regularization: 0.009801, Discriminator: 0.021693; Generator: 0.010957,\n",
      "D(x): 0.495, D(G(z)): 0.496\n",
      "2019-04-09 21:38:02,731 root         INFO     Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 0.199085\n",
      "Reconstruction: 0.156983, Regularization: 0.009451, Discriminator: 0.021674; Generator: 0.010977,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-04-09 21:38:02,817 root         INFO     Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 0.212522\n",
      "Reconstruction: 0.170628, Regularization: 0.009383, Discriminator: 0.021524; Generator: 0.010987,\n",
      "D(x): 0.500, D(G(z)): 0.495\n",
      "2019-04-09 21:38:02,901 root         INFO     ====> Epoch: 53 Average loss: 0.2065\n",
      "2019-04-09 21:38:02,926 root         INFO     Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 0.241356\n",
      "Reconstruction: 0.197487, Regularization: 0.011302, Discriminator: 0.021574; Generator: 0.010993,\n",
      "D(x): 0.498, D(G(z)): 0.495\n",
      "2019-04-09 21:38:03,012 root         INFO     Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 0.208329\n",
      "Reconstruction: 0.166354, Regularization: 0.009366, Discriminator: 0.021602; Generator: 0.011007,\n",
      "D(x): 0.497, D(G(z)): 0.494\n",
      "2019-04-09 21:38:03,097 root         INFO     Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 0.184460\n",
      "Reconstruction: 0.143788, Regularization: 0.008037, Discriminator: 0.021618; Generator: 0.011016,\n",
      "D(x): 0.496, D(G(z)): 0.494\n",
      "2019-04-09 21:38:03,182 root         INFO     Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 0.214929\n",
      "Reconstruction: 0.173000, Regularization: 0.009367, Discriminator: 0.021535; Generator: 0.011027,\n",
      "D(x): 0.498, D(G(z)): 0.494\n",
      "2019-04-09 21:38:03,267 root         INFO     Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 0.200513\n",
      "Reconstruction: 0.159814, Regularization: 0.008203, Discriminator: 0.021463; Generator: 0.011033,\n",
      "D(x): 0.500, D(G(z)): 0.494\n",
      "2019-04-09 21:38:03,352 root         INFO     Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 0.185806\n",
      "Reconstruction: 0.145015, Regularization: 0.008159, Discriminator: 0.021586; Generator: 0.011046,\n",
      "D(x): 0.496, D(G(z)): 0.493\n",
      "2019-04-09 21:38:03,437 root         INFO     Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 0.193544\n",
      "Reconstruction: 0.153354, Regularization: 0.007705, Discriminator: 0.021424; Generator: 0.011060,\n",
      "D(x): 0.501, D(G(z)): 0.493\n",
      "2019-04-09 21:38:03,522 root         INFO     Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 0.243955\n",
      "Reconstruction: 0.200544, Regularization: 0.010871, Discriminator: 0.021466; Generator: 0.011075,\n",
      "D(x): 0.499, D(G(z)): 0.492\n",
      "2019-04-09 21:38:03,604 root         INFO     ====> Epoch: 54 Average loss: 0.2060\n",
      "2019-04-09 21:38:03,630 root         INFO     Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 0.176585\n",
      "Reconstruction: 0.136144, Regularization: 0.007777, Discriminator: 0.021578; Generator: 0.011086,\n",
      "D(x): 0.495, D(G(z)): 0.492\n",
      "2019-04-09 21:38:03,718 root         INFO     Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 0.195262\n",
      "Reconstruction: 0.154519, Regularization: 0.008136, Discriminator: 0.021505; Generator: 0.011102,\n",
      "D(x): 0.497, D(G(z)): 0.491\n",
      "2019-04-09 21:38:03,802 root         INFO     Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 0.192136\n",
      "Reconstruction: 0.151630, Regularization: 0.007965, Discriminator: 0.021433; Generator: 0.011109,\n",
      "D(x): 0.499, D(G(z)): 0.491\n",
      "2019-04-09 21:38:03,887 root         INFO     Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 0.224713\n",
      "Reconstruction: 0.182498, Regularization: 0.009635, Discriminator: 0.021434; Generator: 0.011146,\n",
      "D(x): 0.498, D(G(z)): 0.490\n",
      "2019-04-09 21:38:03,971 root         INFO     Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 0.182357\n",
      "Reconstruction: 0.142558, Regularization: 0.007180, Discriminator: 0.021477; Generator: 0.011142,\n",
      "D(x): 0.497, D(G(z)): 0.490\n",
      "2019-04-09 21:38:04,057 root         INFO     Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 0.188147\n",
      "Reconstruction: 0.146652, Regularization: 0.008746, Discriminator: 0.021582; Generator: 0.011167,\n",
      "D(x): 0.492, D(G(z)): 0.489\n",
      "2019-04-09 21:38:04,142 root         INFO     Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 0.192480\n",
      "Reconstruction: 0.152266, Regularization: 0.007604, Discriminator: 0.021448; Generator: 0.011162,\n",
      "D(x): 0.497, D(G(z)): 0.489\n",
      "2019-04-09 21:38:04,227 root         INFO     Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 0.212186\n",
      "Reconstruction: 0.171158, Regularization: 0.008501, Discriminator: 0.021351; Generator: 0.011176,\n",
      "D(x): 0.500, D(G(z)): 0.489\n",
      "2019-04-09 21:38:04,308 root         INFO     ====> Epoch: 55 Average loss: 0.2051\n",
      "2019-04-09 21:38:04,335 root         INFO     Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 0.275232\n",
      "Reconstruction: 0.230363, Regularization: 0.012300, Discriminator: 0.021386; Generator: 0.011184,\n",
      "D(x): 0.499, D(G(z)): 0.489\n",
      "2019-04-09 21:38:04,423 root         INFO     Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 0.226024\n",
      "Reconstruction: 0.184859, Regularization: 0.008668, Discriminator: 0.021335; Generator: 0.011162,\n",
      "D(x): 0.500, D(G(z)): 0.489\n",
      "2019-04-09 21:38:04,513 root         INFO     Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 0.236729\n",
      "Reconstruction: 0.194389, Regularization: 0.009823, Discriminator: 0.021286; Generator: 0.011231,\n",
      "D(x): 0.500, D(G(z)): 0.487\n",
      "2019-04-09 21:38:04,602 root         INFO     Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 0.185364\n",
      "Reconstruction: 0.145520, Regularization: 0.007161, Discriminator: 0.021494; Generator: 0.011188,\n",
      "D(x): 0.495, D(G(z)): 0.489\n",
      "2019-04-09 21:38:04,691 root         INFO     Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 0.190813\n",
      "Reconstruction: 0.149669, Regularization: 0.008375, Discriminator: 0.021544; Generator: 0.011225,\n",
      "D(x): 0.492, D(G(z)): 0.488\n",
      "2019-04-09 21:38:04,780 root         INFO     Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 0.197322\n",
      "Reconstruction: 0.155951, Regularization: 0.008650, Discriminator: 0.021462; Generator: 0.011259,\n",
      "D(x): 0.494, D(G(z)): 0.486\n",
      "2019-04-09 21:38:04,870 root         INFO     Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 0.191689\n",
      "Reconstruction: 0.151239, Regularization: 0.007758, Discriminator: 0.021432; Generator: 0.011259,\n",
      "D(x): 0.494, D(G(z)): 0.486\n",
      "2019-04-09 21:38:04,960 root         INFO     Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 0.197488\n",
      "Reconstruction: 0.157504, Regularization: 0.007295, Discriminator: 0.021400; Generator: 0.011289,\n",
      "D(x): 0.495, D(G(z)): 0.486\n",
      "2019-04-09 21:38:05,045 root         INFO     ====> Epoch: 56 Average loss: 0.2042\n",
      "2019-04-09 21:38:05,071 root         INFO     Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 0.233320\n",
      "Reconstruction: 0.191086, Regularization: 0.009694, Discriminator: 0.021265; Generator: 0.011275,\n",
      "D(x): 0.499, D(G(z)): 0.486\n",
      "2019-04-09 21:38:05,162 root         INFO     Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 0.183529\n",
      "Reconstruction: 0.144351, Regularization: 0.006625, Discriminator: 0.021252; Generator: 0.011301,\n",
      "D(x): 0.499, D(G(z)): 0.485\n",
      "2019-04-09 21:38:05,253 root         INFO     Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 0.176555\n",
      "Reconstruction: 0.137518, Regularization: 0.006340, Discriminator: 0.021413; Generator: 0.011285,\n",
      "D(x): 0.495, D(G(z)): 0.486\n",
      "2019-04-09 21:38:05,344 root         INFO     Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 0.224739\n",
      "Reconstruction: 0.182526, Regularization: 0.009374, Discriminator: 0.021519; Generator: 0.011321,\n",
      "D(x): 0.491, D(G(z)): 0.485\n",
      "2019-04-09 21:38:05,434 root         INFO     Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 0.206639\n",
      "Reconstruction: 0.166623, Regularization: 0.007384, Discriminator: 0.021355; Generator: 0.011277,\n",
      "D(x): 0.497, D(G(z)): 0.486\n",
      "2019-04-09 21:38:05,524 root         INFO     Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 0.181472\n",
      "Reconstruction: 0.142405, Regularization: 0.006497, Discriminator: 0.021244; Generator: 0.011327,\n",
      "D(x): 0.499, D(G(z)): 0.484\n",
      "2019-04-09 21:38:05,613 root         INFO     Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 0.163164\n",
      "Reconstruction: 0.125011, Regularization: 0.005468, Discriminator: 0.021320; Generator: 0.011366,\n",
      "D(x): 0.495, D(G(z)): 0.483\n",
      "2019-04-09 21:38:05,699 root         INFO     Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 0.244753\n",
      "Reconstruction: 0.202043, Regularization: 0.010036, Discriminator: 0.021371; Generator: 0.011303,\n",
      "D(x): 0.496, D(G(z)): 0.485\n",
      "2019-04-09 21:38:05,782 root         INFO     ====> Epoch: 57 Average loss: 0.2029\n",
      "2019-04-09 21:38:05,807 root         INFO     Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 0.217607\n",
      "Reconstruction: 0.176977, Regularization: 0.007999, Discriminator: 0.021348; Generator: 0.011283,\n",
      "D(x): 0.497, D(G(z)): 0.486\n",
      "2019-04-09 21:38:05,898 root         INFO     Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 0.181896\n",
      "Reconstruction: 0.142184, Regularization: 0.007088, Discriminator: 0.021338; Generator: 0.011285,\n",
      "D(x): 0.497, D(G(z)): 0.486\n",
      "2019-04-09 21:38:05,989 root         INFO     Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 0.184423\n",
      "Reconstruction: 0.145659, Regularization: 0.006136, Discriminator: 0.021297; Generator: 0.011332,\n",
      "D(x): 0.497, D(G(z)): 0.484\n",
      "2019-04-09 21:38:06,077 root         INFO     Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 0.177696\n",
      "Reconstruction: 0.138265, Regularization: 0.006828, Discriminator: 0.021303; Generator: 0.011300,\n",
      "D(x): 0.498, D(G(z)): 0.485\n",
      "2019-04-09 21:38:06,166 root         INFO     Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 0.230636\n",
      "Reconstruction: 0.189993, Regularization: 0.008220, Discriminator: 0.021086; Generator: 0.011336,\n",
      "D(x): 0.503, D(G(z)): 0.484\n",
      "2019-04-09 21:38:06,253 root         INFO     Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 0.174480\n",
      "Reconstruction: 0.135671, Regularization: 0.006168, Discriminator: 0.021354; Generator: 0.011287,\n",
      "D(x): 0.496, D(G(z)): 0.486\n",
      "2019-04-09 21:38:06,342 root         INFO     Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 0.176198\n",
      "Reconstruction: 0.138106, Regularization: 0.005513, Discriminator: 0.021320; Generator: 0.011259,\n",
      "D(x): 0.499, D(G(z)): 0.487\n",
      "2019-04-09 21:38:06,430 root         INFO     Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 0.185997\n",
      "Reconstruction: 0.146126, Regularization: 0.007147, Discriminator: 0.021510; Generator: 0.011215,\n",
      "D(x): 0.494, D(G(z)): 0.488\n",
      "2019-04-09 21:38:06,514 root         INFO     ====> Epoch: 58 Average loss: 0.2013\n",
      "2019-04-09 21:38:06,539 root         INFO     Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 0.221850\n",
      "Reconstruction: 0.180640, Regularization: 0.008479, Discriminator: 0.021448; Generator: 0.011284,\n",
      "D(x): 0.494, D(G(z)): 0.486\n",
      "2019-04-09 21:38:06,629 root         INFO     Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 0.201725\n",
      "Reconstruction: 0.161345, Regularization: 0.007776, Discriminator: 0.021412; Generator: 0.011192,\n",
      "D(x): 0.498, D(G(z)): 0.489\n",
      "2019-04-09 21:38:06,719 root         INFO     Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 0.215057\n",
      "Reconstruction: 0.173803, Regularization: 0.008728, Discriminator: 0.021300; Generator: 0.011226,\n",
      "D(x): 0.501, D(G(z)): 0.488\n",
      "2019-04-09 21:38:06,807 root         INFO     Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 0.252981\n",
      "Reconstruction: 0.210674, Regularization: 0.009759, Discriminator: 0.021332; Generator: 0.011216,\n",
      "D(x): 0.500, D(G(z)): 0.488\n",
      "2019-04-09 21:38:06,897 root         INFO     Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 0.226259\n",
      "Reconstruction: 0.185651, Regularization: 0.007946, Discriminator: 0.021467; Generator: 0.011195,\n",
      "D(x): 0.496, D(G(z)): 0.489\n",
      "2019-04-09 21:38:06,986 root         INFO     Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 0.197481\n",
      "Reconstruction: 0.157693, Regularization: 0.007238, Discriminator: 0.021329; Generator: 0.011221,\n",
      "D(x): 0.500, D(G(z)): 0.488\n",
      "2019-04-09 21:38:07,075 root         INFO     Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 0.215659\n",
      "Reconstruction: 0.175083, Regularization: 0.008305, Discriminator: 0.021098; Generator: 0.011172,\n",
      "D(x): 0.509, D(G(z)): 0.489\n",
      "2019-04-09 21:38:07,165 root         INFO     Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 0.201374\n",
      "Reconstruction: 0.161776, Regularization: 0.007254, Discriminator: 0.021081; Generator: 0.011264,\n",
      "D(x): 0.506, D(G(z)): 0.486\n",
      "2019-04-09 21:38:07,250 root         INFO     ====> Epoch: 59 Average loss: 0.1997\n",
      "2019-04-09 21:38:07,275 root         INFO     Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 0.226391\n",
      "Reconstruction: 0.185981, Regularization: 0.008081, Discriminator: 0.021121; Generator: 0.011209,\n",
      "D(x): 0.507, D(G(z)): 0.488\n",
      "2019-04-09 21:38:07,364 root         INFO     Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 0.182279\n",
      "Reconstruction: 0.143271, Regularization: 0.006590, Discriminator: 0.021372; Generator: 0.011046,\n",
      "D(x): 0.504, D(G(z)): 0.493\n",
      "2019-04-09 21:38:07,452 root         INFO     Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 0.214416\n",
      "Reconstruction: 0.173837, Regularization: 0.008076, Discriminator: 0.021420; Generator: 0.011083,\n",
      "D(x): 0.502, D(G(z)): 0.492\n",
      "2019-04-09 21:38:07,541 root         INFO     Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 0.180424\n",
      "Reconstruction: 0.140932, Regularization: 0.006772, Discriminator: 0.021479; Generator: 0.011240,\n",
      "D(x): 0.495, D(G(z)): 0.487\n",
      "2019-04-09 21:38:07,631 root         INFO     Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 0.166563\n",
      "Reconstruction: 0.128026, Regularization: 0.005640, Discriminator: 0.021644; Generator: 0.011253,\n",
      "D(x): 0.489, D(G(z)): 0.487\n",
      "2019-04-09 21:38:07,720 root         INFO     Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 0.186060\n",
      "Reconstruction: 0.147069, Regularization: 0.006393, Discriminator: 0.021467; Generator: 0.011132,\n",
      "D(x): 0.498, D(G(z)): 0.491\n",
      "2019-04-09 21:38:07,809 root         INFO     Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 0.194154\n",
      "Reconstruction: 0.155272, Regularization: 0.006591, Discriminator: 0.021224; Generator: 0.011067,\n",
      "D(x): 0.508, D(G(z)): 0.493\n",
      "2019-04-09 21:38:07,898 root         INFO     Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 0.229824\n",
      "Reconstruction: 0.188834, Regularization: 0.008713, Discriminator: 0.021219; Generator: 0.011058,\n",
      "D(x): 0.510, D(G(z)): 0.493\n",
      "2019-04-09 21:38:07,982 root         INFO     ====> Epoch: 60 Average loss: 0.1982\n",
      "2019-04-09 21:38:08,008 root         INFO     Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 0.219323\n",
      "Reconstruction: 0.177973, Regularization: 0.008801, Discriminator: 0.021575; Generator: 0.010973,\n",
      "D(x): 0.501, D(G(z)): 0.496\n",
      "2019-04-09 21:38:08,099 root         INFO     Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 0.182108\n",
      "Reconstruction: 0.143187, Regularization: 0.006396, Discriminator: 0.021406; Generator: 0.011120,\n",
      "D(x): 0.501, D(G(z)): 0.491\n",
      "2019-04-09 21:38:08,189 root         INFO     Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 0.176318\n",
      "Reconstruction: 0.137749, Regularization: 0.005957, Discriminator: 0.021621; Generator: 0.010991,\n",
      "D(x): 0.498, D(G(z)): 0.495\n",
      "2019-04-09 21:38:08,279 root         INFO     Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 0.201444\n",
      "Reconstruction: 0.161762, Regularization: 0.007094, Discriminator: 0.021544; Generator: 0.011045,\n",
      "D(x): 0.498, D(G(z)): 0.493\n",
      "2019-04-09 21:38:08,370 root         INFO     Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 0.156915\n",
      "Reconstruction: 0.119238, Regularization: 0.005303, Discriminator: 0.021350; Generator: 0.011024,\n",
      "D(x): 0.506, D(G(z)): 0.494\n",
      "2019-04-09 21:38:08,460 root         INFO     Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 0.169869\n",
      "Reconstruction: 0.132374, Regularization: 0.005089, Discriminator: 0.021429; Generator: 0.010978,\n",
      "D(x): 0.504, D(G(z)): 0.495\n",
      "2019-04-09 21:38:08,548 root         INFO     Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 0.191793\n",
      "Reconstruction: 0.153023, Regularization: 0.006202, Discriminator: 0.021621; Generator: 0.010947,\n",
      "D(x): 0.499, D(G(z)): 0.496\n",
      "2019-04-09 21:38:08,635 root         INFO     Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 0.176444\n",
      "Reconstruction: 0.138614, Regularization: 0.005403, Discriminator: 0.021541; Generator: 0.010887,\n",
      "D(x): 0.504, D(G(z)): 0.498\n",
      "2019-04-09 21:38:08,718 root         INFO     ====> Epoch: 61 Average loss: 0.1966\n",
      "2019-04-09 21:38:08,744 root         INFO     Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 0.161990\n",
      "Reconstruction: 0.124622, Regularization: 0.004845, Discriminator: 0.021649; Generator: 0.010874,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 21:38:08,832 root         INFO     Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 0.197615\n",
      "Reconstruction: 0.158250, Regularization: 0.007071, Discriminator: 0.021396; Generator: 0.010900,\n",
      "D(x): 0.509, D(G(z)): 0.498\n",
      "2019-04-09 21:38:08,919 root         INFO     Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 0.188503\n",
      "Reconstruction: 0.149203, Regularization: 0.007020, Discriminator: 0.021534; Generator: 0.010746,\n",
      "D(x): 0.509, D(G(z)): 0.503\n",
      "2019-04-09 21:38:09,006 root         INFO     Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 0.224831\n",
      "Reconstruction: 0.184225, Regularization: 0.008136, Discriminator: 0.021593; Generator: 0.010877,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 21:38:09,098 root         INFO     Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 0.180776\n",
      "Reconstruction: 0.141759, Regularization: 0.006396, Discriminator: 0.021731; Generator: 0.010890,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 21:38:09,191 root         INFO     Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 0.198448\n",
      "Reconstruction: 0.159367, Regularization: 0.006406, Discriminator: 0.021765; Generator: 0.010911,\n",
      "D(x): 0.496, D(G(z)): 0.497\n",
      "2019-04-09 21:38:09,283 root         INFO     Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 0.251646\n",
      "Reconstruction: 0.210079, Regularization: 0.009240, Discriminator: 0.021487; Generator: 0.010840,\n",
      "D(x): 0.508, D(G(z)): 0.500\n",
      "2019-04-09 21:38:09,376 root         INFO     Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 0.228824\n",
      "Reconstruction: 0.188071, Regularization: 0.008038, Discriminator: 0.021887; Generator: 0.010827,\n",
      "D(x): 0.495, D(G(z)): 0.500\n",
      "2019-04-09 21:38:09,464 root         INFO     ====> Epoch: 62 Average loss: 0.1952\n",
      "2019-04-09 21:38:09,489 root         INFO     Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 0.220744\n",
      "Reconstruction: 0.180710, Regularization: 0.007652, Discriminator: 0.021624; Generator: 0.010758,\n",
      "D(x): 0.505, D(G(z)): 0.502\n",
      "2019-04-09 21:38:09,580 root         INFO     Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 0.224195\n",
      "Reconstruction: 0.182936, Regularization: 0.008977, Discriminator: 0.021500; Generator: 0.010782,\n",
      "D(x): 0.509, D(G(z)): 0.502\n",
      "2019-04-09 21:38:09,667 root         INFO     Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 0.207113\n",
      "Reconstruction: 0.167084, Regularization: 0.007283, Discriminator: 0.021973; Generator: 0.010774,\n",
      "D(x): 0.494, D(G(z)): 0.502\n",
      "2019-04-09 21:38:09,753 root         INFO     Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 0.198919\n",
      "Reconstruction: 0.159183, Regularization: 0.007177, Discriminator: 0.021815; Generator: 0.010744,\n",
      "D(x): 0.500, D(G(z)): 0.503\n",
      "2019-04-09 21:38:09,840 root         INFO     Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 0.201580\n",
      "Reconstruction: 0.162334, Regularization: 0.006815, Discriminator: 0.021686; Generator: 0.010744,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-09 21:38:09,928 root         INFO     Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 0.220166\n",
      "Reconstruction: 0.179230, Regularization: 0.008460, Discriminator: 0.021688; Generator: 0.010787,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 21:38:10,015 root         INFO     Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 0.173482\n",
      "Reconstruction: 0.135640, Regularization: 0.005512, Discriminator: 0.021572; Generator: 0.010758,\n",
      "D(x): 0.507, D(G(z)): 0.502\n",
      "2019-04-09 21:38:10,101 root         INFO     Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 0.195365\n",
      "Reconstruction: 0.157050, Regularization: 0.006116, Discriminator: 0.021444; Generator: 0.010754,\n",
      "D(x): 0.511, D(G(z)): 0.503\n",
      "2019-04-09 21:38:10,186 root         INFO     ====> Epoch: 63 Average loss: 0.1940\n",
      "2019-04-09 21:38:10,211 root         INFO     Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 0.214028\n",
      "Reconstruction: 0.174313, Regularization: 0.007102, Discriminator: 0.021945; Generator: 0.010668,\n",
      "D(x): 0.498, D(G(z)): 0.505\n",
      "2019-04-09 21:38:10,302 root         INFO     Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 0.184683\n",
      "Reconstruction: 0.146412, Regularization: 0.005836, Discriminator: 0.021713; Generator: 0.010722,\n",
      "D(x): 0.503, D(G(z)): 0.504\n",
      "2019-04-09 21:38:10,393 root         INFO     Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 0.176325\n",
      "Reconstruction: 0.138560, Regularization: 0.005365, Discriminator: 0.021706; Generator: 0.010694,\n",
      "D(x): 0.505, D(G(z)): 0.504\n",
      "2019-04-09 21:38:10,484 root         INFO     Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 0.202241\n",
      "Reconstruction: 0.163195, Regularization: 0.006787, Discriminator: 0.021568; Generator: 0.010691,\n",
      "D(x): 0.510, D(G(z)): 0.505\n",
      "2019-04-09 21:38:10,575 root         INFO     Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 0.163281\n",
      "Reconstruction: 0.125962, Regularization: 0.004847, Discriminator: 0.021812; Generator: 0.010660,\n",
      "D(x): 0.502, D(G(z)): 0.506\n",
      "2019-04-09 21:38:10,665 root         INFO     Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 0.225792\n",
      "Reconstruction: 0.184958, Regularization: 0.008361, Discriminator: 0.021772; Generator: 0.010702,\n",
      "D(x): 0.502, D(G(z)): 0.504\n",
      "2019-04-09 21:38:10,756 root         INFO     Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 0.222842\n",
      "Reconstruction: 0.182178, Regularization: 0.008269, Discriminator: 0.021745; Generator: 0.010650,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-09 21:38:10,848 root         INFO     Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 0.175210\n",
      "Reconstruction: 0.137001, Regularization: 0.005620, Discriminator: 0.021875; Generator: 0.010714,\n",
      "D(x): 0.499, D(G(z)): 0.504\n",
      "2019-04-09 21:38:10,935 root         INFO     ====> Epoch: 64 Average loss: 0.1932\n",
      "2019-04-09 21:38:10,960 root         INFO     Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 0.194253\n",
      "Reconstruction: 0.155519, Regularization: 0.006049, Discriminator: 0.022068; Generator: 0.010616,\n",
      "D(x): 0.495, D(G(z)): 0.507\n",
      "2019-04-09 21:38:11,050 root         INFO     Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 0.218105\n",
      "Reconstruction: 0.178405, Regularization: 0.007399, Discriminator: 0.021689; Generator: 0.010612,\n",
      "D(x): 0.507, D(G(z)): 0.507\n",
      "2019-04-09 21:38:11,141 root         INFO     Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 0.203219\n",
      "Reconstruction: 0.163852, Regularization: 0.007052, Discriminator: 0.021689; Generator: 0.010626,\n",
      "D(x): 0.507, D(G(z)): 0.507\n",
      "2019-04-09 21:38:11,231 root         INFO     Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 0.168679\n",
      "Reconstruction: 0.131104, Regularization: 0.005239, Discriminator: 0.021697; Generator: 0.010639,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-09 21:38:11,323 root         INFO     Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 0.258480\n",
      "Reconstruction: 0.217067, Regularization: 0.009103, Discriminator: 0.021698; Generator: 0.010613,\n",
      "D(x): 0.507, D(G(z)): 0.507\n",
      "2019-04-09 21:38:11,414 root         INFO     Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 0.170478\n",
      "Reconstruction: 0.133026, Regularization: 0.004969, Discriminator: 0.021828; Generator: 0.010654,\n",
      "D(x): 0.501, D(G(z)): 0.506\n",
      "2019-04-09 21:38:11,506 root         INFO     Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 0.224823\n",
      "Reconstruction: 0.184904, Regularization: 0.007526, Discriminator: 0.021743; Generator: 0.010650,\n",
      "D(x): 0.504, D(G(z)): 0.506\n",
      "2019-04-09 21:38:11,597 root         INFO     Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 0.201492\n",
      "Reconstruction: 0.162174, Regularization: 0.006879, Discriminator: 0.021822; Generator: 0.010617,\n",
      "D(x): 0.503, D(G(z)): 0.507\n",
      "2019-04-09 21:38:11,684 root         INFO     ====> Epoch: 65 Average loss: 0.1923\n",
      "2019-04-09 21:38:11,710 root         INFO     Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 0.196817\n",
      "Reconstruction: 0.157927, Regularization: 0.006324, Discriminator: 0.021937; Generator: 0.010629,\n",
      "D(x): 0.499, D(G(z)): 0.507\n",
      "2019-04-09 21:38:11,799 root         INFO     Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 0.185977\n",
      "Reconstruction: 0.147652, Regularization: 0.005811, Discriminator: 0.021879; Generator: 0.010634,\n",
      "D(x): 0.500, D(G(z)): 0.506\n",
      "2019-04-09 21:38:11,888 root         INFO     Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 0.162477\n",
      "Reconstruction: 0.125068, Regularization: 0.004800, Discriminator: 0.021978; Generator: 0.010631,\n",
      "D(x): 0.497, D(G(z)): 0.506\n",
      "2019-04-09 21:38:11,976 root         INFO     Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 0.200289\n",
      "Reconstruction: 0.161525, Regularization: 0.006396, Discriminator: 0.021739; Generator: 0.010628,\n",
      "D(x): 0.505, D(G(z)): 0.507\n",
      "2019-04-09 21:38:12,065 root         INFO     Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 0.165188\n",
      "Reconstruction: 0.127964, Regularization: 0.004590, Discriminator: 0.022003; Generator: 0.010632,\n",
      "D(x): 0.496, D(G(z)): 0.506\n",
      "2019-04-09 21:38:12,154 root         INFO     Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 0.208550\n",
      "Reconstruction: 0.169546, Regularization: 0.006759, Discriminator: 0.021639; Generator: 0.010606,\n",
      "D(x): 0.509, D(G(z)): 0.507\n",
      "2019-04-09 21:38:12,245 root         INFO     Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 0.224697\n",
      "Reconstruction: 0.184114, Regularization: 0.008189, Discriminator: 0.021771; Generator: 0.010624,\n",
      "D(x): 0.504, D(G(z)): 0.507\n",
      "2019-04-09 21:38:12,335 root         INFO     Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 0.175481\n",
      "Reconstruction: 0.137611, Regularization: 0.005301, Discriminator: 0.021960; Generator: 0.010609,\n",
      "D(x): 0.498, D(G(z)): 0.507\n",
      "2019-04-09 21:38:12,421 root         INFO     ====> Epoch: 66 Average loss: 0.1917\n",
      "2019-04-09 21:38:12,446 root         INFO     Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 0.195443\n",
      "Reconstruction: 0.156711, Regularization: 0.006270, Discriminator: 0.021855; Generator: 0.010607,\n",
      "D(x): 0.502, D(G(z)): 0.507\n",
      "2019-04-09 21:38:12,534 root         INFO     Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 0.161686\n",
      "Reconstruction: 0.124318, Regularization: 0.004872, Discriminator: 0.021886; Generator: 0.010610,\n",
      "D(x): 0.501, D(G(z)): 0.507\n",
      "2019-04-09 21:38:12,620 root         INFO     Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 0.153451\n",
      "Reconstruction: 0.117083, Regularization: 0.004031, Discriminator: 0.021704; Generator: 0.010633,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-09 21:38:12,705 root         INFO     Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 0.175341\n",
      "Reconstruction: 0.137698, Regularization: 0.005141, Discriminator: 0.021854; Generator: 0.010648,\n",
      "D(x): 0.500, D(G(z)): 0.506\n",
      "2019-04-09 21:38:12,793 root         INFO     Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 0.267526\n",
      "Reconstruction: 0.225360, Regularization: 0.009494, Discriminator: 0.022042; Generator: 0.010630,\n",
      "D(x): 0.495, D(G(z)): 0.506\n",
      "2019-04-09 21:38:12,880 root         INFO     Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 0.204620\n",
      "Reconstruction: 0.165377, Regularization: 0.006895, Discriminator: 0.021699; Generator: 0.010648,\n",
      "D(x): 0.505, D(G(z)): 0.506\n",
      "2019-04-09 21:38:12,967 root         INFO     Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 0.176282\n",
      "Reconstruction: 0.138774, Regularization: 0.005093, Discriminator: 0.021792; Generator: 0.010624,\n",
      "D(x): 0.503, D(G(z)): 0.507\n",
      "2019-04-09 21:38:13,054 root         INFO     Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 0.223295\n",
      "Reconstruction: 0.183118, Regularization: 0.007852, Discriminator: 0.021699; Generator: 0.010626,\n",
      "D(x): 0.506, D(G(z)): 0.507\n",
      "2019-04-09 21:38:13,138 root         INFO     ====> Epoch: 67 Average loss: 0.1910\n",
      "2019-04-09 21:38:13,163 root         INFO     Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 0.198592\n",
      "Reconstruction: 0.160123, Regularization: 0.006132, Discriminator: 0.021690; Generator: 0.010646,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-09 21:38:13,251 root         INFO     Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 0.176565\n",
      "Reconstruction: 0.138938, Regularization: 0.005209, Discriminator: 0.021795; Generator: 0.010623,\n",
      "D(x): 0.503, D(G(z)): 0.507\n",
      "2019-04-09 21:38:13,339 root         INFO     Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 0.177238\n",
      "Reconstruction: 0.139382, Regularization: 0.005379, Discriminator: 0.021866; Generator: 0.010610,\n",
      "D(x): 0.501, D(G(z)): 0.507\n",
      "2019-04-09 21:38:13,427 root         INFO     Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 0.203805\n",
      "Reconstruction: 0.164851, Regularization: 0.006378, Discriminator: 0.021918; Generator: 0.010658,\n",
      "D(x): 0.498, D(G(z)): 0.506\n",
      "2019-04-09 21:38:13,515 root         INFO     Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 0.172440\n",
      "Reconstruction: 0.134710, Regularization: 0.005163, Discriminator: 0.021929; Generator: 0.010638,\n",
      "D(x): 0.498, D(G(z)): 0.506\n",
      "2019-04-09 21:38:13,604 root         INFO     Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 0.197578\n",
      "Reconstruction: 0.159166, Regularization: 0.005895, Discriminator: 0.021837; Generator: 0.010680,\n",
      "D(x): 0.500, D(G(z)): 0.505\n",
      "2019-04-09 21:38:13,693 root         INFO     Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 0.167717\n",
      "Reconstruction: 0.130371, Regularization: 0.004834, Discriminator: 0.021821; Generator: 0.010690,\n",
      "D(x): 0.500, D(G(z)): 0.505\n",
      "2019-04-09 21:38:13,781 root         INFO     Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 0.169386\n",
      "Reconstruction: 0.131938, Regularization: 0.004983, Discriminator: 0.021779; Generator: 0.010687,\n",
      "D(x): 0.501, D(G(z)): 0.505\n",
      "2019-04-09 21:38:13,867 root         INFO     ====> Epoch: 68 Average loss: 0.1906\n",
      "2019-04-09 21:38:13,893 root         INFO     Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 0.158365\n",
      "Reconstruction: 0.121703, Regularization: 0.004210, Discriminator: 0.021770; Generator: 0.010682,\n",
      "D(x): 0.502, D(G(z)): 0.505\n",
      "2019-04-09 21:38:13,983 root         INFO     Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 0.207558\n",
      "Reconstruction: 0.168791, Regularization: 0.006316, Discriminator: 0.021764; Generator: 0.010686,\n",
      "D(x): 0.502, D(G(z)): 0.505\n",
      "2019-04-09 21:38:14,071 root         INFO     Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 0.219607\n",
      "Reconstruction: 0.179957, Regularization: 0.007190, Discriminator: 0.021774; Generator: 0.010686,\n",
      "D(x): 0.501, D(G(z)): 0.505\n",
      "2019-04-09 21:38:14,160 root         INFO     Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 0.183978\n",
      "Reconstruction: 0.146204, Regularization: 0.005325, Discriminator: 0.021757; Generator: 0.010692,\n",
      "D(x): 0.502, D(G(z)): 0.504\n",
      "2019-04-09 21:38:14,250 root         INFO     Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 0.178340\n",
      "Reconstruction: 0.140845, Regularization: 0.005067, Discriminator: 0.021734; Generator: 0.010694,\n",
      "D(x): 0.502, D(G(z)): 0.504\n",
      "2019-04-09 21:38:14,339 root         INFO     Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 0.183928\n",
      "Reconstruction: 0.146116, Regularization: 0.005220, Discriminator: 0.021873; Generator: 0.010719,\n",
      "D(x): 0.497, D(G(z)): 0.504\n",
      "2019-04-09 21:38:14,428 root         INFO     Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 0.198080\n",
      "Reconstruction: 0.159546, Regularization: 0.006108, Discriminator: 0.021709; Generator: 0.010717,\n",
      "D(x): 0.502, D(G(z)): 0.504\n",
      "2019-04-09 21:38:14,518 root         INFO     Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 0.244595\n",
      "Reconstruction: 0.204545, Regularization: 0.007589, Discriminator: 0.021742; Generator: 0.010719,\n",
      "D(x): 0.501, D(G(z)): 0.504\n",
      "2019-04-09 21:38:14,604 root         INFO     ====> Epoch: 69 Average loss: 0.1901\n",
      "2019-04-09 21:38:14,629 root         INFO     Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 0.180842\n",
      "Reconstruction: 0.143284, Regularization: 0.005016, Discriminator: 0.021813; Generator: 0.010728,\n",
      "D(x): 0.499, D(G(z)): 0.503\n",
      "2019-04-09 21:38:14,720 root         INFO     Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 0.177273\n",
      "Reconstruction: 0.139918, Regularization: 0.004810, Discriminator: 0.021818; Generator: 0.010727,\n",
      "D(x): 0.499, D(G(z)): 0.503\n",
      "2019-04-09 21:38:14,810 root         INFO     Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 0.159470\n",
      "Reconstruction: 0.122936, Regularization: 0.004032, Discriminator: 0.021778; Generator: 0.010725,\n",
      "D(x): 0.500, D(G(z)): 0.503\n",
      "2019-04-09 21:38:14,901 root         INFO     Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 0.187868\n",
      "Reconstruction: 0.149802, Regularization: 0.005548, Discriminator: 0.021779; Generator: 0.010738,\n",
      "D(x): 0.499, D(G(z)): 0.503\n",
      "2019-04-09 21:38:14,991 root         INFO     Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 0.212719\n",
      "Reconstruction: 0.173950, Regularization: 0.006294, Discriminator: 0.021741; Generator: 0.010734,\n",
      "D(x): 0.501, D(G(z)): 0.503\n",
      "2019-04-09 21:38:15,081 root         INFO     Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 0.174073\n",
      "Reconstruction: 0.136846, Regularization: 0.004730, Discriminator: 0.021754; Generator: 0.010743,\n",
      "D(x): 0.500, D(G(z)): 0.503\n",
      "2019-04-09 21:38:15,171 root         INFO     Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 0.201348\n",
      "Reconstruction: 0.162927, Regularization: 0.006011, Discriminator: 0.021651; Generator: 0.010758,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-09 21:38:15,262 root         INFO     Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 0.182853\n",
      "Reconstruction: 0.145124, Regularization: 0.005226, Discriminator: 0.021740; Generator: 0.010764,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 21:38:15,348 root         INFO     ====> Epoch: 70 Average loss: 0.1898\n",
      "2019-04-09 21:38:15,373 root         INFO     Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 0.150441\n",
      "Reconstruction: 0.114268, Regularization: 0.003767, Discriminator: 0.021636; Generator: 0.010770,\n",
      "D(x): 0.503, D(G(z)): 0.502\n",
      "2019-04-09 21:38:15,462 root         INFO     Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 0.195901\n",
      "Reconstruction: 0.157755, Regularization: 0.005556, Discriminator: 0.021812; Generator: 0.010778,\n",
      "D(x): 0.497, D(G(z)): 0.502\n",
      "2019-04-09 21:38:15,550 root         INFO     Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 0.152010\n",
      "Reconstruction: 0.115780, Regularization: 0.003748, Discriminator: 0.021698; Generator: 0.010785,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:15,638 root         INFO     Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 0.160828\n",
      "Reconstruction: 0.123883, Regularization: 0.004437, Discriminator: 0.021730; Generator: 0.010779,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 21:38:15,726 root         INFO     Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 0.222365\n",
      "Reconstruction: 0.183248, Regularization: 0.006642, Discriminator: 0.021685; Generator: 0.010790,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 21:38:15,814 root         INFO     Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 0.167660\n",
      "Reconstruction: 0.130536, Regularization: 0.004624, Discriminator: 0.021699; Generator: 0.010801,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:15,902 root         INFO     Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 0.152036\n",
      "Reconstruction: 0.115700, Regularization: 0.003935, Discriminator: 0.021597; Generator: 0.010804,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 21:38:15,990 root         INFO     Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 0.183687\n",
      "Reconstruction: 0.145965, Regularization: 0.005181, Discriminator: 0.021734; Generator: 0.010806,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 21:38:16,074 root         INFO     ====> Epoch: 71 Average loss: 0.1898\n",
      "2019-04-09 21:38:16,099 root         INFO     Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 0.222574\n",
      "Reconstruction: 0.183421, Regularization: 0.006552, Discriminator: 0.021789; Generator: 0.010811,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 21:38:16,190 root         INFO     Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 0.165283\n",
      "Reconstruction: 0.128513, Regularization: 0.004265, Discriminator: 0.021691; Generator: 0.010814,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:16,281 root         INFO     Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 0.165711\n",
      "Reconstruction: 0.129099, Regularization: 0.004115, Discriminator: 0.021670; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:16,372 root         INFO     Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 0.208018\n",
      "Reconstruction: 0.169874, Regularization: 0.005629, Discriminator: 0.021688; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:16,462 root         INFO     Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 0.159999\n",
      "Reconstruction: 0.123781, Regularization: 0.003830, Discriminator: 0.021549; Generator: 0.010840,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 21:38:16,552 root         INFO     Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 0.177890\n",
      "Reconstruction: 0.140525, Regularization: 0.004897, Discriminator: 0.021643; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:16,642 root         INFO     Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 0.185592\n",
      "Reconstruction: 0.147836, Regularization: 0.005216, Discriminator: 0.021699; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:16,732 root         INFO     Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 0.213047\n",
      "Reconstruction: 0.174471, Regularization: 0.006100, Discriminator: 0.021644; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:16,818 root         INFO     ====> Epoch: 72 Average loss: 0.1900\n",
      "2019-04-09 21:38:16,844 root         INFO     Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 0.139408\n",
      "Reconstruction: 0.103504, Regularization: 0.003424, Discriminator: 0.021644; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:16,931 root         INFO     Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 0.198436\n",
      "Reconstruction: 0.160623, Regularization: 0.005417, Discriminator: 0.021552; Generator: 0.010844,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 21:38:17,019 root         INFO     Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 0.165197\n",
      "Reconstruction: 0.128573, Regularization: 0.004150, Discriminator: 0.021636; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:17,109 root         INFO     Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 0.189475\n",
      "Reconstruction: 0.151690, Regularization: 0.005239, Discriminator: 0.021700; Generator: 0.010847,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 21:38:17,199 root         INFO     Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 0.193894\n",
      "Reconstruction: 0.155400, Regularization: 0.005999, Discriminator: 0.021638; Generator: 0.010857,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:17,289 root         INFO     Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 0.176017\n",
      "Reconstruction: 0.138650, Regularization: 0.004822, Discriminator: 0.021699; Generator: 0.010845,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:17,380 root         INFO     Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 0.187185\n",
      "Reconstruction: 0.149691, Regularization: 0.004981, Discriminator: 0.021651; Generator: 0.010862,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:17,467 root         INFO     Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 0.222535\n",
      "Reconstruction: 0.183738, Regularization: 0.006351, Discriminator: 0.021576; Generator: 0.010870,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 21:38:17,552 root         INFO     ====> Epoch: 73 Average loss: 0.1901\n",
      "2019-04-09 21:38:17,578 root         INFO     Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 0.230430\n",
      "Reconstruction: 0.190752, Regularization: 0.007127, Discriminator: 0.021681; Generator: 0.010870,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 21:38:17,669 root         INFO     Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 0.224191\n",
      "Reconstruction: 0.185106, Regularization: 0.006576, Discriminator: 0.021628; Generator: 0.010881,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:17,757 root         INFO     Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 0.177626\n",
      "Reconstruction: 0.140786, Regularization: 0.004334, Discriminator: 0.021632; Generator: 0.010875,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:17,846 root         INFO     Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 0.231927\n",
      "Reconstruction: 0.192707, Regularization: 0.006727, Discriminator: 0.021621; Generator: 0.010872,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:17,935 root         INFO     Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 0.185894\n",
      "Reconstruction: 0.148566, Regularization: 0.004946, Discriminator: 0.021501; Generator: 0.010881,\n",
      "D(x): 0.504, D(G(z)): 0.498\n",
      "2019-04-09 21:38:18,024 root         INFO     Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 0.184831\n",
      "Reconstruction: 0.147727, Regularization: 0.004712, Discriminator: 0.021534; Generator: 0.010858,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 21:38:18,112 root         INFO     Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 0.208641\n",
      "Reconstruction: 0.170434, Regularization: 0.005808, Discriminator: 0.021510; Generator: 0.010889,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 21:38:18,200 root         INFO     Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 0.181129\n",
      "Reconstruction: 0.144464, Regularization: 0.004231, Discriminator: 0.021565; Generator: 0.010869,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 21:38:18,284 root         INFO     ====> Epoch: 74 Average loss: 0.1901\n",
      "2019-04-09 21:38:18,310 root         INFO     Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 0.207901\n",
      "Reconstruction: 0.170047, Regularization: 0.005463, Discriminator: 0.021510; Generator: 0.010881,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 21:38:18,399 root         INFO     Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 0.217566\n",
      "Reconstruction: 0.178678, Regularization: 0.006373, Discriminator: 0.021639; Generator: 0.010876,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:18,485 root         INFO     Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 0.199017\n",
      "Reconstruction: 0.161230, Regularization: 0.005318, Discriminator: 0.021619; Generator: 0.010850,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 21:38:18,570 root         INFO     Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 0.167127\n",
      "Reconstruction: 0.130469, Regularization: 0.004167, Discriminator: 0.021623; Generator: 0.010868,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:18,655 root         INFO     Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 0.194006\n",
      "Reconstruction: 0.156606, Regularization: 0.004951, Discriminator: 0.021569; Generator: 0.010879,\n",
      "D(x): 0.502, D(G(z)): 0.498\n",
      "2019-04-09 21:38:18,740 root         INFO     Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 0.169141\n",
      "Reconstruction: 0.132090, Regularization: 0.004535, Discriminator: 0.021633; Generator: 0.010883,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:18,826 root         INFO     Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 0.232155\n",
      "Reconstruction: 0.193433, Regularization: 0.006312, Discriminator: 0.021526; Generator: 0.010885,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 21:38:18,912 root         INFO     Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 0.218725\n",
      "Reconstruction: 0.180461, Regularization: 0.005856, Discriminator: 0.021529; Generator: 0.010880,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 21:38:18,995 root         INFO     ====> Epoch: 75 Average loss: 0.1903\n",
      "2019-04-09 21:38:19,021 root         INFO     Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 0.170966\n",
      "Reconstruction: 0.134332, Regularization: 0.004222, Discriminator: 0.021533; Generator: 0.010880,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 21:38:19,109 root         INFO     Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 0.204768\n",
      "Reconstruction: 0.166777, Regularization: 0.005464, Discriminator: 0.021652; Generator: 0.010875,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 21:38:19,198 root         INFO     Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 0.194490\n",
      "Reconstruction: 0.157163, Regularization: 0.004927, Discriminator: 0.021494; Generator: 0.010906,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 21:38:19,285 root         INFO     Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 0.175127\n",
      "Reconstruction: 0.138493, Regularization: 0.004219, Discriminator: 0.021539; Generator: 0.010877,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 21:38:19,374 root         INFO     Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 0.171715\n",
      "Reconstruction: 0.134926, Regularization: 0.004274, Discriminator: 0.021672; Generator: 0.010843,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:19,462 root         INFO     Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 0.171783\n",
      "Reconstruction: 0.135136, Regularization: 0.004187, Discriminator: 0.021592; Generator: 0.010867,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 21:38:19,550 root         INFO     Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 0.177950\n",
      "Reconstruction: 0.140797, Regularization: 0.004625, Discriminator: 0.021666; Generator: 0.010862,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 21:38:19,639 root         INFO     Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 0.160562\n",
      "Reconstruction: 0.124531, Regularization: 0.003563, Discriminator: 0.021572; Generator: 0.010896,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 21:38:19,726 root         INFO     ====> Epoch: 76 Average loss: 0.1908\n",
      "2019-04-09 21:38:19,752 root         INFO     Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 0.173345\n",
      "Reconstruction: 0.136659, Regularization: 0.004130, Discriminator: 0.021694; Generator: 0.010862,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 21:38:19,841 root         INFO     Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 0.161125\n",
      "Reconstruction: 0.124763, Regularization: 0.003884, Discriminator: 0.021592; Generator: 0.010886,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 21:38:19,928 root         INFO     Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 0.179430\n",
      "Reconstruction: 0.142222, Regularization: 0.004663, Discriminator: 0.021664; Generator: 0.010880,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 21:38:20,016 root         INFO     Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 0.176441\n",
      "Reconstruction: 0.139640, Regularization: 0.004366, Discriminator: 0.021546; Generator: 0.010888,\n",
      "D(x): 0.502, D(G(z)): 0.498\n",
      "2019-04-09 21:38:20,103 root         INFO     Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 0.204466\n",
      "Reconstruction: 0.167057, Regularization: 0.005084, Discriminator: 0.021443; Generator: 0.010883,\n",
      "D(x): 0.506, D(G(z)): 0.498\n",
      "2019-04-09 21:38:20,191 root         INFO     Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 0.211295\n",
      "Reconstruction: 0.173727, Regularization: 0.005205, Discriminator: 0.021470; Generator: 0.010893,\n",
      "D(x): 0.505, D(G(z)): 0.498\n",
      "2019-04-09 21:38:20,277 root         INFO     Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 0.213943\n",
      "Reconstruction: 0.176047, Regularization: 0.005387, Discriminator: 0.021635; Generator: 0.010875,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:20,363 root         INFO     Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 0.172674\n",
      "Reconstruction: 0.136127, Regularization: 0.004092, Discriminator: 0.021568; Generator: 0.010887,\n",
      "D(x): 0.502, D(G(z)): 0.498\n",
      "2019-04-09 21:38:20,445 root         INFO     ====> Epoch: 77 Average loss: 0.1913\n",
      "2019-04-09 21:38:20,472 root         INFO     Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 0.192113\n",
      "Reconstruction: 0.155241, Regularization: 0.004498, Discriminator: 0.021517; Generator: 0.010856,\n",
      "D(x): 0.504, D(G(z)): 0.499\n",
      "2019-04-09 21:38:20,559 root         INFO     Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 0.169955\n",
      "Reconstruction: 0.133691, Regularization: 0.003922, Discriminator: 0.021448; Generator: 0.010894,\n",
      "D(x): 0.505, D(G(z)): 0.498\n",
      "2019-04-09 21:38:20,646 root         INFO     Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 0.241552\n",
      "Reconstruction: 0.202556, Regularization: 0.006480, Discriminator: 0.021648; Generator: 0.010869,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:20,734 root         INFO     Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 0.195554\n",
      "Reconstruction: 0.158011, Regularization: 0.004997, Discriminator: 0.021674; Generator: 0.010872,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 21:38:20,820 root         INFO     Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 0.189914\n",
      "Reconstruction: 0.152762, Regularization: 0.004572, Discriminator: 0.021711; Generator: 0.010869,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 21:38:20,908 root         INFO     Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 0.174485\n",
      "Reconstruction: 0.137747, Regularization: 0.004160, Discriminator: 0.021691; Generator: 0.010886,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 21:38:20,996 root         INFO     Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 0.196148\n",
      "Reconstruction: 0.158604, Regularization: 0.005037, Discriminator: 0.021602; Generator: 0.010905,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:21,084 root         INFO     Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 0.194834\n",
      "Reconstruction: 0.157564, Regularization: 0.004760, Discriminator: 0.021631; Generator: 0.010878,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:21,169 root         INFO     ====> Epoch: 78 Average loss: 0.1921\n",
      "2019-04-09 21:38:21,194 root         INFO     Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 0.186867\n",
      "Reconstruction: 0.150069, Regularization: 0.004396, Discriminator: 0.021493; Generator: 0.010909,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 21:38:21,282 root         INFO     Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 0.228410\n",
      "Reconstruction: 0.190270, Regularization: 0.005687, Discriminator: 0.021587; Generator: 0.010866,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 21:38:21,369 root         INFO     Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 0.212847\n",
      "Reconstruction: 0.175002, Regularization: 0.005389, Discriminator: 0.021592; Generator: 0.010865,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 21:38:21,456 root         INFO     Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 0.168779\n",
      "Reconstruction: 0.132831, Regularization: 0.003478, Discriminator: 0.021597; Generator: 0.010873,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 21:38:21,543 root         INFO     Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 0.230837\n",
      "Reconstruction: 0.192921, Regularization: 0.005441, Discriminator: 0.021588; Generator: 0.010885,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 21:38:21,630 root         INFO     Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 0.207587\n",
      "Reconstruction: 0.169411, Regularization: 0.005468, Discriminator: 0.021820; Generator: 0.010889,\n",
      "D(x): 0.494, D(G(z)): 0.498\n",
      "2019-04-09 21:38:21,716 root         INFO     Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 0.189179\n",
      "Reconstruction: 0.152306, Regularization: 0.004395, Discriminator: 0.021564; Generator: 0.010914,\n",
      "D(x): 0.501, D(G(z)): 0.497\n",
      "2019-04-09 21:38:21,803 root         INFO     Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 0.200307\n",
      "Reconstruction: 0.163254, Regularization: 0.004546, Discriminator: 0.021603; Generator: 0.010904,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:21,887 root         INFO     ====> Epoch: 79 Average loss: 0.1928\n",
      "2019-04-09 21:38:21,912 root         INFO     Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 0.190979\n",
      "Reconstruction: 0.154004, Regularization: 0.004455, Discriminator: 0.021618; Generator: 0.010902,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:22,000 root         INFO     Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 0.193010\n",
      "Reconstruction: 0.155771, Regularization: 0.004535, Discriminator: 0.021825; Generator: 0.010879,\n",
      "D(x): 0.494, D(G(z)): 0.498\n",
      "2019-04-09 21:38:22,086 root         INFO     Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 0.188606\n",
      "Reconstruction: 0.151325, Regularization: 0.004758, Discriminator: 0.021656; Generator: 0.010867,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:22,173 root         INFO     Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 0.144597\n",
      "Reconstruction: 0.109065, Regularization: 0.003060, Discriminator: 0.021617; Generator: 0.010855,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 21:38:22,260 root         INFO     Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 0.192270\n",
      "Reconstruction: 0.155418, Regularization: 0.004324, Discriminator: 0.021662; Generator: 0.010866,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 21:38:22,346 root         INFO     Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 0.179993\n",
      "Reconstruction: 0.143486, Regularization: 0.003971, Discriminator: 0.021678; Generator: 0.010858,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 21:38:22,433 root         INFO     Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 0.192061\n",
      "Reconstruction: 0.154842, Regularization: 0.004526, Discriminator: 0.021789; Generator: 0.010904,\n",
      "D(x): 0.494, D(G(z)): 0.498\n",
      "2019-04-09 21:38:22,520 root         INFO     Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 0.226242\n",
      "Reconstruction: 0.187918, Regularization: 0.005720, Discriminator: 0.021709; Generator: 0.010896,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 21:38:22,605 root         INFO     ====> Epoch: 80 Average loss: 0.1936\n",
      "2019-04-09 21:38:22,630 root         INFO     Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 0.180393\n",
      "Reconstruction: 0.143721, Regularization: 0.004110, Discriminator: 0.021681; Generator: 0.010880,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 21:38:22,717 root         INFO     Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 0.212392\n",
      "Reconstruction: 0.174457, Regularization: 0.005330, Discriminator: 0.021721; Generator: 0.010884,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 21:38:22,805 root         INFO     Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 0.204259\n",
      "Reconstruction: 0.167319, Regularization: 0.004433, Discriminator: 0.021599; Generator: 0.010908,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:22,892 root         INFO     Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 0.185608\n",
      "Reconstruction: 0.148924, Regularization: 0.004096, Discriminator: 0.021705; Generator: 0.010883,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 21:38:22,980 root         INFO     Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 0.190136\n",
      "Reconstruction: 0.153282, Regularization: 0.004204, Discriminator: 0.021765; Generator: 0.010886,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 21:38:23,067 root         INFO     Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 0.190378\n",
      "Reconstruction: 0.153531, Regularization: 0.004233, Discriminator: 0.021720; Generator: 0.010894,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 21:38:23,155 root         INFO     Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 0.221399\n",
      "Reconstruction: 0.182994, Regularization: 0.005753, Discriminator: 0.021761; Generator: 0.010891,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 21:38:23,241 root         INFO     Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 0.243075\n",
      "Reconstruction: 0.203584, Regularization: 0.006822, Discriminator: 0.021796; Generator: 0.010873,\n",
      "D(x): 0.495, D(G(z)): 0.499\n",
      "2019-04-09 21:38:23,325 root         INFO     ====> Epoch: 81 Average loss: 0.1942\n",
      "2019-04-09 21:38:23,350 root         INFO     Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 0.226635\n",
      "Reconstruction: 0.188921, Regularization: 0.005133, Discriminator: 0.021715; Generator: 0.010866,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 21:38:23,436 root         INFO     Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 0.212573\n",
      "Reconstruction: 0.174865, Regularization: 0.005034, Discriminator: 0.021827; Generator: 0.010847,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 21:38:23,522 root         INFO     Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 0.180087\n",
      "Reconstruction: 0.143476, Regularization: 0.003944, Discriminator: 0.021806; Generator: 0.010861,\n",
      "D(x): 0.495, D(G(z)): 0.499\n",
      "2019-04-09 21:38:23,608 root         INFO     Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 0.192298\n",
      "Reconstruction: 0.155886, Regularization: 0.003991, Discriminator: 0.021566; Generator: 0.010853,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 21:38:23,693 root         INFO     Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 0.181862\n",
      "Reconstruction: 0.145341, Regularization: 0.003887, Discriminator: 0.021780; Generator: 0.010854,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 21:38:23,779 root         INFO     Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 0.214158\n",
      "Reconstruction: 0.177094, Regularization: 0.004554, Discriminator: 0.021680; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:23,864 root         INFO     Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 0.217425\n",
      "Reconstruction: 0.179500, Regularization: 0.005242, Discriminator: 0.021827; Generator: 0.010856,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 21:38:23,949 root         INFO     Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 0.158193\n",
      "Reconstruction: 0.122072, Regularization: 0.003426, Discriminator: 0.021838; Generator: 0.010857,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 21:38:24,031 root         INFO     ====> Epoch: 82 Average loss: 0.1950\n",
      "2019-04-09 21:38:24,057 root         INFO     Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 0.227814\n",
      "Reconstruction: 0.189785, Regularization: 0.005399, Discriminator: 0.021771; Generator: 0.010860,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 21:38:24,145 root         INFO     Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 0.188218\n",
      "Reconstruction: 0.151414, Regularization: 0.004133, Discriminator: 0.021803; Generator: 0.010867,\n",
      "D(x): 0.495, D(G(z)): 0.499\n",
      "2019-04-09 21:38:24,232 root         INFO     Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 0.215227\n",
      "Reconstruction: 0.177139, Regularization: 0.005397, Discriminator: 0.021807; Generator: 0.010885,\n",
      "D(x): 0.494, D(G(z)): 0.498\n",
      "2019-04-09 21:38:24,320 root         INFO     Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 0.189103\n",
      "Reconstruction: 0.152273, Regularization: 0.004225, Discriminator: 0.021748; Generator: 0.010857,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 21:38:24,407 root         INFO     Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 0.221556\n",
      "Reconstruction: 0.184202, Regularization: 0.004817, Discriminator: 0.021660; Generator: 0.010877,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 21:38:24,495 root         INFO     Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 0.213921\n",
      "Reconstruction: 0.176792, Regularization: 0.004545, Discriminator: 0.021726; Generator: 0.010858,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 21:38:24,583 root         INFO     Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 0.181770\n",
      "Reconstruction: 0.145675, Regularization: 0.003655, Discriminator: 0.021589; Generator: 0.010851,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 21:38:24,670 root         INFO     Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 0.187677\n",
      "Reconstruction: 0.151141, Regularization: 0.003978, Discriminator: 0.021727; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:24,753 root         INFO     ====> Epoch: 83 Average loss: 0.1960\n",
      "2019-04-09 21:38:24,779 root         INFO     Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 0.167081\n",
      "Reconstruction: 0.130926, Regularization: 0.003611, Discriminator: 0.021702; Generator: 0.010842,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:24,867 root         INFO     Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 0.175221\n",
      "Reconstruction: 0.139318, Regularization: 0.003382, Discriminator: 0.021697; Generator: 0.010824,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:24,954 root         INFO     Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 0.174012\n",
      "Reconstruction: 0.137992, Regularization: 0.003491, Discriminator: 0.021711; Generator: 0.010818,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:25,042 root         INFO     Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 0.205602\n",
      "Reconstruction: 0.167976, Regularization: 0.004956, Discriminator: 0.021842; Generator: 0.010829,\n",
      "D(x): 0.494, D(G(z)): 0.500\n",
      "2019-04-09 21:38:25,166 root         INFO     Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 0.248202\n",
      "Reconstruction: 0.210274, Regularization: 0.005454, Discriminator: 0.021651; Generator: 0.010822,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:25,256 root         INFO     Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 0.223723\n",
      "Reconstruction: 0.186437, Regularization: 0.004765, Discriminator: 0.021682; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:25,347 root         INFO     Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 0.193068\n",
      "Reconstruction: 0.156300, Regularization: 0.004185, Discriminator: 0.021765; Generator: 0.010818,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 21:38:25,438 root         INFO     Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 0.194924\n",
      "Reconstruction: 0.158503, Regularization: 0.003863, Discriminator: 0.021734; Generator: 0.010824,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:25,524 root         INFO     ====> Epoch: 84 Average loss: 0.1960\n",
      "2019-04-09 21:38:25,550 root         INFO     Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 0.202928\n",
      "Reconstruction: 0.165805, Regularization: 0.004537, Discriminator: 0.021744; Generator: 0.010841,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 21:38:25,640 root         INFO     Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 0.219994\n",
      "Reconstruction: 0.182406, Regularization: 0.004978, Discriminator: 0.021769; Generator: 0.010842,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 21:38:25,731 root         INFO     Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 0.189393\n",
      "Reconstruction: 0.152733, Regularization: 0.004068, Discriminator: 0.021757; Generator: 0.010835,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 21:38:25,821 root         INFO     Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 0.166031\n",
      "Reconstruction: 0.130160, Regularization: 0.003323, Discriminator: 0.021705; Generator: 0.010842,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:25,911 root         INFO     Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 0.192944\n",
      "Reconstruction: 0.156649, Regularization: 0.003750, Discriminator: 0.021698; Generator: 0.010847,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 21:38:26,002 root         INFO     Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 0.211622\n",
      "Reconstruction: 0.174435, Regularization: 0.004599, Discriminator: 0.021740; Generator: 0.010847,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 21:38:26,091 root         INFO     Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 0.183483\n",
      "Reconstruction: 0.147372, Regularization: 0.003583, Discriminator: 0.021701; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:26,180 root         INFO     Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 0.213830\n",
      "Reconstruction: 0.176999, Regularization: 0.004320, Discriminator: 0.021690; Generator: 0.010821,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:26,265 root         INFO     ====> Epoch: 85 Average loss: 0.1966\n",
      "2019-04-09 21:38:26,291 root         INFO     Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 0.169130\n",
      "Reconstruction: 0.133435, Regularization: 0.003187, Discriminator: 0.021690; Generator: 0.010818,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:26,378 root         INFO     Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 0.166693\n",
      "Reconstruction: 0.131010, Regularization: 0.003142, Discriminator: 0.021707; Generator: 0.010834,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:26,466 root         INFO     Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 0.177322\n",
      "Reconstruction: 0.141367, Regularization: 0.003422, Discriminator: 0.021696; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:26,556 root         INFO     Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 0.205512\n",
      "Reconstruction: 0.168188, Regularization: 0.004776, Discriminator: 0.021721; Generator: 0.010828,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:26,645 root         INFO     Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 0.212060\n",
      "Reconstruction: 0.175094, Regularization: 0.004474, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:26,734 root         INFO     Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 0.194386\n",
      "Reconstruction: 0.157889, Regularization: 0.003943, Discriminator: 0.021727; Generator: 0.010827,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:26,823 root         INFO     Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 0.152418\n",
      "Reconstruction: 0.117297, Regularization: 0.002612, Discriminator: 0.021692; Generator: 0.010817,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:26,915 root         INFO     Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 0.166333\n",
      "Reconstruction: 0.130365, Regularization: 0.003457, Discriminator: 0.021699; Generator: 0.010812,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 21:38:27,004 root         INFO     ====> Epoch: 86 Average loss: 0.1973\n",
      "2019-04-09 21:38:27,029 root         INFO     Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 0.242459\n",
      "Reconstruction: 0.204720, Regularization: 0.005243, Discriminator: 0.021681; Generator: 0.010815,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:27,120 root         INFO     Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 0.211714\n",
      "Reconstruction: 0.175022, Regularization: 0.004200, Discriminator: 0.021674; Generator: 0.010817,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:27,209 root         INFO     Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 0.183650\n",
      "Reconstruction: 0.147242, Regularization: 0.003901, Discriminator: 0.021688; Generator: 0.010820,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:27,296 root         INFO     Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 0.181716\n",
      "Reconstruction: 0.145608, Regularization: 0.003622, Discriminator: 0.021668; Generator: 0.010818,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:27,381 root         INFO     Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 0.194004\n",
      "Reconstruction: 0.157790, Regularization: 0.003714, Discriminator: 0.021672; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:27,468 root         INFO     Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 0.239989\n",
      "Reconstruction: 0.202376, Regularization: 0.005123, Discriminator: 0.021675; Generator: 0.010816,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:27,555 root         INFO     Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 0.163653\n",
      "Reconstruction: 0.128029, Regularization: 0.003136, Discriminator: 0.021679; Generator: 0.010809,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:27,640 root         INFO     Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 0.134662\n",
      "Reconstruction: 0.099925, Regularization: 0.002247, Discriminator: 0.021669; Generator: 0.010821,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:27,723 root         INFO     ====> Epoch: 87 Average loss: 0.1973\n",
      "2019-04-09 21:38:27,749 root         INFO     Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 0.190449\n",
      "Reconstruction: 0.153891, Regularization: 0.004062, Discriminator: 0.021676; Generator: 0.010821,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:27,839 root         INFO     Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 0.235783\n",
      "Reconstruction: 0.197959, Regularization: 0.005319, Discriminator: 0.021675; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:27,929 root         INFO     Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 0.175977\n",
      "Reconstruction: 0.139584, Regularization: 0.003896, Discriminator: 0.021665; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:28,018 root         INFO     Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 0.201014\n",
      "Reconstruction: 0.164548, Regularization: 0.003974, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:28,108 root         INFO     Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 0.206776\n",
      "Reconstruction: 0.170237, Regularization: 0.004045, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:28,196 root         INFO     Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 0.197225\n",
      "Reconstruction: 0.160843, Regularization: 0.003891, Discriminator: 0.021662; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:28,285 root         INFO     Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 0.183443\n",
      "Reconstruction: 0.147757, Regularization: 0.003191, Discriminator: 0.021661; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:28,374 root         INFO     Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 0.225186\n",
      "Reconstruction: 0.187915, Regularization: 0.004799, Discriminator: 0.021646; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:28,460 root         INFO     ====> Epoch: 88 Average loss: 0.1973\n",
      "2019-04-09 21:38:28,485 root         INFO     Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 0.270298\n",
      "Reconstruction: 0.232091, Regularization: 0.005737, Discriminator: 0.021647; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:28,576 root         INFO     Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 0.214368\n",
      "Reconstruction: 0.176786, Regularization: 0.005086, Discriminator: 0.021659; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:28,667 root         INFO     Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 0.175556\n",
      "Reconstruction: 0.139515, Regularization: 0.003535, Discriminator: 0.021665; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:28,759 root         INFO     Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 0.210637\n",
      "Reconstruction: 0.174145, Regularization: 0.004006, Discriminator: 0.021649; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:28,851 root         INFO     Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 0.199404\n",
      "Reconstruction: 0.163191, Regularization: 0.003744, Discriminator: 0.021634; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:28,942 root         INFO     Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 0.189179\n",
      "Reconstruction: 0.153195, Regularization: 0.003505, Discriminator: 0.021648; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:29,029 root         INFO     Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 0.188257\n",
      "Reconstruction: 0.152189, Regularization: 0.003614, Discriminator: 0.021629; Generator: 0.010825,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:29,117 root         INFO     Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 0.195801\n",
      "Reconstruction: 0.159137, Regularization: 0.004151, Discriminator: 0.021678; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:29,202 root         INFO     ====> Epoch: 89 Average loss: 0.1973\n",
      "2019-04-09 21:38:29,227 root         INFO     Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 0.212357\n",
      "Reconstruction: 0.175716, Regularization: 0.004193, Discriminator: 0.021597; Generator: 0.010852,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 21:38:29,315 root         INFO     Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 0.177511\n",
      "Reconstruction: 0.141282, Regularization: 0.003756, Discriminator: 0.021618; Generator: 0.010855,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 21:38:29,402 root         INFO     Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 0.184718\n",
      "Reconstruction: 0.148396, Regularization: 0.003843, Discriminator: 0.021605; Generator: 0.010873,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:29,489 root         INFO     Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 0.199277\n",
      "Reconstruction: 0.163080, Regularization: 0.003667, Discriminator: 0.021658; Generator: 0.010871,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 21:38:29,574 root         INFO     Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 0.248075\n",
      "Reconstruction: 0.210247, Regularization: 0.005327, Discriminator: 0.021632; Generator: 0.010869,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:29,659 root         INFO     Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 0.180220\n",
      "Reconstruction: 0.144262, Regularization: 0.003493, Discriminator: 0.021599; Generator: 0.010866,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 21:38:29,744 root         INFO     Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 0.197410\n",
      "Reconstruction: 0.160890, Regularization: 0.004016, Discriminator: 0.021638; Generator: 0.010866,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:29,830 root         INFO     Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 0.177695\n",
      "Reconstruction: 0.141887, Regularization: 0.003344, Discriminator: 0.021601; Generator: 0.010863,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 21:38:29,913 root         INFO     ====> Epoch: 90 Average loss: 0.1971\n",
      "2019-04-09 21:38:29,939 root         INFO     Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 0.248615\n",
      "Reconstruction: 0.210969, Regularization: 0.005146, Discriminator: 0.021643; Generator: 0.010856,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:30,024 root         INFO     Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 0.208286\n",
      "Reconstruction: 0.171553, Regularization: 0.004264, Discriminator: 0.021603; Generator: 0.010866,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 21:38:30,110 root         INFO     Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 0.177871\n",
      "Reconstruction: 0.141967, Regularization: 0.003406, Discriminator: 0.021631; Generator: 0.010867,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:30,196 root         INFO     Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 0.199154\n",
      "Reconstruction: 0.162308, Regularization: 0.004358, Discriminator: 0.021607; Generator: 0.010880,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:30,282 root         INFO     Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 0.173764\n",
      "Reconstruction: 0.138045, Regularization: 0.003206, Discriminator: 0.021629; Generator: 0.010883,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 21:38:30,368 root         INFO     Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 0.227340\n",
      "Reconstruction: 0.190184, Regularization: 0.004609, Discriminator: 0.021666; Generator: 0.010881,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 21:38:30,453 root         INFO     Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 0.165932\n",
      "Reconstruction: 0.130495, Regularization: 0.002965, Discriminator: 0.021589; Generator: 0.010884,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 21:38:30,539 root         INFO     Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 0.214068\n",
      "Reconstruction: 0.177391, Regularization: 0.004140, Discriminator: 0.021650; Generator: 0.010887,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 21:38:30,621 root         INFO     ====> Epoch: 91 Average loss: 0.1965\n",
      "2019-04-09 21:38:30,646 root         INFO     Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 0.211501\n",
      "Reconstruction: 0.174993, Regularization: 0.004007, Discriminator: 0.021616; Generator: 0.010885,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:30,736 root         INFO     Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 0.242588\n",
      "Reconstruction: 0.204563, Regularization: 0.005567, Discriminator: 0.021578; Generator: 0.010880,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 21:38:30,824 root         INFO     Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 0.176740\n",
      "Reconstruction: 0.140908, Regularization: 0.003344, Discriminator: 0.021607; Generator: 0.010881,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:30,912 root         INFO     Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 0.232745\n",
      "Reconstruction: 0.195490, Regularization: 0.004718, Discriminator: 0.021647; Generator: 0.010891,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 21:38:31,001 root         INFO     Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 0.217821\n",
      "Reconstruction: 0.181082, Regularization: 0.004252, Discriminator: 0.021593; Generator: 0.010895,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:31,089 root         INFO     Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 0.192863\n",
      "Reconstruction: 0.156475, Regularization: 0.003915, Discriminator: 0.021575; Generator: 0.010898,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 21:38:31,177 root         INFO     Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 0.188823\n",
      "Reconstruction: 0.152413, Regularization: 0.003926, Discriminator: 0.021595; Generator: 0.010888,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:31,265 root         INFO     Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 0.179758\n",
      "Reconstruction: 0.143871, Regularization: 0.003308, Discriminator: 0.021687; Generator: 0.010892,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 21:38:31,349 root         INFO     ====> Epoch: 92 Average loss: 0.1959\n",
      "2019-04-09 21:38:31,375 root         INFO     Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 0.191599\n",
      "Reconstruction: 0.155163, Regularization: 0.003930, Discriminator: 0.021612; Generator: 0.010894,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:31,464 root         INFO     Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 0.198238\n",
      "Reconstruction: 0.160781, Regularization: 0.004951, Discriminator: 0.021603; Generator: 0.010902,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:31,552 root         INFO     Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 0.195200\n",
      "Reconstruction: 0.158796, Regularization: 0.003876, Discriminator: 0.021631; Generator: 0.010897,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 21:38:31,640 root         INFO     Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 0.179230\n",
      "Reconstruction: 0.143217, Regularization: 0.003552, Discriminator: 0.021567; Generator: 0.010895,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 21:38:31,728 root         INFO     Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 0.197733\n",
      "Reconstruction: 0.161382, Regularization: 0.003871, Discriminator: 0.021584; Generator: 0.010896,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:31,817 root         INFO     Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 0.223896\n",
      "Reconstruction: 0.186842, Regularization: 0.004474, Discriminator: 0.021693; Generator: 0.010887,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 21:38:31,905 root         INFO     Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 0.221417\n",
      "Reconstruction: 0.183551, Regularization: 0.005374, Discriminator: 0.021597; Generator: 0.010896,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 21:38:31,993 root         INFO     Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 0.177706\n",
      "Reconstruction: 0.141984, Regularization: 0.003156, Discriminator: 0.021699; Generator: 0.010866,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 21:38:32,077 root         INFO     ====> Epoch: 93 Average loss: 0.1951\n",
      "2019-04-09 21:38:32,103 root         INFO     Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 0.177085\n",
      "Reconstruction: 0.140783, Regularization: 0.003873, Discriminator: 0.021546; Generator: 0.010883,\n",
      "D(x): 0.502, D(G(z)): 0.498\n",
      "2019-04-09 21:38:32,192 root         INFO     Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 0.184027\n",
      "Reconstruction: 0.147784, Regularization: 0.003700, Discriminator: 0.021633; Generator: 0.010909,\n",
      "D(x): 0.499, D(G(z)): 0.497\n",
      "2019-04-09 21:38:32,280 root         INFO     Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 0.187632\n",
      "Reconstruction: 0.151223, Regularization: 0.003858, Discriminator: 0.021695; Generator: 0.010856,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 21:38:32,368 root         INFO     Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 0.214168\n",
      "Reconstruction: 0.176880, Regularization: 0.004718, Discriminator: 0.021691; Generator: 0.010879,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 21:38:32,456 root         INFO     Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 0.195958\n",
      "Reconstruction: 0.159633, Regularization: 0.003728, Discriminator: 0.021725; Generator: 0.010872,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 21:38:32,544 root         INFO     Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 0.154896\n",
      "Reconstruction: 0.119605, Regularization: 0.002796, Discriminator: 0.021620; Generator: 0.010875,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:32,633 root         INFO     Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 0.181864\n",
      "Reconstruction: 0.145617, Regularization: 0.003695, Discriminator: 0.021642; Generator: 0.010909,\n",
      "D(x): 0.498, D(G(z)): 0.497\n",
      "2019-04-09 21:38:32,721 root         INFO     Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 0.181429\n",
      "Reconstruction: 0.145175, Regularization: 0.003780, Discriminator: 0.021592; Generator: 0.010882,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 21:38:32,805 root         INFO     ====> Epoch: 94 Average loss: 0.1942\n",
      "2019-04-09 21:38:32,831 root         INFO     Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 0.193264\n",
      "Reconstruction: 0.156877, Regularization: 0.003860, Discriminator: 0.021662; Generator: 0.010864,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 21:38:32,916 root         INFO     Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 0.195465\n",
      "Reconstruction: 0.159021, Regularization: 0.003903, Discriminator: 0.021681; Generator: 0.010861,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 21:38:33,002 root         INFO     Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 0.229507\n",
      "Reconstruction: 0.191944, Regularization: 0.005083, Discriminator: 0.021640; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:33,087 root         INFO     Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 0.191000\n",
      "Reconstruction: 0.154904, Regularization: 0.003574, Discriminator: 0.021687; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:33,173 root         INFO     Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 0.187614\n",
      "Reconstruction: 0.151183, Regularization: 0.003932, Discriminator: 0.021654; Generator: 0.010844,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:33,258 root         INFO     Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 0.206795\n",
      "Reconstruction: 0.170004, Regularization: 0.004304, Discriminator: 0.021665; Generator: 0.010823,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:33,344 root         INFO     Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 0.226778\n",
      "Reconstruction: 0.189085, Regularization: 0.005211, Discriminator: 0.021624; Generator: 0.010859,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:33,429 root         INFO     Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 0.232815\n",
      "Reconstruction: 0.195430, Regularization: 0.004752, Discriminator: 0.021783; Generator: 0.010849,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 21:38:33,512 root         INFO     ====> Epoch: 95 Average loss: 0.1934\n",
      "2019-04-09 21:38:33,537 root         INFO     Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 0.168577\n",
      "Reconstruction: 0.132797, Regularization: 0.003286, Discriminator: 0.021650; Generator: 0.010845,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:33,626 root         INFO     Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 0.183279\n",
      "Reconstruction: 0.147096, Regularization: 0.003638, Discriminator: 0.021697; Generator: 0.010848,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 21:38:33,714 root         INFO     Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 0.177176\n",
      "Reconstruction: 0.141309, Regularization: 0.003285, Discriminator: 0.021753; Generator: 0.010829,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 21:38:33,803 root         INFO     Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 0.183047\n",
      "Reconstruction: 0.147017, Regularization: 0.003552, Discriminator: 0.021654; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:33,891 root         INFO     Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 0.203320\n",
      "Reconstruction: 0.166729, Regularization: 0.004038, Discriminator: 0.021739; Generator: 0.010815,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 21:38:33,979 root         INFO     Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 0.254506\n",
      "Reconstruction: 0.215748, Regularization: 0.006321, Discriminator: 0.021627; Generator: 0.010811,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 21:38:34,067 root         INFO     Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 0.183000\n",
      "Reconstruction: 0.146604, Regularization: 0.003904, Discriminator: 0.021666; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:34,155 root         INFO     Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 0.205756\n",
      "Reconstruction: 0.167912, Regularization: 0.005384, Discriminator: 0.021643; Generator: 0.010817,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:34,239 root         INFO     ====> Epoch: 96 Average loss: 0.1926\n",
      "2019-04-09 21:38:34,265 root         INFO     Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 0.198202\n",
      "Reconstruction: 0.161257, Regularization: 0.004436, Discriminator: 0.021691; Generator: 0.010818,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:34,353 root         INFO     Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 0.210973\n",
      "Reconstruction: 0.173796, Regularization: 0.004658, Discriminator: 0.021710; Generator: 0.010808,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 21:38:34,441 root         INFO     Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 0.185511\n",
      "Reconstruction: 0.149336, Regularization: 0.003623, Discriminator: 0.021741; Generator: 0.010810,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 21:38:34,529 root         INFO     Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 0.160965\n",
      "Reconstruction: 0.125281, Regularization: 0.003193, Discriminator: 0.021691; Generator: 0.010799,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:34,617 root         INFO     Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 0.193611\n",
      "Reconstruction: 0.156736, Regularization: 0.004368, Discriminator: 0.021702; Generator: 0.010805,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:34,705 root         INFO     Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 0.181472\n",
      "Reconstruction: 0.145642, Regularization: 0.003301, Discriminator: 0.021722; Generator: 0.010807,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 21:38:34,793 root         INFO     Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 0.216725\n",
      "Reconstruction: 0.179585, Regularization: 0.004616, Discriminator: 0.021706; Generator: 0.010819,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:34,881 root         INFO     Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 0.209291\n",
      "Reconstruction: 0.172553, Regularization: 0.004218, Discriminator: 0.021697; Generator: 0.010823,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:34,965 root         INFO     ====> Epoch: 97 Average loss: 0.1919\n",
      "2019-04-09 21:38:34,990 root         INFO     Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 0.170687\n",
      "Reconstruction: 0.134546, Regularization: 0.003572, Discriminator: 0.021749; Generator: 0.010820,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:35,079 root         INFO     Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 0.193537\n",
      "Reconstruction: 0.157065, Regularization: 0.003981, Discriminator: 0.021654; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:35,167 root         INFO     Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 0.141470\n",
      "Reconstruction: 0.106379, Regularization: 0.002560, Discriminator: 0.021707; Generator: 0.010823,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:35,255 root         INFO     Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 0.170104\n",
      "Reconstruction: 0.134151, Regularization: 0.003412, Discriminator: 0.021719; Generator: 0.010823,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:35,343 root         INFO     Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 0.164469\n",
      "Reconstruction: 0.129089, Regularization: 0.002883, Discriminator: 0.021675; Generator: 0.010821,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:35,431 root         INFO     Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 0.190911\n",
      "Reconstruction: 0.154409, Regularization: 0.003997, Discriminator: 0.021689; Generator: 0.010817,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:35,519 root         INFO     Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 0.233432\n",
      "Reconstruction: 0.195657, Regularization: 0.005288, Discriminator: 0.021672; Generator: 0.010816,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:35,607 root         INFO     Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 0.187452\n",
      "Reconstruction: 0.151243, Regularization: 0.003721, Discriminator: 0.021663; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:35,691 root         INFO     ====> Epoch: 98 Average loss: 0.1914\n",
      "2019-04-09 21:38:35,717 root         INFO     Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 0.191546\n",
      "Reconstruction: 0.155110, Regularization: 0.004009, Discriminator: 0.021596; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 21:38:35,806 root         INFO     Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 0.190635\n",
      "Reconstruction: 0.153996, Regularization: 0.004132, Discriminator: 0.021676; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:35,893 root         INFO     Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 0.184974\n",
      "Reconstruction: 0.148859, Regularization: 0.003590, Discriminator: 0.021696; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:35,979 root         INFO     Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 0.205066\n",
      "Reconstruction: 0.167927, Regularization: 0.004624, Discriminator: 0.021686; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:36,070 root         INFO     Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 0.185751\n",
      "Reconstruction: 0.149384, Regularization: 0.003843, Discriminator: 0.021696; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:36,161 root         INFO     Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 0.184407\n",
      "Reconstruction: 0.148221, Regularization: 0.003661, Discriminator: 0.021690; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:36,251 root         INFO     Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 0.190890\n",
      "Reconstruction: 0.154043, Regularization: 0.004333, Discriminator: 0.021684; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:36,342 root         INFO     Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 0.192712\n",
      "Reconstruction: 0.156129, Regularization: 0.004052, Discriminator: 0.021697; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:36,428 root         INFO     ====> Epoch: 99 Average loss: 0.1911\n",
      "2019-04-09 21:38:36,453 root         INFO     Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 0.200584\n",
      "Reconstruction: 0.164049, Regularization: 0.004040, Discriminator: 0.021664; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:36,544 root         INFO     Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 0.186699\n",
      "Reconstruction: 0.150299, Regularization: 0.003915, Discriminator: 0.021648; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:36,635 root         INFO     Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 0.174311\n",
      "Reconstruction: 0.138528, Regularization: 0.003274, Discriminator: 0.021674; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:36,725 root         INFO     Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 0.165545\n",
      "Reconstruction: 0.129571, Regularization: 0.003458, Discriminator: 0.021686; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:36,815 root         INFO     Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 0.182650\n",
      "Reconstruction: 0.146436, Regularization: 0.003710, Discriminator: 0.021669; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:36,903 root         INFO     Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 0.215632\n",
      "Reconstruction: 0.178541, Regularization: 0.004593, Discriminator: 0.021657; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:36,991 root         INFO     Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 0.173067\n",
      "Reconstruction: 0.136886, Regularization: 0.003653, Discriminator: 0.021695; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:37,080 root         INFO     Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 0.185149\n",
      "Reconstruction: 0.148987, Regularization: 0.003640, Discriminator: 0.021682; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:37,164 root         INFO     ====> Epoch: 100 Average loss: 0.1909\n",
      "2019-04-09 21:38:37,190 root         INFO     Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 0.189778\n",
      "Reconstruction: 0.153505, Regularization: 0.003795, Discriminator: 0.021640; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:37,278 root         INFO     Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 0.188212\n",
      "Reconstruction: 0.152036, Regularization: 0.003631, Discriminator: 0.021695; Generator: 0.010850,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 21:38:37,365 root         INFO     Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 0.203733\n",
      "Reconstruction: 0.166862, Regularization: 0.004343, Discriminator: 0.021692; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:37,453 root         INFO     Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 0.163568\n",
      "Reconstruction: 0.128132, Regularization: 0.002962, Discriminator: 0.021641; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:37,541 root         INFO     Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 0.153458\n",
      "Reconstruction: 0.117896, Regularization: 0.003117, Discriminator: 0.021620; Generator: 0.010825,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 21:38:37,629 root         INFO     Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 0.198851\n",
      "Reconstruction: 0.162632, Regularization: 0.003792, Discriminator: 0.021595; Generator: 0.010832,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 21:38:37,718 root         INFO     Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 0.178805\n",
      "Reconstruction: 0.143232, Regularization: 0.003144, Discriminator: 0.021606; Generator: 0.010823,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 21:38:37,808 root         INFO     Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 0.228982\n",
      "Reconstruction: 0.191247, Regularization: 0.005243, Discriminator: 0.021655; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:37,895 root         INFO     ====> Epoch: 101 Average loss: 0.1912\n",
      "2019-04-09 21:38:37,920 root         INFO     Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 0.146939\n",
      "Reconstruction: 0.111816, Regularization: 0.002625, Discriminator: 0.021661; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:38,010 root         INFO     Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 0.200029\n",
      "Reconstruction: 0.163688, Regularization: 0.003902, Discriminator: 0.021614; Generator: 0.010825,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 21:38:38,100 root         INFO     Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 0.191017\n",
      "Reconstruction: 0.154725, Regularization: 0.003849, Discriminator: 0.021618; Generator: 0.010825,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 21:38:38,190 root         INFO     Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 0.186505\n",
      "Reconstruction: 0.150107, Regularization: 0.003931, Discriminator: 0.021642; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:38,279 root         INFO     Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 0.197363\n",
      "Reconstruction: 0.161015, Regularization: 0.003946, Discriminator: 0.021593; Generator: 0.010809,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 21:38:38,369 root         INFO     Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 0.190920\n",
      "Reconstruction: 0.154509, Regularization: 0.003951, Discriminator: 0.021630; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:38,458 root         INFO     Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 0.236511\n",
      "Reconstruction: 0.198710, Regularization: 0.005340, Discriminator: 0.021626; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:38,547 root         INFO     Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 0.194714\n",
      "Reconstruction: 0.158135, Regularization: 0.004107, Discriminator: 0.021645; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:38,630 root         INFO     ====> Epoch: 102 Average loss: 0.1914\n",
      "2019-04-09 21:38:38,656 root         INFO     Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 0.172351\n",
      "Reconstruction: 0.136332, Regularization: 0.003568, Discriminator: 0.021620; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:38,744 root         INFO     Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 0.244436\n",
      "Reconstruction: 0.206511, Regularization: 0.005406, Discriminator: 0.021693; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:38,835 root         INFO     Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 0.179978\n",
      "Reconstruction: 0.143754, Regularization: 0.003729, Discriminator: 0.021677; Generator: 0.010817,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:38,926 root         INFO     Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 0.242300\n",
      "Reconstruction: 0.204455, Regularization: 0.005325, Discriminator: 0.021693; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:39,016 root         INFO     Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 0.194320\n",
      "Reconstruction: 0.158225, Regularization: 0.003669, Discriminator: 0.021594; Generator: 0.010831,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 21:38:39,105 root         INFO     Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 0.203577\n",
      "Reconstruction: 0.166882, Regularization: 0.004233, Discriminator: 0.021656; Generator: 0.010807,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 21:38:39,193 root         INFO     Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 0.181433\n",
      "Reconstruction: 0.145604, Regularization: 0.003352, Discriminator: 0.021649; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:39,281 root         INFO     Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 0.183165\n",
      "Reconstruction: 0.147265, Regularization: 0.003401, Discriminator: 0.021696; Generator: 0.010802,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:39,367 root         INFO     ====> Epoch: 103 Average loss: 0.1920\n",
      "2019-04-09 21:38:39,393 root         INFO     Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 0.182141\n",
      "Reconstruction: 0.146351, Regularization: 0.003335, Discriminator: 0.021615; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:39,484 root         INFO     Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 0.155525\n",
      "Reconstruction: 0.120636, Regularization: 0.002452, Discriminator: 0.021609; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 21:38:39,575 root         INFO     Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 0.162050\n",
      "Reconstruction: 0.126868, Regularization: 0.002719, Discriminator: 0.021620; Generator: 0.010843,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:39,663 root         INFO     Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 0.219097\n",
      "Reconstruction: 0.182270, Regularization: 0.004375, Discriminator: 0.021630; Generator: 0.010822,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:39,750 root         INFO     Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 0.190880\n",
      "Reconstruction: 0.154454, Regularization: 0.003880, Discriminator: 0.021729; Generator: 0.010817,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:39,837 root         INFO     Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 0.194752\n",
      "Reconstruction: 0.158770, Regularization: 0.003502, Discriminator: 0.021644; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:39,924 root         INFO     Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 0.166131\n",
      "Reconstruction: 0.130892, Regularization: 0.002737, Discriminator: 0.021677; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:40,011 root         INFO     Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 0.147899\n",
      "Reconstruction: 0.112867, Regularization: 0.002529, Discriminator: 0.021666; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:40,094 root         INFO     ====> Epoch: 104 Average loss: 0.1930\n",
      "2019-04-09 21:38:40,120 root         INFO     Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 0.211876\n",
      "Reconstruction: 0.175573, Regularization: 0.003898, Discriminator: 0.021585; Generator: 0.010819,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 21:38:40,206 root         INFO     Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 0.169981\n",
      "Reconstruction: 0.134251, Regularization: 0.003231, Discriminator: 0.021682; Generator: 0.010817,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:40,291 root         INFO     Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 0.181815\n",
      "Reconstruction: 0.146347, Regularization: 0.003020, Discriminator: 0.021627; Generator: 0.010821,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 21:38:40,376 root         INFO     Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 0.168900\n",
      "Reconstruction: 0.133513, Regularization: 0.002886, Discriminator: 0.021681; Generator: 0.010820,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:40,462 root         INFO     Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 0.198307\n",
      "Reconstruction: 0.162124, Regularization: 0.003709, Discriminator: 0.021654; Generator: 0.010820,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:40,549 root         INFO     Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 0.234048\n",
      "Reconstruction: 0.197030, Regularization: 0.004554, Discriminator: 0.021654; Generator: 0.010810,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 21:38:40,637 root         INFO     Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 0.238364\n",
      "Reconstruction: 0.201245, Regularization: 0.004672, Discriminator: 0.021632; Generator: 0.010815,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 21:38:40,726 root         INFO     Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 0.239888\n",
      "Reconstruction: 0.202527, Regularization: 0.004803, Discriminator: 0.021731; Generator: 0.010826,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:40,811 root         INFO     ====> Epoch: 105 Average loss: 0.1941\n",
      "2019-04-09 21:38:40,836 root         INFO     Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 0.196046\n",
      "Reconstruction: 0.159879, Regularization: 0.003618, Discriminator: 0.021724; Generator: 0.010824,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:40,925 root         INFO     Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 0.158301\n",
      "Reconstruction: 0.123225, Regularization: 0.002561, Discriminator: 0.021682; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:41,013 root         INFO     Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 0.161135\n",
      "Reconstruction: 0.126117, Regularization: 0.002524, Discriminator: 0.021670; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:41,100 root         INFO     Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 0.226417\n",
      "Reconstruction: 0.188726, Regularization: 0.005117, Discriminator: 0.021743; Generator: 0.010831,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 21:38:41,186 root         INFO     Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 0.215620\n",
      "Reconstruction: 0.178652, Regularization: 0.004443, Discriminator: 0.021718; Generator: 0.010808,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 21:38:41,272 root         INFO     Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 0.204182\n",
      "Reconstruction: 0.168183, Regularization: 0.003514, Discriminator: 0.021670; Generator: 0.010815,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:41,357 root         INFO     Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 0.245130\n",
      "Reconstruction: 0.207980, Regularization: 0.004642, Discriminator: 0.021686; Generator: 0.010822,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:41,443 root         INFO     Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 0.185866\n",
      "Reconstruction: 0.149770, Regularization: 0.003531, Discriminator: 0.021729; Generator: 0.010836,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:41,526 root         INFO     ====> Epoch: 106 Average loss: 0.1947\n",
      "2019-04-09 21:38:41,552 root         INFO     Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 0.202171\n",
      "Reconstruction: 0.166447, Regularization: 0.003246, Discriminator: 0.021648; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:41,638 root         INFO     Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 0.201881\n",
      "Reconstruction: 0.165518, Regularization: 0.003797, Discriminator: 0.021729; Generator: 0.010837,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:41,723 root         INFO     Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 0.189953\n",
      "Reconstruction: 0.153866, Regularization: 0.003553, Discriminator: 0.021695; Generator: 0.010838,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:41,808 root         INFO     Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 0.204617\n",
      "Reconstruction: 0.168149, Regularization: 0.003958, Discriminator: 0.021677; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:41,894 root         INFO     Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 0.231457\n",
      "Reconstruction: 0.194336, Regularization: 0.004617, Discriminator: 0.021678; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:41,980 root         INFO     Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 0.218116\n",
      "Reconstruction: 0.181763, Regularization: 0.003839, Discriminator: 0.021687; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:42,066 root         INFO     Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 0.198196\n",
      "Reconstruction: 0.161833, Regularization: 0.003850, Discriminator: 0.021686; Generator: 0.010827,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:42,152 root         INFO     Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 0.213791\n",
      "Reconstruction: 0.177489, Regularization: 0.003801, Discriminator: 0.021671; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:42,235 root         INFO     ====> Epoch: 107 Average loss: 0.1953\n",
      "2019-04-09 21:38:42,261 root         INFO     Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 0.195543\n",
      "Reconstruction: 0.159250, Regularization: 0.003793, Discriminator: 0.021671; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:42,345 root         INFO     Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 0.175405\n",
      "Reconstruction: 0.140070, Regularization: 0.002838, Discriminator: 0.021665; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:42,430 root         INFO     Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 0.157452\n",
      "Reconstruction: 0.122424, Regularization: 0.002511, Discriminator: 0.021680; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:42,514 root         INFO     Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 0.180039\n",
      "Reconstruction: 0.144483, Regularization: 0.003068, Discriminator: 0.021659; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:42,598 root         INFO     Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 0.189235\n",
      "Reconstruction: 0.153259, Regularization: 0.003467, Discriminator: 0.021674; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:42,684 root         INFO     Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 0.172334\n",
      "Reconstruction: 0.137327, Regularization: 0.002516, Discriminator: 0.021649; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:42,771 root         INFO     Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 0.192010\n",
      "Reconstruction: 0.156316, Regularization: 0.003201, Discriminator: 0.021656; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:42,859 root         INFO     Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 0.209002\n",
      "Reconstruction: 0.172989, Regularization: 0.003513, Discriminator: 0.021663; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:42,943 root         INFO     ====> Epoch: 108 Average loss: 0.1955\n",
      "2019-04-09 21:38:42,968 root         INFO     Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 0.177408\n",
      "Reconstruction: 0.142094, Regularization: 0.002846, Discriminator: 0.021634; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:43,056 root         INFO     Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 0.144540\n",
      "Reconstruction: 0.109680, Regularization: 0.002357, Discriminator: 0.021665; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:43,143 root         INFO     Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 0.190324\n",
      "Reconstruction: 0.154614, Regularization: 0.003210, Discriminator: 0.021659; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:43,230 root         INFO     Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 0.218883\n",
      "Reconstruction: 0.182824, Regularization: 0.003579, Discriminator: 0.021643; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:43,318 root         INFO     Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 0.167167\n",
      "Reconstruction: 0.131889, Regularization: 0.002806, Discriminator: 0.021633; Generator: 0.010839,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:43,405 root         INFO     Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 0.209976\n",
      "Reconstruction: 0.173402, Regularization: 0.004075, Discriminator: 0.021661; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:43,493 root         INFO     Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 0.180904\n",
      "Reconstruction: 0.145245, Regularization: 0.003167, Discriminator: 0.021650; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:43,580 root         INFO     Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 0.185894\n",
      "Reconstruction: 0.149624, Regularization: 0.003802, Discriminator: 0.021631; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:43,664 root         INFO     ====> Epoch: 109 Average loss: 0.1951\n",
      "2019-04-09 21:38:43,689 root         INFO     Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 0.197883\n",
      "Reconstruction: 0.161936, Regularization: 0.003462, Discriminator: 0.021632; Generator: 0.010852,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 21:38:43,777 root         INFO     Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 0.183091\n",
      "Reconstruction: 0.147558, Regularization: 0.003031, Discriminator: 0.021658; Generator: 0.010843,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:43,865 root         INFO     Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 0.145354\n",
      "Reconstruction: 0.110674, Regularization: 0.002157, Discriminator: 0.021689; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:43,953 root         INFO     Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 0.201173\n",
      "Reconstruction: 0.165073, Regularization: 0.003636, Discriminator: 0.021637; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:44,040 root         INFO     Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 0.165569\n",
      "Reconstruction: 0.130410, Regularization: 0.002663, Discriminator: 0.021664; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:44,128 root         INFO     Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 0.222448\n",
      "Reconstruction: 0.185620, Regularization: 0.004345, Discriminator: 0.021641; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:44,215 root         INFO     Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 0.210039\n",
      "Reconstruction: 0.173586, Regularization: 0.003952, Discriminator: 0.021668; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:44,302 root         INFO     Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 0.174215\n",
      "Reconstruction: 0.138570, Regularization: 0.003187, Discriminator: 0.021620; Generator: 0.010838,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:44,386 root         INFO     ====> Epoch: 110 Average loss: 0.1943\n",
      "2019-04-09 21:38:44,411 root         INFO     Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 0.210698\n",
      "Reconstruction: 0.174433, Regularization: 0.003736, Discriminator: 0.021685; Generator: 0.010844,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:44,499 root         INFO     Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 0.213186\n",
      "Reconstruction: 0.176888, Regularization: 0.003820, Discriminator: 0.021658; Generator: 0.010822,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:44,586 root         INFO     Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 0.203052\n",
      "Reconstruction: 0.167184, Regularization: 0.003375, Discriminator: 0.021654; Generator: 0.010839,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:44,673 root         INFO     Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 0.232184\n",
      "Reconstruction: 0.195496, Regularization: 0.004182, Discriminator: 0.021678; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:44,760 root         INFO     Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 0.221714\n",
      "Reconstruction: 0.185530, Regularization: 0.003723, Discriminator: 0.021638; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:44,847 root         INFO     Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 0.176298\n",
      "Reconstruction: 0.141009, Regularization: 0.002793, Discriminator: 0.021679; Generator: 0.010816,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:44,934 root         INFO     Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 0.253509\n",
      "Reconstruction: 0.216465, Regularization: 0.004563, Discriminator: 0.021661; Generator: 0.010820,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:45,021 root         INFO     Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 0.151808\n",
      "Reconstruction: 0.116968, Regularization: 0.002402, Discriminator: 0.021615; Generator: 0.010823,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 21:38:45,105 root         INFO     ====> Epoch: 111 Average loss: 0.1934\n",
      "2019-04-09 21:38:45,130 root         INFO     Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 0.207067\n",
      "Reconstruction: 0.170875, Regularization: 0.003624, Discriminator: 0.021752; Generator: 0.010816,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:45,216 root         INFO     Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 0.206804\n",
      "Reconstruction: 0.170494, Regularization: 0.003797, Discriminator: 0.021704; Generator: 0.010808,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 21:38:45,301 root         INFO     Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 0.187681\n",
      "Reconstruction: 0.152160, Regularization: 0.003063, Discriminator: 0.021639; Generator: 0.010819,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:45,387 root         INFO     Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 0.207338\n",
      "Reconstruction: 0.171241, Regularization: 0.003577, Discriminator: 0.021701; Generator: 0.010818,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:45,472 root         INFO     Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 0.179853\n",
      "Reconstruction: 0.144409, Regularization: 0.002951, Discriminator: 0.021690; Generator: 0.010804,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:45,559 root         INFO     Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 0.224124\n",
      "Reconstruction: 0.187229, Regularization: 0.004432, Discriminator: 0.021651; Generator: 0.010812,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 21:38:45,644 root         INFO     Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 0.187513\n",
      "Reconstruction: 0.151621, Regularization: 0.003443, Discriminator: 0.021637; Generator: 0.010812,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 21:38:45,729 root         INFO     Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 0.206672\n",
      "Reconstruction: 0.170113, Regularization: 0.004065, Discriminator: 0.021671; Generator: 0.010823,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:45,812 root         INFO     ====> Epoch: 112 Average loss: 0.1925\n",
      "2019-04-09 21:38:45,837 root         INFO     Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 0.178743\n",
      "Reconstruction: 0.143040, Regularization: 0.003224, Discriminator: 0.021667; Generator: 0.010812,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:45,925 root         INFO     Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 0.142204\n",
      "Reconstruction: 0.107453, Regularization: 0.002253, Discriminator: 0.021675; Generator: 0.010823,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:46,016 root         INFO     Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 0.169381\n",
      "Reconstruction: 0.134316, Regularization: 0.002568, Discriminator: 0.021687; Generator: 0.010810,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:46,103 root         INFO     Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 0.187760\n",
      "Reconstruction: 0.152421, Regularization: 0.002851, Discriminator: 0.021675; Generator: 0.010813,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:46,192 root         INFO     Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 0.198997\n",
      "Reconstruction: 0.163092, Regularization: 0.003417, Discriminator: 0.021680; Generator: 0.010809,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:46,280 root         INFO     Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 0.232127\n",
      "Reconstruction: 0.194706, Regularization: 0.004945, Discriminator: 0.021657; Generator: 0.010818,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:46,368 root         INFO     Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 0.136861\n",
      "Reconstruction: 0.102490, Regularization: 0.001885, Discriminator: 0.021671; Generator: 0.010815,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:46,456 root         INFO     Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 0.166901\n",
      "Reconstruction: 0.131524, Regularization: 0.002918, Discriminator: 0.021646; Generator: 0.010813,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 21:38:46,540 root         INFO     ====> Epoch: 113 Average loss: 0.1920\n",
      "2019-04-09 21:38:46,566 root         INFO     Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 0.198567\n",
      "Reconstruction: 0.162461, Regularization: 0.003616, Discriminator: 0.021677; Generator: 0.010814,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:46,657 root         INFO     Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 0.171921\n",
      "Reconstruction: 0.136440, Regularization: 0.002996, Discriminator: 0.021671; Generator: 0.010815,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:46,746 root         INFO     Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 0.168984\n",
      "Reconstruction: 0.133944, Regularization: 0.002537, Discriminator: 0.021686; Generator: 0.010817,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:46,835 root         INFO     Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 0.209964\n",
      "Reconstruction: 0.173582, Regularization: 0.003890, Discriminator: 0.021671; Generator: 0.010821,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:46,923 root         INFO     Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 0.215910\n",
      "Reconstruction: 0.179494, Regularization: 0.003927, Discriminator: 0.021667; Generator: 0.010822,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:47,011 root         INFO     Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 0.179953\n",
      "Reconstruction: 0.144298, Regularization: 0.003155, Discriminator: 0.021673; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:47,100 root         INFO     Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 0.182334\n",
      "Reconstruction: 0.146528, Regularization: 0.003314, Discriminator: 0.021664; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:47,188 root         INFO     Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 0.176424\n",
      "Reconstruction: 0.141052, Regularization: 0.002875, Discriminator: 0.021673; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:47,272 root         INFO     ====> Epoch: 114 Average loss: 0.1914\n",
      "2019-04-09 21:38:47,298 root         INFO     Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 0.206397\n",
      "Reconstruction: 0.169612, Regularization: 0.004303, Discriminator: 0.021662; Generator: 0.010821,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:47,386 root         INFO     Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 0.171681\n",
      "Reconstruction: 0.136147, Regularization: 0.003043, Discriminator: 0.021672; Generator: 0.010819,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:47,473 root         INFO     Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 0.164693\n",
      "Reconstruction: 0.129184, Regularization: 0.003019, Discriminator: 0.021665; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:47,563 root         INFO     Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 0.212457\n",
      "Reconstruction: 0.176167, Regularization: 0.003802, Discriminator: 0.021664; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:47,655 root         INFO     Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 0.185795\n",
      "Reconstruction: 0.150079, Regularization: 0.003228, Discriminator: 0.021661; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:47,745 root         INFO     Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 0.205330\n",
      "Reconstruction: 0.168558, Regularization: 0.004281, Discriminator: 0.021663; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:47,835 root         INFO     Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 0.227672\n",
      "Reconstruction: 0.190511, Regularization: 0.004662, Discriminator: 0.021667; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:47,926 root         INFO     Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 0.190118\n",
      "Reconstruction: 0.154154, Regularization: 0.003470, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:48,013 root         INFO     ====> Epoch: 115 Average loss: 0.1915\n",
      "2019-04-09 21:38:48,038 root         INFO     Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 0.161241\n",
      "Reconstruction: 0.125963, Regularization: 0.002795, Discriminator: 0.021651; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:48,129 root         INFO     Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 0.215666\n",
      "Reconstruction: 0.179096, Regularization: 0.004083, Discriminator: 0.021658; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:48,219 root         INFO     Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 0.220821\n",
      "Reconstruction: 0.184375, Regularization: 0.003966, Discriminator: 0.021648; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:48,309 root         INFO     Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 0.214132\n",
      "Reconstruction: 0.177862, Regularization: 0.003779, Discriminator: 0.021659; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:48,399 root         INFO     Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 0.207752\n",
      "Reconstruction: 0.171538, Regularization: 0.003731, Discriminator: 0.021648; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:48,488 root         INFO     Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 0.200655\n",
      "Reconstruction: 0.164659, Regularization: 0.003515, Discriminator: 0.021654; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:48,578 root         INFO     Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 0.205614\n",
      "Reconstruction: 0.169788, Regularization: 0.003360, Discriminator: 0.021645; Generator: 0.010821,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:48,668 root         INFO     Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 0.242933\n",
      "Reconstruction: 0.205758, Regularization: 0.004698, Discriminator: 0.021647; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:48,754 root         INFO     ====> Epoch: 116 Average loss: 0.1916\n",
      "2019-04-09 21:38:48,779 root         INFO     Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 0.179822\n",
      "Reconstruction: 0.143888, Regularization: 0.003419, Discriminator: 0.021682; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:48,870 root         INFO     Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 0.205865\n",
      "Reconstruction: 0.169445, Regularization: 0.003930, Discriminator: 0.021654; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:48,961 root         INFO     Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 0.231339\n",
      "Reconstruction: 0.194148, Regularization: 0.004715, Discriminator: 0.021650; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:49,053 root         INFO     Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 0.204107\n",
      "Reconstruction: 0.167996, Regularization: 0.003651, Discriminator: 0.021642; Generator: 0.010817,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:49,144 root         INFO     Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 0.154095\n",
      "Reconstruction: 0.118833, Regularization: 0.002762, Discriminator: 0.021670; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:49,235 root         INFO     Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 0.170223\n",
      "Reconstruction: 0.135198, Regularization: 0.002545, Discriminator: 0.021641; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:49,327 root         INFO     Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 0.232679\n",
      "Reconstruction: 0.195994, Regularization: 0.004244, Discriminator: 0.021615; Generator: 0.010826,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 21:38:49,418 root         INFO     Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 0.169856\n",
      "Reconstruction: 0.134503, Regularization: 0.002870, Discriminator: 0.021649; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:49,504 root         INFO     ====> Epoch: 117 Average loss: 0.1922\n",
      "2019-04-09 21:38:49,530 root         INFO     Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 0.213621\n",
      "Reconstruction: 0.177630, Regularization: 0.003543, Discriminator: 0.021617; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:49,619 root         INFO     Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 0.228507\n",
      "Reconstruction: 0.191722, Regularization: 0.004285, Discriminator: 0.021671; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:49,707 root         INFO     Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 0.196540\n",
      "Reconstruction: 0.159770, Regularization: 0.004245, Discriminator: 0.021692; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:49,794 root         INFO     Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 0.229499\n",
      "Reconstruction: 0.192842, Regularization: 0.004188, Discriminator: 0.021641; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:49,882 root         INFO     Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 0.216161\n",
      "Reconstruction: 0.180202, Regularization: 0.003488, Discriminator: 0.021643; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:49,971 root         INFO     Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 0.197698\n",
      "Reconstruction: 0.161728, Regularization: 0.003476, Discriminator: 0.021685; Generator: 0.010809,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:50,060 root         INFO     Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 0.197443\n",
      "Reconstruction: 0.161571, Regularization: 0.003442, Discriminator: 0.021601; Generator: 0.010829,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 21:38:50,149 root         INFO     Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 0.204075\n",
      "Reconstruction: 0.168104, Regularization: 0.003489, Discriminator: 0.021671; Generator: 0.010812,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 21:38:50,234 root         INFO     ====> Epoch: 118 Average loss: 0.1927\n",
      "2019-04-09 21:38:50,260 root         INFO     Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 0.213980\n",
      "Reconstruction: 0.177069, Regularization: 0.004363, Discriminator: 0.021718; Generator: 0.010830,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:50,350 root         INFO     Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 0.156104\n",
      "Reconstruction: 0.121306, Regularization: 0.002293, Discriminator: 0.021687; Generator: 0.010819,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:50,440 root         INFO     Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 0.191765\n",
      "Reconstruction: 0.156286, Regularization: 0.002994, Discriminator: 0.021651; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:50,528 root         INFO     Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 0.181540\n",
      "Reconstruction: 0.146084, Regularization: 0.002938, Discriminator: 0.021699; Generator: 0.010819,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:50,617 root         INFO     Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 0.191851\n",
      "Reconstruction: 0.156084, Regularization: 0.003286, Discriminator: 0.021655; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:50,706 root         INFO     Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 0.211496\n",
      "Reconstruction: 0.175197, Regularization: 0.003795, Discriminator: 0.021684; Generator: 0.010820,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:50,795 root         INFO     Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 0.167007\n",
      "Reconstruction: 0.132030, Regularization: 0.002503, Discriminator: 0.021654; Generator: 0.010819,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:50,884 root         INFO     Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 0.207691\n",
      "Reconstruction: 0.171589, Regularization: 0.003621, Discriminator: 0.021648; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:50,968 root         INFO     ====> Epoch: 119 Average loss: 0.1936\n",
      "2019-04-09 21:38:50,995 root         INFO     Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 0.233907\n",
      "Reconstruction: 0.196999, Regularization: 0.004394, Discriminator: 0.021686; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:51,084 root         INFO     Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 0.190578\n",
      "Reconstruction: 0.155024, Regularization: 0.003034, Discriminator: 0.021686; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:51,173 root         INFO     Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 0.175340\n",
      "Reconstruction: 0.140228, Regularization: 0.002631, Discriminator: 0.021656; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:51,261 root         INFO     Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 0.182122\n",
      "Reconstruction: 0.146557, Regularization: 0.003090, Discriminator: 0.021654; Generator: 0.010821,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:51,349 root         INFO     Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 0.208627\n",
      "Reconstruction: 0.172705, Regularization: 0.003412, Discriminator: 0.021695; Generator: 0.010815,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 21:38:51,438 root         INFO     Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 0.200016\n",
      "Reconstruction: 0.163947, Regularization: 0.003600, Discriminator: 0.021640; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:51,526 root         INFO     Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 0.214821\n",
      "Reconstruction: 0.178714, Regularization: 0.003600, Discriminator: 0.021677; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:51,615 root         INFO     Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 0.210067\n",
      "Reconstruction: 0.173907, Regularization: 0.003665, Discriminator: 0.021665; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:51,701 root         INFO     ====> Epoch: 120 Average loss: 0.1942\n",
      "2019-04-09 21:38:51,726 root         INFO     Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 0.155484\n",
      "Reconstruction: 0.120666, Regularization: 0.002301, Discriminator: 0.021691; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:51,811 root         INFO     Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 0.180371\n",
      "Reconstruction: 0.144685, Regularization: 0.003185, Discriminator: 0.021670; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:51,898 root         INFO     Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 0.171983\n",
      "Reconstruction: 0.136525, Regularization: 0.002950, Discriminator: 0.021680; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:51,985 root         INFO     Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 0.162944\n",
      "Reconstruction: 0.127957, Regularization: 0.002489, Discriminator: 0.021666; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:52,072 root         INFO     Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 0.186524\n",
      "Reconstruction: 0.151098, Regularization: 0.002948, Discriminator: 0.021646; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:52,160 root         INFO     Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 0.196115\n",
      "Reconstruction: 0.160353, Regularization: 0.003286, Discriminator: 0.021651; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:52,248 root         INFO     Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 0.251646\n",
      "Reconstruction: 0.214661, Regularization: 0.004498, Discriminator: 0.021659; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:52,336 root         INFO     Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 0.235539\n",
      "Reconstruction: 0.198529, Regularization: 0.004504, Discriminator: 0.021675; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:52,419 root         INFO     ====> Epoch: 121 Average loss: 0.1948\n",
      "2019-04-09 21:38:52,446 root         INFO     Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 0.213836\n",
      "Reconstruction: 0.177786, Regularization: 0.003546, Discriminator: 0.021672; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:52,534 root         INFO     Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 0.192543\n",
      "Reconstruction: 0.157064, Regularization: 0.002994, Discriminator: 0.021651; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:52,623 root         INFO     Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 0.180717\n",
      "Reconstruction: 0.145328, Regularization: 0.002882, Discriminator: 0.021677; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:52,710 root         INFO     Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 0.164551\n",
      "Reconstruction: 0.129632, Regularization: 0.002417, Discriminator: 0.021667; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:52,798 root         INFO     Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 0.193622\n",
      "Reconstruction: 0.157947, Regularization: 0.003211, Discriminator: 0.021628; Generator: 0.010836,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:52,885 root         INFO     Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 0.194362\n",
      "Reconstruction: 0.158654, Regularization: 0.003194, Discriminator: 0.021677; Generator: 0.010837,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:52,972 root         INFO     Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 0.190380\n",
      "Reconstruction: 0.155038, Regularization: 0.002848, Discriminator: 0.021657; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:53,059 root         INFO     Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 0.178711\n",
      "Reconstruction: 0.143359, Regularization: 0.002854, Discriminator: 0.021661; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:53,143 root         INFO     ====> Epoch: 122 Average loss: 0.1944\n",
      "2019-04-09 21:38:53,170 root         INFO     Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 0.199789\n",
      "Reconstruction: 0.163723, Regularization: 0.003595, Discriminator: 0.021636; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:53,260 root         INFO     Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 0.202720\n",
      "Reconstruction: 0.166553, Regularization: 0.003694, Discriminator: 0.021637; Generator: 0.010835,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:53,350 root         INFO     Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 0.187830\n",
      "Reconstruction: 0.152343, Regularization: 0.003006, Discriminator: 0.021649; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:53,439 root         INFO     Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 0.210026\n",
      "Reconstruction: 0.173679, Regularization: 0.003899, Discriminator: 0.021616; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:53,528 root         INFO     Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 0.226845\n",
      "Reconstruction: 0.190413, Regularization: 0.003922, Discriminator: 0.021669; Generator: 0.010841,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:53,617 root         INFO     Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 0.155229\n",
      "Reconstruction: 0.120375, Regularization: 0.002358, Discriminator: 0.021660; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:53,707 root         INFO     Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 0.170525\n",
      "Reconstruction: 0.135214, Regularization: 0.002823, Discriminator: 0.021652; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:53,796 root         INFO     Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 0.169126\n",
      "Reconstruction: 0.133686, Regularization: 0.002965, Discriminator: 0.021638; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:53,882 root         INFO     ====> Epoch: 123 Average loss: 0.1939\n",
      "2019-04-09 21:38:53,908 root         INFO     Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 0.165453\n",
      "Reconstruction: 0.129976, Regularization: 0.003001, Discriminator: 0.021646; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:53,998 root         INFO     Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 0.178719\n",
      "Reconstruction: 0.142990, Regularization: 0.003251, Discriminator: 0.021637; Generator: 0.010840,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:54,089 root         INFO     Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 0.230845\n",
      "Reconstruction: 0.193926, Regularization: 0.004385, Discriminator: 0.021704; Generator: 0.010830,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:54,180 root         INFO     Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 0.250848\n",
      "Reconstruction: 0.213410, Regularization: 0.004914, Discriminator: 0.021681; Generator: 0.010843,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:54,268 root         INFO     Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 0.238130\n",
      "Reconstruction: 0.201005, Regularization: 0.004671, Discriminator: 0.021614; Generator: 0.010840,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:54,353 root         INFO     Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 0.199324\n",
      "Reconstruction: 0.163659, Regularization: 0.003187, Discriminator: 0.021648; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:54,440 root         INFO     Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 0.205460\n",
      "Reconstruction: 0.168967, Regularization: 0.004044, Discriminator: 0.021623; Generator: 0.010827,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:54,526 root         INFO     Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 0.206108\n",
      "Reconstruction: 0.169957, Regularization: 0.003679, Discriminator: 0.021643; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:54,609 root         INFO     ====> Epoch: 124 Average loss: 0.1929\n",
      "2019-04-09 21:38:54,635 root         INFO     Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 0.169927\n",
      "Reconstruction: 0.134332, Regularization: 0.003132, Discriminator: 0.021640; Generator: 0.010823,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:54,726 root         INFO     Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 0.223768\n",
      "Reconstruction: 0.187058, Regularization: 0.004226, Discriminator: 0.021657; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:54,816 root         INFO     Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 0.179882\n",
      "Reconstruction: 0.144150, Regularization: 0.003242, Discriminator: 0.021666; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:54,907 root         INFO     Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 0.203350\n",
      "Reconstruction: 0.167255, Regularization: 0.003614, Discriminator: 0.021655; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:54,996 root         INFO     Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 0.182480\n",
      "Reconstruction: 0.147102, Regularization: 0.002906, Discriminator: 0.021648; Generator: 0.010824,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:55,086 root         INFO     Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 0.156762\n",
      "Reconstruction: 0.121935, Regularization: 0.002287, Discriminator: 0.021716; Generator: 0.010824,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 21:38:55,176 root         INFO     Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 0.191357\n",
      "Reconstruction: 0.155282, Regularization: 0.003586, Discriminator: 0.021660; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:55,266 root         INFO     Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 0.192944\n",
      "Reconstruction: 0.157055, Regularization: 0.003392, Discriminator: 0.021672; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:55,352 root         INFO     ====> Epoch: 125 Average loss: 0.1924\n",
      "2019-04-09 21:38:55,377 root         INFO     Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 0.193266\n",
      "Reconstruction: 0.157285, Regularization: 0.003509, Discriminator: 0.021643; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:55,469 root         INFO     Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 0.183623\n",
      "Reconstruction: 0.147713, Regularization: 0.003391, Discriminator: 0.021693; Generator: 0.010826,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:55,560 root         INFO     Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 0.178122\n",
      "Reconstruction: 0.142564, Regularization: 0.003044, Discriminator: 0.021686; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:55,651 root         INFO     Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 0.229489\n",
      "Reconstruction: 0.192396, Regularization: 0.004616, Discriminator: 0.021652; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:55,742 root         INFO     Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 0.203698\n",
      "Reconstruction: 0.167507, Regularization: 0.003706, Discriminator: 0.021658; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:55,834 root         INFO     Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 0.191762\n",
      "Reconstruction: 0.155881, Regularization: 0.003381, Discriminator: 0.021671; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:55,925 root         INFO     Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 0.161386\n",
      "Reconstruction: 0.126317, Regularization: 0.002588, Discriminator: 0.021652; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:56,016 root         INFO     Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 0.166316\n",
      "Reconstruction: 0.130777, Regularization: 0.003052, Discriminator: 0.021658; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:56,102 root         INFO     ====> Epoch: 126 Average loss: 0.1920\n",
      "2019-04-09 21:38:56,128 root         INFO     Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 0.203645\n",
      "Reconstruction: 0.167474, Regularization: 0.003661, Discriminator: 0.021677; Generator: 0.010833,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:56,219 root         INFO     Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 0.198374\n",
      "Reconstruction: 0.161922, Regularization: 0.003969, Discriminator: 0.021653; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:56,310 root         INFO     Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 0.223169\n",
      "Reconstruction: 0.186352, Regularization: 0.004340, Discriminator: 0.021645; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:56,400 root         INFO     Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 0.180169\n",
      "Reconstruction: 0.144490, Regularization: 0.003181, Discriminator: 0.021667; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:56,490 root         INFO     Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 0.204422\n",
      "Reconstruction: 0.168316, Regularization: 0.003604, Discriminator: 0.021670; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:56,581 root         INFO     Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 0.175325\n",
      "Reconstruction: 0.139707, Regularization: 0.003122, Discriminator: 0.021662; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:56,670 root         INFO     Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 0.201635\n",
      "Reconstruction: 0.165469, Regularization: 0.003689, Discriminator: 0.021643; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:56,759 root         INFO     Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 0.177001\n",
      "Reconstruction: 0.141553, Regularization: 0.002958, Discriminator: 0.021655; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:56,844 root         INFO     ====> Epoch: 127 Average loss: 0.1919\n",
      "2019-04-09 21:38:56,871 root         INFO     Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 0.187333\n",
      "Reconstruction: 0.151328, Regularization: 0.003527, Discriminator: 0.021646; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:56,961 root         INFO     Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 0.188426\n",
      "Reconstruction: 0.152364, Regularization: 0.003582, Discriminator: 0.021652; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:57,051 root         INFO     Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 0.187108\n",
      "Reconstruction: 0.150844, Regularization: 0.003773, Discriminator: 0.021659; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:57,143 root         INFO     Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 0.153936\n",
      "Reconstruction: 0.118762, Regularization: 0.002656, Discriminator: 0.021687; Generator: 0.010831,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:57,232 root         INFO     Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 0.204062\n",
      "Reconstruction: 0.167611, Regularization: 0.003984, Discriminator: 0.021635; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:57,321 root         INFO     Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 0.185133\n",
      "Reconstruction: 0.149082, Regularization: 0.003569, Discriminator: 0.021651; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:57,409 root         INFO     Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 0.193822\n",
      "Reconstruction: 0.157847, Regularization: 0.003493, Discriminator: 0.021644; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:57,497 root         INFO     Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 0.165857\n",
      "Reconstruction: 0.130701, Regularization: 0.002678, Discriminator: 0.021647; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:57,581 root         INFO     ====> Epoch: 128 Average loss: 0.1923\n",
      "2019-04-09 21:38:57,606 root         INFO     Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 0.177333\n",
      "Reconstruction: 0.141251, Regularization: 0.003585, Discriminator: 0.021671; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:57,697 root         INFO     Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 0.184710\n",
      "Reconstruction: 0.149080, Regularization: 0.003153, Discriminator: 0.021646; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:57,786 root         INFO     Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 0.193065\n",
      "Reconstruction: 0.157070, Regularization: 0.003525, Discriminator: 0.021636; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:57,875 root         INFO     Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 0.181678\n",
      "Reconstruction: 0.145847, Regularization: 0.003337, Discriminator: 0.021667; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:57,965 root         INFO     Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 0.186834\n",
      "Reconstruction: 0.150814, Regularization: 0.003550, Discriminator: 0.021637; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:38:58,055 root         INFO     Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 0.229531\n",
      "Reconstruction: 0.192434, Regularization: 0.004615, Discriminator: 0.021647; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:58,144 root         INFO     Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 0.177501\n",
      "Reconstruction: 0.141052, Regularization: 0.003912, Discriminator: 0.021697; Generator: 0.010840,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:58,234 root         INFO     Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 0.173021\n",
      "Reconstruction: 0.137701, Regularization: 0.002835, Discriminator: 0.021653; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:58,319 root         INFO     ====> Epoch: 129 Average loss: 0.1931\n",
      "2019-04-09 21:38:58,345 root         INFO     Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 0.200133\n",
      "Reconstruction: 0.163892, Regularization: 0.003740, Discriminator: 0.021679; Generator: 0.010822,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:58,435 root         INFO     Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 0.178999\n",
      "Reconstruction: 0.143194, Regularization: 0.003293, Discriminator: 0.021684; Generator: 0.010828,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:38:58,524 root         INFO     Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 0.176319\n",
      "Reconstruction: 0.140898, Regularization: 0.002928, Discriminator: 0.021656; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:58,613 root         INFO     Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 0.224454\n",
      "Reconstruction: 0.187667, Regularization: 0.004302, Discriminator: 0.021653; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:58,702 root         INFO     Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 0.235094\n",
      "Reconstruction: 0.197664, Regularization: 0.004934, Discriminator: 0.021664; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:58,792 root         INFO     Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 0.189262\n",
      "Reconstruction: 0.153146, Regularization: 0.003625, Discriminator: 0.021661; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:58,881 root         INFO     Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 0.183554\n",
      "Reconstruction: 0.147372, Regularization: 0.003687, Discriminator: 0.021661; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:58,971 root         INFO     Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 0.180919\n",
      "Reconstruction: 0.145415, Regularization: 0.003007, Discriminator: 0.021666; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:59,056 root         INFO     ====> Epoch: 130 Average loss: 0.1937\n",
      "2019-04-09 21:38:59,082 root         INFO     Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 0.183448\n",
      "Reconstruction: 0.147476, Regularization: 0.003466, Discriminator: 0.021675; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:59,172 root         INFO     Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 0.202745\n",
      "Reconstruction: 0.166638, Regularization: 0.003619, Discriminator: 0.021657; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:59,261 root         INFO     Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 0.191589\n",
      "Reconstruction: 0.155814, Regularization: 0.003284, Discriminator: 0.021659; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:59,351 root         INFO     Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 0.212341\n",
      "Reconstruction: 0.175368, Regularization: 0.004470, Discriminator: 0.021669; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:59,442 root         INFO     Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 0.259185\n",
      "Reconstruction: 0.221360, Regularization: 0.005328, Discriminator: 0.021664; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:59,531 root         INFO     Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 0.197512\n",
      "Reconstruction: 0.161357, Regularization: 0.003663, Discriminator: 0.021663; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:59,618 root         INFO     Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 0.154565\n",
      "Reconstruction: 0.119581, Regularization: 0.002490, Discriminator: 0.021659; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:59,706 root         INFO     Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 0.188576\n",
      "Reconstruction: 0.152334, Regularization: 0.003760, Discriminator: 0.021651; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:59,792 root         INFO     ====> Epoch: 131 Average loss: 0.1941\n",
      "2019-04-09 21:38:59,817 root         INFO     Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 0.171369\n",
      "Reconstruction: 0.135852, Regularization: 0.003020, Discriminator: 0.021666; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:38:59,910 root         INFO     Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 0.178465\n",
      "Reconstruction: 0.142700, Regularization: 0.003273, Discriminator: 0.021658; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:00,000 root         INFO     Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 0.225911\n",
      "Reconstruction: 0.188846, Regularization: 0.004581, Discriminator: 0.021652; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:00,089 root         INFO     Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 0.163545\n",
      "Reconstruction: 0.128167, Regularization: 0.002889, Discriminator: 0.021655; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:00,179 root         INFO     Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 0.194765\n",
      "Reconstruction: 0.158587, Regularization: 0.003685, Discriminator: 0.021660; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:00,270 root         INFO     Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 0.219951\n",
      "Reconstruction: 0.182762, Regularization: 0.004699, Discriminator: 0.021653; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:00,361 root         INFO     Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 0.151980\n",
      "Reconstruction: 0.116938, Regularization: 0.002562, Discriminator: 0.021645; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:00,452 root         INFO     Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 0.195147\n",
      "Reconstruction: 0.158303, Regularization: 0.004373, Discriminator: 0.021638; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:39:00,539 root         INFO     ====> Epoch: 132 Average loss: 0.1939\n",
      "2019-04-09 21:39:00,565 root         INFO     Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 0.180931\n",
      "Reconstruction: 0.145247, Regularization: 0.003179, Discriminator: 0.021669; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:00,656 root         INFO     Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 0.167953\n",
      "Reconstruction: 0.132494, Regularization: 0.002963, Discriminator: 0.021664; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:00,746 root         INFO     Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 0.156671\n",
      "Reconstruction: 0.121746, Regularization: 0.002410, Discriminator: 0.021675; Generator: 0.010839,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:39:00,835 root         INFO     Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 0.228842\n",
      "Reconstruction: 0.191941, Regularization: 0.004396, Discriminator: 0.021664; Generator: 0.010842,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:00,924 root         INFO     Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 0.182432\n",
      "Reconstruction: 0.146706, Regularization: 0.003224, Discriminator: 0.021669; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:01,013 root         INFO     Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 0.194423\n",
      "Reconstruction: 0.158258, Regularization: 0.003694, Discriminator: 0.021643; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:39:01,102 root         INFO     Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 0.188827\n",
      "Reconstruction: 0.152598, Regularization: 0.003742, Discriminator: 0.021653; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:01,192 root         INFO     Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 0.173487\n",
      "Reconstruction: 0.138078, Regularization: 0.002905, Discriminator: 0.021672; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:01,277 root         INFO     ====> Epoch: 133 Average loss: 0.1933\n",
      "2019-04-09 21:39:01,302 root         INFO     Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 0.190704\n",
      "Reconstruction: 0.154588, Regularization: 0.003636, Discriminator: 0.021645; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:01,392 root         INFO     Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 0.202719\n",
      "Reconstruction: 0.166026, Regularization: 0.004204, Discriminator: 0.021653; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:01,483 root         INFO     Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 0.197986\n",
      "Reconstruction: 0.161681, Regularization: 0.003799, Discriminator: 0.021678; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:01,573 root         INFO     Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 0.183581\n",
      "Reconstruction: 0.147414, Regularization: 0.003681, Discriminator: 0.021655; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:01,664 root         INFO     Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 0.190087\n",
      "Reconstruction: 0.153956, Regularization: 0.003647, Discriminator: 0.021657; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:01,754 root         INFO     Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 0.199918\n",
      "Reconstruction: 0.163182, Regularization: 0.004274, Discriminator: 0.021628; Generator: 0.010834,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:39:01,845 root         INFO     Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 0.155209\n",
      "Reconstruction: 0.119951, Regularization: 0.002778, Discriminator: 0.021652; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:01,937 root         INFO     Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 0.188373\n",
      "Reconstruction: 0.152436, Regularization: 0.003459, Discriminator: 0.021653; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:02,025 root         INFO     ====> Epoch: 134 Average loss: 0.1925\n",
      "2019-04-09 21:39:02,050 root         INFO     Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 0.160929\n",
      "Reconstruction: 0.125615, Regularization: 0.002818, Discriminator: 0.021668; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:02,142 root         INFO     Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 0.150076\n",
      "Reconstruction: 0.114833, Regularization: 0.002759, Discriminator: 0.021660; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:02,233 root         INFO     Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 0.186163\n",
      "Reconstruction: 0.150217, Regularization: 0.003457, Discriminator: 0.021662; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:02,323 root         INFO     Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 0.221348\n",
      "Reconstruction: 0.184512, Regularization: 0.004340, Discriminator: 0.021669; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:02,414 root         INFO     Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 0.147280\n",
      "Reconstruction: 0.112151, Regularization: 0.002636, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:02,505 root         INFO     Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 0.202927\n",
      "Reconstruction: 0.166313, Regularization: 0.004112, Discriminator: 0.021669; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:02,597 root         INFO     Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 0.200334\n",
      "Reconstruction: 0.164160, Regularization: 0.003682, Discriminator: 0.021658; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:02,689 root         INFO     Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 0.202864\n",
      "Reconstruction: 0.166897, Regularization: 0.003478, Discriminator: 0.021660; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:02,776 root         INFO     ====> Epoch: 135 Average loss: 0.1921\n",
      "2019-04-09 21:39:02,802 root         INFO     Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 0.184412\n",
      "Reconstruction: 0.148458, Regularization: 0.003460, Discriminator: 0.021660; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:02,893 root         INFO     Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 0.202908\n",
      "Reconstruction: 0.165763, Regularization: 0.004658, Discriminator: 0.021657; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:02,985 root         INFO     Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 0.189646\n",
      "Reconstruction: 0.153537, Regularization: 0.003615, Discriminator: 0.021659; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:03,077 root         INFO     Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 0.178027\n",
      "Reconstruction: 0.142300, Regularization: 0.003234, Discriminator: 0.021665; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:03,167 root         INFO     Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 0.228838\n",
      "Reconstruction: 0.191309, Regularization: 0.005036, Discriminator: 0.021662; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:03,256 root         INFO     Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 0.216429\n",
      "Reconstruction: 0.180003, Regularization: 0.003944, Discriminator: 0.021648; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:03,346 root         INFO     Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 0.201628\n",
      "Reconstruction: 0.165704, Regularization: 0.003450, Discriminator: 0.021637; Generator: 0.010837,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:39:03,436 root         INFO     Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 0.213403\n",
      "Reconstruction: 0.176418, Regularization: 0.004496, Discriminator: 0.021648; Generator: 0.010841,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:03,521 root         INFO     ====> Epoch: 136 Average loss: 0.1920\n",
      "2019-04-09 21:39:03,547 root         INFO     Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 0.213578\n",
      "Reconstruction: 0.177051, Regularization: 0.004051, Discriminator: 0.021649; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:03,638 root         INFO     Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 0.178746\n",
      "Reconstruction: 0.142729, Regularization: 0.003525, Discriminator: 0.021658; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:03,731 root         INFO     Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 0.163282\n",
      "Reconstruction: 0.127764, Regularization: 0.003022, Discriminator: 0.021662; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:03,822 root         INFO     Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 0.204160\n",
      "Reconstruction: 0.167745, Regularization: 0.003903, Discriminator: 0.021681; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:39:03,912 root         INFO     Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 0.249881\n",
      "Reconstruction: 0.212040, Regularization: 0.005375, Discriminator: 0.021640; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:39:04,002 root         INFO     Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 0.182878\n",
      "Reconstruction: 0.147021, Regularization: 0.003387, Discriminator: 0.021637; Generator: 0.010833,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:39:04,093 root         INFO     Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 0.224468\n",
      "Reconstruction: 0.187476, Regularization: 0.004519, Discriminator: 0.021641; Generator: 0.010831,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:39:04,184 root         INFO     Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 0.186219\n",
      "Reconstruction: 0.150383, Regularization: 0.003357, Discriminator: 0.021644; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:04,270 root         INFO     ====> Epoch: 137 Average loss: 0.1926\n",
      "2019-04-09 21:39:04,295 root         INFO     Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 0.198223\n",
      "Reconstruction: 0.161788, Regularization: 0.003940, Discriminator: 0.021665; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:04,387 root         INFO     Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 0.201959\n",
      "Reconstruction: 0.165494, Regularization: 0.003974, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:04,478 root         INFO     Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 0.193230\n",
      "Reconstruction: 0.156917, Regularization: 0.003828, Discriminator: 0.021653; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:04,570 root         INFO     Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 0.165113\n",
      "Reconstruction: 0.129413, Regularization: 0.003173, Discriminator: 0.021699; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:39:04,661 root         INFO     Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 0.151646\n",
      "Reconstruction: 0.116554, Regularization: 0.002602, Discriminator: 0.021660; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:04,752 root         INFO     Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 0.177623\n",
      "Reconstruction: 0.142077, Regularization: 0.003030, Discriminator: 0.021681; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:39:04,844 root         INFO     Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 0.181628\n",
      "Reconstruction: 0.145965, Regularization: 0.003178, Discriminator: 0.021655; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:04,936 root         INFO     Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 0.198499\n",
      "Reconstruction: 0.162087, Regularization: 0.003916, Discriminator: 0.021666; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:05,023 root         INFO     ====> Epoch: 138 Average loss: 0.1933\n",
      "2019-04-09 21:39:05,048 root         INFO     Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 0.179734\n",
      "Reconstruction: 0.143988, Regularization: 0.003259, Discriminator: 0.021650; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:05,137 root         INFO     Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 0.176417\n",
      "Reconstruction: 0.140633, Regularization: 0.003291, Discriminator: 0.021671; Generator: 0.010823,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:05,225 root         INFO     Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 0.176669\n",
      "Reconstruction: 0.140910, Regularization: 0.003263, Discriminator: 0.021667; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:05,313 root         INFO     Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 0.176618\n",
      "Reconstruction: 0.141323, Regularization: 0.002816, Discriminator: 0.021647; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:05,401 root         INFO     Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 0.175259\n",
      "Reconstruction: 0.139707, Regularization: 0.003055, Discriminator: 0.021665; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:05,488 root         INFO     Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 0.198713\n",
      "Reconstruction: 0.162649, Regularization: 0.003573, Discriminator: 0.021658; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:05,578 root         INFO     Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 0.179098\n",
      "Reconstruction: 0.143235, Regularization: 0.003360, Discriminator: 0.021672; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:05,668 root         INFO     Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 0.221534\n",
      "Reconstruction: 0.185109, Regularization: 0.003929, Discriminator: 0.021662; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:05,754 root         INFO     ====> Epoch: 139 Average loss: 0.1939\n",
      "2019-04-09 21:39:05,780 root         INFO     Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 0.192433\n",
      "Reconstruction: 0.156661, Regularization: 0.003281, Discriminator: 0.021659; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:05,869 root         INFO     Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 0.202661\n",
      "Reconstruction: 0.166167, Regularization: 0.004018, Discriminator: 0.021646; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:39:05,956 root         INFO     Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 0.234888\n",
      "Reconstruction: 0.197674, Regularization: 0.004711, Discriminator: 0.021668; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:06,043 root         INFO     Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 0.194065\n",
      "Reconstruction: 0.157972, Regularization: 0.003599, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:06,129 root         INFO     Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 0.218733\n",
      "Reconstruction: 0.182122, Regularization: 0.004133, Discriminator: 0.021645; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:06,215 root         INFO     Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 0.179235\n",
      "Reconstruction: 0.143671, Regularization: 0.003077, Discriminator: 0.021654; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:06,300 root         INFO     Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 0.169049\n",
      "Reconstruction: 0.133472, Regularization: 0.003085, Discriminator: 0.021661; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:06,385 root         INFO     Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 0.216310\n",
      "Reconstruction: 0.179605, Regularization: 0.004229, Discriminator: 0.021645; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:39:06,468 root         INFO     ====> Epoch: 140 Average loss: 0.1939\n",
      "2019-04-09 21:39:06,494 root         INFO     Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 0.174304\n",
      "Reconstruction: 0.138586, Regularization: 0.003254, Discriminator: 0.021634; Generator: 0.010830,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:39:06,579 root         INFO     Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 0.185099\n",
      "Reconstruction: 0.149239, Regularization: 0.003376, Discriminator: 0.021656; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:06,666 root         INFO     Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 0.200710\n",
      "Reconstruction: 0.164834, Regularization: 0.003388, Discriminator: 0.021656; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:06,753 root         INFO     Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 0.173878\n",
      "Reconstruction: 0.138231, Regularization: 0.003153, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:06,843 root         INFO     Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 0.254882\n",
      "Reconstruction: 0.217374, Regularization: 0.005020, Discriminator: 0.021653; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:06,931 root         INFO     Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 0.182781\n",
      "Reconstruction: 0.147269, Regularization: 0.003037, Discriminator: 0.021646; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:39:07,018 root         INFO     Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 0.175622\n",
      "Reconstruction: 0.140055, Regularization: 0.003060, Discriminator: 0.021672; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:07,105 root         INFO     Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 0.207674\n",
      "Reconstruction: 0.171503, Regularization: 0.003664, Discriminator: 0.021678; Generator: 0.010829,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:39:07,187 root         INFO     ====> Epoch: 141 Average loss: 0.1932\n",
      "2019-04-09 21:39:07,212 root         INFO     Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 0.160879\n",
      "Reconstruction: 0.125684, Regularization: 0.002721, Discriminator: 0.021648; Generator: 0.010826,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:39:07,302 root         INFO     Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 0.181022\n",
      "Reconstruction: 0.145451, Regularization: 0.003085, Discriminator: 0.021662; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:07,391 root         INFO     Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 0.158281\n",
      "Reconstruction: 0.122993, Regularization: 0.002803, Discriminator: 0.021648; Generator: 0.010837,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:07,481 root         INFO     Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 0.188961\n",
      "Reconstruction: 0.152836, Regularization: 0.003621, Discriminator: 0.021671; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:07,570 root         INFO     Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 0.193968\n",
      "Reconstruction: 0.157812, Regularization: 0.003679, Discriminator: 0.021650; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:07,660 root         INFO     Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 0.177962\n",
      "Reconstruction: 0.142262, Regularization: 0.003207, Discriminator: 0.021664; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:07,749 root         INFO     Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 0.180569\n",
      "Reconstruction: 0.144691, Regularization: 0.003388, Discriminator: 0.021664; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:07,839 root         INFO     Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 0.240852\n",
      "Reconstruction: 0.203428, Regularization: 0.004945, Discriminator: 0.021654; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:07,924 root         INFO     ====> Epoch: 142 Average loss: 0.1925\n",
      "2019-04-09 21:39:07,950 root         INFO     Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 0.157945\n",
      "Reconstruction: 0.122893, Regularization: 0.002562, Discriminator: 0.021661; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:08,038 root         INFO     Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 0.199373\n",
      "Reconstruction: 0.163133, Regularization: 0.003753, Discriminator: 0.021651; Generator: 0.010836,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:08,126 root         INFO     Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 0.207684\n",
      "Reconstruction: 0.171111, Regularization: 0.004065, Discriminator: 0.021676; Generator: 0.010832,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:39:08,213 root         INFO     Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 0.208424\n",
      "Reconstruction: 0.171805, Regularization: 0.004122, Discriminator: 0.021667; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:08,301 root         INFO     Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 0.161373\n",
      "Reconstruction: 0.126097, Regularization: 0.002785, Discriminator: 0.021664; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:08,389 root         INFO     Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 0.158404\n",
      "Reconstruction: 0.123324, Regularization: 0.002590, Discriminator: 0.021661; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:08,475 root         INFO     Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 0.211843\n",
      "Reconstruction: 0.175018, Regularization: 0.004328, Discriminator: 0.021674; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:08,562 root         INFO     Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 0.222062\n",
      "Reconstruction: 0.185926, Regularization: 0.003663, Discriminator: 0.021645; Generator: 0.010829,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:39:08,645 root         INFO     ====> Epoch: 143 Average loss: 0.1923\n",
      "2019-04-09 21:39:08,671 root         INFO     Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 0.199266\n",
      "Reconstruction: 0.162949, Regularization: 0.003817, Discriminator: 0.021667; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:08,759 root         INFO     Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 0.197237\n",
      "Reconstruction: 0.161160, Regularization: 0.003575, Discriminator: 0.021667; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:08,845 root         INFO     Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 0.160022\n",
      "Reconstruction: 0.124997, Regularization: 0.002524, Discriminator: 0.021672; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:08,937 root         INFO     Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 0.202255\n",
      "Reconstruction: 0.166475, Regularization: 0.003293, Discriminator: 0.021656; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:09,028 root         INFO     Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 0.198865\n",
      "Reconstruction: 0.162912, Regularization: 0.003460, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:09,118 root         INFO     Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 0.169119\n",
      "Reconstruction: 0.133904, Regularization: 0.002724, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:09,207 root         INFO     Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 0.168469\n",
      "Reconstruction: 0.133268, Regularization: 0.002695, Discriminator: 0.021677; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:09,296 root         INFO     Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 0.190214\n",
      "Reconstruction: 0.154496, Regularization: 0.003238, Discriminator: 0.021658; Generator: 0.010822,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:09,382 root         INFO     ====> Epoch: 144 Average loss: 0.1925\n",
      "2019-04-09 21:39:09,408 root         INFO     Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 0.195438\n",
      "Reconstruction: 0.159463, Regularization: 0.003495, Discriminator: 0.021651; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:09,501 root         INFO     Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 0.208985\n",
      "Reconstruction: 0.172565, Regularization: 0.003928, Discriminator: 0.021660; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:09,592 root         INFO     Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 0.190880\n",
      "Reconstruction: 0.155040, Regularization: 0.003361, Discriminator: 0.021649; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:09,681 root         INFO     Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 0.223206\n",
      "Reconstruction: 0.186268, Regularization: 0.004438, Discriminator: 0.021676; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:09,769 root         INFO     Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 0.222838\n",
      "Reconstruction: 0.186188, Regularization: 0.004158, Discriminator: 0.021668; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:09,858 root         INFO     Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 0.198644\n",
      "Reconstruction: 0.162642, Regularization: 0.003510, Discriminator: 0.021667; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:09,946 root         INFO     Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 0.174251\n",
      "Reconstruction: 0.138845, Regularization: 0.002915, Discriminator: 0.021663; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:10,035 root         INFO     Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 0.180316\n",
      "Reconstruction: 0.144967, Regularization: 0.002861, Discriminator: 0.021657; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:10,119 root         INFO     ====> Epoch: 145 Average loss: 0.1932\n",
      "2019-04-09 21:39:10,145 root         INFO     Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 0.150324\n",
      "Reconstruction: 0.115626, Regularization: 0.002215, Discriminator: 0.021656; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:10,236 root         INFO     Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 0.222201\n",
      "Reconstruction: 0.185698, Regularization: 0.004007, Discriminator: 0.021666; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:10,326 root         INFO     Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 0.179674\n",
      "Reconstruction: 0.143909, Regularization: 0.003271, Discriminator: 0.021671; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:10,416 root         INFO     Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 0.187247\n",
      "Reconstruction: 0.151773, Regularization: 0.002986, Discriminator: 0.021659; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:10,506 root         INFO     Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 0.180262\n",
      "Reconstruction: 0.144580, Regularization: 0.003189, Discriminator: 0.021664; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:10,596 root         INFO     Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 0.191637\n",
      "Reconstruction: 0.155899, Regularization: 0.003246, Discriminator: 0.021663; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:10,683 root         INFO     Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 0.242082\n",
      "Reconstruction: 0.204679, Regularization: 0.004912, Discriminator: 0.021664; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:10,770 root         INFO     Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 0.162518\n",
      "Reconstruction: 0.127668, Regularization: 0.002354, Discriminator: 0.021661; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:10,854 root         INFO     ====> Epoch: 146 Average loss: 0.1937\n",
      "2019-04-09 21:39:10,880 root         INFO     Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 0.214838\n",
      "Reconstruction: 0.178461, Regularization: 0.003888, Discriminator: 0.021659; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:10,970 root         INFO     Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 0.189261\n",
      "Reconstruction: 0.153656, Regularization: 0.003113, Discriminator: 0.021660; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:11,060 root         INFO     Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 0.233996\n",
      "Reconstruction: 0.197016, Regularization: 0.004490, Discriminator: 0.021658; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:11,150 root         INFO     Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 0.195943\n",
      "Reconstruction: 0.159366, Regularization: 0.004090, Discriminator: 0.021658; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:11,240 root         INFO     Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 0.154702\n",
      "Reconstruction: 0.119643, Regularization: 0.002572, Discriminator: 0.021654; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:11,330 root         INFO     Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 0.198016\n",
      "Reconstruction: 0.162187, Regularization: 0.003335, Discriminator: 0.021664; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:11,420 root         INFO     Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 0.187157\n",
      "Reconstruction: 0.151216, Regularization: 0.003454, Discriminator: 0.021656; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:11,510 root         INFO     Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 0.137106\n",
      "Reconstruction: 0.102784, Regularization: 0.001834, Discriminator: 0.021657; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:11,596 root         INFO     ====> Epoch: 147 Average loss: 0.1936\n",
      "2019-04-09 21:39:11,622 root         INFO     Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 0.209350\n",
      "Reconstruction: 0.173122, Regularization: 0.003735, Discriminator: 0.021663; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:11,714 root         INFO     Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 0.190618\n",
      "Reconstruction: 0.155079, Regularization: 0.003052, Discriminator: 0.021658; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:11,806 root         INFO     Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 0.184352\n",
      "Reconstruction: 0.148900, Regularization: 0.002934, Discriminator: 0.021683; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:39:11,893 root         INFO     Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 0.238310\n",
      "Reconstruction: 0.201291, Regularization: 0.004533, Discriminator: 0.021652; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:11,977 root         INFO     Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 0.185962\n",
      "Reconstruction: 0.150359, Regularization: 0.003116, Discriminator: 0.021661; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:12,062 root         INFO     Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 0.185725\n",
      "Reconstruction: 0.150399, Regularization: 0.002824, Discriminator: 0.021664; Generator: 0.010838,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:12,148 root         INFO     Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 0.183414\n",
      "Reconstruction: 0.147780, Regularization: 0.003144, Discriminator: 0.021659; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:12,234 root         INFO     Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 0.182177\n",
      "Reconstruction: 0.146557, Regularization: 0.003129, Discriminator: 0.021663; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:12,316 root         INFO     ====> Epoch: 148 Average loss: 0.1931\n",
      "2019-04-09 21:39:12,342 root         INFO     Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 0.197696\n",
      "Reconstruction: 0.161876, Regularization: 0.003344, Discriminator: 0.021653; Generator: 0.010823,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:12,428 root         INFO     Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 0.213390\n",
      "Reconstruction: 0.176865, Regularization: 0.004033, Discriminator: 0.021665; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:12,516 root         INFO     Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 0.174707\n",
      "Reconstruction: 0.139219, Regularization: 0.002998, Discriminator: 0.021660; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:12,603 root         INFO     Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 0.193408\n",
      "Reconstruction: 0.157424, Regularization: 0.003495, Discriminator: 0.021663; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:12,691 root         INFO     Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 0.227542\n",
      "Reconstruction: 0.190645, Regularization: 0.004416, Discriminator: 0.021654; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:12,778 root         INFO     Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 0.190679\n",
      "Reconstruction: 0.154601, Regularization: 0.003594, Discriminator: 0.021654; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:12,866 root         INFO     Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 0.181190\n",
      "Reconstruction: 0.145938, Regularization: 0.002749, Discriminator: 0.021673; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:12,953 root         INFO     Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 0.218375\n",
      "Reconstruction: 0.181628, Regularization: 0.004249, Discriminator: 0.021667; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:13,036 root         INFO     ====> Epoch: 149 Average loss: 0.1923\n",
      "2019-04-09 21:39:13,062 root         INFO     Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 0.146267\n",
      "Reconstruction: 0.111421, Regularization: 0.002355, Discriminator: 0.021660; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:13,151 root         INFO     Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 0.167659\n",
      "Reconstruction: 0.132404, Regularization: 0.002767, Discriminator: 0.021658; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:13,238 root         INFO     Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 0.156797\n",
      "Reconstruction: 0.121809, Regularization: 0.002503, Discriminator: 0.021655; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:13,326 root         INFO     Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 0.151736\n",
      "Reconstruction: 0.116812, Regularization: 0.002441, Discriminator: 0.021654; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:13,413 root         INFO     Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 0.169520\n",
      "Reconstruction: 0.134106, Regularization: 0.002916, Discriminator: 0.021667; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:13,500 root         INFO     Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 0.172054\n",
      "Reconstruction: 0.136556, Regularization: 0.003011, Discriminator: 0.021659; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:13,588 root         INFO     Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 0.181528\n",
      "Reconstruction: 0.145865, Regularization: 0.003171, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:13,676 root         INFO     Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 0.165510\n",
      "Reconstruction: 0.130373, Regularization: 0.002654, Discriminator: 0.021651; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:13,759 root         INFO     ====> Epoch: 150 Average loss: 0.1924\n",
      "2019-04-09 21:39:13,785 root         INFO     Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 0.199472\n",
      "Reconstruction: 0.163253, Regularization: 0.003722, Discriminator: 0.021667; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:13,873 root         INFO     Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 0.223808\n",
      "Reconstruction: 0.187616, Regularization: 0.003712, Discriminator: 0.021647; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:13,963 root         INFO     Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 0.178266\n",
      "Reconstruction: 0.143138, Regularization: 0.002643, Discriminator: 0.021656; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:14,054 root         INFO     Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 0.178821\n",
      "Reconstruction: 0.143111, Regularization: 0.003222, Discriminator: 0.021656; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:14,144 root         INFO     Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 0.221836\n",
      "Reconstruction: 0.185236, Regularization: 0.004099, Discriminator: 0.021672; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:14,234 root         INFO     Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 0.193800\n",
      "Reconstruction: 0.157578, Regularization: 0.003728, Discriminator: 0.021665; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:14,324 root         INFO     Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 0.182014\n",
      "Reconstruction: 0.146680, Regularization: 0.002853, Discriminator: 0.021653; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:14,415 root         INFO     Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 0.186074\n",
      "Reconstruction: 0.150342, Regularization: 0.003233, Discriminator: 0.021665; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:14,502 root         INFO     ====> Epoch: 151 Average loss: 0.1931\n",
      "2019-04-09 21:39:14,527 root         INFO     Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 0.191636\n",
      "Reconstruction: 0.155868, Regularization: 0.003273, Discriminator: 0.021665; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:14,613 root         INFO     Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 0.228134\n",
      "Reconstruction: 0.191131, Regularization: 0.004521, Discriminator: 0.021655; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:14,700 root         INFO     Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 0.160013\n",
      "Reconstruction: 0.124951, Regularization: 0.002574, Discriminator: 0.021658; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:14,786 root         INFO     Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 0.228275\n",
      "Reconstruction: 0.191463, Regularization: 0.004321, Discriminator: 0.021660; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:14,873 root         INFO     Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 0.223777\n",
      "Reconstruction: 0.186673, Regularization: 0.004614, Discriminator: 0.021662; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:14,960 root         INFO     Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 0.168393\n",
      "Reconstruction: 0.133346, Regularization: 0.002554, Discriminator: 0.021662; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:15,046 root         INFO     Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 0.205753\n",
      "Reconstruction: 0.169281, Regularization: 0.003984, Discriminator: 0.021659; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:15,133 root         INFO     Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 0.197378\n",
      "Reconstruction: 0.161446, Regularization: 0.003449, Discriminator: 0.021652; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:15,216 root         INFO     ====> Epoch: 152 Average loss: 0.1936\n",
      "2019-04-09 21:39:15,241 root         INFO     Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 0.188651\n",
      "Reconstruction: 0.152857, Regularization: 0.003296, Discriminator: 0.021667; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:15,331 root         INFO     Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 0.180139\n",
      "Reconstruction: 0.144357, Regularization: 0.003294, Discriminator: 0.021657; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:15,421 root         INFO     Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 0.172899\n",
      "Reconstruction: 0.137337, Regularization: 0.003077, Discriminator: 0.021654; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:15,510 root         INFO     Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 0.216185\n",
      "Reconstruction: 0.179913, Regularization: 0.003775, Discriminator: 0.021664; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:15,600 root         INFO     Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 0.214506\n",
      "Reconstruction: 0.177819, Regularization: 0.004205, Discriminator: 0.021652; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:15,690 root         INFO     Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 0.189470\n",
      "Reconstruction: 0.153514, Regularization: 0.003448, Discriminator: 0.021674; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:39:15,778 root         INFO     Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 0.176865\n",
      "Reconstruction: 0.141391, Regularization: 0.002986, Discriminator: 0.021656; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:15,868 root         INFO     Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 0.186559\n",
      "Reconstruction: 0.150569, Regularization: 0.003496, Discriminator: 0.021660; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:15,953 root         INFO     ====> Epoch: 153 Average loss: 0.1938\n",
      "2019-04-09 21:39:15,979 root         INFO     Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 0.225052\n",
      "Reconstruction: 0.188720, Regularization: 0.003827, Discriminator: 0.021671; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:16,069 root         INFO     Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 0.167521\n",
      "Reconstruction: 0.132312, Regularization: 0.002728, Discriminator: 0.021650; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:16,158 root         INFO     Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 0.225362\n",
      "Reconstruction: 0.188484, Regularization: 0.004381, Discriminator: 0.021663; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:16,248 root         INFO     Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 0.215779\n",
      "Reconstruction: 0.178920, Regularization: 0.004369, Discriminator: 0.021655; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:16,337 root         INFO     Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 0.172315\n",
      "Reconstruction: 0.136913, Regularization: 0.002901, Discriminator: 0.021668; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:16,427 root         INFO     Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 0.208444\n",
      "Reconstruction: 0.171908, Regularization: 0.004059, Discriminator: 0.021649; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:16,516 root         INFO     Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 0.192427\n",
      "Reconstruction: 0.156833, Regularization: 0.003094, Discriminator: 0.021671; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:16,606 root         INFO     Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 0.216866\n",
      "Reconstruction: 0.180124, Regularization: 0.004259, Discriminator: 0.021659; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:16,691 root         INFO     ====> Epoch: 154 Average loss: 0.1931\n",
      "2019-04-09 21:39:16,717 root         INFO     Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 0.208004\n",
      "Reconstruction: 0.171550, Regularization: 0.003960, Discriminator: 0.021666; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:16,807 root         INFO     Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 0.180917\n",
      "Reconstruction: 0.145188, Regularization: 0.003242, Discriminator: 0.021657; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:16,896 root         INFO     Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 0.177260\n",
      "Reconstruction: 0.141485, Regularization: 0.003283, Discriminator: 0.021660; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:16,985 root         INFO     Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 0.145420\n",
      "Reconstruction: 0.110642, Regularization: 0.002294, Discriminator: 0.021655; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:17,077 root         INFO     Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 0.192016\n",
      "Reconstruction: 0.156477, Regularization: 0.003044, Discriminator: 0.021666; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:17,168 root         INFO     Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 0.197036\n",
      "Reconstruction: 0.160599, Regularization: 0.003948, Discriminator: 0.021659; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:17,260 root         INFO     Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 0.195626\n",
      "Reconstruction: 0.159561, Regularization: 0.003573, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:17,351 root         INFO     Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 0.182665\n",
      "Reconstruction: 0.146827, Regularization: 0.003345, Discriminator: 0.021663; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:17,438 root         INFO     ====> Epoch: 155 Average loss: 0.1922\n",
      "2019-04-09 21:39:17,463 root         INFO     Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 0.200819\n",
      "Reconstruction: 0.164526, Regularization: 0.003802, Discriminator: 0.021662; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:17,551 root         INFO     Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 0.188210\n",
      "Reconstruction: 0.152546, Regularization: 0.003170, Discriminator: 0.021664; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:17,640 root         INFO     Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 0.205162\n",
      "Reconstruction: 0.168675, Regularization: 0.003999, Discriminator: 0.021657; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:17,728 root         INFO     Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 0.174348\n",
      "Reconstruction: 0.138951, Regularization: 0.002909, Discriminator: 0.021658; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:17,816 root         INFO     Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 0.158612\n",
      "Reconstruction: 0.123327, Regularization: 0.002792, Discriminator: 0.021662; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:17,905 root         INFO     Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 0.207241\n",
      "Reconstruction: 0.171023, Regularization: 0.003735, Discriminator: 0.021651; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:17,992 root         INFO     Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 0.199991\n",
      "Reconstruction: 0.164215, Regularization: 0.003283, Discriminator: 0.021659; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:18,080 root         INFO     Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 0.208911\n",
      "Reconstruction: 0.172342, Regularization: 0.004078, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:18,164 root         INFO     ====> Epoch: 156 Average loss: 0.1923\n",
      "2019-04-09 21:39:18,190 root         INFO     Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 0.206650\n",
      "Reconstruction: 0.170151, Regularization: 0.003999, Discriminator: 0.021670; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:18,278 root         INFO     Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 0.194223\n",
      "Reconstruction: 0.158120, Regularization: 0.003611, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:18,366 root         INFO     Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 0.191282\n",
      "Reconstruction: 0.155411, Regularization: 0.003368, Discriminator: 0.021672; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:18,454 root         INFO     Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 0.158911\n",
      "Reconstruction: 0.123645, Regularization: 0.002778, Discriminator: 0.021659; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:18,540 root         INFO     Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 0.204352\n",
      "Reconstruction: 0.168259, Regularization: 0.003602, Discriminator: 0.021662; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:18,627 root         INFO     Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 0.165671\n",
      "Reconstruction: 0.130296, Regularization: 0.002886, Discriminator: 0.021659; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:18,717 root         INFO     Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 0.217720\n",
      "Reconstruction: 0.181256, Regularization: 0.003973, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:18,803 root         INFO     Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 0.227590\n",
      "Reconstruction: 0.190571, Regularization: 0.004527, Discriminator: 0.021658; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:18,886 root         INFO     ====> Epoch: 157 Average loss: 0.1933\n",
      "2019-04-09 21:39:18,912 root         INFO     Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 0.162616\n",
      "Reconstruction: 0.127450, Regularization: 0.002669, Discriminator: 0.021666; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:18,997 root         INFO     Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 0.213712\n",
      "Reconstruction: 0.176961, Regularization: 0.004256, Discriminator: 0.021663; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:19,082 root         INFO     Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 0.234136\n",
      "Reconstruction: 0.196636, Regularization: 0.005002, Discriminator: 0.021666; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:19,168 root         INFO     Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 0.167533\n",
      "Reconstruction: 0.132289, Regularization: 0.002754, Discriminator: 0.021658; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:19,253 root         INFO     Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 0.199985\n",
      "Reconstruction: 0.163991, Regularization: 0.003502, Discriminator: 0.021664; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:19,337 root         INFO     Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 0.194332\n",
      "Reconstruction: 0.158259, Regularization: 0.003581, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:19,422 root         INFO     Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 0.184138\n",
      "Reconstruction: 0.148897, Regularization: 0.002748, Discriminator: 0.021661; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:19,508 root         INFO     Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 0.214508\n",
      "Reconstruction: 0.178141, Regularization: 0.003876, Discriminator: 0.021658; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:19,590 root         INFO     ====> Epoch: 158 Average loss: 0.1940\n",
      "2019-04-09 21:39:19,616 root         INFO     Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 0.206082\n",
      "Reconstruction: 0.169456, Regularization: 0.004140, Discriminator: 0.021657; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:19,703 root         INFO     Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 0.202345\n",
      "Reconstruction: 0.166341, Regularization: 0.003508, Discriminator: 0.021662; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:19,789 root         INFO     Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 0.194966\n",
      "Reconstruction: 0.158882, Regularization: 0.003597, Discriminator: 0.021653; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:19,875 root         INFO     Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 0.165889\n",
      "Reconstruction: 0.130713, Regularization: 0.002666, Discriminator: 0.021673; Generator: 0.010836,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:39:19,961 root         INFO     Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 0.177657\n",
      "Reconstruction: 0.141957, Regularization: 0.003208, Discriminator: 0.021660; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:20,047 root         INFO     Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 0.201424\n",
      "Reconstruction: 0.165081, Regularization: 0.003860, Discriminator: 0.021651; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:20,133 root         INFO     Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 0.164271\n",
      "Reconstruction: 0.129020, Regularization: 0.002769, Discriminator: 0.021652; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:20,219 root         INFO     Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 0.196548\n",
      "Reconstruction: 0.160554, Regularization: 0.003490, Discriminator: 0.021673; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:20,302 root         INFO     ====> Epoch: 159 Average loss: 0.1935\n",
      "2019-04-09 21:39:20,328 root         INFO     Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 0.195421\n",
      "Reconstruction: 0.159573, Regularization: 0.003361, Discriminator: 0.021657; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:20,419 root         INFO     Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 0.250527\n",
      "Reconstruction: 0.212600, Regularization: 0.005451, Discriminator: 0.021647; Generator: 0.010828,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:39:20,510 root         INFO     Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 0.207710\n",
      "Reconstruction: 0.171373, Regularization: 0.003843, Discriminator: 0.021665; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:20,601 root         INFO     Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 0.231930\n",
      "Reconstruction: 0.194954, Regularization: 0.004485, Discriminator: 0.021663; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:20,692 root         INFO     Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 0.158164\n",
      "Reconstruction: 0.123126, Regularization: 0.002529, Discriminator: 0.021674; Generator: 0.010834,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:39:20,783 root         INFO     Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 0.167456\n",
      "Reconstruction: 0.131947, Regularization: 0.003017, Discriminator: 0.021666; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:20,875 root         INFO     Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 0.145429\n",
      "Reconstruction: 0.110874, Regularization: 0.002061, Discriminator: 0.021665; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:20,966 root         INFO     Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 0.186937\n",
      "Reconstruction: 0.150824, Regularization: 0.003621, Discriminator: 0.021664; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:21,053 root         INFO     ====> Epoch: 160 Average loss: 0.1926\n",
      "2019-04-09 21:39:21,079 root         INFO     Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 0.203839\n",
      "Reconstruction: 0.167741, Regularization: 0.003613, Discriminator: 0.021657; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:21,169 root         INFO     Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 0.157718\n",
      "Reconstruction: 0.122727, Regularization: 0.002495, Discriminator: 0.021666; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:21,259 root         INFO     Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 0.222036\n",
      "Reconstruction: 0.185043, Regularization: 0.004504, Discriminator: 0.021661; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:21,349 root         INFO     Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 0.169676\n",
      "Reconstruction: 0.134697, Regularization: 0.002490, Discriminator: 0.021657; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:21,440 root         INFO     Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 0.164498\n",
      "Reconstruction: 0.129036, Regularization: 0.002970, Discriminator: 0.021663; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:21,531 root         INFO     Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 0.258391\n",
      "Reconstruction: 0.220746, Regularization: 0.005159, Discriminator: 0.021654; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:21,623 root         INFO     Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 0.172353\n",
      "Reconstruction: 0.136735, Regularization: 0.003124, Discriminator: 0.021662; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:21,713 root         INFO     Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 0.169580\n",
      "Reconstruction: 0.133968, Regularization: 0.003116, Discriminator: 0.021665; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:21,799 root         INFO     ====> Epoch: 161 Average loss: 0.1922\n",
      "2019-04-09 21:39:21,824 root         INFO     Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 0.160923\n",
      "Reconstruction: 0.125666, Regularization: 0.002763, Discriminator: 0.021662; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:21,915 root         INFO     Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 0.182399\n",
      "Reconstruction: 0.146829, Regularization: 0.003093, Discriminator: 0.021646; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:22,003 root         INFO     Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 0.216748\n",
      "Reconstruction: 0.180202, Regularization: 0.004052, Discriminator: 0.021661; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:22,088 root         INFO     Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 0.161911\n",
      "Reconstruction: 0.126659, Regularization: 0.002758, Discriminator: 0.021664; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:22,173 root         INFO     Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 0.209461\n",
      "Reconstruction: 0.172998, Regularization: 0.003961, Discriminator: 0.021671; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:22,257 root         INFO     Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 0.199443\n",
      "Reconstruction: 0.163121, Regularization: 0.003827, Discriminator: 0.021668; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:22,342 root         INFO     Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 0.231348\n",
      "Reconstruction: 0.193845, Regularization: 0.005014, Discriminator: 0.021665; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:22,427 root         INFO     Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 0.177624\n",
      "Reconstruction: 0.142005, Regularization: 0.003124, Discriminator: 0.021660; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:22,508 root         INFO     ====> Epoch: 162 Average loss: 0.1928\n",
      "2019-04-09 21:39:22,534 root         INFO     Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 0.188863\n",
      "Reconstruction: 0.152824, Regularization: 0.003545, Discriminator: 0.021664; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:22,628 root         INFO     Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 0.174605\n",
      "Reconstruction: 0.139313, Regularization: 0.002807, Discriminator: 0.021656; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:22,721 root         INFO     Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 0.196870\n",
      "Reconstruction: 0.160812, Regularization: 0.003570, Discriminator: 0.021662; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:22,814 root         INFO     Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 0.174478\n",
      "Reconstruction: 0.138923, Regularization: 0.003056, Discriminator: 0.021665; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:22,907 root         INFO     Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 0.172743\n",
      "Reconstruction: 0.137308, Regularization: 0.002923, Discriminator: 0.021677; Generator: 0.010835,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 21:39:23,001 root         INFO     Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 0.232115\n",
      "Reconstruction: 0.194981, Regularization: 0.004634, Discriminator: 0.021671; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:23,093 root         INFO     Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 0.210969\n",
      "Reconstruction: 0.174482, Regularization: 0.003995, Discriminator: 0.021659; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:23,183 root         INFO     Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 0.209363\n",
      "Reconstruction: 0.173204, Regularization: 0.003669, Discriminator: 0.021663; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:23,269 root         INFO     ====> Epoch: 163 Average loss: 0.1935\n",
      "2019-04-09 21:39:23,295 root         INFO     Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 0.160347\n",
      "Reconstruction: 0.125133, Regularization: 0.002724, Discriminator: 0.021660; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:23,386 root         INFO     Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 0.218964\n",
      "Reconstruction: 0.182548, Regularization: 0.003932, Discriminator: 0.021653; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:23,477 root         INFO     Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 0.169640\n",
      "Reconstruction: 0.134296, Regularization: 0.002842, Discriminator: 0.021669; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:23,567 root         INFO     Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 0.197262\n",
      "Reconstruction: 0.161101, Regularization: 0.003676, Discriminator: 0.021654; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:23,659 root         INFO     Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 0.182385\n",
      "Reconstruction: 0.146695, Regularization: 0.003214, Discriminator: 0.021643; Generator: 0.010832,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 21:39:23,750 root         INFO     Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 0.206015\n",
      "Reconstruction: 0.169810, Regularization: 0.003706, Discriminator: 0.021667; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:23,841 root         INFO     Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 0.177329\n",
      "Reconstruction: 0.141813, Regularization: 0.003034, Discriminator: 0.021651; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:23,932 root         INFO     Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 0.205319\n",
      "Reconstruction: 0.169161, Regularization: 0.003675, Discriminator: 0.021655; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:24,018 root         INFO     ====> Epoch: 164 Average loss: 0.1936\n",
      "2019-04-09 21:39:24,044 root         INFO     Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 0.182754\n",
      "Reconstruction: 0.147125, Regularization: 0.003139, Discriminator: 0.021663; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:24,136 root         INFO     Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 0.195228\n",
      "Reconstruction: 0.159126, Regularization: 0.003613, Discriminator: 0.021662; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:24,227 root         INFO     Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 0.197141\n",
      "Reconstruction: 0.161160, Regularization: 0.003494, Discriminator: 0.021662; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:24,316 root         INFO     Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 0.195094\n",
      "Reconstruction: 0.159271, Regularization: 0.003342, Discriminator: 0.021654; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:24,405 root         INFO     Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 0.206729\n",
      "Reconstruction: 0.170521, Regularization: 0.003709, Discriminator: 0.021672; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:24,494 root         INFO     Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 0.231936\n",
      "Reconstruction: 0.194712, Regularization: 0.004735, Discriminator: 0.021657; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:24,582 root         INFO     Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 0.204052\n",
      "Reconstruction: 0.168001, Regularization: 0.003552, Discriminator: 0.021669; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:24,671 root         INFO     Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 0.165950\n",
      "Reconstruction: 0.130704, Regularization: 0.002764, Discriminator: 0.021655; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:24,756 root         INFO     ====> Epoch: 165 Average loss: 0.1925\n",
      "2019-04-09 21:39:24,781 root         INFO     Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 0.231387\n",
      "Reconstruction: 0.194329, Regularization: 0.004573, Discriminator: 0.021659; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:24,873 root         INFO     Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 0.164489\n",
      "Reconstruction: 0.129572, Regularization: 0.002426, Discriminator: 0.021662; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:24,962 root         INFO     Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 0.158434\n",
      "Reconstruction: 0.123514, Regularization: 0.002430, Discriminator: 0.021660; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:25,050 root         INFO     Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 0.182799\n",
      "Reconstruction: 0.147292, Regularization: 0.003013, Discriminator: 0.021661; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:25,139 root         INFO     Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 0.160099\n",
      "Reconstruction: 0.124904, Regularization: 0.002705, Discriminator: 0.021660; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:25,229 root         INFO     Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 0.234411\n",
      "Reconstruction: 0.197478, Regularization: 0.004449, Discriminator: 0.021653; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:25,319 root         INFO     Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 0.176535\n",
      "Reconstruction: 0.140929, Regularization: 0.003107, Discriminator: 0.021667; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:25,409 root         INFO     Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 0.226538\n",
      "Reconstruction: 0.189856, Regularization: 0.004203, Discriminator: 0.021650; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:25,495 root         INFO     ====> Epoch: 166 Average loss: 0.1923\n",
      "2019-04-09 21:39:25,521 root         INFO     Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 0.192356\n",
      "Reconstruction: 0.156598, Regularization: 0.003274, Discriminator: 0.021654; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:25,610 root         INFO     Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 0.194493\n",
      "Reconstruction: 0.158415, Regularization: 0.003585, Discriminator: 0.021663; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:25,700 root         INFO     Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 0.214105\n",
      "Reconstruction: 0.177621, Regularization: 0.003992, Discriminator: 0.021657; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:25,791 root         INFO     Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 0.196062\n",
      "Reconstruction: 0.160012, Regularization: 0.003557, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:25,883 root         INFO     Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 0.177686\n",
      "Reconstruction: 0.142033, Regularization: 0.003169, Discriminator: 0.021653; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:25,976 root         INFO     Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 0.202689\n",
      "Reconstruction: 0.166732, Regularization: 0.003473, Discriminator: 0.021653; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:26,067 root         INFO     Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 0.184295\n",
      "Reconstruction: 0.148847, Regularization: 0.002964, Discriminator: 0.021654; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:26,158 root         INFO     Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 0.223492\n",
      "Reconstruction: 0.187075, Regularization: 0.003933, Discriminator: 0.021658; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:26,243 root         INFO     ====> Epoch: 167 Average loss: 0.1928\n",
      "2019-04-09 21:39:26,269 root         INFO     Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 0.216790\n",
      "Reconstruction: 0.180412, Regularization: 0.003890, Discriminator: 0.021660; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:26,359 root         INFO     Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 0.217745\n",
      "Reconstruction: 0.181231, Regularization: 0.004023, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:26,449 root         INFO     Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 0.194533\n",
      "Reconstruction: 0.158861, Regularization: 0.003180, Discriminator: 0.021660; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:26,539 root         INFO     Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 0.212724\n",
      "Reconstruction: 0.176364, Regularization: 0.003874, Discriminator: 0.021657; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:26,629 root         INFO     Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 0.152984\n",
      "Reconstruction: 0.118173, Regularization: 0.002319, Discriminator: 0.021664; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:26,717 root         INFO     Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 0.210390\n",
      "Reconstruction: 0.174380, Regularization: 0.003521, Discriminator: 0.021661; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:26,804 root         INFO     Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 0.281967\n",
      "Reconstruction: 0.243954, Regularization: 0.005518, Discriminator: 0.021663; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:26,891 root         INFO     Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 0.189933\n",
      "Reconstruction: 0.154115, Regularization: 0.003327, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:26,973 root         INFO     ====> Epoch: 168 Average loss: 0.1938\n",
      "2019-04-09 21:39:26,999 root         INFO     Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 0.223308\n",
      "Reconstruction: 0.186756, Regularization: 0.004061, Discriminator: 0.021659; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:27,088 root         INFO     Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 0.190848\n",
      "Reconstruction: 0.155009, Regularization: 0.003348, Discriminator: 0.021660; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:27,176 root         INFO     Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 0.225261\n",
      "Reconstruction: 0.188401, Regularization: 0.004368, Discriminator: 0.021660; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:27,265 root         INFO     Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 0.191478\n",
      "Reconstruction: 0.155855, Regularization: 0.003130, Discriminator: 0.021664; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:27,354 root         INFO     Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 0.166000\n",
      "Reconstruction: 0.130963, Regularization: 0.002548, Discriminator: 0.021660; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:27,443 root         INFO     Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 0.211737\n",
      "Reconstruction: 0.175341, Regularization: 0.003902, Discriminator: 0.021665; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:27,534 root         INFO     Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 0.194091\n",
      "Reconstruction: 0.158009, Regularization: 0.003596, Discriminator: 0.021655; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:27,625 root         INFO     Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 0.171492\n",
      "Reconstruction: 0.136435, Regularization: 0.002564, Discriminator: 0.021663; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:27,712 root         INFO     ====> Epoch: 169 Average loss: 0.1935\n",
      "2019-04-09 21:39:27,738 root         INFO     Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 0.202692\n",
      "Reconstruction: 0.166800, Regularization: 0.003396, Discriminator: 0.021663; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:27,827 root         INFO     Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 0.182426\n",
      "Reconstruction: 0.146951, Regularization: 0.002983, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:27,916 root         INFO     Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 0.219355\n",
      "Reconstruction: 0.183225, Regularization: 0.003632, Discriminator: 0.021670; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:28,006 root         INFO     Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 0.173155\n",
      "Reconstruction: 0.137952, Regularization: 0.002708, Discriminator: 0.021669; Generator: 0.010826,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:28,095 root         INFO     Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 0.182903\n",
      "Reconstruction: 0.147080, Regularization: 0.003335, Discriminator: 0.021660; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:28,184 root         INFO     Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 0.161467\n",
      "Reconstruction: 0.126379, Regularization: 0.002595, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:28,274 root         INFO     Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 0.190020\n",
      "Reconstruction: 0.154331, Regularization: 0.003200, Discriminator: 0.021661; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:28,362 root         INFO     Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 0.195851\n",
      "Reconstruction: 0.159866, Regularization: 0.003490, Discriminator: 0.021662; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:28,447 root         INFO     ====> Epoch: 170 Average loss: 0.1928\n",
      "2019-04-09 21:39:28,473 root         INFO     Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 0.251319\n",
      "Reconstruction: 0.214257, Regularization: 0.004567, Discriminator: 0.021666; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:28,565 root         INFO     Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 0.219796\n",
      "Reconstruction: 0.182997, Regularization: 0.004308, Discriminator: 0.021659; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:28,655 root         INFO     Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 0.185107\n",
      "Reconstruction: 0.149216, Regularization: 0.003401, Discriminator: 0.021660; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:28,744 root         INFO     Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 0.165448\n",
      "Reconstruction: 0.130130, Regularization: 0.002827, Discriminator: 0.021660; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:28,833 root         INFO     Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 0.174035\n",
      "Reconstruction: 0.138463, Regularization: 0.003083, Discriminator: 0.021660; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:28,922 root         INFO     Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 0.218344\n",
      "Reconstruction: 0.181387, Regularization: 0.004464, Discriminator: 0.021661; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:29,010 root         INFO     Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 0.171267\n",
      "Reconstruction: 0.135664, Regularization: 0.003118, Discriminator: 0.021654; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:29,099 root         INFO     Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 0.223165\n",
      "Reconstruction: 0.186361, Regularization: 0.004320, Discriminator: 0.021655; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:29,183 root         INFO     ====> Epoch: 171 Average loss: 0.1924\n",
      "2019-04-09 21:39:29,209 root         INFO     Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 0.203702\n",
      "Reconstruction: 0.167624, Regularization: 0.003592, Discriminator: 0.021654; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:29,300 root         INFO     Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 0.182993\n",
      "Reconstruction: 0.147486, Regularization: 0.003022, Discriminator: 0.021655; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:29,390 root         INFO     Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 0.153730\n",
      "Reconstruction: 0.118842, Regularization: 0.002397, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:29,481 root         INFO     Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 0.226165\n",
      "Reconstruction: 0.189758, Regularization: 0.003919, Discriminator: 0.021656; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:29,571 root         INFO     Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 0.190630\n",
      "Reconstruction: 0.155071, Regularization: 0.003069, Discriminator: 0.021655; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:29,662 root         INFO     Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 0.180315\n",
      "Reconstruction: 0.144705, Regularization: 0.003123, Discriminator: 0.021658; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:29,752 root         INFO     Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 0.192555\n",
      "Reconstruction: 0.156794, Regularization: 0.003266, Discriminator: 0.021664; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:29,842 root         INFO     Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 0.242917\n",
      "Reconstruction: 0.205322, Regularization: 0.005097, Discriminator: 0.021673; Generator: 0.010824,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:29,927 root         INFO     ====> Epoch: 172 Average loss: 0.1927\n",
      "2019-04-09 21:39:29,953 root         INFO     Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 0.215078\n",
      "Reconstruction: 0.178700, Regularization: 0.003883, Discriminator: 0.021665; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:30,045 root         INFO     Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 0.190731\n",
      "Reconstruction: 0.155233, Regularization: 0.002999, Discriminator: 0.021668; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:30,136 root         INFO     Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 0.149498\n",
      "Reconstruction: 0.114735, Regularization: 0.002266, Discriminator: 0.021668; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:30,227 root         INFO     Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 0.178131\n",
      "Reconstruction: 0.142612, Regularization: 0.003022, Discriminator: 0.021664; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:30,318 root         INFO     Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 0.205514\n",
      "Reconstruction: 0.169042, Regularization: 0.003984, Discriminator: 0.021659; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:30,409 root         INFO     Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 0.222624\n",
      "Reconstruction: 0.185612, Regularization: 0.004524, Discriminator: 0.021658; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:30,500 root         INFO     Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 0.236247\n",
      "Reconstruction: 0.199313, Regularization: 0.004441, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:30,591 root         INFO     Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 0.204978\n",
      "Reconstruction: 0.168737, Regularization: 0.003751, Discriminator: 0.021659; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:30,678 root         INFO     ====> Epoch: 173 Average loss: 0.1938\n",
      "2019-04-09 21:39:30,703 root         INFO     Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 0.171333\n",
      "Reconstruction: 0.135991, Regularization: 0.002856, Discriminator: 0.021656; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:30,794 root         INFO     Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 0.224362\n",
      "Reconstruction: 0.187471, Regularization: 0.004408, Discriminator: 0.021651; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:30,884 root         INFO     Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 0.198352\n",
      "Reconstruction: 0.162161, Regularization: 0.003705, Discriminator: 0.021653; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:30,975 root         INFO     Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 0.177204\n",
      "Reconstruction: 0.141513, Regularization: 0.003200, Discriminator: 0.021660; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:31,065 root         INFO     Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 0.182800\n",
      "Reconstruction: 0.147413, Regularization: 0.002884, Discriminator: 0.021672; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:31,155 root         INFO     Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 0.204390\n",
      "Reconstruction: 0.167991, Regularization: 0.003923, Discriminator: 0.021646; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:31,245 root         INFO     Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 0.184506\n",
      "Reconstruction: 0.148662, Regularization: 0.003357, Discriminator: 0.021657; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:31,335 root         INFO     Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 0.169535\n",
      "Reconstruction: 0.134259, Regularization: 0.002779, Discriminator: 0.021670; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:31,418 root         INFO     ====> Epoch: 174 Average loss: 0.1934\n",
      "2019-04-09 21:39:31,444 root         INFO     Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 0.155904\n",
      "Reconstruction: 0.121032, Regularization: 0.002375, Discriminator: 0.021663; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:31,535 root         INFO     Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 0.185103\n",
      "Reconstruction: 0.149617, Regularization: 0.002984, Discriminator: 0.021673; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:31,626 root         INFO     Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 0.191370\n",
      "Reconstruction: 0.155400, Regularization: 0.003487, Discriminator: 0.021654; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:31,716 root         INFO     Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 0.185812\n",
      "Reconstruction: 0.150110, Regularization: 0.003206, Discriminator: 0.021663; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:31,807 root         INFO     Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 0.205816\n",
      "Reconstruction: 0.169818, Regularization: 0.003505, Discriminator: 0.021664; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:31,897 root         INFO     Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 0.185463\n",
      "Reconstruction: 0.150002, Regularization: 0.002964, Discriminator: 0.021667; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:31,987 root         INFO     Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 0.173788\n",
      "Reconstruction: 0.138578, Regularization: 0.002715, Discriminator: 0.021666; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:32,077 root         INFO     Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 0.176641\n",
      "Reconstruction: 0.140864, Regularization: 0.003285, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:32,163 root         INFO     ====> Epoch: 175 Average loss: 0.1926\n",
      "2019-04-09 21:39:32,189 root         INFO     Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 0.172692\n",
      "Reconstruction: 0.137163, Regularization: 0.003038, Discriminator: 0.021659; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:32,280 root         INFO     Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 0.178709\n",
      "Reconstruction: 0.143130, Regularization: 0.003088, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:32,371 root         INFO     Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 0.195271\n",
      "Reconstruction: 0.159689, Regularization: 0.003091, Discriminator: 0.021663; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:32,461 root         INFO     Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 0.182869\n",
      "Reconstruction: 0.147172, Regularization: 0.003204, Discriminator: 0.021660; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:32,552 root         INFO     Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 0.196660\n",
      "Reconstruction: 0.160944, Regularization: 0.003227, Discriminator: 0.021660; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:32,642 root         INFO     Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 0.198115\n",
      "Reconstruction: 0.161820, Regularization: 0.003806, Discriminator: 0.021659; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:32,733 root         INFO     Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 0.184939\n",
      "Reconstruction: 0.149311, Regularization: 0.003142, Discriminator: 0.021655; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:32,823 root         INFO     Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 0.161814\n",
      "Reconstruction: 0.126744, Regularization: 0.002578, Discriminator: 0.021663; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:32,909 root         INFO     ====> Epoch: 176 Average loss: 0.1925\n",
      "2019-04-09 21:39:32,935 root         INFO     Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 0.172134\n",
      "Reconstruction: 0.136930, Regularization: 0.002709, Discriminator: 0.021664; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:33,025 root         INFO     Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 0.206953\n",
      "Reconstruction: 0.170972, Regularization: 0.003493, Discriminator: 0.021656; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:33,116 root         INFO     Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 0.175973\n",
      "Reconstruction: 0.140427, Regularization: 0.003049, Discriminator: 0.021666; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:33,207 root         INFO     Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 0.207127\n",
      "Reconstruction: 0.170365, Regularization: 0.004267, Discriminator: 0.021666; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:33,299 root         INFO     Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 0.168245\n",
      "Reconstruction: 0.133237, Regularization: 0.002519, Discriminator: 0.021658; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:33,390 root         INFO     Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 0.197383\n",
      "Reconstruction: 0.161570, Regularization: 0.003326, Discriminator: 0.021656; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:33,481 root         INFO     Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 0.175010\n",
      "Reconstruction: 0.139480, Regularization: 0.003032, Discriminator: 0.021668; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:33,572 root         INFO     Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 0.186985\n",
      "Reconstruction: 0.151319, Regularization: 0.003172, Discriminator: 0.021664; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:33,659 root         INFO     ====> Epoch: 177 Average loss: 0.1931\n",
      "2019-04-09 21:39:33,684 root         INFO     Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 0.159328\n",
      "Reconstruction: 0.124290, Regularization: 0.002546, Discriminator: 0.021662; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:33,776 root         INFO     Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 0.179402\n",
      "Reconstruction: 0.143500, Regularization: 0.003400, Discriminator: 0.021668; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:33,867 root         INFO     Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 0.176021\n",
      "Reconstruction: 0.140582, Regularization: 0.002947, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:33,959 root         INFO     Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 0.164812\n",
      "Reconstruction: 0.129838, Regularization: 0.002483, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:34,050 root         INFO     Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 0.168758\n",
      "Reconstruction: 0.133395, Regularization: 0.002872, Discriminator: 0.021662; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:34,142 root         INFO     Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 0.176397\n",
      "Reconstruction: 0.141193, Regularization: 0.002717, Discriminator: 0.021660; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:34,233 root         INFO     Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 0.201069\n",
      "Reconstruction: 0.165089, Regularization: 0.003490, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:34,324 root         INFO     Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 0.192976\n",
      "Reconstruction: 0.156917, Regularization: 0.003565, Discriminator: 0.021661; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:34,411 root         INFO     ====> Epoch: 178 Average loss: 0.1938\n",
      "2019-04-09 21:39:34,436 root         INFO     Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 0.127505\n",
      "Reconstruction: 0.093381, Regularization: 0.001636, Discriminator: 0.021657; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:34,526 root         INFO     Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 0.170944\n",
      "Reconstruction: 0.135429, Regularization: 0.003024, Discriminator: 0.021656; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:34,616 root         INFO     Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 0.208940\n",
      "Reconstruction: 0.172690, Regularization: 0.003758, Discriminator: 0.021664; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:34,707 root         INFO     Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 0.188066\n",
      "Reconstruction: 0.152441, Regularization: 0.003136, Discriminator: 0.021659; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:34,793 root         INFO     Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 0.189754\n",
      "Reconstruction: 0.153695, Regularization: 0.003572, Discriminator: 0.021656; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:34,880 root         INFO     Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 0.201107\n",
      "Reconstruction: 0.164903, Regularization: 0.003709, Discriminator: 0.021661; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:34,968 root         INFO     Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 0.192291\n",
      "Reconstruction: 0.156200, Regularization: 0.003597, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:35,056 root         INFO     Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 0.191981\n",
      "Reconstruction: 0.156331, Regularization: 0.003163, Discriminator: 0.021657; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:35,141 root         INFO     ====> Epoch: 179 Average loss: 0.1933\n",
      "2019-04-09 21:39:35,166 root         INFO     Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 0.202422\n",
      "Reconstruction: 0.166374, Regularization: 0.003556, Discriminator: 0.021663; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:35,258 root         INFO     Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 0.228866\n",
      "Reconstruction: 0.192134, Regularization: 0.004238, Discriminator: 0.021661; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:35,348 root         INFO     Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 0.197462\n",
      "Reconstruction: 0.160998, Regularization: 0.003977, Discriminator: 0.021656; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:35,440 root         INFO     Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 0.227906\n",
      "Reconstruction: 0.191088, Regularization: 0.004325, Discriminator: 0.021664; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:35,531 root         INFO     Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 0.207657\n",
      "Reconstruction: 0.171583, Regularization: 0.003578, Discriminator: 0.021666; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:35,622 root         INFO     Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 0.218489\n",
      "Reconstruction: 0.181358, Regularization: 0.004636, Discriminator: 0.021666; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:35,712 root         INFO     Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 0.184821\n",
      "Reconstruction: 0.148947, Regularization: 0.003377, Discriminator: 0.021665; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:35,802 root         INFO     Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 0.155276\n",
      "Reconstruction: 0.120527, Regularization: 0.002259, Discriminator: 0.021660; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:35,888 root         INFO     ====> Epoch: 180 Average loss: 0.1925\n",
      "2019-04-09 21:39:35,914 root         INFO     Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 0.193298\n",
      "Reconstruction: 0.157195, Regularization: 0.003612, Discriminator: 0.021660; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:36,003 root         INFO     Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 0.197728\n",
      "Reconstruction: 0.161819, Regularization: 0.003422, Discriminator: 0.021658; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:36,091 root         INFO     Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 0.166800\n",
      "Reconstruction: 0.131500, Regularization: 0.002814, Discriminator: 0.021658; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:36,179 root         INFO     Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 0.182775\n",
      "Reconstruction: 0.147052, Regularization: 0.003225, Discriminator: 0.021663; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:36,267 root         INFO     Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 0.160211\n",
      "Reconstruction: 0.125682, Regularization: 0.002052, Discriminator: 0.021644; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:36,354 root         INFO     Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 0.163444\n",
      "Reconstruction: 0.128279, Regularization: 0.002679, Discriminator: 0.021658; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:36,443 root         INFO     Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 0.186098\n",
      "Reconstruction: 0.150046, Regularization: 0.003556, Discriminator: 0.021667; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:36,531 root         INFO     Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 0.190318\n",
      "Reconstruction: 0.154912, Regularization: 0.002925, Discriminator: 0.021652; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:36,616 root         INFO     ====> Epoch: 181 Average loss: 0.1927\n",
      "2019-04-09 21:39:36,641 root         INFO     Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 0.182972\n",
      "Reconstruction: 0.147391, Regularization: 0.003099, Discriminator: 0.021651; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:36,732 root         INFO     Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 0.165989\n",
      "Reconstruction: 0.130753, Regularization: 0.002744, Discriminator: 0.021663; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:36,823 root         INFO     Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 0.174432\n",
      "Reconstruction: 0.139137, Regularization: 0.002810, Discriminator: 0.021657; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:36,915 root         INFO     Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 0.204626\n",
      "Reconstruction: 0.168411, Regularization: 0.003716, Discriminator: 0.021669; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:37,005 root         INFO     Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 0.184383\n",
      "Reconstruction: 0.148716, Regularization: 0.003170, Discriminator: 0.021669; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:37,096 root         INFO     Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 0.161552\n",
      "Reconstruction: 0.126347, Regularization: 0.002713, Discriminator: 0.021662; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:37,187 root         INFO     Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 0.185203\n",
      "Reconstruction: 0.149429, Regularization: 0.003278, Discriminator: 0.021667; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:37,277 root         INFO     Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 0.199902\n",
      "Reconstruction: 0.163477, Regularization: 0.003932, Discriminator: 0.021661; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:37,362 root         INFO     ====> Epoch: 182 Average loss: 0.1936\n",
      "2019-04-09 21:39:37,387 root         INFO     Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 0.196885\n",
      "Reconstruction: 0.161048, Regularization: 0.003345, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:37,478 root         INFO     Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 0.189234\n",
      "Reconstruction: 0.153728, Regularization: 0.003011, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:37,568 root         INFO     Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 0.183122\n",
      "Reconstruction: 0.147210, Regularization: 0.003423, Discriminator: 0.021657; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:37,658 root         INFO     Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 0.251560\n",
      "Reconstruction: 0.214144, Regularization: 0.004927, Discriminator: 0.021660; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:37,747 root         INFO     Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 0.253616\n",
      "Reconstruction: 0.215784, Regularization: 0.005338, Discriminator: 0.021661; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:37,836 root         INFO     Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 0.232793\n",
      "Reconstruction: 0.196053, Regularization: 0.004245, Discriminator: 0.021662; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:37,925 root         INFO     Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 0.166341\n",
      "Reconstruction: 0.131033, Regularization: 0.002818, Discriminator: 0.021662; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:38,014 root         INFO     Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 0.201766\n",
      "Reconstruction: 0.165257, Regularization: 0.004022, Discriminator: 0.021659; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:38,099 root         INFO     ====> Epoch: 183 Average loss: 0.1941\n",
      "2019-04-09 21:39:38,125 root         INFO     Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 0.178300\n",
      "Reconstruction: 0.143036, Regularization: 0.002773, Discriminator: 0.021659; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:38,215 root         INFO     Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 0.201953\n",
      "Reconstruction: 0.166097, Regularization: 0.003363, Discriminator: 0.021658; Generator: 0.010835,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:38,305 root         INFO     Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 0.193080\n",
      "Reconstruction: 0.157377, Regularization: 0.003210, Discriminator: 0.021664; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:38,396 root         INFO     Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 0.174587\n",
      "Reconstruction: 0.139514, Regularization: 0.002581, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:38,486 root         INFO     Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 0.178925\n",
      "Reconstruction: 0.143731, Regularization: 0.002698, Discriminator: 0.021668; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:38,576 root         INFO     Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 0.170189\n",
      "Reconstruction: 0.135068, Regularization: 0.002623, Discriminator: 0.021670; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:38,666 root         INFO     Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 0.188869\n",
      "Reconstruction: 0.153020, Regularization: 0.003350, Discriminator: 0.021669; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:38,756 root         INFO     Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 0.188698\n",
      "Reconstruction: 0.153020, Regularization: 0.003183, Discriminator: 0.021662; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:38,842 root         INFO     ====> Epoch: 184 Average loss: 0.1927\n",
      "2019-04-09 21:39:38,868 root         INFO     Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 0.187343\n",
      "Reconstruction: 0.151706, Regularization: 0.003144, Discriminator: 0.021663; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:38,958 root         INFO     Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 0.152826\n",
      "Reconstruction: 0.118142, Regularization: 0.002191, Discriminator: 0.021662; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:39,048 root         INFO     Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 0.206927\n",
      "Reconstruction: 0.170950, Regularization: 0.003486, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:39,138 root         INFO     Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 0.215151\n",
      "Reconstruction: 0.178600, Regularization: 0.004061, Discriminator: 0.021661; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:39,227 root         INFO     Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 0.186169\n",
      "Reconstruction: 0.150747, Regularization: 0.002933, Discriminator: 0.021658; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:39,315 root         INFO     Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 0.254256\n",
      "Reconstruction: 0.216951, Regularization: 0.004814, Discriminator: 0.021660; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:39,404 root         INFO     Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 0.148101\n",
      "Reconstruction: 0.113284, Regularization: 0.002323, Discriminator: 0.021663; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:39,493 root         INFO     Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 0.190324\n",
      "Reconstruction: 0.154837, Regularization: 0.003002, Discriminator: 0.021657; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:39,577 root         INFO     ====> Epoch: 185 Average loss: 0.1924\n",
      "2019-04-09 21:39:39,603 root         INFO     Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 0.214581\n",
      "Reconstruction: 0.178128, Regularization: 0.003968, Discriminator: 0.021657; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:39,692 root         INFO     Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 0.181618\n",
      "Reconstruction: 0.145813, Regularization: 0.003318, Discriminator: 0.021654; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:39,782 root         INFO     Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 0.159657\n",
      "Reconstruction: 0.124719, Regularization: 0.002446, Discriminator: 0.021665; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:39,871 root         INFO     Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 0.183922\n",
      "Reconstruction: 0.148442, Regularization: 0.002994, Discriminator: 0.021658; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:39,960 root         INFO     Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 0.201900\n",
      "Reconstruction: 0.166286, Regularization: 0.003126, Discriminator: 0.021660; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:40,048 root         INFO     Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 0.226171\n",
      "Reconstruction: 0.189260, Regularization: 0.004411, Discriminator: 0.021671; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:40,137 root         INFO     Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 0.214474\n",
      "Reconstruction: 0.178311, Regularization: 0.003668, Discriminator: 0.021662; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:40,222 root         INFO     Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 0.181075\n",
      "Reconstruction: 0.145284, Regularization: 0.003299, Discriminator: 0.021662; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:40,305 root         INFO     ====> Epoch: 186 Average loss: 0.1932\n",
      "2019-04-09 21:39:40,332 root         INFO     Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 0.225087\n",
      "Reconstruction: 0.188677, Regularization: 0.003915, Discriminator: 0.021665; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:40,420 root         INFO     Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 0.181657\n",
      "Reconstruction: 0.146335, Regularization: 0.002829, Discriminator: 0.021663; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:40,507 root         INFO     Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 0.181555\n",
      "Reconstruction: 0.146117, Regularization: 0.002951, Discriminator: 0.021659; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:40,595 root         INFO     Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 0.227283\n",
      "Reconstruction: 0.190890, Regularization: 0.003901, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:40,682 root         INFO     Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 0.212786\n",
      "Reconstruction: 0.176780, Regularization: 0.003515, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:40,769 root         INFO     Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 0.177559\n",
      "Reconstruction: 0.142056, Regularization: 0.003012, Discriminator: 0.021659; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:40,856 root         INFO     Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 0.159279\n",
      "Reconstruction: 0.124400, Regularization: 0.002383, Discriminator: 0.021663; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:40,943 root         INFO     Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 0.190566\n",
      "Reconstruction: 0.155282, Regularization: 0.002792, Discriminator: 0.021660; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:41,026 root         INFO     ====> Epoch: 187 Average loss: 0.1937\n",
      "2019-04-09 21:39:41,051 root         INFO     Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 0.223787\n",
      "Reconstruction: 0.187089, Regularization: 0.004212, Discriminator: 0.021656; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:41,136 root         INFO     Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 0.199789\n",
      "Reconstruction: 0.163940, Regularization: 0.003357, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:41,220 root         INFO     Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 0.177129\n",
      "Reconstruction: 0.141620, Regularization: 0.003016, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:41,304 root         INFO     Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 0.204965\n",
      "Reconstruction: 0.168770, Regularization: 0.003714, Discriminator: 0.021652; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:41,388 root         INFO     Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 0.171644\n",
      "Reconstruction: 0.136037, Regularization: 0.003116, Discriminator: 0.021663; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:41,473 root         INFO     Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 0.195165\n",
      "Reconstruction: 0.159381, Regularization: 0.003292, Discriminator: 0.021663; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:41,557 root         INFO     Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 0.217611\n",
      "Reconstruction: 0.181341, Regularization: 0.003777, Discriminator: 0.021665; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:41,641 root         INFO     Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 0.186193\n",
      "Reconstruction: 0.150685, Regularization: 0.003019, Discriminator: 0.021658; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:41,722 root         INFO     ====> Epoch: 188 Average loss: 0.1932\n",
      "2019-04-09 21:39:41,747 root         INFO     Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 0.218563\n",
      "Reconstruction: 0.181883, Regularization: 0.004189, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:41,832 root         INFO     Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 0.172787\n",
      "Reconstruction: 0.137264, Regularization: 0.003035, Discriminator: 0.021658; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:41,917 root         INFO     Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 0.187393\n",
      "Reconstruction: 0.151707, Regularization: 0.003193, Discriminator: 0.021661; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:42,001 root         INFO     Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 0.226243\n",
      "Reconstruction: 0.189757, Regularization: 0.003994, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:42,085 root         INFO     Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 0.208758\n",
      "Reconstruction: 0.172421, Regularization: 0.003848, Discriminator: 0.021659; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:42,169 root         INFO     Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 0.185359\n",
      "Reconstruction: 0.149804, Regularization: 0.003061, Discriminator: 0.021662; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:42,253 root         INFO     Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 0.232475\n",
      "Reconstruction: 0.195321, Regularization: 0.004665, Discriminator: 0.021660; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:42,336 root         INFO     Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 0.193849\n",
      "Reconstruction: 0.157967, Regularization: 0.003391, Discriminator: 0.021661; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:42,417 root         INFO     ====> Epoch: 189 Average loss: 0.1926\n",
      "2019-04-09 21:39:42,443 root         INFO     Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 0.200106\n",
      "Reconstruction: 0.164014, Regularization: 0.003605, Discriminator: 0.021657; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:42,529 root         INFO     Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 0.255268\n",
      "Reconstruction: 0.217979, Regularization: 0.004796, Discriminator: 0.021663; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:42,615 root         INFO     Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 0.166717\n",
      "Reconstruction: 0.131917, Regularization: 0.002307, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:42,700 root         INFO     Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 0.210362\n",
      "Reconstruction: 0.174023, Regularization: 0.003847, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:42,785 root         INFO     Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 0.170613\n",
      "Reconstruction: 0.135600, Regularization: 0.002516, Discriminator: 0.021665; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:42,870 root         INFO     Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 0.248670\n",
      "Reconstruction: 0.211506, Regularization: 0.004674, Discriminator: 0.021660; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:42,956 root         INFO     Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 0.179816\n",
      "Reconstruction: 0.144215, Regularization: 0.003116, Discriminator: 0.021655; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:43,040 root         INFO     Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 0.189227\n",
      "Reconstruction: 0.153171, Regularization: 0.003566, Discriminator: 0.021660; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:43,122 root         INFO     ====> Epoch: 190 Average loss: 0.1930\n",
      "2019-04-09 21:39:43,147 root         INFO     Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 0.182932\n",
      "Reconstruction: 0.146923, Regularization: 0.003507, Discriminator: 0.021671; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:43,235 root         INFO     Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 0.189244\n",
      "Reconstruction: 0.153495, Regularization: 0.003251, Discriminator: 0.021667; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:43,325 root         INFO     Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 0.202629\n",
      "Reconstruction: 0.166396, Regularization: 0.003740, Discriminator: 0.021662; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:43,415 root         INFO     Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 0.196618\n",
      "Reconstruction: 0.161219, Regularization: 0.002909, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:43,503 root         INFO     Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 0.206804\n",
      "Reconstruction: 0.170707, Regularization: 0.003608, Discriminator: 0.021662; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:43,590 root         INFO     Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 0.177595\n",
      "Reconstruction: 0.142329, Regularization: 0.002775, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:43,677 root         INFO     Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 0.183324\n",
      "Reconstruction: 0.147790, Regularization: 0.003040, Discriminator: 0.021662; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:43,765 root         INFO     Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 0.168164\n",
      "Reconstruction: 0.132609, Regularization: 0.003067, Discriminator: 0.021659; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:43,850 root         INFO     ====> Epoch: 191 Average loss: 0.1934\n",
      "2019-04-09 21:39:43,876 root         INFO     Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 0.241721\n",
      "Reconstruction: 0.204479, Regularization: 0.004753, Discriminator: 0.021660; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:43,968 root         INFO     Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 0.188509\n",
      "Reconstruction: 0.152875, Regularization: 0.003142, Discriminator: 0.021658; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:44,060 root         INFO     Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.191351\n",
      "Reconstruction: 0.155457, Regularization: 0.003398, Discriminator: 0.021666; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:44,151 root         INFO     Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 0.203744\n",
      "Reconstruction: 0.167542, Regularization: 0.003710, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:44,243 root         INFO     Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 0.164193\n",
      "Reconstruction: 0.129221, Regularization: 0.002478, Discriminator: 0.021664; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:44,334 root         INFO     Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 0.201827\n",
      "Reconstruction: 0.165380, Regularization: 0.003961, Discriminator: 0.021655; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:44,426 root         INFO     Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 0.195632\n",
      "Reconstruction: 0.159771, Regularization: 0.003360, Discriminator: 0.021670; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:44,518 root         INFO     Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 0.238881\n",
      "Reconstruction: 0.201598, Regularization: 0.004791, Discriminator: 0.021660; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:44,603 root         INFO     ====> Epoch: 192 Average loss: 0.1932\n",
      "2019-04-09 21:39:44,628 root         INFO     Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 0.150399\n",
      "Reconstruction: 0.115614, Regularization: 0.002292, Discriminator: 0.021663; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:44,718 root         INFO     Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 0.190760\n",
      "Reconstruction: 0.155080, Regularization: 0.003189, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:44,806 root         INFO     Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 0.194392\n",
      "Reconstruction: 0.158562, Regularization: 0.003338, Discriminator: 0.021661; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:44,893 root         INFO     Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 0.156014\n",
      "Reconstruction: 0.120910, Regularization: 0.002615, Discriminator: 0.021660; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:44,980 root         INFO     Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 0.220248\n",
      "Reconstruction: 0.183452, Regularization: 0.004304, Discriminator: 0.021661; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:45,065 root         INFO     Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 0.164840\n",
      "Reconstruction: 0.129639, Regularization: 0.002711, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:45,150 root         INFO     Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 0.200116\n",
      "Reconstruction: 0.164145, Regularization: 0.003482, Discriminator: 0.021660; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:45,236 root         INFO     Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 0.212831\n",
      "Reconstruction: 0.176344, Regularization: 0.003997, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:45,318 root         INFO     ====> Epoch: 193 Average loss: 0.1925\n",
      "2019-04-09 21:39:45,343 root         INFO     Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 0.210913\n",
      "Reconstruction: 0.174753, Regularization: 0.003668, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:45,430 root         INFO     Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 0.200129\n",
      "Reconstruction: 0.164097, Regularization: 0.003543, Discriminator: 0.021658; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:45,517 root         INFO     Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 0.251323\n",
      "Reconstruction: 0.214265, Regularization: 0.004570, Discriminator: 0.021658; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:45,603 root         INFO     Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 0.224259\n",
      "Reconstruction: 0.187293, Regularization: 0.004475, Discriminator: 0.021659; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:45,689 root         INFO     Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 0.163882\n",
      "Reconstruction: 0.128633, Regularization: 0.002756, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:45,775 root         INFO     Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 0.147090\n",
      "Reconstruction: 0.112381, Regularization: 0.002216, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:45,859 root         INFO     Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 0.229469\n",
      "Reconstruction: 0.192564, Regularization: 0.004415, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:45,945 root         INFO     Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 0.179627\n",
      "Reconstruction: 0.144437, Regularization: 0.002701, Discriminator: 0.021661; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:46,028 root         INFO     ====> Epoch: 194 Average loss: 0.1930\n",
      "2019-04-09 21:39:46,053 root         INFO     Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 0.208880\n",
      "Reconstruction: 0.172661, Regularization: 0.003730, Discriminator: 0.021659; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:46,141 root         INFO     Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 0.181031\n",
      "Reconstruction: 0.145283, Regularization: 0.003253, Discriminator: 0.021663; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:46,228 root         INFO     Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 0.215857\n",
      "Reconstruction: 0.179269, Regularization: 0.004090, Discriminator: 0.021665; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:46,316 root         INFO     Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 0.186320\n",
      "Reconstruction: 0.150649, Regularization: 0.003178, Discriminator: 0.021662; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:46,403 root         INFO     Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 0.196175\n",
      "Reconstruction: 0.160100, Regularization: 0.003579, Discriminator: 0.021665; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:46,489 root         INFO     Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 0.210172\n",
      "Reconstruction: 0.173691, Regularization: 0.003990, Discriminator: 0.021663; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:46,573 root         INFO     Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 0.193089\n",
      "Reconstruction: 0.157325, Regularization: 0.003276, Discriminator: 0.021658; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:46,658 root         INFO     Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 0.173533\n",
      "Reconstruction: 0.138244, Regularization: 0.002794, Discriminator: 0.021664; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:46,742 root         INFO     ====> Epoch: 195 Average loss: 0.1934\n",
      "2019-04-09 21:39:46,768 root         INFO     Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 0.161092\n",
      "Reconstruction: 0.126174, Regularization: 0.002425, Discriminator: 0.021663; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:46,857 root         INFO     Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 0.182557\n",
      "Reconstruction: 0.147002, Regularization: 0.003067, Discriminator: 0.021654; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:46,947 root         INFO     Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 0.194769\n",
      "Reconstruction: 0.158847, Regularization: 0.003426, Discriminator: 0.021662; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:47,037 root         INFO     Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 0.178603\n",
      "Reconstruction: 0.143172, Regularization: 0.002934, Discriminator: 0.021668; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:47,126 root         INFO     Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 0.238027\n",
      "Reconstruction: 0.200765, Regularization: 0.004771, Discriminator: 0.021663; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:47,215 root         INFO     Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 0.212909\n",
      "Reconstruction: 0.176621, Regularization: 0.003798, Discriminator: 0.021660; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:47,304 root         INFO     Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 0.180028\n",
      "Reconstruction: 0.144340, Regularization: 0.003192, Discriminator: 0.021669; Generator: 0.010827,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:47,393 root         INFO     Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 0.167103\n",
      "Reconstruction: 0.131822, Regularization: 0.002787, Discriminator: 0.021662; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:47,478 root         INFO     ====> Epoch: 196 Average loss: 0.1927\n",
      "2019-04-09 21:39:47,504 root         INFO     Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 0.195013\n",
      "Reconstruction: 0.159326, Regularization: 0.003196, Discriminator: 0.021660; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:47,593 root         INFO     Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 0.178933\n",
      "Reconstruction: 0.143341, Regularization: 0.003101, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:47,679 root         INFO     Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 0.180493\n",
      "Reconstruction: 0.144810, Regularization: 0.003192, Discriminator: 0.021664; Generator: 0.010828,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:47,764 root         INFO     Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 0.189891\n",
      "Reconstruction: 0.153894, Regularization: 0.003502, Discriminator: 0.021666; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:47,849 root         INFO     Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 0.183815\n",
      "Reconstruction: 0.147998, Regularization: 0.003323, Discriminator: 0.021662; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:47,935 root         INFO     Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 0.150337\n",
      "Reconstruction: 0.115460, Regularization: 0.002383, Discriminator: 0.021661; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:48,021 root         INFO     Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 0.170726\n",
      "Reconstruction: 0.135379, Regularization: 0.002859, Discriminator: 0.021658; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:48,106 root         INFO     Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 0.228110\n",
      "Reconstruction: 0.191509, Regularization: 0.004112, Discriminator: 0.021658; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:48,188 root         INFO     ====> Epoch: 197 Average loss: 0.1927\n",
      "2019-04-09 21:39:48,214 root         INFO     Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 0.164912\n",
      "Reconstruction: 0.129729, Regularization: 0.002692, Discriminator: 0.021661; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:48,298 root         INFO     Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.210290\n",
      "Reconstruction: 0.174098, Regularization: 0.003697, Discriminator: 0.021665; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:48,383 root         INFO     Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 0.204181\n",
      "Reconstruction: 0.167239, Regularization: 0.004442, Discriminator: 0.021668; Generator: 0.010832,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:48,467 root         INFO     Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 0.176913\n",
      "Reconstruction: 0.141616, Regularization: 0.002813, Discriminator: 0.021659; Generator: 0.010825,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:48,552 root         INFO     Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 0.177264\n",
      "Reconstruction: 0.142068, Regularization: 0.002702, Discriminator: 0.021663; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:48,636 root         INFO     Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 0.217602\n",
      "Reconstruction: 0.181540, Regularization: 0.003570, Discriminator: 0.021659; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:48,721 root         INFO     Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 0.232566\n",
      "Reconstruction: 0.195879, Regularization: 0.004195, Discriminator: 0.021662; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:48,808 root         INFO     Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 0.202650\n",
      "Reconstruction: 0.166749, Regularization: 0.003412, Discriminator: 0.021661; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:48,893 root         INFO     ====> Epoch: 198 Average loss: 0.1934\n",
      "2019-04-09 21:39:48,919 root         INFO     Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 0.199851\n",
      "Reconstruction: 0.163772, Regularization: 0.003587, Discriminator: 0.021661; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:49,010 root         INFO     Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 0.191584\n",
      "Reconstruction: 0.156113, Regularization: 0.002982, Discriminator: 0.021661; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:49,101 root         INFO     Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 0.198063\n",
      "Reconstruction: 0.162562, Regularization: 0.003012, Discriminator: 0.021659; Generator: 0.010830,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:49,191 root         INFO     Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 0.222311\n",
      "Reconstruction: 0.185715, Regularization: 0.004100, Discriminator: 0.021663; Generator: 0.010834,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:49,281 root         INFO     Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 0.160340\n",
      "Reconstruction: 0.125705, Regularization: 0.002144, Discriminator: 0.021660; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:49,371 root         INFO     Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 0.203163\n",
      "Reconstruction: 0.167025, Regularization: 0.003650, Discriminator: 0.021656; Generator: 0.010833,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:49,461 root         INFO     Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.208901\n",
      "Reconstruction: 0.172649, Regularization: 0.003756, Discriminator: 0.021665; Generator: 0.010831,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:49,551 root         INFO     Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 0.228280\n",
      "Reconstruction: 0.191980, Regularization: 0.003805, Discriminator: 0.021667; Generator: 0.010829,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 21:39:49,637 root         INFO     ====> Epoch: 199 Average loss: 0.1933\n",
      "2019-04-09 21:39:49,652 luigi-interface INFO     [pid 25020] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=25020) done      TrainVEM()\n",
      "2019-04-09 21:39:49,653 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 21:39:49,653 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   DONE\n",
      "2019-04-09 21:39:49,653 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 21:39:49,653 luigi-interface DEBUG    Pending tasks: 2\n",
      "2019-04-09 21:39:49,653 luigi-interface INFO     [pid 25020] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=25020) running   TrainVAE()\n",
      "2019-04-09 21:39:49,654 root         INFO     --Dataset tensor: (10000, 2)\n",
      "2019-04-09 21:39:49,654 root         INFO     -- Train tensor: (8000, 2)\n",
      "2019-04-09 21:39:49,655 root         INFO     Values of VAE's decoder parameters before training:\n",
      "2019-04-09 21:39:49,655 root         INFO     layers.0.weight\n",
      "2019-04-09 21:39:49,655 root         INFO     tensor([[-0.4871],\n",
      "        [-0.5880]], device='cuda:0')\n",
      "2019-04-09 21:39:49,656 root         INFO     layers.0.bias\n",
      "2019-04-09 21:39:49,656 root         INFO     tensor([-0.5522,  0.0713], device='cuda:0')\n",
      "2019-04-09 21:39:49,657 root         INFO     layers.1.weight\n",
      "2019-04-09 21:39:49,657 root         INFO     tensor([[ 0.3872, -0.6214],\n",
      "        [-0.3895,  0.4841]], device='cuda:0')\n",
      "2019-04-09 21:39:49,658 root         INFO     layers.1.bias\n",
      "2019-04-09 21:39:49,658 root         INFO     tensor([ 0.6309, -0.6735], device='cuda:0')\n",
      "2019-04-09 21:39:49,659 root         INFO     layers.2.weight\n",
      "2019-04-09 21:39:49,660 root         INFO     tensor([[ 0.6277, -0.6320],\n",
      "        [-0.1864, -0.4989]], device='cuda:0')\n",
      "2019-04-09 21:39:49,661 root         INFO     layers.2.bias\n",
      "2019-04-09 21:39:49,661 root         INFO     tensor([-0.3475, -0.3752], device='cuda:0')\n",
      "2019-04-09 21:39:49,684 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 0.709227\n",
      "Reconstruction: 0.367016, Regularization: 0.342211\n",
      "2019-04-09 21:39:49,728 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 0.421704\n",
      "Reconstruction: 0.112094, Regularization: 0.309610\n",
      "2019-04-09 21:39:49,771 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 0.400985\n",
      "Reconstruction: 0.127634, Regularization: 0.273350\n",
      "2019-04-09 21:39:49,815 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 0.379511\n",
      "Reconstruction: 0.106307, Regularization: 0.273204\n",
      "2019-04-09 21:39:49,859 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 0.593775\n",
      "Reconstruction: 0.279433, Regularization: 0.314342\n",
      "2019-04-09 21:39:49,903 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 1.494802\n",
      "Reconstruction: 1.183067, Regularization: 0.311736\n",
      "2019-04-09 21:39:49,948 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 0.450419\n",
      "Reconstruction: 0.153409, Regularization: 0.297010\n",
      "2019-04-09 21:39:49,992 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 0.647089\n",
      "Reconstruction: 0.260845, Regularization: 0.386245\n",
      "2019-04-09 21:39:50,044 root         INFO     ====> Epoch: 0 Average loss: 5.3841\n",
      "2019-04-09 21:39:50,066 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 0.409516\n",
      "Reconstruction: 0.164506, Regularization: 0.245009\n",
      "2019-04-09 21:39:50,111 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 0.850214\n",
      "Reconstruction: 0.532809, Regularization: 0.317405\n",
      "2019-04-09 21:39:50,157 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 0.458856\n",
      "Reconstruction: 0.208382, Regularization: 0.250474\n",
      "2019-04-09 21:39:50,201 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 0.518497\n",
      "Reconstruction: 0.234408, Regularization: 0.284089\n",
      "2019-04-09 21:39:50,246 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 1.622615\n",
      "Reconstruction: 1.341800, Regularization: 0.280815\n",
      "2019-04-09 21:39:50,291 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 0.517715\n",
      "Reconstruction: 0.246588, Regularization: 0.271127\n",
      "2019-04-09 21:39:50,335 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 0.772793\n",
      "Reconstruction: 0.471988, Regularization: 0.300805\n",
      "2019-04-09 21:39:50,380 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 0.555585\n",
      "Reconstruction: 0.320960, Regularization: 0.234625\n",
      "2019-04-09 21:39:50,432 root         INFO     ====> Epoch: 1 Average loss: 6.0256\n",
      "2019-04-09 21:39:50,455 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 0.489631\n",
      "Reconstruction: 0.243230, Regularization: 0.246401\n",
      "2019-04-09 21:39:50,499 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 0.687006\n",
      "Reconstruction: 0.443962, Regularization: 0.243044\n",
      "2019-04-09 21:39:50,542 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 0.558788\n",
      "Reconstruction: 0.315335, Regularization: 0.243453\n",
      "2019-04-09 21:39:50,585 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 0.404682\n",
      "Reconstruction: 0.142265, Regularization: 0.262417\n",
      "2019-04-09 21:39:50,628 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 0.610730\n",
      "Reconstruction: 0.303426, Regularization: 0.307304\n",
      "2019-04-09 21:39:50,672 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 1.283931\n",
      "Reconstruction: 1.009946, Regularization: 0.273985\n",
      "2019-04-09 21:39:50,717 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 0.449363\n",
      "Reconstruction: 0.136146, Regularization: 0.313217\n",
      "2019-04-09 21:39:50,763 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 0.447878\n",
      "Reconstruction: 0.167183, Regularization: 0.280694\n",
      "2019-04-09 21:39:50,816 root         INFO     ====> Epoch: 2 Average loss: 4.8308\n",
      "2019-04-09 21:39:50,839 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 2.202415\n",
      "Reconstruction: 1.914663, Regularization: 0.287752\n",
      "2019-04-09 21:39:50,885 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 0.620813\n",
      "Reconstruction: 0.336360, Regularization: 0.284454\n",
      "2019-04-09 21:39:50,928 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 0.716468\n",
      "Reconstruction: 0.399079, Regularization: 0.317388\n",
      "2019-04-09 21:39:50,972 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 0.747487\n",
      "Reconstruction: 0.501912, Regularization: 0.245575\n",
      "2019-04-09 21:39:51,016 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 1.518601\n",
      "Reconstruction: 1.171566, Regularization: 0.347035\n",
      "2019-04-09 21:39:51,059 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 0.433383\n",
      "Reconstruction: 0.180374, Regularization: 0.253009\n",
      "2019-04-09 21:39:51,100 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 0.440659\n",
      "Reconstruction: 0.131493, Regularization: 0.309165\n",
      "2019-04-09 21:39:51,142 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 0.724392\n",
      "Reconstruction: 0.434382, Regularization: 0.290010\n",
      "2019-04-09 21:39:51,191 root         INFO     ====> Epoch: 3 Average loss: 1.3558\n",
      "2019-04-09 21:39:51,215 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 1.219675\n",
      "Reconstruction: 0.893839, Regularization: 0.325837\n",
      "2019-04-09 21:39:51,260 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 0.796424\n",
      "Reconstruction: 0.438964, Regularization: 0.357460\n",
      "2019-04-09 21:39:51,304 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 0.422733\n",
      "Reconstruction: 0.169906, Regularization: 0.252826\n",
      "2019-04-09 21:39:51,349 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 3.760892\n",
      "Reconstruction: 3.481640, Regularization: 0.279252\n",
      "2019-04-09 21:39:51,393 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 1.229913\n",
      "Reconstruction: 0.899927, Regularization: 0.329986\n",
      "2019-04-09 21:39:51,437 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 0.600032\n",
      "Reconstruction: 0.312625, Regularization: 0.287408\n",
      "2019-04-09 21:39:51,482 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 2.101268\n",
      "Reconstruction: 1.767367, Regularization: 0.333901\n",
      "2019-04-09 21:39:51,526 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 0.371347\n",
      "Reconstruction: 0.111081, Regularization: 0.260266\n",
      "2019-04-09 21:39:51,577 root         INFO     ====> Epoch: 4 Average loss: 4.4653\n",
      "2019-04-09 21:39:51,600 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 0.854832\n",
      "Reconstruction: 0.537269, Regularization: 0.317563\n",
      "2019-04-09 21:39:51,645 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 0.361802\n",
      "Reconstruction: 0.093246, Regularization: 0.268556\n",
      "2019-04-09 21:39:51,689 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 216.665344\n",
      "Reconstruction: 216.369034, Regularization: 0.296305\n",
      "2019-04-09 21:39:51,733 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 0.430098\n",
      "Reconstruction: 0.146209, Regularization: 0.283889\n",
      "2019-04-09 21:39:51,778 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 2.693475\n",
      "Reconstruction: 2.296961, Regularization: 0.396514\n",
      "2019-04-09 21:39:51,823 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 0.439263\n",
      "Reconstruction: 0.198226, Regularization: 0.241037\n",
      "2019-04-09 21:39:51,867 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 0.677833\n",
      "Reconstruction: 0.410120, Regularization: 0.267713\n",
      "2019-04-09 21:39:51,911 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 0.453251\n",
      "Reconstruction: 0.157402, Regularization: 0.295849\n",
      "2019-04-09 21:39:51,961 root         INFO     ====> Epoch: 5 Average loss: 2.9900\n",
      "2019-04-09 21:39:51,984 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 0.637460\n",
      "Reconstruction: 0.326680, Regularization: 0.310779\n",
      "2019-04-09 21:39:52,028 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 0.836496\n",
      "Reconstruction: 0.484561, Regularization: 0.351934\n",
      "2019-04-09 21:39:52,072 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 0.687299\n",
      "Reconstruction: 0.430800, Regularization: 0.256499\n",
      "2019-04-09 21:39:52,118 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 2.174881\n",
      "Reconstruction: 1.874374, Regularization: 0.300507\n",
      "2019-04-09 21:39:52,163 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 0.517611\n",
      "Reconstruction: 0.141343, Regularization: 0.376268\n",
      "2019-04-09 21:39:52,208 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 0.433772\n",
      "Reconstruction: 0.124009, Regularization: 0.309763\n",
      "2019-04-09 21:39:52,254 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 0.477840\n",
      "Reconstruction: 0.178316, Regularization: 0.299523\n",
      "2019-04-09 21:39:52,299 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 0.515321\n",
      "Reconstruction: 0.180815, Regularization: 0.334506\n",
      "2019-04-09 21:39:52,351 root         INFO     ====> Epoch: 6 Average loss: 1.4727\n",
      "2019-04-09 21:39:52,374 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 1.103922\n",
      "Reconstruction: 0.796949, Regularization: 0.306973\n",
      "2019-04-09 21:39:52,420 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 0.733382\n",
      "Reconstruction: 0.407080, Regularization: 0.326302\n",
      "2019-04-09 21:39:52,464 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 23.307377\n",
      "Reconstruction: 22.935072, Regularization: 0.372304\n",
      "2019-04-09 21:39:52,510 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 0.842481\n",
      "Reconstruction: 0.571844, Regularization: 0.270636\n",
      "2019-04-09 21:39:52,555 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 0.692333\n",
      "Reconstruction: 0.416911, Regularization: 0.275421\n",
      "2019-04-09 21:39:52,600 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 0.496687\n",
      "Reconstruction: 0.163884, Regularization: 0.332803\n",
      "2019-04-09 21:39:52,645 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 0.404062\n",
      "Reconstruction: 0.144290, Regularization: 0.259772\n",
      "2019-04-09 21:39:52,691 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 0.385669\n",
      "Reconstruction: 0.105531, Regularization: 0.280138\n",
      "2019-04-09 21:39:52,742 root         INFO     ====> Epoch: 7 Average loss: 1.0510\n",
      "2019-04-09 21:39:52,765 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 0.440479\n",
      "Reconstruction: 0.161038, Regularization: 0.279442\n",
      "2019-04-09 21:39:52,811 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 0.442364\n",
      "Reconstruction: 0.109461, Regularization: 0.332903\n",
      "2019-04-09 21:39:52,856 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 0.806081\n",
      "Reconstruction: 0.552366, Regularization: 0.253715\n",
      "2019-04-09 21:39:52,901 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 0.477313\n",
      "Reconstruction: 0.181691, Regularization: 0.295623\n",
      "2019-04-09 21:39:52,947 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 0.428328\n",
      "Reconstruction: 0.173531, Regularization: 0.254797\n",
      "2019-04-09 21:39:52,992 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 0.399987\n",
      "Reconstruction: 0.185972, Regularization: 0.214015\n",
      "2019-04-09 21:39:53,037 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 0.552940\n",
      "Reconstruction: 0.253011, Regularization: 0.299930\n",
      "2019-04-09 21:39:53,083 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 1.645180\n",
      "Reconstruction: 1.449370, Regularization: 0.195810\n",
      "2019-04-09 21:39:53,134 root         INFO     ====> Epoch: 8 Average loss: 2.0557\n",
      "2019-04-09 21:39:53,157 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 0.452358\n",
      "Reconstruction: 0.121936, Regularization: 0.330422\n",
      "2019-04-09 21:39:53,203 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 0.880939\n",
      "Reconstruction: 0.561355, Regularization: 0.319583\n",
      "2019-04-09 21:39:53,248 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 0.478961\n",
      "Reconstruction: 0.182664, Regularization: 0.296296\n",
      "2019-04-09 21:39:53,294 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 0.596442\n",
      "Reconstruction: 0.181385, Regularization: 0.415057\n",
      "2019-04-09 21:39:53,339 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 0.611542\n",
      "Reconstruction: 0.294224, Regularization: 0.317318\n",
      "2019-04-09 21:39:53,385 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 0.407538\n",
      "Reconstruction: 0.092413, Regularization: 0.315125\n",
      "2019-04-09 21:39:53,430 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 0.428098\n",
      "Reconstruction: 0.137775, Regularization: 0.290323\n",
      "2019-04-09 21:39:53,476 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 0.447082\n",
      "Reconstruction: 0.163811, Regularization: 0.283271\n",
      "2019-04-09 21:39:53,527 root         INFO     ====> Epoch: 9 Average loss: 1.3347\n",
      "2019-04-09 21:39:53,550 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 0.806000\n",
      "Reconstruction: 0.492177, Regularization: 0.313823\n",
      "2019-04-09 21:39:53,596 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 0.451930\n",
      "Reconstruction: 0.102685, Regularization: 0.349244\n",
      "2019-04-09 21:39:53,642 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 0.509161\n",
      "Reconstruction: 0.178172, Regularization: 0.330989\n",
      "2019-04-09 21:39:53,686 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 0.549596\n",
      "Reconstruction: 0.314333, Regularization: 0.235263\n",
      "2019-04-09 21:39:53,730 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 0.488597\n",
      "Reconstruction: 0.145267, Regularization: 0.343331\n",
      "2019-04-09 21:39:53,775 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 0.563642\n",
      "Reconstruction: 0.197214, Regularization: 0.366429\n",
      "2019-04-09 21:39:53,819 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 0.692477\n",
      "Reconstruction: 0.364921, Regularization: 0.327556\n",
      "2019-04-09 21:39:53,864 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 0.530182\n",
      "Reconstruction: 0.149996, Regularization: 0.380186\n",
      "2019-04-09 21:39:53,915 root         INFO     ====> Epoch: 10 Average loss: 1.6260\n",
      "2019-04-09 21:39:53,938 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.565659\n",
      "Reconstruction: 0.241166, Regularization: 0.324493\n",
      "2019-04-09 21:39:53,981 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 1.176607\n",
      "Reconstruction: 0.892198, Regularization: 0.284409\n",
      "2019-04-09 21:39:54,025 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.468467\n",
      "Reconstruction: 0.251542, Regularization: 0.216926\n",
      "2019-04-09 21:39:54,069 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 0.481340\n",
      "Reconstruction: 0.199731, Regularization: 0.281610\n",
      "2019-04-09 21:39:54,113 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 0.598016\n",
      "Reconstruction: 0.278399, Regularization: 0.319617\n",
      "2019-04-09 21:39:54,157 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 0.525884\n",
      "Reconstruction: 0.215311, Regularization: 0.310573\n",
      "2019-04-09 21:39:54,201 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.448762\n",
      "Reconstruction: 0.147151, Regularization: 0.301611\n",
      "2019-04-09 21:39:54,245 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 0.489228\n",
      "Reconstruction: 0.205132, Regularization: 0.284096\n",
      "2019-04-09 21:39:54,296 root         INFO     ====> Epoch: 11 Average loss: 1.6477\n",
      "2019-04-09 21:39:54,318 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 0.473703\n",
      "Reconstruction: 0.199880, Regularization: 0.273823\n",
      "2019-04-09 21:39:54,362 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 0.575176\n",
      "Reconstruction: 0.305400, Regularization: 0.269776\n",
      "2019-04-09 21:39:54,405 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 3.277589\n",
      "Reconstruction: 3.041296, Regularization: 0.236294\n",
      "2019-04-09 21:39:54,450 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 0.587812\n",
      "Reconstruction: 0.283911, Regularization: 0.303901\n",
      "2019-04-09 21:39:54,494 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 2.116071\n",
      "Reconstruction: 1.847559, Regularization: 0.268512\n",
      "2019-04-09 21:39:54,538 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.403346\n",
      "Reconstruction: 0.109481, Regularization: 0.293866\n",
      "2019-04-09 21:39:54,582 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.457168\n",
      "Reconstruction: 0.144806, Regularization: 0.312362\n",
      "2019-04-09 21:39:54,627 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 1.843415\n",
      "Reconstruction: 1.521661, Regularization: 0.321754\n",
      "2019-04-09 21:39:54,678 root         INFO     ====> Epoch: 12 Average loss: 1.8751\n",
      "2019-04-09 21:39:54,701 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 0.403382\n",
      "Reconstruction: 0.102651, Regularization: 0.300730\n",
      "2019-04-09 21:39:54,746 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 1.113066\n",
      "Reconstruction: 0.805144, Regularization: 0.307922\n",
      "2019-04-09 21:39:54,790 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 0.566553\n",
      "Reconstruction: 0.380328, Regularization: 0.186225\n",
      "2019-04-09 21:39:54,835 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 0.613480\n",
      "Reconstruction: 0.248253, Regularization: 0.365228\n",
      "2019-04-09 21:39:54,880 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 0.349919\n",
      "Reconstruction: 0.092471, Regularization: 0.257448\n",
      "2019-04-09 21:39:54,924 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 0.584800\n",
      "Reconstruction: 0.198163, Regularization: 0.386637\n",
      "2019-04-09 21:39:54,969 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 0.474995\n",
      "Reconstruction: 0.181688, Regularization: 0.293307\n",
      "2019-04-09 21:39:55,013 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 0.442989\n",
      "Reconstruction: 0.159549, Regularization: 0.283440\n",
      "2019-04-09 21:39:55,065 root         INFO     ====> Epoch: 13 Average loss: 1.4021\n",
      "2019-04-09 21:39:55,088 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.403646\n",
      "Reconstruction: 0.109527, Regularization: 0.294118\n",
      "2019-04-09 21:39:55,133 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.397727\n",
      "Reconstruction: 0.123117, Regularization: 0.274610\n",
      "2019-04-09 21:39:55,178 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 0.439897\n",
      "Reconstruction: 0.139705, Regularization: 0.300192\n",
      "2019-04-09 21:39:55,222 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.455745\n",
      "Reconstruction: 0.107748, Regularization: 0.347997\n",
      "2019-04-09 21:39:55,267 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.465545\n",
      "Reconstruction: 0.147925, Regularization: 0.317620\n",
      "2019-04-09 21:39:55,310 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 0.436485\n",
      "Reconstruction: 0.108747, Regularization: 0.327738\n",
      "2019-04-09 21:39:55,353 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.542139\n",
      "Reconstruction: 0.226092, Regularization: 0.316047\n",
      "2019-04-09 21:39:55,397 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.457244\n",
      "Reconstruction: 0.180526, Regularization: 0.276718\n",
      "2019-04-09 21:39:55,448 root         INFO     ====> Epoch: 14 Average loss: 2.2810\n",
      "2019-04-09 21:39:55,471 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 0.492807\n",
      "Reconstruction: 0.215519, Regularization: 0.277288\n",
      "2019-04-09 21:39:55,516 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 0.659000\n",
      "Reconstruction: 0.363349, Regularization: 0.295651\n",
      "2019-04-09 21:39:55,561 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.389729\n",
      "Reconstruction: 0.120728, Regularization: 0.269001\n",
      "2019-04-09 21:39:55,606 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.526370\n",
      "Reconstruction: 0.297036, Regularization: 0.229335\n",
      "2019-04-09 21:39:55,650 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.377538\n",
      "Reconstruction: 0.110802, Regularization: 0.266737\n",
      "2019-04-09 21:39:55,695 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.479285\n",
      "Reconstruction: 0.176531, Regularization: 0.302754\n",
      "2019-04-09 21:39:55,739 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.483921\n",
      "Reconstruction: 0.207804, Regularization: 0.276117\n",
      "2019-04-09 21:39:55,784 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 0.503852\n",
      "Reconstruction: 0.262045, Regularization: 0.241807\n",
      "2019-04-09 21:39:55,836 root         INFO     ====> Epoch: 15 Average loss: 2.3037\n",
      "2019-04-09 21:39:55,858 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 0.367555\n",
      "Reconstruction: 0.105413, Regularization: 0.262142\n",
      "2019-04-09 21:39:55,904 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 0.514773\n",
      "Reconstruction: 0.196556, Regularization: 0.318217\n",
      "2019-04-09 21:39:55,949 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.619504\n",
      "Reconstruction: 0.350564, Regularization: 0.268940\n",
      "2019-04-09 21:39:55,994 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 0.413607\n",
      "Reconstruction: 0.148109, Regularization: 0.265498\n",
      "2019-04-09 21:39:56,039 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 0.419122\n",
      "Reconstruction: 0.145217, Regularization: 0.273904\n",
      "2019-04-09 21:39:56,084 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 0.542975\n",
      "Reconstruction: 0.261877, Regularization: 0.281098\n",
      "2019-04-09 21:39:56,129 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 0.566625\n",
      "Reconstruction: 0.245737, Regularization: 0.320888\n",
      "2019-04-09 21:39:56,175 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.472922\n",
      "Reconstruction: 0.140891, Regularization: 0.332031\n",
      "2019-04-09 21:39:56,226 root         INFO     ====> Epoch: 16 Average loss: 0.8733\n",
      "2019-04-09 21:39:56,249 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.549945\n",
      "Reconstruction: 0.320228, Regularization: 0.229717\n",
      "2019-04-09 21:39:56,294 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 0.611738\n",
      "Reconstruction: 0.379474, Regularization: 0.232264\n",
      "2019-04-09 21:39:56,339 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.403673\n",
      "Reconstruction: 0.130146, Regularization: 0.273527\n",
      "2019-04-09 21:39:56,383 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 0.473532\n",
      "Reconstruction: 0.182448, Regularization: 0.291084\n",
      "2019-04-09 21:39:56,428 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.800021\n",
      "Reconstruction: 0.538741, Regularization: 0.261280\n",
      "2019-04-09 21:39:56,472 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 1.642601\n",
      "Reconstruction: 1.223656, Regularization: 0.418944\n",
      "2019-04-09 21:39:56,517 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 0.483433\n",
      "Reconstruction: 0.247716, Regularization: 0.235717\n",
      "2019-04-09 21:39:56,561 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 0.726325\n",
      "Reconstruction: 0.436665, Regularization: 0.289660\n",
      "2019-04-09 21:39:56,612 root         INFO     ====> Epoch: 17 Average loss: 1.4487\n",
      "2019-04-09 21:39:56,635 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 0.433315\n",
      "Reconstruction: 0.120171, Regularization: 0.313143\n",
      "2019-04-09 21:39:56,680 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.471630\n",
      "Reconstruction: 0.151678, Regularization: 0.319952\n",
      "2019-04-09 21:39:56,725 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 0.563250\n",
      "Reconstruction: 0.215245, Regularization: 0.348004\n",
      "2019-04-09 21:39:56,769 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.427934\n",
      "Reconstruction: 0.125001, Regularization: 0.302933\n",
      "2019-04-09 21:39:56,814 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 0.913640\n",
      "Reconstruction: 0.634597, Regularization: 0.279043\n",
      "2019-04-09 21:39:56,859 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.508942\n",
      "Reconstruction: 0.184169, Regularization: 0.324774\n",
      "2019-04-09 21:39:56,904 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 0.541602\n",
      "Reconstruction: 0.286189, Regularization: 0.255413\n",
      "2019-04-09 21:39:56,948 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 0.417932\n",
      "Reconstruction: 0.112313, Regularization: 0.305619\n",
      "2019-04-09 21:39:56,999 root         INFO     ====> Epoch: 18 Average loss: 1.0194\n",
      "2019-04-09 21:39:57,022 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 0.432864\n",
      "Reconstruction: 0.144474, Regularization: 0.288389\n",
      "2019-04-09 21:39:57,067 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 0.474077\n",
      "Reconstruction: 0.198646, Regularization: 0.275431\n",
      "2019-04-09 21:39:57,113 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 0.467935\n",
      "Reconstruction: 0.186546, Regularization: 0.281389\n",
      "2019-04-09 21:39:57,158 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 16.353205\n",
      "Reconstruction: 16.031498, Regularization: 0.321707\n",
      "2019-04-09 21:39:57,203 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 0.644961\n",
      "Reconstruction: 0.352796, Regularization: 0.292165\n",
      "2019-04-09 21:39:57,247 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 0.975369\n",
      "Reconstruction: 0.656518, Regularization: 0.318851\n",
      "2019-04-09 21:39:57,291 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 0.639263\n",
      "Reconstruction: 0.351756, Regularization: 0.287507\n",
      "2019-04-09 21:39:57,335 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.537755\n",
      "Reconstruction: 0.265165, Regularization: 0.272590\n",
      "2019-04-09 21:39:57,386 root         INFO     ====> Epoch: 19 Average loss: 0.8883\n",
      "2019-04-09 21:39:57,408 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 1.009915\n",
      "Reconstruction: 0.676123, Regularization: 0.333792\n",
      "2019-04-09 21:39:57,453 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 0.642839\n",
      "Reconstruction: 0.319181, Regularization: 0.323658\n",
      "2019-04-09 21:39:57,498 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 0.584391\n",
      "Reconstruction: 0.309221, Regularization: 0.275170\n",
      "2019-04-09 21:39:57,543 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 0.459658\n",
      "Reconstruction: 0.115126, Regularization: 0.344533\n",
      "2019-04-09 21:39:57,588 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 1.810740\n",
      "Reconstruction: 1.560259, Regularization: 0.250480\n",
      "2019-04-09 21:39:57,633 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 0.634298\n",
      "Reconstruction: 0.281957, Regularization: 0.352341\n",
      "2019-04-09 21:39:57,678 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 2.359624\n",
      "Reconstruction: 2.062282, Regularization: 0.297342\n",
      "2019-04-09 21:39:57,723 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 1.682538\n",
      "Reconstruction: 1.383554, Regularization: 0.298985\n",
      "2019-04-09 21:39:57,775 root         INFO     ====> Epoch: 20 Average loss: 1.0455\n",
      "2019-04-09 21:39:57,798 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.385658\n",
      "Reconstruction: 0.158892, Regularization: 0.226766\n",
      "2019-04-09 21:39:57,843 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 0.521510\n",
      "Reconstruction: 0.266364, Regularization: 0.255145\n",
      "2019-04-09 21:39:57,889 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 52.705833\n",
      "Reconstruction: 52.337341, Regularization: 0.368491\n",
      "2019-04-09 21:39:57,934 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 0.472963\n",
      "Reconstruction: 0.167556, Regularization: 0.305406\n",
      "2019-04-09 21:39:57,980 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.868738\n",
      "Reconstruction: 0.555829, Regularization: 0.312909\n",
      "2019-04-09 21:39:58,026 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 0.503615\n",
      "Reconstruction: 0.239833, Regularization: 0.263783\n",
      "2019-04-09 21:39:58,072 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 0.612543\n",
      "Reconstruction: 0.286259, Regularization: 0.326284\n",
      "2019-04-09 21:39:58,118 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.433393\n",
      "Reconstruction: 0.135032, Regularization: 0.298361\n",
      "2019-04-09 21:39:58,171 root         INFO     ====> Epoch: 21 Average loss: 1.2632\n",
      "2019-04-09 21:39:58,194 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 0.745172\n",
      "Reconstruction: 0.426042, Regularization: 0.319130\n",
      "2019-04-09 21:39:58,239 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 0.452665\n",
      "Reconstruction: 0.147497, Regularization: 0.305168\n",
      "2019-04-09 21:39:58,284 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 7.784251\n",
      "Reconstruction: 7.447630, Regularization: 0.336620\n",
      "2019-04-09 21:39:58,330 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 0.538800\n",
      "Reconstruction: 0.218451, Regularization: 0.320349\n",
      "2019-04-09 21:39:58,375 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.436466\n",
      "Reconstruction: 0.148547, Regularization: 0.287919\n",
      "2019-04-09 21:39:58,421 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 0.680612\n",
      "Reconstruction: 0.397661, Regularization: 0.282951\n",
      "2019-04-09 21:39:58,466 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 0.416983\n",
      "Reconstruction: 0.126491, Regularization: 0.290492\n",
      "2019-04-09 21:39:58,512 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 0.623528\n",
      "Reconstruction: 0.216042, Regularization: 0.407486\n",
      "2019-04-09 21:39:58,564 root         INFO     ====> Epoch: 22 Average loss: 1.2652\n",
      "2019-04-09 21:39:58,587 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 0.506745\n",
      "Reconstruction: 0.198820, Regularization: 0.307925\n",
      "2019-04-09 21:39:58,632 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 0.421332\n",
      "Reconstruction: 0.125797, Regularization: 0.295535\n",
      "2019-04-09 21:39:58,678 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 0.431850\n",
      "Reconstruction: 0.138571, Regularization: 0.293280\n",
      "2019-04-09 21:39:58,722 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 0.782913\n",
      "Reconstruction: 0.455607, Regularization: 0.327305\n",
      "2019-04-09 21:39:58,766 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 0.427548\n",
      "Reconstruction: 0.157079, Regularization: 0.270469\n",
      "2019-04-09 21:39:58,809 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 0.413220\n",
      "Reconstruction: 0.114033, Regularization: 0.299187\n",
      "2019-04-09 21:39:58,854 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 0.412942\n",
      "Reconstruction: 0.111380, Regularization: 0.301562\n",
      "2019-04-09 21:39:58,897 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 0.601448\n",
      "Reconstruction: 0.267318, Regularization: 0.334130\n",
      "2019-04-09 21:39:58,949 root         INFO     ====> Epoch: 23 Average loss: 0.8269\n",
      "2019-04-09 21:39:58,971 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.389889\n",
      "Reconstruction: 0.140411, Regularization: 0.249477\n",
      "2019-04-09 21:39:59,017 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 0.543441\n",
      "Reconstruction: 0.276641, Regularization: 0.266800\n",
      "2019-04-09 21:39:59,062 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 0.564151\n",
      "Reconstruction: 0.290177, Regularization: 0.273974\n",
      "2019-04-09 21:39:59,106 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 0.454659\n",
      "Reconstruction: 0.188020, Regularization: 0.266639\n",
      "2019-04-09 21:39:59,151 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 0.398220\n",
      "Reconstruction: 0.102790, Regularization: 0.295431\n",
      "2019-04-09 21:39:59,196 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 0.610392\n",
      "Reconstruction: 0.339512, Regularization: 0.270880\n",
      "2019-04-09 21:39:59,241 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 2.714440\n",
      "Reconstruction: 2.434281, Regularization: 0.280159\n",
      "2019-04-09 21:39:59,286 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 2.081657\n",
      "Reconstruction: 1.696607, Regularization: 0.385050\n",
      "2019-04-09 21:39:59,338 root         INFO     ====> Epoch: 24 Average loss: 1.1951\n",
      "2019-04-09 21:39:59,360 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 0.506180\n",
      "Reconstruction: 0.211286, Regularization: 0.294894\n",
      "2019-04-09 21:39:59,404 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 0.660004\n",
      "Reconstruction: 0.278812, Regularization: 0.381192\n",
      "2019-04-09 21:39:59,449 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 0.483748\n",
      "Reconstruction: 0.124209, Regularization: 0.359539\n",
      "2019-04-09 21:39:59,493 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 0.477397\n",
      "Reconstruction: 0.228709, Regularization: 0.248688\n",
      "2019-04-09 21:39:59,537 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 0.561287\n",
      "Reconstruction: 0.292819, Regularization: 0.268468\n",
      "2019-04-09 21:39:59,581 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 0.522198\n",
      "Reconstruction: 0.238326, Regularization: 0.283872\n",
      "2019-04-09 21:39:59,626 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.698388\n",
      "Reconstruction: 0.439206, Regularization: 0.259183\n",
      "2019-04-09 21:39:59,671 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 0.471397\n",
      "Reconstruction: 0.106503, Regularization: 0.364894\n",
      "2019-04-09 21:39:59,723 root         INFO     ====> Epoch: 25 Average loss: 0.8657\n",
      "2019-04-09 21:39:59,745 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 0.402914\n",
      "Reconstruction: 0.104757, Regularization: 0.298156\n",
      "2019-04-09 21:39:59,791 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 0.820669\n",
      "Reconstruction: 0.573282, Regularization: 0.247386\n",
      "2019-04-09 21:39:59,836 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 0.496286\n",
      "Reconstruction: 0.193361, Regularization: 0.302925\n",
      "2019-04-09 21:39:59,882 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 1.958085\n",
      "Reconstruction: 1.678018, Regularization: 0.280067\n",
      "2019-04-09 21:39:59,927 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.399993\n",
      "Reconstruction: 0.125487, Regularization: 0.274505\n",
      "2019-04-09 21:39:59,973 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 0.488302\n",
      "Reconstruction: 0.164236, Regularization: 0.324067\n",
      "2019-04-09 21:40:00,017 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 0.574797\n",
      "Reconstruction: 0.225248, Regularization: 0.349550\n",
      "2019-04-09 21:40:00,061 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 0.347403\n",
      "Reconstruction: 0.098333, Regularization: 0.249071\n",
      "2019-04-09 21:40:00,112 root         INFO     ====> Epoch: 26 Average loss: 1.0328\n",
      "2019-04-09 21:40:00,134 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 1.059035\n",
      "Reconstruction: 0.754625, Regularization: 0.304410\n",
      "2019-04-09 21:40:00,180 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.391889\n",
      "Reconstruction: 0.103530, Regularization: 0.288359\n",
      "2019-04-09 21:40:00,226 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 0.443598\n",
      "Reconstruction: 0.153850, Regularization: 0.289748\n",
      "2019-04-09 21:40:00,271 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.450078\n",
      "Reconstruction: 0.187903, Regularization: 0.262174\n",
      "2019-04-09 21:40:00,317 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 0.434143\n",
      "Reconstruction: 0.142935, Regularization: 0.291208\n",
      "2019-04-09 21:40:00,363 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.373116\n",
      "Reconstruction: 0.112314, Regularization: 0.260802\n",
      "2019-04-09 21:40:00,408 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.516960\n",
      "Reconstruction: 0.104193, Regularization: 0.412767\n",
      "2019-04-09 21:40:00,453 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 0.485602\n",
      "Reconstruction: 0.144658, Regularization: 0.340944\n",
      "2019-04-09 21:40:00,506 root         INFO     ====> Epoch: 27 Average loss: 0.7475\n",
      "2019-04-09 21:40:00,529 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.763496\n",
      "Reconstruction: 0.390023, Regularization: 0.373473\n",
      "2019-04-09 21:40:00,574 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.418206\n",
      "Reconstruction: 0.132375, Regularization: 0.285832\n",
      "2019-04-09 21:40:00,618 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 0.490192\n",
      "Reconstruction: 0.183138, Regularization: 0.307053\n",
      "2019-04-09 21:40:00,662 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.424477\n",
      "Reconstruction: 0.124147, Regularization: 0.300330\n",
      "2019-04-09 21:40:00,706 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.439597\n",
      "Reconstruction: 0.178693, Regularization: 0.260904\n",
      "2019-04-09 21:40:00,750 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.382472\n",
      "Reconstruction: 0.119092, Regularization: 0.263380\n",
      "2019-04-09 21:40:00,795 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.472662\n",
      "Reconstruction: 0.131814, Regularization: 0.340848\n",
      "2019-04-09 21:40:00,839 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.425175\n",
      "Reconstruction: 0.105889, Regularization: 0.319286\n",
      "2019-04-09 21:40:00,891 root         INFO     ====> Epoch: 28 Average loss: 0.9610\n",
      "2019-04-09 21:40:00,913 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 0.458526\n",
      "Reconstruction: 0.135943, Regularization: 0.322583\n",
      "2019-04-09 21:40:00,960 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 0.460620\n",
      "Reconstruction: 0.126209, Regularization: 0.334410\n",
      "2019-04-09 21:40:01,006 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 0.701685\n",
      "Reconstruction: 0.413504, Regularization: 0.288181\n",
      "2019-04-09 21:40:01,051 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 0.389235\n",
      "Reconstruction: 0.105771, Regularization: 0.283464\n",
      "2019-04-09 21:40:01,097 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.592764\n",
      "Reconstruction: 0.306168, Regularization: 0.286596\n",
      "2019-04-09 21:40:01,143 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 0.513647\n",
      "Reconstruction: 0.170469, Regularization: 0.343178\n",
      "2019-04-09 21:40:01,188 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 0.529930\n",
      "Reconstruction: 0.224600, Regularization: 0.305331\n",
      "2019-04-09 21:40:01,233 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.401068\n",
      "Reconstruction: 0.136039, Regularization: 0.265029\n",
      "2019-04-09 21:40:01,285 root         INFO     ====> Epoch: 29 Average loss: 1.5691\n",
      "2019-04-09 21:40:01,308 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.470685\n",
      "Reconstruction: 0.217517, Regularization: 0.253167\n",
      "2019-04-09 21:40:01,354 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.392242\n",
      "Reconstruction: 0.122374, Regularization: 0.269869\n",
      "2019-04-09 21:40:01,400 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.476810\n",
      "Reconstruction: 0.146882, Regularization: 0.329928\n",
      "2019-04-09 21:40:01,446 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.362410\n",
      "Reconstruction: 0.101581, Regularization: 0.260829\n",
      "2019-04-09 21:40:01,492 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.487577\n",
      "Reconstruction: 0.138032, Regularization: 0.349545\n",
      "2019-04-09 21:40:01,546 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.506992\n",
      "Reconstruction: 0.269160, Regularization: 0.237831\n",
      "2019-04-09 21:40:01,606 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.427298\n",
      "Reconstruction: 0.161584, Regularization: 0.265714\n",
      "2019-04-09 21:40:01,652 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 0.312520\n",
      "Reconstruction: 0.109051, Regularization: 0.203469\n",
      "2019-04-09 21:40:01,704 root         INFO     ====> Epoch: 30 Average loss: 0.9996\n",
      "2019-04-09 21:40:01,726 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.435648\n",
      "Reconstruction: 0.135201, Regularization: 0.300447\n",
      "2019-04-09 21:40:01,772 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.610688\n",
      "Reconstruction: 0.290030, Regularization: 0.320659\n",
      "2019-04-09 21:40:01,817 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 0.354222\n",
      "Reconstruction: 0.114296, Regularization: 0.239927\n",
      "2019-04-09 21:40:01,861 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.620145\n",
      "Reconstruction: 0.291426, Regularization: 0.328720\n",
      "2019-04-09 21:40:01,905 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.373196\n",
      "Reconstruction: 0.141872, Regularization: 0.231324\n",
      "2019-04-09 21:40:01,948 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.425917\n",
      "Reconstruction: 0.138190, Regularization: 0.287728\n",
      "2019-04-09 21:40:01,992 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 0.618886\n",
      "Reconstruction: 0.243621, Regularization: 0.375265\n",
      "2019-04-09 21:40:02,035 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 1.699128\n",
      "Reconstruction: 1.351932, Regularization: 0.347196\n",
      "2019-04-09 21:40:02,086 root         INFO     ====> Epoch: 31 Average loss: 0.7422\n",
      "2019-04-09 21:40:02,108 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.505812\n",
      "Reconstruction: 0.234983, Regularization: 0.270829\n",
      "2019-04-09 21:40:02,152 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.473199\n",
      "Reconstruction: 0.196679, Regularization: 0.276520\n",
      "2019-04-09 21:40:02,197 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.396550\n",
      "Reconstruction: 0.159820, Regularization: 0.236730\n",
      "2019-04-09 21:40:02,241 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.405434\n",
      "Reconstruction: 0.111892, Regularization: 0.293542\n",
      "2019-04-09 21:40:02,285 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.442992\n",
      "Reconstruction: 0.123780, Regularization: 0.319212\n",
      "2019-04-09 21:40:02,329 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 0.405872\n",
      "Reconstruction: 0.135007, Regularization: 0.270866\n",
      "2019-04-09 21:40:02,374 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.390022\n",
      "Reconstruction: 0.114073, Regularization: 0.275948\n",
      "2019-04-09 21:40:02,418 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.634946\n",
      "Reconstruction: 0.332483, Regularization: 0.302463\n",
      "2019-04-09 21:40:02,470 root         INFO     ====> Epoch: 32 Average loss: 0.8831\n",
      "2019-04-09 21:40:02,494 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.806267\n",
      "Reconstruction: 0.465158, Regularization: 0.341109\n",
      "2019-04-09 21:40:02,539 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.398079\n",
      "Reconstruction: 0.101502, Regularization: 0.296576\n",
      "2019-04-09 21:40:02,584 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.444624\n",
      "Reconstruction: 0.135260, Regularization: 0.309364\n",
      "2019-04-09 21:40:02,630 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.502373\n",
      "Reconstruction: 0.252067, Regularization: 0.250306\n",
      "2019-04-09 21:40:02,675 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 0.383146\n",
      "Reconstruction: 0.165790, Regularization: 0.217356\n",
      "2019-04-09 21:40:02,720 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.471515\n",
      "Reconstruction: 0.187542, Regularization: 0.283973\n",
      "2019-04-09 21:40:02,766 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 4.623222\n",
      "Reconstruction: 4.277069, Regularization: 0.346153\n",
      "2019-04-09 21:40:02,810 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.409540\n",
      "Reconstruction: 0.107792, Regularization: 0.301749\n",
      "2019-04-09 21:40:02,863 root         INFO     ====> Epoch: 33 Average loss: 0.6978\n",
      "2019-04-09 21:40:02,886 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.407895\n",
      "Reconstruction: 0.123619, Regularization: 0.284276\n",
      "2019-04-09 21:40:02,930 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.420314\n",
      "Reconstruction: 0.146357, Regularization: 0.273957\n",
      "2019-04-09 21:40:02,975 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.357622\n",
      "Reconstruction: 0.143451, Regularization: 0.214171\n",
      "2019-04-09 21:40:03,021 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.701443\n",
      "Reconstruction: 0.392345, Regularization: 0.309098\n",
      "2019-04-09 21:40:03,066 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.414623\n",
      "Reconstruction: 0.174631, Regularization: 0.239992\n",
      "2019-04-09 21:40:03,111 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.522611\n",
      "Reconstruction: 0.216617, Regularization: 0.305993\n",
      "2019-04-09 21:40:03,156 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.530575\n",
      "Reconstruction: 0.227705, Regularization: 0.302870\n",
      "2019-04-09 21:40:03,201 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 0.426313\n",
      "Reconstruction: 0.155146, Regularization: 0.271167\n",
      "2019-04-09 21:40:03,253 root         INFO     ====> Epoch: 34 Average loss: 1.3046\n",
      "2019-04-09 21:40:03,276 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.431009\n",
      "Reconstruction: 0.118988, Regularization: 0.312021\n",
      "2019-04-09 21:40:03,321 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.592774\n",
      "Reconstruction: 0.287323, Regularization: 0.305451\n",
      "2019-04-09 21:40:03,367 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.458455\n",
      "Reconstruction: 0.156149, Regularization: 0.302306\n",
      "2019-04-09 21:40:03,412 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.322783\n",
      "Reconstruction: 0.109286, Regularization: 0.213497\n",
      "2019-04-09 21:40:03,459 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.389914\n",
      "Reconstruction: 0.103053, Regularization: 0.286861\n",
      "2019-04-09 21:40:03,503 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.567566\n",
      "Reconstruction: 0.222782, Regularization: 0.344784\n",
      "2019-04-09 21:40:03,550 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.428139\n",
      "Reconstruction: 0.146255, Regularization: 0.281884\n",
      "2019-04-09 21:40:03,594 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.438362\n",
      "Reconstruction: 0.137452, Regularization: 0.300911\n",
      "2019-04-09 21:40:03,646 root         INFO     ====> Epoch: 35 Average loss: 1.1671\n",
      "2019-04-09 21:40:03,669 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 0.446557\n",
      "Reconstruction: 0.118284, Regularization: 0.328273\n",
      "2019-04-09 21:40:03,715 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.473472\n",
      "Reconstruction: 0.165853, Regularization: 0.307618\n",
      "2019-04-09 21:40:03,760 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.453587\n",
      "Reconstruction: 0.177057, Regularization: 0.276530\n",
      "2019-04-09 21:40:03,803 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.526718\n",
      "Reconstruction: 0.213906, Regularization: 0.312812\n",
      "2019-04-09 21:40:03,848 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.457108\n",
      "Reconstruction: 0.207492, Regularization: 0.249617\n",
      "2019-04-09 21:40:03,892 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.392958\n",
      "Reconstruction: 0.110562, Regularization: 0.282396\n",
      "2019-04-09 21:40:03,938 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 0.796534\n",
      "Reconstruction: 0.533602, Regularization: 0.262932\n",
      "2019-04-09 21:40:03,983 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.430930\n",
      "Reconstruction: 0.101760, Regularization: 0.329170\n",
      "2019-04-09 21:40:04,034 root         INFO     ====> Epoch: 36 Average loss: 0.6970\n",
      "2019-04-09 21:40:04,056 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.446392\n",
      "Reconstruction: 0.131095, Regularization: 0.315297\n",
      "2019-04-09 21:40:04,103 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.469937\n",
      "Reconstruction: 0.130332, Regularization: 0.339606\n",
      "2019-04-09 21:40:04,147 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.492628\n",
      "Reconstruction: 0.253139, Regularization: 0.239488\n",
      "2019-04-09 21:40:04,191 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 0.406511\n",
      "Reconstruction: 0.108108, Regularization: 0.298403\n",
      "2019-04-09 21:40:04,237 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.464546\n",
      "Reconstruction: 0.127073, Regularization: 0.337474\n",
      "2019-04-09 21:40:04,281 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.351885\n",
      "Reconstruction: 0.096468, Regularization: 0.255417\n",
      "2019-04-09 21:40:04,325 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.580982\n",
      "Reconstruction: 0.305026, Regularization: 0.275956\n",
      "2019-04-09 21:40:04,370 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.409090\n",
      "Reconstruction: 0.139421, Regularization: 0.269668\n",
      "2019-04-09 21:40:04,422 root         INFO     ====> Epoch: 37 Average loss: 0.8144\n",
      "2019-04-09 21:40:04,445 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.389183\n",
      "Reconstruction: 0.143696, Regularization: 0.245487\n",
      "2019-04-09 21:40:04,492 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.425375\n",
      "Reconstruction: 0.106297, Regularization: 0.319078\n",
      "2019-04-09 21:40:04,538 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.413268\n",
      "Reconstruction: 0.102571, Regularization: 0.310697\n",
      "2019-04-09 21:40:04,584 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 0.693241\n",
      "Reconstruction: 0.406046, Regularization: 0.287194\n",
      "2019-04-09 21:40:04,631 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.452365\n",
      "Reconstruction: 0.123854, Regularization: 0.328510\n",
      "2019-04-09 21:40:04,677 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.462711\n",
      "Reconstruction: 0.164417, Regularization: 0.298294\n",
      "2019-04-09 21:40:04,721 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.571746\n",
      "Reconstruction: 0.225167, Regularization: 0.346579\n",
      "2019-04-09 21:40:04,765 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.379504\n",
      "Reconstruction: 0.162236, Regularization: 0.217268\n",
      "2019-04-09 21:40:04,820 root         INFO     ====> Epoch: 38 Average loss: 0.6869\n",
      "2019-04-09 21:40:04,843 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 0.902469\n",
      "Reconstruction: 0.616768, Regularization: 0.285701\n",
      "2019-04-09 21:40:04,891 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.609244\n",
      "Reconstruction: 0.351758, Regularization: 0.257486\n",
      "2019-04-09 21:40:04,938 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.421497\n",
      "Reconstruction: 0.107874, Regularization: 0.313623\n",
      "2019-04-09 21:40:04,982 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.419504\n",
      "Reconstruction: 0.115449, Regularization: 0.304055\n",
      "2019-04-09 21:40:05,026 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.459432\n",
      "Reconstruction: 0.170498, Regularization: 0.288934\n",
      "2019-04-09 21:40:05,071 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.412753\n",
      "Reconstruction: 0.139585, Regularization: 0.273168\n",
      "2019-04-09 21:40:05,115 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.431985\n",
      "Reconstruction: 0.124461, Regularization: 0.307524\n",
      "2019-04-09 21:40:05,161 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.578790\n",
      "Reconstruction: 0.220751, Regularization: 0.358039\n",
      "2019-04-09 21:40:05,213 root         INFO     ====> Epoch: 39 Average loss: 0.7325\n",
      "2019-04-09 21:40:05,236 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.446216\n",
      "Reconstruction: 0.216374, Regularization: 0.229843\n",
      "2019-04-09 21:40:05,283 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.528195\n",
      "Reconstruction: 0.223411, Regularization: 0.304783\n",
      "2019-04-09 21:40:05,330 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.567995\n",
      "Reconstruction: 0.316202, Regularization: 0.251794\n",
      "2019-04-09 21:40:05,375 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.395124\n",
      "Reconstruction: 0.113742, Regularization: 0.281382\n",
      "2019-04-09 21:40:05,420 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.400873\n",
      "Reconstruction: 0.153231, Regularization: 0.247642\n",
      "2019-04-09 21:40:05,466 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 0.477201\n",
      "Reconstruction: 0.181401, Regularization: 0.295800\n",
      "2019-04-09 21:40:05,512 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.379515\n",
      "Reconstruction: 0.146462, Regularization: 0.233053\n",
      "2019-04-09 21:40:05,560 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.393975\n",
      "Reconstruction: 0.133220, Regularization: 0.260755\n",
      "2019-04-09 21:40:05,624 root         INFO     ====> Epoch: 40 Average loss: 0.6920\n",
      "2019-04-09 21:40:05,647 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 2.168935\n",
      "Reconstruction: 1.863379, Regularization: 0.305556\n",
      "2019-04-09 21:40:05,692 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.418372\n",
      "Reconstruction: 0.118313, Regularization: 0.300059\n",
      "2019-04-09 21:40:05,737 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 0.356150\n",
      "Reconstruction: 0.126459, Regularization: 0.229691\n",
      "2019-04-09 21:40:05,781 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.473780\n",
      "Reconstruction: 0.128446, Regularization: 0.345334\n",
      "2019-04-09 21:40:05,826 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.365472\n",
      "Reconstruction: 0.119940, Regularization: 0.245531\n",
      "2019-04-09 21:40:05,870 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 0.343626\n",
      "Reconstruction: 0.120607, Regularization: 0.223019\n",
      "2019-04-09 21:40:05,915 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.553630\n",
      "Reconstruction: 0.267271, Regularization: 0.286358\n",
      "2019-04-09 21:40:05,959 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.547083\n",
      "Reconstruction: 0.269749, Regularization: 0.277334\n",
      "2019-04-09 21:40:06,012 root         INFO     ====> Epoch: 41 Average loss: 0.6780\n",
      "2019-04-09 21:40:06,035 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.387051\n",
      "Reconstruction: 0.101745, Regularization: 0.285305\n",
      "2019-04-09 21:40:06,080 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.476339\n",
      "Reconstruction: 0.231368, Regularization: 0.244971\n",
      "2019-04-09 21:40:06,125 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.514833\n",
      "Reconstruction: 0.185875, Regularization: 0.328957\n",
      "2019-04-09 21:40:06,169 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 2.042810\n",
      "Reconstruction: 1.695892, Regularization: 0.346919\n",
      "2019-04-09 21:40:06,214 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.434046\n",
      "Reconstruction: 0.112937, Regularization: 0.321108\n",
      "2019-04-09 21:40:06,260 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.453630\n",
      "Reconstruction: 0.107990, Regularization: 0.345641\n",
      "2019-04-09 21:40:06,305 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.408240\n",
      "Reconstruction: 0.105408, Regularization: 0.302832\n",
      "2019-04-09 21:40:06,349 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.447280\n",
      "Reconstruction: 0.110299, Regularization: 0.336981\n",
      "2019-04-09 21:40:06,399 root         INFO     ====> Epoch: 42 Average loss: 0.6487\n",
      "2019-04-09 21:40:06,421 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.386735\n",
      "Reconstruction: 0.114647, Regularization: 0.272088\n",
      "2019-04-09 21:40:06,467 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.702700\n",
      "Reconstruction: 0.380462, Regularization: 0.322238\n",
      "2019-04-09 21:40:06,512 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.396445\n",
      "Reconstruction: 0.139794, Regularization: 0.256651\n",
      "2019-04-09 21:40:06,557 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.420811\n",
      "Reconstruction: 0.106374, Regularization: 0.314437\n",
      "2019-04-09 21:40:06,602 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.401661\n",
      "Reconstruction: 0.130350, Regularization: 0.271311\n",
      "2019-04-09 21:40:06,647 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.420595\n",
      "Reconstruction: 0.143079, Regularization: 0.277516\n",
      "2019-04-09 21:40:06,691 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.410388\n",
      "Reconstruction: 0.119897, Regularization: 0.290491\n",
      "2019-04-09 21:40:06,735 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.460642\n",
      "Reconstruction: 0.237737, Regularization: 0.222905\n",
      "2019-04-09 21:40:06,786 root         INFO     ====> Epoch: 43 Average loss: 0.6431\n",
      "2019-04-09 21:40:06,809 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.382874\n",
      "Reconstruction: 0.109201, Regularization: 0.273673\n",
      "2019-04-09 21:40:06,855 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.524915\n",
      "Reconstruction: 0.231653, Regularization: 0.293262\n",
      "2019-04-09 21:40:06,901 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.579165\n",
      "Reconstruction: 0.281887, Regularization: 0.297277\n",
      "2019-04-09 21:40:06,947 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.398646\n",
      "Reconstruction: 0.112238, Regularization: 0.286408\n",
      "2019-04-09 21:40:06,992 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.427114\n",
      "Reconstruction: 0.141151, Regularization: 0.285963\n",
      "2019-04-09 21:40:07,038 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.438822\n",
      "Reconstruction: 0.123618, Regularization: 0.315204\n",
      "2019-04-09 21:40:07,084 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.419198\n",
      "Reconstruction: 0.134385, Regularization: 0.284813\n",
      "2019-04-09 21:40:07,130 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.466793\n",
      "Reconstruction: 0.145711, Regularization: 0.321082\n",
      "2019-04-09 21:40:07,182 root         INFO     ====> Epoch: 44 Average loss: 0.6875\n",
      "2019-04-09 21:40:07,205 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.479382\n",
      "Reconstruction: 0.144975, Regularization: 0.334408\n",
      "2019-04-09 21:40:07,251 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 1.024496\n",
      "Reconstruction: 0.681090, Regularization: 0.343406\n",
      "2019-04-09 21:40:07,296 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.378469\n",
      "Reconstruction: 0.104001, Regularization: 0.274468\n",
      "2019-04-09 21:40:07,342 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.389141\n",
      "Reconstruction: 0.101089, Regularization: 0.288052\n",
      "2019-04-09 21:40:07,388 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.387882\n",
      "Reconstruction: 0.164365, Regularization: 0.223517\n",
      "2019-04-09 21:40:07,433 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.381323\n",
      "Reconstruction: 0.126556, Regularization: 0.254766\n",
      "2019-04-09 21:40:07,479 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.404892\n",
      "Reconstruction: 0.121594, Regularization: 0.283298\n",
      "2019-04-09 21:40:07,525 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.812448\n",
      "Reconstruction: 0.496501, Regularization: 0.315948\n",
      "2019-04-09 21:40:07,577 root         INFO     ====> Epoch: 45 Average loss: 0.6242\n",
      "2019-04-09 21:40:07,599 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.494379\n",
      "Reconstruction: 0.185741, Regularization: 0.308638\n",
      "2019-04-09 21:40:07,645 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.398884\n",
      "Reconstruction: 0.114946, Regularization: 0.283939\n",
      "2019-04-09 21:40:07,690 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.374072\n",
      "Reconstruction: 0.097877, Regularization: 0.276195\n",
      "2019-04-09 21:40:07,736 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.404306\n",
      "Reconstruction: 0.132459, Regularization: 0.271847\n",
      "2019-04-09 21:40:07,781 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.422070\n",
      "Reconstruction: 0.137174, Regularization: 0.284895\n",
      "2019-04-09 21:40:07,824 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.337874\n",
      "Reconstruction: 0.114908, Regularization: 0.222966\n",
      "2019-04-09 21:40:07,869 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.409090\n",
      "Reconstruction: 0.131592, Regularization: 0.277498\n",
      "2019-04-09 21:40:07,912 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.855571\n",
      "Reconstruction: 0.494535, Regularization: 0.361036\n",
      "2019-04-09 21:40:07,963 root         INFO     ====> Epoch: 46 Average loss: 0.6378\n",
      "2019-04-09 21:40:07,986 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.444590\n",
      "Reconstruction: 0.191952, Regularization: 0.252638\n",
      "2019-04-09 21:40:08,031 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.494409\n",
      "Reconstruction: 0.125688, Regularization: 0.368721\n",
      "2019-04-09 21:40:08,077 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.423228\n",
      "Reconstruction: 0.128736, Regularization: 0.294492\n",
      "2019-04-09 21:40:08,122 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.441260\n",
      "Reconstruction: 0.119205, Regularization: 0.322055\n",
      "2019-04-09 21:40:08,167 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.783811\n",
      "Reconstruction: 0.540559, Regularization: 0.243252\n",
      "2019-04-09 21:40:08,213 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.376613\n",
      "Reconstruction: 0.125610, Regularization: 0.251004\n",
      "2019-04-09 21:40:08,256 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.512335\n",
      "Reconstruction: 0.141470, Regularization: 0.370865\n",
      "2019-04-09 21:40:08,299 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.575730\n",
      "Reconstruction: 0.242132, Regularization: 0.333598\n",
      "2019-04-09 21:40:08,349 root         INFO     ====> Epoch: 47 Average loss: 0.8035\n",
      "2019-04-09 21:40:08,371 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 5.332050\n",
      "Reconstruction: 5.044722, Regularization: 0.287329\n",
      "2019-04-09 21:40:08,416 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.440545\n",
      "Reconstruction: 0.113668, Regularization: 0.326877\n",
      "2019-04-09 21:40:08,459 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 1.881752\n",
      "Reconstruction: 1.643279, Regularization: 0.238474\n",
      "2019-04-09 21:40:08,502 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.342166\n",
      "Reconstruction: 0.099033, Regularization: 0.243133\n",
      "2019-04-09 21:40:08,546 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.398238\n",
      "Reconstruction: 0.157545, Regularization: 0.240693\n",
      "2019-04-09 21:40:08,589 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.419926\n",
      "Reconstruction: 0.167456, Regularization: 0.252470\n",
      "2019-04-09 21:40:08,632 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.448144\n",
      "Reconstruction: 0.103889, Regularization: 0.344255\n",
      "2019-04-09 21:40:08,675 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.480111\n",
      "Reconstruction: 0.156631, Regularization: 0.323480\n",
      "2019-04-09 21:40:08,725 root         INFO     ====> Epoch: 48 Average loss: 0.6080\n",
      "2019-04-09 21:40:08,748 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.421394\n",
      "Reconstruction: 0.117148, Regularization: 0.304246\n",
      "2019-04-09 21:40:08,793 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.406337\n",
      "Reconstruction: 0.165677, Regularization: 0.240660\n",
      "2019-04-09 21:40:08,837 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.395659\n",
      "Reconstruction: 0.113283, Regularization: 0.282376\n",
      "2019-04-09 21:40:08,882 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.446946\n",
      "Reconstruction: 0.186647, Regularization: 0.260299\n",
      "2019-04-09 21:40:08,927 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.359022\n",
      "Reconstruction: 0.137997, Regularization: 0.221024\n",
      "2019-04-09 21:40:08,972 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.358975\n",
      "Reconstruction: 0.119512, Regularization: 0.239463\n",
      "2019-04-09 21:40:09,017 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.418046\n",
      "Reconstruction: 0.102107, Regularization: 0.315939\n",
      "2019-04-09 21:40:09,061 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.598192\n",
      "Reconstruction: 0.245235, Regularization: 0.352956\n",
      "2019-04-09 21:40:09,112 root         INFO     ====> Epoch: 49 Average loss: 0.5963\n",
      "2019-04-09 21:40:09,135 root         INFO     Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 0.909866\n",
      "Reconstruction: 0.623265, Regularization: 0.286601\n",
      "2019-04-09 21:40:09,179 root         INFO     Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 0.329279\n",
      "Reconstruction: 0.101720, Regularization: 0.227559\n",
      "2019-04-09 21:40:09,222 root         INFO     Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 0.443846\n",
      "Reconstruction: 0.106174, Regularization: 0.337672\n",
      "2019-04-09 21:40:09,265 root         INFO     Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 0.532413\n",
      "Reconstruction: 0.204062, Regularization: 0.328350\n",
      "2019-04-09 21:40:09,309 root         INFO     Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 0.343559\n",
      "Reconstruction: 0.109663, Regularization: 0.233896\n",
      "2019-04-09 21:40:09,352 root         INFO     Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 3.225879\n",
      "Reconstruction: 2.856375, Regularization: 0.369505\n",
      "2019-04-09 21:40:09,395 root         INFO     Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 0.434850\n",
      "Reconstruction: 0.165760, Regularization: 0.269089\n",
      "2019-04-09 21:40:09,439 root         INFO     Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 0.412072\n",
      "Reconstruction: 0.165816, Regularization: 0.246256\n",
      "2019-04-09 21:40:09,489 root         INFO     ====> Epoch: 50 Average loss: 0.6066\n",
      "2019-04-09 21:40:09,512 root         INFO     Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 0.490714\n",
      "Reconstruction: 0.235524, Regularization: 0.255190\n",
      "2019-04-09 21:40:09,557 root         INFO     Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 0.381847\n",
      "Reconstruction: 0.131845, Regularization: 0.250001\n",
      "2019-04-09 21:40:09,603 root         INFO     Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 0.628798\n",
      "Reconstruction: 0.347318, Regularization: 0.281480\n",
      "2019-04-09 21:40:09,647 root         INFO     Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 0.368332\n",
      "Reconstruction: 0.111780, Regularization: 0.256553\n",
      "2019-04-09 21:40:09,692 root         INFO     Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 0.554136\n",
      "Reconstruction: 0.328795, Regularization: 0.225341\n",
      "2019-04-09 21:40:09,737 root         INFO     Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 0.919371\n",
      "Reconstruction: 0.625011, Regularization: 0.294360\n",
      "2019-04-09 21:40:09,782 root         INFO     Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 0.823670\n",
      "Reconstruction: 0.526585, Regularization: 0.297084\n",
      "2019-04-09 21:40:09,827 root         INFO     Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 0.581991\n",
      "Reconstruction: 0.326370, Regularization: 0.255621\n",
      "2019-04-09 21:40:09,878 root         INFO     ====> Epoch: 51 Average loss: 0.6047\n",
      "2019-04-09 21:40:09,901 root         INFO     Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 0.593263\n",
      "Reconstruction: 0.302462, Regularization: 0.290801\n",
      "2019-04-09 21:40:09,946 root         INFO     Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 0.562536\n",
      "Reconstruction: 0.228060, Regularization: 0.334476\n",
      "2019-04-09 21:40:09,991 root         INFO     Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 0.441303\n",
      "Reconstruction: 0.182483, Regularization: 0.258820\n",
      "2019-04-09 21:40:10,036 root         INFO     Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 0.493582\n",
      "Reconstruction: 0.126084, Regularization: 0.367499\n",
      "2019-04-09 21:40:10,082 root         INFO     Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 4.663587\n",
      "Reconstruction: 4.395874, Regularization: 0.267712\n",
      "2019-04-09 21:40:10,127 root         INFO     Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 0.405090\n",
      "Reconstruction: 0.099649, Regularization: 0.305441\n",
      "2019-04-09 21:40:10,172 root         INFO     Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 1.167951\n",
      "Reconstruction: 0.800982, Regularization: 0.366970\n",
      "2019-04-09 21:40:10,217 root         INFO     Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 0.421036\n",
      "Reconstruction: 0.139395, Regularization: 0.281641\n",
      "2019-04-09 21:40:10,269 root         INFO     ====> Epoch: 52 Average loss: 0.5836\n",
      "2019-04-09 21:40:10,292 root         INFO     Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 0.397707\n",
      "Reconstruction: 0.125784, Regularization: 0.271922\n",
      "2019-04-09 21:40:10,337 root         INFO     Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 0.427427\n",
      "Reconstruction: 0.170099, Regularization: 0.257327\n",
      "2019-04-09 21:40:10,383 root         INFO     Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 0.608741\n",
      "Reconstruction: 0.286517, Regularization: 0.322224\n",
      "2019-04-09 21:40:10,428 root         INFO     Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 0.473853\n",
      "Reconstruction: 0.203311, Regularization: 0.270542\n",
      "2019-04-09 21:40:10,474 root         INFO     Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 0.493363\n",
      "Reconstruction: 0.156975, Regularization: 0.336388\n",
      "2019-04-09 21:40:10,519 root         INFO     Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 0.589725\n",
      "Reconstruction: 0.330764, Regularization: 0.258960\n",
      "2019-04-09 21:40:10,565 root         INFO     Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 0.456966\n",
      "Reconstruction: 0.150089, Regularization: 0.306877\n",
      "2019-04-09 21:40:10,610 root         INFO     Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 0.663914\n",
      "Reconstruction: 0.377097, Regularization: 0.286818\n",
      "2019-04-09 21:40:10,662 root         INFO     ====> Epoch: 53 Average loss: 0.5858\n",
      "2019-04-09 21:40:10,684 root         INFO     Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 0.481341\n",
      "Reconstruction: 0.152722, Regularization: 0.328619\n",
      "2019-04-09 21:40:10,730 root         INFO     Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 0.456602\n",
      "Reconstruction: 0.165434, Regularization: 0.291167\n",
      "2019-04-09 21:40:10,776 root         INFO     Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 0.401570\n",
      "Reconstruction: 0.129266, Regularization: 0.272303\n",
      "2019-04-09 21:40:10,823 root         INFO     Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 0.436416\n",
      "Reconstruction: 0.143250, Regularization: 0.293166\n",
      "2019-04-09 21:40:10,870 root         INFO     Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 0.374585\n",
      "Reconstruction: 0.149015, Regularization: 0.225570\n",
      "2019-04-09 21:40:10,917 root         INFO     Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 0.507894\n",
      "Reconstruction: 0.142778, Regularization: 0.365117\n",
      "2019-04-09 21:40:10,964 root         INFO     Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 0.425750\n",
      "Reconstruction: 0.124660, Regularization: 0.301089\n",
      "2019-04-09 21:40:11,010 root         INFO     Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 1.082347\n",
      "Reconstruction: 0.790806, Regularization: 0.291541\n",
      "2019-04-09 21:40:11,063 root         INFO     ====> Epoch: 54 Average loss: 0.5970\n",
      "2019-04-09 21:40:11,086 root         INFO     Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 0.405260\n",
      "Reconstruction: 0.114070, Regularization: 0.291191\n",
      "2019-04-09 21:40:11,131 root         INFO     Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 1.480005\n",
      "Reconstruction: 1.180516, Regularization: 0.299489\n",
      "2019-04-09 21:40:11,176 root         INFO     Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 0.456770\n",
      "Reconstruction: 0.124494, Regularization: 0.332276\n",
      "2019-04-09 21:40:11,221 root         INFO     Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 0.387992\n",
      "Reconstruction: 0.118737, Regularization: 0.269256\n",
      "2019-04-09 21:40:11,266 root         INFO     Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 0.606238\n",
      "Reconstruction: 0.328469, Regularization: 0.277768\n",
      "2019-04-09 21:40:11,311 root         INFO     Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 0.404240\n",
      "Reconstruction: 0.119520, Regularization: 0.284719\n",
      "2019-04-09 21:40:11,355 root         INFO     Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 0.517488\n",
      "Reconstruction: 0.285967, Regularization: 0.231521\n",
      "2019-04-09 21:40:11,400 root         INFO     Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 0.435525\n",
      "Reconstruction: 0.185603, Regularization: 0.249922\n",
      "2019-04-09 21:40:11,452 root         INFO     ====> Epoch: 55 Average loss: 0.5848\n",
      "2019-04-09 21:40:11,475 root         INFO     Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 0.469352\n",
      "Reconstruction: 0.134556, Regularization: 0.334797\n",
      "2019-04-09 21:40:11,521 root         INFO     Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 0.376676\n",
      "Reconstruction: 0.133036, Regularization: 0.243641\n",
      "2019-04-09 21:40:11,566 root         INFO     Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 0.406124\n",
      "Reconstruction: 0.116850, Regularization: 0.289274\n",
      "2019-04-09 21:40:11,611 root         INFO     Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 0.424361\n",
      "Reconstruction: 0.092880, Regularization: 0.331481\n",
      "2019-04-09 21:40:11,655 root         INFO     Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 0.509742\n",
      "Reconstruction: 0.205942, Regularization: 0.303801\n",
      "2019-04-09 21:40:11,700 root         INFO     Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 0.457216\n",
      "Reconstruction: 0.169095, Regularization: 0.288120\n",
      "2019-04-09 21:40:11,745 root         INFO     Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 0.379076\n",
      "Reconstruction: 0.101553, Regularization: 0.277523\n",
      "2019-04-09 21:40:11,790 root         INFO     Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 0.473076\n",
      "Reconstruction: 0.205621, Regularization: 0.267455\n",
      "2019-04-09 21:40:11,842 root         INFO     ====> Epoch: 56 Average loss: 0.6600\n",
      "2019-04-09 21:40:11,865 root         INFO     Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 0.446855\n",
      "Reconstruction: 0.180096, Regularization: 0.266759\n",
      "2019-04-09 21:40:11,910 root         INFO     Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 0.431682\n",
      "Reconstruction: 0.176434, Regularization: 0.255247\n",
      "2019-04-09 21:40:11,956 root         INFO     Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 0.383026\n",
      "Reconstruction: 0.098031, Regularization: 0.284994\n",
      "2019-04-09 21:40:12,000 root         INFO     Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 0.485933\n",
      "Reconstruction: 0.174075, Regularization: 0.311858\n",
      "2019-04-09 21:40:12,045 root         INFO     Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 0.440781\n",
      "Reconstruction: 0.193277, Regularization: 0.247503\n",
      "2019-04-09 21:40:12,091 root         INFO     Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 0.419991\n",
      "Reconstruction: 0.157077, Regularization: 0.262914\n",
      "2019-04-09 21:40:12,136 root         INFO     Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 0.360917\n",
      "Reconstruction: 0.129127, Regularization: 0.231790\n",
      "2019-04-09 21:40:12,181 root         INFO     Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 0.479420\n",
      "Reconstruction: 0.211670, Regularization: 0.267750\n",
      "2019-04-09 21:40:12,234 root         INFO     ====> Epoch: 57 Average loss: 0.5637\n",
      "2019-04-09 21:40:12,257 root         INFO     Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 0.355074\n",
      "Reconstruction: 0.153956, Regularization: 0.201117\n",
      "2019-04-09 21:40:12,303 root         INFO     Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 10.457088\n",
      "Reconstruction: 10.130302, Regularization: 0.326786\n",
      "2019-04-09 21:40:12,349 root         INFO     Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 1.021839\n",
      "Reconstruction: 0.737659, Regularization: 0.284181\n",
      "2019-04-09 21:40:12,394 root         INFO     Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 0.398530\n",
      "Reconstruction: 0.124950, Regularization: 0.273580\n",
      "2019-04-09 21:40:12,440 root         INFO     Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 0.903738\n",
      "Reconstruction: 0.582396, Regularization: 0.321342\n",
      "2019-04-09 21:40:12,486 root         INFO     Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 0.396285\n",
      "Reconstruction: 0.094385, Regularization: 0.301901\n",
      "2019-04-09 21:40:12,532 root         INFO     Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 0.411941\n",
      "Reconstruction: 0.123414, Regularization: 0.288528\n",
      "2019-04-09 21:40:12,578 root         INFO     Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 0.630534\n",
      "Reconstruction: 0.311168, Regularization: 0.319366\n",
      "2019-04-09 21:40:12,631 root         INFO     ====> Epoch: 58 Average loss: 0.6138\n",
      "2019-04-09 21:40:12,654 root         INFO     Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 0.383609\n",
      "Reconstruction: 0.105072, Regularization: 0.278537\n",
      "2019-04-09 21:40:12,700 root         INFO     Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 0.584646\n",
      "Reconstruction: 0.304259, Regularization: 0.280387\n",
      "2019-04-09 21:40:12,744 root         INFO     Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 0.366129\n",
      "Reconstruction: 0.125885, Regularization: 0.240244\n",
      "2019-04-09 21:40:12,788 root         INFO     Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 0.413900\n",
      "Reconstruction: 0.122031, Regularization: 0.291869\n",
      "2019-04-09 21:40:12,834 root         INFO     Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 0.510601\n",
      "Reconstruction: 0.133247, Regularization: 0.377353\n",
      "2019-04-09 21:40:12,879 root         INFO     Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 0.588185\n",
      "Reconstruction: 0.274008, Regularization: 0.314177\n",
      "2019-04-09 21:40:12,922 root         INFO     Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 0.546816\n",
      "Reconstruction: 0.282500, Regularization: 0.264316\n",
      "2019-04-09 21:40:12,965 root         INFO     Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 0.494090\n",
      "Reconstruction: 0.216536, Regularization: 0.277554\n",
      "2019-04-09 21:40:13,016 root         INFO     ====> Epoch: 59 Average loss: 0.5553\n",
      "2019-04-09 21:40:13,040 root         INFO     Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 0.922537\n",
      "Reconstruction: 0.626281, Regularization: 0.296256\n",
      "2019-04-09 21:40:13,084 root         INFO     Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 1.400898\n",
      "Reconstruction: 1.113882, Regularization: 0.287016\n",
      "2019-04-09 21:40:13,128 root         INFO     Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 0.355076\n",
      "Reconstruction: 0.120563, Regularization: 0.234512\n",
      "2019-04-09 21:40:13,172 root         INFO     Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 0.449413\n",
      "Reconstruction: 0.100740, Regularization: 0.348673\n",
      "2019-04-09 21:40:13,216 root         INFO     Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 0.394988\n",
      "Reconstruction: 0.161628, Regularization: 0.233360\n",
      "2019-04-09 21:40:13,260 root         INFO     Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 0.499845\n",
      "Reconstruction: 0.123693, Regularization: 0.376152\n",
      "2019-04-09 21:40:13,304 root         INFO     Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 0.781714\n",
      "Reconstruction: 0.465979, Regularization: 0.315735\n",
      "2019-04-09 21:40:13,348 root         INFO     Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 0.377057\n",
      "Reconstruction: 0.140574, Regularization: 0.236483\n",
      "2019-04-09 21:40:13,399 root         INFO     ====> Epoch: 60 Average loss: 0.5539\n",
      "2019-04-09 21:40:13,422 root         INFO     Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 0.421717\n",
      "Reconstruction: 0.104524, Regularization: 0.317192\n",
      "2019-04-09 21:40:13,467 root         INFO     Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 0.922226\n",
      "Reconstruction: 0.643288, Regularization: 0.278938\n",
      "2019-04-09 21:40:13,511 root         INFO     Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 0.528799\n",
      "Reconstruction: 0.226057, Regularization: 0.302742\n",
      "2019-04-09 21:40:13,555 root         INFO     Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 0.448129\n",
      "Reconstruction: 0.153574, Regularization: 0.294555\n",
      "2019-04-09 21:40:13,600 root         INFO     Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 0.429766\n",
      "Reconstruction: 0.115527, Regularization: 0.314239\n",
      "2019-04-09 21:40:13,644 root         INFO     Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 0.632663\n",
      "Reconstruction: 0.337443, Regularization: 0.295220\n",
      "2019-04-09 21:40:13,688 root         INFO     Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 0.386097\n",
      "Reconstruction: 0.103164, Regularization: 0.282934\n",
      "2019-04-09 21:40:13,733 root         INFO     Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 0.378831\n",
      "Reconstruction: 0.149793, Regularization: 0.229037\n",
      "2019-04-09 21:40:13,785 root         INFO     ====> Epoch: 61 Average loss: 0.5360\n",
      "2019-04-09 21:40:13,808 root         INFO     Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 0.833278\n",
      "Reconstruction: 0.580369, Regularization: 0.252908\n",
      "2019-04-09 21:40:13,852 root         INFO     Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 0.416975\n",
      "Reconstruction: 0.123373, Regularization: 0.293602\n",
      "2019-04-09 21:40:13,897 root         INFO     Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 0.418694\n",
      "Reconstruction: 0.181842, Regularization: 0.236852\n",
      "2019-04-09 21:40:13,941 root         INFO     Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 0.514576\n",
      "Reconstruction: 0.128052, Regularization: 0.386524\n",
      "2019-04-09 21:40:13,985 root         INFO     Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 0.518370\n",
      "Reconstruction: 0.312829, Regularization: 0.205541\n",
      "2019-04-09 21:40:14,030 root         INFO     Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 0.401450\n",
      "Reconstruction: 0.134899, Regularization: 0.266551\n",
      "2019-04-09 21:40:14,073 root         INFO     Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 0.526621\n",
      "Reconstruction: 0.209415, Regularization: 0.317206\n",
      "2019-04-09 21:40:14,117 root         INFO     Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 0.330505\n",
      "Reconstruction: 0.095599, Regularization: 0.234906\n",
      "2019-04-09 21:40:14,168 root         INFO     ====> Epoch: 62 Average loss: 0.5295\n",
      "2019-04-09 21:40:14,191 root         INFO     Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 0.523787\n",
      "Reconstruction: 0.260267, Regularization: 0.263520\n",
      "2019-04-09 21:40:14,236 root         INFO     Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 0.345656\n",
      "Reconstruction: 0.117612, Regularization: 0.228044\n",
      "2019-04-09 21:40:14,280 root         INFO     Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 0.483096\n",
      "Reconstruction: 0.154434, Regularization: 0.328661\n",
      "2019-04-09 21:40:14,324 root         INFO     Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 0.346535\n",
      "Reconstruction: 0.111286, Regularization: 0.235249\n",
      "2019-04-09 21:40:14,368 root         INFO     Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 0.407584\n",
      "Reconstruction: 0.138653, Regularization: 0.268931\n",
      "2019-04-09 21:40:14,412 root         INFO     Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 0.416311\n",
      "Reconstruction: 0.142172, Regularization: 0.274139\n",
      "2019-04-09 21:40:14,455 root         INFO     Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 0.356236\n",
      "Reconstruction: 0.090398, Regularization: 0.265838\n",
      "2019-04-09 21:40:14,499 root         INFO     Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 0.950515\n",
      "Reconstruction: 0.633900, Regularization: 0.316614\n",
      "2019-04-09 21:40:14,549 root         INFO     ====> Epoch: 63 Average loss: 0.5505\n",
      "2019-04-09 21:40:14,572 root         INFO     Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 0.384480\n",
      "Reconstruction: 0.124402, Regularization: 0.260078\n",
      "2019-04-09 21:40:14,617 root         INFO     Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 0.451857\n",
      "Reconstruction: 0.191722, Regularization: 0.260134\n",
      "2019-04-09 21:40:14,662 root         INFO     Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 0.399637\n",
      "Reconstruction: 0.098685, Regularization: 0.300952\n",
      "2019-04-09 21:40:14,707 root         INFO     Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 0.462051\n",
      "Reconstruction: 0.145636, Regularization: 0.316416\n",
      "2019-04-09 21:40:14,752 root         INFO     Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 0.377279\n",
      "Reconstruction: 0.099147, Regularization: 0.278132\n",
      "2019-04-09 21:40:14,796 root         INFO     Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 0.672729\n",
      "Reconstruction: 0.391831, Regularization: 0.280898\n",
      "2019-04-09 21:40:14,843 root         INFO     Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 0.390103\n",
      "Reconstruction: 0.143041, Regularization: 0.247062\n",
      "2019-04-09 21:40:14,889 root         INFO     Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 0.421489\n",
      "Reconstruction: 0.127975, Regularization: 0.293513\n",
      "2019-04-09 21:40:14,942 root         INFO     ====> Epoch: 64 Average loss: 0.5290\n",
      "2019-04-09 21:40:14,965 root         INFO     Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 0.330777\n",
      "Reconstruction: 0.082800, Regularization: 0.247977\n",
      "2019-04-09 21:40:15,010 root         INFO     Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 0.364436\n",
      "Reconstruction: 0.132404, Regularization: 0.232032\n",
      "2019-04-09 21:40:15,055 root         INFO     Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 0.530617\n",
      "Reconstruction: 0.212047, Regularization: 0.318570\n",
      "2019-04-09 21:40:15,100 root         INFO     Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 0.423604\n",
      "Reconstruction: 0.114307, Regularization: 0.309297\n",
      "2019-04-09 21:40:15,145 root         INFO     Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 0.441035\n",
      "Reconstruction: 0.137831, Regularization: 0.303204\n",
      "2019-04-09 21:40:15,190 root         INFO     Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 0.945856\n",
      "Reconstruction: 0.671346, Regularization: 0.274510\n",
      "2019-04-09 21:40:15,234 root         INFO     Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 0.427924\n",
      "Reconstruction: 0.114175, Regularization: 0.313750\n",
      "2019-04-09 21:40:15,279 root         INFO     Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 0.431250\n",
      "Reconstruction: 0.213686, Regularization: 0.217563\n",
      "2019-04-09 21:40:15,331 root         INFO     ====> Epoch: 65 Average loss: 0.5134\n",
      "2019-04-09 21:40:15,354 root         INFO     Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 0.398887\n",
      "Reconstruction: 0.147317, Regularization: 0.251570\n",
      "2019-04-09 21:40:15,399 root         INFO     Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 0.385024\n",
      "Reconstruction: 0.121842, Regularization: 0.263182\n",
      "2019-04-09 21:40:15,443 root         INFO     Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 0.344468\n",
      "Reconstruction: 0.092665, Regularization: 0.251803\n",
      "2019-04-09 21:40:15,488 root         INFO     Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 0.468180\n",
      "Reconstruction: 0.194884, Regularization: 0.273296\n",
      "2019-04-09 21:40:15,533 root         INFO     Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 0.368556\n",
      "Reconstruction: 0.108685, Regularization: 0.259870\n",
      "2019-04-09 21:40:15,578 root         INFO     Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 0.333085\n",
      "Reconstruction: 0.106350, Regularization: 0.226734\n",
      "2019-04-09 21:40:15,623 root         INFO     Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 0.421941\n",
      "Reconstruction: 0.119571, Regularization: 0.302370\n",
      "2019-04-09 21:40:15,668 root         INFO     Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 0.901849\n",
      "Reconstruction: 0.638903, Regularization: 0.262946\n",
      "2019-04-09 21:40:15,720 root         INFO     ====> Epoch: 66 Average loss: 0.5306\n",
      "2019-04-09 21:40:15,742 root         INFO     Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 0.393243\n",
      "Reconstruction: 0.124208, Regularization: 0.269035\n",
      "2019-04-09 21:40:15,786 root         INFO     Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 0.389402\n",
      "Reconstruction: 0.155666, Regularization: 0.233735\n",
      "2019-04-09 21:40:15,830 root         INFO     Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 0.327572\n",
      "Reconstruction: 0.115158, Regularization: 0.212415\n",
      "2019-04-09 21:40:15,873 root         INFO     Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 0.874729\n",
      "Reconstruction: 0.600570, Regularization: 0.274160\n",
      "2019-04-09 21:40:15,917 root         INFO     Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 0.348434\n",
      "Reconstruction: 0.098782, Regularization: 0.249651\n",
      "2019-04-09 21:40:15,960 root         INFO     Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 0.374376\n",
      "Reconstruction: 0.132051, Regularization: 0.242325\n",
      "2019-04-09 21:40:16,004 root         INFO     Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 1.694138\n",
      "Reconstruction: 1.352285, Regularization: 0.341853\n",
      "2019-04-09 21:40:16,047 root         INFO     Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 0.443949\n",
      "Reconstruction: 0.175131, Regularization: 0.268818\n",
      "2019-04-09 21:40:16,098 root         INFO     ====> Epoch: 67 Average loss: 0.5064\n",
      "2019-04-09 21:40:16,120 root         INFO     Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 0.381121\n",
      "Reconstruction: 0.106451, Regularization: 0.274670\n",
      "2019-04-09 21:40:16,165 root         INFO     Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 1.045486\n",
      "Reconstruction: 0.762164, Regularization: 0.283322\n",
      "2019-04-09 21:40:16,209 root         INFO     Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 0.458205\n",
      "Reconstruction: 0.141164, Regularization: 0.317041\n",
      "2019-04-09 21:40:16,253 root         INFO     Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 0.385064\n",
      "Reconstruction: 0.127861, Regularization: 0.257203\n",
      "2019-04-09 21:40:16,297 root         INFO     Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 0.708448\n",
      "Reconstruction: 0.423770, Regularization: 0.284678\n",
      "2019-04-09 21:40:16,341 root         INFO     Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 0.397469\n",
      "Reconstruction: 0.136183, Regularization: 0.261287\n",
      "2019-04-09 21:40:16,386 root         INFO     Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 0.913758\n",
      "Reconstruction: 0.585632, Regularization: 0.328126\n",
      "2019-04-09 21:40:16,431 root         INFO     Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 0.474714\n",
      "Reconstruction: 0.158571, Regularization: 0.316143\n",
      "2019-04-09 21:40:16,482 root         INFO     ====> Epoch: 68 Average loss: 0.5018\n",
      "2019-04-09 21:40:16,505 root         INFO     Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 0.427239\n",
      "Reconstruction: 0.145513, Regularization: 0.281725\n",
      "2019-04-09 21:40:16,549 root         INFO     Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 0.422074\n",
      "Reconstruction: 0.171567, Regularization: 0.250506\n",
      "2019-04-09 21:40:16,595 root         INFO     Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 0.442610\n",
      "Reconstruction: 0.101797, Regularization: 0.340814\n",
      "2019-04-09 21:40:16,640 root         INFO     Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 0.434882\n",
      "Reconstruction: 0.134139, Regularization: 0.300743\n",
      "2019-04-09 21:40:16,686 root         INFO     Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 2.462549\n",
      "Reconstruction: 2.131331, Regularization: 0.331218\n",
      "2019-04-09 21:40:16,732 root         INFO     Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 0.874173\n",
      "Reconstruction: 0.538266, Regularization: 0.335907\n",
      "2019-04-09 21:40:16,778 root         INFO     Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 0.521347\n",
      "Reconstruction: 0.298748, Regularization: 0.222599\n",
      "2019-04-09 21:40:16,823 root         INFO     Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 0.372794\n",
      "Reconstruction: 0.106975, Regularization: 0.265819\n",
      "2019-04-09 21:40:16,875 root         INFO     ====> Epoch: 69 Average loss: 0.4910\n",
      "2019-04-09 21:40:16,898 root         INFO     Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 0.650819\n",
      "Reconstruction: 0.374312, Regularization: 0.276507\n",
      "2019-04-09 21:40:16,944 root         INFO     Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 0.455021\n",
      "Reconstruction: 0.169629, Regularization: 0.285392\n",
      "2019-04-09 21:40:16,990 root         INFO     Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 0.725696\n",
      "Reconstruction: 0.390555, Regularization: 0.335141\n",
      "2019-04-09 21:40:17,037 root         INFO     Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 0.392038\n",
      "Reconstruction: 0.106341, Regularization: 0.285696\n",
      "2019-04-09 21:40:17,083 root         INFO     Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 0.471156\n",
      "Reconstruction: 0.137061, Regularization: 0.334094\n",
      "2019-04-09 21:40:17,129 root         INFO     Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 0.343392\n",
      "Reconstruction: 0.091888, Regularization: 0.251504\n",
      "2019-04-09 21:40:17,175 root         INFO     Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 0.381123\n",
      "Reconstruction: 0.126744, Regularization: 0.254379\n",
      "2019-04-09 21:40:17,221 root         INFO     Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 0.383573\n",
      "Reconstruction: 0.134738, Regularization: 0.248835\n",
      "2019-04-09 21:40:17,274 root         INFO     ====> Epoch: 70 Average loss: 0.4938\n",
      "2019-04-09 21:40:17,297 root         INFO     Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 0.646809\n",
      "Reconstruction: 0.376437, Regularization: 0.270372\n",
      "2019-04-09 21:40:17,343 root         INFO     Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 0.396274\n",
      "Reconstruction: 0.082893, Regularization: 0.313380\n",
      "2019-04-09 21:40:17,388 root         INFO     Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 0.632385\n",
      "Reconstruction: 0.322679, Regularization: 0.309706\n",
      "2019-04-09 21:40:17,434 root         INFO     Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 0.404117\n",
      "Reconstruction: 0.154360, Regularization: 0.249757\n",
      "2019-04-09 21:40:17,479 root         INFO     Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 0.385797\n",
      "Reconstruction: 0.096510, Regularization: 0.289286\n",
      "2019-04-09 21:40:17,524 root         INFO     Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 0.349828\n",
      "Reconstruction: 0.089496, Regularization: 0.260332\n",
      "2019-04-09 21:40:17,569 root         INFO     Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 1.450541\n",
      "Reconstruction: 1.068507, Regularization: 0.382033\n",
      "2019-04-09 21:40:17,614 root         INFO     Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 0.423224\n",
      "Reconstruction: 0.144948, Regularization: 0.278276\n",
      "2019-04-09 21:40:17,666 root         INFO     ====> Epoch: 71 Average loss: 0.4794\n",
      "2019-04-09 21:40:17,688 root         INFO     Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 0.400939\n",
      "Reconstruction: 0.128718, Regularization: 0.272221\n",
      "2019-04-09 21:40:17,733 root         INFO     Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 0.378383\n",
      "Reconstruction: 0.090592, Regularization: 0.287791\n",
      "2019-04-09 21:40:17,778 root         INFO     Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 0.488170\n",
      "Reconstruction: 0.124559, Regularization: 0.363611\n",
      "2019-04-09 21:40:17,822 root         INFO     Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 0.425828\n",
      "Reconstruction: 0.152873, Regularization: 0.272955\n",
      "2019-04-09 21:40:17,867 root         INFO     Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 0.470606\n",
      "Reconstruction: 0.162205, Regularization: 0.308401\n",
      "2019-04-09 21:40:17,913 root         INFO     Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 0.391576\n",
      "Reconstruction: 0.109200, Regularization: 0.282376\n",
      "2019-04-09 21:40:17,959 root         INFO     Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 1.032689\n",
      "Reconstruction: 0.728639, Regularization: 0.304051\n",
      "2019-04-09 21:40:18,006 root         INFO     Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 0.322065\n",
      "Reconstruction: 0.096937, Regularization: 0.225128\n",
      "2019-04-09 21:40:18,059 root         INFO     ====> Epoch: 72 Average loss: 0.4819\n",
      "2019-04-09 21:40:18,081 root         INFO     Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 0.396172\n",
      "Reconstruction: 0.094485, Regularization: 0.301687\n",
      "2019-04-09 21:40:18,127 root         INFO     Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 0.390774\n",
      "Reconstruction: 0.083280, Regularization: 0.307494\n",
      "2019-04-09 21:40:18,173 root         INFO     Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 0.449205\n",
      "Reconstruction: 0.200200, Regularization: 0.249006\n",
      "2019-04-09 21:40:18,219 root         INFO     Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 0.605765\n",
      "Reconstruction: 0.386688, Regularization: 0.219077\n",
      "2019-04-09 21:40:18,265 root         INFO     Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 0.354506\n",
      "Reconstruction: 0.128641, Regularization: 0.225866\n",
      "2019-04-09 21:40:18,310 root         INFO     Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 0.468521\n",
      "Reconstruction: 0.120945, Regularization: 0.347576\n",
      "2019-04-09 21:40:18,354 root         INFO     Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 0.379920\n",
      "Reconstruction: 0.124660, Regularization: 0.255260\n",
      "2019-04-09 21:40:18,399 root         INFO     Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 1.035625\n",
      "Reconstruction: 0.752869, Regularization: 0.282756\n",
      "2019-04-09 21:40:18,450 root         INFO     ====> Epoch: 73 Average loss: 0.4744\n",
      "2019-04-09 21:40:18,473 root         INFO     Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 0.417567\n",
      "Reconstruction: 0.093108, Regularization: 0.324460\n",
      "2019-04-09 21:40:18,518 root         INFO     Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 0.373165\n",
      "Reconstruction: 0.117302, Regularization: 0.255863\n",
      "2019-04-09 21:40:18,564 root         INFO     Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 0.464720\n",
      "Reconstruction: 0.203920, Regularization: 0.260799\n",
      "2019-04-09 21:40:18,609 root         INFO     Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 0.370621\n",
      "Reconstruction: 0.119466, Regularization: 0.251155\n",
      "2019-04-09 21:40:18,654 root         INFO     Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 0.311842\n",
      "Reconstruction: 0.132310, Regularization: 0.179532\n",
      "2019-04-09 21:40:18,700 root         INFO     Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 0.342696\n",
      "Reconstruction: 0.082710, Regularization: 0.259986\n",
      "2019-04-09 21:40:18,745 root         INFO     Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 0.352174\n",
      "Reconstruction: 0.092042, Regularization: 0.260131\n",
      "2019-04-09 21:40:18,790 root         INFO     Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 0.406677\n",
      "Reconstruction: 0.167106, Regularization: 0.239572\n",
      "2019-04-09 21:40:18,842 root         INFO     ====> Epoch: 74 Average loss: 0.4695\n",
      "2019-04-09 21:40:18,865 root         INFO     Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 0.399826\n",
      "Reconstruction: 0.098344, Regularization: 0.301482\n",
      "2019-04-09 21:40:18,911 root         INFO     Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 0.540272\n",
      "Reconstruction: 0.156093, Regularization: 0.384178\n",
      "2019-04-09 21:40:18,956 root         INFO     Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 0.369879\n",
      "Reconstruction: 0.090395, Regularization: 0.279484\n",
      "2019-04-09 21:40:19,001 root         INFO     Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 0.393005\n",
      "Reconstruction: 0.090603, Regularization: 0.302402\n",
      "2019-04-09 21:40:19,046 root         INFO     Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 0.373098\n",
      "Reconstruction: 0.096599, Regularization: 0.276499\n",
      "2019-04-09 21:40:19,092 root         INFO     Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 0.408435\n",
      "Reconstruction: 0.098327, Regularization: 0.310108\n",
      "2019-04-09 21:40:19,137 root         INFO     Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 0.397074\n",
      "Reconstruction: 0.143451, Regularization: 0.253623\n",
      "2019-04-09 21:40:19,181 root         INFO     Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 0.348239\n",
      "Reconstruction: 0.126677, Regularization: 0.221562\n",
      "2019-04-09 21:40:19,233 root         INFO     ====> Epoch: 75 Average loss: 0.4675\n",
      "2019-04-09 21:40:19,255 root         INFO     Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 0.375327\n",
      "Reconstruction: 0.110077, Regularization: 0.265251\n",
      "2019-04-09 21:40:19,301 root         INFO     Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 0.390270\n",
      "Reconstruction: 0.142123, Regularization: 0.248147\n",
      "2019-04-09 21:40:19,347 root         INFO     Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 0.387775\n",
      "Reconstruction: 0.129044, Regularization: 0.258731\n",
      "2019-04-09 21:40:19,392 root         INFO     Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 0.378704\n",
      "Reconstruction: 0.098307, Regularization: 0.280398\n",
      "2019-04-09 21:40:19,437 root         INFO     Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 0.403564\n",
      "Reconstruction: 0.131763, Regularization: 0.271801\n",
      "2019-04-09 21:40:19,482 root         INFO     Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 0.477143\n",
      "Reconstruction: 0.186714, Regularization: 0.290429\n",
      "2019-04-09 21:40:19,528 root         INFO     Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 0.319937\n",
      "Reconstruction: 0.094326, Regularization: 0.225611\n",
      "2019-04-09 21:40:19,573 root         INFO     Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 0.376810\n",
      "Reconstruction: 0.096195, Regularization: 0.280616\n",
      "2019-04-09 21:40:19,624 root         INFO     ====> Epoch: 76 Average loss: 0.4612\n",
      "2019-04-09 21:40:19,647 root         INFO     Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 0.377546\n",
      "Reconstruction: 0.126201, Regularization: 0.251345\n",
      "2019-04-09 21:40:19,693 root         INFO     Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 0.396793\n",
      "Reconstruction: 0.132602, Regularization: 0.264191\n",
      "2019-04-09 21:40:19,738 root         INFO     Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 0.481075\n",
      "Reconstruction: 0.213721, Regularization: 0.267354\n",
      "2019-04-09 21:40:19,783 root         INFO     Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 0.571582\n",
      "Reconstruction: 0.299147, Regularization: 0.272435\n",
      "2019-04-09 21:40:19,829 root         INFO     Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 0.444410\n",
      "Reconstruction: 0.111917, Regularization: 0.332494\n",
      "2019-04-09 21:40:19,873 root         INFO     Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 0.419276\n",
      "Reconstruction: 0.151140, Regularization: 0.268136\n",
      "2019-04-09 21:40:19,918 root         INFO     Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 0.458460\n",
      "Reconstruction: 0.118687, Regularization: 0.339773\n",
      "2019-04-09 21:40:19,962 root         INFO     Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 0.426585\n",
      "Reconstruction: 0.096983, Regularization: 0.329602\n",
      "2019-04-09 21:40:20,014 root         INFO     ====> Epoch: 77 Average loss: 0.4687\n",
      "2019-04-09 21:40:20,036 root         INFO     Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 0.373438\n",
      "Reconstruction: 0.101617, Regularization: 0.271821\n",
      "2019-04-09 21:40:20,082 root         INFO     Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 0.379083\n",
      "Reconstruction: 0.095831, Regularization: 0.283252\n",
      "2019-04-09 21:40:20,127 root         INFO     Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 0.437594\n",
      "Reconstruction: 0.172078, Regularization: 0.265516\n",
      "2019-04-09 21:40:20,172 root         INFO     Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 0.374353\n",
      "Reconstruction: 0.080026, Regularization: 0.294327\n",
      "2019-04-09 21:40:20,218 root         INFO     Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 0.374194\n",
      "Reconstruction: 0.107749, Regularization: 0.266445\n",
      "2019-04-09 21:40:20,263 root         INFO     Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 0.730909\n",
      "Reconstruction: 0.505163, Regularization: 0.225746\n",
      "2019-04-09 21:40:20,309 root         INFO     Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 0.359458\n",
      "Reconstruction: 0.093238, Regularization: 0.266220\n",
      "2019-04-09 21:40:20,355 root         INFO     Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 0.418795\n",
      "Reconstruction: 0.150537, Regularization: 0.268258\n",
      "2019-04-09 21:40:20,408 root         INFO     ====> Epoch: 78 Average loss: 0.4505\n",
      "2019-04-09 21:40:20,431 root         INFO     Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 0.362430\n",
      "Reconstruction: 0.089820, Regularization: 0.272610\n",
      "2019-04-09 21:40:20,476 root         INFO     Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 0.398775\n",
      "Reconstruction: 0.136667, Regularization: 0.262109\n",
      "2019-04-09 21:40:20,521 root         INFO     Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 0.416843\n",
      "Reconstruction: 0.139424, Regularization: 0.277418\n",
      "2019-04-09 21:40:20,566 root         INFO     Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 0.407351\n",
      "Reconstruction: 0.101134, Regularization: 0.306216\n",
      "2019-04-09 21:40:20,612 root         INFO     Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 0.438530\n",
      "Reconstruction: 0.122176, Regularization: 0.316353\n",
      "2019-04-09 21:40:20,657 root         INFO     Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 0.374027\n",
      "Reconstruction: 0.113983, Regularization: 0.260043\n",
      "2019-04-09 21:40:20,701 root         INFO     Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 0.765681\n",
      "Reconstruction: 0.526593, Regularization: 0.239088\n",
      "2019-04-09 21:40:20,746 root         INFO     Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 0.377724\n",
      "Reconstruction: 0.150138, Regularization: 0.227586\n",
      "2019-04-09 21:40:20,796 root         INFO     ====> Epoch: 79 Average loss: 0.4493\n",
      "2019-04-09 21:40:20,819 root         INFO     Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 0.415695\n",
      "Reconstruction: 0.153716, Regularization: 0.261978\n",
      "2019-04-09 21:40:20,864 root         INFO     Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 0.456344\n",
      "Reconstruction: 0.148664, Regularization: 0.307680\n",
      "2019-04-09 21:40:20,910 root         INFO     Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 0.418412\n",
      "Reconstruction: 0.110435, Regularization: 0.307977\n",
      "2019-04-09 21:40:20,955 root         INFO     Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 0.358949\n",
      "Reconstruction: 0.113157, Regularization: 0.245793\n",
      "2019-04-09 21:40:21,000 root         INFO     Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 0.320163\n",
      "Reconstruction: 0.110187, Regularization: 0.209976\n",
      "2019-04-09 21:40:21,043 root         INFO     Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 0.380825\n",
      "Reconstruction: 0.099761, Regularization: 0.281064\n",
      "2019-04-09 21:40:21,086 root         INFO     Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 0.398710\n",
      "Reconstruction: 0.107549, Regularization: 0.291161\n",
      "2019-04-09 21:40:21,130 root         INFO     Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 0.316206\n",
      "Reconstruction: 0.089815, Regularization: 0.226391\n",
      "2019-04-09 21:40:21,182 root         INFO     ====> Epoch: 80 Average loss: 0.4460\n",
      "2019-04-09 21:40:21,204 root         INFO     Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 0.365931\n",
      "Reconstruction: 0.091938, Regularization: 0.273993\n",
      "2019-04-09 21:40:21,250 root         INFO     Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 0.662563\n",
      "Reconstruction: 0.362505, Regularization: 0.300058\n",
      "2019-04-09 21:40:21,296 root         INFO     Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 0.405167\n",
      "Reconstruction: 0.097196, Regularization: 0.307971\n",
      "2019-04-09 21:40:21,342 root         INFO     Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 0.311128\n",
      "Reconstruction: 0.086624, Regularization: 0.224504\n",
      "2019-04-09 21:40:21,387 root         INFO     Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 0.415815\n",
      "Reconstruction: 0.098881, Regularization: 0.316934\n",
      "2019-04-09 21:40:21,433 root         INFO     Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 0.409550\n",
      "Reconstruction: 0.125801, Regularization: 0.283749\n",
      "2019-04-09 21:40:21,479 root         INFO     Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 0.452652\n",
      "Reconstruction: 0.151242, Regularization: 0.301411\n",
      "2019-04-09 21:40:21,525 root         INFO     Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 0.438512\n",
      "Reconstruction: 0.126679, Regularization: 0.311833\n",
      "2019-04-09 21:40:21,578 root         INFO     ====> Epoch: 81 Average loss: 0.4367\n",
      "2019-04-09 21:40:21,600 root         INFO     Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 0.836204\n",
      "Reconstruction: 0.563043, Regularization: 0.273162\n",
      "2019-04-09 21:40:21,647 root         INFO     Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 0.584633\n",
      "Reconstruction: 0.267731, Regularization: 0.316902\n",
      "2019-04-09 21:40:21,693 root         INFO     Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 0.318012\n",
      "Reconstruction: 0.132893, Regularization: 0.185119\n",
      "2019-04-09 21:40:21,739 root         INFO     Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 0.376641\n",
      "Reconstruction: 0.097177, Regularization: 0.279465\n",
      "2019-04-09 21:40:21,785 root         INFO     Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 0.429172\n",
      "Reconstruction: 0.128444, Regularization: 0.300729\n",
      "2019-04-09 21:40:21,831 root         INFO     Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 0.454061\n",
      "Reconstruction: 0.189351, Regularization: 0.264709\n",
      "2019-04-09 21:40:21,877 root         INFO     Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 0.375001\n",
      "Reconstruction: 0.121236, Regularization: 0.253766\n",
      "2019-04-09 21:40:21,923 root         INFO     Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 0.414903\n",
      "Reconstruction: 0.097164, Regularization: 0.317739\n",
      "2019-04-09 21:40:21,974 root         INFO     ====> Epoch: 82 Average loss: 0.4341\n",
      "2019-04-09 21:40:21,997 root         INFO     Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 0.434951\n",
      "Reconstruction: 0.129254, Regularization: 0.305697\n",
      "2019-04-09 21:40:22,043 root         INFO     Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 0.997741\n",
      "Reconstruction: 0.725011, Regularization: 0.272731\n",
      "2019-04-09 21:40:22,089 root         INFO     Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 0.321858\n",
      "Reconstruction: 0.099653, Regularization: 0.222204\n",
      "2019-04-09 21:40:22,134 root         INFO     Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 0.456079\n",
      "Reconstruction: 0.143353, Regularization: 0.312727\n",
      "2019-04-09 21:40:22,179 root         INFO     Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 0.423136\n",
      "Reconstruction: 0.110311, Regularization: 0.312825\n",
      "2019-04-09 21:40:22,224 root         INFO     Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 0.395068\n",
      "Reconstruction: 0.089489, Regularization: 0.305579\n",
      "2019-04-09 21:40:22,269 root         INFO     Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 0.419898\n",
      "Reconstruction: 0.112172, Regularization: 0.307726\n",
      "2019-04-09 21:40:22,314 root         INFO     Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 0.396557\n",
      "Reconstruction: 0.102166, Regularization: 0.294391\n",
      "2019-04-09 21:40:22,366 root         INFO     ====> Epoch: 83 Average loss: 0.4355\n",
      "2019-04-09 21:40:22,389 root         INFO     Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 0.388131\n",
      "Reconstruction: 0.093965, Regularization: 0.294166\n",
      "2019-04-09 21:40:22,433 root         INFO     Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 0.359055\n",
      "Reconstruction: 0.115480, Regularization: 0.243575\n",
      "2019-04-09 21:40:22,476 root         INFO     Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 0.383600\n",
      "Reconstruction: 0.114074, Regularization: 0.269526\n",
      "2019-04-09 21:40:22,519 root         INFO     Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 0.374436\n",
      "Reconstruction: 0.118081, Regularization: 0.256355\n",
      "2019-04-09 21:40:22,562 root         INFO     Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 0.379183\n",
      "Reconstruction: 0.090834, Regularization: 0.288349\n",
      "2019-04-09 21:40:22,605 root         INFO     Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 0.426247\n",
      "Reconstruction: 0.149884, Regularization: 0.276364\n",
      "2019-04-09 21:40:22,648 root         INFO     Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 0.298944\n",
      "Reconstruction: 0.099608, Regularization: 0.199336\n",
      "2019-04-09 21:40:22,691 root         INFO     Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 0.490825\n",
      "Reconstruction: 0.224066, Regularization: 0.266759\n",
      "2019-04-09 21:40:22,742 root         INFO     ====> Epoch: 84 Average loss: 0.4239\n",
      "2019-04-09 21:40:22,764 root         INFO     Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 0.385067\n",
      "Reconstruction: 0.110816, Regularization: 0.274251\n",
      "2019-04-09 21:40:22,809 root         INFO     Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 0.368265\n",
      "Reconstruction: 0.127455, Regularization: 0.240810\n",
      "2019-04-09 21:40:22,854 root         INFO     Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 0.368969\n",
      "Reconstruction: 0.085311, Regularization: 0.283658\n",
      "2019-04-09 21:40:22,898 root         INFO     Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 0.378197\n",
      "Reconstruction: 0.110978, Regularization: 0.267219\n",
      "2019-04-09 21:40:22,942 root         INFO     Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 0.362917\n",
      "Reconstruction: 0.081538, Regularization: 0.281379\n",
      "2019-04-09 21:40:22,986 root         INFO     Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 0.436537\n",
      "Reconstruction: 0.180380, Regularization: 0.256157\n",
      "2019-04-09 21:40:23,030 root         INFO     Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 0.402629\n",
      "Reconstruction: 0.118448, Regularization: 0.284180\n",
      "2019-04-09 21:40:23,073 root         INFO     Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 0.783255\n",
      "Reconstruction: 0.368491, Regularization: 0.414764\n",
      "2019-04-09 21:40:23,124 root         INFO     ====> Epoch: 85 Average loss: 0.4283\n",
      "2019-04-09 21:40:23,146 root         INFO     Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 0.405375\n",
      "Reconstruction: 0.104047, Regularization: 0.301328\n",
      "2019-04-09 21:40:23,191 root         INFO     Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 0.366160\n",
      "Reconstruction: 0.094848, Regularization: 0.271312\n",
      "2019-04-09 21:40:23,235 root         INFO     Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 0.436429\n",
      "Reconstruction: 0.121161, Regularization: 0.315268\n",
      "2019-04-09 21:40:23,280 root         INFO     Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 0.425226\n",
      "Reconstruction: 0.175997, Regularization: 0.249229\n",
      "2019-04-09 21:40:23,324 root         INFO     Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 0.338057\n",
      "Reconstruction: 0.109752, Regularization: 0.228305\n",
      "2019-04-09 21:40:23,368 root         INFO     Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 0.431360\n",
      "Reconstruction: 0.089818, Regularization: 0.341543\n",
      "2019-04-09 21:40:23,412 root         INFO     Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 0.376246\n",
      "Reconstruction: 0.107577, Regularization: 0.268668\n",
      "2019-04-09 21:40:23,455 root         INFO     Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 0.599481\n",
      "Reconstruction: 0.342401, Regularization: 0.257080\n",
      "2019-04-09 21:40:23,506 root         INFO     ====> Epoch: 86 Average loss: 0.4170\n",
      "2019-04-09 21:40:23,529 root         INFO     Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 0.312928\n",
      "Reconstruction: 0.113586, Regularization: 0.199343\n",
      "2019-04-09 21:40:23,574 root         INFO     Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 0.547184\n",
      "Reconstruction: 0.235200, Regularization: 0.311985\n",
      "2019-04-09 21:40:23,618 root         INFO     Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 0.436552\n",
      "Reconstruction: 0.133543, Regularization: 0.303009\n",
      "2019-04-09 21:40:23,662 root         INFO     Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 0.322217\n",
      "Reconstruction: 0.100275, Regularization: 0.221941\n",
      "2019-04-09 21:40:23,706 root         INFO     Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 0.334412\n",
      "Reconstruction: 0.106314, Regularization: 0.228098\n",
      "2019-04-09 21:40:23,750 root         INFO     Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 0.387224\n",
      "Reconstruction: 0.074159, Regularization: 0.313066\n",
      "2019-04-09 21:40:23,795 root         INFO     Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 0.457384\n",
      "Reconstruction: 0.114698, Regularization: 0.342686\n",
      "2019-04-09 21:40:23,839 root         INFO     Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 0.374794\n",
      "Reconstruction: 0.082487, Regularization: 0.292307\n",
      "2019-04-09 21:40:23,890 root         INFO     ====> Epoch: 87 Average loss: 0.4129\n",
      "2019-04-09 21:40:23,913 root         INFO     Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 0.385380\n",
      "Reconstruction: 0.094368, Regularization: 0.291012\n",
      "2019-04-09 21:40:23,959 root         INFO     Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 0.433537\n",
      "Reconstruction: 0.148934, Regularization: 0.284603\n",
      "2019-04-09 21:40:24,005 root         INFO     Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 0.323066\n",
      "Reconstruction: 0.105509, Regularization: 0.217556\n",
      "2019-04-09 21:40:24,050 root         INFO     Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 0.375887\n",
      "Reconstruction: 0.110559, Regularization: 0.265328\n",
      "2019-04-09 21:40:24,094 root         INFO     Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 0.335147\n",
      "Reconstruction: 0.115835, Regularization: 0.219312\n",
      "2019-04-09 21:40:24,138 root         INFO     Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 0.314270\n",
      "Reconstruction: 0.085860, Regularization: 0.228410\n",
      "2019-04-09 21:40:24,182 root         INFO     Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 0.527754\n",
      "Reconstruction: 0.315483, Regularization: 0.212271\n",
      "2019-04-09 21:40:24,226 root         INFO     Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 0.380551\n",
      "Reconstruction: 0.106794, Regularization: 0.273756\n",
      "2019-04-09 21:40:24,277 root         INFO     ====> Epoch: 88 Average loss: 0.4091\n",
      "2019-04-09 21:40:24,299 root         INFO     Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 0.318101\n",
      "Reconstruction: 0.082512, Regularization: 0.235589\n",
      "2019-04-09 21:40:24,345 root         INFO     Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 0.604759\n",
      "Reconstruction: 0.356716, Regularization: 0.248043\n",
      "2019-04-09 21:40:24,389 root         INFO     Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 0.335502\n",
      "Reconstruction: 0.128723, Regularization: 0.206779\n",
      "2019-04-09 21:40:24,435 root         INFO     Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 0.327060\n",
      "Reconstruction: 0.084710, Regularization: 0.242349\n",
      "2019-04-09 21:40:24,480 root         INFO     Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 0.337457\n",
      "Reconstruction: 0.084581, Regularization: 0.252877\n",
      "2019-04-09 21:40:24,525 root         INFO     Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 0.380919\n",
      "Reconstruction: 0.092629, Regularization: 0.288290\n",
      "2019-04-09 21:40:24,570 root         INFO     Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 0.403757\n",
      "Reconstruction: 0.103989, Regularization: 0.299769\n",
      "2019-04-09 21:40:24,616 root         INFO     Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 0.455192\n",
      "Reconstruction: 0.126406, Regularization: 0.328786\n",
      "2019-04-09 21:40:24,668 root         INFO     ====> Epoch: 89 Average loss: 0.4040\n",
      "2019-04-09 21:40:24,690 root         INFO     Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 0.354410\n",
      "Reconstruction: 0.105427, Regularization: 0.248983\n",
      "2019-04-09 21:40:24,736 root         INFO     Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 0.354722\n",
      "Reconstruction: 0.091021, Regularization: 0.263700\n",
      "2019-04-09 21:40:24,782 root         INFO     Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 0.319211\n",
      "Reconstruction: 0.108536, Regularization: 0.210675\n",
      "2019-04-09 21:40:24,827 root         INFO     Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 0.440226\n",
      "Reconstruction: 0.195931, Regularization: 0.244295\n",
      "2019-04-09 21:40:24,873 root         INFO     Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 0.386086\n",
      "Reconstruction: 0.091591, Regularization: 0.294495\n",
      "2019-04-09 21:40:24,919 root         INFO     Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 0.910628\n",
      "Reconstruction: 0.515059, Regularization: 0.395569\n",
      "2019-04-09 21:40:24,964 root         INFO     Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 0.333171\n",
      "Reconstruction: 0.089677, Regularization: 0.243493\n",
      "2019-04-09 21:40:25,010 root         INFO     Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 0.293156\n",
      "Reconstruction: 0.079847, Regularization: 0.213309\n",
      "2019-04-09 21:40:25,062 root         INFO     ====> Epoch: 90 Average loss: 0.4012\n",
      "2019-04-09 21:40:25,085 root         INFO     Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 0.432940\n",
      "Reconstruction: 0.140619, Regularization: 0.292321\n",
      "2019-04-09 21:40:25,131 root         INFO     Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 0.317641\n",
      "Reconstruction: 0.077679, Regularization: 0.239962\n",
      "2019-04-09 21:40:25,177 root         INFO     Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 0.437904\n",
      "Reconstruction: 0.162316, Regularization: 0.275588\n",
      "2019-04-09 21:40:25,223 root         INFO     Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 0.342281\n",
      "Reconstruction: 0.087844, Regularization: 0.254437\n",
      "2019-04-09 21:40:25,269 root         INFO     Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 0.339648\n",
      "Reconstruction: 0.074696, Regularization: 0.264952\n",
      "2019-04-09 21:40:25,314 root         INFO     Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 0.420784\n",
      "Reconstruction: 0.137477, Regularization: 0.283307\n",
      "2019-04-09 21:40:25,360 root         INFO     Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 0.340371\n",
      "Reconstruction: 0.113667, Regularization: 0.226704\n",
      "2019-04-09 21:40:25,405 root         INFO     Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 0.795934\n",
      "Reconstruction: 0.498418, Regularization: 0.297516\n",
      "2019-04-09 21:40:25,458 root         INFO     ====> Epoch: 91 Average loss: 0.3977\n",
      "2019-04-09 21:40:25,480 root         INFO     Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 0.398922\n",
      "Reconstruction: 0.105844, Regularization: 0.293079\n",
      "2019-04-09 21:40:25,525 root         INFO     Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 0.360729\n",
      "Reconstruction: 0.090853, Regularization: 0.269876\n",
      "2019-04-09 21:40:25,570 root         INFO     Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 0.301114\n",
      "Reconstruction: 0.088290, Regularization: 0.212824\n",
      "2019-04-09 21:40:25,614 root         INFO     Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 0.394985\n",
      "Reconstruction: 0.115183, Regularization: 0.279802\n",
      "2019-04-09 21:40:25,659 root         INFO     Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 0.313843\n",
      "Reconstruction: 0.106511, Regularization: 0.207332\n",
      "2019-04-09 21:40:25,704 root         INFO     Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 0.372187\n",
      "Reconstruction: 0.118799, Regularization: 0.253388\n",
      "2019-04-09 21:40:25,749 root         INFO     Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 0.294222\n",
      "Reconstruction: 0.090663, Regularization: 0.203558\n",
      "2019-04-09 21:40:25,794 root         INFO     Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 0.413299\n",
      "Reconstruction: 0.086410, Regularization: 0.326889\n",
      "2019-04-09 21:40:25,845 root         INFO     ====> Epoch: 92 Average loss: 0.3925\n",
      "2019-04-09 21:40:25,868 root         INFO     Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 0.368447\n",
      "Reconstruction: 0.079763, Regularization: 0.288685\n",
      "2019-04-09 21:40:25,913 root         INFO     Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 0.624228\n",
      "Reconstruction: 0.288904, Regularization: 0.335324\n",
      "2019-04-09 21:40:25,958 root         INFO     Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 0.333607\n",
      "Reconstruction: 0.091370, Regularization: 0.242237\n",
      "2019-04-09 21:40:26,003 root         INFO     Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 0.431427\n",
      "Reconstruction: 0.141003, Regularization: 0.290424\n",
      "2019-04-09 21:40:26,049 root         INFO     Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 0.504973\n",
      "Reconstruction: 0.261628, Regularization: 0.243345\n",
      "2019-04-09 21:40:26,094 root         INFO     Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 0.393970\n",
      "Reconstruction: 0.088621, Regularization: 0.305348\n",
      "2019-04-09 21:40:26,139 root         INFO     Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 0.381933\n",
      "Reconstruction: 0.107330, Regularization: 0.274603\n",
      "2019-04-09 21:40:26,184 root         INFO     Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 0.426785\n",
      "Reconstruction: 0.121085, Regularization: 0.305701\n",
      "2019-04-09 21:40:26,236 root         INFO     ====> Epoch: 93 Average loss: 0.3881\n",
      "2019-04-09 21:40:26,259 root         INFO     Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 0.342685\n",
      "Reconstruction: 0.102414, Regularization: 0.240272\n",
      "2019-04-09 21:40:26,304 root         INFO     Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 0.386164\n",
      "Reconstruction: 0.083618, Regularization: 0.302546\n",
      "2019-04-09 21:40:26,349 root         INFO     Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 0.366303\n",
      "Reconstruction: 0.103809, Regularization: 0.262494\n",
      "2019-04-09 21:40:26,395 root         INFO     Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 0.287400\n",
      "Reconstruction: 0.088992, Regularization: 0.198408\n",
      "2019-04-09 21:40:26,440 root         INFO     Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 0.343456\n",
      "Reconstruction: 0.093044, Regularization: 0.250412\n",
      "2019-04-09 21:40:26,485 root         INFO     Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 0.320465\n",
      "Reconstruction: 0.083542, Regularization: 0.236923\n",
      "2019-04-09 21:40:26,531 root         INFO     Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 0.429256\n",
      "Reconstruction: 0.083465, Regularization: 0.345791\n",
      "2019-04-09 21:40:26,576 root         INFO     Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 0.357735\n",
      "Reconstruction: 0.082991, Regularization: 0.274744\n",
      "2019-04-09 21:40:26,628 root         INFO     ====> Epoch: 94 Average loss: 0.3847\n",
      "2019-04-09 21:40:26,650 root         INFO     Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 0.311092\n",
      "Reconstruction: 0.083688, Regularization: 0.227404\n",
      "2019-04-09 21:40:26,696 root         INFO     Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 0.482564\n",
      "Reconstruction: 0.230660, Regularization: 0.251903\n",
      "2019-04-09 21:40:26,742 root         INFO     Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 0.365041\n",
      "Reconstruction: 0.143014, Regularization: 0.222027\n",
      "2019-04-09 21:40:26,787 root         INFO     Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 0.440958\n",
      "Reconstruction: 0.101358, Regularization: 0.339600\n",
      "2019-04-09 21:40:26,833 root         INFO     Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 0.337206\n",
      "Reconstruction: 0.078648, Regularization: 0.258558\n",
      "2019-04-09 21:40:26,878 root         INFO     Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 0.365348\n",
      "Reconstruction: 0.100546, Regularization: 0.264802\n",
      "2019-04-09 21:40:26,924 root         INFO     Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 0.370308\n",
      "Reconstruction: 0.103002, Regularization: 0.267306\n",
      "2019-04-09 21:40:26,969 root         INFO     Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 0.357194\n",
      "Reconstruction: 0.098443, Regularization: 0.258751\n",
      "2019-04-09 21:40:27,021 root         INFO     ====> Epoch: 95 Average loss: 0.3812\n",
      "2019-04-09 21:40:27,044 root         INFO     Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 0.306066\n",
      "Reconstruction: 0.081789, Regularization: 0.224277\n",
      "2019-04-09 21:40:27,090 root         INFO     Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 0.355273\n",
      "Reconstruction: 0.077533, Regularization: 0.277740\n",
      "2019-04-09 21:40:27,135 root         INFO     Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 0.526141\n",
      "Reconstruction: 0.246306, Regularization: 0.279834\n",
      "2019-04-09 21:40:27,181 root         INFO     Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 0.356224\n",
      "Reconstruction: 0.108138, Regularization: 0.248087\n",
      "2019-04-09 21:40:27,226 root         INFO     Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 0.394723\n",
      "Reconstruction: 0.106799, Regularization: 0.287924\n",
      "2019-04-09 21:40:27,272 root         INFO     Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 0.359494\n",
      "Reconstruction: 0.076206, Regularization: 0.283288\n",
      "2019-04-09 21:40:27,317 root         INFO     Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 0.350482\n",
      "Reconstruction: 0.072286, Regularization: 0.278197\n",
      "2019-04-09 21:40:27,362 root         INFO     Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 0.302498\n",
      "Reconstruction: 0.071602, Regularization: 0.230896\n",
      "2019-04-09 21:40:27,415 root         INFO     ====> Epoch: 96 Average loss: 0.3771\n",
      "2019-04-09 21:40:27,437 root         INFO     Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 0.312919\n",
      "Reconstruction: 0.091583, Regularization: 0.221336\n",
      "2019-04-09 21:40:27,483 root         INFO     Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 0.411329\n",
      "Reconstruction: 0.121688, Regularization: 0.289642\n",
      "2019-04-09 21:40:27,528 root         INFO     Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 0.321920\n",
      "Reconstruction: 0.081435, Regularization: 0.240485\n",
      "2019-04-09 21:40:27,573 root         INFO     Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 0.394168\n",
      "Reconstruction: 0.104055, Regularization: 0.290113\n",
      "2019-04-09 21:40:27,618 root         INFO     Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 0.542917\n",
      "Reconstruction: 0.265636, Regularization: 0.277281\n",
      "2019-04-09 21:40:27,662 root         INFO     Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 0.336035\n",
      "Reconstruction: 0.065204, Regularization: 0.270832\n",
      "2019-04-09 21:40:27,706 root         INFO     Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 0.309602\n",
      "Reconstruction: 0.090423, Regularization: 0.219179\n",
      "2019-04-09 21:40:27,751 root         INFO     Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 0.338122\n",
      "Reconstruction: 0.072283, Regularization: 0.265839\n",
      "2019-04-09 21:40:27,802 root         INFO     ====> Epoch: 97 Average loss: 0.3738\n",
      "2019-04-09 21:40:27,824 root         INFO     Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 0.306926\n",
      "Reconstruction: 0.104525, Regularization: 0.202401\n",
      "2019-04-09 21:40:27,870 root         INFO     Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 0.378801\n",
      "Reconstruction: 0.073996, Regularization: 0.304806\n",
      "2019-04-09 21:40:27,915 root         INFO     Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 0.431852\n",
      "Reconstruction: 0.148345, Regularization: 0.283506\n",
      "2019-04-09 21:40:27,960 root         INFO     Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 0.355048\n",
      "Reconstruction: 0.078299, Regularization: 0.276749\n",
      "2019-04-09 21:40:28,005 root         INFO     Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 0.358039\n",
      "Reconstruction: 0.074641, Regularization: 0.283399\n",
      "2019-04-09 21:40:28,049 root         INFO     Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 0.331066\n",
      "Reconstruction: 0.078609, Regularization: 0.252457\n",
      "2019-04-09 21:40:28,094 root         INFO     Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 0.445021\n",
      "Reconstruction: 0.136656, Regularization: 0.308365\n",
      "2019-04-09 21:40:28,138 root         INFO     Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 0.335887\n",
      "Reconstruction: 0.096644, Regularization: 0.239243\n",
      "2019-04-09 21:40:28,190 root         INFO     ====> Epoch: 98 Average loss: 0.3712\n",
      "2019-04-09 21:40:28,213 root         INFO     Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 0.333744\n",
      "Reconstruction: 0.082996, Regularization: 0.250748\n",
      "2019-04-09 21:40:28,258 root         INFO     Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 0.347109\n",
      "Reconstruction: 0.081829, Regularization: 0.265280\n",
      "2019-04-09 21:40:28,303 root         INFO     Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 0.455818\n",
      "Reconstruction: 0.170600, Regularization: 0.285218\n",
      "2019-04-09 21:40:28,349 root         INFO     Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 0.371819\n",
      "Reconstruction: 0.072431, Regularization: 0.299388\n",
      "2019-04-09 21:40:28,395 root         INFO     Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 0.423024\n",
      "Reconstruction: 0.145893, Regularization: 0.277132\n",
      "2019-04-09 21:40:28,440 root         INFO     Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 0.379877\n",
      "Reconstruction: 0.081236, Regularization: 0.298641\n",
      "2019-04-09 21:40:28,486 root         INFO     Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 0.424342\n",
      "Reconstruction: 0.129923, Regularization: 0.294419\n",
      "2019-04-09 21:40:28,532 root         INFO     Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 0.382616\n",
      "Reconstruction: 0.140941, Regularization: 0.241675\n",
      "2019-04-09 21:40:28,584 root         INFO     ====> Epoch: 99 Average loss: 0.3668\n",
      "2019-04-09 21:40:28,606 root         INFO     Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 0.331429\n",
      "Reconstruction: 0.091553, Regularization: 0.239876\n",
      "2019-04-09 21:40:28,652 root         INFO     Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 0.351294\n",
      "Reconstruction: 0.069651, Regularization: 0.281643\n",
      "2019-04-09 21:40:28,695 root         INFO     Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 0.481703\n",
      "Reconstruction: 0.177255, Regularization: 0.304448\n",
      "2019-04-09 21:40:28,739 root         INFO     Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 0.361953\n",
      "Reconstruction: 0.067488, Regularization: 0.294465\n",
      "2019-04-09 21:40:28,782 root         INFO     Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 0.368798\n",
      "Reconstruction: 0.094407, Regularization: 0.274391\n",
      "2019-04-09 21:40:28,827 root         INFO     Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 0.326798\n",
      "Reconstruction: 0.091627, Regularization: 0.235170\n",
      "2019-04-09 21:40:28,871 root         INFO     Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 0.314909\n",
      "Reconstruction: 0.099509, Regularization: 0.215400\n",
      "2019-04-09 21:40:28,916 root         INFO     Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 0.332018\n",
      "Reconstruction: 0.078153, Regularization: 0.253865\n",
      "2019-04-09 21:40:28,968 root         INFO     ====> Epoch: 100 Average loss: 0.3626\n",
      "2019-04-09 21:40:28,990 root         INFO     Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 0.343073\n",
      "Reconstruction: 0.086007, Regularization: 0.257066\n",
      "2019-04-09 21:40:29,035 root         INFO     Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 0.330236\n",
      "Reconstruction: 0.084134, Regularization: 0.246102\n",
      "2019-04-09 21:40:29,080 root         INFO     Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 0.315090\n",
      "Reconstruction: 0.076238, Regularization: 0.238852\n",
      "2019-04-09 21:40:29,125 root         INFO     Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 0.437473\n",
      "Reconstruction: 0.221551, Regularization: 0.215922\n",
      "2019-04-09 21:40:29,170 root         INFO     Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 0.357352\n",
      "Reconstruction: 0.075165, Regularization: 0.282186\n",
      "2019-04-09 21:40:29,215 root         INFO     Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 0.333533\n",
      "Reconstruction: 0.085588, Regularization: 0.247945\n",
      "2019-04-09 21:40:29,260 root         INFO     Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 0.296515\n",
      "Reconstruction: 0.071274, Regularization: 0.225240\n",
      "2019-04-09 21:40:29,304 root         INFO     Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 0.376894\n",
      "Reconstruction: 0.100857, Regularization: 0.276037\n",
      "2019-04-09 21:40:29,356 root         INFO     ====> Epoch: 101 Average loss: 0.3590\n",
      "2019-04-09 21:40:29,378 root         INFO     Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 0.381845\n",
      "Reconstruction: 0.087932, Regularization: 0.293912\n",
      "2019-04-09 21:40:29,422 root         INFO     Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 0.347171\n",
      "Reconstruction: 0.070932, Regularization: 0.276240\n",
      "2019-04-09 21:40:29,467 root         INFO     Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 0.360878\n",
      "Reconstruction: 0.106965, Regularization: 0.253913\n",
      "2019-04-09 21:40:29,511 root         INFO     Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 0.386424\n",
      "Reconstruction: 0.123007, Regularization: 0.263417\n",
      "2019-04-09 21:40:29,555 root         INFO     Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 0.330893\n",
      "Reconstruction: 0.082334, Regularization: 0.248559\n",
      "2019-04-09 21:40:29,599 root         INFO     Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 0.294199\n",
      "Reconstruction: 0.075552, Regularization: 0.218647\n",
      "2019-04-09 21:40:29,643 root         INFO     Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 0.367538\n",
      "Reconstruction: 0.074022, Regularization: 0.293516\n",
      "2019-04-09 21:40:29,688 root         INFO     Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 0.321348\n",
      "Reconstruction: 0.073847, Regularization: 0.247501\n",
      "2019-04-09 21:40:29,740 root         INFO     ====> Epoch: 102 Average loss: 0.3559\n",
      "2019-04-09 21:40:29,763 root         INFO     Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 0.449993\n",
      "Reconstruction: 0.200868, Regularization: 0.249125\n",
      "2019-04-09 21:40:29,807 root         INFO     Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 0.345031\n",
      "Reconstruction: 0.103598, Regularization: 0.241433\n",
      "2019-04-09 21:40:29,852 root         INFO     Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 0.409877\n",
      "Reconstruction: 0.144636, Regularization: 0.265242\n",
      "2019-04-09 21:40:29,896 root         INFO     Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 0.364551\n",
      "Reconstruction: 0.068502, Regularization: 0.296049\n",
      "2019-04-09 21:40:29,941 root         INFO     Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 0.458362\n",
      "Reconstruction: 0.118044, Regularization: 0.340318\n",
      "2019-04-09 21:40:29,984 root         INFO     Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 0.273590\n",
      "Reconstruction: 0.073991, Regularization: 0.199599\n",
      "2019-04-09 21:40:30,027 root         INFO     Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 0.428830\n",
      "Reconstruction: 0.180082, Regularization: 0.248748\n",
      "2019-04-09 21:40:30,069 root         INFO     Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 0.332843\n",
      "Reconstruction: 0.069805, Regularization: 0.263038\n",
      "2019-04-09 21:40:30,120 root         INFO     ====> Epoch: 103 Average loss: 0.3521\n",
      "2019-04-09 21:40:30,142 root         INFO     Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 0.343637\n",
      "Reconstruction: 0.082606, Regularization: 0.261031\n",
      "2019-04-09 21:40:30,187 root         INFO     Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 0.334260\n",
      "Reconstruction: 0.066924, Regularization: 0.267336\n",
      "2019-04-09 21:40:30,231 root         INFO     Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 0.307923\n",
      "Reconstruction: 0.075477, Regularization: 0.232447\n",
      "2019-04-09 21:40:30,275 root         INFO     Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 0.261073\n",
      "Reconstruction: 0.081697, Regularization: 0.179376\n",
      "2019-04-09 21:40:30,320 root         INFO     Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 0.356957\n",
      "Reconstruction: 0.096894, Regularization: 0.260063\n",
      "2019-04-09 21:40:30,364 root         INFO     Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 0.255238\n",
      "Reconstruction: 0.063012, Regularization: 0.192226\n",
      "2019-04-09 21:40:30,408 root         INFO     Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 0.401653\n",
      "Reconstruction: 0.086101, Regularization: 0.315552\n",
      "2019-04-09 21:40:30,452 root         INFO     Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 0.352388\n",
      "Reconstruction: 0.117304, Regularization: 0.235084\n",
      "2019-04-09 21:40:30,503 root         INFO     ====> Epoch: 104 Average loss: 0.3480\n",
      "2019-04-09 21:40:30,525 root         INFO     Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 0.301611\n",
      "Reconstruction: 0.085512, Regularization: 0.216099\n",
      "2019-04-09 21:40:30,570 root         INFO     Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 0.325377\n",
      "Reconstruction: 0.080733, Regularization: 0.244645\n",
      "2019-04-09 21:40:30,615 root         INFO     Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 0.308267\n",
      "Reconstruction: 0.072434, Regularization: 0.235833\n",
      "2019-04-09 21:40:30,659 root         INFO     Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 0.371970\n",
      "Reconstruction: 0.128844, Regularization: 0.243126\n",
      "2019-04-09 21:40:30,704 root         INFO     Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 0.334952\n",
      "Reconstruction: 0.076569, Regularization: 0.258383\n",
      "2019-04-09 21:40:30,748 root         INFO     Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 0.362010\n",
      "Reconstruction: 0.115157, Regularization: 0.246854\n",
      "2019-04-09 21:40:30,792 root         INFO     Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 0.397350\n",
      "Reconstruction: 0.094509, Regularization: 0.302841\n",
      "2019-04-09 21:40:30,836 root         INFO     Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 0.321822\n",
      "Reconstruction: 0.108018, Regularization: 0.213803\n",
      "2019-04-09 21:40:30,887 root         INFO     ====> Epoch: 105 Average loss: 0.3446\n",
      "2019-04-09 21:40:30,910 root         INFO     Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 0.336871\n",
      "Reconstruction: 0.097787, Regularization: 0.239084\n",
      "2019-04-09 21:40:30,954 root         INFO     Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 0.314863\n",
      "Reconstruction: 0.104599, Regularization: 0.210264\n",
      "2019-04-09 21:40:30,997 root         INFO     Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 0.349500\n",
      "Reconstruction: 0.067446, Regularization: 0.282054\n",
      "2019-04-09 21:40:31,040 root         INFO     Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 0.307305\n",
      "Reconstruction: 0.061604, Regularization: 0.245701\n",
      "2019-04-09 21:40:31,084 root         INFO     Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 0.308779\n",
      "Reconstruction: 0.072335, Regularization: 0.236445\n",
      "2019-04-09 21:40:31,127 root         INFO     Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 0.311554\n",
      "Reconstruction: 0.084528, Regularization: 0.227026\n",
      "2019-04-09 21:40:31,170 root         INFO     Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 0.309085\n",
      "Reconstruction: 0.089508, Regularization: 0.219577\n",
      "2019-04-09 21:40:31,214 root         INFO     Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 0.296815\n",
      "Reconstruction: 0.075228, Regularization: 0.221586\n",
      "2019-04-09 21:40:31,264 root         INFO     ====> Epoch: 106 Average loss: 0.3409\n",
      "2019-04-09 21:40:31,287 root         INFO     Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 0.336403\n",
      "Reconstruction: 0.081715, Regularization: 0.254687\n",
      "2019-04-09 21:40:31,331 root         INFO     Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 0.312153\n",
      "Reconstruction: 0.081803, Regularization: 0.230350\n",
      "2019-04-09 21:40:31,374 root         INFO     Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 0.311455\n",
      "Reconstruction: 0.094012, Regularization: 0.217443\n",
      "2019-04-09 21:40:31,418 root         INFO     Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 0.312834\n",
      "Reconstruction: 0.085594, Regularization: 0.227240\n",
      "2019-04-09 21:40:31,461 root         INFO     Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 0.332941\n",
      "Reconstruction: 0.062031, Regularization: 0.270910\n",
      "2019-04-09 21:40:31,505 root         INFO     Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 0.274649\n",
      "Reconstruction: 0.072614, Regularization: 0.202036\n",
      "2019-04-09 21:40:31,548 root         INFO     Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 0.306266\n",
      "Reconstruction: 0.091472, Regularization: 0.214793\n",
      "2019-04-09 21:40:31,591 root         INFO     Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 0.329425\n",
      "Reconstruction: 0.072069, Regularization: 0.257356\n",
      "2019-04-09 21:40:31,642 root         INFO     ====> Epoch: 107 Average loss: 0.3372\n",
      "2019-04-09 21:40:31,665 root         INFO     Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 0.313158\n",
      "Reconstruction: 0.071765, Regularization: 0.241393\n",
      "2019-04-09 21:40:31,709 root         INFO     Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 0.284756\n",
      "Reconstruction: 0.066619, Regularization: 0.218137\n",
      "2019-04-09 21:40:31,754 root         INFO     Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 0.320656\n",
      "Reconstruction: 0.087836, Regularization: 0.232819\n",
      "2019-04-09 21:40:31,799 root         INFO     Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 0.367570\n",
      "Reconstruction: 0.148245, Regularization: 0.219325\n",
      "2019-04-09 21:40:31,843 root         INFO     Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 0.354779\n",
      "Reconstruction: 0.083321, Regularization: 0.271458\n",
      "2019-04-09 21:40:31,887 root         INFO     Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 0.331973\n",
      "Reconstruction: 0.067007, Regularization: 0.264966\n",
      "2019-04-09 21:40:31,932 root         INFO     Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 0.279632\n",
      "Reconstruction: 0.068707, Regularization: 0.210924\n",
      "2019-04-09 21:40:31,976 root         INFO     Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 0.384370\n",
      "Reconstruction: 0.086719, Regularization: 0.297652\n",
      "2019-04-09 21:40:32,027 root         INFO     ====> Epoch: 108 Average loss: 0.3345\n",
      "2019-04-09 21:40:32,049 root         INFO     Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 0.313755\n",
      "Reconstruction: 0.078549, Regularization: 0.235206\n",
      "2019-04-09 21:40:32,094 root         INFO     Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 0.354440\n",
      "Reconstruction: 0.100646, Regularization: 0.253794\n",
      "2019-04-09 21:40:32,139 root         INFO     Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 0.333378\n",
      "Reconstruction: 0.076697, Regularization: 0.256681\n",
      "2019-04-09 21:40:32,182 root         INFO     Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 0.331147\n",
      "Reconstruction: 0.104206, Regularization: 0.226941\n",
      "2019-04-09 21:40:32,225 root         INFO     Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 0.586442\n",
      "Reconstruction: 0.332200, Regularization: 0.254243\n",
      "2019-04-09 21:40:32,268 root         INFO     Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 0.302844\n",
      "Reconstruction: 0.098967, Regularization: 0.203878\n",
      "2019-04-09 21:40:32,310 root         INFO     Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 0.317553\n",
      "Reconstruction: 0.074325, Regularization: 0.243228\n",
      "2019-04-09 21:40:32,353 root         INFO     Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 0.333388\n",
      "Reconstruction: 0.074772, Regularization: 0.258616\n",
      "2019-04-09 21:40:32,403 root         INFO     ====> Epoch: 109 Average loss: 0.3298\n",
      "2019-04-09 21:40:32,425 root         INFO     Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 0.282675\n",
      "Reconstruction: 0.074836, Regularization: 0.207839\n",
      "2019-04-09 21:40:32,469 root         INFO     Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 0.297842\n",
      "Reconstruction: 0.082611, Regularization: 0.215231\n",
      "2019-04-09 21:40:32,513 root         INFO     Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 0.374646\n",
      "Reconstruction: 0.061504, Regularization: 0.313142\n",
      "2019-04-09 21:40:32,556 root         INFO     Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 0.268646\n",
      "Reconstruction: 0.090535, Regularization: 0.178111\n",
      "2019-04-09 21:40:32,600 root         INFO     Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 0.344123\n",
      "Reconstruction: 0.069854, Regularization: 0.274269\n",
      "2019-04-09 21:40:32,644 root         INFO     Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 0.312554\n",
      "Reconstruction: 0.095189, Regularization: 0.217365\n",
      "2019-04-09 21:40:32,687 root         INFO     Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 0.336039\n",
      "Reconstruction: 0.065997, Regularization: 0.270042\n",
      "2019-04-09 21:40:32,730 root         INFO     Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 0.289452\n",
      "Reconstruction: 0.065477, Regularization: 0.223975\n",
      "2019-04-09 21:40:32,780 root         INFO     ====> Epoch: 110 Average loss: 0.3264\n",
      "2019-04-09 21:40:32,803 root         INFO     Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 0.408601\n",
      "Reconstruction: 0.157256, Regularization: 0.251345\n",
      "2019-04-09 21:40:32,847 root         INFO     Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 0.314886\n",
      "Reconstruction: 0.085642, Regularization: 0.229243\n",
      "2019-04-09 21:40:32,892 root         INFO     Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 0.343252\n",
      "Reconstruction: 0.118402, Regularization: 0.224850\n",
      "2019-04-09 21:40:32,937 root         INFO     Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 0.314514\n",
      "Reconstruction: 0.059679, Regularization: 0.254835\n",
      "2019-04-09 21:40:32,982 root         INFO     Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 0.288597\n",
      "Reconstruction: 0.088948, Regularization: 0.199649\n",
      "2019-04-09 21:40:33,026 root         INFO     Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 0.352177\n",
      "Reconstruction: 0.119405, Regularization: 0.232771\n",
      "2019-04-09 21:40:33,071 root         INFO     Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 0.251891\n",
      "Reconstruction: 0.070175, Regularization: 0.181717\n",
      "2019-04-09 21:40:33,116 root         INFO     Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 0.347267\n",
      "Reconstruction: 0.127587, Regularization: 0.219680\n",
      "2019-04-09 21:40:33,167 root         INFO     ====> Epoch: 111 Average loss: 0.3226\n",
      "2019-04-09 21:40:33,190 root         INFO     Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 0.291581\n",
      "Reconstruction: 0.065968, Regularization: 0.225613\n",
      "2019-04-09 21:40:33,234 root         INFO     Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 0.297375\n",
      "Reconstruction: 0.066570, Regularization: 0.230804\n",
      "2019-04-09 21:40:33,278 root         INFO     Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 0.304066\n",
      "Reconstruction: 0.072385, Regularization: 0.231680\n",
      "2019-04-09 21:40:33,323 root         INFO     Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 0.346051\n",
      "Reconstruction: 0.112208, Regularization: 0.233842\n",
      "2019-04-09 21:40:33,367 root         INFO     Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 0.291636\n",
      "Reconstruction: 0.073746, Regularization: 0.217890\n",
      "2019-04-09 21:40:33,412 root         INFO     Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 0.342941\n",
      "Reconstruction: 0.068812, Regularization: 0.274129\n",
      "2019-04-09 21:40:33,456 root         INFO     Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 0.306734\n",
      "Reconstruction: 0.097078, Regularization: 0.209657\n",
      "2019-04-09 21:40:33,501 root         INFO     Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 0.330335\n",
      "Reconstruction: 0.071541, Regularization: 0.258793\n",
      "2019-04-09 21:40:33,553 root         INFO     ====> Epoch: 112 Average loss: 0.3190\n",
      "2019-04-09 21:40:33,576 root         INFO     Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 0.305509\n",
      "Reconstruction: 0.103704, Regularization: 0.201805\n",
      "2019-04-09 21:40:33,621 root         INFO     Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 0.300454\n",
      "Reconstruction: 0.096147, Regularization: 0.204307\n",
      "2019-04-09 21:40:33,666 root         INFO     Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 0.288007\n",
      "Reconstruction: 0.061262, Regularization: 0.226745\n",
      "2019-04-09 21:40:33,710 root         INFO     Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 0.294064\n",
      "Reconstruction: 0.091207, Regularization: 0.202857\n",
      "2019-04-09 21:40:33,754 root         INFO     Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 0.274318\n",
      "Reconstruction: 0.073048, Regularization: 0.201271\n",
      "2019-04-09 21:40:33,799 root         INFO     Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 0.312642\n",
      "Reconstruction: 0.066708, Regularization: 0.245934\n",
      "2019-04-09 21:40:33,843 root         INFO     Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 0.375787\n",
      "Reconstruction: 0.116661, Regularization: 0.259126\n",
      "2019-04-09 21:40:33,887 root         INFO     Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 0.325980\n",
      "Reconstruction: 0.097853, Regularization: 0.228127\n",
      "2019-04-09 21:40:33,939 root         INFO     ====> Epoch: 113 Average loss: 0.3155\n",
      "2019-04-09 21:40:33,961 root         INFO     Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 0.298535\n",
      "Reconstruction: 0.080071, Regularization: 0.218464\n",
      "2019-04-09 21:40:34,006 root         INFO     Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 0.293878\n",
      "Reconstruction: 0.075512, Regularization: 0.218366\n",
      "2019-04-09 21:40:34,050 root         INFO     Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 0.276245\n",
      "Reconstruction: 0.077643, Regularization: 0.198602\n",
      "2019-04-09 21:40:34,095 root         INFO     Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 0.284100\n",
      "Reconstruction: 0.082194, Regularization: 0.201906\n",
      "2019-04-09 21:40:34,139 root         INFO     Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 0.339047\n",
      "Reconstruction: 0.095550, Regularization: 0.243497\n",
      "2019-04-09 21:40:34,184 root         INFO     Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 0.367128\n",
      "Reconstruction: 0.112734, Regularization: 0.254394\n",
      "2019-04-09 21:40:34,229 root         INFO     Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 0.292922\n",
      "Reconstruction: 0.068828, Regularization: 0.224094\n",
      "2019-04-09 21:40:34,273 root         INFO     Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 0.333545\n",
      "Reconstruction: 0.105697, Regularization: 0.227848\n",
      "2019-04-09 21:40:34,324 root         INFO     ====> Epoch: 114 Average loss: 0.3116\n",
      "2019-04-09 21:40:34,347 root         INFO     Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 0.312948\n",
      "Reconstruction: 0.074141, Regularization: 0.238807\n",
      "2019-04-09 21:40:34,392 root         INFO     Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 0.321347\n",
      "Reconstruction: 0.081637, Regularization: 0.239710\n",
      "2019-04-09 21:40:34,438 root         INFO     Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 0.279518\n",
      "Reconstruction: 0.078405, Regularization: 0.201113\n",
      "2019-04-09 21:40:34,483 root         INFO     Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 0.377463\n",
      "Reconstruction: 0.080255, Regularization: 0.297209\n",
      "2019-04-09 21:40:34,528 root         INFO     Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 0.298170\n",
      "Reconstruction: 0.076903, Regularization: 0.221267\n",
      "2019-04-09 21:40:34,574 root         INFO     Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 0.286955\n",
      "Reconstruction: 0.059283, Regularization: 0.227672\n",
      "2019-04-09 21:40:34,619 root         INFO     Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 0.276703\n",
      "Reconstruction: 0.088834, Regularization: 0.187869\n",
      "2019-04-09 21:40:34,665 root         INFO     Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 0.307240\n",
      "Reconstruction: 0.063639, Regularization: 0.243601\n",
      "2019-04-09 21:40:34,717 root         INFO     ====> Epoch: 115 Average loss: 0.3080\n",
      "2019-04-09 21:40:34,740 root         INFO     Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 0.310494\n",
      "Reconstruction: 0.068164, Regularization: 0.242329\n",
      "2019-04-09 21:40:34,785 root         INFO     Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 0.312457\n",
      "Reconstruction: 0.074222, Regularization: 0.238235\n",
      "2019-04-09 21:40:34,829 root         INFO     Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 0.306464\n",
      "Reconstruction: 0.072386, Regularization: 0.234078\n",
      "2019-04-09 21:40:34,873 root         INFO     Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 0.363024\n",
      "Reconstruction: 0.086236, Regularization: 0.276788\n",
      "2019-04-09 21:40:34,918 root         INFO     Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 0.253278\n",
      "Reconstruction: 0.074915, Regularization: 0.178363\n",
      "2019-04-09 21:40:34,963 root         INFO     Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 0.256935\n",
      "Reconstruction: 0.061056, Regularization: 0.195879\n",
      "2019-04-09 21:40:35,007 root         INFO     Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 0.379381\n",
      "Reconstruction: 0.089555, Regularization: 0.289826\n",
      "2019-04-09 21:40:35,051 root         INFO     Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 0.281007\n",
      "Reconstruction: 0.074320, Regularization: 0.206687\n",
      "2019-04-09 21:40:35,102 root         INFO     ====> Epoch: 116 Average loss: 0.3045\n",
      "2019-04-09 21:40:35,125 root         INFO     Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 0.259209\n",
      "Reconstruction: 0.076923, Regularization: 0.182286\n",
      "2019-04-09 21:40:35,170 root         INFO     Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 0.289736\n",
      "Reconstruction: 0.082805, Regularization: 0.206931\n",
      "2019-04-09 21:40:35,214 root         INFO     Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 0.326813\n",
      "Reconstruction: 0.074166, Regularization: 0.252647\n",
      "2019-04-09 21:40:35,258 root         INFO     Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 0.309907\n",
      "Reconstruction: 0.055881, Regularization: 0.254026\n",
      "2019-04-09 21:40:35,303 root         INFO     Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 0.335161\n",
      "Reconstruction: 0.077902, Regularization: 0.257260\n",
      "2019-04-09 21:40:35,347 root         INFO     Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 0.314042\n",
      "Reconstruction: 0.076764, Regularization: 0.237278\n",
      "2019-04-09 21:40:35,391 root         INFO     Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 0.278137\n",
      "Reconstruction: 0.073601, Regularization: 0.204536\n",
      "2019-04-09 21:40:35,435 root         INFO     Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 0.299567\n",
      "Reconstruction: 0.078211, Regularization: 0.221356\n",
      "2019-04-09 21:40:35,487 root         INFO     ====> Epoch: 117 Average loss: 0.3009\n",
      "2019-04-09 21:40:35,509 root         INFO     Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 0.258046\n",
      "Reconstruction: 0.060290, Regularization: 0.197755\n",
      "2019-04-09 21:40:35,554 root         INFO     Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 0.302205\n",
      "Reconstruction: 0.068195, Regularization: 0.234010\n",
      "2019-04-09 21:40:35,598 root         INFO     Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 0.348200\n",
      "Reconstruction: 0.098646, Regularization: 0.249554\n",
      "2019-04-09 21:40:35,642 root         INFO     Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 0.300792\n",
      "Reconstruction: 0.067101, Regularization: 0.233691\n",
      "2019-04-09 21:40:35,687 root         INFO     Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 0.301196\n",
      "Reconstruction: 0.081571, Regularization: 0.219625\n",
      "2019-04-09 21:40:35,730 root         INFO     Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 0.330861\n",
      "Reconstruction: 0.063964, Regularization: 0.266897\n",
      "2019-04-09 21:40:35,773 root         INFO     Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 0.264631\n",
      "Reconstruction: 0.058682, Regularization: 0.205950\n",
      "2019-04-09 21:40:35,817 root         INFO     Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 0.209650\n",
      "Reconstruction: 0.062456, Regularization: 0.147194\n",
      "2019-04-09 21:40:35,868 root         INFO     ====> Epoch: 118 Average loss: 0.2970\n",
      "2019-04-09 21:40:35,891 root         INFO     Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 0.321753\n",
      "Reconstruction: 0.064601, Regularization: 0.257152\n",
      "2019-04-09 21:40:35,936 root         INFO     Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 0.253877\n",
      "Reconstruction: 0.074385, Regularization: 0.179492\n",
      "2019-04-09 21:40:35,980 root         INFO     Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 0.281370\n",
      "Reconstruction: 0.070399, Regularization: 0.210970\n",
      "2019-04-09 21:40:36,028 root         INFO     Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 0.365862\n",
      "Reconstruction: 0.121186, Regularization: 0.244676\n",
      "2019-04-09 21:40:36,076 root         INFO     Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 0.299393\n",
      "Reconstruction: 0.074636, Regularization: 0.224757\n",
      "2019-04-09 21:40:36,124 root         INFO     Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 0.262153\n",
      "Reconstruction: 0.078385, Regularization: 0.183768\n",
      "2019-04-09 21:40:36,170 root         INFO     Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 0.257180\n",
      "Reconstruction: 0.091204, Regularization: 0.165976\n",
      "2019-04-09 21:40:36,217 root         INFO     Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 0.361133\n",
      "Reconstruction: 0.085651, Regularization: 0.275482\n",
      "2019-04-09 21:40:36,270 root         INFO     ====> Epoch: 119 Average loss: 0.2933\n",
      "2019-04-09 21:40:36,293 root         INFO     Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 0.284004\n",
      "Reconstruction: 0.071407, Regularization: 0.212596\n",
      "2019-04-09 21:40:36,338 root         INFO     Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 0.255879\n",
      "Reconstruction: 0.071738, Regularization: 0.184141\n",
      "2019-04-09 21:40:36,383 root         INFO     Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 0.332162\n",
      "Reconstruction: 0.091055, Regularization: 0.241107\n",
      "2019-04-09 21:40:36,427 root         INFO     Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 0.274110\n",
      "Reconstruction: 0.069996, Regularization: 0.204115\n",
      "2019-04-09 21:40:36,471 root         INFO     Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 0.298550\n",
      "Reconstruction: 0.074606, Regularization: 0.223944\n",
      "2019-04-09 21:40:36,515 root         INFO     Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 0.336674\n",
      "Reconstruction: 0.059198, Regularization: 0.277476\n",
      "2019-04-09 21:40:36,559 root         INFO     Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 0.252839\n",
      "Reconstruction: 0.062863, Regularization: 0.189976\n",
      "2019-04-09 21:40:36,602 root         INFO     Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 0.315418\n",
      "Reconstruction: 0.083473, Regularization: 0.231945\n",
      "2019-04-09 21:40:36,651 root         INFO     ====> Epoch: 120 Average loss: 0.2896\n",
      "2019-04-09 21:40:36,674 root         INFO     Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 0.269471\n",
      "Reconstruction: 0.074763, Regularization: 0.194708\n",
      "2019-04-09 21:40:36,718 root         INFO     Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 0.311191\n",
      "Reconstruction: 0.062671, Regularization: 0.248520\n",
      "2019-04-09 21:40:36,763 root         INFO     Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 0.312519\n",
      "Reconstruction: 0.082613, Regularization: 0.229906\n",
      "2019-04-09 21:40:36,808 root         INFO     Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 0.312668\n",
      "Reconstruction: 0.071574, Regularization: 0.241094\n",
      "2019-04-09 21:40:36,852 root         INFO     Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 0.255990\n",
      "Reconstruction: 0.059705, Regularization: 0.196285\n",
      "2019-04-09 21:40:36,896 root         INFO     Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 0.307772\n",
      "Reconstruction: 0.079597, Regularization: 0.228175\n",
      "2019-04-09 21:40:36,940 root         INFO     Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 0.278234\n",
      "Reconstruction: 0.070430, Regularization: 0.207804\n",
      "2019-04-09 21:40:36,985 root         INFO     Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 0.321566\n",
      "Reconstruction: 0.086763, Regularization: 0.234803\n",
      "2019-04-09 21:40:37,036 root         INFO     ====> Epoch: 121 Average loss: 0.2859\n",
      "2019-04-09 21:40:37,058 root         INFO     Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 0.245072\n",
      "Reconstruction: 0.060417, Regularization: 0.184655\n",
      "2019-04-09 21:40:37,103 root         INFO     Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 0.246965\n",
      "Reconstruction: 0.058425, Regularization: 0.188541\n",
      "2019-04-09 21:40:37,148 root         INFO     Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 0.341264\n",
      "Reconstruction: 0.081215, Regularization: 0.260049\n",
      "2019-04-09 21:40:37,192 root         INFO     Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 0.275467\n",
      "Reconstruction: 0.081830, Regularization: 0.193638\n",
      "2019-04-09 21:40:37,236 root         INFO     Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 0.327135\n",
      "Reconstruction: 0.093157, Regularization: 0.233978\n",
      "2019-04-09 21:40:37,280 root         INFO     Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 0.291948\n",
      "Reconstruction: 0.069385, Regularization: 0.222562\n",
      "2019-04-09 21:40:37,324 root         INFO     Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 0.257267\n",
      "Reconstruction: 0.073051, Regularization: 0.184216\n",
      "2019-04-09 21:40:37,368 root         INFO     Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 0.289928\n",
      "Reconstruction: 0.071264, Regularization: 0.218664\n",
      "2019-04-09 21:40:37,418 root         INFO     ====> Epoch: 122 Average loss: 0.2820\n",
      "2019-04-09 21:40:37,441 root         INFO     Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 0.293941\n",
      "Reconstruction: 0.061253, Regularization: 0.232688\n",
      "2019-04-09 21:40:37,486 root         INFO     Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 0.280525\n",
      "Reconstruction: 0.067883, Regularization: 0.212642\n",
      "2019-04-09 21:40:37,531 root         INFO     Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 0.296965\n",
      "Reconstruction: 0.119788, Regularization: 0.177177\n",
      "2019-04-09 21:40:37,576 root         INFO     Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 0.293800\n",
      "Reconstruction: 0.073743, Regularization: 0.220057\n",
      "2019-04-09 21:40:37,621 root         INFO     Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 0.293363\n",
      "Reconstruction: 0.064847, Regularization: 0.228516\n",
      "2019-04-09 21:40:37,664 root         INFO     Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 0.296519\n",
      "Reconstruction: 0.083305, Regularization: 0.213213\n",
      "2019-04-09 21:40:37,707 root         INFO     Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 0.259865\n",
      "Reconstruction: 0.077289, Regularization: 0.182576\n",
      "2019-04-09 21:40:37,749 root         INFO     Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 0.272589\n",
      "Reconstruction: 0.067336, Regularization: 0.205254\n",
      "2019-04-09 21:40:37,799 root         INFO     ====> Epoch: 123 Average loss: 0.2780\n",
      "2019-04-09 21:40:37,821 root         INFO     Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 0.256587\n",
      "Reconstruction: 0.056958, Regularization: 0.199629\n",
      "2019-04-09 21:40:37,866 root         INFO     Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 0.313609\n",
      "Reconstruction: 0.062258, Regularization: 0.251350\n",
      "2019-04-09 21:40:37,911 root         INFO     Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 0.229851\n",
      "Reconstruction: 0.070146, Regularization: 0.159705\n",
      "2019-04-09 21:40:37,956 root         INFO     Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 0.249710\n",
      "Reconstruction: 0.065597, Regularization: 0.184113\n",
      "2019-04-09 21:40:38,000 root         INFO     Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 0.222253\n",
      "Reconstruction: 0.056074, Regularization: 0.166179\n",
      "2019-04-09 21:40:38,044 root         INFO     Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 0.264140\n",
      "Reconstruction: 0.087936, Regularization: 0.176205\n",
      "2019-04-09 21:40:38,088 root         INFO     Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 0.256176\n",
      "Reconstruction: 0.064062, Regularization: 0.192114\n",
      "2019-04-09 21:40:38,132 root         INFO     Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 0.261574\n",
      "Reconstruction: 0.055475, Regularization: 0.206099\n",
      "2019-04-09 21:40:38,184 root         INFO     ====> Epoch: 124 Average loss: 0.2740\n",
      "2019-04-09 21:40:38,206 root         INFO     Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 0.246096\n",
      "Reconstruction: 0.062612, Regularization: 0.183484\n",
      "2019-04-09 21:40:38,250 root         INFO     Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 0.249815\n",
      "Reconstruction: 0.058827, Regularization: 0.190988\n",
      "2019-04-09 21:40:38,295 root         INFO     Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 0.251328\n",
      "Reconstruction: 0.057027, Regularization: 0.194301\n",
      "2019-04-09 21:40:38,339 root         INFO     Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 0.247314\n",
      "Reconstruction: 0.061556, Regularization: 0.185759\n",
      "2019-04-09 21:40:38,383 root         INFO     Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 0.249806\n",
      "Reconstruction: 0.063724, Regularization: 0.186082\n",
      "2019-04-09 21:40:38,428 root         INFO     Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 0.293904\n",
      "Reconstruction: 0.072349, Regularization: 0.221554\n",
      "2019-04-09 21:40:38,472 root         INFO     Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 0.327420\n",
      "Reconstruction: 0.079330, Regularization: 0.248090\n",
      "2019-04-09 21:40:38,517 root         INFO     Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 0.253054\n",
      "Reconstruction: 0.065552, Regularization: 0.187502\n",
      "2019-04-09 21:40:38,568 root         INFO     ====> Epoch: 125 Average loss: 0.2705\n",
      "2019-04-09 21:40:38,591 root         INFO     Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 0.311145\n",
      "Reconstruction: 0.058620, Regularization: 0.252525\n",
      "2019-04-09 21:40:38,636 root         INFO     Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 0.325929\n",
      "Reconstruction: 0.067576, Regularization: 0.258353\n",
      "2019-04-09 21:40:38,681 root         INFO     Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 0.266309\n",
      "Reconstruction: 0.067089, Regularization: 0.199220\n",
      "2019-04-09 21:40:38,724 root         INFO     Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 0.224546\n",
      "Reconstruction: 0.063073, Regularization: 0.161473\n",
      "2019-04-09 21:40:38,768 root         INFO     Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 0.277559\n",
      "Reconstruction: 0.076376, Regularization: 0.201183\n",
      "2019-04-09 21:40:38,813 root         INFO     Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 0.256506\n",
      "Reconstruction: 0.081387, Regularization: 0.175119\n",
      "2019-04-09 21:40:38,856 root         INFO     Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 0.290903\n",
      "Reconstruction: 0.064631, Regularization: 0.226272\n",
      "2019-04-09 21:40:38,899 root         INFO     Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 0.280250\n",
      "Reconstruction: 0.068443, Regularization: 0.211807\n",
      "2019-04-09 21:40:38,950 root         INFO     ====> Epoch: 126 Average loss: 0.2666\n",
      "2019-04-09 21:40:38,972 root         INFO     Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 0.232024\n",
      "Reconstruction: 0.061718, Regularization: 0.170306\n",
      "2019-04-09 21:40:39,017 root         INFO     Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 0.230340\n",
      "Reconstruction: 0.070158, Regularization: 0.160183\n",
      "2019-04-09 21:40:39,062 root         INFO     Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 0.262848\n",
      "Reconstruction: 0.062859, Regularization: 0.199989\n",
      "2019-04-09 21:40:39,106 root         INFO     Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 0.298040\n",
      "Reconstruction: 0.071430, Regularization: 0.226610\n",
      "2019-04-09 21:40:39,150 root         INFO     Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 0.261527\n",
      "Reconstruction: 0.081099, Regularization: 0.180428\n",
      "2019-04-09 21:40:39,195 root         INFO     Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 0.246541\n",
      "Reconstruction: 0.074733, Regularization: 0.171808\n",
      "2019-04-09 21:40:39,239 root         INFO     Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 0.248878\n",
      "Reconstruction: 0.059817, Regularization: 0.189061\n",
      "2019-04-09 21:40:39,283 root         INFO     Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 0.397350\n",
      "Reconstruction: 0.153112, Regularization: 0.244238\n",
      "2019-04-09 21:40:39,334 root         INFO     ====> Epoch: 127 Average loss: 0.2625\n",
      "2019-04-09 21:40:39,357 root         INFO     Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 0.336003\n",
      "Reconstruction: 0.073387, Regularization: 0.262616\n",
      "2019-04-09 21:40:39,402 root         INFO     Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 0.188124\n",
      "Reconstruction: 0.058449, Regularization: 0.129674\n",
      "2019-04-09 21:40:39,447 root         INFO     Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 0.283761\n",
      "Reconstruction: 0.065073, Regularization: 0.218688\n",
      "2019-04-09 21:40:39,492 root         INFO     Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 0.284393\n",
      "Reconstruction: 0.068214, Regularization: 0.216179\n",
      "2019-04-09 21:40:39,537 root         INFO     Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 0.239140\n",
      "Reconstruction: 0.060580, Regularization: 0.178560\n",
      "2019-04-09 21:40:39,582 root         INFO     Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 0.239479\n",
      "Reconstruction: 0.058718, Regularization: 0.180760\n",
      "2019-04-09 21:40:39,626 root         INFO     Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 0.238513\n",
      "Reconstruction: 0.059740, Regularization: 0.178773\n",
      "2019-04-09 21:40:39,671 root         INFO     Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 0.230369\n",
      "Reconstruction: 0.076267, Regularization: 0.154102\n",
      "2019-04-09 21:40:39,723 root         INFO     ====> Epoch: 128 Average loss: 0.2588\n",
      "2019-04-09 21:40:39,745 root         INFO     Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 0.242913\n",
      "Reconstruction: 0.058541, Regularization: 0.184372\n",
      "2019-04-09 21:40:39,789 root         INFO     Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 0.275281\n",
      "Reconstruction: 0.059234, Regularization: 0.216048\n",
      "2019-04-09 21:40:39,833 root         INFO     Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 0.267297\n",
      "Reconstruction: 0.074792, Regularization: 0.192504\n",
      "2019-04-09 21:40:39,877 root         INFO     Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 0.302411\n",
      "Reconstruction: 0.094184, Regularization: 0.208227\n",
      "2019-04-09 21:40:39,921 root         INFO     Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 0.289680\n",
      "Reconstruction: 0.061922, Regularization: 0.227759\n",
      "2019-04-09 21:40:39,964 root         INFO     Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 0.253020\n",
      "Reconstruction: 0.059939, Regularization: 0.193081\n",
      "2019-04-09 21:40:40,009 root         INFO     Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 0.271955\n",
      "Reconstruction: 0.069179, Regularization: 0.202776\n",
      "2019-04-09 21:40:40,053 root         INFO     Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 0.264004\n",
      "Reconstruction: 0.064805, Regularization: 0.199199\n",
      "2019-04-09 21:40:40,105 root         INFO     ====> Epoch: 129 Average loss: 0.2548\n",
      "2019-04-09 21:40:40,127 root         INFO     Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 0.214102\n",
      "Reconstruction: 0.067968, Regularization: 0.146134\n",
      "2019-04-09 21:40:40,172 root         INFO     Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 0.224614\n",
      "Reconstruction: 0.068954, Regularization: 0.155660\n",
      "2019-04-09 21:40:40,217 root         INFO     Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 0.256310\n",
      "Reconstruction: 0.074242, Regularization: 0.182068\n",
      "2019-04-09 21:40:40,261 root         INFO     Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 0.268175\n",
      "Reconstruction: 0.073816, Regularization: 0.194358\n",
      "2019-04-09 21:40:40,306 root         INFO     Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 0.262852\n",
      "Reconstruction: 0.063948, Regularization: 0.198905\n",
      "2019-04-09 21:40:40,350 root         INFO     Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 0.215198\n",
      "Reconstruction: 0.055580, Regularization: 0.159618\n",
      "2019-04-09 21:40:40,394 root         INFO     Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 0.243213\n",
      "Reconstruction: 0.071349, Regularization: 0.171864\n",
      "2019-04-09 21:40:40,437 root         INFO     Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 0.220513\n",
      "Reconstruction: 0.058104, Regularization: 0.162409\n",
      "2019-04-09 21:40:40,487 root         INFO     ====> Epoch: 130 Average loss: 0.2507\n",
      "2019-04-09 21:40:40,510 root         INFO     Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 0.281546\n",
      "Reconstruction: 0.069214, Regularization: 0.212332\n",
      "2019-04-09 21:40:40,553 root         INFO     Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 0.224380\n",
      "Reconstruction: 0.062270, Regularization: 0.162110\n",
      "2019-04-09 21:40:40,597 root         INFO     Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 0.248039\n",
      "Reconstruction: 0.063579, Regularization: 0.184460\n",
      "2019-04-09 21:40:40,641 root         INFO     Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 0.259840\n",
      "Reconstruction: 0.058715, Regularization: 0.201125\n",
      "2019-04-09 21:40:40,684 root         INFO     Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 0.290585\n",
      "Reconstruction: 0.067200, Regularization: 0.223386\n",
      "2019-04-09 21:40:40,728 root         INFO     Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 0.250043\n",
      "Reconstruction: 0.064677, Regularization: 0.185366\n",
      "2019-04-09 21:40:40,771 root         INFO     Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 0.201400\n",
      "Reconstruction: 0.057143, Regularization: 0.144257\n",
      "2019-04-09 21:40:40,815 root         INFO     Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 0.270492\n",
      "Reconstruction: 0.067366, Regularization: 0.203125\n",
      "2019-04-09 21:40:40,865 root         INFO     ====> Epoch: 131 Average loss: 0.2470\n",
      "2019-04-09 21:40:40,888 root         INFO     Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 0.241447\n",
      "Reconstruction: 0.065583, Regularization: 0.175864\n",
      "2019-04-09 21:40:40,931 root         INFO     Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 0.221259\n",
      "Reconstruction: 0.066370, Regularization: 0.154889\n",
      "2019-04-09 21:40:40,975 root         INFO     Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 0.267625\n",
      "Reconstruction: 0.066793, Regularization: 0.200832\n",
      "2019-04-09 21:40:41,018 root         INFO     Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 0.292940\n",
      "Reconstruction: 0.059767, Regularization: 0.233173\n",
      "2019-04-09 21:40:41,061 root         INFO     Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 0.235034\n",
      "Reconstruction: 0.072164, Regularization: 0.162870\n",
      "2019-04-09 21:40:41,105 root         INFO     Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 0.251434\n",
      "Reconstruction: 0.064098, Regularization: 0.187336\n",
      "2019-04-09 21:40:41,148 root         INFO     Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 0.249442\n",
      "Reconstruction: 0.064608, Regularization: 0.184834\n",
      "2019-04-09 21:40:41,191 root         INFO     Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 0.241000\n",
      "Reconstruction: 0.065786, Regularization: 0.175214\n",
      "2019-04-09 21:40:41,242 root         INFO     ====> Epoch: 132 Average loss: 0.2428\n",
      "2019-04-09 21:40:41,264 root         INFO     Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 0.268414\n",
      "Reconstruction: 0.070571, Regularization: 0.197844\n",
      "2019-04-09 21:40:41,309 root         INFO     Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 0.186770\n",
      "Reconstruction: 0.054424, Regularization: 0.132346\n",
      "2019-04-09 21:40:41,353 root         INFO     Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 0.224441\n",
      "Reconstruction: 0.063726, Regularization: 0.160715\n",
      "2019-04-09 21:40:41,397 root         INFO     Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 0.231357\n",
      "Reconstruction: 0.060348, Regularization: 0.171009\n",
      "2019-04-09 21:40:41,441 root         INFO     Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 0.249142\n",
      "Reconstruction: 0.064427, Regularization: 0.184715\n",
      "2019-04-09 21:40:41,485 root         INFO     Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 0.258808\n",
      "Reconstruction: 0.051738, Regularization: 0.207070\n",
      "2019-04-09 21:40:41,530 root         INFO     Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 0.197378\n",
      "Reconstruction: 0.056398, Regularization: 0.140980\n",
      "2019-04-09 21:40:41,574 root         INFO     Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 0.233366\n",
      "Reconstruction: 0.067641, Regularization: 0.165725\n",
      "2019-04-09 21:40:41,624 root         INFO     ====> Epoch: 133 Average loss: 0.2388\n",
      "2019-04-09 21:40:41,648 root         INFO     Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 0.225657\n",
      "Reconstruction: 0.062826, Regularization: 0.162831\n",
      "2019-04-09 21:40:41,693 root         INFO     Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 0.224693\n",
      "Reconstruction: 0.056694, Regularization: 0.167999\n",
      "2019-04-09 21:40:41,737 root         INFO     Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 0.215261\n",
      "Reconstruction: 0.071106, Regularization: 0.144154\n",
      "2019-04-09 21:40:41,781 root         INFO     Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 0.219095\n",
      "Reconstruction: 0.065512, Regularization: 0.153583\n",
      "2019-04-09 21:40:41,825 root         INFO     Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 0.249590\n",
      "Reconstruction: 0.068147, Regularization: 0.181443\n",
      "2019-04-09 21:40:41,869 root         INFO     Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 0.235625\n",
      "Reconstruction: 0.059707, Regularization: 0.175918\n",
      "2019-04-09 21:40:41,913 root         INFO     Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 0.247378\n",
      "Reconstruction: 0.062016, Regularization: 0.185362\n",
      "2019-04-09 21:40:41,957 root         INFO     Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 0.209781\n",
      "Reconstruction: 0.057352, Regularization: 0.152429\n",
      "2019-04-09 21:40:42,008 root         INFO     ====> Epoch: 134 Average loss: 0.2351\n",
      "2019-04-09 21:40:42,030 root         INFO     Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 0.246139\n",
      "Reconstruction: 0.060382, Regularization: 0.185757\n",
      "2019-04-09 21:40:42,074 root         INFO     Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 0.248149\n",
      "Reconstruction: 0.071083, Regularization: 0.177066\n",
      "2019-04-09 21:40:42,117 root         INFO     Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 0.234744\n",
      "Reconstruction: 0.074004, Regularization: 0.160740\n",
      "2019-04-09 21:40:42,161 root         INFO     Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 0.241564\n",
      "Reconstruction: 0.060934, Regularization: 0.180630\n",
      "2019-04-09 21:40:42,204 root         INFO     Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 0.174085\n",
      "Reconstruction: 0.059494, Regularization: 0.114592\n",
      "2019-04-09 21:40:42,248 root         INFO     Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 0.233908\n",
      "Reconstruction: 0.059677, Regularization: 0.174231\n",
      "2019-04-09 21:40:42,291 root         INFO     Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 0.229357\n",
      "Reconstruction: 0.062868, Regularization: 0.166489\n",
      "2019-04-09 21:40:42,334 root         INFO     Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 0.232902\n",
      "Reconstruction: 0.055542, Regularization: 0.177360\n",
      "2019-04-09 21:40:42,385 root         INFO     ====> Epoch: 135 Average loss: 0.2308\n",
      "2019-04-09 21:40:42,408 root         INFO     Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 0.219702\n",
      "Reconstruction: 0.061044, Regularization: 0.158659\n",
      "2019-04-09 21:40:42,452 root         INFO     Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 0.210966\n",
      "Reconstruction: 0.066809, Regularization: 0.144157\n",
      "2019-04-09 21:40:42,496 root         INFO     Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 0.231937\n",
      "Reconstruction: 0.061578, Regularization: 0.170359\n",
      "2019-04-09 21:40:42,540 root         INFO     Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 0.249897\n",
      "Reconstruction: 0.056061, Regularization: 0.193836\n",
      "2019-04-09 21:40:42,584 root         INFO     Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 0.249632\n",
      "Reconstruction: 0.053449, Regularization: 0.196184\n",
      "2019-04-09 21:40:42,629 root         INFO     Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 0.226819\n",
      "Reconstruction: 0.071786, Regularization: 0.155033\n",
      "2019-04-09 21:40:42,672 root         INFO     Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 0.207719\n",
      "Reconstruction: 0.060912, Regularization: 0.146807\n",
      "2019-04-09 21:40:42,715 root         INFO     Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 0.242946\n",
      "Reconstruction: 0.082795, Regularization: 0.160151\n",
      "2019-04-09 21:40:42,765 root         INFO     ====> Epoch: 136 Average loss: 0.2269\n",
      "2019-04-09 21:40:42,788 root         INFO     Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 0.179198\n",
      "Reconstruction: 0.067347, Regularization: 0.111851\n",
      "2019-04-09 21:40:42,833 root         INFO     Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 0.202173\n",
      "Reconstruction: 0.055450, Regularization: 0.146722\n",
      "2019-04-09 21:40:42,877 root         INFO     Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 0.241375\n",
      "Reconstruction: 0.071153, Regularization: 0.170222\n",
      "2019-04-09 21:40:42,921 root         INFO     Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 0.219194\n",
      "Reconstruction: 0.072575, Regularization: 0.146619\n",
      "2019-04-09 21:40:42,965 root         INFO     Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 0.260886\n",
      "Reconstruction: 0.058296, Regularization: 0.202589\n",
      "2019-04-09 21:40:43,009 root         INFO     Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 0.257162\n",
      "Reconstruction: 0.078620, Regularization: 0.178542\n",
      "2019-04-09 21:40:43,053 root         INFO     Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 0.244585\n",
      "Reconstruction: 0.060207, Regularization: 0.184377\n",
      "2019-04-09 21:40:43,096 root         INFO     Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 0.206114\n",
      "Reconstruction: 0.071218, Regularization: 0.134896\n",
      "2019-04-09 21:40:43,147 root         INFO     ====> Epoch: 137 Average loss: 0.2228\n",
      "2019-04-09 21:40:43,170 root         INFO     Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 0.250809\n",
      "Reconstruction: 0.064563, Regularization: 0.186246\n",
      "2019-04-09 21:40:43,215 root         INFO     Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 0.202210\n",
      "Reconstruction: 0.053087, Regularization: 0.149124\n",
      "2019-04-09 21:40:43,259 root         INFO     Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 0.198129\n",
      "Reconstruction: 0.068896, Regularization: 0.129234\n",
      "2019-04-09 21:40:43,304 root         INFO     Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 0.208668\n",
      "Reconstruction: 0.056111, Regularization: 0.152557\n",
      "2019-04-09 21:40:43,347 root         INFO     Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 0.203224\n",
      "Reconstruction: 0.051250, Regularization: 0.151974\n",
      "2019-04-09 21:40:43,390 root         INFO     Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 0.250750\n",
      "Reconstruction: 0.065098, Regularization: 0.185652\n",
      "2019-04-09 21:40:43,434 root         INFO     Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 0.210204\n",
      "Reconstruction: 0.076125, Regularization: 0.134080\n",
      "2019-04-09 21:40:43,477 root         INFO     Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 0.184579\n",
      "Reconstruction: 0.056078, Regularization: 0.128501\n",
      "2019-04-09 21:40:43,528 root         INFO     ====> Epoch: 138 Average loss: 0.2191\n",
      "2019-04-09 21:40:43,550 root         INFO     Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 0.215045\n",
      "Reconstruction: 0.060582, Regularization: 0.154463\n",
      "2019-04-09 21:40:43,596 root         INFO     Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 0.203049\n",
      "Reconstruction: 0.068800, Regularization: 0.134249\n",
      "2019-04-09 21:40:43,640 root         INFO     Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 0.185613\n",
      "Reconstruction: 0.056872, Regularization: 0.128741\n",
      "2019-04-09 21:40:43,685 root         INFO     Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 0.213453\n",
      "Reconstruction: 0.061492, Regularization: 0.151961\n",
      "2019-04-09 21:40:43,729 root         INFO     Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 0.235536\n",
      "Reconstruction: 0.061837, Regularization: 0.173700\n",
      "2019-04-09 21:40:43,774 root         INFO     Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 0.180058\n",
      "Reconstruction: 0.054155, Regularization: 0.125904\n",
      "2019-04-09 21:40:43,818 root         INFO     Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 0.245105\n",
      "Reconstruction: 0.062027, Regularization: 0.183078\n",
      "2019-04-09 21:40:43,862 root         INFO     Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 0.194978\n",
      "Reconstruction: 0.059719, Regularization: 0.135259\n",
      "2019-04-09 21:40:43,914 root         INFO     ====> Epoch: 139 Average loss: 0.2150\n",
      "2019-04-09 21:40:43,936 root         INFO     Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 0.232955\n",
      "Reconstruction: 0.063929, Regularization: 0.169026\n",
      "2019-04-09 21:40:43,980 root         INFO     Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 0.200377\n",
      "Reconstruction: 0.054724, Regularization: 0.145653\n",
      "2019-04-09 21:40:44,024 root         INFO     Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 0.201557\n",
      "Reconstruction: 0.069757, Regularization: 0.131800\n",
      "2019-04-09 21:40:44,068 root         INFO     Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 0.220600\n",
      "Reconstruction: 0.067882, Regularization: 0.152718\n",
      "2019-04-09 21:40:44,112 root         INFO     Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 0.215326\n",
      "Reconstruction: 0.053208, Regularization: 0.162118\n",
      "2019-04-09 21:40:44,155 root         INFO     Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 0.248107\n",
      "Reconstruction: 0.058446, Regularization: 0.189661\n",
      "2019-04-09 21:40:44,199 root         INFO     Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 0.208258\n",
      "Reconstruction: 0.070009, Regularization: 0.138250\n",
      "2019-04-09 21:40:44,242 root         INFO     Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 0.210597\n",
      "Reconstruction: 0.052926, Regularization: 0.157670\n",
      "2019-04-09 21:40:44,293 root         INFO     ====> Epoch: 140 Average loss: 0.2112\n",
      "2019-04-09 21:40:44,316 root         INFO     Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 0.216082\n",
      "Reconstruction: 0.062365, Regularization: 0.153717\n",
      "2019-04-09 21:40:44,360 root         INFO     Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 0.188487\n",
      "Reconstruction: 0.064079, Regularization: 0.124408\n",
      "2019-04-09 21:40:44,404 root         INFO     Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 0.216150\n",
      "Reconstruction: 0.055640, Regularization: 0.160510\n",
      "2019-04-09 21:40:44,448 root         INFO     Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 0.252063\n",
      "Reconstruction: 0.068138, Regularization: 0.183925\n",
      "2019-04-09 21:40:44,491 root         INFO     Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 0.233540\n",
      "Reconstruction: 0.061966, Regularization: 0.171574\n",
      "2019-04-09 21:40:44,535 root         INFO     Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 0.207690\n",
      "Reconstruction: 0.061694, Regularization: 0.145996\n",
      "2019-04-09 21:40:44,578 root         INFO     Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 0.233520\n",
      "Reconstruction: 0.063741, Regularization: 0.169780\n",
      "2019-04-09 21:40:44,621 root         INFO     Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 0.231449\n",
      "Reconstruction: 0.053909, Regularization: 0.177540\n",
      "2019-04-09 21:40:44,672 root         INFO     ====> Epoch: 141 Average loss: 0.2069\n",
      "2019-04-09 21:40:44,695 root         INFO     Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 0.196173\n",
      "Reconstruction: 0.066087, Regularization: 0.130087\n",
      "2019-04-09 21:40:44,739 root         INFO     Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 0.169440\n",
      "Reconstruction: 0.049082, Regularization: 0.120358\n",
      "2019-04-09 21:40:44,785 root         INFO     Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 0.190990\n",
      "Reconstruction: 0.053977, Regularization: 0.137013\n",
      "2019-04-09 21:40:44,829 root         INFO     Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 0.177792\n",
      "Reconstruction: 0.057874, Regularization: 0.119918\n",
      "2019-04-09 21:40:44,873 root         INFO     Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 0.213216\n",
      "Reconstruction: 0.068160, Regularization: 0.145056\n",
      "2019-04-09 21:40:44,917 root         INFO     Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 0.187856\n",
      "Reconstruction: 0.055313, Regularization: 0.132543\n",
      "2019-04-09 21:40:44,962 root         INFO     Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 0.225175\n",
      "Reconstruction: 0.065161, Regularization: 0.160014\n",
      "2019-04-09 21:40:45,007 root         INFO     Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 0.183762\n",
      "Reconstruction: 0.056259, Regularization: 0.127503\n",
      "2019-04-09 21:40:45,058 root         INFO     ====> Epoch: 142 Average loss: 0.2031\n",
      "2019-04-09 21:40:45,080 root         INFO     Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 0.192390\n",
      "Reconstruction: 0.062379, Regularization: 0.130012\n",
      "2019-04-09 21:40:45,124 root         INFO     Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 0.210100\n",
      "Reconstruction: 0.072331, Regularization: 0.137768\n",
      "2019-04-09 21:40:45,167 root         INFO     Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 0.193332\n",
      "Reconstruction: 0.063020, Regularization: 0.130312\n",
      "2019-04-09 21:40:45,210 root         INFO     Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 0.192347\n",
      "Reconstruction: 0.050854, Regularization: 0.141493\n",
      "2019-04-09 21:40:45,253 root         INFO     Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 0.186993\n",
      "Reconstruction: 0.053116, Regularization: 0.133877\n",
      "2019-04-09 21:40:45,296 root         INFO     Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 0.178532\n",
      "Reconstruction: 0.056539, Regularization: 0.121992\n",
      "2019-04-09 21:40:45,339 root         INFO     Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 0.205660\n",
      "Reconstruction: 0.078347, Regularization: 0.127312\n",
      "2019-04-09 21:40:45,382 root         INFO     Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 0.203759\n",
      "Reconstruction: 0.075093, Regularization: 0.128665\n",
      "2019-04-09 21:40:45,432 root         INFO     ====> Epoch: 143 Average loss: 0.1994\n",
      "2019-04-09 21:40:45,454 root         INFO     Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 0.170025\n",
      "Reconstruction: 0.057165, Regularization: 0.112860\n",
      "2019-04-09 21:40:45,499 root         INFO     Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 0.203329\n",
      "Reconstruction: 0.060254, Regularization: 0.143075\n",
      "2019-04-09 21:40:45,544 root         INFO     Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 0.198529\n",
      "Reconstruction: 0.059733, Regularization: 0.138796\n",
      "2019-04-09 21:40:45,588 root         INFO     Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 0.200864\n",
      "Reconstruction: 0.053220, Regularization: 0.147644\n",
      "2019-04-09 21:40:45,633 root         INFO     Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 0.209906\n",
      "Reconstruction: 0.057507, Regularization: 0.152399\n",
      "2019-04-09 21:40:45,677 root         INFO     Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 0.175464\n",
      "Reconstruction: 0.067661, Regularization: 0.107803\n",
      "2019-04-09 21:40:45,722 root         INFO     Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 0.211704\n",
      "Reconstruction: 0.057468, Regularization: 0.154236\n",
      "2019-04-09 21:40:45,766 root         INFO     Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 0.200791\n",
      "Reconstruction: 0.055864, Regularization: 0.144927\n",
      "2019-04-09 21:40:45,818 root         INFO     ====> Epoch: 144 Average loss: 0.1955\n",
      "2019-04-09 21:40:45,841 root         INFO     Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 0.167597\n",
      "Reconstruction: 0.048141, Regularization: 0.119456\n",
      "2019-04-09 21:40:45,886 root         INFO     Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 0.160063\n",
      "Reconstruction: 0.055996, Regularization: 0.104066\n",
      "2019-04-09 21:40:45,930 root         INFO     Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 0.204647\n",
      "Reconstruction: 0.063310, Regularization: 0.141337\n",
      "2019-04-09 21:40:45,975 root         INFO     Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 0.214005\n",
      "Reconstruction: 0.070104, Regularization: 0.143902\n",
      "2019-04-09 21:40:46,021 root         INFO     Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 0.173713\n",
      "Reconstruction: 0.058650, Regularization: 0.115063\n",
      "2019-04-09 21:40:46,068 root         INFO     Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 0.197811\n",
      "Reconstruction: 0.061111, Regularization: 0.136700\n",
      "2019-04-09 21:40:46,114 root         INFO     Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 0.204667\n",
      "Reconstruction: 0.065890, Regularization: 0.138778\n",
      "2019-04-09 21:40:46,160 root         INFO     Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 0.171123\n",
      "Reconstruction: 0.066490, Regularization: 0.104634\n",
      "2019-04-09 21:40:46,213 root         INFO     ====> Epoch: 145 Average loss: 0.1919\n",
      "2019-04-09 21:40:46,235 root         INFO     Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 0.182450\n",
      "Reconstruction: 0.051134, Regularization: 0.131316\n",
      "2019-04-09 21:40:46,280 root         INFO     Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 0.180261\n",
      "Reconstruction: 0.059186, Regularization: 0.121075\n",
      "2019-04-09 21:40:46,324 root         INFO     Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 0.189761\n",
      "Reconstruction: 0.065335, Regularization: 0.124425\n",
      "2019-04-09 21:40:46,369 root         INFO     Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 0.183361\n",
      "Reconstruction: 0.054477, Regularization: 0.128885\n",
      "2019-04-09 21:40:46,413 root         INFO     Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 0.171734\n",
      "Reconstruction: 0.053205, Regularization: 0.118529\n",
      "2019-04-09 21:40:46,457 root         INFO     Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 0.215361\n",
      "Reconstruction: 0.056991, Regularization: 0.158370\n",
      "2019-04-09 21:40:46,502 root         INFO     Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 0.157242\n",
      "Reconstruction: 0.052916, Regularization: 0.104326\n",
      "2019-04-09 21:40:46,546 root         INFO     Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 0.170558\n",
      "Reconstruction: 0.052919, Regularization: 0.117639\n",
      "2019-04-09 21:40:46,597 root         INFO     ====> Epoch: 146 Average loss: 0.1877\n",
      "2019-04-09 21:40:46,620 root         INFO     Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 0.192324\n",
      "Reconstruction: 0.053096, Regularization: 0.139227\n",
      "2019-04-09 21:40:46,666 root         INFO     Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 0.156194\n",
      "Reconstruction: 0.054134, Regularization: 0.102060\n",
      "2019-04-09 21:40:46,713 root         INFO     Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 0.202059\n",
      "Reconstruction: 0.061521, Regularization: 0.140538\n",
      "2019-04-09 21:40:46,760 root         INFO     Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 0.156669\n",
      "Reconstruction: 0.050468, Regularization: 0.106201\n",
      "2019-04-09 21:40:46,807 root         INFO     Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 0.191021\n",
      "Reconstruction: 0.057460, Regularization: 0.133561\n",
      "2019-04-09 21:40:46,854 root         INFO     Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 0.187439\n",
      "Reconstruction: 0.058461, Regularization: 0.128978\n",
      "2019-04-09 21:40:46,901 root         INFO     Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 0.177971\n",
      "Reconstruction: 0.052332, Regularization: 0.125639\n",
      "2019-04-09 21:40:46,947 root         INFO     Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 0.215062\n",
      "Reconstruction: 0.058393, Regularization: 0.156669\n",
      "2019-04-09 21:40:46,999 root         INFO     ====> Epoch: 147 Average loss: 0.1841\n",
      "2019-04-09 21:40:47,021 root         INFO     Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 0.198817\n",
      "Reconstruction: 0.072848, Regularization: 0.125969\n",
      "2019-04-09 21:40:47,067 root         INFO     Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 0.205927\n",
      "Reconstruction: 0.079522, Regularization: 0.126405\n",
      "2019-04-09 21:40:47,112 root         INFO     Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 0.167986\n",
      "Reconstruction: 0.056762, Regularization: 0.111224\n",
      "2019-04-09 21:40:47,158 root         INFO     Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 0.194938\n",
      "Reconstruction: 0.063791, Regularization: 0.131147\n",
      "2019-04-09 21:40:47,203 root         INFO     Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 0.165028\n",
      "Reconstruction: 0.056038, Regularization: 0.108990\n",
      "2019-04-09 21:40:47,249 root         INFO     Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 0.168603\n",
      "Reconstruction: 0.061452, Regularization: 0.107151\n",
      "2019-04-09 21:40:47,293 root         INFO     Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 0.205784\n",
      "Reconstruction: 0.058958, Regularization: 0.146827\n",
      "2019-04-09 21:40:47,338 root         INFO     Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 0.177380\n",
      "Reconstruction: 0.064854, Regularization: 0.112525\n",
      "2019-04-09 21:40:47,389 root         INFO     ====> Epoch: 148 Average loss: 0.1804\n",
      "2019-04-09 21:40:47,412 root         INFO     Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 0.159672\n",
      "Reconstruction: 0.059505, Regularization: 0.100168\n",
      "2019-04-09 21:40:47,458 root         INFO     Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 0.163620\n",
      "Reconstruction: 0.058146, Regularization: 0.105474\n",
      "2019-04-09 21:40:47,503 root         INFO     Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 0.175178\n",
      "Reconstruction: 0.061339, Regularization: 0.113840\n",
      "2019-04-09 21:40:47,549 root         INFO     Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 0.191474\n",
      "Reconstruction: 0.060773, Regularization: 0.130700\n",
      "2019-04-09 21:40:47,595 root         INFO     Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 0.181184\n",
      "Reconstruction: 0.059978, Regularization: 0.121207\n",
      "2019-04-09 21:40:47,638 root         INFO     Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 0.190045\n",
      "Reconstruction: 0.071804, Regularization: 0.118241\n",
      "2019-04-09 21:40:47,680 root         INFO     Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 0.200781\n",
      "Reconstruction: 0.058710, Regularization: 0.142071\n",
      "2019-04-09 21:40:47,724 root         INFO     Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 0.165636\n",
      "Reconstruction: 0.068256, Regularization: 0.097380\n",
      "2019-04-09 21:40:47,775 root         INFO     ====> Epoch: 149 Average loss: 0.1766\n",
      "2019-04-09 21:40:47,798 root         INFO     Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 0.163129\n",
      "Reconstruction: 0.059321, Regularization: 0.103808\n",
      "2019-04-09 21:40:47,843 root         INFO     Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 0.156717\n",
      "Reconstruction: 0.053477, Regularization: 0.103240\n",
      "2019-04-09 21:40:47,888 root         INFO     Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 0.184641\n",
      "Reconstruction: 0.053264, Regularization: 0.131377\n",
      "2019-04-09 21:40:47,933 root         INFO     Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 0.180570\n",
      "Reconstruction: 0.070687, Regularization: 0.109884\n",
      "2019-04-09 21:40:47,978 root         INFO     Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 0.171509\n",
      "Reconstruction: 0.057007, Regularization: 0.114502\n",
      "2019-04-09 21:40:48,023 root         INFO     Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 0.172308\n",
      "Reconstruction: 0.054811, Regularization: 0.117497\n",
      "2019-04-09 21:40:48,068 root         INFO     Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 0.176213\n",
      "Reconstruction: 0.056858, Regularization: 0.119355\n",
      "2019-04-09 21:40:48,113 root         INFO     Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 0.165615\n",
      "Reconstruction: 0.053366, Regularization: 0.112249\n",
      "2019-04-09 21:40:48,165 root         INFO     ====> Epoch: 150 Average loss: 0.1731\n",
      "2019-04-09 21:40:48,187 root         INFO     Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 0.172503\n",
      "Reconstruction: 0.062869, Regularization: 0.109634\n",
      "2019-04-09 21:40:48,232 root         INFO     Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 0.189799\n",
      "Reconstruction: 0.057312, Regularization: 0.132487\n",
      "2019-04-09 21:40:48,277 root         INFO     Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 0.161490\n",
      "Reconstruction: 0.054579, Regularization: 0.106911\n",
      "2019-04-09 21:40:48,321 root         INFO     Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 0.204621\n",
      "Reconstruction: 0.061584, Regularization: 0.143037\n",
      "2019-04-09 21:40:48,366 root         INFO     Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 0.197902\n",
      "Reconstruction: 0.070235, Regularization: 0.127667\n",
      "2019-04-09 21:40:48,411 root         INFO     Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 0.179870\n",
      "Reconstruction: 0.055789, Regularization: 0.124081\n",
      "2019-04-09 21:40:48,455 root         INFO     Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 0.153789\n",
      "Reconstruction: 0.056209, Regularization: 0.097581\n",
      "2019-04-09 21:40:48,500 root         INFO     Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 0.188385\n",
      "Reconstruction: 0.059969, Regularization: 0.128416\n",
      "2019-04-09 21:40:48,551 root         INFO     ====> Epoch: 151 Average loss: 0.1697\n",
      "2019-04-09 21:40:48,574 root         INFO     Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 0.183258\n",
      "Reconstruction: 0.056592, Regularization: 0.126665\n",
      "2019-04-09 21:40:48,619 root         INFO     Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 0.143250\n",
      "Reconstruction: 0.057350, Regularization: 0.085900\n",
      "2019-04-09 21:40:48,665 root         INFO     Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 0.183064\n",
      "Reconstruction: 0.061970, Regularization: 0.121094\n",
      "2019-04-09 21:40:48,710 root         INFO     Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 0.157187\n",
      "Reconstruction: 0.055507, Regularization: 0.101680\n",
      "2019-04-09 21:40:48,755 root         INFO     Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 0.170106\n",
      "Reconstruction: 0.059233, Regularization: 0.110873\n",
      "2019-04-09 21:40:48,800 root         INFO     Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 0.203083\n",
      "Reconstruction: 0.056641, Regularization: 0.146442\n",
      "2019-04-09 21:40:48,845 root         INFO     Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 0.155561\n",
      "Reconstruction: 0.056936, Regularization: 0.098625\n",
      "2019-04-09 21:40:48,889 root         INFO     Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 0.159204\n",
      "Reconstruction: 0.058137, Regularization: 0.101067\n",
      "2019-04-09 21:40:48,940 root         INFO     ====> Epoch: 152 Average loss: 0.1662\n",
      "2019-04-09 21:40:48,963 root         INFO     Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 0.156316\n",
      "Reconstruction: 0.059050, Regularization: 0.097266\n",
      "2019-04-09 21:40:49,007 root         INFO     Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 0.148745\n",
      "Reconstruction: 0.056249, Regularization: 0.092497\n",
      "2019-04-09 21:40:49,051 root         INFO     Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 0.157189\n",
      "Reconstruction: 0.064033, Regularization: 0.093156\n",
      "2019-04-09 21:40:49,094 root         INFO     Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 0.154065\n",
      "Reconstruction: 0.058198, Regularization: 0.095867\n",
      "2019-04-09 21:40:49,138 root         INFO     Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 0.183316\n",
      "Reconstruction: 0.064054, Regularization: 0.119262\n",
      "2019-04-09 21:40:49,181 root         INFO     Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 0.188758\n",
      "Reconstruction: 0.061432, Regularization: 0.127326\n",
      "2019-04-09 21:40:49,225 root         INFO     Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 0.166244\n",
      "Reconstruction: 0.065625, Regularization: 0.100619\n",
      "2019-04-09 21:40:49,268 root         INFO     Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 0.145180\n",
      "Reconstruction: 0.055697, Regularization: 0.089484\n",
      "2019-04-09 21:40:49,319 root         INFO     ====> Epoch: 153 Average loss: 0.1627\n",
      "2019-04-09 21:40:49,341 root         INFO     Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 0.156691\n",
      "Reconstruction: 0.057469, Regularization: 0.099222\n",
      "2019-04-09 21:40:49,386 root         INFO     Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 0.156382\n",
      "Reconstruction: 0.058814, Regularization: 0.097568\n",
      "2019-04-09 21:40:49,431 root         INFO     Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 0.177424\n",
      "Reconstruction: 0.057373, Regularization: 0.120052\n",
      "2019-04-09 21:40:49,475 root         INFO     Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 0.170686\n",
      "Reconstruction: 0.059895, Regularization: 0.110790\n",
      "2019-04-09 21:40:49,520 root         INFO     Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 0.145019\n",
      "Reconstruction: 0.055580, Regularization: 0.089439\n",
      "2019-04-09 21:40:49,565 root         INFO     Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 0.166200\n",
      "Reconstruction: 0.058955, Regularization: 0.107246\n",
      "2019-04-09 21:40:49,609 root         INFO     Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 0.140324\n",
      "Reconstruction: 0.050182, Regularization: 0.090142\n",
      "2019-04-09 21:40:49,653 root         INFO     Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 0.146134\n",
      "Reconstruction: 0.054610, Regularization: 0.091524\n",
      "2019-04-09 21:40:49,703 root         INFO     ====> Epoch: 154 Average loss: 0.1589\n",
      "2019-04-09 21:40:49,725 root         INFO     Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 0.149299\n",
      "Reconstruction: 0.053759, Regularization: 0.095540\n",
      "2019-04-09 21:40:49,769 root         INFO     Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 0.142062\n",
      "Reconstruction: 0.050266, Regularization: 0.091796\n",
      "2019-04-09 21:40:49,813 root         INFO     Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 0.157950\n",
      "Reconstruction: 0.061031, Regularization: 0.096919\n",
      "2019-04-09 21:40:49,856 root         INFO     Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 0.173840\n",
      "Reconstruction: 0.072852, Regularization: 0.100988\n",
      "2019-04-09 21:40:49,900 root         INFO     Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 0.158251\n",
      "Reconstruction: 0.053124, Regularization: 0.105126\n",
      "2019-04-09 21:40:49,943 root         INFO     Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 0.155034\n",
      "Reconstruction: 0.053687, Regularization: 0.101347\n",
      "2019-04-09 21:40:49,986 root         INFO     Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 0.159861\n",
      "Reconstruction: 0.056596, Regularization: 0.103264\n",
      "2019-04-09 21:40:50,030 root         INFO     Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 0.130748\n",
      "Reconstruction: 0.056064, Regularization: 0.074684\n",
      "2019-04-09 21:40:50,080 root         INFO     ====> Epoch: 155 Average loss: 0.1558\n",
      "2019-04-09 21:40:50,103 root         INFO     Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 0.161737\n",
      "Reconstruction: 0.065717, Regularization: 0.096021\n",
      "2019-04-09 21:40:50,147 root         INFO     Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 0.156207\n",
      "Reconstruction: 0.053580, Regularization: 0.102626\n",
      "2019-04-09 21:40:50,192 root         INFO     Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 0.159252\n",
      "Reconstruction: 0.065595, Regularization: 0.093657\n",
      "2019-04-09 21:40:50,236 root         INFO     Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 0.151641\n",
      "Reconstruction: 0.060603, Regularization: 0.091037\n",
      "2019-04-09 21:40:50,280 root         INFO     Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 0.201616\n",
      "Reconstruction: 0.084124, Regularization: 0.117492\n",
      "2019-04-09 21:40:50,324 root         INFO     Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 0.147173\n",
      "Reconstruction: 0.061947, Regularization: 0.085225\n",
      "2019-04-09 21:40:50,368 root         INFO     Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 0.146999\n",
      "Reconstruction: 0.057901, Regularization: 0.089098\n",
      "2019-04-09 21:40:50,412 root         INFO     Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 0.148891\n",
      "Reconstruction: 0.051930, Regularization: 0.096961\n",
      "2019-04-09 21:40:50,463 root         INFO     ====> Epoch: 156 Average loss: 0.1526\n",
      "2019-04-09 21:40:50,486 root         INFO     Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 0.164326\n",
      "Reconstruction: 0.062769, Regularization: 0.101557\n",
      "2019-04-09 21:40:50,531 root         INFO     Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 0.154258\n",
      "Reconstruction: 0.054528, Regularization: 0.099730\n",
      "2019-04-09 21:40:50,575 root         INFO     Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 0.158052\n",
      "Reconstruction: 0.065035, Regularization: 0.093017\n",
      "2019-04-09 21:40:50,620 root         INFO     Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 0.126802\n",
      "Reconstruction: 0.054053, Regularization: 0.072749\n",
      "2019-04-09 21:40:50,664 root         INFO     Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 0.145047\n",
      "Reconstruction: 0.051991, Regularization: 0.093056\n",
      "2019-04-09 21:40:50,709 root         INFO     Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 0.146393\n",
      "Reconstruction: 0.062086, Regularization: 0.084307\n",
      "2019-04-09 21:40:50,753 root         INFO     Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 0.148760\n",
      "Reconstruction: 0.050484, Regularization: 0.098275\n",
      "2019-04-09 21:40:50,798 root         INFO     Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 0.153252\n",
      "Reconstruction: 0.059956, Regularization: 0.093296\n",
      "2019-04-09 21:40:50,850 root         INFO     ====> Epoch: 157 Average loss: 0.1498\n",
      "2019-04-09 21:40:50,872 root         INFO     Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 0.145528\n",
      "Reconstruction: 0.056881, Regularization: 0.088647\n",
      "2019-04-09 21:40:50,918 root         INFO     Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 0.136306\n",
      "Reconstruction: 0.052442, Regularization: 0.083864\n",
      "2019-04-09 21:40:50,962 root         INFO     Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 0.152393\n",
      "Reconstruction: 0.056024, Regularization: 0.096370\n",
      "2019-04-09 21:40:51,007 root         INFO     Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 0.130320\n",
      "Reconstruction: 0.050419, Regularization: 0.079902\n",
      "2019-04-09 21:40:51,052 root         INFO     Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 0.165582\n",
      "Reconstruction: 0.064287, Regularization: 0.101295\n",
      "2019-04-09 21:40:51,097 root         INFO     Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 0.150403\n",
      "Reconstruction: 0.058221, Regularization: 0.092182\n",
      "2019-04-09 21:40:51,143 root         INFO     Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 0.143354\n",
      "Reconstruction: 0.068344, Regularization: 0.075010\n",
      "2019-04-09 21:40:51,188 root         INFO     Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 0.144106\n",
      "Reconstruction: 0.054484, Regularization: 0.089622\n",
      "2019-04-09 21:40:51,240 root         INFO     ====> Epoch: 158 Average loss: 0.1464\n",
      "2019-04-09 21:40:51,262 root         INFO     Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 0.145727\n",
      "Reconstruction: 0.055814, Regularization: 0.089913\n",
      "2019-04-09 21:40:51,308 root         INFO     Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 0.133846\n",
      "Reconstruction: 0.053286, Regularization: 0.080560\n",
      "2019-04-09 21:40:51,352 root         INFO     Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 0.137602\n",
      "Reconstruction: 0.055817, Regularization: 0.081785\n",
      "2019-04-09 21:40:51,396 root         INFO     Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 0.125723\n",
      "Reconstruction: 0.049468, Regularization: 0.076255\n",
      "2019-04-09 21:40:51,441 root         INFO     Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 0.140336\n",
      "Reconstruction: 0.058597, Regularization: 0.081739\n",
      "2019-04-09 21:40:51,487 root         INFO     Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 0.124528\n",
      "Reconstruction: 0.055350, Regularization: 0.069178\n",
      "2019-04-09 21:40:51,531 root         INFO     Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 0.149427\n",
      "Reconstruction: 0.058835, Regularization: 0.090592\n",
      "2019-04-09 21:40:51,576 root         INFO     Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 0.132751\n",
      "Reconstruction: 0.051488, Regularization: 0.081263\n",
      "2019-04-09 21:40:51,628 root         INFO     ====> Epoch: 159 Average loss: 0.1434\n",
      "2019-04-09 21:40:51,650 root         INFO     Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 0.136959\n",
      "Reconstruction: 0.055086, Regularization: 0.081872\n",
      "2019-04-09 21:40:51,696 root         INFO     Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 0.150493\n",
      "Reconstruction: 0.057054, Regularization: 0.093439\n",
      "2019-04-09 21:40:51,742 root         INFO     Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 0.149370\n",
      "Reconstruction: 0.052012, Regularization: 0.097359\n",
      "2019-04-09 21:40:51,785 root         INFO     Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 0.136158\n",
      "Reconstruction: 0.054887, Regularization: 0.081271\n",
      "2019-04-09 21:40:51,829 root         INFO     Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 0.138164\n",
      "Reconstruction: 0.051591, Regularization: 0.086573\n",
      "2019-04-09 21:40:51,873 root         INFO     Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 0.135038\n",
      "Reconstruction: 0.055811, Regularization: 0.079226\n",
      "2019-04-09 21:40:51,916 root         INFO     Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 0.144417\n",
      "Reconstruction: 0.057392, Regularization: 0.087025\n",
      "2019-04-09 21:40:51,959 root         INFO     Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 0.115899\n",
      "Reconstruction: 0.049431, Regularization: 0.066468\n",
      "2019-04-09 21:40:52,010 root         INFO     ====> Epoch: 160 Average loss: 0.1403\n",
      "2019-04-09 21:40:52,033 root         INFO     Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 0.134393\n",
      "Reconstruction: 0.051530, Regularization: 0.082863\n",
      "2019-04-09 21:40:52,079 root         INFO     Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 0.140700\n",
      "Reconstruction: 0.056903, Regularization: 0.083797\n",
      "2019-04-09 21:40:52,123 root         INFO     Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 0.135407\n",
      "Reconstruction: 0.053831, Regularization: 0.081576\n",
      "2019-04-09 21:40:52,169 root         INFO     Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 0.127554\n",
      "Reconstruction: 0.055378, Regularization: 0.072176\n",
      "2019-04-09 21:40:52,215 root         INFO     Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 0.134410\n",
      "Reconstruction: 0.056359, Regularization: 0.078051\n",
      "2019-04-09 21:40:52,261 root         INFO     Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 0.145149\n",
      "Reconstruction: 0.059685, Regularization: 0.085464\n",
      "2019-04-09 21:40:52,307 root         INFO     Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 0.134922\n",
      "Reconstruction: 0.057879, Regularization: 0.077043\n",
      "2019-04-09 21:40:52,352 root         INFO     Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 0.132073\n",
      "Reconstruction: 0.059115, Regularization: 0.072958\n",
      "2019-04-09 21:40:52,404 root         INFO     ====> Epoch: 161 Average loss: 0.1376\n",
      "2019-04-09 21:40:52,426 root         INFO     Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 0.136346\n",
      "Reconstruction: 0.052671, Regularization: 0.083676\n",
      "2019-04-09 21:40:52,472 root         INFO     Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 0.140808\n",
      "Reconstruction: 0.062889, Regularization: 0.077919\n",
      "2019-04-09 21:40:52,518 root         INFO     Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 0.141727\n",
      "Reconstruction: 0.065182, Regularization: 0.076546\n",
      "2019-04-09 21:40:52,564 root         INFO     Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 0.130545\n",
      "Reconstruction: 0.052450, Regularization: 0.078095\n",
      "2019-04-09 21:40:52,608 root         INFO     Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 0.152554\n",
      "Reconstruction: 0.055976, Regularization: 0.096579\n",
      "2019-04-09 21:40:52,653 root         INFO     Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 0.136481\n",
      "Reconstruction: 0.058264, Regularization: 0.078217\n",
      "2019-04-09 21:40:52,697 root         INFO     Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 0.161565\n",
      "Reconstruction: 0.075192, Regularization: 0.086373\n",
      "2019-04-09 21:40:52,741 root         INFO     Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 0.138195\n",
      "Reconstruction: 0.058819, Regularization: 0.079376\n",
      "2019-04-09 21:40:52,793 root         INFO     ====> Epoch: 162 Average loss: 0.1350\n",
      "2019-04-09 21:40:52,816 root         INFO     Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 0.123105\n",
      "Reconstruction: 0.052497, Regularization: 0.070608\n",
      "2019-04-09 21:40:52,861 root         INFO     Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 0.131570\n",
      "Reconstruction: 0.053462, Regularization: 0.078108\n",
      "2019-04-09 21:40:52,906 root         INFO     Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 0.131999\n",
      "Reconstruction: 0.054027, Regularization: 0.077972\n",
      "2019-04-09 21:40:52,951 root         INFO     Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 0.133613\n",
      "Reconstruction: 0.052476, Regularization: 0.081137\n",
      "2019-04-09 21:40:52,996 root         INFO     Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 0.137977\n",
      "Reconstruction: 0.060164, Regularization: 0.077813\n",
      "2019-04-09 21:40:53,041 root         INFO     Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 0.135302\n",
      "Reconstruction: 0.059675, Regularization: 0.075627\n",
      "2019-04-09 21:40:53,086 root         INFO     Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 0.135933\n",
      "Reconstruction: 0.049875, Regularization: 0.086058\n",
      "2019-04-09 21:40:53,130 root         INFO     Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 0.119724\n",
      "Reconstruction: 0.051797, Regularization: 0.067927\n",
      "2019-04-09 21:40:53,182 root         INFO     ====> Epoch: 163 Average loss: 0.1320\n",
      "2019-04-09 21:40:53,204 root         INFO     Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 0.139769\n",
      "Reconstruction: 0.065202, Regularization: 0.074566\n",
      "2019-04-09 21:40:53,249 root         INFO     Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 0.127816\n",
      "Reconstruction: 0.055084, Regularization: 0.072733\n",
      "2019-04-09 21:40:53,294 root         INFO     Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 0.123320\n",
      "Reconstruction: 0.060518, Regularization: 0.062802\n",
      "2019-04-09 21:40:53,339 root         INFO     Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 0.150245\n",
      "Reconstruction: 0.061261, Regularization: 0.088984\n",
      "2019-04-09 21:40:53,384 root         INFO     Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 0.114148\n",
      "Reconstruction: 0.053464, Regularization: 0.060684\n",
      "2019-04-09 21:40:53,429 root         INFO     Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 0.119957\n",
      "Reconstruction: 0.052966, Regularization: 0.066991\n",
      "2019-04-09 21:40:53,474 root         INFO     Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 0.112245\n",
      "Reconstruction: 0.050329, Regularization: 0.061916\n",
      "2019-04-09 21:40:53,518 root         INFO     Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 0.126986\n",
      "Reconstruction: 0.053136, Regularization: 0.073851\n",
      "2019-04-09 21:40:53,570 root         INFO     ====> Epoch: 164 Average loss: 0.1294\n",
      "2019-04-09 21:40:53,593 root         INFO     Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 0.129673\n",
      "Reconstruction: 0.054087, Regularization: 0.075586\n",
      "2019-04-09 21:40:53,638 root         INFO     Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 0.112916\n",
      "Reconstruction: 0.052835, Regularization: 0.060081\n",
      "2019-04-09 21:40:53,683 root         INFO     Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 0.130868\n",
      "Reconstruction: 0.055976, Regularization: 0.074892\n",
      "2019-04-09 21:40:53,728 root         INFO     Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 0.137082\n",
      "Reconstruction: 0.059841, Regularization: 0.077241\n",
      "2019-04-09 21:40:53,774 root         INFO     Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 0.153195\n",
      "Reconstruction: 0.074390, Regularization: 0.078805\n",
      "2019-04-09 21:40:53,819 root         INFO     Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 0.130144\n",
      "Reconstruction: 0.052792, Regularization: 0.077352\n",
      "2019-04-09 21:40:53,864 root         INFO     Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 0.114364\n",
      "Reconstruction: 0.049052, Regularization: 0.065312\n",
      "2019-04-09 21:40:53,908 root         INFO     Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 0.125521\n",
      "Reconstruction: 0.054055, Regularization: 0.071466\n",
      "2019-04-09 21:40:53,961 root         INFO     ====> Epoch: 165 Average loss: 0.1272\n",
      "2019-04-09 21:40:53,983 root         INFO     Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 0.122322\n",
      "Reconstruction: 0.050639, Regularization: 0.071683\n",
      "2019-04-09 21:40:54,028 root         INFO     Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 0.120578\n",
      "Reconstruction: 0.048315, Regularization: 0.072263\n",
      "2019-04-09 21:40:54,074 root         INFO     Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 0.147737\n",
      "Reconstruction: 0.066600, Regularization: 0.081137\n",
      "2019-04-09 21:40:54,120 root         INFO     Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 0.126591\n",
      "Reconstruction: 0.055465, Regularization: 0.071125\n",
      "2019-04-09 21:40:54,166 root         INFO     Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 0.126525\n",
      "Reconstruction: 0.054735, Regularization: 0.071790\n",
      "2019-04-09 21:40:54,212 root         INFO     Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 0.122321\n",
      "Reconstruction: 0.056143, Regularization: 0.066178\n",
      "2019-04-09 21:40:54,258 root         INFO     Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 0.124073\n",
      "Reconstruction: 0.053941, Regularization: 0.070132\n",
      "2019-04-09 21:40:54,304 root         INFO     Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 0.139238\n",
      "Reconstruction: 0.060908, Regularization: 0.078330\n",
      "2019-04-09 21:40:54,357 root         INFO     ====> Epoch: 166 Average loss: 0.1245\n",
      "2019-04-09 21:40:54,379 root         INFO     Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 0.124184\n",
      "Reconstruction: 0.048507, Regularization: 0.075678\n",
      "2019-04-09 21:40:54,425 root         INFO     Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 0.116592\n",
      "Reconstruction: 0.054666, Regularization: 0.061926\n",
      "2019-04-09 21:40:54,471 root         INFO     Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 0.124374\n",
      "Reconstruction: 0.054027, Regularization: 0.070346\n",
      "2019-04-09 21:40:54,517 root         INFO     Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 0.117325\n",
      "Reconstruction: 0.051783, Regularization: 0.065542\n",
      "2019-04-09 21:40:54,562 root         INFO     Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 0.118895\n",
      "Reconstruction: 0.055284, Regularization: 0.063610\n",
      "2019-04-09 21:40:54,606 root         INFO     Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 0.122442\n",
      "Reconstruction: 0.053074, Regularization: 0.069368\n",
      "2019-04-09 21:40:54,651 root         INFO     Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 0.130738\n",
      "Reconstruction: 0.059844, Regularization: 0.070894\n",
      "2019-04-09 21:40:54,696 root         INFO     Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 0.117753\n",
      "Reconstruction: 0.052976, Regularization: 0.064776\n",
      "2019-04-09 21:40:54,749 root         INFO     ====> Epoch: 167 Average loss: 0.1221\n",
      "2019-04-09 21:40:54,771 root         INFO     Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 0.119164\n",
      "Reconstruction: 0.054786, Regularization: 0.064378\n",
      "2019-04-09 21:40:54,817 root         INFO     Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 0.116521\n",
      "Reconstruction: 0.051459, Regularization: 0.065061\n",
      "2019-04-09 21:40:54,863 root         INFO     Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 0.104070\n",
      "Reconstruction: 0.049279, Regularization: 0.054791\n",
      "2019-04-09 21:40:54,909 root         INFO     Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 0.120934\n",
      "Reconstruction: 0.052476, Regularization: 0.068458\n",
      "2019-04-09 21:40:54,956 root         INFO     Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 0.118151\n",
      "Reconstruction: 0.056104, Regularization: 0.062047\n",
      "2019-04-09 21:40:55,003 root         INFO     Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 0.115210\n",
      "Reconstruction: 0.058445, Regularization: 0.056765\n",
      "2019-04-09 21:40:55,048 root         INFO     Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 0.122844\n",
      "Reconstruction: 0.049839, Regularization: 0.073005\n",
      "2019-04-09 21:40:55,093 root         INFO     Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 0.127561\n",
      "Reconstruction: 0.056638, Regularization: 0.070923\n",
      "2019-04-09 21:40:55,146 root         INFO     ====> Epoch: 168 Average loss: 0.1198\n",
      "2019-04-09 21:40:55,169 root         INFO     Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 0.120881\n",
      "Reconstruction: 0.053567, Regularization: 0.067314\n",
      "2019-04-09 21:40:55,214 root         INFO     Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 0.112483\n",
      "Reconstruction: 0.052594, Regularization: 0.059889\n",
      "2019-04-09 21:40:55,259 root         INFO     Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 0.126793\n",
      "Reconstruction: 0.053502, Regularization: 0.073292\n",
      "2019-04-09 21:40:55,304 root         INFO     Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 0.118226\n",
      "Reconstruction: 0.053563, Regularization: 0.064663\n",
      "2019-04-09 21:40:55,349 root         INFO     Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 0.117308\n",
      "Reconstruction: 0.049217, Regularization: 0.068091\n",
      "2019-04-09 21:40:55,395 root         INFO     Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 0.123171\n",
      "Reconstruction: 0.053161, Regularization: 0.070010\n",
      "2019-04-09 21:40:55,440 root         INFO     Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 0.116575\n",
      "Reconstruction: 0.057783, Regularization: 0.058792\n",
      "2019-04-09 21:40:55,485 root         INFO     Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 0.132664\n",
      "Reconstruction: 0.061991, Regularization: 0.070673\n",
      "2019-04-09 21:40:55,536 root         INFO     ====> Epoch: 169 Average loss: 0.1177\n",
      "2019-04-09 21:40:55,559 root         INFO     Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 0.132064\n",
      "Reconstruction: 0.064812, Regularization: 0.067251\n",
      "2019-04-09 21:40:55,605 root         INFO     Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 0.113841\n",
      "Reconstruction: 0.052615, Regularization: 0.061227\n",
      "2019-04-09 21:40:55,650 root         INFO     Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 0.112526\n",
      "Reconstruction: 0.054256, Regularization: 0.058270\n",
      "2019-04-09 21:40:55,695 root         INFO     Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 0.097045\n",
      "Reconstruction: 0.047581, Regularization: 0.049464\n",
      "2019-04-09 21:40:55,740 root         INFO     Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 0.110003\n",
      "Reconstruction: 0.050351, Regularization: 0.059652\n",
      "2019-04-09 21:40:55,787 root         INFO     Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 0.121839\n",
      "Reconstruction: 0.054675, Regularization: 0.067164\n",
      "2019-04-09 21:40:55,833 root         INFO     Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 0.105796\n",
      "Reconstruction: 0.051851, Regularization: 0.053945\n",
      "2019-04-09 21:40:55,880 root         INFO     Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 0.114572\n",
      "Reconstruction: 0.051121, Regularization: 0.063450\n",
      "2019-04-09 21:40:55,932 root         INFO     ====> Epoch: 170 Average loss: 0.1157\n",
      "2019-04-09 21:40:55,955 root         INFO     Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 0.104405\n",
      "Reconstruction: 0.054888, Regularization: 0.049517\n",
      "2019-04-09 21:40:56,000 root         INFO     Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 0.118484\n",
      "Reconstruction: 0.054860, Regularization: 0.063623\n",
      "2019-04-09 21:40:56,046 root         INFO     Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 0.125070\n",
      "Reconstruction: 0.058248, Regularization: 0.066822\n",
      "2019-04-09 21:40:56,091 root         INFO     Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 0.112184\n",
      "Reconstruction: 0.052975, Regularization: 0.059208\n",
      "2019-04-09 21:40:56,136 root         INFO     Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 0.136020\n",
      "Reconstruction: 0.063390, Regularization: 0.072630\n",
      "2019-04-09 21:40:56,182 root         INFO     Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 0.109146\n",
      "Reconstruction: 0.057126, Regularization: 0.052020\n",
      "2019-04-09 21:40:56,227 root         INFO     Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 0.104205\n",
      "Reconstruction: 0.054727, Regularization: 0.049478\n",
      "2019-04-09 21:40:56,272 root         INFO     Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 0.105098\n",
      "Reconstruction: 0.051484, Regularization: 0.053613\n",
      "2019-04-09 21:40:56,324 root         INFO     ====> Epoch: 171 Average loss: 0.1136\n",
      "2019-04-09 21:40:56,347 root         INFO     Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 0.133854\n",
      "Reconstruction: 0.058211, Regularization: 0.075643\n",
      "2019-04-09 21:40:56,392 root         INFO     Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 0.121351\n",
      "Reconstruction: 0.057957, Regularization: 0.063393\n",
      "2019-04-09 21:40:56,438 root         INFO     Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 0.108817\n",
      "Reconstruction: 0.052688, Regularization: 0.056129\n",
      "2019-04-09 21:40:56,484 root         INFO     Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 0.115520\n",
      "Reconstruction: 0.053174, Regularization: 0.062346\n",
      "2019-04-09 21:40:56,529 root         INFO     Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 0.110227\n",
      "Reconstruction: 0.050419, Regularization: 0.059809\n",
      "2019-04-09 21:40:56,575 root         INFO     Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 0.103692\n",
      "Reconstruction: 0.051720, Regularization: 0.051972\n",
      "2019-04-09 21:40:56,620 root         INFO     Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 0.110680\n",
      "Reconstruction: 0.059288, Regularization: 0.051391\n",
      "2019-04-09 21:40:56,666 root         INFO     Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 0.103410\n",
      "Reconstruction: 0.050926, Regularization: 0.052484\n",
      "2019-04-09 21:40:56,718 root         INFO     ====> Epoch: 172 Average loss: 0.1115\n",
      "2019-04-09 21:40:56,741 root         INFO     Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 0.107814\n",
      "Reconstruction: 0.052517, Regularization: 0.055298\n",
      "2019-04-09 21:40:56,786 root         INFO     Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 0.119783\n",
      "Reconstruction: 0.059821, Regularization: 0.059962\n",
      "2019-04-09 21:40:56,830 root         INFO     Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 0.111655\n",
      "Reconstruction: 0.056348, Regularization: 0.055307\n",
      "2019-04-09 21:40:56,874 root         INFO     Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 0.105963\n",
      "Reconstruction: 0.054006, Regularization: 0.051958\n",
      "2019-04-09 21:40:56,918 root         INFO     Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 0.109824\n",
      "Reconstruction: 0.053398, Regularization: 0.056426\n",
      "2019-04-09 21:40:56,962 root         INFO     Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 0.128877\n",
      "Reconstruction: 0.060337, Regularization: 0.068540\n",
      "2019-04-09 21:40:57,005 root         INFO     Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 0.109303\n",
      "Reconstruction: 0.055119, Regularization: 0.054184\n",
      "2019-04-09 21:40:57,050 root         INFO     Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 0.114398\n",
      "Reconstruction: 0.058112, Regularization: 0.056286\n",
      "2019-04-09 21:40:57,101 root         INFO     ====> Epoch: 173 Average loss: 0.1098\n",
      "2019-04-09 21:40:57,124 root         INFO     Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 0.117274\n",
      "Reconstruction: 0.060373, Regularization: 0.056901\n",
      "2019-04-09 21:40:57,169 root         INFO     Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 0.115619\n",
      "Reconstruction: 0.064036, Regularization: 0.051583\n",
      "2019-04-09 21:40:57,211 root         INFO     Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 0.111781\n",
      "Reconstruction: 0.055058, Regularization: 0.056724\n",
      "2019-04-09 21:40:57,254 root         INFO     Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 0.104724\n",
      "Reconstruction: 0.052394, Regularization: 0.052331\n",
      "2019-04-09 21:40:57,297 root         INFO     Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 0.104079\n",
      "Reconstruction: 0.053923, Regularization: 0.050157\n",
      "2019-04-09 21:40:57,340 root         INFO     Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 0.104095\n",
      "Reconstruction: 0.054302, Regularization: 0.049794\n",
      "2019-04-09 21:40:57,384 root         INFO     Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 0.119102\n",
      "Reconstruction: 0.058132, Regularization: 0.060970\n",
      "2019-04-09 21:40:57,427 root         INFO     Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 0.109215\n",
      "Reconstruction: 0.058053, Regularization: 0.051162\n",
      "2019-04-09 21:40:57,478 root         INFO     ====> Epoch: 174 Average loss: 0.1080\n",
      "2019-04-09 21:40:57,501 root         INFO     Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 0.107485\n",
      "Reconstruction: 0.052804, Regularization: 0.054682\n",
      "2019-04-09 21:40:57,546 root         INFO     Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 0.104169\n",
      "Reconstruction: 0.055820, Regularization: 0.048348\n",
      "2019-04-09 21:40:57,591 root         INFO     Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 0.103166\n",
      "Reconstruction: 0.055770, Regularization: 0.047397\n",
      "2019-04-09 21:40:57,636 root         INFO     Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 0.103982\n",
      "Reconstruction: 0.052207, Regularization: 0.051775\n",
      "2019-04-09 21:40:57,680 root         INFO     Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 0.114067\n",
      "Reconstruction: 0.054281, Regularization: 0.059786\n",
      "2019-04-09 21:40:57,725 root         INFO     Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 0.108695\n",
      "Reconstruction: 0.051737, Regularization: 0.056958\n",
      "2019-04-09 21:40:57,769 root         INFO     Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 0.106569\n",
      "Reconstruction: 0.050937, Regularization: 0.055631\n",
      "2019-04-09 21:40:57,811 root         INFO     Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 0.104161\n",
      "Reconstruction: 0.057859, Regularization: 0.046301\n",
      "2019-04-09 21:40:57,862 root         INFO     ====> Epoch: 175 Average loss: 0.1063\n",
      "2019-04-09 21:40:57,884 root         INFO     Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 0.113201\n",
      "Reconstruction: 0.063144, Regularization: 0.050057\n",
      "2019-04-09 21:40:57,929 root         INFO     Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 0.096897\n",
      "Reconstruction: 0.051867, Regularization: 0.045030\n",
      "2019-04-09 21:40:57,973 root         INFO     Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 0.106366\n",
      "Reconstruction: 0.054476, Regularization: 0.051890\n",
      "2019-04-09 21:40:58,017 root         INFO     Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 0.111623\n",
      "Reconstruction: 0.058140, Regularization: 0.053483\n",
      "2019-04-09 21:40:58,061 root         INFO     Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 0.099453\n",
      "Reconstruction: 0.052536, Regularization: 0.046917\n",
      "2019-04-09 21:40:58,105 root         INFO     Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 0.101860\n",
      "Reconstruction: 0.053880, Regularization: 0.047981\n",
      "2019-04-09 21:40:58,149 root         INFO     Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 0.112733\n",
      "Reconstruction: 0.054800, Regularization: 0.057933\n",
      "2019-04-09 21:40:58,193 root         INFO     Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 0.100051\n",
      "Reconstruction: 0.052949, Regularization: 0.047102\n",
      "2019-04-09 21:40:58,245 root         INFO     ====> Epoch: 176 Average loss: 0.1049\n",
      "2019-04-09 21:40:58,268 root         INFO     Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 0.096850\n",
      "Reconstruction: 0.052690, Regularization: 0.044161\n",
      "2019-04-09 21:40:58,314 root         INFO     Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 0.096662\n",
      "Reconstruction: 0.052810, Regularization: 0.043852\n",
      "2019-04-09 21:40:58,357 root         INFO     Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 0.102643\n",
      "Reconstruction: 0.053880, Regularization: 0.048763\n",
      "2019-04-09 21:40:58,401 root         INFO     Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 0.095147\n",
      "Reconstruction: 0.050220, Regularization: 0.044927\n",
      "2019-04-09 21:40:58,445 root         INFO     Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 0.103558\n",
      "Reconstruction: 0.052684, Regularization: 0.050874\n",
      "2019-04-09 21:40:58,490 root         INFO     Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 0.093547\n",
      "Reconstruction: 0.051279, Regularization: 0.042268\n",
      "2019-04-09 21:40:58,534 root         INFO     Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 0.098020\n",
      "Reconstruction: 0.052488, Regularization: 0.045532\n",
      "2019-04-09 21:40:58,577 root         INFO     Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 0.087264\n",
      "Reconstruction: 0.050503, Regularization: 0.036761\n",
      "2019-04-09 21:40:58,628 root         INFO     ====> Epoch: 177 Average loss: 0.1036\n",
      "2019-04-09 21:40:58,651 root         INFO     Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 0.104206\n",
      "Reconstruction: 0.053211, Regularization: 0.050995\n",
      "2019-04-09 21:40:58,695 root         INFO     Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 0.100540\n",
      "Reconstruction: 0.055628, Regularization: 0.044912\n",
      "2019-04-09 21:40:58,740 root         INFO     Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 0.098284\n",
      "Reconstruction: 0.057363, Regularization: 0.040921\n",
      "2019-04-09 21:40:58,784 root         INFO     Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 0.109116\n",
      "Reconstruction: 0.056869, Regularization: 0.052248\n",
      "2019-04-09 21:40:58,828 root         INFO     Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 0.098060\n",
      "Reconstruction: 0.051351, Regularization: 0.046709\n",
      "2019-04-09 21:40:58,873 root         INFO     Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 0.100421\n",
      "Reconstruction: 0.054397, Regularization: 0.046024\n",
      "2019-04-09 21:40:58,917 root         INFO     Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 0.106242\n",
      "Reconstruction: 0.061411, Regularization: 0.044831\n",
      "2019-04-09 21:40:58,961 root         INFO     Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 0.093596\n",
      "Reconstruction: 0.049091, Regularization: 0.044505\n",
      "2019-04-09 21:40:59,012 root         INFO     ====> Epoch: 178 Average loss: 0.1018\n",
      "2019-04-09 21:40:59,035 root         INFO     Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 0.107159\n",
      "Reconstruction: 0.062648, Regularization: 0.044511\n",
      "2019-04-09 21:40:59,080 root         INFO     Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 0.103460\n",
      "Reconstruction: 0.057135, Regularization: 0.046325\n",
      "2019-04-09 21:40:59,125 root         INFO     Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 0.099903\n",
      "Reconstruction: 0.054859, Regularization: 0.045044\n",
      "2019-04-09 21:40:59,169 root         INFO     Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 0.108395\n",
      "Reconstruction: 0.057046, Regularization: 0.051349\n",
      "2019-04-09 21:40:59,214 root         INFO     Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 0.102400\n",
      "Reconstruction: 0.056195, Regularization: 0.046205\n",
      "2019-04-09 21:40:59,259 root         INFO     Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 0.109176\n",
      "Reconstruction: 0.058202, Regularization: 0.050974\n",
      "2019-04-09 21:40:59,302 root         INFO     Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 0.101412\n",
      "Reconstruction: 0.058146, Regularization: 0.043266\n",
      "2019-04-09 21:40:59,345 root         INFO     Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 0.095906\n",
      "Reconstruction: 0.052507, Regularization: 0.043399\n",
      "2019-04-09 21:40:59,396 root         INFO     ====> Epoch: 179 Average loss: 0.1005\n",
      "2019-04-09 21:40:59,418 root         INFO     Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 0.104079\n",
      "Reconstruction: 0.054934, Regularization: 0.049145\n",
      "2019-04-09 21:40:59,463 root         INFO     Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 0.106873\n",
      "Reconstruction: 0.056245, Regularization: 0.050628\n",
      "2019-04-09 21:40:59,507 root         INFO     Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 0.097314\n",
      "Reconstruction: 0.054004, Regularization: 0.043311\n",
      "2019-04-09 21:40:59,551 root         INFO     Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 0.100376\n",
      "Reconstruction: 0.051192, Regularization: 0.049184\n",
      "2019-04-09 21:40:59,595 root         INFO     Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 0.091671\n",
      "Reconstruction: 0.057045, Regularization: 0.034626\n",
      "2019-04-09 21:40:59,638 root         INFO     Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 0.091949\n",
      "Reconstruction: 0.052566, Regularization: 0.039383\n",
      "2019-04-09 21:40:59,681 root         INFO     Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 0.101940\n",
      "Reconstruction: 0.058342, Regularization: 0.043598\n",
      "2019-04-09 21:40:59,724 root         INFO     Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 0.103040\n",
      "Reconstruction: 0.054681, Regularization: 0.048359\n",
      "2019-04-09 21:40:59,775 root         INFO     ====> Epoch: 180 Average loss: 0.0992\n",
      "2019-04-09 21:40:59,797 root         INFO     Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 0.100486\n",
      "Reconstruction: 0.057202, Regularization: 0.043284\n",
      "2019-04-09 21:40:59,842 root         INFO     Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 0.095091\n",
      "Reconstruction: 0.054541, Regularization: 0.040549\n",
      "2019-04-09 21:40:59,886 root         INFO     Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 0.100517\n",
      "Reconstruction: 0.057206, Regularization: 0.043312\n",
      "2019-04-09 21:40:59,930 root         INFO     Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 0.096169\n",
      "Reconstruction: 0.054889, Regularization: 0.041280\n",
      "2019-04-09 21:40:59,974 root         INFO     Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 0.106014\n",
      "Reconstruction: 0.066068, Regularization: 0.039947\n",
      "2019-04-09 21:41:00,018 root         INFO     Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 0.103875\n",
      "Reconstruction: 0.052714, Regularization: 0.051161\n",
      "2019-04-09 21:41:00,062 root         INFO     Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 0.103001\n",
      "Reconstruction: 0.055359, Regularization: 0.047642\n",
      "2019-04-09 21:41:00,107 root         INFO     Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 0.114322\n",
      "Reconstruction: 0.066666, Regularization: 0.047655\n",
      "2019-04-09 21:41:00,158 root         INFO     ====> Epoch: 181 Average loss: 0.0979\n",
      "2019-04-09 21:41:00,180 root         INFO     Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 0.095468\n",
      "Reconstruction: 0.057851, Regularization: 0.037617\n",
      "2019-04-09 21:41:00,224 root         INFO     Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 0.094569\n",
      "Reconstruction: 0.057406, Regularization: 0.037162\n",
      "2019-04-09 21:41:00,269 root         INFO     Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 0.092209\n",
      "Reconstruction: 0.053701, Regularization: 0.038508\n",
      "2019-04-09 21:41:00,313 root         INFO     Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 0.092072\n",
      "Reconstruction: 0.056411, Regularization: 0.035661\n",
      "2019-04-09 21:41:00,357 root         INFO     Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 0.105367\n",
      "Reconstruction: 0.058129, Regularization: 0.047239\n",
      "2019-04-09 21:41:00,401 root         INFO     Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 0.093052\n",
      "Reconstruction: 0.055688, Regularization: 0.037364\n",
      "2019-04-09 21:41:00,446 root         INFO     Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 0.097460\n",
      "Reconstruction: 0.055036, Regularization: 0.042424\n",
      "2019-04-09 21:41:00,490 root         INFO     Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 0.087952\n",
      "Reconstruction: 0.049695, Regularization: 0.038257\n",
      "2019-04-09 21:41:00,541 root         INFO     ====> Epoch: 182 Average loss: 0.0970\n",
      "2019-04-09 21:41:00,563 root         INFO     Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 0.096407\n",
      "Reconstruction: 0.054844, Regularization: 0.041563\n",
      "2019-04-09 21:41:00,608 root         INFO     Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 0.090534\n",
      "Reconstruction: 0.052121, Regularization: 0.038413\n",
      "2019-04-09 21:41:00,652 root         INFO     Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 0.094583\n",
      "Reconstruction: 0.056578, Regularization: 0.038005\n",
      "2019-04-09 21:41:00,696 root         INFO     Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 0.096770\n",
      "Reconstruction: 0.057250, Regularization: 0.039519\n",
      "2019-04-09 21:41:00,740 root         INFO     Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 0.094082\n",
      "Reconstruction: 0.055168, Regularization: 0.038914\n",
      "2019-04-09 21:41:00,784 root         INFO     Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 0.102394\n",
      "Reconstruction: 0.059717, Regularization: 0.042677\n",
      "2019-04-09 21:41:00,827 root         INFO     Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 0.094061\n",
      "Reconstruction: 0.055003, Regularization: 0.039058\n",
      "2019-04-09 21:41:00,870 root         INFO     Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 0.085077\n",
      "Reconstruction: 0.050510, Regularization: 0.034567\n",
      "2019-04-09 21:41:00,920 root         INFO     ====> Epoch: 183 Average loss: 0.0954\n",
      "2019-04-09 21:41:00,943 root         INFO     Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 0.086032\n",
      "Reconstruction: 0.051863, Regularization: 0.034169\n",
      "2019-04-09 21:41:00,987 root         INFO     Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 0.098630\n",
      "Reconstruction: 0.054317, Regularization: 0.044313\n",
      "2019-04-09 21:41:01,030 root         INFO     Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 0.091100\n",
      "Reconstruction: 0.054640, Regularization: 0.036460\n",
      "2019-04-09 21:41:01,074 root         INFO     Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 0.098289\n",
      "Reconstruction: 0.061928, Regularization: 0.036360\n",
      "2019-04-09 21:41:01,117 root         INFO     Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 0.097989\n",
      "Reconstruction: 0.058470, Regularization: 0.039519\n",
      "2019-04-09 21:41:01,161 root         INFO     Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 0.092514\n",
      "Reconstruction: 0.056764, Regularization: 0.035750\n",
      "2019-04-09 21:41:01,204 root         INFO     Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 0.092627\n",
      "Reconstruction: 0.054869, Regularization: 0.037758\n",
      "2019-04-09 21:41:01,248 root         INFO     Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 0.098696\n",
      "Reconstruction: 0.060769, Regularization: 0.037927\n",
      "2019-04-09 21:41:01,298 root         INFO     ====> Epoch: 184 Average loss: 0.0946\n",
      "2019-04-09 21:41:01,321 root         INFO     Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 0.087690\n",
      "Reconstruction: 0.050348, Regularization: 0.037342\n",
      "2019-04-09 21:41:01,365 root         INFO     Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 0.092917\n",
      "Reconstruction: 0.053933, Regularization: 0.038984\n",
      "2019-04-09 21:41:01,409 root         INFO     Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 0.099493\n",
      "Reconstruction: 0.057888, Regularization: 0.041605\n",
      "2019-04-09 21:41:01,454 root         INFO     Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 0.093830\n",
      "Reconstruction: 0.058334, Regularization: 0.035496\n",
      "2019-04-09 21:41:01,498 root         INFO     Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 0.090778\n",
      "Reconstruction: 0.055982, Regularization: 0.034797\n",
      "2019-04-09 21:41:01,543 root         INFO     Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 0.096441\n",
      "Reconstruction: 0.057182, Regularization: 0.039259\n",
      "2019-04-09 21:41:01,587 root         INFO     Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 0.096806\n",
      "Reconstruction: 0.059664, Regularization: 0.037141\n",
      "2019-04-09 21:41:01,632 root         INFO     Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 0.087333\n",
      "Reconstruction: 0.054109, Regularization: 0.033224\n",
      "2019-04-09 21:41:01,683 root         INFO     ====> Epoch: 185 Average loss: 0.0935\n",
      "2019-04-09 21:41:01,705 root         INFO     Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 0.089258\n",
      "Reconstruction: 0.055758, Regularization: 0.033499\n",
      "2019-04-09 21:41:01,750 root         INFO     Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 0.102169\n",
      "Reconstruction: 0.054619, Regularization: 0.047550\n",
      "2019-04-09 21:41:01,794 root         INFO     Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 0.088030\n",
      "Reconstruction: 0.055183, Regularization: 0.032847\n",
      "2019-04-09 21:41:01,839 root         INFO     Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 0.093002\n",
      "Reconstruction: 0.056862, Regularization: 0.036140\n",
      "2019-04-09 21:41:01,884 root         INFO     Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 0.083014\n",
      "Reconstruction: 0.050390, Regularization: 0.032624\n",
      "2019-04-09 21:41:01,929 root         INFO     Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 0.092233\n",
      "Reconstruction: 0.058668, Regularization: 0.033565\n",
      "2019-04-09 21:41:01,973 root         INFO     Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 0.090795\n",
      "Reconstruction: 0.056196, Regularization: 0.034599\n",
      "2019-04-09 21:41:02,016 root         INFO     Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 0.097103\n",
      "Reconstruction: 0.056696, Regularization: 0.040407\n",
      "2019-04-09 21:41:02,067 root         INFO     ====> Epoch: 186 Average loss: 0.0924\n",
      "2019-04-09 21:41:02,090 root         INFO     Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 0.094134\n",
      "Reconstruction: 0.054410, Regularization: 0.039724\n",
      "2019-04-09 21:41:02,134 root         INFO     Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 0.094191\n",
      "Reconstruction: 0.056207, Regularization: 0.037983\n",
      "2019-04-09 21:41:02,179 root         INFO     Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 0.095983\n",
      "Reconstruction: 0.058600, Regularization: 0.037382\n",
      "2019-04-09 21:41:02,223 root         INFO     Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 0.093372\n",
      "Reconstruction: 0.060070, Regularization: 0.033302\n",
      "2019-04-09 21:41:02,267 root         INFO     Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 0.085999\n",
      "Reconstruction: 0.056274, Regularization: 0.029724\n",
      "2019-04-09 21:41:02,311 root         INFO     Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 0.088225\n",
      "Reconstruction: 0.051408, Regularization: 0.036817\n",
      "2019-04-09 21:41:02,356 root         INFO     Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 0.089749\n",
      "Reconstruction: 0.057162, Regularization: 0.032587\n",
      "2019-04-09 21:41:02,400 root         INFO     Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 0.088355\n",
      "Reconstruction: 0.055735, Regularization: 0.032620\n",
      "2019-04-09 21:41:02,452 root         INFO     ====> Epoch: 187 Average loss: 0.0916\n",
      "2019-04-09 21:41:02,474 root         INFO     Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 0.091989\n",
      "Reconstruction: 0.060787, Regularization: 0.031201\n",
      "2019-04-09 21:41:02,518 root         INFO     Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 0.081751\n",
      "Reconstruction: 0.051966, Regularization: 0.029785\n",
      "2019-04-09 21:41:02,561 root         INFO     Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 0.093169\n",
      "Reconstruction: 0.058637, Regularization: 0.034532\n",
      "2019-04-09 21:41:02,604 root         INFO     Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 0.093240\n",
      "Reconstruction: 0.055963, Regularization: 0.037277\n",
      "2019-04-09 21:41:02,648 root         INFO     Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 0.090762\n",
      "Reconstruction: 0.057096, Regularization: 0.033665\n",
      "2019-04-09 21:41:02,692 root         INFO     Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 0.094706\n",
      "Reconstruction: 0.063094, Regularization: 0.031612\n",
      "2019-04-09 21:41:02,735 root         INFO     Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 0.097505\n",
      "Reconstruction: 0.054399, Regularization: 0.043107\n",
      "2019-04-09 21:41:02,778 root         INFO     Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 0.092627\n",
      "Reconstruction: 0.055778, Regularization: 0.036849\n",
      "2019-04-09 21:41:02,829 root         INFO     ====> Epoch: 188 Average loss: 0.0905\n",
      "2019-04-09 21:41:02,851 root         INFO     Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 0.091759\n",
      "Reconstruction: 0.057259, Regularization: 0.034500\n",
      "2019-04-09 21:41:02,896 root         INFO     Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 0.091258\n",
      "Reconstruction: 0.058612, Regularization: 0.032646\n",
      "2019-04-09 21:41:02,940 root         INFO     Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 0.081542\n",
      "Reconstruction: 0.050040, Regularization: 0.031501\n",
      "2019-04-09 21:41:02,985 root         INFO     Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 0.087632\n",
      "Reconstruction: 0.051722, Regularization: 0.035910\n",
      "2019-04-09 21:41:03,029 root         INFO     Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 0.090695\n",
      "Reconstruction: 0.058742, Regularization: 0.031954\n",
      "2019-04-09 21:41:03,073 root         INFO     Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 0.085116\n",
      "Reconstruction: 0.055873, Regularization: 0.029243\n",
      "2019-04-09 21:41:03,118 root         INFO     Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 0.094225\n",
      "Reconstruction: 0.057193, Regularization: 0.037032\n",
      "2019-04-09 21:41:03,162 root         INFO     Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 0.096914\n",
      "Reconstruction: 0.062409, Regularization: 0.034504\n",
      "2019-04-09 21:41:03,213 root         INFO     ====> Epoch: 189 Average loss: 0.0898\n",
      "2019-04-09 21:41:03,236 root         INFO     Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 0.083666\n",
      "Reconstruction: 0.054914, Regularization: 0.028751\n",
      "2019-04-09 21:41:03,281 root         INFO     Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 0.092929\n",
      "Reconstruction: 0.060458, Regularization: 0.032471\n",
      "2019-04-09 21:41:03,326 root         INFO     Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 0.085941\n",
      "Reconstruction: 0.054214, Regularization: 0.031727\n",
      "2019-04-09 21:41:03,370 root         INFO     Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 0.085909\n",
      "Reconstruction: 0.057008, Regularization: 0.028901\n",
      "2019-04-09 21:41:03,415 root         INFO     Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 0.087625\n",
      "Reconstruction: 0.056563, Regularization: 0.031062\n",
      "2019-04-09 21:41:03,459 root         INFO     Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 0.082160\n",
      "Reconstruction: 0.051209, Regularization: 0.030951\n",
      "2019-04-09 21:41:03,504 root         INFO     Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 0.091599\n",
      "Reconstruction: 0.056377, Regularization: 0.035222\n",
      "2019-04-09 21:41:03,548 root         INFO     Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 0.088313\n",
      "Reconstruction: 0.055771, Regularization: 0.032542\n",
      "2019-04-09 21:41:03,600 root         INFO     ====> Epoch: 190 Average loss: 0.0892\n",
      "2019-04-09 21:41:03,623 root         INFO     Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 0.082398\n",
      "Reconstruction: 0.051852, Regularization: 0.030546\n",
      "2019-04-09 21:41:03,667 root         INFO     Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 0.096676\n",
      "Reconstruction: 0.062991, Regularization: 0.033685\n",
      "2019-04-09 21:41:03,712 root         INFO     Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 0.088386\n",
      "Reconstruction: 0.055181, Regularization: 0.033205\n",
      "2019-04-09 21:41:03,756 root         INFO     Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 0.087465\n",
      "Reconstruction: 0.054737, Regularization: 0.032728\n",
      "2019-04-09 21:41:03,800 root         INFO     Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 0.089155\n",
      "Reconstruction: 0.053965, Regularization: 0.035190\n",
      "2019-04-09 21:41:03,844 root         INFO     Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 0.080943\n",
      "Reconstruction: 0.053222, Regularization: 0.027721\n",
      "2019-04-09 21:41:03,890 root         INFO     Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 0.084989\n",
      "Reconstruction: 0.057148, Regularization: 0.027841\n",
      "2019-04-09 21:41:03,938 root         INFO     Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 0.089438\n",
      "Reconstruction: 0.058043, Regularization: 0.031395\n",
      "2019-04-09 21:41:03,990 root         INFO     ====> Epoch: 191 Average loss: 0.0877\n",
      "2019-04-09 21:41:04,013 root         INFO     Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 0.080118\n",
      "Reconstruction: 0.052248, Regularization: 0.027870\n",
      "2019-04-09 21:41:04,059 root         INFO     Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 0.083289\n",
      "Reconstruction: 0.055463, Regularization: 0.027826\n",
      "2019-04-09 21:41:04,104 root         INFO     Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.089712\n",
      "Reconstruction: 0.057500, Regularization: 0.032212\n",
      "2019-04-09 21:41:04,150 root         INFO     Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 0.081614\n",
      "Reconstruction: 0.052417, Regularization: 0.029197\n",
      "2019-04-09 21:41:04,195 root         INFO     Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 0.085289\n",
      "Reconstruction: 0.054258, Regularization: 0.031030\n",
      "2019-04-09 21:41:04,241 root         INFO     Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 0.085226\n",
      "Reconstruction: 0.055404, Regularization: 0.029823\n",
      "2019-04-09 21:41:04,286 root         INFO     Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 0.106605\n",
      "Reconstruction: 0.066036, Regularization: 0.040569\n",
      "2019-04-09 21:41:04,331 root         INFO     Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 0.078980\n",
      "Reconstruction: 0.052002, Regularization: 0.026977\n",
      "2019-04-09 21:41:04,383 root         INFO     ====> Epoch: 192 Average loss: 0.0874\n",
      "2019-04-09 21:41:04,406 root         INFO     Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 0.094528\n",
      "Reconstruction: 0.060798, Regularization: 0.033730\n",
      "2019-04-09 21:41:04,450 root         INFO     Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 0.080335\n",
      "Reconstruction: 0.056069, Regularization: 0.024266\n",
      "2019-04-09 21:41:04,495 root         INFO     Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 0.098622\n",
      "Reconstruction: 0.068928, Regularization: 0.029695\n",
      "2019-04-09 21:41:04,540 root         INFO     Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 0.084402\n",
      "Reconstruction: 0.052046, Regularization: 0.032356\n",
      "2019-04-09 21:41:04,585 root         INFO     Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 0.081109\n",
      "Reconstruction: 0.055062, Regularization: 0.026047\n",
      "2019-04-09 21:41:04,629 root         INFO     Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 0.085759\n",
      "Reconstruction: 0.055756, Regularization: 0.030003\n",
      "2019-04-09 21:41:04,672 root         INFO     Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 0.097563\n",
      "Reconstruction: 0.062316, Regularization: 0.035246\n",
      "2019-04-09 21:41:04,714 root         INFO     Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 0.081060\n",
      "Reconstruction: 0.056375, Regularization: 0.024685\n",
      "2019-04-09 21:41:04,764 root         INFO     ====> Epoch: 193 Average loss: 0.0867\n",
      "2019-04-09 21:41:04,786 root         INFO     Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 0.091626\n",
      "Reconstruction: 0.055246, Regularization: 0.036380\n",
      "2019-04-09 21:41:04,829 root         INFO     Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 0.089913\n",
      "Reconstruction: 0.055871, Regularization: 0.034043\n",
      "2019-04-09 21:41:04,872 root         INFO     Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 0.082424\n",
      "Reconstruction: 0.054558, Regularization: 0.027867\n",
      "2019-04-09 21:41:04,915 root         INFO     Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 0.091218\n",
      "Reconstruction: 0.058760, Regularization: 0.032458\n",
      "2019-04-09 21:41:04,959 root         INFO     Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 0.085954\n",
      "Reconstruction: 0.055949, Regularization: 0.030005\n",
      "2019-04-09 21:41:05,001 root         INFO     Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 0.083526\n",
      "Reconstruction: 0.055173, Regularization: 0.028353\n",
      "2019-04-09 21:41:05,044 root         INFO     Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 0.085805\n",
      "Reconstruction: 0.061471, Regularization: 0.024334\n",
      "2019-04-09 21:41:05,087 root         INFO     Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 0.081828\n",
      "Reconstruction: 0.053210, Regularization: 0.028618\n",
      "2019-04-09 21:41:05,136 root         INFO     ====> Epoch: 194 Average loss: 0.0851\n",
      "2019-04-09 21:41:05,159 root         INFO     Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 0.083721\n",
      "Reconstruction: 0.056074, Regularization: 0.027647\n",
      "2019-04-09 21:41:05,204 root         INFO     Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 0.083698\n",
      "Reconstruction: 0.055609, Regularization: 0.028089\n",
      "2019-04-09 21:41:05,248 root         INFO     Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 0.080731\n",
      "Reconstruction: 0.054856, Regularization: 0.025875\n",
      "2019-04-09 21:41:05,292 root         INFO     Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 0.078878\n",
      "Reconstruction: 0.051705, Regularization: 0.027172\n",
      "2019-04-09 21:41:05,337 root         INFO     Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 0.089524\n",
      "Reconstruction: 0.059815, Regularization: 0.029709\n",
      "2019-04-09 21:41:05,382 root         INFO     Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 0.081875\n",
      "Reconstruction: 0.055455, Regularization: 0.026420\n",
      "2019-04-09 21:41:05,426 root         INFO     Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 0.076816\n",
      "Reconstruction: 0.053181, Regularization: 0.023635\n",
      "2019-04-09 21:41:05,470 root         INFO     Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 0.082628\n",
      "Reconstruction: 0.053711, Regularization: 0.028917\n",
      "2019-04-09 21:41:05,521 root         INFO     ====> Epoch: 195 Average loss: 0.0847\n",
      "2019-04-09 21:41:05,544 root         INFO     Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 0.083789\n",
      "Reconstruction: 0.055082, Regularization: 0.028708\n",
      "2019-04-09 21:41:05,589 root         INFO     Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 0.094764\n",
      "Reconstruction: 0.065500, Regularization: 0.029264\n",
      "2019-04-09 21:41:05,631 root         INFO     Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 0.077873\n",
      "Reconstruction: 0.049446, Regularization: 0.028427\n",
      "2019-04-09 21:41:05,674 root         INFO     Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 0.085002\n",
      "Reconstruction: 0.057621, Regularization: 0.027382\n",
      "2019-04-09 21:41:05,717 root         INFO     Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 0.082343\n",
      "Reconstruction: 0.056953, Regularization: 0.025391\n",
      "2019-04-09 21:41:05,762 root         INFO     Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 0.076930\n",
      "Reconstruction: 0.054082, Regularization: 0.022848\n",
      "2019-04-09 21:41:05,806 root         INFO     Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 0.087836\n",
      "Reconstruction: 0.057762, Regularization: 0.030074\n",
      "2019-04-09 21:41:05,850 root         INFO     Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 0.083155\n",
      "Reconstruction: 0.054143, Regularization: 0.029011\n",
      "2019-04-09 21:41:05,902 root         INFO     ====> Epoch: 196 Average loss: 0.0838\n",
      "2019-04-09 21:41:05,925 root         INFO     Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 0.085104\n",
      "Reconstruction: 0.057001, Regularization: 0.028103\n",
      "2019-04-09 21:41:05,971 root         INFO     Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 0.083075\n",
      "Reconstruction: 0.057305, Regularization: 0.025771\n",
      "2019-04-09 21:41:06,017 root         INFO     Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 0.087934\n",
      "Reconstruction: 0.059775, Regularization: 0.028158\n",
      "2019-04-09 21:41:06,062 root         INFO     Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 0.087469\n",
      "Reconstruction: 0.059029, Regularization: 0.028440\n",
      "2019-04-09 21:41:06,106 root         INFO     Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 0.077805\n",
      "Reconstruction: 0.053796, Regularization: 0.024008\n",
      "2019-04-09 21:41:06,149 root         INFO     Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 0.076097\n",
      "Reconstruction: 0.052055, Regularization: 0.024042\n",
      "2019-04-09 21:41:06,192 root         INFO     Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 0.080223\n",
      "Reconstruction: 0.053963, Regularization: 0.026260\n",
      "2019-04-09 21:41:06,235 root         INFO     Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 0.076267\n",
      "Reconstruction: 0.053249, Regularization: 0.023018\n",
      "2019-04-09 21:41:06,284 root         INFO     ====> Epoch: 197 Average loss: 0.0832\n",
      "2019-04-09 21:41:06,307 root         INFO     Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 0.082441\n",
      "Reconstruction: 0.054827, Regularization: 0.027614\n",
      "2019-04-09 21:41:06,351 root         INFO     Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.088646\n",
      "Reconstruction: 0.062905, Regularization: 0.025741\n",
      "2019-04-09 21:41:06,394 root         INFO     Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 0.074216\n",
      "Reconstruction: 0.052057, Regularization: 0.022159\n",
      "2019-04-09 21:41:06,438 root         INFO     Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 0.080759\n",
      "Reconstruction: 0.057694, Regularization: 0.023065\n",
      "2019-04-09 21:41:06,481 root         INFO     Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 0.081209\n",
      "Reconstruction: 0.055044, Regularization: 0.026165\n",
      "2019-04-09 21:41:06,525 root         INFO     Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 0.084185\n",
      "Reconstruction: 0.056384, Regularization: 0.027801\n",
      "2019-04-09 21:41:06,568 root         INFO     Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 0.083981\n",
      "Reconstruction: 0.056101, Regularization: 0.027880\n",
      "2019-04-09 21:41:06,611 root         INFO     Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 0.083466\n",
      "Reconstruction: 0.057268, Regularization: 0.026198\n",
      "2019-04-09 21:41:06,661 root         INFO     ====> Epoch: 198 Average loss: 0.0824\n",
      "2019-04-09 21:41:06,684 root         INFO     Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 0.077920\n",
      "Reconstruction: 0.056996, Regularization: 0.020923\n",
      "2019-04-09 21:41:06,727 root         INFO     Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 0.088654\n",
      "Reconstruction: 0.061883, Regularization: 0.026772\n",
      "2019-04-09 21:41:06,771 root         INFO     Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 0.086863\n",
      "Reconstruction: 0.058340, Regularization: 0.028523\n",
      "2019-04-09 21:41:06,814 root         INFO     Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 0.085360\n",
      "Reconstruction: 0.058208, Regularization: 0.027153\n",
      "2019-04-09 21:41:06,859 root         INFO     Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 0.080642\n",
      "Reconstruction: 0.055916, Regularization: 0.024726\n",
      "2019-04-09 21:41:06,903 root         INFO     Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 0.078373\n",
      "Reconstruction: 0.053139, Regularization: 0.025234\n",
      "2019-04-09 21:41:06,946 root         INFO     Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.090406\n",
      "Reconstruction: 0.062879, Regularization: 0.027527\n",
      "2019-04-09 21:41:06,989 root         INFO     Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 0.080333\n",
      "Reconstruction: 0.054765, Regularization: 0.025569\n",
      "2019-04-09 21:41:07,039 root         INFO     ====> Epoch: 199 Average loss: 0.0820\n",
      "2019-04-09 21:41:07,047 luigi-interface INFO     [pid 25020] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=25020) done      TrainVAE()\n",
      "2019-04-09 21:41:07,048 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 21:41:07,048 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   DONE\n",
      "2019-04-09 21:41:07,048 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 21:41:07,048 luigi-interface DEBUG    Pending tasks: 1\n",
      "2019-04-09 21:41:07,048 luigi-interface INFO     [pid 25020] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=25020) running   RunAll()\n",
      "2019-04-09 21:41:07,049 luigi-interface INFO     [pid 25020] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=25020) done      RunAll()\n",
      "2019-04-09 21:41:07,049 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 21:41:07,049 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   DONE\n",
      "2019-04-09 21:41:07,049 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 21:41:07,049 luigi-interface DEBUG    Done\n",
      "2019-04-09 21:41:07,049 luigi-interface DEBUG    There are no more tasks to run at this time\n",
      "2019-04-09 21:41:07,050 luigi-interface INFO     Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=25020) was stopped. Shutting down Keep-Alive thread\n",
      "2019-04-09 21:41:07,051 luigi-interface INFO     \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 4 tasks of which:\n",
      "* 1 complete ones were encountered:\n",
      "    - 1 MakeDataSet()\n",
      "* 3 ran successfully:\n",
      "    - 1 RunAll()\n",
      "    - 1 TrainVAE()\n",
      "    - 1 TrainVEM()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pattern = 'logs'\n",
    "logs = []\n",
    "for filename in os.listdir(OUTPUT):\n",
    "    if re.search(pattern, filename):\n",
    "        logs.append(filename)\n",
    "\n",
    "print('Found %d log files.' % len(logs))\n",
    "        \n",
    "for filename in logs:\n",
    "    path = os.path.join(OUTPUT, filename)\n",
    "    print('\\n-- Log file: %s\\n' % filename)\n",
    "    with open(path, 'r') as f:\n",
    "        message = f.read()\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
