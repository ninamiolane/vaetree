{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import importlib\n",
    "import toylosses\n",
    "importlib.reload(toylosses)\n",
    "import toynn\n",
    "importlib.reload(toynn)\n",
    "import toyvis\n",
    "importlib.reload(toyvis)\n",
    "\n",
    "import torch\n",
    "sns.set()\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "OUTPUT = '/scratch/users/nmiolane/toyoutput'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide on experiment's configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-35.45901743847549, 35.07994011318854, -6.574045953607253, 3.9237758036696855)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_DIM = 2\n",
    "LATENT_DIM = 1\n",
    "N_DECODER_LAYERS = 2\n",
    "NONLINEARITY = False\n",
    "N_SAMPLES = 10000\n",
    "WITH_BIASX = True\n",
    "WITH_LOGVARX = True\n",
    "\n",
    "W_TRUE = {}\n",
    "B_TRUE = {}\n",
    "\n",
    "W_TRUE[0] = [[1.], [1.]]\n",
    "B_TRUE[0] = [0., -1.]\n",
    "\n",
    "# For the reconstruction\n",
    "W_TRUE[1] = [[2., 1.], [-1., 2.]]\n",
    "B_TRUE[1] = [0., 0.]\n",
    "\n",
    "# For the logvarx\n",
    "W_TRUE[2] = [[1., -1.], [0., 1.]]\n",
    "B_TRUE[2] = [3., -1.]\n",
    "\n",
    "if WITH_LOGVARX:\n",
    "    assert len(W_TRUE) == N_DECODER_LAYERS + 1\n",
    "else:\n",
    "    assert len(W_TRUE) == N_DECODER_LAYERS\n",
    "\n",
    "WITH_BIASZ = True\n",
    "WITH_LOGVARZ = True\n",
    "\n",
    "decoder_true = toynn.make_decoder_true(\n",
    "    w_true=W_TRUE, b_true=B_TRUE, latent_dim=LATENT_DIM, \n",
    "    data_dim=DATA_DIM, n_layers=N_DECODER_LAYERS,\n",
    "    nonlinearity=NONLINEARITY, with_biasx=WITH_BIASX, with_logvarx=WITH_LOGVARX)\n",
    "\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, N_SAMPLES)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = toyvis.plot_data(generated_true_x, color='green', label='from decoder true', ax=ax)\n",
    "ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect generation of synthetic data from decoder_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight tensor([[1.],\n",
      "        [1.]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0., -1.], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 2.,  1.],\n",
      "        [-1.,  2.]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([0., 0.], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 1., -1.],\n",
      "        [ 0.,  1.]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([ 3., -1.], device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(nina): Add a comparison to a FA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results from standard VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[1.],\n",
      "        [1.]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0., -1.], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 2.,  1.],\n",
      "        [-1.,  2.]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([0., 0.], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 1., -1.],\n",
      "        [ 0.,  1.]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([ 3., -1.], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[-0.4043],\n",
      "        [-0.2794]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0.0440, -0.8985], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[-0.7276, -0.0537],\n",
      "        [-0.5463,  0.7060]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([-0.8899, -1.4534], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 0.8270, -1.3013],\n",
      "        [-0.4685,  0.6545]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([0.2127, 0.6712], device='cuda:0') \n",
      "\n",
      "Last losses:\n",
      "[1.5386065254211425, 1.511280706167221, 1.48375474524498, 1.4556800575256348, 1.4264577593803405]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "decoder_path = glob.glob(f'{OUTPUT}/train_vae/models/decoder.pth')[0]\n",
    "decoder = torch.load(decoder_path, map_location=DEVICE)\n",
    "\n",
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "losses_vae_path = glob.glob(f'{OUTPUT}/train_vae/train_losses.pkl')[0]\n",
    "train_losses_all_epochs = pickle.load(open(losses_vae_path, 'rb'))\n",
    "\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 4))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(range(n_epochs), train_losses_total)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(range(90, n_epochs), train_losses_total[90:])\n",
    "\n",
    "ax = axes[2]\n",
    "ax.plot(range(160, n_epochs), train_losses_total[160:])\n",
    "\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-29.84966039848803, 24.673002678067412, -6.089774284066346, 2.665690821115047)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "\n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)\n",
    "ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results from VEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- True values of parameters\n",
      "layers.0.weight tensor([[1.],\n",
      "        [1.]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0., -1.], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 2.,  1.],\n",
      "        [-1.,  2.]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([0., 0.], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 1., -1.],\n",
      "        [ 0.,  1.]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([ 3., -1.], device='cuda:0') \n",
      "\n",
      "\n",
      "-- Learnt values of parameters\n",
      "layers.0.weight tensor([[-0.2193],\n",
      "        [-0.1899]], device='cuda:0') \n",
      "\n",
      "layers.0.bias tensor([ 0.5845, -1.3090], device='cuda:0') \n",
      "\n",
      "layers.1.weight tensor([[ 0.7279,  0.5505],\n",
      "        [-0.8447,  0.5077]], device='cuda:0') \n",
      "\n",
      "layers.1.bias tensor([-0.6466, -0.8168], device='cuda:0') \n",
      "\n",
      "layers.2.weight tensor([[ 0.2010, -0.4003],\n",
      "        [ 0.3128, -0.6565]], device='cuda:0') \n",
      "\n",
      "layers.2.bias tensor([-0.1202, -0.0849], device='cuda:0') \n",
      "\n",
      "Last losses:\n",
      "[0.7177514861822129, 0.7156790163516998, 0.7181191428899765, 0.7165926012992859, 0.7155657385587693]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder_true_path = glob.glob(f'{OUTPUT}/synthetic/decoder_true.pth')[0]\n",
    "decoder_true = torch.load(decoder_true_path, map_location=DEVICE)\n",
    "\n",
    "decoder_path = glob.glob(f'{OUTPUT}/train_vem/models/decoder.pth')[0]\n",
    "decoder = torch.load(decoder_path, map_location=DEVICE)\n",
    "\n",
    "print('-- True values of parameters')\n",
    "for name, param in decoder_true.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "\n",
    "print('\\n-- Learnt values of parameters')\n",
    "for name, param in decoder.named_parameters():\n",
    "    print(name, param.data, '\\n')\n",
    "    \n",
    "losses_vae_path = glob.glob(f'{OUTPUT}/train_vem/train_losses.pkl')[0]\n",
    "train_losses_all_epochs = pickle.load(open(losses_vae_path, 'rb'))\n",
    "\n",
    "plt.figure()\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "plt.plot(range(n_epochs), train_losses_total)\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-28.347982306500587, 29.17848519131388, -7.052893099222922, 3.78542406816151)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "generated_true_x = toynn.generate_from_decoder(decoder_true, n_samples)\n",
    "generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "\n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='orange', ax=ax)\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(generated_true_x, color='darkgreen', ax=ax)\n",
    "toyvis.plot_data(generated_x, color='orange', ax=ax)\n",
    "ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print pipeline logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 log files.\n",
      "\n",
      "-- Log file: logs2019-04-09 22:40:55.655206.txt\n",
      "\n",
      "2019-04-09 22:40:55,655 root         INFO     start\n",
      "2019-04-09 22:40:55,670 luigi        INFO     logging configured by default settings\n",
      "2019-04-09 22:40:55,674 luigi-interface DEBUG    Checking if RunAll() is complete\n",
      "2019-04-09 22:40:55,675 luigi-interface DEBUG    Checking if TrainVAE() is complete\n",
      "2019-04-09 22:40:55,675 luigi-interface DEBUG    Checking if TrainVEM() is complete\n",
      "2019-04-09 22:40:55,675 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   PENDING\n",
      "2019-04-09 22:40:55,676 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   DONE\n",
      "2019-04-09 22:40:55,676 luigi-interface DEBUG    Checking if MakeDataSet() is complete\n",
      "2019-04-09 22:40:55,677 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   PENDING\n",
      "2019-04-09 22:40:55,677 luigi-interface INFO     Informed scheduler that task   MakeDataSet__99914b932b   has status   DONE\n",
      "2019-04-09 22:40:55,677 luigi-interface INFO     Done scheduling tasks\n",
      "2019-04-09 22:40:55,677 luigi-interface INFO     Running Worker with 1 processes\n",
      "2019-04-09 22:40:55,678 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 22:40:55,678 luigi-interface DEBUG    Pending tasks: 2\n",
      "2019-04-09 22:40:55,678 luigi-interface INFO     [pid 7258] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=7258) running   TrainVAE()\n",
      "2019-04-09 22:40:55,693 root         INFO     --Dataset tensor: (10000, 2)\n",
      "2019-04-09 22:40:55,694 root         INFO     -- Train tensor: (8000, 2)\n",
      "2019-04-09 22:40:59,487 root         INFO     Values of VAE's decoder parameters before training:\n",
      "2019-04-09 22:40:59,487 root         INFO     layers.0.weight\n",
      "2019-04-09 22:40:59,488 root         INFO     tensor([[-0.2651],\n",
      "        [ 0.1353]], device='cuda:0')\n",
      "2019-04-09 22:40:59,507 root         INFO     layers.0.bias\n",
      "2019-04-09 22:40:59,507 root         INFO     tensor([-0.3248, -0.5761], device='cuda:0')\n",
      "2019-04-09 22:40:59,508 root         INFO     layers.1.weight\n",
      "2019-04-09 22:40:59,508 root         INFO     tensor([[-0.0574,  0.4460],\n",
      "        [ 0.5879, -0.3491]], device='cuda:0')\n",
      "2019-04-09 22:40:59,509 root         INFO     layers.1.bias\n",
      "2019-04-09 22:40:59,509 root         INFO     tensor([-0.4054, -0.0326], device='cuda:0')\n",
      "2019-04-09 22:40:59,510 root         INFO     layers.2.weight\n",
      "2019-04-09 22:40:59,510 root         INFO     tensor([[ 0.3113,  0.3165],\n",
      "        [-0.2632,  0.2449]], device='cuda:0')\n",
      "2019-04-09 22:40:59,511 root         INFO     layers.2.bias\n",
      "2019-04-09 22:40:59,511 root         INFO     tensor([-0.1202, -0.0849], device='cuda:0')\n",
      "2019-04-09 22:40:59,573 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 429821.968750\n",
      "Reconstruction: 429820.125000, Regularization: 1.828875\n",
      "2019-04-09 22:40:59,632 root         INFO     Train Epoch: 0 [512/8000 (6%)]\tTotal Loss: 150604.265625\n",
      "Reconstruction: 150602.187500, Regularization: 2.083999\n",
      "2019-04-09 22:40:59,688 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 1234.182739\n",
      "Reconstruction: 1233.183960, Regularization: 0.998729\n",
      "2019-04-09 22:40:59,744 root         INFO     Train Epoch: 0 [1536/8000 (19%)]\tTotal Loss: 12070.977539\n",
      "Reconstruction: 12069.491211, Regularization: 1.486216\n",
      "2019-04-09 22:40:59,800 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 5144.624023\n",
      "Reconstruction: 5143.151367, Regularization: 1.472596\n",
      "2019-04-09 22:40:59,855 root         INFO     Train Epoch: 0 [2560/8000 (32%)]\tTotal Loss: 451.472992\n",
      "Reconstruction: 449.926147, Regularization: 1.546835\n",
      "2019-04-09 22:40:59,909 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 3483.494385\n",
      "Reconstruction: 3482.287109, Regularization: 1.207222\n",
      "2019-04-09 22:40:59,964 root         INFO     Train Epoch: 0 [3584/8000 (45%)]\tTotal Loss: 3722.145752\n",
      "Reconstruction: 3720.129150, Regularization: 2.016556\n",
      "2019-04-09 22:41:00,019 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 2.569832\n",
      "Reconstruction: 1.487756, Regularization: 1.082076\n",
      "2019-04-09 22:41:00,074 root         INFO     Train Epoch: 0 [4608/8000 (58%)]\tTotal Loss: 30866.312500\n",
      "Reconstruction: 30864.644531, Regularization: 1.668413\n",
      "2019-04-09 22:41:00,129 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 2971.372803\n",
      "Reconstruction: 2970.315918, Regularization: 1.056832\n",
      "2019-04-09 22:41:00,184 root         INFO     Train Epoch: 0 [5632/8000 (70%)]\tTotal Loss: 609.557983\n",
      "Reconstruction: 607.836914, Regularization: 1.721067\n",
      "2019-04-09 22:41:00,239 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 26373506.000000\n",
      "Reconstruction: 26373504.000000, Regularization: 1.906903\n",
      "2019-04-09 22:41:00,293 root         INFO     Train Epoch: 0 [6656/8000 (83%)]\tTotal Loss: 5748.960938\n",
      "Reconstruction: 5746.978516, Regularization: 1.982273\n",
      "2019-04-09 22:41:00,348 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 184676.265625\n",
      "Reconstruction: 184673.312500, Regularization: 2.958999\n",
      "2019-04-09 22:41:00,404 root         INFO     Train Epoch: 0 [7680/8000 (96%)]\tTotal Loss: 499.775543\n",
      "Reconstruction: 498.991333, Regularization: 0.784195\n",
      "2019-04-09 22:41:00,453 root         INFO     ====> Epoch: 0 Average loss: 12361416.9030\n",
      "2019-04-09 22:41:00,476 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 1036854.500000\n",
      "Reconstruction: 1036852.687500, Regularization: 1.829792\n",
      "2019-04-09 22:41:00,531 root         INFO     Train Epoch: 1 [512/8000 (6%)]\tTotal Loss: 5287.818359\n",
      "Reconstruction: 5286.286133, Regularization: 1.532108\n",
      "2019-04-09 22:41:00,586 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 11852.205078\n",
      "Reconstruction: 11851.112305, Regularization: 1.092972\n",
      "2019-04-09 22:41:00,641 root         INFO     Train Epoch: 1 [1536/8000 (19%)]\tTotal Loss: 206.469696\n",
      "Reconstruction: 204.167465, Regularization: 2.302227\n",
      "2019-04-09 22:41:00,695 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 8326.894531\n",
      "Reconstruction: 8325.546875, Regularization: 1.347942\n",
      "2019-04-09 22:41:00,750 root         INFO     Train Epoch: 1 [2560/8000 (32%)]\tTotal Loss: 136.697876\n",
      "Reconstruction: 135.174149, Regularization: 1.523722\n",
      "2019-04-09 22:41:00,804 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 804146.812500\n",
      "Reconstruction: 804144.750000, Regularization: 2.037269\n",
      "2019-04-09 22:41:00,858 root         INFO     Train Epoch: 1 [3584/8000 (45%)]\tTotal Loss: 3188451.250000\n",
      "Reconstruction: 3188448.750000, Regularization: 2.514465\n",
      "2019-04-09 22:41:00,912 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 149.004333\n",
      "Reconstruction: 147.153229, Regularization: 1.851110\n",
      "2019-04-09 22:41:00,966 root         INFO     Train Epoch: 1 [4608/8000 (58%)]\tTotal Loss: 67.439346\n",
      "Reconstruction: 65.756371, Regularization: 1.682976\n",
      "2019-04-09 22:41:01,021 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 7733.846680\n",
      "Reconstruction: 7732.290039, Regularization: 1.556594\n",
      "2019-04-09 22:41:01,076 root         INFO     Train Epoch: 1 [5632/8000 (70%)]\tTotal Loss: 10800.427734\n",
      "Reconstruction: 10797.982422, Regularization: 2.444925\n",
      "2019-04-09 22:41:01,130 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 1083.413208\n",
      "Reconstruction: 1081.735840, Regularization: 1.677366\n",
      "2019-04-09 22:41:01,184 root         INFO     Train Epoch: 1 [6656/8000 (83%)]\tTotal Loss: 991381.687500\n",
      "Reconstruction: 991379.875000, Regularization: 1.787535\n",
      "2019-04-09 22:41:01,238 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 7011.173828\n",
      "Reconstruction: 7009.648926, Regularization: 1.524974\n",
      "2019-04-09 22:41:01,292 root         INFO     Train Epoch: 1 [7680/8000 (96%)]\tTotal Loss: 15554.916992\n",
      "Reconstruction: 15554.005859, Regularization: 0.911163\n",
      "2019-04-09 22:41:01,342 root         INFO     ====> Epoch: 1 Average loss: 18181802.7665\n",
      "2019-04-09 22:41:01,365 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 49.950901\n",
      "Reconstruction: 48.585278, Regularization: 1.365624\n",
      "2019-04-09 22:41:01,420 root         INFO     Train Epoch: 2 [512/8000 (6%)]\tTotal Loss: 1070.082275\n",
      "Reconstruction: 1068.475220, Regularization: 1.607113\n",
      "2019-04-09 22:41:01,474 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 239.719116\n",
      "Reconstruction: 238.077240, Regularization: 1.641870\n",
      "2019-04-09 22:41:01,529 root         INFO     Train Epoch: 2 [1536/8000 (19%)]\tTotal Loss: 125408.007812\n",
      "Reconstruction: 125406.062500, Regularization: 1.948756\n",
      "2019-04-09 22:41:01,583 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 120882.460938\n",
      "Reconstruction: 120880.890625, Regularization: 1.571136\n",
      "2019-04-09 22:41:01,638 root         INFO     Train Epoch: 2 [2560/8000 (32%)]\tTotal Loss: 846.647400\n",
      "Reconstruction: 844.585999, Regularization: 2.061373\n",
      "2019-04-09 22:41:01,692 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 263.054413\n",
      "Reconstruction: 261.875732, Regularization: 1.178689\n",
      "2019-04-09 22:41:01,747 root         INFO     Train Epoch: 2 [3584/8000 (45%)]\tTotal Loss: 18503.095703\n",
      "Reconstruction: 18501.253906, Regularization: 1.842712\n",
      "2019-04-09 22:41:01,802 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 1200.495239\n",
      "Reconstruction: 1198.990112, Regularization: 1.505074\n",
      "2019-04-09 22:41:01,857 root         INFO     Train Epoch: 2 [4608/8000 (58%)]\tTotal Loss: 31640.390625\n",
      "Reconstruction: 31638.347656, Regularization: 2.042543\n",
      "2019-04-09 22:41:01,912 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 422.638184\n",
      "Reconstruction: 420.820526, Regularization: 1.817652\n",
      "2019-04-09 22:41:01,966 root         INFO     Train Epoch: 2 [5632/8000 (70%)]\tTotal Loss: 26401.701172\n",
      "Reconstruction: 26399.228516, Regularization: 2.473565\n",
      "2019-04-09 22:41:02,021 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 15897.567383\n",
      "Reconstruction: 15895.607422, Regularization: 1.959623\n",
      "2019-04-09 22:41:02,075 root         INFO     Train Epoch: 2 [6656/8000 (83%)]\tTotal Loss: 5450.179688\n",
      "Reconstruction: 5448.834473, Regularization: 1.345121\n",
      "2019-04-09 22:41:02,130 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 89826.921875\n",
      "Reconstruction: 89825.156250, Regularization: 1.767959\n",
      "2019-04-09 22:41:02,185 root         INFO     Train Epoch: 2 [7680/8000 (96%)]\tTotal Loss: 10.028317\n",
      "Reconstruction: 8.275126, Regularization: 1.753192\n",
      "2019-04-09 22:41:02,235 root         INFO     ====> Epoch: 2 Average loss: 8246438.4266\n",
      "2019-04-09 22:41:02,257 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 44.721348\n",
      "Reconstruction: 43.713886, Regularization: 1.007463\n",
      "2019-04-09 22:41:02,312 root         INFO     Train Epoch: 3 [512/8000 (6%)]\tTotal Loss: 2150.390137\n",
      "Reconstruction: 2148.305176, Regularization: 2.084859\n",
      "2019-04-09 22:41:02,367 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 133.243668\n",
      "Reconstruction: 131.501678, Regularization: 1.741987\n",
      "2019-04-09 22:41:02,422 root         INFO     Train Epoch: 3 [1536/8000 (19%)]\tTotal Loss: 15884.054688\n",
      "Reconstruction: 15882.417969, Regularization: 1.636369\n",
      "2019-04-09 22:41:02,477 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 4198.026855\n",
      "Reconstruction: 4196.436523, Regularization: 1.590452\n",
      "2019-04-09 22:41:02,532 root         INFO     Train Epoch: 3 [2560/8000 (32%)]\tTotal Loss: 332.527985\n",
      "Reconstruction: 330.307098, Regularization: 2.220900\n",
      "2019-04-09 22:41:02,586 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 148.170197\n",
      "Reconstruction: 146.875610, Regularization: 1.294588\n",
      "2019-04-09 22:41:02,641 root         INFO     Train Epoch: 3 [3584/8000 (45%)]\tTotal Loss: 8849.893555\n",
      "Reconstruction: 8848.269531, Regularization: 1.623636\n",
      "2019-04-09 22:41:02,695 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 15552.869141\n",
      "Reconstruction: 15551.208984, Regularization: 1.660497\n",
      "2019-04-09 22:41:02,750 root         INFO     Train Epoch: 3 [4608/8000 (58%)]\tTotal Loss: 1271.994995\n",
      "Reconstruction: 1270.432739, Regularization: 1.562226\n",
      "2019-04-09 22:41:02,805 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 12717.884766\n",
      "Reconstruction: 12715.670898, Regularization: 2.214001\n",
      "2019-04-09 22:41:02,859 root         INFO     Train Epoch: 3 [5632/8000 (70%)]\tTotal Loss: 31598.332031\n",
      "Reconstruction: 31596.951172, Regularization: 1.380943\n",
      "2019-04-09 22:41:02,914 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 345.592529\n",
      "Reconstruction: 344.334259, Regularization: 1.258270\n",
      "2019-04-09 22:41:02,968 root         INFO     Train Epoch: 3 [6656/8000 (83%)]\tTotal Loss: 2349.263428\n",
      "Reconstruction: 2347.998047, Regularization: 1.265320\n",
      "2019-04-09 22:41:03,023 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 395.025940\n",
      "Reconstruction: 393.510040, Regularization: 1.515905\n",
      "2019-04-09 22:41:03,077 root         INFO     Train Epoch: 3 [7680/8000 (96%)]\tTotal Loss: 42771.011719\n",
      "Reconstruction: 42769.167969, Regularization: 1.844250\n",
      "2019-04-09 22:41:03,126 root         INFO     ====> Epoch: 3 Average loss: 1993506.5879\n",
      "2019-04-09 22:41:03,149 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 102017.054688\n",
      "Reconstruction: 102015.171875, Regularization: 1.881391\n",
      "2019-04-09 22:41:03,204 root         INFO     Train Epoch: 4 [512/8000 (6%)]\tTotal Loss: 19057.765625\n",
      "Reconstruction: 19056.267578, Regularization: 1.497783\n",
      "2019-04-09 22:41:03,259 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 1430.769165\n",
      "Reconstruction: 1429.207764, Regularization: 1.561459\n",
      "2019-04-09 22:41:03,314 root         INFO     Train Epoch: 4 [1536/8000 (19%)]\tTotal Loss: 120.674156\n",
      "Reconstruction: 119.500969, Regularization: 1.173186\n",
      "2019-04-09 22:41:03,368 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 1394.713257\n",
      "Reconstruction: 1392.343262, Regularization: 2.370031\n",
      "2019-04-09 22:41:03,424 root         INFO     Train Epoch: 4 [2560/8000 (32%)]\tTotal Loss: 38172.367188\n",
      "Reconstruction: 38170.871094, Regularization: 1.495528\n",
      "2019-04-09 22:41:03,479 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 16698.082031\n",
      "Reconstruction: 16696.205078, Regularization: 1.876810\n",
      "2019-04-09 22:41:03,534 root         INFO     Train Epoch: 4 [3584/8000 (45%)]\tTotal Loss: 3488.653320\n",
      "Reconstruction: 3486.190430, Regularization: 2.462963\n",
      "2019-04-09 22:41:03,589 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 13216.649414\n",
      "Reconstruction: 13215.558594, Regularization: 1.091285\n",
      "2019-04-09 22:41:03,644 root         INFO     Train Epoch: 4 [4608/8000 (58%)]\tTotal Loss: 279.781281\n",
      "Reconstruction: 277.908203, Regularization: 1.873090\n",
      "2019-04-09 22:41:03,699 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 87266.109375\n",
      "Reconstruction: 87264.468750, Regularization: 1.643886\n",
      "2019-04-09 22:41:03,753 root         INFO     Train Epoch: 4 [5632/8000 (70%)]\tTotal Loss: 771.678101\n",
      "Reconstruction: 770.516968, Regularization: 1.161155\n",
      "2019-04-09 22:41:03,808 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 29894.130859\n",
      "Reconstruction: 29892.478516, Regularization: 1.651996\n",
      "2019-04-09 22:41:03,863 root         INFO     Train Epoch: 4 [6656/8000 (83%)]\tTotal Loss: 33809.324219\n",
      "Reconstruction: 33807.605469, Regularization: 1.717679\n",
      "2019-04-09 22:41:03,917 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 49340.558594\n",
      "Reconstruction: 49338.281250, Regularization: 2.276149\n",
      "2019-04-09 22:41:03,972 root         INFO     Train Epoch: 4 [7680/8000 (96%)]\tTotal Loss: 2102.522949\n",
      "Reconstruction: 2100.217773, Regularization: 2.305257\n",
      "2019-04-09 22:41:04,021 root         INFO     ====> Epoch: 4 Average loss: 3573825.7423\n",
      "2019-04-09 22:41:04,044 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 33.346336\n",
      "Reconstruction: 31.362438, Regularization: 1.983900\n",
      "2019-04-09 22:41:04,099 root         INFO     Train Epoch: 5 [512/8000 (6%)]\tTotal Loss: 1534117.500000\n",
      "Reconstruction: 1534115.500000, Regularization: 2.046094\n",
      "2019-04-09 22:41:04,155 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 1158.106812\n",
      "Reconstruction: 1156.833618, Regularization: 1.273152\n",
      "2019-04-09 22:41:04,210 root         INFO     Train Epoch: 5 [1536/8000 (19%)]\tTotal Loss: 57.348373\n",
      "Reconstruction: 56.377453, Regularization: 0.970922\n",
      "2019-04-09 22:41:04,265 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 3646.926270\n",
      "Reconstruction: 3644.675293, Regularization: 2.250926\n",
      "2019-04-09 22:41:04,320 root         INFO     Train Epoch: 5 [2560/8000 (32%)]\tTotal Loss: 8685.693359\n",
      "Reconstruction: 8684.279297, Regularization: 1.414166\n",
      "2019-04-09 22:41:04,375 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 3432.272461\n",
      "Reconstruction: 3430.015869, Regularization: 2.256586\n",
      "2019-04-09 22:41:04,430 root         INFO     Train Epoch: 5 [3584/8000 (45%)]\tTotal Loss: 522.396179\n",
      "Reconstruction: 519.457153, Regularization: 2.939045\n",
      "2019-04-09 22:41:04,486 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 56.975464\n",
      "Reconstruction: 55.772804, Regularization: 1.202659\n",
      "2019-04-09 22:41:04,541 root         INFO     Train Epoch: 5 [4608/8000 (58%)]\tTotal Loss: 185.147629\n",
      "Reconstruction: 184.068939, Regularization: 1.078691\n",
      "2019-04-09 22:41:04,597 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 130.774414\n",
      "Reconstruction: 128.933899, Regularization: 1.840520\n",
      "2019-04-09 22:41:04,653 root         INFO     Train Epoch: 5 [5632/8000 (70%)]\tTotal Loss: 18499.873047\n",
      "Reconstruction: 18497.699219, Regularization: 2.174486\n",
      "2019-04-09 22:41:04,708 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 11402.544922\n",
      "Reconstruction: 11400.083984, Regularization: 2.460594\n",
      "2019-04-09 22:41:04,764 root         INFO     Train Epoch: 5 [6656/8000 (83%)]\tTotal Loss: 7509.621094\n",
      "Reconstruction: 7508.040527, Regularization: 1.580552\n",
      "2019-04-09 22:41:04,819 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 139470.953125\n",
      "Reconstruction: 139469.140625, Regularization: 1.816655\n",
      "2019-04-09 22:41:04,875 root         INFO     Train Epoch: 5 [7680/8000 (96%)]\tTotal Loss: 55.259224\n",
      "Reconstruction: 53.544476, Regularization: 1.714750\n",
      "2019-04-09 22:41:04,924 root         INFO     ====> Epoch: 5 Average loss: 12433651.8040\n",
      "2019-04-09 22:41:04,947 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 1838040.375000\n",
      "Reconstruction: 1838038.750000, Regularization: 1.669417\n",
      "2019-04-09 22:41:05,003 root         INFO     Train Epoch: 6 [512/8000 (6%)]\tTotal Loss: 791.176086\n",
      "Reconstruction: 789.553833, Regularization: 1.622274\n",
      "2019-04-09 22:41:05,058 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 180.306992\n",
      "Reconstruction: 178.634125, Regularization: 1.672866\n",
      "2019-04-09 22:41:05,114 root         INFO     Train Epoch: 6 [1536/8000 (19%)]\tTotal Loss: 6192.781738\n",
      "Reconstruction: 6190.954590, Regularization: 1.827244\n",
      "2019-04-09 22:41:05,170 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 354.813416\n",
      "Reconstruction: 353.154480, Regularization: 1.658948\n",
      "2019-04-09 22:41:05,225 root         INFO     Train Epoch: 6 [2560/8000 (32%)]\tTotal Loss: 1974887.875000\n",
      "Reconstruction: 1974886.000000, Regularization: 1.816292\n",
      "2019-04-09 22:41:05,280 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 4707.338867\n",
      "Reconstruction: 4705.775391, Regularization: 1.563365\n",
      "2019-04-09 22:41:05,336 root         INFO     Train Epoch: 6 [3584/8000 (45%)]\tTotal Loss: 1734.617310\n",
      "Reconstruction: 1733.150757, Regularization: 1.466509\n",
      "2019-04-09 22:41:05,391 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 6551.662109\n",
      "Reconstruction: 6550.142090, Regularization: 1.520131\n",
      "2019-04-09 22:41:05,447 root         INFO     Train Epoch: 6 [4608/8000 (58%)]\tTotal Loss: 2406.153564\n",
      "Reconstruction: 2405.195557, Regularization: 0.957951\n",
      "2019-04-09 22:41:05,504 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 395.119141\n",
      "Reconstruction: 393.048981, Regularization: 2.070154\n",
      "2019-04-09 22:41:05,560 root         INFO     Train Epoch: 6 [5632/8000 (70%)]\tTotal Loss: 177247.328125\n",
      "Reconstruction: 177245.015625, Regularization: 2.317808\n",
      "2019-04-09 22:41:05,616 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 217.062485\n",
      "Reconstruction: 215.698380, Regularization: 1.364104\n",
      "2019-04-09 22:41:05,673 root         INFO     Train Epoch: 6 [6656/8000 (83%)]\tTotal Loss: 145.869141\n",
      "Reconstruction: 144.411331, Regularization: 1.457815\n",
      "2019-04-09 22:41:05,729 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 51282.378906\n",
      "Reconstruction: 51280.578125, Regularization: 1.799361\n",
      "2019-04-09 22:41:05,785 root         INFO     Train Epoch: 6 [7680/8000 (96%)]\tTotal Loss: 5503.958984\n",
      "Reconstruction: 5502.693848, Regularization: 1.265059\n",
      "2019-04-09 22:41:05,836 root         INFO     ====> Epoch: 6 Average loss: 4392723.8333\n",
      "2019-04-09 22:41:05,858 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 214.090210\n",
      "Reconstruction: 211.912109, Regularization: 2.178098\n",
      "2019-04-09 22:41:05,914 root         INFO     Train Epoch: 7 [512/8000 (6%)]\tTotal Loss: 11771.076172\n",
      "Reconstruction: 11768.646484, Regularization: 2.429736\n",
      "2019-04-09 22:41:05,969 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 8858.359375\n",
      "Reconstruction: 8856.489258, Regularization: 1.870206\n",
      "2019-04-09 22:41:06,024 root         INFO     Train Epoch: 7 [1536/8000 (19%)]\tTotal Loss: 326921.937500\n",
      "Reconstruction: 326920.250000, Regularization: 1.679955\n",
      "2019-04-09 22:41:06,079 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 119.084213\n",
      "Reconstruction: 117.983604, Regularization: 1.100605\n",
      "2019-04-09 22:41:06,133 root         INFO     Train Epoch: 7 [2560/8000 (32%)]\tTotal Loss: 5972.083496\n",
      "Reconstruction: 5971.031250, Regularization: 1.052108\n",
      "2019-04-09 22:41:06,188 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 222644.875000\n",
      "Reconstruction: 222643.156250, Regularization: 1.724518\n",
      "2019-04-09 22:41:06,242 root         INFO     Train Epoch: 7 [3584/8000 (45%)]\tTotal Loss: 26690.791016\n",
      "Reconstruction: 26689.080078, Regularization: 1.710252\n",
      "2019-04-09 22:41:06,297 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 28932.853516\n",
      "Reconstruction: 28931.167969, Regularization: 1.685579\n",
      "2019-04-09 22:41:06,352 root         INFO     Train Epoch: 7 [4608/8000 (58%)]\tTotal Loss: 25854.400391\n",
      "Reconstruction: 25852.751953, Regularization: 1.648548\n",
      "2019-04-09 22:41:06,406 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 27503.300781\n",
      "Reconstruction: 27501.335938, Regularization: 1.964416\n",
      "2019-04-09 22:41:06,461 root         INFO     Train Epoch: 7 [5632/8000 (70%)]\tTotal Loss: 824.116699\n",
      "Reconstruction: 823.244507, Regularization: 0.872181\n",
      "2019-04-09 22:41:06,516 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 4187.060547\n",
      "Reconstruction: 4184.684570, Regularization: 2.376092\n",
      "2019-04-09 22:41:06,571 root         INFO     Train Epoch: 7 [6656/8000 (83%)]\tTotal Loss: 5484.321777\n",
      "Reconstruction: 5482.197266, Regularization: 2.124321\n",
      "2019-04-09 22:41:06,625 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 14793632.000000\n",
      "Reconstruction: 14793630.000000, Regularization: 2.127249\n",
      "2019-04-09 22:41:06,680 root         INFO     Train Epoch: 7 [7680/8000 (96%)]\tTotal Loss: 445945.718750\n",
      "Reconstruction: 445943.656250, Regularization: 2.077228\n",
      "2019-04-09 22:41:06,728 root         INFO     ====> Epoch: 7 Average loss: 3823685.1131\n",
      "2019-04-09 22:41:06,751 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 701.515259\n",
      "Reconstruction: 699.495300, Regularization: 2.019933\n",
      "2019-04-09 22:41:06,807 root         INFO     Train Epoch: 8 [512/8000 (6%)]\tTotal Loss: 1793.976929\n",
      "Reconstruction: 1792.655518, Regularization: 1.321393\n",
      "2019-04-09 22:41:06,862 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 419.403717\n",
      "Reconstruction: 417.619690, Regularization: 1.784015\n",
      "2019-04-09 22:41:06,917 root         INFO     Train Epoch: 8 [1536/8000 (19%)]\tTotal Loss: 3526.181885\n",
      "Reconstruction: 3524.131348, Regularization: 2.050576\n",
      "2019-04-09 22:41:06,972 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 4112.591797\n",
      "Reconstruction: 4111.326660, Regularization: 1.265157\n",
      "2019-04-09 22:41:07,028 root         INFO     Train Epoch: 8 [2560/8000 (32%)]\tTotal Loss: 343705.687500\n",
      "Reconstruction: 343704.000000, Regularization: 1.679061\n",
      "2019-04-09 22:41:07,083 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 9186.844727\n",
      "Reconstruction: 9185.079102, Regularization: 1.765253\n",
      "2019-04-09 22:41:07,137 root         INFO     Train Epoch: 8 [3584/8000 (45%)]\tTotal Loss: 3569.666748\n",
      "Reconstruction: 3567.314697, Regularization: 2.352147\n",
      "2019-04-09 22:41:07,192 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 255.738617\n",
      "Reconstruction: 254.076019, Regularization: 1.662601\n",
      "2019-04-09 22:41:07,246 root         INFO     Train Epoch: 8 [4608/8000 (58%)]\tTotal Loss: 16719.650391\n",
      "Reconstruction: 16718.121094, Regularization: 1.529378\n",
      "2019-04-09 22:41:07,300 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 5772.583984\n",
      "Reconstruction: 5771.220703, Regularization: 1.363521\n",
      "2019-04-09 22:41:07,355 root         INFO     Train Epoch: 8 [5632/8000 (70%)]\tTotal Loss: 2102.457764\n",
      "Reconstruction: 2100.638672, Regularization: 1.819045\n",
      "2019-04-09 22:41:07,410 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 46558268.000000\n",
      "Reconstruction: 46558268.000000, Regularization: 1.805830\n",
      "2019-04-09 22:41:07,465 root         INFO     Train Epoch: 8 [6656/8000 (83%)]\tTotal Loss: 681.833130\n",
      "Reconstruction: 680.509338, Regularization: 1.323799\n",
      "2019-04-09 22:41:07,522 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 79509616.000000\n",
      "Reconstruction: 79509616.000000, Regularization: 1.764807\n",
      "2019-04-09 22:41:07,579 root         INFO     Train Epoch: 8 [7680/8000 (96%)]\tTotal Loss: 3345.790771\n",
      "Reconstruction: 3344.559082, Regularization: 1.231644\n",
      "2019-04-09 22:41:07,630 root         INFO     ====> Epoch: 8 Average loss: 1424660.3415\n",
      "2019-04-09 22:41:07,653 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 44.710388\n",
      "Reconstruction: 43.387390, Regularization: 1.322998\n",
      "2019-04-09 22:41:07,708 root         INFO     Train Epoch: 9 [512/8000 (6%)]\tTotal Loss: 77980.531250\n",
      "Reconstruction: 77978.929688, Regularization: 1.603894\n",
      "2019-04-09 22:41:07,767 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 151.868347\n",
      "Reconstruction: 150.860779, Regularization: 1.007571\n",
      "2019-04-09 22:41:07,824 root         INFO     Train Epoch: 9 [1536/8000 (19%)]\tTotal Loss: 744.680176\n",
      "Reconstruction: 743.647949, Regularization: 1.032196\n",
      "2019-04-09 22:41:07,881 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 4598.338867\n",
      "Reconstruction: 4596.476562, Regularization: 1.862380\n",
      "2019-04-09 22:41:07,938 root         INFO     Train Epoch: 9 [2560/8000 (32%)]\tTotal Loss: 6132.536133\n",
      "Reconstruction: 6130.243164, Regularization: 2.292985\n",
      "2019-04-09 22:41:07,994 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 334.074066\n",
      "Reconstruction: 333.078247, Regularization: 0.995833\n",
      "2019-04-09 22:41:08,051 root         INFO     Train Epoch: 9 [3584/8000 (45%)]\tTotal Loss: 147.480103\n",
      "Reconstruction: 145.450882, Regularization: 2.029222\n",
      "2019-04-09 22:41:08,108 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 5806.601074\n",
      "Reconstruction: 5804.820312, Regularization: 1.780835\n",
      "2019-04-09 22:41:08,164 root         INFO     Train Epoch: 9 [4608/8000 (58%)]\tTotal Loss: 435360.781250\n",
      "Reconstruction: 435358.750000, Regularization: 2.018136\n",
      "2019-04-09 22:41:08,221 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 114515216.000000\n",
      "Reconstruction: 114515216.000000, Regularization: 2.665295\n",
      "2019-04-09 22:41:08,278 root         INFO     Train Epoch: 9 [5632/8000 (70%)]\tTotal Loss: 5607.951172\n",
      "Reconstruction: 5606.350098, Regularization: 1.601221\n",
      "2019-04-09 22:41:08,334 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 1277.845215\n",
      "Reconstruction: 1276.672119, Regularization: 1.173109\n",
      "2019-04-09 22:41:08,391 root         INFO     Train Epoch: 9 [6656/8000 (83%)]\tTotal Loss: 130.435745\n",
      "Reconstruction: 129.219742, Regularization: 1.216002\n",
      "2019-04-09 22:41:08,447 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 7063.501953\n",
      "Reconstruction: 7061.795410, Regularization: 1.706622\n",
      "2019-04-09 22:41:08,504 root         INFO     Train Epoch: 9 [7680/8000 (96%)]\tTotal Loss: 5963.794434\n",
      "Reconstruction: 5962.802734, Regularization: 0.991798\n",
      "2019-04-09 22:41:08,555 root         INFO     ====> Epoch: 9 Average loss: 8438829.9430\n",
      "2019-04-09 22:41:08,578 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 183.818054\n",
      "Reconstruction: 182.692368, Regularization: 1.125686\n",
      "2019-04-09 22:41:08,634 root         INFO     Train Epoch: 10 [512/8000 (6%)]\tTotal Loss: 1487.095947\n",
      "Reconstruction: 1485.346436, Regularization: 1.749572\n",
      "2019-04-09 22:41:08,691 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 5060.942871\n",
      "Reconstruction: 5058.938965, Regularization: 2.004074\n",
      "2019-04-09 22:41:08,747 root         INFO     Train Epoch: 10 [1536/8000 (19%)]\tTotal Loss: 7425.795410\n",
      "Reconstruction: 7424.010742, Regularization: 1.784775\n",
      "2019-04-09 22:41:08,804 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 4262.594238\n",
      "Reconstruction: 4261.110840, Regularization: 1.483358\n",
      "2019-04-09 22:41:08,860 root         INFO     Train Epoch: 10 [2560/8000 (32%)]\tTotal Loss: 82.310921\n",
      "Reconstruction: 80.955696, Regularization: 1.355228\n",
      "2019-04-09 22:41:08,915 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 2027.159302\n",
      "Reconstruction: 2025.855225, Regularization: 1.304109\n",
      "2019-04-09 22:41:08,970 root         INFO     Train Epoch: 10 [3584/8000 (45%)]\tTotal Loss: 184.967850\n",
      "Reconstruction: 183.666382, Regularization: 1.301471\n",
      "2019-04-09 22:41:09,025 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 2855.533447\n",
      "Reconstruction: 2853.594238, Regularization: 1.939146\n",
      "2019-04-09 22:41:09,081 root         INFO     Train Epoch: 10 [4608/8000 (58%)]\tTotal Loss: 150.458984\n",
      "Reconstruction: 148.950912, Regularization: 1.508073\n",
      "2019-04-09 22:41:09,137 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 587.071960\n",
      "Reconstruction: 585.568481, Regularization: 1.503501\n",
      "2019-04-09 22:41:09,193 root         INFO     Train Epoch: 10 [5632/8000 (70%)]\tTotal Loss: 11.141720\n",
      "Reconstruction: 9.644930, Regularization: 1.496790\n",
      "2019-04-09 22:41:09,250 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 24.992216\n",
      "Reconstruction: 23.555664, Regularization: 1.436553\n",
      "2019-04-09 22:41:09,306 root         INFO     Train Epoch: 10 [6656/8000 (83%)]\tTotal Loss: 257.554779\n",
      "Reconstruction: 256.396729, Regularization: 1.158052\n",
      "2019-04-09 22:41:09,362 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 314.491882\n",
      "Reconstruction: 313.310394, Regularization: 1.181475\n",
      "2019-04-09 22:41:09,418 root         INFO     Train Epoch: 10 [7680/8000 (96%)]\tTotal Loss: 1185.598022\n",
      "Reconstruction: 1184.667480, Regularization: 0.930504\n",
      "2019-04-09 22:41:09,468 root         INFO     ====> Epoch: 10 Average loss: 1031068.9378\n",
      "2019-04-09 22:41:09,491 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 117.833763\n",
      "Reconstruction: 116.243317, Regularization: 1.590448\n",
      "2019-04-09 22:41:09,548 root         INFO     Train Epoch: 11 [512/8000 (6%)]\tTotal Loss: 34706248.000000\n",
      "Reconstruction: 34706248.000000, Regularization: 1.923165\n",
      "2019-04-09 22:41:09,604 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 3992.739990\n",
      "Reconstruction: 3990.918457, Regularization: 1.821535\n",
      "2019-04-09 22:41:09,661 root         INFO     Train Epoch: 11 [1536/8000 (19%)]\tTotal Loss: 1993.492798\n",
      "Reconstruction: 1992.031982, Regularization: 1.460782\n",
      "2019-04-09 22:41:09,716 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 7406.098633\n",
      "Reconstruction: 7404.254883, Regularization: 1.843747\n",
      "2019-04-09 22:41:09,771 root         INFO     Train Epoch: 11 [2560/8000 (32%)]\tTotal Loss: 188.662109\n",
      "Reconstruction: 187.460571, Regularization: 1.201542\n",
      "2019-04-09 22:41:09,825 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 3172.885498\n",
      "Reconstruction: 3171.024658, Regularization: 1.860813\n",
      "2019-04-09 22:41:09,880 root         INFO     Train Epoch: 11 [3584/8000 (45%)]\tTotal Loss: 118017.562500\n",
      "Reconstruction: 118016.148438, Regularization: 1.413498\n",
      "2019-04-09 22:41:09,937 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 5278.526367\n",
      "Reconstruction: 5276.162109, Regularization: 2.364460\n",
      "2019-04-09 22:41:09,993 root         INFO     Train Epoch: 11 [4608/8000 (58%)]\tTotal Loss: 913.049133\n",
      "Reconstruction: 911.732910, Regularization: 1.316208\n",
      "2019-04-09 22:41:10,049 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 17975.929688\n",
      "Reconstruction: 17974.058594, Regularization: 1.871748\n",
      "2019-04-09 22:41:10,105 root         INFO     Train Epoch: 11 [5632/8000 (70%)]\tTotal Loss: 615.921875\n",
      "Reconstruction: 614.780334, Regularization: 1.141558\n",
      "2019-04-09 22:41:10,161 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 2340.970703\n",
      "Reconstruction: 2338.717529, Regularization: 2.253273\n",
      "2019-04-09 22:41:10,217 root         INFO     Train Epoch: 11 [6656/8000 (83%)]\tTotal Loss: 53217.750000\n",
      "Reconstruction: 53216.593750, Regularization: 1.157447\n",
      "2019-04-09 22:41:10,274 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 567459.625000\n",
      "Reconstruction: 567458.062500, Regularization: 1.563148\n",
      "2019-04-09 22:41:10,330 root         INFO     Train Epoch: 11 [7680/8000 (96%)]\tTotal Loss: 175.518753\n",
      "Reconstruction: 173.957733, Regularization: 1.561013\n",
      "2019-04-09 22:41:10,379 root         INFO     ====> Epoch: 11 Average loss: 9632497.5594\n",
      "2019-04-09 22:41:10,402 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 102734.000000\n",
      "Reconstruction: 102732.593750, Regularization: 1.405468\n",
      "2019-04-09 22:41:10,459 root         INFO     Train Epoch: 12 [512/8000 (6%)]\tTotal Loss: 340.182526\n",
      "Reconstruction: 339.073181, Regularization: 1.109336\n",
      "2019-04-09 22:41:10,515 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 44437.953125\n",
      "Reconstruction: 44435.542969, Regularization: 2.409638\n",
      "2019-04-09 22:41:10,571 root         INFO     Train Epoch: 12 [1536/8000 (19%)]\tTotal Loss: 448.011963\n",
      "Reconstruction: 445.916046, Regularization: 2.095922\n",
      "2019-04-09 22:41:10,627 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 200.732193\n",
      "Reconstruction: 198.480637, Regularization: 2.251558\n",
      "2019-04-09 22:41:10,683 root         INFO     Train Epoch: 12 [2560/8000 (32%)]\tTotal Loss: 643.933960\n",
      "Reconstruction: 642.873474, Regularization: 1.060472\n",
      "2019-04-09 22:41:10,739 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 2128.328125\n",
      "Reconstruction: 2126.545166, Regularization: 1.782928\n",
      "2019-04-09 22:41:10,796 root         INFO     Train Epoch: 12 [3584/8000 (45%)]\tTotal Loss: 31538.359375\n",
      "Reconstruction: 31536.996094, Regularization: 1.362509\n",
      "2019-04-09 22:41:10,852 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 1879.340088\n",
      "Reconstruction: 1877.185547, Regularization: 2.154573\n",
      "2019-04-09 22:41:10,908 root         INFO     Train Epoch: 12 [4608/8000 (58%)]\tTotal Loss: 87331.218750\n",
      "Reconstruction: 87329.335938, Regularization: 1.879005\n",
      "2019-04-09 22:41:10,963 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 2760.025635\n",
      "Reconstruction: 2758.372314, Regularization: 1.653403\n",
      "2019-04-09 22:41:11,019 root         INFO     Train Epoch: 12 [5632/8000 (70%)]\tTotal Loss: 381.548035\n",
      "Reconstruction: 379.781250, Regularization: 1.766794\n",
      "2019-04-09 22:41:11,074 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 6269.797852\n",
      "Reconstruction: 6267.189941, Regularization: 2.608097\n",
      "2019-04-09 22:41:11,130 root         INFO     Train Epoch: 12 [6656/8000 (83%)]\tTotal Loss: 1273.909668\n",
      "Reconstruction: 1272.446411, Regularization: 1.463216\n",
      "2019-04-09 22:41:11,185 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 853633.125000\n",
      "Reconstruction: 853630.937500, Regularization: 2.171912\n",
      "2019-04-09 22:41:11,241 root         INFO     Train Epoch: 12 [7680/8000 (96%)]\tTotal Loss: 50005.859375\n",
      "Reconstruction: 50003.628906, Regularization: 2.231179\n",
      "2019-04-09 22:41:11,290 root         INFO     ====> Epoch: 12 Average loss: 7397114.0212\n",
      "2019-04-09 22:41:11,312 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 185.240036\n",
      "Reconstruction: 183.479248, Regularization: 1.760787\n",
      "2019-04-09 22:41:11,369 root         INFO     Train Epoch: 13 [512/8000 (6%)]\tTotal Loss: 64.388542\n",
      "Reconstruction: 63.510120, Regularization: 0.878422\n",
      "2019-04-09 22:41:11,426 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 40.502399\n",
      "Reconstruction: 38.376011, Regularization: 2.126390\n",
      "2019-04-09 22:41:11,483 root         INFO     Train Epoch: 13 [1536/8000 (19%)]\tTotal Loss: 140.858536\n",
      "Reconstruction: 139.238159, Regularization: 1.620375\n",
      "2019-04-09 22:41:11,539 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 881.795654\n",
      "Reconstruction: 880.301758, Regularization: 1.493927\n",
      "2019-04-09 22:41:11,596 root         INFO     Train Epoch: 13 [2560/8000 (32%)]\tTotal Loss: 3561.547852\n",
      "Reconstruction: 3559.548584, Regularization: 1.999209\n",
      "2019-04-09 22:41:11,652 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 2864.601807\n",
      "Reconstruction: 2863.045166, Regularization: 1.556720\n",
      "2019-04-09 22:41:11,708 root         INFO     Train Epoch: 13 [3584/8000 (45%)]\tTotal Loss: 25247.285156\n",
      "Reconstruction: 25245.900391, Regularization: 1.384702\n",
      "2019-04-09 22:41:11,764 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 106.155441\n",
      "Reconstruction: 105.066017, Regularization: 1.089426\n",
      "2019-04-09 22:41:11,820 root         INFO     Train Epoch: 13 [4608/8000 (58%)]\tTotal Loss: 47.274563\n",
      "Reconstruction: 46.102337, Regularization: 1.172227\n",
      "2019-04-09 22:41:11,876 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 5675.195312\n",
      "Reconstruction: 5673.522461, Regularization: 1.672789\n",
      "2019-04-09 22:41:11,932 root         INFO     Train Epoch: 13 [5632/8000 (70%)]\tTotal Loss: 2353.371826\n",
      "Reconstruction: 2351.259277, Regularization: 2.112448\n",
      "2019-04-09 22:41:11,988 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 14271.901367\n",
      "Reconstruction: 14269.953125, Regularization: 1.947827\n",
      "2019-04-09 22:41:12,045 root         INFO     Train Epoch: 13 [6656/8000 (83%)]\tTotal Loss: 15.013973\n",
      "Reconstruction: 14.172514, Regularization: 0.841460\n",
      "2019-04-09 22:41:12,100 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 90.690025\n",
      "Reconstruction: 89.004036, Regularization: 1.685992\n",
      "2019-04-09 22:41:12,154 root         INFO     Train Epoch: 13 [7680/8000 (96%)]\tTotal Loss: 2497260.750000\n",
      "Reconstruction: 2497258.250000, Regularization: 2.445583\n",
      "2019-04-09 22:41:12,203 root         INFO     ====> Epoch: 13 Average loss: 493487.8393\n",
      "2019-04-09 22:41:12,226 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 97273.421875\n",
      "Reconstruction: 97271.820312, Regularization: 1.597799\n",
      "2019-04-09 22:41:12,283 root         INFO     Train Epoch: 14 [512/8000 (6%)]\tTotal Loss: 1565.006226\n",
      "Reconstruction: 1563.317749, Regularization: 1.688417\n",
      "2019-04-09 22:41:12,338 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 1910.494263\n",
      "Reconstruction: 1908.931396, Regularization: 1.562812\n",
      "2019-04-09 22:41:12,392 root         INFO     Train Epoch: 14 [1536/8000 (19%)]\tTotal Loss: 3382.634521\n",
      "Reconstruction: 3381.153564, Regularization: 1.480896\n",
      "2019-04-09 22:41:12,448 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 1102.963257\n",
      "Reconstruction: 1101.746094, Regularization: 1.217197\n",
      "2019-04-09 22:41:12,504 root         INFO     Train Epoch: 14 [2560/8000 (32%)]\tTotal Loss: 7237.269531\n",
      "Reconstruction: 7236.047363, Regularization: 1.222364\n",
      "2019-04-09 22:41:12,559 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 345.124359\n",
      "Reconstruction: 344.181641, Regularization: 0.942724\n",
      "2019-04-09 22:41:12,613 root         INFO     Train Epoch: 14 [3584/8000 (45%)]\tTotal Loss: 130.974731\n",
      "Reconstruction: 129.728500, Regularization: 1.246225\n",
      "2019-04-09 22:41:12,669 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 2291.870605\n",
      "Reconstruction: 2289.608398, Regularization: 2.262262\n",
      "2019-04-09 22:41:12,724 root         INFO     Train Epoch: 14 [4608/8000 (58%)]\tTotal Loss: 95.886856\n",
      "Reconstruction: 94.648239, Regularization: 1.238620\n",
      "2019-04-09 22:41:12,780 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 754882.250000\n",
      "Reconstruction: 754880.250000, Regularization: 1.998620\n",
      "2019-04-09 22:41:12,834 root         INFO     Train Epoch: 14 [5632/8000 (70%)]\tTotal Loss: 3182.585449\n",
      "Reconstruction: 3181.002686, Regularization: 1.582767\n",
      "2019-04-09 22:41:12,890 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 202576.484375\n",
      "Reconstruction: 202574.968750, Regularization: 1.511372\n",
      "2019-04-09 22:41:12,946 root         INFO     Train Epoch: 14 [6656/8000 (83%)]\tTotal Loss: 874.715942\n",
      "Reconstruction: 873.387207, Regularization: 1.328740\n",
      "2019-04-09 22:41:13,001 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 19272.892578\n",
      "Reconstruction: 19270.826172, Regularization: 2.067140\n",
      "2019-04-09 22:41:13,057 root         INFO     Train Epoch: 14 [7680/8000 (96%)]\tTotal Loss: 452.761627\n",
      "Reconstruction: 451.052429, Regularization: 1.709201\n",
      "2019-04-09 22:41:13,106 root         INFO     ====> Epoch: 14 Average loss: 1181307.1299\n",
      "2019-04-09 22:41:13,129 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 2758.264648\n",
      "Reconstruction: 2757.012451, Regularization: 1.252078\n",
      "2019-04-09 22:41:13,184 root         INFO     Train Epoch: 15 [512/8000 (6%)]\tTotal Loss: 10478.976562\n",
      "Reconstruction: 10477.183594, Regularization: 1.793195\n",
      "2019-04-09 22:41:13,239 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 69525.742188\n",
      "Reconstruction: 69523.562500, Regularization: 2.178938\n",
      "2019-04-09 22:41:13,294 root         INFO     Train Epoch: 15 [1536/8000 (19%)]\tTotal Loss: 390.453247\n",
      "Reconstruction: 388.086487, Regularization: 2.366760\n",
      "2019-04-09 22:41:13,348 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 105.675446\n",
      "Reconstruction: 104.236618, Regularization: 1.438830\n",
      "2019-04-09 22:41:13,401 root         INFO     Train Epoch: 15 [2560/8000 (32%)]\tTotal Loss: 7696.929688\n",
      "Reconstruction: 7695.341797, Regularization: 1.587707\n",
      "2019-04-09 22:41:13,456 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 10046.975586\n",
      "Reconstruction: 10045.058594, Regularization: 1.917030\n",
      "2019-04-09 22:41:13,510 root         INFO     Train Epoch: 15 [3584/8000 (45%)]\tTotal Loss: 9032.869141\n",
      "Reconstruction: 9031.155273, Regularization: 1.714229\n",
      "2019-04-09 22:41:13,564 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 853.403564\n",
      "Reconstruction: 851.857422, Regularization: 1.546126\n",
      "2019-04-09 22:41:13,618 root         INFO     Train Epoch: 15 [4608/8000 (58%)]\tTotal Loss: 3017.640869\n",
      "Reconstruction: 3016.291504, Regularization: 1.349331\n",
      "2019-04-09 22:41:13,672 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 632.226868\n",
      "Reconstruction: 631.095825, Regularization: 1.131060\n",
      "2019-04-09 22:41:13,726 root         INFO     Train Epoch: 15 [5632/8000 (70%)]\tTotal Loss: 2032.567993\n",
      "Reconstruction: 2030.981201, Regularization: 1.586752\n",
      "2019-04-09 22:41:13,781 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 186086.953125\n",
      "Reconstruction: 186084.921875, Regularization: 2.024929\n",
      "2019-04-09 22:41:13,835 root         INFO     Train Epoch: 15 [6656/8000 (83%)]\tTotal Loss: 752.538696\n",
      "Reconstruction: 751.220703, Regularization: 1.317988\n",
      "2019-04-09 22:41:13,889 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 156.123230\n",
      "Reconstruction: 154.710159, Regularization: 1.413072\n",
      "2019-04-09 22:41:13,943 root         INFO     Train Epoch: 15 [7680/8000 (96%)]\tTotal Loss: 21405.630859\n",
      "Reconstruction: 21403.753906, Regularization: 1.876711\n",
      "2019-04-09 22:41:13,993 root         INFO     ====> Epoch: 15 Average loss: 379160.6242\n",
      "2019-04-09 22:41:14,016 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 18365.148438\n",
      "Reconstruction: 18363.369141, Regularization: 1.779266\n",
      "2019-04-09 22:41:14,072 root         INFO     Train Epoch: 16 [512/8000 (6%)]\tTotal Loss: 1223832960.000000\n",
      "Reconstruction: 1223832960.000000, Regularization: 2.816447\n",
      "2019-04-09 22:41:14,128 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 4219051.000000\n",
      "Reconstruction: 4219049.000000, Regularization: 2.098565\n",
      "2019-04-09 22:41:14,184 root         INFO     Train Epoch: 16 [1536/8000 (19%)]\tTotal Loss: 22.015768\n",
      "Reconstruction: 20.089907, Regularization: 1.925862\n",
      "2019-04-09 22:41:14,240 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 804.553833\n",
      "Reconstruction: 802.973633, Regularization: 1.580226\n",
      "2019-04-09 22:41:14,296 root         INFO     Train Epoch: 16 [2560/8000 (32%)]\tTotal Loss: 6467.020508\n",
      "Reconstruction: 6465.360352, Regularization: 1.660069\n",
      "2019-04-09 22:41:14,351 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 27978.410156\n",
      "Reconstruction: 27976.412109, Regularization: 1.997346\n",
      "2019-04-09 22:41:14,407 root         INFO     Train Epoch: 16 [3584/8000 (45%)]\tTotal Loss: 11787.065430\n",
      "Reconstruction: 11785.876953, Regularization: 1.188241\n",
      "2019-04-09 22:41:14,463 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 16006.452148\n",
      "Reconstruction: 16004.533203, Regularization: 1.919016\n",
      "2019-04-09 22:41:14,519 root         INFO     Train Epoch: 16 [4608/8000 (58%)]\tTotal Loss: 3339763.500000\n",
      "Reconstruction: 3339761.500000, Regularization: 1.967530\n",
      "2019-04-09 22:41:14,575 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 4027381.500000\n",
      "Reconstruction: 4027379.500000, Regularization: 1.929713\n",
      "2019-04-09 22:41:14,631 root         INFO     Train Epoch: 16 [5632/8000 (70%)]\tTotal Loss: 3.837323\n",
      "Reconstruction: 1.764414, Regularization: 2.072908\n",
      "2019-04-09 22:41:14,687 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 513.763123\n",
      "Reconstruction: 512.211975, Regularization: 1.551172\n",
      "2019-04-09 22:41:14,743 root         INFO     Train Epoch: 16 [6656/8000 (83%)]\tTotal Loss: 61633.347656\n",
      "Reconstruction: 61630.328125, Regularization: 3.018213\n",
      "2019-04-09 22:41:14,799 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 39010.050781\n",
      "Reconstruction: 39008.875000, Regularization: 1.176198\n",
      "2019-04-09 22:41:14,855 root         INFO     Train Epoch: 16 [7680/8000 (96%)]\tTotal Loss: 3566.000244\n",
      "Reconstruction: 3564.515381, Regularization: 1.484863\n",
      "2019-04-09 22:41:14,904 root         INFO     ====> Epoch: 16 Average loss: 5960575.5492\n",
      "2019-04-09 22:41:14,927 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 61851868.000000\n",
      "Reconstruction: 61851864.000000, Regularization: 2.571515\n",
      "2019-04-09 22:41:14,984 root         INFO     Train Epoch: 17 [512/8000 (6%)]\tTotal Loss: 13213.149414\n",
      "Reconstruction: 13211.160156, Regularization: 1.989013\n",
      "2019-04-09 22:41:15,040 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 74704.617188\n",
      "Reconstruction: 74702.601562, Regularization: 2.019264\n",
      "2019-04-09 22:41:15,096 root         INFO     Train Epoch: 17 [1536/8000 (19%)]\tTotal Loss: 1179.023315\n",
      "Reconstruction: 1176.509277, Regularization: 2.514048\n",
      "2019-04-09 22:41:15,151 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 273181.093750\n",
      "Reconstruction: 273179.125000, Regularization: 1.970913\n",
      "2019-04-09 22:41:15,207 root         INFO     Train Epoch: 17 [2560/8000 (32%)]\tTotal Loss: 3.744343\n",
      "Reconstruction: 2.216419, Regularization: 1.527923\n",
      "2019-04-09 22:41:15,263 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 1507.724121\n",
      "Reconstruction: 1505.935913, Regularization: 1.788247\n",
      "2019-04-09 22:41:15,319 root         INFO     Train Epoch: 17 [3584/8000 (45%)]\tTotal Loss: 706345.125000\n",
      "Reconstruction: 706343.937500, Regularization: 1.207065\n",
      "2019-04-09 22:41:15,375 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 490058.531250\n",
      "Reconstruction: 490056.781250, Regularization: 1.741905\n",
      "2019-04-09 22:41:15,431 root         INFO     Train Epoch: 17 [4608/8000 (58%)]\tTotal Loss: 3185.212158\n",
      "Reconstruction: 3183.419434, Regularization: 1.792729\n",
      "2019-04-09 22:41:15,486 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 65.824974\n",
      "Reconstruction: 64.153809, Regularization: 1.671165\n",
      "2019-04-09 22:41:15,542 root         INFO     Train Epoch: 17 [5632/8000 (70%)]\tTotal Loss: 17529.623047\n",
      "Reconstruction: 17527.744141, Regularization: 1.878881\n",
      "2019-04-09 22:41:15,598 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 4825.829590\n",
      "Reconstruction: 4824.036133, Regularization: 1.793635\n",
      "2019-04-09 22:41:15,654 root         INFO     Train Epoch: 17 [6656/8000 (83%)]\tTotal Loss: 43.680157\n",
      "Reconstruction: 42.416634, Regularization: 1.263523\n",
      "2019-04-09 22:41:15,710 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 3483.440430\n",
      "Reconstruction: 3481.278076, Regularization: 2.162362\n",
      "2019-04-09 22:41:15,766 root         INFO     Train Epoch: 17 [7680/8000 (96%)]\tTotal Loss: 13989.614258\n",
      "Reconstruction: 13988.098633, Regularization: 1.516081\n",
      "2019-04-09 22:41:15,816 root         INFO     ====> Epoch: 17 Average loss: 682023.3079\n",
      "2019-04-09 22:41:15,839 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 179.596954\n",
      "Reconstruction: 178.169800, Regularization: 1.427153\n",
      "2019-04-09 22:41:15,895 root         INFO     Train Epoch: 18 [512/8000 (6%)]\tTotal Loss: 17286.136719\n",
      "Reconstruction: 17283.783203, Regularization: 2.354114\n",
      "2019-04-09 22:41:15,951 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 2467.987305\n",
      "Reconstruction: 2466.710693, Regularization: 1.276555\n",
      "2019-04-09 22:41:16,007 root         INFO     Train Epoch: 18 [1536/8000 (19%)]\tTotal Loss: 1248.333252\n",
      "Reconstruction: 1247.032837, Regularization: 1.300454\n",
      "2019-04-09 22:41:16,062 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 790.834412\n",
      "Reconstruction: 789.186340, Regularization: 1.648046\n",
      "2019-04-09 22:41:16,117 root         INFO     Train Epoch: 18 [2560/8000 (32%)]\tTotal Loss: 12654.041992\n",
      "Reconstruction: 12652.079102, Regularization: 1.962456\n",
      "2019-04-09 22:41:16,173 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 20106.828125\n",
      "Reconstruction: 20105.392578, Regularization: 1.434627\n",
      "2019-04-09 22:41:16,228 root         INFO     Train Epoch: 18 [3584/8000 (45%)]\tTotal Loss: 974.043152\n",
      "Reconstruction: 973.164246, Regularization: 0.878928\n",
      "2019-04-09 22:41:16,284 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 200.982025\n",
      "Reconstruction: 199.364059, Regularization: 1.617961\n",
      "2019-04-09 22:41:16,339 root         INFO     Train Epoch: 18 [4608/8000 (58%)]\tTotal Loss: 86.611252\n",
      "Reconstruction: 84.966370, Regularization: 1.644884\n",
      "2019-04-09 22:41:16,394 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 42770.550781\n",
      "Reconstruction: 42768.675781, Regularization: 1.876677\n",
      "2019-04-09 22:41:16,450 root         INFO     Train Epoch: 18 [5632/8000 (70%)]\tTotal Loss: 209107.750000\n",
      "Reconstruction: 209105.765625, Regularization: 1.984952\n",
      "2019-04-09 22:41:16,505 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 355005.812500\n",
      "Reconstruction: 355003.625000, Regularization: 2.182534\n",
      "2019-04-09 22:41:16,560 root         INFO     Train Epoch: 18 [6656/8000 (83%)]\tTotal Loss: 27.935762\n",
      "Reconstruction: 26.924673, Regularization: 1.011089\n",
      "2019-04-09 22:41:16,616 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 49.386024\n",
      "Reconstruction: 48.507599, Regularization: 0.878428\n",
      "2019-04-09 22:41:16,671 root         INFO     Train Epoch: 18 [7680/8000 (96%)]\tTotal Loss: 485021.281250\n",
      "Reconstruction: 485019.218750, Regularization: 2.051321\n",
      "2019-04-09 22:41:16,720 root         INFO     ====> Epoch: 18 Average loss: 322745.9956\n",
      "2019-04-09 22:41:16,743 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 9350.018555\n",
      "Reconstruction: 9348.497070, Regularization: 1.521516\n",
      "2019-04-09 22:41:16,799 root         INFO     Train Epoch: 19 [512/8000 (6%)]\tTotal Loss: 290.416412\n",
      "Reconstruction: 288.579102, Regularization: 1.837317\n",
      "2019-04-09 22:41:16,855 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 239.383118\n",
      "Reconstruction: 237.768280, Regularization: 1.614841\n",
      "2019-04-09 22:41:16,911 root         INFO     Train Epoch: 19 [1536/8000 (19%)]\tTotal Loss: 26.570120\n",
      "Reconstruction: 25.242025, Regularization: 1.328094\n",
      "2019-04-09 22:41:16,966 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 350.420563\n",
      "Reconstruction: 348.403137, Regularization: 2.017427\n",
      "2019-04-09 22:41:17,022 root         INFO     Train Epoch: 19 [2560/8000 (32%)]\tTotal Loss: 593.097168\n",
      "Reconstruction: 590.866699, Regularization: 2.230478\n",
      "2019-04-09 22:41:17,077 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 19.437975\n",
      "Reconstruction: 18.561378, Regularization: 0.876596\n",
      "2019-04-09 22:41:17,133 root         INFO     Train Epoch: 19 [3584/8000 (45%)]\tTotal Loss: 38.703377\n",
      "Reconstruction: 36.915787, Regularization: 1.787590\n",
      "2019-04-09 22:41:17,189 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 146.785629\n",
      "Reconstruction: 145.474991, Regularization: 1.310632\n",
      "2019-04-09 22:41:17,244 root         INFO     Train Epoch: 19 [4608/8000 (58%)]\tTotal Loss: 322.428497\n",
      "Reconstruction: 320.058441, Regularization: 2.370058\n",
      "2019-04-09 22:41:17,299 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 1865.314697\n",
      "Reconstruction: 1864.086304, Regularization: 1.228342\n",
      "2019-04-09 22:41:17,355 root         INFO     Train Epoch: 19 [5632/8000 (70%)]\tTotal Loss: 2555.022949\n",
      "Reconstruction: 2553.184326, Regularization: 1.838696\n",
      "2019-04-09 22:41:17,410 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 105.664352\n",
      "Reconstruction: 104.111320, Regularization: 1.553030\n",
      "2019-04-09 22:41:17,466 root         INFO     Train Epoch: 19 [6656/8000 (83%)]\tTotal Loss: 571.591248\n",
      "Reconstruction: 570.494202, Regularization: 1.097046\n",
      "2019-04-09 22:41:17,521 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 46475.746094\n",
      "Reconstruction: 46473.484375, Regularization: 2.262145\n",
      "2019-04-09 22:41:17,577 root         INFO     Train Epoch: 19 [7680/8000 (96%)]\tTotal Loss: 59113.593750\n",
      "Reconstruction: 59111.261719, Regularization: 2.333916\n",
      "2019-04-09 22:41:17,626 root         INFO     ====> Epoch: 19 Average loss: 1507555.2121\n",
      "2019-04-09 22:41:17,649 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 320.225861\n",
      "Reconstruction: 318.360870, Regularization: 1.864994\n",
      "2019-04-09 22:41:17,705 root         INFO     Train Epoch: 20 [512/8000 (6%)]\tTotal Loss: 21742.351562\n",
      "Reconstruction: 21739.806641, Regularization: 2.544079\n",
      "2019-04-09 22:41:17,760 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 34816.207031\n",
      "Reconstruction: 34814.960938, Regularization: 1.247476\n",
      "2019-04-09 22:41:17,817 root         INFO     Train Epoch: 20 [1536/8000 (19%)]\tTotal Loss: 373835.625000\n",
      "Reconstruction: 373833.656250, Regularization: 1.970172\n",
      "2019-04-09 22:41:17,871 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 11102.958984\n",
      "Reconstruction: 11100.613281, Regularization: 2.345612\n",
      "2019-04-09 22:41:17,927 root         INFO     Train Epoch: 20 [2560/8000 (32%)]\tTotal Loss: 3381.484619\n",
      "Reconstruction: 3380.031738, Regularization: 1.452960\n",
      "2019-04-09 22:41:17,982 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 15.411762\n",
      "Reconstruction: 13.637566, Regularization: 1.774197\n",
      "2019-04-09 22:41:18,038 root         INFO     Train Epoch: 20 [3584/8000 (45%)]\tTotal Loss: 522.538818\n",
      "Reconstruction: 520.892334, Regularization: 1.646492\n",
      "2019-04-09 22:41:18,093 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 304.828430\n",
      "Reconstruction: 302.945007, Regularization: 1.883437\n",
      "2019-04-09 22:41:18,148 root         INFO     Train Epoch: 20 [4608/8000 (58%)]\tTotal Loss: 12887.736328\n",
      "Reconstruction: 12886.353516, Regularization: 1.382429\n",
      "2019-04-09 22:41:18,203 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 4120.045898\n",
      "Reconstruction: 4117.729980, Regularization: 2.315723\n",
      "2019-04-09 22:41:18,258 root         INFO     Train Epoch: 20 [5632/8000 (70%)]\tTotal Loss: 4887.764648\n",
      "Reconstruction: 4886.338867, Regularization: 1.425726\n",
      "2019-04-09 22:41:18,313 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 85569.398438\n",
      "Reconstruction: 85566.859375, Regularization: 2.535473\n",
      "2019-04-09 22:41:18,368 root         INFO     Train Epoch: 20 [6656/8000 (83%)]\tTotal Loss: 41222.976562\n",
      "Reconstruction: 41221.371094, Regularization: 1.605101\n",
      "2019-04-09 22:41:18,423 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 147.817368\n",
      "Reconstruction: 146.079163, Regularization: 1.738211\n",
      "2019-04-09 22:41:18,478 root         INFO     Train Epoch: 20 [7680/8000 (96%)]\tTotal Loss: 1579.767944\n",
      "Reconstruction: 1578.155884, Regularization: 1.612033\n",
      "2019-04-09 22:41:18,527 root         INFO     ====> Epoch: 20 Average loss: 934653.8040\n",
      "2019-04-09 22:41:18,550 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 109.858261\n",
      "Reconstruction: 108.685028, Regularization: 1.173233\n",
      "2019-04-09 22:41:18,607 root         INFO     Train Epoch: 21 [512/8000 (6%)]\tTotal Loss: 1666.381714\n",
      "Reconstruction: 1664.433228, Regularization: 1.948516\n",
      "2019-04-09 22:41:18,663 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 8181.796387\n",
      "Reconstruction: 8179.848145, Regularization: 1.948443\n",
      "2019-04-09 22:41:18,719 root         INFO     Train Epoch: 21 [1536/8000 (19%)]\tTotal Loss: 21946.728516\n",
      "Reconstruction: 21944.478516, Regularization: 2.250923\n",
      "2019-04-09 22:41:18,774 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 385.535889\n",
      "Reconstruction: 384.358582, Regularization: 1.177313\n",
      "2019-04-09 22:41:18,830 root         INFO     Train Epoch: 21 [2560/8000 (32%)]\tTotal Loss: 194.926331\n",
      "Reconstruction: 193.667038, Regularization: 1.259288\n",
      "2019-04-09 22:41:18,885 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 11592.804688\n",
      "Reconstruction: 11591.455078, Regularization: 1.349763\n",
      "2019-04-09 22:41:18,941 root         INFO     Train Epoch: 21 [3584/8000 (45%)]\tTotal Loss: 22612.187500\n",
      "Reconstruction: 22610.435547, Regularization: 1.751844\n",
      "2019-04-09 22:41:18,996 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 562612.250000\n",
      "Reconstruction: 562610.062500, Regularization: 2.163702\n",
      "2019-04-09 22:41:19,050 root         INFO     Train Epoch: 21 [4608/8000 (58%)]\tTotal Loss: 1363.353149\n",
      "Reconstruction: 1361.441895, Regularization: 1.911278\n",
      "2019-04-09 22:41:19,104 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 10.742087\n",
      "Reconstruction: 9.144790, Regularization: 1.597298\n",
      "2019-04-09 22:41:19,158 root         INFO     Train Epoch: 21 [5632/8000 (70%)]\tTotal Loss: 13.753851\n",
      "Reconstruction: 12.974010, Regularization: 0.779841\n",
      "2019-04-09 22:41:19,212 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 1195.196655\n",
      "Reconstruction: 1193.376709, Regularization: 1.819962\n",
      "2019-04-09 22:41:19,267 root         INFO     Train Epoch: 21 [6656/8000 (83%)]\tTotal Loss: 6575.030762\n",
      "Reconstruction: 6573.424805, Regularization: 1.605949\n",
      "2019-04-09 22:41:19,321 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 1313.851807\n",
      "Reconstruction: 1312.645508, Regularization: 1.206325\n",
      "2019-04-09 22:41:19,375 root         INFO     Train Epoch: 21 [7680/8000 (96%)]\tTotal Loss: 260.594849\n",
      "Reconstruction: 258.757446, Regularization: 1.837409\n",
      "2019-04-09 22:41:19,424 root         INFO     ====> Epoch: 21 Average loss: 877405.7405\n",
      "2019-04-09 22:41:19,447 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 11100.254883\n",
      "Reconstruction: 11099.106445, Regularization: 1.148845\n",
      "2019-04-09 22:41:19,503 root         INFO     Train Epoch: 22 [512/8000 (6%)]\tTotal Loss: 10693.073242\n",
      "Reconstruction: 10691.369141, Regularization: 1.704224\n",
      "2019-04-09 22:41:19,557 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 61.296654\n",
      "Reconstruction: 59.648529, Regularization: 1.648124\n",
      "2019-04-09 22:41:19,612 root         INFO     Train Epoch: 22 [1536/8000 (19%)]\tTotal Loss: 2275.676514\n",
      "Reconstruction: 2273.960449, Regularization: 1.716053\n",
      "2019-04-09 22:41:19,667 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 1833.549194\n",
      "Reconstruction: 1831.852905, Regularization: 1.696254\n",
      "2019-04-09 22:41:19,722 root         INFO     Train Epoch: 22 [2560/8000 (32%)]\tTotal Loss: 343.943939\n",
      "Reconstruction: 342.037903, Regularization: 1.906037\n",
      "2019-04-09 22:41:19,777 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 5117797.000000\n",
      "Reconstruction: 5117795.500000, Regularization: 1.508485\n",
      "2019-04-09 22:41:19,832 root         INFO     Train Epoch: 22 [3584/8000 (45%)]\tTotal Loss: 475.191315\n",
      "Reconstruction: 473.699524, Regularization: 1.491787\n",
      "2019-04-09 22:41:19,887 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 738.371094\n",
      "Reconstruction: 736.868225, Regularization: 1.502896\n",
      "2019-04-09 22:41:19,942 root         INFO     Train Epoch: 22 [4608/8000 (58%)]\tTotal Loss: 3.381021\n",
      "Reconstruction: 2.435116, Regularization: 0.945905\n",
      "2019-04-09 22:41:19,997 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 1375.194458\n",
      "Reconstruction: 1373.617432, Regularization: 1.577029\n",
      "2019-04-09 22:41:20,051 root         INFO     Train Epoch: 22 [5632/8000 (70%)]\tTotal Loss: 227.170303\n",
      "Reconstruction: 224.251389, Regularization: 2.918919\n",
      "2019-04-09 22:41:20,107 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 67581.023438\n",
      "Reconstruction: 67579.500000, Regularization: 1.523480\n",
      "2019-04-09 22:41:20,161 root         INFO     Train Epoch: 22 [6656/8000 (83%)]\tTotal Loss: 7716.242676\n",
      "Reconstruction: 7714.595703, Regularization: 1.646814\n",
      "2019-04-09 22:41:20,216 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 14.448912\n",
      "Reconstruction: 13.552320, Regularization: 0.896592\n",
      "2019-04-09 22:41:20,271 root         INFO     Train Epoch: 22 [7680/8000 (96%)]\tTotal Loss: 3929.629883\n",
      "Reconstruction: 3927.733887, Regularization: 1.895896\n",
      "2019-04-09 22:41:20,320 root         INFO     ====> Epoch: 22 Average loss: 2392909.0538\n",
      "2019-04-09 22:41:20,343 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 9.382399\n",
      "Reconstruction: 7.419444, Regularization: 1.962955\n",
      "2019-04-09 22:41:20,400 root         INFO     Train Epoch: 23 [512/8000 (6%)]\tTotal Loss: 13761.958984\n",
      "Reconstruction: 13759.891602, Regularization: 2.067017\n",
      "2019-04-09 22:41:20,456 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 697.056763\n",
      "Reconstruction: 695.386841, Regularization: 1.669893\n",
      "2019-04-09 22:41:20,513 root         INFO     Train Epoch: 23 [1536/8000 (19%)]\tTotal Loss: 31.123564\n",
      "Reconstruction: 29.973827, Regularization: 1.149737\n",
      "2019-04-09 22:41:20,569 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 1023.766907\n",
      "Reconstruction: 1021.744507, Regularization: 2.022375\n",
      "2019-04-09 22:41:20,625 root         INFO     Train Epoch: 23 [2560/8000 (32%)]\tTotal Loss: 218454.421875\n",
      "Reconstruction: 218452.281250, Regularization: 2.139082\n",
      "2019-04-09 22:41:20,681 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 7501.595215\n",
      "Reconstruction: 7499.757324, Regularization: 1.837986\n",
      "2019-04-09 22:41:20,737 root         INFO     Train Epoch: 23 [3584/8000 (45%)]\tTotal Loss: 2220.570557\n",
      "Reconstruction: 2218.770752, Regularization: 1.799716\n",
      "2019-04-09 22:41:20,793 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 2806.803955\n",
      "Reconstruction: 2805.492676, Regularization: 1.311288\n",
      "2019-04-09 22:41:20,848 root         INFO     Train Epoch: 23 [4608/8000 (58%)]\tTotal Loss: 7254.739746\n",
      "Reconstruction: 7253.565430, Regularization: 1.174269\n",
      "2019-04-09 22:41:20,903 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 354.086639\n",
      "Reconstruction: 352.292969, Regularization: 1.793684\n",
      "2019-04-09 22:41:20,958 root         INFO     Train Epoch: 23 [5632/8000 (70%)]\tTotal Loss: 5083.551758\n",
      "Reconstruction: 5082.270996, Regularization: 1.280886\n",
      "2019-04-09 22:41:21,013 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 1487.151123\n",
      "Reconstruction: 1485.280273, Regularization: 1.870838\n",
      "2019-04-09 22:41:21,068 root         INFO     Train Epoch: 23 [6656/8000 (83%)]\tTotal Loss: 8557.853516\n",
      "Reconstruction: 8556.253906, Regularization: 1.599920\n",
      "2019-04-09 22:41:21,122 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 5509.301270\n",
      "Reconstruction: 5506.979004, Regularization: 2.322434\n",
      "2019-04-09 22:41:21,176 root         INFO     Train Epoch: 23 [7680/8000 (96%)]\tTotal Loss: 379.870026\n",
      "Reconstruction: 378.611267, Regularization: 1.258758\n",
      "2019-04-09 22:41:21,225 root         INFO     ====> Epoch: 23 Average loss: 1317734.0305\n",
      "2019-04-09 22:41:21,249 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 49.475948\n",
      "Reconstruction: 47.128651, Regularization: 2.347297\n",
      "2019-04-09 22:41:21,305 root         INFO     Train Epoch: 24 [512/8000 (6%)]\tTotal Loss: 3670.574951\n",
      "Reconstruction: 3668.292236, Regularization: 2.282710\n",
      "2019-04-09 22:41:21,360 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 133.140869\n",
      "Reconstruction: 131.534103, Regularization: 1.606761\n",
      "2019-04-09 22:41:21,416 root         INFO     Train Epoch: 24 [1536/8000 (19%)]\tTotal Loss: 279.794525\n",
      "Reconstruction: 277.105011, Regularization: 2.689514\n",
      "2019-04-09 22:41:21,471 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 194.442917\n",
      "Reconstruction: 192.485275, Regularization: 1.957642\n",
      "2019-04-09 22:41:21,526 root         INFO     Train Epoch: 24 [2560/8000 (32%)]\tTotal Loss: 6040.140625\n",
      "Reconstruction: 6038.646484, Regularization: 1.494354\n",
      "2019-04-09 22:41:21,581 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 126.033028\n",
      "Reconstruction: 124.806129, Regularization: 1.226897\n",
      "2019-04-09 22:41:21,636 root         INFO     Train Epoch: 24 [3584/8000 (45%)]\tTotal Loss: 8638.997070\n",
      "Reconstruction: 8637.411133, Regularization: 1.585988\n",
      "2019-04-09 22:41:21,690 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 2164.703369\n",
      "Reconstruction: 2163.063965, Regularization: 1.639283\n",
      "2019-04-09 22:41:21,744 root         INFO     Train Epoch: 24 [4608/8000 (58%)]\tTotal Loss: 25.991505\n",
      "Reconstruction: 24.480587, Regularization: 1.510917\n",
      "2019-04-09 22:41:21,799 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 944.324951\n",
      "Reconstruction: 942.354614, Regularization: 1.970326\n",
      "2019-04-09 22:41:21,853 root         INFO     Train Epoch: 24 [5632/8000 (70%)]\tTotal Loss: 10095.200195\n",
      "Reconstruction: 10093.639648, Regularization: 1.560063\n",
      "2019-04-09 22:41:21,907 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 265.001678\n",
      "Reconstruction: 263.439728, Regularization: 1.561939\n",
      "2019-04-09 22:41:21,962 root         INFO     Train Epoch: 24 [6656/8000 (83%)]\tTotal Loss: 910.200317\n",
      "Reconstruction: 907.999878, Regularization: 2.200446\n",
      "2019-04-09 22:41:22,016 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 12849.481445\n",
      "Reconstruction: 12847.501953, Regularization: 1.979042\n",
      "2019-04-09 22:41:22,070 root         INFO     Train Epoch: 24 [7680/8000 (96%)]\tTotal Loss: 101352.453125\n",
      "Reconstruction: 101350.664062, Regularization: 1.786457\n",
      "2019-04-09 22:41:22,119 root         INFO     ====> Epoch: 24 Average loss: 357517.2236\n",
      "2019-04-09 22:41:22,143 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 137.133530\n",
      "Reconstruction: 135.328369, Regularization: 1.805156\n",
      "2019-04-09 22:41:22,200 root         INFO     Train Epoch: 25 [512/8000 (6%)]\tTotal Loss: 15.768511\n",
      "Reconstruction: 14.512142, Regularization: 1.256368\n",
      "2019-04-09 22:41:22,257 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 1689.755859\n",
      "Reconstruction: 1688.351318, Regularization: 1.404582\n",
      "2019-04-09 22:41:22,313 root         INFO     Train Epoch: 25 [1536/8000 (19%)]\tTotal Loss: 551.047180\n",
      "Reconstruction: 549.461792, Regularization: 1.585388\n",
      "2019-04-09 22:41:22,371 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 55074.894531\n",
      "Reconstruction: 55073.335938, Regularization: 1.557250\n",
      "2019-04-09 22:41:22,427 root         INFO     Train Epoch: 25 [2560/8000 (32%)]\tTotal Loss: 46.574062\n",
      "Reconstruction: 45.758987, Regularization: 0.815075\n",
      "2019-04-09 22:41:22,484 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 36.660019\n",
      "Reconstruction: 34.102264, Regularization: 2.557753\n",
      "2019-04-09 22:41:22,544 root         INFO     Train Epoch: 25 [3584/8000 (45%)]\tTotal Loss: 4.271175\n",
      "Reconstruction: 2.429293, Regularization: 1.841883\n",
      "2019-04-09 22:41:22,599 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 1767752.375000\n",
      "Reconstruction: 1767750.250000, Regularization: 2.134749\n",
      "2019-04-09 22:41:22,655 root         INFO     Train Epoch: 25 [4608/8000 (58%)]\tTotal Loss: 228.653992\n",
      "Reconstruction: 227.564529, Regularization: 1.089461\n",
      "2019-04-09 22:41:22,711 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 121.371117\n",
      "Reconstruction: 119.408714, Regularization: 1.962405\n",
      "2019-04-09 22:41:22,767 root         INFO     Train Epoch: 25 [5632/8000 (70%)]\tTotal Loss: 4.845899\n",
      "Reconstruction: 3.075007, Regularization: 1.770892\n",
      "2019-04-09 22:41:22,823 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 35763.351562\n",
      "Reconstruction: 35761.667969, Regularization: 1.684742\n",
      "2019-04-09 22:41:22,879 root         INFO     Train Epoch: 25 [6656/8000 (83%)]\tTotal Loss: 4587.048828\n",
      "Reconstruction: 4584.650879, Regularization: 2.398081\n",
      "2019-04-09 22:41:22,935 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 4210.275879\n",
      "Reconstruction: 4207.886719, Regularization: 2.389069\n",
      "2019-04-09 22:41:22,991 root         INFO     Train Epoch: 25 [7680/8000 (96%)]\tTotal Loss: 104.687637\n",
      "Reconstruction: 103.285965, Regularization: 1.401669\n",
      "2019-04-09 22:41:23,041 root         INFO     ====> Epoch: 25 Average loss: 338628.1087\n",
      "2019-04-09 22:41:23,064 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 710.062317\n",
      "Reconstruction: 708.437927, Regularization: 1.624408\n",
      "2019-04-09 22:41:23,120 root         INFO     Train Epoch: 26 [512/8000 (6%)]\tTotal Loss: 91292.835938\n",
      "Reconstruction: 91290.734375, Regularization: 2.097837\n",
      "2019-04-09 22:41:23,177 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 6.072416\n",
      "Reconstruction: 4.818858, Regularization: 1.253559\n",
      "2019-04-09 22:41:23,233 root         INFO     Train Epoch: 26 [1536/8000 (19%)]\tTotal Loss: 201.262375\n",
      "Reconstruction: 200.018616, Regularization: 1.243759\n",
      "2019-04-09 22:41:23,289 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 7971.614746\n",
      "Reconstruction: 7970.060547, Regularization: 1.554155\n",
      "2019-04-09 22:41:23,346 root         INFO     Train Epoch: 26 [2560/8000 (32%)]\tTotal Loss: 10793.711914\n",
      "Reconstruction: 10791.616211, Regularization: 2.095582\n",
      "2019-04-09 22:41:23,402 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 19.985880\n",
      "Reconstruction: 17.959986, Regularization: 2.025893\n",
      "2019-04-09 22:41:23,458 root         INFO     Train Epoch: 26 [3584/8000 (45%)]\tTotal Loss: 3509.471680\n",
      "Reconstruction: 3507.593994, Regularization: 1.877736\n",
      "2019-04-09 22:41:23,515 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 173.654678\n",
      "Reconstruction: 172.163956, Regularization: 1.490730\n",
      "2019-04-09 22:41:23,571 root         INFO     Train Epoch: 26 [4608/8000 (58%)]\tTotal Loss: 19.020760\n",
      "Reconstruction: 17.838020, Regularization: 1.182739\n",
      "2019-04-09 22:41:23,627 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 17126.865234\n",
      "Reconstruction: 17125.173828, Regularization: 1.691851\n",
      "2019-04-09 22:41:23,684 root         INFO     Train Epoch: 26 [5632/8000 (70%)]\tTotal Loss: 4352.630371\n",
      "Reconstruction: 4350.464844, Regularization: 2.165458\n",
      "2019-04-09 22:41:23,740 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 3390.099121\n",
      "Reconstruction: 3388.414307, Regularization: 1.684925\n",
      "2019-04-09 22:41:23,797 root         INFO     Train Epoch: 26 [6656/8000 (83%)]\tTotal Loss: 8409.877930\n",
      "Reconstruction: 8407.753906, Regularization: 2.123892\n",
      "2019-04-09 22:41:23,852 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 2021.668945\n",
      "Reconstruction: 2020.247803, Regularization: 1.421098\n",
      "2019-04-09 22:41:23,909 root         INFO     Train Epoch: 26 [7680/8000 (96%)]\tTotal Loss: 30.294931\n",
      "Reconstruction: 28.650898, Regularization: 1.644033\n",
      "2019-04-09 22:41:23,958 root         INFO     ====> Epoch: 26 Average loss: 203572.8730\n",
      "2019-04-09 22:41:23,981 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 1157.471191\n",
      "Reconstruction: 1155.689331, Regularization: 1.781846\n",
      "2019-04-09 22:41:24,038 root         INFO     Train Epoch: 27 [512/8000 (6%)]\tTotal Loss: 722.308472\n",
      "Reconstruction: 720.355713, Regularization: 1.952781\n",
      "2019-04-09 22:41:24,095 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 1542062.500000\n",
      "Reconstruction: 1542060.875000, Regularization: 1.620382\n",
      "2019-04-09 22:41:24,151 root         INFO     Train Epoch: 27 [1536/8000 (19%)]\tTotal Loss: 723.546204\n",
      "Reconstruction: 722.243042, Regularization: 1.303155\n",
      "2019-04-09 22:41:24,207 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 11029.422852\n",
      "Reconstruction: 11028.255859, Regularization: 1.167152\n",
      "2019-04-09 22:41:24,262 root         INFO     Train Epoch: 27 [2560/8000 (32%)]\tTotal Loss: 77.406403\n",
      "Reconstruction: 76.555450, Regularization: 0.850950\n",
      "2019-04-09 22:41:24,316 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 201.158173\n",
      "Reconstruction: 199.194077, Regularization: 1.964096\n",
      "2019-04-09 22:41:24,371 root         INFO     Train Epoch: 27 [3584/8000 (45%)]\tTotal Loss: 171.824677\n",
      "Reconstruction: 170.544678, Regularization: 1.280005\n",
      "2019-04-09 22:41:24,426 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 791.960876\n",
      "Reconstruction: 790.907715, Regularization: 1.053181\n",
      "2019-04-09 22:41:24,481 root         INFO     Train Epoch: 27 [4608/8000 (58%)]\tTotal Loss: 4964.678711\n",
      "Reconstruction: 4963.080566, Regularization: 1.598154\n",
      "2019-04-09 22:41:24,536 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 3722.054932\n",
      "Reconstruction: 3720.013184, Regularization: 2.041776\n",
      "2019-04-09 22:41:24,590 root         INFO     Train Epoch: 27 [5632/8000 (70%)]\tTotal Loss: 394.786713\n",
      "Reconstruction: 392.766235, Regularization: 2.020483\n",
      "2019-04-09 22:41:24,646 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 276.552155\n",
      "Reconstruction: 274.756958, Regularization: 1.795211\n",
      "2019-04-09 22:41:24,703 root         INFO     Train Epoch: 27 [6656/8000 (83%)]\tTotal Loss: 498.866211\n",
      "Reconstruction: 496.652893, Regularization: 2.213317\n",
      "2019-04-09 22:41:24,760 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 57.344746\n",
      "Reconstruction: 55.743847, Regularization: 1.600900\n",
      "2019-04-09 22:41:24,816 root         INFO     Train Epoch: 27 [7680/8000 (96%)]\tTotal Loss: 89855.460938\n",
      "Reconstruction: 89853.343750, Regularization: 2.114525\n",
      "2019-04-09 22:41:24,866 root         INFO     ====> Epoch: 27 Average loss: 909414.8383\n",
      "2019-04-09 22:41:24,889 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 94.109344\n",
      "Reconstruction: 92.836754, Regularization: 1.272592\n",
      "2019-04-09 22:41:24,946 root         INFO     Train Epoch: 28 [512/8000 (6%)]\tTotal Loss: 9.555844\n",
      "Reconstruction: 8.501720, Regularization: 1.054124\n",
      "2019-04-09 22:41:25,003 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 52.787239\n",
      "Reconstruction: 51.815189, Regularization: 0.972049\n",
      "2019-04-09 22:41:25,059 root         INFO     Train Epoch: 28 [1536/8000 (19%)]\tTotal Loss: 63.132946\n",
      "Reconstruction: 61.519852, Regularization: 1.613095\n",
      "2019-04-09 22:41:25,116 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 169.100647\n",
      "Reconstruction: 167.772583, Regularization: 1.328060\n",
      "2019-04-09 22:41:25,172 root         INFO     Train Epoch: 28 [2560/8000 (32%)]\tTotal Loss: 1670.147583\n",
      "Reconstruction: 1668.818604, Regularization: 1.328964\n",
      "2019-04-09 22:41:25,228 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 11802.165039\n",
      "Reconstruction: 11800.124023, Regularization: 2.041130\n",
      "2019-04-09 22:41:25,283 root         INFO     Train Epoch: 28 [3584/8000 (45%)]\tTotal Loss: 78.516861\n",
      "Reconstruction: 77.704102, Regularization: 0.812762\n",
      "2019-04-09 22:41:25,338 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 2066.508301\n",
      "Reconstruction: 2064.637939, Regularization: 1.870299\n",
      "2019-04-09 22:41:25,393 root         INFO     Train Epoch: 28 [4608/8000 (58%)]\tTotal Loss: 544.028076\n",
      "Reconstruction: 542.911621, Regularization: 1.116436\n",
      "2019-04-09 22:41:25,448 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 2772.317627\n",
      "Reconstruction: 2770.426514, Regularization: 1.891161\n",
      "2019-04-09 22:41:25,504 root         INFO     Train Epoch: 28 [5632/8000 (70%)]\tTotal Loss: 25.754141\n",
      "Reconstruction: 23.733158, Regularization: 2.020982\n",
      "2019-04-09 22:41:25,560 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 4807.785156\n",
      "Reconstruction: 4806.479004, Regularization: 1.306375\n",
      "2019-04-09 22:41:25,616 root         INFO     Train Epoch: 28 [6656/8000 (83%)]\tTotal Loss: 14337.953125\n",
      "Reconstruction: 14335.593750, Regularization: 2.359211\n",
      "2019-04-09 22:41:25,672 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 1843.014648\n",
      "Reconstruction: 1841.179199, Regularization: 1.835504\n",
      "2019-04-09 22:41:25,728 root         INFO     Train Epoch: 28 [7680/8000 (96%)]\tTotal Loss: 1205.861816\n",
      "Reconstruction: 1204.617310, Regularization: 1.244493\n",
      "2019-04-09 22:41:25,777 root         INFO     ====> Epoch: 28 Average loss: 444011.7253\n",
      "2019-04-09 22:41:25,801 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 2338.920410\n",
      "Reconstruction: 2337.734619, Regularization: 1.185684\n",
      "2019-04-09 22:41:25,858 root         INFO     Train Epoch: 29 [512/8000 (6%)]\tTotal Loss: 9036394.000000\n",
      "Reconstruction: 9036392.000000, Regularization: 1.699012\n",
      "2019-04-09 22:41:25,914 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 973970.875000\n",
      "Reconstruction: 973969.312500, Regularization: 1.533659\n",
      "2019-04-09 22:41:25,972 root         INFO     Train Epoch: 29 [1536/8000 (19%)]\tTotal Loss: 5087.882812\n",
      "Reconstruction: 5086.645996, Regularization: 1.236840\n",
      "2019-04-09 22:41:26,028 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 335.499084\n",
      "Reconstruction: 333.665070, Regularization: 1.834011\n",
      "2019-04-09 22:41:26,084 root         INFO     Train Epoch: 29 [2560/8000 (32%)]\tTotal Loss: 1136834.875000\n",
      "Reconstruction: 1136833.250000, Regularization: 1.570174\n",
      "2019-04-09 22:41:26,140 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 50.699070\n",
      "Reconstruction: 48.471672, Regularization: 2.227397\n",
      "2019-04-09 22:41:26,197 root         INFO     Train Epoch: 29 [3584/8000 (45%)]\tTotal Loss: 294.157166\n",
      "Reconstruction: 292.167725, Regularization: 1.989434\n",
      "2019-04-09 22:41:26,253 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 10.013996\n",
      "Reconstruction: 8.770041, Regularization: 1.243956\n",
      "2019-04-09 22:41:26,309 root         INFO     Train Epoch: 29 [4608/8000 (58%)]\tTotal Loss: 434.164246\n",
      "Reconstruction: 432.184875, Regularization: 1.979364\n",
      "2019-04-09 22:41:26,365 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 57704.988281\n",
      "Reconstruction: 57703.082031, Regularization: 1.905748\n",
      "2019-04-09 22:41:26,422 root         INFO     Train Epoch: 29 [5632/8000 (70%)]\tTotal Loss: 3576.368896\n",
      "Reconstruction: 3574.492676, Regularization: 1.876128\n",
      "2019-04-09 22:41:26,478 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 2555976.750000\n",
      "Reconstruction: 2555974.250000, Regularization: 2.460973\n",
      "2019-04-09 22:41:26,534 root         INFO     Train Epoch: 29 [6656/8000 (83%)]\tTotal Loss: 440.576447\n",
      "Reconstruction: 438.910919, Regularization: 1.665533\n",
      "2019-04-09 22:41:26,590 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 22.109755\n",
      "Reconstruction: 20.081514, Regularization: 2.028241\n",
      "2019-04-09 22:41:26,646 root         INFO     Train Epoch: 29 [7680/8000 (96%)]\tTotal Loss: 21.087757\n",
      "Reconstruction: 20.287548, Regularization: 0.800210\n",
      "2019-04-09 22:41:26,696 root         INFO     ====> Epoch: 29 Average loss: 803745.6715\n",
      "2019-04-09 22:41:26,719 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 2326.241211\n",
      "Reconstruction: 2324.925049, Regularization: 1.316101\n",
      "2019-04-09 22:41:26,777 root         INFO     Train Epoch: 30 [512/8000 (6%)]\tTotal Loss: 48.236439\n",
      "Reconstruction: 46.773605, Regularization: 1.462835\n",
      "2019-04-09 22:41:26,833 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 6813.148926\n",
      "Reconstruction: 6811.371094, Regularization: 1.777612\n",
      "2019-04-09 22:41:26,887 root         INFO     Train Epoch: 30 [1536/8000 (19%)]\tTotal Loss: 5615.066895\n",
      "Reconstruction: 5612.666504, Regularization: 2.400568\n",
      "2019-04-09 22:41:26,941 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 297.866364\n",
      "Reconstruction: 296.449585, Regularization: 1.416773\n",
      "2019-04-09 22:41:26,995 root         INFO     Train Epoch: 30 [2560/8000 (32%)]\tTotal Loss: 24.129972\n",
      "Reconstruction: 22.498720, Regularization: 1.631253\n",
      "2019-04-09 22:41:27,048 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 27.347832\n",
      "Reconstruction: 26.013470, Regularization: 1.334361\n",
      "2019-04-09 22:41:27,102 root         INFO     Train Epoch: 30 [3584/8000 (45%)]\tTotal Loss: 957.912781\n",
      "Reconstruction: 956.515869, Regularization: 1.396908\n",
      "2019-04-09 22:41:27,156 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 1794.712158\n",
      "Reconstruction: 1793.196777, Regularization: 1.515381\n",
      "2019-04-09 22:41:27,209 root         INFO     Train Epoch: 30 [4608/8000 (58%)]\tTotal Loss: 100.311058\n",
      "Reconstruction: 98.823334, Regularization: 1.487721\n",
      "2019-04-09 22:41:27,262 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 66.632240\n",
      "Reconstruction: 64.791473, Regularization: 1.840769\n",
      "2019-04-09 22:41:27,315 root         INFO     Train Epoch: 30 [5632/8000 (70%)]\tTotal Loss: 652.835327\n",
      "Reconstruction: 651.004028, Regularization: 1.831319\n",
      "2019-04-09 22:41:27,368 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 63.809834\n",
      "Reconstruction: 62.528076, Regularization: 1.281758\n",
      "2019-04-09 22:41:27,421 root         INFO     Train Epoch: 30 [6656/8000 (83%)]\tTotal Loss: 29.314278\n",
      "Reconstruction: 27.123264, Regularization: 2.191013\n",
      "2019-04-09 22:41:27,474 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 8779.567383\n",
      "Reconstruction: 8778.308594, Regularization: 1.258950\n",
      "2019-04-09 22:41:27,527 root         INFO     Train Epoch: 30 [7680/8000 (96%)]\tTotal Loss: 549.959900\n",
      "Reconstruction: 548.890991, Regularization: 1.068879\n",
      "2019-04-09 22:41:27,575 root         INFO     ====> Epoch: 30 Average loss: 283497.6805\n",
      "2019-04-09 22:41:27,598 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 1175881.250000\n",
      "Reconstruction: 1175879.875000, Regularization: 1.401893\n",
      "2019-04-09 22:41:27,655 root         INFO     Train Epoch: 31 [512/8000 (6%)]\tTotal Loss: 570.203369\n",
      "Reconstruction: 569.144714, Regularization: 1.058627\n",
      "2019-04-09 22:41:27,711 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 317.206360\n",
      "Reconstruction: 315.067932, Regularization: 2.138442\n",
      "2019-04-09 22:41:27,767 root         INFO     Train Epoch: 31 [1536/8000 (19%)]\tTotal Loss: 740.854004\n",
      "Reconstruction: 739.579956, Regularization: 1.274032\n",
      "2019-04-09 22:41:27,823 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 11395.995117\n",
      "Reconstruction: 11393.980469, Regularization: 2.014611\n",
      "2019-04-09 22:41:27,879 root         INFO     Train Epoch: 31 [2560/8000 (32%)]\tTotal Loss: 48.958073\n",
      "Reconstruction: 47.777546, Regularization: 1.180525\n",
      "2019-04-09 22:41:27,935 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 447.371826\n",
      "Reconstruction: 445.719055, Regularization: 1.652777\n",
      "2019-04-09 22:41:27,991 root         INFO     Train Epoch: 31 [3584/8000 (45%)]\tTotal Loss: 1043.877686\n",
      "Reconstruction: 1041.635620, Regularization: 2.242110\n",
      "2019-04-09 22:41:28,047 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 3585.974121\n",
      "Reconstruction: 3583.843750, Regularization: 2.130425\n",
      "2019-04-09 22:41:28,104 root         INFO     Train Epoch: 31 [4608/8000 (58%)]\tTotal Loss: 25.487473\n",
      "Reconstruction: 24.077976, Regularization: 1.409497\n",
      "2019-04-09 22:41:28,160 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 7457.284180\n",
      "Reconstruction: 7455.906738, Regularization: 1.377591\n",
      "2019-04-09 22:41:28,216 root         INFO     Train Epoch: 31 [5632/8000 (70%)]\tTotal Loss: 920.375977\n",
      "Reconstruction: 919.081909, Regularization: 1.294069\n",
      "2019-04-09 22:41:28,272 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 5518.730469\n",
      "Reconstruction: 5516.629395, Regularization: 2.100944\n",
      "2019-04-09 22:41:28,328 root         INFO     Train Epoch: 31 [6656/8000 (83%)]\tTotal Loss: 494777.781250\n",
      "Reconstruction: 494776.218750, Regularization: 1.576860\n",
      "2019-04-09 22:41:28,384 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 71355.007812\n",
      "Reconstruction: 71353.570312, Regularization: 1.440200\n",
      "2019-04-09 22:41:28,441 root         INFO     Train Epoch: 31 [7680/8000 (96%)]\tTotal Loss: 7855.691895\n",
      "Reconstruction: 7853.953613, Regularization: 1.738142\n",
      "2019-04-09 22:41:28,490 root         INFO     ====> Epoch: 31 Average loss: 149016.7718\n",
      "2019-04-09 22:41:28,513 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 169.218414\n",
      "Reconstruction: 167.524353, Regularization: 1.694065\n",
      "2019-04-09 22:41:28,569 root         INFO     Train Epoch: 32 [512/8000 (6%)]\tTotal Loss: 978.200928\n",
      "Reconstruction: 976.820679, Regularization: 1.380220\n",
      "2019-04-09 22:41:28,626 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 2381555.250000\n",
      "Reconstruction: 2381553.250000, Regularization: 1.948173\n",
      "2019-04-09 22:41:28,681 root         INFO     Train Epoch: 32 [1536/8000 (19%)]\tTotal Loss: 430.637665\n",
      "Reconstruction: 428.847595, Regularization: 1.790080\n",
      "2019-04-09 22:41:28,736 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 361.336151\n",
      "Reconstruction: 359.475830, Regularization: 1.860322\n",
      "2019-04-09 22:41:28,792 root         INFO     Train Epoch: 32 [2560/8000 (32%)]\tTotal Loss: 5070583.500000\n",
      "Reconstruction: 5070581.500000, Regularization: 1.884454\n",
      "2019-04-09 22:41:28,847 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 390.842255\n",
      "Reconstruction: 388.946594, Regularization: 1.895660\n",
      "2019-04-09 22:41:28,902 root         INFO     Train Epoch: 32 [3584/8000 (45%)]\tTotal Loss: 1712.477783\n",
      "Reconstruction: 1710.777588, Regularization: 1.700236\n",
      "2019-04-09 22:41:28,958 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 233913.406250\n",
      "Reconstruction: 233910.703125, Regularization: 2.699260\n",
      "2019-04-09 22:41:29,013 root         INFO     Train Epoch: 32 [4608/8000 (58%)]\tTotal Loss: 2822.559326\n",
      "Reconstruction: 2820.876221, Regularization: 1.683115\n",
      "2019-04-09 22:41:29,068 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 299.904327\n",
      "Reconstruction: 297.900757, Regularization: 2.003562\n",
      "2019-04-09 22:41:29,124 root         INFO     Train Epoch: 32 [5632/8000 (70%)]\tTotal Loss: 35440.113281\n",
      "Reconstruction: 35438.335938, Regularization: 1.777869\n",
      "2019-04-09 22:41:29,179 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 11.024305\n",
      "Reconstruction: 9.514908, Regularization: 1.509397\n",
      "2019-04-09 22:41:29,234 root         INFO     Train Epoch: 32 [6656/8000 (83%)]\tTotal Loss: 4086.216553\n",
      "Reconstruction: 4083.815918, Regularization: 2.400627\n",
      "2019-04-09 22:41:29,288 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 7383.743164\n",
      "Reconstruction: 7381.868164, Regularization: 1.874796\n",
      "2019-04-09 22:41:29,342 root         INFO     Train Epoch: 32 [7680/8000 (96%)]\tTotal Loss: 10.499291\n",
      "Reconstruction: 9.310623, Regularization: 1.188668\n",
      "2019-04-09 22:41:29,391 root         INFO     ====> Epoch: 32 Average loss: 372027.0223\n",
      "2019-04-09 22:41:29,413 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 30.859612\n",
      "Reconstruction: 29.970812, Regularization: 0.888800\n",
      "2019-04-09 22:41:29,470 root         INFO     Train Epoch: 33 [512/8000 (6%)]\tTotal Loss: 2748.764893\n",
      "Reconstruction: 2747.262939, Regularization: 1.501905\n",
      "2019-04-09 22:41:29,526 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 106.902664\n",
      "Reconstruction: 105.361580, Regularization: 1.541086\n",
      "2019-04-09 22:41:29,582 root         INFO     Train Epoch: 33 [1536/8000 (19%)]\tTotal Loss: 797849.625000\n",
      "Reconstruction: 797847.812500, Regularization: 1.818479\n",
      "2019-04-09 22:41:29,639 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 2765.497070\n",
      "Reconstruction: 2764.260498, Regularization: 1.236531\n",
      "2019-04-09 22:41:29,695 root         INFO     Train Epoch: 33 [2560/8000 (32%)]\tTotal Loss: 102.713165\n",
      "Reconstruction: 101.487053, Regularization: 1.226112\n",
      "2019-04-09 22:41:29,752 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 2533.833496\n",
      "Reconstruction: 2532.281982, Regularization: 1.551600\n",
      "2019-04-09 22:41:29,808 root         INFO     Train Epoch: 33 [3584/8000 (45%)]\tTotal Loss: 29.442261\n",
      "Reconstruction: 28.665192, Regularization: 0.777069\n",
      "2019-04-09 22:41:29,865 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 3656.327881\n",
      "Reconstruction: 3654.545898, Regularization: 1.781883\n",
      "2019-04-09 22:41:29,921 root         INFO     Train Epoch: 33 [4608/8000 (58%)]\tTotal Loss: 6.330173\n",
      "Reconstruction: 4.874599, Regularization: 1.455574\n",
      "2019-04-09 22:41:29,977 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 30081.128906\n",
      "Reconstruction: 30079.031250, Regularization: 2.097040\n",
      "2019-04-09 22:41:30,033 root         INFO     Train Epoch: 33 [5632/8000 (70%)]\tTotal Loss: 4322.759766\n",
      "Reconstruction: 4320.701172, Regularization: 2.058584\n",
      "2019-04-09 22:41:30,089 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 538.735535\n",
      "Reconstruction: 537.237000, Regularization: 1.498542\n",
      "2019-04-09 22:41:30,143 root         INFO     Train Epoch: 33 [6656/8000 (83%)]\tTotal Loss: 226.854752\n",
      "Reconstruction: 225.418243, Regularization: 1.436510\n",
      "2019-04-09 22:41:30,198 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 766.781250\n",
      "Reconstruction: 765.057007, Regularization: 1.724232\n",
      "2019-04-09 22:41:30,254 root         INFO     Train Epoch: 33 [7680/8000 (96%)]\tTotal Loss: 2988.604736\n",
      "Reconstruction: 2987.426025, Regularization: 1.178686\n",
      "2019-04-09 22:41:30,303 root         INFO     ====> Epoch: 33 Average loss: 304716.1106\n",
      "2019-04-09 22:41:30,326 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 23.024914\n",
      "Reconstruction: 21.393547, Regularization: 1.631366\n",
      "2019-04-09 22:41:30,383 root         INFO     Train Epoch: 34 [512/8000 (6%)]\tTotal Loss: 34.660042\n",
      "Reconstruction: 32.387276, Regularization: 2.272767\n",
      "2019-04-09 22:41:30,439 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 18124.097656\n",
      "Reconstruction: 18122.460938, Regularization: 1.636628\n",
      "2019-04-09 22:41:30,496 root         INFO     Train Epoch: 34 [1536/8000 (19%)]\tTotal Loss: 4335.445801\n",
      "Reconstruction: 4333.922852, Regularization: 1.522936\n",
      "2019-04-09 22:41:30,552 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 13882.739258\n",
      "Reconstruction: 13880.136719, Regularization: 2.602946\n",
      "2019-04-09 22:41:30,608 root         INFO     Train Epoch: 34 [2560/8000 (32%)]\tTotal Loss: 2130.761230\n",
      "Reconstruction: 2128.682129, Regularization: 2.079172\n",
      "2019-04-09 22:41:30,664 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 4129.004395\n",
      "Reconstruction: 4127.613281, Regularization: 1.391155\n",
      "2019-04-09 22:41:30,721 root         INFO     Train Epoch: 34 [3584/8000 (45%)]\tTotal Loss: 713.489990\n",
      "Reconstruction: 711.988892, Regularization: 1.501127\n",
      "2019-04-09 22:41:30,778 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 1713.751587\n",
      "Reconstruction: 1712.882080, Regularization: 0.869556\n",
      "2019-04-09 22:41:30,836 root         INFO     Train Epoch: 34 [4608/8000 (58%)]\tTotal Loss: 113.738419\n",
      "Reconstruction: 111.990219, Regularization: 1.748203\n",
      "2019-04-09 22:41:30,894 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 1685.952759\n",
      "Reconstruction: 1683.567871, Regularization: 2.384917\n",
      "2019-04-09 22:41:30,951 root         INFO     Train Epoch: 34 [5632/8000 (70%)]\tTotal Loss: 27.820280\n",
      "Reconstruction: 26.671097, Regularization: 1.149184\n",
      "2019-04-09 22:41:31,009 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 134.926102\n",
      "Reconstruction: 133.708771, Regularization: 1.217328\n",
      "2019-04-09 22:41:31,067 root         INFO     Train Epoch: 34 [6656/8000 (83%)]\tTotal Loss: 730213.750000\n",
      "Reconstruction: 730211.375000, Regularization: 2.400844\n",
      "2019-04-09 22:41:31,126 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 34996.496094\n",
      "Reconstruction: 34994.183594, Regularization: 2.310778\n",
      "2019-04-09 22:41:31,183 root         INFO     Train Epoch: 34 [7680/8000 (96%)]\tTotal Loss: 544.171265\n",
      "Reconstruction: 542.579468, Regularization: 1.591792\n",
      "2019-04-09 22:41:31,233 root         INFO     ====> Epoch: 34 Average loss: 152759.3104\n",
      "2019-04-09 22:41:31,256 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 290956.812500\n",
      "Reconstruction: 290954.875000, Regularization: 1.950569\n",
      "2019-04-09 22:41:31,312 root         INFO     Train Epoch: 35 [512/8000 (6%)]\tTotal Loss: 73.723839\n",
      "Reconstruction: 72.023361, Regularization: 1.700476\n",
      "2019-04-09 22:41:31,367 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 8.917498\n",
      "Reconstruction: 6.894618, Regularization: 2.022880\n",
      "2019-04-09 22:41:31,423 root         INFO     Train Epoch: 35 [1536/8000 (19%)]\tTotal Loss: 955.240906\n",
      "Reconstruction: 953.744568, Regularization: 1.496327\n",
      "2019-04-09 22:41:31,478 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 12956.656250\n",
      "Reconstruction: 12954.951172, Regularization: 1.704633\n",
      "2019-04-09 22:41:31,533 root         INFO     Train Epoch: 35 [2560/8000 (32%)]\tTotal Loss: 4908.418457\n",
      "Reconstruction: 4906.936035, Regularization: 1.482423\n",
      "2019-04-09 22:41:31,588 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 33.614250\n",
      "Reconstruction: 32.619652, Regularization: 0.994599\n",
      "2019-04-09 22:41:31,643 root         INFO     Train Epoch: 35 [3584/8000 (45%)]\tTotal Loss: 3820.383545\n",
      "Reconstruction: 3818.185303, Regularization: 2.198291\n",
      "2019-04-09 22:41:31,698 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 369.127625\n",
      "Reconstruction: 367.683594, Regularization: 1.444039\n",
      "2019-04-09 22:41:31,754 root         INFO     Train Epoch: 35 [4608/8000 (58%)]\tTotal Loss: 2900.682129\n",
      "Reconstruction: 2899.188477, Regularization: 1.493575\n",
      "2019-04-09 22:41:31,810 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 976480.562500\n",
      "Reconstruction: 976478.250000, Regularization: 2.336705\n",
      "2019-04-09 22:41:31,866 root         INFO     Train Epoch: 35 [5632/8000 (70%)]\tTotal Loss: 4251.963867\n",
      "Reconstruction: 4250.407715, Regularization: 1.556175\n",
      "2019-04-09 22:41:31,922 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 627.432312\n",
      "Reconstruction: 625.218994, Regularization: 2.213311\n",
      "2019-04-09 22:41:31,978 root         INFO     Train Epoch: 35 [6656/8000 (83%)]\tTotal Loss: 3810.673096\n",
      "Reconstruction: 3808.960205, Regularization: 1.712832\n",
      "2019-04-09 22:41:32,034 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 509.311066\n",
      "Reconstruction: 507.349915, Regularization: 1.961148\n",
      "2019-04-09 22:41:32,090 root         INFO     Train Epoch: 35 [7680/8000 (96%)]\tTotal Loss: 306853.750000\n",
      "Reconstruction: 306852.218750, Regularization: 1.515965\n",
      "2019-04-09 22:41:32,139 root         INFO     ====> Epoch: 35 Average loss: 196042.8998\n",
      "2019-04-09 22:41:32,162 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 1301938.625000\n",
      "Reconstruction: 1301936.375000, Regularization: 2.233521\n",
      "2019-04-09 22:41:32,219 root         INFO     Train Epoch: 36 [512/8000 (6%)]\tTotal Loss: 312796448.000000\n",
      "Reconstruction: 312796448.000000, Regularization: 1.787346\n",
      "2019-04-09 22:41:32,276 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 653.277832\n",
      "Reconstruction: 651.500366, Regularization: 1.777493\n",
      "2019-04-09 22:41:32,332 root         INFO     Train Epoch: 36 [1536/8000 (19%)]\tTotal Loss: 42.103031\n",
      "Reconstruction: 40.983952, Regularization: 1.119080\n",
      "2019-04-09 22:41:32,389 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 7502.273926\n",
      "Reconstruction: 7500.130859, Regularization: 2.143104\n",
      "2019-04-09 22:41:32,445 root         INFO     Train Epoch: 36 [2560/8000 (32%)]\tTotal Loss: 177.076294\n",
      "Reconstruction: 175.791870, Regularization: 1.284430\n",
      "2019-04-09 22:41:32,500 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 67166.500000\n",
      "Reconstruction: 67164.476562, Regularization: 2.027326\n",
      "2019-04-09 22:41:32,553 root         INFO     Train Epoch: 36 [3584/8000 (45%)]\tTotal Loss: 234.891876\n",
      "Reconstruction: 233.330276, Regularization: 1.561602\n",
      "2019-04-09 22:41:32,606 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 14262.583008\n",
      "Reconstruction: 14260.368164, Regularization: 2.215232\n",
      "2019-04-09 22:41:32,660 root         INFO     Train Epoch: 36 [4608/8000 (58%)]\tTotal Loss: 43.022228\n",
      "Reconstruction: 42.082169, Regularization: 0.940060\n",
      "2019-04-09 22:41:32,713 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 4293.620605\n",
      "Reconstruction: 4291.901855, Regularization: 1.718563\n",
      "2019-04-09 22:41:32,766 root         INFO     Train Epoch: 36 [5632/8000 (70%)]\tTotal Loss: 4149.741211\n",
      "Reconstruction: 4147.788574, Regularization: 1.952642\n",
      "2019-04-09 22:41:32,819 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 17.151184\n",
      "Reconstruction: 15.699629, Regularization: 1.451555\n",
      "2019-04-09 22:41:32,872 root         INFO     Train Epoch: 36 [6656/8000 (83%)]\tTotal Loss: 2852.173828\n",
      "Reconstruction: 2850.364990, Regularization: 1.808802\n",
      "2019-04-09 22:41:32,925 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 4212.945801\n",
      "Reconstruction: 4211.682129, Regularization: 1.263524\n",
      "2019-04-09 22:41:32,979 root         INFO     Train Epoch: 36 [7680/8000 (96%)]\tTotal Loss: 315531.343750\n",
      "Reconstruction: 315529.656250, Regularization: 1.699086\n",
      "2019-04-09 22:41:33,027 root         INFO     ====> Epoch: 36 Average loss: 2490059.0982\n",
      "2019-04-09 22:41:33,050 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 6295.229492\n",
      "Reconstruction: 6292.667480, Regularization: 2.561934\n",
      "2019-04-09 22:41:33,105 root         INFO     Train Epoch: 37 [512/8000 (6%)]\tTotal Loss: 58.577637\n",
      "Reconstruction: 57.280495, Regularization: 1.297141\n",
      "2019-04-09 22:41:33,160 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 617.454834\n",
      "Reconstruction: 615.163574, Regularization: 2.291273\n",
      "2019-04-09 22:41:33,214 root         INFO     Train Epoch: 37 [1536/8000 (19%)]\tTotal Loss: 47176.398438\n",
      "Reconstruction: 47174.667969, Regularization: 1.729536\n",
      "2019-04-09 22:41:33,268 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 189.642700\n",
      "Reconstruction: 188.205078, Regularization: 1.437622\n",
      "2019-04-09 22:41:33,323 root         INFO     Train Epoch: 37 [2560/8000 (32%)]\tTotal Loss: 60.475914\n",
      "Reconstruction: 59.376186, Regularization: 1.099726\n",
      "2019-04-09 22:41:33,377 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 65.070877\n",
      "Reconstruction: 63.073002, Regularization: 1.997873\n",
      "2019-04-09 22:41:33,431 root         INFO     Train Epoch: 37 [3584/8000 (45%)]\tTotal Loss: 10636.997070\n",
      "Reconstruction: 10635.389648, Regularization: 1.607495\n",
      "2019-04-09 22:41:33,485 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 2751.361572\n",
      "Reconstruction: 2749.933838, Regularization: 1.427758\n",
      "2019-04-09 22:41:33,540 root         INFO     Train Epoch: 37 [4608/8000 (58%)]\tTotal Loss: 3235.427979\n",
      "Reconstruction: 3233.900635, Regularization: 1.527303\n",
      "2019-04-09 22:41:33,594 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 5060.744141\n",
      "Reconstruction: 5059.334961, Regularization: 1.409175\n",
      "2019-04-09 22:41:33,649 root         INFO     Train Epoch: 37 [5632/8000 (70%)]\tTotal Loss: 8.802876\n",
      "Reconstruction: 7.306521, Regularization: 1.496355\n",
      "2019-04-09 22:41:33,703 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 163.470016\n",
      "Reconstruction: 162.224579, Regularization: 1.245440\n",
      "2019-04-09 22:41:33,758 root         INFO     Train Epoch: 37 [6656/8000 (83%)]\tTotal Loss: 6547.713379\n",
      "Reconstruction: 6545.612305, Regularization: 2.101202\n",
      "2019-04-09 22:41:33,812 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 554.228149\n",
      "Reconstruction: 552.903320, Regularization: 1.324817\n",
      "2019-04-09 22:41:33,867 root         INFO     Train Epoch: 37 [7680/8000 (96%)]\tTotal Loss: 96.861946\n",
      "Reconstruction: 95.680847, Regularization: 1.181100\n",
      "2019-04-09 22:41:33,916 root         INFO     ====> Epoch: 37 Average loss: 536501.7787\n",
      "2019-04-09 22:41:33,939 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 319767.281250\n",
      "Reconstruction: 319765.281250, Regularization: 1.997411\n",
      "2019-04-09 22:41:33,994 root         INFO     Train Epoch: 38 [512/8000 (6%)]\tTotal Loss: 193.771103\n",
      "Reconstruction: 192.180405, Regularization: 1.590693\n",
      "2019-04-09 22:41:34,050 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 18.474752\n",
      "Reconstruction: 17.042707, Regularization: 1.432045\n",
      "2019-04-09 22:41:34,105 root         INFO     Train Epoch: 38 [1536/8000 (19%)]\tTotal Loss: 30.959532\n",
      "Reconstruction: 29.578659, Regularization: 1.380872\n",
      "2019-04-09 22:41:34,160 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 496.670502\n",
      "Reconstruction: 494.741791, Regularization: 1.928714\n",
      "2019-04-09 22:41:34,215 root         INFO     Train Epoch: 38 [2560/8000 (32%)]\tTotal Loss: 232.915939\n",
      "Reconstruction: 230.662079, Regularization: 2.253862\n",
      "2019-04-09 22:41:34,271 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 1132.606689\n",
      "Reconstruction: 1130.648682, Regularization: 1.958031\n",
      "2019-04-09 22:41:34,326 root         INFO     Train Epoch: 38 [3584/8000 (45%)]\tTotal Loss: 7587.593750\n",
      "Reconstruction: 7585.819336, Regularization: 1.774498\n",
      "2019-04-09 22:41:34,381 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 15.449107\n",
      "Reconstruction: 13.468437, Regularization: 1.980670\n",
      "2019-04-09 22:41:34,436 root         INFO     Train Epoch: 38 [4608/8000 (58%)]\tTotal Loss: 57.372585\n",
      "Reconstruction: 56.493729, Regularization: 0.878855\n",
      "2019-04-09 22:41:34,491 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 306724.625000\n",
      "Reconstruction: 306722.375000, Regularization: 2.244359\n",
      "2019-04-09 22:41:34,546 root         INFO     Train Epoch: 38 [5632/8000 (70%)]\tTotal Loss: 25.320799\n",
      "Reconstruction: 23.750975, Regularization: 1.569824\n",
      "2019-04-09 22:41:34,601 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 614057.250000\n",
      "Reconstruction: 614055.687500, Regularization: 1.558069\n",
      "2019-04-09 22:41:34,657 root         INFO     Train Epoch: 38 [6656/8000 (83%)]\tTotal Loss: 17976.054688\n",
      "Reconstruction: 17974.113281, Regularization: 1.940915\n",
      "2019-04-09 22:41:34,712 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 589.354370\n",
      "Reconstruction: 587.884521, Regularization: 1.469875\n",
      "2019-04-09 22:41:34,767 root         INFO     Train Epoch: 38 [7680/8000 (96%)]\tTotal Loss: 80.011223\n",
      "Reconstruction: 78.440842, Regularization: 1.570378\n",
      "2019-04-09 22:41:34,817 root         INFO     ====> Epoch: 38 Average loss: 114392.5796\n",
      "2019-04-09 22:41:34,840 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 723.407959\n",
      "Reconstruction: 721.683777, Regularization: 1.724195\n",
      "2019-04-09 22:41:34,896 root         INFO     Train Epoch: 39 [512/8000 (6%)]\tTotal Loss: 261.570618\n",
      "Reconstruction: 260.702667, Regularization: 0.867943\n",
      "2019-04-09 22:41:34,952 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 7365.951172\n",
      "Reconstruction: 7364.001465, Regularization: 1.949814\n",
      "2019-04-09 22:41:35,008 root         INFO     Train Epoch: 39 [1536/8000 (19%)]\tTotal Loss: 1230.842651\n",
      "Reconstruction: 1229.118774, Regularization: 1.723892\n",
      "2019-04-09 22:41:35,063 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 58201.039062\n",
      "Reconstruction: 58198.722656, Regularization: 2.317656\n",
      "2019-04-09 22:41:35,119 root         INFO     Train Epoch: 39 [2560/8000 (32%)]\tTotal Loss: 2237.338135\n",
      "Reconstruction: 2235.597168, Regularization: 1.741049\n",
      "2019-04-09 22:41:35,174 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 1660.797729\n",
      "Reconstruction: 1659.335571, Regularization: 1.462218\n",
      "2019-04-09 22:41:35,230 root         INFO     Train Epoch: 39 [3584/8000 (45%)]\tTotal Loss: 2524.268311\n",
      "Reconstruction: 2522.257568, Regularization: 2.010828\n",
      "2019-04-09 22:41:35,285 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 423.796448\n",
      "Reconstruction: 422.229828, Regularization: 1.566605\n",
      "2019-04-09 22:41:35,340 root         INFO     Train Epoch: 39 [4608/8000 (58%)]\tTotal Loss: 17267.652344\n",
      "Reconstruction: 17266.013672, Regularization: 1.638444\n",
      "2019-04-09 22:41:35,394 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 16.926113\n",
      "Reconstruction: 15.654861, Regularization: 1.271251\n",
      "2019-04-09 22:41:35,449 root         INFO     Train Epoch: 39 [5632/8000 (70%)]\tTotal Loss: 158915.375000\n",
      "Reconstruction: 158913.656250, Regularization: 1.717557\n",
      "2019-04-09 22:41:35,505 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 60.141544\n",
      "Reconstruction: 59.046223, Regularization: 1.095321\n",
      "2019-04-09 22:41:35,559 root         INFO     Train Epoch: 39 [6656/8000 (83%)]\tTotal Loss: 785.054443\n",
      "Reconstruction: 783.858032, Regularization: 1.196410\n",
      "2019-04-09 22:41:35,615 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 60.607048\n",
      "Reconstruction: 59.287659, Regularization: 1.319391\n",
      "2019-04-09 22:41:35,670 root         INFO     Train Epoch: 39 [7680/8000 (96%)]\tTotal Loss: 282.322540\n",
      "Reconstruction: 280.419373, Regularization: 1.903173\n",
      "2019-04-09 22:41:35,719 root         INFO     ====> Epoch: 39 Average loss: 96139.0682\n",
      "2019-04-09 22:41:35,743 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 50.354431\n",
      "Reconstruction: 48.665817, Regularization: 1.688615\n",
      "2019-04-09 22:41:35,799 root         INFO     Train Epoch: 40 [512/8000 (6%)]\tTotal Loss: 26468194.000000\n",
      "Reconstruction: 26468192.000000, Regularization: 2.151084\n",
      "2019-04-09 22:41:35,854 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 1164.639526\n",
      "Reconstruction: 1162.908203, Regularization: 1.731366\n",
      "2019-04-09 22:41:35,910 root         INFO     Train Epoch: 40 [1536/8000 (19%)]\tTotal Loss: 6425.666016\n",
      "Reconstruction: 6424.425293, Regularization: 1.240777\n",
      "2019-04-09 22:41:35,965 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 610.625732\n",
      "Reconstruction: 609.541748, Regularization: 1.083978\n",
      "2019-04-09 22:41:36,021 root         INFO     Train Epoch: 40 [2560/8000 (32%)]\tTotal Loss: 682291.125000\n",
      "Reconstruction: 682289.500000, Regularization: 1.612456\n",
      "2019-04-09 22:41:36,076 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 2439.908203\n",
      "Reconstruction: 2437.684814, Regularization: 2.223351\n",
      "2019-04-09 22:41:36,132 root         INFO     Train Epoch: 40 [3584/8000 (45%)]\tTotal Loss: 7.923712\n",
      "Reconstruction: 6.481404, Regularization: 1.442308\n",
      "2019-04-09 22:41:36,187 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 14.364663\n",
      "Reconstruction: 13.230350, Regularization: 1.134313\n",
      "2019-04-09 22:41:36,243 root         INFO     Train Epoch: 40 [4608/8000 (58%)]\tTotal Loss: 13004.771484\n",
      "Reconstruction: 13003.404297, Regularization: 1.366996\n",
      "2019-04-09 22:41:36,299 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 3067.162842\n",
      "Reconstruction: 3066.089355, Regularization: 1.073530\n",
      "2019-04-09 22:41:36,354 root         INFO     Train Epoch: 40 [5632/8000 (70%)]\tTotal Loss: 3897.027832\n",
      "Reconstruction: 3895.567871, Regularization: 1.459985\n",
      "2019-04-09 22:41:36,410 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 60.968472\n",
      "Reconstruction: 59.268410, Regularization: 1.700060\n",
      "2019-04-09 22:41:36,464 root         INFO     Train Epoch: 40 [6656/8000 (83%)]\tTotal Loss: 812.887939\n",
      "Reconstruction: 810.981201, Regularization: 1.906719\n",
      "2019-04-09 22:41:36,518 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 320.022980\n",
      "Reconstruction: 319.091553, Regularization: 0.931429\n",
      "2019-04-09 22:41:36,572 root         INFO     Train Epoch: 40 [7680/8000 (96%)]\tTotal Loss: 5757.967285\n",
      "Reconstruction: 5755.976562, Regularization: 1.990479\n",
      "2019-04-09 22:41:36,620 root         INFO     ====> Epoch: 40 Average loss: 404873.4090\n",
      "2019-04-09 22:41:36,643 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 4707.530762\n",
      "Reconstruction: 4705.544434, Regularization: 1.986265\n",
      "2019-04-09 22:41:36,699 root         INFO     Train Epoch: 41 [512/8000 (6%)]\tTotal Loss: 123.931366\n",
      "Reconstruction: 122.420692, Regularization: 1.510675\n",
      "2019-04-09 22:41:36,753 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 171.647522\n",
      "Reconstruction: 170.394165, Regularization: 1.253356\n",
      "2019-04-09 22:41:36,808 root         INFO     Train Epoch: 41 [1536/8000 (19%)]\tTotal Loss: 43.017227\n",
      "Reconstruction: 41.862232, Regularization: 1.154995\n",
      "2019-04-09 22:41:36,862 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 156.610031\n",
      "Reconstruction: 154.963486, Regularization: 1.646543\n",
      "2019-04-09 22:41:36,917 root         INFO     Train Epoch: 41 [2560/8000 (32%)]\tTotal Loss: 10454.680664\n",
      "Reconstruction: 10453.536133, Regularization: 1.144147\n",
      "2019-04-09 22:41:36,972 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 880.839355\n",
      "Reconstruction: 879.640991, Regularization: 1.198372\n",
      "2019-04-09 22:41:37,027 root         INFO     Train Epoch: 41 [3584/8000 (45%)]\tTotal Loss: 2.324388\n",
      "Reconstruction: 0.794793, Regularization: 1.529595\n",
      "2019-04-09 22:41:37,082 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 1491.516113\n",
      "Reconstruction: 1490.103394, Regularization: 1.412758\n",
      "2019-04-09 22:41:37,137 root         INFO     Train Epoch: 41 [4608/8000 (58%)]\tTotal Loss: 38.321865\n",
      "Reconstruction: 37.049351, Regularization: 1.272513\n",
      "2019-04-09 22:41:37,191 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 4161.065430\n",
      "Reconstruction: 4159.689453, Regularization: 1.375768\n",
      "2019-04-09 22:41:37,246 root         INFO     Train Epoch: 41 [5632/8000 (70%)]\tTotal Loss: 793.746765\n",
      "Reconstruction: 792.217957, Regularization: 1.528790\n",
      "2019-04-09 22:41:37,301 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 2541.379639\n",
      "Reconstruction: 2539.106689, Regularization: 2.273051\n",
      "2019-04-09 22:41:37,356 root         INFO     Train Epoch: 41 [6656/8000 (83%)]\tTotal Loss: 3526.583252\n",
      "Reconstruction: 3524.897461, Regularization: 1.685857\n",
      "2019-04-09 22:41:37,412 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 423.210815\n",
      "Reconstruction: 420.680969, Regularization: 2.529832\n",
      "2019-04-09 22:41:37,467 root         INFO     Train Epoch: 41 [7680/8000 (96%)]\tTotal Loss: 45.262909\n",
      "Reconstruction: 43.514389, Regularization: 1.748519\n",
      "2019-04-09 22:41:37,518 root         INFO     ====> Epoch: 41 Average loss: 173613.7003\n",
      "2019-04-09 22:41:37,541 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 486.556488\n",
      "Reconstruction: 484.522278, Regularization: 2.034206\n",
      "2019-04-09 22:41:37,597 root         INFO     Train Epoch: 42 [512/8000 (6%)]\tTotal Loss: 200.979095\n",
      "Reconstruction: 199.756622, Regularization: 1.222478\n",
      "2019-04-09 22:41:37,653 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 5466.859863\n",
      "Reconstruction: 5466.024414, Regularization: 0.835258\n",
      "2019-04-09 22:41:37,711 root         INFO     Train Epoch: 42 [1536/8000 (19%)]\tTotal Loss: 164466.375000\n",
      "Reconstruction: 164464.000000, Regularization: 2.375662\n",
      "2019-04-09 22:41:37,769 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 1595.230347\n",
      "Reconstruction: 1594.080933, Regularization: 1.149473\n",
      "2019-04-09 22:41:37,827 root         INFO     Train Epoch: 42 [2560/8000 (32%)]\tTotal Loss: 6027.016602\n",
      "Reconstruction: 6025.259766, Regularization: 1.756782\n",
      "2019-04-09 22:41:37,885 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 441.605103\n",
      "Reconstruction: 440.187347, Regularization: 1.417763\n",
      "2019-04-09 22:41:37,943 root         INFO     Train Epoch: 42 [3584/8000 (45%)]\tTotal Loss: 36.076981\n",
      "Reconstruction: 35.407696, Regularization: 0.669285\n",
      "2019-04-09 22:41:38,002 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 979.381653\n",
      "Reconstruction: 977.783813, Regularization: 1.597863\n",
      "2019-04-09 22:41:38,060 root         INFO     Train Epoch: 42 [4608/8000 (58%)]\tTotal Loss: 184.634506\n",
      "Reconstruction: 183.157135, Regularization: 1.477378\n",
      "2019-04-09 22:41:38,118 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 243.045441\n",
      "Reconstruction: 242.091324, Regularization: 0.954113\n",
      "2019-04-09 22:41:38,176 root         INFO     Train Epoch: 42 [5632/8000 (70%)]\tTotal Loss: 7292.726074\n",
      "Reconstruction: 7291.339355, Regularization: 1.386574\n",
      "2019-04-09 22:41:38,234 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 1197.813965\n",
      "Reconstruction: 1196.533203, Regularization: 1.280728\n",
      "2019-04-09 22:41:38,292 root         INFO     Train Epoch: 42 [6656/8000 (83%)]\tTotal Loss: 16961.517578\n",
      "Reconstruction: 16959.462891, Regularization: 2.054086\n",
      "2019-04-09 22:41:38,348 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 720.667236\n",
      "Reconstruction: 718.993347, Regularization: 1.673905\n",
      "2019-04-09 22:41:38,404 root         INFO     Train Epoch: 42 [7680/8000 (96%)]\tTotal Loss: 168.557648\n",
      "Reconstruction: 167.620163, Regularization: 0.937492\n",
      "2019-04-09 22:41:38,453 root         INFO     ====> Epoch: 42 Average loss: 211025.9312\n",
      "2019-04-09 22:41:38,476 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 165.529388\n",
      "Reconstruction: 163.875153, Regularization: 1.654231\n",
      "2019-04-09 22:41:38,531 root         INFO     Train Epoch: 43 [512/8000 (6%)]\tTotal Loss: 571.017334\n",
      "Reconstruction: 569.856934, Regularization: 1.160419\n",
      "2019-04-09 22:41:38,586 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 127.360664\n",
      "Reconstruction: 126.102028, Regularization: 1.258633\n",
      "2019-04-09 22:41:38,642 root         INFO     Train Epoch: 43 [1536/8000 (19%)]\tTotal Loss: 32.970020\n",
      "Reconstruction: 32.074234, Regularization: 0.895785\n",
      "2019-04-09 22:41:38,698 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 21483.982422\n",
      "Reconstruction: 21482.447266, Regularization: 1.536129\n",
      "2019-04-09 22:41:38,754 root         INFO     Train Epoch: 43 [2560/8000 (32%)]\tTotal Loss: 156.830124\n",
      "Reconstruction: 155.628632, Regularization: 1.201493\n",
      "2019-04-09 22:41:38,810 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 176.999435\n",
      "Reconstruction: 175.205719, Regularization: 1.793714\n",
      "2019-04-09 22:41:38,866 root         INFO     Train Epoch: 43 [3584/8000 (45%)]\tTotal Loss: 2615.582031\n",
      "Reconstruction: 2613.661377, Regularization: 1.920536\n",
      "2019-04-09 22:41:38,922 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 2636.628662\n",
      "Reconstruction: 2634.594727, Regularization: 2.033963\n",
      "2019-04-09 22:41:38,977 root         INFO     Train Epoch: 43 [4608/8000 (58%)]\tTotal Loss: 125.485413\n",
      "Reconstruction: 124.168915, Regularization: 1.316499\n",
      "2019-04-09 22:41:39,031 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 212.200317\n",
      "Reconstruction: 210.346130, Regularization: 1.854191\n",
      "2019-04-09 22:41:39,084 root         INFO     Train Epoch: 43 [5632/8000 (70%)]\tTotal Loss: 152.772263\n",
      "Reconstruction: 151.396896, Regularization: 1.375366\n",
      "2019-04-09 22:41:39,138 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 144933.125000\n",
      "Reconstruction: 144931.031250, Regularization: 2.098284\n",
      "2019-04-09 22:41:39,193 root         INFO     Train Epoch: 43 [6656/8000 (83%)]\tTotal Loss: 3199.663330\n",
      "Reconstruction: 3197.937500, Regularization: 1.725855\n",
      "2019-04-09 22:41:39,248 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 201.340408\n",
      "Reconstruction: 200.306564, Regularization: 1.033849\n",
      "2019-04-09 22:41:39,302 root         INFO     Train Epoch: 43 [7680/8000 (96%)]\tTotal Loss: 2867.720703\n",
      "Reconstruction: 2866.170898, Regularization: 1.549695\n",
      "2019-04-09 22:41:39,351 root         INFO     ====> Epoch: 43 Average loss: 50839.3277\n",
      "2019-04-09 22:41:39,374 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 1220.722534\n",
      "Reconstruction: 1219.016968, Regularization: 1.705560\n",
      "2019-04-09 22:41:39,430 root         INFO     Train Epoch: 44 [512/8000 (6%)]\tTotal Loss: 534.142822\n",
      "Reconstruction: 532.504456, Regularization: 1.638376\n",
      "2019-04-09 22:41:39,487 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 136.551880\n",
      "Reconstruction: 135.048889, Regularization: 1.502986\n",
      "2019-04-09 22:41:39,542 root         INFO     Train Epoch: 44 [1536/8000 (19%)]\tTotal Loss: 1042.061523\n",
      "Reconstruction: 1040.423096, Regularization: 1.638379\n",
      "2019-04-09 22:41:39,596 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 159.888641\n",
      "Reconstruction: 159.010529, Regularization: 0.878110\n",
      "2019-04-09 22:41:39,651 root         INFO     Train Epoch: 44 [2560/8000 (32%)]\tTotal Loss: 500.751984\n",
      "Reconstruction: 498.946136, Regularization: 1.805857\n",
      "2019-04-09 22:41:39,707 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 208257.562500\n",
      "Reconstruction: 208255.468750, Regularization: 2.087119\n",
      "2019-04-09 22:41:39,763 root         INFO     Train Epoch: 44 [3584/8000 (45%)]\tTotal Loss: 63768.242188\n",
      "Reconstruction: 63767.003906, Regularization: 1.239198\n",
      "2019-04-09 22:41:39,819 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 13356.585938\n",
      "Reconstruction: 13354.608398, Regularization: 1.977857\n",
      "2019-04-09 22:41:39,874 root         INFO     Train Epoch: 44 [4608/8000 (58%)]\tTotal Loss: 1085.887451\n",
      "Reconstruction: 1084.781616, Regularization: 1.105801\n",
      "2019-04-09 22:41:39,929 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 789.983643\n",
      "Reconstruction: 787.947693, Regularization: 2.035920\n",
      "2019-04-09 22:41:39,983 root         INFO     Train Epoch: 44 [5632/8000 (70%)]\tTotal Loss: 202.838867\n",
      "Reconstruction: 201.773499, Regularization: 1.065362\n",
      "2019-04-09 22:41:40,040 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 972.037231\n",
      "Reconstruction: 970.148438, Regularization: 1.888796\n",
      "2019-04-09 22:41:40,096 root         INFO     Train Epoch: 44 [6656/8000 (83%)]\tTotal Loss: 296.606171\n",
      "Reconstruction: 295.348816, Regularization: 1.257353\n",
      "2019-04-09 22:41:40,153 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 157354.484375\n",
      "Reconstruction: 157352.859375, Regularization: 1.619584\n",
      "2019-04-09 22:41:40,209 root         INFO     Train Epoch: 44 [7680/8000 (96%)]\tTotal Loss: 3722.724609\n",
      "Reconstruction: 3720.806641, Regularization: 1.918038\n",
      "2019-04-09 22:41:40,259 root         INFO     ====> Epoch: 44 Average loss: 36206.9301\n",
      "2019-04-09 22:41:40,283 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 197.984222\n",
      "Reconstruction: 196.584381, Regularization: 1.399837\n",
      "2019-04-09 22:41:40,338 root         INFO     Train Epoch: 45 [512/8000 (6%)]\tTotal Loss: 30819.431641\n",
      "Reconstruction: 30818.222656, Regularization: 1.208473\n",
      "2019-04-09 22:41:40,394 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 93.750778\n",
      "Reconstruction: 92.146576, Regularization: 1.604201\n",
      "2019-04-09 22:41:40,449 root         INFO     Train Epoch: 45 [1536/8000 (19%)]\tTotal Loss: 2023.188843\n",
      "Reconstruction: 2021.089844, Regularization: 2.098971\n",
      "2019-04-09 22:41:40,505 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 108698.695312\n",
      "Reconstruction: 108696.156250, Regularization: 2.535564\n",
      "2019-04-09 22:41:40,560 root         INFO     Train Epoch: 45 [2560/8000 (32%)]\tTotal Loss: 2520.561279\n",
      "Reconstruction: 2518.686279, Regularization: 1.875108\n",
      "2019-04-09 22:41:40,615 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 1725.808105\n",
      "Reconstruction: 1724.079224, Regularization: 1.728883\n",
      "2019-04-09 22:41:40,671 root         INFO     Train Epoch: 45 [3584/8000 (45%)]\tTotal Loss: 29.188078\n",
      "Reconstruction: 27.733120, Regularization: 1.454959\n",
      "2019-04-09 22:41:40,726 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 136.447937\n",
      "Reconstruction: 135.110199, Regularization: 1.337740\n",
      "2019-04-09 22:41:40,782 root         INFO     Train Epoch: 45 [4608/8000 (58%)]\tTotal Loss: 358.861847\n",
      "Reconstruction: 356.628143, Regularization: 2.233700\n",
      "2019-04-09 22:41:40,837 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 741656.250000\n",
      "Reconstruction: 741654.375000, Regularization: 1.887150\n",
      "2019-04-09 22:41:40,892 root         INFO     Train Epoch: 45 [5632/8000 (70%)]\tTotal Loss: 412.128418\n",
      "Reconstruction: 410.612793, Regularization: 1.515620\n",
      "2019-04-09 22:41:40,947 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 5185.040527\n",
      "Reconstruction: 5183.687012, Regularization: 1.353562\n",
      "2019-04-09 22:41:41,002 root         INFO     Train Epoch: 45 [6656/8000 (83%)]\tTotal Loss: 287.483551\n",
      "Reconstruction: 286.337402, Regularization: 1.146139\n",
      "2019-04-09 22:41:41,057 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 3717.885742\n",
      "Reconstruction: 3716.168213, Regularization: 1.717449\n",
      "2019-04-09 22:41:41,112 root         INFO     Train Epoch: 45 [7680/8000 (96%)]\tTotal Loss: 31.629429\n",
      "Reconstruction: 30.093544, Regularization: 1.535885\n",
      "2019-04-09 22:41:41,161 root         INFO     ====> Epoch: 45 Average loss: 40337.1692\n",
      "2019-04-09 22:41:41,184 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 1621.331055\n",
      "Reconstruction: 1619.547119, Regularization: 1.783987\n",
      "2019-04-09 22:41:41,241 root         INFO     Train Epoch: 46 [512/8000 (6%)]\tTotal Loss: 14.149226\n",
      "Reconstruction: 12.850739, Regularization: 1.298488\n",
      "2019-04-09 22:41:41,298 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 75.502762\n",
      "Reconstruction: 74.124420, Regularization: 1.378342\n",
      "2019-04-09 22:41:41,354 root         INFO     Train Epoch: 46 [1536/8000 (19%)]\tTotal Loss: 87833.023438\n",
      "Reconstruction: 87831.921875, Regularization: 1.101634\n",
      "2019-04-09 22:41:41,411 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 13676.536133\n",
      "Reconstruction: 13674.575195, Regularization: 1.961176\n",
      "2019-04-09 22:41:41,467 root         INFO     Train Epoch: 46 [2560/8000 (32%)]\tTotal Loss: 458.804993\n",
      "Reconstruction: 457.495422, Regularization: 1.309574\n",
      "2019-04-09 22:41:41,522 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 401.160217\n",
      "Reconstruction: 400.001221, Regularization: 1.159010\n",
      "2019-04-09 22:41:41,578 root         INFO     Train Epoch: 46 [3584/8000 (45%)]\tTotal Loss: 487.597382\n",
      "Reconstruction: 486.347290, Regularization: 1.250092\n",
      "2019-04-09 22:41:41,634 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 195.365067\n",
      "Reconstruction: 193.573654, Regularization: 1.791415\n",
      "2019-04-09 22:41:41,689 root         INFO     Train Epoch: 46 [4608/8000 (58%)]\tTotal Loss: 212.785095\n",
      "Reconstruction: 211.340607, Regularization: 1.444485\n",
      "2019-04-09 22:41:41,745 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 1439.102661\n",
      "Reconstruction: 1437.417358, Regularization: 1.685246\n",
      "2019-04-09 22:41:41,801 root         INFO     Train Epoch: 46 [5632/8000 (70%)]\tTotal Loss: 70.735710\n",
      "Reconstruction: 68.427948, Regularization: 2.307765\n",
      "2019-04-09 22:41:41,857 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 1202.119385\n",
      "Reconstruction: 1200.345459, Regularization: 1.773890\n",
      "2019-04-09 22:41:41,913 root         INFO     Train Epoch: 46 [6656/8000 (83%)]\tTotal Loss: 6319.895996\n",
      "Reconstruction: 6318.562012, Regularization: 1.333853\n",
      "2019-04-09 22:41:41,968 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 136751.468750\n",
      "Reconstruction: 136749.968750, Regularization: 1.495798\n",
      "2019-04-09 22:41:42,024 root         INFO     Train Epoch: 46 [7680/8000 (96%)]\tTotal Loss: 672.580627\n",
      "Reconstruction: 671.108765, Regularization: 1.471844\n",
      "2019-04-09 22:41:42,074 root         INFO     ====> Epoch: 46 Average loss: 49186.4511\n",
      "2019-04-09 22:41:42,097 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 272.526581\n",
      "Reconstruction: 271.143585, Regularization: 1.382989\n",
      "2019-04-09 22:41:42,152 root         INFO     Train Epoch: 47 [512/8000 (6%)]\tTotal Loss: 7271.478027\n",
      "Reconstruction: 7269.423828, Regularization: 2.054023\n",
      "2019-04-09 22:41:42,208 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 906.712769\n",
      "Reconstruction: 905.251038, Regularization: 1.461731\n",
      "2019-04-09 22:41:42,264 root         INFO     Train Epoch: 47 [1536/8000 (19%)]\tTotal Loss: 502646.375000\n",
      "Reconstruction: 502644.500000, Regularization: 1.866549\n",
      "2019-04-09 22:41:42,320 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 18585.642578\n",
      "Reconstruction: 18583.839844, Regularization: 1.802882\n",
      "2019-04-09 22:41:42,374 root         INFO     Train Epoch: 47 [2560/8000 (32%)]\tTotal Loss: 1318.907959\n",
      "Reconstruction: 1317.297852, Regularization: 1.610165\n",
      "2019-04-09 22:41:42,430 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 458.945282\n",
      "Reconstruction: 457.955139, Regularization: 0.990145\n",
      "2019-04-09 22:41:42,485 root         INFO     Train Epoch: 47 [3584/8000 (45%)]\tTotal Loss: 81.714119\n",
      "Reconstruction: 80.280853, Regularization: 1.433264\n",
      "2019-04-09 22:41:42,539 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 527.784119\n",
      "Reconstruction: 526.551514, Regularization: 1.232594\n",
      "2019-04-09 22:41:42,594 root         INFO     Train Epoch: 47 [4608/8000 (58%)]\tTotal Loss: 26081.863281\n",
      "Reconstruction: 26080.033203, Regularization: 1.830260\n",
      "2019-04-09 22:41:42,649 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 1222.280029\n",
      "Reconstruction: 1219.274658, Regularization: 3.005383\n",
      "2019-04-09 22:41:42,705 root         INFO     Train Epoch: 47 [5632/8000 (70%)]\tTotal Loss: 460.327362\n",
      "Reconstruction: 457.614105, Regularization: 2.713263\n",
      "2019-04-09 22:41:42,760 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 185.689163\n",
      "Reconstruction: 183.613052, Regularization: 2.076109\n",
      "2019-04-09 22:41:42,815 root         INFO     Train Epoch: 47 [6656/8000 (83%)]\tTotal Loss: 881.994629\n",
      "Reconstruction: 880.221619, Regularization: 1.773014\n",
      "2019-04-09 22:41:42,870 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 13002.862305\n",
      "Reconstruction: 13001.009766, Regularization: 1.852540\n",
      "2019-04-09 22:41:42,924 root         INFO     Train Epoch: 47 [7680/8000 (96%)]\tTotal Loss: 653.286316\n",
      "Reconstruction: 651.085205, Regularization: 2.201134\n",
      "2019-04-09 22:41:42,972 root         INFO     ====> Epoch: 47 Average loss: 54739.9005\n",
      "2019-04-09 22:41:42,995 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 2648.226807\n",
      "Reconstruction: 2646.173340, Regularization: 2.053540\n",
      "2019-04-09 22:41:43,052 root         INFO     Train Epoch: 48 [512/8000 (6%)]\tTotal Loss: 279.399200\n",
      "Reconstruction: 277.542633, Regularization: 1.856564\n",
      "2019-04-09 22:41:43,108 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 39.022270\n",
      "Reconstruction: 37.541389, Regularization: 1.480881\n",
      "2019-04-09 22:41:43,164 root         INFO     Train Epoch: 48 [1536/8000 (19%)]\tTotal Loss: 3149.691406\n",
      "Reconstruction: 3148.025635, Regularization: 1.665730\n",
      "2019-04-09 22:41:43,220 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 792.835938\n",
      "Reconstruction: 791.368774, Regularization: 1.467169\n",
      "2019-04-09 22:41:43,276 root         INFO     Train Epoch: 48 [2560/8000 (32%)]\tTotal Loss: 16741.365234\n",
      "Reconstruction: 16738.996094, Regularization: 2.368237\n",
      "2019-04-09 22:41:43,332 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 304.268707\n",
      "Reconstruction: 303.204346, Regularization: 1.064356\n",
      "2019-04-09 22:41:43,389 root         INFO     Train Epoch: 48 [3584/8000 (45%)]\tTotal Loss: 1624.221069\n",
      "Reconstruction: 1623.210571, Regularization: 1.010453\n",
      "2019-04-09 22:41:43,445 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 280.018311\n",
      "Reconstruction: 278.257782, Regularization: 1.760543\n",
      "2019-04-09 22:41:43,501 root         INFO     Train Epoch: 48 [4608/8000 (58%)]\tTotal Loss: 88.285744\n",
      "Reconstruction: 87.074013, Regularization: 1.211732\n",
      "2019-04-09 22:41:43,556 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 135137072.000000\n",
      "Reconstruction: 135137072.000000, Regularization: 2.656390\n",
      "2019-04-09 22:41:43,612 root         INFO     Train Epoch: 48 [5632/8000 (70%)]\tTotal Loss: 102.126266\n",
      "Reconstruction: 100.677124, Regularization: 1.449145\n",
      "2019-04-09 22:41:43,667 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 7726.667969\n",
      "Reconstruction: 7725.441406, Regularization: 1.226772\n",
      "2019-04-09 22:41:43,723 root         INFO     Train Epoch: 48 [6656/8000 (83%)]\tTotal Loss: 1672.031250\n",
      "Reconstruction: 1670.146729, Regularization: 1.884549\n",
      "2019-04-09 22:41:43,780 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 128.957489\n",
      "Reconstruction: 128.015060, Regularization: 0.942422\n",
      "2019-04-09 22:41:43,837 root         INFO     Train Epoch: 48 [7680/8000 (96%)]\tTotal Loss: 258.527405\n",
      "Reconstruction: 257.371155, Regularization: 1.156258\n",
      "2019-04-09 22:41:43,886 root         INFO     ====> Epoch: 48 Average loss: 597859.4845\n",
      "2019-04-09 22:41:43,909 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 450.102234\n",
      "Reconstruction: 448.536041, Regularization: 1.566199\n",
      "2019-04-09 22:41:43,965 root         INFO     Train Epoch: 49 [512/8000 (6%)]\tTotal Loss: 449.483795\n",
      "Reconstruction: 447.452820, Regularization: 2.030987\n",
      "2019-04-09 22:41:44,022 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 73.010651\n",
      "Reconstruction: 71.740547, Regularization: 1.270105\n",
      "2019-04-09 22:41:44,078 root         INFO     Train Epoch: 49 [1536/8000 (19%)]\tTotal Loss: 474.813873\n",
      "Reconstruction: 472.979126, Regularization: 1.834739\n",
      "2019-04-09 22:41:44,134 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 1247.183594\n",
      "Reconstruction: 1245.626831, Regularization: 1.556752\n",
      "2019-04-09 22:41:44,190 root         INFO     Train Epoch: 49 [2560/8000 (32%)]\tTotal Loss: 300.640289\n",
      "Reconstruction: 298.987915, Regularization: 1.652367\n",
      "2019-04-09 22:41:44,246 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 1765.214478\n",
      "Reconstruction: 1763.560913, Regularization: 1.653576\n",
      "2019-04-09 22:41:44,302 root         INFO     Train Epoch: 49 [3584/8000 (45%)]\tTotal Loss: 28193.863281\n",
      "Reconstruction: 28191.597656, Regularization: 2.265784\n",
      "2019-04-09 22:41:44,358 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 98.224083\n",
      "Reconstruction: 97.165276, Regularization: 1.058808\n",
      "2019-04-09 22:41:44,413 root         INFO     Train Epoch: 49 [4608/8000 (58%)]\tTotal Loss: 539.678650\n",
      "Reconstruction: 538.400146, Regularization: 1.278524\n",
      "2019-04-09 22:41:44,469 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 21.278715\n",
      "Reconstruction: 19.927271, Regularization: 1.351445\n",
      "2019-04-09 22:41:44,525 root         INFO     Train Epoch: 49 [5632/8000 (70%)]\tTotal Loss: 22.257256\n",
      "Reconstruction: 20.408020, Regularization: 1.849235\n",
      "2019-04-09 22:41:44,580 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 1168813.500000\n",
      "Reconstruction: 1168811.125000, Regularization: 2.425916\n",
      "2019-04-09 22:41:44,635 root         INFO     Train Epoch: 49 [6656/8000 (83%)]\tTotal Loss: 199.122284\n",
      "Reconstruction: 197.010773, Regularization: 2.111504\n",
      "2019-04-09 22:41:44,690 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 134.154221\n",
      "Reconstruction: 133.114944, Regularization: 1.039281\n",
      "2019-04-09 22:41:44,745 root         INFO     Train Epoch: 49 [7680/8000 (96%)]\tTotal Loss: 42048.003906\n",
      "Reconstruction: 42046.496094, Regularization: 1.507189\n",
      "2019-04-09 22:41:44,794 root         INFO     ====> Epoch: 49 Average loss: 58835.3087\n",
      "2019-04-09 22:41:44,817 root         INFO     Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 869.463379\n",
      "Reconstruction: 868.140015, Regularization: 1.323362\n",
      "2019-04-09 22:41:44,874 root         INFO     Train Epoch: 50 [512/8000 (6%)]\tTotal Loss: 2477.690674\n",
      "Reconstruction: 2475.958008, Regularization: 1.732704\n",
      "2019-04-09 22:41:44,930 root         INFO     Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 2.556876\n",
      "Reconstruction: 1.557789, Regularization: 0.999087\n",
      "2019-04-09 22:41:44,986 root         INFO     Train Epoch: 50 [1536/8000 (19%)]\tTotal Loss: 4437.651367\n",
      "Reconstruction: 4434.964355, Regularization: 2.686866\n",
      "2019-04-09 22:41:45,042 root         INFO     Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 7165.830078\n",
      "Reconstruction: 7164.948730, Regularization: 0.881274\n",
      "2019-04-09 22:41:45,098 root         INFO     Train Epoch: 50 [2560/8000 (32%)]\tTotal Loss: 1285.708008\n",
      "Reconstruction: 1283.789917, Regularization: 1.918147\n",
      "2019-04-09 22:41:45,154 root         INFO     Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 430.402954\n",
      "Reconstruction: 429.361511, Regularization: 1.041451\n",
      "2019-04-09 22:41:45,210 root         INFO     Train Epoch: 50 [3584/8000 (45%)]\tTotal Loss: 242.299591\n",
      "Reconstruction: 240.618561, Regularization: 1.681023\n",
      "2019-04-09 22:41:45,266 root         INFO     Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 155.608398\n",
      "Reconstruction: 153.417450, Regularization: 2.190952\n",
      "2019-04-09 22:41:45,319 root         INFO     Train Epoch: 50 [4608/8000 (58%)]\tTotal Loss: 108.092522\n",
      "Reconstruction: 107.115616, Regularization: 0.976909\n",
      "2019-04-09 22:41:45,374 root         INFO     Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 37.731316\n",
      "Reconstruction: 36.158386, Regularization: 1.572929\n",
      "2019-04-09 22:41:45,429 root         INFO     Train Epoch: 50 [5632/8000 (70%)]\tTotal Loss: 1621.158081\n",
      "Reconstruction: 1619.515015, Regularization: 1.643062\n",
      "2019-04-09 22:41:45,482 root         INFO     Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 921.763367\n",
      "Reconstruction: 920.592896, Regularization: 1.170466\n",
      "2019-04-09 22:41:45,535 root         INFO     Train Epoch: 50 [6656/8000 (83%)]\tTotal Loss: 24.589504\n",
      "Reconstruction: 23.258608, Regularization: 1.330897\n",
      "2019-04-09 22:41:45,589 root         INFO     Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 8.497813\n",
      "Reconstruction: 7.455823, Regularization: 1.041989\n",
      "2019-04-09 22:41:45,643 root         INFO     Train Epoch: 50 [7680/8000 (96%)]\tTotal Loss: 37.710442\n",
      "Reconstruction: 36.265568, Regularization: 1.444875\n",
      "2019-04-09 22:41:45,692 root         INFO     ====> Epoch: 50 Average loss: 34747.2704\n",
      "2019-04-09 22:41:45,715 root         INFO     Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 11.608706\n",
      "Reconstruction: 9.743395, Regularization: 1.865310\n",
      "2019-04-09 22:41:45,770 root         INFO     Train Epoch: 51 [512/8000 (6%)]\tTotal Loss: 196462.203125\n",
      "Reconstruction: 196460.109375, Regularization: 2.100391\n",
      "2019-04-09 22:41:45,825 root         INFO     Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 47.055393\n",
      "Reconstruction: 45.428093, Regularization: 1.627302\n",
      "2019-04-09 22:41:45,881 root         INFO     Train Epoch: 51 [1536/8000 (19%)]\tTotal Loss: 24482.707031\n",
      "Reconstruction: 24480.753906, Regularization: 1.952896\n",
      "2019-04-09 22:41:45,935 root         INFO     Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 68923.406250\n",
      "Reconstruction: 68920.343750, Regularization: 3.062665\n",
      "2019-04-09 22:41:45,989 root         INFO     Train Epoch: 51 [2560/8000 (32%)]\tTotal Loss: 2714.724121\n",
      "Reconstruction: 2713.408447, Regularization: 1.315705\n",
      "2019-04-09 22:41:46,044 root         INFO     Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 179.116028\n",
      "Reconstruction: 177.586624, Regularization: 1.529407\n",
      "2019-04-09 22:41:46,099 root         INFO     Train Epoch: 51 [3584/8000 (45%)]\tTotal Loss: 2462.909912\n",
      "Reconstruction: 2461.268799, Regularization: 1.641176\n",
      "2019-04-09 22:41:46,153 root         INFO     Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 21.608824\n",
      "Reconstruction: 20.745468, Regularization: 0.863355\n",
      "2019-04-09 22:41:46,208 root         INFO     Train Epoch: 51 [4608/8000 (58%)]\tTotal Loss: 2213.364990\n",
      "Reconstruction: 2211.420654, Regularization: 1.944335\n",
      "2019-04-09 22:41:46,262 root         INFO     Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 12520.694336\n",
      "Reconstruction: 12519.118164, Regularization: 1.575751\n",
      "2019-04-09 22:41:46,317 root         INFO     Train Epoch: 51 [5632/8000 (70%)]\tTotal Loss: 11.367950\n",
      "Reconstruction: 10.153111, Regularization: 1.214840\n",
      "2019-04-09 22:41:46,371 root         INFO     Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 388.958618\n",
      "Reconstruction: 387.679749, Regularization: 1.278862\n",
      "2019-04-09 22:41:46,426 root         INFO     Train Epoch: 51 [6656/8000 (83%)]\tTotal Loss: 1770.406006\n",
      "Reconstruction: 1768.944458, Regularization: 1.461509\n",
      "2019-04-09 22:41:46,480 root         INFO     Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 187.214783\n",
      "Reconstruction: 185.561630, Regularization: 1.653154\n",
      "2019-04-09 22:41:46,534 root         INFO     Train Epoch: 51 [7680/8000 (96%)]\tTotal Loss: 6655.951172\n",
      "Reconstruction: 6652.624023, Regularization: 3.326940\n",
      "2019-04-09 22:41:46,583 root         INFO     ====> Epoch: 51 Average loss: 50978.6633\n",
      "2019-04-09 22:41:46,606 root         INFO     Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 58304.417969\n",
      "Reconstruction: 58302.500000, Regularization: 1.919103\n",
      "2019-04-09 22:41:46,661 root         INFO     Train Epoch: 52 [512/8000 (6%)]\tTotal Loss: 212373.390625\n",
      "Reconstruction: 212371.296875, Regularization: 2.095486\n",
      "2019-04-09 22:41:46,716 root         INFO     Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 104.223427\n",
      "Reconstruction: 102.872467, Regularization: 1.350960\n",
      "2019-04-09 22:41:46,770 root         INFO     Train Epoch: 52 [1536/8000 (19%)]\tTotal Loss: 7883.474121\n",
      "Reconstruction: 7881.675781, Regularization: 1.798371\n",
      "2019-04-09 22:41:46,825 root         INFO     Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 18.324299\n",
      "Reconstruction: 16.135740, Regularization: 2.188559\n",
      "2019-04-09 22:41:46,879 root         INFO     Train Epoch: 52 [2560/8000 (32%)]\tTotal Loss: 562.680786\n",
      "Reconstruction: 560.902710, Regularization: 1.778074\n",
      "2019-04-09 22:41:46,933 root         INFO     Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 2599.369141\n",
      "Reconstruction: 2597.396973, Regularization: 1.972152\n",
      "2019-04-09 22:41:46,988 root         INFO     Train Epoch: 52 [3584/8000 (45%)]\tTotal Loss: 182.041245\n",
      "Reconstruction: 180.014145, Regularization: 2.027105\n",
      "2019-04-09 22:41:47,042 root         INFO     Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 14102.713867\n",
      "Reconstruction: 14101.112305, Regularization: 1.602033\n",
      "2019-04-09 22:41:47,097 root         INFO     Train Epoch: 52 [4608/8000 (58%)]\tTotal Loss: 482.737305\n",
      "Reconstruction: 481.507111, Regularization: 1.230179\n",
      "2019-04-09 22:41:47,151 root         INFO     Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 686.193481\n",
      "Reconstruction: 685.192871, Regularization: 1.000600\n",
      "2019-04-09 22:41:47,206 root         INFO     Train Epoch: 52 [5632/8000 (70%)]\tTotal Loss: 10.984702\n",
      "Reconstruction: 9.432178, Regularization: 1.552525\n",
      "2019-04-09 22:41:47,259 root         INFO     Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 1457.706787\n",
      "Reconstruction: 1455.708008, Regularization: 1.998740\n",
      "2019-04-09 22:41:47,313 root         INFO     Train Epoch: 52 [6656/8000 (83%)]\tTotal Loss: 11.358525\n",
      "Reconstruction: 10.054712, Regularization: 1.303813\n",
      "2019-04-09 22:41:47,366 root         INFO     Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 767.544556\n",
      "Reconstruction: 766.302612, Regularization: 1.241925\n",
      "2019-04-09 22:41:47,421 root         INFO     Train Epoch: 52 [7680/8000 (96%)]\tTotal Loss: 77.201332\n",
      "Reconstruction: 75.623573, Regularization: 1.577759\n",
      "2019-04-09 22:41:47,470 root         INFO     ====> Epoch: 52 Average loss: 86255.4500\n",
      "2019-04-09 22:41:47,494 root         INFO     Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 94.718147\n",
      "Reconstruction: 93.335587, Regularization: 1.382559\n",
      "2019-04-09 22:41:47,550 root         INFO     Train Epoch: 53 [512/8000 (6%)]\tTotal Loss: 17.304087\n",
      "Reconstruction: 15.388090, Regularization: 1.915996\n",
      "2019-04-09 22:41:47,605 root         INFO     Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 21.642477\n",
      "Reconstruction: 19.773308, Regularization: 1.869169\n",
      "2019-04-09 22:41:47,660 root         INFO     Train Epoch: 53 [1536/8000 (19%)]\tTotal Loss: 43.340816\n",
      "Reconstruction: 41.713257, Regularization: 1.627561\n",
      "2019-04-09 22:41:47,716 root         INFO     Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 69.582504\n",
      "Reconstruction: 68.542099, Regularization: 1.040408\n",
      "2019-04-09 22:41:47,771 root         INFO     Train Epoch: 53 [2560/8000 (32%)]\tTotal Loss: 137515.593750\n",
      "Reconstruction: 137514.171875, Regularization: 1.415542\n",
      "2019-04-09 22:41:47,826 root         INFO     Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 297.539276\n",
      "Reconstruction: 295.978088, Regularization: 1.561186\n",
      "2019-04-09 22:41:47,882 root         INFO     Train Epoch: 53 [3584/8000 (45%)]\tTotal Loss: 10.463343\n",
      "Reconstruction: 8.828918, Regularization: 1.634425\n",
      "2019-04-09 22:41:47,937 root         INFO     Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 15.738020\n",
      "Reconstruction: 14.564680, Regularization: 1.173340\n",
      "2019-04-09 22:41:47,993 root         INFO     Train Epoch: 53 [4608/8000 (58%)]\tTotal Loss: 48.735619\n",
      "Reconstruction: 47.577873, Regularization: 1.157745\n",
      "2019-04-09 22:41:48,048 root         INFO     Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 95.219872\n",
      "Reconstruction: 94.389473, Regularization: 0.830398\n",
      "2019-04-09 22:41:48,104 root         INFO     Train Epoch: 53 [5632/8000 (70%)]\tTotal Loss: 2545.992920\n",
      "Reconstruction: 2544.684570, Regularization: 1.308448\n",
      "2019-04-09 22:41:48,159 root         INFO     Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 49.275990\n",
      "Reconstruction: 47.803669, Regularization: 1.472321\n",
      "2019-04-09 22:41:48,215 root         INFO     Train Epoch: 53 [6656/8000 (83%)]\tTotal Loss: 16.595863\n",
      "Reconstruction: 14.777782, Regularization: 1.818080\n",
      "2019-04-09 22:41:48,270 root         INFO     Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 1640.150269\n",
      "Reconstruction: 1638.744263, Regularization: 1.406025\n",
      "2019-04-09 22:41:48,326 root         INFO     Train Epoch: 53 [7680/8000 (96%)]\tTotal Loss: 386.691193\n",
      "Reconstruction: 385.146576, Regularization: 1.544619\n",
      "2019-04-09 22:41:48,375 root         INFO     ====> Epoch: 53 Average loss: 56787.1197\n",
      "2019-04-09 22:41:48,398 root         INFO     Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 123.074951\n",
      "Reconstruction: 121.536453, Regularization: 1.538496\n",
      "2019-04-09 22:41:48,452 root         INFO     Train Epoch: 54 [512/8000 (6%)]\tTotal Loss: 228.852341\n",
      "Reconstruction: 226.203995, Regularization: 2.648346\n",
      "2019-04-09 22:41:48,506 root         INFO     Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 401.642914\n",
      "Reconstruction: 399.933044, Regularization: 1.709874\n",
      "2019-04-09 22:41:48,561 root         INFO     Train Epoch: 54 [1536/8000 (19%)]\tTotal Loss: 95.902046\n",
      "Reconstruction: 94.183037, Regularization: 1.719007\n",
      "2019-04-09 22:41:48,615 root         INFO     Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 939.407654\n",
      "Reconstruction: 938.149719, Regularization: 1.257925\n",
      "2019-04-09 22:41:48,669 root         INFO     Train Epoch: 54 [2560/8000 (32%)]\tTotal Loss: 31467.626953\n",
      "Reconstruction: 31465.873047, Regularization: 1.753159\n",
      "2019-04-09 22:41:48,724 root         INFO     Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 10.713242\n",
      "Reconstruction: 9.204503, Regularization: 1.508738\n",
      "2019-04-09 22:41:48,778 root         INFO     Train Epoch: 54 [3584/8000 (45%)]\tTotal Loss: 75.261482\n",
      "Reconstruction: 73.357300, Regularization: 1.904180\n",
      "2019-04-09 22:41:48,833 root         INFO     Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 561.952087\n",
      "Reconstruction: 559.824036, Regularization: 2.128027\n",
      "2019-04-09 22:41:48,888 root         INFO     Train Epoch: 54 [4608/8000 (58%)]\tTotal Loss: 30874.039062\n",
      "Reconstruction: 30872.341797, Regularization: 1.697931\n",
      "2019-04-09 22:41:48,942 root         INFO     Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 1719.552246\n",
      "Reconstruction: 1717.969482, Regularization: 1.582814\n",
      "2019-04-09 22:41:48,996 root         INFO     Train Epoch: 54 [5632/8000 (70%)]\tTotal Loss: 202.927048\n",
      "Reconstruction: 201.523682, Regularization: 1.403366\n",
      "2019-04-09 22:41:49,049 root         INFO     Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 594.813171\n",
      "Reconstruction: 592.909546, Regularization: 1.903631\n",
      "2019-04-09 22:41:49,103 root         INFO     Train Epoch: 54 [6656/8000 (83%)]\tTotal Loss: 616087.187500\n",
      "Reconstruction: 616085.687500, Regularization: 1.518326\n",
      "2019-04-09 22:41:49,157 root         INFO     Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 974.732056\n",
      "Reconstruction: 973.055603, Regularization: 1.676481\n",
      "2019-04-09 22:41:49,210 root         INFO     Train Epoch: 54 [7680/8000 (96%)]\tTotal Loss: 27563.601562\n",
      "Reconstruction: 27561.929688, Regularization: 1.672279\n",
      "2019-04-09 22:41:49,259 root         INFO     ====> Epoch: 54 Average loss: 28392.4006\n",
      "2019-04-09 22:41:49,282 root         INFO     Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 618.726990\n",
      "Reconstruction: 617.424622, Regularization: 1.302387\n",
      "2019-04-09 22:41:49,337 root         INFO     Train Epoch: 55 [512/8000 (6%)]\tTotal Loss: 12896.911133\n",
      "Reconstruction: 12894.412109, Regularization: 2.499059\n",
      "2019-04-09 22:41:49,391 root         INFO     Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 53.005917\n",
      "Reconstruction: 52.002308, Regularization: 1.003608\n",
      "2019-04-09 22:41:49,445 root         INFO     Train Epoch: 55 [1536/8000 (19%)]\tTotal Loss: 8009.463379\n",
      "Reconstruction: 8008.308594, Regularization: 1.154650\n",
      "2019-04-09 22:41:49,499 root         INFO     Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 272.359650\n",
      "Reconstruction: 270.951447, Regularization: 1.408218\n",
      "2019-04-09 22:41:49,553 root         INFO     Train Epoch: 55 [2560/8000 (32%)]\tTotal Loss: 256.775574\n",
      "Reconstruction: 254.738846, Regularization: 2.036743\n",
      "2019-04-09 22:41:49,607 root         INFO     Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 350.559662\n",
      "Reconstruction: 349.334656, Regularization: 1.225000\n",
      "2019-04-09 22:41:49,661 root         INFO     Train Epoch: 55 [3584/8000 (45%)]\tTotal Loss: 24756.226562\n",
      "Reconstruction: 24754.390625, Regularization: 1.836615\n",
      "2019-04-09 22:41:49,716 root         INFO     Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 4385.206055\n",
      "Reconstruction: 4382.874023, Regularization: 2.332066\n",
      "2019-04-09 22:41:49,770 root         INFO     Train Epoch: 55 [4608/8000 (58%)]\tTotal Loss: 23.668011\n",
      "Reconstruction: 22.359650, Regularization: 1.308361\n",
      "2019-04-09 22:41:49,824 root         INFO     Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 56.249859\n",
      "Reconstruction: 55.341240, Regularization: 0.908617\n",
      "2019-04-09 22:41:49,878 root         INFO     Train Epoch: 55 [5632/8000 (70%)]\tTotal Loss: 961.130859\n",
      "Reconstruction: 959.897461, Regularization: 1.233418\n",
      "2019-04-09 22:41:49,932 root         INFO     Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 12.850732\n",
      "Reconstruction: 10.887100, Regularization: 1.963631\n",
      "2019-04-09 22:41:49,986 root         INFO     Train Epoch: 55 [6656/8000 (83%)]\tTotal Loss: 21485.529297\n",
      "Reconstruction: 21483.849609, Regularization: 1.679755\n",
      "2019-04-09 22:41:50,040 root         INFO     Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 41.805511\n",
      "Reconstruction: 40.363869, Regularization: 1.441642\n",
      "2019-04-09 22:41:50,094 root         INFO     Train Epoch: 55 [7680/8000 (96%)]\tTotal Loss: 8148.563965\n",
      "Reconstruction: 8146.777832, Regularization: 1.785963\n",
      "2019-04-09 22:41:50,142 root         INFO     ====> Epoch: 55 Average loss: 52554.4963\n",
      "2019-04-09 22:41:50,166 root         INFO     Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 179.123886\n",
      "Reconstruction: 177.800125, Regularization: 1.323762\n",
      "2019-04-09 22:41:50,221 root         INFO     Train Epoch: 56 [512/8000 (6%)]\tTotal Loss: 106.043762\n",
      "Reconstruction: 103.822205, Regularization: 2.221555\n",
      "2019-04-09 22:41:50,276 root         INFO     Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 36.915611\n",
      "Reconstruction: 35.788662, Regularization: 1.126950\n",
      "2019-04-09 22:41:50,330 root         INFO     Train Epoch: 56 [1536/8000 (19%)]\tTotal Loss: 21.036383\n",
      "Reconstruction: 19.016132, Regularization: 2.020251\n",
      "2019-04-09 22:41:50,385 root         INFO     Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 2094.593506\n",
      "Reconstruction: 2093.007568, Regularization: 1.585892\n",
      "2019-04-09 22:41:50,439 root         INFO     Train Epoch: 56 [2560/8000 (32%)]\tTotal Loss: 198.817734\n",
      "Reconstruction: 196.840363, Regularization: 1.977375\n",
      "2019-04-09 22:41:50,493 root         INFO     Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 594.990906\n",
      "Reconstruction: 593.666748, Regularization: 1.324186\n",
      "2019-04-09 22:41:50,547 root         INFO     Train Epoch: 56 [3584/8000 (45%)]\tTotal Loss: 6517.512207\n",
      "Reconstruction: 6515.897949, Regularization: 1.614373\n",
      "2019-04-09 22:41:50,601 root         INFO     Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 1817.418213\n",
      "Reconstruction: 1816.148560, Regularization: 1.269635\n",
      "2019-04-09 22:41:50,655 root         INFO     Train Epoch: 56 [4608/8000 (58%)]\tTotal Loss: 638.399048\n",
      "Reconstruction: 637.045776, Regularization: 1.353280\n",
      "2019-04-09 22:41:50,709 root         INFO     Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 49.125080\n",
      "Reconstruction: 48.502945, Regularization: 0.622136\n",
      "2019-04-09 22:41:50,763 root         INFO     Train Epoch: 56 [5632/8000 (70%)]\tTotal Loss: 30283.869141\n",
      "Reconstruction: 30282.388672, Regularization: 1.480363\n",
      "2019-04-09 22:41:50,819 root         INFO     Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 62162.992188\n",
      "Reconstruction: 62160.945312, Regularization: 2.048794\n",
      "2019-04-09 22:41:50,874 root         INFO     Train Epoch: 56 [6656/8000 (83%)]\tTotal Loss: 222.485092\n",
      "Reconstruction: 221.223145, Regularization: 1.261943\n",
      "2019-04-09 22:41:50,929 root         INFO     Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 124.904579\n",
      "Reconstruction: 122.926834, Regularization: 1.977741\n",
      "2019-04-09 22:41:50,984 root         INFO     Train Epoch: 56 [7680/8000 (96%)]\tTotal Loss: 145.637589\n",
      "Reconstruction: 144.329697, Regularization: 1.307890\n",
      "2019-04-09 22:41:51,033 root         INFO     ====> Epoch: 56 Average loss: 39572.4879\n",
      "2019-04-09 22:41:51,056 root         INFO     Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 598.026062\n",
      "Reconstruction: 596.323120, Regularization: 1.702950\n",
      "2019-04-09 22:41:51,112 root         INFO     Train Epoch: 57 [512/8000 (6%)]\tTotal Loss: 1003.652283\n",
      "Reconstruction: 1001.853638, Regularization: 1.798637\n",
      "2019-04-09 22:41:51,167 root         INFO     Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 62.418488\n",
      "Reconstruction: 60.810314, Regularization: 1.608171\n",
      "2019-04-09 22:41:51,223 root         INFO     Train Epoch: 57 [1536/8000 (19%)]\tTotal Loss: 65.518524\n",
      "Reconstruction: 64.692627, Regularization: 0.825899\n",
      "2019-04-09 22:41:51,279 root         INFO     Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 20672.527344\n",
      "Reconstruction: 20670.162109, Regularization: 2.364565\n",
      "2019-04-09 22:41:51,334 root         INFO     Train Epoch: 57 [2560/8000 (32%)]\tTotal Loss: 288.898560\n",
      "Reconstruction: 287.239197, Regularization: 1.659348\n",
      "2019-04-09 22:41:51,389 root         INFO     Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 2231.354736\n",
      "Reconstruction: 2229.448730, Regularization: 1.905910\n",
      "2019-04-09 22:41:51,444 root         INFO     Train Epoch: 57 [3584/8000 (45%)]\tTotal Loss: 76.845657\n",
      "Reconstruction: 75.702469, Regularization: 1.143192\n",
      "2019-04-09 22:41:51,500 root         INFO     Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 518.249634\n",
      "Reconstruction: 516.754456, Regularization: 1.495163\n",
      "2019-04-09 22:41:51,555 root         INFO     Train Epoch: 57 [4608/8000 (58%)]\tTotal Loss: 51993.277344\n",
      "Reconstruction: 51991.492188, Regularization: 1.783929\n",
      "2019-04-09 22:41:51,609 root         INFO     Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 1099.355469\n",
      "Reconstruction: 1097.337646, Regularization: 2.017847\n",
      "2019-04-09 22:41:51,663 root         INFO     Train Epoch: 57 [5632/8000 (70%)]\tTotal Loss: 48.812023\n",
      "Reconstruction: 47.134239, Regularization: 1.677785\n",
      "2019-04-09 22:41:51,717 root         INFO     Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 467.460968\n",
      "Reconstruction: 466.122650, Regularization: 1.338323\n",
      "2019-04-09 22:41:51,771 root         INFO     Train Epoch: 57 [6656/8000 (83%)]\tTotal Loss: 786.126038\n",
      "Reconstruction: 784.594421, Regularization: 1.531621\n",
      "2019-04-09 22:41:51,825 root         INFO     Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 190.928253\n",
      "Reconstruction: 189.654236, Regularization: 1.274020\n",
      "2019-04-09 22:41:51,879 root         INFO     Train Epoch: 57 [7680/8000 (96%)]\tTotal Loss: 363.234009\n",
      "Reconstruction: 361.683105, Regularization: 1.550912\n",
      "2019-04-09 22:41:51,928 root         INFO     ====> Epoch: 57 Average loss: 46996.9830\n",
      "2019-04-09 22:41:51,951 root         INFO     Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 187660.750000\n",
      "Reconstruction: 187658.062500, Regularization: 2.685728\n",
      "2019-04-09 22:41:52,005 root         INFO     Train Epoch: 58 [512/8000 (6%)]\tTotal Loss: 369.776062\n",
      "Reconstruction: 367.992554, Regularization: 1.783521\n",
      "2019-04-09 22:41:52,059 root         INFO     Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 190.820770\n",
      "Reconstruction: 189.140915, Regularization: 1.679858\n",
      "2019-04-09 22:41:52,113 root         INFO     Train Epoch: 58 [1536/8000 (19%)]\tTotal Loss: 474.752625\n",
      "Reconstruction: 473.319244, Regularization: 1.433373\n",
      "2019-04-09 22:41:52,166 root         INFO     Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 784709.625000\n",
      "Reconstruction: 784707.687500, Regularization: 1.956987\n",
      "2019-04-09 22:41:52,221 root         INFO     Train Epoch: 58 [2560/8000 (32%)]\tTotal Loss: 6.743399\n",
      "Reconstruction: 5.585931, Regularization: 1.157468\n",
      "2019-04-09 22:41:52,275 root         INFO     Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 35.104980\n",
      "Reconstruction: 33.385891, Regularization: 1.719089\n",
      "2019-04-09 22:41:52,329 root         INFO     Train Epoch: 58 [3584/8000 (45%)]\tTotal Loss: 1075.883667\n",
      "Reconstruction: 1074.258545, Regularization: 1.625149\n",
      "2019-04-09 22:41:52,383 root         INFO     Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 219.320999\n",
      "Reconstruction: 217.601944, Regularization: 1.719048\n",
      "2019-04-09 22:41:52,437 root         INFO     Train Epoch: 58 [4608/8000 (58%)]\tTotal Loss: 350731.343750\n",
      "Reconstruction: 350729.468750, Regularization: 1.860087\n",
      "2019-04-09 22:41:52,491 root         INFO     Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 10.109935\n",
      "Reconstruction: 8.756569, Regularization: 1.353366\n",
      "2019-04-09 22:41:52,546 root         INFO     Train Epoch: 58 [5632/8000 (70%)]\tTotal Loss: 456.674164\n",
      "Reconstruction: 454.874207, Regularization: 1.799963\n",
      "2019-04-09 22:41:52,601 root         INFO     Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 52.870243\n",
      "Reconstruction: 51.749607, Regularization: 1.120637\n",
      "2019-04-09 22:41:52,656 root         INFO     Train Epoch: 58 [6656/8000 (83%)]\tTotal Loss: 7.055275\n",
      "Reconstruction: 5.834075, Regularization: 1.221200\n",
      "2019-04-09 22:41:52,710 root         INFO     Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 507.070282\n",
      "Reconstruction: 504.212524, Regularization: 2.857752\n",
      "2019-04-09 22:41:52,765 root         INFO     Train Epoch: 58 [7680/8000 (96%)]\tTotal Loss: 44.654907\n",
      "Reconstruction: 43.168541, Regularization: 1.486366\n",
      "2019-04-09 22:41:52,815 root         INFO     ====> Epoch: 58 Average loss: 38028.9396\n",
      "2019-04-09 22:41:52,838 root         INFO     Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 11424.350586\n",
      "Reconstruction: 11422.787109, Regularization: 1.563152\n",
      "2019-04-09 22:41:52,894 root         INFO     Train Epoch: 59 [512/8000 (6%)]\tTotal Loss: 135.490753\n",
      "Reconstruction: 134.322235, Regularization: 1.168522\n",
      "2019-04-09 22:41:52,950 root         INFO     Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 2518.615723\n",
      "Reconstruction: 2516.288086, Regularization: 2.327589\n",
      "2019-04-09 22:41:53,005 root         INFO     Train Epoch: 59 [1536/8000 (19%)]\tTotal Loss: 112.831032\n",
      "Reconstruction: 111.392136, Regularization: 1.438897\n",
      "2019-04-09 22:41:53,061 root         INFO     Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 2.955341\n",
      "Reconstruction: 1.672516, Regularization: 1.282825\n",
      "2019-04-09 22:41:53,116 root         INFO     Train Epoch: 59 [2560/8000 (32%)]\tTotal Loss: 29.556732\n",
      "Reconstruction: 28.148787, Regularization: 1.407945\n",
      "2019-04-09 22:41:53,171 root         INFO     Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 62.324032\n",
      "Reconstruction: 60.854485, Regularization: 1.469545\n",
      "2019-04-09 22:41:53,227 root         INFO     Train Epoch: 59 [3584/8000 (45%)]\tTotal Loss: 1855.024536\n",
      "Reconstruction: 1853.600586, Regularization: 1.423990\n",
      "2019-04-09 22:41:53,282 root         INFO     Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 770.055664\n",
      "Reconstruction: 768.179871, Regularization: 1.875781\n",
      "2019-04-09 22:41:53,337 root         INFO     Train Epoch: 59 [4608/8000 (58%)]\tTotal Loss: 186822.156250\n",
      "Reconstruction: 186820.578125, Regularization: 1.576394\n",
      "2019-04-09 22:41:53,392 root         INFO     Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 2.365742\n",
      "Reconstruction: 0.687785, Regularization: 1.677957\n",
      "2019-04-09 22:41:53,447 root         INFO     Train Epoch: 59 [5632/8000 (70%)]\tTotal Loss: 5516.500488\n",
      "Reconstruction: 5514.710449, Regularization: 1.790274\n",
      "2019-04-09 22:41:53,503 root         INFO     Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 1291.190674\n",
      "Reconstruction: 1289.803101, Regularization: 1.387590\n",
      "2019-04-09 22:41:53,558 root         INFO     Train Epoch: 59 [6656/8000 (83%)]\tTotal Loss: 3.500485\n",
      "Reconstruction: 2.071147, Regularization: 1.429338\n",
      "2019-04-09 22:41:53,613 root         INFO     Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 140.619522\n",
      "Reconstruction: 139.531769, Regularization: 1.087746\n",
      "2019-04-09 22:41:53,668 root         INFO     Train Epoch: 59 [7680/8000 (96%)]\tTotal Loss: 131.273605\n",
      "Reconstruction: 130.001556, Regularization: 1.272042\n",
      "2019-04-09 22:41:53,717 root         INFO     ====> Epoch: 59 Average loss: 40034.0763\n",
      "2019-04-09 22:41:53,740 root         INFO     Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 866.652466\n",
      "Reconstruction: 865.653381, Regularization: 0.999071\n",
      "2019-04-09 22:41:53,796 root         INFO     Train Epoch: 60 [512/8000 (6%)]\tTotal Loss: 937.371948\n",
      "Reconstruction: 935.816284, Regularization: 1.555670\n",
      "2019-04-09 22:41:53,851 root         INFO     Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 84.108032\n",
      "Reconstruction: 82.717743, Regularization: 1.390289\n",
      "2019-04-09 22:41:53,906 root         INFO     Train Epoch: 60 [1536/8000 (19%)]\tTotal Loss: 2427.662842\n",
      "Reconstruction: 2424.919678, Regularization: 2.743071\n",
      "2019-04-09 22:41:53,962 root         INFO     Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 1223.155396\n",
      "Reconstruction: 1221.632690, Regularization: 1.522663\n",
      "2019-04-09 22:41:54,017 root         INFO     Train Epoch: 60 [2560/8000 (32%)]\tTotal Loss: 781.654907\n",
      "Reconstruction: 779.723206, Regularization: 1.931692\n",
      "2019-04-09 22:41:54,072 root         INFO     Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 1377.796143\n",
      "Reconstruction: 1375.958740, Regularization: 1.837458\n",
      "2019-04-09 22:41:54,128 root         INFO     Train Epoch: 60 [3584/8000 (45%)]\tTotal Loss: 14.312479\n",
      "Reconstruction: 12.693561, Regularization: 1.618919\n",
      "2019-04-09 22:41:54,183 root         INFO     Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 31640.166016\n",
      "Reconstruction: 31638.378906, Regularization: 1.786267\n",
      "2019-04-09 22:41:54,239 root         INFO     Train Epoch: 60 [4608/8000 (58%)]\tTotal Loss: 218.848022\n",
      "Reconstruction: 217.029144, Regularization: 1.818881\n",
      "2019-04-09 22:41:54,294 root         INFO     Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 1899.087524\n",
      "Reconstruction: 1896.872192, Regularization: 2.215293\n",
      "2019-04-09 22:41:54,349 root         INFO     Train Epoch: 60 [5632/8000 (70%)]\tTotal Loss: 224.459381\n",
      "Reconstruction: 221.985367, Regularization: 2.474020\n",
      "2019-04-09 22:41:54,405 root         INFO     Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 426.508484\n",
      "Reconstruction: 424.592865, Regularization: 1.915605\n",
      "2019-04-09 22:41:54,459 root         INFO     Train Epoch: 60 [6656/8000 (83%)]\tTotal Loss: 1450.507935\n",
      "Reconstruction: 1448.896606, Regularization: 1.611334\n",
      "2019-04-09 22:41:54,513 root         INFO     Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 238005.187500\n",
      "Reconstruction: 238002.921875, Regularization: 2.263502\n",
      "2019-04-09 22:41:54,568 root         INFO     Train Epoch: 60 [7680/8000 (96%)]\tTotal Loss: 3495.825928\n",
      "Reconstruction: 3493.882568, Regularization: 1.943271\n",
      "2019-04-09 22:41:54,616 root         INFO     ====> Epoch: 60 Average loss: 528672.7958\n",
      "2019-04-09 22:41:54,639 root         INFO     Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 44355.781250\n",
      "Reconstruction: 44353.652344, Regularization: 2.128754\n",
      "2019-04-09 22:41:54,693 root         INFO     Train Epoch: 61 [512/8000 (6%)]\tTotal Loss: 237.887146\n",
      "Reconstruction: 236.263535, Regularization: 1.623604\n",
      "2019-04-09 22:41:54,747 root         INFO     Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 643.422119\n",
      "Reconstruction: 642.118347, Regularization: 1.303798\n",
      "2019-04-09 22:41:54,802 root         INFO     Train Epoch: 61 [1536/8000 (19%)]\tTotal Loss: 83617.843750\n",
      "Reconstruction: 83615.585938, Regularization: 2.260598\n",
      "2019-04-09 22:41:54,856 root         INFO     Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 244.735657\n",
      "Reconstruction: 243.451538, Regularization: 1.284126\n",
      "2019-04-09 22:41:54,910 root         INFO     Train Epoch: 61 [2560/8000 (32%)]\tTotal Loss: 436.292786\n",
      "Reconstruction: 434.628510, Regularization: 1.664284\n",
      "2019-04-09 22:41:54,964 root         INFO     Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 2903.846924\n",
      "Reconstruction: 2902.229004, Regularization: 1.617962\n",
      "2019-04-09 22:41:55,018 root         INFO     Train Epoch: 61 [3584/8000 (45%)]\tTotal Loss: 544.834961\n",
      "Reconstruction: 543.096863, Regularization: 1.738072\n",
      "2019-04-09 22:41:55,072 root         INFO     Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 108.365852\n",
      "Reconstruction: 106.567688, Regularization: 1.798165\n",
      "2019-04-09 22:41:55,126 root         INFO     Train Epoch: 61 [4608/8000 (58%)]\tTotal Loss: 446.788940\n",
      "Reconstruction: 445.127411, Regularization: 1.661523\n",
      "2019-04-09 22:41:55,180 root         INFO     Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 1642.860352\n",
      "Reconstruction: 1641.251831, Regularization: 1.608489\n",
      "2019-04-09 22:41:55,235 root         INFO     Train Epoch: 61 [5632/8000 (70%)]\tTotal Loss: 203635.937500\n",
      "Reconstruction: 203632.812500, Regularization: 3.129169\n",
      "2019-04-09 22:41:55,290 root         INFO     Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 48.403130\n",
      "Reconstruction: 47.043137, Regularization: 1.359994\n",
      "2019-04-09 22:41:55,344 root         INFO     Train Epoch: 61 [6656/8000 (83%)]\tTotal Loss: 56.219524\n",
      "Reconstruction: 53.890465, Regularization: 2.329059\n",
      "2019-04-09 22:41:55,398 root         INFO     Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 2159.718994\n",
      "Reconstruction: 2157.121582, Regularization: 2.597527\n",
      "2019-04-09 22:41:55,452 root         INFO     Train Epoch: 61 [7680/8000 (96%)]\tTotal Loss: 1889.702271\n",
      "Reconstruction: 1888.028564, Regularization: 1.673656\n",
      "2019-04-09 22:41:55,500 root         INFO     ====> Epoch: 61 Average loss: 22888.9038\n",
      "2019-04-09 22:41:55,524 root         INFO     Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 33.808922\n",
      "Reconstruction: 32.012562, Regularization: 1.796362\n",
      "2019-04-09 22:41:55,580 root         INFO     Train Epoch: 62 [512/8000 (6%)]\tTotal Loss: 3382.166016\n",
      "Reconstruction: 3380.277344, Regularization: 1.888698\n",
      "2019-04-09 22:41:55,636 root         INFO     Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 32.803398\n",
      "Reconstruction: 31.540699, Regularization: 1.262700\n",
      "2019-04-09 22:41:55,691 root         INFO     Train Epoch: 62 [1536/8000 (19%)]\tTotal Loss: 428.722015\n",
      "Reconstruction: 427.432739, Regularization: 1.289266\n",
      "2019-04-09 22:41:55,746 root         INFO     Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 498.457703\n",
      "Reconstruction: 495.339142, Regularization: 3.118546\n",
      "2019-04-09 22:41:55,802 root         INFO     Train Epoch: 62 [2560/8000 (32%)]\tTotal Loss: 47787.292969\n",
      "Reconstruction: 47785.429688, Regularization: 1.862947\n",
      "2019-04-09 22:41:55,857 root         INFO     Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 10323.213867\n",
      "Reconstruction: 10322.112305, Regularization: 1.101221\n",
      "2019-04-09 22:41:55,912 root         INFO     Train Epoch: 62 [3584/8000 (45%)]\tTotal Loss: 609.697815\n",
      "Reconstruction: 607.499329, Regularization: 2.198506\n",
      "2019-04-09 22:41:55,968 root         INFO     Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 5073.062988\n",
      "Reconstruction: 5071.463379, Regularization: 1.599483\n",
      "2019-04-09 22:41:56,024 root         INFO     Train Epoch: 62 [4608/8000 (58%)]\tTotal Loss: 3083.829590\n",
      "Reconstruction: 3081.213623, Regularization: 2.616041\n",
      "2019-04-09 22:41:56,079 root         INFO     Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 3974.220215\n",
      "Reconstruction: 3972.749023, Regularization: 1.471073\n",
      "2019-04-09 22:41:56,134 root         INFO     Train Epoch: 62 [5632/8000 (70%)]\tTotal Loss: 147.147263\n",
      "Reconstruction: 145.459244, Regularization: 1.688016\n",
      "2019-04-09 22:41:56,189 root         INFO     Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 108.636444\n",
      "Reconstruction: 107.121094, Regularization: 1.515348\n",
      "2019-04-09 22:41:56,244 root         INFO     Train Epoch: 62 [6656/8000 (83%)]\tTotal Loss: 1078.210815\n",
      "Reconstruction: 1077.107788, Regularization: 1.103028\n",
      "2019-04-09 22:41:56,298 root         INFO     Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 155.153748\n",
      "Reconstruction: 153.610001, Regularization: 1.543749\n",
      "2019-04-09 22:41:56,351 root         INFO     Train Epoch: 62 [7680/8000 (96%)]\tTotal Loss: 16.506090\n",
      "Reconstruction: 14.791954, Regularization: 1.714136\n",
      "2019-04-09 22:41:56,400 root         INFO     ====> Epoch: 62 Average loss: 44604.2569\n",
      "2019-04-09 22:41:56,423 root         INFO     Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 2856.890869\n",
      "Reconstruction: 2854.489746, Regularization: 2.401070\n",
      "2019-04-09 22:41:56,480 root         INFO     Train Epoch: 63 [512/8000 (6%)]\tTotal Loss: 65034.683594\n",
      "Reconstruction: 65032.828125, Regularization: 1.855699\n",
      "2019-04-09 22:41:56,537 root         INFO     Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 44.753685\n",
      "Reconstruction: 43.453514, Regularization: 1.300171\n",
      "2019-04-09 22:41:56,593 root         INFO     Train Epoch: 63 [1536/8000 (19%)]\tTotal Loss: 309.019135\n",
      "Reconstruction: 307.659607, Regularization: 1.359530\n",
      "2019-04-09 22:41:56,649 root         INFO     Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 55.817524\n",
      "Reconstruction: 54.146027, Regularization: 1.671499\n",
      "2019-04-09 22:41:56,704 root         INFO     Train Epoch: 63 [2560/8000 (32%)]\tTotal Loss: 17.012955\n",
      "Reconstruction: 16.042967, Regularization: 0.969989\n",
      "2019-04-09 22:41:56,760 root         INFO     Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 53.425301\n",
      "Reconstruction: 51.469158, Regularization: 1.956144\n",
      "2019-04-09 22:41:56,815 root         INFO     Train Epoch: 63 [3584/8000 (45%)]\tTotal Loss: 233047.125000\n",
      "Reconstruction: 233045.515625, Regularization: 1.603888\n",
      "2019-04-09 22:41:56,870 root         INFO     Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 715.555908\n",
      "Reconstruction: 714.090210, Regularization: 1.465690\n",
      "2019-04-09 22:41:56,925 root         INFO     Train Epoch: 63 [4608/8000 (58%)]\tTotal Loss: 443.971680\n",
      "Reconstruction: 442.283386, Regularization: 1.688308\n",
      "2019-04-09 22:41:56,981 root         INFO     Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 43.822659\n",
      "Reconstruction: 42.484158, Regularization: 1.338500\n",
      "2019-04-09 22:41:57,036 root         INFO     Train Epoch: 63 [5632/8000 (70%)]\tTotal Loss: 50.709568\n",
      "Reconstruction: 48.677269, Regularization: 2.032298\n",
      "2019-04-09 22:41:57,091 root         INFO     Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 2.655814\n",
      "Reconstruction: 0.913443, Regularization: 1.742371\n",
      "2019-04-09 22:41:57,147 root         INFO     Train Epoch: 63 [6656/8000 (83%)]\tTotal Loss: 369.888000\n",
      "Reconstruction: 368.645020, Regularization: 1.242988\n",
      "2019-04-09 22:41:57,202 root         INFO     Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 423.750305\n",
      "Reconstruction: 421.791290, Regularization: 1.959013\n",
      "2019-04-09 22:41:57,258 root         INFO     Train Epoch: 63 [7680/8000 (96%)]\tTotal Loss: 151.351547\n",
      "Reconstruction: 149.623795, Regularization: 1.727745\n",
      "2019-04-09 22:41:57,307 root         INFO     ====> Epoch: 63 Average loss: 20311.6191\n",
      "2019-04-09 22:41:57,331 root         INFO     Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 137.382721\n",
      "Reconstruction: 134.792648, Regularization: 2.590080\n",
      "2019-04-09 22:41:57,389 root         INFO     Train Epoch: 64 [512/8000 (6%)]\tTotal Loss: 35.425812\n",
      "Reconstruction: 34.252285, Regularization: 1.173526\n",
      "2019-04-09 22:41:57,446 root         INFO     Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 101.827797\n",
      "Reconstruction: 100.161652, Regularization: 1.666148\n",
      "2019-04-09 22:41:57,502 root         INFO     Train Epoch: 64 [1536/8000 (19%)]\tTotal Loss: 629.641846\n",
      "Reconstruction: 628.161316, Regularization: 1.480507\n",
      "2019-04-09 22:41:57,560 root         INFO     Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 515.565979\n",
      "Reconstruction: 514.388794, Regularization: 1.177211\n",
      "2019-04-09 22:41:57,617 root         INFO     Train Epoch: 64 [2560/8000 (32%)]\tTotal Loss: 9.859588\n",
      "Reconstruction: 7.991801, Regularization: 1.867787\n",
      "2019-04-09 22:41:57,673 root         INFO     Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 692.872437\n",
      "Reconstruction: 691.662476, Regularization: 1.209982\n",
      "2019-04-09 22:41:57,730 root         INFO     Train Epoch: 64 [3584/8000 (45%)]\tTotal Loss: 15.830683\n",
      "Reconstruction: 14.119267, Regularization: 1.711416\n",
      "2019-04-09 22:41:57,787 root         INFO     Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 739.513489\n",
      "Reconstruction: 738.207336, Regularization: 1.306172\n",
      "2019-04-09 22:41:57,844 root         INFO     Train Epoch: 64 [4608/8000 (58%)]\tTotal Loss: 168.634750\n",
      "Reconstruction: 167.131180, Regularization: 1.503577\n",
      "2019-04-09 22:41:57,901 root         INFO     Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 147.192398\n",
      "Reconstruction: 144.860580, Regularization: 2.331813\n",
      "2019-04-09 22:41:57,957 root         INFO     Train Epoch: 64 [5632/8000 (70%)]\tTotal Loss: 1746.186890\n",
      "Reconstruction: 1744.687988, Regularization: 1.498858\n",
      "2019-04-09 22:41:58,014 root         INFO     Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 365.091827\n",
      "Reconstruction: 363.946106, Regularization: 1.145736\n",
      "2019-04-09 22:41:58,071 root         INFO     Train Epoch: 64 [6656/8000 (83%)]\tTotal Loss: 40.077610\n",
      "Reconstruction: 38.031013, Regularization: 2.046596\n",
      "2019-04-09 22:41:58,128 root         INFO     Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 1680.382690\n",
      "Reconstruction: 1678.550903, Regularization: 1.831800\n",
      "2019-04-09 22:41:58,185 root         INFO     Train Epoch: 64 [7680/8000 (96%)]\tTotal Loss: 45.393131\n",
      "Reconstruction: 43.520176, Regularization: 1.872956\n",
      "2019-04-09 22:41:58,235 root         INFO     ====> Epoch: 64 Average loss: 9066.4304\n",
      "2019-04-09 22:41:58,258 root         INFO     Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 3241.205566\n",
      "Reconstruction: 3239.772949, Regularization: 1.432672\n",
      "2019-04-09 22:41:58,315 root         INFO     Train Epoch: 65 [512/8000 (6%)]\tTotal Loss: 90748.960938\n",
      "Reconstruction: 90747.367188, Regularization: 1.591918\n",
      "2019-04-09 22:41:58,371 root         INFO     Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 47.750202\n",
      "Reconstruction: 46.549915, Regularization: 1.200287\n",
      "2019-04-09 22:41:58,428 root         INFO     Train Epoch: 65 [1536/8000 (19%)]\tTotal Loss: 989.492432\n",
      "Reconstruction: 987.539307, Regularization: 1.953124\n",
      "2019-04-09 22:41:58,484 root         INFO     Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 323.577271\n",
      "Reconstruction: 321.948273, Regularization: 1.628992\n",
      "2019-04-09 22:41:58,541 root         INFO     Train Epoch: 65 [2560/8000 (32%)]\tTotal Loss: 189.160446\n",
      "Reconstruction: 186.271118, Regularization: 2.889330\n",
      "2019-04-09 22:41:58,597 root         INFO     Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 92.285126\n",
      "Reconstruction: 90.893082, Regularization: 1.392043\n",
      "2019-04-09 22:41:58,653 root         INFO     Train Epoch: 65 [3584/8000 (45%)]\tTotal Loss: 824.807434\n",
      "Reconstruction: 822.978943, Regularization: 1.828501\n",
      "2019-04-09 22:41:58,709 root         INFO     Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 536.118103\n",
      "Reconstruction: 534.925293, Regularization: 1.192799\n",
      "2019-04-09 22:41:58,766 root         INFO     Train Epoch: 65 [4608/8000 (58%)]\tTotal Loss: 2292.920166\n",
      "Reconstruction: 2291.427246, Regularization: 1.492946\n",
      "2019-04-09 22:41:58,823 root         INFO     Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 7257.969238\n",
      "Reconstruction: 7255.798340, Regularization: 2.170660\n",
      "2019-04-09 22:41:58,879 root         INFO     Train Epoch: 65 [5632/8000 (70%)]\tTotal Loss: 1145.301392\n",
      "Reconstruction: 1143.609985, Regularization: 1.691446\n",
      "2019-04-09 22:41:58,936 root         INFO     Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 1134.201294\n",
      "Reconstruction: 1132.165527, Regularization: 2.035728\n",
      "2019-04-09 22:41:58,993 root         INFO     Train Epoch: 65 [6656/8000 (83%)]\tTotal Loss: 23921.583984\n",
      "Reconstruction: 23920.357422, Regularization: 1.226616\n",
      "2019-04-09 22:41:59,050 root         INFO     Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 479.413879\n",
      "Reconstruction: 478.268921, Regularization: 1.144952\n",
      "2019-04-09 22:41:59,106 root         INFO     Train Epoch: 65 [7680/8000 (96%)]\tTotal Loss: 37.887569\n",
      "Reconstruction: 36.649345, Regularization: 1.238225\n",
      "2019-04-09 22:41:59,157 root         INFO     ====> Epoch: 65 Average loss: 11252.3327\n",
      "2019-04-09 22:41:59,180 root         INFO     Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 229.108627\n",
      "Reconstruction: 227.152405, Regularization: 1.956222\n",
      "2019-04-09 22:41:59,237 root         INFO     Train Epoch: 66 [512/8000 (6%)]\tTotal Loss: 16.246855\n",
      "Reconstruction: 14.667109, Regularization: 1.579745\n",
      "2019-04-09 22:41:59,293 root         INFO     Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 298.620056\n",
      "Reconstruction: 296.214539, Regularization: 2.405525\n",
      "2019-04-09 22:41:59,350 root         INFO     Train Epoch: 66 [1536/8000 (19%)]\tTotal Loss: 172.083969\n",
      "Reconstruction: 171.073029, Regularization: 1.010944\n",
      "2019-04-09 22:41:59,407 root         INFO     Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 9484.795898\n",
      "Reconstruction: 9483.058594, Regularization: 1.737136\n",
      "2019-04-09 22:41:59,463 root         INFO     Train Epoch: 66 [2560/8000 (32%)]\tTotal Loss: 53.116379\n",
      "Reconstruction: 51.699699, Regularization: 1.416678\n",
      "2019-04-09 22:41:59,520 root         INFO     Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 3.981600\n",
      "Reconstruction: 2.600674, Regularization: 1.380926\n",
      "2019-04-09 22:41:59,576 root         INFO     Train Epoch: 66 [3584/8000 (45%)]\tTotal Loss: 454.942474\n",
      "Reconstruction: 452.897614, Regularization: 2.044861\n",
      "2019-04-09 22:41:59,633 root         INFO     Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 944.193115\n",
      "Reconstruction: 942.192261, Regularization: 2.000859\n",
      "2019-04-09 22:41:59,687 root         INFO     Train Epoch: 66 [4608/8000 (58%)]\tTotal Loss: 629.641968\n",
      "Reconstruction: 628.146606, Regularization: 1.495378\n",
      "2019-04-09 22:41:59,742 root         INFO     Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 6.634161\n",
      "Reconstruction: 5.708682, Regularization: 0.925479\n",
      "2019-04-09 22:41:59,797 root         INFO     Train Epoch: 66 [5632/8000 (70%)]\tTotal Loss: 77.434830\n",
      "Reconstruction: 76.230934, Regularization: 1.203898\n",
      "2019-04-09 22:41:59,852 root         INFO     Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 5086347.500000\n",
      "Reconstruction: 5086345.000000, Regularization: 2.284381\n",
      "2019-04-09 22:41:59,907 root         INFO     Train Epoch: 66 [6656/8000 (83%)]\tTotal Loss: 150.344101\n",
      "Reconstruction: 148.613998, Regularization: 1.730108\n",
      "2019-04-09 22:41:59,963 root         INFO     Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 9.091616\n",
      "Reconstruction: 8.287339, Regularization: 0.804276\n",
      "2019-04-09 22:42:00,018 root         INFO     Train Epoch: 66 [7680/8000 (96%)]\tTotal Loss: 425.030518\n",
      "Reconstruction: 423.888000, Regularization: 1.142506\n",
      "2019-04-09 22:42:00,067 root         INFO     ====> Epoch: 66 Average loss: 39928.4396\n",
      "2019-04-09 22:42:00,090 root         INFO     Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 42.269131\n",
      "Reconstruction: 40.804234, Regularization: 1.464896\n",
      "2019-04-09 22:42:00,147 root         INFO     Train Epoch: 67 [512/8000 (6%)]\tTotal Loss: 468.660065\n",
      "Reconstruction: 467.418823, Regularization: 1.241248\n",
      "2019-04-09 22:42:00,204 root         INFO     Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 410.043915\n",
      "Reconstruction: 409.027740, Regularization: 1.016183\n",
      "2019-04-09 22:42:00,258 root         INFO     Train Epoch: 67 [1536/8000 (19%)]\tTotal Loss: 5026.314941\n",
      "Reconstruction: 5024.280273, Regularization: 2.034807\n",
      "2019-04-09 22:42:00,315 root         INFO     Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 19.547424\n",
      "Reconstruction: 17.443895, Regularization: 2.103528\n",
      "2019-04-09 22:42:00,371 root         INFO     Train Epoch: 67 [2560/8000 (32%)]\tTotal Loss: 848.131653\n",
      "Reconstruction: 846.776001, Regularization: 1.355633\n",
      "2019-04-09 22:42:00,427 root         INFO     Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 47501.093750\n",
      "Reconstruction: 47498.867188, Regularization: 2.227761\n",
      "2019-04-09 22:42:00,482 root         INFO     Train Epoch: 67 [3584/8000 (45%)]\tTotal Loss: 563.157959\n",
      "Reconstruction: 562.037109, Regularization: 1.120873\n",
      "2019-04-09 22:42:00,538 root         INFO     Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 3732.451172\n",
      "Reconstruction: 3730.728271, Regularization: 1.722939\n",
      "2019-04-09 22:42:00,594 root         INFO     Train Epoch: 67 [4608/8000 (58%)]\tTotal Loss: 45.561337\n",
      "Reconstruction: 43.964188, Regularization: 1.597150\n",
      "2019-04-09 22:42:00,650 root         INFO     Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 32443.972656\n",
      "Reconstruction: 32441.742188, Regularization: 2.230185\n",
      "2019-04-09 22:42:00,706 root         INFO     Train Epoch: 67 [5632/8000 (70%)]\tTotal Loss: 16.983990\n",
      "Reconstruction: 15.584458, Regularization: 1.399530\n",
      "2019-04-09 22:42:00,762 root         INFO     Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 27.555830\n",
      "Reconstruction: 26.034328, Regularization: 1.521502\n",
      "2019-04-09 22:42:00,819 root         INFO     Train Epoch: 67 [6656/8000 (83%)]\tTotal Loss: 3950263.250000\n",
      "Reconstruction: 3950261.500000, Regularization: 1.840577\n",
      "2019-04-09 22:42:00,875 root         INFO     Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 62.968903\n",
      "Reconstruction: 60.603149, Regularization: 2.365752\n",
      "2019-04-09 22:42:00,931 root         INFO     Train Epoch: 67 [7680/8000 (96%)]\tTotal Loss: 65.211075\n",
      "Reconstruction: 63.903572, Regularization: 1.307504\n",
      "2019-04-09 22:42:00,980 root         INFO     ====> Epoch: 67 Average loss: 30204.6801\n",
      "2019-04-09 22:42:01,004 root         INFO     Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 388.648560\n",
      "Reconstruction: 386.955048, Regularization: 1.693500\n",
      "2019-04-09 22:42:01,061 root         INFO     Train Epoch: 68 [512/8000 (6%)]\tTotal Loss: 236.719681\n",
      "Reconstruction: 235.474182, Regularization: 1.245500\n",
      "2019-04-09 22:42:01,117 root         INFO     Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 335.718719\n",
      "Reconstruction: 333.890839, Regularization: 1.827879\n",
      "2019-04-09 22:42:01,174 root         INFO     Train Epoch: 68 [1536/8000 (19%)]\tTotal Loss: 103.311325\n",
      "Reconstruction: 101.922150, Regularization: 1.389177\n",
      "2019-04-09 22:42:01,230 root         INFO     Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 5.032608\n",
      "Reconstruction: 3.806986, Regularization: 1.225622\n",
      "2019-04-09 22:42:01,286 root         INFO     Train Epoch: 68 [2560/8000 (32%)]\tTotal Loss: 2.131541\n",
      "Reconstruction: 1.093073, Regularization: 1.038469\n",
      "2019-04-09 22:42:01,343 root         INFO     Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 1084.442505\n",
      "Reconstruction: 1082.719360, Regularization: 1.723118\n",
      "2019-04-09 22:42:01,399 root         INFO     Train Epoch: 68 [3584/8000 (45%)]\tTotal Loss: 19.942045\n",
      "Reconstruction: 18.618690, Regularization: 1.323354\n",
      "2019-04-09 22:42:01,455 root         INFO     Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 55.389004\n",
      "Reconstruction: 53.721725, Regularization: 1.667280\n",
      "2019-04-09 22:42:01,511 root         INFO     Train Epoch: 68 [4608/8000 (58%)]\tTotal Loss: 1336.630859\n",
      "Reconstruction: 1334.578857, Regularization: 2.051980\n",
      "2019-04-09 22:42:01,568 root         INFO     Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 234.583664\n",
      "Reconstruction: 233.193146, Regularization: 1.390519\n",
      "2019-04-09 22:42:01,623 root         INFO     Train Epoch: 68 [5632/8000 (70%)]\tTotal Loss: 8.086733\n",
      "Reconstruction: 7.211013, Regularization: 0.875720\n",
      "2019-04-09 22:42:01,679 root         INFO     Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 109.975632\n",
      "Reconstruction: 108.049652, Regularization: 1.925978\n",
      "2019-04-09 22:42:01,735 root         INFO     Train Epoch: 68 [6656/8000 (83%)]\tTotal Loss: 244.523682\n",
      "Reconstruction: 242.540497, Regularization: 1.983184\n",
      "2019-04-09 22:42:01,792 root         INFO     Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 73.341278\n",
      "Reconstruction: 70.643288, Regularization: 2.697994\n",
      "2019-04-09 22:42:01,848 root         INFO     Train Epoch: 68 [7680/8000 (96%)]\tTotal Loss: 234.605957\n",
      "Reconstruction: 233.166351, Regularization: 1.439599\n",
      "2019-04-09 22:42:01,897 root         INFO     ====> Epoch: 68 Average loss: 23093.0994\n",
      "2019-04-09 22:42:01,921 root         INFO     Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 88.077919\n",
      "Reconstruction: 85.953430, Regularization: 2.124487\n",
      "2019-04-09 22:42:01,977 root         INFO     Train Epoch: 69 [512/8000 (6%)]\tTotal Loss: 592.272766\n",
      "Reconstruction: 591.108704, Regularization: 1.164046\n",
      "2019-04-09 22:42:02,033 root         INFO     Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 325.415436\n",
      "Reconstruction: 323.826416, Regularization: 1.589021\n",
      "2019-04-09 22:42:02,088 root         INFO     Train Epoch: 69 [1536/8000 (19%)]\tTotal Loss: 116.589211\n",
      "Reconstruction: 115.166763, Regularization: 1.422445\n",
      "2019-04-09 22:42:02,142 root         INFO     Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 385.154999\n",
      "Reconstruction: 383.764252, Regularization: 1.390744\n",
      "2019-04-09 22:42:02,197 root         INFO     Train Epoch: 69 [2560/8000 (32%)]\tTotal Loss: 14613.629883\n",
      "Reconstruction: 14611.728516, Regularization: 1.901853\n",
      "2019-04-09 22:42:02,252 root         INFO     Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 53.845448\n",
      "Reconstruction: 52.839993, Regularization: 1.005455\n",
      "2019-04-09 22:42:02,307 root         INFO     Train Epoch: 69 [3584/8000 (45%)]\tTotal Loss: 2426.502197\n",
      "Reconstruction: 2424.795654, Regularization: 1.706479\n",
      "2019-04-09 22:42:02,362 root         INFO     Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 10451.318359\n",
      "Reconstruction: 10448.796875, Regularization: 2.521224\n",
      "2019-04-09 22:42:02,417 root         INFO     Train Epoch: 69 [4608/8000 (58%)]\tTotal Loss: 33.788525\n",
      "Reconstruction: 32.130871, Regularization: 1.657653\n",
      "2019-04-09 22:42:02,472 root         INFO     Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 211.213043\n",
      "Reconstruction: 209.886734, Regularization: 1.326306\n",
      "2019-04-09 22:42:02,527 root         INFO     Train Epoch: 69 [5632/8000 (70%)]\tTotal Loss: 4431.761719\n",
      "Reconstruction: 4429.839844, Regularization: 1.921856\n",
      "2019-04-09 22:42:02,582 root         INFO     Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 70.624763\n",
      "Reconstruction: 69.107727, Regularization: 1.517037\n",
      "2019-04-09 22:42:02,636 root         INFO     Train Epoch: 69 [6656/8000 (83%)]\tTotal Loss: 4308.390625\n",
      "Reconstruction: 4306.835938, Regularization: 1.554680\n",
      "2019-04-09 22:42:02,691 root         INFO     Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 161.879547\n",
      "Reconstruction: 160.036224, Regularization: 1.843318\n",
      "2019-04-09 22:42:02,745 root         INFO     Train Epoch: 69 [7680/8000 (96%)]\tTotal Loss: 54.058731\n",
      "Reconstruction: 52.164097, Regularization: 1.894635\n",
      "2019-04-09 22:42:02,794 root         INFO     ====> Epoch: 69 Average loss: 15859.2608\n",
      "2019-04-09 22:42:02,818 root         INFO     Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 18.713161\n",
      "Reconstruction: 16.598888, Regularization: 2.114274\n",
      "2019-04-09 22:42:02,874 root         INFO     Train Epoch: 70 [512/8000 (6%)]\tTotal Loss: 495.375916\n",
      "Reconstruction: 493.821930, Regularization: 1.553982\n",
      "2019-04-09 22:42:02,931 root         INFO     Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 183.342560\n",
      "Reconstruction: 181.633408, Regularization: 1.709154\n",
      "2019-04-09 22:42:02,987 root         INFO     Train Epoch: 70 [1536/8000 (19%)]\tTotal Loss: 113.898598\n",
      "Reconstruction: 111.921265, Regularization: 1.977337\n",
      "2019-04-09 22:42:03,043 root         INFO     Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 16.593706\n",
      "Reconstruction: 14.247322, Regularization: 2.346384\n",
      "2019-04-09 22:42:03,100 root         INFO     Train Epoch: 70 [2560/8000 (32%)]\tTotal Loss: 38.707268\n",
      "Reconstruction: 37.116611, Regularization: 1.590655\n",
      "2019-04-09 22:42:03,156 root         INFO     Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 69.790352\n",
      "Reconstruction: 68.091980, Regularization: 1.698373\n",
      "2019-04-09 22:42:03,212 root         INFO     Train Epoch: 70 [3584/8000 (45%)]\tTotal Loss: 20.162241\n",
      "Reconstruction: 18.602509, Regularization: 1.559733\n",
      "2019-04-09 22:42:03,268 root         INFO     Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 3.922466\n",
      "Reconstruction: 2.245886, Regularization: 1.676580\n",
      "2019-04-09 22:42:03,324 root         INFO     Train Epoch: 70 [4608/8000 (58%)]\tTotal Loss: 136.101898\n",
      "Reconstruction: 134.053879, Regularization: 2.048018\n",
      "2019-04-09 22:42:03,379 root         INFO     Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 216.129242\n",
      "Reconstruction: 214.605972, Regularization: 1.523277\n",
      "2019-04-09 22:42:03,433 root         INFO     Train Epoch: 70 [5632/8000 (70%)]\tTotal Loss: 58.061180\n",
      "Reconstruction: 57.266029, Regularization: 0.795149\n",
      "2019-04-09 22:42:03,488 root         INFO     Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 997.407532\n",
      "Reconstruction: 996.033630, Regularization: 1.373921\n",
      "2019-04-09 22:42:03,543 root         INFO     Train Epoch: 70 [6656/8000 (83%)]\tTotal Loss: 276.610321\n",
      "Reconstruction: 274.679810, Regularization: 1.930499\n",
      "2019-04-09 22:42:03,598 root         INFO     Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 589.757141\n",
      "Reconstruction: 587.521484, Regularization: 2.235634\n",
      "2019-04-09 22:42:03,653 root         INFO     Train Epoch: 70 [7680/8000 (96%)]\tTotal Loss: 66.439217\n",
      "Reconstruction: 65.158287, Regularization: 1.280927\n",
      "2019-04-09 22:42:03,701 root         INFO     ====> Epoch: 70 Average loss: 28092.2013\n",
      "2019-04-09 22:42:03,724 root         INFO     Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 55.930119\n",
      "Reconstruction: 54.344650, Regularization: 1.585467\n",
      "2019-04-09 22:42:03,779 root         INFO     Train Epoch: 71 [512/8000 (6%)]\tTotal Loss: 27787.316406\n",
      "Reconstruction: 27784.591797, Regularization: 2.724505\n",
      "2019-04-09 22:42:03,834 root         INFO     Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 3790.344971\n",
      "Reconstruction: 3788.706787, Regularization: 1.638241\n",
      "2019-04-09 22:42:03,888 root         INFO     Train Epoch: 71 [1536/8000 (19%)]\tTotal Loss: 229.137344\n",
      "Reconstruction: 227.469467, Regularization: 1.667884\n",
      "2019-04-09 22:42:03,943 root         INFO     Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 104.202477\n",
      "Reconstruction: 102.384979, Regularization: 1.817496\n",
      "2019-04-09 22:42:03,997 root         INFO     Train Epoch: 71 [2560/8000 (32%)]\tTotal Loss: 58.444447\n",
      "Reconstruction: 57.207253, Regularization: 1.237196\n",
      "2019-04-09 22:42:04,051 root         INFO     Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 12.756640\n",
      "Reconstruction: 10.985595, Regularization: 1.771046\n",
      "2019-04-09 22:42:04,105 root         INFO     Train Epoch: 71 [3584/8000 (45%)]\tTotal Loss: 46.878162\n",
      "Reconstruction: 45.556824, Regularization: 1.321338\n",
      "2019-04-09 22:42:04,159 root         INFO     Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 155.909836\n",
      "Reconstruction: 154.139023, Regularization: 1.770819\n",
      "2019-04-09 22:42:04,213 root         INFO     Train Epoch: 71 [4608/8000 (58%)]\tTotal Loss: 74.097694\n",
      "Reconstruction: 73.228058, Regularization: 0.869635\n",
      "2019-04-09 22:42:04,267 root         INFO     Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 51.070896\n",
      "Reconstruction: 49.830517, Regularization: 1.240378\n",
      "2019-04-09 22:42:04,322 root         INFO     Train Epoch: 71 [5632/8000 (70%)]\tTotal Loss: 162.204758\n",
      "Reconstruction: 159.939850, Regularization: 2.264909\n",
      "2019-04-09 22:42:04,376 root         INFO     Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 9299.875977\n",
      "Reconstruction: 9298.062500, Regularization: 1.813504\n",
      "2019-04-09 22:42:04,431 root         INFO     Train Epoch: 71 [6656/8000 (83%)]\tTotal Loss: 3505.701904\n",
      "Reconstruction: 3503.704590, Regularization: 1.997204\n",
      "2019-04-09 22:42:04,485 root         INFO     Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 1116.736084\n",
      "Reconstruction: 1114.888184, Regularization: 1.847854\n",
      "2019-04-09 22:42:04,541 root         INFO     Train Epoch: 71 [7680/8000 (96%)]\tTotal Loss: 13.784108\n",
      "Reconstruction: 11.985540, Regularization: 1.798568\n",
      "2019-04-09 22:42:04,591 root         INFO     ====> Epoch: 71 Average loss: 21438.9227\n",
      "2019-04-09 22:42:04,615 root         INFO     Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 13.711973\n",
      "Reconstruction: 12.215825, Regularization: 1.496148\n",
      "2019-04-09 22:42:04,672 root         INFO     Train Epoch: 72 [512/8000 (6%)]\tTotal Loss: 304.388031\n",
      "Reconstruction: 303.453094, Regularization: 0.934938\n",
      "2019-04-09 22:42:04,728 root         INFO     Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 8.420874\n",
      "Reconstruction: 7.061928, Regularization: 1.358945\n",
      "2019-04-09 22:42:04,785 root         INFO     Train Epoch: 72 [1536/8000 (19%)]\tTotal Loss: 1181.868530\n",
      "Reconstruction: 1180.303589, Regularization: 1.564910\n",
      "2019-04-09 22:42:04,842 root         INFO     Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 149.062943\n",
      "Reconstruction: 146.963303, Regularization: 2.099635\n",
      "2019-04-09 22:42:04,898 root         INFO     Train Epoch: 72 [2560/8000 (32%)]\tTotal Loss: 656.901855\n",
      "Reconstruction: 654.711243, Regularization: 2.190642\n",
      "2019-04-09 22:42:04,954 root         INFO     Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 6.004353\n",
      "Reconstruction: 4.653486, Regularization: 1.350867\n",
      "2019-04-09 22:42:05,010 root         INFO     Train Epoch: 72 [3584/8000 (45%)]\tTotal Loss: 120699.398438\n",
      "Reconstruction: 120697.148438, Regularization: 2.246243\n",
      "2019-04-09 22:42:05,065 root         INFO     Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 495.454437\n",
      "Reconstruction: 494.018097, Regularization: 1.436330\n",
      "2019-04-09 22:42:05,121 root         INFO     Train Epoch: 72 [4608/8000 (58%)]\tTotal Loss: 248.481003\n",
      "Reconstruction: 247.102371, Regularization: 1.378636\n",
      "2019-04-09 22:42:05,176 root         INFO     Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 33.170918\n",
      "Reconstruction: 31.635838, Regularization: 1.535081\n",
      "2019-04-09 22:42:05,231 root         INFO     Train Epoch: 72 [5632/8000 (70%)]\tTotal Loss: 8.644297\n",
      "Reconstruction: 7.629228, Regularization: 1.015069\n",
      "2019-04-09 22:42:05,286 root         INFO     Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 17489.806641\n",
      "Reconstruction: 17487.777344, Regularization: 2.029495\n",
      "2019-04-09 22:42:05,341 root         INFO     Train Epoch: 72 [6656/8000 (83%)]\tTotal Loss: 102.066711\n",
      "Reconstruction: 100.979225, Regularization: 1.087484\n",
      "2019-04-09 22:42:05,396 root         INFO     Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 35.691341\n",
      "Reconstruction: 34.278049, Regularization: 1.413291\n",
      "2019-04-09 22:42:05,451 root         INFO     Train Epoch: 72 [7680/8000 (96%)]\tTotal Loss: 3.323095\n",
      "Reconstruction: 1.791734, Regularization: 1.531361\n",
      "2019-04-09 22:42:05,500 root         INFO     ====> Epoch: 72 Average loss: 7259.1910\n",
      "2019-04-09 22:42:05,523 root         INFO     Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 115.900925\n",
      "Reconstruction: 114.147491, Regularization: 1.753437\n",
      "2019-04-09 22:42:05,579 root         INFO     Train Epoch: 73 [512/8000 (6%)]\tTotal Loss: 117.271935\n",
      "Reconstruction: 115.298500, Regularization: 1.973431\n",
      "2019-04-09 22:42:05,636 root         INFO     Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 40.969501\n",
      "Reconstruction: 38.926125, Regularization: 2.043378\n",
      "2019-04-09 22:42:05,692 root         INFO     Train Epoch: 73 [1536/8000 (19%)]\tTotal Loss: 48.160164\n",
      "Reconstruction: 46.865585, Regularization: 1.294578\n",
      "2019-04-09 22:42:05,748 root         INFO     Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 1543.313721\n",
      "Reconstruction: 1542.158203, Regularization: 1.155529\n",
      "2019-04-09 22:42:05,804 root         INFO     Train Epoch: 73 [2560/8000 (32%)]\tTotal Loss: 21.315840\n",
      "Reconstruction: 20.365833, Regularization: 0.950006\n",
      "2019-04-09 22:42:05,860 root         INFO     Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 1469.046631\n",
      "Reconstruction: 1467.546509, Regularization: 1.500155\n",
      "2019-04-09 22:42:05,916 root         INFO     Train Epoch: 73 [3584/8000 (45%)]\tTotal Loss: 91.286194\n",
      "Reconstruction: 89.409607, Regularization: 1.876586\n",
      "2019-04-09 22:42:05,972 root         INFO     Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 421.403717\n",
      "Reconstruction: 419.279449, Regularization: 2.124264\n",
      "2019-04-09 22:42:06,028 root         INFO     Train Epoch: 73 [4608/8000 (58%)]\tTotal Loss: 19.422262\n",
      "Reconstruction: 18.074762, Regularization: 1.347500\n",
      "2019-04-09 22:42:06,083 root         INFO     Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 46.986652\n",
      "Reconstruction: 45.431702, Regularization: 1.554953\n",
      "2019-04-09 22:42:06,140 root         INFO     Train Epoch: 73 [5632/8000 (70%)]\tTotal Loss: 708.727783\n",
      "Reconstruction: 707.183350, Regularization: 1.544430\n",
      "2019-04-09 22:42:06,195 root         INFO     Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 25392.101562\n",
      "Reconstruction: 25390.173828, Regularization: 1.928552\n",
      "2019-04-09 22:42:06,251 root         INFO     Train Epoch: 73 [6656/8000 (83%)]\tTotal Loss: 176.527710\n",
      "Reconstruction: 175.023453, Regularization: 1.504259\n",
      "2019-04-09 22:42:06,307 root         INFO     Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 3327.654053\n",
      "Reconstruction: 3325.867920, Regularization: 1.786041\n",
      "2019-04-09 22:42:06,363 root         INFO     Train Epoch: 73 [7680/8000 (96%)]\tTotal Loss: 40261.183594\n",
      "Reconstruction: 40259.546875, Regularization: 1.636166\n",
      "2019-04-09 22:42:06,413 root         INFO     ====> Epoch: 73 Average loss: 24749.1947\n",
      "2019-04-09 22:42:06,437 root         INFO     Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 367.482758\n",
      "Reconstruction: 365.853027, Regularization: 1.629740\n",
      "2019-04-09 22:42:06,494 root         INFO     Train Epoch: 74 [512/8000 (6%)]\tTotal Loss: 63594.824219\n",
      "Reconstruction: 63592.875000, Regularization: 1.947473\n",
      "2019-04-09 22:42:06,551 root         INFO     Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 41.452301\n",
      "Reconstruction: 39.906754, Regularization: 1.545547\n",
      "2019-04-09 22:42:06,607 root         INFO     Train Epoch: 74 [1536/8000 (19%)]\tTotal Loss: 3649.404785\n",
      "Reconstruction: 3647.139893, Regularization: 2.264832\n",
      "2019-04-09 22:42:06,662 root         INFO     Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 1758.104980\n",
      "Reconstruction: 1756.368408, Regularization: 1.736608\n",
      "2019-04-09 22:42:06,719 root         INFO     Train Epoch: 74 [2560/8000 (32%)]\tTotal Loss: 72.586555\n",
      "Reconstruction: 71.331467, Regularization: 1.255085\n",
      "2019-04-09 22:42:06,774 root         INFO     Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 283.205658\n",
      "Reconstruction: 281.771729, Regularization: 1.433944\n",
      "2019-04-09 22:42:06,830 root         INFO     Train Epoch: 74 [3584/8000 (45%)]\tTotal Loss: 154.848999\n",
      "Reconstruction: 153.567352, Regularization: 1.281643\n",
      "2019-04-09 22:42:06,885 root         INFO     Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 739.875000\n",
      "Reconstruction: 738.107971, Regularization: 1.767041\n",
      "2019-04-09 22:42:06,940 root         INFO     Train Epoch: 74 [4608/8000 (58%)]\tTotal Loss: 648.326294\n",
      "Reconstruction: 646.728455, Regularization: 1.597830\n",
      "2019-04-09 22:42:06,994 root         INFO     Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 197.863510\n",
      "Reconstruction: 196.502304, Regularization: 1.361207\n",
      "2019-04-09 22:42:07,048 root         INFO     Train Epoch: 74 [5632/8000 (70%)]\tTotal Loss: 6212.338379\n",
      "Reconstruction: 6210.290039, Regularization: 2.048342\n",
      "2019-04-09 22:42:07,102 root         INFO     Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 27.413496\n",
      "Reconstruction: 24.994436, Regularization: 2.419060\n",
      "2019-04-09 22:42:07,156 root         INFO     Train Epoch: 74 [6656/8000 (83%)]\tTotal Loss: 1873.145752\n",
      "Reconstruction: 1871.016846, Regularization: 2.128877\n",
      "2019-04-09 22:42:07,209 root         INFO     Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 966.542725\n",
      "Reconstruction: 964.942261, Regularization: 1.600446\n",
      "2019-04-09 22:42:07,263 root         INFO     Train Epoch: 74 [7680/8000 (96%)]\tTotal Loss: 1523.754517\n",
      "Reconstruction: 1522.376221, Regularization: 1.378344\n",
      "2019-04-09 22:42:07,311 root         INFO     ====> Epoch: 74 Average loss: 20929.9243\n",
      "2019-04-09 22:42:07,335 root         INFO     Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 54579.046875\n",
      "Reconstruction: 54576.996094, Regularization: 2.049839\n",
      "2019-04-09 22:42:07,390 root         INFO     Train Epoch: 75 [512/8000 (6%)]\tTotal Loss: 1026.700073\n",
      "Reconstruction: 1025.292603, Regularization: 1.407478\n",
      "2019-04-09 22:42:07,446 root         INFO     Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 2.712987\n",
      "Reconstruction: 0.823914, Regularization: 1.889073\n",
      "2019-04-09 22:42:07,503 root         INFO     Train Epoch: 75 [1536/8000 (19%)]\tTotal Loss: 15683.433594\n",
      "Reconstruction: 15681.751953, Regularization: 1.682107\n",
      "2019-04-09 22:42:07,559 root         INFO     Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 20.904221\n",
      "Reconstruction: 19.693718, Regularization: 1.210502\n",
      "2019-04-09 22:42:07,613 root         INFO     Train Epoch: 75 [2560/8000 (32%)]\tTotal Loss: 406.885010\n",
      "Reconstruction: 405.602661, Regularization: 1.282346\n",
      "2019-04-09 22:42:07,666 root         INFO     Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 2.440817\n",
      "Reconstruction: 1.683131, Regularization: 0.757687\n",
      "2019-04-09 22:42:07,720 root         INFO     Train Epoch: 75 [3584/8000 (45%)]\tTotal Loss: 418.852539\n",
      "Reconstruction: 416.799438, Regularization: 2.053097\n",
      "2019-04-09 22:42:07,774 root         INFO     Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 46.314697\n",
      "Reconstruction: 44.738495, Regularization: 1.576203\n",
      "2019-04-09 22:42:07,827 root         INFO     Train Epoch: 75 [4608/8000 (58%)]\tTotal Loss: 445.858948\n",
      "Reconstruction: 444.406921, Regularization: 1.452037\n",
      "2019-04-09 22:42:07,881 root         INFO     Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 352.845032\n",
      "Reconstruction: 351.742279, Regularization: 1.102762\n",
      "2019-04-09 22:42:07,934 root         INFO     Train Epoch: 75 [5632/8000 (70%)]\tTotal Loss: 289.261688\n",
      "Reconstruction: 288.143402, Regularization: 1.118279\n",
      "2019-04-09 22:42:07,988 root         INFO     Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 4.425204\n",
      "Reconstruction: 2.558229, Regularization: 1.866975\n",
      "2019-04-09 22:42:08,041 root         INFO     Train Epoch: 75 [6656/8000 (83%)]\tTotal Loss: 485.479828\n",
      "Reconstruction: 483.860809, Regularization: 1.619017\n",
      "2019-04-09 22:42:08,095 root         INFO     Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 359.148315\n",
      "Reconstruction: 356.696960, Regularization: 2.451347\n",
      "2019-04-09 22:42:08,150 root         INFO     Train Epoch: 75 [7680/8000 (96%)]\tTotal Loss: 23.314939\n",
      "Reconstruction: 21.852365, Regularization: 1.462574\n",
      "2019-04-09 22:42:08,200 root         INFO     ====> Epoch: 75 Average loss: 34892.3313\n",
      "2019-04-09 22:42:08,223 root         INFO     Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 57.207939\n",
      "Reconstruction: 55.257214, Regularization: 1.950725\n",
      "2019-04-09 22:42:08,279 root         INFO     Train Epoch: 76 [512/8000 (6%)]\tTotal Loss: 1202.828613\n",
      "Reconstruction: 1200.903809, Regularization: 1.924833\n",
      "2019-04-09 22:42:08,335 root         INFO     Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 1900.845703\n",
      "Reconstruction: 1898.674438, Regularization: 2.171314\n",
      "2019-04-09 22:42:08,392 root         INFO     Train Epoch: 76 [1536/8000 (19%)]\tTotal Loss: 4.922837\n",
      "Reconstruction: 3.842106, Regularization: 1.080731\n",
      "2019-04-09 22:42:08,448 root         INFO     Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 2994.959961\n",
      "Reconstruction: 2993.415527, Regularization: 1.544368\n",
      "2019-04-09 22:42:08,504 root         INFO     Train Epoch: 76 [2560/8000 (32%)]\tTotal Loss: 16705.302734\n",
      "Reconstruction: 16703.369141, Regularization: 1.933623\n",
      "2019-04-09 22:42:08,560 root         INFO     Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 579.640747\n",
      "Reconstruction: 577.468140, Regularization: 2.172634\n",
      "2019-04-09 22:42:08,617 root         INFO     Train Epoch: 76 [3584/8000 (45%)]\tTotal Loss: 1564.075684\n",
      "Reconstruction: 1562.703125, Regularization: 1.372530\n",
      "2019-04-09 22:42:08,673 root         INFO     Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 70.026314\n",
      "Reconstruction: 68.610832, Regularization: 1.415478\n",
      "2019-04-09 22:42:08,729 root         INFO     Train Epoch: 76 [4608/8000 (58%)]\tTotal Loss: 44253.621094\n",
      "Reconstruction: 44251.972656, Regularization: 1.646669\n",
      "2019-04-09 22:42:08,785 root         INFO     Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 207.819595\n",
      "Reconstruction: 206.459183, Regularization: 1.360408\n",
      "2019-04-09 22:42:08,841 root         INFO     Train Epoch: 76 [5632/8000 (70%)]\tTotal Loss: 651.109741\n",
      "Reconstruction: 648.835815, Regularization: 2.273952\n",
      "2019-04-09 22:42:08,898 root         INFO     Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 9.007222\n",
      "Reconstruction: 7.302590, Regularization: 1.704633\n",
      "2019-04-09 22:42:08,954 root         INFO     Train Epoch: 76 [6656/8000 (83%)]\tTotal Loss: 12.096037\n",
      "Reconstruction: 10.289573, Regularization: 1.806464\n",
      "2019-04-09 22:42:09,010 root         INFO     Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 884.524048\n",
      "Reconstruction: 882.807373, Regularization: 1.716658\n",
      "2019-04-09 22:42:09,066 root         INFO     Train Epoch: 76 [7680/8000 (96%)]\tTotal Loss: 643.859497\n",
      "Reconstruction: 642.172302, Regularization: 1.687177\n",
      "2019-04-09 22:42:09,115 root         INFO     ====> Epoch: 76 Average loss: 33130.7782\n",
      "2019-04-09 22:42:09,139 root         INFO     Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 118.582687\n",
      "Reconstruction: 117.116089, Regularization: 1.466598\n",
      "2019-04-09 22:42:09,194 root         INFO     Train Epoch: 77 [512/8000 (6%)]\tTotal Loss: 921.920715\n",
      "Reconstruction: 919.485962, Regularization: 2.434746\n",
      "2019-04-09 22:42:09,250 root         INFO     Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 427.875488\n",
      "Reconstruction: 426.515747, Regularization: 1.359744\n",
      "2019-04-09 22:42:09,306 root         INFO     Train Epoch: 77 [1536/8000 (19%)]\tTotal Loss: 8.245685\n",
      "Reconstruction: 6.748558, Regularization: 1.497127\n",
      "2019-04-09 22:42:09,363 root         INFO     Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 505.133545\n",
      "Reconstruction: 503.351562, Regularization: 1.781982\n",
      "2019-04-09 22:42:09,418 root         INFO     Train Epoch: 77 [2560/8000 (32%)]\tTotal Loss: 555.741455\n",
      "Reconstruction: 554.198975, Regularization: 1.542475\n",
      "2019-04-09 22:42:09,473 root         INFO     Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 433.648743\n",
      "Reconstruction: 431.882874, Regularization: 1.765878\n",
      "2019-04-09 22:42:09,528 root         INFO     Train Epoch: 77 [3584/8000 (45%)]\tTotal Loss: 203.300491\n",
      "Reconstruction: 201.541428, Regularization: 1.759061\n",
      "2019-04-09 22:42:09,582 root         INFO     Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 10808.273438\n",
      "Reconstruction: 10806.720703, Regularization: 1.552683\n",
      "2019-04-09 22:42:09,638 root         INFO     Train Epoch: 77 [4608/8000 (58%)]\tTotal Loss: 27.846460\n",
      "Reconstruction: 26.583534, Regularization: 1.262926\n",
      "2019-04-09 22:42:09,693 root         INFO     Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 39268.347656\n",
      "Reconstruction: 39266.824219, Regularization: 1.521943\n",
      "2019-04-09 22:42:09,749 root         INFO     Train Epoch: 77 [5632/8000 (70%)]\tTotal Loss: 760.203857\n",
      "Reconstruction: 757.692871, Regularization: 2.510993\n",
      "2019-04-09 22:42:09,804 root         INFO     Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 3952.124268\n",
      "Reconstruction: 3950.015869, Regularization: 2.108482\n",
      "2019-04-09 22:42:09,859 root         INFO     Train Epoch: 77 [6656/8000 (83%)]\tTotal Loss: 50.165527\n",
      "Reconstruction: 48.245415, Regularization: 1.920113\n",
      "2019-04-09 22:42:09,913 root         INFO     Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 30.451780\n",
      "Reconstruction: 29.428162, Regularization: 1.023619\n",
      "2019-04-09 22:42:09,968 root         INFO     Train Epoch: 77 [7680/8000 (96%)]\tTotal Loss: 94.181808\n",
      "Reconstruction: 91.767220, Regularization: 2.414587\n",
      "2019-04-09 22:42:10,017 root         INFO     ====> Epoch: 77 Average loss: 19941.0308\n",
      "2019-04-09 22:42:10,040 root         INFO     Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 37.169292\n",
      "Reconstruction: 36.071041, Regularization: 1.098252\n",
      "2019-04-09 22:42:10,095 root         INFO     Train Epoch: 78 [512/8000 (6%)]\tTotal Loss: 37.668144\n",
      "Reconstruction: 36.254448, Regularization: 1.413695\n",
      "2019-04-09 22:42:10,150 root         INFO     Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 22.021723\n",
      "Reconstruction: 20.269001, Regularization: 1.752722\n",
      "2019-04-09 22:42:10,204 root         INFO     Train Epoch: 78 [1536/8000 (19%)]\tTotal Loss: 7.111047\n",
      "Reconstruction: 5.280668, Regularization: 1.830379\n",
      "2019-04-09 22:42:10,259 root         INFO     Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 1826.882690\n",
      "Reconstruction: 1825.410889, Regularization: 1.471790\n",
      "2019-04-09 22:42:10,314 root         INFO     Train Epoch: 78 [2560/8000 (32%)]\tTotal Loss: 472.981201\n",
      "Reconstruction: 471.092194, Regularization: 1.889009\n",
      "2019-04-09 22:42:10,370 root         INFO     Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 366.229645\n",
      "Reconstruction: 364.680847, Regularization: 1.548810\n",
      "2019-04-09 22:42:10,426 root         INFO     Train Epoch: 78 [3584/8000 (45%)]\tTotal Loss: 1607.037720\n",
      "Reconstruction: 1604.702148, Regularization: 2.335551\n",
      "2019-04-09 22:42:10,483 root         INFO     Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 30.082561\n",
      "Reconstruction: 28.256893, Regularization: 1.825668\n",
      "2019-04-09 22:42:10,538 root         INFO     Train Epoch: 78 [4608/8000 (58%)]\tTotal Loss: 363.058228\n",
      "Reconstruction: 362.018616, Regularization: 1.039627\n",
      "2019-04-09 22:42:10,593 root         INFO     Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 72.835793\n",
      "Reconstruction: 71.853920, Regularization: 0.981872\n",
      "2019-04-09 22:42:10,648 root         INFO     Train Epoch: 78 [5632/8000 (70%)]\tTotal Loss: 96.894562\n",
      "Reconstruction: 94.943321, Regularization: 1.951239\n",
      "2019-04-09 22:42:10,704 root         INFO     Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 99.636757\n",
      "Reconstruction: 97.394432, Regularization: 2.242328\n",
      "2019-04-09 22:42:10,759 root         INFO     Train Epoch: 78 [6656/8000 (83%)]\tTotal Loss: 226.776016\n",
      "Reconstruction: 225.118271, Regularization: 1.657745\n",
      "2019-04-09 22:42:10,814 root         INFO     Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 118500.304688\n",
      "Reconstruction: 118498.703125, Regularization: 1.598416\n",
      "2019-04-09 22:42:10,869 root         INFO     Train Epoch: 78 [7680/8000 (96%)]\tTotal Loss: 88.511330\n",
      "Reconstruction: 87.239914, Regularization: 1.271415\n",
      "2019-04-09 22:42:10,918 root         INFO     ====> Epoch: 78 Average loss: 4759.0383\n",
      "2019-04-09 22:42:10,941 root         INFO     Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 305.284241\n",
      "Reconstruction: 303.835815, Regularization: 1.448439\n",
      "2019-04-09 22:42:10,997 root         INFO     Train Epoch: 79 [512/8000 (6%)]\tTotal Loss: 15.514159\n",
      "Reconstruction: 14.246664, Regularization: 1.267495\n",
      "2019-04-09 22:42:11,053 root         INFO     Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 1231.625244\n",
      "Reconstruction: 1229.666260, Regularization: 1.958953\n",
      "2019-04-09 22:42:11,109 root         INFO     Train Epoch: 79 [1536/8000 (19%)]\tTotal Loss: 8.520330\n",
      "Reconstruction: 6.826447, Regularization: 1.693884\n",
      "2019-04-09 22:42:11,165 root         INFO     Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 351.045807\n",
      "Reconstruction: 349.440369, Regularization: 1.605450\n",
      "2019-04-09 22:42:11,221 root         INFO     Train Epoch: 79 [2560/8000 (32%)]\tTotal Loss: 55.416737\n",
      "Reconstruction: 54.565487, Regularization: 0.851248\n",
      "2019-04-09 22:42:11,278 root         INFO     Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 31.853762\n",
      "Reconstruction: 30.067741, Regularization: 1.786020\n",
      "2019-04-09 22:42:11,332 root         INFO     Train Epoch: 79 [3584/8000 (45%)]\tTotal Loss: 14.172215\n",
      "Reconstruction: 12.769135, Regularization: 1.403080\n",
      "2019-04-09 22:42:11,385 root         INFO     Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 864.865967\n",
      "Reconstruction: 862.451904, Regularization: 2.414083\n",
      "2019-04-09 22:42:11,440 root         INFO     Train Epoch: 79 [4608/8000 (58%)]\tTotal Loss: 126.184502\n",
      "Reconstruction: 124.819565, Regularization: 1.364937\n",
      "2019-04-09 22:42:11,494 root         INFO     Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 2618.558105\n",
      "Reconstruction: 2616.965820, Regularization: 1.592374\n",
      "2019-04-09 22:42:11,548 root         INFO     Train Epoch: 79 [5632/8000 (70%)]\tTotal Loss: 67.768906\n",
      "Reconstruction: 66.668335, Regularization: 1.100568\n",
      "2019-04-09 22:42:11,602 root         INFO     Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 68.908173\n",
      "Reconstruction: 66.977341, Regularization: 1.930834\n",
      "2019-04-09 22:42:11,656 root         INFO     Train Epoch: 79 [6656/8000 (83%)]\tTotal Loss: 319.977692\n",
      "Reconstruction: 318.039612, Regularization: 1.938080\n",
      "2019-04-09 22:42:11,710 root         INFO     Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 524.509583\n",
      "Reconstruction: 523.350037, Regularization: 1.159550\n",
      "2019-04-09 22:42:11,764 root         INFO     Train Epoch: 79 [7680/8000 (96%)]\tTotal Loss: 6487.350098\n",
      "Reconstruction: 6485.489258, Regularization: 1.860943\n",
      "2019-04-09 22:42:11,813 root         INFO     ====> Epoch: 79 Average loss: 12441.7967\n",
      "2019-04-09 22:42:11,836 root         INFO     Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 16.862526\n",
      "Reconstruction: 15.351498, Regularization: 1.511028\n",
      "2019-04-09 22:42:11,892 root         INFO     Train Epoch: 80 [512/8000 (6%)]\tTotal Loss: 6.554424\n",
      "Reconstruction: 5.642659, Regularization: 0.911766\n",
      "2019-04-09 22:42:11,946 root         INFO     Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 83.297356\n",
      "Reconstruction: 82.319885, Regularization: 0.977471\n",
      "2019-04-09 22:42:12,001 root         INFO     Train Epoch: 80 [1536/8000 (19%)]\tTotal Loss: 437.738281\n",
      "Reconstruction: 435.886841, Regularization: 1.851443\n",
      "2019-04-09 22:42:12,055 root         INFO     Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 270.888550\n",
      "Reconstruction: 268.952393, Regularization: 1.936147\n",
      "2019-04-09 22:42:12,110 root         INFO     Train Epoch: 80 [2560/8000 (32%)]\tTotal Loss: 5184.569824\n",
      "Reconstruction: 5182.751465, Regularization: 1.818492\n",
      "2019-04-09 22:42:12,165 root         INFO     Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 274.382233\n",
      "Reconstruction: 272.694305, Regularization: 1.687918\n",
      "2019-04-09 22:42:12,220 root         INFO     Train Epoch: 80 [3584/8000 (45%)]\tTotal Loss: 73.838913\n",
      "Reconstruction: 71.974922, Regularization: 1.863993\n",
      "2019-04-09 22:42:12,275 root         INFO     Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 91.271469\n",
      "Reconstruction: 89.291779, Regularization: 1.979689\n",
      "2019-04-09 22:42:12,330 root         INFO     Train Epoch: 80 [4608/8000 (58%)]\tTotal Loss: 64.091324\n",
      "Reconstruction: 62.397511, Regularization: 1.693815\n",
      "2019-04-09 22:42:12,384 root         INFO     Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 446.782257\n",
      "Reconstruction: 445.205811, Regularization: 1.576448\n",
      "2019-04-09 22:42:12,439 root         INFO     Train Epoch: 80 [5632/8000 (70%)]\tTotal Loss: 26.753658\n",
      "Reconstruction: 25.599386, Regularization: 1.154273\n",
      "2019-04-09 22:42:12,493 root         INFO     Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 13.290991\n",
      "Reconstruction: 12.147535, Regularization: 1.143455\n",
      "2019-04-09 22:42:12,548 root         INFO     Train Epoch: 80 [6656/8000 (83%)]\tTotal Loss: 22510.417969\n",
      "Reconstruction: 22507.580078, Regularization: 2.838464\n",
      "2019-04-09 22:42:12,603 root         INFO     Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 1049.499878\n",
      "Reconstruction: 1048.008789, Regularization: 1.491071\n",
      "2019-04-09 22:42:12,657 root         INFO     Train Epoch: 80 [7680/8000 (96%)]\tTotal Loss: 24.795063\n",
      "Reconstruction: 23.307957, Regularization: 1.487106\n",
      "2019-04-09 22:42:12,706 root         INFO     ====> Epoch: 80 Average loss: 31028.0048\n",
      "2019-04-09 22:42:12,729 root         INFO     Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 30.045034\n",
      "Reconstruction: 28.843369, Regularization: 1.201666\n",
      "2019-04-09 22:42:12,783 root         INFO     Train Epoch: 81 [512/8000 (6%)]\tTotal Loss: 467.650665\n",
      "Reconstruction: 465.435730, Regularization: 2.214945\n",
      "2019-04-09 22:42:12,838 root         INFO     Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 994.806030\n",
      "Reconstruction: 992.866150, Regularization: 1.939862\n",
      "2019-04-09 22:42:12,892 root         INFO     Train Epoch: 81 [1536/8000 (19%)]\tTotal Loss: 17.353325\n",
      "Reconstruction: 15.757499, Regularization: 1.595825\n",
      "2019-04-09 22:42:12,946 root         INFO     Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 732.704956\n",
      "Reconstruction: 731.610535, Regularization: 1.094399\n",
      "2019-04-09 22:42:13,000 root         INFO     Train Epoch: 81 [2560/8000 (32%)]\tTotal Loss: 1761.027954\n",
      "Reconstruction: 1759.675537, Regularization: 1.352391\n",
      "2019-04-09 22:42:13,054 root         INFO     Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 12.270768\n",
      "Reconstruction: 9.865461, Regularization: 2.405307\n",
      "2019-04-09 22:42:13,109 root         INFO     Train Epoch: 81 [3584/8000 (45%)]\tTotal Loss: 262.472534\n",
      "Reconstruction: 260.760345, Regularization: 1.712196\n",
      "2019-04-09 22:42:13,163 root         INFO     Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 148.759064\n",
      "Reconstruction: 147.559189, Regularization: 1.199870\n",
      "2019-04-09 22:42:13,217 root         INFO     Train Epoch: 81 [4608/8000 (58%)]\tTotal Loss: 193.377075\n",
      "Reconstruction: 191.137772, Regularization: 2.239300\n",
      "2019-04-09 22:42:13,271 root         INFO     Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 158324.265625\n",
      "Reconstruction: 158322.046875, Regularization: 2.216447\n",
      "2019-04-09 22:42:13,325 root         INFO     Train Epoch: 81 [5632/8000 (70%)]\tTotal Loss: 8969.287109\n",
      "Reconstruction: 8967.499023, Regularization: 1.787656\n",
      "2019-04-09 22:42:13,379 root         INFO     Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 6.284558\n",
      "Reconstruction: 5.250566, Regularization: 1.033991\n",
      "2019-04-09 22:42:13,433 root         INFO     Train Epoch: 81 [6656/8000 (83%)]\tTotal Loss: 213.642334\n",
      "Reconstruction: 212.280655, Regularization: 1.361672\n",
      "2019-04-09 22:42:13,487 root         INFO     Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 574.325256\n",
      "Reconstruction: 573.197937, Regularization: 1.127294\n",
      "2019-04-09 22:42:13,541 root         INFO     Train Epoch: 81 [7680/8000 (96%)]\tTotal Loss: 782.290833\n",
      "Reconstruction: 780.947937, Regularization: 1.342897\n",
      "2019-04-09 22:42:13,589 root         INFO     ====> Epoch: 81 Average loss: 5817.6950\n",
      "2019-04-09 22:42:13,612 root         INFO     Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 1372.346558\n",
      "Reconstruction: 1370.555908, Regularization: 1.790695\n",
      "2019-04-09 22:42:13,668 root         INFO     Train Epoch: 82 [512/8000 (6%)]\tTotal Loss: 1054.531982\n",
      "Reconstruction: 1052.704346, Regularization: 1.827631\n",
      "2019-04-09 22:42:13,722 root         INFO     Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 24.248941\n",
      "Reconstruction: 23.367823, Regularization: 0.881119\n",
      "2019-04-09 22:42:13,777 root         INFO     Train Epoch: 82 [1536/8000 (19%)]\tTotal Loss: 2159.024170\n",
      "Reconstruction: 2157.647949, Regularization: 1.376282\n",
      "2019-04-09 22:42:13,831 root         INFO     Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 1783.726562\n",
      "Reconstruction: 1781.853394, Regularization: 1.873132\n",
      "2019-04-09 22:42:13,885 root         INFO     Train Epoch: 82 [2560/8000 (32%)]\tTotal Loss: 699.284119\n",
      "Reconstruction: 697.820496, Regularization: 1.463629\n",
      "2019-04-09 22:42:13,940 root         INFO     Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 8.126014\n",
      "Reconstruction: 6.853164, Regularization: 1.272849\n",
      "2019-04-09 22:42:13,995 root         INFO     Train Epoch: 82 [3584/8000 (45%)]\tTotal Loss: 34.568077\n",
      "Reconstruction: 32.665199, Regularization: 1.902879\n",
      "2019-04-09 22:42:14,049 root         INFO     Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 14.423149\n",
      "Reconstruction: 12.662554, Regularization: 1.760595\n",
      "2019-04-09 22:42:14,104 root         INFO     Train Epoch: 82 [4608/8000 (58%)]\tTotal Loss: 447.231079\n",
      "Reconstruction: 445.090759, Regularization: 2.140330\n",
      "2019-04-09 22:42:14,159 root         INFO     Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 122.945511\n",
      "Reconstruction: 121.753578, Regularization: 1.191933\n",
      "2019-04-09 22:42:14,213 root         INFO     Train Epoch: 82 [5632/8000 (70%)]\tTotal Loss: 2305.745361\n",
      "Reconstruction: 2304.452637, Regularization: 1.292833\n",
      "2019-04-09 22:42:14,266 root         INFO     Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 63.802483\n",
      "Reconstruction: 62.575165, Regularization: 1.227316\n",
      "2019-04-09 22:42:14,321 root         INFO     Train Epoch: 82 [6656/8000 (83%)]\tTotal Loss: 596.349792\n",
      "Reconstruction: 594.063965, Regularization: 2.285814\n",
      "2019-04-09 22:42:14,376 root         INFO     Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 1254.616699\n",
      "Reconstruction: 1252.930176, Regularization: 1.686559\n",
      "2019-04-09 22:42:14,431 root         INFO     Train Epoch: 82 [7680/8000 (96%)]\tTotal Loss: 183.452087\n",
      "Reconstruction: 181.973358, Regularization: 1.478727\n",
      "2019-04-09 22:42:14,480 root         INFO     ====> Epoch: 82 Average loss: 9504.2710\n",
      "2019-04-09 22:42:14,504 root         INFO     Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 241.408630\n",
      "Reconstruction: 239.558212, Regularization: 1.850418\n",
      "2019-04-09 22:42:14,559 root         INFO     Train Epoch: 83 [512/8000 (6%)]\tTotal Loss: 15.851151\n",
      "Reconstruction: 14.474399, Regularization: 1.376752\n",
      "2019-04-09 22:42:14,615 root         INFO     Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 23038.693359\n",
      "Reconstruction: 23036.078125, Regularization: 2.615618\n",
      "2019-04-09 22:42:14,670 root         INFO     Train Epoch: 83 [1536/8000 (19%)]\tTotal Loss: 669.170349\n",
      "Reconstruction: 667.446045, Regularization: 1.724330\n",
      "2019-04-09 22:42:14,726 root         INFO     Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 2255.241699\n",
      "Reconstruction: 2253.668213, Regularization: 1.573478\n",
      "2019-04-09 22:42:14,781 root         INFO     Train Epoch: 83 [2560/8000 (32%)]\tTotal Loss: 24.664740\n",
      "Reconstruction: 23.259670, Regularization: 1.405070\n",
      "2019-04-09 22:42:14,837 root         INFO     Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 102.478020\n",
      "Reconstruction: 100.899666, Regularization: 1.578355\n",
      "2019-04-09 22:42:14,893 root         INFO     Train Epoch: 83 [3584/8000 (45%)]\tTotal Loss: 341.045868\n",
      "Reconstruction: 338.631012, Regularization: 2.414861\n",
      "2019-04-09 22:42:14,948 root         INFO     Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 75.784721\n",
      "Reconstruction: 74.337982, Regularization: 1.446739\n",
      "2019-04-09 22:42:15,004 root         INFO     Train Epoch: 83 [4608/8000 (58%)]\tTotal Loss: 2435.905029\n",
      "Reconstruction: 2433.624023, Regularization: 2.280900\n",
      "2019-04-09 22:42:15,059 root         INFO     Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 365.488159\n",
      "Reconstruction: 363.887573, Regularization: 1.600594\n",
      "2019-04-09 22:42:15,114 root         INFO     Train Epoch: 83 [5632/8000 (70%)]\tTotal Loss: 16044.416016\n",
      "Reconstruction: 16042.658203, Regularization: 1.757691\n",
      "2019-04-09 22:42:15,169 root         INFO     Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 268.657166\n",
      "Reconstruction: 266.757507, Regularization: 1.899653\n",
      "2019-04-09 22:42:15,225 root         INFO     Train Epoch: 83 [6656/8000 (83%)]\tTotal Loss: 7.393747\n",
      "Reconstruction: 5.587481, Regularization: 1.806266\n",
      "2019-04-09 22:42:15,280 root         INFO     Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 204.617599\n",
      "Reconstruction: 203.357529, Regularization: 1.260073\n",
      "2019-04-09 22:42:15,335 root         INFO     Train Epoch: 83 [7680/8000 (96%)]\tTotal Loss: 15.694324\n",
      "Reconstruction: 14.320425, Regularization: 1.373899\n",
      "2019-04-09 22:42:15,385 root         INFO     ====> Epoch: 83 Average loss: 8619.0627\n",
      "2019-04-09 22:42:15,408 root         INFO     Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 12.836030\n",
      "Reconstruction: 11.189930, Regularization: 1.646100\n",
      "2019-04-09 22:42:15,464 root         INFO     Train Epoch: 84 [512/8000 (6%)]\tTotal Loss: 47.242252\n",
      "Reconstruction: 45.778229, Regularization: 1.464025\n",
      "2019-04-09 22:42:15,519 root         INFO     Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 44.603191\n",
      "Reconstruction: 42.984520, Regularization: 1.618672\n",
      "2019-04-09 22:42:15,574 root         INFO     Train Epoch: 84 [1536/8000 (19%)]\tTotal Loss: 3630.807373\n",
      "Reconstruction: 3628.800293, Regularization: 2.007100\n",
      "2019-04-09 22:42:15,628 root         INFO     Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 46138.363281\n",
      "Reconstruction: 46136.640625, Regularization: 1.721110\n",
      "2019-04-09 22:42:15,683 root         INFO     Train Epoch: 84 [2560/8000 (32%)]\tTotal Loss: 138.817551\n",
      "Reconstruction: 137.797073, Regularization: 1.020483\n",
      "2019-04-09 22:42:15,737 root         INFO     Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 28.565399\n",
      "Reconstruction: 27.113140, Regularization: 1.452260\n",
      "2019-04-09 22:42:15,792 root         INFO     Train Epoch: 84 [3584/8000 (45%)]\tTotal Loss: 995.175110\n",
      "Reconstruction: 993.550781, Regularization: 1.624310\n",
      "2019-04-09 22:42:15,847 root         INFO     Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 59.552578\n",
      "Reconstruction: 58.061916, Regularization: 1.490661\n",
      "2019-04-09 22:42:15,902 root         INFO     Train Epoch: 84 [4608/8000 (58%)]\tTotal Loss: 24329.103516\n",
      "Reconstruction: 24327.390625, Regularization: 1.713838\n",
      "2019-04-09 22:42:15,957 root         INFO     Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 7859.006348\n",
      "Reconstruction: 7857.671387, Regularization: 1.335148\n",
      "2019-04-09 22:42:16,011 root         INFO     Train Epoch: 84 [5632/8000 (70%)]\tTotal Loss: 12662.472656\n",
      "Reconstruction: 12660.568359, Regularization: 1.904684\n",
      "2019-04-09 22:42:16,066 root         INFO     Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 46.678787\n",
      "Reconstruction: 45.640457, Regularization: 1.038330\n",
      "2019-04-09 22:42:16,121 root         INFO     Train Epoch: 84 [6656/8000 (83%)]\tTotal Loss: 208.565353\n",
      "Reconstruction: 206.911163, Regularization: 1.654187\n",
      "2019-04-09 22:42:16,175 root         INFO     Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 994.619446\n",
      "Reconstruction: 993.429260, Regularization: 1.190165\n",
      "2019-04-09 22:42:16,230 root         INFO     Train Epoch: 84 [7680/8000 (96%)]\tTotal Loss: 12247.729492\n",
      "Reconstruction: 12245.469727, Regularization: 2.259709\n",
      "2019-04-09 22:42:16,279 root         INFO     ====> Epoch: 84 Average loss: 13266.0103\n",
      "2019-04-09 22:42:16,303 root         INFO     Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 63.482941\n",
      "Reconstruction: 61.737270, Regularization: 1.745670\n",
      "2019-04-09 22:42:16,358 root         INFO     Train Epoch: 85 [512/8000 (6%)]\tTotal Loss: 215.504227\n",
      "Reconstruction: 213.201981, Regularization: 2.302240\n",
      "2019-04-09 22:42:16,414 root         INFO     Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 567.360596\n",
      "Reconstruction: 565.369019, Regularization: 1.991572\n",
      "2019-04-09 22:42:16,469 root         INFO     Train Epoch: 85 [1536/8000 (19%)]\tTotal Loss: 641.076904\n",
      "Reconstruction: 639.661865, Regularization: 1.415040\n",
      "2019-04-09 22:42:16,525 root         INFO     Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 726.875977\n",
      "Reconstruction: 725.297791, Regularization: 1.578205\n",
      "2019-04-09 22:42:16,580 root         INFO     Train Epoch: 85 [2560/8000 (32%)]\tTotal Loss: 19.628094\n",
      "Reconstruction: 18.465204, Regularization: 1.162889\n",
      "2019-04-09 22:42:16,635 root         INFO     Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 658.887390\n",
      "Reconstruction: 657.451233, Regularization: 1.436176\n",
      "2019-04-09 22:42:16,691 root         INFO     Train Epoch: 85 [3584/8000 (45%)]\tTotal Loss: 53.875198\n",
      "Reconstruction: 52.680504, Regularization: 1.194696\n",
      "2019-04-09 22:42:16,746 root         INFO     Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 1602.781250\n",
      "Reconstruction: 1601.249268, Regularization: 1.531933\n",
      "2019-04-09 22:42:16,802 root         INFO     Train Epoch: 85 [4608/8000 (58%)]\tTotal Loss: 1059.101562\n",
      "Reconstruction: 1057.756958, Regularization: 1.344606\n",
      "2019-04-09 22:42:16,858 root         INFO     Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 3309.770996\n",
      "Reconstruction: 3308.614990, Regularization: 1.155996\n",
      "2019-04-09 22:42:16,913 root         INFO     Train Epoch: 85 [5632/8000 (70%)]\tTotal Loss: 45.275978\n",
      "Reconstruction: 43.889851, Regularization: 1.386126\n",
      "2019-04-09 22:42:16,969 root         INFO     Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 420.544495\n",
      "Reconstruction: 418.495178, Regularization: 2.049311\n",
      "2019-04-09 22:42:17,024 root         INFO     Train Epoch: 85 [6656/8000 (83%)]\tTotal Loss: 1846.067749\n",
      "Reconstruction: 1844.232422, Regularization: 1.835330\n",
      "2019-04-09 22:42:17,079 root         INFO     Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 328.835602\n",
      "Reconstruction: 327.475342, Regularization: 1.360249\n",
      "2019-04-09 22:42:17,134 root         INFO     Train Epoch: 85 [7680/8000 (96%)]\tTotal Loss: 98.339470\n",
      "Reconstruction: 96.820702, Regularization: 1.518767\n",
      "2019-04-09 22:42:17,182 root         INFO     ====> Epoch: 85 Average loss: 5874.5561\n",
      "2019-04-09 22:42:17,205 root         INFO     Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 259.214447\n",
      "Reconstruction: 257.460999, Regularization: 1.753449\n",
      "2019-04-09 22:42:17,261 root         INFO     Train Epoch: 86 [512/8000 (6%)]\tTotal Loss: 456966.937500\n",
      "Reconstruction: 456965.281250, Regularization: 1.658006\n",
      "2019-04-09 22:42:17,315 root         INFO     Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 1918.972046\n",
      "Reconstruction: 1917.755615, Regularization: 1.216419\n",
      "2019-04-09 22:42:17,370 root         INFO     Train Epoch: 86 [1536/8000 (19%)]\tTotal Loss: 46.315567\n",
      "Reconstruction: 45.437572, Regularization: 0.877995\n",
      "2019-04-09 22:42:17,424 root         INFO     Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 284.760315\n",
      "Reconstruction: 283.298553, Regularization: 1.461763\n",
      "2019-04-09 22:42:17,478 root         INFO     Train Epoch: 86 [2560/8000 (32%)]\tTotal Loss: 1825.030273\n",
      "Reconstruction: 1823.048340, Regularization: 1.981922\n",
      "2019-04-09 22:42:17,532 root         INFO     Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 209380.109375\n",
      "Reconstruction: 209377.593750, Regularization: 2.521041\n",
      "2019-04-09 22:42:17,587 root         INFO     Train Epoch: 86 [3584/8000 (45%)]\tTotal Loss: 4575.545410\n",
      "Reconstruction: 4573.787598, Regularization: 1.757878\n",
      "2019-04-09 22:42:17,641 root         INFO     Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 72.003876\n",
      "Reconstruction: 70.361725, Regularization: 1.642153\n",
      "2019-04-09 22:42:17,695 root         INFO     Train Epoch: 86 [4608/8000 (58%)]\tTotal Loss: 14.758808\n",
      "Reconstruction: 13.592498, Regularization: 1.166311\n",
      "2019-04-09 22:42:17,750 root         INFO     Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 49.170776\n",
      "Reconstruction: 47.976414, Regularization: 1.194363\n",
      "2019-04-09 22:42:17,805 root         INFO     Train Epoch: 86 [5632/8000 (70%)]\tTotal Loss: 1.895082\n",
      "Reconstruction: 0.522479, Regularization: 1.372603\n",
      "2019-04-09 22:42:17,860 root         INFO     Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 735.198364\n",
      "Reconstruction: 734.091553, Regularization: 1.106821\n",
      "2019-04-09 22:42:17,915 root         INFO     Train Epoch: 86 [6656/8000 (83%)]\tTotal Loss: 703.120667\n",
      "Reconstruction: 701.283936, Regularization: 1.836749\n",
      "2019-04-09 22:42:17,971 root         INFO     Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 105851.289062\n",
      "Reconstruction: 105849.390625, Regularization: 1.899554\n",
      "2019-04-09 22:42:18,026 root         INFO     Train Epoch: 86 [7680/8000 (96%)]\tTotal Loss: 102.831345\n",
      "Reconstruction: 100.362801, Regularization: 2.468547\n",
      "2019-04-09 22:42:18,075 root         INFO     ====> Epoch: 86 Average loss: 7488.1852\n",
      "2019-04-09 22:42:18,099 root         INFO     Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 50.635197\n",
      "Reconstruction: 48.993839, Regularization: 1.641358\n",
      "2019-04-09 22:42:18,157 root         INFO     Train Epoch: 87 [512/8000 (6%)]\tTotal Loss: 16.919432\n",
      "Reconstruction: 15.714913, Regularization: 1.204518\n",
      "2019-04-09 22:42:18,213 root         INFO     Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 2151.271973\n",
      "Reconstruction: 2149.264648, Regularization: 2.007348\n",
      "2019-04-09 22:42:18,268 root         INFO     Train Epoch: 87 [1536/8000 (19%)]\tTotal Loss: 350.792419\n",
      "Reconstruction: 349.438354, Regularization: 1.354059\n",
      "2019-04-09 22:42:18,326 root         INFO     Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 293.604858\n",
      "Reconstruction: 292.264709, Regularization: 1.340144\n",
      "2019-04-09 22:42:18,382 root         INFO     Train Epoch: 87 [2560/8000 (32%)]\tTotal Loss: 1621.366089\n",
      "Reconstruction: 1618.955933, Regularization: 2.410213\n",
      "2019-04-09 22:42:18,436 root         INFO     Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 9.078907\n",
      "Reconstruction: 8.272718, Regularization: 0.806188\n",
      "2019-04-09 22:42:18,492 root         INFO     Train Epoch: 87 [3584/8000 (45%)]\tTotal Loss: 272.736420\n",
      "Reconstruction: 271.111023, Regularization: 1.625383\n",
      "2019-04-09 22:42:18,548 root         INFO     Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 27.615492\n",
      "Reconstruction: 26.055405, Regularization: 1.560088\n",
      "2019-04-09 22:42:18,602 root         INFO     Train Epoch: 87 [4608/8000 (58%)]\tTotal Loss: 9.437768\n",
      "Reconstruction: 7.794732, Regularization: 1.643037\n",
      "2019-04-09 22:42:18,656 root         INFO     Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 60.927448\n",
      "Reconstruction: 59.930462, Regularization: 0.996987\n",
      "2019-04-09 22:42:18,710 root         INFO     Train Epoch: 87 [5632/8000 (70%)]\tTotal Loss: 126.450859\n",
      "Reconstruction: 125.288857, Regularization: 1.162001\n",
      "2019-04-09 22:42:18,764 root         INFO     Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 50.701649\n",
      "Reconstruction: 48.961720, Regularization: 1.739929\n",
      "2019-04-09 22:42:18,818 root         INFO     Train Epoch: 87 [6656/8000 (83%)]\tTotal Loss: 292.542267\n",
      "Reconstruction: 291.143677, Regularization: 1.398599\n",
      "2019-04-09 22:42:18,871 root         INFO     Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 392.961426\n",
      "Reconstruction: 391.768585, Regularization: 1.192849\n",
      "2019-04-09 22:42:18,924 root         INFO     Train Epoch: 87 [7680/8000 (96%)]\tTotal Loss: 184.648438\n",
      "Reconstruction: 182.943146, Regularization: 1.705287\n",
      "2019-04-09 22:42:18,972 root         INFO     ====> Epoch: 87 Average loss: 3402.8288\n",
      "2019-04-09 22:42:18,996 root         INFO     Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 85.392990\n",
      "Reconstruction: 84.360847, Regularization: 1.032140\n",
      "2019-04-09 22:42:19,051 root         INFO     Train Epoch: 88 [512/8000 (6%)]\tTotal Loss: 213.756912\n",
      "Reconstruction: 212.463181, Regularization: 1.293726\n",
      "2019-04-09 22:42:19,105 root         INFO     Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 43.663322\n",
      "Reconstruction: 41.954147, Regularization: 1.709176\n",
      "2019-04-09 22:42:19,160 root         INFO     Train Epoch: 88 [1536/8000 (19%)]\tTotal Loss: 1056.423218\n",
      "Reconstruction: 1054.880859, Regularization: 1.542371\n",
      "2019-04-09 22:42:19,214 root         INFO     Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 409.312164\n",
      "Reconstruction: 408.170013, Regularization: 1.142155\n",
      "2019-04-09 22:42:19,269 root         INFO     Train Epoch: 88 [2560/8000 (32%)]\tTotal Loss: 176.832703\n",
      "Reconstruction: 175.334290, Regularization: 1.498418\n",
      "2019-04-09 22:42:19,324 root         INFO     Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 127.740051\n",
      "Reconstruction: 126.600975, Regularization: 1.139080\n",
      "2019-04-09 22:42:19,379 root         INFO     Train Epoch: 88 [3584/8000 (45%)]\tTotal Loss: 695.023254\n",
      "Reconstruction: 692.614685, Regularization: 2.408545\n",
      "2019-04-09 22:42:19,434 root         INFO     Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 4609.213379\n",
      "Reconstruction: 4608.237793, Regularization: 0.975508\n",
      "2019-04-09 22:42:19,490 root         INFO     Train Epoch: 88 [4608/8000 (58%)]\tTotal Loss: 85.896507\n",
      "Reconstruction: 84.708656, Regularization: 1.187849\n",
      "2019-04-09 22:42:19,545 root         INFO     Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 1446.431274\n",
      "Reconstruction: 1445.049194, Regularization: 1.382114\n",
      "2019-04-09 22:42:19,599 root         INFO     Train Epoch: 88 [5632/8000 (70%)]\tTotal Loss: 353.819794\n",
      "Reconstruction: 351.489777, Regularization: 2.330019\n",
      "2019-04-09 22:42:19,654 root         INFO     Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 1085.279907\n",
      "Reconstruction: 1084.063477, Regularization: 1.216462\n",
      "2019-04-09 22:42:19,709 root         INFO     Train Epoch: 88 [6656/8000 (83%)]\tTotal Loss: 22.222063\n",
      "Reconstruction: 20.876190, Regularization: 1.345874\n",
      "2019-04-09 22:42:19,764 root         INFO     Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 34.808182\n",
      "Reconstruction: 33.891258, Regularization: 0.916923\n",
      "2019-04-09 22:42:19,819 root         INFO     Train Epoch: 88 [7680/8000 (96%)]\tTotal Loss: 8941.985352\n",
      "Reconstruction: 8940.268555, Regularization: 1.716788\n",
      "2019-04-09 22:42:19,868 root         INFO     ====> Epoch: 88 Average loss: 4818.7892\n",
      "2019-04-09 22:42:19,892 root         INFO     Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 436.397308\n",
      "Reconstruction: 435.250214, Regularization: 1.147099\n",
      "2019-04-09 22:42:19,946 root         INFO     Train Epoch: 89 [512/8000 (6%)]\tTotal Loss: 63211.710938\n",
      "Reconstruction: 63209.710938, Regularization: 2.001006\n",
      "2019-04-09 22:42:20,000 root         INFO     Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 16.745935\n",
      "Reconstruction: 15.250860, Regularization: 1.495075\n",
      "2019-04-09 22:42:20,054 root         INFO     Train Epoch: 89 [1536/8000 (19%)]\tTotal Loss: 19.180956\n",
      "Reconstruction: 17.808002, Regularization: 1.372953\n",
      "2019-04-09 22:42:20,107 root         INFO     Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 202.223358\n",
      "Reconstruction: 200.148773, Regularization: 2.074590\n",
      "2019-04-09 22:42:20,162 root         INFO     Train Epoch: 89 [2560/8000 (32%)]\tTotal Loss: 462.516968\n",
      "Reconstruction: 460.810974, Regularization: 1.706005\n",
      "2019-04-09 22:42:20,216 root         INFO     Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 34.719719\n",
      "Reconstruction: 32.875778, Regularization: 1.843942\n",
      "2019-04-09 22:42:20,270 root         INFO     Train Epoch: 89 [3584/8000 (45%)]\tTotal Loss: 31.440855\n",
      "Reconstruction: 29.540981, Regularization: 1.899874\n",
      "2019-04-09 22:42:20,324 root         INFO     Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 6.931025\n",
      "Reconstruction: 5.368214, Regularization: 1.562811\n",
      "2019-04-09 22:42:20,378 root         INFO     Train Epoch: 89 [4608/8000 (58%)]\tTotal Loss: 411.362152\n",
      "Reconstruction: 410.170532, Regularization: 1.191615\n",
      "2019-04-09 22:42:20,432 root         INFO     Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 946.825806\n",
      "Reconstruction: 945.586182, Regularization: 1.239596\n",
      "2019-04-09 22:42:20,486 root         INFO     Train Epoch: 89 [5632/8000 (70%)]\tTotal Loss: 23.726044\n",
      "Reconstruction: 22.182343, Regularization: 1.543701\n",
      "2019-04-09 22:42:20,540 root         INFO     Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 5.717184\n",
      "Reconstruction: 4.030354, Regularization: 1.686830\n",
      "2019-04-09 22:42:20,594 root         INFO     Train Epoch: 89 [6656/8000 (83%)]\tTotal Loss: 1138.959106\n",
      "Reconstruction: 1137.750366, Regularization: 1.208687\n",
      "2019-04-09 22:42:20,648 root         INFO     Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 9.146496\n",
      "Reconstruction: 7.357969, Regularization: 1.788526\n",
      "2019-04-09 22:42:20,702 root         INFO     Train Epoch: 89 [7680/8000 (96%)]\tTotal Loss: 145.689575\n",
      "Reconstruction: 143.944809, Regularization: 1.744766\n",
      "2019-04-09 22:42:20,751 root         INFO     ====> Epoch: 89 Average loss: 4861.1124\n",
      "2019-04-09 22:42:20,775 root         INFO     Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 351.586548\n",
      "Reconstruction: 350.083069, Regularization: 1.503476\n",
      "2019-04-09 22:42:20,830 root         INFO     Train Epoch: 90 [512/8000 (6%)]\tTotal Loss: 31.571556\n",
      "Reconstruction: 30.261940, Regularization: 1.309616\n",
      "2019-04-09 22:42:20,886 root         INFO     Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 72.902657\n",
      "Reconstruction: 70.827827, Regularization: 2.074829\n",
      "2019-04-09 22:42:20,941 root         INFO     Train Epoch: 90 [1536/8000 (19%)]\tTotal Loss: 86.425446\n",
      "Reconstruction: 84.297981, Regularization: 2.127468\n",
      "2019-04-09 22:42:20,996 root         INFO     Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 3.636252\n",
      "Reconstruction: 1.321083, Regularization: 2.315169\n",
      "2019-04-09 22:42:21,051 root         INFO     Train Epoch: 90 [2560/8000 (32%)]\tTotal Loss: 307.308380\n",
      "Reconstruction: 305.517365, Regularization: 1.791011\n",
      "2019-04-09 22:42:21,107 root         INFO     Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 427.743164\n",
      "Reconstruction: 425.777252, Regularization: 1.965923\n",
      "2019-04-09 22:42:21,162 root         INFO     Train Epoch: 90 [3584/8000 (45%)]\tTotal Loss: 57.218109\n",
      "Reconstruction: 56.083775, Regularization: 1.134335\n",
      "2019-04-09 22:42:21,217 root         INFO     Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 16.827127\n",
      "Reconstruction: 15.019920, Regularization: 1.807207\n",
      "2019-04-09 22:42:21,272 root         INFO     Train Epoch: 90 [4608/8000 (58%)]\tTotal Loss: 12.607544\n",
      "Reconstruction: 11.224509, Regularization: 1.383035\n",
      "2019-04-09 22:42:21,327 root         INFO     Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 135.359024\n",
      "Reconstruction: 133.920746, Regularization: 1.438279\n",
      "2019-04-09 22:42:21,382 root         INFO     Train Epoch: 90 [5632/8000 (70%)]\tTotal Loss: 29.211643\n",
      "Reconstruction: 27.852528, Regularization: 1.359116\n",
      "2019-04-09 22:42:21,438 root         INFO     Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 487.002594\n",
      "Reconstruction: 485.326508, Regularization: 1.676071\n",
      "2019-04-09 22:42:21,493 root         INFO     Train Epoch: 90 [6656/8000 (83%)]\tTotal Loss: 63581.988281\n",
      "Reconstruction: 63580.265625, Regularization: 1.724031\n",
      "2019-04-09 22:42:21,548 root         INFO     Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 402.585205\n",
      "Reconstruction: 401.385254, Regularization: 1.199941\n",
      "2019-04-09 22:42:21,603 root         INFO     Train Epoch: 90 [7680/8000 (96%)]\tTotal Loss: 13.269479\n",
      "Reconstruction: 12.378757, Regularization: 0.890722\n",
      "2019-04-09 22:42:21,652 root         INFO     ====> Epoch: 90 Average loss: 5216.3233\n",
      "2019-04-09 22:42:21,676 root         INFO     Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 273.196045\n",
      "Reconstruction: 271.540283, Regularization: 1.655751\n",
      "2019-04-09 22:42:21,731 root         INFO     Train Epoch: 91 [512/8000 (6%)]\tTotal Loss: 3479.386719\n",
      "Reconstruction: 3478.069824, Regularization: 1.317013\n",
      "2019-04-09 22:42:21,787 root         INFO     Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 26.984003\n",
      "Reconstruction: 25.350592, Regularization: 1.633411\n",
      "2019-04-09 22:42:21,842 root         INFO     Train Epoch: 91 [1536/8000 (19%)]\tTotal Loss: 125.418381\n",
      "Reconstruction: 122.543015, Regularization: 2.875370\n",
      "2019-04-09 22:42:21,898 root         INFO     Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 31.536264\n",
      "Reconstruction: 28.231514, Regularization: 3.304750\n",
      "2019-04-09 22:42:21,953 root         INFO     Train Epoch: 91 [2560/8000 (32%)]\tTotal Loss: 446.485504\n",
      "Reconstruction: 444.829773, Regularization: 1.655733\n",
      "2019-04-09 22:42:22,009 root         INFO     Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 72.166786\n",
      "Reconstruction: 71.108162, Regularization: 1.058624\n",
      "2019-04-09 22:42:22,064 root         INFO     Train Epoch: 91 [3584/8000 (45%)]\tTotal Loss: 21.114342\n",
      "Reconstruction: 19.375221, Regularization: 1.739121\n",
      "2019-04-09 22:42:22,120 root         INFO     Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 1068.612061\n",
      "Reconstruction: 1066.651489, Regularization: 1.960599\n",
      "2019-04-09 22:42:22,175 root         INFO     Train Epoch: 91 [4608/8000 (58%)]\tTotal Loss: 26.523956\n",
      "Reconstruction: 25.242422, Regularization: 1.281533\n",
      "2019-04-09 22:42:22,230 root         INFO     Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 744.380920\n",
      "Reconstruction: 743.255249, Regularization: 1.125677\n",
      "2019-04-09 22:42:22,286 root         INFO     Train Epoch: 91 [5632/8000 (70%)]\tTotal Loss: 1047.612061\n",
      "Reconstruction: 1045.615723, Regularization: 1.996292\n",
      "2019-04-09 22:42:22,341 root         INFO     Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 60.448708\n",
      "Reconstruction: 58.914558, Regularization: 1.534150\n",
      "2019-04-09 22:42:22,396 root         INFO     Train Epoch: 91 [6656/8000 (83%)]\tTotal Loss: 55.525673\n",
      "Reconstruction: 54.482731, Regularization: 1.042942\n",
      "2019-04-09 22:42:22,450 root         INFO     Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 4.954781\n",
      "Reconstruction: 2.989910, Regularization: 1.964871\n",
      "2019-04-09 22:42:22,506 root         INFO     Train Epoch: 91 [7680/8000 (96%)]\tTotal Loss: 233.848145\n",
      "Reconstruction: 232.217316, Regularization: 1.630832\n",
      "2019-04-09 22:42:22,556 root         INFO     ====> Epoch: 91 Average loss: 6259.4874\n",
      "2019-04-09 22:42:22,579 root         INFO     Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 52.430351\n",
      "Reconstruction: 50.592030, Regularization: 1.838320\n",
      "2019-04-09 22:42:22,635 root         INFO     Train Epoch: 92 [512/8000 (6%)]\tTotal Loss: 14.432789\n",
      "Reconstruction: 12.282448, Regularization: 2.150341\n",
      "2019-04-09 22:42:22,690 root         INFO     Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 19.737059\n",
      "Reconstruction: 18.212795, Regularization: 1.524263\n",
      "2019-04-09 22:42:22,745 root         INFO     Train Epoch: 92 [1536/8000 (19%)]\tTotal Loss: 45.464340\n",
      "Reconstruction: 44.399754, Regularization: 1.064588\n",
      "2019-04-09 22:42:22,801 root         INFO     Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 35.420689\n",
      "Reconstruction: 33.540722, Regularization: 1.879968\n",
      "2019-04-09 22:42:22,856 root         INFO     Train Epoch: 92 [2560/8000 (32%)]\tTotal Loss: 1345.097046\n",
      "Reconstruction: 1343.524658, Regularization: 1.572374\n",
      "2019-04-09 22:42:22,911 root         INFO     Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 52.296059\n",
      "Reconstruction: 51.364311, Regularization: 0.931749\n",
      "2019-04-09 22:42:22,966 root         INFO     Train Epoch: 92 [3584/8000 (45%)]\tTotal Loss: 1171.350952\n",
      "Reconstruction: 1169.503174, Regularization: 1.847771\n",
      "2019-04-09 22:42:23,021 root         INFO     Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 41.541340\n",
      "Reconstruction: 40.174194, Regularization: 1.367146\n",
      "2019-04-09 22:42:23,077 root         INFO     Train Epoch: 92 [4608/8000 (58%)]\tTotal Loss: 197.993927\n",
      "Reconstruction: 197.147766, Regularization: 0.846166\n",
      "2019-04-09 22:42:23,132 root         INFO     Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 255.517593\n",
      "Reconstruction: 253.777100, Regularization: 1.740493\n",
      "2019-04-09 22:42:23,187 root         INFO     Train Epoch: 92 [5632/8000 (70%)]\tTotal Loss: 1521.088379\n",
      "Reconstruction: 1519.842407, Regularization: 1.245980\n",
      "2019-04-09 22:42:23,242 root         INFO     Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 31.887968\n",
      "Reconstruction: 30.376144, Regularization: 1.511823\n",
      "2019-04-09 22:42:23,298 root         INFO     Train Epoch: 92 [6656/8000 (83%)]\tTotal Loss: 160.281433\n",
      "Reconstruction: 158.478058, Regularization: 1.803374\n",
      "2019-04-09 22:42:23,353 root         INFO     Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 95.380302\n",
      "Reconstruction: 93.392845, Regularization: 1.987458\n",
      "2019-04-09 22:42:23,408 root         INFO     Train Epoch: 92 [7680/8000 (96%)]\tTotal Loss: 3.623075\n",
      "Reconstruction: 2.454577, Regularization: 1.168498\n",
      "2019-04-09 22:42:23,457 root         INFO     ====> Epoch: 92 Average loss: 3781.3628\n",
      "2019-04-09 22:42:23,480 root         INFO     Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 124.899437\n",
      "Reconstruction: 123.086945, Regularization: 1.812491\n",
      "2019-04-09 22:42:23,536 root         INFO     Train Epoch: 93 [512/8000 (6%)]\tTotal Loss: 46.475330\n",
      "Reconstruction: 44.875725, Regularization: 1.599605\n",
      "2019-04-09 22:42:23,591 root         INFO     Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 2.773116\n",
      "Reconstruction: 1.091039, Regularization: 1.682076\n",
      "2019-04-09 22:42:23,647 root         INFO     Train Epoch: 93 [1536/8000 (19%)]\tTotal Loss: 425.711121\n",
      "Reconstruction: 423.843445, Regularization: 1.867663\n",
      "2019-04-09 22:42:23,702 root         INFO     Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 13.149423\n",
      "Reconstruction: 11.568084, Regularization: 1.581339\n",
      "2019-04-09 22:42:23,757 root         INFO     Train Epoch: 93 [2560/8000 (32%)]\tTotal Loss: 199.546005\n",
      "Reconstruction: 197.616760, Regularization: 1.929250\n",
      "2019-04-09 22:42:23,812 root         INFO     Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 4.662406\n",
      "Reconstruction: 3.545166, Regularization: 1.117240\n",
      "2019-04-09 22:42:23,867 root         INFO     Train Epoch: 93 [3584/8000 (45%)]\tTotal Loss: 4.278328\n",
      "Reconstruction: 2.788199, Regularization: 1.490129\n",
      "2019-04-09 22:42:23,922 root         INFO     Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 65.234497\n",
      "Reconstruction: 63.496262, Regularization: 1.738236\n",
      "2019-04-09 22:42:23,978 root         INFO     Train Epoch: 93 [4608/8000 (58%)]\tTotal Loss: 20.597889\n",
      "Reconstruction: 18.454895, Regularization: 2.142994\n",
      "2019-04-09 22:42:24,033 root         INFO     Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 164.585678\n",
      "Reconstruction: 163.463089, Regularization: 1.122587\n",
      "2019-04-09 22:42:24,088 root         INFO     Train Epoch: 93 [5632/8000 (70%)]\tTotal Loss: 428.655487\n",
      "Reconstruction: 426.844116, Regularization: 1.811367\n",
      "2019-04-09 22:42:24,144 root         INFO     Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 25.866560\n",
      "Reconstruction: 23.717560, Regularization: 2.149000\n",
      "2019-04-09 22:42:24,199 root         INFO     Train Epoch: 93 [6656/8000 (83%)]\tTotal Loss: 42.267159\n",
      "Reconstruction: 40.283863, Regularization: 1.983294\n",
      "2019-04-09 22:42:24,254 root         INFO     Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 70.169044\n",
      "Reconstruction: 68.825790, Regularization: 1.343256\n",
      "2019-04-09 22:42:24,309 root         INFO     Train Epoch: 93 [7680/8000 (96%)]\tTotal Loss: 15.046415\n",
      "Reconstruction: 13.684312, Regularization: 1.362103\n",
      "2019-04-09 22:42:24,358 root         INFO     ====> Epoch: 93 Average loss: 5141.9755\n",
      "2019-04-09 22:42:24,381 root         INFO     Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 2926.616943\n",
      "Reconstruction: 2923.899414, Regularization: 2.717499\n",
      "2019-04-09 22:42:24,436 root         INFO     Train Epoch: 94 [512/8000 (6%)]\tTotal Loss: 106.576492\n",
      "Reconstruction: 105.255104, Regularization: 1.321390\n",
      "2019-04-09 22:42:24,492 root         INFO     Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 2.634732\n",
      "Reconstruction: 1.623668, Regularization: 1.011063\n",
      "2019-04-09 22:42:24,547 root         INFO     Train Epoch: 94 [1536/8000 (19%)]\tTotal Loss: 56.248737\n",
      "Reconstruction: 54.799831, Regularization: 1.448905\n",
      "2019-04-09 22:42:24,602 root         INFO     Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 6.386326\n",
      "Reconstruction: 4.692177, Regularization: 1.694149\n",
      "2019-04-09 22:42:24,657 root         INFO     Train Epoch: 94 [2560/8000 (32%)]\tTotal Loss: 192.031357\n",
      "Reconstruction: 190.517441, Regularization: 1.513917\n",
      "2019-04-09 22:42:24,713 root         INFO     Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 76.314209\n",
      "Reconstruction: 74.752274, Regularization: 1.561939\n",
      "2019-04-09 22:42:24,767 root         INFO     Train Epoch: 94 [3584/8000 (45%)]\tTotal Loss: 289.692535\n",
      "Reconstruction: 288.302307, Regularization: 1.390231\n",
      "2019-04-09 22:42:24,823 root         INFO     Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 1.888082\n",
      "Reconstruction: 0.681548, Regularization: 1.206534\n",
      "2019-04-09 22:42:24,878 root         INFO     Train Epoch: 94 [4608/8000 (58%)]\tTotal Loss: 260.402405\n",
      "Reconstruction: 259.425568, Regularization: 0.976848\n",
      "2019-04-09 22:42:24,932 root         INFO     Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 31.788210\n",
      "Reconstruction: 30.517551, Regularization: 1.270659\n",
      "2019-04-09 22:42:24,987 root         INFO     Train Epoch: 94 [5632/8000 (70%)]\tTotal Loss: 2.813342\n",
      "Reconstruction: 1.715248, Regularization: 1.098093\n",
      "2019-04-09 22:42:25,041 root         INFO     Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 183.980545\n",
      "Reconstruction: 182.365265, Regularization: 1.615287\n",
      "2019-04-09 22:42:25,096 root         INFO     Train Epoch: 94 [6656/8000 (83%)]\tTotal Loss: 19.380285\n",
      "Reconstruction: 17.896965, Regularization: 1.483321\n",
      "2019-04-09 22:42:25,150 root         INFO     Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 157.279953\n",
      "Reconstruction: 154.845001, Regularization: 2.434955\n",
      "2019-04-09 22:42:25,204 root         INFO     Train Epoch: 94 [7680/8000 (96%)]\tTotal Loss: 353.141663\n",
      "Reconstruction: 351.151886, Regularization: 1.989773\n",
      "2019-04-09 22:42:25,253 root         INFO     ====> Epoch: 94 Average loss: 2256.0339\n",
      "2019-04-09 22:42:25,277 root         INFO     Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 248.060425\n",
      "Reconstruction: 246.501007, Regularization: 1.559412\n",
      "2019-04-09 22:42:25,332 root         INFO     Train Epoch: 95 [512/8000 (6%)]\tTotal Loss: 9.180984\n",
      "Reconstruction: 7.590250, Regularization: 1.590734\n",
      "2019-04-09 22:42:25,387 root         INFO     Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 9.733891\n",
      "Reconstruction: 8.494727, Regularization: 1.239165\n",
      "2019-04-09 22:42:25,441 root         INFO     Train Epoch: 95 [1536/8000 (19%)]\tTotal Loss: 50.892952\n",
      "Reconstruction: 49.655972, Regularization: 1.236980\n",
      "2019-04-09 22:42:25,496 root         INFO     Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 76.986954\n",
      "Reconstruction: 75.386360, Regularization: 1.600595\n",
      "2019-04-09 22:42:25,551 root         INFO     Train Epoch: 95 [2560/8000 (32%)]\tTotal Loss: 15.751267\n",
      "Reconstruction: 13.969010, Regularization: 1.782257\n",
      "2019-04-09 22:42:25,606 root         INFO     Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 151.057022\n",
      "Reconstruction: 149.491745, Regularization: 1.565284\n",
      "2019-04-09 22:42:25,660 root         INFO     Train Epoch: 95 [3584/8000 (45%)]\tTotal Loss: 521.898254\n",
      "Reconstruction: 520.500610, Regularization: 1.397660\n",
      "2019-04-09 22:42:25,715 root         INFO     Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 51.099155\n",
      "Reconstruction: 49.941223, Regularization: 1.157933\n",
      "2019-04-09 22:42:25,769 root         INFO     Train Epoch: 95 [4608/8000 (58%)]\tTotal Loss: 16.141121\n",
      "Reconstruction: 14.598635, Regularization: 1.542486\n",
      "2019-04-09 22:42:25,824 root         INFO     Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 11.016442\n",
      "Reconstruction: 9.718797, Regularization: 1.297646\n",
      "2019-04-09 22:42:25,879 root         INFO     Train Epoch: 95 [5632/8000 (70%)]\tTotal Loss: 2.810487\n",
      "Reconstruction: 1.393901, Regularization: 1.416585\n",
      "2019-04-09 22:42:25,933 root         INFO     Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 62.986774\n",
      "Reconstruction: 60.980766, Regularization: 2.006008\n",
      "2019-04-09 22:42:25,988 root         INFO     Train Epoch: 95 [6656/8000 (83%)]\tTotal Loss: 6.306533\n",
      "Reconstruction: 4.974475, Regularization: 1.332058\n",
      "2019-04-09 22:42:26,042 root         INFO     Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 127.354050\n",
      "Reconstruction: 125.273338, Regularization: 2.080711\n",
      "2019-04-09 22:42:26,097 root         INFO     Train Epoch: 95 [7680/8000 (96%)]\tTotal Loss: 3954.229736\n",
      "Reconstruction: 3952.003906, Regularization: 2.225749\n",
      "2019-04-09 22:42:26,146 root         INFO     ====> Epoch: 95 Average loss: 1687.6084\n",
      "2019-04-09 22:42:26,169 root         INFO     Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 6903.737793\n",
      "Reconstruction: 6902.009277, Regularization: 1.728450\n",
      "2019-04-09 22:42:26,226 root         INFO     Train Epoch: 96 [512/8000 (6%)]\tTotal Loss: 24.395124\n",
      "Reconstruction: 22.796684, Regularization: 1.598439\n",
      "2019-04-09 22:42:26,282 root         INFO     Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 24.779007\n",
      "Reconstruction: 23.553394, Regularization: 1.225612\n",
      "2019-04-09 22:42:26,339 root         INFO     Train Epoch: 96 [1536/8000 (19%)]\tTotal Loss: 233.795120\n",
      "Reconstruction: 232.067429, Regularization: 1.727693\n",
      "2019-04-09 22:42:26,396 root         INFO     Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 10.778899\n",
      "Reconstruction: 8.691691, Regularization: 2.087208\n",
      "2019-04-09 22:42:26,453 root         INFO     Train Epoch: 96 [2560/8000 (32%)]\tTotal Loss: 98.641098\n",
      "Reconstruction: 96.966156, Regularization: 1.674946\n",
      "2019-04-09 22:42:26,509 root         INFO     Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 196.585999\n",
      "Reconstruction: 194.645691, Regularization: 1.940302\n",
      "2019-04-09 22:42:26,566 root         INFO     Train Epoch: 96 [3584/8000 (45%)]\tTotal Loss: 315.684601\n",
      "Reconstruction: 313.131805, Regularization: 2.552790\n",
      "2019-04-09 22:42:26,623 root         INFO     Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 45.662231\n",
      "Reconstruction: 44.581669, Regularization: 1.080562\n",
      "2019-04-09 22:42:26,680 root         INFO     Train Epoch: 96 [4608/8000 (58%)]\tTotal Loss: 6319.232422\n",
      "Reconstruction: 6317.416504, Regularization: 1.815819\n",
      "2019-04-09 22:42:26,737 root         INFO     Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 4539.862305\n",
      "Reconstruction: 4538.712402, Regularization: 1.150131\n",
      "2019-04-09 22:42:26,793 root         INFO     Train Epoch: 96 [5632/8000 (70%)]\tTotal Loss: 6.929255\n",
      "Reconstruction: 6.023993, Regularization: 0.905262\n",
      "2019-04-09 22:42:26,850 root         INFO     Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 70.191612\n",
      "Reconstruction: 69.276787, Regularization: 0.914828\n",
      "2019-04-09 22:42:26,907 root         INFO     Train Epoch: 96 [6656/8000 (83%)]\tTotal Loss: 789.930481\n",
      "Reconstruction: 788.303162, Regularization: 1.627289\n",
      "2019-04-09 22:42:26,964 root         INFO     Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 104.891090\n",
      "Reconstruction: 103.407700, Regularization: 1.483388\n",
      "2019-04-09 22:42:27,020 root         INFO     Train Epoch: 96 [7680/8000 (96%)]\tTotal Loss: 158.588455\n",
      "Reconstruction: 157.394333, Regularization: 1.194128\n",
      "2019-04-09 22:42:27,071 root         INFO     ====> Epoch: 96 Average loss: 3949.6031\n",
      "2019-04-09 22:42:27,094 root         INFO     Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 167.420059\n",
      "Reconstruction: 165.380020, Regularization: 2.040044\n",
      "2019-04-09 22:42:27,150 root         INFO     Train Epoch: 97 [512/8000 (6%)]\tTotal Loss: 91.279961\n",
      "Reconstruction: 90.163467, Regularization: 1.116493\n",
      "2019-04-09 22:42:27,205 root         INFO     Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 105042.289062\n",
      "Reconstruction: 105040.546875, Regularization: 1.744970\n",
      "2019-04-09 22:42:27,260 root         INFO     Train Epoch: 97 [1536/8000 (19%)]\tTotal Loss: 42.798729\n",
      "Reconstruction: 41.394978, Regularization: 1.403751\n",
      "2019-04-09 22:42:27,316 root         INFO     Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 3.372253\n",
      "Reconstruction: 1.256747, Regularization: 2.115507\n",
      "2019-04-09 22:42:27,371 root         INFO     Train Epoch: 97 [2560/8000 (32%)]\tTotal Loss: 3.240593\n",
      "Reconstruction: 1.977271, Regularization: 1.263322\n",
      "2019-04-09 22:42:27,427 root         INFO     Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 1378.135254\n",
      "Reconstruction: 1376.823730, Regularization: 1.311484\n",
      "2019-04-09 22:42:27,483 root         INFO     Train Epoch: 97 [3584/8000 (45%)]\tTotal Loss: 39.480972\n",
      "Reconstruction: 38.614136, Regularization: 0.866838\n",
      "2019-04-09 22:42:27,539 root         INFO     Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 33.063267\n",
      "Reconstruction: 31.866251, Regularization: 1.197016\n",
      "2019-04-09 22:42:27,595 root         INFO     Train Epoch: 97 [4608/8000 (58%)]\tTotal Loss: 22.217871\n",
      "Reconstruction: 20.552265, Regularization: 1.665606\n",
      "2019-04-09 22:42:27,652 root         INFO     Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 479.737030\n",
      "Reconstruction: 477.576996, Regularization: 2.160024\n",
      "2019-04-09 22:42:27,710 root         INFO     Train Epoch: 97 [5632/8000 (70%)]\tTotal Loss: 935.421692\n",
      "Reconstruction: 933.997864, Regularization: 1.423826\n",
      "2019-04-09 22:42:27,765 root         INFO     Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 41.700188\n",
      "Reconstruction: 39.648460, Regularization: 2.051726\n",
      "2019-04-09 22:42:27,820 root         INFO     Train Epoch: 97 [6656/8000 (83%)]\tTotal Loss: 94.170334\n",
      "Reconstruction: 92.187866, Regularization: 1.982466\n",
      "2019-04-09 22:42:27,874 root         INFO     Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 9.672055\n",
      "Reconstruction: 8.653530, Regularization: 1.018525\n",
      "2019-04-09 22:42:27,929 root         INFO     Train Epoch: 97 [7680/8000 (96%)]\tTotal Loss: 9.056219\n",
      "Reconstruction: 7.812840, Regularization: 1.243379\n",
      "2019-04-09 22:42:27,977 root         INFO     ====> Epoch: 97 Average loss: 2035.5946\n",
      "2019-04-09 22:42:28,000 root         INFO     Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 59.270050\n",
      "Reconstruction: 56.959991, Regularization: 2.310058\n",
      "2019-04-09 22:42:28,057 root         INFO     Train Epoch: 98 [512/8000 (6%)]\tTotal Loss: 180.265961\n",
      "Reconstruction: 178.732391, Regularization: 1.533565\n",
      "2019-04-09 22:42:28,114 root         INFO     Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 1042.439331\n",
      "Reconstruction: 1040.154419, Regularization: 2.284908\n",
      "2019-04-09 22:42:28,171 root         INFO     Train Epoch: 98 [1536/8000 (19%)]\tTotal Loss: 72.106758\n",
      "Reconstruction: 69.844948, Regularization: 2.261812\n",
      "2019-04-09 22:42:28,228 root         INFO     Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 16.304829\n",
      "Reconstruction: 14.489714, Regularization: 1.815116\n",
      "2019-04-09 22:42:28,285 root         INFO     Train Epoch: 98 [2560/8000 (32%)]\tTotal Loss: 17.892843\n",
      "Reconstruction: 16.972151, Regularization: 0.920692\n",
      "2019-04-09 22:42:28,342 root         INFO     Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 8.955021\n",
      "Reconstruction: 8.252786, Regularization: 0.702235\n",
      "2019-04-09 22:42:28,399 root         INFO     Train Epoch: 98 [3584/8000 (45%)]\tTotal Loss: 18.510387\n",
      "Reconstruction: 17.367346, Regularization: 1.143041\n",
      "2019-04-09 22:42:28,455 root         INFO     Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 84.052582\n",
      "Reconstruction: 82.300644, Regularization: 1.751937\n",
      "2019-04-09 22:42:28,512 root         INFO     Train Epoch: 98 [4608/8000 (58%)]\tTotal Loss: 516.411011\n",
      "Reconstruction: 515.037354, Regularization: 1.373635\n",
      "2019-04-09 22:42:28,569 root         INFO     Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 26.853029\n",
      "Reconstruction: 25.375931, Regularization: 1.477099\n",
      "2019-04-09 22:42:28,625 root         INFO     Train Epoch: 98 [5632/8000 (70%)]\tTotal Loss: 38.982777\n",
      "Reconstruction: 37.982136, Regularization: 1.000641\n",
      "2019-04-09 22:42:28,682 root         INFO     Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 15.940378\n",
      "Reconstruction: 14.449468, Regularization: 1.490911\n",
      "2019-04-09 22:42:28,739 root         INFO     Train Epoch: 98 [6656/8000 (83%)]\tTotal Loss: 898.290466\n",
      "Reconstruction: 896.507019, Regularization: 1.783453\n",
      "2019-04-09 22:42:28,795 root         INFO     Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 11.435234\n",
      "Reconstruction: 9.918294, Regularization: 1.516940\n",
      "2019-04-09 22:42:28,852 root         INFO     Train Epoch: 98 [7680/8000 (96%)]\tTotal Loss: 27.491100\n",
      "Reconstruction: 25.757267, Regularization: 1.733832\n",
      "2019-04-09 22:42:28,902 root         INFO     ====> Epoch: 98 Average loss: 3326.3516\n",
      "2019-04-09 22:42:28,925 root         INFO     Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 93.922585\n",
      "Reconstruction: 92.683899, Regularization: 1.238688\n",
      "2019-04-09 22:42:28,982 root         INFO     Train Epoch: 99 [512/8000 (6%)]\tTotal Loss: 310.560394\n",
      "Reconstruction: 309.215607, Regularization: 1.344779\n",
      "2019-04-09 22:42:29,038 root         INFO     Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 1337.469971\n",
      "Reconstruction: 1335.788696, Regularization: 1.681247\n",
      "2019-04-09 22:42:29,094 root         INFO     Train Epoch: 99 [1536/8000 (19%)]\tTotal Loss: 1315.221558\n",
      "Reconstruction: 1313.724854, Regularization: 1.496704\n",
      "2019-04-09 22:42:29,151 root         INFO     Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 897.206299\n",
      "Reconstruction: 895.797485, Regularization: 1.408821\n",
      "2019-04-09 22:42:29,207 root         INFO     Train Epoch: 99 [2560/8000 (32%)]\tTotal Loss: 75.834320\n",
      "Reconstruction: 74.299309, Regularization: 1.535009\n",
      "2019-04-09 22:42:29,264 root         INFO     Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 17.351898\n",
      "Reconstruction: 14.982580, Regularization: 2.369318\n",
      "2019-04-09 22:42:29,320 root         INFO     Train Epoch: 99 [3584/8000 (45%)]\tTotal Loss: 61.854786\n",
      "Reconstruction: 60.602146, Regularization: 1.252639\n",
      "2019-04-09 22:42:29,377 root         INFO     Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 76.910210\n",
      "Reconstruction: 74.846100, Regularization: 2.064108\n",
      "2019-04-09 22:42:29,434 root         INFO     Train Epoch: 99 [4608/8000 (58%)]\tTotal Loss: 23.581734\n",
      "Reconstruction: 22.392330, Regularization: 1.189403\n",
      "2019-04-09 22:42:29,490 root         INFO     Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 72.987915\n",
      "Reconstruction: 70.846046, Regularization: 2.141868\n",
      "2019-04-09 22:42:29,547 root         INFO     Train Epoch: 99 [5632/8000 (70%)]\tTotal Loss: 151.324570\n",
      "Reconstruction: 149.715515, Regularization: 1.609056\n",
      "2019-04-09 22:42:29,604 root         INFO     Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 50460.539062\n",
      "Reconstruction: 50458.878906, Regularization: 1.660223\n",
      "2019-04-09 22:42:29,660 root         INFO     Train Epoch: 99 [6656/8000 (83%)]\tTotal Loss: 37.866543\n",
      "Reconstruction: 36.546848, Regularization: 1.319695\n",
      "2019-04-09 22:42:29,717 root         INFO     Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 51.118877\n",
      "Reconstruction: 49.121876, Regularization: 1.997001\n",
      "2019-04-09 22:42:29,774 root         INFO     Train Epoch: 99 [7680/8000 (96%)]\tTotal Loss: 506.393402\n",
      "Reconstruction: 505.440338, Regularization: 0.953067\n",
      "2019-04-09 22:42:29,823 root         INFO     ====> Epoch: 99 Average loss: 1323.4788\n",
      "2019-04-09 22:42:29,847 root         INFO     Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 101.209679\n",
      "Reconstruction: 99.766777, Regularization: 1.442898\n",
      "2019-04-09 22:42:29,904 root         INFO     Train Epoch: 100 [512/8000 (6%)]\tTotal Loss: 5.430109\n",
      "Reconstruction: 4.522977, Regularization: 0.907132\n",
      "2019-04-09 22:42:29,960 root         INFO     Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 15.694769\n",
      "Reconstruction: 13.881713, Regularization: 1.813056\n",
      "2019-04-09 22:42:30,015 root         INFO     Train Epoch: 100 [1536/8000 (19%)]\tTotal Loss: 99828.101562\n",
      "Reconstruction: 99826.843750, Regularization: 1.260846\n",
      "2019-04-09 22:42:30,071 root         INFO     Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 24.558628\n",
      "Reconstruction: 22.798292, Regularization: 1.760335\n",
      "2019-04-09 22:42:30,126 root         INFO     Train Epoch: 100 [2560/8000 (32%)]\tTotal Loss: 163.167923\n",
      "Reconstruction: 161.824203, Regularization: 1.343725\n",
      "2019-04-09 22:42:30,181 root         INFO     Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 6.967062\n",
      "Reconstruction: 5.487793, Regularization: 1.479268\n",
      "2019-04-09 22:42:30,235 root         INFO     Train Epoch: 100 [3584/8000 (45%)]\tTotal Loss: 7.123077\n",
      "Reconstruction: 5.821172, Regularization: 1.301905\n",
      "2019-04-09 22:42:30,291 root         INFO     Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 470.373352\n",
      "Reconstruction: 467.840790, Regularization: 2.532566\n",
      "2019-04-09 22:42:30,345 root         INFO     Train Epoch: 100 [4608/8000 (58%)]\tTotal Loss: 424.587616\n",
      "Reconstruction: 423.675507, Regularization: 0.912118\n",
      "2019-04-09 22:42:30,401 root         INFO     Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 667.907166\n",
      "Reconstruction: 666.147705, Regularization: 1.759454\n",
      "2019-04-09 22:42:30,455 root         INFO     Train Epoch: 100 [5632/8000 (70%)]\tTotal Loss: 2532.867676\n",
      "Reconstruction: 2531.269775, Regularization: 1.597928\n",
      "2019-04-09 22:42:30,510 root         INFO     Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 382.780121\n",
      "Reconstruction: 381.004639, Regularization: 1.775476\n",
      "2019-04-09 22:42:30,565 root         INFO     Train Epoch: 100 [6656/8000 (83%)]\tTotal Loss: 200.642059\n",
      "Reconstruction: 199.469711, Regularization: 1.172343\n",
      "2019-04-09 22:42:30,620 root         INFO     Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 135.482117\n",
      "Reconstruction: 134.245834, Regularization: 1.236277\n",
      "2019-04-09 22:42:30,674 root         INFO     Train Epoch: 100 [7680/8000 (96%)]\tTotal Loss: 92.036789\n",
      "Reconstruction: 90.358162, Regularization: 1.678629\n",
      "2019-04-09 22:42:30,723 root         INFO     ====> Epoch: 100 Average loss: 1554.2774\n",
      "2019-04-09 22:42:30,746 root         INFO     Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 90.350403\n",
      "Reconstruction: 88.843567, Regularization: 1.506836\n",
      "2019-04-09 22:42:30,802 root         INFO     Train Epoch: 101 [512/8000 (6%)]\tTotal Loss: 25.966995\n",
      "Reconstruction: 24.581074, Regularization: 1.385922\n",
      "2019-04-09 22:42:30,858 root         INFO     Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 38.358120\n",
      "Reconstruction: 37.198483, Regularization: 1.159639\n",
      "2019-04-09 22:42:30,914 root         INFO     Train Epoch: 101 [1536/8000 (19%)]\tTotal Loss: 400.713470\n",
      "Reconstruction: 398.831787, Regularization: 1.881685\n",
      "2019-04-09 22:42:30,970 root         INFO     Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 12142.895508\n",
      "Reconstruction: 12141.217773, Regularization: 1.678010\n",
      "2019-04-09 22:42:31,026 root         INFO     Train Epoch: 101 [2560/8000 (32%)]\tTotal Loss: 304.056854\n",
      "Reconstruction: 302.229187, Regularization: 1.827677\n",
      "2019-04-09 22:42:31,082 root         INFO     Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 8.477133\n",
      "Reconstruction: 6.951764, Regularization: 1.525368\n",
      "2019-04-09 22:42:31,138 root         INFO     Train Epoch: 101 [3584/8000 (45%)]\tTotal Loss: 287.017487\n",
      "Reconstruction: 285.750946, Regularization: 1.266534\n",
      "2019-04-09 22:42:31,193 root         INFO     Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 2843.208740\n",
      "Reconstruction: 2841.301758, Regularization: 1.907009\n",
      "2019-04-09 22:42:31,249 root         INFO     Train Epoch: 101 [4608/8000 (58%)]\tTotal Loss: 2663.812500\n",
      "Reconstruction: 2662.038574, Regularization: 1.773880\n",
      "2019-04-09 22:42:31,305 root         INFO     Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 132.209259\n",
      "Reconstruction: 130.696472, Regularization: 1.512792\n",
      "2019-04-09 22:42:31,361 root         INFO     Train Epoch: 101 [5632/8000 (70%)]\tTotal Loss: 502.442413\n",
      "Reconstruction: 500.355225, Regularization: 2.087179\n",
      "2019-04-09 22:42:31,417 root         INFO     Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 3.924174\n",
      "Reconstruction: 2.907710, Regularization: 1.016465\n",
      "2019-04-09 22:42:31,472 root         INFO     Train Epoch: 101 [6656/8000 (83%)]\tTotal Loss: 26.656796\n",
      "Reconstruction: 25.285315, Regularization: 1.371480\n",
      "2019-04-09 22:42:31,527 root         INFO     Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 153.642151\n",
      "Reconstruction: 152.556793, Regularization: 1.085363\n",
      "2019-04-09 22:42:31,583 root         INFO     Train Epoch: 101 [7680/8000 (96%)]\tTotal Loss: 4579.186035\n",
      "Reconstruction: 4577.462402, Regularization: 1.723861\n",
      "2019-04-09 22:42:31,632 root         INFO     ====> Epoch: 101 Average loss: 2878.4998\n",
      "2019-04-09 22:42:31,655 root         INFO     Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 824.977844\n",
      "Reconstruction: 823.466003, Regularization: 1.511811\n",
      "2019-04-09 22:42:31,710 root         INFO     Train Epoch: 102 [512/8000 (6%)]\tTotal Loss: 10.662266\n",
      "Reconstruction: 9.477907, Regularization: 1.184358\n",
      "2019-04-09 22:42:31,766 root         INFO     Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 163.972824\n",
      "Reconstruction: 162.454315, Regularization: 1.518516\n",
      "2019-04-09 22:42:31,823 root         INFO     Train Epoch: 102 [1536/8000 (19%)]\tTotal Loss: 157.357468\n",
      "Reconstruction: 155.893051, Regularization: 1.464414\n",
      "2019-04-09 22:42:31,880 root         INFO     Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 16.455618\n",
      "Reconstruction: 15.580761, Regularization: 0.874857\n",
      "2019-04-09 22:42:31,936 root         INFO     Train Epoch: 102 [2560/8000 (32%)]\tTotal Loss: 20.082764\n",
      "Reconstruction: 18.640644, Regularization: 1.442120\n",
      "2019-04-09 22:42:31,993 root         INFO     Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 39.326950\n",
      "Reconstruction: 38.270470, Regularization: 1.056482\n",
      "2019-04-09 22:42:32,050 root         INFO     Train Epoch: 102 [3584/8000 (45%)]\tTotal Loss: 4279.137207\n",
      "Reconstruction: 4277.125000, Regularization: 2.012432\n",
      "2019-04-09 22:42:32,106 root         INFO     Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 22.601034\n",
      "Reconstruction: 20.201624, Regularization: 2.399410\n",
      "2019-04-09 22:42:32,163 root         INFO     Train Epoch: 102 [4608/8000 (58%)]\tTotal Loss: 188.155548\n",
      "Reconstruction: 186.856689, Regularization: 1.298859\n",
      "2019-04-09 22:42:32,220 root         INFO     Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 180.911133\n",
      "Reconstruction: 179.129150, Regularization: 1.781985\n",
      "2019-04-09 22:42:32,276 root         INFO     Train Epoch: 102 [5632/8000 (70%)]\tTotal Loss: 19.615662\n",
      "Reconstruction: 18.263910, Regularization: 1.351752\n",
      "2019-04-09 22:42:32,333 root         INFO     Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 3.770893\n",
      "Reconstruction: 2.971559, Regularization: 0.799334\n",
      "2019-04-09 22:42:32,390 root         INFO     Train Epoch: 102 [6656/8000 (83%)]\tTotal Loss: 16.897308\n",
      "Reconstruction: 15.742151, Regularization: 1.155157\n",
      "2019-04-09 22:42:32,447 root         INFO     Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 645.241028\n",
      "Reconstruction: 643.447388, Regularization: 1.793655\n",
      "2019-04-09 22:42:32,504 root         INFO     Train Epoch: 102 [7680/8000 (96%)]\tTotal Loss: 26.827847\n",
      "Reconstruction: 25.356911, Regularization: 1.470936\n",
      "2019-04-09 22:42:32,554 root         INFO     ====> Epoch: 102 Average loss: 1616.1501\n",
      "2019-04-09 22:42:32,577 root         INFO     Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 36.139496\n",
      "Reconstruction: 34.053200, Regularization: 2.086296\n",
      "2019-04-09 22:42:32,633 root         INFO     Train Epoch: 103 [512/8000 (6%)]\tTotal Loss: 2.323315\n",
      "Reconstruction: 1.555210, Regularization: 0.768105\n",
      "2019-04-09 22:42:32,689 root         INFO     Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 2855.246094\n",
      "Reconstruction: 2853.453125, Regularization: 1.793001\n",
      "2019-04-09 22:42:32,746 root         INFO     Train Epoch: 103 [1536/8000 (19%)]\tTotal Loss: 228.688965\n",
      "Reconstruction: 227.013443, Regularization: 1.675522\n",
      "2019-04-09 22:42:32,802 root         INFO     Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 23.481760\n",
      "Reconstruction: 21.863628, Regularization: 1.618132\n",
      "2019-04-09 22:42:32,858 root         INFO     Train Epoch: 103 [2560/8000 (32%)]\tTotal Loss: 12.120094\n",
      "Reconstruction: 11.201163, Regularization: 0.918931\n",
      "2019-04-09 22:42:32,914 root         INFO     Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 6.507091\n",
      "Reconstruction: 5.389780, Regularization: 1.117311\n",
      "2019-04-09 22:42:32,970 root         INFO     Train Epoch: 103 [3584/8000 (45%)]\tTotal Loss: 13804.549805\n",
      "Reconstruction: 13802.762695, Regularization: 1.786838\n",
      "2019-04-09 22:42:33,027 root         INFO     Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 54.516495\n",
      "Reconstruction: 52.729607, Regularization: 1.786889\n",
      "2019-04-09 22:42:33,083 root         INFO     Train Epoch: 103 [4608/8000 (58%)]\tTotal Loss: 5.369531\n",
      "Reconstruction: 3.699431, Regularization: 1.670099\n",
      "2019-04-09 22:42:33,139 root         INFO     Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 148.025925\n",
      "Reconstruction: 146.621765, Regularization: 1.404155\n",
      "2019-04-09 22:42:33,194 root         INFO     Train Epoch: 103 [5632/8000 (70%)]\tTotal Loss: 6.160444\n",
      "Reconstruction: 4.777154, Regularization: 1.383290\n",
      "2019-04-09 22:42:33,250 root         INFO     Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 1022.695557\n",
      "Reconstruction: 1020.445679, Regularization: 2.249864\n",
      "2019-04-09 22:42:33,307 root         INFO     Train Epoch: 103 [6656/8000 (83%)]\tTotal Loss: 11.452132\n",
      "Reconstruction: 10.250317, Regularization: 1.201815\n",
      "2019-04-09 22:42:33,363 root         INFO     Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 71.728935\n",
      "Reconstruction: 70.052124, Regularization: 1.676810\n",
      "2019-04-09 22:42:33,419 root         INFO     Train Epoch: 103 [7680/8000 (96%)]\tTotal Loss: 195.818466\n",
      "Reconstruction: 194.481766, Regularization: 1.336698\n",
      "2019-04-09 22:42:33,468 root         INFO     ====> Epoch: 103 Average loss: 1378.1539\n",
      "2019-04-09 22:42:33,491 root         INFO     Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 291.704285\n",
      "Reconstruction: 290.378540, Regularization: 1.325753\n",
      "2019-04-09 22:42:33,548 root         INFO     Train Epoch: 104 [512/8000 (6%)]\tTotal Loss: 11.247493\n",
      "Reconstruction: 9.785155, Regularization: 1.462337\n",
      "2019-04-09 22:42:33,605 root         INFO     Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 25.455935\n",
      "Reconstruction: 23.894342, Regularization: 1.561592\n",
      "2019-04-09 22:42:33,662 root         INFO     Train Epoch: 104 [1536/8000 (19%)]\tTotal Loss: 10.970215\n",
      "Reconstruction: 9.650879, Regularization: 1.319336\n",
      "2019-04-09 22:42:33,718 root         INFO     Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 49.579525\n",
      "Reconstruction: 47.442032, Regularization: 2.137492\n",
      "2019-04-09 22:42:33,775 root         INFO     Train Epoch: 104 [2560/8000 (32%)]\tTotal Loss: 386.117065\n",
      "Reconstruction: 384.005676, Regularization: 2.111396\n",
      "2019-04-09 22:42:33,833 root         INFO     Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 34.562298\n",
      "Reconstruction: 33.550880, Regularization: 1.011416\n",
      "2019-04-09 22:42:33,891 root         INFO     Train Epoch: 104 [3584/8000 (45%)]\tTotal Loss: 6.298638\n",
      "Reconstruction: 5.027256, Regularization: 1.271382\n",
      "2019-04-09 22:42:33,949 root         INFO     Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 41.245789\n",
      "Reconstruction: 40.025623, Regularization: 1.220165\n",
      "2019-04-09 22:42:34,007 root         INFO     Train Epoch: 104 [4608/8000 (58%)]\tTotal Loss: 1459.565063\n",
      "Reconstruction: 1457.310059, Regularization: 2.254950\n",
      "2019-04-09 22:42:34,063 root         INFO     Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 8.813945\n",
      "Reconstruction: 7.742353, Regularization: 1.071592\n",
      "2019-04-09 22:42:34,120 root         INFO     Train Epoch: 104 [5632/8000 (70%)]\tTotal Loss: 2023.335815\n",
      "Reconstruction: 2021.307373, Regularization: 2.028447\n",
      "2019-04-09 22:42:34,176 root         INFO     Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 9.025670\n",
      "Reconstruction: 7.728331, Regularization: 1.297339\n",
      "2019-04-09 22:42:34,233 root         INFO     Train Epoch: 104 [6656/8000 (83%)]\tTotal Loss: 2969.521484\n",
      "Reconstruction: 2967.731689, Regularization: 1.789728\n",
      "2019-04-09 22:42:34,290 root         INFO     Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 446.106293\n",
      "Reconstruction: 444.503876, Regularization: 1.602420\n",
      "2019-04-09 22:42:34,347 root         INFO     Train Epoch: 104 [7680/8000 (96%)]\tTotal Loss: 389.190308\n",
      "Reconstruction: 387.761292, Regularization: 1.429022\n",
      "2019-04-09 22:42:34,398 root         INFO     ====> Epoch: 104 Average loss: 2036.6868\n",
      "2019-04-09 22:42:34,421 root         INFO     Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 67.924767\n",
      "Reconstruction: 66.407600, Regularization: 1.517169\n",
      "2019-04-09 22:42:34,478 root         INFO     Train Epoch: 105 [512/8000 (6%)]\tTotal Loss: 3.101109\n",
      "Reconstruction: 1.253689, Regularization: 1.847420\n",
      "2019-04-09 22:42:34,534 root         INFO     Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 36.755520\n",
      "Reconstruction: 35.040195, Regularization: 1.715324\n",
      "2019-04-09 22:42:34,591 root         INFO     Train Epoch: 105 [1536/8000 (19%)]\tTotal Loss: 165.645782\n",
      "Reconstruction: 163.635925, Regularization: 2.009851\n",
      "2019-04-09 22:42:34,647 root         INFO     Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 86506.617188\n",
      "Reconstruction: 86504.640625, Regularization: 1.977312\n",
      "2019-04-09 22:42:34,704 root         INFO     Train Epoch: 105 [2560/8000 (32%)]\tTotal Loss: 91.526718\n",
      "Reconstruction: 89.987083, Regularization: 1.539637\n",
      "2019-04-09 22:42:34,760 root         INFO     Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 18.447014\n",
      "Reconstruction: 17.253971, Regularization: 1.193044\n",
      "2019-04-09 22:42:34,817 root         INFO     Train Epoch: 105 [3584/8000 (45%)]\tTotal Loss: 33.359711\n",
      "Reconstruction: 31.775545, Regularization: 1.584166\n",
      "2019-04-09 22:42:34,874 root         INFO     Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 100.223633\n",
      "Reconstruction: 98.636711, Regularization: 1.586918\n",
      "2019-04-09 22:42:34,929 root         INFO     Train Epoch: 105 [4608/8000 (58%)]\tTotal Loss: 87.942642\n",
      "Reconstruction: 85.554367, Regularization: 2.388276\n",
      "2019-04-09 22:42:34,986 root         INFO     Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 138.032715\n",
      "Reconstruction: 137.284195, Regularization: 0.748527\n",
      "2019-04-09 22:42:35,043 root         INFO     Train Epoch: 105 [5632/8000 (70%)]\tTotal Loss: 58.088219\n",
      "Reconstruction: 56.161579, Regularization: 1.926638\n",
      "2019-04-09 22:42:35,099 root         INFO     Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 9.778668\n",
      "Reconstruction: 8.200674, Regularization: 1.577994\n",
      "2019-04-09 22:42:35,156 root         INFO     Train Epoch: 105 [6656/8000 (83%)]\tTotal Loss: 110.967323\n",
      "Reconstruction: 109.417152, Regularization: 1.550174\n",
      "2019-04-09 22:42:35,212 root         INFO     Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 13.890006\n",
      "Reconstruction: 12.703060, Regularization: 1.186946\n",
      "2019-04-09 22:42:35,269 root         INFO     Train Epoch: 105 [7680/8000 (96%)]\tTotal Loss: 6154.213867\n",
      "Reconstruction: 6152.380859, Regularization: 1.833014\n",
      "2019-04-09 22:42:35,319 root         INFO     ====> Epoch: 105 Average loss: 1285.7568\n",
      "2019-04-09 22:42:35,342 root         INFO     Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 450.299408\n",
      "Reconstruction: 448.911591, Regularization: 1.387821\n",
      "2019-04-09 22:42:35,398 root         INFO     Train Epoch: 106 [512/8000 (6%)]\tTotal Loss: 10.655980\n",
      "Reconstruction: 9.308170, Regularization: 1.347810\n",
      "2019-04-09 22:42:35,455 root         INFO     Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 51.995522\n",
      "Reconstruction: 50.032253, Regularization: 1.963270\n",
      "2019-04-09 22:42:35,515 root         INFO     Train Epoch: 106 [1536/8000 (19%)]\tTotal Loss: 3531.838867\n",
      "Reconstruction: 3529.847168, Regularization: 1.991737\n",
      "2019-04-09 22:42:35,573 root         INFO     Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 3138.073730\n",
      "Reconstruction: 3136.308350, Regularization: 1.765414\n",
      "2019-04-09 22:42:35,636 root         INFO     Train Epoch: 106 [2560/8000 (32%)]\tTotal Loss: 107.403358\n",
      "Reconstruction: 106.080902, Regularization: 1.322456\n",
      "2019-04-09 22:42:35,695 root         INFO     Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 25.406036\n",
      "Reconstruction: 23.003361, Regularization: 2.402675\n",
      "2019-04-09 22:42:35,753 root         INFO     Train Epoch: 106 [3584/8000 (45%)]\tTotal Loss: 17.109968\n",
      "Reconstruction: 15.746825, Regularization: 1.363142\n",
      "2019-04-09 22:42:35,810 root         INFO     Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 5.989048\n",
      "Reconstruction: 4.522578, Regularization: 1.466471\n",
      "2019-04-09 22:42:35,868 root         INFO     Train Epoch: 106 [4608/8000 (58%)]\tTotal Loss: 125.932426\n",
      "Reconstruction: 124.217903, Regularization: 1.714526\n",
      "2019-04-09 22:42:35,925 root         INFO     Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 47.217087\n",
      "Reconstruction: 45.589890, Regularization: 1.627196\n",
      "2019-04-09 22:42:35,982 root         INFO     Train Epoch: 106 [5632/8000 (70%)]\tTotal Loss: 276.135071\n",
      "Reconstruction: 274.392456, Regularization: 1.742611\n",
      "2019-04-09 22:42:36,039 root         INFO     Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 943.984192\n",
      "Reconstruction: 942.086914, Regularization: 1.897286\n",
      "2019-04-09 22:42:36,096 root         INFO     Train Epoch: 106 [6656/8000 (83%)]\tTotal Loss: 538.203186\n",
      "Reconstruction: 536.739990, Regularization: 1.463205\n",
      "2019-04-09 22:42:36,154 root         INFO     Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 3.356730\n",
      "Reconstruction: 2.484936, Regularization: 0.871794\n",
      "2019-04-09 22:42:36,211 root         INFO     Train Epoch: 106 [7680/8000 (96%)]\tTotal Loss: 14.052950\n",
      "Reconstruction: 12.728871, Regularization: 1.324078\n",
      "2019-04-09 22:42:36,262 root         INFO     ====> Epoch: 106 Average loss: 789.8193\n",
      "2019-04-09 22:42:36,285 root         INFO     Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 4.337144\n",
      "Reconstruction: 3.431835, Regularization: 0.905309\n",
      "2019-04-09 22:42:36,341 root         INFO     Train Epoch: 107 [512/8000 (6%)]\tTotal Loss: 521.019531\n",
      "Reconstruction: 519.395020, Regularization: 1.624523\n",
      "2019-04-09 22:42:36,396 root         INFO     Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 11.860365\n",
      "Reconstruction: 10.539827, Regularization: 1.320538\n",
      "2019-04-09 22:42:36,451 root         INFO     Train Epoch: 107 [1536/8000 (19%)]\tTotal Loss: 662.242004\n",
      "Reconstruction: 660.782532, Regularization: 1.459457\n",
      "2019-04-09 22:42:36,507 root         INFO     Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 71.772408\n",
      "Reconstruction: 70.138847, Regularization: 1.633560\n",
      "2019-04-09 22:42:36,562 root         INFO     Train Epoch: 107 [2560/8000 (32%)]\tTotal Loss: 279.666870\n",
      "Reconstruction: 277.817871, Regularization: 1.848985\n",
      "2019-04-09 22:42:36,618 root         INFO     Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 37.599503\n",
      "Reconstruction: 36.329826, Regularization: 1.269674\n",
      "2019-04-09 22:42:36,673 root         INFO     Train Epoch: 107 [3584/8000 (45%)]\tTotal Loss: 240.515701\n",
      "Reconstruction: 239.126831, Regularization: 1.388869\n",
      "2019-04-09 22:42:36,728 root         INFO     Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 7.172473\n",
      "Reconstruction: 6.045283, Regularization: 1.127190\n",
      "2019-04-09 22:42:36,784 root         INFO     Train Epoch: 107 [4608/8000 (58%)]\tTotal Loss: 59.172974\n",
      "Reconstruction: 57.703098, Regularization: 1.469875\n",
      "2019-04-09 22:42:36,839 root         INFO     Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 46.265594\n",
      "Reconstruction: 45.283699, Regularization: 0.981894\n",
      "2019-04-09 22:42:36,895 root         INFO     Train Epoch: 107 [5632/8000 (70%)]\tTotal Loss: 2150.437988\n",
      "Reconstruction: 2148.876953, Regularization: 1.560942\n",
      "2019-04-09 22:42:36,950 root         INFO     Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 13.368093\n",
      "Reconstruction: 12.055402, Regularization: 1.312691\n",
      "2019-04-09 22:42:37,005 root         INFO     Train Epoch: 107 [6656/8000 (83%)]\tTotal Loss: 3.172465\n",
      "Reconstruction: 1.859872, Regularization: 1.312593\n",
      "2019-04-09 22:42:37,061 root         INFO     Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 85.200706\n",
      "Reconstruction: 83.822578, Regularization: 1.378127\n",
      "2019-04-09 22:42:37,116 root         INFO     Train Epoch: 107 [7680/8000 (96%)]\tTotal Loss: 59.390839\n",
      "Reconstruction: 58.120811, Regularization: 1.270027\n",
      "2019-04-09 22:42:37,165 root         INFO     ====> Epoch: 107 Average loss: 564.9239\n",
      "2019-04-09 22:42:37,188 root         INFO     Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 52.420723\n",
      "Reconstruction: 50.755890, Regularization: 1.664832\n",
      "2019-04-09 22:42:37,244 root         INFO     Train Epoch: 108 [512/8000 (6%)]\tTotal Loss: 8.571076\n",
      "Reconstruction: 7.033591, Regularization: 1.537485\n",
      "2019-04-09 22:42:37,300 root         INFO     Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 22.521067\n",
      "Reconstruction: 21.702108, Regularization: 0.818958\n",
      "2019-04-09 22:42:37,356 root         INFO     Train Epoch: 108 [1536/8000 (19%)]\tTotal Loss: 147.412445\n",
      "Reconstruction: 145.392426, Regularization: 2.020014\n",
      "2019-04-09 22:42:37,412 root         INFO     Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 60.488083\n",
      "Reconstruction: 59.019646, Regularization: 1.468437\n",
      "2019-04-09 22:42:37,468 root         INFO     Train Epoch: 108 [2560/8000 (32%)]\tTotal Loss: 87.561264\n",
      "Reconstruction: 86.397858, Regularization: 1.163408\n",
      "2019-04-09 22:42:37,526 root         INFO     Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 238.271423\n",
      "Reconstruction: 236.583496, Regularization: 1.687928\n",
      "2019-04-09 22:42:37,582 root         INFO     Train Epoch: 108 [3584/8000 (45%)]\tTotal Loss: 40.568939\n",
      "Reconstruction: 39.110054, Regularization: 1.458884\n",
      "2019-04-09 22:42:37,638 root         INFO     Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 9.894388\n",
      "Reconstruction: 8.631707, Regularization: 1.262681\n",
      "2019-04-09 22:42:37,694 root         INFO     Train Epoch: 108 [4608/8000 (58%)]\tTotal Loss: 10.028753\n",
      "Reconstruction: 8.766644, Regularization: 1.262110\n",
      "2019-04-09 22:42:37,749 root         INFO     Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 29.496521\n",
      "Reconstruction: 28.482979, Regularization: 1.013542\n",
      "2019-04-09 22:42:37,805 root         INFO     Train Epoch: 108 [5632/8000 (70%)]\tTotal Loss: 47.919285\n",
      "Reconstruction: 46.575886, Regularization: 1.343398\n",
      "2019-04-09 22:42:37,861 root         INFO     Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 95.367897\n",
      "Reconstruction: 93.850929, Regularization: 1.516970\n",
      "2019-04-09 22:42:37,917 root         INFO     Train Epoch: 108 [6656/8000 (83%)]\tTotal Loss: 1027.245117\n",
      "Reconstruction: 1025.504883, Regularization: 1.740247\n",
      "2019-04-09 22:42:37,973 root         INFO     Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 720.567139\n",
      "Reconstruction: 719.039551, Regularization: 1.527577\n",
      "2019-04-09 22:42:38,029 root         INFO     Train Epoch: 108 [7680/8000 (96%)]\tTotal Loss: 36.329998\n",
      "Reconstruction: 34.693001, Regularization: 1.636996\n",
      "2019-04-09 22:42:38,079 root         INFO     ====> Epoch: 108 Average loss: 1051.1014\n",
      "2019-04-09 22:42:38,102 root         INFO     Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 193.495667\n",
      "Reconstruction: 192.253860, Regularization: 1.241809\n",
      "2019-04-09 22:42:38,158 root         INFO     Train Epoch: 109 [512/8000 (6%)]\tTotal Loss: 151.074417\n",
      "Reconstruction: 149.694763, Regularization: 1.379659\n",
      "2019-04-09 22:42:38,214 root         INFO     Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 58.577778\n",
      "Reconstruction: 56.758717, Regularization: 1.819063\n",
      "2019-04-09 22:42:38,270 root         INFO     Train Epoch: 109 [1536/8000 (19%)]\tTotal Loss: 204.748215\n",
      "Reconstruction: 203.446457, Regularization: 1.301758\n",
      "2019-04-09 22:42:38,327 root         INFO     Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 66.387451\n",
      "Reconstruction: 64.973312, Regularization: 1.414143\n",
      "2019-04-09 22:42:38,382 root         INFO     Train Epoch: 109 [2560/8000 (32%)]\tTotal Loss: 37.360283\n",
      "Reconstruction: 35.699345, Regularization: 1.660938\n",
      "2019-04-09 22:42:38,438 root         INFO     Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 4.840944\n",
      "Reconstruction: 3.029820, Regularization: 1.811124\n",
      "2019-04-09 22:42:38,495 root         INFO     Train Epoch: 109 [3584/8000 (45%)]\tTotal Loss: 445.473816\n",
      "Reconstruction: 443.784393, Regularization: 1.689418\n",
      "2019-04-09 22:42:38,551 root         INFO     Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 6319.431152\n",
      "Reconstruction: 6317.612793, Regularization: 1.818533\n",
      "2019-04-09 22:42:38,608 root         INFO     Train Epoch: 109 [4608/8000 (58%)]\tTotal Loss: 18.863209\n",
      "Reconstruction: 16.758282, Regularization: 2.104927\n",
      "2019-04-09 22:42:38,664 root         INFO     Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 8637.631836\n",
      "Reconstruction: 8636.222656, Regularization: 1.408938\n",
      "2019-04-09 22:42:38,719 root         INFO     Train Epoch: 109 [5632/8000 (70%)]\tTotal Loss: 10.195343\n",
      "Reconstruction: 9.139206, Regularization: 1.056137\n",
      "2019-04-09 22:42:38,775 root         INFO     Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 33.099915\n",
      "Reconstruction: 31.576708, Regularization: 1.523208\n",
      "2019-04-09 22:42:38,831 root         INFO     Train Epoch: 109 [6656/8000 (83%)]\tTotal Loss: 16.887516\n",
      "Reconstruction: 15.926836, Regularization: 0.960681\n",
      "2019-04-09 22:42:38,887 root         INFO     Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 14.575039\n",
      "Reconstruction: 13.296730, Regularization: 1.278309\n",
      "2019-04-09 22:42:38,943 root         INFO     Train Epoch: 109 [7680/8000 (96%)]\tTotal Loss: 13.168558\n",
      "Reconstruction: 11.824618, Regularization: 1.343940\n",
      "2019-04-09 22:42:38,993 root         INFO     ====> Epoch: 109 Average loss: 941.7756\n",
      "2019-04-09 22:42:39,016 root         INFO     Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 12.874835\n",
      "Reconstruction: 11.824258, Regularization: 1.050577\n",
      "2019-04-09 22:42:39,071 root         INFO     Train Epoch: 110 [512/8000 (6%)]\tTotal Loss: 518.466003\n",
      "Reconstruction: 517.247986, Regularization: 1.218003\n",
      "2019-04-09 22:42:39,128 root         INFO     Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 34.951530\n",
      "Reconstruction: 33.643066, Regularization: 1.308465\n",
      "2019-04-09 22:42:39,184 root         INFO     Train Epoch: 110 [1536/8000 (19%)]\tTotal Loss: 697.992371\n",
      "Reconstruction: 696.436646, Regularization: 1.555740\n",
      "2019-04-09 22:42:39,240 root         INFO     Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 1404.546265\n",
      "Reconstruction: 1402.995483, Regularization: 1.550815\n",
      "2019-04-09 22:42:39,296 root         INFO     Train Epoch: 110 [2560/8000 (32%)]\tTotal Loss: 2164.425293\n",
      "Reconstruction: 2162.013184, Regularization: 2.412078\n",
      "2019-04-09 22:42:39,352 root         INFO     Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 235.267014\n",
      "Reconstruction: 233.764832, Regularization: 1.502179\n",
      "2019-04-09 22:42:39,408 root         INFO     Train Epoch: 110 [3584/8000 (45%)]\tTotal Loss: 39.386711\n",
      "Reconstruction: 38.387417, Regularization: 0.999295\n",
      "2019-04-09 22:42:39,462 root         INFO     Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 154.433899\n",
      "Reconstruction: 152.940842, Regularization: 1.493062\n",
      "2019-04-09 22:42:39,517 root         INFO     Train Epoch: 110 [4608/8000 (58%)]\tTotal Loss: 20.137379\n",
      "Reconstruction: 18.342167, Regularization: 1.795212\n",
      "2019-04-09 22:42:39,572 root         INFO     Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 71.927193\n",
      "Reconstruction: 70.565704, Regularization: 1.361492\n",
      "2019-04-09 22:42:39,626 root         INFO     Train Epoch: 110 [5632/8000 (70%)]\tTotal Loss: 13.208299\n",
      "Reconstruction: 11.934675, Regularization: 1.273624\n",
      "2019-04-09 22:42:39,681 root         INFO     Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 3.399680\n",
      "Reconstruction: 2.148742, Regularization: 1.250938\n",
      "2019-04-09 22:42:39,736 root         INFO     Train Epoch: 110 [6656/8000 (83%)]\tTotal Loss: 12.450615\n",
      "Reconstruction: 10.667736, Regularization: 1.782879\n",
      "2019-04-09 22:42:39,791 root         INFO     Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 3.479560\n",
      "Reconstruction: 2.012304, Regularization: 1.467256\n",
      "2019-04-09 22:42:39,845 root         INFO     Train Epoch: 110 [7680/8000 (96%)]\tTotal Loss: 1456.787598\n",
      "Reconstruction: 1455.508057, Regularization: 1.279519\n",
      "2019-04-09 22:42:39,893 root         INFO     ====> Epoch: 110 Average loss: 775.7262\n",
      "2019-04-09 22:42:39,917 root         INFO     Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 37.671349\n",
      "Reconstruction: 36.468639, Regularization: 1.202709\n",
      "2019-04-09 22:42:39,972 root         INFO     Train Epoch: 111 [512/8000 (6%)]\tTotal Loss: 202.991425\n",
      "Reconstruction: 202.119019, Regularization: 0.872410\n",
      "2019-04-09 22:42:40,029 root         INFO     Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 41.592533\n",
      "Reconstruction: 40.247673, Regularization: 1.344861\n",
      "2019-04-09 22:42:40,085 root         INFO     Train Epoch: 111 [1536/8000 (19%)]\tTotal Loss: 32.578217\n",
      "Reconstruction: 31.182360, Regularization: 1.395859\n",
      "2019-04-09 22:42:40,141 root         INFO     Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 3.569385\n",
      "Reconstruction: 2.597556, Regularization: 0.971829\n",
      "2019-04-09 22:42:40,198 root         INFO     Train Epoch: 111 [2560/8000 (32%)]\tTotal Loss: 2.914077\n",
      "Reconstruction: 1.306884, Regularization: 1.607192\n",
      "2019-04-09 22:42:40,254 root         INFO     Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 45.062225\n",
      "Reconstruction: 43.803520, Regularization: 1.258707\n",
      "2019-04-09 22:42:40,311 root         INFO     Train Epoch: 111 [3584/8000 (45%)]\tTotal Loss: 7.389301\n",
      "Reconstruction: 6.288180, Regularization: 1.101120\n",
      "2019-04-09 22:42:40,367 root         INFO     Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 172.458847\n",
      "Reconstruction: 170.872559, Regularization: 1.586288\n",
      "2019-04-09 22:42:40,423 root         INFO     Train Epoch: 111 [4608/8000 (58%)]\tTotal Loss: 2.079494\n",
      "Reconstruction: 0.345980, Regularization: 1.733514\n",
      "2019-04-09 22:42:40,478 root         INFO     Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 2901.562012\n",
      "Reconstruction: 2899.229736, Regularization: 2.332259\n",
      "2019-04-09 22:42:40,532 root         INFO     Train Epoch: 111 [5632/8000 (70%)]\tTotal Loss: 64.123779\n",
      "Reconstruction: 62.153477, Regularization: 1.970303\n",
      "2019-04-09 22:42:40,587 root         INFO     Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 11.017591\n",
      "Reconstruction: 9.984133, Regularization: 1.033459\n",
      "2019-04-09 22:42:40,641 root         INFO     Train Epoch: 111 [6656/8000 (83%)]\tTotal Loss: 64.666031\n",
      "Reconstruction: 62.803230, Regularization: 1.862802\n",
      "2019-04-09 22:42:40,695 root         INFO     Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 54.399700\n",
      "Reconstruction: 53.144390, Regularization: 1.255309\n",
      "2019-04-09 22:42:40,749 root         INFO     Train Epoch: 111 [7680/8000 (96%)]\tTotal Loss: 136.372009\n",
      "Reconstruction: 134.881454, Regularization: 1.490558\n",
      "2019-04-09 22:42:40,797 root         INFO     ====> Epoch: 111 Average loss: 591.0118\n",
      "2019-04-09 22:42:40,821 root         INFO     Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 4095.065186\n",
      "Reconstruction: 4093.457520, Regularization: 1.607761\n",
      "2019-04-09 22:42:40,877 root         INFO     Train Epoch: 112 [512/8000 (6%)]\tTotal Loss: 87.919189\n",
      "Reconstruction: 85.674606, Regularization: 2.244586\n",
      "2019-04-09 22:42:40,932 root         INFO     Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 15.378843\n",
      "Reconstruction: 14.204391, Regularization: 1.174452\n",
      "2019-04-09 22:42:40,987 root         INFO     Train Epoch: 112 [1536/8000 (19%)]\tTotal Loss: 89.426575\n",
      "Reconstruction: 88.103241, Regularization: 1.323334\n",
      "2019-04-09 22:42:41,042 root         INFO     Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 86.985268\n",
      "Reconstruction: 85.498268, Regularization: 1.487000\n",
      "2019-04-09 22:42:41,097 root         INFO     Train Epoch: 112 [2560/8000 (32%)]\tTotal Loss: 194.262955\n",
      "Reconstruction: 192.783157, Regularization: 1.479798\n",
      "2019-04-09 22:42:41,152 root         INFO     Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 32.927013\n",
      "Reconstruction: 31.722256, Regularization: 1.204756\n",
      "2019-04-09 22:42:41,207 root         INFO     Train Epoch: 112 [3584/8000 (45%)]\tTotal Loss: 78.104446\n",
      "Reconstruction: 76.768631, Regularization: 1.335818\n",
      "2019-04-09 22:42:41,262 root         INFO     Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 17.299599\n",
      "Reconstruction: 15.899629, Regularization: 1.399969\n",
      "2019-04-09 22:42:41,317 root         INFO     Train Epoch: 112 [4608/8000 (58%)]\tTotal Loss: 21.743422\n",
      "Reconstruction: 20.453304, Regularization: 1.290117\n",
      "2019-04-09 22:42:41,372 root         INFO     Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 5.892310\n",
      "Reconstruction: 4.044158, Regularization: 1.848152\n",
      "2019-04-09 22:42:41,428 root         INFO     Train Epoch: 112 [5632/8000 (70%)]\tTotal Loss: 4.409969\n",
      "Reconstruction: 3.004394, Regularization: 1.405576\n",
      "2019-04-09 22:42:41,484 root         INFO     Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 225.018112\n",
      "Reconstruction: 223.251938, Regularization: 1.766172\n",
      "2019-04-09 22:42:41,539 root         INFO     Train Epoch: 112 [6656/8000 (83%)]\tTotal Loss: 3.348455\n",
      "Reconstruction: 1.981628, Regularization: 1.366827\n",
      "2019-04-09 22:42:41,595 root         INFO     Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 195.512726\n",
      "Reconstruction: 194.118576, Regularization: 1.394144\n",
      "2019-04-09 22:42:41,650 root         INFO     Train Epoch: 112 [7680/8000 (96%)]\tTotal Loss: 2.827572\n",
      "Reconstruction: 1.139414, Regularization: 1.688158\n",
      "2019-04-09 22:42:41,699 root         INFO     ====> Epoch: 112 Average loss: 744.0660\n",
      "2019-04-09 22:42:41,722 root         INFO     Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 62.334763\n",
      "Reconstruction: 60.203590, Regularization: 2.131173\n",
      "2019-04-09 22:42:41,777 root         INFO     Train Epoch: 113 [512/8000 (6%)]\tTotal Loss: 37.640911\n",
      "Reconstruction: 35.666992, Regularization: 1.973919\n",
      "2019-04-09 22:42:41,832 root         INFO     Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 32.693199\n",
      "Reconstruction: 31.182861, Regularization: 1.510337\n",
      "2019-04-09 22:42:41,888 root         INFO     Train Epoch: 113 [1536/8000 (19%)]\tTotal Loss: 181.958130\n",
      "Reconstruction: 179.970993, Regularization: 1.987134\n",
      "2019-04-09 22:42:41,943 root         INFO     Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 13502.389648\n",
      "Reconstruction: 13500.542969, Regularization: 1.846394\n",
      "2019-04-09 22:42:41,998 root         INFO     Train Epoch: 113 [2560/8000 (32%)]\tTotal Loss: 47.833096\n",
      "Reconstruction: 46.467815, Regularization: 1.365280\n",
      "2019-04-09 22:42:42,053 root         INFO     Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 53.186775\n",
      "Reconstruction: 51.665466, Regularization: 1.521308\n",
      "2019-04-09 22:42:42,108 root         INFO     Train Epoch: 113 [3584/8000 (45%)]\tTotal Loss: 6.082179\n",
      "Reconstruction: 4.004251, Regularization: 2.077927\n",
      "2019-04-09 22:42:42,163 root         INFO     Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 23.406607\n",
      "Reconstruction: 21.282648, Regularization: 2.123959\n",
      "2019-04-09 22:42:42,218 root         INFO     Train Epoch: 113 [4608/8000 (58%)]\tTotal Loss: 25.594547\n",
      "Reconstruction: 24.147802, Regularization: 1.446744\n",
      "2019-04-09 22:42:42,273 root         INFO     Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 15.584518\n",
      "Reconstruction: 14.961001, Regularization: 0.623517\n",
      "2019-04-09 22:42:42,328 root         INFO     Train Epoch: 113 [5632/8000 (70%)]\tTotal Loss: 3477.964600\n",
      "Reconstruction: 3476.336914, Regularization: 1.627695\n",
      "2019-04-09 22:42:42,383 root         INFO     Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 3.806791\n",
      "Reconstruction: 2.290374, Regularization: 1.516417\n",
      "2019-04-09 22:42:42,438 root         INFO     Train Epoch: 113 [6656/8000 (83%)]\tTotal Loss: 10.568098\n",
      "Reconstruction: 9.523463, Regularization: 1.044635\n",
      "2019-04-09 22:42:42,493 root         INFO     Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 150.104691\n",
      "Reconstruction: 148.130157, Regularization: 1.974537\n",
      "2019-04-09 22:42:42,549 root         INFO     Train Epoch: 113 [7680/8000 (96%)]\tTotal Loss: 21.508892\n",
      "Reconstruction: 20.339302, Regularization: 1.169590\n",
      "2019-04-09 22:42:42,598 root         INFO     ====> Epoch: 113 Average loss: 416.8847\n",
      "2019-04-09 22:42:42,621 root         INFO     Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 335.309479\n",
      "Reconstruction: 333.835999, Regularization: 1.473483\n",
      "2019-04-09 22:42:42,676 root         INFO     Train Epoch: 114 [512/8000 (6%)]\tTotal Loss: 67.073952\n",
      "Reconstruction: 65.627235, Regularization: 1.446717\n",
      "2019-04-09 22:42:42,731 root         INFO     Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 9.155723\n",
      "Reconstruction: 8.353547, Regularization: 0.802175\n",
      "2019-04-09 22:42:42,786 root         INFO     Train Epoch: 114 [1536/8000 (19%)]\tTotal Loss: 2.753124\n",
      "Reconstruction: 1.766138, Regularization: 0.986986\n",
      "2019-04-09 22:42:42,842 root         INFO     Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 10.800209\n",
      "Reconstruction: 8.877075, Regularization: 1.923134\n",
      "2019-04-09 22:42:42,897 root         INFO     Train Epoch: 114 [2560/8000 (32%)]\tTotal Loss: 8.302423\n",
      "Reconstruction: 6.878429, Regularization: 1.423993\n",
      "2019-04-09 22:42:42,952 root         INFO     Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 18.710054\n",
      "Reconstruction: 17.749647, Regularization: 0.960408\n",
      "2019-04-09 22:42:43,007 root         INFO     Train Epoch: 114 [3584/8000 (45%)]\tTotal Loss: 3.882431\n",
      "Reconstruction: 1.859558, Regularization: 2.022873\n",
      "2019-04-09 22:42:43,062 root         INFO     Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 36.635063\n",
      "Reconstruction: 34.948685, Regularization: 1.686379\n",
      "2019-04-09 22:42:43,117 root         INFO     Train Epoch: 114 [4608/8000 (58%)]\tTotal Loss: 26.204199\n",
      "Reconstruction: 24.092636, Regularization: 2.111563\n",
      "2019-04-09 22:42:43,172 root         INFO     Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 134.909576\n",
      "Reconstruction: 133.397278, Regularization: 1.512300\n",
      "2019-04-09 22:42:43,227 root         INFO     Train Epoch: 114 [5632/8000 (70%)]\tTotal Loss: 6.417026\n",
      "Reconstruction: 5.639719, Regularization: 0.777308\n",
      "2019-04-09 22:42:43,283 root         INFO     Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 14.231630\n",
      "Reconstruction: 13.160208, Regularization: 1.071423\n",
      "2019-04-09 22:42:43,338 root         INFO     Train Epoch: 114 [6656/8000 (83%)]\tTotal Loss: 14.513951\n",
      "Reconstruction: 13.129033, Regularization: 1.384918\n",
      "2019-04-09 22:42:43,393 root         INFO     Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 33.811146\n",
      "Reconstruction: 32.073685, Regularization: 1.737460\n",
      "2019-04-09 22:42:43,448 root         INFO     Train Epoch: 114 [7680/8000 (96%)]\tTotal Loss: 43.556694\n",
      "Reconstruction: 42.093624, Regularization: 1.463069\n",
      "2019-04-09 22:42:43,497 root         INFO     ====> Epoch: 114 Average loss: 576.1703\n",
      "2019-04-09 22:42:43,520 root         INFO     Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 770.399597\n",
      "Reconstruction: 768.920776, Regularization: 1.478839\n",
      "2019-04-09 22:42:43,575 root         INFO     Train Epoch: 115 [512/8000 (6%)]\tTotal Loss: 14.442234\n",
      "Reconstruction: 11.558532, Regularization: 2.883702\n",
      "2019-04-09 22:42:43,630 root         INFO     Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 12.579751\n",
      "Reconstruction: 11.460084, Regularization: 1.119667\n",
      "2019-04-09 22:42:43,685 root         INFO     Train Epoch: 115 [1536/8000 (19%)]\tTotal Loss: 23.357830\n",
      "Reconstruction: 21.395718, Regularization: 1.962113\n",
      "2019-04-09 22:42:43,740 root         INFO     Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 33.156189\n",
      "Reconstruction: 31.714209, Regularization: 1.441982\n",
      "2019-04-09 22:42:43,795 root         INFO     Train Epoch: 115 [2560/8000 (32%)]\tTotal Loss: 6.482635\n",
      "Reconstruction: 5.417212, Regularization: 1.065422\n",
      "2019-04-09 22:42:43,852 root         INFO     Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 9.186181\n",
      "Reconstruction: 7.830663, Regularization: 1.355518\n",
      "2019-04-09 22:42:43,907 root         INFO     Train Epoch: 115 [3584/8000 (45%)]\tTotal Loss: 11.019621\n",
      "Reconstruction: 10.116179, Regularization: 0.903442\n",
      "2019-04-09 22:42:43,963 root         INFO     Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 122.417267\n",
      "Reconstruction: 120.778534, Regularization: 1.638733\n",
      "2019-04-09 22:42:44,018 root         INFO     Train Epoch: 115 [4608/8000 (58%)]\tTotal Loss: 15.364105\n",
      "Reconstruction: 14.174150, Regularization: 1.189955\n",
      "2019-04-09 22:42:44,074 root         INFO     Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 13.389485\n",
      "Reconstruction: 12.292564, Regularization: 1.096921\n",
      "2019-04-09 22:42:44,130 root         INFO     Train Epoch: 115 [5632/8000 (70%)]\tTotal Loss: 64.939735\n",
      "Reconstruction: 63.584934, Regularization: 1.354803\n",
      "2019-04-09 22:42:44,186 root         INFO     Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 7.023567\n",
      "Reconstruction: 5.844811, Regularization: 1.178756\n",
      "2019-04-09 22:42:44,242 root         INFO     Train Epoch: 115 [6656/8000 (83%)]\tTotal Loss: 17.988140\n",
      "Reconstruction: 15.965158, Regularization: 2.022982\n",
      "2019-04-09 22:42:44,298 root         INFO     Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 9.462242\n",
      "Reconstruction: 7.729339, Regularization: 1.732903\n",
      "2019-04-09 22:42:44,353 root         INFO     Train Epoch: 115 [7680/8000 (96%)]\tTotal Loss: 697.600403\n",
      "Reconstruction: 695.543518, Regularization: 2.056885\n",
      "2019-04-09 22:42:44,403 root         INFO     ====> Epoch: 115 Average loss: 308.5629\n",
      "2019-04-09 22:42:44,426 root         INFO     Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 244.682755\n",
      "Reconstruction: 243.307709, Regularization: 1.375048\n",
      "2019-04-09 22:42:44,483 root         INFO     Train Epoch: 116 [512/8000 (6%)]\tTotal Loss: 30.027563\n",
      "Reconstruction: 28.922686, Regularization: 1.104877\n",
      "2019-04-09 22:42:44,539 root         INFO     Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 70.048225\n",
      "Reconstruction: 67.963768, Regularization: 2.084459\n",
      "2019-04-09 22:42:44,595 root         INFO     Train Epoch: 116 [1536/8000 (19%)]\tTotal Loss: 35.200630\n",
      "Reconstruction: 34.136543, Regularization: 1.064087\n",
      "2019-04-09 22:42:44,651 root         INFO     Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 30.571941\n",
      "Reconstruction: 29.634060, Regularization: 0.937882\n",
      "2019-04-09 22:42:44,707 root         INFO     Train Epoch: 116 [2560/8000 (32%)]\tTotal Loss: 10.895531\n",
      "Reconstruction: 9.599146, Regularization: 1.296385\n",
      "2019-04-09 22:42:44,763 root         INFO     Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 74.473923\n",
      "Reconstruction: 73.182175, Regularization: 1.291747\n",
      "2019-04-09 22:42:44,817 root         INFO     Train Epoch: 116 [3584/8000 (45%)]\tTotal Loss: 103.294289\n",
      "Reconstruction: 101.481621, Regularization: 1.812664\n",
      "2019-04-09 22:42:44,871 root         INFO     Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 11.082320\n",
      "Reconstruction: 9.951304, Regularization: 1.131016\n",
      "2019-04-09 22:42:44,925 root         INFO     Train Epoch: 116 [4608/8000 (58%)]\tTotal Loss: 16.965538\n",
      "Reconstruction: 15.924026, Regularization: 1.041512\n",
      "2019-04-09 22:42:44,980 root         INFO     Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 10.742010\n",
      "Reconstruction: 9.337015, Regularization: 1.404995\n",
      "2019-04-09 22:42:45,035 root         INFO     Train Epoch: 116 [5632/8000 (70%)]\tTotal Loss: 50.277969\n",
      "Reconstruction: 48.748768, Regularization: 1.529202\n",
      "2019-04-09 22:42:45,090 root         INFO     Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 51.804848\n",
      "Reconstruction: 49.891075, Regularization: 1.913772\n",
      "2019-04-09 22:42:45,145 root         INFO     Train Epoch: 116 [6656/8000 (83%)]\tTotal Loss: 172.034973\n",
      "Reconstruction: 170.314560, Regularization: 1.720411\n",
      "2019-04-09 22:42:45,200 root         INFO     Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 3.126825\n",
      "Reconstruction: 1.008956, Regularization: 2.117869\n",
      "2019-04-09 22:42:45,255 root         INFO     Train Epoch: 116 [7680/8000 (96%)]\tTotal Loss: 38.796558\n",
      "Reconstruction: 37.283169, Regularization: 1.513391\n",
      "2019-04-09 22:42:45,304 root         INFO     ====> Epoch: 116 Average loss: 288.5729\n",
      "2019-04-09 22:42:45,327 root         INFO     Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 289.758118\n",
      "Reconstruction: 288.121887, Regularization: 1.636232\n",
      "2019-04-09 22:42:45,384 root         INFO     Train Epoch: 117 [512/8000 (6%)]\tTotal Loss: 36.974819\n",
      "Reconstruction: 35.049427, Regularization: 1.925394\n",
      "2019-04-09 22:42:45,441 root         INFO     Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 25.665751\n",
      "Reconstruction: 23.911106, Regularization: 1.754645\n",
      "2019-04-09 22:42:45,498 root         INFO     Train Epoch: 117 [1536/8000 (19%)]\tTotal Loss: 143.898834\n",
      "Reconstruction: 142.405045, Regularization: 1.493793\n",
      "2019-04-09 22:42:45,555 root         INFO     Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 96.383362\n",
      "Reconstruction: 94.578560, Regularization: 1.804802\n",
      "2019-04-09 22:42:45,611 root         INFO     Train Epoch: 117 [2560/8000 (32%)]\tTotal Loss: 2.317271\n",
      "Reconstruction: 0.978173, Regularization: 1.339098\n",
      "2019-04-09 22:42:45,667 root         INFO     Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 34.125736\n",
      "Reconstruction: 32.682083, Regularization: 1.443655\n",
      "2019-04-09 22:42:45,723 root         INFO     Train Epoch: 117 [3584/8000 (45%)]\tTotal Loss: 5.364888\n",
      "Reconstruction: 3.853710, Regularization: 1.511178\n",
      "2019-04-09 22:42:45,778 root         INFO     Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 16.878326\n",
      "Reconstruction: 15.153876, Regularization: 1.724449\n",
      "2019-04-09 22:42:45,833 root         INFO     Train Epoch: 117 [4608/8000 (58%)]\tTotal Loss: 12.414141\n",
      "Reconstruction: 11.266523, Regularization: 1.147617\n",
      "2019-04-09 22:42:45,887 root         INFO     Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 46.504616\n",
      "Reconstruction: 44.524826, Regularization: 1.979789\n",
      "2019-04-09 22:42:45,942 root         INFO     Train Epoch: 117 [5632/8000 (70%)]\tTotal Loss: 2.032021\n",
      "Reconstruction: 1.042159, Regularization: 0.989861\n",
      "2019-04-09 22:42:45,997 root         INFO     Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 45.749065\n",
      "Reconstruction: 44.412659, Regularization: 1.336407\n",
      "2019-04-09 22:42:46,054 root         INFO     Train Epoch: 117 [6656/8000 (83%)]\tTotal Loss: 8.896467\n",
      "Reconstruction: 7.809799, Regularization: 1.086668\n",
      "2019-04-09 22:42:46,112 root         INFO     Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 7.973793\n",
      "Reconstruction: 6.912085, Regularization: 1.061708\n",
      "2019-04-09 22:42:46,170 root         INFO     Train Epoch: 117 [7680/8000 (96%)]\tTotal Loss: 5.038206\n",
      "Reconstruction: 3.848635, Regularization: 1.189571\n",
      "2019-04-09 22:42:46,229 root         INFO     ====> Epoch: 117 Average loss: 384.4618\n",
      "2019-04-09 22:42:46,256 root         INFO     Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 2120.750000\n",
      "Reconstruction: 2118.853027, Regularization: 1.897083\n",
      "2019-04-09 22:42:46,312 root         INFO     Train Epoch: 118 [512/8000 (6%)]\tTotal Loss: 4.273048\n",
      "Reconstruction: 2.879697, Regularization: 1.393351\n",
      "2019-04-09 22:42:46,375 root         INFO     Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 19.926600\n",
      "Reconstruction: 17.561558, Regularization: 2.365041\n",
      "2019-04-09 22:42:46,431 root         INFO     Train Epoch: 118 [1536/8000 (19%)]\tTotal Loss: 5.321307\n",
      "Reconstruction: 3.642029, Regularization: 1.679278\n",
      "2019-04-09 22:42:46,486 root         INFO     Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 167.003189\n",
      "Reconstruction: 165.220673, Regularization: 1.782514\n",
      "2019-04-09 22:42:46,540 root         INFO     Train Epoch: 118 [2560/8000 (32%)]\tTotal Loss: 39.685856\n",
      "Reconstruction: 38.397411, Regularization: 1.288444\n",
      "2019-04-09 22:42:46,595 root         INFO     Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 2.484270\n",
      "Reconstruction: 1.068163, Regularization: 1.416107\n",
      "2019-04-09 22:42:46,650 root         INFO     Train Epoch: 118 [3584/8000 (45%)]\tTotal Loss: 31.080248\n",
      "Reconstruction: 28.717440, Regularization: 2.362808\n",
      "2019-04-09 22:42:46,704 root         INFO     Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 774.396240\n",
      "Reconstruction: 773.154541, Regularization: 1.241678\n",
      "2019-04-09 22:42:46,759 root         INFO     Train Epoch: 118 [4608/8000 (58%)]\tTotal Loss: 12.847905\n",
      "Reconstruction: 12.240756, Regularization: 0.607149\n",
      "2019-04-09 22:42:46,815 root         INFO     Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 31.208179\n",
      "Reconstruction: 29.813263, Regularization: 1.394917\n",
      "2019-04-09 22:42:46,870 root         INFO     Train Epoch: 118 [5632/8000 (70%)]\tTotal Loss: 94.740349\n",
      "Reconstruction: 92.534660, Regularization: 2.205688\n",
      "2019-04-09 22:42:46,924 root         INFO     Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 8.306513\n",
      "Reconstruction: 6.662521, Regularization: 1.643992\n",
      "2019-04-09 22:42:46,980 root         INFO     Train Epoch: 118 [6656/8000 (83%)]\tTotal Loss: 28.914442\n",
      "Reconstruction: 27.215286, Regularization: 1.699157\n",
      "2019-04-09 22:42:47,035 root         INFO     Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 44.544300\n",
      "Reconstruction: 42.564445, Regularization: 1.979856\n",
      "2019-04-09 22:42:47,090 root         INFO     Train Epoch: 118 [7680/8000 (96%)]\tTotal Loss: 63.913372\n",
      "Reconstruction: 62.261013, Regularization: 1.652360\n",
      "2019-04-09 22:42:47,139 root         INFO     ====> Epoch: 118 Average loss: 300.6815\n",
      "2019-04-09 22:42:47,163 root         INFO     Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 82.709450\n",
      "Reconstruction: 81.271111, Regularization: 1.438337\n",
      "2019-04-09 22:42:47,220 root         INFO     Train Epoch: 119 [512/8000 (6%)]\tTotal Loss: 1255.454590\n",
      "Reconstruction: 1253.252441, Regularization: 2.202164\n",
      "2019-04-09 22:42:47,276 root         INFO     Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 4.570850\n",
      "Reconstruction: 3.313870, Regularization: 1.256979\n",
      "2019-04-09 22:42:47,333 root         INFO     Train Epoch: 119 [1536/8000 (19%)]\tTotal Loss: 12.087667\n",
      "Reconstruction: 10.961669, Regularization: 1.125998\n",
      "2019-04-09 22:42:47,389 root         INFO     Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 96.747055\n",
      "Reconstruction: 95.350723, Regularization: 1.396335\n",
      "2019-04-09 22:42:47,446 root         INFO     Train Epoch: 119 [2560/8000 (32%)]\tTotal Loss: 22.756695\n",
      "Reconstruction: 21.377697, Regularization: 1.378998\n",
      "2019-04-09 22:42:47,503 root         INFO     Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 142.570724\n",
      "Reconstruction: 141.065750, Regularization: 1.504978\n",
      "2019-04-09 22:42:47,561 root         INFO     Train Epoch: 119 [3584/8000 (45%)]\tTotal Loss: 14.864713\n",
      "Reconstruction: 13.342023, Regularization: 1.522690\n",
      "2019-04-09 22:42:47,618 root         INFO     Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 10.823647\n",
      "Reconstruction: 9.789929, Regularization: 1.033718\n",
      "2019-04-09 22:42:47,676 root         INFO     Train Epoch: 119 [4608/8000 (58%)]\tTotal Loss: 4.684549\n",
      "Reconstruction: 3.427351, Regularization: 1.257197\n",
      "2019-04-09 22:42:47,733 root         INFO     Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 28.124367\n",
      "Reconstruction: 26.816044, Regularization: 1.308322\n",
      "2019-04-09 22:42:47,789 root         INFO     Train Epoch: 119 [5632/8000 (70%)]\tTotal Loss: 2671.086914\n",
      "Reconstruction: 2669.755615, Regularization: 1.331179\n",
      "2019-04-09 22:42:47,846 root         INFO     Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 15.213126\n",
      "Reconstruction: 13.960907, Regularization: 1.252220\n",
      "2019-04-09 22:42:47,903 root         INFO     Train Epoch: 119 [6656/8000 (83%)]\tTotal Loss: 868.942566\n",
      "Reconstruction: 867.446716, Regularization: 1.495827\n",
      "2019-04-09 22:42:47,960 root         INFO     Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 338.658020\n",
      "Reconstruction: 336.433899, Regularization: 2.224122\n",
      "2019-04-09 22:42:48,017 root         INFO     Train Epoch: 119 [7680/8000 (96%)]\tTotal Loss: 24.401251\n",
      "Reconstruction: 22.665176, Regularization: 1.736075\n",
      "2019-04-09 22:42:48,067 root         INFO     ====> Epoch: 119 Average loss: 387.1291\n",
      "2019-04-09 22:42:48,090 root         INFO     Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 56.467831\n",
      "Reconstruction: 55.268089, Regularization: 1.199741\n",
      "2019-04-09 22:42:48,147 root         INFO     Train Epoch: 120 [512/8000 (6%)]\tTotal Loss: 1.594894\n",
      "Reconstruction: 0.614793, Regularization: 0.980101\n",
      "2019-04-09 22:42:48,203 root         INFO     Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 27.487267\n",
      "Reconstruction: 25.884247, Regularization: 1.603020\n",
      "2019-04-09 22:42:48,259 root         INFO     Train Epoch: 120 [1536/8000 (19%)]\tTotal Loss: 3540.979248\n",
      "Reconstruction: 3539.275635, Regularization: 1.703691\n",
      "2019-04-09 22:42:48,316 root         INFO     Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 14.517935\n",
      "Reconstruction: 13.524223, Regularization: 0.993711\n",
      "2019-04-09 22:42:48,372 root         INFO     Train Epoch: 120 [2560/8000 (32%)]\tTotal Loss: 426.209351\n",
      "Reconstruction: 424.257568, Regularization: 1.951777\n",
      "2019-04-09 22:42:48,428 root         INFO     Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 6.564760\n",
      "Reconstruction: 5.050072, Regularization: 1.514688\n",
      "2019-04-09 22:42:48,484 root         INFO     Train Epoch: 120 [3584/8000 (45%)]\tTotal Loss: 20.330902\n",
      "Reconstruction: 18.527004, Regularization: 1.803897\n",
      "2019-04-09 22:42:48,539 root         INFO     Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 90.337135\n",
      "Reconstruction: 88.621071, Regularization: 1.716063\n",
      "2019-04-09 22:42:48,595 root         INFO     Train Epoch: 120 [4608/8000 (58%)]\tTotal Loss: 78.925278\n",
      "Reconstruction: 77.495445, Regularization: 1.429835\n",
      "2019-04-09 22:42:48,652 root         INFO     Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 9.779016\n",
      "Reconstruction: 8.424740, Regularization: 1.354276\n",
      "2019-04-09 22:42:48,708 root         INFO     Train Epoch: 120 [5632/8000 (70%)]\tTotal Loss: 80.764793\n",
      "Reconstruction: 79.136864, Regularization: 1.627932\n",
      "2019-04-09 22:42:48,763 root         INFO     Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 38.243736\n",
      "Reconstruction: 36.552917, Regularization: 1.690817\n",
      "2019-04-09 22:42:48,818 root         INFO     Train Epoch: 120 [6656/8000 (83%)]\tTotal Loss: 73.392006\n",
      "Reconstruction: 71.570358, Regularization: 1.821650\n",
      "2019-04-09 22:42:48,872 root         INFO     Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 20.438246\n",
      "Reconstruction: 19.065481, Regularization: 1.372765\n",
      "2019-04-09 22:42:48,927 root         INFO     Train Epoch: 120 [7680/8000 (96%)]\tTotal Loss: 20.413771\n",
      "Reconstruction: 19.280493, Regularization: 1.133278\n",
      "2019-04-09 22:42:48,977 root         INFO     ====> Epoch: 120 Average loss: 290.8558\n",
      "2019-04-09 22:42:49,000 root         INFO     Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 13.540152\n",
      "Reconstruction: 11.846976, Regularization: 1.693175\n",
      "2019-04-09 22:42:49,057 root         INFO     Train Epoch: 121 [512/8000 (6%)]\tTotal Loss: 215.705078\n",
      "Reconstruction: 214.191132, Regularization: 1.513952\n",
      "2019-04-09 22:42:49,113 root         INFO     Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 17.783287\n",
      "Reconstruction: 16.316868, Regularization: 1.466419\n",
      "2019-04-09 22:42:49,169 root         INFO     Train Epoch: 121 [1536/8000 (19%)]\tTotal Loss: 8.628784\n",
      "Reconstruction: 7.018823, Regularization: 1.609961\n",
      "2019-04-09 22:42:49,226 root         INFO     Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 10.015530\n",
      "Reconstruction: 8.623851, Regularization: 1.391679\n",
      "2019-04-09 22:42:49,282 root         INFO     Train Epoch: 121 [2560/8000 (32%)]\tTotal Loss: 820.525024\n",
      "Reconstruction: 818.743042, Regularization: 1.782000\n",
      "2019-04-09 22:42:49,338 root         INFO     Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 574.750488\n",
      "Reconstruction: 571.925354, Regularization: 2.825134\n",
      "2019-04-09 22:42:49,394 root         INFO     Train Epoch: 121 [3584/8000 (45%)]\tTotal Loss: 113.815033\n",
      "Reconstruction: 112.695267, Regularization: 1.119765\n",
      "2019-04-09 22:42:49,449 root         INFO     Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 64.684219\n",
      "Reconstruction: 63.023758, Regularization: 1.660462\n",
      "2019-04-09 22:42:49,505 root         INFO     Train Epoch: 121 [4608/8000 (58%)]\tTotal Loss: 73.262016\n",
      "Reconstruction: 71.775620, Regularization: 1.486397\n",
      "2019-04-09 22:42:49,560 root         INFO     Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 181.869446\n",
      "Reconstruction: 179.865601, Regularization: 2.003845\n",
      "2019-04-09 22:42:49,615 root         INFO     Train Epoch: 121 [5632/8000 (70%)]\tTotal Loss: 20.807598\n",
      "Reconstruction: 19.803122, Regularization: 1.004477\n",
      "2019-04-09 22:42:49,671 root         INFO     Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 4045.057373\n",
      "Reconstruction: 4043.278564, Regularization: 1.778915\n",
      "2019-04-09 22:42:49,726 root         INFO     Train Epoch: 121 [6656/8000 (83%)]\tTotal Loss: 5.042414\n",
      "Reconstruction: 2.692304, Regularization: 2.350110\n",
      "2019-04-09 22:42:49,782 root         INFO     Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 90.641647\n",
      "Reconstruction: 89.228127, Regularization: 1.413517\n",
      "2019-04-09 22:42:49,837 root         INFO     Train Epoch: 121 [7680/8000 (96%)]\tTotal Loss: 54.141926\n",
      "Reconstruction: 52.600964, Regularization: 1.540961\n",
      "2019-04-09 22:42:49,886 root         INFO     ====> Epoch: 121 Average loss: 213.8277\n",
      "2019-04-09 22:42:49,909 root         INFO     Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 60.275078\n",
      "Reconstruction: 58.384182, Regularization: 1.890895\n",
      "2019-04-09 22:42:49,966 root         INFO     Train Epoch: 122 [512/8000 (6%)]\tTotal Loss: 10.932686\n",
      "Reconstruction: 8.917892, Regularization: 2.014794\n",
      "2019-04-09 22:42:50,023 root         INFO     Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 24.195488\n",
      "Reconstruction: 22.125130, Regularization: 2.070358\n",
      "2019-04-09 22:42:50,079 root         INFO     Train Epoch: 122 [1536/8000 (19%)]\tTotal Loss: 10.634905\n",
      "Reconstruction: 9.452219, Regularization: 1.182686\n",
      "2019-04-09 22:42:50,135 root         INFO     Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 5.909230\n",
      "Reconstruction: 4.635842, Regularization: 1.273388\n",
      "2019-04-09 22:42:50,192 root         INFO     Train Epoch: 122 [2560/8000 (32%)]\tTotal Loss: 1132.662109\n",
      "Reconstruction: 1130.970581, Regularization: 1.691575\n",
      "2019-04-09 22:42:50,248 root         INFO     Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 2.194236\n",
      "Reconstruction: 0.706343, Regularization: 1.487893\n",
      "2019-04-09 22:42:50,305 root         INFO     Train Epoch: 122 [3584/8000 (45%)]\tTotal Loss: 54.413837\n",
      "Reconstruction: 52.850159, Regularization: 1.563678\n",
      "2019-04-09 22:42:50,361 root         INFO     Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 2221.956055\n",
      "Reconstruction: 2219.557617, Regularization: 2.398559\n",
      "2019-04-09 22:42:50,417 root         INFO     Train Epoch: 122 [4608/8000 (58%)]\tTotal Loss: 15.821742\n",
      "Reconstruction: 14.518167, Regularization: 1.303575\n",
      "2019-04-09 22:42:50,472 root         INFO     Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 4.262216\n",
      "Reconstruction: 3.013329, Regularization: 1.248886\n",
      "2019-04-09 22:42:50,528 root         INFO     Train Epoch: 122 [5632/8000 (70%)]\tTotal Loss: 113.279648\n",
      "Reconstruction: 112.070107, Regularization: 1.209539\n",
      "2019-04-09 22:42:50,584 root         INFO     Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 76.819511\n",
      "Reconstruction: 74.782791, Regularization: 2.036717\n",
      "2019-04-09 22:42:50,638 root         INFO     Train Epoch: 122 [6656/8000 (83%)]\tTotal Loss: 14.395252\n",
      "Reconstruction: 12.791992, Regularization: 1.603261\n",
      "2019-04-09 22:42:50,693 root         INFO     Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 4993.520996\n",
      "Reconstruction: 4990.735352, Regularization: 2.785639\n",
      "2019-04-09 22:42:50,747 root         INFO     Train Epoch: 122 [7680/8000 (96%)]\tTotal Loss: 26.171967\n",
      "Reconstruction: 24.723045, Regularization: 1.448921\n",
      "2019-04-09 22:42:50,797 root         INFO     ====> Epoch: 122 Average loss: 150.4600\n",
      "2019-04-09 22:42:50,820 root         INFO     Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 22.200500\n",
      "Reconstruction: 20.261410, Regularization: 1.939091\n",
      "2019-04-09 22:42:50,876 root         INFO     Train Epoch: 123 [512/8000 (6%)]\tTotal Loss: 339.411377\n",
      "Reconstruction: 337.389496, Regularization: 2.021888\n",
      "2019-04-09 22:42:50,932 root         INFO     Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 6.192781\n",
      "Reconstruction: 4.529842, Regularization: 1.662939\n",
      "2019-04-09 22:42:50,988 root         INFO     Train Epoch: 123 [1536/8000 (19%)]\tTotal Loss: 6.939394\n",
      "Reconstruction: 5.169436, Regularization: 1.769958\n",
      "2019-04-09 22:42:51,045 root         INFO     Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 3.397973\n",
      "Reconstruction: 2.225397, Regularization: 1.172576\n",
      "2019-04-09 22:42:51,101 root         INFO     Train Epoch: 123 [2560/8000 (32%)]\tTotal Loss: 54.113411\n",
      "Reconstruction: 52.548302, Regularization: 1.565108\n",
      "2019-04-09 22:42:51,156 root         INFO     Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 4.099655\n",
      "Reconstruction: 1.794513, Regularization: 2.305141\n",
      "2019-04-09 22:42:51,213 root         INFO     Train Epoch: 123 [3584/8000 (45%)]\tTotal Loss: 3.869373\n",
      "Reconstruction: 2.687558, Regularization: 1.181815\n",
      "2019-04-09 22:42:51,268 root         INFO     Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 89.242516\n",
      "Reconstruction: 87.849274, Regularization: 1.393240\n",
      "2019-04-09 22:42:51,324 root         INFO     Train Epoch: 123 [4608/8000 (58%)]\tTotal Loss: 1152.959717\n",
      "Reconstruction: 1151.156494, Regularization: 1.803262\n",
      "2019-04-09 22:42:51,379 root         INFO     Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 26.966652\n",
      "Reconstruction: 25.547453, Regularization: 1.419198\n",
      "2019-04-09 22:42:51,434 root         INFO     Train Epoch: 123 [5632/8000 (70%)]\tTotal Loss: 19.086901\n",
      "Reconstruction: 18.059240, Regularization: 1.027661\n",
      "2019-04-09 22:42:51,488 root         INFO     Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 5.096810\n",
      "Reconstruction: 4.120123, Regularization: 0.976687\n",
      "2019-04-09 22:42:51,543 root         INFO     Train Epoch: 123 [6656/8000 (83%)]\tTotal Loss: 10.371859\n",
      "Reconstruction: 8.882937, Regularization: 1.488921\n",
      "2019-04-09 22:42:51,597 root         INFO     Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 4.697381\n",
      "Reconstruction: 3.265269, Regularization: 1.432112\n",
      "2019-04-09 22:42:51,652 root         INFO     Train Epoch: 123 [7680/8000 (96%)]\tTotal Loss: 13.442454\n",
      "Reconstruction: 12.520379, Regularization: 0.922076\n",
      "2019-04-09 22:42:51,701 root         INFO     ====> Epoch: 123 Average loss: 216.2054\n",
      "2019-04-09 22:42:51,724 root         INFO     Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 115.094994\n",
      "Reconstruction: 114.052216, Regularization: 1.042776\n",
      "2019-04-09 22:42:51,781 root         INFO     Train Epoch: 124 [512/8000 (6%)]\tTotal Loss: 2.620109\n",
      "Reconstruction: 1.274647, Regularization: 1.345463\n",
      "2019-04-09 22:42:51,837 root         INFO     Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 10.733797\n",
      "Reconstruction: 9.370031, Regularization: 1.363766\n",
      "2019-04-09 22:42:51,894 root         INFO     Train Epoch: 124 [1536/8000 (19%)]\tTotal Loss: 32.907803\n",
      "Reconstruction: 31.736458, Regularization: 1.171345\n",
      "2019-04-09 22:42:51,950 root         INFO     Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 34.457409\n",
      "Reconstruction: 32.607143, Regularization: 1.850266\n",
      "2019-04-09 22:42:52,006 root         INFO     Train Epoch: 124 [2560/8000 (32%)]\tTotal Loss: 31.170856\n",
      "Reconstruction: 29.680340, Regularization: 1.490516\n",
      "2019-04-09 22:42:52,059 root         INFO     Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 97.461945\n",
      "Reconstruction: 95.766739, Regularization: 1.695204\n",
      "2019-04-09 22:42:52,112 root         INFO     Train Epoch: 124 [3584/8000 (45%)]\tTotal Loss: 5.025641\n",
      "Reconstruction: 3.666253, Regularization: 1.359389\n",
      "2019-04-09 22:42:52,165 root         INFO     Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 11.327742\n",
      "Reconstruction: 10.180187, Regularization: 1.147555\n",
      "2019-04-09 22:42:52,218 root         INFO     Train Epoch: 124 [4608/8000 (58%)]\tTotal Loss: 926.532166\n",
      "Reconstruction: 923.880615, Regularization: 2.651566\n",
      "2019-04-09 22:42:52,271 root         INFO     Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 147.963242\n",
      "Reconstruction: 145.244019, Regularization: 2.719223\n",
      "2019-04-09 22:42:52,324 root         INFO     Train Epoch: 124 [5632/8000 (70%)]\tTotal Loss: 4.419395\n",
      "Reconstruction: 2.547164, Regularization: 1.872231\n",
      "2019-04-09 22:42:52,377 root         INFO     Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 14.435177\n",
      "Reconstruction: 13.624041, Regularization: 0.811137\n",
      "2019-04-09 22:42:52,431 root         INFO     Train Epoch: 124 [6656/8000 (83%)]\tTotal Loss: 15.989958\n",
      "Reconstruction: 14.592279, Regularization: 1.397679\n",
      "2019-04-09 22:42:52,486 root         INFO     Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 4.909395\n",
      "Reconstruction: 3.403134, Regularization: 1.506261\n",
      "2019-04-09 22:42:52,541 root         INFO     Train Epoch: 124 [7680/8000 (96%)]\tTotal Loss: 12.551964\n",
      "Reconstruction: 10.894585, Regularization: 1.657379\n",
      "2019-04-09 22:42:52,591 root         INFO     ====> Epoch: 124 Average loss: 166.3744\n",
      "2019-04-09 22:42:52,614 root         INFO     Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 3.412530\n",
      "Reconstruction: 1.814200, Regularization: 1.598330\n",
      "2019-04-09 22:42:52,670 root         INFO     Train Epoch: 125 [512/8000 (6%)]\tTotal Loss: 30.891670\n",
      "Reconstruction: 29.370810, Regularization: 1.520860\n",
      "2019-04-09 22:42:52,726 root         INFO     Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 2.888684\n",
      "Reconstruction: 1.683185, Regularization: 1.205500\n",
      "2019-04-09 22:42:52,781 root         INFO     Train Epoch: 125 [1536/8000 (19%)]\tTotal Loss: 240.514069\n",
      "Reconstruction: 238.513535, Regularization: 2.000536\n",
      "2019-04-09 22:42:52,837 root         INFO     Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 250.656219\n",
      "Reconstruction: 249.205765, Regularization: 1.450451\n",
      "2019-04-09 22:42:52,892 root         INFO     Train Epoch: 125 [2560/8000 (32%)]\tTotal Loss: 25.812222\n",
      "Reconstruction: 24.510307, Regularization: 1.301913\n",
      "2019-04-09 22:42:52,948 root         INFO     Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 10.385832\n",
      "Reconstruction: 8.476180, Regularization: 1.909652\n",
      "2019-04-09 22:42:53,003 root         INFO     Train Epoch: 125 [3584/8000 (45%)]\tTotal Loss: 5.863885\n",
      "Reconstruction: 4.387596, Regularization: 1.476289\n",
      "2019-04-09 22:42:53,059 root         INFO     Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 6.613577\n",
      "Reconstruction: 5.666486, Regularization: 0.947091\n",
      "2019-04-09 22:42:53,114 root         INFO     Train Epoch: 125 [4608/8000 (58%)]\tTotal Loss: 2.002098\n",
      "Reconstruction: 1.051684, Regularization: 0.950413\n",
      "2019-04-09 22:42:53,169 root         INFO     Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 3.660970\n",
      "Reconstruction: 2.637329, Regularization: 1.023641\n",
      "2019-04-09 22:42:53,225 root         INFO     Train Epoch: 125 [5632/8000 (70%)]\tTotal Loss: 6.344447\n",
      "Reconstruction: 4.893007, Regularization: 1.451440\n",
      "2019-04-09 22:42:53,281 root         INFO     Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 14.270616\n",
      "Reconstruction: 12.919527, Regularization: 1.351088\n",
      "2019-04-09 22:42:53,336 root         INFO     Train Epoch: 125 [6656/8000 (83%)]\tTotal Loss: 20.323122\n",
      "Reconstruction: 19.100912, Regularization: 1.222210\n",
      "2019-04-09 22:42:53,392 root         INFO     Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 81.021362\n",
      "Reconstruction: 80.204636, Regularization: 0.816727\n",
      "2019-04-09 22:42:53,448 root         INFO     Train Epoch: 125 [7680/8000 (96%)]\tTotal Loss: 255.025131\n",
      "Reconstruction: 253.317520, Regularization: 1.707611\n",
      "2019-04-09 22:42:53,497 root         INFO     ====> Epoch: 125 Average loss: 193.3870\n",
      "2019-04-09 22:42:53,520 root         INFO     Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 4.810099\n",
      "Reconstruction: 3.450501, Regularization: 1.359597\n",
      "2019-04-09 22:42:53,577 root         INFO     Train Epoch: 126 [512/8000 (6%)]\tTotal Loss: 32.283192\n",
      "Reconstruction: 30.270300, Regularization: 2.012892\n",
      "2019-04-09 22:42:53,633 root         INFO     Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 56.070889\n",
      "Reconstruction: 54.583782, Regularization: 1.487107\n",
      "2019-04-09 22:42:53,689 root         INFO     Train Epoch: 126 [1536/8000 (19%)]\tTotal Loss: 12.432802\n",
      "Reconstruction: 11.070633, Regularization: 1.362169\n",
      "2019-04-09 22:42:53,746 root         INFO     Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 31.967604\n",
      "Reconstruction: 30.306528, Regularization: 1.661076\n",
      "2019-04-09 22:42:53,804 root         INFO     Train Epoch: 126 [2560/8000 (32%)]\tTotal Loss: 2.995049\n",
      "Reconstruction: 1.651200, Regularization: 1.343848\n",
      "2019-04-09 22:42:53,861 root         INFO     Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 30.500965\n",
      "Reconstruction: 28.286343, Regularization: 2.214622\n",
      "2019-04-09 22:42:53,917 root         INFO     Train Epoch: 126 [3584/8000 (45%)]\tTotal Loss: 24.124327\n",
      "Reconstruction: 22.859627, Regularization: 1.264699\n",
      "2019-04-09 22:42:53,974 root         INFO     Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 48.870346\n",
      "Reconstruction: 47.097271, Regularization: 1.773074\n",
      "2019-04-09 22:42:54,030 root         INFO     Train Epoch: 126 [4608/8000 (58%)]\tTotal Loss: 400.016144\n",
      "Reconstruction: 398.650513, Regularization: 1.365638\n",
      "2019-04-09 22:42:54,086 root         INFO     Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 20.209803\n",
      "Reconstruction: 18.914324, Regularization: 1.295479\n",
      "2019-04-09 22:42:54,143 root         INFO     Train Epoch: 126 [5632/8000 (70%)]\tTotal Loss: 21.180555\n",
      "Reconstruction: 19.838018, Regularization: 1.342536\n",
      "2019-04-09 22:42:54,199 root         INFO     Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 6.391189\n",
      "Reconstruction: 4.962222, Regularization: 1.428966\n",
      "2019-04-09 22:42:54,255 root         INFO     Train Epoch: 126 [6656/8000 (83%)]\tTotal Loss: 5.343744\n",
      "Reconstruction: 3.774970, Regularization: 1.568775\n",
      "2019-04-09 22:42:54,312 root         INFO     Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 6.811285\n",
      "Reconstruction: 5.150743, Regularization: 1.660542\n",
      "2019-04-09 22:42:54,368 root         INFO     Train Epoch: 126 [7680/8000 (96%)]\tTotal Loss: 25.009834\n",
      "Reconstruction: 23.557491, Regularization: 1.452343\n",
      "2019-04-09 22:42:54,418 root         INFO     ====> Epoch: 126 Average loss: 160.7730\n",
      "2019-04-09 22:42:54,442 root         INFO     Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 213.415283\n",
      "Reconstruction: 211.676147, Regularization: 1.739141\n",
      "2019-04-09 22:42:54,498 root         INFO     Train Epoch: 127 [512/8000 (6%)]\tTotal Loss: 4.982029\n",
      "Reconstruction: 3.123179, Regularization: 1.858850\n",
      "2019-04-09 22:42:54,554 root         INFO     Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 16.375984\n",
      "Reconstruction: 15.301231, Regularization: 1.074752\n",
      "2019-04-09 22:42:54,609 root         INFO     Train Epoch: 127 [1536/8000 (19%)]\tTotal Loss: 10.242548\n",
      "Reconstruction: 8.451883, Regularization: 1.790664\n",
      "2019-04-09 22:42:54,664 root         INFO     Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 73.139656\n",
      "Reconstruction: 71.066025, Regularization: 2.073632\n",
      "2019-04-09 22:42:54,720 root         INFO     Train Epoch: 127 [2560/8000 (32%)]\tTotal Loss: 33.675732\n",
      "Reconstruction: 32.192909, Regularization: 1.482823\n",
      "2019-04-09 22:42:54,775 root         INFO     Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 21.744535\n",
      "Reconstruction: 20.061852, Regularization: 1.682684\n",
      "2019-04-09 22:42:54,830 root         INFO     Train Epoch: 127 [3584/8000 (45%)]\tTotal Loss: 7.627088\n",
      "Reconstruction: 6.116630, Regularization: 1.510458\n",
      "2019-04-09 22:42:54,885 root         INFO     Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 7.579884\n",
      "Reconstruction: 6.427319, Regularization: 1.152565\n",
      "2019-04-09 22:42:54,939 root         INFO     Train Epoch: 127 [4608/8000 (58%)]\tTotal Loss: 3.546139\n",
      "Reconstruction: 2.325609, Regularization: 1.220530\n",
      "2019-04-09 22:42:54,994 root         INFO     Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 55.928604\n",
      "Reconstruction: 54.452946, Regularization: 1.475660\n",
      "2019-04-09 22:42:55,049 root         INFO     Train Epoch: 127 [5632/8000 (70%)]\tTotal Loss: 3.433880\n",
      "Reconstruction: 2.004756, Regularization: 1.429124\n",
      "2019-04-09 22:42:55,103 root         INFO     Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 26.483433\n",
      "Reconstruction: 24.388876, Regularization: 2.094557\n",
      "2019-04-09 22:42:55,157 root         INFO     Train Epoch: 127 [6656/8000 (83%)]\tTotal Loss: 60.200222\n",
      "Reconstruction: 59.081005, Regularization: 1.119218\n",
      "2019-04-09 22:42:55,211 root         INFO     Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 4.268415\n",
      "Reconstruction: 3.415080, Regularization: 0.853336\n",
      "2019-04-09 22:42:55,265 root         INFO     Train Epoch: 127 [7680/8000 (96%)]\tTotal Loss: 971.851990\n",
      "Reconstruction: 969.657410, Regularization: 2.194579\n",
      "2019-04-09 22:42:55,313 root         INFO     ====> Epoch: 127 Average loss: 117.3068\n",
      "2019-04-09 22:42:55,337 root         INFO     Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 6.174470\n",
      "Reconstruction: 4.946871, Regularization: 1.227599\n",
      "2019-04-09 22:42:55,393 root         INFO     Train Epoch: 128 [512/8000 (6%)]\tTotal Loss: 100.602722\n",
      "Reconstruction: 99.455719, Regularization: 1.147004\n",
      "2019-04-09 22:42:55,449 root         INFO     Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 4.049696\n",
      "Reconstruction: 2.255886, Regularization: 1.793810\n",
      "2019-04-09 22:42:55,503 root         INFO     Train Epoch: 128 [1536/8000 (19%)]\tTotal Loss: 29.032581\n",
      "Reconstruction: 27.657555, Regularization: 1.375026\n",
      "2019-04-09 22:42:55,557 root         INFO     Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 9.422164\n",
      "Reconstruction: 8.228172, Regularization: 1.193991\n",
      "2019-04-09 22:42:55,611 root         INFO     Train Epoch: 128 [2560/8000 (32%)]\tTotal Loss: 61.361641\n",
      "Reconstruction: 59.383682, Regularization: 1.977959\n",
      "2019-04-09 22:42:55,665 root         INFO     Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 2.343276\n",
      "Reconstruction: 1.141279, Regularization: 1.201997\n",
      "2019-04-09 22:42:55,719 root         INFO     Train Epoch: 128 [3584/8000 (45%)]\tTotal Loss: 6.048347\n",
      "Reconstruction: 5.341239, Regularization: 0.707108\n",
      "2019-04-09 22:42:55,773 root         INFO     Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 39.398708\n",
      "Reconstruction: 37.931629, Regularization: 1.467078\n",
      "2019-04-09 22:42:55,827 root         INFO     Train Epoch: 128 [4608/8000 (58%)]\tTotal Loss: 41.950352\n",
      "Reconstruction: 40.664810, Regularization: 1.285543\n",
      "2019-04-09 22:42:55,881 root         INFO     Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 50.784969\n",
      "Reconstruction: 49.038132, Regularization: 1.746836\n",
      "2019-04-09 22:42:55,935 root         INFO     Train Epoch: 128 [5632/8000 (70%)]\tTotal Loss: 26.529926\n",
      "Reconstruction: 24.744246, Regularization: 1.785680\n",
      "2019-04-09 22:42:55,989 root         INFO     Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 511.968323\n",
      "Reconstruction: 510.082428, Regularization: 1.885888\n",
      "2019-04-09 22:42:56,042 root         INFO     Train Epoch: 128 [6656/8000 (83%)]\tTotal Loss: 5.127442\n",
      "Reconstruction: 3.354021, Regularization: 1.773422\n",
      "2019-04-09 22:42:56,094 root         INFO     Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 4.630598\n",
      "Reconstruction: 3.169513, Regularization: 1.461084\n",
      "2019-04-09 22:42:56,147 root         INFO     Train Epoch: 128 [7680/8000 (96%)]\tTotal Loss: 273.644531\n",
      "Reconstruction: 272.036560, Regularization: 1.607962\n",
      "2019-04-09 22:42:56,195 root         INFO     ====> Epoch: 128 Average loss: 177.9868\n",
      "2019-04-09 22:42:56,218 root         INFO     Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 74.954178\n",
      "Reconstruction: 73.249504, Regularization: 1.704670\n",
      "2019-04-09 22:42:56,274 root         INFO     Train Epoch: 129 [512/8000 (6%)]\tTotal Loss: 75.893173\n",
      "Reconstruction: 73.310287, Regularization: 2.582887\n",
      "2019-04-09 22:42:56,329 root         INFO     Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 28.194044\n",
      "Reconstruction: 26.236530, Regularization: 1.957513\n",
      "2019-04-09 22:42:56,384 root         INFO     Train Epoch: 129 [1536/8000 (19%)]\tTotal Loss: 38.473579\n",
      "Reconstruction: 36.942196, Regularization: 1.531382\n",
      "2019-04-09 22:42:56,439 root         INFO     Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 16.777380\n",
      "Reconstruction: 15.285819, Regularization: 1.491561\n",
      "2019-04-09 22:42:56,494 root         INFO     Train Epoch: 129 [2560/8000 (32%)]\tTotal Loss: 2.604699\n",
      "Reconstruction: 1.199713, Regularization: 1.404986\n",
      "2019-04-09 22:42:56,548 root         INFO     Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 20.082832\n",
      "Reconstruction: 18.722889, Regularization: 1.359944\n",
      "2019-04-09 22:42:56,603 root         INFO     Train Epoch: 129 [3584/8000 (45%)]\tTotal Loss: 497.893646\n",
      "Reconstruction: 495.797058, Regularization: 2.096601\n",
      "2019-04-09 22:42:56,657 root         INFO     Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 6.180661\n",
      "Reconstruction: 5.193303, Regularization: 0.987358\n",
      "2019-04-09 22:42:56,711 root         INFO     Train Epoch: 129 [4608/8000 (58%)]\tTotal Loss: 36.300869\n",
      "Reconstruction: 33.981369, Regularization: 2.319499\n",
      "2019-04-09 22:42:56,765 root         INFO     Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 25.509562\n",
      "Reconstruction: 24.307737, Regularization: 1.201823\n",
      "2019-04-09 22:42:56,820 root         INFO     Train Epoch: 129 [5632/8000 (70%)]\tTotal Loss: 3.553777\n",
      "Reconstruction: 2.578844, Regularization: 0.974934\n",
      "2019-04-09 22:42:56,874 root         INFO     Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 4.980146\n",
      "Reconstruction: 3.815759, Regularization: 1.164387\n",
      "2019-04-09 22:42:56,929 root         INFO     Train Epoch: 129 [6656/8000 (83%)]\tTotal Loss: 5.969023\n",
      "Reconstruction: 4.548682, Regularization: 1.420341\n",
      "2019-04-09 22:42:56,984 root         INFO     Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 3.738600\n",
      "Reconstruction: 1.599827, Regularization: 2.138773\n",
      "2019-04-09 22:42:57,038 root         INFO     Train Epoch: 129 [7680/8000 (96%)]\tTotal Loss: 12.545678\n",
      "Reconstruction: 11.164409, Regularization: 1.381269\n",
      "2019-04-09 22:42:57,087 root         INFO     ====> Epoch: 129 Average loss: 119.3574\n",
      "2019-04-09 22:42:57,110 root         INFO     Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 7.849205\n",
      "Reconstruction: 6.799767, Regularization: 1.049439\n",
      "2019-04-09 22:42:57,166 root         INFO     Train Epoch: 130 [512/8000 (6%)]\tTotal Loss: 4.253156\n",
      "Reconstruction: 3.067460, Regularization: 1.185696\n",
      "2019-04-09 22:42:57,222 root         INFO     Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 170.889389\n",
      "Reconstruction: 168.684967, Regularization: 2.204419\n",
      "2019-04-09 22:42:57,278 root         INFO     Train Epoch: 130 [1536/8000 (19%)]\tTotal Loss: 7.039318\n",
      "Reconstruction: 5.840465, Regularization: 1.198853\n",
      "2019-04-09 22:42:57,333 root         INFO     Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 77.726395\n",
      "Reconstruction: 75.973373, Regularization: 1.753024\n",
      "2019-04-09 22:42:57,389 root         INFO     Train Epoch: 130 [2560/8000 (32%)]\tTotal Loss: 5.699721\n",
      "Reconstruction: 4.352430, Regularization: 1.347291\n",
      "2019-04-09 22:42:57,443 root         INFO     Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 70.306313\n",
      "Reconstruction: 68.673195, Regularization: 1.633118\n",
      "2019-04-09 22:42:57,498 root         INFO     Train Epoch: 130 [3584/8000 (45%)]\tTotal Loss: 23.020319\n",
      "Reconstruction: 21.675779, Regularization: 1.344540\n",
      "2019-04-09 22:42:57,551 root         INFO     Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 7.908467\n",
      "Reconstruction: 6.211663, Regularization: 1.696804\n",
      "2019-04-09 22:42:57,605 root         INFO     Train Epoch: 130 [4608/8000 (58%)]\tTotal Loss: 116.445442\n",
      "Reconstruction: 114.922836, Regularization: 1.522605\n",
      "2019-04-09 22:42:57,659 root         INFO     Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 6.149709\n",
      "Reconstruction: 4.828189, Regularization: 1.321520\n",
      "2019-04-09 22:42:57,712 root         INFO     Train Epoch: 130 [5632/8000 (70%)]\tTotal Loss: 124.118362\n",
      "Reconstruction: 122.963722, Regularization: 1.154643\n",
      "2019-04-09 22:42:57,766 root         INFO     Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 3.744606\n",
      "Reconstruction: 2.502497, Regularization: 1.242108\n",
      "2019-04-09 22:42:57,820 root         INFO     Train Epoch: 130 [6656/8000 (83%)]\tTotal Loss: 12.921917\n",
      "Reconstruction: 11.641381, Regularization: 1.280536\n",
      "2019-04-09 22:42:57,873 root         INFO     Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 8.483915\n",
      "Reconstruction: 6.962171, Regularization: 1.521744\n",
      "2019-04-09 22:42:57,926 root         INFO     Train Epoch: 130 [7680/8000 (96%)]\tTotal Loss: 102.285950\n",
      "Reconstruction: 100.281929, Regularization: 2.004021\n",
      "2019-04-09 22:42:57,975 root         INFO     ====> Epoch: 130 Average loss: 81.8454\n",
      "2019-04-09 22:42:57,998 root         INFO     Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 81.161255\n",
      "Reconstruction: 79.537437, Regularization: 1.623814\n",
      "2019-04-09 22:42:58,054 root         INFO     Train Epoch: 131 [512/8000 (6%)]\tTotal Loss: 307.689240\n",
      "Reconstruction: 305.605927, Regularization: 2.083315\n",
      "2019-04-09 22:42:58,109 root         INFO     Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 36.431149\n",
      "Reconstruction: 34.799942, Regularization: 1.631207\n",
      "2019-04-09 22:42:58,165 root         INFO     Train Epoch: 131 [1536/8000 (19%)]\tTotal Loss: 15.994448\n",
      "Reconstruction: 14.472736, Regularization: 1.521712\n",
      "2019-04-09 22:42:58,223 root         INFO     Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 23.622330\n",
      "Reconstruction: 22.244551, Regularization: 1.377779\n",
      "2019-04-09 22:42:58,280 root         INFO     Train Epoch: 131 [2560/8000 (32%)]\tTotal Loss: 29.758469\n",
      "Reconstruction: 28.599062, Regularization: 1.159407\n",
      "2019-04-09 22:42:58,338 root         INFO     Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 93.019135\n",
      "Reconstruction: 91.378418, Regularization: 1.640714\n",
      "2019-04-09 22:42:58,396 root         INFO     Train Epoch: 131 [3584/8000 (45%)]\tTotal Loss: 33.365467\n",
      "Reconstruction: 31.405926, Regularization: 1.959542\n",
      "2019-04-09 22:42:58,454 root         INFO     Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 69.781960\n",
      "Reconstruction: 68.235817, Regularization: 1.546144\n",
      "2019-04-09 22:42:58,511 root         INFO     Train Epoch: 131 [4608/8000 (58%)]\tTotal Loss: 8.427639\n",
      "Reconstruction: 6.923063, Regularization: 1.504576\n",
      "2019-04-09 22:42:58,569 root         INFO     Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 66.412888\n",
      "Reconstruction: 64.376572, Regularization: 2.036312\n",
      "2019-04-09 22:42:58,627 root         INFO     Train Epoch: 131 [5632/8000 (70%)]\tTotal Loss: 9.534657\n",
      "Reconstruction: 8.408666, Regularization: 1.125991\n",
      "2019-04-09 22:42:58,686 root         INFO     Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 49.462143\n",
      "Reconstruction: 47.913818, Regularization: 1.548325\n",
      "2019-04-09 22:42:58,745 root         INFO     Train Epoch: 131 [6656/8000 (83%)]\tTotal Loss: 9.091752\n",
      "Reconstruction: 7.461273, Regularization: 1.630479\n",
      "2019-04-09 22:42:58,803 root         INFO     Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 10.569821\n",
      "Reconstruction: 9.117620, Regularization: 1.452202\n",
      "2019-04-09 22:42:58,861 root         INFO     Train Epoch: 131 [7680/8000 (96%)]\tTotal Loss: 8.082720\n",
      "Reconstruction: 6.214292, Regularization: 1.868429\n",
      "2019-04-09 22:42:58,912 root         INFO     ====> Epoch: 131 Average loss: 83.8466\n",
      "2019-04-09 22:42:58,935 root         INFO     Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 8.307537\n",
      "Reconstruction: 6.582868, Regularization: 1.724669\n",
      "2019-04-09 22:42:58,992 root         INFO     Train Epoch: 132 [512/8000 (6%)]\tTotal Loss: 8.199785\n",
      "Reconstruction: 6.405231, Regularization: 1.794554\n",
      "2019-04-09 22:42:59,048 root         INFO     Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 48.422157\n",
      "Reconstruction: 46.700291, Regularization: 1.721866\n",
      "2019-04-09 22:42:59,105 root         INFO     Train Epoch: 132 [1536/8000 (19%)]\tTotal Loss: 303.436005\n",
      "Reconstruction: 301.545349, Regularization: 1.890655\n",
      "2019-04-09 22:42:59,161 root         INFO     Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 11.109409\n",
      "Reconstruction: 10.137421, Regularization: 0.971989\n",
      "2019-04-09 22:42:59,218 root         INFO     Train Epoch: 132 [2560/8000 (32%)]\tTotal Loss: 5.790541\n",
      "Reconstruction: 4.670363, Regularization: 1.120178\n",
      "2019-04-09 22:42:59,274 root         INFO     Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 8.810186\n",
      "Reconstruction: 7.339097, Regularization: 1.471090\n",
      "2019-04-09 22:42:59,330 root         INFO     Train Epoch: 132 [3584/8000 (45%)]\tTotal Loss: 10.937248\n",
      "Reconstruction: 9.245528, Regularization: 1.691720\n",
      "2019-04-09 22:42:59,387 root         INFO     Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 12.258078\n",
      "Reconstruction: 10.816856, Regularization: 1.441221\n",
      "2019-04-09 22:42:59,444 root         INFO     Train Epoch: 132 [4608/8000 (58%)]\tTotal Loss: 11.068378\n",
      "Reconstruction: 9.542702, Regularization: 1.525677\n",
      "2019-04-09 22:42:59,500 root         INFO     Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 4.892094\n",
      "Reconstruction: 3.014609, Regularization: 1.877485\n",
      "2019-04-09 22:42:59,556 root         INFO     Train Epoch: 132 [5632/8000 (70%)]\tTotal Loss: 21.673904\n",
      "Reconstruction: 19.853699, Regularization: 1.820205\n",
      "2019-04-09 22:42:59,612 root         INFO     Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 140.633774\n",
      "Reconstruction: 138.983337, Regularization: 1.650431\n",
      "2019-04-09 22:42:59,667 root         INFO     Train Epoch: 132 [6656/8000 (83%)]\tTotal Loss: 150.688156\n",
      "Reconstruction: 148.452927, Regularization: 2.235223\n",
      "2019-04-09 22:42:59,724 root         INFO     Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 12.977935\n",
      "Reconstruction: 11.094779, Regularization: 1.883156\n",
      "2019-04-09 22:42:59,779 root         INFO     Train Epoch: 132 [7680/8000 (96%)]\tTotal Loss: 2.703738\n",
      "Reconstruction: 1.071460, Regularization: 1.632277\n",
      "2019-04-09 22:42:59,828 root         INFO     ====> Epoch: 132 Average loss: 93.5798\n",
      "2019-04-09 22:42:59,852 root         INFO     Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 2.547785\n",
      "Reconstruction: 1.674041, Regularization: 0.873744\n",
      "2019-04-09 22:42:59,907 root         INFO     Train Epoch: 133 [512/8000 (6%)]\tTotal Loss: 23.627443\n",
      "Reconstruction: 22.518345, Regularization: 1.109098\n",
      "2019-04-09 22:42:59,963 root         INFO     Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 8.540430\n",
      "Reconstruction: 6.552086, Regularization: 1.988344\n",
      "2019-04-09 22:43:00,018 root         INFO     Train Epoch: 133 [1536/8000 (19%)]\tTotal Loss: 4.361078\n",
      "Reconstruction: 2.790949, Regularization: 1.570129\n",
      "2019-04-09 22:43:00,073 root         INFO     Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 17.072491\n",
      "Reconstruction: 15.839982, Regularization: 1.232509\n",
      "2019-04-09 22:43:00,129 root         INFO     Train Epoch: 133 [2560/8000 (32%)]\tTotal Loss: 5.497872\n",
      "Reconstruction: 4.265938, Regularization: 1.231935\n",
      "2019-04-09 22:43:00,184 root         INFO     Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 27.423571\n",
      "Reconstruction: 26.223572, Regularization: 1.199999\n",
      "2019-04-09 22:43:00,240 root         INFO     Train Epoch: 133 [3584/8000 (45%)]\tTotal Loss: 18.922518\n",
      "Reconstruction: 17.084940, Regularization: 1.837578\n",
      "2019-04-09 22:43:00,295 root         INFO     Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 10.375026\n",
      "Reconstruction: 9.068686, Regularization: 1.306340\n",
      "2019-04-09 22:43:00,350 root         INFO     Train Epoch: 133 [4608/8000 (58%)]\tTotal Loss: 17.013407\n",
      "Reconstruction: 15.306663, Regularization: 1.706744\n",
      "2019-04-09 22:43:00,405 root         INFO     Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 18.367527\n",
      "Reconstruction: 16.943384, Regularization: 1.424142\n",
      "2019-04-09 22:43:00,461 root         INFO     Train Epoch: 133 [5632/8000 (70%)]\tTotal Loss: 26.432764\n",
      "Reconstruction: 24.668043, Regularization: 1.764721\n",
      "2019-04-09 22:43:00,517 root         INFO     Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 2.230689\n",
      "Reconstruction: 1.323458, Regularization: 0.907230\n",
      "2019-04-09 22:43:00,572 root         INFO     Train Epoch: 133 [6656/8000 (83%)]\tTotal Loss: 6.972154\n",
      "Reconstruction: 5.422525, Regularization: 1.549629\n",
      "2019-04-09 22:43:00,627 root         INFO     Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 20.850903\n",
      "Reconstruction: 19.166821, Regularization: 1.684082\n",
      "2019-04-09 22:43:00,683 root         INFO     Train Epoch: 133 [7680/8000 (96%)]\tTotal Loss: 6.205835\n",
      "Reconstruction: 5.015020, Regularization: 1.190815\n",
      "2019-04-09 22:43:00,732 root         INFO     ====> Epoch: 133 Average loss: 67.5815\n",
      "2019-04-09 22:43:00,755 root         INFO     Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 10.700357\n",
      "Reconstruction: 9.012211, Regularization: 1.688146\n",
      "2019-04-09 22:43:00,811 root         INFO     Train Epoch: 134 [512/8000 (6%)]\tTotal Loss: 3.577815\n",
      "Reconstruction: 1.282821, Regularization: 2.294994\n",
      "2019-04-09 22:43:00,867 root         INFO     Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 12.805951\n",
      "Reconstruction: 11.217721, Regularization: 1.588230\n",
      "2019-04-09 22:43:00,923 root         INFO     Train Epoch: 134 [1536/8000 (19%)]\tTotal Loss: 13.486268\n",
      "Reconstruction: 12.204721, Regularization: 1.281547\n",
      "2019-04-09 22:43:00,979 root         INFO     Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 431.509369\n",
      "Reconstruction: 430.421570, Regularization: 1.087791\n",
      "2019-04-09 22:43:01,035 root         INFO     Train Epoch: 134 [2560/8000 (32%)]\tTotal Loss: 10.222831\n",
      "Reconstruction: 9.005768, Regularization: 1.217063\n",
      "2019-04-09 22:43:01,091 root         INFO     Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 4.140850\n",
      "Reconstruction: 2.996995, Regularization: 1.143854\n",
      "2019-04-09 22:43:01,147 root         INFO     Train Epoch: 134 [3584/8000 (45%)]\tTotal Loss: 8.937381\n",
      "Reconstruction: 7.611692, Regularization: 1.325689\n",
      "2019-04-09 22:43:01,203 root         INFO     Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 4.442740\n",
      "Reconstruction: 2.573957, Regularization: 1.868783\n",
      "2019-04-09 22:43:01,259 root         INFO     Train Epoch: 134 [4608/8000 (58%)]\tTotal Loss: 19.443972\n",
      "Reconstruction: 17.904013, Regularization: 1.539959\n",
      "2019-04-09 22:43:01,315 root         INFO     Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 31.079889\n",
      "Reconstruction: 28.810673, Regularization: 2.269216\n",
      "2019-04-09 22:43:01,371 root         INFO     Train Epoch: 134 [5632/8000 (70%)]\tTotal Loss: 133.562332\n",
      "Reconstruction: 131.661072, Regularization: 1.901265\n",
      "2019-04-09 22:43:01,427 root         INFO     Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 16.836832\n",
      "Reconstruction: 14.978844, Regularization: 1.857989\n",
      "2019-04-09 22:43:01,483 root         INFO     Train Epoch: 134 [6656/8000 (83%)]\tTotal Loss: 52.565670\n",
      "Reconstruction: 51.476845, Regularization: 1.088827\n",
      "2019-04-09 22:43:01,539 root         INFO     Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 19.581528\n",
      "Reconstruction: 18.277424, Regularization: 1.304103\n",
      "2019-04-09 22:43:01,595 root         INFO     Train Epoch: 134 [7680/8000 (96%)]\tTotal Loss: 20.828911\n",
      "Reconstruction: 19.656557, Regularization: 1.172353\n",
      "2019-04-09 22:43:01,644 root         INFO     ====> Epoch: 134 Average loss: 60.2427\n",
      "2019-04-09 22:43:01,668 root         INFO     Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 20.546417\n",
      "Reconstruction: 18.454002, Regularization: 2.092416\n",
      "2019-04-09 22:43:01,724 root         INFO     Train Epoch: 135 [512/8000 (6%)]\tTotal Loss: 5.636583\n",
      "Reconstruction: 4.306108, Regularization: 1.330475\n",
      "2019-04-09 22:43:01,780 root         INFO     Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 2.553427\n",
      "Reconstruction: 1.690537, Regularization: 0.862890\n",
      "2019-04-09 22:43:01,837 root         INFO     Train Epoch: 135 [1536/8000 (19%)]\tTotal Loss: 2.108857\n",
      "Reconstruction: 0.717223, Regularization: 1.391634\n",
      "2019-04-09 22:43:01,892 root         INFO     Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 1.643936\n",
      "Reconstruction: 0.699449, Regularization: 0.944487\n",
      "2019-04-09 22:43:01,948 root         INFO     Train Epoch: 135 [2560/8000 (32%)]\tTotal Loss: 4.301388\n",
      "Reconstruction: 2.679131, Regularization: 1.622256\n",
      "2019-04-09 22:43:02,003 root         INFO     Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 18.907192\n",
      "Reconstruction: 17.629873, Regularization: 1.277319\n",
      "2019-04-09 22:43:02,059 root         INFO     Train Epoch: 135 [3584/8000 (45%)]\tTotal Loss: 4.313282\n",
      "Reconstruction: 2.188065, Regularization: 2.125216\n",
      "2019-04-09 22:43:02,114 root         INFO     Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 37.012344\n",
      "Reconstruction: 35.323479, Regularization: 1.688865\n",
      "2019-04-09 22:43:02,169 root         INFO     Train Epoch: 135 [4608/8000 (58%)]\tTotal Loss: 12.467152\n",
      "Reconstruction: 10.780515, Regularization: 1.686637\n",
      "2019-04-09 22:43:02,225 root         INFO     Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 8.048547\n",
      "Reconstruction: 7.018363, Regularization: 1.030184\n",
      "2019-04-09 22:43:02,280 root         INFO     Train Epoch: 135 [5632/8000 (70%)]\tTotal Loss: 3.348796\n",
      "Reconstruction: 2.194863, Regularization: 1.153933\n",
      "2019-04-09 22:43:02,336 root         INFO     Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 192.722153\n",
      "Reconstruction: 190.303558, Regularization: 2.418595\n",
      "2019-04-09 22:43:02,391 root         INFO     Train Epoch: 135 [6656/8000 (83%)]\tTotal Loss: 24.354904\n",
      "Reconstruction: 23.231676, Regularization: 1.123228\n",
      "2019-04-09 22:43:02,446 root         INFO     Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 7.881920\n",
      "Reconstruction: 6.143654, Regularization: 1.738265\n",
      "2019-04-09 22:43:02,502 root         INFO     Train Epoch: 135 [7680/8000 (96%)]\tTotal Loss: 125.768181\n",
      "Reconstruction: 124.216751, Regularization: 1.551431\n",
      "2019-04-09 22:43:02,552 root         INFO     ====> Epoch: 135 Average loss: 78.5956\n",
      "2019-04-09 22:43:02,575 root         INFO     Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 2.052286\n",
      "Reconstruction: 0.923670, Regularization: 1.128616\n",
      "2019-04-09 22:43:02,632 root         INFO     Train Epoch: 136 [512/8000 (6%)]\tTotal Loss: 77.318016\n",
      "Reconstruction: 75.831718, Regularization: 1.486297\n",
      "2019-04-09 22:43:02,689 root         INFO     Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 25.028643\n",
      "Reconstruction: 23.113586, Regularization: 1.915056\n",
      "2019-04-09 22:43:02,745 root         INFO     Train Epoch: 136 [1536/8000 (19%)]\tTotal Loss: 3.572451\n",
      "Reconstruction: 2.433136, Regularization: 1.139315\n",
      "2019-04-09 22:43:02,802 root         INFO     Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 5.526623\n",
      "Reconstruction: 3.521378, Regularization: 2.005245\n",
      "2019-04-09 22:43:02,858 root         INFO     Train Epoch: 136 [2560/8000 (32%)]\tTotal Loss: 6.813435\n",
      "Reconstruction: 5.592619, Regularization: 1.220816\n",
      "2019-04-09 22:43:02,915 root         INFO     Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 3.417934\n",
      "Reconstruction: 2.371696, Regularization: 1.046237\n",
      "2019-04-09 22:43:02,972 root         INFO     Train Epoch: 136 [3584/8000 (45%)]\tTotal Loss: 63.498413\n",
      "Reconstruction: 62.288109, Regularization: 1.210304\n",
      "2019-04-09 22:43:03,028 root         INFO     Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 16.668148\n",
      "Reconstruction: 15.295765, Regularization: 1.372382\n",
      "2019-04-09 22:43:03,085 root         INFO     Train Epoch: 136 [4608/8000 (58%)]\tTotal Loss: 2.476740\n",
      "Reconstruction: 1.197116, Regularization: 1.279625\n",
      "2019-04-09 22:43:03,142 root         INFO     Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 12.426020\n",
      "Reconstruction: 11.218968, Regularization: 1.207051\n",
      "2019-04-09 22:43:03,199 root         INFO     Train Epoch: 136 [5632/8000 (70%)]\tTotal Loss: 208.259888\n",
      "Reconstruction: 206.309052, Regularization: 1.950840\n",
      "2019-04-09 22:43:03,256 root         INFO     Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 5.954254\n",
      "Reconstruction: 4.653488, Regularization: 1.300766\n",
      "2019-04-09 22:43:03,312 root         INFO     Train Epoch: 136 [6656/8000 (83%)]\tTotal Loss: 9.032757\n",
      "Reconstruction: 7.034251, Regularization: 1.998506\n",
      "2019-04-09 22:43:03,369 root         INFO     Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 2.996837\n",
      "Reconstruction: 1.726810, Regularization: 1.270027\n",
      "2019-04-09 22:43:03,426 root         INFO     Train Epoch: 136 [7680/8000 (96%)]\tTotal Loss: 13.585823\n",
      "Reconstruction: 11.854946, Regularization: 1.730877\n",
      "2019-04-09 22:43:03,477 root         INFO     ====> Epoch: 136 Average loss: 38.3352\n",
      "2019-04-09 22:43:03,500 root         INFO     Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 2.013139\n",
      "Reconstruction: 0.838242, Regularization: 1.174896\n",
      "2019-04-09 22:43:03,557 root         INFO     Train Epoch: 137 [512/8000 (6%)]\tTotal Loss: 23.968115\n",
      "Reconstruction: 21.999723, Regularization: 1.968392\n",
      "2019-04-09 22:43:03,614 root         INFO     Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 14.529394\n",
      "Reconstruction: 13.080400, Regularization: 1.448995\n",
      "2019-04-09 22:43:03,671 root         INFO     Train Epoch: 137 [1536/8000 (19%)]\tTotal Loss: 8.870507\n",
      "Reconstruction: 7.592752, Regularization: 1.277755\n",
      "2019-04-09 22:43:03,728 root         INFO     Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 116.881691\n",
      "Reconstruction: 114.887497, Regularization: 1.994195\n",
      "2019-04-09 22:43:03,784 root         INFO     Train Epoch: 137 [2560/8000 (32%)]\tTotal Loss: 6.021807\n",
      "Reconstruction: 4.187314, Regularization: 1.834493\n",
      "2019-04-09 22:43:03,840 root         INFO     Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 14.731409\n",
      "Reconstruction: 13.098403, Regularization: 1.633006\n",
      "2019-04-09 22:43:03,896 root         INFO     Train Epoch: 137 [3584/8000 (45%)]\tTotal Loss: 14.889692\n",
      "Reconstruction: 13.126058, Regularization: 1.763635\n",
      "2019-04-09 22:43:03,952 root         INFO     Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 2.869400\n",
      "Reconstruction: 1.341617, Regularization: 1.527783\n",
      "2019-04-09 22:43:04,009 root         INFO     Train Epoch: 137 [4608/8000 (58%)]\tTotal Loss: 36.620132\n",
      "Reconstruction: 35.278393, Regularization: 1.341741\n",
      "2019-04-09 22:43:04,065 root         INFO     Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 3.907268\n",
      "Reconstruction: 2.450035, Regularization: 1.457233\n",
      "2019-04-09 22:43:04,121 root         INFO     Train Epoch: 137 [5632/8000 (70%)]\tTotal Loss: 2.597203\n",
      "Reconstruction: 1.391476, Regularization: 1.205728\n",
      "2019-04-09 22:43:04,178 root         INFO     Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 2.907332\n",
      "Reconstruction: 1.456617, Regularization: 1.450715\n",
      "2019-04-09 22:43:04,234 root         INFO     Train Epoch: 137 [6656/8000 (83%)]\tTotal Loss: 162.699890\n",
      "Reconstruction: 159.384048, Regularization: 3.315839\n",
      "2019-04-09 22:43:04,290 root         INFO     Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 8.091867\n",
      "Reconstruction: 6.704148, Regularization: 1.387719\n",
      "2019-04-09 22:43:04,346 root         INFO     Train Epoch: 137 [7680/8000 (96%)]\tTotal Loss: 9.113330\n",
      "Reconstruction: 8.030972, Regularization: 1.082358\n",
      "2019-04-09 22:43:04,396 root         INFO     ====> Epoch: 137 Average loss: 45.7112\n",
      "2019-04-09 22:43:04,419 root         INFO     Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 11.926803\n",
      "Reconstruction: 10.748583, Regularization: 1.178220\n",
      "2019-04-09 22:43:04,476 root         INFO     Train Epoch: 138 [512/8000 (6%)]\tTotal Loss: 4.770832\n",
      "Reconstruction: 3.228290, Regularization: 1.542542\n",
      "2019-04-09 22:43:04,532 root         INFO     Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 5.696184\n",
      "Reconstruction: 4.308558, Regularization: 1.387625\n",
      "2019-04-09 22:43:04,588 root         INFO     Train Epoch: 138 [1536/8000 (19%)]\tTotal Loss: 4.002392\n",
      "Reconstruction: 2.807982, Regularization: 1.194410\n",
      "2019-04-09 22:43:04,643 root         INFO     Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 7.317745\n",
      "Reconstruction: 5.709999, Regularization: 1.607746\n",
      "2019-04-09 22:43:04,699 root         INFO     Train Epoch: 138 [2560/8000 (32%)]\tTotal Loss: 7.431342\n",
      "Reconstruction: 6.217238, Regularization: 1.214104\n",
      "2019-04-09 22:43:04,754 root         INFO     Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 10.587315\n",
      "Reconstruction: 9.157006, Regularization: 1.430308\n",
      "2019-04-09 22:43:04,810 root         INFO     Train Epoch: 138 [3584/8000 (45%)]\tTotal Loss: 54.824265\n",
      "Reconstruction: 53.094086, Regularization: 1.730178\n",
      "2019-04-09 22:43:04,866 root         INFO     Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 4.432460\n",
      "Reconstruction: 2.465287, Regularization: 1.967173\n",
      "2019-04-09 22:43:04,922 root         INFO     Train Epoch: 138 [4608/8000 (58%)]\tTotal Loss: 33.258244\n",
      "Reconstruction: 31.687504, Regularization: 1.570740\n",
      "2019-04-09 22:43:04,977 root         INFO     Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 23.123440\n",
      "Reconstruction: 21.503647, Regularization: 1.619794\n",
      "2019-04-09 22:43:05,033 root         INFO     Train Epoch: 138 [5632/8000 (70%)]\tTotal Loss: 246.883713\n",
      "Reconstruction: 245.444031, Regularization: 1.439687\n",
      "2019-04-09 22:43:05,089 root         INFO     Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 24.597912\n",
      "Reconstruction: 23.093861, Regularization: 1.504051\n",
      "2019-04-09 22:43:05,145 root         INFO     Train Epoch: 138 [6656/8000 (83%)]\tTotal Loss: 4.022148\n",
      "Reconstruction: 2.740077, Regularization: 1.282070\n",
      "2019-04-09 22:43:05,200 root         INFO     Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 7.847625\n",
      "Reconstruction: 6.262326, Regularization: 1.585299\n",
      "2019-04-09 22:43:05,256 root         INFO     Train Epoch: 138 [7680/8000 (96%)]\tTotal Loss: 5.179101\n",
      "Reconstruction: 3.661630, Regularization: 1.517471\n",
      "2019-04-09 22:43:05,305 root         INFO     ====> Epoch: 138 Average loss: 43.1183\n",
      "2019-04-09 22:43:05,329 root         INFO     Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 17.764904\n",
      "Reconstruction: 16.108038, Regularization: 1.656867\n",
      "2019-04-09 22:43:05,386 root         INFO     Train Epoch: 139 [512/8000 (6%)]\tTotal Loss: 18.531557\n",
      "Reconstruction: 17.559765, Regularization: 0.971793\n",
      "2019-04-09 22:43:05,442 root         INFO     Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 8.766215\n",
      "Reconstruction: 7.567147, Regularization: 1.199068\n",
      "2019-04-09 22:43:05,499 root         INFO     Train Epoch: 139 [1536/8000 (19%)]\tTotal Loss: 11.439638\n",
      "Reconstruction: 9.472610, Regularization: 1.967029\n",
      "2019-04-09 22:43:05,556 root         INFO     Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 162.861588\n",
      "Reconstruction: 161.026566, Regularization: 1.835025\n",
      "2019-04-09 22:43:05,611 root         INFO     Train Epoch: 139 [2560/8000 (32%)]\tTotal Loss: 1.969234\n",
      "Reconstruction: 0.546550, Regularization: 1.422684\n",
      "2019-04-09 22:43:05,667 root         INFO     Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 7.387604\n",
      "Reconstruction: 5.641950, Regularization: 1.745654\n",
      "2019-04-09 22:43:05,723 root         INFO     Train Epoch: 139 [3584/8000 (45%)]\tTotal Loss: 14.114102\n",
      "Reconstruction: 13.349478, Regularization: 0.764625\n",
      "2019-04-09 22:43:05,779 root         INFO     Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 7.146146\n",
      "Reconstruction: 6.193351, Regularization: 0.952795\n",
      "2019-04-09 22:43:05,835 root         INFO     Train Epoch: 139 [4608/8000 (58%)]\tTotal Loss: 3.900979\n",
      "Reconstruction: 2.441040, Regularization: 1.459939\n",
      "2019-04-09 22:43:05,890 root         INFO     Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 20.287996\n",
      "Reconstruction: 18.751335, Regularization: 1.536661\n",
      "2019-04-09 22:43:05,946 root         INFO     Train Epoch: 139 [5632/8000 (70%)]\tTotal Loss: 10.285272\n",
      "Reconstruction: 8.632756, Regularization: 1.652515\n",
      "2019-04-09 22:43:06,002 root         INFO     Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 55.670120\n",
      "Reconstruction: 54.223053, Regularization: 1.447067\n",
      "2019-04-09 22:43:06,058 root         INFO     Train Epoch: 139 [6656/8000 (83%)]\tTotal Loss: 5.675038\n",
      "Reconstruction: 4.286326, Regularization: 1.388712\n",
      "2019-04-09 22:43:06,113 root         INFO     Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 5.071856\n",
      "Reconstruction: 3.229915, Regularization: 1.841940\n",
      "2019-04-09 22:43:06,170 root         INFO     Train Epoch: 139 [7680/8000 (96%)]\tTotal Loss: 3.674625\n",
      "Reconstruction: 2.190226, Regularization: 1.484399\n",
      "2019-04-09 22:43:06,219 root         INFO     ====> Epoch: 139 Average loss: 43.3133\n",
      "2019-04-09 22:43:06,242 root         INFO     Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 48.601074\n",
      "Reconstruction: 46.868767, Regularization: 1.732306\n",
      "2019-04-09 22:43:06,299 root         INFO     Train Epoch: 140 [512/8000 (6%)]\tTotal Loss: 4.990288\n",
      "Reconstruction: 3.046519, Regularization: 1.943769\n",
      "2019-04-09 22:43:06,354 root         INFO     Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 50.979946\n",
      "Reconstruction: 49.467731, Regularization: 1.512215\n",
      "2019-04-09 22:43:06,410 root         INFO     Train Epoch: 140 [1536/8000 (19%)]\tTotal Loss: 3.312484\n",
      "Reconstruction: 1.706837, Regularization: 1.605646\n",
      "2019-04-09 22:43:06,466 root         INFO     Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 17.159758\n",
      "Reconstruction: 15.815566, Regularization: 1.344191\n",
      "2019-04-09 22:43:06,521 root         INFO     Train Epoch: 140 [2560/8000 (32%)]\tTotal Loss: 13.115210\n",
      "Reconstruction: 11.364547, Regularization: 1.750663\n",
      "2019-04-09 22:43:06,575 root         INFO     Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 17.032494\n",
      "Reconstruction: 15.670965, Regularization: 1.361527\n",
      "2019-04-09 22:43:06,630 root         INFO     Train Epoch: 140 [3584/8000 (45%)]\tTotal Loss: 10.788995\n",
      "Reconstruction: 9.419987, Regularization: 1.369008\n",
      "2019-04-09 22:43:06,684 root         INFO     Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 30.297184\n",
      "Reconstruction: 29.376938, Regularization: 0.920245\n",
      "2019-04-09 22:43:06,739 root         INFO     Train Epoch: 140 [4608/8000 (58%)]\tTotal Loss: 82.603867\n",
      "Reconstruction: 80.599930, Regularization: 2.003935\n",
      "2019-04-09 22:43:06,794 root         INFO     Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 9.648351\n",
      "Reconstruction: 8.233482, Regularization: 1.414868\n",
      "2019-04-09 22:43:06,850 root         INFO     Train Epoch: 140 [5632/8000 (70%)]\tTotal Loss: 3.213980\n",
      "Reconstruction: 1.680047, Regularization: 1.533933\n",
      "2019-04-09 22:43:06,906 root         INFO     Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 22.577717\n",
      "Reconstruction: 21.011997, Regularization: 1.565720\n",
      "2019-04-09 22:43:06,962 root         INFO     Train Epoch: 140 [6656/8000 (83%)]\tTotal Loss: 5.741142\n",
      "Reconstruction: 4.995734, Regularization: 0.745409\n",
      "2019-04-09 22:43:07,018 root         INFO     Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 24.143394\n",
      "Reconstruction: 23.087593, Regularization: 1.055801\n",
      "2019-04-09 22:43:07,073 root         INFO     Train Epoch: 140 [7680/8000 (96%)]\tTotal Loss: 181.202698\n",
      "Reconstruction: 179.949219, Regularization: 1.253473\n",
      "2019-04-09 22:43:07,122 root         INFO     ====> Epoch: 140 Average loss: 32.5250\n",
      "2019-04-09 22:43:07,145 root         INFO     Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 2.453188\n",
      "Reconstruction: 0.924626, Regularization: 1.528563\n",
      "2019-04-09 22:43:07,202 root         INFO     Train Epoch: 141 [512/8000 (6%)]\tTotal Loss: 8.096534\n",
      "Reconstruction: 6.253550, Regularization: 1.842983\n",
      "2019-04-09 22:43:07,258 root         INFO     Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 4.758723\n",
      "Reconstruction: 2.997520, Regularization: 1.761203\n",
      "2019-04-09 22:43:07,315 root         INFO     Train Epoch: 141 [1536/8000 (19%)]\tTotal Loss: 24.027164\n",
      "Reconstruction: 22.445152, Regularization: 1.582011\n",
      "2019-04-09 22:43:07,371 root         INFO     Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 104.315727\n",
      "Reconstruction: 102.135841, Regularization: 2.179884\n",
      "2019-04-09 22:43:07,428 root         INFO     Train Epoch: 141 [2560/8000 (32%)]\tTotal Loss: 90.358681\n",
      "Reconstruction: 88.920197, Regularization: 1.438486\n",
      "2019-04-09 22:43:07,484 root         INFO     Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 9.057676\n",
      "Reconstruction: 7.444703, Regularization: 1.612973\n",
      "2019-04-09 22:43:07,542 root         INFO     Train Epoch: 141 [3584/8000 (45%)]\tTotal Loss: 4.628232\n",
      "Reconstruction: 2.758579, Regularization: 1.869654\n",
      "2019-04-09 22:43:07,597 root         INFO     Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 2.323080\n",
      "Reconstruction: 1.366326, Regularization: 0.956754\n",
      "2019-04-09 22:43:07,651 root         INFO     Train Epoch: 141 [4608/8000 (58%)]\tTotal Loss: 2.118785\n",
      "Reconstruction: 0.801257, Regularization: 1.317528\n",
      "2019-04-09 22:43:07,704 root         INFO     Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 151.455093\n",
      "Reconstruction: 149.347733, Regularization: 2.107357\n",
      "2019-04-09 22:43:07,759 root         INFO     Train Epoch: 141 [5632/8000 (70%)]\tTotal Loss: 4.087162\n",
      "Reconstruction: 2.848394, Regularization: 1.238768\n",
      "2019-04-09 22:43:07,814 root         INFO     Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 25.099270\n",
      "Reconstruction: 23.627409, Regularization: 1.471861\n",
      "2019-04-09 22:43:07,870 root         INFO     Train Epoch: 141 [6656/8000 (83%)]\tTotal Loss: 4.660203\n",
      "Reconstruction: 3.819595, Regularization: 0.840607\n",
      "2019-04-09 22:43:07,925 root         INFO     Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 3.062647\n",
      "Reconstruction: 1.476637, Regularization: 1.586010\n",
      "2019-04-09 22:43:07,981 root         INFO     Train Epoch: 141 [7680/8000 (96%)]\tTotal Loss: 3.226612\n",
      "Reconstruction: 1.629540, Regularization: 1.597072\n",
      "2019-04-09 22:43:08,031 root         INFO     ====> Epoch: 141 Average loss: 29.2847\n",
      "2019-04-09 22:43:08,053 root         INFO     Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 11.020986\n",
      "Reconstruction: 9.174444, Regularization: 1.846541\n",
      "2019-04-09 22:43:08,108 root         INFO     Train Epoch: 142 [512/8000 (6%)]\tTotal Loss: 406.879242\n",
      "Reconstruction: 404.811829, Regularization: 2.067422\n",
      "2019-04-09 22:43:08,162 root         INFO     Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 121.293427\n",
      "Reconstruction: 119.817291, Regularization: 1.476133\n",
      "2019-04-09 22:43:08,217 root         INFO     Train Epoch: 142 [1536/8000 (19%)]\tTotal Loss: 172.665802\n",
      "Reconstruction: 171.012207, Regularization: 1.653599\n",
      "2019-04-09 22:43:08,271 root         INFO     Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 7.617737\n",
      "Reconstruction: 6.151316, Regularization: 1.466422\n",
      "2019-04-09 22:43:08,325 root         INFO     Train Epoch: 142 [2560/8000 (32%)]\tTotal Loss: 6.182967\n",
      "Reconstruction: 4.896949, Regularization: 1.286018\n",
      "2019-04-09 22:43:08,379 root         INFO     Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 2.772511\n",
      "Reconstruction: 1.066432, Regularization: 1.706079\n",
      "2019-04-09 22:43:08,434 root         INFO     Train Epoch: 142 [3584/8000 (45%)]\tTotal Loss: 3.553108\n",
      "Reconstruction: 2.393137, Regularization: 1.159972\n",
      "2019-04-09 22:43:08,488 root         INFO     Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 21.926662\n",
      "Reconstruction: 20.595375, Regularization: 1.331287\n",
      "2019-04-09 22:43:08,542 root         INFO     Train Epoch: 142 [4608/8000 (58%)]\tTotal Loss: 9.274526\n",
      "Reconstruction: 7.709225, Regularization: 1.565301\n",
      "2019-04-09 22:43:08,596 root         INFO     Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 5.312634\n",
      "Reconstruction: 3.203269, Regularization: 2.109366\n",
      "2019-04-09 22:43:08,650 root         INFO     Train Epoch: 142 [5632/8000 (70%)]\tTotal Loss: 2.798381\n",
      "Reconstruction: 1.580853, Regularization: 1.217529\n",
      "2019-04-09 22:43:08,704 root         INFO     Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 3.096974\n",
      "Reconstruction: 1.201651, Regularization: 1.895324\n",
      "2019-04-09 22:43:08,758 root         INFO     Train Epoch: 142 [6656/8000 (83%)]\tTotal Loss: 6.888316\n",
      "Reconstruction: 4.974878, Regularization: 1.913438\n",
      "2019-04-09 22:43:08,813 root         INFO     Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 8.719853\n",
      "Reconstruction: 7.355795, Regularization: 1.364058\n",
      "2019-04-09 22:43:08,867 root         INFO     Train Epoch: 142 [7680/8000 (96%)]\tTotal Loss: 15.088457\n",
      "Reconstruction: 13.966817, Regularization: 1.121640\n",
      "2019-04-09 22:43:08,916 root         INFO     ====> Epoch: 142 Average loss: 28.6294\n",
      "2019-04-09 22:43:08,939 root         INFO     Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 2.542559\n",
      "Reconstruction: 0.575584, Regularization: 1.966975\n",
      "2019-04-09 22:43:08,993 root         INFO     Train Epoch: 143 [512/8000 (6%)]\tTotal Loss: 6.180905\n",
      "Reconstruction: 5.228655, Regularization: 0.952250\n",
      "2019-04-09 22:43:09,047 root         INFO     Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 10.981820\n",
      "Reconstruction: 9.555589, Regularization: 1.426232\n",
      "2019-04-09 22:43:09,102 root         INFO     Train Epoch: 143 [1536/8000 (19%)]\tTotal Loss: 47.890453\n",
      "Reconstruction: 46.248302, Regularization: 1.642150\n",
      "2019-04-09 22:43:09,156 root         INFO     Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 223.652512\n",
      "Reconstruction: 221.632812, Regularization: 2.019705\n",
      "2019-04-09 22:43:09,211 root         INFO     Train Epoch: 143 [2560/8000 (32%)]\tTotal Loss: 3.630381\n",
      "Reconstruction: 1.908625, Regularization: 1.721756\n",
      "2019-04-09 22:43:09,265 root         INFO     Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 11.750334\n",
      "Reconstruction: 10.478513, Regularization: 1.271821\n",
      "2019-04-09 22:43:09,319 root         INFO     Train Epoch: 143 [3584/8000 (45%)]\tTotal Loss: 75.611427\n",
      "Reconstruction: 74.154068, Regularization: 1.457356\n",
      "2019-04-09 22:43:09,374 root         INFO     Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 2.879887\n",
      "Reconstruction: 1.863088, Regularization: 1.016799\n",
      "2019-04-09 22:43:09,428 root         INFO     Train Epoch: 143 [4608/8000 (58%)]\tTotal Loss: 7.951389\n",
      "Reconstruction: 6.130994, Regularization: 1.820395\n",
      "2019-04-09 22:43:09,482 root         INFO     Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 9.629449\n",
      "Reconstruction: 8.205013, Regularization: 1.424436\n",
      "2019-04-09 22:43:09,536 root         INFO     Train Epoch: 143 [5632/8000 (70%)]\tTotal Loss: 22.304270\n",
      "Reconstruction: 20.656532, Regularization: 1.647737\n",
      "2019-04-09 22:43:09,589 root         INFO     Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 22.829786\n",
      "Reconstruction: 20.680387, Regularization: 2.149398\n",
      "2019-04-09 22:43:09,644 root         INFO     Train Epoch: 143 [6656/8000 (83%)]\tTotal Loss: 4.800821\n",
      "Reconstruction: 3.558042, Regularization: 1.242779\n",
      "2019-04-09 22:43:09,698 root         INFO     Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 4.468488\n",
      "Reconstruction: 3.474308, Regularization: 0.994179\n",
      "2019-04-09 22:43:09,752 root         INFO     Train Epoch: 143 [7680/8000 (96%)]\tTotal Loss: 3.695209\n",
      "Reconstruction: 2.496676, Regularization: 1.198533\n",
      "2019-04-09 22:43:09,800 root         INFO     ====> Epoch: 143 Average loss: 24.2625\n",
      "2019-04-09 22:43:09,823 root         INFO     Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 14.834209\n",
      "Reconstruction: 12.590205, Regularization: 2.244004\n",
      "2019-04-09 22:43:09,878 root         INFO     Train Epoch: 144 [512/8000 (6%)]\tTotal Loss: 31.460514\n",
      "Reconstruction: 30.106874, Regularization: 1.353639\n",
      "2019-04-09 22:43:09,933 root         INFO     Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 4.112695\n",
      "Reconstruction: 3.215856, Regularization: 0.896839\n",
      "2019-04-09 22:43:09,987 root         INFO     Train Epoch: 144 [1536/8000 (19%)]\tTotal Loss: 15.334392\n",
      "Reconstruction: 13.380886, Regularization: 1.953506\n",
      "2019-04-09 22:43:10,041 root         INFO     Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 6.575479\n",
      "Reconstruction: 5.244969, Regularization: 1.330509\n",
      "2019-04-09 22:43:10,095 root         INFO     Train Epoch: 144 [2560/8000 (32%)]\tTotal Loss: 3.019679\n",
      "Reconstruction: 1.373325, Regularization: 1.646354\n",
      "2019-04-09 22:43:10,149 root         INFO     Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 2.833546\n",
      "Reconstruction: 1.175826, Regularization: 1.657719\n",
      "2019-04-09 22:43:10,204 root         INFO     Train Epoch: 144 [3584/8000 (45%)]\tTotal Loss: 6.327962\n",
      "Reconstruction: 5.006120, Regularization: 1.321842\n",
      "2019-04-09 22:43:10,258 root         INFO     Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 5.907338\n",
      "Reconstruction: 4.749218, Regularization: 1.158120\n",
      "2019-04-09 22:43:10,312 root         INFO     Train Epoch: 144 [4608/8000 (58%)]\tTotal Loss: 2.431234\n",
      "Reconstruction: 1.495741, Regularization: 0.935493\n",
      "2019-04-09 22:43:10,367 root         INFO     Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 12.134802\n",
      "Reconstruction: 10.453131, Regularization: 1.681671\n",
      "2019-04-09 22:43:10,421 root         INFO     Train Epoch: 144 [5632/8000 (70%)]\tTotal Loss: 20.282572\n",
      "Reconstruction: 18.825237, Regularization: 1.457335\n",
      "2019-04-09 22:43:10,475 root         INFO     Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 7.367676\n",
      "Reconstruction: 5.480922, Regularization: 1.886754\n",
      "2019-04-09 22:43:10,529 root         INFO     Train Epoch: 144 [6656/8000 (83%)]\tTotal Loss: 9.010084\n",
      "Reconstruction: 7.751934, Regularization: 1.258151\n",
      "2019-04-09 22:43:10,584 root         INFO     Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 2.065438\n",
      "Reconstruction: 0.417050, Regularization: 1.648387\n",
      "2019-04-09 22:43:10,638 root         INFO     Train Epoch: 144 [7680/8000 (96%)]\tTotal Loss: 15.428389\n",
      "Reconstruction: 13.861709, Regularization: 1.566680\n",
      "2019-04-09 22:43:10,686 root         INFO     ====> Epoch: 144 Average loss: 22.7657\n",
      "2019-04-09 22:43:10,710 root         INFO     Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 13.270587\n",
      "Reconstruction: 11.649075, Regularization: 1.621512\n",
      "2019-04-09 22:43:10,766 root         INFO     Train Epoch: 145 [512/8000 (6%)]\tTotal Loss: 41.424145\n",
      "Reconstruction: 39.818089, Regularization: 1.606058\n",
      "2019-04-09 22:43:10,823 root         INFO     Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 29.874271\n",
      "Reconstruction: 27.659878, Regularization: 2.214394\n",
      "2019-04-09 22:43:10,879 root         INFO     Train Epoch: 145 [1536/8000 (19%)]\tTotal Loss: 10.176195\n",
      "Reconstruction: 8.858639, Regularization: 1.317556\n",
      "2019-04-09 22:43:10,936 root         INFO     Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 22.595146\n",
      "Reconstruction: 20.677385, Regularization: 1.917760\n",
      "2019-04-09 22:43:10,992 root         INFO     Train Epoch: 145 [2560/8000 (32%)]\tTotal Loss: 140.599472\n",
      "Reconstruction: 138.663315, Regularization: 1.936160\n",
      "2019-04-09 22:43:11,049 root         INFO     Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 2.540286\n",
      "Reconstruction: 1.184855, Regularization: 1.355432\n",
      "2019-04-09 22:43:11,102 root         INFO     Train Epoch: 145 [3584/8000 (45%)]\tTotal Loss: 5.425570\n",
      "Reconstruction: 3.724483, Regularization: 1.701086\n",
      "2019-04-09 22:43:11,155 root         INFO     Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 4.527252\n",
      "Reconstruction: 2.105241, Regularization: 2.422011\n",
      "2019-04-09 22:43:11,208 root         INFO     Train Epoch: 145 [4608/8000 (58%)]\tTotal Loss: 3.489038\n",
      "Reconstruction: 1.748799, Regularization: 1.740240\n",
      "2019-04-09 22:43:11,262 root         INFO     Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 3.862731\n",
      "Reconstruction: 2.252992, Regularization: 1.609740\n",
      "2019-04-09 22:43:11,315 root         INFO     Train Epoch: 145 [5632/8000 (70%)]\tTotal Loss: 3.443184\n",
      "Reconstruction: 2.537553, Regularization: 0.905631\n",
      "2019-04-09 22:43:11,368 root         INFO     Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 5.773247\n",
      "Reconstruction: 4.089484, Regularization: 1.683763\n",
      "2019-04-09 22:43:11,422 root         INFO     Train Epoch: 145 [6656/8000 (83%)]\tTotal Loss: 42.118546\n",
      "Reconstruction: 40.371719, Regularization: 1.746825\n",
      "2019-04-09 22:43:11,475 root         INFO     Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 22.255341\n",
      "Reconstruction: 20.319717, Regularization: 1.935622\n",
      "2019-04-09 22:43:11,529 root         INFO     Train Epoch: 145 [7680/8000 (96%)]\tTotal Loss: 6.884159\n",
      "Reconstruction: 5.685870, Regularization: 1.198289\n",
      "2019-04-09 22:43:11,577 root         INFO     ====> Epoch: 145 Average loss: 22.0772\n",
      "2019-04-09 22:43:11,600 root         INFO     Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 6.896741\n",
      "Reconstruction: 5.464931, Regularization: 1.431810\n",
      "2019-04-09 22:43:11,655 root         INFO     Train Epoch: 146 [512/8000 (6%)]\tTotal Loss: 229.879623\n",
      "Reconstruction: 228.364700, Regularization: 1.514916\n",
      "2019-04-09 22:43:11,711 root         INFO     Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 5.540174\n",
      "Reconstruction: 3.993018, Regularization: 1.547156\n",
      "2019-04-09 22:43:11,766 root         INFO     Train Epoch: 146 [1536/8000 (19%)]\tTotal Loss: 4.668155\n",
      "Reconstruction: 3.211877, Regularization: 1.456278\n",
      "2019-04-09 22:43:11,822 root         INFO     Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 12.033037\n",
      "Reconstruction: 10.777043, Regularization: 1.255994\n",
      "2019-04-09 22:43:11,877 root         INFO     Train Epoch: 146 [2560/8000 (32%)]\tTotal Loss: 5.019759\n",
      "Reconstruction: 3.423201, Regularization: 1.596558\n",
      "2019-04-09 22:43:11,932 root         INFO     Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 10.401681\n",
      "Reconstruction: 9.086584, Regularization: 1.315097\n",
      "2019-04-09 22:43:11,988 root         INFO     Train Epoch: 146 [3584/8000 (45%)]\tTotal Loss: 4.255775\n",
      "Reconstruction: 2.861735, Regularization: 1.394040\n",
      "2019-04-09 22:43:12,044 root         INFO     Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 3.909338\n",
      "Reconstruction: 2.919909, Regularization: 0.989428\n",
      "2019-04-09 22:43:12,100 root         INFO     Train Epoch: 146 [4608/8000 (58%)]\tTotal Loss: 10.454428\n",
      "Reconstruction: 9.646379, Regularization: 0.808048\n",
      "2019-04-09 22:43:12,155 root         INFO     Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 4.089555\n",
      "Reconstruction: 2.356765, Regularization: 1.732791\n",
      "2019-04-09 22:43:12,210 root         INFO     Train Epoch: 146 [5632/8000 (70%)]\tTotal Loss: 3.388883\n",
      "Reconstruction: 1.737251, Regularization: 1.651633\n",
      "2019-04-09 22:43:12,265 root         INFO     Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 7.625375\n",
      "Reconstruction: 6.950322, Regularization: 0.675053\n",
      "2019-04-09 22:43:12,319 root         INFO     Train Epoch: 146 [6656/8000 (83%)]\tTotal Loss: 15.420024\n",
      "Reconstruction: 14.097996, Regularization: 1.322028\n",
      "2019-04-09 22:43:12,374 root         INFO     Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 5.409875\n",
      "Reconstruction: 4.277008, Regularization: 1.132867\n",
      "2019-04-09 22:43:12,429 root         INFO     Train Epoch: 146 [7680/8000 (96%)]\tTotal Loss: 12.243376\n",
      "Reconstruction: 10.131766, Regularization: 2.111609\n",
      "2019-04-09 22:43:12,478 root         INFO     ====> Epoch: 146 Average loss: 20.2395\n",
      "2019-04-09 22:43:12,501 root         INFO     Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 25.940207\n",
      "Reconstruction: 24.880165, Regularization: 1.060041\n",
      "2019-04-09 22:43:12,556 root         INFO     Train Epoch: 147 [512/8000 (6%)]\tTotal Loss: 1.316220\n",
      "Reconstruction: 0.368101, Regularization: 0.948119\n",
      "2019-04-09 22:43:12,611 root         INFO     Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 3.106123\n",
      "Reconstruction: 1.770633, Regularization: 1.335491\n",
      "2019-04-09 22:43:12,666 root         INFO     Train Epoch: 147 [1536/8000 (19%)]\tTotal Loss: 5.300802\n",
      "Reconstruction: 2.827813, Regularization: 2.472989\n",
      "2019-04-09 22:43:12,721 root         INFO     Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 3.638654\n",
      "Reconstruction: 1.995676, Regularization: 1.642977\n",
      "2019-04-09 22:43:12,776 root         INFO     Train Epoch: 147 [2560/8000 (32%)]\tTotal Loss: 2.580310\n",
      "Reconstruction: 0.891613, Regularization: 1.688697\n",
      "2019-04-09 22:43:12,831 root         INFO     Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 20.557354\n",
      "Reconstruction: 19.095463, Regularization: 1.461892\n",
      "2019-04-09 22:43:12,885 root         INFO     Train Epoch: 147 [3584/8000 (45%)]\tTotal Loss: 3.872585\n",
      "Reconstruction: 2.339545, Regularization: 1.533041\n",
      "2019-04-09 22:43:12,940 root         INFO     Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 5.306529\n",
      "Reconstruction: 3.351399, Regularization: 1.955130\n",
      "2019-04-09 22:43:12,994 root         INFO     Train Epoch: 147 [4608/8000 (58%)]\tTotal Loss: 1.224355\n",
      "Reconstruction: 0.285473, Regularization: 0.938882\n",
      "2019-04-09 22:43:13,049 root         INFO     Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 108.241241\n",
      "Reconstruction: 106.318390, Regularization: 1.922849\n",
      "2019-04-09 22:43:13,104 root         INFO     Train Epoch: 147 [5632/8000 (70%)]\tTotal Loss: 14.083197\n",
      "Reconstruction: 13.024070, Regularization: 1.059127\n",
      "2019-04-09 22:43:13,159 root         INFO     Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 3.239359\n",
      "Reconstruction: 1.635357, Regularization: 1.604002\n",
      "2019-04-09 22:43:13,213 root         INFO     Train Epoch: 147 [6656/8000 (83%)]\tTotal Loss: 8.818812\n",
      "Reconstruction: 7.272750, Regularization: 1.546063\n",
      "2019-04-09 22:43:13,267 root         INFO     Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 651.488647\n",
      "Reconstruction: 649.632629, Regularization: 1.856023\n",
      "2019-04-09 22:43:13,321 root         INFO     Train Epoch: 147 [7680/8000 (96%)]\tTotal Loss: 4.492602\n",
      "Reconstruction: 3.295804, Regularization: 1.196798\n",
      "2019-04-09 22:43:13,369 root         INFO     ====> Epoch: 147 Average loss: 17.9697\n",
      "2019-04-09 22:43:13,393 root         INFO     Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 2.981397\n",
      "Reconstruction: 1.990748, Regularization: 0.990649\n",
      "2019-04-09 22:43:13,448 root         INFO     Train Epoch: 148 [512/8000 (6%)]\tTotal Loss: 6.127371\n",
      "Reconstruction: 4.400410, Regularization: 1.726961\n",
      "2019-04-09 22:43:13,504 root         INFO     Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 61.098541\n",
      "Reconstruction: 59.635769, Regularization: 1.462774\n",
      "2019-04-09 22:43:13,558 root         INFO     Train Epoch: 148 [1536/8000 (19%)]\tTotal Loss: 5.530433\n",
      "Reconstruction: 4.271394, Regularization: 1.259039\n",
      "2019-04-09 22:43:13,613 root         INFO     Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 19.288448\n",
      "Reconstruction: 17.606693, Regularization: 1.681754\n",
      "2019-04-09 22:43:13,667 root         INFO     Train Epoch: 148 [2560/8000 (32%)]\tTotal Loss: 6.680022\n",
      "Reconstruction: 4.567978, Regularization: 2.112044\n",
      "2019-04-09 22:43:13,722 root         INFO     Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 3.633961\n",
      "Reconstruction: 2.138246, Regularization: 1.495716\n",
      "2019-04-09 22:43:13,776 root         INFO     Train Epoch: 148 [3584/8000 (45%)]\tTotal Loss: 3.206245\n",
      "Reconstruction: 1.958818, Regularization: 1.247427\n",
      "2019-04-09 22:43:13,831 root         INFO     Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 3.642962\n",
      "Reconstruction: 2.823010, Regularization: 0.819952\n",
      "2019-04-09 22:43:13,886 root         INFO     Train Epoch: 148 [4608/8000 (58%)]\tTotal Loss: 11.538030\n",
      "Reconstruction: 9.805904, Regularization: 1.732125\n",
      "2019-04-09 22:43:13,940 root         INFO     Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 3.929648\n",
      "Reconstruction: 1.701118, Regularization: 2.228530\n",
      "2019-04-09 22:43:13,995 root         INFO     Train Epoch: 148 [5632/8000 (70%)]\tTotal Loss: 1.961545\n",
      "Reconstruction: 0.945487, Regularization: 1.016058\n",
      "2019-04-09 22:43:14,049 root         INFO     Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 8.247415\n",
      "Reconstruction: 6.995630, Regularization: 1.251785\n",
      "2019-04-09 22:43:14,103 root         INFO     Train Epoch: 148 [6656/8000 (83%)]\tTotal Loss: 25.535160\n",
      "Reconstruction: 24.142593, Regularization: 1.392567\n",
      "2019-04-09 22:43:14,158 root         INFO     Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 3.403884\n",
      "Reconstruction: 1.581206, Regularization: 1.822678\n",
      "2019-04-09 22:43:14,212 root         INFO     Train Epoch: 148 [7680/8000 (96%)]\tTotal Loss: 5.436913\n",
      "Reconstruction: 3.977025, Regularization: 1.459889\n",
      "2019-04-09 22:43:14,261 root         INFO     ====> Epoch: 148 Average loss: 15.0916\n",
      "2019-04-09 22:43:14,284 root         INFO     Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 5.645060\n",
      "Reconstruction: 4.260934, Regularization: 1.384126\n",
      "2019-04-09 22:43:14,340 root         INFO     Train Epoch: 149 [512/8000 (6%)]\tTotal Loss: 10.163061\n",
      "Reconstruction: 8.922967, Regularization: 1.240094\n",
      "2019-04-09 22:43:14,395 root         INFO     Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 7.574748\n",
      "Reconstruction: 6.262599, Regularization: 1.312149\n",
      "2019-04-09 22:43:14,451 root         INFO     Train Epoch: 149 [1536/8000 (19%)]\tTotal Loss: 8.276357\n",
      "Reconstruction: 5.852933, Regularization: 2.423423\n",
      "2019-04-09 22:43:14,507 root         INFO     Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 14.043057\n",
      "Reconstruction: 12.463618, Regularization: 1.579439\n",
      "2019-04-09 22:43:14,563 root         INFO     Train Epoch: 149 [2560/8000 (32%)]\tTotal Loss: 4.994372\n",
      "Reconstruction: 4.006073, Regularization: 0.988299\n",
      "2019-04-09 22:43:14,617 root         INFO     Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 3.604057\n",
      "Reconstruction: 2.264887, Regularization: 1.339170\n",
      "2019-04-09 22:43:14,671 root         INFO     Train Epoch: 149 [3584/8000 (45%)]\tTotal Loss: 2.626213\n",
      "Reconstruction: 1.153888, Regularization: 1.472325\n",
      "2019-04-09 22:43:14,727 root         INFO     Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 3.911597\n",
      "Reconstruction: 2.183011, Regularization: 1.728586\n",
      "2019-04-09 22:43:14,783 root         INFO     Train Epoch: 149 [4608/8000 (58%)]\tTotal Loss: 3.252414\n",
      "Reconstruction: 1.667201, Regularization: 1.585213\n",
      "2019-04-09 22:43:14,838 root         INFO     Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 24.557142\n",
      "Reconstruction: 22.854965, Regularization: 1.702177\n",
      "2019-04-09 22:43:14,894 root         INFO     Train Epoch: 149 [5632/8000 (70%)]\tTotal Loss: 5.821163\n",
      "Reconstruction: 4.434190, Regularization: 1.386973\n",
      "2019-04-09 22:43:14,949 root         INFO     Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 5.575447\n",
      "Reconstruction: 4.468676, Regularization: 1.106771\n",
      "2019-04-09 22:43:15,004 root         INFO     Train Epoch: 149 [6656/8000 (83%)]\tTotal Loss: 9.971423\n",
      "Reconstruction: 8.576135, Regularization: 1.395289\n",
      "2019-04-09 22:43:15,059 root         INFO     Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 4.023932\n",
      "Reconstruction: 2.519657, Regularization: 1.504274\n",
      "2019-04-09 22:43:15,115 root         INFO     Train Epoch: 149 [7680/8000 (96%)]\tTotal Loss: 3.724958\n",
      "Reconstruction: 2.461971, Regularization: 1.262987\n",
      "2019-04-09 22:43:15,164 root         INFO     ====> Epoch: 149 Average loss: 13.7415\n",
      "2019-04-09 22:43:15,187 root         INFO     Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 11.861637\n",
      "Reconstruction: 10.157612, Regularization: 1.704025\n",
      "2019-04-09 22:43:15,243 root         INFO     Train Epoch: 150 [512/8000 (6%)]\tTotal Loss: 247.747711\n",
      "Reconstruction: 245.762726, Regularization: 1.984983\n",
      "2019-04-09 22:43:15,298 root         INFO     Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 10.091332\n",
      "Reconstruction: 8.380172, Regularization: 1.711161\n",
      "2019-04-09 22:43:15,352 root         INFO     Train Epoch: 150 [1536/8000 (19%)]\tTotal Loss: 16.833725\n",
      "Reconstruction: 14.593504, Regularization: 2.240220\n",
      "2019-04-09 22:43:15,406 root         INFO     Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 8.953875\n",
      "Reconstruction: 6.971397, Regularization: 1.982478\n",
      "2019-04-09 22:43:15,462 root         INFO     Train Epoch: 150 [2560/8000 (32%)]\tTotal Loss: 7.856652\n",
      "Reconstruction: 6.472081, Regularization: 1.384571\n",
      "2019-04-09 22:43:15,517 root         INFO     Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 4.826465\n",
      "Reconstruction: 3.544117, Regularization: 1.282348\n",
      "2019-04-09 22:43:15,572 root         INFO     Train Epoch: 150 [3584/8000 (45%)]\tTotal Loss: 9.586263\n",
      "Reconstruction: 8.145879, Regularization: 1.440384\n",
      "2019-04-09 22:43:15,628 root         INFO     Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 10.217600\n",
      "Reconstruction: 8.850401, Regularization: 1.367199\n",
      "2019-04-09 22:43:15,683 root         INFO     Train Epoch: 150 [4608/8000 (58%)]\tTotal Loss: 2.521893\n",
      "Reconstruction: 1.197903, Regularization: 1.323990\n",
      "2019-04-09 22:43:15,739 root         INFO     Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 5.941138\n",
      "Reconstruction: 3.318091, Regularization: 2.623048\n",
      "2019-04-09 22:43:15,794 root         INFO     Train Epoch: 150 [5632/8000 (70%)]\tTotal Loss: 11.543905\n",
      "Reconstruction: 10.147079, Regularization: 1.396825\n",
      "2019-04-09 22:43:15,850 root         INFO     Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 19.462631\n",
      "Reconstruction: 17.461239, Regularization: 2.001393\n",
      "2019-04-09 22:43:15,905 root         INFO     Train Epoch: 150 [6656/8000 (83%)]\tTotal Loss: 4.318404\n",
      "Reconstruction: 2.074191, Regularization: 2.244213\n",
      "2019-04-09 22:43:15,961 root         INFO     Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 6.669065\n",
      "Reconstruction: 4.473983, Regularization: 2.195083\n",
      "2019-04-09 22:43:16,016 root         INFO     Train Epoch: 150 [7680/8000 (96%)]\tTotal Loss: 5.331625\n",
      "Reconstruction: 3.769328, Regularization: 1.562297\n",
      "2019-04-09 22:43:16,065 root         INFO     ====> Epoch: 150 Average loss: 12.4377\n",
      "2019-04-09 22:43:16,088 root         INFO     Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 15.318121\n",
      "Reconstruction: 13.648258, Regularization: 1.669863\n",
      "2019-04-09 22:43:16,143 root         INFO     Train Epoch: 151 [512/8000 (6%)]\tTotal Loss: 12.779265\n",
      "Reconstruction: 10.964390, Regularization: 1.814876\n",
      "2019-04-09 22:43:16,198 root         INFO     Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 12.398085\n",
      "Reconstruction: 11.261038, Regularization: 1.137047\n",
      "2019-04-09 22:43:16,253 root         INFO     Train Epoch: 151 [1536/8000 (19%)]\tTotal Loss: 2.148533\n",
      "Reconstruction: 0.678893, Regularization: 1.469641\n",
      "2019-04-09 22:43:16,307 root         INFO     Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 32.937820\n",
      "Reconstruction: 31.160908, Regularization: 1.776911\n",
      "2019-04-09 22:43:16,361 root         INFO     Train Epoch: 151 [2560/8000 (32%)]\tTotal Loss: 2.104516\n",
      "Reconstruction: 0.957787, Regularization: 1.146729\n",
      "2019-04-09 22:43:16,416 root         INFO     Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 2.543448\n",
      "Reconstruction: 0.999940, Regularization: 1.543508\n",
      "2019-04-09 22:43:16,471 root         INFO     Train Epoch: 151 [3584/8000 (45%)]\tTotal Loss: 7.722845\n",
      "Reconstruction: 6.095107, Regularization: 1.627738\n",
      "2019-04-09 22:43:16,525 root         INFO     Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 46.915775\n",
      "Reconstruction: 44.706497, Regularization: 2.209277\n",
      "2019-04-09 22:43:16,579 root         INFO     Train Epoch: 151 [4608/8000 (58%)]\tTotal Loss: 4.370461\n",
      "Reconstruction: 3.246180, Regularization: 1.124280\n",
      "2019-04-09 22:43:16,633 root         INFO     Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 8.918932\n",
      "Reconstruction: 7.994606, Regularization: 0.924325\n",
      "2019-04-09 22:43:16,687 root         INFO     Train Epoch: 151 [5632/8000 (70%)]\tTotal Loss: 3.558275\n",
      "Reconstruction: 2.129978, Regularization: 1.428297\n",
      "2019-04-09 22:43:16,741 root         INFO     Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 7.250912\n",
      "Reconstruction: 5.178602, Regularization: 2.072310\n",
      "2019-04-09 22:43:16,795 root         INFO     Train Epoch: 151 [6656/8000 (83%)]\tTotal Loss: 89.884087\n",
      "Reconstruction: 88.308937, Regularization: 1.575153\n",
      "2019-04-09 22:43:16,849 root         INFO     Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 4.636863\n",
      "Reconstruction: 3.758517, Regularization: 0.878346\n",
      "2019-04-09 22:43:16,904 root         INFO     Train Epoch: 151 [7680/8000 (96%)]\tTotal Loss: 2.592024\n",
      "Reconstruction: 0.714100, Regularization: 1.877924\n",
      "2019-04-09 22:43:16,952 root         INFO     ====> Epoch: 151 Average loss: 14.4211\n",
      "2019-04-09 22:43:16,975 root         INFO     Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 9.561746\n",
      "Reconstruction: 8.168840, Regularization: 1.392905\n",
      "2019-04-09 22:43:17,030 root         INFO     Train Epoch: 152 [512/8000 (6%)]\tTotal Loss: 1.886311\n",
      "Reconstruction: 0.841905, Regularization: 1.044407\n",
      "2019-04-09 22:43:17,085 root         INFO     Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 3.939322\n",
      "Reconstruction: 2.250750, Regularization: 1.688572\n",
      "2019-04-09 22:43:17,140 root         INFO     Train Epoch: 152 [1536/8000 (19%)]\tTotal Loss: 102.525726\n",
      "Reconstruction: 100.822708, Regularization: 1.703015\n",
      "2019-04-09 22:43:17,194 root         INFO     Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 39.269905\n",
      "Reconstruction: 36.856373, Regularization: 2.413533\n",
      "2019-04-09 22:43:17,249 root         INFO     Train Epoch: 152 [2560/8000 (32%)]\tTotal Loss: 3.069385\n",
      "Reconstruction: 1.044384, Regularization: 2.025001\n",
      "2019-04-09 22:43:17,303 root         INFO     Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 3.252070\n",
      "Reconstruction: 2.143404, Regularization: 1.108667\n",
      "2019-04-09 22:43:17,358 root         INFO     Train Epoch: 152 [3584/8000 (45%)]\tTotal Loss: 2.199100\n",
      "Reconstruction: 0.412522, Regularization: 1.786578\n",
      "2019-04-09 22:43:17,413 root         INFO     Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 2.148976\n",
      "Reconstruction: 0.815735, Regularization: 1.333241\n",
      "2019-04-09 22:43:17,468 root         INFO     Train Epoch: 152 [4608/8000 (58%)]\tTotal Loss: 7.610660\n",
      "Reconstruction: 6.492839, Regularization: 1.117821\n",
      "2019-04-09 22:43:17,522 root         INFO     Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 5.680114\n",
      "Reconstruction: 4.072833, Regularization: 1.607282\n",
      "2019-04-09 22:43:17,577 root         INFO     Train Epoch: 152 [5632/8000 (70%)]\tTotal Loss: 22.401417\n",
      "Reconstruction: 20.395304, Regularization: 2.006114\n",
      "2019-04-09 22:43:17,632 root         INFO     Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 2.620913\n",
      "Reconstruction: 0.839997, Regularization: 1.780916\n",
      "2019-04-09 22:43:17,686 root         INFO     Train Epoch: 152 [6656/8000 (83%)]\tTotal Loss: 2.193151\n",
      "Reconstruction: 0.839510, Regularization: 1.353642\n",
      "2019-04-09 22:43:17,741 root         INFO     Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 3.131344\n",
      "Reconstruction: 1.486407, Regularization: 1.644937\n",
      "2019-04-09 22:43:17,796 root         INFO     Train Epoch: 152 [7680/8000 (96%)]\tTotal Loss: 4.861469\n",
      "Reconstruction: 2.686207, Regularization: 2.175262\n",
      "2019-04-09 22:43:17,845 root         INFO     ====> Epoch: 152 Average loss: 11.5621\n",
      "2019-04-09 22:43:17,868 root         INFO     Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 2.975277\n",
      "Reconstruction: 1.167128, Regularization: 1.808150\n",
      "2019-04-09 22:43:17,924 root         INFO     Train Epoch: 153 [512/8000 (6%)]\tTotal Loss: 2.835239\n",
      "Reconstruction: 1.680316, Regularization: 1.154923\n",
      "2019-04-09 22:43:17,980 root         INFO     Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 5.707205\n",
      "Reconstruction: 4.461131, Regularization: 1.246074\n",
      "2019-04-09 22:43:18,036 root         INFO     Train Epoch: 153 [1536/8000 (19%)]\tTotal Loss: 3.537041\n",
      "Reconstruction: 1.929898, Regularization: 1.607143\n",
      "2019-04-09 22:43:18,092 root         INFO     Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 7.890883\n",
      "Reconstruction: 6.146146, Regularization: 1.744737\n",
      "2019-04-09 22:43:18,148 root         INFO     Train Epoch: 153 [2560/8000 (32%)]\tTotal Loss: 2.023727\n",
      "Reconstruction: 0.938269, Regularization: 1.085458\n",
      "2019-04-09 22:43:18,205 root         INFO     Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 2.008936\n",
      "Reconstruction: 0.832948, Regularization: 1.175988\n",
      "2019-04-09 22:43:18,261 root         INFO     Train Epoch: 153 [3584/8000 (45%)]\tTotal Loss: 7.805961\n",
      "Reconstruction: 6.203835, Regularization: 1.602125\n",
      "2019-04-09 22:43:18,323 root         INFO     Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 3.831371\n",
      "Reconstruction: 1.776575, Regularization: 2.054795\n",
      "2019-04-09 22:43:18,383 root         INFO     Train Epoch: 153 [4608/8000 (58%)]\tTotal Loss: 4.872106\n",
      "Reconstruction: 3.029480, Regularization: 1.842626\n",
      "2019-04-09 22:43:18,443 root         INFO     Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 10.931754\n",
      "Reconstruction: 9.665167, Regularization: 1.266587\n",
      "2019-04-09 22:43:18,508 root         INFO     Train Epoch: 153 [5632/8000 (70%)]\tTotal Loss: 9.652572\n",
      "Reconstruction: 8.083990, Regularization: 1.568581\n",
      "2019-04-09 22:43:18,566 root         INFO     Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 3.663252\n",
      "Reconstruction: 2.458215, Regularization: 1.205036\n",
      "2019-04-09 22:43:18,624 root         INFO     Train Epoch: 153 [6656/8000 (83%)]\tTotal Loss: 2.592747\n",
      "Reconstruction: 0.696528, Regularization: 1.896219\n",
      "2019-04-09 22:43:18,682 root         INFO     Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 12.427544\n",
      "Reconstruction: 10.952237, Regularization: 1.475307\n",
      "2019-04-09 22:43:18,740 root         INFO     Train Epoch: 153 [7680/8000 (96%)]\tTotal Loss: 37.542477\n",
      "Reconstruction: 35.782928, Regularization: 1.759549\n",
      "2019-04-09 22:43:18,790 root         INFO     ====> Epoch: 153 Average loss: 10.0227\n",
      "2019-04-09 22:43:18,813 root         INFO     Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 3.006340\n",
      "Reconstruction: 1.677599, Regularization: 1.328741\n",
      "2019-04-09 22:43:18,870 root         INFO     Train Epoch: 154 [512/8000 (6%)]\tTotal Loss: 2.991628\n",
      "Reconstruction: 1.628497, Regularization: 1.363131\n",
      "2019-04-09 22:43:18,926 root         INFO     Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 5.501238\n",
      "Reconstruction: 3.405090, Regularization: 2.096148\n",
      "2019-04-09 22:43:18,982 root         INFO     Train Epoch: 154 [1536/8000 (19%)]\tTotal Loss: 7.566144\n",
      "Reconstruction: 5.589724, Regularization: 1.976419\n",
      "2019-04-09 22:43:19,038 root         INFO     Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 2.076948\n",
      "Reconstruction: 1.119400, Regularization: 0.957548\n",
      "2019-04-09 22:43:19,093 root         INFO     Train Epoch: 154 [2560/8000 (32%)]\tTotal Loss: 4.323130\n",
      "Reconstruction: 3.180819, Regularization: 1.142311\n",
      "2019-04-09 22:43:19,149 root         INFO     Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 2.345952\n",
      "Reconstruction: 1.297922, Regularization: 1.048029\n",
      "2019-04-09 22:43:19,205 root         INFO     Train Epoch: 154 [3584/8000 (45%)]\tTotal Loss: 34.445358\n",
      "Reconstruction: 33.304428, Regularization: 1.140930\n",
      "2019-04-09 22:43:19,261 root         INFO     Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 3.467990\n",
      "Reconstruction: 2.456419, Regularization: 1.011571\n",
      "2019-04-09 22:43:19,317 root         INFO     Train Epoch: 154 [4608/8000 (58%)]\tTotal Loss: 4.317897\n",
      "Reconstruction: 3.199908, Regularization: 1.117989\n",
      "2019-04-09 22:43:19,372 root         INFO     Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 2.177895\n",
      "Reconstruction: 0.491681, Regularization: 1.686214\n",
      "2019-04-09 22:43:19,428 root         INFO     Train Epoch: 154 [5632/8000 (70%)]\tTotal Loss: 15.327137\n",
      "Reconstruction: 14.051665, Regularization: 1.275471\n",
      "2019-04-09 22:43:19,484 root         INFO     Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 1.354003\n",
      "Reconstruction: 0.470083, Regularization: 0.883920\n",
      "2019-04-09 22:43:19,540 root         INFO     Train Epoch: 154 [6656/8000 (83%)]\tTotal Loss: 4.677852\n",
      "Reconstruction: 3.345958, Regularization: 1.331894\n",
      "2019-04-09 22:43:19,596 root         INFO     Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 6.921188\n",
      "Reconstruction: 5.296542, Regularization: 1.624646\n",
      "2019-04-09 22:43:19,652 root         INFO     Train Epoch: 154 [7680/8000 (96%)]\tTotal Loss: 2.692498\n",
      "Reconstruction: 1.426056, Regularization: 1.266442\n",
      "2019-04-09 22:43:19,701 root         INFO     ====> Epoch: 154 Average loss: 9.0493\n",
      "2019-04-09 22:43:19,724 root         INFO     Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 3.155584\n",
      "Reconstruction: 1.361595, Regularization: 1.793989\n",
      "2019-04-09 22:43:19,780 root         INFO     Train Epoch: 155 [512/8000 (6%)]\tTotal Loss: 1.183285\n",
      "Reconstruction: 0.301112, Regularization: 0.882173\n",
      "2019-04-09 22:43:19,836 root         INFO     Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 3.171167\n",
      "Reconstruction: 1.519926, Regularization: 1.651240\n",
      "2019-04-09 22:43:19,892 root         INFO     Train Epoch: 155 [1536/8000 (19%)]\tTotal Loss: 1.544025\n",
      "Reconstruction: 0.819580, Regularization: 0.724445\n",
      "2019-04-09 22:43:19,948 root         INFO     Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 7.884118\n",
      "Reconstruction: 5.579156, Regularization: 2.304962\n",
      "2019-04-09 22:43:20,004 root         INFO     Train Epoch: 155 [2560/8000 (32%)]\tTotal Loss: 5.808047\n",
      "Reconstruction: 4.374909, Regularization: 1.433138\n",
      "2019-04-09 22:43:20,061 root         INFO     Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 2.620139\n",
      "Reconstruction: 0.771539, Regularization: 1.848600\n",
      "2019-04-09 22:43:20,117 root         INFO     Train Epoch: 155 [3584/8000 (45%)]\tTotal Loss: 2.421994\n",
      "Reconstruction: 1.033313, Regularization: 1.388681\n",
      "2019-04-09 22:43:20,173 root         INFO     Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 7.253623\n",
      "Reconstruction: 6.189419, Regularization: 1.064204\n",
      "2019-04-09 22:43:20,229 root         INFO     Train Epoch: 155 [4608/8000 (58%)]\tTotal Loss: 2.693485\n",
      "Reconstruction: 1.543176, Regularization: 1.150309\n",
      "2019-04-09 22:43:20,285 root         INFO     Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 6.735471\n",
      "Reconstruction: 4.425040, Regularization: 2.310431\n",
      "2019-04-09 22:43:20,342 root         INFO     Train Epoch: 155 [5632/8000 (70%)]\tTotal Loss: 4.050470\n",
      "Reconstruction: 2.707769, Regularization: 1.342702\n",
      "2019-04-09 22:43:20,398 root         INFO     Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 2.739934\n",
      "Reconstruction: 1.326752, Regularization: 1.413182\n",
      "2019-04-09 22:43:20,454 root         INFO     Train Epoch: 155 [6656/8000 (83%)]\tTotal Loss: 4.200969\n",
      "Reconstruction: 2.814777, Regularization: 1.386192\n",
      "2019-04-09 22:43:20,510 root         INFO     Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 39.384369\n",
      "Reconstruction: 37.729145, Regularization: 1.655225\n",
      "2019-04-09 22:43:20,566 root         INFO     Train Epoch: 155 [7680/8000 (96%)]\tTotal Loss: 3.055722\n",
      "Reconstruction: 1.327083, Regularization: 1.728639\n",
      "2019-04-09 22:43:20,616 root         INFO     ====> Epoch: 155 Average loss: 8.3003\n",
      "2019-04-09 22:43:20,639 root         INFO     Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 34.834251\n",
      "Reconstruction: 33.049816, Regularization: 1.784436\n",
      "2019-04-09 22:43:20,695 root         INFO     Train Epoch: 156 [512/8000 (6%)]\tTotal Loss: 12.645046\n",
      "Reconstruction: 10.789565, Regularization: 1.855482\n",
      "2019-04-09 22:43:20,751 root         INFO     Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 2.110406\n",
      "Reconstruction: 0.631139, Regularization: 1.479266\n",
      "2019-04-09 22:43:20,807 root         INFO     Train Epoch: 156 [1536/8000 (19%)]\tTotal Loss: 5.421987\n",
      "Reconstruction: 4.111118, Regularization: 1.310868\n",
      "2019-04-09 22:43:20,863 root         INFO     Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 2.624987\n",
      "Reconstruction: 1.047130, Regularization: 1.577857\n",
      "2019-04-09 22:43:20,918 root         INFO     Train Epoch: 156 [2560/8000 (32%)]\tTotal Loss: 106.757591\n",
      "Reconstruction: 105.333672, Regularization: 1.423917\n",
      "2019-04-09 22:43:20,974 root         INFO     Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 4.072888\n",
      "Reconstruction: 2.437757, Regularization: 1.635132\n",
      "2019-04-09 22:43:21,029 root         INFO     Train Epoch: 156 [3584/8000 (45%)]\tTotal Loss: 3.231148\n",
      "Reconstruction: 2.028691, Regularization: 1.202457\n",
      "2019-04-09 22:43:21,085 root         INFO     Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 1.862720\n",
      "Reconstruction: 0.614102, Regularization: 1.248617\n",
      "2019-04-09 22:43:21,141 root         INFO     Train Epoch: 156 [4608/8000 (58%)]\tTotal Loss: 2.907625\n",
      "Reconstruction: 1.396312, Regularization: 1.511312\n",
      "2019-04-09 22:43:21,197 root         INFO     Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 4.398855\n",
      "Reconstruction: 2.099521, Regularization: 2.299334\n",
      "2019-04-09 22:43:21,253 root         INFO     Train Epoch: 156 [5632/8000 (70%)]\tTotal Loss: 2.796980\n",
      "Reconstruction: 0.795930, Regularization: 2.001050\n",
      "2019-04-09 22:43:21,309 root         INFO     Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 10.595518\n",
      "Reconstruction: 9.146973, Regularization: 1.448546\n",
      "2019-04-09 22:43:21,365 root         INFO     Train Epoch: 156 [6656/8000 (83%)]\tTotal Loss: 7.147765\n",
      "Reconstruction: 5.635317, Regularization: 1.512448\n",
      "2019-04-09 22:43:21,421 root         INFO     Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 2.911309\n",
      "Reconstruction: 1.852725, Regularization: 1.058584\n",
      "2019-04-09 22:43:21,478 root         INFO     Train Epoch: 156 [7680/8000 (96%)]\tTotal Loss: 7.794858\n",
      "Reconstruction: 6.144566, Regularization: 1.650292\n",
      "2019-04-09 22:43:21,527 root         INFO     ====> Epoch: 156 Average loss: 7.8507\n",
      "2019-04-09 22:43:21,550 root         INFO     Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 1.742860\n",
      "Reconstruction: 0.816525, Regularization: 0.926335\n",
      "2019-04-09 22:43:21,606 root         INFO     Train Epoch: 157 [512/8000 (6%)]\tTotal Loss: 5.179527\n",
      "Reconstruction: 3.990509, Regularization: 1.189018\n",
      "2019-04-09 22:43:21,662 root         INFO     Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 2.716088\n",
      "Reconstruction: 1.424615, Regularization: 1.291472\n",
      "2019-04-09 22:43:21,718 root         INFO     Train Epoch: 157 [1536/8000 (19%)]\tTotal Loss: 2.963354\n",
      "Reconstruction: 1.734489, Regularization: 1.228865\n",
      "2019-04-09 22:43:21,773 root         INFO     Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 64.086205\n",
      "Reconstruction: 61.334366, Regularization: 2.751838\n",
      "2019-04-09 22:43:21,828 root         INFO     Train Epoch: 157 [2560/8000 (32%)]\tTotal Loss: 1.924736\n",
      "Reconstruction: 1.076652, Regularization: 0.848083\n",
      "2019-04-09 22:43:21,882 root         INFO     Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 1.938429\n",
      "Reconstruction: 0.757614, Regularization: 1.180815\n",
      "2019-04-09 22:43:21,936 root         INFO     Train Epoch: 157 [3584/8000 (45%)]\tTotal Loss: 5.373852\n",
      "Reconstruction: 4.044828, Regularization: 1.329024\n",
      "2019-04-09 22:43:21,990 root         INFO     Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 3.340595\n",
      "Reconstruction: 1.927497, Regularization: 1.413098\n",
      "2019-04-09 22:43:22,044 root         INFO     Train Epoch: 157 [4608/8000 (58%)]\tTotal Loss: 1.599438\n",
      "Reconstruction: 0.586100, Regularization: 1.013338\n",
      "2019-04-09 22:43:22,098 root         INFO     Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 3.187742\n",
      "Reconstruction: 1.765793, Regularization: 1.421949\n",
      "2019-04-09 22:43:22,152 root         INFO     Train Epoch: 157 [5632/8000 (70%)]\tTotal Loss: 8.879336\n",
      "Reconstruction: 7.194099, Regularization: 1.685237\n",
      "2019-04-09 22:43:22,206 root         INFO     Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 1.925215\n",
      "Reconstruction: 0.381928, Regularization: 1.543287\n",
      "2019-04-09 22:43:22,260 root         INFO     Train Epoch: 157 [6656/8000 (83%)]\tTotal Loss: 2.053429\n",
      "Reconstruction: 0.610625, Regularization: 1.442804\n",
      "2019-04-09 22:43:22,314 root         INFO     Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 5.412230\n",
      "Reconstruction: 3.977757, Regularization: 1.434474\n",
      "2019-04-09 22:43:22,368 root         INFO     Train Epoch: 157 [7680/8000 (96%)]\tTotal Loss: 6.995449\n",
      "Reconstruction: 5.349349, Regularization: 1.646099\n",
      "2019-04-09 22:43:22,418 root         INFO     ====> Epoch: 157 Average loss: 7.2782\n",
      "2019-04-09 22:43:22,441 root         INFO     Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 5.947176\n",
      "Reconstruction: 3.946754, Regularization: 2.000421\n",
      "2019-04-09 22:43:22,498 root         INFO     Train Epoch: 158 [512/8000 (6%)]\tTotal Loss: 14.810010\n",
      "Reconstruction: 12.810815, Regularization: 1.999195\n",
      "2019-04-09 22:43:22,554 root         INFO     Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 1.533800\n",
      "Reconstruction: 0.533741, Regularization: 1.000058\n",
      "2019-04-09 22:43:22,609 root         INFO     Train Epoch: 158 [1536/8000 (19%)]\tTotal Loss: 18.338907\n",
      "Reconstruction: 16.807138, Regularization: 1.531768\n",
      "2019-04-09 22:43:22,664 root         INFO     Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 63.358608\n",
      "Reconstruction: 61.671780, Regularization: 1.686827\n",
      "2019-04-09 22:43:22,719 root         INFO     Train Epoch: 158 [2560/8000 (32%)]\tTotal Loss: 8.446283\n",
      "Reconstruction: 6.824994, Regularization: 1.621290\n",
      "2019-04-09 22:43:22,774 root         INFO     Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 4.218846\n",
      "Reconstruction: 2.856833, Regularization: 1.362013\n",
      "2019-04-09 22:43:22,829 root         INFO     Train Epoch: 158 [3584/8000 (45%)]\tTotal Loss: 5.017613\n",
      "Reconstruction: 3.233069, Regularization: 1.784544\n",
      "2019-04-09 22:43:22,884 root         INFO     Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 2.594829\n",
      "Reconstruction: 0.919442, Regularization: 1.675387\n",
      "2019-04-09 22:43:22,940 root         INFO     Train Epoch: 158 [4608/8000 (58%)]\tTotal Loss: 14.789298\n",
      "Reconstruction: 13.567504, Regularization: 1.221794\n",
      "2019-04-09 22:43:22,994 root         INFO     Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 3.331406\n",
      "Reconstruction: 2.098941, Regularization: 1.232465\n",
      "2019-04-09 22:43:23,049 root         INFO     Train Epoch: 158 [5632/8000 (70%)]\tTotal Loss: 3.193807\n",
      "Reconstruction: 2.048224, Regularization: 1.145583\n",
      "2019-04-09 22:43:23,104 root         INFO     Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 2.572558\n",
      "Reconstruction: 1.225484, Regularization: 1.347074\n",
      "2019-04-09 22:43:23,158 root         INFO     Train Epoch: 158 [6656/8000 (83%)]\tTotal Loss: 2.486704\n",
      "Reconstruction: 1.342248, Regularization: 1.144456\n",
      "2019-04-09 22:43:23,212 root         INFO     Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 2.611188\n",
      "Reconstruction: 0.840130, Regularization: 1.771058\n",
      "2019-04-09 22:43:23,265 root         INFO     Train Epoch: 158 [7680/8000 (96%)]\tTotal Loss: 1.438897\n",
      "Reconstruction: 0.494902, Regularization: 0.943995\n",
      "2019-04-09 22:43:23,313 root         INFO     ====> Epoch: 158 Average loss: 6.6113\n",
      "2019-04-09 22:43:23,336 root         INFO     Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 5.121084\n",
      "Reconstruction: 3.530083, Regularization: 1.591001\n",
      "2019-04-09 22:43:23,393 root         INFO     Train Epoch: 159 [512/8000 (6%)]\tTotal Loss: 3.646757\n",
      "Reconstruction: 1.646755, Regularization: 2.000002\n",
      "2019-04-09 22:43:23,449 root         INFO     Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 1.786412\n",
      "Reconstruction: 0.331129, Regularization: 1.455283\n",
      "2019-04-09 22:43:23,505 root         INFO     Train Epoch: 159 [1536/8000 (19%)]\tTotal Loss: 6.004478\n",
      "Reconstruction: 3.856941, Regularization: 2.147537\n",
      "2019-04-09 22:43:23,561 root         INFO     Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 1.593609\n",
      "Reconstruction: 0.655662, Regularization: 0.937947\n",
      "2019-04-09 22:43:23,617 root         INFO     Train Epoch: 159 [2560/8000 (32%)]\tTotal Loss: 2.398507\n",
      "Reconstruction: 1.187557, Regularization: 1.210950\n",
      "2019-04-09 22:43:23,674 root         INFO     Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 2.633217\n",
      "Reconstruction: 1.559919, Regularization: 1.073298\n",
      "2019-04-09 22:43:23,730 root         INFO     Train Epoch: 159 [3584/8000 (45%)]\tTotal Loss: 2.488064\n",
      "Reconstruction: 1.109078, Regularization: 1.378986\n",
      "2019-04-09 22:43:23,786 root         INFO     Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 9.856560\n",
      "Reconstruction: 8.433059, Regularization: 1.423501\n",
      "2019-04-09 22:43:23,843 root         INFO     Train Epoch: 159 [4608/8000 (58%)]\tTotal Loss: 4.191760\n",
      "Reconstruction: 2.489936, Regularization: 1.701824\n",
      "2019-04-09 22:43:23,899 root         INFO     Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 17.374353\n",
      "Reconstruction: 16.401205, Regularization: 0.973148\n",
      "2019-04-09 22:43:23,955 root         INFO     Train Epoch: 159 [5632/8000 (70%)]\tTotal Loss: 16.537167\n",
      "Reconstruction: 15.062497, Regularization: 1.474669\n",
      "2019-04-09 22:43:24,011 root         INFO     Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 4.053366\n",
      "Reconstruction: 2.679554, Regularization: 1.373811\n",
      "2019-04-09 22:43:24,067 root         INFO     Train Epoch: 159 [6656/8000 (83%)]\tTotal Loss: 6.098135\n",
      "Reconstruction: 4.770278, Regularization: 1.327857\n",
      "2019-04-09 22:43:24,124 root         INFO     Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 20.875147\n",
      "Reconstruction: 19.324409, Regularization: 1.550737\n",
      "2019-04-09 22:43:24,180 root         INFO     Train Epoch: 159 [7680/8000 (96%)]\tTotal Loss: 2.278387\n",
      "Reconstruction: 0.660662, Regularization: 1.617725\n",
      "2019-04-09 22:43:24,229 root         INFO     ====> Epoch: 159 Average loss: 6.1810\n",
      "2019-04-09 22:43:24,252 root         INFO     Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 3.580586\n",
      "Reconstruction: 2.046867, Regularization: 1.533719\n",
      "2019-04-09 22:43:24,308 root         INFO     Train Epoch: 160 [512/8000 (6%)]\tTotal Loss: 2.013212\n",
      "Reconstruction: 0.518960, Regularization: 1.494252\n",
      "2019-04-09 22:43:24,363 root         INFO     Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 2.251931\n",
      "Reconstruction: 1.021471, Regularization: 1.230460\n",
      "2019-04-09 22:43:24,418 root         INFO     Train Epoch: 160 [1536/8000 (19%)]\tTotal Loss: 3.797761\n",
      "Reconstruction: 2.254189, Regularization: 1.543572\n",
      "2019-04-09 22:43:24,474 root         INFO     Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 31.657627\n",
      "Reconstruction: 29.915386, Regularization: 1.742241\n",
      "2019-04-09 22:43:24,530 root         INFO     Train Epoch: 160 [2560/8000 (32%)]\tTotal Loss: 86.993179\n",
      "Reconstruction: 85.248749, Regularization: 1.744430\n",
      "2019-04-09 22:43:24,585 root         INFO     Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 2.415528\n",
      "Reconstruction: 1.098139, Regularization: 1.317389\n",
      "2019-04-09 22:43:24,641 root         INFO     Train Epoch: 160 [3584/8000 (45%)]\tTotal Loss: 1.616630\n",
      "Reconstruction: 0.596820, Regularization: 1.019811\n",
      "2019-04-09 22:43:24,696 root         INFO     Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 1.748091\n",
      "Reconstruction: 0.591391, Regularization: 1.156700\n",
      "2019-04-09 22:43:24,751 root         INFO     Train Epoch: 160 [4608/8000 (58%)]\tTotal Loss: 2.715091\n",
      "Reconstruction: 0.992602, Regularization: 1.722489\n",
      "2019-04-09 22:43:24,807 root         INFO     Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 3.233290\n",
      "Reconstruction: 2.058611, Regularization: 1.174679\n",
      "2019-04-09 22:43:24,862 root         INFO     Train Epoch: 160 [5632/8000 (70%)]\tTotal Loss: 12.191081\n",
      "Reconstruction: 10.325842, Regularization: 1.865240\n",
      "2019-04-09 22:43:24,918 root         INFO     Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 2.101636\n",
      "Reconstruction: 1.250533, Regularization: 0.851103\n",
      "2019-04-09 22:43:24,973 root         INFO     Train Epoch: 160 [6656/8000 (83%)]\tTotal Loss: 2.113842\n",
      "Reconstruction: 1.089762, Regularization: 1.024080\n",
      "2019-04-09 22:43:25,029 root         INFO     Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 14.560680\n",
      "Reconstruction: 12.385810, Regularization: 2.174870\n",
      "2019-04-09 22:43:25,084 root         INFO     Train Epoch: 160 [7680/8000 (96%)]\tTotal Loss: 4.083081\n",
      "Reconstruction: 2.662375, Regularization: 1.420706\n",
      "2019-04-09 22:43:25,133 root         INFO     ====> Epoch: 160 Average loss: 5.5886\n",
      "2019-04-09 22:43:25,156 root         INFO     Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 1.635452\n",
      "Reconstruction: 0.175516, Regularization: 1.459936\n",
      "2019-04-09 22:43:25,213 root         INFO     Train Epoch: 161 [512/8000 (6%)]\tTotal Loss: 4.897608\n",
      "Reconstruction: 3.636739, Regularization: 1.260869\n",
      "2019-04-09 22:43:25,269 root         INFO     Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 3.126719\n",
      "Reconstruction: 1.454143, Regularization: 1.672575\n",
      "2019-04-09 22:43:25,325 root         INFO     Train Epoch: 161 [1536/8000 (19%)]\tTotal Loss: 8.351524\n",
      "Reconstruction: 5.803627, Regularization: 2.547898\n",
      "2019-04-09 22:43:25,381 root         INFO     Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 2.381806\n",
      "Reconstruction: 1.170528, Regularization: 1.211279\n",
      "2019-04-09 22:43:25,437 root         INFO     Train Epoch: 161 [2560/8000 (32%)]\tTotal Loss: 1.786452\n",
      "Reconstruction: 0.914814, Regularization: 0.871638\n",
      "2019-04-09 22:43:25,494 root         INFO     Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 3.352229\n",
      "Reconstruction: 1.979487, Regularization: 1.372742\n",
      "2019-04-09 22:43:25,550 root         INFO     Train Epoch: 161 [3584/8000 (45%)]\tTotal Loss: 3.149191\n",
      "Reconstruction: 1.946921, Regularization: 1.202269\n",
      "2019-04-09 22:43:25,606 root         INFO     Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 2.028901\n",
      "Reconstruction: 0.847128, Regularization: 1.181773\n",
      "2019-04-09 22:43:25,662 root         INFO     Train Epoch: 161 [4608/8000 (58%)]\tTotal Loss: 3.162022\n",
      "Reconstruction: 1.659753, Regularization: 1.502269\n",
      "2019-04-09 22:43:25,717 root         INFO     Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 3.068494\n",
      "Reconstruction: 1.385445, Regularization: 1.683049\n",
      "2019-04-09 22:43:25,773 root         INFO     Train Epoch: 161 [5632/8000 (70%)]\tTotal Loss: 4.470519\n",
      "Reconstruction: 3.155135, Regularization: 1.315384\n",
      "2019-04-09 22:43:25,829 root         INFO     Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 6.712301\n",
      "Reconstruction: 4.761502, Regularization: 1.950799\n",
      "2019-04-09 22:43:25,885 root         INFO     Train Epoch: 161 [6656/8000 (83%)]\tTotal Loss: 1.548621\n",
      "Reconstruction: 0.337205, Regularization: 1.211416\n",
      "2019-04-09 22:43:25,941 root         INFO     Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 9.612349\n",
      "Reconstruction: 8.111448, Regularization: 1.500900\n",
      "2019-04-09 22:43:25,997 root         INFO     Train Epoch: 161 [7680/8000 (96%)]\tTotal Loss: 1.830329\n",
      "Reconstruction: 0.870037, Regularization: 0.960292\n",
      "2019-04-09 22:43:26,047 root         INFO     ====> Epoch: 161 Average loss: 5.0758\n",
      "2019-04-09 22:43:26,070 root         INFO     Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 2.065483\n",
      "Reconstruction: 0.812344, Regularization: 1.253139\n",
      "2019-04-09 22:43:26,127 root         INFO     Train Epoch: 162 [512/8000 (6%)]\tTotal Loss: 2.711638\n",
      "Reconstruction: 0.808877, Regularization: 1.902761\n",
      "2019-04-09 22:43:26,183 root         INFO     Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 2.691744\n",
      "Reconstruction: 1.480379, Regularization: 1.211365\n",
      "2019-04-09 22:43:26,239 root         INFO     Train Epoch: 162 [1536/8000 (19%)]\tTotal Loss: 2.419353\n",
      "Reconstruction: 0.666853, Regularization: 1.752500\n",
      "2019-04-09 22:43:26,295 root         INFO     Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 1.256762\n",
      "Reconstruction: 0.203570, Regularization: 1.053191\n",
      "2019-04-09 22:43:26,352 root         INFO     Train Epoch: 162 [2560/8000 (32%)]\tTotal Loss: 3.157214\n",
      "Reconstruction: 1.627415, Regularization: 1.529799\n",
      "2019-04-09 22:43:26,408 root         INFO     Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 2.014867\n",
      "Reconstruction: 0.499064, Regularization: 1.515803\n",
      "2019-04-09 22:43:26,464 root         INFO     Train Epoch: 162 [3584/8000 (45%)]\tTotal Loss: 3.972404\n",
      "Reconstruction: 2.866358, Regularization: 1.106046\n",
      "2019-04-09 22:43:26,520 root         INFO     Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 4.333078\n",
      "Reconstruction: 2.912271, Regularization: 1.420807\n",
      "2019-04-09 22:43:26,576 root         INFO     Train Epoch: 162 [4608/8000 (58%)]\tTotal Loss: 4.884296\n",
      "Reconstruction: 3.582927, Regularization: 1.301368\n",
      "2019-04-09 22:43:26,633 root         INFO     Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 3.017650\n",
      "Reconstruction: 2.052269, Regularization: 0.965381\n",
      "2019-04-09 22:43:26,689 root         INFO     Train Epoch: 162 [5632/8000 (70%)]\tTotal Loss: 10.880451\n",
      "Reconstruction: 9.409554, Regularization: 1.470898\n",
      "2019-04-09 22:43:26,745 root         INFO     Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 1.627404\n",
      "Reconstruction: 0.690812, Regularization: 0.936592\n",
      "2019-04-09 22:43:26,802 root         INFO     Train Epoch: 162 [6656/8000 (83%)]\tTotal Loss: 14.120482\n",
      "Reconstruction: 12.225279, Regularization: 1.895204\n",
      "2019-04-09 22:43:26,858 root         INFO     Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 32.981228\n",
      "Reconstruction: 30.775383, Regularization: 2.205846\n",
      "2019-04-09 22:43:26,914 root         INFO     Train Epoch: 162 [7680/8000 (96%)]\tTotal Loss: 9.660560\n",
      "Reconstruction: 8.008330, Regularization: 1.652229\n",
      "2019-04-09 22:43:26,963 root         INFO     ====> Epoch: 162 Average loss: 4.8596\n",
      "2019-04-09 22:43:26,986 root         INFO     Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 4.216938\n",
      "Reconstruction: 2.985505, Regularization: 1.231433\n",
      "2019-04-09 22:43:27,043 root         INFO     Train Epoch: 163 [512/8000 (6%)]\tTotal Loss: 22.243456\n",
      "Reconstruction: 20.141769, Regularization: 2.101686\n",
      "2019-04-09 22:43:27,099 root         INFO     Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 5.301899\n",
      "Reconstruction: 3.908576, Regularization: 1.393323\n",
      "2019-04-09 22:43:27,155 root         INFO     Train Epoch: 163 [1536/8000 (19%)]\tTotal Loss: 3.284930\n",
      "Reconstruction: 1.782611, Regularization: 1.502318\n",
      "2019-04-09 22:43:27,211 root         INFO     Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 2.052665\n",
      "Reconstruction: 0.433119, Regularization: 1.619546\n",
      "2019-04-09 22:43:27,267 root         INFO     Train Epoch: 163 [2560/8000 (32%)]\tTotal Loss: 6.231590\n",
      "Reconstruction: 4.781502, Regularization: 1.450088\n",
      "2019-04-09 22:43:27,323 root         INFO     Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 2.747999\n",
      "Reconstruction: 1.688145, Regularization: 1.059854\n",
      "2019-04-09 22:43:27,379 root         INFO     Train Epoch: 163 [3584/8000 (45%)]\tTotal Loss: 3.816716\n",
      "Reconstruction: 2.236688, Regularization: 1.580029\n",
      "2019-04-09 22:43:27,436 root         INFO     Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 0.862691\n",
      "Reconstruction: 0.296371, Regularization: 0.566320\n",
      "2019-04-09 22:43:27,492 root         INFO     Train Epoch: 163 [4608/8000 (58%)]\tTotal Loss: 2.822733\n",
      "Reconstruction: 1.406179, Regularization: 1.416555\n",
      "2019-04-09 22:43:27,548 root         INFO     Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 8.156189\n",
      "Reconstruction: 6.533916, Regularization: 1.622273\n",
      "2019-04-09 22:43:27,605 root         INFO     Train Epoch: 163 [5632/8000 (70%)]\tTotal Loss: 3.688362\n",
      "Reconstruction: 1.934742, Regularization: 1.753620\n",
      "2019-04-09 22:43:27,661 root         INFO     Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 2.751366\n",
      "Reconstruction: 1.064163, Regularization: 1.687203\n",
      "2019-04-09 22:43:27,717 root         INFO     Train Epoch: 163 [6656/8000 (83%)]\tTotal Loss: 4.845474\n",
      "Reconstruction: 2.921624, Regularization: 1.923850\n",
      "2019-04-09 22:43:27,774 root         INFO     Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 2.142420\n",
      "Reconstruction: 1.235192, Regularization: 0.907228\n",
      "2019-04-09 22:43:27,830 root         INFO     Train Epoch: 163 [7680/8000 (96%)]\tTotal Loss: 3.252026\n",
      "Reconstruction: 1.996250, Regularization: 1.255775\n",
      "2019-04-09 22:43:27,880 root         INFO     ====> Epoch: 163 Average loss: 4.7864\n",
      "2019-04-09 22:43:27,903 root         INFO     Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 13.130928\n",
      "Reconstruction: 11.427282, Regularization: 1.703646\n",
      "2019-04-09 22:43:27,960 root         INFO     Train Epoch: 164 [512/8000 (6%)]\tTotal Loss: 4.703218\n",
      "Reconstruction: 3.571486, Regularization: 1.131732\n",
      "2019-04-09 22:43:28,016 root         INFO     Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 4.541282\n",
      "Reconstruction: 2.552607, Regularization: 1.988675\n",
      "2019-04-09 22:43:28,073 root         INFO     Train Epoch: 164 [1536/8000 (19%)]\tTotal Loss: 5.349261\n",
      "Reconstruction: 3.518201, Regularization: 1.831059\n",
      "2019-04-09 22:43:28,129 root         INFO     Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 1.956135\n",
      "Reconstruction: 0.622775, Regularization: 1.333360\n",
      "2019-04-09 22:43:28,186 root         INFO     Train Epoch: 164 [2560/8000 (32%)]\tTotal Loss: 1.804296\n",
      "Reconstruction: 0.661318, Regularization: 1.142978\n",
      "2019-04-09 22:43:28,242 root         INFO     Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 2.105668\n",
      "Reconstruction: 0.765903, Regularization: 1.339764\n",
      "2019-04-09 22:43:28,298 root         INFO     Train Epoch: 164 [3584/8000 (45%)]\tTotal Loss: 2.106118\n",
      "Reconstruction: 0.910805, Regularization: 1.195313\n",
      "2019-04-09 22:43:28,355 root         INFO     Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 2.110007\n",
      "Reconstruction: 1.266475, Regularization: 0.843532\n",
      "2019-04-09 22:43:28,412 root         INFO     Train Epoch: 164 [4608/8000 (58%)]\tTotal Loss: 2.554263\n",
      "Reconstruction: 1.633829, Regularization: 0.920434\n",
      "2019-04-09 22:43:28,468 root         INFO     Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 1.952706\n",
      "Reconstruction: 0.443572, Regularization: 1.509134\n",
      "2019-04-09 22:43:28,525 root         INFO     Train Epoch: 164 [5632/8000 (70%)]\tTotal Loss: 3.360560\n",
      "Reconstruction: 1.768565, Regularization: 1.591995\n",
      "2019-04-09 22:43:28,581 root         INFO     Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 4.113695\n",
      "Reconstruction: 2.397637, Regularization: 1.716057\n",
      "2019-04-09 22:43:28,638 root         INFO     Train Epoch: 164 [6656/8000 (83%)]\tTotal Loss: 5.300185\n",
      "Reconstruction: 3.937947, Regularization: 1.362238\n",
      "2019-04-09 22:43:28,694 root         INFO     Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 4.690638\n",
      "Reconstruction: 3.057104, Regularization: 1.633534\n",
      "2019-04-09 22:43:28,750 root         INFO     Train Epoch: 164 [7680/8000 (96%)]\tTotal Loss: 3.253021\n",
      "Reconstruction: 1.809516, Regularization: 1.443505\n",
      "2019-04-09 22:43:28,798 root         INFO     ====> Epoch: 164 Average loss: 4.5557\n",
      "2019-04-09 22:43:28,822 root         INFO     Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 7.540381\n",
      "Reconstruction: 5.585961, Regularization: 1.954419\n",
      "2019-04-09 22:43:28,877 root         INFO     Train Epoch: 165 [512/8000 (6%)]\tTotal Loss: 2.820794\n",
      "Reconstruction: 1.433611, Regularization: 1.387183\n",
      "2019-04-09 22:43:28,931 root         INFO     Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 6.517197\n",
      "Reconstruction: 4.612480, Regularization: 1.904717\n",
      "2019-04-09 22:43:28,987 root         INFO     Train Epoch: 165 [1536/8000 (19%)]\tTotal Loss: 2.985989\n",
      "Reconstruction: 1.408383, Regularization: 1.577607\n",
      "2019-04-09 22:43:29,042 root         INFO     Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 3.357883\n",
      "Reconstruction: 1.435946, Regularization: 1.921937\n",
      "2019-04-09 22:43:29,096 root         INFO     Train Epoch: 165 [2560/8000 (32%)]\tTotal Loss: 4.998369\n",
      "Reconstruction: 3.310905, Regularization: 1.687463\n",
      "2019-04-09 22:43:29,152 root         INFO     Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 1.197397\n",
      "Reconstruction: 0.446769, Regularization: 0.750629\n",
      "2019-04-09 22:43:29,206 root         INFO     Train Epoch: 165 [3584/8000 (45%)]\tTotal Loss: 2.760287\n",
      "Reconstruction: 1.058955, Regularization: 1.701332\n",
      "2019-04-09 22:43:29,261 root         INFO     Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 2.343134\n",
      "Reconstruction: 1.262149, Regularization: 1.080985\n",
      "2019-04-09 22:43:29,315 root         INFO     Train Epoch: 165 [4608/8000 (58%)]\tTotal Loss: 2.247289\n",
      "Reconstruction: 0.765036, Regularization: 1.482253\n",
      "2019-04-09 22:43:29,370 root         INFO     Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 3.655215\n",
      "Reconstruction: 2.517703, Regularization: 1.137512\n",
      "2019-04-09 22:43:29,425 root         INFO     Train Epoch: 165 [5632/8000 (70%)]\tTotal Loss: 2.447396\n",
      "Reconstruction: 0.901776, Regularization: 1.545620\n",
      "2019-04-09 22:43:29,479 root         INFO     Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 2.452092\n",
      "Reconstruction: 1.499316, Regularization: 0.952776\n",
      "2019-04-09 22:43:29,533 root         INFO     Train Epoch: 165 [6656/8000 (83%)]\tTotal Loss: 2.027267\n",
      "Reconstruction: 0.927261, Regularization: 1.100006\n",
      "2019-04-09 22:43:29,588 root         INFO     Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 3.982227\n",
      "Reconstruction: 2.478025, Regularization: 1.504202\n",
      "2019-04-09 22:43:29,642 root         INFO     Train Epoch: 165 [7680/8000 (96%)]\tTotal Loss: 2.191474\n",
      "Reconstruction: 0.527615, Regularization: 1.663859\n",
      "2019-04-09 22:43:29,691 root         INFO     ====> Epoch: 165 Average loss: 4.1653\n",
      "2019-04-09 22:43:29,714 root         INFO     Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 3.650213\n",
      "Reconstruction: 2.029414, Regularization: 1.620798\n",
      "2019-04-09 22:43:29,770 root         INFO     Train Epoch: 166 [512/8000 (6%)]\tTotal Loss: 1.080879\n",
      "Reconstruction: 0.209086, Regularization: 0.871793\n",
      "2019-04-09 22:43:29,824 root         INFO     Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 2.660312\n",
      "Reconstruction: 1.003996, Regularization: 1.656316\n",
      "2019-04-09 22:43:29,879 root         INFO     Train Epoch: 166 [1536/8000 (19%)]\tTotal Loss: 7.506858\n",
      "Reconstruction: 5.878358, Regularization: 1.628499\n",
      "2019-04-09 22:43:29,933 root         INFO     Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 3.517687\n",
      "Reconstruction: 1.835944, Regularization: 1.681743\n",
      "2019-04-09 22:43:29,988 root         INFO     Train Epoch: 166 [2560/8000 (32%)]\tTotal Loss: 2.448133\n",
      "Reconstruction: 1.073186, Regularization: 1.374948\n",
      "2019-04-09 22:43:30,042 root         INFO     Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 1.907626\n",
      "Reconstruction: 0.491686, Regularization: 1.415940\n",
      "2019-04-09 22:43:30,096 root         INFO     Train Epoch: 166 [3584/8000 (45%)]\tTotal Loss: 10.815581\n",
      "Reconstruction: 9.579030, Regularization: 1.236551\n",
      "2019-04-09 22:43:30,151 root         INFO     Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 1.580045\n",
      "Reconstruction: 0.461865, Regularization: 1.118180\n",
      "2019-04-09 22:43:30,205 root         INFO     Train Epoch: 166 [4608/8000 (58%)]\tTotal Loss: 2.478247\n",
      "Reconstruction: 1.607293, Regularization: 0.870954\n",
      "2019-04-09 22:43:30,260 root         INFO     Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 21.614216\n",
      "Reconstruction: 20.103739, Regularization: 1.510476\n",
      "2019-04-09 22:43:30,314 root         INFO     Train Epoch: 166 [5632/8000 (70%)]\tTotal Loss: 2.560912\n",
      "Reconstruction: 1.508945, Regularization: 1.051967\n",
      "2019-04-09 22:43:30,368 root         INFO     Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 1.534417\n",
      "Reconstruction: 0.441659, Regularization: 1.092757\n",
      "2019-04-09 22:43:30,423 root         INFO     Train Epoch: 166 [6656/8000 (83%)]\tTotal Loss: 3.167263\n",
      "Reconstruction: 1.508337, Regularization: 1.658926\n",
      "2019-04-09 22:43:30,477 root         INFO     Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 1.720009\n",
      "Reconstruction: 0.938899, Regularization: 0.781109\n",
      "2019-04-09 22:43:30,532 root         INFO     Train Epoch: 166 [7680/8000 (96%)]\tTotal Loss: 5.005434\n",
      "Reconstruction: 3.380070, Regularization: 1.625365\n",
      "2019-04-09 22:43:30,581 root         INFO     ====> Epoch: 166 Average loss: 3.8049\n",
      "2019-04-09 22:43:30,605 root         INFO     Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 3.780306\n",
      "Reconstruction: 2.348520, Regularization: 1.431785\n",
      "2019-04-09 22:43:30,661 root         INFO     Train Epoch: 167 [512/8000 (6%)]\tTotal Loss: 1.406397\n",
      "Reconstruction: 0.563170, Regularization: 0.843227\n",
      "2019-04-09 22:43:30,717 root         INFO     Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 2.381825\n",
      "Reconstruction: 0.783059, Regularization: 1.598766\n",
      "2019-04-09 22:43:30,773 root         INFO     Train Epoch: 167 [1536/8000 (19%)]\tTotal Loss: 7.745214\n",
      "Reconstruction: 5.652481, Regularization: 2.092733\n",
      "2019-04-09 22:43:30,830 root         INFO     Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 2.145658\n",
      "Reconstruction: 0.554990, Regularization: 1.590667\n",
      "2019-04-09 22:43:30,887 root         INFO     Train Epoch: 167 [2560/8000 (32%)]\tTotal Loss: 5.952291\n",
      "Reconstruction: 4.298704, Regularization: 1.653588\n",
      "2019-04-09 22:43:30,943 root         INFO     Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 3.958385\n",
      "Reconstruction: 2.637896, Regularization: 1.320489\n",
      "2019-04-09 22:43:31,000 root         INFO     Train Epoch: 167 [3584/8000 (45%)]\tTotal Loss: 5.935044\n",
      "Reconstruction: 4.198559, Regularization: 1.736486\n",
      "2019-04-09 22:43:31,057 root         INFO     Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 1.987238\n",
      "Reconstruction: 0.983862, Regularization: 1.003376\n",
      "2019-04-09 22:43:31,114 root         INFO     Train Epoch: 167 [4608/8000 (58%)]\tTotal Loss: 1.560479\n",
      "Reconstruction: 0.279216, Regularization: 1.281263\n",
      "2019-04-09 22:43:31,170 root         INFO     Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 3.073399\n",
      "Reconstruction: 1.367385, Regularization: 1.706014\n",
      "2019-04-09 22:43:31,226 root         INFO     Train Epoch: 167 [5632/8000 (70%)]\tTotal Loss: 1.899581\n",
      "Reconstruction: 0.383499, Regularization: 1.516082\n",
      "2019-04-09 22:43:31,282 root         INFO     Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 1.606731\n",
      "Reconstruction: 0.570330, Regularization: 1.036401\n",
      "2019-04-09 22:43:31,338 root         INFO     Train Epoch: 167 [6656/8000 (83%)]\tTotal Loss: 3.435428\n",
      "Reconstruction: 2.180890, Regularization: 1.254539\n",
      "2019-04-09 22:43:31,394 root         INFO     Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 2.715073\n",
      "Reconstruction: 0.979476, Regularization: 1.735597\n",
      "2019-04-09 22:43:31,450 root         INFO     Train Epoch: 167 [7680/8000 (96%)]\tTotal Loss: 2.317632\n",
      "Reconstruction: 1.135860, Regularization: 1.181772\n",
      "2019-04-09 22:43:31,500 root         INFO     ====> Epoch: 167 Average loss: 3.6009\n",
      "2019-04-09 22:43:31,523 root         INFO     Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 2.064594\n",
      "Reconstruction: 0.515256, Regularization: 1.549339\n",
      "2019-04-09 22:43:31,580 root         INFO     Train Epoch: 168 [512/8000 (6%)]\tTotal Loss: 2.723940\n",
      "Reconstruction: 1.115877, Regularization: 1.608063\n",
      "2019-04-09 22:43:31,637 root         INFO     Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 1.531302\n",
      "Reconstruction: 0.376072, Regularization: 1.155230\n",
      "2019-04-09 22:43:31,694 root         INFO     Train Epoch: 168 [1536/8000 (19%)]\tTotal Loss: 1.320410\n",
      "Reconstruction: 0.342458, Regularization: 0.977952\n",
      "2019-04-09 22:43:31,750 root         INFO     Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 1.874841\n",
      "Reconstruction: 0.660605, Regularization: 1.214237\n",
      "2019-04-09 22:43:31,807 root         INFO     Train Epoch: 168 [2560/8000 (32%)]\tTotal Loss: 3.383121\n",
      "Reconstruction: 1.816982, Regularization: 1.566139\n",
      "2019-04-09 22:43:31,864 root         INFO     Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 2.914418\n",
      "Reconstruction: 1.588468, Regularization: 1.325950\n",
      "2019-04-09 22:43:31,921 root         INFO     Train Epoch: 168 [3584/8000 (45%)]\tTotal Loss: 1.473217\n",
      "Reconstruction: 0.428772, Regularization: 1.044446\n",
      "2019-04-09 22:43:31,977 root         INFO     Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 4.487005\n",
      "Reconstruction: 2.763628, Regularization: 1.723377\n",
      "2019-04-09 22:43:32,033 root         INFO     Train Epoch: 168 [4608/8000 (58%)]\tTotal Loss: 5.313298\n",
      "Reconstruction: 3.757968, Regularization: 1.555330\n",
      "2019-04-09 22:43:32,090 root         INFO     Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 1.715763\n",
      "Reconstruction: 0.404556, Regularization: 1.311207\n",
      "2019-04-09 22:43:32,145 root         INFO     Train Epoch: 168 [5632/8000 (70%)]\tTotal Loss: 1.603441\n",
      "Reconstruction: 0.656455, Regularization: 0.946985\n",
      "2019-04-09 22:43:32,201 root         INFO     Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 4.195712\n",
      "Reconstruction: 2.454534, Regularization: 1.741177\n",
      "2019-04-09 22:43:32,258 root         INFO     Train Epoch: 168 [6656/8000 (83%)]\tTotal Loss: 3.294216\n",
      "Reconstruction: 1.560579, Regularization: 1.733637\n",
      "2019-04-09 22:43:32,315 root         INFO     Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 5.711140\n",
      "Reconstruction: 4.147083, Regularization: 1.564056\n",
      "2019-04-09 22:43:32,371 root         INFO     Train Epoch: 168 [7680/8000 (96%)]\tTotal Loss: 12.774858\n",
      "Reconstruction: 11.213267, Regularization: 1.561591\n",
      "2019-04-09 22:43:32,421 root         INFO     ====> Epoch: 168 Average loss: 3.4823\n",
      "2019-04-09 22:43:32,445 root         INFO     Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 4.506849\n",
      "Reconstruction: 3.063447, Regularization: 1.443403\n",
      "2019-04-09 22:43:32,502 root         INFO     Train Epoch: 169 [512/8000 (6%)]\tTotal Loss: 2.702957\n",
      "Reconstruction: 1.086279, Regularization: 1.616678\n",
      "2019-04-09 22:43:32,558 root         INFO     Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 3.337972\n",
      "Reconstruction: 1.475279, Regularization: 1.862693\n",
      "2019-04-09 22:43:32,615 root         INFO     Train Epoch: 169 [1536/8000 (19%)]\tTotal Loss: 1.790988\n",
      "Reconstruction: 0.567235, Regularization: 1.223753\n",
      "2019-04-09 22:43:32,672 root         INFO     Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 2.933682\n",
      "Reconstruction: 1.031390, Regularization: 1.902292\n",
      "2019-04-09 22:43:32,728 root         INFO     Train Epoch: 169 [2560/8000 (32%)]\tTotal Loss: 1.379182\n",
      "Reconstruction: 0.616473, Regularization: 0.762709\n",
      "2019-04-09 22:43:32,784 root         INFO     Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 3.801560\n",
      "Reconstruction: 2.300766, Regularization: 1.500793\n",
      "2019-04-09 22:43:32,840 root         INFO     Train Epoch: 169 [3584/8000 (45%)]\tTotal Loss: 1.986870\n",
      "Reconstruction: 0.646788, Regularization: 1.340082\n",
      "2019-04-09 22:43:32,895 root         INFO     Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 1.375838\n",
      "Reconstruction: 0.387597, Regularization: 0.988240\n",
      "2019-04-09 22:43:32,951 root         INFO     Train Epoch: 169 [4608/8000 (58%)]\tTotal Loss: 1.978160\n",
      "Reconstruction: 0.566886, Regularization: 1.411274\n",
      "2019-04-09 22:43:33,007 root         INFO     Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 1.423048\n",
      "Reconstruction: 0.379350, Regularization: 1.043698\n",
      "2019-04-09 22:43:33,063 root         INFO     Train Epoch: 169 [5632/8000 (70%)]\tTotal Loss: 2.639111\n",
      "Reconstruction: 0.543965, Regularization: 2.095146\n",
      "2019-04-09 22:43:33,118 root         INFO     Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 1.807267\n",
      "Reconstruction: 0.459213, Regularization: 1.348054\n",
      "2019-04-09 22:43:33,174 root         INFO     Train Epoch: 169 [6656/8000 (83%)]\tTotal Loss: 4.923699\n",
      "Reconstruction: 2.505495, Regularization: 2.418204\n",
      "2019-04-09 22:43:33,229 root         INFO     Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 4.572829\n",
      "Reconstruction: 2.910148, Regularization: 1.662682\n",
      "2019-04-09 22:43:33,285 root         INFO     Train Epoch: 169 [7680/8000 (96%)]\tTotal Loss: 3.251314\n",
      "Reconstruction: 1.768022, Regularization: 1.483292\n",
      "2019-04-09 22:43:33,334 root         INFO     ====> Epoch: 169 Average loss: 3.3302\n",
      "2019-04-09 22:43:33,357 root         INFO     Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 2.867328\n",
      "Reconstruction: 1.187827, Regularization: 1.679501\n",
      "2019-04-09 22:43:33,413 root         INFO     Train Epoch: 170 [512/8000 (6%)]\tTotal Loss: 2.220859\n",
      "Reconstruction: 0.733078, Regularization: 1.487781\n",
      "2019-04-09 22:43:33,469 root         INFO     Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 1.389985\n",
      "Reconstruction: 0.442109, Regularization: 0.947876\n",
      "2019-04-09 22:43:33,525 root         INFO     Train Epoch: 170 [1536/8000 (19%)]\tTotal Loss: 2.947204\n",
      "Reconstruction: 1.414902, Regularization: 1.532302\n",
      "2019-04-09 22:43:33,581 root         INFO     Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 3.258177\n",
      "Reconstruction: 1.472753, Regularization: 1.785424\n",
      "2019-04-09 22:43:33,636 root         INFO     Train Epoch: 170 [2560/8000 (32%)]\tTotal Loss: 2.416959\n",
      "Reconstruction: 1.387353, Regularization: 1.029606\n",
      "2019-04-09 22:43:33,690 root         INFO     Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 1.871426\n",
      "Reconstruction: 0.775255, Regularization: 1.096171\n",
      "2019-04-09 22:43:33,745 root         INFO     Train Epoch: 170 [3584/8000 (45%)]\tTotal Loss: 2.193508\n",
      "Reconstruction: 0.928934, Regularization: 1.264574\n",
      "2019-04-09 22:43:33,800 root         INFO     Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 1.744591\n",
      "Reconstruction: 0.714245, Regularization: 1.030346\n",
      "2019-04-09 22:43:33,855 root         INFO     Train Epoch: 170 [4608/8000 (58%)]\tTotal Loss: 2.387232\n",
      "Reconstruction: 0.899200, Regularization: 1.488032\n",
      "2019-04-09 22:43:33,909 root         INFO     Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 2.230493\n",
      "Reconstruction: 0.916545, Regularization: 1.313949\n",
      "2019-04-09 22:43:33,964 root         INFO     Train Epoch: 170 [5632/8000 (70%)]\tTotal Loss: 6.311300\n",
      "Reconstruction: 4.607077, Regularization: 1.704224\n",
      "2019-04-09 22:43:34,018 root         INFO     Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 4.993321\n",
      "Reconstruction: 3.718179, Regularization: 1.275143\n",
      "2019-04-09 22:43:34,072 root         INFO     Train Epoch: 170 [6656/8000 (83%)]\tTotal Loss: 2.012972\n",
      "Reconstruction: 0.303661, Regularization: 1.709311\n",
      "2019-04-09 22:43:34,127 root         INFO     Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 1.684519\n",
      "Reconstruction: 0.587045, Regularization: 1.097474\n",
      "2019-04-09 22:43:34,182 root         INFO     Train Epoch: 170 [7680/8000 (96%)]\tTotal Loss: 2.211620\n",
      "Reconstruction: 0.970658, Regularization: 1.240962\n",
      "2019-04-09 22:43:34,230 root         INFO     ====> Epoch: 170 Average loss: 3.0621\n",
      "2019-04-09 22:43:34,253 root         INFO     Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 4.417372\n",
      "Reconstruction: 2.015516, Regularization: 2.401855\n",
      "2019-04-09 22:43:34,310 root         INFO     Train Epoch: 171 [512/8000 (6%)]\tTotal Loss: 5.932580\n",
      "Reconstruction: 3.788967, Regularization: 2.143613\n",
      "2019-04-09 22:43:34,366 root         INFO     Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 1.767010\n",
      "Reconstruction: 0.542320, Regularization: 1.224690\n",
      "2019-04-09 22:43:34,423 root         INFO     Train Epoch: 171 [1536/8000 (19%)]\tTotal Loss: 2.390918\n",
      "Reconstruction: 1.126616, Regularization: 1.264302\n",
      "2019-04-09 22:43:34,481 root         INFO     Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 3.269584\n",
      "Reconstruction: 1.753029, Regularization: 1.516555\n",
      "2019-04-09 22:43:34,538 root         INFO     Train Epoch: 171 [2560/8000 (32%)]\tTotal Loss: 9.730554\n",
      "Reconstruction: 7.893410, Regularization: 1.837144\n",
      "2019-04-09 22:43:34,594 root         INFO     Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 3.295155\n",
      "Reconstruction: 1.576091, Regularization: 1.719064\n",
      "2019-04-09 22:43:34,651 root         INFO     Train Epoch: 171 [3584/8000 (45%)]\tTotal Loss: 2.294213\n",
      "Reconstruction: 0.610789, Regularization: 1.683424\n",
      "2019-04-09 22:43:34,708 root         INFO     Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 2.729778\n",
      "Reconstruction: 1.328025, Regularization: 1.401753\n",
      "2019-04-09 22:43:34,765 root         INFO     Train Epoch: 171 [4608/8000 (58%)]\tTotal Loss: 1.958488\n",
      "Reconstruction: 0.604070, Regularization: 1.354418\n",
      "2019-04-09 22:43:34,822 root         INFO     Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 2.196638\n",
      "Reconstruction: 0.762226, Regularization: 1.434412\n",
      "2019-04-09 22:43:34,879 root         INFO     Train Epoch: 171 [5632/8000 (70%)]\tTotal Loss: 2.686734\n",
      "Reconstruction: 1.294256, Regularization: 1.392478\n",
      "2019-04-09 22:43:34,935 root         INFO     Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 2.263902\n",
      "Reconstruction: 0.781038, Regularization: 1.482864\n",
      "2019-04-09 22:43:34,992 root         INFO     Train Epoch: 171 [6656/8000 (83%)]\tTotal Loss: 2.563301\n",
      "Reconstruction: 0.467491, Regularization: 2.095810\n",
      "2019-04-09 22:43:35,048 root         INFO     Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 2.259546\n",
      "Reconstruction: 1.090361, Regularization: 1.169185\n",
      "2019-04-09 22:43:35,104 root         INFO     Train Epoch: 171 [7680/8000 (96%)]\tTotal Loss: 3.457407\n",
      "Reconstruction: 1.845669, Regularization: 1.611739\n",
      "2019-04-09 22:43:35,154 root         INFO     ====> Epoch: 171 Average loss: 2.8991\n",
      "2019-04-09 22:43:35,177 root         INFO     Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 2.111573\n",
      "Reconstruction: 0.767955, Regularization: 1.343618\n",
      "2019-04-09 22:43:35,234 root         INFO     Train Epoch: 172 [512/8000 (6%)]\tTotal Loss: 2.007759\n",
      "Reconstruction: 0.515809, Regularization: 1.491950\n",
      "2019-04-09 22:43:35,290 root         INFO     Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 2.531608\n",
      "Reconstruction: 0.971608, Regularization: 1.560000\n",
      "2019-04-09 22:43:35,347 root         INFO     Train Epoch: 172 [1536/8000 (19%)]\tTotal Loss: 2.008262\n",
      "Reconstruction: 0.838980, Regularization: 1.169282\n",
      "2019-04-09 22:43:35,403 root         INFO     Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 2.784691\n",
      "Reconstruction: 1.025145, Regularization: 1.759546\n",
      "2019-04-09 22:43:35,460 root         INFO     Train Epoch: 172 [2560/8000 (32%)]\tTotal Loss: 6.382749\n",
      "Reconstruction: 4.632200, Regularization: 1.750548\n",
      "2019-04-09 22:43:35,516 root         INFO     Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 1.402476\n",
      "Reconstruction: 0.365160, Regularization: 1.037316\n",
      "2019-04-09 22:43:35,573 root         INFO     Train Epoch: 172 [3584/8000 (45%)]\tTotal Loss: 1.319960\n",
      "Reconstruction: 0.285315, Regularization: 1.034645\n",
      "2019-04-09 22:43:35,629 root         INFO     Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 5.598207\n",
      "Reconstruction: 4.072914, Regularization: 1.525294\n",
      "2019-04-09 22:43:35,684 root         INFO     Train Epoch: 172 [4608/8000 (58%)]\tTotal Loss: 1.634194\n",
      "Reconstruction: 0.326062, Regularization: 1.308132\n",
      "2019-04-09 22:43:35,739 root         INFO     Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 3.010801\n",
      "Reconstruction: 1.107867, Regularization: 1.902933\n",
      "2019-04-09 22:43:35,794 root         INFO     Train Epoch: 172 [5632/8000 (70%)]\tTotal Loss: 1.574583\n",
      "Reconstruction: 0.297473, Regularization: 1.277111\n",
      "2019-04-09 22:43:35,848 root         INFO     Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 3.207305\n",
      "Reconstruction: 1.487660, Regularization: 1.719645\n",
      "2019-04-09 22:43:35,903 root         INFO     Train Epoch: 172 [6656/8000 (83%)]\tTotal Loss: 2.957719\n",
      "Reconstruction: 1.456793, Regularization: 1.500927\n",
      "2019-04-09 22:43:35,957 root         INFO     Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 3.032861\n",
      "Reconstruction: 1.816627, Regularization: 1.216234\n",
      "2019-04-09 22:43:36,011 root         INFO     Train Epoch: 172 [7680/8000 (96%)]\tTotal Loss: 15.994549\n",
      "Reconstruction: 14.000109, Regularization: 1.994440\n",
      "2019-04-09 22:43:36,060 root         INFO     ====> Epoch: 172 Average loss: 2.8073\n",
      "2019-04-09 22:43:36,083 root         INFO     Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 3.814360\n",
      "Reconstruction: 2.207435, Regularization: 1.606925\n",
      "2019-04-09 22:43:36,138 root         INFO     Train Epoch: 173 [512/8000 (6%)]\tTotal Loss: 3.016893\n",
      "Reconstruction: 1.216419, Regularization: 1.800474\n",
      "2019-04-09 22:43:36,193 root         INFO     Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 2.180344\n",
      "Reconstruction: 1.097962, Regularization: 1.082382\n",
      "2019-04-09 22:43:36,247 root         INFO     Train Epoch: 173 [1536/8000 (19%)]\tTotal Loss: 3.083178\n",
      "Reconstruction: 1.783286, Regularization: 1.299892\n",
      "2019-04-09 22:43:36,302 root         INFO     Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 1.760444\n",
      "Reconstruction: 0.642729, Regularization: 1.117715\n",
      "2019-04-09 22:43:36,356 root         INFO     Train Epoch: 173 [2560/8000 (32%)]\tTotal Loss: 1.655028\n",
      "Reconstruction: 0.643077, Regularization: 1.011951\n",
      "2019-04-09 22:43:36,410 root         INFO     Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 3.464293\n",
      "Reconstruction: 1.822819, Regularization: 1.641474\n",
      "2019-04-09 22:43:36,465 root         INFO     Train Epoch: 173 [3584/8000 (45%)]\tTotal Loss: 1.723381\n",
      "Reconstruction: 0.638497, Regularization: 1.084883\n",
      "2019-04-09 22:43:36,519 root         INFO     Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 4.477538\n",
      "Reconstruction: 2.987234, Regularization: 1.490304\n",
      "2019-04-09 22:43:36,574 root         INFO     Train Epoch: 173 [4608/8000 (58%)]\tTotal Loss: 2.905774\n",
      "Reconstruction: 1.246395, Regularization: 1.659379\n",
      "2019-04-09 22:43:36,629 root         INFO     Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 4.761105\n",
      "Reconstruction: 2.794533, Regularization: 1.966573\n",
      "2019-04-09 22:43:36,684 root         INFO     Train Epoch: 173 [5632/8000 (70%)]\tTotal Loss: 1.382474\n",
      "Reconstruction: 0.357107, Regularization: 1.025367\n",
      "2019-04-09 22:43:36,738 root         INFO     Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 4.535263\n",
      "Reconstruction: 1.951026, Regularization: 2.584237\n",
      "2019-04-09 22:43:36,793 root         INFO     Train Epoch: 173 [6656/8000 (83%)]\tTotal Loss: 3.570847\n",
      "Reconstruction: 1.556703, Regularization: 2.014143\n",
      "2019-04-09 22:43:36,847 root         INFO     Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 1.168576\n",
      "Reconstruction: 0.260182, Regularization: 0.908394\n",
      "2019-04-09 22:43:36,902 root         INFO     Train Epoch: 173 [7680/8000 (96%)]\tTotal Loss: 2.638271\n",
      "Reconstruction: 1.414448, Regularization: 1.223823\n",
      "2019-04-09 22:43:36,950 root         INFO     ====> Epoch: 173 Average loss: 2.6355\n",
      "2019-04-09 22:43:36,973 root         INFO     Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 1.527414\n",
      "Reconstruction: 0.561996, Regularization: 0.965418\n",
      "2019-04-09 22:43:37,029 root         INFO     Train Epoch: 174 [512/8000 (6%)]\tTotal Loss: 1.027931\n",
      "Reconstruction: 0.211489, Regularization: 0.816443\n",
      "2019-04-09 22:43:37,085 root         INFO     Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 1.534163\n",
      "Reconstruction: 0.491250, Regularization: 1.042913\n",
      "2019-04-09 22:43:37,140 root         INFO     Train Epoch: 174 [1536/8000 (19%)]\tTotal Loss: 2.575179\n",
      "Reconstruction: 0.854139, Regularization: 1.721040\n",
      "2019-04-09 22:43:37,196 root         INFO     Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 2.300064\n",
      "Reconstruction: 1.160895, Regularization: 1.139169\n",
      "2019-04-09 22:43:37,251 root         INFO     Train Epoch: 174 [2560/8000 (32%)]\tTotal Loss: 3.003262\n",
      "Reconstruction: 1.257265, Regularization: 1.745997\n",
      "2019-04-09 22:43:37,307 root         INFO     Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 1.751828\n",
      "Reconstruction: 0.705437, Regularization: 1.046391\n",
      "2019-04-09 22:43:37,363 root         INFO     Train Epoch: 174 [3584/8000 (45%)]\tTotal Loss: 2.971406\n",
      "Reconstruction: 1.490353, Regularization: 1.481052\n",
      "2019-04-09 22:43:37,420 root         INFO     Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 1.081548\n",
      "Reconstruction: 0.284920, Regularization: 0.796628\n",
      "2019-04-09 22:43:37,476 root         INFO     Train Epoch: 174 [4608/8000 (58%)]\tTotal Loss: 1.581782\n",
      "Reconstruction: 0.416466, Regularization: 1.165316\n",
      "2019-04-09 22:43:37,534 root         INFO     Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 1.793696\n",
      "Reconstruction: 0.809740, Regularization: 0.983956\n",
      "2019-04-09 22:43:37,591 root         INFO     Train Epoch: 174 [5632/8000 (70%)]\tTotal Loss: 1.620687\n",
      "Reconstruction: 0.589335, Regularization: 1.031353\n",
      "2019-04-09 22:43:37,648 root         INFO     Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 1.503888\n",
      "Reconstruction: 0.584504, Regularization: 0.919383\n",
      "2019-04-09 22:43:37,704 root         INFO     Train Epoch: 174 [6656/8000 (83%)]\tTotal Loss: 5.477280\n",
      "Reconstruction: 3.592393, Regularization: 1.884887\n",
      "2019-04-09 22:43:37,760 root         INFO     Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 2.773718\n",
      "Reconstruction: 0.730732, Regularization: 2.042986\n",
      "2019-04-09 22:43:37,817 root         INFO     Train Epoch: 174 [7680/8000 (96%)]\tTotal Loss: 2.944576\n",
      "Reconstruction: 1.257616, Regularization: 1.686960\n",
      "2019-04-09 22:43:37,867 root         INFO     ====> Epoch: 174 Average loss: 2.5504\n",
      "2019-04-09 22:43:37,890 root         INFO     Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 2.031873\n",
      "Reconstruction: 0.545334, Regularization: 1.486538\n",
      "2019-04-09 22:43:37,946 root         INFO     Train Epoch: 175 [512/8000 (6%)]\tTotal Loss: 2.336019\n",
      "Reconstruction: 1.189685, Regularization: 1.146334\n",
      "2019-04-09 22:43:38,002 root         INFO     Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 1.921660\n",
      "Reconstruction: 0.463779, Regularization: 1.457882\n",
      "2019-04-09 22:43:38,057 root         INFO     Train Epoch: 175 [1536/8000 (19%)]\tTotal Loss: 2.512046\n",
      "Reconstruction: 1.051415, Regularization: 1.460632\n",
      "2019-04-09 22:43:38,113 root         INFO     Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 1.955384\n",
      "Reconstruction: 0.527231, Regularization: 1.428153\n",
      "2019-04-09 22:43:38,168 root         INFO     Train Epoch: 175 [2560/8000 (32%)]\tTotal Loss: 3.009042\n",
      "Reconstruction: 1.840054, Regularization: 1.168988\n",
      "2019-04-09 22:43:38,223 root         INFO     Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 2.234784\n",
      "Reconstruction: 0.537625, Regularization: 1.697159\n",
      "2019-04-09 22:43:38,279 root         INFO     Train Epoch: 175 [3584/8000 (45%)]\tTotal Loss: 1.483634\n",
      "Reconstruction: 0.238988, Regularization: 1.244646\n",
      "2019-04-09 22:43:38,333 root         INFO     Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 2.265016\n",
      "Reconstruction: 0.527871, Regularization: 1.737145\n",
      "2019-04-09 22:43:38,388 root         INFO     Train Epoch: 175 [4608/8000 (58%)]\tTotal Loss: 2.153749\n",
      "Reconstruction: 0.565926, Regularization: 1.587823\n",
      "2019-04-09 22:43:38,443 root         INFO     Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 3.600876\n",
      "Reconstruction: 2.300820, Regularization: 1.300057\n",
      "2019-04-09 22:43:38,498 root         INFO     Train Epoch: 175 [5632/8000 (70%)]\tTotal Loss: 3.983385\n",
      "Reconstruction: 2.523463, Regularization: 1.459922\n",
      "2019-04-09 22:43:38,552 root         INFO     Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 1.705385\n",
      "Reconstruction: 0.708910, Regularization: 0.996475\n",
      "2019-04-09 22:43:38,607 root         INFO     Train Epoch: 175 [6656/8000 (83%)]\tTotal Loss: 3.682180\n",
      "Reconstruction: 1.972114, Regularization: 1.710066\n",
      "2019-04-09 22:43:38,662 root         INFO     Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 1.998066\n",
      "Reconstruction: 0.905386, Regularization: 1.092680\n",
      "2019-04-09 22:43:38,716 root         INFO     Train Epoch: 175 [7680/8000 (96%)]\tTotal Loss: 1.143107\n",
      "Reconstruction: 0.459837, Regularization: 0.683270\n",
      "2019-04-09 22:43:38,765 root         INFO     ====> Epoch: 175 Average loss: 2.4870\n",
      "2019-04-09 22:43:38,788 root         INFO     Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 2.415743\n",
      "Reconstruction: 1.200863, Regularization: 1.214881\n",
      "2019-04-09 22:43:38,843 root         INFO     Train Epoch: 176 [512/8000 (6%)]\tTotal Loss: 9.787121\n",
      "Reconstruction: 7.881363, Regularization: 1.905758\n",
      "2019-04-09 22:43:38,899 root         INFO     Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 1.331263\n",
      "Reconstruction: 0.381949, Regularization: 0.949314\n",
      "2019-04-09 22:43:38,954 root         INFO     Train Epoch: 176 [1536/8000 (19%)]\tTotal Loss: 1.720447\n",
      "Reconstruction: 0.618819, Regularization: 1.101628\n",
      "2019-04-09 22:43:39,009 root         INFO     Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 1.930197\n",
      "Reconstruction: 0.187655, Regularization: 1.742543\n",
      "2019-04-09 22:43:39,064 root         INFO     Train Epoch: 176 [2560/8000 (32%)]\tTotal Loss: 1.563319\n",
      "Reconstruction: 0.575212, Regularization: 0.988106\n",
      "2019-04-09 22:43:39,119 root         INFO     Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 4.284244\n",
      "Reconstruction: 2.772313, Regularization: 1.511931\n",
      "2019-04-09 22:43:39,174 root         INFO     Train Epoch: 176 [3584/8000 (45%)]\tTotal Loss: 2.253308\n",
      "Reconstruction: 1.068602, Regularization: 1.184706\n",
      "2019-04-09 22:43:39,229 root         INFO     Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 1.002319\n",
      "Reconstruction: 0.365437, Regularization: 0.636881\n",
      "2019-04-09 22:43:39,284 root         INFO     Train Epoch: 176 [4608/8000 (58%)]\tTotal Loss: 1.391608\n",
      "Reconstruction: 0.355229, Regularization: 1.036379\n",
      "2019-04-09 22:43:39,339 root         INFO     Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 4.405980\n",
      "Reconstruction: 2.682033, Regularization: 1.723947\n",
      "2019-04-09 22:43:39,394 root         INFO     Train Epoch: 176 [5632/8000 (70%)]\tTotal Loss: 2.357487\n",
      "Reconstruction: 0.544661, Regularization: 1.812826\n",
      "2019-04-09 22:43:39,449 root         INFO     Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 2.113996\n",
      "Reconstruction: 0.855352, Regularization: 1.258643\n",
      "2019-04-09 22:43:39,504 root         INFO     Train Epoch: 176 [6656/8000 (83%)]\tTotal Loss: 1.620226\n",
      "Reconstruction: 0.729073, Regularization: 0.891153\n",
      "2019-04-09 22:43:39,560 root         INFO     Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 1.603483\n",
      "Reconstruction: 0.429755, Regularization: 1.173728\n",
      "2019-04-09 22:43:39,615 root         INFO     Train Epoch: 176 [7680/8000 (96%)]\tTotal Loss: 2.325314\n",
      "Reconstruction: 0.605730, Regularization: 1.719583\n",
      "2019-04-09 22:43:39,664 root         INFO     ====> Epoch: 176 Average loss: 2.3938\n",
      "2019-04-09 22:43:39,688 root         INFO     Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 1.476850\n",
      "Reconstruction: 0.325724, Regularization: 1.151126\n",
      "2019-04-09 22:43:39,744 root         INFO     Train Epoch: 177 [512/8000 (6%)]\tTotal Loss: 2.925930\n",
      "Reconstruction: 0.937946, Regularization: 1.987984\n",
      "2019-04-09 22:43:39,800 root         INFO     Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 2.054909\n",
      "Reconstruction: 0.475069, Regularization: 1.579840\n",
      "2019-04-09 22:43:39,856 root         INFO     Train Epoch: 177 [1536/8000 (19%)]\tTotal Loss: 2.427393\n",
      "Reconstruction: 0.803122, Regularization: 1.624271\n",
      "2019-04-09 22:43:39,911 root         INFO     Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 2.143599\n",
      "Reconstruction: 0.444200, Regularization: 1.699399\n",
      "2019-04-09 22:43:39,967 root         INFO     Train Epoch: 177 [2560/8000 (32%)]\tTotal Loss: 1.157627\n",
      "Reconstruction: 0.286264, Regularization: 0.871364\n",
      "2019-04-09 22:43:40,023 root         INFO     Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 1.929517\n",
      "Reconstruction: 0.316011, Regularization: 1.613507\n",
      "2019-04-09 22:43:40,078 root         INFO     Train Epoch: 177 [3584/8000 (45%)]\tTotal Loss: 3.212442\n",
      "Reconstruction: 1.437083, Regularization: 1.775359\n",
      "2019-04-09 22:43:40,134 root         INFO     Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 1.677850\n",
      "Reconstruction: 0.334640, Regularization: 1.343210\n",
      "2019-04-09 22:43:40,190 root         INFO     Train Epoch: 177 [4608/8000 (58%)]\tTotal Loss: 2.928666\n",
      "Reconstruction: 1.056636, Regularization: 1.872030\n",
      "2019-04-09 22:43:40,245 root         INFO     Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 1.938561\n",
      "Reconstruction: 0.550797, Regularization: 1.387764\n",
      "2019-04-09 22:43:40,301 root         INFO     Train Epoch: 177 [5632/8000 (70%)]\tTotal Loss: 1.231948\n",
      "Reconstruction: 0.297819, Regularization: 0.934129\n",
      "2019-04-09 22:43:40,356 root         INFO     Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 2.715355\n",
      "Reconstruction: 0.616518, Regularization: 2.098837\n",
      "2019-04-09 22:43:40,411 root         INFO     Train Epoch: 177 [6656/8000 (83%)]\tTotal Loss: 1.214137\n",
      "Reconstruction: 0.385488, Regularization: 0.828650\n",
      "2019-04-09 22:43:40,466 root         INFO     Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 2.025118\n",
      "Reconstruction: 0.647051, Regularization: 1.378067\n",
      "2019-04-09 22:43:40,521 root         INFO     Train Epoch: 177 [7680/8000 (96%)]\tTotal Loss: 1.420910\n",
      "Reconstruction: 0.399649, Regularization: 1.021261\n",
      "2019-04-09 22:43:40,569 root         INFO     ====> Epoch: 177 Average loss: 2.2797\n",
      "2019-04-09 22:43:40,592 root         INFO     Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 1.689732\n",
      "Reconstruction: 0.452759, Regularization: 1.236973\n",
      "2019-04-09 22:43:40,647 root         INFO     Train Epoch: 178 [512/8000 (6%)]\tTotal Loss: 3.132696\n",
      "Reconstruction: 1.532563, Regularization: 1.600133\n",
      "2019-04-09 22:43:40,703 root         INFO     Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 1.601600\n",
      "Reconstruction: 0.397289, Regularization: 1.204311\n",
      "2019-04-09 22:43:40,759 root         INFO     Train Epoch: 178 [1536/8000 (19%)]\tTotal Loss: 1.945359\n",
      "Reconstruction: 0.424754, Regularization: 1.520604\n",
      "2019-04-09 22:43:40,814 root         INFO     Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 1.463778\n",
      "Reconstruction: 0.223316, Regularization: 1.240461\n",
      "2019-04-09 22:43:40,869 root         INFO     Train Epoch: 178 [2560/8000 (32%)]\tTotal Loss: 1.839947\n",
      "Reconstruction: 0.623720, Regularization: 1.216227\n",
      "2019-04-09 22:43:40,925 root         INFO     Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 2.009698\n",
      "Reconstruction: 0.650813, Regularization: 1.358885\n",
      "2019-04-09 22:43:40,980 root         INFO     Train Epoch: 178 [3584/8000 (45%)]\tTotal Loss: 1.872307\n",
      "Reconstruction: 0.313824, Regularization: 1.558484\n",
      "2019-04-09 22:43:41,035 root         INFO     Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 2.239180\n",
      "Reconstruction: 0.284348, Regularization: 1.954832\n",
      "2019-04-09 22:43:41,090 root         INFO     Train Epoch: 178 [4608/8000 (58%)]\tTotal Loss: 1.800976\n",
      "Reconstruction: 0.378766, Regularization: 1.422210\n",
      "2019-04-09 22:43:41,145 root         INFO     Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 1.456697\n",
      "Reconstruction: 0.280662, Regularization: 1.176034\n",
      "2019-04-09 22:43:41,200 root         INFO     Train Epoch: 178 [5632/8000 (70%)]\tTotal Loss: 1.794503\n",
      "Reconstruction: 0.386698, Regularization: 1.407805\n",
      "2019-04-09 22:43:41,255 root         INFO     Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 2.545048\n",
      "Reconstruction: 0.800188, Regularization: 1.744860\n",
      "2019-04-09 22:43:41,310 root         INFO     Train Epoch: 178 [6656/8000 (83%)]\tTotal Loss: 2.390023\n",
      "Reconstruction: 0.806841, Regularization: 1.583182\n",
      "2019-04-09 22:43:41,365 root         INFO     Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 1.883481\n",
      "Reconstruction: 0.669626, Regularization: 1.213856\n",
      "2019-04-09 22:43:41,420 root         INFO     Train Epoch: 178 [7680/8000 (96%)]\tTotal Loss: 2.155360\n",
      "Reconstruction: 0.592746, Regularization: 1.562614\n",
      "2019-04-09 22:43:41,469 root         INFO     ====> Epoch: 178 Average loss: 2.2161\n",
      "2019-04-09 22:43:41,493 root         INFO     Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 2.621938\n",
      "Reconstruction: 1.086805, Regularization: 1.535132\n",
      "2019-04-09 22:43:41,549 root         INFO     Train Epoch: 179 [512/8000 (6%)]\tTotal Loss: 2.059341\n",
      "Reconstruction: 0.467462, Regularization: 1.591880\n",
      "2019-04-09 22:43:41,604 root         INFO     Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 1.898368\n",
      "Reconstruction: 0.505559, Regularization: 1.392809\n",
      "2019-04-09 22:43:41,660 root         INFO     Train Epoch: 179 [1536/8000 (19%)]\tTotal Loss: 2.623791\n",
      "Reconstruction: 1.112045, Regularization: 1.511745\n",
      "2019-04-09 22:43:41,716 root         INFO     Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 1.961264\n",
      "Reconstruction: 1.017721, Regularization: 0.943542\n",
      "2019-04-09 22:43:41,773 root         INFO     Train Epoch: 179 [2560/8000 (32%)]\tTotal Loss: 1.476457\n",
      "Reconstruction: 0.317193, Regularization: 1.159263\n",
      "2019-04-09 22:43:41,830 root         INFO     Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 2.544976\n",
      "Reconstruction: 0.868244, Regularization: 1.676732\n",
      "2019-04-09 22:43:41,886 root         INFO     Train Epoch: 179 [3584/8000 (45%)]\tTotal Loss: 2.969783\n",
      "Reconstruction: 0.753160, Regularization: 2.216623\n",
      "2019-04-09 22:43:41,942 root         INFO     Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 3.162154\n",
      "Reconstruction: 0.847684, Regularization: 2.314470\n",
      "2019-04-09 22:43:41,999 root         INFO     Train Epoch: 179 [4608/8000 (58%)]\tTotal Loss: 1.348050\n",
      "Reconstruction: 0.290431, Regularization: 1.057619\n",
      "2019-04-09 22:43:42,055 root         INFO     Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 1.911265\n",
      "Reconstruction: 0.562976, Regularization: 1.348289\n",
      "2019-04-09 22:43:42,111 root         INFO     Train Epoch: 179 [5632/8000 (70%)]\tTotal Loss: 2.363590\n",
      "Reconstruction: 0.830303, Regularization: 1.533287\n",
      "2019-04-09 22:43:42,167 root         INFO     Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 1.520641\n",
      "Reconstruction: 0.232746, Regularization: 1.287895\n",
      "2019-04-09 22:43:42,224 root         INFO     Train Epoch: 179 [6656/8000 (83%)]\tTotal Loss: 2.720336\n",
      "Reconstruction: 1.380913, Regularization: 1.339423\n",
      "2019-04-09 22:43:42,280 root         INFO     Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 2.458763\n",
      "Reconstruction: 0.226933, Regularization: 2.231831\n",
      "2019-04-09 22:43:42,336 root         INFO     Train Epoch: 179 [7680/8000 (96%)]\tTotal Loss: 3.415414\n",
      "Reconstruction: 1.473891, Regularization: 1.941523\n",
      "2019-04-09 22:43:42,386 root         INFO     ====> Epoch: 179 Average loss: 2.1479\n",
      "2019-04-09 22:43:42,410 root         INFO     Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 1.355692\n",
      "Reconstruction: 0.244512, Regularization: 1.111180\n",
      "2019-04-09 22:43:42,466 root         INFO     Train Epoch: 180 [512/8000 (6%)]\tTotal Loss: 2.630243\n",
      "Reconstruction: 1.530388, Regularization: 1.099855\n",
      "2019-04-09 22:43:42,523 root         INFO     Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 1.323101\n",
      "Reconstruction: 0.288096, Regularization: 1.035005\n",
      "2019-04-09 22:43:42,579 root         INFO     Train Epoch: 180 [1536/8000 (19%)]\tTotal Loss: 1.697154\n",
      "Reconstruction: 0.518964, Regularization: 1.178190\n",
      "2019-04-09 22:43:42,636 root         INFO     Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 1.612461\n",
      "Reconstruction: 0.338007, Regularization: 1.274454\n",
      "2019-04-09 22:43:42,692 root         INFO     Train Epoch: 180 [2560/8000 (32%)]\tTotal Loss: 2.781924\n",
      "Reconstruction: 0.556817, Regularization: 2.225106\n",
      "2019-04-09 22:43:42,749 root         INFO     Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 1.847173\n",
      "Reconstruction: 0.676024, Regularization: 1.171149\n",
      "2019-04-09 22:43:42,806 root         INFO     Train Epoch: 180 [3584/8000 (45%)]\tTotal Loss: 1.576785\n",
      "Reconstruction: 0.306369, Regularization: 1.270416\n",
      "2019-04-09 22:43:42,863 root         INFO     Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 1.714028\n",
      "Reconstruction: 0.505777, Regularization: 1.208251\n",
      "2019-04-09 22:43:42,920 root         INFO     Train Epoch: 180 [4608/8000 (58%)]\tTotal Loss: 2.342281\n",
      "Reconstruction: 1.473081, Regularization: 0.869200\n",
      "2019-04-09 22:43:42,976 root         INFO     Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 1.684101\n",
      "Reconstruction: 0.521704, Regularization: 1.162397\n",
      "2019-04-09 22:43:43,032 root         INFO     Train Epoch: 180 [5632/8000 (70%)]\tTotal Loss: 2.128011\n",
      "Reconstruction: 0.336857, Regularization: 1.791155\n",
      "2019-04-09 22:43:43,089 root         INFO     Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 1.982265\n",
      "Reconstruction: 0.901676, Regularization: 1.080589\n",
      "2019-04-09 22:43:43,145 root         INFO     Train Epoch: 180 [6656/8000 (83%)]\tTotal Loss: 2.540356\n",
      "Reconstruction: 1.298378, Regularization: 1.241978\n",
      "2019-04-09 22:43:43,202 root         INFO     Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 1.913275\n",
      "Reconstruction: 0.624048, Regularization: 1.289228\n",
      "2019-04-09 22:43:43,259 root         INFO     Train Epoch: 180 [7680/8000 (96%)]\tTotal Loss: 1.561262\n",
      "Reconstruction: 0.490107, Regularization: 1.071155\n",
      "2019-04-09 22:43:43,308 root         INFO     ====> Epoch: 180 Average loss: 2.0863\n",
      "2019-04-09 22:43:43,332 root         INFO     Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 1.567682\n",
      "Reconstruction: 0.321015, Regularization: 1.246667\n",
      "2019-04-09 22:43:43,386 root         INFO     Train Epoch: 181 [512/8000 (6%)]\tTotal Loss: 1.861855\n",
      "Reconstruction: 0.337011, Regularization: 1.524844\n",
      "2019-04-09 22:43:43,441 root         INFO     Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 1.669189\n",
      "Reconstruction: 0.552864, Regularization: 1.116325\n",
      "2019-04-09 22:43:43,495 root         INFO     Train Epoch: 181 [1536/8000 (19%)]\tTotal Loss: 2.063836\n",
      "Reconstruction: 0.319073, Regularization: 1.744763\n",
      "2019-04-09 22:43:43,549 root         INFO     Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 1.967355\n",
      "Reconstruction: 0.611157, Regularization: 1.356198\n",
      "2019-04-09 22:43:43,603 root         INFO     Train Epoch: 181 [2560/8000 (32%)]\tTotal Loss: 2.753774\n",
      "Reconstruction: 0.667619, Regularization: 2.086155\n",
      "2019-04-09 22:43:43,658 root         INFO     Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 2.149241\n",
      "Reconstruction: 0.684506, Regularization: 1.464735\n",
      "2019-04-09 22:43:43,712 root         INFO     Train Epoch: 181 [3584/8000 (45%)]\tTotal Loss: 1.695197\n",
      "Reconstruction: 0.498850, Regularization: 1.196347\n",
      "2019-04-09 22:43:43,768 root         INFO     Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 2.502451\n",
      "Reconstruction: 0.619078, Regularization: 1.883373\n",
      "2019-04-09 22:43:43,822 root         INFO     Train Epoch: 181 [4608/8000 (58%)]\tTotal Loss: 1.698961\n",
      "Reconstruction: 0.197118, Regularization: 1.501843\n",
      "2019-04-09 22:43:43,876 root         INFO     Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 1.378050\n",
      "Reconstruction: 0.162046, Regularization: 1.216004\n",
      "2019-04-09 22:43:43,931 root         INFO     Train Epoch: 181 [5632/8000 (70%)]\tTotal Loss: 2.047421\n",
      "Reconstruction: 0.805593, Regularization: 1.241829\n",
      "2019-04-09 22:43:43,985 root         INFO     Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 2.855682\n",
      "Reconstruction: 0.897408, Regularization: 1.958274\n",
      "2019-04-09 22:43:44,039 root         INFO     Train Epoch: 181 [6656/8000 (83%)]\tTotal Loss: 1.505053\n",
      "Reconstruction: 0.304027, Regularization: 1.201026\n",
      "2019-04-09 22:43:44,094 root         INFO     Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 1.755287\n",
      "Reconstruction: 0.782768, Regularization: 0.972519\n",
      "2019-04-09 22:43:44,148 root         INFO     Train Epoch: 181 [7680/8000 (96%)]\tTotal Loss: 1.751484\n",
      "Reconstruction: 0.511893, Regularization: 1.239592\n",
      "2019-04-09 22:43:44,197 root         INFO     ====> Epoch: 181 Average loss: 2.0315\n",
      "2019-04-09 22:43:44,221 root         INFO     Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 1.687749\n",
      "Reconstruction: 0.300649, Regularization: 1.387100\n",
      "2019-04-09 22:43:44,276 root         INFO     Train Epoch: 182 [512/8000 (6%)]\tTotal Loss: 1.407855\n",
      "Reconstruction: 0.330744, Regularization: 1.077111\n",
      "2019-04-09 22:43:44,330 root         INFO     Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 2.376317\n",
      "Reconstruction: 0.539360, Regularization: 1.836957\n",
      "2019-04-09 22:43:44,385 root         INFO     Train Epoch: 182 [1536/8000 (19%)]\tTotal Loss: 2.714862\n",
      "Reconstruction: 0.580501, Regularization: 2.134361\n",
      "2019-04-09 22:43:44,440 root         INFO     Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 2.289525\n",
      "Reconstruction: 0.881780, Regularization: 1.407744\n",
      "2019-04-09 22:43:44,495 root         INFO     Train Epoch: 182 [2560/8000 (32%)]\tTotal Loss: 2.375678\n",
      "Reconstruction: 0.435619, Regularization: 1.940059\n",
      "2019-04-09 22:43:44,549 root         INFO     Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 2.062504\n",
      "Reconstruction: 0.855112, Regularization: 1.207392\n",
      "2019-04-09 22:43:44,604 root         INFO     Train Epoch: 182 [3584/8000 (45%)]\tTotal Loss: 1.238181\n",
      "Reconstruction: 0.284366, Regularization: 0.953815\n",
      "2019-04-09 22:43:44,659 root         INFO     Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 2.143691\n",
      "Reconstruction: 0.554833, Regularization: 1.588858\n",
      "2019-04-09 22:43:44,714 root         INFO     Train Epoch: 182 [4608/8000 (58%)]\tTotal Loss: 1.738132\n",
      "Reconstruction: 0.495953, Regularization: 1.242180\n",
      "2019-04-09 22:43:44,768 root         INFO     Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 2.592592\n",
      "Reconstruction: 1.197667, Regularization: 1.394924\n",
      "2019-04-09 22:43:44,823 root         INFO     Train Epoch: 182 [5632/8000 (70%)]\tTotal Loss: 1.742338\n",
      "Reconstruction: 0.485249, Regularization: 1.257088\n",
      "2019-04-09 22:43:44,878 root         INFO     Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 2.068489\n",
      "Reconstruction: 0.297992, Regularization: 1.770497\n",
      "2019-04-09 22:43:44,933 root         INFO     Train Epoch: 182 [6656/8000 (83%)]\tTotal Loss: 2.467447\n",
      "Reconstruction: 0.522939, Regularization: 1.944508\n",
      "2019-04-09 22:43:44,988 root         INFO     Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 1.199071\n",
      "Reconstruction: 0.228217, Regularization: 0.970854\n",
      "2019-04-09 22:43:45,043 root         INFO     Train Epoch: 182 [7680/8000 (96%)]\tTotal Loss: 1.428437\n",
      "Reconstruction: 0.316930, Regularization: 1.111507\n",
      "2019-04-09 22:43:45,092 root         INFO     ====> Epoch: 182 Average loss: 1.9780\n",
      "2019-04-09 22:43:45,115 root         INFO     Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 2.903610\n",
      "Reconstruction: 1.268616, Regularization: 1.634994\n",
      "2019-04-09 22:43:45,170 root         INFO     Train Epoch: 183 [512/8000 (6%)]\tTotal Loss: 2.240527\n",
      "Reconstruction: 0.832092, Regularization: 1.408436\n",
      "2019-04-09 22:43:45,226 root         INFO     Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 2.361108\n",
      "Reconstruction: 0.760508, Regularization: 1.600600\n",
      "2019-04-09 22:43:45,282 root         INFO     Train Epoch: 183 [1536/8000 (19%)]\tTotal Loss: 1.812590\n",
      "Reconstruction: 0.614843, Regularization: 1.197747\n",
      "2019-04-09 22:43:45,337 root         INFO     Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 1.628585\n",
      "Reconstruction: 0.366839, Regularization: 1.261746\n",
      "2019-04-09 22:43:45,392 root         INFO     Train Epoch: 183 [2560/8000 (32%)]\tTotal Loss: 1.875405\n",
      "Reconstruction: 0.802638, Regularization: 1.072767\n",
      "2019-04-09 22:43:45,447 root         INFO     Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 1.378153\n",
      "Reconstruction: 0.444802, Regularization: 0.933351\n",
      "2019-04-09 22:43:45,501 root         INFO     Train Epoch: 183 [3584/8000 (45%)]\tTotal Loss: 2.629740\n",
      "Reconstruction: 0.807454, Regularization: 1.822286\n",
      "2019-04-09 22:43:45,556 root         INFO     Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 2.659827\n",
      "Reconstruction: 0.761062, Regularization: 1.898765\n",
      "2019-04-09 22:43:45,611 root         INFO     Train Epoch: 183 [4608/8000 (58%)]\tTotal Loss: 1.054192\n",
      "Reconstruction: 0.377952, Regularization: 0.676239\n",
      "2019-04-09 22:43:45,665 root         INFO     Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 3.067883\n",
      "Reconstruction: 0.976460, Regularization: 2.091423\n",
      "2019-04-09 22:43:45,720 root         INFO     Train Epoch: 183 [5632/8000 (70%)]\tTotal Loss: 2.326166\n",
      "Reconstruction: 0.943194, Regularization: 1.382972\n",
      "2019-04-09 22:43:45,774 root         INFO     Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 1.462837\n",
      "Reconstruction: 0.415251, Regularization: 1.047587\n",
      "2019-04-09 22:43:45,829 root         INFO     Train Epoch: 183 [6656/8000 (83%)]\tTotal Loss: 1.678667\n",
      "Reconstruction: 0.491520, Regularization: 1.187147\n",
      "2019-04-09 22:43:45,884 root         INFO     Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 1.488950\n",
      "Reconstruction: 0.371633, Regularization: 1.117317\n",
      "2019-04-09 22:43:45,940 root         INFO     Train Epoch: 183 [7680/8000 (96%)]\tTotal Loss: 1.507416\n",
      "Reconstruction: 0.335798, Regularization: 1.171618\n",
      "2019-04-09 22:43:45,989 root         INFO     ====> Epoch: 183 Average loss: 1.9288\n",
      "2019-04-09 22:43:46,013 root         INFO     Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 1.961625\n",
      "Reconstruction: 0.496859, Regularization: 1.464766\n",
      "2019-04-09 22:43:46,068 root         INFO     Train Epoch: 184 [512/8000 (6%)]\tTotal Loss: 2.029600\n",
      "Reconstruction: 0.471062, Regularization: 1.558537\n",
      "2019-04-09 22:43:46,123 root         INFO     Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 1.676414\n",
      "Reconstruction: 0.377505, Regularization: 1.298908\n",
      "2019-04-09 22:43:46,177 root         INFO     Train Epoch: 184 [1536/8000 (19%)]\tTotal Loss: 2.012823\n",
      "Reconstruction: 0.560243, Regularization: 1.452579\n",
      "2019-04-09 22:43:46,232 root         INFO     Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 1.745142\n",
      "Reconstruction: 0.578302, Regularization: 1.166841\n",
      "2019-04-09 22:43:46,287 root         INFO     Train Epoch: 184 [2560/8000 (32%)]\tTotal Loss: 1.699379\n",
      "Reconstruction: 0.235463, Regularization: 1.463916\n",
      "2019-04-09 22:43:46,342 root         INFO     Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 1.386197\n",
      "Reconstruction: 0.519623, Regularization: 0.866574\n",
      "2019-04-09 22:43:46,397 root         INFO     Train Epoch: 184 [3584/8000 (45%)]\tTotal Loss: 2.144055\n",
      "Reconstruction: 0.923517, Regularization: 1.220539\n",
      "2019-04-09 22:43:46,453 root         INFO     Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 1.883061\n",
      "Reconstruction: 0.397464, Regularization: 1.485597\n",
      "2019-04-09 22:43:46,508 root         INFO     Train Epoch: 184 [4608/8000 (58%)]\tTotal Loss: 2.147109\n",
      "Reconstruction: 0.332390, Regularization: 1.814719\n",
      "2019-04-09 22:43:46,563 root         INFO     Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 1.615801\n",
      "Reconstruction: 0.468355, Regularization: 1.147446\n",
      "2019-04-09 22:43:46,617 root         INFO     Train Epoch: 184 [5632/8000 (70%)]\tTotal Loss: 2.123643\n",
      "Reconstruction: 0.521648, Regularization: 1.601995\n",
      "2019-04-09 22:43:46,672 root         INFO     Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 2.155869\n",
      "Reconstruction: 0.590772, Regularization: 1.565097\n",
      "2019-04-09 22:43:46,726 root         INFO     Train Epoch: 184 [6656/8000 (83%)]\tTotal Loss: 1.945613\n",
      "Reconstruction: 0.432380, Regularization: 1.513234\n",
      "2019-04-09 22:43:46,780 root         INFO     Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 1.708955\n",
      "Reconstruction: 0.615473, Regularization: 1.093482\n",
      "2019-04-09 22:43:46,835 root         INFO     Train Epoch: 184 [7680/8000 (96%)]\tTotal Loss: 2.184793\n",
      "Reconstruction: 0.819916, Regularization: 1.364877\n",
      "2019-04-09 22:43:46,884 root         INFO     ====> Epoch: 184 Average loss: 1.8920\n",
      "2019-04-09 22:43:46,907 root         INFO     Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 2.221300\n",
      "Reconstruction: 0.479111, Regularization: 1.742188\n",
      "2019-04-09 22:43:46,963 root         INFO     Train Epoch: 185 [512/8000 (6%)]\tTotal Loss: 1.939739\n",
      "Reconstruction: 0.709919, Regularization: 1.229820\n",
      "2019-04-09 22:43:47,018 root         INFO     Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 1.863270\n",
      "Reconstruction: 0.481400, Regularization: 1.381869\n",
      "2019-04-09 22:43:47,074 root         INFO     Train Epoch: 185 [1536/8000 (19%)]\tTotal Loss: 2.287938\n",
      "Reconstruction: 0.514464, Regularization: 1.773474\n",
      "2019-04-09 22:43:47,129 root         INFO     Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 1.531165\n",
      "Reconstruction: 0.259988, Regularization: 1.271176\n",
      "2019-04-09 22:43:47,185 root         INFO     Train Epoch: 185 [2560/8000 (32%)]\tTotal Loss: 2.461021\n",
      "Reconstruction: 0.964018, Regularization: 1.497003\n",
      "2019-04-09 22:43:47,240 root         INFO     Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 1.494323\n",
      "Reconstruction: 0.295418, Regularization: 1.198905\n",
      "2019-04-09 22:43:47,295 root         INFO     Train Epoch: 185 [3584/8000 (45%)]\tTotal Loss: 1.886123\n",
      "Reconstruction: 0.318677, Regularization: 1.567446\n",
      "2019-04-09 22:43:47,350 root         INFO     Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 2.017647\n",
      "Reconstruction: 0.518403, Regularization: 1.499244\n",
      "2019-04-09 22:43:47,404 root         INFO     Train Epoch: 185 [4608/8000 (58%)]\tTotal Loss: 1.923477\n",
      "Reconstruction: 0.327769, Regularization: 1.595708\n",
      "2019-04-09 22:43:47,458 root         INFO     Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 1.998947\n",
      "Reconstruction: 0.399386, Regularization: 1.599560\n",
      "2019-04-09 22:43:47,512 root         INFO     Train Epoch: 185 [5632/8000 (70%)]\tTotal Loss: 1.716753\n",
      "Reconstruction: 0.394224, Regularization: 1.322529\n",
      "2019-04-09 22:43:47,566 root         INFO     Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 2.184827\n",
      "Reconstruction: 0.525088, Regularization: 1.659738\n",
      "2019-04-09 22:43:47,620 root         INFO     Train Epoch: 185 [6656/8000 (83%)]\tTotal Loss: 1.736547\n",
      "Reconstruction: 0.348976, Regularization: 1.387570\n",
      "2019-04-09 22:43:47,674 root         INFO     Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 1.944514\n",
      "Reconstruction: 0.375191, Regularization: 1.569322\n",
      "2019-04-09 22:43:47,729 root         INFO     Train Epoch: 185 [7680/8000 (96%)]\tTotal Loss: 1.588376\n",
      "Reconstruction: 0.144214, Regularization: 1.444162\n",
      "2019-04-09 22:43:47,777 root         INFO     ====> Epoch: 185 Average loss: 1.8427\n",
      "2019-04-09 22:43:47,801 root         INFO     Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 1.381082\n",
      "Reconstruction: 0.354422, Regularization: 1.026661\n",
      "2019-04-09 22:43:47,857 root         INFO     Train Epoch: 186 [512/8000 (6%)]\tTotal Loss: 1.859599\n",
      "Reconstruction: 0.518969, Regularization: 1.340630\n",
      "2019-04-09 22:43:47,912 root         INFO     Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 2.665135\n",
      "Reconstruction: 0.918702, Regularization: 1.746433\n",
      "2019-04-09 22:43:47,968 root         INFO     Train Epoch: 186 [1536/8000 (19%)]\tTotal Loss: 1.648767\n",
      "Reconstruction: 0.358750, Regularization: 1.290016\n",
      "2019-04-09 22:43:48,023 root         INFO     Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 1.263136\n",
      "Reconstruction: 0.346169, Regularization: 0.916968\n",
      "2019-04-09 22:43:48,079 root         INFO     Train Epoch: 186 [2560/8000 (32%)]\tTotal Loss: 1.845185\n",
      "Reconstruction: 0.379377, Regularization: 1.465807\n",
      "2019-04-09 22:43:48,134 root         INFO     Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 2.118599\n",
      "Reconstruction: 0.890420, Regularization: 1.228179\n",
      "2019-04-09 22:43:48,190 root         INFO     Train Epoch: 186 [3584/8000 (45%)]\tTotal Loss: 2.150223\n",
      "Reconstruction: 0.855043, Regularization: 1.295179\n",
      "2019-04-09 22:43:48,245 root         INFO     Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 1.557802\n",
      "Reconstruction: 0.344722, Regularization: 1.213081\n",
      "2019-04-09 22:43:48,299 root         INFO     Train Epoch: 186 [4608/8000 (58%)]\tTotal Loss: 1.410391\n",
      "Reconstruction: 0.262126, Regularization: 1.148264\n",
      "2019-04-09 22:43:48,353 root         INFO     Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 2.589469\n",
      "Reconstruction: 0.624624, Regularization: 1.964845\n",
      "2019-04-09 22:43:48,407 root         INFO     Train Epoch: 186 [5632/8000 (70%)]\tTotal Loss: 2.309634\n",
      "Reconstruction: 0.357805, Regularization: 1.951829\n",
      "2019-04-09 22:43:48,463 root         INFO     Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 2.342369\n",
      "Reconstruction: 0.340128, Regularization: 2.002241\n",
      "2019-04-09 22:43:48,518 root         INFO     Train Epoch: 186 [6656/8000 (83%)]\tTotal Loss: 2.456484\n",
      "Reconstruction: 0.574298, Regularization: 1.882186\n",
      "2019-04-09 22:43:48,574 root         INFO     Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 2.587935\n",
      "Reconstruction: 0.760309, Regularization: 1.827627\n",
      "2019-04-09 22:43:48,631 root         INFO     Train Epoch: 186 [7680/8000 (96%)]\tTotal Loss: 1.407632\n",
      "Reconstruction: 0.267852, Regularization: 1.139780\n",
      "2019-04-09 22:43:48,681 root         INFO     ====> Epoch: 186 Average loss: 1.8051\n",
      "2019-04-09 22:43:48,704 root         INFO     Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 1.050209\n",
      "Reconstruction: 0.180833, Regularization: 0.869376\n",
      "2019-04-09 22:43:48,761 root         INFO     Train Epoch: 187 [512/8000 (6%)]\tTotal Loss: 2.385134\n",
      "Reconstruction: 0.752498, Regularization: 1.632636\n",
      "2019-04-09 22:43:48,818 root         INFO     Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 2.508262\n",
      "Reconstruction: 0.614273, Regularization: 1.893989\n",
      "2019-04-09 22:43:48,876 root         INFO     Train Epoch: 187 [1536/8000 (19%)]\tTotal Loss: 1.209715\n",
      "Reconstruction: 0.236245, Regularization: 0.973470\n",
      "2019-04-09 22:43:48,933 root         INFO     Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 1.289507\n",
      "Reconstruction: 0.171713, Regularization: 1.117794\n",
      "2019-04-09 22:43:48,989 root         INFO     Train Epoch: 187 [2560/8000 (32%)]\tTotal Loss: 1.512254\n",
      "Reconstruction: 0.324091, Regularization: 1.188163\n",
      "2019-04-09 22:43:49,045 root         INFO     Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 1.897614\n",
      "Reconstruction: 0.332852, Regularization: 1.564762\n",
      "2019-04-09 22:43:49,100 root         INFO     Train Epoch: 187 [3584/8000 (45%)]\tTotal Loss: 1.454237\n",
      "Reconstruction: 0.333789, Regularization: 1.120448\n",
      "2019-04-09 22:43:49,156 root         INFO     Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 2.171975\n",
      "Reconstruction: 0.311579, Regularization: 1.860396\n",
      "2019-04-09 22:43:49,211 root         INFO     Train Epoch: 187 [4608/8000 (58%)]\tTotal Loss: 1.313561\n",
      "Reconstruction: 0.377102, Regularization: 0.936459\n",
      "2019-04-09 22:43:49,266 root         INFO     Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 1.509453\n",
      "Reconstruction: 0.200733, Regularization: 1.308721\n",
      "2019-04-09 22:43:49,321 root         INFO     Train Epoch: 187 [5632/8000 (70%)]\tTotal Loss: 1.061773\n",
      "Reconstruction: 0.216104, Regularization: 0.845669\n",
      "2019-04-09 22:43:49,376 root         INFO     Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 1.680153\n",
      "Reconstruction: 0.318360, Regularization: 1.361793\n",
      "2019-04-09 22:43:49,431 root         INFO     Train Epoch: 187 [6656/8000 (83%)]\tTotal Loss: 2.746805\n",
      "Reconstruction: 0.396927, Regularization: 2.349879\n",
      "2019-04-09 22:43:49,486 root         INFO     Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 1.358464\n",
      "Reconstruction: 0.328041, Regularization: 1.030423\n",
      "2019-04-09 22:43:49,541 root         INFO     Train Epoch: 187 [7680/8000 (96%)]\tTotal Loss: 1.113890\n",
      "Reconstruction: 0.279162, Regularization: 0.834728\n",
      "2019-04-09 22:43:49,590 root         INFO     ====> Epoch: 187 Average loss: 1.7698\n",
      "2019-04-09 22:43:49,614 root         INFO     Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 1.416197\n",
      "Reconstruction: 0.303456, Regularization: 1.112741\n",
      "2019-04-09 22:43:49,669 root         INFO     Train Epoch: 188 [512/8000 (6%)]\tTotal Loss: 1.539645\n",
      "Reconstruction: 0.253007, Regularization: 1.286638\n",
      "2019-04-09 22:43:49,723 root         INFO     Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 1.656002\n",
      "Reconstruction: 0.477201, Regularization: 1.178801\n",
      "2019-04-09 22:43:49,778 root         INFO     Train Epoch: 188 [1536/8000 (19%)]\tTotal Loss: 1.211799\n",
      "Reconstruction: 0.241282, Regularization: 0.970517\n",
      "2019-04-09 22:43:49,832 root         INFO     Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 3.133663\n",
      "Reconstruction: 1.046662, Regularization: 2.087001\n",
      "2019-04-09 22:43:49,887 root         INFO     Train Epoch: 188 [2560/8000 (32%)]\tTotal Loss: 2.411910\n",
      "Reconstruction: 0.964336, Regularization: 1.447574\n",
      "2019-04-09 22:43:49,941 root         INFO     Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 1.790444\n",
      "Reconstruction: 0.265521, Regularization: 1.524923\n",
      "2019-04-09 22:43:49,996 root         INFO     Train Epoch: 188 [3584/8000 (45%)]\tTotal Loss: 1.946777\n",
      "Reconstruction: 0.185800, Regularization: 1.760977\n",
      "2019-04-09 22:43:50,050 root         INFO     Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 1.414193\n",
      "Reconstruction: 0.317044, Regularization: 1.097149\n",
      "2019-04-09 22:43:50,104 root         INFO     Train Epoch: 188 [4608/8000 (58%)]\tTotal Loss: 2.497809\n",
      "Reconstruction: 0.420839, Regularization: 2.076970\n",
      "2019-04-09 22:43:50,158 root         INFO     Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 1.636851\n",
      "Reconstruction: 0.309600, Regularization: 1.327251\n",
      "2019-04-09 22:43:50,212 root         INFO     Train Epoch: 188 [5632/8000 (70%)]\tTotal Loss: 2.144662\n",
      "Reconstruction: 0.988456, Regularization: 1.156206\n",
      "2019-04-09 22:43:50,267 root         INFO     Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 2.300165\n",
      "Reconstruction: 0.778402, Regularization: 1.521763\n",
      "2019-04-09 22:43:50,321 root         INFO     Train Epoch: 188 [6656/8000 (83%)]\tTotal Loss: 0.958962\n",
      "Reconstruction: 0.246282, Regularization: 0.712681\n",
      "2019-04-09 22:43:50,375 root         INFO     Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 1.893684\n",
      "Reconstruction: 0.594876, Regularization: 1.298808\n",
      "2019-04-09 22:43:50,429 root         INFO     Train Epoch: 188 [7680/8000 (96%)]\tTotal Loss: 1.379049\n",
      "Reconstruction: 0.261015, Regularization: 1.118034\n",
      "2019-04-09 22:43:50,478 root         INFO     ====> Epoch: 188 Average loss: 1.7372\n",
      "2019-04-09 22:43:50,501 root         INFO     Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 1.820822\n",
      "Reconstruction: 0.326090, Regularization: 1.494732\n",
      "2019-04-09 22:43:50,556 root         INFO     Train Epoch: 189 [512/8000 (6%)]\tTotal Loss: 2.014212\n",
      "Reconstruction: 0.408515, Regularization: 1.605697\n",
      "2019-04-09 22:43:50,610 root         INFO     Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 2.322411\n",
      "Reconstruction: 0.542232, Regularization: 1.780180\n",
      "2019-04-09 22:43:50,665 root         INFO     Train Epoch: 189 [1536/8000 (19%)]\tTotal Loss: 1.625427\n",
      "Reconstruction: 0.294377, Regularization: 1.331050\n",
      "2019-04-09 22:43:50,719 root         INFO     Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 1.643186\n",
      "Reconstruction: 0.360354, Regularization: 1.282831\n",
      "2019-04-09 22:43:50,773 root         INFO     Train Epoch: 189 [2560/8000 (32%)]\tTotal Loss: 2.495032\n",
      "Reconstruction: 0.779688, Regularization: 1.715344\n",
      "2019-04-09 22:43:50,827 root         INFO     Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 1.718315\n",
      "Reconstruction: 0.477996, Regularization: 1.240319\n",
      "2019-04-09 22:43:50,880 root         INFO     Train Epoch: 189 [3584/8000 (45%)]\tTotal Loss: 1.548273\n",
      "Reconstruction: 0.452460, Regularization: 1.095813\n",
      "2019-04-09 22:43:50,934 root         INFO     Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 1.477397\n",
      "Reconstruction: 0.222231, Regularization: 1.255166\n",
      "2019-04-09 22:43:50,988 root         INFO     Train Epoch: 189 [4608/8000 (58%)]\tTotal Loss: 1.049146\n",
      "Reconstruction: 0.330286, Regularization: 0.718861\n",
      "2019-04-09 22:43:51,041 root         INFO     Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 1.490254\n",
      "Reconstruction: 0.367311, Regularization: 1.122943\n",
      "2019-04-09 22:43:51,095 root         INFO     Train Epoch: 189 [5632/8000 (70%)]\tTotal Loss: 2.204310\n",
      "Reconstruction: 0.633289, Regularization: 1.571021\n",
      "2019-04-09 22:43:51,149 root         INFO     Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 1.518742\n",
      "Reconstruction: 0.342232, Regularization: 1.176511\n",
      "2019-04-09 22:43:51,202 root         INFO     Train Epoch: 189 [6656/8000 (83%)]\tTotal Loss: 2.160521\n",
      "Reconstruction: 0.355762, Regularization: 1.804759\n",
      "2019-04-09 22:43:51,256 root         INFO     Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 1.063195\n",
      "Reconstruction: 0.171206, Regularization: 0.891989\n",
      "2019-04-09 22:43:51,310 root         INFO     Train Epoch: 189 [7680/8000 (96%)]\tTotal Loss: 1.582650\n",
      "Reconstruction: 0.367451, Regularization: 1.215199\n",
      "2019-04-09 22:43:51,358 root         INFO     ====> Epoch: 189 Average loss: 1.7061\n",
      "2019-04-09 22:43:51,381 root         INFO     Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 1.397434\n",
      "Reconstruction: 0.195082, Regularization: 1.202352\n",
      "2019-04-09 22:43:51,437 root         INFO     Train Epoch: 190 [512/8000 (6%)]\tTotal Loss: 0.978262\n",
      "Reconstruction: 0.259433, Regularization: 0.718828\n",
      "2019-04-09 22:43:51,493 root         INFO     Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 1.476017\n",
      "Reconstruction: 0.352187, Regularization: 1.123830\n",
      "2019-04-09 22:43:51,547 root         INFO     Train Epoch: 190 [1536/8000 (19%)]\tTotal Loss: 1.985027\n",
      "Reconstruction: 0.477831, Regularization: 1.507196\n",
      "2019-04-09 22:43:51,601 root         INFO     Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 1.406190\n",
      "Reconstruction: 0.320874, Regularization: 1.085317\n",
      "2019-04-09 22:43:51,655 root         INFO     Train Epoch: 190 [2560/8000 (32%)]\tTotal Loss: 1.482722\n",
      "Reconstruction: 0.373106, Regularization: 1.109617\n",
      "2019-04-09 22:43:51,709 root         INFO     Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 1.741891\n",
      "Reconstruction: 0.263877, Regularization: 1.478013\n",
      "2019-04-09 22:43:51,763 root         INFO     Train Epoch: 190 [3584/8000 (45%)]\tTotal Loss: 1.403348\n",
      "Reconstruction: 0.301798, Regularization: 1.101550\n",
      "2019-04-09 22:43:51,817 root         INFO     Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 1.863784\n",
      "Reconstruction: 0.323570, Regularization: 1.540214\n",
      "2019-04-09 22:43:51,872 root         INFO     Train Epoch: 190 [4608/8000 (58%)]\tTotal Loss: 1.902461\n",
      "Reconstruction: 0.379481, Regularization: 1.522980\n",
      "2019-04-09 22:43:51,926 root         INFO     Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 1.623954\n",
      "Reconstruction: 0.317940, Regularization: 1.306014\n",
      "2019-04-09 22:43:51,980 root         INFO     Train Epoch: 190 [5632/8000 (70%)]\tTotal Loss: 1.025167\n",
      "Reconstruction: 0.280342, Regularization: 0.744825\n",
      "2019-04-09 22:43:52,034 root         INFO     Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 1.799254\n",
      "Reconstruction: 0.307906, Regularization: 1.491348\n",
      "2019-04-09 22:43:52,088 root         INFO     Train Epoch: 190 [6656/8000 (83%)]\tTotal Loss: 1.374103\n",
      "Reconstruction: 0.344781, Regularization: 1.029322\n",
      "2019-04-09 22:43:52,143 root         INFO     Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 1.799558\n",
      "Reconstruction: 0.322636, Regularization: 1.476922\n",
      "2019-04-09 22:43:52,197 root         INFO     Train Epoch: 190 [7680/8000 (96%)]\tTotal Loss: 1.577316\n",
      "Reconstruction: 0.404030, Regularization: 1.173287\n",
      "2019-04-09 22:43:52,246 root         INFO     ====> Epoch: 190 Average loss: 1.6762\n",
      "2019-04-09 22:43:52,269 root         INFO     Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 1.883076\n",
      "Reconstruction: 0.447674, Regularization: 1.435403\n",
      "2019-04-09 22:43:52,323 root         INFO     Train Epoch: 191 [512/8000 (6%)]\tTotal Loss: 1.627902\n",
      "Reconstruction: 0.311709, Regularization: 1.316193\n",
      "2019-04-09 22:43:52,378 root         INFO     Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 2.172286\n",
      "Reconstruction: 0.665868, Regularization: 1.506418\n",
      "2019-04-09 22:43:52,433 root         INFO     Train Epoch: 191 [1536/8000 (19%)]\tTotal Loss: 2.593527\n",
      "Reconstruction: 0.402709, Regularization: 2.190818\n",
      "2019-04-09 22:43:52,487 root         INFO     Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 1.372461\n",
      "Reconstruction: 0.196608, Regularization: 1.175853\n",
      "2019-04-09 22:43:52,543 root         INFO     Train Epoch: 191 [2560/8000 (32%)]\tTotal Loss: 1.346532\n",
      "Reconstruction: 0.330161, Regularization: 1.016371\n",
      "2019-04-09 22:43:52,598 root         INFO     Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 2.512939\n",
      "Reconstruction: 0.804780, Regularization: 1.708159\n",
      "2019-04-09 22:43:52,653 root         INFO     Train Epoch: 191 [3584/8000 (45%)]\tTotal Loss: 1.601628\n",
      "Reconstruction: 0.303064, Regularization: 1.298564\n",
      "2019-04-09 22:43:52,708 root         INFO     Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 1.784772\n",
      "Reconstruction: 0.201982, Regularization: 1.582789\n",
      "2019-04-09 22:43:52,763 root         INFO     Train Epoch: 191 [4608/8000 (58%)]\tTotal Loss: 1.671321\n",
      "Reconstruction: 0.257697, Regularization: 1.413624\n",
      "2019-04-09 22:43:52,818 root         INFO     Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 1.280439\n",
      "Reconstruction: 0.300281, Regularization: 0.980158\n",
      "2019-04-09 22:43:52,873 root         INFO     Train Epoch: 191 [5632/8000 (70%)]\tTotal Loss: 1.755953\n",
      "Reconstruction: 0.221832, Regularization: 1.534121\n",
      "2019-04-09 22:43:52,927 root         INFO     Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 1.359573\n",
      "Reconstruction: 0.294042, Regularization: 1.065531\n",
      "2019-04-09 22:43:52,982 root         INFO     Train Epoch: 191 [6656/8000 (83%)]\tTotal Loss: 1.683424\n",
      "Reconstruction: 0.289350, Regularization: 1.394075\n",
      "2019-04-09 22:43:53,037 root         INFO     Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 1.480002\n",
      "Reconstruction: 0.315018, Regularization: 1.164984\n",
      "2019-04-09 22:43:53,092 root         INFO     Train Epoch: 191 [7680/8000 (96%)]\tTotal Loss: 1.438176\n",
      "Reconstruction: 0.276741, Regularization: 1.161436\n",
      "2019-04-09 22:43:53,141 root         INFO     ====> Epoch: 191 Average loss: 1.6473\n",
      "2019-04-09 22:43:53,164 root         INFO     Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 2.016476\n",
      "Reconstruction: 0.290242, Regularization: 1.726235\n",
      "2019-04-09 22:43:53,219 root         INFO     Train Epoch: 192 [512/8000 (6%)]\tTotal Loss: 1.165825\n",
      "Reconstruction: 0.220984, Regularization: 0.944841\n",
      "2019-04-09 22:43:53,274 root         INFO     Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 2.270184\n",
      "Reconstruction: 0.288029, Regularization: 1.982154\n",
      "2019-04-09 22:43:53,329 root         INFO     Train Epoch: 192 [1536/8000 (19%)]\tTotal Loss: 1.762432\n",
      "Reconstruction: 0.233065, Regularization: 1.529367\n",
      "2019-04-09 22:43:53,384 root         INFO     Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.684451\n",
      "Reconstruction: 0.226598, Regularization: 0.457853\n",
      "2019-04-09 22:43:53,439 root         INFO     Train Epoch: 192 [2560/8000 (32%)]\tTotal Loss: 1.914698\n",
      "Reconstruction: 0.452234, Regularization: 1.462464\n",
      "2019-04-09 22:43:53,494 root         INFO     Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 1.228462\n",
      "Reconstruction: 0.276165, Regularization: 0.952297\n",
      "2019-04-09 22:43:53,549 root         INFO     Train Epoch: 192 [3584/8000 (45%)]\tTotal Loss: 2.005971\n",
      "Reconstruction: 0.381757, Regularization: 1.624214\n",
      "2019-04-09 22:43:53,604 root         INFO     Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 1.053078\n",
      "Reconstruction: 0.293343, Regularization: 0.759735\n",
      "2019-04-09 22:43:53,658 root         INFO     Train Epoch: 192 [4608/8000 (58%)]\tTotal Loss: 2.200176\n",
      "Reconstruction: 0.311693, Regularization: 1.888483\n",
      "2019-04-09 22:43:53,713 root         INFO     Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 1.547030\n",
      "Reconstruction: 0.313389, Regularization: 1.233641\n",
      "2019-04-09 22:43:53,769 root         INFO     Train Epoch: 192 [5632/8000 (70%)]\tTotal Loss: 1.468674\n",
      "Reconstruction: 0.362292, Regularization: 1.106382\n",
      "2019-04-09 22:43:53,823 root         INFO     Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 1.737618\n",
      "Reconstruction: 0.254451, Regularization: 1.483166\n",
      "2019-04-09 22:43:53,878 root         INFO     Train Epoch: 192 [6656/8000 (83%)]\tTotal Loss: 1.763632\n",
      "Reconstruction: 0.348141, Regularization: 1.415491\n",
      "2019-04-09 22:43:53,933 root         INFO     Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 1.362462\n",
      "Reconstruction: 0.270068, Regularization: 1.092394\n",
      "2019-04-09 22:43:53,988 root         INFO     Train Epoch: 192 [7680/8000 (96%)]\tTotal Loss: 1.195347\n",
      "Reconstruction: 0.198053, Regularization: 0.997294\n",
      "2019-04-09 22:43:54,037 root         INFO     ====> Epoch: 192 Average loss: 1.6194\n",
      "2019-04-09 22:43:54,060 root         INFO     Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 1.748208\n",
      "Reconstruction: 0.289221, Regularization: 1.458987\n",
      "2019-04-09 22:43:54,115 root         INFO     Train Epoch: 193 [512/8000 (6%)]\tTotal Loss: 2.115380\n",
      "Reconstruction: 0.259811, Regularization: 1.855569\n",
      "2019-04-09 22:43:54,170 root         INFO     Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 1.544224\n",
      "Reconstruction: 0.214339, Regularization: 1.329885\n",
      "2019-04-09 22:43:54,225 root         INFO     Train Epoch: 193 [1536/8000 (19%)]\tTotal Loss: 1.683660\n",
      "Reconstruction: 0.373036, Regularization: 1.310624\n",
      "2019-04-09 22:43:54,280 root         INFO     Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 1.194041\n",
      "Reconstruction: 0.390414, Regularization: 0.803627\n",
      "2019-04-09 22:43:54,335 root         INFO     Train Epoch: 193 [2560/8000 (32%)]\tTotal Loss: 1.377175\n",
      "Reconstruction: 0.370536, Regularization: 1.006639\n",
      "2019-04-09 22:43:54,390 root         INFO     Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 1.992245\n",
      "Reconstruction: 0.444797, Regularization: 1.547447\n",
      "2019-04-09 22:43:54,444 root         INFO     Train Epoch: 193 [3584/8000 (45%)]\tTotal Loss: 1.406108\n",
      "Reconstruction: 0.267857, Regularization: 1.138251\n",
      "2019-04-09 22:43:54,499 root         INFO     Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 1.919790\n",
      "Reconstruction: 0.543347, Regularization: 1.376443\n",
      "2019-04-09 22:43:54,554 root         INFO     Train Epoch: 193 [4608/8000 (58%)]\tTotal Loss: 1.494244\n",
      "Reconstruction: 0.250553, Regularization: 1.243691\n",
      "2019-04-09 22:43:54,608 root         INFO     Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 1.324167\n",
      "Reconstruction: 0.352226, Regularization: 0.971940\n",
      "2019-04-09 22:43:54,663 root         INFO     Train Epoch: 193 [5632/8000 (70%)]\tTotal Loss: 1.507894\n",
      "Reconstruction: 0.213508, Regularization: 1.294386\n",
      "2019-04-09 22:43:54,718 root         INFO     Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 1.071669\n",
      "Reconstruction: 0.188197, Regularization: 0.883472\n",
      "2019-04-09 22:43:54,773 root         INFO     Train Epoch: 193 [6656/8000 (83%)]\tTotal Loss: 1.434124\n",
      "Reconstruction: 0.247023, Regularization: 1.187102\n",
      "2019-04-09 22:43:54,827 root         INFO     Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 1.512557\n",
      "Reconstruction: 0.196914, Regularization: 1.315643\n",
      "2019-04-09 22:43:54,882 root         INFO     Train Epoch: 193 [7680/8000 (96%)]\tTotal Loss: 1.971287\n",
      "Reconstruction: 0.411159, Regularization: 1.560127\n",
      "2019-04-09 22:43:54,932 root         INFO     ====> Epoch: 193 Average loss: 1.5925\n",
      "2019-04-09 22:43:54,955 root         INFO     Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 1.363866\n",
      "Reconstruction: 0.203297, Regularization: 1.160568\n",
      "2019-04-09 22:43:55,009 root         INFO     Train Epoch: 194 [512/8000 (6%)]\tTotal Loss: 1.298945\n",
      "Reconstruction: 0.249906, Regularization: 1.049039\n",
      "2019-04-09 22:43:55,062 root         INFO     Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 1.621282\n",
      "Reconstruction: 0.284994, Regularization: 1.336288\n",
      "2019-04-09 22:43:55,116 root         INFO     Train Epoch: 194 [1536/8000 (19%)]\tTotal Loss: 1.462070\n",
      "Reconstruction: 0.286313, Regularization: 1.175758\n",
      "2019-04-09 22:43:55,170 root         INFO     Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 1.337056\n",
      "Reconstruction: 0.242764, Regularization: 1.094292\n",
      "2019-04-09 22:43:55,224 root         INFO     Train Epoch: 194 [2560/8000 (32%)]\tTotal Loss: 1.874856\n",
      "Reconstruction: 0.352794, Regularization: 1.522062\n",
      "2019-04-09 22:43:55,278 root         INFO     Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 2.255605\n",
      "Reconstruction: 0.317610, Regularization: 1.937995\n",
      "2019-04-09 22:43:55,332 root         INFO     Train Epoch: 194 [3584/8000 (45%)]\tTotal Loss: 1.297341\n",
      "Reconstruction: 0.390956, Regularization: 0.906385\n",
      "2019-04-09 22:43:55,386 root         INFO     Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 1.597445\n",
      "Reconstruction: 0.241966, Regularization: 1.355479\n",
      "2019-04-09 22:43:55,440 root         INFO     Train Epoch: 194 [4608/8000 (58%)]\tTotal Loss: 1.760386\n",
      "Reconstruction: 0.283699, Regularization: 1.476688\n",
      "2019-04-09 22:43:55,493 root         INFO     Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 1.283418\n",
      "Reconstruction: 0.282338, Regularization: 1.001080\n",
      "2019-04-09 22:43:55,547 root         INFO     Train Epoch: 194 [5632/8000 (70%)]\tTotal Loss: 1.393692\n",
      "Reconstruction: 0.253587, Regularization: 1.140105\n",
      "2019-04-09 22:43:55,601 root         INFO     Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 1.491125\n",
      "Reconstruction: 0.309776, Regularization: 1.181349\n",
      "2019-04-09 22:43:55,655 root         INFO     Train Epoch: 194 [6656/8000 (83%)]\tTotal Loss: 1.789647\n",
      "Reconstruction: 0.363783, Regularization: 1.425864\n",
      "2019-04-09 22:43:55,708 root         INFO     Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 1.790792\n",
      "Reconstruction: 0.242071, Regularization: 1.548721\n",
      "2019-04-09 22:43:55,763 root         INFO     Train Epoch: 194 [7680/8000 (96%)]\tTotal Loss: 1.232149\n",
      "Reconstruction: 0.381340, Regularization: 0.850809\n",
      "2019-04-09 22:43:55,811 root         INFO     ====> Epoch: 194 Average loss: 1.5655\n",
      "2019-04-09 22:43:55,834 root         INFO     Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 1.435103\n",
      "Reconstruction: 0.322631, Regularization: 1.112472\n",
      "2019-04-09 22:43:55,888 root         INFO     Train Epoch: 195 [512/8000 (6%)]\tTotal Loss: 1.448550\n",
      "Reconstruction: 0.174651, Regularization: 1.273900\n",
      "2019-04-09 22:43:55,942 root         INFO     Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 1.200381\n",
      "Reconstruction: 0.184650, Regularization: 1.015731\n",
      "2019-04-09 22:43:55,996 root         INFO     Train Epoch: 195 [1536/8000 (19%)]\tTotal Loss: 2.339296\n",
      "Reconstruction: 0.534655, Regularization: 1.804641\n",
      "2019-04-09 22:43:56,050 root         INFO     Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 2.109663\n",
      "Reconstruction: 0.220278, Regularization: 1.889385\n",
      "2019-04-09 22:43:56,104 root         INFO     Train Epoch: 195 [2560/8000 (32%)]\tTotal Loss: 1.598604\n",
      "Reconstruction: 0.389657, Regularization: 1.208948\n",
      "2019-04-09 22:43:56,158 root         INFO     Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 1.589275\n",
      "Reconstruction: 0.210051, Regularization: 1.379224\n",
      "2019-04-09 22:43:56,211 root         INFO     Train Epoch: 195 [3584/8000 (45%)]\tTotal Loss: 1.330541\n",
      "Reconstruction: 0.198150, Regularization: 1.132392\n",
      "2019-04-09 22:43:56,265 root         INFO     Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 1.041919\n",
      "Reconstruction: 0.290280, Regularization: 0.751639\n",
      "2019-04-09 22:43:56,319 root         INFO     Train Epoch: 195 [4608/8000 (58%)]\tTotal Loss: 1.193043\n",
      "Reconstruction: 0.231144, Regularization: 0.961899\n",
      "2019-04-09 22:43:56,373 root         INFO     Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 1.563906\n",
      "Reconstruction: 0.332586, Regularization: 1.231320\n",
      "2019-04-09 22:43:56,428 root         INFO     Train Epoch: 195 [5632/8000 (70%)]\tTotal Loss: 1.157791\n",
      "Reconstruction: 0.163526, Regularization: 0.994266\n",
      "2019-04-09 22:43:56,483 root         INFO     Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 1.192591\n",
      "Reconstruction: 0.301299, Regularization: 0.891292\n",
      "2019-04-09 22:43:56,537 root         INFO     Train Epoch: 195 [6656/8000 (83%)]\tTotal Loss: 1.475392\n",
      "Reconstruction: 0.286582, Regularization: 1.188810\n",
      "2019-04-09 22:43:56,592 root         INFO     Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 1.310916\n",
      "Reconstruction: 0.231035, Regularization: 1.079882\n",
      "2019-04-09 22:43:56,646 root         INFO     Train Epoch: 195 [7680/8000 (96%)]\tTotal Loss: 1.081971\n",
      "Reconstruction: 0.224659, Regularization: 0.857312\n",
      "2019-04-09 22:43:56,694 root         INFO     ====> Epoch: 195 Average loss: 1.5386\n",
      "2019-04-09 22:43:56,718 root         INFO     Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 2.530468\n",
      "Reconstruction: 0.268273, Regularization: 2.262195\n",
      "2019-04-09 22:43:56,773 root         INFO     Train Epoch: 196 [512/8000 (6%)]\tTotal Loss: 1.374488\n",
      "Reconstruction: 0.188103, Regularization: 1.186385\n",
      "2019-04-09 22:43:56,827 root         INFO     Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 2.448356\n",
      "Reconstruction: 0.443554, Regularization: 2.004803\n",
      "2019-04-09 22:43:56,881 root         INFO     Train Epoch: 196 [1536/8000 (19%)]\tTotal Loss: 1.851748\n",
      "Reconstruction: 0.253119, Regularization: 1.598630\n",
      "2019-04-09 22:43:56,936 root         INFO     Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 1.850605\n",
      "Reconstruction: 0.263279, Regularization: 1.587326\n",
      "2019-04-09 22:43:56,990 root         INFO     Train Epoch: 196 [2560/8000 (32%)]\tTotal Loss: 1.414281\n",
      "Reconstruction: 0.250634, Regularization: 1.163646\n",
      "2019-04-09 22:43:57,045 root         INFO     Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 1.333252\n",
      "Reconstruction: 0.265236, Regularization: 1.068016\n",
      "2019-04-09 22:43:57,100 root         INFO     Train Epoch: 196 [3584/8000 (45%)]\tTotal Loss: 1.459686\n",
      "Reconstruction: 0.319735, Regularization: 1.139951\n",
      "2019-04-09 22:43:57,154 root         INFO     Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 1.236594\n",
      "Reconstruction: 0.261644, Regularization: 0.974950\n",
      "2019-04-09 22:43:57,209 root         INFO     Train Epoch: 196 [4608/8000 (58%)]\tTotal Loss: 1.310209\n",
      "Reconstruction: 0.240632, Regularization: 1.069577\n",
      "2019-04-09 22:43:57,264 root         INFO     Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 1.657162\n",
      "Reconstruction: 0.257023, Regularization: 1.400139\n",
      "2019-04-09 22:43:57,318 root         INFO     Train Epoch: 196 [5632/8000 (70%)]\tTotal Loss: 1.695439\n",
      "Reconstruction: 0.161768, Regularization: 1.533672\n",
      "2019-04-09 22:43:57,374 root         INFO     Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 1.729349\n",
      "Reconstruction: 0.201289, Regularization: 1.528059\n",
      "2019-04-09 22:43:57,430 root         INFO     Train Epoch: 196 [6656/8000 (83%)]\tTotal Loss: 1.201087\n",
      "Reconstruction: 0.203775, Regularization: 0.997312\n",
      "2019-04-09 22:43:57,486 root         INFO     Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 1.662917\n",
      "Reconstruction: 0.298479, Regularization: 1.364438\n",
      "2019-04-09 22:43:57,539 root         INFO     Train Epoch: 196 [7680/8000 (96%)]\tTotal Loss: 1.227178\n",
      "Reconstruction: 0.283279, Regularization: 0.943899\n",
      "2019-04-09 22:43:57,588 root         INFO     ====> Epoch: 196 Average loss: 1.5113\n",
      "2019-04-09 22:43:57,611 root         INFO     Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 1.241183\n",
      "Reconstruction: 0.218345, Regularization: 1.022838\n",
      "2019-04-09 22:43:57,666 root         INFO     Train Epoch: 197 [512/8000 (6%)]\tTotal Loss: 1.489294\n",
      "Reconstruction: 0.271650, Regularization: 1.217644\n",
      "2019-04-09 22:43:57,722 root         INFO     Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 1.156371\n",
      "Reconstruction: 0.274714, Regularization: 0.881657\n",
      "2019-04-09 22:43:57,777 root         INFO     Train Epoch: 197 [1536/8000 (19%)]\tTotal Loss: 1.496889\n",
      "Reconstruction: 0.251716, Regularization: 1.245173\n",
      "2019-04-09 22:43:57,832 root         INFO     Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 1.765855\n",
      "Reconstruction: 0.235399, Regularization: 1.530456\n",
      "2019-04-09 22:43:57,887 root         INFO     Train Epoch: 197 [2560/8000 (32%)]\tTotal Loss: 1.335785\n",
      "Reconstruction: 0.207195, Regularization: 1.128590\n",
      "2019-04-09 22:43:57,942 root         INFO     Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 1.102123\n",
      "Reconstruction: 0.221776, Regularization: 0.880347\n",
      "2019-04-09 22:43:57,997 root         INFO     Train Epoch: 197 [3584/8000 (45%)]\tTotal Loss: 1.448455\n",
      "Reconstruction: 0.291581, Regularization: 1.156873\n",
      "2019-04-09 22:43:58,052 root         INFO     Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 1.334507\n",
      "Reconstruction: 0.164050, Regularization: 1.170457\n",
      "2019-04-09 22:43:58,106 root         INFO     Train Epoch: 197 [4608/8000 (58%)]\tTotal Loss: 1.316983\n",
      "Reconstruction: 0.199593, Regularization: 1.117389\n",
      "2019-04-09 22:43:58,161 root         INFO     Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 1.517479\n",
      "Reconstruction: 0.239506, Regularization: 1.277973\n",
      "2019-04-09 22:43:58,216 root         INFO     Train Epoch: 197 [5632/8000 (70%)]\tTotal Loss: 1.436857\n",
      "Reconstruction: 0.231786, Regularization: 1.205072\n",
      "2019-04-09 22:43:58,270 root         INFO     Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 1.095168\n",
      "Reconstruction: 0.223716, Regularization: 0.871452\n",
      "2019-04-09 22:43:58,325 root         INFO     Train Epoch: 197 [6656/8000 (83%)]\tTotal Loss: 1.822842\n",
      "Reconstruction: 0.324254, Regularization: 1.498588\n",
      "2019-04-09 22:43:58,380 root         INFO     Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 1.397835\n",
      "Reconstruction: 0.188419, Regularization: 1.209416\n",
      "2019-04-09 22:43:58,435 root         INFO     Train Epoch: 197 [7680/8000 (96%)]\tTotal Loss: 1.819108\n",
      "Reconstruction: 0.232267, Regularization: 1.586840\n",
      "2019-04-09 22:43:58,484 root         INFO     ====> Epoch: 197 Average loss: 1.4838\n",
      "2019-04-09 22:43:58,507 root         INFO     Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 1.547806\n",
      "Reconstruction: 0.261419, Regularization: 1.286387\n",
      "2019-04-09 22:43:58,562 root         INFO     Train Epoch: 198 [512/8000 (6%)]\tTotal Loss: 1.628084\n",
      "Reconstruction: 0.288922, Regularization: 1.339162\n",
      "2019-04-09 22:43:58,618 root         INFO     Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.818948\n",
      "Reconstruction: 0.202418, Regularization: 0.616529\n",
      "2019-04-09 22:43:58,674 root         INFO     Train Epoch: 198 [1536/8000 (19%)]\tTotal Loss: 1.857171\n",
      "Reconstruction: 0.222053, Regularization: 1.635118\n",
      "2019-04-09 22:43:58,731 root         INFO     Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 1.054891\n",
      "Reconstruction: 0.216839, Regularization: 0.838052\n",
      "2019-04-09 22:43:58,788 root         INFO     Train Epoch: 198 [2560/8000 (32%)]\tTotal Loss: 1.397283\n",
      "Reconstruction: 0.205999, Regularization: 1.191284\n",
      "2019-04-09 22:43:58,845 root         INFO     Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 1.206566\n",
      "Reconstruction: 0.236808, Regularization: 0.969757\n",
      "2019-04-09 22:43:58,902 root         INFO     Train Epoch: 198 [3584/8000 (45%)]\tTotal Loss: 1.490531\n",
      "Reconstruction: 0.213145, Regularization: 1.277386\n",
      "2019-04-09 22:43:58,958 root         INFO     Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 2.321502\n",
      "Reconstruction: 0.303763, Regularization: 2.017739\n",
      "2019-04-09 22:43:59,015 root         INFO     Train Epoch: 198 [4608/8000 (58%)]\tTotal Loss: 1.848701\n",
      "Reconstruction: 0.317546, Regularization: 1.531155\n",
      "2019-04-09 22:43:59,072 root         INFO     Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 1.488052\n",
      "Reconstruction: 0.191159, Regularization: 1.296894\n",
      "2019-04-09 22:43:59,128 root         INFO     Train Epoch: 198 [5632/8000 (70%)]\tTotal Loss: 1.602629\n",
      "Reconstruction: 0.184968, Regularization: 1.417661\n",
      "2019-04-09 22:43:59,184 root         INFO     Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 1.709185\n",
      "Reconstruction: 0.173659, Regularization: 1.535526\n",
      "2019-04-09 22:43:59,239 root         INFO     Train Epoch: 198 [6656/8000 (83%)]\tTotal Loss: 1.831167\n",
      "Reconstruction: 0.292466, Regularization: 1.538701\n",
      "2019-04-09 22:43:59,295 root         INFO     Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 1.550308\n",
      "Reconstruction: 0.207669, Regularization: 1.342639\n",
      "2019-04-09 22:43:59,350 root         INFO     Train Epoch: 198 [7680/8000 (96%)]\tTotal Loss: 1.619896\n",
      "Reconstruction: 0.301232, Regularization: 1.318664\n",
      "2019-04-09 22:43:59,401 root         INFO     ====> Epoch: 198 Average loss: 1.4557\n",
      "2019-04-09 22:43:59,424 root         INFO     Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 1.464872\n",
      "Reconstruction: 0.224685, Regularization: 1.240187\n",
      "2019-04-09 22:43:59,481 root         INFO     Train Epoch: 199 [512/8000 (6%)]\tTotal Loss: 2.248342\n",
      "Reconstruction: 0.288914, Regularization: 1.959428\n",
      "2019-04-09 22:43:59,537 root         INFO     Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 1.603375\n",
      "Reconstruction: 0.264626, Regularization: 1.338749\n",
      "2019-04-09 22:43:59,594 root         INFO     Train Epoch: 199 [1536/8000 (19%)]\tTotal Loss: 1.061128\n",
      "Reconstruction: 0.238304, Regularization: 0.822825\n",
      "2019-04-09 22:43:59,650 root         INFO     Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 1.764074\n",
      "Reconstruction: 0.203615, Regularization: 1.560459\n",
      "2019-04-09 22:43:59,707 root         INFO     Train Epoch: 199 [2560/8000 (32%)]\tTotal Loss: 1.306243\n",
      "Reconstruction: 0.251524, Regularization: 1.054719\n",
      "2019-04-09 22:43:59,763 root         INFO     Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 1.572051\n",
      "Reconstruction: 0.215887, Regularization: 1.356163\n",
      "2019-04-09 22:43:59,820 root         INFO     Train Epoch: 199 [3584/8000 (45%)]\tTotal Loss: 1.729128\n",
      "Reconstruction: 0.175262, Regularization: 1.553867\n",
      "2019-04-09 22:43:59,875 root         INFO     Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 1.325552\n",
      "Reconstruction: 0.295499, Regularization: 1.030053\n",
      "2019-04-09 22:43:59,931 root         INFO     Train Epoch: 199 [4608/8000 (58%)]\tTotal Loss: 1.527297\n",
      "Reconstruction: 0.180233, Regularization: 1.347064\n",
      "2019-04-09 22:43:59,986 root         INFO     Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 1.086231\n",
      "Reconstruction: 0.164683, Regularization: 0.921548\n",
      "2019-04-09 22:44:00,042 root         INFO     Train Epoch: 199 [5632/8000 (70%)]\tTotal Loss: 1.533341\n",
      "Reconstruction: 0.209845, Regularization: 1.323496\n",
      "2019-04-09 22:44:00,097 root         INFO     Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.987522\n",
      "Reconstruction: 0.193769, Regularization: 0.793753\n",
      "2019-04-09 22:44:00,153 root         INFO     Train Epoch: 199 [6656/8000 (83%)]\tTotal Loss: 1.148411\n",
      "Reconstruction: 0.229608, Regularization: 0.918803\n",
      "2019-04-09 22:44:00,208 root         INFO     Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 1.286602\n",
      "Reconstruction: 0.178643, Regularization: 1.107959\n",
      "2019-04-09 22:44:00,264 root         INFO     Train Epoch: 199 [7680/8000 (96%)]\tTotal Loss: 1.431602\n",
      "Reconstruction: 0.313640, Regularization: 1.117962\n",
      "2019-04-09 22:44:00,313 root         INFO     ====> Epoch: 199 Average loss: 1.4265\n",
      "2019-04-09 22:44:00,323 luigi-interface INFO     [pid 7258] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=7258) done      TrainVAE()\n",
      "2019-04-09 22:44:00,324 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 22:44:00,324 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   DONE\n",
      "2019-04-09 22:44:00,324 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 22:44:00,324 luigi-interface DEBUG    Pending tasks: 1\n",
      "2019-04-09 22:44:00,325 luigi-interface INFO     [pid 7258] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=7258) running   RunAll()\n",
      "2019-04-09 22:44:00,325 luigi-interface INFO     [pid 7258] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=7258) done      RunAll()\n",
      "2019-04-09 22:44:00,325 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 22:44:00,326 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   DONE\n",
      "2019-04-09 22:44:00,326 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 22:44:00,326 luigi-interface DEBUG    Done\n",
      "2019-04-09 22:44:00,326 luigi-interface DEBUG    There are no more tasks to run at this time\n",
      "2019-04-09 22:44:00,326 luigi-interface INFO     Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=7258) was stopped. Shutting down Keep-Alive thread\n",
      "2019-04-09 22:44:00,327 luigi-interface INFO     \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 4 tasks of which:\n",
      "* 2 complete ones were encountered:\n",
      "    - 1 MakeDataSet()\n",
      "    - 1 TrainVEM()\n",
      "* 2 ran successfully:\n",
      "    - 1 RunAll()\n",
      "    - 1 TrainVAE()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "\n",
      "\n",
      "-- Log file: logs2019-04-09 22:45:14.535834.txt\n",
      "\n",
      "2019-04-09 22:45:14,535 root         INFO     start\n",
      "2019-04-09 22:45:14,550 luigi        INFO     logging configured by default settings\n",
      "2019-04-09 22:45:14,571 luigi-interface DEBUG    Checking if RunAll() is complete\n",
      "2019-04-09 22:45:14,572 luigi-interface DEBUG    Checking if TrainVAE() is complete\n",
      "2019-04-09 22:45:14,572 luigi-interface DEBUG    Checking if TrainVEM() is complete\n",
      "2019-04-09 22:45:14,572 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   PENDING\n",
      "2019-04-09 22:45:14,573 luigi-interface DEBUG    Checking if MakeDataSet() is complete\n",
      "2019-04-09 22:45:14,573 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   PENDING\n",
      "2019-04-09 22:45:14,573 luigi-interface INFO     Informed scheduler that task   MakeDataSet__99914b932b   has status   DONE\n",
      "2019-04-09 22:45:14,574 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   DONE\n",
      "2019-04-09 22:45:14,574 luigi-interface INFO     Done scheduling tasks\n",
      "2019-04-09 22:45:14,574 luigi-interface INFO     Running Worker with 1 processes\n",
      "2019-04-09 22:45:14,574 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 22:45:14,574 luigi-interface DEBUG    Pending tasks: 2\n",
      "2019-04-09 22:45:14,574 luigi-interface INFO     [pid 8911] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=8911) running   TrainVEM()\n",
      "2019-04-09 22:45:14,590 root         INFO     --Dataset tensor: (10000, 2)\n",
      "2019-04-09 22:45:14,591 root         INFO     -- Train tensor: (8000, 2)\n",
      "2019-04-09 22:45:18,399 root         INFO     Values of VEM's decoder parameters before training:\n",
      "2019-04-09 22:45:18,400 root         INFO     layers.0.weight\n",
      "2019-04-09 22:45:18,400 root         INFO     tensor([[-0.2651],\n",
      "        [ 0.1353]], device='cuda:0')\n",
      "2019-04-09 22:45:18,419 root         INFO     layers.0.bias\n",
      "2019-04-09 22:45:18,419 root         INFO     tensor([-0.3248, -0.5761], device='cuda:0')\n",
      "2019-04-09 22:45:18,420 root         INFO     layers.1.weight\n",
      "2019-04-09 22:45:18,420 root         INFO     tensor([[-0.0574,  0.4460],\n",
      "        [ 0.5879, -0.3491]], device='cuda:0')\n",
      "2019-04-09 22:45:18,421 root         INFO     layers.1.bias\n",
      "2019-04-09 22:45:18,421 root         INFO     tensor([-0.4054, -0.0326], device='cuda:0')\n",
      "2019-04-09 22:45:18,422 root         INFO     layers.2.weight\n",
      "2019-04-09 22:45:18,422 root         INFO     tensor([[ 0.3113,  0.3165],\n",
      "        [-0.2632,  0.2449]], device='cuda:0')\n",
      "2019-04-09 22:45:18,424 root         INFO     layers.2.bias\n",
      "2019-04-09 22:45:18,424 root         INFO     tensor([-0.1202, -0.0849], device='cuda:0')\n",
      "2019-04-09 22:45:18,490 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 1.085833\n",
      "Reconstruction: 0.980561, Regularization: 0.034797, Discriminator: 0.049762; Generator: 0.020713,\n",
      "D(x): 0.450, D(G(z)): 0.515\n",
      "2019-04-09 22:45:18,589 root         INFO     Train Epoch: 0 [512/8000 (6%)]\tTotal Loss: 0.717956\n",
      "Reconstruction: 0.621221, Regularization: 0.029237, Discriminator: 0.046879; Generator: 0.020618,\n",
      "D(x): 0.480, D(G(z)): 0.517\n",
      "2019-04-09 22:45:18,685 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 1.023191\n",
      "Reconstruction: 0.921144, Regularization: 0.034932, Discriminator: 0.046557; Generator: 0.020558,\n",
      "D(x): 0.496, D(G(z)): 0.518\n",
      "2019-04-09 22:45:18,783 root         INFO     Train Epoch: 0 [1536/8000 (19%)]\tTotal Loss: 1.422387\n",
      "Reconstruction: 1.314488, Regularization: 0.041109, Discriminator: 0.046290; Generator: 0.020500,\n",
      "D(x): 0.509, D(G(z)): 0.519\n",
      "2019-04-09 22:45:18,882 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 1.355396\n",
      "Reconstruction: 1.239676, Regularization: 0.045896, Discriminator: 0.049384; Generator: 0.020440,\n",
      "D(x): 0.459, D(G(z)): 0.520\n",
      "2019-04-09 22:45:18,979 root         INFO     Train Epoch: 0 [2560/8000 (32%)]\tTotal Loss: 1.240718\n",
      "Reconstruction: 1.134086, Regularization: 0.038166, Discriminator: 0.048117; Generator: 0.020348,\n",
      "D(x): 0.479, D(G(z)): 0.521\n",
      "2019-04-09 22:45:19,076 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 1.322321\n",
      "Reconstruction: 1.210302, Regularization: 0.043827, Discriminator: 0.047899; Generator: 0.020293,\n",
      "D(x): 0.479, D(G(z)): 0.522\n",
      "2019-04-09 22:45:19,172 root         INFO     Train Epoch: 0 [3584/8000 (45%)]\tTotal Loss: 1.031295\n",
      "Reconstruction: 0.932653, Regularization: 0.029010, Discriminator: 0.049375; Generator: 0.020257,\n",
      "D(x): 0.450, D(G(z)): 0.523\n",
      "2019-04-09 22:45:19,269 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 1.192349\n",
      "Reconstruction: 1.084436, Regularization: 0.041295, Discriminator: 0.046369; Generator: 0.020248,\n",
      "D(x): 0.495, D(G(z)): 0.523\n",
      "2019-04-09 22:45:19,365 root         INFO     Train Epoch: 0 [4608/8000 (58%)]\tTotal Loss: 0.982458\n",
      "Reconstruction: 0.881647, Regularization: 0.033972, Discriminator: 0.046646; Generator: 0.020193,\n",
      "D(x): 0.487, D(G(z)): 0.524\n",
      "2019-04-09 22:45:19,462 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 1.195920\n",
      "Reconstruction: 1.084639, Regularization: 0.044114, Discriminator: 0.046992; Generator: 0.020174,\n",
      "D(x): 0.484, D(G(z)): 0.524\n",
      "2019-04-09 22:45:19,558 root         INFO     Train Epoch: 0 [5632/8000 (70%)]\tTotal Loss: 1.037561\n",
      "Reconstruction: 0.930744, Regularization: 0.040658, Discriminator: 0.046013; Generator: 0.020146,\n",
      "D(x): 0.497, D(G(z)): 0.525\n",
      "2019-04-09 22:45:19,654 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 1.062131\n",
      "Reconstruction: 0.960547, Regularization: 0.034146, Discriminator: 0.047312; Generator: 0.020125,\n",
      "D(x): 0.476, D(G(z)): 0.525\n",
      "2019-04-09 22:45:19,750 root         INFO     Train Epoch: 0 [6656/8000 (83%)]\tTotal Loss: 0.952494\n",
      "Reconstruction: 0.854852, Regularization: 0.030767, Discriminator: 0.046764; Generator: 0.020110,\n",
      "D(x): 0.482, D(G(z)): 0.525\n",
      "2019-04-09 22:45:19,847 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 1.280804\n",
      "Reconstruction: 1.178537, Regularization: 0.034360, Discriminator: 0.047816; Generator: 0.020091,\n",
      "D(x): 0.466, D(G(z)): 0.526\n",
      "2019-04-09 22:45:19,943 root         INFO     Train Epoch: 0 [7680/8000 (96%)]\tTotal Loss: 1.005843\n",
      "Reconstruction: 0.915935, Regularization: 0.025773, Discriminator: 0.044056; Generator: 0.020078,\n",
      "D(x): 0.525, D(G(z)): 0.526\n",
      "2019-04-09 22:45:20,017 root         INFO     ====> Epoch: 0 Average loss: 1.1873\n",
      "2019-04-09 22:45:20,043 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 1.253984\n",
      "Reconstruction: 1.153117, Regularization: 0.035372, Discriminator: 0.045413; Generator: 0.020083,\n",
      "D(x): 0.505, D(G(z)): 0.526\n",
      "2019-04-09 22:45:20,142 root         INFO     Train Epoch: 1 [512/8000 (6%)]\tTotal Loss: 1.081081\n",
      "Reconstruction: 0.989393, Regularization: 0.025691, Discriminator: 0.045912; Generator: 0.020085,\n",
      "D(x): 0.494, D(G(z)): 0.526\n",
      "2019-04-09 22:45:20,241 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 0.983094\n",
      "Reconstruction: 0.890262, Regularization: 0.027007, Discriminator: 0.045752; Generator: 0.020074,\n",
      "D(x): 0.495, D(G(z)): 0.526\n",
      "2019-04-09 22:45:20,340 root         INFO     Train Epoch: 1 [1536/8000 (19%)]\tTotal Loss: 1.188182\n",
      "Reconstruction: 1.094279, Regularization: 0.026691, Discriminator: 0.047117; Generator: 0.020095,\n",
      "D(x): 0.474, D(G(z)): 0.526\n",
      "2019-04-09 22:45:20,439 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 1.299354\n",
      "Reconstruction: 1.198412, Regularization: 0.036134, Discriminator: 0.044714; Generator: 0.020094,\n",
      "D(x): 0.511, D(G(z)): 0.526\n",
      "2019-04-09 22:45:20,537 root         INFO     Train Epoch: 1 [2560/8000 (32%)]\tTotal Loss: 1.016305\n",
      "Reconstruction: 0.922997, Regularization: 0.027494, Discriminator: 0.045711; Generator: 0.020104,\n",
      "D(x): 0.493, D(G(z)): 0.526\n",
      "2019-04-09 22:45:20,634 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 1.283581\n",
      "Reconstruction: 1.180432, Regularization: 0.037915, Discriminator: 0.045116; Generator: 0.020118,\n",
      "D(x): 0.504, D(G(z)): 0.525\n",
      "2019-04-09 22:45:20,731 root         INFO     Train Epoch: 1 [3584/8000 (45%)]\tTotal Loss: 1.105095\n",
      "Reconstruction: 1.016382, Regularization: 0.024279, Discriminator: 0.044304; Generator: 0.020131,\n",
      "D(x): 0.515, D(G(z)): 0.525\n",
      "2019-04-09 22:45:20,828 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 1.081883\n",
      "Reconstruction: 0.989635, Regularization: 0.026129, Discriminator: 0.045969; Generator: 0.020151,\n",
      "D(x): 0.487, D(G(z)): 0.525\n",
      "2019-04-09 22:45:20,926 root         INFO     Train Epoch: 1 [4608/8000 (58%)]\tTotal Loss: 0.889304\n",
      "Reconstruction: 0.801958, Regularization: 0.021618, Discriminator: 0.045558; Generator: 0.020170,\n",
      "D(x): 0.492, D(G(z)): 0.524\n",
      "2019-04-09 22:45:21,022 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 1.407153\n",
      "Reconstruction: 1.297569, Regularization: 0.044163, Discriminator: 0.045238; Generator: 0.020183,\n",
      "D(x): 0.498, D(G(z)): 0.524\n",
      "2019-04-09 22:45:21,119 root         INFO     Train Epoch: 1 [5632/8000 (70%)]\tTotal Loss: 1.265791\n",
      "Reconstruction: 1.163593, Regularization: 0.037351, Discriminator: 0.044654; Generator: 0.020194,\n",
      "D(x): 0.507, D(G(z)): 0.524\n",
      "2019-04-09 22:45:21,213 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 0.803439\n",
      "Reconstruction: 0.715725, Regularization: 0.023475, Discriminator: 0.044018; Generator: 0.020222,\n",
      "D(x): 0.515, D(G(z)): 0.524\n",
      "2019-04-09 22:45:21,308 root         INFO     Train Epoch: 1 [6656/8000 (83%)]\tTotal Loss: 0.894726\n",
      "Reconstruction: 0.807211, Regularization: 0.022799, Discriminator: 0.044475; Generator: 0.020241,\n",
      "D(x): 0.507, D(G(z)): 0.523\n",
      "2019-04-09 22:45:21,403 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 1.543586\n",
      "Reconstruction: 1.443206, Regularization: 0.035682, Discriminator: 0.044422; Generator: 0.020275,\n",
      "D(x): 0.509, D(G(z)): 0.523\n",
      "2019-04-09 22:45:21,498 root         INFO     Train Epoch: 1 [7680/8000 (96%)]\tTotal Loss: 1.124621\n",
      "Reconstruction: 1.031502, Regularization: 0.028705, Discriminator: 0.044110; Generator: 0.020305,\n",
      "D(x): 0.512, D(G(z)): 0.522\n",
      "2019-04-09 22:45:21,570 root         INFO     ====> Epoch: 1 Average loss: 1.1651\n",
      "2019-04-09 22:45:21,596 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 1.454646\n",
      "Reconstruction: 1.364511, Regularization: 0.025017, Discriminator: 0.044798; Generator: 0.020320,\n",
      "D(x): 0.501, D(G(z)): 0.522\n",
      "2019-04-09 22:45:21,694 root         INFO     Train Epoch: 2 [512/8000 (6%)]\tTotal Loss: 0.900053\n",
      "Reconstruction: 0.808002, Regularization: 0.027349, Discriminator: 0.044368; Generator: 0.020334,\n",
      "D(x): 0.507, D(G(z)): 0.522\n",
      "2019-04-09 22:45:21,793 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 1.080179\n",
      "Reconstruction: 0.985345, Regularization: 0.030305, Discriminator: 0.044176; Generator: 0.020352,\n",
      "D(x): 0.510, D(G(z)): 0.521\n",
      "2019-04-09 22:45:21,891 root         INFO     Train Epoch: 2 [1536/8000 (19%)]\tTotal Loss: 0.999432\n",
      "Reconstruction: 0.904549, Regularization: 0.030054, Discriminator: 0.044449; Generator: 0.020381,\n",
      "D(x): 0.504, D(G(z)): 0.521\n",
      "2019-04-09 22:45:21,989 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 1.353712\n",
      "Reconstruction: 1.263555, Regularization: 0.025114, Discriminator: 0.044641; Generator: 0.020402,\n",
      "D(x): 0.501, D(G(z)): 0.521\n",
      "2019-04-09 22:45:22,087 root         INFO     Train Epoch: 2 [2560/8000 (32%)]\tTotal Loss: 0.916273\n",
      "Reconstruction: 0.823259, Regularization: 0.028905, Discriminator: 0.043688; Generator: 0.020421,\n",
      "D(x): 0.516, D(G(z)): 0.520\n",
      "2019-04-09 22:45:22,184 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 1.241262\n",
      "Reconstruction: 1.139058, Regularization: 0.038210, Discriminator: 0.043544; Generator: 0.020449,\n",
      "D(x): 0.518, D(G(z)): 0.520\n",
      "2019-04-09 22:45:22,282 root         INFO     Train Epoch: 2 [3584/8000 (45%)]\tTotal Loss: 1.148513\n",
      "Reconstruction: 1.062963, Regularization: 0.021203, Discriminator: 0.043878; Generator: 0.020468,\n",
      "D(x): 0.512, D(G(z)): 0.519\n",
      "2019-04-09 22:45:22,380 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 1.147148\n",
      "Reconstruction: 1.050727, Regularization: 0.032157, Discriminator: 0.043772; Generator: 0.020492,\n",
      "D(x): 0.513, D(G(z)): 0.519\n",
      "2019-04-09 22:45:22,478 root         INFO     Train Epoch: 2 [4608/8000 (58%)]\tTotal Loss: 0.810956\n",
      "Reconstruction: 0.726231, Regularization: 0.020608, Discriminator: 0.043603; Generator: 0.020514,\n",
      "D(x): 0.515, D(G(z)): 0.519\n",
      "2019-04-09 22:45:22,578 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 1.294028\n",
      "Reconstruction: 1.205366, Regularization: 0.024317, Discriminator: 0.043806; Generator: 0.020539,\n",
      "D(x): 0.511, D(G(z)): 0.518\n",
      "2019-04-09 22:45:22,674 root         INFO     Train Epoch: 2 [5632/8000 (70%)]\tTotal Loss: 0.629903\n",
      "Reconstruction: 0.547903, Regularization: 0.017749, Discriminator: 0.043699; Generator: 0.020553,\n",
      "D(x): 0.513, D(G(z)): 0.518\n",
      "2019-04-09 22:45:22,771 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 1.370283\n",
      "Reconstruction: 1.276333, Regularization: 0.029863, Discriminator: 0.043512; Generator: 0.020575,\n",
      "D(x): 0.515, D(G(z)): 0.518\n",
      "2019-04-09 22:45:22,868 root         INFO     Train Epoch: 2 [6656/8000 (83%)]\tTotal Loss: 1.714200\n",
      "Reconstruction: 1.617319, Regularization: 0.032824, Discriminator: 0.043463; Generator: 0.020594,\n",
      "D(x): 0.516, D(G(z)): 0.517\n",
      "2019-04-09 22:45:22,964 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 0.627023\n",
      "Reconstruction: 0.544288, Regularization: 0.018782, Discriminator: 0.043334; Generator: 0.020618,\n",
      "D(x): 0.517, D(G(z)): 0.517\n",
      "2019-04-09 22:45:23,061 root         INFO     Train Epoch: 2 [7680/8000 (96%)]\tTotal Loss: 1.140030\n",
      "Reconstruction: 1.051800, Regularization: 0.024351, Discriminator: 0.043245; Generator: 0.020635,\n",
      "D(x): 0.519, D(G(z)): 0.517\n",
      "2019-04-09 22:45:23,134 root         INFO     ====> Epoch: 2 Average loss: 1.1353\n",
      "2019-04-09 22:45:23,160 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 1.045202\n",
      "Reconstruction: 0.954311, Regularization: 0.027019, Discriminator: 0.043222; Generator: 0.020649,\n",
      "D(x): 0.519, D(G(z)): 0.516\n",
      "2019-04-09 22:45:23,260 root         INFO     Train Epoch: 3 [512/8000 (6%)]\tTotal Loss: 1.131392\n",
      "Reconstruction: 1.043711, Regularization: 0.023784, Discriminator: 0.043223; Generator: 0.020673,\n",
      "D(x): 0.518, D(G(z)): 0.516\n",
      "2019-04-09 22:45:23,358 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 1.156652\n",
      "Reconstruction: 1.068518, Regularization: 0.024272, Discriminator: 0.043172; Generator: 0.020690,\n",
      "D(x): 0.519, D(G(z)): 0.516\n",
      "2019-04-09 22:45:23,456 root         INFO     Train Epoch: 3 [1536/8000 (19%)]\tTotal Loss: 1.381325\n",
      "Reconstruction: 1.289085, Regularization: 0.028391, Discriminator: 0.043128; Generator: 0.020720,\n",
      "D(x): 0.519, D(G(z)): 0.515\n",
      "2019-04-09 22:45:23,555 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 0.949998\n",
      "Reconstruction: 0.864140, Regularization: 0.022052, Discriminator: 0.043069; Generator: 0.020737,\n",
      "D(x): 0.520, D(G(z)): 0.515\n",
      "2019-04-09 22:45:23,653 root         INFO     Train Epoch: 3 [2560/8000 (32%)]\tTotal Loss: 1.018510\n",
      "Reconstruction: 0.928216, Regularization: 0.026473, Discriminator: 0.043073; Generator: 0.020748,\n",
      "D(x): 0.519, D(G(z)): 0.515\n",
      "2019-04-09 22:45:23,751 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 0.872759\n",
      "Reconstruction: 0.790037, Regularization: 0.019087, Discriminator: 0.042868; Generator: 0.020767,\n",
      "D(x): 0.523, D(G(z)): 0.515\n",
      "2019-04-09 22:45:23,849 root         INFO     Train Epoch: 3 [3584/8000 (45%)]\tTotal Loss: 0.978567\n",
      "Reconstruction: 0.893783, Regularization: 0.021076, Discriminator: 0.042926; Generator: 0.020782,\n",
      "D(x): 0.521, D(G(z)): 0.514\n",
      "2019-04-09 22:45:23,947 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 1.328358\n",
      "Reconstruction: 1.239458, Regularization: 0.025228, Discriminator: 0.042863; Generator: 0.020809,\n",
      "D(x): 0.522, D(G(z)): 0.514\n",
      "2019-04-09 22:45:24,045 root         INFO     Train Epoch: 3 [4608/8000 (58%)]\tTotal Loss: 1.027208\n",
      "Reconstruction: 0.943519, Regularization: 0.020106, Discriminator: 0.042761; Generator: 0.020822,\n",
      "D(x): 0.523, D(G(z)): 0.514\n",
      "2019-04-09 22:45:24,143 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 1.163319\n",
      "Reconstruction: 1.065473, Regularization: 0.034316, Discriminator: 0.042692; Generator: 0.020838,\n",
      "D(x): 0.524, D(G(z)): 0.513\n",
      "2019-04-09 22:45:24,241 root         INFO     Train Epoch: 3 [5632/8000 (70%)]\tTotal Loss: 1.113089\n",
      "Reconstruction: 1.020896, Regularization: 0.028496, Discriminator: 0.042840; Generator: 0.020856,\n",
      "D(x): 0.522, D(G(z)): 0.513\n",
      "2019-04-09 22:45:24,338 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 0.789484\n",
      "Reconstruction: 0.706042, Regularization: 0.019937, Discriminator: 0.042621; Generator: 0.020884,\n",
      "D(x): 0.525, D(G(z)): 0.513\n",
      "2019-04-09 22:45:24,436 root         INFO     Train Epoch: 3 [6656/8000 (83%)]\tTotal Loss: 1.130558\n",
      "Reconstruction: 1.036479, Regularization: 0.030156, Discriminator: 0.043017; Generator: 0.020907,\n",
      "D(x): 0.518, D(G(z)): 0.512\n",
      "2019-04-09 22:45:24,533 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 0.999187\n",
      "Reconstruction: 0.913661, Regularization: 0.021815, Discriminator: 0.042789; Generator: 0.020922,\n",
      "D(x): 0.522, D(G(z)): 0.512\n",
      "2019-04-09 22:45:24,631 root         INFO     Train Epoch: 3 [7680/8000 (96%)]\tTotal Loss: 1.101044\n",
      "Reconstruction: 1.019303, Regularization: 0.018187, Discriminator: 0.042615; Generator: 0.020939,\n",
      "D(x): 0.524, D(G(z)): 0.512\n",
      "2019-04-09 22:45:24,704 root         INFO     ====> Epoch: 3 Average loss: 1.1213\n",
      "2019-04-09 22:45:24,730 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 0.926250\n",
      "Reconstruction: 0.838146, Regularization: 0.024621, Discriminator: 0.042534; Generator: 0.020949,\n",
      "D(x): 0.525, D(G(z)): 0.512\n",
      "2019-04-09 22:45:24,829 root         INFO     Train Epoch: 4 [512/8000 (6%)]\tTotal Loss: 1.239663\n",
      "Reconstruction: 1.155372, Regularization: 0.021333, Discriminator: 0.041992; Generator: 0.020967,\n",
      "D(x): 0.534, D(G(z)): 0.511\n",
      "2019-04-09 22:45:24,928 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 0.759502\n",
      "Reconstruction: 0.676046, Regularization: 0.020148, Discriminator: 0.042331; Generator: 0.020976,\n",
      "D(x): 0.528, D(G(z)): 0.511\n",
      "2019-04-09 22:45:25,027 root         INFO     Train Epoch: 4 [1536/8000 (19%)]\tTotal Loss: 0.698321\n",
      "Reconstruction: 0.614727, Regularization: 0.020346, Discriminator: 0.042254; Generator: 0.020993,\n",
      "D(x): 0.529, D(G(z)): 0.511\n",
      "2019-04-09 22:45:25,126 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 1.703987\n",
      "Reconstruction: 1.616961, Regularization: 0.023977, Discriminator: 0.042035; Generator: 0.021015,\n",
      "D(x): 0.534, D(G(z)): 0.510\n",
      "2019-04-09 22:45:25,226 root         INFO     Train Epoch: 4 [2560/8000 (32%)]\tTotal Loss: 1.245094\n",
      "Reconstruction: 1.157769, Regularization: 0.023609, Discriminator: 0.042688; Generator: 0.021028,\n",
      "D(x): 0.523, D(G(z)): 0.510\n",
      "2019-04-09 22:45:25,325 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 1.077896\n",
      "Reconstruction: 0.983676, Regularization: 0.030305, Discriminator: 0.042869; Generator: 0.021046,\n",
      "D(x): 0.519, D(G(z)): 0.510\n",
      "2019-04-09 22:45:25,423 root         INFO     Train Epoch: 4 [3584/8000 (45%)]\tTotal Loss: 0.956505\n",
      "Reconstruction: 0.875784, Regularization: 0.017285, Discriminator: 0.042373; Generator: 0.021064,\n",
      "D(x): 0.527, D(G(z)): 0.510\n",
      "2019-04-09 22:45:25,522 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 1.701884\n",
      "Reconstruction: 1.614008, Regularization: 0.024455, Discriminator: 0.042333; Generator: 0.021088,\n",
      "D(x): 0.528, D(G(z)): 0.509\n",
      "2019-04-09 22:45:25,622 root         INFO     Train Epoch: 4 [4608/8000 (58%)]\tTotal Loss: 1.059923\n",
      "Reconstruction: 0.972456, Regularization: 0.023778, Discriminator: 0.042587; Generator: 0.021102,\n",
      "D(x): 0.523, D(G(z)): 0.509\n",
      "2019-04-09 22:45:25,719 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 1.002122\n",
      "Reconstruction: 0.914275, Regularization: 0.024504, Discriminator: 0.042238; Generator: 0.021105,\n",
      "D(x): 0.529, D(G(z)): 0.509\n",
      "2019-04-09 22:45:25,817 root         INFO     Train Epoch: 4 [5632/8000 (70%)]\tTotal Loss: 1.132536\n",
      "Reconstruction: 1.050392, Regularization: 0.019706, Discriminator: 0.041313; Generator: 0.021125,\n",
      "D(x): 0.544, D(G(z)): 0.509\n",
      "2019-04-09 22:45:25,915 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 0.976048\n",
      "Reconstruction: 0.890544, Regularization: 0.022075, Discriminator: 0.042279; Generator: 0.021150,\n",
      "D(x): 0.528, D(G(z)): 0.508\n",
      "2019-04-09 22:45:26,013 root         INFO     Train Epoch: 4 [6656/8000 (83%)]\tTotal Loss: 1.937999\n",
      "Reconstruction: 1.846987, Regularization: 0.028699, Discriminator: 0.041143; Generator: 0.021170,\n",
      "D(x): 0.548, D(G(z)): 0.508\n",
      "2019-04-09 22:45:26,111 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 1.094517\n",
      "Reconstruction: 1.012617, Regularization: 0.018505, Discriminator: 0.042213; Generator: 0.021182,\n",
      "D(x): 0.529, D(G(z)): 0.508\n",
      "2019-04-09 22:45:26,209 root         INFO     Train Epoch: 4 [7680/8000 (96%)]\tTotal Loss: 1.485546\n",
      "Reconstruction: 1.391675, Regularization: 0.030147, Discriminator: 0.042522; Generator: 0.021203,\n",
      "D(x): 0.524, D(G(z)): 0.507\n",
      "2019-04-09 22:45:26,283 root         INFO     ====> Epoch: 4 Average loss: 1.0983\n",
      "2019-04-09 22:45:26,309 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 1.708438\n",
      "Reconstruction: 1.620572, Regularization: 0.025224, Discriminator: 0.041426; Generator: 0.021217,\n",
      "D(x): 0.543, D(G(z)): 0.507\n",
      "2019-04-09 22:45:26,410 root         INFO     Train Epoch: 5 [512/8000 (6%)]\tTotal Loss: 0.927938\n",
      "Reconstruction: 0.845767, Regularization: 0.019579, Discriminator: 0.041365; Generator: 0.021227,\n",
      "D(x): 0.542, D(G(z)): 0.507\n",
      "2019-04-09 22:45:26,511 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 1.715185\n",
      "Reconstruction: 1.621508, Regularization: 0.029745, Discriminator: 0.042672; Generator: 0.021259,\n",
      "D(x): 0.522, D(G(z)): 0.506\n",
      "2019-04-09 22:45:26,612 root         INFO     Train Epoch: 5 [1536/8000 (19%)]\tTotal Loss: 1.280110\n",
      "Reconstruction: 1.198714, Regularization: 0.018072, Discriminator: 0.042073; Generator: 0.021252,\n",
      "D(x): 0.531, D(G(z)): 0.507\n",
      "2019-04-09 22:45:26,712 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 1.659968\n",
      "Reconstruction: 1.569250, Regularization: 0.028585, Discriminator: 0.040866; Generator: 0.021268,\n",
      "D(x): 0.552, D(G(z)): 0.506\n",
      "2019-04-09 22:45:26,813 root         INFO     Train Epoch: 5 [2560/8000 (32%)]\tTotal Loss: 1.285836\n",
      "Reconstruction: 1.196663, Regularization: 0.025181, Discriminator: 0.042714; Generator: 0.021278,\n",
      "D(x): 0.521, D(G(z)): 0.506\n",
      "2019-04-09 22:45:26,913 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 0.919461\n",
      "Reconstruction: 0.834010, Regularization: 0.020591, Discriminator: 0.043553; Generator: 0.021306,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-09 22:45:27,014 root         INFO     Train Epoch: 5 [3584/8000 (45%)]\tTotal Loss: 0.860443\n",
      "Reconstruction: 0.778341, Regularization: 0.017782, Discriminator: 0.042987; Generator: 0.021332,\n",
      "D(x): 0.514, D(G(z)): 0.505\n",
      "2019-04-09 22:45:27,111 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 0.994387\n",
      "Reconstruction: 0.910046, Regularization: 0.021531, Discriminator: 0.041455; Generator: 0.021356,\n",
      "D(x): 0.539, D(G(z)): 0.505\n",
      "2019-04-09 22:45:27,212 root         INFO     Train Epoch: 5 [4608/8000 (58%)]\tTotal Loss: 0.995068\n",
      "Reconstruction: 0.909693, Regularization: 0.021555, Discriminator: 0.042450; Generator: 0.021371,\n",
      "D(x): 0.523, D(G(z)): 0.505\n",
      "2019-04-09 22:45:27,312 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 1.101770\n",
      "Reconstruction: 1.009503, Regularization: 0.027091, Discriminator: 0.043794; Generator: 0.021381,\n",
      "D(x): 0.502, D(G(z)): 0.505\n",
      "2019-04-09 22:45:27,409 root         INFO     Train Epoch: 5 [5632/8000 (70%)]\tTotal Loss: 1.022510\n",
      "Reconstruction: 0.942153, Regularization: 0.018865, Discriminator: 0.040098; Generator: 0.021394,\n",
      "D(x): 0.563, D(G(z)): 0.504\n",
      "2019-04-09 22:45:27,509 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 0.965041\n",
      "Reconstruction: 0.877456, Regularization: 0.023656, Discriminator: 0.042522; Generator: 0.021407,\n",
      "D(x): 0.522, D(G(z)): 0.504\n",
      "2019-04-09 22:45:27,609 root         INFO     Train Epoch: 5 [6656/8000 (83%)]\tTotal Loss: 0.801316\n",
      "Reconstruction: 0.718741, Regularization: 0.019169, Discriminator: 0.041978; Generator: 0.021429,\n",
      "D(x): 0.531, D(G(z)): 0.504\n",
      "2019-04-09 22:45:27,710 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 0.685547\n",
      "Reconstruction: 0.606620, Regularization: 0.014926, Discriminator: 0.042546; Generator: 0.021455,\n",
      "D(x): 0.520, D(G(z)): 0.503\n",
      "2019-04-09 22:45:27,810 root         INFO     Train Epoch: 5 [7680/8000 (96%)]\tTotal Loss: 1.066033\n",
      "Reconstruction: 0.984456, Regularization: 0.019391, Discriminator: 0.040713; Generator: 0.021474,\n",
      "D(x): 0.551, D(G(z)): 0.503\n",
      "2019-04-09 22:45:27,884 root         INFO     ====> Epoch: 5 Average loss: 1.0853\n",
      "2019-04-09 22:45:27,910 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 0.795118\n",
      "Reconstruction: 0.715017, Regularization: 0.017239, Discriminator: 0.041390; Generator: 0.021472,\n",
      "D(x): 0.539, D(G(z)): 0.503\n",
      "2019-04-09 22:45:28,010 root         INFO     Train Epoch: 6 [512/8000 (6%)]\tTotal Loss: 0.785263\n",
      "Reconstruction: 0.695955, Regularization: 0.025271, Discriminator: 0.042529; Generator: 0.021509,\n",
      "D(x): 0.520, D(G(z)): 0.502\n",
      "2019-04-09 22:45:28,109 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 1.141789\n",
      "Reconstruction: 1.057720, Regularization: 0.021305, Discriminator: 0.041245; Generator: 0.021520,\n",
      "D(x): 0.542, D(G(z)): 0.502\n",
      "2019-04-09 22:45:28,207 root         INFO     Train Epoch: 6 [1536/8000 (19%)]\tTotal Loss: 0.964812\n",
      "Reconstruction: 0.873867, Regularization: 0.027432, Discriminator: 0.041984; Generator: 0.021530,\n",
      "D(x): 0.530, D(G(z)): 0.502\n",
      "2019-04-09 22:45:28,305 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 1.107464\n",
      "Reconstruction: 1.017378, Regularization: 0.026478, Discriminator: 0.042046; Generator: 0.021563,\n",
      "D(x): 0.530, D(G(z)): 0.502\n",
      "2019-04-09 22:45:28,403 root         INFO     Train Epoch: 6 [2560/8000 (32%)]\tTotal Loss: 0.748750\n",
      "Reconstruction: 0.653582, Regularization: 0.030710, Discriminator: 0.042874; Generator: 0.021584,\n",
      "D(x): 0.513, D(G(z)): 0.501\n",
      "2019-04-09 22:45:28,501 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 1.172601\n",
      "Reconstruction: 1.085066, Regularization: 0.023620, Discriminator: 0.042315; Generator: 0.021600,\n",
      "D(x): 0.526, D(G(z)): 0.501\n",
      "2019-04-09 22:45:28,599 root         INFO     Train Epoch: 6 [3584/8000 (45%)]\tTotal Loss: 1.154909\n",
      "Reconstruction: 1.070852, Regularization: 0.022079, Discriminator: 0.040379; Generator: 0.021599,\n",
      "D(x): 0.558, D(G(z)): 0.501\n",
      "2019-04-09 22:45:28,696 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 1.346075\n",
      "Reconstruction: 1.258205, Regularization: 0.023346, Discriminator: 0.042893; Generator: 0.021631,\n",
      "D(x): 0.518, D(G(z)): 0.500\n",
      "2019-04-09 22:45:28,793 root         INFO     Train Epoch: 6 [4608/8000 (58%)]\tTotal Loss: 1.135935\n",
      "Reconstruction: 1.045194, Regularization: 0.027472, Discriminator: 0.041603; Generator: 0.021666,\n",
      "D(x): 0.537, D(G(z)): 0.500\n",
      "2019-04-09 22:45:28,890 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 1.335406\n",
      "Reconstruction: 1.244773, Regularization: 0.028286, Discriminator: 0.040653; Generator: 0.021694,\n",
      "D(x): 0.553, D(G(z)): 0.499\n",
      "2019-04-09 22:45:28,987 root         INFO     Train Epoch: 6 [5632/8000 (70%)]\tTotal Loss: 1.015285\n",
      "Reconstruction: 0.932959, Regularization: 0.018258, Discriminator: 0.042363; Generator: 0.021705,\n",
      "D(x): 0.524, D(G(z)): 0.499\n",
      "2019-04-09 22:45:29,085 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 0.986493\n",
      "Reconstruction: 0.899229, Regularization: 0.024448, Discriminator: 0.041109; Generator: 0.021707,\n",
      "D(x): 0.544, D(G(z)): 0.499\n",
      "2019-04-09 22:45:29,182 root         INFO     Train Epoch: 6 [6656/8000 (83%)]\tTotal Loss: 1.161320\n",
      "Reconstruction: 1.070358, Regularization: 0.028711, Discriminator: 0.040521; Generator: 0.021729,\n",
      "D(x): 0.555, D(G(z)): 0.499\n",
      "2019-04-09 22:45:29,280 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 1.087280\n",
      "Reconstruction: 0.997182, Regularization: 0.027111, Discriminator: 0.041227; Generator: 0.021761,\n",
      "D(x): 0.543, D(G(z)): 0.498\n",
      "2019-04-09 22:45:29,378 root         INFO     Train Epoch: 6 [7680/8000 (96%)]\tTotal Loss: 1.288696\n",
      "Reconstruction: 1.193966, Regularization: 0.029910, Discriminator: 0.043025; Generator: 0.021795,\n",
      "D(x): 0.515, D(G(z)): 0.498\n",
      "2019-04-09 22:45:29,452 root         INFO     ====> Epoch: 6 Average loss: 1.0727\n",
      "2019-04-09 22:45:29,478 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 1.087738\n",
      "Reconstruction: 0.996827, Regularization: 0.027237, Discriminator: 0.041871; Generator: 0.021803,\n",
      "D(x): 0.533, D(G(z)): 0.498\n",
      "2019-04-09 22:45:29,579 root         INFO     Train Epoch: 7 [512/8000 (6%)]\tTotal Loss: 0.900134\n",
      "Reconstruction: 0.813763, Regularization: 0.023118, Discriminator: 0.041416; Generator: 0.021838,\n",
      "D(x): 0.537, D(G(z)): 0.497\n",
      "2019-04-09 22:45:29,678 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 1.604536\n",
      "Reconstruction: 1.509082, Regularization: 0.027676, Discriminator: 0.045919; Generator: 0.021859,\n",
      "D(x): 0.473, D(G(z)): 0.497\n",
      "2019-04-09 22:45:29,777 root         INFO     Train Epoch: 7 [1536/8000 (19%)]\tTotal Loss: 1.038052\n",
      "Reconstruction: 0.951508, Regularization: 0.022848, Discriminator: 0.041831; Generator: 0.021865,\n",
      "D(x): 0.532, D(G(z)): 0.497\n",
      "2019-04-09 22:45:29,876 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 1.191741\n",
      "Reconstruction: 1.105319, Regularization: 0.023215, Discriminator: 0.041316; Generator: 0.021891,\n",
      "D(x): 0.541, D(G(z)): 0.496\n",
      "2019-04-09 22:45:29,975 root         INFO     Train Epoch: 7 [2560/8000 (32%)]\tTotal Loss: 0.727398\n",
      "Reconstruction: 0.631402, Regularization: 0.031678, Discriminator: 0.042407; Generator: 0.021911,\n",
      "D(x): 0.517, D(G(z)): 0.496\n",
      "2019-04-09 22:45:30,071 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 0.730157\n",
      "Reconstruction: 0.636054, Regularization: 0.029578, Discriminator: 0.042609; Generator: 0.021917,\n",
      "D(x): 0.515, D(G(z)): 0.496\n",
      "2019-04-09 22:45:30,168 root         INFO     Train Epoch: 7 [3584/8000 (45%)]\tTotal Loss: 1.237979\n",
      "Reconstruction: 1.150939, Regularization: 0.025664, Discriminator: 0.039421; Generator: 0.021954,\n",
      "D(x): 0.573, D(G(z)): 0.495\n",
      "2019-04-09 22:45:30,264 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 1.206163\n",
      "Reconstruction: 1.114922, Regularization: 0.027083, Discriminator: 0.042170; Generator: 0.021988,\n",
      "D(x): 0.530, D(G(z)): 0.495\n",
      "2019-04-09 22:45:30,362 root         INFO     Train Epoch: 7 [4608/8000 (58%)]\tTotal Loss: 0.778078\n",
      "Reconstruction: 0.691213, Regularization: 0.024257, Discriminator: 0.040618; Generator: 0.021989,\n",
      "D(x): 0.547, D(G(z)): 0.495\n",
      "2019-04-09 22:45:30,459 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 0.888700\n",
      "Reconstruction: 0.802297, Regularization: 0.024550, Discriminator: 0.039834; Generator: 0.022018,\n",
      "D(x): 0.560, D(G(z)): 0.494\n",
      "2019-04-09 22:45:30,556 root         INFO     Train Epoch: 7 [5632/8000 (70%)]\tTotal Loss: 0.646712\n",
      "Reconstruction: 0.563187, Regularization: 0.021140, Discriminator: 0.040325; Generator: 0.022061,\n",
      "D(x): 0.551, D(G(z)): 0.494\n",
      "2019-04-09 22:45:30,653 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 0.816418\n",
      "Reconstruction: 0.734985, Regularization: 0.018375, Discriminator: 0.040979; Generator: 0.022079,\n",
      "D(x): 0.543, D(G(z)): 0.493\n",
      "2019-04-09 22:45:30,749 root         INFO     Train Epoch: 7 [6656/8000 (83%)]\tTotal Loss: 1.082852\n",
      "Reconstruction: 0.999742, Regularization: 0.021821, Discriminator: 0.039203; Generator: 0.022088,\n",
      "D(x): 0.573, D(G(z)): 0.493\n",
      "2019-04-09 22:45:30,846 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 1.176691\n",
      "Reconstruction: 1.093873, Regularization: 0.019763, Discriminator: 0.040925; Generator: 0.022130,\n",
      "D(x): 0.548, D(G(z)): 0.493\n",
      "2019-04-09 22:45:30,943 root         INFO     Train Epoch: 7 [7680/8000 (96%)]\tTotal Loss: 1.083598\n",
      "Reconstruction: 0.993909, Regularization: 0.026657, Discriminator: 0.040871; Generator: 0.022161,\n",
      "D(x): 0.549, D(G(z)): 0.492\n",
      "2019-04-09 22:45:31,016 root         INFO     ====> Epoch: 7 Average loss: 1.0634\n",
      "2019-04-09 22:45:31,042 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 1.004476\n",
      "Reconstruction: 0.912985, Regularization: 0.027537, Discriminator: 0.041801; Generator: 0.022153,\n",
      "D(x): 0.532, D(G(z)): 0.492\n",
      "2019-04-09 22:45:31,141 root         INFO     Train Epoch: 8 [512/8000 (6%)]\tTotal Loss: 0.925050\n",
      "Reconstruction: 0.839067, Regularization: 0.021937, Discriminator: 0.041868; Generator: 0.022178,\n",
      "D(x): 0.529, D(G(z)): 0.492\n",
      "2019-04-09 22:45:31,241 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 1.287650\n",
      "Reconstruction: 1.191792, Regularization: 0.030824, Discriminator: 0.042823; Generator: 0.022211,\n",
      "D(x): 0.525, D(G(z)): 0.491\n",
      "2019-04-09 22:45:31,339 root         INFO     Train Epoch: 8 [1536/8000 (19%)]\tTotal Loss: 1.101746\n",
      "Reconstruction: 1.015515, Regularization: 0.023509, Discriminator: 0.040459; Generator: 0.022264,\n",
      "D(x): 0.554, D(G(z)): 0.490\n",
      "2019-04-09 22:45:31,438 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 1.038241\n",
      "Reconstruction: 0.949599, Regularization: 0.024864, Discriminator: 0.041507; Generator: 0.022271,\n",
      "D(x): 0.535, D(G(z)): 0.490\n",
      "2019-04-09 22:45:31,537 root         INFO     Train Epoch: 8 [2560/8000 (32%)]\tTotal Loss: 0.612326\n",
      "Reconstruction: 0.531418, Regularization: 0.018830, Discriminator: 0.039768; Generator: 0.022310,\n",
      "D(x): 0.558, D(G(z)): 0.490\n",
      "2019-04-09 22:45:31,635 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 1.549462\n",
      "Reconstruction: 1.459118, Regularization: 0.029665, Discriminator: 0.038356; Generator: 0.022323,\n",
      "D(x): 0.592, D(G(z)): 0.490\n",
      "2019-04-09 22:45:31,733 root         INFO     Train Epoch: 8 [3584/8000 (45%)]\tTotal Loss: 0.813454\n",
      "Reconstruction: 0.723177, Regularization: 0.027235, Discriminator: 0.040674; Generator: 0.022368,\n",
      "D(x): 0.545, D(G(z)): 0.489\n",
      "2019-04-09 22:45:31,832 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 0.879551\n",
      "Reconstruction: 0.786039, Regularization: 0.030156, Discriminator: 0.040965; Generator: 0.022391,\n",
      "D(x): 0.539, D(G(z)): 0.488\n",
      "2019-04-09 22:45:31,930 root         INFO     Train Epoch: 8 [4608/8000 (58%)]\tTotal Loss: 0.842668\n",
      "Reconstruction: 0.755700, Regularization: 0.021755, Discriminator: 0.042792; Generator: 0.022421,\n",
      "D(x): 0.512, D(G(z)): 0.488\n",
      "2019-04-09 22:45:32,029 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 0.974328\n",
      "Reconstruction: 0.885791, Regularization: 0.026474, Discriminator: 0.039611; Generator: 0.022451,\n",
      "D(x): 0.564, D(G(z)): 0.488\n",
      "2019-04-09 22:45:32,126 root         INFO     Train Epoch: 8 [5632/8000 (70%)]\tTotal Loss: 0.698487\n",
      "Reconstruction: 0.608903, Regularization: 0.026150, Discriminator: 0.040969; Generator: 0.022465,\n",
      "D(x): 0.540, D(G(z)): 0.487\n",
      "2019-04-09 22:45:32,224 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 0.766798\n",
      "Reconstruction: 0.674888, Regularization: 0.026416, Discriminator: 0.043027; Generator: 0.022467,\n",
      "D(x): 0.508, D(G(z)): 0.487\n",
      "2019-04-09 22:45:32,322 root         INFO     Train Epoch: 8 [6656/8000 (83%)]\tTotal Loss: 1.293642\n",
      "Reconstruction: 1.200194, Regularization: 0.031303, Discriminator: 0.039599; Generator: 0.022545,\n",
      "D(x): 0.572, D(G(z)): 0.486\n",
      "2019-04-09 22:45:32,420 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 0.855374\n",
      "Reconstruction: 0.754128, Regularization: 0.037353, Discriminator: 0.041335; Generator: 0.022559,\n",
      "D(x): 0.538, D(G(z)): 0.486\n",
      "2019-04-09 22:45:32,518 root         INFO     Train Epoch: 8 [7680/8000 (96%)]\tTotal Loss: 1.509639\n",
      "Reconstruction: 1.423214, Regularization: 0.021874, Discriminator: 0.041918; Generator: 0.022633,\n",
      "D(x): 0.542, D(G(z)): 0.485\n",
      "2019-04-09 22:45:32,592 root         INFO     ====> Epoch: 8 Average loss: 1.0451\n",
      "2019-04-09 22:45:32,618 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 1.008410\n",
      "Reconstruction: 0.917789, Regularization: 0.029328, Discriminator: 0.038631; Generator: 0.022661,\n",
      "D(x): 0.577, D(G(z)): 0.484\n",
      "2019-04-09 22:45:32,718 root         INFO     Train Epoch: 9 [512/8000 (6%)]\tTotal Loss: 1.058730\n",
      "Reconstruction: 0.967836, Regularization: 0.024972, Discriminator: 0.043280; Generator: 0.022642,\n",
      "D(x): 0.511, D(G(z)): 0.485\n",
      "2019-04-09 22:45:32,816 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 1.244143\n",
      "Reconstruction: 1.151319, Regularization: 0.030614, Discriminator: 0.039505; Generator: 0.022704,\n",
      "D(x): 0.570, D(G(z)): 0.484\n",
      "2019-04-09 22:45:32,915 root         INFO     Train Epoch: 9 [1536/8000 (19%)]\tTotal Loss: 1.167467\n",
      "Reconstruction: 1.070214, Regularization: 0.032330, Discriminator: 0.042178; Generator: 0.022746,\n",
      "D(x): 0.522, D(G(z)): 0.483\n",
      "2019-04-09 22:45:33,014 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 1.050379\n",
      "Reconstruction: 0.953145, Regularization: 0.028850, Discriminator: 0.045612; Generator: 0.022771,\n",
      "D(x): 0.471, D(G(z)): 0.483\n",
      "2019-04-09 22:45:33,112 root         INFO     Train Epoch: 9 [2560/8000 (32%)]\tTotal Loss: 1.319920\n",
      "Reconstruction: 1.233332, Regularization: 0.023564, Discriminator: 0.040237; Generator: 0.022787,\n",
      "D(x): 0.567, D(G(z)): 0.482\n",
      "2019-04-09 22:45:33,211 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 0.990201\n",
      "Reconstruction: 0.901829, Regularization: 0.023309, Discriminator: 0.042232; Generator: 0.022831,\n",
      "D(x): 0.521, D(G(z)): 0.482\n",
      "2019-04-09 22:45:33,309 root         INFO     Train Epoch: 9 [3584/8000 (45%)]\tTotal Loss: 1.514938\n",
      "Reconstruction: 1.425897, Regularization: 0.024434, Discriminator: 0.041725; Generator: 0.022882,\n",
      "D(x): 0.539, D(G(z)): 0.481\n",
      "2019-04-09 22:45:33,408 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 0.894992\n",
      "Reconstruction: 0.805811, Regularization: 0.025265, Discriminator: 0.041060; Generator: 0.022856,\n",
      "D(x): 0.541, D(G(z)): 0.481\n",
      "2019-04-09 22:45:33,507 root         INFO     Train Epoch: 9 [4608/8000 (58%)]\tTotal Loss: 1.130024\n",
      "Reconstruction: 1.038811, Regularization: 0.028519, Discriminator: 0.039709; Generator: 0.022985,\n",
      "D(x): 0.561, D(G(z)): 0.479\n",
      "2019-04-09 22:45:33,606 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 0.894511\n",
      "Reconstruction: 0.806416, Regularization: 0.026715, Discriminator: 0.038373; Generator: 0.023007,\n",
      "D(x): 0.580, D(G(z)): 0.479\n",
      "2019-04-09 22:45:33,705 root         INFO     Train Epoch: 9 [5632/8000 (70%)]\tTotal Loss: 0.912167\n",
      "Reconstruction: 0.819029, Regularization: 0.028465, Discriminator: 0.041656; Generator: 0.023017,\n",
      "D(x): 0.532, D(G(z)): 0.479\n",
      "2019-04-09 22:45:33,804 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 1.160758\n",
      "Reconstruction: 1.069464, Regularization: 0.028884, Discriminator: 0.039357; Generator: 0.023053,\n",
      "D(x): 0.569, D(G(z)): 0.478\n",
      "2019-04-09 22:45:33,902 root         INFO     Train Epoch: 9 [6656/8000 (83%)]\tTotal Loss: 0.820402\n",
      "Reconstruction: 0.725915, Regularization: 0.029278, Discriminator: 0.042126; Generator: 0.023083,\n",
      "D(x): 0.519, D(G(z)): 0.478\n",
      "2019-04-09 22:45:34,001 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 1.056968\n",
      "Reconstruction: 0.967704, Regularization: 0.026625, Discriminator: 0.039539; Generator: 0.023100,\n",
      "D(x): 0.562, D(G(z)): 0.478\n",
      "2019-04-09 22:45:34,100 root         INFO     Train Epoch: 9 [7680/8000 (96%)]\tTotal Loss: 0.631834\n",
      "Reconstruction: 0.541504, Regularization: 0.027539, Discriminator: 0.039656; Generator: 0.023135,\n",
      "D(x): 0.552, D(G(z)): 0.477\n",
      "2019-04-09 22:45:34,174 root         INFO     ====> Epoch: 9 Average loss: 1.0151\n",
      "2019-04-09 22:45:34,200 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 0.988088\n",
      "Reconstruction: 0.892627, Regularization: 0.031720, Discriminator: 0.040560; Generator: 0.023181,\n",
      "D(x): 0.552, D(G(z)): 0.476\n",
      "2019-04-09 22:45:34,299 root         INFO     Train Epoch: 10 [512/8000 (6%)]\tTotal Loss: 0.780900\n",
      "Reconstruction: 0.686743, Regularization: 0.029002, Discriminator: 0.041926; Generator: 0.023229,\n",
      "D(x): 0.516, D(G(z)): 0.476\n",
      "2019-04-09 22:45:34,398 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 0.998459\n",
      "Reconstruction: 0.908751, Regularization: 0.025714, Discriminator: 0.040718; Generator: 0.023277,\n",
      "D(x): 0.543, D(G(z)): 0.475\n",
      "2019-04-09 22:45:34,497 root         INFO     Train Epoch: 10 [1536/8000 (19%)]\tTotal Loss: 0.763228\n",
      "Reconstruction: 0.669725, Regularization: 0.031115, Discriminator: 0.039032; Generator: 0.023356,\n",
      "D(x): 0.561, D(G(z)): 0.474\n",
      "2019-04-09 22:45:34,595 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 0.968825\n",
      "Reconstruction: 0.885315, Regularization: 0.018526, Discriminator: 0.041661; Generator: 0.023323,\n",
      "D(x): 0.533, D(G(z)): 0.474\n",
      "2019-04-09 22:45:34,693 root         INFO     Train Epoch: 10 [2560/8000 (32%)]\tTotal Loss: 1.002780\n",
      "Reconstruction: 0.910476, Regularization: 0.030300, Discriminator: 0.038646; Generator: 0.023359,\n",
      "D(x): 0.580, D(G(z)): 0.474\n",
      "2019-04-09 22:45:34,792 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 1.187678\n",
      "Reconstruction: 1.103099, Regularization: 0.022779, Discriminator: 0.038365; Generator: 0.023435,\n",
      "D(x): 0.578, D(G(z)): 0.472\n",
      "2019-04-09 22:45:34,891 root         INFO     Train Epoch: 10 [3584/8000 (45%)]\tTotal Loss: 1.212338\n",
      "Reconstruction: 1.120547, Regularization: 0.029002, Discriminator: 0.039303; Generator: 0.023486,\n",
      "D(x): 0.571, D(G(z)): 0.472\n",
      "2019-04-09 22:45:34,989 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 0.882947\n",
      "Reconstruction: 0.785422, Regularization: 0.031995, Discriminator: 0.041968; Generator: 0.023562,\n",
      "D(x): 0.520, D(G(z)): 0.471\n",
      "2019-04-09 22:45:35,088 root         INFO     Train Epoch: 10 [4608/8000 (58%)]\tTotal Loss: 0.723852\n",
      "Reconstruction: 0.636530, Regularization: 0.023236, Discriminator: 0.040556; Generator: 0.023529,\n",
      "D(x): 0.537, D(G(z)): 0.471\n",
      "2019-04-09 22:45:35,186 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 1.236063\n",
      "Reconstruction: 1.144801, Regularization: 0.030252, Discriminator: 0.037411; Generator: 0.023600,\n",
      "D(x): 0.598, D(G(z)): 0.470\n",
      "2019-04-09 22:45:35,285 root         INFO     Train Epoch: 10 [5632/8000 (70%)]\tTotal Loss: 1.029438\n",
      "Reconstruction: 0.937879, Regularization: 0.029533, Discriminator: 0.038388; Generator: 0.023637,\n",
      "D(x): 0.575, D(G(z)): 0.469\n",
      "2019-04-09 22:45:35,383 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 1.052164\n",
      "Reconstruction: 0.953191, Regularization: 0.033991, Discriminator: 0.041300; Generator: 0.023683,\n",
      "D(x): 0.527, D(G(z)): 0.469\n",
      "2019-04-09 22:45:35,482 root         INFO     Train Epoch: 10 [6656/8000 (83%)]\tTotal Loss: 1.332453\n",
      "Reconstruction: 1.238177, Regularization: 0.031194, Discriminator: 0.039399; Generator: 0.023682,\n",
      "D(x): 0.571, D(G(z)): 0.469\n",
      "2019-04-09 22:45:35,580 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 1.080467\n",
      "Reconstruction: 0.983934, Regularization: 0.034072, Discriminator: 0.038801; Generator: 0.023659,\n",
      "D(x): 0.574, D(G(z)): 0.469\n",
      "2019-04-09 22:45:35,679 root         INFO     Train Epoch: 10 [7680/8000 (96%)]\tTotal Loss: 1.054531\n",
      "Reconstruction: 0.964730, Regularization: 0.029035, Discriminator: 0.036876; Generator: 0.023890,\n",
      "D(x): 0.609, D(G(z)): 0.466\n",
      "2019-04-09 22:45:35,752 root         INFO     ====> Epoch: 10 Average loss: 0.9820\n",
      "2019-04-09 22:45:35,778 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.935808\n",
      "Reconstruction: 0.831529, Regularization: 0.039005, Discriminator: 0.041402; Generator: 0.023873,\n",
      "D(x): 0.527, D(G(z)): 0.466\n",
      "2019-04-09 22:45:35,877 root         INFO     Train Epoch: 11 [512/8000 (6%)]\tTotal Loss: 0.934979\n",
      "Reconstruction: 0.837320, Regularization: 0.036764, Discriminator: 0.037012; Generator: 0.023882,\n",
      "D(x): 0.596, D(G(z)): 0.466\n",
      "2019-04-09 22:45:35,975 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 0.926464\n",
      "Reconstruction: 0.838388, Regularization: 0.026090, Discriminator: 0.037984; Generator: 0.024002,\n",
      "D(x): 0.579, D(G(z)): 0.464\n",
      "2019-04-09 22:45:36,072 root         INFO     Train Epoch: 11 [1536/8000 (19%)]\tTotal Loss: 1.116094\n",
      "Reconstruction: 1.017002, Regularization: 0.037380, Discriminator: 0.037744; Generator: 0.023968,\n",
      "D(x): 0.587, D(G(z)): 0.464\n",
      "2019-04-09 22:45:36,172 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.942683\n",
      "Reconstruction: 0.854331, Regularization: 0.026638, Discriminator: 0.037557; Generator: 0.024157,\n",
      "D(x): 0.582, D(G(z)): 0.462\n",
      "2019-04-09 22:45:36,270 root         INFO     Train Epoch: 11 [2560/8000 (32%)]\tTotal Loss: 0.980756\n",
      "Reconstruction: 0.890306, Regularization: 0.028513, Discriminator: 0.037797; Generator: 0.024140,\n",
      "D(x): 0.583, D(G(z)): 0.462\n",
      "2019-04-09 22:45:36,368 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 1.103629\n",
      "Reconstruction: 1.018988, Regularization: 0.023401, Discriminator: 0.037142; Generator: 0.024097,\n",
      "D(x): 0.595, D(G(z)): 0.463\n",
      "2019-04-09 22:45:36,466 root         INFO     Train Epoch: 11 [3584/8000 (45%)]\tTotal Loss: 0.667995\n",
      "Reconstruction: 0.573921, Regularization: 0.032250, Discriminator: 0.037544; Generator: 0.024280,\n",
      "D(x): 0.572, D(G(z)): 0.460\n",
      "2019-04-09 22:45:36,564 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 1.067936\n",
      "Reconstruction: 0.977600, Regularization: 0.028868, Discriminator: 0.037188; Generator: 0.024279,\n",
      "D(x): 0.595, D(G(z)): 0.460\n",
      "2019-04-09 22:45:36,662 root         INFO     Train Epoch: 11 [4608/8000 (58%)]\tTotal Loss: 1.125702\n",
      "Reconstruction: 1.035759, Regularization: 0.027519, Discriminator: 0.038000; Generator: 0.024423,\n",
      "D(x): 0.583, D(G(z)): 0.458\n",
      "2019-04-09 22:45:36,761 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 1.054394\n",
      "Reconstruction: 0.964630, Regularization: 0.029676, Discriminator: 0.035599; Generator: 0.024488,\n",
      "D(x): 0.621, D(G(z)): 0.457\n",
      "2019-04-09 22:45:36,858 root         INFO     Train Epoch: 11 [5632/8000 (70%)]\tTotal Loss: 0.863264\n",
      "Reconstruction: 0.773319, Regularization: 0.027058, Discriminator: 0.038357; Generator: 0.024530,\n",
      "D(x): 0.578, D(G(z)): 0.456\n",
      "2019-04-09 22:45:36,957 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.909330\n",
      "Reconstruction: 0.820872, Regularization: 0.027456, Discriminator: 0.036419; Generator: 0.024582,\n",
      "D(x): 0.596, D(G(z)): 0.455\n",
      "2019-04-09 22:45:37,054 root         INFO     Train Epoch: 11 [6656/8000 (83%)]\tTotal Loss: 1.035689\n",
      "Reconstruction: 0.941102, Regularization: 0.031691, Discriminator: 0.038153; Generator: 0.024744,\n",
      "D(x): 0.564, D(G(z)): 0.453\n",
      "2019-04-09 22:45:37,156 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 1.140236\n",
      "Reconstruction: 1.044978, Regularization: 0.034579, Discriminator: 0.035977; Generator: 0.024703,\n",
      "D(x): 0.613, D(G(z)): 0.454\n",
      "2019-04-09 22:45:37,254 root         INFO     Train Epoch: 11 [7680/8000 (96%)]\tTotal Loss: 0.911920\n",
      "Reconstruction: 0.816358, Regularization: 0.031807, Discriminator: 0.038953; Generator: 0.024802,\n",
      "D(x): 0.566, D(G(z)): 0.452\n",
      "2019-04-09 22:45:37,327 root         INFO     ====> Epoch: 11 Average loss: 0.9509\n",
      "2019-04-09 22:45:37,353 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 1.155646\n",
      "Reconstruction: 1.066204, Regularization: 0.027265, Discriminator: 0.037420; Generator: 0.024757,\n",
      "D(x): 0.589, D(G(z)): 0.453\n",
      "2019-04-09 22:45:37,452 root         INFO     Train Epoch: 12 [512/8000 (6%)]\tTotal Loss: 0.897914\n",
      "Reconstruction: 0.806602, Regularization: 0.028836, Discriminator: 0.037530; Generator: 0.024946,\n",
      "D(x): 0.566, D(G(z)): 0.450\n",
      "2019-04-09 22:45:37,552 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 1.006539\n",
      "Reconstruction: 0.911797, Regularization: 0.028591, Discriminator: 0.041212; Generator: 0.024938,\n",
      "D(x): 0.523, D(G(z)): 0.450\n",
      "2019-04-09 22:45:37,652 root         INFO     Train Epoch: 12 [1536/8000 (19%)]\tTotal Loss: 0.881390\n",
      "Reconstruction: 0.799446, Regularization: 0.021574, Discriminator: 0.035114; Generator: 0.025256,\n",
      "D(x): 0.611, D(G(z)): 0.446\n",
      "2019-04-09 22:45:37,752 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 0.926088\n",
      "Reconstruction: 0.829557, Regularization: 0.031687, Discriminator: 0.039825; Generator: 0.025019,\n",
      "D(x): 0.539, D(G(z)): 0.449\n",
      "2019-04-09 22:45:37,852 root         INFO     Train Epoch: 12 [2560/8000 (32%)]\tTotal Loss: 0.737384\n",
      "Reconstruction: 0.637984, Regularization: 0.037996, Discriminator: 0.036288; Generator: 0.025115,\n",
      "D(x): 0.587, D(G(z)): 0.448\n",
      "2019-04-09 22:45:37,951 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 1.122631\n",
      "Reconstruction: 1.030843, Regularization: 0.028112, Discriminator: 0.038565; Generator: 0.025111,\n",
      "D(x): 0.564, D(G(z)): 0.448\n",
      "2019-04-09 22:45:38,051 root         INFO     Train Epoch: 12 [3584/8000 (45%)]\tTotal Loss: 1.068763\n",
      "Reconstruction: 0.981550, Regularization: 0.026254, Discriminator: 0.035554; Generator: 0.025406,\n",
      "D(x): 0.617, D(G(z)): 0.444\n",
      "2019-04-09 22:45:38,150 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 0.848287\n",
      "Reconstruction: 0.757385, Regularization: 0.028311, Discriminator: 0.036988; Generator: 0.025603,\n",
      "D(x): 0.575, D(G(z)): 0.441\n",
      "2019-04-09 22:45:38,249 root         INFO     Train Epoch: 12 [4608/8000 (58%)]\tTotal Loss: 0.803644\n",
      "Reconstruction: 0.716046, Regularization: 0.028319, Discriminator: 0.033700; Generator: 0.025579,\n",
      "D(x): 0.623, D(G(z)): 0.441\n",
      "2019-04-09 22:45:38,348 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.912261\n",
      "Reconstruction: 0.824419, Regularization: 0.024937, Discriminator: 0.037012; Generator: 0.025893,\n",
      "D(x): 0.585, D(G(z)): 0.437\n",
      "2019-04-09 22:45:38,448 root         INFO     Train Epoch: 12 [5632/8000 (70%)]\tTotal Loss: 0.760690\n",
      "Reconstruction: 0.675574, Regularization: 0.025068, Discriminator: 0.034272; Generator: 0.025776,\n",
      "D(x): 0.612, D(G(z)): 0.438\n",
      "2019-04-09 22:45:38,547 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.732859\n",
      "Reconstruction: 0.645503, Regularization: 0.027419, Discriminator: 0.033905; Generator: 0.026033,\n",
      "D(x): 0.614, D(G(z)): 0.435\n",
      "2019-04-09 22:45:38,646 root         INFO     Train Epoch: 12 [6656/8000 (83%)]\tTotal Loss: 0.709192\n",
      "Reconstruction: 0.622707, Regularization: 0.026614, Discriminator: 0.034029; Generator: 0.025842,\n",
      "D(x): 0.614, D(G(z)): 0.438\n",
      "2019-04-09 22:45:38,745 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 1.052209\n",
      "Reconstruction: 0.951990, Regularization: 0.037599, Discriminator: 0.036975; Generator: 0.025645,\n",
      "D(x): 0.580, D(G(z)): 0.440\n",
      "2019-04-09 22:45:38,845 root         INFO     Train Epoch: 12 [7680/8000 (96%)]\tTotal Loss: 1.168831\n",
      "Reconstruction: 1.065985, Regularization: 0.041029, Discriminator: 0.035796; Generator: 0.026020,\n",
      "D(x): 0.590, D(G(z)): 0.435\n",
      "2019-04-09 22:45:38,919 root         INFO     ====> Epoch: 12 Average loss: 0.9180\n",
      "2019-04-09 22:45:38,946 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 1.023400\n",
      "Reconstruction: 0.924086, Regularization: 0.036299, Discriminator: 0.036671; Generator: 0.026343,\n",
      "D(x): 0.568, D(G(z)): 0.431\n",
      "2019-04-09 22:45:39,045 root         INFO     Train Epoch: 13 [512/8000 (6%)]\tTotal Loss: 1.024838\n",
      "Reconstruction: 0.932454, Regularization: 0.030860, Discriminator: 0.035137; Generator: 0.026388,\n",
      "D(x): 0.608, D(G(z)): 0.430\n",
      "2019-04-09 22:45:39,142 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 1.403922\n",
      "Reconstruction: 1.303061, Regularization: 0.040262, Discriminator: 0.034187; Generator: 0.026411,\n",
      "D(x): 0.612, D(G(z)): 0.430\n",
      "2019-04-09 22:45:39,238 root         INFO     Train Epoch: 13 [1536/8000 (19%)]\tTotal Loss: 0.702261\n",
      "Reconstruction: 0.607908, Regularization: 0.031742, Discriminator: 0.035924; Generator: 0.026687,\n",
      "D(x): 0.584, D(G(z)): 0.426\n",
      "2019-04-09 22:45:39,336 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 1.369622\n",
      "Reconstruction: 1.282110, Regularization: 0.026184, Discriminator: 0.034824; Generator: 0.026504,\n",
      "D(x): 0.602, D(G(z)): 0.428\n",
      "2019-04-09 22:45:39,434 root         INFO     Train Epoch: 13 [2560/8000 (32%)]\tTotal Loss: 0.685745\n",
      "Reconstruction: 0.591079, Regularization: 0.032625, Discriminator: 0.034956; Generator: 0.027086,\n",
      "D(x): 0.588, D(G(z)): 0.421\n",
      "2019-04-09 22:45:39,535 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 0.815474\n",
      "Reconstruction: 0.707419, Regularization: 0.048468, Discriminator: 0.032643; Generator: 0.026944,\n",
      "D(x): 0.636, D(G(z)): 0.423\n",
      "2019-04-09 22:45:39,633 root         INFO     Train Epoch: 13 [3584/8000 (45%)]\tTotal Loss: 1.120283\n",
      "Reconstruction: 1.017004, Regularization: 0.039826, Discriminator: 0.036392; Generator: 0.027062,\n",
      "D(x): 0.565, D(G(z)): 0.421\n",
      "2019-04-09 22:45:39,729 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 0.805142\n",
      "Reconstruction: 0.710236, Regularization: 0.031097, Discriminator: 0.036819; Generator: 0.026991,\n",
      "D(x): 0.554, D(G(z)): 0.422\n",
      "2019-04-09 22:45:39,825 root         INFO     Train Epoch: 13 [4608/8000 (58%)]\tTotal Loss: 0.976429\n",
      "Reconstruction: 0.884359, Regularization: 0.033190, Discriminator: 0.031906; Generator: 0.026974,\n",
      "D(x): 0.646, D(G(z)): 0.422\n",
      "2019-04-09 22:45:39,923 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 1.061192\n",
      "Reconstruction: 0.962527, Regularization: 0.036649, Discriminator: 0.035466; Generator: 0.026550,\n",
      "D(x): 0.596, D(G(z)): 0.428\n",
      "2019-04-09 22:45:40,022 root         INFO     Train Epoch: 13 [5632/8000 (70%)]\tTotal Loss: 1.046933\n",
      "Reconstruction: 0.954335, Regularization: 0.031319, Discriminator: 0.034312; Generator: 0.026968,\n",
      "D(x): 0.604, D(G(z)): 0.422\n",
      "2019-04-09 22:45:40,120 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 0.898105\n",
      "Reconstruction: 0.811279, Regularization: 0.028129, Discriminator: 0.031061; Generator: 0.027636,\n",
      "D(x): 0.655, D(G(z)): 0.414\n",
      "2019-04-09 22:45:40,218 root         INFO     Train Epoch: 13 [6656/8000 (83%)]\tTotal Loss: 0.794153\n",
      "Reconstruction: 0.707910, Regularization: 0.023950, Discriminator: 0.034858; Generator: 0.027436,\n",
      "D(x): 0.584, D(G(z)): 0.416\n",
      "2019-04-09 22:45:40,315 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 1.152709\n",
      "Reconstruction: 1.052366, Regularization: 0.042773, Discriminator: 0.030116; Generator: 0.027455,\n",
      "D(x): 0.667, D(G(z)): 0.416\n",
      "2019-04-09 22:45:40,413 root         INFO     Train Epoch: 13 [7680/8000 (96%)]\tTotal Loss: 0.879690\n",
      "Reconstruction: 0.785465, Regularization: 0.035226, Discriminator: 0.030944; Generator: 0.028056,\n",
      "D(x): 0.652, D(G(z)): 0.409\n",
      "2019-04-09 22:45:40,488 root         INFO     ====> Epoch: 13 Average loss: 0.8908\n",
      "2019-04-09 22:45:40,514 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.989340\n",
      "Reconstruction: 0.891576, Regularization: 0.036802, Discriminator: 0.033577; Generator: 0.027385,\n",
      "D(x): 0.620, D(G(z)): 0.417\n",
      "2019-04-09 22:45:40,614 root         INFO     Train Epoch: 14 [512/8000 (6%)]\tTotal Loss: 0.589094\n",
      "Reconstruction: 0.494909, Regularization: 0.033545, Discriminator: 0.032809; Generator: 0.027831,\n",
      "D(x): 0.615, D(G(z)): 0.411\n",
      "2019-04-09 22:45:40,713 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.886917\n",
      "Reconstruction: 0.794307, Regularization: 0.032781, Discriminator: 0.031075; Generator: 0.028755,\n",
      "D(x): 0.648, D(G(z)): 0.399\n",
      "2019-04-09 22:45:40,813 root         INFO     Train Epoch: 14 [1536/8000 (19%)]\tTotal Loss: 0.848864\n",
      "Reconstruction: 0.754530, Regularization: 0.032463, Discriminator: 0.033582; Generator: 0.028288,\n",
      "D(x): 0.599, D(G(z)): 0.405\n",
      "2019-04-09 22:45:40,913 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 0.859096\n",
      "Reconstruction: 0.764094, Regularization: 0.033966, Discriminator: 0.033093; Generator: 0.027943,\n",
      "D(x): 0.622, D(G(z)): 0.410\n",
      "2019-04-09 22:45:41,013 root         INFO     Train Epoch: 14 [2560/8000 (32%)]\tTotal Loss: 1.094793\n",
      "Reconstruction: 1.003338, Regularization: 0.032718, Discriminator: 0.030081; Generator: 0.028656,\n",
      "D(x): 0.661, D(G(z)): 0.401\n",
      "2019-04-09 22:45:41,113 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.684942\n",
      "Reconstruction: 0.589122, Regularization: 0.036332, Discriminator: 0.031134; Generator: 0.028355,\n",
      "D(x): 0.635, D(G(z)): 0.405\n",
      "2019-04-09 22:45:41,211 root         INFO     Train Epoch: 14 [3584/8000 (45%)]\tTotal Loss: 1.135248\n",
      "Reconstruction: 1.041599, Regularization: 0.031499, Discriminator: 0.034280; Generator: 0.027870,\n",
      "D(x): 0.615, D(G(z)): 0.412\n",
      "2019-04-09 22:45:41,310 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.719822\n",
      "Reconstruction: 0.626061, Regularization: 0.031055, Discriminator: 0.033761; Generator: 0.028944,\n",
      "D(x): 0.610, D(G(z)): 0.397\n",
      "2019-04-09 22:45:41,409 root         INFO     Train Epoch: 14 [4608/8000 (58%)]\tTotal Loss: 0.992087\n",
      "Reconstruction: 0.896056, Regularization: 0.036438, Discriminator: 0.030951; Generator: 0.028641,\n",
      "D(x): 0.656, D(G(z)): 0.402\n",
      "2019-04-09 22:45:41,506 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 1.044791\n",
      "Reconstruction: 0.947069, Regularization: 0.034037, Discriminator: 0.035285; Generator: 0.028400,\n",
      "D(x): 0.616, D(G(z)): 0.405\n",
      "2019-04-09 22:45:41,605 root         INFO     Train Epoch: 14 [5632/8000 (70%)]\tTotal Loss: 0.970301\n",
      "Reconstruction: 0.876515, Regularization: 0.033967, Discriminator: 0.031651; Generator: 0.028168,\n",
      "D(x): 0.639, D(G(z)): 0.407\n",
      "2019-04-09 22:45:41,703 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.968673\n",
      "Reconstruction: 0.878452, Regularization: 0.027569, Discriminator: 0.033219; Generator: 0.029433,\n",
      "D(x): 0.604, D(G(z)): 0.392\n",
      "2019-04-09 22:45:41,801 root         INFO     Train Epoch: 14 [6656/8000 (83%)]\tTotal Loss: 0.861892\n",
      "Reconstruction: 0.759119, Regularization: 0.040757, Discriminator: 0.033376; Generator: 0.028640,\n",
      "D(x): 0.616, D(G(z)): 0.401\n",
      "2019-04-09 22:45:41,901 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.827481\n",
      "Reconstruction: 0.732698, Regularization: 0.035431, Discriminator: 0.030571; Generator: 0.028781,\n",
      "D(x): 0.656, D(G(z)): 0.399\n",
      "2019-04-09 22:45:41,999 root         INFO     Train Epoch: 14 [7680/8000 (96%)]\tTotal Loss: 0.850552\n",
      "Reconstruction: 0.755975, Regularization: 0.035270, Discriminator: 0.030670; Generator: 0.028637,\n",
      "D(x): 0.656, D(G(z)): 0.402\n",
      "2019-04-09 22:45:42,074 root         INFO     ====> Epoch: 14 Average loss: 0.8679\n",
      "2019-04-09 22:45:42,100 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 0.923277\n",
      "Reconstruction: 0.836221, Regularization: 0.024913, Discriminator: 0.031832; Generator: 0.030311,\n",
      "D(x): 0.639, D(G(z)): 0.380\n",
      "2019-04-09 22:45:42,201 root         INFO     Train Epoch: 15 [512/8000 (6%)]\tTotal Loss: 0.786997\n",
      "Reconstruction: 0.697313, Regularization: 0.027170, Discriminator: 0.033789; Generator: 0.028724,\n",
      "D(x): 0.616, D(G(z)): 0.401\n",
      "2019-04-09 22:45:42,302 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 1.071430\n",
      "Reconstruction: 0.981124, Regularization: 0.031521, Discriminator: 0.029444; Generator: 0.029342,\n",
      "D(x): 0.668, D(G(z)): 0.394\n",
      "2019-04-09 22:45:42,402 root         INFO     Train Epoch: 15 [1536/8000 (19%)]\tTotal Loss: 0.780229\n",
      "Reconstruction: 0.681583, Regularization: 0.040623, Discriminator: 0.028296; Generator: 0.029728,\n",
      "D(x): 0.691, D(G(z)): 0.389\n",
      "2019-04-09 22:45:42,502 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.872919\n",
      "Reconstruction: 0.780453, Regularization: 0.032368, Discriminator: 0.031052; Generator: 0.029046,\n",
      "D(x): 0.672, D(G(z)): 0.396\n",
      "2019-04-09 22:45:42,603 root         INFO     Train Epoch: 15 [2560/8000 (32%)]\tTotal Loss: 0.953583\n",
      "Reconstruction: 0.856878, Regularization: 0.031181, Discriminator: 0.034612; Generator: 0.030911,\n",
      "D(x): 0.601, D(G(z)): 0.374\n",
      "2019-04-09 22:45:42,703 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.817457\n",
      "Reconstruction: 0.717775, Regularization: 0.042915, Discriminator: 0.027143; Generator: 0.029624,\n",
      "D(x): 0.713, D(G(z)): 0.390\n",
      "2019-04-09 22:45:42,804 root         INFO     Train Epoch: 15 [3584/8000 (45%)]\tTotal Loss: 1.146810\n",
      "Reconstruction: 1.059524, Regularization: 0.027269, Discriminator: 0.030765; Generator: 0.029252,\n",
      "D(x): 0.651, D(G(z)): 0.395\n",
      "2019-04-09 22:45:42,904 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.888712\n",
      "Reconstruction: 0.796251, Regularization: 0.035308, Discriminator: 0.028469; Generator: 0.028684,\n",
      "D(x): 0.696, D(G(z)): 0.401\n",
      "2019-04-09 22:45:43,005 root         INFO     Train Epoch: 15 [4608/8000 (58%)]\tTotal Loss: 0.828212\n",
      "Reconstruction: 0.734266, Regularization: 0.033107, Discriminator: 0.030719; Generator: 0.030121,\n",
      "D(x): 0.648, D(G(z)): 0.384\n",
      "2019-04-09 22:45:43,105 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.772221\n",
      "Reconstruction: 0.674070, Regularization: 0.034912, Discriminator: 0.033989; Generator: 0.029250,\n",
      "D(x): 0.625, D(G(z)): 0.395\n",
      "2019-04-09 22:45:43,205 root         INFO     Train Epoch: 15 [5632/8000 (70%)]\tTotal Loss: 0.648824\n",
      "Reconstruction: 0.549032, Regularization: 0.040599, Discriminator: 0.028389; Generator: 0.030804,\n",
      "D(x): 0.686, D(G(z)): 0.378\n",
      "2019-04-09 22:45:43,306 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.904193\n",
      "Reconstruction: 0.808668, Regularization: 0.032776, Discriminator: 0.032750; Generator: 0.029999,\n",
      "D(x): 0.606, D(G(z)): 0.385\n",
      "2019-04-09 22:45:43,406 root         INFO     Train Epoch: 15 [6656/8000 (83%)]\tTotal Loss: 0.876486\n",
      "Reconstruction: 0.779285, Regularization: 0.037267, Discriminator: 0.029237; Generator: 0.030697,\n",
      "D(x): 0.675, D(G(z)): 0.379\n",
      "2019-04-09 22:45:43,506 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 1.138451\n",
      "Reconstruction: 1.027545, Regularization: 0.051260, Discriminator: 0.028567; Generator: 0.031078,\n",
      "D(x): 0.687, D(G(z)): 0.373\n",
      "2019-04-09 22:45:43,606 root         INFO     Train Epoch: 15 [7680/8000 (96%)]\tTotal Loss: 0.645513\n",
      "Reconstruction: 0.549115, Regularization: 0.034060, Discriminator: 0.031467; Generator: 0.030871,\n",
      "D(x): 0.632, D(G(z)): 0.375\n",
      "2019-04-09 22:45:43,681 root         INFO     ====> Epoch: 15 Average loss: 0.8470\n",
      "2019-04-09 22:45:43,707 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 0.786670\n",
      "Reconstruction: 0.695816, Regularization: 0.029377, Discriminator: 0.030665; Generator: 0.030811,\n",
      "D(x): 0.635, D(G(z)): 0.379\n",
      "2019-04-09 22:45:43,809 root         INFO     Train Epoch: 16 [512/8000 (6%)]\tTotal Loss: 0.737260\n",
      "Reconstruction: 0.645756, Regularization: 0.032554, Discriminator: 0.028776; Generator: 0.030175,\n",
      "D(x): 0.675, D(G(z)): 0.385\n",
      "2019-04-09 22:45:43,910 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 0.876807\n",
      "Reconstruction: 0.767635, Regularization: 0.048859, Discriminator: 0.029319; Generator: 0.030994,\n",
      "D(x): 0.729, D(G(z)): 0.376\n",
      "2019-04-09 22:45:44,011 root         INFO     Train Epoch: 16 [1536/8000 (19%)]\tTotal Loss: 0.839976\n",
      "Reconstruction: 0.744382, Regularization: 0.032703, Discriminator: 0.032310; Generator: 0.030582,\n",
      "D(x): 0.626, D(G(z)): 0.379\n",
      "2019-04-09 22:45:44,112 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.574343\n",
      "Reconstruction: 0.479427, Regularization: 0.035368, Discriminator: 0.028035; Generator: 0.031513,\n",
      "D(x): 0.672, D(G(z)): 0.370\n",
      "2019-04-09 22:45:44,213 root         INFO     Train Epoch: 16 [2560/8000 (32%)]\tTotal Loss: 0.871549\n",
      "Reconstruction: 0.773092, Regularization: 0.042031, Discriminator: 0.026503; Generator: 0.029923,\n",
      "D(x): 0.722, D(G(z)): 0.388\n",
      "2019-04-09 22:45:44,314 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 0.734126\n",
      "Reconstruction: 0.639880, Regularization: 0.032683, Discriminator: 0.030832; Generator: 0.030731,\n",
      "D(x): 0.652, D(G(z)): 0.378\n",
      "2019-04-09 22:45:44,415 root         INFO     Train Epoch: 16 [3584/8000 (45%)]\tTotal Loss: 0.795202\n",
      "Reconstruction: 0.691754, Regularization: 0.041442, Discriminator: 0.030401; Generator: 0.031605,\n",
      "D(x): 0.665, D(G(z)): 0.371\n",
      "2019-04-09 22:45:44,512 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 0.804064\n",
      "Reconstruction: 0.696673, Regularization: 0.053030, Discriminator: 0.025411; Generator: 0.028950,\n",
      "D(x): 0.763, D(G(z)): 0.399\n",
      "2019-04-09 22:45:44,609 root         INFO     Train Epoch: 16 [4608/8000 (58%)]\tTotal Loss: 1.182387\n",
      "Reconstruction: 1.089073, Regularization: 0.033940, Discriminator: 0.028387; Generator: 0.030987,\n",
      "D(x): 0.687, D(G(z)): 0.375\n",
      "2019-04-09 22:45:44,708 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 1.145453\n",
      "Reconstruction: 1.049617, Regularization: 0.035994, Discriminator: 0.027673; Generator: 0.032168,\n",
      "D(x): 0.687, D(G(z)): 0.361\n",
      "2019-04-09 22:45:44,807 root         INFO     Train Epoch: 16 [5632/8000 (70%)]\tTotal Loss: 1.098110\n",
      "Reconstruction: 0.996256, Regularization: 0.036242, Discriminator: 0.033555; Generator: 0.032056,\n",
      "D(x): 0.632, D(G(z)): 0.364\n",
      "2019-04-09 22:45:44,906 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 1.007752\n",
      "Reconstruction: 0.899514, Regularization: 0.044227, Discriminator: 0.032989; Generator: 0.031022,\n",
      "D(x): 0.659, D(G(z)): 0.377\n",
      "2019-04-09 22:45:45,004 root         INFO     Train Epoch: 16 [6656/8000 (83%)]\tTotal Loss: 0.924685\n",
      "Reconstruction: 0.826352, Regularization: 0.037962, Discriminator: 0.030033; Generator: 0.030338,\n",
      "D(x): 0.683, D(G(z)): 0.383\n",
      "2019-04-09 22:45:45,103 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.712398\n",
      "Reconstruction: 0.621054, Regularization: 0.026485, Discriminator: 0.034471; Generator: 0.030389,\n",
      "D(x): 0.603, D(G(z)): 0.384\n",
      "2019-04-09 22:45:45,202 root         INFO     Train Epoch: 16 [7680/8000 (96%)]\tTotal Loss: 0.665478\n",
      "Reconstruction: 0.568359, Regularization: 0.034020, Discriminator: 0.032127; Generator: 0.030972,\n",
      "D(x): 0.625, D(G(z)): 0.376\n",
      "2019-04-09 22:45:45,275 root         INFO     ====> Epoch: 16 Average loss: 0.8323\n",
      "2019-04-09 22:45:45,302 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.651872\n",
      "Reconstruction: 0.561023, Regularization: 0.029357, Discriminator: 0.028024; Generator: 0.033468,\n",
      "D(x): 0.658, D(G(z)): 0.348\n",
      "2019-04-09 22:45:45,403 root         INFO     Train Epoch: 17 [512/8000 (6%)]\tTotal Loss: 0.847999\n",
      "Reconstruction: 0.745637, Regularization: 0.043623, Discriminator: 0.027791; Generator: 0.030947,\n",
      "D(x): 0.711, D(G(z)): 0.379\n",
      "2019-04-09 22:45:45,504 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 0.781938\n",
      "Reconstruction: 0.679940, Regularization: 0.040360, Discriminator: 0.031814; Generator: 0.029824,\n",
      "D(x): 0.651, D(G(z)): 0.393\n",
      "2019-04-09 22:45:45,604 root         INFO     Train Epoch: 17 [1536/8000 (19%)]\tTotal Loss: 0.722908\n",
      "Reconstruction: 0.619507, Regularization: 0.042028, Discriminator: 0.031429; Generator: 0.029944,\n",
      "D(x): 0.662, D(G(z)): 0.389\n",
      "2019-04-09 22:45:45,705 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.670767\n",
      "Reconstruction: 0.570613, Regularization: 0.039181, Discriminator: 0.029632; Generator: 0.031342,\n",
      "D(x): 0.692, D(G(z)): 0.374\n",
      "2019-04-09 22:45:45,805 root         INFO     Train Epoch: 17 [2560/8000 (32%)]\tTotal Loss: 1.040753\n",
      "Reconstruction: 0.945466, Regularization: 0.032872, Discriminator: 0.029856; Generator: 0.032559,\n",
      "D(x): 0.652, D(G(z)): 0.361\n",
      "2019-04-09 22:45:45,903 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 0.727095\n",
      "Reconstruction: 0.625829, Regularization: 0.040554, Discriminator: 0.030540; Generator: 0.030172,\n",
      "D(x): 0.679, D(G(z)): 0.386\n",
      "2019-04-09 22:45:46,000 root         INFO     Train Epoch: 17 [3584/8000 (45%)]\tTotal Loss: 0.959203\n",
      "Reconstruction: 0.857327, Regularization: 0.040113, Discriminator: 0.031966; Generator: 0.029797,\n",
      "D(x): 0.698, D(G(z)): 0.393\n",
      "2019-04-09 22:45:46,098 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.890127\n",
      "Reconstruction: 0.796934, Regularization: 0.034214, Discriminator: 0.028290; Generator: 0.030688,\n",
      "D(x): 0.693, D(G(z)): 0.381\n",
      "2019-04-09 22:45:46,196 root         INFO     Train Epoch: 17 [4608/8000 (58%)]\tTotal Loss: 1.013665\n",
      "Reconstruction: 0.907693, Regularization: 0.038141, Discriminator: 0.037883; Generator: 0.029948,\n",
      "D(x): 0.619, D(G(z)): 0.390\n",
      "2019-04-09 22:45:46,293 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 0.669901\n",
      "Reconstruction: 0.566742, Regularization: 0.039016, Discriminator: 0.032924; Generator: 0.031218,\n",
      "D(x): 0.675, D(G(z)): 0.378\n",
      "2019-04-09 22:45:46,391 root         INFO     Train Epoch: 17 [5632/8000 (70%)]\tTotal Loss: 0.665503\n",
      "Reconstruction: 0.554328, Regularization: 0.052901, Discriminator: 0.027858; Generator: 0.030416,\n",
      "D(x): 0.719, D(G(z)): 0.384\n",
      "2019-04-09 22:45:46,489 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 0.995424\n",
      "Reconstruction: 0.904555, Regularization: 0.024616, Discriminator: 0.035933; Generator: 0.030320,\n",
      "D(x): 0.621, D(G(z)): 0.386\n",
      "2019-04-09 22:45:46,586 root         INFO     Train Epoch: 17 [6656/8000 (83%)]\tTotal Loss: 0.933212\n",
      "Reconstruction: 0.832198, Regularization: 0.037538, Discriminator: 0.032937; Generator: 0.030540,\n",
      "D(x): 0.652, D(G(z)): 0.383\n",
      "2019-04-09 22:45:46,684 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 1.002726\n",
      "Reconstruction: 0.910278, Regularization: 0.032437, Discriminator: 0.028714; Generator: 0.031298,\n",
      "D(x): 0.698, D(G(z)): 0.377\n",
      "2019-04-09 22:45:46,781 root         INFO     Train Epoch: 17 [7680/8000 (96%)]\tTotal Loss: 1.105059\n",
      "Reconstruction: 1.003341, Regularization: 0.036575, Discriminator: 0.034649; Generator: 0.030494,\n",
      "D(x): 0.647, D(G(z)): 0.385\n",
      "2019-04-09 22:45:46,854 root         INFO     ====> Epoch: 17 Average loss: 0.8235\n",
      "2019-04-09 22:45:46,880 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 1.048577\n",
      "Reconstruction: 0.938528, Regularization: 0.046268, Discriminator: 0.032794; Generator: 0.030988,\n",
      "D(x): 0.665, D(G(z)): 0.380\n",
      "2019-04-09 22:45:46,980 root         INFO     Train Epoch: 18 [512/8000 (6%)]\tTotal Loss: 0.803405\n",
      "Reconstruction: 0.707020, Regularization: 0.037912, Discriminator: 0.027904; Generator: 0.030570,\n",
      "D(x): 0.710, D(G(z)): 0.384\n",
      "2019-04-09 22:45:47,081 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.758380\n",
      "Reconstruction: 0.660534, Regularization: 0.039098, Discriminator: 0.029374; Generator: 0.029374,\n",
      "D(x): 0.711, D(G(z)): 0.401\n",
      "2019-04-09 22:45:47,180 root         INFO     Train Epoch: 18 [1536/8000 (19%)]\tTotal Loss: 0.892824\n",
      "Reconstruction: 0.784159, Regularization: 0.048435, Discriminator: 0.029731; Generator: 0.030498,\n",
      "D(x): 0.714, D(G(z)): 0.386\n",
      "2019-04-09 22:45:47,280 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 1.117803\n",
      "Reconstruction: 1.016738, Regularization: 0.044120, Discriminator: 0.027322; Generator: 0.029623,\n",
      "D(x): 0.745, D(G(z)): 0.396\n",
      "2019-04-09 22:45:47,379 root         INFO     Train Epoch: 18 [2560/8000 (32%)]\tTotal Loss: 0.949199\n",
      "Reconstruction: 0.846943, Regularization: 0.038446, Discriminator: 0.031318; Generator: 0.032491,\n",
      "D(x): 0.663, D(G(z)): 0.362\n",
      "2019-04-09 22:45:47,479 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.961606\n",
      "Reconstruction: 0.855159, Regularization: 0.040731, Discriminator: 0.035529; Generator: 0.030187,\n",
      "D(x): 0.643, D(G(z)): 0.394\n",
      "2019-04-09 22:45:47,578 root         INFO     Train Epoch: 18 [3584/8000 (45%)]\tTotal Loss: 0.554109\n",
      "Reconstruction: 0.460282, Regularization: 0.027358, Discriminator: 0.037277; Generator: 0.029192,\n",
      "D(x): 0.600, D(G(z)): 0.401\n",
      "2019-04-09 22:45:47,678 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 0.972714\n",
      "Reconstruction: 0.870022, Regularization: 0.037636, Discriminator: 0.035594; Generator: 0.029462,\n",
      "D(x): 0.630, D(G(z)): 0.395\n",
      "2019-04-09 22:45:47,777 root         INFO     Train Epoch: 18 [4608/8000 (58%)]\tTotal Loss: 1.220582\n",
      "Reconstruction: 1.102507, Regularization: 0.050604, Discriminator: 0.037214; Generator: 0.030258,\n",
      "D(x): 0.697, D(G(z)): 0.386\n",
      "2019-04-09 22:45:47,878 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.828877\n",
      "Reconstruction: 0.720258, Regularization: 0.047623, Discriminator: 0.030437; Generator: 0.030558,\n",
      "D(x): 0.684, D(G(z)): 0.384\n",
      "2019-04-09 22:45:47,977 root         INFO     Train Epoch: 18 [5632/8000 (70%)]\tTotal Loss: 0.751435\n",
      "Reconstruction: 0.648645, Regularization: 0.040292, Discriminator: 0.032037; Generator: 0.030461,\n",
      "D(x): 0.672, D(G(z)): 0.385\n",
      "2019-04-09 22:45:48,076 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 1.181809\n",
      "Reconstruction: 1.084576, Regularization: 0.035344, Discriminator: 0.032997; Generator: 0.028890,\n",
      "D(x): 0.635, D(G(z)): 0.403\n",
      "2019-04-09 22:45:48,176 root         INFO     Train Epoch: 18 [6656/8000 (83%)]\tTotal Loss: 0.891710\n",
      "Reconstruction: 0.780277, Regularization: 0.049220, Discriminator: 0.030617; Generator: 0.031596,\n",
      "D(x): 0.722, D(G(z)): 0.372\n",
      "2019-04-09 22:45:48,275 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 0.733343\n",
      "Reconstruction: 0.627286, Regularization: 0.041382, Discriminator: 0.038175; Generator: 0.026501,\n",
      "D(x): 0.622, D(G(z)): 0.438\n",
      "2019-04-09 22:45:48,374 root         INFO     Train Epoch: 18 [7680/8000 (96%)]\tTotal Loss: 0.765952\n",
      "Reconstruction: 0.664060, Regularization: 0.038456, Discriminator: 0.035042; Generator: 0.028394,\n",
      "D(x): 0.630, D(G(z)): 0.409\n",
      "2019-04-09 22:45:48,447 root         INFO     ====> Epoch: 18 Average loss: 0.8145\n",
      "2019-04-09 22:45:48,474 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 0.874258\n",
      "Reconstruction: 0.771359, Regularization: 0.042598, Discriminator: 0.031678; Generator: 0.028624,\n",
      "D(x): 0.690, D(G(z)): 0.407\n",
      "2019-04-09 22:45:48,575 root         INFO     Train Epoch: 19 [512/8000 (6%)]\tTotal Loss: 0.809561\n",
      "Reconstruction: 0.707737, Regularization: 0.034131, Discriminator: 0.036772; Generator: 0.030921,\n",
      "D(x): 0.580, D(G(z)): 0.384\n",
      "2019-04-09 22:45:48,673 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 1.064285\n",
      "Reconstruction: 0.953151, Regularization: 0.050261, Discriminator: 0.031738; Generator: 0.029136,\n",
      "D(x): 0.690, D(G(z)): 0.402\n",
      "2019-04-09 22:45:48,769 root         INFO     Train Epoch: 19 [1536/8000 (19%)]\tTotal Loss: 0.694960\n",
      "Reconstruction: 0.594974, Regularization: 0.033597, Discriminator: 0.034501; Generator: 0.031888,\n",
      "D(x): 0.633, D(G(z)): 0.369\n",
      "2019-04-09 22:45:48,865 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 0.634093\n",
      "Reconstruction: 0.531203, Regularization: 0.037267, Discriminator: 0.037164; Generator: 0.028458,\n",
      "D(x): 0.618, D(G(z)): 0.407\n",
      "2019-04-09 22:45:48,961 root         INFO     Train Epoch: 19 [2560/8000 (32%)]\tTotal Loss: 0.640330\n",
      "Reconstruction: 0.530295, Regularization: 0.043947, Discriminator: 0.035010; Generator: 0.031078,\n",
      "D(x): 0.639, D(G(z)): 0.378\n",
      "2019-04-09 22:45:49,058 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 0.537707\n",
      "Reconstruction: 0.444697, Regularization: 0.029483, Discriminator: 0.032835; Generator: 0.030692,\n",
      "D(x): 0.654, D(G(z)): 0.383\n",
      "2019-04-09 22:45:49,155 root         INFO     Train Epoch: 19 [3584/8000 (45%)]\tTotal Loss: 0.651080\n",
      "Reconstruction: 0.557229, Regularization: 0.028298, Discriminator: 0.034756; Generator: 0.030797,\n",
      "D(x): 0.611, D(G(z)): 0.377\n",
      "2019-04-09 22:45:49,252 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 1.085708\n",
      "Reconstruction: 0.972817, Regularization: 0.041975, Discriminator: 0.041412; Generator: 0.029504,\n",
      "D(x): 0.576, D(G(z)): 0.399\n",
      "2019-04-09 22:45:49,349 root         INFO     Train Epoch: 19 [4608/8000 (58%)]\tTotal Loss: 0.811979\n",
      "Reconstruction: 0.710004, Regularization: 0.040507, Discriminator: 0.032947; Generator: 0.028521,\n",
      "D(x): 0.670, D(G(z)): 0.409\n",
      "2019-04-09 22:45:49,446 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 0.839485\n",
      "Reconstruction: 0.743215, Regularization: 0.028881, Discriminator: 0.038499; Generator: 0.028890,\n",
      "D(x): 0.583, D(G(z)): 0.403\n",
      "2019-04-09 22:45:49,543 root         INFO     Train Epoch: 19 [5632/8000 (70%)]\tTotal Loss: 0.671316\n",
      "Reconstruction: 0.577628, Regularization: 0.030896, Discriminator: 0.036136; Generator: 0.026657,\n",
      "D(x): 0.628, D(G(z)): 0.434\n",
      "2019-04-09 22:45:49,640 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 1.091814\n",
      "Reconstruction: 0.994786, Regularization: 0.035914, Discriminator: 0.031901; Generator: 0.029213,\n",
      "D(x): 0.660, D(G(z)): 0.403\n",
      "2019-04-09 22:45:49,737 root         INFO     Train Epoch: 19 [6656/8000 (83%)]\tTotal Loss: 1.009583\n",
      "Reconstruction: 0.904401, Regularization: 0.037449, Discriminator: 0.037353; Generator: 0.030380,\n",
      "D(x): 0.585, D(G(z)): 0.384\n",
      "2019-04-09 22:45:49,834 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.697110\n",
      "Reconstruction: 0.593316, Regularization: 0.045832, Discriminator: 0.027897; Generator: 0.030063,\n",
      "D(x): 0.721, D(G(z)): 0.389\n",
      "2019-04-09 22:45:49,931 root         INFO     Train Epoch: 19 [7680/8000 (96%)]\tTotal Loss: 0.863753\n",
      "Reconstruction: 0.762983, Regularization: 0.032761, Discriminator: 0.038448; Generator: 0.029560,\n",
      "D(x): 0.602, D(G(z)): 0.397\n",
      "2019-04-09 22:45:50,004 root         INFO     ====> Epoch: 19 Average loss: 0.8085\n",
      "2019-04-09 22:45:50,030 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 1.170486\n",
      "Reconstruction: 1.040948, Regularization: 0.043509, Discriminator: 0.056980; Generator: 0.029049,\n",
      "D(x): 0.494, D(G(z)): 0.401\n",
      "2019-04-09 22:45:50,127 root         INFO     Train Epoch: 20 [512/8000 (6%)]\tTotal Loss: 1.158188\n",
      "Reconstruction: 1.054020, Regularization: 0.037165, Discriminator: 0.039796; Generator: 0.027207,\n",
      "D(x): 0.613, D(G(z)): 0.425\n",
      "2019-04-09 22:45:50,224 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 0.786945\n",
      "Reconstruction: 0.691211, Regularization: 0.035919, Discriminator: 0.032579; Generator: 0.027236,\n",
      "D(x): 0.695, D(G(z)): 0.423\n",
      "2019-04-09 22:45:50,321 root         INFO     Train Epoch: 20 [1536/8000 (19%)]\tTotal Loss: 1.125996\n",
      "Reconstruction: 1.015413, Regularization: 0.046749, Discriminator: 0.034288; Generator: 0.029545,\n",
      "D(x): 0.652, D(G(z)): 0.395\n",
      "2019-04-09 22:45:50,417 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 0.763542\n",
      "Reconstruction: 0.665829, Regularization: 0.035749, Discriminator: 0.033924; Generator: 0.028040,\n",
      "D(x): 0.625, D(G(z)): 0.414\n",
      "2019-04-09 22:45:50,512 root         INFO     Train Epoch: 20 [2560/8000 (32%)]\tTotal Loss: 0.748293\n",
      "Reconstruction: 0.650457, Regularization: 0.028674, Discriminator: 0.039610; Generator: 0.029552,\n",
      "D(x): 0.569, D(G(z)): 0.393\n",
      "2019-04-09 22:45:50,607 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 0.809582\n",
      "Reconstruction: 0.711801, Regularization: 0.037316, Discriminator: 0.031737; Generator: 0.028728,\n",
      "D(x): 0.678, D(G(z)): 0.404\n",
      "2019-04-09 22:45:50,702 root         INFO     Train Epoch: 20 [3584/8000 (45%)]\tTotal Loss: 0.697951\n",
      "Reconstruction: 0.595292, Regularization: 0.041622, Discriminator: 0.033145; Generator: 0.027891,\n",
      "D(x): 0.689, D(G(z)): 0.417\n",
      "2019-04-09 22:45:50,796 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 0.876518\n",
      "Reconstruction: 0.778191, Regularization: 0.034146, Discriminator: 0.034179; Generator: 0.030002,\n",
      "D(x): 0.643, D(G(z)): 0.389\n",
      "2019-04-09 22:45:50,890 root         INFO     Train Epoch: 20 [4608/8000 (58%)]\tTotal Loss: 0.723213\n",
      "Reconstruction: 0.616924, Regularization: 0.041296, Discriminator: 0.037339; Generator: 0.027654,\n",
      "D(x): 0.626, D(G(z)): 0.419\n",
      "2019-04-09 22:45:50,984 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 1.015767\n",
      "Reconstruction: 0.917416, Regularization: 0.033955, Discriminator: 0.035278; Generator: 0.029118,\n",
      "D(x): 0.603, D(G(z)): 0.402\n",
      "2019-04-09 22:45:51,079 root         INFO     Train Epoch: 20 [5632/8000 (70%)]\tTotal Loss: 1.123278\n",
      "Reconstruction: 1.015265, Regularization: 0.041956, Discriminator: 0.037812; Generator: 0.028246,\n",
      "D(x): 0.582, D(G(z)): 0.410\n",
      "2019-04-09 22:45:51,173 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 0.814699\n",
      "Reconstruction: 0.709061, Regularization: 0.043552, Discriminator: 0.034570; Generator: 0.027517,\n",
      "D(x): 0.649, D(G(z)): 0.422\n",
      "2019-04-09 22:45:51,267 root         INFO     Train Epoch: 20 [6656/8000 (83%)]\tTotal Loss: 0.812218\n",
      "Reconstruction: 0.713966, Regularization: 0.028911, Discriminator: 0.042425; Generator: 0.026916,\n",
      "D(x): 0.533, D(G(z)): 0.428\n",
      "2019-04-09 22:45:51,362 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 0.657133\n",
      "Reconstruction: 0.554469, Regularization: 0.037100, Discriminator: 0.038875; Generator: 0.026688,\n",
      "D(x): 0.586, D(G(z)): 0.433\n",
      "2019-04-09 22:45:51,456 root         INFO     Train Epoch: 20 [7680/8000 (96%)]\tTotal Loss: 0.761708\n",
      "Reconstruction: 0.662883, Regularization: 0.033881, Discriminator: 0.038647; Generator: 0.026297,\n",
      "D(x): 0.594, D(G(z)): 0.437\n",
      "2019-04-09 22:45:51,528 root         INFO     ====> Epoch: 20 Average loss: 0.8019\n",
      "2019-04-09 22:45:51,553 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.731964\n",
      "Reconstruction: 0.633142, Regularization: 0.034733, Discriminator: 0.037319; Generator: 0.026770,\n",
      "D(x): 0.603, D(G(z)): 0.429\n",
      "2019-04-09 22:45:51,650 root         INFO     Train Epoch: 21 [512/8000 (6%)]\tTotal Loss: 0.576851\n",
      "Reconstruction: 0.475423, Regularization: 0.037106, Discriminator: 0.035867; Generator: 0.028456,\n",
      "D(x): 0.621, D(G(z)): 0.408\n",
      "2019-04-09 22:45:51,746 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 0.801595\n",
      "Reconstruction: 0.699391, Regularization: 0.038191, Discriminator: 0.035913; Generator: 0.028101,\n",
      "D(x): 0.635, D(G(z)): 0.412\n",
      "2019-04-09 22:45:51,843 root         INFO     Train Epoch: 21 [1536/8000 (19%)]\tTotal Loss: 0.901740\n",
      "Reconstruction: 0.798610, Regularization: 0.031010, Discriminator: 0.043609; Generator: 0.028511,\n",
      "D(x): 0.588, D(G(z)): 0.407\n",
      "2019-04-09 22:45:51,939 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 1.233165\n",
      "Reconstruction: 1.101213, Regularization: 0.056484, Discriminator: 0.048526; Generator: 0.026942,\n",
      "D(x): 0.607, D(G(z)): 0.429\n",
      "2019-04-09 22:45:52,037 root         INFO     Train Epoch: 21 [2560/8000 (32%)]\tTotal Loss: 0.598573\n",
      "Reconstruction: 0.499574, Regularization: 0.039607, Discriminator: 0.030235; Generator: 0.029156,\n",
      "D(x): 0.673, D(G(z)): 0.399\n",
      "2019-04-09 22:45:52,133 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 0.798529\n",
      "Reconstruction: 0.697794, Regularization: 0.037166, Discriminator: 0.035783; Generator: 0.027785,\n",
      "D(x): 0.635, D(G(z)): 0.422\n",
      "2019-04-09 22:45:52,231 root         INFO     Train Epoch: 21 [3584/8000 (45%)]\tTotal Loss: 0.596137\n",
      "Reconstruction: 0.500740, Regularization: 0.024802, Discriminator: 0.043451; Generator: 0.027144,\n",
      "D(x): 0.508, D(G(z)): 0.424\n",
      "2019-04-09 22:45:52,327 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.746234\n",
      "Reconstruction: 0.642173, Regularization: 0.032462, Discriminator: 0.043743; Generator: 0.027856,\n",
      "D(x): 0.545, D(G(z)): 0.416\n",
      "2019-04-09 22:45:52,424 root         INFO     Train Epoch: 21 [4608/8000 (58%)]\tTotal Loss: 0.765659\n",
      "Reconstruction: 0.665112, Regularization: 0.033794, Discriminator: 0.039029; Generator: 0.027724,\n",
      "D(x): 0.572, D(G(z)): 0.420\n",
      "2019-04-09 22:45:52,520 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 0.718152\n",
      "Reconstruction: 0.613679, Regularization: 0.033561, Discriminator: 0.042277; Generator: 0.028634,\n",
      "D(x): 0.522, D(G(z)): 0.406\n",
      "2019-04-09 22:45:52,619 root         INFO     Train Epoch: 21 [5632/8000 (70%)]\tTotal Loss: 0.805987\n",
      "Reconstruction: 0.709324, Regularization: 0.037950, Discriminator: 0.031121; Generator: 0.027593,\n",
      "D(x): 0.670, D(G(z)): 0.418\n",
      "2019-04-09 22:45:52,716 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 0.601875\n",
      "Reconstruction: 0.496635, Regularization: 0.037225, Discriminator: 0.040277; Generator: 0.027738,\n",
      "D(x): 0.572, D(G(z)): 0.420\n",
      "2019-04-09 22:45:52,812 root         INFO     Train Epoch: 21 [6656/8000 (83%)]\tTotal Loss: 0.948233\n",
      "Reconstruction: 0.858144, Regularization: 0.023130, Discriminator: 0.040217; Generator: 0.026742,\n",
      "D(x): 0.573, D(G(z)): 0.431\n",
      "2019-04-09 22:45:52,909 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.853320\n",
      "Reconstruction: 0.760125, Regularization: 0.032176, Discriminator: 0.033138; Generator: 0.027882,\n",
      "D(x): 0.649, D(G(z)): 0.416\n",
      "2019-04-09 22:45:53,006 root         INFO     Train Epoch: 21 [7680/8000 (96%)]\tTotal Loss: 0.750159\n",
      "Reconstruction: 0.641158, Regularization: 0.032759, Discriminator: 0.048918; Generator: 0.027324,\n",
      "D(x): 0.502, D(G(z)): 0.424\n",
      "2019-04-09 22:45:53,080 root         INFO     ====> Epoch: 21 Average loss: 0.7944\n",
      "2019-04-09 22:45:53,105 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 0.801639\n",
      "Reconstruction: 0.705605, Regularization: 0.032341, Discriminator: 0.036211; Generator: 0.027481,\n",
      "D(x): 0.597, D(G(z)): 0.419\n",
      "2019-04-09 22:45:53,203 root         INFO     Train Epoch: 22 [512/8000 (6%)]\tTotal Loss: 1.124473\n",
      "Reconstruction: 1.030194, Regularization: 0.034405, Discriminator: 0.032867; Generator: 0.027008,\n",
      "D(x): 0.648, D(G(z)): 0.425\n",
      "2019-04-09 22:45:53,301 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 0.836188\n",
      "Reconstruction: 0.731824, Regularization: 0.031925, Discriminator: 0.046380; Generator: 0.026060,\n",
      "D(x): 0.541, D(G(z)): 0.439\n",
      "2019-04-09 22:45:53,402 root         INFO     Train Epoch: 22 [1536/8000 (19%)]\tTotal Loss: 1.044951\n",
      "Reconstruction: 0.946337, Regularization: 0.034731, Discriminator: 0.038190; Generator: 0.025693,\n",
      "D(x): 0.585, D(G(z)): 0.444\n",
      "2019-04-09 22:45:53,503 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 0.641402\n",
      "Reconstruction: 0.542229, Regularization: 0.035884, Discriminator: 0.036851; Generator: 0.026439,\n",
      "D(x): 0.617, D(G(z)): 0.433\n",
      "2019-04-09 22:45:53,603 root         INFO     Train Epoch: 22 [2560/8000 (32%)]\tTotal Loss: 0.514723\n",
      "Reconstruction: 0.406084, Regularization: 0.042229, Discriminator: 0.039220; Generator: 0.027190,\n",
      "D(x): 0.564, D(G(z)): 0.423\n",
      "2019-04-09 22:45:53,703 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 0.997127\n",
      "Reconstruction: 0.904985, Regularization: 0.026091, Discriminator: 0.039645; Generator: 0.026405,\n",
      "D(x): 0.553, D(G(z)): 0.433\n",
      "2019-04-09 22:45:53,804 root         INFO     Train Epoch: 22 [3584/8000 (45%)]\tTotal Loss: 0.727271\n",
      "Reconstruction: 0.627410, Regularization: 0.034867, Discriminator: 0.038195; Generator: 0.026799,\n",
      "D(x): 0.584, D(G(z)): 0.429\n",
      "2019-04-09 22:45:53,905 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.782790\n",
      "Reconstruction: 0.671103, Regularization: 0.043608, Discriminator: 0.041801; Generator: 0.026277,\n",
      "D(x): 0.549, D(G(z)): 0.434\n",
      "2019-04-09 22:45:54,006 root         INFO     Train Epoch: 22 [4608/8000 (58%)]\tTotal Loss: 0.550935\n",
      "Reconstruction: 0.446880, Regularization: 0.039001, Discriminator: 0.039236; Generator: 0.025818,\n",
      "D(x): 0.584, D(G(z)): 0.440\n",
      "2019-04-09 22:45:54,106 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 0.598937\n",
      "Reconstruction: 0.508812, Regularization: 0.018030, Discriminator: 0.045679; Generator: 0.026417,\n",
      "D(x): 0.493, D(G(z)): 0.435\n",
      "2019-04-09 22:45:54,207 root         INFO     Train Epoch: 22 [5632/8000 (70%)]\tTotal Loss: 0.786665\n",
      "Reconstruction: 0.693054, Regularization: 0.027860, Discriminator: 0.039637; Generator: 0.026114,\n",
      "D(x): 0.558, D(G(z)): 0.439\n",
      "2019-04-09 22:45:54,307 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 0.749279\n",
      "Reconstruction: 0.648830, Regularization: 0.030482, Discriminator: 0.043654; Generator: 0.026312,\n",
      "D(x): 0.533, D(G(z)): 0.434\n",
      "2019-04-09 22:45:54,406 root         INFO     Train Epoch: 22 [6656/8000 (83%)]\tTotal Loss: 0.679231\n",
      "Reconstruction: 0.566218, Regularization: 0.048323, Discriminator: 0.039023; Generator: 0.025667,\n",
      "D(x): 0.574, D(G(z)): 0.444\n",
      "2019-04-09 22:45:54,505 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 0.750173\n",
      "Reconstruction: 0.636648, Regularization: 0.045719, Discriminator: 0.042679; Generator: 0.025126,\n",
      "D(x): 0.562, D(G(z)): 0.451\n",
      "2019-04-09 22:45:54,603 root         INFO     Train Epoch: 22 [7680/8000 (96%)]\tTotal Loss: 0.883975\n",
      "Reconstruction: 0.777928, Regularization: 0.035163, Discriminator: 0.044256; Generator: 0.026627,\n",
      "D(x): 0.551, D(G(z)): 0.431\n",
      "2019-04-09 22:45:54,676 root         INFO     ====> Epoch: 22 Average loss: 0.7861\n",
      "2019-04-09 22:45:54,703 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 0.781037\n",
      "Reconstruction: 0.676389, Regularization: 0.038714, Discriminator: 0.039318; Generator: 0.026616,\n",
      "D(x): 0.568, D(G(z)): 0.430\n",
      "2019-04-09 22:45:54,803 root         INFO     Train Epoch: 23 [512/8000 (6%)]\tTotal Loss: 0.938618\n",
      "Reconstruction: 0.830275, Regularization: 0.042328, Discriminator: 0.040342; Generator: 0.025673,\n",
      "D(x): 0.560, D(G(z)): 0.445\n",
      "2019-04-09 22:45:54,903 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 0.895634\n",
      "Reconstruction: 0.787888, Regularization: 0.043415, Discriminator: 0.038783; Generator: 0.025548,\n",
      "D(x): 0.578, D(G(z)): 0.444\n",
      "2019-04-09 22:45:55,002 root         INFO     Train Epoch: 23 [1536/8000 (19%)]\tTotal Loss: 1.001249\n",
      "Reconstruction: 0.891778, Regularization: 0.040266, Discriminator: 0.043994; Generator: 0.025212,\n",
      "D(x): 0.543, D(G(z)): 0.450\n",
      "2019-04-09 22:45:55,102 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 0.758154\n",
      "Reconstruction: 0.659404, Regularization: 0.035474, Discriminator: 0.037357; Generator: 0.025919,\n",
      "D(x): 0.613, D(G(z)): 0.440\n",
      "2019-04-09 22:45:55,201 root         INFO     Train Epoch: 23 [2560/8000 (32%)]\tTotal Loss: 1.038375\n",
      "Reconstruction: 0.933106, Regularization: 0.039118, Discriminator: 0.041176; Generator: 0.024975,\n",
      "D(x): 0.573, D(G(z)): 0.453\n",
      "2019-04-09 22:45:55,301 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 1.188554\n",
      "Reconstruction: 1.082206, Regularization: 0.037785, Discriminator: 0.042495; Generator: 0.026069,\n",
      "D(x): 0.520, D(G(z)): 0.437\n",
      "2019-04-09 22:45:55,400 root         INFO     Train Epoch: 23 [3584/8000 (45%)]\tTotal Loss: 0.935831\n",
      "Reconstruction: 0.828686, Regularization: 0.044838, Discriminator: 0.036808; Generator: 0.025499,\n",
      "D(x): 0.601, D(G(z)): 0.445\n",
      "2019-04-09 22:45:55,500 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 1.073807\n",
      "Reconstruction: 0.969569, Regularization: 0.034291, Discriminator: 0.044350; Generator: 0.025597,\n",
      "D(x): 0.532, D(G(z)): 0.444\n",
      "2019-04-09 22:45:55,599 root         INFO     Train Epoch: 23 [4608/8000 (58%)]\tTotal Loss: 0.830295\n",
      "Reconstruction: 0.724195, Regularization: 0.036314, Discriminator: 0.044470; Generator: 0.025316,\n",
      "D(x): 0.506, D(G(z)): 0.447\n",
      "2019-04-09 22:45:55,699 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 0.797554\n",
      "Reconstruction: 0.689846, Regularization: 0.043482, Discriminator: 0.038591; Generator: 0.025636,\n",
      "D(x): 0.563, D(G(z)): 0.443\n",
      "2019-04-09 22:45:55,798 root         INFO     Train Epoch: 23 [5632/8000 (70%)]\tTotal Loss: 0.777217\n",
      "Reconstruction: 0.677341, Regularization: 0.036896, Discriminator: 0.036908; Generator: 0.026072,\n",
      "D(x): 0.585, D(G(z)): 0.437\n",
      "2019-04-09 22:45:55,897 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 0.891394\n",
      "Reconstruction: 0.792584, Regularization: 0.033248, Discriminator: 0.040641; Generator: 0.024921,\n",
      "D(x): 0.558, D(G(z)): 0.453\n",
      "2019-04-09 22:45:55,995 root         INFO     Train Epoch: 23 [6656/8000 (83%)]\tTotal Loss: 0.828184\n",
      "Reconstruction: 0.730801, Regularization: 0.032991, Discriminator: 0.039550; Generator: 0.024843,\n",
      "D(x): 0.564, D(G(z)): 0.457\n",
      "2019-04-09 22:45:56,092 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 0.742150\n",
      "Reconstruction: 0.645387, Regularization: 0.029427, Discriminator: 0.042590; Generator: 0.024746,\n",
      "D(x): 0.526, D(G(z)): 0.455\n",
      "2019-04-09 22:45:56,190 root         INFO     Train Epoch: 23 [7680/8000 (96%)]\tTotal Loss: 0.731613\n",
      "Reconstruction: 0.621978, Regularization: 0.043644, Discriminator: 0.040666; Generator: 0.025325,\n",
      "D(x): 0.545, D(G(z)): 0.448\n",
      "2019-04-09 22:45:56,264 root         INFO     ====> Epoch: 23 Average loss: 0.7782\n",
      "2019-04-09 22:45:56,290 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.872416\n",
      "Reconstruction: 0.764071, Regularization: 0.035235, Discriminator: 0.048480; Generator: 0.024630,\n",
      "D(x): 0.454, D(G(z)): 0.457\n",
      "2019-04-09 22:45:56,391 root         INFO     Train Epoch: 24 [512/8000 (6%)]\tTotal Loss: 0.763594\n",
      "Reconstruction: 0.647891, Regularization: 0.046720, Discriminator: 0.044191; Generator: 0.024791,\n",
      "D(x): 0.518, D(G(z)): 0.455\n",
      "2019-04-09 22:45:56,491 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 0.714819\n",
      "Reconstruction: 0.611511, Regularization: 0.036309, Discriminator: 0.041092; Generator: 0.025907,\n",
      "D(x): 0.542, D(G(z)): 0.439\n",
      "2019-04-09 22:45:56,590 root         INFO     Train Epoch: 24 [1536/8000 (19%)]\tTotal Loss: 0.953161\n",
      "Reconstruction: 0.868550, Regularization: 0.016541, Discriminator: 0.043201; Generator: 0.024869,\n",
      "D(x): 0.543, D(G(z)): 0.453\n",
      "2019-04-09 22:45:56,686 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 1.028943\n",
      "Reconstruction: 0.922840, Regularization: 0.035339, Discriminator: 0.046645; Generator: 0.024119,\n",
      "D(x): 0.496, D(G(z)): 0.464\n",
      "2019-04-09 22:45:56,782 root         INFO     Train Epoch: 24 [2560/8000 (32%)]\tTotal Loss: 0.604532\n",
      "Reconstruction: 0.511312, Regularization: 0.025715, Discriminator: 0.043579; Generator: 0.023926,\n",
      "D(x): 0.529, D(G(z)): 0.468\n",
      "2019-04-09 22:45:56,876 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 1.098113\n",
      "Reconstruction: 0.985973, Regularization: 0.045416, Discriminator: 0.042293; Generator: 0.024431,\n",
      "D(x): 0.530, D(G(z)): 0.460\n",
      "2019-04-09 22:45:56,971 root         INFO     Train Epoch: 24 [3584/8000 (45%)]\tTotal Loss: 0.789160\n",
      "Reconstruction: 0.692333, Regularization: 0.029172, Discriminator: 0.042443; Generator: 0.025212,\n",
      "D(x): 0.513, D(G(z)): 0.449\n",
      "2019-04-09 22:45:57,066 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 0.685068\n",
      "Reconstruction: 0.573766, Regularization: 0.049923, Discriminator: 0.036539; Generator: 0.024840,\n",
      "D(x): 0.619, D(G(z)): 0.455\n",
      "2019-04-09 22:45:57,161 root         INFO     Train Epoch: 24 [4608/8000 (58%)]\tTotal Loss: 0.598041\n",
      "Reconstruction: 0.505076, Regularization: 0.022639, Discriminator: 0.046284; Generator: 0.024042,\n",
      "D(x): 0.508, D(G(z)): 0.465\n",
      "2019-04-09 22:45:57,257 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 0.573856\n",
      "Reconstruction: 0.473591, Regularization: 0.031107, Discriminator: 0.045498; Generator: 0.023661,\n",
      "D(x): 0.520, D(G(z)): 0.471\n",
      "2019-04-09 22:45:57,354 root         INFO     Train Epoch: 24 [5632/8000 (70%)]\tTotal Loss: 0.620796\n",
      "Reconstruction: 0.517234, Regularization: 0.033496, Discriminator: 0.045759; Generator: 0.024307,\n",
      "D(x): 0.481, D(G(z)): 0.462\n",
      "2019-04-09 22:45:57,450 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 0.631455\n",
      "Reconstruction: 0.535410, Regularization: 0.033287, Discriminator: 0.038330; Generator: 0.024428,\n",
      "D(x): 0.573, D(G(z)): 0.459\n",
      "2019-04-09 22:45:57,546 root         INFO     Train Epoch: 24 [6656/8000 (83%)]\tTotal Loss: 0.722791\n",
      "Reconstruction: 0.626072, Regularization: 0.032521, Discriminator: 0.040233; Generator: 0.023965,\n",
      "D(x): 0.557, D(G(z)): 0.467\n",
      "2019-04-09 22:45:57,643 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 0.581356\n",
      "Reconstruction: 0.481483, Regularization: 0.033577, Discriminator: 0.041751; Generator: 0.024545,\n",
      "D(x): 0.533, D(G(z)): 0.458\n",
      "2019-04-09 22:45:57,740 root         INFO     Train Epoch: 24 [7680/8000 (96%)]\tTotal Loss: 0.709863\n",
      "Reconstruction: 0.594472, Regularization: 0.038657, Discriminator: 0.052598; Generator: 0.024136,\n",
      "D(x): 0.450, D(G(z)): 0.463\n",
      "2019-04-09 22:45:57,813 root         INFO     ====> Epoch: 24 Average loss: 0.7698\n",
      "2019-04-09 22:45:57,839 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 0.836510\n",
      "Reconstruction: 0.728551, Regularization: 0.037005, Discriminator: 0.047472; Generator: 0.023482,\n",
      "D(x): 0.508, D(G(z)): 0.475\n",
      "2019-04-09 22:45:57,940 root         INFO     Train Epoch: 25 [512/8000 (6%)]\tTotal Loss: 0.688075\n",
      "Reconstruction: 0.587149, Regularization: 0.032553, Discriminator: 0.044734; Generator: 0.023638,\n",
      "D(x): 0.531, D(G(z)): 0.471\n",
      "2019-04-09 22:45:58,039 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 0.660355\n",
      "Reconstruction: 0.561398, Regularization: 0.026632, Discriminator: 0.048811; Generator: 0.023514,\n",
      "D(x): 0.464, D(G(z)): 0.473\n",
      "2019-04-09 22:45:58,140 root         INFO     Train Epoch: 25 [1536/8000 (19%)]\tTotal Loss: 0.837038\n",
      "Reconstruction: 0.724786, Regularization: 0.047708, Discriminator: 0.040339; Generator: 0.024205,\n",
      "D(x): 0.573, D(G(z)): 0.463\n",
      "2019-04-09 22:45:58,240 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 1.039191\n",
      "Reconstruction: 0.920323, Regularization: 0.048507, Discriminator: 0.045995; Generator: 0.024366,\n",
      "D(x): 0.477, D(G(z)): 0.461\n",
      "2019-04-09 22:45:58,340 root         INFO     Train Epoch: 25 [2560/8000 (32%)]\tTotal Loss: 0.586909\n",
      "Reconstruction: 0.480196, Regularization: 0.034969, Discriminator: 0.047726; Generator: 0.024018,\n",
      "D(x): 0.472, D(G(z)): 0.465\n",
      "2019-04-09 22:45:58,440 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 0.658986\n",
      "Reconstruction: 0.546897, Regularization: 0.044756, Discriminator: 0.043521; Generator: 0.023812,\n",
      "D(x): 0.514, D(G(z)): 0.469\n",
      "2019-04-09 22:45:58,540 root         INFO     Train Epoch: 25 [3584/8000 (45%)]\tTotal Loss: 1.069284\n",
      "Reconstruction: 0.956607, Regularization: 0.037421, Discriminator: 0.051026; Generator: 0.024230,\n",
      "D(x): 0.462, D(G(z)): 0.462\n",
      "2019-04-09 22:45:58,638 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 0.878482\n",
      "Reconstruction: 0.774271, Regularization: 0.036370, Discriminator: 0.043957; Generator: 0.023883,\n",
      "D(x): 0.508, D(G(z)): 0.468\n",
      "2019-04-09 22:45:58,735 root         INFO     Train Epoch: 25 [4608/8000 (58%)]\tTotal Loss: 0.788425\n",
      "Reconstruction: 0.701029, Regularization: 0.020929, Discriminator: 0.041952; Generator: 0.024514,\n",
      "D(x): 0.532, D(G(z)): 0.458\n",
      "2019-04-09 22:45:58,833 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 1.097473\n",
      "Reconstruction: 1.001346, Regularization: 0.028861, Discriminator: 0.043893; Generator: 0.023373,\n",
      "D(x): 0.515, D(G(z)): 0.475\n",
      "2019-04-09 22:45:58,930 root         INFO     Train Epoch: 25 [5632/8000 (70%)]\tTotal Loss: 0.858701\n",
      "Reconstruction: 0.755632, Regularization: 0.032880, Discriminator: 0.046195; Generator: 0.023994,\n",
      "D(x): 0.467, D(G(z)): 0.466\n",
      "2019-04-09 22:45:59,028 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.667636\n",
      "Reconstruction: 0.570132, Regularization: 0.030874, Discriminator: 0.042656; Generator: 0.023973,\n",
      "D(x): 0.519, D(G(z)): 0.466\n",
      "2019-04-09 22:45:59,125 root         INFO     Train Epoch: 25 [6656/8000 (83%)]\tTotal Loss: 0.546077\n",
      "Reconstruction: 0.452390, Regularization: 0.028451, Discriminator: 0.041229; Generator: 0.024008,\n",
      "D(x): 0.536, D(G(z)): 0.465\n",
      "2019-04-09 22:45:59,222 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 0.565578\n",
      "Reconstruction: 0.467797, Regularization: 0.035040, Discriminator: 0.039302; Generator: 0.023438,\n",
      "D(x): 0.573, D(G(z)): 0.475\n",
      "2019-04-09 22:45:59,320 root         INFO     Train Epoch: 25 [7680/8000 (96%)]\tTotal Loss: 0.607404\n",
      "Reconstruction: 0.516011, Regularization: 0.025341, Discriminator: 0.042575; Generator: 0.023477,\n",
      "D(x): 0.517, D(G(z)): 0.473\n",
      "2019-04-09 22:45:59,393 root         INFO     ====> Epoch: 25 Average loss: 0.7594\n",
      "2019-04-09 22:45:59,419 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 0.796582\n",
      "Reconstruction: 0.692170, Regularization: 0.040108, Discriminator: 0.040640; Generator: 0.023665,\n",
      "D(x): 0.545, D(G(z)): 0.470\n",
      "2019-04-09 22:45:59,519 root         INFO     Train Epoch: 26 [512/8000 (6%)]\tTotal Loss: 0.625301\n",
      "Reconstruction: 0.514268, Regularization: 0.043460, Discriminator: 0.044375; Generator: 0.023197,\n",
      "D(x): 0.525, D(G(z)): 0.478\n",
      "2019-04-09 22:45:59,618 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 0.916593\n",
      "Reconstruction: 0.810413, Regularization: 0.035928, Discriminator: 0.046727; Generator: 0.023525,\n",
      "D(x): 0.467, D(G(z)): 0.472\n",
      "2019-04-09 22:45:59,715 root         INFO     Train Epoch: 26 [1536/8000 (19%)]\tTotal Loss: 0.596706\n",
      "Reconstruction: 0.493557, Regularization: 0.038492, Discriminator: 0.040905; Generator: 0.023752,\n",
      "D(x): 0.542, D(G(z)): 0.469\n",
      "2019-04-09 22:45:59,811 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 0.766855\n",
      "Reconstruction: 0.658578, Regularization: 0.040201, Discriminator: 0.044630; Generator: 0.023446,\n",
      "D(x): 0.501, D(G(z)): 0.474\n",
      "2019-04-09 22:45:59,907 root         INFO     Train Epoch: 26 [2560/8000 (32%)]\tTotal Loss: 0.817039\n",
      "Reconstruction: 0.717898, Regularization: 0.028974, Discriminator: 0.046750; Generator: 0.023418,\n",
      "D(x): 0.461, D(G(z)): 0.473\n",
      "2019-04-09 22:46:00,003 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 0.790389\n",
      "Reconstruction: 0.684821, Regularization: 0.039698, Discriminator: 0.042248; Generator: 0.023623,\n",
      "D(x): 0.522, D(G(z)): 0.471\n",
      "2019-04-09 22:46:00,099 root         INFO     Train Epoch: 26 [3584/8000 (45%)]\tTotal Loss: 0.541479\n",
      "Reconstruction: 0.453146, Regularization: 0.021971, Discriminator: 0.042971; Generator: 0.023389,\n",
      "D(x): 0.513, D(G(z)): 0.474\n",
      "2019-04-09 22:46:00,195 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.730331\n",
      "Reconstruction: 0.624793, Regularization: 0.038452, Discriminator: 0.043659; Generator: 0.023427,\n",
      "D(x): 0.496, D(G(z)): 0.474\n",
      "2019-04-09 22:46:00,292 root         INFO     Train Epoch: 26 [4608/8000 (58%)]\tTotal Loss: 0.675383\n",
      "Reconstruction: 0.574880, Regularization: 0.030526, Discriminator: 0.046531; Generator: 0.023446,\n",
      "D(x): 0.471, D(G(z)): 0.474\n",
      "2019-04-09 22:46:00,388 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 0.961169\n",
      "Reconstruction: 0.847384, Regularization: 0.044693, Discriminator: 0.046116; Generator: 0.022976,\n",
      "D(x): 0.481, D(G(z)): 0.480\n",
      "2019-04-09 22:46:00,485 root         INFO     Train Epoch: 26 [5632/8000 (70%)]\tTotal Loss: 0.635559\n",
      "Reconstruction: 0.524447, Regularization: 0.044108, Discriminator: 0.044212; Generator: 0.022792,\n",
      "D(x): 0.497, D(G(z)): 0.483\n",
      "2019-04-09 22:46:00,581 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 0.828851\n",
      "Reconstruction: 0.719661, Regularization: 0.043635, Discriminator: 0.042646; Generator: 0.022908,\n",
      "D(x): 0.535, D(G(z)): 0.481\n",
      "2019-04-09 22:46:00,677 root         INFO     Train Epoch: 26 [6656/8000 (83%)]\tTotal Loss: 0.735322\n",
      "Reconstruction: 0.622055, Regularization: 0.041419, Discriminator: 0.048739; Generator: 0.023109,\n",
      "D(x): 0.460, D(G(z)): 0.478\n",
      "2019-04-09 22:46:00,773 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 0.855680\n",
      "Reconstruction: 0.760101, Regularization: 0.031407, Discriminator: 0.040895; Generator: 0.023277,\n",
      "D(x): 0.543, D(G(z)): 0.476\n",
      "2019-04-09 22:46:00,869 root         INFO     Train Epoch: 26 [7680/8000 (96%)]\tTotal Loss: 0.601255\n",
      "Reconstruction: 0.497114, Regularization: 0.035810, Discriminator: 0.045122; Generator: 0.023209,\n",
      "D(x): 0.481, D(G(z)): 0.477\n",
      "2019-04-09 22:46:00,940 root         INFO     ====> Epoch: 26 Average loss: 0.7526\n",
      "2019-04-09 22:46:00,967 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 1.041711\n",
      "Reconstruction: 0.917251, Regularization: 0.056040, Discriminator: 0.045557; Generator: 0.022864,\n",
      "D(x): 0.471, D(G(z)): 0.482\n",
      "2019-04-09 22:46:01,067 root         INFO     Train Epoch: 27 [512/8000 (6%)]\tTotal Loss: 0.641499\n",
      "Reconstruction: 0.548797, Regularization: 0.026055, Discriminator: 0.043840; Generator: 0.022807,\n",
      "D(x): 0.501, D(G(z)): 0.483\n",
      "2019-04-09 22:46:01,165 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.767823\n",
      "Reconstruction: 0.647404, Regularization: 0.054219, Discriminator: 0.042911; Generator: 0.023289,\n",
      "D(x): 0.507, D(G(z)): 0.475\n",
      "2019-04-09 22:46:01,264 root         INFO     Train Epoch: 27 [1536/8000 (19%)]\tTotal Loss: 0.899572\n",
      "Reconstruction: 0.789676, Regularization: 0.044522, Discriminator: 0.043035; Generator: 0.022339,\n",
      "D(x): 0.539, D(G(z)): 0.490\n",
      "2019-04-09 22:46:01,363 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 0.706707\n",
      "Reconstruction: 0.607058, Regularization: 0.031774, Discriminator: 0.045336; Generator: 0.022539,\n",
      "D(x): 0.481, D(G(z)): 0.487\n",
      "2019-04-09 22:46:01,462 root         INFO     Train Epoch: 27 [2560/8000 (32%)]\tTotal Loss: 0.865822\n",
      "Reconstruction: 0.738698, Regularization: 0.055344, Discriminator: 0.049146; Generator: 0.022634,\n",
      "D(x): 0.456, D(G(z)): 0.485\n",
      "2019-04-09 22:46:01,563 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.613700\n",
      "Reconstruction: 0.505939, Regularization: 0.039830, Discriminator: 0.045270; Generator: 0.022661,\n",
      "D(x): 0.477, D(G(z)): 0.485\n",
      "2019-04-09 22:46:01,660 root         INFO     Train Epoch: 27 [3584/8000 (45%)]\tTotal Loss: 0.763114\n",
      "Reconstruction: 0.642870, Regularization: 0.050369, Discriminator: 0.047085; Generator: 0.022790,\n",
      "D(x): 0.483, D(G(z)): 0.483\n",
      "2019-04-09 22:46:01,755 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 0.682383\n",
      "Reconstruction: 0.569484, Regularization: 0.042980, Discriminator: 0.047369; Generator: 0.022550,\n",
      "D(x): 0.457, D(G(z)): 0.487\n",
      "2019-04-09 22:46:01,848 root         INFO     Train Epoch: 27 [4608/8000 (58%)]\tTotal Loss: 0.819617\n",
      "Reconstruction: 0.703909, Regularization: 0.047704, Discriminator: 0.045436; Generator: 0.022568,\n",
      "D(x): 0.484, D(G(z)): 0.487\n",
      "2019-04-09 22:46:01,946 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.920095\n",
      "Reconstruction: 0.815179, Regularization: 0.039753, Discriminator: 0.042324; Generator: 0.022839,\n",
      "D(x): 0.518, D(G(z)): 0.482\n",
      "2019-04-09 22:46:02,042 root         INFO     Train Epoch: 27 [5632/8000 (70%)]\tTotal Loss: 0.745123\n",
      "Reconstruction: 0.632714, Regularization: 0.044324, Discriminator: 0.045813; Generator: 0.022272,\n",
      "D(x): 0.491, D(G(z)): 0.491\n",
      "2019-04-09 22:46:02,138 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.668128\n",
      "Reconstruction: 0.569432, Regularization: 0.030484, Discriminator: 0.046020; Generator: 0.022192,\n",
      "D(x): 0.479, D(G(z)): 0.492\n",
      "2019-04-09 22:46:02,234 root         INFO     Train Epoch: 27 [6656/8000 (83%)]\tTotal Loss: 0.693640\n",
      "Reconstruction: 0.592351, Regularization: 0.032283, Discriminator: 0.045954; Generator: 0.023052,\n",
      "D(x): 0.463, D(G(z)): 0.479\n",
      "2019-04-09 22:46:02,330 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 0.550268\n",
      "Reconstruction: 0.453744, Regularization: 0.030366, Discriminator: 0.043612; Generator: 0.022545,\n",
      "D(x): 0.502, D(G(z)): 0.487\n",
      "2019-04-09 22:46:02,427 root         INFO     Train Epoch: 27 [7680/8000 (96%)]\tTotal Loss: 0.467290\n",
      "Reconstruction: 0.369179, Regularization: 0.032518, Discriminator: 0.042936; Generator: 0.022657,\n",
      "D(x): 0.511, D(G(z)): 0.485\n",
      "2019-04-09 22:46:02,500 root         INFO     ====> Epoch: 27 Average loss: 0.7439\n",
      "2019-04-09 22:46:02,526 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.620736\n",
      "Reconstruction: 0.526232, Regularization: 0.023860, Discriminator: 0.047925; Generator: 0.022719,\n",
      "D(x): 0.452, D(G(z)): 0.484\n",
      "2019-04-09 22:46:02,622 root         INFO     Train Epoch: 28 [512/8000 (6%)]\tTotal Loss: 0.612097\n",
      "Reconstruction: 0.515106, Regularization: 0.028519, Discriminator: 0.045685; Generator: 0.022788,\n",
      "D(x): 0.473, D(G(z)): 0.483\n",
      "2019-04-09 22:46:02,718 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.691899\n",
      "Reconstruction: 0.595414, Regularization: 0.029353, Discriminator: 0.044752; Generator: 0.022379,\n",
      "D(x): 0.495, D(G(z)): 0.489\n",
      "2019-04-09 22:46:02,814 root         INFO     Train Epoch: 28 [1536/8000 (19%)]\tTotal Loss: 0.685903\n",
      "Reconstruction: 0.573514, Regularization: 0.044979, Discriminator: 0.044860; Generator: 0.022549,\n",
      "D(x): 0.488, D(G(z)): 0.486\n",
      "2019-04-09 22:46:02,910 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 1.040894\n",
      "Reconstruction: 0.933824, Regularization: 0.039825, Discriminator: 0.044677; Generator: 0.022568,\n",
      "D(x): 0.506, D(G(z)): 0.486\n",
      "2019-04-09 22:46:03,006 root         INFO     Train Epoch: 28 [2560/8000 (32%)]\tTotal Loss: 0.814491\n",
      "Reconstruction: 0.708425, Regularization: 0.037870, Discriminator: 0.045695; Generator: 0.022500,\n",
      "D(x): 0.480, D(G(z)): 0.487\n",
      "2019-04-09 22:46:03,101 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.666507\n",
      "Reconstruction: 0.557954, Regularization: 0.041937, Discriminator: 0.043903; Generator: 0.022713,\n",
      "D(x): 0.500, D(G(z)): 0.484\n",
      "2019-04-09 22:46:03,198 root         INFO     Train Epoch: 28 [3584/8000 (45%)]\tTotal Loss: 0.645437\n",
      "Reconstruction: 0.534390, Regularization: 0.045825, Discriminator: 0.042497; Generator: 0.022725,\n",
      "D(x): 0.521, D(G(z)): 0.484\n",
      "2019-04-09 22:46:03,294 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.995278\n",
      "Reconstruction: 0.884500, Regularization: 0.043997, Discriminator: 0.044052; Generator: 0.022729,\n",
      "D(x): 0.513, D(G(z)): 0.484\n",
      "2019-04-09 22:46:03,389 root         INFO     Train Epoch: 28 [4608/8000 (58%)]\tTotal Loss: 1.187262\n",
      "Reconstruction: 1.063381, Regularization: 0.056810, Discriminator: 0.044407; Generator: 0.022665,\n",
      "D(x): 0.497, D(G(z)): 0.485\n",
      "2019-04-09 22:46:03,486 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.752591\n",
      "Reconstruction: 0.632636, Regularization: 0.053303, Discriminator: 0.043908; Generator: 0.022743,\n",
      "D(x): 0.502, D(G(z)): 0.484\n",
      "2019-04-09 22:46:03,582 root         INFO     Train Epoch: 28 [5632/8000 (70%)]\tTotal Loss: 0.525829\n",
      "Reconstruction: 0.427585, Regularization: 0.029194, Discriminator: 0.046226; Generator: 0.022825,\n",
      "D(x): 0.460, D(G(z)): 0.482\n",
      "2019-04-09 22:46:03,679 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.730559\n",
      "Reconstruction: 0.628888, Regularization: 0.032865, Discriminator: 0.046366; Generator: 0.022440,\n",
      "D(x): 0.460, D(G(z)): 0.488\n",
      "2019-04-09 22:46:03,776 root         INFO     Train Epoch: 28 [6656/8000 (83%)]\tTotal Loss: 0.623509\n",
      "Reconstruction: 0.526354, Regularization: 0.031158, Discriminator: 0.043401; Generator: 0.022595,\n",
      "D(x): 0.502, D(G(z)): 0.486\n",
      "2019-04-09 22:46:03,872 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.589036\n",
      "Reconstruction: 0.496677, Regularization: 0.025185, Discriminator: 0.044452; Generator: 0.022722,\n",
      "D(x): 0.485, D(G(z)): 0.484\n",
      "2019-04-09 22:46:03,968 root         INFO     Train Epoch: 28 [7680/8000 (96%)]\tTotal Loss: 0.699261\n",
      "Reconstruction: 0.591400, Regularization: 0.040802, Discriminator: 0.044533; Generator: 0.022526,\n",
      "D(x): 0.480, D(G(z)): 0.487\n",
      "2019-04-09 22:46:04,041 root         INFO     ====> Epoch: 28 Average loss: 0.7372\n",
      "2019-04-09 22:46:04,067 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 0.480846\n",
      "Reconstruction: 0.384654, Regularization: 0.026864, Discriminator: 0.046649; Generator: 0.022679,\n",
      "D(x): 0.454, D(G(z)): 0.484\n",
      "2019-04-09 22:46:04,166 root         INFO     Train Epoch: 29 [512/8000 (6%)]\tTotal Loss: 0.766142\n",
      "Reconstruction: 0.639646, Regularization: 0.052292, Discriminator: 0.051816; Generator: 0.022388,\n",
      "D(x): 0.403, D(G(z)): 0.489\n",
      "2019-04-09 22:46:04,265 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 0.772869\n",
      "Reconstruction: 0.668730, Regularization: 0.036050, Discriminator: 0.045805; Generator: 0.022285,\n",
      "D(x): 0.468, D(G(z)): 0.490\n",
      "2019-04-09 22:46:04,363 root         INFO     Train Epoch: 29 [1536/8000 (19%)]\tTotal Loss: 0.556042\n",
      "Reconstruction: 0.459580, Regularization: 0.028819, Discriminator: 0.045083; Generator: 0.022559,\n",
      "D(x): 0.477, D(G(z)): 0.486\n",
      "2019-04-09 22:46:04,462 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 0.485447\n",
      "Reconstruction: 0.391564, Regularization: 0.029286, Discriminator: 0.042344; Generator: 0.022254,\n",
      "D(x): 0.516, D(G(z)): 0.491\n",
      "2019-04-09 22:46:04,560 root         INFO     Train Epoch: 29 [2560/8000 (32%)]\tTotal Loss: 0.763380\n",
      "Reconstruction: 0.648336, Regularization: 0.047115, Discriminator: 0.045604; Generator: 0.022325,\n",
      "D(x): 0.469, D(G(z)): 0.490\n",
      "2019-04-09 22:46:04,659 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 0.792986\n",
      "Reconstruction: 0.696546, Regularization: 0.029764, Discriminator: 0.044070; Generator: 0.022606,\n",
      "D(x): 0.491, D(G(z)): 0.485\n",
      "2019-04-09 22:46:04,757 root         INFO     Train Epoch: 29 [3584/8000 (45%)]\tTotal Loss: 0.643334\n",
      "Reconstruction: 0.549070, Regularization: 0.030116, Discriminator: 0.041574; Generator: 0.022574,\n",
      "D(x): 0.521, D(G(z)): 0.486\n",
      "2019-04-09 22:46:04,856 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.635061\n",
      "Reconstruction: 0.538046, Regularization: 0.031973, Discriminator: 0.043227; Generator: 0.021815,\n",
      "D(x): 0.511, D(G(z)): 0.498\n",
      "2019-04-09 22:46:04,954 root         INFO     Train Epoch: 29 [4608/8000 (58%)]\tTotal Loss: 0.862621\n",
      "Reconstruction: 0.761532, Regularization: 0.037092, Discriminator: 0.041505; Generator: 0.022492,\n",
      "D(x): 0.532, D(G(z)): 0.487\n",
      "2019-04-09 22:46:05,052 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 0.529513\n",
      "Reconstruction: 0.433829, Regularization: 0.027924, Discriminator: 0.045798; Generator: 0.021962,\n",
      "D(x): 0.478, D(G(z)): 0.495\n",
      "2019-04-09 22:46:05,151 root         INFO     Train Epoch: 29 [5632/8000 (70%)]\tTotal Loss: 0.450645\n",
      "Reconstruction: 0.361443, Regularization: 0.019255, Discriminator: 0.047825; Generator: 0.022122,\n",
      "D(x): 0.445, D(G(z)): 0.493\n",
      "2019-04-09 22:46:05,249 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 0.647707\n",
      "Reconstruction: 0.556010, Regularization: 0.025366, Discriminator: 0.044182; Generator: 0.022150,\n",
      "D(x): 0.497, D(G(z)): 0.493\n",
      "2019-04-09 22:46:05,347 root         INFO     Train Epoch: 29 [6656/8000 (83%)]\tTotal Loss: 0.829771\n",
      "Reconstruction: 0.721553, Regularization: 0.041478, Discriminator: 0.044479; Generator: 0.022262,\n",
      "D(x): 0.484, D(G(z)): 0.491\n",
      "2019-04-09 22:46:05,445 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.727437\n",
      "Reconstruction: 0.613470, Regularization: 0.044521, Discriminator: 0.047039; Generator: 0.022407,\n",
      "D(x): 0.447, D(G(z)): 0.488\n",
      "2019-04-09 22:46:05,542 root         INFO     Train Epoch: 29 [7680/8000 (96%)]\tTotal Loss: 0.678848\n",
      "Reconstruction: 0.583189, Regularization: 0.029534, Discriminator: 0.043592; Generator: 0.022533,\n",
      "D(x): 0.495, D(G(z)): 0.486\n",
      "2019-04-09 22:46:05,616 root         INFO     ====> Epoch: 29 Average loss: 0.7305\n",
      "2019-04-09 22:46:05,642 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.816667\n",
      "Reconstruction: 0.709262, Regularization: 0.039012, Discriminator: 0.046045; Generator: 0.022349,\n",
      "D(x): 0.462, D(G(z)): 0.489\n",
      "2019-04-09 22:46:05,740 root         INFO     Train Epoch: 30 [512/8000 (6%)]\tTotal Loss: 0.808535\n",
      "Reconstruction: 0.696637, Regularization: 0.045137, Discriminator: 0.043977; Generator: 0.022784,\n",
      "D(x): 0.481, D(G(z)): 0.483\n",
      "2019-04-09 22:46:05,839 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.720918\n",
      "Reconstruction: 0.625265, Regularization: 0.029294, Discriminator: 0.044006; Generator: 0.022352,\n",
      "D(x): 0.494, D(G(z)): 0.489\n",
      "2019-04-09 22:46:05,937 root         INFO     Train Epoch: 30 [1536/8000 (19%)]\tTotal Loss: 0.764117\n",
      "Reconstruction: 0.653159, Regularization: 0.044244, Discriminator: 0.044560; Generator: 0.022155,\n",
      "D(x): 0.480, D(G(z)): 0.492\n",
      "2019-04-09 22:46:06,041 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.884430\n",
      "Reconstruction: 0.778588, Regularization: 0.037386, Discriminator: 0.046181; Generator: 0.022275,\n",
      "D(x): 0.461, D(G(z)): 0.491\n",
      "2019-04-09 22:46:06,143 root         INFO     Train Epoch: 30 [2560/8000 (32%)]\tTotal Loss: 0.563294\n",
      "Reconstruction: 0.459478, Regularization: 0.036791, Discriminator: 0.044798; Generator: 0.022227,\n",
      "D(x): 0.480, D(G(z)): 0.491\n",
      "2019-04-09 22:46:06,250 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.841683\n",
      "Reconstruction: 0.722125, Regularization: 0.053389, Discriminator: 0.043767; Generator: 0.022402,\n",
      "D(x): 0.490, D(G(z)): 0.488\n",
      "2019-04-09 22:46:06,348 root         INFO     Train Epoch: 30 [3584/8000 (45%)]\tTotal Loss: 0.655854\n",
      "Reconstruction: 0.558628, Regularization: 0.032178, Discriminator: 0.042690; Generator: 0.022358,\n",
      "D(x): 0.512, D(G(z)): 0.489\n",
      "2019-04-09 22:46:06,444 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.479338\n",
      "Reconstruction: 0.385344, Regularization: 0.026824, Discriminator: 0.044923; Generator: 0.022246,\n",
      "D(x): 0.474, D(G(z)): 0.491\n",
      "2019-04-09 22:46:06,543 root         INFO     Train Epoch: 30 [4608/8000 (58%)]\tTotal Loss: 0.705228\n",
      "Reconstruction: 0.601206, Regularization: 0.036029, Discriminator: 0.045719; Generator: 0.022274,\n",
      "D(x): 0.461, D(G(z)): 0.490\n",
      "2019-04-09 22:46:06,652 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.561886\n",
      "Reconstruction: 0.458233, Regularization: 0.036050, Discriminator: 0.045285; Generator: 0.022319,\n",
      "D(x): 0.470, D(G(z)): 0.490\n",
      "2019-04-09 22:46:06,754 root         INFO     Train Epoch: 30 [5632/8000 (70%)]\tTotal Loss: 0.474491\n",
      "Reconstruction: 0.387512, Regularization: 0.019144, Discriminator: 0.045533; Generator: 0.022302,\n",
      "D(x): 0.465, D(G(z)): 0.490\n",
      "2019-04-09 22:46:06,859 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.538297\n",
      "Reconstruction: 0.449278, Regularization: 0.021596, Discriminator: 0.045142; Generator: 0.022281,\n",
      "D(x): 0.472, D(G(z)): 0.490\n",
      "2019-04-09 22:46:06,957 root         INFO     Train Epoch: 30 [6656/8000 (83%)]\tTotal Loss: 0.932577\n",
      "Reconstruction: 0.814153, Regularization: 0.051146, Discriminator: 0.044864; Generator: 0.022413,\n",
      "D(x): 0.475, D(G(z)): 0.488\n",
      "2019-04-09 22:46:07,061 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 0.617461\n",
      "Reconstruction: 0.518369, Regularization: 0.032080, Discriminator: 0.044974; Generator: 0.022038,\n",
      "D(x): 0.480, D(G(z)): 0.494\n",
      "2019-04-09 22:46:07,165 root         INFO     Train Epoch: 30 [7680/8000 (96%)]\tTotal Loss: 0.873447\n",
      "Reconstruction: 0.749897, Regularization: 0.055979, Discriminator: 0.045584; Generator: 0.021987,\n",
      "D(x): 0.472, D(G(z)): 0.495\n",
      "2019-04-09 22:46:07,240 root         INFO     ====> Epoch: 30 Average loss: 0.7249\n",
      "2019-04-09 22:46:07,266 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.651307\n",
      "Reconstruction: 0.545354, Regularization: 0.038402, Discriminator: 0.045447; Generator: 0.022105,\n",
      "D(x): 0.473, D(G(z)): 0.493\n",
      "2019-04-09 22:46:07,364 root         INFO     Train Epoch: 31 [512/8000 (6%)]\tTotal Loss: 0.942155\n",
      "Reconstruction: 0.825203, Regularization: 0.049595, Discriminator: 0.045228; Generator: 0.022129,\n",
      "D(x): 0.476, D(G(z)): 0.493\n",
      "2019-04-09 22:46:07,462 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.671859\n",
      "Reconstruction: 0.565533, Regularization: 0.040378, Discriminator: 0.043369; Generator: 0.022579,\n",
      "D(x): 0.491, D(G(z)): 0.486\n",
      "2019-04-09 22:46:07,560 root         INFO     Train Epoch: 31 [1536/8000 (19%)]\tTotal Loss: 0.587187\n",
      "Reconstruction: 0.493408, Regularization: 0.027218, Discriminator: 0.044395; Generator: 0.022166,\n",
      "D(x): 0.482, D(G(z)): 0.492\n",
      "2019-04-09 22:46:07,658 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 0.512470\n",
      "Reconstruction: 0.422534, Regularization: 0.023148, Discriminator: 0.044545; Generator: 0.022243,\n",
      "D(x): 0.481, D(G(z)): 0.491\n",
      "2019-04-09 22:46:07,756 root         INFO     Train Epoch: 31 [2560/8000 (32%)]\tTotal Loss: 0.761418\n",
      "Reconstruction: 0.650042, Regularization: 0.045199, Discriminator: 0.044266; Generator: 0.021911,\n",
      "D(x): 0.486, D(G(z)): 0.496\n",
      "2019-04-09 22:46:07,854 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.727756\n",
      "Reconstruction: 0.626443, Regularization: 0.033885, Discriminator: 0.045291; Generator: 0.022137,\n",
      "D(x): 0.471, D(G(z)): 0.493\n",
      "2019-04-09 22:46:07,952 root         INFO     Train Epoch: 31 [3584/8000 (45%)]\tTotal Loss: 0.671632\n",
      "Reconstruction: 0.565593, Regularization: 0.038974, Discriminator: 0.045094; Generator: 0.021970,\n",
      "D(x): 0.473, D(G(z)): 0.495\n",
      "2019-04-09 22:46:08,049 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.657611\n",
      "Reconstruction: 0.552225, Regularization: 0.037498, Discriminator: 0.045832; Generator: 0.022056,\n",
      "D(x): 0.465, D(G(z)): 0.494\n",
      "2019-04-09 22:46:08,147 root         INFO     Train Epoch: 31 [4608/8000 (58%)]\tTotal Loss: 0.511335\n",
      "Reconstruction: 0.417027, Regularization: 0.025861, Discriminator: 0.046234; Generator: 0.022212,\n",
      "D(x): 0.453, D(G(z)): 0.491\n",
      "2019-04-09 22:46:08,246 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.811202\n",
      "Reconstruction: 0.701893, Regularization: 0.042307, Discriminator: 0.044940; Generator: 0.022062,\n",
      "D(x): 0.475, D(G(z)): 0.494\n",
      "2019-04-09 22:46:08,346 root         INFO     Train Epoch: 31 [5632/8000 (70%)]\tTotal Loss: 0.532441\n",
      "Reconstruction: 0.440013, Regularization: 0.026449, Discriminator: 0.043608; Generator: 0.022370,\n",
      "D(x): 0.491, D(G(z)): 0.489\n",
      "2019-04-09 22:46:08,446 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 0.864479\n",
      "Reconstruction: 0.757374, Regularization: 0.041419, Discriminator: 0.043645; Generator: 0.022041,\n",
      "D(x): 0.498, D(G(z)): 0.494\n",
      "2019-04-09 22:46:08,545 root         INFO     Train Epoch: 31 [6656/8000 (83%)]\tTotal Loss: 0.732191\n",
      "Reconstruction: 0.630137, Regularization: 0.035372, Discriminator: 0.044398; Generator: 0.022283,\n",
      "D(x): 0.480, D(G(z)): 0.490\n",
      "2019-04-09 22:46:08,645 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 0.525094\n",
      "Reconstruction: 0.427449, Regularization: 0.031731, Discriminator: 0.043870; Generator: 0.022044,\n",
      "D(x): 0.491, D(G(z)): 0.494\n",
      "2019-04-09 22:46:08,744 root         INFO     Train Epoch: 31 [7680/8000 (96%)]\tTotal Loss: 0.909291\n",
      "Reconstruction: 0.791985, Regularization: 0.050925, Discriminator: 0.044331; Generator: 0.022049,\n",
      "D(x): 0.489, D(G(z)): 0.494\n",
      "2019-04-09 22:46:08,819 root         INFO     ====> Epoch: 31 Average loss: 0.7188\n",
      "2019-04-09 22:46:08,845 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.691945\n",
      "Reconstruction: 0.584034, Regularization: 0.039099, Discriminator: 0.046550; Generator: 0.022262,\n",
      "D(x): 0.450, D(G(z)): 0.491\n",
      "2019-04-09 22:46:08,945 root         INFO     Train Epoch: 32 [512/8000 (6%)]\tTotal Loss: 0.535319\n",
      "Reconstruction: 0.441007, Regularization: 0.026487, Discriminator: 0.045761; Generator: 0.022065,\n",
      "D(x): 0.461, D(G(z)): 0.494\n",
      "2019-04-09 22:46:09,045 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.642803\n",
      "Reconstruction: 0.539975, Regularization: 0.035617, Discriminator: 0.045098; Generator: 0.022113,\n",
      "D(x): 0.471, D(G(z)): 0.493\n",
      "2019-04-09 22:46:09,145 root         INFO     Train Epoch: 32 [1536/8000 (19%)]\tTotal Loss: 0.554094\n",
      "Reconstruction: 0.461612, Regularization: 0.025703, Discriminator: 0.044577; Generator: 0.022202,\n",
      "D(x): 0.477, D(G(z)): 0.491\n",
      "2019-04-09 22:46:09,244 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.519648\n",
      "Reconstruction: 0.429814, Regularization: 0.023028, Discriminator: 0.044566; Generator: 0.022241,\n",
      "D(x): 0.479, D(G(z)): 0.491\n",
      "2019-04-09 22:46:09,343 root         INFO     Train Epoch: 32 [2560/8000 (32%)]\tTotal Loss: 0.789241\n",
      "Reconstruction: 0.684943, Regularization: 0.039267, Discriminator: 0.042978; Generator: 0.022053,\n",
      "D(x): 0.505, D(G(z)): 0.494\n",
      "2019-04-09 22:46:09,442 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.737940\n",
      "Reconstruction: 0.628329, Regularization: 0.041892, Discriminator: 0.045562; Generator: 0.022157,\n",
      "D(x): 0.464, D(G(z)): 0.492\n",
      "2019-04-09 22:46:09,541 root         INFO     Train Epoch: 32 [3584/8000 (45%)]\tTotal Loss: 0.801586\n",
      "Reconstruction: 0.695306, Regularization: 0.038459, Discriminator: 0.045940; Generator: 0.021881,\n",
      "D(x): 0.465, D(G(z)): 0.497\n",
      "2019-04-09 22:46:09,641 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.790808\n",
      "Reconstruction: 0.687805, Regularization: 0.036324, Discriminator: 0.044430; Generator: 0.022249,\n",
      "D(x): 0.479, D(G(z)): 0.491\n",
      "2019-04-09 22:46:09,740 root         INFO     Train Epoch: 32 [4608/8000 (58%)]\tTotal Loss: 0.677803\n",
      "Reconstruction: 0.577736, Regularization: 0.032853, Discriminator: 0.045116; Generator: 0.022098,\n",
      "D(x): 0.471, D(G(z)): 0.493\n",
      "2019-04-09 22:46:09,839 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 1.026161\n",
      "Reconstruction: 0.909191, Regularization: 0.049487, Discriminator: 0.045354; Generator: 0.022128,\n",
      "D(x): 0.471, D(G(z)): 0.493\n",
      "2019-04-09 22:46:09,939 root         INFO     Train Epoch: 32 [5632/8000 (70%)]\tTotal Loss: 0.644415\n",
      "Reconstruction: 0.547199, Regularization: 0.029446, Discriminator: 0.045680; Generator: 0.022090,\n",
      "D(x): 0.463, D(G(z)): 0.493\n",
      "2019-04-09 22:46:10,038 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.701635\n",
      "Reconstruction: 0.599411, Regularization: 0.035625, Discriminator: 0.044429; Generator: 0.022169,\n",
      "D(x): 0.481, D(G(z)): 0.492\n",
      "2019-04-09 22:46:10,138 root         INFO     Train Epoch: 32 [6656/8000 (83%)]\tTotal Loss: 0.620474\n",
      "Reconstruction: 0.524046, Regularization: 0.029938, Discriminator: 0.044298; Generator: 0.022191,\n",
      "D(x): 0.481, D(G(z)): 0.492\n",
      "2019-04-09 22:46:10,237 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.681517\n",
      "Reconstruction: 0.587559, Regularization: 0.027178, Discriminator: 0.044764; Generator: 0.022016,\n",
      "D(x): 0.478, D(G(z)): 0.494\n",
      "2019-04-09 22:46:10,336 root         INFO     Train Epoch: 32 [7680/8000 (96%)]\tTotal Loss: 1.026904\n",
      "Reconstruction: 0.910273, Regularization: 0.050568, Discriminator: 0.043886; Generator: 0.022177,\n",
      "D(x): 0.489, D(G(z)): 0.492\n",
      "2019-04-09 22:46:10,410 root         INFO     ====> Epoch: 32 Average loss: 0.7151\n",
      "2019-04-09 22:46:10,436 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.671511\n",
      "Reconstruction: 0.578504, Regularization: 0.026674, Discriminator: 0.044223; Generator: 0.022110,\n",
      "D(x): 0.484, D(G(z)): 0.493\n",
      "2019-04-09 22:46:10,536 root         INFO     Train Epoch: 33 [512/8000 (6%)]\tTotal Loss: 0.714182\n",
      "Reconstruction: 0.610447, Regularization: 0.037934, Discriminator: 0.043634; Generator: 0.022168,\n",
      "D(x): 0.490, D(G(z)): 0.492\n",
      "2019-04-09 22:46:10,636 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.446687\n",
      "Reconstruction: 0.356946, Regularization: 0.022233, Discriminator: 0.045326; Generator: 0.022182,\n",
      "D(x): 0.464, D(G(z)): 0.492\n",
      "2019-04-09 22:46:10,736 root         INFO     Train Epoch: 33 [1536/8000 (19%)]\tTotal Loss: 0.666758\n",
      "Reconstruction: 0.569260, Regularization: 0.030805, Discriminator: 0.044440; Generator: 0.022252,\n",
      "D(x): 0.479, D(G(z)): 0.491\n",
      "2019-04-09 22:46:10,835 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.572875\n",
      "Reconstruction: 0.477136, Regularization: 0.029072, Discriminator: 0.044573; Generator: 0.022094,\n",
      "D(x): 0.479, D(G(z)): 0.493\n",
      "2019-04-09 22:46:10,935 root         INFO     Train Epoch: 33 [2560/8000 (32%)]\tTotal Loss: 0.683619\n",
      "Reconstruction: 0.580361, Regularization: 0.037144, Discriminator: 0.043854; Generator: 0.022261,\n",
      "D(x): 0.485, D(G(z)): 0.491\n",
      "2019-04-09 22:46:11,034 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.834686\n",
      "Reconstruction: 0.722556, Regularization: 0.045372, Discriminator: 0.044608; Generator: 0.022149,\n",
      "D(x): 0.477, D(G(z)): 0.492\n",
      "2019-04-09 22:46:11,133 root         INFO     Train Epoch: 33 [3584/8000 (45%)]\tTotal Loss: 0.810392\n",
      "Reconstruction: 0.704306, Regularization: 0.040729, Discriminator: 0.043163; Generator: 0.022194,\n",
      "D(x): 0.497, D(G(z)): 0.492\n",
      "2019-04-09 22:46:11,233 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 0.534331\n",
      "Reconstruction: 0.444669, Regularization: 0.023242, Discriminator: 0.044337; Generator: 0.022083,\n",
      "D(x): 0.483, D(G(z)): 0.493\n",
      "2019-04-09 22:46:11,333 root         INFO     Train Epoch: 33 [4608/8000 (58%)]\tTotal Loss: 0.615214\n",
      "Reconstruction: 0.518181, Regularization: 0.031833, Discriminator: 0.043047; Generator: 0.022153,\n",
      "D(x): 0.502, D(G(z)): 0.492\n",
      "2019-04-09 22:46:11,433 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.733915\n",
      "Reconstruction: 0.623919, Regularization: 0.044235, Discriminator: 0.043650; Generator: 0.022112,\n",
      "D(x): 0.490, D(G(z)): 0.493\n",
      "2019-04-09 22:46:11,530 root         INFO     Train Epoch: 33 [5632/8000 (70%)]\tTotal Loss: 0.800395\n",
      "Reconstruction: 0.691563, Regularization: 0.043913, Discriminator: 0.042797; Generator: 0.022121,\n",
      "D(x): 0.504, D(G(z)): 0.493\n",
      "2019-04-09 22:46:11,630 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 0.636016\n",
      "Reconstruction: 0.534276, Regularization: 0.034557, Discriminator: 0.045057; Generator: 0.022126,\n",
      "D(x): 0.469, D(G(z)): 0.493\n",
      "2019-04-09 22:46:11,728 root         INFO     Train Epoch: 33 [6656/8000 (83%)]\tTotal Loss: 0.613064\n",
      "Reconstruction: 0.518997, Regularization: 0.027939, Discriminator: 0.043984; Generator: 0.022143,\n",
      "D(x): 0.485, D(G(z)): 0.492\n",
      "2019-04-09 22:46:11,827 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.567690\n",
      "Reconstruction: 0.471173, Regularization: 0.030808, Discriminator: 0.043626; Generator: 0.022082,\n",
      "D(x): 0.491, D(G(z)): 0.493\n",
      "2019-04-09 22:46:11,926 root         INFO     Train Epoch: 33 [7680/8000 (96%)]\tTotal Loss: 0.681768\n",
      "Reconstruction: 0.575133, Regularization: 0.041073, Discriminator: 0.043389; Generator: 0.022174,\n",
      "D(x): 0.493, D(G(z)): 0.492\n",
      "2019-04-09 22:46:12,000 root         INFO     ====> Epoch: 33 Average loss: 0.7095\n",
      "2019-04-09 22:46:12,026 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.692750\n",
      "Reconstruction: 0.592499, Regularization: 0.032789, Discriminator: 0.045347; Generator: 0.022115,\n",
      "D(x): 0.466, D(G(z)): 0.493\n",
      "2019-04-09 22:46:12,125 root         INFO     Train Epoch: 34 [512/8000 (6%)]\tTotal Loss: 0.829824\n",
      "Reconstruction: 0.726380, Regularization: 0.037244, Discriminator: 0.044113; Generator: 0.022086,\n",
      "D(x): 0.486, D(G(z)): 0.493\n",
      "2019-04-09 22:46:12,223 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.729298\n",
      "Reconstruction: 0.617839, Regularization: 0.045067, Discriminator: 0.044243; Generator: 0.022149,\n",
      "D(x): 0.481, D(G(z)): 0.492\n",
      "2019-04-09 22:46:12,321 root         INFO     Train Epoch: 34 [1536/8000 (19%)]\tTotal Loss: 0.701369\n",
      "Reconstruction: 0.595199, Regularization: 0.039199, Discriminator: 0.044887; Generator: 0.022084,\n",
      "D(x): 0.473, D(G(z)): 0.493\n",
      "2019-04-09 22:46:12,419 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.438307\n",
      "Reconstruction: 0.351980, Regularization: 0.020257, Discriminator: 0.043954; Generator: 0.022116,\n",
      "D(x): 0.485, D(G(z)): 0.493\n",
      "2019-04-09 22:46:12,517 root         INFO     Train Epoch: 34 [2560/8000 (32%)]\tTotal Loss: 0.838889\n",
      "Reconstruction: 0.731703, Regularization: 0.041550, Discriminator: 0.043581; Generator: 0.022054,\n",
      "D(x): 0.492, D(G(z)): 0.494\n",
      "2019-04-09 22:46:12,615 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.797905\n",
      "Reconstruction: 0.698079, Regularization: 0.034549, Discriminator: 0.043224; Generator: 0.022053,\n",
      "D(x): 0.498, D(G(z)): 0.494\n",
      "2019-04-09 22:46:12,713 root         INFO     Train Epoch: 34 [3584/8000 (45%)]\tTotal Loss: 0.517912\n",
      "Reconstruction: 0.421423, Regularization: 0.029260, Discriminator: 0.045134; Generator: 0.022094,\n",
      "D(x): 0.467, D(G(z)): 0.493\n",
      "2019-04-09 22:46:12,810 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.635151\n",
      "Reconstruction: 0.542470, Regularization: 0.027472, Discriminator: 0.043126; Generator: 0.022083,\n",
      "D(x): 0.499, D(G(z)): 0.493\n",
      "2019-04-09 22:46:12,906 root         INFO     Train Epoch: 34 [4608/8000 (58%)]\tTotal Loss: 1.046149\n",
      "Reconstruction: 0.930895, Regularization: 0.049352, Discriminator: 0.043767; Generator: 0.022135,\n",
      "D(x): 0.490, D(G(z)): 0.492\n",
      "2019-04-09 22:46:13,004 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.516837\n",
      "Reconstruction: 0.424056, Regularization: 0.026648, Discriminator: 0.044014; Generator: 0.022119,\n",
      "D(x): 0.484, D(G(z)): 0.493\n",
      "2019-04-09 22:46:13,101 root         INFO     Train Epoch: 34 [5632/8000 (70%)]\tTotal Loss: 0.729259\n",
      "Reconstruction: 0.621333, Regularization: 0.042507, Discriminator: 0.043260; Generator: 0.022157,\n",
      "D(x): 0.495, D(G(z)): 0.492\n",
      "2019-04-09 22:46:13,198 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.525550\n",
      "Reconstruction: 0.440364, Regularization: 0.019726, Discriminator: 0.043319; Generator: 0.022141,\n",
      "D(x): 0.494, D(G(z)): 0.492\n",
      "2019-04-09 22:46:13,296 root         INFO     Train Epoch: 34 [6656/8000 (83%)]\tTotal Loss: 0.479707\n",
      "Reconstruction: 0.394538, Regularization: 0.018644, Discriminator: 0.044366; Generator: 0.022159,\n",
      "D(x): 0.479, D(G(z)): 0.492\n",
      "2019-04-09 22:46:13,392 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 0.663319\n",
      "Reconstruction: 0.566523, Regularization: 0.031399, Discriminator: 0.043297; Generator: 0.022100,\n",
      "D(x): 0.496, D(G(z)): 0.493\n",
      "2019-04-09 22:46:13,486 root         INFO     Train Epoch: 34 [7680/8000 (96%)]\tTotal Loss: 0.763053\n",
      "Reconstruction: 0.662855, Regularization: 0.034417, Discriminator: 0.043624; Generator: 0.022157,\n",
      "D(x): 0.490, D(G(z)): 0.492\n",
      "2019-04-09 22:46:13,559 root         INFO     ====> Epoch: 34 Average loss: 0.7056\n",
      "2019-04-09 22:46:13,586 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.764191\n",
      "Reconstruction: 0.670121, Regularization: 0.028377, Discriminator: 0.043579; Generator: 0.022114,\n",
      "D(x): 0.492, D(G(z)): 0.493\n",
      "2019-04-09 22:46:13,686 root         INFO     Train Epoch: 35 [512/8000 (6%)]\tTotal Loss: 0.968003\n",
      "Reconstruction: 0.860190, Regularization: 0.042252, Discriminator: 0.043412; Generator: 0.022149,\n",
      "D(x): 0.495, D(G(z)): 0.492\n",
      "2019-04-09 22:46:13,785 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.553932\n",
      "Reconstruction: 0.463052, Regularization: 0.025058, Discriminator: 0.043644; Generator: 0.022178,\n",
      "D(x): 0.489, D(G(z)): 0.492\n",
      "2019-04-09 22:46:13,884 root         INFO     Train Epoch: 35 [1536/8000 (19%)]\tTotal Loss: 0.752259\n",
      "Reconstruction: 0.645760, Regularization: 0.040657, Discriminator: 0.043717; Generator: 0.022125,\n",
      "D(x): 0.489, D(G(z)): 0.493\n",
      "2019-04-09 22:46:13,983 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.578950\n",
      "Reconstruction: 0.487122, Regularization: 0.026263, Discriminator: 0.043412; Generator: 0.022152,\n",
      "D(x): 0.493, D(G(z)): 0.492\n",
      "2019-04-09 22:46:14,082 root         INFO     Train Epoch: 35 [2560/8000 (32%)]\tTotal Loss: 0.760940\n",
      "Reconstruction: 0.664858, Regularization: 0.030963, Discriminator: 0.042977; Generator: 0.022142,\n",
      "D(x): 0.501, D(G(z)): 0.492\n",
      "2019-04-09 22:46:14,181 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.771641\n",
      "Reconstruction: 0.671909, Regularization: 0.034973, Discriminator: 0.042629; Generator: 0.022131,\n",
      "D(x): 0.506, D(G(z)): 0.493\n",
      "2019-04-09 22:46:14,277 root         INFO     Train Epoch: 35 [3584/8000 (45%)]\tTotal Loss: 0.829357\n",
      "Reconstruction: 0.731215, Regularization: 0.033455, Discriminator: 0.042541; Generator: 0.022146,\n",
      "D(x): 0.507, D(G(z)): 0.492\n",
      "2019-04-09 22:46:14,374 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.814375\n",
      "Reconstruction: 0.711112, Regularization: 0.037943, Discriminator: 0.043173; Generator: 0.022147,\n",
      "D(x): 0.497, D(G(z)): 0.492\n",
      "2019-04-09 22:46:14,470 root         INFO     Train Epoch: 35 [4608/8000 (58%)]\tTotal Loss: 0.489151\n",
      "Reconstruction: 0.399496, Regularization: 0.023403, Discriminator: 0.044098; Generator: 0.022153,\n",
      "D(x): 0.482, D(G(z)): 0.492\n",
      "2019-04-09 22:46:14,566 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.661125\n",
      "Reconstruction: 0.564569, Regularization: 0.030711, Discriminator: 0.043692; Generator: 0.022152,\n",
      "D(x): 0.489, D(G(z)): 0.492\n",
      "2019-04-09 22:46:14,662 root         INFO     Train Epoch: 35 [5632/8000 (70%)]\tTotal Loss: 0.535347\n",
      "Reconstruction: 0.442474, Regularization: 0.026981, Discriminator: 0.043727; Generator: 0.022165,\n",
      "D(x): 0.487, D(G(z)): 0.492\n",
      "2019-04-09 22:46:14,758 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.523930\n",
      "Reconstruction: 0.438137, Regularization: 0.020455, Discriminator: 0.043162; Generator: 0.022176,\n",
      "D(x): 0.496, D(G(z)): 0.492\n",
      "2019-04-09 22:46:14,854 root         INFO     Train Epoch: 35 [6656/8000 (83%)]\tTotal Loss: 0.747610\n",
      "Reconstruction: 0.653724, Regularization: 0.027954, Discriminator: 0.043740; Generator: 0.022192,\n",
      "D(x): 0.488, D(G(z)): 0.492\n",
      "2019-04-09 22:46:14,950 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.543638\n",
      "Reconstruction: 0.461192, Regularization: 0.017164, Discriminator: 0.043082; Generator: 0.022200,\n",
      "D(x): 0.497, D(G(z)): 0.491\n",
      "2019-04-09 22:46:15,046 root         INFO     Train Epoch: 35 [7680/8000 (96%)]\tTotal Loss: 0.701097\n",
      "Reconstruction: 0.607732, Regularization: 0.028914, Discriminator: 0.042266; Generator: 0.022185,\n",
      "D(x): 0.510, D(G(z)): 0.492\n",
      "2019-04-09 22:46:15,118 root         INFO     ====> Epoch: 35 Average loss: 0.7022\n",
      "2019-04-09 22:46:15,144 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 0.715712\n",
      "Reconstruction: 0.621732, Regularization: 0.029285, Discriminator: 0.042508; Generator: 0.022186,\n",
      "D(x): 0.507, D(G(z)): 0.492\n",
      "2019-04-09 22:46:15,239 root         INFO     Train Epoch: 36 [512/8000 (6%)]\tTotal Loss: 0.660073\n",
      "Reconstruction: 0.562529, Regularization: 0.032231, Discriminator: 0.043105; Generator: 0.022208,\n",
      "D(x): 0.497, D(G(z)): 0.491\n",
      "2019-04-09 22:46:15,333 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.781369\n",
      "Reconstruction: 0.683390, Regularization: 0.033101, Discriminator: 0.042692; Generator: 0.022187,\n",
      "D(x): 0.504, D(G(z)): 0.492\n",
      "2019-04-09 22:46:15,428 root         INFO     Train Epoch: 36 [1536/8000 (19%)]\tTotal Loss: 0.738123\n",
      "Reconstruction: 0.632656, Regularization: 0.040394, Discriminator: 0.042851; Generator: 0.022221,\n",
      "D(x): 0.501, D(G(z)): 0.491\n",
      "2019-04-09 22:46:15,523 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.664463\n",
      "Reconstruction: 0.567835, Regularization: 0.031028, Discriminator: 0.043381; Generator: 0.022219,\n",
      "D(x): 0.493, D(G(z)): 0.491\n",
      "2019-04-09 22:46:15,618 root         INFO     Train Epoch: 36 [2560/8000 (32%)]\tTotal Loss: 0.512714\n",
      "Reconstruction: 0.429638, Regularization: 0.017930, Discriminator: 0.042905; Generator: 0.022242,\n",
      "D(x): 0.499, D(G(z)): 0.491\n",
      "2019-04-09 22:46:15,712 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.522689\n",
      "Reconstruction: 0.437805, Regularization: 0.019834, Discriminator: 0.042834; Generator: 0.022215,\n",
      "D(x): 0.501, D(G(z)): 0.491\n",
      "2019-04-09 22:46:15,807 root         INFO     Train Epoch: 36 [3584/8000 (45%)]\tTotal Loss: 0.522138\n",
      "Reconstruction: 0.431847, Regularization: 0.023929, Discriminator: 0.044120; Generator: 0.022242,\n",
      "D(x): 0.480, D(G(z)): 0.491\n",
      "2019-04-09 22:46:15,901 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.548032\n",
      "Reconstruction: 0.459378, Regularization: 0.022823, Discriminator: 0.043574; Generator: 0.022256,\n",
      "D(x): 0.488, D(G(z)): 0.491\n",
      "2019-04-09 22:46:15,995 root         INFO     Train Epoch: 36 [4608/8000 (58%)]\tTotal Loss: 0.618784\n",
      "Reconstruction: 0.525235, Regularization: 0.028107, Discriminator: 0.043185; Generator: 0.022257,\n",
      "D(x): 0.495, D(G(z)): 0.491\n",
      "2019-04-09 22:46:16,090 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.705999\n",
      "Reconstruction: 0.598142, Regularization: 0.041551, Discriminator: 0.044031; Generator: 0.022274,\n",
      "D(x): 0.482, D(G(z)): 0.490\n",
      "2019-04-09 22:46:16,184 root         INFO     Train Epoch: 36 [5632/8000 (70%)]\tTotal Loss: 0.756846\n",
      "Reconstruction: 0.658144, Regularization: 0.032640, Discriminator: 0.043795; Generator: 0.022266,\n",
      "D(x): 0.486, D(G(z)): 0.490\n",
      "2019-04-09 22:46:16,279 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 1.018707\n",
      "Reconstruction: 0.906183, Regularization: 0.047271, Discriminator: 0.042950; Generator: 0.022303,\n",
      "D(x): 0.499, D(G(z)): 0.490\n",
      "2019-04-09 22:46:16,373 root         INFO     Train Epoch: 36 [6656/8000 (83%)]\tTotal Loss: 0.567093\n",
      "Reconstruction: 0.476315, Regularization: 0.025032, Discriminator: 0.043407; Generator: 0.022338,\n",
      "D(x): 0.490, D(G(z)): 0.489\n",
      "2019-04-09 22:46:16,467 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.840263\n",
      "Reconstruction: 0.734903, Regularization: 0.038708, Discriminator: 0.044284; Generator: 0.022369,\n",
      "D(x): 0.477, D(G(z)): 0.489\n",
      "2019-04-09 22:46:16,561 root         INFO     Train Epoch: 36 [7680/8000 (96%)]\tTotal Loss: 0.571657\n",
      "Reconstruction: 0.479514, Regularization: 0.026748, Discriminator: 0.043007; Generator: 0.022388,\n",
      "D(x): 0.495, D(G(z)): 0.489\n",
      "2019-04-09 22:46:16,632 root         INFO     ====> Epoch: 36 Average loss: 0.7011\n",
      "2019-04-09 22:46:16,659 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.572007\n",
      "Reconstruction: 0.481932, Regularization: 0.023609, Discriminator: 0.044095; Generator: 0.022370,\n",
      "D(x): 0.479, D(G(z)): 0.489\n",
      "2019-04-09 22:46:16,757 root         INFO     Train Epoch: 37 [512/8000 (6%)]\tTotal Loss: 0.629605\n",
      "Reconstruction: 0.533984, Regularization: 0.029238, Discriminator: 0.044017; Generator: 0.022366,\n",
      "D(x): 0.480, D(G(z)): 0.489\n",
      "2019-04-09 22:46:16,854 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.814694\n",
      "Reconstruction: 0.716726, Regularization: 0.032194, Discriminator: 0.043379; Generator: 0.022395,\n",
      "D(x): 0.490, D(G(z)): 0.488\n",
      "2019-04-09 22:46:16,954 root         INFO     Train Epoch: 37 [1536/8000 (19%)]\tTotal Loss: 0.768215\n",
      "Reconstruction: 0.669067, Regularization: 0.033559, Discriminator: 0.043197; Generator: 0.022392,\n",
      "D(x): 0.493, D(G(z)): 0.488\n",
      "2019-04-09 22:46:17,053 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.744429\n",
      "Reconstruction: 0.649525, Regularization: 0.029688, Discriminator: 0.042820; Generator: 0.022396,\n",
      "D(x): 0.499, D(G(z)): 0.488\n",
      "2019-04-09 22:46:17,152 root         INFO     Train Epoch: 37 [2560/8000 (32%)]\tTotal Loss: 0.856557\n",
      "Reconstruction: 0.750151, Regularization: 0.040591, Discriminator: 0.043305; Generator: 0.022510,\n",
      "D(x): 0.490, D(G(z)): 0.487\n",
      "2019-04-09 22:46:17,252 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 0.575798\n",
      "Reconstruction: 0.479844, Regularization: 0.029600, Discriminator: 0.043949; Generator: 0.022405,\n",
      "D(x): 0.481, D(G(z)): 0.488\n",
      "2019-04-09 22:46:17,351 root         INFO     Train Epoch: 37 [3584/8000 (45%)]\tTotal Loss: 0.652200\n",
      "Reconstruction: 0.552291, Regularization: 0.034512, Discriminator: 0.042864; Generator: 0.022532,\n",
      "D(x): 0.496, D(G(z)): 0.486\n",
      "2019-04-09 22:46:17,450 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.706396\n",
      "Reconstruction: 0.611628, Regularization: 0.029056, Discriminator: 0.043182; Generator: 0.022530,\n",
      "D(x): 0.491, D(G(z)): 0.486\n",
      "2019-04-09 22:46:17,550 root         INFO     Train Epoch: 37 [4608/8000 (58%)]\tTotal Loss: 0.584096\n",
      "Reconstruction: 0.490805, Regularization: 0.027602, Discriminator: 0.043246; Generator: 0.022443,\n",
      "D(x): 0.491, D(G(z)): 0.488\n",
      "2019-04-09 22:46:17,649 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.752885\n",
      "Reconstruction: 0.664843, Regularization: 0.022221, Discriminator: 0.043358; Generator: 0.022464,\n",
      "D(x): 0.489, D(G(z)): 0.487\n",
      "2019-04-09 22:46:17,748 root         INFO     Train Epoch: 37 [5632/8000 (70%)]\tTotal Loss: 0.569647\n",
      "Reconstruction: 0.486229, Regularization: 0.017512, Discriminator: 0.043361; Generator: 0.022543,\n",
      "D(x): 0.487, D(G(z)): 0.486\n",
      "2019-04-09 22:46:17,850 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.749713\n",
      "Reconstruction: 0.644310, Regularization: 0.039096, Discriminator: 0.043740; Generator: 0.022567,\n",
      "D(x): 0.482, D(G(z)): 0.486\n",
      "2019-04-09 22:46:17,947 root         INFO     Train Epoch: 37 [6656/8000 (83%)]\tTotal Loss: 0.521418\n",
      "Reconstruction: 0.436969, Regularization: 0.018883, Discriminator: 0.042892; Generator: 0.022674,\n",
      "D(x): 0.493, D(G(z)): 0.484\n",
      "2019-04-09 22:46:18,048 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.674617\n",
      "Reconstruction: 0.579540, Regularization: 0.029881, Discriminator: 0.042600; Generator: 0.022597,\n",
      "D(x): 0.499, D(G(z)): 0.485\n",
      "2019-04-09 22:46:18,146 root         INFO     Train Epoch: 37 [7680/8000 (96%)]\tTotal Loss: 0.791491\n",
      "Reconstruction: 0.691339, Regularization: 0.034721, Discriminator: 0.042887; Generator: 0.022544,\n",
      "D(x): 0.496, D(G(z)): 0.486\n",
      "2019-04-09 22:46:18,221 root         INFO     ====> Epoch: 37 Average loss: 0.7010\n",
      "2019-04-09 22:46:18,247 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.504555\n",
      "Reconstruction: 0.416210, Regularization: 0.022053, Discriminator: 0.043729; Generator: 0.022563,\n",
      "D(x): 0.481, D(G(z)): 0.486\n",
      "2019-04-09 22:46:18,348 root         INFO     Train Epoch: 38 [512/8000 (6%)]\tTotal Loss: 0.607438\n",
      "Reconstruction: 0.517795, Regularization: 0.024257, Discriminator: 0.042809; Generator: 0.022576,\n",
      "D(x): 0.496, D(G(z)): 0.486\n",
      "2019-04-09 22:46:18,447 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.590510\n",
      "Reconstruction: 0.501784, Regularization: 0.023543, Discriminator: 0.042542; Generator: 0.022640,\n",
      "D(x): 0.499, D(G(z)): 0.485\n",
      "2019-04-09 22:46:18,544 root         INFO     Train Epoch: 38 [1536/8000 (19%)]\tTotal Loss: 0.584236\n",
      "Reconstruction: 0.494257, Regularization: 0.024078, Discriminator: 0.043218; Generator: 0.022683,\n",
      "D(x): 0.488, D(G(z)): 0.484\n",
      "2019-04-09 22:46:18,641 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.735461\n",
      "Reconstruction: 0.638274, Regularization: 0.031062, Discriminator: 0.043379; Generator: 0.022746,\n",
      "D(x): 0.485, D(G(z)): 0.483\n",
      "2019-04-09 22:46:18,741 root         INFO     Train Epoch: 38 [2560/8000 (32%)]\tTotal Loss: 0.649223\n",
      "Reconstruction: 0.553607, Regularization: 0.030153, Discriminator: 0.042814; Generator: 0.022649,\n",
      "D(x): 0.495, D(G(z)): 0.484\n",
      "2019-04-09 22:46:18,838 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 1.013007\n",
      "Reconstruction: 0.899324, Regularization: 0.047657, Discriminator: 0.043197; Generator: 0.022829,\n",
      "D(x): 0.488, D(G(z)): 0.482\n",
      "2019-04-09 22:46:18,938 root         INFO     Train Epoch: 38 [3584/8000 (45%)]\tTotal Loss: 0.569071\n",
      "Reconstruction: 0.483607, Regularization: 0.020064, Discriminator: 0.042674; Generator: 0.022726,\n",
      "D(x): 0.495, D(G(z)): 0.483\n",
      "2019-04-09 22:46:19,036 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.754961\n",
      "Reconstruction: 0.665034, Regularization: 0.024460, Discriminator: 0.042730; Generator: 0.022737,\n",
      "D(x): 0.495, D(G(z)): 0.483\n",
      "2019-04-09 22:46:19,133 root         INFO     Train Epoch: 38 [4608/8000 (58%)]\tTotal Loss: 0.523392\n",
      "Reconstruction: 0.439839, Regularization: 0.018290, Discriminator: 0.042559; Generator: 0.022703,\n",
      "D(x): 0.498, D(G(z)): 0.484\n",
      "2019-04-09 22:46:19,233 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.553313\n",
      "Reconstruction: 0.468056, Regularization: 0.019807, Discriminator: 0.042710; Generator: 0.022740,\n",
      "D(x): 0.495, D(G(z)): 0.483\n",
      "2019-04-09 22:46:19,332 root         INFO     Train Epoch: 38 [5632/8000 (70%)]\tTotal Loss: 0.677669\n",
      "Reconstruction: 0.584300, Regularization: 0.028224, Discriminator: 0.042451; Generator: 0.022693,\n",
      "D(x): 0.500, D(G(z)): 0.484\n",
      "2019-04-09 22:46:19,431 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.607682\n",
      "Reconstruction: 0.516776, Regularization: 0.025896, Discriminator: 0.042235; Generator: 0.022775,\n",
      "D(x): 0.502, D(G(z)): 0.483\n",
      "2019-04-09 22:46:19,529 root         INFO     Train Epoch: 38 [6656/8000 (83%)]\tTotal Loss: 0.452135\n",
      "Reconstruction: 0.372097, Regularization: 0.014552, Discriminator: 0.042720; Generator: 0.022765,\n",
      "D(x): 0.494, D(G(z)): 0.483\n",
      "2019-04-09 22:46:19,628 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.548287\n",
      "Reconstruction: 0.463087, Regularization: 0.019725, Discriminator: 0.042701; Generator: 0.022773,\n",
      "D(x): 0.495, D(G(z)): 0.483\n",
      "2019-04-09 22:46:19,727 root         INFO     Train Epoch: 38 [7680/8000 (96%)]\tTotal Loss: 0.397294\n",
      "Reconstruction: 0.317168, Regularization: 0.014446, Discriminator: 0.042810; Generator: 0.022869,\n",
      "D(x): 0.491, D(G(z)): 0.481\n",
      "2019-04-09 22:46:19,801 root         INFO     ====> Epoch: 38 Average loss: 0.7028\n",
      "2019-04-09 22:46:19,827 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 1.015057\n",
      "Reconstruction: 0.903008, Regularization: 0.045180, Discriminator: 0.044148; Generator: 0.022721,\n",
      "D(x): 0.474, D(G(z)): 0.483\n",
      "2019-04-09 22:46:19,926 root         INFO     Train Epoch: 39 [512/8000 (6%)]\tTotal Loss: 0.700771\n",
      "Reconstruction: 0.603324, Regularization: 0.032091, Discriminator: 0.042814; Generator: 0.022543,\n",
      "D(x): 0.497, D(G(z)): 0.486\n",
      "2019-04-09 22:46:20,024 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.422949\n",
      "Reconstruction: 0.341555, Regularization: 0.015713, Discriminator: 0.042915; Generator: 0.022766,\n",
      "D(x): 0.492, D(G(z)): 0.483\n",
      "2019-04-09 22:46:20,123 root         INFO     Train Epoch: 39 [1536/8000 (19%)]\tTotal Loss: 0.600444\n",
      "Reconstruction: 0.509748, Regularization: 0.024707, Discriminator: 0.043110; Generator: 0.022879,\n",
      "D(x): 0.487, D(G(z)): 0.481\n",
      "2019-04-09 22:46:20,221 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.986273\n",
      "Reconstruction: 0.876452, Regularization: 0.042760, Discriminator: 0.044295; Generator: 0.022767,\n",
      "D(x): 0.471, D(G(z)): 0.483\n",
      "2019-04-09 22:46:20,319 root         INFO     Train Epoch: 39 [2560/8000 (32%)]\tTotal Loss: 0.791219\n",
      "Reconstruction: 0.691951, Regularization: 0.034492, Discriminator: 0.042140; Generator: 0.022636,\n",
      "D(x): 0.506, D(G(z)): 0.485\n",
      "2019-04-09 22:46:20,417 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.683959\n",
      "Reconstruction: 0.598893, Regularization: 0.019520, Discriminator: 0.042905; Generator: 0.022641,\n",
      "D(x): 0.493, D(G(z)): 0.485\n",
      "2019-04-09 22:46:20,515 root         INFO     Train Epoch: 39 [3584/8000 (45%)]\tTotal Loss: 0.683414\n",
      "Reconstruction: 0.587479, Regularization: 0.029066, Discriminator: 0.044260; Generator: 0.022609,\n",
      "D(x): 0.473, D(G(z)): 0.485\n",
      "2019-04-09 22:46:20,614 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.725166\n",
      "Reconstruction: 0.632388, Regularization: 0.026745, Discriminator: 0.043359; Generator: 0.022674,\n",
      "D(x): 0.486, D(G(z)): 0.484\n",
      "2019-04-09 22:46:20,712 root         INFO     Train Epoch: 39 [4608/8000 (58%)]\tTotal Loss: 0.980545\n",
      "Reconstruction: 0.875513, Regularization: 0.040144, Discriminator: 0.042273; Generator: 0.022616,\n",
      "D(x): 0.504, D(G(z)): 0.485\n",
      "2019-04-09 22:46:20,810 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.743158\n",
      "Reconstruction: 0.650397, Regularization: 0.027615, Discriminator: 0.042613; Generator: 0.022534,\n",
      "D(x): 0.501, D(G(z)): 0.486\n",
      "2019-04-09 22:46:20,907 root         INFO     Train Epoch: 39 [5632/8000 (70%)]\tTotal Loss: 0.728031\n",
      "Reconstruction: 0.630704, Regularization: 0.031345, Discriminator: 0.043368; Generator: 0.022613,\n",
      "D(x): 0.488, D(G(z)): 0.485\n",
      "2019-04-09 22:46:21,004 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.911262\n",
      "Reconstruction: 0.812302, Regularization: 0.033804, Discriminator: 0.042624; Generator: 0.022532,\n",
      "D(x): 0.500, D(G(z)): 0.486\n",
      "2019-04-09 22:46:21,103 root         INFO     Train Epoch: 39 [6656/8000 (83%)]\tTotal Loss: 0.401728\n",
      "Reconstruction: 0.323732, Regularization: 0.013251, Discriminator: 0.042117; Generator: 0.022629,\n",
      "D(x): 0.506, D(G(z)): 0.485\n",
      "2019-04-09 22:46:21,202 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.988213\n",
      "Reconstruction: 0.881780, Regularization: 0.040165, Discriminator: 0.043732; Generator: 0.022536,\n",
      "D(x): 0.483, D(G(z)): 0.486\n",
      "2019-04-09 22:46:21,300 root         INFO     Train Epoch: 39 [7680/8000 (96%)]\tTotal Loss: 0.720250\n",
      "Reconstruction: 0.625331, Regularization: 0.029551, Discriminator: 0.042846; Generator: 0.022522,\n",
      "D(x): 0.497, D(G(z)): 0.486\n",
      "2019-04-09 22:46:21,374 root         INFO     ====> Epoch: 39 Average loss: 0.7056\n",
      "2019-04-09 22:46:21,400 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.539474\n",
      "Reconstruction: 0.455787, Regularization: 0.018418, Discriminator: 0.042774; Generator: 0.022495,\n",
      "D(x): 0.498, D(G(z)): 0.487\n",
      "2019-04-09 22:46:21,498 root         INFO     Train Epoch: 40 [512/8000 (6%)]\tTotal Loss: 0.633162\n",
      "Reconstruction: 0.544029, Regularization: 0.023307, Discriminator: 0.043372; Generator: 0.022454,\n",
      "D(x): 0.490, D(G(z)): 0.488\n",
      "2019-04-09 22:46:21,594 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.681257\n",
      "Reconstruction: 0.588979, Regularization: 0.028178, Discriminator: 0.041607; Generator: 0.022492,\n",
      "D(x): 0.517, D(G(z)): 0.487\n",
      "2019-04-09 22:46:21,691 root         INFO     Train Epoch: 40 [1536/8000 (19%)]\tTotal Loss: 0.586607\n",
      "Reconstruction: 0.497270, Regularization: 0.025102, Discriminator: 0.041686; Generator: 0.022548,\n",
      "D(x): 0.516, D(G(z)): 0.486\n",
      "2019-04-09 22:46:21,788 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.871218\n",
      "Reconstruction: 0.775934, Regularization: 0.030445, Discriminator: 0.042358; Generator: 0.022481,\n",
      "D(x): 0.505, D(G(z)): 0.487\n",
      "2019-04-09 22:46:21,884 root         INFO     Train Epoch: 40 [2560/8000 (32%)]\tTotal Loss: 0.512576\n",
      "Reconstruction: 0.428860, Regularization: 0.018706, Discriminator: 0.042546; Generator: 0.022464,\n",
      "D(x): 0.502, D(G(z)): 0.487\n",
      "2019-04-09 22:46:21,980 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.618171\n",
      "Reconstruction: 0.531246, Regularization: 0.020111, Discriminator: 0.044545; Generator: 0.022269,\n",
      "D(x): 0.474, D(G(z)): 0.490\n",
      "2019-04-09 22:46:22,075 root         INFO     Train Epoch: 40 [3584/8000 (45%)]\tTotal Loss: 1.024415\n",
      "Reconstruction: 0.928173, Regularization: 0.031006, Discriminator: 0.043041; Generator: 0.022195,\n",
      "D(x): 0.500, D(G(z)): 0.492\n",
      "2019-04-09 22:46:22,171 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.690622\n",
      "Reconstruction: 0.593516, Regularization: 0.032124, Discriminator: 0.042564; Generator: 0.022419,\n",
      "D(x): 0.505, D(G(z)): 0.488\n",
      "2019-04-09 22:46:22,266 root         INFO     Train Epoch: 40 [4608/8000 (58%)]\tTotal Loss: 0.661915\n",
      "Reconstruction: 0.568986, Regularization: 0.027508, Discriminator: 0.043211; Generator: 0.022210,\n",
      "D(x): 0.496, D(G(z)): 0.491\n",
      "2019-04-09 22:46:22,362 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 0.838566\n",
      "Reconstruction: 0.740247, Regularization: 0.033651, Discriminator: 0.042399; Generator: 0.022269,\n",
      "D(x): 0.509, D(G(z)): 0.490\n",
      "2019-04-09 22:46:22,458 root         INFO     Train Epoch: 40 [5632/8000 (70%)]\tTotal Loss: 0.772013\n",
      "Reconstruction: 0.679507, Regularization: 0.028085, Discriminator: 0.042183; Generator: 0.022238,\n",
      "D(x): 0.512, D(G(z)): 0.491\n",
      "2019-04-09 22:46:22,554 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.571192\n",
      "Reconstruction: 0.486988, Regularization: 0.018455, Discriminator: 0.043508; Generator: 0.022241,\n",
      "D(x): 0.490, D(G(z)): 0.491\n",
      "2019-04-09 22:46:22,649 root         INFO     Train Epoch: 40 [6656/8000 (83%)]\tTotal Loss: 0.647775\n",
      "Reconstruction: 0.559087, Regularization: 0.022658, Discriminator: 0.043774; Generator: 0.022256,\n",
      "D(x): 0.486, D(G(z)): 0.491\n",
      "2019-04-09 22:46:22,746 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.557460\n",
      "Reconstruction: 0.475063, Regularization: 0.018092, Discriminator: 0.042011; Generator: 0.022294,\n",
      "D(x): 0.513, D(G(z)): 0.490\n",
      "2019-04-09 22:46:22,842 root         INFO     Train Epoch: 40 [7680/8000 (96%)]\tTotal Loss: 0.697414\n",
      "Reconstruction: 0.606282, Regularization: 0.025338, Discriminator: 0.043473; Generator: 0.022322,\n",
      "D(x): 0.490, D(G(z)): 0.490\n",
      "2019-04-09 22:46:22,915 root         INFO     ====> Epoch: 40 Average loss: 0.7104\n",
      "2019-04-09 22:46:22,941 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 0.463561\n",
      "Reconstruction: 0.387192, Regularization: 0.011528, Discriminator: 0.042724; Generator: 0.022118,\n",
      "D(x): 0.505, D(G(z)): 0.493\n",
      "2019-04-09 22:46:23,035 root         INFO     Train Epoch: 41 [512/8000 (6%)]\tTotal Loss: 0.690148\n",
      "Reconstruction: 0.604615, Regularization: 0.020927, Discriminator: 0.042559; Generator: 0.022047,\n",
      "D(x): 0.510, D(G(z)): 0.494\n",
      "2019-04-09 22:46:23,130 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.641882\n",
      "Reconstruction: 0.548714, Regularization: 0.028099, Discriminator: 0.042966; Generator: 0.022103,\n",
      "D(x): 0.503, D(G(z)): 0.493\n",
      "2019-04-09 22:46:23,224 root         INFO     Train Epoch: 41 [1536/8000 (19%)]\tTotal Loss: 0.549431\n",
      "Reconstruction: 0.468830, Regularization: 0.015539, Discriminator: 0.042921; Generator: 0.022140,\n",
      "D(x): 0.501, D(G(z)): 0.492\n",
      "2019-04-09 22:46:23,319 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 0.774037\n",
      "Reconstruction: 0.683101, Regularization: 0.024610, Discriminator: 0.044298; Generator: 0.022029,\n",
      "D(x): 0.482, D(G(z)): 0.494\n",
      "2019-04-09 22:46:23,414 root         INFO     Train Epoch: 41 [2560/8000 (32%)]\tTotal Loss: 0.610230\n",
      "Reconstruction: 0.526901, Regularization: 0.018068, Discriminator: 0.043179; Generator: 0.022082,\n",
      "D(x): 0.498, D(G(z)): 0.493\n",
      "2019-04-09 22:46:23,507 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.654463\n",
      "Reconstruction: 0.563676, Regularization: 0.025680, Discriminator: 0.043245; Generator: 0.021863,\n",
      "D(x): 0.501, D(G(z)): 0.497\n",
      "2019-04-09 22:46:23,601 root         INFO     Train Epoch: 41 [3584/8000 (45%)]\tTotal Loss: 0.591060\n",
      "Reconstruction: 0.505811, Regularization: 0.020164, Discriminator: 0.043350; Generator: 0.021735,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 22:46:23,694 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.686215\n",
      "Reconstruction: 0.596037, Regularization: 0.026495, Discriminator: 0.041745; Generator: 0.021938,\n",
      "D(x): 0.524, D(G(z)): 0.496\n",
      "2019-04-09 22:46:23,788 root         INFO     Train Epoch: 41 [4608/8000 (58%)]\tTotal Loss: 0.961031\n",
      "Reconstruction: 0.860984, Regularization: 0.033776, Discriminator: 0.044311; Generator: 0.021959,\n",
      "D(x): 0.481, D(G(z)): 0.495\n",
      "2019-04-09 22:46:23,884 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 1.134468\n",
      "Reconstruction: 1.028517, Regularization: 0.041339, Discriminator: 0.042697; Generator: 0.021915,\n",
      "D(x): 0.510, D(G(z)): 0.496\n",
      "2019-04-09 22:46:23,986 root         INFO     Train Epoch: 41 [5632/8000 (70%)]\tTotal Loss: 0.799713\n",
      "Reconstruction: 0.704694, Regularization: 0.030130, Discriminator: 0.042923; Generator: 0.021967,\n",
      "D(x): 0.505, D(G(z)): 0.495\n",
      "2019-04-09 22:46:24,087 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.628895\n",
      "Reconstruction: 0.539715, Regularization: 0.024781, Discriminator: 0.042714; Generator: 0.021684,\n",
      "D(x): 0.512, D(G(z)): 0.500\n",
      "2019-04-09 22:46:24,187 root         INFO     Train Epoch: 41 [6656/8000 (83%)]\tTotal Loss: 0.751299\n",
      "Reconstruction: 0.656781, Regularization: 0.029179, Discriminator: 0.043598; Generator: 0.021742,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 22:46:24,286 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.468249\n",
      "Reconstruction: 0.388088, Regularization: 0.015684, Discriminator: 0.042815; Generator: 0.021661,\n",
      "D(x): 0.510, D(G(z)): 0.500\n",
      "2019-04-09 22:46:24,385 root         INFO     Train Epoch: 41 [7680/8000 (96%)]\tTotal Loss: 0.573198\n",
      "Reconstruction: 0.488147, Regularization: 0.020992, Discriminator: 0.042322; Generator: 0.021736,\n",
      "D(x): 0.518, D(G(z)): 0.499\n",
      "2019-04-09 22:46:24,459 root         INFO     ====> Epoch: 41 Average loss: 0.7162\n",
      "2019-04-09 22:46:24,486 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.747923\n",
      "Reconstruction: 0.658136, Regularization: 0.023895, Discriminator: 0.044309; Generator: 0.021584,\n",
      "D(x): 0.488, D(G(z)): 0.501\n",
      "2019-04-09 22:46:24,588 root         INFO     Train Epoch: 42 [512/8000 (6%)]\tTotal Loss: 0.716984\n",
      "Reconstruction: 0.625798, Regularization: 0.026291, Discriminator: 0.043248; Generator: 0.021648,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 22:46:24,683 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.479181\n",
      "Reconstruction: 0.399663, Regularization: 0.014788, Discriminator: 0.042915; Generator: 0.021815,\n",
      "D(x): 0.506, D(G(z)): 0.498\n",
      "2019-04-09 22:46:24,778 root         INFO     Train Epoch: 42 [1536/8000 (19%)]\tTotal Loss: 0.757315\n",
      "Reconstruction: 0.667919, Regularization: 0.025122, Discriminator: 0.042712; Generator: 0.021562,\n",
      "D(x): 0.514, D(G(z)): 0.502\n",
      "2019-04-09 22:46:24,873 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.620442\n",
      "Reconstruction: 0.532200, Regularization: 0.023215, Discriminator: 0.043219; Generator: 0.021808,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 22:46:24,968 root         INFO     Train Epoch: 42 [2560/8000 (32%)]\tTotal Loss: 0.700144\n",
      "Reconstruction: 0.606222, Regularization: 0.028644, Discriminator: 0.043580; Generator: 0.021698,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:25,063 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 0.492393\n",
      "Reconstruction: 0.411158, Regularization: 0.016233, Discriminator: 0.043381; Generator: 0.021621,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 22:46:25,157 root         INFO     Train Epoch: 42 [3584/8000 (45%)]\tTotal Loss: 0.717606\n",
      "Reconstruction: 0.626109, Regularization: 0.026227, Discriminator: 0.043594; Generator: 0.021677,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 22:46:25,252 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.805009\n",
      "Reconstruction: 0.711002, Regularization: 0.030088, Discriminator: 0.042382; Generator: 0.021536,\n",
      "D(x): 0.521, D(G(z)): 0.502\n",
      "2019-04-09 22:46:25,347 root         INFO     Train Epoch: 42 [4608/8000 (58%)]\tTotal Loss: 0.623452\n",
      "Reconstruction: 0.537174, Regularization: 0.021099, Discriminator: 0.043676; Generator: 0.021503,\n",
      "D(x): 0.499, D(G(z)): 0.503\n",
      "2019-04-09 22:46:25,443 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.638666\n",
      "Reconstruction: 0.556490, Regularization: 0.017046, Discriminator: 0.043701; Generator: 0.021430,\n",
      "D(x): 0.499, D(G(z)): 0.504\n",
      "2019-04-09 22:46:25,538 root         INFO     Train Epoch: 42 [5632/8000 (70%)]\tTotal Loss: 0.827416\n",
      "Reconstruction: 0.728551, Regularization: 0.033480, Discriminator: 0.044097; Generator: 0.021288,\n",
      "D(x): 0.496, D(G(z)): 0.506\n",
      "2019-04-09 22:46:25,632 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.514302\n",
      "Reconstruction: 0.430404, Regularization: 0.019173, Discriminator: 0.043296; Generator: 0.021429,\n",
      "D(x): 0.506, D(G(z)): 0.504\n",
      "2019-04-09 22:46:25,727 root         INFO     Train Epoch: 42 [6656/8000 (83%)]\tTotal Loss: 0.635118\n",
      "Reconstruction: 0.550409, Regularization: 0.019211, Discriminator: 0.044214; Generator: 0.021284,\n",
      "D(x): 0.493, D(G(z)): 0.506\n",
      "2019-04-09 22:46:25,823 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.579195\n",
      "Reconstruction: 0.492057, Regularization: 0.022095, Discriminator: 0.043458; Generator: 0.021586,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-09 22:46:25,920 root         INFO     Train Epoch: 42 [7680/8000 (96%)]\tTotal Loss: 0.751486\n",
      "Reconstruction: 0.666100, Regularization: 0.020289, Discriminator: 0.043683; Generator: 0.021414,\n",
      "D(x): 0.500, D(G(z)): 0.504\n",
      "2019-04-09 22:46:25,994 root         INFO     ====> Epoch: 42 Average loss: 0.7215\n",
      "2019-04-09 22:46:26,020 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.675616\n",
      "Reconstruction: 0.583889, Regularization: 0.026170, Discriminator: 0.044070; Generator: 0.021487,\n",
      "D(x): 0.493, D(G(z)): 0.503\n",
      "2019-04-09 22:46:26,121 root         INFO     Train Epoch: 43 [512/8000 (6%)]\tTotal Loss: 0.627894\n",
      "Reconstruction: 0.541112, Regularization: 0.021215, Discriminator: 0.044088; Generator: 0.021479,\n",
      "D(x): 0.493, D(G(z)): 0.503\n",
      "2019-04-09 22:46:26,220 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.779112\n",
      "Reconstruction: 0.685248, Regularization: 0.028924, Discriminator: 0.043603; Generator: 0.021337,\n",
      "D(x): 0.503, D(G(z)): 0.505\n",
      "2019-04-09 22:46:26,320 root         INFO     Train Epoch: 43 [1536/8000 (19%)]\tTotal Loss: 0.623660\n",
      "Reconstruction: 0.540157, Regularization: 0.017678, Discriminator: 0.044338; Generator: 0.021487,\n",
      "D(x): 0.488, D(G(z)): 0.503\n",
      "2019-04-09 22:46:26,419 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.987882\n",
      "Reconstruction: 0.887652, Regularization: 0.034586, Discriminator: 0.044278; Generator: 0.021366,\n",
      "D(x): 0.491, D(G(z)): 0.505\n",
      "2019-04-09 22:46:26,519 root         INFO     Train Epoch: 43 [2560/8000 (32%)]\tTotal Loss: 0.673014\n",
      "Reconstruction: 0.581844, Regularization: 0.026123, Discriminator: 0.043570; Generator: 0.021477,\n",
      "D(x): 0.501, D(G(z)): 0.503\n",
      "2019-04-09 22:46:26,619 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.743660\n",
      "Reconstruction: 0.650343, Regularization: 0.028550, Discriminator: 0.043305; Generator: 0.021462,\n",
      "D(x): 0.505, D(G(z)): 0.503\n",
      "2019-04-09 22:46:26,718 root         INFO     Train Epoch: 43 [3584/8000 (45%)]\tTotal Loss: 0.574541\n",
      "Reconstruction: 0.498650, Regularization: 0.010942, Discriminator: 0.043586; Generator: 0.021362,\n",
      "D(x): 0.502, D(G(z)): 0.505\n",
      "2019-04-09 22:46:26,818 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.682250\n",
      "Reconstruction: 0.593569, Regularization: 0.023402, Discriminator: 0.043884; Generator: 0.021394,\n",
      "D(x): 0.497, D(G(z)): 0.504\n",
      "2019-04-09 22:46:26,918 root         INFO     Train Epoch: 43 [4608/8000 (58%)]\tTotal Loss: 0.742889\n",
      "Reconstruction: 0.661300, Regularization: 0.017158, Discriminator: 0.042888; Generator: 0.021542,\n",
      "D(x): 0.510, D(G(z)): 0.502\n",
      "2019-04-09 22:46:27,018 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.733753\n",
      "Reconstruction: 0.642067, Regularization: 0.026367, Discriminator: 0.043841; Generator: 0.021477,\n",
      "D(x): 0.496, D(G(z)): 0.503\n",
      "2019-04-09 22:46:27,117 root         INFO     Train Epoch: 43 [5632/8000 (70%)]\tTotal Loss: 0.637415\n",
      "Reconstruction: 0.546665, Regularization: 0.025625, Discriminator: 0.043752; Generator: 0.021373,\n",
      "D(x): 0.499, D(G(z)): 0.505\n",
      "2019-04-09 22:46:27,218 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.595366\n",
      "Reconstruction: 0.509695, Regularization: 0.019668, Discriminator: 0.044537; Generator: 0.021466,\n",
      "D(x): 0.485, D(G(z)): 0.503\n",
      "2019-04-09 22:46:27,317 root         INFO     Train Epoch: 43 [6656/8000 (83%)]\tTotal Loss: 0.673077\n",
      "Reconstruction: 0.580261, Regularization: 0.028445, Discriminator: 0.042989; Generator: 0.021383,\n",
      "D(x): 0.511, D(G(z)): 0.504\n",
      "2019-04-09 22:46:27,416 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.573329\n",
      "Reconstruction: 0.490760, Regularization: 0.017552, Discriminator: 0.043654; Generator: 0.021363,\n",
      "D(x): 0.500, D(G(z)): 0.505\n",
      "2019-04-09 22:46:27,514 root         INFO     Train Epoch: 43 [7680/8000 (96%)]\tTotal Loss: 0.709044\n",
      "Reconstruction: 0.619220, Regularization: 0.024672, Discriminator: 0.043720; Generator: 0.021431,\n",
      "D(x): 0.499, D(G(z)): 0.504\n",
      "2019-04-09 22:46:27,588 root         INFO     ====> Epoch: 43 Average loss: 0.7276\n",
      "2019-04-09 22:46:27,614 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.622691\n",
      "Reconstruction: 0.534561, Regularization: 0.023332, Discriminator: 0.043441; Generator: 0.021357,\n",
      "D(x): 0.504, D(G(z)): 0.505\n",
      "2019-04-09 22:46:27,712 root         INFO     Train Epoch: 44 [512/8000 (6%)]\tTotal Loss: 0.938228\n",
      "Reconstruction: 0.842369, Regularization: 0.030930, Discriminator: 0.043471; Generator: 0.021458,\n",
      "D(x): 0.502, D(G(z)): 0.503\n",
      "2019-04-09 22:46:27,808 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.559716\n",
      "Reconstruction: 0.474936, Regularization: 0.019879, Discriminator: 0.043526; Generator: 0.021375,\n",
      "D(x): 0.502, D(G(z)): 0.505\n",
      "2019-04-09 22:46:27,906 root         INFO     Train Epoch: 44 [1536/8000 (19%)]\tTotal Loss: 0.700414\n",
      "Reconstruction: 0.607473, Regularization: 0.028039, Discriminator: 0.043454; Generator: 0.021449,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-09 22:46:28,004 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.555466\n",
      "Reconstruction: 0.471594, Regularization: 0.019104, Discriminator: 0.043304; Generator: 0.021464,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-09 22:46:28,102 root         INFO     Train Epoch: 44 [2560/8000 (32%)]\tTotal Loss: 0.895150\n",
      "Reconstruction: 0.801403, Regularization: 0.028930, Discriminator: 0.043381; Generator: 0.021437,\n",
      "D(x): 0.503, D(G(z)): 0.504\n",
      "2019-04-09 22:46:28,198 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.740514\n",
      "Reconstruction: 0.652214, Regularization: 0.023064, Discriminator: 0.043889; Generator: 0.021347,\n",
      "D(x): 0.497, D(G(z)): 0.505\n",
      "2019-04-09 22:46:28,296 root         INFO     Train Epoch: 44 [3584/8000 (45%)]\tTotal Loss: 0.968183\n",
      "Reconstruction: 0.869355, Regularization: 0.033058, Discriminator: 0.044311; Generator: 0.021460,\n",
      "D(x): 0.488, D(G(z)): 0.503\n",
      "2019-04-09 22:46:28,394 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.499974\n",
      "Reconstruction: 0.418901, Regularization: 0.016422, Discriminator: 0.043181; Generator: 0.021469,\n",
      "D(x): 0.506, D(G(z)): 0.503\n",
      "2019-04-09 22:46:28,491 root         INFO     Train Epoch: 44 [4608/8000 (58%)]\tTotal Loss: 0.932712\n",
      "Reconstruction: 0.840072, Regularization: 0.027681, Discriminator: 0.043519; Generator: 0.021441,\n",
      "D(x): 0.501, D(G(z)): 0.504\n",
      "2019-04-09 22:46:28,589 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.715260\n",
      "Reconstruction: 0.623764, Regularization: 0.026439, Discriminator: 0.043639; Generator: 0.021418,\n",
      "D(x): 0.500, D(G(z)): 0.504\n",
      "2019-04-09 22:46:28,688 root         INFO     Train Epoch: 44 [5632/8000 (70%)]\tTotal Loss: 0.616790\n",
      "Reconstruction: 0.534205, Regularization: 0.017303, Discriminator: 0.043780; Generator: 0.021502,\n",
      "D(x): 0.496, D(G(z)): 0.503\n",
      "2019-04-09 22:46:28,785 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.881180\n",
      "Reconstruction: 0.785711, Regularization: 0.030684, Discriminator: 0.043301; Generator: 0.021485,\n",
      "D(x): 0.504, D(G(z)): 0.503\n",
      "2019-04-09 22:46:28,884 root         INFO     Train Epoch: 44 [6656/8000 (83%)]\tTotal Loss: 0.576764\n",
      "Reconstruction: 0.495178, Regularization: 0.016422, Discriminator: 0.043677; Generator: 0.021488,\n",
      "D(x): 0.498, D(G(z)): 0.503\n",
      "2019-04-09 22:46:28,981 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.777072\n",
      "Reconstruction: 0.685216, Regularization: 0.026379, Discriminator: 0.044014; Generator: 0.021463,\n",
      "D(x): 0.493, D(G(z)): 0.503\n",
      "2019-04-09 22:46:29,077 root         INFO     Train Epoch: 44 [7680/8000 (96%)]\tTotal Loss: 0.750193\n",
      "Reconstruction: 0.662186, Regularization: 0.022788, Discriminator: 0.043719; Generator: 0.021500,\n",
      "D(x): 0.497, D(G(z)): 0.503\n",
      "2019-04-09 22:46:29,150 root         INFO     ====> Epoch: 44 Average loss: 0.7315\n",
      "2019-04-09 22:46:29,176 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.668754\n",
      "Reconstruction: 0.579917, Regularization: 0.023790, Discriminator: 0.043479; Generator: 0.021568,\n",
      "D(x): 0.500, D(G(z)): 0.502\n",
      "2019-04-09 22:46:29,277 root         INFO     Train Epoch: 45 [512/8000 (6%)]\tTotal Loss: 0.462776\n",
      "Reconstruction: 0.383576, Regularization: 0.013951, Discriminator: 0.043753; Generator: 0.021496,\n",
      "D(x): 0.496, D(G(z)): 0.503\n",
      "2019-04-09 22:46:29,376 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 0.570742\n",
      "Reconstruction: 0.492212, Regularization: 0.013228, Discriminator: 0.043752; Generator: 0.021551,\n",
      "D(x): 0.495, D(G(z)): 0.502\n",
      "2019-04-09 22:46:29,473 root         INFO     Train Epoch: 45 [1536/8000 (19%)]\tTotal Loss: 0.536975\n",
      "Reconstruction: 0.456444, Regularization: 0.015760, Discriminator: 0.043201; Generator: 0.021571,\n",
      "D(x): 0.504, D(G(z)): 0.501\n",
      "2019-04-09 22:46:29,570 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.553238\n",
      "Reconstruction: 0.468057, Regularization: 0.020225, Discriminator: 0.043439; Generator: 0.021517,\n",
      "D(x): 0.501, D(G(z)): 0.502\n",
      "2019-04-09 22:46:29,666 root         INFO     Train Epoch: 45 [2560/8000 (32%)]\tTotal Loss: 1.085161\n",
      "Reconstruction: 0.991163, Regularization: 0.028825, Discriminator: 0.043596; Generator: 0.021576,\n",
      "D(x): 0.498, D(G(z)): 0.501\n",
      "2019-04-09 22:46:29,763 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.585381\n",
      "Reconstruction: 0.502438, Regularization: 0.017863, Discriminator: 0.043547; Generator: 0.021532,\n",
      "D(x): 0.499, D(G(z)): 0.502\n",
      "2019-04-09 22:46:29,860 root         INFO     Train Epoch: 45 [3584/8000 (45%)]\tTotal Loss: 0.603773\n",
      "Reconstruction: 0.516191, Regularization: 0.022900, Discriminator: 0.043059; Generator: 0.021622,\n",
      "D(x): 0.505, D(G(z)): 0.501\n",
      "2019-04-09 22:46:29,956 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 1.232856\n",
      "Reconstruction: 1.117678, Regularization: 0.050546, Discriminator: 0.043059; Generator: 0.021572,\n",
      "D(x): 0.507, D(G(z)): 0.501\n",
      "2019-04-09 22:46:30,052 root         INFO     Train Epoch: 45 [4608/8000 (58%)]\tTotal Loss: 0.702248\n",
      "Reconstruction: 0.606868, Regularization: 0.030551, Discriminator: 0.043234; Generator: 0.021594,\n",
      "D(x): 0.503, D(G(z)): 0.501\n",
      "2019-04-09 22:46:30,148 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 1.003258\n",
      "Reconstruction: 0.906455, Regularization: 0.031714, Discriminator: 0.043479; Generator: 0.021610,\n",
      "D(x): 0.499, D(G(z)): 0.501\n",
      "2019-04-09 22:46:30,245 root         INFO     Train Epoch: 45 [5632/8000 (70%)]\tTotal Loss: 0.820368\n",
      "Reconstruction: 0.728226, Regularization: 0.026600, Discriminator: 0.043951; Generator: 0.021592,\n",
      "D(x): 0.492, D(G(z)): 0.501\n",
      "2019-04-09 22:46:30,341 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.676361\n",
      "Reconstruction: 0.590700, Regularization: 0.020671, Discriminator: 0.043381; Generator: 0.021608,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 22:46:30,438 root         INFO     Train Epoch: 45 [6656/8000 (83%)]\tTotal Loss: 0.548111\n",
      "Reconstruction: 0.467801, Regularization: 0.015313, Discriminator: 0.043407; Generator: 0.021590,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 22:46:30,534 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.742876\n",
      "Reconstruction: 0.651382, Regularization: 0.026928, Discriminator: 0.042936; Generator: 0.021630,\n",
      "D(x): 0.507, D(G(z)): 0.501\n",
      "2019-04-09 22:46:30,630 root         INFO     Train Epoch: 45 [7680/8000 (96%)]\tTotal Loss: 0.646053\n",
      "Reconstruction: 0.562889, Regularization: 0.017945, Discriminator: 0.043601; Generator: 0.021618,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 22:46:30,703 root         INFO     ====> Epoch: 45 Average loss: 0.7347\n",
      "2019-04-09 22:46:30,729 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.612647\n",
      "Reconstruction: 0.527675, Regularization: 0.019709, Discriminator: 0.043561; Generator: 0.021702,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 22:46:30,830 root         INFO     Train Epoch: 46 [512/8000 (6%)]\tTotal Loss: 0.633057\n",
      "Reconstruction: 0.546848, Regularization: 0.021352, Discriminator: 0.043184; Generator: 0.021672,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:46:30,931 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.576747\n",
      "Reconstruction: 0.492819, Regularization: 0.018681, Discriminator: 0.043586; Generator: 0.021661,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 22:46:31,031 root         INFO     Train Epoch: 46 [1536/8000 (19%)]\tTotal Loss: 1.098307\n",
      "Reconstruction: 0.997087, Regularization: 0.036253, Discriminator: 0.043298; Generator: 0.021669,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:46:31,132 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.942746\n",
      "Reconstruction: 0.845905, Regularization: 0.031208, Discriminator: 0.043953; Generator: 0.021679,\n",
      "D(x): 0.490, D(G(z)): 0.500\n",
      "2019-04-09 22:46:31,232 root         INFO     Train Epoch: 46 [2560/8000 (32%)]\tTotal Loss: 0.956427\n",
      "Reconstruction: 0.862402, Regularization: 0.028752, Discriminator: 0.043568; Generator: 0.021704,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 22:46:31,333 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.743455\n",
      "Reconstruction: 0.652439, Regularization: 0.026362, Discriminator: 0.042981; Generator: 0.021673,\n",
      "D(x): 0.506, D(G(z)): 0.500\n",
      "2019-04-09 22:46:31,433 root         INFO     Train Epoch: 46 [3584/8000 (45%)]\tTotal Loss: 0.845932\n",
      "Reconstruction: 0.750047, Regularization: 0.030978, Discriminator: 0.043213; Generator: 0.021693,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 22:46:31,534 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.762534\n",
      "Reconstruction: 0.673224, Regularization: 0.023778, Discriminator: 0.043827; Generator: 0.021705,\n",
      "D(x): 0.492, D(G(z)): 0.499\n",
      "2019-04-09 22:46:31,634 root         INFO     Train Epoch: 46 [4608/8000 (58%)]\tTotal Loss: 0.650439\n",
      "Reconstruction: 0.564336, Regularization: 0.021080, Discriminator: 0.043315; Generator: 0.021708,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:31,735 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.925961\n",
      "Reconstruction: 0.830648, Regularization: 0.029842, Discriminator: 0.043755; Generator: 0.021717,\n",
      "D(x): 0.493, D(G(z)): 0.499\n",
      "2019-04-09 22:46:31,833 root         INFO     Train Epoch: 46 [5632/8000 (70%)]\tTotal Loss: 0.538930\n",
      "Reconstruction: 0.455927, Regularization: 0.017585, Discriminator: 0.043709; Generator: 0.021709,\n",
      "D(x): 0.493, D(G(z)): 0.499\n",
      "2019-04-09 22:46:31,932 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.745758\n",
      "Reconstruction: 0.657175, Regularization: 0.023804, Discriminator: 0.043041; Generator: 0.021739,\n",
      "D(x): 0.504, D(G(z)): 0.499\n",
      "2019-04-09 22:46:32,031 root         INFO     Train Epoch: 46 [6656/8000 (83%)]\tTotal Loss: 0.803206\n",
      "Reconstruction: 0.712092, Regularization: 0.026286, Discriminator: 0.043080; Generator: 0.021748,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 22:46:32,130 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.690464\n",
      "Reconstruction: 0.600237, Regularization: 0.025469, Discriminator: 0.043019; Generator: 0.021739,\n",
      "D(x): 0.504, D(G(z)): 0.499\n",
      "2019-04-09 22:46:32,229 root         INFO     Train Epoch: 46 [7680/8000 (96%)]\tTotal Loss: 0.868096\n",
      "Reconstruction: 0.773480, Regularization: 0.029216, Discriminator: 0.043655; Generator: 0.021744,\n",
      "D(x): 0.494, D(G(z)): 0.499\n",
      "2019-04-09 22:46:32,302 root         INFO     ====> Epoch: 46 Average loss: 0.7365\n",
      "2019-04-09 22:46:32,329 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.746207\n",
      "Reconstruction: 0.651322, Regularization: 0.029939, Discriminator: 0.043193; Generator: 0.021753,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 22:46:32,429 root         INFO     Train Epoch: 47 [512/8000 (6%)]\tTotal Loss: 0.777523\n",
      "Reconstruction: 0.688188, Regularization: 0.024087, Discriminator: 0.043488; Generator: 0.021760,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 22:46:32,530 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.990354\n",
      "Reconstruction: 0.893904, Regularization: 0.031176, Discriminator: 0.043517; Generator: 0.021758,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 22:46:32,630 root         INFO     Train Epoch: 47 [1536/8000 (19%)]\tTotal Loss: 0.808929\n",
      "Reconstruction: 0.721011, Regularization: 0.022287, Discriminator: 0.043864; Generator: 0.021768,\n",
      "D(x): 0.490, D(G(z)): 0.498\n",
      "2019-04-09 22:46:32,728 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.911559\n",
      "Reconstruction: 0.817711, Regularization: 0.028846, Discriminator: 0.043221; Generator: 0.021781,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 22:46:32,826 root         INFO     Train Epoch: 47 [2560/8000 (32%)]\tTotal Loss: 1.050223\n",
      "Reconstruction: 0.944608, Regularization: 0.040667, Discriminator: 0.043158; Generator: 0.021790,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 22:46:32,922 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.584123\n",
      "Reconstruction: 0.500167, Regularization: 0.019195, Discriminator: 0.042968; Generator: 0.021793,\n",
      "D(x): 0.504, D(G(z)): 0.498\n",
      "2019-04-09 22:46:33,018 root         INFO     Train Epoch: 47 [3584/8000 (45%)]\tTotal Loss: 0.602432\n",
      "Reconstruction: 0.520274, Regularization: 0.017019, Discriminator: 0.043349; Generator: 0.021790,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 22:46:33,115 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.642442\n",
      "Reconstruction: 0.556419, Regularization: 0.021113, Discriminator: 0.043126; Generator: 0.021785,\n",
      "D(x): 0.502, D(G(z)): 0.498\n",
      "2019-04-09 22:46:33,213 root         INFO     Train Epoch: 47 [4608/8000 (58%)]\tTotal Loss: 0.695088\n",
      "Reconstruction: 0.608444, Regularization: 0.021378, Discriminator: 0.043476; Generator: 0.021790,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 22:46:33,312 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.718203\n",
      "Reconstruction: 0.625307, Regularization: 0.027927, Discriminator: 0.043173; Generator: 0.021796,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 22:46:33,409 root         INFO     Train Epoch: 47 [5632/8000 (70%)]\tTotal Loss: 0.715680\n",
      "Reconstruction: 0.631788, Regularization: 0.018889, Discriminator: 0.043205; Generator: 0.021798,\n",
      "D(x): 0.501, D(G(z)): 0.498\n",
      "2019-04-09 22:46:33,507 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.683729\n",
      "Reconstruction: 0.599811, Regularization: 0.018867, Discriminator: 0.043249; Generator: 0.021801,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 22:46:33,605 root         INFO     Train Epoch: 47 [6656/8000 (83%)]\tTotal Loss: 0.791582\n",
      "Reconstruction: 0.701902, Regularization: 0.024391, Discriminator: 0.043480; Generator: 0.021809,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 22:46:33,703 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.624773\n",
      "Reconstruction: 0.541598, Regularization: 0.018477, Discriminator: 0.042887; Generator: 0.021811,\n",
      "D(x): 0.505, D(G(z)): 0.498\n",
      "2019-04-09 22:46:33,801 root         INFO     Train Epoch: 47 [7680/8000 (96%)]\tTotal Loss: 1.105158\n",
      "Reconstruction: 1.007252, Regularization: 0.031907, Discriminator: 0.044195; Generator: 0.021804,\n",
      "D(x): 0.485, D(G(z)): 0.498\n",
      "2019-04-09 22:46:33,875 root         INFO     ====> Epoch: 47 Average loss: 0.7359\n",
      "2019-04-09 22:46:33,901 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.933704\n",
      "Reconstruction: 0.838567, Regularization: 0.029766, Discriminator: 0.043558; Generator: 0.021813,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 22:46:33,998 root         INFO     Train Epoch: 48 [512/8000 (6%)]\tTotal Loss: 0.902749\n",
      "Reconstruction: 0.806426, Regularization: 0.030969, Discriminator: 0.043539; Generator: 0.021815,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 22:46:34,095 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.835036\n",
      "Reconstruction: 0.741821, Regularization: 0.027762, Discriminator: 0.043644; Generator: 0.021808,\n",
      "D(x): 0.493, D(G(z)): 0.498\n",
      "2019-04-09 22:46:34,191 root         INFO     Train Epoch: 48 [1536/8000 (19%)]\tTotal Loss: 0.752628\n",
      "Reconstruction: 0.662959, Regularization: 0.024392, Discriminator: 0.043456; Generator: 0.021821,\n",
      "D(x): 0.496, D(G(z)): 0.497\n",
      "2019-04-09 22:46:34,288 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.771025\n",
      "Reconstruction: 0.677142, Regularization: 0.028602, Discriminator: 0.043438; Generator: 0.021843,\n",
      "D(x): 0.496, D(G(z)): 0.497\n",
      "2019-04-09 22:46:34,385 root         INFO     Train Epoch: 48 [2560/8000 (32%)]\tTotal Loss: 0.552901\n",
      "Reconstruction: 0.473128, Regularization: 0.014958, Discriminator: 0.042991; Generator: 0.021824,\n",
      "D(x): 0.503, D(G(z)): 0.497\n",
      "2019-04-09 22:46:34,481 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.656138\n",
      "Reconstruction: 0.574509, Regularization: 0.016515, Discriminator: 0.043276; Generator: 0.021839,\n",
      "D(x): 0.499, D(G(z)): 0.497\n",
      "2019-04-09 22:46:34,578 root         INFO     Train Epoch: 48 [3584/8000 (45%)]\tTotal Loss: 0.700428\n",
      "Reconstruction: 0.615572, Regularization: 0.019768, Discriminator: 0.043268; Generator: 0.021820,\n",
      "D(x): 0.499, D(G(z)): 0.497\n",
      "2019-04-09 22:46:34,675 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.728784\n",
      "Reconstruction: 0.642909, Regularization: 0.020551, Discriminator: 0.043501; Generator: 0.021823,\n",
      "D(x): 0.495, D(G(z)): 0.497\n",
      "2019-04-09 22:46:34,772 root         INFO     Train Epoch: 48 [4608/8000 (58%)]\tTotal Loss: 0.884139\n",
      "Reconstruction: 0.795204, Regularization: 0.023798, Discriminator: 0.043324; Generator: 0.021814,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 22:46:34,869 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.548172\n",
      "Reconstruction: 0.465873, Regularization: 0.017490, Discriminator: 0.042993; Generator: 0.021816,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 22:46:34,966 root         INFO     Train Epoch: 48 [5632/8000 (70%)]\tTotal Loss: 0.909898\n",
      "Reconstruction: 0.820512, Regularization: 0.023699, Discriminator: 0.043877; Generator: 0.021811,\n",
      "D(x): 0.490, D(G(z)): 0.498\n",
      "2019-04-09 22:46:35,062 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.823997\n",
      "Reconstruction: 0.736245, Regularization: 0.022627, Discriminator: 0.043320; Generator: 0.021805,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 22:46:35,158 root         INFO     Train Epoch: 48 [6656/8000 (83%)]\tTotal Loss: 0.738498\n",
      "Reconstruction: 0.653105, Regularization: 0.020174, Discriminator: 0.043392; Generator: 0.021826,\n",
      "D(x): 0.498, D(G(z)): 0.497\n",
      "2019-04-09 22:46:35,255 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.763987\n",
      "Reconstruction: 0.676207, Regularization: 0.022414, Discriminator: 0.043544; Generator: 0.021822,\n",
      "D(x): 0.495, D(G(z)): 0.497\n",
      "2019-04-09 22:46:35,352 root         INFO     Train Epoch: 48 [7680/8000 (96%)]\tTotal Loss: 0.471589\n",
      "Reconstruction: 0.390682, Regularization: 0.016030, Discriminator: 0.043076; Generator: 0.021800,\n",
      "D(x): 0.502, D(G(z)): 0.498\n",
      "2019-04-09 22:46:35,426 root         INFO     ====> Epoch: 48 Average loss: 0.7326\n",
      "2019-04-09 22:46:35,452 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.636925\n",
      "Reconstruction: 0.553397, Regularization: 0.018452, Discriminator: 0.043255; Generator: 0.021821,\n",
      "D(x): 0.499, D(G(z)): 0.497\n",
      "2019-04-09 22:46:35,550 root         INFO     Train Epoch: 49 [512/8000 (6%)]\tTotal Loss: 0.788991\n",
      "Reconstruction: 0.693118, Regularization: 0.030753, Discriminator: 0.043313; Generator: 0.021806,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 22:46:35,648 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.674943\n",
      "Reconstruction: 0.587594, Regularization: 0.022475, Discriminator: 0.043057; Generator: 0.021817,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 22:46:35,747 root         INFO     Train Epoch: 49 [1536/8000 (19%)]\tTotal Loss: 0.848781\n",
      "Reconstruction: 0.754594, Regularization: 0.028960, Discriminator: 0.043413; Generator: 0.021813,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 22:46:35,845 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.538174\n",
      "Reconstruction: 0.458868, Regularization: 0.014133, Discriminator: 0.043348; Generator: 0.021825,\n",
      "D(x): 0.498, D(G(z)): 0.497\n",
      "2019-04-09 22:46:35,943 root         INFO     Train Epoch: 49 [2560/8000 (32%)]\tTotal Loss: 0.633384\n",
      "Reconstruction: 0.550401, Regularization: 0.017909, Discriminator: 0.043259; Generator: 0.021815,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 22:46:36,041 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.674141\n",
      "Reconstruction: 0.592818, Regularization: 0.015867, Discriminator: 0.043661; Generator: 0.021795,\n",
      "D(x): 0.494, D(G(z)): 0.498\n",
      "2019-04-09 22:46:36,139 root         INFO     Train Epoch: 49 [3584/8000 (45%)]\tTotal Loss: 0.738909\n",
      "Reconstruction: 0.654229, Regularization: 0.019819, Discriminator: 0.043063; Generator: 0.021798,\n",
      "D(x): 0.503, D(G(z)): 0.498\n",
      "2019-04-09 22:46:36,237 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.606600\n",
      "Reconstruction: 0.521060, Regularization: 0.021228, Discriminator: 0.042510; Generator: 0.021802,\n",
      "D(x): 0.511, D(G(z)): 0.498\n",
      "2019-04-09 22:46:36,335 root         INFO     Train Epoch: 49 [4608/8000 (58%)]\tTotal Loss: 1.069579\n",
      "Reconstruction: 0.970978, Regularization: 0.033329, Discriminator: 0.043454; Generator: 0.021819,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-04-09 22:46:36,434 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.427731\n",
      "Reconstruction: 0.349062, Regularization: 0.013717, Discriminator: 0.043121; Generator: 0.021832,\n",
      "D(x): 0.501, D(G(z)): 0.497\n",
      "2019-04-09 22:46:36,532 root         INFO     Train Epoch: 49 [5632/8000 (70%)]\tTotal Loss: 1.077360\n",
      "Reconstruction: 0.977096, Regularization: 0.034870, Discriminator: 0.043589; Generator: 0.021805,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 22:46:36,630 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.584844\n",
      "Reconstruction: 0.502142, Regularization: 0.017420, Discriminator: 0.043458; Generator: 0.021825,\n",
      "D(x): 0.496, D(G(z)): 0.497\n",
      "2019-04-09 22:46:36,728 root         INFO     Train Epoch: 49 [6656/8000 (83%)]\tTotal Loss: 0.827280\n",
      "Reconstruction: 0.735339, Regularization: 0.027100, Discriminator: 0.043002; Generator: 0.021839,\n",
      "D(x): 0.503, D(G(z)): 0.497\n",
      "2019-04-09 22:46:36,826 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.660840\n",
      "Reconstruction: 0.573386, Regularization: 0.022890, Discriminator: 0.042718; Generator: 0.021845,\n",
      "D(x): 0.507, D(G(z)): 0.497\n",
      "2019-04-09 22:46:36,924 root         INFO     Train Epoch: 49 [7680/8000 (96%)]\tTotal Loss: 0.743394\n",
      "Reconstruction: 0.659208, Regularization: 0.018618, Discriminator: 0.043747; Generator: 0.021820,\n",
      "D(x): 0.492, D(G(z)): 0.497\n",
      "2019-04-09 22:46:36,997 root         INFO     ====> Epoch: 49 Average loss: 0.7292\n",
      "2019-04-09 22:46:37,023 root         INFO     Train Epoch: 50 [0/8000 (0%)]\tTotal Loss: 0.594134\n",
      "Reconstruction: 0.514043, Regularization: 0.014590, Discriminator: 0.043682; Generator: 0.021820,\n",
      "D(x): 0.492, D(G(z)): 0.497\n",
      "2019-04-09 22:46:37,121 root         INFO     Train Epoch: 50 [512/8000 (6%)]\tTotal Loss: 0.639172\n",
      "Reconstruction: 0.558673, Regularization: 0.015206, Discriminator: 0.043471; Generator: 0.021822,\n",
      "D(x): 0.496, D(G(z)): 0.497\n",
      "2019-04-09 22:46:37,218 root         INFO     Train Epoch: 50 [1024/8000 (13%)]\tTotal Loss: 0.780449\n",
      "Reconstruction: 0.692363, Regularization: 0.022757, Discriminator: 0.043537; Generator: 0.021792,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 22:46:37,314 root         INFO     Train Epoch: 50 [1536/8000 (19%)]\tTotal Loss: 0.852781\n",
      "Reconstruction: 0.762908, Regularization: 0.025270, Discriminator: 0.042817; Generator: 0.021786,\n",
      "D(x): 0.507, D(G(z)): 0.498\n",
      "2019-04-09 22:46:37,412 root         INFO     Train Epoch: 50 [2048/8000 (26%)]\tTotal Loss: 0.624504\n",
      "Reconstruction: 0.533441, Regularization: 0.026180, Discriminator: 0.043082; Generator: 0.021800,\n",
      "D(x): 0.502, D(G(z)): 0.498\n",
      "2019-04-09 22:46:37,509 root         INFO     Train Epoch: 50 [2560/8000 (32%)]\tTotal Loss: 0.837025\n",
      "Reconstruction: 0.748375, Regularization: 0.023451, Discriminator: 0.043386; Generator: 0.021814,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 22:46:37,608 root         INFO     Train Epoch: 50 [3072/8000 (38%)]\tTotal Loss: 0.766082\n",
      "Reconstruction: 0.677412, Regularization: 0.023880, Discriminator: 0.042961; Generator: 0.021829,\n",
      "D(x): 0.504, D(G(z)): 0.497\n",
      "2019-04-09 22:46:37,705 root         INFO     Train Epoch: 50 [3584/8000 (45%)]\tTotal Loss: 0.581782\n",
      "Reconstruction: 0.497945, Regularization: 0.018618, Discriminator: 0.043405; Generator: 0.021813,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 22:46:37,804 root         INFO     Train Epoch: 50 [4096/8000 (51%)]\tTotal Loss: 0.680072\n",
      "Reconstruction: 0.594045, Regularization: 0.020906, Discriminator: 0.043324; Generator: 0.021798,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 22:46:37,901 root         INFO     Train Epoch: 50 [4608/8000 (58%)]\tTotal Loss: 1.080004\n",
      "Reconstruction: 0.987286, Regularization: 0.027247, Discriminator: 0.043662; Generator: 0.021809,\n",
      "D(x): 0.493, D(G(z)): 0.498\n",
      "2019-04-09 22:46:37,999 root         INFO     Train Epoch: 50 [5120/8000 (64%)]\tTotal Loss: 0.611096\n",
      "Reconstruction: 0.527460, Regularization: 0.018493, Discriminator: 0.043336; Generator: 0.021806,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 22:46:38,095 root         INFO     Train Epoch: 50 [5632/8000 (70%)]\tTotal Loss: 0.688151\n",
      "Reconstruction: 0.606508, Regularization: 0.016031, Discriminator: 0.043772; Generator: 0.021841,\n",
      "D(x): 0.491, D(G(z)): 0.497\n",
      "2019-04-09 22:46:38,193 root         INFO     Train Epoch: 50 [6144/8000 (77%)]\tTotal Loss: 0.693855\n",
      "Reconstruction: 0.607265, Regularization: 0.021553, Discriminator: 0.043200; Generator: 0.021837,\n",
      "D(x): 0.499, D(G(z)): 0.497\n",
      "2019-04-09 22:46:38,290 root         INFO     Train Epoch: 50 [6656/8000 (83%)]\tTotal Loss: 0.870556\n",
      "Reconstruction: 0.778055, Regularization: 0.027236, Discriminator: 0.043425; Generator: 0.021840,\n",
      "D(x): 0.496, D(G(z)): 0.497\n",
      "2019-04-09 22:46:38,387 root         INFO     Train Epoch: 50 [7168/8000 (90%)]\tTotal Loss: 0.577040\n",
      "Reconstruction: 0.491363, Regularization: 0.020912, Discriminator: 0.042953; Generator: 0.021811,\n",
      "D(x): 0.504, D(G(z)): 0.498\n",
      "2019-04-09 22:46:38,485 root         INFO     Train Epoch: 50 [7680/8000 (96%)]\tTotal Loss: 0.508763\n",
      "Reconstruction: 0.429640, Regularization: 0.013965, Discriminator: 0.043351; Generator: 0.021806,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 22:46:38,559 root         INFO     ====> Epoch: 50 Average loss: 0.7254\n",
      "2019-04-09 22:46:38,585 root         INFO     Train Epoch: 51 [0/8000 (0%)]\tTotal Loss: 0.761048\n",
      "Reconstruction: 0.673338, Regularization: 0.022519, Discriminator: 0.043385; Generator: 0.021806,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 22:46:38,686 root         INFO     Train Epoch: 51 [512/8000 (6%)]\tTotal Loss: 0.583256\n",
      "Reconstruction: 0.500802, Regularization: 0.017283, Discriminator: 0.043368; Generator: 0.021804,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 22:46:38,786 root         INFO     Train Epoch: 51 [1024/8000 (13%)]\tTotal Loss: 0.453738\n",
      "Reconstruction: 0.372377, Regularization: 0.015940, Discriminator: 0.043629; Generator: 0.021792,\n",
      "D(x): 0.493, D(G(z)): 0.498\n",
      "2019-04-09 22:46:38,886 root         INFO     Train Epoch: 51 [1536/8000 (19%)]\tTotal Loss: 0.645034\n",
      "Reconstruction: 0.564521, Regularization: 0.015016, Discriminator: 0.043709; Generator: 0.021788,\n",
      "D(x): 0.492, D(G(z)): 0.498\n",
      "2019-04-09 22:46:38,986 root         INFO     Train Epoch: 51 [2048/8000 (26%)]\tTotal Loss: 0.786202\n",
      "Reconstruction: 0.698848, Regularization: 0.022124, Discriminator: 0.043468; Generator: 0.021762,\n",
      "D(x): 0.497, D(G(z)): 0.498\n",
      "2019-04-09 22:46:39,086 root         INFO     Train Epoch: 51 [2560/8000 (32%)]\tTotal Loss: 0.565764\n",
      "Reconstruction: 0.481328, Regularization: 0.019465, Discriminator: 0.043170; Generator: 0.021801,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 22:46:39,186 root         INFO     Train Epoch: 51 [3072/8000 (38%)]\tTotal Loss: 0.769599\n",
      "Reconstruction: 0.683020, Regularization: 0.021324, Discriminator: 0.043458; Generator: 0.021797,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 22:46:39,285 root         INFO     Train Epoch: 51 [3584/8000 (45%)]\tTotal Loss: 0.631763\n",
      "Reconstruction: 0.545828, Regularization: 0.020923, Discriminator: 0.043220; Generator: 0.021791,\n",
      "D(x): 0.500, D(G(z)): 0.498\n",
      "2019-04-09 22:46:39,381 root         INFO     Train Epoch: 51 [4096/8000 (51%)]\tTotal Loss: 0.663732\n",
      "Reconstruction: 0.576459, Regularization: 0.022194, Discriminator: 0.043280; Generator: 0.021799,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 22:46:39,477 root         INFO     Train Epoch: 51 [4608/8000 (58%)]\tTotal Loss: 0.781682\n",
      "Reconstruction: 0.691532, Regularization: 0.024892, Discriminator: 0.043468; Generator: 0.021790,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 22:46:39,573 root         INFO     Train Epoch: 51 [5120/8000 (64%)]\tTotal Loss: 0.795593\n",
      "Reconstruction: 0.708907, Regularization: 0.021378, Discriminator: 0.043535; Generator: 0.021773,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 22:46:39,668 root         INFO     Train Epoch: 51 [5632/8000 (70%)]\tTotal Loss: 0.743603\n",
      "Reconstruction: 0.660939, Regularization: 0.017238, Discriminator: 0.043688; Generator: 0.021738,\n",
      "D(x): 0.493, D(G(z)): 0.499\n",
      "2019-04-09 22:46:39,764 root         INFO     Train Epoch: 51 [6144/8000 (77%)]\tTotal Loss: 0.698367\n",
      "Reconstruction: 0.613214, Regularization: 0.019739, Discriminator: 0.043678; Generator: 0.021737,\n",
      "D(x): 0.493, D(G(z)): 0.499\n",
      "2019-04-09 22:46:39,860 root         INFO     Train Epoch: 51 [6656/8000 (83%)]\tTotal Loss: 0.728403\n",
      "Reconstruction: 0.641382, Regularization: 0.021965, Discriminator: 0.043323; Generator: 0.021733,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:39,956 root         INFO     Train Epoch: 51 [7168/8000 (90%)]\tTotal Loss: 0.581254\n",
      "Reconstruction: 0.503232, Regularization: 0.012549, Discriminator: 0.043751; Generator: 0.021721,\n",
      "D(x): 0.492, D(G(z)): 0.499\n",
      "2019-04-09 22:46:40,051 root         INFO     Train Epoch: 51 [7680/8000 (96%)]\tTotal Loss: 0.775822\n",
      "Reconstruction: 0.689806, Regularization: 0.020773, Discriminator: 0.043503; Generator: 0.021740,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 22:46:40,123 root         INFO     ====> Epoch: 51 Average loss: 0.7204\n",
      "2019-04-09 22:46:40,149 root         INFO     Train Epoch: 52 [0/8000 (0%)]\tTotal Loss: 0.697935\n",
      "Reconstruction: 0.616706, Regularization: 0.015651, Discriminator: 0.043811; Generator: 0.021767,\n",
      "D(x): 0.491, D(G(z)): 0.498\n",
      "2019-04-09 22:46:40,251 root         INFO     Train Epoch: 52 [512/8000 (6%)]\tTotal Loss: 0.745775\n",
      "Reconstruction: 0.660229, Regularization: 0.020248, Discriminator: 0.043528; Generator: 0.021769,\n",
      "D(x): 0.495, D(G(z)): 0.498\n",
      "2019-04-09 22:46:40,351 root         INFO     Train Epoch: 52 [1024/8000 (13%)]\tTotal Loss: 0.577599\n",
      "Reconstruction: 0.493406, Regularization: 0.018926, Discriminator: 0.043508; Generator: 0.021758,\n",
      "D(x): 0.496, D(G(z)): 0.498\n",
      "2019-04-09 22:46:40,450 root         INFO     Train Epoch: 52 [1536/8000 (19%)]\tTotal Loss: 0.527529\n",
      "Reconstruction: 0.449591, Regularization: 0.012912, Discriminator: 0.043285; Generator: 0.021741,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:40,549 root         INFO     Train Epoch: 52 [2048/8000 (26%)]\tTotal Loss: 0.556716\n",
      "Reconstruction: 0.478825, Regularization: 0.012729, Discriminator: 0.043443; Generator: 0.021718,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 22:46:40,647 root         INFO     Train Epoch: 52 [2560/8000 (32%)]\tTotal Loss: 0.538498\n",
      "Reconstruction: 0.457610, Regularization: 0.015947, Discriminator: 0.043236; Generator: 0.021704,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 22:46:40,745 root         INFO     Train Epoch: 52 [3072/8000 (38%)]\tTotal Loss: 0.757964\n",
      "Reconstruction: 0.669457, Regularization: 0.023339, Discriminator: 0.043455; Generator: 0.021713,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 22:46:40,844 root         INFO     Train Epoch: 52 [3584/8000 (45%)]\tTotal Loss: 0.599744\n",
      "Reconstruction: 0.512312, Regularization: 0.022420, Discriminator: 0.043308; Generator: 0.021704,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:40,943 root         INFO     Train Epoch: 52 [4096/8000 (51%)]\tTotal Loss: 0.593730\n",
      "Reconstruction: 0.511165, Regularization: 0.017503, Discriminator: 0.043363; Generator: 0.021699,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:41,041 root         INFO     Train Epoch: 52 [4608/8000 (58%)]\tTotal Loss: 1.066342\n",
      "Reconstruction: 0.970266, Regularization: 0.030820, Discriminator: 0.043545; Generator: 0.021711,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 22:46:41,140 root         INFO     Train Epoch: 52 [5120/8000 (64%)]\tTotal Loss: 0.737892\n",
      "Reconstruction: 0.654871, Regularization: 0.017950, Discriminator: 0.043367; Generator: 0.021704,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:41,239 root         INFO     Train Epoch: 52 [5632/8000 (70%)]\tTotal Loss: 0.651051\n",
      "Reconstruction: 0.569050, Regularization: 0.016810, Discriminator: 0.043482; Generator: 0.021710,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 22:46:41,337 root         INFO     Train Epoch: 52 [6144/8000 (77%)]\tTotal Loss: 0.661726\n",
      "Reconstruction: 0.579841, Regularization: 0.016661, Discriminator: 0.043499; Generator: 0.021726,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 22:46:41,435 root         INFO     Train Epoch: 52 [6656/8000 (83%)]\tTotal Loss: 0.417525\n",
      "Reconstruction: 0.340420, Regularization: 0.011905, Discriminator: 0.043493; Generator: 0.021707,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 22:46:41,533 root         INFO     Train Epoch: 52 [7168/8000 (90%)]\tTotal Loss: 0.807093\n",
      "Reconstruction: 0.717425, Regularization: 0.024703, Discriminator: 0.043255; Generator: 0.021711,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:41,631 root         INFO     Train Epoch: 52 [7680/8000 (96%)]\tTotal Loss: 0.561663\n",
      "Reconstruction: 0.478038, Regularization: 0.018529, Discriminator: 0.043386; Generator: 0.021710,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:41,706 root         INFO     ====> Epoch: 52 Average loss: 0.7169\n",
      "2019-04-09 22:46:41,732 root         INFO     Train Epoch: 53 [0/8000 (0%)]\tTotal Loss: 0.747065\n",
      "Reconstruction: 0.659049, Regularization: 0.023051, Discriminator: 0.043253; Generator: 0.021713,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:41,832 root         INFO     Train Epoch: 53 [512/8000 (6%)]\tTotal Loss: 0.677467\n",
      "Reconstruction: 0.594900, Regularization: 0.017604, Discriminator: 0.043241; Generator: 0.021722,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:41,931 root         INFO     Train Epoch: 53 [1024/8000 (13%)]\tTotal Loss: 0.543487\n",
      "Reconstruction: 0.465849, Regularization: 0.012638, Discriminator: 0.043299; Generator: 0.021700,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:42,031 root         INFO     Train Epoch: 53 [1536/8000 (19%)]\tTotal Loss: 0.804730\n",
      "Reconstruction: 0.717227, Regularization: 0.022232, Discriminator: 0.043564; Generator: 0.021708,\n",
      "D(x): 0.495, D(G(z)): 0.499\n",
      "2019-04-09 22:46:42,130 root         INFO     Train Epoch: 53 [2048/8000 (26%)]\tTotal Loss: 0.809141\n",
      "Reconstruction: 0.721399, Regularization: 0.022554, Discriminator: 0.043483; Generator: 0.021705,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 22:46:42,228 root         INFO     Train Epoch: 53 [2560/8000 (32%)]\tTotal Loss: 0.547660\n",
      "Reconstruction: 0.469223, Regularization: 0.013376, Discriminator: 0.043364; Generator: 0.021698,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:42,327 root         INFO     Train Epoch: 53 [3072/8000 (38%)]\tTotal Loss: 0.960465\n",
      "Reconstruction: 0.862453, Regularization: 0.032889, Discriminator: 0.043410; Generator: 0.021713,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:42,425 root         INFO     Train Epoch: 53 [3584/8000 (45%)]\tTotal Loss: 0.725361\n",
      "Reconstruction: 0.640363, Regularization: 0.019920, Discriminator: 0.043365; Generator: 0.021713,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:42,523 root         INFO     Train Epoch: 53 [4096/8000 (51%)]\tTotal Loss: 0.829496\n",
      "Reconstruction: 0.742820, Regularization: 0.021621, Discriminator: 0.043344; Generator: 0.021711,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:42,621 root         INFO     Train Epoch: 53 [4608/8000 (58%)]\tTotal Loss: 0.954104\n",
      "Reconstruction: 0.858457, Regularization: 0.030547, Discriminator: 0.043395; Generator: 0.021705,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:42,719 root         INFO     Train Epoch: 53 [5120/8000 (64%)]\tTotal Loss: 0.696914\n",
      "Reconstruction: 0.614562, Regularization: 0.017130, Discriminator: 0.043516; Generator: 0.021706,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 22:46:42,817 root         INFO     Train Epoch: 53 [5632/8000 (70%)]\tTotal Loss: 0.766073\n",
      "Reconstruction: 0.677319, Regularization: 0.023717, Discriminator: 0.043338; Generator: 0.021700,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:42,915 root         INFO     Train Epoch: 53 [6144/8000 (77%)]\tTotal Loss: 0.710131\n",
      "Reconstruction: 0.625897, Regularization: 0.019114, Discriminator: 0.043421; Generator: 0.021699,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:43,012 root         INFO     Train Epoch: 53 [6656/8000 (83%)]\tTotal Loss: 0.931016\n",
      "Reconstruction: 0.842687, Regularization: 0.023192, Discriminator: 0.043431; Generator: 0.021706,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:43,110 root         INFO     Train Epoch: 53 [7168/8000 (90%)]\tTotal Loss: 0.627291\n",
      "Reconstruction: 0.545185, Regularization: 0.017078, Discriminator: 0.043333; Generator: 0.021695,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:43,209 root         INFO     Train Epoch: 53 [7680/8000 (96%)]\tTotal Loss: 0.708877\n",
      "Reconstruction: 0.623018, Regularization: 0.020934, Discriminator: 0.043240; Generator: 0.021685,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:46:43,282 root         INFO     ====> Epoch: 53 Average loss: 0.7145\n",
      "2019-04-09 22:46:43,308 root         INFO     Train Epoch: 54 [0/8000 (0%)]\tTotal Loss: 0.767692\n",
      "Reconstruction: 0.685485, Regularization: 0.017112, Discriminator: 0.043415; Generator: 0.021681,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:46:43,407 root         INFO     Train Epoch: 54 [512/8000 (6%)]\tTotal Loss: 0.939651\n",
      "Reconstruction: 0.847775, Regularization: 0.026814, Discriminator: 0.043381; Generator: 0.021681,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:46:43,504 root         INFO     Train Epoch: 54 [1024/8000 (13%)]\tTotal Loss: 0.743520\n",
      "Reconstruction: 0.659846, Regularization: 0.018600, Discriminator: 0.043382; Generator: 0.021690,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:46:43,601 root         INFO     Train Epoch: 54 [1536/8000 (19%)]\tTotal Loss: 0.570349\n",
      "Reconstruction: 0.492289, Regularization: 0.012970, Discriminator: 0.043404; Generator: 0.021685,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:46:43,699 root         INFO     Train Epoch: 54 [2048/8000 (26%)]\tTotal Loss: 0.715128\n",
      "Reconstruction: 0.630866, Regularization: 0.019211, Discriminator: 0.043358; Generator: 0.021692,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:43,795 root         INFO     Train Epoch: 54 [2560/8000 (32%)]\tTotal Loss: 1.049873\n",
      "Reconstruction: 0.958545, Regularization: 0.026209, Discriminator: 0.043412; Generator: 0.021706,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:43,892 root         INFO     Train Epoch: 54 [3072/8000 (38%)]\tTotal Loss: 0.591161\n",
      "Reconstruction: 0.505666, Regularization: 0.020601, Discriminator: 0.043194; Generator: 0.021701,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 22:46:43,989 root         INFO     Train Epoch: 54 [3584/8000 (45%)]\tTotal Loss: 0.791211\n",
      "Reconstruction: 0.705613, Regularization: 0.020523, Discriminator: 0.043380; Generator: 0.021695,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:44,086 root         INFO     Train Epoch: 54 [4096/8000 (51%)]\tTotal Loss: 0.570432\n",
      "Reconstruction: 0.488148, Regularization: 0.017323, Discriminator: 0.043263; Generator: 0.021698,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:44,182 root         INFO     Train Epoch: 54 [4608/8000 (58%)]\tTotal Loss: 0.912224\n",
      "Reconstruction: 0.817497, Regularization: 0.029761, Discriminator: 0.043277; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:44,277 root         INFO     Train Epoch: 54 [5120/8000 (64%)]\tTotal Loss: 0.548329\n",
      "Reconstruction: 0.468297, Regularization: 0.015015, Discriminator: 0.043323; Generator: 0.021695,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:44,371 root         INFO     Train Epoch: 54 [5632/8000 (70%)]\tTotal Loss: 0.588058\n",
      "Reconstruction: 0.503891, Regularization: 0.019193, Discriminator: 0.043272; Generator: 0.021702,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:44,465 root         INFO     Train Epoch: 54 [6144/8000 (77%)]\tTotal Loss: 0.583478\n",
      "Reconstruction: 0.501695, Regularization: 0.016743, Discriminator: 0.043333; Generator: 0.021707,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:44,560 root         INFO     Train Epoch: 54 [6656/8000 (83%)]\tTotal Loss: 0.755185\n",
      "Reconstruction: 0.669935, Regularization: 0.020191, Discriminator: 0.043368; Generator: 0.021692,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:46:44,654 root         INFO     Train Epoch: 54 [7168/8000 (90%)]\tTotal Loss: 0.638099\n",
      "Reconstruction: 0.555582, Regularization: 0.017491, Discriminator: 0.043335; Generator: 0.021691,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:46:44,749 root         INFO     Train Epoch: 54 [7680/8000 (96%)]\tTotal Loss: 0.676741\n",
      "Reconstruction: 0.593772, Regularization: 0.017995, Discriminator: 0.043264; Generator: 0.021710,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:44,820 root         INFO     ====> Epoch: 54 Average loss: 0.7136\n",
      "2019-04-09 22:46:44,848 root         INFO     Train Epoch: 55 [0/8000 (0%)]\tTotal Loss: 0.599642\n",
      "Reconstruction: 0.518589, Regularization: 0.016014, Discriminator: 0.043306; Generator: 0.021733,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:44,944 root         INFO     Train Epoch: 55 [512/8000 (6%)]\tTotal Loss: 0.688403\n",
      "Reconstruction: 0.605030, Regularization: 0.018314, Discriminator: 0.043347; Generator: 0.021713,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:45,039 root         INFO     Train Epoch: 55 [1024/8000 (13%)]\tTotal Loss: 0.635601\n",
      "Reconstruction: 0.552549, Regularization: 0.018005, Discriminator: 0.043329; Generator: 0.021717,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:45,134 root         INFO     Train Epoch: 55 [1536/8000 (19%)]\tTotal Loss: 0.904055\n",
      "Reconstruction: 0.810819, Regularization: 0.028156, Discriminator: 0.043363; Generator: 0.021718,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:45,229 root         INFO     Train Epoch: 55 [2048/8000 (26%)]\tTotal Loss: 0.591870\n",
      "Reconstruction: 0.514826, Regularization: 0.012002, Discriminator: 0.043306; Generator: 0.021735,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:45,324 root         INFO     Train Epoch: 55 [2560/8000 (32%)]\tTotal Loss: 0.677310\n",
      "Reconstruction: 0.597416, Regularization: 0.014901, Discriminator: 0.043260; Generator: 0.021732,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:45,419 root         INFO     Train Epoch: 55 [3072/8000 (38%)]\tTotal Loss: 0.878871\n",
      "Reconstruction: 0.790295, Regularization: 0.023628, Discriminator: 0.043210; Generator: 0.021738,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 22:46:45,513 root         INFO     Train Epoch: 55 [3584/8000 (45%)]\tTotal Loss: 0.601762\n",
      "Reconstruction: 0.517227, Regularization: 0.019501, Discriminator: 0.043273; Generator: 0.021760,\n",
      "D(x): 0.499, D(G(z)): 0.498\n",
      "2019-04-09 22:46:45,609 root         INFO     Train Epoch: 55 [4096/8000 (51%)]\tTotal Loss: 0.814916\n",
      "Reconstruction: 0.728520, Regularization: 0.021203, Discriminator: 0.043445; Generator: 0.021747,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 22:46:45,704 root         INFO     Train Epoch: 55 [4608/8000 (58%)]\tTotal Loss: 0.667473\n",
      "Reconstruction: 0.579199, Regularization: 0.023400, Discriminator: 0.043140; Generator: 0.021734,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 22:46:45,799 root         INFO     Train Epoch: 55 [5120/8000 (64%)]\tTotal Loss: 0.537182\n",
      "Reconstruction: 0.458715, Regularization: 0.013600, Discriminator: 0.043149; Generator: 0.021717,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 22:46:45,897 root         INFO     Train Epoch: 55 [5632/8000 (70%)]\tTotal Loss: 0.670354\n",
      "Reconstruction: 0.586784, Regularization: 0.018480, Discriminator: 0.043337; Generator: 0.021754,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:45,994 root         INFO     Train Epoch: 55 [6144/8000 (77%)]\tTotal Loss: 0.879120\n",
      "Reconstruction: 0.787799, Regularization: 0.026275, Discriminator: 0.043316; Generator: 0.021729,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:46,091 root         INFO     Train Epoch: 55 [6656/8000 (83%)]\tTotal Loss: 0.664648\n",
      "Reconstruction: 0.582125, Regularization: 0.017503, Discriminator: 0.043284; Generator: 0.021736,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:46,188 root         INFO     Train Epoch: 55 [7168/8000 (90%)]\tTotal Loss: 0.526745\n",
      "Reconstruction: 0.446024, Regularization: 0.015724, Discriminator: 0.043259; Generator: 0.021737,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:46,285 root         INFO     Train Epoch: 55 [7680/8000 (96%)]\tTotal Loss: 0.589369\n",
      "Reconstruction: 0.510641, Regularization: 0.013786, Discriminator: 0.043215; Generator: 0.021727,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 22:46:46,358 root         INFO     ====> Epoch: 55 Average loss: 0.7160\n",
      "2019-04-09 22:46:46,384 root         INFO     Train Epoch: 56 [0/8000 (0%)]\tTotal Loss: 0.872583\n",
      "Reconstruction: 0.782653, Regularization: 0.024623, Discriminator: 0.043575; Generator: 0.021731,\n",
      "D(x): 0.495, D(G(z)): 0.499\n",
      "2019-04-09 22:46:46,482 root         INFO     Train Epoch: 56 [512/8000 (6%)]\tTotal Loss: 0.693158\n",
      "Reconstruction: 0.609735, Regularization: 0.018347, Discriminator: 0.043356; Generator: 0.021720,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:46,579 root         INFO     Train Epoch: 56 [1024/8000 (13%)]\tTotal Loss: 0.551603\n",
      "Reconstruction: 0.470643, Regularization: 0.015856, Discriminator: 0.043358; Generator: 0.021745,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:46,676 root         INFO     Train Epoch: 56 [1536/8000 (19%)]\tTotal Loss: 0.547376\n",
      "Reconstruction: 0.467203, Regularization: 0.015376, Discriminator: 0.043060; Generator: 0.021736,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 22:46:46,772 root         INFO     Train Epoch: 56 [2048/8000 (26%)]\tTotal Loss: 0.699449\n",
      "Reconstruction: 0.614387, Regularization: 0.019968, Discriminator: 0.043377; Generator: 0.021716,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:46,868 root         INFO     Train Epoch: 56 [2560/8000 (32%)]\tTotal Loss: 0.767374\n",
      "Reconstruction: 0.678575, Regularization: 0.023768, Discriminator: 0.043304; Generator: 0.021727,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:46,968 root         INFO     Train Epoch: 56 [3072/8000 (38%)]\tTotal Loss: 0.723117\n",
      "Reconstruction: 0.638683, Regularization: 0.019295, Discriminator: 0.043433; Generator: 0.021706,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:47,066 root         INFO     Train Epoch: 56 [3584/8000 (45%)]\tTotal Loss: 0.957528\n",
      "Reconstruction: 0.866068, Regularization: 0.026596, Discriminator: 0.043139; Generator: 0.021725,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 22:46:47,163 root         INFO     Train Epoch: 56 [4096/8000 (51%)]\tTotal Loss: 0.541524\n",
      "Reconstruction: 0.461208, Regularization: 0.015439, Discriminator: 0.043154; Generator: 0.021723,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 22:46:47,259 root         INFO     Train Epoch: 56 [4608/8000 (58%)]\tTotal Loss: 0.675860\n",
      "Reconstruction: 0.590031, Regularization: 0.020688, Discriminator: 0.043405; Generator: 0.021736,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:47,355 root         INFO     Train Epoch: 56 [5120/8000 (64%)]\tTotal Loss: 0.703113\n",
      "Reconstruction: 0.621648, Regularization: 0.016648, Discriminator: 0.043107; Generator: 0.021710,\n",
      "D(x): 0.503, D(G(z)): 0.499\n",
      "2019-04-09 22:46:47,452 root         INFO     Train Epoch: 56 [5632/8000 (70%)]\tTotal Loss: 0.649505\n",
      "Reconstruction: 0.566155, Regularization: 0.018339, Discriminator: 0.043310; Generator: 0.021702,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:47,548 root         INFO     Train Epoch: 56 [6144/8000 (77%)]\tTotal Loss: 0.720865\n",
      "Reconstruction: 0.636598, Regularization: 0.019419, Discriminator: 0.043158; Generator: 0.021690,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:46:47,647 root         INFO     Train Epoch: 56 [6656/8000 (83%)]\tTotal Loss: 0.797212\n",
      "Reconstruction: 0.712916, Regularization: 0.019169, Discriminator: 0.043389; Generator: 0.021739,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:47,745 root         INFO     Train Epoch: 56 [7168/8000 (90%)]\tTotal Loss: 0.872929\n",
      "Reconstruction: 0.787573, Regularization: 0.020215, Discriminator: 0.043378; Generator: 0.021764,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-04-09 22:46:47,843 root         INFO     Train Epoch: 56 [7680/8000 (96%)]\tTotal Loss: 0.713549\n",
      "Reconstruction: 0.629081, Regularization: 0.019427, Discriminator: 0.043332; Generator: 0.021709,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:47,916 root         INFO     ====> Epoch: 56 Average loss: 0.7207\n",
      "2019-04-09 22:46:47,942 root         INFO     Train Epoch: 57 [0/8000 (0%)]\tTotal Loss: 0.718638\n",
      "Reconstruction: 0.634459, Regularization: 0.019046, Discriminator: 0.043389; Generator: 0.021742,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:48,043 root         INFO     Train Epoch: 57 [512/8000 (6%)]\tTotal Loss: 0.930753\n",
      "Reconstruction: 0.838310, Regularization: 0.027209, Discriminator: 0.043492; Generator: 0.021742,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 22:46:48,142 root         INFO     Train Epoch: 57 [1024/8000 (13%)]\tTotal Loss: 0.654908\n",
      "Reconstruction: 0.570998, Regularization: 0.018806, Discriminator: 0.043351; Generator: 0.021752,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:48,241 root         INFO     Train Epoch: 57 [1536/8000 (19%)]\tTotal Loss: 0.614071\n",
      "Reconstruction: 0.534081, Regularization: 0.014734, Discriminator: 0.043518; Generator: 0.021737,\n",
      "D(x): 0.496, D(G(z)): 0.499\n",
      "2019-04-09 22:46:48,340 root         INFO     Train Epoch: 57 [2048/8000 (26%)]\tTotal Loss: 0.672351\n",
      "Reconstruction: 0.588799, Regularization: 0.018471, Discriminator: 0.043361; Generator: 0.021719,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:48,439 root         INFO     Train Epoch: 57 [2560/8000 (32%)]\tTotal Loss: 0.557405\n",
      "Reconstruction: 0.478586, Regularization: 0.013961, Discriminator: 0.043138; Generator: 0.021720,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 22:46:48,538 root         INFO     Train Epoch: 57 [3072/8000 (38%)]\tTotal Loss: 0.914269\n",
      "Reconstruction: 0.822059, Regularization: 0.027273, Discriminator: 0.043230; Generator: 0.021706,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 22:46:48,638 root         INFO     Train Epoch: 57 [3584/8000 (45%)]\tTotal Loss: 1.026040\n",
      "Reconstruction: 0.928235, Regularization: 0.032804, Discriminator: 0.043295; Generator: 0.021706,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:48,736 root         INFO     Train Epoch: 57 [4096/8000 (51%)]\tTotal Loss: 0.498977\n",
      "Reconstruction: 0.422865, Regularization: 0.010979, Discriminator: 0.043424; Generator: 0.021709,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:48,836 root         INFO     Train Epoch: 57 [4608/8000 (58%)]\tTotal Loss: 1.066236\n",
      "Reconstruction: 0.970110, Regularization: 0.031158, Discriminator: 0.043275; Generator: 0.021693,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:48,935 root         INFO     Train Epoch: 57 [5120/8000 (64%)]\tTotal Loss: 0.559561\n",
      "Reconstruction: 0.479936, Regularization: 0.014685, Discriminator: 0.043228; Generator: 0.021712,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 22:46:49,035 root         INFO     Train Epoch: 57 [5632/8000 (70%)]\tTotal Loss: 0.679482\n",
      "Reconstruction: 0.597085, Regularization: 0.017419, Discriminator: 0.043287; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:49,134 root         INFO     Train Epoch: 57 [6144/8000 (77%)]\tTotal Loss: 0.654325\n",
      "Reconstruction: 0.571334, Regularization: 0.017931, Discriminator: 0.043356; Generator: 0.021704,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:49,233 root         INFO     Train Epoch: 57 [6656/8000 (83%)]\tTotal Loss: 0.870896\n",
      "Reconstruction: 0.786102, Regularization: 0.019801, Discriminator: 0.043315; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:49,332 root         INFO     Train Epoch: 57 [7168/8000 (90%)]\tTotal Loss: 1.125130\n",
      "Reconstruction: 1.029215, Regularization: 0.030927, Discriminator: 0.043275; Generator: 0.021712,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:49,431 root         INFO     Train Epoch: 57 [7680/8000 (96%)]\tTotal Loss: 0.613325\n",
      "Reconstruction: 0.535426, Regularization: 0.012866, Discriminator: 0.043317; Generator: 0.021716,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:49,505 root         INFO     ====> Epoch: 57 Average loss: 0.7258\n",
      "2019-04-09 22:46:49,531 root         INFO     Train Epoch: 58 [0/8000 (0%)]\tTotal Loss: 0.693688\n",
      "Reconstruction: 0.613733, Regularization: 0.014948, Discriminator: 0.043300; Generator: 0.021707,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:49,631 root         INFO     Train Epoch: 58 [512/8000 (6%)]\tTotal Loss: 0.746101\n",
      "Reconstruction: 0.659473, Regularization: 0.021557, Discriminator: 0.043369; Generator: 0.021702,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:49,729 root         INFO     Train Epoch: 58 [1024/8000 (13%)]\tTotal Loss: 0.655778\n",
      "Reconstruction: 0.574663, Regularization: 0.016103, Discriminator: 0.043310; Generator: 0.021703,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:49,828 root         INFO     Train Epoch: 58 [1536/8000 (19%)]\tTotal Loss: 0.829490\n",
      "Reconstruction: 0.741099, Regularization: 0.023331, Discriminator: 0.043358; Generator: 0.021702,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:49,924 root         INFO     Train Epoch: 58 [2048/8000 (26%)]\tTotal Loss: 0.693290\n",
      "Reconstruction: 0.608312, Regularization: 0.019959, Discriminator: 0.043320; Generator: 0.021698,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:50,021 root         INFO     Train Epoch: 58 [2560/8000 (32%)]\tTotal Loss: 0.733421\n",
      "Reconstruction: 0.650144, Regularization: 0.018297, Discriminator: 0.043273; Generator: 0.021708,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:50,119 root         INFO     Train Epoch: 58 [3072/8000 (38%)]\tTotal Loss: 0.491444\n",
      "Reconstruction: 0.413640, Regularization: 0.012826, Discriminator: 0.043280; Generator: 0.021698,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:50,217 root         INFO     Train Epoch: 58 [3584/8000 (45%)]\tTotal Loss: 0.789559\n",
      "Reconstruction: 0.703172, Regularization: 0.021469, Discriminator: 0.043215; Generator: 0.021703,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 22:46:50,315 root         INFO     Train Epoch: 58 [4096/8000 (51%)]\tTotal Loss: 0.728858\n",
      "Reconstruction: 0.642799, Regularization: 0.020958, Discriminator: 0.043396; Generator: 0.021706,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:50,412 root         INFO     Train Epoch: 58 [4608/8000 (58%)]\tTotal Loss: 0.680843\n",
      "Reconstruction: 0.598022, Regularization: 0.017779, Discriminator: 0.043345; Generator: 0.021698,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:50,510 root         INFO     Train Epoch: 58 [5120/8000 (64%)]\tTotal Loss: 0.566487\n",
      "Reconstruction: 0.489078, Regularization: 0.012386, Discriminator: 0.043328; Generator: 0.021696,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:50,606 root         INFO     Train Epoch: 58 [5632/8000 (70%)]\tTotal Loss: 0.681430\n",
      "Reconstruction: 0.593745, Regularization: 0.022617, Discriminator: 0.043371; Generator: 0.021697,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:50,702 root         INFO     Train Epoch: 58 [6144/8000 (77%)]\tTotal Loss: 0.614118\n",
      "Reconstruction: 0.529445, Regularization: 0.019594, Discriminator: 0.043385; Generator: 0.021694,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:50,797 root         INFO     Train Epoch: 58 [6656/8000 (83%)]\tTotal Loss: 0.763475\n",
      "Reconstruction: 0.672987, Regularization: 0.025409, Discriminator: 0.043374; Generator: 0.021704,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:50,894 root         INFO     Train Epoch: 58 [7168/8000 (90%)]\tTotal Loss: 0.575033\n",
      "Reconstruction: 0.495591, Regularization: 0.014472, Discriminator: 0.043264; Generator: 0.021707,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:50,989 root         INFO     Train Epoch: 58 [7680/8000 (96%)]\tTotal Loss: 0.670613\n",
      "Reconstruction: 0.588815, Regularization: 0.016784, Discriminator: 0.043313; Generator: 0.021702,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:51,062 root         INFO     ====> Epoch: 58 Average loss: 0.7279\n",
      "2019-04-09 22:46:51,088 root         INFO     Train Epoch: 59 [0/8000 (0%)]\tTotal Loss: 0.638633\n",
      "Reconstruction: 0.555914, Regularization: 0.017650, Discriminator: 0.043365; Generator: 0.021704,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:51,188 root         INFO     Train Epoch: 59 [512/8000 (6%)]\tTotal Loss: 0.652088\n",
      "Reconstruction: 0.572318, Regularization: 0.014798, Discriminator: 0.043259; Generator: 0.021712,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:51,287 root         INFO     Train Epoch: 59 [1024/8000 (13%)]\tTotal Loss: 0.603526\n",
      "Reconstruction: 0.521438, Regularization: 0.017061, Discriminator: 0.043318; Generator: 0.021709,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:51,386 root         INFO     Train Epoch: 59 [1536/8000 (19%)]\tTotal Loss: 0.708189\n",
      "Reconstruction: 0.618609, Regularization: 0.024461, Discriminator: 0.043418; Generator: 0.021701,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:51,486 root         INFO     Train Epoch: 59 [2048/8000 (26%)]\tTotal Loss: 0.738789\n",
      "Reconstruction: 0.652982, Regularization: 0.020793, Discriminator: 0.043312; Generator: 0.021702,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:51,585 root         INFO     Train Epoch: 59 [2560/8000 (32%)]\tTotal Loss: 0.652472\n",
      "Reconstruction: 0.574834, Regularization: 0.012638, Discriminator: 0.043305; Generator: 0.021695,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:51,684 root         INFO     Train Epoch: 59 [3072/8000 (38%)]\tTotal Loss: 0.757878\n",
      "Reconstruction: 0.667516, Regularization: 0.025312, Discriminator: 0.043330; Generator: 0.021721,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:51,783 root         INFO     Train Epoch: 59 [3584/8000 (45%)]\tTotal Loss: 0.544422\n",
      "Reconstruction: 0.464615, Regularization: 0.014791, Discriminator: 0.043309; Generator: 0.021707,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:51,882 root         INFO     Train Epoch: 59 [4096/8000 (51%)]\tTotal Loss: 0.957403\n",
      "Reconstruction: 0.864253, Regularization: 0.028196, Discriminator: 0.043239; Generator: 0.021715,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:51,981 root         INFO     Train Epoch: 59 [4608/8000 (58%)]\tTotal Loss: 0.890489\n",
      "Reconstruction: 0.798173, Regularization: 0.027251, Discriminator: 0.043351; Generator: 0.021713,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:52,079 root         INFO     Train Epoch: 59 [5120/8000 (64%)]\tTotal Loss: 0.676176\n",
      "Reconstruction: 0.595243, Regularization: 0.016054, Discriminator: 0.043168; Generator: 0.021711,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 22:46:52,178 root         INFO     Train Epoch: 59 [5632/8000 (70%)]\tTotal Loss: 0.516887\n",
      "Reconstruction: 0.441433, Regularization: 0.010483, Discriminator: 0.043254; Generator: 0.021717,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:52,277 root         INFO     Train Epoch: 59 [6144/8000 (77%)]\tTotal Loss: 0.780982\n",
      "Reconstruction: 0.694954, Regularization: 0.020947, Discriminator: 0.043381; Generator: 0.021699,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:52,372 root         INFO     Train Epoch: 59 [6656/8000 (83%)]\tTotal Loss: 0.665882\n",
      "Reconstruction: 0.583249, Regularization: 0.017693, Discriminator: 0.043233; Generator: 0.021706,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 22:46:52,470 root         INFO     Train Epoch: 59 [7168/8000 (90%)]\tTotal Loss: 0.555438\n",
      "Reconstruction: 0.474755, Regularization: 0.015581, Discriminator: 0.043402; Generator: 0.021700,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:52,570 root         INFO     Train Epoch: 59 [7680/8000 (96%)]\tTotal Loss: 0.674741\n",
      "Reconstruction: 0.593896, Regularization: 0.015921, Discriminator: 0.043218; Generator: 0.021708,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 22:46:52,642 root         INFO     ====> Epoch: 59 Average loss: 0.7271\n",
      "2019-04-09 22:46:52,668 root         INFO     Train Epoch: 60 [0/8000 (0%)]\tTotal Loss: 0.980911\n",
      "Reconstruction: 0.885544, Regularization: 0.030301, Discriminator: 0.043350; Generator: 0.021715,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:52,767 root         INFO     Train Epoch: 60 [512/8000 (6%)]\tTotal Loss: 0.589406\n",
      "Reconstruction: 0.510863, Regularization: 0.013578, Discriminator: 0.043253; Generator: 0.021713,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:52,866 root         INFO     Train Epoch: 60 [1024/8000 (13%)]\tTotal Loss: 0.649918\n",
      "Reconstruction: 0.564847, Regularization: 0.020045, Discriminator: 0.043326; Generator: 0.021700,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:52,966 root         INFO     Train Epoch: 60 [1536/8000 (19%)]\tTotal Loss: 0.728074\n",
      "Reconstruction: 0.639504, Regularization: 0.023444, Discriminator: 0.043403; Generator: 0.021724,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:53,065 root         INFO     Train Epoch: 60 [2048/8000 (26%)]\tTotal Loss: 0.718111\n",
      "Reconstruction: 0.633943, Regularization: 0.019064, Discriminator: 0.043403; Generator: 0.021701,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:53,164 root         INFO     Train Epoch: 60 [2560/8000 (32%)]\tTotal Loss: 0.577601\n",
      "Reconstruction: 0.494817, Regularization: 0.017695, Discriminator: 0.043352; Generator: 0.021736,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:53,263 root         INFO     Train Epoch: 60 [3072/8000 (38%)]\tTotal Loss: 0.852398\n",
      "Reconstruction: 0.762707, Regularization: 0.024647, Discriminator: 0.043324; Generator: 0.021721,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:53,363 root         INFO     Train Epoch: 60 [3584/8000 (45%)]\tTotal Loss: 0.579340\n",
      "Reconstruction: 0.496381, Regularization: 0.017815, Discriminator: 0.043430; Generator: 0.021713,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 22:46:53,461 root         INFO     Train Epoch: 60 [4096/8000 (51%)]\tTotal Loss: 0.511074\n",
      "Reconstruction: 0.434616, Regularization: 0.011525, Discriminator: 0.043239; Generator: 0.021695,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 22:46:53,559 root         INFO     Train Epoch: 60 [4608/8000 (58%)]\tTotal Loss: 0.647916\n",
      "Reconstruction: 0.566420, Regularization: 0.016480, Discriminator: 0.043329; Generator: 0.021688,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:53,659 root         INFO     Train Epoch: 60 [5120/8000 (64%)]\tTotal Loss: 0.528650\n",
      "Reconstruction: 0.450013, Regularization: 0.013618, Discriminator: 0.043323; Generator: 0.021695,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:53,758 root         INFO     Train Epoch: 60 [5632/8000 (70%)]\tTotal Loss: 0.757583\n",
      "Reconstruction: 0.671715, Regularization: 0.021007, Discriminator: 0.043154; Generator: 0.021706,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 22:46:53,857 root         INFO     Train Epoch: 60 [6144/8000 (77%)]\tTotal Loss: 0.683252\n",
      "Reconstruction: 0.596835, Regularization: 0.021374, Discriminator: 0.043342; Generator: 0.021701,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:53,956 root         INFO     Train Epoch: 60 [6656/8000 (83%)]\tTotal Loss: 0.885574\n",
      "Reconstruction: 0.795405, Regularization: 0.025179, Discriminator: 0.043284; Generator: 0.021706,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:54,055 root         INFO     Train Epoch: 60 [7168/8000 (90%)]\tTotal Loss: 1.002019\n",
      "Reconstruction: 0.906644, Regularization: 0.030230, Discriminator: 0.043439; Generator: 0.021706,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:54,154 root         INFO     Train Epoch: 60 [7680/8000 (96%)]\tTotal Loss: 0.834320\n",
      "Reconstruction: 0.749449, Regularization: 0.019864, Discriminator: 0.043315; Generator: 0.021691,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:54,228 root         INFO     ====> Epoch: 60 Average loss: 0.7232\n",
      "2019-04-09 22:46:54,254 root         INFO     Train Epoch: 61 [0/8000 (0%)]\tTotal Loss: 0.897724\n",
      "Reconstruction: 0.809395, Regularization: 0.023495, Discriminator: 0.043151; Generator: 0.021683,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:46:54,355 root         INFO     Train Epoch: 61 [512/8000 (6%)]\tTotal Loss: 0.992991\n",
      "Reconstruction: 0.898682, Regularization: 0.029240, Discriminator: 0.043362; Generator: 0.021707,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:54,454 root         INFO     Train Epoch: 61 [1024/8000 (13%)]\tTotal Loss: 0.620638\n",
      "Reconstruction: 0.537990, Regularization: 0.017523, Discriminator: 0.043415; Generator: 0.021709,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:54,553 root         INFO     Train Epoch: 61 [1536/8000 (19%)]\tTotal Loss: 0.766981\n",
      "Reconstruction: 0.679369, Regularization: 0.022481, Discriminator: 0.043425; Generator: 0.021706,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:54,652 root         INFO     Train Epoch: 61 [2048/8000 (26%)]\tTotal Loss: 0.898077\n",
      "Reconstruction: 0.803578, Regularization: 0.029468, Discriminator: 0.043333; Generator: 0.021699,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:54,751 root         INFO     Train Epoch: 61 [2560/8000 (32%)]\tTotal Loss: 0.544557\n",
      "Reconstruction: 0.464779, Regularization: 0.014693, Discriminator: 0.043385; Generator: 0.021700,\n",
      "D(x): 0.498, D(G(z)): 0.499\n",
      "2019-04-09 22:46:54,850 root         INFO     Train Epoch: 61 [3072/8000 (38%)]\tTotal Loss: 0.805899\n",
      "Reconstruction: 0.716433, Regularization: 0.024402, Discriminator: 0.043381; Generator: 0.021683,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:46:54,948 root         INFO     Train Epoch: 61 [3584/8000 (45%)]\tTotal Loss: 0.847683\n",
      "Reconstruction: 0.758973, Regularization: 0.023694, Discriminator: 0.043324; Generator: 0.021693,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:46:55,046 root         INFO     Train Epoch: 61 [4096/8000 (51%)]\tTotal Loss: 0.454073\n",
      "Reconstruction: 0.379225, Regularization: 0.009902, Discriminator: 0.043245; Generator: 0.021700,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 22:46:55,144 root         INFO     Train Epoch: 61 [4608/8000 (58%)]\tTotal Loss: 0.515183\n",
      "Reconstruction: 0.436168, Regularization: 0.013968, Discriminator: 0.043358; Generator: 0.021690,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:46:55,242 root         INFO     Train Epoch: 61 [5120/8000 (64%)]\tTotal Loss: 0.849638\n",
      "Reconstruction: 0.759763, Regularization: 0.025000, Discriminator: 0.043172; Generator: 0.021703,\n",
      "D(x): 0.502, D(G(z)): 0.499\n",
      "2019-04-09 22:46:55,340 root         INFO     Train Epoch: 61 [5632/8000 (70%)]\tTotal Loss: 0.490070\n",
      "Reconstruction: 0.414514, Regularization: 0.010561, Discriminator: 0.043309; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:55,438 root         INFO     Train Epoch: 61 [6144/8000 (77%)]\tTotal Loss: 0.855267\n",
      "Reconstruction: 0.768365, Regularization: 0.022098, Discriminator: 0.043120; Generator: 0.021684,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 22:46:55,537 root         INFO     Train Epoch: 61 [6656/8000 (83%)]\tTotal Loss: 0.758658\n",
      "Reconstruction: 0.670634, Regularization: 0.023089, Discriminator: 0.043239; Generator: 0.021696,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 22:46:55,638 root         INFO     Train Epoch: 61 [7168/8000 (90%)]\tTotal Loss: 0.668073\n",
      "Reconstruction: 0.580636, Regularization: 0.022320, Discriminator: 0.043435; Generator: 0.021682,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:46:55,738 root         INFO     Train Epoch: 61 [7680/8000 (96%)]\tTotal Loss: 0.579244\n",
      "Reconstruction: 0.502796, Regularization: 0.011601, Discriminator: 0.043166; Generator: 0.021681,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:46:55,812 root         INFO     ====> Epoch: 61 Average loss: 0.7184\n",
      "2019-04-09 22:46:55,838 root         INFO     Train Epoch: 62 [0/8000 (0%)]\tTotal Loss: 0.619993\n",
      "Reconstruction: 0.538444, Regularization: 0.016579, Discriminator: 0.043278; Generator: 0.021692,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:55,939 root         INFO     Train Epoch: 62 [512/8000 (6%)]\tTotal Loss: 0.602833\n",
      "Reconstruction: 0.520822, Regularization: 0.016934, Discriminator: 0.043408; Generator: 0.021670,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:46:56,039 root         INFO     Train Epoch: 62 [1024/8000 (13%)]\tTotal Loss: 0.493573\n",
      "Reconstruction: 0.416637, Regularization: 0.012078, Discriminator: 0.043197; Generator: 0.021661,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:46:56,138 root         INFO     Train Epoch: 62 [1536/8000 (19%)]\tTotal Loss: 0.964125\n",
      "Reconstruction: 0.870578, Regularization: 0.028710, Discriminator: 0.043187; Generator: 0.021649,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:46:56,238 root         INFO     Train Epoch: 62 [2048/8000 (26%)]\tTotal Loss: 0.646296\n",
      "Reconstruction: 0.568970, Regularization: 0.012573, Discriminator: 0.043098; Generator: 0.021655,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 22:46:56,336 root         INFO     Train Epoch: 62 [2560/8000 (32%)]\tTotal Loss: 0.782822\n",
      "Reconstruction: 0.695937, Regularization: 0.022015, Discriminator: 0.043213; Generator: 0.021656,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:46:56,432 root         INFO     Train Epoch: 62 [3072/8000 (38%)]\tTotal Loss: 1.012912\n",
      "Reconstruction: 0.915308, Regularization: 0.032568, Discriminator: 0.043357; Generator: 0.021679,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:46:56,528 root         INFO     Train Epoch: 62 [3584/8000 (45%)]\tTotal Loss: 0.580717\n",
      "Reconstruction: 0.499126, Regularization: 0.016692, Discriminator: 0.043210; Generator: 0.021690,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:46:56,623 root         INFO     Train Epoch: 62 [4096/8000 (51%)]\tTotal Loss: 0.937234\n",
      "Reconstruction: 0.843996, Regularization: 0.028408, Discriminator: 0.043167; Generator: 0.021662,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 22:46:56,718 root         INFO     Train Epoch: 62 [4608/8000 (58%)]\tTotal Loss: 0.785761\n",
      "Reconstruction: 0.697973, Regularization: 0.022861, Discriminator: 0.043258; Generator: 0.021669,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:46:56,813 root         INFO     Train Epoch: 62 [5120/8000 (64%)]\tTotal Loss: 0.708567\n",
      "Reconstruction: 0.623113, Regularization: 0.020473, Discriminator: 0.043301; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:56,908 root         INFO     Train Epoch: 62 [5632/8000 (70%)]\tTotal Loss: 0.581062\n",
      "Reconstruction: 0.497929, Regularization: 0.018129, Discriminator: 0.043322; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:57,003 root         INFO     Train Epoch: 62 [6144/8000 (77%)]\tTotal Loss: 0.735217\n",
      "Reconstruction: 0.649643, Regularization: 0.020729, Discriminator: 0.043171; Generator: 0.021674,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:46:57,098 root         INFO     Train Epoch: 62 [6656/8000 (83%)]\tTotal Loss: 0.827424\n",
      "Reconstruction: 0.738046, Regularization: 0.024459, Discriminator: 0.043269; Generator: 0.021650,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:46:57,193 root         INFO     Train Epoch: 62 [7168/8000 (90%)]\tTotal Loss: 0.836754\n",
      "Reconstruction: 0.746157, Regularization: 0.025547, Discriminator: 0.043381; Generator: 0.021669,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:46:57,289 root         INFO     Train Epoch: 62 [7680/8000 (96%)]\tTotal Loss: 0.554909\n",
      "Reconstruction: 0.474043, Regularization: 0.015851, Discriminator: 0.043340; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:57,361 root         INFO     ====> Epoch: 62 Average loss: 0.7157\n",
      "2019-04-09 22:46:57,388 root         INFO     Train Epoch: 63 [0/8000 (0%)]\tTotal Loss: 0.608930\n",
      "Reconstruction: 0.526012, Regularization: 0.017859, Discriminator: 0.043379; Generator: 0.021680,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:46:57,485 root         INFO     Train Epoch: 63 [512/8000 (6%)]\tTotal Loss: 0.547163\n",
      "Reconstruction: 0.467301, Regularization: 0.014886, Discriminator: 0.043307; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:57,583 root         INFO     Train Epoch: 63 [1024/8000 (13%)]\tTotal Loss: 0.540456\n",
      "Reconstruction: 0.466641, Regularization: 0.009133, Discriminator: 0.043014; Generator: 0.021668,\n",
      "D(x): 0.505, D(G(z)): 0.500\n",
      "2019-04-09 22:46:57,681 root         INFO     Train Epoch: 63 [1536/8000 (19%)]\tTotal Loss: 0.872062\n",
      "Reconstruction: 0.779919, Regularization: 0.027093, Discriminator: 0.043383; Generator: 0.021667,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:46:57,779 root         INFO     Train Epoch: 63 [2048/8000 (26%)]\tTotal Loss: 0.698729\n",
      "Reconstruction: 0.614743, Regularization: 0.019115, Discriminator: 0.043221; Generator: 0.021649,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:46:57,882 root         INFO     Train Epoch: 63 [2560/8000 (32%)]\tTotal Loss: 0.846138\n",
      "Reconstruction: 0.754848, Regularization: 0.026306, Discriminator: 0.043315; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:57,983 root         INFO     Train Epoch: 63 [3072/8000 (38%)]\tTotal Loss: 0.819642\n",
      "Reconstruction: 0.730844, Regularization: 0.023975, Discriminator: 0.043150; Generator: 0.021673,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 22:46:58,084 root         INFO     Train Epoch: 63 [3584/8000 (45%)]\tTotal Loss: 0.696913\n",
      "Reconstruction: 0.610008, Regularization: 0.021848, Discriminator: 0.043364; Generator: 0.021693,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-04-09 22:46:58,184 root         INFO     Train Epoch: 63 [4096/8000 (51%)]\tTotal Loss: 0.854436\n",
      "Reconstruction: 0.765023, Regularization: 0.024489, Discriminator: 0.043246; Generator: 0.021679,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:46:58,285 root         INFO     Train Epoch: 63 [4608/8000 (58%)]\tTotal Loss: 0.699879\n",
      "Reconstruction: 0.616678, Regularization: 0.018480, Discriminator: 0.043037; Generator: 0.021684,\n",
      "D(x): 0.504, D(G(z)): 0.500\n",
      "2019-04-09 22:46:58,386 root         INFO     Train Epoch: 63 [5120/8000 (64%)]\tTotal Loss: 0.793111\n",
      "Reconstruction: 0.706318, Regularization: 0.021872, Discriminator: 0.043227; Generator: 0.021694,\n",
      "D(x): 0.501, D(G(z)): 0.499\n",
      "2019-04-09 22:46:58,488 root         INFO     Train Epoch: 63 [5632/8000 (70%)]\tTotal Loss: 0.810251\n",
      "Reconstruction: 0.721834, Regularization: 0.023210, Discriminator: 0.043509; Generator: 0.021698,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 22:46:58,588 root         INFO     Train Epoch: 63 [6144/8000 (77%)]\tTotal Loss: 0.652838\n",
      "Reconstruction: 0.571220, Regularization: 0.016733, Discriminator: 0.043202; Generator: 0.021683,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:46:58,690 root         INFO     Train Epoch: 63 [6656/8000 (83%)]\tTotal Loss: 0.508565\n",
      "Reconstruction: 0.431171, Regularization: 0.012422, Discriminator: 0.043295; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:58,790 root         INFO     Train Epoch: 63 [7168/8000 (90%)]\tTotal Loss: 0.716685\n",
      "Reconstruction: 0.628775, Regularization: 0.022575, Discriminator: 0.043674; Generator: 0.021661,\n",
      "D(x): 0.495, D(G(z)): 0.500\n",
      "2019-04-09 22:46:58,892 root         INFO     Train Epoch: 63 [7680/8000 (96%)]\tTotal Loss: 0.746482\n",
      "Reconstruction: 0.657292, Regularization: 0.024077, Discriminator: 0.043458; Generator: 0.021655,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:46:58,966 root         INFO     ====> Epoch: 63 Average loss: 0.7182\n",
      "2019-04-09 22:46:58,993 root         INFO     Train Epoch: 64 [0/8000 (0%)]\tTotal Loss: 1.135030\n",
      "Reconstruction: 1.034627, Regularization: 0.035563, Discriminator: 0.043200; Generator: 0.021640,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:46:59,093 root         INFO     Train Epoch: 64 [512/8000 (6%)]\tTotal Loss: 0.591505\n",
      "Reconstruction: 0.508900, Regularization: 0.017596, Discriminator: 0.043367; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:59,191 root         INFO     Train Epoch: 64 [1024/8000 (13%)]\tTotal Loss: 0.664828\n",
      "Reconstruction: 0.581734, Regularization: 0.018067, Discriminator: 0.043396; Generator: 0.021631,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:46:59,289 root         INFO     Train Epoch: 64 [1536/8000 (19%)]\tTotal Loss: 0.662357\n",
      "Reconstruction: 0.578387, Regularization: 0.019002, Discriminator: 0.043331; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:59,388 root         INFO     Train Epoch: 64 [2048/8000 (26%)]\tTotal Loss: 0.848548\n",
      "Reconstruction: 0.754627, Regularization: 0.028894, Discriminator: 0.043382; Generator: 0.021644,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:46:59,486 root         INFO     Train Epoch: 64 [2560/8000 (32%)]\tTotal Loss: 1.193494\n",
      "Reconstruction: 1.092820, Regularization: 0.035823, Discriminator: 0.043215; Generator: 0.021635,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:46:59,583 root         INFO     Train Epoch: 64 [3072/8000 (38%)]\tTotal Loss: 0.778512\n",
      "Reconstruction: 0.685556, Regularization: 0.027886, Discriminator: 0.043420; Generator: 0.021650,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:46:59,681 root         INFO     Train Epoch: 64 [3584/8000 (45%)]\tTotal Loss: 0.807087\n",
      "Reconstruction: 0.717458, Regularization: 0.024646, Discriminator: 0.043330; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:46:59,779 root         INFO     Train Epoch: 64 [4096/8000 (51%)]\tTotal Loss: 0.521987\n",
      "Reconstruction: 0.443703, Regularization: 0.013226, Discriminator: 0.043409; Generator: 0.021649,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:46:59,877 root         INFO     Train Epoch: 64 [4608/8000 (58%)]\tTotal Loss: 0.530524\n",
      "Reconstruction: 0.453589, Regularization: 0.012133, Discriminator: 0.043144; Generator: 0.021658,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 22:46:59,975 root         INFO     Train Epoch: 64 [5120/8000 (64%)]\tTotal Loss: 0.628156\n",
      "Reconstruction: 0.545778, Regularization: 0.017495, Discriminator: 0.043216; Generator: 0.021668,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:47:00,073 root         INFO     Train Epoch: 64 [5632/8000 (70%)]\tTotal Loss: 0.488705\n",
      "Reconstruction: 0.411093, Regularization: 0.012564, Discriminator: 0.043365; Generator: 0.021683,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:00,171 root         INFO     Train Epoch: 64 [6144/8000 (77%)]\tTotal Loss: 0.891255\n",
      "Reconstruction: 0.795023, Regularization: 0.031233, Discriminator: 0.043301; Generator: 0.021698,\n",
      "D(x): 0.500, D(G(z)): 0.499\n",
      "2019-04-09 22:47:00,269 root         INFO     Train Epoch: 64 [6656/8000 (83%)]\tTotal Loss: 0.510719\n",
      "Reconstruction: 0.431277, Regularization: 0.014346, Discriminator: 0.043409; Generator: 0.021688,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:47:00,366 root         INFO     Train Epoch: 64 [7168/8000 (90%)]\tTotal Loss: 0.783585\n",
      "Reconstruction: 0.694505, Regularization: 0.024118, Discriminator: 0.043288; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:00,464 root         INFO     Train Epoch: 64 [7680/8000 (96%)]\tTotal Loss: 1.115296\n",
      "Reconstruction: 1.016999, Regularization: 0.033436, Discriminator: 0.043183; Generator: 0.021677,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:47:00,537 root         INFO     ====> Epoch: 64 Average loss: 0.7219\n",
      "2019-04-09 22:47:00,564 root         INFO     Train Epoch: 65 [0/8000 (0%)]\tTotal Loss: 0.880926\n",
      "Reconstruction: 0.784919, Regularization: 0.030765, Discriminator: 0.043571; Generator: 0.021671,\n",
      "D(x): 0.496, D(G(z)): 0.500\n",
      "2019-04-09 22:47:00,662 root         INFO     Train Epoch: 65 [512/8000 (6%)]\tTotal Loss: 0.792820\n",
      "Reconstruction: 0.701906, Regularization: 0.025719, Discriminator: 0.043501; Generator: 0.021694,\n",
      "D(x): 0.497, D(G(z)): 0.499\n",
      "2019-04-09 22:47:00,760 root         INFO     Train Epoch: 65 [1024/8000 (13%)]\tTotal Loss: 0.589819\n",
      "Reconstruction: 0.511511, Regularization: 0.013291, Discriminator: 0.043329; Generator: 0.021688,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:00,858 root         INFO     Train Epoch: 65 [1536/8000 (19%)]\tTotal Loss: 0.863514\n",
      "Reconstruction: 0.766475, Regularization: 0.031857, Discriminator: 0.043515; Generator: 0.021668,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 22:47:00,956 root         INFO     Train Epoch: 65 [2048/8000 (26%)]\tTotal Loss: 0.656413\n",
      "Reconstruction: 0.573930, Regularization: 0.017507, Discriminator: 0.043305; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:01,054 root         INFO     Train Epoch: 65 [2560/8000 (32%)]\tTotal Loss: 0.526637\n",
      "Reconstruction: 0.445513, Regularization: 0.016029, Discriminator: 0.043427; Generator: 0.021667,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:47:01,151 root         INFO     Train Epoch: 65 [3072/8000 (38%)]\tTotal Loss: 0.704302\n",
      "Reconstruction: 0.614834, Regularization: 0.024320, Discriminator: 0.043503; Generator: 0.021645,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 22:47:01,249 root         INFO     Train Epoch: 65 [3584/8000 (45%)]\tTotal Loss: 0.828764\n",
      "Reconstruction: 0.737480, Regularization: 0.026328, Discriminator: 0.043326; Generator: 0.021631,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:01,345 root         INFO     Train Epoch: 65 [4096/8000 (51%)]\tTotal Loss: 0.923720\n",
      "Reconstruction: 0.831198, Regularization: 0.027459, Discriminator: 0.043409; Generator: 0.021654,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:01,442 root         INFO     Train Epoch: 65 [4608/8000 (58%)]\tTotal Loss: 0.632032\n",
      "Reconstruction: 0.545281, Regularization: 0.021703, Discriminator: 0.043381; Generator: 0.021668,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:01,538 root         INFO     Train Epoch: 65 [5120/8000 (64%)]\tTotal Loss: 0.585135\n",
      "Reconstruction: 0.501634, Regularization: 0.018425, Discriminator: 0.043409; Generator: 0.021667,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:01,636 root         INFO     Train Epoch: 65 [5632/8000 (70%)]\tTotal Loss: 0.606327\n",
      "Reconstruction: 0.522748, Regularization: 0.018513, Discriminator: 0.043381; Generator: 0.021686,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:01,732 root         INFO     Train Epoch: 65 [6144/8000 (77%)]\tTotal Loss: 0.770459\n",
      "Reconstruction: 0.681291, Regularization: 0.024078, Discriminator: 0.043431; Generator: 0.021658,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:47:01,830 root         INFO     Train Epoch: 65 [6656/8000 (83%)]\tTotal Loss: 0.734498\n",
      "Reconstruction: 0.645804, Regularization: 0.023749, Discriminator: 0.043287; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:01,927 root         INFO     Train Epoch: 65 [7168/8000 (90%)]\tTotal Loss: 0.798397\n",
      "Reconstruction: 0.707548, Regularization: 0.025880, Discriminator: 0.043303; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:02,024 root         INFO     Train Epoch: 65 [7680/8000 (96%)]\tTotal Loss: 0.618669\n",
      "Reconstruction: 0.535646, Regularization: 0.018155, Discriminator: 0.043210; Generator: 0.021658,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:47:02,098 root         INFO     ====> Epoch: 65 Average loss: 0.7235\n",
      "2019-04-09 22:47:02,124 root         INFO     Train Epoch: 66 [0/8000 (0%)]\tTotal Loss: 0.892071\n",
      "Reconstruction: 0.798404, Regularization: 0.028751, Discriminator: 0.043260; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:02,223 root         INFO     Train Epoch: 66 [512/8000 (6%)]\tTotal Loss: 0.930627\n",
      "Reconstruction: 0.829874, Regularization: 0.035570, Discriminator: 0.043556; Generator: 0.021628,\n",
      "D(x): 0.497, D(G(z)): 0.501\n",
      "2019-04-09 22:47:02,320 root         INFO     Train Epoch: 66 [1024/8000 (13%)]\tTotal Loss: 0.671110\n",
      "Reconstruction: 0.584569, Regularization: 0.021512, Discriminator: 0.043377; Generator: 0.021651,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:02,418 root         INFO     Train Epoch: 66 [1536/8000 (19%)]\tTotal Loss: 0.709525\n",
      "Reconstruction: 0.622360, Regularization: 0.022103, Discriminator: 0.043408; Generator: 0.021654,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:02,516 root         INFO     Train Epoch: 66 [2048/8000 (26%)]\tTotal Loss: 0.732485\n",
      "Reconstruction: 0.644708, Regularization: 0.022894, Discriminator: 0.043229; Generator: 0.021654,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:47:02,611 root         INFO     Train Epoch: 66 [2560/8000 (32%)]\tTotal Loss: 0.778395\n",
      "Reconstruction: 0.686376, Regularization: 0.027024, Discriminator: 0.043327; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:02,709 root         INFO     Train Epoch: 66 [3072/8000 (38%)]\tTotal Loss: 0.846311\n",
      "Reconstruction: 0.751769, Regularization: 0.029444, Discriminator: 0.043432; Generator: 0.021666,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:47:02,807 root         INFO     Train Epoch: 66 [3584/8000 (45%)]\tTotal Loss: 0.814217\n",
      "Reconstruction: 0.724664, Regularization: 0.024685, Discriminator: 0.043241; Generator: 0.021627,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 22:47:02,904 root         INFO     Train Epoch: 66 [4096/8000 (51%)]\tTotal Loss: 0.738032\n",
      "Reconstruction: 0.647227, Regularization: 0.025752, Discriminator: 0.043410; Generator: 0.021642,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:03,002 root         INFO     Train Epoch: 66 [4608/8000 (58%)]\tTotal Loss: 0.577383\n",
      "Reconstruction: 0.493308, Regularization: 0.019098, Discriminator: 0.043337; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:03,100 root         INFO     Train Epoch: 66 [5120/8000 (64%)]\tTotal Loss: 0.781044\n",
      "Reconstruction: 0.690555, Regularization: 0.025471, Discriminator: 0.043367; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:03,198 root         INFO     Train Epoch: 66 [5632/8000 (70%)]\tTotal Loss: 0.766405\n",
      "Reconstruction: 0.674570, Regularization: 0.026736, Discriminator: 0.043456; Generator: 0.021642,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:47:03,295 root         INFO     Train Epoch: 66 [6144/8000 (77%)]\tTotal Loss: 0.948780\n",
      "Reconstruction: 0.857893, Regularization: 0.026041, Discriminator: 0.043201; Generator: 0.021646,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:47:03,393 root         INFO     Train Epoch: 66 [6656/8000 (83%)]\tTotal Loss: 0.625009\n",
      "Reconstruction: 0.541445, Regularization: 0.018650, Discriminator: 0.043270; Generator: 0.021643,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:03,490 root         INFO     Train Epoch: 66 [7168/8000 (90%)]\tTotal Loss: 0.664404\n",
      "Reconstruction: 0.576629, Regularization: 0.022729, Discriminator: 0.043397; Generator: 0.021649,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:03,587 root         INFO     Train Epoch: 66 [7680/8000 (96%)]\tTotal Loss: 0.702796\n",
      "Reconstruction: 0.619774, Regularization: 0.018236, Discriminator: 0.043148; Generator: 0.021638,\n",
      "D(x): 0.503, D(G(z)): 0.500\n",
      "2019-04-09 22:47:03,660 root         INFO     ====> Epoch: 66 Average loss: 0.7217\n",
      "2019-04-09 22:47:03,686 root         INFO     Train Epoch: 67 [0/8000 (0%)]\tTotal Loss: 0.841734\n",
      "Reconstruction: 0.747785, Regularization: 0.028939, Discriminator: 0.043363; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:03,785 root         INFO     Train Epoch: 67 [512/8000 (6%)]\tTotal Loss: 0.852297\n",
      "Reconstruction: 0.761444, Regularization: 0.025997, Discriminator: 0.043199; Generator: 0.021658,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:47:03,883 root         INFO     Train Epoch: 67 [1024/8000 (13%)]\tTotal Loss: 0.818848\n",
      "Reconstruction: 0.723775, Regularization: 0.030026, Discriminator: 0.043397; Generator: 0.021651,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:03,982 root         INFO     Train Epoch: 67 [1536/8000 (19%)]\tTotal Loss: 0.705279\n",
      "Reconstruction: 0.616217, Regularization: 0.023972, Discriminator: 0.043448; Generator: 0.021642,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:47:04,080 root         INFO     Train Epoch: 67 [2048/8000 (26%)]\tTotal Loss: 0.797653\n",
      "Reconstruction: 0.704898, Regularization: 0.027728, Discriminator: 0.043376; Generator: 0.021651,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:04,178 root         INFO     Train Epoch: 67 [2560/8000 (32%)]\tTotal Loss: 0.559228\n",
      "Reconstruction: 0.476932, Regularization: 0.017324, Discriminator: 0.043344; Generator: 0.021627,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 22:47:04,276 root         INFO     Train Epoch: 67 [3072/8000 (38%)]\tTotal Loss: 0.830840\n",
      "Reconstruction: 0.737383, Regularization: 0.028518, Discriminator: 0.043301; Generator: 0.021638,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:04,374 root         INFO     Train Epoch: 67 [3584/8000 (45%)]\tTotal Loss: 0.857200\n",
      "Reconstruction: 0.763939, Regularization: 0.028309, Discriminator: 0.043313; Generator: 0.021638,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:04,472 root         INFO     Train Epoch: 67 [4096/8000 (51%)]\tTotal Loss: 1.012189\n",
      "Reconstruction: 0.915997, Regularization: 0.031239, Discriminator: 0.043304; Generator: 0.021647,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:04,570 root         INFO     Train Epoch: 67 [4608/8000 (58%)]\tTotal Loss: 0.476777\n",
      "Reconstruction: 0.398252, Regularization: 0.013508, Discriminator: 0.043369; Generator: 0.021648,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:04,669 root         INFO     Train Epoch: 67 [5120/8000 (64%)]\tTotal Loss: 0.572114\n",
      "Reconstruction: 0.491256, Regularization: 0.015863, Discriminator: 0.043341; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:04,767 root         INFO     Train Epoch: 67 [5632/8000 (70%)]\tTotal Loss: 0.719871\n",
      "Reconstruction: 0.628137, Regularization: 0.026579, Discriminator: 0.043494; Generator: 0.021661,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 22:47:04,865 root         INFO     Train Epoch: 67 [6144/8000 (77%)]\tTotal Loss: 0.850244\n",
      "Reconstruction: 0.754277, Regularization: 0.030901, Discriminator: 0.043415; Generator: 0.021651,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:04,963 root         INFO     Train Epoch: 67 [6656/8000 (83%)]\tTotal Loss: 0.698599\n",
      "Reconstruction: 0.606627, Regularization: 0.026803, Discriminator: 0.043519; Generator: 0.021649,\n",
      "D(x): 0.497, D(G(z)): 0.500\n",
      "2019-04-09 22:47:05,063 root         INFO     Train Epoch: 67 [7168/8000 (90%)]\tTotal Loss: 0.642165\n",
      "Reconstruction: 0.556604, Regularization: 0.020658, Discriminator: 0.043269; Generator: 0.021634,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:05,163 root         INFO     Train Epoch: 67 [7680/8000 (96%)]\tTotal Loss: 0.925626\n",
      "Reconstruction: 0.827668, Regularization: 0.032910, Discriminator: 0.043411; Generator: 0.021636,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:05,237 root         INFO     ====> Epoch: 67 Average loss: 0.7190\n",
      "2019-04-09 22:47:05,264 root         INFO     Train Epoch: 68 [0/8000 (0%)]\tTotal Loss: 0.794382\n",
      "Reconstruction: 0.703528, Regularization: 0.025850, Discriminator: 0.043373; Generator: 0.021631,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:05,362 root         INFO     Train Epoch: 68 [512/8000 (6%)]\tTotal Loss: 0.427278\n",
      "Reconstruction: 0.349431, Regularization: 0.012846, Discriminator: 0.043375; Generator: 0.021627,\n",
      "D(x): 0.500, D(G(z)): 0.501\n",
      "2019-04-09 22:47:05,461 root         INFO     Train Epoch: 68 [1024/8000 (13%)]\tTotal Loss: 0.651824\n",
      "Reconstruction: 0.568973, Regularization: 0.018003, Discriminator: 0.043217; Generator: 0.021631,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:47:05,560 root         INFO     Train Epoch: 68 [1536/8000 (19%)]\tTotal Loss: 0.573944\n",
      "Reconstruction: 0.491176, Regularization: 0.017908, Discriminator: 0.043228; Generator: 0.021633,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:47:05,659 root         INFO     Train Epoch: 68 [2048/8000 (26%)]\tTotal Loss: 0.785839\n",
      "Reconstruction: 0.697009, Regularization: 0.023982, Discriminator: 0.043227; Generator: 0.021621,\n",
      "D(x): 0.502, D(G(z)): 0.501\n",
      "2019-04-09 22:47:05,758 root         INFO     Train Epoch: 68 [2560/8000 (32%)]\tTotal Loss: 0.562101\n",
      "Reconstruction: 0.480710, Regularization: 0.016443, Discriminator: 0.043314; Generator: 0.021634,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:05,857 root         INFO     Train Epoch: 68 [3072/8000 (38%)]\tTotal Loss: 0.731399\n",
      "Reconstruction: 0.642607, Regularization: 0.023858, Discriminator: 0.043290; Generator: 0.021644,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:05,956 root         INFO     Train Epoch: 68 [3584/8000 (45%)]\tTotal Loss: 0.517705\n",
      "Reconstruction: 0.435441, Regularization: 0.017272, Discriminator: 0.043350; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:06,056 root         INFO     Train Epoch: 68 [4096/8000 (51%)]\tTotal Loss: 0.568397\n",
      "Reconstruction: 0.486004, Regularization: 0.017476, Discriminator: 0.043273; Generator: 0.021644,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:06,151 root         INFO     Train Epoch: 68 [4608/8000 (58%)]\tTotal Loss: 0.850209\n",
      "Reconstruction: 0.753686, Regularization: 0.031474, Discriminator: 0.043394; Generator: 0.021655,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:06,245 root         INFO     Train Epoch: 68 [5120/8000 (64%)]\tTotal Loss: 0.834813\n",
      "Reconstruction: 0.740844, Regularization: 0.029001, Discriminator: 0.043314; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:06,339 root         INFO     Train Epoch: 68 [5632/8000 (70%)]\tTotal Loss: 0.660129\n",
      "Reconstruction: 0.572432, Regularization: 0.022609, Discriminator: 0.043440; Generator: 0.021648,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:47:06,434 root         INFO     Train Epoch: 68 [6144/8000 (77%)]\tTotal Loss: 0.841384\n",
      "Reconstruction: 0.750234, Regularization: 0.026210, Discriminator: 0.043284; Generator: 0.021655,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:06,527 root         INFO     Train Epoch: 68 [6656/8000 (83%)]\tTotal Loss: 0.693220\n",
      "Reconstruction: 0.604225, Regularization: 0.023965, Discriminator: 0.043378; Generator: 0.021653,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:06,623 root         INFO     Train Epoch: 68 [7168/8000 (90%)]\tTotal Loss: 0.674214\n",
      "Reconstruction: 0.586977, Regularization: 0.022314, Discriminator: 0.043273; Generator: 0.021651,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:06,720 root         INFO     Train Epoch: 68 [7680/8000 (96%)]\tTotal Loss: 0.638428\n",
      "Reconstruction: 0.553347, Regularization: 0.020146, Discriminator: 0.043287; Generator: 0.021647,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:06,792 root         INFO     ====> Epoch: 68 Average loss: 0.7205\n",
      "2019-04-09 22:47:06,819 root         INFO     Train Epoch: 69 [0/8000 (0%)]\tTotal Loss: 0.467858\n",
      "Reconstruction: 0.388657, Regularization: 0.014216, Discriminator: 0.043338; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:06,916 root         INFO     Train Epoch: 69 [512/8000 (6%)]\tTotal Loss: 0.547040\n",
      "Reconstruction: 0.464071, Regularization: 0.018013, Discriminator: 0.043320; Generator: 0.021635,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:07,013 root         INFO     Train Epoch: 69 [1024/8000 (13%)]\tTotal Loss: 0.925215\n",
      "Reconstruction: 0.828218, Regularization: 0.032044, Discriminator: 0.043317; Generator: 0.021637,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:07,110 root         INFO     Train Epoch: 69 [1536/8000 (19%)]\tTotal Loss: 0.735419\n",
      "Reconstruction: 0.647679, Regularization: 0.022850, Discriminator: 0.043249; Generator: 0.021641,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:47:07,206 root         INFO     Train Epoch: 69 [2048/8000 (26%)]\tTotal Loss: 0.694779\n",
      "Reconstruction: 0.608173, Regularization: 0.021621, Discriminator: 0.043342; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:07,303 root         INFO     Train Epoch: 69 [2560/8000 (32%)]\tTotal Loss: 0.525931\n",
      "Reconstruction: 0.444793, Regularization: 0.016152, Discriminator: 0.043343; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:07,400 root         INFO     Train Epoch: 69 [3072/8000 (38%)]\tTotal Loss: 0.724605\n",
      "Reconstruction: 0.633550, Regularization: 0.025981, Discriminator: 0.043429; Generator: 0.021646,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:07,496 root         INFO     Train Epoch: 69 [3584/8000 (45%)]\tTotal Loss: 0.791611\n",
      "Reconstruction: 0.697215, Regularization: 0.029305, Discriminator: 0.043455; Generator: 0.021636,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:47:07,597 root         INFO     Train Epoch: 69 [4096/8000 (51%)]\tTotal Loss: 0.623134\n",
      "Reconstruction: 0.535565, Regularization: 0.022511, Discriminator: 0.043413; Generator: 0.021645,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:07,697 root         INFO     Train Epoch: 69 [4608/8000 (58%)]\tTotal Loss: 0.750154\n",
      "Reconstruction: 0.663678, Regularization: 0.021593, Discriminator: 0.043229; Generator: 0.021655,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:47:07,799 root         INFO     Train Epoch: 69 [5120/8000 (64%)]\tTotal Loss: 0.720596\n",
      "Reconstruction: 0.627672, Regularization: 0.027837, Discriminator: 0.043433; Generator: 0.021654,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:47:07,899 root         INFO     Train Epoch: 69 [5632/8000 (70%)]\tTotal Loss: 0.741774\n",
      "Reconstruction: 0.650324, Regularization: 0.026470, Discriminator: 0.043330; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:07,997 root         INFO     Train Epoch: 69 [6144/8000 (77%)]\tTotal Loss: 0.729619\n",
      "Reconstruction: 0.638230, Regularization: 0.026329, Discriminator: 0.043406; Generator: 0.021654,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:08,095 root         INFO     Train Epoch: 69 [6656/8000 (83%)]\tTotal Loss: 0.517830\n",
      "Reconstruction: 0.437597, Regularization: 0.015271, Discriminator: 0.043310; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:08,193 root         INFO     Train Epoch: 69 [7168/8000 (90%)]\tTotal Loss: 0.953226\n",
      "Reconstruction: 0.855990, Regularization: 0.032283, Discriminator: 0.043306; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:08,290 root         INFO     Train Epoch: 69 [7680/8000 (96%)]\tTotal Loss: 0.723103\n",
      "Reconstruction: 0.635024, Regularization: 0.023073, Discriminator: 0.043345; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:08,363 root         INFO     ====> Epoch: 69 Average loss: 0.7236\n",
      "2019-04-09 22:47:08,389 root         INFO     Train Epoch: 70 [0/8000 (0%)]\tTotal Loss: 0.762386\n",
      "Reconstruction: 0.671559, Regularization: 0.025841, Discriminator: 0.043335; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:08,490 root         INFO     Train Epoch: 70 [512/8000 (6%)]\tTotal Loss: 0.559348\n",
      "Reconstruction: 0.478273, Regularization: 0.016127, Discriminator: 0.043299; Generator: 0.021650,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:08,589 root         INFO     Train Epoch: 70 [1024/8000 (13%)]\tTotal Loss: 0.798619\n",
      "Reconstruction: 0.707942, Regularization: 0.025811, Discriminator: 0.043224; Generator: 0.021641,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:47:08,686 root         INFO     Train Epoch: 70 [1536/8000 (19%)]\tTotal Loss: 0.933881\n",
      "Reconstruction: 0.835690, Regularization: 0.033215, Discriminator: 0.043331; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:08,784 root         INFO     Train Epoch: 70 [2048/8000 (26%)]\tTotal Loss: 0.628118\n",
      "Reconstruction: 0.544721, Regularization: 0.018476, Discriminator: 0.043276; Generator: 0.021645,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:08,881 root         INFO     Train Epoch: 70 [2560/8000 (32%)]\tTotal Loss: 0.576326\n",
      "Reconstruction: 0.490319, Regularization: 0.021014, Discriminator: 0.043344; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:08,978 root         INFO     Train Epoch: 70 [3072/8000 (38%)]\tTotal Loss: 0.949925\n",
      "Reconstruction: 0.849371, Regularization: 0.035599, Discriminator: 0.043306; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:09,076 root         INFO     Train Epoch: 70 [3584/8000 (45%)]\tTotal Loss: 0.742223\n",
      "Reconstruction: 0.652956, Regularization: 0.024338, Discriminator: 0.043293; Generator: 0.021635,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:09,173 root         INFO     Train Epoch: 70 [4096/8000 (51%)]\tTotal Loss: 0.678248\n",
      "Reconstruction: 0.589948, Regularization: 0.023294, Discriminator: 0.043355; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:09,270 root         INFO     Train Epoch: 70 [4608/8000 (58%)]\tTotal Loss: 0.646123\n",
      "Reconstruction: 0.556185, Regularization: 0.024972, Discriminator: 0.043326; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:09,368 root         INFO     Train Epoch: 70 [5120/8000 (64%)]\tTotal Loss: 0.599955\n",
      "Reconstruction: 0.518111, Regularization: 0.016909, Discriminator: 0.043298; Generator: 0.021637,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:09,465 root         INFO     Train Epoch: 70 [5632/8000 (70%)]\tTotal Loss: 0.535930\n",
      "Reconstruction: 0.452276, Regularization: 0.018653, Discriminator: 0.043357; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:09,562 root         INFO     Train Epoch: 70 [6144/8000 (77%)]\tTotal Loss: 0.622399\n",
      "Reconstruction: 0.537595, Regularization: 0.019862, Discriminator: 0.043297; Generator: 0.021644,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:09,660 root         INFO     Train Epoch: 70 [6656/8000 (83%)]\tTotal Loss: 0.878203\n",
      "Reconstruction: 0.781061, Regularization: 0.032178, Discriminator: 0.043311; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:09,757 root         INFO     Train Epoch: 70 [7168/8000 (90%)]\tTotal Loss: 0.770913\n",
      "Reconstruction: 0.676776, Regularization: 0.029128, Discriminator: 0.043349; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:09,854 root         INFO     Train Epoch: 70 [7680/8000 (96%)]\tTotal Loss: 0.738899\n",
      "Reconstruction: 0.649360, Regularization: 0.024590, Discriminator: 0.043291; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:09,928 root         INFO     ====> Epoch: 70 Average loss: 0.7238\n",
      "2019-04-09 22:47:09,954 root         INFO     Train Epoch: 71 [0/8000 (0%)]\tTotal Loss: 0.717554\n",
      "Reconstruction: 0.625427, Regularization: 0.027135, Discriminator: 0.043333; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:10,054 root         INFO     Train Epoch: 71 [512/8000 (6%)]\tTotal Loss: 0.926380\n",
      "Reconstruction: 0.824185, Regularization: 0.037177, Discriminator: 0.043370; Generator: 0.021648,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:10,154 root         INFO     Train Epoch: 71 [1024/8000 (13%)]\tTotal Loss: 0.935097\n",
      "Reconstruction: 0.835966, Regularization: 0.034114, Discriminator: 0.043376; Generator: 0.021642,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:10,254 root         INFO     Train Epoch: 71 [1536/8000 (19%)]\tTotal Loss: 0.578177\n",
      "Reconstruction: 0.497268, Regularization: 0.015972, Discriminator: 0.043280; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:10,355 root         INFO     Train Epoch: 71 [2048/8000 (26%)]\tTotal Loss: 0.629352\n",
      "Reconstruction: 0.541813, Regularization: 0.022542, Discriminator: 0.043349; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:10,455 root         INFO     Train Epoch: 71 [2560/8000 (32%)]\tTotal Loss: 0.919072\n",
      "Reconstruction: 0.816399, Regularization: 0.037669, Discriminator: 0.043363; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:10,555 root         INFO     Train Epoch: 71 [3072/8000 (38%)]\tTotal Loss: 0.525475\n",
      "Reconstruction: 0.443418, Regularization: 0.017050, Discriminator: 0.043365; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:10,655 root         INFO     Train Epoch: 71 [3584/8000 (45%)]\tTotal Loss: 0.586421\n",
      "Reconstruction: 0.502267, Regularization: 0.019176, Discriminator: 0.043336; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:10,756 root         INFO     Train Epoch: 71 [4096/8000 (51%)]\tTotal Loss: 0.670104\n",
      "Reconstruction: 0.583082, Regularization: 0.022063, Discriminator: 0.043314; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:10,856 root         INFO     Train Epoch: 71 [4608/8000 (58%)]\tTotal Loss: 0.556609\n",
      "Reconstruction: 0.473155, Regularization: 0.018483, Discriminator: 0.043325; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:10,956 root         INFO     Train Epoch: 71 [5120/8000 (64%)]\tTotal Loss: 0.558261\n",
      "Reconstruction: 0.476621, Regularization: 0.016688, Discriminator: 0.043296; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:11,057 root         INFO     Train Epoch: 71 [5632/8000 (70%)]\tTotal Loss: 0.631954\n",
      "Reconstruction: 0.545283, Regularization: 0.021677, Discriminator: 0.043339; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:11,157 root         INFO     Train Epoch: 71 [6144/8000 (77%)]\tTotal Loss: 0.543375\n",
      "Reconstruction: 0.458819, Regularization: 0.019554, Discriminator: 0.043349; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:11,257 root         INFO     Train Epoch: 71 [6656/8000 (83%)]\tTotal Loss: 0.600692\n",
      "Reconstruction: 0.515557, Regularization: 0.020160, Discriminator: 0.043320; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:11,356 root         INFO     Train Epoch: 71 [7168/8000 (90%)]\tTotal Loss: 0.695294\n",
      "Reconstruction: 0.605813, Regularization: 0.024522, Discriminator: 0.043312; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:11,457 root         INFO     Train Epoch: 71 [7680/8000 (96%)]\tTotal Loss: 0.573622\n",
      "Reconstruction: 0.489618, Regularization: 0.019032, Discriminator: 0.043323; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:11,531 root         INFO     ====> Epoch: 71 Average loss: 0.7204\n",
      "2019-04-09 22:47:11,557 root         INFO     Train Epoch: 72 [0/8000 (0%)]\tTotal Loss: 0.739280\n",
      "Reconstruction: 0.647765, Regularization: 0.026531, Discriminator: 0.043332; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:11,658 root         INFO     Train Epoch: 72 [512/8000 (6%)]\tTotal Loss: 0.761885\n",
      "Reconstruction: 0.666247, Regularization: 0.030634, Discriminator: 0.043347; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:11,758 root         INFO     Train Epoch: 72 [1024/8000 (13%)]\tTotal Loss: 0.500500\n",
      "Reconstruction: 0.417811, Regularization: 0.017692, Discriminator: 0.043346; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:11,858 root         INFO     Train Epoch: 72 [1536/8000 (19%)]\tTotal Loss: 0.674915\n",
      "Reconstruction: 0.592157, Regularization: 0.017820, Discriminator: 0.043286; Generator: 0.021652,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:11,958 root         INFO     Train Epoch: 72 [2048/8000 (26%)]\tTotal Loss: 0.728992\n",
      "Reconstruction: 0.637859, Regularization: 0.026137, Discriminator: 0.043342; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:12,058 root         INFO     Train Epoch: 72 [2560/8000 (32%)]\tTotal Loss: 0.755550\n",
      "Reconstruction: 0.667302, Regularization: 0.023339, Discriminator: 0.043254; Generator: 0.021655,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:12,158 root         INFO     Train Epoch: 72 [3072/8000 (38%)]\tTotal Loss: 0.731375\n",
      "Reconstruction: 0.641869, Regularization: 0.024555, Discriminator: 0.043296; Generator: 0.021655,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:12,258 root         INFO     Train Epoch: 72 [3584/8000 (45%)]\tTotal Loss: 0.784820\n",
      "Reconstruction: 0.691492, Regularization: 0.028332, Discriminator: 0.043331; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:12,358 root         INFO     Train Epoch: 72 [4096/8000 (51%)]\tTotal Loss: 0.673386\n",
      "Reconstruction: 0.585302, Regularization: 0.023045, Discriminator: 0.043387; Generator: 0.021652,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:12,457 root         INFO     Train Epoch: 72 [4608/8000 (58%)]\tTotal Loss: 0.714176\n",
      "Reconstruction: 0.624439, Regularization: 0.024748, Discriminator: 0.043337; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:12,557 root         INFO     Train Epoch: 72 [5120/8000 (64%)]\tTotal Loss: 0.752275\n",
      "Reconstruction: 0.656246, Regularization: 0.031073, Discriminator: 0.043315; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:12,657 root         INFO     Train Epoch: 72 [5632/8000 (70%)]\tTotal Loss: 0.890413\n",
      "Reconstruction: 0.789230, Regularization: 0.036154, Discriminator: 0.043392; Generator: 0.021638,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:12,756 root         INFO     Train Epoch: 72 [6144/8000 (77%)]\tTotal Loss: 0.464871\n",
      "Reconstruction: 0.383715, Regularization: 0.016185, Discriminator: 0.043328; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:12,854 root         INFO     Train Epoch: 72 [6656/8000 (83%)]\tTotal Loss: 0.935978\n",
      "Reconstruction: 0.839837, Regularization: 0.031179, Discriminator: 0.043313; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:12,951 root         INFO     Train Epoch: 72 [7168/8000 (90%)]\tTotal Loss: 0.988121\n",
      "Reconstruction: 0.883748, Regularization: 0.039380, Discriminator: 0.043342; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:13,050 root         INFO     Train Epoch: 72 [7680/8000 (96%)]\tTotal Loss: 0.470357\n",
      "Reconstruction: 0.392256, Regularization: 0.013128, Discriminator: 0.043324; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:13,124 root         INFO     ====> Epoch: 72 Average loss: 0.7223\n",
      "2019-04-09 22:47:13,151 root         INFO     Train Epoch: 73 [0/8000 (0%)]\tTotal Loss: 0.614142\n",
      "Reconstruction: 0.525366, Regularization: 0.023796, Discriminator: 0.043332; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:13,251 root         INFO     Train Epoch: 73 [512/8000 (6%)]\tTotal Loss: 0.885294\n",
      "Reconstruction: 0.786669, Regularization: 0.033645, Discriminator: 0.043333; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:13,350 root         INFO     Train Epoch: 73 [1024/8000 (13%)]\tTotal Loss: 0.902007\n",
      "Reconstruction: 0.801151, Regularization: 0.035890, Discriminator: 0.043319; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:13,448 root         INFO     Train Epoch: 73 [1536/8000 (19%)]\tTotal Loss: 0.551652\n",
      "Reconstruction: 0.464734, Regularization: 0.021943, Discriminator: 0.043322; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:13,546 root         INFO     Train Epoch: 73 [2048/8000 (26%)]\tTotal Loss: 0.512081\n",
      "Reconstruction: 0.428438, Regularization: 0.018678, Discriminator: 0.043314; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:13,644 root         INFO     Train Epoch: 73 [2560/8000 (32%)]\tTotal Loss: 0.730218\n",
      "Reconstruction: 0.636267, Regularization: 0.028976, Discriminator: 0.043322; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:13,743 root         INFO     Train Epoch: 73 [3072/8000 (38%)]\tTotal Loss: 0.551379\n",
      "Reconstruction: 0.469943, Regularization: 0.016454, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:13,842 root         INFO     Train Epoch: 73 [3584/8000 (45%)]\tTotal Loss: 0.777486\n",
      "Reconstruction: 0.685180, Regularization: 0.027318, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:13,941 root         INFO     Train Epoch: 73 [4096/8000 (51%)]\tTotal Loss: 0.626938\n",
      "Reconstruction: 0.539420, Regularization: 0.022546, Discriminator: 0.043313; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:14,040 root         INFO     Train Epoch: 73 [4608/8000 (58%)]\tTotal Loss: 0.698601\n",
      "Reconstruction: 0.605769, Regularization: 0.027854, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:14,139 root         INFO     Train Epoch: 73 [5120/8000 (64%)]\tTotal Loss: 0.659889\n",
      "Reconstruction: 0.571205, Regularization: 0.023696, Discriminator: 0.043335; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:14,239 root         INFO     Train Epoch: 73 [5632/8000 (70%)]\tTotal Loss: 0.661984\n",
      "Reconstruction: 0.572926, Regularization: 0.024085, Discriminator: 0.043314; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:14,338 root         INFO     Train Epoch: 73 [6144/8000 (77%)]\tTotal Loss: 0.548240\n",
      "Reconstruction: 0.464222, Regularization: 0.019032, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:14,437 root         INFO     Train Epoch: 73 [6656/8000 (83%)]\tTotal Loss: 0.813504\n",
      "Reconstruction: 0.721943, Regularization: 0.026568, Discriminator: 0.043339; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:14,535 root         INFO     Train Epoch: 73 [7168/8000 (90%)]\tTotal Loss: 0.727937\n",
      "Reconstruction: 0.636570, Regularization: 0.026405, Discriminator: 0.043308; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:14,634 root         INFO     Train Epoch: 73 [7680/8000 (96%)]\tTotal Loss: 0.659562\n",
      "Reconstruction: 0.571554, Regularization: 0.023037, Discriminator: 0.043318; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:14,706 root         INFO     ====> Epoch: 73 Average loss: 0.7234\n",
      "2019-04-09 22:47:14,732 root         INFO     Train Epoch: 74 [0/8000 (0%)]\tTotal Loss: 0.697105\n",
      "Reconstruction: 0.610362, Regularization: 0.021758, Discriminator: 0.043331; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:14,832 root         INFO     Train Epoch: 74 [512/8000 (6%)]\tTotal Loss: 0.740034\n",
      "Reconstruction: 0.643969, Regularization: 0.031103, Discriminator: 0.043302; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:14,931 root         INFO     Train Epoch: 74 [1024/8000 (13%)]\tTotal Loss: 0.787560\n",
      "Reconstruction: 0.696793, Regularization: 0.025787, Discriminator: 0.043324; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:15,029 root         INFO     Train Epoch: 74 [1536/8000 (19%)]\tTotal Loss: 0.564096\n",
      "Reconstruction: 0.478813, Regularization: 0.020316, Discriminator: 0.043313; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:15,128 root         INFO     Train Epoch: 74 [2048/8000 (26%)]\tTotal Loss: 0.666887\n",
      "Reconstruction: 0.578369, Regularization: 0.023546, Discriminator: 0.043321; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:15,227 root         INFO     Train Epoch: 74 [2560/8000 (32%)]\tTotal Loss: 0.766034\n",
      "Reconstruction: 0.673390, Regularization: 0.027667, Discriminator: 0.043317; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:15,326 root         INFO     Train Epoch: 74 [3072/8000 (38%)]\tTotal Loss: 0.985565\n",
      "Reconstruction: 0.885293, Regularization: 0.035292, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:15,425 root         INFO     Train Epoch: 74 [3584/8000 (45%)]\tTotal Loss: 0.658410\n",
      "Reconstruction: 0.570269, Regularization: 0.023165, Discriminator: 0.043316; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:15,521 root         INFO     Train Epoch: 74 [4096/8000 (51%)]\tTotal Loss: 0.691805\n",
      "Reconstruction: 0.602700, Regularization: 0.024128, Discriminator: 0.043318; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:15,617 root         INFO     Train Epoch: 74 [4608/8000 (58%)]\tTotal Loss: 0.617817\n",
      "Reconstruction: 0.530992, Regularization: 0.021857, Discriminator: 0.043315; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:15,712 root         INFO     Train Epoch: 74 [5120/8000 (64%)]\tTotal Loss: 0.651443\n",
      "Reconstruction: 0.562428, Regularization: 0.024040, Discriminator: 0.043321; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:15,808 root         INFO     Train Epoch: 74 [5632/8000 (70%)]\tTotal Loss: 0.831710\n",
      "Reconstruction: 0.738920, Regularization: 0.027804, Discriminator: 0.043331; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:15,903 root         INFO     Train Epoch: 74 [6144/8000 (77%)]\tTotal Loss: 0.881307\n",
      "Reconstruction: 0.780469, Regularization: 0.035910, Discriminator: 0.043270; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:15,999 root         INFO     Train Epoch: 74 [6656/8000 (83%)]\tTotal Loss: 0.823318\n",
      "Reconstruction: 0.727215, Regularization: 0.031136, Discriminator: 0.043311; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:16,094 root         INFO     Train Epoch: 74 [7168/8000 (90%)]\tTotal Loss: 0.671314\n",
      "Reconstruction: 0.587845, Regularization: 0.018452, Discriminator: 0.043360; Generator: 0.021658,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:16,190 root         INFO     Train Epoch: 74 [7680/8000 (96%)]\tTotal Loss: 0.654118\n",
      "Reconstruction: 0.566828, Regularization: 0.022316, Discriminator: 0.043314; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:16,262 root         INFO     ====> Epoch: 74 Average loss: 0.7224\n",
      "2019-04-09 22:47:16,288 root         INFO     Train Epoch: 75 [0/8000 (0%)]\tTotal Loss: 0.841796\n",
      "Reconstruction: 0.744923, Regularization: 0.031902, Discriminator: 0.043316; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:16,387 root         INFO     Train Epoch: 75 [512/8000 (6%)]\tTotal Loss: 0.548371\n",
      "Reconstruction: 0.465111, Regularization: 0.018283, Discriminator: 0.043318; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:16,486 root         INFO     Train Epoch: 75 [1024/8000 (13%)]\tTotal Loss: 0.787598\n",
      "Reconstruction: 0.693363, Regularization: 0.029285, Discriminator: 0.043290; Generator: 0.021660,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:16,585 root         INFO     Train Epoch: 75 [1536/8000 (19%)]\tTotal Loss: 0.795722\n",
      "Reconstruction: 0.702532, Regularization: 0.028218, Discriminator: 0.043312; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:16,684 root         INFO     Train Epoch: 75 [2048/8000 (26%)]\tTotal Loss: 0.907863\n",
      "Reconstruction: 0.812119, Regularization: 0.030747, Discriminator: 0.043336; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:16,779 root         INFO     Train Epoch: 75 [2560/8000 (32%)]\tTotal Loss: 0.510665\n",
      "Reconstruction: 0.427778, Regularization: 0.017920, Discriminator: 0.043304; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:16,876 root         INFO     Train Epoch: 75 [3072/8000 (38%)]\tTotal Loss: 0.599381\n",
      "Reconstruction: 0.515194, Regularization: 0.019205, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:16,972 root         INFO     Train Epoch: 75 [3584/8000 (45%)]\tTotal Loss: 0.840841\n",
      "Reconstruction: 0.747258, Regularization: 0.028606, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:17,068 root         INFO     Train Epoch: 75 [4096/8000 (51%)]\tTotal Loss: 0.835251\n",
      "Reconstruction: 0.737973, Regularization: 0.032318, Discriminator: 0.043303; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:17,164 root         INFO     Train Epoch: 75 [4608/8000 (58%)]\tTotal Loss: 0.689749\n",
      "Reconstruction: 0.600861, Regularization: 0.023912, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:17,260 root         INFO     Train Epoch: 75 [5120/8000 (64%)]\tTotal Loss: 0.502778\n",
      "Reconstruction: 0.420799, Regularization: 0.017016, Discriminator: 0.043303; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:17,356 root         INFO     Train Epoch: 75 [5632/8000 (70%)]\tTotal Loss: 0.935358\n",
      "Reconstruction: 0.833010, Regularization: 0.037378, Discriminator: 0.043307; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:17,452 root         INFO     Train Epoch: 75 [6144/8000 (77%)]\tTotal Loss: 0.816862\n",
      "Reconstruction: 0.722161, Regularization: 0.029736, Discriminator: 0.043307; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:17,547 root         INFO     Train Epoch: 75 [6656/8000 (83%)]\tTotal Loss: 0.609800\n",
      "Reconstruction: 0.520982, Regularization: 0.023870, Discriminator: 0.043287; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:17,643 root         INFO     Train Epoch: 75 [7168/8000 (90%)]\tTotal Loss: 0.929924\n",
      "Reconstruction: 0.830098, Regularization: 0.034875, Discriminator: 0.043291; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:17,738 root         INFO     Train Epoch: 75 [7680/8000 (96%)]\tTotal Loss: 0.493479\n",
      "Reconstruction: 0.410166, Regularization: 0.018389, Discriminator: 0.043266; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:17,810 root         INFO     ====> Epoch: 75 Average loss: 0.7217\n",
      "2019-04-09 22:47:17,837 root         INFO     Train Epoch: 76 [0/8000 (0%)]\tTotal Loss: 0.533701\n",
      "Reconstruction: 0.451423, Regularization: 0.017328, Discriminator: 0.043292; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:17,937 root         INFO     Train Epoch: 76 [512/8000 (6%)]\tTotal Loss: 0.705455\n",
      "Reconstruction: 0.616572, Regularization: 0.023898, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:18,037 root         INFO     Train Epoch: 76 [1024/8000 (13%)]\tTotal Loss: 0.855271\n",
      "Reconstruction: 0.757895, Regularization: 0.032453, Discriminator: 0.043260; Generator: 0.021662,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:18,136 root         INFO     Train Epoch: 76 [1536/8000 (19%)]\tTotal Loss: 0.657264\n",
      "Reconstruction: 0.571030, Regularization: 0.021248, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:18,235 root         INFO     Train Epoch: 76 [2048/8000 (26%)]\tTotal Loss: 0.865186\n",
      "Reconstruction: 0.766387, Regularization: 0.033841, Discriminator: 0.043296; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:18,334 root         INFO     Train Epoch: 76 [2560/8000 (32%)]\tTotal Loss: 0.620682\n",
      "Reconstruction: 0.533088, Regularization: 0.022659, Discriminator: 0.043274; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:18,432 root         INFO     Train Epoch: 76 [3072/8000 (38%)]\tTotal Loss: 0.628236\n",
      "Reconstruction: 0.544379, Regularization: 0.018857, Discriminator: 0.043336; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:18,529 root         INFO     Train Epoch: 76 [3584/8000 (45%)]\tTotal Loss: 0.671771\n",
      "Reconstruction: 0.586330, Regularization: 0.020434, Discriminator: 0.043346; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:18,626 root         INFO     Train Epoch: 76 [4096/8000 (51%)]\tTotal Loss: 0.723744\n",
      "Reconstruction: 0.632899, Regularization: 0.025874, Discriminator: 0.043310; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:18,724 root         INFO     Train Epoch: 76 [4608/8000 (58%)]\tTotal Loss: 0.550610\n",
      "Reconstruction: 0.468371, Regularization: 0.017228, Discriminator: 0.043350; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:18,822 root         INFO     Train Epoch: 76 [5120/8000 (64%)]\tTotal Loss: 0.720287\n",
      "Reconstruction: 0.631468, Regularization: 0.023823, Discriminator: 0.043333; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:18,919 root         INFO     Train Epoch: 76 [5632/8000 (70%)]\tTotal Loss: 0.552055\n",
      "Reconstruction: 0.470614, Regularization: 0.016450, Discriminator: 0.043328; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:19,016 root         INFO     Train Epoch: 76 [6144/8000 (77%)]\tTotal Loss: 0.744646\n",
      "Reconstruction: 0.654104, Regularization: 0.025542, Discriminator: 0.043340; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:19,114 root         INFO     Train Epoch: 76 [6656/8000 (83%)]\tTotal Loss: 0.622410\n",
      "Reconstruction: 0.539425, Regularization: 0.017943, Discriminator: 0.043382; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:19,211 root         INFO     Train Epoch: 76 [7168/8000 (90%)]\tTotal Loss: 0.692713\n",
      "Reconstruction: 0.603675, Regularization: 0.024052, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:19,308 root         INFO     Train Epoch: 76 [7680/8000 (96%)]\tTotal Loss: 0.722888\n",
      "Reconstruction: 0.634554, Regularization: 0.023351, Discriminator: 0.043327; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:19,382 root         INFO     ====> Epoch: 76 Average loss: 0.7229\n",
      "2019-04-09 22:47:19,408 root         INFO     Train Epoch: 77 [0/8000 (0%)]\tTotal Loss: 0.579638\n",
      "Reconstruction: 0.497969, Regularization: 0.016640, Discriminator: 0.043371; Generator: 0.021658,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:19,509 root         INFO     Train Epoch: 77 [512/8000 (6%)]\tTotal Loss: 0.656406\n",
      "Reconstruction: 0.569618, Regularization: 0.021814, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:19,607 root         INFO     Train Epoch: 77 [1024/8000 (13%)]\tTotal Loss: 0.408159\n",
      "Reconstruction: 0.332331, Regularization: 0.010846, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:19,706 root         INFO     Train Epoch: 77 [1536/8000 (19%)]\tTotal Loss: 0.612186\n",
      "Reconstruction: 0.529085, Regularization: 0.018109, Discriminator: 0.043330; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:19,805 root         INFO     Train Epoch: 77 [2048/8000 (26%)]\tTotal Loss: 0.775875\n",
      "Reconstruction: 0.681199, Regularization: 0.029742, Discriminator: 0.043276; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:19,904 root         INFO     Train Epoch: 77 [2560/8000 (32%)]\tTotal Loss: 0.724638\n",
      "Reconstruction: 0.634988, Regularization: 0.024673, Discriminator: 0.043318; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:20,001 root         INFO     Train Epoch: 77 [3072/8000 (38%)]\tTotal Loss: 0.525394\n",
      "Reconstruction: 0.444578, Regularization: 0.015803, Discriminator: 0.043357; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:20,096 root         INFO     Train Epoch: 77 [3584/8000 (45%)]\tTotal Loss: 0.695853\n",
      "Reconstruction: 0.609738, Regularization: 0.021102, Discriminator: 0.043354; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:20,192 root         INFO     Train Epoch: 77 [4096/8000 (51%)]\tTotal Loss: 0.809216\n",
      "Reconstruction: 0.716104, Regularization: 0.028129, Discriminator: 0.043326; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:20,288 root         INFO     Train Epoch: 77 [4608/8000 (58%)]\tTotal Loss: 0.678667\n",
      "Reconstruction: 0.596298, Regularization: 0.017271, Discriminator: 0.043432; Generator: 0.021666,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:47:20,385 root         INFO     Train Epoch: 77 [5120/8000 (64%)]\tTotal Loss: 0.718465\n",
      "Reconstruction: 0.630489, Regularization: 0.023006, Discriminator: 0.043309; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:20,480 root         INFO     Train Epoch: 77 [5632/8000 (70%)]\tTotal Loss: 0.656360\n",
      "Reconstruction: 0.568846, Regularization: 0.022577, Discriminator: 0.043275; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:20,576 root         INFO     Train Epoch: 77 [6144/8000 (77%)]\tTotal Loss: 0.618560\n",
      "Reconstruction: 0.533565, Regularization: 0.020018, Discriminator: 0.043315; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:20,671 root         INFO     Train Epoch: 77 [6656/8000 (83%)]\tTotal Loss: 0.677835\n",
      "Reconstruction: 0.586326, Regularization: 0.026625, Discriminator: 0.043223; Generator: 0.021662,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:47:20,766 root         INFO     Train Epoch: 77 [7168/8000 (90%)]\tTotal Loss: 0.856258\n",
      "Reconstruction: 0.761847, Regularization: 0.029393, Discriminator: 0.043352; Generator: 0.021666,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:20,862 root         INFO     Train Epoch: 77 [7680/8000 (96%)]\tTotal Loss: 0.667994\n",
      "Reconstruction: 0.580022, Regularization: 0.023014, Discriminator: 0.043296; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:20,935 root         INFO     ====> Epoch: 77 Average loss: 0.7215\n",
      "2019-04-09 22:47:20,962 root         INFO     Train Epoch: 78 [0/8000 (0%)]\tTotal Loss: 0.895797\n",
      "Reconstruction: 0.797910, Regularization: 0.032962, Discriminator: 0.043265; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:21,062 root         INFO     Train Epoch: 78 [512/8000 (6%)]\tTotal Loss: 0.667552\n",
      "Reconstruction: 0.578146, Regularization: 0.024472, Discriminator: 0.043267; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:21,161 root         INFO     Train Epoch: 78 [1024/8000 (13%)]\tTotal Loss: 0.709512\n",
      "Reconstruction: 0.625441, Regularization: 0.018970, Discriminator: 0.043439; Generator: 0.021661,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:47:21,261 root         INFO     Train Epoch: 78 [1536/8000 (19%)]\tTotal Loss: 0.651847\n",
      "Reconstruction: 0.564065, Regularization: 0.022820, Discriminator: 0.043299; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:21,360 root         INFO     Train Epoch: 78 [2048/8000 (26%)]\tTotal Loss: 0.884308\n",
      "Reconstruction: 0.790719, Regularization: 0.028564, Discriminator: 0.043363; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:21,459 root         INFO     Train Epoch: 78 [2560/8000 (32%)]\tTotal Loss: 0.822689\n",
      "Reconstruction: 0.729682, Regularization: 0.028074, Discriminator: 0.043273; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:21,559 root         INFO     Train Epoch: 78 [3072/8000 (38%)]\tTotal Loss: 0.691526\n",
      "Reconstruction: 0.601407, Regularization: 0.025233, Discriminator: 0.043224; Generator: 0.021661,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:47:21,658 root         INFO     Train Epoch: 78 [3584/8000 (45%)]\tTotal Loss: 1.010799\n",
      "Reconstruction: 0.906723, Regularization: 0.039175, Discriminator: 0.043244; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:21,757 root         INFO     Train Epoch: 78 [4096/8000 (51%)]\tTotal Loss: 0.429418\n",
      "Reconstruction: 0.353451, Regularization: 0.010947, Discriminator: 0.043358; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:21,856 root         INFO     Train Epoch: 78 [4608/8000 (58%)]\tTotal Loss: 0.599501\n",
      "Reconstruction: 0.516722, Regularization: 0.017775, Discriminator: 0.043341; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:21,955 root         INFO     Train Epoch: 78 [5120/8000 (64%)]\tTotal Loss: 0.626303\n",
      "Reconstruction: 0.541745, Regularization: 0.019571, Discriminator: 0.043324; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:22,054 root         INFO     Train Epoch: 78 [5632/8000 (70%)]\tTotal Loss: 0.573602\n",
      "Reconstruction: 0.491145, Regularization: 0.017493, Discriminator: 0.043304; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:22,152 root         INFO     Train Epoch: 78 [6144/8000 (77%)]\tTotal Loss: 0.686327\n",
      "Reconstruction: 0.602586, Regularization: 0.018657, Discriminator: 0.043421; Generator: 0.021664,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:47:22,250 root         INFO     Train Epoch: 78 [6656/8000 (83%)]\tTotal Loss: 0.704311\n",
      "Reconstruction: 0.617431, Regularization: 0.021833, Discriminator: 0.043387; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:22,348 root         INFO     Train Epoch: 78 [7168/8000 (90%)]\tTotal Loss: 0.762117\n",
      "Reconstruction: 0.669890, Regularization: 0.027280, Discriminator: 0.043286; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:22,446 root         INFO     Train Epoch: 78 [7680/8000 (96%)]\tTotal Loss: 0.733077\n",
      "Reconstruction: 0.642830, Regularization: 0.025287, Discriminator: 0.043300; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:22,520 root         INFO     ====> Epoch: 78 Average loss: 0.7206\n",
      "2019-04-09 22:47:22,547 root         INFO     Train Epoch: 79 [0/8000 (0%)]\tTotal Loss: 0.577654\n",
      "Reconstruction: 0.494473, Regularization: 0.018221, Discriminator: 0.043298; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:22,648 root         INFO     Train Epoch: 79 [512/8000 (6%)]\tTotal Loss: 0.738425\n",
      "Reconstruction: 0.646613, Regularization: 0.026942, Discriminator: 0.043207; Generator: 0.021664,\n",
      "D(x): 0.502, D(G(z)): 0.500\n",
      "2019-04-09 22:47:22,747 root         INFO     Train Epoch: 79 [1024/8000 (13%)]\tTotal Loss: 0.692791\n",
      "Reconstruction: 0.605053, Regularization: 0.022753, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:22,846 root         INFO     Train Epoch: 79 [1536/8000 (19%)]\tTotal Loss: 0.585187\n",
      "Reconstruction: 0.500344, Regularization: 0.019906, Discriminator: 0.043275; Generator: 0.021662,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:22,944 root         INFO     Train Epoch: 79 [2048/8000 (26%)]\tTotal Loss: 0.746240\n",
      "Reconstruction: 0.658493, Regularization: 0.022714, Discriminator: 0.043373; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:23,043 root         INFO     Train Epoch: 79 [2560/8000 (32%)]\tTotal Loss: 0.904182\n",
      "Reconstruction: 0.814047, Regularization: 0.025051, Discriminator: 0.043421; Generator: 0.021663,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:47:23,141 root         INFO     Train Epoch: 79 [3072/8000 (38%)]\tTotal Loss: 0.465283\n",
      "Reconstruction: 0.388144, Regularization: 0.012130, Discriminator: 0.043352; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:23,240 root         INFO     Train Epoch: 79 [3584/8000 (45%)]\tTotal Loss: 0.867014\n",
      "Reconstruction: 0.771772, Regularization: 0.030297, Discriminator: 0.043285; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:23,339 root         INFO     Train Epoch: 79 [4096/8000 (51%)]\tTotal Loss: 0.841459\n",
      "Reconstruction: 0.749521, Regularization: 0.026943, Discriminator: 0.043331; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:23,437 root         INFO     Train Epoch: 79 [4608/8000 (58%)]\tTotal Loss: 0.631283\n",
      "Reconstruction: 0.548276, Regularization: 0.017989, Discriminator: 0.043355; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:23,537 root         INFO     Train Epoch: 79 [5120/8000 (64%)]\tTotal Loss: 0.591330\n",
      "Reconstruction: 0.508363, Regularization: 0.017994, Discriminator: 0.043309; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:23,636 root         INFO     Train Epoch: 79 [5632/8000 (70%)]\tTotal Loss: 0.885473\n",
      "Reconstruction: 0.794929, Regularization: 0.025512, Discriminator: 0.043372; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:23,736 root         INFO     Train Epoch: 79 [6144/8000 (77%)]\tTotal Loss: 0.853558\n",
      "Reconstruction: 0.763239, Regularization: 0.025285, Discriminator: 0.043371; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:23,836 root         INFO     Train Epoch: 79 [6656/8000 (83%)]\tTotal Loss: 0.754211\n",
      "Reconstruction: 0.662700, Regularization: 0.026557, Discriminator: 0.043289; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:23,936 root         INFO     Train Epoch: 79 [7168/8000 (90%)]\tTotal Loss: 0.753429\n",
      "Reconstruction: 0.664156, Regularization: 0.024305, Discriminator: 0.043311; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:24,036 root         INFO     Train Epoch: 79 [7680/8000 (96%)]\tTotal Loss: 0.532114\n",
      "Reconstruction: 0.452387, Regularization: 0.014715, Discriminator: 0.043349; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:24,110 root         INFO     ====> Epoch: 79 Average loss: 0.7187\n",
      "2019-04-09 22:47:24,136 root         INFO     Train Epoch: 80 [0/8000 (0%)]\tTotal Loss: 0.603923\n",
      "Reconstruction: 0.519820, Regularization: 0.019156, Discriminator: 0.043284; Generator: 0.021662,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:24,235 root         INFO     Train Epoch: 80 [512/8000 (6%)]\tTotal Loss: 0.510537\n",
      "Reconstruction: 0.431602, Regularization: 0.013954, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:24,332 root         INFO     Train Epoch: 80 [1024/8000 (13%)]\tTotal Loss: 0.824322\n",
      "Reconstruction: 0.731872, Regularization: 0.027505, Discriminator: 0.043284; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:24,430 root         INFO     Train Epoch: 80 [1536/8000 (19%)]\tTotal Loss: 0.532958\n",
      "Reconstruction: 0.450298, Regularization: 0.017726, Discriminator: 0.043273; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:24,529 root         INFO     Train Epoch: 80 [2048/8000 (26%)]\tTotal Loss: 0.570068\n",
      "Reconstruction: 0.489065, Regularization: 0.016004, Discriminator: 0.043339; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:24,627 root         INFO     Train Epoch: 80 [2560/8000 (32%)]\tTotal Loss: 0.738618\n",
      "Reconstruction: 0.651255, Regularization: 0.022362, Discriminator: 0.043338; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:24,724 root         INFO     Train Epoch: 80 [3072/8000 (38%)]\tTotal Loss: 0.715716\n",
      "Reconstruction: 0.626617, Regularization: 0.024138, Discriminator: 0.043299; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:24,822 root         INFO     Train Epoch: 80 [3584/8000 (45%)]\tTotal Loss: 0.674469\n",
      "Reconstruction: 0.586009, Regularization: 0.023531, Discriminator: 0.043268; Generator: 0.021660,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:24,920 root         INFO     Train Epoch: 80 [4096/8000 (51%)]\tTotal Loss: 0.725402\n",
      "Reconstruction: 0.641436, Regularization: 0.018885, Discriminator: 0.043415; Generator: 0.021665,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:47:25,018 root         INFO     Train Epoch: 80 [4608/8000 (58%)]\tTotal Loss: 0.644404\n",
      "Reconstruction: 0.561314, Regularization: 0.018078, Discriminator: 0.043351; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:25,117 root         INFO     Train Epoch: 80 [5120/8000 (64%)]\tTotal Loss: 0.784105\n",
      "Reconstruction: 0.691251, Regularization: 0.027917, Discriminator: 0.043273; Generator: 0.021665,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:25,227 root         INFO     Train Epoch: 80 [5632/8000 (70%)]\tTotal Loss: 0.575703\n",
      "Reconstruction: 0.494244, Regularization: 0.016448, Discriminator: 0.043350; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:25,350 root         INFO     Train Epoch: 80 [6144/8000 (77%)]\tTotal Loss: 0.800594\n",
      "Reconstruction: 0.711180, Regularization: 0.024422, Discriminator: 0.043328; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:25,452 root         INFO     Train Epoch: 80 [6656/8000 (83%)]\tTotal Loss: 0.717992\n",
      "Reconstruction: 0.627016, Regularization: 0.026043, Discriminator: 0.043269; Generator: 0.021664,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:25,550 root         INFO     Train Epoch: 80 [7168/8000 (90%)]\tTotal Loss: 0.843633\n",
      "Reconstruction: 0.751116, Regularization: 0.027527, Discriminator: 0.043330; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:25,644 root         INFO     Train Epoch: 80 [7680/8000 (96%)]\tTotal Loss: 0.675024\n",
      "Reconstruction: 0.586231, Regularization: 0.023864, Discriminator: 0.043270; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:25,715 root         INFO     ====> Epoch: 80 Average loss: 0.7189\n",
      "2019-04-09 22:47:25,741 root         INFO     Train Epoch: 81 [0/8000 (0%)]\tTotal Loss: 0.803873\n",
      "Reconstruction: 0.713448, Regularization: 0.025424, Discriminator: 0.043344; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:25,838 root         INFO     Train Epoch: 81 [512/8000 (6%)]\tTotal Loss: 0.589238\n",
      "Reconstruction: 0.509010, Regularization: 0.015206, Discriminator: 0.043363; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:25,936 root         INFO     Train Epoch: 81 [1024/8000 (13%)]\tTotal Loss: 0.692022\n",
      "Reconstruction: 0.604519, Regularization: 0.022559, Discriminator: 0.043281; Generator: 0.021663,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:26,033 root         INFO     Train Epoch: 81 [1536/8000 (19%)]\tTotal Loss: 0.667568\n",
      "Reconstruction: 0.580046, Regularization: 0.022558, Discriminator: 0.043302; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:26,130 root         INFO     Train Epoch: 81 [2048/8000 (26%)]\tTotal Loss: 0.935873\n",
      "Reconstruction: 0.839221, Regularization: 0.031703, Discriminator: 0.043285; Generator: 0.021663,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:26,227 root         INFO     Train Epoch: 81 [2560/8000 (32%)]\tTotal Loss: 0.828325\n",
      "Reconstruction: 0.740014, Regularization: 0.023283, Discriminator: 0.043365; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:26,324 root         INFO     Train Epoch: 81 [3072/8000 (38%)]\tTotal Loss: 0.679999\n",
      "Reconstruction: 0.591201, Regularization: 0.023857, Discriminator: 0.043279; Generator: 0.021662,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:26,421 root         INFO     Train Epoch: 81 [3584/8000 (45%)]\tTotal Loss: 0.746368\n",
      "Reconstruction: 0.659104, Regularization: 0.022298, Discriminator: 0.043304; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:26,519 root         INFO     Train Epoch: 81 [4096/8000 (51%)]\tTotal Loss: 0.689548\n",
      "Reconstruction: 0.600330, Regularization: 0.024282, Discriminator: 0.043273; Generator: 0.021663,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:26,616 root         INFO     Train Epoch: 81 [4608/8000 (58%)]\tTotal Loss: 0.690970\n",
      "Reconstruction: 0.603079, Regularization: 0.022902, Discriminator: 0.043326; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:26,714 root         INFO     Train Epoch: 81 [5120/8000 (64%)]\tTotal Loss: 0.685159\n",
      "Reconstruction: 0.598670, Regularization: 0.021517, Discriminator: 0.043311; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:26,811 root         INFO     Train Epoch: 81 [5632/8000 (70%)]\tTotal Loss: 0.837797\n",
      "Reconstruction: 0.744744, Regularization: 0.028096, Discriminator: 0.043296; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:26,908 root         INFO     Train Epoch: 81 [6144/8000 (77%)]\tTotal Loss: 0.667364\n",
      "Reconstruction: 0.583561, Regularization: 0.018815, Discriminator: 0.043331; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:27,005 root         INFO     Train Epoch: 81 [6656/8000 (83%)]\tTotal Loss: 0.748248\n",
      "Reconstruction: 0.661258, Regularization: 0.022012, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:27,102 root         INFO     Train Epoch: 81 [7168/8000 (90%)]\tTotal Loss: 0.498095\n",
      "Reconstruction: 0.420450, Regularization: 0.012650, Discriminator: 0.043337; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:27,200 root         INFO     Train Epoch: 81 [7680/8000 (96%)]\tTotal Loss: 0.576202\n",
      "Reconstruction: 0.493810, Regularization: 0.017414, Discriminator: 0.043315; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:27,272 root         INFO     ====> Epoch: 81 Average loss: 0.7180\n",
      "2019-04-09 22:47:27,299 root         INFO     Train Epoch: 82 [0/8000 (0%)]\tTotal Loss: 0.799932\n",
      "Reconstruction: 0.711834, Regularization: 0.023099, Discriminator: 0.043337; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:27,397 root         INFO     Train Epoch: 82 [512/8000 (6%)]\tTotal Loss: 0.723868\n",
      "Reconstruction: 0.637193, Regularization: 0.021683, Discriminator: 0.043331; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:27,496 root         INFO     Train Epoch: 82 [1024/8000 (13%)]\tTotal Loss: 0.683668\n",
      "Reconstruction: 0.596612, Regularization: 0.022102, Discriminator: 0.043292; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:27,595 root         INFO     Train Epoch: 82 [1536/8000 (19%)]\tTotal Loss: 0.893198\n",
      "Reconstruction: 0.799746, Regularization: 0.028472, Discriminator: 0.043316; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:27,693 root         INFO     Train Epoch: 82 [2048/8000 (26%)]\tTotal Loss: 0.789221\n",
      "Reconstruction: 0.698200, Regularization: 0.026044, Discriminator: 0.043311; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:27,791 root         INFO     Train Epoch: 82 [2560/8000 (32%)]\tTotal Loss: 0.663620\n",
      "Reconstruction: 0.577623, Regularization: 0.021030, Discriminator: 0.043308; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:27,890 root         INFO     Train Epoch: 82 [3072/8000 (38%)]\tTotal Loss: 0.864078\n",
      "Reconstruction: 0.774503, Regularization: 0.024563, Discriminator: 0.043351; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:27,989 root         INFO     Train Epoch: 82 [3584/8000 (45%)]\tTotal Loss: 0.671167\n",
      "Reconstruction: 0.585666, Regularization: 0.020517, Discriminator: 0.043321; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:28,087 root         INFO     Train Epoch: 82 [4096/8000 (51%)]\tTotal Loss: 0.760063\n",
      "Reconstruction: 0.671966, Regularization: 0.023114, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:28,186 root         INFO     Train Epoch: 82 [4608/8000 (58%)]\tTotal Loss: 0.800851\n",
      "Reconstruction: 0.709977, Regularization: 0.025888, Discriminator: 0.043323; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:28,284 root         INFO     Train Epoch: 82 [5120/8000 (64%)]\tTotal Loss: 0.883399\n",
      "Reconstruction: 0.790864, Regularization: 0.027540, Discriminator: 0.043332; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:28,383 root         INFO     Train Epoch: 82 [5632/8000 (70%)]\tTotal Loss: 0.843686\n",
      "Reconstruction: 0.750962, Regularization: 0.027735, Discriminator: 0.043327; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:28,481 root         INFO     Train Epoch: 82 [6144/8000 (77%)]\tTotal Loss: 0.788418\n",
      "Reconstruction: 0.695699, Regularization: 0.027763, Discriminator: 0.043298; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:28,579 root         INFO     Train Epoch: 82 [6656/8000 (83%)]\tTotal Loss: 0.832440\n",
      "Reconstruction: 0.741435, Regularization: 0.026021, Discriminator: 0.043325; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:28,677 root         INFO     Train Epoch: 82 [7168/8000 (90%)]\tTotal Loss: 0.693698\n",
      "Reconstruction: 0.604745, Regularization: 0.023996, Discriminator: 0.043299; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:28,776 root         INFO     Train Epoch: 82 [7680/8000 (96%)]\tTotal Loss: 0.903054\n",
      "Reconstruction: 0.812030, Regularization: 0.026026, Discriminator: 0.043334; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:28,849 root         INFO     ====> Epoch: 82 Average loss: 0.7162\n",
      "2019-04-09 22:47:28,876 root         INFO     Train Epoch: 83 [0/8000 (0%)]\tTotal Loss: 0.838261\n",
      "Reconstruction: 0.747408, Regularization: 0.025881, Discriminator: 0.043306; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:28,974 root         INFO     Train Epoch: 83 [512/8000 (6%)]\tTotal Loss: 0.663604\n",
      "Reconstruction: 0.578871, Regularization: 0.019745, Discriminator: 0.043325; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:29,073 root         INFO     Train Epoch: 83 [1024/8000 (13%)]\tTotal Loss: 0.573301\n",
      "Reconstruction: 0.490913, Regularization: 0.017416, Discriminator: 0.043301; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:29,169 root         INFO     Train Epoch: 83 [1536/8000 (19%)]\tTotal Loss: 0.774588\n",
      "Reconstruction: 0.687410, Regularization: 0.022186, Discriminator: 0.043333; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:29,266 root         INFO     Train Epoch: 83 [2048/8000 (26%)]\tTotal Loss: 0.703098\n",
      "Reconstruction: 0.616289, Regularization: 0.021824, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:29,363 root         INFO     Train Epoch: 83 [2560/8000 (32%)]\tTotal Loss: 0.585479\n",
      "Reconstruction: 0.504314, Regularization: 0.016176, Discriminator: 0.043327; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:29,460 root         INFO     Train Epoch: 83 [3072/8000 (38%)]\tTotal Loss: 0.570854\n",
      "Reconstruction: 0.491547, Regularization: 0.014318, Discriminator: 0.043323; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:29,557 root         INFO     Train Epoch: 83 [3584/8000 (45%)]\tTotal Loss: 0.825704\n",
      "Reconstruction: 0.734522, Regularization: 0.026188, Discriminator: 0.043326; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:29,654 root         INFO     Train Epoch: 83 [4096/8000 (51%)]\tTotal Loss: 0.702531\n",
      "Reconstruction: 0.618767, Regularization: 0.018775, Discriminator: 0.043325; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:29,752 root         INFO     Train Epoch: 83 [4608/8000 (58%)]\tTotal Loss: 0.509858\n",
      "Reconstruction: 0.431650, Regularization: 0.013218, Discriminator: 0.043327; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:29,849 root         INFO     Train Epoch: 83 [5120/8000 (64%)]\tTotal Loss: 0.828852\n",
      "Reconstruction: 0.739524, Regularization: 0.024340, Discriminator: 0.043321; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:29,946 root         INFO     Train Epoch: 83 [5632/8000 (70%)]\tTotal Loss: 0.692120\n",
      "Reconstruction: 0.608870, Regularization: 0.018258, Discriminator: 0.043328; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:30,044 root         INFO     Train Epoch: 83 [6144/8000 (77%)]\tTotal Loss: 0.667865\n",
      "Reconstruction: 0.585123, Regularization: 0.017778, Discriminator: 0.043298; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:30,140 root         INFO     Train Epoch: 83 [6656/8000 (83%)]\tTotal Loss: 0.407441\n",
      "Reconstruction: 0.332597, Regularization: 0.009884, Discriminator: 0.043296; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:30,237 root         INFO     Train Epoch: 83 [7168/8000 (90%)]\tTotal Loss: 0.543228\n",
      "Reconstruction: 0.462050, Regularization: 0.016194, Discriminator: 0.043325; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:30,335 root         INFO     Train Epoch: 83 [7680/8000 (96%)]\tTotal Loss: 0.683637\n",
      "Reconstruction: 0.600121, Regularization: 0.018528, Discriminator: 0.043324; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:30,408 root         INFO     ====> Epoch: 83 Average loss: 0.7187\n",
      "2019-04-09 22:47:30,434 root         INFO     Train Epoch: 84 [0/8000 (0%)]\tTotal Loss: 0.774799\n",
      "Reconstruction: 0.685634, Regularization: 0.024162, Discriminator: 0.043343; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:30,532 root         INFO     Train Epoch: 84 [512/8000 (6%)]\tTotal Loss: 0.705139\n",
      "Reconstruction: 0.620638, Regularization: 0.019502, Discriminator: 0.043340; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:30,630 root         INFO     Train Epoch: 84 [1024/8000 (13%)]\tTotal Loss: 0.826037\n",
      "Reconstruction: 0.738133, Regularization: 0.022928, Discriminator: 0.043317; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:30,727 root         INFO     Train Epoch: 84 [1536/8000 (19%)]\tTotal Loss: 0.605275\n",
      "Reconstruction: 0.522430, Regularization: 0.017867, Discriminator: 0.043320; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:30,824 root         INFO     Train Epoch: 84 [2048/8000 (26%)]\tTotal Loss: 0.613864\n",
      "Reconstruction: 0.534533, Regularization: 0.014331, Discriminator: 0.043337; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:30,922 root         INFO     Train Epoch: 84 [2560/8000 (32%)]\tTotal Loss: 0.942903\n",
      "Reconstruction: 0.849064, Regularization: 0.028877, Discriminator: 0.043304; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:31,019 root         INFO     Train Epoch: 84 [3072/8000 (38%)]\tTotal Loss: 0.782017\n",
      "Reconstruction: 0.691986, Regularization: 0.025042, Discriminator: 0.043330; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:31,116 root         INFO     Train Epoch: 84 [3584/8000 (45%)]\tTotal Loss: 0.716007\n",
      "Reconstruction: 0.632386, Regularization: 0.018637, Discriminator: 0.043324; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:31,214 root         INFO     Train Epoch: 84 [4096/8000 (51%)]\tTotal Loss: 0.767536\n",
      "Reconstruction: 0.679284, Regularization: 0.023265, Discriminator: 0.043323; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:31,312 root         INFO     Train Epoch: 84 [4608/8000 (58%)]\tTotal Loss: 0.809164\n",
      "Reconstruction: 0.719842, Regularization: 0.024342, Discriminator: 0.043312; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:31,408 root         INFO     Train Epoch: 84 [5120/8000 (64%)]\tTotal Loss: 0.914004\n",
      "Reconstruction: 0.821636, Regularization: 0.027383, Discriminator: 0.043320; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:31,506 root         INFO     Train Epoch: 84 [5632/8000 (70%)]\tTotal Loss: 0.600577\n",
      "Reconstruction: 0.519628, Regularization: 0.015989, Discriminator: 0.043303; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:31,604 root         INFO     Train Epoch: 84 [6144/8000 (77%)]\tTotal Loss: 0.876353\n",
      "Reconstruction: 0.786039, Regularization: 0.025349, Discriminator: 0.043308; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:31,701 root         INFO     Train Epoch: 84 [6656/8000 (83%)]\tTotal Loss: 0.657677\n",
      "Reconstruction: 0.573989, Regularization: 0.018701, Discriminator: 0.043316; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:31,798 root         INFO     Train Epoch: 84 [7168/8000 (90%)]\tTotal Loss: 0.595667\n",
      "Reconstruction: 0.514913, Regularization: 0.015789, Discriminator: 0.043302; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:31,896 root         INFO     Train Epoch: 84 [7680/8000 (96%)]\tTotal Loss: 0.871653\n",
      "Reconstruction: 0.783358, Regularization: 0.023350, Discriminator: 0.043274; Generator: 0.021671,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:31,970 root         INFO     ====> Epoch: 84 Average loss: 0.7138\n",
      "2019-04-09 22:47:31,996 root         INFO     Train Epoch: 85 [0/8000 (0%)]\tTotal Loss: 0.538037\n",
      "Reconstruction: 0.458217, Regularization: 0.014801, Discriminator: 0.043344; Generator: 0.021675,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:32,094 root         INFO     Train Epoch: 85 [512/8000 (6%)]\tTotal Loss: 0.694081\n",
      "Reconstruction: 0.611147, Regularization: 0.017973, Discriminator: 0.043287; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:32,191 root         INFO     Train Epoch: 85 [1024/8000 (13%)]\tTotal Loss: 0.725630\n",
      "Reconstruction: 0.640494, Regularization: 0.020189, Discriminator: 0.043290; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:32,288 root         INFO     Train Epoch: 85 [1536/8000 (19%)]\tTotal Loss: 0.642307\n",
      "Reconstruction: 0.560082, Regularization: 0.017296, Discriminator: 0.043265; Generator: 0.021665,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:32,385 root         INFO     Train Epoch: 85 [2048/8000 (26%)]\tTotal Loss: 0.603384\n",
      "Reconstruction: 0.519895, Regularization: 0.018490, Discriminator: 0.043341; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:32,482 root         INFO     Train Epoch: 85 [2560/8000 (32%)]\tTotal Loss: 0.657798\n",
      "Reconstruction: 0.573720, Regularization: 0.019121, Discriminator: 0.043300; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:32,580 root         INFO     Train Epoch: 85 [3072/8000 (38%)]\tTotal Loss: 0.695744\n",
      "Reconstruction: 0.608920, Regularization: 0.021820, Discriminator: 0.043335; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:32,678 root         INFO     Train Epoch: 85 [3584/8000 (45%)]\tTotal Loss: 0.914574\n",
      "Reconstruction: 0.825322, Regularization: 0.024283, Discriminator: 0.043307; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:32,776 root         INFO     Train Epoch: 85 [4096/8000 (51%)]\tTotal Loss: 0.663862\n",
      "Reconstruction: 0.578589, Regularization: 0.020275, Discriminator: 0.043333; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:32,875 root         INFO     Train Epoch: 85 [4608/8000 (58%)]\tTotal Loss: 0.635208\n",
      "Reconstruction: 0.551174, Regularization: 0.019042, Discriminator: 0.043326; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:32,975 root         INFO     Train Epoch: 85 [5120/8000 (64%)]\tTotal Loss: 0.954638\n",
      "Reconstruction: 0.860405, Regularization: 0.029259, Discriminator: 0.043318; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:33,075 root         INFO     Train Epoch: 85 [5632/8000 (70%)]\tTotal Loss: 0.884453\n",
      "Reconstruction: 0.793572, Regularization: 0.025893, Discriminator: 0.043330; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:33,174 root         INFO     Train Epoch: 85 [6144/8000 (77%)]\tTotal Loss: 0.688624\n",
      "Reconstruction: 0.607367, Regularization: 0.016314, Discriminator: 0.043279; Generator: 0.021664,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:33,273 root         INFO     Train Epoch: 85 [6656/8000 (83%)]\tTotal Loss: 0.556455\n",
      "Reconstruction: 0.476777, Regularization: 0.014698, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:33,372 root         INFO     Train Epoch: 85 [7168/8000 (90%)]\tTotal Loss: 0.496444\n",
      "Reconstruction: 0.419062, Regularization: 0.012420, Discriminator: 0.043295; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:33,472 root         INFO     Train Epoch: 85 [7680/8000 (96%)]\tTotal Loss: 0.840699\n",
      "Reconstruction: 0.746299, Regularization: 0.029399, Discriminator: 0.043335; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:33,546 root         INFO     ====> Epoch: 85 Average loss: 0.7206\n",
      "2019-04-09 22:47:33,572 root         INFO     Train Epoch: 86 [0/8000 (0%)]\tTotal Loss: 0.668667\n",
      "Reconstruction: 0.584576, Regularization: 0.019105, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:33,672 root         INFO     Train Epoch: 86 [512/8000 (6%)]\tTotal Loss: 0.720874\n",
      "Reconstruction: 0.635873, Regularization: 0.019947, Discriminator: 0.043390; Generator: 0.021664,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:33,771 root         INFO     Train Epoch: 86 [1024/8000 (13%)]\tTotal Loss: 0.865490\n",
      "Reconstruction: 0.773868, Regularization: 0.026648, Discriminator: 0.043317; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:33,870 root         INFO     Train Epoch: 86 [1536/8000 (19%)]\tTotal Loss: 0.968495\n",
      "Reconstruction: 0.866788, Regularization: 0.036687, Discriminator: 0.043355; Generator: 0.021665,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:33,969 root         INFO     Train Epoch: 86 [2048/8000 (26%)]\tTotal Loss: 0.664623\n",
      "Reconstruction: 0.578360, Regularization: 0.021283, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:34,069 root         INFO     Train Epoch: 86 [2560/8000 (32%)]\tTotal Loss: 0.537943\n",
      "Reconstruction: 0.459585, Regularization: 0.013374, Discriminator: 0.043318; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:34,168 root         INFO     Train Epoch: 86 [3072/8000 (38%)]\tTotal Loss: 0.756769\n",
      "Reconstruction: 0.670615, Regularization: 0.021175, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:34,267 root         INFO     Train Epoch: 86 [3584/8000 (45%)]\tTotal Loss: 0.861847\n",
      "Reconstruction: 0.772087, Regularization: 0.024784, Discriminator: 0.043311; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:34,366 root         INFO     Train Epoch: 86 [4096/8000 (51%)]\tTotal Loss: 0.808163\n",
      "Reconstruction: 0.719125, Regularization: 0.024066, Discriminator: 0.043318; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:34,465 root         INFO     Train Epoch: 86 [4608/8000 (58%)]\tTotal Loss: 0.714988\n",
      "Reconstruction: 0.629286, Regularization: 0.020722, Discriminator: 0.043312; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:34,564 root         INFO     Train Epoch: 86 [5120/8000 (64%)]\tTotal Loss: 0.853475\n",
      "Reconstruction: 0.758781, Regularization: 0.029663, Discriminator: 0.043361; Generator: 0.021670,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:34,663 root         INFO     Train Epoch: 86 [5632/8000 (70%)]\tTotal Loss: 0.722041\n",
      "Reconstruction: 0.632419, Regularization: 0.024609, Discriminator: 0.043361; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:34,762 root         INFO     Train Epoch: 86 [6144/8000 (77%)]\tTotal Loss: 0.651056\n",
      "Reconstruction: 0.564986, Regularization: 0.021069, Discriminator: 0.043343; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:34,861 root         INFO     Train Epoch: 86 [6656/8000 (83%)]\tTotal Loss: 0.846723\n",
      "Reconstruction: 0.752364, Regularization: 0.029335, Discriminator: 0.043365; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:34,960 root         INFO     Train Epoch: 86 [7168/8000 (90%)]\tTotal Loss: 0.506706\n",
      "Reconstruction: 0.427552, Regularization: 0.014161, Discriminator: 0.043331; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:35,059 root         INFO     Train Epoch: 86 [7680/8000 (96%)]\tTotal Loss: 1.016968\n",
      "Reconstruction: 0.919778, Regularization: 0.032223, Discriminator: 0.043303; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:35,133 root         INFO     ====> Epoch: 86 Average loss: 0.7154\n",
      "2019-04-09 22:47:35,159 root         INFO     Train Epoch: 87 [0/8000 (0%)]\tTotal Loss: 0.951885\n",
      "Reconstruction: 0.860317, Regularization: 0.026621, Discriminator: 0.043290; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:35,259 root         INFO     Train Epoch: 87 [512/8000 (6%)]\tTotal Loss: 0.713997\n",
      "Reconstruction: 0.624710, Regularization: 0.024285, Discriminator: 0.043340; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:35,358 root         INFO     Train Epoch: 87 [1024/8000 (13%)]\tTotal Loss: 0.893473\n",
      "Reconstruction: 0.803698, Regularization: 0.024826, Discriminator: 0.043282; Generator: 0.021668,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:35,456 root         INFO     Train Epoch: 87 [1536/8000 (19%)]\tTotal Loss: 0.803637\n",
      "Reconstruction: 0.713412, Regularization: 0.025214, Discriminator: 0.043339; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:35,554 root         INFO     Train Epoch: 87 [2048/8000 (26%)]\tTotal Loss: 0.618174\n",
      "Reconstruction: 0.535151, Regularization: 0.018058, Discriminator: 0.043305; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:35,652 root         INFO     Train Epoch: 87 [2560/8000 (32%)]\tTotal Loss: 0.603851\n",
      "Reconstruction: 0.523641, Regularization: 0.015273, Discriminator: 0.043278; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:35,748 root         INFO     Train Epoch: 87 [3072/8000 (38%)]\tTotal Loss: 0.758383\n",
      "Reconstruction: 0.670720, Regularization: 0.022673, Discriminator: 0.043328; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:35,846 root         INFO     Train Epoch: 87 [3584/8000 (45%)]\tTotal Loss: 0.760083\n",
      "Reconstruction: 0.670613, Regularization: 0.024447, Discriminator: 0.043367; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:35,944 root         INFO     Train Epoch: 87 [4096/8000 (51%)]\tTotal Loss: 0.578882\n",
      "Reconstruction: 0.496338, Regularization: 0.017525, Discriminator: 0.043339; Generator: 0.021679,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:36,042 root         INFO     Train Epoch: 87 [4608/8000 (58%)]\tTotal Loss: 0.627579\n",
      "Reconstruction: 0.542333, Regularization: 0.020270, Discriminator: 0.043318; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:36,140 root         INFO     Train Epoch: 87 [5120/8000 (64%)]\tTotal Loss: 0.850096\n",
      "Reconstruction: 0.760984, Regularization: 0.024160, Discriminator: 0.043296; Generator: 0.021655,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:36,238 root         INFO     Train Epoch: 87 [5632/8000 (70%)]\tTotal Loss: 0.817777\n",
      "Reconstruction: 0.724918, Regularization: 0.027858, Discriminator: 0.043349; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:36,336 root         INFO     Train Epoch: 87 [6144/8000 (77%)]\tTotal Loss: 0.709587\n",
      "Reconstruction: 0.623395, Regularization: 0.021218, Discriminator: 0.043311; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:36,432 root         INFO     Train Epoch: 87 [6656/8000 (83%)]\tTotal Loss: 0.823748\n",
      "Reconstruction: 0.735060, Regularization: 0.023733, Discriminator: 0.043289; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:36,530 root         INFO     Train Epoch: 87 [7168/8000 (90%)]\tTotal Loss: 0.720825\n",
      "Reconstruction: 0.630896, Regularization: 0.024923, Discriminator: 0.043349; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:36,628 root         INFO     Train Epoch: 87 [7680/8000 (96%)]\tTotal Loss: 0.607845\n",
      "Reconstruction: 0.524622, Regularization: 0.018235, Discriminator: 0.043330; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:36,701 root         INFO     ====> Epoch: 87 Average loss: 0.7155\n",
      "2019-04-09 22:47:36,728 root         INFO     Train Epoch: 88 [0/8000 (0%)]\tTotal Loss: 0.754438\n",
      "Reconstruction: 0.667632, Regularization: 0.021842, Discriminator: 0.043303; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:36,827 root         INFO     Train Epoch: 88 [512/8000 (6%)]\tTotal Loss: 0.675209\n",
      "Reconstruction: 0.588135, Regularization: 0.022061, Discriminator: 0.043345; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:36,924 root         INFO     Train Epoch: 88 [1024/8000 (13%)]\tTotal Loss: 0.674126\n",
      "Reconstruction: 0.586682, Regularization: 0.022422, Discriminator: 0.043355; Generator: 0.021668,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:37,022 root         INFO     Train Epoch: 88 [1536/8000 (19%)]\tTotal Loss: 0.797200\n",
      "Reconstruction: 0.707381, Regularization: 0.024851, Discriminator: 0.043310; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:37,120 root         INFO     Train Epoch: 88 [2048/8000 (26%)]\tTotal Loss: 0.563202\n",
      "Reconstruction: 0.482572, Regularization: 0.015640, Discriminator: 0.043324; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:37,218 root         INFO     Train Epoch: 88 [2560/8000 (32%)]\tTotal Loss: 0.666048\n",
      "Reconstruction: 0.581121, Regularization: 0.019935, Discriminator: 0.043326; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:37,316 root         INFO     Train Epoch: 88 [3072/8000 (38%)]\tTotal Loss: 0.842277\n",
      "Reconstruction: 0.747909, Regularization: 0.029367, Discriminator: 0.043345; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:37,414 root         INFO     Train Epoch: 88 [3584/8000 (45%)]\tTotal Loss: 0.713243\n",
      "Reconstruction: 0.626394, Regularization: 0.021870, Discriminator: 0.043324; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:37,511 root         INFO     Train Epoch: 88 [4096/8000 (51%)]\tTotal Loss: 0.702982\n",
      "Reconstruction: 0.616244, Regularization: 0.021765, Discriminator: 0.043316; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:37,610 root         INFO     Train Epoch: 88 [4608/8000 (58%)]\tTotal Loss: 0.514673\n",
      "Reconstruction: 0.432125, Regularization: 0.017536, Discriminator: 0.043351; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:37,708 root         INFO     Train Epoch: 88 [5120/8000 (64%)]\tTotal Loss: 0.873838\n",
      "Reconstruction: 0.782219, Regularization: 0.026682, Discriminator: 0.043272; Generator: 0.021666,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:37,806 root         INFO     Train Epoch: 88 [5632/8000 (70%)]\tTotal Loss: 0.670048\n",
      "Reconstruction: 0.588822, Regularization: 0.016287, Discriminator: 0.043278; Generator: 0.021662,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:37,904 root         INFO     Train Epoch: 88 [6144/8000 (77%)]\tTotal Loss: 0.541003\n",
      "Reconstruction: 0.462281, Regularization: 0.013792, Discriminator: 0.043276; Generator: 0.021653,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:38,002 root         INFO     Train Epoch: 88 [6656/8000 (83%)]\tTotal Loss: 0.546036\n",
      "Reconstruction: 0.466664, Regularization: 0.014414, Discriminator: 0.043300; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:38,100 root         INFO     Train Epoch: 88 [7168/8000 (90%)]\tTotal Loss: 0.607936\n",
      "Reconstruction: 0.521677, Regularization: 0.021229, Discriminator: 0.043375; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:38,196 root         INFO     Train Epoch: 88 [7680/8000 (96%)]\tTotal Loss: 0.813941\n",
      "Reconstruction: 0.724854, Regularization: 0.024106, Discriminator: 0.043313; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:38,268 root         INFO     ====> Epoch: 88 Average loss: 0.7194\n",
      "2019-04-09 22:47:38,294 root         INFO     Train Epoch: 89 [0/8000 (0%)]\tTotal Loss: 0.945058\n",
      "Reconstruction: 0.850434, Regularization: 0.029683, Discriminator: 0.043290; Generator: 0.021651,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:38,393 root         INFO     Train Epoch: 89 [512/8000 (6%)]\tTotal Loss: 0.672649\n",
      "Reconstruction: 0.586134, Regularization: 0.021535, Discriminator: 0.043333; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:38,491 root         INFO     Train Epoch: 89 [1024/8000 (13%)]\tTotal Loss: 0.626646\n",
      "Reconstruction: 0.547914, Regularization: 0.013764, Discriminator: 0.043299; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:38,589 root         INFO     Train Epoch: 89 [1536/8000 (19%)]\tTotal Loss: 0.722843\n",
      "Reconstruction: 0.632912, Regularization: 0.024929, Discriminator: 0.043336; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:38,687 root         INFO     Train Epoch: 89 [2048/8000 (26%)]\tTotal Loss: 0.736289\n",
      "Reconstruction: 0.645719, Regularization: 0.025556, Discriminator: 0.043359; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:38,786 root         INFO     Train Epoch: 89 [2560/8000 (32%)]\tTotal Loss: 0.879710\n",
      "Reconstruction: 0.784785, Regularization: 0.029945, Discriminator: 0.043323; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:38,884 root         INFO     Train Epoch: 89 [3072/8000 (38%)]\tTotal Loss: 0.864710\n",
      "Reconstruction: 0.774576, Regularization: 0.025191, Discriminator: 0.043283; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:38,983 root         INFO     Train Epoch: 89 [3584/8000 (45%)]\tTotal Loss: 1.236616\n",
      "Reconstruction: 1.127941, Regularization: 0.043669, Discriminator: 0.043349; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:39,081 root         INFO     Train Epoch: 89 [4096/8000 (51%)]\tTotal Loss: 0.537413\n",
      "Reconstruction: 0.456358, Regularization: 0.016065, Discriminator: 0.043332; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:39,179 root         INFO     Train Epoch: 89 [4608/8000 (58%)]\tTotal Loss: 0.671618\n",
      "Reconstruction: 0.582631, Regularization: 0.023987, Discriminator: 0.043350; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:39,277 root         INFO     Train Epoch: 89 [5120/8000 (64%)]\tTotal Loss: 0.869171\n",
      "Reconstruction: 0.777697, Regularization: 0.026521, Discriminator: 0.043299; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:39,375 root         INFO     Train Epoch: 89 [5632/8000 (70%)]\tTotal Loss: 0.731729\n",
      "Reconstruction: 0.639688, Regularization: 0.027032, Discriminator: 0.043357; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:39,473 root         INFO     Train Epoch: 89 [6144/8000 (77%)]\tTotal Loss: 0.816498\n",
      "Reconstruction: 0.724086, Regularization: 0.027430, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:39,572 root         INFO     Train Epoch: 89 [6656/8000 (83%)]\tTotal Loss: 0.852153\n",
      "Reconstruction: 0.754699, Regularization: 0.032430, Discriminator: 0.043365; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:39,670 root         INFO     Train Epoch: 89 [7168/8000 (90%)]\tTotal Loss: 0.725771\n",
      "Reconstruction: 0.640195, Regularization: 0.020627, Discriminator: 0.043285; Generator: 0.021664,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:39,768 root         INFO     Train Epoch: 89 [7680/8000 (96%)]\tTotal Loss: 0.857438\n",
      "Reconstruction: 0.761911, Regularization: 0.030506, Discriminator: 0.043349; Generator: 0.021672,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:39,841 root         INFO     ====> Epoch: 89 Average loss: 0.7155\n",
      "2019-04-09 22:47:39,867 root         INFO     Train Epoch: 90 [0/8000 (0%)]\tTotal Loss: 0.726195\n",
      "Reconstruction: 0.634570, Regularization: 0.026583, Discriminator: 0.043375; Generator: 0.021667,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:39,967 root         INFO     Train Epoch: 90 [512/8000 (6%)]\tTotal Loss: 0.810700\n",
      "Reconstruction: 0.718307, Regularization: 0.027432, Discriminator: 0.043310; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:40,065 root         INFO     Train Epoch: 90 [1024/8000 (13%)]\tTotal Loss: 0.566689\n",
      "Reconstruction: 0.487664, Regularization: 0.014107, Discriminator: 0.043253; Generator: 0.021665,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:40,163 root         INFO     Train Epoch: 90 [1536/8000 (19%)]\tTotal Loss: 0.598153\n",
      "Reconstruction: 0.516311, Regularization: 0.016885, Discriminator: 0.043294; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:40,261 root         INFO     Train Epoch: 90 [2048/8000 (26%)]\tTotal Loss: 0.530753\n",
      "Reconstruction: 0.447928, Regularization: 0.017822, Discriminator: 0.043327; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:40,359 root         INFO     Train Epoch: 90 [2560/8000 (32%)]\tTotal Loss: 0.664623\n",
      "Reconstruction: 0.578795, Regularization: 0.020886, Discriminator: 0.043278; Generator: 0.021663,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:40,457 root         INFO     Train Epoch: 90 [3072/8000 (38%)]\tTotal Loss: 0.811218\n",
      "Reconstruction: 0.719233, Regularization: 0.026962, Discriminator: 0.043362; Generator: 0.021661,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:40,554 root         INFO     Train Epoch: 90 [3584/8000 (45%)]\tTotal Loss: 0.756455\n",
      "Reconstruction: 0.666368, Regularization: 0.025129, Discriminator: 0.043306; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:40,650 root         INFO     Train Epoch: 90 [4096/8000 (51%)]\tTotal Loss: 1.056226\n",
      "Reconstruction: 0.954119, Regularization: 0.037110, Discriminator: 0.043345; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:40,746 root         INFO     Train Epoch: 90 [4608/8000 (58%)]\tTotal Loss: 0.547457\n",
      "Reconstruction: 0.466177, Regularization: 0.016322, Discriminator: 0.043296; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:40,843 root         INFO     Train Epoch: 90 [5120/8000 (64%)]\tTotal Loss: 0.652617\n",
      "Reconstruction: 0.566539, Regularization: 0.021078, Discriminator: 0.043341; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:40,939 root         INFO     Train Epoch: 90 [5632/8000 (70%)]\tTotal Loss: 0.798252\n",
      "Reconstruction: 0.706594, Regularization: 0.026689, Discriminator: 0.043318; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:41,035 root         INFO     Train Epoch: 90 [6144/8000 (77%)]\tTotal Loss: 0.803872\n",
      "Reconstruction: 0.713779, Regularization: 0.025117, Discriminator: 0.043311; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:41,132 root         INFO     Train Epoch: 90 [6656/8000 (83%)]\tTotal Loss: 0.736992\n",
      "Reconstruction: 0.648167, Regularization: 0.023830, Discriminator: 0.043333; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:41,227 root         INFO     Train Epoch: 90 [7168/8000 (90%)]\tTotal Loss: 0.770653\n",
      "Reconstruction: 0.679145, Regularization: 0.026525, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:41,322 root         INFO     Train Epoch: 90 [7680/8000 (96%)]\tTotal Loss: 0.635990\n",
      "Reconstruction: 0.552104, Regularization: 0.018902, Discriminator: 0.043315; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:41,394 root         INFO     ====> Epoch: 90 Average loss: 0.7209\n",
      "2019-04-09 22:47:41,420 root         INFO     Train Epoch: 91 [0/8000 (0%)]\tTotal Loss: 0.802733\n",
      "Reconstruction: 0.716777, Regularization: 0.021042, Discriminator: 0.043241; Generator: 0.021673,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:41,519 root         INFO     Train Epoch: 91 [512/8000 (6%)]\tTotal Loss: 0.764122\n",
      "Reconstruction: 0.677171, Regularization: 0.021991, Discriminator: 0.043306; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:41,617 root         INFO     Train Epoch: 91 [1024/8000 (13%)]\tTotal Loss: 0.718166\n",
      "Reconstruction: 0.631141, Regularization: 0.021975, Discriminator: 0.043398; Generator: 0.021653,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:41,714 root         INFO     Train Epoch: 91 [1536/8000 (19%)]\tTotal Loss: 0.701431\n",
      "Reconstruction: 0.615369, Regularization: 0.021095, Discriminator: 0.043316; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:41,811 root         INFO     Train Epoch: 91 [2048/8000 (26%)]\tTotal Loss: 0.608749\n",
      "Reconstruction: 0.523954, Regularization: 0.019827, Discriminator: 0.043312; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:41,909 root         INFO     Train Epoch: 91 [2560/8000 (32%)]\tTotal Loss: 0.673362\n",
      "Reconstruction: 0.588961, Regularization: 0.019382, Discriminator: 0.043363; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:42,005 root         INFO     Train Epoch: 91 [3072/8000 (38%)]\tTotal Loss: 0.736422\n",
      "Reconstruction: 0.651053, Regularization: 0.020317, Discriminator: 0.043402; Generator: 0.021650,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:42,104 root         INFO     Train Epoch: 91 [3584/8000 (45%)]\tTotal Loss: 0.677719\n",
      "Reconstruction: 0.594349, Regularization: 0.018393, Discriminator: 0.043332; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:42,202 root         INFO     Train Epoch: 91 [4096/8000 (51%)]\tTotal Loss: 0.579132\n",
      "Reconstruction: 0.495054, Regularization: 0.019087, Discriminator: 0.043334; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:42,301 root         INFO     Train Epoch: 91 [4608/8000 (58%)]\tTotal Loss: 0.565260\n",
      "Reconstruction: 0.482915, Regularization: 0.017341, Discriminator: 0.043352; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:42,399 root         INFO     Train Epoch: 91 [5120/8000 (64%)]\tTotal Loss: 0.813089\n",
      "Reconstruction: 0.722672, Regularization: 0.025453, Discriminator: 0.043306; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:42,498 root         INFO     Train Epoch: 91 [5632/8000 (70%)]\tTotal Loss: 0.874249\n",
      "Reconstruction: 0.781688, Regularization: 0.027573, Discriminator: 0.043334; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:42,596 root         INFO     Train Epoch: 91 [6144/8000 (77%)]\tTotal Loss: 0.569977\n",
      "Reconstruction: 0.485150, Regularization: 0.019842, Discriminator: 0.043330; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:42,695 root         INFO     Train Epoch: 91 [6656/8000 (83%)]\tTotal Loss: 0.557835\n",
      "Reconstruction: 0.475649, Regularization: 0.017199, Discriminator: 0.043321; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:42,793 root         INFO     Train Epoch: 91 [7168/8000 (90%)]\tTotal Loss: 0.751602\n",
      "Reconstruction: 0.661675, Regularization: 0.024951, Discriminator: 0.043320; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:42,892 root         INFO     Train Epoch: 91 [7680/8000 (96%)]\tTotal Loss: 0.608868\n",
      "Reconstruction: 0.524999, Regularization: 0.018890, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:42,967 root         INFO     ====> Epoch: 91 Average loss: 0.7139\n",
      "2019-04-09 22:47:42,993 root         INFO     Train Epoch: 92 [0/8000 (0%)]\tTotal Loss: 0.789930\n",
      "Reconstruction: 0.696708, Regularization: 0.028229, Discriminator: 0.043334; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:43,091 root         INFO     Train Epoch: 92 [512/8000 (6%)]\tTotal Loss: 0.659522\n",
      "Reconstruction: 0.571964, Regularization: 0.022569, Discriminator: 0.043328; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:43,188 root         INFO     Train Epoch: 92 [1024/8000 (13%)]\tTotal Loss: 0.807548\n",
      "Reconstruction: 0.716008, Regularization: 0.026587, Discriminator: 0.043292; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:43,286 root         INFO     Train Epoch: 92 [1536/8000 (19%)]\tTotal Loss: 0.592492\n",
      "Reconstruction: 0.509020, Regularization: 0.018492, Discriminator: 0.043317; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:43,384 root         INFO     Train Epoch: 92 [2048/8000 (26%)]\tTotal Loss: 0.532369\n",
      "Reconstruction: 0.451361, Regularization: 0.016041, Discriminator: 0.043311; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:43,481 root         INFO     Train Epoch: 92 [2560/8000 (32%)]\tTotal Loss: 0.908355\n",
      "Reconstruction: 0.809158, Regularization: 0.034187, Discriminator: 0.043341; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:43,578 root         INFO     Train Epoch: 92 [3072/8000 (38%)]\tTotal Loss: 0.801355\n",
      "Reconstruction: 0.711294, Regularization: 0.025101, Discriminator: 0.043285; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:43,675 root         INFO     Train Epoch: 92 [3584/8000 (45%)]\tTotal Loss: 0.364741\n",
      "Reconstruction: 0.289089, Regularization: 0.010591, Discriminator: 0.043391; Generator: 0.021670,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:43,771 root         INFO     Train Epoch: 92 [4096/8000 (51%)]\tTotal Loss: 0.899758\n",
      "Reconstruction: 0.799729, Regularization: 0.034944, Discriminator: 0.043422; Generator: 0.021664,\n",
      "D(x): 0.498, D(G(z)): 0.500\n",
      "2019-04-09 22:47:43,867 root         INFO     Train Epoch: 92 [4608/8000 (58%)]\tTotal Loss: 0.920621\n",
      "Reconstruction: 0.819650, Regularization: 0.035982, Discriminator: 0.043336; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:43,963 root         INFO     Train Epoch: 92 [5120/8000 (64%)]\tTotal Loss: 0.586604\n",
      "Reconstruction: 0.503447, Regularization: 0.018145, Discriminator: 0.043360; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:44,061 root         INFO     Train Epoch: 92 [5632/8000 (70%)]\tTotal Loss: 0.588944\n",
      "Reconstruction: 0.503212, Regularization: 0.020708, Discriminator: 0.043362; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:44,159 root         INFO     Train Epoch: 92 [6144/8000 (77%)]\tTotal Loss: 0.677775\n",
      "Reconstruction: 0.590137, Regularization: 0.022626, Discriminator: 0.043352; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:44,256 root         INFO     Train Epoch: 92 [6656/8000 (83%)]\tTotal Loss: 0.804029\n",
      "Reconstruction: 0.711866, Regularization: 0.027137, Discriminator: 0.043372; Generator: 0.021653,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:44,352 root         INFO     Train Epoch: 92 [7168/8000 (90%)]\tTotal Loss: 0.646301\n",
      "Reconstruction: 0.560239, Regularization: 0.021069, Discriminator: 0.043330; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:44,448 root         INFO     Train Epoch: 92 [7680/8000 (96%)]\tTotal Loss: 0.708500\n",
      "Reconstruction: 0.619306, Regularization: 0.024211, Discriminator: 0.043338; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:44,520 root         INFO     ====> Epoch: 92 Average loss: 0.7161\n",
      "2019-04-09 22:47:44,546 root         INFO     Train Epoch: 93 [0/8000 (0%)]\tTotal Loss: 0.725113\n",
      "Reconstruction: 0.638184, Regularization: 0.021959, Discriminator: 0.043315; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:44,646 root         INFO     Train Epoch: 93 [512/8000 (6%)]\tTotal Loss: 0.526451\n",
      "Reconstruction: 0.446456, Regularization: 0.015008, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:44,745 root         INFO     Train Epoch: 93 [1024/8000 (13%)]\tTotal Loss: 0.478258\n",
      "Reconstruction: 0.400320, Regularization: 0.012939, Discriminator: 0.043335; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:44,843 root         INFO     Train Epoch: 93 [1536/8000 (19%)]\tTotal Loss: 0.608753\n",
      "Reconstruction: 0.527995, Regularization: 0.015756, Discriminator: 0.043344; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:44,941 root         INFO     Train Epoch: 93 [2048/8000 (26%)]\tTotal Loss: 0.761324\n",
      "Reconstruction: 0.670542, Regularization: 0.025797, Discriminator: 0.043329; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:45,039 root         INFO     Train Epoch: 93 [2560/8000 (32%)]\tTotal Loss: 0.866256\n",
      "Reconstruction: 0.775804, Regularization: 0.025466, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:45,137 root         INFO     Train Epoch: 93 [3072/8000 (38%)]\tTotal Loss: 0.498573\n",
      "Reconstruction: 0.416637, Regularization: 0.016960, Discriminator: 0.043308; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:45,236 root         INFO     Train Epoch: 93 [3584/8000 (45%)]\tTotal Loss: 0.816437\n",
      "Reconstruction: 0.728466, Regularization: 0.022991, Discriminator: 0.043318; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:45,334 root         INFO     Train Epoch: 93 [4096/8000 (51%)]\tTotal Loss: 0.748370\n",
      "Reconstruction: 0.659965, Regularization: 0.023412, Discriminator: 0.043320; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:45,431 root         INFO     Train Epoch: 93 [4608/8000 (58%)]\tTotal Loss: 0.506631\n",
      "Reconstruction: 0.430026, Regularization: 0.011610, Discriminator: 0.043336; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:45,528 root         INFO     Train Epoch: 93 [5120/8000 (64%)]\tTotal Loss: 0.898830\n",
      "Reconstruction: 0.801741, Regularization: 0.032115, Discriminator: 0.043308; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:45,626 root         INFO     Train Epoch: 93 [5632/8000 (70%)]\tTotal Loss: 0.751853\n",
      "Reconstruction: 0.655996, Regularization: 0.030956, Discriminator: 0.043237; Generator: 0.021664,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:45,724 root         INFO     Train Epoch: 93 [6144/8000 (77%)]\tTotal Loss: 0.664365\n",
      "Reconstruction: 0.572961, Regularization: 0.026452, Discriminator: 0.043295; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:45,822 root         INFO     Train Epoch: 93 [6656/8000 (83%)]\tTotal Loss: 0.569798\n",
      "Reconstruction: 0.486753, Regularization: 0.017991, Discriminator: 0.043391; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:45,917 root         INFO     Train Epoch: 93 [7168/8000 (90%)]\tTotal Loss: 0.757934\n",
      "Reconstruction: 0.666401, Regularization: 0.026603, Discriminator: 0.043270; Generator: 0.021660,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:46,013 root         INFO     Train Epoch: 93 [7680/8000 (96%)]\tTotal Loss: 0.834969\n",
      "Reconstruction: 0.739281, Regularization: 0.030642, Discriminator: 0.043386; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:46,085 root         INFO     ====> Epoch: 93 Average loss: 0.7211\n",
      "2019-04-09 22:47:46,111 root         INFO     Train Epoch: 94 [0/8000 (0%)]\tTotal Loss: 0.548048\n",
      "Reconstruction: 0.466695, Regularization: 0.016321, Discriminator: 0.043379; Generator: 0.021653,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:46,210 root         INFO     Train Epoch: 94 [512/8000 (6%)]\tTotal Loss: 0.751848\n",
      "Reconstruction: 0.656663, Regularization: 0.030192, Discriminator: 0.043336; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:46,308 root         INFO     Train Epoch: 94 [1024/8000 (13%)]\tTotal Loss: 1.016571\n",
      "Reconstruction: 0.908930, Regularization: 0.042739, Discriminator: 0.043239; Generator: 0.021664,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:46,406 root         INFO     Train Epoch: 94 [1536/8000 (19%)]\tTotal Loss: 0.599181\n",
      "Reconstruction: 0.516040, Regularization: 0.018076, Discriminator: 0.043397; Generator: 0.021669,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:46,505 root         INFO     Train Epoch: 94 [2048/8000 (26%)]\tTotal Loss: 0.506700\n",
      "Reconstruction: 0.423132, Regularization: 0.018652, Discriminator: 0.043257; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:46,603 root         INFO     Train Epoch: 94 [2560/8000 (32%)]\tTotal Loss: 0.692163\n",
      "Reconstruction: 0.605561, Regularization: 0.021603, Discriminator: 0.043338; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:46,700 root         INFO     Train Epoch: 94 [3072/8000 (38%)]\tTotal Loss: 0.764369\n",
      "Reconstruction: 0.675787, Regularization: 0.023582, Discriminator: 0.043346; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:46,798 root         INFO     Train Epoch: 94 [3584/8000 (45%)]\tTotal Loss: 0.616998\n",
      "Reconstruction: 0.532524, Regularization: 0.019495, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:46,896 root         INFO     Train Epoch: 94 [4096/8000 (51%)]\tTotal Loss: 0.630280\n",
      "Reconstruction: 0.545256, Regularization: 0.020062, Discriminator: 0.043304; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:46,996 root         INFO     Train Epoch: 94 [4608/8000 (58%)]\tTotal Loss: 0.746950\n",
      "Reconstruction: 0.657640, Regularization: 0.024325, Discriminator: 0.043327; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:47,096 root         INFO     Train Epoch: 94 [5120/8000 (64%)]\tTotal Loss: 0.682892\n",
      "Reconstruction: 0.590701, Regularization: 0.027230, Discriminator: 0.043302; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:47,195 root         INFO     Train Epoch: 94 [5632/8000 (70%)]\tTotal Loss: 0.552404\n",
      "Reconstruction: 0.470594, Regularization: 0.016832, Discriminator: 0.043313; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:47,292 root         INFO     Train Epoch: 94 [6144/8000 (77%)]\tTotal Loss: 0.660933\n",
      "Reconstruction: 0.571327, Regularization: 0.024617, Discriminator: 0.043317; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:47,390 root         INFO     Train Epoch: 94 [6656/8000 (83%)]\tTotal Loss: 0.436958\n",
      "Reconstruction: 0.360659, Regularization: 0.011303, Discriminator: 0.043328; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:47,488 root         INFO     Train Epoch: 94 [7168/8000 (90%)]\tTotal Loss: 0.631085\n",
      "Reconstruction: 0.545710, Regularization: 0.020403, Discriminator: 0.043299; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:47,586 root         INFO     Train Epoch: 94 [7680/8000 (96%)]\tTotal Loss: 0.622318\n",
      "Reconstruction: 0.536763, Regularization: 0.020598, Discriminator: 0.043286; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:47,661 root         INFO     ====> Epoch: 94 Average loss: 0.7144\n",
      "2019-04-09 22:47:47,687 root         INFO     Train Epoch: 95 [0/8000 (0%)]\tTotal Loss: 0.703489\n",
      "Reconstruction: 0.618239, Regularization: 0.020275, Discriminator: 0.043316; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:47,789 root         INFO     Train Epoch: 95 [512/8000 (6%)]\tTotal Loss: 0.769800\n",
      "Reconstruction: 0.675643, Regularization: 0.029150, Discriminator: 0.043342; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:47,889 root         INFO     Train Epoch: 95 [1024/8000 (13%)]\tTotal Loss: 0.640869\n",
      "Reconstruction: 0.553628, Regularization: 0.022213, Discriminator: 0.043366; Generator: 0.021664,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:47,988 root         INFO     Train Epoch: 95 [1536/8000 (19%)]\tTotal Loss: 0.681097\n",
      "Reconstruction: 0.593867, Regularization: 0.022252, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:48,088 root         INFO     Train Epoch: 95 [2048/8000 (26%)]\tTotal Loss: 1.241602\n",
      "Reconstruction: 1.126414, Regularization: 0.050149, Discriminator: 0.043386; Generator: 0.021654,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:48,188 root         INFO     Train Epoch: 95 [2560/8000 (32%)]\tTotal Loss: 0.587230\n",
      "Reconstruction: 0.504464, Regularization: 0.017808, Discriminator: 0.043300; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:48,287 root         INFO     Train Epoch: 95 [3072/8000 (38%)]\tTotal Loss: 0.795392\n",
      "Reconstruction: 0.701954, Regularization: 0.028478, Discriminator: 0.043298; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:48,386 root         INFO     Train Epoch: 95 [3584/8000 (45%)]\tTotal Loss: 1.087788\n",
      "Reconstruction: 0.990286, Regularization: 0.032520, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:48,486 root         INFO     Train Epoch: 95 [4096/8000 (51%)]\tTotal Loss: 0.869772\n",
      "Reconstruction: 0.779357, Regularization: 0.025412, Discriminator: 0.043343; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:48,585 root         INFO     Train Epoch: 95 [4608/8000 (58%)]\tTotal Loss: 0.989893\n",
      "Reconstruction: 0.891331, Regularization: 0.033567, Discriminator: 0.043331; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:48,683 root         INFO     Train Epoch: 95 [5120/8000 (64%)]\tTotal Loss: 0.874503\n",
      "Reconstruction: 0.778339, Regularization: 0.031215, Discriminator: 0.043292; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:48,781 root         INFO     Train Epoch: 95 [5632/8000 (70%)]\tTotal Loss: 0.636800\n",
      "Reconstruction: 0.551292, Regularization: 0.020543, Discriminator: 0.043306; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:48,879 root         INFO     Train Epoch: 95 [6144/8000 (77%)]\tTotal Loss: 0.849672\n",
      "Reconstruction: 0.757477, Regularization: 0.027206, Discriminator: 0.043333; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:48,976 root         INFO     Train Epoch: 95 [6656/8000 (83%)]\tTotal Loss: 0.637264\n",
      "Reconstruction: 0.548115, Regularization: 0.024179, Discriminator: 0.043309; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:49,074 root         INFO     Train Epoch: 95 [7168/8000 (90%)]\tTotal Loss: 0.799611\n",
      "Reconstruction: 0.709846, Regularization: 0.024734, Discriminator: 0.043372; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:49,172 root         INFO     Train Epoch: 95 [7680/8000 (96%)]\tTotal Loss: 0.568367\n",
      "Reconstruction: 0.483592, Regularization: 0.019805, Discriminator: 0.043314; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:49,246 root         INFO     ====> Epoch: 95 Average loss: 0.7189\n",
      "2019-04-09 22:47:49,272 root         INFO     Train Epoch: 96 [0/8000 (0%)]\tTotal Loss: 0.531108\n",
      "Reconstruction: 0.448504, Regularization: 0.017639, Discriminator: 0.043303; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:49,372 root         INFO     Train Epoch: 96 [512/8000 (6%)]\tTotal Loss: 0.787515\n",
      "Reconstruction: 0.700565, Regularization: 0.021945, Discriminator: 0.043340; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:49,472 root         INFO     Train Epoch: 96 [1024/8000 (13%)]\tTotal Loss: 0.747233\n",
      "Reconstruction: 0.657272, Regularization: 0.024983, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:49,572 root         INFO     Train Epoch: 96 [1536/8000 (19%)]\tTotal Loss: 0.638249\n",
      "Reconstruction: 0.554144, Regularization: 0.019116, Discriminator: 0.043327; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:49,672 root         INFO     Train Epoch: 96 [2048/8000 (26%)]\tTotal Loss: 0.714502\n",
      "Reconstruction: 0.623467, Regularization: 0.026089, Discriminator: 0.043282; Generator: 0.021663,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:49,772 root         INFO     Train Epoch: 96 [2560/8000 (32%)]\tTotal Loss: 0.845011\n",
      "Reconstruction: 0.751454, Regularization: 0.028570, Discriminator: 0.043324; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:49,872 root         INFO     Train Epoch: 96 [3072/8000 (38%)]\tTotal Loss: 0.825762\n",
      "Reconstruction: 0.733822, Regularization: 0.026945, Discriminator: 0.043331; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:49,972 root         INFO     Train Epoch: 96 [3584/8000 (45%)]\tTotal Loss: 1.201021\n",
      "Reconstruction: 1.093712, Regularization: 0.042359, Discriminator: 0.043290; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:50,071 root         INFO     Train Epoch: 96 [4096/8000 (51%)]\tTotal Loss: 0.987213\n",
      "Reconstruction: 0.887708, Regularization: 0.034564, Discriminator: 0.043274; Generator: 0.021667,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:50,169 root         INFO     Train Epoch: 96 [4608/8000 (58%)]\tTotal Loss: 0.748210\n",
      "Reconstruction: 0.661391, Regularization: 0.021810, Discriminator: 0.043343; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:50,268 root         INFO     Train Epoch: 96 [5120/8000 (64%)]\tTotal Loss: 0.678487\n",
      "Reconstruction: 0.591089, Regularization: 0.022382, Discriminator: 0.043349; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:50,365 root         INFO     Train Epoch: 96 [5632/8000 (70%)]\tTotal Loss: 0.641190\n",
      "Reconstruction: 0.558594, Regularization: 0.017568, Discriminator: 0.043373; Generator: 0.021655,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:50,463 root         INFO     Train Epoch: 96 [6144/8000 (77%)]\tTotal Loss: 0.536767\n",
      "Reconstruction: 0.459606, Regularization: 0.012134, Discriminator: 0.043368; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:50,559 root         INFO     Train Epoch: 96 [6656/8000 (83%)]\tTotal Loss: 0.697713\n",
      "Reconstruction: 0.608066, Regularization: 0.024674, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:50,656 root         INFO     Train Epoch: 96 [7168/8000 (90%)]\tTotal Loss: 0.596003\n",
      "Reconstruction: 0.509682, Regularization: 0.021329, Discriminator: 0.043332; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:50,753 root         INFO     Train Epoch: 96 [7680/8000 (96%)]\tTotal Loss: 0.874916\n",
      "Reconstruction: 0.782735, Regularization: 0.027193, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:50,826 root         INFO     ====> Epoch: 96 Average loss: 0.7206\n",
      "2019-04-09 22:47:50,853 root         INFO     Train Epoch: 97 [0/8000 (0%)]\tTotal Loss: 0.495919\n",
      "Reconstruction: 0.413181, Regularization: 0.017790, Discriminator: 0.043291; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:50,953 root         INFO     Train Epoch: 97 [512/8000 (6%)]\tTotal Loss: 0.709790\n",
      "Reconstruction: 0.620025, Regularization: 0.024760, Discriminator: 0.043348; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:51,053 root         INFO     Train Epoch: 97 [1024/8000 (13%)]\tTotal Loss: 0.511500\n",
      "Reconstruction: 0.431150, Regularization: 0.015389, Discriminator: 0.043303; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:51,153 root         INFO     Train Epoch: 97 [1536/8000 (19%)]\tTotal Loss: 0.934890\n",
      "Reconstruction: 0.839531, Regularization: 0.030372, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:51,251 root         INFO     Train Epoch: 97 [2048/8000 (26%)]\tTotal Loss: 0.550406\n",
      "Reconstruction: 0.470570, Regularization: 0.014845, Discriminator: 0.043332; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:51,350 root         INFO     Train Epoch: 97 [2560/8000 (32%)]\tTotal Loss: 0.877191\n",
      "Reconstruction: 0.787421, Regularization: 0.024753, Discriminator: 0.043354; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:51,449 root         INFO     Train Epoch: 97 [3072/8000 (38%)]\tTotal Loss: 0.567255\n",
      "Reconstruction: 0.484045, Regularization: 0.018237, Discriminator: 0.043313; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:51,548 root         INFO     Train Epoch: 97 [3584/8000 (45%)]\tTotal Loss: 0.849852\n",
      "Reconstruction: 0.755878, Regularization: 0.029008, Discriminator: 0.043306; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:51,647 root         INFO     Train Epoch: 97 [4096/8000 (51%)]\tTotal Loss: 0.650672\n",
      "Reconstruction: 0.567475, Regularization: 0.018198, Discriminator: 0.043341; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:51,745 root         INFO     Train Epoch: 97 [4608/8000 (58%)]\tTotal Loss: 0.556571\n",
      "Reconstruction: 0.477919, Regularization: 0.013642, Discriminator: 0.043351; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:51,844 root         INFO     Train Epoch: 97 [5120/8000 (64%)]\tTotal Loss: 0.926910\n",
      "Reconstruction: 0.833609, Regularization: 0.028305, Discriminator: 0.043335; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:51,943 root         INFO     Train Epoch: 97 [5632/8000 (70%)]\tTotal Loss: 0.693679\n",
      "Reconstruction: 0.610144, Regularization: 0.018535, Discriminator: 0.043336; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:52,041 root         INFO     Train Epoch: 97 [6144/8000 (77%)]\tTotal Loss: 0.812733\n",
      "Reconstruction: 0.724538, Regularization: 0.023205, Discriminator: 0.043327; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:52,140 root         INFO     Train Epoch: 97 [6656/8000 (83%)]\tTotal Loss: 0.757334\n",
      "Reconstruction: 0.667735, Regularization: 0.024640, Discriminator: 0.043296; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:52,239 root         INFO     Train Epoch: 97 [7168/8000 (90%)]\tTotal Loss: 0.711198\n",
      "Reconstruction: 0.625736, Regularization: 0.020472, Discriminator: 0.043327; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:52,338 root         INFO     Train Epoch: 97 [7680/8000 (96%)]\tTotal Loss: 0.594499\n",
      "Reconstruction: 0.511830, Regularization: 0.017704, Discriminator: 0.043304; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:52,412 root         INFO     ====> Epoch: 97 Average loss: 0.7150\n",
      "2019-04-09 22:47:52,438 root         INFO     Train Epoch: 98 [0/8000 (0%)]\tTotal Loss: 0.558435\n",
      "Reconstruction: 0.476928, Regularization: 0.016482, Discriminator: 0.043355; Generator: 0.021670,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:52,537 root         INFO     Train Epoch: 98 [512/8000 (6%)]\tTotal Loss: 0.876742\n",
      "Reconstruction: 0.785816, Regularization: 0.025966, Discriminator: 0.043278; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:52,638 root         INFO     Train Epoch: 98 [1024/8000 (13%)]\tTotal Loss: 0.941604\n",
      "Reconstruction: 0.845435, Regularization: 0.031231, Discriminator: 0.043279; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:52,737 root         INFO     Train Epoch: 98 [1536/8000 (19%)]\tTotal Loss: 0.581934\n",
      "Reconstruction: 0.501206, Regularization: 0.015756, Discriminator: 0.043297; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:52,836 root         INFO     Train Epoch: 98 [2048/8000 (26%)]\tTotal Loss: 0.606480\n",
      "Reconstruction: 0.522042, Regularization: 0.019457, Discriminator: 0.043344; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:52,936 root         INFO     Train Epoch: 98 [2560/8000 (32%)]\tTotal Loss: 0.565691\n",
      "Reconstruction: 0.482708, Regularization: 0.018026, Discriminator: 0.043308; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:53,036 root         INFO     Train Epoch: 98 [3072/8000 (38%)]\tTotal Loss: 0.588438\n",
      "Reconstruction: 0.506481, Regularization: 0.016948, Discriminator: 0.043356; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:53,135 root         INFO     Train Epoch: 98 [3584/8000 (45%)]\tTotal Loss: 0.655012\n",
      "Reconstruction: 0.573454, Regularization: 0.016611, Discriminator: 0.043291; Generator: 0.021655,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:53,235 root         INFO     Train Epoch: 98 [4096/8000 (51%)]\tTotal Loss: 0.787530\n",
      "Reconstruction: 0.695228, Regularization: 0.027316, Discriminator: 0.043329; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:53,333 root         INFO     Train Epoch: 98 [4608/8000 (58%)]\tTotal Loss: 0.501564\n",
      "Reconstruction: 0.421494, Regularization: 0.015096, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:53,430 root         INFO     Train Epoch: 98 [5120/8000 (64%)]\tTotal Loss: 0.957088\n",
      "Reconstruction: 0.866374, Regularization: 0.025709, Discriminator: 0.043342; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:53,529 root         INFO     Train Epoch: 98 [5632/8000 (70%)]\tTotal Loss: 0.641296\n",
      "Reconstruction: 0.555222, Regularization: 0.021097, Discriminator: 0.043315; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:53,627 root         INFO     Train Epoch: 98 [6144/8000 (77%)]\tTotal Loss: 0.885385\n",
      "Reconstruction: 0.793537, Regularization: 0.026861, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:53,725 root         INFO     Train Epoch: 98 [6656/8000 (83%)]\tTotal Loss: 0.809311\n",
      "Reconstruction: 0.721266, Regularization: 0.023048, Discriminator: 0.043333; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:53,825 root         INFO     Train Epoch: 98 [7168/8000 (90%)]\tTotal Loss: 0.995989\n",
      "Reconstruction: 0.904324, Regularization: 0.026650, Discriminator: 0.043354; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:53,923 root         INFO     Train Epoch: 98 [7680/8000 (96%)]\tTotal Loss: 0.572306\n",
      "Reconstruction: 0.494809, Regularization: 0.012489, Discriminator: 0.043345; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:53,997 root         INFO     ====> Epoch: 98 Average loss: 0.7213\n",
      "2019-04-09 22:47:54,024 root         INFO     Train Epoch: 99 [0/8000 (0%)]\tTotal Loss: 0.862603\n",
      "Reconstruction: 0.778418, Regularization: 0.019166, Discriminator: 0.043357; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:54,124 root         INFO     Train Epoch: 99 [512/8000 (6%)]\tTotal Loss: 0.770589\n",
      "Reconstruction: 0.684445, Regularization: 0.021152, Discriminator: 0.043326; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:54,224 root         INFO     Train Epoch: 99 [1024/8000 (13%)]\tTotal Loss: 0.738277\n",
      "Reconstruction: 0.647236, Regularization: 0.026061, Discriminator: 0.043318; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:54,324 root         INFO     Train Epoch: 99 [1536/8000 (19%)]\tTotal Loss: 0.543666\n",
      "Reconstruction: 0.462712, Regularization: 0.015955, Discriminator: 0.043334; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:54,425 root         INFO     Train Epoch: 99 [2048/8000 (26%)]\tTotal Loss: 0.935488\n",
      "Reconstruction: 0.840417, Regularization: 0.030103, Discriminator: 0.043307; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:54,525 root         INFO     Train Epoch: 99 [2560/8000 (32%)]\tTotal Loss: 0.666767\n",
      "Reconstruction: 0.579601, Regularization: 0.022207, Discriminator: 0.043295; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:54,625 root         INFO     Train Epoch: 99 [3072/8000 (38%)]\tTotal Loss: 0.767265\n",
      "Reconstruction: 0.673801, Regularization: 0.028503, Discriminator: 0.043296; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:54,724 root         INFO     Train Epoch: 99 [3584/8000 (45%)]\tTotal Loss: 0.540435\n",
      "Reconstruction: 0.462418, Regularization: 0.013030, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:54,824 root         INFO     Train Epoch: 99 [4096/8000 (51%)]\tTotal Loss: 0.829492\n",
      "Reconstruction: 0.737034, Regularization: 0.027494, Discriminator: 0.043292; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:54,923 root         INFO     Train Epoch: 99 [4608/8000 (58%)]\tTotal Loss: 0.714384\n",
      "Reconstruction: 0.623482, Regularization: 0.025930, Discriminator: 0.043312; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:55,023 root         INFO     Train Epoch: 99 [5120/8000 (64%)]\tTotal Loss: 0.623596\n",
      "Reconstruction: 0.541855, Regularization: 0.016753, Discriminator: 0.043327; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:55,122 root         INFO     Train Epoch: 99 [5632/8000 (70%)]\tTotal Loss: 0.943320\n",
      "Reconstruction: 0.847520, Regularization: 0.030821, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:55,222 root         INFO     Train Epoch: 99 [6144/8000 (77%)]\tTotal Loss: 0.848685\n",
      "Reconstruction: 0.760303, Regularization: 0.023401, Discriminator: 0.043326; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:55,322 root         INFO     Train Epoch: 99 [6656/8000 (83%)]\tTotal Loss: 0.755373\n",
      "Reconstruction: 0.668966, Regularization: 0.021418, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:55,421 root         INFO     Train Epoch: 99 [7168/8000 (90%)]\tTotal Loss: 0.576283\n",
      "Reconstruction: 0.491552, Regularization: 0.019754, Discriminator: 0.043321; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:55,520 root         INFO     Train Epoch: 99 [7680/8000 (96%)]\tTotal Loss: 0.694935\n",
      "Reconstruction: 0.610090, Regularization: 0.019871, Discriminator: 0.043314; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:55,595 root         INFO     ====> Epoch: 99 Average loss: 0.7194\n",
      "2019-04-09 22:47:55,621 root         INFO     Train Epoch: 100 [0/8000 (0%)]\tTotal Loss: 0.826730\n",
      "Reconstruction: 0.739732, Regularization: 0.022002, Discriminator: 0.043341; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:55,721 root         INFO     Train Epoch: 100 [512/8000 (6%)]\tTotal Loss: 0.696228\n",
      "Reconstruction: 0.613788, Regularization: 0.017447, Discriminator: 0.043329; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:55,819 root         INFO     Train Epoch: 100 [1024/8000 (13%)]\tTotal Loss: 0.506922\n",
      "Reconstruction: 0.427954, Regularization: 0.013987, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:55,917 root         INFO     Train Epoch: 100 [1536/8000 (19%)]\tTotal Loss: 0.712196\n",
      "Reconstruction: 0.622970, Regularization: 0.024249, Discriminator: 0.043318; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:56,014 root         INFO     Train Epoch: 100 [2048/8000 (26%)]\tTotal Loss: 0.594318\n",
      "Reconstruction: 0.508853, Regularization: 0.020479, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:56,113 root         INFO     Train Epoch: 100 [2560/8000 (32%)]\tTotal Loss: 0.688351\n",
      "Reconstruction: 0.605579, Regularization: 0.017792, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:56,211 root         INFO     Train Epoch: 100 [3072/8000 (38%)]\tTotal Loss: 0.474251\n",
      "Reconstruction: 0.393880, Regularization: 0.015386, Discriminator: 0.043323; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:56,309 root         INFO     Train Epoch: 100 [3584/8000 (45%)]\tTotal Loss: 0.823251\n",
      "Reconstruction: 0.733402, Regularization: 0.024867, Discriminator: 0.043318; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:56,407 root         INFO     Train Epoch: 100 [4096/8000 (51%)]\tTotal Loss: 0.846433\n",
      "Reconstruction: 0.755200, Regularization: 0.026243, Discriminator: 0.043328; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:56,505 root         INFO     Train Epoch: 100 [4608/8000 (58%)]\tTotal Loss: 0.520403\n",
      "Reconstruction: 0.436310, Regularization: 0.019106, Discriminator: 0.043330; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:56,603 root         INFO     Train Epoch: 100 [5120/8000 (64%)]\tTotal Loss: 0.768770\n",
      "Reconstruction: 0.679053, Regularization: 0.024723, Discriminator: 0.043328; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:56,700 root         INFO     Train Epoch: 100 [5632/8000 (70%)]\tTotal Loss: 0.872662\n",
      "Reconstruction: 0.784271, Regularization: 0.023421, Discriminator: 0.043316; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:56,798 root         INFO     Train Epoch: 100 [6144/8000 (77%)]\tTotal Loss: 0.544631\n",
      "Reconstruction: 0.459367, Regularization: 0.020261, Discriminator: 0.043343; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:56,896 root         INFO     Train Epoch: 100 [6656/8000 (83%)]\tTotal Loss: 0.702254\n",
      "Reconstruction: 0.621349, Regularization: 0.015903, Discriminator: 0.043342; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:56,994 root         INFO     Train Epoch: 100 [7168/8000 (90%)]\tTotal Loss: 0.895909\n",
      "Reconstruction: 0.798092, Regularization: 0.032781, Discriminator: 0.043363; Generator: 0.021673,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:57,092 root         INFO     Train Epoch: 100 [7680/8000 (96%)]\tTotal Loss: 0.650643\n",
      "Reconstruction: 0.564297, Regularization: 0.021358, Discriminator: 0.043331; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:57,166 root         INFO     ====> Epoch: 100 Average loss: 0.7157\n",
      "2019-04-09 22:47:57,192 root         INFO     Train Epoch: 101 [0/8000 (0%)]\tTotal Loss: 0.976680\n",
      "Reconstruction: 0.882902, Regularization: 0.028815, Discriminator: 0.043310; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:57,293 root         INFO     Train Epoch: 101 [512/8000 (6%)]\tTotal Loss: 0.467169\n",
      "Reconstruction: 0.390314, Regularization: 0.011920, Discriminator: 0.043273; Generator: 0.021662,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:57,394 root         INFO     Train Epoch: 101 [1024/8000 (13%)]\tTotal Loss: 0.619272\n",
      "Reconstruction: 0.532304, Regularization: 0.021939, Discriminator: 0.043361; Generator: 0.021668,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:57,494 root         INFO     Train Epoch: 101 [1536/8000 (19%)]\tTotal Loss: 0.674993\n",
      "Reconstruction: 0.590474, Regularization: 0.019531, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:57,595 root         INFO     Train Epoch: 101 [2048/8000 (26%)]\tTotal Loss: 0.725487\n",
      "Reconstruction: 0.637717, Regularization: 0.022760, Discriminator: 0.043347; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:57,695 root         INFO     Train Epoch: 101 [2560/8000 (32%)]\tTotal Loss: 0.781007\n",
      "Reconstruction: 0.691644, Regularization: 0.024379, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:57,796 root         INFO     Train Epoch: 101 [3072/8000 (38%)]\tTotal Loss: 0.608231\n",
      "Reconstruction: 0.523748, Regularization: 0.019494, Discriminator: 0.043336; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:57,896 root         INFO     Train Epoch: 101 [3584/8000 (45%)]\tTotal Loss: 0.699392\n",
      "Reconstruction: 0.612247, Regularization: 0.022152, Discriminator: 0.043338; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:57,996 root         INFO     Train Epoch: 101 [4096/8000 (51%)]\tTotal Loss: 0.482983\n",
      "Reconstruction: 0.406566, Regularization: 0.011443, Discriminator: 0.043314; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:58,095 root         INFO     Train Epoch: 101 [4608/8000 (58%)]\tTotal Loss: 0.865298\n",
      "Reconstruction: 0.771155, Regularization: 0.029152, Discriminator: 0.043327; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:58,195 root         INFO     Train Epoch: 101 [5120/8000 (64%)]\tTotal Loss: 1.266659\n",
      "Reconstruction: 1.161131, Regularization: 0.040545, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:58,294 root         INFO     Train Epoch: 101 [5632/8000 (70%)]\tTotal Loss: 0.621186\n",
      "Reconstruction: 0.535063, Regularization: 0.021137, Discriminator: 0.043320; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:58,393 root         INFO     Train Epoch: 101 [6144/8000 (77%)]\tTotal Loss: 0.671652\n",
      "Reconstruction: 0.588723, Regularization: 0.017943, Discriminator: 0.043320; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:58,492 root         INFO     Train Epoch: 101 [6656/8000 (83%)]\tTotal Loss: 0.700287\n",
      "Reconstruction: 0.611656, Regularization: 0.023642, Discriminator: 0.043331; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:58,590 root         INFO     Train Epoch: 101 [7168/8000 (90%)]\tTotal Loss: 1.149122\n",
      "Reconstruction: 1.051261, Regularization: 0.032900, Discriminator: 0.043303; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:58,688 root         INFO     Train Epoch: 101 [7680/8000 (96%)]\tTotal Loss: 0.699957\n",
      "Reconstruction: 0.615183, Regularization: 0.019787, Discriminator: 0.043316; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:58,760 root         INFO     ====> Epoch: 101 Average loss: 0.7205\n",
      "2019-04-09 22:47:58,787 root         INFO     Train Epoch: 102 [0/8000 (0%)]\tTotal Loss: 0.583722\n",
      "Reconstruction: 0.501210, Regularization: 0.017551, Discriminator: 0.043295; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:58,887 root         INFO     Train Epoch: 102 [512/8000 (6%)]\tTotal Loss: 0.801110\n",
      "Reconstruction: 0.709891, Regularization: 0.026222, Discriminator: 0.043329; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:58,986 root         INFO     Train Epoch: 102 [1024/8000 (13%)]\tTotal Loss: 0.831280\n",
      "Reconstruction: 0.745335, Regularization: 0.021003, Discriminator: 0.043284; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:47:59,084 root         INFO     Train Epoch: 102 [1536/8000 (19%)]\tTotal Loss: 0.602422\n",
      "Reconstruction: 0.518310, Regularization: 0.019104, Discriminator: 0.043354; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:59,183 root         INFO     Train Epoch: 102 [2048/8000 (26%)]\tTotal Loss: 0.624964\n",
      "Reconstruction: 0.542161, Regularization: 0.017799, Discriminator: 0.043345; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:59,282 root         INFO     Train Epoch: 102 [2560/8000 (32%)]\tTotal Loss: 0.731686\n",
      "Reconstruction: 0.650128, Regularization: 0.016561, Discriminator: 0.043329; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:59,380 root         INFO     Train Epoch: 102 [3072/8000 (38%)]\tTotal Loss: 0.662506\n",
      "Reconstruction: 0.575796, Regularization: 0.021692, Discriminator: 0.043359; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:47:59,478 root         INFO     Train Epoch: 102 [3584/8000 (45%)]\tTotal Loss: 0.699519\n",
      "Reconstruction: 0.616701, Regularization: 0.017851, Discriminator: 0.043304; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:59,574 root         INFO     Train Epoch: 102 [4096/8000 (51%)]\tTotal Loss: 0.754288\n",
      "Reconstruction: 0.668812, Regularization: 0.020468, Discriminator: 0.043346; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:59,672 root         INFO     Train Epoch: 102 [4608/8000 (58%)]\tTotal Loss: 1.099809\n",
      "Reconstruction: 0.997514, Regularization: 0.037303, Discriminator: 0.043336; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:59,770 root         INFO     Train Epoch: 102 [5120/8000 (64%)]\tTotal Loss: 0.567001\n",
      "Reconstruction: 0.485398, Regularization: 0.016629, Discriminator: 0.043319; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:59,866 root         INFO     Train Epoch: 102 [5632/8000 (70%)]\tTotal Loss: 0.890650\n",
      "Reconstruction: 0.795371, Regularization: 0.030291, Discriminator: 0.043324; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:47:59,964 root         INFO     Train Epoch: 102 [6144/8000 (77%)]\tTotal Loss: 0.766575\n",
      "Reconstruction: 0.677683, Regularization: 0.023916, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:00,060 root         INFO     Train Epoch: 102 [6656/8000 (83%)]\tTotal Loss: 0.883031\n",
      "Reconstruction: 0.787876, Regularization: 0.030155, Discriminator: 0.043335; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:00,156 root         INFO     Train Epoch: 102 [7168/8000 (90%)]\tTotal Loss: 0.741749\n",
      "Reconstruction: 0.655179, Regularization: 0.021587, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:00,254 root         INFO     Train Epoch: 102 [7680/8000 (96%)]\tTotal Loss: 0.653116\n",
      "Reconstruction: 0.566328, Regularization: 0.021786, Discriminator: 0.043334; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:00,327 root         INFO     ====> Epoch: 102 Average loss: 0.7167\n",
      "2019-04-09 22:48:00,353 root         INFO     Train Epoch: 103 [0/8000 (0%)]\tTotal Loss: 0.799488\n",
      "Reconstruction: 0.708331, Regularization: 0.026179, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:00,453 root         INFO     Train Epoch: 103 [512/8000 (6%)]\tTotal Loss: 0.658333\n",
      "Reconstruction: 0.576156, Regularization: 0.017206, Discriminator: 0.043313; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:00,552 root         INFO     Train Epoch: 103 [1024/8000 (13%)]\tTotal Loss: 0.788923\n",
      "Reconstruction: 0.696786, Regularization: 0.027146, Discriminator: 0.043328; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:00,651 root         INFO     Train Epoch: 103 [1536/8000 (19%)]\tTotal Loss: 0.773897\n",
      "Reconstruction: 0.682772, Regularization: 0.026131, Discriminator: 0.043333; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:00,750 root         INFO     Train Epoch: 103 [2048/8000 (26%)]\tTotal Loss: 0.593560\n",
      "Reconstruction: 0.511116, Regularization: 0.017441, Discriminator: 0.043343; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:00,850 root         INFO     Train Epoch: 103 [2560/8000 (32%)]\tTotal Loss: 0.552094\n",
      "Reconstruction: 0.470909, Regularization: 0.016199, Discriminator: 0.043328; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:00,948 root         INFO     Train Epoch: 103 [3072/8000 (38%)]\tTotal Loss: 0.903026\n",
      "Reconstruction: 0.801834, Regularization: 0.036170, Discriminator: 0.043359; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:01,048 root         INFO     Train Epoch: 103 [3584/8000 (45%)]\tTotal Loss: 0.697271\n",
      "Reconstruction: 0.608144, Regularization: 0.024139, Discriminator: 0.043327; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:01,149 root         INFO     Train Epoch: 103 [4096/8000 (51%)]\tTotal Loss: 0.921992\n",
      "Reconstruction: 0.825024, Regularization: 0.031972, Discriminator: 0.043332; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:01,248 root         INFO     Train Epoch: 103 [4608/8000 (58%)]\tTotal Loss: 0.588062\n",
      "Reconstruction: 0.502479, Regularization: 0.020593, Discriminator: 0.043333; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:01,348 root         INFO     Train Epoch: 103 [5120/8000 (64%)]\tTotal Loss: 1.000064\n",
      "Reconstruction: 0.901009, Regularization: 0.034069, Discriminator: 0.043328; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:01,448 root         INFO     Train Epoch: 103 [5632/8000 (70%)]\tTotal Loss: 0.656012\n",
      "Reconstruction: 0.571042, Regularization: 0.019988, Discriminator: 0.043313; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:01,547 root         INFO     Train Epoch: 103 [6144/8000 (77%)]\tTotal Loss: 0.724631\n",
      "Reconstruction: 0.633233, Regularization: 0.026406, Discriminator: 0.043332; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:01,645 root         INFO     Train Epoch: 103 [6656/8000 (83%)]\tTotal Loss: 0.784148\n",
      "Reconstruction: 0.693730, Regularization: 0.025450, Discriminator: 0.043314; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:01,744 root         INFO     Train Epoch: 103 [7168/8000 (90%)]\tTotal Loss: 0.911504\n",
      "Reconstruction: 0.811367, Regularization: 0.035140, Discriminator: 0.043342; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:01,842 root         INFO     Train Epoch: 103 [7680/8000 (96%)]\tTotal Loss: 0.630240\n",
      "Reconstruction: 0.547322, Regularization: 0.017942, Discriminator: 0.043311; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:01,917 root         INFO     ====> Epoch: 103 Average loss: 0.7175\n",
      "2019-04-09 22:48:01,943 root         INFO     Train Epoch: 104 [0/8000 (0%)]\tTotal Loss: 0.847437\n",
      "Reconstruction: 0.754053, Regularization: 0.028366, Discriminator: 0.043344; Generator: 0.021674,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:02,044 root         INFO     Train Epoch: 104 [512/8000 (6%)]\tTotal Loss: 0.568190\n",
      "Reconstruction: 0.485843, Regularization: 0.017360, Discriminator: 0.043322; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:02,143 root         INFO     Train Epoch: 104 [1024/8000 (13%)]\tTotal Loss: 0.584479\n",
      "Reconstruction: 0.499548, Regularization: 0.019939, Discriminator: 0.043330; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:02,242 root         INFO     Train Epoch: 104 [1536/8000 (19%)]\tTotal Loss: 0.620008\n",
      "Reconstruction: 0.538668, Regularization: 0.016368, Discriminator: 0.043315; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:02,341 root         INFO     Train Epoch: 104 [2048/8000 (26%)]\tTotal Loss: 0.687485\n",
      "Reconstruction: 0.600657, Regularization: 0.021851, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:02,440 root         INFO     Train Epoch: 104 [2560/8000 (32%)]\tTotal Loss: 0.609940\n",
      "Reconstruction: 0.527210, Regularization: 0.017744, Discriminator: 0.043329; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:02,538 root         INFO     Train Epoch: 104 [3072/8000 (38%)]\tTotal Loss: 0.747343\n",
      "Reconstruction: 0.661129, Regularization: 0.021242, Discriminator: 0.043310; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:02,636 root         INFO     Train Epoch: 104 [3584/8000 (45%)]\tTotal Loss: 0.533393\n",
      "Reconstruction: 0.451232, Regularization: 0.017169, Discriminator: 0.043331; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:02,735 root         INFO     Train Epoch: 104 [4096/8000 (51%)]\tTotal Loss: 0.576738\n",
      "Reconstruction: 0.495571, Regularization: 0.016184, Discriminator: 0.043315; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:02,833 root         INFO     Train Epoch: 104 [4608/8000 (58%)]\tTotal Loss: 0.719316\n",
      "Reconstruction: 0.636364, Regularization: 0.017973, Discriminator: 0.043323; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:02,931 root         INFO     Train Epoch: 104 [5120/8000 (64%)]\tTotal Loss: 0.643473\n",
      "Reconstruction: 0.556451, Regularization: 0.022029, Discriminator: 0.043330; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:03,029 root         INFO     Train Epoch: 104 [5632/8000 (70%)]\tTotal Loss: 0.806031\n",
      "Reconstruction: 0.709439, Regularization: 0.031585, Discriminator: 0.043346; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:03,128 root         INFO     Train Epoch: 104 [6144/8000 (77%)]\tTotal Loss: 0.966556\n",
      "Reconstruction: 0.869629, Regularization: 0.031946, Discriminator: 0.043317; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:03,226 root         INFO     Train Epoch: 104 [6656/8000 (83%)]\tTotal Loss: 0.792666\n",
      "Reconstruction: 0.702917, Regularization: 0.024776, Discriminator: 0.043317; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:03,324 root         INFO     Train Epoch: 104 [7168/8000 (90%)]\tTotal Loss: 0.564600\n",
      "Reconstruction: 0.480791, Regularization: 0.018818, Discriminator: 0.043327; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:03,423 root         INFO     Train Epoch: 104 [7680/8000 (96%)]\tTotal Loss: 0.602512\n",
      "Reconstruction: 0.522884, Regularization: 0.014664, Discriminator: 0.043309; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:03,497 root         INFO     ====> Epoch: 104 Average loss: 0.7188\n",
      "2019-04-09 22:48:03,523 root         INFO     Train Epoch: 105 [0/8000 (0%)]\tTotal Loss: 0.836217\n",
      "Reconstruction: 0.744378, Regularization: 0.026864, Discriminator: 0.043312; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:03,625 root         INFO     Train Epoch: 105 [512/8000 (6%)]\tTotal Loss: 0.676763\n",
      "Reconstruction: 0.592337, Regularization: 0.019445, Discriminator: 0.043317; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:03,726 root         INFO     Train Epoch: 105 [1024/8000 (13%)]\tTotal Loss: 0.654574\n",
      "Reconstruction: 0.571610, Regularization: 0.017983, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:03,827 root         INFO     Train Epoch: 105 [1536/8000 (19%)]\tTotal Loss: 0.839734\n",
      "Reconstruction: 0.747003, Regularization: 0.027745, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:03,928 root         INFO     Train Epoch: 105 [2048/8000 (26%)]\tTotal Loss: 0.732709\n",
      "Reconstruction: 0.644929, Regularization: 0.022813, Discriminator: 0.043315; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:04,028 root         INFO     Train Epoch: 105 [2560/8000 (32%)]\tTotal Loss: 0.580543\n",
      "Reconstruction: 0.497550, Regularization: 0.018014, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:04,129 root         INFO     Train Epoch: 105 [3072/8000 (38%)]\tTotal Loss: 0.413068\n",
      "Reconstruction: 0.333858, Regularization: 0.014219, Discriminator: 0.043328; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:04,230 root         INFO     Train Epoch: 105 [3584/8000 (45%)]\tTotal Loss: 0.780194\n",
      "Reconstruction: 0.693007, Regularization: 0.022218, Discriminator: 0.043316; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:04,330 root         INFO     Train Epoch: 105 [4096/8000 (51%)]\tTotal Loss: 0.931577\n",
      "Reconstruction: 0.833879, Regularization: 0.032719, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:04,431 root         INFO     Train Epoch: 105 [4608/8000 (58%)]\tTotal Loss: 0.456866\n",
      "Reconstruction: 0.378175, Regularization: 0.013711, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:04,531 root         INFO     Train Epoch: 105 [5120/8000 (64%)]\tTotal Loss: 0.900855\n",
      "Reconstruction: 0.809306, Regularization: 0.026581, Discriminator: 0.043313; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:04,631 root         INFO     Train Epoch: 105 [5632/8000 (70%)]\tTotal Loss: 0.609529\n",
      "Reconstruction: 0.522745, Regularization: 0.021793, Discriminator: 0.043333; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:04,730 root         INFO     Train Epoch: 105 [6144/8000 (77%)]\tTotal Loss: 1.051261\n",
      "Reconstruction: 0.955794, Regularization: 0.030487, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:04,829 root         INFO     Train Epoch: 105 [6656/8000 (83%)]\tTotal Loss: 0.769079\n",
      "Reconstruction: 0.681802, Regularization: 0.022296, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:04,928 root         INFO     Train Epoch: 105 [7168/8000 (90%)]\tTotal Loss: 0.908938\n",
      "Reconstruction: 0.806104, Regularization: 0.037839, Discriminator: 0.043330; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:05,027 root         INFO     Train Epoch: 105 [7680/8000 (96%)]\tTotal Loss: 0.680654\n",
      "Reconstruction: 0.591460, Regularization: 0.024213, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:05,101 root         INFO     ====> Epoch: 105 Average loss: 0.7163\n",
      "2019-04-09 22:48:05,128 root         INFO     Train Epoch: 106 [0/8000 (0%)]\tTotal Loss: 0.828484\n",
      "Reconstruction: 0.729578, Regularization: 0.033923, Discriminator: 0.043327; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:05,227 root         INFO     Train Epoch: 106 [512/8000 (6%)]\tTotal Loss: 0.626730\n",
      "Reconstruction: 0.543837, Regularization: 0.017916, Discriminator: 0.043314; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:05,327 root         INFO     Train Epoch: 106 [1024/8000 (13%)]\tTotal Loss: 0.642459\n",
      "Reconstruction: 0.558425, Regularization: 0.019062, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:05,427 root         INFO     Train Epoch: 106 [1536/8000 (19%)]\tTotal Loss: 0.712640\n",
      "Reconstruction: 0.626895, Regularization: 0.020766, Discriminator: 0.043320; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:05,526 root         INFO     Train Epoch: 106 [2048/8000 (26%)]\tTotal Loss: 0.673560\n",
      "Reconstruction: 0.588816, Regularization: 0.019753, Discriminator: 0.043329; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:05,625 root         INFO     Train Epoch: 106 [2560/8000 (32%)]\tTotal Loss: 0.526753\n",
      "Reconstruction: 0.446272, Regularization: 0.015498, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:05,724 root         INFO     Train Epoch: 106 [3072/8000 (38%)]\tTotal Loss: 0.829280\n",
      "Reconstruction: 0.731934, Regularization: 0.032367, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:05,824 root         INFO     Train Epoch: 106 [3584/8000 (45%)]\tTotal Loss: 0.744541\n",
      "Reconstruction: 0.652113, Regularization: 0.027448, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:05,924 root         INFO     Train Epoch: 106 [4096/8000 (51%)]\tTotal Loss: 0.686958\n",
      "Reconstruction: 0.600973, Regularization: 0.021003, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:06,023 root         INFO     Train Epoch: 106 [4608/8000 (58%)]\tTotal Loss: 0.554043\n",
      "Reconstruction: 0.469476, Regularization: 0.019593, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:06,123 root         INFO     Train Epoch: 106 [5120/8000 (64%)]\tTotal Loss: 0.662729\n",
      "Reconstruction: 0.580054, Regularization: 0.017685, Discriminator: 0.043329; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:06,223 root         INFO     Train Epoch: 106 [5632/8000 (70%)]\tTotal Loss: 0.850122\n",
      "Reconstruction: 0.759402, Regularization: 0.025735, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:06,321 root         INFO     Train Epoch: 106 [6144/8000 (77%)]\tTotal Loss: 0.821355\n",
      "Reconstruction: 0.732619, Regularization: 0.023714, Discriminator: 0.043361; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:06,418 root         INFO     Train Epoch: 106 [6656/8000 (83%)]\tTotal Loss: 0.597872\n",
      "Reconstruction: 0.516386, Regularization: 0.016497, Discriminator: 0.043332; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:06,516 root         INFO     Train Epoch: 106 [7168/8000 (90%)]\tTotal Loss: 0.504971\n",
      "Reconstruction: 0.422419, Regularization: 0.017568, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:06,614 root         INFO     Train Epoch: 106 [7680/8000 (96%)]\tTotal Loss: 0.655067\n",
      "Reconstruction: 0.568464, Regularization: 0.021609, Discriminator: 0.043332; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:06,689 root         INFO     ====> Epoch: 106 Average loss: 0.7180\n",
      "2019-04-09 22:48:06,715 root         INFO     Train Epoch: 107 [0/8000 (0%)]\tTotal Loss: 0.998060\n",
      "Reconstruction: 0.905407, Regularization: 0.027666, Discriminator: 0.043331; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:06,815 root         INFO     Train Epoch: 107 [512/8000 (6%)]\tTotal Loss: 0.781506\n",
      "Reconstruction: 0.694462, Regularization: 0.022050, Discriminator: 0.043333; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:06,914 root         INFO     Train Epoch: 107 [1024/8000 (13%)]\tTotal Loss: 0.603468\n",
      "Reconstruction: 0.520439, Regularization: 0.018044, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:07,014 root         INFO     Train Epoch: 107 [1536/8000 (19%)]\tTotal Loss: 0.887834\n",
      "Reconstruction: 0.794036, Regularization: 0.028812, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:07,113 root         INFO     Train Epoch: 107 [2048/8000 (26%)]\tTotal Loss: 0.539518\n",
      "Reconstruction: 0.458270, Regularization: 0.016265, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:07,212 root         INFO     Train Epoch: 107 [2560/8000 (32%)]\tTotal Loss: 0.710696\n",
      "Reconstruction: 0.620569, Regularization: 0.025147, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:07,310 root         INFO     Train Epoch: 107 [3072/8000 (38%)]\tTotal Loss: 0.753733\n",
      "Reconstruction: 0.664615, Regularization: 0.024137, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:07,409 root         INFO     Train Epoch: 107 [3584/8000 (45%)]\tTotal Loss: 0.761698\n",
      "Reconstruction: 0.669190, Regularization: 0.027527, Discriminator: 0.043316; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:07,507 root         INFO     Train Epoch: 107 [4096/8000 (51%)]\tTotal Loss: 0.640416\n",
      "Reconstruction: 0.552713, Regularization: 0.022728, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:07,606 root         INFO     Train Epoch: 107 [4608/8000 (58%)]\tTotal Loss: 0.480017\n",
      "Reconstruction: 0.402784, Regularization: 0.012246, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:07,705 root         INFO     Train Epoch: 107 [5120/8000 (64%)]\tTotal Loss: 0.829668\n",
      "Reconstruction: 0.736264, Regularization: 0.028418, Discriminator: 0.043326; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:07,804 root         INFO     Train Epoch: 107 [5632/8000 (70%)]\tTotal Loss: 0.831928\n",
      "Reconstruction: 0.744726, Regularization: 0.022198, Discriminator: 0.043342; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:07,902 root         INFO     Train Epoch: 107 [6144/8000 (77%)]\tTotal Loss: 0.624854\n",
      "Reconstruction: 0.540861, Regularization: 0.019007, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:08,000 root         INFO     Train Epoch: 107 [6656/8000 (83%)]\tTotal Loss: 0.590824\n",
      "Reconstruction: 0.511036, Regularization: 0.014794, Discriminator: 0.043335; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:08,099 root         INFO     Train Epoch: 107 [7168/8000 (90%)]\tTotal Loss: 0.671559\n",
      "Reconstruction: 0.584314, Regularization: 0.022262, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:08,197 root         INFO     Train Epoch: 107 [7680/8000 (96%)]\tTotal Loss: 0.628308\n",
      "Reconstruction: 0.544542, Regularization: 0.018781, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:08,271 root         INFO     ====> Epoch: 107 Average loss: 0.7175\n",
      "2019-04-09 22:48:08,297 root         INFO     Train Epoch: 108 [0/8000 (0%)]\tTotal Loss: 0.515605\n",
      "Reconstruction: 0.436998, Regularization: 0.013618, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:08,397 root         INFO     Train Epoch: 108 [512/8000 (6%)]\tTotal Loss: 0.475610\n",
      "Reconstruction: 0.393704, Regularization: 0.016936, Discriminator: 0.043309; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:08,496 root         INFO     Train Epoch: 108 [1024/8000 (13%)]\tTotal Loss: 0.687740\n",
      "Reconstruction: 0.602650, Regularization: 0.020101, Discriminator: 0.043329; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:08,595 root         INFO     Train Epoch: 108 [1536/8000 (19%)]\tTotal Loss: 0.752291\n",
      "Reconstruction: 0.663531, Regularization: 0.023772, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:08,694 root         INFO     Train Epoch: 108 [2048/8000 (26%)]\tTotal Loss: 0.626760\n",
      "Reconstruction: 0.540301, Regularization: 0.021484, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:08,793 root         INFO     Train Epoch: 108 [2560/8000 (32%)]\tTotal Loss: 0.734693\n",
      "Reconstruction: 0.644136, Regularization: 0.025580, Discriminator: 0.043315; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:08,892 root         INFO     Train Epoch: 108 [3072/8000 (38%)]\tTotal Loss: 0.828669\n",
      "Reconstruction: 0.735584, Regularization: 0.028107, Discriminator: 0.043314; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:08,991 root         INFO     Train Epoch: 108 [3584/8000 (45%)]\tTotal Loss: 0.876049\n",
      "Reconstruction: 0.787489, Regularization: 0.023566, Discriminator: 0.043337; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:09,090 root         INFO     Train Epoch: 108 [4096/8000 (51%)]\tTotal Loss: 0.519821\n",
      "Reconstruction: 0.437613, Regularization: 0.017235, Discriminator: 0.043310; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:09,189 root         INFO     Train Epoch: 108 [4608/8000 (58%)]\tTotal Loss: 0.589360\n",
      "Reconstruction: 0.504666, Regularization: 0.019715, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:09,288 root         INFO     Train Epoch: 108 [5120/8000 (64%)]\tTotal Loss: 0.767872\n",
      "Reconstruction: 0.677178, Regularization: 0.025710, Discriminator: 0.043324; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:09,388 root         INFO     Train Epoch: 108 [5632/8000 (70%)]\tTotal Loss: 0.584318\n",
      "Reconstruction: 0.503515, Regularization: 0.015812, Discriminator: 0.043332; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:09,487 root         INFO     Train Epoch: 108 [6144/8000 (77%)]\tTotal Loss: 0.690347\n",
      "Reconstruction: 0.604221, Regularization: 0.021133, Discriminator: 0.043333; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:09,586 root         INFO     Train Epoch: 108 [6656/8000 (83%)]\tTotal Loss: 0.595265\n",
      "Reconstruction: 0.512847, Regularization: 0.017432, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:09,686 root         INFO     Train Epoch: 108 [7168/8000 (90%)]\tTotal Loss: 0.636063\n",
      "Reconstruction: 0.550964, Regularization: 0.020117, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:09,785 root         INFO     Train Epoch: 108 [7680/8000 (96%)]\tTotal Loss: 0.544719\n",
      "Reconstruction: 0.465545, Regularization: 0.014184, Discriminator: 0.043330; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:09,859 root         INFO     ====> Epoch: 108 Average loss: 0.7177\n",
      "2019-04-09 22:48:09,885 root         INFO     Train Epoch: 109 [0/8000 (0%)]\tTotal Loss: 0.612716\n",
      "Reconstruction: 0.531569, Regularization: 0.016150, Discriminator: 0.043335; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:09,985 root         INFO     Train Epoch: 109 [512/8000 (6%)]\tTotal Loss: 0.755555\n",
      "Reconstruction: 0.664833, Regularization: 0.025746, Discriminator: 0.043313; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:10,085 root         INFO     Train Epoch: 109 [1024/8000 (13%)]\tTotal Loss: 0.481045\n",
      "Reconstruction: 0.398540, Regularization: 0.017536, Discriminator: 0.043310; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:10,184 root         INFO     Train Epoch: 109 [1536/8000 (19%)]\tTotal Loss: 0.645389\n",
      "Reconstruction: 0.553289, Regularization: 0.027148, Discriminator: 0.043293; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:10,283 root         INFO     Train Epoch: 109 [2048/8000 (26%)]\tTotal Loss: 0.662897\n",
      "Reconstruction: 0.575283, Regularization: 0.022639, Discriminator: 0.043314; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:10,383 root         INFO     Train Epoch: 109 [2560/8000 (32%)]\tTotal Loss: 0.920291\n",
      "Reconstruction: 0.821061, Regularization: 0.034262, Discriminator: 0.043310; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:10,481 root         INFO     Train Epoch: 109 [3072/8000 (38%)]\tTotal Loss: 0.811504\n",
      "Reconstruction: 0.719762, Regularization: 0.026762, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:10,580 root         INFO     Train Epoch: 109 [3584/8000 (45%)]\tTotal Loss: 0.587982\n",
      "Reconstruction: 0.501861, Regularization: 0.021158, Discriminator: 0.043301; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:10,679 root         INFO     Train Epoch: 109 [4096/8000 (51%)]\tTotal Loss: 0.681344\n",
      "Reconstruction: 0.595556, Regularization: 0.020805, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:10,778 root         INFO     Train Epoch: 109 [4608/8000 (58%)]\tTotal Loss: 0.562133\n",
      "Reconstruction: 0.477682, Regularization: 0.019485, Discriminator: 0.043304; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:10,877 root         INFO     Train Epoch: 109 [5120/8000 (64%)]\tTotal Loss: 0.686040\n",
      "Reconstruction: 0.597621, Regularization: 0.023442, Discriminator: 0.043313; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:10,975 root         INFO     Train Epoch: 109 [5632/8000 (70%)]\tTotal Loss: 0.639868\n",
      "Reconstruction: 0.555633, Regularization: 0.019249, Discriminator: 0.043327; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:11,074 root         INFO     Train Epoch: 109 [6144/8000 (77%)]\tTotal Loss: 0.865774\n",
      "Reconstruction: 0.773355, Regularization: 0.027434, Discriminator: 0.043327; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:11,172 root         INFO     Train Epoch: 109 [6656/8000 (83%)]\tTotal Loss: 0.539121\n",
      "Reconstruction: 0.456770, Regularization: 0.017387, Discriminator: 0.043303; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:11,270 root         INFO     Train Epoch: 109 [7168/8000 (90%)]\tTotal Loss: 0.487551\n",
      "Reconstruction: 0.405511, Regularization: 0.017078, Discriminator: 0.043304; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:11,368 root         INFO     Train Epoch: 109 [7680/8000 (96%)]\tTotal Loss: 0.745198\n",
      "Reconstruction: 0.657565, Regularization: 0.022647, Discriminator: 0.043329; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:11,441 root         INFO     ====> Epoch: 109 Average loss: 0.7171\n",
      "2019-04-09 22:48:11,467 root         INFO     Train Epoch: 110 [0/8000 (0%)]\tTotal Loss: 0.794100\n",
      "Reconstruction: 0.701596, Regularization: 0.027531, Discriminator: 0.043314; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:11,564 root         INFO     Train Epoch: 110 [512/8000 (6%)]\tTotal Loss: 0.734222\n",
      "Reconstruction: 0.650848, Regularization: 0.018387, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:11,661 root         INFO     Train Epoch: 110 [1024/8000 (13%)]\tTotal Loss: 0.812749\n",
      "Reconstruction: 0.724758, Regularization: 0.022994, Discriminator: 0.043335; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:11,758 root         INFO     Train Epoch: 110 [1536/8000 (19%)]\tTotal Loss: 0.784766\n",
      "Reconstruction: 0.695970, Regularization: 0.023811, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:11,855 root         INFO     Train Epoch: 110 [2048/8000 (26%)]\tTotal Loss: 0.550328\n",
      "Reconstruction: 0.467926, Regularization: 0.017413, Discriminator: 0.043330; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:11,952 root         INFO     Train Epoch: 110 [2560/8000 (32%)]\tTotal Loss: 0.671111\n",
      "Reconstruction: 0.582982, Regularization: 0.023153, Discriminator: 0.043316; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:12,047 root         INFO     Train Epoch: 110 [3072/8000 (38%)]\tTotal Loss: 0.767103\n",
      "Reconstruction: 0.682866, Regularization: 0.019247, Discriminator: 0.043330; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:12,142 root         INFO     Train Epoch: 110 [3584/8000 (45%)]\tTotal Loss: 0.502194\n",
      "Reconstruction: 0.420953, Regularization: 0.016260, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:12,238 root         INFO     Train Epoch: 110 [4096/8000 (51%)]\tTotal Loss: 0.713616\n",
      "Reconstruction: 0.623017, Regularization: 0.025623, Discriminator: 0.043315; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:12,333 root         INFO     Train Epoch: 110 [4608/8000 (58%)]\tTotal Loss: 0.842476\n",
      "Reconstruction: 0.753696, Regularization: 0.023793, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:12,429 root         INFO     Train Epoch: 110 [5120/8000 (64%)]\tTotal Loss: 0.616060\n",
      "Reconstruction: 0.536352, Regularization: 0.014732, Discriminator: 0.043311; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:12,524 root         INFO     Train Epoch: 110 [5632/8000 (70%)]\tTotal Loss: 0.954043\n",
      "Reconstruction: 0.859894, Regularization: 0.029159, Discriminator: 0.043324; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:12,619 root         INFO     Train Epoch: 110 [6144/8000 (77%)]\tTotal Loss: 0.710892\n",
      "Reconstruction: 0.626153, Regularization: 0.019759, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:12,714 root         INFO     Train Epoch: 110 [6656/8000 (83%)]\tTotal Loss: 0.565305\n",
      "Reconstruction: 0.484130, Regularization: 0.016194, Discriminator: 0.043319; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:12,810 root         INFO     Train Epoch: 110 [7168/8000 (90%)]\tTotal Loss: 0.615375\n",
      "Reconstruction: 0.532910, Regularization: 0.017486, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:12,905 root         INFO     Train Epoch: 110 [7680/8000 (96%)]\tTotal Loss: 0.799238\n",
      "Reconstruction: 0.711184, Regularization: 0.023074, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:12,977 root         INFO     ====> Epoch: 110 Average loss: 0.7171\n",
      "2019-04-09 22:48:13,004 root         INFO     Train Epoch: 111 [0/8000 (0%)]\tTotal Loss: 0.728428\n",
      "Reconstruction: 0.640034, Regularization: 0.023411, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:13,102 root         INFO     Train Epoch: 111 [512/8000 (6%)]\tTotal Loss: 0.764485\n",
      "Reconstruction: 0.672409, Regularization: 0.027091, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:13,201 root         INFO     Train Epoch: 111 [1024/8000 (13%)]\tTotal Loss: 0.811318\n",
      "Reconstruction: 0.725053, Regularization: 0.021281, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:13,299 root         INFO     Train Epoch: 111 [1536/8000 (19%)]\tTotal Loss: 0.440749\n",
      "Reconstruction: 0.364789, Regularization: 0.010982, Discriminator: 0.043310; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:13,398 root         INFO     Train Epoch: 111 [2048/8000 (26%)]\tTotal Loss: 0.765664\n",
      "Reconstruction: 0.675879, Regularization: 0.024807, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:13,498 root         INFO     Train Epoch: 111 [2560/8000 (32%)]\tTotal Loss: 0.735774\n",
      "Reconstruction: 0.648529, Regularization: 0.022259, Discriminator: 0.043319; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:13,597 root         INFO     Train Epoch: 111 [3072/8000 (38%)]\tTotal Loss: 0.975334\n",
      "Reconstruction: 0.879408, Regularization: 0.030945, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:13,696 root         INFO     Train Epoch: 111 [3584/8000 (45%)]\tTotal Loss: 0.501133\n",
      "Reconstruction: 0.422668, Regularization: 0.013475, Discriminator: 0.043325; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:13,798 root         INFO     Train Epoch: 111 [4096/8000 (51%)]\tTotal Loss: 0.804953\n",
      "Reconstruction: 0.710988, Regularization: 0.028951, Discriminator: 0.043350; Generator: 0.021665,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:13,915 root         INFO     Train Epoch: 111 [4608/8000 (58%)]\tTotal Loss: 0.863906\n",
      "Reconstruction: 0.775701, Regularization: 0.023231, Discriminator: 0.043310; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:14,019 root         INFO     Train Epoch: 111 [5120/8000 (64%)]\tTotal Loss: 0.886060\n",
      "Reconstruction: 0.795040, Regularization: 0.026041, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:14,128 root         INFO     Train Epoch: 111 [5632/8000 (70%)]\tTotal Loss: 0.682749\n",
      "Reconstruction: 0.595400, Regularization: 0.022367, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:14,228 root         INFO     Train Epoch: 111 [6144/8000 (77%)]\tTotal Loss: 0.733403\n",
      "Reconstruction: 0.648291, Regularization: 0.020143, Discriminator: 0.043314; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:14,328 root         INFO     Train Epoch: 111 [6656/8000 (83%)]\tTotal Loss: 0.596147\n",
      "Reconstruction: 0.514243, Regularization: 0.016925, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:14,428 root         INFO     Train Epoch: 111 [7168/8000 (90%)]\tTotal Loss: 0.470527\n",
      "Reconstruction: 0.390451, Regularization: 0.015093, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:14,528 root         INFO     Train Epoch: 111 [7680/8000 (96%)]\tTotal Loss: 0.589452\n",
      "Reconstruction: 0.512233, Regularization: 0.012255, Discriminator: 0.043302; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:14,602 root         INFO     ====> Epoch: 111 Average loss: 0.7178\n",
      "2019-04-09 22:48:14,629 root         INFO     Train Epoch: 112 [0/8000 (0%)]\tTotal Loss: 0.551907\n",
      "Reconstruction: 0.472905, Regularization: 0.014020, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:14,729 root         INFO     Train Epoch: 112 [512/8000 (6%)]\tTotal Loss: 0.885814\n",
      "Reconstruction: 0.796736, Regularization: 0.024112, Discriminator: 0.043312; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:14,828 root         INFO     Train Epoch: 112 [1024/8000 (13%)]\tTotal Loss: 0.599005\n",
      "Reconstruction: 0.517448, Regularization: 0.016570, Discriminator: 0.043320; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:14,928 root         INFO     Train Epoch: 112 [1536/8000 (19%)]\tTotal Loss: 1.042904\n",
      "Reconstruction: 0.944207, Regularization: 0.033703, Discriminator: 0.043334; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:15,028 root         INFO     Train Epoch: 112 [2048/8000 (26%)]\tTotal Loss: 0.504869\n",
      "Reconstruction: 0.426874, Regularization: 0.013043, Discriminator: 0.043299; Generator: 0.021653,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:48:15,128 root         INFO     Train Epoch: 112 [2560/8000 (32%)]\tTotal Loss: 0.645223\n",
      "Reconstruction: 0.565362, Regularization: 0.014899, Discriminator: 0.043304; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:15,228 root         INFO     Train Epoch: 112 [3072/8000 (38%)]\tTotal Loss: 0.678484\n",
      "Reconstruction: 0.596345, Regularization: 0.017167, Discriminator: 0.043319; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:15,327 root         INFO     Train Epoch: 112 [3584/8000 (45%)]\tTotal Loss: 0.787740\n",
      "Reconstruction: 0.697744, Regularization: 0.025011, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:15,427 root         INFO     Train Epoch: 112 [4096/8000 (51%)]\tTotal Loss: 0.621911\n",
      "Reconstruction: 0.542969, Regularization: 0.013973, Discriminator: 0.043310; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:15,526 root         INFO     Train Epoch: 112 [4608/8000 (58%)]\tTotal Loss: 0.752160\n",
      "Reconstruction: 0.659180, Regularization: 0.027979, Discriminator: 0.043334; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:15,626 root         INFO     Train Epoch: 112 [5120/8000 (64%)]\tTotal Loss: 0.835204\n",
      "Reconstruction: 0.748415, Regularization: 0.021813, Discriminator: 0.043316; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:15,726 root         INFO     Train Epoch: 112 [5632/8000 (70%)]\tTotal Loss: 0.684877\n",
      "Reconstruction: 0.602415, Regularization: 0.017484, Discriminator: 0.043312; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:15,825 root         INFO     Train Epoch: 112 [6144/8000 (77%)]\tTotal Loss: 0.860801\n",
      "Reconstruction: 0.767255, Regularization: 0.028554, Discriminator: 0.043325; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:15,926 root         INFO     Train Epoch: 112 [6656/8000 (83%)]\tTotal Loss: 0.577118\n",
      "Reconstruction: 0.493622, Regularization: 0.018505, Discriminator: 0.043330; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:16,027 root         INFO     Train Epoch: 112 [7168/8000 (90%)]\tTotal Loss: 0.531044\n",
      "Reconstruction: 0.450382, Regularization: 0.015671, Discriminator: 0.043326; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:16,126 root         INFO     Train Epoch: 112 [7680/8000 (96%)]\tTotal Loss: 0.473540\n",
      "Reconstruction: 0.394321, Regularization: 0.014224, Discriminator: 0.043329; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:16,201 root         INFO     ====> Epoch: 112 Average loss: 0.7184\n",
      "2019-04-09 22:48:16,227 root         INFO     Train Epoch: 113 [0/8000 (0%)]\tTotal Loss: 0.688112\n",
      "Reconstruction: 0.598032, Regularization: 0.025080, Discriminator: 0.043337; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:16,328 root         INFO     Train Epoch: 113 [512/8000 (6%)]\tTotal Loss: 1.097434\n",
      "Reconstruction: 1.000044, Regularization: 0.032415, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:16,429 root         INFO     Train Epoch: 113 [1024/8000 (13%)]\tTotal Loss: 0.492929\n",
      "Reconstruction: 0.415258, Regularization: 0.012706, Discriminator: 0.043317; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:16,530 root         INFO     Train Epoch: 113 [1536/8000 (19%)]\tTotal Loss: 1.085999\n",
      "Reconstruction: 0.984623, Regularization: 0.036400, Discriminator: 0.043309; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:16,631 root         INFO     Train Epoch: 113 [2048/8000 (26%)]\tTotal Loss: 0.704831\n",
      "Reconstruction: 0.619267, Regularization: 0.020571, Discriminator: 0.043322; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:16,733 root         INFO     Train Epoch: 113 [2560/8000 (32%)]\tTotal Loss: 0.716034\n",
      "Reconstruction: 0.633487, Regularization: 0.017586, Discriminator: 0.043305; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:16,832 root         INFO     Train Epoch: 113 [3072/8000 (38%)]\tTotal Loss: 0.937093\n",
      "Reconstruction: 0.838035, Regularization: 0.034061, Discriminator: 0.043341; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:16,932 root         INFO     Train Epoch: 113 [3584/8000 (45%)]\tTotal Loss: 0.780777\n",
      "Reconstruction: 0.691771, Regularization: 0.024014, Discriminator: 0.043330; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:17,030 root         INFO     Train Epoch: 113 [4096/8000 (51%)]\tTotal Loss: 0.901390\n",
      "Reconstruction: 0.809273, Regularization: 0.027131, Discriminator: 0.043328; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:17,131 root         INFO     Train Epoch: 113 [4608/8000 (58%)]\tTotal Loss: 0.781575\n",
      "Reconstruction: 0.694782, Regularization: 0.021826, Discriminator: 0.043313; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:17,232 root         INFO     Train Epoch: 113 [5120/8000 (64%)]\tTotal Loss: 0.636829\n",
      "Reconstruction: 0.553951, Regularization: 0.017903, Discriminator: 0.043317; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:17,331 root         INFO     Train Epoch: 113 [5632/8000 (70%)]\tTotal Loss: 1.027314\n",
      "Reconstruction: 0.928204, Regularization: 0.034115, Discriminator: 0.043332; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:17,429 root         INFO     Train Epoch: 113 [6144/8000 (77%)]\tTotal Loss: 0.463858\n",
      "Reconstruction: 0.385043, Regularization: 0.013838, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:17,526 root         INFO     Train Epoch: 113 [6656/8000 (83%)]\tTotal Loss: 0.910626\n",
      "Reconstruction: 0.815333, Regularization: 0.030304, Discriminator: 0.043326; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:17,624 root         INFO     Train Epoch: 113 [7168/8000 (90%)]\tTotal Loss: 0.558275\n",
      "Reconstruction: 0.478202, Regularization: 0.015095, Discriminator: 0.043309; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:17,722 root         INFO     Train Epoch: 113 [7680/8000 (96%)]\tTotal Loss: 0.680209\n",
      "Reconstruction: 0.596538, Regularization: 0.018699, Discriminator: 0.043313; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:17,795 root         INFO     ====> Epoch: 113 Average loss: 0.7172\n",
      "2019-04-09 22:48:17,821 root         INFO     Train Epoch: 114 [0/8000 (0%)]\tTotal Loss: 0.598338\n",
      "Reconstruction: 0.513103, Regularization: 0.020237, Discriminator: 0.043341; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:17,922 root         INFO     Train Epoch: 114 [512/8000 (6%)]\tTotal Loss: 0.501986\n",
      "Reconstruction: 0.422614, Regularization: 0.014393, Discriminator: 0.043317; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:18,023 root         INFO     Train Epoch: 114 [1024/8000 (13%)]\tTotal Loss: 0.738844\n",
      "Reconstruction: 0.650374, Regularization: 0.023483, Discriminator: 0.043323; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:18,124 root         INFO     Train Epoch: 114 [1536/8000 (19%)]\tTotal Loss: 0.833269\n",
      "Reconstruction: 0.743871, Regularization: 0.024415, Discriminator: 0.043316; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:18,224 root         INFO     Train Epoch: 114 [2048/8000 (26%)]\tTotal Loss: 0.645376\n",
      "Reconstruction: 0.562895, Regularization: 0.017507, Discriminator: 0.043309; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:18,325 root         INFO     Train Epoch: 114 [2560/8000 (32%)]\tTotal Loss: 0.625477\n",
      "Reconstruction: 0.545383, Regularization: 0.015122, Discriminator: 0.043307; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:18,425 root         INFO     Train Epoch: 114 [3072/8000 (38%)]\tTotal Loss: 0.715014\n",
      "Reconstruction: 0.624225, Regularization: 0.025798, Discriminator: 0.043336; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:18,532 root         INFO     Train Epoch: 114 [3584/8000 (45%)]\tTotal Loss: 0.739731\n",
      "Reconstruction: 0.650512, Regularization: 0.024234, Discriminator: 0.043328; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:18,632 root         INFO     Train Epoch: 114 [4096/8000 (51%)]\tTotal Loss: 0.631640\n",
      "Reconstruction: 0.550726, Regularization: 0.015947, Discriminator: 0.043310; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:18,729 root         INFO     Train Epoch: 114 [4608/8000 (58%)]\tTotal Loss: 0.589165\n",
      "Reconstruction: 0.506985, Regularization: 0.017201, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:18,826 root         INFO     Train Epoch: 114 [5120/8000 (64%)]\tTotal Loss: 0.541159\n",
      "Reconstruction: 0.462071, Regularization: 0.014109, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:18,923 root         INFO     Train Epoch: 114 [5632/8000 (70%)]\tTotal Loss: 0.836593\n",
      "Reconstruction: 0.749433, Regularization: 0.022196, Discriminator: 0.043306; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:19,021 root         INFO     Train Epoch: 114 [6144/8000 (77%)]\tTotal Loss: 0.673693\n",
      "Reconstruction: 0.584822, Regularization: 0.023887, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:19,121 root         INFO     Train Epoch: 114 [6656/8000 (83%)]\tTotal Loss: 1.004030\n",
      "Reconstruction: 0.907347, Regularization: 0.031702, Discriminator: 0.043319; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:19,221 root         INFO     Train Epoch: 114 [7168/8000 (90%)]\tTotal Loss: 0.883614\n",
      "Reconstruction: 0.789699, Regularization: 0.028925, Discriminator: 0.043329; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:19,322 root         INFO     Train Epoch: 114 [7680/8000 (96%)]\tTotal Loss: 0.858999\n",
      "Reconstruction: 0.766526, Regularization: 0.027494, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:19,396 root         INFO     ====> Epoch: 114 Average loss: 0.7189\n",
      "2019-04-09 22:48:19,422 root         INFO     Train Epoch: 115 [0/8000 (0%)]\tTotal Loss: 0.712730\n",
      "Reconstruction: 0.627787, Regularization: 0.019963, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:19,522 root         INFO     Train Epoch: 115 [512/8000 (6%)]\tTotal Loss: 0.562047\n",
      "Reconstruction: 0.478286, Regularization: 0.018772, Discriminator: 0.043325; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:19,622 root         INFO     Train Epoch: 115 [1024/8000 (13%)]\tTotal Loss: 0.455630\n",
      "Reconstruction: 0.376827, Regularization: 0.013819, Discriminator: 0.043320; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:19,721 root         INFO     Train Epoch: 115 [1536/8000 (19%)]\tTotal Loss: 0.605508\n",
      "Reconstruction: 0.520619, Regularization: 0.019921, Discriminator: 0.043314; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:19,820 root         INFO     Train Epoch: 115 [2048/8000 (26%)]\tTotal Loss: 0.447299\n",
      "Reconstruction: 0.370062, Regularization: 0.012250, Discriminator: 0.043328; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:19,920 root         INFO     Train Epoch: 115 [2560/8000 (32%)]\tTotal Loss: 0.745999\n",
      "Reconstruction: 0.657952, Regularization: 0.023076, Discriminator: 0.043311; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:20,019 root         INFO     Train Epoch: 115 [3072/8000 (38%)]\tTotal Loss: 0.734563\n",
      "Reconstruction: 0.646474, Regularization: 0.023100, Discriminator: 0.043330; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:20,118 root         INFO     Train Epoch: 115 [3584/8000 (45%)]\tTotal Loss: 0.590064\n",
      "Reconstruction: 0.510130, Regularization: 0.014951, Discriminator: 0.043325; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:20,213 root         INFO     Train Epoch: 115 [4096/8000 (51%)]\tTotal Loss: 0.552857\n",
      "Reconstruction: 0.475616, Regularization: 0.012252, Discriminator: 0.043329; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:20,310 root         INFO     Train Epoch: 115 [4608/8000 (58%)]\tTotal Loss: 0.880559\n",
      "Reconstruction: 0.786258, Regularization: 0.029318, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:20,406 root         INFO     Train Epoch: 115 [5120/8000 (64%)]\tTotal Loss: 0.708204\n",
      "Reconstruction: 0.623315, Regularization: 0.019906, Discriminator: 0.043327; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:20,505 root         INFO     Train Epoch: 115 [5632/8000 (70%)]\tTotal Loss: 0.613765\n",
      "Reconstruction: 0.530110, Regularization: 0.018665, Discriminator: 0.043330; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:20,601 root         INFO     Train Epoch: 115 [6144/8000 (77%)]\tTotal Loss: 0.808496\n",
      "Reconstruction: 0.710462, Regularization: 0.033061, Discriminator: 0.043310; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:20,697 root         INFO     Train Epoch: 115 [6656/8000 (83%)]\tTotal Loss: 0.599915\n",
      "Reconstruction: 0.515836, Regularization: 0.019094, Discriminator: 0.043323; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:20,793 root         INFO     Train Epoch: 115 [7168/8000 (90%)]\tTotal Loss: 0.654310\n",
      "Reconstruction: 0.565657, Regularization: 0.023667, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:20,890 root         INFO     Train Epoch: 115 [7680/8000 (96%)]\tTotal Loss: 0.657807\n",
      "Reconstruction: 0.574231, Regularization: 0.018594, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:20,963 root         INFO     ====> Epoch: 115 Average loss: 0.7181\n",
      "2019-04-09 22:48:20,990 root         INFO     Train Epoch: 116 [0/8000 (0%)]\tTotal Loss: 0.485947\n",
      "Reconstruction: 0.405235, Regularization: 0.015736, Discriminator: 0.043316; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:21,087 root         INFO     Train Epoch: 116 [512/8000 (6%)]\tTotal Loss: 0.623554\n",
      "Reconstruction: 0.540313, Regularization: 0.018258, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:21,185 root         INFO     Train Epoch: 116 [1024/8000 (13%)]\tTotal Loss: 0.883006\n",
      "Reconstruction: 0.792555, Regularization: 0.025460, Discriminator: 0.043328; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:21,283 root         INFO     Train Epoch: 116 [1536/8000 (19%)]\tTotal Loss: 0.783539\n",
      "Reconstruction: 0.693236, Regularization: 0.025320, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:21,381 root         INFO     Train Epoch: 116 [2048/8000 (26%)]\tTotal Loss: 0.786920\n",
      "Reconstruction: 0.697431, Regularization: 0.024510, Discriminator: 0.043323; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:21,479 root         INFO     Train Epoch: 116 [2560/8000 (32%)]\tTotal Loss: 0.883029\n",
      "Reconstruction: 0.788751, Regularization: 0.029301, Discriminator: 0.043321; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:21,577 root         INFO     Train Epoch: 116 [3072/8000 (38%)]\tTotal Loss: 0.732716\n",
      "Reconstruction: 0.642395, Regularization: 0.025342, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:21,675 root         INFO     Train Epoch: 116 [3584/8000 (45%)]\tTotal Loss: 0.618306\n",
      "Reconstruction: 0.533280, Regularization: 0.020045, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:21,773 root         INFO     Train Epoch: 116 [4096/8000 (51%)]\tTotal Loss: 0.668223\n",
      "Reconstruction: 0.581920, Regularization: 0.021320, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:21,871 root         INFO     Train Epoch: 116 [4608/8000 (58%)]\tTotal Loss: 0.857826\n",
      "Reconstruction: 0.764223, Regularization: 0.028621, Discriminator: 0.043324; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:21,968 root         INFO     Train Epoch: 116 [5120/8000 (64%)]\tTotal Loss: 0.794863\n",
      "Reconstruction: 0.706660, Regularization: 0.023206, Discriminator: 0.043337; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:22,066 root         INFO     Train Epoch: 116 [5632/8000 (70%)]\tTotal Loss: 0.600897\n",
      "Reconstruction: 0.520504, Regularization: 0.015409, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:22,164 root         INFO     Train Epoch: 116 [6144/8000 (77%)]\tTotal Loss: 0.832808\n",
      "Reconstruction: 0.736790, Regularization: 0.031054, Discriminator: 0.043304; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:22,262 root         INFO     Train Epoch: 116 [6656/8000 (83%)]\tTotal Loss: 0.686235\n",
      "Reconstruction: 0.604604, Regularization: 0.016619, Discriminator: 0.043350; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:22,360 root         INFO     Train Epoch: 116 [7168/8000 (90%)]\tTotal Loss: 0.695407\n",
      "Reconstruction: 0.606483, Regularization: 0.023951, Discriminator: 0.043314; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:22,458 root         INFO     Train Epoch: 116 [7680/8000 (96%)]\tTotal Loss: 0.734168\n",
      "Reconstruction: 0.648358, Regularization: 0.020812, Discriminator: 0.043339; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:22,532 root         INFO     ====> Epoch: 116 Average loss: 0.7167\n",
      "2019-04-09 22:48:22,558 root         INFO     Train Epoch: 117 [0/8000 (0%)]\tTotal Loss: 0.581847\n",
      "Reconstruction: 0.491396, Regularization: 0.025491, Discriminator: 0.043299; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:22,659 root         INFO     Train Epoch: 117 [512/8000 (6%)]\tTotal Loss: 0.749019\n",
      "Reconstruction: 0.662053, Regularization: 0.021975, Discriminator: 0.043330; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:22,757 root         INFO     Train Epoch: 117 [1024/8000 (13%)]\tTotal Loss: 0.760041\n",
      "Reconstruction: 0.671712, Regularization: 0.023341, Discriminator: 0.043327; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:22,854 root         INFO     Train Epoch: 117 [1536/8000 (19%)]\tTotal Loss: 0.669513\n",
      "Reconstruction: 0.586042, Regularization: 0.018481, Discriminator: 0.043330; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:22,950 root         INFO     Train Epoch: 117 [2048/8000 (26%)]\tTotal Loss: 0.667555\n",
      "Reconstruction: 0.583298, Regularization: 0.019254, Discriminator: 0.043333; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:23,046 root         INFO     Train Epoch: 117 [2560/8000 (32%)]\tTotal Loss: 0.856045\n",
      "Reconstruction: 0.764443, Regularization: 0.026617, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:23,142 root         INFO     Train Epoch: 117 [3072/8000 (38%)]\tTotal Loss: 0.597977\n",
      "Reconstruction: 0.518593, Regularization: 0.014369, Discriminator: 0.043351; Generator: 0.021665,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:23,238 root         INFO     Train Epoch: 117 [3584/8000 (45%)]\tTotal Loss: 0.761585\n",
      "Reconstruction: 0.675517, Regularization: 0.021058, Discriminator: 0.043342; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:23,336 root         INFO     Train Epoch: 117 [4096/8000 (51%)]\tTotal Loss: 0.551402\n",
      "Reconstruction: 0.472602, Regularization: 0.013801, Discriminator: 0.043340; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:23,434 root         INFO     Train Epoch: 117 [4608/8000 (58%)]\tTotal Loss: 0.885271\n",
      "Reconstruction: 0.797255, Regularization: 0.023009, Discriminator: 0.043344; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:23,533 root         INFO     Train Epoch: 117 [5120/8000 (64%)]\tTotal Loss: 0.519049\n",
      "Reconstruction: 0.440337, Regularization: 0.013720, Discriminator: 0.043335; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:23,632 root         INFO     Train Epoch: 117 [5632/8000 (70%)]\tTotal Loss: 0.752631\n",
      "Reconstruction: 0.662010, Regularization: 0.025633, Discriminator: 0.043330; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:23,730 root         INFO     Train Epoch: 117 [6144/8000 (77%)]\tTotal Loss: 0.801576\n",
      "Reconstruction: 0.715572, Regularization: 0.021011, Discriminator: 0.043328; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:23,826 root         INFO     Train Epoch: 117 [6656/8000 (83%)]\tTotal Loss: 0.474985\n",
      "Reconstruction: 0.397762, Regularization: 0.012240, Discriminator: 0.043327; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:23,922 root         INFO     Train Epoch: 117 [7168/8000 (90%)]\tTotal Loss: 0.870739\n",
      "Reconstruction: 0.775141, Regularization: 0.030623, Discriminator: 0.043316; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:24,018 root         INFO     Train Epoch: 117 [7680/8000 (96%)]\tTotal Loss: 0.803588\n",
      "Reconstruction: 0.710668, Regularization: 0.027950, Discriminator: 0.043313; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:24,090 root         INFO     ====> Epoch: 117 Average loss: 0.7160\n",
      "2019-04-09 22:48:24,116 root         INFO     Train Epoch: 118 [0/8000 (0%)]\tTotal Loss: 0.944236\n",
      "Reconstruction: 0.847690, Regularization: 0.031564, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:24,216 root         INFO     Train Epoch: 118 [512/8000 (6%)]\tTotal Loss: 0.534338\n",
      "Reconstruction: 0.455334, Regularization: 0.014013, Discriminator: 0.043329; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:24,324 root         INFO     Train Epoch: 118 [1024/8000 (13%)]\tTotal Loss: 0.815010\n",
      "Reconstruction: 0.722748, Regularization: 0.027296, Discriminator: 0.043304; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:24,443 root         INFO     Train Epoch: 118 [1536/8000 (19%)]\tTotal Loss: 0.730691\n",
      "Reconstruction: 0.644162, Regularization: 0.021544, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:24,551 root         INFO     Train Epoch: 118 [2048/8000 (26%)]\tTotal Loss: 0.596871\n",
      "Reconstruction: 0.513194, Regularization: 0.018694, Discriminator: 0.043321; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:24,650 root         INFO     Train Epoch: 118 [2560/8000 (32%)]\tTotal Loss: 1.079859\n",
      "Reconstruction: 0.980742, Regularization: 0.034118, Discriminator: 0.043332; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:24,746 root         INFO     Train Epoch: 118 [3072/8000 (38%)]\tTotal Loss: 1.025847\n",
      "Reconstruction: 0.928042, Regularization: 0.032791, Discriminator: 0.043349; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:24,842 root         INFO     Train Epoch: 118 [3584/8000 (45%)]\tTotal Loss: 0.679666\n",
      "Reconstruction: 0.595374, Regularization: 0.019310, Discriminator: 0.043319; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:24,938 root         INFO     Train Epoch: 118 [4096/8000 (51%)]\tTotal Loss: 0.787191\n",
      "Reconstruction: 0.699007, Regularization: 0.023205, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:25,035 root         INFO     Train Epoch: 118 [4608/8000 (58%)]\tTotal Loss: 0.839282\n",
      "Reconstruction: 0.746685, Regularization: 0.027611, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:25,131 root         INFO     Train Epoch: 118 [5120/8000 (64%)]\tTotal Loss: 0.623714\n",
      "Reconstruction: 0.540164, Regularization: 0.018571, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:25,228 root         INFO     Train Epoch: 118 [5632/8000 (70%)]\tTotal Loss: 0.557044\n",
      "Reconstruction: 0.473197, Regularization: 0.018869, Discriminator: 0.043314; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:25,325 root         INFO     Train Epoch: 118 [6144/8000 (77%)]\tTotal Loss: 0.728024\n",
      "Reconstruction: 0.640723, Regularization: 0.022305, Discriminator: 0.043328; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:25,422 root         INFO     Train Epoch: 118 [6656/8000 (83%)]\tTotal Loss: 0.700840\n",
      "Reconstruction: 0.611874, Regularization: 0.023976, Discriminator: 0.043313; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:25,518 root         INFO     Train Epoch: 118 [7168/8000 (90%)]\tTotal Loss: 0.632247\n",
      "Reconstruction: 0.550856, Regularization: 0.016393, Discriminator: 0.043344; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:25,614 root         INFO     Train Epoch: 118 [7680/8000 (96%)]\tTotal Loss: 1.043096\n",
      "Reconstruction: 0.941403, Regularization: 0.036721, Discriminator: 0.043318; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:25,686 root         INFO     ====> Epoch: 118 Average loss: 0.7193\n",
      "2019-04-09 22:48:25,712 root         INFO     Train Epoch: 119 [0/8000 (0%)]\tTotal Loss: 0.662588\n",
      "Reconstruction: 0.576926, Regularization: 0.020670, Discriminator: 0.043329; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:25,813 root         INFO     Train Epoch: 119 [512/8000 (6%)]\tTotal Loss: 0.801239\n",
      "Reconstruction: 0.708410, Regularization: 0.027837, Discriminator: 0.043325; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:25,911 root         INFO     Train Epoch: 119 [1024/8000 (13%)]\tTotal Loss: 0.642287\n",
      "Reconstruction: 0.555099, Regularization: 0.022190, Discriminator: 0.043332; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:26,010 root         INFO     Train Epoch: 119 [1536/8000 (19%)]\tTotal Loss: 1.149424\n",
      "Reconstruction: 1.048123, Regularization: 0.036328, Discriminator: 0.043327; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:26,109 root         INFO     Train Epoch: 119 [2048/8000 (26%)]\tTotal Loss: 0.981472\n",
      "Reconstruction: 0.888342, Regularization: 0.028120, Discriminator: 0.043346; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:26,208 root         INFO     Train Epoch: 119 [2560/8000 (32%)]\tTotal Loss: 0.886285\n",
      "Reconstruction: 0.795394, Regularization: 0.025889, Discriminator: 0.043340; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:26,304 root         INFO     Train Epoch: 119 [3072/8000 (38%)]\tTotal Loss: 0.902681\n",
      "Reconstruction: 0.803472, Regularization: 0.034218, Discriminator: 0.043335; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:26,401 root         INFO     Train Epoch: 119 [3584/8000 (45%)]\tTotal Loss: 0.459044\n",
      "Reconstruction: 0.380276, Regularization: 0.013782, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:26,497 root         INFO     Train Epoch: 119 [4096/8000 (51%)]\tTotal Loss: 0.678306\n",
      "Reconstruction: 0.592112, Regularization: 0.021213, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:26,593 root         INFO     Train Epoch: 119 [4608/8000 (58%)]\tTotal Loss: 0.407629\n",
      "Reconstruction: 0.334781, Regularization: 0.007859, Discriminator: 0.043332; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:26,691 root         INFO     Train Epoch: 119 [5120/8000 (64%)]\tTotal Loss: 0.761223\n",
      "Reconstruction: 0.669277, Regularization: 0.026988, Discriminator: 0.043297; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:26,787 root         INFO     Train Epoch: 119 [5632/8000 (70%)]\tTotal Loss: 0.676744\n",
      "Reconstruction: 0.594984, Regularization: 0.016773, Discriminator: 0.043327; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:26,884 root         INFO     Train Epoch: 119 [6144/8000 (77%)]\tTotal Loss: 0.622236\n",
      "Reconstruction: 0.538429, Regularization: 0.018817, Discriminator: 0.043327; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:26,980 root         INFO     Train Epoch: 119 [6656/8000 (83%)]\tTotal Loss: 0.759049\n",
      "Reconstruction: 0.668135, Regularization: 0.025920, Discriminator: 0.043333; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:27,076 root         INFO     Train Epoch: 119 [7168/8000 (90%)]\tTotal Loss: 0.746099\n",
      "Reconstruction: 0.664259, Regularization: 0.016893, Discriminator: 0.043282; Generator: 0.021665,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:48:27,172 root         INFO     Train Epoch: 119 [7680/8000 (96%)]\tTotal Loss: 0.632816\n",
      "Reconstruction: 0.547474, Regularization: 0.020375, Discriminator: 0.043304; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:27,245 root         INFO     ====> Epoch: 119 Average loss: 0.7134\n",
      "2019-04-09 22:48:27,271 root         INFO     Train Epoch: 120 [0/8000 (0%)]\tTotal Loss: 0.737841\n",
      "Reconstruction: 0.653148, Regularization: 0.019749, Discriminator: 0.043283; Generator: 0.021662,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:48:27,370 root         INFO     Train Epoch: 120 [512/8000 (6%)]\tTotal Loss: 0.770820\n",
      "Reconstruction: 0.681956, Regularization: 0.023891, Discriminator: 0.043315; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:27,468 root         INFO     Train Epoch: 120 [1024/8000 (13%)]\tTotal Loss: 0.773470\n",
      "Reconstruction: 0.687603, Regularization: 0.020925, Discriminator: 0.043282; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:48:27,567 root         INFO     Train Epoch: 120 [1536/8000 (19%)]\tTotal Loss: 0.841596\n",
      "Reconstruction: 0.754248, Regularization: 0.022397, Discriminator: 0.043295; Generator: 0.021656,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:48:27,666 root         INFO     Train Epoch: 120 [2048/8000 (26%)]\tTotal Loss: 0.821615\n",
      "Reconstruction: 0.728109, Regularization: 0.028520, Discriminator: 0.043334; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:27,764 root         INFO     Train Epoch: 120 [2560/8000 (32%)]\tTotal Loss: 0.659629\n",
      "Reconstruction: 0.573060, Regularization: 0.021578, Discriminator: 0.043328; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:27,861 root         INFO     Train Epoch: 120 [3072/8000 (38%)]\tTotal Loss: 0.581492\n",
      "Reconstruction: 0.498632, Regularization: 0.017869, Discriminator: 0.043331; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:27,957 root         INFO     Train Epoch: 120 [3584/8000 (45%)]\tTotal Loss: 0.781958\n",
      "Reconstruction: 0.693729, Regularization: 0.023244, Discriminator: 0.043321; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:28,054 root         INFO     Train Epoch: 120 [4096/8000 (51%)]\tTotal Loss: 0.900450\n",
      "Reconstruction: 0.808551, Regularization: 0.026907, Discriminator: 0.043327; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:28,152 root         INFO     Train Epoch: 120 [4608/8000 (58%)]\tTotal Loss: 0.519237\n",
      "Reconstruction: 0.439468, Regularization: 0.014784, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:28,249 root         INFO     Train Epoch: 120 [5120/8000 (64%)]\tTotal Loss: 0.597362\n",
      "Reconstruction: 0.512004, Regularization: 0.020380, Discriminator: 0.043307; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:28,346 root         INFO     Train Epoch: 120 [5632/8000 (70%)]\tTotal Loss: 0.795104\n",
      "Reconstruction: 0.708601, Regularization: 0.021545, Discriminator: 0.043300; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:28,442 root         INFO     Train Epoch: 120 [6144/8000 (77%)]\tTotal Loss: 0.711968\n",
      "Reconstruction: 0.629725, Regularization: 0.017231, Discriminator: 0.043345; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:28,539 root         INFO     Train Epoch: 120 [6656/8000 (83%)]\tTotal Loss: 0.660761\n",
      "Reconstruction: 0.577883, Regularization: 0.017889, Discriminator: 0.043327; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:28,636 root         INFO     Train Epoch: 120 [7168/8000 (90%)]\tTotal Loss: 0.564495\n",
      "Reconstruction: 0.482365, Regularization: 0.017166, Discriminator: 0.043292; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:28,734 root         INFO     Train Epoch: 120 [7680/8000 (96%)]\tTotal Loss: 0.731833\n",
      "Reconstruction: 0.638591, Regularization: 0.028255, Discriminator: 0.043323; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:28,808 root         INFO     ====> Epoch: 120 Average loss: 0.7206\n",
      "2019-04-09 22:48:28,835 root         INFO     Train Epoch: 121 [0/8000 (0%)]\tTotal Loss: 0.612141\n",
      "Reconstruction: 0.532373, Regularization: 0.014774, Discriminator: 0.043335; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:28,935 root         INFO     Train Epoch: 121 [512/8000 (6%)]\tTotal Loss: 0.597948\n",
      "Reconstruction: 0.518222, Regularization: 0.014758, Discriminator: 0.043307; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:29,034 root         INFO     Train Epoch: 121 [1024/8000 (13%)]\tTotal Loss: 0.708553\n",
      "Reconstruction: 0.625581, Regularization: 0.018000, Discriminator: 0.043308; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:29,133 root         INFO     Train Epoch: 121 [1536/8000 (19%)]\tTotal Loss: 0.673086\n",
      "Reconstruction: 0.589494, Regularization: 0.018620, Discriminator: 0.043316; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:29,232 root         INFO     Train Epoch: 121 [2048/8000 (26%)]\tTotal Loss: 0.592794\n",
      "Reconstruction: 0.506517, Regularization: 0.021259, Discriminator: 0.043362; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:29,331 root         INFO     Train Epoch: 121 [2560/8000 (32%)]\tTotal Loss: 0.594557\n",
      "Reconstruction: 0.508517, Regularization: 0.021051, Discriminator: 0.043334; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:29,429 root         INFO     Train Epoch: 121 [3072/8000 (38%)]\tTotal Loss: 0.488261\n",
      "Reconstruction: 0.408585, Regularization: 0.014696, Discriminator: 0.043324; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:29,526 root         INFO     Train Epoch: 121 [3584/8000 (45%)]\tTotal Loss: 0.649368\n",
      "Reconstruction: 0.563131, Regularization: 0.021247, Discriminator: 0.043327; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:29,622 root         INFO     Train Epoch: 121 [4096/8000 (51%)]\tTotal Loss: 0.416078\n",
      "Reconstruction: 0.341154, Regularization: 0.009946, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:29,718 root         INFO     Train Epoch: 121 [4608/8000 (58%)]\tTotal Loss: 0.838450\n",
      "Reconstruction: 0.747008, Regularization: 0.026465, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:29,814 root         INFO     Train Epoch: 121 [5120/8000 (64%)]\tTotal Loss: 0.729061\n",
      "Reconstruction: 0.638569, Regularization: 0.025500, Discriminator: 0.043329; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:29,909 root         INFO     Train Epoch: 121 [5632/8000 (70%)]\tTotal Loss: 0.750147\n",
      "Reconstruction: 0.658224, Regularization: 0.026937, Discriminator: 0.043328; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:30,005 root         INFO     Train Epoch: 121 [6144/8000 (77%)]\tTotal Loss: 0.877832\n",
      "Reconstruction: 0.785869, Regularization: 0.026976, Discriminator: 0.043322; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:30,101 root         INFO     Train Epoch: 121 [6656/8000 (83%)]\tTotal Loss: 0.652414\n",
      "Reconstruction: 0.569564, Regularization: 0.017870, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:30,197 root         INFO     Train Epoch: 121 [7168/8000 (90%)]\tTotal Loss: 0.642945\n",
      "Reconstruction: 0.561331, Regularization: 0.016638, Discriminator: 0.043312; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:30,293 root         INFO     Train Epoch: 121 [7680/8000 (96%)]\tTotal Loss: 0.712979\n",
      "Reconstruction: 0.622633, Regularization: 0.025361, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:30,365 root         INFO     ====> Epoch: 121 Average loss: 0.7139\n",
      "2019-04-09 22:48:30,392 root         INFO     Train Epoch: 122 [0/8000 (0%)]\tTotal Loss: 0.974998\n",
      "Reconstruction: 0.883383, Regularization: 0.026647, Discriminator: 0.043303; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:30,490 root         INFO     Train Epoch: 122 [512/8000 (6%)]\tTotal Loss: 0.859110\n",
      "Reconstruction: 0.765126, Regularization: 0.029004, Discriminator: 0.043325; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:30,588 root         INFO     Train Epoch: 122 [1024/8000 (13%)]\tTotal Loss: 0.749020\n",
      "Reconstruction: 0.657027, Regularization: 0.027006, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:30,685 root         INFO     Train Epoch: 122 [1536/8000 (19%)]\tTotal Loss: 0.869645\n",
      "Reconstruction: 0.773780, Regularization: 0.030882, Discriminator: 0.043328; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:30,782 root         INFO     Train Epoch: 122 [2048/8000 (26%)]\tTotal Loss: 0.737911\n",
      "Reconstruction: 0.656147, Regularization: 0.016795, Discriminator: 0.043308; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:30,879 root         INFO     Train Epoch: 122 [2560/8000 (32%)]\tTotal Loss: 0.832444\n",
      "Reconstruction: 0.736432, Regularization: 0.031033, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:30,975 root         INFO     Train Epoch: 122 [3072/8000 (38%)]\tTotal Loss: 0.608568\n",
      "Reconstruction: 0.523338, Regularization: 0.020242, Discriminator: 0.043331; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:31,072 root         INFO     Train Epoch: 122 [3584/8000 (45%)]\tTotal Loss: 0.824540\n",
      "Reconstruction: 0.733510, Regularization: 0.026071, Discriminator: 0.043298; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:31,168 root         INFO     Train Epoch: 122 [4096/8000 (51%)]\tTotal Loss: 0.673381\n",
      "Reconstruction: 0.583820, Regularization: 0.024563, Discriminator: 0.043342; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:31,264 root         INFO     Train Epoch: 122 [4608/8000 (58%)]\tTotal Loss: 0.576906\n",
      "Reconstruction: 0.495820, Regularization: 0.016087, Discriminator: 0.043335; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:31,360 root         INFO     Train Epoch: 122 [5120/8000 (64%)]\tTotal Loss: 0.737416\n",
      "Reconstruction: 0.652842, Regularization: 0.019609, Discriminator: 0.043306; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:31,456 root         INFO     Train Epoch: 122 [5632/8000 (70%)]\tTotal Loss: 0.795674\n",
      "Reconstruction: 0.701951, Regularization: 0.028744, Discriminator: 0.043323; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:31,553 root         INFO     Train Epoch: 122 [6144/8000 (77%)]\tTotal Loss: 0.764921\n",
      "Reconstruction: 0.673383, Regularization: 0.026550, Discriminator: 0.043321; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:31,650 root         INFO     Train Epoch: 122 [6656/8000 (83%)]\tTotal Loss: 0.514841\n",
      "Reconstruction: 0.434326, Regularization: 0.015525, Discriminator: 0.043324; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:31,747 root         INFO     Train Epoch: 122 [7168/8000 (90%)]\tTotal Loss: 0.761487\n",
      "Reconstruction: 0.674294, Regularization: 0.022211, Discriminator: 0.043316; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:31,844 root         INFO     Train Epoch: 122 [7680/8000 (96%)]\tTotal Loss: 0.711431\n",
      "Reconstruction: 0.626775, Regularization: 0.019662, Discriminator: 0.043326; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:31,917 root         INFO     ====> Epoch: 122 Average loss: 0.7188\n",
      "2019-04-09 22:48:31,943 root         INFO     Train Epoch: 123 [0/8000 (0%)]\tTotal Loss: 0.672291\n",
      "Reconstruction: 0.585807, Regularization: 0.021507, Discriminator: 0.043308; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:32,043 root         INFO     Train Epoch: 123 [512/8000 (6%)]\tTotal Loss: 0.570266\n",
      "Reconstruction: 0.490874, Regularization: 0.014420, Discriminator: 0.043298; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:32,141 root         INFO     Train Epoch: 123 [1024/8000 (13%)]\tTotal Loss: 0.808245\n",
      "Reconstruction: 0.720340, Regularization: 0.022936, Discriminator: 0.043294; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:32,240 root         INFO     Train Epoch: 123 [1536/8000 (19%)]\tTotal Loss: 0.703253\n",
      "Reconstruction: 0.613110, Regularization: 0.025139, Discriminator: 0.043349; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:32,339 root         INFO     Train Epoch: 123 [2048/8000 (26%)]\tTotal Loss: 0.814071\n",
      "Reconstruction: 0.723861, Regularization: 0.025224, Discriminator: 0.043318; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:32,439 root         INFO     Train Epoch: 123 [2560/8000 (32%)]\tTotal Loss: 0.682763\n",
      "Reconstruction: 0.597638, Regularization: 0.020167, Discriminator: 0.043304; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:32,537 root         INFO     Train Epoch: 123 [3072/8000 (38%)]\tTotal Loss: 0.762162\n",
      "Reconstruction: 0.667092, Regularization: 0.030107, Discriminator: 0.043311; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:32,636 root         INFO     Train Epoch: 123 [3584/8000 (45%)]\tTotal Loss: 0.892197\n",
      "Reconstruction: 0.797811, Regularization: 0.029371, Discriminator: 0.043360; Generator: 0.021655,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:32,735 root         INFO     Train Epoch: 123 [4096/8000 (51%)]\tTotal Loss: 0.854035\n",
      "Reconstruction: 0.766788, Regularization: 0.022281, Discriminator: 0.043314; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:32,833 root         INFO     Train Epoch: 123 [4608/8000 (58%)]\tTotal Loss: 0.790871\n",
      "Reconstruction: 0.702138, Regularization: 0.023759, Discriminator: 0.043321; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:32,930 root         INFO     Train Epoch: 123 [5120/8000 (64%)]\tTotal Loss: 0.527571\n",
      "Reconstruction: 0.443584, Regularization: 0.019004, Discriminator: 0.043334; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:33,028 root         INFO     Train Epoch: 123 [5632/8000 (70%)]\tTotal Loss: 0.723000\n",
      "Reconstruction: 0.633756, Regularization: 0.024261, Discriminator: 0.043325; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:33,126 root         INFO     Train Epoch: 123 [6144/8000 (77%)]\tTotal Loss: 0.918913\n",
      "Reconstruction: 0.823271, Regularization: 0.030657, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:33,224 root         INFO     Train Epoch: 123 [6656/8000 (83%)]\tTotal Loss: 0.607102\n",
      "Reconstruction: 0.520089, Regularization: 0.022029, Discriminator: 0.043326; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:33,323 root         INFO     Train Epoch: 123 [7168/8000 (90%)]\tTotal Loss: 0.482326\n",
      "Reconstruction: 0.400076, Regularization: 0.017265, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:33,422 root         INFO     Train Epoch: 123 [7680/8000 (96%)]\tTotal Loss: 0.825448\n",
      "Reconstruction: 0.732924, Regularization: 0.027519, Discriminator: 0.043343; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:33,496 root         INFO     ====> Epoch: 123 Average loss: 0.7138\n",
      "2019-04-09 22:48:33,522 root         INFO     Train Epoch: 124 [0/8000 (0%)]\tTotal Loss: 0.476272\n",
      "Reconstruction: 0.393548, Regularization: 0.017754, Discriminator: 0.043306; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:33,619 root         INFO     Train Epoch: 124 [512/8000 (6%)]\tTotal Loss: 0.667816\n",
      "Reconstruction: 0.584263, Regularization: 0.018562, Discriminator: 0.043330; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:33,716 root         INFO     Train Epoch: 124 [1024/8000 (13%)]\tTotal Loss: 0.668265\n",
      "Reconstruction: 0.580889, Regularization: 0.022416, Discriminator: 0.043292; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:33,812 root         INFO     Train Epoch: 124 [1536/8000 (19%)]\tTotal Loss: 0.553845\n",
      "Reconstruction: 0.475773, Regularization: 0.013093, Discriminator: 0.043326; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:33,909 root         INFO     Train Epoch: 124 [2048/8000 (26%)]\tTotal Loss: 0.537997\n",
      "Reconstruction: 0.462066, Regularization: 0.010956, Discriminator: 0.043315; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:34,005 root         INFO     Train Epoch: 124 [2560/8000 (32%)]\tTotal Loss: 0.640545\n",
      "Reconstruction: 0.551879, Regularization: 0.023720, Discriminator: 0.043291; Generator: 0.021655,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:48:34,101 root         INFO     Train Epoch: 124 [3072/8000 (38%)]\tTotal Loss: 0.784450\n",
      "Reconstruction: 0.697062, Regularization: 0.022401, Discriminator: 0.043331; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:34,197 root         INFO     Train Epoch: 124 [3584/8000 (45%)]\tTotal Loss: 0.801888\n",
      "Reconstruction: 0.713636, Regularization: 0.023234, Discriminator: 0.043359; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:34,294 root         INFO     Train Epoch: 124 [4096/8000 (51%)]\tTotal Loss: 0.601160\n",
      "Reconstruction: 0.515626, Regularization: 0.020577, Discriminator: 0.043296; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:34,390 root         INFO     Train Epoch: 124 [4608/8000 (58%)]\tTotal Loss: 0.675700\n",
      "Reconstruction: 0.585168, Regularization: 0.025493, Discriminator: 0.043383; Generator: 0.021656,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:34,487 root         INFO     Train Epoch: 124 [5120/8000 (64%)]\tTotal Loss: 0.757483\n",
      "Reconstruction: 0.670954, Regularization: 0.021543, Discriminator: 0.043326; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:34,583 root         INFO     Train Epoch: 124 [5632/8000 (70%)]\tTotal Loss: 0.891081\n",
      "Reconstruction: 0.795801, Regularization: 0.030294, Discriminator: 0.043331; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:34,679 root         INFO     Train Epoch: 124 [6144/8000 (77%)]\tTotal Loss: 0.556535\n",
      "Reconstruction: 0.471668, Regularization: 0.019873, Discriminator: 0.043328; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:34,775 root         INFO     Train Epoch: 124 [6656/8000 (83%)]\tTotal Loss: 0.912534\n",
      "Reconstruction: 0.817524, Regularization: 0.030025, Discriminator: 0.043321; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:34,872 root         INFO     Train Epoch: 124 [7168/8000 (90%)]\tTotal Loss: 0.764792\n",
      "Reconstruction: 0.674472, Regularization: 0.025341, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:34,968 root         INFO     Train Epoch: 124 [7680/8000 (96%)]\tTotal Loss: 0.833225\n",
      "Reconstruction: 0.742094, Regularization: 0.026158, Discriminator: 0.043313; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:35,041 root         INFO     ====> Epoch: 124 Average loss: 0.7192\n",
      "2019-04-09 22:48:35,067 root         INFO     Train Epoch: 125 [0/8000 (0%)]\tTotal Loss: 0.854088\n",
      "Reconstruction: 0.760641, Regularization: 0.028452, Discriminator: 0.043326; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:35,168 root         INFO     Train Epoch: 125 [512/8000 (6%)]\tTotal Loss: 0.648551\n",
      "Reconstruction: 0.568209, Regularization: 0.015346, Discriminator: 0.043327; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:35,267 root         INFO     Train Epoch: 125 [1024/8000 (13%)]\tTotal Loss: 0.678966\n",
      "Reconstruction: 0.586976, Regularization: 0.027019, Discriminator: 0.043309; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:35,367 root         INFO     Train Epoch: 125 [1536/8000 (19%)]\tTotal Loss: 0.632497\n",
      "Reconstruction: 0.543549, Regularization: 0.023985, Discriminator: 0.043294; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:35,467 root         INFO     Train Epoch: 125 [2048/8000 (26%)]\tTotal Loss: 0.669642\n",
      "Reconstruction: 0.585900, Regularization: 0.018726, Discriminator: 0.043359; Generator: 0.021657,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:35,566 root         INFO     Train Epoch: 125 [2560/8000 (32%)]\tTotal Loss: 0.691708\n",
      "Reconstruction: 0.599907, Regularization: 0.026812, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:35,666 root         INFO     Train Epoch: 125 [3072/8000 (38%)]\tTotal Loss: 0.826350\n",
      "Reconstruction: 0.731156, Regularization: 0.030185, Discriminator: 0.043360; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:35,766 root         INFO     Train Epoch: 125 [3584/8000 (45%)]\tTotal Loss: 0.855578\n",
      "Reconstruction: 0.755908, Regularization: 0.034673, Discriminator: 0.043336; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:35,866 root         INFO     Train Epoch: 125 [4096/8000 (51%)]\tTotal Loss: 0.839872\n",
      "Reconstruction: 0.743636, Regularization: 0.031249, Discriminator: 0.043329; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:35,965 root         INFO     Train Epoch: 125 [4608/8000 (58%)]\tTotal Loss: 0.666053\n",
      "Reconstruction: 0.576165, Regularization: 0.024896, Discriminator: 0.043337; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:36,063 root         INFO     Train Epoch: 125 [5120/8000 (64%)]\tTotal Loss: 0.638271\n",
      "Reconstruction: 0.555150, Regularization: 0.018081, Discriminator: 0.043379; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:36,163 root         INFO     Train Epoch: 125 [5632/8000 (70%)]\tTotal Loss: 0.606572\n",
      "Reconstruction: 0.524899, Regularization: 0.016706, Discriminator: 0.043311; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:36,262 root         INFO     Train Epoch: 125 [6144/8000 (77%)]\tTotal Loss: 0.690537\n",
      "Reconstruction: 0.601070, Regularization: 0.024489, Discriminator: 0.043326; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:36,361 root         INFO     Train Epoch: 125 [6656/8000 (83%)]\tTotal Loss: 0.653998\n",
      "Reconstruction: 0.569579, Regularization: 0.019424, Discriminator: 0.043333; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:36,460 root         INFO     Train Epoch: 125 [7168/8000 (90%)]\tTotal Loss: 0.719785\n",
      "Reconstruction: 0.633921, Regularization: 0.020876, Discriminator: 0.043334; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:36,559 root         INFO     Train Epoch: 125 [7680/8000 (96%)]\tTotal Loss: 0.625453\n",
      "Reconstruction: 0.538762, Regularization: 0.021709, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:36,634 root         INFO     ====> Epoch: 125 Average loss: 0.7158\n",
      "2019-04-09 22:48:36,660 root         INFO     Train Epoch: 126 [0/8000 (0%)]\tTotal Loss: 0.547738\n",
      "Reconstruction: 0.464775, Regularization: 0.017984, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:36,759 root         INFO     Train Epoch: 126 [512/8000 (6%)]\tTotal Loss: 0.716667\n",
      "Reconstruction: 0.628639, Regularization: 0.023046, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:36,858 root         INFO     Train Epoch: 126 [1024/8000 (13%)]\tTotal Loss: 0.580388\n",
      "Reconstruction: 0.500574, Regularization: 0.014822, Discriminator: 0.043331; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:36,957 root         INFO     Train Epoch: 126 [1536/8000 (19%)]\tTotal Loss: 1.008594\n",
      "Reconstruction: 0.914286, Regularization: 0.029309, Discriminator: 0.043335; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:37,056 root         INFO     Train Epoch: 126 [2048/8000 (26%)]\tTotal Loss: 0.635146\n",
      "Reconstruction: 0.550940, Regularization: 0.019223, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:37,155 root         INFO     Train Epoch: 126 [2560/8000 (32%)]\tTotal Loss: 0.798967\n",
      "Reconstruction: 0.705719, Regularization: 0.028261, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:37,255 root         INFO     Train Epoch: 126 [3072/8000 (38%)]\tTotal Loss: 0.798000\n",
      "Reconstruction: 0.707463, Regularization: 0.025550, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:37,353 root         INFO     Train Epoch: 126 [3584/8000 (45%)]\tTotal Loss: 0.976001\n",
      "Reconstruction: 0.879382, Regularization: 0.031634, Discriminator: 0.043326; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:37,452 root         INFO     Train Epoch: 126 [4096/8000 (51%)]\tTotal Loss: 0.741074\n",
      "Reconstruction: 0.651972, Regularization: 0.024101, Discriminator: 0.043342; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:37,552 root         INFO     Train Epoch: 126 [4608/8000 (58%)]\tTotal Loss: 0.805954\n",
      "Reconstruction: 0.712845, Regularization: 0.028138, Discriminator: 0.043307; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:37,650 root         INFO     Train Epoch: 126 [5120/8000 (64%)]\tTotal Loss: 0.711386\n",
      "Reconstruction: 0.622226, Regularization: 0.024182, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:37,745 root         INFO     Train Epoch: 126 [5632/8000 (70%)]\tTotal Loss: 0.771710\n",
      "Reconstruction: 0.686176, Regularization: 0.020551, Discriminator: 0.043317; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:37,843 root         INFO     Train Epoch: 126 [6144/8000 (77%)]\tTotal Loss: 0.470724\n",
      "Reconstruction: 0.390770, Regularization: 0.014969, Discriminator: 0.043327; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:37,941 root         INFO     Train Epoch: 126 [6656/8000 (83%)]\tTotal Loss: 0.566373\n",
      "Reconstruction: 0.478807, Regularization: 0.022588, Discriminator: 0.043320; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:38,038 root         INFO     Train Epoch: 126 [7168/8000 (90%)]\tTotal Loss: 0.792666\n",
      "Reconstruction: 0.701874, Regularization: 0.025787, Discriminator: 0.043346; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:38,136 root         INFO     Train Epoch: 126 [7680/8000 (96%)]\tTotal Loss: 0.796300\n",
      "Reconstruction: 0.706339, Regularization: 0.024965, Discriminator: 0.043325; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:38,210 root         INFO     ====> Epoch: 126 Average loss: 0.7144\n",
      "2019-04-09 22:48:38,237 root         INFO     Train Epoch: 127 [0/8000 (0%)]\tTotal Loss: 0.693306\n",
      "Reconstruction: 0.603981, Regularization: 0.024350, Discriminator: 0.043317; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:38,334 root         INFO     Train Epoch: 127 [512/8000 (6%)]\tTotal Loss: 0.688386\n",
      "Reconstruction: 0.603655, Regularization: 0.019717, Discriminator: 0.043359; Generator: 0.021655,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:38,433 root         INFO     Train Epoch: 127 [1024/8000 (13%)]\tTotal Loss: 0.642486\n",
      "Reconstruction: 0.555807, Regularization: 0.021678, Discriminator: 0.043337; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:38,531 root         INFO     Train Epoch: 127 [1536/8000 (19%)]\tTotal Loss: 0.915171\n",
      "Reconstruction: 0.826325, Regularization: 0.023849, Discriminator: 0.043339; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:38,629 root         INFO     Train Epoch: 127 [2048/8000 (26%)]\tTotal Loss: 0.814213\n",
      "Reconstruction: 0.717772, Regularization: 0.031469, Discriminator: 0.043316; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:38,728 root         INFO     Train Epoch: 127 [2560/8000 (32%)]\tTotal Loss: 0.812546\n",
      "Reconstruction: 0.715567, Regularization: 0.032002, Discriminator: 0.043312; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:38,827 root         INFO     Train Epoch: 127 [3072/8000 (38%)]\tTotal Loss: 0.589530\n",
      "Reconstruction: 0.502290, Regularization: 0.022281, Discriminator: 0.043299; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:38,926 root         INFO     Train Epoch: 127 [3584/8000 (45%)]\tTotal Loss: 0.633655\n",
      "Reconstruction: 0.552550, Regularization: 0.016110, Discriminator: 0.043330; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:39,025 root         INFO     Train Epoch: 127 [4096/8000 (51%)]\tTotal Loss: 0.811964\n",
      "Reconstruction: 0.724617, Regularization: 0.022353, Discriminator: 0.043329; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:39,122 root         INFO     Train Epoch: 127 [4608/8000 (58%)]\tTotal Loss: 0.524543\n",
      "Reconstruction: 0.443356, Regularization: 0.016199, Discriminator: 0.043321; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:39,219 root         INFO     Train Epoch: 127 [5120/8000 (64%)]\tTotal Loss: 0.619218\n",
      "Reconstruction: 0.537292, Regularization: 0.016932, Discriminator: 0.043330; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:39,317 root         INFO     Train Epoch: 127 [5632/8000 (70%)]\tTotal Loss: 0.848900\n",
      "Reconstruction: 0.760880, Regularization: 0.023045, Discriminator: 0.043304; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:39,415 root         INFO     Train Epoch: 127 [6144/8000 (77%)]\tTotal Loss: 0.778397\n",
      "Reconstruction: 0.686059, Regularization: 0.027372, Discriminator: 0.043303; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:39,512 root         INFO     Train Epoch: 127 [6656/8000 (83%)]\tTotal Loss: 0.783206\n",
      "Reconstruction: 0.699961, Regularization: 0.018235, Discriminator: 0.043340; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:39,610 root         INFO     Train Epoch: 127 [7168/8000 (90%)]\tTotal Loss: 0.680019\n",
      "Reconstruction: 0.591678, Regularization: 0.023365, Discriminator: 0.043314; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:39,707 root         INFO     Train Epoch: 127 [7680/8000 (96%)]\tTotal Loss: 0.778587\n",
      "Reconstruction: 0.692011, Regularization: 0.021608, Discriminator: 0.043301; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:39,781 root         INFO     ====> Epoch: 127 Average loss: 0.7224\n",
      "2019-04-09 22:48:39,807 root         INFO     Train Epoch: 128 [0/8000 (0%)]\tTotal Loss: 0.514697\n",
      "Reconstruction: 0.431181, Regularization: 0.018557, Discriminator: 0.043285; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:39,907 root         INFO     Train Epoch: 128 [512/8000 (6%)]\tTotal Loss: 0.357616\n",
      "Reconstruction: 0.283092, Regularization: 0.009489, Discriminator: 0.043368; Generator: 0.021667,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:40,005 root         INFO     Train Epoch: 128 [1024/8000 (13%)]\tTotal Loss: 0.785094\n",
      "Reconstruction: 0.692522, Regularization: 0.027667, Discriminator: 0.043245; Generator: 0.021660,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:48:40,103 root         INFO     Train Epoch: 128 [1536/8000 (19%)]\tTotal Loss: 0.709552\n",
      "Reconstruction: 0.619257, Regularization: 0.025346, Discriminator: 0.043289; Generator: 0.021660,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:48:40,202 root         INFO     Train Epoch: 128 [2048/8000 (26%)]\tTotal Loss: 0.629507\n",
      "Reconstruction: 0.547683, Regularization: 0.016848, Discriminator: 0.043332; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:40,297 root         INFO     Train Epoch: 128 [2560/8000 (32%)]\tTotal Loss: 0.960318\n",
      "Reconstruction: 0.863582, Regularization: 0.031763, Discriminator: 0.043313; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:40,396 root         INFO     Train Epoch: 128 [3072/8000 (38%)]\tTotal Loss: 0.629043\n",
      "Reconstruction: 0.543826, Regularization: 0.020215, Discriminator: 0.043356; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:40,494 root         INFO     Train Epoch: 128 [3584/8000 (45%)]\tTotal Loss: 0.673835\n",
      "Reconstruction: 0.587355, Regularization: 0.021506, Discriminator: 0.043322; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:40,592 root         INFO     Train Epoch: 128 [4096/8000 (51%)]\tTotal Loss: 0.553903\n",
      "Reconstruction: 0.474490, Regularization: 0.014433, Discriminator: 0.043324; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:40,690 root         INFO     Train Epoch: 128 [4608/8000 (58%)]\tTotal Loss: 0.803195\n",
      "Reconstruction: 0.709508, Regularization: 0.028698, Discriminator: 0.043327; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:40,789 root         INFO     Train Epoch: 128 [5120/8000 (64%)]\tTotal Loss: 0.616442\n",
      "Reconstruction: 0.530444, Regularization: 0.021018, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:40,888 root         INFO     Train Epoch: 128 [5632/8000 (70%)]\tTotal Loss: 0.753328\n",
      "Reconstruction: 0.668512, Regularization: 0.019835, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:40,987 root         INFO     Train Epoch: 128 [6144/8000 (77%)]\tTotal Loss: 0.656022\n",
      "Reconstruction: 0.571060, Regularization: 0.019972, Discriminator: 0.043327; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:41,085 root         INFO     Train Epoch: 128 [6656/8000 (83%)]\tTotal Loss: 0.914773\n",
      "Reconstruction: 0.820397, Regularization: 0.029389, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:41,185 root         INFO     Train Epoch: 128 [7168/8000 (90%)]\tTotal Loss: 0.739729\n",
      "Reconstruction: 0.650745, Regularization: 0.024007, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:41,284 root         INFO     Train Epoch: 128 [7680/8000 (96%)]\tTotal Loss: 0.594114\n",
      "Reconstruction: 0.503846, Regularization: 0.025288, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:41,359 root         INFO     ====> Epoch: 128 Average loss: 0.7141\n",
      "2019-04-09 22:48:41,385 root         INFO     Train Epoch: 129 [0/8000 (0%)]\tTotal Loss: 0.770894\n",
      "Reconstruction: 0.678842, Regularization: 0.027074, Discriminator: 0.043316; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:41,482 root         INFO     Train Epoch: 129 [512/8000 (6%)]\tTotal Loss: 0.655534\n",
      "Reconstruction: 0.568126, Regularization: 0.022435, Discriminator: 0.043315; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:41,580 root         INFO     Train Epoch: 129 [1024/8000 (13%)]\tTotal Loss: 0.614081\n",
      "Reconstruction: 0.529796, Regularization: 0.019310, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:41,679 root         INFO     Train Epoch: 129 [1536/8000 (19%)]\tTotal Loss: 0.595859\n",
      "Reconstruction: 0.514177, Regularization: 0.016702, Discriminator: 0.043315; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:41,778 root         INFO     Train Epoch: 129 [2048/8000 (26%)]\tTotal Loss: 0.502367\n",
      "Reconstruction: 0.421093, Regularization: 0.016282, Discriminator: 0.043324; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:41,876 root         INFO     Train Epoch: 129 [2560/8000 (32%)]\tTotal Loss: 0.854775\n",
      "Reconstruction: 0.763462, Regularization: 0.026305, Discriminator: 0.043348; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:41,975 root         INFO     Train Epoch: 129 [3072/8000 (38%)]\tTotal Loss: 0.548898\n",
      "Reconstruction: 0.465970, Regularization: 0.017984, Discriminator: 0.043283; Generator: 0.021661,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:48:42,074 root         INFO     Train Epoch: 129 [3584/8000 (45%)]\tTotal Loss: 0.678835\n",
      "Reconstruction: 0.592141, Regularization: 0.021703, Discriminator: 0.043324; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:42,174 root         INFO     Train Epoch: 129 [4096/8000 (51%)]\tTotal Loss: 0.580849\n",
      "Reconstruction: 0.494462, Regularization: 0.021362, Discriminator: 0.043363; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:42,272 root         INFO     Train Epoch: 129 [4608/8000 (58%)]\tTotal Loss: 0.683063\n",
      "Reconstruction: 0.603210, Regularization: 0.014847, Discriminator: 0.043344; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:42,371 root         INFO     Train Epoch: 129 [5120/8000 (64%)]\tTotal Loss: 0.777085\n",
      "Reconstruction: 0.688670, Regularization: 0.023404, Discriminator: 0.043346; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:42,469 root         INFO     Train Epoch: 129 [5632/8000 (70%)]\tTotal Loss: 0.900088\n",
      "Reconstruction: 0.806870, Regularization: 0.028228, Discriminator: 0.043328; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:42,568 root         INFO     Train Epoch: 129 [6144/8000 (77%)]\tTotal Loss: 0.521120\n",
      "Reconstruction: 0.439026, Regularization: 0.017140, Discriminator: 0.043286; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:42,666 root         INFO     Train Epoch: 129 [6656/8000 (83%)]\tTotal Loss: 0.529440\n",
      "Reconstruction: 0.445438, Regularization: 0.018981, Discriminator: 0.043355; Generator: 0.021666,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:42,765 root         INFO     Train Epoch: 129 [7168/8000 (90%)]\tTotal Loss: 0.574738\n",
      "Reconstruction: 0.489988, Regularization: 0.019745, Discriminator: 0.043342; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:42,863 root         INFO     Train Epoch: 129 [7680/8000 (96%)]\tTotal Loss: 0.461303\n",
      "Reconstruction: 0.382216, Regularization: 0.014118, Discriminator: 0.043309; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:42,938 root         INFO     ====> Epoch: 129 Average loss: 0.7174\n",
      "2019-04-09 22:48:42,964 root         INFO     Train Epoch: 130 [0/8000 (0%)]\tTotal Loss: 0.559214\n",
      "Reconstruction: 0.473706, Regularization: 0.020515, Discriminator: 0.043332; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:43,063 root         INFO     Train Epoch: 130 [512/8000 (6%)]\tTotal Loss: 0.731456\n",
      "Reconstruction: 0.645010, Regularization: 0.021453, Discriminator: 0.043334; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:43,161 root         INFO     Train Epoch: 130 [1024/8000 (13%)]\tTotal Loss: 0.684056\n",
      "Reconstruction: 0.601681, Regularization: 0.017391, Discriminator: 0.043318; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:43,258 root         INFO     Train Epoch: 130 [1536/8000 (19%)]\tTotal Loss: 0.585224\n",
      "Reconstruction: 0.506377, Regularization: 0.013868, Discriminator: 0.043316; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:43,356 root         INFO     Train Epoch: 130 [2048/8000 (26%)]\tTotal Loss: 0.661644\n",
      "Reconstruction: 0.575282, Regularization: 0.021367, Discriminator: 0.043327; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:43,454 root         INFO     Train Epoch: 130 [2560/8000 (32%)]\tTotal Loss: 0.599105\n",
      "Reconstruction: 0.515240, Regularization: 0.018879, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:43,552 root         INFO     Train Epoch: 130 [3072/8000 (38%)]\tTotal Loss: 0.839011\n",
      "Reconstruction: 0.748846, Regularization: 0.025186, Discriminator: 0.043311; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:43,653 root         INFO     Train Epoch: 130 [3584/8000 (45%)]\tTotal Loss: 0.786664\n",
      "Reconstruction: 0.696170, Regularization: 0.025516, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:43,754 root         INFO     Train Epoch: 130 [4096/8000 (51%)]\tTotal Loss: 0.521061\n",
      "Reconstruction: 0.440772, Regularization: 0.015294, Discriminator: 0.043332; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:43,855 root         INFO     Train Epoch: 130 [4608/8000 (58%)]\tTotal Loss: 0.913499\n",
      "Reconstruction: 0.822277, Regularization: 0.026266, Discriminator: 0.043285; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:43,955 root         INFO     Train Epoch: 130 [5120/8000 (64%)]\tTotal Loss: 0.646648\n",
      "Reconstruction: 0.560881, Regularization: 0.020824, Discriminator: 0.043296; Generator: 0.021648,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:48:44,056 root         INFO     Train Epoch: 130 [5632/8000 (70%)]\tTotal Loss: 0.758275\n",
      "Reconstruction: 0.666104, Regularization: 0.027148, Discriminator: 0.043360; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:44,156 root         INFO     Train Epoch: 130 [6144/8000 (77%)]\tTotal Loss: 0.591993\n",
      "Reconstruction: 0.506659, Regularization: 0.020362, Discriminator: 0.043308; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:44,256 root         INFO     Train Epoch: 130 [6656/8000 (83%)]\tTotal Loss: 0.717055\n",
      "Reconstruction: 0.629419, Regularization: 0.022677, Discriminator: 0.043296; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:44,357 root         INFO     Train Epoch: 130 [7168/8000 (90%)]\tTotal Loss: 0.947886\n",
      "Reconstruction: 0.859638, Regularization: 0.023275, Discriminator: 0.043315; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:44,458 root         INFO     Train Epoch: 130 [7680/8000 (96%)]\tTotal Loss: 0.719571\n",
      "Reconstruction: 0.632426, Regularization: 0.022179, Discriminator: 0.043312; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:44,532 root         INFO     ====> Epoch: 130 Average loss: 0.7198\n",
      "2019-04-09 22:48:44,558 root         INFO     Train Epoch: 131 [0/8000 (0%)]\tTotal Loss: 0.769475\n",
      "Reconstruction: 0.682225, Regularization: 0.022261, Discriminator: 0.043325; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:44,657 root         INFO     Train Epoch: 131 [512/8000 (6%)]\tTotal Loss: 0.594588\n",
      "Reconstruction: 0.510744, Regularization: 0.018878, Discriminator: 0.043312; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:44,757 root         INFO     Train Epoch: 131 [1024/8000 (13%)]\tTotal Loss: 1.006987\n",
      "Reconstruction: 0.905882, Regularization: 0.036127, Discriminator: 0.043326; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:44,856 root         INFO     Train Epoch: 131 [1536/8000 (19%)]\tTotal Loss: 0.801131\n",
      "Reconstruction: 0.708941, Regularization: 0.027166, Discriminator: 0.043360; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:44,953 root         INFO     Train Epoch: 131 [2048/8000 (26%)]\tTotal Loss: 0.606675\n",
      "Reconstruction: 0.525404, Regularization: 0.016299, Discriminator: 0.043322; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:45,050 root         INFO     Train Epoch: 131 [2560/8000 (32%)]\tTotal Loss: 0.683732\n",
      "Reconstruction: 0.598423, Regularization: 0.020312, Discriminator: 0.043333; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:45,148 root         INFO     Train Epoch: 131 [3072/8000 (38%)]\tTotal Loss: 0.591810\n",
      "Reconstruction: 0.507599, Regularization: 0.019225, Discriminator: 0.043331; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:45,245 root         INFO     Train Epoch: 131 [3584/8000 (45%)]\tTotal Loss: 0.532410\n",
      "Reconstruction: 0.450831, Regularization: 0.016601, Discriminator: 0.043326; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:45,341 root         INFO     Train Epoch: 131 [4096/8000 (51%)]\tTotal Loss: 1.040554\n",
      "Reconstruction: 0.945342, Regularization: 0.030237, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:45,438 root         INFO     Train Epoch: 131 [4608/8000 (58%)]\tTotal Loss: 0.675211\n",
      "Reconstruction: 0.586360, Regularization: 0.023863, Discriminator: 0.043326; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:45,535 root         INFO     Train Epoch: 131 [5120/8000 (64%)]\tTotal Loss: 0.669139\n",
      "Reconstruction: 0.581768, Regularization: 0.022388, Discriminator: 0.043326; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:45,632 root         INFO     Train Epoch: 131 [5632/8000 (70%)]\tTotal Loss: 0.675595\n",
      "Reconstruction: 0.594327, Regularization: 0.016323, Discriminator: 0.043288; Generator: 0.021656,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:48:45,729 root         INFO     Train Epoch: 131 [6144/8000 (77%)]\tTotal Loss: 0.547297\n",
      "Reconstruction: 0.462982, Regularization: 0.019333, Discriminator: 0.043317; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:45,826 root         INFO     Train Epoch: 131 [6656/8000 (83%)]\tTotal Loss: 0.467077\n",
      "Reconstruction: 0.389286, Regularization: 0.012815, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:45,925 root         INFO     Train Epoch: 131 [7168/8000 (90%)]\tTotal Loss: 0.639142\n",
      "Reconstruction: 0.553836, Regularization: 0.020327, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:46,022 root         INFO     Train Epoch: 131 [7680/8000 (96%)]\tTotal Loss: 0.800529\n",
      "Reconstruction: 0.707593, Regularization: 0.027904, Discriminator: 0.043368; Generator: 0.021664,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:46,096 root         INFO     ====> Epoch: 131 Average loss: 0.7130\n",
      "2019-04-09 22:48:46,122 root         INFO     Train Epoch: 132 [0/8000 (0%)]\tTotal Loss: 0.534097\n",
      "Reconstruction: 0.454868, Regularization: 0.014256, Discriminator: 0.043309; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:46,222 root         INFO     Train Epoch: 132 [512/8000 (6%)]\tTotal Loss: 0.878873\n",
      "Reconstruction: 0.781993, Regularization: 0.031897, Discriminator: 0.043326; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:46,321 root         INFO     Train Epoch: 132 [1024/8000 (13%)]\tTotal Loss: 0.641556\n",
      "Reconstruction: 0.560474, Regularization: 0.016078, Discriminator: 0.043347; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:46,419 root         INFO     Train Epoch: 132 [1536/8000 (19%)]\tTotal Loss: 0.671231\n",
      "Reconstruction: 0.585849, Regularization: 0.020417, Discriminator: 0.043311; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:46,517 root         INFO     Train Epoch: 132 [2048/8000 (26%)]\tTotal Loss: 0.732887\n",
      "Reconstruction: 0.638303, Regularization: 0.029578, Discriminator: 0.043346; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:46,614 root         INFO     Train Epoch: 132 [2560/8000 (32%)]\tTotal Loss: 0.722981\n",
      "Reconstruction: 0.632229, Regularization: 0.025772, Discriminator: 0.043317; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:46,712 root         INFO     Train Epoch: 132 [3072/8000 (38%)]\tTotal Loss: 0.615893\n",
      "Reconstruction: 0.528833, Regularization: 0.022075, Discriminator: 0.043330; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:46,810 root         INFO     Train Epoch: 132 [3584/8000 (45%)]\tTotal Loss: 0.675741\n",
      "Reconstruction: 0.589222, Regularization: 0.021544, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:46,908 root         INFO     Train Epoch: 132 [4096/8000 (51%)]\tTotal Loss: 0.729285\n",
      "Reconstruction: 0.644058, Regularization: 0.020250, Discriminator: 0.043316; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:47,006 root         INFO     Train Epoch: 132 [4608/8000 (58%)]\tTotal Loss: 0.643133\n",
      "Reconstruction: 0.559610, Regularization: 0.018546, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:47,104 root         INFO     Train Epoch: 132 [5120/8000 (64%)]\tTotal Loss: 0.845031\n",
      "Reconstruction: 0.752737, Regularization: 0.027293, Discriminator: 0.043337; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:47,203 root         INFO     Train Epoch: 132 [5632/8000 (70%)]\tTotal Loss: 0.855119\n",
      "Reconstruction: 0.758326, Regularization: 0.031800, Discriminator: 0.043332; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:47,301 root         INFO     Train Epoch: 132 [6144/8000 (77%)]\tTotal Loss: 0.783920\n",
      "Reconstruction: 0.692878, Regularization: 0.026060, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:47,400 root         INFO     Train Epoch: 132 [6656/8000 (83%)]\tTotal Loss: 0.616190\n",
      "Reconstruction: 0.526528, Regularization: 0.024660, Discriminator: 0.043329; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:47,498 root         INFO     Train Epoch: 132 [7168/8000 (90%)]\tTotal Loss: 0.613241\n",
      "Reconstruction: 0.529744, Regularization: 0.018489, Discriminator: 0.043340; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:47,596 root         INFO     Train Epoch: 132 [7680/8000 (96%)]\tTotal Loss: 0.908341\n",
      "Reconstruction: 0.815547, Regularization: 0.027800, Discriminator: 0.043335; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:47,669 root         INFO     ====> Epoch: 132 Average loss: 0.7189\n",
      "2019-04-09 22:48:47,696 root         INFO     Train Epoch: 133 [0/8000 (0%)]\tTotal Loss: 0.527305\n",
      "Reconstruction: 0.445314, Regularization: 0.017007, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:47,792 root         INFO     Train Epoch: 133 [512/8000 (6%)]\tTotal Loss: 0.550612\n",
      "Reconstruction: 0.468673, Regularization: 0.016976, Discriminator: 0.043296; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:47,892 root         INFO     Train Epoch: 133 [1024/8000 (13%)]\tTotal Loss: 0.577992\n",
      "Reconstruction: 0.498968, Regularization: 0.014061, Discriminator: 0.043292; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:47,992 root         INFO     Train Epoch: 133 [1536/8000 (19%)]\tTotal Loss: 0.822915\n",
      "Reconstruction: 0.732310, Regularization: 0.025613, Discriminator: 0.043324; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:48,092 root         INFO     Train Epoch: 133 [2048/8000 (26%)]\tTotal Loss: 0.591379\n",
      "Reconstruction: 0.512484, Regularization: 0.013901, Discriminator: 0.043339; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:48,192 root         INFO     Train Epoch: 133 [2560/8000 (32%)]\tTotal Loss: 0.489590\n",
      "Reconstruction: 0.408884, Regularization: 0.015713, Discriminator: 0.043329; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:48,292 root         INFO     Train Epoch: 133 [3072/8000 (38%)]\tTotal Loss: 0.806434\n",
      "Reconstruction: 0.716877, Regularization: 0.024572, Discriminator: 0.043328; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:48,392 root         INFO     Train Epoch: 133 [3584/8000 (45%)]\tTotal Loss: 0.608899\n",
      "Reconstruction: 0.527037, Regularization: 0.016874, Discriminator: 0.043332; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:48,492 root         INFO     Train Epoch: 133 [4096/8000 (51%)]\tTotal Loss: 0.551773\n",
      "Reconstruction: 0.469729, Regularization: 0.017073, Discriminator: 0.043307; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:48,592 root         INFO     Train Epoch: 133 [4608/8000 (58%)]\tTotal Loss: 0.519074\n",
      "Reconstruction: 0.432735, Regularization: 0.021362, Discriminator: 0.043314; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:48,692 root         INFO     Train Epoch: 133 [5120/8000 (64%)]\tTotal Loss: 0.885083\n",
      "Reconstruction: 0.788130, Regularization: 0.031975, Discriminator: 0.043318; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:48,792 root         INFO     Train Epoch: 133 [5632/8000 (70%)]\tTotal Loss: 0.673987\n",
      "Reconstruction: 0.585926, Regularization: 0.023091, Discriminator: 0.043318; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:48,892 root         INFO     Train Epoch: 133 [6144/8000 (77%)]\tTotal Loss: 0.649412\n",
      "Reconstruction: 0.564986, Regularization: 0.019415, Discriminator: 0.043356; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:48,992 root         INFO     Train Epoch: 133 [6656/8000 (83%)]\tTotal Loss: 0.587509\n",
      "Reconstruction: 0.507100, Regularization: 0.015435, Discriminator: 0.043319; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:49,091 root         INFO     Train Epoch: 133 [7168/8000 (90%)]\tTotal Loss: 0.653618\n",
      "Reconstruction: 0.565132, Regularization: 0.023504, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:49,192 root         INFO     Train Epoch: 133 [7680/8000 (96%)]\tTotal Loss: 0.578032\n",
      "Reconstruction: 0.496126, Regularization: 0.016929, Discriminator: 0.043323; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:49,266 root         INFO     ====> Epoch: 133 Average loss: 0.7160\n",
      "2019-04-09 22:48:49,292 root         INFO     Train Epoch: 134 [0/8000 (0%)]\tTotal Loss: 0.825561\n",
      "Reconstruction: 0.737867, Regularization: 0.022714, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:49,393 root         INFO     Train Epoch: 134 [512/8000 (6%)]\tTotal Loss: 0.465707\n",
      "Reconstruction: 0.385792, Regularization: 0.014935, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:49,492 root         INFO     Train Epoch: 134 [1024/8000 (13%)]\tTotal Loss: 0.646546\n",
      "Reconstruction: 0.563399, Regularization: 0.018166, Discriminator: 0.043324; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:49,591 root         INFO     Train Epoch: 134 [1536/8000 (19%)]\tTotal Loss: 0.753230\n",
      "Reconstruction: 0.666204, Regularization: 0.022038, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:49,690 root         INFO     Train Epoch: 134 [2048/8000 (26%)]\tTotal Loss: 0.749667\n",
      "Reconstruction: 0.653131, Regularization: 0.031546, Discriminator: 0.043326; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:49,789 root         INFO     Train Epoch: 134 [2560/8000 (32%)]\tTotal Loss: 0.729432\n",
      "Reconstruction: 0.642168, Regularization: 0.022309, Discriminator: 0.043298; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:49,888 root         INFO     Train Epoch: 134 [3072/8000 (38%)]\tTotal Loss: 0.693811\n",
      "Reconstruction: 0.604753, Regularization: 0.024085, Discriminator: 0.043316; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:49,986 root         INFO     Train Epoch: 134 [3584/8000 (45%)]\tTotal Loss: 0.675961\n",
      "Reconstruction: 0.594107, Regularization: 0.016873, Discriminator: 0.043318; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:50,085 root         INFO     Train Epoch: 134 [4096/8000 (51%)]\tTotal Loss: 0.674774\n",
      "Reconstruction: 0.586281, Regularization: 0.023533, Discriminator: 0.043301; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:50,182 root         INFO     Train Epoch: 134 [4608/8000 (58%)]\tTotal Loss: 0.880133\n",
      "Reconstruction: 0.786932, Regularization: 0.028256, Discriminator: 0.043285; Generator: 0.021660,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:48:50,280 root         INFO     Train Epoch: 134 [5120/8000 (64%)]\tTotal Loss: 0.890395\n",
      "Reconstruction: 0.796830, Regularization: 0.028575, Discriminator: 0.043329; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:50,378 root         INFO     Train Epoch: 134 [5632/8000 (70%)]\tTotal Loss: 0.715708\n",
      "Reconstruction: 0.627184, Regularization: 0.023549, Discriminator: 0.043319; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:50,476 root         INFO     Train Epoch: 134 [6144/8000 (77%)]\tTotal Loss: 0.773293\n",
      "Reconstruction: 0.681494, Regularization: 0.026817, Discriminator: 0.043316; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:50,575 root         INFO     Train Epoch: 134 [6656/8000 (83%)]\tTotal Loss: 0.872690\n",
      "Reconstruction: 0.777760, Regularization: 0.029942, Discriminator: 0.043325; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:50,673 root         INFO     Train Epoch: 134 [7168/8000 (90%)]\tTotal Loss: 0.780740\n",
      "Reconstruction: 0.689590, Regularization: 0.026171, Discriminator: 0.043316; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:50,769 root         INFO     Train Epoch: 134 [7680/8000 (96%)]\tTotal Loss: 0.684561\n",
      "Reconstruction: 0.596543, Regularization: 0.023032, Discriminator: 0.043322; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:50,842 root         INFO     ====> Epoch: 134 Average loss: 0.7163\n",
      "2019-04-09 22:48:50,869 root         INFO     Train Epoch: 135 [0/8000 (0%)]\tTotal Loss: 0.799302\n",
      "Reconstruction: 0.712856, Regularization: 0.021456, Discriminator: 0.043328; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:50,970 root         INFO     Train Epoch: 135 [512/8000 (6%)]\tTotal Loss: 0.889855\n",
      "Reconstruction: 0.790295, Regularization: 0.034579, Discriminator: 0.043312; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:51,071 root         INFO     Train Epoch: 135 [1024/8000 (13%)]\tTotal Loss: 0.566951\n",
      "Reconstruction: 0.479672, Regularization: 0.022276, Discriminator: 0.043334; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:51,171 root         INFO     Train Epoch: 135 [1536/8000 (19%)]\tTotal Loss: 0.934238\n",
      "Reconstruction: 0.837542, Regularization: 0.031720, Discriminator: 0.043312; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:51,271 root         INFO     Train Epoch: 135 [2048/8000 (26%)]\tTotal Loss: 0.705827\n",
      "Reconstruction: 0.615927, Regularization: 0.024922, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:51,369 root         INFO     Train Epoch: 135 [2560/8000 (32%)]\tTotal Loss: 0.535054\n",
      "Reconstruction: 0.449540, Regularization: 0.020543, Discriminator: 0.043310; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:51,468 root         INFO     Train Epoch: 135 [3072/8000 (38%)]\tTotal Loss: 0.638822\n",
      "Reconstruction: 0.552107, Regularization: 0.021724, Discriminator: 0.043327; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:51,567 root         INFO     Train Epoch: 135 [3584/8000 (45%)]\tTotal Loss: 0.612852\n",
      "Reconstruction: 0.526603, Regularization: 0.021256, Discriminator: 0.043336; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:51,665 root         INFO     Train Epoch: 135 [4096/8000 (51%)]\tTotal Loss: 0.508245\n",
      "Reconstruction: 0.429089, Regularization: 0.014172, Discriminator: 0.043330; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:51,763 root         INFO     Train Epoch: 135 [4608/8000 (58%)]\tTotal Loss: 0.446138\n",
      "Reconstruction: 0.364130, Regularization: 0.017029, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:51,862 root         INFO     Train Epoch: 135 [5120/8000 (64%)]\tTotal Loss: 0.900959\n",
      "Reconstruction: 0.800140, Regularization: 0.035883, Discriminator: 0.043285; Generator: 0.021651,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:48:51,960 root         INFO     Train Epoch: 135 [5632/8000 (70%)]\tTotal Loss: 0.740403\n",
      "Reconstruction: 0.648744, Regularization: 0.026694, Discriminator: 0.043309; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:52,058 root         INFO     Train Epoch: 135 [6144/8000 (77%)]\tTotal Loss: 0.692367\n",
      "Reconstruction: 0.604236, Regularization: 0.023152, Discriminator: 0.043324; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:52,155 root         INFO     Train Epoch: 135 [6656/8000 (83%)]\tTotal Loss: 0.747495\n",
      "Reconstruction: 0.656033, Regularization: 0.026488, Discriminator: 0.043319; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:52,252 root         INFO     Train Epoch: 135 [7168/8000 (90%)]\tTotal Loss: 0.727465\n",
      "Reconstruction: 0.639656, Regularization: 0.022823, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:52,350 root         INFO     Train Epoch: 135 [7680/8000 (96%)]\tTotal Loss: 0.824291\n",
      "Reconstruction: 0.726512, Regularization: 0.032808, Discriminator: 0.043307; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:52,425 root         INFO     ====> Epoch: 135 Average loss: 0.7173\n",
      "2019-04-09 22:48:52,452 root         INFO     Train Epoch: 136 [0/8000 (0%)]\tTotal Loss: 0.695100\n",
      "Reconstruction: 0.609281, Regularization: 0.020829, Discriminator: 0.043330; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:52,553 root         INFO     Train Epoch: 136 [512/8000 (6%)]\tTotal Loss: 0.567339\n",
      "Reconstruction: 0.484635, Regularization: 0.017723, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:52,650 root         INFO     Train Epoch: 136 [1024/8000 (13%)]\tTotal Loss: 0.659768\n",
      "Reconstruction: 0.579217, Regularization: 0.015554, Discriminator: 0.043330; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:52,748 root         INFO     Train Epoch: 136 [1536/8000 (19%)]\tTotal Loss: 0.494651\n",
      "Reconstruction: 0.413522, Regularization: 0.016146, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:52,846 root         INFO     Train Epoch: 136 [2048/8000 (26%)]\tTotal Loss: 0.570063\n",
      "Reconstruction: 0.490178, Regularization: 0.014902, Discriminator: 0.043326; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:52,943 root         INFO     Train Epoch: 136 [2560/8000 (32%)]\tTotal Loss: 0.609345\n",
      "Reconstruction: 0.525922, Regularization: 0.018442, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:53,041 root         INFO     Train Epoch: 136 [3072/8000 (38%)]\tTotal Loss: 0.917901\n",
      "Reconstruction: 0.820261, Regularization: 0.032670, Discriminator: 0.043315; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:53,138 root         INFO     Train Epoch: 136 [3584/8000 (45%)]\tTotal Loss: 0.669487\n",
      "Reconstruction: 0.584273, Regularization: 0.020231, Discriminator: 0.043325; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:53,236 root         INFO     Train Epoch: 136 [4096/8000 (51%)]\tTotal Loss: 0.781945\n",
      "Reconstruction: 0.690310, Regularization: 0.026653, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:53,333 root         INFO     Train Epoch: 136 [4608/8000 (58%)]\tTotal Loss: 0.732415\n",
      "Reconstruction: 0.646862, Regularization: 0.020541, Discriminator: 0.043349; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:53,431 root         INFO     Train Epoch: 136 [5120/8000 (64%)]\tTotal Loss: 0.657180\n",
      "Reconstruction: 0.571425, Regularization: 0.020740, Discriminator: 0.043351; Generator: 0.021664,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:48:53,527 root         INFO     Train Epoch: 136 [5632/8000 (70%)]\tTotal Loss: 0.786743\n",
      "Reconstruction: 0.701479, Regularization: 0.020280, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:53,624 root         INFO     Train Epoch: 136 [6144/8000 (77%)]\tTotal Loss: 0.611102\n",
      "Reconstruction: 0.530197, Regularization: 0.015916, Discriminator: 0.043333; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:53,720 root         INFO     Train Epoch: 136 [6656/8000 (83%)]\tTotal Loss: 0.623943\n",
      "Reconstruction: 0.538794, Regularization: 0.020161, Discriminator: 0.043328; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:53,818 root         INFO     Train Epoch: 136 [7168/8000 (90%)]\tTotal Loss: 1.128959\n",
      "Reconstruction: 1.033092, Regularization: 0.030883, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:53,916 root         INFO     Train Epoch: 136 [7680/8000 (96%)]\tTotal Loss: 0.659797\n",
      "Reconstruction: 0.573813, Regularization: 0.020994, Discriminator: 0.043329; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:53,989 root         INFO     ====> Epoch: 136 Average loss: 0.7166\n",
      "2019-04-09 22:48:54,016 root         INFO     Train Epoch: 137 [0/8000 (0%)]\tTotal Loss: 0.914752\n",
      "Reconstruction: 0.822803, Regularization: 0.026972, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:54,114 root         INFO     Train Epoch: 137 [512/8000 (6%)]\tTotal Loss: 0.723899\n",
      "Reconstruction: 0.631281, Regularization: 0.027632, Discriminator: 0.043321; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:54,211 root         INFO     Train Epoch: 137 [1024/8000 (13%)]\tTotal Loss: 0.524369\n",
      "Reconstruction: 0.441476, Regularization: 0.017909, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:54,308 root         INFO     Train Epoch: 137 [1536/8000 (19%)]\tTotal Loss: 0.928682\n",
      "Reconstruction: 0.835905, Regularization: 0.027786, Discriminator: 0.043325; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:54,406 root         INFO     Train Epoch: 137 [2048/8000 (26%)]\tTotal Loss: 0.780257\n",
      "Reconstruction: 0.692918, Regularization: 0.022351, Discriminator: 0.043321; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:54,503 root         INFO     Train Epoch: 137 [2560/8000 (32%)]\tTotal Loss: 0.479646\n",
      "Reconstruction: 0.400331, Regularization: 0.014337, Discriminator: 0.043317; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:54,600 root         INFO     Train Epoch: 137 [3072/8000 (38%)]\tTotal Loss: 0.758852\n",
      "Reconstruction: 0.669062, Regularization: 0.024795, Discriminator: 0.043326; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:54,698 root         INFO     Train Epoch: 137 [3584/8000 (45%)]\tTotal Loss: 0.865882\n",
      "Reconstruction: 0.772692, Regularization: 0.028187, Discriminator: 0.043346; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:54,795 root         INFO     Train Epoch: 137 [4096/8000 (51%)]\tTotal Loss: 0.847346\n",
      "Reconstruction: 0.758920, Regularization: 0.023437, Discriminator: 0.043313; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:54,893 root         INFO     Train Epoch: 137 [4608/8000 (58%)]\tTotal Loss: 0.614425\n",
      "Reconstruction: 0.534763, Regularization: 0.014690, Discriminator: 0.043308; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:54,997 root         INFO     Train Epoch: 137 [5120/8000 (64%)]\tTotal Loss: 0.694910\n",
      "Reconstruction: 0.606713, Regularization: 0.023207, Discriminator: 0.043323; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:55,107 root         INFO     Train Epoch: 137 [5632/8000 (70%)]\tTotal Loss: 0.633406\n",
      "Reconstruction: 0.547044, Regularization: 0.021396, Discriminator: 0.043309; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:55,215 root         INFO     Train Epoch: 137 [6144/8000 (77%)]\tTotal Loss: 0.843436\n",
      "Reconstruction: 0.760847, Regularization: 0.017623, Discriminator: 0.043315; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:55,318 root         INFO     Train Epoch: 137 [6656/8000 (83%)]\tTotal Loss: 0.833837\n",
      "Reconstruction: 0.744076, Regularization: 0.024795, Discriminator: 0.043306; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:55,418 root         INFO     Train Epoch: 137 [7168/8000 (90%)]\tTotal Loss: 0.707941\n",
      "Reconstruction: 0.621391, Regularization: 0.021577, Discriminator: 0.043319; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:55,517 root         INFO     Train Epoch: 137 [7680/8000 (96%)]\tTotal Loss: 0.990806\n",
      "Reconstruction: 0.893301, Regularization: 0.032520, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:55,592 root         INFO     ====> Epoch: 137 Average loss: 0.7174\n",
      "2019-04-09 22:48:55,618 root         INFO     Train Epoch: 138 [0/8000 (0%)]\tTotal Loss: 1.021947\n",
      "Reconstruction: 0.924629, Regularization: 0.032336, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:55,718 root         INFO     Train Epoch: 138 [512/8000 (6%)]\tTotal Loss: 0.660172\n",
      "Reconstruction: 0.580202, Regularization: 0.014992, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:55,817 root         INFO     Train Epoch: 138 [1024/8000 (13%)]\tTotal Loss: 0.925718\n",
      "Reconstruction: 0.829745, Regularization: 0.030993, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:55,916 root         INFO     Train Epoch: 138 [1536/8000 (19%)]\tTotal Loss: 0.744916\n",
      "Reconstruction: 0.657112, Regularization: 0.022818, Discriminator: 0.043321; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:56,015 root         INFO     Train Epoch: 138 [2048/8000 (26%)]\tTotal Loss: 0.834327\n",
      "Reconstruction: 0.751555, Regularization: 0.017805, Discriminator: 0.043308; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:56,114 root         INFO     Train Epoch: 138 [2560/8000 (32%)]\tTotal Loss: 0.988689\n",
      "Reconstruction: 0.895833, Regularization: 0.027877, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:56,213 root         INFO     Train Epoch: 138 [3072/8000 (38%)]\tTotal Loss: 0.642434\n",
      "Reconstruction: 0.551546, Regularization: 0.025903, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:56,312 root         INFO     Train Epoch: 138 [3584/8000 (45%)]\tTotal Loss: 0.702233\n",
      "Reconstruction: 0.616507, Regularization: 0.020745, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:56,411 root         INFO     Train Epoch: 138 [4096/8000 (51%)]\tTotal Loss: 0.569108\n",
      "Reconstruction: 0.482856, Regularization: 0.021277, Discriminator: 0.043316; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:56,510 root         INFO     Train Epoch: 138 [4608/8000 (58%)]\tTotal Loss: 0.686528\n",
      "Reconstruction: 0.596117, Regularization: 0.025417, Discriminator: 0.043330; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:56,609 root         INFO     Train Epoch: 138 [5120/8000 (64%)]\tTotal Loss: 0.713938\n",
      "Reconstruction: 0.627062, Regularization: 0.021898, Discriminator: 0.043314; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:56,708 root         INFO     Train Epoch: 138 [5632/8000 (70%)]\tTotal Loss: 0.597667\n",
      "Reconstruction: 0.515864, Regularization: 0.016812, Discriminator: 0.043330; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:56,807 root         INFO     Train Epoch: 138 [6144/8000 (77%)]\tTotal Loss: 0.511190\n",
      "Reconstruction: 0.431505, Regularization: 0.014685, Discriminator: 0.043339; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:56,906 root         INFO     Train Epoch: 138 [6656/8000 (83%)]\tTotal Loss: 0.815077\n",
      "Reconstruction: 0.726649, Regularization: 0.023472, Discriminator: 0.043295; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:57,005 root         INFO     Train Epoch: 138 [7168/8000 (90%)]\tTotal Loss: 0.662235\n",
      "Reconstruction: 0.576684, Regularization: 0.020580, Discriminator: 0.043316; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:57,104 root         INFO     Train Epoch: 138 [7680/8000 (96%)]\tTotal Loss: 0.556635\n",
      "Reconstruction: 0.474324, Regularization: 0.017313, Discriminator: 0.043338; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:57,178 root         INFO     ====> Epoch: 138 Average loss: 0.7159\n",
      "2019-04-09 22:48:57,204 root         INFO     Train Epoch: 139 [0/8000 (0%)]\tTotal Loss: 0.725422\n",
      "Reconstruction: 0.645086, Regularization: 0.015352, Discriminator: 0.043311; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:57,305 root         INFO     Train Epoch: 139 [512/8000 (6%)]\tTotal Loss: 0.858470\n",
      "Reconstruction: 0.766356, Regularization: 0.027127, Discriminator: 0.043323; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:57,406 root         INFO     Train Epoch: 139 [1024/8000 (13%)]\tTotal Loss: 0.563259\n",
      "Reconstruction: 0.481593, Regularization: 0.016687, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:57,507 root         INFO     Train Epoch: 139 [1536/8000 (19%)]\tTotal Loss: 0.734153\n",
      "Reconstruction: 0.645473, Regularization: 0.023696, Discriminator: 0.043324; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:57,607 root         INFO     Train Epoch: 139 [2048/8000 (26%)]\tTotal Loss: 0.728392\n",
      "Reconstruction: 0.640039, Regularization: 0.023365, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:57,708 root         INFO     Train Epoch: 139 [2560/8000 (32%)]\tTotal Loss: 0.703809\n",
      "Reconstruction: 0.613340, Regularization: 0.025488, Discriminator: 0.043324; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:57,808 root         INFO     Train Epoch: 139 [3072/8000 (38%)]\tTotal Loss: 0.575867\n",
      "Reconstruction: 0.497108, Regularization: 0.013780, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:57,908 root         INFO     Train Epoch: 139 [3584/8000 (45%)]\tTotal Loss: 0.609826\n",
      "Reconstruction: 0.526328, Regularization: 0.018514, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:58,007 root         INFO     Train Epoch: 139 [4096/8000 (51%)]\tTotal Loss: 0.644464\n",
      "Reconstruction: 0.558937, Regularization: 0.020549, Discriminator: 0.043315; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:58,107 root         INFO     Train Epoch: 139 [4608/8000 (58%)]\tTotal Loss: 0.790013\n",
      "Reconstruction: 0.697600, Regularization: 0.027427, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:58,206 root         INFO     Train Epoch: 139 [5120/8000 (64%)]\tTotal Loss: 0.912455\n",
      "Reconstruction: 0.815882, Regularization: 0.031587, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:58,306 root         INFO     Train Epoch: 139 [5632/8000 (70%)]\tTotal Loss: 0.578618\n",
      "Reconstruction: 0.494855, Regularization: 0.018784, Discriminator: 0.043314; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:58,407 root         INFO     Train Epoch: 139 [6144/8000 (77%)]\tTotal Loss: 0.728996\n",
      "Reconstruction: 0.642463, Regularization: 0.021567, Discriminator: 0.043299; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:58,507 root         INFO     Train Epoch: 139 [6656/8000 (83%)]\tTotal Loss: 0.642219\n",
      "Reconstruction: 0.556458, Regularization: 0.020779, Discriminator: 0.043329; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:58,604 root         INFO     Train Epoch: 139 [7168/8000 (90%)]\tTotal Loss: 0.615869\n",
      "Reconstruction: 0.531964, Regularization: 0.018923, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:58,701 root         INFO     Train Epoch: 139 [7680/8000 (96%)]\tTotal Loss: 0.676706\n",
      "Reconstruction: 0.590112, Regularization: 0.021623, Discriminator: 0.043311; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:58,775 root         INFO     ====> Epoch: 139 Average loss: 0.7189\n",
      "2019-04-09 22:48:58,801 root         INFO     Train Epoch: 140 [0/8000 (0%)]\tTotal Loss: 0.787203\n",
      "Reconstruction: 0.698257, Regularization: 0.023955, Discriminator: 0.043326; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:58,900 root         INFO     Train Epoch: 140 [512/8000 (6%)]\tTotal Loss: 0.587141\n",
      "Reconstruction: 0.501364, Regularization: 0.020800, Discriminator: 0.043314; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:58,998 root         INFO     Train Epoch: 140 [1024/8000 (13%)]\tTotal Loss: 0.630139\n",
      "Reconstruction: 0.543570, Regularization: 0.021576, Discriminator: 0.043341; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:59,096 root         INFO     Train Epoch: 140 [1536/8000 (19%)]\tTotal Loss: 0.815850\n",
      "Reconstruction: 0.730666, Regularization: 0.020202, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:59,194 root         INFO     Train Epoch: 140 [2048/8000 (26%)]\tTotal Loss: 0.495226\n",
      "Reconstruction: 0.412566, Regularization: 0.017682, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:59,292 root         INFO     Train Epoch: 140 [2560/8000 (32%)]\tTotal Loss: 0.917812\n",
      "Reconstruction: 0.822825, Regularization: 0.030009, Discriminator: 0.043321; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:59,391 root         INFO     Train Epoch: 140 [3072/8000 (38%)]\tTotal Loss: 0.577151\n",
      "Reconstruction: 0.495491, Regularization: 0.016674, Discriminator: 0.043320; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:59,489 root         INFO     Train Epoch: 140 [3584/8000 (45%)]\tTotal Loss: 0.772566\n",
      "Reconstruction: 0.685723, Regularization: 0.021861, Discriminator: 0.043319; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:59,587 root         INFO     Train Epoch: 140 [4096/8000 (51%)]\tTotal Loss: 0.803426\n",
      "Reconstruction: 0.714747, Regularization: 0.023712, Discriminator: 0.043308; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:59,685 root         INFO     Train Epoch: 140 [4608/8000 (58%)]\tTotal Loss: 0.532399\n",
      "Reconstruction: 0.450229, Regularization: 0.017185, Discriminator: 0.043328; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:59,784 root         INFO     Train Epoch: 140 [5120/8000 (64%)]\tTotal Loss: 0.587901\n",
      "Reconstruction: 0.504605, Regularization: 0.018314, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:59,882 root         INFO     Train Epoch: 140 [5632/8000 (70%)]\tTotal Loss: 0.752036\n",
      "Reconstruction: 0.656655, Regularization: 0.030405, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:48:59,980 root         INFO     Train Epoch: 140 [6144/8000 (77%)]\tTotal Loss: 0.528966\n",
      "Reconstruction: 0.444992, Regularization: 0.019005, Discriminator: 0.043308; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:00,078 root         INFO     Train Epoch: 140 [6656/8000 (83%)]\tTotal Loss: 0.709877\n",
      "Reconstruction: 0.622065, Regularization: 0.022819, Discriminator: 0.043333; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:00,176 root         INFO     Train Epoch: 140 [7168/8000 (90%)]\tTotal Loss: 0.758615\n",
      "Reconstruction: 0.671724, Regularization: 0.021914, Discriminator: 0.043317; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:00,274 root         INFO     Train Epoch: 140 [7680/8000 (96%)]\tTotal Loss: 0.764076\n",
      "Reconstruction: 0.674732, Regularization: 0.024359, Discriminator: 0.043328; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:00,348 root         INFO     ====> Epoch: 140 Average loss: 0.7146\n",
      "2019-04-09 22:49:00,375 root         INFO     Train Epoch: 141 [0/8000 (0%)]\tTotal Loss: 0.509834\n",
      "Reconstruction: 0.428720, Regularization: 0.016136, Discriminator: 0.043314; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:00,476 root         INFO     Train Epoch: 141 [512/8000 (6%)]\tTotal Loss: 0.576434\n",
      "Reconstruction: 0.493664, Regularization: 0.017786, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:00,576 root         INFO     Train Epoch: 141 [1024/8000 (13%)]\tTotal Loss: 0.730743\n",
      "Reconstruction: 0.639165, Regularization: 0.026596, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:00,676 root         INFO     Train Epoch: 141 [1536/8000 (19%)]\tTotal Loss: 0.539200\n",
      "Reconstruction: 0.460588, Regularization: 0.013636, Discriminator: 0.043319; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:00,776 root         INFO     Train Epoch: 141 [2048/8000 (26%)]\tTotal Loss: 0.644319\n",
      "Reconstruction: 0.560839, Regularization: 0.018504, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:00,876 root         INFO     Train Epoch: 141 [2560/8000 (32%)]\tTotal Loss: 0.765013\n",
      "Reconstruction: 0.674195, Regularization: 0.025836, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:00,975 root         INFO     Train Epoch: 141 [3072/8000 (38%)]\tTotal Loss: 0.535329\n",
      "Reconstruction: 0.454369, Regularization: 0.015976, Discriminator: 0.043323; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:01,074 root         INFO     Train Epoch: 141 [3584/8000 (45%)]\tTotal Loss: 0.718291\n",
      "Reconstruction: 0.631868, Regularization: 0.021438, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:01,172 root         INFO     Train Epoch: 141 [4096/8000 (51%)]\tTotal Loss: 1.044504\n",
      "Reconstruction: 0.942108, Regularization: 0.037415, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:01,271 root         INFO     Train Epoch: 141 [4608/8000 (58%)]\tTotal Loss: 0.481525\n",
      "Reconstruction: 0.403378, Regularization: 0.013166, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:01,369 root         INFO     Train Epoch: 141 [5120/8000 (64%)]\tTotal Loss: 0.799650\n",
      "Reconstruction: 0.707965, Regularization: 0.026677, Discriminator: 0.043341; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:01,468 root         INFO     Train Epoch: 141 [5632/8000 (70%)]\tTotal Loss: 1.123732\n",
      "Reconstruction: 1.011701, Regularization: 0.047041, Discriminator: 0.043331; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:01,566 root         INFO     Train Epoch: 141 [6144/8000 (77%)]\tTotal Loss: 0.566690\n",
      "Reconstruction: 0.482983, Regularization: 0.018735, Discriminator: 0.043314; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:01,665 root         INFO     Train Epoch: 141 [6656/8000 (83%)]\tTotal Loss: 0.813953\n",
      "Reconstruction: 0.719880, Regularization: 0.029091, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:01,763 root         INFO     Train Epoch: 141 [7168/8000 (90%)]\tTotal Loss: 0.689716\n",
      "Reconstruction: 0.605252, Regularization: 0.019494, Discriminator: 0.043315; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:01,862 root         INFO     Train Epoch: 141 [7680/8000 (96%)]\tTotal Loss: 0.777488\n",
      "Reconstruction: 0.683223, Regularization: 0.029300, Discriminator: 0.043302; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:01,935 root         INFO     ====> Epoch: 141 Average loss: 0.7181\n",
      "2019-04-09 22:49:01,962 root         INFO     Train Epoch: 142 [0/8000 (0%)]\tTotal Loss: 0.925331\n",
      "Reconstruction: 0.826373, Regularization: 0.033970, Discriminator: 0.043326; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:02,062 root         INFO     Train Epoch: 142 [512/8000 (6%)]\tTotal Loss: 0.685662\n",
      "Reconstruction: 0.600109, Regularization: 0.020583, Discriminator: 0.043316; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:02,162 root         INFO     Train Epoch: 142 [1024/8000 (13%)]\tTotal Loss: 0.624905\n",
      "Reconstruction: 0.539971, Regularization: 0.019949, Discriminator: 0.043330; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:02,262 root         INFO     Train Epoch: 142 [1536/8000 (19%)]\tTotal Loss: 0.573289\n",
      "Reconstruction: 0.490148, Regularization: 0.018166, Discriminator: 0.043315; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:02,359 root         INFO     Train Epoch: 142 [2048/8000 (26%)]\tTotal Loss: 0.507989\n",
      "Reconstruction: 0.428072, Regularization: 0.014928, Discriminator: 0.043330; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:02,456 root         INFO     Train Epoch: 142 [2560/8000 (32%)]\tTotal Loss: 0.620750\n",
      "Reconstruction: 0.534746, Regularization: 0.021027, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:02,554 root         INFO     Train Epoch: 142 [3072/8000 (38%)]\tTotal Loss: 0.630593\n",
      "Reconstruction: 0.546918, Regularization: 0.018682, Discriminator: 0.043332; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:02,651 root         INFO     Train Epoch: 142 [3584/8000 (45%)]\tTotal Loss: 0.832490\n",
      "Reconstruction: 0.740899, Regularization: 0.026617, Discriminator: 0.043315; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:02,748 root         INFO     Train Epoch: 142 [4096/8000 (51%)]\tTotal Loss: 0.929187\n",
      "Reconstruction: 0.836552, Regularization: 0.027659, Discriminator: 0.043323; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:02,846 root         INFO     Train Epoch: 142 [4608/8000 (58%)]\tTotal Loss: 0.408168\n",
      "Reconstruction: 0.326615, Regularization: 0.016570, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:02,943 root         INFO     Train Epoch: 142 [5120/8000 (64%)]\tTotal Loss: 0.528378\n",
      "Reconstruction: 0.443906, Regularization: 0.019514, Discriminator: 0.043299; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:03,041 root         INFO     Train Epoch: 142 [5632/8000 (70%)]\tTotal Loss: 0.723578\n",
      "Reconstruction: 0.635818, Regularization: 0.022798, Discriminator: 0.043299; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:03,138 root         INFO     Train Epoch: 142 [6144/8000 (77%)]\tTotal Loss: 0.745207\n",
      "Reconstruction: 0.659094, Regularization: 0.021130, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:03,235 root         INFO     Train Epoch: 142 [6656/8000 (83%)]\tTotal Loss: 0.599611\n",
      "Reconstruction: 0.513965, Regularization: 0.020664, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:03,332 root         INFO     Train Epoch: 142 [7168/8000 (90%)]\tTotal Loss: 0.805872\n",
      "Reconstruction: 0.717096, Regularization: 0.023795, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:03,430 root         INFO     Train Epoch: 142 [7680/8000 (96%)]\tTotal Loss: 0.552731\n",
      "Reconstruction: 0.471286, Regularization: 0.016464, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:03,503 root         INFO     ====> Epoch: 142 Average loss: 0.7160\n",
      "2019-04-09 22:49:03,529 root         INFO     Train Epoch: 143 [0/8000 (0%)]\tTotal Loss: 0.740175\n",
      "Reconstruction: 0.658322, Regularization: 0.016859, Discriminator: 0.043332; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:03,627 root         INFO     Train Epoch: 143 [512/8000 (6%)]\tTotal Loss: 0.841229\n",
      "Reconstruction: 0.749449, Regularization: 0.026796, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:03,724 root         INFO     Train Epoch: 143 [1024/8000 (13%)]\tTotal Loss: 0.749901\n",
      "Reconstruction: 0.662196, Regularization: 0.022728, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:03,821 root         INFO     Train Epoch: 143 [1536/8000 (19%)]\tTotal Loss: 0.991540\n",
      "Reconstruction: 0.898901, Regularization: 0.027657, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:03,919 root         INFO     Train Epoch: 143 [2048/8000 (26%)]\tTotal Loss: 0.727589\n",
      "Reconstruction: 0.637933, Regularization: 0.024674, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:04,016 root         INFO     Train Epoch: 143 [2560/8000 (32%)]\tTotal Loss: 0.936421\n",
      "Reconstruction: 0.834657, Regularization: 0.036779, Discriminator: 0.043322; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:04,114 root         INFO     Train Epoch: 143 [3072/8000 (38%)]\tTotal Loss: 0.925658\n",
      "Reconstruction: 0.827677, Regularization: 0.033001, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:04,211 root         INFO     Train Epoch: 143 [3584/8000 (45%)]\tTotal Loss: 0.585623\n",
      "Reconstruction: 0.500457, Regularization: 0.020178, Discriminator: 0.043325; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:04,308 root         INFO     Train Epoch: 143 [4096/8000 (51%)]\tTotal Loss: 0.492487\n",
      "Reconstruction: 0.416350, Regularization: 0.011156, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:04,406 root         INFO     Train Epoch: 143 [4608/8000 (58%)]\tTotal Loss: 0.743813\n",
      "Reconstruction: 0.657527, Regularization: 0.021304, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:04,504 root         INFO     Train Epoch: 143 [5120/8000 (64%)]\tTotal Loss: 0.562586\n",
      "Reconstruction: 0.478503, Regularization: 0.019103, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:04,600 root         INFO     Train Epoch: 143 [5632/8000 (70%)]\tTotal Loss: 0.738587\n",
      "Reconstruction: 0.648477, Regularization: 0.025146, Discriminator: 0.043299; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:04,698 root         INFO     Train Epoch: 143 [6144/8000 (77%)]\tTotal Loss: 0.527231\n",
      "Reconstruction: 0.444760, Regularization: 0.017526, Discriminator: 0.043282; Generator: 0.021663,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:49:04,796 root         INFO     Train Epoch: 143 [6656/8000 (83%)]\tTotal Loss: 0.567416\n",
      "Reconstruction: 0.480757, Regularization: 0.021674, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:04,894 root         INFO     Train Epoch: 143 [7168/8000 (90%)]\tTotal Loss: 1.188925\n",
      "Reconstruction: 1.090350, Regularization: 0.033540, Discriminator: 0.043377; Generator: 0.021658,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:49:04,992 root         INFO     Train Epoch: 143 [7680/8000 (96%)]\tTotal Loss: 0.568380\n",
      "Reconstruction: 0.487496, Regularization: 0.015901, Discriminator: 0.043326; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:05,065 root         INFO     ====> Epoch: 143 Average loss: 0.7179\n",
      "2019-04-09 22:49:05,092 root         INFO     Train Epoch: 144 [0/8000 (0%)]\tTotal Loss: 0.578287\n",
      "Reconstruction: 0.495740, Regularization: 0.017594, Discriminator: 0.043296; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:05,190 root         INFO     Train Epoch: 144 [512/8000 (6%)]\tTotal Loss: 0.532722\n",
      "Reconstruction: 0.455084, Regularization: 0.012649, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:05,287 root         INFO     Train Epoch: 144 [1024/8000 (13%)]\tTotal Loss: 0.627111\n",
      "Reconstruction: 0.543275, Regularization: 0.018854, Discriminator: 0.043324; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:05,384 root         INFO     Train Epoch: 144 [1536/8000 (19%)]\tTotal Loss: 0.739651\n",
      "Reconstruction: 0.649707, Regularization: 0.024961, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:05,482 root         INFO     Train Epoch: 144 [2048/8000 (26%)]\tTotal Loss: 0.455828\n",
      "Reconstruction: 0.376958, Regularization: 0.013891, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:05,580 root         INFO     Train Epoch: 144 [2560/8000 (32%)]\tTotal Loss: 0.513319\n",
      "Reconstruction: 0.430378, Regularization: 0.017959, Discriminator: 0.043318; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:05,679 root         INFO     Train Epoch: 144 [3072/8000 (38%)]\tTotal Loss: 0.746711\n",
      "Reconstruction: 0.657895, Regularization: 0.023824, Discriminator: 0.043330; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:05,777 root         INFO     Train Epoch: 144 [3584/8000 (45%)]\tTotal Loss: 0.800466\n",
      "Reconstruction: 0.712728, Regularization: 0.022771, Discriminator: 0.043306; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:05,875 root         INFO     Train Epoch: 144 [4096/8000 (51%)]\tTotal Loss: 0.621734\n",
      "Reconstruction: 0.534184, Regularization: 0.022578, Discriminator: 0.043312; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:05,972 root         INFO     Train Epoch: 144 [4608/8000 (58%)]\tTotal Loss: 0.677047\n",
      "Reconstruction: 0.591274, Regularization: 0.020777, Discriminator: 0.043333; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:06,069 root         INFO     Train Epoch: 144 [5120/8000 (64%)]\tTotal Loss: 0.702201\n",
      "Reconstruction: 0.617074, Regularization: 0.020163, Discriminator: 0.043302; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:06,166 root         INFO     Train Epoch: 144 [5632/8000 (70%)]\tTotal Loss: 0.533151\n",
      "Reconstruction: 0.457421, Regularization: 0.010738, Discriminator: 0.043331; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:06,262 root         INFO     Train Epoch: 144 [6144/8000 (77%)]\tTotal Loss: 0.787255\n",
      "Reconstruction: 0.693117, Regularization: 0.029158, Discriminator: 0.043323; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:06,359 root         INFO     Train Epoch: 144 [6656/8000 (83%)]\tTotal Loss: 0.648919\n",
      "Reconstruction: 0.563390, Regularization: 0.020559, Discriminator: 0.043310; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:06,455 root         INFO     Train Epoch: 144 [7168/8000 (90%)]\tTotal Loss: 0.528865\n",
      "Reconstruction: 0.448678, Regularization: 0.015173, Discriminator: 0.043361; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:06,552 root         INFO     Train Epoch: 144 [7680/8000 (96%)]\tTotal Loss: 0.741127\n",
      "Reconstruction: 0.654099, Regularization: 0.022012, Discriminator: 0.043352; Generator: 0.021664,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:49:06,624 root         INFO     ====> Epoch: 144 Average loss: 0.7153\n",
      "2019-04-09 22:49:06,651 root         INFO     Train Epoch: 145 [0/8000 (0%)]\tTotal Loss: 0.604688\n",
      "Reconstruction: 0.523878, Regularization: 0.015836, Discriminator: 0.043314; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:06,749 root         INFO     Train Epoch: 145 [512/8000 (6%)]\tTotal Loss: 0.812503\n",
      "Reconstruction: 0.718598, Regularization: 0.028922, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:06,845 root         INFO     Train Epoch: 145 [1024/8000 (13%)]\tTotal Loss: 0.851691\n",
      "Reconstruction: 0.761557, Regularization: 0.025143, Discriminator: 0.043323; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:06,942 root         INFO     Train Epoch: 145 [1536/8000 (19%)]\tTotal Loss: 0.597388\n",
      "Reconstruction: 0.512591, Regularization: 0.019809, Discriminator: 0.043321; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:07,040 root         INFO     Train Epoch: 145 [2048/8000 (26%)]\tTotal Loss: 0.829044\n",
      "Reconstruction: 0.736653, Regularization: 0.027410, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:07,136 root         INFO     Train Epoch: 145 [2560/8000 (32%)]\tTotal Loss: 0.736560\n",
      "Reconstruction: 0.649138, Regularization: 0.022440, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:07,232 root         INFO     Train Epoch: 145 [3072/8000 (38%)]\tTotal Loss: 0.839065\n",
      "Reconstruction: 0.752542, Regularization: 0.021529, Discriminator: 0.043330; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:07,328 root         INFO     Train Epoch: 145 [3584/8000 (45%)]\tTotal Loss: 0.714849\n",
      "Reconstruction: 0.627132, Regularization: 0.022747, Discriminator: 0.043312; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:07,425 root         INFO     Train Epoch: 145 [4096/8000 (51%)]\tTotal Loss: 1.088627\n",
      "Reconstruction: 0.989193, Regularization: 0.034453, Discriminator: 0.043316; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:07,521 root         INFO     Train Epoch: 145 [4608/8000 (58%)]\tTotal Loss: 0.589867\n",
      "Reconstruction: 0.508915, Regularization: 0.015954, Discriminator: 0.043338; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:07,619 root         INFO     Train Epoch: 145 [5120/8000 (64%)]\tTotal Loss: 0.682213\n",
      "Reconstruction: 0.592310, Regularization: 0.024913, Discriminator: 0.043326; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:07,716 root         INFO     Train Epoch: 145 [5632/8000 (70%)]\tTotal Loss: 0.539359\n",
      "Reconstruction: 0.457441, Regularization: 0.016943, Discriminator: 0.043312; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:07,814 root         INFO     Train Epoch: 145 [6144/8000 (77%)]\tTotal Loss: 0.586337\n",
      "Reconstruction: 0.505754, Regularization: 0.015594, Discriminator: 0.043321; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:07,912 root         INFO     Train Epoch: 145 [6656/8000 (83%)]\tTotal Loss: 0.975152\n",
      "Reconstruction: 0.886763, Regularization: 0.023415, Discriminator: 0.043316; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:08,012 root         INFO     Train Epoch: 145 [7168/8000 (90%)]\tTotal Loss: 0.632170\n",
      "Reconstruction: 0.551686, Regularization: 0.015488, Discriminator: 0.043327; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:08,110 root         INFO     Train Epoch: 145 [7680/8000 (96%)]\tTotal Loss: 0.560158\n",
      "Reconstruction: 0.473654, Regularization: 0.021526, Discriminator: 0.043315; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:08,185 root         INFO     ====> Epoch: 145 Average loss: 0.7185\n",
      "2019-04-09 22:49:08,211 root         INFO     Train Epoch: 146 [0/8000 (0%)]\tTotal Loss: 0.583066\n",
      "Reconstruction: 0.503111, Regularization: 0.014955, Discriminator: 0.043334; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:08,310 root         INFO     Train Epoch: 146 [512/8000 (6%)]\tTotal Loss: 0.662916\n",
      "Reconstruction: 0.575023, Regularization: 0.022897, Discriminator: 0.043344; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:08,408 root         INFO     Train Epoch: 146 [1024/8000 (13%)]\tTotal Loss: 0.785556\n",
      "Reconstruction: 0.696993, Regularization: 0.023566, Discriminator: 0.043336; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:08,507 root         INFO     Train Epoch: 146 [1536/8000 (19%)]\tTotal Loss: 0.693850\n",
      "Reconstruction: 0.607589, Regularization: 0.021292, Discriminator: 0.043310; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:08,605 root         INFO     Train Epoch: 146 [2048/8000 (26%)]\tTotal Loss: 0.636633\n",
      "Reconstruction: 0.555888, Regularization: 0.015770, Discriminator: 0.043319; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:08,703 root         INFO     Train Epoch: 146 [2560/8000 (32%)]\tTotal Loss: 0.847793\n",
      "Reconstruction: 0.764485, Regularization: 0.018321, Discriminator: 0.043332; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:08,801 root         INFO     Train Epoch: 146 [3072/8000 (38%)]\tTotal Loss: 0.506336\n",
      "Reconstruction: 0.426585, Regularization: 0.014771, Discriminator: 0.043324; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:08,899 root         INFO     Train Epoch: 146 [3584/8000 (45%)]\tTotal Loss: 0.668824\n",
      "Reconstruction: 0.583141, Regularization: 0.020709, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:08,998 root         INFO     Train Epoch: 146 [4096/8000 (51%)]\tTotal Loss: 0.631236\n",
      "Reconstruction: 0.546339, Regularization: 0.019925, Discriminator: 0.043314; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:09,096 root         INFO     Train Epoch: 146 [4608/8000 (58%)]\tTotal Loss: 0.632404\n",
      "Reconstruction: 0.541730, Regularization: 0.025699, Discriminator: 0.043313; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:09,194 root         INFO     Train Epoch: 146 [5120/8000 (64%)]\tTotal Loss: 0.686351\n",
      "Reconstruction: 0.594047, Regularization: 0.027301, Discriminator: 0.043337; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:09,292 root         INFO     Train Epoch: 146 [5632/8000 (70%)]\tTotal Loss: 0.792976\n",
      "Reconstruction: 0.695226, Regularization: 0.032752, Discriminator: 0.043335; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:09,391 root         INFO     Train Epoch: 146 [6144/8000 (77%)]\tTotal Loss: 0.613946\n",
      "Reconstruction: 0.527956, Regularization: 0.021005, Discriminator: 0.043326; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:09,491 root         INFO     Train Epoch: 146 [6656/8000 (83%)]\tTotal Loss: 0.818612\n",
      "Reconstruction: 0.728226, Regularization: 0.025428, Discriminator: 0.043304; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:09,591 root         INFO     Train Epoch: 146 [7168/8000 (90%)]\tTotal Loss: 0.883495\n",
      "Reconstruction: 0.792469, Regularization: 0.026022, Discriminator: 0.043332; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:09,691 root         INFO     Train Epoch: 146 [7680/8000 (96%)]\tTotal Loss: 0.628620\n",
      "Reconstruction: 0.545832, Regularization: 0.017823, Discriminator: 0.043300; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:09,766 root         INFO     ====> Epoch: 146 Average loss: 0.7128\n",
      "2019-04-09 22:49:09,792 root         INFO     Train Epoch: 147 [0/8000 (0%)]\tTotal Loss: 0.916959\n",
      "Reconstruction: 0.822449, Regularization: 0.029563, Discriminator: 0.043295; Generator: 0.021653,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:49:09,892 root         INFO     Train Epoch: 147 [512/8000 (6%)]\tTotal Loss: 0.680882\n",
      "Reconstruction: 0.595330, Regularization: 0.020574, Discriminator: 0.043327; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:09,991 root         INFO     Train Epoch: 147 [1024/8000 (13%)]\tTotal Loss: 0.897574\n",
      "Reconstruction: 0.796979, Regularization: 0.035598, Discriminator: 0.043334; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:10,090 root         INFO     Train Epoch: 147 [1536/8000 (19%)]\tTotal Loss: 0.648638\n",
      "Reconstruction: 0.561683, Regularization: 0.021970, Discriminator: 0.043327; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:10,189 root         INFO     Train Epoch: 147 [2048/8000 (26%)]\tTotal Loss: 0.728949\n",
      "Reconstruction: 0.637361, Regularization: 0.026597, Discriminator: 0.043321; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:10,288 root         INFO     Train Epoch: 147 [2560/8000 (32%)]\tTotal Loss: 0.462990\n",
      "Reconstruction: 0.384987, Regularization: 0.013005, Discriminator: 0.043335; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:10,387 root         INFO     Train Epoch: 147 [3072/8000 (38%)]\tTotal Loss: 0.701163\n",
      "Reconstruction: 0.613831, Regularization: 0.022347, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:10,486 root         INFO     Train Epoch: 147 [3584/8000 (45%)]\tTotal Loss: 0.747928\n",
      "Reconstruction: 0.660610, Regularization: 0.022333, Discriminator: 0.043318; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:10,585 root         INFO     Train Epoch: 147 [4096/8000 (51%)]\tTotal Loss: 0.567007\n",
      "Reconstruction: 0.483658, Regularization: 0.018365, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:10,684 root         INFO     Train Epoch: 147 [4608/8000 (58%)]\tTotal Loss: 0.855400\n",
      "Reconstruction: 0.763581, Regularization: 0.026824, Discriminator: 0.043331; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:10,783 root         INFO     Train Epoch: 147 [5120/8000 (64%)]\tTotal Loss: 0.623254\n",
      "Reconstruction: 0.541239, Regularization: 0.017033, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:10,882 root         INFO     Train Epoch: 147 [5632/8000 (70%)]\tTotal Loss: 0.634905\n",
      "Reconstruction: 0.546199, Regularization: 0.023698, Discriminator: 0.043343; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:10,981 root         INFO     Train Epoch: 147 [6144/8000 (77%)]\tTotal Loss: 0.710339\n",
      "Reconstruction: 0.625308, Regularization: 0.020038, Discriminator: 0.043327; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:11,079 root         INFO     Train Epoch: 147 [6656/8000 (83%)]\tTotal Loss: 0.637750\n",
      "Reconstruction: 0.555871, Regularization: 0.016904, Discriminator: 0.043314; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:11,177 root         INFO     Train Epoch: 147 [7168/8000 (90%)]\tTotal Loss: 0.534111\n",
      "Reconstruction: 0.453079, Regularization: 0.016049, Discriminator: 0.043325; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:11,276 root         INFO     Train Epoch: 147 [7680/8000 (96%)]\tTotal Loss: 0.815604\n",
      "Reconstruction: 0.723330, Regularization: 0.027312, Discriminator: 0.043306; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:11,349 root         INFO     ====> Epoch: 147 Average loss: 0.7195\n",
      "2019-04-09 22:49:11,375 root         INFO     Train Epoch: 148 [0/8000 (0%)]\tTotal Loss: 0.663209\n",
      "Reconstruction: 0.580271, Regularization: 0.017981, Discriminator: 0.043290; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:11,475 root         INFO     Train Epoch: 148 [512/8000 (6%)]\tTotal Loss: 0.789689\n",
      "Reconstruction: 0.700004, Regularization: 0.024710, Discriminator: 0.043329; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:11,574 root         INFO     Train Epoch: 148 [1024/8000 (13%)]\tTotal Loss: 0.761591\n",
      "Reconstruction: 0.669514, Regularization: 0.027057, Discriminator: 0.043355; Generator: 0.021665,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:49:11,674 root         INFO     Train Epoch: 148 [1536/8000 (19%)]\tTotal Loss: 0.473990\n",
      "Reconstruction: 0.395229, Regularization: 0.013806, Discriminator: 0.043306; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:11,773 root         INFO     Train Epoch: 148 [2048/8000 (26%)]\tTotal Loss: 0.713485\n",
      "Reconstruction: 0.626148, Regularization: 0.022390, Discriminator: 0.043291; Generator: 0.021655,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:49:11,873 root         INFO     Train Epoch: 148 [2560/8000 (32%)]\tTotal Loss: 0.759637\n",
      "Reconstruction: 0.674158, Regularization: 0.020506, Discriminator: 0.043321; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:11,974 root         INFO     Train Epoch: 148 [3072/8000 (38%)]\tTotal Loss: 0.954749\n",
      "Reconstruction: 0.856020, Regularization: 0.033747, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:12,075 root         INFO     Train Epoch: 148 [3584/8000 (45%)]\tTotal Loss: 0.692620\n",
      "Reconstruction: 0.609863, Regularization: 0.017784, Discriminator: 0.043310; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:12,176 root         INFO     Train Epoch: 148 [4096/8000 (51%)]\tTotal Loss: 0.543220\n",
      "Reconstruction: 0.465546, Regularization: 0.012702, Discriminator: 0.043318; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:12,276 root         INFO     Train Epoch: 148 [4608/8000 (58%)]\tTotal Loss: 0.740900\n",
      "Reconstruction: 0.651851, Regularization: 0.024063, Discriminator: 0.043323; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:12,377 root         INFO     Train Epoch: 148 [5120/8000 (64%)]\tTotal Loss: 0.660516\n",
      "Reconstruction: 0.572487, Regularization: 0.023038, Discriminator: 0.043326; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:12,477 root         INFO     Train Epoch: 148 [5632/8000 (70%)]\tTotal Loss: 0.799158\n",
      "Reconstruction: 0.707599, Regularization: 0.026576, Discriminator: 0.043317; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:12,577 root         INFO     Train Epoch: 148 [6144/8000 (77%)]\tTotal Loss: 0.583832\n",
      "Reconstruction: 0.495995, Regularization: 0.022855, Discriminator: 0.043327; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:12,677 root         INFO     Train Epoch: 148 [6656/8000 (83%)]\tTotal Loss: 0.502371\n",
      "Reconstruction: 0.416803, Regularization: 0.020568, Discriminator: 0.043337; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:12,777 root         INFO     Train Epoch: 148 [7168/8000 (90%)]\tTotal Loss: 0.497542\n",
      "Reconstruction: 0.412785, Regularization: 0.019745, Discriminator: 0.043357; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:12,877 root         INFO     Train Epoch: 148 [7680/8000 (96%)]\tTotal Loss: 0.430228\n",
      "Reconstruction: 0.355914, Regularization: 0.009348, Discriminator: 0.043310; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:12,951 root         INFO     ====> Epoch: 148 Average loss: 0.7141\n",
      "2019-04-09 22:49:12,978 root         INFO     Train Epoch: 149 [0/8000 (0%)]\tTotal Loss: 0.781242\n",
      "Reconstruction: 0.690039, Regularization: 0.026239, Discriminator: 0.043309; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:13,077 root         INFO     Train Epoch: 149 [512/8000 (6%)]\tTotal Loss: 0.754069\n",
      "Reconstruction: 0.666621, Regularization: 0.022463, Discriminator: 0.043327; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:13,176 root         INFO     Train Epoch: 149 [1024/8000 (13%)]\tTotal Loss: 0.750005\n",
      "Reconstruction: 0.658022, Regularization: 0.026994, Discriminator: 0.043327; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:13,275 root         INFO     Train Epoch: 149 [1536/8000 (19%)]\tTotal Loss: 0.646424\n",
      "Reconstruction: 0.560967, Regularization: 0.020468, Discriminator: 0.043335; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:13,373 root         INFO     Train Epoch: 149 [2048/8000 (26%)]\tTotal Loss: 0.683412\n",
      "Reconstruction: 0.593712, Regularization: 0.024725, Discriminator: 0.043316; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:13,470 root         INFO     Train Epoch: 149 [2560/8000 (32%)]\tTotal Loss: 0.625468\n",
      "Reconstruction: 0.539419, Regularization: 0.021090, Discriminator: 0.043298; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:13,568 root         INFO     Train Epoch: 149 [3072/8000 (38%)]\tTotal Loss: 0.989713\n",
      "Reconstruction: 0.894183, Regularization: 0.030534, Discriminator: 0.043338; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:13,664 root         INFO     Train Epoch: 149 [3584/8000 (45%)]\tTotal Loss: 0.752388\n",
      "Reconstruction: 0.658367, Regularization: 0.029033, Discriminator: 0.043324; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:13,762 root         INFO     Train Epoch: 149 [4096/8000 (51%)]\tTotal Loss: 0.597441\n",
      "Reconstruction: 0.513931, Regularization: 0.018522, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:13,860 root         INFO     Train Epoch: 149 [4608/8000 (58%)]\tTotal Loss: 0.776478\n",
      "Reconstruction: 0.682591, Regularization: 0.028911, Discriminator: 0.043312; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:13,958 root         INFO     Train Epoch: 149 [5120/8000 (64%)]\tTotal Loss: 0.713940\n",
      "Reconstruction: 0.619164, Regularization: 0.029802, Discriminator: 0.043310; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:14,056 root         INFO     Train Epoch: 149 [5632/8000 (70%)]\tTotal Loss: 0.853469\n",
      "Reconstruction: 0.766601, Regularization: 0.021881, Discriminator: 0.043327; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:14,154 root         INFO     Train Epoch: 149 [6144/8000 (77%)]\tTotal Loss: 0.757851\n",
      "Reconstruction: 0.676957, Regularization: 0.015902, Discriminator: 0.043325; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:14,250 root         INFO     Train Epoch: 149 [6656/8000 (83%)]\tTotal Loss: 0.870580\n",
      "Reconstruction: 0.781743, Regularization: 0.023853, Discriminator: 0.043330; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:14,348 root         INFO     Train Epoch: 149 [7168/8000 (90%)]\tTotal Loss: 0.839735\n",
      "Reconstruction: 0.758001, Regularization: 0.016733, Discriminator: 0.043333; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:14,446 root         INFO     Train Epoch: 149 [7680/8000 (96%)]\tTotal Loss: 0.872678\n",
      "Reconstruction: 0.783969, Regularization: 0.023704, Discriminator: 0.043329; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:14,520 root         INFO     ====> Epoch: 149 Average loss: 0.7181\n",
      "2019-04-09 22:49:14,546 root         INFO     Train Epoch: 150 [0/8000 (0%)]\tTotal Loss: 0.682742\n",
      "Reconstruction: 0.597308, Regularization: 0.020465, Discriminator: 0.043315; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:14,646 root         INFO     Train Epoch: 150 [512/8000 (6%)]\tTotal Loss: 0.741387\n",
      "Reconstruction: 0.654962, Regularization: 0.021432, Discriminator: 0.043326; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:14,746 root         INFO     Train Epoch: 150 [1024/8000 (13%)]\tTotal Loss: 0.727643\n",
      "Reconstruction: 0.635769, Regularization: 0.026903, Discriminator: 0.043317; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:14,846 root         INFO     Train Epoch: 150 [1536/8000 (19%)]\tTotal Loss: 0.919046\n",
      "Reconstruction: 0.823482, Regularization: 0.030582, Discriminator: 0.043317; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:14,945 root         INFO     Train Epoch: 150 [2048/8000 (26%)]\tTotal Loss: 0.635905\n",
      "Reconstruction: 0.546892, Regularization: 0.024052, Discriminator: 0.043312; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:15,045 root         INFO     Train Epoch: 150 [2560/8000 (32%)]\tTotal Loss: 0.857964\n",
      "Reconstruction: 0.762447, Regularization: 0.030534, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:15,144 root         INFO     Train Epoch: 150 [3072/8000 (38%)]\tTotal Loss: 0.534767\n",
      "Reconstruction: 0.452145, Regularization: 0.017648, Discriminator: 0.043321; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:15,244 root         INFO     Train Epoch: 150 [3584/8000 (45%)]\tTotal Loss: 0.559422\n",
      "Reconstruction: 0.476239, Regularization: 0.018210, Discriminator: 0.043321; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:15,344 root         INFO     Train Epoch: 150 [4096/8000 (51%)]\tTotal Loss: 0.828733\n",
      "Reconstruction: 0.736738, Regularization: 0.027011, Discriminator: 0.043326; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:15,443 root         INFO     Train Epoch: 150 [4608/8000 (58%)]\tTotal Loss: 0.970916\n",
      "Reconstruction: 0.877236, Regularization: 0.028697, Discriminator: 0.043328; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:15,543 root         INFO     Train Epoch: 150 [5120/8000 (64%)]\tTotal Loss: 0.496171\n",
      "Reconstruction: 0.412325, Regularization: 0.018873, Discriminator: 0.043318; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:15,640 root         INFO     Train Epoch: 150 [5632/8000 (70%)]\tTotal Loss: 0.667109\n",
      "Reconstruction: 0.578417, Regularization: 0.023712, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:15,748 root         INFO     Train Epoch: 150 [6144/8000 (77%)]\tTotal Loss: 0.849318\n",
      "Reconstruction: 0.751508, Regularization: 0.032831, Discriminator: 0.043317; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:15,857 root         INFO     Train Epoch: 150 [6656/8000 (83%)]\tTotal Loss: 0.577092\n",
      "Reconstruction: 0.498917, Regularization: 0.013190, Discriminator: 0.043330; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:15,961 root         INFO     Train Epoch: 150 [7168/8000 (90%)]\tTotal Loss: 0.547596\n",
      "Reconstruction: 0.467835, Regularization: 0.014769, Discriminator: 0.043332; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:16,061 root         INFO     Train Epoch: 150 [7680/8000 (96%)]\tTotal Loss: 1.154568\n",
      "Reconstruction: 1.047570, Regularization: 0.042020, Discriminator: 0.043316; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:16,134 root         INFO     ====> Epoch: 150 Average loss: 0.7147\n",
      "2019-04-09 22:49:16,160 root         INFO     Train Epoch: 151 [0/8000 (0%)]\tTotal Loss: 0.764575\n",
      "Reconstruction: 0.674077, Regularization: 0.025517, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:16,257 root         INFO     Train Epoch: 151 [512/8000 (6%)]\tTotal Loss: 0.800519\n",
      "Reconstruction: 0.713290, Regularization: 0.022252, Discriminator: 0.043316; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:16,354 root         INFO     Train Epoch: 151 [1024/8000 (13%)]\tTotal Loss: 0.922422\n",
      "Reconstruction: 0.824632, Regularization: 0.032795, Discriminator: 0.043330; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:16,451 root         INFO     Train Epoch: 151 [1536/8000 (19%)]\tTotal Loss: 0.582245\n",
      "Reconstruction: 0.495868, Regularization: 0.021399, Discriminator: 0.043321; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:16,548 root         INFO     Train Epoch: 151 [2048/8000 (26%)]\tTotal Loss: 0.814302\n",
      "Reconstruction: 0.727377, Regularization: 0.021943, Discriminator: 0.043325; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:16,645 root         INFO     Train Epoch: 151 [2560/8000 (32%)]\tTotal Loss: 0.635445\n",
      "Reconstruction: 0.554723, Regularization: 0.015727, Discriminator: 0.043332; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:16,742 root         INFO     Train Epoch: 151 [3072/8000 (38%)]\tTotal Loss: 0.598277\n",
      "Reconstruction: 0.509356, Regularization: 0.023929, Discriminator: 0.043324; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:16,839 root         INFO     Train Epoch: 151 [3584/8000 (45%)]\tTotal Loss: 0.834963\n",
      "Reconstruction: 0.741252, Regularization: 0.028722, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:16,937 root         INFO     Train Epoch: 151 [4096/8000 (51%)]\tTotal Loss: 0.744651\n",
      "Reconstruction: 0.654367, Regularization: 0.025305, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:17,034 root         INFO     Train Epoch: 151 [4608/8000 (58%)]\tTotal Loss: 0.831558\n",
      "Reconstruction: 0.737941, Regularization: 0.028630, Discriminator: 0.043325; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:17,132 root         INFO     Train Epoch: 151 [5120/8000 (64%)]\tTotal Loss: 0.491645\n",
      "Reconstruction: 0.408795, Regularization: 0.017870, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:17,229 root         INFO     Train Epoch: 151 [5632/8000 (70%)]\tTotal Loss: 0.667184\n",
      "Reconstruction: 0.577270, Regularization: 0.024930, Discriminator: 0.043321; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:17,326 root         INFO     Train Epoch: 151 [6144/8000 (77%)]\tTotal Loss: 0.696938\n",
      "Reconstruction: 0.612741, Regularization: 0.019205, Discriminator: 0.043334; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:17,423 root         INFO     Train Epoch: 151 [6656/8000 (83%)]\tTotal Loss: 0.742304\n",
      "Reconstruction: 0.660408, Regularization: 0.016897, Discriminator: 0.043335; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:17,520 root         INFO     Train Epoch: 151 [7168/8000 (90%)]\tTotal Loss: 0.503325\n",
      "Reconstruction: 0.419074, Regularization: 0.019271, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:17,618 root         INFO     Train Epoch: 151 [7680/8000 (96%)]\tTotal Loss: 0.720389\n",
      "Reconstruction: 0.634956, Regularization: 0.020449, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:17,690 root         INFO     ====> Epoch: 151 Average loss: 0.7168\n",
      "2019-04-09 22:49:17,716 root         INFO     Train Epoch: 152 [0/8000 (0%)]\tTotal Loss: 0.636619\n",
      "Reconstruction: 0.550459, Regularization: 0.021178, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:17,814 root         INFO     Train Epoch: 152 [512/8000 (6%)]\tTotal Loss: 0.813249\n",
      "Reconstruction: 0.718178, Regularization: 0.030085, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:17,910 root         INFO     Train Epoch: 152 [1024/8000 (13%)]\tTotal Loss: 0.724501\n",
      "Reconstruction: 0.639700, Regularization: 0.019824, Discriminator: 0.043320; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:18,006 root         INFO     Train Epoch: 152 [1536/8000 (19%)]\tTotal Loss: 0.914619\n",
      "Reconstruction: 0.816855, Regularization: 0.032791, Discriminator: 0.043311; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:18,102 root         INFO     Train Epoch: 152 [2048/8000 (26%)]\tTotal Loss: 0.828279\n",
      "Reconstruction: 0.742055, Regularization: 0.021235, Discriminator: 0.043327; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:18,198 root         INFO     Train Epoch: 152 [2560/8000 (32%)]\tTotal Loss: 0.698019\n",
      "Reconstruction: 0.609779, Regularization: 0.023255, Discriminator: 0.043321; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:18,294 root         INFO     Train Epoch: 152 [3072/8000 (38%)]\tTotal Loss: 0.624516\n",
      "Reconstruction: 0.542599, Regularization: 0.016915, Discriminator: 0.043337; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:18,391 root         INFO     Train Epoch: 152 [3584/8000 (45%)]\tTotal Loss: 0.540406\n",
      "Reconstruction: 0.460767, Regularization: 0.014665, Discriminator: 0.043313; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:18,487 root         INFO     Train Epoch: 152 [4096/8000 (51%)]\tTotal Loss: 0.671176\n",
      "Reconstruction: 0.585163, Regularization: 0.021029, Discriminator: 0.043321; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:18,584 root         INFO     Train Epoch: 152 [4608/8000 (58%)]\tTotal Loss: 0.809876\n",
      "Reconstruction: 0.716553, Regularization: 0.028347, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:18,680 root         INFO     Train Epoch: 152 [5120/8000 (64%)]\tTotal Loss: 0.708763\n",
      "Reconstruction: 0.624325, Regularization: 0.019448, Discriminator: 0.043331; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:18,777 root         INFO     Train Epoch: 152 [5632/8000 (70%)]\tTotal Loss: 0.779226\n",
      "Reconstruction: 0.690510, Regularization: 0.023723, Discriminator: 0.043334; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:18,873 root         INFO     Train Epoch: 152 [6144/8000 (77%)]\tTotal Loss: 0.913626\n",
      "Reconstruction: 0.818428, Regularization: 0.030225, Discriminator: 0.043322; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:18,969 root         INFO     Train Epoch: 152 [6656/8000 (83%)]\tTotal Loss: 0.583887\n",
      "Reconstruction: 0.497091, Regularization: 0.021799, Discriminator: 0.043335; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:19,066 root         INFO     Train Epoch: 152 [7168/8000 (90%)]\tTotal Loss: 0.616513\n",
      "Reconstruction: 0.528860, Regularization: 0.022676, Discriminator: 0.043321; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:19,162 root         INFO     Train Epoch: 152 [7680/8000 (96%)]\tTotal Loss: 0.625595\n",
      "Reconstruction: 0.543548, Regularization: 0.017066, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:19,234 root         INFO     ====> Epoch: 152 Average loss: 0.7152\n",
      "2019-04-09 22:49:19,260 root         INFO     Train Epoch: 153 [0/8000 (0%)]\tTotal Loss: 0.760326\n",
      "Reconstruction: 0.672661, Regularization: 0.022694, Discriminator: 0.043311; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:19,359 root         INFO     Train Epoch: 153 [512/8000 (6%)]\tTotal Loss: 0.583479\n",
      "Reconstruction: 0.501057, Regularization: 0.017448, Discriminator: 0.043315; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:19,456 root         INFO     Train Epoch: 153 [1024/8000 (13%)]\tTotal Loss: 0.575502\n",
      "Reconstruction: 0.492842, Regularization: 0.017682, Discriminator: 0.043314; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:19,553 root         INFO     Train Epoch: 153 [1536/8000 (19%)]\tTotal Loss: 0.631608\n",
      "Reconstruction: 0.548045, Regularization: 0.018585, Discriminator: 0.043318; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:19,651 root         INFO     Train Epoch: 153 [2048/8000 (26%)]\tTotal Loss: 0.536459\n",
      "Reconstruction: 0.458478, Regularization: 0.012989, Discriminator: 0.043332; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:19,748 root         INFO     Train Epoch: 153 [2560/8000 (32%)]\tTotal Loss: 0.641798\n",
      "Reconstruction: 0.555187, Regularization: 0.021634, Discriminator: 0.043315; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:19,846 root         INFO     Train Epoch: 153 [3072/8000 (38%)]\tTotal Loss: 0.803254\n",
      "Reconstruction: 0.714019, Regularization: 0.024242, Discriminator: 0.043330; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:19,943 root         INFO     Train Epoch: 153 [3584/8000 (45%)]\tTotal Loss: 0.835595\n",
      "Reconstruction: 0.745699, Regularization: 0.024915, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:20,040 root         INFO     Train Epoch: 153 [4096/8000 (51%)]\tTotal Loss: 0.590834\n",
      "Reconstruction: 0.508500, Regularization: 0.017350, Discriminator: 0.043320; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:20,137 root         INFO     Train Epoch: 153 [4608/8000 (58%)]\tTotal Loss: 0.572586\n",
      "Reconstruction: 0.491551, Regularization: 0.016054, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:20,234 root         INFO     Train Epoch: 153 [5120/8000 (64%)]\tTotal Loss: 0.789424\n",
      "Reconstruction: 0.704136, Regularization: 0.020312, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:20,331 root         INFO     Train Epoch: 153 [5632/8000 (70%)]\tTotal Loss: 0.783615\n",
      "Reconstruction: 0.696208, Regularization: 0.022427, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:20,428 root         INFO     Train Epoch: 153 [6144/8000 (77%)]\tTotal Loss: 0.806295\n",
      "Reconstruction: 0.716462, Regularization: 0.024847, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:20,525 root         INFO     Train Epoch: 153 [6656/8000 (83%)]\tTotal Loss: 0.547562\n",
      "Reconstruction: 0.464856, Regularization: 0.017717, Discriminator: 0.043329; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:20,621 root         INFO     Train Epoch: 153 [7168/8000 (90%)]\tTotal Loss: 0.677377\n",
      "Reconstruction: 0.593569, Regularization: 0.018826, Discriminator: 0.043319; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:20,719 root         INFO     Train Epoch: 153 [7680/8000 (96%)]\tTotal Loss: 0.884259\n",
      "Reconstruction: 0.788180, Regularization: 0.031102, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:20,792 root         INFO     ====> Epoch: 153 Average loss: 0.7163\n",
      "2019-04-09 22:49:20,818 root         INFO     Train Epoch: 154 [0/8000 (0%)]\tTotal Loss: 0.766525\n",
      "Reconstruction: 0.679023, Regularization: 0.022520, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:20,913 root         INFO     Train Epoch: 154 [512/8000 (6%)]\tTotal Loss: 0.866536\n",
      "Reconstruction: 0.775126, Regularization: 0.026407, Discriminator: 0.043342; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:21,008 root         INFO     Train Epoch: 154 [1024/8000 (13%)]\tTotal Loss: 0.673426\n",
      "Reconstruction: 0.584564, Regularization: 0.023873, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:21,102 root         INFO     Train Epoch: 154 [1536/8000 (19%)]\tTotal Loss: 0.656897\n",
      "Reconstruction: 0.577796, Regularization: 0.014121, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:21,197 root         INFO     Train Epoch: 154 [2048/8000 (26%)]\tTotal Loss: 0.876856\n",
      "Reconstruction: 0.789753, Regularization: 0.022126, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:21,291 root         INFO     Train Epoch: 154 [2560/8000 (32%)]\tTotal Loss: 0.665102\n",
      "Reconstruction: 0.577845, Regularization: 0.022267, Discriminator: 0.043323; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:21,385 root         INFO     Train Epoch: 154 [3072/8000 (38%)]\tTotal Loss: 0.653411\n",
      "Reconstruction: 0.573415, Regularization: 0.015014, Discriminator: 0.043317; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:21,480 root         INFO     Train Epoch: 154 [3584/8000 (45%)]\tTotal Loss: 0.641763\n",
      "Reconstruction: 0.555298, Regularization: 0.021486, Discriminator: 0.043311; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:21,574 root         INFO     Train Epoch: 154 [4096/8000 (51%)]\tTotal Loss: 0.567501\n",
      "Reconstruction: 0.485264, Regularization: 0.017259, Discriminator: 0.043323; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:21,670 root         INFO     Train Epoch: 154 [4608/8000 (58%)]\tTotal Loss: 0.936764\n",
      "Reconstruction: 0.840913, Regularization: 0.030866, Discriminator: 0.043321; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:21,766 root         INFO     Train Epoch: 154 [5120/8000 (64%)]\tTotal Loss: 0.894818\n",
      "Reconstruction: 0.797913, Regularization: 0.031928, Discriminator: 0.043313; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:21,862 root         INFO     Train Epoch: 154 [5632/8000 (70%)]\tTotal Loss: 0.763434\n",
      "Reconstruction: 0.670386, Regularization: 0.028039, Discriminator: 0.043342; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:21,958 root         INFO     Train Epoch: 154 [6144/8000 (77%)]\tTotal Loss: 0.614977\n",
      "Reconstruction: 0.535060, Regularization: 0.014952, Discriminator: 0.043304; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:22,054 root         INFO     Train Epoch: 154 [6656/8000 (83%)]\tTotal Loss: 0.630790\n",
      "Reconstruction: 0.542160, Regularization: 0.023639, Discriminator: 0.043324; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:22,149 root         INFO     Train Epoch: 154 [7168/8000 (90%)]\tTotal Loss: 0.763208\n",
      "Reconstruction: 0.671088, Regularization: 0.027122, Discriminator: 0.043340; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:22,245 root         INFO     Train Epoch: 154 [7680/8000 (96%)]\tTotal Loss: 0.788064\n",
      "Reconstruction: 0.700964, Regularization: 0.022133, Discriminator: 0.043314; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:22,317 root         INFO     ====> Epoch: 154 Average loss: 0.7184\n",
      "2019-04-09 22:49:22,382 root         INFO     Train Epoch: 155 [0/8000 (0%)]\tTotal Loss: 0.677012\n",
      "Reconstruction: 0.588045, Regularization: 0.023973, Discriminator: 0.043327; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:22,480 root         INFO     Train Epoch: 155 [512/8000 (6%)]\tTotal Loss: 0.854987\n",
      "Reconstruction: 0.761108, Regularization: 0.028890, Discriminator: 0.043321; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:22,580 root         INFO     Train Epoch: 155 [1024/8000 (13%)]\tTotal Loss: 0.960972\n",
      "Reconstruction: 0.861486, Regularization: 0.034494, Discriminator: 0.043332; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:22,678 root         INFO     Train Epoch: 155 [1536/8000 (19%)]\tTotal Loss: 0.609595\n",
      "Reconstruction: 0.525480, Regularization: 0.019133, Discriminator: 0.043325; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:22,776 root         INFO     Train Epoch: 155 [2048/8000 (26%)]\tTotal Loss: 0.668407\n",
      "Reconstruction: 0.581921, Regularization: 0.021507, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:22,872 root         INFO     Train Epoch: 155 [2560/8000 (32%)]\tTotal Loss: 0.610673\n",
      "Reconstruction: 0.529899, Regularization: 0.015797, Discriminator: 0.043323; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:22,967 root         INFO     Train Epoch: 155 [3072/8000 (38%)]\tTotal Loss: 0.848885\n",
      "Reconstruction: 0.749581, Regularization: 0.034332, Discriminator: 0.043315; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:23,064 root         INFO     Train Epoch: 155 [3584/8000 (45%)]\tTotal Loss: 0.658693\n",
      "Reconstruction: 0.575629, Regularization: 0.018073, Discriminator: 0.043327; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:23,160 root         INFO     Train Epoch: 155 [4096/8000 (51%)]\tTotal Loss: 0.589104\n",
      "Reconstruction: 0.504795, Regularization: 0.019335, Discriminator: 0.043312; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:23,255 root         INFO     Train Epoch: 155 [4608/8000 (58%)]\tTotal Loss: 0.571612\n",
      "Reconstruction: 0.494865, Regularization: 0.011768, Discriminator: 0.043317; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:23,351 root         INFO     Train Epoch: 155 [5120/8000 (64%)]\tTotal Loss: 0.797022\n",
      "Reconstruction: 0.712250, Regularization: 0.019796, Discriminator: 0.043313; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:23,447 root         INFO     Train Epoch: 155 [5632/8000 (70%)]\tTotal Loss: 0.609477\n",
      "Reconstruction: 0.518021, Regularization: 0.026465, Discriminator: 0.043329; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:23,543 root         INFO     Train Epoch: 155 [6144/8000 (77%)]\tTotal Loss: 0.914698\n",
      "Reconstruction: 0.827407, Regularization: 0.022312, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:23,640 root         INFO     Train Epoch: 155 [6656/8000 (83%)]\tTotal Loss: 0.781274\n",
      "Reconstruction: 0.693716, Regularization: 0.022572, Discriminator: 0.043320; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:23,736 root         INFO     Train Epoch: 155 [7168/8000 (90%)]\tTotal Loss: 0.778381\n",
      "Reconstruction: 0.689493, Regularization: 0.023915, Discriminator: 0.043316; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:23,831 root         INFO     Train Epoch: 155 [7680/8000 (96%)]\tTotal Loss: 0.617414\n",
      "Reconstruction: 0.531948, Regularization: 0.020472, Discriminator: 0.043331; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:23,904 root         INFO     ====> Epoch: 155 Average loss: 0.7152\n",
      "2019-04-09 22:49:23,931 root         INFO     Train Epoch: 156 [0/8000 (0%)]\tTotal Loss: 1.047536\n",
      "Reconstruction: 0.948245, Regularization: 0.034306, Discriminator: 0.043321; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:24,030 root         INFO     Train Epoch: 156 [512/8000 (6%)]\tTotal Loss: 0.901605\n",
      "Reconstruction: 0.805187, Regularization: 0.031437, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:24,128 root         INFO     Train Epoch: 156 [1024/8000 (13%)]\tTotal Loss: 0.610149\n",
      "Reconstruction: 0.529681, Regularization: 0.015482, Discriminator: 0.043322; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:24,226 root         INFO     Train Epoch: 156 [1536/8000 (19%)]\tTotal Loss: 0.596021\n",
      "Reconstruction: 0.507560, Regularization: 0.023464, Discriminator: 0.043325; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:24,325 root         INFO     Train Epoch: 156 [2048/8000 (26%)]\tTotal Loss: 0.791959\n",
      "Reconstruction: 0.702954, Regularization: 0.024025, Discriminator: 0.043317; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:24,424 root         INFO     Train Epoch: 156 [2560/8000 (32%)]\tTotal Loss: 0.823624\n",
      "Reconstruction: 0.731312, Regularization: 0.027329, Discriminator: 0.043324; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:24,522 root         INFO     Train Epoch: 156 [3072/8000 (38%)]\tTotal Loss: 0.719184\n",
      "Reconstruction: 0.629911, Regularization: 0.024289, Discriminator: 0.043324; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:24,623 root         INFO     Train Epoch: 156 [3584/8000 (45%)]\tTotal Loss: 0.502310\n",
      "Reconstruction: 0.423595, Regularization: 0.013730, Discriminator: 0.043318; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:24,721 root         INFO     Train Epoch: 156 [4096/8000 (51%)]\tTotal Loss: 0.752969\n",
      "Reconstruction: 0.669813, Regularization: 0.018171, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:24,818 root         INFO     Train Epoch: 156 [4608/8000 (58%)]\tTotal Loss: 0.667355\n",
      "Reconstruction: 0.584149, Regularization: 0.018225, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:24,916 root         INFO     Train Epoch: 156 [5120/8000 (64%)]\tTotal Loss: 0.648754\n",
      "Reconstruction: 0.563444, Regularization: 0.020336, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:25,014 root         INFO     Train Epoch: 156 [5632/8000 (70%)]\tTotal Loss: 0.774618\n",
      "Reconstruction: 0.683124, Regularization: 0.026518, Discriminator: 0.043323; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:25,112 root         INFO     Train Epoch: 156 [6144/8000 (77%)]\tTotal Loss: 0.752004\n",
      "Reconstruction: 0.660466, Regularization: 0.026545, Discriminator: 0.043331; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:25,210 root         INFO     Train Epoch: 156 [6656/8000 (83%)]\tTotal Loss: 0.764023\n",
      "Reconstruction: 0.670866, Regularization: 0.028181, Discriminator: 0.043321; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:25,308 root         INFO     Train Epoch: 156 [7168/8000 (90%)]\tTotal Loss: 0.739958\n",
      "Reconstruction: 0.648360, Regularization: 0.026619, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:25,406 root         INFO     Train Epoch: 156 [7680/8000 (96%)]\tTotal Loss: 0.650310\n",
      "Reconstruction: 0.558880, Regularization: 0.026445, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:25,479 root         INFO     ====> Epoch: 156 Average loss: 0.7163\n",
      "2019-04-09 22:49:25,506 root         INFO     Train Epoch: 157 [0/8000 (0%)]\tTotal Loss: 0.732215\n",
      "Reconstruction: 0.648230, Regularization: 0.019011, Discriminator: 0.043318; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:25,606 root         INFO     Train Epoch: 157 [512/8000 (6%)]\tTotal Loss: 0.694114\n",
      "Reconstruction: 0.604934, Regularization: 0.024207, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:25,706 root         INFO     Train Epoch: 157 [1024/8000 (13%)]\tTotal Loss: 0.634233\n",
      "Reconstruction: 0.550551, Regularization: 0.018700, Discriminator: 0.043319; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:25,805 root         INFO     Train Epoch: 157 [1536/8000 (19%)]\tTotal Loss: 0.858660\n",
      "Reconstruction: 0.760351, Regularization: 0.033336, Discriminator: 0.043314; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:25,905 root         INFO     Train Epoch: 157 [2048/8000 (26%)]\tTotal Loss: 0.764180\n",
      "Reconstruction: 0.677198, Regularization: 0.022004, Discriminator: 0.043316; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:26,004 root         INFO     Train Epoch: 157 [2560/8000 (32%)]\tTotal Loss: 0.590157\n",
      "Reconstruction: 0.503973, Regularization: 0.021183, Discriminator: 0.043343; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:26,104 root         INFO     Train Epoch: 157 [3072/8000 (38%)]\tTotal Loss: 0.625481\n",
      "Reconstruction: 0.540777, Regularization: 0.019712, Discriminator: 0.043334; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:26,203 root         INFO     Train Epoch: 157 [3584/8000 (45%)]\tTotal Loss: 0.637070\n",
      "Reconstruction: 0.551733, Regularization: 0.020345, Discriminator: 0.043329; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:26,303 root         INFO     Train Epoch: 157 [4096/8000 (51%)]\tTotal Loss: 0.643068\n",
      "Reconstruction: 0.555416, Regularization: 0.022675, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:26,402 root         INFO     Train Epoch: 157 [4608/8000 (58%)]\tTotal Loss: 0.719019\n",
      "Reconstruction: 0.636112, Regularization: 0.017922, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:26,500 root         INFO     Train Epoch: 157 [5120/8000 (64%)]\tTotal Loss: 0.758334\n",
      "Reconstruction: 0.674819, Regularization: 0.018523, Discriminator: 0.043329; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:26,598 root         INFO     Train Epoch: 157 [5632/8000 (70%)]\tTotal Loss: 0.637668\n",
      "Reconstruction: 0.550095, Regularization: 0.022589, Discriminator: 0.043320; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:26,695 root         INFO     Train Epoch: 157 [6144/8000 (77%)]\tTotal Loss: 0.946844\n",
      "Reconstruction: 0.848308, Regularization: 0.033550, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:26,792 root         INFO     Train Epoch: 157 [6656/8000 (83%)]\tTotal Loss: 1.014472\n",
      "Reconstruction: 0.916733, Regularization: 0.032757, Discriminator: 0.043315; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:26,887 root         INFO     Train Epoch: 157 [7168/8000 (90%)]\tTotal Loss: 0.795405\n",
      "Reconstruction: 0.708475, Regularization: 0.021953, Discriminator: 0.043323; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:26,981 root         INFO     Train Epoch: 157 [7680/8000 (96%)]\tTotal Loss: 0.661665\n",
      "Reconstruction: 0.568313, Regularization: 0.028393, Discriminator: 0.043303; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:27,059 root         INFO     ====> Epoch: 157 Average loss: 0.7169\n",
      "2019-04-09 22:49:27,087 root         INFO     Train Epoch: 158 [0/8000 (0%)]\tTotal Loss: 0.636298\n",
      "Reconstruction: 0.550733, Regularization: 0.020587, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:27,234 root         INFO     Train Epoch: 158 [512/8000 (6%)]\tTotal Loss: 0.624865\n",
      "Reconstruction: 0.541430, Regularization: 0.018457, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:27,339 root         INFO     Train Epoch: 158 [1024/8000 (13%)]\tTotal Loss: 0.591059\n",
      "Reconstruction: 0.508529, Regularization: 0.017553, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:27,443 root         INFO     Train Epoch: 158 [1536/8000 (19%)]\tTotal Loss: 0.623537\n",
      "Reconstruction: 0.537057, Regularization: 0.021472, Discriminator: 0.043336; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:27,542 root         INFO     Train Epoch: 158 [2048/8000 (26%)]\tTotal Loss: 0.912325\n",
      "Reconstruction: 0.814189, Regularization: 0.033150, Discriminator: 0.043327; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:27,639 root         INFO     Train Epoch: 158 [2560/8000 (32%)]\tTotal Loss: 0.883479\n",
      "Reconstruction: 0.791114, Regularization: 0.027384, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:27,737 root         INFO     Train Epoch: 158 [3072/8000 (38%)]\tTotal Loss: 0.688438\n",
      "Reconstruction: 0.602036, Regularization: 0.021412, Discriminator: 0.043320; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:27,835 root         INFO     Train Epoch: 158 [3584/8000 (45%)]\tTotal Loss: 0.740141\n",
      "Reconstruction: 0.651130, Regularization: 0.024030, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:27,933 root         INFO     Train Epoch: 158 [4096/8000 (51%)]\tTotal Loss: 0.575661\n",
      "Reconstruction: 0.491770, Regularization: 0.018903, Discriminator: 0.043325; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:28,032 root         INFO     Train Epoch: 158 [4608/8000 (58%)]\tTotal Loss: 0.506270\n",
      "Reconstruction: 0.429024, Regularization: 0.012273, Discriminator: 0.043318; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:28,129 root         INFO     Train Epoch: 158 [5120/8000 (64%)]\tTotal Loss: 0.821235\n",
      "Reconstruction: 0.726017, Regularization: 0.030242, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:28,227 root         INFO     Train Epoch: 158 [5632/8000 (70%)]\tTotal Loss: 1.108402\n",
      "Reconstruction: 1.009110, Regularization: 0.034314, Discriminator: 0.043315; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:28,325 root         INFO     Train Epoch: 158 [6144/8000 (77%)]\tTotal Loss: 0.690875\n",
      "Reconstruction: 0.606315, Regularization: 0.019584, Discriminator: 0.043313; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:28,423 root         INFO     Train Epoch: 158 [6656/8000 (83%)]\tTotal Loss: 0.708290\n",
      "Reconstruction: 0.623757, Regularization: 0.019555, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:28,520 root         INFO     Train Epoch: 158 [7168/8000 (90%)]\tTotal Loss: 0.741654\n",
      "Reconstruction: 0.656778, Regularization: 0.019910, Discriminator: 0.043310; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:28,616 root         INFO     Train Epoch: 158 [7680/8000 (96%)]\tTotal Loss: 0.641523\n",
      "Reconstruction: 0.552120, Regularization: 0.024426, Discriminator: 0.043321; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:28,690 root         INFO     ====> Epoch: 158 Average loss: 0.7150\n",
      "2019-04-09 22:49:28,717 root         INFO     Train Epoch: 159 [0/8000 (0%)]\tTotal Loss: 0.775465\n",
      "Reconstruction: 0.682933, Regularization: 0.027556, Discriminator: 0.043316; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:28,816 root         INFO     Train Epoch: 159 [512/8000 (6%)]\tTotal Loss: 0.646969\n",
      "Reconstruction: 0.562109, Regularization: 0.019879, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:28,915 root         INFO     Train Epoch: 159 [1024/8000 (13%)]\tTotal Loss: 0.713725\n",
      "Reconstruction: 0.623909, Regularization: 0.024832, Discriminator: 0.043324; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:29,013 root         INFO     Train Epoch: 159 [1536/8000 (19%)]\tTotal Loss: 0.711317\n",
      "Reconstruction: 0.622407, Regularization: 0.023932, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:29,110 root         INFO     Train Epoch: 159 [2048/8000 (26%)]\tTotal Loss: 0.616457\n",
      "Reconstruction: 0.529361, Regularization: 0.022114, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:29,209 root         INFO     Train Epoch: 159 [2560/8000 (32%)]\tTotal Loss: 0.611241\n",
      "Reconstruction: 0.531335, Regularization: 0.014913, Discriminator: 0.043329; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:29,305 root         INFO     Train Epoch: 159 [3072/8000 (38%)]\tTotal Loss: 0.544751\n",
      "Reconstruction: 0.464525, Regularization: 0.015234, Discriminator: 0.043328; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:29,402 root         INFO     Train Epoch: 159 [3584/8000 (45%)]\tTotal Loss: 0.998133\n",
      "Reconstruction: 0.902179, Regularization: 0.030969, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:29,499 root         INFO     Train Epoch: 159 [4096/8000 (51%)]\tTotal Loss: 0.653885\n",
      "Reconstruction: 0.572105, Regularization: 0.016795, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:29,596 root         INFO     Train Epoch: 159 [4608/8000 (58%)]\tTotal Loss: 0.518149\n",
      "Reconstruction: 0.433146, Regularization: 0.020028, Discriminator: 0.043313; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:29,694 root         INFO     Train Epoch: 159 [5120/8000 (64%)]\tTotal Loss: 0.694879\n",
      "Reconstruction: 0.604103, Regularization: 0.025794, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:29,790 root         INFO     Train Epoch: 159 [5632/8000 (70%)]\tTotal Loss: 0.508325\n",
      "Reconstruction: 0.431918, Regularization: 0.011415, Discriminator: 0.043330; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:29,886 root         INFO     Train Epoch: 159 [6144/8000 (77%)]\tTotal Loss: 0.662503\n",
      "Reconstruction: 0.574051, Regularization: 0.023475, Discriminator: 0.043317; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:29,982 root         INFO     Train Epoch: 159 [6656/8000 (83%)]\tTotal Loss: 0.720068\n",
      "Reconstruction: 0.636263, Regularization: 0.018805, Discriminator: 0.043336; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:30,079 root         INFO     Train Epoch: 159 [7168/8000 (90%)]\tTotal Loss: 0.793049\n",
      "Reconstruction: 0.706912, Regularization: 0.021151, Discriminator: 0.043321; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:30,176 root         INFO     Train Epoch: 159 [7680/8000 (96%)]\tTotal Loss: 0.673089\n",
      "Reconstruction: 0.590603, Regularization: 0.017515, Discriminator: 0.043315; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:30,250 root         INFO     ====> Epoch: 159 Average loss: 0.7181\n",
      "2019-04-09 22:49:30,276 root         INFO     Train Epoch: 160 [0/8000 (0%)]\tTotal Loss: 0.560452\n",
      "Reconstruction: 0.476966, Regularization: 0.018493, Discriminator: 0.043330; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:30,377 root         INFO     Train Epoch: 160 [512/8000 (6%)]\tTotal Loss: 0.850788\n",
      "Reconstruction: 0.763594, Regularization: 0.022201, Discriminator: 0.043335; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:30,477 root         INFO     Train Epoch: 160 [1024/8000 (13%)]\tTotal Loss: 0.668309\n",
      "Reconstruction: 0.587578, Regularization: 0.015732, Discriminator: 0.043330; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:30,578 root         INFO     Train Epoch: 160 [1536/8000 (19%)]\tTotal Loss: 0.614743\n",
      "Reconstruction: 0.526454, Regularization: 0.023300, Discriminator: 0.043326; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:30,678 root         INFO     Train Epoch: 160 [2048/8000 (26%)]\tTotal Loss: 0.629482\n",
      "Reconstruction: 0.544268, Regularization: 0.020231, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:30,779 root         INFO     Train Epoch: 160 [2560/8000 (32%)]\tTotal Loss: 0.667170\n",
      "Reconstruction: 0.580873, Regularization: 0.021309, Discriminator: 0.043324; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:30,879 root         INFO     Train Epoch: 160 [3072/8000 (38%)]\tTotal Loss: 0.928873\n",
      "Reconstruction: 0.839718, Regularization: 0.024167, Discriminator: 0.043328; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:30,978 root         INFO     Train Epoch: 160 [3584/8000 (45%)]\tTotal Loss: 1.112126\n",
      "Reconstruction: 1.012014, Regularization: 0.035129, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:31,076 root         INFO     Train Epoch: 160 [4096/8000 (51%)]\tTotal Loss: 0.678925\n",
      "Reconstruction: 0.586552, Regularization: 0.027397, Discriminator: 0.043315; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:31,175 root         INFO     Train Epoch: 160 [4608/8000 (58%)]\tTotal Loss: 0.839610\n",
      "Reconstruction: 0.753965, Regularization: 0.020658, Discriminator: 0.043324; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:31,273 root         INFO     Train Epoch: 160 [5120/8000 (64%)]\tTotal Loss: 0.556212\n",
      "Reconstruction: 0.473125, Regularization: 0.018105, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:31,371 root         INFO     Train Epoch: 160 [5632/8000 (70%)]\tTotal Loss: 0.866052\n",
      "Reconstruction: 0.771365, Regularization: 0.029707, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:31,470 root         INFO     Train Epoch: 160 [6144/8000 (77%)]\tTotal Loss: 0.570888\n",
      "Reconstruction: 0.487222, Regularization: 0.018681, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:31,568 root         INFO     Train Epoch: 160 [6656/8000 (83%)]\tTotal Loss: 0.674147\n",
      "Reconstruction: 0.586023, Regularization: 0.023141, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:31,666 root         INFO     Train Epoch: 160 [7168/8000 (90%)]\tTotal Loss: 0.551127\n",
      "Reconstruction: 0.471587, Regularization: 0.014557, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:31,764 root         INFO     Train Epoch: 160 [7680/8000 (96%)]\tTotal Loss: 0.778304\n",
      "Reconstruction: 0.687399, Regularization: 0.025915, Discriminator: 0.043327; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:31,838 root         INFO     ====> Epoch: 160 Average loss: 0.7160\n",
      "2019-04-09 22:49:31,864 root         INFO     Train Epoch: 161 [0/8000 (0%)]\tTotal Loss: 0.719703\n",
      "Reconstruction: 0.635419, Regularization: 0.019306, Discriminator: 0.043320; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:31,965 root         INFO     Train Epoch: 161 [512/8000 (6%)]\tTotal Loss: 0.781742\n",
      "Reconstruction: 0.693020, Regularization: 0.023741, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:32,065 root         INFO     Train Epoch: 161 [1024/8000 (13%)]\tTotal Loss: 0.658148\n",
      "Reconstruction: 0.576117, Regularization: 0.017048, Discriminator: 0.043324; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:32,165 root         INFO     Train Epoch: 161 [1536/8000 (19%)]\tTotal Loss: 0.967119\n",
      "Reconstruction: 0.864982, Regularization: 0.037151, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:32,262 root         INFO     Train Epoch: 161 [2048/8000 (26%)]\tTotal Loss: 1.223031\n",
      "Reconstruction: 1.118174, Regularization: 0.039859, Discriminator: 0.043334; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:32,357 root         INFO     Train Epoch: 161 [2560/8000 (32%)]\tTotal Loss: 0.790811\n",
      "Reconstruction: 0.696584, Regularization: 0.029233, Discriminator: 0.043336; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:32,454 root         INFO     Train Epoch: 161 [3072/8000 (38%)]\tTotal Loss: 0.707674\n",
      "Reconstruction: 0.620829, Regularization: 0.021850, Discriminator: 0.043334; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:32,551 root         INFO     Train Epoch: 161 [3584/8000 (45%)]\tTotal Loss: 0.602409\n",
      "Reconstruction: 0.522620, Regularization: 0.014810, Discriminator: 0.043324; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:32,648 root         INFO     Train Epoch: 161 [4096/8000 (51%)]\tTotal Loss: 0.546968\n",
      "Reconstruction: 0.461300, Regularization: 0.020691, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:32,745 root         INFO     Train Epoch: 161 [4608/8000 (58%)]\tTotal Loss: 0.817354\n",
      "Reconstruction: 0.726370, Regularization: 0.026004, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:32,841 root         INFO     Train Epoch: 161 [5120/8000 (64%)]\tTotal Loss: 0.963521\n",
      "Reconstruction: 0.871635, Regularization: 0.026896, Discriminator: 0.043326; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:32,938 root         INFO     Train Epoch: 161 [5632/8000 (70%)]\tTotal Loss: 0.582889\n",
      "Reconstruction: 0.495347, Regularization: 0.022565, Discriminator: 0.043318; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:33,034 root         INFO     Train Epoch: 161 [6144/8000 (77%)]\tTotal Loss: 0.824773\n",
      "Reconstruction: 0.734589, Regularization: 0.025204, Discriminator: 0.043316; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:33,130 root         INFO     Train Epoch: 161 [6656/8000 (83%)]\tTotal Loss: 0.506990\n",
      "Reconstruction: 0.423776, Regularization: 0.018212, Discriminator: 0.043337; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:33,226 root         INFO     Train Epoch: 161 [7168/8000 (90%)]\tTotal Loss: 0.659522\n",
      "Reconstruction: 0.569665, Regularization: 0.024859, Discriminator: 0.043338; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:33,322 root         INFO     Train Epoch: 161 [7680/8000 (96%)]\tTotal Loss: 0.781178\n",
      "Reconstruction: 0.695374, Regularization: 0.020835, Discriminator: 0.043318; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:33,394 root         INFO     ====> Epoch: 161 Average loss: 0.7156\n",
      "2019-04-09 22:49:33,420 root         INFO     Train Epoch: 162 [0/8000 (0%)]\tTotal Loss: 0.703944\n",
      "Reconstruction: 0.620803, Regularization: 0.018153, Discriminator: 0.043325; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:33,518 root         INFO     Train Epoch: 162 [512/8000 (6%)]\tTotal Loss: 0.850884\n",
      "Reconstruction: 0.759890, Regularization: 0.025998, Discriminator: 0.043333; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:33,616 root         INFO     Train Epoch: 162 [1024/8000 (13%)]\tTotal Loss: 0.684439\n",
      "Reconstruction: 0.601711, Regularization: 0.017742, Discriminator: 0.043318; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:33,712 root         INFO     Train Epoch: 162 [1536/8000 (19%)]\tTotal Loss: 0.386119\n",
      "Reconstruction: 0.309961, Regularization: 0.011179, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:33,810 root         INFO     Train Epoch: 162 [2048/8000 (26%)]\tTotal Loss: 0.682285\n",
      "Reconstruction: 0.595635, Regularization: 0.021664, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:33,908 root         INFO     Train Epoch: 162 [2560/8000 (32%)]\tTotal Loss: 0.719969\n",
      "Reconstruction: 0.629714, Regularization: 0.025276, Discriminator: 0.043323; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:34,006 root         INFO     Train Epoch: 162 [3072/8000 (38%)]\tTotal Loss: 0.745983\n",
      "Reconstruction: 0.654678, Regularization: 0.026315, Discriminator: 0.043327; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:34,103 root         INFO     Train Epoch: 162 [3584/8000 (45%)]\tTotal Loss: 0.755660\n",
      "Reconstruction: 0.671097, Regularization: 0.019582, Discriminator: 0.043315; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:34,200 root         INFO     Train Epoch: 162 [4096/8000 (51%)]\tTotal Loss: 0.776172\n",
      "Reconstruction: 0.676255, Regularization: 0.034919, Discriminator: 0.043335; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:34,298 root         INFO     Train Epoch: 162 [4608/8000 (58%)]\tTotal Loss: 0.580176\n",
      "Reconstruction: 0.498261, Regularization: 0.016959, Discriminator: 0.043298; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:34,396 root         INFO     Train Epoch: 162 [5120/8000 (64%)]\tTotal Loss: 0.860064\n",
      "Reconstruction: 0.765512, Regularization: 0.029596, Discriminator: 0.043292; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:34,494 root         INFO     Train Epoch: 162 [5632/8000 (70%)]\tTotal Loss: 0.911727\n",
      "Reconstruction: 0.816240, Regularization: 0.030507, Discriminator: 0.043317; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:34,591 root         INFO     Train Epoch: 162 [6144/8000 (77%)]\tTotal Loss: 0.743205\n",
      "Reconstruction: 0.658535, Regularization: 0.019670, Discriminator: 0.043337; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:34,688 root         INFO     Train Epoch: 162 [6656/8000 (83%)]\tTotal Loss: 0.622234\n",
      "Reconstruction: 0.543423, Regularization: 0.013858, Discriminator: 0.043302; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:34,786 root         INFO     Train Epoch: 162 [7168/8000 (90%)]\tTotal Loss: 0.585756\n",
      "Reconstruction: 0.502291, Regularization: 0.018496, Discriminator: 0.043320; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:34,884 root         INFO     Train Epoch: 162 [7680/8000 (96%)]\tTotal Loss: 0.768681\n",
      "Reconstruction: 0.675940, Regularization: 0.027754, Discriminator: 0.043326; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:34,957 root         INFO     ====> Epoch: 162 Average loss: 0.7164\n",
      "2019-04-09 22:49:34,983 root         INFO     Train Epoch: 163 [0/8000 (0%)]\tTotal Loss: 0.682708\n",
      "Reconstruction: 0.592896, Regularization: 0.024837, Discriminator: 0.043320; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:35,081 root         INFO     Train Epoch: 163 [512/8000 (6%)]\tTotal Loss: 0.602816\n",
      "Reconstruction: 0.516953, Regularization: 0.020860, Discriminator: 0.043338; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:35,178 root         INFO     Train Epoch: 163 [1024/8000 (13%)]\tTotal Loss: 0.534337\n",
      "Reconstruction: 0.453544, Regularization: 0.015819, Discriminator: 0.043317; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:35,276 root         INFO     Train Epoch: 163 [1536/8000 (19%)]\tTotal Loss: 0.543867\n",
      "Reconstruction: 0.459549, Regularization: 0.019330, Discriminator: 0.043327; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:35,372 root         INFO     Train Epoch: 163 [2048/8000 (26%)]\tTotal Loss: 0.552609\n",
      "Reconstruction: 0.469687, Regularization: 0.017945, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:35,470 root         INFO     Train Epoch: 163 [2560/8000 (32%)]\tTotal Loss: 0.641026\n",
      "Reconstruction: 0.558221, Regularization: 0.017817, Discriminator: 0.043322; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:35,568 root         INFO     Train Epoch: 163 [3072/8000 (38%)]\tTotal Loss: 0.749143\n",
      "Reconstruction: 0.660819, Regularization: 0.023342, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:35,666 root         INFO     Train Epoch: 163 [3584/8000 (45%)]\tTotal Loss: 0.794341\n",
      "Reconstruction: 0.701460, Regularization: 0.027889, Discriminator: 0.043329; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:35,764 root         INFO     Train Epoch: 163 [4096/8000 (51%)]\tTotal Loss: 0.743582\n",
      "Reconstruction: 0.651942, Regularization: 0.026632, Discriminator: 0.043344; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:35,862 root         INFO     Train Epoch: 163 [4608/8000 (58%)]\tTotal Loss: 0.874729\n",
      "Reconstruction: 0.788518, Regularization: 0.021231, Discriminator: 0.043324; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:35,960 root         INFO     Train Epoch: 163 [5120/8000 (64%)]\tTotal Loss: 0.845472\n",
      "Reconstruction: 0.749969, Regularization: 0.030510, Discriminator: 0.043333; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:36,058 root         INFO     Train Epoch: 163 [5632/8000 (70%)]\tTotal Loss: 0.637860\n",
      "Reconstruction: 0.552960, Regularization: 0.019915, Discriminator: 0.043335; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:36,156 root         INFO     Train Epoch: 163 [6144/8000 (77%)]\tTotal Loss: 0.989193\n",
      "Reconstruction: 0.889059, Regularization: 0.035155, Discriminator: 0.043316; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:36,253 root         INFO     Train Epoch: 163 [6656/8000 (83%)]\tTotal Loss: 0.581157\n",
      "Reconstruction: 0.502342, Regularization: 0.013828, Discriminator: 0.043342; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:36,351 root         INFO     Train Epoch: 163 [7168/8000 (90%)]\tTotal Loss: 0.682743\n",
      "Reconstruction: 0.594245, Regularization: 0.023511, Discriminator: 0.043331; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:36,449 root         INFO     Train Epoch: 163 [7680/8000 (96%)]\tTotal Loss: 1.098003\n",
      "Reconstruction: 1.004563, Regularization: 0.028449, Discriminator: 0.043330; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:36,522 root         INFO     ====> Epoch: 163 Average loss: 0.7156\n",
      "2019-04-09 22:49:36,548 root         INFO     Train Epoch: 164 [0/8000 (0%)]\tTotal Loss: 0.638804\n",
      "Reconstruction: 0.556645, Regularization: 0.017175, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:36,645 root         INFO     Train Epoch: 164 [512/8000 (6%)]\tTotal Loss: 0.743854\n",
      "Reconstruction: 0.655416, Regularization: 0.023450, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:36,743 root         INFO     Train Epoch: 164 [1024/8000 (13%)]\tTotal Loss: 0.696783\n",
      "Reconstruction: 0.611697, Regularization: 0.020104, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:36,841 root         INFO     Train Epoch: 164 [1536/8000 (19%)]\tTotal Loss: 0.485276\n",
      "Reconstruction: 0.405049, Regularization: 0.015236, Discriminator: 0.043325; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:36,939 root         INFO     Train Epoch: 164 [2048/8000 (26%)]\tTotal Loss: 0.784399\n",
      "Reconstruction: 0.688413, Regularization: 0.031011, Discriminator: 0.043312; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:37,036 root         INFO     Train Epoch: 164 [2560/8000 (32%)]\tTotal Loss: 0.911832\n",
      "Reconstruction: 0.820176, Regularization: 0.026671, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:37,134 root         INFO     Train Epoch: 164 [3072/8000 (38%)]\tTotal Loss: 0.792894\n",
      "Reconstruction: 0.702218, Regularization: 0.025695, Discriminator: 0.043314; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:37,232 root         INFO     Train Epoch: 164 [3584/8000 (45%)]\tTotal Loss: 0.678172\n",
      "Reconstruction: 0.586718, Regularization: 0.026485, Discriminator: 0.043309; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:37,329 root         INFO     Train Epoch: 164 [4096/8000 (51%)]\tTotal Loss: 0.767429\n",
      "Reconstruction: 0.678890, Regularization: 0.023535, Discriminator: 0.043338; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:37,427 root         INFO     Train Epoch: 164 [4608/8000 (58%)]\tTotal Loss: 0.523786\n",
      "Reconstruction: 0.441772, Regularization: 0.016989, Discriminator: 0.043362; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:49:37,525 root         INFO     Train Epoch: 164 [5120/8000 (64%)]\tTotal Loss: 0.707848\n",
      "Reconstruction: 0.620308, Regularization: 0.022566, Discriminator: 0.043316; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:37,624 root         INFO     Train Epoch: 164 [5632/8000 (70%)]\tTotal Loss: 0.819300\n",
      "Reconstruction: 0.728369, Regularization: 0.025953, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:37,722 root         INFO     Train Epoch: 164 [6144/8000 (77%)]\tTotal Loss: 0.761879\n",
      "Reconstruction: 0.673819, Regularization: 0.023056, Discriminator: 0.043344; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:37,820 root         INFO     Train Epoch: 164 [6656/8000 (83%)]\tTotal Loss: 0.628819\n",
      "Reconstruction: 0.547708, Regularization: 0.016133, Discriminator: 0.043324; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:37,917 root         INFO     Train Epoch: 164 [7168/8000 (90%)]\tTotal Loss: 0.882877\n",
      "Reconstruction: 0.790193, Regularization: 0.027692, Discriminator: 0.043334; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:38,014 root         INFO     Train Epoch: 164 [7680/8000 (96%)]\tTotal Loss: 1.250673\n",
      "Reconstruction: 1.142519, Regularization: 0.043175, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:38,086 root         INFO     ====> Epoch: 164 Average loss: 0.7175\n",
      "2019-04-09 22:49:38,113 root         INFO     Train Epoch: 165 [0/8000 (0%)]\tTotal Loss: 0.537267\n",
      "Reconstruction: 0.450622, Regularization: 0.021666, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:38,211 root         INFO     Train Epoch: 165 [512/8000 (6%)]\tTotal Loss: 0.815817\n",
      "Reconstruction: 0.722933, Regularization: 0.027905, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:38,309 root         INFO     Train Epoch: 165 [1024/8000 (13%)]\tTotal Loss: 0.770888\n",
      "Reconstruction: 0.684629, Regularization: 0.021275, Discriminator: 0.043324; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:38,408 root         INFO     Train Epoch: 165 [1536/8000 (19%)]\tTotal Loss: 0.958348\n",
      "Reconstruction: 0.862502, Regularization: 0.030870, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:38,506 root         INFO     Train Epoch: 165 [2048/8000 (26%)]\tTotal Loss: 0.969651\n",
      "Reconstruction: 0.878181, Regularization: 0.026471, Discriminator: 0.043339; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:38,604 root         INFO     Train Epoch: 165 [2560/8000 (32%)]\tTotal Loss: 0.923760\n",
      "Reconstruction: 0.826197, Regularization: 0.032599, Discriminator: 0.043305; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:38,703 root         INFO     Train Epoch: 165 [3072/8000 (38%)]\tTotal Loss: 0.648898\n",
      "Reconstruction: 0.557715, Regularization: 0.026228, Discriminator: 0.043298; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:38,801 root         INFO     Train Epoch: 165 [3584/8000 (45%)]\tTotal Loss: 0.791857\n",
      "Reconstruction: 0.699796, Regularization: 0.027081, Discriminator: 0.043319; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:38,899 root         INFO     Train Epoch: 165 [4096/8000 (51%)]\tTotal Loss: 0.856461\n",
      "Reconstruction: 0.767935, Regularization: 0.023508, Discriminator: 0.043357; Generator: 0.021662,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:49:38,997 root         INFO     Train Epoch: 165 [4608/8000 (58%)]\tTotal Loss: 0.634047\n",
      "Reconstruction: 0.546401, Regularization: 0.022658, Discriminator: 0.043324; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:39,096 root         INFO     Train Epoch: 165 [5120/8000 (64%)]\tTotal Loss: 0.699527\n",
      "Reconstruction: 0.621354, Regularization: 0.013189, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:39,194 root         INFO     Train Epoch: 165 [5632/8000 (70%)]\tTotal Loss: 0.664414\n",
      "Reconstruction: 0.582422, Regularization: 0.017026, Discriminator: 0.043306; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:39,291 root         INFO     Train Epoch: 165 [6144/8000 (77%)]\tTotal Loss: 0.634843\n",
      "Reconstruction: 0.555015, Regularization: 0.014855, Discriminator: 0.043311; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:39,388 root         INFO     Train Epoch: 165 [6656/8000 (83%)]\tTotal Loss: 0.831346\n",
      "Reconstruction: 0.743375, Regularization: 0.022976, Discriminator: 0.043337; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:39,484 root         INFO     Train Epoch: 165 [7168/8000 (90%)]\tTotal Loss: 0.669211\n",
      "Reconstruction: 0.583431, Regularization: 0.020831, Discriminator: 0.043292; Generator: 0.021657,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:49:39,581 root         INFO     Train Epoch: 165 [7680/8000 (96%)]\tTotal Loss: 0.788851\n",
      "Reconstruction: 0.699272, Regularization: 0.024578, Discriminator: 0.043339; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:39,654 root         INFO     ====> Epoch: 165 Average loss: 0.7146\n",
      "2019-04-09 22:49:39,681 root         INFO     Train Epoch: 166 [0/8000 (0%)]\tTotal Loss: 1.156531\n",
      "Reconstruction: 1.057221, Regularization: 0.034328, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:39,780 root         INFO     Train Epoch: 166 [512/8000 (6%)]\tTotal Loss: 0.637720\n",
      "Reconstruction: 0.549249, Regularization: 0.023488, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:39,880 root         INFO     Train Epoch: 166 [1024/8000 (13%)]\tTotal Loss: 0.808261\n",
      "Reconstruction: 0.715674, Regularization: 0.027608, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:39,980 root         INFO     Train Epoch: 166 [1536/8000 (19%)]\tTotal Loss: 0.716289\n",
      "Reconstruction: 0.631266, Regularization: 0.020036, Discriminator: 0.043327; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:40,080 root         INFO     Train Epoch: 166 [2048/8000 (26%)]\tTotal Loss: 0.801267\n",
      "Reconstruction: 0.708497, Regularization: 0.027785, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:40,181 root         INFO     Train Epoch: 166 [2560/8000 (32%)]\tTotal Loss: 0.855965\n",
      "Reconstruction: 0.756269, Regularization: 0.034713, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:40,280 root         INFO     Train Epoch: 166 [3072/8000 (38%)]\tTotal Loss: 0.736544\n",
      "Reconstruction: 0.650407, Regularization: 0.021167, Discriminator: 0.043311; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:40,380 root         INFO     Train Epoch: 166 [3584/8000 (45%)]\tTotal Loss: 1.139323\n",
      "Reconstruction: 1.035131, Regularization: 0.039199, Discriminator: 0.043326; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:40,480 root         INFO     Train Epoch: 166 [4096/8000 (51%)]\tTotal Loss: 0.477602\n",
      "Reconstruction: 0.399380, Regularization: 0.013239, Discriminator: 0.043319; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:40,580 root         INFO     Train Epoch: 166 [4608/8000 (58%)]\tTotal Loss: 0.563292\n",
      "Reconstruction: 0.482740, Regularization: 0.015578, Discriminator: 0.043309; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:40,679 root         INFO     Train Epoch: 166 [5120/8000 (64%)]\tTotal Loss: 0.521771\n",
      "Reconstruction: 0.442785, Regularization: 0.014000, Discriminator: 0.043332; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:40,778 root         INFO     Train Epoch: 166 [5632/8000 (70%)]\tTotal Loss: 0.530015\n",
      "Reconstruction: 0.446109, Regularization: 0.018934, Discriminator: 0.043309; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:40,877 root         INFO     Train Epoch: 166 [6144/8000 (77%)]\tTotal Loss: 0.533255\n",
      "Reconstruction: 0.444791, Regularization: 0.023509, Discriminator: 0.043297; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:40,976 root         INFO     Train Epoch: 166 [6656/8000 (83%)]\tTotal Loss: 1.167587\n",
      "Reconstruction: 1.069424, Regularization: 0.033178, Discriminator: 0.043327; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:41,074 root         INFO     Train Epoch: 166 [7168/8000 (90%)]\tTotal Loss: 0.661747\n",
      "Reconstruction: 0.581461, Regularization: 0.015295, Discriminator: 0.043328; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:41,173 root         INFO     Train Epoch: 166 [7680/8000 (96%)]\tTotal Loss: 0.619541\n",
      "Reconstruction: 0.531326, Regularization: 0.023244, Discriminator: 0.043323; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:41,247 root         INFO     ====> Epoch: 166 Average loss: 0.7180\n",
      "2019-04-09 22:49:41,273 root         INFO     Train Epoch: 167 [0/8000 (0%)]\tTotal Loss: 0.645113\n",
      "Reconstruction: 0.562020, Regularization: 0.018117, Discriminator: 0.043320; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:41,373 root         INFO     Train Epoch: 167 [512/8000 (6%)]\tTotal Loss: 0.690461\n",
      "Reconstruction: 0.606168, Regularization: 0.019315, Discriminator: 0.043327; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:41,473 root         INFO     Train Epoch: 167 [1024/8000 (13%)]\tTotal Loss: 0.610674\n",
      "Reconstruction: 0.525257, Regularization: 0.020443, Discriminator: 0.043319; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:41,573 root         INFO     Train Epoch: 167 [1536/8000 (19%)]\tTotal Loss: 0.935129\n",
      "Reconstruction: 0.845756, Regularization: 0.024391, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:41,673 root         INFO     Train Epoch: 167 [2048/8000 (26%)]\tTotal Loss: 0.719848\n",
      "Reconstruction: 0.629837, Regularization: 0.025013, Discriminator: 0.043336; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:41,773 root         INFO     Train Epoch: 167 [2560/8000 (32%)]\tTotal Loss: 0.945422\n",
      "Reconstruction: 0.851788, Regularization: 0.028653, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:41,873 root         INFO     Train Epoch: 167 [3072/8000 (38%)]\tTotal Loss: 0.892136\n",
      "Reconstruction: 0.797860, Regularization: 0.029282, Discriminator: 0.043333; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:41,973 root         INFO     Train Epoch: 167 [3584/8000 (45%)]\tTotal Loss: 0.671651\n",
      "Reconstruction: 0.590992, Regularization: 0.015677, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:42,073 root         INFO     Train Epoch: 167 [4096/8000 (51%)]\tTotal Loss: 0.500577\n",
      "Reconstruction: 0.423775, Regularization: 0.011815, Discriminator: 0.043328; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:42,173 root         INFO     Train Epoch: 167 [4608/8000 (58%)]\tTotal Loss: 0.666436\n",
      "Reconstruction: 0.579093, Regularization: 0.022370, Discriminator: 0.043314; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:42,272 root         INFO     Train Epoch: 167 [5120/8000 (64%)]\tTotal Loss: 0.697068\n",
      "Reconstruction: 0.611935, Regularization: 0.020142, Discriminator: 0.043329; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:42,372 root         INFO     Train Epoch: 167 [5632/8000 (70%)]\tTotal Loss: 0.708665\n",
      "Reconstruction: 0.621538, Regularization: 0.022144, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:42,472 root         INFO     Train Epoch: 167 [6144/8000 (77%)]\tTotal Loss: 0.596318\n",
      "Reconstruction: 0.517407, Regularization: 0.013938, Discriminator: 0.043308; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:42,572 root         INFO     Train Epoch: 167 [6656/8000 (83%)]\tTotal Loss: 0.852558\n",
      "Reconstruction: 0.759959, Regularization: 0.027621, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:42,671 root         INFO     Train Epoch: 167 [7168/8000 (90%)]\tTotal Loss: 0.721149\n",
      "Reconstruction: 0.634317, Regularization: 0.021852, Discriminator: 0.043326; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:42,771 root         INFO     Train Epoch: 167 [7680/8000 (96%)]\tTotal Loss: 0.761553\n",
      "Reconstruction: 0.671695, Regularization: 0.024870, Discriminator: 0.043326; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:42,846 root         INFO     ====> Epoch: 167 Average loss: 0.7141\n",
      "2019-04-09 22:49:42,872 root         INFO     Train Epoch: 168 [0/8000 (0%)]\tTotal Loss: 0.781156\n",
      "Reconstruction: 0.693096, Regularization: 0.023103, Discriminator: 0.043301; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:42,971 root         INFO     Train Epoch: 168 [512/8000 (6%)]\tTotal Loss: 0.563126\n",
      "Reconstruction: 0.483552, Regularization: 0.014597, Discriminator: 0.043318; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:43,072 root         INFO     Train Epoch: 168 [1024/8000 (13%)]\tTotal Loss: 0.690775\n",
      "Reconstruction: 0.609753, Regularization: 0.016051, Discriminator: 0.043306; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:43,171 root         INFO     Train Epoch: 168 [1536/8000 (19%)]\tTotal Loss: 0.656401\n",
      "Reconstruction: 0.572943, Regularization: 0.018471, Discriminator: 0.043323; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:43,270 root         INFO     Train Epoch: 168 [2048/8000 (26%)]\tTotal Loss: 0.644174\n",
      "Reconstruction: 0.557766, Regularization: 0.021409, Discriminator: 0.043330; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:43,370 root         INFO     Train Epoch: 168 [2560/8000 (32%)]\tTotal Loss: 0.843667\n",
      "Reconstruction: 0.754644, Regularization: 0.024046, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:43,469 root         INFO     Train Epoch: 168 [3072/8000 (38%)]\tTotal Loss: 0.624093\n",
      "Reconstruction: 0.536511, Regularization: 0.022593, Discriminator: 0.043324; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:43,568 root         INFO     Train Epoch: 168 [3584/8000 (45%)]\tTotal Loss: 0.699881\n",
      "Reconstruction: 0.611375, Regularization: 0.023527, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:43,668 root         INFO     Train Epoch: 168 [4096/8000 (51%)]\tTotal Loss: 0.666463\n",
      "Reconstruction: 0.581348, Regularization: 0.020139, Discriminator: 0.043320; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:43,767 root         INFO     Train Epoch: 168 [4608/8000 (58%)]\tTotal Loss: 0.590649\n",
      "Reconstruction: 0.508470, Regularization: 0.017196, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:43,867 root         INFO     Train Epoch: 168 [5120/8000 (64%)]\tTotal Loss: 0.716941\n",
      "Reconstruction: 0.630141, Regularization: 0.021820, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:43,967 root         INFO     Train Epoch: 168 [5632/8000 (70%)]\tTotal Loss: 0.668639\n",
      "Reconstruction: 0.581035, Regularization: 0.022624, Discriminator: 0.043323; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:44,066 root         INFO     Train Epoch: 168 [6144/8000 (77%)]\tTotal Loss: 0.990506\n",
      "Reconstruction: 0.895865, Regularization: 0.029643, Discriminator: 0.043340; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:44,166 root         INFO     Train Epoch: 168 [6656/8000 (83%)]\tTotal Loss: 0.666685\n",
      "Reconstruction: 0.584312, Regularization: 0.017379, Discriminator: 0.043329; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:44,266 root         INFO     Train Epoch: 168 [7168/8000 (90%)]\tTotal Loss: 0.639644\n",
      "Reconstruction: 0.551982, Regularization: 0.022669, Discriminator: 0.043333; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:44,365 root         INFO     Train Epoch: 168 [7680/8000 (96%)]\tTotal Loss: 0.697936\n",
      "Reconstruction: 0.614161, Regularization: 0.018799, Discriminator: 0.043309; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:44,441 root         INFO     ====> Epoch: 168 Average loss: 0.7193\n",
      "2019-04-09 22:49:44,467 root         INFO     Train Epoch: 169 [0/8000 (0%)]\tTotal Loss: 1.132582\n",
      "Reconstruction: 1.022411, Regularization: 0.045203, Discriminator: 0.043313; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:44,567 root         INFO     Train Epoch: 169 [512/8000 (6%)]\tTotal Loss: 0.599706\n",
      "Reconstruction: 0.517447, Regularization: 0.017285, Discriminator: 0.043308; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:44,665 root         INFO     Train Epoch: 169 [1024/8000 (13%)]\tTotal Loss: 0.565655\n",
      "Reconstruction: 0.484738, Regularization: 0.015923, Discriminator: 0.043331; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:44,765 root         INFO     Train Epoch: 169 [1536/8000 (19%)]\tTotal Loss: 1.108110\n",
      "Reconstruction: 1.007125, Regularization: 0.036017, Discriminator: 0.043310; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:44,863 root         INFO     Train Epoch: 169 [2048/8000 (26%)]\tTotal Loss: 0.841911\n",
      "Reconstruction: 0.752121, Regularization: 0.024812, Discriminator: 0.043315; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:44,959 root         INFO     Train Epoch: 169 [2560/8000 (32%)]\tTotal Loss: 0.715930\n",
      "Reconstruction: 0.629051, Regularization: 0.021903, Discriminator: 0.043324; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:45,055 root         INFO     Train Epoch: 169 [3072/8000 (38%)]\tTotal Loss: 0.637378\n",
      "Reconstruction: 0.548864, Regularization: 0.023525, Discriminator: 0.043326; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:45,151 root         INFO     Train Epoch: 169 [3584/8000 (45%)]\tTotal Loss: 0.630557\n",
      "Reconstruction: 0.547311, Regularization: 0.018259, Discriminator: 0.043323; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:45,248 root         INFO     Train Epoch: 169 [4096/8000 (51%)]\tTotal Loss: 0.840045\n",
      "Reconstruction: 0.747632, Regularization: 0.027418, Discriminator: 0.043331; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:45,344 root         INFO     Train Epoch: 169 [4608/8000 (58%)]\tTotal Loss: 0.753732\n",
      "Reconstruction: 0.658998, Regularization: 0.029757, Discriminator: 0.043327; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:45,441 root         INFO     Train Epoch: 169 [5120/8000 (64%)]\tTotal Loss: 0.703184\n",
      "Reconstruction: 0.620331, Regularization: 0.017890, Discriminator: 0.043306; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:45,540 root         INFO     Train Epoch: 169 [5632/8000 (70%)]\tTotal Loss: 0.680151\n",
      "Reconstruction: 0.596639, Regularization: 0.018529, Discriminator: 0.043325; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:45,638 root         INFO     Train Epoch: 169 [6144/8000 (77%)]\tTotal Loss: 0.736304\n",
      "Reconstruction: 0.645253, Regularization: 0.026063, Discriminator: 0.043332; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:45,735 root         INFO     Train Epoch: 169 [6656/8000 (83%)]\tTotal Loss: 0.840328\n",
      "Reconstruction: 0.754029, Regularization: 0.021302, Discriminator: 0.043338; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:45,833 root         INFO     Train Epoch: 169 [7168/8000 (90%)]\tTotal Loss: 0.748851\n",
      "Reconstruction: 0.660800, Regularization: 0.023069, Discriminator: 0.043324; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:45,931 root         INFO     Train Epoch: 169 [7680/8000 (96%)]\tTotal Loss: 0.887276\n",
      "Reconstruction: 0.795169, Regularization: 0.027119, Discriminator: 0.043329; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:46,003 root         INFO     ====> Epoch: 169 Average loss: 0.7145\n",
      "2019-04-09 22:49:46,029 root         INFO     Train Epoch: 170 [0/8000 (0%)]\tTotal Loss: 0.835279\n",
      "Reconstruction: 0.749731, Regularization: 0.020563, Discriminator: 0.043319; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:46,129 root         INFO     Train Epoch: 170 [512/8000 (6%)]\tTotal Loss: 0.930773\n",
      "Reconstruction: 0.833168, Regularization: 0.032622, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:46,229 root         INFO     Train Epoch: 170 [1024/8000 (13%)]\tTotal Loss: 0.738709\n",
      "Reconstruction: 0.648046, Regularization: 0.025662, Discriminator: 0.043341; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:46,329 root         INFO     Train Epoch: 170 [1536/8000 (19%)]\tTotal Loss: 0.661896\n",
      "Reconstruction: 0.578368, Regularization: 0.018539, Discriminator: 0.043320; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:46,429 root         INFO     Train Epoch: 170 [2048/8000 (26%)]\tTotal Loss: 0.995977\n",
      "Reconstruction: 0.902401, Regularization: 0.028597, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:46,529 root         INFO     Train Epoch: 170 [2560/8000 (32%)]\tTotal Loss: 0.901990\n",
      "Reconstruction: 0.810470, Regularization: 0.026553, Discriminator: 0.043311; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:46,629 root         INFO     Train Epoch: 170 [3072/8000 (38%)]\tTotal Loss: 0.718819\n",
      "Reconstruction: 0.635784, Regularization: 0.018048, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:46,729 root         INFO     Train Epoch: 170 [3584/8000 (45%)]\tTotal Loss: 0.545143\n",
      "Reconstruction: 0.469159, Regularization: 0.011009, Discriminator: 0.043313; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:46,829 root         INFO     Train Epoch: 170 [4096/8000 (51%)]\tTotal Loss: 0.938759\n",
      "Reconstruction: 0.844541, Regularization: 0.029230, Discriminator: 0.043325; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:46,929 root         INFO     Train Epoch: 170 [4608/8000 (58%)]\tTotal Loss: 0.607441\n",
      "Reconstruction: 0.526251, Regularization: 0.016201, Discriminator: 0.043325; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:47,029 root         INFO     Train Epoch: 170 [5120/8000 (64%)]\tTotal Loss: 0.697642\n",
      "Reconstruction: 0.609621, Regularization: 0.023045, Discriminator: 0.043318; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:47,129 root         INFO     Train Epoch: 170 [5632/8000 (70%)]\tTotal Loss: 0.734867\n",
      "Reconstruction: 0.652736, Regularization: 0.017157, Discriminator: 0.043307; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:47,229 root         INFO     Train Epoch: 170 [6144/8000 (77%)]\tTotal Loss: 0.962545\n",
      "Reconstruction: 0.862825, Regularization: 0.034746, Discriminator: 0.043301; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:47,329 root         INFO     Train Epoch: 170 [6656/8000 (83%)]\tTotal Loss: 0.520645\n",
      "Reconstruction: 0.438624, Regularization: 0.017012, Discriminator: 0.043350; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:47,428 root         INFO     Train Epoch: 170 [7168/8000 (90%)]\tTotal Loss: 0.876763\n",
      "Reconstruction: 0.784018, Regularization: 0.027810, Discriminator: 0.043275; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:49:47,528 root         INFO     Train Epoch: 170 [7680/8000 (96%)]\tTotal Loss: 0.831938\n",
      "Reconstruction: 0.738935, Regularization: 0.028046, Discriminator: 0.043300; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:47,602 root         INFO     ====> Epoch: 170 Average loss: 0.7199\n",
      "2019-04-09 22:49:47,628 root         INFO     Train Epoch: 171 [0/8000 (0%)]\tTotal Loss: 0.679516\n",
      "Reconstruction: 0.589288, Regularization: 0.025238, Discriminator: 0.043331; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:47,731 root         INFO     Train Epoch: 171 [512/8000 (6%)]\tTotal Loss: 0.731892\n",
      "Reconstruction: 0.642105, Regularization: 0.024800, Discriminator: 0.043324; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:47,832 root         INFO     Train Epoch: 171 [1024/8000 (13%)]\tTotal Loss: 0.777568\n",
      "Reconstruction: 0.684299, Regularization: 0.028313, Discriminator: 0.043307; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:47,933 root         INFO     Train Epoch: 171 [1536/8000 (19%)]\tTotal Loss: 0.635358\n",
      "Reconstruction: 0.544007, Regularization: 0.026376, Discriminator: 0.043322; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:48,032 root         INFO     Train Epoch: 171 [2048/8000 (26%)]\tTotal Loss: 0.555465\n",
      "Reconstruction: 0.473760, Regularization: 0.016715, Discriminator: 0.043328; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:48,131 root         INFO     Train Epoch: 171 [2560/8000 (32%)]\tTotal Loss: 0.630669\n",
      "Reconstruction: 0.545629, Regularization: 0.020057, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:48,230 root         INFO     Train Epoch: 171 [3072/8000 (38%)]\tTotal Loss: 0.626306\n",
      "Reconstruction: 0.541492, Regularization: 0.019834, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:48,330 root         INFO     Train Epoch: 171 [3584/8000 (45%)]\tTotal Loss: 0.759436\n",
      "Reconstruction: 0.671275, Regularization: 0.023184, Discriminator: 0.043323; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:48,430 root         INFO     Train Epoch: 171 [4096/8000 (51%)]\tTotal Loss: 0.493072\n",
      "Reconstruction: 0.409941, Regularization: 0.018153, Discriminator: 0.043318; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:48,529 root         INFO     Train Epoch: 171 [4608/8000 (58%)]\tTotal Loss: 0.652856\n",
      "Reconstruction: 0.564774, Regularization: 0.023108, Discriminator: 0.043318; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:48,628 root         INFO     Train Epoch: 171 [5120/8000 (64%)]\tTotal Loss: 0.825560\n",
      "Reconstruction: 0.733876, Regularization: 0.026702, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:48,728 root         INFO     Train Epoch: 171 [5632/8000 (70%)]\tTotal Loss: 0.730229\n",
      "Reconstruction: 0.640996, Regularization: 0.024248, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:48,827 root         INFO     Train Epoch: 171 [6144/8000 (77%)]\tTotal Loss: 0.477491\n",
      "Reconstruction: 0.398073, Regularization: 0.014435, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:48,926 root         INFO     Train Epoch: 171 [6656/8000 (83%)]\tTotal Loss: 0.649185\n",
      "Reconstruction: 0.560658, Regularization: 0.023550, Discriminator: 0.043317; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:49,025 root         INFO     Train Epoch: 171 [7168/8000 (90%)]\tTotal Loss: 0.548365\n",
      "Reconstruction: 0.467051, Regularization: 0.016331, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:49,124 root         INFO     Train Epoch: 171 [7680/8000 (96%)]\tTotal Loss: 0.689575\n",
      "Reconstruction: 0.596198, Regularization: 0.028395, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:49,198 root         INFO     ====> Epoch: 171 Average loss: 0.7148\n",
      "2019-04-09 22:49:49,224 root         INFO     Train Epoch: 172 [0/8000 (0%)]\tTotal Loss: 0.702245\n",
      "Reconstruction: 0.614908, Regularization: 0.022352, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:49,325 root         INFO     Train Epoch: 172 [512/8000 (6%)]\tTotal Loss: 0.750382\n",
      "Reconstruction: 0.662380, Regularization: 0.023015, Discriminator: 0.043326; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:49,425 root         INFO     Train Epoch: 172 [1024/8000 (13%)]\tTotal Loss: 0.799310\n",
      "Reconstruction: 0.708823, Regularization: 0.025503, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:49,525 root         INFO     Train Epoch: 172 [1536/8000 (19%)]\tTotal Loss: 0.792007\n",
      "Reconstruction: 0.692397, Regularization: 0.034633, Discriminator: 0.043317; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:49,625 root         INFO     Train Epoch: 172 [2048/8000 (26%)]\tTotal Loss: 0.552621\n",
      "Reconstruction: 0.468631, Regularization: 0.019014, Discriminator: 0.043318; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:49,725 root         INFO     Train Epoch: 172 [2560/8000 (32%)]\tTotal Loss: 0.679038\n",
      "Reconstruction: 0.597822, Regularization: 0.016217, Discriminator: 0.043338; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:49,825 root         INFO     Train Epoch: 172 [3072/8000 (38%)]\tTotal Loss: 0.946108\n",
      "Reconstruction: 0.849684, Regularization: 0.031432, Discriminator: 0.043332; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:49,925 root         INFO     Train Epoch: 172 [3584/8000 (45%)]\tTotal Loss: 0.672398\n",
      "Reconstruction: 0.583512, Regularization: 0.023893, Discriminator: 0.043334; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:50,024 root         INFO     Train Epoch: 172 [4096/8000 (51%)]\tTotal Loss: 0.815787\n",
      "Reconstruction: 0.732477, Regularization: 0.018329, Discriminator: 0.043319; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:50,123 root         INFO     Train Epoch: 172 [4608/8000 (58%)]\tTotal Loss: 0.832277\n",
      "Reconstruction: 0.739210, Regularization: 0.028084, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:50,222 root         INFO     Train Epoch: 172 [5120/8000 (64%)]\tTotal Loss: 0.513431\n",
      "Reconstruction: 0.431837, Regularization: 0.016605, Discriminator: 0.043331; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:50,321 root         INFO     Train Epoch: 172 [5632/8000 (70%)]\tTotal Loss: 0.672824\n",
      "Reconstruction: 0.581957, Regularization: 0.025886, Discriminator: 0.043319; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:50,420 root         INFO     Train Epoch: 172 [6144/8000 (77%)]\tTotal Loss: 0.806297\n",
      "Reconstruction: 0.718647, Regularization: 0.022663, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:50,519 root         INFO     Train Epoch: 172 [6656/8000 (83%)]\tTotal Loss: 0.714013\n",
      "Reconstruction: 0.625938, Regularization: 0.023091, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:50,616 root         INFO     Train Epoch: 172 [7168/8000 (90%)]\tTotal Loss: 0.638227\n",
      "Reconstruction: 0.554405, Regularization: 0.018843, Discriminator: 0.043324; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:50,715 root         INFO     Train Epoch: 172 [7680/8000 (96%)]\tTotal Loss: 0.763836\n",
      "Reconstruction: 0.681898, Regularization: 0.016955, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:50,787 root         INFO     ====> Epoch: 172 Average loss: 0.7178\n",
      "2019-04-09 22:49:50,814 root         INFO     Train Epoch: 173 [0/8000 (0%)]\tTotal Loss: 0.928149\n",
      "Reconstruction: 0.833239, Regularization: 0.029913, Discriminator: 0.043331; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:50,913 root         INFO     Train Epoch: 173 [512/8000 (6%)]\tTotal Loss: 0.743298\n",
      "Reconstruction: 0.657002, Regularization: 0.021307, Discriminator: 0.043326; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:51,011 root         INFO     Train Epoch: 173 [1024/8000 (13%)]\tTotal Loss: 0.745618\n",
      "Reconstruction: 0.657204, Regularization: 0.023419, Discriminator: 0.043326; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:51,110 root         INFO     Train Epoch: 173 [1536/8000 (19%)]\tTotal Loss: 0.661095\n",
      "Reconstruction: 0.573779, Regularization: 0.022321, Discriminator: 0.043333; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:51,209 root         INFO     Train Epoch: 173 [2048/8000 (26%)]\tTotal Loss: 0.659728\n",
      "Reconstruction: 0.574139, Regularization: 0.020581, Discriminator: 0.043343; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:51,308 root         INFO     Train Epoch: 173 [2560/8000 (32%)]\tTotal Loss: 1.050856\n",
      "Reconstruction: 0.951811, Regularization: 0.034071, Discriminator: 0.043316; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:51,407 root         INFO     Train Epoch: 173 [3072/8000 (38%)]\tTotal Loss: 0.626747\n",
      "Reconstruction: 0.543395, Regularization: 0.018376, Discriminator: 0.043319; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:51,506 root         INFO     Train Epoch: 173 [3584/8000 (45%)]\tTotal Loss: 0.718559\n",
      "Reconstruction: 0.632863, Regularization: 0.020715, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:51,604 root         INFO     Train Epoch: 173 [4096/8000 (51%)]\tTotal Loss: 0.694379\n",
      "Reconstruction: 0.608280, Regularization: 0.021120, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:51,700 root         INFO     Train Epoch: 173 [4608/8000 (58%)]\tTotal Loss: 0.519300\n",
      "Reconstruction: 0.438203, Regularization: 0.016116, Discriminator: 0.043325; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:51,795 root         INFO     Train Epoch: 173 [5120/8000 (64%)]\tTotal Loss: 0.681881\n",
      "Reconstruction: 0.594385, Regularization: 0.022517, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:51,891 root         INFO     Train Epoch: 173 [5632/8000 (70%)]\tTotal Loss: 0.706384\n",
      "Reconstruction: 0.626138, Regularization: 0.015263, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:51,986 root         INFO     Train Epoch: 173 [6144/8000 (77%)]\tTotal Loss: 0.938568\n",
      "Reconstruction: 0.843325, Regularization: 0.030254, Discriminator: 0.043330; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:52,081 root         INFO     Train Epoch: 173 [6656/8000 (83%)]\tTotal Loss: 0.837274\n",
      "Reconstruction: 0.740420, Regularization: 0.031862, Discriminator: 0.043327; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:52,176 root         INFO     Train Epoch: 173 [7168/8000 (90%)]\tTotal Loss: 0.776640\n",
      "Reconstruction: 0.686913, Regularization: 0.024745, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:52,272 root         INFO     Train Epoch: 173 [7680/8000 (96%)]\tTotal Loss: 0.745588\n",
      "Reconstruction: 0.656215, Regularization: 0.024392, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:52,344 root         INFO     ====> Epoch: 173 Average loss: 0.7160\n",
      "2019-04-09 22:49:52,370 root         INFO     Train Epoch: 174 [0/8000 (0%)]\tTotal Loss: 0.942472\n",
      "Reconstruction: 0.842357, Regularization: 0.035132, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:52,469 root         INFO     Train Epoch: 174 [512/8000 (6%)]\tTotal Loss: 0.539682\n",
      "Reconstruction: 0.457989, Regularization: 0.016725, Discriminator: 0.043312; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:52,569 root         INFO     Train Epoch: 174 [1024/8000 (13%)]\tTotal Loss: 0.918534\n",
      "Reconstruction: 0.822003, Regularization: 0.031548, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:52,667 root         INFO     Train Epoch: 174 [1536/8000 (19%)]\tTotal Loss: 0.472107\n",
      "Reconstruction: 0.392391, Regularization: 0.014728, Discriminator: 0.043326; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:52,767 root         INFO     Train Epoch: 174 [2048/8000 (26%)]\tTotal Loss: 0.639982\n",
      "Reconstruction: 0.551593, Regularization: 0.023404, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:52,865 root         INFO     Train Epoch: 174 [2560/8000 (32%)]\tTotal Loss: 0.651328\n",
      "Reconstruction: 0.571453, Regularization: 0.014892, Discriminator: 0.043319; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:52,962 root         INFO     Train Epoch: 174 [3072/8000 (38%)]\tTotal Loss: 0.612555\n",
      "Reconstruction: 0.530047, Regularization: 0.017520, Discriminator: 0.043328; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:53,059 root         INFO     Train Epoch: 174 [3584/8000 (45%)]\tTotal Loss: 0.853107\n",
      "Reconstruction: 0.751847, Regularization: 0.036287, Discriminator: 0.043311; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:53,156 root         INFO     Train Epoch: 174 [4096/8000 (51%)]\tTotal Loss: 0.596794\n",
      "Reconstruction: 0.512659, Regularization: 0.019133, Discriminator: 0.043335; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:53,253 root         INFO     Train Epoch: 174 [4608/8000 (58%)]\tTotal Loss: 1.055820\n",
      "Reconstruction: 0.956206, Regularization: 0.034621, Discriminator: 0.043329; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:53,350 root         INFO     Train Epoch: 174 [5120/8000 (64%)]\tTotal Loss: 0.752693\n",
      "Reconstruction: 0.664782, Regularization: 0.022926, Discriminator: 0.043320; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:53,447 root         INFO     Train Epoch: 174 [5632/8000 (70%)]\tTotal Loss: 0.974987\n",
      "Reconstruction: 0.877872, Regularization: 0.032131, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:53,544 root         INFO     Train Epoch: 174 [6144/8000 (77%)]\tTotal Loss: 0.840838\n",
      "Reconstruction: 0.749310, Regularization: 0.026544, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:53,642 root         INFO     Train Epoch: 174 [6656/8000 (83%)]\tTotal Loss: 0.896907\n",
      "Reconstruction: 0.803312, Regularization: 0.028609, Discriminator: 0.043323; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:53,738 root         INFO     Train Epoch: 174 [7168/8000 (90%)]\tTotal Loss: 0.621475\n",
      "Reconstruction: 0.540039, Regularization: 0.016451, Discriminator: 0.043317; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:53,836 root         INFO     Train Epoch: 174 [7680/8000 (96%)]\tTotal Loss: 0.543629\n",
      "Reconstruction: 0.465157, Regularization: 0.013476, Discriminator: 0.043335; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:53,908 root         INFO     ====> Epoch: 174 Average loss: 0.7172\n",
      "2019-04-09 22:49:53,934 root         INFO     Train Epoch: 175 [0/8000 (0%)]\tTotal Loss: 0.685160\n",
      "Reconstruction: 0.598798, Regularization: 0.021386, Discriminator: 0.043313; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:54,034 root         INFO     Train Epoch: 175 [512/8000 (6%)]\tTotal Loss: 0.720449\n",
      "Reconstruction: 0.629640, Regularization: 0.025827, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:54,133 root         INFO     Train Epoch: 175 [1024/8000 (13%)]\tTotal Loss: 0.610957\n",
      "Reconstruction: 0.529422, Regularization: 0.016562, Discriminator: 0.043315; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:54,231 root         INFO     Train Epoch: 175 [1536/8000 (19%)]\tTotal Loss: 0.539974\n",
      "Reconstruction: 0.456918, Regularization: 0.018079, Discriminator: 0.043316; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:54,329 root         INFO     Train Epoch: 175 [2048/8000 (26%)]\tTotal Loss: 0.930677\n",
      "Reconstruction: 0.830929, Regularization: 0.034762, Discriminator: 0.043321; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:54,427 root         INFO     Train Epoch: 175 [2560/8000 (32%)]\tTotal Loss: 0.582982\n",
      "Reconstruction: 0.499448, Regularization: 0.018557, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:54,525 root         INFO     Train Epoch: 175 [3072/8000 (38%)]\tTotal Loss: 0.683960\n",
      "Reconstruction: 0.598702, Regularization: 0.020285, Discriminator: 0.043324; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:54,623 root         INFO     Train Epoch: 175 [3584/8000 (45%)]\tTotal Loss: 0.565496\n",
      "Reconstruction: 0.479803, Regularization: 0.020704, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:54,720 root         INFO     Train Epoch: 175 [4096/8000 (51%)]\tTotal Loss: 0.920967\n",
      "Reconstruction: 0.827805, Regularization: 0.028188, Discriminator: 0.043319; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:54,816 root         INFO     Train Epoch: 175 [4608/8000 (58%)]\tTotal Loss: 0.605599\n",
      "Reconstruction: 0.524099, Regularization: 0.016515, Discriminator: 0.043331; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:54,912 root         INFO     Train Epoch: 175 [5120/8000 (64%)]\tTotal Loss: 0.598339\n",
      "Reconstruction: 0.517712, Regularization: 0.015642, Discriminator: 0.043321; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:55,008 root         INFO     Train Epoch: 175 [5632/8000 (70%)]\tTotal Loss: 0.511407\n",
      "Reconstruction: 0.431740, Regularization: 0.014687, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:55,104 root         INFO     Train Epoch: 175 [6144/8000 (77%)]\tTotal Loss: 0.656300\n",
      "Reconstruction: 0.567192, Regularization: 0.024121, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:55,200 root         INFO     Train Epoch: 175 [6656/8000 (83%)]\tTotal Loss: 0.813231\n",
      "Reconstruction: 0.718585, Regularization: 0.029670, Discriminator: 0.043322; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:55,296 root         INFO     Train Epoch: 175 [7168/8000 (90%)]\tTotal Loss: 0.512902\n",
      "Reconstruction: 0.431412, Regularization: 0.016511, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:55,393 root         INFO     Train Epoch: 175 [7680/8000 (96%)]\tTotal Loss: 0.604205\n",
      "Reconstruction: 0.519340, Regularization: 0.019875, Discriminator: 0.043329; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:55,464 root         INFO     ====> Epoch: 175 Average loss: 0.7152\n",
      "2019-04-09 22:49:55,491 root         INFO     Train Epoch: 176 [0/8000 (0%)]\tTotal Loss: 0.703686\n",
      "Reconstruction: 0.612181, Regularization: 0.026510, Discriminator: 0.043333; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:55,593 root         INFO     Train Epoch: 176 [512/8000 (6%)]\tTotal Loss: 0.502791\n",
      "Reconstruction: 0.421351, Regularization: 0.016441, Discriminator: 0.043344; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:55,693 root         INFO     Train Epoch: 176 [1024/8000 (13%)]\tTotal Loss: 0.626865\n",
      "Reconstruction: 0.544621, Regularization: 0.017262, Discriminator: 0.043316; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:55,792 root         INFO     Train Epoch: 176 [1536/8000 (19%)]\tTotal Loss: 0.572991\n",
      "Reconstruction: 0.486089, Regularization: 0.021906, Discriminator: 0.043334; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:55,892 root         INFO     Train Epoch: 176 [2048/8000 (26%)]\tTotal Loss: 0.842053\n",
      "Reconstruction: 0.761913, Regularization: 0.015153, Discriminator: 0.043334; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:55,992 root         INFO     Train Epoch: 176 [2560/8000 (32%)]\tTotal Loss: 0.761560\n",
      "Reconstruction: 0.672158, Regularization: 0.024401, Discriminator: 0.043337; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:56,092 root         INFO     Train Epoch: 176 [3072/8000 (38%)]\tTotal Loss: 0.867278\n",
      "Reconstruction: 0.773453, Regularization: 0.028846, Discriminator: 0.043315; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:56,192 root         INFO     Train Epoch: 176 [3584/8000 (45%)]\tTotal Loss: 0.605887\n",
      "Reconstruction: 0.524671, Regularization: 0.016235, Discriminator: 0.043315; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:56,291 root         INFO     Train Epoch: 176 [4096/8000 (51%)]\tTotal Loss: 0.708553\n",
      "Reconstruction: 0.624486, Regularization: 0.019091, Discriminator: 0.043324; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:56,390 root         INFO     Train Epoch: 176 [4608/8000 (58%)]\tTotal Loss: 0.848869\n",
      "Reconstruction: 0.761092, Regularization: 0.022807, Discriminator: 0.043313; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:56,490 root         INFO     Train Epoch: 176 [5120/8000 (64%)]\tTotal Loss: 0.885900\n",
      "Reconstruction: 0.793690, Regularization: 0.027224, Discriminator: 0.043317; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:56,590 root         INFO     Train Epoch: 176 [5632/8000 (70%)]\tTotal Loss: 0.707426\n",
      "Reconstruction: 0.615801, Regularization: 0.026638, Discriminator: 0.043323; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:56,690 root         INFO     Train Epoch: 176 [6144/8000 (77%)]\tTotal Loss: 0.502645\n",
      "Reconstruction: 0.418543, Regularization: 0.019130, Discriminator: 0.043310; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:56,789 root         INFO     Train Epoch: 176 [6656/8000 (83%)]\tTotal Loss: 0.853759\n",
      "Reconstruction: 0.755097, Regularization: 0.033689, Discriminator: 0.043309; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:56,889 root         INFO     Train Epoch: 176 [7168/8000 (90%)]\tTotal Loss: 0.585682\n",
      "Reconstruction: 0.500975, Regularization: 0.019709, Discriminator: 0.043327; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:56,989 root         INFO     Train Epoch: 176 [7680/8000 (96%)]\tTotal Loss: 0.619634\n",
      "Reconstruction: 0.534830, Regularization: 0.019831, Discriminator: 0.043319; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:57,063 root         INFO     ====> Epoch: 176 Average loss: 0.7206\n",
      "2019-04-09 22:49:57,089 root         INFO     Train Epoch: 177 [0/8000 (0%)]\tTotal Loss: 0.685809\n",
      "Reconstruction: 0.602572, Regularization: 0.018194, Discriminator: 0.043366; Generator: 0.021677,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:49:57,189 root         INFO     Train Epoch: 177 [512/8000 (6%)]\tTotal Loss: 1.073205\n",
      "Reconstruction: 0.971098, Regularization: 0.037078, Discriminator: 0.043371; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:49:57,289 root         INFO     Train Epoch: 177 [1024/8000 (13%)]\tTotal Loss: 0.631950\n",
      "Reconstruction: 0.544222, Regularization: 0.022771, Discriminator: 0.043298; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:57,389 root         INFO     Train Epoch: 177 [1536/8000 (19%)]\tTotal Loss: 0.720433\n",
      "Reconstruction: 0.633156, Regularization: 0.022310, Discriminator: 0.043304; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:57,489 root         INFO     Train Epoch: 177 [2048/8000 (26%)]\tTotal Loss: 0.487284\n",
      "Reconstruction: 0.410607, Regularization: 0.011670, Discriminator: 0.043356; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:57,589 root         INFO     Train Epoch: 177 [2560/8000 (32%)]\tTotal Loss: 0.470092\n",
      "Reconstruction: 0.393770, Regularization: 0.011342, Discriminator: 0.043325; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:57,690 root         INFO     Train Epoch: 177 [3072/8000 (38%)]\tTotal Loss: 0.713832\n",
      "Reconstruction: 0.628733, Regularization: 0.020119, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:57,789 root         INFO     Train Epoch: 177 [3584/8000 (45%)]\tTotal Loss: 0.648341\n",
      "Reconstruction: 0.559205, Regularization: 0.024159, Discriminator: 0.043323; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:57,890 root         INFO     Train Epoch: 177 [4096/8000 (51%)]\tTotal Loss: 0.400692\n",
      "Reconstruction: 0.323816, Regularization: 0.011889, Discriminator: 0.043331; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:57,990 root         INFO     Train Epoch: 177 [4608/8000 (58%)]\tTotal Loss: 0.564161\n",
      "Reconstruction: 0.481971, Regularization: 0.017210, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:58,090 root         INFO     Train Epoch: 177 [5120/8000 (64%)]\tTotal Loss: 0.601186\n",
      "Reconstruction: 0.518207, Regularization: 0.017997, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:58,190 root         INFO     Train Epoch: 177 [5632/8000 (70%)]\tTotal Loss: 0.636786\n",
      "Reconstruction: 0.553053, Regularization: 0.018746, Discriminator: 0.043327; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:58,290 root         INFO     Train Epoch: 177 [6144/8000 (77%)]\tTotal Loss: 0.780299\n",
      "Reconstruction: 0.685597, Regularization: 0.029723, Discriminator: 0.043323; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:58,389 root         INFO     Train Epoch: 177 [6656/8000 (83%)]\tTotal Loss: 0.708109\n",
      "Reconstruction: 0.617733, Regularization: 0.025399, Discriminator: 0.043314; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:58,487 root         INFO     Train Epoch: 177 [7168/8000 (90%)]\tTotal Loss: 0.659453\n",
      "Reconstruction: 0.572207, Regularization: 0.022279, Discriminator: 0.043306; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:58,586 root         INFO     Train Epoch: 177 [7680/8000 (96%)]\tTotal Loss: 0.698052\n",
      "Reconstruction: 0.603249, Regularization: 0.029828, Discriminator: 0.043312; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:58,659 root         INFO     ====> Epoch: 177 Average loss: 0.7124\n",
      "2019-04-09 22:49:58,685 root         INFO     Train Epoch: 178 [0/8000 (0%)]\tTotal Loss: 0.880529\n",
      "Reconstruction: 0.785245, Regularization: 0.030307, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:58,784 root         INFO     Train Epoch: 178 [512/8000 (6%)]\tTotal Loss: 0.647259\n",
      "Reconstruction: 0.562961, Regularization: 0.019298, Discriminator: 0.043339; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:58,882 root         INFO     Train Epoch: 178 [1024/8000 (13%)]\tTotal Loss: 0.656874\n",
      "Reconstruction: 0.573481, Regularization: 0.018469, Discriminator: 0.043262; Generator: 0.021662,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:49:58,980 root         INFO     Train Epoch: 178 [1536/8000 (19%)]\tTotal Loss: 0.487445\n",
      "Reconstruction: 0.408324, Regularization: 0.014161, Discriminator: 0.043301; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:59,078 root         INFO     Train Epoch: 178 [2048/8000 (26%)]\tTotal Loss: 0.592602\n",
      "Reconstruction: 0.507371, Regularization: 0.020213, Discriminator: 0.043365; Generator: 0.021652,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:49:59,177 root         INFO     Train Epoch: 178 [2560/8000 (32%)]\tTotal Loss: 0.554986\n",
      "Reconstruction: 0.470973, Regularization: 0.019011, Discriminator: 0.043326; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:59,274 root         INFO     Train Epoch: 178 [3072/8000 (38%)]\tTotal Loss: 0.776717\n",
      "Reconstruction: 0.685300, Regularization: 0.026459, Discriminator: 0.043295; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:59,372 root         INFO     Train Epoch: 178 [3584/8000 (45%)]\tTotal Loss: 0.644631\n",
      "Reconstruction: 0.557306, Regularization: 0.022377, Discriminator: 0.043298; Generator: 0.021650,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:49:59,473 root         INFO     Train Epoch: 178 [4096/8000 (51%)]\tTotal Loss: 0.620904\n",
      "Reconstruction: 0.528843, Regularization: 0.027092, Discriminator: 0.043315; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:59,573 root         INFO     Train Epoch: 178 [4608/8000 (58%)]\tTotal Loss: 0.831753\n",
      "Reconstruction: 0.746243, Regularization: 0.020520, Discriminator: 0.043330; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:59,672 root         INFO     Train Epoch: 178 [5120/8000 (64%)]\tTotal Loss: 0.925546\n",
      "Reconstruction: 0.832682, Regularization: 0.027875, Discriminator: 0.043332; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:59,772 root         INFO     Train Epoch: 178 [5632/8000 (70%)]\tTotal Loss: 0.921938\n",
      "Reconstruction: 0.831862, Regularization: 0.025089, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:59,872 root         INFO     Train Epoch: 178 [6144/8000 (77%)]\tTotal Loss: 0.859524\n",
      "Reconstruction: 0.769862, Regularization: 0.024670, Discriminator: 0.043327; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:49:59,973 root         INFO     Train Epoch: 178 [6656/8000 (83%)]\tTotal Loss: 1.028339\n",
      "Reconstruction: 0.928130, Regularization: 0.035225, Discriminator: 0.043317; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:00,073 root         INFO     Train Epoch: 178 [7168/8000 (90%)]\tTotal Loss: 0.753274\n",
      "Reconstruction: 0.664164, Regularization: 0.024141, Discriminator: 0.043303; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:00,174 root         INFO     Train Epoch: 178 [7680/8000 (96%)]\tTotal Loss: 0.759479\n",
      "Reconstruction: 0.663164, Regularization: 0.031330, Discriminator: 0.043319; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:00,249 root         INFO     ====> Epoch: 178 Average loss: 0.7191\n",
      "2019-04-09 22:50:00,276 root         INFO     Train Epoch: 179 [0/8000 (0%)]\tTotal Loss: 0.576636\n",
      "Reconstruction: 0.493923, Regularization: 0.017724, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:00,374 root         INFO     Train Epoch: 179 [512/8000 (6%)]\tTotal Loss: 0.845196\n",
      "Reconstruction: 0.751802, Regularization: 0.028424, Discriminator: 0.043311; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:00,473 root         INFO     Train Epoch: 179 [1024/8000 (13%)]\tTotal Loss: 0.514081\n",
      "Reconstruction: 0.431190, Regularization: 0.017916, Discriminator: 0.043316; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:00,572 root         INFO     Train Epoch: 179 [1536/8000 (19%)]\tTotal Loss: 0.536360\n",
      "Reconstruction: 0.457245, Regularization: 0.014160, Discriminator: 0.043289; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:00,671 root         INFO     Train Epoch: 179 [2048/8000 (26%)]\tTotal Loss: 0.764341\n",
      "Reconstruction: 0.670666, Regularization: 0.028734, Discriminator: 0.043281; Generator: 0.021660,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:00,770 root         INFO     Train Epoch: 179 [2560/8000 (32%)]\tTotal Loss: 0.875121\n",
      "Reconstruction: 0.784077, Regularization: 0.026061, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:00,869 root         INFO     Train Epoch: 179 [3072/8000 (38%)]\tTotal Loss: 0.793205\n",
      "Reconstruction: 0.706552, Regularization: 0.021643, Discriminator: 0.043343; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:00,968 root         INFO     Train Epoch: 179 [3584/8000 (45%)]\tTotal Loss: 1.001071\n",
      "Reconstruction: 0.909780, Regularization: 0.026296, Discriminator: 0.043337; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:01,068 root         INFO     Train Epoch: 179 [4096/8000 (51%)]\tTotal Loss: 0.704117\n",
      "Reconstruction: 0.619441, Regularization: 0.019708, Discriminator: 0.043308; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:01,169 root         INFO     Train Epoch: 179 [4608/8000 (58%)]\tTotal Loss: 0.524639\n",
      "Reconstruction: 0.442107, Regularization: 0.017557, Discriminator: 0.043323; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:01,268 root         INFO     Train Epoch: 179 [5120/8000 (64%)]\tTotal Loss: 0.600543\n",
      "Reconstruction: 0.512591, Regularization: 0.022990, Discriminator: 0.043305; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:01,367 root         INFO     Train Epoch: 179 [5632/8000 (70%)]\tTotal Loss: 0.980829\n",
      "Reconstruction: 0.887528, Regularization: 0.028327, Discriminator: 0.043315; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:01,468 root         INFO     Train Epoch: 179 [6144/8000 (77%)]\tTotal Loss: 0.724113\n",
      "Reconstruction: 0.639390, Regularization: 0.019754, Discriminator: 0.043312; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:01,566 root         INFO     Train Epoch: 179 [6656/8000 (83%)]\tTotal Loss: 0.589308\n",
      "Reconstruction: 0.506427, Regularization: 0.017883, Discriminator: 0.043336; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:01,662 root         INFO     Train Epoch: 179 [7168/8000 (90%)]\tTotal Loss: 0.625936\n",
      "Reconstruction: 0.541983, Regularization: 0.018961, Discriminator: 0.043337; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:01,756 root         INFO     Train Epoch: 179 [7680/8000 (96%)]\tTotal Loss: 0.434209\n",
      "Reconstruction: 0.359502, Regularization: 0.009721, Discriminator: 0.043327; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:01,827 root         INFO     ====> Epoch: 179 Average loss: 0.7173\n",
      "2019-04-09 22:50:01,854 root         INFO     Train Epoch: 180 [0/8000 (0%)]\tTotal Loss: 0.695650\n",
      "Reconstruction: 0.612418, Regularization: 0.018248, Discriminator: 0.043326; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:01,951 root         INFO     Train Epoch: 180 [512/8000 (6%)]\tTotal Loss: 0.959924\n",
      "Reconstruction: 0.864904, Regularization: 0.030034, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:02,048 root         INFO     Train Epoch: 180 [1024/8000 (13%)]\tTotal Loss: 0.879803\n",
      "Reconstruction: 0.786079, Regularization: 0.028753, Discriminator: 0.043316; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:02,144 root         INFO     Train Epoch: 180 [1536/8000 (19%)]\tTotal Loss: 0.646320\n",
      "Reconstruction: 0.562101, Regularization: 0.019242, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:02,240 root         INFO     Train Epoch: 180 [2048/8000 (26%)]\tTotal Loss: 0.603894\n",
      "Reconstruction: 0.519035, Regularization: 0.019888, Discriminator: 0.043309; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:02,336 root         INFO     Train Epoch: 180 [2560/8000 (32%)]\tTotal Loss: 1.008178\n",
      "Reconstruction: 0.909945, Regularization: 0.033250, Discriminator: 0.043320; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:02,432 root         INFO     Train Epoch: 180 [3072/8000 (38%)]\tTotal Loss: 0.767500\n",
      "Reconstruction: 0.677676, Regularization: 0.024843, Discriminator: 0.043318; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:02,528 root         INFO     Train Epoch: 180 [3584/8000 (45%)]\tTotal Loss: 0.566403\n",
      "Reconstruction: 0.485747, Regularization: 0.015707, Discriminator: 0.043283; Generator: 0.021666,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:02,626 root         INFO     Train Epoch: 180 [4096/8000 (51%)]\tTotal Loss: 0.797474\n",
      "Reconstruction: 0.712835, Regularization: 0.019666, Discriminator: 0.043312; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:02,723 root         INFO     Train Epoch: 180 [4608/8000 (58%)]\tTotal Loss: 0.800138\n",
      "Reconstruction: 0.712890, Regularization: 0.022228, Discriminator: 0.043362; Generator: 0.021659,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:50:02,819 root         INFO     Train Epoch: 180 [5120/8000 (64%)]\tTotal Loss: 0.680218\n",
      "Reconstruction: 0.589844, Regularization: 0.025372, Discriminator: 0.043341; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:02,919 root         INFO     Train Epoch: 180 [5632/8000 (70%)]\tTotal Loss: 0.814675\n",
      "Reconstruction: 0.726742, Regularization: 0.022926, Discriminator: 0.043346; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:03,019 root         INFO     Train Epoch: 180 [6144/8000 (77%)]\tTotal Loss: 0.750727\n",
      "Reconstruction: 0.662791, Regularization: 0.022936, Discriminator: 0.043338; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:03,119 root         INFO     Train Epoch: 180 [6656/8000 (83%)]\tTotal Loss: 0.570496\n",
      "Reconstruction: 0.489478, Regularization: 0.016006, Discriminator: 0.043355; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:03,219 root         INFO     Train Epoch: 180 [7168/8000 (90%)]\tTotal Loss: 0.552089\n",
      "Reconstruction: 0.467974, Regularization: 0.019144, Discriminator: 0.043312; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:03,317 root         INFO     Train Epoch: 180 [7680/8000 (96%)]\tTotal Loss: 0.788018\n",
      "Reconstruction: 0.694413, Regularization: 0.028652, Discriminator: 0.043297; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:03,392 root         INFO     ====> Epoch: 180 Average loss: 0.7145\n",
      "2019-04-09 22:50:03,419 root         INFO     Train Epoch: 181 [0/8000 (0%)]\tTotal Loss: 0.678102\n",
      "Reconstruction: 0.593832, Regularization: 0.019271, Discriminator: 0.043338; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:03,524 root         INFO     Train Epoch: 181 [512/8000 (6%)]\tTotal Loss: 0.698471\n",
      "Reconstruction: 0.615695, Regularization: 0.017800, Discriminator: 0.043314; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:03,625 root         INFO     Train Epoch: 181 [1024/8000 (13%)]\tTotal Loss: 0.883570\n",
      "Reconstruction: 0.792786, Regularization: 0.025821, Discriminator: 0.043305; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:03,724 root         INFO     Train Epoch: 181 [1536/8000 (19%)]\tTotal Loss: 0.593879\n",
      "Reconstruction: 0.512170, Regularization: 0.016727, Discriminator: 0.043317; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:03,822 root         INFO     Train Epoch: 181 [2048/8000 (26%)]\tTotal Loss: 0.522769\n",
      "Reconstruction: 0.443590, Regularization: 0.014198, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:03,921 root         INFO     Train Epoch: 181 [2560/8000 (32%)]\tTotal Loss: 0.522905\n",
      "Reconstruction: 0.442197, Regularization: 0.015724, Discriminator: 0.043322; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:04,020 root         INFO     Train Epoch: 181 [3072/8000 (38%)]\tTotal Loss: 0.734690\n",
      "Reconstruction: 0.645715, Regularization: 0.023985, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:04,121 root         INFO     Train Epoch: 181 [3584/8000 (45%)]\tTotal Loss: 0.993044\n",
      "Reconstruction: 0.896792, Regularization: 0.031270, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:04,223 root         INFO     Train Epoch: 181 [4096/8000 (51%)]\tTotal Loss: 0.710128\n",
      "Reconstruction: 0.628162, Regularization: 0.016989, Discriminator: 0.043318; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:04,325 root         INFO     Train Epoch: 181 [4608/8000 (58%)]\tTotal Loss: 0.813308\n",
      "Reconstruction: 0.715268, Regularization: 0.033048, Discriminator: 0.043327; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:04,433 root         INFO     Train Epoch: 181 [5120/8000 (64%)]\tTotal Loss: 0.564685\n",
      "Reconstruction: 0.482429, Regularization: 0.017272, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:04,535 root         INFO     Train Epoch: 181 [5632/8000 (70%)]\tTotal Loss: 0.657745\n",
      "Reconstruction: 0.571366, Regularization: 0.021412, Discriminator: 0.043303; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:04,637 root         INFO     Train Epoch: 181 [6144/8000 (77%)]\tTotal Loss: 0.771346\n",
      "Reconstruction: 0.680739, Regularization: 0.025630, Discriminator: 0.043313; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:04,740 root         INFO     Train Epoch: 181 [6656/8000 (83%)]\tTotal Loss: 0.823843\n",
      "Reconstruction: 0.729167, Regularization: 0.029724, Discriminator: 0.043289; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:04,867 root         INFO     Train Epoch: 181 [7168/8000 (90%)]\tTotal Loss: 0.510975\n",
      "Reconstruction: 0.432991, Regularization: 0.012976, Discriminator: 0.043352; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:04,975 root         INFO     Train Epoch: 181 [7680/8000 (96%)]\tTotal Loss: 0.695554\n",
      "Reconstruction: 0.604758, Regularization: 0.025843, Discriminator: 0.043300; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:05,065 root         INFO     ====> Epoch: 181 Average loss: 0.7207\n",
      "2019-04-09 22:50:05,099 root         INFO     Train Epoch: 182 [0/8000 (0%)]\tTotal Loss: 0.944399\n",
      "Reconstruction: 0.848140, Regularization: 0.031306, Discriminator: 0.043291; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:05,211 root         INFO     Train Epoch: 182 [512/8000 (6%)]\tTotal Loss: 0.484885\n",
      "Reconstruction: 0.407556, Regularization: 0.012355, Discriminator: 0.043310; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:05,316 root         INFO     Train Epoch: 182 [1024/8000 (13%)]\tTotal Loss: 0.720848\n",
      "Reconstruction: 0.631688, Regularization: 0.024162, Discriminator: 0.043341; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:05,422 root         INFO     Train Epoch: 182 [1536/8000 (19%)]\tTotal Loss: 0.497805\n",
      "Reconstruction: 0.413711, Regularization: 0.019149, Discriminator: 0.043280; Generator: 0.021665,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:05,528 root         INFO     Train Epoch: 182 [2048/8000 (26%)]\tTotal Loss: 0.725864\n",
      "Reconstruction: 0.636352, Regularization: 0.024562, Discriminator: 0.043291; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:05,631 root         INFO     Train Epoch: 182 [2560/8000 (32%)]\tTotal Loss: 0.707013\n",
      "Reconstruction: 0.621138, Regularization: 0.020921, Discriminator: 0.043296; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:05,735 root         INFO     Train Epoch: 182 [3072/8000 (38%)]\tTotal Loss: 0.703492\n",
      "Reconstruction: 0.613690, Regularization: 0.024827, Discriminator: 0.043316; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:05,837 root         INFO     Train Epoch: 182 [3584/8000 (45%)]\tTotal Loss: 0.741167\n",
      "Reconstruction: 0.657826, Regularization: 0.018327, Discriminator: 0.043354; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:05,939 root         INFO     Train Epoch: 182 [4096/8000 (51%)]\tTotal Loss: 0.864872\n",
      "Reconstruction: 0.769258, Regularization: 0.030623, Discriminator: 0.043326; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:06,040 root         INFO     Train Epoch: 182 [4608/8000 (58%)]\tTotal Loss: 0.776682\n",
      "Reconstruction: 0.687662, Regularization: 0.024058, Discriminator: 0.043304; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:06,142 root         INFO     Train Epoch: 182 [5120/8000 (64%)]\tTotal Loss: 0.584405\n",
      "Reconstruction: 0.500123, Regularization: 0.019307, Discriminator: 0.043320; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:06,244 root         INFO     Train Epoch: 182 [5632/8000 (70%)]\tTotal Loss: 0.783671\n",
      "Reconstruction: 0.693490, Regularization: 0.025203, Discriminator: 0.043321; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:06,345 root         INFO     Train Epoch: 182 [6144/8000 (77%)]\tTotal Loss: 0.621685\n",
      "Reconstruction: 0.533756, Regularization: 0.022948, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:06,446 root         INFO     Train Epoch: 182 [6656/8000 (83%)]\tTotal Loss: 0.747927\n",
      "Reconstruction: 0.654853, Regularization: 0.028104, Discriminator: 0.043315; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:06,548 root         INFO     Train Epoch: 182 [7168/8000 (90%)]\tTotal Loss: 0.708203\n",
      "Reconstruction: 0.627728, Regularization: 0.015520, Discriminator: 0.043291; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:06,649 root         INFO     Train Epoch: 182 [7680/8000 (96%)]\tTotal Loss: 0.508329\n",
      "Reconstruction: 0.429272, Regularization: 0.014081, Discriminator: 0.043308; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:06,724 root         INFO     ====> Epoch: 182 Average loss: 0.7131\n",
      "2019-04-09 22:50:06,751 root         INFO     Train Epoch: 183 [0/8000 (0%)]\tTotal Loss: 0.906174\n",
      "Reconstruction: 0.808716, Regularization: 0.032504, Discriminator: 0.043292; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:06,849 root         INFO     Train Epoch: 183 [512/8000 (6%)]\tTotal Loss: 0.615463\n",
      "Reconstruction: 0.533926, Regularization: 0.016605, Discriminator: 0.043273; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:06,948 root         INFO     Train Epoch: 183 [1024/8000 (13%)]\tTotal Loss: 0.673824\n",
      "Reconstruction: 0.586466, Regularization: 0.022334, Discriminator: 0.043363; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:50:07,047 root         INFO     Train Epoch: 183 [1536/8000 (19%)]\tTotal Loss: 0.654277\n",
      "Reconstruction: 0.571251, Regularization: 0.018028, Discriminator: 0.043339; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:07,145 root         INFO     Train Epoch: 183 [2048/8000 (26%)]\tTotal Loss: 0.577727\n",
      "Reconstruction: 0.496255, Regularization: 0.016506, Discriminator: 0.043301; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:07,244 root         INFO     Train Epoch: 183 [2560/8000 (32%)]\tTotal Loss: 0.691000\n",
      "Reconstruction: 0.603538, Regularization: 0.022480, Discriminator: 0.043320; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:07,341 root         INFO     Train Epoch: 183 [3072/8000 (38%)]\tTotal Loss: 0.646004\n",
      "Reconstruction: 0.561290, Regularization: 0.019727, Discriminator: 0.043330; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:07,438 root         INFO     Train Epoch: 183 [3584/8000 (45%)]\tTotal Loss: 0.903432\n",
      "Reconstruction: 0.808218, Regularization: 0.030222, Discriminator: 0.043329; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:07,535 root         INFO     Train Epoch: 183 [4096/8000 (51%)]\tTotal Loss: 0.726975\n",
      "Reconstruction: 0.640020, Regularization: 0.021942, Discriminator: 0.043350; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:07,635 root         INFO     Train Epoch: 183 [4608/8000 (58%)]\tTotal Loss: 0.634119\n",
      "Reconstruction: 0.550738, Regularization: 0.018384, Discriminator: 0.043336; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:07,733 root         INFO     Train Epoch: 183 [5120/8000 (64%)]\tTotal Loss: 0.925061\n",
      "Reconstruction: 0.831739, Regularization: 0.028339, Discriminator: 0.043326; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:07,832 root         INFO     Train Epoch: 183 [5632/8000 (70%)]\tTotal Loss: 0.879120\n",
      "Reconstruction: 0.781849, Regularization: 0.032300, Discriminator: 0.043309; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:07,931 root         INFO     Train Epoch: 183 [6144/8000 (77%)]\tTotal Loss: 0.709903\n",
      "Reconstruction: 0.623278, Regularization: 0.021627, Discriminator: 0.043337; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:08,028 root         INFO     Train Epoch: 183 [6656/8000 (83%)]\tTotal Loss: 0.616707\n",
      "Reconstruction: 0.534289, Regularization: 0.017434, Discriminator: 0.043318; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:08,127 root         INFO     Train Epoch: 183 [7168/8000 (90%)]\tTotal Loss: 0.587325\n",
      "Reconstruction: 0.505411, Regularization: 0.016933, Discriminator: 0.043323; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:08,225 root         INFO     Train Epoch: 183 [7680/8000 (96%)]\tTotal Loss: 0.532992\n",
      "Reconstruction: 0.453058, Regularization: 0.014944, Discriminator: 0.043320; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:08,299 root         INFO     ====> Epoch: 183 Average loss: 0.7191\n",
      "2019-04-09 22:50:08,325 root         INFO     Train Epoch: 184 [0/8000 (0%)]\tTotal Loss: 0.723725\n",
      "Reconstruction: 0.635268, Regularization: 0.023472, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:08,425 root         INFO     Train Epoch: 184 [512/8000 (6%)]\tTotal Loss: 0.879858\n",
      "Reconstruction: 0.781132, Regularization: 0.033741, Discriminator: 0.043321; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:08,523 root         INFO     Train Epoch: 184 [1024/8000 (13%)]\tTotal Loss: 0.743998\n",
      "Reconstruction: 0.659280, Regularization: 0.019738, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:08,621 root         INFO     Train Epoch: 184 [1536/8000 (19%)]\tTotal Loss: 0.608819\n",
      "Reconstruction: 0.520905, Regularization: 0.022939, Discriminator: 0.043309; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:08,720 root         INFO     Train Epoch: 184 [2048/8000 (26%)]\tTotal Loss: 0.755644\n",
      "Reconstruction: 0.666710, Regularization: 0.023966, Discriminator: 0.043308; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:08,817 root         INFO     Train Epoch: 184 [2560/8000 (32%)]\tTotal Loss: 0.842550\n",
      "Reconstruction: 0.755725, Regularization: 0.021870, Discriminator: 0.043282; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:08,914 root         INFO     Train Epoch: 184 [3072/8000 (38%)]\tTotal Loss: 0.754252\n",
      "Reconstruction: 0.663328, Regularization: 0.025943, Discriminator: 0.043311; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:09,010 root         INFO     Train Epoch: 184 [3584/8000 (45%)]\tTotal Loss: 0.682980\n",
      "Reconstruction: 0.596272, Regularization: 0.021769, Discriminator: 0.043280; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:09,105 root         INFO     Train Epoch: 184 [4096/8000 (51%)]\tTotal Loss: 0.926455\n",
      "Reconstruction: 0.831562, Regularization: 0.029936, Discriminator: 0.043294; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:09,201 root         INFO     Train Epoch: 184 [4608/8000 (58%)]\tTotal Loss: 0.776320\n",
      "Reconstruction: 0.690068, Regularization: 0.021245, Discriminator: 0.043351; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:09,297 root         INFO     Train Epoch: 184 [5120/8000 (64%)]\tTotal Loss: 0.674282\n",
      "Reconstruction: 0.594750, Regularization: 0.014542, Discriminator: 0.043335; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:09,393 root         INFO     Train Epoch: 184 [5632/8000 (70%)]\tTotal Loss: 0.558964\n",
      "Reconstruction: 0.477914, Regularization: 0.016004, Discriminator: 0.043375; Generator: 0.021670,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:50:09,489 root         INFO     Train Epoch: 184 [6144/8000 (77%)]\tTotal Loss: 0.488491\n",
      "Reconstruction: 0.410020, Regularization: 0.013525, Discriminator: 0.043293; Generator: 0.021653,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:09,585 root         INFO     Train Epoch: 184 [6656/8000 (83%)]\tTotal Loss: 0.572867\n",
      "Reconstruction: 0.491872, Regularization: 0.015968, Discriminator: 0.043371; Generator: 0.021657,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:50:09,680 root         INFO     Train Epoch: 184 [7168/8000 (90%)]\tTotal Loss: 0.565649\n",
      "Reconstruction: 0.480084, Regularization: 0.020586, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:09,776 root         INFO     Train Epoch: 184 [7680/8000 (96%)]\tTotal Loss: 0.714761\n",
      "Reconstruction: 0.622851, Regularization: 0.026921, Discriminator: 0.043330; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:09,849 root         INFO     ====> Epoch: 184 Average loss: 0.7188\n",
      "2019-04-09 22:50:09,875 root         INFO     Train Epoch: 185 [0/8000 (0%)]\tTotal Loss: 0.969407\n",
      "Reconstruction: 0.872660, Regularization: 0.031765, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:09,974 root         INFO     Train Epoch: 185 [512/8000 (6%)]\tTotal Loss: 0.661619\n",
      "Reconstruction: 0.576808, Regularization: 0.019827, Discriminator: 0.043326; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:10,070 root         INFO     Train Epoch: 185 [1024/8000 (13%)]\tTotal Loss: 0.460457\n",
      "Reconstruction: 0.380652, Regularization: 0.014825, Discriminator: 0.043324; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:10,166 root         INFO     Train Epoch: 185 [1536/8000 (19%)]\tTotal Loss: 0.653519\n",
      "Reconstruction: 0.569927, Regularization: 0.018621, Discriminator: 0.043315; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:10,262 root         INFO     Train Epoch: 185 [2048/8000 (26%)]\tTotal Loss: 0.867166\n",
      "Reconstruction: 0.773875, Regularization: 0.028313, Discriminator: 0.043323; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:10,358 root         INFO     Train Epoch: 185 [2560/8000 (32%)]\tTotal Loss: 0.588467\n",
      "Reconstruction: 0.503193, Regularization: 0.020294, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:10,454 root         INFO     Train Epoch: 185 [3072/8000 (38%)]\tTotal Loss: 0.710526\n",
      "Reconstruction: 0.622165, Regularization: 0.023378, Discriminator: 0.043325; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:10,550 root         INFO     Train Epoch: 185 [3584/8000 (45%)]\tTotal Loss: 0.642017\n",
      "Reconstruction: 0.556008, Regularization: 0.021011, Discriminator: 0.043337; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:10,645 root         INFO     Train Epoch: 185 [4096/8000 (51%)]\tTotal Loss: 0.638699\n",
      "Reconstruction: 0.552177, Regularization: 0.021536, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:10,742 root         INFO     Train Epoch: 185 [4608/8000 (58%)]\tTotal Loss: 0.505290\n",
      "Reconstruction: 0.424495, Regularization: 0.015823, Discriminator: 0.043307; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:10,838 root         INFO     Train Epoch: 185 [5120/8000 (64%)]\tTotal Loss: 0.744558\n",
      "Reconstruction: 0.655812, Regularization: 0.023789, Discriminator: 0.043291; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:10,934 root         INFO     Train Epoch: 185 [5632/8000 (70%)]\tTotal Loss: 0.925116\n",
      "Reconstruction: 0.829188, Regularization: 0.030927, Discriminator: 0.043342; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:11,030 root         INFO     Train Epoch: 185 [6144/8000 (77%)]\tTotal Loss: 0.637297\n",
      "Reconstruction: 0.551411, Regularization: 0.020914, Discriminator: 0.043314; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:11,126 root         INFO     Train Epoch: 185 [6656/8000 (83%)]\tTotal Loss: 0.829540\n",
      "Reconstruction: 0.735268, Regularization: 0.029277, Discriminator: 0.043342; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:11,221 root         INFO     Train Epoch: 185 [7168/8000 (90%)]\tTotal Loss: 0.713661\n",
      "Reconstruction: 0.625092, Regularization: 0.023599, Discriminator: 0.043315; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:11,318 root         INFO     Train Epoch: 185 [7680/8000 (96%)]\tTotal Loss: 0.804193\n",
      "Reconstruction: 0.710985, Regularization: 0.028216, Discriminator: 0.043332; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:11,391 root         INFO     ====> Epoch: 185 Average loss: 0.7133\n",
      "2019-04-09 22:50:11,417 root         INFO     Train Epoch: 186 [0/8000 (0%)]\tTotal Loss: 0.779301\n",
      "Reconstruction: 0.682859, Regularization: 0.031458, Discriminator: 0.043328; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:11,518 root         INFO     Train Epoch: 186 [512/8000 (6%)]\tTotal Loss: 0.898521\n",
      "Reconstruction: 0.805057, Regularization: 0.028483, Discriminator: 0.043328; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:11,618 root         INFO     Train Epoch: 186 [1024/8000 (13%)]\tTotal Loss: 0.610340\n",
      "Reconstruction: 0.527920, Regularization: 0.017416, Discriminator: 0.043340; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:11,717 root         INFO     Train Epoch: 186 [1536/8000 (19%)]\tTotal Loss: 0.669457\n",
      "Reconstruction: 0.582451, Regularization: 0.022006, Discriminator: 0.043343; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:11,816 root         INFO     Train Epoch: 186 [2048/8000 (26%)]\tTotal Loss: 0.564100\n",
      "Reconstruction: 0.482947, Regularization: 0.016162, Discriminator: 0.043328; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:11,915 root         INFO     Train Epoch: 186 [2560/8000 (32%)]\tTotal Loss: 0.535860\n",
      "Reconstruction: 0.452731, Regularization: 0.018125, Discriminator: 0.043341; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:12,013 root         INFO     Train Epoch: 186 [3072/8000 (38%)]\tTotal Loss: 0.624274\n",
      "Reconstruction: 0.544670, Regularization: 0.014616, Discriminator: 0.043326; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:12,111 root         INFO     Train Epoch: 186 [3584/8000 (45%)]\tTotal Loss: 0.665782\n",
      "Reconstruction: 0.573817, Regularization: 0.026969, Discriminator: 0.043332; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:12,210 root         INFO     Train Epoch: 186 [4096/8000 (51%)]\tTotal Loss: 0.700236\n",
      "Reconstruction: 0.609717, Regularization: 0.025541, Discriminator: 0.043315; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:12,309 root         INFO     Train Epoch: 186 [4608/8000 (58%)]\tTotal Loss: 0.771232\n",
      "Reconstruction: 0.685975, Regularization: 0.020274, Discriminator: 0.043325; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:12,408 root         INFO     Train Epoch: 186 [5120/8000 (64%)]\tTotal Loss: 0.897017\n",
      "Reconstruction: 0.796353, Regularization: 0.035686, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:12,507 root         INFO     Train Epoch: 186 [5632/8000 (70%)]\tTotal Loss: 0.628351\n",
      "Reconstruction: 0.544960, Regularization: 0.018408, Discriminator: 0.043323; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:12,606 root         INFO     Train Epoch: 186 [6144/8000 (77%)]\tTotal Loss: 0.501622\n",
      "Reconstruction: 0.419460, Regularization: 0.017182, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:12,704 root         INFO     Train Epoch: 186 [6656/8000 (83%)]\tTotal Loss: 0.699773\n",
      "Reconstruction: 0.607092, Regularization: 0.027707, Discriminator: 0.043312; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:12,803 root         INFO     Train Epoch: 186 [7168/8000 (90%)]\tTotal Loss: 0.565758\n",
      "Reconstruction: 0.482185, Regularization: 0.018593, Discriminator: 0.043314; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:12,902 root         INFO     Train Epoch: 186 [7680/8000 (96%)]\tTotal Loss: 0.569563\n",
      "Reconstruction: 0.487722, Regularization: 0.016860, Discriminator: 0.043318; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:12,976 root         INFO     ====> Epoch: 186 Average loss: 0.7200\n",
      "2019-04-09 22:50:13,003 root         INFO     Train Epoch: 187 [0/8000 (0%)]\tTotal Loss: 0.850929\n",
      "Reconstruction: 0.755587, Regularization: 0.030355, Discriminator: 0.043321; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:13,102 root         INFO     Train Epoch: 187 [512/8000 (6%)]\tTotal Loss: 0.585332\n",
      "Reconstruction: 0.498954, Regularization: 0.021416, Discriminator: 0.043294; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:13,200 root         INFO     Train Epoch: 187 [1024/8000 (13%)]\tTotal Loss: 0.397481\n",
      "Reconstruction: 0.319679, Regularization: 0.012798, Discriminator: 0.043343; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:13,298 root         INFO     Train Epoch: 187 [1536/8000 (19%)]\tTotal Loss: 0.769532\n",
      "Reconstruction: 0.681437, Regularization: 0.023120, Discriminator: 0.043318; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:13,396 root         INFO     Train Epoch: 187 [2048/8000 (26%)]\tTotal Loss: 0.652647\n",
      "Reconstruction: 0.566833, Regularization: 0.020839, Discriminator: 0.043310; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:13,494 root         INFO     Train Epoch: 187 [2560/8000 (32%)]\tTotal Loss: 0.894860\n",
      "Reconstruction: 0.795493, Regularization: 0.034384, Discriminator: 0.043324; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:13,592 root         INFO     Train Epoch: 187 [3072/8000 (38%)]\tTotal Loss: 0.919756\n",
      "Reconstruction: 0.827380, Regularization: 0.027399, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:13,690 root         INFO     Train Epoch: 187 [3584/8000 (45%)]\tTotal Loss: 0.745783\n",
      "Reconstruction: 0.654994, Regularization: 0.025796, Discriminator: 0.043319; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:13,788 root         INFO     Train Epoch: 187 [4096/8000 (51%)]\tTotal Loss: 0.884950\n",
      "Reconstruction: 0.785844, Regularization: 0.034137, Discriminator: 0.043305; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:13,889 root         INFO     Train Epoch: 187 [4608/8000 (58%)]\tTotal Loss: 0.761009\n",
      "Reconstruction: 0.671551, Regularization: 0.024492, Discriminator: 0.043307; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:13,989 root         INFO     Train Epoch: 187 [5120/8000 (64%)]\tTotal Loss: 0.718136\n",
      "Reconstruction: 0.629276, Regularization: 0.023879, Discriminator: 0.043324; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:14,089 root         INFO     Train Epoch: 187 [5632/8000 (70%)]\tTotal Loss: 0.479339\n",
      "Reconstruction: 0.397454, Regularization: 0.016925, Discriminator: 0.043297; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:14,189 root         INFO     Train Epoch: 187 [6144/8000 (77%)]\tTotal Loss: 0.718508\n",
      "Reconstruction: 0.625009, Regularization: 0.028536, Discriminator: 0.043304; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:14,288 root         INFO     Train Epoch: 187 [6656/8000 (83%)]\tTotal Loss: 0.551724\n",
      "Reconstruction: 0.469666, Regularization: 0.017091, Discriminator: 0.043311; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:14,388 root         INFO     Train Epoch: 187 [7168/8000 (90%)]\tTotal Loss: 0.684644\n",
      "Reconstruction: 0.600822, Regularization: 0.018814, Discriminator: 0.043347; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:14,489 root         INFO     Train Epoch: 187 [7680/8000 (96%)]\tTotal Loss: 0.666061\n",
      "Reconstruction: 0.581516, Regularization: 0.019563, Discriminator: 0.043324; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:14,564 root         INFO     ====> Epoch: 187 Average loss: 0.7163\n",
      "2019-04-09 22:50:14,591 root         INFO     Train Epoch: 188 [0/8000 (0%)]\tTotal Loss: 0.814060\n",
      "Reconstruction: 0.716407, Regularization: 0.032683, Discriminator: 0.043310; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:14,691 root         INFO     Train Epoch: 188 [512/8000 (6%)]\tTotal Loss: 0.648407\n",
      "Reconstruction: 0.558385, Regularization: 0.025047, Discriminator: 0.043314; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:14,789 root         INFO     Train Epoch: 188 [1024/8000 (13%)]\tTotal Loss: 0.865719\n",
      "Reconstruction: 0.774295, Regularization: 0.026446, Discriminator: 0.043321; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:14,888 root         INFO     Train Epoch: 188 [1536/8000 (19%)]\tTotal Loss: 0.807027\n",
      "Reconstruction: 0.720835, Regularization: 0.021209, Discriminator: 0.043325; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:14,987 root         INFO     Train Epoch: 188 [2048/8000 (26%)]\tTotal Loss: 0.615323\n",
      "Reconstruction: 0.529386, Regularization: 0.020962, Discriminator: 0.043319; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:15,085 root         INFO     Train Epoch: 188 [2560/8000 (32%)]\tTotal Loss: 0.705544\n",
      "Reconstruction: 0.615748, Regularization: 0.024819, Discriminator: 0.043314; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:15,184 root         INFO     Train Epoch: 188 [3072/8000 (38%)]\tTotal Loss: 0.837415\n",
      "Reconstruction: 0.743930, Regularization: 0.028513, Discriminator: 0.043310; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:15,282 root         INFO     Train Epoch: 188 [3584/8000 (45%)]\tTotal Loss: 0.597975\n",
      "Reconstruction: 0.513802, Regularization: 0.019194, Discriminator: 0.043319; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:15,381 root         INFO     Train Epoch: 188 [4096/8000 (51%)]\tTotal Loss: 0.504994\n",
      "Reconstruction: 0.426555, Regularization: 0.013446, Discriminator: 0.043335; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:15,478 root         INFO     Train Epoch: 188 [4608/8000 (58%)]\tTotal Loss: 0.718698\n",
      "Reconstruction: 0.632276, Regularization: 0.021444, Discriminator: 0.043314; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:15,573 root         INFO     Train Epoch: 188 [5120/8000 (64%)]\tTotal Loss: 0.580792\n",
      "Reconstruction: 0.499975, Regularization: 0.015842, Discriminator: 0.043317; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:15,670 root         INFO     Train Epoch: 188 [5632/8000 (70%)]\tTotal Loss: 0.584024\n",
      "Reconstruction: 0.502806, Regularization: 0.016246, Discriminator: 0.043310; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:15,767 root         INFO     Train Epoch: 188 [6144/8000 (77%)]\tTotal Loss: 0.800259\n",
      "Reconstruction: 0.714056, Regularization: 0.021236, Discriminator: 0.043311; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:15,864 root         INFO     Train Epoch: 188 [6656/8000 (83%)]\tTotal Loss: 0.711938\n",
      "Reconstruction: 0.624270, Regularization: 0.022694, Discriminator: 0.043314; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:15,962 root         INFO     Train Epoch: 188 [7168/8000 (90%)]\tTotal Loss: 0.963350\n",
      "Reconstruction: 0.861540, Regularization: 0.036836, Discriminator: 0.043314; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:16,058 root         INFO     Train Epoch: 188 [7680/8000 (96%)]\tTotal Loss: 0.835956\n",
      "Reconstruction: 0.746625, Regularization: 0.024347, Discriminator: 0.043320; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:16,131 root         INFO     ====> Epoch: 188 Average loss: 0.7141\n",
      "2019-04-09 22:50:16,157 root         INFO     Train Epoch: 189 [0/8000 (0%)]\tTotal Loss: 0.690363\n",
      "Reconstruction: 0.605072, Regularization: 0.020330, Discriminator: 0.043311; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:16,257 root         INFO     Train Epoch: 189 [512/8000 (6%)]\tTotal Loss: 0.598229\n",
      "Reconstruction: 0.517407, Regularization: 0.015882, Discriminator: 0.043286; Generator: 0.021654,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:16,357 root         INFO     Train Epoch: 189 [1024/8000 (13%)]\tTotal Loss: 0.565411\n",
      "Reconstruction: 0.479704, Regularization: 0.020741, Discriminator: 0.043301; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:16,456 root         INFO     Train Epoch: 189 [1536/8000 (19%)]\tTotal Loss: 0.828517\n",
      "Reconstruction: 0.733396, Regularization: 0.030150, Discriminator: 0.043309; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:16,555 root         INFO     Train Epoch: 189 [2048/8000 (26%)]\tTotal Loss: 0.857669\n",
      "Reconstruction: 0.759730, Regularization: 0.032947, Discriminator: 0.043330; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:16,653 root         INFO     Train Epoch: 189 [2560/8000 (32%)]\tTotal Loss: 0.731979\n",
      "Reconstruction: 0.641473, Regularization: 0.025529, Discriminator: 0.043317; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:16,751 root         INFO     Train Epoch: 189 [3072/8000 (38%)]\tTotal Loss: 0.810627\n",
      "Reconstruction: 0.719656, Regularization: 0.025957, Discriminator: 0.043348; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:16,848 root         INFO     Train Epoch: 189 [3584/8000 (45%)]\tTotal Loss: 0.676591\n",
      "Reconstruction: 0.594189, Regularization: 0.017413, Discriminator: 0.043326; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:16,944 root         INFO     Train Epoch: 189 [4096/8000 (51%)]\tTotal Loss: 0.679150\n",
      "Reconstruction: 0.590743, Regularization: 0.023422, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:17,041 root         INFO     Train Epoch: 189 [4608/8000 (58%)]\tTotal Loss: 0.674798\n",
      "Reconstruction: 0.589152, Regularization: 0.020658, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:17,139 root         INFO     Train Epoch: 189 [5120/8000 (64%)]\tTotal Loss: 0.731734\n",
      "Reconstruction: 0.639541, Regularization: 0.027192, Discriminator: 0.043330; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:17,237 root         INFO     Train Epoch: 189 [5632/8000 (70%)]\tTotal Loss: 0.838281\n",
      "Reconstruction: 0.748451, Regularization: 0.024852, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:17,335 root         INFO     Train Epoch: 189 [6144/8000 (77%)]\tTotal Loss: 0.924277\n",
      "Reconstruction: 0.826775, Regularization: 0.032513, Discriminator: 0.043326; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:17,432 root         INFO     Train Epoch: 189 [6656/8000 (83%)]\tTotal Loss: 0.517536\n",
      "Reconstruction: 0.436174, Regularization: 0.016387, Discriminator: 0.043316; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:17,530 root         INFO     Train Epoch: 189 [7168/8000 (90%)]\tTotal Loss: 0.885335\n",
      "Reconstruction: 0.793823, Regularization: 0.026522, Discriminator: 0.043321; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:17,627 root         INFO     Train Epoch: 189 [7680/8000 (96%)]\tTotal Loss: 0.757091\n",
      "Reconstruction: 0.666614, Regularization: 0.025498, Discriminator: 0.043305; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:17,700 root         INFO     ====> Epoch: 189 Average loss: 0.7204\n",
      "2019-04-09 22:50:17,727 root         INFO     Train Epoch: 190 [0/8000 (0%)]\tTotal Loss: 0.823052\n",
      "Reconstruction: 0.732091, Regularization: 0.025983, Discriminator: 0.043311; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:17,824 root         INFO     Train Epoch: 190 [512/8000 (6%)]\tTotal Loss: 0.808753\n",
      "Reconstruction: 0.714251, Regularization: 0.029502, Discriminator: 0.043325; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:17,922 root         INFO     Train Epoch: 190 [1024/8000 (13%)]\tTotal Loss: 0.660932\n",
      "Reconstruction: 0.578508, Regularization: 0.017444, Discriminator: 0.043319; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:18,018 root         INFO     Train Epoch: 190 [1536/8000 (19%)]\tTotal Loss: 0.821443\n",
      "Reconstruction: 0.722698, Regularization: 0.033731, Discriminator: 0.043352; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:18,116 root         INFO     Train Epoch: 190 [2048/8000 (26%)]\tTotal Loss: 0.603586\n",
      "Reconstruction: 0.525023, Regularization: 0.013585, Discriminator: 0.043334; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:18,213 root         INFO     Train Epoch: 190 [2560/8000 (32%)]\tTotal Loss: 0.835081\n",
      "Reconstruction: 0.750159, Regularization: 0.019917, Discriminator: 0.043336; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:18,310 root         INFO     Train Epoch: 190 [3072/8000 (38%)]\tTotal Loss: 0.671290\n",
      "Reconstruction: 0.582212, Regularization: 0.024129, Discriminator: 0.043297; Generator: 0.021652,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:18,407 root         INFO     Train Epoch: 190 [3584/8000 (45%)]\tTotal Loss: 0.604991\n",
      "Reconstruction: 0.521013, Regularization: 0.018998, Discriminator: 0.043310; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:18,505 root         INFO     Train Epoch: 190 [4096/8000 (51%)]\tTotal Loss: 0.773924\n",
      "Reconstruction: 0.689954, Regularization: 0.018942, Discriminator: 0.043365; Generator: 0.021663,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:50:18,602 root         INFO     Train Epoch: 190 [4608/8000 (58%)]\tTotal Loss: 0.568919\n",
      "Reconstruction: 0.486623, Regularization: 0.017368, Discriminator: 0.043279; Generator: 0.021649,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:18,698 root         INFO     Train Epoch: 190 [5120/8000 (64%)]\tTotal Loss: 0.972457\n",
      "Reconstruction: 0.878411, Regularization: 0.029053, Discriminator: 0.043332; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:18,794 root         INFO     Train Epoch: 190 [5632/8000 (70%)]\tTotal Loss: 0.726704\n",
      "Reconstruction: 0.637314, Regularization: 0.024447, Discriminator: 0.043291; Generator: 0.021651,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:18,890 root         INFO     Train Epoch: 190 [6144/8000 (77%)]\tTotal Loss: 0.767866\n",
      "Reconstruction: 0.678531, Regularization: 0.024360, Discriminator: 0.043316; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:18,986 root         INFO     Train Epoch: 190 [6656/8000 (83%)]\tTotal Loss: 0.685447\n",
      "Reconstruction: 0.599470, Regularization: 0.020990, Discriminator: 0.043330; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:19,082 root         INFO     Train Epoch: 190 [7168/8000 (90%)]\tTotal Loss: 0.610417\n",
      "Reconstruction: 0.525275, Regularization: 0.020165, Discriminator: 0.043321; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:19,178 root         INFO     Train Epoch: 190 [7680/8000 (96%)]\tTotal Loss: 0.730327\n",
      "Reconstruction: 0.640120, Regularization: 0.025223, Discriminator: 0.043326; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:19,251 root         INFO     ====> Epoch: 190 Average loss: 0.7157\n",
      "2019-04-09 22:50:19,277 root         INFO     Train Epoch: 191 [0/8000 (0%)]\tTotal Loss: 0.703833\n",
      "Reconstruction: 0.615902, Regularization: 0.022968, Discriminator: 0.043303; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:19,377 root         INFO     Train Epoch: 191 [512/8000 (6%)]\tTotal Loss: 0.693822\n",
      "Reconstruction: 0.603514, Regularization: 0.025342, Discriminator: 0.043312; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:19,477 root         INFO     Train Epoch: 191 [1024/8000 (13%)]\tTotal Loss: 0.684139\n",
      "Reconstruction: 0.595295, Regularization: 0.023882, Discriminator: 0.043293; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:19,576 root         INFO     Train Epoch: 191 [1536/8000 (19%)]\tTotal Loss: 0.845540\n",
      "Reconstruction: 0.760795, Regularization: 0.019762, Discriminator: 0.043325; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:19,676 root         INFO     Train Epoch: 191 [2048/8000 (26%)]\tTotal Loss: 0.815699\n",
      "Reconstruction: 0.716951, Regularization: 0.033736, Discriminator: 0.043351; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:19,775 root         INFO     Train Epoch: 191 [2560/8000 (32%)]\tTotal Loss: 0.891793\n",
      "Reconstruction: 0.795733, Regularization: 0.031087, Discriminator: 0.043300; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:19,875 root         INFO     Train Epoch: 191 [3072/8000 (38%)]\tTotal Loss: 0.538922\n",
      "Reconstruction: 0.458086, Regularization: 0.015867, Discriminator: 0.043313; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:19,974 root         INFO     Train Epoch: 191 [3584/8000 (45%)]\tTotal Loss: 0.752611\n",
      "Reconstruction: 0.661114, Regularization: 0.026478, Discriminator: 0.043352; Generator: 0.021666,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:50:20,072 root         INFO     Train Epoch: 191 [4096/8000 (51%)]\tTotal Loss: 0.603950\n",
      "Reconstruction: 0.528819, Regularization: 0.010211, Discriminator: 0.043276; Generator: 0.021644,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:20,170 root         INFO     Train Epoch: 191 [4608/8000 (58%)]\tTotal Loss: 0.692376\n",
      "Reconstruction: 0.605947, Regularization: 0.021498, Discriminator: 0.043271; Generator: 0.021660,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:20,268 root         INFO     Train Epoch: 191 [5120/8000 (64%)]\tTotal Loss: 0.807870\n",
      "Reconstruction: 0.717079, Regularization: 0.025822, Discriminator: 0.043309; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:20,366 root         INFO     Train Epoch: 191 [5632/8000 (70%)]\tTotal Loss: 0.835963\n",
      "Reconstruction: 0.745338, Regularization: 0.025653, Discriminator: 0.043318; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:20,464 root         INFO     Train Epoch: 191 [6144/8000 (77%)]\tTotal Loss: 0.901152\n",
      "Reconstruction: 0.805254, Regularization: 0.030898, Discriminator: 0.043335; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:20,562 root         INFO     Train Epoch: 191 [6656/8000 (83%)]\tTotal Loss: 0.781008\n",
      "Reconstruction: 0.694828, Regularization: 0.021192, Discriminator: 0.043323; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:20,660 root         INFO     Train Epoch: 191 [7168/8000 (90%)]\tTotal Loss: 0.615156\n",
      "Reconstruction: 0.531440, Regularization: 0.018720, Discriminator: 0.043338; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:20,758 root         INFO     Train Epoch: 191 [7680/8000 (96%)]\tTotal Loss: 0.760345\n",
      "Reconstruction: 0.665907, Regularization: 0.029438, Discriminator: 0.043338; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:20,831 root         INFO     ====> Epoch: 191 Average loss: 0.7162\n",
      "2019-04-09 22:50:20,858 root         INFO     Train Epoch: 192 [0/8000 (0%)]\tTotal Loss: 1.046132\n",
      "Reconstruction: 0.946579, Regularization: 0.034574, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:20,958 root         INFO     Train Epoch: 192 [512/8000 (6%)]\tTotal Loss: 0.512164\n",
      "Reconstruction: 0.431629, Regularization: 0.015548, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:21,058 root         INFO     Train Epoch: 192 [1024/8000 (13%)]\tTotal Loss: 0.786570\n",
      "Reconstruction: 0.693885, Regularization: 0.027701, Discriminator: 0.043327; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:21,157 root         INFO     Train Epoch: 192 [1536/8000 (19%)]\tTotal Loss: 0.763291\n",
      "Reconstruction: 0.678497, Regularization: 0.019811, Discriminator: 0.043318; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:21,256 root         INFO     Train Epoch: 192 [2048/8000 (26%)]\tTotal Loss: 0.800138\n",
      "Reconstruction: 0.711302, Regularization: 0.023856, Discriminator: 0.043317; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:21,355 root         INFO     Train Epoch: 192 [2560/8000 (32%)]\tTotal Loss: 0.672848\n",
      "Reconstruction: 0.591503, Regularization: 0.016358, Discriminator: 0.043326; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:21,455 root         INFO     Train Epoch: 192 [3072/8000 (38%)]\tTotal Loss: 0.770473\n",
      "Reconstruction: 0.680563, Regularization: 0.024940, Discriminator: 0.043312; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:21,552 root         INFO     Train Epoch: 192 [3584/8000 (45%)]\tTotal Loss: 0.610037\n",
      "Reconstruction: 0.527211, Regularization: 0.017848, Discriminator: 0.043319; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:21,651 root         INFO     Train Epoch: 192 [4096/8000 (51%)]\tTotal Loss: 0.834399\n",
      "Reconstruction: 0.748500, Regularization: 0.020923, Discriminator: 0.043315; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:21,749 root         INFO     Train Epoch: 192 [4608/8000 (58%)]\tTotal Loss: 0.748279\n",
      "Reconstruction: 0.656017, Regularization: 0.027309, Discriminator: 0.043288; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:21,847 root         INFO     Train Epoch: 192 [5120/8000 (64%)]\tTotal Loss: 0.793199\n",
      "Reconstruction: 0.701084, Regularization: 0.027137, Discriminator: 0.043317; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:21,945 root         INFO     Train Epoch: 192 [5632/8000 (70%)]\tTotal Loss: 0.895538\n",
      "Reconstruction: 0.800182, Regularization: 0.030355, Discriminator: 0.043336; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:22,043 root         INFO     Train Epoch: 192 [6144/8000 (77%)]\tTotal Loss: 0.942103\n",
      "Reconstruction: 0.852256, Regularization: 0.024903, Discriminator: 0.043280; Generator: 0.021664,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:22,141 root         INFO     Train Epoch: 192 [6656/8000 (83%)]\tTotal Loss: 0.678847\n",
      "Reconstruction: 0.593178, Regularization: 0.020612, Discriminator: 0.043392; Generator: 0.021665,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:50:22,239 root         INFO     Train Epoch: 192 [7168/8000 (90%)]\tTotal Loss: 0.963788\n",
      "Reconstruction: 0.870397, Regularization: 0.028372, Discriminator: 0.043357; Generator: 0.021661,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:50:22,337 root         INFO     Train Epoch: 192 [7680/8000 (96%)]\tTotal Loss: 1.017228\n",
      "Reconstruction: 0.916872, Regularization: 0.035393, Discriminator: 0.043306; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:22,410 root         INFO     ====> Epoch: 192 Average loss: 0.7190\n",
      "2019-04-09 22:50:22,437 root         INFO     Train Epoch: 193 [0/8000 (0%)]\tTotal Loss: 0.519555\n",
      "Reconstruction: 0.439819, Regularization: 0.014794, Discriminator: 0.043293; Generator: 0.021650,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:22,536 root         INFO     Train Epoch: 193 [512/8000 (6%)]\tTotal Loss: 0.553690\n",
      "Reconstruction: 0.474642, Regularization: 0.014063, Discriminator: 0.043331; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:22,636 root         INFO     Train Epoch: 193 [1024/8000 (13%)]\tTotal Loss: 0.659310\n",
      "Reconstruction: 0.576866, Regularization: 0.017479, Discriminator: 0.043309; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:22,735 root         INFO     Train Epoch: 193 [1536/8000 (19%)]\tTotal Loss: 0.659488\n",
      "Reconstruction: 0.575909, Regularization: 0.018563, Discriminator: 0.043356; Generator: 0.021660,\n",
      "D(x): 0.499, D(G(z)): 0.500\n",
      "2019-04-09 22:50:22,833 root         INFO     Train Epoch: 193 [2048/8000 (26%)]\tTotal Loss: 0.596863\n",
      "Reconstruction: 0.513856, Regularization: 0.018032, Discriminator: 0.043324; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:22,932 root         INFO     Train Epoch: 193 [2560/8000 (32%)]\tTotal Loss: 0.563919\n",
      "Reconstruction: 0.479382, Regularization: 0.019561, Discriminator: 0.043319; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:23,030 root         INFO     Train Epoch: 193 [3072/8000 (38%)]\tTotal Loss: 0.844459\n",
      "Reconstruction: 0.746761, Regularization: 0.032713, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:23,129 root         INFO     Train Epoch: 193 [3584/8000 (45%)]\tTotal Loss: 0.769916\n",
      "Reconstruction: 0.678354, Regularization: 0.026580, Discriminator: 0.043320; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:23,227 root         INFO     Train Epoch: 193 [4096/8000 (51%)]\tTotal Loss: 0.694570\n",
      "Reconstruction: 0.605337, Regularization: 0.024255, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:23,326 root         INFO     Train Epoch: 193 [4608/8000 (58%)]\tTotal Loss: 0.940745\n",
      "Reconstruction: 0.845830, Regularization: 0.029930, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:23,425 root         INFO     Train Epoch: 193 [5120/8000 (64%)]\tTotal Loss: 0.514422\n",
      "Reconstruction: 0.432131, Regularization: 0.017321, Discriminator: 0.043314; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:23,523 root         INFO     Train Epoch: 193 [5632/8000 (70%)]\tTotal Loss: 0.763518\n",
      "Reconstruction: 0.676365, Regularization: 0.022180, Discriminator: 0.043309; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:23,622 root         INFO     Train Epoch: 193 [6144/8000 (77%)]\tTotal Loss: 1.022575\n",
      "Reconstruction: 0.933172, Regularization: 0.024460, Discriminator: 0.043284; Generator: 0.021659,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:23,720 root         INFO     Train Epoch: 193 [6656/8000 (83%)]\tTotal Loss: 0.504818\n",
      "Reconstruction: 0.418853, Regularization: 0.020996, Discriminator: 0.043310; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:23,818 root         INFO     Train Epoch: 193 [7168/8000 (90%)]\tTotal Loss: 0.733596\n",
      "Reconstruction: 0.647328, Regularization: 0.021310, Discriminator: 0.043300; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:23,917 root         INFO     Train Epoch: 193 [7680/8000 (96%)]\tTotal Loss: 0.929973\n",
      "Reconstruction: 0.838587, Regularization: 0.026407, Discriminator: 0.043325; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:23,990 root         INFO     ====> Epoch: 193 Average loss: 0.7128\n",
      "2019-04-09 22:50:24,016 root         INFO     Train Epoch: 194 [0/8000 (0%)]\tTotal Loss: 0.780309\n",
      "Reconstruction: 0.687610, Regularization: 0.027729, Discriminator: 0.043310; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:24,115 root         INFO     Train Epoch: 194 [512/8000 (6%)]\tTotal Loss: 1.015363\n",
      "Reconstruction: 0.917395, Regularization: 0.033004, Discriminator: 0.043305; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:24,212 root         INFO     Train Epoch: 194 [1024/8000 (13%)]\tTotal Loss: 0.656829\n",
      "Reconstruction: 0.571477, Regularization: 0.020376, Discriminator: 0.043315; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:24,310 root         INFO     Train Epoch: 194 [1536/8000 (19%)]\tTotal Loss: 0.650073\n",
      "Reconstruction: 0.562018, Regularization: 0.023054, Discriminator: 0.043343; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:24,407 root         INFO     Train Epoch: 194 [2048/8000 (26%)]\tTotal Loss: 1.037684\n",
      "Reconstruction: 0.940028, Regularization: 0.032681, Discriminator: 0.043316; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:24,504 root         INFO     Train Epoch: 194 [2560/8000 (32%)]\tTotal Loss: 0.787518\n",
      "Reconstruction: 0.694407, Regularization: 0.028114, Discriminator: 0.043336; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:24,601 root         INFO     Train Epoch: 194 [3072/8000 (38%)]\tTotal Loss: 0.650289\n",
      "Reconstruction: 0.563377, Regularization: 0.021915, Discriminator: 0.043333; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:24,694 root         INFO     Train Epoch: 194 [3584/8000 (45%)]\tTotal Loss: 0.467260\n",
      "Reconstruction: 0.392123, Regularization: 0.010158, Discriminator: 0.043320; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:24,788 root         INFO     Train Epoch: 194 [4096/8000 (51%)]\tTotal Loss: 0.468908\n",
      "Reconstruction: 0.390865, Regularization: 0.013047, Discriminator: 0.043334; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:24,882 root         INFO     Train Epoch: 194 [4608/8000 (58%)]\tTotal Loss: 0.579950\n",
      "Reconstruction: 0.492353, Regularization: 0.022599, Discriminator: 0.043337; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:24,976 root         INFO     Train Epoch: 194 [5120/8000 (64%)]\tTotal Loss: 0.354418\n",
      "Reconstruction: 0.280432, Regularization: 0.009002, Discriminator: 0.043325; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:25,069 root         INFO     Train Epoch: 194 [5632/8000 (70%)]\tTotal Loss: 0.717474\n",
      "Reconstruction: 0.632213, Regularization: 0.020282, Discriminator: 0.043321; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:25,166 root         INFO     Train Epoch: 194 [6144/8000 (77%)]\tTotal Loss: 0.587327\n",
      "Reconstruction: 0.505438, Regularization: 0.016901, Discriminator: 0.043327; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:25,263 root         INFO     Train Epoch: 194 [6656/8000 (83%)]\tTotal Loss: 0.490225\n",
      "Reconstruction: 0.409955, Regularization: 0.015282, Discriminator: 0.043323; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:25,360 root         INFO     Train Epoch: 194 [7168/8000 (90%)]\tTotal Loss: 0.544021\n",
      "Reconstruction: 0.459369, Regularization: 0.019676, Discriminator: 0.043317; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:25,457 root         INFO     Train Epoch: 194 [7680/8000 (96%)]\tTotal Loss: 0.482042\n",
      "Reconstruction: 0.403744, Regularization: 0.013309, Discriminator: 0.043328; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:25,530 root         INFO     ====> Epoch: 194 Average loss: 0.7174\n",
      "2019-04-09 22:50:25,557 root         INFO     Train Epoch: 195 [0/8000 (0%)]\tTotal Loss: 0.590597\n",
      "Reconstruction: 0.515917, Regularization: 0.009685, Discriminator: 0.043331; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:25,658 root         INFO     Train Epoch: 195 [512/8000 (6%)]\tTotal Loss: 0.408937\n",
      "Reconstruction: 0.333920, Regularization: 0.010032, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:25,758 root         INFO     Train Epoch: 195 [1024/8000 (13%)]\tTotal Loss: 0.740038\n",
      "Reconstruction: 0.648068, Regularization: 0.026988, Discriminator: 0.043318; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:25,858 root         INFO     Train Epoch: 195 [1536/8000 (19%)]\tTotal Loss: 0.899320\n",
      "Reconstruction: 0.809313, Regularization: 0.025022, Discriminator: 0.043322; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:25,953 root         INFO     Train Epoch: 195 [2048/8000 (26%)]\tTotal Loss: 0.767772\n",
      "Reconstruction: 0.672261, Regularization: 0.030523, Discriminator: 0.043320; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:26,049 root         INFO     Train Epoch: 195 [2560/8000 (32%)]\tTotal Loss: 0.577249\n",
      "Reconstruction: 0.494661, Regularization: 0.017613, Discriminator: 0.043310; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:26,145 root         INFO     Train Epoch: 195 [3072/8000 (38%)]\tTotal Loss: 0.714785\n",
      "Reconstruction: 0.628578, Regularization: 0.021232, Discriminator: 0.043310; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:26,240 root         INFO     Train Epoch: 195 [3584/8000 (45%)]\tTotal Loss: 0.963076\n",
      "Reconstruction: 0.867344, Regularization: 0.030761, Discriminator: 0.043309; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:26,336 root         INFO     Train Epoch: 195 [4096/8000 (51%)]\tTotal Loss: 0.824236\n",
      "Reconstruction: 0.728726, Regularization: 0.030553, Discriminator: 0.043304; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:26,431 root         INFO     Train Epoch: 195 [4608/8000 (58%)]\tTotal Loss: 0.787187\n",
      "Reconstruction: 0.694419, Regularization: 0.027778, Discriminator: 0.043327; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:26,528 root         INFO     Train Epoch: 195 [5120/8000 (64%)]\tTotal Loss: 0.722075\n",
      "Reconstruction: 0.636022, Regularization: 0.021056, Discriminator: 0.043329; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:26,623 root         INFO     Train Epoch: 195 [5632/8000 (70%)]\tTotal Loss: 0.847075\n",
      "Reconstruction: 0.751308, Regularization: 0.030828, Discriminator: 0.043281; Generator: 0.021658,\n",
      "D(x): 0.501, D(G(z)): 0.500\n",
      "2019-04-09 22:50:26,719 root         INFO     Train Epoch: 195 [6144/8000 (77%)]\tTotal Loss: 0.539094\n",
      "Reconstruction: 0.457424, Regularization: 0.016676, Discriminator: 0.043337; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:26,815 root         INFO     Train Epoch: 195 [6656/8000 (83%)]\tTotal Loss: 0.641953\n",
      "Reconstruction: 0.560992, Regularization: 0.015973, Discriminator: 0.043332; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:26,911 root         INFO     Train Epoch: 195 [7168/8000 (90%)]\tTotal Loss: 0.730500\n",
      "Reconstruction: 0.645483, Regularization: 0.020051, Discriminator: 0.043309; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:27,006 root         INFO     Train Epoch: 195 [7680/8000 (96%)]\tTotal Loss: 0.666518\n",
      "Reconstruction: 0.580663, Regularization: 0.020875, Discriminator: 0.043330; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:27,078 root         INFO     ====> Epoch: 195 Average loss: 0.7178\n",
      "2019-04-09 22:50:27,105 root         INFO     Train Epoch: 196 [0/8000 (0%)]\tTotal Loss: 0.763054\n",
      "Reconstruction: 0.673263, Regularization: 0.024819, Discriminator: 0.043316; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:27,206 root         INFO     Train Epoch: 196 [512/8000 (6%)]\tTotal Loss: 0.532956\n",
      "Reconstruction: 0.453740, Regularization: 0.014223, Discriminator: 0.043339; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:27,306 root         INFO     Train Epoch: 196 [1024/8000 (13%)]\tTotal Loss: 0.692363\n",
      "Reconstruction: 0.603700, Regularization: 0.023670, Discriminator: 0.043339; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:27,406 root         INFO     Train Epoch: 196 [1536/8000 (19%)]\tTotal Loss: 0.598328\n",
      "Reconstruction: 0.515884, Regularization: 0.017462, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:27,506 root         INFO     Train Epoch: 196 [2048/8000 (26%)]\tTotal Loss: 0.807130\n",
      "Reconstruction: 0.716550, Regularization: 0.025594, Discriminator: 0.043328; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:27,606 root         INFO     Train Epoch: 196 [2560/8000 (32%)]\tTotal Loss: 0.577670\n",
      "Reconstruction: 0.493360, Regularization: 0.019337, Discriminator: 0.043316; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:27,706 root         INFO     Train Epoch: 196 [3072/8000 (38%)]\tTotal Loss: 0.605104\n",
      "Reconstruction: 0.526090, Regularization: 0.014021, Discriminator: 0.043336; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:27,806 root         INFO     Train Epoch: 196 [3584/8000 (45%)]\tTotal Loss: 0.715074\n",
      "Reconstruction: 0.627427, Regularization: 0.022669, Discriminator: 0.043317; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:27,905 root         INFO     Train Epoch: 196 [4096/8000 (51%)]\tTotal Loss: 0.578346\n",
      "Reconstruction: 0.498117, Regularization: 0.015248, Discriminator: 0.043321; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:28,004 root         INFO     Train Epoch: 196 [4608/8000 (58%)]\tTotal Loss: 0.666705\n",
      "Reconstruction: 0.577354, Regularization: 0.024358, Discriminator: 0.043334; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:28,102 root         INFO     Train Epoch: 196 [5120/8000 (64%)]\tTotal Loss: 0.663966\n",
      "Reconstruction: 0.573132, Regularization: 0.025865, Discriminator: 0.043308; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:28,201 root         INFO     Train Epoch: 196 [5632/8000 (70%)]\tTotal Loss: 0.795307\n",
      "Reconstruction: 0.707267, Regularization: 0.023063, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:28,299 root         INFO     Train Epoch: 196 [6144/8000 (77%)]\tTotal Loss: 0.660224\n",
      "Reconstruction: 0.579612, Regularization: 0.015606, Discriminator: 0.043349; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:28,397 root         INFO     Train Epoch: 196 [6656/8000 (83%)]\tTotal Loss: 0.936662\n",
      "Reconstruction: 0.845850, Regularization: 0.025825, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:28,496 root         INFO     Train Epoch: 196 [7168/8000 (90%)]\tTotal Loss: 0.895467\n",
      "Reconstruction: 0.799425, Regularization: 0.031048, Discriminator: 0.043328; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:28,594 root         INFO     Train Epoch: 196 [7680/8000 (96%)]\tTotal Loss: 0.485739\n",
      "Reconstruction: 0.407011, Regularization: 0.013744, Discriminator: 0.043322; Generator: 0.021663,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:28,668 root         INFO     ====> Epoch: 196 Average loss: 0.7157\n",
      "2019-04-09 22:50:28,695 root         INFO     Train Epoch: 197 [0/8000 (0%)]\tTotal Loss: 0.718212\n",
      "Reconstruction: 0.631796, Regularization: 0.021445, Discriminator: 0.043306; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:28,796 root         INFO     Train Epoch: 197 [512/8000 (6%)]\tTotal Loss: 0.791725\n",
      "Reconstruction: 0.703639, Regularization: 0.023118, Discriminator: 0.043306; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:28,895 root         INFO     Train Epoch: 197 [1024/8000 (13%)]\tTotal Loss: 0.720504\n",
      "Reconstruction: 0.634679, Regularization: 0.020832, Discriminator: 0.043332; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:28,994 root         INFO     Train Epoch: 197 [1536/8000 (19%)]\tTotal Loss: 0.812765\n",
      "Reconstruction: 0.723707, Regularization: 0.024064, Discriminator: 0.043329; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:29,093 root         INFO     Train Epoch: 197 [2048/8000 (26%)]\tTotal Loss: 0.899407\n",
      "Reconstruction: 0.796848, Regularization: 0.037569, Discriminator: 0.043332; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:29,192 root         INFO     Train Epoch: 197 [2560/8000 (32%)]\tTotal Loss: 0.822112\n",
      "Reconstruction: 0.736054, Regularization: 0.021070, Discriminator: 0.043326; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:29,291 root         INFO     Train Epoch: 197 [3072/8000 (38%)]\tTotal Loss: 0.830417\n",
      "Reconstruction: 0.734052, Regularization: 0.031378, Discriminator: 0.043324; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:29,390 root         INFO     Train Epoch: 197 [3584/8000 (45%)]\tTotal Loss: 0.872126\n",
      "Reconstruction: 0.777079, Regularization: 0.030063, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:29,489 root         INFO     Train Epoch: 197 [4096/8000 (51%)]\tTotal Loss: 0.639298\n",
      "Reconstruction: 0.554205, Regularization: 0.020113, Discriminator: 0.043318; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:29,589 root         INFO     Train Epoch: 197 [4608/8000 (58%)]\tTotal Loss: 0.825290\n",
      "Reconstruction: 0.734589, Regularization: 0.025717, Discriminator: 0.043322; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:29,688 root         INFO     Train Epoch: 197 [5120/8000 (64%)]\tTotal Loss: 0.492648\n",
      "Reconstruction: 0.412796, Regularization: 0.014865, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:29,785 root         INFO     Train Epoch: 197 [5632/8000 (70%)]\tTotal Loss: 0.761390\n",
      "Reconstruction: 0.671493, Regularization: 0.024920, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:29,882 root         INFO     Train Epoch: 197 [6144/8000 (77%)]\tTotal Loss: 0.474070\n",
      "Reconstruction: 0.394140, Regularization: 0.014947, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:29,979 root         INFO     Train Epoch: 197 [6656/8000 (83%)]\tTotal Loss: 0.557898\n",
      "Reconstruction: 0.477008, Regularization: 0.015914, Discriminator: 0.043320; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:30,076 root         INFO     Train Epoch: 197 [7168/8000 (90%)]\tTotal Loss: 0.665174\n",
      "Reconstruction: 0.581727, Regularization: 0.018459, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:30,173 root         INFO     Train Epoch: 197 [7680/8000 (96%)]\tTotal Loss: 0.825040\n",
      "Reconstruction: 0.735613, Regularization: 0.024442, Discriminator: 0.043323; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:30,246 root         INFO     ====> Epoch: 197 Average loss: 0.7181\n",
      "2019-04-09 22:50:30,272 root         INFO     Train Epoch: 198 [0/8000 (0%)]\tTotal Loss: 0.499045\n",
      "Reconstruction: 0.418221, Regularization: 0.015848, Discriminator: 0.043319; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:30,371 root         INFO     Train Epoch: 198 [512/8000 (6%)]\tTotal Loss: 0.634146\n",
      "Reconstruction: 0.549617, Regularization: 0.019547, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:30,470 root         INFO     Train Epoch: 198 [1024/8000 (13%)]\tTotal Loss: 0.710548\n",
      "Reconstruction: 0.620034, Regularization: 0.025532, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:30,568 root         INFO     Train Epoch: 198 [1536/8000 (19%)]\tTotal Loss: 0.601107\n",
      "Reconstruction: 0.519195, Regularization: 0.016921, Discriminator: 0.043329; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:30,666 root         INFO     Train Epoch: 198 [2048/8000 (26%)]\tTotal Loss: 0.630657\n",
      "Reconstruction: 0.547052, Regularization: 0.018616, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:30,764 root         INFO     Train Epoch: 198 [2560/8000 (32%)]\tTotal Loss: 0.670509\n",
      "Reconstruction: 0.581621, Regularization: 0.023895, Discriminator: 0.043325; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:30,863 root         INFO     Train Epoch: 198 [3072/8000 (38%)]\tTotal Loss: 0.588749\n",
      "Reconstruction: 0.504809, Regularization: 0.018954, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:30,960 root         INFO     Train Epoch: 198 [3584/8000 (45%)]\tTotal Loss: 0.700613\n",
      "Reconstruction: 0.617529, Regularization: 0.018099, Discriminator: 0.043328; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:31,059 root         INFO     Train Epoch: 198 [4096/8000 (51%)]\tTotal Loss: 0.648036\n",
      "Reconstruction: 0.560144, Regularization: 0.022913, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:31,157 root         INFO     Train Epoch: 198 [4608/8000 (58%)]\tTotal Loss: 0.759160\n",
      "Reconstruction: 0.673946, Regularization: 0.020239, Discriminator: 0.043317; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:31,255 root         INFO     Train Epoch: 198 [5120/8000 (64%)]\tTotal Loss: 0.893999\n",
      "Reconstruction: 0.799807, Regularization: 0.029203, Discriminator: 0.043324; Generator: 0.021665,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:31,353 root         INFO     Train Epoch: 198 [5632/8000 (70%)]\tTotal Loss: 0.490203\n",
      "Reconstruction: 0.408320, Regularization: 0.016898, Discriminator: 0.043324; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:31,451 root         INFO     Train Epoch: 198 [6144/8000 (77%)]\tTotal Loss: 1.045685\n",
      "Reconstruction: 0.938725, Regularization: 0.041959, Discriminator: 0.043343; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:31,549 root         INFO     Train Epoch: 198 [6656/8000 (83%)]\tTotal Loss: 0.577361\n",
      "Reconstruction: 0.494397, Regularization: 0.017981, Discriminator: 0.043321; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:31,647 root         INFO     Train Epoch: 198 [7168/8000 (90%)]\tTotal Loss: 0.696785\n",
      "Reconstruction: 0.606017, Regularization: 0.025777, Discriminator: 0.043334; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:31,746 root         INFO     Train Epoch: 198 [7680/8000 (96%)]\tTotal Loss: 0.675635\n",
      "Reconstruction: 0.587212, Regularization: 0.023437, Discriminator: 0.043325; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:31,819 root         INFO     ====> Epoch: 198 Average loss: 0.7166\n",
      "2019-04-09 22:50:31,846 root         INFO     Train Epoch: 199 [0/8000 (0%)]\tTotal Loss: 0.828056\n",
      "Reconstruction: 0.734386, Regularization: 0.028683, Discriminator: 0.043327; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:31,946 root         INFO     Train Epoch: 199 [512/8000 (6%)]\tTotal Loss: 0.752953\n",
      "Reconstruction: 0.666570, Regularization: 0.021400, Discriminator: 0.043321; Generator: 0.021662,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:32,046 root         INFO     Train Epoch: 199 [1024/8000 (13%)]\tTotal Loss: 0.875473\n",
      "Reconstruction: 0.786086, Regularization: 0.024411, Discriminator: 0.043320; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:32,145 root         INFO     Train Epoch: 199 [1536/8000 (19%)]\tTotal Loss: 0.803446\n",
      "Reconstruction: 0.716424, Regularization: 0.022049, Discriminator: 0.043319; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:32,245 root         INFO     Train Epoch: 199 [2048/8000 (26%)]\tTotal Loss: 1.093417\n",
      "Reconstruction: 0.990944, Regularization: 0.037486, Discriminator: 0.043328; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:32,344 root         INFO     Train Epoch: 199 [2560/8000 (32%)]\tTotal Loss: 0.503272\n",
      "Reconstruction: 0.425791, Regularization: 0.012501, Discriminator: 0.043312; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:32,443 root         INFO     Train Epoch: 199 [3072/8000 (38%)]\tTotal Loss: 0.854084\n",
      "Reconstruction: 0.758127, Regularization: 0.030986, Discriminator: 0.043317; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:32,543 root         INFO     Train Epoch: 199 [3584/8000 (45%)]\tTotal Loss: 0.990868\n",
      "Reconstruction: 0.888316, Regularization: 0.037570, Discriminator: 0.043323; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:32,642 root         INFO     Train Epoch: 199 [4096/8000 (51%)]\tTotal Loss: 0.841606\n",
      "Reconstruction: 0.750792, Regularization: 0.025834, Discriminator: 0.043321; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:32,742 root         INFO     Train Epoch: 199 [4608/8000 (58%)]\tTotal Loss: 0.728371\n",
      "Reconstruction: 0.639117, Regularization: 0.024270, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:32,842 root         INFO     Train Epoch: 199 [5120/8000 (64%)]\tTotal Loss: 0.583289\n",
      "Reconstruction: 0.499676, Regularization: 0.018635, Discriminator: 0.043319; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:32,941 root         INFO     Train Epoch: 199 [5632/8000 (70%)]\tTotal Loss: 0.668016\n",
      "Reconstruction: 0.580111, Regularization: 0.022916, Discriminator: 0.043324; Generator: 0.021664,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:33,041 root         INFO     Train Epoch: 199 [6144/8000 (77%)]\tTotal Loss: 0.700466\n",
      "Reconstruction: 0.611156, Regularization: 0.024322, Discriminator: 0.043331; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:33,140 root         INFO     Train Epoch: 199 [6656/8000 (83%)]\tTotal Loss: 0.566509\n",
      "Reconstruction: 0.483440, Regularization: 0.018090, Discriminator: 0.043320; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:33,239 root         INFO     Train Epoch: 199 [7168/8000 (90%)]\tTotal Loss: 1.099481\n",
      "Reconstruction: 1.001912, Regularization: 0.032584, Discriminator: 0.043325; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:33,339 root         INFO     Train Epoch: 199 [7680/8000 (96%)]\tTotal Loss: 0.750316\n",
      "Reconstruction: 0.662786, Regularization: 0.022547, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-09 22:50:33,413 root         INFO     ====> Epoch: 199 Average loss: 0.7156\n",
      "2019-04-09 22:50:33,428 luigi-interface INFO     [pid 8911] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=8911) done      TrainVEM()\n",
      "2019-04-09 22:50:33,428 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 22:50:33,429 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   DONE\n",
      "2019-04-09 22:50:33,429 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 22:50:33,429 luigi-interface DEBUG    Pending tasks: 1\n",
      "2019-04-09 22:50:33,429 luigi-interface INFO     [pid 8911] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=8911) running   RunAll()\n",
      "2019-04-09 22:50:33,430 luigi-interface INFO     [pid 8911] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=8911) done      RunAll()\n",
      "2019-04-09 22:50:33,430 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 22:50:33,430 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   DONE\n",
      "2019-04-09 22:50:33,431 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 22:50:33,431 luigi-interface DEBUG    Done\n",
      "2019-04-09 22:50:33,431 luigi-interface DEBUG    There are no more tasks to run at this time\n",
      "2019-04-09 22:50:33,431 luigi-interface INFO     Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=8911) was stopped. Shutting down Keep-Alive thread\n",
      "2019-04-09 22:50:33,432 luigi-interface INFO     \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 4 tasks of which:\n",
      "* 2 complete ones were encountered:\n",
      "    - 1 MakeDataSet()\n",
      "    - 1 TrainVAE()\n",
      "* 2 ran successfully:\n",
      "    - 1 RunAll()\n",
      "    - 1 TrainVEM()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "\n",
      "\n",
      "-- Log file: logs2019-04-09 22:40:25.767620.txt\n",
      "\n",
      "2019-04-09 22:40:25,767 root         INFO     start\n",
      "2019-04-09 22:40:25,782 luigi        INFO     logging configured by default settings\n",
      "2019-04-09 22:40:25,807 luigi-interface DEBUG    Checking if RunAll() is complete\n",
      "2019-04-09 22:40:25,808 luigi-interface DEBUG    Checking if TrainVAE() is complete\n",
      "2019-04-09 22:40:25,808 luigi-interface DEBUG    Checking if TrainVEM() is complete\n",
      "2019-04-09 22:40:25,809 luigi-interface INFO     Informed scheduler that task   RunAll__99914b932b   has status   PENDING\n",
      "2019-04-09 22:40:25,809 luigi-interface INFO     Informed scheduler that task   TrainVEM__99914b932b   has status   DONE\n",
      "2019-04-09 22:40:25,809 luigi-interface DEBUG    Checking if MakeDataSet() is complete\n",
      "2019-04-09 22:40:25,810 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   PENDING\n",
      "2019-04-09 22:40:25,810 luigi-interface INFO     Informed scheduler that task   MakeDataSet__99914b932b   has status   DONE\n",
      "2019-04-09 22:40:25,810 luigi-interface INFO     Done scheduling tasks\n",
      "2019-04-09 22:40:25,810 luigi-interface INFO     Running Worker with 1 processes\n",
      "2019-04-09 22:40:25,810 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 22:40:25,810 luigi-interface DEBUG    Pending tasks: 2\n",
      "2019-04-09 22:40:25,811 luigi-interface INFO     [pid 7159] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=7159) running   TrainVAE()\n",
      "2019-04-09 22:40:25,825 root         INFO     --Dataset tensor: (10000, 2)\n",
      "2019-04-09 22:40:25,826 root         INFO     -- Train tensor: (8000, 2)\n",
      "2019-04-09 22:40:29,613 root         INFO     Values of VAE's decoder parameters before training:\n",
      "2019-04-09 22:40:29,613 root         INFO     layers.0.weight\n",
      "2019-04-09 22:40:29,614 root         INFO     tensor([[-0.2651],\n",
      "        [ 0.1353]], device='cuda:0')\n",
      "2019-04-09 22:40:29,633 root         INFO     layers.0.bias\n",
      "2019-04-09 22:40:29,633 root         INFO     tensor([-0.3248, -0.5761], device='cuda:0')\n",
      "2019-04-09 22:40:29,634 root         INFO     layers.1.weight\n",
      "2019-04-09 22:40:29,634 root         INFO     tensor([[-0.0574,  0.4460],\n",
      "        [ 0.5879, -0.3491]], device='cuda:0')\n",
      "2019-04-09 22:40:29,635 root         INFO     layers.1.bias\n",
      "2019-04-09 22:40:29,636 root         INFO     tensor([-0.4054, -0.0326], device='cuda:0')\n",
      "2019-04-09 22:40:29,636 root         INFO     layers.2.weight\n",
      "2019-04-09 22:40:29,636 root         INFO     tensor([[ 0.3113,  0.3165],\n",
      "        [-0.2632,  0.2449]], device='cuda:0')\n",
      "2019-04-09 22:40:29,638 root         INFO     layers.2.bias\n",
      "2019-04-09 22:40:29,638 root         INFO     tensor([-0.1202, -0.0849], device='cuda:0')\n",
      "2019-04-09 22:40:29,703 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 60456.519531\n",
      "Reconstruction: 60456.050781, Regularization: 0.467440\n",
      "2019-04-09 22:40:29,752 luigi-interface ERROR    [pid 7159] Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=7159) failed    TrainVAE()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/luigi/worker.py\", line 199, in run\n",
      "    new_deps = self._run_get_new_deps()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/luigi/worker.py\", line 139, in _run_get_new_deps\n",
      "    task_gen = self.task.run()\n",
      "  File \"toypipeline.py\", line 306, in run\n",
      "    epoch, train_loader, modules, optimizers)\n",
      "  File \"toypipeline.py\", line 197, in train_vae\n",
      "    batch_data, batch_recon, batch_logvarx)\n",
      "  File \"/home/nina/code/vaetree/toylosses.py\", line 39, in reconstruction_loss\n",
      "    raise ValueError('aux has a inf')\n",
      "ValueError: aux has a inf\n",
      "2019-04-09 22:40:29,754 luigi-interface DEBUG    1 running tasks, waiting for next task to finish\n",
      "2019-04-09 22:40:29,756 luigi-interface INFO     Informed scheduler that task   TrainVAE__99914b932b   has status   FAILED\n",
      "2019-04-09 22:40:29,756 luigi-interface DEBUG    Asking scheduler for work...\n",
      "2019-04-09 22:40:29,756 luigi-interface DEBUG    Done\n",
      "2019-04-09 22:40:29,756 luigi-interface DEBUG    There are no more tasks to run at this time\n",
      "2019-04-09 22:40:29,756 luigi-interface DEBUG    There are 2 pending tasks possibly being run by other workers\n",
      "2019-04-09 22:40:29,756 luigi-interface DEBUG    There are 2 pending tasks unique to this worker\n",
      "2019-04-09 22:40:29,756 luigi-interface DEBUG    There are 2 pending tasks last scheduled by this worker\n",
      "2019-04-09 22:40:29,756 luigi-interface INFO     Worker Worker(salt=447342177, workers=1, host=gne, username=nina, pid=7159) was stopped. Shutting down Keep-Alive thread\n",
      "2019-04-09 22:40:29,758 luigi-interface INFO     \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 4 tasks of which:\n",
      "* 2 complete ones were encountered:\n",
      "    - 1 MakeDataSet()\n",
      "    - 1 TrainVEM()\n",
      "* 1 failed:\n",
      "    - 1 TrainVAE()\n",
      "* 1 were left pending, among these:\n",
      "    * 1 had failed dependencies:\n",
      "        - 1 RunAll()\n",
      "\n",
      "This progress looks :( because there were failed tasks\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pattern = 'logs'\n",
    "logs = []\n",
    "for filename in os.listdir(OUTPUT):\n",
    "    if re.search(pattern, filename):\n",
    "        logs.append(filename)\n",
    "\n",
    "print('Found %d log files.' % len(logs))\n",
    "        \n",
    "for filename in logs:\n",
    "    path = os.path.join(OUTPUT, filename)\n",
    "    print('\\n-- Log file: %s\\n' % filename)\n",
    "    with open(path, 'r') as f:\n",
    "        message = f.read()\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
