{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GAN / Discriminator part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:09:54,683 root         INFO     start\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.nn import functional as F\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import importlib\n",
    "import toylosses\n",
    "importlib.reload(toylosses)\n",
    "import toynn\n",
    "importlib.reload(toynn)\n",
    "import toyvis\n",
    "importlib.reload(toyvis)\n",
    "\n",
    "sns.set()\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "logging.basicConfig(\n",
    "        format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\n",
    "        level=logging.INFO)\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logging.info('start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(epoch, train_loader, modules, optimizers):\n",
    "    for module in modules.values():\n",
    "        module.train()\n",
    " \n",
    "    total_loss_discriminator = 0\n",
    "    total_loss_generator = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    n_data = len(train_loader.dataset)\n",
    "    n_batches = len(train_loader)\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        if DEBUG and batch_idx > 3:\n",
    "            continue\n",
    "\n",
    "        batch_data = batch_data[0].to(DEVICE)\n",
    "        n_batch_data = len(batch_data)\n",
    "\n",
    "        for optimizer in optimizers.values():\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        decoder = modules['decoder']\n",
    "\n",
    "        z_from_prior = toynn.sample_from_prior(\n",
    "                    LATENT_DIM, n_samples=n_batch_data).to(DEVICE)\n",
    "        batch_from_prior, batch_logvarx_from_prior = decoder(\n",
    "                    z_from_prior)\n",
    "\n",
    "        discriminator = modules['discriminator']\n",
    "\n",
    "        real_labels = torch.full((n_batch_data, 1), 1, device=DEVICE)\n",
    "        fake_labels = torch.full((n_batch_data, 1), 0, device=DEVICE)\n",
    "        #noise_for_real_labels = np.random.normal(loc=0, scale=0.1, size=(n_batch_data, 1))\n",
    "        #noise_for_fake_labels = np.random.normal(loc=0, scale=0.1, size=(n_batch_data, 1))\n",
    "        #real_labels = real_labels - torch.Tensor(np.abs(noise_for_real_labels)).to(DEVICE)\n",
    "        #fake_labels = fake_labels + torch.Tensor(np.abs(noise_for_fake_labels)).to(DEVICE)\n",
    "        \n",
    "        #noise_for_data = np.random.normal(loc=0, scale=2, size=(n_batch_data, 1))\n",
    "        #noise_for_prior = np.random.normal(loc=0, scale=2, size=(n_batch_data, 1))\n",
    "        noisy_batch_data = batch_data #+ torch.Tensor(noise_for_data).to(DEVICE)\n",
    "        noisy_batch_from_prior = batch_from_prior #+ torch.Tensor(noise_for_prior).to(DEVICE)\n",
    "\n",
    "        labels_data = discriminator(noisy_batch_data)\n",
    "        labels_from_prior = discriminator(noisy_batch_from_prior)\n",
    "\n",
    "        \n",
    "        criterion = torch.nn.BCELoss()\n",
    "        \n",
    "        loss_dis_data = criterion(\n",
    "                        labels_data,\n",
    "                        real_labels)\n",
    "        loss_dis_from_prior = criterion(\n",
    "                        labels_from_prior,\n",
    "                        fake_labels)\n",
    "\n",
    "        loss_discriminator = (\n",
    "                    loss_dis_data + loss_dis_from_prior)\n",
    "\n",
    "        loss_discriminator.backward(retain_graph=True)\n",
    "        #logging.info('Discriminator gradients')\n",
    "        #for name, param in discriminator.named_parameters():\n",
    "            #logging.info(name)\n",
    "            #logging.info(param.grad)\n",
    "        \n",
    "        optimizers['discriminator'].step()\n",
    "\n",
    "        loss_generator = criterion(\n",
    "                    labels_from_prior,\n",
    "                    real_labels)\n",
    "        loss_generator.backward()\n",
    "        \n",
    "        #logging.info('Decoder gradients')\n",
    "        #for name, param in decoder.named_parameters():\n",
    "            #logging.info(name)\n",
    "            #logging.info(param.grad)\n",
    "\n",
    "        optimizers['decoder'].step()\n",
    "\n",
    "        loss = loss_discriminator + loss_generator\n",
    "\n",
    "        if batch_idx % PRINT_INTERVAL == 0:\n",
    "            batch_loss = loss / n_batch_data\n",
    "            batch_loss_discriminator = loss_discriminator / n_batch_data\n",
    "            batch_loss_generator = loss_generator / n_batch_data\n",
    "\n",
    "            dx = labels_data.mean()\n",
    "            dgz = labels_from_prior.mean()\n",
    "\n",
    "            string_base = (\n",
    "                    'Train Epoch: {} [{}/{} ({:.0f}%)]\\tTotal Loss: {:.6f}'\n",
    "                    ', Discriminator: {:.6f}; Generator: {:.6f},'\n",
    "                    '\\nD(x): {:.3f}, D(G(z)): {:.3f}')\n",
    "            logging.info(\n",
    "                    string_base.format(\n",
    "                        epoch, batch_idx * n_batch_data, n_data,\n",
    "                        100. * batch_idx / n_batches,\n",
    "                        batch_loss,\n",
    "                        batch_loss_discriminator,\n",
    "                        batch_loss_generator,\n",
    "                        dx, dgz))\n",
    "\n",
    "        total_loss_discriminator += loss_discriminator.item()\n",
    "        total_loss_generator += loss_generator.item()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / n_data\n",
    "\n",
    "    logging.info('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "                epoch, average_loss))\n",
    "    \n",
    "    train_losses = {}\n",
    "    train_losses['total'] = average_loss\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_true = 2\n",
    "color_true = 'green'\n",
    "\n",
    "def generate_synthetic_1d(w=w_true, n=10):\n",
    "    z = np.random.normal(loc=0, scale=1, size=(n, 1))\n",
    "    eps = np.random.normal(loc=0, scale=1, size=(n, 1))\n",
    "\n",
    "    x = w * z + eps\n",
    "    return x\n",
    "\n",
    "dataset = generate_synthetic_1d(w=w_true, n=10000)\n",
    "fig, ax = plt.subplots()\n",
    "ax = toyvis.plot_data(dataset, color=color_true, label='from decoder true', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "\n",
    "# Seed\n",
    "SEED = 12345\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DATA_DIM = 1\n",
    "LATENT_DIM = 1\n",
    "N_DECODER_LAYERS = 1\n",
    "NONLINEARITY = False\n",
    "N_SAMPLES = 10000\n",
    "WITH_BIASX = False\n",
    "WITH_LOGVARX = False\n",
    "WITH_BIASZ = False\n",
    "WITH_LOGVARZ = False\n",
    "\n",
    "FRAC_TEST = 0.2\n",
    "BATCH_SIZE = 32\n",
    "KWARGS = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n",
    "\n",
    "PRINT_INTERVAL = 16\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "N_EPOCHS = 50\n",
    "LR = 1e-3\n",
    "\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:09:55,598 root         INFO     --Dataset tensor: (10000, 1)\n",
      "2019-04-24 21:09:55,600 root         INFO     -- Train tensor: (8000, 1)\n",
      "2019-04-24 21:09:55,609 root         INFO     Values of VAE's decoder parameters before training:\n",
      "2019-04-24 21:09:55,610 root         INFO     layers.0.weight\n",
      "2019-04-24 21:09:55,611 root         INFO     tensor([[1.1000]], device='cuda:0')\n",
      "2019-04-24 21:09:55,670 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 0.059782, Discriminator: 0.046017; Generator: 0.013765,\n",
      "D(x): 0.644, D(G(z)): 0.644\n",
      "2019-04-24 21:09:55,762 root         INFO     Train Epoch: 0 [512/8000 (6%)]\tTotal Loss: 0.059810, Discriminator: 0.045906; Generator: 0.013904,\n",
      "D(x): 0.641, D(G(z)): 0.641\n",
      "2019-04-24 21:09:55,854 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 0.059841, Discriminator: 0.045802; Generator: 0.014039,\n",
      "D(x): 0.638, D(G(z)): 0.638\n",
      "2019-04-24 21:09:55,946 root         INFO     Train Epoch: 0 [1536/8000 (19%)]\tTotal Loss: 0.059874, Discriminator: 0.045702; Generator: 0.014172,\n",
      "D(x): 0.635, D(G(z)): 0.635\n",
      "2019-04-24 21:09:56,038 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 0.059908, Discriminator: 0.045606; Generator: 0.014302,\n",
      "D(x): 0.633, D(G(z)): 0.633\n",
      "2019-04-24 21:09:56,130 root         INFO     Train Epoch: 0 [2560/8000 (32%)]\tTotal Loss: 0.059945, Discriminator: 0.045515; Generator: 0.014430,\n",
      "D(x): 0.630, D(G(z)): 0.630\n",
      "2019-04-24 21:09:56,221 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 0.059983, Discriminator: 0.045428; Generator: 0.014555,\n",
      "D(x): 0.628, D(G(z)): 0.628\n",
      "2019-04-24 21:09:56,313 root         INFO     Train Epoch: 0 [3584/8000 (45%)]\tTotal Loss: 0.060023, Discriminator: 0.045345; Generator: 0.014677,\n",
      "D(x): 0.625, D(G(z)): 0.625\n",
      "2019-04-24 21:09:56,405 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 0.060064, Discriminator: 0.045266; Generator: 0.014798,\n",
      "D(x): 0.623, D(G(z)): 0.623\n",
      "2019-04-24 21:09:56,500 root         INFO     Train Epoch: 0 [4608/8000 (58%)]\tTotal Loss: 0.060106, Discriminator: 0.045190; Generator: 0.014916,\n",
      "D(x): 0.620, D(G(z)): 0.620\n",
      "2019-04-24 21:09:56,595 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 0.060149, Discriminator: 0.045118; Generator: 0.015032,\n",
      "D(x): 0.618, D(G(z)): 0.618\n",
      "2019-04-24 21:09:56,687 root         INFO     Train Epoch: 0 [5632/8000 (70%)]\tTotal Loss: 0.060193, Discriminator: 0.045048; Generator: 0.015145,\n",
      "D(x): 0.616, D(G(z)): 0.616\n",
      "2019-04-24 21:09:56,779 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 0.060238, Discriminator: 0.044982; Generator: 0.015257,\n",
      "D(x): 0.614, D(G(z)): 0.614\n",
      "2019-04-24 21:09:56,870 root         INFO     Train Epoch: 0 [6656/8000 (83%)]\tTotal Loss: 0.060284, Discriminator: 0.044918; Generator: 0.015366,\n",
      "D(x): 0.612, D(G(z)): 0.612\n",
      "2019-04-24 21:09:56,963 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 0.060330, Discriminator: 0.044857; Generator: 0.015473,\n",
      "D(x): 0.609, D(G(z)): 0.609\n",
      "2019-04-24 21:09:57,056 root         INFO     Train Epoch: 0 [7680/8000 (96%)]\tTotal Loss: 0.060378, Discriminator: 0.044799; Generator: 0.015579,\n",
      "D(x): 0.607, D(G(z)): 0.607\n",
      "2019-04-24 21:09:57,142 root         INFO     ====> Epoch: 0 Average loss: 0.0601\n",
      "2019-04-24 21:09:57,189 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 0.060407, Discriminator: 0.044763; Generator: 0.015644,\n",
      "D(x): 0.606, D(G(z)): 0.606\n",
      "2019-04-24 21:09:57,283 root         INFO     Train Epoch: 1 [512/8000 (6%)]\tTotal Loss: 0.060455, Discriminator: 0.044709; Generator: 0.015746,\n",
      "D(x): 0.604, D(G(z)): 0.604\n",
      "2019-04-24 21:09:57,377 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 0.060503, Discriminator: 0.044656; Generator: 0.015847,\n",
      "D(x): 0.602, D(G(z)): 0.602\n",
      "2019-04-24 21:09:57,470 root         INFO     Train Epoch: 1 [1536/8000 (19%)]\tTotal Loss: 0.060552, Discriminator: 0.044606; Generator: 0.015946,\n",
      "D(x): 0.600, D(G(z)): 0.600\n",
      "2019-04-24 21:09:57,564 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 0.060601, Discriminator: 0.044558; Generator: 0.016043,\n",
      "D(x): 0.598, D(G(z)): 0.598\n",
      "2019-04-24 21:09:57,657 root         INFO     Train Epoch: 1 [2560/8000 (32%)]\tTotal Loss: 0.060650, Discriminator: 0.044512; Generator: 0.016138,\n",
      "D(x): 0.597, D(G(z)): 0.597\n",
      "2019-04-24 21:09:57,751 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 0.060699, Discriminator: 0.044467; Generator: 0.016232,\n",
      "D(x): 0.595, D(G(z)): 0.595\n",
      "2019-04-24 21:09:57,844 root         INFO     Train Epoch: 1 [3584/8000 (45%)]\tTotal Loss: 0.060749, Discriminator: 0.044425; Generator: 0.016324,\n",
      "D(x): 0.593, D(G(z)): 0.593\n",
      "2019-04-24 21:09:57,937 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 0.060798, Discriminator: 0.044384; Generator: 0.016415,\n",
      "D(x): 0.591, D(G(z)): 0.591\n",
      "2019-04-24 21:09:58,032 root         INFO     Train Epoch: 1 [4608/8000 (58%)]\tTotal Loss: 0.060848, Discriminator: 0.044344; Generator: 0.016504,\n",
      "D(x): 0.590, D(G(z)): 0.590\n",
      "2019-04-24 21:09:58,124 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 0.060898, Discriminator: 0.044306; Generator: 0.016591,\n",
      "D(x): 0.588, D(G(z)): 0.588\n",
      "2019-04-24 21:09:58,217 root         INFO     Train Epoch: 1 [5632/8000 (70%)]\tTotal Loss: 0.060947, Discriminator: 0.044270; Generator: 0.016677,\n",
      "D(x): 0.586, D(G(z)): 0.586\n",
      "2019-04-24 21:09:58,309 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 0.060997, Discriminator: 0.044235; Generator: 0.016762,\n",
      "D(x): 0.585, D(G(z)): 0.585\n",
      "2019-04-24 21:09:58,401 root         INFO     Train Epoch: 1 [6656/8000 (83%)]\tTotal Loss: 0.061046, Discriminator: 0.044202; Generator: 0.016845,\n",
      "D(x): 0.583, D(G(z)): 0.583\n",
      "2019-04-24 21:09:58,492 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 0.061096, Discriminator: 0.044169; Generator: 0.016926,\n",
      "D(x): 0.582, D(G(z)): 0.582\n",
      "2019-04-24 21:09:58,584 root         INFO     Train Epoch: 1 [7680/8000 (96%)]\tTotal Loss: 0.061145, Discriminator: 0.044138; Generator: 0.017007,\n",
      "D(x): 0.580, D(G(z)): 0.580\n",
      "2019-04-24 21:09:58,670 root         INFO     ====> Epoch: 1 Average loss: 0.0608\n",
      "2019-04-24 21:09:58,717 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 0.061176, Discriminator: 0.044119; Generator: 0.017056,\n",
      "D(x): 0.579, D(G(z)): 0.579\n",
      "2019-04-24 21:09:58,810 root         INFO     Train Epoch: 2 [512/8000 (6%)]\tTotal Loss: 0.061225, Discriminator: 0.044090; Generator: 0.017134,\n",
      "D(x): 0.578, D(G(z)): 0.578\n",
      "2019-04-24 21:09:58,902 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 0.061273, Discriminator: 0.044062; Generator: 0.017211,\n",
      "D(x): 0.577, D(G(z)): 0.577\n",
      "2019-04-24 21:09:58,993 root         INFO     Train Epoch: 2 [1536/8000 (19%)]\tTotal Loss: 0.061322, Discriminator: 0.044035; Generator: 0.017287,\n",
      "D(x): 0.575, D(G(z)): 0.575\n",
      "2019-04-24 21:09:59,085 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 0.061370, Discriminator: 0.044009; Generator: 0.017361,\n",
      "D(x): 0.574, D(G(z)): 0.574\n",
      "2019-04-24 21:09:59,178 root         INFO     Train Epoch: 2 [2560/8000 (32%)]\tTotal Loss: 0.061418, Discriminator: 0.043984; Generator: 0.017434,\n",
      "D(x): 0.572, D(G(z)): 0.572\n",
      "2019-04-24 21:09:59,270 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 0.061466, Discriminator: 0.043960; Generator: 0.017506,\n",
      "D(x): 0.571, D(G(z)): 0.571\n",
      "2019-04-24 21:09:59,362 root         INFO     Train Epoch: 2 [3584/8000 (45%)]\tTotal Loss: 0.061514, Discriminator: 0.043937; Generator: 0.017577,\n",
      "D(x): 0.570, D(G(z)): 0.570\n",
      "2019-04-24 21:09:59,452 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 0.061561, Discriminator: 0.043915; Generator: 0.017646,\n",
      "D(x): 0.569, D(G(z)): 0.569\n",
      "2019-04-24 21:09:59,542 root         INFO     Train Epoch: 2 [4608/8000 (58%)]\tTotal Loss: 0.061608, Discriminator: 0.043893; Generator: 0.017715,\n",
      "D(x): 0.567, D(G(z)): 0.567\n",
      "2019-04-24 21:09:59,633 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 0.061654, Discriminator: 0.043872; Generator: 0.017782,\n",
      "D(x): 0.566, D(G(z)): 0.566\n",
      "2019-04-24 21:09:59,725 root         INFO     Train Epoch: 2 [5632/8000 (70%)]\tTotal Loss: 0.061700, Discriminator: 0.043852; Generator: 0.017848,\n",
      "D(x): 0.565, D(G(z)): 0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:09:59,817 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 0.061746, Discriminator: 0.043833; Generator: 0.017913,\n",
      "D(x): 0.564, D(G(z)): 0.564\n",
      "2019-04-24 21:09:59,908 root         INFO     Train Epoch: 2 [6656/8000 (83%)]\tTotal Loss: 0.061792, Discriminator: 0.043815; Generator: 0.017977,\n",
      "D(x): 0.563, D(G(z)): 0.563\n",
      "2019-04-24 21:09:59,998 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 0.061837, Discriminator: 0.043797; Generator: 0.018040,\n",
      "D(x): 0.561, D(G(z)): 0.561\n",
      "2019-04-24 21:10:00,088 root         INFO     Train Epoch: 2 [7680/8000 (96%)]\tTotal Loss: 0.061882, Discriminator: 0.043780; Generator: 0.018102,\n",
      "D(x): 0.560, D(G(z)): 0.560\n",
      "2019-04-24 21:10:00,173 root         INFO     ====> Epoch: 2 Average loss: 0.0615\n",
      "2019-04-24 21:10:00,220 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 0.061909, Discriminator: 0.043769; Generator: 0.018140,\n",
      "D(x): 0.560, D(G(z)): 0.560\n",
      "2019-04-24 21:10:00,313 root         INFO     Train Epoch: 3 [512/8000 (6%)]\tTotal Loss: 0.061954, Discriminator: 0.043753; Generator: 0.018200,\n",
      "D(x): 0.559, D(G(z)): 0.559\n",
      "2019-04-24 21:10:00,405 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 0.061997, Discriminator: 0.043738; Generator: 0.018260,\n",
      "D(x): 0.557, D(G(z)): 0.557\n",
      "2019-04-24 21:10:00,497 root         INFO     Train Epoch: 3 [1536/8000 (19%)]\tTotal Loss: 0.062041, Discriminator: 0.043723; Generator: 0.018318,\n",
      "D(x): 0.556, D(G(z)): 0.556\n",
      "2019-04-24 21:10:00,588 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 0.062083, Discriminator: 0.043708; Generator: 0.018375,\n",
      "D(x): 0.555, D(G(z)): 0.555\n",
      "2019-04-24 21:10:00,679 root         INFO     Train Epoch: 3 [2560/8000 (32%)]\tTotal Loss: 0.062126, Discriminator: 0.043694; Generator: 0.018432,\n",
      "D(x): 0.554, D(G(z)): 0.554\n",
      "2019-04-24 21:10:00,769 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 0.062168, Discriminator: 0.043681; Generator: 0.018487,\n",
      "D(x): 0.553, D(G(z)): 0.553\n",
      "2019-04-24 21:10:00,860 root         INFO     Train Epoch: 3 [3584/8000 (45%)]\tTotal Loss: 0.062210, Discriminator: 0.043668; Generator: 0.018542,\n",
      "D(x): 0.552, D(G(z)): 0.552\n",
      "2019-04-24 21:10:00,951 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 0.062251, Discriminator: 0.043655; Generator: 0.018596,\n",
      "D(x): 0.552, D(G(z)): 0.552\n",
      "2019-04-24 21:10:01,041 root         INFO     Train Epoch: 3 [4608/8000 (58%)]\tTotal Loss: 0.062292, Discriminator: 0.043643; Generator: 0.018648,\n",
      "D(x): 0.551, D(G(z)): 0.551\n",
      "2019-04-24 21:10:01,135 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 0.062332, Discriminator: 0.043632; Generator: 0.018700,\n",
      "D(x): 0.550, D(G(z)): 0.550\n",
      "2019-04-24 21:10:01,231 root         INFO     Train Epoch: 3 [5632/8000 (70%)]\tTotal Loss: 0.062372, Discriminator: 0.043621; Generator: 0.018751,\n",
      "D(x): 0.549, D(G(z)): 0.549\n",
      "2019-04-24 21:10:01,326 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 0.062412, Discriminator: 0.043610; Generator: 0.018802,\n",
      "D(x): 0.548, D(G(z)): 0.548\n",
      "2019-04-24 21:10:01,422 root         INFO     Train Epoch: 3 [6656/8000 (83%)]\tTotal Loss: 0.062451, Discriminator: 0.043600; Generator: 0.018851,\n",
      "D(x): 0.547, D(G(z)): 0.547\n",
      "2019-04-24 21:10:01,518 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 0.062489, Discriminator: 0.043590; Generator: 0.018900,\n",
      "D(x): 0.546, D(G(z)): 0.546\n",
      "2019-04-24 21:10:01,612 root         INFO     Train Epoch: 3 [7680/8000 (96%)]\tTotal Loss: 0.062527, Discriminator: 0.043580; Generator: 0.018948,\n",
      "D(x): 0.545, D(G(z)): 0.545\n",
      "2019-04-24 21:10:01,696 root         INFO     ====> Epoch: 3 Average loss: 0.0622\n",
      "2019-04-24 21:10:01,743 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 0.062551, Discriminator: 0.043574; Generator: 0.018977,\n",
      "D(x): 0.545, D(G(z)): 0.545\n",
      "2019-04-24 21:10:01,833 root         INFO     Train Epoch: 4 [512/8000 (6%)]\tTotal Loss: 0.062589, Discriminator: 0.043565; Generator: 0.019024,\n",
      "D(x): 0.544, D(G(z)): 0.544\n",
      "2019-04-24 21:10:01,922 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 0.062626, Discriminator: 0.043556; Generator: 0.019069,\n",
      "D(x): 0.543, D(G(z)): 0.543\n",
      "2019-04-24 21:10:02,012 root         INFO     Train Epoch: 4 [1536/8000 (19%)]\tTotal Loss: 0.062662, Discriminator: 0.043548; Generator: 0.019114,\n",
      "D(x): 0.542, D(G(z)): 0.542\n",
      "2019-04-24 21:10:02,103 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 0.062698, Discriminator: 0.043540; Generator: 0.019159,\n",
      "D(x): 0.542, D(G(z)): 0.542\n",
      "2019-04-24 21:10:02,192 root         INFO     Train Epoch: 4 [2560/8000 (32%)]\tTotal Loss: 0.062734, Discriminator: 0.043532; Generator: 0.019202,\n",
      "D(x): 0.541, D(G(z)): 0.541\n",
      "2019-04-24 21:10:02,282 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 0.062769, Discriminator: 0.043524; Generator: 0.019245,\n",
      "D(x): 0.540, D(G(z)): 0.540\n",
      "2019-04-24 21:10:02,374 root         INFO     Train Epoch: 4 [3584/8000 (45%)]\tTotal Loss: 0.062804, Discriminator: 0.043517; Generator: 0.019287,\n",
      "D(x): 0.539, D(G(z)): 0.539\n",
      "2019-04-24 21:10:02,465 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 0.062838, Discriminator: 0.043510; Generator: 0.019329,\n",
      "D(x): 0.539, D(G(z)): 0.539\n",
      "2019-04-24 21:10:02,557 root         INFO     Train Epoch: 4 [4608/8000 (58%)]\tTotal Loss: 0.062872, Discriminator: 0.043503; Generator: 0.019369,\n",
      "D(x): 0.538, D(G(z)): 0.538\n",
      "2019-04-24 21:10:02,649 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 0.062906, Discriminator: 0.043497; Generator: 0.019409,\n",
      "D(x): 0.537, D(G(z)): 0.537\n",
      "2019-04-24 21:10:02,742 root         INFO     Train Epoch: 4 [5632/8000 (70%)]\tTotal Loss: 0.062939, Discriminator: 0.043490; Generator: 0.019449,\n",
      "D(x): 0.537, D(G(z)): 0.537\n",
      "2019-04-24 21:10:02,834 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 0.062972, Discriminator: 0.043484; Generator: 0.019488,\n",
      "D(x): 0.536, D(G(z)): 0.536\n",
      "2019-04-24 21:10:02,926 root         INFO     Train Epoch: 4 [6656/8000 (83%)]\tTotal Loss: 0.063004, Discriminator: 0.043478; Generator: 0.019526,\n",
      "D(x): 0.535, D(G(z)): 0.535\n",
      "2019-04-24 21:10:03,018 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 0.063036, Discriminator: 0.043473; Generator: 0.019563,\n",
      "D(x): 0.535, D(G(z)): 0.535\n",
      "2019-04-24 21:10:03,110 root         INFO     Train Epoch: 4 [7680/8000 (96%)]\tTotal Loss: 0.063067, Discriminator: 0.043467; Generator: 0.019600,\n",
      "D(x): 0.534, D(G(z)): 0.534\n",
      "2019-04-24 21:10:03,193 root         INFO     ====> Epoch: 4 Average loss: 0.0628\n",
      "2019-04-24 21:10:03,241 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 0.063087, Discriminator: 0.043464; Generator: 0.019623,\n",
      "D(x): 0.534, D(G(z)): 0.534\n",
      "2019-04-24 21:10:03,335 root         INFO     Train Epoch: 5 [512/8000 (6%)]\tTotal Loss: 0.063117, Discriminator: 0.043459; Generator: 0.019658,\n",
      "D(x): 0.533, D(G(z)): 0.533\n",
      "2019-04-24 21:10:03,428 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 0.063148, Discriminator: 0.043454; Generator: 0.019694,\n",
      "D(x): 0.532, D(G(z)): 0.532\n",
      "2019-04-24 21:10:03,520 root         INFO     Train Epoch: 5 [1536/8000 (19%)]\tTotal Loss: 0.063177, Discriminator: 0.043449; Generator: 0.019728,\n",
      "D(x): 0.532, D(G(z)): 0.532\n",
      "2019-04-24 21:10:03,614 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 0.063207, Discriminator: 0.043445; Generator: 0.019762,\n",
      "D(x): 0.531, D(G(z)): 0.531\n",
      "2019-04-24 21:10:03,708 root         INFO     Train Epoch: 5 [2560/8000 (32%)]\tTotal Loss: 0.063236, Discriminator: 0.043440; Generator: 0.019796,\n",
      "D(x): 0.531, D(G(z)): 0.531\n",
      "2019-04-24 21:10:03,802 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 0.063265, Discriminator: 0.043436; Generator: 0.019829,\n",
      "D(x): 0.530, D(G(z)): 0.530\n",
      "2019-04-24 21:10:03,895 root         INFO     Train Epoch: 5 [3584/8000 (45%)]\tTotal Loss: 0.063293, Discriminator: 0.043432; Generator: 0.019861,\n",
      "D(x): 0.530, D(G(z)): 0.530\n",
      "2019-04-24 21:10:03,988 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 0.063321, Discriminator: 0.043428; Generator: 0.019893,\n",
      "D(x): 0.529, D(G(z)): 0.529\n",
      "2019-04-24 21:10:04,079 root         INFO     Train Epoch: 5 [4608/8000 (58%)]\tTotal Loss: 0.063348, Discriminator: 0.043424; Generator: 0.019924,\n",
      "D(x): 0.529, D(G(z)): 0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:10:04,171 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 0.063375, Discriminator: 0.043420; Generator: 0.019955,\n",
      "D(x): 0.528, D(G(z)): 0.528\n",
      "2019-04-24 21:10:04,264 root         INFO     Train Epoch: 5 [5632/8000 (70%)]\tTotal Loss: 0.063402, Discriminator: 0.043417; Generator: 0.019985,\n",
      "D(x): 0.528, D(G(z)): 0.528\n",
      "2019-04-24 21:10:04,357 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 0.063428, Discriminator: 0.043413; Generator: 0.020015,\n",
      "D(x): 0.527, D(G(z)): 0.527\n",
      "2019-04-24 21:10:04,447 root         INFO     Train Epoch: 5 [6656/8000 (83%)]\tTotal Loss: 0.063454, Discriminator: 0.043410; Generator: 0.020044,\n",
      "D(x): 0.527, D(G(z)): 0.527\n",
      "2019-04-24 21:10:04,539 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 0.063480, Discriminator: 0.043407; Generator: 0.020073,\n",
      "D(x): 0.526, D(G(z)): 0.526\n",
      "2019-04-24 21:10:04,631 root         INFO     Train Epoch: 5 [7680/8000 (96%)]\tTotal Loss: 0.063505, Discriminator: 0.043404; Generator: 0.020101,\n",
      "D(x): 0.526, D(G(z)): 0.526\n",
      "2019-04-24 21:10:04,717 root         INFO     ====> Epoch: 5 Average loss: 0.0633\n",
      "2019-04-24 21:10:04,764 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 0.063520, Discriminator: 0.043402; Generator: 0.020119,\n",
      "D(x): 0.525, D(G(z)): 0.525\n",
      "2019-04-24 21:10:04,866 root         INFO     Train Epoch: 6 [512/8000 (6%)]\tTotal Loss: 0.063545, Discriminator: 0.043399; Generator: 0.020146,\n",
      "D(x): 0.525, D(G(z)): 0.525\n",
      "2019-04-24 21:10:04,969 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 0.063569, Discriminator: 0.043396; Generator: 0.020173,\n",
      "D(x): 0.524, D(G(z)): 0.524\n",
      "2019-04-24 21:10:05,104 root         INFO     Train Epoch: 6 [1536/8000 (19%)]\tTotal Loss: 0.063593, Discriminator: 0.043393; Generator: 0.020200,\n",
      "D(x): 0.524, D(G(z)): 0.524\n",
      "2019-04-24 21:10:05,225 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 0.063616, Discriminator: 0.043391; Generator: 0.020226,\n",
      "D(x): 0.523, D(G(z)): 0.523\n",
      "2019-04-24 21:10:05,319 root         INFO     Train Epoch: 6 [2560/8000 (32%)]\tTotal Loss: 0.063640, Discriminator: 0.043388; Generator: 0.020251,\n",
      "D(x): 0.523, D(G(z)): 0.523\n",
      "2019-04-24 21:10:05,412 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 0.063662, Discriminator: 0.043386; Generator: 0.020276,\n",
      "D(x): 0.523, D(G(z)): 0.523\n",
      "2019-04-24 21:10:05,505 root         INFO     Train Epoch: 6 [3584/8000 (45%)]\tTotal Loss: 0.063685, Discriminator: 0.043384; Generator: 0.020301,\n",
      "D(x): 0.522, D(G(z)): 0.522\n",
      "2019-04-24 21:10:05,599 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 0.063707, Discriminator: 0.043381; Generator: 0.020326,\n",
      "D(x): 0.522, D(G(z)): 0.522\n",
      "2019-04-24 21:10:05,692 root         INFO     Train Epoch: 6 [4608/8000 (58%)]\tTotal Loss: 0.063729, Discriminator: 0.043379; Generator: 0.020349,\n",
      "D(x): 0.521, D(G(z)): 0.521\n",
      "2019-04-24 21:10:05,785 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 0.063750, Discriminator: 0.043377; Generator: 0.020373,\n",
      "D(x): 0.521, D(G(z)): 0.521\n",
      "2019-04-24 21:10:05,879 root         INFO     Train Epoch: 6 [5632/8000 (70%)]\tTotal Loss: 0.063771, Discriminator: 0.043375; Generator: 0.020396,\n",
      "D(x): 0.521, D(G(z)): 0.521\n",
      "2019-04-24 21:10:05,972 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 0.063792, Discriminator: 0.043373; Generator: 0.020419,\n",
      "D(x): 0.520, D(G(z)): 0.520\n",
      "2019-04-24 21:10:06,064 root         INFO     Train Epoch: 6 [6656/8000 (83%)]\tTotal Loss: 0.063812, Discriminator: 0.043371; Generator: 0.020441,\n",
      "D(x): 0.520, D(G(z)): 0.520\n",
      "2019-04-24 21:10:06,156 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 0.063832, Discriminator: 0.043369; Generator: 0.020463,\n",
      "D(x): 0.520, D(G(z)): 0.520\n",
      "2019-04-24 21:10:06,248 root         INFO     Train Epoch: 6 [7680/8000 (96%)]\tTotal Loss: 0.063852, Discriminator: 0.043368; Generator: 0.020485,\n",
      "D(x): 0.519, D(G(z)): 0.519\n",
      "2019-04-24 21:10:06,333 root         INFO     ====> Epoch: 6 Average loss: 0.0637\n",
      "2019-04-24 21:10:06,380 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 0.063864, Discriminator: 0.043367; Generator: 0.020498,\n",
      "D(x): 0.519, D(G(z)): 0.519\n",
      "2019-04-24 21:10:06,471 root         INFO     Train Epoch: 7 [512/8000 (6%)]\tTotal Loss: 0.063884, Discriminator: 0.043365; Generator: 0.020519,\n",
      "D(x): 0.519, D(G(z)): 0.519\n",
      "2019-04-24 21:10:06,561 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 0.063903, Discriminator: 0.043363; Generator: 0.020539,\n",
      "D(x): 0.518, D(G(z)): 0.518\n",
      "2019-04-24 21:10:06,652 root         INFO     Train Epoch: 7 [1536/8000 (19%)]\tTotal Loss: 0.063921, Discriminator: 0.043362; Generator: 0.020559,\n",
      "D(x): 0.518, D(G(z)): 0.518\n",
      "2019-04-24 21:10:06,744 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 0.063940, Discriminator: 0.043360; Generator: 0.020579,\n",
      "D(x): 0.518, D(G(z)): 0.518\n",
      "2019-04-24 21:10:06,835 root         INFO     Train Epoch: 7 [2560/8000 (32%)]\tTotal Loss: 0.063958, Discriminator: 0.043359; Generator: 0.020599,\n",
      "D(x): 0.517, D(G(z)): 0.517\n",
      "2019-04-24 21:10:06,925 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 0.063976, Discriminator: 0.043358; Generator: 0.020618,\n",
      "D(x): 0.517, D(G(z)): 0.517\n",
      "2019-04-24 21:10:07,015 root         INFO     Train Epoch: 7 [3584/8000 (45%)]\tTotal Loss: 0.063993, Discriminator: 0.043356; Generator: 0.020637,\n",
      "D(x): 0.517, D(G(z)): 0.517\n",
      "2019-04-24 21:10:07,104 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 0.064010, Discriminator: 0.043355; Generator: 0.020655,\n",
      "D(x): 0.516, D(G(z)): 0.516\n",
      "2019-04-24 21:10:07,194 root         INFO     Train Epoch: 7 [4608/8000 (58%)]\tTotal Loss: 0.064027, Discriminator: 0.043354; Generator: 0.020674,\n",
      "D(x): 0.516, D(G(z)): 0.516\n",
      "2019-04-24 21:10:07,286 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 0.064044, Discriminator: 0.043353; Generator: 0.020691,\n",
      "D(x): 0.516, D(G(z)): 0.516\n",
      "2019-04-24 21:10:07,379 root         INFO     Train Epoch: 7 [5632/8000 (70%)]\tTotal Loss: 0.064061, Discriminator: 0.043352; Generator: 0.020709,\n",
      "D(x): 0.515, D(G(z)): 0.515\n",
      "2019-04-24 21:10:07,471 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 0.064077, Discriminator: 0.043351; Generator: 0.020726,\n",
      "D(x): 0.515, D(G(z)): 0.515\n",
      "2019-04-24 21:10:07,563 root         INFO     Train Epoch: 7 [6656/8000 (83%)]\tTotal Loss: 0.064093, Discriminator: 0.043349; Generator: 0.020743,\n",
      "D(x): 0.515, D(G(z)): 0.515\n",
      "2019-04-24 21:10:07,653 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 0.064108, Discriminator: 0.043348; Generator: 0.020760,\n",
      "D(x): 0.515, D(G(z)): 0.515\n",
      "2019-04-24 21:10:07,744 root         INFO     Train Epoch: 7 [7680/8000 (96%)]\tTotal Loss: 0.064124, Discriminator: 0.043347; Generator: 0.020776,\n",
      "D(x): 0.514, D(G(z)): 0.514\n",
      "2019-04-24 21:10:07,828 root         INFO     ====> Epoch: 7 Average loss: 0.0640\n",
      "2019-04-24 21:10:07,874 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 0.064133, Discriminator: 0.043347; Generator: 0.020786,\n",
      "D(x): 0.514, D(G(z)): 0.514\n",
      "2019-04-24 21:10:07,967 root         INFO     Train Epoch: 8 [512/8000 (6%)]\tTotal Loss: 0.064148, Discriminator: 0.043346; Generator: 0.020802,\n",
      "D(x): 0.514, D(G(z)): 0.514\n",
      "2019-04-24 21:10:08,059 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 0.064163, Discriminator: 0.043345; Generator: 0.020818,\n",
      "D(x): 0.514, D(G(z)): 0.514\n",
      "2019-04-24 21:10:08,150 root         INFO     Train Epoch: 8 [1536/8000 (19%)]\tTotal Loss: 0.064177, Discriminator: 0.043344; Generator: 0.020833,\n",
      "D(x): 0.513, D(G(z)): 0.513\n",
      "2019-04-24 21:10:08,240 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 0.064191, Discriminator: 0.043343; Generator: 0.020848,\n",
      "D(x): 0.513, D(G(z)): 0.513\n",
      "2019-04-24 21:10:08,333 root         INFO     Train Epoch: 8 [2560/8000 (32%)]\tTotal Loss: 0.064205, Discriminator: 0.043343; Generator: 0.020863,\n",
      "D(x): 0.513, D(G(z)): 0.513\n",
      "2019-04-24 21:10:08,423 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 0.064219, Discriminator: 0.043342; Generator: 0.020877,\n",
      "D(x): 0.513, D(G(z)): 0.513\n",
      "2019-04-24 21:10:08,514 root         INFO     Train Epoch: 8 [3584/8000 (45%)]\tTotal Loss: 0.064233, Discriminator: 0.043341; Generator: 0.020892,\n",
      "D(x): 0.512, D(G(z)): 0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:10:08,606 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 0.064246, Discriminator: 0.043340; Generator: 0.020906,\n",
      "D(x): 0.512, D(G(z)): 0.512\n",
      "2019-04-24 21:10:08,696 root         INFO     Train Epoch: 8 [4608/8000 (58%)]\tTotal Loss: 0.064259, Discriminator: 0.043340; Generator: 0.020919,\n",
      "D(x): 0.512, D(G(z)): 0.512\n",
      "2019-04-24 21:10:08,788 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 0.064272, Discriminator: 0.043339; Generator: 0.020933,\n",
      "D(x): 0.512, D(G(z)): 0.512\n",
      "2019-04-24 21:10:08,880 root         INFO     Train Epoch: 8 [5632/8000 (70%)]\tTotal Loss: 0.064285, Discriminator: 0.043338; Generator: 0.020946,\n",
      "D(x): 0.512, D(G(z)): 0.512\n",
      "2019-04-24 21:10:08,972 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 0.064297, Discriminator: 0.043338; Generator: 0.020959,\n",
      "D(x): 0.511, D(G(z)): 0.511\n",
      "2019-04-24 21:10:09,063 root         INFO     Train Epoch: 8 [6656/8000 (83%)]\tTotal Loss: 0.064309, Discriminator: 0.043337; Generator: 0.020972,\n",
      "D(x): 0.511, D(G(z)): 0.511\n",
      "2019-04-24 21:10:09,154 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 0.064321, Discriminator: 0.043337; Generator: 0.020985,\n",
      "D(x): 0.511, D(G(z)): 0.511\n",
      "2019-04-24 21:10:09,246 root         INFO     Train Epoch: 8 [7680/8000 (96%)]\tTotal Loss: 0.064333, Discriminator: 0.043336; Generator: 0.020997,\n",
      "D(x): 0.511, D(G(z)): 0.511\n",
      "2019-04-24 21:10:09,330 root         INFO     ====> Epoch: 8 Average loss: 0.0642\n",
      "2019-04-24 21:10:09,377 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 0.064340, Discriminator: 0.043336; Generator: 0.021004,\n",
      "D(x): 0.511, D(G(z)): 0.511\n",
      "2019-04-24 21:10:09,469 root         INFO     Train Epoch: 9 [512/8000 (6%)]\tTotal Loss: 0.064352, Discriminator: 0.043335; Generator: 0.021016,\n",
      "D(x): 0.510, D(G(z)): 0.510\n",
      "2019-04-24 21:10:09,562 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 0.064363, Discriminator: 0.043335; Generator: 0.021028,\n",
      "D(x): 0.510, D(G(z)): 0.510\n",
      "2019-04-24 21:10:09,655 root         INFO     Train Epoch: 9 [1536/8000 (19%)]\tTotal Loss: 0.064374, Discriminator: 0.043334; Generator: 0.021040,\n",
      "D(x): 0.510, D(G(z)): 0.510\n",
      "2019-04-24 21:10:09,748 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 0.064385, Discriminator: 0.043334; Generator: 0.021051,\n",
      "D(x): 0.510, D(G(z)): 0.510\n",
      "2019-04-24 21:10:09,840 root         INFO     Train Epoch: 9 [2560/8000 (32%)]\tTotal Loss: 0.064396, Discriminator: 0.043333; Generator: 0.021062,\n",
      "D(x): 0.510, D(G(z)): 0.510\n",
      "2019-04-24 21:10:09,934 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 0.064406, Discriminator: 0.043333; Generator: 0.021073,\n",
      "D(x): 0.509, D(G(z)): 0.509\n",
      "2019-04-24 21:10:10,027 root         INFO     Train Epoch: 9 [3584/8000 (45%)]\tTotal Loss: 0.064417, Discriminator: 0.043333; Generator: 0.021084,\n",
      "D(x): 0.509, D(G(z)): 0.509\n",
      "2019-04-24 21:10:10,121 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 0.064427, Discriminator: 0.043332; Generator: 0.021095,\n",
      "D(x): 0.509, D(G(z)): 0.509\n",
      "2019-04-24 21:10:10,213 root         INFO     Train Epoch: 9 [4608/8000 (58%)]\tTotal Loss: 0.064437, Discriminator: 0.043332; Generator: 0.021105,\n",
      "D(x): 0.509, D(G(z)): 0.509\n",
      "2019-04-24 21:10:10,305 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 0.064447, Discriminator: 0.043331; Generator: 0.021115,\n",
      "D(x): 0.509, D(G(z)): 0.509\n",
      "2019-04-24 21:10:10,395 root         INFO     Train Epoch: 9 [5632/8000 (70%)]\tTotal Loss: 0.064456, Discriminator: 0.043331; Generator: 0.021125,\n",
      "D(x): 0.509, D(G(z)): 0.509\n",
      "2019-04-24 21:10:10,485 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 0.064466, Discriminator: 0.043331; Generator: 0.021135,\n",
      "D(x): 0.508, D(G(z)): 0.508\n",
      "2019-04-24 21:10:10,575 root         INFO     Train Epoch: 9 [6656/8000 (83%)]\tTotal Loss: 0.064475, Discriminator: 0.043330; Generator: 0.021145,\n",
      "D(x): 0.508, D(G(z)): 0.508\n",
      "2019-04-24 21:10:10,666 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 0.064484, Discriminator: 0.043330; Generator: 0.021154,\n",
      "D(x): 0.508, D(G(z)): 0.508\n",
      "2019-04-24 21:10:10,756 root         INFO     Train Epoch: 9 [7680/8000 (96%)]\tTotal Loss: 0.064493, Discriminator: 0.043330; Generator: 0.021163,\n",
      "D(x): 0.508, D(G(z)): 0.508\n",
      "2019-04-24 21:10:10,840 root         INFO     ====> Epoch: 9 Average loss: 0.0644\n",
      "2019-04-24 21:10:10,887 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 0.064499, Discriminator: 0.043330; Generator: 0.021169,\n",
      "D(x): 0.508, D(G(z)): 0.508\n",
      "2019-04-24 21:10:10,980 root         INFO     Train Epoch: 10 [512/8000 (6%)]\tTotal Loss: 0.064507, Discriminator: 0.043329; Generator: 0.021178,\n",
      "D(x): 0.508, D(G(z)): 0.508\n",
      "2019-04-24 21:10:11,070 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 0.064516, Discriminator: 0.043329; Generator: 0.021187,\n",
      "D(x): 0.508, D(G(z)): 0.508\n",
      "2019-04-24 21:10:11,162 root         INFO     Train Epoch: 10 [1536/8000 (19%)]\tTotal Loss: 0.064525, Discriminator: 0.043329; Generator: 0.021196,\n",
      "D(x): 0.507, D(G(z)): 0.507\n",
      "2019-04-24 21:10:11,254 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 0.064533, Discriminator: 0.043328; Generator: 0.021204,\n",
      "D(x): 0.507, D(G(z)): 0.507\n",
      "2019-04-24 21:10:11,346 root         INFO     Train Epoch: 10 [2560/8000 (32%)]\tTotal Loss: 0.064541, Discriminator: 0.043328; Generator: 0.021213,\n",
      "D(x): 0.507, D(G(z)): 0.507\n",
      "2019-04-24 21:10:11,438 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 0.064549, Discriminator: 0.043328; Generator: 0.021221,\n",
      "D(x): 0.507, D(G(z)): 0.507\n",
      "2019-04-24 21:10:11,530 root         INFO     Train Epoch: 10 [3584/8000 (45%)]\tTotal Loss: 0.064557, Discriminator: 0.043328; Generator: 0.021229,\n",
      "D(x): 0.507, D(G(z)): 0.507\n",
      "2019-04-24 21:10:11,623 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 0.064565, Discriminator: 0.043328; Generator: 0.021237,\n",
      "D(x): 0.507, D(G(z)): 0.507\n",
      "2019-04-24 21:10:11,715 root         INFO     Train Epoch: 10 [4608/8000 (58%)]\tTotal Loss: 0.064572, Discriminator: 0.043327; Generator: 0.021245,\n",
      "D(x): 0.507, D(G(z)): 0.507\n",
      "2019-04-24 21:10:11,806 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 0.064580, Discriminator: 0.043327; Generator: 0.021252,\n",
      "D(x): 0.507, D(G(z)): 0.507\n",
      "2019-04-24 21:10:11,898 root         INFO     Train Epoch: 10 [5632/8000 (70%)]\tTotal Loss: 0.064587, Discriminator: 0.043327; Generator: 0.021260,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-24 21:10:11,991 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 0.064594, Discriminator: 0.043327; Generator: 0.021267,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-24 21:10:12,082 root         INFO     Train Epoch: 10 [6656/8000 (83%)]\tTotal Loss: 0.064601, Discriminator: 0.043327; Generator: 0.021275,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-24 21:10:12,174 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 0.064608, Discriminator: 0.043326; Generator: 0.021282,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-24 21:10:12,266 root         INFO     Train Epoch: 10 [7680/8000 (96%)]\tTotal Loss: 0.064615, Discriminator: 0.043326; Generator: 0.021289,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-24 21:10:12,351 root         INFO     ====> Epoch: 10 Average loss: 0.0646\n",
      "2019-04-24 21:10:12,397 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.064619, Discriminator: 0.043326; Generator: 0.021293,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-24 21:10:12,491 root         INFO     Train Epoch: 11 [512/8000 (6%)]\tTotal Loss: 0.064626, Discriminator: 0.043326; Generator: 0.021300,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-24 21:10:12,582 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 0.064632, Discriminator: 0.043326; Generator: 0.021307,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-24 21:10:12,673 root         INFO     Train Epoch: 11 [1536/8000 (19%)]\tTotal Loss: 0.064639, Discriminator: 0.043326; Generator: 0.021313,\n",
      "D(x): 0.506, D(G(z)): 0.506\n",
      "2019-04-24 21:10:12,765 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.064645, Discriminator: 0.043325; Generator: 0.021319,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-24 21:10:12,855 root         INFO     Train Epoch: 11 [2560/8000 (32%)]\tTotal Loss: 0.064651, Discriminator: 0.043325; Generator: 0.021326,\n",
      "D(x): 0.505, D(G(z)): 0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:10:12,946 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 0.064657, Discriminator: 0.043325; Generator: 0.021332,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-24 21:10:13,038 root         INFO     Train Epoch: 11 [3584/8000 (45%)]\tTotal Loss: 0.064663, Discriminator: 0.043325; Generator: 0.021338,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-24 21:10:13,128 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 0.064669, Discriminator: 0.043325; Generator: 0.021344,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-24 21:10:13,217 root         INFO     Train Epoch: 11 [4608/8000 (58%)]\tTotal Loss: 0.064675, Discriminator: 0.043325; Generator: 0.021350,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-24 21:10:13,310 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 0.064680, Discriminator: 0.043325; Generator: 0.021356,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-24 21:10:13,402 root         INFO     Train Epoch: 11 [5632/8000 (70%)]\tTotal Loss: 0.064686, Discriminator: 0.043325; Generator: 0.021361,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-24 21:10:13,492 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.064691, Discriminator: 0.043324; Generator: 0.021367,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-24 21:10:13,583 root         INFO     Train Epoch: 11 [6656/8000 (83%)]\tTotal Loss: 0.064697, Discriminator: 0.043324; Generator: 0.021372,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-24 21:10:13,675 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 0.064702, Discriminator: 0.043324; Generator: 0.021378,\n",
      "D(x): 0.505, D(G(z)): 0.505\n",
      "2019-04-24 21:10:13,766 root         INFO     Train Epoch: 11 [7680/8000 (96%)]\tTotal Loss: 0.064707, Discriminator: 0.043324; Generator: 0.021383,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-24 21:10:13,851 root         INFO     ====> Epoch: 11 Average loss: 0.0647\n",
      "2019-04-24 21:10:13,899 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 0.064710, Discriminator: 0.043324; Generator: 0.021386,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-24 21:10:13,991 root         INFO     Train Epoch: 12 [512/8000 (6%)]\tTotal Loss: 0.064715, Discriminator: 0.043324; Generator: 0.021391,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-24 21:10:14,083 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 0.064720, Discriminator: 0.043324; Generator: 0.021396,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-24 21:10:14,176 root         INFO     Train Epoch: 12 [1536/8000 (19%)]\tTotal Loss: 0.064725, Discriminator: 0.043324; Generator: 0.021401,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-24 21:10:14,268 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 0.064730, Discriminator: 0.043324; Generator: 0.021406,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-24 21:10:14,359 root         INFO     Train Epoch: 12 [2560/8000 (32%)]\tTotal Loss: 0.064734, Discriminator: 0.043324; Generator: 0.021411,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-24 21:10:14,450 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 0.064739, Discriminator: 0.043324; Generator: 0.021415,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-24 21:10:14,540 root         INFO     Train Epoch: 12 [3584/8000 (45%)]\tTotal Loss: 0.064743, Discriminator: 0.043324; Generator: 0.021420,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-24 21:10:14,631 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 0.064748, Discriminator: 0.043324; Generator: 0.021424,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-24 21:10:14,723 root         INFO     Train Epoch: 12 [4608/8000 (58%)]\tTotal Loss: 0.064752, Discriminator: 0.043323; Generator: 0.021429,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-24 21:10:14,814 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.064756, Discriminator: 0.043323; Generator: 0.021433,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-24 21:10:14,906 root         INFO     Train Epoch: 12 [5632/8000 (70%)]\tTotal Loss: 0.064760, Discriminator: 0.043323; Generator: 0.021437,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-24 21:10:14,997 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.064765, Discriminator: 0.043323; Generator: 0.021441,\n",
      "D(x): 0.504, D(G(z)): 0.504\n",
      "2019-04-24 21:10:15,089 root         INFO     Train Epoch: 12 [6656/8000 (83%)]\tTotal Loss: 0.064769, Discriminator: 0.043323; Generator: 0.021445,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:15,180 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 0.064772, Discriminator: 0.043323; Generator: 0.021449,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:15,272 root         INFO     Train Epoch: 12 [7680/8000 (96%)]\tTotal Loss: 0.064776, Discriminator: 0.043323; Generator: 0.021453,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:15,355 root         INFO     ====> Epoch: 12 Average loss: 0.0647\n",
      "2019-04-24 21:10:15,403 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 0.064779, Discriminator: 0.043323; Generator: 0.021456,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:15,496 root         INFO     Train Epoch: 13 [512/8000 (6%)]\tTotal Loss: 0.064782, Discriminator: 0.043323; Generator: 0.021459,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:15,588 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 0.064786, Discriminator: 0.043323; Generator: 0.021463,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:15,679 root         INFO     Train Epoch: 13 [1536/8000 (19%)]\tTotal Loss: 0.064790, Discriminator: 0.043323; Generator: 0.021467,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:15,770 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 0.064793, Discriminator: 0.043323; Generator: 0.021470,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:15,862 root         INFO     Train Epoch: 13 [2560/8000 (32%)]\tTotal Loss: 0.064797, Discriminator: 0.043323; Generator: 0.021474,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:15,954 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 0.064800, Discriminator: 0.043323; Generator: 0.021477,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:16,045 root         INFO     Train Epoch: 13 [3584/8000 (45%)]\tTotal Loss: 0.064804, Discriminator: 0.043323; Generator: 0.021481,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:16,137 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 0.064807, Discriminator: 0.043323; Generator: 0.021484,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:16,231 root         INFO     Train Epoch: 13 [4608/8000 (58%)]\tTotal Loss: 0.064810, Discriminator: 0.043323; Generator: 0.021488,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:16,324 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 0.064813, Discriminator: 0.043323; Generator: 0.021491,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:16,418 root         INFO     Train Epoch: 13 [5632/8000 (70%)]\tTotal Loss: 0.064816, Discriminator: 0.043323; Generator: 0.021494,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:16,511 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 0.064820, Discriminator: 0.043323; Generator: 0.021497,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:16,605 root         INFO     Train Epoch: 13 [6656/8000 (83%)]\tTotal Loss: 0.064823, Discriminator: 0.043323; Generator: 0.021500,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:16,698 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 0.064826, Discriminator: 0.043322; Generator: 0.021503,\n",
      "D(x): 0.503, D(G(z)): 0.503\n",
      "2019-04-24 21:10:16,792 root         INFO     Train Epoch: 13 [7680/8000 (96%)]\tTotal Loss: 0.064828, Discriminator: 0.043322; Generator: 0.021506,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:16,877 root         INFO     ====> Epoch: 13 Average loss: 0.0648\n",
      "2019-04-24 21:10:16,924 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.064830, Discriminator: 0.043322; Generator: 0.021508,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:17,017 root         INFO     Train Epoch: 14 [512/8000 (6%)]\tTotal Loss: 0.064833, Discriminator: 0.043322; Generator: 0.021511,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:17,109 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.064836, Discriminator: 0.043322; Generator: 0.021513,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:17,202 root         INFO     Train Epoch: 14 [1536/8000 (19%)]\tTotal Loss: 0.064839, Discriminator: 0.043322; Generator: 0.021516,\n",
      "D(x): 0.502, D(G(z)): 0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:10:17,293 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 0.064841, Discriminator: 0.043322; Generator: 0.021519,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:17,385 root         INFO     Train Epoch: 14 [2560/8000 (32%)]\tTotal Loss: 0.064844, Discriminator: 0.043322; Generator: 0.021521,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:17,477 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.064846, Discriminator: 0.043322; Generator: 0.021524,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:17,569 root         INFO     Train Epoch: 14 [3584/8000 (45%)]\tTotal Loss: 0.064849, Discriminator: 0.043322; Generator: 0.021527,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:17,661 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.064851, Discriminator: 0.043322; Generator: 0.021529,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:17,753 root         INFO     Train Epoch: 14 [4608/8000 (58%)]\tTotal Loss: 0.064854, Discriminator: 0.043322; Generator: 0.021532,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:17,845 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 0.064856, Discriminator: 0.043322; Generator: 0.021534,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:17,937 root         INFO     Train Epoch: 14 [5632/8000 (70%)]\tTotal Loss: 0.064859, Discriminator: 0.043322; Generator: 0.021536,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:18,029 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.064861, Discriminator: 0.043322; Generator: 0.021539,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:18,121 root         INFO     Train Epoch: 14 [6656/8000 (83%)]\tTotal Loss: 0.064863, Discriminator: 0.043322; Generator: 0.021541,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:18,214 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.064865, Discriminator: 0.043322; Generator: 0.021543,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:18,307 root         INFO     Train Epoch: 14 [7680/8000 (96%)]\tTotal Loss: 0.064867, Discriminator: 0.043322; Generator: 0.021545,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:18,392 root         INFO     ====> Epoch: 14 Average loss: 0.0649\n",
      "2019-04-24 21:10:18,440 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 0.064869, Discriminator: 0.043322; Generator: 0.021547,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:18,533 root         INFO     Train Epoch: 15 [512/8000 (6%)]\tTotal Loss: 0.064871, Discriminator: 0.043322; Generator: 0.021549,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:18,625 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 0.064873, Discriminator: 0.043322; Generator: 0.021551,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:18,718 root         INFO     Train Epoch: 15 [1536/8000 (19%)]\tTotal Loss: 0.064875, Discriminator: 0.043322; Generator: 0.021553,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:18,811 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.064877, Discriminator: 0.043322; Generator: 0.021555,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:18,903 root         INFO     Train Epoch: 15 [2560/8000 (32%)]\tTotal Loss: 0.064879, Discriminator: 0.043322; Generator: 0.021557,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:18,996 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.064881, Discriminator: 0.043322; Generator: 0.021559,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:19,088 root         INFO     Train Epoch: 15 [3584/8000 (45%)]\tTotal Loss: 0.064883, Discriminator: 0.043322; Generator: 0.021561,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:19,179 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.064885, Discriminator: 0.043322; Generator: 0.021563,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:19,271 root         INFO     Train Epoch: 15 [4608/8000 (58%)]\tTotal Loss: 0.064886, Discriminator: 0.043322; Generator: 0.021564,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:19,364 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.064888, Discriminator: 0.043322; Generator: 0.021566,\n",
      "D(x): 0.502, D(G(z)): 0.502\n",
      "2019-04-24 21:10:19,456 root         INFO     Train Epoch: 15 [5632/8000 (70%)]\tTotal Loss: 0.064890, Discriminator: 0.043322; Generator: 0.021568,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:19,548 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.064892, Discriminator: 0.043322; Generator: 0.021570,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:19,639 root         INFO     Train Epoch: 15 [6656/8000 (83%)]\tTotal Loss: 0.064893, Discriminator: 0.043322; Generator: 0.021571,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:19,732 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 0.064895, Discriminator: 0.043322; Generator: 0.021573,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:19,823 root         INFO     Train Epoch: 15 [7680/8000 (96%)]\tTotal Loss: 0.064897, Discriminator: 0.043322; Generator: 0.021575,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:19,908 root         INFO     ====> Epoch: 15 Average loss: 0.0649\n",
      "2019-04-24 21:10:19,955 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 0.064898, Discriminator: 0.043322; Generator: 0.021576,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:20,049 root         INFO     Train Epoch: 16 [512/8000 (6%)]\tTotal Loss: 0.064899, Discriminator: 0.043322; Generator: 0.021577,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:20,142 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 0.064901, Discriminator: 0.043322; Generator: 0.021579,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:20,234 root         INFO     Train Epoch: 16 [1536/8000 (19%)]\tTotal Loss: 0.064902, Discriminator: 0.043322; Generator: 0.021580,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:20,327 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.064904, Discriminator: 0.043322; Generator: 0.021582,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:20,420 root         INFO     Train Epoch: 16 [2560/8000 (32%)]\tTotal Loss: 0.064905, Discriminator: 0.043322; Generator: 0.021583,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:20,513 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 0.064907, Discriminator: 0.043322; Generator: 0.021585,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:20,606 root         INFO     Train Epoch: 16 [3584/8000 (45%)]\tTotal Loss: 0.064908, Discriminator: 0.043322; Generator: 0.021586,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:20,700 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 0.064909, Discriminator: 0.043322; Generator: 0.021588,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:20,793 root         INFO     Train Epoch: 16 [4608/8000 (58%)]\tTotal Loss: 0.064911, Discriminator: 0.043322; Generator: 0.021589,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:20,887 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 0.064912, Discriminator: 0.043322; Generator: 0.021590,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:20,980 root         INFO     Train Epoch: 16 [5632/8000 (70%)]\tTotal Loss: 0.064913, Discriminator: 0.043322; Generator: 0.021592,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:21,073 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 0.064915, Discriminator: 0.043322; Generator: 0.021593,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:21,167 root         INFO     Train Epoch: 16 [6656/8000 (83%)]\tTotal Loss: 0.064916, Discriminator: 0.043322; Generator: 0.021594,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:21,260 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.064917, Discriminator: 0.043322; Generator: 0.021595,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:21,352 root         INFO     Train Epoch: 16 [7680/8000 (96%)]\tTotal Loss: 0.064918, Discriminator: 0.043322; Generator: 0.021597,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:21,437 root         INFO     ====> Epoch: 16 Average loss: 0.0649\n",
      "2019-04-24 21:10:21,484 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.064919, Discriminator: 0.043322; Generator: 0.021597,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:21,578 root         INFO     Train Epoch: 17 [512/8000 (6%)]\tTotal Loss: 0.064920, Discriminator: 0.043322; Generator: 0.021599,\n",
      "D(x): 0.501, D(G(z)): 0.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:10:21,672 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 0.064922, Discriminator: 0.043322; Generator: 0.021600,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:21,766 root         INFO     Train Epoch: 17 [1536/8000 (19%)]\tTotal Loss: 0.064923, Discriminator: 0.043322; Generator: 0.021601,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:21,858 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.064924, Discriminator: 0.043322; Generator: 0.021602,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:21,951 root         INFO     Train Epoch: 17 [2560/8000 (32%)]\tTotal Loss: 0.064925, Discriminator: 0.043322; Generator: 0.021603,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:22,042 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 0.064926, Discriminator: 0.043322; Generator: 0.021604,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:22,134 root         INFO     Train Epoch: 17 [3584/8000 (45%)]\tTotal Loss: 0.064927, Discriminator: 0.043322; Generator: 0.021605,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:22,226 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.064928, Discriminator: 0.043322; Generator: 0.021606,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:22,317 root         INFO     Train Epoch: 17 [4608/8000 (58%)]\tTotal Loss: 0.064929, Discriminator: 0.043322; Generator: 0.021607,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:22,409 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 0.064930, Discriminator: 0.043322; Generator: 0.021608,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:22,500 root         INFO     Train Epoch: 17 [5632/8000 (70%)]\tTotal Loss: 0.064931, Discriminator: 0.043322; Generator: 0.021609,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:22,590 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 0.064932, Discriminator: 0.043322; Generator: 0.021610,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:22,681 root         INFO     Train Epoch: 17 [6656/8000 (83%)]\tTotal Loss: 0.064933, Discriminator: 0.043322; Generator: 0.021611,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:22,772 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 0.064934, Discriminator: 0.043322; Generator: 0.021612,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:22,863 root         INFO     Train Epoch: 17 [7680/8000 (96%)]\tTotal Loss: 0.064935, Discriminator: 0.043322; Generator: 0.021613,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:22,947 root         INFO     ====> Epoch: 17 Average loss: 0.0649\n",
      "2019-04-24 21:10:22,995 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 0.064935, Discriminator: 0.043322; Generator: 0.021614,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:23,085 root         INFO     Train Epoch: 18 [512/8000 (6%)]\tTotal Loss: 0.064936, Discriminator: 0.043322; Generator: 0.021614,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:23,175 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.064937, Discriminator: 0.043322; Generator: 0.021615,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:23,265 root         INFO     Train Epoch: 18 [1536/8000 (19%)]\tTotal Loss: 0.064938, Discriminator: 0.043322; Generator: 0.021616,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:23,355 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 0.064939, Discriminator: 0.043322; Generator: 0.021617,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:23,446 root         INFO     Train Epoch: 18 [2560/8000 (32%)]\tTotal Loss: 0.064940, Discriminator: 0.043322; Generator: 0.021618,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:23,536 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.064940, Discriminator: 0.043322; Generator: 0.021619,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:23,625 root         INFO     Train Epoch: 18 [3584/8000 (45%)]\tTotal Loss: 0.064941, Discriminator: 0.043322; Generator: 0.021619,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:23,716 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 0.064942, Discriminator: 0.043322; Generator: 0.021620,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:23,806 root         INFO     Train Epoch: 18 [4608/8000 (58%)]\tTotal Loss: 0.064943, Discriminator: 0.043322; Generator: 0.021621,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:23,896 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.064943, Discriminator: 0.043322; Generator: 0.021622,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:23,987 root         INFO     Train Epoch: 18 [5632/8000 (70%)]\tTotal Loss: 0.064944, Discriminator: 0.043322; Generator: 0.021622,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:24,077 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 0.064945, Discriminator: 0.043322; Generator: 0.021623,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:24,167 root         INFO     Train Epoch: 18 [6656/8000 (83%)]\tTotal Loss: 0.064946, Discriminator: 0.043322; Generator: 0.021624,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:24,257 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 0.064946, Discriminator: 0.043322; Generator: 0.021625,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:24,349 root         INFO     Train Epoch: 18 [7680/8000 (96%)]\tTotal Loss: 0.064947, Discriminator: 0.043322; Generator: 0.021625,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:24,433 root         INFO     ====> Epoch: 18 Average loss: 0.0649\n",
      "2019-04-24 21:10:24,480 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 0.064947, Discriminator: 0.043322; Generator: 0.021626,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:24,573 root         INFO     Train Epoch: 19 [512/8000 (6%)]\tTotal Loss: 0.064948, Discriminator: 0.043322; Generator: 0.021626,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:24,665 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 0.064949, Discriminator: 0.043322; Generator: 0.021627,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:24,757 root         INFO     Train Epoch: 19 [1536/8000 (19%)]\tTotal Loss: 0.064949, Discriminator: 0.043322; Generator: 0.021628,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:24,846 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 0.064950, Discriminator: 0.043322; Generator: 0.021628,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:24,935 root         INFO     Train Epoch: 19 [2560/8000 (32%)]\tTotal Loss: 0.064951, Discriminator: 0.043322; Generator: 0.021629,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:25,024 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 0.064951, Discriminator: 0.043322; Generator: 0.021629,\n",
      "D(x): 0.501, D(G(z)): 0.501\n",
      "2019-04-24 21:10:25,113 root         INFO     Train Epoch: 19 [3584/8000 (45%)]\tTotal Loss: 0.064952, Discriminator: 0.043322; Generator: 0.021630,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:25,203 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 0.064952, Discriminator: 0.043322; Generator: 0.021631,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:25,292 root         INFO     Train Epoch: 19 [4608/8000 (58%)]\tTotal Loss: 0.064953, Discriminator: 0.043322; Generator: 0.021631,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:25,382 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 0.064953, Discriminator: 0.043322; Generator: 0.021632,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:25,471 root         INFO     Train Epoch: 19 [5632/8000 (70%)]\tTotal Loss: 0.064954, Discriminator: 0.043322; Generator: 0.021632,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:25,560 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 0.064954, Discriminator: 0.043322; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:25,649 root         INFO     Train Epoch: 19 [6656/8000 (83%)]\tTotal Loss: 0.064955, Discriminator: 0.043322; Generator: 0.021633,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:25,738 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.064956, Discriminator: 0.043322; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:25,828 root         INFO     Train Epoch: 19 [7680/8000 (96%)]\tTotal Loss: 0.064956, Discriminator: 0.043322; Generator: 0.021634,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:10:25,911 root         INFO     ====> Epoch: 19 Average loss: 0.0650\n",
      "2019-04-24 21:10:25,959 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 0.064956, Discriminator: 0.043322; Generator: 0.021635,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:26,049 root         INFO     Train Epoch: 20 [512/8000 (6%)]\tTotal Loss: 0.064957, Discriminator: 0.043322; Generator: 0.021635,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:26,138 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 0.064957, Discriminator: 0.043322; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:26,227 root         INFO     Train Epoch: 20 [1536/8000 (19%)]\tTotal Loss: 0.064958, Discriminator: 0.043322; Generator: 0.021636,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:26,316 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 0.064958, Discriminator: 0.043322; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:26,404 root         INFO     Train Epoch: 20 [2560/8000 (32%)]\tTotal Loss: 0.064959, Discriminator: 0.043322; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:26,493 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 0.064959, Discriminator: 0.043322; Generator: 0.021637,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:26,582 root         INFO     Train Epoch: 20 [3584/8000 (45%)]\tTotal Loss: 0.064960, Discriminator: 0.043322; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:26,670 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 0.064960, Discriminator: 0.043322; Generator: 0.021638,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:26,758 root         INFO     Train Epoch: 20 [4608/8000 (58%)]\tTotal Loss: 0.064960, Discriminator: 0.043322; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:26,847 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 0.064961, Discriminator: 0.043322; Generator: 0.021639,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:26,935 root         INFO     Train Epoch: 20 [5632/8000 (70%)]\tTotal Loss: 0.064961, Discriminator: 0.043322; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:27,024 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 0.064962, Discriminator: 0.043322; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:27,112 root         INFO     Train Epoch: 20 [6656/8000 (83%)]\tTotal Loss: 0.064962, Discriminator: 0.043322; Generator: 0.021640,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:27,201 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 0.064962, Discriminator: 0.043322; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:27,290 root         INFO     Train Epoch: 20 [7680/8000 (96%)]\tTotal Loss: 0.064963, Discriminator: 0.043322; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:27,373 root         INFO     ====> Epoch: 20 Average loss: 0.0650\n",
      "2019-04-24 21:10:27,421 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.064963, Discriminator: 0.043322; Generator: 0.021641,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:27,512 root         INFO     Train Epoch: 21 [512/8000 (6%)]\tTotal Loss: 0.064963, Discriminator: 0.043322; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:27,603 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 0.064964, Discriminator: 0.043322; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:27,694 root         INFO     Train Epoch: 21 [1536/8000 (19%)]\tTotal Loss: 0.064964, Discriminator: 0.043322; Generator: 0.021642,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:27,786 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 0.064964, Discriminator: 0.043322; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:27,876 root         INFO     Train Epoch: 21 [2560/8000 (32%)]\tTotal Loss: 0.064965, Discriminator: 0.043322; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:27,969 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 0.064965, Discriminator: 0.043322; Generator: 0.021643,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:28,061 root         INFO     Train Epoch: 21 [3584/8000 (45%)]\tTotal Loss: 0.064965, Discriminator: 0.043322; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:28,152 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.064966, Discriminator: 0.043322; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:28,245 root         INFO     Train Epoch: 21 [4608/8000 (58%)]\tTotal Loss: 0.064966, Discriminator: 0.043322; Generator: 0.021644,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:28,338 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 0.064966, Discriminator: 0.043322; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:28,428 root         INFO     Train Epoch: 21 [5632/8000 (70%)]\tTotal Loss: 0.064967, Discriminator: 0.043322; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:28,520 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 0.064967, Discriminator: 0.043322; Generator: 0.021645,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:28,611 root         INFO     Train Epoch: 21 [6656/8000 (83%)]\tTotal Loss: 0.064967, Discriminator: 0.043322; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:28,701 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.064968, Discriminator: 0.043322; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:28,794 root         INFO     Train Epoch: 21 [7680/8000 (96%)]\tTotal Loss: 0.064968, Discriminator: 0.043322; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:28,879 root         INFO     ====> Epoch: 21 Average loss: 0.0650\n",
      "2019-04-24 21:10:28,926 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 0.064968, Discriminator: 0.043322; Generator: 0.021646,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:29,017 root         INFO     Train Epoch: 22 [512/8000 (6%)]\tTotal Loss: 0.064968, Discriminator: 0.043322; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:29,107 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 0.064969, Discriminator: 0.043322; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:29,199 root         INFO     Train Epoch: 22 [1536/8000 (19%)]\tTotal Loss: 0.064969, Discriminator: 0.043322; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:29,290 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 0.064969, Discriminator: 0.043322; Generator: 0.021647,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:29,381 root         INFO     Train Epoch: 22 [2560/8000 (32%)]\tTotal Loss: 0.064969, Discriminator: 0.043322; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:29,473 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 0.064970, Discriminator: 0.043322; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:29,564 root         INFO     Train Epoch: 22 [3584/8000 (45%)]\tTotal Loss: 0.064970, Discriminator: 0.043322; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:29,656 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.064970, Discriminator: 0.043322; Generator: 0.021648,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:29,747 root         INFO     Train Epoch: 22 [4608/8000 (58%)]\tTotal Loss: 0.064970, Discriminator: 0.043322; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:29,837 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 0.064970, Discriminator: 0.043322; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:29,929 root         INFO     Train Epoch: 22 [5632/8000 (70%)]\tTotal Loss: 0.064971, Discriminator: 0.043322; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:30,018 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 0.064971, Discriminator: 0.043322; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:30,107 root         INFO     Train Epoch: 22 [6656/8000 (83%)]\tTotal Loss: 0.064971, Discriminator: 0.043322; Generator: 0.021649,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:10:30,197 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 0.064971, Discriminator: 0.043322; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:30,288 root         INFO     Train Epoch: 22 [7680/8000 (96%)]\tTotal Loss: 0.064972, Discriminator: 0.043322; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:30,371 root         INFO     ====> Epoch: 22 Average loss: 0.0650\n",
      "2019-04-24 21:10:30,419 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 0.064972, Discriminator: 0.043322; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:30,510 root         INFO     Train Epoch: 23 [512/8000 (6%)]\tTotal Loss: 0.064972, Discriminator: 0.043322; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:30,601 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 0.064972, Discriminator: 0.043322; Generator: 0.021650,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:30,693 root         INFO     Train Epoch: 23 [1536/8000 (19%)]\tTotal Loss: 0.064972, Discriminator: 0.043322; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:30,787 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 0.064972, Discriminator: 0.043322; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:30,880 root         INFO     Train Epoch: 23 [2560/8000 (32%)]\tTotal Loss: 0.064973, Discriminator: 0.043322; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:30,973 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 0.064973, Discriminator: 0.043322; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:31,066 root         INFO     Train Epoch: 23 [3584/8000 (45%)]\tTotal Loss: 0.064973, Discriminator: 0.043322; Generator: 0.021651,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:31,159 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 0.064973, Discriminator: 0.043322; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:31,252 root         INFO     Train Epoch: 23 [4608/8000 (58%)]\tTotal Loss: 0.064973, Discriminator: 0.043322; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:31,342 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 0.064974, Discriminator: 0.043322; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:31,431 root         INFO     Train Epoch: 23 [5632/8000 (70%)]\tTotal Loss: 0.064974, Discriminator: 0.043322; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:31,520 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 0.064974, Discriminator: 0.043322; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:31,611 root         INFO     Train Epoch: 23 [6656/8000 (83%)]\tTotal Loss: 0.064974, Discriminator: 0.043322; Generator: 0.021652,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:31,701 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 0.064974, Discriminator: 0.043322; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:31,792 root         INFO     Train Epoch: 23 [7680/8000 (96%)]\tTotal Loss: 0.064974, Discriminator: 0.043322; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:31,876 root         INFO     ====> Epoch: 23 Average loss: 0.0650\n",
      "2019-04-24 21:10:31,923 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.064974, Discriminator: 0.043322; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:32,014 root         INFO     Train Epoch: 24 [512/8000 (6%)]\tTotal Loss: 0.064975, Discriminator: 0.043322; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:32,103 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 0.064975, Discriminator: 0.043322; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:32,192 root         INFO     Train Epoch: 24 [1536/8000 (19%)]\tTotal Loss: 0.064975, Discriminator: 0.043322; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:32,280 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 0.064975, Discriminator: 0.043322; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:32,370 root         INFO     Train Epoch: 24 [2560/8000 (32%)]\tTotal Loss: 0.064975, Discriminator: 0.043322; Generator: 0.021653,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:32,459 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 0.064975, Discriminator: 0.043322; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:32,551 root         INFO     Train Epoch: 24 [3584/8000 (45%)]\tTotal Loss: 0.064975, Discriminator: 0.043322; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:32,642 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 0.064976, Discriminator: 0.043322; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:32,733 root         INFO     Train Epoch: 24 [4608/8000 (58%)]\tTotal Loss: 0.064976, Discriminator: 0.043322; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:32,822 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 0.064976, Discriminator: 0.043322; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:32,912 root         INFO     Train Epoch: 24 [5632/8000 (70%)]\tTotal Loss: 0.064976, Discriminator: 0.043322; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:33,002 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 0.064976, Discriminator: 0.043322; Generator: 0.021654,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:33,093 root         INFO     Train Epoch: 24 [6656/8000 (83%)]\tTotal Loss: 0.064976, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:33,182 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 0.064976, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:33,273 root         INFO     Train Epoch: 24 [7680/8000 (96%)]\tTotal Loss: 0.064976, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:33,357 root         INFO     ====> Epoch: 24 Average loss: 0.0650\n",
      "2019-04-24 21:10:33,403 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 0.064977, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:33,494 root         INFO     Train Epoch: 25 [512/8000 (6%)]\tTotal Loss: 0.064977, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:33,583 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 0.064977, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:33,674 root         INFO     Train Epoch: 25 [1536/8000 (19%)]\tTotal Loss: 0.064977, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:33,763 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 0.064977, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:33,853 root         INFO     Train Epoch: 25 [2560/8000 (32%)]\tTotal Loss: 0.064977, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:33,943 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 0.064977, Discriminator: 0.043322; Generator: 0.021655,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:34,033 root         INFO     Train Epoch: 25 [3584/8000 (45%)]\tTotal Loss: 0.064977, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:34,122 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 0.064977, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:34,212 root         INFO     Train Epoch: 25 [4608/8000 (58%)]\tTotal Loss: 0.064977, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:34,304 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 0.064978, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:34,396 root         INFO     Train Epoch: 25 [5632/8000 (70%)]\tTotal Loss: 0.064978, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:10:34,488 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.064978, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:34,580 root         INFO     Train Epoch: 25 [6656/8000 (83%)]\tTotal Loss: 0.064978, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:34,672 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 0.064978, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:34,764 root         INFO     Train Epoch: 25 [7680/8000 (96%)]\tTotal Loss: 0.064978, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:34,850 root         INFO     ====> Epoch: 25 Average loss: 0.0650\n",
      "2019-04-24 21:10:34,897 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 0.064978, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:34,991 root         INFO     Train Epoch: 26 [512/8000 (6%)]\tTotal Loss: 0.064978, Discriminator: 0.043322; Generator: 0.021656,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:35,083 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 0.064978, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:35,176 root         INFO     Train Epoch: 26 [1536/8000 (19%)]\tTotal Loss: 0.064978, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:35,267 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 0.064978, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:35,359 root         INFO     Train Epoch: 26 [2560/8000 (32%)]\tTotal Loss: 0.064978, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:35,452 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:35,543 root         INFO     Train Epoch: 26 [3584/8000 (45%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:35,635 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:35,726 root         INFO     Train Epoch: 26 [4608/8000 (58%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:35,818 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:35,910 root         INFO     Train Epoch: 26 [5632/8000 (70%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:36,001 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:36,091 root         INFO     Train Epoch: 26 [6656/8000 (83%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:36,183 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:36,273 root         INFO     Train Epoch: 26 [7680/8000 (96%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:36,357 root         INFO     ====> Epoch: 26 Average loss: 0.0650\n",
      "2019-04-24 21:10:36,404 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021657,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:36,496 root         INFO     Train Epoch: 27 [512/8000 (6%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:36,585 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:36,675 root         INFO     Train Epoch: 27 [1536/8000 (19%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:36,765 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:36,857 root         INFO     Train Epoch: 27 [2560/8000 (32%)]\tTotal Loss: 0.064979, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:36,947 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:37,038 root         INFO     Train Epoch: 27 [3584/8000 (45%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:37,128 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:37,219 root         INFO     Train Epoch: 27 [4608/8000 (58%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:37,310 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:37,400 root         INFO     Train Epoch: 27 [5632/8000 (70%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:37,491 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:37,583 root         INFO     Train Epoch: 27 [6656/8000 (83%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:37,675 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:37,767 root         INFO     Train Epoch: 27 [7680/8000 (96%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:37,852 root         INFO     ====> Epoch: 27 Average loss: 0.0650\n",
      "2019-04-24 21:10:37,899 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:37,993 root         INFO     Train Epoch: 28 [512/8000 (6%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:38,085 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:38,176 root         INFO     Train Epoch: 28 [1536/8000 (19%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021658,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:38,267 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:38,358 root         INFO     Train Epoch: 28 [2560/8000 (32%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:38,449 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:38,540 root         INFO     Train Epoch: 28 [3584/8000 (45%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:38,631 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:38,722 root         INFO     Train Epoch: 28 [4608/8000 (58%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:10:38,813 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:38,905 root         INFO     Train Epoch: 28 [5632/8000 (70%)]\tTotal Loss: 0.064980, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:38,996 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:39,087 root         INFO     Train Epoch: 28 [6656/8000 (83%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:39,178 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:39,268 root         INFO     Train Epoch: 28 [7680/8000 (96%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:39,352 root         INFO     ====> Epoch: 28 Average loss: 0.0650\n",
      "2019-04-24 21:10:39,400 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:39,492 root         INFO     Train Epoch: 29 [512/8000 (6%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:39,582 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:39,671 root         INFO     Train Epoch: 29 [1536/8000 (19%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:39,760 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:39,849 root         INFO     Train Epoch: 29 [2560/8000 (32%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:39,938 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:40,027 root         INFO     Train Epoch: 29 [3584/8000 (45%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:40,118 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:40,209 root         INFO     Train Epoch: 29 [4608/8000 (58%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:40,299 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:40,389 root         INFO     Train Epoch: 29 [5632/8000 (70%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:40,480 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:40,570 root         INFO     Train Epoch: 29 [6656/8000 (83%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:40,662 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:40,753 root         INFO     Train Epoch: 29 [7680/8000 (96%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:40,837 root         INFO     ====> Epoch: 29 Average loss: 0.0650\n",
      "2019-04-24 21:10:40,885 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:40,978 root         INFO     Train Epoch: 30 [512/8000 (6%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:41,070 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021659,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:41,162 root         INFO     Train Epoch: 30 [1536/8000 (19%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:41,254 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:41,346 root         INFO     Train Epoch: 30 [2560/8000 (32%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:41,438 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:41,530 root         INFO     Train Epoch: 30 [3584/8000 (45%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:41,622 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:41,714 root         INFO     Train Epoch: 30 [4608/8000 (58%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:41,806 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:41,899 root         INFO     Train Epoch: 30 [5632/8000 (70%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:41,991 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:42,084 root         INFO     Train Epoch: 30 [6656/8000 (83%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:42,176 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:42,268 root         INFO     Train Epoch: 30 [7680/8000 (96%)]\tTotal Loss: 0.064981, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:42,352 root         INFO     ====> Epoch: 30 Average loss: 0.0650\n",
      "2019-04-24 21:10:42,400 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:42,493 root         INFO     Train Epoch: 31 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:42,584 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:42,676 root         INFO     Train Epoch: 31 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:42,767 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:42,858 root         INFO     Train Epoch: 31 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:42,949 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:43,040 root         INFO     Train Epoch: 31 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:10:43,133 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:43,224 root         INFO     Train Epoch: 31 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:43,314 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:43,405 root         INFO     Train Epoch: 31 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:43,496 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:43,587 root         INFO     Train Epoch: 31 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:43,677 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:43,768 root         INFO     Train Epoch: 31 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:43,852 root         INFO     ====> Epoch: 31 Average loss: 0.0650\n",
      "2019-04-24 21:10:43,900 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:43,992 root         INFO     Train Epoch: 32 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:44,084 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:44,174 root         INFO     Train Epoch: 32 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:44,268 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:44,360 root         INFO     Train Epoch: 32 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:44,452 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:44,544 root         INFO     Train Epoch: 32 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:44,635 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:44,727 root         INFO     Train Epoch: 32 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:44,819 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:44,911 root         INFO     Train Epoch: 32 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:45,003 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:45,095 root         INFO     Train Epoch: 32 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:45,186 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:45,278 root         INFO     Train Epoch: 32 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:45,363 root         INFO     ====> Epoch: 32 Average loss: 0.0650\n",
      "2019-04-24 21:10:45,409 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:45,500 root         INFO     Train Epoch: 33 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:45,589 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:45,678 root         INFO     Train Epoch: 33 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:45,767 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:45,857 root         INFO     Train Epoch: 33 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:45,946 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:46,035 root         INFO     Train Epoch: 33 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:46,125 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:46,214 root         INFO     Train Epoch: 33 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:46,303 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:46,392 root         INFO     Train Epoch: 33 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:46,482 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:46,570 root         INFO     Train Epoch: 33 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:46,659 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:46,747 root         INFO     Train Epoch: 33 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:46,830 root         INFO     ====> Epoch: 33 Average loss: 0.0650\n",
      "2019-04-24 21:10:46,878 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:46,967 root         INFO     Train Epoch: 34 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:47,056 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:47,145 root         INFO     Train Epoch: 34 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:47,234 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:47,323 root         INFO     Train Epoch: 34 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:10:47,411 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:47,500 root         INFO     Train Epoch: 34 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:47,588 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:47,676 root         INFO     Train Epoch: 34 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:47,765 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:47,856 root         INFO     Train Epoch: 34 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021660,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:47,947 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:48,038 root         INFO     Train Epoch: 34 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:48,129 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:48,221 root         INFO     Train Epoch: 34 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:48,305 root         INFO     ====> Epoch: 34 Average loss: 0.0650\n",
      "2019-04-24 21:10:48,352 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:48,445 root         INFO     Train Epoch: 35 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:48,539 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:48,633 root         INFO     Train Epoch: 35 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:48,727 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:48,820 root         INFO     Train Epoch: 35 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:48,912 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:49,006 root         INFO     Train Epoch: 35 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:49,097 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:49,188 root         INFO     Train Epoch: 35 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:49,280 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:49,371 root         INFO     Train Epoch: 35 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:49,463 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:49,553 root         INFO     Train Epoch: 35 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:49,645 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:49,736 root         INFO     Train Epoch: 35 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:49,821 root         INFO     ====> Epoch: 35 Average loss: 0.0650\n",
      "2019-04-24 21:10:49,867 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:49,959 root         INFO     Train Epoch: 36 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:50,050 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:50,141 root         INFO     Train Epoch: 36 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:50,231 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:50,323 root         INFO     Train Epoch: 36 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:50,415 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:50,507 root         INFO     Train Epoch: 36 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:50,598 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:50,688 root         INFO     Train Epoch: 36 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:50,781 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:50,871 root         INFO     Train Epoch: 36 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:50,962 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:51,053 root         INFO     Train Epoch: 36 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:51,144 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:51,235 root         INFO     Train Epoch: 36 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:51,320 root         INFO     ====> Epoch: 36 Average loss: 0.0650\n",
      "2019-04-24 21:10:51,368 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:51,461 root         INFO     Train Epoch: 37 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:51,553 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:51,646 root         INFO     Train Epoch: 37 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:10:51,738 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:51,830 root         INFO     Train Epoch: 37 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:51,923 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:52,013 root         INFO     Train Epoch: 37 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:52,105 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:52,197 root         INFO     Train Epoch: 37 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:52,290 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:52,382 root         INFO     Train Epoch: 37 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:52,474 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:52,566 root         INFO     Train Epoch: 37 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:52,658 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:52,750 root         INFO     Train Epoch: 37 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:52,834 root         INFO     ====> Epoch: 37 Average loss: 0.0650\n",
      "2019-04-24 21:10:52,881 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:52,974 root         INFO     Train Epoch: 38 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:53,067 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:53,161 root         INFO     Train Epoch: 38 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:53,252 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:53,345 root         INFO     Train Epoch: 38 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:53,437 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:53,530 root         INFO     Train Epoch: 38 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:53,623 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:53,716 root         INFO     Train Epoch: 38 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:53,809 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:53,902 root         INFO     Train Epoch: 38 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:53,995 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:54,089 root         INFO     Train Epoch: 38 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:54,182 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:54,275 root         INFO     Train Epoch: 38 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:54,360 root         INFO     ====> Epoch: 38 Average loss: 0.0650\n",
      "2019-04-24 21:10:54,407 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:54,501 root         INFO     Train Epoch: 39 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:54,593 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:54,685 root         INFO     Train Epoch: 39 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:54,778 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:54,870 root         INFO     Train Epoch: 39 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:54,963 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:55,055 root         INFO     Train Epoch: 39 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:55,148 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:55,241 root         INFO     Train Epoch: 39 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:55,333 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:55,426 root         INFO     Train Epoch: 39 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:55,518 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:55,610 root         INFO     Train Epoch: 39 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:55,700 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:55,790 root         INFO     Train Epoch: 39 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:55,875 root         INFO     ====> Epoch: 39 Average loss: 0.0650\n",
      "2019-04-24 21:10:55,922 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:56,015 root         INFO     Train Epoch: 40 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:10:56,107 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:56,200 root         INFO     Train Epoch: 40 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:56,292 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:56,384 root         INFO     Train Epoch: 40 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:56,478 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:56,572 root         INFO     Train Epoch: 40 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:56,665 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:56,758 root         INFO     Train Epoch: 40 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:56,852 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:56,945 root         INFO     Train Epoch: 40 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:57,039 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:57,132 root         INFO     Train Epoch: 40 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:57,224 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:57,316 root         INFO     Train Epoch: 40 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:57,400 root         INFO     ====> Epoch: 40 Average loss: 0.0650\n",
      "2019-04-24 21:10:57,447 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:57,537 root         INFO     Train Epoch: 41 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:57,628 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:57,718 root         INFO     Train Epoch: 41 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:57,808 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:57,898 root         INFO     Train Epoch: 41 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:57,989 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:58,082 root         INFO     Train Epoch: 41 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:58,173 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:58,267 root         INFO     Train Epoch: 41 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:58,360 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:58,451 root         INFO     Train Epoch: 41 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:58,544 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:58,636 root         INFO     Train Epoch: 41 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:58,728 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:58,820 root         INFO     Train Epoch: 41 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:58,905 root         INFO     ====> Epoch: 41 Average loss: 0.0650\n",
      "2019-04-24 21:10:58,952 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:59,044 root         INFO     Train Epoch: 42 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:59,134 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:59,226 root         INFO     Train Epoch: 42 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:59,316 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:59,407 root         INFO     Train Epoch: 42 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:59,500 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:59,592 root         INFO     Train Epoch: 42 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:59,684 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:59,776 root         INFO     Train Epoch: 42 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:59,868 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:10:59,961 root         INFO     Train Epoch: 42 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:00,053 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:00,145 root         INFO     Train Epoch: 42 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:00,237 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:00,331 root         INFO     Train Epoch: 42 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:11:00,416 root         INFO     ====> Epoch: 42 Average loss: 0.0650\n",
      "2019-04-24 21:11:00,463 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:00,555 root         INFO     Train Epoch: 43 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:00,645 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:00,737 root         INFO     Train Epoch: 43 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:00,828 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:00,919 root         INFO     Train Epoch: 43 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:01,010 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:01,101 root         INFO     Train Epoch: 43 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:01,192 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:01,283 root         INFO     Train Epoch: 43 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:01,374 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:01,465 root         INFO     Train Epoch: 43 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:01,556 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:01,647 root         INFO     Train Epoch: 43 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:01,738 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:01,829 root         INFO     Train Epoch: 43 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:01,913 root         INFO     ====> Epoch: 43 Average loss: 0.0650\n",
      "2019-04-24 21:11:01,960 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:02,052 root         INFO     Train Epoch: 44 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:02,143 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:02,234 root         INFO     Train Epoch: 44 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:02,326 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:02,417 root         INFO     Train Epoch: 44 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:02,508 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:02,598 root         INFO     Train Epoch: 44 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:02,688 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:02,778 root         INFO     Train Epoch: 44 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:02,868 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:02,958 root         INFO     Train Epoch: 44 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:03,049 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:03,140 root         INFO     Train Epoch: 44 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:03,229 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:03,318 root         INFO     Train Epoch: 44 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:03,401 root         INFO     ====> Epoch: 44 Average loss: 0.0650\n",
      "2019-04-24 21:11:03,448 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:03,541 root         INFO     Train Epoch: 45 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:03,633 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:03,724 root         INFO     Train Epoch: 45 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:03,815 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:03,906 root         INFO     Train Epoch: 45 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:03,996 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:04,087 root         INFO     Train Epoch: 45 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:04,178 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:04,269 root         INFO     Train Epoch: 45 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:04,360 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:04,450 root         INFO     Train Epoch: 45 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:04,539 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:04,628 root         INFO     Train Epoch: 45 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:11:04,717 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:04,806 root         INFO     Train Epoch: 45 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:04,889 root         INFO     ====> Epoch: 45 Average loss: 0.0650\n",
      "2019-04-24 21:11:04,937 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:05,030 root         INFO     Train Epoch: 46 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:05,121 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:05,212 root         INFO     Train Epoch: 46 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:05,304 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:05,395 root         INFO     Train Epoch: 46 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:05,487 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:05,580 root         INFO     Train Epoch: 46 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:05,672 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:05,763 root         INFO     Train Epoch: 46 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:05,855 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:05,946 root         INFO     Train Epoch: 46 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:06,038 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:06,130 root         INFO     Train Epoch: 46 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:06,221 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:06,312 root         INFO     Train Epoch: 46 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:06,397 root         INFO     ====> Epoch: 46 Average loss: 0.0650\n",
      "2019-04-24 21:11:06,444 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:06,536 root         INFO     Train Epoch: 47 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:06,627 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:06,719 root         INFO     Train Epoch: 47 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:06,810 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:06,901 root         INFO     Train Epoch: 47 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:06,993 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:07,084 root         INFO     Train Epoch: 47 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:07,175 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:07,266 root         INFO     Train Epoch: 47 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:07,358 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:07,450 root         INFO     Train Epoch: 47 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:07,541 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:07,633 root         INFO     Train Epoch: 47 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:07,724 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:07,816 root         INFO     Train Epoch: 47 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:07,901 root         INFO     ====> Epoch: 47 Average loss: 0.0650\n",
      "2019-04-24 21:11:07,949 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:08,043 root         INFO     Train Epoch: 48 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:08,136 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:08,228 root         INFO     Train Epoch: 48 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:08,321 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:08,410 root         INFO     Train Epoch: 48 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:08,500 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:08,590 root         INFO     Train Epoch: 48 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:08,681 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:08,771 root         INFO     Train Epoch: 48 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:08,862 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:08,952 root         INFO     Train Epoch: 48 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:11:09,042 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:09,133 root         INFO     Train Epoch: 48 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:09,223 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:09,314 root         INFO     Train Epoch: 48 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:09,397 root         INFO     ====> Epoch: 48 Average loss: 0.0650\n",
      "2019-04-24 21:11:09,444 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:09,536 root         INFO     Train Epoch: 49 [512/8000 (6%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:09,626 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:09,716 root         INFO     Train Epoch: 49 [1536/8000 (19%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:09,806 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:09,896 root         INFO     Train Epoch: 49 [2560/8000 (32%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:09,986 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:10,076 root         INFO     Train Epoch: 49 [3584/8000 (45%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:10,168 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:10,259 root         INFO     Train Epoch: 49 [4608/8000 (58%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:10,353 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:10,446 root         INFO     Train Epoch: 49 [5632/8000 (70%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:10,537 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:10,627 root         INFO     Train Epoch: 49 [6656/8000 (83%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:10,718 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:10,808 root         INFO     Train Epoch: 49 [7680/8000 (96%)]\tTotal Loss: 0.064982, Discriminator: 0.043322; Generator: 0.021661,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-04-24 21:11:10,892 root         INFO     ====> Epoch: 49 Average loss: 0.0650\n"
     ]
    }
   ],
   "source": [
    "logging.info('--Dataset tensor: (%d, %d)' % dataset.shape)\n",
    "\n",
    "n_train = int((1 - FRAC_TEST) * N_SAMPLES)\n",
    "train = torch.Tensor(dataset[:n_train, :])\n",
    "\n",
    "logging.info('-- Train tensor: (%d, %d)' % train.shape)\n",
    "train_dataset = torch.utils.data.TensorDataset(train)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "train_dataset, batch_size=BATCH_SIZE, shuffle=True, **KWARGS)\n",
    "\n",
    "decoder = toynn.Decoder(\n",
    "            latent_dim=LATENT_DIM,\n",
    "            data_dim=DATA_DIM,\n",
    "            n_layers=N_DECODER_LAYERS,\n",
    "            nonlinearity=NONLINEARITY,\n",
    "            with_biasx=WITH_BIASX,\n",
    "            with_logvarx=WITH_LOGVARX).to(DEVICE)\n",
    "\n",
    "# Set the value of the decoder to the biased value we know happens\n",
    "\n",
    "decoder.layers[0].weight.data = torch.tensor([[1.10]]).to(DEVICE)\n",
    "\n",
    "discriminator = toynn.Discriminator(data_dim=DATA_DIM).to(DEVICE)\n",
    "\n",
    "modules = {}\n",
    "modules['decoder'] = decoder\n",
    "modules['discriminator'] = discriminator\n",
    "\n",
    "logging.info('Values of VAE\\'s decoder parameters before training:')\n",
    "for name, param in decoder.named_parameters():\n",
    "    logging.info(name)\n",
    "    logging.info(param.data)\n",
    "\n",
    "optimizers = {}\n",
    "optimizers['decoder'] = torch.optim.Adam(\n",
    "    modules['decoder'].parameters(), lr=LR, betas=(BETA1, BETA2))\n",
    "optimizers['discriminator'] = torch.optim.SGD(\n",
    "    modules['discriminator'].parameters(), lr=LR)\n",
    "\n",
    "\n",
    "def init_xavier_normal(m):\n",
    "    if type(m) == tnn.Linear:\n",
    "        tnn.init.xavier_normal_(m.weight)\n",
    "\n",
    "    for module in modules.values():\n",
    "        module.apply(init_xavier_normal)\n",
    "\n",
    "train_losses_all_epochs = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    if DEBUG:\n",
    "        if epoch > 2:\n",
    "            break\n",
    "\n",
    "    train_losses = train_gan(\n",
    "                epoch, train_loader, modules, optimizers)\n",
    "    train_losses_all_epochs.append(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 21:11:10,910 root         INFO     Values of VAE's decoder parameters after training:\n",
      "2019-04-24 21:11:10,910 root         INFO     layers.0.weight\n",
      "2019-04-24 21:11:10,910 root         INFO     tensor([[1.1000]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last losses:\n",
      "[0.06498245894908905, 0.06498245894908905, 0.06498245894908905, 0.06498245894908905, 0.06498245894908905]\n",
      "1.1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "plt.plot(range(n_epochs), train_losses_total)\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])\n",
    "\n",
    "logging.info('Values of VAE\\'s decoder parameters after training:')\n",
    "for name, param in decoder.named_parameters():\n",
    "    logging.info(name)\n",
    "    logging.info(param.data)\n",
    "    w_learnt = param.data[0,0].cpu().numpy()\n",
    "print(w_learnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f965bd7dac8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 10000\n",
    "#generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "generated_x = generate_synthetic_1d(w=w_learnt, n=n_samples)\n",
    "                                    \n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(dataset, color='darkgreen', ax=ax)\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(dataset, color='darkgreen', ax=ax, label='true')\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax, label='vae estimate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
