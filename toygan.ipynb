{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GAN / Discriminator part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:40:51,061 root         INFO     start\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.nn import functional as F\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import importlib\n",
    "import toylosses\n",
    "importlib.reload(toylosses)\n",
    "import toynn\n",
    "importlib.reload(toynn)\n",
    "import toyvis\n",
    "importlib.reload(toyvis)\n",
    "\n",
    "sns.set()\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "logging.basicConfig(\n",
    "        format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\n",
    "        level=logging.INFO)\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logging.info('start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(epoch, train_loader, modules, optimizers):\n",
    "    for module in modules.values():\n",
    "        module.train()\n",
    " \n",
    "    total_loss_discriminator = 0\n",
    "    total_loss_generator = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    n_data = len(train_loader.dataset)\n",
    "    n_batches = len(train_loader)\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        if DEBUG and batch_idx > 3:\n",
    "            continue\n",
    "\n",
    "        batch_data = batch_data[0].to(DEVICE)\n",
    "        n_batch_data = len(batch_data)\n",
    "\n",
    "        for optimizer in optimizers.values():\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        decoder = modules['decoder']\n",
    "\n",
    "        z_from_prior = toynn.sample_from_prior(\n",
    "                    LATENT_DIM, n_samples=n_batch_data).to(DEVICE)\n",
    "        batch_from_prior, batch_logvarx_from_prior = decoder(\n",
    "                    z_from_prior)\n",
    "\n",
    "        discriminator = modules['discriminator']\n",
    "\n",
    "        real_labels = torch.full((n_batch_data, 1), 1, device=DEVICE)\n",
    "        fake_labels = torch.full((n_batch_data, 1), 0, device=DEVICE)\n",
    "        #noise_for_real_labels = np.random.normal(loc=0, scale=0.1, size=(n_batch_data, 1))\n",
    "        #noise_for_fake_labels = np.random.normal(loc=0, scale=0.1, size=(n_batch_data, 1))\n",
    "        #real_labels = real_labels - torch.Tensor(np.abs(noise_for_real_labels)).to(DEVICE)\n",
    "        #fake_labels = fake_labels + torch.Tensor(np.abs(noise_for_fake_labels)).to(DEVICE)\n",
    "        \n",
    "        #noise_for_data = np.random.normal(loc=0, scale=2, size=(n_batch_data, 1))\n",
    "        #noise_for_prior = np.random.normal(loc=0, scale=2, size=(n_batch_data, 1))\n",
    "        noisy_batch_data = batch_data #+ torch.Tensor(noise_for_data).to(DEVICE)\n",
    "        noisy_batch_from_prior = batch_from_prior #+ torch.Tensor(noise_for_prior).to(DEVICE)\n",
    "\n",
    "        labels_data = discriminator(noisy_batch_data)\n",
    "        labels_from_prior = discriminator(noisy_batch_from_prior)\n",
    "\n",
    "        \n",
    "        criterion = torch.nn.BCELoss()\n",
    "        \n",
    "        loss_dis_data = criterion(\n",
    "                        labels_data,\n",
    "                        real_labels)\n",
    "        loss_dis_from_prior = criterion(\n",
    "                        labels_from_prior,\n",
    "                        fake_labels)\n",
    "\n",
    "        loss_discriminator = (\n",
    "                    loss_dis_data + loss_dis_from_prior)\n",
    "\n",
    "        loss_discriminator.backward(retain_graph=True)\n",
    "        #logging.info('Discriminator gradients')\n",
    "        #for name, param in discriminator.named_parameters():\n",
    "            #logging.info(name)\n",
    "            #logging.info(param.grad)\n",
    "        \n",
    "        optimizers['discriminator'].step()\n",
    "\n",
    "        loss_generator = criterion(\n",
    "                    labels_from_prior,\n",
    "                    real_labels)\n",
    "        loss_generator.backward()\n",
    "        \n",
    "        #logging.info('Decoder gradients')\n",
    "        #for name, param in decoder.named_parameters():\n",
    "            #logging.info(name)\n",
    "            #logging.info(param.grad)\n",
    "\n",
    "        optimizers['decoder'].step()\n",
    "\n",
    "        loss = loss_discriminator + loss_generator\n",
    "\n",
    "        if batch_idx % PRINT_INTERVAL == 0:\n",
    "            batch_loss = loss / n_batch_data\n",
    "            batch_loss_discriminator = loss_discriminator / n_batch_data\n",
    "            batch_loss_generator = loss_generator / n_batch_data\n",
    "\n",
    "            dx = labels_data.mean()\n",
    "            dgz = labels_from_prior.mean()\n",
    "\n",
    "            string_base = (\n",
    "                    'Train Epoch: {} [{}/{} ({:.0f}%)]\\tTotal Loss: {:.6f}'\n",
    "                    ', Discriminator: {:.6f}; Generator: {:.6f},'\n",
    "                    '\\nD(x): {:.3f}, D(G(z)): {:.3f}')\n",
    "            logging.info(\n",
    "                    string_base.format(\n",
    "                        epoch, batch_idx * n_batch_data, n_data,\n",
    "                        100. * batch_idx / n_batches,\n",
    "                        batch_loss,\n",
    "                        batch_loss_discriminator,\n",
    "                        batch_loss_generator,\n",
    "                        dx, dgz))\n",
    "\n",
    "        total_loss_discriminator += loss_discriminator.item()\n",
    "        total_loss_generator += loss_generator.item()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / n_data\n",
    "\n",
    "    logging.info('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "                epoch, average_loss))\n",
    "    \n",
    "    train_losses = {}\n",
    "    train_losses['total'] = average_loss\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_true = 2\n",
    "color_true = 'green'\n",
    "\n",
    "def generate_synthetic_1d(w=w_true, n=10):\n",
    "    z = np.random.normal(loc=0, scale=1, size=(n, 1))\n",
    "    eps = np.random.normal(loc=0, scale=1, size=(n, 1))\n",
    "\n",
    "    x = w * z + eps\n",
    "    return x\n",
    "\n",
    "dataset = generate_synthetic_1d(w=w_true, n=10000)\n",
    "fig, ax = plt.subplots()\n",
    "ax = toyvis.plot_data(dataset, color=color_true, label='from decoder true', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "\n",
    "# Seed\n",
    "SEED = 12345\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DATA_DIM = 1\n",
    "LATENT_DIM = 1\n",
    "N_DECODER_LAYERS = 1\n",
    "NONLINEARITY = False\n",
    "N_SAMPLES = 10000\n",
    "WITH_BIASX = False\n",
    "WITH_LOGVARX = False\n",
    "WITH_BIASZ = False\n",
    "WITH_LOGVARZ = False\n",
    "\n",
    "FRAC_TEST = 0.2\n",
    "BATCH_SIZE = 32\n",
    "KWARGS = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n",
    "\n",
    "PRINT_INTERVAL = 16\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "N_EPOCHS = 50\n",
    "LR = 1e-3\n",
    "\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:40:51,297 root         INFO     --Dataset tensor: (10000, 1)\n",
      "2019-05-02 20:40:51,298 root         INFO     -- Train tensor: (8000, 1)\n",
      "2019-05-02 20:40:53,092 root         INFO     Values of VAE's decoder parameters before training:\n",
      "2019-05-02 20:40:53,093 root         INFO     layers.0.weight\n",
      "2019-05-02 20:40:53,093 root         INFO     tensor([[1.1000]], device='cuda:0')\n",
      "2019-05-02 20:40:53,136 root         INFO     Train Epoch: 0 [0/8000 (0%)]\tTotal Loss: 0.084263, Discriminator: 0.048007; Generator: 0.036256,\n",
      "D(x): 0.313, D(G(z)): 0.313\n",
      "2019-05-02 20:40:53,194 root         INFO     Train Epoch: 0 [512/8000 (6%)]\tTotal Loss: 0.084053, Discriminator: 0.047933; Generator: 0.036119,\n",
      "D(x): 0.315, D(G(z)): 0.315\n",
      "2019-05-02 20:40:53,251 root         INFO     Train Epoch: 0 [1024/8000 (13%)]\tTotal Loss: 0.083845, Discriminator: 0.047860; Generator: 0.035984,\n",
      "D(x): 0.316, D(G(z)): 0.316\n",
      "2019-05-02 20:40:53,308 root         INFO     Train Epoch: 0 [1536/8000 (19%)]\tTotal Loss: 0.083639, Discriminator: 0.047789; Generator: 0.035850,\n",
      "D(x): 0.318, D(G(z)): 0.318\n",
      "2019-05-02 20:40:53,366 root         INFO     Train Epoch: 0 [2048/8000 (26%)]\tTotal Loss: 0.083436, Discriminator: 0.047718; Generator: 0.035718,\n",
      "D(x): 0.319, D(G(z)): 0.319\n",
      "2019-05-02 20:40:53,424 root         INFO     Train Epoch: 0 [2560/8000 (32%)]\tTotal Loss: 0.083234, Discriminator: 0.047648; Generator: 0.035586,\n",
      "D(x): 0.320, D(G(z)): 0.320\n",
      "2019-05-02 20:40:53,481 root         INFO     Train Epoch: 0 [3072/8000 (38%)]\tTotal Loss: 0.083035, Discriminator: 0.047579; Generator: 0.035456,\n",
      "D(x): 0.322, D(G(z)): 0.322\n",
      "2019-05-02 20:40:53,538 root         INFO     Train Epoch: 0 [3584/8000 (45%)]\tTotal Loss: 0.082838, Discriminator: 0.047511; Generator: 0.035327,\n",
      "D(x): 0.323, D(G(z)): 0.323\n",
      "2019-05-02 20:40:53,595 root         INFO     Train Epoch: 0 [4096/8000 (51%)]\tTotal Loss: 0.082643, Discriminator: 0.047445; Generator: 0.035198,\n",
      "D(x): 0.324, D(G(z)): 0.324\n",
      "2019-05-02 20:40:53,653 root         INFO     Train Epoch: 0 [4608/8000 (58%)]\tTotal Loss: 0.082450, Discriminator: 0.047379; Generator: 0.035071,\n",
      "D(x): 0.326, D(G(z)): 0.326\n",
      "2019-05-02 20:40:53,711 root         INFO     Train Epoch: 0 [5120/8000 (64%)]\tTotal Loss: 0.082259, Discriminator: 0.047314; Generator: 0.034945,\n",
      "D(x): 0.327, D(G(z)): 0.327\n",
      "2019-05-02 20:40:53,769 root         INFO     Train Epoch: 0 [5632/8000 (70%)]\tTotal Loss: 0.082070, Discriminator: 0.047250; Generator: 0.034820,\n",
      "D(x): 0.328, D(G(z)): 0.328\n",
      "2019-05-02 20:40:53,826 root         INFO     Train Epoch: 0 [6144/8000 (77%)]\tTotal Loss: 0.081883, Discriminator: 0.047187; Generator: 0.034697,\n",
      "D(x): 0.329, D(G(z)): 0.329\n",
      "2019-05-02 20:40:53,883 root         INFO     Train Epoch: 0 [6656/8000 (83%)]\tTotal Loss: 0.081698, Discriminator: 0.047124; Generator: 0.034574,\n",
      "D(x): 0.331, D(G(z)): 0.331\n",
      "2019-05-02 20:40:53,940 root         INFO     Train Epoch: 0 [7168/8000 (90%)]\tTotal Loss: 0.081515, Discriminator: 0.047063; Generator: 0.034452,\n",
      "D(x): 0.332, D(G(z)): 0.332\n",
      "2019-05-02 20:40:53,997 root         INFO     Train Epoch: 0 [7680/8000 (96%)]\tTotal Loss: 0.081334, Discriminator: 0.047003; Generator: 0.034332,\n",
      "D(x): 0.333, D(G(z)): 0.333\n",
      "2019-05-02 20:40:54,058 root         INFO     ====> Epoch: 0 Average loss: 0.0827\n",
      "2019-05-02 20:40:54,094 root         INFO     Train Epoch: 1 [0/8000 (0%)]\tTotal Loss: 0.081222, Discriminator: 0.046965; Generator: 0.034257,\n",
      "D(x): 0.334, D(G(z)): 0.334\n",
      "2019-05-02 20:40:54,153 root         INFO     Train Epoch: 1 [512/8000 (6%)]\tTotal Loss: 0.081044, Discriminator: 0.046906; Generator: 0.034138,\n",
      "D(x): 0.335, D(G(z)): 0.335\n",
      "2019-05-02 20:40:54,212 root         INFO     Train Epoch: 1 [1024/8000 (13%)]\tTotal Loss: 0.080868, Discriminator: 0.046848; Generator: 0.034020,\n",
      "D(x): 0.337, D(G(z)): 0.337\n",
      "2019-05-02 20:40:54,271 root         INFO     Train Epoch: 1 [1536/8000 (19%)]\tTotal Loss: 0.080694, Discriminator: 0.046791; Generator: 0.033904,\n",
      "D(x): 0.338, D(G(z)): 0.338\n",
      "2019-05-02 20:40:54,331 root         INFO     Train Epoch: 1 [2048/8000 (26%)]\tTotal Loss: 0.080522, Discriminator: 0.046734; Generator: 0.033788,\n",
      "D(x): 0.339, D(G(z)): 0.339\n",
      "2019-05-02 20:40:54,390 root         INFO     Train Epoch: 1 [2560/8000 (32%)]\tTotal Loss: 0.080352, Discriminator: 0.046678; Generator: 0.033673,\n",
      "D(x): 0.340, D(G(z)): 0.340\n",
      "2019-05-02 20:40:54,450 root         INFO     Train Epoch: 1 [3072/8000 (38%)]\tTotal Loss: 0.080183, Discriminator: 0.046624; Generator: 0.033560,\n",
      "D(x): 0.342, D(G(z)): 0.342\n",
      "2019-05-02 20:40:54,509 root         INFO     Train Epoch: 1 [3584/8000 (45%)]\tTotal Loss: 0.080016, Discriminator: 0.046570; Generator: 0.033447,\n",
      "D(x): 0.343, D(G(z)): 0.343\n",
      "2019-05-02 20:40:54,569 root         INFO     Train Epoch: 1 [4096/8000 (51%)]\tTotal Loss: 0.079851, Discriminator: 0.046516; Generator: 0.033335,\n",
      "D(x): 0.344, D(G(z)): 0.344\n",
      "2019-05-02 20:40:54,628 root         INFO     Train Epoch: 1 [4608/8000 (58%)]\tTotal Loss: 0.079688, Discriminator: 0.046464; Generator: 0.033224,\n",
      "D(x): 0.345, D(G(z)): 0.345\n",
      "2019-05-02 20:40:54,688 root         INFO     Train Epoch: 1 [5120/8000 (64%)]\tTotal Loss: 0.079527, Discriminator: 0.046412; Generator: 0.033115,\n",
      "D(x): 0.347, D(G(z)): 0.347\n",
      "2019-05-02 20:40:54,747 root         INFO     Train Epoch: 1 [5632/8000 (70%)]\tTotal Loss: 0.079367, Discriminator: 0.046361; Generator: 0.033006,\n",
      "D(x): 0.348, D(G(z)): 0.348\n",
      "2019-05-02 20:40:54,807 root         INFO     Train Epoch: 1 [6144/8000 (77%)]\tTotal Loss: 0.079209, Discriminator: 0.046311; Generator: 0.032898,\n",
      "D(x): 0.349, D(G(z)): 0.349\n",
      "2019-05-02 20:40:54,866 root         INFO     Train Epoch: 1 [6656/8000 (83%)]\tTotal Loss: 0.079053, Discriminator: 0.046262; Generator: 0.032791,\n",
      "D(x): 0.350, D(G(z)): 0.350\n",
      "2019-05-02 20:40:54,926 root         INFO     Train Epoch: 1 [7168/8000 (90%)]\tTotal Loss: 0.078898, Discriminator: 0.046213; Generator: 0.032685,\n",
      "D(x): 0.351, D(G(z)): 0.351\n",
      "2019-05-02 20:40:54,985 root         INFO     Train Epoch: 1 [7680/8000 (96%)]\tTotal Loss: 0.078745, Discriminator: 0.046165; Generator: 0.032580,\n",
      "D(x): 0.353, D(G(z)): 0.353\n",
      "2019-05-02 20:40:55,048 root         INFO     ====> Epoch: 1 Average loss: 0.0799\n",
      "2019-05-02 20:40:55,085 root         INFO     Train Epoch: 2 [0/8000 (0%)]\tTotal Loss: 0.078651, Discriminator: 0.046135; Generator: 0.032515,\n",
      "D(x): 0.353, D(G(z)): 0.353\n",
      "2019-05-02 20:40:55,144 root         INFO     Train Epoch: 2 [512/8000 (6%)]\tTotal Loss: 0.078501, Discriminator: 0.046089; Generator: 0.032412,\n",
      "D(x): 0.354, D(G(z)): 0.354\n",
      "2019-05-02 20:40:55,204 root         INFO     Train Epoch: 2 [1024/8000 (13%)]\tTotal Loss: 0.078352, Discriminator: 0.046043; Generator: 0.032309,\n",
      "D(x): 0.356, D(G(z)): 0.356\n",
      "2019-05-02 20:40:55,262 root         INFO     Train Epoch: 2 [1536/8000 (19%)]\tTotal Loss: 0.078205, Discriminator: 0.045997; Generator: 0.032208,\n",
      "D(x): 0.357, D(G(z)): 0.357\n",
      "2019-05-02 20:40:55,322 root         INFO     Train Epoch: 2 [2048/8000 (26%)]\tTotal Loss: 0.078060, Discriminator: 0.045953; Generator: 0.032107,\n",
      "D(x): 0.358, D(G(z)): 0.358\n",
      "2019-05-02 20:40:55,380 root         INFO     Train Epoch: 2 [2560/8000 (32%)]\tTotal Loss: 0.077916, Discriminator: 0.045909; Generator: 0.032007,\n",
      "D(x): 0.359, D(G(z)): 0.359\n",
      "2019-05-02 20:40:55,439 root         INFO     Train Epoch: 2 [3072/8000 (38%)]\tTotal Loss: 0.077774, Discriminator: 0.045865; Generator: 0.031909,\n",
      "D(x): 0.360, D(G(z)): 0.360\n",
      "2019-05-02 20:40:55,498 root         INFO     Train Epoch: 2 [3584/8000 (45%)]\tTotal Loss: 0.077633, Discriminator: 0.045823; Generator: 0.031811,\n",
      "D(x): 0.361, D(G(z)): 0.361\n",
      "2019-05-02 20:40:55,557 root         INFO     Train Epoch: 2 [4096/8000 (51%)]\tTotal Loss: 0.077494, Discriminator: 0.045780; Generator: 0.031713,\n",
      "D(x): 0.362, D(G(z)): 0.362\n",
      "2019-05-02 20:40:55,616 root         INFO     Train Epoch: 2 [4608/8000 (58%)]\tTotal Loss: 0.077356, Discriminator: 0.045739; Generator: 0.031617,\n",
      "D(x): 0.364, D(G(z)): 0.364\n",
      "2019-05-02 20:40:55,674 root         INFO     Train Epoch: 2 [5120/8000 (64%)]\tTotal Loss: 0.077220, Discriminator: 0.045698; Generator: 0.031522,\n",
      "D(x): 0.365, D(G(z)): 0.365\n",
      "2019-05-02 20:40:55,733 root         INFO     Train Epoch: 2 [5632/8000 (70%)]\tTotal Loss: 0.077086, Discriminator: 0.045658; Generator: 0.031427,\n",
      "D(x): 0.366, D(G(z)): 0.366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:40:55,792 root         INFO     Train Epoch: 2 [6144/8000 (77%)]\tTotal Loss: 0.076952, Discriminator: 0.045619; Generator: 0.031334,\n",
      "D(x): 0.367, D(G(z)): 0.367\n",
      "2019-05-02 20:40:55,851 root         INFO     Train Epoch: 2 [6656/8000 (83%)]\tTotal Loss: 0.076821, Discriminator: 0.045580; Generator: 0.031241,\n",
      "D(x): 0.368, D(G(z)): 0.368\n",
      "2019-05-02 20:40:55,910 root         INFO     Train Epoch: 2 [7168/8000 (90%)]\tTotal Loss: 0.076690, Discriminator: 0.045542; Generator: 0.031149,\n",
      "D(x): 0.369, D(G(z)): 0.369\n",
      "2019-05-02 20:40:55,969 root         INFO     Train Epoch: 2 [7680/8000 (96%)]\tTotal Loss: 0.076562, Discriminator: 0.045504; Generator: 0.031058,\n",
      "D(x): 0.370, D(G(z)): 0.370\n",
      "2019-05-02 20:40:56,031 root         INFO     ====> Epoch: 2 Average loss: 0.0775\n",
      "2019-05-02 20:40:56,068 root         INFO     Train Epoch: 3 [0/8000 (0%)]\tTotal Loss: 0.076482, Discriminator: 0.045481; Generator: 0.031001,\n",
      "D(x): 0.371, D(G(z)): 0.371\n",
      "2019-05-02 20:40:56,129 root         INFO     Train Epoch: 3 [512/8000 (6%)]\tTotal Loss: 0.076355, Discriminator: 0.045444; Generator: 0.030912,\n",
      "D(x): 0.372, D(G(z)): 0.372\n",
      "2019-05-02 20:40:56,187 root         INFO     Train Epoch: 3 [1024/8000 (13%)]\tTotal Loss: 0.076230, Discriminator: 0.045408; Generator: 0.030823,\n",
      "D(x): 0.373, D(G(z)): 0.373\n",
      "2019-05-02 20:40:56,245 root         INFO     Train Epoch: 3 [1536/8000 (19%)]\tTotal Loss: 0.076106, Discriminator: 0.045372; Generator: 0.030734,\n",
      "D(x): 0.374, D(G(z)): 0.374\n",
      "2019-05-02 20:40:56,303 root         INFO     Train Epoch: 3 [2048/8000 (26%)]\tTotal Loss: 0.075984, Discriminator: 0.045337; Generator: 0.030647,\n",
      "D(x): 0.375, D(G(z)): 0.375\n",
      "2019-05-02 20:40:56,361 root         INFO     Train Epoch: 3 [2560/8000 (32%)]\tTotal Loss: 0.075863, Discriminator: 0.045302; Generator: 0.030560,\n",
      "D(x): 0.376, D(G(z)): 0.376\n",
      "2019-05-02 20:40:56,419 root         INFO     Train Epoch: 3 [3072/8000 (38%)]\tTotal Loss: 0.075743, Discriminator: 0.045269; Generator: 0.030475,\n",
      "D(x): 0.377, D(G(z)): 0.377\n",
      "2019-05-02 20:40:56,478 root         INFO     Train Epoch: 3 [3584/8000 (45%)]\tTotal Loss: 0.075625, Discriminator: 0.045235; Generator: 0.030390,\n",
      "D(x): 0.378, D(G(z)): 0.378\n",
      "2019-05-02 20:40:56,535 root         INFO     Train Epoch: 3 [4096/8000 (51%)]\tTotal Loss: 0.075508, Discriminator: 0.045202; Generator: 0.030305,\n",
      "D(x): 0.379, D(G(z)): 0.379\n",
      "2019-05-02 20:40:56,594 root         INFO     Train Epoch: 3 [4608/8000 (58%)]\tTotal Loss: 0.075392, Discriminator: 0.045170; Generator: 0.030222,\n",
      "D(x): 0.380, D(G(z)): 0.380\n",
      "2019-05-02 20:40:56,652 root         INFO     Train Epoch: 3 [5120/8000 (64%)]\tTotal Loss: 0.075277, Discriminator: 0.045138; Generator: 0.030139,\n",
      "D(x): 0.381, D(G(z)): 0.381\n",
      "2019-05-02 20:40:56,710 root         INFO     Train Epoch: 3 [5632/8000 (70%)]\tTotal Loss: 0.075164, Discriminator: 0.045107; Generator: 0.030057,\n",
      "D(x): 0.382, D(G(z)): 0.382\n",
      "2019-05-02 20:40:56,768 root         INFO     Train Epoch: 3 [6144/8000 (77%)]\tTotal Loss: 0.075052, Discriminator: 0.045076; Generator: 0.029976,\n",
      "D(x): 0.383, D(G(z)): 0.383\n",
      "2019-05-02 20:40:56,826 root         INFO     Train Epoch: 3 [6656/8000 (83%)]\tTotal Loss: 0.074941, Discriminator: 0.045045; Generator: 0.029896,\n",
      "D(x): 0.384, D(G(z)): 0.384\n",
      "2019-05-02 20:40:56,884 root         INFO     Train Epoch: 3 [7168/8000 (90%)]\tTotal Loss: 0.074832, Discriminator: 0.045016; Generator: 0.029816,\n",
      "D(x): 0.385, D(G(z)): 0.385\n",
      "2019-05-02 20:40:56,942 root         INFO     Train Epoch: 3 [7680/8000 (96%)]\tTotal Loss: 0.074723, Discriminator: 0.044986; Generator: 0.029737,\n",
      "D(x): 0.386, D(G(z)): 0.386\n",
      "2019-05-02 20:40:57,003 root         INFO     ====> Epoch: 3 Average loss: 0.0755\n",
      "2019-05-02 20:40:57,040 root         INFO     Train Epoch: 4 [0/8000 (0%)]\tTotal Loss: 0.074656, Discriminator: 0.044968; Generator: 0.029688,\n",
      "D(x): 0.387, D(G(z)): 0.387\n",
      "2019-05-02 20:40:57,100 root         INFO     Train Epoch: 4 [512/8000 (6%)]\tTotal Loss: 0.074550, Discriminator: 0.044939; Generator: 0.029610,\n",
      "D(x): 0.388, D(G(z)): 0.388\n",
      "2019-05-02 20:40:57,159 root         INFO     Train Epoch: 4 [1024/8000 (13%)]\tTotal Loss: 0.074444, Discriminator: 0.044911; Generator: 0.029533,\n",
      "D(x): 0.389, D(G(z)): 0.389\n",
      "2019-05-02 20:40:57,216 root         INFO     Train Epoch: 4 [1536/8000 (19%)]\tTotal Loss: 0.074340, Discriminator: 0.044883; Generator: 0.029457,\n",
      "D(x): 0.390, D(G(z)): 0.390\n",
      "2019-05-02 20:40:57,273 root         INFO     Train Epoch: 4 [2048/8000 (26%)]\tTotal Loss: 0.074237, Discriminator: 0.044856; Generator: 0.029381,\n",
      "D(x): 0.391, D(G(z)): 0.391\n",
      "2019-05-02 20:40:57,330 root         INFO     Train Epoch: 4 [2560/8000 (32%)]\tTotal Loss: 0.074136, Discriminator: 0.044829; Generator: 0.029306,\n",
      "D(x): 0.391, D(G(z)): 0.391\n",
      "2019-05-02 20:40:57,387 root         INFO     Train Epoch: 4 [3072/8000 (38%)]\tTotal Loss: 0.074035, Discriminator: 0.044803; Generator: 0.029232,\n",
      "D(x): 0.392, D(G(z)): 0.392\n",
      "2019-05-02 20:40:57,443 root         INFO     Train Epoch: 4 [3584/8000 (45%)]\tTotal Loss: 0.073936, Discriminator: 0.044777; Generator: 0.029159,\n",
      "D(x): 0.393, D(G(z)): 0.393\n",
      "2019-05-02 20:40:57,500 root         INFO     Train Epoch: 4 [4096/8000 (51%)]\tTotal Loss: 0.073837, Discriminator: 0.044751; Generator: 0.029086,\n",
      "D(x): 0.394, D(G(z)): 0.394\n",
      "2019-05-02 20:40:57,556 root         INFO     Train Epoch: 4 [4608/8000 (58%)]\tTotal Loss: 0.073740, Discriminator: 0.044726; Generator: 0.029013,\n",
      "D(x): 0.395, D(G(z)): 0.395\n",
      "2019-05-02 20:40:57,613 root         INFO     Train Epoch: 4 [5120/8000 (64%)]\tTotal Loss: 0.073643, Discriminator: 0.044702; Generator: 0.028942,\n",
      "D(x): 0.396, D(G(z)): 0.396\n",
      "2019-05-02 20:40:57,669 root         INFO     Train Epoch: 4 [5632/8000 (70%)]\tTotal Loss: 0.073548, Discriminator: 0.044677; Generator: 0.028871,\n",
      "D(x): 0.397, D(G(z)): 0.397\n",
      "2019-05-02 20:40:57,726 root         INFO     Train Epoch: 4 [6144/8000 (77%)]\tTotal Loss: 0.073454, Discriminator: 0.044653; Generator: 0.028801,\n",
      "D(x): 0.398, D(G(z)): 0.398\n",
      "2019-05-02 20:40:57,783 root         INFO     Train Epoch: 4 [6656/8000 (83%)]\tTotal Loss: 0.073361, Discriminator: 0.044630; Generator: 0.028731,\n",
      "D(x): 0.399, D(G(z)): 0.399\n",
      "2019-05-02 20:40:57,839 root         INFO     Train Epoch: 4 [7168/8000 (90%)]\tTotal Loss: 0.073269, Discriminator: 0.044607; Generator: 0.028662,\n",
      "D(x): 0.400, D(G(z)): 0.400\n",
      "2019-05-02 20:40:57,897 root         INFO     Train Epoch: 4 [7680/8000 (96%)]\tTotal Loss: 0.073178, Discriminator: 0.044584; Generator: 0.028594,\n",
      "D(x): 0.401, D(G(z)): 0.401\n",
      "2019-05-02 20:40:57,958 root         INFO     ====> Epoch: 4 Average loss: 0.0739\n",
      "2019-05-02 20:40:57,994 root         INFO     Train Epoch: 5 [0/8000 (0%)]\tTotal Loss: 0.073122, Discriminator: 0.044570; Generator: 0.028552,\n",
      "D(x): 0.401, D(G(z)): 0.401\n",
      "2019-05-02 20:40:58,054 root         INFO     Train Epoch: 5 [512/8000 (6%)]\tTotal Loss: 0.073032, Discriminator: 0.044548; Generator: 0.028484,\n",
      "D(x): 0.402, D(G(z)): 0.402\n",
      "2019-05-02 20:40:58,113 root         INFO     Train Epoch: 5 [1024/8000 (13%)]\tTotal Loss: 0.072944, Discriminator: 0.044526; Generator: 0.028418,\n",
      "D(x): 0.403, D(G(z)): 0.403\n",
      "2019-05-02 20:40:58,172 root         INFO     Train Epoch: 5 [1536/8000 (19%)]\tTotal Loss: 0.072856, Discriminator: 0.044505; Generator: 0.028352,\n",
      "D(x): 0.404, D(G(z)): 0.404\n",
      "2019-05-02 20:40:58,230 root         INFO     Train Epoch: 5 [2048/8000 (26%)]\tTotal Loss: 0.072770, Discriminator: 0.044484; Generator: 0.028286,\n",
      "D(x): 0.404, D(G(z)): 0.404\n",
      "2019-05-02 20:40:58,288 root         INFO     Train Epoch: 5 [2560/8000 (32%)]\tTotal Loss: 0.072684, Discriminator: 0.044463; Generator: 0.028221,\n",
      "D(x): 0.405, D(G(z)): 0.405\n",
      "2019-05-02 20:40:58,346 root         INFO     Train Epoch: 5 [3072/8000 (38%)]\tTotal Loss: 0.072600, Discriminator: 0.044443; Generator: 0.028157,\n",
      "D(x): 0.406, D(G(z)): 0.406\n",
      "2019-05-02 20:40:58,404 root         INFO     Train Epoch: 5 [3584/8000 (45%)]\tTotal Loss: 0.072516, Discriminator: 0.044423; Generator: 0.028094,\n",
      "D(x): 0.407, D(G(z)): 0.407\n",
      "2019-05-02 20:40:58,462 root         INFO     Train Epoch: 5 [4096/8000 (51%)]\tTotal Loss: 0.072434, Discriminator: 0.044403; Generator: 0.028031,\n",
      "D(x): 0.408, D(G(z)): 0.408\n",
      "2019-05-02 20:40:58,519 root         INFO     Train Epoch: 5 [4608/8000 (58%)]\tTotal Loss: 0.072352, Discriminator: 0.044384; Generator: 0.027968,\n",
      "D(x): 0.409, D(G(z)): 0.409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:40:58,576 root         INFO     Train Epoch: 5 [5120/8000 (64%)]\tTotal Loss: 0.072271, Discriminator: 0.044364; Generator: 0.027907,\n",
      "D(x): 0.409, D(G(z)): 0.409\n",
      "2019-05-02 20:40:58,633 root         INFO     Train Epoch: 5 [5632/8000 (70%)]\tTotal Loss: 0.072191, Discriminator: 0.044346; Generator: 0.027845,\n",
      "D(x): 0.410, D(G(z)): 0.410\n",
      "2019-05-02 20:40:58,690 root         INFO     Train Epoch: 5 [6144/8000 (77%)]\tTotal Loss: 0.072112, Discriminator: 0.044327; Generator: 0.027785,\n",
      "D(x): 0.411, D(G(z)): 0.411\n",
      "2019-05-02 20:40:58,747 root         INFO     Train Epoch: 5 [6656/8000 (83%)]\tTotal Loss: 0.072034, Discriminator: 0.044309; Generator: 0.027725,\n",
      "D(x): 0.412, D(G(z)): 0.412\n",
      "2019-05-02 20:40:58,804 root         INFO     Train Epoch: 5 [7168/8000 (90%)]\tTotal Loss: 0.071957, Discriminator: 0.044292; Generator: 0.027665,\n",
      "D(x): 0.413, D(G(z)): 0.413\n",
      "2019-05-02 20:40:58,862 root         INFO     Train Epoch: 5 [7680/8000 (96%)]\tTotal Loss: 0.071880, Discriminator: 0.044274; Generator: 0.027606,\n",
      "D(x): 0.413, D(G(z)): 0.413\n",
      "2019-05-02 20:40:58,923 root         INFO     ====> Epoch: 5 Average loss: 0.0725\n",
      "2019-05-02 20:40:58,960 root         INFO     Train Epoch: 6 [0/8000 (0%)]\tTotal Loss: 0.071833, Discriminator: 0.044263; Generator: 0.027570,\n",
      "D(x): 0.414, D(G(z)): 0.414\n",
      "2019-05-02 20:40:59,019 root         INFO     Train Epoch: 6 [512/8000 (6%)]\tTotal Loss: 0.071758, Discriminator: 0.044246; Generator: 0.027512,\n",
      "D(x): 0.415, D(G(z)): 0.415\n",
      "2019-05-02 20:40:59,078 root         INFO     Train Epoch: 6 [1024/8000 (13%)]\tTotal Loss: 0.071684, Discriminator: 0.044230; Generator: 0.027454,\n",
      "D(x): 0.415, D(G(z)): 0.415\n",
      "2019-05-02 20:40:59,136 root         INFO     Train Epoch: 6 [1536/8000 (19%)]\tTotal Loss: 0.071610, Discriminator: 0.044213; Generator: 0.027397,\n",
      "D(x): 0.416, D(G(z)): 0.416\n",
      "2019-05-02 20:40:59,195 root         INFO     Train Epoch: 6 [2048/8000 (26%)]\tTotal Loss: 0.071538, Discriminator: 0.044197; Generator: 0.027341,\n",
      "D(x): 0.417, D(G(z)): 0.417\n",
      "2019-05-02 20:40:59,253 root         INFO     Train Epoch: 6 [2560/8000 (32%)]\tTotal Loss: 0.071466, Discriminator: 0.044181; Generator: 0.027285,\n",
      "D(x): 0.418, D(G(z)): 0.418\n",
      "2019-05-02 20:40:59,311 root         INFO     Train Epoch: 6 [3072/8000 (38%)]\tTotal Loss: 0.071395, Discriminator: 0.044166; Generator: 0.027229,\n",
      "D(x): 0.418, D(G(z)): 0.418\n",
      "2019-05-02 20:40:59,370 root         INFO     Train Epoch: 6 [3584/8000 (45%)]\tTotal Loss: 0.071325, Discriminator: 0.044150; Generator: 0.027175,\n",
      "D(x): 0.419, D(G(z)): 0.419\n",
      "2019-05-02 20:40:59,428 root         INFO     Train Epoch: 6 [4096/8000 (51%)]\tTotal Loss: 0.071255, Discriminator: 0.044135; Generator: 0.027120,\n",
      "D(x): 0.420, D(G(z)): 0.420\n",
      "2019-05-02 20:40:59,486 root         INFO     Train Epoch: 6 [4608/8000 (58%)]\tTotal Loss: 0.071187, Discriminator: 0.044120; Generator: 0.027066,\n",
      "D(x): 0.421, D(G(z)): 0.421\n",
      "2019-05-02 20:40:59,545 root         INFO     Train Epoch: 6 [5120/8000 (64%)]\tTotal Loss: 0.071119, Discriminator: 0.044106; Generator: 0.027013,\n",
      "D(x): 0.421, D(G(z)): 0.421\n",
      "2019-05-02 20:40:59,603 root         INFO     Train Epoch: 6 [5632/8000 (70%)]\tTotal Loss: 0.071052, Discriminator: 0.044091; Generator: 0.026960,\n",
      "D(x): 0.422, D(G(z)): 0.422\n",
      "2019-05-02 20:40:59,662 root         INFO     Train Epoch: 6 [6144/8000 (77%)]\tTotal Loss: 0.070985, Discriminator: 0.044077; Generator: 0.026908,\n",
      "D(x): 0.423, D(G(z)): 0.423\n",
      "2019-05-02 20:40:59,720 root         INFO     Train Epoch: 6 [6656/8000 (83%)]\tTotal Loss: 0.070920, Discriminator: 0.044064; Generator: 0.026856,\n",
      "D(x): 0.423, D(G(z)): 0.423\n",
      "2019-05-02 20:40:59,779 root         INFO     Train Epoch: 6 [7168/8000 (90%)]\tTotal Loss: 0.070855, Discriminator: 0.044050; Generator: 0.026805,\n",
      "D(x): 0.424, D(G(z)): 0.424\n",
      "2019-05-02 20:40:59,837 root         INFO     Train Epoch: 6 [7680/8000 (96%)]\tTotal Loss: 0.070791, Discriminator: 0.044037; Generator: 0.026754,\n",
      "D(x): 0.425, D(G(z)): 0.425\n",
      "2019-05-02 20:40:59,899 root         INFO     ====> Epoch: 6 Average loss: 0.0713\n",
      "2019-05-02 20:40:59,935 root         INFO     Train Epoch: 7 [0/8000 (0%)]\tTotal Loss: 0.070751, Discriminator: 0.044028; Generator: 0.026723,\n",
      "D(x): 0.425, D(G(z)): 0.425\n",
      "2019-05-02 20:40:59,993 root         INFO     Train Epoch: 7 [512/8000 (6%)]\tTotal Loss: 0.070688, Discriminator: 0.044015; Generator: 0.026673,\n",
      "D(x): 0.426, D(G(z)): 0.426\n",
      "2019-05-02 20:41:00,052 root         INFO     Train Epoch: 7 [1024/8000 (13%)]\tTotal Loss: 0.070626, Discriminator: 0.044003; Generator: 0.026623,\n",
      "D(x): 0.427, D(G(z)): 0.427\n",
      "2019-05-02 20:41:00,110 root         INFO     Train Epoch: 7 [1536/8000 (19%)]\tTotal Loss: 0.070564, Discriminator: 0.043990; Generator: 0.026574,\n",
      "D(x): 0.427, D(G(z)): 0.427\n",
      "2019-05-02 20:41:00,169 root         INFO     Train Epoch: 7 [2048/8000 (26%)]\tTotal Loss: 0.070503, Discriminator: 0.043978; Generator: 0.026525,\n",
      "D(x): 0.428, D(G(z)): 0.428\n",
      "2019-05-02 20:41:00,228 root         INFO     Train Epoch: 7 [2560/8000 (32%)]\tTotal Loss: 0.070443, Discriminator: 0.043966; Generator: 0.026477,\n",
      "D(x): 0.429, D(G(z)): 0.429\n",
      "2019-05-02 20:41:00,287 root         INFO     Train Epoch: 7 [3072/8000 (38%)]\tTotal Loss: 0.070384, Discriminator: 0.043954; Generator: 0.026430,\n",
      "D(x): 0.429, D(G(z)): 0.429\n",
      "2019-05-02 20:41:00,345 root         INFO     Train Epoch: 7 [3584/8000 (45%)]\tTotal Loss: 0.070325, Discriminator: 0.043942; Generator: 0.026382,\n",
      "D(x): 0.430, D(G(z)): 0.430\n",
      "2019-05-02 20:41:00,404 root         INFO     Train Epoch: 7 [4096/8000 (51%)]\tTotal Loss: 0.070266, Discriminator: 0.043931; Generator: 0.026336,\n",
      "D(x): 0.431, D(G(z)): 0.431\n",
      "2019-05-02 20:41:00,462 root         INFO     Train Epoch: 7 [4608/8000 (58%)]\tTotal Loss: 0.070209, Discriminator: 0.043920; Generator: 0.026289,\n",
      "D(x): 0.431, D(G(z)): 0.431\n",
      "2019-05-02 20:41:00,521 root         INFO     Train Epoch: 7 [5120/8000 (64%)]\tTotal Loss: 0.070152, Discriminator: 0.043909; Generator: 0.026243,\n",
      "D(x): 0.432, D(G(z)): 0.432\n",
      "2019-05-02 20:41:00,580 root         INFO     Train Epoch: 7 [5632/8000 (70%)]\tTotal Loss: 0.070095, Discriminator: 0.043898; Generator: 0.026198,\n",
      "D(x): 0.432, D(G(z)): 0.432\n",
      "2019-05-02 20:41:00,639 root         INFO     Train Epoch: 7 [6144/8000 (77%)]\tTotal Loss: 0.070040, Discriminator: 0.043887; Generator: 0.026153,\n",
      "D(x): 0.433, D(G(z)): 0.433\n",
      "2019-05-02 20:41:00,698 root         INFO     Train Epoch: 7 [6656/8000 (83%)]\tTotal Loss: 0.069985, Discriminator: 0.043877; Generator: 0.026108,\n",
      "D(x): 0.434, D(G(z)): 0.434\n",
      "2019-05-02 20:41:00,757 root         INFO     Train Epoch: 7 [7168/8000 (90%)]\tTotal Loss: 0.069930, Discriminator: 0.043866; Generator: 0.026064,\n",
      "D(x): 0.434, D(G(z)): 0.434\n",
      "2019-05-02 20:41:00,814 root         INFO     Train Epoch: 7 [7680/8000 (96%)]\tTotal Loss: 0.069876, Discriminator: 0.043856; Generator: 0.026020,\n",
      "D(x): 0.435, D(G(z)): 0.435\n",
      "2019-05-02 20:41:00,875 root         INFO     ====> Epoch: 7 Average loss: 0.0703\n",
      "2019-05-02 20:41:00,912 root         INFO     Train Epoch: 8 [0/8000 (0%)]\tTotal Loss: 0.069843, Discriminator: 0.043850; Generator: 0.025993,\n",
      "D(x): 0.435, D(G(z)): 0.435\n",
      "2019-05-02 20:41:00,969 root         INFO     Train Epoch: 8 [512/8000 (6%)]\tTotal Loss: 0.069790, Discriminator: 0.043840; Generator: 0.025950,\n",
      "D(x): 0.436, D(G(z)): 0.436\n",
      "2019-05-02 20:41:01,025 root         INFO     Train Epoch: 8 [1024/8000 (13%)]\tTotal Loss: 0.069738, Discriminator: 0.043830; Generator: 0.025908,\n",
      "D(x): 0.436, D(G(z)): 0.436\n",
      "2019-05-02 20:41:01,082 root         INFO     Train Epoch: 8 [1536/8000 (19%)]\tTotal Loss: 0.069686, Discriminator: 0.043821; Generator: 0.025865,\n",
      "D(x): 0.437, D(G(z)): 0.437\n",
      "2019-05-02 20:41:01,138 root         INFO     Train Epoch: 8 [2048/8000 (26%)]\tTotal Loss: 0.069635, Discriminator: 0.043812; Generator: 0.025824,\n",
      "D(x): 0.438, D(G(z)): 0.438\n",
      "2019-05-02 20:41:01,195 root         INFO     Train Epoch: 8 [2560/8000 (32%)]\tTotal Loss: 0.069585, Discriminator: 0.043802; Generator: 0.025782,\n",
      "D(x): 0.438, D(G(z)): 0.438\n",
      "2019-05-02 20:41:01,252 root         INFO     Train Epoch: 8 [3072/8000 (38%)]\tTotal Loss: 0.069535, Discriminator: 0.043793; Generator: 0.025741,\n",
      "D(x): 0.439, D(G(z)): 0.439\n",
      "2019-05-02 20:41:01,308 root         INFO     Train Epoch: 8 [3584/8000 (45%)]\tTotal Loss: 0.069485, Discriminator: 0.043785; Generator: 0.025700,\n",
      "D(x): 0.439, D(G(z)): 0.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:01,365 root         INFO     Train Epoch: 8 [4096/8000 (51%)]\tTotal Loss: 0.069436, Discriminator: 0.043776; Generator: 0.025660,\n",
      "D(x): 0.440, D(G(z)): 0.440\n",
      "2019-05-02 20:41:01,421 root         INFO     Train Epoch: 8 [4608/8000 (58%)]\tTotal Loss: 0.069388, Discriminator: 0.043767; Generator: 0.025620,\n",
      "D(x): 0.440, D(G(z)): 0.440\n",
      "2019-05-02 20:41:01,477 root         INFO     Train Epoch: 8 [5120/8000 (64%)]\tTotal Loss: 0.069340, Discriminator: 0.043759; Generator: 0.025581,\n",
      "D(x): 0.441, D(G(z)): 0.441\n",
      "2019-05-02 20:41:01,533 root         INFO     Train Epoch: 8 [5632/8000 (70%)]\tTotal Loss: 0.069293, Discriminator: 0.043751; Generator: 0.025542,\n",
      "D(x): 0.442, D(G(z)): 0.442\n",
      "2019-05-02 20:41:01,590 root         INFO     Train Epoch: 8 [6144/8000 (77%)]\tTotal Loss: 0.069246, Discriminator: 0.043743; Generator: 0.025503,\n",
      "D(x): 0.442, D(G(z)): 0.442\n",
      "2019-05-02 20:41:01,646 root         INFO     Train Epoch: 8 [6656/8000 (83%)]\tTotal Loss: 0.069200, Discriminator: 0.043735; Generator: 0.025465,\n",
      "D(x): 0.443, D(G(z)): 0.443\n",
      "2019-05-02 20:41:01,702 root         INFO     Train Epoch: 8 [7168/8000 (90%)]\tTotal Loss: 0.069154, Discriminator: 0.043727; Generator: 0.025427,\n",
      "D(x): 0.443, D(G(z)): 0.443\n",
      "2019-05-02 20:41:01,758 root         INFO     Train Epoch: 8 [7680/8000 (96%)]\tTotal Loss: 0.069109, Discriminator: 0.043719; Generator: 0.025389,\n",
      "D(x): 0.444, D(G(z)): 0.444\n",
      "2019-05-02 20:41:01,818 root         INFO     ====> Epoch: 8 Average loss: 0.0695\n",
      "2019-05-02 20:41:01,854 root         INFO     Train Epoch: 9 [0/8000 (0%)]\tTotal Loss: 0.069081, Discriminator: 0.043715; Generator: 0.025366,\n",
      "D(x): 0.444, D(G(z)): 0.444\n",
      "2019-05-02 20:41:01,912 root         INFO     Train Epoch: 9 [512/8000 (6%)]\tTotal Loss: 0.069036, Discriminator: 0.043707; Generator: 0.025329,\n",
      "D(x): 0.445, D(G(z)): 0.445\n",
      "2019-05-02 20:41:01,970 root         INFO     Train Epoch: 9 [1024/8000 (13%)]\tTotal Loss: 0.068993, Discriminator: 0.043700; Generator: 0.025292,\n",
      "D(x): 0.445, D(G(z)): 0.445\n",
      "2019-05-02 20:41:02,027 root         INFO     Train Epoch: 9 [1536/8000 (19%)]\tTotal Loss: 0.068949, Discriminator: 0.043693; Generator: 0.025256,\n",
      "D(x): 0.446, D(G(z)): 0.446\n",
      "2019-05-02 20:41:02,085 root         INFO     Train Epoch: 9 [2048/8000 (26%)]\tTotal Loss: 0.068906, Discriminator: 0.043686; Generator: 0.025220,\n",
      "D(x): 0.446, D(G(z)): 0.446\n",
      "2019-05-02 20:41:02,142 root         INFO     Train Epoch: 9 [2560/8000 (32%)]\tTotal Loss: 0.068864, Discriminator: 0.043679; Generator: 0.025185,\n",
      "D(x): 0.447, D(G(z)): 0.447\n",
      "2019-05-02 20:41:02,199 root         INFO     Train Epoch: 9 [3072/8000 (38%)]\tTotal Loss: 0.068822, Discriminator: 0.043672; Generator: 0.025149,\n",
      "D(x): 0.447, D(G(z)): 0.447\n",
      "2019-05-02 20:41:02,256 root         INFO     Train Epoch: 9 [3584/8000 (45%)]\tTotal Loss: 0.068780, Discriminator: 0.043666; Generator: 0.025115,\n",
      "D(x): 0.448, D(G(z)): 0.448\n",
      "2019-05-02 20:41:02,313 root         INFO     Train Epoch: 9 [4096/8000 (51%)]\tTotal Loss: 0.068739, Discriminator: 0.043659; Generator: 0.025080,\n",
      "D(x): 0.448, D(G(z)): 0.448\n",
      "2019-05-02 20:41:02,371 root         INFO     Train Epoch: 9 [4608/8000 (58%)]\tTotal Loss: 0.068699, Discriminator: 0.043653; Generator: 0.025046,\n",
      "D(x): 0.449, D(G(z)): 0.449\n",
      "2019-05-02 20:41:02,428 root         INFO     Train Epoch: 9 [5120/8000 (64%)]\tTotal Loss: 0.068658, Discriminator: 0.043646; Generator: 0.025012,\n",
      "D(x): 0.449, D(G(z)): 0.449\n",
      "2019-05-02 20:41:02,484 root         INFO     Train Epoch: 9 [5632/8000 (70%)]\tTotal Loss: 0.068619, Discriminator: 0.043640; Generator: 0.024978,\n",
      "D(x): 0.450, D(G(z)): 0.450\n",
      "2019-05-02 20:41:02,542 root         INFO     Train Epoch: 9 [6144/8000 (77%)]\tTotal Loss: 0.068579, Discriminator: 0.043634; Generator: 0.024945,\n",
      "D(x): 0.450, D(G(z)): 0.450\n",
      "2019-05-02 20:41:02,599 root         INFO     Train Epoch: 9 [6656/8000 (83%)]\tTotal Loss: 0.068541, Discriminator: 0.043628; Generator: 0.024912,\n",
      "D(x): 0.451, D(G(z)): 0.451\n",
      "2019-05-02 20:41:02,656 root         INFO     Train Epoch: 9 [7168/8000 (90%)]\tTotal Loss: 0.068502, Discriminator: 0.043622; Generator: 0.024880,\n",
      "D(x): 0.451, D(G(z)): 0.451\n",
      "2019-05-02 20:41:02,712 root         INFO     Train Epoch: 9 [7680/8000 (96%)]\tTotal Loss: 0.068464, Discriminator: 0.043617; Generator: 0.024847,\n",
      "D(x): 0.452, D(G(z)): 0.452\n",
      "2019-05-02 20:41:02,773 root         INFO     ====> Epoch: 9 Average loss: 0.0688\n",
      "2019-05-02 20:41:02,809 root         INFO     Train Epoch: 10 [0/8000 (0%)]\tTotal Loss: 0.068441, Discriminator: 0.043613; Generator: 0.024827,\n",
      "D(x): 0.452, D(G(z)): 0.452\n",
      "2019-05-02 20:41:02,866 root         INFO     Train Epoch: 10 [512/8000 (6%)]\tTotal Loss: 0.068403, Discriminator: 0.043608; Generator: 0.024796,\n",
      "D(x): 0.452, D(G(z)): 0.452\n",
      "2019-05-02 20:41:02,924 root         INFO     Train Epoch: 10 [1024/8000 (13%)]\tTotal Loss: 0.068366, Discriminator: 0.043602; Generator: 0.024764,\n",
      "D(x): 0.453, D(G(z)): 0.453\n",
      "2019-05-02 20:41:02,981 root         INFO     Train Epoch: 10 [1536/8000 (19%)]\tTotal Loss: 0.068330, Discriminator: 0.043597; Generator: 0.024733,\n",
      "D(x): 0.453, D(G(z)): 0.453\n",
      "2019-05-02 20:41:03,038 root         INFO     Train Epoch: 10 [2048/8000 (26%)]\tTotal Loss: 0.068294, Discriminator: 0.043592; Generator: 0.024702,\n",
      "D(x): 0.454, D(G(z)): 0.454\n",
      "2019-05-02 20:41:03,095 root         INFO     Train Epoch: 10 [2560/8000 (32%)]\tTotal Loss: 0.068258, Discriminator: 0.043586; Generator: 0.024672,\n",
      "D(x): 0.454, D(G(z)): 0.454\n",
      "2019-05-02 20:41:03,151 root         INFO     Train Epoch: 10 [3072/8000 (38%)]\tTotal Loss: 0.068223, Discriminator: 0.043581; Generator: 0.024641,\n",
      "D(x): 0.455, D(G(z)): 0.455\n",
      "2019-05-02 20:41:03,208 root         INFO     Train Epoch: 10 [3584/8000 (45%)]\tTotal Loss: 0.068188, Discriminator: 0.043576; Generator: 0.024612,\n",
      "D(x): 0.455, D(G(z)): 0.455\n",
      "2019-05-02 20:41:03,265 root         INFO     Train Epoch: 10 [4096/8000 (51%)]\tTotal Loss: 0.068153, Discriminator: 0.043572; Generator: 0.024582,\n",
      "D(x): 0.455, D(G(z)): 0.455\n",
      "2019-05-02 20:41:03,322 root         INFO     Train Epoch: 10 [4608/8000 (58%)]\tTotal Loss: 0.068119, Discriminator: 0.043567; Generator: 0.024553,\n",
      "D(x): 0.456, D(G(z)): 0.456\n",
      "2019-05-02 20:41:03,379 root         INFO     Train Epoch: 10 [5120/8000 (64%)]\tTotal Loss: 0.068086, Discriminator: 0.043562; Generator: 0.024524,\n",
      "D(x): 0.456, D(G(z)): 0.456\n",
      "2019-05-02 20:41:03,436 root         INFO     Train Epoch: 10 [5632/8000 (70%)]\tTotal Loss: 0.068052, Discriminator: 0.043557; Generator: 0.024495,\n",
      "D(x): 0.457, D(G(z)): 0.457\n",
      "2019-05-02 20:41:03,492 root         INFO     Train Epoch: 10 [6144/8000 (77%)]\tTotal Loss: 0.068019, Discriminator: 0.043553; Generator: 0.024466,\n",
      "D(x): 0.457, D(G(z)): 0.457\n",
      "2019-05-02 20:41:03,549 root         INFO     Train Epoch: 10 [6656/8000 (83%)]\tTotal Loss: 0.067987, Discriminator: 0.043549; Generator: 0.024438,\n",
      "D(x): 0.457, D(G(z)): 0.457\n",
      "2019-05-02 20:41:03,606 root         INFO     Train Epoch: 10 [7168/8000 (90%)]\tTotal Loss: 0.067954, Discriminator: 0.043544; Generator: 0.024410,\n",
      "D(x): 0.458, D(G(z)): 0.458\n",
      "2019-05-02 20:41:03,663 root         INFO     Train Epoch: 10 [7680/8000 (96%)]\tTotal Loss: 0.067922, Discriminator: 0.043540; Generator: 0.024382,\n",
      "D(x): 0.458, D(G(z)): 0.458\n",
      "2019-05-02 20:41:03,723 root         INFO     ====> Epoch: 10 Average loss: 0.0682\n",
      "2019-05-02 20:41:03,760 root         INFO     Train Epoch: 11 [0/8000 (0%)]\tTotal Loss: 0.067903, Discriminator: 0.043537; Generator: 0.024365,\n",
      "D(x): 0.459, D(G(z)): 0.459\n",
      "2019-05-02 20:41:03,818 root         INFO     Train Epoch: 11 [512/8000 (6%)]\tTotal Loss: 0.067871, Discriminator: 0.043533; Generator: 0.024338,\n",
      "D(x): 0.459, D(G(z)): 0.459\n",
      "2019-05-02 20:41:03,876 root         INFO     Train Epoch: 11 [1024/8000 (13%)]\tTotal Loss: 0.067840, Discriminator: 0.043529; Generator: 0.024311,\n",
      "D(x): 0.459, D(G(z)): 0.459\n",
      "2019-05-02 20:41:03,936 root         INFO     Train Epoch: 11 [1536/8000 (19%)]\tTotal Loss: 0.067809, Discriminator: 0.043525; Generator: 0.024284,\n",
      "D(x): 0.460, D(G(z)): 0.460\n",
      "2019-05-02 20:41:03,996 root         INFO     Train Epoch: 11 [2048/8000 (26%)]\tTotal Loss: 0.067779, Discriminator: 0.043521; Generator: 0.024258,\n",
      "D(x): 0.460, D(G(z)): 0.460\n",
      "2019-05-02 20:41:04,055 root         INFO     Train Epoch: 11 [2560/8000 (32%)]\tTotal Loss: 0.067749, Discriminator: 0.043517; Generator: 0.024232,\n",
      "D(x): 0.461, D(G(z)): 0.461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:04,114 root         INFO     Train Epoch: 11 [3072/8000 (38%)]\tTotal Loss: 0.067719, Discriminator: 0.043513; Generator: 0.024206,\n",
      "D(x): 0.461, D(G(z)): 0.461\n",
      "2019-05-02 20:41:04,172 root         INFO     Train Epoch: 11 [3584/8000 (45%)]\tTotal Loss: 0.067690, Discriminator: 0.043510; Generator: 0.024180,\n",
      "D(x): 0.461, D(G(z)): 0.461\n",
      "2019-05-02 20:41:04,229 root         INFO     Train Epoch: 11 [4096/8000 (51%)]\tTotal Loss: 0.067661, Discriminator: 0.043506; Generator: 0.024155,\n",
      "D(x): 0.462, D(G(z)): 0.462\n",
      "2019-05-02 20:41:04,286 root         INFO     Train Epoch: 11 [4608/8000 (58%)]\tTotal Loss: 0.067632, Discriminator: 0.043503; Generator: 0.024130,\n",
      "D(x): 0.462, D(G(z)): 0.462\n",
      "2019-05-02 20:41:04,343 root         INFO     Train Epoch: 11 [5120/8000 (64%)]\tTotal Loss: 0.067604, Discriminator: 0.043499; Generator: 0.024105,\n",
      "D(x): 0.462, D(G(z)): 0.462\n",
      "2019-05-02 20:41:04,400 root         INFO     Train Epoch: 11 [5632/8000 (70%)]\tTotal Loss: 0.067576, Discriminator: 0.043496; Generator: 0.024080,\n",
      "D(x): 0.463, D(G(z)): 0.463\n",
      "2019-05-02 20:41:04,456 root         INFO     Train Epoch: 11 [6144/8000 (77%)]\tTotal Loss: 0.067548, Discriminator: 0.043492; Generator: 0.024056,\n",
      "D(x): 0.463, D(G(z)): 0.463\n",
      "2019-05-02 20:41:04,513 root         INFO     Train Epoch: 11 [6656/8000 (83%)]\tTotal Loss: 0.067521, Discriminator: 0.043489; Generator: 0.024032,\n",
      "D(x): 0.463, D(G(z)): 0.463\n",
      "2019-05-02 20:41:04,570 root         INFO     Train Epoch: 11 [7168/8000 (90%)]\tTotal Loss: 0.067493, Discriminator: 0.043486; Generator: 0.024008,\n",
      "D(x): 0.464, D(G(z)): 0.464\n",
      "2019-05-02 20:41:04,628 root         INFO     Train Epoch: 11 [7680/8000 (96%)]\tTotal Loss: 0.067467, Discriminator: 0.043483; Generator: 0.023984,\n",
      "D(x): 0.464, D(G(z)): 0.464\n",
      "2019-05-02 20:41:04,690 root         INFO     ====> Epoch: 11 Average loss: 0.0677\n",
      "2019-05-02 20:41:04,726 root         INFO     Train Epoch: 12 [0/8000 (0%)]\tTotal Loss: 0.067450, Discriminator: 0.043481; Generator: 0.023969,\n",
      "D(x): 0.464, D(G(z)): 0.464\n",
      "2019-05-02 20:41:04,785 root         INFO     Train Epoch: 12 [512/8000 (6%)]\tTotal Loss: 0.067424, Discriminator: 0.043477; Generator: 0.023946,\n",
      "D(x): 0.465, D(G(z)): 0.465\n",
      "2019-05-02 20:41:04,843 root         INFO     Train Epoch: 12 [1024/8000 (13%)]\tTotal Loss: 0.067397, Discriminator: 0.043474; Generator: 0.023923,\n",
      "D(x): 0.465, D(G(z)): 0.465\n",
      "2019-05-02 20:41:04,901 root         INFO     Train Epoch: 12 [1536/8000 (19%)]\tTotal Loss: 0.067372, Discriminator: 0.043471; Generator: 0.023900,\n",
      "D(x): 0.465, D(G(z)): 0.465\n",
      "2019-05-02 20:41:04,959 root         INFO     Train Epoch: 12 [2048/8000 (26%)]\tTotal Loss: 0.067346, Discriminator: 0.043469; Generator: 0.023877,\n",
      "D(x): 0.466, D(G(z)): 0.466\n",
      "2019-05-02 20:41:05,017 root         INFO     Train Epoch: 12 [2560/8000 (32%)]\tTotal Loss: 0.067321, Discriminator: 0.043466; Generator: 0.023855,\n",
      "D(x): 0.466, D(G(z)): 0.466\n",
      "2019-05-02 20:41:05,074 root         INFO     Train Epoch: 12 [3072/8000 (38%)]\tTotal Loss: 0.067296, Discriminator: 0.043463; Generator: 0.023833,\n",
      "D(x): 0.466, D(G(z)): 0.466\n",
      "2019-05-02 20:41:05,132 root         INFO     Train Epoch: 12 [3584/8000 (45%)]\tTotal Loss: 0.067271, Discriminator: 0.043460; Generator: 0.023811,\n",
      "D(x): 0.467, D(G(z)): 0.467\n",
      "2019-05-02 20:41:05,190 root         INFO     Train Epoch: 12 [4096/8000 (51%)]\tTotal Loss: 0.067247, Discriminator: 0.043457; Generator: 0.023789,\n",
      "D(x): 0.467, D(G(z)): 0.467\n",
      "2019-05-02 20:41:05,248 root         INFO     Train Epoch: 12 [4608/8000 (58%)]\tTotal Loss: 0.067222, Discriminator: 0.043455; Generator: 0.023768,\n",
      "D(x): 0.467, D(G(z)): 0.467\n",
      "2019-05-02 20:41:05,306 root         INFO     Train Epoch: 12 [5120/8000 (64%)]\tTotal Loss: 0.067199, Discriminator: 0.043452; Generator: 0.023746,\n",
      "D(x): 0.468, D(G(z)): 0.468\n",
      "2019-05-02 20:41:05,364 root         INFO     Train Epoch: 12 [5632/8000 (70%)]\tTotal Loss: 0.067175, Discriminator: 0.043450; Generator: 0.023725,\n",
      "D(x): 0.468, D(G(z)): 0.468\n",
      "2019-05-02 20:41:05,422 root         INFO     Train Epoch: 12 [6144/8000 (77%)]\tTotal Loss: 0.067152, Discriminator: 0.043447; Generator: 0.023704,\n",
      "D(x): 0.468, D(G(z)): 0.468\n",
      "2019-05-02 20:41:05,479 root         INFO     Train Epoch: 12 [6656/8000 (83%)]\tTotal Loss: 0.067128, Discriminator: 0.043445; Generator: 0.023684,\n",
      "D(x): 0.469, D(G(z)): 0.469\n",
      "2019-05-02 20:41:05,537 root         INFO     Train Epoch: 12 [7168/8000 (90%)]\tTotal Loss: 0.067106, Discriminator: 0.043442; Generator: 0.023663,\n",
      "D(x): 0.469, D(G(z)): 0.469\n",
      "2019-05-02 20:41:05,594 root         INFO     Train Epoch: 12 [7680/8000 (96%)]\tTotal Loss: 0.067083, Discriminator: 0.043440; Generator: 0.023643,\n",
      "D(x): 0.469, D(G(z)): 0.469\n",
      "2019-05-02 20:41:05,656 root         INFO     ====> Epoch: 12 Average loss: 0.0673\n",
      "2019-05-02 20:41:05,692 root         INFO     Train Epoch: 13 [0/8000 (0%)]\tTotal Loss: 0.067069, Discriminator: 0.043439; Generator: 0.023630,\n",
      "D(x): 0.469, D(G(z)): 0.469\n",
      "2019-05-02 20:41:05,751 root         INFO     Train Epoch: 13 [512/8000 (6%)]\tTotal Loss: 0.067047, Discriminator: 0.043436; Generator: 0.023610,\n",
      "D(x): 0.470, D(G(z)): 0.470\n",
      "2019-05-02 20:41:05,808 root         INFO     Train Epoch: 13 [1024/8000 (13%)]\tTotal Loss: 0.067025, Discriminator: 0.043434; Generator: 0.023591,\n",
      "D(x): 0.470, D(G(z)): 0.470\n",
      "2019-05-02 20:41:05,865 root         INFO     Train Epoch: 13 [1536/8000 (19%)]\tTotal Loss: 0.067003, Discriminator: 0.043432; Generator: 0.023571,\n",
      "D(x): 0.470, D(G(z)): 0.470\n",
      "2019-05-02 20:41:05,922 root         INFO     Train Epoch: 13 [2048/8000 (26%)]\tTotal Loss: 0.066981, Discriminator: 0.043430; Generator: 0.023552,\n",
      "D(x): 0.471, D(G(z)): 0.471\n",
      "2019-05-02 20:41:05,979 root         INFO     Train Epoch: 13 [2560/8000 (32%)]\tTotal Loss: 0.066960, Discriminator: 0.043428; Generator: 0.023533,\n",
      "D(x): 0.471, D(G(z)): 0.471\n",
      "2019-05-02 20:41:06,036 root         INFO     Train Epoch: 13 [3072/8000 (38%)]\tTotal Loss: 0.066939, Discriminator: 0.043425; Generator: 0.023514,\n",
      "D(x): 0.471, D(G(z)): 0.471\n",
      "2019-05-02 20:41:06,093 root         INFO     Train Epoch: 13 [3584/8000 (45%)]\tTotal Loss: 0.066918, Discriminator: 0.043423; Generator: 0.023495,\n",
      "D(x): 0.471, D(G(z)): 0.471\n",
      "2019-05-02 20:41:06,150 root         INFO     Train Epoch: 13 [4096/8000 (51%)]\tTotal Loss: 0.066898, Discriminator: 0.043421; Generator: 0.023476,\n",
      "D(x): 0.472, D(G(z)): 0.472\n",
      "2019-05-02 20:41:06,206 root         INFO     Train Epoch: 13 [4608/8000 (58%)]\tTotal Loss: 0.066877, Discriminator: 0.043419; Generator: 0.023458,\n",
      "D(x): 0.472, D(G(z)): 0.472\n",
      "2019-05-02 20:41:06,263 root         INFO     Train Epoch: 13 [5120/8000 (64%)]\tTotal Loss: 0.066857, Discriminator: 0.043418; Generator: 0.023440,\n",
      "D(x): 0.472, D(G(z)): 0.472\n",
      "2019-05-02 20:41:06,319 root         INFO     Train Epoch: 13 [5632/8000 (70%)]\tTotal Loss: 0.066837, Discriminator: 0.043416; Generator: 0.023422,\n",
      "D(x): 0.473, D(G(z)): 0.473\n",
      "2019-05-02 20:41:06,376 root         INFO     Train Epoch: 13 [6144/8000 (77%)]\tTotal Loss: 0.066818, Discriminator: 0.043414; Generator: 0.023404,\n",
      "D(x): 0.473, D(G(z)): 0.473\n",
      "2019-05-02 20:41:06,433 root         INFO     Train Epoch: 13 [6656/8000 (83%)]\tTotal Loss: 0.066798, Discriminator: 0.043412; Generator: 0.023386,\n",
      "D(x): 0.473, D(G(z)): 0.473\n",
      "2019-05-02 20:41:06,489 root         INFO     Train Epoch: 13 [7168/8000 (90%)]\tTotal Loss: 0.066779, Discriminator: 0.043410; Generator: 0.023369,\n",
      "D(x): 0.473, D(G(z)): 0.473\n",
      "2019-05-02 20:41:06,546 root         INFO     Train Epoch: 13 [7680/8000 (96%)]\tTotal Loss: 0.066760, Discriminator: 0.043408; Generator: 0.023351,\n",
      "D(x): 0.474, D(G(z)): 0.474\n",
      "2019-05-02 20:41:06,607 root         INFO     ====> Epoch: 13 Average loss: 0.0669\n",
      "2019-05-02 20:41:06,643 root         INFO     Train Epoch: 14 [0/8000 (0%)]\tTotal Loss: 0.066748, Discriminator: 0.043407; Generator: 0.023341,\n",
      "D(x): 0.474, D(G(z)): 0.474\n",
      "2019-05-02 20:41:06,700 root         INFO     Train Epoch: 14 [512/8000 (6%)]\tTotal Loss: 0.066729, Discriminator: 0.043406; Generator: 0.023323,\n",
      "D(x): 0.474, D(G(z)): 0.474\n",
      "2019-05-02 20:41:06,757 root         INFO     Train Epoch: 14 [1024/8000 (13%)]\tTotal Loss: 0.066711, Discriminator: 0.043404; Generator: 0.023307,\n",
      "D(x): 0.474, D(G(z)): 0.474\n",
      "2019-05-02 20:41:06,815 root         INFO     Train Epoch: 14 [1536/8000 (19%)]\tTotal Loss: 0.066692, Discriminator: 0.043402; Generator: 0.023290,\n",
      "D(x): 0.475, D(G(z)): 0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:06,872 root         INFO     Train Epoch: 14 [2048/8000 (26%)]\tTotal Loss: 0.066674, Discriminator: 0.043401; Generator: 0.023273,\n",
      "D(x): 0.475, D(G(z)): 0.475\n",
      "2019-05-02 20:41:06,929 root         INFO     Train Epoch: 14 [2560/8000 (32%)]\tTotal Loss: 0.066656, Discriminator: 0.043399; Generator: 0.023257,\n",
      "D(x): 0.475, D(G(z)): 0.475\n",
      "2019-05-02 20:41:06,985 root         INFO     Train Epoch: 14 [3072/8000 (38%)]\tTotal Loss: 0.066638, Discriminator: 0.043398; Generator: 0.023241,\n",
      "D(x): 0.475, D(G(z)): 0.475\n",
      "2019-05-02 20:41:07,042 root         INFO     Train Epoch: 14 [3584/8000 (45%)]\tTotal Loss: 0.066621, Discriminator: 0.043396; Generator: 0.023225,\n",
      "D(x): 0.476, D(G(z)): 0.476\n",
      "2019-05-02 20:41:07,098 root         INFO     Train Epoch: 14 [4096/8000 (51%)]\tTotal Loss: 0.066604, Discriminator: 0.043395; Generator: 0.023209,\n",
      "D(x): 0.476, D(G(z)): 0.476\n",
      "2019-05-02 20:41:07,154 root         INFO     Train Epoch: 14 [4608/8000 (58%)]\tTotal Loss: 0.066586, Discriminator: 0.043393; Generator: 0.023193,\n",
      "D(x): 0.476, D(G(z)): 0.476\n",
      "2019-05-02 20:41:07,211 root         INFO     Train Epoch: 14 [5120/8000 (64%)]\tTotal Loss: 0.066569, Discriminator: 0.043392; Generator: 0.023177,\n",
      "D(x): 0.476, D(G(z)): 0.476\n",
      "2019-05-02 20:41:07,268 root         INFO     Train Epoch: 14 [5632/8000 (70%)]\tTotal Loss: 0.066553, Discriminator: 0.043391; Generator: 0.023162,\n",
      "D(x): 0.477, D(G(z)): 0.477\n",
      "2019-05-02 20:41:07,325 root         INFO     Train Epoch: 14 [6144/8000 (77%)]\tTotal Loss: 0.066536, Discriminator: 0.043389; Generator: 0.023147,\n",
      "D(x): 0.477, D(G(z)): 0.477\n",
      "2019-05-02 20:41:07,382 root         INFO     Train Epoch: 14 [6656/8000 (83%)]\tTotal Loss: 0.066519, Discriminator: 0.043388; Generator: 0.023132,\n",
      "D(x): 0.477, D(G(z)): 0.477\n",
      "2019-05-02 20:41:07,439 root         INFO     Train Epoch: 14 [7168/8000 (90%)]\tTotal Loss: 0.066503, Discriminator: 0.043387; Generator: 0.023117,\n",
      "D(x): 0.477, D(G(z)): 0.477\n",
      "2019-05-02 20:41:07,496 root         INFO     Train Epoch: 14 [7680/8000 (96%)]\tTotal Loss: 0.066487, Discriminator: 0.043385; Generator: 0.023102,\n",
      "D(x): 0.477, D(G(z)): 0.477\n",
      "2019-05-02 20:41:07,557 root         INFO     ====> Epoch: 14 Average loss: 0.0666\n",
      "2019-05-02 20:41:07,593 root         INFO     Train Epoch: 15 [0/8000 (0%)]\tTotal Loss: 0.066477, Discriminator: 0.043384; Generator: 0.023093,\n",
      "D(x): 0.478, D(G(z)): 0.478\n",
      "2019-05-02 20:41:07,651 root         INFO     Train Epoch: 15 [512/8000 (6%)]\tTotal Loss: 0.066461, Discriminator: 0.043383; Generator: 0.023078,\n",
      "D(x): 0.478, D(G(z)): 0.478\n",
      "2019-05-02 20:41:07,708 root         INFO     Train Epoch: 15 [1024/8000 (13%)]\tTotal Loss: 0.066446, Discriminator: 0.043382; Generator: 0.023064,\n",
      "D(x): 0.478, D(G(z)): 0.478\n",
      "2019-05-02 20:41:07,765 root         INFO     Train Epoch: 15 [1536/8000 (19%)]\tTotal Loss: 0.066430, Discriminator: 0.043381; Generator: 0.023049,\n",
      "D(x): 0.478, D(G(z)): 0.478\n",
      "2019-05-02 20:41:07,823 root         INFO     Train Epoch: 15 [2048/8000 (26%)]\tTotal Loss: 0.066415, Discriminator: 0.043380; Generator: 0.023035,\n",
      "D(x): 0.478, D(G(z)): 0.478\n",
      "2019-05-02 20:41:07,880 root         INFO     Train Epoch: 15 [2560/8000 (32%)]\tTotal Loss: 0.066400, Discriminator: 0.043378; Generator: 0.023021,\n",
      "D(x): 0.479, D(G(z)): 0.479\n",
      "2019-05-02 20:41:07,938 root         INFO     Train Epoch: 15 [3072/8000 (38%)]\tTotal Loss: 0.066385, Discriminator: 0.043377; Generator: 0.023007,\n",
      "D(x): 0.479, D(G(z)): 0.479\n",
      "2019-05-02 20:41:07,995 root         INFO     Train Epoch: 15 [3584/8000 (45%)]\tTotal Loss: 0.066370, Discriminator: 0.043376; Generator: 0.022994,\n",
      "D(x): 0.479, D(G(z)): 0.479\n",
      "2019-05-02 20:41:08,052 root         INFO     Train Epoch: 15 [4096/8000 (51%)]\tTotal Loss: 0.066355, Discriminator: 0.043375; Generator: 0.022980,\n",
      "D(x): 0.479, D(G(z)): 0.479\n",
      "2019-05-02 20:41:08,109 root         INFO     Train Epoch: 15 [4608/8000 (58%)]\tTotal Loss: 0.066341, Discriminator: 0.043374; Generator: 0.022967,\n",
      "D(x): 0.480, D(G(z)): 0.480\n",
      "2019-05-02 20:41:08,166 root         INFO     Train Epoch: 15 [5120/8000 (64%)]\tTotal Loss: 0.066327, Discriminator: 0.043373; Generator: 0.022953,\n",
      "D(x): 0.480, D(G(z)): 0.480\n",
      "2019-05-02 20:41:08,223 root         INFO     Train Epoch: 15 [5632/8000 (70%)]\tTotal Loss: 0.066312, Discriminator: 0.043372; Generator: 0.022940,\n",
      "D(x): 0.480, D(G(z)): 0.480\n",
      "2019-05-02 20:41:08,280 root         INFO     Train Epoch: 15 [6144/8000 (77%)]\tTotal Loss: 0.066298, Discriminator: 0.043371; Generator: 0.022927,\n",
      "D(x): 0.480, D(G(z)): 0.480\n",
      "2019-05-02 20:41:08,337 root         INFO     Train Epoch: 15 [6656/8000 (83%)]\tTotal Loss: 0.066284, Discriminator: 0.043370; Generator: 0.022914,\n",
      "D(x): 0.480, D(G(z)): 0.480\n",
      "2019-05-02 20:41:08,394 root         INFO     Train Epoch: 15 [7168/8000 (90%)]\tTotal Loss: 0.066271, Discriminator: 0.043369; Generator: 0.022902,\n",
      "D(x): 0.481, D(G(z)): 0.481\n",
      "2019-05-02 20:41:08,452 root         INFO     Train Epoch: 15 [7680/8000 (96%)]\tTotal Loss: 0.066257, Discriminator: 0.043368; Generator: 0.022889,\n",
      "D(x): 0.481, D(G(z)): 0.481\n",
      "2019-05-02 20:41:08,513 root         INFO     ====> Epoch: 15 Average loss: 0.0664\n",
      "2019-05-02 20:41:08,549 root         INFO     Train Epoch: 16 [0/8000 (0%)]\tTotal Loss: 0.066249, Discriminator: 0.043368; Generator: 0.022881,\n",
      "D(x): 0.481, D(G(z)): 0.481\n",
      "2019-05-02 20:41:08,606 root         INFO     Train Epoch: 16 [512/8000 (6%)]\tTotal Loss: 0.066235, Discriminator: 0.043367; Generator: 0.022869,\n",
      "D(x): 0.481, D(G(z)): 0.481\n",
      "2019-05-02 20:41:08,663 root         INFO     Train Epoch: 16 [1024/8000 (13%)]\tTotal Loss: 0.066222, Discriminator: 0.043366; Generator: 0.022856,\n",
      "D(x): 0.481, D(G(z)): 0.481\n",
      "2019-05-02 20:41:08,720 root         INFO     Train Epoch: 16 [1536/8000 (19%)]\tTotal Loss: 0.066209, Discriminator: 0.043365; Generator: 0.022844,\n",
      "D(x): 0.481, D(G(z)): 0.481\n",
      "2019-05-02 20:41:08,778 root         INFO     Train Epoch: 16 [2048/8000 (26%)]\tTotal Loss: 0.066196, Discriminator: 0.043364; Generator: 0.022832,\n",
      "D(x): 0.482, D(G(z)): 0.482\n",
      "2019-05-02 20:41:08,835 root         INFO     Train Epoch: 16 [2560/8000 (32%)]\tTotal Loss: 0.066183, Discriminator: 0.043363; Generator: 0.022820,\n",
      "D(x): 0.482, D(G(z)): 0.482\n",
      "2019-05-02 20:41:08,892 root         INFO     Train Epoch: 16 [3072/8000 (38%)]\tTotal Loss: 0.066171, Discriminator: 0.043362; Generator: 0.022808,\n",
      "D(x): 0.482, D(G(z)): 0.482\n",
      "2019-05-02 20:41:08,950 root         INFO     Train Epoch: 16 [3584/8000 (45%)]\tTotal Loss: 0.066158, Discriminator: 0.043362; Generator: 0.022797,\n",
      "D(x): 0.482, D(G(z)): 0.482\n",
      "2019-05-02 20:41:09,009 root         INFO     Train Epoch: 16 [4096/8000 (51%)]\tTotal Loss: 0.066146, Discriminator: 0.043361; Generator: 0.022785,\n",
      "D(x): 0.482, D(G(z)): 0.482\n",
      "2019-05-02 20:41:09,067 root         INFO     Train Epoch: 16 [4608/8000 (58%)]\tTotal Loss: 0.066133, Discriminator: 0.043360; Generator: 0.022774,\n",
      "D(x): 0.483, D(G(z)): 0.483\n",
      "2019-05-02 20:41:09,126 root         INFO     Train Epoch: 16 [5120/8000 (64%)]\tTotal Loss: 0.066121, Discriminator: 0.043359; Generator: 0.022762,\n",
      "D(x): 0.483, D(G(z)): 0.483\n",
      "2019-05-02 20:41:09,184 root         INFO     Train Epoch: 16 [5632/8000 (70%)]\tTotal Loss: 0.066109, Discriminator: 0.043358; Generator: 0.022751,\n",
      "D(x): 0.483, D(G(z)): 0.483\n",
      "2019-05-02 20:41:09,243 root         INFO     Train Epoch: 16 [6144/8000 (77%)]\tTotal Loss: 0.066098, Discriminator: 0.043358; Generator: 0.022740,\n",
      "D(x): 0.483, D(G(z)): 0.483\n",
      "2019-05-02 20:41:09,302 root         INFO     Train Epoch: 16 [6656/8000 (83%)]\tTotal Loss: 0.066086, Discriminator: 0.043357; Generator: 0.022729,\n",
      "D(x): 0.483, D(G(z)): 0.483\n",
      "2019-05-02 20:41:09,359 root         INFO     Train Epoch: 16 [7168/8000 (90%)]\tTotal Loss: 0.066074, Discriminator: 0.043356; Generator: 0.022718,\n",
      "D(x): 0.483, D(G(z)): 0.483\n",
      "2019-05-02 20:41:09,417 root         INFO     Train Epoch: 16 [7680/8000 (96%)]\tTotal Loss: 0.066063, Discriminator: 0.043356; Generator: 0.022707,\n",
      "D(x): 0.484, D(G(z)): 0.484\n",
      "2019-05-02 20:41:09,479 root         INFO     ====> Epoch: 16 Average loss: 0.0661\n",
      "2019-05-02 20:41:09,515 root         INFO     Train Epoch: 17 [0/8000 (0%)]\tTotal Loss: 0.066056, Discriminator: 0.043355; Generator: 0.022700,\n",
      "D(x): 0.484, D(G(z)): 0.484\n",
      "2019-05-02 20:41:09,573 root         INFO     Train Epoch: 17 [512/8000 (6%)]\tTotal Loss: 0.066044, Discriminator: 0.043355; Generator: 0.022690,\n",
      "D(x): 0.484, D(G(z)): 0.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:09,630 root         INFO     Train Epoch: 17 [1024/8000 (13%)]\tTotal Loss: 0.066033, Discriminator: 0.043354; Generator: 0.022679,\n",
      "D(x): 0.484, D(G(z)): 0.484\n",
      "2019-05-02 20:41:09,687 root         INFO     Train Epoch: 17 [1536/8000 (19%)]\tTotal Loss: 0.066022, Discriminator: 0.043353; Generator: 0.022669,\n",
      "D(x): 0.484, D(G(z)): 0.484\n",
      "2019-05-02 20:41:09,744 root         INFO     Train Epoch: 17 [2048/8000 (26%)]\tTotal Loss: 0.066011, Discriminator: 0.043353; Generator: 0.022659,\n",
      "D(x): 0.484, D(G(z)): 0.484\n",
      "2019-05-02 20:41:09,801 root         INFO     Train Epoch: 17 [2560/8000 (32%)]\tTotal Loss: 0.066000, Discriminator: 0.043352; Generator: 0.022648,\n",
      "D(x): 0.484, D(G(z)): 0.484\n",
      "2019-05-02 20:41:09,858 root         INFO     Train Epoch: 17 [3072/8000 (38%)]\tTotal Loss: 0.065990, Discriminator: 0.043351; Generator: 0.022638,\n",
      "D(x): 0.485, D(G(z)): 0.485\n",
      "2019-05-02 20:41:09,916 root         INFO     Train Epoch: 17 [3584/8000 (45%)]\tTotal Loss: 0.065979, Discriminator: 0.043351; Generator: 0.022628,\n",
      "D(x): 0.485, D(G(z)): 0.485\n",
      "2019-05-02 20:41:09,974 root         INFO     Train Epoch: 17 [4096/8000 (51%)]\tTotal Loss: 0.065969, Discriminator: 0.043350; Generator: 0.022618,\n",
      "D(x): 0.485, D(G(z)): 0.485\n",
      "2019-05-02 20:41:10,031 root         INFO     Train Epoch: 17 [4608/8000 (58%)]\tTotal Loss: 0.065958, Discriminator: 0.043350; Generator: 0.022609,\n",
      "D(x): 0.485, D(G(z)): 0.485\n",
      "2019-05-02 20:41:10,089 root         INFO     Train Epoch: 17 [5120/8000 (64%)]\tTotal Loss: 0.065948, Discriminator: 0.043349; Generator: 0.022599,\n",
      "D(x): 0.485, D(G(z)): 0.485\n",
      "2019-05-02 20:41:10,147 root         INFO     Train Epoch: 17 [5632/8000 (70%)]\tTotal Loss: 0.065938, Discriminator: 0.043348; Generator: 0.022589,\n",
      "D(x): 0.485, D(G(z)): 0.485\n",
      "2019-05-02 20:41:10,205 root         INFO     Train Epoch: 17 [6144/8000 (77%)]\tTotal Loss: 0.065928, Discriminator: 0.043348; Generator: 0.022580,\n",
      "D(x): 0.486, D(G(z)): 0.486\n",
      "2019-05-02 20:41:10,262 root         INFO     Train Epoch: 17 [6656/8000 (83%)]\tTotal Loss: 0.065918, Discriminator: 0.043347; Generator: 0.022571,\n",
      "D(x): 0.486, D(G(z)): 0.486\n",
      "2019-05-02 20:41:10,320 root         INFO     Train Epoch: 17 [7168/8000 (90%)]\tTotal Loss: 0.065908, Discriminator: 0.043347; Generator: 0.022561,\n",
      "D(x): 0.486, D(G(z)): 0.486\n",
      "2019-05-02 20:41:10,378 root         INFO     Train Epoch: 17 [7680/8000 (96%)]\tTotal Loss: 0.065898, Discriminator: 0.043346; Generator: 0.022552,\n",
      "D(x): 0.486, D(G(z)): 0.486\n",
      "2019-05-02 20:41:10,439 root         INFO     ====> Epoch: 17 Average loss: 0.0660\n",
      "2019-05-02 20:41:10,475 root         INFO     Train Epoch: 18 [0/8000 (0%)]\tTotal Loss: 0.065892, Discriminator: 0.043346; Generator: 0.022546,\n",
      "D(x): 0.486, D(G(z)): 0.486\n",
      "2019-05-02 20:41:10,533 root         INFO     Train Epoch: 18 [512/8000 (6%)]\tTotal Loss: 0.065883, Discriminator: 0.043346; Generator: 0.022537,\n",
      "D(x): 0.486, D(G(z)): 0.486\n",
      "2019-05-02 20:41:10,590 root         INFO     Train Epoch: 18 [1024/8000 (13%)]\tTotal Loss: 0.065873, Discriminator: 0.043345; Generator: 0.022528,\n",
      "D(x): 0.486, D(G(z)): 0.486\n",
      "2019-05-02 20:41:10,648 root         INFO     Train Epoch: 18 [1536/8000 (19%)]\tTotal Loss: 0.065864, Discriminator: 0.043345; Generator: 0.022519,\n",
      "D(x): 0.486, D(G(z)): 0.486\n",
      "2019-05-02 20:41:10,705 root         INFO     Train Epoch: 18 [2048/8000 (26%)]\tTotal Loss: 0.065855, Discriminator: 0.043344; Generator: 0.022511,\n",
      "D(x): 0.487, D(G(z)): 0.487\n",
      "2019-05-02 20:41:10,763 root         INFO     Train Epoch: 18 [2560/8000 (32%)]\tTotal Loss: 0.065846, Discriminator: 0.043344; Generator: 0.022502,\n",
      "D(x): 0.487, D(G(z)): 0.487\n",
      "2019-05-02 20:41:10,821 root         INFO     Train Epoch: 18 [3072/8000 (38%)]\tTotal Loss: 0.065837, Discriminator: 0.043343; Generator: 0.022493,\n",
      "D(x): 0.487, D(G(z)): 0.487\n",
      "2019-05-02 20:41:10,878 root         INFO     Train Epoch: 18 [3584/8000 (45%)]\tTotal Loss: 0.065828, Discriminator: 0.043343; Generator: 0.022485,\n",
      "D(x): 0.487, D(G(z)): 0.487\n",
      "2019-05-02 20:41:10,936 root         INFO     Train Epoch: 18 [4096/8000 (51%)]\tTotal Loss: 0.065819, Discriminator: 0.043342; Generator: 0.022476,\n",
      "D(x): 0.487, D(G(z)): 0.487\n",
      "2019-05-02 20:41:10,994 root         INFO     Train Epoch: 18 [4608/8000 (58%)]\tTotal Loss: 0.065810, Discriminator: 0.043342; Generator: 0.022468,\n",
      "D(x): 0.487, D(G(z)): 0.487\n",
      "2019-05-02 20:41:11,051 root         INFO     Train Epoch: 18 [5120/8000 (64%)]\tTotal Loss: 0.065801, Discriminator: 0.043342; Generator: 0.022460,\n",
      "D(x): 0.487, D(G(z)): 0.487\n",
      "2019-05-02 20:41:11,109 root         INFO     Train Epoch: 18 [5632/8000 (70%)]\tTotal Loss: 0.065793, Discriminator: 0.043341; Generator: 0.022452,\n",
      "D(x): 0.488, D(G(z)): 0.488\n",
      "2019-05-02 20:41:11,167 root         INFO     Train Epoch: 18 [6144/8000 (77%)]\tTotal Loss: 0.065784, Discriminator: 0.043341; Generator: 0.022444,\n",
      "D(x): 0.488, D(G(z)): 0.488\n",
      "2019-05-02 20:41:11,224 root         INFO     Train Epoch: 18 [6656/8000 (83%)]\tTotal Loss: 0.065776, Discriminator: 0.043340; Generator: 0.022436,\n",
      "D(x): 0.488, D(G(z)): 0.488\n",
      "2019-05-02 20:41:11,282 root         INFO     Train Epoch: 18 [7168/8000 (90%)]\tTotal Loss: 0.065768, Discriminator: 0.043340; Generator: 0.022428,\n",
      "D(x): 0.488, D(G(z)): 0.488\n",
      "2019-05-02 20:41:11,340 root         INFO     Train Epoch: 18 [7680/8000 (96%)]\tTotal Loss: 0.065759, Discriminator: 0.043340; Generator: 0.022420,\n",
      "D(x): 0.488, D(G(z)): 0.488\n",
      "2019-05-02 20:41:11,401 root         INFO     ====> Epoch: 18 Average loss: 0.0658\n",
      "2019-05-02 20:41:11,438 root         INFO     Train Epoch: 19 [0/8000 (0%)]\tTotal Loss: 0.065754, Discriminator: 0.043339; Generator: 0.022415,\n",
      "D(x): 0.488, D(G(z)): 0.488\n",
      "2019-05-02 20:41:11,498 root         INFO     Train Epoch: 19 [512/8000 (6%)]\tTotal Loss: 0.065746, Discriminator: 0.043339; Generator: 0.022407,\n",
      "D(x): 0.488, D(G(z)): 0.488\n",
      "2019-05-02 20:41:11,557 root         INFO     Train Epoch: 19 [1024/8000 (13%)]\tTotal Loss: 0.065738, Discriminator: 0.043339; Generator: 0.022399,\n",
      "D(x): 0.488, D(G(z)): 0.488\n",
      "2019-05-02 20:41:11,615 root         INFO     Train Epoch: 19 [1536/8000 (19%)]\tTotal Loss: 0.065730, Discriminator: 0.043338; Generator: 0.022392,\n",
      "D(x): 0.488, D(G(z)): 0.488\n",
      "2019-05-02 20:41:11,674 root         INFO     Train Epoch: 19 [2048/8000 (26%)]\tTotal Loss: 0.065723, Discriminator: 0.043338; Generator: 0.022384,\n",
      "D(x): 0.489, D(G(z)): 0.489\n",
      "2019-05-02 20:41:11,733 root         INFO     Train Epoch: 19 [2560/8000 (32%)]\tTotal Loss: 0.065715, Discriminator: 0.043338; Generator: 0.022377,\n",
      "D(x): 0.489, D(G(z)): 0.489\n",
      "2019-05-02 20:41:11,792 root         INFO     Train Epoch: 19 [3072/8000 (38%)]\tTotal Loss: 0.065707, Discriminator: 0.043337; Generator: 0.022370,\n",
      "D(x): 0.489, D(G(z)): 0.489\n",
      "2019-05-02 20:41:11,851 root         INFO     Train Epoch: 19 [3584/8000 (45%)]\tTotal Loss: 0.065700, Discriminator: 0.043337; Generator: 0.022362,\n",
      "D(x): 0.489, D(G(z)): 0.489\n",
      "2019-05-02 20:41:11,910 root         INFO     Train Epoch: 19 [4096/8000 (51%)]\tTotal Loss: 0.065692, Discriminator: 0.043337; Generator: 0.022355,\n",
      "D(x): 0.489, D(G(z)): 0.489\n",
      "2019-05-02 20:41:11,969 root         INFO     Train Epoch: 19 [4608/8000 (58%)]\tTotal Loss: 0.065685, Discriminator: 0.043336; Generator: 0.022348,\n",
      "D(x): 0.489, D(G(z)): 0.489\n",
      "2019-05-02 20:41:12,028 root         INFO     Train Epoch: 19 [5120/8000 (64%)]\tTotal Loss: 0.065677, Discriminator: 0.043336; Generator: 0.022341,\n",
      "D(x): 0.489, D(G(z)): 0.489\n",
      "2019-05-02 20:41:12,086 root         INFO     Train Epoch: 19 [5632/8000 (70%)]\tTotal Loss: 0.065670, Discriminator: 0.043336; Generator: 0.022334,\n",
      "D(x): 0.489, D(G(z)): 0.489\n",
      "2019-05-02 20:41:12,147 root         INFO     Train Epoch: 19 [6144/8000 (77%)]\tTotal Loss: 0.065663, Discriminator: 0.043336; Generator: 0.022327,\n",
      "D(x): 0.489, D(G(z)): 0.489\n",
      "2019-05-02 20:41:12,206 root         INFO     Train Epoch: 19 [6656/8000 (83%)]\tTotal Loss: 0.065656, Discriminator: 0.043335; Generator: 0.022320,\n",
      "D(x): 0.490, D(G(z)): 0.490\n",
      "2019-05-02 20:41:12,265 root         INFO     Train Epoch: 19 [7168/8000 (90%)]\tTotal Loss: 0.065649, Discriminator: 0.043335; Generator: 0.022314,\n",
      "D(x): 0.490, D(G(z)): 0.490\n",
      "2019-05-02 20:41:12,321 root         INFO     Train Epoch: 19 [7680/8000 (96%)]\tTotal Loss: 0.065642, Discriminator: 0.043335; Generator: 0.022307,\n",
      "D(x): 0.490, D(G(z)): 0.490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:12,382 root         INFO     ====> Epoch: 19 Average loss: 0.0657\n",
      "2019-05-02 20:41:12,420 root         INFO     Train Epoch: 20 [0/8000 (0%)]\tTotal Loss: 0.065637, Discriminator: 0.043335; Generator: 0.022303,\n",
      "D(x): 0.490, D(G(z)): 0.490\n",
      "2019-05-02 20:41:12,478 root         INFO     Train Epoch: 20 [512/8000 (6%)]\tTotal Loss: 0.065631, Discriminator: 0.043334; Generator: 0.022296,\n",
      "D(x): 0.490, D(G(z)): 0.490\n",
      "2019-05-02 20:41:12,536 root         INFO     Train Epoch: 20 [1024/8000 (13%)]\tTotal Loss: 0.065624, Discriminator: 0.043334; Generator: 0.022290,\n",
      "D(x): 0.490, D(G(z)): 0.490\n",
      "2019-05-02 20:41:12,594 root         INFO     Train Epoch: 20 [1536/8000 (19%)]\tTotal Loss: 0.065617, Discriminator: 0.043334; Generator: 0.022283,\n",
      "D(x): 0.490, D(G(z)): 0.490\n",
      "2019-05-02 20:41:12,650 root         INFO     Train Epoch: 20 [2048/8000 (26%)]\tTotal Loss: 0.065611, Discriminator: 0.043334; Generator: 0.022277,\n",
      "D(x): 0.490, D(G(z)): 0.490\n",
      "2019-05-02 20:41:12,707 root         INFO     Train Epoch: 20 [2560/8000 (32%)]\tTotal Loss: 0.065604, Discriminator: 0.043333; Generator: 0.022271,\n",
      "D(x): 0.490, D(G(z)): 0.490\n",
      "2019-05-02 20:41:12,763 root         INFO     Train Epoch: 20 [3072/8000 (38%)]\tTotal Loss: 0.065597, Discriminator: 0.043333; Generator: 0.022264,\n",
      "D(x): 0.490, D(G(z)): 0.490\n",
      "2019-05-02 20:41:12,820 root         INFO     Train Epoch: 20 [3584/8000 (45%)]\tTotal Loss: 0.065591, Discriminator: 0.043333; Generator: 0.022258,\n",
      "D(x): 0.491, D(G(z)): 0.491\n",
      "2019-05-02 20:41:12,876 root         INFO     Train Epoch: 20 [4096/8000 (51%)]\tTotal Loss: 0.065585, Discriminator: 0.043333; Generator: 0.022252,\n",
      "D(x): 0.491, D(G(z)): 0.491\n",
      "2019-05-02 20:41:12,933 root         INFO     Train Epoch: 20 [4608/8000 (58%)]\tTotal Loss: 0.065578, Discriminator: 0.043332; Generator: 0.022246,\n",
      "D(x): 0.491, D(G(z)): 0.491\n",
      "2019-05-02 20:41:12,990 root         INFO     Train Epoch: 20 [5120/8000 (64%)]\tTotal Loss: 0.065572, Discriminator: 0.043332; Generator: 0.022240,\n",
      "D(x): 0.491, D(G(z)): 0.491\n",
      "2019-05-02 20:41:13,046 root         INFO     Train Epoch: 20 [5632/8000 (70%)]\tTotal Loss: 0.065566, Discriminator: 0.043332; Generator: 0.022234,\n",
      "D(x): 0.491, D(G(z)): 0.491\n",
      "2019-05-02 20:41:13,103 root         INFO     Train Epoch: 20 [6144/8000 (77%)]\tTotal Loss: 0.065560, Discriminator: 0.043332; Generator: 0.022228,\n",
      "D(x): 0.491, D(G(z)): 0.491\n",
      "2019-05-02 20:41:13,159 root         INFO     Train Epoch: 20 [6656/8000 (83%)]\tTotal Loss: 0.065554, Discriminator: 0.043332; Generator: 0.022222,\n",
      "D(x): 0.491, D(G(z)): 0.491\n",
      "2019-05-02 20:41:13,216 root         INFO     Train Epoch: 20 [7168/8000 (90%)]\tTotal Loss: 0.065548, Discriminator: 0.043331; Generator: 0.022217,\n",
      "D(x): 0.491, D(G(z)): 0.491\n",
      "2019-05-02 20:41:13,273 root         INFO     Train Epoch: 20 [7680/8000 (96%)]\tTotal Loss: 0.065542, Discriminator: 0.043331; Generator: 0.022211,\n",
      "D(x): 0.491, D(G(z)): 0.491\n",
      "2019-05-02 20:41:13,334 root         INFO     ====> Epoch: 20 Average loss: 0.0656\n",
      "2019-05-02 20:41:13,370 root         INFO     Train Epoch: 21 [0/8000 (0%)]\tTotal Loss: 0.065538, Discriminator: 0.043331; Generator: 0.022207,\n",
      "D(x): 0.491, D(G(z)): 0.491\n",
      "2019-05-02 20:41:13,428 root         INFO     Train Epoch: 21 [512/8000 (6%)]\tTotal Loss: 0.065533, Discriminator: 0.043331; Generator: 0.022202,\n",
      "D(x): 0.491, D(G(z)): 0.491\n",
      "2019-05-02 20:41:13,486 root         INFO     Train Epoch: 21 [1024/8000 (13%)]\tTotal Loss: 0.065527, Discriminator: 0.043331; Generator: 0.022196,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-05-02 20:41:13,544 root         INFO     Train Epoch: 21 [1536/8000 (19%)]\tTotal Loss: 0.065521, Discriminator: 0.043331; Generator: 0.022191,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-05-02 20:41:13,602 root         INFO     Train Epoch: 21 [2048/8000 (26%)]\tTotal Loss: 0.065516, Discriminator: 0.043330; Generator: 0.022185,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-05-02 20:41:13,660 root         INFO     Train Epoch: 21 [2560/8000 (32%)]\tTotal Loss: 0.065510, Discriminator: 0.043330; Generator: 0.022180,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-05-02 20:41:13,718 root         INFO     Train Epoch: 21 [3072/8000 (38%)]\tTotal Loss: 0.065505, Discriminator: 0.043330; Generator: 0.022175,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-05-02 20:41:13,776 root         INFO     Train Epoch: 21 [3584/8000 (45%)]\tTotal Loss: 0.065499, Discriminator: 0.043330; Generator: 0.022169,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-05-02 20:41:13,836 root         INFO     Train Epoch: 21 [4096/8000 (51%)]\tTotal Loss: 0.065494, Discriminator: 0.043330; Generator: 0.022164,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-05-02 20:41:13,895 root         INFO     Train Epoch: 21 [4608/8000 (58%)]\tTotal Loss: 0.065488, Discriminator: 0.043330; Generator: 0.022159,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-05-02 20:41:13,955 root         INFO     Train Epoch: 21 [5120/8000 (64%)]\tTotal Loss: 0.065483, Discriminator: 0.043329; Generator: 0.022154,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-05-02 20:41:14,014 root         INFO     Train Epoch: 21 [5632/8000 (70%)]\tTotal Loss: 0.065478, Discriminator: 0.043329; Generator: 0.022149,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-05-02 20:41:14,073 root         INFO     Train Epoch: 21 [6144/8000 (77%)]\tTotal Loss: 0.065473, Discriminator: 0.043329; Generator: 0.022144,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-05-02 20:41:14,131 root         INFO     Train Epoch: 21 [6656/8000 (83%)]\tTotal Loss: 0.065468, Discriminator: 0.043329; Generator: 0.022139,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-05-02 20:41:14,188 root         INFO     Train Epoch: 21 [7168/8000 (90%)]\tTotal Loss: 0.065463, Discriminator: 0.043329; Generator: 0.022134,\n",
      "D(x): 0.492, D(G(z)): 0.492\n",
      "2019-05-02 20:41:14,245 root         INFO     Train Epoch: 21 [7680/8000 (96%)]\tTotal Loss: 0.065458, Discriminator: 0.043329; Generator: 0.022129,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "2019-05-02 20:41:14,306 root         INFO     ====> Epoch: 21 Average loss: 0.0655\n",
      "2019-05-02 20:41:14,342 root         INFO     Train Epoch: 22 [0/8000 (0%)]\tTotal Loss: 0.065454, Discriminator: 0.043329; Generator: 0.022126,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "2019-05-02 20:41:14,401 root         INFO     Train Epoch: 22 [512/8000 (6%)]\tTotal Loss: 0.065450, Discriminator: 0.043328; Generator: 0.022121,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "2019-05-02 20:41:14,458 root         INFO     Train Epoch: 22 [1024/8000 (13%)]\tTotal Loss: 0.065445, Discriminator: 0.043328; Generator: 0.022116,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "2019-05-02 20:41:14,515 root         INFO     Train Epoch: 22 [1536/8000 (19%)]\tTotal Loss: 0.065440, Discriminator: 0.043328; Generator: 0.022112,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "2019-05-02 20:41:14,573 root         INFO     Train Epoch: 22 [2048/8000 (26%)]\tTotal Loss: 0.065435, Discriminator: 0.043328; Generator: 0.022107,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "2019-05-02 20:41:14,631 root         INFO     Train Epoch: 22 [2560/8000 (32%)]\tTotal Loss: 0.065430, Discriminator: 0.043328; Generator: 0.022103,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "2019-05-02 20:41:14,689 root         INFO     Train Epoch: 22 [3072/8000 (38%)]\tTotal Loss: 0.065426, Discriminator: 0.043328; Generator: 0.022098,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "2019-05-02 20:41:14,747 root         INFO     Train Epoch: 22 [3584/8000 (45%)]\tTotal Loss: 0.065421, Discriminator: 0.043328; Generator: 0.022094,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "2019-05-02 20:41:14,805 root         INFO     Train Epoch: 22 [4096/8000 (51%)]\tTotal Loss: 0.065417, Discriminator: 0.043327; Generator: 0.022089,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "2019-05-02 20:41:14,864 root         INFO     Train Epoch: 22 [4608/8000 (58%)]\tTotal Loss: 0.065412, Discriminator: 0.043327; Generator: 0.022085,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "2019-05-02 20:41:14,922 root         INFO     Train Epoch: 22 [5120/8000 (64%)]\tTotal Loss: 0.065408, Discriminator: 0.043327; Generator: 0.022080,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "2019-05-02 20:41:14,982 root         INFO     Train Epoch: 22 [5632/8000 (70%)]\tTotal Loss: 0.065403, Discriminator: 0.043327; Generator: 0.022076,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "2019-05-02 20:41:15,040 root         INFO     Train Epoch: 22 [6144/8000 (77%)]\tTotal Loss: 0.065399, Discriminator: 0.043327; Generator: 0.022072,\n",
      "D(x): 0.493, D(G(z)): 0.493\n",
      "2019-05-02 20:41:15,099 root         INFO     Train Epoch: 22 [6656/8000 (83%)]\tTotal Loss: 0.065395, Discriminator: 0.043327; Generator: 0.022068,\n",
      "D(x): 0.494, D(G(z)): 0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:15,158 root         INFO     Train Epoch: 22 [7168/8000 (90%)]\tTotal Loss: 0.065390, Discriminator: 0.043327; Generator: 0.022063,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:15,218 root         INFO     Train Epoch: 22 [7680/8000 (96%)]\tTotal Loss: 0.065386, Discriminator: 0.043327; Generator: 0.022059,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:15,281 root         INFO     ====> Epoch: 22 Average loss: 0.0654\n",
      "2019-05-02 20:41:15,317 root         INFO     Train Epoch: 23 [0/8000 (0%)]\tTotal Loss: 0.065383, Discriminator: 0.043327; Generator: 0.022057,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:15,376 root         INFO     Train Epoch: 23 [512/8000 (6%)]\tTotal Loss: 0.065379, Discriminator: 0.043327; Generator: 0.022053,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:15,433 root         INFO     Train Epoch: 23 [1024/8000 (13%)]\tTotal Loss: 0.065375, Discriminator: 0.043326; Generator: 0.022049,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:15,491 root         INFO     Train Epoch: 23 [1536/8000 (19%)]\tTotal Loss: 0.065371, Discriminator: 0.043326; Generator: 0.022045,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:15,548 root         INFO     Train Epoch: 23 [2048/8000 (26%)]\tTotal Loss: 0.065367, Discriminator: 0.043326; Generator: 0.022041,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:15,605 root         INFO     Train Epoch: 23 [2560/8000 (32%)]\tTotal Loss: 0.065363, Discriminator: 0.043326; Generator: 0.022037,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:15,662 root         INFO     Train Epoch: 23 [3072/8000 (38%)]\tTotal Loss: 0.065359, Discriminator: 0.043326; Generator: 0.022033,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:15,719 root         INFO     Train Epoch: 23 [3584/8000 (45%)]\tTotal Loss: 0.065355, Discriminator: 0.043326; Generator: 0.022029,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:15,777 root         INFO     Train Epoch: 23 [4096/8000 (51%)]\tTotal Loss: 0.065351, Discriminator: 0.043326; Generator: 0.022025,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:15,834 root         INFO     Train Epoch: 23 [4608/8000 (58%)]\tTotal Loss: 0.065347, Discriminator: 0.043326; Generator: 0.022022,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:15,891 root         INFO     Train Epoch: 23 [5120/8000 (64%)]\tTotal Loss: 0.065344, Discriminator: 0.043326; Generator: 0.022018,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:15,949 root         INFO     Train Epoch: 23 [5632/8000 (70%)]\tTotal Loss: 0.065340, Discriminator: 0.043326; Generator: 0.022014,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:16,006 root         INFO     Train Epoch: 23 [6144/8000 (77%)]\tTotal Loss: 0.065336, Discriminator: 0.043326; Generator: 0.022011,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:16,064 root         INFO     Train Epoch: 23 [6656/8000 (83%)]\tTotal Loss: 0.065332, Discriminator: 0.043325; Generator: 0.022007,\n",
      "D(x): 0.494, D(G(z)): 0.494\n",
      "2019-05-02 20:41:16,121 root         INFO     Train Epoch: 23 [7168/8000 (90%)]\tTotal Loss: 0.065329, Discriminator: 0.043325; Generator: 0.022003,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:16,178 root         INFO     Train Epoch: 23 [7680/8000 (96%)]\tTotal Loss: 0.065325, Discriminator: 0.043325; Generator: 0.022000,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:16,240 root         INFO     ====> Epoch: 23 Average loss: 0.0654\n",
      "2019-05-02 20:41:16,277 root         INFO     Train Epoch: 24 [0/8000 (0%)]\tTotal Loss: 0.065323, Discriminator: 0.043325; Generator: 0.021998,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:16,335 root         INFO     Train Epoch: 24 [512/8000 (6%)]\tTotal Loss: 0.065319, Discriminator: 0.043325; Generator: 0.021994,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:16,394 root         INFO     Train Epoch: 24 [1024/8000 (13%)]\tTotal Loss: 0.065316, Discriminator: 0.043325; Generator: 0.021991,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:16,454 root         INFO     Train Epoch: 24 [1536/8000 (19%)]\tTotal Loss: 0.065313, Discriminator: 0.043325; Generator: 0.021987,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:16,514 root         INFO     Train Epoch: 24 [2048/8000 (26%)]\tTotal Loss: 0.065309, Discriminator: 0.043325; Generator: 0.021984,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:16,573 root         INFO     Train Epoch: 24 [2560/8000 (32%)]\tTotal Loss: 0.065306, Discriminator: 0.043325; Generator: 0.021981,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:16,631 root         INFO     Train Epoch: 24 [3072/8000 (38%)]\tTotal Loss: 0.065302, Discriminator: 0.043325; Generator: 0.021977,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:16,690 root         INFO     Train Epoch: 24 [3584/8000 (45%)]\tTotal Loss: 0.065299, Discriminator: 0.043325; Generator: 0.021974,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:16,749 root         INFO     Train Epoch: 24 [4096/8000 (51%)]\tTotal Loss: 0.065296, Discriminator: 0.043325; Generator: 0.021971,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:16,809 root         INFO     Train Epoch: 24 [4608/8000 (58%)]\tTotal Loss: 0.065292, Discriminator: 0.043325; Generator: 0.021968,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:16,869 root         INFO     Train Epoch: 24 [5120/8000 (64%)]\tTotal Loss: 0.065289, Discriminator: 0.043325; Generator: 0.021965,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:16,928 root         INFO     Train Epoch: 24 [5632/8000 (70%)]\tTotal Loss: 0.065286, Discriminator: 0.043325; Generator: 0.021962,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:16,988 root         INFO     Train Epoch: 24 [6144/8000 (77%)]\tTotal Loss: 0.065283, Discriminator: 0.043325; Generator: 0.021958,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:17,047 root         INFO     Train Epoch: 24 [6656/8000 (83%)]\tTotal Loss: 0.065280, Discriminator: 0.043324; Generator: 0.021955,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:17,106 root         INFO     Train Epoch: 24 [7168/8000 (90%)]\tTotal Loss: 0.065277, Discriminator: 0.043324; Generator: 0.021952,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:17,165 root         INFO     Train Epoch: 24 [7680/8000 (96%)]\tTotal Loss: 0.065274, Discriminator: 0.043324; Generator: 0.021949,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:17,226 root         INFO     ====> Epoch: 24 Average loss: 0.0653\n",
      "2019-05-02 20:41:17,263 root         INFO     Train Epoch: 25 [0/8000 (0%)]\tTotal Loss: 0.065272, Discriminator: 0.043324; Generator: 0.021947,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:17,321 root         INFO     Train Epoch: 25 [512/8000 (6%)]\tTotal Loss: 0.065269, Discriminator: 0.043324; Generator: 0.021945,\n",
      "D(x): 0.495, D(G(z)): 0.495\n",
      "2019-05-02 20:41:17,378 root         INFO     Train Epoch: 25 [1024/8000 (13%)]\tTotal Loss: 0.065266, Discriminator: 0.043324; Generator: 0.021942,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:17,437 root         INFO     Train Epoch: 25 [1536/8000 (19%)]\tTotal Loss: 0.065263, Discriminator: 0.043324; Generator: 0.021939,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:17,495 root         INFO     Train Epoch: 25 [2048/8000 (26%)]\tTotal Loss: 0.065260, Discriminator: 0.043324; Generator: 0.021936,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:17,553 root         INFO     Train Epoch: 25 [2560/8000 (32%)]\tTotal Loss: 0.065257, Discriminator: 0.043324; Generator: 0.021933,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:17,612 root         INFO     Train Epoch: 25 [3072/8000 (38%)]\tTotal Loss: 0.065254, Discriminator: 0.043324; Generator: 0.021930,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:17,670 root         INFO     Train Epoch: 25 [3584/8000 (45%)]\tTotal Loss: 0.065251, Discriminator: 0.043324; Generator: 0.021927,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:17,727 root         INFO     Train Epoch: 25 [4096/8000 (51%)]\tTotal Loss: 0.065249, Discriminator: 0.043324; Generator: 0.021925,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:17,785 root         INFO     Train Epoch: 25 [4608/8000 (58%)]\tTotal Loss: 0.065246, Discriminator: 0.043324; Generator: 0.021922,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:17,843 root         INFO     Train Epoch: 25 [5120/8000 (64%)]\tTotal Loss: 0.065243, Discriminator: 0.043324; Generator: 0.021919,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:17,901 root         INFO     Train Epoch: 25 [5632/8000 (70%)]\tTotal Loss: 0.065240, Discriminator: 0.043324; Generator: 0.021917,\n",
      "D(x): 0.496, D(G(z)): 0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:17,959 root         INFO     Train Epoch: 25 [6144/8000 (77%)]\tTotal Loss: 0.065238, Discriminator: 0.043324; Generator: 0.021914,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:18,016 root         INFO     Train Epoch: 25 [6656/8000 (83%)]\tTotal Loss: 0.065235, Discriminator: 0.043324; Generator: 0.021911,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:18,074 root         INFO     Train Epoch: 25 [7168/8000 (90%)]\tTotal Loss: 0.065233, Discriminator: 0.043324; Generator: 0.021909,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:18,132 root         INFO     Train Epoch: 25 [7680/8000 (96%)]\tTotal Loss: 0.065230, Discriminator: 0.043324; Generator: 0.021906,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:18,193 root         INFO     ====> Epoch: 25 Average loss: 0.0652\n",
      "2019-05-02 20:41:18,229 root         INFO     Train Epoch: 26 [0/8000 (0%)]\tTotal Loss: 0.065228, Discriminator: 0.043324; Generator: 0.021905,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:18,289 root         INFO     Train Epoch: 26 [512/8000 (6%)]\tTotal Loss: 0.065226, Discriminator: 0.043324; Generator: 0.021902,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:18,349 root         INFO     Train Epoch: 26 [1024/8000 (13%)]\tTotal Loss: 0.065223, Discriminator: 0.043324; Generator: 0.021900,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:18,408 root         INFO     Train Epoch: 26 [1536/8000 (19%)]\tTotal Loss: 0.065221, Discriminator: 0.043323; Generator: 0.021897,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:18,467 root         INFO     Train Epoch: 26 [2048/8000 (26%)]\tTotal Loss: 0.065218, Discriminator: 0.043323; Generator: 0.021895,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:18,526 root         INFO     Train Epoch: 26 [2560/8000 (32%)]\tTotal Loss: 0.065216, Discriminator: 0.043323; Generator: 0.021892,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:18,585 root         INFO     Train Epoch: 26 [3072/8000 (38%)]\tTotal Loss: 0.065213, Discriminator: 0.043323; Generator: 0.021890,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:18,644 root         INFO     Train Epoch: 26 [3584/8000 (45%)]\tTotal Loss: 0.065211, Discriminator: 0.043323; Generator: 0.021888,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:18,703 root         INFO     Train Epoch: 26 [4096/8000 (51%)]\tTotal Loss: 0.065209, Discriminator: 0.043323; Generator: 0.021885,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:18,762 root         INFO     Train Epoch: 26 [4608/8000 (58%)]\tTotal Loss: 0.065206, Discriminator: 0.043323; Generator: 0.021883,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:18,819 root         INFO     Train Epoch: 26 [5120/8000 (64%)]\tTotal Loss: 0.065204, Discriminator: 0.043323; Generator: 0.021881,\n",
      "D(x): 0.496, D(G(z)): 0.496\n",
      "2019-05-02 20:41:18,876 root         INFO     Train Epoch: 26 [5632/8000 (70%)]\tTotal Loss: 0.065202, Discriminator: 0.043323; Generator: 0.021878,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:18,933 root         INFO     Train Epoch: 26 [6144/8000 (77%)]\tTotal Loss: 0.065199, Discriminator: 0.043323; Generator: 0.021876,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:18,990 root         INFO     Train Epoch: 26 [6656/8000 (83%)]\tTotal Loss: 0.065197, Discriminator: 0.043323; Generator: 0.021874,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,046 root         INFO     Train Epoch: 26 [7168/8000 (90%)]\tTotal Loss: 0.065195, Discriminator: 0.043323; Generator: 0.021872,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,102 root         INFO     Train Epoch: 26 [7680/8000 (96%)]\tTotal Loss: 0.065193, Discriminator: 0.043323; Generator: 0.021870,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,163 root         INFO     ====> Epoch: 26 Average loss: 0.0652\n",
      "2019-05-02 20:41:19,200 root         INFO     Train Epoch: 27 [0/8000 (0%)]\tTotal Loss: 0.065191, Discriminator: 0.043323; Generator: 0.021868,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,257 root         INFO     Train Epoch: 27 [512/8000 (6%)]\tTotal Loss: 0.065189, Discriminator: 0.043323; Generator: 0.021866,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,313 root         INFO     Train Epoch: 27 [1024/8000 (13%)]\tTotal Loss: 0.065187, Discriminator: 0.043323; Generator: 0.021864,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,369 root         INFO     Train Epoch: 27 [1536/8000 (19%)]\tTotal Loss: 0.065185, Discriminator: 0.043323; Generator: 0.021862,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,426 root         INFO     Train Epoch: 27 [2048/8000 (26%)]\tTotal Loss: 0.065183, Discriminator: 0.043323; Generator: 0.021860,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,483 root         INFO     Train Epoch: 27 [2560/8000 (32%)]\tTotal Loss: 0.065181, Discriminator: 0.043323; Generator: 0.021858,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,540 root         INFO     Train Epoch: 27 [3072/8000 (38%)]\tTotal Loss: 0.065179, Discriminator: 0.043323; Generator: 0.021856,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,597 root         INFO     Train Epoch: 27 [3584/8000 (45%)]\tTotal Loss: 0.065177, Discriminator: 0.043323; Generator: 0.021854,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,654 root         INFO     Train Epoch: 27 [4096/8000 (51%)]\tTotal Loss: 0.065175, Discriminator: 0.043323; Generator: 0.021852,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,711 root         INFO     Train Epoch: 27 [4608/8000 (58%)]\tTotal Loss: 0.065173, Discriminator: 0.043323; Generator: 0.021850,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,768 root         INFO     Train Epoch: 27 [5120/8000 (64%)]\tTotal Loss: 0.065171, Discriminator: 0.043323; Generator: 0.021848,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,825 root         INFO     Train Epoch: 27 [5632/8000 (70%)]\tTotal Loss: 0.065169, Discriminator: 0.043323; Generator: 0.021846,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,882 root         INFO     Train Epoch: 27 [6144/8000 (77%)]\tTotal Loss: 0.065167, Discriminator: 0.043323; Generator: 0.021844,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,939 root         INFO     Train Epoch: 27 [6656/8000 (83%)]\tTotal Loss: 0.065165, Discriminator: 0.043323; Generator: 0.021842,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:19,996 root         INFO     Train Epoch: 27 [7168/8000 (90%)]\tTotal Loss: 0.065163, Discriminator: 0.043323; Generator: 0.021840,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:20,053 root         INFO     Train Epoch: 27 [7680/8000 (96%)]\tTotal Loss: 0.065161, Discriminator: 0.043323; Generator: 0.021839,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:20,114 root         INFO     ====> Epoch: 27 Average loss: 0.0652\n",
      "2019-05-02 20:41:20,151 root         INFO     Train Epoch: 28 [0/8000 (0%)]\tTotal Loss: 0.065160, Discriminator: 0.043323; Generator: 0.021837,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:20,211 root         INFO     Train Epoch: 28 [512/8000 (6%)]\tTotal Loss: 0.065158, Discriminator: 0.043323; Generator: 0.021836,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:20,271 root         INFO     Train Epoch: 28 [1024/8000 (13%)]\tTotal Loss: 0.065156, Discriminator: 0.043323; Generator: 0.021834,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:20,331 root         INFO     Train Epoch: 28 [1536/8000 (19%)]\tTotal Loss: 0.065155, Discriminator: 0.043323; Generator: 0.021832,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:20,391 root         INFO     Train Epoch: 28 [2048/8000 (26%)]\tTotal Loss: 0.065153, Discriminator: 0.043323; Generator: 0.021830,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:20,451 root         INFO     Train Epoch: 28 [2560/8000 (32%)]\tTotal Loss: 0.065151, Discriminator: 0.043323; Generator: 0.021828,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:20,511 root         INFO     Train Epoch: 28 [3072/8000 (38%)]\tTotal Loss: 0.065149, Discriminator: 0.043323; Generator: 0.021827,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:20,571 root         INFO     Train Epoch: 28 [3584/8000 (45%)]\tTotal Loss: 0.065148, Discriminator: 0.043323; Generator: 0.021825,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:20,631 root         INFO     Train Epoch: 28 [4096/8000 (51%)]\tTotal Loss: 0.065146, Discriminator: 0.043323; Generator: 0.021823,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:20,691 root         INFO     Train Epoch: 28 [4608/8000 (58%)]\tTotal Loss: 0.065144, Discriminator: 0.043323; Generator: 0.021822,\n",
      "D(x): 0.497, D(G(z)): 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:20,748 root         INFO     Train Epoch: 28 [5120/8000 (64%)]\tTotal Loss: 0.065143, Discriminator: 0.043323; Generator: 0.021820,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:20,810 root         INFO     Train Epoch: 28 [5632/8000 (70%)]\tTotal Loss: 0.065141, Discriminator: 0.043322; Generator: 0.021818,\n",
      "D(x): 0.497, D(G(z)): 0.497\n",
      "2019-05-02 20:41:20,871 root         INFO     Train Epoch: 28 [6144/8000 (77%)]\tTotal Loss: 0.065139, Discriminator: 0.043322; Generator: 0.021817,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:20,933 root         INFO     Train Epoch: 28 [6656/8000 (83%)]\tTotal Loss: 0.065138, Discriminator: 0.043322; Generator: 0.021815,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:20,995 root         INFO     Train Epoch: 28 [7168/8000 (90%)]\tTotal Loss: 0.065136, Discriminator: 0.043322; Generator: 0.021814,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,057 root         INFO     Train Epoch: 28 [7680/8000 (96%)]\tTotal Loss: 0.065134, Discriminator: 0.043322; Generator: 0.021812,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,119 root         INFO     ====> Epoch: 28 Average loss: 0.0651\n",
      "2019-05-02 20:41:21,155 root         INFO     Train Epoch: 29 [0/8000 (0%)]\tTotal Loss: 0.065133, Discriminator: 0.043322; Generator: 0.021811,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,214 root         INFO     Train Epoch: 29 [512/8000 (6%)]\tTotal Loss: 0.065132, Discriminator: 0.043322; Generator: 0.021809,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,273 root         INFO     Train Epoch: 29 [1024/8000 (13%)]\tTotal Loss: 0.065130, Discriminator: 0.043322; Generator: 0.021808,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,331 root         INFO     Train Epoch: 29 [1536/8000 (19%)]\tTotal Loss: 0.065129, Discriminator: 0.043322; Generator: 0.021806,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,389 root         INFO     Train Epoch: 29 [2048/8000 (26%)]\tTotal Loss: 0.065127, Discriminator: 0.043322; Generator: 0.021805,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,447 root         INFO     Train Epoch: 29 [2560/8000 (32%)]\tTotal Loss: 0.065126, Discriminator: 0.043322; Generator: 0.021803,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,506 root         INFO     Train Epoch: 29 [3072/8000 (38%)]\tTotal Loss: 0.065124, Discriminator: 0.043322; Generator: 0.021802,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,564 root         INFO     Train Epoch: 29 [3584/8000 (45%)]\tTotal Loss: 0.065123, Discriminator: 0.043322; Generator: 0.021801,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,622 root         INFO     Train Epoch: 29 [4096/8000 (51%)]\tTotal Loss: 0.065121, Discriminator: 0.043322; Generator: 0.021799,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,680 root         INFO     Train Epoch: 29 [4608/8000 (58%)]\tTotal Loss: 0.065120, Discriminator: 0.043322; Generator: 0.021798,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,739 root         INFO     Train Epoch: 29 [5120/8000 (64%)]\tTotal Loss: 0.065119, Discriminator: 0.043322; Generator: 0.021796,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,797 root         INFO     Train Epoch: 29 [5632/8000 (70%)]\tTotal Loss: 0.065117, Discriminator: 0.043322; Generator: 0.021795,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,855 root         INFO     Train Epoch: 29 [6144/8000 (77%)]\tTotal Loss: 0.065116, Discriminator: 0.043322; Generator: 0.021793,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,914 root         INFO     Train Epoch: 29 [6656/8000 (83%)]\tTotal Loss: 0.065114, Discriminator: 0.043322; Generator: 0.021792,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:21,972 root         INFO     Train Epoch: 29 [7168/8000 (90%)]\tTotal Loss: 0.065113, Discriminator: 0.043322; Generator: 0.021791,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,031 root         INFO     Train Epoch: 29 [7680/8000 (96%)]\tTotal Loss: 0.065112, Discriminator: 0.043322; Generator: 0.021789,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,093 root         INFO     ====> Epoch: 29 Average loss: 0.0651\n",
      "2019-05-02 20:41:22,129 root         INFO     Train Epoch: 30 [0/8000 (0%)]\tTotal Loss: 0.065111, Discriminator: 0.043322; Generator: 0.021789,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,188 root         INFO     Train Epoch: 30 [512/8000 (6%)]\tTotal Loss: 0.065109, Discriminator: 0.043322; Generator: 0.021787,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,247 root         INFO     Train Epoch: 30 [1024/8000 (13%)]\tTotal Loss: 0.065108, Discriminator: 0.043322; Generator: 0.021786,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,305 root         INFO     Train Epoch: 30 [1536/8000 (19%)]\tTotal Loss: 0.065107, Discriminator: 0.043322; Generator: 0.021785,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,362 root         INFO     Train Epoch: 30 [2048/8000 (26%)]\tTotal Loss: 0.065106, Discriminator: 0.043322; Generator: 0.021783,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,421 root         INFO     Train Epoch: 30 [2560/8000 (32%)]\tTotal Loss: 0.065104, Discriminator: 0.043322; Generator: 0.021782,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,480 root         INFO     Train Epoch: 30 [3072/8000 (38%)]\tTotal Loss: 0.065103, Discriminator: 0.043322; Generator: 0.021781,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,538 root         INFO     Train Epoch: 30 [3584/8000 (45%)]\tTotal Loss: 0.065102, Discriminator: 0.043322; Generator: 0.021780,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,596 root         INFO     Train Epoch: 30 [4096/8000 (51%)]\tTotal Loss: 0.065101, Discriminator: 0.043322; Generator: 0.021778,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,654 root         INFO     Train Epoch: 30 [4608/8000 (58%)]\tTotal Loss: 0.065099, Discriminator: 0.043322; Generator: 0.021777,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,712 root         INFO     Train Epoch: 30 [5120/8000 (64%)]\tTotal Loss: 0.065098, Discriminator: 0.043322; Generator: 0.021776,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,770 root         INFO     Train Epoch: 30 [5632/8000 (70%)]\tTotal Loss: 0.065097, Discriminator: 0.043322; Generator: 0.021775,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,829 root         INFO     Train Epoch: 30 [6144/8000 (77%)]\tTotal Loss: 0.065096, Discriminator: 0.043322; Generator: 0.021774,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,887 root         INFO     Train Epoch: 30 [6656/8000 (83%)]\tTotal Loss: 0.065095, Discriminator: 0.043322; Generator: 0.021773,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:22,946 root         INFO     Train Epoch: 30 [7168/8000 (90%)]\tTotal Loss: 0.065093, Discriminator: 0.043322; Generator: 0.021771,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:23,004 root         INFO     Train Epoch: 30 [7680/8000 (96%)]\tTotal Loss: 0.065092, Discriminator: 0.043322; Generator: 0.021770,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:23,066 root         INFO     ====> Epoch: 30 Average loss: 0.0651\n",
      "2019-05-02 20:41:23,102 root         INFO     Train Epoch: 31 [0/8000 (0%)]\tTotal Loss: 0.065092, Discriminator: 0.043322; Generator: 0.021770,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:23,162 root         INFO     Train Epoch: 31 [512/8000 (6%)]\tTotal Loss: 0.065090, Discriminator: 0.043322; Generator: 0.021768,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:23,221 root         INFO     Train Epoch: 31 [1024/8000 (13%)]\tTotal Loss: 0.065089, Discriminator: 0.043322; Generator: 0.021767,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:23,281 root         INFO     Train Epoch: 31 [1536/8000 (19%)]\tTotal Loss: 0.065088, Discriminator: 0.043322; Generator: 0.021766,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:23,339 root         INFO     Train Epoch: 31 [2048/8000 (26%)]\tTotal Loss: 0.065087, Discriminator: 0.043322; Generator: 0.021765,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:23,399 root         INFO     Train Epoch: 31 [2560/8000 (32%)]\tTotal Loss: 0.065086, Discriminator: 0.043322; Generator: 0.021764,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:23,463 root         INFO     Train Epoch: 31 [3072/8000 (38%)]\tTotal Loss: 0.065085, Discriminator: 0.043322; Generator: 0.021763,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:23,526 root         INFO     Train Epoch: 31 [3584/8000 (45%)]\tTotal Loss: 0.065084, Discriminator: 0.043322; Generator: 0.021762,\n",
      "D(x): 0.498, D(G(z)): 0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:23,590 root         INFO     Train Epoch: 31 [4096/8000 (51%)]\tTotal Loss: 0.065083, Discriminator: 0.043322; Generator: 0.021761,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:23,653 root         INFO     Train Epoch: 31 [4608/8000 (58%)]\tTotal Loss: 0.065082, Discriminator: 0.043322; Generator: 0.021760,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:23,717 root         INFO     Train Epoch: 31 [5120/8000 (64%)]\tTotal Loss: 0.065081, Discriminator: 0.043322; Generator: 0.021759,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:23,780 root         INFO     Train Epoch: 31 [5632/8000 (70%)]\tTotal Loss: 0.065080, Discriminator: 0.043322; Generator: 0.021758,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:23,844 root         INFO     Train Epoch: 31 [6144/8000 (77%)]\tTotal Loss: 0.065079, Discriminator: 0.043322; Generator: 0.021757,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:23,907 root         INFO     Train Epoch: 31 [6656/8000 (83%)]\tTotal Loss: 0.065078, Discriminator: 0.043322; Generator: 0.021756,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:23,971 root         INFO     Train Epoch: 31 [7168/8000 (90%)]\tTotal Loss: 0.065077, Discriminator: 0.043322; Generator: 0.021755,\n",
      "D(x): 0.498, D(G(z)): 0.498\n",
      "2019-05-02 20:41:24,034 root         INFO     Train Epoch: 31 [7680/8000 (96%)]\tTotal Loss: 0.065076, Discriminator: 0.043322; Generator: 0.021754,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:24,099 root         INFO     ====> Epoch: 31 Average loss: 0.0651\n",
      "2019-05-02 20:41:24,136 root         INFO     Train Epoch: 32 [0/8000 (0%)]\tTotal Loss: 0.065075, Discriminator: 0.043322; Generator: 0.021753,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:24,194 root         INFO     Train Epoch: 32 [512/8000 (6%)]\tTotal Loss: 0.065074, Discriminator: 0.043322; Generator: 0.021752,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:24,252 root         INFO     Train Epoch: 32 [1024/8000 (13%)]\tTotal Loss: 0.065073, Discriminator: 0.043322; Generator: 0.021751,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:24,310 root         INFO     Train Epoch: 32 [1536/8000 (19%)]\tTotal Loss: 0.065072, Discriminator: 0.043322; Generator: 0.021750,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:24,370 root         INFO     Train Epoch: 32 [2048/8000 (26%)]\tTotal Loss: 0.065071, Discriminator: 0.043322; Generator: 0.021750,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:24,430 root         INFO     Train Epoch: 32 [2560/8000 (32%)]\tTotal Loss: 0.065071, Discriminator: 0.043322; Generator: 0.021749,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:24,492 root         INFO     Train Epoch: 32 [3072/8000 (38%)]\tTotal Loss: 0.065070, Discriminator: 0.043322; Generator: 0.021748,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:24,552 root         INFO     Train Epoch: 32 [3584/8000 (45%)]\tTotal Loss: 0.065069, Discriminator: 0.043322; Generator: 0.021747,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:24,611 root         INFO     Train Epoch: 32 [4096/8000 (51%)]\tTotal Loss: 0.065068, Discriminator: 0.043322; Generator: 0.021746,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:24,669 root         INFO     Train Epoch: 32 [4608/8000 (58%)]\tTotal Loss: 0.065067, Discriminator: 0.043322; Generator: 0.021745,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:24,728 root         INFO     Train Epoch: 32 [5120/8000 (64%)]\tTotal Loss: 0.065066, Discriminator: 0.043322; Generator: 0.021744,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:24,787 root         INFO     Train Epoch: 32 [5632/8000 (70%)]\tTotal Loss: 0.065065, Discriminator: 0.043322; Generator: 0.021743,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:24,846 root         INFO     Train Epoch: 32 [6144/8000 (77%)]\tTotal Loss: 0.065064, Discriminator: 0.043322; Generator: 0.021742,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:24,906 root         INFO     Train Epoch: 32 [6656/8000 (83%)]\tTotal Loss: 0.065064, Discriminator: 0.043322; Generator: 0.021742,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:24,966 root         INFO     Train Epoch: 32 [7168/8000 (90%)]\tTotal Loss: 0.065063, Discriminator: 0.043322; Generator: 0.021741,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,024 root         INFO     Train Epoch: 32 [7680/8000 (96%)]\tTotal Loss: 0.065062, Discriminator: 0.043322; Generator: 0.021740,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,085 root         INFO     ====> Epoch: 32 Average loss: 0.0651\n",
      "2019-05-02 20:41:25,121 root         INFO     Train Epoch: 33 [0/8000 (0%)]\tTotal Loss: 0.065061, Discriminator: 0.043322; Generator: 0.021739,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,179 root         INFO     Train Epoch: 33 [512/8000 (6%)]\tTotal Loss: 0.065061, Discriminator: 0.043322; Generator: 0.021739,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,236 root         INFO     Train Epoch: 33 [1024/8000 (13%)]\tTotal Loss: 0.065060, Discriminator: 0.043322; Generator: 0.021738,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,294 root         INFO     Train Epoch: 33 [1536/8000 (19%)]\tTotal Loss: 0.065059, Discriminator: 0.043322; Generator: 0.021737,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,352 root         INFO     Train Epoch: 33 [2048/8000 (26%)]\tTotal Loss: 0.065058, Discriminator: 0.043322; Generator: 0.021736,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,409 root         INFO     Train Epoch: 33 [2560/8000 (32%)]\tTotal Loss: 0.065057, Discriminator: 0.043322; Generator: 0.021736,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,467 root         INFO     Train Epoch: 33 [3072/8000 (38%)]\tTotal Loss: 0.065057, Discriminator: 0.043322; Generator: 0.021735,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,525 root         INFO     Train Epoch: 33 [3584/8000 (45%)]\tTotal Loss: 0.065056, Discriminator: 0.043322; Generator: 0.021734,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,582 root         INFO     Train Epoch: 33 [4096/8000 (51%)]\tTotal Loss: 0.065055, Discriminator: 0.043322; Generator: 0.021733,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,640 root         INFO     Train Epoch: 33 [4608/8000 (58%)]\tTotal Loss: 0.065054, Discriminator: 0.043322; Generator: 0.021732,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,698 root         INFO     Train Epoch: 33 [5120/8000 (64%)]\tTotal Loss: 0.065054, Discriminator: 0.043322; Generator: 0.021732,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,755 root         INFO     Train Epoch: 33 [5632/8000 (70%)]\tTotal Loss: 0.065053, Discriminator: 0.043322; Generator: 0.021731,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,813 root         INFO     Train Epoch: 33 [6144/8000 (77%)]\tTotal Loss: 0.065052, Discriminator: 0.043322; Generator: 0.021730,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,870 root         INFO     Train Epoch: 33 [6656/8000 (83%)]\tTotal Loss: 0.065051, Discriminator: 0.043322; Generator: 0.021730,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,928 root         INFO     Train Epoch: 33 [7168/8000 (90%)]\tTotal Loss: 0.065051, Discriminator: 0.043322; Generator: 0.021729,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:25,986 root         INFO     Train Epoch: 33 [7680/8000 (96%)]\tTotal Loss: 0.065050, Discriminator: 0.043322; Generator: 0.021728,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:26,047 root         INFO     ====> Epoch: 33 Average loss: 0.0651\n",
      "2019-05-02 20:41:26,083 root         INFO     Train Epoch: 34 [0/8000 (0%)]\tTotal Loss: 0.065050, Discriminator: 0.043322; Generator: 0.021728,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:26,142 root         INFO     Train Epoch: 34 [512/8000 (6%)]\tTotal Loss: 0.065049, Discriminator: 0.043322; Generator: 0.021727,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:26,202 root         INFO     Train Epoch: 34 [1024/8000 (13%)]\tTotal Loss: 0.065048, Discriminator: 0.043322; Generator: 0.021726,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:26,262 root         INFO     Train Epoch: 34 [1536/8000 (19%)]\tTotal Loss: 0.065048, Discriminator: 0.043322; Generator: 0.021726,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:26,321 root         INFO     Train Epoch: 34 [2048/8000 (26%)]\tTotal Loss: 0.065047, Discriminator: 0.043322; Generator: 0.021725,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:26,381 root         INFO     Train Epoch: 34 [2560/8000 (32%)]\tTotal Loss: 0.065046, Discriminator: 0.043322; Generator: 0.021724,\n",
      "D(x): 0.499, D(G(z)): 0.499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:26,441 root         INFO     Train Epoch: 34 [3072/8000 (38%)]\tTotal Loss: 0.065046, Discriminator: 0.043322; Generator: 0.021724,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:26,500 root         INFO     Train Epoch: 34 [3584/8000 (45%)]\tTotal Loss: 0.065045, Discriminator: 0.043322; Generator: 0.021723,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:26,560 root         INFO     Train Epoch: 34 [4096/8000 (51%)]\tTotal Loss: 0.065044, Discriminator: 0.043322; Generator: 0.021722,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:26,619 root         INFO     Train Epoch: 34 [4608/8000 (58%)]\tTotal Loss: 0.065044, Discriminator: 0.043322; Generator: 0.021722,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:26,676 root         INFO     Train Epoch: 34 [5120/8000 (64%)]\tTotal Loss: 0.065043, Discriminator: 0.043322; Generator: 0.021721,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:26,732 root         INFO     Train Epoch: 34 [5632/8000 (70%)]\tTotal Loss: 0.065042, Discriminator: 0.043322; Generator: 0.021721,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:26,790 root         INFO     Train Epoch: 34 [6144/8000 (77%)]\tTotal Loss: 0.065042, Discriminator: 0.043322; Generator: 0.021720,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:26,847 root         INFO     Train Epoch: 34 [6656/8000 (83%)]\tTotal Loss: 0.065041, Discriminator: 0.043322; Generator: 0.021719,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:26,905 root         INFO     Train Epoch: 34 [7168/8000 (90%)]\tTotal Loss: 0.065041, Discriminator: 0.043322; Generator: 0.021719,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:26,962 root         INFO     Train Epoch: 34 [7680/8000 (96%)]\tTotal Loss: 0.065040, Discriminator: 0.043322; Generator: 0.021718,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,023 root         INFO     ====> Epoch: 34 Average loss: 0.0650\n",
      "2019-05-02 20:41:27,059 root         INFO     Train Epoch: 35 [0/8000 (0%)]\tTotal Loss: 0.065040, Discriminator: 0.043322; Generator: 0.021718,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,118 root         INFO     Train Epoch: 35 [512/8000 (6%)]\tTotal Loss: 0.065039, Discriminator: 0.043322; Generator: 0.021717,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,176 root         INFO     Train Epoch: 35 [1024/8000 (13%)]\tTotal Loss: 0.065038, Discriminator: 0.043322; Generator: 0.021717,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,232 root         INFO     Train Epoch: 35 [1536/8000 (19%)]\tTotal Loss: 0.065038, Discriminator: 0.043322; Generator: 0.021716,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,289 root         INFO     Train Epoch: 35 [2048/8000 (26%)]\tTotal Loss: 0.065037, Discriminator: 0.043322; Generator: 0.021715,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,346 root         INFO     Train Epoch: 35 [2560/8000 (32%)]\tTotal Loss: 0.065037, Discriminator: 0.043322; Generator: 0.021715,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,402 root         INFO     Train Epoch: 35 [3072/8000 (38%)]\tTotal Loss: 0.065036, Discriminator: 0.043322; Generator: 0.021714,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,459 root         INFO     Train Epoch: 35 [3584/8000 (45%)]\tTotal Loss: 0.065036, Discriminator: 0.043322; Generator: 0.021714,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,516 root         INFO     Train Epoch: 35 [4096/8000 (51%)]\tTotal Loss: 0.065035, Discriminator: 0.043322; Generator: 0.021713,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,572 root         INFO     Train Epoch: 35 [4608/8000 (58%)]\tTotal Loss: 0.065034, Discriminator: 0.043322; Generator: 0.021713,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,630 root         INFO     Train Epoch: 35 [5120/8000 (64%)]\tTotal Loss: 0.065034, Discriminator: 0.043322; Generator: 0.021712,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,687 root         INFO     Train Epoch: 35 [5632/8000 (70%)]\tTotal Loss: 0.065033, Discriminator: 0.043322; Generator: 0.021712,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,744 root         INFO     Train Epoch: 35 [6144/8000 (77%)]\tTotal Loss: 0.065033, Discriminator: 0.043322; Generator: 0.021711,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,801 root         INFO     Train Epoch: 35 [6656/8000 (83%)]\tTotal Loss: 0.065032, Discriminator: 0.043322; Generator: 0.021711,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,858 root         INFO     Train Epoch: 35 [7168/8000 (90%)]\tTotal Loss: 0.065032, Discriminator: 0.043322; Generator: 0.021710,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,915 root         INFO     Train Epoch: 35 [7680/8000 (96%)]\tTotal Loss: 0.065031, Discriminator: 0.043322; Generator: 0.021710,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:27,977 root         INFO     ====> Epoch: 35 Average loss: 0.0650\n",
      "2019-05-02 20:41:28,013 root         INFO     Train Epoch: 36 [0/8000 (0%)]\tTotal Loss: 0.065031, Discriminator: 0.043322; Generator: 0.021709,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,071 root         INFO     Train Epoch: 36 [512/8000 (6%)]\tTotal Loss: 0.065031, Discriminator: 0.043322; Generator: 0.021709,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,128 root         INFO     Train Epoch: 36 [1024/8000 (13%)]\tTotal Loss: 0.065030, Discriminator: 0.043322; Generator: 0.021708,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,185 root         INFO     Train Epoch: 36 [1536/8000 (19%)]\tTotal Loss: 0.065030, Discriminator: 0.043322; Generator: 0.021708,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,243 root         INFO     Train Epoch: 36 [2048/8000 (26%)]\tTotal Loss: 0.065029, Discriminator: 0.043322; Generator: 0.021707,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,300 root         INFO     Train Epoch: 36 [2560/8000 (32%)]\tTotal Loss: 0.065029, Discriminator: 0.043322; Generator: 0.021707,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,357 root         INFO     Train Epoch: 36 [3072/8000 (38%)]\tTotal Loss: 0.065028, Discriminator: 0.043322; Generator: 0.021706,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,413 root         INFO     Train Epoch: 36 [3584/8000 (45%)]\tTotal Loss: 0.065028, Discriminator: 0.043322; Generator: 0.021706,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,470 root         INFO     Train Epoch: 36 [4096/8000 (51%)]\tTotal Loss: 0.065027, Discriminator: 0.043322; Generator: 0.021705,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,526 root         INFO     Train Epoch: 36 [4608/8000 (58%)]\tTotal Loss: 0.065027, Discriminator: 0.043322; Generator: 0.021705,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,583 root         INFO     Train Epoch: 36 [5120/8000 (64%)]\tTotal Loss: 0.065026, Discriminator: 0.043322; Generator: 0.021704,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,639 root         INFO     Train Epoch: 36 [5632/8000 (70%)]\tTotal Loss: 0.065026, Discriminator: 0.043322; Generator: 0.021704,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,695 root         INFO     Train Epoch: 36 [6144/8000 (77%)]\tTotal Loss: 0.065025, Discriminator: 0.043322; Generator: 0.021704,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,754 root         INFO     Train Epoch: 36 [6656/8000 (83%)]\tTotal Loss: 0.065025, Discriminator: 0.043322; Generator: 0.021703,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,810 root         INFO     Train Epoch: 36 [7168/8000 (90%)]\tTotal Loss: 0.065024, Discriminator: 0.043322; Generator: 0.021703,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,867 root         INFO     Train Epoch: 36 [7680/8000 (96%)]\tTotal Loss: 0.065024, Discriminator: 0.043322; Generator: 0.021702,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:28,927 root         INFO     ====> Epoch: 36 Average loss: 0.0650\n",
      "2019-05-02 20:41:28,964 root         INFO     Train Epoch: 37 [0/8000 (0%)]\tTotal Loss: 0.065024, Discriminator: 0.043322; Generator: 0.021702,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,024 root         INFO     Train Epoch: 37 [512/8000 (6%)]\tTotal Loss: 0.065023, Discriminator: 0.043322; Generator: 0.021702,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,083 root         INFO     Train Epoch: 37 [1024/8000 (13%)]\tTotal Loss: 0.065023, Discriminator: 0.043322; Generator: 0.021701,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,142 root         INFO     Train Epoch: 37 [1536/8000 (19%)]\tTotal Loss: 0.065022, Discriminator: 0.043322; Generator: 0.021701,\n",
      "D(x): 0.499, D(G(z)): 0.499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:29,200 root         INFO     Train Epoch: 37 [2048/8000 (26%)]\tTotal Loss: 0.065022, Discriminator: 0.043322; Generator: 0.021700,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,259 root         INFO     Train Epoch: 37 [2560/8000 (32%)]\tTotal Loss: 0.065022, Discriminator: 0.043322; Generator: 0.021700,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,316 root         INFO     Train Epoch: 37 [3072/8000 (38%)]\tTotal Loss: 0.065021, Discriminator: 0.043322; Generator: 0.021700,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,374 root         INFO     Train Epoch: 37 [3584/8000 (45%)]\tTotal Loss: 0.065021, Discriminator: 0.043322; Generator: 0.021699,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,433 root         INFO     Train Epoch: 37 [4096/8000 (51%)]\tTotal Loss: 0.065020, Discriminator: 0.043322; Generator: 0.021699,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,491 root         INFO     Train Epoch: 37 [4608/8000 (58%)]\tTotal Loss: 0.065020, Discriminator: 0.043322; Generator: 0.021698,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,552 root         INFO     Train Epoch: 37 [5120/8000 (64%)]\tTotal Loss: 0.065020, Discriminator: 0.043322; Generator: 0.021698,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,610 root         INFO     Train Epoch: 37 [5632/8000 (70%)]\tTotal Loss: 0.065019, Discriminator: 0.043322; Generator: 0.021698,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,667 root         INFO     Train Epoch: 37 [6144/8000 (77%)]\tTotal Loss: 0.065019, Discriminator: 0.043322; Generator: 0.021697,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,725 root         INFO     Train Epoch: 37 [6656/8000 (83%)]\tTotal Loss: 0.065019, Discriminator: 0.043322; Generator: 0.021697,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,782 root         INFO     Train Epoch: 37 [7168/8000 (90%)]\tTotal Loss: 0.065018, Discriminator: 0.043322; Generator: 0.021696,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,839 root         INFO     Train Epoch: 37 [7680/8000 (96%)]\tTotal Loss: 0.065018, Discriminator: 0.043322; Generator: 0.021696,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,900 root         INFO     ====> Epoch: 37 Average loss: 0.0650\n",
      "2019-05-02 20:41:29,937 root         INFO     Train Epoch: 38 [0/8000 (0%)]\tTotal Loss: 0.065018, Discriminator: 0.043322; Generator: 0.021696,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:29,995 root         INFO     Train Epoch: 38 [512/8000 (6%)]\tTotal Loss: 0.065017, Discriminator: 0.043322; Generator: 0.021695,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:30,052 root         INFO     Train Epoch: 38 [1024/8000 (13%)]\tTotal Loss: 0.065017, Discriminator: 0.043322; Generator: 0.021695,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:30,109 root         INFO     Train Epoch: 38 [1536/8000 (19%)]\tTotal Loss: 0.065017, Discriminator: 0.043322; Generator: 0.021695,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:30,167 root         INFO     Train Epoch: 38 [2048/8000 (26%)]\tTotal Loss: 0.065016, Discriminator: 0.043322; Generator: 0.021694,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:30,224 root         INFO     Train Epoch: 38 [2560/8000 (32%)]\tTotal Loss: 0.065016, Discriminator: 0.043322; Generator: 0.021694,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:30,281 root         INFO     Train Epoch: 38 [3072/8000 (38%)]\tTotal Loss: 0.065015, Discriminator: 0.043322; Generator: 0.021694,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:30,338 root         INFO     Train Epoch: 38 [3584/8000 (45%)]\tTotal Loss: 0.065015, Discriminator: 0.043322; Generator: 0.021693,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:30,395 root         INFO     Train Epoch: 38 [4096/8000 (51%)]\tTotal Loss: 0.065015, Discriminator: 0.043322; Generator: 0.021693,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:30,452 root         INFO     Train Epoch: 38 [4608/8000 (58%)]\tTotal Loss: 0.065014, Discriminator: 0.043322; Generator: 0.021693,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:30,510 root         INFO     Train Epoch: 38 [5120/8000 (64%)]\tTotal Loss: 0.065014, Discriminator: 0.043322; Generator: 0.021692,\n",
      "D(x): 0.499, D(G(z)): 0.499\n",
      "2019-05-02 20:41:30,567 root         INFO     Train Epoch: 38 [5632/8000 (70%)]\tTotal Loss: 0.065014, Discriminator: 0.043322; Generator: 0.021692,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:30,624 root         INFO     Train Epoch: 38 [6144/8000 (77%)]\tTotal Loss: 0.065013, Discriminator: 0.043322; Generator: 0.021692,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:30,681 root         INFO     Train Epoch: 38 [6656/8000 (83%)]\tTotal Loss: 0.065013, Discriminator: 0.043322; Generator: 0.021691,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:30,738 root         INFO     Train Epoch: 38 [7168/8000 (90%)]\tTotal Loss: 0.065013, Discriminator: 0.043322; Generator: 0.021691,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:30,796 root         INFO     Train Epoch: 38 [7680/8000 (96%)]\tTotal Loss: 0.065013, Discriminator: 0.043322; Generator: 0.021691,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:30,857 root         INFO     ====> Epoch: 38 Average loss: 0.0650\n",
      "2019-05-02 20:41:30,893 root         INFO     Train Epoch: 39 [0/8000 (0%)]\tTotal Loss: 0.065012, Discriminator: 0.043322; Generator: 0.021691,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:30,952 root         INFO     Train Epoch: 39 [512/8000 (6%)]\tTotal Loss: 0.065012, Discriminator: 0.043322; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,011 root         INFO     Train Epoch: 39 [1024/8000 (13%)]\tTotal Loss: 0.065012, Discriminator: 0.043322; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,069 root         INFO     Train Epoch: 39 [1536/8000 (19%)]\tTotal Loss: 0.065011, Discriminator: 0.043322; Generator: 0.021690,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,127 root         INFO     Train Epoch: 39 [2048/8000 (26%)]\tTotal Loss: 0.065011, Discriminator: 0.043322; Generator: 0.021689,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,186 root         INFO     Train Epoch: 39 [2560/8000 (32%)]\tTotal Loss: 0.065011, Discriminator: 0.043322; Generator: 0.021689,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,243 root         INFO     Train Epoch: 39 [3072/8000 (38%)]\tTotal Loss: 0.065011, Discriminator: 0.043322; Generator: 0.021689,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,301 root         INFO     Train Epoch: 39 [3584/8000 (45%)]\tTotal Loss: 0.065010, Discriminator: 0.043322; Generator: 0.021689,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,360 root         INFO     Train Epoch: 39 [4096/8000 (51%)]\tTotal Loss: 0.065010, Discriminator: 0.043322; Generator: 0.021688,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,419 root         INFO     Train Epoch: 39 [4608/8000 (58%)]\tTotal Loss: 0.065010, Discriminator: 0.043322; Generator: 0.021688,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,478 root         INFO     Train Epoch: 39 [5120/8000 (64%)]\tTotal Loss: 0.065009, Discriminator: 0.043322; Generator: 0.021688,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,537 root         INFO     Train Epoch: 39 [5632/8000 (70%)]\tTotal Loss: 0.065009, Discriminator: 0.043322; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,594 root         INFO     Train Epoch: 39 [6144/8000 (77%)]\tTotal Loss: 0.065009, Discriminator: 0.043322; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,651 root         INFO     Train Epoch: 39 [6656/8000 (83%)]\tTotal Loss: 0.065009, Discriminator: 0.043322; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,707 root         INFO     Train Epoch: 39 [7168/8000 (90%)]\tTotal Loss: 0.065008, Discriminator: 0.043322; Generator: 0.021687,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,764 root         INFO     Train Epoch: 39 [7680/8000 (96%)]\tTotal Loss: 0.065008, Discriminator: 0.043322; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,825 root         INFO     ====> Epoch: 39 Average loss: 0.0650\n",
      "2019-05-02 20:41:31,863 root         INFO     Train Epoch: 40 [0/8000 (0%)]\tTotal Loss: 0.065008, Discriminator: 0.043322; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:31,922 root         INFO     Train Epoch: 40 [512/8000 (6%)]\tTotal Loss: 0.065008, Discriminator: 0.043322; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:31,980 root         INFO     Train Epoch: 40 [1024/8000 (13%)]\tTotal Loss: 0.065007, Discriminator: 0.043322; Generator: 0.021686,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,038 root         INFO     Train Epoch: 40 [1536/8000 (19%)]\tTotal Loss: 0.065007, Discriminator: 0.043322; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,096 root         INFO     Train Epoch: 40 [2048/8000 (26%)]\tTotal Loss: 0.065007, Discriminator: 0.043322; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,156 root         INFO     Train Epoch: 40 [2560/8000 (32%)]\tTotal Loss: 0.065007, Discriminator: 0.043322; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,214 root         INFO     Train Epoch: 40 [3072/8000 (38%)]\tTotal Loss: 0.065006, Discriminator: 0.043322; Generator: 0.021685,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,273 root         INFO     Train Epoch: 40 [3584/8000 (45%)]\tTotal Loss: 0.065006, Discriminator: 0.043322; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,332 root         INFO     Train Epoch: 40 [4096/8000 (51%)]\tTotal Loss: 0.065006, Discriminator: 0.043322; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,391 root         INFO     Train Epoch: 40 [4608/8000 (58%)]\tTotal Loss: 0.065006, Discriminator: 0.043322; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,451 root         INFO     Train Epoch: 40 [5120/8000 (64%)]\tTotal Loss: 0.065005, Discriminator: 0.043322; Generator: 0.021684,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,511 root         INFO     Train Epoch: 40 [5632/8000 (70%)]\tTotal Loss: 0.065005, Discriminator: 0.043322; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,570 root         INFO     Train Epoch: 40 [6144/8000 (77%)]\tTotal Loss: 0.065005, Discriminator: 0.043322; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,630 root         INFO     Train Epoch: 40 [6656/8000 (83%)]\tTotal Loss: 0.065005, Discriminator: 0.043322; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,689 root         INFO     Train Epoch: 40 [7168/8000 (90%)]\tTotal Loss: 0.065004, Discriminator: 0.043322; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,749 root         INFO     Train Epoch: 40 [7680/8000 (96%)]\tTotal Loss: 0.065004, Discriminator: 0.043322; Generator: 0.021683,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,812 root         INFO     ====> Epoch: 40 Average loss: 0.0650\n",
      "2019-05-02 20:41:32,848 root         INFO     Train Epoch: 41 [0/8000 (0%)]\tTotal Loss: 0.065004, Discriminator: 0.043322; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,909 root         INFO     Train Epoch: 41 [512/8000 (6%)]\tTotal Loss: 0.065004, Discriminator: 0.043322; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:32,966 root         INFO     Train Epoch: 41 [1024/8000 (13%)]\tTotal Loss: 0.065004, Discriminator: 0.043322; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,024 root         INFO     Train Epoch: 41 [1536/8000 (19%)]\tTotal Loss: 0.065003, Discriminator: 0.043322; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,082 root         INFO     Train Epoch: 41 [2048/8000 (26%)]\tTotal Loss: 0.065003, Discriminator: 0.043322; Generator: 0.021682,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,140 root         INFO     Train Epoch: 41 [2560/8000 (32%)]\tTotal Loss: 0.065003, Discriminator: 0.043322; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,198 root         INFO     Train Epoch: 41 [3072/8000 (38%)]\tTotal Loss: 0.065003, Discriminator: 0.043322; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,256 root         INFO     Train Epoch: 41 [3584/8000 (45%)]\tTotal Loss: 0.065003, Discriminator: 0.043322; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,314 root         INFO     Train Epoch: 41 [4096/8000 (51%)]\tTotal Loss: 0.065002, Discriminator: 0.043322; Generator: 0.021681,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,371 root         INFO     Train Epoch: 41 [4608/8000 (58%)]\tTotal Loss: 0.065002, Discriminator: 0.043322; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,429 root         INFO     Train Epoch: 41 [5120/8000 (64%)]\tTotal Loss: 0.065002, Discriminator: 0.043322; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,487 root         INFO     Train Epoch: 41 [5632/8000 (70%)]\tTotal Loss: 0.065002, Discriminator: 0.043322; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,545 root         INFO     Train Epoch: 41 [6144/8000 (77%)]\tTotal Loss: 0.065002, Discriminator: 0.043322; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,602 root         INFO     Train Epoch: 41 [6656/8000 (83%)]\tTotal Loss: 0.065001, Discriminator: 0.043322; Generator: 0.021680,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,660 root         INFO     Train Epoch: 41 [7168/8000 (90%)]\tTotal Loss: 0.065001, Discriminator: 0.043322; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,718 root         INFO     Train Epoch: 41 [7680/8000 (96%)]\tTotal Loss: 0.065001, Discriminator: 0.043322; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,779 root         INFO     ====> Epoch: 41 Average loss: 0.0650\n",
      "2019-05-02 20:41:33,816 root         INFO     Train Epoch: 42 [0/8000 (0%)]\tTotal Loss: 0.065001, Discriminator: 0.043322; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,876 root         INFO     Train Epoch: 42 [512/8000 (6%)]\tTotal Loss: 0.065001, Discriminator: 0.043322; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,933 root         INFO     Train Epoch: 42 [1024/8000 (13%)]\tTotal Loss: 0.065000, Discriminator: 0.043322; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:33,991 root         INFO     Train Epoch: 42 [1536/8000 (19%)]\tTotal Loss: 0.065000, Discriminator: 0.043322; Generator: 0.021679,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:34,048 root         INFO     Train Epoch: 42 [2048/8000 (26%)]\tTotal Loss: 0.065000, Discriminator: 0.043322; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:34,106 root         INFO     Train Epoch: 42 [2560/8000 (32%)]\tTotal Loss: 0.065000, Discriminator: 0.043322; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:34,164 root         INFO     Train Epoch: 42 [3072/8000 (38%)]\tTotal Loss: 0.065000, Discriminator: 0.043322; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:34,221 root         INFO     Train Epoch: 42 [3584/8000 (45%)]\tTotal Loss: 0.065000, Discriminator: 0.043322; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:34,278 root         INFO     Train Epoch: 42 [4096/8000 (51%)]\tTotal Loss: 0.064999, Discriminator: 0.043322; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:34,335 root         INFO     Train Epoch: 42 [4608/8000 (58%)]\tTotal Loss: 0.064999, Discriminator: 0.043322; Generator: 0.021678,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:34,393 root         INFO     Train Epoch: 42 [5120/8000 (64%)]\tTotal Loss: 0.064999, Discriminator: 0.043322; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:34,450 root         INFO     Train Epoch: 42 [5632/8000 (70%)]\tTotal Loss: 0.064999, Discriminator: 0.043322; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:34,507 root         INFO     Train Epoch: 42 [6144/8000 (77%)]\tTotal Loss: 0.064999, Discriminator: 0.043322; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:34,564 root         INFO     Train Epoch: 42 [6656/8000 (83%)]\tTotal Loss: 0.064999, Discriminator: 0.043322; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:34,622 root         INFO     Train Epoch: 42 [7168/8000 (90%)]\tTotal Loss: 0.064998, Discriminator: 0.043322; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:34,680 root         INFO     Train Epoch: 42 [7680/8000 (96%)]\tTotal Loss: 0.064998, Discriminator: 0.043322; Generator: 0.021677,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:34,742 root         INFO     ====> Epoch: 42 Average loss: 0.0650\n",
      "2019-05-02 20:41:34,778 root         INFO     Train Epoch: 43 [0/8000 (0%)]\tTotal Loss: 0.064998, Discriminator: 0.043322; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:34,837 root         INFO     Train Epoch: 43 [512/8000 (6%)]\tTotal Loss: 0.064998, Discriminator: 0.043322; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:34,896 root         INFO     Train Epoch: 43 [1024/8000 (13%)]\tTotal Loss: 0.064998, Discriminator: 0.043322; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:34,954 root         INFO     Train Epoch: 43 [1536/8000 (19%)]\tTotal Loss: 0.064998, Discriminator: 0.043322; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,013 root         INFO     Train Epoch: 43 [2048/8000 (26%)]\tTotal Loss: 0.064997, Discriminator: 0.043322; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,071 root         INFO     Train Epoch: 43 [2560/8000 (32%)]\tTotal Loss: 0.064997, Discriminator: 0.043322; Generator: 0.021676,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,129 root         INFO     Train Epoch: 43 [3072/8000 (38%)]\tTotal Loss: 0.064997, Discriminator: 0.043322; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,188 root         INFO     Train Epoch: 43 [3584/8000 (45%)]\tTotal Loss: 0.064997, Discriminator: 0.043322; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,247 root         INFO     Train Epoch: 43 [4096/8000 (51%)]\tTotal Loss: 0.064997, Discriminator: 0.043322; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,306 root         INFO     Train Epoch: 43 [4608/8000 (58%)]\tTotal Loss: 0.064997, Discriminator: 0.043322; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,365 root         INFO     Train Epoch: 43 [5120/8000 (64%)]\tTotal Loss: 0.064997, Discriminator: 0.043322; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,424 root         INFO     Train Epoch: 43 [5632/8000 (70%)]\tTotal Loss: 0.064996, Discriminator: 0.043322; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,483 root         INFO     Train Epoch: 43 [6144/8000 (77%)]\tTotal Loss: 0.064996, Discriminator: 0.043322; Generator: 0.021675,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,542 root         INFO     Train Epoch: 43 [6656/8000 (83%)]\tTotal Loss: 0.064996, Discriminator: 0.043322; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,601 root         INFO     Train Epoch: 43 [7168/8000 (90%)]\tTotal Loss: 0.064996, Discriminator: 0.043322; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,660 root         INFO     Train Epoch: 43 [7680/8000 (96%)]\tTotal Loss: 0.064996, Discriminator: 0.043322; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,723 root         INFO     ====> Epoch: 43 Average loss: 0.0650\n",
      "2019-05-02 20:41:35,759 root         INFO     Train Epoch: 44 [0/8000 (0%)]\tTotal Loss: 0.064996, Discriminator: 0.043322; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,818 root         INFO     Train Epoch: 44 [512/8000 (6%)]\tTotal Loss: 0.064996, Discriminator: 0.043322; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,877 root         INFO     Train Epoch: 44 [1024/8000 (13%)]\tTotal Loss: 0.064996, Discriminator: 0.043322; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,936 root         INFO     Train Epoch: 44 [1536/8000 (19%)]\tTotal Loss: 0.064995, Discriminator: 0.043322; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:35,994 root         INFO     Train Epoch: 44 [2048/8000 (26%)]\tTotal Loss: 0.064995, Discriminator: 0.043322; Generator: 0.021674,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,053 root         INFO     Train Epoch: 44 [2560/8000 (32%)]\tTotal Loss: 0.064995, Discriminator: 0.043322; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,111 root         INFO     Train Epoch: 44 [3072/8000 (38%)]\tTotal Loss: 0.064995, Discriminator: 0.043322; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,170 root         INFO     Train Epoch: 44 [3584/8000 (45%)]\tTotal Loss: 0.064995, Discriminator: 0.043322; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,228 root         INFO     Train Epoch: 44 [4096/8000 (51%)]\tTotal Loss: 0.064995, Discriminator: 0.043322; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,287 root         INFO     Train Epoch: 44 [4608/8000 (58%)]\tTotal Loss: 0.064995, Discriminator: 0.043322; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,346 root         INFO     Train Epoch: 44 [5120/8000 (64%)]\tTotal Loss: 0.064995, Discriminator: 0.043322; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,404 root         INFO     Train Epoch: 44 [5632/8000 (70%)]\tTotal Loss: 0.064994, Discriminator: 0.043322; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,463 root         INFO     Train Epoch: 44 [6144/8000 (77%)]\tTotal Loss: 0.064994, Discriminator: 0.043322; Generator: 0.021673,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,521 root         INFO     Train Epoch: 44 [6656/8000 (83%)]\tTotal Loss: 0.064994, Discriminator: 0.043322; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,579 root         INFO     Train Epoch: 44 [7168/8000 (90%)]\tTotal Loss: 0.064994, Discriminator: 0.043322; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,637 root         INFO     Train Epoch: 44 [7680/8000 (96%)]\tTotal Loss: 0.064994, Discriminator: 0.043322; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,700 root         INFO     ====> Epoch: 44 Average loss: 0.0650\n",
      "2019-05-02 20:41:36,736 root         INFO     Train Epoch: 45 [0/8000 (0%)]\tTotal Loss: 0.064994, Discriminator: 0.043322; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,795 root         INFO     Train Epoch: 45 [512/8000 (6%)]\tTotal Loss: 0.064994, Discriminator: 0.043322; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,854 root         INFO     Train Epoch: 45 [1024/8000 (13%)]\tTotal Loss: 0.064994, Discriminator: 0.043322; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,912 root         INFO     Train Epoch: 45 [1536/8000 (19%)]\tTotal Loss: 0.064993, Discriminator: 0.043322; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:36,969 root         INFO     Train Epoch: 45 [2048/8000 (26%)]\tTotal Loss: 0.064993, Discriminator: 0.043322; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,027 root         INFO     Train Epoch: 45 [2560/8000 (32%)]\tTotal Loss: 0.064993, Discriminator: 0.043322; Generator: 0.021672,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,084 root         INFO     Train Epoch: 45 [3072/8000 (38%)]\tTotal Loss: 0.064993, Discriminator: 0.043322; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,141 root         INFO     Train Epoch: 45 [3584/8000 (45%)]\tTotal Loss: 0.064993, Discriminator: 0.043322; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,199 root         INFO     Train Epoch: 45 [4096/8000 (51%)]\tTotal Loss: 0.064993, Discriminator: 0.043322; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,257 root         INFO     Train Epoch: 45 [4608/8000 (58%)]\tTotal Loss: 0.064993, Discriminator: 0.043322; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,314 root         INFO     Train Epoch: 45 [5120/8000 (64%)]\tTotal Loss: 0.064993, Discriminator: 0.043322; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,372 root         INFO     Train Epoch: 45 [5632/8000 (70%)]\tTotal Loss: 0.064993, Discriminator: 0.043322; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,429 root         INFO     Train Epoch: 45 [6144/8000 (77%)]\tTotal Loss: 0.064992, Discriminator: 0.043322; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,487 root         INFO     Train Epoch: 45 [6656/8000 (83%)]\tTotal Loss: 0.064992, Discriminator: 0.043322; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:37,544 root         INFO     Train Epoch: 45 [7168/8000 (90%)]\tTotal Loss: 0.064992, Discriminator: 0.043322; Generator: 0.021671,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,601 root         INFO     Train Epoch: 45 [7680/8000 (96%)]\tTotal Loss: 0.064992, Discriminator: 0.043322; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,663 root         INFO     ====> Epoch: 45 Average loss: 0.0650\n",
      "2019-05-02 20:41:37,698 root         INFO     Train Epoch: 46 [0/8000 (0%)]\tTotal Loss: 0.064992, Discriminator: 0.043322; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,757 root         INFO     Train Epoch: 46 [512/8000 (6%)]\tTotal Loss: 0.064992, Discriminator: 0.043322; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,815 root         INFO     Train Epoch: 46 [1024/8000 (13%)]\tTotal Loss: 0.064992, Discriminator: 0.043322; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,872 root         INFO     Train Epoch: 46 [1536/8000 (19%)]\tTotal Loss: 0.064992, Discriminator: 0.043322; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,930 root         INFO     Train Epoch: 46 [2048/8000 (26%)]\tTotal Loss: 0.064992, Discriminator: 0.043322; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:37,988 root         INFO     Train Epoch: 46 [2560/8000 (32%)]\tTotal Loss: 0.064992, Discriminator: 0.043322; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,046 root         INFO     Train Epoch: 46 [3072/8000 (38%)]\tTotal Loss: 0.064992, Discriminator: 0.043322; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,104 root         INFO     Train Epoch: 46 [3584/8000 (45%)]\tTotal Loss: 0.064991, Discriminator: 0.043322; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,162 root         INFO     Train Epoch: 46 [4096/8000 (51%)]\tTotal Loss: 0.064991, Discriminator: 0.043322; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,220 root         INFO     Train Epoch: 46 [4608/8000 (58%)]\tTotal Loss: 0.064991, Discriminator: 0.043322; Generator: 0.021670,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,278 root         INFO     Train Epoch: 46 [5120/8000 (64%)]\tTotal Loss: 0.064991, Discriminator: 0.043322; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,336 root         INFO     Train Epoch: 46 [5632/8000 (70%)]\tTotal Loss: 0.064991, Discriminator: 0.043322; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,394 root         INFO     Train Epoch: 46 [6144/8000 (77%)]\tTotal Loss: 0.064991, Discriminator: 0.043322; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,451 root         INFO     Train Epoch: 46 [6656/8000 (83%)]\tTotal Loss: 0.064991, Discriminator: 0.043322; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,507 root         INFO     Train Epoch: 46 [7168/8000 (90%)]\tTotal Loss: 0.064991, Discriminator: 0.043322; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,563 root         INFO     Train Epoch: 46 [7680/8000 (96%)]\tTotal Loss: 0.064991, Discriminator: 0.043322; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,624 root         INFO     ====> Epoch: 46 Average loss: 0.0650\n",
      "2019-05-02 20:41:38,660 root         INFO     Train Epoch: 47 [0/8000 (0%)]\tTotal Loss: 0.064991, Discriminator: 0.043322; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,720 root         INFO     Train Epoch: 47 [512/8000 (6%)]\tTotal Loss: 0.064991, Discriminator: 0.043322; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,778 root         INFO     Train Epoch: 47 [1024/8000 (13%)]\tTotal Loss: 0.064991, Discriminator: 0.043322; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,837 root         INFO     Train Epoch: 47 [1536/8000 (19%)]\tTotal Loss: 0.064990, Discriminator: 0.043322; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,895 root         INFO     Train Epoch: 47 [2048/8000 (26%)]\tTotal Loss: 0.064990, Discriminator: 0.043322; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:38,953 root         INFO     Train Epoch: 47 [2560/8000 (32%)]\tTotal Loss: 0.064990, Discriminator: 0.043322; Generator: 0.021669,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,011 root         INFO     Train Epoch: 47 [3072/8000 (38%)]\tTotal Loss: 0.064990, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,068 root         INFO     Train Epoch: 47 [3584/8000 (45%)]\tTotal Loss: 0.064990, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,126 root         INFO     Train Epoch: 47 [4096/8000 (51%)]\tTotal Loss: 0.064990, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,184 root         INFO     Train Epoch: 47 [4608/8000 (58%)]\tTotal Loss: 0.064990, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,240 root         INFO     Train Epoch: 47 [5120/8000 (64%)]\tTotal Loss: 0.064990, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,296 root         INFO     Train Epoch: 47 [5632/8000 (70%)]\tTotal Loss: 0.064990, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,352 root         INFO     Train Epoch: 47 [6144/8000 (77%)]\tTotal Loss: 0.064990, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,407 root         INFO     Train Epoch: 47 [6656/8000 (83%)]\tTotal Loss: 0.064990, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,463 root         INFO     Train Epoch: 47 [7168/8000 (90%)]\tTotal Loss: 0.064990, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,518 root         INFO     Train Epoch: 47 [7680/8000 (96%)]\tTotal Loss: 0.064990, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,579 root         INFO     ====> Epoch: 47 Average loss: 0.0650\n",
      "2019-05-02 20:41:39,615 root         INFO     Train Epoch: 48 [0/8000 (0%)]\tTotal Loss: 0.064989, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,674 root         INFO     Train Epoch: 48 [512/8000 (6%)]\tTotal Loss: 0.064989, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,733 root         INFO     Train Epoch: 48 [1024/8000 (13%)]\tTotal Loss: 0.064989, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,791 root         INFO     Train Epoch: 48 [1536/8000 (19%)]\tTotal Loss: 0.064989, Discriminator: 0.043322; Generator: 0.021668,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,849 root         INFO     Train Epoch: 48 [2048/8000 (26%)]\tTotal Loss: 0.064989, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,907 root         INFO     Train Epoch: 48 [2560/8000 (32%)]\tTotal Loss: 0.064989, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:39,965 root         INFO     Train Epoch: 48 [3072/8000 (38%)]\tTotal Loss: 0.064989, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,023 root         INFO     Train Epoch: 48 [3584/8000 (45%)]\tTotal Loss: 0.064989, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,082 root         INFO     Train Epoch: 48 [4096/8000 (51%)]\tTotal Loss: 0.064989, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,140 root         INFO     Train Epoch: 48 [4608/8000 (58%)]\tTotal Loss: 0.064989, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,197 root         INFO     Train Epoch: 48 [5120/8000 (64%)]\tTotal Loss: 0.064989, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,255 root         INFO     Train Epoch: 48 [5632/8000 (70%)]\tTotal Loss: 0.064989, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:40,313 root         INFO     Train Epoch: 48 [6144/8000 (77%)]\tTotal Loss: 0.064989, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,372 root         INFO     Train Epoch: 48 [6656/8000 (83%)]\tTotal Loss: 0.064989, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,429 root         INFO     Train Epoch: 48 [7168/8000 (90%)]\tTotal Loss: 0.064989, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,487 root         INFO     Train Epoch: 48 [7680/8000 (96%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,549 root         INFO     ====> Epoch: 48 Average loss: 0.0650\n",
      "2019-05-02 20:41:40,585 root         INFO     Train Epoch: 49 [0/8000 (0%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,644 root         INFO     Train Epoch: 49 [512/8000 (6%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,703 root         INFO     Train Epoch: 49 [1024/8000 (13%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,761 root         INFO     Train Epoch: 49 [1536/8000 (19%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,820 root         INFO     Train Epoch: 49 [2048/8000 (26%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021667,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,878 root         INFO     Train Epoch: 49 [2560/8000 (32%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,937 root         INFO     Train Epoch: 49 [3072/8000 (38%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:40,996 root         INFO     Train Epoch: 49 [3584/8000 (45%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:41,055 root         INFO     Train Epoch: 49 [4096/8000 (51%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:41,114 root         INFO     Train Epoch: 49 [4608/8000 (58%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:41,172 root         INFO     Train Epoch: 49 [5120/8000 (64%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:41,231 root         INFO     Train Epoch: 49 [5632/8000 (70%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:41,290 root         INFO     Train Epoch: 49 [6144/8000 (77%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:41,349 root         INFO     Train Epoch: 49 [6656/8000 (83%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:41,408 root         INFO     Train Epoch: 49 [7168/8000 (90%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:41,466 root         INFO     Train Epoch: 49 [7680/8000 (96%)]\tTotal Loss: 0.064988, Discriminator: 0.043322; Generator: 0.021666,\n",
      "D(x): 0.500, D(G(z)): 0.500\n",
      "2019-05-02 20:41:41,529 root         INFO     ====> Epoch: 49 Average loss: 0.0650\n"
     ]
    }
   ],
   "source": [
    "logging.info('--Dataset tensor: (%d, %d)' % dataset.shape)\n",
    "\n",
    "n_train = int((1 - FRAC_TEST) * N_SAMPLES)\n",
    "train = torch.Tensor(dataset[:n_train, :])\n",
    "\n",
    "logging.info('-- Train tensor: (%d, %d)' % train.shape)\n",
    "train_dataset = torch.utils.data.TensorDataset(train)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "train_dataset, batch_size=BATCH_SIZE, shuffle=True, **KWARGS)\n",
    "\n",
    "decoder = toynn.Decoder(\n",
    "            latent_dim=LATENT_DIM,\n",
    "            data_dim=DATA_DIM,\n",
    "            n_layers=N_DECODER_LAYERS,\n",
    "            nonlinearity=NONLINEARITY,\n",
    "            with_biasx=WITH_BIASX,\n",
    "            with_logvarx=WITH_LOGVARX).to(DEVICE)\n",
    "\n",
    "# Set the value of the decoder to the biased value we know happens\n",
    "\n",
    "decoder.layers[0].weight.data = torch.tensor([[1.10]]).to(DEVICE)\n",
    "\n",
    "discriminator = toynn.Discriminator(data_dim=DATA_DIM).to(DEVICE)\n",
    "\n",
    "modules = {}\n",
    "modules['decoder'] = decoder\n",
    "modules['discriminator'] = discriminator\n",
    "\n",
    "logging.info('Values of VAE\\'s decoder parameters before training:')\n",
    "for name, param in decoder.named_parameters():\n",
    "    logging.info(name)\n",
    "    logging.info(param.data)\n",
    "\n",
    "optimizers = {}\n",
    "optimizers['decoder'] = torch.optim.Adam(\n",
    "    modules['decoder'].parameters(), lr=LR, betas=(BETA1, BETA2))\n",
    "optimizers['discriminator'] = torch.optim.SGD(\n",
    "    modules['discriminator'].parameters(), lr=LR)\n",
    "\n",
    "\n",
    "def init_xavier_normal(m):\n",
    "    if type(m) == tnn.Linear:\n",
    "        tnn.init.xavier_normal_(m.weight)\n",
    "\n",
    "    for module in modules.values():\n",
    "        module.apply(init_xavier_normal)\n",
    "\n",
    "train_losses_all_epochs = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    if DEBUG:\n",
    "        if epoch > 2:\n",
    "            break\n",
    "\n",
    "    train_losses = train_gan(\n",
    "                epoch, train_loader, modules, optimizers)\n",
    "    train_losses_all_epochs.append(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-02 20:41:41,545 root         INFO     Values of VAE's decoder parameters after training:\n",
      "2019-05-02 20:41:41,545 root         INFO     layers.0.weight\n",
      "2019-05-02 20:41:41,545 root         INFO     tensor([[1.1362]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last losses:\n",
      "[0.0649929473400116, 0.06499139633774757, 0.06499006834626198, 0.06498894593119621, 0.06498799261450768]\n",
      "1.1362075\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "train_losses_total = [loss['total'] for loss in train_losses_all_epochs]\n",
    "n_epochs = len(train_losses_total)\n",
    "plt.plot(range(n_epochs), train_losses_total)\n",
    "print('Last losses:')\n",
    "print(train_losses_total[-5:])\n",
    "\n",
    "logging.info('Values of VAE\\'s decoder parameters after training:')\n",
    "for name, param in decoder.named_parameters():\n",
    "    logging.info(name)\n",
    "    logging.info(param.data)\n",
    "    w_learnt = param.data[0,0].cpu().numpy()\n",
    "print(w_learnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0a50bfdcc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 10000\n",
    "#generated_x = toynn.generate_from_decoder(decoder, n_samples)\n",
    "generated_x = generate_synthetic_1d(w=w_learnt, n=n_samples)\n",
    "                                    \n",
    "# For 1D\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(16, 4))\n",
    "axis_side = 20\n",
    "\n",
    "ax = axes[0]\n",
    "toyvis.plot_data(dataset, color='darkgreen', ax=ax)\n",
    "\n",
    "ax = axes[1]\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax)\n",
    "\n",
    "ax = axes[2]\n",
    "toyvis.plot_data(dataset, color='darkgreen', ax=ax, label='true')\n",
    "toyvis.plot_data(generated_x, color='red', ax=ax, label='vae estimate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
